[
  {
    "text": "welcome to this first breakout session I hope you enjoyed the keynote my name is",
    "start": "60",
    "end": "6060"
  },
  {
    "text": "Julian I'm tech evangelist with AWS focusing on AI and machine learning and",
    "start": "6060",
    "end": "11099"
  },
  {
    "text": "it's great to be back in London is the in this beautiful spring day we're going to talk about machine learning and I'm",
    "start": "11099",
    "end": "17670"
  },
  {
    "text": "joined by a large the CTO of libera a name you're certainly familiar with",
    "start": "17670",
    "end": "23090"
  },
  {
    "text": "who's going to talk about their use case in a few minutes but let's get started so who has never really done machine",
    "start": "23090",
    "end": "30779"
  },
  {
    "text": "learning before it's alright I can raise my hand I'm just faking it okay so this",
    "start": "30779",
    "end": "37440"
  },
  {
    "text": "is pretty much what machine learning is all about right it's not just about algorithms and parameters and all kinds",
    "start": "37440",
    "end": "44670"
  },
  {
    "text": "of weird techniques it's actually engineering it's a whole bunch of things so you start from a business problem",
    "start": "44670",
    "end": "51449"
  },
  {
    "text": "that you need to solve you try to frame it into machine learning problem figuring out how data can help you solve",
    "start": "51449",
    "end": "58829"
  },
  {
    "text": "that problem and then you need to collect that data you need to put it in",
    "start": "58829",
    "end": "64860"
  },
  {
    "text": "a central place you need to clean it prepare it you know real life data is",
    "start": "64860",
    "end": "70710"
  },
  {
    "text": "always messy and ugly so there's a lot of work there and then you move on to",
    "start": "70710",
    "end": "76070"
  },
  {
    "text": "actually trying different algorithms training models experimenting until you",
    "start": "76070",
    "end": "83640"
  },
  {
    "text": "find a model that you like that's good enough to solve your business problem and then you deploy that model in",
    "start": "83640",
    "end": "90060"
  },
  {
    "text": "production and and you have to live with that model in production 24/7 probably monitoring gait scaling it etc etc so",
    "start": "90060",
    "end": "97860"
  },
  {
    "text": "when we talk about machine learning we talk about the whole thing we don't just talk about algorithms and data science",
    "start": "97860",
    "end": "105979"
  },
  {
    "text": "so the first step means of course collecting data but in some cases it",
    "start": "107000",
    "end": "114149"
  },
  {
    "text": "does actually mean building data building datasets okay and in a lot of cases building a dataset",
    "start": "114149",
    "end": "121710"
  },
  {
    "text": "is actually a very time-consuming and expensive task imagine you had to label",
    "start": "121710",
    "end": "127849"
  },
  {
    "text": "images for autonomous driving models okay this is one of the more advanced",
    "start": "127849",
    "end": "134400"
  },
  {
    "text": "applicationnow there any kind of image application computer vision application",
    "start": "134400",
    "end": "140310"
  },
  {
    "text": "and even texts natural language processing application needs a data set",
    "start": "140310",
    "end": "146130"
  },
  {
    "text": "to be labeled so you would have to do this in the case of computer vision right so for every single frame you",
    "start": "146130",
    "end": "151650"
  },
  {
    "text": "would have to do this thing called semantic segmentation assigning every pixel in the image to specific instance",
    "start": "151650",
    "end": "157620"
  },
  {
    "text": "this is a car this is a tree this is the road etc etc so imagine you have the",
    "start": "157620",
    "end": "162960"
  },
  {
    "text": "right tools to do this you know how much how long does it take you to do one of those images right few minutes right",
    "start": "162960",
    "end": "171300"
  },
  {
    "text": "once you've warmed up okay imagine you did to do thousands of hours right maybe",
    "start": "171300",
    "end": "177390"
  },
  {
    "text": "more it's an impossible task okay the same for medical images imagine you",
    "start": "177390",
    "end": "183540"
  },
  {
    "text": "had to you know highlight cancer cells you know that kind of work it's expert",
    "start": "183540",
    "end": "189690"
  },
  {
    "text": "work it's extremely time-consuming and it's expensive as well so we built a",
    "start": "189690",
    "end": "194730"
  },
  {
    "text": "service called Amazon sage make your ground truth that lets you annotate data set quickly so we provide you with the",
    "start": "194730",
    "end": "201780"
  },
  {
    "text": "tools the actual graphical tools to do image annotation text annotation and you",
    "start": "201780",
    "end": "207720"
  },
  {
    "text": "can also build all kinds of workflows for other types of data you can create",
    "start": "207720",
    "end": "212970"
  },
  {
    "text": "workforces so if you have experts in the company that know how to annotate this stuff you canyou can distribute the work",
    "start": "212970",
    "end": "219720"
  },
  {
    "text": "to them or you could distribute it to third parties port an herbalist partners",
    "start": "219720",
    "end": "225120"
  },
  {
    "text": "who have that expertise or you could distribute it to Amazon Mechanical Turk where you could leverage up to 500,000",
    "start": "225120",
    "end": "232500"
  },
  {
    "text": "workers to work on your annotation workflows okay and not only that but we",
    "start": "232500",
    "end": "237870"
  },
  {
    "text": "can also we also add machine learning into the mix so as humans start annotating data samples in parallel we",
    "start": "237870",
    "end": "245880"
  },
  {
    "text": "automatically train a machine learning model and as soon as that model becomes",
    "start": "245880",
    "end": "250920"
  },
  {
    "text": "as accurate or more accurate that's human annotations then it starts labeling at scale and so this saves you",
    "start": "250920",
    "end": "258060"
  },
  {
    "text": "from a lot of human work saving time and money okay so sage maker ground truth",
    "start": "258060",
    "end": "263160"
  },
  {
    "text": "lots of cool features check it out if you have an attention issues then of course you need",
    "start": "263160",
    "end": "269759"
  },
  {
    "text": "to prepare the data okay transform it aggregated run ETL jobs and",
    "start": "269759",
    "end": "276689"
  },
  {
    "text": "whatnot and here you'll find you know a lot of let's call them big data tools",
    "start": "276689",
    "end": "281759"
  },
  {
    "text": "to-do lists on AWS EMR if you like Hadoop spark redshift if you need data",
    "start": "281759",
    "end": "290219"
  },
  {
    "text": "warehousing Athena if you're if you like sterilized analytics etc etc so that",
    "start": "290219",
    "end": "297479"
  },
  {
    "text": "part is more about Big Data the machine learning it's still very important you need to get your data clean and ready to",
    "start": "297479",
    "end": "303750"
  },
  {
    "text": "be trained and then of course you need to deploy so you could deploy using",
    "start": "303750",
    "end": "311550"
  },
  {
    "text": "literally any of the compute services on AWS if you're more of an ec2 person then",
    "start": "311550",
    "end": "316620"
  },
  {
    "text": "fine you can deploy models on ec2 do everything yourself if that suits you",
    "start": "316620",
    "end": "321690"
  },
  {
    "text": "that's okay you could use container services like SES or ETS or kubernetes",
    "start": "321690",
    "end": "327449"
  },
  {
    "text": "container service if you're more of a darker shop then fine you can absolutely",
    "start": "327449",
    "end": "332520"
  },
  {
    "text": "build your own containers and deploy them on ECS and eks and if you just leave batch machine learning batch",
    "start": "332520",
    "end": "338610"
  },
  {
    "text": "prediction then you could use AWS batch which is a batch service I guess that's a good name for it so all of these work",
    "start": "338610",
    "end": "345589"
  },
  {
    "text": "and they'll take you from training to deployment to scaling in in pretty nice",
    "start": "345589",
    "end": "352259"
  },
  {
    "text": "ways to make your life a little easier we have a collection of tools so if you'd like to work with ec2 virtual",
    "start": "352259",
    "end": "358860"
  },
  {
    "text": "machines we've built a collection of a Mis Amazon machine images the actual",
    "start": "358860",
    "end": "365400"
  },
  {
    "text": "binary files that are used to create virtual machines to help you get started",
    "start": "365400",
    "end": "370589"
  },
  {
    "text": "quickly with deep learning ok so they're so-called deep learning a.m. eyes are just off the shelf you can",
    "start": "370589",
    "end": "376560"
  },
  {
    "text": "fire them up in one API call and they come pre-installed with all those good libraries optimized by AWS so literally",
    "start": "376560",
    "end": "384389"
  },
  {
    "text": "you don't have anything to do here just start that get to work ok they are free to use you just pay for the underlying",
    "start": "384389",
    "end": "390779"
  },
  {
    "text": "instance and as of a couple of weeks ago we also launched deep running containers",
    "start": "390779",
    "end": "395940"
  },
  {
    "text": "which are exactly the same thing so for now we have a tensorflow container we MX net container more libraries coming",
    "start": "395940",
    "end": "402510"
  },
  {
    "text": "soon that you could use automatically off-the-shelf there hosting in AWS just",
    "start": "402510",
    "end": "408630"
  },
  {
    "text": "grab them run them on your darker clusters and save the trouble of building those containers but I guess if",
    "start": "408630",
    "end": "416010"
  },
  {
    "text": "you want to keep it simple if you're more of a fully managed person if you",
    "start": "416010",
    "end": "421110"
  },
  {
    "text": "want to focus on machine learning and not on infrastructure tasks then we've built this service called sage maker and",
    "start": "421110",
    "end": "427260"
  },
  {
    "text": "sage maker is really the simplest and easiest way to go from experimentation",
    "start": "427260",
    "end": "433650"
  },
  {
    "text": "to training to deployment to scaling with the same service and the same sdk",
    "start": "433650",
    "end": "439139"
  },
  {
    "text": "so it really does cover all those steps when you train on sage maker you have a",
    "start": "439139",
    "end": "445919"
  },
  {
    "text": "number of options ok if fully-managed doesn't mean boring or generic or or",
    "start": "445919",
    "end": "452490"
  },
  {
    "text": "inflexible it's actually very flexible so when you train you have three options you can use built-in algorithms we have",
    "start": "452490",
    "end": "459450"
  },
  {
    "text": "a collection of 17 machine learning and deep learning algorithms already implemented by AWS just ready to go so",
    "start": "459450",
    "end": "467669"
  },
  {
    "text": "just a few here and actually Lars will talk about a few in a minute these are ready to go like I said no",
    "start": "467669",
    "end": "475350"
  },
  {
    "text": "machine learning coding required just configure the algo no infrastructure work required because sage maker is",
    "start": "475350",
    "end": "481260"
  },
  {
    "text": "fully managed tools I'll show you a demo later in the session you see we'll never worry about infrastructure at all and",
    "start": "481260",
    "end": "488880"
  },
  {
    "text": "you get all kinds of cool features like distributed training out-of-the-box pipe",
    "start": "488880",
    "end": "494250"
  },
  {
    "text": "mode that lets you stream humongous data sets to instances so there's really no",
    "start": "494250",
    "end": "500010"
  },
  {
    "text": "limit to the data set size you can train on etc etc so this is really the easiest",
    "start": "500010",
    "end": "505350"
  },
  {
    "text": "and simplest way to get started if you're already doing machine learning with the libraries like tensorflow MX",
    "start": "505350",
    "end": "512039"
  },
  {
    "text": "net scikit-learn etc we have those built in frameworks okay so again pre-installed pre-configured optimized so just bring",
    "start": "512039",
    "end": "519240"
  },
  {
    "text": "your own code and and train ok and you can bring the exact same code that you",
    "start": "519240",
    "end": "525540"
  },
  {
    "text": "would be using on your laptop it's called script mode it's a cool feature I will demo it in the other",
    "start": "525540",
    "end": "531510"
  },
  {
    "text": "machine running this afternoon all these containers because of course this is based on",
    "start": "531510",
    "end": "536880"
  },
  {
    "text": "containers are open source so you can inspect them you can customize them you'll find everything on github you",
    "start": "536880",
    "end": "543450"
  },
  {
    "text": "still have no infrastructure work to do and you can still enjoy some of the cool features in Sage Maker and last but not",
    "start": "543450",
    "end": "551160"
  },
  {
    "text": "least if you need something else ok anybody using our oh come on there's got",
    "start": "551160",
    "end": "556890"
  },
  {
    "text": "to be a few more yeah you guys are hiding out there come on I'm not gonna make fun of you and sir it's alright it's alright air is very cool C++ or anything else",
    "start": "556890",
    "end": "565140"
  },
  {
    "text": "okay you know any custom code that you wrote or your company uses and you want to train and deploy models with that you",
    "start": "565140",
    "end": "572550"
  },
  {
    "text": "can just create your own container it's very simple to do and and run it on Sage",
    "start": "572550",
    "end": "578310"
  },
  {
    "text": "maker okay so it's a managed service yes it makes infrastructure transparent yes but it doesn't lock you into one",
    "start": "578310",
    "end": "585660"
  },
  {
    "text": "specific framework or one specific way of doing machine learning you can literally run anything that you like and",
    "start": "585660",
    "end": "591980"
  },
  {
    "text": "there's another cool feature launch that we invent a few months ago called the",
    "start": "591980",
    "end": "597510"
  },
  {
    "text": "machine learning marketplace where we have a collection of machine learning models built by AWS partners okay and",
    "start": "597510",
    "end": "604950"
  },
  {
    "text": "there are all kinds of things out there and you can just grab them and deploy them on Sage maker so this might very",
    "start": "604950",
    "end": "611250"
  },
  {
    "text": "well save you from doing machine learning in the first place so I I really encourage you to take a look at",
    "start": "611250",
    "end": "617610"
  },
  {
    "text": "those models okay just look for machine learning marketplace and you'll find that okay just like the ec2 marketplace",
    "start": "617610",
    "end": "623850"
  },
  {
    "text": "saves you from doing you know from packaging third-party software this",
    "start": "623850",
    "end": "630000"
  },
  {
    "text": "machine learning marketplace saves you from doing machine learning so you can go home early and enjoy your life and",
    "start": "630000",
    "end": "635750"
  },
  {
    "text": "talking about enjoying life let's bring a Loris on stage come on let's giving a",
    "start": "635750",
    "end": "641130"
  },
  {
    "text": "round of applause and it's going to talk about lebara [Applause]",
    "start": "641130",
    "end": "648680"
  },
  {
    "text": "good morning everyone nice to be here as Julian says I'm going to talk about",
    "start": "648680",
    "end": "654750"
  },
  {
    "text": "machine learning at lebara to be honest this is something we've only just started there so we're only in the",
    "start": "654750",
    "end": "659760"
  },
  {
    "text": "beginning of this journey but I think it fits nicely with what Julian was just explaining and we did something in a",
    "start": "659760",
    "end": "666810"
  },
  {
    "text": "couple of days that already gave us very nice results so what I'm going to be",
    "start": "666810",
    "end": "675600"
  },
  {
    "text": "talking about I'm going to tell you a bit about libera who we are and what we wanted to use machine learning for so",
    "start": "675600",
    "end": "682140"
  },
  {
    "text": "what we wanted to use it for is is a telco fraud I'll explain it later and yeah using e-learning for that and now",
    "start": "682140",
    "end": "689930"
  },
  {
    "text": "what our next plans are for this so",
    "start": "689930",
    "end": "695190"
  },
  {
    "text": "lebara we are a multi mobile virtual network operator so basically we are a",
    "start": "695190",
    "end": "700320"
  },
  {
    "text": "mobile operator we don't have our own networks we use the networks of other operators here in the UK we use the",
    "start": "700320",
    "end": "705990"
  },
  {
    "text": "Vodafone Network we are active in five countries across Europe and we mostly target immigrants or global citizens and",
    "start": "705990",
    "end": "715800"
  },
  {
    "text": "our mission is to make it easier for people to communicate with their friends",
    "start": "715800",
    "end": "721140"
  },
  {
    "text": "and family back home as I said we wanted",
    "start": "721140",
    "end": "727200"
  },
  {
    "text": "to look at applying machine learning to Toco fraud taco fraud basically is",
    "start": "727200",
    "end": "734210"
  },
  {
    "text": "fraudsters trying to abuse talk of products or services and trying to",
    "start": "734210",
    "end": "740160"
  },
  {
    "text": "basically cheat you know us as an operator or our customers out of money",
    "start": "740160",
    "end": "746270"
  },
  {
    "text": "there's very many different ways of fraudulent behavior I mean I've listed a",
    "start": "746839",
    "end": "753780"
  },
  {
    "text": "couple of them one very common is embarking it's it's a where companies",
    "start": "753780",
    "end": "762540"
  },
  {
    "text": "usually VoIP providers try to talk terminate calls in a country by putting",
    "start": "762540",
    "end": "768150"
  },
  {
    "text": "a lot of sims in a device and basically that way they bypass and the International connection fees",
    "start": "768150",
    "end": "774860"
  },
  {
    "text": "usually national calls are cheaper than than international calls a way of",
    "start": "774860",
    "end": "781699"
  },
  {
    "text": "finding out that because the sim is being used in a sim boxing scenario would be that you have one number",
    "start": "781699",
    "end": "788899"
  },
  {
    "text": "calling many different B numbers and normally any number unless you're a",
    "start": "788899",
    "end": "793910"
  },
  {
    "text": "small business or something like that you would only call maybe five six ten numbers but in a simple scenario you can",
    "start": "793910",
    "end": "801470"
  },
  {
    "text": "see a lot of course being made from from a single sim and our example is a",
    "start": "801470",
    "end": "806720"
  },
  {
    "text": "revenue share fraud and this is the scenario I'm going to be talking about in the rest of my presentation basically",
    "start": "806720",
    "end": "813019"
  },
  {
    "text": "what happens is in revenue share fraud is fraudsters get these revenue share",
    "start": "813019",
    "end": "820489"
  },
  {
    "text": "numbers so basically all 900 numbers numbers that you know allow them to cash",
    "start": "820489",
    "end": "825679"
  },
  {
    "text": "out then they use sims that either have been topped up with let's say maybe a stolen credit card or they you know find",
    "start": "825679",
    "end": "836899"
  },
  {
    "text": "a way that maybe there's a problem with our numbering plan and we've maybe mispriced a certain destination so a",
    "start": "836899",
    "end": "843379"
  },
  {
    "text": "scenario like that would be we would see a lot of calls from a lot of different sims to one a number or a set of any",
    "start": "843379",
    "end": "849470"
  },
  {
    "text": "numbers being a business or a special case of that is one Geary fraud and this",
    "start": "849470",
    "end": "855829"
  },
  {
    "text": "is something where actually floats it'll make the calls themselves but they set up calls to a lot of people and then",
    "start": "855829",
    "end": "864860"
  },
  {
    "text": "they hope that customer that our customers will go back to those numbers not realizing that actually they're",
    "start": "864860",
    "end": "870079"
  },
  {
    "text": "hitting a very expensive premium number",
    "start": "870079",
    "end": "875019"
  },
  {
    "text": "so how do we detect fraud today currently we have a rule-based system",
    "start": "875619",
    "end": "881709"
  },
  {
    "text": "and it works fairly well but of course",
    "start": "881709",
    "end": "887660"
  },
  {
    "text": "it's rule-based so if people if fraudsters find out what the rules are they might find ways to you know get",
    "start": "887660",
    "end": "894139"
  },
  {
    "text": "around those rules and also we don't know what we don't know so maybe there's a lot of fraudulent patterns that we're",
    "start": "894139",
    "end": "901759"
  },
  {
    "text": "not seeing today so you know we were thinking can we use machine learning improve our fraud detection capabilities",
    "start": "901759",
    "end": "910339"
  },
  {
    "text": "but yeah then the Puma is yeah we've only got we've only just started how do",
    "start": "911240",
    "end": "916830"
  },
  {
    "text": "we how do we you get up and running quickly with our limited knowledge so",
    "start": "916830",
    "end": "923070"
  },
  {
    "text": "what we did is we organized a three-day workshop together with AWS where they were kind enough to fly in",
    "start": "923070",
    "end": "929820"
  },
  {
    "text": "some of their machine learning experts and we worked with our own data",
    "start": "929820",
    "end": "935040"
  },
  {
    "text": "absolu live customer data our call detail records which I'll show you a bit but more bit more about later and we",
    "start": "935040",
    "end": "943610"
  },
  {
    "text": "created using the school data records a data set that was annotated using our",
    "start": "943610",
    "end": "949890"
  },
  {
    "text": "existing rule-based system combined a bit with sort of the knowledge that our",
    "start": "949890",
    "end": "956210"
  },
  {
    "text": "fraud team has you know basically we said okay we know who the forces are let's tag all the data we have with okay",
    "start": "956210",
    "end": "963240"
  },
  {
    "text": "this is a call made by a fraudulent same or to a fortunate number we focused yeah",
    "start": "963240",
    "end": "970410"
  },
  {
    "text": "we split up with three groups each group tried to you know detect a different",
    "start": "970410",
    "end": "976140"
  },
  {
    "text": "kind of fraud using machine learning as I said I'm going to be talking about the revenue share fraud use case and what we",
    "start": "976140",
    "end": "984000"
  },
  {
    "text": "did is we we used Amazon Amazon Sage maker to yeah get get up and running so",
    "start": "984000",
    "end": "993540"
  },
  {
    "text": "call Beatle records so we have in our back-end we have something called an online charging system and whenever",
    "start": "993540",
    "end": "999900"
  },
  {
    "text": "someone makes a call or uses a byte of data or or B there's a whole data",
    "start": "999900",
    "end": "1006830"
  },
  {
    "text": "session or sends an SMS or anything that can be charged there's a CDR a cool data",
    "start": "1006830",
    "end": "1014000"
  },
  {
    "text": "record being generated in real time by that system at lebara we take those CDOs",
    "start": "1014000",
    "end": "1019610"
  },
  {
    "text": "and then we stream them using Kinesis and store them in s3 using fire hose",
    "start": "1019610",
    "end": "1026678"
  },
  {
    "text": "which is nice so we have already have the data accessible in a location that's",
    "start": "1026679",
    "end": "1031880"
  },
  {
    "text": "easy for other area services to consume so what does the senior look",
    "start": "1031880",
    "end": "1038610"
  },
  {
    "text": "like so this is an example of one CDR it's actually a cool I made to my wife as you can see this it's basically a CSV",
    "start": "1038610",
    "end": "1046829"
  },
  {
    "text": "file csv record comma separated values of the pipe pipe delimited and it's got",
    "start": "1046829",
    "end": "1053370"
  },
  {
    "text": "a lot of information in here but actually the only relevant pieces are you know it is an a number a b number",
    "start": "1053370",
    "end": "1061470"
  },
  {
    "text": "there's a duration and there's a timestamp and then there's a whole lot of other information basically saying okay which account was charged is it how",
    "start": "1061470",
    "end": "1070890"
  },
  {
    "text": "much money was paid etc so we had these videos so next step as julian was saying",
    "start": "1070890",
    "end": "1077790"
  },
  {
    "text": "before as well as and we need to we need to prepare the data so we spent we spent quite a lot of we spent three days in a",
    "start": "1077790",
    "end": "1083880"
  },
  {
    "text": "workshop with that's eight people we spent a considerable amount of time preparing the data so we had to clean up",
    "start": "1083880",
    "end": "1091920"
  },
  {
    "text": "the data there were some records in there which were not they were not really close to correct numbers they",
    "start": "1091920",
    "end": "1098730"
  },
  {
    "text": "were not numeric or some weird characters in there so we had to clean",
    "start": "1098730",
    "end": "1105000"
  },
  {
    "text": "those out we found out it was there was really strange",
    "start": "1105000",
    "end": "1110400"
  },
  {
    "text": "data in there in terms of you know very long numbers for instance and also what we noticed is if you look at I've added",
    "start": "1110400",
    "end": "1117300"
  },
  {
    "text": "a diagram at the bottom on the left you see the data before it was cleaned up on the right you see after clean up",
    "start": "1117300",
    "end": "1123510"
  },
  {
    "text": "basically this shows a histogram of the number of calls for the for the time period that we looked at the number of",
    "start": "1123510",
    "end": "1132630"
  },
  {
    "text": "course made to a number of a certain length and as you can see there's a lot of calls of like five or six five or six",
    "start": "1132630",
    "end": "1141810"
  },
  {
    "text": "number B numbers and you know when we looked at them we immediately found out okay these are calls to our customer",
    "start": "1141810",
    "end": "1148110"
  },
  {
    "text": "services agents to our top up IVR etc etc so we decided I mean did this might",
    "start": "1148110",
    "end": "1153870"
  },
  {
    "text": "you know we know this is not fraud and it might confuse our algorithms so we decided okay let's let's remove those so",
    "start": "1153870",
    "end": "1161250"
  },
  {
    "text": "on the right you can see the the histogram of the cleaned-up data set and we did a couple of things like this",
    "start": "1161250",
    "end": "1167810"
  },
  {
    "text": "basically to get everything perfectly ready for our machine learning algorithm",
    "start": "1167810",
    "end": "1174700"
  },
  {
    "text": "so then we needed to extract some features from the data here so we know we were looking at we wanted to look at",
    "start": "1174820",
    "end": "1183800"
  },
  {
    "text": "revenue share fraud so what you usually see is you know fraudsters that would try to do this at maybe in weekends or",
    "start": "1183800",
    "end": "1189560"
  },
  {
    "text": "on on Friday evening or when you know when there's a public holiday so the",
    "start": "1189560",
    "end": "1195770"
  },
  {
    "text": "time of the day the day of the week is very very relevant for this kind of fraud scenario because basically forces",
    "start": "1195770",
    "end": "1201830"
  },
  {
    "text": "hope that you know if it's a weekend no one is working and then they can get away with it undetected it's also",
    "start": "1201830",
    "end": "1209540"
  },
  {
    "text": "relevant as I said the number of eight numbers calling a certain B number I mean if it and if if you have just one",
    "start": "1209540",
    "end": "1218540"
  },
  {
    "text": "number calling one B numbers it's probably no fraud that if you have a lot of different sims calling a specific set",
    "start": "1218540",
    "end": "1224960"
  },
  {
    "text": "of of B numbers it might be indicative of fraud unless maybe it's a I know it's",
    "start": "1224960",
    "end": "1230270"
  },
  {
    "text": "it's a bank or a insurance company or",
    "start": "1230270",
    "end": "1235310"
  },
  {
    "text": "something like that then ratio of A to B numbers so you know just basically",
    "start": "1235310",
    "end": "1240950"
  },
  {
    "text": "factor of number of calls to some B number develop a number of any numbers calling it and the average call duration",
    "start": "1240950",
    "end": "1247400"
  },
  {
    "text": "as I said you know fraudsters move on to lost have these calls lasts as long as",
    "start": "1247400",
    "end": "1253220"
  },
  {
    "text": "possible and so they can they can make a lot of money whereas a normal call maybe",
    "start": "1253220",
    "end": "1259010"
  },
  {
    "text": "only lost two or three minutes using the",
    "start": "1259010",
    "end": "1265250"
  },
  {
    "text": "data set that we created we decided to use two different models machine",
    "start": "1265250",
    "end": "1271010"
  },
  {
    "text": "learning models to to test with one is an unsupervised learning model so basically we wanted to see can we detect",
    "start": "1271010",
    "end": "1277130"
  },
  {
    "text": "any anomalies in the data that we have we use random cut forests for that and",
    "start": "1277130",
    "end": "1282230"
  },
  {
    "text": "it was actually quite interesting because I didn't expect this so this uses the sort of untagged data but we",
    "start": "1282230",
    "end": "1290630"
  },
  {
    "text": "actually did find scenarios that look very fishy and when our fraud team looked at it it turned out well actually we had detected",
    "start": "1290630",
    "end": "1296809"
  },
  {
    "text": "fraud within like what it was like second day of our workshop so there was a quite a big success for us and then we",
    "start": "1296809",
    "end": "1305659"
  },
  {
    "text": "started looking at you know supervised learning so with with a label data set I",
    "start": "1305659",
    "end": "1312080"
  },
  {
    "text": "have to say it's quite a bit of a tricky situation because yeah looking at the date said only one in every three or",
    "start": "1312080",
    "end": "1318559"
  },
  {
    "text": "four thousand calls actually is a can be considered a fortunate call the",
    "start": "1318559",
    "end": "1325279"
  },
  {
    "text": "algorithm we use is actually boost and despite yeah data being so yeah",
    "start": "1325279",
    "end": "1332619"
  },
  {
    "text": "unbalanced we did manage to find some some pretty interesting results on the right you can see the first you know",
    "start": "1332619",
    "end": "1339200"
  },
  {
    "text": "after training our model the first the very first results that we got and as",
    "start": "1339200",
    "end": "1344509"
  },
  {
    "text": "you can see of the fraudulent cases that were in the dataset it managed to pick up about a third of them easily so you",
    "start": "1344509",
    "end": "1352489"
  },
  {
    "text": "know next step for us is to do some some tuning of our models to make sure that we detect more of our fraudulent cases",
    "start": "1352489",
    "end": "1361480"
  },
  {
    "text": "and for us it's not such a big deal if actually we we do catch some fraud which is which is not fraud because if yeah we",
    "start": "1361480",
    "end": "1369470"
  },
  {
    "text": "can we have our own for team they will look at all the cases anyway so it's",
    "start": "1369470",
    "end": "1375200"
  },
  {
    "text": "it's better for us to catch a bit more",
    "start": "1375200",
    "end": "1379028"
  },
  {
    "text": "so summarizing I think using using sage maker we were able to get started with",
    "start": "1380440",
    "end": "1387220"
  },
  {
    "text": "machine learning very quickly without any prior knowledge we've got some very promising results that we we hope to you",
    "start": "1387220",
    "end": "1393850"
  },
  {
    "text": "know continue on building after you building on and yeah we really want to",
    "start": "1393850",
    "end": "1399160"
  },
  {
    "text": "take into production and we're also looking at applying machine learning in",
    "start": "1399160",
    "end": "1405820"
  },
  {
    "text": "some other areas who is that I hand back to Julie",
    "start": "1405820",
    "end": "1410820"
  },
  {
    "text": "okay this is pretty cool stuff right pretty cool stuff I'm I'm really you",
    "start": "1415580",
    "end": "1422970"
  },
  {
    "text": "know we're we keep saying we want to make machine learning simpler for everyone and this is a great example okay just a few days of work and you",
    "start": "1422970",
    "end": "1430650"
  },
  {
    "text": "guys are even finding a fraud scheme that you didn't know about so there you go and obviously the fraud examples that",
    "start": "1430650",
    "end": "1437580"
  },
  {
    "text": "Lars gave are for educational purposes right okay so don't go and start ripping",
    "start": "1437580",
    "end": "1444030"
  },
  {
    "text": "off people please okay so let's move on so in this second section I'd like to",
    "start": "1444030",
    "end": "1451320"
  },
  {
    "text": "actually show you how to use sage maker so as always with the ws everything's",
    "start": "1451320",
    "end": "1458640"
  },
  {
    "text": "going to be based on api's and we actually built a specific sdk for sage",
    "start": "1458640",
    "end": "1464490"
  },
  {
    "text": "maker and we call it the sage maker sdk it's a Python SDK and it's very high",
    "start": "1464490",
    "end": "1471000"
  },
  {
    "text": "level as you will see it's if you're familiar will be typically SS SDKs there",
    "start": "1471000",
    "end": "1476550"
  },
  {
    "text": "tend to be lower level infrastructure level but this one is really about",
    "start": "1476550",
    "end": "1481620"
  },
  {
    "text": "machine learning so the objects that will work with our you know algorithms",
    "start": "1481620",
    "end": "1488130"
  },
  {
    "text": "and models and deployments etc etc so it's good because it means you end up",
    "start": "1488130",
    "end": "1494730"
  },
  {
    "text": "writing very little code and you really need zero infrastructure knowledge and",
    "start": "1494730",
    "end": "1500100"
  },
  {
    "text": "you need very limited ml knowledge as well because a lot of that stuff is",
    "start": "1500100",
    "end": "1505620"
  },
  {
    "text": "already done for you if you use spark and there's also spark SDK for sage",
    "start": "1505620",
    "end": "1512160"
  },
  {
    "text": "maker in Python and Scala that lets you call sage maker api's from your spark",
    "start": "1512160",
    "end": "1518160"
  },
  {
    "text": "apps okay I'm not going to cover that today ask me questions at the end if you want to but the short version is the",
    "start": "1518160",
    "end": "1525090"
  },
  {
    "text": "combination of spark for ETL and sage maker for machine learning and deep learning is very cool okay that's my",
    "start": "1525090",
    "end": "1531900"
  },
  {
    "text": "elevator pitch for it obviously you can also use now that's weird okay we're",
    "start": "1531900",
    "end": "1537750"
  },
  {
    "text": "missing your words power point weirdness here it doesn't want to display this should say SS SDK okay so obviously we",
    "start": "1537750",
    "end": "1545340"
  },
  {
    "text": "have a service level SDK just like we have an SDK for a spark and easy to not spark sorry",
    "start": "1545340",
    "end": "1552150"
  },
  {
    "text": "s3 ec2 RDS etc but this one like I said is more you know it's more low level",
    "start": "1552150",
    "end": "1557430"
  },
  {
    "text": "it's really about managing lower level service api so in the demo i'm gonna be",
    "start": "1557430",
    "end": "1562890"
  },
  {
    "text": "using the high level sdk okay so a large mentioned using extra boost so I figured",
    "start": "1562890",
    "end": "1569640"
  },
  {
    "text": "that I figured let's let's continue on that theme okay so I'm gonna show you how to train and deploy and",
    "start": "1569640",
    "end": "1575390"
  },
  {
    "text": "automatically tune a model based on XJ boost okay so let's do this",
    "start": "1575390",
    "end": "1582289"
  },
  {
    "text": "okay can you read okay in the back yeah okay yell at me if it's too small so I'm",
    "start": "1590010",
    "end": "1599020"
  },
  {
    "text": "not gonna do fraud detection here I'm going to do going to do marketing so the idea here is that we have a data set a",
    "start": "1599020",
    "end": "1605650"
  },
  {
    "text": "historical data set about 40 thousand samples telling us yes or no did a",
    "start": "1605650",
    "end": "1613390"
  },
  {
    "text": "specific customer accept a marketing offer okay and the goal here is to build",
    "start": "1613390",
    "end": "1619260"
  },
  {
    "text": "a machine learning model that can successfully classify customers into two",
    "start": "1619260",
    "end": "1625570"
  },
  {
    "text": "categories yes they will accept the offer no they won't okay so binary classification and just",
    "start": "1625570",
    "end": "1633700"
  },
  {
    "text": "like fraud detection is binary classification is this fraudulent use it's not an XJ which is a good way to do",
    "start": "1633700",
    "end": "1639760"
  },
  {
    "text": "this okay so it's one of the built-in algos okay so I'll try to go yeah we",
    "start": "1639760",
    "end": "1644860"
  },
  {
    "text": "have time so I'll try to go reasonably slow this time so first obviously I need",
    "start": "1644860",
    "end": "1651340"
  },
  {
    "text": "a development environment okay so if you do machine learning already or even if",
    "start": "1651340",
    "end": "1656710"
  },
  {
    "text": "you don't you know those notebooks Jupiter notebooks are a super popular way to do this so Jupiter is a web app",
    "start": "1656710",
    "end": "1663430"
  },
  {
    "text": "that lets you easily write and run and and experiment with the Python code okay",
    "start": "1663430",
    "end": "1670030"
  },
  {
    "text": "and this is actually part of sage maker as well we have a feature in sage maker",
    "start": "1670030",
    "end": "1675550"
  },
  {
    "text": "called notebook instances which are fully managed instances pre-installed with Jupiter and all the libraries that",
    "start": "1675550",
    "end": "1683050"
  },
  {
    "text": "I mentioned before and you can just create them in minutes and open the notebook and get to work okay so if you",
    "start": "1683050",
    "end": "1689230"
  },
  {
    "text": "need Devon Devon test environments you can use those notebook instances if you like okay so obviously I need to import",
    "start": "1689230",
    "end": "1696460"
  },
  {
    "text": "the sage maker SDK I need to grab an s3 bucket because sage maker needs training",
    "start": "1696460",
    "end": "1704920"
  },
  {
    "text": "data to be hosted in s3 and it will save the train model in s3 as well okay so we",
    "start": "1704920",
    "end": "1711010"
  },
  {
    "text": "need the bucket so we can just grab a default bucket that's okay next I will download the data set okay so here I'm",
    "start": "1711010",
    "end": "1718600"
  },
  {
    "text": "downloading it from the internet to my notebook instance okay and obviously we'd like to take a",
    "start": "1718600",
    "end": "1724030"
  },
  {
    "text": "look at this it's a CSV file so looking at CSV files",
    "start": "1724030",
    "end": "1729220"
  },
  {
    "text": "is pretty unpleasant unless you use this very nice",
    "start": "1729220",
    "end": "1734710"
  },
  {
    "text": "Python library called pandas okay so we can just import that file with pandas",
    "start": "1734710",
    "end": "1740950"
  },
  {
    "text": "and display okay and now it looks reasonably nice so we see the first ten",
    "start": "1740950",
    "end": "1746170"
  },
  {
    "text": "samples we have about I think we have 20 yeah we can see 21 we have 21 columns a",
    "start": "1746170",
    "end": "1752130"
  },
  {
    "text": "little less than 42,000 samples as you can see and so we have 20 features that",
    "start": "1752130",
    "end": "1759280"
  },
  {
    "text": "you can see here and we have the target value that says yes or no did that",
    "start": "1759280",
    "end": "1767110"
  },
  {
    "text": "person accept the offer okay so it's labeled it's supervised learning and we're trying to train a model that",
    "start": "1767110",
    "end": "1773320"
  },
  {
    "text": "learns the patterns from this data okay so interestingly this is very unbalanced",
    "start": "1773320",
    "end": "1781240"
  },
  {
    "text": "as well okay we can count the number of yes and the number of no and we see there's a ratio",
    "start": "1781240",
    "end": "1787390"
  },
  {
    "text": "about 1 - wait wait which makes sense right so about 8 times 8 people will say",
    "start": "1787390",
    "end": "1795400"
  },
  {
    "text": "no for one people who say yes who says yes ok so it's a problem in itself we might have to work on it next I'm gonna",
    "start": "1795400",
    "end": "1802750"
  },
  {
    "text": "do feature engineering ok so I'm gonna skip that part because this is not a data science tutorial and obviously you",
    "start": "1802750",
    "end": "1810700"
  },
  {
    "text": "will get the notebook and everything else but in a nutshell what I'm doing here is I'm encoding all the categorical",
    "start": "1810700",
    "end": "1819340"
  },
  {
    "text": "variables like the jobs and and a few more the marital status and so on",
    "start": "1819340",
    "end": "1825340"
  },
  {
    "text": "I'm encoding those because you know we don't wanna we don't want to use with text rings and and we need to have",
    "start": "1825340",
    "end": "1832840"
  },
  {
    "text": "proper categories okay so for those of you do machine learning either I'm using one art encoding and I'm getting rid of",
    "start": "1832840",
    "end": "1840100"
  },
  {
    "text": "a few columns that don't make much sense ok so once once I've done that you know",
    "start": "1840100",
    "end": "1847450"
  },
  {
    "text": "I have a few more columns because you know I've exploded those categorical columns into individual columns so if I",
    "start": "1847450",
    "end": "1854650"
  },
  {
    "text": "have 10 different jobs then I will have one column for each job that's pretty much what I'm doing here okay so dropping a few features and then",
    "start": "1854650",
    "end": "1863700"
  },
  {
    "text": "I'm ready to I'm ready to Train okay again don't worry you'll get that notebook you can look at all the details",
    "start": "1863700",
    "end": "1869480"
  },
  {
    "text": "let's not get bogged down into into data set preparation then I need to split the",
    "start": "1869480",
    "end": "1875850"
  },
  {
    "text": "data set okay and I'm splitting it in training so to build a model validation",
    "start": "1875850",
    "end": "1881630"
  },
  {
    "text": "to evaluate the model while it's being trained and test to actually benchmark",
    "start": "1881630",
    "end": "1888570"
  },
  {
    "text": "my model once it has been trained completely okay so I split it I save",
    "start": "1888570",
    "end": "1893940"
  },
  {
    "text": "that into three different files and all of that stuff is done locally on the notebook instance because this is such a",
    "start": "1893940",
    "end": "1899820"
  },
  {
    "text": "tiny data set if I was working with a terabyte of data of course I would not",
    "start": "1899820",
    "end": "1904980"
  },
  {
    "text": "do this on the notebook instance like I said earlier I would probably use EMR or",
    "start": "1904980",
    "end": "1910140"
  },
  {
    "text": "athina or any you know scalable back-end to do that transformation and",
    "start": "1910140",
    "end": "1915960"
  },
  {
    "text": "pre-processing okay but here you know just 40 K lines I guess are are okay",
    "start": "1915960",
    "end": "1922400"
  },
  {
    "text": "then I need to upload this stuff to a3 here okay because again like I said data",
    "start": "1922400",
    "end": "1929130"
  },
  {
    "text": "needs to be stored in s3 for sage maker to pick it up okay so I'm uploading the",
    "start": "1929130",
    "end": "1935250"
  },
  {
    "text": "training set in a specific location the validation set and the test set okay then I'm defining those locations",
    "start": "1935250",
    "end": "1944540"
  },
  {
    "text": "here okay so this is CSV format this is the location of the training set this is",
    "start": "1944540",
    "end": "1950130"
  },
  {
    "text": "the location of the validation set and this is actually the the information I'm going to pass to the training job okay",
    "start": "1950130",
    "end": "1957440"
  },
  {
    "text": "all right so so far we downloaded the data we've we've done some cleaning some",
    "start": "1957440",
    "end": "1962880"
  },
  {
    "text": "feature engineering splits it put it in s3 right now we're ready to do machine",
    "start": "1962880",
    "end": "1968310"
  },
  {
    "text": "learning so extra boost is one of those built-in algos okay so I don't have to",
    "start": "1968310",
    "end": "1974430"
  },
  {
    "text": "write a single line of machine learning code the only thing I have to do is ask sage maker to select the XJ boosts I'll",
    "start": "1974430",
    "end": "1982260"
  },
  {
    "text": "go so that really means the extra boost container in the region I'm running in",
    "start": "1982260",
    "end": "1987580"
  },
  {
    "text": "okay and this is what you see here okay just give me the give me the container",
    "start": "1987580",
    "end": "1993399"
  },
  {
    "text": "name for the region I'm running in so this is probably the Dublin region here and I want the extra boost I'll go",
    "start": "1993399",
    "end": "2000330"
  },
  {
    "text": "please okay that's it okay so now I know what container to use and then I can",
    "start": "2000330",
    "end": "2008070"
  },
  {
    "text": "configure my training job just like this okay remember we said say maker is fully managed it's it makes infrastructure",
    "start": "2008070",
    "end": "2016049"
  },
  {
    "text": "disappear okay that's what I'm talking about so we use this SDK object called",
    "start": "2016049",
    "end": "2021239"
  },
  {
    "text": "the estimator which is the generic object for training jobs on stage maker",
    "start": "2021239",
    "end": "2027350"
  },
  {
    "text": "passing the the container okay so which I'll go am I actually using here and",
    "start": "2027350",
    "end": "2034970"
  },
  {
    "text": "importantly how much infrastructure the one on training so here I want to train",
    "start": "2034970",
    "end": "2040379"
  },
  {
    "text": "on one m4 two XL instance okay which is more than enough for 40,000 lines I",
    "start": "2040379",
    "end": "2046289"
  },
  {
    "text": "could use something smaller even okay and then where to save the model in s3",
    "start": "2046289",
    "end": "2052020"
  },
  {
    "text": "and the rest are just technical parameters we can ignore for now okay if",
    "start": "2052020",
    "end": "2057388"
  },
  {
    "text": "if I add a huge data set and I needed to train on how do the instances why not I",
    "start": "2057389",
    "end": "2063240"
  },
  {
    "text": "would just say that right that's it that's all it takes okay and this applies to built-in",
    "start": "2063240",
    "end": "2068700"
  },
  {
    "text": "algorithms built-in frameworks tensorflow etc etc okay out of the box",
    "start": "2068700",
    "end": "2073858"
  },
  {
    "text": "you can just train on an arbitrary number of instances because sage maker is fully managing all of them and taking",
    "start": "2073859",
    "end": "2079799"
  },
  {
    "text": "care of distributing the training job okay so infrastructure disappears okay",
    "start": "2079799",
    "end": "2087059"
  },
  {
    "text": "then I need to set hyper parameters so of course each of those built-in algos",
    "start": "2087059",
    "end": "2095520"
  },
  {
    "text": "will have specific parameters they're explained in the sage make your documentation actually boost is actually",
    "start": "2095520",
    "end": "2102240"
  },
  {
    "text": "an open source I'll go so you can also refer to the to the open source documentation on there the first",
    "start": "2102240",
    "end": "2108299"
  },
  {
    "text": "parameter says I want to do binary classification okay the next two",
    "start": "2108299",
    "end": "2113730"
  },
  {
    "text": "parameters say hey you're gonna train 400 rounds but if",
    "start": "2113730",
    "end": "2119070"
  },
  {
    "text": "she has not improved in 10 rounds just stop okay so this is called early stopping this helps you know save time",
    "start": "2119070",
    "end": "2126810"
  },
  {
    "text": "and money by not letting long lasting jobs go go for too long when accuracy",
    "start": "2126810",
    "end": "2135030"
  },
  {
    "text": "doesn't doesn't improve and that other parameter is actually scaled pause weight is actually a way to rebalance",
    "start": "2135030",
    "end": "2141990"
  },
  {
    "text": "things okay so you can say well I've got eight more times negative samples than",
    "start": "2141990",
    "end": "2147510"
  },
  {
    "text": "positive samples so please try and pay more attention to the negative cases by",
    "start": "2147510",
    "end": "2154350"
  },
  {
    "text": "applying this multiplication factor okay so this I guess this is really when you",
    "start": "2154350",
    "end": "2161430"
  },
  {
    "text": "work with the built in algos this is really only part where you even if you have no machine learning experience you",
    "start": "2161430",
    "end": "2166890"
  },
  {
    "text": "need to read a little bit of documentation and and figure out what those parameters are but initially and I",
    "start": "2166890",
    "end": "2173640"
  },
  {
    "text": "don't know if that's what you guys did you can stick with the the reasonable defaults right stick with the mandatory",
    "start": "2173640",
    "end": "2179190"
  },
  {
    "text": "parameters and then keep tweaking okay",
    "start": "2179190",
    "end": "2184590"
  },
  {
    "text": "so at this point I could train and deploy you right but there are a whole",
    "start": "2184590",
    "end": "2190440"
  },
  {
    "text": "bunch of other parameters that could probably gave me give me extra accuracy okay like Lars mentioned initially you",
    "start": "2190440",
    "end": "2197280"
  },
  {
    "text": "can train those models very easily but after a while we want to get the best performance okay so I could just go xgb",
    "start": "2197280",
    "end": "2204720"
  },
  {
    "text": "fit to train and xgb deploy to deploy the model and start predicting but I'm",
    "start": "2204720",
    "end": "2210540"
  },
  {
    "text": "gonna do one extra step in between okay we're going to use model tuning okay",
    "start": "2210540",
    "end": "2216500"
  },
  {
    "text": "also called hyper parameter optimization or hpo okay so the idea here is extra",
    "start": "2216500",
    "end": "2226470"
  },
  {
    "text": "boost maybe has you know 20-25 parameters and maybe you know five are",
    "start": "2226470",
    "end": "2232080"
  },
  {
    "text": "really really important in getting the best accuracy so you could spend a day a month a life exploring those parameters",
    "start": "2232080",
    "end": "2241050"
  },
  {
    "text": "trying to get to the best value okay the value that gives you the best accuracy or if like me you like to go",
    "start": "2241050",
    "end": "2247290"
  },
  {
    "text": "home early whenever possible you can use automatic model tuning and ask saij maker to automatically find the",
    "start": "2247290",
    "end": "2254620"
  },
  {
    "text": "optimal parameters okay so let me explain how this works so here let's say we want to optimize on those",
    "start": "2254620",
    "end": "2262120"
  },
  {
    "text": "four parameters here okay and it really doesn't matter what they are okay let's",
    "start": "2262120",
    "end": "2268060"
  },
  {
    "text": "just say we know they're important in getting good accuracy from this algo and",
    "start": "2268060",
    "end": "2273580"
  },
  {
    "text": "we know by design for example eta is between 0 & 1 okay by design it's a",
    "start": "2273580",
    "end": "2279250"
  },
  {
    "text": "floating point value min child weight okay is a reasonable default is between",
    "start": "2279250",
    "end": "2285220"
  },
  {
    "text": "1 and 10 etc so it's difficult to find the top values but you could add you could find the range that you want to",
    "start": "2285220",
    "end": "2292180"
  },
  {
    "text": "explore okay that's that's reasonable okay alpha is between 0 & 2 and max depth is",
    "start": "2292180",
    "end": "2299320"
  },
  {
    "text": "at the actual depth of the prediction tree built by XJ boost and you can say okay 2 to 8 sounds reasonable",
    "start": "2299320",
    "end": "2305170"
  },
  {
    "text": "okay so let's try to explore that that's four dimensional space okay and find in",
    "start": "2305170",
    "end": "2312310"
  },
  {
    "text": "that space the best performing model okay so what does it mean the best",
    "start": "2312310",
    "end": "2317470"
  },
  {
    "text": "performing model it means the model with the highest metric okay and this metric",
    "start": "2317470",
    "end": "2324130"
  },
  {
    "text": "in this case is called the area under curve so AUC sorry for the machine running jump mumbo-jumbo here but for",
    "start": "2324130",
    "end": "2331450"
  },
  {
    "text": "classifiers it's a good metric to know if your model is predicting well or not",
    "start": "2331450",
    "end": "2337390"
  },
  {
    "text": "okay so we want to maximize that okay so in a nutshell we want to find the optimal set of those four parameters",
    "start": "2337390",
    "end": "2343620"
  },
  {
    "text": "within those ranges that give me the maximum AUC okay and again you could",
    "start": "2343620",
    "end": "2349660"
  },
  {
    "text": "spend your life doing this but we're not going to spend our life doing this we're just creating this hyper parameter tuner",
    "start": "2349660",
    "end": "2356050"
  },
  {
    "text": "object passing the estimator the metric the DI / parameter ranges that we want",
    "start": "2356050",
    "end": "2362770"
  },
  {
    "text": "to explore and how many jobs we want to run okay so we're gonna run ten jobs one",
    "start": "2362770",
    "end": "2367870"
  },
  {
    "text": "after the other and how does that work well we run one job okay so we get",
    "start": "2367870",
    "end": "2374640"
  },
  {
    "text": "initially we pick random values for the parameters and we run one job and so we",
    "start": "2374640",
    "end": "2380140"
  },
  {
    "text": "get one accuracy and then using that single data point we apply machine",
    "start": "2380140",
    "end": "2385960"
  },
  {
    "text": "optimization to predict to literally predict what the next set of parameters",
    "start": "2385960",
    "end": "2392250"
  },
  {
    "text": "should be should be which one should be tried out and so it's not a random",
    "start": "2392250",
    "end": "2397569"
  },
  {
    "text": "search like some people do it's really at after each data points we apply algos",
    "start": "2397569",
    "end": "2403809"
  },
  {
    "text": "called Bayesian optimization and Gaussian process regression okay you",
    "start": "2403809",
    "end": "2408910"
  },
  {
    "text": "didn't want to know that I know but now you know so machine learning up machine learning I'll go at will actually",
    "start": "2408910",
    "end": "2414609"
  },
  {
    "text": "predict where to look next in search of that maximum AUC okay so we do this ten",
    "start": "2414609",
    "end": "2422950"
  },
  {
    "text": "times and then we call fit okay and when",
    "start": "2422950",
    "end": "2428710"
  },
  {
    "text": "we call fit the the job actually the tuning job actually starts okay",
    "start": "2428710",
    "end": "2436990"
  },
  {
    "text": "and we can see we can see those ten jobs here so each job is very short as you can see",
    "start": "2436990",
    "end": "2443859"
  },
  {
    "text": "takes about one minute so the whole process took about ten or ten minutes or",
    "start": "2443859",
    "end": "2448960"
  },
  {
    "text": "something okay and we see the individual jobs and we see the AUC value the",
    "start": "2448960",
    "end": "2455349"
  },
  {
    "text": "accuracy value not the accuracy sorry the AUC metric that was that was reached",
    "start": "2455349",
    "end": "2460930"
  },
  {
    "text": "and so we can see this one sucks right point five okay so I perfect classifier",
    "start": "2460930",
    "end": "2466720"
  },
  {
    "text": "would be one okay hundred percent so we see some variability here as as sage",
    "start": "2466720",
    "end": "2475750"
  },
  {
    "text": "maker explores and moves in that four dimensional space in search of that optimal AUC okay and so we can see the",
    "start": "2475750",
    "end": "2484809"
  },
  {
    "text": "best one okay so you see the first one is not great and then it kind of",
    "start": "2484809",
    "end": "2492130"
  },
  {
    "text": "improves okay and then we explore a little more just in case but probably",
    "start": "2492130",
    "end": "2497829"
  },
  {
    "text": "the best one is still the third one okay so we could see the best training job and you can see the parameters that",
    "start": "2497829",
    "end": "2504819"
  },
  {
    "text": "actually gave us that high performing job okay so ten is probably a little too low I should probably run a few more",
    "start": "2504819",
    "end": "2511780"
  },
  {
    "text": "jobs to explore it or more but you know I wanted this notebook to be very short",
    "start": "2511780",
    "end": "2516910"
  },
  {
    "text": "to run so you could just run maybe 20 30 jobs see if you keep converging to high",
    "start": "2516910",
    "end": "2523060"
  },
  {
    "text": "performing jobs okay so of course we're happy with that and we can just grab the",
    "start": "2523060",
    "end": "2530440"
  },
  {
    "text": "best model okay so we can find the name for the best model and we can deploy it",
    "start": "2530440",
    "end": "2537400"
  },
  {
    "text": "and it's as easy as calling dot deploy okay and saying how much infrastructure",
    "start": "2537400",
    "end": "2543160"
  },
  {
    "text": "you want okay so in this case I want to deploy on one m4 XL instance okay so",
    "start": "2543160",
    "end": "2548620"
  },
  {
    "text": "this sage maker will create that instance create an HTTP endpoint that I",
    "start": "2548620",
    "end": "2554710"
  },
  {
    "text": "can invoke and predict with okay so we could do that okay so I can grab let's",
    "start": "2554710",
    "end": "2562930"
  },
  {
    "text": "try and learn this okay so here I'm grabbing ten samples from my test set",
    "start": "2562930",
    "end": "2568960"
  },
  {
    "text": "okay so the first line is actually the sample okay that I've with the the",
    "start": "2568960",
    "end": "2574570"
  },
  {
    "text": "internet features and the numerical value here is the actual prediction okay",
    "start": "2574570",
    "end": "2579970"
  },
  {
    "text": "so binary classification predicts a value between zero and one and then you have to apply a cut-off value saying by",
    "start": "2579970",
    "end": "2588160"
  },
  {
    "text": "default let's say anything lower than 0.5 is a zero so it's a no anything",
    "start": "2588160",
    "end": "2594340"
  },
  {
    "text": "higher than 0.5 is a 1 so it's a yes okay and we can predict with that okay",
    "start": "2594340",
    "end": "2600790"
  },
  {
    "text": "so what we're doing here is calling an API to predict what this really does is it HTTP posts that data to the endpoint",
    "start": "2600790",
    "end": "2609120"
  },
  {
    "text": "okay but you could do that in any of your favorite languages Java C++ etc",
    "start": "2609120",
    "end": "2614860"
  },
  {
    "text": "using the SDKs okay but when experimenting is just convenient to use that that API ok and",
    "start": "2614860",
    "end": "2621550"
  },
  {
    "text": "when we're done we can just delete the endpoint okay and stop paying ok man I",
    "start": "2621550",
    "end": "2629260"
  },
  {
    "text": "didn't mention anything about pricing because it's it very straight forward actually so for training you just pay",
    "start": "2629260",
    "end": "2636250"
  },
  {
    "text": "for what you use so if you trained on demand this extra boost I'll go for let's say one minute",
    "start": "2636250",
    "end": "2644470"
  },
  {
    "text": "well that's what you pay for one minute okay stage maker creates infrastructure trains takes it down automatically so",
    "start": "2644470",
    "end": "2651730"
  },
  {
    "text": "you will never overpay for training you will leave anything on that's not doing anything useful okay",
    "start": "2651730",
    "end": "2657170"
  },
  {
    "text": "so that's what you pay for by the second for the actual training duration for",
    "start": "2657170",
    "end": "2662450"
  },
  {
    "text": "endpoints you just pay for how long that endpoint has been up right and you take",
    "start": "2662450",
    "end": "2668150"
  },
  {
    "text": "it down and up again if you need to okay so again I'm doing it at very small scale here but if we had you know 50",
    "start": "2668150",
    "end": "2676760"
  },
  {
    "text": "training instances and 20 instances backing this endpoint that would be the exact same code I would just say give me",
    "start": "2676760",
    "end": "2683420"
  },
  {
    "text": "50 training instances and 20 instances to back the endpoint okay nothing more so how do you get started",
    "start": "2683420",
    "end": "2693970"
  },
  {
    "text": "so sage maker is sage maker oops it's actually part of the free tier okay",
    "start": "2695770",
    "end": "2702590"
  },
  {
    "text": "which is a way for you to use AWS services for free for 12 months so check it out if you want to literally",
    "start": "2702590",
    "end": "2709400"
  },
  {
    "text": "experiment at zero cost if you if you want to practice a little more I would",
    "start": "2709400",
    "end": "2716000"
  },
  {
    "text": "highly recommend that you check out the Amazon sage maker examples repo on github which has a huge collection of",
    "start": "2716000",
    "end": "2722690"
  },
  {
    "text": "notebooks showing you all the built-in algos and tensorflow and then max net and everything else it's it's growing by",
    "start": "2722690",
    "end": "2728660"
  },
  {
    "text": "the day so it's really great and it's a good way to to explore if you if you",
    "start": "2728660",
    "end": "2734210"
  },
  {
    "text": "want this example I showed you is actually a very short version of a workshop idea that we invent last year",
    "start": "2734210",
    "end": "2740570"
  },
  {
    "text": "called en 3 3 2 1 so if you want the full three hour for our version it's in",
    "start": "2740570",
    "end": "2747170"
  },
  {
    "text": "there feel free to check my blog on medium and and you can also grab some more notebooks and examples on on git",
    "start": "2747170",
    "end": "2754250"
  },
  {
    "text": "lab we're going to thank the large again thank you very much cause for being with us today and sharing your your use case",
    "start": "2754250",
    "end": "2760400"
  },
  {
    "text": "thank you very much for attending enjoy the rest of the day [Applause]",
    "start": "2760400",
    "end": "2767580"
  }
]
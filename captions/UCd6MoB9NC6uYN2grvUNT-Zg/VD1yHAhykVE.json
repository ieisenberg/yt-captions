[
  {
    "text": "so welcome to another session of 2019 AWS public sector this is summit just",
    "start": "680",
    "end": "7140"
  },
  {
    "text": "have a few ice I'll skip an item to share with you we have to get to exit doors right to the left and to the left",
    "start": "7140",
    "end": "14400"
  },
  {
    "text": "of the alway you have the bathroom and then please remember to silence all your devices this session is being recorded",
    "start": "14400",
    "end": "21740"
  },
  {
    "text": "so when you at the end of this session we may have Kiran here it's important that you use a microphone I could give",
    "start": "21740",
    "end": "27810"
  },
  {
    "text": "you the microphone or you could use the one right in the middle of the room and the session recordings will be made",
    "start": "27810",
    "end": "33630"
  },
  {
    "text": "available after these events and also please if you have not already done so download our AWS app for the summit from",
    "start": "33630",
    "end": "40920"
  },
  {
    "text": "there you can share your feedback on each session you attend so that we can improve this next time we come here with",
    "start": "40920",
    "end": "46050"
  },
  {
    "text": "that I'll welcome Anna Pinheiro gravity and rich cygnets",
    "start": "46050",
    "end": "51570"
  },
  {
    "text": "onstage for the next session called community tools for analysis of earth science data in the cloud welcome Anna",
    "start": "51570",
    "end": "60020"
  },
  {
    "text": "[Applause]",
    "start": "60020",
    "end": "66260"
  },
  {
    "text": "ok hello everybody and thank you for joining us I appreciate you coming after",
    "start": "66260",
    "end": "72180"
  },
  {
    "text": "lunch I know it's a little bit tough we're going to try to keep this as entertaining as possible so nobody falls asleep my name is Anna Pinet pre-vet I'm",
    "start": "72180",
    "end": "80400"
  },
  {
    "text": "a Senior Program Manager in Amazon I'm actually not with Ada progress but I'm with a sustainability team but I worked",
    "start": "80400",
    "end": "87509"
  },
  {
    "text": "very closely with AWS in particular with the open data team in a project that",
    "start": "87509",
    "end": "93030"
  },
  {
    "text": "I'll introduce in a few minutes called the Amazon sustainability data initiative today in addition to this",
    "start": "93030",
    "end": "99659"
  },
  {
    "text": "quick presentation that I'll give as an overview to that program and showing what are the opportunities to work",
    "start": "99659",
    "end": "104939"
  },
  {
    "text": "together if anybody is interested in pursuing that further we also have rich",
    "start": "104939",
    "end": "111360"
  },
  {
    "text": "signal who works for USGS for 30 years which is amazing it brings the deep",
    "start": "111360",
    "end": "118619"
  },
  {
    "text": "knowledge and understanding of the space of data and scientific data analysis and",
    "start": "118619",
    "end": "124500"
  },
  {
    "text": "you will be speaking today with us about Pangaea which is a project it's almost",
    "start": "124500",
    "end": "129810"
  },
  {
    "text": "like a community now I would say that is it's doing some amazing work and",
    "start": "129810",
    "end": "135180"
  },
  {
    "text": "that we are very proud to be supporting and so we were eager to see how we can",
    "start": "135180",
    "end": "141510"
  },
  {
    "text": "move this space forward and do more with them if possible okay so I am gonna try",
    "start": "141510",
    "end": "146939"
  },
  {
    "text": "to find the tracker which is right here and jump straight into the Amazon",
    "start": "146939",
    "end": "153690"
  },
  {
    "text": "sustainability that initiative so this program we launched this program",
    "start": "153690",
    "end": "159230"
  },
  {
    "text": "officially in publicly less December but really we've been working on this with",
    "start": "159230",
    "end": "164879"
  },
  {
    "text": "the open tater data team and other groups that Amazon for for quite a while and and the goal of this program is",
    "start": "164879",
    "end": "171120"
  },
  {
    "text": "really try to understand how do we leverage the scale of Amazon in our",
    "start": "171120",
    "end": "176280"
  },
  {
    "text": "infrastructure and the knowledge and the technology to try to promote more innovation and problem solving in the",
    "start": "176280",
    "end": "182639"
  },
  {
    "text": "space of sustainability so not necessarily focus internally how do we help Amazon but externally how do we",
    "start": "182639",
    "end": "190049"
  },
  {
    "text": "help the broader community move forward in this space and remove some of the barriers that are preventing us from",
    "start": "190049",
    "end": "195420"
  },
  {
    "text": "from gathering more knowledge and and more insight that is required so just to",
    "start": "195420",
    "end": "201780"
  },
  {
    "text": "provide a little bit of context and when you think of a global sustainable development we really need to think of",
    "start": "201780",
    "end": "208489"
  },
  {
    "text": "know how do we work that delicate balance of promoting economic development and prosperity and at the",
    "start": "208489",
    "end": "215430"
  },
  {
    "text": "same time how do we preserve the natural resources and how do we ensure you know",
    "start": "215430",
    "end": "220980"
  },
  {
    "text": "social fairness and all of those aspects that sustainability encompasses so for that is really critical that we have",
    "start": "220980",
    "end": "228829"
  },
  {
    "text": "meaningful and timely insights to make decisions so but what we see is that",
    "start": "228829",
    "end": "235260"
  },
  {
    "text": "although we we live in a space and time where we have more data than ever what",
    "start": "235260",
    "end": "240419"
  },
  {
    "text": "we are observing is that that availability of data is not necessarily translating into the insights that we",
    "start": "240419",
    "end": "247349"
  },
  {
    "text": "need to make decisions and so that code here is just something that I'm sure most of you have experiences and if not",
    "start": "247349",
    "end": "254280"
  },
  {
    "text": "about the quote about the actual fact that as a researcher or a developer or a",
    "start": "254280",
    "end": "259919"
  },
  {
    "text": "scientist in general most of the time that is required to extract some kind of",
    "start": "259919",
    "end": "265590"
  },
  {
    "text": "in side from data is really spent on gathering the data discovering it and and in preparing the data for analysis",
    "start": "265590",
    "end": "272939"
  },
  {
    "text": "which really you know if you think about it if eighty percent of that time is",
    "start": "272939",
    "end": "278279"
  },
  {
    "text": "pants on that kind of activity there's a potential to unleash that that time and",
    "start": "278279",
    "end": "283650"
  },
  {
    "text": "effort towards producing more insights and more knowledge that can help us move forward faster so the what we're trying",
    "start": "283650",
    "end": "290310"
  },
  {
    "text": "to do with the Amazon sustainability data initiative is really to try to remove as much as possible that",
    "start": "290310",
    "end": "295409"
  },
  {
    "text": "undifferentiated heavy lifting as Amazon and AWS likes to call it that will",
    "start": "295409",
    "end": "300719"
  },
  {
    "text": "hopefully bring us all to a higher level so you know just just for context I was trained as a research scientist and I",
    "start": "300719",
    "end": "307529"
  },
  {
    "text": "spent most of my career during research so I fell that very strongly in my skin okay so what the Amazon",
    "start": "307529",
    "end": "313800"
  },
  {
    "text": "sustainability data initiative is trying to do is really try to understand how do we work with the community to remove",
    "start": "313800",
    "end": "319319"
  },
  {
    "text": "some of those barriers and decrease the cost and the effort involved in creating",
    "start": "319319",
    "end": "324689"
  },
  {
    "text": "sustainability insights that can help us all so we believe that by working on",
    "start": "324689",
    "end": "330300"
  },
  {
    "text": "these three core areas we can hopefully make an impact so one is the data which",
    "start": "330300",
    "end": "336210"
  },
  {
    "text": "is at the core of everything that we're doing and for that we leverage the the",
    "start": "336210",
    "end": "341639"
  },
  {
    "text": "scalable infrastructure available us to make available datasets in the cloud and",
    "start": "341639",
    "end": "346919"
  },
  {
    "text": "make them publicly available to anybody to analyze and and access and then we",
    "start": "346919",
    "end": "352919"
  },
  {
    "text": "believe that so by removing the burden of data acquisition and also",
    "start": "352919",
    "end": "358550"
  },
  {
    "text": "democratizing access to the tools and the analytical capabilities that the cloud offers together with you know",
    "start": "358550",
    "end": "365969"
  },
  {
    "text": "promoting knowledge exchange we might be able to somehow move this space forward",
    "start": "365969",
    "end": "371610"
  },
  {
    "text": "okay so very pragmatically what are we doing so on the data side we as I said",
    "start": "371610",
    "end": "377909"
  },
  {
    "text": "we work closely with the community not only with AWS customers but with the community in general and try to",
    "start": "377909",
    "end": "382949"
  },
  {
    "text": "understand what are those foundational datasets that we should bring to the cloud that would really have the",
    "start": "382949",
    "end": "388439"
  },
  {
    "text": "potential to unleash a lot of knowledge extraction so the idea here is not we don't want to move all the datasets to",
    "start": "388439",
    "end": "394860"
  },
  {
    "text": "the cloud we want to curate this this space so that we the ones datasets that are really",
    "start": "394860",
    "end": "401430"
  },
  {
    "text": "critical for this conversation at least in this first phase so we've been very focused on working with different data",
    "start": "401430",
    "end": "408060"
  },
  {
    "text": "providers around the world to identify those datasets there's authoritative datasets and then bring them to the",
    "start": "408060",
    "end": "414180"
  },
  {
    "text": "cloud and we do that through an existing program on AWS called the public datasets program that Joe flasher",
    "start": "414180",
    "end": "421590"
  },
  {
    "text": "somewhere here in the audience is as part of and it's been a very active",
    "start": "421590",
    "end": "427050"
  },
  {
    "text": "partner in this in this effort and currently we have I believe over 40",
    "start": "427050",
    "end": "432750"
  },
  {
    "text": "datasets that span anything from like weather observations from NOAA and from",
    "start": "432750",
    "end": "438750"
  },
  {
    "text": "different agencies around the world to climate projections hair quality and and these are is just a few examples of the",
    "start": "438750",
    "end": "444690"
  },
  {
    "text": "the kind of sub domains that we are exploring so far and we continue to grow",
    "start": "444690",
    "end": "450810"
  },
  {
    "text": "this catalog in response to the needs that we then Phi as we work with the community the other one is as I",
    "start": "450810",
    "end": "456870"
  },
  {
    "text": "mentioned how do we democratize access to the tools how do we ensure that you",
    "start": "456870",
    "end": "462180"
  },
  {
    "text": "know beyond the big institutions that have the data centers and the high performance computers we enable others",
    "start": "462180",
    "end": "468360"
  },
  {
    "text": "around the world to have access to those datasets and extract knowledge and we really work across a broad domain of",
    "start": "468360",
    "end": "475730"
  },
  {
    "text": "audiences out there so anywhere from startups to nonprofits and academia so",
    "start": "475730",
    "end": "480810"
  },
  {
    "text": "we are not just necessarily trying to encourage the research academics but",
    "start": "480810",
    "end": "486180"
  },
  {
    "text": "also the broader community to access this resources and and try to see how",
    "start": "486180",
    "end": "491700"
  },
  {
    "text": "they can innovate so I was just going to mention so as part of that process we we",
    "start": "491700",
    "end": "497100"
  },
  {
    "text": "really try to offset the cost of experimentation and to do that we we",
    "start": "497100",
    "end": "502110"
  },
  {
    "text": "enable anybody that is interested in in basically anybody that is interested in",
    "start": "502110",
    "end": "507210"
  },
  {
    "text": "in experimenting with an idea in the cloud that is related to sustainability we have cloud credits and different",
    "start": "507210",
    "end": "513450"
  },
  {
    "text": "grants that we offer for for those that are interested so if you want to learn more please let me know and and this",
    "start": "513450",
    "end": "519180"
  },
  {
    "text": "would provide us access to all of the different tools and basically all the services on AWS that that are",
    "start": "519180",
    "end": "526290"
  },
  {
    "text": "traditionally available to the customers okay and the final component as I",
    "start": "526290",
    "end": "531330"
  },
  {
    "text": "mentioned is this idea of K this there's still a lot of barriers you know we have to recognize there's still a lot",
    "start": "531330",
    "end": "536820"
  },
  {
    "text": "of barriers for the majority of the people to move the cloud there's still a lot of legacy code that has been written",
    "start": "536820",
    "end": "543779"
  },
  {
    "text": "you know like for on-premise systems and and so we recognize that there is an",
    "start": "543779",
    "end": "549360"
  },
  {
    "text": "effort to move across and we're trying to understand how do we remove those barriers how do we make it easier for",
    "start": "549360",
    "end": "554790"
  },
  {
    "text": "all of us to kind of learn together through this process and move forward so we've been putting a lot of effort into",
    "start": "554790",
    "end": "560550"
  },
  {
    "text": "not only just writing tutorials with our customers that are innovating to try to",
    "start": "560550",
    "end": "566580"
  },
  {
    "text": "show what is possible and how they did it but also create opportunities for instance to connect data providers with",
    "start": "566580",
    "end": "573870"
  },
  {
    "text": "the customers and the broader communities so that we can have a closer connection and exchange of knowledge there as well okay that is all for me I",
    "start": "573870",
    "end": "582089"
  },
  {
    "text": "just I added a few links there and more information feel feel free to contact me",
    "start": "582089",
    "end": "587910"
  },
  {
    "text": "or that address that as well if you have any questions or if you would like to get involved with this initiative one",
    "start": "587910",
    "end": "595680"
  },
  {
    "text": "last thing I wanted to mention before I give the stage to rich is that so the",
    "start": "595680",
    "end": "601290"
  },
  {
    "text": "open data team as I mentioned we working very closely with them and they have for many years been devoting a lot of their",
    "start": "601290",
    "end": "608370"
  },
  {
    "text": "time and expertise to understand what is the optimal way to share that in the cloud to make it analysis ready and to",
    "start": "608370",
    "end": "614640"
  },
  {
    "text": "encourage people to actually extract value from it so we they recently put",
    "start": "614640",
    "end": "620010"
  },
  {
    "text": "together this guide that is called sharing data on AWS which is really an",
    "start": "620010",
    "end": "626130"
  },
  {
    "text": "interesting and and very helpful example you know guidelines basically of what",
    "start": "626130",
    "end": "632100"
  },
  {
    "text": "are the things that they have learned it's been led by Jets and well and it did a great job putting this together so",
    "start": "632100",
    "end": "638370"
  },
  {
    "text": "I have a few copies of this if you're interested come and see me at the end and we also have it available on PDF",
    "start": "638370",
    "end": "644670"
  },
  {
    "text": "format if you don't want to carry this with you and I'll just mention that it is available at open data dot AWS slash",
    "start": "644670",
    "end": "652350"
  },
  {
    "text": "guide and again if you come in to see me at the end I can give you that information okay I guess that's all for",
    "start": "652350",
    "end": "658290"
  },
  {
    "text": "me I just want to mention that it's rich please come on stage I just want to mention that is that as part of that",
    "start": "658290",
    "end": "665550"
  },
  {
    "text": "conversation I was mentioning one of the component how do we encourage people to experiment in the cloud we've been providing",
    "start": "665550",
    "end": "672520"
  },
  {
    "text": "different grants to different groups and I'm very encouraged that the Pangea group is is also looking at how to",
    "start": "672520",
    "end": "678960"
  },
  {
    "text": "potentially explore the cloud as a way to make it democratize access to these tools to the rest of the communities so",
    "start": "678960",
    "end": "687120"
  },
  {
    "text": "thank you so I'm really I'm happy to talk to you about Pangaea today I think",
    "start": "688260",
    "end": "694450"
  },
  {
    "text": "it's a really exciting project the let's",
    "start": "694450",
    "end": "700090"
  },
  {
    "text": "see no okay yeah okay so so pan geo is a",
    "start": "700090",
    "end": "710610"
  },
  {
    "text": "community platform for Big Data Geoscience I'm a research oceanographer the US Geological Survey",
    "start": "710610",
    "end": "716830"
  },
  {
    "text": "but I'm here representing this pan geo community that consists of a lot more",
    "start": "716830",
    "end": "722980"
  },
  {
    "text": "people that are on that slide right there but those people have been very instrumental in leading the project and",
    "start": "722980",
    "end": "728200"
  },
  {
    "text": "bringing people on board so before I tell you about pan geo I want to tell",
    "start": "728200",
    "end": "734320"
  },
  {
    "text": "you about what inspired pan geo this is a NASA simulation of the world ocean showing you circulation and this model",
    "start": "734320",
    "end": "741880"
  },
  {
    "text": "in its most recent incarnation it saved at one hourly time steps for a year is",
    "start": "741880",
    "end": "748110"
  },
  {
    "text": "two petabytes of data for this single simulation so how this is what inspired",
    "start": "748110",
    "end": "755170"
  },
  {
    "text": "Ryan Abernathy at Columbia to start this Pangea project of sort of a selfish interest as an oceanographer how do I",
    "start": "755170",
    "end": "760690"
  },
  {
    "text": "work with data this size how do I share this with my colleagues as most of you know the ocean has absorbed 90% of the",
    "start": "760690",
    "end": "769570"
  },
  {
    "text": "warming due to climate change and so understanding the ocean is really fundamental to understanding how our",
    "start": "769570",
    "end": "775480"
  },
  {
    "text": "planet is changing and what its response will be so we absolutely need this kind",
    "start": "775480",
    "end": "780640"
  },
  {
    "text": "of data to be in the hands of as many people as possible so we understand it as best as possible it can't be locked",
    "start": "780640",
    "end": "786490"
  },
  {
    "text": "up in just the hands of the modelers who created this and this was Ryan's inspiration so I am at the US Geological",
    "start": "786490",
    "end": "795490"
  },
  {
    "text": "Survey I also have a selfish interest in this project because I supervise a sediment transport",
    "start": "795490",
    "end": "801100"
  },
  {
    "text": "modeling group we have a couple of modeling system that goes from wind to waves to circulation to sediment",
    "start": "801100",
    "end": "807940"
  },
  {
    "text": "transport that helps to tell us how the beaches and the coastline changes in response to storms and response to",
    "start": "807940",
    "end": "813880"
  },
  {
    "text": "climate change so we have hundreds of terabytes of data that we want to share",
    "start": "813880",
    "end": "819280"
  },
  {
    "text": "with our we don't have petabytes but we have hundreds of terabytes that we want to share with our colleagues and we save",
    "start": "819280",
    "end": "827230"
  },
  {
    "text": "this data from both of those models that you just saw there the data is stored in these netcdf files so the net CDF for is",
    "start": "827230",
    "end": "834760"
  },
  {
    "text": "actually hdf5 file underneath this is a scientific data format that was designed specifically for multi dimensional data",
    "start": "834760",
    "end": "841930"
  },
  {
    "text": "and it's been with us for about 25 years it's used extensively throughout the geosciences and this is just showing you",
    "start": "841930",
    "end": "848530"
  },
  {
    "text": "that on the left here this is the vertical grid so it's the main point here is in the vertical it's not a you",
    "start": "848530",
    "end": "855400"
  },
  {
    "text": "know it's not a raster it's not regular intervals and in the horizontal field it's also not regular intervals this is not a 3d raster it's more complicated",
    "start": "855400",
    "end": "862360"
  },
  {
    "text": "than that and of course we're not alone you know I've been talking about model",
    "start": "862360",
    "end": "868660"
  },
  {
    "text": "output it on the right is the cmip5 archive the CIA archives cmip5 and CMM",
    "start": "868660",
    "end": "874510"
  },
  {
    "text": "six these are the climate simulations you know they went from two petabytes six years later at a hundred fifty",
    "start": "874510",
    "end": "879880"
  },
  {
    "text": "petabytes so that for the next release they're heading to exabyte scale and on the left is nasa's cloud projected cloud",
    "start": "879880",
    "end": "886750"
  },
  {
    "text": "storage from about 50 petabytes now to over 300 petabytes in in five years or",
    "start": "886750",
    "end": "893590"
  },
  {
    "text": "in you know at six years so everyone has this problem this is remote sensing data",
    "start": "893590",
    "end": "899170"
  },
  {
    "text": "this is model output but everybody has the same problem so you know this is",
    "start": "899170",
    "end": "906190"
  },
  {
    "text": "still the way that most scientists do their analysis they they run their simulations somewhere on some",
    "start": "906190",
    "end": "912070"
  },
  {
    "text": "high-performance computing facility and then they download that data over a very fat pipe hopefully so it comes in fast",
    "start": "912070",
    "end": "917080"
  },
  {
    "text": "to their local workstations where they you know store the data locally and they",
    "start": "917080",
    "end": "922270"
  },
  {
    "text": "have their software and their hardware you know that they maintain and they do their analysis and visualization of",
    "start": "922270",
    "end": "927970"
  },
  {
    "text": "course they're limited to the number of processors they have they can't share their data with it you know that that",
    "start": "927970",
    "end": "933250"
  },
  {
    "text": "same workflows that they're executing can't be easily replicated and the data has to be copied many times we all know",
    "start": "933250",
    "end": "939700"
  },
  {
    "text": "this so what we want is what is is the data in the cloud all the analysis and",
    "start": "939700",
    "end": "946510"
  },
  {
    "text": "visualization in the cloud and only a lightweight connection down to you sitting in the park with your laptop and",
    "start": "946510",
    "end": "953589"
  },
  {
    "text": "your Wi-Fi hotspot and you can do scale a little data proximate analysis on your output so what is Pangaea so pan geo is",
    "start": "953589",
    "end": "963459"
  },
  {
    "text": "a community first and foremost it was started as I mentioned by Ryan Abernathy",
    "start": "963459",
    "end": "968490"
  },
  {
    "text": "from Lamont within a collaboration with you car in the British Medical aberration and with",
    "start": "968490",
    "end": "975310"
  },
  {
    "text": "Google credits and funding from the NSF on their Earth Cube program and anaconda",
    "start": "975310",
    "end": "980709"
  },
  {
    "text": "here with providing Python support on some of the packages but it was pretty",
    "start": "980709",
    "end": "985779"
  },
  {
    "text": "quickly joined and expanded there's a nasa access grant that was a combination",
    "start": "985779",
    "end": "991209"
  },
  {
    "text": "of the washington d science institute an element 84 and and amazon provided",
    "start": "991209",
    "end": "997720"
  },
  {
    "text": "significant funding for that and also provided some funding for cloud credits",
    "start": "997720",
    "end": "1002760"
  },
  {
    "text": "for a nice tip project that I was involved with and recently Azur has as",
    "start": "1002760",
    "end": "1008190"
  },
  {
    "text": "entered in in the Pangea funding arena funding queen's college for a quite significant amount to look to look at",
    "start": "1008190",
    "end": "1014149"
  },
  {
    "text": "how to handle use Pangea for ocean observations and then there's a number",
    "start": "1014149",
    "end": "1019529"
  },
  {
    "text": "of other groups that many more logos than I could put on here actually see",
    "start": "1019529",
    "end": "1025678"
  },
  {
    "text": "can I go back I wanted to point out that this is a very open group and in fact if",
    "start": "1025679",
    "end": "1032370"
  },
  {
    "text": "you go to the their github site you know they tell you to add your name to this list so here's the community you know",
    "start": "1032370",
    "end": "1037920"
  },
  {
    "text": "who you are what you do where you where you work and you can put your name on this list you just fork the repo and you",
    "start": "1037920",
    "end": "1045178"
  },
  {
    "text": "add yourself and you know they when they accept the pull request you're part of the team and so and you really are part",
    "start": "1045179",
    "end": "1054030"
  },
  {
    "text": "of the team you know you can participate in the weekly calls everything is discussed out in the open on github they really do not like you talking about the",
    "start": "1054030",
    "end": "1063300"
  },
  {
    "text": "project via email or slack they want it as open as possible and I think that's really helped this project",
    "start": "1063300",
    "end": "1068760"
  },
  {
    "text": "bro so what is pan geo again pan geo is actually a software stack as well the",
    "start": "1068760",
    "end": "1075990"
  },
  {
    "text": "foundation is Python on top so on this Python platform that the idea was let's",
    "start": "1075990",
    "end": "1081120"
  },
  {
    "text": "not build anything new let's take the things that are really successful out in the Python community already and make them really work well in this to solve",
    "start": "1081120",
    "end": "1088140"
  },
  {
    "text": "these kind of problems so on top of this Python environment this pan geo framework it really fundamentally is a",
    "start": "1088140",
    "end": "1095130"
  },
  {
    "text": "data is a data model I'm going to jump around here but there's the data model of X ray which represents that native",
    "start": "1095130",
    "end": "1100920"
  },
  {
    "text": "netcdf data model and iris is a similar package from the British met office you can use either one of these you can also",
    "start": "1100920",
    "end": "1107100"
  },
  {
    "text": "use pandas for tabular data for handling these n-dimensional Ray's we used asked",
    "start": "1107100",
    "end": "1112110"
  },
  {
    "text": "primarily which actually sits on top of numpy probably should be modified a little bit but this handles the parallel",
    "start": "1112110",
    "end": "1117510"
  },
  {
    "text": "execution of code in this system and the processing you can use it interactively",
    "start": "1117510",
    "end": "1122610"
  },
  {
    "text": "through a jupiter environment you can do batch or server lists and you can run on HPC you can run on your laptop you can",
    "start": "1122610",
    "end": "1129150"
  },
  {
    "text": "run on a AWS Google or as your so you can run the same thing every work you don't it's cloud agnostic you don't have",
    "start": "1129150",
    "end": "1135480"
  },
  {
    "text": "to and you can run it on your HPC if you're not ready for cloud or you have some other reason to do that so you know",
    "start": "1135480",
    "end": "1142500"
  },
  {
    "text": "this is the way we usually use it though these are the fundamental components again shown a little bit more clearly but it's the way we almost everyone is",
    "start": "1142500",
    "end": "1148860"
  },
  {
    "text": "actually using you have some so this is HPC architecture you have your n dimensional array data and some",
    "start": "1148860",
    "end": "1154710"
  },
  {
    "text": "distributed you know a bunch of files perhaps sitting on a file system and those files are chunked in the HDF and",
    "start": "1154710",
    "end": "1162600"
  },
  {
    "text": "netcdf allow you to chunk your data so each little piece can be extracted separately okay and that's pretty",
    "start": "1162600",
    "end": "1169530"
  },
  {
    "text": "important because this dash scheduler then can have a bunch of workers go work on those little pieces of data and",
    "start": "1169530",
    "end": "1175800"
  },
  {
    "text": "return them to X array and this is the data again this is the data model you can do this kind of crunching here with",
    "start": "1175800",
    "end": "1181710"
  },
  {
    "text": "these tools and then PI this is the visualization piece that allows you to see interact with the data visually and",
    "start": "1181710",
    "end": "1189210"
  },
  {
    "text": "all this can it happen through your browser if you're using Jupiter so that you you get this kind of experience so",
    "start": "1189210",
    "end": "1194580"
  },
  {
    "text": "I'm going to show you a demo later the cloud architecture",
    "start": "1194580",
    "end": "1200230"
  },
  {
    "text": "looks the same as I mentioned the only thing here is that this is an important",
    "start": "1200230",
    "end": "1205700"
  },
  {
    "text": "piece this n dimensional array data you've stored here on the cloud has to be in a cloud friendly format otherwise",
    "start": "1205700",
    "end": "1213260"
  },
  {
    "text": "you get a very poor performance if you just move those netcdf files to the cloud you get poor performance and why",
    "start": "1213260",
    "end": "1219230"
  },
  {
    "text": "is that well Matthew rockland part of the Pangaea team used to be an anaconda",
    "start": "1219230",
    "end": "1224420"
  },
  {
    "text": "now at Nvidia wrote a really nice blog piece on this called a hdf in the cloud",
    "start": "1224420",
    "end": "1229460"
  },
  {
    "text": "challenges and solutions for scientific data and he offered some various solutions one is the cloud optimized geo",
    "start": "1229460",
    "end": "1236060"
  },
  {
    "text": "tip just do what the image folks do but it turns out that doesn't work so well for us because we have non raster data",
    "start": "1236060",
    "end": "1241910"
  },
  {
    "text": "and we also have it doesn't really meet this netcdf data model and also that basically gives you a chunk size of one",
    "start": "1241910",
    "end": "1248300"
  },
  {
    "text": "and the time dimension you're stuck with that ok so what can you also give you do",
    "start": "1248300",
    "end": "1253880"
  },
  {
    "text": "if you just stick those files on on the cloud and pretend they're files through using fuse so just pretend they're you",
    "start": "1253880",
    "end": "1259550"
  },
  {
    "text": "know files and this is actually quite slow another solution would be to put",
    "start": "1259550",
    "end": "1264980"
  },
  {
    "text": "those files on on the cloud and use some kind of custom reader get tricky with how you read them instead of using the existing libraries do some fancy things",
    "start": "1264980",
    "end": "1270920"
  },
  {
    "text": "so the problem with netcdf is an hdf is that you have to do lots of little requests and that doesn't work so well",
    "start": "1270920",
    "end": "1277040"
  },
  {
    "text": "in s3 you really want to load all the metadata at once and then just go after the chunks of data so you could do try",
    "start": "1277040",
    "end": "1283700"
  },
  {
    "text": "to do some fancy thing like that with a with a custom reader you could build a distributed service not too many people",
    "start": "1283700",
    "end": "1288890"
  },
  {
    "text": "are interested in a data service they'd rather go right to the s3 and then the last one is new formats for scientific",
    "start": "1288890",
    "end": "1294590"
  },
  {
    "text": "data and that's what I'm talking about with this are with the SAR format so the",
    "start": "1294590",
    "end": "1300770"
  },
  {
    "text": "SAR format was actually developed in the genomics community interestingly enough and it was addressed",
    "start": "1300770",
    "end": "1306770"
  },
  {
    "text": "it was developed specifically to address these issues with hdf and netcdf and cloud it's really simple it's got a",
    "start": "1306770",
    "end": "1313670"
  },
  {
    "text": "clear specification every chunk is a separate object so if you think of all those chunks in a netcdf file you take",
    "start": "1313670",
    "end": "1319760"
  },
  {
    "text": "those out and you put each one of those chunks in a separate object in object storage so whoops sorry and so it's",
    "start": "1319760",
    "end": "1329720"
  },
  {
    "text": "pretty lightweight and and all the data is just all the variable med everything is stored in just JSON and",
    "start": "1329720",
    "end": "1335759"
  },
  {
    "text": "then each one of these little chunks you can have filtering and compression on that chunk using a very standard Blas",
    "start": "1335759",
    "end": "1341909"
  },
  {
    "text": "library it's all free and open source and you can read that data just the same way you would read in that CDF file in",
    "start": "1341909",
    "end": "1348809"
  },
  {
    "text": "x-ray so from the user perspective once the data since are they can just use their same workflow they don't they",
    "start": "1348809",
    "end": "1354989"
  },
  {
    "text": "don't notice all they notice is that it works faster so this hour format actually looks like this is another",
    "start": "1354989",
    "end": "1362639"
  },
  {
    "text": "clever thing so if you have four chunks here that chunk the neh the tag on",
    "start": "1362639",
    "end": "1367830"
  },
  {
    "text": "object storage for chunk 0 0 is 0.0 okay",
    "start": "1367830",
    "end": "1373229"
  },
  {
    "text": "so what this means is you don't have to have any fancy figuring out where the chunks are you can just go exactly to",
    "start": "1373229",
    "end": "1378359"
  },
  {
    "text": "the chunks that you need and and so if",
    "start": "1378359",
    "end": "1383609"
  },
  {
    "text": "you look at the metadata so it's just JSON as I mentioned there's two attributes so if you look at a data set",
    "start": "1383609",
    "end": "1389039"
  },
  {
    "text": "like this add surf data set and a particular variable like Zeta you'll find these two things z array and z",
    "start": "1389039",
    "end": "1394109"
  },
  {
    "text": "adders and this z array just tells you the chunks and what kind of compression was used things like that and the",
    "start": "1394109",
    "end": "1400739"
  },
  {
    "text": "attributes could provide all the other sort of netcdf like information that tell you okay this thing called zeta is",
    "start": "1400739",
    "end": "1406940"
  },
  {
    "text": "actually water level elevation above geo and okay these are the things that make up the CF conventions but it's so this",
    "start": "1406940",
    "end": "1412859"
  },
  {
    "text": "is very simple and probably the most important thing I think actually and",
    "start": "1412859",
    "end": "1418649"
  },
  {
    "text": "sort of overlooked perhaps is that this is really truly community driven so so if we want a format to save all of our",
    "start": "1418649",
    "end": "1425969"
  },
  {
    "text": "scientific data for a long-term do we want a complicated data format that's",
    "start": "1425969",
    "end": "1431070"
  },
  {
    "text": "only held by you know tightly by one group development group or do we want something that is and you know only what",
    "start": "1431070",
    "end": "1436710"
  },
  {
    "text": "maybe two or three people understand the library that reads that data that's a little scary I think you know I'd much",
    "start": "1436710",
    "end": "1442889"
  },
  {
    "text": "rather have something that was community driven the people who have contributed to this our package they're some of the rock stars in this community and there's",
    "start": "1442889",
    "end": "1450659"
  },
  {
    "text": "a bunch of more you know so it's developed out and open what do you think about this newman has spent a lot of this discussion back and forth on github",
    "start": "1450659",
    "end": "1455999"
  },
  {
    "text": "and then something gets implemented so I'm very very hopeful about this our format so now we'll get into actually",
    "start": "1455999",
    "end": "1465539"
  },
  {
    "text": "some actually looking how this been used Noah had a big data project where I think he might have heard some",
    "start": "1465539",
    "end": "1472020"
  },
  {
    "text": "of the previous talks here at the summit about how a lot of data environmental data was moved on to the cloud and Noah",
    "start": "1472020",
    "end": "1478860"
  },
  {
    "text": "provided the data and the vendors the different cloud vendors moved it on the cloud and at no cost to Noah and so",
    "start": "1478860",
    "end": "1487260"
  },
  {
    "text": "whoops sorry so with this national water model 1.0",
    "start": "1487260",
    "end": "1493680"
  },
  {
    "text": "okay what it predicts the discharge on 2.7 million rivers and there's a one kilometer grid for the US that has all",
    "start": "1493680",
    "end": "1500430"
  },
  {
    "text": "the the forcing parameters everything so altogether about one month of forcing and output is about 15 terabytes and it",
    "start": "1500430",
    "end": "1507180"
  },
  {
    "text": "was pushed to the cloud so it is out there in buckets but it's in that CDF files and this 25-year analysis it",
    "start": "1507180",
    "end": "1513120"
  },
  {
    "text": "consists though if you want to go look at the River forecast data the hindcast data for that period it's it's 230,000",
    "start": "1513120",
    "end": "1520740"
  },
  {
    "text": "hourly netcdf files so if you try to extract a time series from that you're going to be disappointed so the idea",
    "start": "1520740",
    "end": "1529500"
  },
  {
    "text": "behind this project was let's take some of this data and put it up back on the clock in a cloud friendly format and see",
    "start": "1529500",
    "end": "1536220"
  },
  {
    "text": "and see what the performance looks like so so this is what we did so here's",
    "start": "1536220",
    "end": "1543090"
  },
  {
    "text": "here's just a simple test of reading some day taking the mean of some data and this particular dataset it was 23",
    "start": "1543090",
    "end": "1550590"
  },
  {
    "text": "gigabytes of data and we ran it and it finished in two minutes this was just pretending they're just regular files",
    "start": "1550590",
    "end": "1556680"
  },
  {
    "text": "and if you do the same thing with ZAR you do its exact same data set and we take the mean and it's 11 is 12 seconds",
    "start": "1556680",
    "end": "1563730"
  },
  {
    "text": "10 it's 10 times faster it was 10% faster nobody would care ten times faster is kind of a big deal so this is",
    "start": "1563730",
    "end": "1574560"
  },
  {
    "text": "just showing reading some national water model data from SAR and going through and computing the max of maximum",
    "start": "1574560",
    "end": "1582660"
  },
  {
    "text": "temperature over the US for a week of data and again this is the test we were doing before finishes in just a few",
    "start": "1582660",
    "end": "1588030"
  },
  {
    "text": "seconds all right so I'm now I'm going to do a live demo because I don't think",
    "start": "1588030",
    "end": "1593460"
  },
  {
    "text": "I've seen a live demo yet and it's Wednesday afternoon and so he's entertaining to see if it'll work",
    "start": "1593460",
    "end": "1599460"
  },
  {
    "text": "in fact my laptop is locked so I have to unlock that first all right so we're",
    "start": "1599460",
    "end": "1609539"
  },
  {
    "text": "gonna use everybody's favorite search engine DuckDuckGo and and we're gonna type in",
    "start": "1609539",
    "end": "1617309"
  },
  {
    "text": "so this is something you can do yourself don't do it right now they listen to me reproducible notebooks github okay",
    "start": "1617309",
    "end": "1628940"
  },
  {
    "text": "clearance on notebooks that's not the one we want we want this one here and so",
    "start": "1628940",
    "end": "1635659"
  },
  {
    "text": "this is a bunch of this is a proper organization with some repositories where each one of these things can just",
    "start": "1635659",
    "end": "1641369"
  },
  {
    "text": "be executed by you can download the code if I click on this it'll bring up the repo you can see that all is in this",
    "start": "1641369",
    "end": "1647309"
  },
  {
    "text": "repo is a ipython Jupiter notebook and some configuration that specifies the",
    "start": "1647309",
    "end": "1653849"
  },
  {
    "text": "software environment but all we're going to do is go down here and we're gonna launch we're gonna click on Pangea",
    "start": "1653849",
    "end": "1659009"
  },
  {
    "text": "binder which is going to launch this hopefully on amazon cloud using this",
    "start": "1659009",
    "end": "1667019"
  },
  {
    "text": "binder instance and what it does is it actually takes that the the",
    "start": "1667019",
    "end": "1673440"
  },
  {
    "text": "specifications the repo builds a docker container and then the docker container is launched into this environment so so",
    "start": "1673440",
    "end": "1680159"
  },
  {
    "text": "now i have a notebook so i didn't install anything right all i did was go to a link and and and and execute that",
    "start": "1680159",
    "end": "1685859"
  },
  {
    "text": "and now i'm on the cloud and and Pangea was paying for they're paying for this",
    "start": "1685859",
    "end": "1691879"
  },
  {
    "text": "so i executed a cell that just imports some libraries and now i'm going to here",
    "start": "1691879",
    "end": "1699149"
  },
  {
    "text": "i'm gonna move up a little bit and i'm gonna start this cluster up so the only thing that's different on the cloud besides you know for this whole workflow",
    "start": "1699149",
    "end": "1706019"
  },
  {
    "text": "if you're on a local machine you say local cluster and you use however many CPUs you have on your machine if you're",
    "start": "1706019",
    "end": "1711029"
  },
  {
    "text": "on HBC you can launch a cluster on your on your scheduling system like slurm and",
    "start": "1711029",
    "end": "1717179"
  },
  {
    "text": "it'll it'll actually request a whole bunch of workers which will then come back and form your cluster and on the cloud were using kubernetes and so we",
    "start": "1717179",
    "end": "1723599"
  },
  {
    "text": "can just request actually hopefully I should have executed this next well okay",
    "start": "1723599",
    "end": "1729029"
  },
  {
    "text": "we already got the 30 workers and the 60 cores and now I'm going execute this next cell actually which",
    "start": "1729029",
    "end": "1735210"
  },
  {
    "text": "adapts the workflow so you can see if so if we need these 60 workers they're going to work for us if we don't need",
    "start": "1735210",
    "end": "1741460"
  },
  {
    "text": "them they're going to disappear if I could get the Ness cell because I'm not really doing anything probably this cube cluster is going to",
    "start": "1741460",
    "end": "1746740"
  },
  {
    "text": "like okay so it's now it's back down to zero okay so just I wanted to show you how it can adapt adapt dynamically and",
    "start": "1746740",
    "end": "1753010"
  },
  {
    "text": "that's important obviously for cost so I've got my client I'm going to scroll",
    "start": "1753010",
    "end": "1758440"
  },
  {
    "text": "down a little bit here can people see this yeah okay and so now I just got",
    "start": "1758440",
    "end": "1765549"
  },
  {
    "text": "some logic what am I on Google or I'm on Amazon I'm on Amazon so I open up that particular bucket and after a few",
    "start": "1765549",
    "end": "1774190"
  },
  {
    "text": "seconds I can then look at this data set that I've opened you see I've opened it with X array opens are okay and actually",
    "start": "1774190",
    "end": "1782260"
  },
  {
    "text": "let's just insert a cell here below so you can see actually see the data set oops where did I type that so here's the",
    "start": "1782260",
    "end": "1793240"
  },
  {
    "text": "data set that we loaded so it looks just like netcdf it's got time to the coordinates x and y it's got these",
    "start": "1793240",
    "end": "1799210"
  },
  {
    "text": "different variables okay but we haven't really loaded any data yet so a bunch of",
    "start": "1799210",
    "end": "1806400"
  },
  {
    "text": "attributes and then we took a look at this particular variable Zeta okay I'm gonna execute that again it's",
    "start": "1806400",
    "end": "1812260"
  },
  {
    "text": "this water surface it's got 720 time steps and 9 million nodes and it's chunk",
    "start": "1812260",
    "end": "1818559"
  },
  {
    "text": "size okay is 10 and the time dimension at 140,000 nodes okay so these are nodes",
    "start": "1818559",
    "end": "1824679"
  },
  {
    "text": "of triangles this is a triangular mesh is that this ocean and you'll see when",
    "start": "1824679",
    "end": "1829960"
  },
  {
    "text": "we visualize this it's very detailed mesh of the Gulf of Mexico and we're",
    "start": "1829960",
    "end": "1835240"
  },
  {
    "text": "looking at the hurricane at Hurricane Ike water levels we're going to try to find the maximum water level during this storm so so we're going to go down here",
    "start": "1835240",
    "end": "1844690"
  },
  {
    "text": "and we're gonna see how big this variable is it's 53 gigabytes okay and so now the next we still haven't done",
    "start": "1844690",
    "end": "1850840"
  },
  {
    "text": "anything so the next cell that I'm gonna execute the next cell is a comment the next cell is going to be taking the",
    "start": "1850840",
    "end": "1857380"
  },
  {
    "text": "maximum over the time dimension this is x-ray magic right and I'm going to persist this onto the workers so that",
    "start": "1857380",
    "end": "1864490"
  },
  {
    "text": "when you if the data is going to go onto the workers if I need that data later I might want to use it to calculate say",
    "start": "1864490",
    "end": "1870619"
  },
  {
    "text": "the minimum okay so here I'm going to execute this cell and now we're gonna actually start doing some work and",
    "start": "1870619",
    "end": "1875869"
  },
  {
    "text": "actually while that's running I'm going to go back and they should have opened up the dashboard so we can see the",
    "start": "1875869",
    "end": "1880999"
  },
  {
    "text": "workers so the horizontal lines here are the different workers and now it's",
    "start": "1880999",
    "end": "1886369"
  },
  {
    "text": "adapting it's saying hey I need some more workers this is a big job so every one of those horizontal lines on that",
    "start": "1886369",
    "end": "1891459"
  },
  {
    "text": "upper right plot here is actually one of those CPUs reading frames are taking the",
    "start": "1891459",
    "end": "1898849"
  },
  {
    "text": "take getting a chunk of data so each the worker goes and gets a chunk of data and computes them the maximum for that chunk",
    "start": "1898849",
    "end": "1904940"
  },
  {
    "text": "and then it's aggregating it back together with the rest of the chunks and then putting it back together for the user",
    "start": "1904940",
    "end": "1910369"
  },
  {
    "text": "now all the user did was say hey give me the mean or give me the maximum water",
    "start": "1910369",
    "end": "1915589"
  },
  {
    "text": "level and desk and x-ray handle all the rest of the mat you know all the rest of the work so this is stuff you used to",
    "start": "1915589",
    "end": "1921409"
  },
  {
    "text": "have to do you know explicitly and so so we got this result back it took 43",
    "start": "1921409",
    "end": "1928759"
  },
  {
    "text": "seconds to crunch 50 gigs of data it would have taken you know 60 times",
    "start": "1928759",
    "end": "1934519"
  },
  {
    "text": "longer if we did that with a single core and and it doesn't matter on the cloud right it doesn't matter whether you use a blunt you can use one core for 60",
    "start": "1934519",
    "end": "1940700"
  },
  {
    "text": "minutes you can use 60 course for a minute you pay the same alright that's the beauty of the cloud so here I'm just",
    "start": "1940700",
    "end": "1948139"
  },
  {
    "text": "going to load some visualization this PI this package I was talking about I'm just gonna execute all these cells but",
    "start": "1948139",
    "end": "1953809"
  },
  {
    "text": "the magic here is this again this try mesh so I have a bunch of triangles I",
    "start": "1953809",
    "end": "1959749"
  },
  {
    "text": "have some data on a triangular grid I'm going to say try mesh and then I'm gonna say I hey I don't want you to render 9",
    "start": "1959749",
    "end": "1965869"
  },
  {
    "text": "million polygons into my browser that would crash my browser I want you to rasterize the result of those polygons",
    "start": "1965869",
    "end": "1973489"
  },
  {
    "text": "onto a window that I'm gonna specify here oops to be 600 by 400 so that's what happened",
    "start": "1973489",
    "end": "1980929"
  },
  {
    "text": "here with that sing that single those two lines of code I generated not just a plot but an interactive visualization",
    "start": "1980929",
    "end": "1987259"
  },
  {
    "text": "here which I'm going to show you so here's the result here's the maximum water level during Hurricane Ike we see",
    "start": "1987259",
    "end": "1993829"
  },
  {
    "text": "the goat the tides in the Gulf of Maine which we don't really care about right that had nothing to do with Hurricane Ike and we see this little blob down",
    "start": "1993829",
    "end": "1999229"
  },
  {
    "text": "here that we can't they tell what it is something happened down there so let's zoom in this is the again the magic of pi vis so I'm going",
    "start": "1999229",
    "end": "2006580"
  },
  {
    "text": "to zoom in here and when i zoom in you're going to see the original grid and now on the back end python is rerender again delivering back the",
    "start": "2006580",
    "end": "2013149"
  },
  {
    "text": "higher resolution let's do it again this is a really detailed grid I'm gonna zoom",
    "start": "2013149",
    "end": "2018700"
  },
  {
    "text": "in again it's going to re-render again and now you see the full resolution this is awesome we couldn't even render these models in",
    "start": "2018700",
    "end": "2024309"
  },
  {
    "text": "the browser before and now we've got a full we've got this tool where we can do all of our analysis and yeah you know we",
    "start": "2024309",
    "end": "2030669"
  },
  {
    "text": "can do this scalable data proximate analysis and we can visualize the results interactively we really can't",
    "start": "2030669",
    "end": "2035799"
  },
  {
    "text": "sit in the park with that notebook it's amazing so I am going to switch back to",
    "start": "2035799",
    "end": "2042159"
  },
  {
    "text": "the presentation hopefully and just to",
    "start": "2042159",
    "end": "2047909"
  },
  {
    "text": "let's stay here okay I'm going to skip over these because I didn't need them I just want to point out that this is not",
    "start": "2048480",
    "end": "2054398"
  },
  {
    "text": "just for model output as I mentioned the beginning if you feel if you check out pan geo and medium there's a bunch of",
    "start": "2054399",
    "end": "2060099"
  },
  {
    "text": "great blog posts and one of the one of the really nice ones is this one by Scott Henderson who is working on that",
    "start": "2060099",
    "end": "2067270"
  },
  {
    "text": "and on that NASA access grant and with AWS funding and he he's doing Landsat",
    "start": "2067270",
    "end": "2075099"
  },
  {
    "text": "processing with Angie oh okay well you know it can work with any imagery but he's got this really nice blog post",
    "start": "2075099",
    "end": "2081490"
  },
  {
    "text": "about about doing this work and this is just one image from his blog post showing a Landsat this sort of the hello",
    "start": "2081490",
    "end": "2088810"
  },
  {
    "text": "world NDVI calculation but the cool thing here is what he says what is special about this example is that the",
    "start": "2088810",
    "end": "2094480"
  },
  {
    "text": "analysis is easily reproduced scalable and interactive hundred gigabytes of Landsat 8 you know basically just using",
    "start": "2094480",
    "end": "2101619"
  },
  {
    "text": "the data right from s3 not using any fancy tools just using Python to crank",
    "start": "2101619",
    "end": "2108040"
  },
  {
    "text": "on this data and do what you could do in Google Earth engine but in a completely cloud agnostic and open way no copies of",
    "start": "2108040",
    "end": "2114250"
  },
  {
    "text": "the data were needed and it's not just",
    "start": "2114250",
    "end": "2120490"
  },
  {
    "text": "for Geoscience data actually we might have to change our title slide you know there's people using it for oops there's people using it for neuro data",
    "start": "2120490",
    "end": "2128230"
  },
  {
    "text": "and neuroscience data were you and it's not just for big data this is a",
    "start": "2128230",
    "end": "2135030"
  },
  {
    "text": "machine learning class that we actually did it USGS sponsored by our community for data integration where we had these two",
    "start": "2135030",
    "end": "2140820"
  },
  {
    "text": "training workshops you it wouldn't have mattered how many students we had because we just scaled up with Jupiter hub and we could have every all the data",
    "start": "2140820",
    "end": "2148470"
  },
  {
    "text": "and the training was on the cloud and so they could just use their notebooks they didn't have to try you know spend the",
    "start": "2148470",
    "end": "2154230"
  },
  {
    "text": "first half of the first morning trying to get everything installed so just a",
    "start": "2154230",
    "end": "2159600"
  },
  {
    "text": "little note about how we deploy Pangea on AWS it is as I mentioned on kubernetes on all the clouds but on on",
    "start": "2159600",
    "end": "2167190"
  },
  {
    "text": "this we're using eks and there's three classes of node pools for you the geeks",
    "start": "2167190",
    "end": "2172500"
  },
  {
    "text": "in the crowd this is the core pool which runs stupider hub there's and then there's an auto scaling pool to handle",
    "start": "2172500",
    "end": "2178350"
  },
  {
    "text": "like the number of users that you know for each notebook and then there's this task pool of workers that I was that I",
    "start": "2178350",
    "end": "2185370"
  },
  {
    "text": "was talking about and when you know when you saw those workers get added those are in a pool that it can be preempted preemptable so they're on spot instances",
    "start": "2185370",
    "end": "2192450"
  },
  {
    "text": "because if we lose those workers just another worker will pick up and keep you know they'll just keep going so it's",
    "start": "2192450",
    "end": "2199920"
  },
  {
    "text": "installed with a helmet art there's full instructions at pan geo IO and as I mentioned repo to docker is used to make",
    "start": "2199920",
    "end": "2207450"
  },
  {
    "text": "it really easy to for people to take customise their environment and create a doctor container that's appropriate for",
    "start": "2207450",
    "end": "2213030"
  },
  {
    "text": "their discipline okay so overcoming",
    "start": "2213030",
    "end": "2218160"
  },
  {
    "text": "barriers to adoption there's still some barriers a lot of people when you talk",
    "start": "2218160",
    "end": "2224430"
  },
  {
    "text": "to about the stuff they're concerned about cost and in fact you know at our institution at USGS and at our sister",
    "start": "2224430",
    "end": "2231420"
  },
  {
    "text": "academic institution in Woods Hole they have a program where HPC is basically free for research and and but",
    "start": "2231420",
    "end": "2240000"
  },
  {
    "text": "yet the cloud is you pay full price so you know trying to get researchers to",
    "start": "2240000",
    "end": "2245460"
  },
  {
    "text": "use the cloud when you have that kind of a model is not - not too encouraging so",
    "start": "2245460",
    "end": "2251730"
  },
  {
    "text": "I'm hoping that institutions will start subsidizing cloud research the same way they subsidize HPC because because",
    "start": "2251730",
    "end": "2258570"
  },
  {
    "text": "there's really there's really not a lot of reason to stay on HPC these days so they might believe anyway you know",
    "start": "2258570",
    "end": "2265980"
  },
  {
    "text": "there's things that poor okay there's things that I think Amazon is doing this that are really",
    "start": "2265980",
    "end": "2271240"
  },
  {
    "text": "helpful these research credits obviously fergie letting people experiment and see what this would look like for their",
    "start": "2271240",
    "end": "2276880"
  },
  {
    "text": "workflows and waving egress charges for research this various sort of approaches to that that really help because",
    "start": "2276880",
    "end": "2282760"
  },
  {
    "text": "sometimes researchers want to work on a big data set on Google Cloud say and on Amazon Cloud and combine the results you",
    "start": "2282760",
    "end": "2289330"
  },
  {
    "text": "know this egress happening there the new skills that are required or a challenge",
    "start": "2289330",
    "end": "2295570"
  },
  {
    "text": "I think these ATM be us I went to like a one day training workshop in Boston on containerization that was super helpful you know obviously summits like this are",
    "start": "2295570",
    "end": "2302110"
  },
  {
    "text": "super super helpful about you know you don't see too many research scientists here probably right we've got to get the",
    "start": "2302110",
    "end": "2307630"
  },
  {
    "text": "word out to them that this is a major major will have major short-term impact on their ability to do science these",
    "start": "2307630",
    "end": "2315130"
  },
  {
    "text": "hackathons they're held like science hackathons ever been really useful and I think these sort of institutional roadshows can be really helpful where",
    "start": "2315130",
    "end": "2320980"
  },
  {
    "text": "someone who knows about this stuff like I could go into some university give a talk about how this is important you",
    "start": "2320980",
    "end": "2326770"
  },
  {
    "text": "know and what impacts it I could meet with their scientists they might listen to me because I'm a scientist and you know and we might actually get them on",
    "start": "2326770",
    "end": "2332500"
  },
  {
    "text": "board so and then the data formats and you know people are worried are these",
    "start": "2332500",
    "end": "2338800"
  },
  {
    "text": "things that have changed how stable is this is our thing and so I think that'll just happen that'll be that'll naturally",
    "start": "2338800",
    "end": "2344890"
  },
  {
    "text": "the community will come together I think and you know by if we publish our benchmarks on these things and we blog and we present eventually it'll it'll",
    "start": "2344890",
    "end": "2352660"
  },
  {
    "text": "it'll happen faster so finally Panchito is a movement come",
    "start": "2352660",
    "end": "2359410"
  },
  {
    "text": "visit us at Pangaea at i/o read those medium.com articles you can chat with us on Gitter",
    "start": "2359410",
    "end": "2365830"
  },
  {
    "text": "and please come help and join us on github thank you very much",
    "start": "2365830",
    "end": "2370960"
  },
  {
    "text": "[Applause]",
    "start": "2370960",
    "end": "2377759"
  },
  {
    "text": "yeah I think we have some time for Q&A",
    "start": "2377759",
    "end": "2382469"
  },
  {
    "text": "thank you yeah so I was just curious you show the",
    "start": "2393689",
    "end": "2399729"
  },
  {
    "text": "the increment to the size of the cmf data which is a critical data set for",
    "start": "2399729",
    "end": "2405669"
  },
  {
    "text": "you know you know like in an app tation so 150 petabytes is what you",
    "start": "2405669",
    "end": "2413799"
  },
  {
    "text": "I guess the community says respecting the statistics to be it's been do you",
    "start": "2413799",
    "end": "2419249"
  },
  {
    "text": "planning to do anything to enable access to their data and make it more accessible to the broader community yeah",
    "start": "2419249",
    "end": "2425079"
  },
  {
    "text": "it's absolutely there's a there is a lot of I actually didn't talk about the the",
    "start": "2425079",
    "end": "2431319"
  },
  {
    "text": "climate folks are involved with Pangaea but there is a movement to move some of the sea mix cement six data to the cloud",
    "start": "2431319",
    "end": "2438729"
  },
  {
    "text": "and Tsar format but like the sustainability program would be you know really exciting to get some of that on",
    "start": "2438729",
    "end": "2445539"
  },
  {
    "text": "there and you know I guess you know you're not just providing this space but you're providing some of these other these other parts of the environment",
    "start": "2445539",
    "end": "2452679"
  },
  {
    "text": "they can really help researchers that I think I think that's that'll be huge I think what's you know you don't have to",
    "start": "2452679",
    "end": "2457900"
  },
  {
    "text": "move it all there for people to see the value and then maybe when they see the value then we move it all there you know",
    "start": "2457900",
    "end": "2464099"
  },
  {
    "text": "right thank you so I I would like to see if anybody have any questions either for rich for myself",
    "start": "2464099",
    "end": "2471989"
  },
  {
    "text": "please feel free to maybe raise your hand and we'll give you the microphone",
    "start": "2471989",
    "end": "2478859"
  },
  {
    "text": "hello I'm away from you no stove Merlin I work with the department geography",
    "start": "2488490",
    "end": "2493890"
  },
  {
    "text": "Sciences we we do a lot of NASA data processing so I guess my question",
    "start": "2493890",
    "end": "2499710"
  },
  {
    "text": "is for you a map so as you saw the scale of data is is pretty high it can go into",
    "start": "2499710",
    "end": "2507660"
  },
  {
    "text": "three or four events come in coming years what AWS would be hosting all of that on",
    "start": "2507660",
    "end": "2513420"
  },
  {
    "text": "s3 why would it be on on a deep layer or",
    "start": "2513420",
    "end": "2518640"
  },
  {
    "text": "someplace we are way to access it because that's a realistic way a",
    "start": "2518640",
    "end": "2524040"
  },
  {
    "text": "scenario we are looking at and right now I know nASA has been moving the data",
    "start": "2524040",
    "end": "2529140"
  },
  {
    "text": "sets to it has like so I'm trying to",
    "start": "2529140",
    "end": "2535470"
  },
  {
    "text": "understand where does the data actually lie in a Tobias environment is it on s3 or is it on deep pleasure yeah so I'm",
    "start": "2535470",
    "end": "2545670"
  },
  {
    "text": "not exactly the best person to answer that and wonder if Joe flashier is on the odd in the audience actually I can",
    "start": "2545670",
    "end": "2551730"
  },
  {
    "text": "check that hands question you get yeah my solutions like it said so s3 has unlimited size force data storage",
    "start": "2551730",
    "end": "2558839"
  },
  {
    "text": "literally we can host any amount of the Iranians now Glaser is a subset of s s3",
    "start": "2558839",
    "end": "2564540"
  },
  {
    "text": "so we have s 3 standard where you have the frequent access that's a different pricing model and different speed of",
    "start": "2564540",
    "end": "2570900"
  },
  {
    "text": "retrieval then we have the s3 infrequent access so it depends on how they are accessing that data they can move in in",
    "start": "2570900",
    "end": "2577530"
  },
  {
    "text": "between tools and then a third one is a glacier are we actually have typically sure which makes it like four different storage classes so it depends on the",
    "start": "2577530",
    "end": "2584820"
  },
  {
    "text": "access of the data and the design of the architecture they can move those data in between those and within those that",
    "start": "2584820",
    "end": "2590490"
  },
  {
    "text": "different pricing models and different speed of retriever so it's a string I mean I can't say I",
    "start": "2590490",
    "end": "2601680"
  },
  {
    "text": "don't Walken is there I'm just telling you that the power of Astrakhan host infinite amount of data so I",
    "start": "2601680",
    "end": "2610220"
  },
  {
    "text": "I can it yeah I can't add that USGS is",
    "start": "2611609",
    "end": "2620599"
  },
  {
    "text": "working on moving the the data to the cloud as you know their own activity and",
    "start": "2620599",
    "end": "2626130"
  },
  {
    "text": "working with us on that I don't know exactly what the timely timeline is but",
    "start": "2626130",
    "end": "2632009"
  },
  {
    "text": "we can put you in touch with the people if you're interested specifically about the planets history",
    "start": "2632009",
    "end": "2637229"
  },
  {
    "text": "thank you do we have another question",
    "start": "2637229",
    "end": "2647059"
  },
  {
    "text": "okay so and a nice session enriched",
    "start": "2647059",
    "end": "2655200"
  },
  {
    "text": "really nice presentation couple of quick questions one is how do you search for",
    "start": "2655200",
    "end": "2662549"
  },
  {
    "text": "data and Panji oh I assume in this case you knew exactly what was there on the",
    "start": "2662549",
    "end": "2668519"
  },
  {
    "text": "s3 does the catalog have to be changed because the catalog is designed for",
    "start": "2668519",
    "end": "2673650"
  },
  {
    "text": "files and now you are looking at you know Tsar is different objects and the",
    "start": "2673650",
    "end": "2680670"
  },
  {
    "text": "second question is how do you do batch processing i I know you mentioned batch processing a lot of people are still",
    "start": "2680670",
    "end": "2687869"
  },
  {
    "text": "used to processing files in the batch mode does Pangaea support that yeah so",
    "start": "2687869",
    "end": "2694410"
  },
  {
    "text": "the first part of the question there's definitely need for a catalog",
    "start": "2694410",
    "end": "2699469"
  },
  {
    "text": "you know I I think you know depending on who you ask and pans you'd probably get",
    "start": "2699469",
    "end": "2705059"
  },
  {
    "text": "a different answer but I think that you know if you go to something like data.gov you know which we might hope",
    "start": "2705059",
    "end": "2711690"
  },
  {
    "text": "would be the place you can find all the data you'll find all these data services and you'll find some you know URLs for",
    "start": "2711690",
    "end": "2717209"
  },
  {
    "text": "different sites I mean why not why could you know that could easily return a URL for about you know an",
    "start": "2717209",
    "end": "2724019"
  },
  {
    "text": "object like as our file right is our file is our data our data set and so",
    "start": "2724019",
    "end": "2729900"
  },
  {
    "text": "actually we did that a little experiment I worked with Andrew Pulaski from element 84 last year at the Developers",
    "start": "2729900",
    "end": "2737549"
  },
  {
    "text": "Conference we actually and and actually the whole system it's just that's all you have to do it's just a different",
    "start": "2737549",
    "end": "2742799"
  },
  {
    "text": "type you know it's just so you can certainly all the search capabilities that we currently have you just have to know",
    "start": "2742799",
    "end": "2748610"
  },
  {
    "text": "like when you find this thing you know in the metadata you have to identify this with enough information that you",
    "start": "2748610",
    "end": "2753740"
  },
  {
    "text": "know what to do with it you know when you load it so you know you have to be able to represent that as some you'd",
    "start": "2753740",
    "end": "2759650"
  },
  {
    "text": "like to be able to represent it as something you can load as a netcdf CF you know data object and but then you",
    "start": "2759650",
    "end": "2766070"
  },
  {
    "text": "have to identify whether it's and you know as your or Google or Amazon or whatever but but really I don't think it",
    "start": "2766070",
    "end": "2773090"
  },
  {
    "text": "presents any particular challenges but in pancha hood specifically who kind of looked at stack a little bit which is",
    "start": "2773090",
    "end": "2778490"
  },
  {
    "text": "stack is being used in the remote sensing community a lot there's and then there's an intake intake which is sort",
    "start": "2778490",
    "end": "2784520"
  },
  {
    "text": "of a Python centric thing there's a stack to intake catalog things so that's one way you can find data you know like",
    "start": "2784520",
    "end": "2790190"
  },
  {
    "text": "Scott Henderson's demo if you go look at that it's using this stack intake connection to actually locate all the",
    "start": "2790190",
    "end": "2795410"
  },
  {
    "text": "scenes you know that are needed so that's all working nicely what's not quite working perfectly is cataloging of",
    "start": "2795410",
    "end": "2803780"
  },
  {
    "text": "like the ocean model output and all the climate data and stuff but we'll get there Oh",
    "start": "2803780",
    "end": "2810160"
  },
  {
    "text": "in the second what was the second part Oh the batch of the batch processing yeah I mean so in this is just Python",
    "start": "2812119",
    "end": "2818840"
  },
  {
    "text": "you know so you can you can bet you can batch Python and you know it's there's",
    "start": "2818840",
    "end": "2826430"
  },
  {
    "text": "no particular issue there yeah but when",
    "start": "2826430",
    "end": "2838670"
  },
  {
    "text": "you're doing a batch processing and you're trying to scale it out then is",
    "start": "2838670",
    "end": "2843770"
  },
  {
    "text": "the responsibility back on the programmer who's creating the Python code or how do you do that or not no I",
    "start": "2843770",
    "end": "2849770"
  },
  {
    "text": "mean it's I mean that des can handle it in just the exact same way okay yeah",
    "start": "2849770",
    "end": "2857170"
  },
  {
    "text": "Amiata question thank you rich hunting",
    "start": "2859890",
    "end": "2865769"
  },
  {
    "text": "piranha [Applause]",
    "start": "2865769",
    "end": "2869820"
  }
]
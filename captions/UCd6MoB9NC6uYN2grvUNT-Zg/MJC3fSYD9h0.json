[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "all right welcome everybody um let's get started the session is on getting",
    "start": "520",
    "end": "5920"
  },
  {
    "text": "started with realtime analytics um I'm Rahul baa I'm a solution architect with",
    "start": "5920",
    "end": "11759"
  },
  {
    "text": "Amazon web services and joining me with as today is kander I will have kab introduce himself uh I'm Kap sha I am",
    "start": "11759",
    "end": "19359"
  },
  {
    "text": "engineering manager for data platform and game Services team at G International thank you ker so with that",
    "start": "19359",
    "end": "27160"
  },
  {
    "start": "25000",
    "end": "55000"
  },
  {
    "text": "let's just do a quick run through to the agenda today we're going to take a macro level of the two main streams within",
    "start": "27160",
    "end": "33559"
  },
  {
    "text": "data realtime analytics we look both at the data ingestion and the data processing later after that we'll have",
    "start": "33559",
    "end": "40960"
  },
  {
    "text": "kandar walk through green International and their architecture on a realtime analytics on AWS he will also share some",
    "start": "40960",
    "end": "48239"
  },
  {
    "text": "of the lessons he they learned while building the architecture on AWS and key some of the key takeaways as a part of",
    "start": "48239",
    "end": "53680"
  },
  {
    "text": "this talk so if you look at the two macro level of realtime analytics we described",
    "start": "53680",
    "end": "60640"
  },
  {
    "start": "55000",
    "end": "185000"
  },
  {
    "text": "um the first being realtime inje of data or collection of data and second the processing of data both these two macro",
    "start": "60640",
    "end": "68200"
  },
  {
    "text": "levels I have quite some key semantics in there which are parallel to each other if you look at it on the",
    "start": "68200",
    "end": "74280"
  },
  {
    "text": "collection side why you need a collection system which can scale to collect data from thousands or hundreds",
    "start": "74280",
    "end": "79600"
  },
  {
    "text": "of thousands of sources but on the same processing side you need the processing",
    "start": "79600",
    "end": "84680"
  },
  {
    "text": "system to be able to scale up to keep up with those events as they're flowing into your collection system not only",
    "start": "84680",
    "end": "90400"
  },
  {
    "text": "your collection system needs to provide you a durable durability of data so once you write in there you are certain that",
    "start": "90400",
    "end": "96000"
  },
  {
    "text": "data is going to be available for you to process on the other side your",
    "start": "96000",
    "end": "101200"
  },
  {
    "text": "processing system needs to be able to able to recover from failures in case they need to be able to do a checkpoint",
    "start": "101200",
    "end": "107000"
  },
  {
    "text": "so so to say that you have processed till this date or this um this records",
    "start": "107000",
    "end": "112159"
  },
  {
    "text": "in case any failure happens you can resume from there on without any hardship on your part they both need to",
    "start": "112159",
    "end": "118320"
  },
  {
    "text": "support the concept of elasticity that as you know that your data flow rate or data processing rate is not going to be",
    "start": "118320",
    "end": "124240"
  },
  {
    "text": "the same throughout the whole time it's going to scale up and down as the number of users for example in a website the",
    "start": "124240",
    "end": "129640"
  },
  {
    "text": "traffic on your website is never going to be the same throughout the 24 hours it's going to change depending on certain lot of factors and you need to",
    "start": "129640",
    "end": "135680"
  },
  {
    "text": "be have a system which can Scale based on the patterns of the traffic your website or your collection system is",
    "start": "135680",
    "end": "140800"
  },
  {
    "text": "facing into and the lastly being there's a concept of a data bus as architecture where what you have is your data source",
    "start": "140800",
    "end": "147920"
  },
  {
    "text": "producers do write data into a single system at once but you can have multiple streams of data processing being",
    "start": "147920",
    "end": "154440"
  },
  {
    "text": "happening on the other side the multiprocessing could be for example you're doing a realtime monitoring using",
    "start": "154440",
    "end": "160000"
  },
  {
    "text": "simple metrics could be that you're doing a machine learning a deep learning with that data set you're writing that",
    "start": "160000",
    "end": "165200"
  },
  {
    "text": "to some SQL store for doing some operational monitoring and EDC the idea being that once you write the data you wouldn't have to replicate it to",
    "start": "165200",
    "end": "171480"
  },
  {
    "text": "multiple places to do the processing for different paths or different ways",
    "start": "171480",
    "end": "177239"
  },
  {
    "text": "mechanisms so with that those those two processes describe those two streams describe within a real time analytics",
    "start": "177239",
    "end": "183040"
  },
  {
    "text": "let's look at the pattern of data inje first So within a data collection imagine that you want to build a website",
    "start": "183040",
    "end": "189200"
  },
  {
    "text": "which just shows you from some stream of Records top Time Records example being let's say that from a website you want",
    "start": "189200",
    "end": "195440"
  },
  {
    "text": "to know the top 10 referers of to your website people who are coming to website and how they're being referred to your website on a very simple design what you",
    "start": "195440",
    "end": "202879"
  },
  {
    "text": "could do is you could build basically a web server the webs is collecting all the clickstream logs does all the processing and finds the top 10 and",
    "start": "202879",
    "end": "209239"
  },
  {
    "text": "displays it back in a graph or something of that sort it works for a small you know if your website has a small",
    "start": "209239",
    "end": "214760"
  },
  {
    "text": "thousands of few users maybe it could work but what if it grows out to hundreds of thousands of users or millions of user at that point in time",
    "start": "214760",
    "end": "223040"
  },
  {
    "start": "222000",
    "end": "302000"
  },
  {
    "text": "you could look into something like partitioning your data set so what you do is you build another Fleet of servers",
    "start": "223040",
    "end": "228360"
  },
  {
    "text": "before your web servers and what these boxes the orange boxes are doing here they are collecting your data from your",
    "start": "228360",
    "end": "234959"
  },
  {
    "text": "producers they're doing a computation on top of it to figure out how many records or which are the top producers or two",
    "start": "234959",
    "end": "240959"
  },
  {
    "text": "top referers in there and sending them back to your website or your web server your web server at the same time is now",
    "start": "240959",
    "end": "247519"
  },
  {
    "text": "taking the records Computing the from all the records coming in from different boxes Computing the local or Global top",
    "start": "247519",
    "end": "254079"
  },
  {
    "text": "10 and displaying it back to your users so now each of these boxes is doing a computation so your work is a little bit",
    "start": "254079",
    "end": "259880"
  },
  {
    "text": "distributed yet there a problem remains in there that if you look at the lines colors of",
    "start": "259880",
    "end": "265680"
  },
  {
    "text": "the lines which are going from your data sources to the boxes they are random in color so each of these boxes don't know",
    "start": "265680",
    "end": "271639"
  },
  {
    "text": "which group of Records is getting from whether the refers are coming from Google from Amazon from somewhere else",
    "start": "271639",
    "end": "276800"
  },
  {
    "text": "they have no idea about who's the refer to these websites so they cannot do a computation of top 10 endly what they",
    "start": "276800",
    "end": "282400"
  },
  {
    "text": "can do is they can do approximation of something saying that based on million of referers here are one record per",
    "start": "282400",
    "end": "288160"
  },
  {
    "text": "referer and hey web server can you compute the top Global top 10 now which still means that your website has to",
    "start": "288160",
    "end": "294039"
  },
  {
    "text": "deal with some kind of computation which you shouldn't have to in the first place so how do you really",
    "start": "294039",
    "end": "299320"
  },
  {
    "text": "solve that problem Well turns out what you could do is if you had in between a",
    "start": "299320",
    "end": "304680"
  },
  {
    "start": "302000",
    "end": "363000"
  },
  {
    "text": "data broker service and imagine what the data broker service does is it ingests the data at scale and on the output it",
    "start": "304680",
    "end": "311960"
  },
  {
    "text": "sorts the data based on some group or based on some partition and now each of your orange boxes can do a computation",
    "start": "311960",
    "end": "318880"
  },
  {
    "text": "so to compute top 10 all of these orange boxes have to do is they have to send only 10 records back to your web server",
    "start": "318880",
    "end": "325759"
  },
  {
    "text": "and in this case for example being three boxes your web server needs to process only 30 records which is better than",
    "start": "325759",
    "end": "331280"
  },
  {
    "text": "solving a 3 million record problem or 100 of millions of Records problem so now in this architecture your data is",
    "start": "331280",
    "end": "338240"
  },
  {
    "text": "coming ingested there's a central data broker which is basically ingesting the data providing a sort of buffer within",
    "start": "338240",
    "end": "344120"
  },
  {
    "text": "that buffer it's sorting the data so your processing boxes can take the data set in a certain order or by a certain",
    "start": "344120",
    "end": "349520"
  },
  {
    "text": "group do the computation and send the data set back to the web server so now your web server is basically just doing",
    "start": "349520",
    "end": "355639"
  },
  {
    "text": "the idea behind what it is doing is to display the data records out of 30 displaying the top Dr and Records back to",
    "start": "355639",
    "end": "361560"
  },
  {
    "text": "users it turns out that Central blue box is what Amazon Kinesis is so Amazon",
    "start": "361560",
    "end": "367680"
  },
  {
    "start": "363000",
    "end": "486000"
  },
  {
    "text": "Kinesis is basically a service a managed service which can allow you to ingest data sources or data streams in real",
    "start": "367680",
    "end": "373720"
  },
  {
    "text": "time from hundreds of thousands of sources and not only that it can allow you to stream data up to terabytes per",
    "start": "373720",
    "end": "379960"
  },
  {
    "text": "day so you can inest that much of data sets within an Amazon Kinesis from hundreds of thousands of sources but it",
    "start": "379960",
    "end": "387120"
  },
  {
    "text": "also allows you data to be processed in the manner we spoke about earlier and logically",
    "start": "387120",
    "end": "392240"
  },
  {
    "text": "speaking a named object within Kinesis is a stream a stream is something in",
    "start": "392240",
    "end": "397840"
  },
  {
    "text": "which you put data onto a stream is a collection of something called Shard A",
    "start": "397840",
    "end": "402960"
  },
  {
    "text": "Shard being a basic unit of capacity within a stream um so as your stream as number of sharts within a stream grows",
    "start": "402960",
    "end": "409639"
  },
  {
    "text": "your stream has more capacity to read data or to process data the one thing which determines that",
    "start": "409639",
    "end": "415840"
  },
  {
    "text": "where the records goes within each Shard for the given stream is something a partition key think of partition key as",
    "start": "415840",
    "end": "421639"
  },
  {
    "text": "something a way you can distribute your data across multiple sharts so if you have for example let's say 10 charts",
    "start": "421639",
    "end": "427199"
  },
  {
    "text": "within a stream you could say that my partition key going be number be 1 to 10 so which means the number partition key",
    "start": "427199",
    "end": "433240"
  },
  {
    "text": "one is going to let's say uh Shard one and the partition key number 10 is going to sh 10 it's is just a simple",
    "start": "433240",
    "end": "438800"
  },
  {
    "text": "illustrative example but the idea being a partition key is something natural which can help you distribute your data",
    "start": "438800",
    "end": "444280"
  },
  {
    "text": "across multiple charts in a stream then you have something called a record which is basically like think of",
    "start": "444280",
    "end": "450639"
  },
  {
    "text": "something like a clickstream log a tweet these are all a single record which goes within a stream and whenever you put",
    "start": "450639",
    "end": "456759"
  },
  {
    "text": "data within a stream what Kinesis gives you back is something called a sequence number and that sequence number which is",
    "start": "456759",
    "end": "463479"
  },
  {
    "text": "generally increasing within a given partition key is that what you can use for doing checkpointing for doing Replay",
    "start": "463479",
    "end": "470080"
  },
  {
    "text": "for doing uh failure recovery and Etc because that's a number which is increasing so you can create a simple",
    "start": "470080",
    "end": "475159"
  },
  {
    "text": "checkpoint saying that I have processed my data till sequence number 10 so next time if your process fails or anything",
    "start": "475159",
    "end": "481080"
  },
  {
    "text": "happens you can start resuming your process from sequence number 10 onwards what Kinesis also does is once",
    "start": "481080",
    "end": "488159"
  },
  {
    "start": "486000",
    "end": "554000"
  },
  {
    "text": "you do uput data into Kinesis it stores or it gives you ability to read your data for a period of up to 24 hours and",
    "start": "488159",
    "end": "495919"
  },
  {
    "text": "you can have multiple processes read the same data set over and over again so you could build a multiple processing",
    "start": "495919",
    "end": "501599"
  },
  {
    "text": "platform so once you put data into Kinesis it's available for you to read up to 24 hours and that means now you",
    "start": "501599",
    "end": "508039"
  },
  {
    "text": "can have multiple readers reading out of it for example doing work like data archiving into S3 um which is our Object",
    "start": "508039",
    "end": "514479"
  },
  {
    "text": "Store data archive sorry Matrix realtime Matrix into Dynamo DB which is a nosql",
    "start": "514479",
    "end": "520039"
  },
  {
    "text": "um no SQL store or they can do um operational metric back into red shift",
    "start": "520039",
    "end": "526959"
  },
  {
    "text": "uh which is our data warehouse a pabit scale data warehouse or you can even write uh something like EMR to basically",
    "start": "526959",
    "end": "532839"
  },
  {
    "text": "do machine learning on top of the data set being return in S3 so with Kinesis the idea of central data bus base",
    "start": "532839",
    "end": "539440"
  },
  {
    "text": "basically becomes as a part of a connection collection process of data once you write data into Kinesis you",
    "start": "539440",
    "end": "544519"
  },
  {
    "text": "could have multiple data you could have multiple processing applications which can take the data and process it using",
    "start": "544519",
    "end": "550000"
  },
  {
    "text": "multiple paths and the way KES allows you to do it is by something as we mentioned something called",
    "start": "550000",
    "end": "556440"
  },
  {
    "start": "554000",
    "end": "656000"
  },
  {
    "text": "Shard a stream being a named object and A Shard being a unit of capacity what",
    "start": "556440",
    "end": "562120"
  },
  {
    "text": "each Shard gives you each CH gives you the ability to write data at the rate of 1 MV per second or thousand transaction",
    "start": "562120",
    "end": "569399"
  },
  {
    "text": "per second which means that either of which comes first that's the limit of A Shard is so you can write up to th",
    "start": "569399",
    "end": "575600"
  },
  {
    "text": "transactions or thousand records or you can write in collection up to a megabyte per second on the read side what it",
    "start": "575600",
    "end": "582800"
  },
  {
    "text": "gives you ability is to read at 2 megabytes per second or five transactions per",
    "start": "582800",
    "end": "588959"
  },
  {
    "text": "second what it means that on a single chart you could have up to five processors reading data out of that",
    "start": "588959",
    "end": "595279"
  },
  {
    "text": "chard and each reading the data at the speed of um what 2 megabytes up to up to",
    "start": "595279",
    "end": "601000"
  },
  {
    "text": "2 megabytes in uh in total and how you scale up and down your Shard is the",
    "start": "601000",
    "end": "606720"
  },
  {
    "text": "elastic part of the ginesis is by two AP operations called merge Shard and a split Shard the moment you call a merge",
    "start": "606720",
    "end": "613320"
  },
  {
    "text": "Shard for example a pair of shards become one Single Shard and since you're charged by Shard hour and your capacity",
    "start": "613320",
    "end": "620040"
  },
  {
    "text": "also is is determined by The Shard you elastic Scale based on the number of shots in a given stream if your data is",
    "start": "620040",
    "end": "626680"
  },
  {
    "text": "going to grow you can call U split chart which is going to give you from one parent chart it's going to give you two",
    "start": "626680",
    "end": "632240"
  },
  {
    "text": "child sharts and now you have doubled the capacity of a single chart given before the point in time",
    "start": "632240",
    "end": "637680"
  },
  {
    "text": "sorry and data is again as I mentioned before is available for you to process uh up to 24 hours once you do a put",
    "start": "637680",
    "end": "644480"
  },
  {
    "text": "record back into kesis and now you can basically use anything to do that data within the 24-hour window which could be",
    "start": "644480",
    "end": "651360"
  },
  {
    "text": "archiving it processing it or any of that pattern so imagine that now you have two",
    "start": "651360",
    "end": "659839"
  },
  {
    "text": "producers in your applications each of these two producers are producing records at 2 KB of size but at 500",
    "start": "659839",
    "end": "666880"
  },
  {
    "text": "transaction per second and if you want to stream that data set into Kinesis so how you going to Res how you going to",
    "start": "666880",
    "end": "672880"
  },
  {
    "text": "size the number of shots in your Kinesis Stream So it turns out since each stream or each chart gives you ability to write",
    "start": "672880",
    "end": "678839"
  },
  {
    "text": "data at 1 Megabyte per second and you have roughly two producers here both of them producing at the rate of 1",
    "start": "678839",
    "end": "685639"
  },
  {
    "text": "megabytes per second cumulative of 2 megabyte per second so you can have two sharts basically here and at the other",
    "start": "685639",
    "end": "692040"
  },
  {
    "text": "reading s is going to give you ability for have two applications which can read data out of this because you're putting",
    "start": "692040",
    "end": "697320"
  },
  {
    "text": "2 megabyte per second total in the Stream two charts are there and each charts give you 2 megabyte per second of",
    "start": "697320",
    "end": "702800"
  },
  {
    "text": "read so total of 4 megabytes and each application has to read at least 2 megabytes per second which leads to 4",
    "start": "702800",
    "end": "708680"
  },
  {
    "text": "megabytes per second as a number in there so in this case two charts are enough for you to start processing but",
    "start": "708680",
    "end": "714800"
  },
  {
    "text": "what if you need a third application to read now that idea being that on the other side your get is remaining the",
    "start": "714800",
    "end": "721399"
  },
  {
    "text": "same your read is remaining the same sorry your write is remaining the same but your read is increasing to have one more application now in that case what",
    "start": "721399",
    "end": "728000"
  },
  {
    "text": "you could do is add a third Shard simply so you the moment you add another shard in there now your read capacity has",
    "start": "728000",
    "end": "733399"
  },
  {
    "text": "doubled so which means that while your inje is still maintained at 2 megabyte per second your reading now can be at 6",
    "start": "733399",
    "end": "740519"
  },
  {
    "text": "megabytes in total so which means the three application totally can read 2 megabytes each so it can they all three",
    "start": "740519",
    "end": "746240"
  },
  {
    "text": "can process the entire data set which you have been put into Kinesis stream and that's the pattern based on which you can uh elastically scale a Kinesis",
    "start": "746240",
    "end": "755480"
  },
  {
    "text": "Stream So to recap we talked about on the data inje side that how Kinesis helps you move from a batch based",
    "start": "755720",
    "end": "762199"
  },
  {
    "start": "756000",
    "end": "802000"
  },
  {
    "text": "processing into continuous inje of data not only that how it can elastically scale up or down based on your workload",
    "start": "762199",
    "end": "768639"
  },
  {
    "text": "or based on your inje patterns that workers can replay the data up to 24 hours once you do a single record it the",
    "start": "768639",
    "end": "774839"
  },
  {
    "text": "record is available for to processed up to 24 hours and you can scale up to gigaby seconds or terabytes per day",
    "start": "774839",
    "end": "781240"
  },
  {
    "text": "without losing any durability because what Kinesis does is automatically writes data into multiple availability zones once it do uh uh once you do a put",
    "start": "781240",
    "end": "788519"
  },
  {
    "text": "record within Kinesis and finally you can run multiple Kinesis applications because the way it is designed that each",
    "start": "788519",
    "end": "794000"
  },
  {
    "text": "shart is given to designed to Fan out your reads so you can have multiple applications processing the data set out",
    "start": "794000",
    "end": "799839"
  },
  {
    "text": "of that uh stream now we're going to move on to the data processing side of things that once",
    "start": "799839",
    "end": "805800"
  },
  {
    "start": "802000",
    "end": "820000"
  },
  {
    "text": "we have data being collected in con stream assuming and you have ability to collect data at scale what you want to",
    "start": "805800",
    "end": "811560"
  },
  {
    "text": "really do with this data set because real time actually is a platform it's just not collection you have to figure out something to do with that data set",
    "start": "811560",
    "end": "818240"
  },
  {
    "text": "also uh a very common architecture what we see in general is around data streams is people use different stream",
    "start": "818240",
    "end": "825079"
  },
  {
    "start": "820000",
    "end": "889000"
  },
  {
    "text": "processing systems such as um Kinesis client Library we'll talk about that a moment spark streaming uh apachi apachi",
    "start": "825079",
    "end": "834480"
  },
  {
    "text": "storm they use all of these stream analytics process to basically get realtime counters realtime metrics and",
    "start": "834480",
    "end": "840600"
  },
  {
    "text": "put them into some kind of delivery be it via notification via apis SNS be it bya dashboards alerts or Etc and at the",
    "start": "840600",
    "end": "848399"
  },
  {
    "text": "same time it is quite important that you build a layer which can take data from a stream and archive into something like",
    "start": "848399",
    "end": "855240"
  },
  {
    "text": "S3 for that matter why because eventually what you're going to come to a point where you need to restate",
    "start": "855240",
    "end": "860839"
  },
  {
    "text": "something where something might have failed or something might have gone wrong in your realtime system with having that data archive ability it",
    "start": "860839",
    "end": "866720"
  },
  {
    "text": "gives you the ability for you to restate what was gone wrong wrong or reevaluate your understanding as you understand",
    "start": "866720",
    "end": "871839"
  },
  {
    "text": "your systems more as you as you learn to more about system it gives you the ability for you to restate that purpose",
    "start": "871839",
    "end": "877560"
  },
  {
    "text": "to change with your questions and answers so we're going to talk about all three patterns as we go along both on",
    "start": "877560",
    "end": "884320"
  },
  {
    "text": "real time micro batching and uh batch process so on the real time and micro",
    "start": "884320",
    "end": "890839"
  },
  {
    "start": "889000",
    "end": "940000"
  },
  {
    "text": "batch if you look at it the main distinction being with the real time or the streaming system the idea is that",
    "start": "890839",
    "end": "895959"
  },
  {
    "text": "you are responding to a single event which is happening within your stream um for example let's say if you're a",
    "start": "895959",
    "end": "901519"
  },
  {
    "text": "payment website each every transaction which is coming you it's important for you to you to respond to each every and",
    "start": "901519",
    "end": "908600"
  },
  {
    "text": "every single transaction at that point in time to know that whether transaction is let's say you want to build a fraud monitoring system whether transaction is",
    "start": "908600",
    "end": "915120"
  },
  {
    "text": "fraud or not but on the microbat side the idea is less about being able to respond um to a single event but is more",
    "start": "915120",
    "end": "922800"
  },
  {
    "text": "about being able to respond to a group of events on a small interval the small interval being could be minutes could be",
    "start": "922800",
    "end": "928279"
  },
  {
    "text": "seconds or whatever be the need of or based on that idea there are three different processing systems we're going",
    "start": "928279",
    "end": "933639"
  },
  {
    "text": "to talk about in that context Kinesis client Library spark streaming and Apache",
    "start": "933639",
    "end": "939800"
  },
  {
    "text": "storm so starting with the first one the Kinesis client Library the once you",
    "start": "939800",
    "end": "945959"
  },
  {
    "start": "940000",
    "end": "1040000"
  },
  {
    "text": "write your data into Kinesis to process it as we mentioned before there are multiple things you need to understand of first your application has to scale",
    "start": "945959",
    "end": "952440"
  },
  {
    "text": "up and down as your number of A Shard grows or Shard uh strings you have to be able to recover from failure you have to",
    "start": "952440",
    "end": "958199"
  },
  {
    "text": "deal with checkpoints you have to make sure that each and every record is getting processed with the worker so what KCl does actually is",
    "start": "958199",
    "end": "964800"
  },
  {
    "text": "KCl takes away all of these problems away from you so you can focus on your record processing logic and KCl can",
    "start": "964800",
    "end": "971440"
  },
  {
    "text": "handle elastically scaling based on your number of shards making sure that it's any records which are being processed is",
    "start": "971440",
    "end": "976959"
  },
  {
    "text": "getting checkpointed and in case any failures happen it canally scale up or scale down with that and that's what",
    "start": "976959",
    "end": "982480"
  },
  {
    "text": "really K helps you building a distributed processing system on a streaming data set in ginesis how how it",
    "start": "982480",
    "end": "989120"
  },
  {
    "text": "really does is that within KCl you have first a worker which is Illustrated in the previous slide a worker being a unit",
    "start": "989120",
    "end": "996120"
  },
  {
    "text": "of um process which runs on um within the context of a CASL application uh",
    "start": "996120",
    "end": "1001519"
  },
  {
    "text": "within each worker you create record processor and what the workers does is it assigns a record processor to each",
    "start": "1001519",
    "end": "1007440"
  },
  {
    "text": "Shard so worker will take the data from A Shard give it to a record processor for The Shard and also keep",
    "start": "1007440",
    "end": "1013000"
  },
  {
    "text": "checkpointing the data set back in a Dynamo DV table the name of the Dynamo DV table is same is the the name of the",
    "start": "1013000",
    "end": "1019399"
  },
  {
    "text": "cas application itself and that is what is used for checkpointing to help it recover also from failures in case that",
    "start": "1019399",
    "end": "1026720"
  },
  {
    "text": "happens and in this model all you need to do is basically write to application logic in the record processor and the",
    "start": "1026720",
    "end": "1032360"
  },
  {
    "text": "cas KL can take um care of running that at running that elastically with your Amazon Kinesis",
    "start": "1032360",
    "end": "1039959"
  },
  {
    "start": "1040000",
    "end": "1088000"
  },
  {
    "text": "stream further along that built on top of KCl we also have connector Library",
    "start": "1040400",
    "end": "1046240"
  },
  {
    "text": "the connector Library allows you to use uh services such as Amazon S3 Dynamo DB Kinesis red shift and also elas search",
    "start": "1046240",
    "end": "1054280"
  },
  {
    "text": "so you can use the case connector library to write data to any of these streams and the various use cases could",
    "start": "1054280",
    "end": "1059799"
  },
  {
    "text": "be for example you could have a simple KL application or connector library application which is writing archiving",
    "start": "1059799",
    "end": "1066200"
  },
  {
    "text": "your data to S3 there could be another one which is doing a microbatch loads into red shift or doing a real-time",
    "start": "1066200",
    "end": "1072320"
  },
  {
    "text": "monitoring metric extraction and writing the back to Dynamo DB or something of that sort and each of these connector",
    "start": "1072320",
    "end": "1078360"
  },
  {
    "text": "Library gives you a further much easier pattern a much easier boiler plate template code you can use to build your",
    "start": "1078360",
    "end": "1083799"
  },
  {
    "text": "application processing on top of AWS using Kinesis um Amazon EMR which is a manage",
    "start": "1083799",
    "end": "1091039"
  },
  {
    "start": "1088000",
    "end": "1136000"
  },
  {
    "text": "Hadoop cluster in the cloud on AWS which also gives you the ability to have um run familiar tools within your Hado EOS",
    "start": "1091039",
    "end": "1097799"
  },
  {
    "text": "system such as Hive Peg um map ruce Etc to take the data and runs something like",
    "start": "1097799",
    "end": "1104000"
  },
  {
    "text": "SQL queries using hi on top of a kesis stream it's as simple as starting basically creating a table on top of",
    "start": "1104000",
    "end": "1109919"
  },
  {
    "text": "Kinesis stream using the input storage Handler we provide so using that you can just basically start running simple",
    "start": "1109919",
    "end": "1115760"
  },
  {
    "text": "extraction jobs on top of your kesis streams on a certain micro batches interval on a small intervals of data",
    "start": "1115760",
    "end": "1121000"
  },
  {
    "text": "itself you don't really have to do anything you can just use your familiar expertise what you have in house to deal",
    "start": "1121000",
    "end": "1126679"
  },
  {
    "text": "with with working with tools such as Hive and pig and apply the same principle on top of a data stream such",
    "start": "1126679",
    "end": "1132240"
  },
  {
    "text": "as Kinesis without doing any underling work in there uh there just a brief introduction",
    "start": "1132240",
    "end": "1139280"
  },
  {
    "start": "1136000",
    "end": "1189000"
  },
  {
    "text": "to spark streaming um for those of for those of you who don't know about spark",
    "start": "1139280",
    "end": "1144400"
  },
  {
    "text": "it's basically inmemory compute uh framework the basic principle behind spark is something called rdd which is",
    "start": "1144400",
    "end": "1149880"
  },
  {
    "text": "stands for resilient distributed data sets think of it it as a partition data set across the notes of memory in a",
    "start": "1149880",
    "end": "1156320"
  },
  {
    "text": "cluster and what spark streaming does is it allows you to basically apply operations in parallel on those",
    "start": "1156320",
    "end": "1162400"
  },
  {
    "text": "partitions by the rdd the spark streaming goes a step further by having",
    "start": "1162400",
    "end": "1167799"
  },
  {
    "text": "micro batches of of rdd created in something called a group of um group of rdds called discret discretized streams",
    "start": "1167799",
    "end": "1174440"
  },
  {
    "text": "or D streams and any operations you can apply in principle on rdds the same operations you can apply now on D",
    "start": "1174440",
    "end": "1180600"
  },
  {
    "text": "streams and that can give you a better way to uh run across your run your operations across a stream uh streaming",
    "start": "1180600",
    "end": "1186679"
  },
  {
    "text": "data sets the second one being storm um storm is um stream processing framework",
    "start": "1186679",
    "end": "1195039"
  },
  {
    "start": "1189000",
    "end": "1225000"
  },
  {
    "text": "the basic unit of um processing behind storm is something called a topology topology is basically a unit of work",
    "start": "1195039",
    "end": "1201120"
  },
  {
    "text": "which runs on a storm cluster within topology you have something called a spout uh in this case a Kinesis spout",
    "start": "1201120",
    "end": "1206559"
  },
  {
    "text": "which is going to read data from Kinesis and play Into the Storm topology and the bolts are one which are going to do operations on the records coming in or",
    "start": "1206559",
    "end": "1213799"
  },
  {
    "text": "or on the tuples coming in and bolts can do work like counting processing filtering and Etc and any sort of the",
    "start": "1213799",
    "end": "1219720"
  },
  {
    "text": "window which uh you know any sort of processing which uh storm can support for both of these um for the first one",
    "start": "1219720",
    "end": "1226200"
  },
  {
    "start": "1225000",
    "end": "1244000"
  },
  {
    "text": "there's a Kinesis receiver uh available with spark 1.2.1 I think which can start using with",
    "start": "1226200",
    "end": "1231919"
  },
  {
    "text": "spark streaming and for the storm we have a Kinesis storm spout available in",
    "start": "1231919",
    "end": "1236960"
  },
  {
    "text": "GitHub and you can use that as a pre-built spot for you to replay your data within your storm",
    "start": "1236960",
    "end": "1243440"
  },
  {
    "text": "topology uh in the end of it as you mentioned just to put it all together",
    "start": "1243440",
    "end": "1248880"
  },
  {
    "start": "1244000",
    "end": "1304000"
  },
  {
    "text": "that you will have multiple patterns of data setes coming in and the idea being that first you're using different",
    "start": "1248880",
    "end": "1254200"
  },
  {
    "text": "processing paths with Kinesis data sets to do different things first being that you could write a counter back to a",
    "start": "1254200",
    "end": "1260159"
  },
  {
    "text": "real-time counter a monitors monitoring counters in Dynamo DB so your application can display a realtime dashboard Etc you can even use that K to",
    "start": "1260159",
    "end": "1267520"
  },
  {
    "text": "do a micro batches load into red shift so you can use your extracting VI tools or extrating inhouse visualization tools",
    "start": "1267520",
    "end": "1273360"
  },
  {
    "text": "to look at the data in a more timely manner and the last one being that you can accumulate your data in S3 and you",
    "start": "1273360",
    "end": "1280039"
  },
  {
    "text": "can use something like EMR to do um deep learning machine learning build your fraud models Etc and push that back up",
    "start": "1280039",
    "end": "1286480"
  },
  {
    "text": "to into Dynamo DB tier so can react in real time to when uh when you come to determining what whether transition",
    "start": "1286480",
    "end": "1292679"
  },
  {
    "text": "should be allowed through a fraud system or not and those are some of the patterns you can build together using Amazon web services with Kinesis for",
    "start": "1292679",
    "end": "1299480"
  },
  {
    "text": "doing a realtime analytics on AWS and finally to help you get started",
    "start": "1299480",
    "end": "1307200"
  },
  {
    "start": "1304000",
    "end": "1341000"
  },
  {
    "text": "we also have AWS Big Data blog there are few blog entries which can help you with uh learning some of the processing you",
    "start": "1307200",
    "end": "1312320"
  },
  {
    "text": "can do with Kinesis for examples there on how to use a Lambda function how to use a micro batching load and workload",
    "start": "1312320",
    "end": "1318360"
  },
  {
    "text": "on to Red shift with Kinesis how we going to build a sliding window application using Kinesis and storm and",
    "start": "1318360",
    "end": "1323720"
  },
  {
    "text": "I'll encourage you guys to go take a look at some of these blogs and these are the patterns you can help build basically to get started with realtime",
    "start": "1323720",
    "end": "1329640"
  },
  {
    "text": "analytics on AWS um with that I will invite kab to talk about grie",
    "start": "1329640",
    "end": "1334960"
  },
  {
    "text": "further uh thanks rul so uh just little bit about G International uh we are a",
    "start": "1334960",
    "end": "1342320"
  },
  {
    "start": "1341000",
    "end": "1367000"
  },
  {
    "text": "global gaming company uh headquartered in Japan and uh we started our Western",
    "start": "1342320",
    "end": "1347720"
  },
  {
    "text": "operation in San Francisco in 2008 uh since then we have released like several",
    "start": "1347720",
    "end": "1353480"
  },
  {
    "text": "uh titles uh both in apple I Apple Store and Google Play Store uh some of the",
    "start": "1353480",
    "end": "1359679"
  },
  {
    "text": "titles we have are in top grossing uh",
    "start": "1359679",
    "end": "1365519"
  },
  {
    "text": "category so why do we need analytics right uh we have like all of these games",
    "start": "1366919",
    "end": "1373120"
  },
  {
    "start": "1367000",
    "end": "1391000"
  },
  {
    "text": "and uh we want to like constantly uh improve player experience for our",
    "start": "1373120",
    "end": "1379039"
  },
  {
    "text": "uh our players so to improve that uh in order to enable us to improve that",
    "start": "1379039",
    "end": "1385679"
  },
  {
    "text": "experience we keep tracking of like player activity within the games so we",
    "start": "1385679",
    "end": "1391320"
  },
  {
    "start": "1391000",
    "end": "1474000"
  },
  {
    "text": "have this all of this game data uh coming from the game client and the server we also have like some user",
    "start": "1391320",
    "end": "1398880"
  },
  {
    "text": "tracking EV uh user interaction uh that's happening on the screen client",
    "start": "1398880",
    "end": "1404520"
  },
  {
    "text": "screen uh we collect those data as well uh and some of the performance uh data",
    "start": "1404520",
    "end": "1410600"
  },
  {
    "text": "for our game Services as well so we take all of those data and uh constantly try",
    "start": "1410600",
    "end": "1415840"
  },
  {
    "text": "to improve player game experience in addition to that uh we run",
    "start": "1415840",
    "end": "1422000"
  },
  {
    "text": "several marketing campaign to uh get engage more players for in our game uh",
    "start": "1422000",
    "end": "1428679"
  },
  {
    "text": "and all of those C campaigns we uh want to keep track of like user click data",
    "start": "1428679",
    "end": "1434679"
  },
  {
    "text": "and downloads application download data and all of those data help us like",
    "start": "1434679",
    "end": "1440279"
  },
  {
    "text": "enhancing our marketing span uh for marketing campaign that we run",
    "start": "1440279",
    "end": "1446799"
  },
  {
    "text": "and uh in addition to that we want to like also keep our player engaging so uh",
    "start": "1446799",
    "end": "1453520"
  },
  {
    "text": "we have this play targeting data and other game events uh and so that can",
    "start": "1453520",
    "end": "1459640"
  },
  {
    "text": "give us a good idea of what's going on within the game ecosystem so uh from",
    "start": "1459640",
    "end": "1465760"
  },
  {
    "text": "very beginning we started as a data driv company as we collect huge amount of analytics data from throughout all of",
    "start": "1465760",
    "end": "1473080"
  },
  {
    "text": "our games some of the uh sources of the data that we collect uh is like mobile",
    "start": "1473080",
    "end": "1480440"
  },
  {
    "text": "devices uh game servers that basically serving our web traffics then ad",
    "start": "1480440",
    "end": "1487520"
  },
  {
    "text": "networks that we partner with so we collect all of these data uh and then uh",
    "start": "1487520",
    "end": "1493120"
  },
  {
    "text": "we analyze those data if we look at our overall data volume it's 500 gab a day",
    "start": "1493120",
    "end": "1500840"
  },
  {
    "text": "and uh in overall like we have 500 million plus events uh that we are",
    "start": "1500840",
    "end": "1506360"
  },
  {
    "text": "generating throughout our uh titles average size of the those events are 1",
    "start": "1506360",
    "end": "1514480"
  },
  {
    "text": "kilobyte uh also uh this is our how our analytics data look like uh we decided",
    "start": "1515039",
    "end": "1522960"
  },
  {
    "text": "to go ahead with the Json structure as a schema aware format for all of our",
    "start": "1522960",
    "end": "1528600"
  },
  {
    "text": "analytics data and that helped us a lot uh throughout our various tools that we",
    "start": "1528600",
    "end": "1534679"
  },
  {
    "text": "build uh having schema aware format for analytics datas allows us to like run",
    "start": "1534679",
    "end": "1540120"
  },
  {
    "text": "EMR jobs or uh process it in uh whatever way we want to do uh help help us a lot",
    "start": "1540120",
    "end": "1548240"
  },
  {
    "text": "uh in addition to the actual game data or event data we also have some metadata",
    "start": "1548240",
    "end": "1554039"
  },
  {
    "text": "that's attached to each event some of those metadata are like what database",
    "start": "1554039",
    "end": "1559120"
  },
  {
    "text": "this event is going to then what's the actual event name uh when this event get",
    "start": "1559120",
    "end": "1565440"
  },
  {
    "text": "generated and we create like unique ID for each event so those are some of the",
    "start": "1565440",
    "end": "1570559"
  },
  {
    "text": "example of metadata that we have for each of our analytics",
    "start": "1570559",
    "end": "1576679"
  },
  {
    "start": "1576000",
    "end": "1705000"
  },
  {
    "text": "event uh so before we uh started working with the Kinesis we had our inhouse data",
    "start": "1577399",
    "end": "1583640"
  },
  {
    "text": "analytics data pipeline to collect and store all of this data that we were",
    "start": "1583640",
    "end": "1588919"
  },
  {
    "text": "generating uh but as we started adding more games and our player base started",
    "start": "1588919",
    "end": "1594159"
  },
  {
    "text": "increasing uh we uh started to kind of getting into the uh managing uh issues",
    "start": "1594159",
    "end": "1601880"
  },
  {
    "text": "of uh this analytics data uh some of the key requirement we had is like we want",
    "start": "1601880",
    "end": "1608640"
  },
  {
    "text": "to be able to like do guaranteed data delivery we want zero data loss and Corruption and we want to be able to add",
    "start": "1608640",
    "end": "1616440"
  },
  {
    "text": "consumer multiple consumers easily uh so uh it can be a consumer for like just",
    "start": "1616440",
    "end": "1624320"
  },
  {
    "text": "storing data and then forwarding it to any data warehouse or we might want to like just do real-time",
    "start": "1624320",
    "end": "1631159"
  },
  {
    "text": "aggregation uh on stream of analytics data that coming in so uh whatever analy",
    "start": "1631159",
    "end": "1639279"
  },
  {
    "text": "analytics pipeline we had uh which is developed in house like it was we were",
    "start": "1639279",
    "end": "1644360"
  },
  {
    "text": "trying to get into scalability issues when we Tred to add more consumers uh",
    "start": "1644360",
    "end": "1650520"
  },
  {
    "text": "and uh also like as we started analyzing this data more and more there are also",
    "start": "1650520",
    "end": "1657000"
  },
  {
    "text": "requirement to in order to like do a realtime uh analysis so we real-time",
    "start": "1657000",
    "end": "1664159"
  },
  {
    "text": "latency for analytics data was also uh started to be getting important for",
    "start": "1664159",
    "end": "1671279"
  },
  {
    "text": "us uh we also want to be able to do like real time ad hoc analysis on top of our",
    "start": "1671279",
    "end": "1676320"
  },
  {
    "text": "analytics data and uh we wanted this service to be a",
    "start": "1676320",
    "end": "1681880"
  },
  {
    "text": "managed service because uh we believe that we should really focus on uh developing a game and not managing this",
    "start": "1681880",
    "end": "1688279"
  },
  {
    "text": "data pipeline uh so having a managed service like help us focus more on uh",
    "start": "1688279",
    "end": "1694159"
  },
  {
    "text": "building tools on top of this data uh so we can uh give uh better",
    "start": "1694159",
    "end": "1701440"
  },
  {
    "text": "results so uh so before so after converting after",
    "start": "1701440",
    "end": "1708240"
  },
  {
    "start": "1705000",
    "end": "1715000"
  },
  {
    "text": "started using Amazon Kinesis uh we uh we have this is our analytics",
    "start": "1708240",
    "end": "1714679"
  },
  {
    "text": "architecture so our game CLI sending data to game server that are also events",
    "start": "1714679",
    "end": "1720159"
  },
  {
    "text": "generating from the game servers and uh that data is being forwarded to Amazon",
    "start": "1720159",
    "end": "1726039"
  },
  {
    "text": "kesis uh we have sender install on each game servers which forwards any",
    "start": "1726039",
    "end": "1732159"
  },
  {
    "text": "analytics data that we generate to uh further in the pipeline uh here in this case it's forwarding data to Amazon",
    "start": "1732159",
    "end": "1738799"
  },
  {
    "text": "Kinesis uh from Amazon Kinesis uh we have multiple consumer applications that",
    "start": "1738799",
    "end": "1745760"
  },
  {
    "text": "uh processes data out of the kesis one of the consumer we have is a simple uh",
    "start": "1745760",
    "end": "1751640"
  },
  {
    "text": "store consumer which stores data into S3 and uh once we have data in S3 uh we uh",
    "start": "1751640",
    "end": "1760399"
  },
  {
    "text": "load that data into Amazon red shift or we run EMR jobs on uh for doing more",
    "start": "1760399",
    "end": "1766840"
  },
  {
    "text": "deeper analysis on top of that data so that's pretty uh simple",
    "start": "1766840",
    "end": "1772240"
  },
  {
    "text": "consumer uh if you look at like so we build this uh this particular consumer",
    "start": "1772240",
    "end": "1779600"
  },
  {
    "text": "and whole pipeline using only three to four Engineers uh and in really short",
    "start": "1779600",
    "end": "1785039"
  },
  {
    "text": "amount of time like four months and that was a really great win for us and initially like we run this uh inhouse",
    "start": "1785039",
    "end": "1792320"
  },
  {
    "text": "Pipeline and this new pipeline uh in parallel and we made sure like we have",
    "start": "1792320",
    "end": "1797600"
  },
  {
    "text": "all the data data integrity and uh other things uh in addition to S3 consumer we",
    "start": "1797600",
    "end": "1803880"
  },
  {
    "text": "also have a consumer for calculating a realtime stats within the game uh and",
    "start": "1803880",
    "end": "1809799"
  },
  {
    "text": "that one is using doing real-time calculation and storing data into raders",
    "start": "1809799",
    "end": "1815000"
  },
  {
    "text": "and from there uh we display that data into a",
    "start": "1815000",
    "end": "1820080"
  },
  {
    "start": "1819000",
    "end": "1874000"
  },
  {
    "text": "dashboard uh so let's talk about like some of the key components of that analytics architecture U I mentioned",
    "start": "1820279",
    "end": "1827559"
  },
  {
    "text": "before that we run Kinesis sender on each of the game server and uh just to",
    "start": "1827559",
    "end": "1833919"
  },
  {
    "text": "be on very high level like what that sender does uh so this sender is hosting",
    "start": "1833919",
    "end": "1841080"
  },
  {
    "text": "on the game server it connects to uh Amazon K stream uh it reads like how",
    "start": "1841080",
    "end": "1847840"
  },
  {
    "text": "many shots within within that particular stream uh as Rahul mentioned before there are multiple shots in the Stream",
    "start": "1847840",
    "end": "1855000"
  },
  {
    "text": "so uh sender needs to know like how many sh starts uh it's sending data to now uh",
    "start": "1855000",
    "end": "1862440"
  },
  {
    "text": "all of our analytics data that we generate we store it in a file uh local files and that local files uh is being",
    "start": "1862440",
    "end": "1869639"
  },
  {
    "text": "consumed by the sender on the machine and uh once uh so sender keep reading those",
    "start": "1869639",
    "end": "1877159"
  },
  {
    "start": "1874000",
    "end": "1969000"
  },
  {
    "text": "files uh and it create the buffers uh it also compresses that data and uh once it",
    "start": "1877159",
    "end": "1884480"
  },
  {
    "text": "reaches the limit of 50 kilobyte uh it sends that data using kesis put record",
    "start": "1884480",
    "end": "1889840"
  },
  {
    "text": "calls uh to one of the sharts into Amazon kesis stream uh now uh here if",
    "start": "1889840",
    "end": "1896399"
  },
  {
    "text": "you noticed we are doing a compression as well uh it might be a heavy processing so uh depending on your how",
    "start": "1896399",
    "end": "1904880"
  },
  {
    "text": "you are sending data you might want to uh not compress your data and just send",
    "start": "1904880",
    "end": "1910519"
  },
  {
    "text": "it directly uh as we are we have uh decoupled the process from uh data",
    "start": "1910519",
    "end": "1917360"
  },
  {
    "text": "generation to sending uh we are doing compression here and it's totally independent process and because of that",
    "start": "1917360",
    "end": "1923799"
  },
  {
    "text": "uh even if you do a compression and it's a little bit heavy on the CPU we aren't worry worrying about that much but like",
    "start": "1923799",
    "end": "1930600"
  },
  {
    "text": "allowing doing compression allows us to like send uh larger chunk of the data uh",
    "start": "1930600",
    "end": "1935760"
  },
  {
    "text": "greater than 50 kilobyte uh Kinesis has a limit of 50 kilobyte but uh if you do",
    "start": "1935760",
    "end": "1941720"
  },
  {
    "text": "compression we can send more data now most of our events are 1 kilobyte but there are cases where uh event can be a",
    "start": "1941720",
    "end": "1948679"
  },
  {
    "text": "larger than 50 kilobyte uh for an example we store uh client crash log",
    "start": "1948679",
    "end": "1954559"
  },
  {
    "text": "events uh which can easily be uh greater than 50 kilobyte uh doing compression",
    "start": "1954559",
    "end": "1961120"
  },
  {
    "text": "allows us to send more data so we can still send the crash log went through the same analytics",
    "start": "1961120",
    "end": "1968880"
  },
  {
    "start": "1969000",
    "end": "2038000"
  },
  {
    "text": "pipeline so some of the design choices we made while building this sender uh as",
    "start": "1969559",
    "end": "1975760"
  },
  {
    "text": "we as I told before that we have multiple titles and uh we we could have",
    "start": "1975760",
    "end": "1981159"
  },
  {
    "text": "gone with the either single stream approach or uh stream per a game uh in our case we choose to go with the single",
    "start": "1981159",
    "end": "1987480"
  },
  {
    "text": "stream because management of single stream is easier than managing multiple streams and uh uh processing that we",
    "start": "1987480",
    "end": "1995760"
  },
  {
    "text": "were doing on the other side consumer side was uh fast enough in our case uh",
    "start": "1995760",
    "end": "2000880"
  },
  {
    "text": "even with the single stream so we decided to go ahead with the single stream in uh in our use case",
    "start": "2000880",
    "end": "2008399"
  },
  {
    "text": "then uh you can either do a batch of batch events or you can do a single event uh",
    "start": "2008399",
    "end": "2013840"
  },
  {
    "text": "now uh we have our analytics data is like on average it's a 1 kilobyte uh if",
    "start": "2013840",
    "end": "2019720"
  },
  {
    "text": "we do a batch events uh we can send like more events uh within the single call so",
    "start": "2019720",
    "end": "2025200"
  },
  {
    "text": "we we do a batch event and we also have the decoupled process so uh it allows us to like do those buffering uh in",
    "start": "2025200",
    "end": "2032919"
  },
  {
    "text": "independent independent process uh so we we are using badge event",
    "start": "2032919",
    "end": "2038919"
  },
  {
    "start": "2038000",
    "end": "2053000"
  },
  {
    "text": "then uh compression and should we use compression or not so as I mentioned",
    "start": "2038919",
    "end": "2044440"
  },
  {
    "text": "before we are using compression so we can like send larger events it also allows us to like send more data within",
    "start": "2044440",
    "end": "2051520"
  },
  {
    "text": "just single call U another thing you can use like",
    "start": "2051520",
    "end": "2057118"
  },
  {
    "start": "2053000",
    "end": "2101000"
  },
  {
    "text": "should you use partition key or explicit hash key now uh if you are doing uh",
    "start": "2057119",
    "end": "2063480"
  },
  {
    "text": "depending on your application you might want to do a partition key if you are uh doing Aggregates or other kind of things",
    "start": "2063480",
    "end": "2070118"
  },
  {
    "text": "that you so you want to make sure that the same player data falls into the same",
    "start": "2070119",
    "end": "2075240"
  },
  {
    "text": "Shard uh so you might want to use a partition key uh in our case we are using explicit hash key because we want",
    "start": "2075240",
    "end": "2082440"
  },
  {
    "text": "to uh we want to minimize our resharding strategy if you use a partition key you",
    "start": "2082440",
    "end": "2088398"
  },
  {
    "text": "might end up doing like uh resharding a lot uh but if you use explicit hash key",
    "start": "2088399",
    "end": "2094040"
  },
  {
    "text": "uh you can like evenly distribute load uh to available shards within the",
    "start": "2094040",
    "end": "2100720"
  },
  {
    "start": "2101000",
    "end": "2341000"
  },
  {
    "text": "stream so next we're going to talk about the consumer uh which is a very simple",
    "start": "2102000",
    "end": "2109079"
  },
  {
    "text": "uh store Amazon S3 consumer so this consumer uh stores like so we are using",
    "start": "2109079",
    "end": "2116599"
  },
  {
    "text": "KCl on the on a consumer application uh as Rahul mentioned before uh it uh helps",
    "start": "2116599",
    "end": "2123359"
  },
  {
    "text": "you to uh like helps you with the resharding that might happen within your",
    "start": "2123359",
    "end": "2129839"
  },
  {
    "text": "kesis stream and it take carees of most of the task for you um so for example",
    "start": "2129839",
    "end": "2136839"
  },
  {
    "text": "you are seeing here uh two uh processes two consumer processes processing data",
    "start": "2136839",
    "end": "2143240"
  },
  {
    "text": "but if you had more shards like KCl Library make sure that it creates any",
    "start": "2143240",
    "end": "2148599"
  },
  {
    "text": "necessary worker uh to in order to process uh that new Shard and at the",
    "start": "2148599",
    "end": "2155119"
  },
  {
    "text": "same time if you take out any Shard from your string stre uh that cons that",
    "start": "2155119",
    "end": "2160240"
  },
  {
    "text": "particular worker will eventually stop processing data and you can free up that resources so uh using KCl allowed us to",
    "start": "2160240",
    "end": "2168400"
  },
  {
    "text": "like build uh this overall system like very rapidly uh so KCl all it does like you",
    "start": "2168400",
    "end": "2178079"
  },
  {
    "text": "uh it emits record for you so whatever data you are putting in using the put record in Kinesis uh it provides you",
    "start": "2178079",
    "end": "2185319"
  },
  {
    "text": "that data and then that data you can uh use it whichever way you want to use it",
    "start": "2185319",
    "end": "2192079"
  },
  {
    "text": "so for in Amazon S3 consumer uh as we are compressing data we do a we do a",
    "start": "2192079",
    "end": "2198480"
  },
  {
    "text": "decompress first uh we also checking for the duplicates here uh once we do a",
    "start": "2198480",
    "end": "2203960"
  },
  {
    "text": "decompression uh the reason we are checking for the ddop is like because when you do a put record call to Kinesis",
    "start": "2203960",
    "end": "2211359"
  },
  {
    "text": "uh it might be possible that you received 500 HTTP 500 response and uh",
    "start": "2211359",
    "end": "2216800"
  },
  {
    "text": "whenever you receive this HTTP 500 response you are really not sure uh whether that data you send it to Kinesis",
    "start": "2216800",
    "end": "2223400"
  },
  {
    "text": "made into the Kinesis or not so because of that we have to retry that uh",
    "start": "2223400",
    "end": "2229040"
  },
  {
    "text": "particular uh data that we sent so in that case if that data already made into",
    "start": "2229040",
    "end": "2234240"
  },
  {
    "text": "Kinesis before we will end up with the duplicates so uh we find this out after",
    "start": "2234240",
    "end": "2241920"
  },
  {
    "text": "initially uh initial like testing phase and that's why we introduced the DD",
    "start": "2241920",
    "end": "2248200"
  },
  {
    "text": "phase uh in the consumer uh once you D dup uh we divide",
    "start": "2248200",
    "end": "2254359"
  },
  {
    "text": "that data into a Target table uh the reason we are doing it here because it's",
    "start": "2254359",
    "end": "2259440"
  },
  {
    "text": "uh we are sending probably thousand plus events uh within the same stream so we",
    "start": "2259440",
    "end": "2265480"
  },
  {
    "text": "need to know like which data we need to divide that data and then do a",
    "start": "2265480",
    "end": "2271119"
  },
  {
    "text": "validation uh to make sure the data formats and uh data types are valid",
    "start": "2271119",
    "end": "2278240"
  },
  {
    "text": "uh and this data is primarily used for loading data into red shift uh we are",
    "start": "2278240",
    "end": "2283880"
  },
  {
    "text": "doing validation based on the schema we have in a red",
    "start": "2283880",
    "end": "2289319"
  },
  {
    "text": "shift so after validation uh we do a dsv transformation uh it's just a d Limited",
    "start": "2289880",
    "end": "2297079"
  },
  {
    "text": "Format that we use for loading data into red shift and uh once that happens like we still",
    "start": "2297079",
    "end": "2304560"
  },
  {
    "text": "we again buffer that data up to certain size or or timeout occurs and uh from",
    "start": "2304560",
    "end": "2310960"
  },
  {
    "text": "that uh that data goes into S3 uh we compress that data again and store it",
    "start": "2310960",
    "end": "2316200"
  },
  {
    "text": "into S3 uh we also at the same time we also make a pointer to that S3 file and",
    "start": "2316200",
    "end": "2323760"
  },
  {
    "text": "put it into uh our file metadata DB storage and uh that pointer basically",
    "start": "2323760",
    "end": "2330079"
  },
  {
    "text": "help us to load data into R shift uh in the later phase so that's our simple S3",
    "start": "2330079",
    "end": "2340920"
  },
  {
    "start": "2341000",
    "end": "2364000"
  },
  {
    "text": "consumer so uh let's talk about the loading data into red shift now uh so as",
    "start": "2342319",
    "end": "2348640"
  },
  {
    "text": "I mentioned before like we have this file pointer into S3 that we want to load data into red shift uh so we start",
    "start": "2348640",
    "end": "2356440"
  },
  {
    "text": "with that metadata DB and then uh we we open up a transaction and then uh we we",
    "start": "2356440",
    "end": "2364720"
  },
  {
    "text": "get the list of pending pending events that we want to load into into red shift",
    "start": "2364720",
    "end": "2370560"
  },
  {
    "text": "uh so from uh once we get the list of pending files for a particular event we create a manifest file uh that goes to",
    "start": "2370560",
    "end": "2378880"
  },
  {
    "text": "S3 again and from there uh using that manifest file we execute a copy command",
    "start": "2378880",
    "end": "2385520"
  },
  {
    "text": "on the red shift cluster uh and once you execute a copy command it will get back",
    "start": "2385520",
    "end": "2392040"
  },
  {
    "text": "to you with the like status of that particular copy command uh so we do that",
    "start": "2392040",
    "end": "2397760"
  },
  {
    "text": "uh in a in a batch mode so every transaction like loads data 10 or 15",
    "start": "2397760",
    "end": "2404640"
  },
  {
    "text": "events at a time so that basically multiple events in one",
    "start": "2404640",
    "end": "2410400"
  },
  {
    "text": "transaction uh now this is something like not uh usual like uh you can you",
    "start": "2410400",
    "end": "2417520"
  },
  {
    "text": "don't need to open up a transaction here uh the reason we are doing a transaction here is because we have uh the way we",
    "start": "2417520",
    "end": "2425160"
  },
  {
    "text": "have uh structured our data into red shift we have thousand plus events uh",
    "start": "2425160",
    "end": "2431920"
  },
  {
    "text": "for all of our titles now some of the events are uh same events but it has",
    "start": "2431920",
    "end": "2437240"
  },
  {
    "text": "like some additional data so for an example like one game has a level up event and another game has a level up",
    "start": "2437240",
    "end": "2444119"
  },
  {
    "text": "event but it still count as like two separate event and uh those event might",
    "start": "2444119",
    "end": "2449359"
  },
  {
    "text": "be deferring like some of additional data or like some uh additional columns",
    "start": "2449359",
    "end": "2455319"
  },
  {
    "text": "uh that they have and because of that we ended up with like thousand plus tables that we need to load uh so when we have",
    "start": "2455319",
    "end": "2462240"
  },
  {
    "text": "that many tables to load uh to be able to do efficient load in red shift uh we are using",
    "start": "2462240",
    "end": "2469319"
  },
  {
    "start": "2470000",
    "end": "2497000"
  },
  {
    "text": "transaction so at the end of the transaction we uh update status back into the metadata DB and uh uh that way",
    "start": "2470760",
    "end": "2478760"
  },
  {
    "text": "we know like next time we run that uh process again we know that that file has",
    "start": "2478760",
    "end": "2483839"
  },
  {
    "text": "been already loaded uh one of the reason we are using metad DB so we can bring up",
    "start": "2483839",
    "end": "2489800"
  },
  {
    "text": "actually another cluster uh for any OC analysis that we want to do uh",
    "start": "2489800",
    "end": "2497040"
  },
  {
    "start": "2497000",
    "end": "2517000"
  },
  {
    "text": "so yeah sorry so in order to provide ad analysis",
    "start": "2497640",
    "end": "2503640"
  },
  {
    "text": "on uh additional rad shift cluster we can just use this uh data metadata",
    "start": "2503640",
    "end": "2509040"
  },
  {
    "text": "information and then uh load uh even one table for on a totally separate R shift",
    "start": "2509040",
    "end": "2515280"
  },
  {
    "text": "cluster uh so the next thing is like consumer",
    "start": "2515280",
    "end": "2521359"
  },
  {
    "start": "2517000",
    "end": "2552000"
  },
  {
    "text": "realtime stats so this consumer is uh primarily function to calculate the",
    "start": "2521359",
    "end": "2527079"
  },
  {
    "text": "realtime stats uh from the Kinesis streaming data that coming into Kinesis from Kinesis uh this consumer is uh",
    "start": "2527079",
    "end": "2535800"
  },
  {
    "text": "pretty much same uh to the S3 consumer uh so it's doing like it's using KCl",
    "start": "2535800",
    "end": "2542720"
  },
  {
    "text": "it's using decompression it's using like ddop and then it divid that data into",
    "start": "2542720",
    "end": "2547880"
  },
  {
    "text": "Target table uh but from now here like it takes uh configuration files so we have",
    "start": "2547880",
    "end": "2555040"
  },
  {
    "start": "2552000",
    "end": "2630000"
  },
  {
    "text": "a configuration file that uh let us know like which event we are interested in so",
    "start": "2555040",
    "end": "2561079"
  },
  {
    "text": "we filter uh number of events based on that configuration file uh we have",
    "start": "2561079",
    "end": "2566960"
  },
  {
    "text": "thousand plus events but we might not be necessarily interested in all the events",
    "start": "2566960",
    "end": "2572079"
  },
  {
    "text": "so uh based on the configuration file we might be like only processing uh 10 or",
    "start": "2572079",
    "end": "2577800"
  },
  {
    "text": "100 uh events uh so it uses that for filtering an event uh in addition to",
    "start": "2577800",
    "end": "2584960"
  },
  {
    "text": "that U it also calculates like data based on the uh configuration setup for",
    "start": "2584960",
    "end": "2591760"
  },
  {
    "text": "each metric that we want to calculate uh it uses that configuration again to like calculate the metrix segments uh like",
    "start": "2591760",
    "end": "2599520"
  },
  {
    "text": "what's the value for that particular matric and segment and uh what's the time slot and from that that data goes",
    "start": "2599520",
    "end": "2606760"
  },
  {
    "text": "to into radar again uh so so data goes into radar and",
    "start": "2606760",
    "end": "2612200"
  },
  {
    "text": "we have built a dashboard on top of the radar so we can uh see in real time uh",
    "start": "2612200",
    "end": "2617640"
  },
  {
    "text": "what's going on within our game so that's a realtime stats",
    "start": "2617640",
    "end": "2623680"
  },
  {
    "text": "consumer uh some of the lessons we learned during uh building this Kinesis",
    "start": "2623680",
    "end": "2629839"
  },
  {
    "text": "pipeline uh it's always good idea to like decouple your data generation part from your uh sending part that allows",
    "start": "2629839",
    "end": "2637400"
  },
  {
    "start": "2630000",
    "end": "2684000"
  },
  {
    "text": "you to do like multiple things you can uh buffer event or you can batch event uh you are if you if you need to do",
    "start": "2637400",
    "end": "2644839"
  },
  {
    "text": "compression you can also do compression uh and uh in case like uh",
    "start": "2644839",
    "end": "2651359"
  },
  {
    "text": "and de decoupling your sending part also allows you to like not worrying about",
    "start": "2651359",
    "end": "2656920"
  },
  {
    "text": "your actual application latency and just you can focus on your",
    "start": "2656920",
    "end": "2662119"
  },
  {
    "text": "uh actual uh data generation in separate process",
    "start": "2662119",
    "end": "2667640"
  },
  {
    "text": "then batch and compression if you want to send more data in a single",
    "start": "2667640",
    "end": "2673480"
  },
  {
    "text": "call uh put record HTTP 500 can result in a duplicate that's why we have",
    "start": "2673480",
    "end": "2678800"
  },
  {
    "text": "introduced DD process in a",
    "start": "2678800",
    "end": "2683680"
  },
  {
    "start": "2684000",
    "end": "2724000"
  },
  {
    "text": "consumer uh also like we recommend like monitoring some of those events when you",
    "start": "2684640",
    "end": "2689920"
  },
  {
    "text": "send a uh when you send data to Kinesis using put record call it comes up with",
    "start": "2689920",
    "end": "2695520"
  },
  {
    "text": "like few error message types one of the error message type is like provision through put exate uh if you",
    "start": "2695520",
    "end": "2701400"
  },
  {
    "text": "start getting lot of if you start getting lot of those events you might want to like add more",
    "start": "2701400",
    "end": "2707920"
  },
  {
    "text": "sharts because what that means is that uh you have more data to send compared",
    "start": "2707920",
    "end": "2713040"
  },
  {
    "text": "to number of number of uh compared to",
    "start": "2713040",
    "end": "2718160"
  },
  {
    "text": "number of like sharts you have available in the system or your shards capacity in the",
    "start": "2718160",
    "end": "2724519"
  },
  {
    "start": "2724000",
    "end": "2811000"
  },
  {
    "text": "system uh on the the consumer side uh it's uh very recommended to use KCl",
    "start": "2724880",
    "end": "2732040"
  },
  {
    "text": "because it makes your development really fast uh and it take carees of like resharding mechanism uh or checkpointing",
    "start": "2732040",
    "end": "2740640"
  },
  {
    "text": "your data within each Shard so that helps a lot in Expediting the development process uh always Auto scale",
    "start": "2740640",
    "end": "2749680"
  },
  {
    "text": "and uh monitor your load on the consumer application uh that will also give you an idea of like adding more shards if",
    "start": "2749680",
    "end": "2755960"
  },
  {
    "text": "you are cons what is falling behind uh for in compared to like how many what",
    "start": "2755960",
    "end": "2762880"
  },
  {
    "text": "amount of data you generating within the system uh in overall uh provision enough",
    "start": "2762880",
    "end": "2769559"
  },
  {
    "text": "Shard when you are start working with The KES stream and you can add more Shard as you go uh handle your shutdown",
    "start": "2769559",
    "end": "2777079"
  },
  {
    "text": "gracefully in both consumer and sender application uh it's very important that you handle uh shut down gracefully and",
    "start": "2777079",
    "end": "2784280"
  },
  {
    "text": "do a proper checkpointing uh so that will allow that will",
    "start": "2784280",
    "end": "2790760"
  },
  {
    "text": "like that will help not generating duplicates for your s like for your",
    "start": "2790760",
    "end": "2796720"
  },
  {
    "text": "data and in the last like follow AWS based practices for error retries and",
    "start": "2796720",
    "end": "2803040"
  },
  {
    "text": "exponential back off uh some of the takeaways from the",
    "start": "2803040",
    "end": "2811160"
  },
  {
    "start": "2811000",
    "end": "2876000"
  },
  {
    "text": "system uh Kinesis in general like it's a Pro Data whatever data you send to",
    "start": "2811160",
    "end": "2816520"
  },
  {
    "text": "kinesis stream is available for processing within the seconds uh so that",
    "start": "2816520",
    "end": "2821880"
  },
  {
    "text": "allows you to like build your real-time application uh one of the thing uh Rahul",
    "start": "2821880",
    "end": "2827200"
  },
  {
    "text": "mentioned before that you can uh build your real time uh monitoring on your",
    "start": "2827200",
    "end": "2833200"
  },
  {
    "text": "some of the transactions so uh for an example if you want to like see if the",
    "start": "2833200",
    "end": "2838359"
  },
  {
    "text": "trans if that particular transaction is a fraudulent activity or not you can you can do such things using",
    "start": "2838359",
    "end": "2844920"
  },
  {
    "text": "Kinesis uh use they have pretty robust API uh and there are lots of libraries",
    "start": "2844920",
    "end": "2852359"
  },
  {
    "text": "available as well to help you get started KCl uh and there are connector",
    "start": "2852359",
    "end": "2857559"
  },
  {
    "text": "libraries for S3 uh red shift and EMR as well so you can uh so that connector",
    "start": "2857559",
    "end": "2865079"
  },
  {
    "text": "Library can help you on the consumer side and uh you can just plug that library in and it will send data uh to",
    "start": "2865079",
    "end": "2872640"
  },
  {
    "text": "S3 or red sh whatever data source you are providing uh in general AWS uh it's always good to",
    "start": "2872640",
    "end": "2879400"
  },
  {
    "start": "2876000",
    "end": "2924000"
  },
  {
    "text": "have a managed service in compared to like managing your own cluster and uh uh",
    "start": "2879400",
    "end": "2884520"
  },
  {
    "text": "spending time in that INF that infrastructure uh scalable and uh very",
    "start": "2884520",
    "end": "2890520"
  },
  {
    "text": "cost effective in general yeah so quick to get up and",
    "start": "2890520",
    "end": "2896319"
  },
  {
    "text": "running uh we actually build all of this system like in 3 to four months with very small team so from that you can",
    "start": "2896319",
    "end": "2903319"
  },
  {
    "text": "take an idea of like using kinosis like how it how quickly you can build this",
    "start": "2903319",
    "end": "2908559"
  },
  {
    "text": "analytics data Pipeline and that scales uh automatically as your volume",
    "start": "2908559",
    "end": "2915520"
  },
  {
    "text": "grows uh thank you all for listening to us and uh yep thank you thank you",
    "start": "2915520",
    "end": "2921400"
  },
  {
    "text": "everybody for attending and",
    "start": "2921400",
    "end": "2926078"
  }
]
[
  {
    "text": "- All right. Hey folks, Emily here. Principal machine learning\nspecialist solutions architect at Amazon Web Services, and\ntoday we are gonna learn how",
    "start": "870",
    "end": "9210"
  },
  {
    "text": "to prepare data and train at scale. So in particular, this is a part of our larger YouTube course",
    "start": "9210",
    "end": "15450"
  },
  {
    "text": "on generative AI foundations on AWS. And in the last video you got a taste",
    "start": "15450",
    "end": "22140"
  },
  {
    "text": "of creating foundation models and pre-training foundation\nmodels from scratch.",
    "start": "22140",
    "end": "27540"
  },
  {
    "text": "We learned about distributed\ntraining optimizations. We introduced something called Data Parallel, something\ncalled Model Parallel.",
    "start": "27540",
    "end": "35910"
  },
  {
    "text": "We learned about this cluster concepts that you can create all these things,",
    "start": "35910",
    "end": "41130"
  },
  {
    "text": "but how do we actually do it? And so that's what we're gonna\nlearn about in this session. So let's get rolling.",
    "start": "41130",
    "end": "46350"
  },
  {
    "text": "All right. So in particular, the first\nthing we're gonna learn about today is how to\nprepare data at scale on AWS.",
    "start": "48210",
    "end": "56270"
  },
  {
    "text": "And you'll notice there are\nmany ways of doing this. We'll suggest just a couple of them, and a lot of them really focus",
    "start": "57330",
    "end": "63480"
  },
  {
    "text": "on making CPUs do a lot of the work. CPUs are a tiny fraction of the cost",
    "start": "63480",
    "end": "69690"
  },
  {
    "text": "of accelerators,\nparticularly a tiny fraction of the cost of GPUs. So I would strongly\nsuggest that you use CPUs",
    "start": "69690",
    "end": "77130"
  },
  {
    "text": "as much as you can, and we'll\ntalk about what it means to hydrate your training loop, right?",
    "start": "77130",
    "end": "82920"
  },
  {
    "text": "You wanna get to this\npoint where your forward and your backward pass\nis running really nicely",
    "start": "82920",
    "end": "88650"
  },
  {
    "text": "in PyTorch or however\nyou have it implemented. So basically we wanna\nhydrate that with data.",
    "start": "88650",
    "end": "93987"
  },
  {
    "text": "And so we're gonna work\nbackwards from that to figure out how to get you this. We'll look about distributed file systems,",
    "start": "93987",
    "end": "99840"
  },
  {
    "text": "in particular FSx for\nLustre, setting this up, configuring it, getting it to work nicely.",
    "start": "99840",
    "end": "106230"
  },
  {
    "text": "We'll learn about warm pools on SageMaker training and troubleshooting. And then we'll close that\nwith a hands-on walkthrough",
    "start": "106230",
    "end": "113130"
  },
  {
    "text": "of creating Sage Maker warm pools, and then running them with FSx for Lustre.",
    "start": "113130",
    "end": "117783"
  },
  {
    "text": "All right. So ideally, data preparation\nshould be these things.",
    "start": "119640",
    "end": "124908"
  },
  {
    "text": "(chuckles) When you're picking data\npreparation solutions, obviously you're gonna wanna\npick one that's not expensive.",
    "start": "124908",
    "end": "131790"
  },
  {
    "text": "You want to save money and\nnot lose money on data. So low cost. You want data preparation to\nbe somewhat simple, which is",
    "start": "131790",
    "end": "141180"
  },
  {
    "text": "to say you want the amount\nof work that you have to do to manage this\nsing and provision it.",
    "start": "141180",
    "end": "146940"
  },
  {
    "text": "You want that to be low. So you want the work itself that's necessary should\nbe somewhat simple.",
    "start": "146940",
    "end": "153540"
  },
  {
    "text": "You want your data\npreparation to be scalable. So you want to easily start from, Hey, I have just a small\nsample of data to process,",
    "start": "153540",
    "end": "161400"
  },
  {
    "text": "to now I have multiple terabytes and maybe I have multiple petabytes. So you want this ability to scale upwards,",
    "start": "161400",
    "end": "168930"
  },
  {
    "text": "but then to scale back down\nwhen it's not necessary. So that core elasticity that you get",
    "start": "168930",
    "end": "174210"
  },
  {
    "text": "with the cloud is super valuable. So we want that scalability\nand that elasticity.",
    "start": "174210",
    "end": "179343"
  },
  {
    "text": "You want your data prep\nto be reliable. (chuckles) You want this thing to not go down.",
    "start": "180600",
    "end": "185880"
  },
  {
    "text": "You wanna be able to trust it. You wanna know that when you hit it from end number of ways,\nit's still gonna be there.",
    "start": "185880",
    "end": "192930"
  },
  {
    "text": "So you want a reliable data store. You want data preparation to be usable",
    "start": "192930",
    "end": "198300"
  },
  {
    "text": "like it should be, have\ngood usability, (chuckles) like the user experience should be fun,",
    "start": "198300",
    "end": "204510"
  },
  {
    "text": "should be enticing, should\nbe easy, should be intuitive. And then you want data\nprep to be easy to manage.",
    "start": "204510",
    "end": "210900"
  },
  {
    "text": "So you want all of it to be\nstraightforward and simple",
    "start": "210900",
    "end": "215900"
  },
  {
    "text": "and you know, intuitive and easy to track it and to manage it.",
    "start": "216210",
    "end": "222093"
  },
  {
    "text": "So you have a ton of ways\n(chuckles) to do this on AWS. There are many,",
    "start": "223260",
    "end": "228653"
  },
  {
    "text": "many different data\npreparation options on AWS. For the purposes of time,\nI am just gonna laser focus",
    "start": "228653",
    "end": "236489"
  },
  {
    "text": "on these top four. So we're gonna look at S3 buckets. We're gonna look at storing images in ECR.",
    "start": "236490",
    "end": "243659"
  },
  {
    "text": "We're gonna create FSx Lustre and we're gonna use SageMaker. But that being said, I\nmean, again, there are a lot",
    "start": "243660",
    "end": "249870"
  },
  {
    "text": "of really good options and you might end up using those options for when you're storing\neven larger datasets, such",
    "start": "249870",
    "end": "257176"
  },
  {
    "text": "as with Redshift, if you're\ncreating a data catalog, such as with glue, if you're\nrunning EMR processing",
    "start": "257176",
    "end": "264360"
  },
  {
    "text": "with Amazon EMR, if you're\njust spinning up instances, if you're storing in\nDynamoDB in Aurora or Athena,",
    "start": "264360",
    "end": "272759"
  },
  {
    "text": "if you're creating a dashboard. So you have, again, a lot of\noptions for data prep on AWS,",
    "start": "272760",
    "end": "278669"
  },
  {
    "text": "and I'm just gonna laser\nfocus in on these four, but the other ones are really awesome.",
    "start": "278670",
    "end": "283780"
  },
  {
    "text": "All right, so how are we\ngonna do this? So steps. So again, step one, it's just\nidentify and store your data.",
    "start": "284940",
    "end": "292410"
  },
  {
    "text": "Park that in your S3 buckets,\nmake sure you have data in S3, which sometimes\nis harder than it sounds,",
    "start": "292410",
    "end": "300900"
  },
  {
    "text": "but other times is as easy as I'm just gonna upload the thing or I'm just gonna do a copy. So nice and straightforward.\nSo you've got data in S3.",
    "start": "300900",
    "end": "307983"
  },
  {
    "text": "I always start with collecting\nlike a tiny sample of this. So I'll spin up a notebook",
    "start": "309180",
    "end": "314190"
  },
  {
    "text": "on some CPUs, I'll just\nload pandas, just port",
    "start": "314190",
    "end": "319190"
  },
  {
    "text": "to a small sample of this dataset. Run some analysis and pandas just",
    "start": "320340",
    "end": "326100"
  },
  {
    "text": "to get a good understanding of what this dataset looks like. After that, then we're gonna create",
    "start": "326100",
    "end": "333510"
  },
  {
    "text": "a distributed file system. So in particular we'll use FSx for Lustre",
    "start": "333510",
    "end": "338639"
  },
  {
    "text": "and you're gonna learn how\nto do that in this video. You're gonna create an\nFSx for Lustre volume",
    "start": "338640",
    "end": "344759"
  },
  {
    "text": "with all of this data. So the reason we're gonna do this is that copying data is very, very slow",
    "start": "344760",
    "end": "352919"
  },
  {
    "text": "and is very error prone. And not every use case is\nwell solved by data streaming.",
    "start": "352920",
    "end": "359690"
  },
  {
    "text": "Particular neural network\noptimization is quite challenging to write with streaming.",
    "start": "359730",
    "end": "365789"
  },
  {
    "text": "And you still might encounter\nthe case where everyone is pointing to the same, where all of your accelerators are pointing",
    "start": "365790",
    "end": "372630"
  },
  {
    "text": "to the same files, which\nthen causes read conflict. So in any case, distributed\nfile systems are a great way",
    "start": "372630",
    "end": "380460"
  },
  {
    "text": "to take one piece of data,\none object or terabytes",
    "start": "380460",
    "end": "385460"
  },
  {
    "text": "of objects, park those in a single spot, and then scale throughput actually",
    "start": "385950",
    "end": "391889"
  },
  {
    "text": "as a function of all of your accelerators. So you can have one object",
    "start": "391890",
    "end": "397980"
  },
  {
    "text": "or one set of data with number of mounts. So there will be actually as many mounts",
    "start": "397980",
    "end": "404100"
  },
  {
    "text": "as there are accelerators. And the whole thing sort of scales with this entire processes.",
    "start": "404100",
    "end": "409290"
  },
  {
    "text": "So it's much easier to interact with when you're running a\nlarge scale distributed system.",
    "start": "409290",
    "end": "414930"
  },
  {
    "text": "So once you have your\ndistributed file system built, I love using warm pools.",
    "start": "414930",
    "end": "421020"
  },
  {
    "text": "Warm pools on SageMaker is so nice. Basically you're running training jobs and then you add this one\nparameter, keep alive period",
    "start": "421020",
    "end": "429570"
  },
  {
    "text": "in seconds (chuckles) is\nthe name of this parameter. And then you'll run these\nnew training jobs where",
    "start": "429570",
    "end": "437360"
  },
  {
    "text": "the instances just stay warm. So as you run new scripts,\nthe instances are still alive.",
    "start": "437580",
    "end": "443340"
  },
  {
    "text": "And so they're perfect for\ndeveloping and testing because as you're iterating through your cycle,",
    "start": "443340",
    "end": "449785"
  },
  {
    "text": "the instance is just\nliterally still there. And so you can ship a new line of code in seconds and it's beautiful.",
    "start": "449786",
    "end": "457380"
  },
  {
    "text": "So manage warm pools. And so you'll run manage warm pools on your FSx for Lustre volume",
    "start": "457380",
    "end": "463800"
  },
  {
    "text": "to develop this training script. And then once it's developed,\nthen again you'll scale",
    "start": "463800",
    "end": "468840"
  },
  {
    "text": "up those training and processing runs. So you'll go from just\nwhat we proposed last time",
    "start": "468840",
    "end": "474870"
  },
  {
    "text": "in the phases. You'll do your first run with like one GPU or one accelerator, then you'll move up",
    "start": "474870",
    "end": "481320"
  },
  {
    "text": "to eight, then you'll move up to two nodes, then maybe you'll move up to 16 nodes or 64 nodes or\nhowever large you want to go.",
    "start": "481320",
    "end": "490050"
  },
  {
    "text": "And then at each phase,\nagain, you're just evaluating that model artifact and downloading it so",
    "start": "490050",
    "end": "496393"
  },
  {
    "text": "that you know you can trust\nit and then it's working. So let's learn how to do this.",
    "start": "496393",
    "end": "500640"
  },
  {
    "text": "All right, so step one,\nobviously S3 is great. (chuckles)",
    "start": "501900",
    "end": "506900"
  },
  {
    "text": "Let's be real. S3 is really good, right? You can upload data in S3, you can do it",
    "start": "507600",
    "end": "512969"
  },
  {
    "text": "in the web browser, you\ncan do it with your SDK, you can do it with your CLI,\nyou can do it with an API.",
    "start": "512970",
    "end": "519300"
  },
  {
    "text": "You can download straight to S3 when you're doing web scraping or if you're doing any other\nlarge scale data processing.",
    "start": "519300",
    "end": "527040"
  },
  {
    "text": "Tons of features for management, for security, access control.",
    "start": "527040",
    "end": "532050"
  },
  {
    "text": "S3 is, so we call this\n11 9s of durability. So that means 99 point and then nine more",
    "start": "532050",
    "end": "541079"
  },
  {
    "text": "of these things is how durable S3 is. So you're gonna be able to\nget your files in a year",
    "start": "541080",
    "end": "548430"
  },
  {
    "text": "with a tiny, tiny, tiny\nmoment of downtime. And also what's nice about\nS3 is you do not need",
    "start": "548430",
    "end": "557089"
  },
  {
    "text": "to provision a thing. The user experience (chuckles)\nis so on point with S3",
    "start": "557089",
    "end": "564720"
  },
  {
    "text": "because you just create a\nbucket, you can put literally as much data in this bucket as you want to",
    "start": "564720",
    "end": "571470"
  },
  {
    "text": "and there is no end. (chuckles) Like you can put as much data volume",
    "start": "571470",
    "end": "576660"
  },
  {
    "text": "in S3 as you want to. You don't have to provision\nanything, you don't have to manage instances, you don't have to",
    "start": "576660",
    "end": "583620"
  },
  {
    "text": "like lifecycle a piece, you just drop it in S3 and it's happy.",
    "start": "583620",
    "end": "589829"
  },
  {
    "text": "So step one is get your\nS3 bucket online, create",
    "start": "589830",
    "end": "594830"
  },
  {
    "text": "that thing, get your data loaded into S3. And then yeah, we're gonna\nmount a distributed file system.",
    "start": "595860",
    "end": "604440"
  },
  {
    "text": "So the distributed file\nsystem is gonna read from S3.",
    "start": "604440",
    "end": "609440"
  },
  {
    "text": "So it's gonna read from\nS3, the processing jobs and the training jobs can run here.",
    "start": "609810",
    "end": "616530"
  },
  {
    "text": "And then when you write to Lustre, when you enable\nthe two-way replication, it'll copy it back to\nS3, so it's really nice.",
    "start": "616530",
    "end": "625140"
  },
  {
    "text": "And then for your data processing, you can do your data processing straight from S3 as well.",
    "start": "625140",
    "end": "631320"
  },
  {
    "text": "You could do your data\nprocessing to Lustre. It depends on if you already\nhave it created or not.",
    "start": "631320",
    "end": "638519"
  },
  {
    "text": "Once you have Lustre created then and you have this two-way\ndata repository created,",
    "start": "638520",
    "end": "644910"
  },
  {
    "text": "then the two are kind of interchangeable. You just need to make sure that once you have something written",
    "start": "644910",
    "end": "650100"
  },
  {
    "text": "to one place that the\nreplication job has happened, which should be automatic. But yeah, so you can run processing jobs",
    "start": "650100",
    "end": "657000"
  },
  {
    "text": "and point those to S3,\nwhatever works for you. So step one is just\ngetting your data stored.",
    "start": "657000",
    "end": "663153"
  },
  {
    "text": "Step two, again, is we're\ngonna sample our dataset and we're gonna analyze that thing.",
    "start": "664170",
    "end": "669900"
  },
  {
    "text": "So again, I like to\nstart with my data in S3. I'll store a sample of data in S3",
    "start": "669900",
    "end": "676079"
  },
  {
    "text": "and then I'm gonna pull a\nsmall sample from that thing. So I'll pull my 1%, my 2% data sample,",
    "start": "676080",
    "end": "683370"
  },
  {
    "text": "something really small and I'll\njust pop it on my notebook. Again, notebooks, you can run those on your laptops, you can run those",
    "start": "683370",
    "end": "690120"
  },
  {
    "text": "on SageMaker instances, you can run those on other instances.",
    "start": "690120",
    "end": "694323"
  },
  {
    "text": "It's completely up to you. Notebooks are great as a\nBrian Granger co-founder",
    "start": "695220",
    "end": "700230"
  },
  {
    "text": "of Jupyter, who's a senior\nprincipal technologist at SageMaker. He likes to say that the\nprimary verb that we use",
    "start": "700230",
    "end": "708270"
  },
  {
    "text": "to describe Jupyter Notebooks\nis to think (chuckles) like Jupyter Notebooks are here",
    "start": "708270",
    "end": "714150"
  },
  {
    "text": "to help you think actually\nmore than anything. So you can use a notebook to\ntest a couple lines of code",
    "start": "714150",
    "end": "721470"
  },
  {
    "text": "and analyze and assess and\nunderstand what your dataset is,",
    "start": "721470",
    "end": "726470"
  },
  {
    "text": "why it's composed that way, what to do. So you can run your notebook",
    "start": "726600",
    "end": "731910"
  },
  {
    "text": "on your small data sample using SageMaker or using any instance.",
    "start": "731910",
    "end": "738329"
  },
  {
    "text": "Again, I'm gonna run Python code there to just understand and inspect my dataset. You can detect bias in your datasets.",
    "start": "738330",
    "end": "746790"
  },
  {
    "text": "You can work with small model versions. You might do some prompt engineering. You might do some lightweight fine tuning.",
    "start": "746790",
    "end": "753600"
  },
  {
    "text": "And you can also use this new\n@remote decorator to scale. So for SageMaker as of a couple\nmonths ago, you can add this",
    "start": "753600",
    "end": "762907"
  },
  {
    "text": "@remote decorator to local functions and those will actually\nrun on training jobs.",
    "start": "762907",
    "end": "767910"
  },
  {
    "text": "So we'll actually like\nlook at your configuration and then run a SageMaker training job",
    "start": "767910",
    "end": "773399"
  },
  {
    "text": "in the backend taking this function. So definitely you could use that here. So that's step two is we\nsample and we analyze.",
    "start": "773400",
    "end": "780602"
  },
  {
    "text": "And then step three is\nwe're gonna actually create a distributed file system.",
    "start": "781960",
    "end": "787440"
  },
  {
    "text": "So in the AWS console, my\ngo-to way of doing this,",
    "start": "787440",
    "end": "792440"
  },
  {
    "text": "I'll just go to the Lustre console page and click create an FSx for Lustre volume.",
    "start": "792840",
    "end": "800010"
  },
  {
    "text": "Lustre will prompt you for what's called a VPC,\na virtual private cloud.",
    "start": "800010",
    "end": "805456"
  },
  {
    "text": "If you're new to this, you\ncan just use the default VPC, every account chips with a default VPC.",
    "start": "805456",
    "end": "811740"
  },
  {
    "text": "So feel free to use that. Otherwise you may have like a specific VPC",
    "start": "811740",
    "end": "818310"
  },
  {
    "text": "with specific subnets and\navailability zones with capacity. So yeah, definitely something to consider.",
    "start": "818310",
    "end": "825772"
  },
  {
    "text": "But in any case, you'll create\nyour FSx for Lustre volume. While you're creating this\nvolume, you're gonna point",
    "start": "825772",
    "end": "833970"
  },
  {
    "text": "to an S3 bucket actually. So you can point to an S3 bucket",
    "start": "833970",
    "end": "839280"
  },
  {
    "text": "that again has all of your data stored. So this might have your two terabytes",
    "start": "839280",
    "end": "844770"
  },
  {
    "text": "of text files or your 200 terabytes of image files, whichever way you feel.",
    "start": "844770",
    "end": "852390"
  },
  {
    "text": "And then, yeah, when you enable this two-way data repository,\nthere will be a connection",
    "start": "852390",
    "end": "859350"
  },
  {
    "text": "that's established between FSx\nfor Lustre and your bucket. And this is a two-way data repository.",
    "start": "859350",
    "end": "865410"
  },
  {
    "text": "So as new files are written to S3, these are automatically\nreplicated to Lustre.",
    "start": "865410",
    "end": "874760"
  },
  {
    "text": "And then the second way is the reverse. So as you for example,\nwrite model checkpoints",
    "start": "875640",
    "end": "881430"
  },
  {
    "text": "to Lustre, those will\nthen be sent back to S3 and they'll be made available. So it has that really nice\ntwo-way replication. Great.",
    "start": "881430",
    "end": "889907"
  },
  {
    "text": "And so then once you have Lustre set, you can actually mount this\nLustre volume to a notebook.",
    "start": "891690",
    "end": "899100"
  },
  {
    "text": "So you could mount that to a\nSageMaker notebook instance for example, just as long\nas that notebook instance is",
    "start": "899100",
    "end": "906300"
  },
  {
    "text": "in the same VPC. So you want to make sure\nthat it's in the same VPC.",
    "start": "906300",
    "end": "912090"
  },
  {
    "text": "You might do this in the same\nsubnet and then just make sure that the two pieces\ncan talk to each other.",
    "start": "912090",
    "end": "919023"
  },
  {
    "text": "Go get some routing friends (chuckles) to help you stand this up. Yeah, there are a couple pro tips",
    "start": "919920",
    "end": "927630"
  },
  {
    "text": "to connect these two things. But, so in any case, you'll\nget your notebook stood up, you can mount the Lustre volume",
    "start": "927630",
    "end": "935190"
  },
  {
    "text": "and then analyze it right there. Using SageMaker is really\nnice for this as well",
    "start": "935190",
    "end": "940980"
  },
  {
    "text": "because it's very easy to\nmove up to a bigger instance. So for your notebook instance,\nyou can turn the thing off",
    "start": "940980",
    "end": "948540"
  },
  {
    "text": "and then recreate it with a larger volume. Or alternatively, you\ncan use SageMaker studio,",
    "start": "948540",
    "end": "955920"
  },
  {
    "text": "which just lets you click a\nbutton and then switch out to a larger instance type. So it's really nice.",
    "start": "955920",
    "end": "961263"
  },
  {
    "text": "So a couple pro tips for\nusing FSx for Lustre. Again, it just takes a couple minutes",
    "start": "962220",
    "end": "967740"
  },
  {
    "text": "to create FSx for Lustre in the console. And then yeah, just follow guides to do this in your preferred VPC.",
    "start": "967740",
    "end": "975720"
  },
  {
    "text": "Make sure you're tracking\nyour security groups, your ACLs, things like this.",
    "start": "975720",
    "end": "981333"
  },
  {
    "text": "One word of caution\nhere is Lustre is going to copy all of the file\nnames onto the mount.",
    "start": "982290",
    "end": "989990"
  },
  {
    "text": "So the mount here, the\nvolume is gonna have all of the file names, you need",
    "start": "990750",
    "end": "996029"
  },
  {
    "text": "to actually run a CPU based\njob to read all of those. It doesn't have to literally be CPU,",
    "start": "996030",
    "end": "1001463"
  },
  {
    "text": "it's just a lot more cost\neffective to do this. So you run a CPU job to read all of those.",
    "start": "1001463",
    "end": "1009350"
  },
  {
    "text": "When you read it, Lustre\nwill manage the copy and then the file sits there.",
    "start": "1009350",
    "end": "1014389"
  },
  {
    "text": "And then the read is scalable\nwith all of your accelerators.",
    "start": "1014390",
    "end": "1019390"
  },
  {
    "text": "So definitely something to note. Yeah, and then you can mount\nthe notebook, mount the volume from the notebook in\nyour same VPC to test.",
    "start": "1020000",
    "end": "1026930"
  },
  {
    "text": "So that's how to create a\ndistributed file system such as FSx for Lustre and then\nmount a notebook to this",
    "start": "1026930",
    "end": "1035725"
  },
  {
    "text": "to test it and analyze your data. All right, and so once you\nhave your data actually mounted",
    "start": "1036470",
    "end": "1045799"
  },
  {
    "text": "in this file system, rather\nonce you have your data in the file system, you're\nready to do things with this.",
    "start": "1045800",
    "end": "1052910"
  },
  {
    "text": "And so remember we learned\nabout job parallelism in the previous YouTube video\nand here we're gonna use",
    "start": "1052910",
    "end": "1060980"
  },
  {
    "text": "that job parallelism, but just\nto process our data at scale. So remember we're going to\nuse CPUs to keep costs low",
    "start": "1060980",
    "end": "1069080"
  },
  {
    "text": "and you might use this process to,",
    "start": "1069080",
    "end": "1074002"
  },
  {
    "text": "or this job parallelism framework to run a lot of data processing.",
    "start": "1075020",
    "end": "1080870"
  },
  {
    "text": "So if you have say like 18 parquet files like I did when I was fine\ntuning a stable diffusion with",
    "start": "1080870",
    "end": "1088370"
  },
  {
    "text": "like 10 million, 50\nmillion image taxpayers as one does, then yeah, I ended\nup using 18 different jobs.",
    "start": "1088370",
    "end": "1096430"
  },
  {
    "text": "So I had 18 SageMaker jobs where each one of them used a different\nparquet file and then on each",
    "start": "1098240",
    "end": "1105770"
  },
  {
    "text": "of the jobs they were then\nrunning multi-processing CPU to go out to the internet,\ncopy the images (chuckles)",
    "start": "1105770",
    "end": "1113870"
  },
  {
    "text": "and then download those\nlocally and do any processing. So definitely you can use\nsort of this job parallelism",
    "start": "1113870",
    "end": "1122930"
  },
  {
    "text": "framework on SageMaker\nto easily process all of your instances. Again, use CPUs for this.",
    "start": "1122930",
    "end": "1130220"
  },
  {
    "text": "Do not use, use GPUs, it's too expensive. And then you can also\nuse the C instance series",
    "start": "1130220",
    "end": "1139480"
  },
  {
    "text": "is really nice for compute\noptimized, it's perfect for data processing. So, it'll run really nicely for you.",
    "start": "1140060",
    "end": "1147260"
  },
  {
    "text": "The M is like a little bit too expensive. I mean the M series is\nnice, but the C series is like perfect for this type\nof heavy compute workloads.",
    "start": "1147260",
    "end": "1155632"
  },
  {
    "text": "All right, so, you now you\nhave your data pre-processed.",
    "start": "1157370",
    "end": "1162370"
  },
  {
    "text": "Maybe you trained a tokenize. Maybe you processed the tokens. Maybe you downloaded your images.",
    "start": "1163850",
    "end": "1171013"
  },
  {
    "text": "You have your data pre-processed and now we're ready to run some training. Again, I strongly recommend",
    "start": "1171013",
    "end": "1177470"
  },
  {
    "text": "in SageMaker adding this new parameter keep alive period in seconds.",
    "start": "1177470",
    "end": "1184040"
  },
  {
    "text": "This is also called, again,\nwarm pools is the name of this feature. And warm pools will literally\nkeep your instances warm.",
    "start": "1184040",
    "end": "1192590"
  },
  {
    "text": "So while you're writing your\nlocal scripts, you're doing, you know, again, basic\ndeveloping tasks, you have these,",
    "start": "1192590",
    "end": "1199970"
  },
  {
    "text": "forward and backward\npasses this training loop that's running and this is running on your SageMaker training instances",
    "start": "1199970",
    "end": "1206390"
  },
  {
    "text": "when you wanna scale it on AWS. When you add this new\nparameter, keep alive period",
    "start": "1206390",
    "end": "1211730"
  },
  {
    "text": "in seconds, your instances\nactually stay warm. So your instances are\njust still there, even",
    "start": "1211730",
    "end": "1219200"
  },
  {
    "text": "after the job finishes up\nto this max time of an hour. And then after the script breaks again",
    "start": "1219200",
    "end": "1227540"
  },
  {
    "text": "because we typed in something wrong or the syntax changed, then\nthe instances are still there.",
    "start": "1227540",
    "end": "1234725"
  },
  {
    "text": "It's just the nicest thing. And so, yeah, so then you go back",
    "start": "1236060",
    "end": "1242118"
  },
  {
    "text": "to your script once you\nrealize something broke. You update your two three\nlines of code, click go,",
    "start": "1242118",
    "end": "1248630"
  },
  {
    "text": "and then it runs again on\nthose training instances and you're only waiting a couple seconds",
    "start": "1248630",
    "end": "1255410"
  },
  {
    "text": "for your new job to run. Previously you were\nwaiting multiple minutes for the new job to run.",
    "start": "1255410",
    "end": "1261890"
  },
  {
    "text": "Worst case scenario you were\nwaiting a solid eight minutes and even more 'cause\nyou'd have to wait for",
    "start": "1261890",
    "end": "1267020"
  },
  {
    "text": "that first instance to\nactually stop (chuckles) for the data to get\ndownloaded or the model",
    "start": "1267020",
    "end": "1272690"
  },
  {
    "text": "to get uploaded if there was one. And then you're turning\non the new instance. So anyway, this is much better.",
    "start": "1272690",
    "end": "1278740"
  },
  {
    "text": "All right, so that's using\nSageMaker warm pools, right?",
    "start": "1280460",
    "end": "1285460"
  },
  {
    "text": "And we'll use warm pools\nto develop and test. Then we're gonna mount this\ndistributed file system",
    "start": "1286040",
    "end": "1292250"
  },
  {
    "text": "to SageMaker training. So we have this file system created",
    "start": "1292250",
    "end": "1297710"
  },
  {
    "text": "and we're going to pass this file system as an input to SageMaker training.",
    "start": "1297710",
    "end": "1303290"
  },
  {
    "text": "So we're gonna set our\nfile system settings. So again, that file\nsystem ID, security group,",
    "start": "1303290",
    "end": "1309710"
  },
  {
    "text": "the subnet and the mount name. So you wanna capture all of these things when you are\ncreating that Lustre volume.",
    "start": "1309710",
    "end": "1318443"
  },
  {
    "text": "You need to pass VPC configs as well. So to your SageMaker\ntraining job, you need",
    "start": "1319610",
    "end": "1324710"
  },
  {
    "text": "to pass your VPC subnet\nand your security group.",
    "start": "1324710",
    "end": "1329303"
  },
  {
    "text": "You need to create an S3 VPC endpoint.",
    "start": "1330260",
    "end": "1333923"
  },
  {
    "text": "In order for the SageMaker\ntraining resources",
    "start": "1336500",
    "end": "1341500"
  },
  {
    "text": "that are training in your VPC for them to be able to write to\nS3 at the completion",
    "start": "1341870",
    "end": "1347630"
  },
  {
    "text": "of the job, which they\nwill try to do, you have to actually create an S3\nendpoint from the VPC.",
    "start": "1347630",
    "end": "1354530"
  },
  {
    "text": "And then this way everything\ncan train inside of the VPC. So you create this endpoint",
    "start": "1354530",
    "end": "1359520"
  },
  {
    "text": "and then we gotta update the VPC rules to ensure that there is a\nNAT gateway and that the ACLs",
    "start": "1360890",
    "end": "1369500"
  },
  {
    "text": "and route tables are all\nflowing like a river. (chuckles) So basically, you need\nyour instances to be able",
    "start": "1369500",
    "end": "1376730"
  },
  {
    "text": "to hit the internet\ngateway that is in your VPC",
    "start": "1376730",
    "end": "1381730"
  },
  {
    "text": "by writing to the same route table. I am not a networking pro. (chuckles)",
    "start": "1383787",
    "end": "1388790"
  },
  {
    "text": "I love my networking\nfriends, you should too. And so yeah, great. So then we create a data channel",
    "start": "1388790",
    "end": "1396679"
  },
  {
    "text": "and we're going to create data channels that point to, again, our\ntraining files, actually.",
    "start": "1396680",
    "end": "1403880"
  },
  {
    "text": "So a training channel. So here for example, in this little SageMaker screenshot here,",
    "start": "1403880",
    "end": "1410270"
  },
  {
    "text": "we have a data channel\nand we are creating two. So one is literally called train",
    "start": "1410270",
    "end": "1416930"
  },
  {
    "text": "and the other is literally called test. And so that's two data channels.",
    "start": "1416930",
    "end": "1422030"
  },
  {
    "text": "In this case, they're\nboth actually pointing to this file system ID. So they're pointing to\nthis Lustre file system ID,",
    "start": "1422030",
    "end": "1429765"
  },
  {
    "text": "I like actually passing\nmy model as a channel. I find it a lot easier because then inside",
    "start": "1429765",
    "end": "1437210"
  },
  {
    "text": "of the training scripts,\nyou're gonna point to those channels. Inside the training script it actually",
    "start": "1437210",
    "end": "1444530"
  },
  {
    "text": "is an environment variable. So you point inside the scripts\nto an environment variable",
    "start": "1444530",
    "end": "1449810"
  },
  {
    "text": "that lets you read from\nthe training channel and that lets you read your model.",
    "start": "1449810",
    "end": "1455210"
  },
  {
    "text": "So I find it very\nintuitive to pass the model",
    "start": "1455210",
    "end": "1460210"
  },
  {
    "text": "as a train channel in addition to obviously your training files. So you'll do that, then\nyou send the configs",
    "start": "1460730",
    "end": "1468460"
  },
  {
    "text": "to the trainee job and you click run. And this is the beauty of it\nis it's gonna mount in seconds.",
    "start": "1468460",
    "end": "1474380"
  },
  {
    "text": "So if you were not doing Lustre, if you were copying your files from S3",
    "start": "1474380",
    "end": "1481455"
  },
  {
    "text": "to SageMaker, if you\nhave multiple hundreds of GBS, it will take\nhours to just sit there",
    "start": "1481456",
    "end": "1488630"
  },
  {
    "text": "and copy your files,\nwhich you don't wanna pay for if you're in a GPU world.",
    "start": "1488630",
    "end": "1493810"
  },
  {
    "text": "So definitely Lustre is strongly\npreferred for that reason.",
    "start": "1493810",
    "end": "1498413"
  },
  {
    "text": "All right, and then again, one word of caution here, your pro tip,\nplease remember. (chuckles)",
    "start": "1499880",
    "end": "1506540"
  },
  {
    "text": "So you need to hydrate your Lustre volume with the actual data. So when you create your\nLustre volume in the console,",
    "start": "1506540",
    "end": "1514490"
  },
  {
    "text": "that is not copying all of the data that is just creating the metadata.",
    "start": "1514490",
    "end": "1522290"
  },
  {
    "text": "So the metadata is available on Lustre the minute it's created. But you need to hydrate the Lustre volume",
    "start": "1522290",
    "end": "1529670"
  },
  {
    "text": "with the actual data. So I like to run a CPU job\nto hit my Lustre volume.",
    "start": "1529670",
    "end": "1536090"
  },
  {
    "text": "That just reads like you\njust read the file on Lustre",
    "start": "1536090",
    "end": "1541090"
  },
  {
    "text": "and then Lustre manages the copy. So you read it from Lustre\nthat manages the copy over",
    "start": "1542750",
    "end": "1549529"
  },
  {
    "text": "to the volume and use CPUs for that thing. 'Cause that's gonna be a\ntiny fraction of the cost.",
    "start": "1549530",
    "end": "1555560"
  },
  {
    "text": "Honestly, you can use small CPUs for that. 'Cause your CPU is literally just reading. So, it can be a very inexpensive job,",
    "start": "1555560",
    "end": "1562580"
  },
  {
    "text": "but just remember to hydrate that thing. All right and so once we have\nour training scripts built",
    "start": "1562580",
    "end": "1571600"
  },
  {
    "text": "and we have our Lustre volume mounted to our training instances",
    "start": "1571660",
    "end": "1576830"
  },
  {
    "text": "and we have our training loop built because we were using warm pools, now we're gonna run the job",
    "start": "1576830",
    "end": "1582530"
  },
  {
    "text": "and we wanna monitor the performance and we wanna troubleshoot\nanything that's going wrong. So your training instances are up, right?",
    "start": "1582530",
    "end": "1589670"
  },
  {
    "text": "And they're storing all of your metadata. So they're storing the image URI",
    "start": "1589670",
    "end": "1595310"
  },
  {
    "text": "and the hyper parameters\nand the job configs, all that's available in the\nSageMaker control plane.",
    "start": "1595310",
    "end": "1601760"
  },
  {
    "text": "So if you need to search for any buckets or any metrics, those are available.",
    "start": "1601760",
    "end": "1607302"
  },
  {
    "text": "You can add all of the metrics that you care about to\nCloudWatch actually.",
    "start": "1607302",
    "end": "1613130"
  },
  {
    "text": "So in your SageMaker\ntraining instance, everything that you write to logging,\neverything that you print",
    "start": "1613130",
    "end": "1620390"
  },
  {
    "text": "to standard outs, that\nwill show up in CloudWatch. So you can always like\nhead over to CloudWatch",
    "start": "1620390",
    "end": "1627980"
  },
  {
    "text": "to view the action, see the play by play and see what's happening in\nyour training environment.",
    "start": "1627980",
    "end": "1636350"
  },
  {
    "text": "Yeah, so all the metadata again, is stored in SageMaker control plane. Once you're there, you can\neasily do a one click hop over",
    "start": "1636350",
    "end": "1643700"
  },
  {
    "text": "to CloudWatch and see all\nthe logs for that instance.",
    "start": "1643700",
    "end": "1648700"
  },
  {
    "text": "And it's really nice. So,\nthat's a very nice experience. And then your training\ninstances are up, they're happy,",
    "start": "1648800",
    "end": "1655549"
  },
  {
    "text": "they're running, they're\nstoring your metadata, they're streaming your logs. And then your training instances\nare literally reading from",
    "start": "1655550",
    "end": "1663260"
  },
  {
    "text": "and writing to your Lustre\ndistributed file system. So your training instances,\nagain are connected",
    "start": "1663260",
    "end": "1670550"
  },
  {
    "text": "to this Lustre volume. And you're like literally\nreading your files.",
    "start": "1670550",
    "end": "1676430"
  },
  {
    "text": "You're passing your files\nthrough mini batches through your training loop. You're writing checkpoints and\nthen writing those to Lustre.",
    "start": "1676430",
    "end": "1686300"
  },
  {
    "text": "Lustre then copies that\nout to S3 on your behalf and then you can run TensorBoard\nfrom those checkpoints.",
    "start": "1686300",
    "end": "1693560"
  },
  {
    "text": "So you can download and analyze those model artifacts from S3.",
    "start": "1693560",
    "end": "1700360"
  },
  {
    "text": "So yeah, you can run\nTensorBoard, you can run any type of analysis frameworks or\nnotebooks off of that to make sure",
    "start": "1700850",
    "end": "1708474"
  },
  {
    "text": "that your model is trending\nin the right direction that you're happy with it. A couple other things you\ncan do, again, view the logs.",
    "start": "1708980",
    "end": "1716780"
  },
  {
    "text": "So you can go into the AWS console, click into your SageMaker training\nlogs page and just watch.",
    "start": "1716780",
    "end": "1724990"
  },
  {
    "text": "Like (chuckles) you could look\nat CloudWatch and just see like, oh, it PIP\ninstalled my requirements.",
    "start": "1725090",
    "end": "1731030"
  },
  {
    "text": "Here are all of the environment variables. Here's how SageMaker executed my script.",
    "start": "1731030",
    "end": "1737210"
  },
  {
    "text": "Here are all of the\naccelerators that it's using. It's a beautiful thing. So you can definitely view\nthe whole process just",
    "start": "1737210",
    "end": "1743870"
  },
  {
    "text": "in CloudWatch. You can read error\nstatements in CloudWatch. Again, so if and when jobs fail,",
    "start": "1743870",
    "end": "1750230"
  },
  {
    "text": "and fail they will, as Werner Vogels love to say, \"Everything fails all the time.\"",
    "start": "1750230",
    "end": "1755750"
  },
  {
    "text": "And so yeah, you can read\nthe error statements. The error statements can come\nin from your training scripts.",
    "start": "1755750",
    "end": "1762274"
  },
  {
    "text": "They could come in, maybe there was a GPU that went south somewhere\nin your training instance.",
    "start": "1762274",
    "end": "1768140"
  },
  {
    "text": "And so you can read those\nand then if it's an error on your side, then you can\ngo and update your scripts.",
    "start": "1768140",
    "end": "1776180"
  },
  {
    "text": "Point to something,\nreconfigure it, get it online. If it's something that's\noutside of your control,",
    "start": "1776180",
    "end": "1781490"
  },
  {
    "text": "like an internal service error\nor some other unknown issue,",
    "start": "1781490",
    "end": "1786132"
  },
  {
    "text": "then you can create a support ticket. So right inside of the\nconsole you can go over",
    "start": "1787730",
    "end": "1793309"
  },
  {
    "text": "to support, click create a support ticket, and then yeah, we'll be online",
    "start": "1793310",
    "end": "1799070"
  },
  {
    "text": "and we'll help you troubleshoot and figure out what's going on. Yes, and then the top question, what",
    "start": "1799070",
    "end": "1805790"
  },
  {
    "text": "if my instances go down? (laughs) So accelerators, GPUs,",
    "start": "1805790",
    "end": "1812300"
  },
  {
    "text": "are a super complex distributed systems. While a single CPU, a\nCPU chip is gonna have",
    "start": "1812300",
    "end": "1819500"
  },
  {
    "text": "like a few blocks in it, it's got like a few caches wherein\nit can do, you know,",
    "start": "1819500",
    "end": "1827530"
  },
  {
    "text": "sort of processing for just a few objects like holding clicks in\nmemory, for example.",
    "start": "1827810",
    "end": "1834260"
  },
  {
    "text": "It's great at that, but it's\nnot great at throughput. A GPU and an accelerator is\nuseful because it's massive.",
    "start": "1834260",
    "end": "1843440"
  },
  {
    "text": "You have tens of thousands of\ncores that are sitting inside of this super complex distributed system.",
    "start": "1843440",
    "end": "1850250"
  },
  {
    "text": "And so the software that runs on top of an accelerator is\ntrying to maintain those",
    "start": "1850250",
    "end": "1855950"
  },
  {
    "text": "and is trying to keep them\nhealthy and keep them active and let you run your PyTorch software",
    "start": "1855950",
    "end": "1863120"
  },
  {
    "text": "or your neural network\nsoftware on top of it. Using hundreds and thousands\nof accelerators increases the",
    "start": "1863120",
    "end": "1871130"
  },
  {
    "text": "likelihood of even one\nof those going down. So as you scale your overall\ntraining cluster size,",
    "start": "1871130",
    "end": "1878350"
  },
  {
    "text": "once you're hitting, you\nknow, 20, 40, 60 instances,",
    "start": "1878690",
    "end": "1883690"
  },
  {
    "text": "which is a couple hundred accelerators and then some, the\nlikelihood that even one",
    "start": "1884030",
    "end": "1890000"
  },
  {
    "text": "of those chips is gonna break goes down. And so managed services are a nice way",
    "start": "1890000",
    "end": "1896990"
  },
  {
    "text": "to get this enhanced reliability. So we run again, GPU health checks ahead",
    "start": "1896990",
    "end": "1903080"
  },
  {
    "text": "of launching the instances. So that gives you a nice way to ensure that the instances you're\nreceiving, the GPUs,",
    "start": "1903080",
    "end": "1910190"
  },
  {
    "text": "are actually healthy, (chuckles) they're good, they're not buggy. We can replace the instances\nduring the training process.",
    "start": "1910190",
    "end": "1918260"
  },
  {
    "text": "So while the training loop is going on, we can replace those instances so",
    "start": "1918260",
    "end": "1924320"
  },
  {
    "text": "that your training\nexperience is again, A plus. And you can train this massive\nand awesome foundation model",
    "start": "1924320",
    "end": "1933110"
  },
  {
    "text": "while getting updated instances for you. We do automatic job retries.",
    "start": "1933110",
    "end": "1939620"
  },
  {
    "text": "So if you're using the\ntraining job construct in SageMaker, basically, you\ncan keep retrying. (chuckles)",
    "start": "1939620",
    "end": "1946930"
  },
  {
    "text": "You can retry your job using\nthis automatic job retry to get over the problem of\nnot finding instances or",
    "start": "1948050",
    "end": "1957620"
  },
  {
    "text": "to counter any instance errors. And then we strongly recommend\nadding model checkpoints.",
    "start": "1957620",
    "end": "1963379"
  },
  {
    "text": "So in your training scripts you\ncan add a model checkpoints. And honestly you can do\nthis every couple hours",
    "start": "1963380",
    "end": "1970340"
  },
  {
    "text": "and then just continue\ntraining from the checkpoints. So when a job fails, you can\nwrite a checkpoints maybe",
    "start": "1970340",
    "end": "1977710"
  },
  {
    "text": "before the failure, right,\nor after the failure. Like in your trading loop,\nmaybe you have a try and accept",
    "start": "1978830",
    "end": "1984920"
  },
  {
    "text": "and then you try and do your forward loop. And if you can't do that, then\njust go write a checkpoint.",
    "start": "1984920",
    "end": "1991700"
  },
  {
    "text": "And so yeah, so then you\ncheckpoint every every few hours",
    "start": "1991700",
    "end": "1996700"
  },
  {
    "text": "and then when your job\nfails, the next time you try, then just point to the checkpoints",
    "start": "1997460",
    "end": "2004060"
  },
  {
    "text": "and continue training from there. So then you get to save all\nof the work that you just did.",
    "start": "2004060",
    "end": "2009610"
  },
  {
    "text": "And lambda functions can\nreally do a lot for you. You can really make lambda\nfunctions your friends here,",
    "start": "2009610",
    "end": "2016390"
  },
  {
    "text": "while the managed service\nis doing a lot right of the, we call\nundifferentiated heavy lifting.",
    "start": "2016390",
    "end": "2023170"
  },
  {
    "text": "A lot of the labor to keep\nthe service really awesome for you, the lambda\nfunction, you can come in",
    "start": "2023170",
    "end": "2029440"
  },
  {
    "text": "and layer that thing on\ntop to monitor your jobs, to restart them on different conditions.",
    "start": "2029440",
    "end": "2035713"
  },
  {
    "text": "Like if your script airs out or if the loss does something\ncrazy, if the data looks odd,",
    "start": "2036640",
    "end": "2043800"
  },
  {
    "text": "then you can use again\nyour own lambda functions to restart the job based\non different conditions.",
    "start": "2044110",
    "end": "2050563"
  },
  {
    "text": "All right, so again, let's recap\neverything we learned here. So we talked about storing our data in S3.",
    "start": "2052450",
    "end": "2059530"
  },
  {
    "text": "We talked about collecting\na small set of data to analyze it with a notebook.",
    "start": "2059530",
    "end": "2064810"
  },
  {
    "text": "We learned how to create\na distributed file system using FSx for Lustre.",
    "start": "2064810",
    "end": "2070690"
  },
  {
    "text": "We talked about sort of mounting Lustre to the SageMaker training jobs",
    "start": "2070690",
    "end": "2077290"
  },
  {
    "text": "in particular using\nthese manage warm pools to develop a training script. Then we learned about\nscaling up the training runs.",
    "start": "2077290",
    "end": "2084429"
  },
  {
    "text": "So hitting that, you know,\n20, 40, 60 node threshold.",
    "start": "2084430",
    "end": "2089429"
  },
  {
    "text": "And then as always, take a\nlook at your model artifacts and make sure they're\ndoing the right thing.",
    "start": "2089440",
    "end": "2095000"
  },
  {
    "text": "And with that, let's\ntake a look at the demo. So you may notice that this\nis in fact the same notebook",
    "start": "2095920",
    "end": "2104820"
  },
  {
    "text": "as the one we just saw. So in the last YouTube video, number four",
    "start": "2105010",
    "end": "2110230"
  },
  {
    "text": "on pre-training foundation\nmodels, we learned generally how to get started with pre-training.",
    "start": "2110230",
    "end": "2115480"
  },
  {
    "text": "We learned about distributed\ntraining, using model and data parallel in SageMaker",
    "start": "2115480",
    "end": "2121270"
  },
  {
    "text": "and the overall training\njob construct in addition to some of the basic\npieces of functionality.",
    "start": "2121270",
    "end": "2128890"
  },
  {
    "text": "And we got a little bit\nfamiliar with this notebook. In this demo, we're going\nto use the same notebook,",
    "start": "2128890",
    "end": "2134319"
  },
  {
    "text": "but we're gonna modify it to\nuse a much larger dataset. So the dataset we're gonna\nuse is on lion, I'm sorry,",
    "start": "2134320",
    "end": "2142660"
  },
  {
    "text": "the dataset is on FSx for\nLustre and it is the web text,",
    "start": "2142660",
    "end": "2147660"
  },
  {
    "text": "so the sort of canonical GPT based dataset",
    "start": "2148690",
    "end": "2153690"
  },
  {
    "text": "that has quite a few hundreds of GBs. And so I'm gonna walk you through how",
    "start": "2154390",
    "end": "2159670"
  },
  {
    "text": "to set up FSx for Lustre\nand then mount that to your training\ninstances so you can train",
    "start": "2159670",
    "end": "2167890"
  },
  {
    "text": "on terabytes of data using SageMaker. So let's check this out.",
    "start": "2167890",
    "end": "2173473"
  },
  {
    "text": "So just one second here\nas I get my notebook over to the right screen.",
    "start": "2179250",
    "end": "2185890"
  },
  {
    "text": "All right, here we go. So FSx for Lustre is a\ndistributed file system.",
    "start": "2185890",
    "end": "2193000"
  },
  {
    "text": "And what's nice about it\nis that you can point it to a data repository on S3\nand then it manages the reads",
    "start": "2193000",
    "end": "2201690"
  },
  {
    "text": "and writes to that data\nrepository for you. And you're gonna use it for two reasons.",
    "start": "2202480",
    "end": "2208510"
  },
  {
    "text": "The first is that it will\nminimize the amount time on your training jobs down\nto a few seconds, actually",
    "start": "2208510",
    "end": "2217770"
  },
  {
    "text": "for multiple terabytes of data. And so obviously that's a lot\nfaster than a copy. (chuckles)",
    "start": "2217840",
    "end": "2223360"
  },
  {
    "text": "The S3 copy is gonna be extremely slow. And streamers such as setting\nup a data streaming function",
    "start": "2223360",
    "end": "2231930"
  },
  {
    "text": "can be somewhat challenging to implement. Particularly when you need to restart",
    "start": "2232983",
    "end": "2238930"
  },
  {
    "text": "from various checkpoints\nand ensure the ordering of some of the batches.",
    "start": "2238930",
    "end": "2244390"
  },
  {
    "text": "It's not the easiest thing and so many cases it's actually\nmore straightforward to just just work with Lustre.",
    "start": "2244390",
    "end": "2251050"
  },
  {
    "text": "And so we'll show you\nhow to do that today. So AWS console.",
    "start": "2251050",
    "end": "2256240"
  },
  {
    "text": "Then in the AWS console,\nwe just picked FSx. And so there are a number of\nfile systems that you can see.",
    "start": "2256240",
    "end": "2263950"
  },
  {
    "text": "And we're gonna use FSx for Lustre, which is an optimized file system for high performance computing.",
    "start": "2263950",
    "end": "2271060"
  },
  {
    "text": "So for the sake of\nargument here, let's try to create a file system. So we're gonna create FSx\nfor Lustre, click next here.",
    "start": "2271060",
    "end": "2280830"
  },
  {
    "text": "And then we can give this a name. We can say my test FSx maybe for fun.",
    "start": "2281560",
    "end": "2288450"
  },
  {
    "text": "And then a couple different\nstorage options here. These ones at the top\nare more high performant.",
    "start": "2288610",
    "end": "2295690"
  },
  {
    "text": "The one in the middle\nis more low performance. We'll leave this here.",
    "start": "2295690",
    "end": "2300643"
  },
  {
    "text": "And then throughput per unit of storage. If we want to max this out,\nlet's go ahead and do that.",
    "start": "2302230",
    "end": "2309519"
  },
  {
    "text": "And then storage capacity,\nso this is in terabytes.",
    "start": "2309520",
    "end": "2313483"
  },
  {
    "text": "Let's go ahead and set\nthis to just one terabyte",
    "start": "2314650",
    "end": "2319650"
  },
  {
    "text": "and then we'll leave the\ndata compression as is. And then the virtual private cloud.",
    "start": "2320590",
    "end": "2326320"
  },
  {
    "text": "So if you haven't worked with a VPC before, this is something that you may want to get some help with",
    "start": "2326320",
    "end": "2332830"
  },
  {
    "text": "from your other AWS friends. VPCs are are somewhat\nchallenging and it's helpful",
    "start": "2332830",
    "end": "2338920"
  },
  {
    "text": "to work with someone who\nhas a networking background to stand this up. But in any case, every AWS\naccount comes with a default VPC,",
    "start": "2338920",
    "end": "2348690"
  },
  {
    "text": "so you can always just\nuse the default VPC. And then here the Wizard has\nselected a default called",
    "start": "2349120",
    "end": "2357600"
  },
  {
    "text": "a security group and a default subnet. You're welcome to use both of those.",
    "start": "2358000",
    "end": "2364180"
  },
  {
    "text": "If you need to switch your security group or your subnet, please do that now.",
    "start": "2364180",
    "end": "2369880"
  },
  {
    "text": "But once Lustre has been created, we're gonna copy these settings actually",
    "start": "2369880",
    "end": "2376330"
  },
  {
    "text": "and put those in our\nnotebook to then train",
    "start": "2376330",
    "end": "2381330"
  },
  {
    "text": "in that network actually. So feel free to modify those, but please do just keep a note\nof which one you're using.",
    "start": "2381550",
    "end": "2390580"
  },
  {
    "text": "The metadata for them\nwill also be captured in the Lustre console page. So if you forget it, don't worry about it.",
    "start": "2390580",
    "end": "2397690"
  },
  {
    "text": "It's easy to go catch optional\nencryption by default.",
    "start": "2397690",
    "end": "2402690"
  },
  {
    "text": "And then the data repository. So here we'll say yes, we\nwant to import data from",
    "start": "2404680",
    "end": "2410170"
  },
  {
    "text": "and export data to S3. So you don't need a\ntwo-way data repository",
    "start": "2410170",
    "end": "2417490"
  },
  {
    "text": "if you don't want one. I find it handy so that I\ncan essentially load my data",
    "start": "2417490",
    "end": "2424140"
  },
  {
    "text": "in S3, send this over to Lustre, and then read from Lustre\nduring my training runs.",
    "start": "2425860",
    "end": "2433900"
  },
  {
    "text": "The training runs will then\nwrite the checkpoint to Lustre,",
    "start": "2433900",
    "end": "2438900"
  },
  {
    "text": "and then Lustre sends it back to S3. So then I'll just download it\nfrom S3 once it's complete.",
    "start": "2439150",
    "end": "2445540"
  },
  {
    "text": "And so we can send in some S3 paths here. So for me, we'll just open\nup my S3 page, this account,",
    "start": "2445540",
    "end": "2455010"
  },
  {
    "text": "and then we'll just pick an S3 bucket",
    "start": "2461080",
    "end": "2466080"
  },
  {
    "text": "and I'll choose my web text. That's right. So web.text.",
    "start": "2466180",
    "end": "2473173"
  },
  {
    "text": "Hmm. And we need to\nset a file system path. This is the local path on the file system",
    "start": "2475660",
    "end": "2483460"
  },
  {
    "text": "that will mount our data. So we could say local mount or\nsomething like this and then,",
    "start": "2483460",
    "end": "2490980"
  },
  {
    "text": "or we could put in something\na little bit more meaningful. So maybe we can say training data.",
    "start": "2491320",
    "end": "2495570"
  },
  {
    "text": "And then we'll say S3\nand then just the name of your bucket here. So mine is web text,",
    "start": "2496900",
    "end": "2503170"
  },
  {
    "text": "and then the optional\nimport on the metadata. Go ahead and do that. So it imports the metadata",
    "start": "2503170",
    "end": "2510369"
  },
  {
    "text": "and then some of the import policies. So if we want the new metadata",
    "start": "2510370",
    "end": "2515770"
  },
  {
    "text": "as the files are added, the\nchanged and the deletes. And then the same thing\non the export settings.",
    "start": "2515770",
    "end": "2522280"
  },
  {
    "text": "Now again, something to keep in mind is that when we create Lustre,\nit will copy the metadata",
    "start": "2522280",
    "end": "2528880"
  },
  {
    "text": "for this S3 path, but not the actual file. So it's gonna copy the name basically of,",
    "start": "2528880",
    "end": "2535210"
  },
  {
    "text": "and the metadata of all of the files, but not the files themselves. To copy the files over, we're gonna need",
    "start": "2535210",
    "end": "2541780"
  },
  {
    "text": "to do another step, actually\nto actually move those,",
    "start": "2541780",
    "end": "2546103"
  },
  {
    "text": "which we'll take a look at. All right, so then we'll say next",
    "start": "2547420",
    "end": "2551270"
  },
  {
    "text": "and then let's see if this works. So we'll try to create the file system.",
    "start": "2553660",
    "end": "2559810"
  },
  {
    "text": "All right, so we have this\nnew file system coming online, which is quite exciting.",
    "start": "2561430",
    "end": "2566680"
  },
  {
    "text": "Luckily for you. I already have one set. So this is my pre-created\nweb data in FSx for Lustre.",
    "start": "2566680",
    "end": "2575520"
  },
  {
    "text": "And so you'll see a couple\nof these items we need. So we need this file system\nID, which is great, quite a bit",
    "start": "2576760",
    "end": "2584790"
  },
  {
    "text": "of storage capacity here. And then remember it's\ntracking the VPC ID,",
    "start": "2585460",
    "end": "2591220"
  },
  {
    "text": "which we'll need. The subnet and we'll also\nneed this mount name.",
    "start": "2591220",
    "end": "2596830"
  },
  {
    "text": "So all of that is stored in the metadata for the Lustre volume,\nwhich is quite handy.",
    "start": "2596830",
    "end": "2603940"
  },
  {
    "text": "So now that we've configured\na Lustre file system, let's mount that to our training jobs.",
    "start": "2603940",
    "end": "2611983"
  },
  {
    "text": "So the notebook that we looked at in the last demo was to\ntrain a GPT-2 based model",
    "start": "2615700",
    "end": "2623850"
  },
  {
    "text": "from scratch and training a\n30 billion parameter model.",
    "start": "2624460",
    "end": "2629460"
  },
  {
    "text": "And so now we're gonna\nuse the same notebook, but we'll add some modifications to this",
    "start": "2629650",
    "end": "2635140"
  },
  {
    "text": "to mount the Lustre volume\nrather than pointing to S3. Now actually, I'm gonna be training here",
    "start": "2635140",
    "end": "2643240"
  },
  {
    "text": "for you the glue synthetic dataset, because that is the settings\nthat the notebook ships with.",
    "start": "2643240",
    "end": "2651460"
  },
  {
    "text": "You're welcome to modify that\nto use the actual web dataset, which also in fact does\ncome with this repository.",
    "start": "2651460",
    "end": "2658630"
  },
  {
    "text": "So you should be somewhat\nfamiliar with this notebook if you follow the last demo.",
    "start": "2658630",
    "end": "2664077"
  },
  {
    "text": "And let's just jump to the changes that we're gonna make for Lustre.",
    "start": "2664077",
    "end": "2669343"
  },
  {
    "text": "So first off, I am\nsending the synthetic data",
    "start": "2671740",
    "end": "2676740"
  },
  {
    "text": "to the bucket that has the\nLustre data repository.",
    "start": "2677620",
    "end": "2682620"
  },
  {
    "text": "So that bucket is web text, and then in the volume I'd already\ncreated, I actually set the path",
    "start": "2683830",
    "end": "2691780"
  },
  {
    "text": "to then this data folder. So in the notebook, I tokenize\nthe files and then load them",
    "start": "2691780",
    "end": "2698580"
  },
  {
    "text": "into the S3 bucket, doing\nthe actual copy here and then storing the paths.",
    "start": "2698710",
    "end": "2705640"
  },
  {
    "text": "And then once I've done this S3 copy, then we can actually go back to Lustre.",
    "start": "2705640",
    "end": "2712450"
  },
  {
    "text": "So you can go back to\nthis Lustre file system and then we can click on data repository.",
    "start": "2712450",
    "end": "2719233"
  },
  {
    "text": "So in data repository. And\nthen we can take an action. So you should see this\nassociation ID that is pointing",
    "start": "2720760",
    "end": "2730320"
  },
  {
    "text": "to your local file system path. So this one is Fsx/data, that's the name of this local path.",
    "start": "2730840",
    "end": "2738820"
  },
  {
    "text": "And then the data repository path in S3. So web dash text, and then data.",
    "start": "2738820",
    "end": "2746200"
  },
  {
    "text": "And so what I wanna do\nright now is move the files",
    "start": "2746200",
    "end": "2751200"
  },
  {
    "text": "that I just copied into\nS3, move those over to FSx for Lustre.",
    "start": "2752980",
    "end": "2758619"
  },
  {
    "text": "So for that, I'm gonna\nclick this association ID. I'm gonna go to actions and\nI'll say create an import task.",
    "start": "2758620",
    "end": "2767803"
  },
  {
    "text": "And so this create import\ntask, it's going to look at this data repository path,\nand then it's just going",
    "start": "2768640",
    "end": "2776770"
  },
  {
    "text": "to import those files. And again, it's importing\nthe metadata for those files.",
    "start": "2776770",
    "end": "2782410"
  },
  {
    "text": "So that gets imported over. And you can see we have this new task",
    "start": "2782410",
    "end": "2788357"
  },
  {
    "text": "that's showing status pending because it's still in progress. And I've just completed this\nlast task from earlier today.",
    "start": "2788357",
    "end": "2797140"
  },
  {
    "text": "So the data that we processed\nin the notebook, first we load",
    "start": "2797140",
    "end": "2802140"
  },
  {
    "text": "that up in S3, then we\nmoved it over to Lustre. Now that it's in Lustre, whoops.",
    "start": "2802510",
    "end": "2808872"
  },
  {
    "text": "Now that it's in Lustre, we can run on it.",
    "start": "2810220",
    "end": "2814867"
  },
  {
    "text": "So this notebook has a few configs, so we'll set use FSx to true.",
    "start": "2819610",
    "end": "2825670"
  },
  {
    "text": "Obviously not every\nnotebook you'll interact with has this, but this one does. So use FSx, we'll set this to true.",
    "start": "2825670",
    "end": "2832360"
  },
  {
    "text": "And then let's make our\nmodifications. Great.",
    "start": "2832360",
    "end": "2836967"
  },
  {
    "text": "So here, so from SageMaker inputs, we're importing this file system inputs,",
    "start": "2837970",
    "end": "2844450"
  },
  {
    "text": "and then we're gonna hydrate this with that file system ID, the\nsecurity group ID, the subnet,",
    "start": "2844450",
    "end": "2851130"
  },
  {
    "text": "and the base path. And that is what we\nwanna get our hands on. So let's see if we can\nfind the file system ID.",
    "start": "2853120",
    "end": "2860533"
  },
  {
    "text": "Fortunately for us, it\nis sitting right here in our Lustre page and\nthe task has completed,",
    "start": "2862000",
    "end": "2868780"
  },
  {
    "text": "which is great. So, we'll look at our file system ID. So this web data is the\nname of the file system,",
    "start": "2868780",
    "end": "2877150"
  },
  {
    "text": "but what we want is the file\nsystem ID, which is this one. So we'll copy this and then\nwe can paste this right here.",
    "start": "2877150",
    "end": "2885703"
  },
  {
    "text": "So I'll just re paste it for you. Great. So we'll paste that in.\nThen let's get the subnet.",
    "start": "2886570",
    "end": "2895500"
  },
  {
    "text": "So the subnet is in the\nnetwork and security,",
    "start": "2897850",
    "end": "2902850"
  },
  {
    "text": "and then the subnet is down here. So let's copy the subnet\nand we'll put this in here.",
    "start": "2904120",
    "end": "2912330"
  },
  {
    "text": "All right, and now we wanna get this\nsecurity group ID business.",
    "start": "2914980",
    "end": "2921280"
  },
  {
    "text": "So the security group ID is not sitting in your Lustre page unfortunately,",
    "start": "2921280",
    "end": "2926290"
  },
  {
    "text": "but it is sitting in your subnet page. So let's remember that the\nsubnet we're we're using ends",
    "start": "2926290",
    "end": "2933760"
  },
  {
    "text": "in be1, so we're gonna click on this. This takes us out to the\nvirtual private cloud dashboard",
    "start": "2933760",
    "end": "2943220"
  },
  {
    "text": "wherein we can see all of the details about our various subnets\nthat again, are created",
    "start": "2944710",
    "end": "2951880"
  },
  {
    "text": "by default in every account\nin that default VPC.",
    "start": "2951880",
    "end": "2956112"
  },
  {
    "text": "And then I am gonna click on in this left hand side\nin the security group,",
    "start": "2957190",
    "end": "2962680"
  },
  {
    "text": "and in the security tab, we'll\nclick on security groups.",
    "start": "2962680",
    "end": "2966073"
  },
  {
    "text": "So here in our security groups, and let's close this out\nhere, we wanna find the subnet",
    "start": "2968020",
    "end": "2974493"
  },
  {
    "text": "that corresponds to, well\nactually here, so default VPC.",
    "start": "2979810",
    "end": "2984810"
  },
  {
    "text": "So this is our default VPC. So let's see if we can click on this one.",
    "start": "2986950",
    "end": "2994183"
  },
  {
    "text": "All right. And then here's\nthe security group ID. Beautiful.",
    "start": "2998050",
    "end": "3002793"
  },
  {
    "text": "Great. We'll get this\nand we'll paste this in.",
    "start": "3009420",
    "end": "3014192"
  },
  {
    "text": "Just wanna double check that\nthis is indeed the same one. All right, beautiful.\nSo that's the same one.",
    "start": "3015840",
    "end": "3024569"
  },
  {
    "text": "So I'll just put this here. Great. So we have the file system\nID, the security group ID,",
    "start": "3024570",
    "end": "3031590"
  },
  {
    "text": "the subnet, the base\npath should be the same as that mount name.",
    "start": "3031590",
    "end": "3038220"
  },
  {
    "text": "So let's get that from\nback on this Lustre page. Then you see this mount name here.",
    "start": "3038220",
    "end": "3044450"
  },
  {
    "text": "So let's give that a copy. And then the syntax here likes\nto see this forward slash,",
    "start": "3044450",
    "end": "3053450"
  },
  {
    "text": "so just make sure you have\nthis forward slash here at the beginning of the base path.",
    "start": "3054180",
    "end": "3059670"
  },
  {
    "text": "Otherwise you will get an error that says it can't normalize it. And then let's define this.",
    "start": "3059670",
    "end": "3066063"
  },
  {
    "text": "And then once you have that defined, I don't think\nwe need the VPC ID actually,",
    "start": "3068288",
    "end": "3074433"
  },
  {
    "text": "once you have that defined, the rest of the notebook should be\nself-explanatory, actually.",
    "start": "3075810",
    "end": "3080980"
  },
  {
    "text": "It, same as last time,\nuses the hyper parameters. And you can define your model config.",
    "start": "3082170",
    "end": "3090393"
  },
  {
    "text": "Define your instance count, and then create your SageMaker estimator.",
    "start": "3092430",
    "end": "3098520"
  },
  {
    "text": "Now I went through another step to create this, which is I\nactually built my own image",
    "start": "3098520",
    "end": "3105980"
  },
  {
    "text": "and then that image was running in ECR. Now, I did this because the VPC, in order",
    "start": "3106320",
    "end": "3114230"
  },
  {
    "text": "to essentially set up SageMaker\ntraining to run nicely",
    "start": "3115710",
    "end": "3120710"
  },
  {
    "text": "in a VPC, there are some extra\nrouting steps we need to do.",
    "start": "3120840",
    "end": "3125840"
  },
  {
    "text": "We need to make sure that your default VPC\nhas an internet gateway",
    "start": "3126960",
    "end": "3131349"
  },
  {
    "text": "and that the subnet\nwe're using has a route",
    "start": "3132241",
    "end": "3137241"
  },
  {
    "text": "to that internet gateway. So we need to connect those two things. And then there's another set of rules",
    "start": "3137820",
    "end": "3146970"
  },
  {
    "text": "that we add to the subnet,\nwhich is like a joint inbound and outbound such that they can talk",
    "start": "3146970",
    "end": "3152700"
  },
  {
    "text": "to each other, basically. And then once you've\ndone that, you can train.",
    "start": "3152700",
    "end": "3157323"
  },
  {
    "text": "We also need to create an S3 endpoint so",
    "start": "3158400",
    "end": "3163400"
  },
  {
    "text": "that your training resources\nin the VPC can hit S3",
    "start": "3164490",
    "end": "3169490"
  },
  {
    "text": "to write your model artifacts and so on. But neither of those extra rules are gonna",
    "start": "3171000",
    "end": "3179100"
  },
  {
    "text": "let you install from PiPi, actually. So install new packages.",
    "start": "3179100",
    "end": "3183693"
  },
  {
    "text": "And so to get around that, what I've done is created a\nnew image and push that to ECR.",
    "start": "3184740",
    "end": "3190890"
  },
  {
    "text": "So let's explore how to do that. So I'm gonna go out to SageMaker.",
    "start": "3190890",
    "end": "3195692"
  },
  {
    "text": "And then inside of SageMaker, I've created\na notebook instance. So notebook, notebook instance.",
    "start": "3204210",
    "end": "3211353"
  },
  {
    "text": "And then my image builder\nis running on a healthy CPU.",
    "start": "3213030",
    "end": "3218030"
  },
  {
    "text": "So that's an m5.4xlarge.\nWe're gonna open this up.",
    "start": "3218960",
    "end": "3222903"
  },
  {
    "text": "Now, you'll need to change\na couple permissions with your notebook, with\nyour notebook instance.",
    "start": "3224970",
    "end": "3232470"
  },
  {
    "text": "First off, you'll need to\nuse a notebook instance to create a new docker image. Still not supported by\nSageMaker Studio necessarily.",
    "start": "3232470",
    "end": "3240690"
  },
  {
    "text": "And so it's handy to\nuse a notebook instance. And then we need to give\nyour notebook instance access",
    "start": "3240690",
    "end": "3249630"
  },
  {
    "text": "to ECR actually. So once you've created a\nCPU based notebook instance,",
    "start": "3249630",
    "end": "3256470"
  },
  {
    "text": "and you have the IAM role,\nwe're gonna click on that and then we're gonna add some\npermissions to that IAM role.",
    "start": "3256470",
    "end": "3266340"
  },
  {
    "text": "Really what you need in\nthis IAM role is called, EC2 Container Registry full access.",
    "start": "3267210",
    "end": "3273900"
  },
  {
    "text": "The other ones were\nnot strictly necessary, but the EC2 Container Registry really is.",
    "start": "3273900",
    "end": "3279930"
  },
  {
    "text": "And so to add that, you'll go to add permissions, you're\ngonna attach a policy,",
    "start": "3279930",
    "end": "3284823"
  },
  {
    "text": "and then up here you'll say EC2.",
    "start": "3286080",
    "end": "3288783"
  },
  {
    "text": "And then if you haven't already added it, it should say EC2 Container\nRegistry full access.",
    "start": "3291390",
    "end": "3298960"
  },
  {
    "text": "And then that's the\npermissions that you wanna add. I already have it, so\nI don't need to add it,",
    "start": "3301260",
    "end": "3306540"
  },
  {
    "text": "but then you'll just click on it for example this and then say add. But again, I've already done\nthis, so I won't do this here.",
    "start": "3306540",
    "end": "3314670"
  },
  {
    "text": "All right, so that's the IAM role. Now let's take a look\nat the setup for this.",
    "start": "3314670",
    "end": "3321119"
  },
  {
    "text": "So I like to be sort of a minimalist in creating docker images\nbecause that way it's just",
    "start": "3321120",
    "end": "3329520"
  },
  {
    "text": "so much easier to maintain them. So the docker container\nitself is ridiculously simple.",
    "start": "3329520",
    "end": "3335661"
  },
  {
    "text": "(chuckles) It's literally a three line. So you're gonna start in\nyour docker image by pointing",
    "start": "3335661",
    "end": "3344910"
  },
  {
    "text": "to a prebuilt, what's called\nAWS deep learning container. Now the list of the deep\nlearning containers is out here",
    "start": "3344910",
    "end": "3352430"
  },
  {
    "text": "on GitHub, so AWS deep\nlearning containers.",
    "start": "3352430",
    "end": "3356463"
  },
  {
    "text": "And then once you have your\ndeep learning containers, go",
    "start": "3357912",
    "end": "3362413"
  },
  {
    "text": "and click on for a list of\nall available DLC images, which is right here.",
    "start": "3363630",
    "end": "3368493"
  },
  {
    "text": "And these are nice to use because they're updated extremely well. So when there are major updates",
    "start": "3370320",
    "end": "3376500"
  },
  {
    "text": "to the frameworks, including\nPyTorch, TensorFlow, Hugging Face, et cetera,\nwe'll create new images",
    "start": "3376500",
    "end": "3384890"
  },
  {
    "text": "for CPU, GPU, training and inference and additional options\nincluding custom accelerators.",
    "start": "3384990",
    "end": "3393723"
  },
  {
    "text": "And then these should be much\neasier for you to get started. So let's look for the SageMaker.",
    "start": "3394500",
    "end": "3400590"
  },
  {
    "text": "So these are the images\nthat support SageMaker. And then I want the\nlatest version of PyTorch.",
    "start": "3400590",
    "end": "3406349"
  },
  {
    "text": "So I'm gonna go PyTorch,\ntraining, and then I want a GPU.",
    "start": "3406350",
    "end": "3411350"
  },
  {
    "text": "So that's gonna be this. And then you're literally\ngonna copy and paste this. Now, if you're running",
    "start": "3411720",
    "end": "3417930"
  },
  {
    "text": "in USD east one, this is\nthe exact URL you're going to use, you're actually gonna point to",
    "start": "3417930",
    "end": "3423870"
  },
  {
    "text": "that AWS account to pull this image. And then you're gonna push\nto your private AWS account.",
    "start": "3423870",
    "end": "3432150"
  },
  {
    "text": "So literally you're gonna say\nfrom, and then just paste it.",
    "start": "3432150",
    "end": "3437150"
  },
  {
    "text": "Now this is exactly\nwhat I have here, right? From this base image.",
    "start": "3438510",
    "end": "3442922"
  },
  {
    "text": "Then I have a local requirements.txt file. So I just copy that into the container.",
    "start": "3443760",
    "end": "3451740"
  },
  {
    "text": "I'm not overly concerned about where in the container, (chuckles)\nI just copy in the container.",
    "start": "3451740",
    "end": "3457290"
  },
  {
    "text": "And then I run pip install\ndash -r, the requirements. So this is now in the container.",
    "start": "3457290",
    "end": "3464460"
  },
  {
    "text": "Now you may see some examples pointing to setting other environment variables,",
    "start": "3464460",
    "end": "3470640"
  },
  {
    "text": "setting the SageMaker program. I found most of those settings to actually slow me down and\nactually introduce more errors.",
    "start": "3470640",
    "end": "3478619"
  },
  {
    "text": "And so this extreme minimalism seemed to limit the number of errors.",
    "start": "3478620",
    "end": "3483720"
  },
  {
    "text": "So this S3 line dockerfile after five versions ended\nup being quite handy.",
    "start": "3483720",
    "end": "3489513"
  },
  {
    "text": "So now I have the dockerfile\nand then the requirements.txt. This is a straight copy\nfrom the GitHub repository.",
    "start": "3490560",
    "end": "3499859"
  },
  {
    "text": "So in the Git repository it\nhas a requirements.txt file,",
    "start": "3499860",
    "end": "3504860"
  },
  {
    "text": "which once you have this,\nyou'll wanna take it out of that source directory, otherwise\nit will try to PIP install.",
    "start": "3506850",
    "end": "3515400"
  },
  {
    "text": "And then you'll air out\nbecause you can't point to PiPi from your training file, from\nyour training directory for",
    "start": "3515400",
    "end": "3521490"
  },
  {
    "text": "in training instances rather. So great. So take that out\nand then let's look at this.",
    "start": "3521490",
    "end": "3528470"
  },
  {
    "text": "So that's a requirements.txt,\nnothing crazy going on there.",
    "start": "3532980",
    "end": "3537453"
  },
  {
    "text": "And then let's look at\nwhat it's gonna take to create this image.",
    "start": "3539880",
    "end": "3545910"
  },
  {
    "text": "So again, we're on a notebook\ninstance, we're running on a CPU, and we wanna\ncreate the repository.",
    "start": "3545910",
    "end": "3553044"
  },
  {
    "text": "Now, I like creating\nassets in the AWS console.",
    "start": "3553620",
    "end": "3558620"
  },
  {
    "text": "It helps me, I'm a visual\nlearner, so I like being able to see my assets and sort\nof understand where they are",
    "start": "3558960",
    "end": "3567190"
  },
  {
    "text": "and what metadata is associated with them. So you can just create a repository in the console, it's quite easy to do.",
    "start": "3568200",
    "end": "3576180"
  },
  {
    "text": "Just go to your ECR,\nElastic Container Registry and then we're gonna say,\ncreate a repository, set it",
    "start": "3576180",
    "end": "3584460"
  },
  {
    "text": "to private as you like, and\nthen say my new GPT image",
    "start": "3584460",
    "end": "3589460"
  },
  {
    "text": "or really whatever you like. And then create this, set\nthe rest of your settings",
    "start": "3591630",
    "end": "3597301"
  },
  {
    "text": "and then just say, create repository. Again, very easy to do.",
    "start": "3597301",
    "end": "3603603"
  },
  {
    "text": "And it's lovely because once you have this\nnew repository created,",
    "start": "3605310",
    "end": "3611013"
  },
  {
    "text": "you can see what images have\nbeen successfully uploaded to this repository. And you can view the push command.",
    "start": "3612150",
    "end": "3619109"
  },
  {
    "text": "So we're gonna use these push commands to build our image locally and then push",
    "start": "3619110",
    "end": "3625650"
  },
  {
    "text": "that image to the elastic\ncontainer registry. So that's basically what we're gonna do",
    "start": "3625650",
    "end": "3631380"
  },
  {
    "text": "in this notebook with\none twist. (chuckles) And the twist is that\nfirst we're gonna log",
    "start": "3631380",
    "end": "3638700"
  },
  {
    "text": "into the AWS deep learning container. So, the notebook, just\nto level you out here",
    "start": "3638700",
    "end": "3645330"
  },
  {
    "text": "in terms of directory. So my notebook is one directory above. So I have this folder\nthat's called container.",
    "start": "3645330",
    "end": "3653130"
  },
  {
    "text": "And then the dockerfile lives\ninside of this directory because the command tends\nto prefer a directory",
    "start": "3653130",
    "end": "3660750"
  },
  {
    "text": "and not a file. So, we'll send it here. So my notebook is above\nit, but nonetheless.",
    "start": "3660750",
    "end": "3666630"
  },
  {
    "text": "So I'm gonna CD into that container. And so now we're in that same directory.",
    "start": "3666630",
    "end": "3671703"
  },
  {
    "text": "And then, so this login\ncommand is exactly the same",
    "start": "3672630",
    "end": "3677630"
  },
  {
    "text": "from ECR, right? So we're in ECR, we're gonna\nview the push commands.",
    "start": "3677910",
    "end": "3682920"
  },
  {
    "text": "And then that is exactly the same login. But notice this is logging\nin to my private AWS account.",
    "start": "3682920",
    "end": "3690251"
  },
  {
    "text": "The first thing I wanna do is log into the AWS DLC account.",
    "start": "3691800",
    "end": "3697529"
  },
  {
    "text": "So, here's what we're gonna\ndo, we're gonna paste, so you're gonna add your exclamation mark,",
    "start": "3697530",
    "end": "3703890"
  },
  {
    "text": "you're gonna paste that command. Looks good.",
    "start": "3703890",
    "end": "3707793"
  },
  {
    "text": "And then we're gonna\nmodify this number to point to this number actually,\nbecause we wanna log",
    "start": "3709140",
    "end": "3716446"
  },
  {
    "text": "into the AWS Deep Learning\ncontainer account, which is right here.",
    "start": "3716446",
    "end": "3722612"
  },
  {
    "text": "So now we're gonna modify\nthis, and this lets us log in",
    "start": "3726570",
    "end": "3731570"
  },
  {
    "text": "to the AWS DLC, which we've now done.",
    "start": "3731717",
    "end": "3736717"
  },
  {
    "text": "So then I'll delete that\n'cause I've already done this. And then I tend to iterate\non versions quite rapidly.",
    "start": "3737910",
    "end": "3745620"
  },
  {
    "text": "So I find it handy to just\ncreate a variable around this. But in any case, following\nthose build commands,",
    "start": "3745620",
    "end": "3752825"
  },
  {
    "text": "we're gonna say, bang, docker build, and then tag it so -t and\nthen set the image name",
    "start": "3752825",
    "end": "3761480"
  },
  {
    "text": "for whatever image you want to use. And then the version, actually I believe",
    "start": "3762210",
    "end": "3768690"
  },
  {
    "text": "this should match the repository name.",
    "start": "3768690",
    "end": "3772996"
  },
  {
    "text": "Let me just double check this. Yes. So the name of the image, this is the one",
    "start": "3774600",
    "end": "3781290"
  },
  {
    "text": "I'm actually training on right now. The name of the image should be what you tag your local dockerfile.",
    "start": "3781290",
    "end": "3788970"
  },
  {
    "text": "You don't have to do that necessarily 'cause you can still tag it later,",
    "start": "3788970",
    "end": "3794033"
  },
  {
    "text": "but I like to do this right now. So you'll say, bang, docker build -t,",
    "start": "3794033",
    "end": "3800310"
  },
  {
    "text": "and then the name of your repository, and then colon the name of your image,",
    "start": "3800310",
    "end": "3806339"
  },
  {
    "text": "and then your space dot. And then this will pull from the AWS deep learning container.",
    "start": "3806340",
    "end": "3812460"
  },
  {
    "text": "Again, as long as you have access to EC2 Container Registry,\ngenerally speaking.",
    "start": "3812460",
    "end": "3819680"
  },
  {
    "text": "And if you've logged into the deep learning container\naccount, which is this one, then you can pull from that,\ncopy any your requirements,",
    "start": "3821040",
    "end": "3829619"
  },
  {
    "text": "PIP install those, tag it, you're done. Once you've built it, now we're gonna log",
    "start": "3829620",
    "end": "3837630"
  },
  {
    "text": "into your ECR repository,\nso that same login command,",
    "start": "3837630",
    "end": "3842630"
  },
  {
    "text": "but this time we're logging\ninto your private AWS account. So this one is the one I'm using.",
    "start": "3842730",
    "end": "3848430"
  },
  {
    "text": "Obviously you're gonna wanna\npaste this, change this out to point to your AWS account.",
    "start": "3848430",
    "end": "3854193"
  },
  {
    "text": "And so log into your ECR\naccount in your AWS account.",
    "start": "3856530",
    "end": "3861530"
  },
  {
    "text": "And then we're gonna\ntag that docker image. And now again, this is\njust a direct copy paste",
    "start": "3861660",
    "end": "3869069"
  },
  {
    "text": "from those push commands, right? So the push commands, the\nfirst one is logging in. The second is docker build -t image,",
    "start": "3869070",
    "end": "3877620"
  },
  {
    "text": "and then docker tag image, colon latest with that full ECR address,\nincluding the accounts, docker,",
    "start": "3877620",
    "end": "3887180"
  },
  {
    "text": "ECR, your region,\namazonaws.com, GPT dash image,",
    "start": "3887790",
    "end": "3892790"
  },
  {
    "text": "colon latest (chuckles) colon tag. So, it's quite verbose, which\nis why the copy is handy.",
    "start": "3894120",
    "end": "3901501"
  },
  {
    "text": "And so you're gonna tag your local image that's already been built",
    "start": "3901501",
    "end": "3906720"
  },
  {
    "text": "with this massive ECR registry name. So with this whole image name.",
    "start": "3906720",
    "end": "3913380"
  },
  {
    "text": "And then you're gonna do a docker push. And so docker push and then",
    "start": "3913380",
    "end": "3919380"
  },
  {
    "text": "that whole image is available,\nwhich is quite nice. And so you'll see all of these logs, all",
    "start": "3919380",
    "end": "3928140"
  },
  {
    "text": "of this information. Then we can go back to the\nElastic Container Registry",
    "start": "3928140",
    "end": "3933180"
  },
  {
    "text": "and just confirm. So you can do a refresh and\nyou should see, yes indeed, I have a new image and I have\na new version of that image.",
    "start": "3933180",
    "end": "3942950"
  },
  {
    "text": "And then you can copy that image URI. And now we're gonna go\nback to SageMaker studio",
    "start": "3943949",
    "end": "3951760"
  },
  {
    "text": "and we're gonna use that to train.",
    "start": "3952830",
    "end": "3955713"
  },
  {
    "text": "So now back in SageMaker Studio, we have our PyTorch estimator\nwith all of our credentials.",
    "start": "3958080",
    "end": "3966140"
  },
  {
    "text": "And we're gonna add this new parameter that's called image URI. And then we're gonna\npaste in that ECR address.",
    "start": "3967230",
    "end": "3976470"
  },
  {
    "text": "So this is the full image\nURI that we wanna paste. Then we're gonna add,",
    "start": "3976470",
    "end": "3981563"
  },
  {
    "text": "of course, the instance count\nshould already be there. And then you'll need to comment\nout the version of Python",
    "start": "3981563",
    "end": "3988740"
  },
  {
    "text": "and the framework version if\nyou're bringing your own image. This is just due to the way the SDK checks",
    "start": "3988740",
    "end": "3996579"
  },
  {
    "text": "for various conflicts. One other parameter that's quite handy",
    "start": "3996580",
    "end": "4002830"
  },
  {
    "text": "to add is called warm pools. So essentially this\nkeeps the instances warm",
    "start": "4002830",
    "end": "4010130"
  },
  {
    "text": "for you so that you can\ndevelop on them very quickly. And so the parameter here is\nkeep alive period in seconds.",
    "start": "4010130",
    "end": "4017960"
  },
  {
    "text": "You can max this out at one\nhour, which I like to do. You'll need to add an extra\nservice limit increase",
    "start": "4017960",
    "end": "4027243"
  },
  {
    "text": "for warm pools. So generally to request service\nlimit increases, you go out",
    "start": "4027350",
    "end": "4033170"
  },
  {
    "text": "to SageMaker or you go out to, in the AWS console, you\ncan go to a service quota.",
    "start": "4033170",
    "end": "4039442"
  },
  {
    "text": "So service quota. And then inside of service\nquota, you can search",
    "start": "4040700",
    "end": "4048800"
  },
  {
    "text": "for different services. And then you can essentially\nrequest an increase",
    "start": "4048800",
    "end": "4056330"
  },
  {
    "text": "for both SageMaker training instances and SageMaker warm pool\nfor training instances.",
    "start": "4056330",
    "end": "4063797"
  },
  {
    "text": "And so that's how you can\nreally get those warm pools.",
    "start": "4063797",
    "end": "4068797"
  },
  {
    "text": "And then once you have that, I'm gonna call estimator outfits. The data channels are passed here.",
    "start": "4069140",
    "end": "4074990"
  },
  {
    "text": "Again, those are pointing to\nLustre now and again, I like to always set logs to\nfalse and wait to false.",
    "start": "4074990",
    "end": "4083900"
  },
  {
    "text": "This is because I like getting\nmy notebook back immediately. And if you have too many logs,",
    "start": "4083900",
    "end": "4089720"
  },
  {
    "text": "then it will kill your notebook (chuckles) and it will will certainly\ncrash the kernel. So let's go out to the SageMaker console",
    "start": "4089720",
    "end": "4097279"
  },
  {
    "text": "and see what's happening. All right, so let's\ntake a look at this job.",
    "start": "4097280",
    "end": "4104539"
  },
  {
    "text": "So I have quite a few jobs up and running. And in particular, I actually had",
    "start": "4104540",
    "end": "4109730"
  },
  {
    "text": "to do some troubleshooting\nbecause apparently I had set up my data channels incorrectly,\nso let's take a look.",
    "start": "4109730",
    "end": "4119706"
  },
  {
    "text": "You'll see I was very, very actively using the warm pool feature. I'm big advocate of this feature.",
    "start": "4120080",
    "end": "4127700"
  },
  {
    "text": "Super helpful, (chuckles) super useful. Basically what this is gonna let you do,",
    "start": "4127700",
    "end": "4133069"
  },
  {
    "text": "and let's get a few more jobs here set. Basically, what warm pools,",
    "start": "4133070",
    "end": "4138290"
  },
  {
    "text": "and that's this piece\nhere, the warm pool status. What this lets you do is very\neasily reuse a given resource.",
    "start": "4138290",
    "end": "4146529"
  },
  {
    "text": "So when you are running jobs, for example, I've been working on this SMSP GPT-2 30\nbillion parameter job pretty",
    "start": "4148190",
    "end": "4158080"
  },
  {
    "text": "actively today, July 3rd. And essentially you run a job\nusing this warm pool feature",
    "start": "4158180",
    "end": "4167650"
  },
  {
    "text": "and then you add that parameter, right? Keep alive period in seconds, and then the instance is still there.",
    "start": "4168920",
    "end": "4175190"
  },
  {
    "text": "And so you can rapid\nfire ship changes to this and then the new instance comes\nonline in seconds actually.",
    "start": "4175190",
    "end": "4184040"
  },
  {
    "text": "So it's so much faster. It really just totally changes the game",
    "start": "4184040",
    "end": "4189920"
  },
  {
    "text": "for SageMaker training development\nbecause you can just fly. So it's great. And so, I use\nthe warm pool feature a lot.",
    "start": "4189920",
    "end": "4199420"
  },
  {
    "text": "You can see when the job has finished and the instances are available,",
    "start": "4199700",
    "end": "4204890"
  },
  {
    "text": "you'll see this little green bar and then I can say, I\ncan highlight this bar",
    "start": "4204890",
    "end": "4210484"
  },
  {
    "text": "and I can say, actions\nrelease the cluster. So that turns it off. So we'll release the cluster\nbecause this is finished",
    "start": "4210484",
    "end": "4219320"
  },
  {
    "text": "and then this will change to terminated. But if I had run a new job\nusing those same instances,",
    "start": "4219320",
    "end": "4227505"
  },
  {
    "text": "then it would've been set to reused. And so you see all of those\nreused. So let's take a look.",
    "start": "4227505",
    "end": "4235207"
  },
  {
    "text": "So this last job I ran actually came after some CPU troubleshooting.",
    "start": "4236120",
    "end": "4244150"
  },
  {
    "text": "So essentially, I was\njust not able to point to my training data,\n(chuckles) try my best,",
    "start": "4244160",
    "end": "4251179"
  },
  {
    "text": "I just wasn't able to do it. So I ended up just writing\na new little mini scripts",
    "start": "4251180",
    "end": "4256770"
  },
  {
    "text": "and running some CPUs on\nthis Lustre volume just to make sure I could\nactually read my data.",
    "start": "4257720",
    "end": "4266502"
  },
  {
    "text": "And so I copy and pasted\nthe config from below",
    "start": "4266502",
    "end": "4271502"
  },
  {
    "text": "and then just disabled all\nof the distribution here and created this little mini file load.pi,",
    "start": "4272720",
    "end": "4280219"
  },
  {
    "text": "which is just this. And theoretically, I knew my\ntraining data was supposed",
    "start": "4280220",
    "end": "4286750"
  },
  {
    "text": "to be in this directory\non the training cluster, just opt/ml/input.",
    "start": "4287210",
    "end": "4292474"
  },
  {
    "text": "And so I just got this little walker here, so OS.walk on this training\ndirectory and then just",
    "start": "4292474",
    "end": "4299869"
  },
  {
    "text": "through this list of file\nnames, just print me the path. And so I ran this as a CPU\njob, again using this c5.18",
    "start": "4299870",
    "end": "4308260"
  },
  {
    "text": "with my same custom\nimage and obviously went through a few rounds\nof this to get it nice",
    "start": "4310584",
    "end": "4316789"
  },
  {
    "text": "and sparkling and yeah. And then in the logs I was able to see, oh actually I had pointed",
    "start": "4316790",
    "end": "4323893"
  },
  {
    "text": "to something incorrectly (chuckles) so then I could go back and fix that. And really the pro tip here is just",
    "start": "4323893",
    "end": "4331280"
  },
  {
    "text": "that when you're pointing\nto the training data,",
    "start": "4331280",
    "end": "4336023"
  },
  {
    "text": "essentially, when you're\nsetting the training data as a hyper parameter, which\nthis notebook prompts you",
    "start": "4337400",
    "end": "4344150"
  },
  {
    "text": "to do, then all I was missing was the local Lustre mount name, actually.",
    "start": "4344150",
    "end": "4351740"
  },
  {
    "text": "So I was just missing the name of the directory on Lustre\nand everything else was fine.",
    "start": "4351740",
    "end": "4358610"
  },
  {
    "text": "So then when I added it,\nthis FSx/data, I was able",
    "start": "4358610",
    "end": "4363610"
  },
  {
    "text": "to train appropriately,\nwhich was a huge relief. (chuckles) So once I figured that\nout, then I could go back",
    "start": "4364100",
    "end": "4372260"
  },
  {
    "text": "and start training the actual model which uses this estimator.",
    "start": "4372260",
    "end": "4377660"
  },
  {
    "text": "So then I went back and used my image",
    "start": "4377660",
    "end": "4382660"
  },
  {
    "text": "and then this much larger\ntrain.py, which we explored in the previous video in some detail",
    "start": "4383310",
    "end": "4390170"
  },
  {
    "text": "with all the distribution\nparameters and ran it.",
    "start": "4390170",
    "end": "4395170"
  },
  {
    "text": "And so now let's poke at that thing. Okay, so here are the jobs",
    "start": "4395867",
    "end": "4402440"
  },
  {
    "text": "and here's the one I just\nran and let's validate this. So the status, a handy way you\ncan see how long things took.",
    "start": "4402440",
    "end": "4411460"
  },
  {
    "text": "So the data download right started at 4:37",
    "start": "4412580",
    "end": "4417580"
  },
  {
    "text": "and it ended at 4:37, (chuckles) right? So again, because I'm\nusing FSx for Lustre,",
    "start": "4419870",
    "end": "4426560"
  },
  {
    "text": "it's just mounting to\nthe training instances literally in seconds. And so if you are out\nthere trying to copy data",
    "start": "4426560",
    "end": "4436190"
  },
  {
    "text": "to your training instances,\nand if it's taking like a half hour, you\ndon't need to do that. (chuckles)",
    "start": "4436190",
    "end": "4442125"
  },
  {
    "text": "You just mount to your Lustre volume and you'll be on your merry way. And so then we invoke the training image",
    "start": "4442125",
    "end": "4450019"
  },
  {
    "text": "and the process for this\nran for about eight minutes",
    "start": "4450020",
    "end": "4455020"
  },
  {
    "text": "because it's a synthetic dataset. Then we upload the model and\nthen we released the instances.",
    "start": "4455720",
    "end": "4462793"
  },
  {
    "text": "And so again, the\ntraining page captures all of your metadata including\nthe training image.",
    "start": "4463367",
    "end": "4470663"
  },
  {
    "text": "Again, (chuckles) running on 16 p4ds here. Pointing to FSx for Lustre with all",
    "start": "4471830",
    "end": "4479269"
  },
  {
    "text": "of my relevant parameters and configs. All of my hyper parameters\nand then we can view the logs.",
    "start": "4479270",
    "end": "4488980"
  },
  {
    "text": "So let's take a look at those logs.",
    "start": "4491000",
    "end": "4493163"
  },
  {
    "text": "So remember the SageMaker\ntraining environment is gonna give you a log stream",
    "start": "4503630",
    "end": "4508730"
  },
  {
    "text": "for each of the training instances. So as many training instances as you have,",
    "start": "4508730",
    "end": "4515660"
  },
  {
    "text": "that is how many log\nstreams you'll get per job. So we're gonna do some clicking here",
    "start": "4515660",
    "end": "4521660"
  },
  {
    "text": "and what we wanna do is we\nwanna find the leader node. There's one primary node who's\norchestrating the others,",
    "start": "4521660",
    "end": "4530510"
  },
  {
    "text": "and we wanna find out which one that is so that we can view those logs.",
    "start": "4530510",
    "end": "4536270"
  },
  {
    "text": "As you click through these\nlog streams, you'll see that all of them appear to\nbe connecting to one of them.",
    "start": "4536270",
    "end": "4543970"
  },
  {
    "text": "So here is this telltale,\nit says can connect to host algo 12.",
    "start": "4544400",
    "end": "4549530"
  },
  {
    "text": "That tells you that algo 12 is unambiguously\nthe leader node.",
    "start": "4549530",
    "end": "4554690"
  },
  {
    "text": "And so now we're gonna go back and we're gonna go find algo 12. So algo 12 is this one and\nthat tells us the overall logs.",
    "start": "4554690",
    "end": "4564453"
  },
  {
    "text": "And let's take this from the top. So again, when you're working",
    "start": "4568070",
    "end": "4573619"
  },
  {
    "text": "in CloudWatch, we're gonna\ndo a little custom view here. So this has been running\nfor about 15 minutes,",
    "start": "4573620",
    "end": "4579949"
  },
  {
    "text": "so let me, give me 30\nminutes, give us 30 minutes from this moment.",
    "start": "4579950",
    "end": "4585199"
  },
  {
    "text": "It'll go back in time, 30\nminutes and then great, we can see all of the reads.",
    "start": "4585200",
    "end": "4591052"
  },
  {
    "text": "So first, MPI will try to just connect to all of the instances.",
    "start": "4593810",
    "end": "4599960"
  },
  {
    "text": "And so because algo 12\nis our sort of leader",
    "start": "4599960",
    "end": "4604960"
  },
  {
    "text": "in this config, it needs\nto connect to all of them. And so first you'll see just",
    "start": "4605360",
    "end": "4611176"
  },
  {
    "text": "this cross node connection using MPI. So it's connecting to all the\ndifferent hosts and verifying",
    "start": "4611176",
    "end": "4619250"
  },
  {
    "text": "that yes, indeed the connection is valid. And you'll see some error\nstatements occasionally",
    "start": "4619250",
    "end": "4625670"
  },
  {
    "text": "and then it'll retry. No worries about that. Eventually we'll get all of these hosts.",
    "start": "4625670",
    "end": "4630800"
  },
  {
    "text": "So all these 16 instances, each of them have eight GPUs giving\nus a total of 128 cards.",
    "start": "4630800",
    "end": "4637829"
  },
  {
    "text": "Then as before, SageMaker\nwill print the training environment so we get all of\nthe information that we need.",
    "start": "4639074",
    "end": "4647860"
  },
  {
    "text": "Somehow SMDDP was disabled\nthrough this, I think because we were using the\nmodel parallel library.",
    "start": "4649100",
    "end": "4655040"
  },
  {
    "text": "And then we'll see the\ncurrent host, the rest of the hosts, the instance,",
    "start": "4655040",
    "end": "4660593"
  },
  {
    "text": "and the rest of the hyper parameters. So again, SageMaker will print\nall of this into the log.",
    "start": "4662278",
    "end": "4668420"
  },
  {
    "text": "So it's just easily viewable\nand verifiable and onward ho.",
    "start": "4668420",
    "end": "4673420"
  },
  {
    "text": "And then we have all\nof the hyper parameters and these are the environment variables. And so you can access all of\nthese from your training script",
    "start": "4675980",
    "end": "4685660"
  },
  {
    "text": "by looking them up as\nenvironment variables. So you'll say os.environ,\nand then this key.",
    "start": "4687260",
    "end": "4694580"
  },
  {
    "text": "And then you can look up\nall of these values directly from your training script.",
    "start": "4694580",
    "end": "4700044"
  },
  {
    "text": "For instance groups and then the rest of the hyper parameters,\nmore environment variables.",
    "start": "4700044",
    "end": "4708470"
  },
  {
    "text": "Obviously, there's a little\nbit of redundancy here, but that's fine, that's healthy. And then we have all of these\nuser arms listed out again.",
    "start": "4708470",
    "end": "4717060"
  },
  {
    "text": "And when it says SM/HP like that, that means it's actually\ncustom hyper parameter.",
    "start": "4719120",
    "end": "4724370"
  },
  {
    "text": "So in the script, that\nmeans we're just adding it as a hyper parameter to\nthat hyper parameter object.",
    "start": "4724370",
    "end": "4730310"
  },
  {
    "text": "And then it's showing up here, SM/HP/, whatever your name is. So that's how you can add\nyour own hyper parameters.",
    "start": "4730310",
    "end": "4737989"
  },
  {
    "text": "And then here's a little bundle of the model parallel parameters.",
    "start": "4737990",
    "end": "4742912"
  },
  {
    "text": "And then here is our massive\n(chuckles) script invocation.",
    "start": "4744373",
    "end": "4749373"
  },
  {
    "text": "So MPI run, all of the algorithm names, the number processes, and\nthen all of those flags.",
    "start": "4750020",
    "end": "4759710"
  },
  {
    "text": "These are the parameters\nthat we add at the bottom. These are the environment\nvariables that are added.",
    "start": "4759710",
    "end": "4767060"
  },
  {
    "text": "You can see our script name\nis right here, mpi4py train.py",
    "start": "4767060",
    "end": "4772060"
  },
  {
    "text": "and so forth and then we get the job map.",
    "start": "4773720",
    "end": "4778720"
  },
  {
    "text": "So then you can see that yes, indeed the\ndistributed environment is able",
    "start": "4780320",
    "end": "4787430"
  },
  {
    "text": "to map out all of the processes to all of our 128 accelerators.",
    "start": "4787430",
    "end": "4792833"
  },
  {
    "text": "And here it's essentially\ncopying the models appropriately",
    "start": "4793790",
    "end": "4798790"
  },
  {
    "text": "and the different copies of the models using SageMaker distributed.",
    "start": "4799400",
    "end": "4805070"
  },
  {
    "text": "And then we initialize the torch, distributed\ntraining process using",
    "start": "4805070",
    "end": "4810110"
  },
  {
    "text": "that SMDDP backend and onward ho.",
    "start": "4810110",
    "end": "4815110"
  },
  {
    "text": "And so this job will run, basically, this is how you're gonna get this.",
    "start": "4816140",
    "end": "4822590"
  },
  {
    "text": "And then it's opening\nthe different devices,",
    "start": "4822590",
    "end": "4827590"
  },
  {
    "text": "which are the GPUs and the accelerators. And then the buffer manager\nis moving the training data",
    "start": "4828110",
    "end": "4836710"
  },
  {
    "text": "through all of the model\ncopies, managing again,",
    "start": "4836990",
    "end": "4841990"
  },
  {
    "text": "how much data they're holding in order to keep the GPU utilization\nstable, which basically is",
    "start": "4842020",
    "end": "4849620"
  },
  {
    "text": "a fancy way of saying\nour model is training. So basically it's training\nour model, which is great.",
    "start": "4849620",
    "end": "4855770"
  },
  {
    "text": "That is exactly what we want. And so this job continues and\nhere it completed one barrier.",
    "start": "4855770",
    "end": "4862267"
  },
  {
    "text": "So it got enough gradients and then now it's distributing\nthose gradients out",
    "start": "4863150",
    "end": "4869900"
  },
  {
    "text": "and continuing. And so in this notebook, we learned how",
    "start": "4869900",
    "end": "4875720"
  },
  {
    "text": "to configure FSx for Lustre. We learned how to train on FSx for Lustre.",
    "start": "4875720",
    "end": "4882977"
  },
  {
    "text": "And we also learned how to troubleshoot. 'Cause in some cases, as long as you can troubleshoot,\nyou can do anything.",
    "start": "4882977",
    "end": "4888620"
  },
  {
    "text": "But if you can't troubleshoot,\nyou're sort of stuck. So troubleshooting with Lustre. Again, just run some CPU jobs.",
    "start": "4888620",
    "end": "4896183"
  },
  {
    "text": "If you like, you can also actually create a notebook instance in the same subnet",
    "start": "4897230",
    "end": "4905083"
  },
  {
    "text": "as your Lustre volume and\nthen just mount that directly. For me, I actually find it easier",
    "start": "4905083",
    "end": "4911690"
  },
  {
    "text": "to just run jobs using the\nwarm pools feature than to create it in the new subnet.",
    "start": "4911690",
    "end": "4919850"
  },
  {
    "text": "But depending on your skills and backgrounds, you can just\npick simply whatever you like.",
    "start": "4919850",
    "end": "4925313"
  },
  {
    "text": "And so I hope you enjoyed this demo. In the next video,\nwe're going to learn how",
    "start": "4925313",
    "end": "4931309"
  },
  {
    "text": "to do reinforcement learning\nwith human feedback on AWS. So I will see you there. Thanks.",
    "start": "4931310",
    "end": "4936983"
  }
]
[
  {
    "text": "This is My Architecture\nGumGum Verity:",
    "start": "130",
    "end": "2133"
  },
  {
    "text": "Low Latency Contextual Analysis and Data\nPrivacy at Scale on AWS Outposts",
    "start": "2133",
    "end": "4060"
  },
  {
    "text": "Welcome to This is My Architecture.",
    "start": "4553",
    "end": "6314"
  },
  {
    "text": "My name is Andrea,",
    "start": "6315",
    "end": "7364"
  },
  {
    "text": "and I'm here with Florian from GumGum.",
    "start": "7364",
    "end": "9102"
  },
  {
    "text": "Welcome to the show.",
    "start": "9102",
    "end": "10194"
  },
  {
    "text": "-Thank you.\n-So what do you guys do?",
    "start": "10194",
    "end": "11970"
  },
  {
    "text": "Yes, GumGum is a technology company",
    "start": "11970",
    "end": "13890"
  },
  {
    "text": "that is on a mission to erase\nthe use of personal data",
    "start": "13890",
    "end": "16402"
  },
  {
    "text": "in digital advertising.",
    "start": "16402",
    "end": "17784"
  },
  {
    "text": "And to do so, we power Verity,",
    "start": "17784",
    "end": "19416"
  },
  {
    "text": "our very own contextual intelligence platform",
    "start": "19416",
    "end": "21762"
  },
  {
    "text": "that provides the ability\nfor clients to classify text,",
    "start": "21762",
    "end": "24626"
  },
  {
    "text": "webpages, images, video, and audio content.",
    "start": "24626",
    "end": "27802"
  },
  {
    "text": "Great. This is on AWS.",
    "start": "27802",
    "end": "29424"
  },
  {
    "text": "-So let's dive in.\n-Sure.",
    "start": "29424",
    "end": "30986"
  },
  {
    "text": "-And find out what it does.\n-Sure.",
    "start": "30986",
    "end": "33066"
  },
  {
    "text": "So most of the work happens\nin the region here.",
    "start": "33066",
    "end": "36378"
  },
  {
    "text": "So here our clients will go,\nand talk to our API, and say,",
    "start": "36378",
    "end": "39946"
  },
  {
    "text": "for example, I want to classify\ngumgum.com webpage,",
    "start": "39946",
    "end": "43902"
  },
  {
    "text": "-and know what's in that webpage.\n-Okay.",
    "start": "43902",
    "end": "46654"
  },
  {
    "text": "So the first flow is\nusers interact with API Gateway",
    "start": "46903",
    "end": "50788"
  },
  {
    "text": "that will then communicate\nwith our EKS cluster,",
    "start": "50788",
    "end": "54440"
  },
  {
    "text": "on which we run\nour main API RESTful API project.",
    "start": "54440",
    "end": "58910"
  },
  {
    "text": "And this API will do\na database lookup on DynamoDB",
    "start": "59600",
    "end": "64823"
  },
  {
    "text": "to see if we have any information\nabout gumgum.com.",
    "start": "64824",
    "end": "67990"
  },
  {
    "text": "I see. And if that information isn't there,",
    "start": "67990",
    "end": "70549"
  },
  {
    "text": "how do you do the contextual analysis?",
    "start": "70550",
    "end": "72780"
  },
  {
    "text": "So, as part of the EKS cluster,",
    "start": "72780",
    "end": "74781"
  },
  {
    "text": "we have another component\nthat act as an orchestrator.",
    "start": "74781",
    "end": "78287"
  },
  {
    "text": "And this orchestrator will also\ninitiate a classification request",
    "start": "78288",
    "end": "83312"
  },
  {
    "text": "back to our entire GumGum AI.",
    "start": "83312",
    "end": "85380"
  },
  {
    "text": "So the Gumgum AI stack here is made of",
    "start": "85380",
    "end": "88588"
  },
  {
    "text": "natural language processing microservices,",
    "start": "88588",
    "end": "91471"
  },
  {
    "text": "as well as computer vision microservices.",
    "start": "91471",
    "end": "94244"
  },
  {
    "text": "Wonderful. So you run\nyour custom models to do the contextual,",
    "start": "94244",
    "end": "97460"
  },
  {
    "text": "and then do you store\nthat information back in DynamoDB?",
    "start": "97460",
    "end": "100324"
  },
  {
    "text": "Yeah. So there's a whole back and fold here",
    "start": "100324",
    "end": "102813"
  },
  {
    "text": "in between ECS microservices and EKS.",
    "start": "102814",
    "end": "106088"
  },
  {
    "text": "And the component here\nwill keep updating DynamoDB",
    "start": "106088",
    "end": "109175"
  },
  {
    "text": "until we get the classification\nfully complete",
    "start": "109176",
    "end": "111570"
  },
  {
    "text": "and return it back to the client.",
    "start": "111570",
    "end": "113000"
  },
  {
    "text": "Awesome. I'm super curious\nwith Outpost, right?",
    "start": "113000",
    "end": "116470"
  },
  {
    "text": "And talk us through what was the requirement",
    "start": "116470",
    "end": "119324"
  },
  {
    "text": "that led you to pick Outpost\nfor this use case?",
    "start": "119324",
    "end": "121846"
  },
  {
    "text": "Yeah. So as you guys know,",
    "start": "121846",
    "end": "123756"
  },
  {
    "text": "the AI is a process that is sometimes slow.",
    "start": "123756",
    "end": "128360"
  },
  {
    "text": "And achieving a high throughput,",
    "start": "128361",
    "end": "130752"
  },
  {
    "text": "and really low latency\non AI inference is quite challenging.",
    "start": "130752",
    "end": "134567"
  },
  {
    "text": "The system here wasn't built\nwith latency in mind,",
    "start": "135330",
    "end": "138122"
  },
  {
    "text": "but just serve different type\nof use cases, classifies video,",
    "start": "138122",
    "end": "144670"
  },
  {
    "text": "and a whole set of different things.",
    "start": "144670",
    "end": "145982"
  },
  {
    "text": "But certain clients here have\njust the need to classify webpages.",
    "start": "145982",
    "end": "150276"
  },
  {
    "text": "So the Outpost here,\nand for this specific client,",
    "start": "150276",
    "end": "153172"
  },
  {
    "text": "we needed to achieve a latency\nof less than ten milliseconds.",
    "start": "153172",
    "end": "156556"
  },
  {
    "text": "And that was our SLA.\nAnd this is doing 100K requests per second.",
    "start": "156556",
    "end": "161202"
  },
  {
    "text": "So this is really intensive.",
    "start": "161202",
    "end": "162696"
  },
  {
    "text": "Okay. So walk us through the flow rate.",
    "start": "162696",
    "end": "164354"
  },
  {
    "text": "So I see users clients say,\n\"I need that sub ten millisecond.\"",
    "start": "164354",
    "end": "169369"
  },
  {
    "text": "That's low latency. What happens?",
    "start": "169369",
    "end": "171606"
  },
  {
    "text": "Yeah. So the interesting part here is",
    "start": "171606",
    "end": "173673"
  },
  {
    "text": "that we've been redesigning\nour API product that runs here,",
    "start": "173673",
    "end": "178534"
  },
  {
    "text": "and we rewrote it in Go so that we build it",
    "start": "178534",
    "end": "181548"
  },
  {
    "text": "with direct latency in mind.",
    "start": "181548",
    "end": "183818"
  },
  {
    "text": "So we have this API product here\nrunning on EKS.",
    "start": "183818",
    "end": "187808"
  },
  {
    "text": "So we can call it our Edge API.",
    "start": "187808",
    "end": "190520"
  },
  {
    "text": "And this Edge API here, running on EKS,",
    "start": "194940",
    "end": "198436"
  },
  {
    "text": "will simply do lookups in Elasticache.",
    "start": "198436",
    "end": "201972"
  },
  {
    "text": "-I see. Okay. For retrieval of information.\n-Yeah.",
    "start": "201972",
    "end": "204670"
  },
  {
    "text": "So essentially have\nyour cluster API request coming in here.",
    "start": "204670",
    "end": "208994"
  },
  {
    "text": "Now, talk us through the rationale now,",
    "start": "208994",
    "end": "211394"
  },
  {
    "text": "what size is this,\nand what's your cache hit ratio?",
    "start": "211394",
    "end": "215144"
  },
  {
    "text": "So, part of the design\nof this whole outpost was",
    "start": "215144",
    "end": "218418"
  },
  {
    "text": "to really consider how do we want to leverage",
    "start": "218418",
    "end": "220940"
  },
  {
    "text": "those EC2 machines and to do what,",
    "start": "220940",
    "end": "222742"
  },
  {
    "text": "and how many of them we needed.",
    "start": "222742",
    "end": "224486"
  },
  {
    "text": "So, what we plan here is\nthat the Elasticache cluster is 1TB big.",
    "start": "224696",
    "end": "229722"
  },
  {
    "text": "So we dedicate a bunch of nodes\nto run the Redis cluster.",
    "start": "229722",
    "end": "234752"
  },
  {
    "text": "But here, as you can see,\nthere might be a challenge here",
    "start": "234752",
    "end": "237198"
  },
  {
    "text": "where we have 15TB\nof classification data in DynamoDB,",
    "start": "237198",
    "end": "242084"
  },
  {
    "text": "and basically, not all the data here\nfits in the cluster.",
    "start": "242084",
    "end": "246212"
  },
  {
    "text": "And if we can talk",
    "start": "246212",
    "end": "248081"
  },
  {
    "text": "-about eviction process,\n-Yeah.",
    "start": "248082",
    "end": "249979"
  },
  {
    "text": "what's your cache hitch ratio,\nand what's the eviction process?",
    "start": "249979",
    "end": "253602"
  },
  {
    "text": "How often do you store new information on it?",
    "start": "253602",
    "end": "257510"
  },
  {
    "text": "Yeah, so new information is\nbeing stored just in real time.",
    "start": "257511",
    "end": "261409"
  },
  {
    "text": "We keep adding new data because\nthis client keeps asking for new pages.",
    "start": "261410",
    "end": "265944"
  },
  {
    "text": "And the web is dynamic by nature,",
    "start": "265944",
    "end": "268434"
  },
  {
    "text": "so we keep getting new information.",
    "start": "268434",
    "end": "270038"
  },
  {
    "text": "What matters for these clients is to get",
    "start": "270038",
    "end": "272406"
  },
  {
    "text": "as much contextual information as possible.",
    "start": "272406",
    "end": "275366"
  },
  {
    "text": "So the least frequently used page\nis not really useful",
    "start": "275366",
    "end": "280156"
  },
  {
    "text": "to be stored in this cache,",
    "start": "280156",
    "end": "281809"
  },
  {
    "text": "given that we have only 1 TB.",
    "start": "281809",
    "end": "283535"
  },
  {
    "text": "So we use a list recently used\neviction policy,",
    "start": "283536",
    "end": "286826"
  },
  {
    "text": "which means that\nour Elasticache cluster is always full,",
    "start": "287036",
    "end": "289162"
  },
  {
    "text": "and always evicting data\nto store new contextual data coming.",
    "start": "289162",
    "end": "292746"
  },
  {
    "text": "And assume that you have\nnot seen that webpage before,",
    "start": "292746",
    "end": "296478"
  },
  {
    "text": "so there's no contextual information here,\nwhat do you do?",
    "start": "296478",
    "end": "299232"
  },
  {
    "text": "Correct.\nSo, to close the gap on the other side,",
    "start": "299232",
    "end": "301742"
  },
  {
    "text": "so here we have a replication process\nin between this region",
    "start": "301742",
    "end": "305576"
  },
  {
    "text": "that will sync up the data\nfrom Dynamo to Redis.",
    "start": "305576",
    "end": "309512"
  },
  {
    "text": "But now on the other side,\nthis component here,",
    "start": "309512",
    "end": "312211"
  },
  {
    "text": "the Edge API, is also aware of,",
    "start": "312211",
    "end": "317410"
  },
  {
    "text": "where do I go if I need\nto initiate a new classification?",
    "start": "317410",
    "end": "320153"
  },
  {
    "text": "And this message will be sent back\nto the main region,",
    "start": "320153",
    "end": "323676"
  },
  {
    "text": "to another component here\nthat we run on our EKS",
    "start": "323676",
    "end": "326988"
  },
  {
    "text": "so that we can just resume\nthe first loop that we went through.",
    "start": "326988",
    "end": "330346"
  },
  {
    "text": "So you have an orchestration",
    "start": "330346",
    "end": "332281"
  },
  {
    "text": "essentially kicking off\nthat whole AI/ML analytics,",
    "start": "332600",
    "end": "336192"
  },
  {
    "text": "-and then bringing back onto Elasticache.\n-That is correct.",
    "start": "336192",
    "end": "340185"
  },
  {
    "text": "Awesome, Florian.\nThank you so much for walking us",
    "start": "340186",
    "end": "342122"
  },
  {
    "text": "through this contextual platform\nthat you built",
    "start": "342122",
    "end": "345002"
  },
  {
    "text": "for low latency requirements.",
    "start": "345002",
    "end": "347968"
  },
  {
    "text": "And we truly have appreciated this overview.",
    "start": "347968",
    "end": "351177"
  },
  {
    "text": "Thank you.",
    "start": "351178",
    "end": "352187"
  },
  {
    "text": "Thank you for watching\nThis is My Architecture.",
    "start": "352187",
    "end": "354344"
  },
  {
    "text": "Thank you for Watching",
    "start": "354671",
    "end": "357806"
  }
]
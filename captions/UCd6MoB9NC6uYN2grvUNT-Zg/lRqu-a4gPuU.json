[
  {
    "start": "0",
    "end": "76000"
  },
  {
    "text": "everyone my name is yang I li tech at",
    "start": "79",
    "end": "3600"
  },
  {
    "text": "SAC adapt this is Ned he leads data at",
    "start": "3600",
    "end": "6390"
  },
  {
    "text": "SAC adapt and officially to engineering",
    "start": "6390",
    "end": "8519"
  },
  {
    "text": "so today we're going to be talking about",
    "start": "8519",
    "end": "10139"
  },
  {
    "text": "all the cool different things that we've",
    "start": "10139",
    "end": "12360"
  },
  {
    "text": "been doing on Amazon our whole",
    "start": "12360",
    "end": "14250"
  },
  {
    "text": "infrastructure is hosted on Amazon we",
    "start": "14250",
    "end": "16800"
  },
  {
    "text": "started around just under five years ago",
    "start": "16800",
    "end": "20000"
  },
  {
    "text": "the main problems we tend to solve on",
    "start": "20000",
    "end": "23730"
  },
  {
    "text": "Amazon our scalability analytics and",
    "start": "23730",
    "end": "26699"
  },
  {
    "text": "massive amounts of data to give you guys",
    "start": "26699",
    "end": "29640"
  },
  {
    "text": "a quick intro our company is in the",
    "start": "29640",
    "end": "32308"
  },
  {
    "text": "online advertising space so clients have",
    "start": "32309",
    "end": "35550"
  },
  {
    "text": "to come to us and run ad campaigns and",
    "start": "35550",
    "end": "37739"
  },
  {
    "text": "we target over up to a billion users",
    "start": "37739",
    "end": "39629"
  },
  {
    "text": "online so for this we're integrated with",
    "start": "39629",
    "end": "42570"
  },
  {
    "text": "up to 550 thousand websites and apps and",
    "start": "42570",
    "end": "45390"
  },
  {
    "text": "so that's a lot of scale we have to",
    "start": "45390",
    "end": "47370"
  },
  {
    "text": "handle because let's say every time you",
    "start": "47370",
    "end": "49469"
  },
  {
    "text": "go to a website let's say CNN that would",
    "start": "49469",
    "end": "52260"
  },
  {
    "text": "hit our server because we have to load",
    "start": "52260",
    "end": "55770"
  },
  {
    "text": "an ad for you possibly so we have to",
    "start": "55770",
    "end": "59219"
  },
  {
    "text": "essentially handle the traffic of all",
    "start": "59219",
    "end": "61379"
  },
  {
    "text": "these a huge portion of the Internet at",
    "start": "61379",
    "end": "63750"
  },
  {
    "text": "peak times we have to do up to 500,000",
    "start": "63750",
    "end": "67530"
  },
  {
    "text": "to a million QPS so first I'm going to",
    "start": "67530",
    "end": "71310"
  },
  {
    "text": "be talking about scalability and how we",
    "start": "71310",
    "end": "73290"
  },
  {
    "text": "did that efficiently as you can imagine",
    "start": "73290",
    "end": "77960"
  },
  {
    "start": "76000",
    "end": "105000"
  },
  {
    "text": "during the day there's going to be a lot",
    "start": "77960",
    "end": "80369"
  },
  {
    "text": "more traffic than during the night so we",
    "start": "80369",
    "end": "82740"
  },
  {
    "text": "don't want to always be spinning up",
    "start": "82740",
    "end": "84540"
  },
  {
    "text": "servers you know a static amount of",
    "start": "84540",
    "end": "87780"
  },
  {
    "text": "servers we want to bring up servers and",
    "start": "87780",
    "end": "89610"
  },
  {
    "text": "bring them down when there isn't that",
    "start": "89610",
    "end": "92009"
  },
  {
    "text": "much load to handle and so for when we",
    "start": "92009",
    "end": "94500"
  },
  {
    "text": "process these requests we also have to",
    "start": "94500",
    "end": "96240"
  },
  {
    "text": "do it very quickly and we have to",
    "start": "96240",
    "end": "98130"
  },
  {
    "text": "respond with the quest in under 100",
    "start": "98130",
    "end": "99720"
  },
  {
    "text": "milliseconds so and we have to ensure",
    "start": "99720",
    "end": "102150"
  },
  {
    "text": "that our servers are also functioning",
    "start": "102150",
    "end": "103680"
  },
  {
    "text": "correctly so one of the main things we",
    "start": "103680",
    "end": "108090"
  },
  {
    "start": "105000",
    "end": "157000"
  },
  {
    "text": "utilize is spa instances for those who",
    "start": "108090",
    "end": "110909"
  },
  {
    "text": "don't know spa instances are essentially",
    "start": "110909",
    "end": "114200"
  },
  {
    "text": "unutilized capacity on Amazon that you",
    "start": "114200",
    "end": "116909"
  },
  {
    "text": "can bid on and so Amazon will calculate",
    "start": "116909",
    "end": "119399"
  },
  {
    "text": "a price based on the demand and many",
    "start": "119399",
    "end": "122549"
  },
  {
    "text": "times around 80 most of the time you can",
    "start": "122549",
    "end": "125130"
  },
  {
    "text": "get up to 70 to 80 percent discounts on",
    "start": "125130",
    "end": "127590"
  },
  {
    "text": "the normal price of a server the only",
    "start": "127590",
    "end": "130940"
  },
  {
    "text": "catch is that these servers",
    "start": "130940",
    "end": "133440"
  },
  {
    "text": "died at any time because someone else",
    "start": "133440",
    "end": "135780"
  },
  {
    "text": "could outbid you or they could be you",
    "start": "135780",
    "end": "138510"
  },
  {
    "text": "know utilized by someone buying reserved",
    "start": "138510",
    "end": "141120"
  },
  {
    "text": "instances for example so these instances",
    "start": "141120",
    "end": "144960"
  },
  {
    "text": "are very good for handling requests that",
    "start": "144960",
    "end": "147960"
  },
  {
    "text": "you know that don't have to be",
    "start": "147960",
    "end": "150690"
  },
  {
    "text": "essentially that can be interrupted and",
    "start": "150690",
    "end": "153720"
  },
  {
    "text": "they're really good for handling massive",
    "start": "153720",
    "end": "155160"
  },
  {
    "text": "amounts of traffic so Amazon has",
    "start": "155160",
    "end": "158160"
  },
  {
    "start": "157000",
    "end": "329000"
  },
  {
    "text": "something called auto scaling that you",
    "start": "158160",
    "end": "159900"
  },
  {
    "text": "could use to help Auto scale services",
    "start": "159900",
    "end": "162630"
  },
  {
    "text": "down and up as you go along but we",
    "start": "162630",
    "end": "165540"
  },
  {
    "text": "actually built our own autoscaler that's",
    "start": "165540",
    "end": "169200"
  },
  {
    "text": "because for us you know being efficient",
    "start": "169200",
    "end": "171600"
  },
  {
    "text": "with price is really critical for us so",
    "start": "171600",
    "end": "174900"
  },
  {
    "text": "because amazon has different types of",
    "start": "174900",
    "end": "177180"
  },
  {
    "text": "servers on spa instances typically with",
    "start": "177180",
    "end": "180510"
  },
  {
    "text": "normal auto scaling you can only bid on",
    "start": "180510",
    "end": "182370"
  },
  {
    "text": "one type one group of these types right",
    "start": "182370",
    "end": "184470"
  },
  {
    "text": "so we wanted to build our own logic in",
    "start": "184470",
    "end": "187310"
  },
  {
    "text": "determining a set of servers that we",
    "start": "187310",
    "end": "190380"
  },
  {
    "text": "bring up we we know that during certain",
    "start": "190380",
    "end": "193760"
  },
  {
    "text": "times of the day we need so many amount",
    "start": "193760",
    "end": "197820"
  },
  {
    "text": "of CPUs that need to be running you know",
    "start": "197820",
    "end": "199860"
  },
  {
    "text": "CPU RAM that we need so what we would do",
    "start": "199860",
    "end": "203400"
  },
  {
    "text": "is that we would look at the price per",
    "start": "203400",
    "end": "206430"
  },
  {
    "text": "processing power across all the",
    "start": "206430",
    "end": "208470"
  },
  {
    "text": "different types of these instances we",
    "start": "208470",
    "end": "210810"
  },
  {
    "text": "would then bid on the cheapest ones and",
    "start": "210810",
    "end": "212580"
  },
  {
    "text": "get as many of them as possible and then",
    "start": "212580",
    "end": "214470"
  },
  {
    "text": "move on to the next type anytime let's",
    "start": "214470",
    "end": "217020"
  },
  {
    "text": "say we get outbid we would then look at",
    "start": "217020",
    "end": "218910"
  },
  {
    "text": "the next cheapest type so in the end we",
    "start": "218910",
    "end": "221760"
  },
  {
    "text": "may end up with the mix of servers with",
    "start": "221760",
    "end": "224370"
  },
  {
    "text": "varying types varying powers some larger",
    "start": "224370",
    "end": "227100"
  },
  {
    "text": "than others but they would all add up to",
    "start": "227100",
    "end": "229260"
  },
  {
    "text": "the same amount of processing power that",
    "start": "229260",
    "end": "231030"
  },
  {
    "text": "we need it also handles some logic let's",
    "start": "231030",
    "end": "234690"
  },
  {
    "text": "say some of them one server for whatever",
    "start": "234690",
    "end": "236820"
  },
  {
    "text": "reason is slower than the others our",
    "start": "236820",
    "end": "238920"
  },
  {
    "text": "system would also try to reboot it to",
    "start": "238920",
    "end": "241140"
  },
  {
    "text": "see if it restarting it will speed it up",
    "start": "241140",
    "end": "243570"
  },
  {
    "text": "and if that doesn't work then we will",
    "start": "243570",
    "end": "245370"
  },
  {
    "text": "terminate it and wait for a better",
    "start": "245370",
    "end": "246780"
  },
  {
    "text": "server to spin up let's say for whatever",
    "start": "246780",
    "end": "249510"
  },
  {
    "text": "reason traffic will spike our server",
    "start": "249510",
    "end": "252150"
  },
  {
    "text": "will look at a certain number of health",
    "start": "252150",
    "end": "253770"
  },
  {
    "text": "metrics such as response times CPU usage",
    "start": "253770",
    "end": "257430"
  },
  {
    "text": "and spin up additional servers as needed",
    "start": "257430",
    "end": "259320"
  },
  {
    "text": "so all this is pretty much dynamic so",
    "start": "259320",
    "end": "262109"
  },
  {
    "text": "during the day we'll have more servers",
    "start": "262109",
    "end": "263700"
  },
  {
    "text": "during the night will have less servers",
    "start": "263700",
    "end": "265830"
  },
  {
    "text": "and we're",
    "start": "265830",
    "end": "266700"
  },
  {
    "text": "always paying the cheapest price",
    "start": "266700",
    "end": "268290"
  },
  {
    "text": "possible on the whole Amazon in that",
    "start": "268290",
    "end": "270810"
  },
  {
    "text": "region essentially and we do this on",
    "start": "270810",
    "end": "272940"
  },
  {
    "text": "three different regions us east us west",
    "start": "272940",
    "end": "274950"
  },
  {
    "text": "and Europe so to give you guys in a",
    "start": "274950",
    "end": "279630"
  },
  {
    "text": "graph this is the amount of CPU we use",
    "start": "279630",
    "end": "283320"
  },
  {
    "text": "during the day and during the night it",
    "start": "283320",
    "end": "285300"
  },
  {
    "text": "goes down and this is the amount of",
    "start": "285300",
    "end": "286890"
  },
  {
    "text": "requests that we process during the day",
    "start": "286890",
    "end": "290220"
  },
  {
    "text": "and during the night so it's always up",
    "start": "290220",
    "end": "292140"
  },
  {
    "text": "and down and so our servers have to",
    "start": "292140",
    "end": "294300"
  },
  {
    "text": "pretty much behave the same way and we",
    "start": "294300",
    "end": "297150"
  },
  {
    "text": "built our own systems essentially get",
    "start": "297150",
    "end": "300780"
  },
  {
    "text": "all this processing power as cheap as",
    "start": "300780",
    "end": "302820"
  },
  {
    "text": "possible and here's where we monitor all",
    "start": "302820",
    "end": "305010"
  },
  {
    "text": "our different servers we look at the",
    "start": "305010",
    "end": "306690"
  },
  {
    "text": "response times the number of you know",
    "start": "306690",
    "end": "309120"
  },
  {
    "text": "bidding for ads that were bringing out",
    "start": "309120",
    "end": "311970"
  },
  {
    "text": "and the whole system health and this",
    "start": "311970",
    "end": "315180"
  },
  {
    "text": "automated system we built called Skynet",
    "start": "315180",
    "end": "316950"
  },
  {
    "text": "essentially looks at all these metrics",
    "start": "316950",
    "end": "318540"
  },
  {
    "text": "to determine you know how many to",
    "start": "318540",
    "end": "320700"
  },
  {
    "text": "determine how many servers to spawn and",
    "start": "320700",
    "end": "322920"
  },
  {
    "text": "how to manage all these servers so yeah",
    "start": "322920",
    "end": "325050"
  },
  {
    "text": "that's essentially on a high level how",
    "start": "325050",
    "end": "326790"
  },
  {
    "text": "we handle auto scaling at stack it up so",
    "start": "326790",
    "end": "329550"
  },
  {
    "text": "next I'm gonna hand it over to Ned that",
    "start": "329550",
    "end": "331980"
  },
  {
    "text": "will talk who will talk more about our",
    "start": "331980",
    "end": "333450"
  },
  {
    "text": "machine learning hi everybody my name is",
    "start": "333450",
    "end": "338010"
  },
  {
    "text": "Ned I'm in charge of data science that",
    "start": "338010",
    "end": "340230"
  },
  {
    "text": "stack adapt and today I'll tell you a",
    "start": "340230",
    "end": "342300"
  },
  {
    "text": "little bit about our machine learning",
    "start": "342300",
    "end": "343800"
  },
  {
    "text": "and bid optimization tools that we've",
    "start": "343800",
    "end": "346440"
  },
  {
    "text": "developed that stack adapt for the",
    "start": "346440",
    "end": "348810"
  },
  {
    "text": "purposes of bidding and these real-time",
    "start": "348810",
    "end": "351480"
  },
  {
    "text": "advertising auctions so the way to think",
    "start": "351480",
    "end": "355530"
  },
  {
    "start": "353000",
    "end": "461000"
  },
  {
    "text": "about it is to separate the things that",
    "start": "355530",
    "end": "358530"
  },
  {
    "text": "we need to do into several tasks and",
    "start": "358530",
    "end": "360330"
  },
  {
    "text": "then the various tools that we use to",
    "start": "360330",
    "end": "361860"
  },
  {
    "text": "address those tasks so one of our major",
    "start": "361860",
    "end": "364920"
  },
  {
    "text": "tasks is click-through rate prediction",
    "start": "364920",
    "end": "366900"
  },
  {
    "text": "so when we get a bid request we have to",
    "start": "366900",
    "end": "369660"
  },
  {
    "text": "at the time of that the bid request",
    "start": "369660",
    "end": "371010"
  },
  {
    "text": "arrives to one of the servers very",
    "start": "371010",
    "end": "372480"
  },
  {
    "text": "quickly determine what's the likelihood",
    "start": "372480",
    "end": "375420"
  },
  {
    "text": "that a user is going to click on this",
    "start": "375420",
    "end": "377040"
  },
  {
    "text": "particular advertisement if we show them",
    "start": "377040",
    "end": "379260"
  },
  {
    "text": "the advertisement and we have to do that",
    "start": "379260",
    "end": "381420"
  },
  {
    "text": "in sub 100 millisecond time so it has to",
    "start": "381420",
    "end": "384840"
  },
  {
    "text": "happen very very quickly another thing",
    "start": "384840",
    "end": "387960"
  },
  {
    "text": "that we need to do is identify similar",
    "start": "387960",
    "end": "390240"
  },
  {
    "text": "users so for example oftentimes",
    "start": "390240",
    "end": "392100"
  },
  {
    "text": "advertisers are concerned with",
    "start": "392100",
    "end": "394010"
  },
  {
    "text": "conversions so for example users",
    "start": "394010",
    "end": "396270"
  },
  {
    "text": "purchasing their product and what they",
    "start": "396270",
    "end": "398370"
  },
  {
    "text": "like to do is they'd like to find out",
    "start": "398370",
    "end": "399900"
  },
  {
    "text": "you",
    "start": "399900",
    "end": "400380"
  },
  {
    "text": "that are similar to the users that have",
    "start": "400380",
    "end": "402090"
  },
  {
    "text": "purchased their product in the past and",
    "start": "402090",
    "end": "404850"
  },
  {
    "text": "so that's one of the things that we do",
    "start": "404850",
    "end": "406860"
  },
  {
    "text": "and the third thing that we do is we",
    "start": "406860",
    "end": "410330"
  },
  {
    "text": "think very carefully about what kind of",
    "start": "410330",
    "end": "413340"
  },
  {
    "text": "bids we should submit to these real-time",
    "start": "413340",
    "end": "415050"
  },
  {
    "text": "auctions so exactly what should be the",
    "start": "415050",
    "end": "417930"
  },
  {
    "text": "price that we submit to a real-time",
    "start": "417930",
    "end": "420090"
  },
  {
    "text": "auction at a particular hour of the day",
    "start": "420090",
    "end": "422010"
  },
  {
    "text": "for a particular advertiser for a",
    "start": "422010",
    "end": "423870"
  },
  {
    "text": "particular campaign and the tools that",
    "start": "423870",
    "end": "426960"
  },
  {
    "text": "we used to address these tasks are very",
    "start": "426960",
    "end": "429710"
  },
  {
    "text": "much elastic MapReduce so that's what we",
    "start": "429710",
    "end": "432960"
  },
  {
    "text": "use primarily to process all of our data",
    "start": "432960",
    "end": "435030"
  },
  {
    "text": "and to do our machine learning and",
    "start": "435030",
    "end": "437780"
  },
  {
    "text": "optimization so that combined with spark",
    "start": "437780",
    "end": "440810"
  },
  {
    "text": "spark because that processes the data",
    "start": "440810",
    "end": "443640"
  },
  {
    "text": "very efficiently and has various machine",
    "start": "443640",
    "end": "446610"
  },
  {
    "text": "learning libraries built into it that",
    "start": "446610",
    "end": "448080"
  },
  {
    "text": "will let us scale to the size that we",
    "start": "448080",
    "end": "449670"
  },
  {
    "text": "want and then we also use Python and",
    "start": "449670",
    "end": "452610"
  },
  {
    "text": "some custom in-house software that we",
    "start": "452610",
    "end": "454470"
  },
  {
    "text": "developed to be able to scale Python out",
    "start": "454470",
    "end": "457020"
  },
  {
    "text": "in a parallel fashion across the EMR so",
    "start": "457020",
    "end": "461490"
  },
  {
    "start": "461000",
    "end": "548000"
  },
  {
    "text": "let me go into each one of the TAS in a",
    "start": "461490",
    "end": "463620"
  },
  {
    "text": "little bit more detail so in terms of",
    "start": "463620",
    "end": "466530"
  },
  {
    "text": "click to rate prediction like I said we",
    "start": "466530",
    "end": "468720"
  },
  {
    "text": "have to do this click through rate",
    "start": "468720",
    "end": "470010"
  },
  {
    "text": "prediction very quickly and in the time",
    "start": "470010",
    "end": "472950"
  },
  {
    "text": "of maybe 20 milliseconds or less when we",
    "start": "472950",
    "end": "475740"
  },
  {
    "text": "receive a bid request and what we have",
    "start": "475740",
    "end": "478170"
  },
  {
    "text": "is a system that does this prediction",
    "start": "478170",
    "end": "480090"
  },
  {
    "text": "based on 50000 features of the bid",
    "start": "480090",
    "end": "482580"
  },
  {
    "text": "requests so quite a sophisticated",
    "start": "482580",
    "end": "486260"
  },
  {
    "text": "machine learning tool especially when it",
    "start": "486260",
    "end": "489900"
  },
  {
    "text": "comes to the feature development and we",
    "start": "489900",
    "end": "492450"
  },
  {
    "text": "train the model daily and we have",
    "start": "492450",
    "end": "494730"
  },
  {
    "text": "hundreds of millions of historical",
    "start": "494730",
    "end": "496350"
  },
  {
    "text": "examples to train the model on in",
    "start": "496350",
    "end": "498990"
  },
  {
    "text": "particular stack adept service anywhere",
    "start": "498990",
    "end": "501510"
  },
  {
    "text": "between 50 million and a hundred million",
    "start": "501510",
    "end": "503490"
  },
  {
    "text": "ad impressions per day and so we use",
    "start": "503490",
    "end": "506130"
  },
  {
    "text": "those historical ad impressions and",
    "start": "506130",
    "end": "507990"
  },
  {
    "text": "whether a person clicked on them or not",
    "start": "507990",
    "end": "509880"
  },
  {
    "text": "as our training data set for this click",
    "start": "509880",
    "end": "512580"
  },
  {
    "text": "through rate prediction and so in doing",
    "start": "512580",
    "end": "516659"
  },
  {
    "text": "this training we're regularly hitting",
    "start": "516660",
    "end": "518460"
  },
  {
    "text": "the limits of the combination of spark",
    "start": "518460",
    "end": "521070"
  },
  {
    "text": "Rolla CMR to process data so we often",
    "start": "521070",
    "end": "523710"
  },
  {
    "text": "get things like out of memory errors or",
    "start": "523710",
    "end": "526200"
  },
  {
    "text": "out of this space errors whenever spark",
    "start": "526200",
    "end": "528180"
  },
  {
    "text": "has to do a shuffle across a large data",
    "start": "528180",
    "end": "530550"
  },
  {
    "text": "set and so to handle this",
    "start": "530550",
    "end": "533880"
  },
  {
    "text": "we have so much data that we actually",
    "start": "533880",
    "end": "535350"
  },
  {
    "text": "have to down sample our historical data",
    "start": "535350",
    "end": "538200"
  },
  {
    "text": "to get feasible computation so when I",
    "start": "538200",
    "end": "542100"
  },
  {
    "text": "say feasible computation I mean both in",
    "start": "542100",
    "end": "544140"
  },
  {
    "text": "time in terms of time and in terms of",
    "start": "544140",
    "end": "546600"
  },
  {
    "text": "memory so this is the kind of",
    "start": "546600",
    "end": "550320"
  },
  {
    "start": "548000",
    "end": "601000"
  },
  {
    "text": "state-of-the-art predictor that we have",
    "start": "550320",
    "end": "552260"
  },
  {
    "text": "so just to help you read this graph on",
    "start": "552260",
    "end": "554760"
  },
  {
    "text": "the horizontal axis we have the click",
    "start": "554760",
    "end": "556890"
  },
  {
    "text": "through rate prediction and on the",
    "start": "556890",
    "end": "558750"
  },
  {
    "text": "vertical axis we have the empirical",
    "start": "558750",
    "end": "560400"
  },
  {
    "text": "click-through rate and this red line is",
    "start": "560400",
    "end": "562950"
  },
  {
    "text": "the ideal x equals y line it's when your",
    "start": "562950",
    "end": "565200"
  },
  {
    "text": "prediction is exactly equal to the",
    "start": "565200",
    "end": "566790"
  },
  {
    "text": "empirical rate and that's where we'd",
    "start": "566790",
    "end": "568170"
  },
  {
    "text": "like to be and the vast majority of",
    "start": "568170",
    "end": "571250"
  },
  {
    "text": "requests are down here are very low",
    "start": "571250",
    "end": "573390"
  },
  {
    "text": "click-through rates and then as you go",
    "start": "573390",
    "end": "575580"
  },
  {
    "text": "up into higher click-through rates",
    "start": "575580",
    "end": "577200"
  },
  {
    "text": "there's less and less requests at those",
    "start": "577200",
    "end": "580260"
  },
  {
    "text": "levels and that's why you can see with",
    "start": "580260",
    "end": "582750"
  },
  {
    "text": "the more see-through circles at higher",
    "start": "582750",
    "end": "586200"
  },
  {
    "text": "request levels but as you can see from",
    "start": "586200",
    "end": "588390"
  },
  {
    "text": "this graph we're very close to hitting",
    "start": "588390",
    "end": "590850"
  },
  {
    "text": "that ideal prediction line and this is",
    "start": "590850",
    "end": "593490"
  },
  {
    "text": "very much due to the number of features",
    "start": "593490",
    "end": "595440"
  },
  {
    "text": "that we use and due to the large amount",
    "start": "595440",
    "end": "597990"
  },
  {
    "text": "of historical data that we use to",
    "start": "597990",
    "end": "599520"
  },
  {
    "text": "actually train our predictor so the next",
    "start": "599520",
    "end": "602910"
  },
  {
    "start": "601000",
    "end": "679000"
  },
  {
    "text": "test though well I talked about was",
    "start": "602910",
    "end": "604860"
  },
  {
    "text": "similar user identification so in our",
    "start": "604860",
    "end": "607890"
  },
  {
    "text": "database we have 1.3 billion users so",
    "start": "607890",
    "end": "611550"
  },
  {
    "text": "users are typically identified by a",
    "start": "611550",
    "end": "613290"
  },
  {
    "text": "cookie ID a device ID or IP address and",
    "start": "613290",
    "end": "616770"
  },
  {
    "text": "we have some information about the user",
    "start": "616770",
    "end": "619410"
  },
  {
    "text": "for example perhaps some information",
    "start": "619410",
    "end": "623730"
  },
  {
    "text": "about what websites the user has been",
    "start": "623730",
    "end": "625680"
  },
  {
    "text": "reading historically so we generate",
    "start": "625680",
    "end": "628500"
  },
  {
    "text": "features based on this user history and",
    "start": "628500",
    "end": "630510"
  },
  {
    "text": "the kind of history that we have on the",
    "start": "630510",
    "end": "632340"
  },
  {
    "text": "user's and we identify similar users and",
    "start": "632340",
    "end": "635550"
  },
  {
    "text": "to do this we use the similar in fact",
    "start": "635550",
    "end": "638070"
  },
  {
    "text": "almost exactly the same spark plus EMR",
    "start": "638070",
    "end": "640770"
  },
  {
    "text": "pipeline that we use for our",
    "start": "640770",
    "end": "642570"
  },
  {
    "text": "click-through rate predictor except now",
    "start": "642570",
    "end": "644610"
  },
  {
    "text": "it's just a different machine learning",
    "start": "644610",
    "end": "645930"
  },
  {
    "text": "task so now we have users instead of",
    "start": "645930",
    "end": "648230"
  },
  {
    "text": "impressions and the goal is to identify",
    "start": "648230",
    "end": "650840"
  },
  {
    "text": "similarity as opposed to whether it's",
    "start": "650840",
    "end": "653970"
  },
  {
    "text": "going to be a click or not and it turns",
    "start": "653970",
    "end": "656730"
  },
  {
    "text": "out that for both of these tasks caching",
    "start": "656730",
    "end": "658770"
  },
  {
    "text": "data on s3",
    "start": "658770",
    "end": "659700"
  },
  {
    "text": "ends up being critical for the machine",
    "start": "659700",
    "end": "662070"
  },
  {
    "text": "learning pipeline so for example feature",
    "start": "662070",
    "end": "664410"
  },
  {
    "text": "generation for",
    "start": "664410",
    "end": "666110"
  },
  {
    "text": "these billion users is quite",
    "start": "666110",
    "end": "668600"
  },
  {
    "text": "computationally intensive it takes a",
    "start": "668600",
    "end": "670640"
  },
  {
    "text": "long time to actually generate the",
    "start": "670640",
    "end": "671899"
  },
  {
    "text": "features for a billion users and so we",
    "start": "671899",
    "end": "674959"
  },
  {
    "text": "have to end up caching that on s3 to",
    "start": "674959",
    "end": "676760"
  },
  {
    "text": "make things computationally feasible and",
    "start": "676760",
    "end": "679850"
  },
  {
    "start": "679000",
    "end": "755000"
  },
  {
    "text": "the final test that I wanted to tell you",
    "start": "679850",
    "end": "681890"
  },
  {
    "text": "about today is our bid optimization so",
    "start": "681890",
    "end": "684290"
  },
  {
    "text": "here we use a sophisticated mathematical",
    "start": "684290",
    "end": "686420"
  },
  {
    "text": "model of auctions and in this",
    "start": "686420",
    "end": "688399"
  },
  {
    "text": "mathematical model we do things like",
    "start": "688399",
    "end": "690260"
  },
  {
    "text": "predict the likelihood of winning at a",
    "start": "690260",
    "end": "691970"
  },
  {
    "text": "particular price the probability of",
    "start": "691970",
    "end": "695029"
  },
  {
    "text": "winning at a particular price we split",
    "start": "695029",
    "end": "697880"
  },
  {
    "text": "the budgets across various inventories",
    "start": "697880",
    "end": "699950"
  },
  {
    "text": "that are available and we optimize the",
    "start": "699950",
    "end": "701990"
  },
  {
    "text": "performance of a campaign and the",
    "start": "701990",
    "end": "703610"
  },
  {
    "text": "revenue that the company is going to",
    "start": "703610",
    "end": "704990"
  },
  {
    "text": "receive from a particular campaign but",
    "start": "704990",
    "end": "707329"
  },
  {
    "text": "just to give you an idea of the scale",
    "start": "707329",
    "end": "708680"
  },
  {
    "text": "here we have about 1500 campaigns and we",
    "start": "708680",
    "end": "712490"
  },
  {
    "text": "optimize these bid prices on an hourly",
    "start": "712490",
    "end": "714350"
  },
  {
    "text": "basis so there's 24 optimization per",
    "start": "714350",
    "end": "717470"
  },
  {
    "text": "campaign daily that we have to run so",
    "start": "717470",
    "end": "720260"
  },
  {
    "text": "that gives us about 36,000 optimizations",
    "start": "720260",
    "end": "722720"
  },
  {
    "text": "daily so the way that we are able to get",
    "start": "722720",
    "end": "726320"
  },
  {
    "text": "that amount of computing power to",
    "start": "726320",
    "end": "727760"
  },
  {
    "text": "actually solve these optimizations is",
    "start": "727760",
    "end": "730010"
  },
  {
    "text": "with six EMR clusters that accounts for",
    "start": "730010",
    "end": "732800"
  },
  {
    "text": "about 1,800 virtual cores and that one's",
    "start": "732800",
    "end": "736370"
  },
  {
    "text": "for about 30 minutes to solve all our",
    "start": "736370",
    "end": "738019"
  },
  {
    "text": "optimization problems to compute the bid",
    "start": "738019",
    "end": "740089"
  },
  {
    "text": "prices that go into the auctions that we",
    "start": "740089",
    "end": "742850"
  },
  {
    "text": "participate in and to do this instead of",
    "start": "742850",
    "end": "745760"
  },
  {
    "text": "using spark in EMR we use parallel",
    "start": "745760",
    "end": "747920"
  },
  {
    "text": "Python and EMR so Python has a number of",
    "start": "747920",
    "end": "751250"
  },
  {
    "text": "optimization tools that are quite useful",
    "start": "751250",
    "end": "753529"
  },
  {
    "text": "for achieving this task so thanks very",
    "start": "753529",
    "end": "757040"
  },
  {
    "start": "755000",
    "end": "779000"
  },
  {
    "text": "much next I'll pass it to a feature",
    "start": "757040",
    "end": "758360"
  },
  {
    "text": "who's our leader of engineering good",
    "start": "758360",
    "end": "764480"
  },
  {
    "text": "afternoon everyone",
    "start": "764480",
    "end": "765560"
  },
  {
    "text": "so I'm going take a few minutes of your",
    "start": "765560",
    "end": "766820"
  },
  {
    "text": "time to talk about how we built an",
    "start": "766820",
    "end": "768890"
  },
  {
    "text": "infrastructure at stock a tab that is",
    "start": "768890",
    "end": "771230"
  },
  {
    "text": "able to index analyze billions of",
    "start": "771230",
    "end": "774110"
  },
  {
    "text": "records using reshef lambda and Kinesis",
    "start": "774110",
    "end": "778779"
  },
  {
    "text": "so for those who of you who are not",
    "start": "778779",
    "end": "781339"
  },
  {
    "start": "779000",
    "end": "810000"
  },
  {
    "text": "familiar with the terminology I'm just",
    "start": "781339",
    "end": "782990"
  },
  {
    "text": "going to quickly talk about them so",
    "start": "782990",
    "end": "784339"
  },
  {
    "text": "redshift is basically a data warehouse",
    "start": "784339",
    "end": "787089"
  },
  {
    "text": "product on AWS that is meant to be",
    "start": "787089",
    "end": "790370"
  },
  {
    "text": "highly scalable and cost-effective",
    "start": "790370",
    "end": "792680"
  },
  {
    "text": "Kinesis is a streaming service which is",
    "start": "792680",
    "end": "795649"
  },
  {
    "text": "which allows you to load massive",
    "start": "795649",
    "end": "797769"
  },
  {
    "text": "so data in any of the Amazon services",
    "start": "797769",
    "end": "799209"
  },
  {
    "text": "and lambda is basically a server list",
    "start": "799209",
    "end": "803699"
  },
  {
    "text": "it's basically a product that allows you",
    "start": "803699",
    "end": "805869"
  },
  {
    "text": "to run code without managing or",
    "start": "805869",
    "end": "808239"
  },
  {
    "text": "provisioning servers so some of the",
    "start": "808239",
    "end": "812050"
  },
  {
    "start": "810000",
    "end": "886000"
  },
  {
    "text": "goals for building this infrastructure -",
    "start": "812050",
    "end": "815639"
  },
  {
    "text": "or some of the goals that we kept in",
    "start": "815639",
    "end": "817629"
  },
  {
    "text": "mind when we were building this",
    "start": "817629",
    "end": "818529"
  },
  {
    "text": "infrastructure were around scalability",
    "start": "818529",
    "end": "820720"
  },
  {
    "text": "because as being mentioned early in a",
    "start": "820720",
    "end": "822459"
  },
  {
    "text": "presentation we process massive amounts",
    "start": "822459",
    "end": "824290"
  },
  {
    "text": "of data on our end and having the",
    "start": "824290",
    "end": "826689"
  },
  {
    "text": "ability to scale up and down is a really",
    "start": "826689",
    "end": "830379"
  },
  {
    "text": "big thing for us and it does help us",
    "start": "830379",
    "end": "832299"
  },
  {
    "text": "with the cost savings the second thing",
    "start": "832299",
    "end": "834220"
  },
  {
    "text": "is because we're storing vast amounts of",
    "start": "834220",
    "end": "837189"
  },
  {
    "text": "data we want to make sure that on top of",
    "start": "837189",
    "end": "840160"
  },
  {
    "text": "the scalability the costs are also",
    "start": "840160",
    "end": "841779"
  },
  {
    "text": "manageable you know there are already",
    "start": "841779",
    "end": "843149"
  },
  {
    "text": "multiple solutions out there in the",
    "start": "843149",
    "end": "845350"
  },
  {
    "text": "industry that allows you to store",
    "start": "845350",
    "end": "847360"
  },
  {
    "text": "massive amounts of data but it's very",
    "start": "847360",
    "end": "848679"
  },
  {
    "text": "expensive in order to process that so",
    "start": "848679",
    "end": "850329"
  },
  {
    "text": "that was one of the other kind of goals",
    "start": "850329",
    "end": "852639"
  },
  {
    "text": "that we wanted to keep in mind when we",
    "start": "852639",
    "end": "854439"
  },
  {
    "text": "are building this the third thing is",
    "start": "854439",
    "end": "857230"
  },
  {
    "text": "reasonable query times I know it's with",
    "start": "857230",
    "end": "860439"
  },
  {
    "text": "the amount of data that you store as the",
    "start": "860439",
    "end": "862629"
  },
  {
    "text": "data goes up the query time itself",
    "start": "862629",
    "end": "864600"
  },
  {
    "text": "increases along with it so we wanted to",
    "start": "864600",
    "end": "867999"
  },
  {
    "text": "keep it we wanted to design schema",
    "start": "867999",
    "end": "870009"
  },
  {
    "text": "infrastructure around the way do we run",
    "start": "870009",
    "end": "873160"
  },
  {
    "text": "the queries such that the query",
    "start": "873160",
    "end": "874360"
  },
  {
    "text": "themselves finish in reasonably our time",
    "start": "874360",
    "end": "876459"
  },
  {
    "text": "like the the goal that we're aiming for",
    "start": "876459",
    "end": "878470"
  },
  {
    "text": "was about 60 seconds or lower and then",
    "start": "878470",
    "end": "882100"
  },
  {
    "text": "other stuff was around flexible queries",
    "start": "882100",
    "end": "883839"
  },
  {
    "text": "consistencies and easy schema changes",
    "start": "883839",
    "end": "886649"
  },
  {
    "text": "okay so this is basically what we had",
    "start": "886649",
    "end": "889059"
  },
  {
    "text": "before we jumped into a redshift lambda",
    "start": "889059",
    "end": "893319"
  },
  {
    "text": "and Kinesis so this is what we had for",
    "start": "893319",
    "end": "896649"
  },
  {
    "text": "the past two years this was basically",
    "start": "896649",
    "end": "898299"
  },
  {
    "text": "our Navy implementation of building a",
    "start": "898299",
    "end": "901509"
  },
  {
    "text": "system which is able to cache and",
    "start": "901509",
    "end": "904449"
  },
  {
    "text": "process a lot of data so we have",
    "start": "904449",
    "end": "907209"
  },
  {
    "text": "something called the event generators",
    "start": "907209",
    "end": "908619"
  },
  {
    "text": "these are basically the servers that get",
    "start": "908619",
    "end": "911499"
  },
  {
    "text": "called whenever an ad is served",
    "start": "911499",
    "end": "913829"
  },
  {
    "text": "externally and an impression is",
    "start": "913829",
    "end": "915819"
  },
  {
    "text": "delivered when somebody clicks on it",
    "start": "915819",
    "end": "917139"
  },
  {
    "text": "when somebody performs any kind of",
    "start": "917139",
    "end": "918939"
  },
  {
    "text": "action with the ad that was served so",
    "start": "918939",
    "end": "921249"
  },
  {
    "text": "this event generators will collect the",
    "start": "921249",
    "end": "923290"
  },
  {
    "text": "data and they will pass it on to",
    "start": "923290",
    "end": "924519"
  },
  {
    "text": "something known as they rent aggregator",
    "start": "924519",
    "end": "925839"
  },
  {
    "text": "which will be responsible for",
    "start": "925839",
    "end": "928140"
  },
  {
    "text": "please keep mashing together data and",
    "start": "928140",
    "end": "930270"
  },
  {
    "text": "then putting that in an elastic search",
    "start": "930270",
    "end": "931740"
  },
  {
    "text": "so this served its purpose relatively",
    "start": "931740",
    "end": "934140"
  },
  {
    "text": "well we use this for about two years and",
    "start": "934140",
    "end": "936110"
  },
  {
    "text": "recently earlier this year we started",
    "start": "936110",
    "end": "938820"
  },
  {
    "text": "noticing some problems with it mainly in",
    "start": "938820",
    "end": "941100"
  },
  {
    "text": "terms of scalability and cost so we",
    "start": "941100",
    "end": "943260"
  },
  {
    "text": "wanted to move away from this and design",
    "start": "943260",
    "end": "944970"
  },
  {
    "text": "something that was completely new that",
    "start": "944970",
    "end": "946440"
  },
  {
    "text": "would serve us for the next few years so",
    "start": "946440",
    "end": "949980"
  },
  {
    "text": "we decided to go with redshift so",
    "start": "949980",
    "end": "953420"
  },
  {
    "text": "basically the event generated part",
    "start": "953420",
    "end": "956490"
  },
  {
    "text": "remained the same but we decide to",
    "start": "956490",
    "end": "957960"
  },
  {
    "text": "employ Amazon Canisius firehose in order",
    "start": "957960",
    "end": "960930"
  },
  {
    "text": "to feed the data into a variety of",
    "start": "960930",
    "end": "963030"
  },
  {
    "text": "classes but basically the way this works",
    "start": "963030",
    "end": "964830"
  },
  {
    "text": "is each of the event event generator",
    "start": "964830",
    "end": "968150"
  },
  {
    "text": "will pass the data along to Kinesis",
    "start": "968150",
    "end": "970650"
  },
  {
    "text": "which in turn will buffer the data into",
    "start": "970650",
    "end": "972930"
  },
  {
    "text": "Amazon s3 temporarily and then issue",
    "start": "972930",
    "end": "975030"
  },
  {
    "text": "command to rest you have to copy the",
    "start": "975030",
    "end": "976710"
  },
  {
    "text": "data leveraging redshifts parallel",
    "start": "976710",
    "end": "979860"
  },
  {
    "text": "processing and parallel data loading",
    "start": "979860",
    "end": "982020"
  },
  {
    "text": "capabilities to basically load millions",
    "start": "982020",
    "end": "984840"
  },
  {
    "text": "of data points in eight to ten seconds",
    "start": "984840",
    "end": "987180"
  },
  {
    "text": "is that's basically what we found to be",
    "start": "987180",
    "end": "988920"
  },
  {
    "text": "the case so in redshift basically we",
    "start": "988920",
    "end": "992070"
  },
  {
    "text": "store the data in something known as a",
    "start": "992070",
    "end": "993510"
  },
  {
    "text": "staging table which is basically a",
    "start": "993510",
    "end": "994890"
  },
  {
    "text": "temporary table where we want to do",
    "start": "994890",
    "end": "996270"
  },
  {
    "text": "further processing on that data before",
    "start": "996270",
    "end": "998610"
  },
  {
    "text": "we put it to the final table that they",
    "start": "998610",
    "end": "1000620"
  },
  {
    "text": "belong to you",
    "start": "1000620",
    "end": "1001610"
  },
  {
    "text": "in order to run the necessary jobs in",
    "start": "1001610",
    "end": "1004970"
  },
  {
    "text": "dude in order to do the processing we",
    "start": "1004970",
    "end": "1006890"
  },
  {
    "text": "leverage Amazon CloudWatch",
    "start": "1006890",
    "end": "1008360"
  },
  {
    "text": "to basically run events or business",
    "start": "1008360",
    "end": "1013280"
  },
  {
    "text": "scheduled events that hit AWS lambda and",
    "start": "1013280",
    "end": "1016340"
  },
  {
    "text": "AWS lambda would be the one that's",
    "start": "1016340",
    "end": "1018170"
  },
  {
    "text": "responsible for running the necessary",
    "start": "1018170",
    "end": "1019820"
  },
  {
    "text": "queries in order to merge the data and",
    "start": "1019820",
    "end": "1021740"
  },
  {
    "text": "in order to visualize the data we had",
    "start": "1021740",
    "end": "1024020"
  },
  {
    "text": "Amazon quick sites as well as our own",
    "start": "1024020",
    "end": "1026180"
  },
  {
    "text": "services that sit on top of red share so",
    "start": "1026180",
    "end": "1030290"
  },
  {
    "start": "1029000",
    "end": "1072000"
  },
  {
    "text": "let's talk about the first part as to",
    "start": "1030290",
    "end": "1031850"
  },
  {
    "text": "how the Kinesis and how we feed the data",
    "start": "1031850",
    "end": "1033410"
  },
  {
    "text": "in there so our event generators would",
    "start": "1033410",
    "end": "1036800"
  },
  {
    "text": "basically pass the data to any one of",
    "start": "1036800",
    "end": "1039949"
  },
  {
    "text": "the Amazon Kinesis firehose streams in a",
    "start": "1039949",
    "end": "1043760"
  },
  {
    "text": "round robin fashion in order to manage",
    "start": "1043760",
    "end": "1045530"
  },
  {
    "text": "the load because I peak times the load",
    "start": "1045530",
    "end": "1047060"
  },
  {
    "text": "is extremely high so we have to leverage",
    "start": "1047060",
    "end": "1049430"
  },
  {
    "text": "multiple streams in order for us to",
    "start": "1049430",
    "end": "1050660"
  },
  {
    "text": "effectively process the data the data",
    "start": "1050660",
    "end": "1053300"
  },
  {
    "text": "would as I mentioned before will be",
    "start": "1053300",
    "end": "1055280"
  },
  {
    "text": "buffered into the s3 buckets",
    "start": "1055280",
    "end": "1058650"
  },
  {
    "text": "temporarily until the data size reaches",
    "start": "1058650",
    "end": "1061140"
  },
  {
    "text": "certain size and then Kinesis will issue",
    "start": "1061140",
    "end": "1064050"
  },
  {
    "text": "a command to recive cluster in order to",
    "start": "1064050",
    "end": "1068430"
  },
  {
    "text": "copy the data into the staging table so",
    "start": "1068430",
    "end": "1072630"
  },
  {
    "start": "1072000",
    "end": "1162000"
  },
  {
    "text": "let's talk a little bit more about",
    "start": "1072630",
    "end": "1073710"
  },
  {
    "text": "redshift so we have two clusters for",
    "start": "1073710",
    "end": "1077040"
  },
  {
    "text": "ratio they serve two different purposes",
    "start": "1077040",
    "end": "1078540"
  },
  {
    "text": "but they need to work together in order",
    "start": "1078540",
    "end": "1080910"
  },
  {
    "text": "for us to store this data so we have",
    "start": "1080910",
    "end": "1083040"
  },
  {
    "text": "something called a primary cluster which",
    "start": "1083040",
    "end": "1084750"
  },
  {
    "text": "is basically a collection of dc2 nodes",
    "start": "1084750",
    "end": "1087140"
  },
  {
    "text": "this akyuu nodes themselves are best buy",
    "start": "1087140",
    "end": "1089820"
  },
  {
    "text": "as back by SSD and the second cluster we",
    "start": "1089820",
    "end": "1093600"
  },
  {
    "text": "have is the archival cluster which is",
    "start": "1093600",
    "end": "1095190"
  },
  {
    "text": "running on ds2 nodes which are primarily",
    "start": "1095190",
    "end": "1097950"
  },
  {
    "text": "which are hard drive based so the",
    "start": "1097950",
    "end": "1100560"
  },
  {
    "text": "difference between the two cluster is",
    "start": "1100560",
    "end": "1102480"
  },
  {
    "text": "the recent data that's there would be",
    "start": "1102480",
    "end": "1104310"
  },
  {
    "text": "always put to the primary cluster so the",
    "start": "1104310",
    "end": "1106470"
  },
  {
    "text": "primary cluster in itself is read and",
    "start": "1106470",
    "end": "1108450"
  },
  {
    "text": "write heavy on the other hand the",
    "start": "1108450",
    "end": "1110220"
  },
  {
    "text": "archival cluster has the data there is",
    "start": "1110220",
    "end": "1112650"
  },
  {
    "text": "historical it's very read heavy but the",
    "start": "1112650",
    "end": "1115200"
  },
  {
    "text": "right happens once a day so that's why",
    "start": "1115200",
    "end": "1117120"
  },
  {
    "text": "we kind of picked the appropriate node",
    "start": "1117120",
    "end": "1120150"
  },
  {
    "text": "types for each of the different cluster",
    "start": "1120150",
    "end": "1123060"
  },
  {
    "text": "so talking about a primary cluster there",
    "start": "1123060",
    "end": "1126450"
  },
  {
    "text": "are two kinds of tables there there's a",
    "start": "1126450",
    "end": "1127770"
  },
  {
    "text": "staging table which is responsible for",
    "start": "1127770",
    "end": "1129300"
  },
  {
    "text": "holding the data there temporarily and",
    "start": "1129300",
    "end": "1131400"
  },
  {
    "text": "then we create something called a time",
    "start": "1131400",
    "end": "1133110"
  },
  {
    "text": "series table so basically what that is",
    "start": "1133110",
    "end": "1134910"
  },
  {
    "text": "is one table created per day which will",
    "start": "1134910",
    "end": "1137190"
  },
  {
    "text": "hold that day's worth of data yeah and",
    "start": "1137190",
    "end": "1141720"
  },
  {
    "text": "we can talk about n sorry and the data",
    "start": "1141720",
    "end": "1143430"
  },
  {
    "text": "gets moved into the archive cluster once",
    "start": "1143430",
    "end": "1145410"
  },
  {
    "text": "ninety days are up so we chose 90 days",
    "start": "1145410",
    "end": "1147270"
  },
  {
    "text": "based on the kind of the type of queries",
    "start": "1147270",
    "end": "1149370"
  },
  {
    "text": "that we run on a platform and we",
    "start": "1149370",
    "end": "1151800"
  },
  {
    "text": "basically pick the optimal point to know",
    "start": "1151800",
    "end": "1153780"
  },
  {
    "text": "that okay after this point it doesn't",
    "start": "1153780",
    "end": "1156660"
  },
  {
    "text": "make sense for the data to rely on SSD",
    "start": "1156660",
    "end": "1158930"
  },
  {
    "text": "back knows based on a cause as well as a",
    "start": "1158930",
    "end": "1161550"
  },
  {
    "text": "processing time so here's our primary",
    "start": "1161550",
    "end": "1164910"
  },
  {
    "start": "1162000",
    "end": "1222000"
  },
  {
    "text": "cluster so primary cluster consists of",
    "start": "1164910",
    "end": "1167070"
  },
  {
    "text": "the staging table and a list of times",
    "start": "1167070",
    "end": "1169440"
  },
  {
    "text": "table there's gonna be about 90 times so",
    "start": "1169440",
    "end": "1171390"
  },
  {
    "text": "this table based on at what point you're",
    "start": "1171390",
    "end": "1174600"
  },
  {
    "text": "looking at so basically what happens is",
    "start": "1174600",
    "end": "1176790"
  },
  {
    "text": "the data that's coming in from our",
    "start": "1176790",
    "end": "1178230"
  },
  {
    "text": "services which goes through Kinesis and",
    "start": "1178230",
    "end": "1180750"
  },
  {
    "text": "gets dumped into the staging table so in",
    "start": "1180750",
    "end": "1182910"
  },
  {
    "text": "the staging table what happens is",
    "start": "1182910",
    "end": "1184710"
  },
  {
    "text": "periodically Cloud Lodge will issue",
    "start": "1184710",
    "end": "1188400"
  },
  {
    "text": "an event to lambda which in turn will",
    "start": "1188400",
    "end": "1191520"
  },
  {
    "text": "take the data that's in the staging",
    "start": "1191520",
    "end": "1192990"
  },
  {
    "text": "table and it will basically read the",
    "start": "1192990",
    "end": "1195360"
  },
  {
    "text": "data merge the events and I will talk",
    "start": "1195360",
    "end": "1197760"
  },
  {
    "text": "about how the event merging happens in",
    "start": "1197760",
    "end": "1199440"
  },
  {
    "text": "the next slide but it will basically",
    "start": "1199440",
    "end": "1200490"
  },
  {
    "text": "merge the events and then push that data",
    "start": "1200490",
    "end": "1203130"
  },
  {
    "text": "into the day that the data needs to go",
    "start": "1203130",
    "end": "1205920"
  },
  {
    "text": "into so for example if we had a bunch of",
    "start": "1205920",
    "end": "1209610"
  },
  {
    "text": "events that were generated on August 1st",
    "start": "1209610",
    "end": "1211530"
  },
  {
    "text": "2018 staging table what the data would",
    "start": "1211530",
    "end": "1213690"
  },
  {
    "text": "basically get merged with in staging",
    "start": "1213690",
    "end": "1215640"
  },
  {
    "text": "table and there'll be one record per",
    "start": "1215640",
    "end": "1217920"
  },
  {
    "text": "event ID put into the August first table",
    "start": "1217920",
    "end": "1222800"
  },
  {
    "start": "1222000",
    "end": "1294000"
  },
  {
    "text": "so what is event merging so for each",
    "start": "1222800",
    "end": "1226250"
  },
  {
    "text": "auction that we run for example for each",
    "start": "1226250",
    "end": "1228950"
  },
  {
    "text": "impact for each ad that we serve out we",
    "start": "1228950",
    "end": "1232230"
  },
  {
    "text": "have a unique ID for it for each of",
    "start": "1232230",
    "end": "1234570"
  },
  {
    "text": "those unique IDs in this case ID is 1 2",
    "start": "1234570",
    "end": "1237090"
  },
  {
    "text": "3 4 5 6 7 there could be multiple events",
    "start": "1237090",
    "end": "1240630"
  },
  {
    "text": "that are generated so it doesn't make",
    "start": "1240630",
    "end": "1242430"
  },
  {
    "text": "sense for us to store each record",
    "start": "1242430",
    "end": "1244680"
  },
  {
    "text": "individually for each event that happens",
    "start": "1244680",
    "end": "1247230"
  },
  {
    "text": "what we can do is in order to save space",
    "start": "1247230",
    "end": "1249870"
  },
  {
    "text": "as well as make the read queries more",
    "start": "1249870",
    "end": "1253590"
  },
  {
    "text": "efficient we can do the merging",
    "start": "1253590",
    "end": "1255240"
  },
  {
    "text": "operation where you basically take the",
    "start": "1255240",
    "end": "1257250"
  },
  {
    "text": "two records and combine the two records",
    "start": "1257250",
    "end": "1259260"
  },
  {
    "text": "because majority of the information in",
    "start": "1259260",
    "end": "1261420"
  },
  {
    "text": "the first and a second record is going",
    "start": "1261420",
    "end": "1262920"
  },
  {
    "text": "to be exactly the same because the it's",
    "start": "1262920",
    "end": "1265500"
  },
  {
    "text": "based on the same auction ID that",
    "start": "1265500",
    "end": "1267300"
  },
  {
    "text": "happened the only difference is the",
    "start": "1267300",
    "end": "1269100"
  },
  {
    "text": "operation that was performed on it so",
    "start": "1269100",
    "end": "1271320"
  },
  {
    "text": "for example in this case 1 2 3 4 5 6 7",
    "start": "1271320",
    "end": "1273300"
  },
  {
    "text": "the first event that happened was",
    "start": "1273300",
    "end": "1276330"
  },
  {
    "text": "impression and the second event that",
    "start": "1276330",
    "end": "1278310"
  },
  {
    "text": "happened was was clicked so what we do",
    "start": "1278310",
    "end": "1281070"
  },
  {
    "text": "is we just merge the two events and say",
    "start": "1281070",
    "end": "1282630"
  },
  {
    "text": "that event ID 1 2 3 4 5 6 7 had both",
    "start": "1282630",
    "end": "1285600"
  },
  {
    "text": "impression and click that happened and",
    "start": "1285600",
    "end": "1289410"
  },
  {
    "text": "then we just store that finalized record",
    "start": "1289410",
    "end": "1291210"
  },
  {
    "text": "into the appropriate daily table so once",
    "start": "1291210",
    "end": "1296640"
  },
  {
    "text": "the data is in daily table it sits there",
    "start": "1296640",
    "end": "1298200"
  },
  {
    "text": "for 90 days so each day has its own",
    "start": "1298200",
    "end": "1300180"
  },
  {
    "text": "table and after 90 days are done we",
    "start": "1300180",
    "end": "1302610"
  },
  {
    "text": "basically take the data from the time",
    "start": "1302610",
    "end": "1306090"
  },
  {
    "text": "series table we dump it into s3 and then",
    "start": "1306090",
    "end": "1309090"
  },
  {
    "text": "we basically put that data back into the",
    "start": "1309090",
    "end": "1311610"
  },
  {
    "text": "archive cluster now the way the archive",
    "start": "1311610",
    "end": "1313470"
  },
  {
    "text": "cluster works it's a little bit",
    "start": "1313470",
    "end": "1315300"
  },
  {
    "text": "different to how the primary cluster",
    "start": "1315300",
    "end": "1317280"
  },
  {
    "text": "works because for primary cluster the",
    "start": "1317280",
    "end": "1319110"
  },
  {
    "text": "data that we want to extract is",
    "start": "1319110",
    "end": "1320370"
  },
  {
    "text": "generally based on the number of days",
    "start": "1320370",
    "end": "1322380"
  },
  {
    "text": "we're looking back we may be looking",
    "start": "1322380",
    "end": "1324270"
  },
  {
    "text": "back three days seven days you know one",
    "start": "1324270",
    "end": "1326280"
  },
  {
    "text": "month and things like that whereas the",
    "start": "1326280",
    "end": "1328110"
  },
  {
    "text": "archive cluster the data is actually",
    "start": "1328110",
    "end": "1329490"
  },
  {
    "text": "stored on a customer ID basis because we",
    "start": "1329490",
    "end": "1332340"
  },
  {
    "text": "want to because the the common queries",
    "start": "1332340",
    "end": "1334470"
  },
  {
    "text": "that run against the archive cluster I",
    "start": "1334470",
    "end": "1336060"
  },
  {
    "text": "based on aggregated data across the",
    "start": "1336060",
    "end": "1339450"
  },
  {
    "text": "customer as opposed to when it actually",
    "start": "1339450",
    "end": "1341310"
  },
  {
    "text": "happened so that's why we adapted the",
    "start": "1341310",
    "end": "1343050"
  },
  {
    "text": "schema to be a little bit different in",
    "start": "1343050",
    "end": "1344460"
  },
  {
    "text": "two of the both of the different we",
    "start": "1344460",
    "end": "1347880"
  },
  {
    "text": "basically had different schema for two",
    "start": "1347880",
    "end": "1349590"
  },
  {
    "text": "different cluster primarily because the",
    "start": "1349590",
    "end": "1351330"
  },
  {
    "text": "type of queries that are running on",
    "start": "1351330",
    "end": "1352800"
  },
  {
    "text": "there are different so I just wanna kind",
    "start": "1352800",
    "end": "1356850"
  },
  {
    "text": "of highlight what has happened since we",
    "start": "1356850",
    "end": "1359670"
  },
  {
    "text": "put this into production so we put this",
    "start": "1359670",
    "end": "1361170"
  },
  {
    "text": "into production in March and the orange",
    "start": "1361170",
    "end": "1363840"
  },
  {
    "text": "line that you see here basically",
    "start": "1363840",
    "end": "1366090"
  },
  {
    "text": "represents from a baseline the number of",
    "start": "1366090",
    "end": "1368640"
  },
  {
    "text": "new events that are supposed to be added",
    "start": "1368640",
    "end": "1370350"
  },
  {
    "text": "so month over month we were expecting",
    "start": "1370350",
    "end": "1372750"
  },
  {
    "text": "about a 10% growth but what we found out",
    "start": "1372750",
    "end": "1375900"
  },
  {
    "text": "once we released this is we actually had",
    "start": "1375900",
    "end": "1377850"
  },
  {
    "text": "a month over month growth of almost 30%",
    "start": "1377850",
    "end": "1379560"
  },
  {
    "text": "so we're adding 30% new data every month",
    "start": "1379560",
    "end": "1382800"
  },
  {
    "text": "compared to the previous month before so",
    "start": "1382800",
    "end": "1385680"
  },
  {
    "text": "I mean for startup that's an awesome",
    "start": "1385680",
    "end": "1387180"
  },
  {
    "text": "problem to have because you know it",
    "start": "1387180",
    "end": "1388440"
  },
  {
    "text": "means we're doing really really great",
    "start": "1388440",
    "end": "1389550"
  },
  {
    "text": "but in terms of infrastructure planning",
    "start": "1389550",
    "end": "1392070"
  },
  {
    "text": "and capacity planning it does make",
    "start": "1392070",
    "end": "1394200"
  },
  {
    "text": "things a lot more difficult however with",
    "start": "1394200",
    "end": "1396240"
  },
  {
    "text": "the redshift it makes it really easy for",
    "start": "1396240",
    "end": "1397890"
  },
  {
    "text": "you to resize your cluster so you'll be",
    "start": "1397890",
    "end": "1399990"
  },
  {
    "text": "able to take we were able to take that",
    "start": "1399990",
    "end": "1401670"
  },
  {
    "text": "advantage of that multiple times in",
    "start": "1401670",
    "end": "1404250"
  },
  {
    "text": "order to make sure that we were able to",
    "start": "1404250",
    "end": "1405870"
  },
  {
    "text": "keep up with the number of new events",
    "start": "1405870",
    "end": "1408480"
  },
  {
    "text": "that got added and the thing on the",
    "start": "1408480",
    "end": "1409680"
  },
  {
    "text": "right here is the total number of events",
    "start": "1409680",
    "end": "1412110"
  },
  {
    "text": "that we stored so because this is",
    "start": "1412110",
    "end": "1414000"
  },
  {
    "text": "basically the net new events added this",
    "start": "1414000",
    "end": "1416280"
  },
  {
    "text": "on the other hand represents the total",
    "start": "1416280",
    "end": "1418140"
  },
  {
    "text": "number of events that are stored in the",
    "start": "1418140",
    "end": "1420270"
  },
  {
    "text": "cluster and as you can see if you easily",
    "start": "1420270",
    "end": "1422550"
  },
  {
    "text": "outpace the what we were actually",
    "start": "1422550",
    "end": "1425100"
  },
  {
    "text": "initially expecting to do compared to",
    "start": "1425100",
    "end": "1428430"
  },
  {
    "text": "what we actually done right and the",
    "start": "1428430",
    "end": "1430710"
  },
  {
    "text": "difference is significant and the",
    "start": "1430710",
    "end": "1432210"
  },
  {
    "text": "difference is actually is pulling apart",
    "start": "1432210",
    "end": "1433970"
  },
  {
    "text": "but we're still able to keep up with",
    "start": "1433970",
    "end": "1436230"
  },
  {
    "text": "this because the infrastructure is set",
    "start": "1436230",
    "end": "1438780"
  },
  {
    "text": "up in such a way and the technologies",
    "start": "1438780",
    "end": "1440580"
  },
  {
    "text": "are there and",
    "start": "1440580",
    "end": "1441539"
  },
  {
    "text": "by the functionality such that they can",
    "start": "1441539",
    "end": "1442979"
  },
  {
    "text": "be skilled very easily and yeah I mean",
    "start": "1442979",
    "end": "1446759"
  },
  {
    "text": "and the query times which is something",
    "start": "1446759",
    "end": "1448590"
  },
  {
    "text": "we were really concerned about initially",
    "start": "1448590",
    "end": "1450059"
  },
  {
    "text": "we're soon been able to keep it under 60",
    "start": "1450059",
    "end": "1451950"
  },
  {
    "text": "seconds for Mature of the queries sure",
    "start": "1451950",
    "end": "1455309"
  },
  {
    "text": "that's it from us if you guys any",
    "start": "1455309",
    "end": "1457379"
  },
  {
    "text": "question we'll be happy to answer them",
    "start": "1457379",
    "end": "1458909"
  },
  {
    "text": "okay thank you very much guys really",
    "start": "1458909",
    "end": "1461190"
  },
  {
    "text": "appreciate it great talk we have time",
    "start": "1461190",
    "end": "1463080"
  },
  {
    "text": "for maybe two questions quickly so if",
    "start": "1463080",
    "end": "1465479"
  },
  {
    "text": "you have a question for these guys just",
    "start": "1465479",
    "end": "1466619"
  },
  {
    "text": "raise your hand and I'll bring the mic",
    "start": "1466619",
    "end": "1467729"
  },
  {
    "text": "to you suzay so clearly explained no",
    "start": "1467729",
    "end": "1473129"
  },
  {
    "text": "questions in terms of training your",
    "start": "1473129",
    "end": "1477210"
  },
  {
    "text": "machine learning models on these",
    "start": "1477210",
    "end": "1478529"
  },
  {
    "text": "billions of data points like how do you",
    "start": "1478529",
    "end": "1482669"
  },
  {
    "text": "do that and how do you do that in a",
    "start": "1482669",
    "end": "1484109"
  },
  {
    "text": "distributed way and how do you train",
    "start": "1484109",
    "end": "1485729"
  },
  {
    "text": "them every day so we do that with the",
    "start": "1485729",
    "end": "1491909"
  },
  {
    "text": "EMR spark software combination so spark",
    "start": "1491909",
    "end": "1495809"
  },
  {
    "text": "in particular has a lot of machine",
    "start": "1495809",
    "end": "1497759"
  },
  {
    "text": "learning algorithms built into it that",
    "start": "1497759",
    "end": "1499440"
  },
  {
    "text": "are written in a distributed format so",
    "start": "1499440",
    "end": "1501989"
  },
  {
    "text": "training is gonna happen across a big",
    "start": "1501989",
    "end": "1504119"
  },
  {
    "text": "cluster where your actual training",
    "start": "1504119",
    "end": "1507239"
  },
  {
    "text": "examples get split up across the cluster",
    "start": "1507239",
    "end": "1509129"
  },
  {
    "text": "as well and that's really the only way",
    "start": "1509129",
    "end": "1511559"
  },
  {
    "text": "to do it",
    "start": "1511559",
    "end": "1512700"
  },
  {
    "text": "in a scalable way for us all right",
    "start": "1512700",
    "end": "1518999"
  },
  {
    "text": "follow-up question",
    "start": "1518999",
    "end": "1521620"
  },
  {
    "text": "um so if it's distributed does that mean",
    "start": "1521620",
    "end": "1524740"
  },
  {
    "text": "that it's a regression model which it",
    "start": "1524740",
    "end": "1527320"
  },
  {
    "text": "sounds like it is and then sorry so so",
    "start": "1527320",
    "end": "1531160"
  },
  {
    "text": "is this a regression model that you're",
    "start": "1531160",
    "end": "1533260"
  },
  {
    "text": "training and then you split up the data",
    "start": "1533260",
    "end": "1535000"
  },
  {
    "text": "into multiple buckets you kind of crunch",
    "start": "1535000",
    "end": "1537550"
  },
  {
    "text": "all those numbers then you average the",
    "start": "1537550",
    "end": "1539170"
  },
  {
    "text": "results or kind of what does that",
    "start": "1539170",
    "end": "1541210"
  },
  {
    "text": "process look like so this this Punk",
    "start": "1541210",
    "end": "1546040"
  },
  {
    "text": "internals are quite sophisticated",
    "start": "1546040",
    "end": "1547540"
  },
  {
    "text": "actually so for example when doing",
    "start": "1547540",
    "end": "1549990"
  },
  {
    "text": "suggested gradient descent to do the",
    "start": "1549990",
    "end": "1552160"
  },
  {
    "text": "optimization it does that in a",
    "start": "1552160",
    "end": "1554200"
  },
  {
    "text": "distributed way where it computes the",
    "start": "1554200",
    "end": "1555910"
  },
  {
    "text": "gradients they're in a distributed way",
    "start": "1555910",
    "end": "1557380"
  },
  {
    "text": "so it's not some sort of like simple",
    "start": "1557380",
    "end": "1560200"
  },
  {
    "text": "averaging where we're our selves",
    "start": "1560200",
    "end": "1562480"
  },
  {
    "text": "implementing the distribution across the",
    "start": "1562480",
    "end": "1565210"
  },
  {
    "text": "different servers but sparks Apache",
    "start": "1565210",
    "end": "1569350"
  },
  {
    "text": "project so quite heavily invested from",
    "start": "1569350",
    "end": "1572110"
  },
  {
    "text": "the community at large",
    "start": "1572110",
    "end": "1573720"
  },
  {
    "text": "into developing those machine learning",
    "start": "1573720",
    "end": "1576160"
  },
  {
    "text": "algorithms all right thanks very much",
    "start": "1576160",
    "end": "1580090"
  },
  {
    "text": "guys really appreciate it",
    "start": "1580090",
    "end": "1583169"
  }
]
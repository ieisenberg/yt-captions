[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "so uh good afternoon folks uh thank you for coming to uh looks like the first breakout session after lunch",
    "start": "1280",
    "end": "7200"
  },
  {
    "text": "for all of you my name is dougal ballentine i'm a solutions architect with amazon web services",
    "start": "7200",
    "end": "12400"
  },
  {
    "text": "i focus on high performance computing which is uh kind of my passion as well one of the",
    "start": "12400",
    "end": "17520"
  },
  {
    "text": "fun things about high performance computing is it places a lot of requirements on the aws platform and so i spend a lot of my time",
    "start": "17520",
    "end": "23519"
  },
  {
    "text": "working with customers trying to get the most performance out of ec2 and ebs and so today i'm going to try and take",
    "start": "23519",
    "end": "29439"
  },
  {
    "text": "some time to walk our way through the ebs service elastic block store and also talk about some of the characteristics and component choices",
    "start": "29439",
    "end": "36800"
  },
  {
    "text": "you need to make to optimize your platform for performance so what we're going to cover today we're",
    "start": "36800",
    "end": "43280"
  },
  {
    "start": "41000",
    "end": "41000"
  },
  {
    "text": "going to do an overview of ebs now ebs is kind of a constantly changing thing it's a service",
    "start": "43280",
    "end": "49680"
  },
  {
    "text": "and so therefore every time we do this presentation i have to update it and add some more content so we we announce larger and faster volumes at",
    "start": "49680",
    "end": "57360"
  },
  {
    "text": "re invent and larger and faster volumes are now part of the service so for folks who haven't caught up with all the changes we'll talk through that as",
    "start": "57360",
    "end": "63760"
  },
  {
    "text": "well we've spent quite a long time talking about performance and the different aspects of ebs",
    "start": "63760",
    "end": "68799"
  },
  {
    "text": "and ec2 that impact performance so you can actually understand what choices you need to make when you're designing for performance or you",
    "start": "68799",
    "end": "75200"
  },
  {
    "text": "have a performance goal you want to achieve we're talking about encryption encryption and ebs has become easier and",
    "start": "75200",
    "end": "81520"
  },
  {
    "text": "easier as we go we have third-party solutions that you're able to put on top of ebs volumes but today we have the service",
    "start": "81520",
    "end": "87759"
  },
  {
    "text": "kms where you can easily just say i want an encrypted volume and it's a checkbox or i want an encrypted volume",
    "start": "87759",
    "end": "93680"
  },
  {
    "text": "and i want to use a master key i've created with auditing and cloudtrail and then we're actually going to leave",
    "start": "93680",
    "end": "98799"
  },
  {
    "text": "some time for q a today i'll do my best see if we can leave time for about 10 minutes of q a at the end",
    "start": "98799",
    "end": "104640"
  },
  {
    "text": "so let's start with an overview of ebs so for most builders for most people",
    "start": "104880",
    "end": "110799"
  },
  {
    "text": "getting started on aws it's get in and go you create an ec2 instance",
    "start": "110799",
    "end": "116640"
  },
  {
    "text": "you attach a volume you mount the volume when you launch your instance you put some data on it",
    "start": "116640",
    "end": "121920"
  },
  {
    "text": "that's about as far as you need to go in your understanding of ebs and for a lot of customers a lot of",
    "start": "121920",
    "end": "127680"
  },
  {
    "text": "people building solutions on aws today that works great but what i want to take",
    "start": "127680",
    "end": "133040"
  },
  {
    "text": "time today is explain exactly how ebs capabilities function what they're doing so when you're",
    "start": "133040",
    "end": "139680"
  },
  {
    "text": "designing an application that has performance goals maybe you're designing a database that needs to deliver a certain amount of steady state iops",
    "start": "139680",
    "end": "146319"
  },
  {
    "text": "or you have an application maybe doing a file share and you need to have a certain amount of throughput from that you know how to get",
    "start": "146319",
    "end": "152879"
  },
  {
    "text": "that throughput consistently and the right way on top of ec2 and ebs",
    "start": "152879",
    "end": "159120"
  },
  {
    "text": "so um a normal hard drive so i've been working in storage for about 15 years now i've committed to",
    "start": "159920",
    "end": "166640"
  },
  {
    "text": "memory the rotational speed of most sata and sas drives i've worked on 7 200 rpm 10k 15k",
    "start": "166640",
    "end": "173120"
  },
  {
    "text": "uh the average read and write latencies these drives deliver and then you use that data to work out",
    "start": "173120",
    "end": "178640"
  },
  {
    "text": "the right rate array to build underneath your database you know that when you put a raid 5 together you're going to give",
    "start": "178640",
    "end": "183760"
  },
  {
    "text": "up some of your iops you know that raid 10 is going to give you the most performance but you lose off your storage all of this stuff is committed to memory",
    "start": "183760",
    "end": "190480"
  },
  {
    "text": "to enable me to build a great solution however ebs is not a bunch of hard",
    "start": "190480",
    "end": "196480"
  },
  {
    "text": "drives this is really important to understand that ebs is not just a hard drive that you plug into the back of your ec2",
    "start": "196480",
    "end": "202879"
  },
  {
    "text": "instance and you use ebs is a service and because it's a service it's going to",
    "start": "202879",
    "end": "209920"
  },
  {
    "text": "operate differently than your average hard drive it comes with added benefits there's",
    "start": "209920",
    "end": "215120"
  },
  {
    "text": "extra features things we're going to talk about like burst buckets you just don't get with a standard ssd plugged into your machine",
    "start": "215120",
    "end": "221680"
  },
  {
    "text": "so what is ebs network attached blocks storage so it's not part of your ec2",
    "start": "221680",
    "end": "227840"
  },
  {
    "text": "instance it's separate from the ec2 instance it's a totally separate service that you're actually consuming block storage from",
    "start": "227840",
    "end": "235040"
  },
  {
    "text": "it's designed for five nines of availability five nines of availability is kind of crazy in storage",
    "start": "235040",
    "end": "241840"
  },
  {
    "text": "so it's designed for five nines and if we look at the last 12 months the trailing performance we exceed that",
    "start": "241840",
    "end": "248080"
  },
  {
    "text": "okay so it really delivers on its promise of five nines of availability attaches to ec2 in the same availability",
    "start": "248080",
    "end": "254640"
  },
  {
    "text": "zone this is important to understand ebs is in your availability zone it's a service that's independent to the",
    "start": "254640",
    "end": "260799"
  },
  {
    "text": "availability zone so that's what you get the availability from and that five nines",
    "start": "260799",
    "end": "266400"
  },
  {
    "text": "it also has a capability to do point in time snapshots point in time snapshots are stored in s3",
    "start": "266400",
    "end": "273040"
  },
  {
    "text": "this increases your durability so s3 has 11 nines of durability which is just a",
    "start": "273040",
    "end": "278160"
  },
  {
    "text": "staggering number and so when you save your data to a snapshot is being copied out of the ebs service and stored in s3",
    "start": "278160",
    "end": "287759"
  },
  {
    "text": "so a couple more things about it we have some pretty tough goals which i",
    "start": "289280",
    "end": "294560"
  },
  {
    "text": "just covered already but they're for regional daily availability goals trailing through the year and so it's a pretty",
    "start": "294560",
    "end": "300400"
  },
  {
    "text": "phenomenal number and we managed to get some stats we could share with you now so today when we're looking at it we're creating over",
    "start": "300400",
    "end": "306400"
  },
  {
    "text": "one and a half million volumes per day in ebs and that's a pretty staggering number of volumes that are",
    "start": "306400",
    "end": "312000"
  },
  {
    "text": "being created so before we get too far into understanding the service and what the",
    "start": "312000",
    "end": "318080"
  },
  {
    "start": "315000",
    "end": "315000"
  },
  {
    "text": "service does i want to set some definitions so we're all talking about the same things and they're kind of important because",
    "start": "318080",
    "end": "323759"
  },
  {
    "text": "a lot of these come back as as to how you launch and launch a volume and create a volume",
    "start": "323759",
    "end": "328880"
  },
  {
    "text": "you're going to need to know these things so we start out with iops input outputs per second this is a number typically it's",
    "start": "328880",
    "end": "335360"
  },
  {
    "text": "associated with provisioned iops a specific number you're dialing in i want 2000 iops or it's part of the burst bucket of gp2",
    "start": "335360",
    "end": "343199"
  },
  {
    "text": "throughput the amount of data we're moving backwards and forwards on the volume so read write operations to",
    "start": "343199",
    "end": "348479"
  },
  {
    "text": "storage latency how long does it take for an i o to get from my ec2 instance to ebs and",
    "start": "348479",
    "end": "354720"
  },
  {
    "text": "back again and it's important because we're going to talk about the different performance consistencies and latencies",
    "start": "354720",
    "end": "359840"
  },
  {
    "text": "capacity it's pretty easy how big is the volume can go all the way up to 16 terabytes on ebs today with larger and",
    "start": "359840",
    "end": "365680"
  },
  {
    "text": "faster so you can put a lot of data on one volume and easily manage it so the operational burden of managing large",
    "start": "365680",
    "end": "373039"
  },
  {
    "text": "amounts of data on top of an ec2 instance has significantly come down with the introduction of larger and faster",
    "start": "373039",
    "end": "379280"
  },
  {
    "text": "and then we have the block size or the i o size and this is really important because we measure things in sizes of i",
    "start": "379280",
    "end": "385440"
  },
  {
    "text": "o so your application is going to be working in a certain i o size your file system has a block size",
    "start": "385440",
    "end": "390639"
  },
  {
    "text": "and then ebs is going to be measuring things in block sizes",
    "start": "390639",
    "end": "395840"
  },
  {
    "text": "so there's three volume types in ebs we have ebs magnetic which was the first",
    "start": "396080",
    "end": "401680"
  },
  {
    "text": "one that launched it's been around for a long time we then introduced provisioned iops so",
    "start": "401680",
    "end": "406720"
  },
  {
    "text": "that customers who had very specific performance consistency requirements could choose the amount of iops they",
    "start": "406720",
    "end": "412240"
  },
  {
    "text": "wanted and have that delivered within three nines of performance consistency and then last year we introduced gp2",
    "start": "412240",
    "end": "419520"
  },
  {
    "text": "general purpose ssd and general purpose ssd enables customers to get ssd performance",
    "start": "419520",
    "end": "425599"
  },
  {
    "text": "with a very simple pricing structure and consistent performance to 99 so two",
    "start": "425599",
    "end": "431199"
  },
  {
    "text": "nines and also burst buckets which we'll dive into a little take away something i want you",
    "start": "431199",
    "end": "437039"
  },
  {
    "text": "to to really understand when we're looking at the volume types when performance matters when performance is one of the aspects of your application",
    "start": "437039",
    "end": "443360"
  },
  {
    "text": "that's critical use ssd it doesn't mean there's not good use cases for magnetic and we're going",
    "start": "443360",
    "end": "448479"
  },
  {
    "text": "to talk about that but when performance matters use ssd",
    "start": "448479",
    "end": "453280"
  },
  {
    "start": "453000",
    "end": "453000"
  },
  {
    "text": "so some numbers or some some data that applies to all of our ssd volumes",
    "start": "453840",
    "end": "459440"
  },
  {
    "text": "iops are measured up to 256 kilobytes now it used to be that we measured those",
    "start": "459440",
    "end": "465199"
  },
  {
    "text": "up to 16 and when we launched the gp2 volumes the general purpose we now measure all of our iops for ssd",
    "start": "465199",
    "end": "472080"
  },
  {
    "text": "volumes up to 256k so what that means is if in the past you were sending a 64k i o down to a piops",
    "start": "472080",
    "end": "479360"
  },
  {
    "text": "volume we would actually chop that up into four i os and you would consume four iops from the provisioned iops you",
    "start": "479360",
    "end": "485120"
  },
  {
    "text": "have in your volume that today would equal one another thing that's changed in ebs services we now do pretty aggressive",
    "start": "485120",
    "end": "492000"
  },
  {
    "text": "i o merging on your behalf so even though we measure up to 256k",
    "start": "492000",
    "end": "497520"
  },
  {
    "text": "if you send down two 16k ios and they happen to be sequential because that's how your file system is laid out or your",
    "start": "497520",
    "end": "503520"
  },
  {
    "text": "data is laid out and we see that we'll do our best to put those together and consume one i o of 32k even though",
    "start": "503520",
    "end": "510240"
  },
  {
    "text": "you sent two down meaning you don't use all the i os you've provisioned including the ios or in your burst bucket",
    "start": "510240",
    "end": "516800"
  },
  {
    "text": "designed for single digit millisecond latency it's designed for so that means that you",
    "start": "516800",
    "end": "522719"
  },
  {
    "text": "need to understand how to achieve that and it's not something that will just turn up if you start running on top of",
    "start": "522719",
    "end": "527760"
  },
  {
    "text": "it we're going to talk about exactly how to achieve single digit millisecond latency and again our availability were designed",
    "start": "527760",
    "end": "534160"
  },
  {
    "text": "actually for five nines across all ebs volumes not just on our ssd",
    "start": "534160",
    "end": "539759"
  },
  {
    "start": "538000",
    "end": "538000"
  },
  {
    "text": "so a deeper dive into exactly what gp2 is so it's the new default volume type for ebs",
    "start": "539839",
    "end": "545120"
  },
  {
    "text": "what we mean by default volume type is when you go to the console today and you go and launch in an ec2 instance and the volume is not",
    "start": "545120",
    "end": "551600"
  },
  {
    "text": "gp2 for the boot volume we'll pop up a little warning on the screen and say hey have you thought about using gp2 would you like to make",
    "start": "551600",
    "end": "558000"
  },
  {
    "text": "that the default i'll talk a little bit more about why we've done that but you'll notice that gp2 is the default",
    "start": "558000",
    "end": "563519"
  },
  {
    "text": "block device for all of the amis that amazon linux runs on almost all of the amis in the console",
    "start": "563519",
    "end": "568640"
  },
  {
    "text": "for the quick launch they're all gp2 based every volume in gp2 every single volume",
    "start": "568640",
    "end": "575200"
  },
  {
    "text": "can burst up to 3 000 iops or go higher if the baseline performance allows it and i'll talk",
    "start": "575200",
    "end": "580640"
  },
  {
    "text": "about that in a second what that means so what that means is you can provision a 10 gigabyte volume",
    "start": "580640",
    "end": "586560"
  },
  {
    "text": "and get 3000 iops from it or a 500 gigabyte volume or a terabyte and if we go higher than a terabyte",
    "start": "586560",
    "end": "592080"
  },
  {
    "text": "you'll get more baseline performance and the throughput of the volumes is increased so when larger and faster",
    "start": "592080",
    "end": "598240"
  },
  {
    "text": "came on the throughput has gone from 128 megabytes a second up to 160 megabytes a",
    "start": "598240",
    "end": "603839"
  },
  {
    "text": "second now it's kind of important to understand that throughput megabytes a second and",
    "start": "603839",
    "end": "608880"
  },
  {
    "text": "iops are closely related but they're two separate limits on the volume itself",
    "start": "608880",
    "end": "615920"
  },
  {
    "start": "615000",
    "end": "615000"
  },
  {
    "text": "so this is kind of a busy graphic but it's important this is something we shared when we launched larger and faster",
    "start": "616079",
    "end": "621519"
  },
  {
    "text": "and i'll take a moment to explain what we're trying to show you here so in the yellow is your burst bucket",
    "start": "621519",
    "end": "627760"
  },
  {
    "text": "and i'm going to take a long time to explain that so the burst bucket is the capability that gp2 provides for",
    "start": "627760",
    "end": "633440"
  },
  {
    "text": "all volumes however the green line is your baseline performance",
    "start": "633440",
    "end": "638880"
  },
  {
    "text": "three iops per gigabyte and so as you can see as we start to pass over the terabyte",
    "start": "638880",
    "end": "644959"
  },
  {
    "text": "volume size and for the people who do a lot of graphs they'll get very upset none of this is to scale so that",
    "start": "644959",
    "end": "651680"
  },
  {
    "text": "people are like that doesn't work and so none of this is a scale it's for graphic illustration and so if you look at it you'll see as",
    "start": "651680",
    "end": "657440"
  },
  {
    "text": "we start to pass the one terabyte volume size the green line our baseline performance that exceeds",
    "start": "657440",
    "end": "663440"
  },
  {
    "text": "3000 iops so at that point our baseline performance is higher than our burst performance and so that's the highest",
    "start": "663440",
    "end": "670399"
  },
  {
    "text": "amount of iops that volume is capable of delivering and so you can see once we get up to about 3.3 terabytes roughly or three",
    "start": "670399",
    "end": "677839"
  },
  {
    "text": "something terabytes we're now up at 10 000 iops and so at 10 000 iops that's the maximum",
    "start": "677839",
    "end": "684560"
  },
  {
    "text": "number of iops the gp2 volume can deliver and so now you're just adding capacities you go all the way up to 16.",
    "start": "684560",
    "end": "692079"
  },
  {
    "start": "693000",
    "end": "693000"
  },
  {
    "text": "can we save questions to the end is that okay",
    "start": "693920",
    "end": "697760"
  },
  {
    "text": "we'll i'll happily answer the questions as we get to the end so understanding what the gp2 burst bucket",
    "start": "700399",
    "end": "706079"
  },
  {
    "text": "does so the burst bucket in my opinion burst bucket in my opinion is a really unique",
    "start": "706079",
    "end": "711519"
  },
  {
    "text": "quality that you just don't see in regular hard drives in regular storage",
    "start": "711519",
    "end": "716800"
  },
  {
    "text": "this is the ability for a volume to have more performance at certain points in",
    "start": "716800",
    "end": "722160"
  },
  {
    "text": "time than it would typically have at other points so the steady state versus burst day",
    "start": "722160",
    "end": "727519"
  },
  {
    "text": "so every single gp2 volume which is created when you do create volume those 1.5 million volume create today",
    "start": "727519",
    "end": "734240"
  },
  {
    "text": "you do create volume it comes with a 5.4 million i o credit bucket so it's automatically",
    "start": "734240",
    "end": "742320"
  },
  {
    "text": "ready to go with 5.4 million iops it will always accumulate iops for every",
    "start": "742320",
    "end": "748240"
  },
  {
    "text": "second at the rate of baseline performance so if we have a 100 gigabyte volume it's",
    "start": "748240",
    "end": "753360"
  },
  {
    "text": "going to be in accumulating iops at 300 iops per second so it's always filling in at the top and",
    "start": "753360",
    "end": "760560"
  },
  {
    "text": "then you're going to use the iops at the bottom of the bucket at the rate that you drive your workload",
    "start": "760560",
    "end": "767040"
  },
  {
    "text": "so when we build talk about burst buckets or when people talk about burst i think the analogy that comes to mind",
    "start": "768399",
    "end": "774320"
  },
  {
    "text": "for me is a firework like it goes up and it goes bang and you're done burst is gone it's like a couple of seconds",
    "start": "774320",
    "end": "780480"
  },
  {
    "text": "that's not really the reality with burst buckets on gp2 so we have a tiny percentage of",
    "start": "780480",
    "end": "786560"
  },
  {
    "text": "customers who've actually emptied their burst bucket it's point zero something it's it's",
    "start": "786560",
    "end": "791680"
  },
  {
    "text": "really tiny because it takes a long time to empty your bucket so what we're graphing here is the size along the x-axis and the",
    "start": "791680",
    "end": "799600"
  },
  {
    "text": "time it takes to empty the burst bucket if you run flat out at 3000 iops per second okay",
    "start": "799600",
    "end": "807200"
  },
  {
    "text": "and so if i give you an example a 500 gigabyte volume would take 60 minutes of sustained",
    "start": "807200",
    "end": "815040"
  },
  {
    "text": "3000 iops constantly to empty that bucket but that also makes the assumption that",
    "start": "815040",
    "end": "821120"
  },
  {
    "text": "you're driving the ios and we're not doing any i o merging so that is 100 random no i os are matched up to get",
    "start": "821120",
    "end": "828000"
  },
  {
    "text": "each other because we'd count that as one rather than two and you've driven it flat out it will take 60 minutes to empty that bucket",
    "start": "828000",
    "end": "834000"
  },
  {
    "text": "it just doesn't happen it takes a really long time what we also show is that once you get past the one terabyte volume",
    "start": "834000",
    "end": "839600"
  },
  {
    "text": "size you can't empty the bucket because the bucket's only three thousand and the volumes are capable of doing much more",
    "start": "839600",
    "end": "846639"
  },
  {
    "text": "so what does this really mean for real-life workloads what what is this done for for you if you're launching an",
    "start": "846959",
    "end": "852079"
  },
  {
    "start": "847000",
    "end": "847000"
  },
  {
    "text": "ec2 instance and choosing a gp2 volume so a good example to illustrate this is the windows boot volume they're typically a",
    "start": "852079",
    "end": "858800"
  },
  {
    "text": "30 gigabyte volume for for a windows boot volume so it's going to get that initial credit of 5.4",
    "start": "858800",
    "end": "864480"
  },
  {
    "text": "million and it's going to be able to burst up to 3000 iops for 30 minutes okay it's pretty phenomenal can do that",
    "start": "864480",
    "end": "871760"
  },
  {
    "text": "and it's always going to be accumulating i o while it's running so if there's even a slight moment where it's not consuming all of those 3000 which is",
    "start": "871760",
    "end": "878480"
  },
  {
    "text": "hard it's going to be building up more iops so what it ultimately does is it",
    "start": "878480",
    "end": "884440"
  },
  {
    "text": "substantially lowers the boot time for your instances and so we did some testing comparing you",
    "start": "884440",
    "end": "890720"
  },
  {
    "text": "know magnetic to gp2 for both linux and windows and if you take a look at the windows it significantly drops",
    "start": "890720",
    "end": "896240"
  },
  {
    "text": "now we didn't change anything this is not an update to windows nothing changed in the ami the application is not",
    "start": "896240",
    "end": "902160"
  },
  {
    "text": "re-architected we simply choosed a different volume type when we launched and when you choose that different",
    "start": "902160",
    "end": "908079"
  },
  {
    "text": "volume type you get a faster boot time now the impact on this for customers is",
    "start": "908079",
    "end": "914480"
  },
  {
    "text": "is pretty dramatic we had customers who had auto scaling groups who would actually over provision their auto scaling group in windows",
    "start": "914480",
    "end": "920959"
  },
  {
    "text": "because the boot time would take too long for the windows instance to come up and you want to react quickly with an auto scaling",
    "start": "920959",
    "end": "926079"
  },
  {
    "text": "so they would over provision one or two instances to sort of always be on the leading edge you don't need to do that anymore with",
    "start": "926079",
    "end": "931279"
  },
  {
    "text": "gb2 the boot time has come down so you can now just add the instance quickly",
    "start": "931279",
    "end": "936639"
  },
  {
    "start": "937000",
    "end": "937000"
  },
  {
    "text": "another example is database volumes and so when you had magnetic the other choice",
    "start": "937519",
    "end": "943360"
  },
  {
    "text": "was provisioned iops so for a database the right choice would be provisioned iop so you would choose a provisioned iops volume",
    "start": "943360",
    "end": "949199"
  },
  {
    "text": "a one terabyte volume four thousand iops it would come in at 526 dollars a month",
    "start": "949199",
    "end": "956399"
  },
  {
    "text": "but if you move over to gp2 today and just use a one terabyte gp2 volume",
    "start": "956399",
    "end": "961680"
  },
  {
    "text": "you'll be able to do that for 102. but you're going to lose some baseline performance you're going to drop down",
    "start": "961680",
    "end": "966959"
  },
  {
    "text": "from from 4000 to 3000. now that might work for your application that makes might make a lot of sense",
    "start": "966959",
    "end": "972639"
  },
  {
    "text": "but you can also do something really creative where you can grab two gp2 volumes remember each volume has got 3000 iops of burst",
    "start": "972639",
    "end": "980639"
  },
  {
    "text": "stick two of them together the dreaded raid which we've managed to get rid of for a lot of larger and faster but it still makes sense here",
    "start": "980639",
    "end": "986800"
  },
  {
    "text": "and you'll actually get a baseline performance of 3000 iops but a burst to 6 000 so now you've got more performance",
    "start": "986800",
    "end": "992720"
  },
  {
    "text": "than you had on your provisioned iops but it's still 102 and so this makes a",
    "start": "992720",
    "end": "997920"
  },
  {
    "text": "really big difference if you're building out databases that don't require the highest level of performance consistency",
    "start": "997920",
    "end": "1003680"
  },
  {
    "text": "which piops delivers you can build them on gp2 and be substantially better than you were on magnetic",
    "start": "1003680",
    "end": "1011040"
  },
  {
    "start": "1010000",
    "end": "1010000"
  },
  {
    "text": "so some guidelines for sizing gp2 like if you're going to be moving on to the gp2 vbs volumes how do you size them",
    "start": "1011040",
    "end": "1016720"
  },
  {
    "text": "what is the right way to do it simply for most applications for most workloads it's the size of volume you",
    "start": "1016720",
    "end": "1021920"
  },
  {
    "text": "need so if you need 100 gigabytes of storage just provision 100 gigabytes for databases or applications where you",
    "start": "1021920",
    "end": "1028400"
  },
  {
    "text": "actually have an iop baseline some steady state that you need to maintain you need to work out the size that will",
    "start": "1028400",
    "end": "1034319"
  },
  {
    "text": "deliver that that steady state of iops and so for example if you need to deliver 300 iops then you take 300",
    "start": "1034319",
    "end": "1042319"
  },
  {
    "text": "divided by 3 it's 100 gigabyte volume and that would be the volume you can provision note that the i o bucket is actually",
    "start": "1042319",
    "end": "1048558"
  },
  {
    "text": "going to deliver a lot of performance the burst bucket is going to deliver a lot of performance so you don't need to",
    "start": "1048559",
    "end": "1053600"
  },
  {
    "text": "size it for table loads or rebuilding indexes it's what is the steady state of the database",
    "start": "1053600",
    "end": "1060240"
  },
  {
    "text": "now our ebs provisioned iops volumes they're targeted at really high performance",
    "start": "1060960",
    "end": "1066000"
  },
  {
    "text": "consistency when we think about it internally we would think about this as like a tier one database and a database",
    "start": "1066000",
    "end": "1072000"
  },
  {
    "text": "that if you were doing a select statement and it stalled for a second that would be noticed",
    "start": "1072000",
    "end": "1077120"
  },
  {
    "text": "this is the type of workload that you'd want to run on top of provisioned iops and so provisioned iops enables you to",
    "start": "1077120",
    "end": "1083280"
  },
  {
    "text": "provision significantly higher iops up to 20 000 iops and significantly more throughput as well",
    "start": "1083280",
    "end": "1089039"
  },
  {
    "text": "but you can do it with a lot less storage so the iops to gigabyte ratio is 30 iops per gigabyte meaning you can",
    "start": "1089039",
    "end": "1096480"
  },
  {
    "text": "provision in 4000 iops in about 140 something gigabytes of storage so it's very easy",
    "start": "1096480",
    "end": "1102640"
  },
  {
    "text": "to do that on top of it it's also designed for three nines of performance consistency",
    "start": "1102640",
    "end": "1108480"
  },
  {
    "text": "which is extremely consistent performance so you know you're always going to get those iops within the time",
    "start": "1108480",
    "end": "1113679"
  },
  {
    "text": "that you specified magnetic volumes absolutely not to be forgotten",
    "start": "1113679",
    "end": "1120960"
  },
  {
    "text": "you can think of ebs magnetic volumes as near-line storage within the platform when you need to have a lot of storage",
    "start": "1121360",
    "end": "1129039"
  },
  {
    "text": "that needs to be there you need to be able to access it maybe you have a posix requirement you can't put it into s3 and lifecycle at the",
    "start": "1129039",
    "end": "1135679"
  },
  {
    "text": "glacier near the ebs magnetic storage is going to be the right choice for your platform",
    "start": "1135679",
    "end": "1142240"
  },
  {
    "text": "for for types of file servers for different solutions like that exactly um the latency is going to vary",
    "start": "1142240",
    "end": "1148720"
  },
  {
    "text": "and the throughput is going to vary and we will highlight that in the summary sheet so it's one of those areas where if performance is required",
    "start": "1148720",
    "end": "1155600"
  },
  {
    "text": "you really want to be focusing on let's jump ahead you really want to be focusing on our",
    "start": "1155600",
    "end": "1160640"
  },
  {
    "text": "ssd backed volumes so this is our summary or our cheat sheet this is typically where everyone grabs their camera takes a picture and",
    "start": "1160640",
    "end": "1167200"
  },
  {
    "text": "but all of our slides will be on slideshare so you can download them and take a look at them offline so you don't need to worry about taking pictures but",
    "start": "1167200",
    "end": "1173600"
  },
  {
    "text": "really the takeaway here is the fact that things like throughput per node so 48 000 iops",
    "start": "1173600",
    "end": "1179679"
  },
  {
    "text": "that's an attribute of the ec2 instance not of ebs and our latency numbers are consistent for ssd",
    "start": "1179679",
    "end": "1186640"
  },
  {
    "text": "and so you can use this to work out what what kind of workloads might fit best for your volumes",
    "start": "1186640",
    "end": "1193520"
  },
  {
    "start": "1192000",
    "end": "1192000"
  },
  {
    "text": "so why did we make gp2 the default why have we made so much effort why have i spent so much time explaining about gp2",
    "start": "1193520",
    "end": "1200640"
  },
  {
    "text": "so first off we're able to deliver a really high baseline of performance so the fact that we can deliver burst",
    "start": "1200640",
    "end": "1207039"
  },
  {
    "text": "and ssd performance at that price point and in the the ability to to do it easily",
    "start": "1207039",
    "end": "1212320"
  },
  {
    "text": "we think it's important so that's why we're putting it in front of you that's why we're making it the first choice um we've changed the pricing of gp2 so",
    "start": "1212320",
    "end": "1220240"
  },
  {
    "text": "gp2 is priced on i think it's 10 cents per gigabyte per month we don't have any iops charge in",
    "start": "1220240",
    "end": "1226720"
  },
  {
    "text": "there it's very simple for you if you're designing an application to work out what will it cost for 100 gigabytes of",
    "start": "1226720",
    "end": "1231760"
  },
  {
    "text": "storage inside my application it makes it much easier for you to architect for cost as well within the",
    "start": "1231760",
    "end": "1236799"
  },
  {
    "text": "platform so take away here always use gp2 for",
    "start": "1236799",
    "end": "1242640"
  },
  {
    "text": "boot volumes so if you have got volumes or armies you made yourself so you've created your own custom amis",
    "start": "1242640",
    "end": "1249600"
  },
  {
    "text": "and you're running those within your workload there's a good chance if you created them before the middle of last year",
    "start": "1249600",
    "end": "1255360"
  },
  {
    "text": "or or haven't looked at how your armies are being created with packer or other tools like that that volume's probably magnetic because",
    "start": "1255360",
    "end": "1261520"
  },
  {
    "text": "it's the default choice and all you need to do is update the block device mapping and that will then",
    "start": "1261520",
    "end": "1266799"
  },
  {
    "text": "enable the access to gp2 how do you migrate onto gp2 data volumes",
    "start": "1266799",
    "end": "1272880"
  },
  {
    "start": "1270000",
    "end": "1270000"
  },
  {
    "text": "so if you've got data volumes and you want to move that data over you can easily change the type when",
    "start": "1272880",
    "end": "1278080"
  },
  {
    "text": "you're launching so if you're launching a new application that's using a snapshot you can you can change it from magnetic to gp2",
    "start": "1278080",
    "end": "1284400"
  },
  {
    "text": "you can use ebs snapshots which we'll talk about a little bit more to move the data easily to new volume type so when you create a snapshot",
    "start": "1284400",
    "end": "1291520"
  },
  {
    "text": "that snapshot can easily be recreated as any volume type so you can actually use it the other way around as well a little tip if you're",
    "start": "1291520",
    "end": "1297679"
  },
  {
    "text": "moving data onto near line if you're moving it to magnetic you can take a snapshot and then run it back on magnetic and",
    "start": "1297679",
    "end": "1302960"
  },
  {
    "text": "lower the cost of running it some file systems support resizing so you'll be able to resize your volumes if",
    "start": "1302960",
    "end": "1309760"
  },
  {
    "text": "you previously over provisioned your volumes because you needed more throughput or you needed more capability of iops you'll be able to resize those",
    "start": "1309760",
    "end": "1316480"
  },
  {
    "text": "volumes to save some cost on there so why do we have what are the benefits",
    "start": "1316480",
    "end": "1323120"
  },
  {
    "start": "1321000",
    "end": "1321000"
  },
  {
    "text": "or why do we have ebs snapshots well the first thing is they're more durable than ebs so ebs",
    "start": "1323120",
    "end": "1328720"
  },
  {
    "text": "is already very durable it's replicated data within the availability zone there's multiple copies of your data",
    "start": "1328720",
    "end": "1334240"
  },
  {
    "text": "when you do a write into ebs but if you want even more durability or the ability to take data and maybe move",
    "start": "1334240",
    "end": "1340720"
  },
  {
    "text": "it to another region for disaster recovery reasons if you make an ebs snapshot we store",
    "start": "1340720",
    "end": "1345760"
  },
  {
    "text": "that in s3 and once it's stored in s3 you can then copy that snapshot to another region you",
    "start": "1345760",
    "end": "1351919"
  },
  {
    "text": "can share it with another account you can do a lot of really cool things with ebs snapshots they're differential so they're not a",
    "start": "1351919",
    "end": "1358720"
  },
  {
    "text": "typical snapshot in the sense that when we take a snapshot of an ebs volume the first time we do it we take a copy",
    "start": "1358720",
    "end": "1365039"
  },
  {
    "text": "of the whole volume so 100 gigabyte volume will take 100 gigabytes and we store that as your snapshot",
    "start": "1365039",
    "end": "1370799"
  },
  {
    "text": "the next time you take a snapshot we will only take the data that's changed so it's an incremental or",
    "start": "1370799",
    "end": "1376720"
  },
  {
    "text": "a differential backup of your volume so if you've only changed 10 gigabytes of data since the last snapshot",
    "start": "1376720",
    "end": "1382880"
  },
  {
    "text": "and you use an ebs snapshot we'll back up 10 gigabytes now where it gets really interesting is",
    "start": "1382880",
    "end": "1388400"
  },
  {
    "text": "we're intelligent enough in the ebs service to understand exactly where all of those blocks are who's changed them which bit is dirty",
    "start": "1388400",
    "end": "1395200"
  },
  {
    "text": "so you can make one ebs snapshot when you create the volume you can then make four snapshots subsequently over the day or over the",
    "start": "1395200",
    "end": "1402000"
  },
  {
    "text": "week and if you delete any of those snapshots we'll still have a full snapshot because",
    "start": "1402000",
    "end": "1407039"
  },
  {
    "text": "we keep all of the blocks that are dirty and we keep track of them so you don't need to actually keep all",
    "start": "1407039",
    "end": "1412159"
  },
  {
    "text": "of your snapshots you can actually keep one snapshot and then one daily as you move through they're independent of the availability",
    "start": "1412159",
    "end": "1418559"
  },
  {
    "text": "zone so it makes it easy for you to move volumes around if you need to get data from one availability zone to another an ebs snapshot is a great way to do it",
    "start": "1418559",
    "end": "1425279"
  },
  {
    "text": "and of course you can copy them over the regions hopefully you've uh already learned this",
    "start": "1425279",
    "end": "1432159"
  },
  {
    "text": "if you've been working with aws for some time uh if you're not i i plead with you please tag everything",
    "start": "1432159",
    "end": "1438799"
  },
  {
    "text": "okay everything supports tags i can't think of many things that don't support tags today tag everything tagging enables you to",
    "start": "1438799",
    "end": "1445600"
  },
  {
    "text": "then easily go into your infrastructure both in ebs and snapshots as we're talking about here but also in ec2 and",
    "start": "1445600",
    "end": "1451760"
  },
  {
    "text": "other parts of the service and identify systems easily and quickly you could see what the purpose is its",
    "start": "1451760",
    "end": "1457440"
  },
  {
    "text": "production its dev test you know who's launched it what cost center it is if that's one of the aspects that is important to you",
    "start": "1457440",
    "end": "1463679"
  },
  {
    "text": "so use tags and tag as much as you can when it comes to snapshots if you use tags it's very easy to filter using the",
    "start": "1463679",
    "end": "1470159"
  },
  {
    "text": "cli or the console and pull out all of my snapshots for a particular instance or all of my snapshots for a particular volume",
    "start": "1470159",
    "end": "1476799"
  },
  {
    "text": "and then easily you can modify those copy those or throw them away if you don't need them anymore",
    "start": "1476799",
    "end": "1482880"
  },
  {
    "text": "so that's the overview of a of of ebs i'm going to move now into talking about the performance",
    "start": "1483279",
    "end": "1488400"
  },
  {
    "text": "and diving into how do you choose the right ec2 instance how do you size your volume appropriately and what are the",
    "start": "1488400",
    "end": "1494640"
  },
  {
    "text": "aspects of ebs that are going to deliver the performance you're looking for",
    "start": "1494640",
    "end": "1500320"
  },
  {
    "start": "1500000",
    "end": "1500000"
  },
  {
    "text": "so i need to start out with a little bit of theory uh it's kind of important because this is actually what tuning",
    "start": "1500320",
    "end": "1505520"
  },
  {
    "text": "theory is based in so little's law which is the q length multiplied by the arrival rate multiplied by the wait time",
    "start": "1505520",
    "end": "1511919"
  },
  {
    "text": "so in ebs speak that is the q depth multiplied by the iops",
    "start": "1511919",
    "end": "1518080"
  },
  {
    "text": "multiplied by the latency now this is a fundamental law that applies to all storage tuning this is not something",
    "start": "1518080",
    "end": "1524159"
  },
  {
    "text": "that's unique to ebs or something that you know we're driving you to learn this is how you would",
    "start": "1524159",
    "end": "1529279"
  },
  {
    "text": "optimize and tune a typical storage solution on premise and so these same things apply on-prem as they",
    "start": "1529279",
    "end": "1535760"
  },
  {
    "text": "apply on aws and so it's good to understand this this foundational theory",
    "start": "1535760",
    "end": "1542559"
  },
  {
    "text": "when we think about performance we typically think about three things we think about the amount of iops that",
    "start": "1542559",
    "end": "1548880"
  },
  {
    "text": "are being achieved or the amount of iops that we would like to achieve we look at the latency how long is it",
    "start": "1548880",
    "end": "1555120"
  },
  {
    "text": "taking for those iops to actually move around in the system and then the throughput how much data is",
    "start": "1555120",
    "end": "1560559"
  },
  {
    "text": "being moved backwards and forwards and typically when we talk about performance we also have performance",
    "start": "1560559",
    "end": "1565600"
  },
  {
    "text": "goals so there may be some goals you're trying to achieve you may want to be moving 2000 iops you may want to have",
    "start": "1565600",
    "end": "1572320"
  },
  {
    "text": "200 megabytes a second of throughput and so we need to understand how to measure and observe those when we build the",
    "start": "1572320",
    "end": "1577440"
  },
  {
    "text": "platform so there's four key components that we're going to talk about",
    "start": "1577440",
    "end": "1583120"
  },
  {
    "start": "1579000",
    "end": "1579000"
  },
  {
    "text": "and how they impact performance on ebs",
    "start": "1583120",
    "end": "1587600"
  },
  {
    "text": "we start with the ec2 instance and it's important to select the right ec2 instance we'll work our way through that",
    "start": "1588559",
    "end": "1594799"
  },
  {
    "text": "we then have the actual i o that you're doing so sequential or random 4k or 32k or one megabyte so the i o",
    "start": "1594799",
    "end": "1601840"
  },
  {
    "text": "that you're sending the actual workload down to the system the network link because as i mentioned ebs is network attached block storage",
    "start": "1601840",
    "end": "1609279"
  },
  {
    "text": "so there's a network link from the ec2 instance to the ebs server that's providing your volumes and it's",
    "start": "1609279",
    "end": "1614400"
  },
  {
    "text": "important to understand that you have choices there and that will impact your performance and then we have the ebs or the ebs",
    "start": "1614400",
    "end": "1620240"
  },
  {
    "text": "volume itself what size of volume do you have and what type of characteristics does it have",
    "start": "1620240",
    "end": "1627200"
  },
  {
    "start": "1626000",
    "end": "1626000"
  },
  {
    "text": "so we've got six areas we're going to dig into specifically and highlight how you would design for performance how",
    "start": "1627200",
    "end": "1632960"
  },
  {
    "text": "you would appropriately select the right features to get the most out of ebs and ec2 ec2",
    "start": "1632960",
    "end": "1638640"
  },
  {
    "text": "instance the ebs optimized instances um workload queue depth raid raid's still an",
    "start": "1638640",
    "end": "1645600"
  },
  {
    "text": "important aspect if you're looking for particular performance characteristics and then pre-warming the dreaded",
    "start": "1645600",
    "end": "1650960"
  },
  {
    "text": "pre-warming so the ec2 instance so we offer a lot of instances",
    "start": "1650960",
    "end": "1656480"
  },
  {
    "start": "1652000",
    "end": "1652000"
  },
  {
    "text": "andy covered in the keynote this morning the large selection of ec2 instances and all of their capabilities",
    "start": "1656480",
    "end": "1662960"
  },
  {
    "text": "all of them have different characteristics and so when you're choosing an ec2 instance you're typically looking for",
    "start": "1662960",
    "end": "1668240"
  },
  {
    "text": "a particular cpu profile or a certain amount of memory that it needs to have or maybe it's a general purpose it's a",
    "start": "1668240",
    "end": "1673679"
  },
  {
    "text": "web server and so those memory and cpu balances make sense but when you select them you also need",
    "start": "1673679",
    "end": "1679919"
  },
  {
    "text": "to be aware that all of them come with a particular amount of network capacity as well and so if you grab a t2 micro instance",
    "start": "1679919",
    "end": "1687520"
  },
  {
    "text": "and you attach a 4000 provision 4000 per iops provisioned iops volume",
    "start": "1687520",
    "end": "1692720"
  },
  {
    "text": "to that instance it's not likely that you're going to be able to drive that performance from a t2 micro they're",
    "start": "1692720",
    "end": "1698000"
  },
  {
    "text": "just not sized appropriately okay and so you need to make sure that you're choosing the right instance for",
    "start": "1698000",
    "end": "1703039"
  },
  {
    "text": "the amount of storage i o that you want to drive in the platform once you've chosen the right instance",
    "start": "1703039",
    "end": "1709279"
  },
  {
    "start": "1707000",
    "end": "1707000"
  },
  {
    "text": "for your application so you've selected the your m3 or your c4 you need to make sure",
    "start": "1709279",
    "end": "1714480"
  },
  {
    "text": "that you're actually turning on some of the attributes in that instance that make it effective or able to drive more",
    "start": "1714480",
    "end": "1720640"
  },
  {
    "text": "performance in ebs and because these are choices they're not on by default except in some of our",
    "start": "1720640",
    "end": "1726240"
  },
  {
    "text": "newer instances like the c4 so ebs optimize will give you an amount of bandwidth between your ec2 instance",
    "start": "1726240",
    "end": "1733440"
  },
  {
    "text": "and the ebs server and you can choose 500 megabytes 500 megabit a thousand",
    "start": "1733440",
    "end": "1738880"
  },
  {
    "text": "megabit two thousand megabit four thousand megabit of ebs optimization which gives you a different",
    "start": "1738880",
    "end": "1744320"
  },
  {
    "text": "path for ebs traffic than your regular instance traffic now where this is really important is",
    "start": "1744320",
    "end": "1749679"
  },
  {
    "text": "if you've architected your application you've set it all up it's running on a m3 2 extra large and you're driving lots",
    "start": "1749679",
    "end": "1756240"
  },
  {
    "text": "of traffic to it you've got lots of users coming in accessing your application or people are connecting to your database",
    "start": "1756240",
    "end": "1761279"
  },
  {
    "text": "if you don't have ebs optimization turned on what you're actually doing is you're contending traffic on that network link",
    "start": "1761279",
    "end": "1766880"
  },
  {
    "text": "so they're having to share the same network link as the ebs traffic and so you're going to get inconsistent performance so if you want to have",
    "start": "1766880",
    "end": "1772799"
  },
  {
    "text": "consistent performance you need to make sure ebs has got its own bandwidth so it's not fighting with other traffic on",
    "start": "1772799",
    "end": "1777840"
  },
  {
    "text": "your network the uh 10 gigabit instances so our 8xl",
    "start": "1777840",
    "end": "1783440"
  },
  {
    "text": "instances they actually have 10 gigabit all the way to ebs as well and so with those instances you you can",
    "start": "1783440",
    "end": "1789039"
  },
  {
    "text": "work out whether that's the most appropriate for driving a lot of storage performance enables you to drive up to 48 000 iops",
    "start": "1789039",
    "end": "1794720"
  },
  {
    "text": "in those instances or all the way up to 800 megabytes a second so takeaway here please use ebs",
    "start": "1794720",
    "end": "1802799"
  },
  {
    "text": "optimized if you want consistent performance so if you're benchmarking or developing your application you're",
    "start": "1802799",
    "end": "1808000"
  },
  {
    "text": "not sure whether the performance is coming from network traffic from your users or somewhere else make sure ebs optimization optimize flag",
    "start": "1808000",
    "end": "1814640"
  },
  {
    "text": "is on so you can separate that traffic out understanding your workload is going to",
    "start": "1814640",
    "end": "1820000"
  },
  {
    "start": "1817000",
    "end": "1817000"
  },
  {
    "text": "be really important when you're sizing ebs or when you're selecting the right ebs volumes so as i mentioned",
    "start": "1820000",
    "end": "1826000"
  },
  {
    "text": "we measure up to 256 kilobytes as an i o so it's slightly less",
    "start": "1826000",
    "end": "1831840"
  },
  {
    "text": "important than it used to be to actually size appropriately because iops used to be 16k and so if you were",
    "start": "1831840",
    "end": "1837840"
  },
  {
    "text": "driving a 64k workload you needed to effectively double or quadruple the number of iops that you",
    "start": "1837840",
    "end": "1843279"
  },
  {
    "text": "wanted so you could drive that through the platform read and write workloads actually don't make that much difference on ebs it's",
    "start": "1843279",
    "end": "1849520"
  },
  {
    "text": "one of the interesting characteristics of it being a service so unlike your typical hard drive where read and write are typically different",
    "start": "1849520",
    "end": "1855679"
  },
  {
    "text": "performance levels they're the same on ebs but it's good to understand how they perform exactly",
    "start": "1855679",
    "end": "1861519"
  },
  {
    "text": "your i o pattern is important so are you driving sequential i o are you driving random i o",
    "start": "1861519",
    "end": "1866799"
  },
  {
    "text": "so if you're driving sequential i o even if you're driving 4k sequential i o we're going to see that",
    "start": "1866799",
    "end": "1872960"
  },
  {
    "text": "as sequential i o and do our best to really translate that all into 256 kios and you'll be able to drive",
    "start": "1872960",
    "end": "1879039"
  },
  {
    "text": "a significant amount of throughput through the volume with hardly any iops being used but if it's all random then it's all",
    "start": "1879039",
    "end": "1885760"
  },
  {
    "text": "going to be iop driven and it won't matter about the throughput you're going to quickly exceed all the iops on it and then io concurrency so io",
    "start": "1885760",
    "end": "1892320"
  },
  {
    "text": "concurrency is something you typically can't easily manage inside your application but it's something you should be aware",
    "start": "1892320",
    "end": "1897760"
  },
  {
    "text": "of so if we're benchmarking if i was using a tool like fio i could set cue depth to four or execute",
    "start": "1897760",
    "end": "1903919"
  },
  {
    "text": "after eight and that will actually manage the number of ios that are pending for the block device and i can easily manage and measure that",
    "start": "1903919",
    "end": "1910559"
  },
  {
    "text": "within an application io concurrency typically means how many threads are doing i o to the volume at the same time",
    "start": "1910559",
    "end": "1916640"
  },
  {
    "text": "how many processes are running inside my web server or inside my database and so at a certain point too much eye",
    "start": "1916640",
    "end": "1922880"
  },
  {
    "text": "open concurrency will increase your q depth that will have a negative impact on your performance so it's important to",
    "start": "1922880",
    "end": "1928080"
  },
  {
    "text": "understand that",
    "start": "1928080",
    "end": "1930799"
  },
  {
    "start": "1933000",
    "end": "1933000"
  },
  {
    "text": "so when we talk about limits on ebs it's important to understand that the two are separate although they are",
    "start": "1933440",
    "end": "1939440"
  },
  {
    "text": "joined because throughput is iops measured by the amount of io size",
    "start": "1939440",
    "end": "1944880"
  },
  {
    "text": "an ebs volume or provision iops ebs volume can be provisioned up to 20 000",
    "start": "1944880",
    "end": "1950080"
  },
  {
    "text": "iops and it has throughput up to 320 megabytes a second",
    "start": "1950080",
    "end": "1955279"
  },
  {
    "text": "however it doesn't mean you can do both of them or all of them at the same time",
    "start": "1955279",
    "end": "1960799"
  },
  {
    "text": "so if we take an example here of an eight thousand provisioned iops volume we can definitely drive eight thousand",
    "start": "1960799",
    "end": "1966799"
  },
  {
    "text": "eight k iops we can drive eight thousand sixteen k iops what we cannot do is drive sixteen",
    "start": "1966799",
    "end": "1972559"
  },
  {
    "text": "thousand iops because that's more than the provisioned iops of the volume even though throughput wise all of these are under",
    "start": "1972559",
    "end": "1978320"
  },
  {
    "text": "320 megabytes a second we're exceeding the provisioned iops capability",
    "start": "1978320",
    "end": "1983600"
  },
  {
    "text": "in the inverse when i take a look at throughput on this volume we can definitely draw i can't drive 8064 ki ops it's 512",
    "start": "1983600",
    "end": "1992240"
  },
  {
    "text": "megabytes a second and so therefore that's exceeding the 320 so i can drive though",
    "start": "1992240",
    "end": "1998840"
  },
  {
    "text": "1250 at 256. so that's the difference between sequential and random on the workloads the more sequential it is",
    "start": "1998840",
    "end": "2005440"
  },
  {
    "text": "typically you're not even going to exceed all of your iops what's important to understand is if you were really building a throughput",
    "start": "2005440",
    "end": "2010880"
  },
  {
    "text": "application here you wouldn't need 4 000 iops in that ebs",
    "start": "2010880",
    "end": "2016000"
  },
  {
    "text": "volume you could probably do it with 1500 maybe 2 000 if you're a little bit conservative",
    "start": "2016000",
    "end": "2021440"
  },
  {
    "text": "and you're only paying for the provisioned iops the throughput is an aspect of it afterwards",
    "start": "2021440",
    "end": "2027039"
  },
  {
    "text": "so the block size is going to determine how much throughput you can get from your application so it's important to understand",
    "start": "2027039",
    "end": "2033360"
  },
  {
    "text": "what is the size of ios i'm sending down to the volumes and how are they being measured as we go through",
    "start": "2033360",
    "end": "2039760"
  },
  {
    "start": "2038000",
    "end": "2038000"
  },
  {
    "text": "so q depth is an important aspect because it's network attached block storage now q depth appears also in",
    "start": "2039840",
    "end": "2045360"
  },
  {
    "text": "local storage but with network attached storage once the i o is gone it's off into the queue",
    "start": "2045360",
    "end": "2050800"
  },
  {
    "text": "there's nothing i can do so it's important to make sure i'm feeding that queue feeding the network pipe appropriately",
    "start": "2050800",
    "end": "2056240"
  },
  {
    "text": "and keeping it filled and driven hard enough to get the performance i'm looking for you can monitor it with cloudwatch and",
    "start": "2056240",
    "end": "2063839"
  },
  {
    "text": "so these cloudwatch metrics are important if you haven't dug into cloudwatch metrics for ebs they measure all of the aspects of the",
    "start": "2063839",
    "end": "2070320"
  },
  {
    "text": "volume that you would need to actually work out things like q depth and latency and throughput and arrival rate so you can apply little's",
    "start": "2070320",
    "end": "2076638"
  },
  {
    "text": "law to your queuing tuning or your tuning theory and understand whether you're actually getting what you expect from the volumes",
    "start": "2076639",
    "end": "2084320"
  },
  {
    "text": "so talk a little bit about what an io latency is and how we can improve i o latency",
    "start": "2085040",
    "end": "2090240"
  },
  {
    "text": "so i o latency is the amount of time it takes for an i o between submission to the network to",
    "start": "2090240",
    "end": "2095679"
  },
  {
    "text": "submission to the block device and the completion time as far as the the application is concerned and",
    "start": "2095679",
    "end": "2103599"
  },
  {
    "text": "what i want to do is talk a little bit around how we measure and think about iops so this is a really really messy",
    "start": "2103599",
    "end": "2109760"
  },
  {
    "text": "graph this is a heat graph and you can see that our read iops are red and our right eye",
    "start": "2109760",
    "end": "2115839"
  },
  {
    "text": "ops are blue and they're all over the place and it's very hard to understand what's going on in that graph",
    "start": "2115839",
    "end": "2121839"
  },
  {
    "text": "so what i want to do is introduce before i go a little bit further for folks who don't remember this what a box plot is and how we use",
    "start": "2121839",
    "end": "2128000"
  },
  {
    "start": "2122000",
    "end": "2122000"
  },
  {
    "text": "box plots to understand this and then show you the impacts of different choices around i o latency for ebs",
    "start": "2128000",
    "end": "2134960"
  },
  {
    "text": "so in this box graph i'm going to show you the same graph we just did but it breaks it down so i can take a look at",
    "start": "2134960",
    "end": "2140000"
  },
  {
    "text": "the median what is the what is the average going through the platform i can then take a look at what's called the p25 and the p75 so the 75 percentile",
    "start": "2140000",
    "end": "2148160"
  },
  {
    "text": "and 25 percentile and then i also have the top and bottom of the of the data what was the zero and the hundred",
    "start": "2148160",
    "end": "2155200"
  },
  {
    "start": "2155000",
    "end": "2155000"
  },
  {
    "text": "so let me show you a baseline latency this is uh some latency testing done on io on an",
    "start": "2155200",
    "end": "2161760"
  },
  {
    "text": "instance with i think random iops and we're doing an m24 extra large and magnetic",
    "start": "2161760",
    "end": "2166960"
  },
  {
    "text": "and so you can see that roughly the median is sitting logarithmically we're probably sitting around five",
    "start": "2166960",
    "end": "2172079"
  },
  {
    "text": "milliseconds there i've got some pretty big outliers pushing all the way up into the between",
    "start": "2172079",
    "end": "2177280"
  },
  {
    "text": "10 and 100 and it comes down pretty low but not too far so the first change i make to this",
    "start": "2177280",
    "end": "2184000"
  },
  {
    "start": "2183000",
    "end": "2183000"
  },
  {
    "text": "platform if i want to reduce the latency if i want to get my ebs performance better is i'm going to move it over to gp2 so",
    "start": "2184000",
    "end": "2190800"
  },
  {
    "text": "you can see with the introduction of gp2 so the plot that's on the right hand",
    "start": "2190800",
    "end": "2196400"
  },
  {
    "text": "side to you my median has significantly come down so on average most of the ios are coming",
    "start": "2196400",
    "end": "2204160"
  },
  {
    "text": "in around one millisecond that's really good but i do have quite a lot of i o that's",
    "start": "2204160",
    "end": "2210320"
  },
  {
    "text": "falling outside of the median i've got quite a big box still there so it shows me there's still a lot of variability in the i o that's passing",
    "start": "2210320",
    "end": "2216400"
  },
  {
    "text": "through although my medians come down there's still a lot of i o variability however if i change it to an r32xl which",
    "start": "2216400",
    "end": "2224160"
  },
  {
    "start": "2222000",
    "end": "2222000"
  },
  {
    "text": "is the latest generation but equivalent of the m22 xl you can see that my medians now dropped",
    "start": "2224160",
    "end": "2230400"
  },
  {
    "text": "under the one millisecond i've got almost no outliers in the 25 to",
    "start": "2230400",
    "end": "2235440"
  },
  {
    "text": "75 range and a couple who sort of take me up a little bit but most of them come down",
    "start": "2235440",
    "end": "2240960"
  },
  {
    "text": "and so now i get a really consistent latency profile by making that change but the really",
    "start": "2240960",
    "end": "2247040"
  },
  {
    "text": "cool thing about making that change is it's cheaper so the gp2 is cheaper",
    "start": "2247040",
    "end": "2253440"
  },
  {
    "text": "and the instance is cheaper so if i move from an m22 xl to an r32xl i'll actually spend",
    "start": "2253440",
    "end": "2260800"
  },
  {
    "text": "less get better performance and lower latency io",
    "start": "2260800",
    "end": "2266640"
  },
  {
    "start": "2268000",
    "end": "2268000"
  },
  {
    "text": "so i want to try and spend a little bit of time explaining how q depth impacts your latency within the ebs",
    "start": "2269680",
    "end": "2276079"
  },
  {
    "text": "platform so what we're graphing here is the tp90 so the 90 percentile of latency so most",
    "start": "2276079",
    "end": "2282960"
  },
  {
    "text": "of them complete within 90. and it shows you the queue depth along the x-axis and the latency in milliseconds and so",
    "start": "2282960",
    "end": "2290880"
  },
  {
    "text": "this is for a 4000 k provisioned iops volume and you can see that it starts out with a q depth of",
    "start": "2290880",
    "end": "2296960"
  },
  {
    "text": "one of 0.075 milliseconds and as we increase our q depth it starts",
    "start": "2296960",
    "end": "2302160"
  },
  {
    "text": "to go up if we graph over the top of it the",
    "start": "2302160",
    "end": "2307200"
  },
  {
    "text": "number of iops achieved against the latency you can see that when we have a q depth",
    "start": "2307200",
    "end": "2312320"
  },
  {
    "text": "of one i'm only achieving 1800 iops so i've provisioned a 4k",
    "start": "2312320",
    "end": "2317599"
  },
  {
    "text": "volume but i'm not getting the iops i'm looking for so this is one of the aspects of ebs that you need to understand",
    "start": "2317599",
    "end": "2323520"
  },
  {
    "text": "is if you don't have enough i o in the network pipe if there's not enough iops going down to the ebs volume you're not driving it",
    "start": "2323520",
    "end": "2330480"
  },
  {
    "text": "hard enough so you might have a 4k volume but if you're only sending ios with basically one pending and nothing else",
    "start": "2330480",
    "end": "2337200"
  },
  {
    "text": "it's not going to drive it hard enough so what we do see is if we increase our",
    "start": "2337200",
    "end": "2342400"
  },
  {
    "text": "q depth and we head up to an optimal q depth of around four typically that we're going to be able to drive 4",
    "start": "2342400",
    "end": "2348640"
  },
  {
    "text": "000 iops comfortably but we're still in the single digit millisecond latency so it's only two",
    "start": "2348640",
    "end": "2354880"
  },
  {
    "text": "millisecond latency for the rights of course if we were to take it all the way up to the other end you can see that",
    "start": "2354880",
    "end": "2360640"
  },
  {
    "text": "if your queue depth is too high it impacts your latency substantially",
    "start": "2360640",
    "end": "2365680"
  },
  {
    "text": "it's taking over 35 milliseconds for these ios to return back to the application",
    "start": "2365680",
    "end": "2371440"
  },
  {
    "text": "now this is when i was talking about i o concurrency so if you've got too many threads doing",
    "start": "2371440",
    "end": "2376960"
  },
  {
    "text": "i o on a volume you're going to drive up the queue depth and when the q depth reaches a certain point your i o",
    "start": "2376960",
    "end": "2383520"
  },
  {
    "text": "is actually impacted substantially and just to make sure we highlight this",
    "start": "2383520",
    "end": "2389200"
  },
  {
    "start": "2387000",
    "end": "2387000"
  },
  {
    "text": "this is the right latency and you can see that again it's the same numbers roughly for right latency as it is for read latency",
    "start": "2389200",
    "end": "2397119"
  },
  {
    "text": "so some takeaways when we talk about latency and performance use the ssd volumes with the latest ec2",
    "start": "2397119",
    "end": "2403280"
  },
  {
    "text": "instances they're probably cheaper and they're probably faster than what you have today",
    "start": "2403280",
    "end": "2408960"
  },
  {
    "text": "so it really behooves you to go out and actually make that make those changes and the optimal q depth you're looking",
    "start": "2408960",
    "end": "2414560"
  },
  {
    "text": "for so q depth is important as we drive this workload the optimal q depth is going to be typically between four and eight",
    "start": "2414560",
    "end": "2420000"
  },
  {
    "text": "we use a number of about one to five hundred iops the larger uq depth gets it may not be",
    "start": "2420000",
    "end": "2426079"
  },
  {
    "text": "optimal so if you if your number comes out at like a q depth of 30 then you might want to dial it back down a little bit but",
    "start": "2426079",
    "end": "2431520"
  },
  {
    "text": "typically 4 to 8 is where we start out and ebs optimized instances provide a",
    "start": "2431520",
    "end": "2437200"
  },
  {
    "text": "consistent latency experience so if you're doing a lot of work around ebs if ebs is actually one of the key components in",
    "start": "2437200",
    "end": "2443920"
  },
  {
    "text": "your application architecture please make sure you're using optimized instances",
    "start": "2443920",
    "end": "2449599"
  },
  {
    "text": "so another aspect we have for increasing or driving more performance is raid now with the introduction of larger and",
    "start": "2449680",
    "end": "2454960"
  },
  {
    "text": "faster it's now possible to attach up to 16 terabytes of ebs to an instance",
    "start": "2454960",
    "end": "2460160"
  },
  {
    "text": "and up to 10 000 iops and 160 megabytes a second if you're using gp2 or general purpose",
    "start": "2460160",
    "end": "2466000"
  },
  {
    "text": "or 20 000 iops and 320 megabytes a second if you're using provision diops now those are pretty big numbers 16",
    "start": "2466000",
    "end": "2472640"
  },
  {
    "text": "terabytes of storage is a lot of storage in one volume and those throughput numbers are pretty substantial as well but there may be a",
    "start": "2472640",
    "end": "2478720"
  },
  {
    "text": "time where you need more typically we see it in a throughput type application where someone wants to drive",
    "start": "2478720",
    "end": "2484079"
  },
  {
    "text": "maybe 500 600 megabytes of io through to gp2 you're still going to want to put them",
    "start": "2484079",
    "end": "2489359"
  },
  {
    "text": "together in a raid configuration so when you took it when you take a look at raid you typically want to be looking",
    "start": "2489359",
    "end": "2494880"
  },
  {
    "text": "at something with raid striping there's no value in doing a raid 5 or a",
    "start": "2494880",
    "end": "2500000"
  },
  {
    "text": "raid 6 on top of ebs the software has already replicated or the service has already replicated your data within the",
    "start": "2500000",
    "end": "2506240"
  },
  {
    "text": "availability zone we've got five nines of availability the annual failure rate is i forget the",
    "start": "2506240",
    "end": "2512079"
  },
  {
    "text": "exact number point zero something one to two it's extremely low failure rates more durable",
    "start": "2512079",
    "end": "2517839"
  },
  {
    "text": "than a hard drive by a long way so raid five is not going to help so the only raid configuration that's typically worth",
    "start": "2517839",
    "end": "2524000"
  },
  {
    "text": "investigating is for more throughput and more performance and that's raid 0.",
    "start": "2524000",
    "end": "2529200"
  },
  {
    "text": "um this is just some testing i wanted to share with you we did to show that you can actually drive some pretty crazy numbers through an ec2 instance so this",
    "start": "2530079",
    "end": "2536960"
  },
  {
    "text": "is an 8xl instance one of the 10 gigabyte instances or 10 gigabit instances we're driving up to 48 000 iops through",
    "start": "2536960",
    "end": "2544240"
  },
  {
    "text": "the ebs volumes and it's going up to 823 megabytes a second so you can drive a",
    "start": "2544240",
    "end": "2550079"
  },
  {
    "text": "huge amount of io from one of the large instances down to ebs",
    "start": "2550079",
    "end": "2555440"
  },
  {
    "text": "if you are doing raid once you've rated those volumes together typically the stripe size that makes the most sense is",
    "start": "2556160",
    "end": "2561440"
  },
  {
    "text": "a takeaway if you use 128k or 256. anything under that you're",
    "start": "2561440",
    "end": "2566480"
  },
  {
    "text": "probably going to end up having all the i o merging happening anyway so it doesn't really make sense to do anything less than that",
    "start": "2566480",
    "end": "2574400"
  },
  {
    "start": "2574000",
    "end": "2574000"
  },
  {
    "text": "the dreaded pre-warming i do have to talk about it just for a little bit so pre-warming is an aspect that comes",
    "start": "2574400",
    "end": "2580400"
  },
  {
    "text": "up typically when you're benchmarking ebs so there's something called the first",
    "start": "2580400",
    "end": "2585599"
  },
  {
    "text": "access penalty today in ebs so when you first touch a block it's going to have a slightly higher",
    "start": "2585599",
    "end": "2590720"
  },
  {
    "text": "latency than the second time or the millions of other times you touch that block in the lifetime of the volume",
    "start": "2590720",
    "end": "2597119"
  },
  {
    "text": "if you're doing benchmarking because you're trying to qualify an application on top of an ebs volume or a particular",
    "start": "2597119",
    "end": "2602160"
  },
  {
    "text": "configuration you may need to pre-warm and there's documentation that explains it and it's something that you know we're always",
    "start": "2602160",
    "end": "2607599"
  },
  {
    "text": "working on to reduce the impact of but you may need to do it so pay attention to the documentation if you're benchmarking",
    "start": "2607599",
    "end": "2614400"
  },
  {
    "text": "if you are going to pre-warm a volume use a very large block size please don't go in and pre-warm the",
    "start": "2614400",
    "end": "2619680"
  },
  {
    "text": "volume with a 4k because all you're doing is testing iops you really want to send like one megabyte or two megabyte",
    "start": "2619680",
    "end": "2624720"
  },
  {
    "text": "ios down to the volume some final tips around performance for that these larger and faster volumes",
    "start": "2624720",
    "end": "2631920"
  },
  {
    "start": "2627000",
    "end": "2627000"
  },
  {
    "text": "have some interesting side effects that you don't realize so when you're formatting 16 terabytes",
    "start": "2631920",
    "end": "2637440"
  },
  {
    "text": "it takes longer than formatting 100 gigabytes and so make sure you're using file systems that support really fast",
    "start": "2637440",
    "end": "2642880"
  },
  {
    "text": "initialization so in the linux space things like ext4 and xfs are going to initialize substantially",
    "start": "2642880",
    "end": "2648880"
  },
  {
    "text": "quicker on top of that block storage than if you're using ext3 and other file systems",
    "start": "2648880",
    "end": "2654000"
  },
  {
    "text": "and alignment does matter so we present a raw block device to you",
    "start": "2654000",
    "end": "2659359"
  },
  {
    "text": "you should be using 4k alignment older operating systems so the rel 5 family some of the older windows stuff",
    "start": "2659359",
    "end": "2665520"
  },
  {
    "text": "they don't recognize that we do 4k sectors or 4k alignment in ebs and so you can actually impact",
    "start": "2665520",
    "end": "2671200"
  },
  {
    "text": "performance by doing that so if you're truly looking for performance make sure you choose the right alignment sector size inside ebs",
    "start": "2671200",
    "end": "2679040"
  },
  {
    "text": "there's another cheat sheet for folks who want to take a quick picture but we'll put them up in slideshare this is really to help you understand",
    "start": "2679040",
    "end": "2685520"
  },
  {
    "text": "where we think some of the performance numbers look for different applications or different databases and workloads on top of aws",
    "start": "2685520",
    "end": "2692160"
  },
  {
    "text": "the numbers you should be able to achieve in the most optimal configuration so if you've followed all of the tuning advice you're using ebs",
    "start": "2692160",
    "end": "2698160"
  },
  {
    "text": "optimization you right-sized your instance you've got the right size of ebs volumes your queue depth is appropriate",
    "start": "2698160",
    "end": "2704079"
  },
  {
    "text": "we think you should be able to drive these numbers happily so if you've done everything correct",
    "start": "2704079",
    "end": "2709920"
  },
  {
    "text": "what you should end up with is something that looks like this and it's an interesting graphic but what we're trying to take away here is that",
    "start": "2709920",
    "end": "2715760"
  },
  {
    "text": "if everything's right sized if your ec2 instance has got 1000 megabit per second of ebs optimization",
    "start": "2715760",
    "end": "2722640"
  },
  {
    "text": "and your application is tuned appropriately to drive on top of that and you've got the right volume or volumes configured",
    "start": "2722640",
    "end": "2728079"
  },
  {
    "text": "you should have a well-balanced system and be able to drive performance end to end through that platform",
    "start": "2728079",
    "end": "2734480"
  },
  {
    "start": "2734000",
    "end": "2734000"
  },
  {
    "text": "so just to recap the tools you have available for tuning performance on ebs and ec2 you have the ec2 instance",
    "start": "2734560",
    "end": "2742000"
  },
  {
    "text": "right sizing the ec2 instance you have ebs optimization you have your workload so making sure you understand that and shooting your",
    "start": "2742000",
    "end": "2748319"
  },
  {
    "text": "workload appropriately make sure you have the right i o concurrency or using the right block size the queue depth you have raid if you",
    "start": "2748319",
    "end": "2755200"
  },
  {
    "text": "need more performance than we offer today with larger and faster and then you do have pre-warming if you're doing benchmarking",
    "start": "2755200",
    "end": "2762318"
  },
  {
    "text": "now i want to take a little bit of time and talk about encryption encryption is an important aspect of ebs",
    "start": "2762800",
    "end": "2768720"
  },
  {
    "text": "which i think we've made substantially easier at reinvent and i want to re just kind of refresh if you haven't seen this",
    "start": "2768720",
    "end": "2774079"
  },
  {
    "text": "already so why do you want to encrypt data volumes so typically people are",
    "start": "2774079",
    "end": "2779760"
  },
  {
    "start": "2776000",
    "end": "2776000"
  },
  {
    "text": "encrypting because they have compliance or security reasons within their business they need to make sure that they're securing data so they can pass that sort",
    "start": "2779760",
    "end": "2786800"
  },
  {
    "text": "of assurance on to their customers or onto their cso that they're carrying this out and so when you encrypt data volumes you",
    "start": "2786800",
    "end": "2794000"
  },
  {
    "text": "need to come up with an infrastructure to manage it you need to come up with a way of managing the encryption keys and managing the services with them",
    "start": "2794000",
    "end": "2800000"
  },
  {
    "text": "and so we used to have the options of third-party products like symantec and trust and trend micro and now with",
    "start": "2800000",
    "end": "2806800"
  },
  {
    "text": "the introduction of kms which if you haven't seen it before we launched at re invent we now have an aws native key management",
    "start": "2806800",
    "end": "2814319"
  },
  {
    "text": "service now key management is not a very fun topic a good friend of mine our security solution architect says it's very boring",
    "start": "2814319",
    "end": "2820079"
  },
  {
    "text": "to talk about because it does exactly what it's supposed to do nothing more nothing less it secures your keys with an audible",
    "start": "2820079",
    "end": "2826319"
  },
  {
    "text": "trail and exposes them to services so they can use them when they want to access your data it's very boring but it's very",
    "start": "2826319",
    "end": "2832800"
  },
  {
    "text": "easy to use inside aws today so you can create a key you can associate a key with projects with",
    "start": "2832800",
    "end": "2838319"
  },
  {
    "text": "workloads with customers any particular reason you want to create a specific key and then you can pass that key into our",
    "start": "2838319",
    "end": "2845040"
  },
  {
    "text": "services and we'll use that key to encrypt your volumes",
    "start": "2845040",
    "end": "2850559"
  },
  {
    "text": "now what's really cool about ebs encryption is it happens on the ec2 host so when you choose an ebs encrypted",
    "start": "2850559",
    "end": "2857280"
  },
  {
    "text": "volume you say hey encrypt that volume for me we're going to encrypt the volume on the ec2 host where your ec2 instance is",
    "start": "2857280",
    "end": "2863760"
  },
  {
    "text": "running and then all of the data that's passing backwards and forwards over the network link that's encrypted with your key and then",
    "start": "2863760",
    "end": "2870319"
  },
  {
    "text": "the ebs snapshot that you're going to make with it because you do snapshots regularly that's going to be encrypted as well so",
    "start": "2870319",
    "end": "2876400"
  },
  {
    "text": "all of your data is going to be encrypted so it's going to be encrypted at rest and it's going to be encrypted in flight as it passes through the network and",
    "start": "2876400",
    "end": "2882880"
  },
  {
    "text": "that's a really cool feature i think of ebs it's also super easy to do okay when you go to create volume in the console",
    "start": "2882880",
    "end": "2889680"
  },
  {
    "text": "you can just turn on a flag encrypted if that's the only thing you have to do if you want to use kms and manage all of",
    "start": "2889680",
    "end": "2895280"
  },
  {
    "text": "the keys that go with it you just enter the key and we'll use that key when we create the volume",
    "start": "2895280",
    "end": "2902480"
  },
  {
    "text": "this is a deeper dive into how it works i i will happily take questions on this because i'm starting to run out of time but uh the",
    "start": "2903520",
    "end": "2909359"
  },
  {
    "text": "the encryption keys uses a a concept of wrapper keys and we can do a sideline on exactly how kms encrypts",
    "start": "2909359",
    "end": "2917200"
  },
  {
    "text": "so a summary when you're trying to get performance when you're really architecting for performance on ec2 and",
    "start": "2917920",
    "end": "2923599"
  },
  {
    "text": "ebs you want to make sure you select the right volume for your workload so that might be general purpose because",
    "start": "2923599",
    "end": "2929599"
  },
  {
    "text": "you have a general purpose workload it might be provisioned iops for that really high performance database",
    "start": "2929599",
    "end": "2934960"
  },
  {
    "text": "or it might be magnetic because you've got cold storage that you want to keep online or cold data that you want to keep online",
    "start": "2934960",
    "end": "2940880"
  },
  {
    "text": "get the right instance so if you haven't recently refreshed your instances you're using make sure you're using the latest",
    "start": "2940880",
    "end": "2946800"
  },
  {
    "text": "generation instance make sure you're turning on attributes to make a difference provisioned iop um ebs optimization for example take",
    "start": "2946800",
    "end": "2954480"
  },
  {
    "text": "snapshots take snapshots often take snapshots early the thing about snapshots is they're not",
    "start": "2954480",
    "end": "2959680"
  },
  {
    "text": "very helpful when you uh have a problem and you want to go back in time if you haven't made them okay so make a snapshot when you create",
    "start": "2959680",
    "end": "2967119"
  },
  {
    "text": "the volume okay they don't cost a lot so make a snapshot when you create the volume and then later on it's very easy to make a",
    "start": "2967119",
    "end": "2973680"
  },
  {
    "text": "new snapshot and only get the differential data and leverage encryption if you need it if encryption is an important aspect of",
    "start": "2973680",
    "end": "2979280"
  },
  {
    "text": "your workload please use it it's very easy to turn on and it's very easy to audit",
    "start": "2979280",
    "end": "2985280"
  },
  {
    "text": "and uh with that i will happily take q a we have a mic there folks want to mic otherwise i can relay questions i'm going to start with",
    "start": "2985280",
    "end": "2992720"
  },
  {
    "text": "you sir because i asked you to wait",
    "start": "2992720",
    "end": "2999838"
  },
  {
    "text": "uh okay so the question was when we talk about iops are we talking about iops that are provided or after the services has",
    "start": "3002240",
    "end": "3008480"
  },
  {
    "text": "created the volume so when we talk about iops we talk about the iops you can achieve in that volume so any of the work we do",
    "start": "3008480",
    "end": "3014480"
  },
  {
    "text": "to make sure your data is durable and redundant within the available zone has nothing to do with the iops we deliver to you",
    "start": "3014480",
    "end": "3020720"
  },
  {
    "text": "100 usabili up so if you provision a volume with 2000 iops it has 2000 iops you can use on your instance",
    "start": "3020720",
    "end": "3040480"
  },
  {
    "text": "yeah so um the question was um i i mentioned that you could choose the amount of vbs optimization you want to use",
    "start": "3040480",
    "end": "3045680"
  },
  {
    "text": "and so that's an that's basically an attribute of the instance so for example certain instances have different levels",
    "start": "3045680",
    "end": "3052160"
  },
  {
    "text": "of ebs optimizations so if you choose an instance like an m3",
    "start": "3052160",
    "end": "3057200"
  },
  {
    "text": "large it has 500 megabits of ebs optimizing m3 extra large has 1000 megabits",
    "start": "3057200",
    "end": "3063040"
  },
  {
    "text": "in so each instance an r32xl i think has a thousand megabits",
    "start": "3063040",
    "end": "3070480"
  },
  {
    "text": "a second but don't quote me on that it could be 2 000.",
    "start": "3070480",
    "end": "3074880"
  },
  {
    "text": "so the um the question was if you go up to higher instances so an 8 extra large instance will have either 10 gigabits of",
    "start": "3077119",
    "end": "3083599"
  },
  {
    "text": "ebs optimization um but on the the latest one the c4 um or if you're looking at",
    "start": "3083599",
    "end": "3089119"
  },
  {
    "text": "the previous generations like the c3s and the cr1s and stuff they have a 10 gigabit to everything so",
    "start": "3089119",
    "end": "3094559"
  },
  {
    "text": "they can choose how much bandwidth they drive",
    "start": "3094559",
    "end": "3098160"
  },
  {
    "text": "yes yeah so the question was when i mentioned raid stripe size i i suggested",
    "start": "3103760",
    "end": "3110400"
  },
  {
    "text": "128 or 256. so that's really when you're creating the raid volume within the operating",
    "start": "3110400",
    "end": "3115440"
  },
  {
    "text": "system so within linux or within windows yeah no",
    "start": "3115440",
    "end": "3122319"
  },
  {
    "text": "so when you match your what you're doing there when you match at the sql server is you're basically causing all of the i",
    "start": "3122319",
    "end": "3128240"
  },
  {
    "text": "o to never be merged we'll do our best to merge it on the back end but at your os you're actually",
    "start": "3128240",
    "end": "3133359"
  },
  {
    "text": "adding overhead so you should the block size should actually match the 128-256",
    "start": "3133359",
    "end": "3140319"
  },
  {
    "text": "yes",
    "start": "3150839",
    "end": "3153839"
  },
  {
    "text": "it does yeah so we have lots of customers so the question was um you mentioned cassandra in the slides and",
    "start": "3158240",
    "end": "3163520"
  },
  {
    "text": "and you know some people recommend using ephemeral with cassandra and and so there's going to be different use cases for for different customers so",
    "start": "3163520",
    "end": "3170720"
  },
  {
    "text": "if we take a look at our i2 8xl which is our really high iops instance that's going to drive a very large",
    "start": "3170720",
    "end": "3176720"
  },
  {
    "text": "number of iops and throughput and if you have a very extreme cassandra workload that might be the instance that",
    "start": "3176720",
    "end": "3182319"
  },
  {
    "text": "you're looking for what we typically find is that customers are not actually at those numbers for performance they're much lower",
    "start": "3182319",
    "end": "3188800"
  },
  {
    "text": "and gp2 provides those numbers with the additional benefits of increased durability",
    "start": "3188800",
    "end": "3193839"
  },
  {
    "text": "and easier snapshot and management of the actual of the application so it might not make",
    "start": "3193839",
    "end": "3200000"
  },
  {
    "text": "sense when you look at it but when you start to look at the total cost of ownership so what does it cost to look after my instances and manage them and",
    "start": "3200000",
    "end": "3205920"
  },
  {
    "text": "if one so with cassandra on ephemeral if one dies you need to re-mirror or remaster him in from a new",
    "start": "3205920",
    "end": "3212720"
  },
  {
    "text": "instance with ec2 and ebs for cassandra if something happens to the instance",
    "start": "3212720",
    "end": "3218559"
  },
  {
    "text": "we'll auto recover it now you can turn that on as an option it'll just come right back up with the volumes attached",
    "start": "3218559",
    "end": "3223839"
  },
  {
    "text": "that they're already there so the recovery time is significantly shorter",
    "start": "3223839",
    "end": "3228880"
  },
  {
    "text": "yes yes so the question was i've created an",
    "start": "3234839",
    "end": "3241200"
  },
  {
    "text": "encrypted volume but i couldn't attach it to a certain instance so only the latest generation instances",
    "start": "3241200",
    "end": "3246640"
  },
  {
    "text": "support encryption and the reason for that is because we leverage the intel aes extensions in the cpu",
    "start": "3246640",
    "end": "3253440"
  },
  {
    "text": "to offload encryption so that we can do encryption at the least cost to your to your application environment so if you've created an",
    "start": "3253440",
    "end": "3260079"
  },
  {
    "text": "encrypted volume and try and attach it to like an m1 or a t2 then it's not going to be available so in the ebs",
    "start": "3260079",
    "end": "3265359"
  },
  {
    "text": "encryption details it lists all the instances that support encryption",
    "start": "3265359",
    "end": "3270240"
  },
  {
    "text": "yes okay",
    "start": "3271440",
    "end": "3279838"
  },
  {
    "text": "it's not that bad at the end of the day you know encryption is never free there's always going to be some cost and i'm happy to talk about it offline",
    "start": "3284480",
    "end": "3290880"
  },
  {
    "text": "about the exact use case",
    "start": "3290880",
    "end": "3293838"
  },
  {
    "text": "oh you mean key well the way kms works it's got master keys so when you're doing key rotation you're just",
    "start": "3298160",
    "end": "3304000"
  },
  {
    "text": "re you're it doesn't change the actual key on the volume itself so we have questions on the mic i do apologize so you talked about content",
    "start": "3304000",
    "end": "3311760"
  },
  {
    "text": "let's say contention between the network traffic and the ebs traffic can you talk about that and what does ebs optimized give you",
    "start": "3311760",
    "end": "3318640"
  },
  {
    "text": "sure so so um when i talk about contention i don't talk about contention that we have but more that the contention your",
    "start": "3318640",
    "end": "3324880"
  },
  {
    "text": "application may introduce so if you have a lot of connections maybe uh you know you're a web server",
    "start": "3324880",
    "end": "3330240"
  },
  {
    "text": "there's a lot of requests coming into your web server that that network pipe is going to be then",
    "start": "3330240",
    "end": "3335680"
  },
  {
    "text": "sharing itself with ebs traffic what ebs optimization does for you is carve out bandwidth separate from the",
    "start": "3335680",
    "end": "3342720"
  },
  {
    "text": "instance just for ebs and so you get this consistent performance throughput to ebs next question what's the performance",
    "start": "3342720",
    "end": "3349920"
  },
  {
    "text": "penalty using encryption uh the performance penalty using encryption it depends on the specific workload block sizes iops etcetera i'm",
    "start": "3349920",
    "end": "3356880"
  },
  {
    "text": "happy to chat to you about what your workload is just have a quick question under linux",
    "start": "3356880",
    "end": "3362799"
  },
  {
    "text": "uh what would you recommend for your raid i notice you had up there either soft raid 0 or lvm uh what would you",
    "start": "3362799",
    "end": "3369200"
  },
  {
    "text": "recommend to actually balance it so that you don't get a hot disk um so typically mdadm on on",
    "start": "3369200",
    "end": "3375599"
  },
  {
    "text": "xero is going to balance your ios anyway it does a balance over them with lvm you want to make sure you're doing lvm",
    "start": "3375599",
    "end": "3381920"
  },
  {
    "text": "uh stripe and not lvm linear so a lot of people get caught out with this there's some great blog posts from lots of",
    "start": "3381920",
    "end": "3387440"
  },
  {
    "text": "people around this i've been burnt by it myself in the past but when you do lvm create i think it defaults to linear",
    "start": "3387440",
    "end": "3394240"
  },
  {
    "text": "which means fill up volume one then volume two then volume three so that's what you end up with this hotspot",
    "start": "3394240",
    "end": "3400079"
  },
  {
    "text": "feeling because you're like hey i should have twice the performance because i have two volumes so watch out if you're using lvm that it's doing a proper stripe and not",
    "start": "3400079",
    "end": "3407200"
  },
  {
    "text": "doing linear cool we're officially out of time at",
    "start": "3407200",
    "end": "3412880"
  },
  {
    "text": "this point so unless there's any burning questions i thank you very much for coming today",
    "start": "3412880",
    "end": "3419838"
  }
]
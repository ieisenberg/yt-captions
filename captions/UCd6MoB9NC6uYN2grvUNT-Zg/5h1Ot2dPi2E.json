[
  {
    "start": "0",
    "end": "158000"
  },
  {
    "text": "hi everyone my name is Dan banger welcome and thanks again for spending",
    "start": "659",
    "end": "7140"
  },
  {
    "text": "your evening with us today my name is Dan banger I do lead a small team of",
    "start": "7140",
    "end": "13200"
  },
  {
    "text": "business about managers are eight of us and what we do is that we do focus on AI",
    "start": "13200",
    "end": "19080"
  },
  {
    "text": "platforms and engines essentially everything that can enable their scientists to be successful with their",
    "start": "19080",
    "end": "25410"
  },
  {
    "text": "journey with machine learning and today specifically I have the honor and",
    "start": "25410",
    "end": "30449"
  },
  {
    "text": "pleasure to have my friend and former colleague from Facebook Joe Spisak joining me today thank you gotta be here",
    "start": "30449",
    "end": "39950"
  },
  {
    "text": "and you guys are in for a treat there's a lot of content to cover so we're going",
    "start": "39950",
    "end": "46739"
  },
  {
    "text": "to be going a little bit faster but just a little bit of housekeeping one is we will be covering some some",
    "start": "46739",
    "end": "54899"
  },
  {
    "text": "code as part of the demo the code is available for you to copy and and play",
    "start": "54899",
    "end": "60899"
  },
  {
    "text": "with today on github so don't worry about trying to figure everything out right now the slides as well will be",
    "start": "60899",
    "end": "68130"
  },
  {
    "text": "available immediately for you to take home and then play around with so don't",
    "start": "68130",
    "end": "73229"
  },
  {
    "text": "worry too much about that piece and also this is a foreign level session today",
    "start": "73229",
    "end": "80490"
  },
  {
    "text": "what we what we decided to do Joe and I is to dig deeper into the Python",
    "start": "80490",
    "end": "85950"
  },
  {
    "text": "experience for the develop or data scientists and try to come up with a",
    "start": "85950",
    "end": "92100"
  },
  {
    "text": "message that really puts aside all the definitions and everything that you",
    "start": "92100",
    "end": "97860"
  },
  {
    "text": "might probably want to read on your own and then dig really deep into the best",
    "start": "97860",
    "end": "102930"
  },
  {
    "text": "practices the opportunity of piperwai piperj what is the strategy that",
    "start": "102930",
    "end": "108420"
  },
  {
    "text": "Facebook had in mind when they built Piper watch as well as what we do at Amazon Web Services that enables fight",
    "start": "108420",
    "end": "116009"
  },
  {
    "text": "or to essentially be a very compelling deep learning framework on the cloud so it's going to be a deep dive like I said",
    "start": "116009",
    "end": "122820"
  },
  {
    "text": "so far in the level session I have some code on the side and I also have a lot of slides to cover so I'll dig right",
    "start": "122820",
    "end": "129209"
  },
  {
    "text": "away just for my own calibration who here is familiar with pike porridge",
    "start": "129209",
    "end": "136290"
  },
  {
    "text": "and who here is probably running a team or part of a team that is using higher torch pretty much every day all right",
    "start": "136290",
    "end": "143450"
  },
  {
    "text": "okay better than I hoped perfect thanks a lot for the calibration again my name",
    "start": "143450",
    "end": "149579"
  },
  {
    "text": "is Dan banger today with me is Joe who would dig into the pythor experience",
    "start": "149579",
    "end": "154709"
  },
  {
    "text": "from a Facebook's perspective I started with thank you and one of the key",
    "start": "154709",
    "end": "160500"
  },
  {
    "start": "158000",
    "end": "627000"
  },
  {
    "text": "reasons one of the key drivers that we all hear today and I believe that you you aware of that as well is that we we",
    "start": "160500",
    "end": "167400"
  },
  {
    "text": "all into technology and we all into trying to touch the the next level the",
    "start": "167400",
    "end": "172799"
  },
  {
    "text": "next stage as far as technology is concerned what are the top ten digital trends that are out there that are",
    "start": "172799",
    "end": "179069"
  },
  {
    "text": "really giving AI and machine learning an opportunity today and so I decided to",
    "start": "179069",
    "end": "184200"
  },
  {
    "text": "put this to distend I mean I got them from from Gartner but it's interesting to look at where the world is going in",
    "start": "184200",
    "end": "191310"
  },
  {
    "text": "terms of technology where we're building autonomous things we're dealing with blockchain smart spaces digital and",
    "start": "191310",
    "end": "197910"
  },
  {
    "text": "digital ethics sorry digital ethics and privacy quantum computing and an empowered edge where",
    "start": "197910",
    "end": "204739"
  },
  {
    "text": "computing is coming closer and closer to end-users as possible and if you dig",
    "start": "204739",
    "end": "210180"
  },
  {
    "text": "deeper into all of these new paradigms and technology we realize that all of them involve some form of AI machine",
    "start": "210180",
    "end": "217139"
  },
  {
    "text": "learning I know that AI is very visible nowadays with all the examples that you",
    "start": "217139",
    "end": "223290"
  },
  {
    "text": "get you know from a marketing standpoint but it's also this optimization game",
    "start": "223290",
    "end": "229019"
  },
  {
    "text": "that is a very back-end related artificial intelligence practice that we don't get to talk about a lot but that",
    "start": "229019",
    "end": "235470"
  },
  {
    "text": "actually exists right so what we see at Amazon Web Services for the past you",
    "start": "235470",
    "end": "241319"
  },
  {
    "text": "know a couple of years working with tens of thousands of active developers building machine learning models adopting different frameworks of machine",
    "start": "241319",
    "end": "248699"
  },
  {
    "text": "learning on the cloud is that there's a 250% growth year over year that we're",
    "start": "248699",
    "end": "253919"
  },
  {
    "text": "capturing simply because of the opportunity to leverage cloud infrastructures and leverage cloud skill",
    "start": "253919",
    "end": "260669"
  },
  {
    "text": "and leverage cloud paradigms and leverage you know platforms like sage maker to accelerate the process through",
    "start": "260669",
    "end": "267270"
  },
  {
    "text": "which developers and their scientists deploy and then build and then train machine learning models we also seeing 8",
    "start": "267270",
    "end": "274560"
  },
  {
    "text": "out of 10 typical machine learning and deep learning workloads running on AWS today including the benchmarks and so I",
    "start": "274560",
    "end": "280919"
  },
  {
    "text": "believe you familiar with most of these customers into it it's using AWS H maker",
    "start": "280919",
    "end": "286080"
  },
  {
    "text": "to build fraud detection models we're having very good use cases coming from companies like Sony in media and",
    "start": "286080",
    "end": "292560"
  },
  {
    "text": "entertainment if you're using sucked up to go to the doctor you're probably using a tensor flow model built on top",
    "start": "292560",
    "end": "299490"
  },
  {
    "text": "of AWS in the backend another example of a customer that I liked holding now the",
    "start": "299490",
    "end": "305400"
  },
  {
    "text": "pretty recent one is Siemens we're using tensor flow and sage maker they were able to bring the computational time",
    "start": "305400",
    "end": "312150"
  },
  {
    "text": "that they use to basically build machine learning models from 12 hours to 30 seconds it's really incredible and in",
    "start": "312150",
    "end": "320130"
  },
  {
    "text": "sports analytics as well we're seeing a lot of movement from folks like the NFL from folks like Formula One handling",
    "start": "320130",
    "end": "327300"
  },
  {
    "text": "terabytes and terabytes of data piping that over to the cloud and then using that to provide a different experience",
    "start": "327300",
    "end": "333870"
  },
  {
    "text": "that the folks that are watching the games or the folks that are watching the races are having simply because of the",
    "start": "333870",
    "end": "340319"
  },
  {
    "text": "opportunity of deep learning or AI and the combination of that and in streaming",
    "start": "340319",
    "end": "346259"
  },
  {
    "text": "analytics so our approach at AWS is very simple well first of all with customer",
    "start": "346259",
    "end": "352199"
  },
  {
    "text": "focus 90 to 95 percent of our roadmap is driven by our customers and then secondly we're very aggressive at the",
    "start": "352199",
    "end": "358949"
  },
  {
    "text": "pace at which we do in vein right so we aggressively listen to our customers and then we go deeper and deeper in terms of",
    "start": "358949",
    "end": "365880"
  },
  {
    "text": "breadth and depth to make sure that we talk to everything that would build is speaking directly to our customers",
    "start": "365880",
    "end": "372509"
  },
  {
    "text": "demand and of course with that we what we've observed what we've observed is that customers are coming to us and",
    "start": "372509",
    "end": "378810"
  },
  {
    "text": "asking us to provide fighters for example as a deep learning framework it doesn't matter whether Amazon created",
    "start": "378810",
    "end": "385289"
  },
  {
    "text": "that are not in the case of fighters for example we've worked with Facebook to make sure that title which is optimized",
    "start": "385289",
    "end": "390389"
  },
  {
    "text": "for the cloud and running on AWS and of course we secure that and we inject research and development in everything",
    "start": "390389",
    "end": "396270"
  },
  {
    "text": "that we build if you look at the word of AI today typically you have developers partnering",
    "start": "396270",
    "end": "403139"
  },
  {
    "text": "with data scientists in order to build real-time applications where you get a developers or a DevOps person that is",
    "start": "403139",
    "end": "410460"
  },
  {
    "text": "getting essentially the build of quantities or the requirements that a",
    "start": "410460",
    "end": "415590"
  },
  {
    "text": "data scientist has in order to put the real product in production and what I",
    "start": "415590",
    "end": "421590"
  },
  {
    "text": "want to challenge you to think about or what I want to get all of us who think about today is the whole concept that",
    "start": "421590",
    "end": "427560"
  },
  {
    "text": "are packaged into AI driven development and by a are driven development I mean a",
    "start": "427560",
    "end": "433080"
  },
  {
    "text": "combination of bringing AI development tools together with algorithms and",
    "start": "433080",
    "end": "439819"
  },
  {
    "text": "end-to-end machine learning platforms and overall machine learning models and",
    "start": "439819",
    "end": "445590"
  },
  {
    "text": "templates combined all together in some form of workflow a process that is",
    "start": "445590",
    "end": "451500"
  },
  {
    "text": "captured by a single platform and that's the opportunity that we have today the",
    "start": "451500",
    "end": "456539"
  },
  {
    "text": "opportunity that we have today is to package all the best practices in terms of platform automation in terms of model",
    "start": "456539",
    "end": "463379"
  },
  {
    "text": "and templating and packaging SDKs and libraries and examples and everything that developers have to use on a day to",
    "start": "463379",
    "end": "470009"
  },
  {
    "text": "day basis in a single platform and of course our Odom's as well so that's what",
    "start": "470009",
    "end": "476219"
  },
  {
    "text": "we built sage maker and th maker is essentially a suit of platforms and services capabilities that enable",
    "start": "476219",
    "end": "483750"
  },
  {
    "text": "machine learning developers and knitter science is to build trained tuned and deploy machine learning models every day",
    "start": "483750",
    "end": "490469"
  },
  {
    "text": "who here is not familiar with sage maker ok just a few people perfect then we",
    "start": "490469",
    "end": "497340"
  },
  {
    "text": "don't have to get into that so it's H maker you can have Python alongside many other deep learning frameworks as well",
    "start": "497340",
    "end": "503340"
  },
  {
    "text": "as the infrastructure that comes around with it and yeah and some higher level",
    "start": "503340",
    "end": "509810"
  },
  {
    "text": "capabilities like an integration with the deep lense device which is a developer first camera",
    "start": "509810",
    "end": "515190"
  },
  {
    "text": "that makes it possible to deploy machine learning models on the field and all of",
    "start": "515190",
    "end": "520560"
  },
  {
    "text": "that is available behind an API so if you think about Amazon sage maker it's really that environment that template",
    "start": "520560",
    "end": "527430"
  },
  {
    "text": "Isis and package is a capability to spin up infrastructure that comes pre-configured with all these machine",
    "start": "527430",
    "end": "533910"
  },
  {
    "text": "learning and learning frameworks including pythons which is a focus of a conversation today and then builds that end-to-end machine",
    "start": "533910",
    "end": "541120"
  },
  {
    "text": "learning workflow behind an API and if you pay attention tomorrow and day after",
    "start": "541120",
    "end": "547030"
  },
  {
    "text": "tomorrow you might hear much more capabilities that are coming to the company's age maker so digging deeper a",
    "start": "547030",
    "end": "554380"
  },
  {
    "text": "little bit into that so sage maker has this environment that enables data scientists to build machine learning",
    "start": "554380",
    "end": "559930"
  },
  {
    "text": "models so Jupiter notebooks as a service you guys heard about that I'm not gonna get into the details the second thing it",
    "start": "559930",
    "end": "565900"
  },
  {
    "text": "provides is a training environment which is again available behind an API in a managed platform to just spin up machine",
    "start": "565900",
    "end": "572470"
  },
  {
    "text": "learning trading jobs and then process them a scale including hyper parameter optimization and speaking of hyper",
    "start": "572470",
    "end": "578410"
  },
  {
    "text": "parameter optimization the difference between 92 percent accurate model and a",
    "start": "578410",
    "end": "584230"
  },
  {
    "text": "95 96 percent accurate model is probably how you tweak the exact same model and how does a platform enable you to get",
    "start": "584230",
    "end": "591700"
  },
  {
    "text": "that capability available and the last thing about the platform is the ability",
    "start": "591700",
    "end": "597610"
  },
  {
    "text": "to deploy machine learning models at scale and of course all of that is packaged with metadata capability",
    "start": "597610",
    "end": "605290"
  },
  {
    "text": "pay-as-you-go and compliance and end-to-end VPC and encryption support",
    "start": "605290",
    "end": "611140"
  },
  {
    "text": "now the reason I take us through this process is because the platform was",
    "start": "611140",
    "end": "616960"
  },
  {
    "text": "built and designed to work with deep learning frameworks like Pi coach in a way that is seamless in the way that",
    "start": "616960",
    "end": "623290"
  },
  {
    "text": "makes the life of the developer and data scientist easier and that's what we're gonna jump into right now so to dig into",
    "start": "623290",
    "end": "632760"
  },
  {
    "start": "627000",
    "end": "951000"
  },
  {
    "text": "the PI torch experience on top of a deep learning on top of the stage make a",
    "start": "632760",
    "end": "638470"
  },
  {
    "text": "platform I decided to walk you through their anatomy what I call the anatomy of a deep learning framework on top of",
    "start": "638470",
    "end": "644620"
  },
  {
    "text": "Amazon tej maker if you look at the developer's experience well it usually",
    "start": "644620",
    "end": "650230"
  },
  {
    "text": "starts either on the developers laptop and by developer here I mean data scientist developer AI researcher pretty",
    "start": "650230",
    "end": "657250"
  },
  {
    "text": "much anyone that has something to do with a machine learning or deep learning framework so they would start with the",
    "start": "657250",
    "end": "664360"
  },
  {
    "text": "laptop or Jupiter notebook somewhere and then when they start acting with Amazon sage maker or on AWS",
    "start": "664360",
    "end": "671209"
  },
  {
    "text": "cloud they have access to the three core capabilities of a platform that I pulled",
    "start": "671209",
    "end": "676520"
  },
  {
    "text": "out earlier the notebook instance the training and tuning capability and so the the radish or the arrows over there",
    "start": "676520",
    "end": "685310"
  },
  {
    "text": "represent the control capabilities that the developer or the data scientist has can either spin up a jupiter notebook",
    "start": "685310",
    "end": "692720"
  },
  {
    "text": "environment or model training environment or model hosting environment with the controls of encryption and the",
    "start": "692720",
    "end": "698839"
  },
  {
    "text": "control of access control and all these things that are provided by sister services and the relationship with a",
    "start": "698839",
    "end": "704690"
  },
  {
    "text": "cloud storage is provided with Amazon s3 which is an infinite infinitely scalable cloud storage capability making it",
    "start": "704690",
    "end": "711680"
  },
  {
    "text": "possible for developers to essentially store data and then seamlessly communicate with a platform and extract",
    "start": "711680",
    "end": "717110"
  },
  {
    "text": "that and so this is where PI quartz and sage maker and other deep learning frameworks come in where the",
    "start": "717110",
    "end": "723589"
  },
  {
    "text": "relationship of sage maker with Amazon ECR makes it possible that we can store",
    "start": "723589",
    "end": "729440"
  },
  {
    "text": "our gotham's in the form of docker containers and then use this docker containers to kick off what we call",
    "start": "729440",
    "end": "735140"
  },
  {
    "text": "machine learning training jobs or tuning jobs all these are the capabilities in that environment and of course we need",
    "start": "735140",
    "end": "741620"
  },
  {
    "text": "we use AWS carwash logs to store the logs externally so that we don't have to maintain that maintain that",
    "start": "741620",
    "end": "747950"
  },
  {
    "text": "infrastructure running at all time and it is possible for you to run a training job and then kill it off at the end of",
    "start": "747950",
    "end": "754130"
  },
  {
    "text": "the training job execution and so if we want to dig deeper slightly into the",
    "start": "754130",
    "end": "759290"
  },
  {
    "text": "jupiter notebook instance pretty simple it's a machine that is attached to an EBS volume and a number of jupiter",
    "start": "759290",
    "end": "764899"
  },
  {
    "text": "notebook examples there to get ramped up and get started faster and there's a lot of high thoughts related examples there",
    "start": "764899",
    "end": "770990"
  },
  {
    "text": "as well to get started now from a model training perspective it becomes interesting so this is an informal",
    "start": "770990",
    "end": "777440"
  },
  {
    "text": "cluster that spins up a game with a Python container and then it's attached to an EBS volume in which we download",
    "start": "777440",
    "end": "784820"
  },
  {
    "text": "the data from the cloud storage with the possibility of streaming the data in directly to the machines to start",
    "start": "784820",
    "end": "790130"
  },
  {
    "text": "training the models and then we use that to train the machine learning model and then after we're done you have the",
    "start": "790130",
    "end": "796100"
  },
  {
    "text": "possibility to host that either in a managed real time and",
    "start": "796100",
    "end": "802010"
  },
  {
    "text": "environment or in a batch inference endpoint environment so I believe you",
    "start": "802010",
    "end": "807350"
  },
  {
    "text": "familiar with that now uh the last thing as far as the workflow and the infrastructure is concerned is that you",
    "start": "807350",
    "end": "814040"
  },
  {
    "text": "can consume your machine learning model using it'll be lambda and API gateway so I hope from here you see how HT maker",
    "start": "814040",
    "end": "820580"
  },
  {
    "text": "fits in the middle of the execution of basically building training and",
    "start": "820580",
    "end": "826160"
  },
  {
    "text": "deploying machine learning models as scaled now where we want to focus our attention now is what happens within the",
    "start": "826160",
    "end": "834380"
  },
  {
    "text": "container once a Python container for example is pulled in so the first thing",
    "start": "834380",
    "end": "840680"
  },
  {
    "text": "to note within that environment is a data agent that exists in stage maker basically the data agents role is to",
    "start": "840680",
    "end": "846470"
  },
  {
    "text": "communicate with the cloud storage and then go fetch the data from there on behalf of of the customer so what",
    "start": "846470",
    "end": "853340"
  },
  {
    "text": "happens is that when a training job comes on the data is handed over to the docker containers by the data agent the",
    "start": "853340",
    "end": "860210"
  },
  {
    "text": "other thing is the love metric agents that runs within the container that can again you know handle the logs if you",
    "start": "860210",
    "end": "866150"
  },
  {
    "text": "have multiple machines that are working together different deep learning frameworks it's possible to go get these",
    "start": "866150",
    "end": "871550"
  },
  {
    "text": "logs from all these machines aggregate them and push them to the class storage and if you start going up the stack then",
    "start": "871550",
    "end": "878090"
  },
  {
    "text": "you have things like the distributed and included GPU capabilities that are",
    "start": "878090",
    "end": "883460"
  },
  {
    "text": "installed there if in case are you using a deep learning a GPU based machine and we start going up the",
    "start": "883460",
    "end": "890900"
  },
  {
    "text": "stack from there then you have the deep learning libraries with the deep learning framework and additional",
    "start": "890900",
    "end": "896810"
  },
  {
    "text": "libraries that are related to that and then you go further up the stack you have the sage maker Python SDK and the",
    "start": "896810",
    "end": "902870"
  },
  {
    "text": "sage maker Python SDK is very very powerful it's actually the core of the",
    "start": "902870",
    "end": "908480"
  },
  {
    "text": "best experience or deep learning practitioner can have on Amazon changemaker today it makes a lot of",
    "start": "908480",
    "end": "913970"
  },
  {
    "text": "thing is things easier things like spinning up their environment configuring that handling hyper",
    "start": "913970",
    "end": "919220"
  },
  {
    "text": "parameters and all these things I'll get into some of the details and then at the very top of the stack you get the",
    "start": "919220",
    "end": "926270"
  },
  {
    "text": "algorithm the algorithm is now what you would write as a script for example if you would want to create a deep learning",
    "start": "926270",
    "end": "932890"
  },
  {
    "text": "distributive a job with PI porridge wouldn't have to write the GPU code you wouldn't have to write the data handling",
    "start": "932890",
    "end": "939820"
  },
  {
    "text": "capabilities the data is handed over to you by the data agent you wouldn't have to worry about where to find a different",
    "start": "939820",
    "end": "945640"
  },
  {
    "text": "log files because the logs are handled by the log agent and so on and so forth",
    "start": "945640",
    "end": "950760"
  },
  {
    "text": "now if you use the sage maker SDK and you do importation maker you get direct",
    "start": "950760",
    "end": "957730"
  },
  {
    "start": "951000",
    "end": "1392000"
  },
  {
    "text": "access to a decent number of capabilities that we are going to jump into right now",
    "start": "957730",
    "end": "962860"
  },
  {
    "text": "Oh something that I have actually done",
    "start": "962860",
    "end": "968700"
  },
  {
    "text": "so I figured before continue I figured I",
    "start": "969029",
    "end": "975459"
  },
  {
    "text": "could share my screen and then get the job started let me run the screen",
    "start": "975459",
    "end": "986459"
  },
  {
    "text": "you seeing my screen is the resolution okay it's pretty small",
    "start": "989840",
    "end": "1000230"
  },
  {
    "text": "is it big enough okay so this is essentially the example that we're going",
    "start": "1007960",
    "end": "1013960"
  },
  {
    "text": "to go through as a demo sometime later but I wanted to make sure that I keep",
    "start": "1013960",
    "end": "1019180"
  },
  {
    "text": "the job off and then it starts training even though even though even though I",
    "start": "1019180",
    "end": "1026439"
  },
  {
    "text": "ran it already and I will show you the results immediately but at least you",
    "start": "1026440",
    "end": "1031600"
  },
  {
    "text": "could see that I'm kicking off as a shoemaker job from my own laptop from my own vehicle environment and then I'll",
    "start": "1031600",
    "end": "1039670"
  },
  {
    "text": "walk you through the details here and what does that mean and so on and so forth if it lets me oh I'll kick up",
    "start": "1039670",
    "end": "1046569"
  },
  {
    "text": "another job so that we can see there",
    "start": "1046570",
    "end": "1051690"
  },
  {
    "text": "okay perfect now back to the slides okay",
    "start": "1057429",
    "end": "1063919"
  },
  {
    "text": "so once you start digging into the sage maker Python SDK things look like this",
    "start": "1063919",
    "end": "1070789"
  },
  {
    "text": "we're familiar with the stack already the anatomy of a typical piece of code",
    "start": "1070789",
    "end": "1077059"
  },
  {
    "text": "you're leveraging the sage Maker Python SDK makes it so easy to get the job started and I'm gonna walk you through",
    "start": "1077059",
    "end": "1083750"
  },
  {
    "text": "what you need to do what does that mean and so on and so forth so of course it starts it starts by importing sage maker",
    "start": "1083750",
    "end": "1091669"
  },
  {
    "text": "which is a Python SDK that gives you access to the PI torch container and so when you do import sage makeup I torch",
    "start": "1091669",
    "end": "1098450"
  },
  {
    "text": "and that gives you access to a few classes one of them is PI torch which is basically the estimator who here is",
    "start": "1098450",
    "end": "1104900"
  },
  {
    "text": "familiar with scikit-learn okay perfect a good deal of people so you can think",
    "start": "1104900",
    "end": "1110240"
  },
  {
    "text": "of the sage maker estimator as a weak analogy of scikit-learn where you can essentially have an",
    "start": "1110240",
    "end": "1116720"
  },
  {
    "text": "environment and leveraging that environment you have a context and then through that context if you do if you do",
    "start": "1116720",
    "end": "1123350"
  },
  {
    "text": "a fit or fit deploy you have the capability of training a machine learning model given that context so the",
    "start": "1123350",
    "end": "1129890"
  },
  {
    "text": "experience is almost similar when you do import the stage makeup I poured estimator it gives you the capability of",
    "start": "1129890",
    "end": "1136130"
  },
  {
    "text": "specifying your main script for example the script that you want to use for training your machine learning model and",
    "start": "1136130",
    "end": "1142429"
  },
  {
    "text": "we alongside other parameters things like the training instance type the one that you want to use the training",
    "start": "1142429",
    "end": "1148340"
  },
  {
    "text": "instance count and a framework version in this case I specify pythons 1.0 the",
    "start": "1148340",
    "end": "1153799"
  },
  {
    "text": "the development branch right now the face book is is pushing to to get to to",
    "start": "1153799",
    "end": "1160190"
  },
  {
    "text": "release candidate and then you also have to specify the hyper parameters now if",
    "start": "1160190",
    "end": "1166100"
  },
  {
    "text": "you look at this carefully you haven't specified the way that the data was",
    "start": "1166100",
    "end": "1171320"
  },
  {
    "text": "going to be distributed to the different machines you haven't specified the way that the logs were going to get handled",
    "start": "1171320",
    "end": "1176570"
  },
  {
    "text": "you haven't specified all of these distributed titled mechanisms and then",
    "start": "1176570",
    "end": "1181700"
  },
  {
    "text": "those are the kind of things that the platform handles in the back end you haven't specified how much data you want",
    "start": "1181700",
    "end": "1187010"
  },
  {
    "text": "to send to one machine or the other sharding is handled matically whether you want to fully replicate the data or you want to send",
    "start": "1187010",
    "end": "1193779"
  },
  {
    "text": "part of the data to a machine or the other so there are some of these backing capabilities that I handled by the",
    "start": "1193779",
    "end": "1199690"
  },
  {
    "text": "platform but it understands PI torch well enough to know that if you want to do this video training with Piper words",
    "start": "1199690",
    "end": "1205990"
  },
  {
    "text": "then you have access to different back-end capabilities as far as disability training is concern and it",
    "start": "1205990",
    "end": "1212110"
  },
  {
    "text": "provides that to you now once you have an estimated object the next thing you need to do is to say hail given my",
    "start": "1212110",
    "end": "1219340"
  },
  {
    "text": "scimitar I want you to fit that on this data set now note here that the data set",
    "start": "1219340",
    "end": "1225429"
  },
  {
    "text": "comes with two in the dictionary with two types of parameters one is the",
    "start": "1225429",
    "end": "1231070"
  },
  {
    "text": "training parameter which is analogous to the training data set and it's pointing",
    "start": "1231070",
    "end": "1236260"
  },
  {
    "text": "to Amazon s3 and the other one is the test what we call channel that is still",
    "start": "1236260",
    "end": "1242139"
  },
  {
    "text": "pointing to Amazon s3 so once you do this what the platform does is okay you",
    "start": "1242139",
    "end": "1247330"
  },
  {
    "text": "want to use PI porridge you've given me this estimator I know what your main function is and I know where your data",
    "start": "1247330",
    "end": "1254049"
  },
  {
    "text": "is so with your permission I'm going to go download that entire data set bring it down to the platform in a specific",
    "start": "1254049",
    "end": "1260409"
  },
  {
    "text": "magic folder that I'm going to make accessible to your deep learning framework and then your deep learning",
    "start": "1260409",
    "end": "1265720"
  },
  {
    "text": "framework and pick that up and leverage the distribution capabilities in the backend that I provide and so once the",
    "start": "1265720",
    "end": "1272590"
  },
  {
    "text": "model is trained the environment also knows where to go pick up the model and",
    "start": "1272590",
    "end": "1277659"
  },
  {
    "text": "then send it back to the cloud storage and where to go pick up the logs and then send it back to the cloud locks",
    "start": "1277659",
    "end": "1283149"
  },
  {
    "text": "capabilities and so the next thing that is left for you to do is to essentially deploy the model in the production",
    "start": "1283149",
    "end": "1289690"
  },
  {
    "text": "environment so with de piel or y6 letters except specifically you can",
    "start": "1289690",
    "end": "1297159"
  },
  {
    "text": "instruct and summon sage maker and say hey bring me a machine of this type mlc",
    "start": "1297159",
    "end": "1302169"
  },
  {
    "text": "for extra large for example and then I want three of these machines and then within these three machines I want you",
    "start": "1302169",
    "end": "1308529"
  },
  {
    "text": "to host the REST API and then host my model there for me and that's the entire that's the entire story so if you take a",
    "start": "1308529",
    "end": "1315340"
  },
  {
    "text": "step back and then look at what it means to kicking up a machine learning training job with three computers in",
    "start": "1315340",
    "end": "1322659"
  },
  {
    "text": "that environment it looks like this you have access to your data again and then the data agents in these",
    "start": "1322659",
    "end": "1327970"
  },
  {
    "text": "three machines are all going into the cloud storage and fetching the logs sorry fetching the data back into into",
    "start": "1327970",
    "end": "1334960"
  },
  {
    "text": "the machine and then so it puts that into a magic folder called up to ml data",
    "start": "1334960",
    "end": "1340480"
  },
  {
    "text": "and then at the distribution layer the platform understands how to make these",
    "start": "1340480",
    "end": "1346870"
  },
  {
    "text": "due to pythons disability capability is working together in order to share things like checkpoints in order to",
    "start": "1346870",
    "end": "1353110"
  },
  {
    "text": "share things like global steps in order to share things like that are required for running a distributed training job",
    "start": "1353110",
    "end": "1358480"
  },
  {
    "text": "and then the next thing that we're going to get to talk about in details right now is the experience so yeah after the",
    "start": "1358480",
    "end": "1367210"
  },
  {
    "text": "model is done training the data is pushed the model is pushed back to the cloud storage and then the logs are also",
    "start": "1367210",
    "end": "1373210"
  },
  {
    "text": "pushed to the to the cloud logs and so we're going up to stack into what is",
    "start": "1373210",
    "end": "1378970"
  },
  {
    "text": "happening now into the deep learning capabilities and what is pythons and what are the different benefits that you",
    "start": "1378970",
    "end": "1384010"
  },
  {
    "text": "have once you're using Patras and for that I like to have joke giving us some of these details cool thank you Dan",
    "start": "1384010",
    "end": "1391740"
  },
  {
    "text": "okay so I'm not Jeff Smith but Jeff Smith is my colleague here won't see a",
    "start": "1391740",
    "end": "1396760"
  },
  {
    "start": "1392000",
    "end": "1449000"
  },
  {
    "text": "repeat of this talk he's gonna come on Friday and I think give it about 10 a.m. but I am Joe Spisak product manager for",
    "start": "1396760",
    "end": "1404110"
  },
  {
    "text": "face book AI platform so that includes PI torch as well as another project called onyx and then our kind of broader open",
    "start": "1404110",
    "end": "1411460"
  },
  {
    "text": "source strategy as with respect to AI one thing that's really cool is like one",
    "start": "1411460",
    "end": "1419050"
  },
  {
    "text": "of the reasons why PI torch is so popular is because of its you know customer obsessed nature like the the",
    "start": "1419050",
    "end": "1425440"
  },
  {
    "text": "customers in this case our researchers and really that's over the last new year or year and a half year has shifted more",
    "start": "1425440",
    "end": "1431590"
  },
  {
    "text": "towards being a production framework so all those researchers that have been doing great things for the framework are now wanting to put ship those into to",
    "start": "1431590",
    "end": "1438310"
  },
  {
    "text": "large-scale production and so that's kind of the story I'll talk about here you know as a project it's only maybe a",
    "start": "1438310",
    "end": "1444700"
  },
  {
    "text": "little less than two years old so it was started in roughly early 2017 so let's",
    "start": "1444700",
    "end": "1450970"
  },
  {
    "start": "1449000",
    "end": "1598000"
  },
  {
    "text": "start with the higher level of why actually Facebook cares about pie tourism and the thing we use it for so of course things like",
    "start": "1450970",
    "end": "1458500"
  },
  {
    "text": "ranking algorithms for recommendations if you ever been on on messenger and",
    "start": "1458500",
    "end": "1465429"
  },
  {
    "text": "you've had a recommendation from a from someone or been chatting in a different",
    "start": "1465429",
    "end": "1470740"
  },
  {
    "text": "language if you have friends that's because language doesn't like to chat we do the all of these translations in real",
    "start": "1470740",
    "end": "1475990"
  },
  {
    "text": "time talk more about translations later on and where Facebook is invested there and and and the code that we've",
    "start": "1475990",
    "end": "1483340"
  },
  {
    "text": "open-sourced in collaboration actually with with Amazon it's also things like",
    "start": "1483340",
    "end": "1488789"
  },
  {
    "text": "accessibility so if I'm for example someone who can't see very well I may be",
    "start": "1488789",
    "end": "1495010"
  },
  {
    "text": "blind or so on you can actually have accessibility features where it can",
    "start": "1495010",
    "end": "1500529"
  },
  {
    "text": "actually do things like text-to-speech based on the content within images and",
    "start": "1500529",
    "end": "1505929"
  },
  {
    "text": "that's been really powerful for for for the viewing impaired and using Facebook",
    "start": "1505929",
    "end": "1512440"
  },
  {
    "text": "things like box and assistance so we have you know em and that's obviously powered by AI and things like generating",
    "start": "1512440",
    "end": "1522309"
  },
  {
    "text": "content so when you upload your your movies onto Facebook we have algorithms that we'll go through and basically",
    "start": "1522309",
    "end": "1528909"
  },
  {
    "text": "generate a preview automatically for you based on you know a number of features within the within your video air effect",
    "start": "1528909",
    "end": "1537460"
  },
  {
    "text": "so has anyone in f8 this year okay no whatever every it's very small so it's a",
    "start": "1537460",
    "end": "1543549"
  },
  {
    "text": "it's Facebook's annual conference but we with our mobile app we're able to generate you know AR effects instead of",
    "start": "1543549",
    "end": "1550419"
  },
  {
    "text": "having kind of this static flat map you just overlay your phone it gives you this visual effect which is really",
    "start": "1550419",
    "end": "1556360"
  },
  {
    "text": "powerful and it kind of gives you a more immersive experience and of course VR hardware so we have oculus as part of",
    "start": "1556360",
    "end": "1563260"
  },
  {
    "text": "the family of platforms within Facebook and AI is a big big part of that so all",
    "start": "1563260",
    "end": "1568809"
  },
  {
    "text": "hand tracking is machine learning based you know things like lip sync movements",
    "start": "1568809",
    "end": "1574659"
  },
  {
    "text": "are all tracked and using machine learning and of course there's a lot of",
    "start": "1574659",
    "end": "1580929"
  },
  {
    "text": "bad things that happen on our platform so things like share baiting which we try and hope you never ever see but",
    "start": "1580929",
    "end": "1586269"
  },
  {
    "text": "sometimes you see it that is hopefully removed ahead of time using machine learning we can tag that remove",
    "start": "1586269",
    "end": "1593150"
  },
  {
    "text": "it also things like suicide prevention that we do within our platform as well",
    "start": "1593150",
    "end": "1598330"
  },
  {
    "text": "and all up we do you know over 300 trillion predictions a day so we run a",
    "start": "1598330",
    "end": "1604490"
  },
  {
    "text": "really really large scale so we actually we need a framework that can basically take a lot of this research that's",
    "start": "1604490",
    "end": "1609650"
  },
  {
    "text": "cutting edge work that we're doing and scale it up into to large-scale production very very quickly you can",
    "start": "1609650",
    "end": "1615080"
  },
  {
    "text": "imagine we take a lot of the data from some of those previous applications we want to train that on algorithms and",
    "start": "1615080",
    "end": "1621530"
  },
  {
    "text": "then get that deployed very very quickly because you know that type of adversarial problem say like share baiting the data has a time value so we",
    "start": "1621530",
    "end": "1629120"
  },
  {
    "text": "want to deploy that very quickly we also deploy on phones so instead of sending",
    "start": "1629120",
    "end": "1635330"
  },
  {
    "text": "data for example from your phone over to our infrastructure you can actually run locally and do predictions so we have a",
    "start": "1635330",
    "end": "1642350"
  },
  {
    "text": "runtime as part of always previously called cafe to runs locally out over a billion phones and it's very compact so",
    "start": "1642350",
    "end": "1649370"
  },
  {
    "text": "things like at the AI camera things like style transfer you know augmented",
    "start": "1649370",
    "end": "1655370"
  },
  {
    "text": "reality effects all that is actually using deep learning and running actually locally on your phone and we actually",
    "start": "1655370",
    "end": "1662960"
  },
  {
    "text": "have a team that makes sure that even if you're using a fairly low end say Android phone all the way up to so the",
    "start": "1662960",
    "end": "1668660"
  },
  {
    "text": "high end iPhone it's gonna work pretty well for you and so one thing that that",
    "start": "1668660",
    "end": "1675860"
  },
  {
    "start": "1673000",
    "end": "1771000"
  },
  {
    "text": "we take is a really a full stack approach and so we we talk about the research we do we talk about the",
    "start": "1675860",
    "end": "1681710"
  },
  {
    "text": "products we we develop we actually open source all of this as well so all the",
    "start": "1681710",
    "end": "1687320"
  },
  {
    "text": "way down from the hardware so we do things like open hardware designs so if",
    "start": "1687320",
    "end": "1692480"
  },
  {
    "text": "anyone's heard of OCP open compute platform has anyone heard of P okay good so a few folks so basically open source",
    "start": "1692480",
    "end": "1698930"
  },
  {
    "text": "all of our design for our hardware we have a kind of a consortium around that",
    "start": "1698930",
    "end": "1703960"
  },
  {
    "text": "and we do fleet wide metrics and benchmarking Zoar we're constantly looking at how is our fleet of servers",
    "start": "1703960",
    "end": "1710000"
  },
  {
    "text": "doing how efficient they are etc we have a number of compiler projects so you",
    "start": "1710000",
    "end": "1717680"
  },
  {
    "text": "know how do you generate the best performance based on that hardware of course Patrick is our are chosen framework and we use",
    "start": "1717680",
    "end": "1723710"
  },
  {
    "text": "that across a number of workloads and then libraries so on top of PI torch so",
    "start": "1723710",
    "end": "1729260"
  },
  {
    "text": "there's a number of different libraries like the one I'll talk about here in a second run translation that are built on",
    "start": "1729260",
    "end": "1735140"
  },
  {
    "text": "top of hi gorge so things like detect Ron which is probably the the cutting edge most cutting-edge computer vision",
    "start": "1735140",
    "end": "1741740"
  },
  {
    "text": "suite of algorithms it's out there it's open source the models are available it runs extremely fast for different",
    "start": "1741740",
    "end": "1748490"
  },
  {
    "text": "things like object detection segmentation etc models we open source a",
    "start": "1748490",
    "end": "1754100"
  },
  {
    "text": "ton of models based on opens to open datasets and then of course datasets themselves so basically we do everything",
    "start": "1754100",
    "end": "1762650"
  },
  {
    "text": "at every level of the stack but then we also open source or open up all the things that we do so it's a very unique",
    "start": "1762650",
    "end": "1767720"
  },
  {
    "text": "place Facebook is in this regard so I was chatting with some folks before the",
    "start": "1767720",
    "end": "1774740"
  },
  {
    "start": "1771000",
    "end": "2145000"
  },
  {
    "text": "the talk here and a few folks hadn't heard of what haven't heard pi torch so I didn't really know what PI torch was",
    "start": "1774740",
    "end": "1780200"
  },
  {
    "text": "so I figured given you know dance talk is jumping right into you know how you use it a sage maker I figured I'd dive a",
    "start": "1780200",
    "end": "1786560"
  },
  {
    "text": "little bit deeper into the code and show you like what is the purpose of a deep learning framework like how does it help",
    "start": "1786560",
    "end": "1792350"
  },
  {
    "text": "you but first it's you know it's popular so pie chart one to give you an idea is",
    "start": "1792350",
    "end": "1798560"
  },
  {
    "text": "it's the number two fastest-growing open-source project on github to give",
    "start": "1798560",
    "end": "1804470"
  },
  {
    "text": "you an idea so it's a very popular project almost three X number of contributors in the last 12 months so I",
    "start": "1804470",
    "end": "1810620"
  },
  {
    "text": "think the only other more popular project on github was as your Docs which",
    "start": "1810620",
    "end": "1815780"
  },
  {
    "text": "I don't know who's using and contribution to add your Docs but okay but PI sources is it is really really",
    "start": "1815780",
    "end": "1821480"
  },
  {
    "text": "popular I get people come up to me all the time saying I love the project thank you this is amazing",
    "start": "1821480",
    "end": "1828170"
  },
  {
    "text": "and so I pass that on of course the dev team but you know when you look at the the project itself so what is it it's in",
    "start": "1828170",
    "end": "1834380"
  },
  {
    "text": "a lot of ways you can think about a framework as a number of api's and libraries for convenience so if anyone has taken",
    "start": "1834380",
    "end": "1841760"
  },
  {
    "text": "say like Andrew and Steve learning AI class or anything actually that takes",
    "start": "1841760",
    "end": "1848120"
  },
  {
    "text": "you from really from scratch like writing things and say like numpy you'll know that it's pretty painful when you",
    "start": "1848120",
    "end": "1853910"
  },
  {
    "text": "start to implement a lot of these yourself so what a framework really does is gives you a set of really nice api's",
    "start": "1853910",
    "end": "1859440"
  },
  {
    "text": "to do different things and accelerates them on different hardware you know backends and so if you look at",
    "start": "1859440",
    "end": "1865980"
  },
  {
    "text": "some of the api's that are supported and packed which now go into the code here in the in the next slide but things like torch tienen is a suite of api's that",
    "start": "1865980",
    "end": "1874110"
  },
  {
    "text": "allows you to define layers or define groups of layers writing those from",
    "start": "1874110",
    "end": "1879960"
  },
  {
    "text": "scratch would be really painful optimizers so things like SGD or atom those are implemented for you and of",
    "start": "1879960",
    "end": "1885149"
  },
  {
    "text": "course they're open source so you can look at how they're implemented or or they might be calling a library underneath",
    "start": "1885149",
    "end": "1890759"
  },
  {
    "text": "Dayna having you write your own data interrater or data loader from scratch",
    "start": "1890759",
    "end": "1896309"
  },
  {
    "text": "is painful so being able to call simple API and load data is really helpful autograph this is kind of the heart and",
    "start": "1896309",
    "end": "1902669"
  },
  {
    "text": "soul of Pi torch and this allows you to do auto differentiations so when you for",
    "start": "1902669",
    "end": "1908519"
  },
  {
    "text": "example define a tensor I can actually just call you know say like lost out",
    "start": "1908519",
    "end": "1914460"
  },
  {
    "text": "backwards and actually it does an auto differentiation for me writing those derivatives writing the chain role is",
    "start": "1914460",
    "end": "1920159"
  },
  {
    "text": "kind of painful so but you know it works like PI torch do this for you makes life",
    "start": "1920159",
    "end": "1925769"
  },
  {
    "text": "easy torch vision or torch vision gives you nice easily accessible models and",
    "start": "1925769",
    "end": "1931590"
  },
  {
    "text": "data and then of course something that's really new to the framework is what we're calling JIT or just-in-time or",
    "start": "1931590",
    "end": "1936929"
  },
  {
    "text": "really a head of time compiler and this is something we'll talk about later on",
    "start": "1936929",
    "end": "1942720"
  },
  {
    "text": "but really this is the core of how you take your code from say a research exploration mode and refactor it so that",
    "start": "1942720",
    "end": "1948600"
  },
  {
    "text": "you can then take it to the large-scale production and this is actually what we do at Facebook this is how we we take",
    "start": "1948600",
    "end": "1953659"
  },
  {
    "text": "our exploration because not all models are gonna go to production maybe less",
    "start": "1953659",
    "end": "1958740"
  },
  {
    "text": "than 1% probably less than 1% of 1% go into production but the ones we do want",
    "start": "1958740",
    "end": "1964139"
  },
  {
    "text": "to take in production we want to take them gracefully we want to take them frictionless and scale the model so",
    "start": "1964139",
    "end": "1971279"
  },
  {
    "text": "hopefully you can read this code but this is a very this is your canonical amnesty example but it really kind of",
    "start": "1971279",
    "end": "1977879"
  },
  {
    "text": "hits home how easy things get with things like the the libraries themselves so for example n n modules so I'm",
    "start": "1977879",
    "end": "1985590"
  },
  {
    "text": "defining a a very simple network here basically two fully connected layers and you call that",
    "start": "1985590",
    "end": "1992799"
  },
  {
    "text": "torch ten dot linear and I can define you know the parameters around those",
    "start": "1992799",
    "end": "1998140"
  },
  {
    "text": "those layers very simple for me to have to do that manually would be a lot of work I can also call things like",
    "start": "1998140",
    "end": "2005370"
  },
  {
    "text": "nonlinear functions so when you get into the the forward function when I want to actually take a forward propagation of",
    "start": "2005370",
    "end": "2011730"
  },
  {
    "text": "that defined network you know rectified linear units are are kind of the state of they are some",
    "start": "2011730",
    "end": "2017789"
  },
  {
    "text": "variant of rectified linear units are pretty much what are used today dropout that's all implemented for you sigmoid",
    "start": "2017789",
    "end": "2025169"
  },
  {
    "text": "these are all functions that basically if you call torch dot you're going to get that it's it's implemented it might",
    "start": "2025169",
    "end": "2030899"
  },
  {
    "text": "actually be calling something like who DNN or mkl underneath but it's very simple the other cool thing about high",
    "start": "2030899",
    "end": "2037320"
  },
  {
    "text": "torch is something we announced about a month or so ago we announced a C++",
    "start": "2037320",
    "end": "2043049"
  },
  {
    "text": "front-end and you know you can really it's actually kind of hard to tell the difference between the Python and C++ so",
    "start": "2043049",
    "end": "2049530"
  },
  {
    "text": "if you if you look at they're they're very very similar there's a few more colons obviously in the C++ but",
    "start": "2049530",
    "end": "2056310"
  },
  {
    "text": "otherwise you know besides the include statement really there's there's not a lot of difference this is actually",
    "start": "2056310",
    "end": "2061679"
  },
  {
    "text": "empowered a lot of folks inside Facebook as well as a lot of high-performance researchers that you know wanted to",
    "start": "2061679",
    "end": "2067858"
  },
  {
    "text": "squeeze that extra bit of performance out of their framework so you know for example our Starcraft team that competes",
    "start": "2067859",
    "end": "2073710"
  },
  {
    "text": "and competitions with their BOTS their application is largely C++ for them",
    "start": "2073710",
    "end": "2079050"
  },
  {
    "text": "writing this code fits right into their bigger application very straightforward and then when you start to get into the",
    "start": "2079050",
    "end": "2085800"
  },
  {
    "text": "training it's very easy so in this case I'm loading data so I have this nice",
    "start": "2085800",
    "end": "2091669"
  },
  {
    "text": "utility called data loader in this case I'm going to bring in a computer vision",
    "start": "2091669",
    "end": "2099170"
  },
  {
    "text": "a data set for computer vision for M nests so I can just basically call the",
    "start": "2099170",
    "end": "2104820"
  },
  {
    "text": "torch data sets torch vision data sets API I can specify my optimizer in this",
    "start": "2104820",
    "end": "2110849"
  },
  {
    "text": "case stochastic gradient descent very simple and then from here I can basically set the number of epochs and",
    "start": "2110849",
    "end": "2117330"
  },
  {
    "text": "train my model so things like you know actually doing",
    "start": "2117330",
    "end": "2123310"
  },
  {
    "text": "backpropagation is as simple as calling los backwards and it actually goes in and does a backdrop for me and then at",
    "start": "2123310",
    "end": "2130180"
  },
  {
    "text": "the end there I'm just doing a check point based on modulo if there's a remainder or not and you can see the",
    "start": "2130180",
    "end": "2135940"
  },
  {
    "text": "analogous C++ code so it's it's actually very very simple if you had to implement",
    "start": "2135940",
    "end": "2141010"
  },
  {
    "text": "all this yourself in something else it would be quite painful so that's really",
    "start": "2141010",
    "end": "2146770"
  },
  {
    "start": "2145000",
    "end": "2163000"
  },
  {
    "text": "what a framework brings for you so let's let's talk about the the problem of resource production because this is the",
    "start": "2146770",
    "end": "2152260"
  },
  {
    "text": "problem that's near and dear to me it's something that it's actually how I'm judged to Facebook how fast we can get",
    "start": "2152260",
    "end": "2157960"
  },
  {
    "text": "researched into production and how in a production scale and solve some of these problems so if you remember there's this",
    "start": "2157960",
    "end": "2165760"
  },
  {
    "start": "2163000",
    "end": "2228000"
  },
  {
    "text": "project called onyx is everyone heard of Audax so onyx okay a few folks onyx is open neural network exchange this was",
    "start": "2165760",
    "end": "2172000"
  },
  {
    "text": "something we developed actually in partnership with Amazon a little over a year ago and it's a project that's still going it's still got a lot of momentum",
    "start": "2172000",
    "end": "2177790"
  },
  {
    "text": "and we actually use it in large scale today at Facebook for a number of applications translation being one of",
    "start": "2177790",
    "end": "2183340"
  },
  {
    "text": "them we had another framework called cafe 2 which is embedded really deeply into our",
    "start": "2183340",
    "end": "2189010"
  },
  {
    "text": "infrastructure it runs most of our applications today at a pretty large scale and really onyx",
    "start": "2189010",
    "end": "2195370"
  },
  {
    "text": "was the bridge to try and get high torch models which were largely research-based",
    "start": "2195370",
    "end": "2201190"
  },
  {
    "text": "into cafe 2 for large scale inference and so you know onyx was was nice and it",
    "start": "2201190",
    "end": "2208510"
  },
  {
    "text": "really helped us but we actually wanted to move faster and that's why we actually started doing this work around",
    "start": "2208510",
    "end": "2214390"
  },
  {
    "text": "PI torch 1 so how do we prototype avoid the transfer but then deploy all in the",
    "start": "2214390",
    "end": "2220780"
  },
  {
    "text": "same framework that basically became what we call high torch and that's that's really what pi torch one is and",
    "start": "2220780",
    "end": "2228810"
  },
  {
    "text": "so to sum up what pi torch one is in one sentence it's for us a seamless path",
    "start": "2228810",
    "end": "2234730"
  },
  {
    "text": "from AI research to production so all the teams that across Facebook and now we're starting to see external teams",
    "start": "2234730",
    "end": "2241540"
  },
  {
    "text": "different research groups and different companies they're starting to to look at PI torch as a production framework not",
    "start": "2241540",
    "end": "2248050"
  },
  {
    "text": "just something that they can explore and hack on this is a real frame that is gonna skill as well as any but",
    "start": "2248050",
    "end": "2255109"
  },
  {
    "text": "give you that flexibility so I'll have a little bit more into what production actually means so when we say",
    "start": "2255109",
    "end": "2261590"
  },
  {
    "text": "transitioning from research to productions it means in the same environment so that's the seedless part",
    "start": "2261590",
    "end": "2266810"
  },
  {
    "text": "so I'm not having to export a model import a model change environments it's",
    "start": "2266810",
    "end": "2272270"
  },
  {
    "text": "all the same code base and that means things are fully loaded so there's basically we expose things like just",
    "start": "2272270",
    "end": "2280160"
  },
  {
    "text": "torch distributed for distributed training things like you know mobile which we're working on for the future",
    "start": "2280160",
    "end": "2286099"
  },
  {
    "text": "here you know all these API is basically anything for performance and related in scaling is exposed to the user on the",
    "start": "2286099",
    "end": "2292550"
  },
  {
    "text": "front end through Python opt in so flexibility is is basically maintained",
    "start": "2292550",
    "end": "2300580"
  },
  {
    "text": "and you only need to trade basically opt-in in two different things when you",
    "start": "2300580",
    "end": "2307490"
  },
  {
    "text": "need them in other words you pay only for what you really want to use so I can have all the flexibility of Python but",
    "start": "2307490",
    "end": "2314630"
  },
  {
    "text": "when I start to transition into a production mode I start to trade-off that flexibility because I want to be able to scale that model and say some",
    "start": "2314630",
    "end": "2321589"
  },
  {
    "text": "type of C++ serving environment like sage maker and again same environment so",
    "start": "2321589",
    "end": "2328160"
  },
  {
    "text": "it allows me really to refactor my model continuously without having to change environments object basically go and",
    "start": "2328160",
    "end": "2334550"
  },
  {
    "text": "serialize my model imported into another framework do anything like that I actually can just refactor in the same",
    "start": "2334550",
    "end": "2339859"
  },
  {
    "text": "environment so what does production concretely mean so for us at Facebook it",
    "start": "2339859",
    "end": "2346190"
  },
  {
    "start": "2341000",
    "end": "2401000"
  },
  {
    "text": "actually means Hardware efficiency so you know I'm I'm judged on things like",
    "start": "2346190",
    "end": "2351589"
  },
  {
    "text": "how you know how well we're utilizing our infrastructure so whether at CPUs GPUs or custom accelerators you know",
    "start": "2351589",
    "end": "2359119"
  },
  {
    "text": "that either were rebuilding our cells or through other vendors scalability so you",
    "start": "2359119",
    "end": "2365540"
  },
  {
    "text": "know power is expensive so we need to utilize our GPUs and our infrastructure as much as possible so distributed",
    "start": "2365540",
    "end": "2372320"
  },
  {
    "text": "training efficiency becomes really important I'll talk about that with respect to translation in a minute and then cross-platform so how do I serve",
    "start": "2372320",
    "end": "2379460"
  },
  {
    "text": "models in an environment where there's no Python interpreter that's a challenge",
    "start": "2379460",
    "end": "2384820"
  },
  {
    "text": "and you know mobile is a great environment for that so mobile devices in our infrastructure serving Python is",
    "start": "2384820",
    "end": "2391960"
  },
  {
    "text": "pretty much a no no unless we we make an exception for it and it's a",
    "start": "2391960",
    "end": "2397510"
  },
  {
    "text": "time-to-market type of situation so we have this thing called torched yet that",
    "start": "2397510",
    "end": "2403900"
  },
  {
    "start": "2401000",
    "end": "2446000"
  },
  {
    "text": "I talked about a little bit earlier so you know things like experimenting so",
    "start": "2403900",
    "end": "2409210"
  },
  {
    "text": "yeah kind of have your full flexibility of PI torch so think pythonic think and",
    "start": "2409210",
    "end": "2414520"
  },
  {
    "text": "dump I but with GPUs and and high performance you know tensor ops I can then take",
    "start": "2414520",
    "end": "2421530"
  },
  {
    "text": "basically parts of my graph I can extract parts that I care about so things like if I'm going to serve the",
    "start": "2421530",
    "end": "2427750"
  },
  {
    "text": "model I can extract a part of that graph and go and serve that and I can identify that using torch JIT and then of course",
    "start": "2427750",
    "end": "2434530"
  },
  {
    "text": "how do i optimize and deploy so Dan talked about deploying at scale with sage maker how do I take those whole",
    "start": "2434530",
    "end": "2441010"
  },
  {
    "text": "program optimizations and deploy without Python in the environment so one thing",
    "start": "2441010",
    "end": "2448060"
  },
  {
    "text": "that you know when you look at frameworks you know historically had these these eager and static frameworks",
    "start": "2448060",
    "end": "2454900"
  },
  {
    "text": "so when we talk about production you know eager mode has never been something",
    "start": "2454900",
    "end": "2459970"
  },
  {
    "text": "that has been production like you've never been able to take eager mode production models directly into a",
    "start": "2459970",
    "end": "2466600"
  },
  {
    "text": "scaling environment to run those a large-scale difference basically the difference between eager and Static is",
    "start": "2466600",
    "end": "2472480"
  },
  {
    "text": "when I actually defined my model I'm actually defining the graph as I'm defining it so it's a kind of a defined",
    "start": "2472480",
    "end": "2478780"
  },
  {
    "text": "by run environment in the case of a static graph so something like cafe 2 or",
    "start": "2478780",
    "end": "2484210"
  },
  {
    "text": "say a tensorflow type of model I'm actually writing I'm doing kind of a meta programming where",
    "start": "2484210",
    "end": "2492100"
  },
  {
    "text": "I'm actually defining my graph I have to compile that graph and then from there I actually have this kind of static graph",
    "start": "2492100",
    "end": "2498340"
  },
  {
    "text": "which I can do new predictions with and that's what I use for frame friends so",
    "start": "2498340",
    "end": "2503650"
  },
  {
    "text": "they both have a lot of you know pluses and minuses from the eager front end perspective this is actually what",
    "start": "2503650",
    "end": "2510280"
  },
  {
    "start": "2505000",
    "end": "2575000"
  },
  {
    "text": "researchers love research is a dynamic environment I don't know if my idea is",
    "start": "2510280",
    "end": "2515470"
  },
  {
    "text": "going to work or not so I might iterate hundreds thousands of times and I try hyper parameters I might try different layers",
    "start": "2515470",
    "end": "2521160"
  },
  {
    "text": "so they like the idea of having something that allows them to express any idea possible it gets some really",
    "start": "2521160",
    "end": "2530190"
  },
  {
    "text": "innovating thinking about different ideas thinking about different approaches but it's hard to optimize a",
    "start": "2530190",
    "end": "2537069"
  },
  {
    "text": "hard to deploy so that's been always the knock on on eager it's always fun to debug Python but getting that into",
    "start": "2537069",
    "end": "2543339"
  },
  {
    "text": "large-scale production typically not going to happen from a static graph the exact opposite is true so it is easy to",
    "start": "2543339",
    "end": "2551349"
  },
  {
    "text": "optimize I can take a graph it's static rack I can optimize that very very easily I can deploy it but man once that",
    "start": "2551349",
    "end": "2558339"
  },
  {
    "text": "static graph is compiled having to rewrite that and recompile that every",
    "start": "2558339",
    "end": "2563559"
  },
  {
    "text": "single time and debug it I can't use print statements for example or Python debugger it becomes very very hard as a",
    "start": "2563559",
    "end": "2571210"
  },
  {
    "text": "researcher looking to iterate fast and do real-time research so that's",
    "start": "2571210",
    "end": "2577480"
  },
  {
    "start": "2575000",
    "end": "2644000"
  },
  {
    "text": "something that we've we've thought a lot about and something that we've brought with PI torch and and some of the things",
    "start": "2577480",
    "end": "2583119"
  },
  {
    "text": "we're doing with this new PI torch warm platform so again hi torch is your",
    "start": "2583119",
    "end": "2588160"
  },
  {
    "text": "models part of Python program with autographs for generating derivatives",
    "start": "2588160",
    "end": "2593279"
  },
  {
    "text": "it's simple it's debuggable so print statements yeah I can use those it's",
    "start": "2593279",
    "end": "2598720"
  },
  {
    "text": "hackable so I can plug in with other Python libraries so anyone who loves Python should love PI torch but of",
    "start": "2598720",
    "end": "2605259"
  },
  {
    "text": "course it needs Python to run and it's difficult to optimize and paralyze but",
    "start": "2605259",
    "end": "2610980"
  },
  {
    "text": "we've added this thing called script mode and so when you start to think",
    "start": "2610980",
    "end": "2616480"
  },
  {
    "text": "about okay this is a model that is functioning and and meeting the requirements of something I want to",
    "start": "2616480",
    "end": "2621670"
  },
  {
    "text": "actually take into production this is when I start to look at how do I take that how do I script that model or how to trace that model and get that into",
    "start": "2621670",
    "end": "2628900"
  },
  {
    "text": "something that can be deployed well into a production environment so where I basically have no per ton know Python",
    "start": "2628900",
    "end": "2634599"
  },
  {
    "text": "dependency I can optimize it I can start to use other libraries that are more hard-coded and and optimize for serious",
    "start": "2634599",
    "end": "2641950"
  },
  {
    "text": "performance in serious infrastructure like we have and that's really what we we have as far as high torch JIT so this",
    "start": "2641950",
    "end": "2648940"
  },
  {
    "start": "2644000",
    "end": "2752000"
  },
  {
    "text": "is what we're betting big time on we're basically this tool allowing you to have",
    "start": "2648940",
    "end": "2655420"
  },
  {
    "text": "the same environment same research development environment would allow you to gradually refactor your code using a",
    "start": "2655420",
    "end": "2662559"
  },
  {
    "text": "couple of rappers or Ritalin called decorators and there's a bunch of tutorials online if you go to Pytor chat",
    "start": "2662559",
    "end": "2668680"
  },
  {
    "text": "or you can check those out but really there's there's two that matter and that's really the the script decorator",
    "start": "2668680",
    "end": "2675339"
  },
  {
    "text": "and the trace decorator and they're both handy and it can be used interoperable",
    "start": "2675339",
    "end": "2680619"
  },
  {
    "text": "so you can use them both together but at a high level what trace does is actually runs dummy data through your network it",
    "start": "2680619",
    "end": "2687760"
  },
  {
    "text": "actually generates a graph and so it'll actually trace a graph out of something",
    "start": "2687760",
    "end": "2692800"
  },
  {
    "text": "that is purely imperative as I'm writing it you actually generate the graph for me in real time it's very cool it's this",
    "start": "2692800",
    "end": "2699369"
  },
  {
    "text": "is very handy and very good for feed-forward networks computer vision CNN's works really really well once you",
    "start": "2699369",
    "end": "2704920"
  },
  {
    "text": "starting to get into things like you know language models that use control flow so I'll talk about in a second the",
    "start": "2704920",
    "end": "2712540"
  },
  {
    "text": "translation work so control flow is nasty it's data dependent in some cases",
    "start": "2712540",
    "end": "2717750"
  },
  {
    "text": "and so basically what we've done is created also a script decorator and what",
    "start": "2717750",
    "end": "2722950"
  },
  {
    "text": "this does is actually constrains you into a subset of a Python looking language it's really a domain-specific",
    "start": "2722950",
    "end": "2729040"
  },
  {
    "text": "language a DSL that does not depend on a Python interpreter and so when you kind",
    "start": "2729040",
    "end": "2735609"
  },
  {
    "text": "of give a get an idea of what you want to do you can start to use the the script decorator control flow will be",
    "start": "2735609",
    "end": "2740770"
  },
  {
    "text": "preserved and it allows you then to save and load that model into a C++ environment so all of a sudden you're",
    "start": "2740770",
    "end": "2747040"
  },
  {
    "text": "free of Python and you can actually run a really large scale very efficiently so",
    "start": "2747040",
    "end": "2752280"
  },
  {
    "text": "I'll talk briefly about translation and stage maker so this is a collaboration",
    "start": "2752280",
    "end": "2757630"
  },
  {
    "text": "between Amazon and Facebook so very briefly translation at Facebook has a",
    "start": "2757630",
    "end": "2763480"
  },
  {
    "text": "history we started out using Bing Translate way back in the day in 2013 we started bringing the all that",
    "start": "2763480",
    "end": "2770559"
  },
  {
    "text": "in-house in 2015 and started using your own machine translation in 2016 and from",
    "start": "2770559",
    "end": "2776109"
  },
  {
    "text": "then on it's been basically all nmt and it's been",
    "start": "2776109",
    "end": "2781210"
  },
  {
    "start": "2781000",
    "end": "2815000"
  },
  {
    "text": "very good so you know our progress has been good I think we've we're now at almost six billion translations a day",
    "start": "2781210",
    "end": "2789480"
  },
  {
    "text": "this is slow graphic and it's used sorry",
    "start": "2789480",
    "end": "2795790"
  },
  {
    "text": "it's used in things like social recommendations engagement bade suicide prevention and a lot of other applications and you can see you know",
    "start": "2795790",
    "end": "2803819"
  },
  {
    "text": "kind of in in action here so this is one one of the research scientists in our",
    "start": "2803819",
    "end": "2808900"
  },
  {
    "text": "translation team and his kids talking about the fact that they love chocolate ice cream and that's translated in",
    "start": "2808900",
    "end": "2814930"
  },
  {
    "text": "real-time and one of the things we talked about previously was performance and distribute training I think the one",
    "start": "2814930",
    "end": "2820300"
  },
  {
    "start": "2815000",
    "end": "2864000"
  },
  {
    "text": "of the gentlemen over here I'm asked me about that so as part of patchworks 1 we support distributed training and then of",
    "start": "2820300",
    "end": "2826720"
  },
  {
    "text": "course working with Amazon we've enabled that through sage maker but we actually brought this down on really large data",
    "start": "2826720",
    "end": "2833410"
  },
  {
    "text": "sets that we have internally down to 32 minutes so we can train these really",
    "start": "2833410",
    "end": "2838599"
  },
  {
    "text": "large data sets with pharisee which is a sequence to sequence translation library",
    "start": "2838599",
    "end": "2844480"
  },
  {
    "text": "that we've open-sourced and that has been optimized for a sage maker and so doing large-scale training",
    "start": "2844480",
    "end": "2850030"
  },
  {
    "text": "on say 128 GPUs and that can be a p3 instance for example takes us for",
    "start": "2850030",
    "end": "2855250"
  },
  {
    "text": "example to 32 minutes so if new data comes in we can train very very quickly someone can go and get a coffee and they're come back and and",
    "start": "2855250",
    "end": "2861849"
  },
  {
    "text": "they have production models trained so now I'm gonna head back over to Dan to",
    "start": "2861849",
    "end": "2866890"
  },
  {
    "start": "2864000",
    "end": "2918000"
  },
  {
    "text": "talk about about the cycle gann work on",
    "start": "2866890",
    "end": "2872230"
  },
  {
    "text": "stage maker using pi Jorge and one quick note here so the fair seek work is",
    "start": "2872230",
    "end": "2877750"
  },
  {
    "text": "actually in this bitly here so I think this is actually Dan's github account",
    "start": "2877750",
    "end": "2882930"
  },
  {
    "text": "for now but it'll be in the in the examples folder in Sage Maker soon but",
    "start": "2882930",
    "end": "2888819"
  },
  {
    "text": "this is again jointly optimized work this is actually what we use in production today at Facebook these you",
    "start": "2888819",
    "end": "2895510"
  },
  {
    "text": "know these models these architectures and this is optimized any sage maker so",
    "start": "2895510",
    "end": "2900940"
  },
  {
    "text": "grab those check them out we do six billion translations a day with it it's it's pretty awesome very high",
    "start": "2900940",
    "end": "2906700"
  },
  {
    "text": "performance so we'll jump into the DC KNX yeah okay thank you so much Joe so it's",
    "start": "2906700",
    "end": "2918710"
  },
  {
    "start": "2918000",
    "end": "2975000"
  },
  {
    "text": "for a quick recap so just spoke about the details of fight forge and how it really drives the",
    "start": "2918710",
    "end": "2926000"
  },
  {
    "text": "momentum from research to production for different data scientists and developers",
    "start": "2926000",
    "end": "2931400"
  },
  {
    "text": "I mean I got hooked on PI torch a year and a half ago when working with a",
    "start": "2931400",
    "end": "2937280"
  },
  {
    "text": "customer and I walked in and I was talking about different deep learning frameworks because again at AWS we",
    "start": "2937280",
    "end": "2944030"
  },
  {
    "text": "support all of them and the customer actually convinced me to to get to play",
    "start": "2944030",
    "end": "2949850"
  },
  {
    "text": "around with PI torch and see how easy it makes things and what I thought I would",
    "start": "2949850",
    "end": "2955369"
  },
  {
    "text": "do is to walk you through a practical example we don't have all the time we need to go through what exactly is a",
    "start": "2955369",
    "end": "2961670"
  },
  {
    "text": "generative adversarial Network but I found it to be cool enough to show you exactly how to put the things that Joe",
    "start": "2961670",
    "end": "2968630"
  },
  {
    "text": "mentioned in practice and again the code is available on github so you can pick it up today and play around with it so",
    "start": "2968630",
    "end": "2975940"
  },
  {
    "text": "when I started learning Python again about a year and a half ago it was",
    "start": "2975940",
    "end": "2981080"
  },
  {
    "text": "really easy for me to to pick that up and then and then follow through the",
    "start": "2981080",
    "end": "2986090"
  },
  {
    "text": "execution as opposed to the way deep learning looked like before where you have to build a computation or a graph",
    "start": "2986090",
    "end": "2992150"
  },
  {
    "text": "and optimize that graph and eventually that graph runs in a very optimal manner but if you have a problem is really hard",
    "start": "2992150",
    "end": "2999500"
  },
  {
    "text": "to debug in right so with PI port it's really easy to just walk through exactly",
    "start": "2999500",
    "end": "3004600"
  },
  {
    "text": "what you're trying to build and then follow the execution step-by-step so that you can troubleshoot that through",
    "start": "3004600",
    "end": "3010720"
  },
  {
    "text": "time that's one of the key benefits that I picked up and it's great to see the movement now with own x-square you can",
    "start": "3010720",
    "end": "3018300"
  },
  {
    "text": "develop in pike forge in a very sequential manner and then after you're done developing you can convert your",
    "start": "3018300",
    "end": "3024700"
  },
  {
    "text": "model in a very optimized binary that you can run here or there so just to",
    "start": "3024700",
    "end": "3030160"
  },
  {
    "text": "look at so this is who here is familiar with generated by their serial networks and guns okay so the the idea here is to",
    "start": "3030160",
    "end": "3038020"
  },
  {
    "text": "train two networks newer networks that work together and then one is",
    "start": "3038020",
    "end": "3043660"
  },
  {
    "text": "designed to basically discriminate between real faces and thick faces in",
    "start": "3043660",
    "end": "3048880"
  },
  {
    "text": "the case of this example and the discriminator in this case is trained towards to understand whenever it sees a",
    "start": "3048880",
    "end": "3056020"
  },
  {
    "text": "new picture whether that picture is a real picture or not and a generator is",
    "start": "3056020",
    "end": "3061299"
  },
  {
    "text": "designed to to generate net new pictures from basically nonsense data aka noise",
    "start": "3061299",
    "end": "3067329"
  },
  {
    "text": "and it's trained against the the goal of being able to fool the discriminator",
    "start": "3067329",
    "end": "3073180"
  },
  {
    "text": "into making sure the discriminator is not able to tell whether a picture was",
    "start": "3073180",
    "end": "3078520"
  },
  {
    "text": "taken up and to the equilibrium state that you get here is where you have the generator getting better and better at",
    "start": "3078520",
    "end": "3085329"
  },
  {
    "text": "generating fake features pictures in this case that look real and a",
    "start": "3085329",
    "end": "3091690"
  },
  {
    "text": "discriminator basically landing at a coin flip of 50/50 whether it thinks",
    "start": "3091690",
    "end": "3097329"
  },
  {
    "text": "that the picture is is real not and then if you if you want to extrapolate that use case into many other scenarios like",
    "start": "3097329",
    "end": "3105549"
  },
  {
    "text": "fraud detection anomaly detection or privacy and different other use cases like that generated by the serial",
    "start": "3105549",
    "end": "3112480"
  },
  {
    "text": "networks to us seem to be very very practical in those domains so this is",
    "start": "3112480",
    "end": "3118089"
  },
  {
    "text": "the structure of my code I'm executing things on Sage maker but at the same time I'm using my own laptop to develop",
    "start": "3118089",
    "end": "3123849"
  },
  {
    "text": "things and thanks to the sage Maker SDK I can actually have that relationship where I leveraged the the hardware from",
    "start": "3123849",
    "end": "3130000"
  },
  {
    "text": "from Sage Maker as for yet using my my own laptop for development so here the normal is the this is the",
    "start": "3130000",
    "end": "3138010"
  },
  {
    "text": "okay let me start with the neural networking and it there's a lot to cover so I'll advise you to just go read the",
    "start": "3138010",
    "end": "3144220"
  },
  {
    "text": "code and on github but the key call-outs here are well we're creating a generator",
    "start": "3144220",
    "end": "3149319"
  },
  {
    "text": "using a generator class leveraging the neural network tenon model library that",
    "start": "3149319",
    "end": "3155260"
  },
  {
    "text": "is provided by Python and not to me of an NN module is is very simple in the English in an init method of the class",
    "start": "3155260",
    "end": "3163440"
  },
  {
    "text": "basically what you have to do is to construct your neuro network if you've ever seen a neural network before it's",
    "start": "3163440",
    "end": "3171069"
  },
  {
    "text": "essentially a set of linear combination that you potentially do",
    "start": "3171069",
    "end": "3177660"
  },
  {
    "start": "3172000",
    "end": "3210000"
  },
  {
    "text": "some convolutions on in case you want to do image analysis or do other types of transformations on and then use you put",
    "start": "3177660",
    "end": "3184740"
  },
  {
    "text": "that in sequences and then you decide whether you want to keep the gradients from these different calculations or the",
    "start": "3184740",
    "end": "3191010"
  },
  {
    "text": "different parameters associated with these calculations or not and then if you keep these gradients then the",
    "start": "3191010",
    "end": "3196109"
  },
  {
    "text": "backward propagation process is basically designed to compute the the",
    "start": "3196109",
    "end": "3201180"
  },
  {
    "text": "rate of change of the last function with regards to the rate of change of these weights so that's the whole architecture",
    "start": "3201180",
    "end": "3207119"
  },
  {
    "text": "mental model of building a deep learning model so in the mid class what you have to do is to describe your neural network",
    "start": "3207119",
    "end": "3212910"
  },
  {
    "start": "3210000",
    "end": "3250000"
  },
  {
    "text": "in the case of a generator that's what we do here and this small part is",
    "start": "3212910",
    "end": "3218579"
  },
  {
    "text": "basically initialization of the weights or the parameters of that generator and the the other important thing that I",
    "start": "3218579",
    "end": "3225089"
  },
  {
    "text": "want to call out here is this forward function so every time you see a Python code where a neural network is being",
    "start": "3225089",
    "end": "3231210"
  },
  {
    "text": "constructed you always see the module created and the forward pass you never see the backward function unless the",
    "start": "3231210",
    "end": "3237720"
  },
  {
    "text": "problem becomes very very complex because by torch essentially makes the backward propagation the calculation of",
    "start": "3237720",
    "end": "3244440"
  },
  {
    "text": "the gradients and then the tracking of all of these rates of changes automatic for you that's the essence of autocrat",
    "start": "3244440",
    "end": "3250500"
  },
  {
    "start": "3250000",
    "end": "3307000"
  },
  {
    "text": "so when you construct the neural networking fighters you always have the the design of the neural network and",
    "start": "3250500",
    "end": "3257210"
  },
  {
    "text": "then the forward function which basically passes the data through the neural network so we're doing that here",
    "start": "3257210",
    "end": "3263490"
  },
  {
    "text": "for the generator and then we're doing the same thing for the discriminator and essentially what the generator does is",
    "start": "3263490",
    "end": "3269970"
  },
  {
    "text": "that it takes any random vector of noise and then come those transpose",
    "start": "3269970",
    "end": "3276569"
  },
  {
    "text": "convolutions to it in order to come up with the structure of an image and then it's trained against making that image",
    "start": "3276569",
    "end": "3282329"
  },
  {
    "text": "look as real as possible and it is this community does the opposite it takes an image looking something and then it does",
    "start": "3282329",
    "end": "3288480"
  },
  {
    "text": "convolution some type of object detection stuff on that and then it has a sigmoid activation or logistic look",
    "start": "3288480",
    "end": "3296130"
  },
  {
    "text": "yeah logistic activate activation function at the end basically compare computing the probability of that image",
    "start": "3296130",
    "end": "3302250"
  },
  {
    "text": "the binary probability of that image being a real or fake so that's really",
    "start": "3302250",
    "end": "3309510"
  },
  {
    "start": "3307000",
    "end": "3339000"
  },
  {
    "text": "what it looks like in this single piece of good in my neural net file I have described the generator and in the",
    "start": "3309510",
    "end": "3315930"
  },
  {
    "text": "discriminator and then I can make them both work together now the next thing that is important as far as part because",
    "start": "3315930",
    "end": "3322770"
  },
  {
    "text": "in this example we're using a PI torch to train to build and train the neural network but we're also using tensor",
    "start": "3322770",
    "end": "3330480"
  },
  {
    "text": "board in order to visualize different things like the last function like some images and like everything else that is",
    "start": "3330480",
    "end": "3337710"
  },
  {
    "text": "related now I've had someone asking me a couple of days ago if I use H maker and",
    "start": "3337710",
    "end": "3343920"
  },
  {
    "start": "3339000",
    "end": "3457000"
  },
  {
    "text": "then I want to add additional libraries like open a I dream if I'm into enforcement learning or anything",
    "start": "3343920",
    "end": "3349710"
  },
  {
    "text": "anything else what can I do on sage maker well the good news is if you if",
    "start": "3349710",
    "end": "3355140"
  },
  {
    "text": "you add in these requirements the text file within your source directory of your code and you deploy that to Sage",
    "start": "3355140",
    "end": "3361380"
  },
  {
    "text": "Maker it's designed to pick that up and then understand that do you need these extra libraries and then go and install them",
    "start": "3361380",
    "end": "3367770"
  },
  {
    "text": "automatically automatically for you so that's basically what I've done here and again not no time to cover everything",
    "start": "3367770",
    "end": "3373440"
  },
  {
    "text": "but I wanted to make sure I hit this point your requirements or text file is important put that in there sage maker",
    "start": "3373440",
    "end": "3379170"
  },
  {
    "text": "would find it and then it's going to install everything that is in that requirements or text file and that's",
    "start": "3379170",
    "end": "3384720"
  },
  {
    "text": "what I've done here to have a 10-2 board capabilities now the next thing is my main function the function that is",
    "start": "3384720",
    "end": "3390660"
  },
  {
    "text": "actually going to leverage that neural network description and then do the iteration and do the training and do the",
    "start": "3390660",
    "end": "3397920"
  },
  {
    "text": "logging of the the the variables and everything else to to to tend to board",
    "start": "3397920",
    "end": "3404180"
  },
  {
    "text": "so in this main function again I'll call the pythons library which are very easy",
    "start": "3404180",
    "end": "3409740"
  },
  {
    "text": "and easy to remember Joe described them just now where you have torch torch distributed gives you distributed",
    "start": "3409740",
    "end": "3415800"
  },
  {
    "text": "capabilities torch  is what gives you the module and in parallel and optimization are basically capabilities",
    "start": "3415800",
    "end": "3422760"
  },
  {
    "text": "for building you know distributed networks and optimization is for the last function and in the backward proper",
    "start": "3422760",
    "end": "3429260"
  },
  {
    "text": "propagation and then you have some utilities functions as well for for",
    "start": "3429260",
    "end": "3434700"
  },
  {
    "text": "handling the data and handling some computer vision use cases so the API is actually not complex and again it's very",
    "start": "3434700",
    "end": "3441180"
  },
  {
    "text": "easy to track and follow so the next thing that I've done here is that from my neural net Wow I",
    "start": "3441180",
    "end": "3447840"
  },
  {
    "text": "import my generator in my discriminator I have some utility functions here to do",
    "start": "3447840",
    "end": "3453180"
  },
  {
    "text": "different things like loading the data and have some loggers that are available and then from tencel board X which is a",
    "start": "3453180",
    "end": "3459090"
  },
  {
    "start": "3457000",
    "end": "3509000"
  },
  {
    "text": "library to basically log ten to log PI porch of a different type of data points",
    "start": "3459090",
    "end": "3465690"
  },
  {
    "text": "onto 10 to board I do import the class called summary writer and it's a summary",
    "start": "3465690",
    "end": "3471030"
  },
  {
    "text": "writer that gives me access to these writer object to which I point to what",
    "start": "3471030",
    "end": "3477060"
  },
  {
    "text": "what I call it tensile board log directory now this log directory is essentially an environment variable that",
    "start": "3477060",
    "end": "3483060"
  },
  {
    "text": "CHT maker provides and the environment variable is called output data directory so again I'm building my own neural",
    "start": "3483060",
    "end": "3489810"
  },
  {
    "text": "network and my own algorithm but I'm aware that station maker would provide that output data directory for me so",
    "start": "3489810",
    "end": "3496560"
  },
  {
    "text": "that if I put something there sage maker it's gonna pick that up at the end of a training job and put that over to Amazon",
    "start": "3496560",
    "end": "3502380"
  },
  {
    "text": "s3 that's the relationship between PI toward stage maker and me as a developer again ai driven development now I start",
    "start": "3502380",
    "end": "3510089"
  },
  {
    "start": "3509000",
    "end": "3600000"
  },
  {
    "text": "my summary writer and these are basically some small helper libraries to load the models I create I load my",
    "start": "3510089",
    "end": "3515790"
  },
  {
    "text": "generators the next important thing here is my training function so in my",
    "start": "3515790",
    "end": "3522270"
  },
  {
    "text": "training function I do I lay down the steps here so that you could read through because we don't have a time to cover everything but in in the training",
    "start": "3522270",
    "end": "3530130"
  },
  {
    "text": "function here I essentially go through some of the details about my environment I try to",
    "start": "3530130",
    "end": "3537030"
  },
  {
    "text": "find out if I have GPUs available and if I have GPUs available I just say hey I want to do distributed training and then",
    "start": "3537030",
    "end": "3543720"
  },
  {
    "text": "sage maker also would provide me with environment variables that would tell me the number of hosts that are involved in",
    "start": "3543720",
    "end": "3549390"
  },
  {
    "text": "these training exercise and as soon as I have that I know that I can do distributed training on these on these",
    "start": "3549390",
    "end": "3556820"
  },
  {
    "text": "different machines so the rest of the code it's really about loading the",
    "start": "3556820",
    "end": "3563520"
  },
  {
    "text": "generator loading the discriminator the optimizer and everything and then adding",
    "start": "3563520",
    "end": "3568589"
  },
  {
    "text": "some mechanisms to to logging the data over to tensile board there's a lot",
    "start": "3568589",
    "end": "3574740"
  },
  {
    "text": "going on there but it's very easy to read hopefully and and I try to come and everything so that",
    "start": "3574740",
    "end": "3580590"
  },
  {
    "text": "you can track that through execution the idea there is all these extra classes and extra libraries like the average",
    "start": "3580590",
    "end": "3586350"
  },
  {
    "text": "meter and other stuff is a mechanism to be capturing data as you training your",
    "start": "3586350",
    "end": "3591660"
  },
  {
    "text": "model and then pushing that over to 10 - board as the model training started and say shoemaker knows how to grab that put",
    "start": "3591660",
    "end": "3598710"
  },
  {
    "text": "that over for you on Amazon a string and then I start my training loop and then I",
    "start": "3598710",
    "end": "3604590"
  },
  {
    "text": "go through the epochs and for each epochs I I do some tracking how much time did it take for me to to load in",
    "start": "3604590",
    "end": "3610800"
  },
  {
    "text": "the data and going through the code a little faster here because I want a hit",
    "start": "3610800",
    "end": "3616020"
  },
  {
    "text": "important point after the whole execution of a training everything is",
    "start": "3616020",
    "end": "3621600"
  },
  {
    "text": "commented so you can go through that I basically write the the I basically",
    "start": "3621600",
    "end": "3628140"
  },
  {
    "text": "write the information that I have back to back to a file or back to 2/10 abort",
    "start": "3628140",
    "end": "3633660"
  },
  {
    "text": "so the idea here is I've created my generator Emma discriminator I pass that to the model I stop my training loop and",
    "start": "3633660",
    "end": "3640470"
  },
  {
    "text": "I do my feed forward and backward propagation what titles helps with but I also have tensor board enable and I have",
    "start": "3640470",
    "end": "3645990"
  },
  {
    "text": "the summary writer that helps me write things back to to tend to board and I have my and I have a mechanism to write",
    "start": "3645990",
    "end": "3654810"
  },
  {
    "text": "the real files to a local folder for me again in that output data directory and because this is about generating images",
    "start": "3654810",
    "end": "3661680"
  },
  {
    "text": "I also want to see these files at the end of the execution stage maker is very useful in that sense because it would",
    "start": "3661680",
    "end": "3667650"
  },
  {
    "text": "capture all of that data that I saved to that output data directory and then push that back to the cloud storage at the",
    "start": "3667650",
    "end": "3673500"
  },
  {
    "text": "end of execution so two more minutes guys we're almost done so the what what",
    "start": "3673500",
    "end": "3679710"
  },
  {
    "text": "the experience looks like at the end of the day is I can go back to my Jupiter notebook now and then start the process",
    "start": "3679710",
    "end": "3686790"
  },
  {
    "text": "of you know playing around with the data a little bit doing some data exploration that's what I was doing here I got into",
    "start": "3686790",
    "end": "3692790"
  },
  {
    "text": "the data and then looked at some of those faces that I wanted to play with just to just to make sure that I had the",
    "start": "3692790",
    "end": "3698730"
  },
  {
    "text": "right data set but this is where the training really begins so if you remember the anatomy of the you know",
    "start": "3698730",
    "end": "3705960"
  },
  {
    "text": "training job kick start with with sage maker I still use the same PI torch estimator",
    "start": "3705960",
    "end": "3711880"
  },
  {
    "text": "I used the main function that we just walked through I pointed to the source directory which has the requirements of",
    "start": "3711880",
    "end": "3718510"
  },
  {
    "text": "text file and then I pointed to the framework version of hi torch that I",
    "start": "3718510",
    "end": "3723910"
  },
  {
    "text": "want and sage maker knows to go give me pyatters 1.0 in case that's what I pointed to and I say I want two",
    "start": "3723910",
    "end": "3730240"
  },
  {
    "text": "instances and I want the P 3 instance which is a CPU base volta instance and I",
    "start": "3730240",
    "end": "3736840"
  },
  {
    "text": "say ok then I want to go through 438 parks and I could I could have added extra hyper parameters here and the",
    "start": "3736840",
    "end": "3744040"
  },
  {
    "text": "framework would know how to kick that off now this is the interesting part based on the estimator if I say fit it",
    "start": "3744040",
    "end": "3749980"
  },
  {
    "text": "to the input and the input here are basically pointing to to the data set on my s3 bucket what's a shoe maker would",
    "start": "3749980",
    "end": "3756580"
  },
  {
    "text": "do is that it will kick up if we kick off the job and the red the green color and the red color logs here are",
    "start": "3756580",
    "end": "3764050"
  },
  {
    "text": "basically the lots that are coming from different nodes that are involved in the inner competition so I could have",
    "start": "3764050",
    "end": "3769180"
  },
  {
    "text": "decided to kick off the job and not wait for the logs that's what that weight variable that you saw earlier is about",
    "start": "3769180",
    "end": "3775240"
  },
  {
    "text": "but if I wait for the logs what's H maker is going to do is that it's going to go back to all these machines that are contributing fetch the logs and",
    "start": "3775240",
    "end": "3781960"
  },
  {
    "text": "bring them back to me on my client wherever my client is and then I see different colored logs that I can track",
    "start": "3781960",
    "end": "3787570"
  },
  {
    "text": "for different execution now the few things I wanted to show you here are the",
    "start": "3787570",
    "end": "3792760"
  },
  {
    "text": "things like CH maker installing these libraries that are in the requirement of text file for me that's basically what",
    "start": "3792760",
    "end": "3798850"
  },
  {
    "text": "is happening here the logs are long but I'll catch that and we will be done yeah",
    "start": "3798850",
    "end": "3805360"
  },
  {
    "text": "so our points in a curse starts it says",
    "start": "3805360",
    "end": "3810550"
  },
  {
    "text": "okay you want these libraries I'm gonna go fetch them for you and I had image IO",
    "start": "3810550",
    "end": "3816100"
  },
  {
    "text": "for example in my requirements a text file so it went and and then search that as long as it's peep installable it can",
    "start": "3816100",
    "end": "3822820"
  },
  {
    "text": "download and install that for me and so on and so forth all the way up until it has all the required libraries that you",
    "start": "3822820",
    "end": "3829210"
  },
  {
    "text": "need to basically start start the training job and then whatever you print out of your whatever you print to",
    "start": "3829210",
    "end": "3837370"
  },
  {
    "text": "standard out by print whatever stage maker is gonna pick that up and then push that out to the logs as well for you and so this",
    "start": "3837370",
    "end": "3845029"
  },
  {
    "text": "this is basically the training experience so in this case I've been using two GPUs on the cloud to GPU",
    "start": "3845029",
    "end": "3850489"
  },
  {
    "text": "machines on the cloud to train my my workload the other interesting thing is that at the end of the execution sage maker",
    "start": "3850489",
    "end": "3857539"
  },
  {
    "text": "would give me all these logs that are metrics from the GPU CPU utilization and",
    "start": "3857539",
    "end": "3862549"
  },
  {
    "text": "everything that I need to to visualize the execution so far so that's what you get from the cloud watch logs and I can",
    "start": "3862549",
    "end": "3870499"
  },
  {
    "text": "I can also get the logs actually that came out that I was looking at in the case I was waiting for for the logs or I",
    "start": "3870499",
    "end": "3876890"
  },
  {
    "text": "can have that stored somewhere on the cloud on AWS cloud watch logs and never",
    "start": "3876890",
    "end": "3882229"
  },
  {
    "text": "look at it if I'm not interested but this is what you guys were all looking for so at the end of the execution of a",
    "start": "3882229",
    "end": "3888049"
  },
  {
    "text": "job in in the specific example that I showed you I've been generating pictures at the end",
    "start": "3888049",
    "end": "3893419"
  },
  {
    "text": "of every epochs just to be able to see what what is the output of my fake what is the output of my real and then if",
    "start": "3893419",
    "end": "3899779"
  },
  {
    "text": "there is anything there that is interesting so all of these output stage maker put in the output folder that I",
    "start": "3899779",
    "end": "3905419"
  },
  {
    "text": "can now come and look at and say ok this is really for each epoch what a fake image looks like right so this is really",
    "start": "3905419",
    "end": "3912829"
  },
  {
    "text": "cool and in the case you you want to do the kind of deep learning that really requires you to do some analysis at the",
    "start": "3912829",
    "end": "3918589"
  },
  {
    "text": "end the relationship between th maker Pike torch and tensor board gives you that capability so there I was looking",
    "start": "3918589",
    "end": "3925279"
  },
  {
    "text": "at some some of the images but all the cool thing that have that that is possible to do here is to basically look",
    "start": "3925279",
    "end": "3932809"
  },
  {
    "text": "at look at the logs for example you can create a Jif or gif depending on how you",
    "start": "3932809",
    "end": "3939439"
  },
  {
    "text": "came to you want to pronounce that you can create a jiff too to start visualizing your your execution and your",
    "start": "3939439",
    "end": "3946009"
  },
  {
    "text": "logs afterwards and all of these things that you can create within the container in your main script stage maker can pick",
    "start": "3946009",
    "end": "3951739"
  },
  {
    "text": "that up and then and then save that for you afterwards so here I can see how my generator is getting better and better",
    "start": "3951739",
    "end": "3959269"
  },
  {
    "text": "at at basically creating fake images that means its own loss function is going down and my discriminator is still",
    "start": "3959269",
    "end": "3966289"
  },
  {
    "text": "very good because it knows you know what is it good and what is a bad image but over time you will see that the",
    "start": "3966289",
    "end": "3971989"
  },
  {
    "text": "generators loss or error is going down and this community of error is going up and they're going to meet each other",
    "start": "3971989",
    "end": "3977089"
  },
  {
    "text": "somewhere 50% of around the point of stability so that was for the last and then you can",
    "start": "3977089",
    "end": "3983430"
  },
  {
    "text": "also visualize some of the epochs you know and what the images are looking like through time now the last thing is",
    "start": "3983430",
    "end": "3991710"
  },
  {
    "text": "the tensor board experience so because of because I've created all of these logs and I stored them using again",
    "start": "3991710",
    "end": "3999300"
  },
  {
    "text": "tensor board X and PI porch I can now kick off a tensor board environment where I can visualize all of these",
    "start": "3999300",
    "end": "4005390"
  },
  {
    "text": "things intense board is powerful in the sense that you can save scalars which are real values and really anything that",
    "start": "4005390",
    "end": "4011330"
  },
  {
    "text": "you have on your mind so in this case I try to track the average batch time the",
    "start": "4011330",
    "end": "4017630"
  },
  {
    "text": "time it takes for me to just like run through a single batch or the time it takes for me to load data whatever you",
    "start": "4017630",
    "end": "4023000"
  },
  {
    "text": "have in mind you can put that on on top of that and that's why I had these average meters and intensive board is",
    "start": "4023000",
    "end": "4028970"
  },
  {
    "text": "going to present those for you so if you go be creative about the type of error you want to lock but the example that I",
    "start": "4028970",
    "end": "4035600"
  },
  {
    "text": "have there can show you a few different types of things to love and then so I can plot the average loss for the",
    "start": "4035600",
    "end": "4040940"
  },
  {
    "text": "generator and then some of the values that came out of the discriminators through time and I could also plug plug",
    "start": "4040940",
    "end": "4048770"
  },
  {
    "text": "the batch time and then plot the data time the time it took to load the data and so on and so forth so all of these",
    "start": "4048770",
    "end": "4054860"
  },
  {
    "text": "things are stored and again station maker picks that up and then sends the log back to you so that you can visualize we tend to board the last",
    "start": "4054860",
    "end": "4061880"
  },
  {
    "text": "thing is also the ability to visualize the images themselves side by side right so using tensor board X as you going",
    "start": "4061880",
    "end": "4068630"
  },
  {
    "text": "through training it doesn't matter if you're using multiple machines if you store these images then sage maker can",
    "start": "4068630",
    "end": "4074780"
  },
  {
    "text": "pick that up that up and then send it to tend to board for you to visualize later on so this really brings again the whole",
    "start": "4074780",
    "end": "4081920"
  },
  {
    "text": "concept of AI driven development together where you can be writing code for building and training deep learning",
    "start": "4081920",
    "end": "4088370"
  },
  {
    "text": "models but at the same time you are also speeding up infrastructure tearing it down and at the same time",
    "start": "4088370",
    "end": "4095060"
  },
  {
    "text": "you're building the cap of the metadata that you would need in order to explain and have a conversation about the deep",
    "start": "4095060",
    "end": "4101660"
  },
  {
    "text": "learning model that you train which your team and which are management and things like that so with that I know we're a",
    "start": "4101660",
    "end": "4106670"
  },
  {
    "text": "little bit over time and thanks again for for for sticking around we will be standing right out there if",
    "start": "4106670",
    "end": "4113429"
  },
  {
    "text": "you have any question and if you want to follow up on any of these the information for the yeah so this is the",
    "start": "4113429",
    "end": "4124258"
  },
  {
    "text": "CTA where you can get the the Python environment and then the the DC gun example code that that will have it's on",
    "start": "4124259",
    "end": "4131219"
  },
  {
    "text": "github thank you so much [Applause]",
    "start": "4131219",
    "end": "4136618"
  }
]
[
  {
    "start": "0",
    "end": "190000"
  },
  {
    "text": "hello great lights thank you thank you all for",
    "start": "3830",
    "end": "10349"
  },
  {
    "text": "coming my name is Adam biglan and I'm a Solutions Architect on the high-performance computing team here at",
    "start": "10349",
    "end": "16980"
  },
  {
    "text": "AWS I'm really excited to talk to you guys today about a subject that I'm really",
    "start": "16980",
    "end": "22470"
  },
  {
    "text": "passionate about which is ec2 performance see I've been a system administrator most of my career and I",
    "start": "22470",
    "end": "29369"
  },
  {
    "text": "know how frustrating it is to not get the performance that you're expecting out of an ec2 instance or out of a",
    "start": "29369",
    "end": "34860"
  },
  {
    "text": "server so what I wouldn't to talk to you today it's about some of the things that I've learned and that my customers do in",
    "start": "34860",
    "end": "41160"
  },
  {
    "text": "order to get the best possible performance out of ec2 my customers are doing things like computational fluid",
    "start": "41160",
    "end": "47250"
  },
  {
    "text": "dynamics and gene sequencing and semiconductor design so as you can imagine performance is a really",
    "start": "47250",
    "end": "53039"
  },
  {
    "text": "important subject to them so I'm glad that I can share this information with you guys today",
    "start": "53039",
    "end": "59270"
  },
  {
    "text": "now this presentation it's definitely built to be a deep dive on ec2 performance and we're gonna dive pretty",
    "start": "61699",
    "end": "68640"
  },
  {
    "text": "deep into the nitty-gritty of how ec2 works but along the way I also want to",
    "start": "68640",
    "end": "74010"
  },
  {
    "text": "make sure that I'm highlighting actionable things that you guys can walk away with and actually apply to your",
    "start": "74010",
    "end": "79439"
  },
  {
    "text": "instances in order to get them to run at their full potential I'm also going to talk a little bit",
    "start": "79439",
    "end": "85170"
  },
  {
    "text": "about things that go into choosing your ec2 instance because when it comes to getting performance out of an instance",
    "start": "85170",
    "end": "91380"
  },
  {
    "text": "making sure that you're picking the right one is just as important as all the performance tips that I'm going to",
    "start": "91380",
    "end": "97079"
  },
  {
    "text": "give you during this presentation",
    "start": "97079",
    "end": "100040"
  },
  {
    "text": "this side the thing works a little bit easier now you see - it's a really big subject and when you talk about ec2 you",
    "start": "102370",
    "end": "110030"
  },
  {
    "text": "can talk about a lot of different things you can talk about the different ways of purchasing easy - all the API is and",
    "start": "110030",
    "end": "116690"
  },
  {
    "text": "SDKs that make managing it easier you even talk about the networking that backs every see - instance but what I'm",
    "start": "116690",
    "end": "123230"
  },
  {
    "text": "going to cover today are the ec2 instances themselves how they operate what their features are and all the",
    "start": "123230",
    "end": "129649"
  },
  {
    "text": "options that you have when you go to launch them for all those other subjects I'm going to be giving some",
    "start": "129649",
    "end": "134900"
  },
  {
    "text": "recommendations for other presentations here at reinvent that'll dive deep into those and I'll give those at the end of",
    "start": "134900",
    "end": "140959"
  },
  {
    "text": "this presentation so let's start at the basics what is an ec2 instance well ec2 instances there",
    "start": "140959",
    "end": "148820"
  },
  {
    "text": "are virtual machines so they are guests that are sitting on top of a hypervisor that's running on a piece of physical",
    "start": "148820",
    "end": "154970"
  },
  {
    "text": "Hardware and when we launched ec2 about 10 years ago in 2006 you didn't get a lot of",
    "start": "154970",
    "end": "163070"
  },
  {
    "text": "choices you didn't get a lot of flexibility you went to launch and you've got a instance you didn't get to",
    "start": "163070",
    "end": "168260"
  },
  {
    "text": "pick how many virtual CPUs it had or how much memory it had it was kind of like the original Model T where you could",
    "start": "168260",
    "end": "174350"
  },
  {
    "text": "have any color you want as long as it's black or in our case we made it orange and we eventually gave it a name we",
    "start": "174350",
    "end": "181760"
  },
  {
    "text": "started calling it the m1 instance the customers they wanted more flexibility and they wanted more choices so we",
    "start": "181760",
    "end": "187970"
  },
  {
    "text": "started iterating on the platform and as you can see we've been growing really",
    "start": "187970",
    "end": "193130"
  },
  {
    "start": "190000",
    "end": "190000"
  },
  {
    "text": "significantly ever since but not only have we been adding more ec2 instances",
    "start": "193130",
    "end": "198440"
  },
  {
    "text": "we've actually been quietly changing how easy to operates underneath the hood a good example of this is in 2011 when we",
    "start": "198440",
    "end": "206360"
  },
  {
    "text": "launched this ec2 instance this was the first instance where we actually gave you the ability to define the physical",
    "start": "206360",
    "end": "212959"
  },
  {
    "text": "topology of your ec2 instances and that was with placement groups so with",
    "start": "212959",
    "end": "218209"
  },
  {
    "text": "placement groups you can actually define that your instances be located physically close together to get you the",
    "start": "218209",
    "end": "224239"
  },
  {
    "text": "best possible bandwidth and the lowest possible latency this was also the time where we introduced hardware-assisted",
    "start": "224239",
    "end": "230900"
  },
  {
    "text": "virtualization and hvm is a great feature because it allows you to you more of the underlying hardware and not",
    "start": "230900",
    "end": "238030"
  },
  {
    "text": "spend so much time talking to the hypervisor now ec2 it's always growing and it's",
    "start": "238030",
    "end": "243909"
  },
  {
    "text": "always changing even the things that I talked about today may be different in the future so whenever you're designing",
    "start": "243909",
    "end": "249790"
  },
  {
    "text": "your infrastructure make sure that you're looking at our documentation to",
    "start": "249790",
    "end": "255129"
  },
  {
    "text": "find the latest information available on ec2 now before we dive into the instances",
    "start": "255129",
    "end": "262810"
  },
  {
    "text": "and dive into the the tuning aspects I want to be sure that we're starting with a common language so here you can see",
    "start": "262810",
    "end": "269080"
  },
  {
    "text": "the name of an instance it's the C for extra-large and the C and C force is the",
    "start": "269080",
    "end": "274690"
  },
  {
    "text": "instance family now the family stands for what the instance is best suited for or what resources it has so you've got C",
    "start": "274690",
    "end": "282820"
  },
  {
    "text": "for compute our ram i for i UPS so and so forth the next number you see is the",
    "start": "282820",
    "end": "288849"
  },
  {
    "text": "instance generation and you can think of this almost like a version number of your ec2 instance so C for instance is",
    "start": "288849",
    "end": "295090"
  },
  {
    "text": "newer than a c3 instance and lastly you have the instance size and I've heard",
    "start": "295090",
    "end": "300160"
  },
  {
    "text": "these called t-shirt sizes which is a really great way of thinking about them so you've got small medium large extra-large so on and so forth",
    "start": "300160",
    "end": "308460"
  },
  {
    "start": "308000",
    "end": "308000"
  },
  {
    "text": "and what all this means for you is that you have a lot of choices you have a lot of flexibility when you go to launch",
    "start": "308460",
    "end": "314409"
  },
  {
    "text": "your instance now I know when you're in the ec2 console it can seem pretty overwhelming when you're faced with that",
    "start": "314409",
    "end": "321010"
  },
  {
    "text": "giant list of instances you're trying to launch for your workload so my suggestion to be able to pick the right",
    "start": "321010",
    "end": "327340"
  },
  {
    "text": "instance is to first start with the instance family and to find the right family you need to look and understand",
    "start": "327340",
    "end": "334090"
  },
  {
    "text": "what your application is constrained by so if your application needs a lot of memory start with a ram optimized",
    "start": "334090",
    "end": "340419"
  },
  {
    "text": "instance like the r3 instance if you need a lot of compute start with the c4 if your application is actually pretty",
    "start": "340419",
    "end": "347229"
  },
  {
    "text": "well balanced you probably want to be in the general purpose category with an m4 or a t2 instance",
    "start": "347229",
    "end": "353789"
  },
  {
    "text": "by choosing your instance from the perspective of your constraint it's pretty easy to find the right family and",
    "start": "353789",
    "end": "360130"
  },
  {
    "text": "then from there it's just a little bit of testing to find the right size within that family if you still need a little",
    "start": "360130",
    "end": "367510"
  },
  {
    "text": "bit of help the ec2 document actually has a list of workloads for every single",
    "start": "367510",
    "end": "372580"
  },
  {
    "text": "family that are well suited for it so it's a great option to go if you're not sure",
    "start": "372580",
    "end": "379050"
  },
  {
    "start": "378000",
    "end": "378000"
  },
  {
    "text": "but when you're going to launch an instance you'll see something a property of that instance that you've probably",
    "start": "379200",
    "end": "384250"
  },
  {
    "text": "not seen outside of AWS and that's the V CPU or virtual CPU and I have a lot of",
    "start": "384250",
    "end": "390190"
  },
  {
    "text": "customers asking you what is a virtual CPU well a V CPU or a virtual CPU on",
    "start": "390190",
    "end": "396160"
  },
  {
    "text": "modern instances except for the T family which is special for reasons we'll talk about later",
    "start": "396160",
    "end": "401170"
  },
  {
    "text": "it's actually just a hyper-threaded physical core now hyper-threading is a really cool",
    "start": "401170",
    "end": "407200"
  },
  {
    "text": "technology that lets you get more out of your cpu so it lets your CPU do almost two things at once so normally if you",
    "start": "407200",
    "end": "414340"
  },
  {
    "text": "have a process that would be blocked on i/o or waiting on a user it would be",
    "start": "414340",
    "end": "420130"
  },
  {
    "text": "stuck and your CPU wouldn't be able to do anything with hyper-threading that CPU can wait and process some requests",
    "start": "420130",
    "end": "426850"
  },
  {
    "text": "as they're coming in now we have some customers who want to know their real core count or their physical",
    "start": "426850",
    "end": "432280"
  },
  {
    "text": "core count on their instances and to do this you can usually just divide that Vee CPU number by two to get that core",
    "start": "432280",
    "end": "439420"
  },
  {
    "text": "count we also list for licensing purposes a list of every ec2 instance",
    "start": "439420",
    "end": "445060"
  },
  {
    "text": "and how many physical cores it has on the link that you see below",
    "start": "445060",
    "end": "450210"
  },
  {
    "text": "and to visualize what a virtual CPU looks like here's the output of a",
    "start": "450210",
    "end": "456340"
  },
  {
    "text": "program that I like to use it's called LS topo that's LS t.o.p oh and I really",
    "start": "456340",
    "end": "462820"
  },
  {
    "text": "like it because it gives you a visual representation of the underlying physical Hardware of your instance so",
    "start": "462820",
    "end": "468850"
  },
  {
    "text": "here you can see the output of an M for 10x large instance you can see how many sockets it has how much memory is",
    "start": "468850",
    "end": "476260"
  },
  {
    "text": "assigned to each socket the level 1 through level 3 cache that it has most",
    "start": "476260",
    "end": "481450"
  },
  {
    "text": "importantly for these purposes you can actually see the physical core count and then the threads that are assigned to",
    "start": "481450",
    "end": "487660"
  },
  {
    "text": "each core so in the case of the M for 10x large you can see that you have 40",
    "start": "487660",
    "end": "492730"
  },
  {
    "text": "threads and 24 some applications that actually don't",
    "start": "492730",
    "end": "499750"
  },
  {
    "text": "benefit from hyper threading where the context switching involved and then can actually slow down the performance these",
    "start": "499750",
    "end": "506889"
  },
  {
    "text": "are typically compute heavy applications things like financial risk calculations and engineering simulations it's been a",
    "start": "506889",
    "end": "513849"
  },
  {
    "text": "lot of time working on that processor these applications both on-premise and",
    "start": "513849",
    "end": "519370"
  },
  {
    "text": "on AWS usually disabled hyper-threading now if you're not sure if this applies",
    "start": "519370",
    "end": "524589"
  },
  {
    "text": "to your workloads look at what you do with your on-premise or your bare metal machines or what your",
    "start": "524589",
    "end": "530320"
  },
  {
    "text": "coworkers do if you normally disable it on-premise you'll probably also want to",
    "start": "530320",
    "end": "535330"
  },
  {
    "text": "disable it on AWS if you're not sure you probably don't need to worry about any of this",
    "start": "535330",
    "end": "540510"
  },
  {
    "text": "but it's really easy to do on Linux slightly harder on Windows on Linux the",
    "start": "540510",
    "end": "546880"
  },
  {
    "text": "way threads are enumerated makes it really easy to turn off that hyper threading so you have let's say you have",
    "start": "546880",
    "end": "552940"
  },
  {
    "text": "two processors the a threads of each processor are listed first so say 0",
    "start": "552940",
    "end": "558730"
  },
  {
    "text": "through 10 on an m4 and then you got 10 through 20 on the other",
    "start": "558730",
    "end": "563880"
  },
  {
    "text": "CPU socket the B threads are then listed second so to disable hyper threading all",
    "start": "563880",
    "end": "571420"
  },
  {
    "text": "you need to do is turn off those B threads and you can do this two different ways the first way that you'll",
    "start": "571420",
    "end": "578110"
  },
  {
    "text": "see here is you can do it online so this is just a simple floor for loop and bash",
    "start": "578110",
    "end": "583600"
  },
  {
    "text": "and what it's doing is its disabling every online processor now this is a",
    "start": "583600",
    "end": "589000"
  },
  {
    "text": "great option because it doesn't require a reboot however the downsides of this is that it could potentially cause",
    "start": "589000",
    "end": "594820"
  },
  {
    "text": "system instability because your data say blowing processors that applications might be running on you'll also lose all",
    "start": "594820",
    "end": "602350"
  },
  {
    "text": "these changes once you reboot the machine so the way that I prefer is the second way which is just in Linux to set",
    "start": "602350",
    "end": "608860"
  },
  {
    "text": "a grub boot parameter for the number of physical cores of that box minus 1 because it starts at 0 the only downside",
    "start": "608860",
    "end": "616660"
  },
  {
    "text": "of this approach is that it does require a reboot and that if you ever change from one instant size to another you're",
    "start": "616660",
    "end": "621940"
  },
  {
    "text": "gonna have to remember to update that setting on Windows this process is a little bit harder and that's because",
    "start": "621940",
    "end": "628540"
  },
  {
    "text": "instead of listing the a first and then the B like Linux does windows actually interleaves the a and the B processors",
    "start": "628540",
    "end": "636000"
  },
  {
    "text": "so it order to disable hyper-threading on a Windows box you've actually got to",
    "start": "636000",
    "end": "641020"
  },
  {
    "text": "use something like CPU thread affinity to lock specific processors to their specific physical course",
    "start": "641020",
    "end": "648960"
  },
  {
    "text": "and here you can see that same output of that same m4 10 X large but just with",
    "start": "649020",
    "end": "654700"
  },
  {
    "text": "hyper-threading enabled you'll notice now that there's one thread for every",
    "start": "654700",
    "end": "660490"
  },
  {
    "text": "physical core whereas there were two earlier so next let's dig a little bit deeper",
    "start": "660490",
    "end": "667630"
  },
  {
    "start": "664000",
    "end": "664000"
  },
  {
    "text": "into how instance sizes work the way we build instances actually is built to",
    "start": "667630",
    "end": "673420"
  },
  {
    "text": "allow you to scale pretty easily both vertically and horizontally so let's take the c4 family as an",
    "start": "673420",
    "end": "680140"
  },
  {
    "text": "example here you can see on the left is the c-4 8x large instance which is the",
    "start": "680140",
    "end": "685840"
  },
  {
    "text": "largest c4 a taxi for instance that we have available that's c4 8 X large",
    "start": "685840",
    "end": "691750"
  },
  {
    "text": "instance is roughly equal and resources to two of the c4 4 x large resources c4",
    "start": "691750",
    "end": "698410"
  },
  {
    "text": "4 X large instances sorry and this is these are things like virtual CPUs that",
    "start": "698410",
    "end": "705970"
  },
  {
    "text": "that instance has the amount of memory that's allocated to it given the amount of network bandwidth that's available to",
    "start": "705970",
    "end": "712240"
  },
  {
    "text": "that instance is roughly half of that size and this follows all the way down the line",
    "start": "712240",
    "end": "718210"
  },
  {
    "text": "so 4 of the c4 2 X largest are roughly equal to two of the c-4 4x largest and",
    "start": "718210",
    "end": "724750"
  },
  {
    "text": "so on and so forth and the reason that things are set up",
    "start": "724750",
    "end": "730510"
  },
  {
    "start": "727000",
    "end": "727000"
  },
  {
    "text": "this way is because of how we partition our instances typically when you're running the largest instance you're",
    "start": "730510",
    "end": "737140"
  },
  {
    "text": "getting the whole physical server when you're running smaller instances you're actually getting a fraction of",
    "start": "737140",
    "end": "743830"
  },
  {
    "text": "that server now virtualization has historically gotten a pretty bad reputation because",
    "start": "743830",
    "end": "750490"
  },
  {
    "text": "it's often used to manage the over utilization of resources so you have more VMs than you have physical hardware",
    "start": "750490",
    "end": "757600"
  },
  {
    "text": "to satisfy them we on the other hand use virtualization for a lot of other",
    "start": "757600",
    "end": "762670"
  },
  {
    "text": "reasons one of the most important ones is for security and isolation from one",
    "start": "762670",
    "end": "767680"
  },
  {
    "text": "virtual machine to another on the piece of physical hardware but we also use virtualization so that we can dedicate",
    "start": "767680",
    "end": "774189"
  },
  {
    "text": "specific resources to specific customers so taking virtual CPUs as an example",
    "start": "774189",
    "end": "780839"
  },
  {
    "text": "again with the exception of the T family which is special for reasons we'll talk about later when you're assigned a",
    "start": "780839",
    "end": "788139"
  },
  {
    "text": "virtual CPU you are the only customer that's using that CPU and you're not sharing it with anyone else on the Box",
    "start": "788139",
    "end": "794529"
  },
  {
    "text": "the same thing applies to memory and network allocation we build ec2",
    "start": "794529",
    "end": "801819"
  },
  {
    "text": "instances with the goal of providing you with a consistent experience every time you use it no matter what else is",
    "start": "801819",
    "end": "807879"
  },
  {
    "text": "happening on that Hardware",
    "start": "807879",
    "end": "811049"
  },
  {
    "text": "and the last thing I want to talk about when it comes to choosing your instance",
    "start": "813299",
    "end": "819480"
  },
  {
    "text": "and I know it's pretty cheesy to quote your own ec2 documentation but I really",
    "start": "819480",
    "end": "825670"
  },
  {
    "text": "like the sentiment behind this it's really easy to spit up in an ec2",
    "start": "825670",
    "end": "831040"
  },
  {
    "text": "instance and install your application and do some testing in it so instead of",
    "start": "831040",
    "end": "836110"
  },
  {
    "text": "doing what I see customers do which is launch a synthetic load testing tool to count the number of flops or I ops or",
    "start": "836110",
    "end": "842949"
  },
  {
    "text": "whatever they can get out of the instance install your real application and test on that so if you have a mobile",
    "start": "842949",
    "end": "849100"
  },
  {
    "text": "app simulate a real user navigating through it if you have an HPC application run some of your common",
    "start": "849100",
    "end": "855220"
  },
  {
    "text": "models if you have a business intelligence database run some of your common queries use a real workload so",
    "start": "855220",
    "end": "861699"
  },
  {
    "text": "that you know how your application is actually going to perform as you go into production and not only that you're",
    "start": "861699",
    "end": "867369"
  },
  {
    "text": "going to be able to understand as you're testing different instance sizes how your application is in a scale and",
    "start": "867369",
    "end": "872379"
  },
  {
    "text": "perform as you grow and scale out",
    "start": "872379",
    "end": "877499"
  },
  {
    "text": "now I want to start digging a little bit deeper into the operating system and how the operating system interacts with the",
    "start": "878459",
    "end": "885279"
  },
  {
    "text": "ec2 Hardware on any instance physical or virtual timekeeping is a really",
    "start": "885279",
    "end": "891220"
  },
  {
    "text": "important operation it's used for things like processing interrupts getting the",
    "start": "891220",
    "end": "896410"
  },
  {
    "text": "time and date and measuring performance of cyclists most a.m. is that you on AWS are going",
    "start": "896410",
    "end": "904360"
  },
  {
    "text": "to use the Zen clock source by default and the reason they do this is because the Zen clock source is compatible with",
    "start": "904360",
    "end": "910630"
  },
  {
    "text": "every single instance that we have however there's around the time of the",
    "start": "910630",
    "end": "916240"
  },
  {
    "text": "Sandy Bridge processor that the TSC clock source became available now the",
    "start": "916240",
    "end": "922090"
  },
  {
    "text": "TSC clock source compared to the Zen clock source is actually handled by bare metal and not the hypervisor so every",
    "start": "922090",
    "end": "929140"
  },
  {
    "text": "time you make a timekeeping call you're going to be talking to the physical processor and not to a virtual device",
    "start": "929140",
    "end": "935050"
  },
  {
    "text": "and because of this calls to the CSC clock source are going to be soon",
    "start": "935050",
    "end": "940090"
  },
  {
    "text": "significantly quicker so to demonstrate this I wrote a very",
    "start": "940090",
    "end": "945760"
  },
  {
    "text": "simple application don't worry about trying to read it my code is terrible unless this admin",
    "start": "945760",
    "end": "951300"
  },
  {
    "text": "but it does two things it performs a large number of get time of day calls",
    "start": "951300",
    "end": "956740"
  },
  {
    "text": "and it also performs a little bit of floating point math",
    "start": "956740",
    "end": "962580"
  },
  {
    "text": "and here's the results of it with the Zen clock source I also used s trace to",
    "start": "962580",
    "end": "969430"
  },
  {
    "start": "963000",
    "end": "963000"
  },
  {
    "text": "profile this application as it's running and I really like s trace because it'll tell you how many system calls are being",
    "start": "969430",
    "end": "975700"
  },
  {
    "text": "made and the amount of time that they're taking up so here you can see it this test took",
    "start": "975700",
    "end": "983350"
  },
  {
    "text": "about 12 seconds and get time of day was the number one call in that list there were a lot of calls being made and it",
    "start": "983350",
    "end": "989740"
  },
  {
    "text": "took up a significant amount of time the same exact system the only thing I",
    "start": "989740",
    "end": "995800"
  },
  {
    "text": "did is switch that clock source from Zen to TSC the test now ran in two seconds as compared to 12 LeFleur and if you",
    "start": "995800",
    "end": "1004350"
  },
  {
    "text": "look at that s trace output get time of day was so quick it doesn't even show up anymore",
    "start": "1004350",
    "end": "1009470"
  },
  {
    "text": "now I know this is a pretty simple application and a pretty extreme set of",
    "start": "1009470",
    "end": "1015660"
  },
  {
    "text": "results but I've seen some applications get as much as a 40% performance improvement just by switching their",
    "start": "1015660",
    "end": "1021960"
  },
  {
    "text": "clock source from Zen to TSC and I could tell that they would because I profiled",
    "start": "1021960",
    "end": "1027600"
  },
  {
    "text": "them with s trace and I saw those number of timekeeping calls so it's an easy change to make on Linux",
    "start": "1027600",
    "end": "1034470"
  },
  {
    "text": "you can see three commands here the top command is going to list all the available clock sources on your system",
    "start": "1034470",
    "end": "1041250"
  },
  {
    "text": "so you can see if TSC is available and if you're running a modern instance it should be the second command is going to",
    "start": "1041250",
    "end": "1048240"
  },
  {
    "text": "list your current clock source and if you launched a standard Linux AMI that's probably going to be Zen the last",
    "start": "1048240",
    "end": "1054630"
  },
  {
    "text": "command is just going to hot online or hot switch your clock source from zen to",
    "start": "1054630",
    "end": "1060360"
  },
  {
    "text": "TSE so if you're running a recently released ec2 instance and you're running",
    "start": "1060360",
    "end": "1066750"
  },
  {
    "text": "an application that's doing maybe some JVM debugging or performance tracing or even s ap your database operations that",
    "start": "1066750",
    "end": "1073500"
  },
  {
    "text": "have a lot of time keeping calls I highly recommend you switch to the TSE clock source because it could make a big",
    "start": "1073500",
    "end": "1079380"
  },
  {
    "text": "boost in your performance another recent change that we made to",
    "start": "1079380",
    "end": "1085650"
  },
  {
    "text": "the platform is giving you the ability to control the C and P states of your instances so we launched this with the",
    "start": "1085650",
    "end": "1093510"
  },
  {
    "text": "c48 x-large instance but it's available on many more today first let's talk about the sea state so",
    "start": "1093510",
    "end": "1100290"
  },
  {
    "text": "sea states allow you to actually set the the power savings features of that",
    "start": "1100290",
    "end": "1107070"
  },
  {
    "text": "processor so using a c 4 or 8 x large as an example c 4 edx large instance as a",
    "start": "1107070",
    "end": "1113970"
  },
  {
    "text": "base clock speed of 2.9 gigahertz however if you're only doing work on one",
    "start": "1113970",
    "end": "1120540"
  },
  {
    "text": "or two cores those cores can turbo boost up to about 3.5 gigahertz but it does so",
    "start": "1120540",
    "end": "1126900"
  },
  {
    "text": "by letting all those other cores on the system idle down now this is really",
    "start": "1126900",
    "end": "1132150"
  },
  {
    "text": "great when you are doing an application that requires very high clock speed but",
    "start": "1132150",
    "end": "1137610"
  },
  {
    "text": "if you're doing work that requires all of your course to be available and working it can actually increase the",
    "start": "1137610",
    "end": "1144360"
  },
  {
    "text": "latency of bringing up those idle course so I have some customers will actually",
    "start": "1144360",
    "end": "1150240"
  },
  {
    "text": "set this the command that you see down at the bottom in grub so to limit how",
    "start": "1150240",
    "end": "1156300"
  },
  {
    "text": "far those instant how far those other cores can idle down so that when you go to use them you won't have the increased",
    "start": "1156300",
    "end": "1162600"
  },
  {
    "text": "latency of spinning them up next thing I wanna talk about is the P",
    "start": "1162600",
    "end": "1169340"
  },
  {
    "start": "1166000",
    "end": "1166000"
  },
  {
    "text": "States P states allow you to set the desired frequency of your course so",
    "start": "1169340",
    "end": "1175010"
  },
  {
    "text": "perhaps you have an application where you can where you need consistency more than performance and you want your",
    "start": "1175010",
    "end": "1181700"
  },
  {
    "text": "course to operate at the same clock speed all the time game servers are a pretty good example",
    "start": "1181700",
    "end": "1187670"
  },
  {
    "text": "for these which stay operated in loops and they expect that loop to happen take the exact same amount of time every time",
    "start": "1187670",
    "end": "1193550"
  },
  {
    "text": "it runs so customers with these needs will actually set the P state of their",
    "start": "1193550",
    "end": "1198890"
  },
  {
    "text": "course so that they don't turbo boost and they just operate at that base clock rate all the time",
    "start": "1198890",
    "end": "1205539"
  },
  {
    "start": "1205000",
    "end": "1205000"
  },
  {
    "text": "next I finally want to talk about those t2 instances that I've been referring to and why they're special so t2 instances",
    "start": "1206800",
    "end": "1214730"
  },
  {
    "text": "they're great general-purpose instances and they're actually the lowest cost instance it's available on ec2 today so",
    "start": "1214730",
    "end": "1221420"
  },
  {
    "text": "that t2 Nano which is the smallest one you can get for about half a penny per hour and it's the t2 instances they're",
    "start": "1221420",
    "end": "1228470"
  },
  {
    "text": "great for workloads that have burstable CPU performance these are things like database servers websites even and",
    "start": "1228470",
    "end": "1236600"
  },
  {
    "text": "especially development environments with a t2 instance you start with a baseline",
    "start": "1236600",
    "end": "1242210"
  },
  {
    "text": "level of performance and you're going to get that all the time on the instance and as you can see that baseline is",
    "start": "1242210",
    "end": "1247520"
  },
  {
    "text": "different depending on which instance size that you go with but the magic of",
    "start": "1247520",
    "end": "1253400"
  },
  {
    "text": "t2 comes in with the burst credits that allow you to burst above that baseline",
    "start": "1253400",
    "end": "1259120"
  },
  {
    "text": "so we launched t2 instances because we saw that most customer workloads aren't",
    "start": "1259120",
    "end": "1265880"
  },
  {
    "text": "using a hundred percent of the CPU all the time so using the CPU burst credits",
    "start": "1265880",
    "end": "1271750"
  },
  {
    "text": "it allows you to get the performance that you need when you need it and not pay for it when you don't",
    "start": "1271750",
    "end": "1279370"
  },
  {
    "start": "1279000",
    "end": "1279000"
  },
  {
    "text": "so let's dig into how those credits actually work and how you can use them so you can think of the credits and a t2",
    "start": "1279550",
    "end": "1287000"
  },
  {
    "text": "instance kind of like a bucket so you boot your instance and you're gonna get enough credits that are in that bucket",
    "start": "1287000",
    "end": "1293360"
  },
  {
    "text": "to handle things like booting your operating system and launching your application and doing whatever work your",
    "start": "1293360",
    "end": "1299420"
  },
  {
    "text": "instance was booted for while your instance is running and doing all that work you're gonna slowly start pulling",
    "start": "1299420",
    "end": "1305270"
  },
  {
    "text": "credits out of that bucket one cpu credit allows you to burst for a hundred percent of one core for one minute now",
    "start": "1305270",
    "end": "1313910"
  },
  {
    "text": "when the work I when the work dies down and your instance becomes idle you're gonna start earning new credits going",
    "start": "1313910",
    "end": "1320210"
  },
  {
    "text": "into that bucket also credits are gonna expire out of that bucket if they're unused for 24",
    "start": "1320210",
    "end": "1326540"
  },
  {
    "text": "hours so finding the right size of that t2 instance is important to make sure that you're always boosting and to help",
    "start": "1326540",
    "end": "1334250"
  },
  {
    "start": "1333000",
    "end": "1333000"
  },
  {
    "text": "you make sure that we offer two different CloudWatch metrics that you can monitor with your instances so the",
    "start": "1334250",
    "end": "1340040"
  },
  {
    "text": "first one in orange this is your cpu credit usage so this is going to tell you how many CPU credits per minute",
    "start": "1340040",
    "end": "1345860"
  },
  {
    "text": "you're using as your CPU is spiking the second one is a CPU credit balance and",
    "start": "1345860",
    "end": "1352880"
  },
  {
    "text": "this is going to be an important metric for you if you always want to be getting the burst performance out of your t2",
    "start": "1352880",
    "end": "1358130"
  },
  {
    "text": "instance so if you always want to be in that burst level of performance and not at that baseline you've got to make sure",
    "start": "1358130",
    "end": "1364280"
  },
  {
    "text": "that this credit balance never drops down to zero if you're using something like auto scaling this is probably the",
    "start": "1364280",
    "end": "1370670"
  },
  {
    "text": "metric that you want to start hooking on instead of CPU usage because your CPU usage is gonna drop once you exhaust all",
    "start": "1370670",
    "end": "1377900"
  },
  {
    "text": "the credits in that bucket the next instance and I want to talk",
    "start": "1377900",
    "end": "1383870"
  },
  {
    "start": "1381000",
    "end": "1381000"
  },
  {
    "text": "about is the x1 instance and the x1 is really exciting because it's the biggest instance that we have available on AWS",
    "start": "1383870",
    "end": "1390490"
  },
  {
    "text": "the x1 32 X large has it's a quad socket system has almost 2 terabytes of RAM and",
    "start": "1390490",
    "end": "1398480"
  },
  {
    "text": "it has 128 virtual CPUs so it's a massive machine that's really great if",
    "start": "1398480",
    "end": "1404780"
  },
  {
    "text": "you have you know a big in-memory database if you're doing some big data processing or even some HPC workloads",
    "start": "1404780",
    "end": "1412190"
  },
  {
    "text": "that need that much memory footprint all on a single machine",
    "start": "1412190",
    "end": "1417340"
  },
  {
    "text": "but when you have that much memory effective management of it is even more important on any system with multiple",
    "start": "1417340",
    "end": "1425420"
  },
  {
    "text": "sockets accessing the memory and the socket closest to you is always going to",
    "start": "1425420",
    "end": "1430820"
  },
  {
    "text": "be faster than accessing memory in the socket in a remote socket and this",
    "start": "1430820",
    "end": "1436170"
  },
  {
    "text": "concept is called Numa or non-uniform memory access",
    "start": "1436170",
    "end": "1441290"
  },
  {
    "text": "between those two sockets you have what's called especially on Intel systems that's called a qpi or quickpath",
    "start": "1441290",
    "end": "1448140"
  },
  {
    "text": "interconnect and this is the bus the transfers memory from one socket to another",
    "start": "1448140",
    "end": "1453950"
  },
  {
    "text": "so let's look at the r38 x-large as an example so this is a two socket box and",
    "start": "1453950",
    "end": "1461100"
  },
  {
    "text": "you can see that there's 122 gigabytes of RAM that are attached to each socket",
    "start": "1461100",
    "end": "1466550"
  },
  {
    "text": "between each socket you have two qpi links to transfer that memory from one socket to another so if you have an",
    "start": "1466550",
    "end": "1473610"
  },
  {
    "text": "application that's running in the socket on the left that's copying data from the socket from memory in the socket on the",
    "start": "1473610",
    "end": "1479940"
  },
  {
    "text": "right it's got to send that memory or send that data over those qpi paths which well fast are never going to be as",
    "start": "1479940",
    "end": "1487770"
  },
  {
    "text": "fast as accessing memory that's local to that socket now when you go to the x1 instance and",
    "start": "1487770",
    "end": "1495390"
  },
  {
    "text": "you go to 4 sockets things get a lot more complex and Numa is even more important",
    "start": "1495390",
    "end": "1502460"
  },
  {
    "text": "compared to the r38 x-large instance we now have far more memory per socket 488",
    "start": "1502460",
    "end": "1509280"
  },
  {
    "text": "gigabytes of RAM on each socket and you'll notice that instead of 2 qpi past",
    "start": "1509280",
    "end": "1514350"
  },
  {
    "text": "because we have more sockets to spread them across we now only have one qpi connecting each socket so memory",
    "start": "1514350",
    "end": "1521340"
  },
  {
    "text": "transfers from one new Mazzone to another are going to take longer on the x1 than they are on the r3",
    "start": "1521340",
    "end": "1529310"
  },
  {
    "text": "so what can you do about this well if you've ever monitored a system",
    "start": "1529310",
    "end": "1534750"
  },
  {
    "start": "1530000",
    "end": "1530000"
  },
  {
    "text": "let's say the top or a process monitor you'll notice that the process scheduler",
    "start": "1534750",
    "end": "1541050"
  },
  {
    "text": "in your operating system is actually moving processes around from one court to another all the time",
    "start": "1541050",
    "end": "1546380"
  },
  {
    "text": "the scheduling helps ensure that your cpu performance is balanced over all the",
    "start": "1546380",
    "end": "1551580"
  },
  {
    "text": "cores in your system on Linux it wasn't until around the 3.8 kernel that it's",
    "start": "1551580",
    "end": "1557190"
  },
  {
    "text": "starting to take Numa into a consideration so with that addition to the kernel or",
    "start": "1557190",
    "end": "1563340"
  },
  {
    "text": "with that addition to the scheduler it's actually going to be moving processes closer to the memory that they're",
    "start": "1563340",
    "end": "1568950"
  },
  {
    "text": "accessing and also moving memory closer to the processes the downside of this is that it can",
    "start": "1568950",
    "end": "1576299"
  },
  {
    "text": "actually slow down performance of some applications especially if they have a huge memory footprint so if your memory",
    "start": "1576299",
    "end": "1583440"
  },
  {
    "text": "footprint overlaps two different Numa zones if you're using a lot of memory for your application it's going to be",
    "start": "1583440",
    "end": "1589379"
  },
  {
    "text": "needlessly moving memory around from one zone to another even though your processes are going to",
    "start": "1589379",
    "end": "1595200"
  },
  {
    "text": "operate in both places and need access to them so you can do a couple of things to",
    "start": "1595200",
    "end": "1600629"
  },
  {
    "text": "mitigate this on linux the first option is to set Numa equals off in your grub",
    "start": "1600629",
    "end": "1607589"
  },
  {
    "text": "boot parameter and what this does is it actually disables all Numa knowledge of",
    "start": "1607589",
    "end": "1612959"
  },
  {
    "text": "that scheduler and of the system itself so it sees one big Numa zone overlapping",
    "start": "1612959",
    "end": "1618749"
  },
  {
    "text": "all of the Sacketts on your system so it's not trying to needlessly move memory around from one zone to another",
    "start": "1618749",
    "end": "1624679"
  },
  {
    "text": "the alternative is if you have an application that you can actually fit",
    "start": "1624679",
    "end": "1629909"
  },
  {
    "text": "within a single Numa zone you may want to use an application like Numa CTL when you launch whatever your workload you",
    "start": "1629909",
    "end": "1636479"
  },
  {
    "text": "have to lock your process into a single new Mazzone so that it'll only ever read",
    "start": "1636479",
    "end": "1642389"
  },
  {
    "text": "and write memory that's local to it and in those processes won't be able to switch from one socket to another",
    "start": "1642389",
    "end": "1650929"
  },
  {
    "start": "1651000",
    "end": "1651000"
  },
  {
    "text": "another thing to keep in mind when it comes to operating systems is how important the version of your operating",
    "start": "1652999",
    "end": "1658919"
  },
  {
    "text": "system is I was working with a customer not too long ago who was migrating a",
    "start": "1658919",
    "end": "1664649"
  },
  {
    "text": "custom in-house developed application from on-premise to AWS and they weren't",
    "start": "1664649",
    "end": "1670229"
  },
  {
    "text": "seeing the performance they were expecting to out of the system now this was a pretty complex application and",
    "start": "1670229",
    "end": "1677429"
  },
  {
    "text": "testing it took a lot of work so what we did is we found an analogue a performance testing analog tool online",
    "start": "1677429",
    "end": "1684509"
  },
  {
    "text": "called a busy which exhibited the same exact behavior as they were seeing",
    "start": "1684509",
    "end": "1690888"
  },
  {
    "text": "so this is the first round of their tests it was run on rl6 and this is with",
    "start": "1691309",
    "end": "1698099"
  },
  {
    "text": "a busy and we also profiled it with per which is another great tool to understand what's going on at a system",
    "start": "1698099",
    "end": "1704520"
  },
  {
    "text": "level from your application and here you can see the first time we ran it we got about twelve thousand records per second",
    "start": "1704520",
    "end": "1711030"
  },
  {
    "text": "but we noticed there was a lot of time being spent in system space in the kernel instead of user space we also",
    "start": "1711030",
    "end": "1718140"
  },
  {
    "text": "looked at the page faults and saw that there's about a million and a half page faults just in this ten-second run so",
    "start": "1718140",
    "end": "1723900"
  },
  {
    "text": "obviously something is wrong here's the output of another tool that",
    "start": "1723900",
    "end": "1729270"
  },
  {
    "text": "we used called flame grass now if you haven't used flame grass before I highly recommend it because and these are this",
    "start": "1729270",
    "end": "1736020"
  },
  {
    "text": "is a tool it was created by Brendan Gregg who's given talks at reinvent before it's a really great way of",
    "start": "1736020",
    "end": "1741090"
  },
  {
    "text": "understanding where the time is spent in your application and the code paths that are happening in there so here you can",
    "start": "1741090",
    "end": "1748110"
  },
  {
    "text": "see a busy is the bottom bar in this chart and the bulk of that time is",
    "start": "1748110",
    "end": "1754050"
  },
  {
    "text": "actually spent in an M advised call which is a memory management call and that memory management call it's",
    "start": "1754050",
    "end": "1761460"
  },
  {
    "text": "going through a lot of different code but eventually it ends up in a Zen hyper call which accounts for all that system",
    "start": "1761460",
    "end": "1768210"
  },
  {
    "text": "time that we're using so we took this same exact code and",
    "start": "1768210",
    "end": "1773490"
  },
  {
    "text": "weari compiled it for rel seven and ranted on the exact same type of",
    "start": "1773490",
    "end": "1779280"
  },
  {
    "text": "instance just by recompiling it and moving it to the newest operating system",
    "start": "1779280",
    "end": "1784320"
  },
  {
    "text": "our performance went from twelve thousand records per second to four hundred twenty-five thousand records per",
    "start": "1784320",
    "end": "1790050"
  },
  {
    "text": "second and all that time that was spent in system space moved into user space where we'd expect it to be we can also",
    "start": "1790050",
    "end": "1796860"
  },
  {
    "text": "see that page faults went down from around a million and a half to only fourteen thousand so what happened what",
    "start": "1796860",
    "end": "1803670"
  },
  {
    "text": "what's the cause of this again flame grass tell the story",
    "start": "1803670",
    "end": "1809240"
  },
  {
    "start": "1805000",
    "end": "1805000"
  },
  {
    "text": "here this is the exact same flame graph generated from just a rel seven system",
    "start": "1809240",
    "end": "1815670"
  },
  {
    "text": "same exact code same exact run type it turns out in rel 7g Lib C changed the",
    "start": "1815670",
    "end": "1822600"
  },
  {
    "text": "way that some memory calls happen so instead of that long M advised call that ended up in that Zen hyper call which",
    "start": "1822600",
    "end": "1829260"
  },
  {
    "text": "ate all our CPU time it's now doing a Intel optimized memory man tasks",
    "start": "1829260",
    "end": "1836000"
  },
  {
    "text": "so the moral of the story is that when you're moving to AWS compile your",
    "start": "1836000",
    "end": "1842550"
  },
  {
    "text": "application or run your application on the latest version of the operating system that it's compatible with and if",
    "start": "1842550",
    "end": "1849030"
  },
  {
    "text": "you can recompile it because it can make a huge difference this customer we even tried bringing",
    "start": "1849030",
    "end": "1854190"
  },
  {
    "text": "over the rl6 binary to Rell seven that was statically compiled and we saw the same problems",
    "start": "1854190",
    "end": "1861260"
  },
  {
    "start": "1861000",
    "end": "1861000"
  },
  {
    "text": "another subject related to memory and this is going to be my last one on memory is to disable transparent huge",
    "start": "1861860",
    "end": "1868650"
  },
  {
    "text": "pages now huge pages they are it is a huge subject so I'm not gonna go into",
    "start": "1868650",
    "end": "1874470"
  },
  {
    "text": "the depths of what huge pages are how they work the link that you see at the bottom of this slide actually it's",
    "start": "1874470",
    "end": "1880530"
  },
  {
    "text": "probably the best article that I found that explains how they work but transparent huge pages are enabled by",
    "start": "1880530",
    "end": "1886710"
  },
  {
    "text": "default on most Linux operating systems disabling transparent huge pages and",
    "start": "1886710",
    "end": "1893420"
  },
  {
    "text": "instead going to an explicit huge page model can significantly boost the performance of any application that's of",
    "start": "1893420",
    "end": "1900900"
  },
  {
    "text": "most applications I should probably say that are accessing a lot of memory so I definitely recommend if you're a memory",
    "start": "1900900",
    "end": "1907560"
  },
  {
    "text": "intensive workload look at huge pages and it's especially explicit",
    "start": "1907560",
    "end": "1913940"
  },
  {
    "start": "1913000",
    "end": "1913000"
  },
  {
    "text": "next I want to talk about IO we have a few different instance families that are",
    "start": "1914570",
    "end": "1919800"
  },
  {
    "text": "optimized for i/o usage we have the I - instance which is an IEEE ops based",
    "start": "1919800",
    "end": "1926270"
  },
  {
    "text": "instance it has a bunch of SSD drives and then we have the d2 instance which is dense storage and uses magnetic but",
    "start": "1926270",
    "end": "1933900"
  },
  {
    "text": "in order to get the best possible performance out of these instances you need to be running a modern Linux kernel",
    "start": "1933900",
    "end": "1939990"
  },
  {
    "text": "and on a modern operating system and the reason for this is because of the split driver model that Xen uses to",
    "start": "1939990",
    "end": "1946560"
  },
  {
    "text": "communicate so let's say you're an application in the upper right that needs to write to a",
    "start": "1946560",
    "end": "1952140"
  },
  {
    "text": "storage device inside of your application or inside of your operating system that application",
    "start": "1952140",
    "end": "1958470"
  },
  {
    "text": "writes to a front end driver that front-end driver then goes through the hypervisor and talks to a back-end",
    "start": "1958470",
    "end": "1964470"
  },
  {
    "text": "driver that back-end driver then has to write to the real physical device driver before sending it down to the storage",
    "start": "1964470",
    "end": "1970980"
  },
  {
    "text": "device from there data transfer happens through shared pages that need to be granted",
    "start": "1970980",
    "end": "1977520"
  },
  {
    "text": "that need permissions to be granted and released and this granting process has a lot of",
    "start": "1977520",
    "end": "1984419"
  },
  {
    "text": "overhead especially on early kernels every time you need to talk to that disk you need to talk to the VM m get",
    "start": "1984419",
    "end": "1990570"
  },
  {
    "text": "permission to write to the vise fill a buffer with the data you want to transfer pass that data back to the",
    "start": "1990570",
    "end": "1996450"
  },
  {
    "text": "backend wait for it to be written and then remove the grant this is a really expensive operation that includes a that",
    "start": "1996450",
    "end": "2004070"
  },
  {
    "text": "involves a lot of buffer flushing that only gets worse the more CPUs that you add to it",
    "start": "2004070",
    "end": "2011260"
  },
  {
    "text": "so to solve this persistent grants were created and with persistent grants the",
    "start": "2011559",
    "end": "2017659"
  },
  {
    "text": "permission to write to that device is actually reused for all the transactions between the front end and the back end",
    "start": "2017659",
    "end": "2024470"
  },
  {
    "text": "driver so grants no need to be unmapped anymore and that translation buffer",
    "start": "2024470",
    "end": "2029539"
  },
  {
    "text": "never needs to be flushed because of this you'll get significantly better performance for all your i/o operations",
    "start": "2029539",
    "end": "2035450"
  },
  {
    "text": "as long as you're running a kernel that supports persistent grants so to validate that you are using",
    "start": "2035450",
    "end": "2042470"
  },
  {
    "start": "2040000",
    "end": "2040000"
  },
  {
    "text": "persistent grants or that they're enabled in your Linux kernel you can simply just run the D message command",
    "start": "2042470",
    "end": "2047899"
  },
  {
    "text": "and grep for the block front driver here you can see I'm running an eye to a Dex",
    "start": "2047899",
    "end": "2052940"
  },
  {
    "text": "large instance and as you can see all of my in all of my volumes have persists and grants enabled",
    "start": "2052940",
    "end": "2060550"
  },
  {
    "text": "so if I haven't said it already using a modern kernel is really important I have",
    "start": "2060609",
    "end": "2066858"
  },
  {
    "text": "a lot of customers that still use sent OS 6 because it's what they've been running their data centers for years but",
    "start": "2066859",
    "end": "2073520"
  },
  {
    "text": "I've seen as much as a 60% performance improvement just by switching your operating system from something that's",
    "start": "2073520",
    "end": "2079760"
  },
  {
    "text": "running a 2.8 kernel or a 2/6 kernel to a 3:10 kernel",
    "start": "2079760",
    "end": "2084820"
  },
  {
    "text": "the kernel that was released with tooth with scent OS 6 was released in 2009 and",
    "start": "2084820",
    "end": "2091358"
  },
  {
    "text": "while it may not always feel like it it was a really long time ago in the cloud computing world so please use a modern",
    "start": "2091359",
    "end": "2098359"
  },
  {
    "text": "operating system with a modern now along the lines of the split driver",
    "start": "2098359",
    "end": "2105680"
  },
  {
    "start": "2102000",
    "end": "2102000"
  },
  {
    "text": "model around it was at the time the c3 launched that we introduced a new way to",
    "start": "2105680",
    "end": "2111170"
  },
  {
    "text": "talk to networked devices and that's enhanced networking now under the hood",
    "start": "2111170",
    "end": "2116270"
  },
  {
    "text": "enhanced networking uses a technology called SR i/o V or single route IO",
    "start": "2116270",
    "end": "2122000"
  },
  {
    "text": "virtualization and what this does is it allows the physical network device to be",
    "start": "2122000",
    "end": "2127610"
  },
  {
    "text": "exposed directly to your operating system so that your calls don't need to go through that hypervisor",
    "start": "2127610",
    "end": "2133390"
  },
  {
    "text": "now to use an enhanced networking it does have a few requirements you do need",
    "start": "2133390",
    "end": "2138560"
  },
  {
    "text": "a special driver to be installed in your operating system and ec2 needs to be told to expose the network device in",
    "start": "2138560",
    "end": "2144710"
  },
  {
    "text": "this different way but as you can see the network path is",
    "start": "2144710",
    "end": "2150050"
  },
  {
    "start": "2147000",
    "end": "2147000"
  },
  {
    "text": "much much simpler packets don't need to go through that hypervisor anymore and because you're talking to bare metal",
    "start": "2150050",
    "end": "2156140"
  },
  {
    "text": "you're going to get a higher rate of packets per second and decrease jitter because the CPU is no longer involved in",
    "start": "2156140",
    "end": "2162440"
  },
  {
    "text": "that process it's free enhanced networking is free on all supported operating on all supported",
    "start": "2162440",
    "end": "2170390"
  },
  {
    "text": "instances and it's enabled by default in most armies however if you're doing an",
    "start": "2170390",
    "end": "2175790"
  },
  {
    "text": "import of a virtual machine from on-premise to ec2 you probably don't have it enabled unless you've explicitly",
    "start": "2175790",
    "end": "2182720"
  },
  {
    "text": "done so I highly recommend it if you're doing anything that touches the network on an ec2 instance",
    "start": "2182720",
    "end": "2190809"
  },
  {
    "start": "2190000",
    "end": "2190000"
  },
  {
    "text": "and when it comes to network performance we're still not done along with the x1 instance we released",
    "start": "2190840",
    "end": "2197630"
  },
  {
    "text": "the next generation of enhanced networking which is called DNA or the elastic network adapter now in a launch",
    "start": "2197630",
    "end": "2205310"
  },
  {
    "text": "with the x1 and it's beginning to roll out on newer and newer instances as we come about so it's on the m416 and the",
    "start": "2205310",
    "end": "2212900"
  },
  {
    "text": "p2 instance but what ena does is it now offers you 20 gigabits of network performance as",
    "start": "2212900",
    "end": "2219950"
  },
  {
    "text": "compared to the 10 that you'd just get with enhanced networking it also has features like hardware checksums and",
    "start": "2219950",
    "end": "2226160"
  },
  {
    "text": "receive side steering give you even more control of the packet processing pipeline so that you can make sure that",
    "start": "2226160",
    "end": "2232310"
  },
  {
    "text": "you're getting the highest rate of packets for a second",
    "start": "2232310",
    "end": "2236740"
  },
  {
    "text": "now when it comes to network performance I want to touch briefly on the subject and we have a deep dive at reinvent that",
    "start": "2237820",
    "end": "2244910"
  },
  {
    "start": "2238000",
    "end": "2238000"
  },
  {
    "text": "I highly recommend that you go to on this but when it comes to networking performance that 20 gigabit and that 10",
    "start": "2244910",
    "end": "2251990"
  },
  {
    "text": "gigabit that you see listed on those instances that only applies to instance to instance communication when those",
    "start": "2251990",
    "end": "2259100"
  },
  {
    "text": "instances are in a placement group but if you do it use placement groups you can actually get by sectional bandwidth",
    "start": "2259100",
    "end": "2265910"
  },
  {
    "text": "out of those instances so that means you can get 20 gigabits out and 20 gigabits in at the same time you'll also need to",
    "start": "2265910",
    "end": "2272570"
  },
  {
    "text": "be using multiple TCP streams to achieve that for things like talking to s3 any",
    "start": "2272570",
    "end": "2279260"
  },
  {
    "text": "network traffic out of ec2 is going to be capped at about five gigabits per second but it's easy to forget that",
    "start": "2279260",
    "end": "2287000"
  },
  {
    "text": "networking throughput is also a function of instant sizes I had a customer who is",
    "start": "2287000",
    "end": "2292430"
  },
  {
    "text": "doing some performance testing with s3 and they weren't getting the performance they were hoping for out of it it turns",
    "start": "2292430",
    "end": "2298220"
  },
  {
    "text": "out their routing all of their Internet traffic through a t2 micro NAT instance which is definitely gonna be your",
    "start": "2298220",
    "end": "2303560"
  },
  {
    "text": "bottleneck so definitely keep in mind the network performance of the instance",
    "start": "2303560",
    "end": "2308930"
  },
  {
    "text": "that you launched and if you care about care about it use iperf to test the throughput from one instance to another",
    "start": "2308930",
    "end": "2315080"
  },
  {
    "text": "in that placement group and just like network performance EBS",
    "start": "2315080",
    "end": "2321320"
  },
  {
    "start": "2317000",
    "end": "2317000"
  },
  {
    "text": "performance is also a factor of instant sizes EBS optimization is a great way to get",
    "start": "2321320",
    "end": "2328340"
  },
  {
    "text": "great EBS performance out of your ec2 instance what it does is it creates a dedicated path for EBS traffic that's",
    "start": "2328340",
    "end": "2335180"
  },
  {
    "text": "separate from your standard network traffic it's actually enabled by default on a lot of our newest instances so if",
    "start": "2335180",
    "end": "2342800"
  },
  {
    "text": "you're doing anything that's requires a lot of heavy storage utilization make sure that you're using EBS optimized now",
    "start": "2342800",
    "end": "2350240"
  },
  {
    "text": "EBS optimized we actually have the chart that you see here is just an excerpt from the EBS optimization pages and this",
    "start": "2350240",
    "end": "2357860"
  },
  {
    "text": "chart will show you that for every instance that supports EBS optimization how much throughput you can get to EBS",
    "start": "2357860",
    "end": "2363560"
  },
  {
    "text": "out of that instance you can see how many I ops you can get out of that so it should definitely be your reference when",
    "start": "2363560",
    "end": "2370970"
  },
  {
    "text": "you're using a workload that uses a heavy that uses EBS heavily",
    "start": "2370970",
    "end": "2377740"
  },
  {
    "text": "so in conclusion there are a lot of things that you can do to get great ec2",
    "start": "2377740",
    "end": "2382850"
  },
  {
    "text": "performance at the bare minimum use a modern operating system make sure you're",
    "start": "2382850",
    "end": "2388430"
  },
  {
    "text": "using an H VM based on me so that you're talking to hardware as much as possible",
    "start": "2388430",
    "end": "2393880"
  },
  {
    "text": "used enhance networking it's free and it's going to significantly increase your packet performance and always",
    "start": "2393880",
    "end": "2401930"
  },
  {
    "text": "profile your application on your instances and test them to see how they'll perform and when it comes to virtualization I",
    "start": "2401930",
    "end": "2409280"
  },
  {
    "start": "2407000",
    "end": "2407000"
  },
  {
    "text": "want to talk onda mention that our goal is to make virtualization as transparent as possible",
    "start": "2409280",
    "end": "2415090"
  },
  {
    "text": "our goal and eliminate any efficiencies that it can cause our goal is to give",
    "start": "2415090",
    "end": "2420890"
  },
  {
    "text": "you bare metal like performance out of your ec2 instance and in a lot of ways we're already there so",
    "start": "2420890",
    "end": "2428470"
  },
  {
    "text": "if you have any questions we actually have a couple of microphones set up if you want to go up and ask",
    "start": "2428680",
    "end": "2434800"
  },
  {
    "text": "otherwise visit the ec2 documentation page and start testing your app",
    "start": "2434800",
    "end": "2441030"
  },
  {
    "text": "[Applause] [Music]",
    "start": "2441030",
    "end": "2446329"
  }
]
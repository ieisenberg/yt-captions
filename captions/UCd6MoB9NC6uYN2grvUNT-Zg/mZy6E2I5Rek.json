[
  {
    "start": "0",
    "end": "45000"
  },
  {
    "text": "thank you all for coming to this very very early session on ec2 my name is",
    "start": "30",
    "end": "6089"
  },
  {
    "text": "Adam Bailen and I'm one of the lead solutions architects on the high-performance computing team here at",
    "start": "6089",
    "end": "11639"
  },
  {
    "text": "AWS and I'm really excited today to talk to you about a subject that I'm really passionate about which is ec2",
    "start": "11639",
    "end": "17580"
  },
  {
    "text": "performance you see I work with customers who are doing things like computational fluid dynamics gene",
    "start": "17580",
    "end": "24420"
  },
  {
    "text": "sequencing and semiconductor design on AWS today and as you can imagine performance is a really important",
    "start": "24420",
    "end": "30750"
  },
  {
    "text": "subject for these types of customers so what I want to do today is share with you some of the things that I've learned",
    "start": "30750",
    "end": "36329"
  },
  {
    "text": "and the things that my customers do on a daily basis in order to get the best possible performance out of the platform",
    "start": "36329",
    "end": "44989"
  },
  {
    "start": "45000",
    "end": "83000"
  },
  {
    "text": "now this presentation it's definitely built to be a deep dive on performance and we're gonna go pretty far into the",
    "start": "45559",
    "end": "52620"
  },
  {
    "text": "you know nitty-gritty of how ec2 works but along the way I want to make sure that I'm highlighting actionable things",
    "start": "52620",
    "end": "59129"
  },
  {
    "text": "that you can walk away with to make sure that you're getting the most out of the platform I also want to talk a little",
    "start": "59129",
    "end": "65729"
  },
  {
    "text": "bit about the process of choosing your ec2 instance because really when it comes to getting the most performance",
    "start": "65729",
    "end": "72299"
  },
  {
    "text": "out of ec2 making sure that you're picking the right instance it's going to be just as important as all the tuning",
    "start": "72299",
    "end": "79229"
  },
  {
    "text": "tips that I give you along the way now ec2 it's a really big subject and",
    "start": "79229",
    "end": "86850"
  },
  {
    "start": "83000",
    "end": "132000"
  },
  {
    "text": "when you talk about ec2 you can talk about a lot of different things you talk about the you know API is and SDKs that",
    "start": "86850",
    "end": "94110"
  },
  {
    "text": "make managing it easier you can talk about the different purchase options like spot or reserved or on-demand I",
    "start": "94110",
    "end": "100320"
  },
  {
    "text": "didn't even talk about the networking direct connects and V PC configurations",
    "start": "100320",
    "end": "105329"
  },
  {
    "text": "that you go to when you actually go to use your instances but today I'm gonna primarily focus on the instances",
    "start": "105329",
    "end": "111659"
  },
  {
    "text": "themselves how they work the the features that they have and the options",
    "start": "111659",
    "end": "116880"
  },
  {
    "text": "that you have when you go to launch them for all those other topics you can find a lot of other sessions here at reinvent",
    "start": "116880",
    "end": "123509"
  },
  {
    "text": "that are going to go a lot deeper than I can into those other ways of managing ec2 and the other components of ec2",
    "start": "123509",
    "end": "131869"
  },
  {
    "start": "132000",
    "end": "149000"
  },
  {
    "text": "so let's dive in and let's start at the basics so what is an easy to instance well easy to instances at their simplest",
    "start": "132220",
    "end": "140080"
  },
  {
    "text": "level their virtual machines so they're guests that are sitting on top of a hypervisor that are sitting on top of a",
    "start": "140080",
    "end": "146590"
  },
  {
    "text": "piece of physical hardware and when we launched our first instance in 2006",
    "start": "146590",
    "end": "153610"
  },
  {
    "start": "149000",
    "end": "187000"
  },
  {
    "text": "almost 10 years ago or more than 10 years ago at this point we didn't give you a lot of choice we gave you what we",
    "start": "153610",
    "end": "161920"
  },
  {
    "text": "called the ec2 instance we didn't really even have a name for it at the time you",
    "start": "161920",
    "end": "167890"
  },
  {
    "text": "don't get to choose how many virtual CPUs it had or how much memory it had you want to launch an instance and this",
    "start": "167890",
    "end": "174610"
  },
  {
    "text": "is what you got now it made the process of choosing your instance a heck of a lot easier but customers they wanted",
    "start": "174610",
    "end": "181810"
  },
  {
    "text": "more flexibility and they wanted more choice so we started iterating on the platform and as you can see we've been",
    "start": "181810",
    "end": "189430"
  },
  {
    "start": "187000",
    "end": "384000"
  },
  {
    "text": "growing and adding a lot of new instances ever since so this is a chart of all of the ec2 instances launched",
    "start": "189430",
    "end": "196420"
  },
  {
    "text": "since that original m1 and as you can see I kind of just ran out of space in 2017 honestly don't know a better way to",
    "start": "196420",
    "end": "203590"
  },
  {
    "text": "visualize this so if you have any ideas I'm all ears but not only have we been adding new instances we've also been",
    "start": "203590",
    "end": "211510"
  },
  {
    "text": "quietly changing how ec2 works underneath the hood so let's take 2011",
    "start": "211510",
    "end": "218440"
  },
  {
    "text": "as an example so we launched the cc2 instance in 2011 and this was actually",
    "start": "218440",
    "end": "223720"
  },
  {
    "text": "the first time that we gave you the ability to choose the physical topology of your ec2 instances within our data",
    "start": "223720",
    "end": "229959"
  },
  {
    "text": "center and we released that feature called placement groups that lets you place your instances as close together",
    "start": "229959",
    "end": "235630"
  },
  {
    "text": "as possible so you'll get the best possible bandwidth and the lowest latency between your instances this was",
    "start": "235630",
    "end": "242290"
  },
  {
    "text": "also the instance that we introduced hardware-assisted virtualization which really enables you to get the best",
    "start": "242290",
    "end": "248019"
  },
  {
    "text": "possible performance out of your ec2 instances and lets us expose more of the physical Hardware of the instance of the",
    "start": "248019",
    "end": "255790"
  },
  {
    "text": "the physical machine to your instance so it's a really big change and enabled a lot of the things that I'm going to talk",
    "start": "255790",
    "end": "262570"
  },
  {
    "text": "about here now ec2 it's always growing and it's always changing",
    "start": "262570",
    "end": "267760"
  },
  {
    "text": "and it's largely based on your feedback as customers and it's important to know",
    "start": "267760",
    "end": "273820"
  },
  {
    "text": "that how we do things in the past may not be the same as how we do things in",
    "start": "273820",
    "end": "278920"
  },
  {
    "text": "the future this is especially the case with something like c5 that we launched recently that I'll go into a little bit",
    "start": "278920",
    "end": "285430"
  },
  {
    "text": "of detail about the changes that we make so make sure that when you're going to",
    "start": "285430",
    "end": "290440"
  },
  {
    "text": "launch an instance or when you're choosing a new instance family or you're looking at you know something that we",
    "start": "290440",
    "end": "295720"
  },
  {
    "text": "just launched check our documentation read the blogs read the FAQ because",
    "start": "295720",
    "end": "300880"
  },
  {
    "text": "it'll tell you what's changed in that instance and how you can expect the behavior to be differently than the in",
    "start": "300880",
    "end": "308200"
  },
  {
    "text": "situ instances that you might be used to now I have a lot of customers who ask me",
    "start": "308200",
    "end": "313210"
  },
  {
    "text": "you know do I have to move to a new instance do I have to upgrade and if you don't want to you don't have to i've",
    "start": "313210",
    "end": "320380"
  },
  {
    "text": "customers you know you can still launch the the m1 instance on ec2 that we",
    "start": "320380",
    "end": "325450"
  },
  {
    "text": "originally launched you know all those years ago but it's only available in the AZ's that it was originally launched in",
    "start": "325450",
    "end": "331780"
  },
  {
    "text": "and we aren't putting new m ones and new you know regions that we come out with but not only you know will you still be",
    "start": "331780",
    "end": "339250"
  },
  {
    "text": "able to launch those instances I suggest that customers upgrade because they get a lot of performance improvements just",
    "start": "339250",
    "end": "344560"
  },
  {
    "text": "by moving to a new instance it's usually as simple as stopping your instance changing the type and starting a backup",
    "start": "344560",
    "end": "350290"
  },
  {
    "text": "or updating your auto scaling group but these new instances and this new hardware it's usually more power",
    "start": "350290",
    "end": "356350"
  },
  {
    "text": "efficient it's usually cheaper for us to operate so what we do is we pass those savings on to you so you may have",
    "start": "356350",
    "end": "362770"
  },
  {
    "text": "noticed when we launched c5 it's actually cheaper than the C for instance and that's just one example we do that",
    "start": "362770",
    "end": "369880"
  },
  {
    "text": "typically with new hardware releases so I highly suggest that you keep up on the latest instance because you'll get",
    "start": "369880",
    "end": "375970"
  },
  {
    "text": "better performance on the platform and typically at a lower cost",
    "start": "375970",
    "end": "381030"
  },
  {
    "start": "384000",
    "end": "453000"
  },
  {
    "text": "so before we dive into the instances themselves I want to just go over briefly you know how we name instances",
    "start": "384140",
    "end": "390050"
  },
  {
    "text": "and how we think about them so here you'd see the name of an instance to see five extra-large instance and we break",
    "start": "390050",
    "end": "398000"
  },
  {
    "text": "this down usually into about three different pieces so that first letter that you see that's the instance family",
    "start": "398000",
    "end": "403370"
  },
  {
    "text": "so this usually stands for the kind of resources an instance has or the workloads that it's best suited for so",
    "start": "403370",
    "end": "410390"
  },
  {
    "text": "you have C that stands for compute R for ram i for i opps m for general purpose",
    "start": "410390",
    "end": "416270"
  },
  {
    "text": "for some reason but that's usually what you'll find the next number that you see",
    "start": "416270",
    "end": "423020"
  },
  {
    "text": "is the instance generation and you can almost think of this like a version number of your ec2 instances so see five",
    "start": "423020",
    "end": "429500"
  },
  {
    "text": "instance is newer than a c for instance which is newer than a c3 instance and the last thing that you see is the",
    "start": "429500",
    "end": "436130"
  },
  {
    "text": "instant size and I've heard these called t-shirt sizes which is a pretty good way of thinking about them so you've got",
    "start": "436130",
    "end": "442040"
  },
  {
    "text": "small medium large all the way up to 32x large which was a massive shirt but it's",
    "start": "442040",
    "end": "448250"
  },
  {
    "text": "really you know it's the same shirt just in different sizes and as you can see",
    "start": "448250",
    "end": "454790"
  },
  {
    "start": "453000",
    "end": "523000"
  },
  {
    "text": "you get a lot of choice and eat a lot of flexibility when you go to launch I know that whatever you're in the console and",
    "start": "454790",
    "end": "460220"
  },
  {
    "text": "you're trying to decide which instance from that massive list that you want to look at it can be a little bit overwhelming but I suggest by first",
    "start": "460220",
    "end": "467150"
  },
  {
    "text": "starting looking at the families that you're interested in and to do that try",
    "start": "467150",
    "end": "472370"
  },
  {
    "text": "to understand or try to think about what your application is constrained by so if",
    "start": "472370",
    "end": "477470"
  },
  {
    "text": "you need a lot of memory an hour for instance is probably the best place to start because it's in the memory",
    "start": "477470",
    "end": "482630"
  },
  {
    "text": "optimized family if you are compute bound you'll want to go with the the C class of instances if you're actually",
    "start": "482630",
    "end": "490250"
  },
  {
    "text": "pretty well balanced or maybe you just don't know what kind of resources you need starting with the general-purpose like the M or the T usually are the best",
    "start": "490250",
    "end": "498650"
  },
  {
    "text": "place to start and then you can keep monitoring your instances and adjusting to a better suited family as you",
    "start": "498650",
    "end": "505010"
  },
  {
    "text": "understand your workload up a little bit better and if you need a little bit of help you can always check our",
    "start": "505010",
    "end": "510650"
  },
  {
    "text": "documentation for each ec2 instance we list the types of workloads that we typically",
    "start": "510650",
    "end": "515729"
  },
  {
    "text": "see customers and use it for so it's a good way to get started if you're just trying to think about it but when you're",
    "start": "515729",
    "end": "524490"
  },
  {
    "start": "523000",
    "end": "592000"
  },
  {
    "text": "looking at all those instances you'll see something that's pretty unique to AWS and that's the virtual CPU or V CPU",
    "start": "524490",
    "end": "531709"
  },
  {
    "text": "now I have a lot of customers who are confused about what a VC pyou is and",
    "start": "531709",
    "end": "536880"
  },
  {
    "text": "it's actually pretty simple so on all modern instances that aren't in the T family and those are special for reasons",
    "start": "536880",
    "end": "543389"
  },
  {
    "text": "I'll talk about later a V CPU is simply a hyper threaded physical core so hyper",
    "start": "543389",
    "end": "549839"
  },
  {
    "text": "threading has been around for a pretty long time it's a really good technology it kind of lets your CPU do two",
    "start": "549839",
    "end": "555959"
  },
  {
    "text": "different things at once so let's say you have one thread that's waiting on i/o you could still serve a web request",
    "start": "555959",
    "end": "561690"
  },
  {
    "text": "to a customer on a different thread but some customers they need to know or they're curious what's the real core",
    "start": "561690",
    "end": "568050"
  },
  {
    "text": "account or what's the physical core count of that box and for most cases you can just take that v CPU number and divide it by two",
    "start": "568050",
    "end": "575180"
  },
  {
    "text": "now if you do need to know how many physical cores you have maybe you have licenses that are constrained by the",
    "start": "575180",
    "end": "581790"
  },
  {
    "text": "number of physical cores on a box you know I check this link that I have on this slide and that'll give you an",
    "start": "581790",
    "end": "587550"
  },
  {
    "text": "up-to-date list of all the instances and their core count so let's give you a",
    "start": "587550",
    "end": "593970"
  },
  {
    "text": "visual representation of what this looks like so here you can see the output of a tool that I like it's called LS topo LST",
    "start": "593970",
    "end": "601560"
  },
  {
    "text": "Opio and it shows you the physical topology of the hardware that you're",
    "start": "601560",
    "end": "606930"
  },
  {
    "text": "using you can run this on bare metal you can run this on AWS and it'll give you a",
    "start": "606930",
    "end": "612630"
  },
  {
    "text": "very similar output so here you can see the output of a m4 10x large instance so",
    "start": "612630",
    "end": "620339"
  },
  {
    "text": "this instance you can see it has two sockets that's the top and bottom things",
    "start": "620339",
    "end": "626069"
  },
  {
    "text": "on the chart here you can see how much memories attached to each socket you can see the level 1 through level 3 cache",
    "start": "626069",
    "end": "631980"
  },
  {
    "text": "and you can even see the CPU thread to physical core mapping and you can see",
    "start": "631980",
    "end": "637139"
  },
  {
    "text": "this because we're exposing that physical topology of the underlying instance or of the underlying hardware",
    "start": "637139",
    "end": "642750"
  },
  {
    "text": "to your instance so you know your threads don't float between cores",
    "start": "642750",
    "end": "649020"
  },
  {
    "text": "so when you see a core or when you see a thread that map's one-to-one to a CPU on",
    "start": "649020",
    "end": "654300"
  },
  {
    "text": "the underlying harbor so there's some",
    "start": "654300",
    "end": "659490"
  },
  {
    "text": "applications that actually don't benefit from hyper threading and the context switching involved can actually slow",
    "start": "659490",
    "end": "665010"
  },
  {
    "text": "down the performance of those applications these are usually pretty compute heavy applications think of",
    "start": "665010",
    "end": "671610"
  },
  {
    "text": "things like financial calculations or engineering simulations things that are just using a lot of compute power maybe",
    "start": "671610",
    "end": "678660"
  },
  {
    "text": "they're just doing a BX or floating point calculations on all systems these",
    "start": "678660",
    "end": "685140"
  },
  {
    "text": "applications typically disable hyper threading and if that's something that you're used to doing you can do that on",
    "start": "685140",
    "end": "691110"
  },
  {
    "text": "ec2 now if you don't usually disable hyper threading or if you don't know you probably don't need to worry about any",
    "start": "691110",
    "end": "696720"
  },
  {
    "text": "of this but if you do you can get that same effect on ec2 it's pretty easy to do on",
    "start": "696720",
    "end": "703650"
  },
  {
    "text": "Linux it's a little bit harder on Windows so with the way that Linux",
    "start": "703650",
    "end": "708870"
  },
  {
    "text": "exposes the physical infrastructure of the CPUs it enumerates as the first set",
    "start": "708870",
    "end": "715920"
  },
  {
    "text": "of threads on each socket first and then the second set of threads second so that",
    "start": "715920",
    "end": "721410"
  },
  {
    "text": "if you want to disable hyper threading all you need to do is disable that second set of threads and you can do",
    "start": "721410",
    "end": "727530"
  },
  {
    "text": "this two different ways and I've listed both of those up here so the first way essentially parses out the CPU mapping",
    "start": "727530",
    "end": "735000"
  },
  {
    "text": "and hot off lines the second thread on each processor this is a pretty good way",
    "start": "735000",
    "end": "741900"
  },
  {
    "text": "of doing it you know you don't need to reboot to have the changes to take effect but I have some customers who are",
    "start": "741900",
    "end": "747840"
  },
  {
    "text": "worried about system instability because you may be disabling processors that threads might be using so a cleaner way",
    "start": "747840",
    "end": "755880"
  },
  {
    "text": "of doing it potentially is to update grub and what you can do is you can set the max CPUs option and grub to be half",
    "start": "755880",
    "end": "762990"
  },
  {
    "text": "the number of virtual CPUs on the box so you just update max CPUs equals whatever",
    "start": "762990",
    "end": "769200"
  },
  {
    "text": "half the V CPU number is update grub and reboot and when your instance comes up hyper threading will be effectively",
    "start": "769200",
    "end": "775620"
  },
  {
    "text": "disabled on Windows it's a little bit difficult because Windows interleaves the threads instead of having you know",
    "start": "775620",
    "end": "782340"
  },
  {
    "text": "the first set of a threads before the B threads so in order to disable hyper threading on Windows you have to use",
    "start": "782340",
    "end": "788460"
  },
  {
    "text": "things like CPU affinity to lock processes to specific physical courts but at the end of the day it'll have the",
    "start": "788460",
    "end": "795330"
  },
  {
    "text": "same effect so let's show you that LS topo output on an m4 10 X large again",
    "start": "795330",
    "end": "801870"
  },
  {
    "start": "797000",
    "end": "815000"
  },
  {
    "text": "but this time with hyper-threading turned off here you can see highlighted in blue each physical CPU of core only",
    "start": "801870",
    "end": "809040"
  },
  {
    "text": "has one thread associated with it as compared to the two that you saw before",
    "start": "809040",
    "end": "814910"
  },
  {
    "start": "815000",
    "end": "893000"
  },
  {
    "text": "now let's talk about the instance sizes and how these sizes work so when we",
    "start": "815870",
    "end": "821280"
  },
  {
    "text": "build instances we build them in a way that makes it pretty easy to scale both horizontally and vertically so let's",
    "start": "821280",
    "end": "828240"
  },
  {
    "text": "take a look the c-5 instance as an example so on the far left you see the c-5 18 X large this is the biggest C 5",
    "start": "828240",
    "end": "835950"
  },
  {
    "text": "instance it has 72 virtual CPUs and it has 144 gigabytes of RAM now that single",
    "start": "835950",
    "end": "843720"
  },
  {
    "text": "C 518 X large is roughly equivalent in size to 2 of the c59 X largest so these",
    "start": "843720",
    "end": "852330"
  },
  {
    "text": "are things like the number of virtual CPUs it has the amount of memory that's available to it even things like the",
    "start": "852330",
    "end": "857820"
  },
  {
    "text": "network bandwidth that's available and this keeps going down the line as you go down each size it roughly cuts the",
    "start": "857820",
    "end": "864600"
  },
  {
    "text": "number of resources that you have in half so you can scale you know if your application needs twice as much power",
    "start": "864600",
    "end": "870840"
  },
  {
    "text": "you can go up just to the next size now for things like the C 5 you know 9 doesn't divide cleanly into by 2 so we",
    "start": "870840",
    "end": "879450"
  },
  {
    "text": "go from a c5 9x large to a c5 4x large and you do have the same proportional",
    "start": "879450",
    "end": "884940"
  },
  {
    "text": "number of CPUs and memory that that CPU to memory ratio stays the same as you change sizes and the reason that we do",
    "start": "884940",
    "end": "895620"
  },
  {
    "start": "893000",
    "end": "985000"
  },
  {
    "text": "this there the reason that we build instances like this is because of how we partition our instances on the physical",
    "start": "895620",
    "end": "902280"
  },
  {
    "text": "infrastructure so typically when you're running the largest size instance you're using an entire physical server the",
    "start": "902280",
    "end": "909690"
  },
  {
    "text": "smaller size is you're just running a fraction of that server depending on what size instance you're running now",
    "start": "909690",
    "end": "915620"
  },
  {
    "text": "virtual has historically gotten a pretty bad reputation that's because in a lot of",
    "start": "915620",
    "end": "921360"
  },
  {
    "text": "environments it's used to over allocate resources so you have more wreath or",
    "start": "921360",
    "end": "926930"
  },
  {
    "text": "instances or more virtual machines than you have physical infrastructure and",
    "start": "926930",
    "end": "931980"
  },
  {
    "text": "you're trying to balance that utilization we use virtualization for a lot of other reasons so one of the",
    "start": "931980",
    "end": "938820"
  },
  {
    "text": "reasons that we use virtualization on AWS is to isolate instances from each other for data protection and also for",
    "start": "938820",
    "end": "946440"
  },
  {
    "text": "resource partitioning you know when we build instances we build them in such a",
    "start": "946440",
    "end": "952140"
  },
  {
    "text": "way that our goal is to provide you with a consistent experience no matter what else is happening on the hardware so",
    "start": "952140",
    "end": "959070"
  },
  {
    "text": "take the BCP use as an example with the exception of the tea family which is",
    "start": "959070",
    "end": "964140"
  },
  {
    "text": "special again for reasons I'll talk about when you're assigned a virtual CPU you're the only customer using that",
    "start": "964140",
    "end": "970290"
  },
  {
    "text": "virtual CPU and you're not sharing it with anyone else on the hardware same thing applies to memory and network",
    "start": "970290",
    "end": "976860"
  },
  {
    "text": "resources we set up these isolations so that you'll get that consistent experience no matter which size that you",
    "start": "976860",
    "end": "982680"
  },
  {
    "text": "pick and the last thing that I want to talk about when it comes to choosing",
    "start": "982680",
    "end": "988290"
  },
  {
    "text": "your instances and I know it's cheesy to quote from your own documentation but I really like the sentiment behind this",
    "start": "988290",
    "end": "994580"
  },
  {
    "text": "it's really easy on ec2 to get an application up and running so instead of",
    "start": "994580",
    "end": "1000350"
  },
  {
    "text": "doing what I see some customers do which is to install a synthetic load testing tool to cut the number of flops or I ops",
    "start": "1000350",
    "end": "1007880"
  },
  {
    "text": "or whatever you get on the hardware install your application and try sending it some realistic load to do some",
    "start": "1007880",
    "end": "1014180"
  },
  {
    "text": "testing so you know if you have a mobile application try to simulate real users navigating your app if you have an HPC",
    "start": "1014180",
    "end": "1021080"
  },
  {
    "text": "application run a common model that you're running not a synthetic benchmark if you have a database try running some",
    "start": "1021080",
    "end": "1027500"
  },
  {
    "text": "you know queries on it by using a real workload you'll actually understand how your application behaves on that",
    "start": "1027500",
    "end": "1034250"
  },
  {
    "text": "hardware and you'll be able to start measuring how the performance scales as you add more instances or as you go up",
    "start": "1034250",
    "end": "1040430"
  },
  {
    "text": "in sizes of your instance so definitely I highly suggest using a real app to do",
    "start": "1040430",
    "end": "1046730"
  },
  {
    "text": "your testing now let's let's dive a little bit deeper into the operating system and on all",
    "start": "1046730",
    "end": "1055110"
  },
  {
    "start": "1049000",
    "end": "1107000"
  },
  {
    "text": "systems timekeeping is an important operation so you know timekeeping or",
    "start": "1055110",
    "end": "1062610"
  },
  {
    "text": "your clock source it's used for things like processing interrupts getting the time of day and measuring performance",
    "start": "1062610",
    "end": "1069559"
  },
  {
    "text": "most a.m. is that you launch on ec2 will use the Zen clock source by default and",
    "start": "1069559",
    "end": "1076440"
  },
  {
    "text": "they do this because it's essentially compatible with almost all of our instance types now with the exception of",
    "start": "1076440",
    "end": "1081659"
  },
  {
    "text": "the c-5 but you know around the Sandy Bridge processor the TSC or time step",
    "start": "1081659",
    "end": "1089399"
  },
  {
    "text": "counter was introduced and what it means is that your timekeeping operations or",
    "start": "1089399",
    "end": "1094830"
  },
  {
    "text": "your your the system calls that are using the clock will now be handled by a",
    "start": "1094830",
    "end": "1100260"
  },
  {
    "text": "piece of physical hardware on your CPU and not the hypervisor which are going to be much much faster so to kind of",
    "start": "1100260",
    "end": "1108149"
  },
  {
    "start": "1107000",
    "end": "1134000"
  },
  {
    "text": "show you an example of this I wrote a really simple application and it just",
    "start": "1108149",
    "end": "1114149"
  },
  {
    "text": "does you know a loop where it does get time of day you know 10,000 times or even more than that now don't get",
    "start": "1114149",
    "end": "1122010"
  },
  {
    "text": "nervous I'm not going to try to actually read every line of code I'm not one of those presenters but this is really just a simple application that I've seen that",
    "start": "1122010",
    "end": "1129389"
  },
  {
    "text": "kind of represents some workloads that I've seen on the platform and here you",
    "start": "1129389",
    "end": "1135720"
  },
  {
    "start": "1134000",
    "end": "1160000"
  },
  {
    "text": "can see I ran that application and I profiled it with s trace I really like s",
    "start": "1135720",
    "end": "1140940"
  },
  {
    "text": "trace because actually shows you the system calls that are being made and how long they take and you know what",
    "start": "1140940",
    "end": "1146549"
  },
  {
    "text": "percentage of the time that they take up and here you can see when I ran this on an instance with the Zen clock source my",
    "start": "1146549",
    "end": "1153269"
  },
  {
    "text": "test took about 10 seconds and as you can see good time of day was up at the top where you'd expect it to now the",
    "start": "1153269",
    "end": "1160769"
  },
  {
    "start": "1160000",
    "end": "1252000"
  },
  {
    "text": "same exact server all I did was I switched the clock source from Zen to TSC and as you can see it went from 10",
    "start": "1160769",
    "end": "1168809"
  },
  {
    "text": "seconds all the way down to 2 seconds and good time of day doesn't even show up on on that report anymore now this is",
    "start": "1168809",
    "end": "1177450"
  },
  {
    "text": "a pretty extreme example for a really simple app but I since some applications have as much as",
    "start": "1177450",
    "end": "1183240"
  },
  {
    "text": "a 40% performance improvement just by changing their clock source from Zenda",
    "start": "1183240",
    "end": "1188250"
  },
  {
    "text": "TSC so how do you do that it's a pretty easy change to make on Linux on Windows",
    "start": "1188250",
    "end": "1194519"
  },
  {
    "text": "you don't have to worry about it it's happy it's handled automatically for you and you can do it two ways just like you",
    "start": "1194519",
    "end": "1201419"
  },
  {
    "text": "can disabling hyper-threading so the first is to do it while the system is running the first command that I have",
    "start": "1201419",
    "end": "1207210"
  },
  {
    "text": "listed shows the current clock source you're using you can echo TSE - the",
    "start": "1207210",
    "end": "1212610"
  },
  {
    "text": "clock source and that'll make that change take effect or if you want it to happen every time you boot the instance",
    "start": "1212610",
    "end": "1218610"
  },
  {
    "text": "you can add the options that I have here into grub and do a reboot now this",
    "start": "1218610",
    "end": "1225299"
  },
  {
    "text": "usually what you'll see the the most difference from this change is for things like you know JVM debugging",
    "start": "1225299",
    "end": "1232340"
  },
  {
    "text": "performance tracing or even some database operations anything that you expect there to be a lot of time keeping",
    "start": "1232340",
    "end": "1238950"
  },
  {
    "text": "calls or measuring of performance and it's a really easy change to make it's",
    "start": "1238950",
    "end": "1244980"
  },
  {
    "text": "free and as far as I've seen there there aren't any downsides to making this change another recent or relatively",
    "start": "1244980",
    "end": "1255240"
  },
  {
    "start": "1252000",
    "end": "1326000"
  },
  {
    "text": "recent change we made to the platform around the time the see for instance is is giving you the ability to control the",
    "start": "1255240",
    "end": "1261000"
  },
  {
    "text": "P and the C states of your instance so let's first talk about C States so C",
    "start": "1261000",
    "end": "1266490"
  },
  {
    "text": "states control the power savings feature of your processor so let's take a C for",
    "start": "1266490",
    "end": "1271710"
  },
  {
    "text": "8x large that's an example because I'd know it I've been using it for a while it's got a base clock speed of 2.9 for",
    "start": "1271710",
    "end": "1278429"
  },
  {
    "text": "your Hertz but it allows you to turbo boost all the way up to 3.5 gigahertz on",
    "start": "1278429",
    "end": "1284250"
  },
  {
    "text": "one or two cores but in order to get that turbo boost it actually needs to let other cores idle down so that the",
    "start": "1284250",
    "end": "1290909"
  },
  {
    "text": "you know total heat output and power threshold of the processor you know it stays stays balanced now it's this is",
    "start": "1290909",
    "end": "1299460"
  },
  {
    "text": "great for when you have a few cores or air applications that need to have very high frequencies but by letting coarse",
    "start": "1299460",
    "end": "1305639"
  },
  {
    "text": "idle down it actually increases the latency of you know using those cores when you actually wouldn't use them so",
    "start": "1305639",
    "end": "1312510"
  },
  {
    "text": "if you have applications where latency is I can you can actually limit how deep those",
    "start": "1312510",
    "end": "1318179"
  },
  {
    "text": "course will idle down by adjusting the Maxie state option and grip the other",
    "start": "1318179",
    "end": "1327899"
  },
  {
    "start": "1326000",
    "end": "1376000"
  },
  {
    "text": "option that you have is adjusting P State on a few of the instances now P State is similar to C States in some",
    "start": "1327899",
    "end": "1334199"
  },
  {
    "text": "ways but what P State does is really define a consistent baseline that that",
    "start": "1334199",
    "end": "1339869"
  },
  {
    "text": "you want your course to be at so this is a good example let's say if you wanted all of your the course on your processor",
    "start": "1339869",
    "end": "1348269"
  },
  {
    "text": "to operate at the same frequency all the time maybe you're sensitive to performance changes or you want to",
    "start": "1348269",
    "end": "1353549"
  },
  {
    "text": "consistent experience all the time game servers are actually a pretty good example of those a lot of game servers",
    "start": "1353549",
    "end": "1360149"
  },
  {
    "text": "operated in loops and they need that loop to happen at the exact same frequency every time it operates so you",
    "start": "1360149",
    "end": "1366149"
  },
  {
    "text": "can set the P state features of your processor to prevent your processor",
    "start": "1366149",
    "end": "1371759"
  },
  {
    "text": "speed from clocking up and down based on demand now let's talk about those T 2 or",
    "start": "1371759",
    "end": "1379889"
  },
  {
    "start": "1376000",
    "end": "1458000"
  },
  {
    "text": "the T instances and why they're special T 2 instances they're really good",
    "start": "1379889",
    "end": "1385139"
  },
  {
    "text": "general-purpose instances and they're in some cases the lowest cost instances",
    "start": "1385139",
    "end": "1390929"
  },
  {
    "text": "available on AWS I think the T 2 nano is about half a cent per hour and they're",
    "start": "1390929",
    "end": "1398009"
  },
  {
    "text": "great for things like websites or databases or developer environments",
    "start": "1398009",
    "end": "1403289"
  },
  {
    "text": "things where your CPU demand actually fluctuates you know over the lifetime of the instance the way the T 2 instances",
    "start": "1403289",
    "end": "1410999"
  },
  {
    "text": "work is when you launch them you get a baseline set of performance and you'll always be you know your instances will",
    "start": "1410999",
    "end": "1418049"
  },
  {
    "text": "always be operating yet at least that baseline and that baseline varies depending on the size of the instance",
    "start": "1418049",
    "end": "1423959"
  },
  {
    "text": "that you're running so the larger instance the the larger the baseline performance but there the magic of T 2",
    "start": "1423959",
    "end": "1429690"
  },
  {
    "text": "is is that you can earn credits for the time that your CPU is idle to let you burst above that baseline so it lets you",
    "start": "1429690",
    "end": "1437429"
  },
  {
    "text": "really get the performance that you need when you need it and not pay for it when you don't we launched the T 2 instances",
    "start": "1437429",
    "end": "1444839"
  },
  {
    "text": "because we saw that most workloads don't 100% of the cpu all the time so the t2",
    "start": "1444839",
    "end": "1451039"
  },
  {
    "text": "instance is a really good way to get that balance to get that performance that you need without paying for it now",
    "start": "1451039",
    "end": "1458679"
  },
  {
    "start": "1458000",
    "end": "1520000"
  },
  {
    "text": "let's talk about how those credits work because this is a subject that customers don't always understand so you can kind",
    "start": "1458679",
    "end": "1466429"
  },
  {
    "text": "of think of CPU credits and a t2 instance like a bucket so when you boot",
    "start": "1466429",
    "end": "1471590"
  },
  {
    "text": "the instance you start with enough credits to do things like boot your operating system and handle the the work",
    "start": "1471590",
    "end": "1477620"
  },
  {
    "text": "that your instance was started up for so and when your applications up and running you'll use credits every time",
    "start": "1477620",
    "end": "1484610"
  },
  {
    "text": "you're using CPU so a single credit will allow you to use a hundred percent of one core for one minute now",
    "start": "1484610",
    "end": "1492889"
  },
  {
    "text": "when the work idles down and in your instance becomes idle you're gonna start earning new credits that they go to fill",
    "start": "1492889",
    "end": "1498500"
  },
  {
    "text": "up that bucket and the rate that you earn those credits is gonna vary depending on the size of the instance so",
    "start": "1498500",
    "end": "1504080"
  },
  {
    "text": "the larger t2 instance you have the more credits you're gonna have that definitely go up credits are also going",
    "start": "1504080",
    "end": "1510049"
  },
  {
    "text": "to expire out of that bucket after 24 hours if they're unused so there is a maximum number of credits that you can",
    "start": "1510049",
    "end": "1516950"
  },
  {
    "text": "have per instance size and so to understand you know whether you are",
    "start": "1516950",
    "end": "1522559"
  },
  {
    "start": "1520000",
    "end": "1591000"
  },
  {
    "text": "using those credits and how much you're using and if you're choosing the right t2 size you'll want to use cloud watch",
    "start": "1522559",
    "end": "1528200"
  },
  {
    "text": "to monitor a few different metrics here you can see two of the important metrics when it comes to CPU credit usage the",
    "start": "1528200",
    "end": "1535940"
  },
  {
    "text": "one in orange is the actual usage so this is gonna spike up as you're using",
    "start": "1535940",
    "end": "1541220"
  },
  {
    "text": "credits on the platform so it'll tell you how many you're using per a minute",
    "start": "1541220",
    "end": "1546250"
  },
  {
    "text": "and the one that you see in blue is your actual CPU credit balance so this is",
    "start": "1546250",
    "end": "1552679"
  },
  {
    "text": "gonna tell you how many credits you have left during your burst bucket or in your",
    "start": "1552679",
    "end": "1558019"
  },
  {
    "text": "burst bucket monitoring your your credit balance is probably the one that you're gonna hook on if you're using t2",
    "start": "1558019",
    "end": "1565159"
  },
  {
    "text": "instances in an auto scaling configuration because whenever you run out of credits your CPU usage is going",
    "start": "1565159",
    "end": "1572600"
  },
  {
    "text": "to drop down to whatever your baseline is and from a cloud watch perspective it's going to look the same as if your",
    "start": "1572600",
    "end": "1577820"
  },
  {
    "text": "instance was idle or using that that level of throughput so monitoring your credit balance over a",
    "start": "1577820",
    "end": "1584000"
  },
  {
    "text": "fleet will tell you when you need to auto scale or add more instances that'll have a higher credit balance next I want",
    "start": "1584000",
    "end": "1593300"
  },
  {
    "start": "1591000",
    "end": "1627000"
  },
  {
    "text": "to talk about x1 instances so x1 instances they're pretty exciting instances here really massive machines",
    "start": "1593300",
    "end": "1599780"
  },
  {
    "text": "with 4 terabytes of RAM and 128 virtual CPUs they're great for things that have",
    "start": "1599780",
    "end": "1606830"
  },
  {
    "text": "a huge memory footprint or even high memory to core ratios with the x1 II",
    "start": "1606830",
    "end": "1611840"
  },
  {
    "text": "instances that we launched you know things like big in memory databases big",
    "start": "1611840",
    "end": "1617390"
  },
  {
    "text": "data processing applications even some HPC workloads are pretty well suited for these x1 family of instances but when",
    "start": "1617390",
    "end": "1628040"
  },
  {
    "start": "1627000",
    "end": "1678000"
  },
  {
    "text": "you have that much memory and when you have a that much that holds that much",
    "start": "1628040",
    "end": "1633980"
  },
  {
    "text": "memory to use making sure that you're using it effectively is a lot more",
    "start": "1633980",
    "end": "1639290"
  },
  {
    "text": "important on any system that has multiple CPU sockets there's a concept",
    "start": "1639290",
    "end": "1644690"
  },
  {
    "text": "called Numa or non-uniform memory access and it allows you to access all the memory across all the sockets you know",
    "start": "1644690",
    "end": "1651350"
  },
  {
    "text": "as if it was just one big memory footprint on Intel systems there's the",
    "start": "1651350",
    "end": "1656960"
  },
  {
    "text": "bus between each socket called a qpi or a quickpath interconnect and this is the",
    "start": "1656960",
    "end": "1662480"
  },
  {
    "text": "the bus that transfers memory from one socket to another now accessing memory",
    "start": "1662480",
    "end": "1668720"
  },
  {
    "text": "in a local socket that your process is running on is always going to be faster than going across that qpi to reading",
    "start": "1668720",
    "end": "1675770"
  },
  {
    "text": "memory in a another socket so it's let's give you a visual representation of what I'm talking about here so let's look at",
    "start": "1675770",
    "end": "1682490"
  },
  {
    "start": "1678000",
    "end": "1716000"
  },
  {
    "text": "in our four 16x large as an example so this is a dual socket box it has 240 4",
    "start": "1682490",
    "end": "1689990"
  },
  {
    "text": "gigabytes of RAM on each socket and between each socket are two different qpi links so let's say you're an",
    "start": "1689990",
    "end": "1697370"
  },
  {
    "text": "application on the Left socket and you're wanting to read memory from the the socket on the right transferring",
    "start": "1697370",
    "end": "1704360"
  },
  {
    "text": "that memory will happen over that qpi now well that's fast its measured in gigatons per second it'll never be as",
    "start": "1704360",
    "end": "1711740"
  },
  {
    "text": "fast as accessing memory that's local - that socket and when you go to things",
    "start": "1711740",
    "end": "1717950"
  },
  {
    "start": "1716000",
    "end": "1756000"
  },
  {
    "text": "like the x1 it gets a lot more complex so the x1 is a for socket system and",
    "start": "1717950",
    "end": "1723799"
  },
  {
    "text": "because of this Numa becomes even more important so compared to that our for instance that I had in the previous",
    "start": "1723799",
    "end": "1730220"
  },
  {
    "text": "slide there's more memory per socket on the x1 II there's almost 2 terabytes of ram",
    "start": "1730220",
    "end": "1736330"
  },
  {
    "text": "sorry I think that's a type of one terabyte of RAM on each socket and",
    "start": "1736330",
    "end": "1742070"
  },
  {
    "text": "there's only one qpi that connects all the sockets because they're 4 of them and they need to be able to transfer",
    "start": "1742070",
    "end": "1747470"
  },
  {
    "text": "memory to each other directly so memory transfers from one socket to another we're gonna take longer on the next one",
    "start": "1747470",
    "end": "1753409"
  },
  {
    "text": "as compared to an r4 so what can you do about this well if you've ever watched",
    "start": "1753409",
    "end": "1759649"
  },
  {
    "start": "1756000",
    "end": "1869000"
  },
  {
    "text": "top on a Linux system you may notice processes moving around from one court",
    "start": "1759649",
    "end": "1764779"
  },
  {
    "text": "to another this is the process scheduler in Linux and Windows has one as well and",
    "start": "1764779",
    "end": "1770539"
  },
  {
    "text": "what it does is it tries to balance the load so that your processes are effectively using all the hardware that",
    "start": "1770539",
    "end": "1777260"
  },
  {
    "text": "you have available to you around the 3.8 series kernel this process scheduler",
    "start": "1777260",
    "end": "1783169"
  },
  {
    "text": "started to take Numa and any into account so it'll try to keep processes in the same Numa zone as the memory that",
    "start": "1783169",
    "end": "1789769"
  },
  {
    "text": "they're accessing but it'll also try to move memory around to be closer to the process the downside of this is that",
    "start": "1789769",
    "end": "1797210"
  },
  {
    "text": "this can actually slow down performance of some applications and this is especially true if you have a large",
    "start": "1797210",
    "end": "1803269"
  },
  {
    "text": "memory pool that spans multiple sockets the when this happens you know the",
    "start": "1803269",
    "end": "1808610"
  },
  {
    "text": "scheduler will spend more time moving processes around than if you just let it",
    "start": "1808610",
    "end": "1813850"
  },
  {
    "text": "tell it to ignore the Numa and lit processes come and go where they're made",
    "start": "1813850",
    "end": "1819279"
  },
  {
    "text": "so to disable this you can do you can do",
    "start": "1819279",
    "end": "1824600"
  },
  {
    "text": "a couple of different things the first option is to set Numa equals off and grub and this is a good use case if you",
    "start": "1824600",
    "end": "1832159"
  },
  {
    "text": "have more memory that fits in one socket and if you don't with the process scheduler to be moving memory around that could impact the performance of",
    "start": "1832159",
    "end": "1838490"
  },
  {
    "text": "your application another option that you have is if you have many processes maybe",
    "start": "1838490",
    "end": "1843529"
  },
  {
    "text": "some that are coming going or or you know that they use the memory footprint that fits within a",
    "start": "1843529",
    "end": "1848870"
  },
  {
    "text": "single socket you can use tools like Numa CTL or process affinity in Windows",
    "start": "1848870",
    "end": "1853880"
  },
  {
    "text": "but to actually bind processes to a specific Numa node or even to a specific",
    "start": "1853880",
    "end": "1858950"
  },
  {
    "text": "physical course since we're exposing that real topology to you so that way they'll always access the memory that's",
    "start": "1858950",
    "end": "1865159"
  },
  {
    "text": "local to them another thing to keep in",
    "start": "1865159",
    "end": "1872299"
  },
  {
    "start": "1869000",
    "end": "1930000"
  },
  {
    "text": "mind is how much your operating system actually impacts the performance of your application and using all systems the",
    "start": "1872299",
    "end": "1883519"
  },
  {
    "text": "the sorry you know using a modern not",
    "start": "1883519",
    "end": "1889519"
  },
  {
    "text": "only is using a modern Linux distribution important but also using a modern Linux kernel is really important",
    "start": "1889519",
    "end": "1896330"
  },
  {
    "text": "so to give you an example of this I was visiting a customer and they were testing a custom application and it used",
    "start": "1896330",
    "end": "1903200"
  },
  {
    "text": "a lot of memory and it was doing a lot of memory allocations and deallocations and they weren't saying as good a",
    "start": "1903200",
    "end": "1908659"
  },
  {
    "text": "performance on AWS as they were saying on their on-premise systems now this application it was really complex it was",
    "start": "1908659",
    "end": "1915440"
  },
  {
    "text": "custom built and benchmarking and testing it took a really long time so I actually found an open-source tool",
    "start": "1915440",
    "end": "1921710"
  },
  {
    "text": "called a busy that had a very similar behavior and I profiled it with a Linux",
    "start": "1921710",
    "end": "1927679"
  },
  {
    "text": "testing tool called perf and here you can see their results of a busy on a Red",
    "start": "1927679",
    "end": "1934279"
  },
  {
    "start": "1930000",
    "end": "1970000"
  },
  {
    "text": "Hat 6 system which is the one that they were testing on so I use proof to",
    "start": "1934279",
    "end": "1939529"
  },
  {
    "text": "profile it and you can see that it was on this specific system you know doing",
    "start": "1939529",
    "end": "1945139"
  },
  {
    "text": "about 12,000 records per second we don't know if that's good or not but we do see that it's using a lot of system time as",
    "start": "1945139",
    "end": "1951440"
  },
  {
    "text": "a as compared to a lot of user time that you'd expect from a well behaved",
    "start": "1951440",
    "end": "1956779"
  },
  {
    "text": "application we'd also see by tracing it with perf that we're doing a there are a lot of page faults happening you know",
    "start": "1956779",
    "end": "1963080"
  },
  {
    "text": "1.4 million in this application on this system so so what's going on here what's",
    "start": "1963080",
    "end": "1969080"
  },
  {
    "text": "actually happening I used the perf output and a tool called old flame graphs that were created by",
    "start": "1969080",
    "end": "1975710"
  },
  {
    "start": "1970000",
    "end": "2019000"
  },
  {
    "text": "Brendan Gregg who's a distinguished distinguished engineer he actually has a talk later today if",
    "start": "1975710",
    "end": "1981440"
  },
  {
    "text": "you want to learn more about this but flame graphs are a really good way of understanding what your application is",
    "start": "1981440",
    "end": "1987290"
  },
  {
    "text": "doing and where they're spending their time so here you can see a busy is the",
    "start": "1987290",
    "end": "1993260"
  },
  {
    "text": "the thread at the bottom and you can see all the system calls it's a little hard to read but these slides will be up on SlideShare you can",
    "start": "1993260",
    "end": "2000610"
  },
  {
    "text": "see all the calls that they make and up at the very top of the stack it ends up in a memory advise call which is an",
    "start": "2000610",
    "end": "2008110"
  },
  {
    "text": "hyper call or sorry it's doing a lot of em advice calls that end up in a Zen",
    "start": "2008110",
    "end": "2013570"
  },
  {
    "text": "hyper call that's taking really the bulk of the time of this application so what",
    "start": "2013570",
    "end": "2019900"
  },
  {
    "start": "2019000",
    "end": "2063000"
  },
  {
    "text": "I did was I took this same exact application same exact instance type and I launched a Red Hat 7 instance",
    "start": "2019900",
    "end": "2026880"
  },
  {
    "text": "recompiled it using Red Hat 7 excuse me and you can see I got significantly",
    "start": "2026880",
    "end": "2032560"
  },
  {
    "text": "better performance just by changing the operating system the amount of Records",
    "start": "2032560",
    "end": "2037900"
  },
  {
    "text": "per second I got went from 12,000 or around 12,000 to 425 thousand records",
    "start": "2037900",
    "end": "2043840"
  },
  {
    "text": "per second and as you can see the system time decreased significantly",
    "start": "2043840",
    "end": "2049540"
  },
  {
    "text": "so it's spending all its time in user space where you'd expect a well-behaved application B and the number of page",
    "start": "2049540",
    "end": "2056470"
  },
  {
    "text": "faults went down from you know a million and a half to only 14,000 so what",
    "start": "2056470",
    "end": "2062560"
  },
  {
    "text": "happened let's check out flame graphs again and this really tells the story so",
    "start": "2062560",
    "end": "2067870"
  },
  {
    "start": "2063000",
    "end": "2129000"
  },
  {
    "text": "this is the exact same flame graph output from the exact same application just compiled and run on a different",
    "start": "2067870",
    "end": "2074320"
  },
  {
    "text": "system and as you can see it's there's a lot fewer calls and a lot less times",
    "start": "2074320",
    "end": "2080710"
  },
  {
    "text": "being spent and what this showed me is actually in the Red Hat 7 the G Lib C",
    "start": "2080710",
    "end": "2086800"
  },
  {
    "text": "version that was being compiled with the application being used by the application instead of making all those",
    "start": "2086800",
    "end": "2092770"
  },
  {
    "text": "M advised calls that end up in the hypervisor they switched to a single Intel optimized call for memory",
    "start": "2092770",
    "end": "2099100"
  },
  {
    "text": "management so that really showed me for this application for the way that it was using changing the operating system made",
    "start": "2099100",
    "end": "2106690"
  },
  {
    "text": "a huge difference and I so I highly recommend that that when you are going to it",
    "start": "2106690",
    "end": "2112010"
  },
  {
    "text": "yes when you're thinking about using your applications use as late of a version of the operating system as you",
    "start": "2112010",
    "end": "2117440"
  },
  {
    "text": "can Red Hat six especially has been around for a really long time and it's not as",
    "start": "2117440",
    "end": "2123140"
  },
  {
    "text": "optimized for the platform yes you know Amazon Linux or even some the new Red Hat releases next let's talk a",
    "start": "2123140",
    "end": "2131600"
  },
  {
    "start": "2129000",
    "end": "2191000"
  },
  {
    "text": "little bit about networking so with the exception of the c-5 instance which I'll",
    "start": "2131600",
    "end": "2138920"
  },
  {
    "text": "talk about a little bit later and ec2 instances by default use the Xen network",
    "start": "2138920",
    "end": "2144500"
  },
  {
    "text": "driver to communicate over the network it's called the net front driver and this driver has a lot of overhead",
    "start": "2144500",
    "end": "2151910"
  },
  {
    "text": "because of the split driver model that Xen uses to communicate so let's say you're an application on the right you",
    "start": "2151910",
    "end": "2157730"
  },
  {
    "text": "need to write some packets what you need to do is you know talk to the front-end driver that's built into your operating",
    "start": "2157730",
    "end": "2163610"
  },
  {
    "text": "system this front-end driver goes through the hypervisor talks to a back-end driver that then has to you",
    "start": "2163610",
    "end": "2170120"
  },
  {
    "text": "know write to the physical the real device driver that then goes across the network this is a pretty CPU intensive",
    "start": "2170120",
    "end": "2176480"
  },
  {
    "text": "process and it limits your total throughput and packets per second that you can get because you have the",
    "start": "2176480",
    "end": "2183620"
  },
  {
    "text": "hypervisor and you have the hypervisor being used for every network packet that",
    "start": "2183620",
    "end": "2189470"
  },
  {
    "text": "you process so what we did is we used a technology called SR io V or single",
    "start": "2189470",
    "end": "2197150"
  },
  {
    "start": "2191000",
    "end": "2252000"
  },
  {
    "text": "route IO virtualization we call it enhanced networking on our instances and",
    "start": "2197150",
    "end": "2202430"
  },
  {
    "text": "what enhanced networking does is it exposes the physical network device directly to the instance so you don't",
    "start": "2202430",
    "end": "2208670"
  },
  {
    "text": "have to have the hypervisor and involved every time you're making a network packet so enhance networking it's",
    "start": "2208670",
    "end": "2215420"
  },
  {
    "text": "available really on all modern instance types it's free to use and it really optimizes that path so that you'll get",
    "start": "2215420",
    "end": "2222800"
  },
  {
    "text": "much better performance and much better throughput on AWS when you're using the",
    "start": "2222800",
    "end": "2228440"
  },
  {
    "text": "network now to use enhanced networking there are a couple of requirements if they make sure that you actually have",
    "start": "2228440",
    "end": "2233990"
  },
  {
    "text": "the network driver for that network card installed in your operating system and you have to tell ec2 that you have that",
    "start": "2233990",
    "end": "2240380"
  },
  {
    "text": "driver installed so that it knows to expose the network card in a different way so there's a flag that",
    "start": "2240380",
    "end": "2245630"
  },
  {
    "text": "you have to flip on your ami or on your ec2 instance to say that you have know that you want to use an enhanced network",
    "start": "2245630",
    "end": "2252789"
  },
  {
    "start": "2252000",
    "end": "2289000"
  },
  {
    "text": "but as you can see the the network path is much simpler when you go to enhance networking because they don't have to",
    "start": "2252789",
    "end": "2259339"
  },
  {
    "text": "transfer through the hypervisor you get decreased jitter because you're talking to the network card itself you know we",
    "start": "2259339",
    "end": "2264859"
  },
  {
    "text": "get a higher rate of packets per second because you don't have that CPU involved in all the processing so enhance",
    "start": "2264859",
    "end": "2271069"
  },
  {
    "text": "networking it's free on all supported instances it's enabled by default in a lot of a mis but especially customers",
    "start": "2271069",
    "end": "2277819"
  },
  {
    "text": "who tend to bring their own or build their own ami or use a VM import it's something that that's easily overlooked",
    "start": "2277819",
    "end": "2284450"
  },
  {
    "text": "and I highly recommend that you enable if you're doing anything that's using the network and when it comes to network",
    "start": "2284450",
    "end": "2292400"
  },
  {
    "start": "2289000",
    "end": "2367000"
  },
  {
    "text": "performance we're still not done improving the network we're constantly making new changes and we launched a new",
    "start": "2292400",
    "end": "2298309"
  },
  {
    "text": "network adapter along with the x1 instance that's been out on all the instances they have come out ever since",
    "start": "2298309",
    "end": "2304880"
  },
  {
    "text": "and that new network card it's called ena or the elastic network adapter now",
    "start": "2304880",
    "end": "2310819"
  },
  {
    "text": "it's an Amazon built network card and an Amazon built network driver and it's going to keep growing with us as we",
    "start": "2310819",
    "end": "2317059"
  },
  {
    "text": "start adding more features to the network one of the the cool things that ena lets us do is that when we",
    "start": "2317059",
    "end": "2323809"
  },
  {
    "text": "originally launched DNA on instances we only supported 20 gigabits per second but with back-end enhancements with",
    "start": "2323809",
    "end": "2330529"
  },
  {
    "text": "enhancements throughout the entire stack we realized that we could offer 25 gigabits to it to all our customers who",
    "start": "2330529",
    "end": "2336650"
  },
  {
    "text": "are using that 20 gigabit interface so essentially overnight we flipped a switch and now there's an instances for",
    "start": "2336650",
    "end": "2343609"
  },
  {
    "text": "free got an extra five gigabits of network throughput without you having to reconfigure your operating system or",
    "start": "2343609",
    "end": "2349430"
  },
  {
    "text": "really make any changes so ena it's really the fastest network that we have available on AWS as other things like",
    "start": "2349430",
    "end": "2356750"
  },
  {
    "text": "hardware checksums and receive side steering that that make it much better and more capable of packet processing so",
    "start": "2356750",
    "end": "2363589"
  },
  {
    "text": "I'm really excited about this network card and while we're talking about",
    "start": "2363589",
    "end": "2369349"
  },
  {
    "start": "2367000",
    "end": "2468000"
  },
  {
    "text": "network performance I want to cover you know what what network performance actually means on AWS so",
    "start": "2369349",
    "end": "2377970"
  },
  {
    "text": "when we show that you know an instance has ten gigabits or twenty five gigabits",
    "start": "2377970",
    "end": "2383099"
  },
  {
    "text": "of network throughput that's actually measured just one way so these instances they have by sectional bandwidth which",
    "start": "2383099",
    "end": "2389910"
  },
  {
    "text": "means that you can do that ten gigabits or twenty five gigabits both in and out at the same time now the smaller",
    "start": "2389910",
    "end": "2397710"
  },
  {
    "text": "instances that are listed as no high moderate or low the amount of throughput",
    "start": "2397710",
    "end": "2403410"
  },
  {
    "text": "available to them is usually a function of the instance size so that the bigger the instance the more network throughput",
    "start": "2403410",
    "end": "2409500"
  },
  {
    "text": "that you have available to you just like I was talking about before now if you actually want to know for those smaller",
    "start": "2409500",
    "end": "2416069"
  },
  {
    "text": "instances how much throughput that you have available I suggest using a tool like iperf that can actually measure and",
    "start": "2416069",
    "end": "2423030"
  },
  {
    "text": "monitor the packet per second performance of your ec2 instances now",
    "start": "2423030",
    "end": "2429750"
  },
  {
    "text": "when you want to get that the ten gigabits or twenty five gigabits from one instance to another you will need to",
    "start": "2429750",
    "end": "2436020"
  },
  {
    "text": "do a little bit more because instance bandwidth is limited to ten gigabits per",
    "start": "2436020",
    "end": "2442710"
  },
  {
    "text": "second for a single TCP stream so if you have applications that need to be able",
    "start": "2442710",
    "end": "2448920"
  },
  {
    "text": "to get more than that that 10 gigabits or more than more than that throughput",
    "start": "2448920",
    "end": "2455010"
  },
  {
    "text": "you'll need to use multiple TCP streams from one instance to another and you can",
    "start": "2455010",
    "end": "2460230"
  },
  {
    "text": "use this a TCP stream is just you know a IP port combination we also made another",
    "start": "2460230",
    "end": "2470400"
  },
  {
    "text": "change to the way network performance works starting with our four instances and going to new instances after that we",
    "start": "2470400",
    "end": "2478950"
  },
  {
    "text": "used to list you know the lower instances or the smaller instances is a low moderate to high performance but",
    "start": "2478950",
    "end": "2486029"
  },
  {
    "text": "with instances starting with the r4 even the smaller instances we're offering you the ability to get up to ten gigabits",
    "start": "2486029",
    "end": "2492450"
  },
  {
    "text": "per second of network throughput and this works in a cpu credit I'm sorry in",
    "start": "2492450",
    "end": "2498180"
  },
  {
    "text": "a credit model that's very similar to the t2 credits so while you get up to",
    "start": "2498180",
    "end": "2503339"
  },
  {
    "text": "ten gigabits you do have a baseline level of throughput that's based on the",
    "start": "2503339",
    "end": "2508500"
  },
  {
    "text": "instance size that you're using and when you're not using Network you",
    "start": "2508500",
    "end": "2514109"
  },
  {
    "text": "earn Network credits to allow you to burst above that baseline up to ten gigabits so it's a really cool change in",
    "start": "2514109",
    "end": "2521189"
  },
  {
    "text": "the platform that allows you to get higher rates of network throughput without having to size up to a larger",
    "start": "2521189",
    "end": "2527279"
  },
  {
    "text": "instance that may have more resources like CPU or network that you don't actually need",
    "start": "2527279",
    "end": "2533959"
  },
  {
    "text": "we also made the change that I talked about around the amount of throughput",
    "start": "2534229",
    "end": "2540539"
  },
  {
    "text": "that you can get per instance so used to be that you can only get that ten gigabits or twenty five gigabits if",
    "start": "2540539",
    "end": "2546119"
  },
  {
    "text": "you're in a placement group together with other ec2 instances but starting around this family we actually offer the",
    "start": "2546119",
    "end": "2552239"
  },
  {
    "text": "ability to get that full bandwidth available on the instances even if you're doing things outside of a",
    "start": "2552239",
    "end": "2557609"
  },
  {
    "text": "placement group or even crossing availability zones so you can actually get twenty five gigabits from one",
    "start": "2557609",
    "end": "2563039"
  },
  {
    "text": "instance to another in different AZ's but to do that you do have to use those multiple TCP flows because each flow is",
    "start": "2563039",
    "end": "2570839"
  },
  {
    "text": "limited to five gigabits when you're not in a placement group and the last thing",
    "start": "2570839",
    "end": "2578880"
  },
  {
    "start": "2576000",
    "end": "2643000"
  },
  {
    "text": "that I want to talk about performance is some of our optimized instance families or our accelerated instance families",
    "start": "2578880",
    "end": "2584599"
  },
  {
    "text": "because these families are things that people don't always think about when it comes to getting performance out of the",
    "start": "2584599",
    "end": "2590699"
  },
  {
    "text": "platform so p3 instances our newest generation of GPU enabled instances so",
    "start": "2590699",
    "end": "2597209"
  },
  {
    "text": "these are really cool instances because they have the Nvidia Volta b100 based GPU in them that's a massive GPU that's",
    "start": "2597209",
    "end": "2604829"
  },
  {
    "text": "really great for accelerated workloads or machine learning applications there's",
    "start": "2604829",
    "end": "2611519"
  },
  {
    "text": "a deep dive on these p3 instances so I'm not going to go into a lot of detail on them but they can offer you know compared to",
    "start": "2611519",
    "end": "2617849"
  },
  {
    "text": "the p2 instance that had the kad GPUs that we launched just a year before them you can get up to two-and-a-half",
    "start": "2617849",
    "end": "2624779"
  },
  {
    "text": "performance improvement for HPC applications or a 14 times perform an improvement for machine learning use",
    "start": "2624779",
    "end": "2631469"
  },
  {
    "text": "cases because the way that they're designed and some of the tensor units they have in them so P 3s are really",
    "start": "2631469",
    "end": "2637229"
  },
  {
    "text": "exciting and since I highly suggest you check out the p3 deep dive if you want to learn more about them",
    "start": "2637229",
    "end": "2642880"
  },
  {
    "text": "in the next instance that is relatively new and it's really unique to AWS is the",
    "start": "2642880",
    "end": "2650230"
  },
  {
    "start": "2643000",
    "end": "2703000"
  },
  {
    "text": "f1 instances so these are FPGA instances and I'm I really like these instances",
    "start": "2650230",
    "end": "2655960"
  },
  {
    "text": "because getting an FPGA used to be a really complicated process we didn't have you know to get one you had to",
    "start": "2655960",
    "end": "2662620"
  },
  {
    "text": "source the board from some place you had this source the the FPGA itself from someplace else",
    "start": "2662620",
    "end": "2667960"
  },
  {
    "text": "and it's really you know a painful process that usually only specialized people or a specialized businesses",
    "start": "2667960",
    "end": "2675000"
  },
  {
    "text": "really started using but with the f1 instance you can get an FPGA that's",
    "start": "2675000",
    "end": "2680680"
  },
  {
    "text": "build by the second and you can use it for whatever applications that you need we've seen it used for you know things",
    "start": "2680680",
    "end": "2687790"
  },
  {
    "text": "like financial computing genomics accelerated search and image processing and definitely check out the f1 workshop",
    "start": "2687790",
    "end": "2695380"
  },
  {
    "text": "and chalk talk that we have to learn how to develop for these F ones to actually improve the performance of your apps and",
    "start": "2695380",
    "end": "2704530"
  },
  {
    "start": "2703000",
    "end": "2927000"
  },
  {
    "text": "you know along this time I've been alluding to the differences that that we've been making with C 5 and C 5 it",
    "start": "2704530",
    "end": "2710890"
  },
  {
    "text": "really is a massive change to the platform we've changed a lot and we're going to talk a little bit at reinvent",
    "start": "2710890",
    "end": "2716980"
  },
  {
    "text": "about some of these changes but I want to talk about from an instance perspective and from an operating",
    "start": "2716980",
    "end": "2722530"
  },
  {
    "text": "perspective what you need to know when you go to launch on C 5 so with C 5 we",
    "start": "2722530",
    "end": "2728740"
  },
  {
    "text": "actually we did change the hypervisor so we're using you know a brand-new very custom KVM based hypervisor on the C 5",
    "start": "2728740",
    "end": "2735880"
  },
  {
    "text": "platform and what this hypervisor does is it allows even more of the resources of the underlying hardware to be exposed",
    "start": "2735880",
    "end": "2743080"
  },
  {
    "text": "to the instance itself but because we're on this new hypervisor because we're not",
    "start": "2743080",
    "end": "2749410"
  },
  {
    "text": "using a Zen anymore we don't have that net front driver so if you go to launch an instance on C 5 that doesn't have",
    "start": "2749410",
    "end": "2755950"
  },
  {
    "text": "enhanced networking for ena enabled you won't be able to get network access and",
    "start": "2755950",
    "end": "2761440"
  },
  {
    "text": "won't be able to do it so make sure that you install it DNA driver and you set the flag on your AMI before you go to",
    "start": "2761440",
    "end": "2768070"
  },
  {
    "text": "launch on the C 5 instance you also need to do something you'll need to disable a",
    "start": "2768070",
    "end": "2774070"
  },
  {
    "text": "feature called predictable network and face names and this is enabled by",
    "start": "2774070",
    "end": "2779730"
  },
  {
    "text": "default on a lot of modern operating systems and what it does is that every time you install a network card into",
    "start": "2779730",
    "end": "2786030"
  },
  {
    "text": "your your Linux OS it'll set that network hard to be unique and always be",
    "start": "2786030",
    "end": "2792060"
  },
  {
    "text": "the same every time you use it so you know let's say you have one card it'll always be zero you add another",
    "start": "2792060",
    "end": "2797280"
  },
  {
    "text": "card it always be eath one the problem with this is if you make an ami on one instance and then you go to launch it on",
    "start": "2797280",
    "end": "2803849"
  },
  {
    "text": "the c-5 there's a different pci address so it'll show up as a different network card so it'll probably show up as eath",
    "start": "2803849",
    "end": "2810060"
  },
  {
    "text": "one or something like that by disabling predictable network interface names your",
    "start": "2810060",
    "end": "2815940"
  },
  {
    "text": "network interfaces will always show up as zero if you only have one interface and then it'll allow you to actually",
    "start": "2815940",
    "end": "2820980"
  },
  {
    "text": "communicate across the network because that's what do you see - is expecting your first network interface to be so",
    "start": "2820980",
    "end": "2827160"
  },
  {
    "text": "there's a few things you have to do and I have them on this side to actually disable predictable network interface",
    "start": "2827160",
    "end": "2832770"
  },
  {
    "text": "manners we're also doing something with different with EBS and we're actually",
    "start": "2832770",
    "end": "2837839"
  },
  {
    "text": "exposing EBS as an nvme device and this has some few changes that you'll need to",
    "start": "2837839",
    "end": "2844560"
  },
  {
    "text": "be aware of as well so the nvme driver that's built into Linux it's constantly",
    "start": "2844560",
    "end": "2850140"
  },
  {
    "text": "improving with new kernel releases so you know so you'll need to make sure that you're on the latest one to get the",
    "start": "2850140",
    "end": "2855990"
  },
  {
    "text": "best possible performance out of EBS and out of anytime you're using an nvme device but you'll also need to keep in",
    "start": "2855990",
    "end": "2863310"
  },
  {
    "text": "mind that nvme devices are named differently than the traditional dev SDA whatever so they'll show up as dev and",
    "start": "2863310",
    "end": "2871050"
  },
  {
    "text": "via me something so to make sure that your am eyes will launch and work on",
    "start": "2871050",
    "end": "2876180"
  },
  {
    "text": "different operating systems make sure that you're using uu IDs or labels",
    "start": "2876180",
    "end": "2881460"
  },
  {
    "text": "instead of actually the dev SD mapping and at ZFS tab that you might be used to",
    "start": "2881460",
    "end": "2887250"
  },
  {
    "text": "before another thing to keep in mind and we don't have a lot of customers that",
    "start": "2887250",
    "end": "2892410"
  },
  {
    "text": "that run into this but you can have a maximum number of 27 PCI devices",
    "start": "2892410",
    "end": "2897750"
  },
  {
    "text": "attached to an ec2 instance with the C 5 family today and because EBS and network",
    "start": "2897750",
    "end": "2904560"
  },
  {
    "text": "both show up as a PCI device that means the total number of network or storage devices that you can have is",
    "start": "2904560",
    "end": "2912230"
  },
  {
    "text": "27 in total added together you also need",
    "start": "2912230",
    "end": "2917400"
  },
  {
    "text": "to make sure that because we're using a CPI to send shutdown signals to your OS via of the a CPI daemon installed and",
    "start": "2917400",
    "end": "2924690"
  },
  {
    "text": "running on here of us so if I haven't said it enough using a modern kernel",
    "start": "2924690",
    "end": "2931800"
  },
  {
    "start": "2927000",
    "end": "2957000"
  },
  {
    "text": "it's really important on the platform I've seen some customers get as much as a 40 percent performance improvement",
    "start": "2931800",
    "end": "2938340"
  },
  {
    "text": "just by upgrading from Red Hat 6 to Red Hat 7 and the 2.6 kernel and sent OS 6",
    "start": "2938340",
    "end": "2944610"
  },
  {
    "text": "was in Red Hat 6 was released in 2009 well it doesn't always feel like it that",
    "start": "2944610",
    "end": "2950010"
  },
  {
    "text": "was a really long time ago especially in the cloud and the last",
    "start": "2950010",
    "end": "2958620"
  },
  {
    "start": "2957000",
    "end": "3018000"
  },
  {
    "text": "thing that I want to cover is EBS performance an EBS performance is",
    "start": "2958620",
    "end": "2964680"
  },
  {
    "text": "similar to network performance in a lot of ways in that it scales with the size of the instance that you have so the",
    "start": "2964680",
    "end": "2971100"
  },
  {
    "text": "larger instance that you have the larger EBS throughput that you have one of the",
    "start": "2971100",
    "end": "2976770"
  },
  {
    "text": "the cool things that we have and I have the link here on the slide is a chart of EBS performance that you can expect out",
    "start": "2976770",
    "end": "2982890"
  },
  {
    "text": "of each instance size given enough EBS volumes so you can see the the max bandwidth you'll get to EBS and the max",
    "start": "2982890",
    "end": "2990120"
  },
  {
    "text": "throughput and I ops that you'll be able to expect out of a given instance size and to get that you'll often have to",
    "start": "2990120",
    "end": "2996630"
  },
  {
    "text": "raid multiple volumes together to be able to fully utilize that instance it's",
    "start": "2996630",
    "end": "3002330"
  },
  {
    "text": "also a great place to go for some new information that we have about burstable",
    "start": "3002330",
    "end": "3007850"
  },
  {
    "text": "EBS performance that was introduced the c-5 instance so you'll go you can get",
    "start": "3007850",
    "end": "3013070"
  },
  {
    "text": "more detail there or attend the EBS deep dive to understand a lot more about that",
    "start": "3013070",
    "end": "3018820"
  },
  {
    "start": "3018000",
    "end": "3037000"
  },
  {
    "text": "so in conclusion there's a lot of things that you can do to really optimize your ec2 experience make sure that your",
    "start": "3018820",
    "end": "3026030"
  },
  {
    "text": "benchmarking your real application you're using a modern operating system and you have enhanced networking",
    "start": "3026030",
    "end": "3031820"
  },
  {
    "text": "available or enabled to get the best network performance out of the platform",
    "start": "3031820",
    "end": "3037640"
  },
  {
    "text": "and when it comes to virtualization our goal is really to make virtualization as transparent as possible and to eliminate",
    "start": "3037640",
    "end": "3044359"
  },
  {
    "text": "any and to eliminate any inefficiencies that it may cause our goal is to provide",
    "start": "3044359",
    "end": "3049999"
  },
  {
    "text": "you with bare metal like performance and in a lot of ways we're already there so",
    "start": "3049999",
    "end": "3055749"
  },
  {
    "start": "3055000",
    "end": "3073000"
  },
  {
    "text": "if you have any questions there's some microphones up here or I'll be you know on the stage or outside after this but",
    "start": "3055749",
    "end": "3063289"
  },
  {
    "text": "otherwise launch an instance and start testing your apps thank you [Applause]",
    "start": "3063289",
    "end": "3069310"
  },
  {
    "text": "[Music]",
    "start": "3069310",
    "end": "3072489"
  }
]
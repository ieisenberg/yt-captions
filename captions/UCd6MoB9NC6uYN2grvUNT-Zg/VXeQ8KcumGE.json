[
  {
    "text": "query the data in Amazon s3 data Lake",
    "start": "0",
    "end": "3290"
  },
  {
    "text": "prom Amazon redshift by writing queries",
    "start": "3290",
    "end": "6089"
  },
  {
    "text": "using the Amazon redshift spectrum",
    "start": "6089",
    "end": "8910"
  },
  {
    "text": "capability",
    "start": "8910",
    "end": "11059"
  },
  {
    "text": "however many of our customers they want",
    "start": "11059",
    "end": "14719"
  },
  {
    "text": "to export the data from Amazon redshift",
    "start": "14719",
    "end": "19759"
  },
  {
    "text": "data warehouse to the data linked to s3",
    "start": "19759",
    "end": "24529"
  },
  {
    "text": "to close the loop so that they can use",
    "start": "24529",
    "end": "27500"
  },
  {
    "text": "the data with other services in the",
    "start": "27500",
    "end": "33739"
  },
  {
    "text": "Amazon s3 data lake",
    "start": "33739",
    "end": "35870"
  },
  {
    "text": "such as",
    "start": "35870",
    "end": "38050"
  },
  {
    "text": "Athena or EMR or spark or hive and they",
    "start": "38050",
    "end": "44050"
  },
  {
    "text": "want to export this data in Apache Park",
    "start": "44050",
    "end": "49000"
  },
  {
    "text": "a farmer so Apache Park a is a very",
    "start": "49000",
    "end": "52210"
  },
  {
    "text": "popular open-source format that is used",
    "start": "52210",
    "end": "55809"
  },
  {
    "text": "by many many products we provide ability",
    "start": "55809",
    "end": "62110"
  },
  {
    "text": "to export this command using the onload",
    "start": "62110",
    "end": "65860"
  },
  {
    "text": "command and what I am going to do is a",
    "start": "65860",
    "end": "69460"
  },
  {
    "text": "quick demonstration of how you can use",
    "start": "69460",
    "end": "72759"
  },
  {
    "text": "the data like export capability of",
    "start": "72759",
    "end": "74920"
  },
  {
    "text": "Amazon redshift",
    "start": "74920",
    "end": "78000"
  },
  {
    "text": "you",
    "start": "79810",
    "end": "81860"
  },
  {
    "text": "as you can see here this is the new",
    "start": "81860",
    "end": "84950"
  },
  {
    "text": "query editor",
    "start": "84950",
    "end": "87210"
  },
  {
    "text": "the query returned allows you to browse",
    "start": "87210",
    "end": "90150"
  },
  {
    "text": "different schemas appear read saved data",
    "start": "90150",
    "end": "96030"
  },
  {
    "text": "warehouse as you can see here I have a",
    "start": "96030",
    "end": "98520"
  },
  {
    "text": "schema called s3 the s3 schema is",
    "start": "98520",
    "end": "103350"
  },
  {
    "text": "actually has tables the external table",
    "start": "103350",
    "end": "106890"
  },
  {
    "text": "and the data is in in s3 I can actually",
    "start": "106890",
    "end": "112320"
  },
  {
    "text": "view preview the data form using the",
    "start": "112320",
    "end": "117380"
  },
  {
    "text": "like a normal table as you can see I",
    "start": "117380",
    "end": "119940"
  },
  {
    "text": "have normal table or else I can query",
    "start": "119940",
    "end": "123119"
  },
  {
    "text": "the data so assume that I am trying to",
    "start": "123119",
    "end": "127080"
  },
  {
    "text": "join a table that s3 sales table is an",
    "start": "127080",
    "end": "131910"
  },
  {
    "text": "s3 the data is an s3 and and then I have",
    "start": "131910",
    "end": "135660"
  },
  {
    "text": "this event our table that is in Amazon",
    "start": "135660",
    "end": "140670"
  },
  {
    "text": "directs it so I want to join this table",
    "start": "140670",
    "end": "143250"
  },
  {
    "text": "and run some queries let's take a look",
    "start": "143250",
    "end": "148420"
  },
  {
    "text": "when I click run is going to execute the",
    "start": "148420",
    "end": "152020"
  },
  {
    "text": "query and give me the data as you see",
    "start": "152020",
    "end": "156040"
  },
  {
    "text": "here I have I'm looking at the top",
    "start": "156040",
    "end": "159130"
  },
  {
    "text": "tendrils that means I'm looking at the",
    "start": "159130",
    "end": "162100"
  },
  {
    "text": "top ten events by by sales and and this",
    "start": "162100",
    "end": "168010"
  },
  {
    "text": "kind of helps me demonstrate how you can",
    "start": "168010",
    "end": "171459"
  },
  {
    "text": "use the data like capability of Amazon",
    "start": "171459",
    "end": "174550"
  },
  {
    "text": "redshift you can actually visually",
    "start": "174550",
    "end": "177790"
  },
  {
    "text": "analyze this data in here too",
    "start": "177790",
    "end": "182069"
  },
  {
    "text": "but main capability that we introduced",
    "start": "182500",
    "end": "185440"
  },
  {
    "text": "at Amazon",
    "start": "185440",
    "end": "188880"
  },
  {
    "text": "the capability that we introduced at AWS",
    "start": "189170",
    "end": "193970"
  },
  {
    "text": "reinvent is ability to export your data",
    "start": "193970",
    "end": "197300"
  },
  {
    "text": "and I'm going to demonstrate how you can",
    "start": "197300",
    "end": "201460"
  },
  {
    "text": "export your data using and the unload",
    "start": "201460",
    "end": "206150"
  },
  {
    "text": "command so as you can see here what I am",
    "start": "206150",
    "end": "208550"
  },
  {
    "text": "doing is that I am exporting the data",
    "start": "208550",
    "end": "211640"
  },
  {
    "text": "from the sales table which are a little",
    "start": "211640",
    "end": "215180"
  },
  {
    "text": "bit older like data ID is less than -",
    "start": "215180",
    "end": "218230"
  },
  {
    "text": "1970 so and and then I am exporting this",
    "start": "218230",
    "end": "222290"
  },
  {
    "text": "to this bucket in my s3 Amazon s3 and",
    "start": "222290",
    "end": "227239"
  },
  {
    "text": "I'm using exporting this data in a parka",
    "start": "227239",
    "end": "231170"
  },
  {
    "text": "format and Amazon redshift allows you to",
    "start": "231170",
    "end": "235459"
  },
  {
    "text": "partition the data by date ID and you",
    "start": "235459",
    "end": "239090"
  },
  {
    "text": "have to provide your I am credentials so",
    "start": "239090",
    "end": "241880"
  },
  {
    "text": "and then I can do run this command let's",
    "start": "241880",
    "end": "247010"
  },
  {
    "text": "say I want to do sales 3 and I'll run",
    "start": "247010",
    "end": "250760"
  },
  {
    "text": "this command so when you run this",
    "start": "250760",
    "end": "253010"
  },
  {
    "text": "command what is doing is that it is",
    "start": "253010",
    "end": "255769"
  },
  {
    "text": "going to export the data into Amazon s3",
    "start": "255769",
    "end": "262200"
  },
  {
    "text": "so let me look at my Amazon s3 console",
    "start": "262200",
    "end": "269420"
  },
  {
    "text": "if you see here it already created as3",
    "start": "271830",
    "end": "275009"
  },
  {
    "text": "polder and f sorry a sales 3 folder and",
    "start": "275009",
    "end": "279330"
  },
  {
    "text": "you see these it also created the file",
    "start": "279330",
    "end": "282800"
  },
  {
    "text": "folder and he actually has the partition",
    "start": "282800",
    "end": "286319"
  },
  {
    "text": "ID 1827",
    "start": "286319",
    "end": "289700"
  },
  {
    "text": "there was a quick demo of data lake",
    "start": "289700",
    "end": "293210"
  },
  {
    "text": "capability",
    "start": "293210",
    "end": "295870"
  }
]
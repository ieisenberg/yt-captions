[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "hello everyone and welcome to AWS is",
    "start": "859",
    "end": "3659"
  },
  {
    "text": "hands-on with deep racer we're going to",
    "start": "3659",
    "end": "6720"
  },
  {
    "text": "get started with a bit of history about",
    "start": "6720",
    "end": "8550"
  },
  {
    "text": "deep race here and then move into",
    "start": "8550",
    "end": "10019"
  },
  {
    "text": "reinforcement learning basics from there",
    "start": "10019",
    "end": "12600"
  },
  {
    "text": "we'll begin discussing what the",
    "start": "12600",
    "end": "13950"
  },
  {
    "text": "simulation looks like in AWS followed by",
    "start": "13950",
    "end": "16439"
  },
  {
    "text": "what that looks like when you bring your",
    "start": "16439",
    "end": "17699"
  },
  {
    "text": "model to an event and have it run the",
    "start": "17699",
    "end": "19560"
  },
  {
    "text": "course will wrap up by taking a quick",
    "start": "19560",
    "end": "22199"
  },
  {
    "text": "look at the deep racer car itself first",
    "start": "22199",
    "end": "25919"
  },
  {
    "text": "let's discuss the origins of AWS deep",
    "start": "25919",
    "end": "28619"
  },
  {
    "text": "racer deep racer was founded on the",
    "start": "28619",
    "end": "32099"
  },
  {
    "text": "principle of helping developers",
    "start": "32099",
    "end": "33719"
  },
  {
    "text": "programmers and IT businesses better",
    "start": "33719",
    "end": "36390"
  },
  {
    "text": "understand how artificial intelligence",
    "start": "36390",
    "end": "38609"
  },
  {
    "text": "machine learning and reinforcement",
    "start": "38609",
    "end": "40980"
  },
  {
    "text": "learning work using virtual and physical",
    "start": "40980",
    "end": "43260"
  },
  {
    "text": "models deep racer has three main",
    "start": "43260",
    "end": "47399"
  },
  {
    "start": "46000",
    "end": "46000"
  },
  {
    "text": "components the car which is a",
    "start": "47399",
    "end": "49910"
  },
  {
    "text": "one-fifteenth scale fully autonomous",
    "start": "49910",
    "end": "52859"
  },
  {
    "text": "vehicle complete with a monster truck",
    "start": "52859",
    "end": "54749"
  },
  {
    "text": "chassis a virtual simulator that allows",
    "start": "54749",
    "end": "58289"
  },
  {
    "text": "your machine learning program to train",
    "start": "58289",
    "end": "59850"
  },
  {
    "text": "itself on and a league where people can",
    "start": "59850",
    "end": "63059"
  },
  {
    "text": "post their best times discuss new ways",
    "start": "63059",
    "end": "64860"
  },
  {
    "text": "to teach their vehicles and compete",
    "start": "64860",
    "end": "67790"
  },
  {
    "text": "let's discuss a bit more about the",
    "start": "67790",
    "end": "70380"
  },
  {
    "start": "68000",
    "end": "68000"
  },
  {
    "text": "mentality that goes in the machine",
    "start": "70380",
    "end": "71940"
  },
  {
    "text": "learning towards deep racer to begin",
    "start": "71940",
    "end": "74220"
  },
  {
    "text": "with we have a model which is really",
    "start": "74220",
    "end": "75780"
  },
  {
    "text": "just the concept of deep racer to raise",
    "start": "75780",
    "end": "78570"
  },
  {
    "text": "autonomous cars around a track that",
    "start": "78570",
    "end": "81120"
  },
  {
    "text": "leads to the agent which is the car",
    "start": "81120",
    "end": "82920"
  },
  {
    "text": "itself the action portion of this",
    "start": "82920",
    "end": "85170"
  },
  {
    "text": "formula is where things can get kind of",
    "start": "85170",
    "end": "86970"
  },
  {
    "text": "tricky and where artificial intelligence",
    "start": "86970",
    "end": "89220"
  },
  {
    "text": "will need to come into play the deep",
    "start": "89220",
    "end": "91500"
  },
  {
    "text": "racer goal is to correctly guess and",
    "start": "91500",
    "end": "93630"
  },
  {
    "text": "understand the best course of action for",
    "start": "93630",
    "end": "95880"
  },
  {
    "text": "each step it takes based on the current",
    "start": "95880",
    "end": "98730"
  },
  {
    "text": "state of the vehicle for example in this",
    "start": "98730",
    "end": "101580"
  },
  {
    "text": "slide on the state portion we see that",
    "start": "101580",
    "end": "103980"
  },
  {
    "text": "the car is able to perceive that it's",
    "start": "103980",
    "end": "105750"
  },
  {
    "text": "going around a curve and is aiming to",
    "start": "105750",
    "end": "107970"
  },
  {
    "text": "get into the inside of that curve to",
    "start": "107970",
    "end": "109890"
  },
  {
    "text": "maximize speed these combinations of",
    "start": "109890",
    "end": "112980"
  },
  {
    "text": "states generate an environment by which",
    "start": "112980",
    "end": "115380"
  },
  {
    "text": "the vehicle will need to successfully",
    "start": "115380",
    "end": "117330"
  },
  {
    "text": "complete its task to reach the goal",
    "start": "117330",
    "end": "121370"
  },
  {
    "text": "let's move on to reinforcement learning",
    "start": "121790",
    "end": "124050"
  },
  {
    "text": "or RL reinforcement learning is part of",
    "start": "124050",
    "end": "128399"
  },
  {
    "text": "the bigger artificial intelligence",
    "start": "128400",
    "end": "130380"
  },
  {
    "text": "umbrella of computing particularly in",
    "start": "130380",
    "end": "133080"
  },
  {
    "text": "the machine learning portion machine",
    "start": "133080",
    "end": "135600"
  },
  {
    "text": "learning is the act of giving examples",
    "start": "135600",
    "end": "137730"
  },
  {
    "text": "of data to a machine and allowing it to",
    "start": "137730",
    "end": "139920"
  },
  {
    "text": "possess them with a goal in mind when we",
    "start": "139920",
    "end": "143010"
  },
  {
    "text": "discuss machine learning we typically",
    "start": "143010",
    "end": "145020"
  },
  {
    "text": "are discussing three disciplines",
    "start": "145020",
    "end": "146930"
  },
  {
    "text": "supervised learning is an m/l that uses",
    "start": "146930",
    "end": "150390"
  },
  {
    "text": "labels to generate a deeper",
    "start": "150390",
    "end": "152010"
  },
  {
    "text": "understanding of what that particular",
    "start": "152010",
    "end": "153690"
  },
  {
    "text": "dataset has in common with itself for",
    "start": "153690",
    "end": "156570"
  },
  {
    "text": "instance facial recognition software",
    "start": "156570",
    "end": "158370"
  },
  {
    "text": "might use names for labels on people's",
    "start": "158370",
    "end": "161070"
  },
  {
    "text": "pictures to help the Machine learn who",
    "start": "161070",
    "end": "162840"
  },
  {
    "text": "is whom unsupervised learning is",
    "start": "162840",
    "end": "165810"
  },
  {
    "text": "essentially the same thing but without",
    "start": "165810",
    "end": "167940"
  },
  {
    "text": "the use of labels so raw data may come",
    "start": "167940",
    "end": "170550"
  },
  {
    "text": "through and it will be up to the",
    "start": "170550",
    "end": "172440"
  },
  {
    "text": "algorithms inside of the ML model to",
    "start": "172440",
    "end": "176010"
  },
  {
    "text": "determine what that data means a good",
    "start": "176010",
    "end": "178920"
  },
  {
    "text": "use of this might be log data coming",
    "start": "178920",
    "end": "180840"
  },
  {
    "text": "from a series of computers where the ML",
    "start": "180840",
    "end": "183150"
  },
  {
    "text": "model might read this data and interpret",
    "start": "183150",
    "end": "185160"
  },
  {
    "text": "various generalizations such as the time",
    "start": "185160",
    "end": "187500"
  },
  {
    "text": "of day when allocations get hit the",
    "start": "187500",
    "end": "189000"
  },
  {
    "text": "hardest or when someone could be",
    "start": "189000",
    "end": "190800"
  },
  {
    "text": "attempting to hack into the system based",
    "start": "190800",
    "end": "192690"
  },
  {
    "text": "off of anomalies reinforcement learning",
    "start": "192690",
    "end": "196530"
  },
  {
    "text": "is what we'll be focusing on with deep",
    "start": "196530",
    "end": "198330"
  },
  {
    "text": "racer reinforcement learning provides",
    "start": "198330",
    "end": "200850"
  },
  {
    "text": "data to a model that you've built that",
    "start": "200850",
    "end": "203070"
  },
  {
    "text": "then takes actions against that data to",
    "start": "203070",
    "end": "205470"
  },
  {
    "text": "provide the best possible outcome using",
    "start": "205470",
    "end": "207540"
  },
  {
    "text": "trial and error a good example of",
    "start": "207540",
    "end": "209970"
  },
  {
    "text": "reinforcement learning might be your",
    "start": "209970",
    "end": "211500"
  },
  {
    "text": "favorite app application on your phone",
    "start": "211500",
    "end": "212930"
  },
  {
    "text": "when you ask it for directions it will",
    "start": "212930",
    "end": "215640"
  },
  {
    "text": "run a series of trial and error",
    "start": "215640",
    "end": "217200"
  },
  {
    "text": "calculations to get you to your",
    "start": "217200",
    "end": "219390"
  },
  {
    "text": "destination and as little time as",
    "start": "219390",
    "end": "221010"
  },
  {
    "text": "possible we actually do reinforcement",
    "start": "221010",
    "end": "225780"
  },
  {
    "text": "learning in the real world all the time",
    "start": "225780",
    "end": "227370"
  },
  {
    "text": "from high fives for a job well done to",
    "start": "227370",
    "end": "230520"
  },
  {
    "text": "teaching your dog to sit by using treats",
    "start": "230520",
    "end": "232320"
  },
  {
    "text": "we reward one another for positive or",
    "start": "232320",
    "end": "234900"
  },
  {
    "text": "beneficial behavior the inverse of that",
    "start": "234900",
    "end": "237630"
  },
  {
    "text": "is to also let one another know when",
    "start": "237630",
    "end": "239970"
  },
  {
    "text": "we've done something wrong",
    "start": "239970",
    "end": "241290"
  },
  {
    "text": "usually in the form of punishment or",
    "start": "241290",
    "end": "242940"
  },
  {
    "text": "consequence for that bad action",
    "start": "242940",
    "end": "246569"
  },
  {
    "text": "if we go back to our formula from before",
    "start": "246569",
    "end": "249120"
  },
  {
    "text": "our agent is now in an environment where",
    "start": "249120",
    "end": "252150"
  },
  {
    "start": "251000",
    "end": "251000"
  },
  {
    "text": "it's up against the particular state",
    "start": "252150",
    "end": "253889"
  },
  {
    "text": "where it must choose an action we use",
    "start": "253889",
    "end": "257039"
  },
  {
    "text": "positive reinforcement in the form of",
    "start": "257039",
    "end": "259109"
  },
  {
    "text": "rewards to tell it to try an action the",
    "start": "259109",
    "end": "263009"
  },
  {
    "text": "first time it tries it might not receive",
    "start": "263009",
    "end": "264870"
  },
  {
    "text": "many points the next time same thing but",
    "start": "264870",
    "end": "268590"
  },
  {
    "text": "the time after that it could find a",
    "start": "268590",
    "end": "270300"
  },
  {
    "text": "proper way to say take a turn and it",
    "start": "270300",
    "end": "273419"
  },
  {
    "text": "gets rewarded with a certain number of",
    "start": "273419",
    "end": "275070"
  },
  {
    "text": "points for doing that each of these",
    "start": "275070",
    "end": "277740"
  },
  {
    "text": "attempts from the time the car starts",
    "start": "277740",
    "end": "279900"
  },
  {
    "text": "from the start line to when it either",
    "start": "279900",
    "end": "283979"
  },
  {
    "text": "fails or crosses the finish line are",
    "start": "283979",
    "end": "285960"
  },
  {
    "text": "called episodes and when compiled",
    "start": "285960",
    "end": "288870"
  },
  {
    "text": "generate a way for the agent to operate",
    "start": "288870",
    "end": "291360"
  },
  {
    "text": "in an opportunity the reward function is",
    "start": "291360",
    "end": "295229"
  },
  {
    "text": "the main conduit by which the car is",
    "start": "295229",
    "end": "297509"
  },
  {
    "text": "learning how to drive thus you'll find",
    "start": "297509",
    "end": "300060"
  },
  {
    "start": "299000",
    "end": "299000"
  },
  {
    "text": "yourself working in this portion of the",
    "start": "300060",
    "end": "301800"
  },
  {
    "text": "model the most let's break it down with",
    "start": "301800",
    "end": "308130"
  },
  {
    "text": "a simple example the deep Reiser car is",
    "start": "308130",
    "end": "310830"
  },
  {
    "text": "on the Left will tell it that all it",
    "start": "310830",
    "end": "313229"
  },
  {
    "text": "needs to do is cross the finish line on",
    "start": "313229",
    "end": "315240"
  },
  {
    "text": "the right as fast as possible since we",
    "start": "315240",
    "end": "318330"
  },
  {
    "text": "know that the fastest way to get from",
    "start": "318330",
    "end": "319889"
  },
  {
    "text": "one point to another is in a straight",
    "start": "319889",
    "end": "321870"
  },
  {
    "text": "line it's easy for us to determine",
    "start": "321870",
    "end": "323970"
  },
  {
    "text": "optimal route what the model will do",
    "start": "323970",
    "end": "326580"
  },
  {
    "text": "however is basically break it down into",
    "start": "326580",
    "end": "329490"
  },
  {
    "text": "a grid with each box constituting one",
    "start": "329490",
    "end": "332039"
  },
  {
    "text": "step from there we can use incentives ie",
    "start": "332039",
    "end": "335370"
  },
  {
    "text": "points to teach it central line driving",
    "start": "335370",
    "end": "337860"
  },
  {
    "text": "in the example on the Left we tell it",
    "start": "337860",
    "end": "341280"
  },
  {
    "start": "341000",
    "end": "341000"
  },
  {
    "text": "for every step you make you go in this",
    "start": "341280",
    "end": "343909"
  },
  {
    "text": "for every step you make where you go in",
    "start": "343909",
    "end": "346380"
  },
  {
    "text": "the straight line you receive the",
    "start": "346380",
    "end": "347880"
  },
  {
    "text": "optimal reward if you stray you don't",
    "start": "347880",
    "end": "350729"
  },
  {
    "text": "get nearly as many points and if you go",
    "start": "350729",
    "end": "352469"
  },
  {
    "text": "off the track you should just restart",
    "start": "352469",
    "end": "354020"
  },
  {
    "text": "there's also the potential for a",
    "start": "354020",
    "end": "356250"
  },
  {
    "text": "discount for each step taken this allows",
    "start": "356250",
    "end": "359219"
  },
  {
    "text": "the car to limit itself with how far it",
    "start": "359219",
    "end": "361199"
  },
  {
    "text": "can look into the future this can be",
    "start": "361199",
    "end": "363479"
  },
  {
    "text": "useful in instances where there's",
    "start": "363479",
    "end": "364949"
  },
  {
    "text": "multiple curves that could cause the car",
    "start": "364949",
    "end": "366719"
  },
  {
    "text": "to stop or misinterpret the track to",
    "start": "366719",
    "end": "369690"
  },
  {
    "text": "gain more points the vehicle will",
    "start": "369690",
    "end": "371669"
  },
  {
    "text": "attempt to explore all states and",
    "start": "371669",
    "end": "373560"
  },
  {
    "text": "actions and build a table reflecting the",
    "start": "373560",
    "end": "376080"
  },
  {
    "text": "the value of being in each state shown",
    "start": "376080",
    "end": "378990"
  },
  {
    "text": "on the",
    "start": "378990",
    "end": "379460"
  },
  {
    "text": "this value is the maximum reward",
    "start": "379460",
    "end": "382400"
  },
  {
    "text": "achievable from each state when it",
    "start": "382400",
    "end": "385050"
  },
  {
    "text": "selects the actions in subsequent states",
    "start": "385050",
    "end": "387900"
  },
  {
    "text": "leading to the states with highest value",
    "start": "387900",
    "end": "390590"
  },
  {
    "text": "learning doesn't just happen in the",
    "start": "390590",
    "end": "393030"
  },
  {
    "text": "first go",
    "start": "393030",
    "end": "393660"
  },
  {
    "text": "it takes some inner Asian because it",
    "start": "393660",
    "end": "395730"
  },
  {
    "text": "first needs to explore and see where it",
    "start": "395730",
    "end": "397680"
  },
  {
    "text": "can get the highest rewards before it",
    "start": "397680",
    "end": "400260"
  },
  {
    "text": "can exploit that knowledge well this may",
    "start": "400260",
    "end": "403200"
  },
  {
    "text": "seem confusing we use this all the time",
    "start": "403200",
    "end": "405240"
  },
  {
    "text": "in driving when you know that a",
    "start": "405240",
    "end": "407070"
  },
  {
    "text": "particular intersection has an",
    "start": "407070",
    "end": "408360"
  },
  {
    "text": "incredibly long red light you tend to",
    "start": "408360",
    "end": "410460"
  },
  {
    "text": "avoid it or if you know that there's a",
    "start": "410460",
    "end": "413010"
  },
  {
    "text": "football game happening at the stadium",
    "start": "413010",
    "end": "414840"
  },
  {
    "text": "you might avoid going to that side of",
    "start": "414840",
    "end": "416790"
  },
  {
    "text": "town for any errands to dig a deep to",
    "start": "416790",
    "end": "422580"
  },
  {
    "start": "422000",
    "end": "422000"
  },
  {
    "text": "dig it a bit deeper let's look at how",
    "start": "422580",
    "end": "424620"
  },
  {
    "text": "deep razor actually works every one",
    "start": "424620",
    "end": "427080"
  },
  {
    "text": "fifteenth of a second the vehicle takes",
    "start": "427080",
    "end": "429090"
  },
  {
    "text": "a picture of its surroundings this is",
    "start": "429090",
    "end": "431430"
  },
  {
    "text": "what we've been referring to as a step",
    "start": "431430",
    "end": "433460"
  },
  {
    "text": "this picture represents its state in the",
    "start": "433460",
    "end": "436710"
  },
  {
    "text": "ML model that you're building will then",
    "start": "436710",
    "end": "438810"
  },
  {
    "text": "use its algorithms to infer what the",
    "start": "438810",
    "end": "440820"
  },
  {
    "text": "next best course of action is this",
    "start": "440820",
    "end": "444390"
  },
  {
    "text": "course of action results in a new state",
    "start": "444390",
    "end": "446280"
  },
  {
    "text": "and the process repeats until it hits",
    "start": "446280",
    "end": "448650"
  },
  {
    "text": "what's called terminal state ie it fails",
    "start": "448650",
    "end": "451200"
  },
  {
    "text": "or completes the track in which case it",
    "start": "451200",
    "end": "453420"
  },
  {
    "text": "will restart since the initial model",
    "start": "453420",
    "end": "457080"
  },
  {
    "text": "doesn't know anything about the best",
    "start": "457080",
    "end": "458610"
  },
  {
    "text": "actions it should tape it will start by",
    "start": "458610",
    "end": "460440"
  },
  {
    "text": "making random actions so that it can",
    "start": "460440",
    "end": "462660"
  },
  {
    "text": "explore making these actions causes it",
    "start": "462660",
    "end": "465090"
  },
  {
    "text": "to build datasets based on these points",
    "start": "465090",
    "end": "467040"
  },
  {
    "text": "and then it attempts to maximize this",
    "start": "467040",
    "end": "469020"
  },
  {
    "text": "point through each episodes of attempt",
    "start": "469020",
    "end": "471440"
  },
  {
    "text": "of attempts this process is the value",
    "start": "471440",
    "end": "474900"
  },
  {
    "text": "function namely the car is saying when",
    "start": "474900",
    "end": "477210"
  },
  {
    "text": "I'm here my next options for points are",
    "start": "477210",
    "end": "480030"
  },
  {
    "text": "this this and this since it would take",
    "start": "480030",
    "end": "483870"
  },
  {
    "text": "an incredible amount of time and effort",
    "start": "483870",
    "end": "485610"
  },
  {
    "text": "to build a complete data set for every",
    "start": "485610",
    "end": "487770"
  },
  {
    "text": "one fifteenth of a second of traversal",
    "start": "487770",
    "end": "489870"
  },
  {
    "text": "across a track there's a point where the",
    "start": "489870",
    "end": "492300"
  },
  {
    "text": "random actions of exploring need to be",
    "start": "492300",
    "end": "494700"
  },
  {
    "text": "replaced by the optimizing of a path",
    "start": "494700",
    "end": "496620"
  },
  {
    "text": "based on the highest points obtainable",
    "start": "496620",
    "end": "498870"
  },
  {
    "text": "from a current state this is referred to",
    "start": "498870",
    "end": "501240"
  },
  {
    "text": "as the policy function in order to",
    "start": "501240",
    "end": "503880"
  },
  {
    "text": "optimize along with this we use",
    "start": "503880",
    "end": "505500"
  },
  {
    "text": "something called value approximation and",
    "start": "505500",
    "end": "507630"
  },
  {
    "text": "policy optimization let's look at an",
    "start": "507630",
    "end": "511410"
  },
  {
    "text": "example of Paul",
    "start": "511410",
    "end": "512360"
  },
  {
    "text": "estimation optimization this is referred",
    "start": "512360",
    "end": "515810"
  },
  {
    "text": "to as vanilla policy gradient this is",
    "start": "515810",
    "end": "518930"
  },
  {
    "start": "517000",
    "end": "517000"
  },
  {
    "text": "just a method where we parameterize the",
    "start": "518930",
    "end": "520880"
  },
  {
    "text": "policy function the parameters are",
    "start": "520880",
    "end": "523070"
  },
  {
    "text": "simply the weights in a neural network",
    "start": "523070",
    "end": "524720"
  },
  {
    "text": "and the neural network represents the",
    "start": "524720",
    "end": "526700"
  },
  {
    "text": "policy function all this policy function",
    "start": "526700",
    "end": "529310"
  },
  {
    "text": "does is taken image as input and outputs",
    "start": "529310",
    "end": "532160"
  },
  {
    "text": "an action thus mapping state to action",
    "start": "532160",
    "end": "535540"
  },
  {
    "text": "we then optimize that policy to get the",
    "start": "535540",
    "end": "538640"
  },
  {
    "text": "best action from each state the goal is",
    "start": "538640",
    "end": "541670"
  },
  {
    "text": "to get the maximum cumulative reward we",
    "start": "541670",
    "end": "544310"
  },
  {
    "text": "chained our model to update the weights",
    "start": "544310",
    "end": "546440"
  },
  {
    "text": "by training to maximize the cumulative",
    "start": "546440",
    "end": "548870"
  },
  {
    "text": "future reward and in doing so we give",
    "start": "548870",
    "end": "551899"
  },
  {
    "text": "higher probability to the action that",
    "start": "551899",
    "end": "553970"
  },
  {
    "text": "leads to the higher cumulative future",
    "start": "553970",
    "end": "556190"
  },
  {
    "text": "reward here we show an overview of the",
    "start": "556190",
    "end": "561680"
  },
  {
    "text": "network architecture that eight of us",
    "start": "561680",
    "end": "563660"
  },
  {
    "start": "562000",
    "end": "562000"
  },
  {
    "text": "deep racer trains in the simulator the",
    "start": "563660",
    "end": "566899"
  },
  {
    "text": "car takes a picture of the environment",
    "start": "566899",
    "end": "568519"
  },
  {
    "text": "and sends it to the convolutional",
    "start": "568519",
    "end": "571160"
  },
  {
    "text": "network or CNN this network consists of",
    "start": "571160",
    "end": "574130"
  },
  {
    "text": "multiple layers whose only job is to",
    "start": "574130",
    "end": "576050"
  },
  {
    "text": "extract features in the picture once",
    "start": "576050",
    "end": "578420"
  },
  {
    "text": "extracted the CNN then feeds this fully",
    "start": "578420",
    "end": "580850"
  },
  {
    "text": "connected layer that represents the",
    "start": "580850",
    "end": "582740"
  },
  {
    "text": "action space we provided at the start of",
    "start": "582740",
    "end": "585140"
  },
  {
    "text": "the training back to the model the model",
    "start": "585140",
    "end": "587540"
  },
  {
    "text": "will output a probability distribution",
    "start": "587540",
    "end": "589730"
  },
  {
    "text": "over the action space and then repeat",
    "start": "589730",
    "end": "591709"
  },
  {
    "text": "the cycle with that let's get into the",
    "start": "591709",
    "end": "595850"
  },
  {
    "text": "guts of the virtual simulator itself",
    "start": "595850",
    "end": "598810"
  },
  {
    "text": "deep research is actually just a service",
    "start": "598810",
    "end": "601339"
  },
  {
    "start": "601000",
    "end": "601000"
  },
  {
    "text": "of services under the hood there's sage",
    "start": "601339",
    "end": "604519"
  },
  {
    "text": "maker to train the RL models AWS Robo",
    "start": "604519",
    "end": "608000"
  },
  {
    "text": "maker to provide the simulation",
    "start": "608000",
    "end": "609529"
  },
  {
    "text": "environment s3 to store models cloud",
    "start": "609529",
    "end": "612380"
  },
  {
    "text": "watch to store logs and Kinesis video",
    "start": "612380",
    "end": "614690"
  },
  {
    "text": "stream display the video in the console",
    "start": "614690",
    "end": "617620"
  },
  {
    "text": "when you start training a model and deep",
    "start": "617620",
    "end": "619970"
  },
  {
    "text": "racer the following happens",
    "start": "619970",
    "end": "622000"
  },
  {
    "text": "AWS deep racer starts in a sage maker",
    "start": "622000",
    "end": "625100"
  },
  {
    "text": "container and a Robo maker container and",
    "start": "625100",
    "end": "627920"
  },
  {
    "text": "your service account and links the to it",
    "start": "627920",
    "end": "629720"
  },
  {
    "text": "then passes the right parameters to",
    "start": "629720",
    "end": "632329"
  },
  {
    "text": "start the training the experience of",
    "start": "632329",
    "end": "634370"
  },
  {
    "text": "state action new state reward tuples are",
    "start": "634370",
    "end": "638269"
  },
  {
    "text": "generated in AWS Robo maker and after a",
    "start": "638269",
    "end": "641270"
  },
  {
    "text": "specified amount of experience is",
    "start": "641270",
    "end": "643860"
  },
  {
    "text": "tamed it is sent back to Sage maker to",
    "start": "643860",
    "end": "646740"
  },
  {
    "text": "train the model the new model is then",
    "start": "646740",
    "end": "649829"
  },
  {
    "text": "sent back to Robo maker to get more",
    "start": "649829",
    "end": "652050"
  },
  {
    "text": "experience in the process continues to",
    "start": "652050",
    "end": "653970"
  },
  {
    "text": "loop the outputs of models video and",
    "start": "653970",
    "end": "657899"
  },
  {
    "text": "metrics are stored in other AWS services",
    "start": "657899",
    "end": "660420"
  },
  {
    "text": "in your account what's kind of cool is",
    "start": "660420",
    "end": "662490"
  },
  {
    "text": "that login into each of those services",
    "start": "662490",
    "end": "664709"
  },
  {
    "text": "you can see the data that's being",
    "start": "664709",
    "end": "666300"
  },
  {
    "text": "created from your device or training",
    "start": "666300",
    "end": "668339"
  },
  {
    "text": "jobs when you begin your deep research",
    "start": "668339",
    "end": "672660"
  },
  {
    "text": "journey you'll start with creating the",
    "start": "672660",
    "end": "674370"
  },
  {
    "start": "674000",
    "end": "674000"
  },
  {
    "text": "model from there you'll choose the",
    "start": "674370",
    "end": "676500"
  },
  {
    "text": "configurations for your training you can",
    "start": "676500",
    "end": "678510"
  },
  {
    "text": "choose to alter the parameters inside of",
    "start": "678510",
    "end": "680430"
  },
  {
    "text": "the reward function to action space and",
    "start": "680430",
    "end": "682649"
  },
  {
    "text": "some other hyper parameters from there",
    "start": "682649",
    "end": "685529"
  },
  {
    "text": "it's off to the races at first your",
    "start": "685529",
    "end": "687839"
  },
  {
    "text": "model mostly will most likely be only be",
    "start": "687839",
    "end": "690899"
  },
  {
    "text": "operating in a random fashion but after",
    "start": "690899",
    "end": "693690"
  },
  {
    "text": "a while you can evaluate how effective",
    "start": "693690",
    "end": "695160"
  },
  {
    "text": "it's running in the event that you're",
    "start": "695160",
    "end": "697829"
  },
  {
    "text": "feeling comfortable with the current",
    "start": "697829",
    "end": "699209"
  },
  {
    "text": "situation there's with the current",
    "start": "699209",
    "end": "700620"
  },
  {
    "text": "simulation you can save your model in",
    "start": "700620",
    "end": "703079"
  },
  {
    "text": "preparation for your upcoming depressor",
    "start": "703079",
    "end": "704850"
  },
  {
    "text": "event otherwise feel free to tweak your",
    "start": "704850",
    "end": "707339"
  },
  {
    "text": "model and resubmit it for training let's",
    "start": "707339",
    "end": "710399"
  },
  {
    "text": "look at that reward function again",
    "start": "710399",
    "end": "712850"
  },
  {
    "text": "during training we take an action in",
    "start": "712850",
    "end": "715500"
  },
  {
    "start": "715000",
    "end": "715000"
  },
  {
    "text": "each step and update the position of the",
    "start": "715500",
    "end": "717540"
  },
  {
    "text": "car the reward function will be used to",
    "start": "717540",
    "end": "720180"
  },
  {
    "text": "determine how good or bad the outcome of",
    "start": "720180",
    "end": "722430"
  },
  {
    "text": "the action is by supplying the logic for",
    "start": "722430",
    "end": "725610"
  },
  {
    "text": "good versus bad you're able to help the",
    "start": "725610",
    "end": "727890"
  },
  {
    "text": "model quantify the outcome of an action",
    "start": "727890",
    "end": "729899"
  },
  {
    "text": "deep racer provides a series of",
    "start": "729899",
    "end": "732149"
  },
  {
    "text": "variables containing measurements from",
    "start": "732149",
    "end": "734130"
  },
  {
    "text": "the simulator after each action that you",
    "start": "734130",
    "end": "736860"
  },
  {
    "text": "can then use to build reward function",
    "start": "736860",
    "end": "738690"
  },
  {
    "text": "logic using Python 3 this is the",
    "start": "738690",
    "end": "744390"
  },
  {
    "text": "first-person view of a WS deep racer as",
    "start": "744390",
    "end": "747209"
  },
  {
    "start": "746000",
    "end": "746000"
  },
  {
    "text": "it drives down a track the main",
    "start": "747209",
    "end": "749610"
  },
  {
    "text": "components of the track are the track",
    "start": "749610",
    "end": "751709"
  },
  {
    "text": "walk off track the track surface or on",
    "start": "751709",
    "end": "755820"
  },
  {
    "text": "track which includes the two boundaries",
    "start": "755820",
    "end": "757529"
  },
  {
    "text": "and the center of the track these",
    "start": "757529",
    "end": "760410"
  },
  {
    "text": "components are important because we can",
    "start": "760410",
    "end": "762420"
  },
  {
    "text": "use them to help determine whether an",
    "start": "762420",
    "end": "763829"
  },
  {
    "text": "action resulted in a good or bad outcome",
    "start": "763829",
    "end": "767990"
  },
  {
    "text": "next we have the coordinate system now",
    "start": "768589",
    "end": "771060"
  },
  {
    "text": "in reality this is a 3d environment so",
    "start": "771060",
    "end": "773910"
  },
  {
    "start": "772000",
    "end": "772000"
  },
  {
    "text": "it has XY and z axes for simplicity",
    "start": "773910",
    "end": "777390"
  },
  {
    "text": "we're on a show",
    "start": "777390",
    "end": "778080"
  },
  {
    "text": "X and y-axis the car has an X Y position",
    "start": "778080",
    "end": "782400"
  },
  {
    "text": "associated with it we provided waypoints",
    "start": "782400",
    "end": "785670"
  },
  {
    "text": "spread around the track in the center as",
    "start": "785670",
    "end": "787800"
  },
  {
    "text": "a series of XY points the superimposed",
    "start": "787800",
    "end": "791280"
  },
  {
    "text": "pink line in the center of the track the",
    "start": "791280",
    "end": "794310"
  },
  {
    "text": "waypoints help us to program",
    "start": "794310",
    "end": "795900"
  },
  {
    "text": "programmatically determine how much of",
    "start": "795900",
    "end": "798090"
  },
  {
    "text": "the track deep racer has completed where",
    "start": "798090",
    "end": "800610"
  },
  {
    "text": "the centerline of the track is and XY",
    "start": "800610",
    "end": "802380"
  },
  {
    "text": "coordinates the distance that deep racer",
    "start": "802380",
    "end": "804870"
  },
  {
    "text": "is from the center of the track the",
    "start": "804870",
    "end": "807060"
  },
  {
    "text": "direction of the flow of the track the",
    "start": "807060",
    "end": "809460"
  },
  {
    "text": "outer boundary and the inner boundary",
    "start": "809460",
    "end": "811700"
  },
  {
    "text": "all of these track components and track",
    "start": "811700",
    "end": "814290"
  },
  {
    "text": "waypoints are really important because",
    "start": "814290",
    "end": "816360"
  },
  {
    "text": "after every action in the state action",
    "start": "816360",
    "end": "818370"
  },
  {
    "text": "reward new state loop they are variables",
    "start": "818370",
    "end": "821940"
  },
  {
    "text": "that we can use to build logic to",
    "start": "821940",
    "end": "823830"
  },
  {
    "text": "determine whether an outcome was good or",
    "start": "823830",
    "end": "825690"
  },
  {
    "text": "bad an important note to make is that",
    "start": "825690",
    "end": "829110"
  },
  {
    "text": "this feedback loop only exists in the",
    "start": "829110",
    "end": "831270"
  },
  {
    "text": "virtual world and as such training can",
    "start": "831270",
    "end": "834060"
  },
  {
    "text": "only happen in the virtual world there",
    "start": "834060",
    "end": "836880"
  },
  {
    "text": "is no feedback loop on the physical car",
    "start": "836880",
    "end": "839030"
  },
  {
    "text": "to help it determine if an action was",
    "start": "839030",
    "end": "841500"
  },
  {
    "text": "good or bad let's move on to some of the",
    "start": "841500",
    "end": "846000"
  },
  {
    "text": "hyper parameters you have available to",
    "start": "846000",
    "end": "847590"
  },
  {
    "text": "you the learning rate controls how big",
    "start": "847590",
    "end": "851550"
  },
  {
    "start": "849000",
    "end": "849000"
  },
  {
    "text": "the updates are to your network weights",
    "start": "851550",
    "end": "853320"
  },
  {
    "text": "if your learning rate is big the model",
    "start": "853320",
    "end": "857160"
  },
  {
    "text": "will train fast but it may struggle to",
    "start": "857160",
    "end": "859440"
  },
  {
    "text": "converge on on some things",
    "start": "859440",
    "end": "861920"
  },
  {
    "text": "next the batch size is used for updating",
    "start": "861920",
    "end": "864930"
  },
  {
    "text": "the network typically we don't use all",
    "start": "864930",
    "end": "867480"
  },
  {
    "text": "of an experience at once instead we",
    "start": "867480",
    "end": "870150"
  },
  {
    "text": "carve it up into an experiment we carve",
    "start": "870150",
    "end": "872130"
  },
  {
    "text": "up in an experience into batch sizes and",
    "start": "872130",
    "end": "874170"
  },
  {
    "text": "use each into batches and eat and use",
    "start": "874170",
    "end": "876990"
  },
  {
    "text": "each batch in turn to update the weights",
    "start": "876990",
    "end": "879180"
  },
  {
    "text": "thus the network is updated one batch at",
    "start": "879180",
    "end": "881910"
  },
  {
    "text": "a time epochs are any combined series of",
    "start": "881910",
    "end": "886680"
  },
  {
    "text": "batches one epoch means we update the",
    "start": "886680",
    "end": "889620"
  },
  {
    "text": "network only once by running through all",
    "start": "889620",
    "end": "891840"
  },
  {
    "text": "the batches only once to epochs means we",
    "start": "891840",
    "end": "895200"
  },
  {
    "text": "run through all the badges twice so it",
    "start": "895200",
    "end": "897180"
  },
  {
    "text": "trains through all of the badges and",
    "start": "897180",
    "end": "899010"
  },
  {
    "text": "then retrains through all the badges and",
    "start": "899010",
    "end": "901080"
  },
  {
    "text": "then optimizes based off of those two",
    "start": "901080",
    "end": "904340"
  },
  {
    "text": "the discount factor specifies how much",
    "start": "904340",
    "end": "907380"
  },
  {
    "text": "future reward contributes to the",
    "start": "907380",
    "end": "909150"
  },
  {
    "text": "expected rule",
    "start": "909150",
    "end": "910070"
  },
  {
    "text": "the larger the discount factor the",
    "start": "910070",
    "end": "912560"
  },
  {
    "text": "farther out the rewards that the model",
    "start": "912560",
    "end": "914180"
  },
  {
    "text": "will consider inevitably this can slow",
    "start": "914180",
    "end": "916550"
  },
  {
    "text": "down training with a discount of 0.9 the",
    "start": "916550",
    "end": "920180"
  },
  {
    "text": "vehicle includes rewards from an order",
    "start": "920180",
    "end": "922490"
  },
  {
    "text": "of 10 feature steps with its count of",
    "start": "922490",
    "end": "925300"
  },
  {
    "text": "0.99 the vehicle considers the rewards",
    "start": "925300",
    "end": "928940"
  },
  {
    "text": "from an order of a thousand future steps",
    "start": "928940",
    "end": "932829"
  },
  {
    "text": "the number of episodes between training",
    "start": "932829",
    "end": "935540"
  },
  {
    "text": "specifies how much experience to obtain",
    "start": "935540",
    "end": "938660"
  },
  {
    "text": "before actually training the model so",
    "start": "938660",
    "end": "940940"
  },
  {
    "text": "basically how many times you want to run",
    "start": "940940",
    "end": "942500"
  },
  {
    "text": "through the batch are the epics which",
    "start": "942500",
    "end": "944389"
  },
  {
    "text": "again are controlled by the batches and",
    "start": "944389",
    "end": "946420"
  },
  {
    "text": "all of those other plays together so",
    "start": "946420",
    "end": "952310"
  },
  {
    "text": "let's fast forward to when you've",
    "start": "952310",
    "end": "953630"
  },
  {
    "text": "decided you have a good enough model to",
    "start": "953630",
    "end": "955610"
  },
  {
    "text": "be to bring to your event once your",
    "start": "955610",
    "end": "958610"
  },
  {
    "text": "training has stopped and you're feeling",
    "start": "958610",
    "end": "960139"
  },
  {
    "text": "good about what your model has come up",
    "start": "960139",
    "end": "961430"
  },
  {
    "text": "with it's time to download your model",
    "start": "961430",
    "end": "963170"
  },
  {
    "start": "962000",
    "end": "962000"
  },
  {
    "text": "and get it ready for the track and deep",
    "start": "963170",
    "end": "965389"
  },
  {
    "text": "racer you can click on that evaluate",
    "start": "965389",
    "end": "967399"
  },
  {
    "text": "your model and then choose download from",
    "start": "967399",
    "end": "971000"
  },
  {
    "text": "there you can just store the download on",
    "start": "971000",
    "end": "973009"
  },
  {
    "text": "a USB Drive and you're off to the races",
    "start": "973009",
    "end": "976389"
  },
  {
    "text": "now that we've talked about the software",
    "start": "976990",
    "end": "979250"
  },
  {
    "text": "and how to raise deep racer let's talk a",
    "start": "979250",
    "end": "981649"
  },
  {
    "text": "bit about what's under the hood deep",
    "start": "981649",
    "end": "984920"
  },
  {
    "text": "racer is comprised of essentially a",
    "start": "984920",
    "end": "986690"
  },
  {
    "text": "microcomputer not too dissimilar from a",
    "start": "986690",
    "end": "989480"
  },
  {
    "start": "988000",
    "end": "988000"
  },
  {
    "text": "smartphone it comes with Wi-Fi a camera",
    "start": "989480",
    "end": "992510"
  },
  {
    "text": "to drive with battery packs and multiple",
    "start": "992510",
    "end": "994699"
  },
  {
    "text": "sensors it runs a scaled-down version of",
    "start": "994699",
    "end": "997490"
  },
  {
    "text": "Ubuntu 1604 utilizing Intel's open V no",
    "start": "997490",
    "end": "1001300"
  },
  {
    "text": "toolkit and our OS during autonomous",
    "start": "1001300",
    "end": "1008620"
  },
  {
    "text": "driving the pictures flow from the",
    "start": "1008620",
    "end": "1011230"
  },
  {
    "start": "1010000",
    "end": "1010000"
  },
  {
    "text": "camera through the media engine into the",
    "start": "1011230",
    "end": "1014740"
  },
  {
    "text": "Intel open V no inference engine from",
    "start": "1014740",
    "end": "1017769"
  },
  {
    "text": "there the inference results are",
    "start": "1017769",
    "end": "1019689"
  },
  {
    "text": "converted into driving actions ie the",
    "start": "1019689",
    "end": "1022180"
  },
  {
    "text": "speed and direction of the car which",
    "start": "1022180",
    "end": "1024100"
  },
  {
    "text": "flows into the control node that",
    "start": "1024100",
    "end": "1026438"
  },
  {
    "text": "converts these to pulse width modulation",
    "start": "1026439",
    "end": "1028540"
  },
  {
    "text": "signals finally these signals are sent",
    "start": "1028540",
    "end": "1032260"
  },
  {
    "text": "to the engine and steering servo in the",
    "start": "1032260",
    "end": "1034480"
  },
  {
    "text": "car and cause it to hopefully move",
    "start": "1034480",
    "end": "1036668"
  },
  {
    "text": "around the track",
    "start": "1036669",
    "end": "1039329"
  },
  {
    "text": "in the confirmation email you received",
    "start": "1040329",
    "end": "1043029"
  },
  {
    "text": "for this webinar are a list of links",
    "start": "1043029",
    "end": "1044769"
  },
  {
    "text": "around resources with a lot more",
    "start": "1044769",
    "end": "1046298"
  },
  {
    "text": "information than what I've provided for",
    "start": "1046299",
    "end": "1047740"
  },
  {
    "text": "you today with that said thank you so",
    "start": "1047740",
    "end": "1051190"
  },
  {
    "text": "much for your time and we look forward",
    "start": "1051190",
    "end": "1052570"
  },
  {
    "text": "to seeing you on the track",
    "start": "1052570",
    "end": "1055470"
  }
]
[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "so in this session we're going to focus on building machine learning pipelines",
    "start": "30",
    "end": "7820"
  },
  {
    "text": "and we'll see that there are a number of ways to do this on AWS",
    "start": "7820",
    "end": "14089"
  },
  {
    "text": "but first let's define the problem why do we even need to focus on this so in",
    "start": "14089",
    "end": "22289"
  },
  {
    "start": "15000",
    "end": "93000"
  },
  {
    "text": "real life you need more than a single model to predict okay in many",
    "start": "22289",
    "end": "27869"
  },
  {
    "text": "applications life is not as easy as load the data send it to the model get the",
    "start": "27869",
    "end": "35100"
  },
  {
    "text": "prediction and do it again a lot of times you will need to pre-process the",
    "start": "35100",
    "end": "41399"
  },
  {
    "text": "data so you need to do normalization you need to do feature engineering before",
    "start": "41399",
    "end": "50010"
  },
  {
    "text": "you can actually predict ok you need to maybe load data from a back-end to",
    "start": "50010",
    "end": "56760"
  },
  {
    "text": "complete whatever data you received on on your API etc etc so the data that you",
    "start": "56760",
    "end": "63180"
  },
  {
    "text": "receive is not enough it's not ready to be predicted immediately and and you may",
    "start": "63180",
    "end": "68880"
  },
  {
    "text": "also need to do post-processing so if you're classifying images and you have a",
    "start": "68880",
    "end": "75750"
  },
  {
    "text": "thousand classes you don't want to return a thousand probabilities to the to the color you want to return maybe",
    "start": "75750",
    "end": "82200"
  },
  {
    "text": "the top five or the top one you may need to sort the data etc etc so there's",
    "start": "82200",
    "end": "88979"
  },
  {
    "text": "probably some extra work that needs to be done after predicting so what we're",
    "start": "88979",
    "end": "95009"
  },
  {
    "start": "93000",
    "end": "136000"
  },
  {
    "text": "going to do is we're going to try to build ml pipelines with minimal",
    "start": "95009",
    "end": "102600"
  },
  {
    "text": "infrastructure drama because infrastructure just gets in the way and we want to do machine learning so we're",
    "start": "102600",
    "end": "109079"
  },
  {
    "text": "going to use managed services like Amazon EMR and I'm going to focus on spark and spark ml so first we'll try",
    "start": "109079",
    "end": "116820"
  },
  {
    "text": "spark on its own and and then we'll try to combine spark and sage maker and",
    "start": "116820",
    "end": "122759"
  },
  {
    "text": "we'll discuss why I think this is a good idea and then we'll see how to build",
    "start": "122759",
    "end": "128610"
  },
  {
    "text": "pipelines with multiple models that are chained strictly using sage maker so",
    "start": "128610",
    "end": "137129"
  },
  {
    "start": "136000",
    "end": "225000"
  },
  {
    "text": "let's start with spark so who's using spark today okay quite a few people so",
    "start": "137129",
    "end": "142260"
  },
  {
    "text": "just a quick reminder of what spark is for for the folks who are not familiar with spark so spark is I like it it's an",
    "start": "142260",
    "end": "153659"
  },
  {
    "text": "open source distributed processing system and it was built to improve on",
    "start": "153659",
    "end": "159930"
  },
  {
    "text": "Hadoop so Hadoop was nice and interesting in its time but it was",
    "start": "159930",
    "end": "167430"
  },
  {
    "text": "painfully slow so the the number one goal of the spark project was to make",
    "start": "167430",
    "end": "172739"
  },
  {
    "text": "everything faster and much faster right about a hundred times faster than than MapReduce by loading everything in",
    "start": "172739",
    "end": "180000"
  },
  {
    "text": "memory loading the data in memory running all the transformations in",
    "start": "180000",
    "end": "185250"
  },
  {
    "text": "memory and making extensive use of caching so avoiding unnecessary",
    "start": "185250",
    "end": "192019"
  },
  {
    "text": "computation by caching intermediate results etc and this is our spark is",
    "start": "192019",
    "end": "197549"
  },
  {
    "text": "blazingly fast it can do a number of things it can do batch processing just like Hadoop did but it can do streaming",
    "start": "197549",
    "end": "203849"
  },
  {
    "text": "it can do machine learning which is what we're interested in today it can do graph databases and you can even query",
    "start": "203849",
    "end": "212870"
  },
  {
    "text": "using some form of sequel language and last but not least you have API is in",
    "start": "212870",
    "end": "220440"
  },
  {
    "text": "different languages but I will use Python today so the central concept in",
    "start": "220440",
    "end": "227040"
  },
  {
    "start": "225000",
    "end": "334000"
  },
  {
    "text": "the spark is the data frame so a data frame is a distributed collection of",
    "start": "227040",
    "end": "234599"
  },
  {
    "text": "data distributed because spark is a cluster system okay so we work with multiple nodes that collaborate in",
    "start": "234599",
    "end": "241439"
  },
  {
    "text": "computing data and we distribute data sets over the different nodes and those",
    "start": "241439",
    "end": "248669"
  },
  {
    "text": "data sets are organizing named columns so you can really see a data frame as",
    "start": "248669",
    "end": "254250"
  },
  {
    "text": "the equivalent and I will put quotes around that of a relational table write",
    "start": "254250",
    "end": "261690"
  },
  {
    "text": "a table in the relational database it looks the same it's obviously different in the sense that it is distributed by it's",
    "start": "261690",
    "end": "270000"
  },
  {
    "text": "distributed on multiple nodes and it's organized differently but the way you interact with it it's very similar to to",
    "start": "270000",
    "end": "277050"
  },
  {
    "text": "a database and the data frame API is very convenient you can load all kinds",
    "start": "277050",
    "end": "282330"
  },
  {
    "text": "of data formats of text files JSON files etc etc CSV files columnar formats and",
    "start": "282330",
    "end": "289560"
  },
  {
    "text": "so on you can support all kinds of files Parque Orkut cetera et cetera so it's",
    "start": "289560",
    "end": "297229"
  },
  {
    "text": "chances are you know there is a built-in loader for you the format that you use",
    "start": "297229",
    "end": "302880"
  },
  {
    "text": "so let's say I have a JSON file okay with names and ages and Jeff as Jeff is",
    "start": "302880",
    "end": "310680"
  },
  {
    "text": "Jeff bar and you know you don't ask Jeff bar how old is he yeah so Boas is 72",
    "start": "310680",
    "end": "316500"
  },
  {
    "text": "years old as we all know and I'm 12 sometimes 8 ok and if I read this JSON",
    "start": "316500",
    "end": "322919"
  },
  {
    "text": "document just like this and I display it this is what I see so this is very similar to to a table ok and it doesn't",
    "start": "322919",
    "end": "330150"
  },
  {
    "text": "have to be really really complicated so the data frame API is really convenient spark has a machine learning library oh",
    "start": "330150",
    "end": "337940"
  },
  {
    "start": "334000",
    "end": "705000"
  },
  {
    "text": "my god bird it's called Emile Lib so as you would",
    "start": "337940",
    "end": "343380"
  },
  {
    "text": "expect it has a collection of algorithms and I'm gonna say a very nice collection",
    "start": "343380",
    "end": "349229"
  },
  {
    "text": "of algorithms plenty of different things like classification regression clustering collaborative filtering with",
    "start": "349229",
    "end": "356370"
  },
  {
    "text": "plenty of variations and it's it's it's one of the better machine learning collection of algos out there it has an",
    "start": "356370",
    "end": "364710"
  },
  {
    "text": "API for feature ization so transforming data feature extraction transformation",
    "start": "364710",
    "end": "371360"
  },
  {
    "text": "dimensionality reduction etc we'll use some of them to pre-process our data and",
    "start": "371360",
    "end": "376789"
  },
  {
    "text": "very interestingly it supports machine learning pipelines so it has the ability",
    "start": "376789",
    "end": "382229"
  },
  {
    "text": "to chain different processing steps ok",
    "start": "382229",
    "end": "388020"
  },
  {
    "text": "and those steps can either be a transformer so a transformer transforms",
    "start": "388020",
    "end": "394800"
  },
  {
    "text": "a data frame in another data frame again this is really about what feature",
    "start": "394800",
    "end": "399910"
  },
  {
    "text": "engineering is about or it can be an estimator so an estimator will predict a",
    "start": "399910",
    "end": "406510"
  },
  {
    "text": "result based on a data frame okay so you can build pipelines by combining those",
    "start": "406510",
    "end": "412930"
  },
  {
    "text": "two types of off steps okay and we'll see an example in a second so when you",
    "start": "412930",
    "end": "420220"
  },
  {
    "text": "train a model on spark it gets trained on the cluster and then obviously you",
    "start": "420220",
    "end": "426730"
  },
  {
    "text": "want to predict with it so the first option is to just do it in the same app",
    "start": "426730",
    "end": "431770"
  },
  {
    "text": "right in the same spark app that you've trained and loaded the data in and train",
    "start": "431770",
    "end": "437500"
  },
  {
    "text": "the model in you can just take your model and you know call the prediction API pass some data to it some data frame",
    "start": "437500",
    "end": "444730"
  },
  {
    "text": "to it and get an output data frame okay we'll see an example in a second or of",
    "start": "444730",
    "end": "450490"
  },
  {
    "text": "course you can save the model and in spark and and load it in another spark",
    "start": "450490",
    "end": "458350"
  },
  {
    "text": "application later on why not you can export it there's a an export format",
    "start": "458350",
    "end": "464380"
  },
  {
    "text": "called PMML that lets you use a model with other languages like Java or etc or",
    "start": "464380",
    "end": "472930"
  },
  {
    "text": "and that's a more recent option and that's the one we'll we'll look at you",
    "start": "472930",
    "end": "479950"
  },
  {
    "text": "can export the the model to format call em leap and this is a format a format",
    "start": "479950",
    "end": "486970"
  },
  {
    "text": "that's interoperable with scikit-learn and tensorflow and once you've exported",
    "start": "486970",
    "end": "492070"
  },
  {
    "text": "the model then you can load it using the M leap API and you can serve predictions",
    "start": "492070",
    "end": "499050"
  },
  {
    "text": "the good thing about M leap is it's completely independent from spark okay",
    "start": "499050",
    "end": "505300"
  },
  {
    "text": "because in the first two options you're predicting in the spark app in the spark",
    "start": "505300",
    "end": "511840"
  },
  {
    "text": "context and it's fair to say there's a bit of overhead involved and it's very difficult to get low latency predictions",
    "start": "511840",
    "end": "518950"
  },
  {
    "text": "inside a spark app and so that's one of the problems that M leap is trying to",
    "start": "518950",
    "end": "524890"
  },
  {
    "text": "solve okay you don't need a spark cluster and you don't pay the spark tax so to speak on your",
    "start": "524890",
    "end": "531100"
  },
  {
    "text": "predictions okay but in any case if you want to do all of this you know you still need ec2 instances or EMR clusters",
    "start": "531100",
    "end": "539350"
  },
  {
    "text": "or you know doctor containers any any compute technology that you like to do",
    "start": "539350",
    "end": "547029"
  },
  {
    "text": "all of this okay so you still need to do infrastructure and well I that's not what I want to do today that's generally",
    "start": "547029",
    "end": "554050"
  },
  {
    "text": "what not what I want to do I want to do machine learning so here's a very simple example of building a pipeline okay so",
    "start": "554050",
    "end": "564940"
  },
  {
    "text": "let's say I want to classify text sentences so my data set would be a set",
    "start": "564940",
    "end": "573430"
  },
  {
    "text": "of samples with an ID the text itself and a label okay we could use this to",
    "start": "573430",
    "end": "580690"
  },
  {
    "text": "build a spam detector or you know sentiment analysis application let's say",
    "start": "580690",
    "end": "586540"
  },
  {
    "text": "okay so let's say I've got some data lying around it doesn't really matter",
    "start": "586540",
    "end": "591730"
  },
  {
    "text": "which format it's in as long as I can read it in the data frame so I would use the data frame API to load it and then I",
    "start": "591730",
    "end": "599920"
  },
  {
    "text": "would build a simple pipeline with the three steps so first a tokenizer that would remove the words replace the",
    "start": "599920",
    "end": "609880"
  },
  {
    "text": "words with integers okay because machine learning wants numbers it doesn't want",
    "start": "609880",
    "end": "616139"
  },
  {
    "text": "text okay and I'll use the tokenizer object to do that then the hashing",
    "start": "616139",
    "end": "622470"
  },
  {
    "text": "transform which will bucket those words because maybe my vocabulary is 50,000",
    "start": "622470",
    "end": "629410"
  },
  {
    "text": "words and you know I don't need 50,000 words to to train this model so maybe I",
    "start": "629410",
    "end": "635380"
  },
  {
    "text": "want to buck it in a thousand features okay so I'm gonna hash my words into in",
    "start": "635380",
    "end": "641079"
  },
  {
    "text": "two buckets okay that's the hashing TF object and then once I have that I'm",
    "start": "641079",
    "end": "646750"
  },
  {
    "text": "gonna train logistic regression so a binary classifier on the on that dataset",
    "start": "646750",
    "end": "653170"
  },
  {
    "text": "okay so three steps get rid of the text bucket bucket the different tokens into",
    "start": "653170",
    "end": "661029"
  },
  {
    "text": "a number of buckets and trained a binary classifier on those",
    "start": "661029",
    "end": "666790"
  },
  {
    "text": "samples okay and then I can combine the PI then them in the pipeline just like you see right new pipeline set stages",
    "start": "666790",
    "end": "674079"
  },
  {
    "text": "and then add my pipeline objects in the right order and then call fit to train okay and then",
    "start": "674079",
    "end": "682149"
  },
  {
    "text": "load some test data and predict it okay so this is a really basic vanilla",
    "start": "682149",
    "end": "688230"
  },
  {
    "text": "example of building a pipeline but that's how you would do this in spark ml okay using different objects doing some",
    "start": "688230",
    "end": "694810"
  },
  {
    "text": "transform so obviously tokenizer is a transformer hashing TF is a transformer and the largest T progression is an",
    "start": "694810",
    "end": "702160"
  },
  {
    "text": "estimator okay so let's let's look at another example",
    "start": "702160",
    "end": "708990"
  },
  {
    "start": "705000",
    "end": "998000"
  },
  {
    "text": "so here I'm gonna use PI spark so this",
    "start": "709380",
    "end": "715269"
  },
  {
    "text": "is a sage maker notebook connected to an EMR cluster okay there's a bit of a",
    "start": "715269",
    "end": "722230"
  },
  {
    "text": "setup phase to do this and what I want to do is I'm gonna use a data set which",
    "start": "722230",
    "end": "728139"
  },
  {
    "text": "which is called the abalone data set so the abalone is a kind of self shellfish not selfish shellfish okay and based on",
    "start": "728139",
    "end": "738420"
  },
  {
    "text": "measurements right based on information that we gathered on different types of",
    "start": "738420",
    "end": "745870"
  },
  {
    "text": "shells of abalone we want to predict the age of a given self shellfish okay so",
    "start": "745870",
    "end": "756160"
  },
  {
    "text": "this is a standard data set you probably seen this before so I'm going to define the schema from",
    "start": "756160",
    "end": "764880"
  },
  {
    "text": "for this so I've got the stat information and data that so I've got the you can see it here as well in the",
    "start": "764880",
    "end": "771130"
  },
  {
    "text": "bottom it's maybe easier so you can see the sex so you have male female and infant samples you have a feature for",
    "start": "771130",
    "end": "781120"
  },
  {
    "text": "the length the diameter the height the whole weight the shocked weight viscera",
    "start": "781120",
    "end": "789910"
  },
  {
    "text": "weight enjoy she'll wait right and the number",
    "start": "789910",
    "end": "795040"
  },
  {
    "text": "of rings that are visible on the she'll and the number of rings is actually on the indicator of the age",
    "start": "795040",
    "end": "801070"
  },
  {
    "text": "okay so that's what the data set looks like so I'm starting by defining the schema for that for that data okay and",
    "start": "801070",
    "end": "811090"
  },
  {
    "text": "then I'm using the data frame API to read the CSV file from history storing",
    "start": "811090",
    "end": "816610"
  },
  {
    "text": "the data displaying few lines and then splitting the data set 80% 20% for",
    "start": "816610",
    "end": "823690"
  },
  {
    "text": "training and validation okay so next I",
    "start": "823690",
    "end": "828970"
  },
  {
    "text": "need to do some feature engineering because you can see that sex variable is a categorical variable and you know I",
    "start": "828970",
    "end": "834790"
  },
  {
    "text": "don't want that I can't use those MF or I there are values I need proper",
    "start": "834790",
    "end": "841510"
  },
  {
    "text": "categories and the rest are just numerical values so they're pretty reasonable so the only feature",
    "start": "841510",
    "end": "848350"
  },
  {
    "text": "engineering that I'm gonna do here is I'm gonna first use a string in dexter",
    "start": "848350",
    "end": "853720"
  },
  {
    "text": "to replace MF or i in the first column with a category number so my guess would",
    "start": "853720",
    "end": "860590"
  },
  {
    "text": "be 0 1 & 2 but don't trust me on that and then the second step is a one out",
    "start": "860590",
    "end": "867130"
  },
  {
    "text": "encoder where I'm going to replace 0 1 & 2 with a bit field with 3 values okay so",
    "start": "867130",
    "end": "877510"
  },
  {
    "text": "so maybe M will correspond to 1 0 0 and F 2 1 0 1 0 and I to 0 0 1 okay and this",
    "start": "877510",
    "end": "887950"
  },
  {
    "text": "is how you deal with categorical variables you want to build different dimensions so first you remove strings",
    "start": "887950",
    "end": "895150"
  },
  {
    "text": "and replace them with integers and then you replace integers with big fields",
    "start": "895150",
    "end": "900330"
  },
  {
    "text": "setting the right bit to 1 okay and then I can leave everything else untouched",
    "start": "900330",
    "end": "905860"
  },
  {
    "text": "those numerical features here are fine so I use a vector assembler to just",
    "start": "905860",
    "end": "912540"
  },
  {
    "text": "append the fixed sex of the modified sex",
    "start": "912540",
    "end": "918780"
  },
  {
    "text": "feature to the numerical features okay very simple stuff",
    "start": "918780",
    "end": "925860"
  },
  {
    "text": "okay and then here I'm going to choose to your train a random forest classifier",
    "start": "925860",
    "end": "934680"
  },
  {
    "text": "okay so the the feature I want to predict is the number of rings okay",
    "start": "934680",
    "end": "941200"
  },
  {
    "text": "because again this is an indicator of the age and I'm giving some hyper parameters depth number of trees etc and",
    "start": "941200",
    "end": "948880"
  },
  {
    "text": "then I can build my pipeline just like we saw okay so again indexing the stacks",
    "start": "948880",
    "end": "954460"
  },
  {
    "text": "feature encoding the sec's feature assembling the engineered sex feature to the numerical features and training the",
    "start": "954460",
    "end": "961870"
  },
  {
    "text": "model okay so another example of a pipeline calling fit to train and then I can take some my",
    "start": "961870",
    "end": "972100"
  },
  {
    "text": "validation set I can process that with the model that I trained and show some",
    "start": "972100",
    "end": "978130"
  },
  {
    "text": "results okay so so the prediction for the top the first five samples in the",
    "start": "978130",
    "end": "984820"
  },
  {
    "text": "validation set is visible here okay so spark ml very easy combined transformer",
    "start": "984820",
    "end": "991930"
  },
  {
    "text": "steps with an estimator and do some",
    "start": "991930",
    "end": "997270"
  },
  {
    "text": "predictions okay so you can do this on your laptop you can do this on EMR you",
    "start": "997270",
    "end": "1005160"
  },
  {
    "start": "998000",
    "end": "1481000"
  },
  {
    "text": "know it's spark and it runs in a lot of different places now let's see why we",
    "start": "1005160",
    "end": "1010620"
  },
  {
    "text": "would want to combine spark and sage maker so we've talked about sage maker a",
    "start": "1010620",
    "end": "1015930"
  },
  {
    "text": "lot so I'm just gonna state the obvious here so it's a fully managed machine learning service it's backed by an sdk",
    "start": "1015930",
    "end": "1024839"
  },
  {
    "text": "that lets you train and deploy models on fully managed infrastructure and we can",
    "start": "1024839",
    "end": "1030209"
  },
  {
    "text": "do other things like hyper parameter optimizations etc etc okay so it's your",
    "start": "1030209",
    "end": "1035490"
  },
  {
    "text": "friendly neighborhood managed machine learning service so how does it fit with",
    "start": "1035490",
    "end": "1042589"
  },
  {
    "text": "spark well there's an extra SDK on top",
    "start": "1042589",
    "end": "1048240"
  },
  {
    "text": "of the stage maker SDK in Python there's a specific SDK for spark ok and it's",
    "start": "1048240",
    "end": "1054180"
  },
  {
    "text": "available in Python and Scala okay it's pre-installed on EMR 511 and",
    "start": "1054180",
    "end": "1061179"
  },
  {
    "text": "up so it is available on your EMR clusters but if you have an in-house",
    "start": "1061179",
    "end": "1066730"
  },
  {
    "text": "Keller cluster just go peep or well no not P because it's not vital just add",
    "start": "1066730",
    "end": "1072399"
  },
  {
    "text": "the right dependency maven dependency or whatever and and install that and the",
    "start": "1072399",
    "end": "1080350"
  },
  {
    "text": "core feature here is now with this SDK from your spark application okay so from",
    "start": "1080350",
    "end": "1087519"
  },
  {
    "text": "your Python your PI spark code or your Scala code you can call sage maker api's",
    "start": "1087519",
    "end": "1093029"
  },
  {
    "text": "okay so you can just you know load data",
    "start": "1093029",
    "end": "1098679"
  },
  {
    "text": "and train with the either built-in I'll go in Sage Maker or maybe the tensorflow",
    "start": "1098679",
    "end": "1105100"
  },
  {
    "text": "a container and sage maker and you can also add sage maker steps in spark",
    "start": "1105100",
    "end": "1111340"
  },
  {
    "text": "pipelines okay so similar to what we've seen except some of these steps will run on stage",
    "start": "1111340",
    "end": "1117730"
  },
  {
    "text": "maker and the best thing about it right",
    "start": "1117730",
    "end": "1122799"
  },
  {
    "text": "what really sold me here is there is no data conversion right you work with data",
    "start": "1122799",
    "end": "1128080"
  },
  {
    "text": "frames load data in the data frame pass the data frame to a sage maker estimator",
    "start": "1128080",
    "end": "1134409"
  },
  {
    "text": "it's going to convert it to whatever format the sage maker algo needs which most of the time is protobuf and and",
    "start": "1134409",
    "end": "1142840"
  },
  {
    "text": "when you predict with that model again it's going to convert to protobuf and back and you never have to mess with",
    "start": "1142840",
    "end": "1149740"
  },
  {
    "text": "that and yes the crowd goes wild or should go wild because this data conversion in",
    "start": "1149740",
    "end": "1157149"
  },
  {
    "text": "sage maker is not always so obvious so here we're completely free of that so",
    "start": "1157149",
    "end": "1163480"
  },
  {
    "text": "why would you want to do that yeah that's the number one question that I get why should I use those two",
    "start": "1163480",
    "end": "1169450"
  },
  {
    "text": "services together so in my opinion the first and the main reason is SPARC is",
    "start": "1169450",
    "end": "1174490"
  },
  {
    "text": "mostly about ETL so yes it can do machine learning but it can't do all of",
    "start": "1174490",
    "end": "1179559"
  },
  {
    "text": "machine running so why don't we use spark for what's its best which is ETL",
    "start": "1179559",
    "end": "1186250"
  },
  {
    "text": "and why don't we use sage maker for what's its best which is machine learning okay and",
    "start": "1186250",
    "end": "1192559"
  },
  {
    "text": "imagine building clusters for spark and clusters for machine running as coasters",
    "start": "1192559",
    "end": "1199859"
  },
  {
    "text": "for ETL and clusters for machine learning the you can't pick the right instance type right ETL needs a lot of",
    "start": "1199859",
    "end": "1207119"
  },
  {
    "text": "memory it generally doesn't need a ton of compute you need a ton of memory because SPARC is all in memory so maybe",
    "start": "1207119",
    "end": "1214229"
  },
  {
    "text": "you need our for instances and and maybe that maybe you want to train a deep",
    "start": "1214229",
    "end": "1219629"
  },
  {
    "text": "learning model okay so you need GPUs so why not p3 and maybe you want to predict",
    "start": "1219629",
    "end": "1225749"
  },
  {
    "text": "you don't need GPUs to predict so maybe you want to use c5 okay so that would be",
    "start": "1225749",
    "end": "1231539"
  },
  {
    "text": "the ideal world but if you work on a spark cluster you you're you know you",
    "start": "1231539",
    "end": "1237629"
  },
  {
    "text": "have to stick to one instance type okay and again sizing and scaling could be",
    "start": "1237629",
    "end": "1244200"
  },
  {
    "text": "different you could need you know a lot of nodes for ETL and just a few notes",
    "start": "1244200",
    "end": "1250679"
  },
  {
    "text": "for training so you would probably size your cluster by default and saying okay",
    "start": "1250679",
    "end": "1258509"
  },
  {
    "text": "I need a lot of nodes for one of those two things so okay I'll stick to that but then one of those processes would",
    "start": "1258509",
    "end": "1264570"
  },
  {
    "text": "actually be wasteful because you would train on a very large cluster and why",
    "start": "1264570",
    "end": "1269639"
  },
  {
    "text": "you don't need that so you could save money by maybe shrinking it and yes you can resize the air more clusters but who",
    "start": "1269639",
    "end": "1275999"
  },
  {
    "text": "loves doing that right that's what I thought and another reason is you could",
    "start": "1275999",
    "end": "1281669"
  },
  {
    "text": "ETL once and train a lot so maybe you just need the spark cluster to true tweet here for a few hours and then you",
    "start": "1281669",
    "end": "1288839"
  },
  {
    "text": "can shut it down and maybe then you're gonna train for it you know 100 models in three days so again different",
    "start": "1288839",
    "end": "1294269"
  },
  {
    "text": "requirements the other reason is spark Emily's is great I like it very much but",
    "start": "1294269",
    "end": "1300929"
  },
  {
    "text": "it doesn't do everything okay you may need algorithms that are not available there and specifically you may need deep",
    "start": "1300929",
    "end": "1309299"
  },
  {
    "text": "learning okay which is not available in spark ml or you may need your own custom",
    "start": "1309299",
    "end": "1315179"
  },
  {
    "text": "code in in any language right maybe your training code is not written in parkour",
    "start": "1315179",
    "end": "1320879"
  },
  {
    "text": "in in Scala right so you would love to do ETL on spark but then you can't really",
    "start": "1320879",
    "end": "1326610"
  },
  {
    "text": "do training in there and the last reason is probably you know something I",
    "start": "1326610",
    "end": "1333269"
  },
  {
    "text": "mentioned before getting the best prediction performance okay and you definitely want to run prediction",
    "start": "1333269",
    "end": "1339510"
  },
  {
    "text": "outside of spark because like I've said if you run prediction inside the spark",
    "start": "1339510",
    "end": "1345120"
  },
  {
    "text": "context you pay you pay the tax right and you need a running cluster first of",
    "start": "1345120",
    "end": "1351539"
  },
  {
    "text": "all and you get the overhead of spark on your predictions so that's not really good plus we saw that we can export",
    "start": "1351539",
    "end": "1359730"
  },
  {
    "text": "spark models to the M leap format and stage maker knows how to load those so",
    "start": "1359730",
    "end": "1365250"
  },
  {
    "text": "there's something here okay so low latency again inside of spark is difficult with sage maker just size your",
    "start": "1365250",
    "end": "1373409"
  },
  {
    "text": "instances and scale your prediction infrastructure as much as you want to get to the right level of performance so",
    "start": "1373409",
    "end": "1382260"
  },
  {
    "text": "some examples okay so maybe you can do you know data preparation and feature",
    "start": "1382260",
    "end": "1387330"
  },
  {
    "text": "engineering on spark and then train on sage maker okay at scale maybe you have",
    "start": "1387330",
    "end": "1394169"
  },
  {
    "text": "an existing model that expects certain features okay and it works well but you",
    "start": "1394169",
    "end": "1400830"
  },
  {
    "text": "have to use it with data that doesn't fit inside the model okay so maybe you",
    "start": "1400830",
    "end": "1406019"
  },
  {
    "text": "want to transform the data to do feature engineering on your data set so that it",
    "start": "1406019",
    "end": "1411360"
  },
  {
    "text": "can be used for prediction okay it's called model reuse okay reusing a model",
    "start": "1411360",
    "end": "1417299"
  },
  {
    "text": "with data that is slightly different but if you can feature engineer the data to fit that model then fine okay you could",
    "start": "1417299",
    "end": "1426240"
  },
  {
    "text": "try using predictions to do data cleaning or data enrichment typically",
    "start": "1426240",
    "end": "1432419"
  },
  {
    "text": "when we have to add missing values you know we take median or we take default",
    "start": "1432419",
    "end": "1437880"
  },
  {
    "text": "values but if you have clean data that you could train a model that knows how to predict a specific attribute and you",
    "start": "1437880",
    "end": "1445500"
  },
  {
    "text": "could probably use that model to predict missing values based on the other",
    "start": "1445500",
    "end": "1450539"
  },
  {
    "text": "features why not okay so that's that's a that's an interesting thing or could use an external model to add more",
    "start": "1450539",
    "end": "1457650"
  },
  {
    "text": "predicted features so all that stuff could happen during ETL so while you're doing ETL on spark you could invoke",
    "start": "1457650",
    "end": "1464430"
  },
  {
    "text": "models in Sage Maker to help with the ETL process okay and generally if you",
    "start": "1464430",
    "end": "1470820"
  },
  {
    "text": "want to deploy at scale large-scale you know I don't think deploying on a spark",
    "start": "1470820",
    "end": "1476220"
  },
  {
    "text": "cluster is the right way okay shoot me so let's look at a couple of",
    "start": "1476220",
    "end": "1481950"
  },
  {
    "start": "1481000",
    "end": "1986000"
  },
  {
    "text": "examples so the first one I want to show",
    "start": "1481950",
    "end": "1491640"
  },
  {
    "text": "you is that too small yes probably can",
    "start": "1491640",
    "end": "1497400"
  },
  {
    "text": "you see in the back or is yeah that okay anyone alive yeah okay thanks",
    "start": "1497400",
    "end": "1505909"
  },
  {
    "text": "so here so I'm using Zeppelin which is another notebook app and I'm running",
    "start": "1506630",
    "end": "1513740"
  },
  {
    "text": "Scala code on an EMR cluster okay so this is running on an EMR cluster in",
    "start": "1513740",
    "end": "1520290"
  },
  {
    "text": "spark okay so what I'm going to do here this time",
    "start": "1520290",
    "end": "1525600"
  },
  {
    "text": "I'm going to work with another data set which you've seen before it's called M NIST are you tired of it yes me too so",
    "start": "1525600",
    "end": "1535500"
  },
  {
    "text": "70 thousand digits okay and the game is to predict the right class from 0 to 9",
    "start": "1535500",
    "end": "1543570"
  },
  {
    "text": "for each image okay so as you would expect I'm reading the dataset it's it's",
    "start": "1543570",
    "end": "1552840"
  },
  {
    "text": "in s3 so I can read the training set the validation set okay load that into spark",
    "start": "1552840",
    "end": "1560280"
  },
  {
    "text": "and these as you can see these have 784",
    "start": "1560280",
    "end": "1566040"
  },
  {
    "text": "features which sounds weird but again as mentioned in the previous talk those are",
    "start": "1566040",
    "end": "1571500"
  },
  {
    "text": "28 by 28 pixel images that we flattened to 784 bytes",
    "start": "1571500",
    "end": "1577770"
  },
  {
    "text": "okay 28 by 28 is 784 trust me so each of those samples is actually an array of",
    "start": "1577770",
    "end": "1585350"
  },
  {
    "text": "784 bytes okay so here I want to train I want to I",
    "start": "1585350",
    "end": "1592250"
  },
  {
    "text": "want to train a clustering model okay I would like to see if k-means the k-means clustering I'll go is able to",
    "start": "1592250",
    "end": "1599270"
  },
  {
    "text": "cluster those samples into ten clusters representing the ten classes okay but",
    "start": "1599270",
    "end": "1607600"
  },
  {
    "text": "784 features that sounds like too many right for k-means to do his job so first",
    "start": "1607600",
    "end": "1612860"
  },
  {
    "text": "I'm going to use the PCA I'll go to reduce the number of dimensions from 784",
    "start": "1612860",
    "end": "1620840"
  },
  {
    "text": "to 50 which is just an arbitrary number okay so I'm configuring a PC a",
    "start": "1620840",
    "end": "1626590"
  },
  {
    "text": "transformer saying well for using the features column and building new columns",
    "start": "1626590",
    "end": "1632390"
  },
  {
    "text": "called projected features please engineer 50 new features okay so that's",
    "start": "1632390",
    "end": "1639950"
  },
  {
    "text": "my first step and this is running on spark in on the Year mark cluster and then the next step is just training",
    "start": "1639950",
    "end": "1647270"
  },
  {
    "text": "k-means on sage maker and deploying k-means on sage maker okay and using",
    "start": "1647270",
    "end": "1652820"
  },
  {
    "text": "that sage maker sdk for spark I asked k-means to take the projected features",
    "start": "1652820",
    "end": "1660620"
  },
  {
    "text": "and build me ten clusters okay so that's",
    "start": "1660620",
    "end": "1666500"
  },
  {
    "text": "my second step of the pipeline and this will not run on the EMR cluster this will run on on stage maker okay then I",
    "start": "1666500",
    "end": "1675230"
  },
  {
    "text": "create my pipeline okay at the stages so PC a right feature",
    "start": "1675230",
    "end": "1681529"
  },
  {
    "text": "engineering first and then clustering next I call fit so it runs for a few minutes okay and as you can see I I",
    "start": "1681529",
    "end": "1688880"
  },
  {
    "text": "don't worry about data format I pass my data frames that I load it and then I",
    "start": "1688880",
    "end": "1695929"
  },
  {
    "text": "can transform using the the model that I trained I can transform my test data okay and we could even maybe go crazy",
    "start": "1695929",
    "end": "1703460"
  },
  {
    "text": "and try to click on this okay so now",
    "start": "1703460",
    "end": "1709279"
  },
  {
    "text": "this is running on my EMR cluster okay so it's predicting all those samples and",
    "start": "1709279",
    "end": "1714289"
  },
  {
    "text": "it should show me in a few seconds the",
    "start": "1714289",
    "end": "1719408"
  },
  {
    "text": "the predicted cluster for each of the samples okay so I see the original",
    "start": "1719789",
    "end": "1725640"
  },
  {
    "text": "features here the 784 features I see the",
    "start": "1725640",
    "end": "1731870"
  },
  {
    "text": "the projected features so the ones that have been computed by PCA and then I see",
    "start": "1731870",
    "end": "1738780"
  },
  {
    "text": "each each cluster okay which to each class to which cluster each sample",
    "start": "1738780",
    "end": "1745490"
  },
  {
    "text": "belongs okay which one is its closest from our closest to okay so if you're",
    "start": "1745490",
    "end": "1751530"
  },
  {
    "text": "curious of about is this accurate or not absolutely not it doesn't work at all okay it's it does a terrible job so so",
    "start": "1751530",
    "end": "1759299"
  },
  {
    "text": "clustering images with k-means here doesn't really work but what does work",
    "start": "1759299",
    "end": "1764940"
  },
  {
    "text": "is building the pipeline with EMR steps and sage maker steps using the same API",
    "start": "1764940",
    "end": "1772970"
  },
  {
    "text": "and you know never worrying about managing sage maker infrastructure never",
    "start": "1772970",
    "end": "1778620"
  },
  {
    "text": "worrying about transforming data right if you use spark ml today it's very easy",
    "start": "1778620",
    "end": "1783750"
  },
  {
    "text": "to integrate this in your routine okay",
    "start": "1783750",
    "end": "1788330"
  },
  {
    "text": "yes so that's the first example sorry so now let's move back to our to our",
    "start": "1789559",
    "end": "1800640"
  },
  {
    "text": "abalone example okay to the shellfish example so what we've done here remember",
    "start": "1800640",
    "end": "1807179"
  },
  {
    "text": "is we train a model on spark okay now could we deploy this on sage maker",
    "start": "1807179",
    "end": "1815309"
  },
  {
    "text": "so let's see how that works so what I'm gonna do here is I'm going to export the",
    "start": "1815309",
    "end": "1825150"
  },
  {
    "text": "model the spark model that I trained I'm going to export it to that M leap format",
    "start": "1825150",
    "end": "1830450"
  },
  {
    "text": "okay so just serialize it convert it",
    "start": "1830450",
    "end": "1836070"
  },
  {
    "text": "into a tour jz format which is what stage maker expects expect for",
    "start": "1836070",
    "end": "1841679"
  },
  {
    "text": "deployment upload the serialized model to a3 okay",
    "start": "1841679",
    "end": "1849870"
  },
  {
    "text": "and then okay it's just another sage maker model so I can import it to Sage",
    "start": "1849870",
    "end": "1858480"
  },
  {
    "text": "maker okay I need to define so let me show you how to do it first okay so you",
    "start": "1858480",
    "end": "1864720"
  },
  {
    "text": "just use that spark ml model object from the SDK passing the location of the M",
    "start": "1864720",
    "end": "1872070"
  },
  {
    "text": "leap bundle in in s3 okay a name for the model and a schema which is what you saw",
    "start": "1872070",
    "end": "1880380"
  },
  {
    "text": "before have to describe the the schema of the data that that model can take",
    "start": "1880380",
    "end": "1887100"
  },
  {
    "text": "okay so that's the Jason and I can pass this as an environment variable and this",
    "start": "1887100",
    "end": "1893850"
  },
  {
    "text": "is pretty much what we've seen before right just listing the features and providing a type okay and the output",
    "start": "1893850",
    "end": "1902280"
  },
  {
    "text": "should be float well double representing the prediction okay so this is all it",
    "start": "1902280",
    "end": "1909840"
  },
  {
    "text": "takes export the model in Emily format import it in Sage Maker and then I can just",
    "start": "1909840",
    "end": "1916860"
  },
  {
    "text": "call deploy like we do all the time model dot deploy and now I have this",
    "start": "1916860",
    "end": "1922679"
  },
  {
    "text": "spark model being served by Sage Maker okay so I can shut down my earmark",
    "start": "1922679",
    "end": "1928530"
  },
  {
    "text": "luster and and I can get the job done okay and I can invoke it just like I",
    "start": "1928530",
    "end": "1935490"
  },
  {
    "text": "would invoke any model so take a payload okay so try to predict the number of",
    "start": "1935490",
    "end": "1942540"
  },
  {
    "text": "rings for a female abalone with those features out there okay this line okay",
    "start": "1942540",
    "end": "1951000"
  },
  {
    "text": "and then just call predict and okay this abalone should have 11 rings pretty much",
    "start": "1951000",
    "end": "1957690"
  },
  {
    "text": "that's what it says okay so you can see you can it's very easy to export models from spark and and deploy them on Sage",
    "start": "1957690",
    "end": "1965429"
  },
  {
    "text": "maker okay and now of course we could be using the instance type that we want we",
    "start": "1965429",
    "end": "1970770"
  },
  {
    "text": "could use auto scaling on that endpoints we're completely free from the spark environment so we can take the best",
    "start": "1970770",
    "end": "1977520"
  },
  {
    "text": "choices for the best performance in in this prediction task okay so here are the two",
    "start": "1977520",
    "end": "1987770"
  },
  {
    "text": "scenarios okay load some data on spark ETH invoke the spark SDK for Sage Maker",
    "start": "1987770",
    "end": "1995929"
  },
  {
    "text": "to train and and keep predicting inside the spark app okay or you could ETL and",
    "start": "1995929",
    "end": "2003400"
  },
  {
    "text": "train on spark export your model to M leap and deploy it on stage maker just",
    "start": "2003400",
    "end": "2009309"
  },
  {
    "text": "like any other model okay alright there's one more thing we need to cover",
    "start": "2009309",
    "end": "2017760"
  },
  {
    "text": "can we do pipelines in Sage Maker only right because we've used parts so far",
    "start": "2019169",
    "end": "2025000"
  },
  {
    "text": "what if we don't have to use part how do we train and a sequence of models right",
    "start": "2025000",
    "end": "2033040"
  },
  {
    "text": "that that are needed to get from raw data to engineered data to predicted",
    "start": "2033040",
    "end": "2039520"
  },
  {
    "text": "result and how can we deploy that okay and it's a newer feature in Sage Maker",
    "start": "2039520",
    "end": "2045220"
  },
  {
    "text": "it came out how to reinvent December and it's called inference pipelines okay and",
    "start": "2045220",
    "end": "2050618"
  },
  {
    "text": "maybe one of the obscure features in there so let's talk about it so an",
    "start": "2050619",
    "end": "2055628"
  },
  {
    "text": "inference pipeline is a sequence of two to five models okay that are involved in",
    "start": "2055629",
    "end": "2066340"
  },
  {
    "text": "a single prediction workflow so you can you can use sike little urn models you",
    "start": "2066340",
    "end": "2074500"
  },
  {
    "text": "can afford feature engineering you can use spark ml models okay just like the one that we've seen before and you can",
    "start": "2074500",
    "end": "2081790"
  },
  {
    "text": "combine them with of course sage maker models built-in algos or chunks of flow",
    "start": "2081790",
    "end": "2087310"
  },
  {
    "text": "deep learning libraries etc etc okay or even your own custom container okay so",
    "start": "2087310",
    "end": "2092679"
  },
  {
    "text": "you can use existing transformers in scikit-learn or spark ml and then predict with your own model and the cool",
    "start": "2092679",
    "end": "2100720"
  },
  {
    "text": "thing about it is it's a single unit so when you deploy that to the endpoints",
    "start": "2100720",
    "end": "2106300"
  },
  {
    "text": "the whole sequence the whole pipeline is deployed as a unit to a single end",
    "start": "2106300",
    "end": "2112880"
  },
  {
    "text": "it okay before that what customers had to do was okay let's train a cyclotron",
    "start": "2112880",
    "end": "2118490"
  },
  {
    "text": "model and deploy it on one end point or let's train a spark model and deploying",
    "start": "2118490",
    "end": "2124819"
  },
  {
    "text": "on another end point and so they had multiple endpoints so extra cost probably and then they needed some",
    "start": "2124819",
    "end": "2131779"
  },
  {
    "text": "high-level API to invoke those those different those prediction API is in",
    "start": "2131779",
    "end": "2138410"
  },
  {
    "text": "sequence so you know plumbing and we don't like plumbing so now it's all deployed on one endpoint and so you call",
    "start": "2138410",
    "end": "2145490"
  },
  {
    "text": "one API and that API will trigger the whole pipeline okay so if you need to do",
    "start": "2145490",
    "end": "2151640"
  },
  {
    "text": "pre-processing prediction post-processing etc you can you can get it done and this works for real time so",
    "start": "2151640",
    "end": "2158630"
  },
  {
    "text": "online predictions with HTTP and it also works for batch transform okay so you",
    "start": "2158630",
    "end": "2164630"
  },
  {
    "text": "can you can run batch predictions at scale with your pipeline so let's look",
    "start": "2164630",
    "end": "2171619"
  },
  {
    "start": "2171000",
    "end": "2646000"
  },
  {
    "text": "at a quick demo and this one uses cyclone",
    "start": "2171619",
    "end": "2177039"
  },
  {
    "text": "okay so let's keep that stuff so we're still working with that abalone dataset",
    "start": "2186559",
    "end": "2192619"
  },
  {
    "text": "okay we're obsessed with a shellfish today so download the data set from the",
    "start": "2192619",
    "end": "2198509"
  },
  {
    "text": "web CSV file again you see what it looks like so you know that categorical",
    "start": "2198509",
    "end": "2205049"
  },
  {
    "text": "feature the sexes male female infant and then numerical features and the last the",
    "start": "2205049",
    "end": "2211559"
  },
  {
    "text": "last number is the number of rings okay so it's the target value we're trying to",
    "start": "2211559",
    "end": "2217170"
  },
  {
    "text": "predict okay so upload the data to s3 because it needs to be there and then",
    "start": "2217170",
    "end": "2224789"
  },
  {
    "text": "we're going to use a scikit-learn script just like we used a spark app to do",
    "start": "2224789",
    "end": "2230970"
  },
  {
    "text": "feature engineering on on that on that data set and then we're going to do",
    "start": "2230970",
    "end": "2235980"
  },
  {
    "text": "pretty similar things so that's the scikit-learn code okay we can see obviously the same columns let's take a",
    "start": "2235980",
    "end": "2244289"
  },
  {
    "text": "look at the the actual work we're doing so loading the data set here okay let's",
    "start": "2244289",
    "end": "2254579"
  },
  {
    "text": "try to keep everything on the screen so what are we doing here so first we're",
    "start": "2254579",
    "end": "2262170"
  },
  {
    "text": "dealing with the numerical features so we're dropping sex because sex is not a",
    "start": "2262170",
    "end": "2267869"
  },
  {
    "text": "numerical feature right it's a categorical feature and we define a pipeline with two steps so one impure",
    "start": "2267869",
    "end": "2276470"
  },
  {
    "text": "and this will feel missing values okay so if one of those samples as a missing",
    "start": "2276470",
    "end": "2283049"
  },
  {
    "text": "value scikit-learn we'll use the median value for that column to replace it okay",
    "start": "2283049",
    "end": "2288720"
  },
  {
    "text": "and that it applies a standard scalar which is just normalization just basic",
    "start": "2288720",
    "end": "2294210"
  },
  {
    "text": "normalization on the that column okay so that's one tiny pipeline for numerical",
    "start": "2294210",
    "end": "2302039"
  },
  {
    "text": "features and then for categorical features again I have another pipeline",
    "start": "2302039",
    "end": "2307380"
  },
  {
    "text": "where I'm using a simple importer again to replace to fix missing values so in",
    "start": "2307380",
    "end": "2315930"
  },
  {
    "text": "this case if one of the lines has no sex we'll just use the missing word",
    "start": "2315930",
    "end": "2322270"
  },
  {
    "text": "the missing string to replace it okay and then we use 1/2 encoding just like",
    "start": "2322270",
    "end": "2328210"
  },
  {
    "text": "we saw before because we want to get rid of strings we want categorical features okay so we have three possible values",
    "start": "2328210",
    "end": "2334599"
  },
  {
    "text": "male female infant so we'll end up with three dimensions two of them will be set",
    "start": "2334599",
    "end": "2339910"
  },
  {
    "text": "to zero one of them will be set to one according to the actual sex okay",
    "start": "2339910",
    "end": "2345880"
  },
  {
    "text": "then I use a column transformer to merge",
    "start": "2345880",
    "end": "2352079"
  },
  {
    "text": "the two the two transformers above okay so the numeric features and the catapult",
    "start": "2352079",
    "end": "2358420"
  },
  {
    "text": "categorical features and then I train okay so you see it's you know it's like it running this time not spark but it's",
    "start": "2358420",
    "end": "2364150"
  },
  {
    "text": "very similar okay it's a simple data set so there's not a ton of work you can do on that data anyway okay so this will do",
    "start": "2364150",
    "end": "2372280"
  },
  {
    "text": "the feature engineering part okay and the rest is just utility functions so",
    "start": "2372280",
    "end": "2378819"
  },
  {
    "text": "I'm going to train this thing on stage maker so I use the scikit-learn estimator passing my script and training",
    "start": "2378819",
    "end": "2387460"
  },
  {
    "text": "this on C for excel okay so what I'm gonna get is a model that that has that",
    "start": "2387460",
    "end": "2396520"
  },
  {
    "text": "has been model that's able to pre-process my my training set okay",
    "start": "2396520",
    "end": "2402730"
  },
  {
    "text": "which is what I do here okay okay but",
    "start": "2402730",
    "end": "2409660"
  },
  {
    "text": "that's just one step okay that's just a feature engineering then I want to train my my actual machine learning model okay",
    "start": "2409660",
    "end": "2417790"
  },
  {
    "text": "so what I'm gonna do is I'm going to batch transform my training data okay",
    "start": "2417790",
    "end": "2423280"
  },
  {
    "text": "because I want my initial training data to be featured engineered and I'm going",
    "start": "2423280",
    "end": "2428740"
  },
  {
    "text": "to train my actual machine learning model on that feature engineer data okay",
    "start": "2428740",
    "end": "2433780"
  },
  {
    "text": "so this is why I need to do batch transform okay and I'm going to load",
    "start": "2433780",
    "end": "2439300"
  },
  {
    "text": "that transform dataset and train my my",
    "start": "2439300",
    "end": "2445089"
  },
  {
    "text": "machine learning are go okay and in this case I'm using linear regression because from those engineered features I want to",
    "start": "2445089",
    "end": "2452380"
  },
  {
    "text": "predict the number of rings okay so I want to predict a numerical value so again I used the estimator object pointing at",
    "start": "2452380",
    "end": "2460030"
  },
  {
    "text": "the linear regression I'll go a built-in algo in sage maker I'm going to train on one m4 to excel instance and I need to",
    "start": "2460030",
    "end": "2470829"
  },
  {
    "text": "set the hyper parameters for linear regression so I've got ten features okay engineered I'm using the regressor mode",
    "start": "2470829",
    "end": "2478720"
  },
  {
    "text": "because again I want to do linear regression and that's about it okay I define where the pre-processed",
    "start": "2478720",
    "end": "2485260"
  },
  {
    "text": "training data is and then I train okay so the important thing to understand is",
    "start": "2485260",
    "end": "2490480"
  },
  {
    "text": "I am NOT training on the initial data set okay I am training on the engineered data set the data set that has been",
    "start": "2490480",
    "end": "2497609"
  },
  {
    "text": "fixed or modified by the cyclotron script okay so I transfer a bit fine",
    "start": "2497609",
    "end": "2504700"
  },
  {
    "text": "and now I can simply create my sage",
    "start": "2504700",
    "end": "2510940"
  },
  {
    "text": "maker pipeline by calling that pipeline model API and defining the different",
    "start": "2510940",
    "end": "2518410"
  },
  {
    "text": "models that that constitute the sequence okay so first the raw data needs to go",
    "start": "2518410",
    "end": "2524140"
  },
  {
    "text": "through the cyclic learn model to be featured engineered okay and that data",
    "start": "2524140",
    "end": "2531970"
  },
  {
    "text": "will automatically then go through the linear regression model to predict the",
    "start": "2531970",
    "end": "2537099"
  },
  {
    "text": "number of rings for that shellfish okay so those two models get the job done and",
    "start": "2537099",
    "end": "2544170"
  },
  {
    "text": "as you can see I can then deploy the pipeline just like I would deploy a normal model okay so those two models",
    "start": "2544170",
    "end": "2552569"
  },
  {
    "text": "consider two single units and they get deployed to one see for Excel instance",
    "start": "2552569",
    "end": "2559680"
  },
  {
    "text": "okay and then you know I can predict just like I would predict usually so",
    "start": "2559680",
    "end": "2566559"
  },
  {
    "text": "take some data create a predictor object and just predict okay and okay in this",
    "start": "2566559",
    "end": "2573520"
  },
  {
    "text": "case this shellfish has between nine and",
    "start": "2573520",
    "end": "2578770"
  },
  {
    "text": "ten rings okay and if we look at the stage maker console here",
    "start": "2578770",
    "end": "2584720"
  },
  {
    "text": "okay we can actually see so we see the endpoint that is being used to predict I",
    "start": "2584720",
    "end": "2590390"
  },
  {
    "text": "can see the URL etc okay and if I look",
    "start": "2590390",
    "end": "2595820"
  },
  {
    "text": "at the training job that I was used to bill the endpoint need to go down a bit",
    "start": "2595820",
    "end": "2607359"
  },
  {
    "text": "where is it oh sorry that's the wrong",
    "start": "2607810",
    "end": "2614330"
  },
  {
    "text": "one let me try that again a model name",
    "start": "2614330",
    "end": "2623119"
  },
  {
    "text": "yes - um okay I can see content so that",
    "start": "2623119",
    "end": "2630230"
  },
  {
    "text": "model that pipeline is really too good the psychic container and the linear",
    "start": "2630230",
    "end": "2639080"
  },
  {
    "text": "learner container okay again deployed as one single unit okay so this is another",
    "start": "2639080",
    "end": "2646400"
  },
  {
    "start": "2646000",
    "end": "2727000"
  },
  {
    "text": "way to deal with pipelines if you are already using spark and you want to do a",
    "start": "2646400",
    "end": "2653720"
  },
  {
    "text": "little a little better at training and predicting etc you can export to M leap",
    "start": "2653720",
    "end": "2660920"
  },
  {
    "text": "and then go to Sage maker or if you if you're not using spark today and if",
    "start": "2660920",
    "end": "2667430"
  },
  {
    "text": "you're just dealing with multiple endpoints and that's not practical then inference pipelines are a great",
    "start": "2667430",
    "end": "2674720"
  },
  {
    "text": "solution a much easier solution to this okay so if you want to get started with this always the same URLs the sage maker",
    "start": "2674720",
    "end": "2681890"
  },
  {
    "text": "URL for all information on sage maker and of course the examples are the",
    "start": "2681890",
    "end": "2688099"
  },
  {
    "text": "notebooks on github and we have some examples for em leap and we have some examples for scikit-learn as well so",
    "start": "2688099",
    "end": "2694520"
  },
  {
    "text": "those will get you started and again my blog on medium where you'll find a lot of sage maker content all right thank",
    "start": "2694520",
    "end": "2702710"
  },
  {
    "text": "you very much again if you want to stay in touch if you want to try it and send me feedback you can do that on Twitter",
    "start": "2702710",
    "end": "2708710"
  },
  {
    "text": "or LinkedIn I'm pretty easy to find I love to hear about your your stories and try to answer your questions thank you",
    "start": "2708710",
    "end": "2715490"
  },
  {
    "text": "very much for thank you I hope this was useful and have a great",
    "start": "2715490",
    "end": "2721400"
  },
  {
    "text": "evening thank you very much",
    "start": "2721400",
    "end": "2724299"
  }
]
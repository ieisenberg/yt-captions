[
  {
    "text": "Welcome to 'Back to Basics'.",
    "start": "6096",
    "end": "7943"
  },
  {
    "text": "To gain business insight,\nyou and your data engineering team",
    "start": "7943",
    "end": "11635"
  },
  {
    "text": "build and manage data pipelines",
    "start": "11635",
    "end": "14592"
  },
  {
    "text": "to extract, transform, and load data.",
    "start": "14592",
    "end": "17544"
  },
  {
    "text": "ETL provides the foundation to your data analytics\nand machine learning applications.",
    "start": "18214",
    "end": "24087"
  },
  {
    "text": "You can apply a series\nof business rules in ETL",
    "start": "25116",
    "end": "28889"
  },
  {
    "text": "to clean and organize data\nto address business intelligence use cases",
    "start": "28889",
    "end": "33850"
  },
  {
    "text": "such as monthly reporting.",
    "start": "33851",
    "end": "35533"
  },
  {
    "text": "Today, we will discuss\nmodernizing ETL process",
    "start": "35947",
    "end": "40070"
  },
  {
    "text": "with an event-driven serverless data pipeline\nyou can build on AWS.",
    "start": "40070",
    "end": "45747"
  },
  {
    "text": "Let's dive in.",
    "start": "45747",
    "end": "46954"
  },
  {
    "text": "When you start building an\nETL data pipeline from the ground up,",
    "start": "47560",
    "end": "50383"
  },
  {
    "text": "you begin with provisioning infrastructure resources\nsuch as servers,",
    "start": "50383",
    "end": "55036"
  },
  {
    "text": "networking to get your ETL tools implemented,\nconfigured and tested.",
    "start": "55036",
    "end": "60044"
  },
  {
    "text": "This provisioning process\ncould take weeks and months,",
    "start": "60044",
    "end": "63121"
  },
  {
    "text": "depending on the complexity\nof your environment and ETL tools.",
    "start": "63121",
    "end": "66927"
  },
  {
    "text": "Once deployed, you will spend time\nmanaging and maintaining ETL tools ",
    "start": "67057",
    "end": "71655"
  },
  {
    "text": "by ensuring servers are patched,\napplications are updated. ",
    "start": "71655",
    "end": "75659"
  },
  {
    "text": "I have experienced patching and fixing\nto stabilize ETL tools",
    "start": "75659",
    "end": "79982"
  },
  {
    "text": "so that overnight ETL batch jobs\ncould continue.",
    "start": "79983",
    "end": "83290"
  },
  {
    "text": "It's not fun.",
    "start": "83290",
    "end": "84408"
  },
  {
    "text": "Once your ETL tools are deployed,",
    "start": "85001",
    "end": "87526"
  },
  {
    "text": "you will need to configure it\nto automate ETL processes.",
    "start": "87526",
    "end": "90633"
  },
  {
    "text": "For a batch job, you configure ETL processes\nto run when data becomes available.",
    "start": "90633",
    "end": "96664"
  },
  {
    "text": "A common method\nis running jobs on schedule.",
    "start": "96664",
    "end": "99423"
  },
  {
    "text": "Because data loads vary,",
    "start": "99423",
    "end": "101230"
  },
  {
    "text": "even a small batch job may run\nfor different duration of times.",
    "start": "101231",
    "end": "105198"
  },
  {
    "text": "This may result in a waste of paying\nidling resources between two job runs",
    "start": "105198",
    "end": "109944"
  },
  {
    "text": "or a job failure\ndue to an extra large load of data.",
    "start": "109944",
    "end": "113450"
  },
  {
    "text": "Many of you have experience with this,",
    "start": "113588",
    "end": "115919"
  },
  {
    "text": "and you may think,\nwhat if an ETL tool can easily scale",
    "start": "115919",
    "end": "120310"
  },
  {
    "text": "and you only need to pay\nfor the resources that've been utilized?",
    "start": "120310",
    "end": "124435"
  },
  {
    "text": "What if your ETL tools\nare always available",
    "start": "124435",
    "end": "127727"
  },
  {
    "text": "for business logic configurations\nand you have no underlying infrastructure to manage?",
    "start": "127727",
    "end": "133313"
  },
  {
    "text": "Here comes AWS Glue.",
    "start": "133313",
    "end": "135364"
  },
  {
    "text": "Given there is a wide range\nof data integration use cases",
    "start": "135682",
    "end": "139263"
  },
  {
    "text": "you can design ETL pipeline solutions for,",
    "start": "139540",
    "end": "142696"
  },
  {
    "text": "we will discuss\nan implementation example",
    "start": "142992",
    "end": "145951"
  },
  {
    "text": "that you can modernize\nin scale ETL pipelines",
    "start": "145951",
    "end": "150120"
  },
  {
    "text": "using AWS Glue",
    "start": "150120",
    "end": "151810"
  },
  {
    "text": "by building an event-driven\nserverless ETL data pipeline on AWS.",
    "start": "151811",
    "end": "157385"
  },
  {
    "text": "A starting point\nwith an ETL process is ingesting data.",
    "start": "158950",
    "end": "163023"
  },
  {
    "text": "You need a scalable data store\nfor the ingested data",
    "start": "163520",
    "end": "167003"
  },
  {
    "text": "when building a scalable ETL data pipeline.",
    "start": "167003",
    "end": "169817"
  },
  {
    "text": "You can pick Amazon S3\nas your serverless data pipeline ",
    "start": "169817",
    "end": "173022"
  },
  {
    "text": "and use it as the primary data store of all your data.",
    "start": "173261",
    "end": "176348"
  },
  {
    "text": "By using Amazon DataSync SFTP application,\nor other techniques and applications",
    "start": "176348",
    "end": "182590"
  },
  {
    "text": "the document data arrives\nin a bucket on Amazon S3 service.",
    "start": "182590",
    "end": "186972"
  },
  {
    "text": "To make your users easily\nand securely find and access data,",
    "start": "187344",
    "end": "191353"
  },
  {
    "text": "the ingested data\nneeds to be cataloged based on its schema.",
    "start": "191354",
    "end": "195519"
  },
  {
    "text": "You can scale and automate this process ",
    "start": "195519",
    "end": "198735"
  },
  {
    "text": "and apply security access rules\nby using AWS Glue Data Catalog.",
    "start": "198735",
    "end": "203386"
  },
  {
    "text": "To turn this ETL data pipeline\nto be event driven,",
    "start": "204148",
    "end": "206995"
  },
  {
    "text": "so you avoid paying idling resources\nbetween the scheduled jobs,",
    "start": "206995",
    "end": "211093"
  },
  {
    "text": "you would want to trigger the data processing\nupon the data arrival in S3 bucket.",
    "start": "211093",
    "end": "216380"
  },
  {
    "text": "You can do this using an AWS Lambda function\ninvoked by Amazon S3 trigger",
    "start": "216763",
    "end": "221764"
  },
  {
    "text": "to start an AWS Glue Crawler\nthat catalogs the data.",
    "start": "221764",
    "end": "225844"
  },
  {
    "text": "You can program the AWS Glue Crawler",
    "start": "226075",
    "end": "228233"
  },
  {
    "text": "to scan data\nin all kinds of repositories,",
    "start": "228233",
    "end": "230936"
  },
  {
    "text": "including Amazon S3\nand database services, classify it,",
    "start": "230936",
    "end": "234990"
  },
  {
    "text": "extract schema information,\nand store the metadata",
    "start": "234990",
    "end": "238507"
  },
  {
    "text": "automatically in AWS Glue Data Catalog.",
    "start": "238507",
    "end": "241699"
  },
  {
    "text": "To scale this event driven\nETL data pipeline,",
    "start": "241869",
    "end": "244717"
  },
  {
    "text": "you would want to run jobs\nin parallel when required.",
    "start": "244717",
    "end": "247732"
  },
  {
    "text": "You can use Amazon SQS\nto manage the large volume of Amazon S3",
    "start": "247805",
    "end": "252624"
  },
  {
    "text": "triggered invocations in the event\nof varied data loads arriving simultaneously.",
    "start": "252624",
    "end": "258709"
  },
  {
    "text": "When AWS Glue Crawler is finished\nstoring metadata in AWS Glue Data Catalog,",
    "start": "259611",
    "end": "265722"
  },
  {
    "text": "you invoke a second Lambda function\nusing an Amazon EventBridge event rule",
    "start": "265722",
    "end": "271483"
  },
  {
    "text": "so AWS Glue Catalog\ncan be used to guide ETL operations.",
    "start": "271484",
    "end": "276604"
  },
  {
    "text": "The AWS Lambda function\nstarts an AWS Glue ETL job",
    "start": "276966",
    "end": "280733"
  },
  {
    "text": "to process and output data\ninto another Amazon's S3 bucket.",
    "start": "280733",
    "end": "284549"
  },
  {
    "text": "For example,\nyou may want to use an AWS Glue ETL job",
    "start": "284549",
    "end": "288846"
  },
  {
    "text": "to convert the data\nto a desirable data format,",
    "start": "288846",
    "end": "292033"
  },
  {
    "text": "such as Apache Parquet format.",
    "start": "292033",
    "end": "294832"
  },
  {
    "text": "You may also modify the ETL job\nto achieve other objectives",
    "start": "295104",
    "end": "299258"
  },
  {
    "text": "like more granular, petitioning compression,\nor enriching of the data.",
    "start": "299258",
    "end": "304464"
  },
  {
    "text": "To make this ETL pipeline\nmore scalable,",
    "start": "304989",
    "end": "307683"
  },
  {
    "text": "you would want to automate the\nmonitoring and notification process",
    "start": "307683",
    "end": "311814"
  },
  {
    "text": "as soon as the ETL job finishes,\nanother EventBridge rule",
    "start": "311814",
    "end": "316261"
  },
  {
    "text": "sends you an email notification",
    "start": "316261",
    "end": "318797"
  },
  {
    "text": "using an Amazon Simple Notification Service SNS topic.",
    "start": "318798",
    "end": "323300"
  },
  {
    "text": "This notification indicates that your data\nwas successfully processed.",
    "start": "323300",
    "end": "328533"
  },
  {
    "text": "There you have an event-driven, scalable,",
    "start": "328767",
    "end": "331361"
  },
  {
    "text": "highly automated ETL data pipeline",
    "start": "331361",
    "end": "334318"
  },
  {
    "text": "that you have no servers\nor underlying infrastructure to manage.",
    "start": "334318",
    "end": "337934"
  },
  {
    "text": "In this episode,\nwe explored an implementation design",
    "start": "338358",
    "end": "341806"
  },
  {
    "text": "of building an event-driven\nserverless data pipeline on AWS.",
    "start": "341806",
    "end": "346268"
  },
  {
    "text": "I have used this design more than once.",
    "start": "346953",
    "end": "349109"
  },
  {
    "text": "Now you can use it too.",
    "start": "349109",
    "end": "350569"
  },
  {
    "text": "Check out the links below for more details.",
    "start": "351272",
    "end": "353632"
  },
  {
    "text": "See you next time.",
    "start": "353632",
    "end": "354886"
  }
]
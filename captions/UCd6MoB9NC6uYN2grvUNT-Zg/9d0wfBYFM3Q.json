[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "hello everyone thank you for coming here and being with us today my name is Cyrus principal evangelist",
    "start": "1429",
    "end": "8189"
  },
  {
    "text": "for AWS AI Labs the deep engine team the",
    "start": "8189",
    "end": "14429"
  },
  {
    "text": "part of the deep engine I'm involved in is working on a product called MX net is",
    "start": "14429",
    "end": "19890"
  },
  {
    "text": "an Apache project is an open source deep learning framework the other section of",
    "start": "19890",
    "end": "26970"
  },
  {
    "text": "the deep engine is involved in Amazon Sage makers development and I'm going to",
    "start": "26970",
    "end": "32880"
  },
  {
    "text": "quickly go through what these things are and why they work well together so we",
    "start": "32880",
    "end": "38640"
  },
  {
    "text": "have our colleagues from work day we reckon Henry that there the second part",
    "start": "38640",
    "end": "43950"
  },
  {
    "text": "of the presentation that would be their projects and they would introduce the project to you in this interest of time",
    "start": "43950",
    "end": "50070"
  },
  {
    "text": "so I'm going to do a further adue trying to get into the tool can the agenda and",
    "start": "50070",
    "end": "55649"
  },
  {
    "start": "54000",
    "end": "54000"
  },
  {
    "text": "what we're going to be doing so in the first part I'm talking about patch emx now it's why we use it's why it's a good",
    "start": "55649",
    "end": "62789"
  },
  {
    "text": "thing to use and why people who use it thinks they should be doing that I go",
    "start": "62789",
    "end": "68220"
  },
  {
    "text": "through to the stage maker as well as distributor training because that brings out a lot of really good features of",
    "start": "68220",
    "end": "74310"
  },
  {
    "text": "them extend about the ability to be doing distributor training and it fits very nicely with sage maker and then",
    "start": "74310",
    "end": "82500"
  },
  {
    "text": "finally it's about how it can fit into an end-to-end delivery or from research",
    "start": "82500",
    "end": "88740"
  },
  {
    "text": "to production in one basically place so",
    "start": "88740",
    "end": "97280"
  },
  {
    "text": "let's start to see back in the day when we were kids and I was studying neural",
    "start": "97909",
    "end": "105360"
  },
  {
    "start": "98000",
    "end": "98000"
  },
  {
    "text": "networks early 2000s and all we could not really get large models or large",
    "start": "105360",
    "end": "110790"
  },
  {
    "text": "data set trained for a very obvious reason that we just had to do so many so",
    "start": "110790",
    "end": "116549"
  },
  {
    "text": "many so much compute too many too many basically processes and we didn't have we didn't realize that we how we could",
    "start": "116549",
    "end": "123570"
  },
  {
    "text": "distribute that so every deep learning framework that you look at is on the",
    "start": "123570",
    "end": "130379"
  },
  {
    "text": "basis of building something called a computational ground so if you take a look at this thing that",
    "start": "130379",
    "end": "135569"
  },
  {
    "text": "we have in here if you're trying to compute T then you need to compute u and",
    "start": "135569",
    "end": "141450"
  },
  {
    "text": "K and then to compute u you need lambda and you need Z but Z and K have no",
    "start": "141450",
    "end": "147659"
  },
  {
    "text": "dependency on one another if you can build a system and when that system looks at what you're trying to compute",
    "start": "147659",
    "end": "153450"
  },
  {
    "text": "and discover all of these parallel paths that you can produce and then you can",
    "start": "153450",
    "end": "158549"
  },
  {
    "text": "parallelize the computation then you can be lot faster and compute so many things",
    "start": "158549",
    "end": "166230"
  },
  {
    "text": "at the same time and that is what made deep learning successful 2010 onwards",
    "start": "166230",
    "end": "173099"
  },
  {
    "text": "for more industrial purposes so if you",
    "start": "173099",
    "end": "179159"
  },
  {
    "text": "look at this is the symbolic code of MX net this is not glue on library this is Gloria a pure there's a symbolic code of",
    "start": "179159",
    "end": "185159"
  },
  {
    "text": "MX net when you look at that it is basically you're trying to tell the framework built me a computational graph",
    "start": "185159",
    "end": "193230"
  },
  {
    "text": "built me a fully connected a dense layer and let have it have 64 nodes and then",
    "start": "193230",
    "end": "200069"
  },
  {
    "text": "you would have an activation and then another layer and then you would have an output for softmax that does a",
    "start": "200069",
    "end": "206280"
  },
  {
    "text": "classification for you so you pass that to a deep learning engine and it takes that and turns that into a computational",
    "start": "206280",
    "end": "213269"
  },
  {
    "text": "graph with the parallel basically figures out how I can parallelize it and",
    "start": "213269",
    "end": "218609"
  },
  {
    "text": "then next step you're going to bind data",
    "start": "218609",
    "end": "224299"
  },
  {
    "text": "to your model and then when you bind data it's basically the model is going",
    "start": "224299",
    "end": "230489"
  },
  {
    "text": "to take your data and take the computational graph that it has created for you and then it is going to",
    "start": "230489",
    "end": "237419"
  },
  {
    "text": "basically throw that on a GPUs that has millions of course that can do these parallel operations of multiplication",
    "start": "237419",
    "end": "243359"
  },
  {
    "text": "and addition of floating-point numbers to one another and that's how generally",
    "start": "243359",
    "end": "249599"
  },
  {
    "text": "is a foundation of every deep learning engine that you're going to use weather is going to be tensorflow or MX net or",
    "start": "249599",
    "end": "256430"
  },
  {
    "text": "something else so why do we use MX net",
    "start": "256430",
    "end": "261440"
  },
  {
    "text": "resign makes net firstly for training efficiency so this graph represents",
    "start": "261440",
    "end": "267570"
  },
  {
    "start": "264000",
    "end": "264000"
  },
  {
    "text": "the efficiency of making use of distributed hardware so an ideal",
    "start": "267570",
    "end": "272730"
  },
  {
    "text": "distributed system is when you have a linear relationship between the amount of hardware that you throw at it the",
    "start": "272730",
    "end": "279000"
  },
  {
    "text": "amount of compute that you throw out your problem and how faster you get so that means if you double your hardware",
    "start": "279000",
    "end": "284220"
  },
  {
    "text": "and you can make your training to have your training time that's ideal because that's a linear relationship then if you",
    "start": "284220",
    "end": "291990"
  },
  {
    "text": "look at it on 256 GPUs that means 16 different machines in a cluster include",
    "start": "291990",
    "end": "300240"
  },
  {
    "text": "that includes things like Network latency and all of that what we have ended up with is a 92 percent efficiency",
    "start": "300240",
    "end": "306600"
  },
  {
    "text": "for resin at 152 which is a very large network that means as you basically",
    "start": "306600",
    "end": "313440"
  },
  {
    "text": "through twice as much compute you become 100 at 82% faster so that means it's",
    "start": "313440",
    "end": "322530"
  },
  {
    "text": "almost linear for such a huge model so that is training efficiency and training",
    "start": "322530",
    "end": "327780"
  },
  {
    "text": "efficiency if you do your modeling correctly is going to hugely reduce to numbers I can give you an example we had",
    "start": "327780",
    "end": "333690"
  },
  {
    "text": "in Japan that were just a few tweaks for a company in Japan that we made their",
    "start": "333690",
    "end": "339570"
  },
  {
    "text": "training more efficient they were they had a projection of 22 million a year",
    "start": "339570",
    "end": "344640"
  },
  {
    "text": "saving on the compute money that they were paying that sort of stuff so if that can be quite expensive because the",
    "start": "344640",
    "end": "350520"
  },
  {
    "text": "this beefy GPU machines are just pricey and the more you can utilize them the",
    "start": "350520",
    "end": "357720"
  },
  {
    "text": "less you pay for for your training then adding to that there is Amazon sage",
    "start": "357720",
    "end": "364350"
  },
  {
    "text": "maker so Amazon sage maker is created as a zero setup tool that can have an end",
    "start": "364350",
    "end": "370350"
  },
  {
    "text": "to an environment for you and it can do a lot of distribution for you it builds a distributed cluster and it trains your",
    "start": "370350",
    "end": "376680"
  },
  {
    "text": "model in the distributor cluster and it adds security features and it would be in your V PC so all of that cluster that",
    "start": "376680",
    "end": "383010"
  },
  {
    "text": "you want to build with the security on the top you don't have to do any sort of",
    "start": "383010",
    "end": "388039"
  },
  {
    "text": "configuration for it and you pay by the second so you're done your cluster has",
    "start": "388700",
    "end": "394140"
  },
  {
    "text": "been created the training is done the training is finished the model is saved into an s3 bucket the cluster is",
    "start": "394140",
    "end": "400950"
  },
  {
    "text": "destroyed and you pay for any second basically for the number of seconds that your cluster was up and running so and then we talked",
    "start": "400950",
    "end": "408810"
  },
  {
    "text": "about their training efficiency one of the probably the biggest bottleneck you have for training a distributed system",
    "start": "408810",
    "end": "415560"
  },
  {
    "text": "is your i/o because your compute is fast but your i/o is not going to be as fast",
    "start": "415560",
    "end": "421200"
  },
  {
    "text": "I Oh is going to be your bottleneck most of the optimization you do is there so we introduced in Sage Maker when we when",
    "start": "421200",
    "end": "427830"
  },
  {
    "text": "it came out some built-in algorithms and then last summer during the New York",
    "start": "427830",
    "end": "435270"
  },
  {
    "text": "summit we introduced something called",
    "start": "435270",
    "end": "439340"
  },
  {
    "text": "streaming so streaming is when s3 to your training instances is basically",
    "start": "440540",
    "end": "448830"
  },
  {
    "text": "quite fast and it can just send your information to different basically nodes that you have and then as of last summer",
    "start": "448830",
    "end": "454530"
  },
  {
    "text": "we introduced it streaming for custom algorithms so that what you see in here is for one of the built-in algorithms",
    "start": "454530",
    "end": "460170"
  },
  {
    "text": "for the PCA algorithm you can find that in the blog in a blog post and there's a reference to that as you see here old a",
    "start": "460170",
    "end": "467070"
  },
  {
    "text": "whole bunch of indicators are getting better whether it is the time to start of your model where there is basically",
    "start": "467070",
    "end": "472350"
  },
  {
    "text": "the amount of data that is stream so we introduced that to your own algorithms too so that means you can go and develop",
    "start": "472350",
    "end": "478680"
  },
  {
    "text": "an algorithm and then use this streaming for custom algorithm in order to use the efficiencies that is built into",
    "start": "478680",
    "end": "485100"
  },
  {
    "text": "connection of s tree to essays to Amazon sage maker in order to not to starve",
    "start": "485100",
    "end": "490140"
  },
  {
    "text": "your GPU instances the way distributor training goes about is that you have your models in say in s3 from s3 you",
    "start": "490140",
    "end": "497940"
  },
  {
    "text": "have your code basically somewhere and then your data is going to be streamed or copied into your basically nodes of",
    "start": "497940",
    "end": "505170"
  },
  {
    "text": "your training cluster and then your model is trained and the result of that model is being put another basically in",
    "start": "505170",
    "end": "511260"
  },
  {
    "text": "an s3 bucket and the way it's done it uses an EC or cluster ACS cluster sorry",
    "start": "511260",
    "end": "516780"
  },
  {
    "text": "an ACS cluster an elastic container service and then this cluster can be",
    "start": "516780",
    "end": "523620"
  },
  {
    "text": "within a bid in your own VPC the connections can be encrypted and all of that extra securities that you would be",
    "start": "523620",
    "end": "529950"
  },
  {
    "text": "normally building a cluster and all of these basically efficiency of the data and connectivity and the location that you want to see when",
    "start": "529950",
    "end": "536490"
  },
  {
    "text": "your source of your data is how far your data goes to reach the server all of that is done behind the scene for you",
    "start": "536490",
    "end": "541710"
  },
  {
    "text": "with a single line of code or a single click so you don't have to do anything about it you don't have to worry about it you can't focus on your developing",
    "start": "541710",
    "end": "548430"
  },
  {
    "start": "548000",
    "end": "548000"
  },
  {
    "text": "your model we also introduced something between last year and now automatic",
    "start": "548430",
    "end": "554610"
  },
  {
    "text": "model training so I do have a basically chalk talk about that that get very scientific about it later on but what we",
    "start": "554610",
    "end": "561660"
  },
  {
    "text": "have what were you doing here is do you have let's say you have an ax stereo than your that has 32 different volume",
    "start": "561660",
    "end": "568500"
  },
  {
    "text": "knobs and you do want to make the best sound out of that and the permutations that start going mad so and the same",
    "start": "568500",
    "end": "576510"
  },
  {
    "text": "thing goes with the hyper parameters of your model that you want to base into the hyper parameter optimization and every time you introduce a new parameter",
    "start": "576510",
    "end": "584730"
  },
  {
    "text": "new hyper parameter what you end up with is exponentially increasing the number of permutations you're going to have and",
    "start": "584730",
    "end": "591180"
  },
  {
    "text": "you get into this curse of dimensionality and basically based on the laws of multiplication so what we do",
    "start": "591180",
    "end": "596940"
  },
  {
    "text": "in here we have used a Bayesian hyper parameter optimization that is build a",
    "start": "596940",
    "end": "602970"
  },
  {
    "text": "machine learning model that looks at your model as they're being trained and it figures out and locks it in which of",
    "start": "602970",
    "end": "609510"
  },
  {
    "text": "these parameters are work best for the results of your model so it uses machine",
    "start": "609510",
    "end": "614670"
  },
  {
    "text": "learning on the top of your model and uses machine learning to figure out the best combination of hyper parameters and that would that used to be hundreds and",
    "start": "614670",
    "end": "622650"
  },
  {
    "text": "hundreds of hours of scientific work for just little tweaking and waiting for another training to go through to see",
    "start": "622650",
    "end": "627900"
  },
  {
    "text": "what the result is oh that wasn't good let's do it the other way so and since this is a Bayesian model it's just very",
    "start": "627900",
    "end": "633750"
  },
  {
    "text": "efficient with the number of samples that it takes it's very quickly zeroes in with a very very few basically iterations that",
    "start": "633750",
    "end": "640050"
  },
  {
    "text": "figure out where those hyper parameters are at their best in terms of the efficiency of your model so this was all",
    "start": "640050",
    "end": "649829"
  },
  {
    "text": "about training efficiency and how you can train better how about the developer",
    "start": "649829",
    "end": "655200"
  },
  {
    "text": "productivity should your developers spend 80 percent 85 percent of their",
    "start": "655200",
    "end": "661050"
  },
  {
    "text": "time sitting down and just thinking about what went wrong with my model and",
    "start": "661050",
    "end": "666360"
  },
  {
    "text": "I have no better no way of debugging it or should they spend 80 90 percent of their time doing something new on doing",
    "start": "666360",
    "end": "671740"
  },
  {
    "text": "less debugging and here's the evolution of frameworks so early on there was the",
    "start": "671740",
    "end": "680020"
  },
  {
    "start": "674000",
    "end": "674000"
  },
  {
    "text": "good old theano and then came cafe and the AMC antique a tensorflow made a case for an industrial grades deep learning",
    "start": "680020",
    "end": "688500"
  },
  {
    "text": "framework with one thing it was something called symbolic that you just did like the code that I had created",
    "start": "688500",
    "end": "694180"
  },
  {
    "text": "before you create a network you bind data to it and then you have no idea",
    "start": "694180",
    "end": "700240"
  },
  {
    "text": "what's going on and then at some point it tells you in the layer three to five I have a shape or good luck figuring out",
    "start": "700240",
    "end": "706210"
  },
  {
    "text": "what's wrong so these are the symbolic ones so MX nets core is the same way",
    "start": "706210",
    "end": "711640"
  },
  {
    "text": "caris is a high level API but it still does the same then came the next move that came by chain ER so chain are",
    "start": "711640",
    "end": "718750"
  },
  {
    "text": "introduced something called imperative model so how it works is that it's like",
    "start": "718750",
    "end": "724720"
  },
  {
    "text": "the way we're used to coding if-then-else and a for loop and an iterator and that sort of stuff so",
    "start": "724720",
    "end": "730650"
  },
  {
    "text": "breakpoints you can debug it but they lost the performance of these models that were building this computational",
    "start": "730650",
    "end": "737140"
  },
  {
    "text": "graph behind the scene and optimizing it for a distribution point torch is the",
    "start": "737140",
    "end": "742150"
  },
  {
    "text": "same way then came gluon we developed blue on in 2017 we released it is a part",
    "start": "742150",
    "end": "747670"
  },
  {
    "text": "of the Apache project to which I belong and gluon is a high-level API very similar to PI torch but it has this",
    "start": "747670",
    "end": "754630"
  },
  {
    "text": "thing that you can take your network and just say network hybridize it suddenly changes from the imperative mood to the",
    "start": "754630",
    "end": "761560"
  },
  {
    "text": "symbolic mood so it combines the best of the two world it's like very friendly in",
    "start": "761560",
    "end": "767320"
  },
  {
    "text": "terms of developers being able to develop things quickly and well while at the same time it gives you all the",
    "start": "767320",
    "end": "773230"
  },
  {
    "text": "performance that you want to get from a symbolic framework so as to bring in the",
    "start": "773230",
    "end": "778630"
  },
  {
    "text": "best of the two worlds together so your model from your experiment to your",
    "start": "778630",
    "end": "783700"
  },
  {
    "text": "production remains within the same boundary so you don't have to go in and out and just convert things together so",
    "start": "783700",
    "end": "789240"
  },
  {
    "text": "why this blue one I already mentioned a few of things so it's the code is easy",
    "start": "789240",
    "end": "795220"
  },
  {
    "text": "to understand it's flexible it's gotten pretty imperative structure its dynamic",
    "start": "795220",
    "end": "801550"
  },
  {
    "text": "graphs is quite nice because you don't have to statically calculate what is going to be output of this layer what is the input",
    "start": "801550",
    "end": "808120"
  },
  {
    "text": "of the next layer it dynamically calculates what how the graph should look like it has the same high",
    "start": "808120",
    "end": "813910"
  },
  {
    "text": "performance of MX nets in its symbolic mood at the end of the day that's why gluon we think is a very good place to",
    "start": "813910",
    "end": "820120"
  },
  {
    "text": "start your coding the code that we saw before or this is how the basically code",
    "start": "820120",
    "end": "826090"
  },
  {
    "text": "looks like so that would be very familiar with the PI torch guys in here so I am building here a basically",
    "start": "826090",
    "end": "833830"
  },
  {
    "text": "Network it's a hybrid sequential network that means I'm stacking layer sequentially but I can hybridize it in",
    "start": "833830",
    "end": "839110"
  },
  {
    "text": "order to make it symbolic and then I'm adding a dense layer a fully connected layer 64 nodes",
    "start": "839110",
    "end": "845410"
  },
  {
    "text": "activation is relu and then I have a discrimination layer that I have a basically ten units at the end that's my",
    "start": "845410",
    "end": "852160"
  },
  {
    "text": "output that's where I want to do classification for ten classes and then I can all different sorts of loss",
    "start": "852160",
    "end": "859150"
  },
  {
    "text": "function I can assign in here I can have initialization of my model with basically different sorts of",
    "start": "859150",
    "end": "864940"
  },
  {
    "text": "initializers in this case Xavier it could be all random normal it could be random uniform it could be just simply",
    "start": "864940",
    "end": "872200"
  },
  {
    "text": "zeros it could be a fixed number or it could be the tensors that you have gone",
    "start": "872200",
    "end": "878140"
  },
  {
    "text": "from the weights of another network you have trained and you can start with the basically weights of a different network which is used in the like so transfer",
    "start": "878140",
    "end": "885370"
  },
  {
    "text": "learning then you can have a choice of the the trainer that would be optimizer",
    "start": "885370",
    "end": "890890"
  },
  {
    "text": "so you can have stochastic gradient descent you can have Adam you can have Armas prom as well as there are some",
    "start": "890890",
    "end": "897810"
  },
  {
    "text": "optimizer that are built for cluster and large-scale training for instance there",
    "start": "897810",
    "end": "903430"
  },
  {
    "text": "is Signum that is using only the sign of gradient and is used for large clusters",
    "start": "903430",
    "end": "909340"
  },
  {
    "text": "of training if you're doing is a lot more efficient because it's just bits that going around rather than the whole floating-point numbers for your",
    "start": "909340",
    "end": "915490"
  },
  {
    "text": "gradients so it's a lot less noisy in your network or there is the big SGD",
    "start": "915490",
    "end": "922530"
  },
  {
    "text": "that is made for very large batches of how in the range of thousands there are",
    "start": "922530",
    "end": "930130"
  },
  {
    "text": "also things like the learning rate scheduler that you can just pass your learning rate",
    "start": "930130",
    "end": "935310"
  },
  {
    "text": "scheduler to your to your optimizer object and then it just does all the",
    "start": "935310",
    "end": "940500"
  },
  {
    "text": "scheduling automatically for you just have to decide how you want to schedule your your your learning rate so that",
    "start": "940500",
    "end": "946320"
  },
  {
    "text": "Israeli really quite easy and then here is the for loop here's where the magic happens this is where you're doing a",
    "start": "946320",
    "end": "953010"
  },
  {
    "text": "training and the training you're having here is a for loop that means you can actually put a breakpoint in there and",
    "start": "953010",
    "end": "958950"
  },
  {
    "text": "just look inside your variables to see what's going on with your code what's wrong with your code why is it why is",
    "start": "958950",
    "end": "964920"
  },
  {
    "text": "the error that you're getting and makes the developers a lot easier to work with the developer productivity doesn't stop",
    "start": "964920",
    "end": "971250"
  },
  {
    "text": "here because we are continuously creating toolset toolkits like we",
    "start": "971250",
    "end": "976710"
  },
  {
    "text": "recently introduced the gluon cv it's a deep learning toolkit for computer vision so we have implemented and",
    "start": "976710",
    "end": "983730"
  },
  {
    "text": "optimized a whole bunch of famous networked like at the VG G's and you know res Nets and we have optimized them",
    "start": "983730",
    "end": "990990"
  },
  {
    "text": "so you can use them for transfer learning for a model you can just use them out of box so hours and hours of",
    "start": "990990",
    "end": "997500"
  },
  {
    "text": "basically optimization and training compute tom has gone to this models so you can just use the model zoo and say I",
    "start": "997500",
    "end": "1002810"
  },
  {
    "text": "want to use a VG 16 and and just use that the other things that they have apart from pre training model they've",
    "start": "1002810",
    "end": "1009320"
  },
  {
    "text": "got lots of utilities that are useful for computer vision like for instance data augmentation utilities and all of",
    "start": "1009320",
    "end": "1014870"
  },
  {
    "text": "that it also has a whole bunch of the public datasets that are available to",
    "start": "1014870",
    "end": "1020240"
  },
  {
    "text": "you through the data library so it's so the data API so if you want to do an experiment very quickly on a public data",
    "start": "1020240",
    "end": "1026928"
  },
  {
    "text": "set you can use blue on TV in order to do a computer vision glow and NLP very",
    "start": "1026929",
    "end": "1033438"
  },
  {
    "text": "similar for NLP tasks for basically it's it's got basically the embedding",
    "start": "1033439",
    "end": "1039410"
  },
  {
    "text": "capabilities it's got the pre train models and it's got the data API and the",
    "start": "1039410",
    "end": "1046130"
  },
  {
    "text": "same sort of thing for basically rapid",
    "start": "1046130",
    "end": "1053690"
  },
  {
    "text": "development of prototypes so that",
    "start": "1053690",
    "end": "1059210"
  },
  {
    "start": "1059000",
    "end": "1059000"
  },
  {
    "text": "doesn't stop here we introduced recently Karis back-end for M X net it is and",
    "start": "1059210",
    "end": "1066679"
  },
  {
    "text": "what you see in here there some from from github you can see some",
    "start": "1066679",
    "end": "1071840"
  },
  {
    "text": "of the comparisons that we have done for different sorts of backsides that we have in here you can compare tensorflow",
    "start": "1071840",
    "end": "1078410"
  },
  {
    "text": "back end to Cara's back in and you see as the number of nodes go up like when you soo go to this basing the back size",
    "start": "1078410",
    "end": "1084650"
  },
  {
    "text": "of to 52 56 on 8p 3 16x large compared",
    "start": "1084650",
    "end": "1090350"
  },
  {
    "text": "to the line before that you see still showing image per second processing it's just still going up in MX net while it",
    "start": "1090350",
    "end": "1097130"
  },
  {
    "text": "started reversing in tensorflow you see that basically that the processing is so much faster so all you need to do if you",
    "start": "1097130",
    "end": "1104030"
  },
  {
    "text": "change your back-end you get the benefit of the performance so in some project I",
    "start": "1104030",
    "end": "1110090"
  },
  {
    "text": "was doing in Portugal we just changed the backend for that a specific model for that a specific data set we just",
    "start": "1110090",
    "end": "1115940"
  },
  {
    "text": "doubled the speed so that sort of stuff it's not guaranteed always so don't get me that I'm saying it doubled it's just",
    "start": "1115940",
    "end": "1121700"
  },
  {
    "text": "an experiment from one project we were doing so what else",
    "start": "1121700",
    "end": "1127640"
  },
  {
    "text": "there are things apart from the gluon NLP that provides your natural language processing component we have also",
    "start": "1127640",
    "end": "1133790"
  },
  {
    "text": "produced something called a sequence the sequence toolkit based on Apache MX Ned my colleagues in Berlin developed that",
    "start": "1133790",
    "end": "1139850"
  },
  {
    "text": "we call it sockets and gates and github and this is the thing that is behind the",
    "start": "1139850",
    "end": "1144890"
  },
  {
    "text": "translation we do in Amazon retail so you we have made that available to you you can actually go on in github and",
    "start": "1144890",
    "end": "1151010"
  },
  {
    "text": "just use it you don't know anyone anything so and these are the stuff that we have done around MX net to make it",
    "start": "1151010",
    "end": "1157280"
  },
  {
    "text": "available for everyone and make them very basically developer friendly it",
    "start": "1157280",
    "end": "1163730"
  },
  {
    "text": "doesn't stop there when we talk to the customer when we started developing these things we were thinking they're",
    "start": "1163730",
    "end": "1169400"
  },
  {
    "text": "academically so we were very much focused on the training performance and the more we worked with the customers it",
    "start": "1169400",
    "end": "1174650"
  },
  {
    "text": "came that you know what I really don't care much about training because I don't do a cluster of 256 but I really care",
    "start": "1174650",
    "end": "1181760"
  },
  {
    "text": "about inference I really care about that how easily I can deploy that then we",
    "start": "1181760",
    "end": "1187820"
  },
  {
    "text": "started working very very heavily on the performance and the diversity of the inference that we do so here is some of",
    "start": "1187820",
    "end": "1194570"
  },
  {
    "text": "the most recent developments that we've done so we released Tenzer RT",
    "start": "1194570",
    "end": "1202700"
  },
  {
    "text": "Tenzer RT makes basically more takes basically makes better use of your",
    "start": "1202700",
    "end": "1208519"
  },
  {
    "text": "inference GPU for inference as you see here from Resident 101 that we doubled",
    "start": "1208519",
    "end": "1214159"
  },
  {
    "text": "that it doubles the speed for inference if you use it basically if you stands or",
    "start": "1214159",
    "end": "1221059"
  },
  {
    "text": "RT compared to not using Tanzer RT to the the to the slowest that is Alex and that is one point for time faster for",
    "start": "1221059",
    "end": "1227600"
  },
  {
    "text": "your inference and inference is your bread and butter because it might be your customers exposed to the entrance endpoint they can't wait they go wait",
    "start": "1227600",
    "end": "1235190"
  },
  {
    "text": "they go somewhere else so that is Tenzer RT that's one of the more recent implementations we move forward so there",
    "start": "1235190",
    "end": "1244190"
  },
  {
    "text": "is n nvm you would hear more about it one of the things that we do in here is",
    "start": "1244190",
    "end": "1250519"
  },
  {
    "text": "we compile the models for the hot target hardware so with a line of code or two you can say I want this thing to go on",
    "start": "1250519",
    "end": "1257299"
  },
  {
    "text": "at some more raspberry pi or want it to go beyond Pascal or a 1-man this and that it does create an optimized model",
    "start": "1257299",
    "end": "1264379"
  },
  {
    "text": "for that's basically your model would be optimize the output D basically your art if model artifact would optimize for",
    "start": "1264379",
    "end": "1270649"
  },
  {
    "text": "that architecture the target architecture so that means you can have efficiency on multiple outputs without",
    "start": "1270649",
    "end": "1276950"
  },
  {
    "text": "having to tweak it yet again I'm not claiming you cannot tweak it and get better manual results per architecture",
    "start": "1276950",
    "end": "1284029"
  },
  {
    "text": "but try to imagine the efficiency of just saying I want this model to be on Raspberry Pi and on basically Voltas and",
    "start": "1284029",
    "end": "1291590"
  },
  {
    "text": "on a Pascal and on this and that so it can actually does be compiling recompile",
    "start": "1291590",
    "end": "1297259"
  },
  {
    "text": "your model for the target forget for the target hardware that you're going to run on it so that's an area things we've",
    "start": "1297259",
    "end": "1302330"
  },
  {
    "text": "done then there is portability it doesn't end here you want your models",
    "start": "1302330",
    "end": "1307700"
  },
  {
    "text": "you don't want to be locked in into a model artifact or locked into a certain hardware so we should think about portability so again trenin VM we have",
    "start": "1307700",
    "end": "1316210"
  },
  {
    "start": "1312000",
    "end": "1312000"
  },
  {
    "text": "developed that so when you look at these two so you have a computational graph and when you have an abstraction layer",
    "start": "1316210",
    "end": "1321799"
  },
  {
    "text": "through an nvm through that basically the compiler you can actually move across different sorts of hardware I",
    "start": "1321799",
    "end": "1328369"
  },
  {
    "text": "just mentioned it not only is it efficient but it also makes it possible otherwise you have to be tweaking",
    "start": "1328369",
    "end": "1333799"
  },
  {
    "text": "everything by hand until you get something wrong something right you have to know every hardware you're working with and let's",
    "start": "1333799",
    "end": "1339410"
  },
  {
    "text": "say what you're doing you're building an app that destroy to do some computer vision do you really want to spend your",
    "start": "1339410",
    "end": "1345350"
  },
  {
    "text": "time trying to learn about every hardware that is out there or you want us to do that for you and you just",
    "start": "1345350",
    "end": "1351440"
  },
  {
    "text": "compile the model for the new hardware ports ability comes also that your model",
    "start": "1351440",
    "end": "1356840"
  },
  {
    "text": "artifacts can move between different models if your PI torch op sure just continue continue developing in PI torch",
    "start": "1356840",
    "end": "1363980"
  },
  {
    "text": "you don't have to move the gluon but through onyx you can actually get your final you can get your model artifact",
    "start": "1363980",
    "end": "1370160"
  },
  {
    "text": "from PI torch and just make the inference with MX net the deployment and",
    "start": "1370160",
    "end": "1375680"
  },
  {
    "text": "use the benefit of this piece of MX net while you continue coding in the environment that you actually like to",
    "start": "1375680",
    "end": "1382040"
  },
  {
    "text": "work on so finally we're going to the deployment so deployment with sage maker",
    "start": "1382040",
    "end": "1388640"
  },
  {
    "start": "1387000",
    "end": "1387000"
  },
  {
    "text": "is that you can have a complete DevOps environment you can say I have created",
    "start": "1388640",
    "end": "1393860"
  },
  {
    "text": "this model I want to deploy it it's the one line of code and some configuration if you want to add something to it and",
    "start": "1393860",
    "end": "1399980"
  },
  {
    "text": "what it does it creates a cluster the Dockers cluster dock Rises your model",
    "start": "1399980",
    "end": "1406370"
  },
  {
    "text": "drops it into these nodes puts a load balancer in front of it it creates a",
    "start": "1406370",
    "end": "1411470"
  },
  {
    "text": "basically a micro service architecture entirely with a single line of code that you just say deployment model and it",
    "start": "1411470",
    "end": "1418370"
  },
  {
    "text": "doesn't have to be developed in Sage Maker it could be your own model that you go and just package it as a docker image and you bring it in here and then",
    "start": "1418370",
    "end": "1425590"
  },
  {
    "text": "then it just does that for you so you can have a be testing it can blueprint",
    "start": "1425590",
    "end": "1430610"
  },
  {
    "text": "as deployments you can say I want to have multiples of profile you can have the percentage twenty percent goes to",
    "start": "1430610",
    "end": "1436550"
  },
  {
    "text": "this model 50 percent goes that model 10 percent 10 percent to these models that kind of architecture so all of that",
    "start": "1436550",
    "end": "1442700"
  },
  {
    "text": "thing is done really without your having to worry about it and it's also scaling so that means more traffic coming in you",
    "start": "1442700",
    "end": "1450050"
  },
  {
    "text": "would have more nodes less traffic coming in you go back to the minimum that you have decided there is one more",
    "start": "1450050",
    "end": "1456320"
  },
  {
    "text": "thing I haven't had in this slide since I have still 40 minutes to go we have",
    "start": "1456320",
    "end": "1462770"
  },
  {
    "text": "made MX nets polyglot poly multi-line multilingual we realize that there's the",
    "start": "1462770",
    "end": "1468020"
  },
  {
    "text": "decision to work too work with our and they don't want to use Python there are people who want to use",
    "start": "1468020",
    "end": "1473090"
  },
  {
    "text": "Perl there are people who want to use Java Scala so the actual high level API comes",
    "start": "1473090",
    "end": "1480180"
  },
  {
    "text": "in all different languages so you're no longer bound to its Python and it's Python in this Python so we have created",
    "start": "1480180",
    "end": "1485850"
  },
  {
    "text": "all of these language api's that you can actually use and language of your choice for developing your gluon MX head models",
    "start": "1485850",
    "end": "1492780"
  },
  {
    "text": "so to recap so MX that gives you the engine the fast engine underneath gluon",
    "start": "1492780",
    "end": "1501660"
  },
  {
    "start": "1496000",
    "end": "1496000"
  },
  {
    "text": "gives you the developer productivity an amazon sage maker brings that together",
    "start": "1501660",
    "end": "1507030"
  },
  {
    "text": "in an enterprise-grade environment with an end-to-end devops as well as adding",
    "start": "1507030",
    "end": "1512730"
  },
  {
    "text": "hyper parameter tuning automats to you and the hyper parameter tuning again is",
    "start": "1512730",
    "end": "1517860"
  },
  {
    "text": "just another line of code to add to your what you do so the whole thing comes together quite easily for you to be able",
    "start": "1517860",
    "end": "1523380"
  },
  {
    "text": "to focus on developing efficient models as opposed to thinking about computing",
    "start": "1523380",
    "end": "1529650"
  },
  {
    "text": "gradients or I don't know just doing your building any or building a Dockers cluster and ECS cluster so why this my",
    "start": "1529650",
    "end": "1537090"
  },
  {
    "text": "part is done I'm passing over to our friends from work day and they would explain their project to you",
    "start": "1537090",
    "end": "1544580"
  },
  {
    "text": "[Applause] thanks for coming I'm Vivek shiver stove",
    "start": "1547530",
    "end": "1553270"
  },
  {
    "text": "I'm a machine learning product manager at workday and my partner in crime is Henry Zhang he's a machine learning",
    "start": "1553270",
    "end": "1559000"
  },
  {
    "text": "engineer at workday essentially the whole purpose of building a machine",
    "start": "1559000",
    "end": "1566410"
  },
  {
    "text": "learning solution using MX net is to simplify and automate some of the",
    "start": "1566410",
    "end": "1572410"
  },
  {
    "text": "processes that we have in workday one of the key things that we identified early on was information extraction for",
    "start": "1572410",
    "end": "1580720"
  },
  {
    "text": "enterprise documents so that sounds kind of very abstract so before I get into",
    "start": "1580720",
    "end": "1586960"
  },
  {
    "text": "the details I just want to show our fans of how many of you actually know what is one day okay that's great so a lot of",
    "start": "1586960",
    "end": "1595930"
  },
  {
    "text": "you know it for those who don't what Bay is a company that provides HR",
    "start": "1595930",
    "end": "1601600"
  },
  {
    "text": "and Finance applications for your enterprise and it's a cloud provider of",
    "start": "1601600",
    "end": "1606930"
  },
  {
    "text": "your HR and Finance business applications it runs your HR and Finance business applications in the cloud so",
    "start": "1606930",
    "end": "1615030"
  },
  {
    "text": "the basic goal when you talk about enterprise documents for an enterprise",
    "start": "1615030",
    "end": "1620100"
  },
  {
    "text": "application it's quite waiting think of you know say your company has what be or",
    "start": "1620100",
    "end": "1627640"
  },
  {
    "text": "subscribe to what day one of the things we provide you as a user is to submit",
    "start": "1627640",
    "end": "1633190"
  },
  {
    "text": "your expenses so you would log into what they submit your Raymond travel expenses",
    "start": "1633190",
    "end": "1638710"
  },
  {
    "text": "so the document they're all logged it becomes a source of truth for storing and processing your receipts so",
    "start": "1638710",
    "end": "1646480"
  },
  {
    "text": "typically what you would do is you would manually enter all that information in that receipt take an example of an",
    "start": "1646480",
    "end": "1654310"
  },
  {
    "text": "account payable department in your company they tend to process a lot of supplier and vendor invoices when your",
    "start": "1654310",
    "end": "1661690"
  },
  {
    "text": "company buy certain products they get an invoice that invoice goes through a processing piece and what day is the",
    "start": "1661690",
    "end": "1669640"
  },
  {
    "text": "platform where you store and process that document and in the end you make that payment to your supplier the third",
    "start": "1669640",
    "end": "1677650"
  },
  {
    "text": "offering if you think about it can be so ugly has an end-to-end recruiting",
    "start": "1677650",
    "end": "1683260"
  },
  {
    "text": "solution where a recruiter basically will you use what they as a single",
    "start": "1683260",
    "end": "1689290"
  },
  {
    "text": "source of truth to store and process resumes of potential candidates who have",
    "start": "1689290",
    "end": "1695980"
  },
  {
    "text": "applied to your you know job racks that the recruiters put out so you have all",
    "start": "1695980",
    "end": "1701140"
  },
  {
    "text": "these enterprise documents that get generated within workday we stored them",
    "start": "1701140",
    "end": "1706690"
  },
  {
    "text": "you know what be users tend to you know process them but we found out that by",
    "start": "1706690",
    "end": "1715360"
  },
  {
    "text": "using machine learning is specifically deep learning we can actually improve the efficiency of some business",
    "start": "1715360",
    "end": "1721630"
  },
  {
    "text": "processes that lead with or that deal with these documents so I'll talk today",
    "start": "1721630",
    "end": "1728170"
  },
  {
    "text": "about two of the specific use cases that we have built a machine learning solution for especially using Apache",
    "start": "1728170",
    "end": "1736990"
  },
  {
    "text": "onyx net so the talk today I'm gonna speak a little bit about the business case a little bit more deeper details on",
    "start": "1736990",
    "end": "1744400"
  },
  {
    "text": "the first one which is going to be your expense report automation so how we have",
    "start": "1744400",
    "end": "1749650"
  },
  {
    "text": "automated that process in workday and the second is going to be the invoice",
    "start": "1749650",
    "end": "1756340"
  },
  {
    "text": "processing automation so how by using machine learning we are enabling that to",
    "start": "1756340",
    "end": "1761650"
  },
  {
    "text": "get automated after that Henry will come forward and talk about the framework",
    "start": "1761650",
    "end": "1768010"
  },
  {
    "text": "we've used I guess no guesses we're all here because we've used Apache and it's not the third we'll talk about is the",
    "start": "1768010",
    "end": "1775510"
  },
  {
    "text": "model and how we build that model and the algorithm for that and we'll talk about the results we've achieved in",
    "start": "1775510",
    "end": "1782230"
  },
  {
    "text": "terms of accuracy for scanning the document and you know identifying appropriate fields I'll come back to",
    "start": "1782230",
    "end": "1790330"
  },
  {
    "text": "talk about how we have productized this entire thing on the workday stack so essentially what Cyrus was talking",
    "start": "1790330",
    "end": "1796360"
  },
  {
    "text": "about in terms of running inference on the world a stack and you know high",
    "start": "1796360",
    "end": "1802300"
  },
  {
    "text": "performant inference and some key learnings from that so let's take the",
    "start": "1802300",
    "end": "1808990"
  },
  {
    "text": "first business use case so typically an expense report filing",
    "start": "1808990",
    "end": "1814570"
  },
  {
    "start": "1809000",
    "end": "1809000"
  },
  {
    "text": "process is a user logs in submits a receipt manually enters feels like",
    "start": "1814570",
    "end": "1822090"
  },
  {
    "text": "amount that was spent where the expense happened and the date the expenditure",
    "start": "1822090",
    "end": "1827650"
  },
  {
    "text": "took place and submits that report that goes to an approval from a manager goes",
    "start": "1827650",
    "end": "1834340"
  },
  {
    "text": "to the finance department accounts to take a look at it and make sure everything is kosher and then the",
    "start": "1834340",
    "end": "1840039"
  },
  {
    "text": "reimbursement check comes to your bank or to your house so what we identified when talking to customers is that some",
    "start": "1840039",
    "end": "1846309"
  },
  {
    "text": "of the top travel and expense pain points was employees either loser receipts the receipts are crumbled and",
    "start": "1846309",
    "end": "1852640"
  },
  {
    "text": "kept somewhere there are errors manually entering that information so all of this",
    "start": "1852640",
    "end": "1858850"
  },
  {
    "text": "in short basically it takes time to reconcile simple things like filing an",
    "start": "1858850",
    "end": "1864580"
  },
  {
    "text": "expense report and time is money especially in the enterprise world the",
    "start": "1864580",
    "end": "1871720"
  },
  {
    "text": "second business case is the accounts payable invoice animation so in word day",
    "start": "1871720",
    "end": "1879130"
  },
  {
    "text": "we deal with invoices basically in the thousands per week for some of our large",
    "start": "1879130",
    "end": "1885730"
  },
  {
    "text": "customers the process of invoice processing is the typical business",
    "start": "1885730",
    "end": "1892090"
  },
  {
    "text": "process is quite involved and involves multiple touchpoints the invoice is",
    "start": "1892090",
    "end": "1899110"
  },
  {
    "text": "scanned the various fields in the invoice including each line item vendor name is all manually typed and then that",
    "start": "1899110",
    "end": "1909669"
  },
  {
    "text": "invoice is in routed to the appropriate accounting department of the cost center and it's then goes through a review",
    "start": "1909669",
    "end": "1915250"
  },
  {
    "text": "process code is attached and the invoice is finally approved once the invoice is",
    "start": "1915250",
    "end": "1920980"
  },
  {
    "text": "approved it gets entered as a journal line in your general ledger so all of",
    "start": "1920980",
    "end": "1926200"
  },
  {
    "text": "this happens within the work base system but the business process itself has a lot of manual steps so what you will see",
    "start": "1926200",
    "end": "1932710"
  },
  {
    "text": "is basically how we have used machine learning to at least automate parts of this process so that this process",
    "start": "1932710",
    "end": "1939250"
  },
  {
    "text": "becomes less painful for our customers and it leads to more efficient",
    "start": "1939250",
    "end": "1944490"
  },
  {
    "text": "overall but customers are using the worldA product so the solution we have",
    "start": "1944490",
    "end": "1951520"
  },
  {
    "text": "basically used is twofold there are based on computer vision and NLU computer vision basically for when a",
    "start": "1951520",
    "end": "1960190"
  },
  {
    "text": "document is presented you have no idea what the document is could be a receipt it could be an invoice so computer",
    "start": "1960190",
    "end": "1966310"
  },
  {
    "text": "vision to basically extract boxes of text from the document and Annalee to",
    "start": "1966310",
    "end": "1973480"
  },
  {
    "text": "understand what the text means so that when you upload a receipt we can auto",
    "start": "1973480",
    "end": "1978670"
  },
  {
    "text": "populate it order populate in the amount the date the merchant name for example and all you have to do is click Submit",
    "start": "1978670",
    "end": "1985990"
  },
  {
    "text": "same thing with invoices we can auto populate the window name the item number",
    "start": "1985990",
    "end": "1993970"
  },
  {
    "text": "the description for the item and the price so allow in right Henry to go into",
    "start": "1993970",
    "end": "1999910"
  },
  {
    "text": "how we built this solution all right",
    "start": "1999910",
    "end": "2005090"
  },
  {
    "text": "yeah so the first step for a machine learning application especially that has",
    "start": "2005090",
    "end": "2010590"
  },
  {
    "text": "deep learning involved this choosing framework we are already over the era of",
    "start": "2010590",
    "end": "2015930"
  },
  {
    "text": "piano and torch which are you know very good for research purposes but not",
    "start": "2015930",
    "end": "2021200"
  },
  {
    "text": "incredibly difficult to productize so for us our requirement is number one it",
    "start": "2021200",
    "end": "2027390"
  },
  {
    "start": "2025000",
    "end": "2025000"
  },
  {
    "text": "has to be fastened to agile in prototyping and experiments in my",
    "start": "2027390",
    "end": "2032610"
  },
  {
    "text": "opinion there if you're if you're solving a state of the art like hard",
    "start": "2032610",
    "end": "2037830"
  },
  {
    "text": "problem that already have solution that's not very hard because you can just take the solution that people",
    "start": "2037830",
    "end": "2043470"
  },
  {
    "text": "already have or if you're solving easy problems that can be self saved by",
    "start": "2043470",
    "end": "2048658"
  },
  {
    "text": "logistic regression or decision tree those are not very difficult either because a lot of a lot of people have",
    "start": "2048659",
    "end": "2054510"
  },
  {
    "text": "experience with them but the difficult problems are if you want to solve",
    "start": "2054510",
    "end": "2060148"
  },
  {
    "text": "problems that are slightly easier than a lot of the hardest problems but no researchers actually care about doing",
    "start": "2060149",
    "end": "2066870"
  },
  {
    "text": "them and making you know improvements on the state of the art so so for the for",
    "start": "2066870",
    "end": "2074850"
  },
  {
    "text": "this applied research purpose it has to be fast and as we are a scholarship on the jvm",
    "start": "2074850",
    "end": "2081090"
  },
  {
    "text": "language we would prefer to have you know the the framework to be able to",
    "start": "2081090",
    "end": "2086129"
  },
  {
    "text": "just practice immediately to jvm language and also of course for the same",
    "start": "2086130",
    "end": "2093480"
  },
  {
    "text": "type of model we want the best accuracy and the best optimization that we can get and as you can see I'm not",
    "start": "2093480",
    "end": "2100560"
  },
  {
    "text": "mentioning performance here that it's not that performance not important but rather we place accuracy as the top most",
    "start": "2100560",
    "end": "2107360"
  },
  {
    "text": "important metric given that for enterprise things have to work and",
    "start": "2107360",
    "end": "2113210"
  },
  {
    "text": "ideally and because there's not that many very mature frameworks when we made",
    "start": "2113210",
    "end": "2120000"
  },
  {
    "text": "this decision which is around maybe end of last year we would appreciate some",
    "start": "2120000",
    "end": "2126180"
  },
  {
    "text": "support but really it's we understand it's very difficult so we ended up",
    "start": "2126180",
    "end": "2131790"
  },
  {
    "start": "2130000",
    "end": "2130000"
  },
  {
    "text": "choosing MX net because it can use",
    "start": "2131790",
    "end": "2137130"
  },
  {
    "text": "Python to prototype and we can immediately export the model and you",
    "start": "2137130",
    "end": "2144420"
  },
  {
    "text": "know have it loaded on the Scala API and just use it immediately so MX net is",
    "start": "2144420",
    "end": "2149730"
  },
  {
    "text": "agile because it's very it's imperative so if you look at tensorflow back in the",
    "start": "2149730",
    "end": "2155400"
  },
  {
    "text": "days it's a it's a graph computation library but if you want to take",
    "start": "2155400",
    "end": "2161220"
  },
  {
    "text": "parameters say you know in middle of a stage it is very very difficult so MX",
    "start": "2161220",
    "end": "2166740"
  },
  {
    "text": "net is imperative and now so as pi torch so both of these frameworks kind of solve this problem and as we compare the",
    "start": "2166740",
    "end": "2174450"
  },
  {
    "text": "training speed an inference speed for our problem we got a 50% faster using MX",
    "start": "2174450",
    "end": "2182130"
  },
  {
    "text": "net versus tensor flow as well as the memory consumption and also as I will show later it has better accuracy for",
    "start": "2182130",
    "end": "2188910"
  },
  {
    "text": "our problems as we pro as we progressed into the project even further we had to",
    "start": "2188910",
    "end": "2194940"
  },
  {
    "text": "use encoder decoder models which we found the sakai framework from adobe say",
    "start": "2194940",
    "end": "2202650"
  },
  {
    "text": "elapsed to be very helpful and one thing we didn't expect out of this framework",
    "start": "2202650",
    "end": "2208980"
  },
  {
    "text": "choice is that we actually had strong and active support from the",
    "start": "2208980",
    "end": "2214109"
  },
  {
    "text": "it Abbess IMAX net team yeah so this is",
    "start": "2214109",
    "end": "2219150"
  },
  {
    "text": "a table showing and by the way I put the year there because frameworks all progressed so I don't I just don't want",
    "start": "2219150",
    "end": "2225119"
  },
  {
    "text": "this to be taken off out of context but at the at the time we made this decision",
    "start": "2225119",
    "end": "2230309"
  },
  {
    "text": "we actually thoroughly compared the two frameworks and these members are because their error rate so the lower the better",
    "start": "2230309",
    "end": "2236549"
  },
  {
    "text": "I just want to make it clear as well so an X net performed a lot better than tensorflow so this is why we end up",
    "start": "2236549",
    "end": "2243869"
  },
  {
    "text": "picking it and our problem is more about recognizing text so generally we look at",
    "start": "2243869",
    "end": "2250170"
  },
  {
    "text": "perfect match and editing distance yeah",
    "start": "2250170",
    "end": "2255630"
  },
  {
    "text": "so next I want to talk about models and algorithms so essentially we're solving three problems right one is where are",
    "start": "2255630",
    "end": "2262589"
  },
  {
    "start": "2258000",
    "end": "2258000"
  },
  {
    "text": "the texts this problem is typically solved by 10 plate matching in the past",
    "start": "2262589",
    "end": "2268289"
  },
  {
    "text": "for enterprise software so you take you take each type of document and you",
    "start": "2268289",
    "end": "2273839"
  },
  {
    "text": "create two different templates for the different variety and then you run a statistical model statistical model on",
    "start": "2273839",
    "end": "2279599"
  },
  {
    "text": "it to figure out which template is the most appropriate and the next part is",
    "start": "2279599",
    "end": "2285480"
  },
  {
    "text": "what are what are the texts so this is a well Traverse problem for deep learning",
    "start": "2285480",
    "end": "2290880"
  },
  {
    "text": "and neural networks even back in the 80s however recently there's some",
    "start": "2290880",
    "end": "2296309"
  },
  {
    "text": "improvements in this as well and the third part is a natural language processing problem so once you recognize",
    "start": "2296309",
    "end": "2303269"
  },
  {
    "text": "the text what do they mean what's important what you are really looking for and this differs between application",
    "start": "2303269",
    "end": "2309029"
  },
  {
    "text": "applications so the first the first",
    "start": "2309029",
    "end": "2314369"
  },
  {
    "start": "2311000",
    "end": "2311000"
  },
  {
    "text": "problem where are the text so our model is a customized you only look once",
    "start": "2314369",
    "end": "2319500"
  },
  {
    "text": "network and what we customized on that is we instead of using convolutional",
    "start": "2319500",
    "end": "2325079"
  },
  {
    "text": "neural network we put a residual net instead and we also added to an",
    "start": "2325079",
    "end": "2331140"
  },
  {
    "text": "additional output which is the angle of tilt so this is very important because when the user takes a photo where they",
    "start": "2331140",
    "end": "2338250"
  },
  {
    "text": "scan something it is possible for that image to be tilted so even consumers face if you're looking at",
    "start": "2338250",
    "end": "2343890"
  },
  {
    "text": "stay tagging a face in a photo and saying hey this is Henry where this is V BEC you don't have that problem because",
    "start": "2343890",
    "end": "2350640"
  },
  {
    "text": "as long as you have the box on the face you're fine but for enterprise we can",
    "start": "2350640",
    "end": "2355920"
  },
  {
    "text": "just box it and have it tilted it's going to affect our enter and accuracy by a huge margin so we added angle of",
    "start": "2355920",
    "end": "2363029"
  },
  {
    "text": "tilt and as well you know we have to make the same modification in our training data to make sure that our",
    "start": "2363029",
    "end": "2368400"
  },
  {
    "text": "model is able to capture and find out how today the model is the second part",
    "start": "2368400",
    "end": "2377579"
  },
  {
    "text": "is where are the text we have a customized model based on wavenet which is originally intended for speech",
    "start": "2377579",
    "end": "2385069"
  },
  {
    "text": "however we're able to modify that and adapt it to a sequence of pixels which",
    "start": "2385069",
    "end": "2392849"
  },
  {
    "text": "you know end up being the words that's being read now the last part is what do",
    "start": "2392849",
    "end": "2400289"
  },
  {
    "start": "2398000",
    "end": "2398000"
  },
  {
    "text": "the text me and there are multiple approaches we're applying for this and",
    "start": "2400289",
    "end": "2405720"
  },
  {
    "text": "the first one is rules based systems so for you know as much as there's a lot of",
    "start": "2405720",
    "end": "2411359"
  },
  {
    "text": "hype on AI and all these magical stuff but I'm looking at you know both myself and everybody here we still do a",
    "start": "2411359",
    "end": "2419039"
  },
  {
    "text": "significant portion of our AI in rules based systems so essentially we're",
    "start": "2419039",
    "end": "2426690"
  },
  {
    "text": "looking at surrounding context so given an example if you're looking for a certain date we you know the dates have",
    "start": "2426690",
    "end": "2435029"
  },
  {
    "text": "a certain format to that and there's certain surrounding context so we combine rules based along with fuzzy",
    "start": "2435029",
    "end": "2441920"
  },
  {
    "text": "regular expression the reason for fuzzy regular expression is because it is possible for you to get error from the",
    "start": "2441920",
    "end": "2449279"
  },
  {
    "text": "text reading process now the second",
    "start": "2449279",
    "end": "2454589"
  },
  {
    "text": "approach we use is a encoder and decoder sequence the sequence approach so with",
    "start": "2454589",
    "end": "2461009"
  },
  {
    "text": "attention mechanism and we actually train the model with the character embedding two word embedding so and also",
    "start": "2461009",
    "end": "2468839"
  },
  {
    "text": "the vocabulary is built with the training data itself now the future work",
    "start": "2468839",
    "end": "2474690"
  },
  {
    "text": "of this is to expand it so that we can apply the things of either fast text or word Tyvek",
    "start": "2474690",
    "end": "2481190"
  },
  {
    "text": "however I think now you can also do by direction of transformer which like kind",
    "start": "2481190",
    "end": "2486630"
  },
  {
    "text": "of like a different newer thing now yeah",
    "start": "2486630",
    "end": "2493890"
  },
  {
    "text": "and the benefit of the encoder and decoder approach is that it's very good",
    "start": "2493890",
    "end": "2499380"
  },
  {
    "text": "at inferring from context so if you look at the receipt on the right we as human",
    "start": "2499380",
    "end": "2506430"
  },
  {
    "text": "know that this is an uber receipt because we know the color of the app and we know that you know in general that",
    "start": "2506430",
    "end": "2514430"
  },
  {
    "text": "the screen is structured however if you're doing this with a traditional",
    "start": "2514430",
    "end": "2519480"
  },
  {
    "text": "machine learning approach there is no sign of uber here right so this approach is really good because it is able to",
    "start": "2519480",
    "end": "2526500"
  },
  {
    "text": "recognize from the training data hey for uber this this is what the context in",
    "start": "2526500",
    "end": "2531870"
  },
  {
    "text": "general look like the order of the words and what is being talked about but there",
    "start": "2531870",
    "end": "2537420"
  },
  {
    "text": "is a drawback of this approach as well which is if you have if you do not have",
    "start": "2537420",
    "end": "2542640"
  },
  {
    "text": "Oberer in your training set then it cannot do anything right so let's say in",
    "start": "2542640",
    "end": "2549090"
  },
  {
    "text": "the next year way Moe has their self-driving capability perfected and",
    "start": "2549090",
    "end": "2554690"
  },
  {
    "text": "somehow we're slacking and we don't have way Moe in our training set yet then",
    "start": "2554690",
    "end": "2560550"
  },
  {
    "text": "then probably we're able to figure out it is some ride-sharing app right like uber or lyft through the context but",
    "start": "2560550",
    "end": "2566790"
  },
  {
    "text": "we're not able to figure out it is way more because we never had that label so",
    "start": "2566790",
    "end": "2571920"
  },
  {
    "text": "we have to employ a different approach to handle that situation and that situation and how we handle that is we",
    "start": "2571920",
    "end": "2580080"
  },
  {
    "text": "use a CNN based approach to classify each box that we recognize so when we",
    "start": "2580080",
    "end": "2586350"
  },
  {
    "text": "first figure out where the texts are we take those boxes and we do some classification on that and we leverage",
    "start": "2586350",
    "end": "2593370"
  },
  {
    "text": "we leverage the work where Tyvek embedding so this approach will consider",
    "start": "2593370",
    "end": "2599670"
  },
  {
    "text": "both language context and also approximate location of each field so in the case where it does not find a it",
    "start": "2599670",
    "end": "2609930"
  },
  {
    "text": "does not find a label that currently just in our in our training set it's going to make a guess on in the past",
    "start": "2609930",
    "end": "2618220"
  },
  {
    "text": "roughly where the the the the field that",
    "start": "2618220",
    "end": "2624340"
  },
  {
    "text": "we have interested in is at for that particular type of receipt and for that",
    "start": "2624340",
    "end": "2629590"
  },
  {
    "text": "particular particular context and now we",
    "start": "2629590",
    "end": "2634770"
  },
  {
    "start": "2633000",
    "end": "2633000"
  },
  {
    "text": "we have we clearly we have three approaches so this is how we use them together we for either fields rule base",
    "start": "2634770",
    "end": "2642610"
  },
  {
    "text": "is very sufficient so we just use that and for more difficult fields the",
    "start": "2642610",
    "end": "2647770"
  },
  {
    "text": "encoder and decoder approach we can get some sort of confidence of how how well",
    "start": "2647770",
    "end": "2653110"
  },
  {
    "text": "we think this result is correct and if that value is not confident then we will",
    "start": "2653110",
    "end": "2659620"
  },
  {
    "text": "take finally the CNN box tagging approach so with only 40 paid training data were able to get 72% accuracy on",
    "start": "2659620",
    "end": "2668710"
  },
  {
    "text": "the test set and the number seems very low but our test set is actually very difficult test set because we got a lot",
    "start": "2668710",
    "end": "2676360"
  },
  {
    "text": "of receipts that are essentially very noisy because we want to make sure that when we release this to the customers we",
    "start": "2676360",
    "end": "2683380"
  },
  {
    "text": "actually test it on a set that is harder than what we would expect and because we",
    "start": "2683380",
    "end": "2691420"
  },
  {
    "start": "2690000",
    "end": "2690000"
  },
  {
    "text": "don't have a lot of training data we had to employ a transfer learning so we wrote a script and took a bunch of",
    "start": "2691420",
    "end": "2697870"
  },
  {
    "text": "photos that our team took randomly in the past we contribute our own photos",
    "start": "2697870",
    "end": "2703390"
  },
  {
    "text": "for the fun of it and we essentially put words on it and we generated a few",
    "start": "2703390",
    "end": "2708700"
  },
  {
    "text": "million of these and we trained the model on these images first to recognize",
    "start": "2708700",
    "end": "2713830"
  },
  {
    "text": "texts and then we fine-tune on the on the 40k 50k of real data that we have so",
    "start": "2713830",
    "end": "2723190"
  },
  {
    "text": "these are the examples of real data that we're dealing with now results so we",
    "start": "2723190",
    "end": "2731620"
  },
  {
    "text": "have very competitive results that's at least on par or on average even performs",
    "start": "2731620",
    "end": "2736840"
  },
  {
    "text": "better than a lot of major public cloud providers on the vision part of the",
    "start": "2736840",
    "end": "2741970"
  },
  {
    "text": "model so this proves that you know for our specific problem if we just use a public cloud provider",
    "start": "2741970",
    "end": "2748900"
  },
  {
    "text": "we actually would have gotten a less accurate result and also for the test",
    "start": "2748900",
    "end": "2755739"
  },
  {
    "text": "set metrics depending on the reason why varies it depends on what field you're",
    "start": "2755739",
    "end": "2761650"
  },
  {
    "text": "looking for because we're looking at end to end metrics not just you know specifically the vision part but also",
    "start": "2761650",
    "end": "2767349"
  },
  {
    "text": "NLP so depending on our field we're looking at 75 to 80 to 85 percent and",
    "start": "2767349",
    "end": "2774190"
  },
  {
    "text": "for production so we got this number from we got this number from how many",
    "start": "2774190",
    "end": "2780670"
  },
  {
    "text": "times it gets changed on the app side so we have metrics for that I mean everybody is data-driven nowadays so as",
    "start": "2780670",
    "end": "2787749"
  },
  {
    "text": "a result only 5% of all the receipts are ever changed so this is how we measure",
    "start": "2787749",
    "end": "2794680"
  },
  {
    "text": "in the end what's what is our production accuracy so I guess one of the key",
    "start": "2794680",
    "end": "2800920"
  },
  {
    "text": "takeaway here is always make your test accuracy sorry test set more difficult",
    "start": "2800920",
    "end": "2805930"
  },
  {
    "text": "than what you would expect okay so now I will hand back to the vet for a predator",
    "start": "2805930",
    "end": "2811869"
  },
  {
    "text": "ization Thanks so we have three more minutes I want to leave ten minutes for questions so",
    "start": "2811869",
    "end": "2818710"
  },
  {
    "text": "quickly I'll talk about how we productize all of this the model building training part and the world",
    "start": "2818710",
    "end": "2824890"
  },
  {
    "text": "base tag so this is a live stack this is",
    "start": "2824890",
    "end": "2830619"
  },
  {
    "start": "2825000",
    "end": "2825000"
  },
  {
    "text": "how actually it's running today in the world a product so this is more system",
    "start": "2830619",
    "end": "2835869"
  },
  {
    "text": "level so basically the leverage IMAX net",
    "start": "2835869",
    "end": "2841180"
  },
  {
    "text": "service which you see at the far bottom for inferencing a prediction we leverage",
    "start": "2841180",
    "end": "2847779"
  },
  {
    "text": "it in multiple ways so we use Kafka for the image coming in we fetch the image",
    "start": "2847779",
    "end": "2853690"
  },
  {
    "text": "from a datastore and the first three boxes that you see is essentially an ensemble of three of the same model",
    "start": "2853690",
    "end": "2861160"
  },
  {
    "text": "where we scale the image three times and FOI is field of interest essentially what feels very interested in it",
    "start": "2861160",
    "end": "2867970"
  },
  {
    "text": "basically depends all the text the blue stuff we saw in Henry's slide earlier we",
    "start": "2867970",
    "end": "2874089"
  },
  {
    "text": "then called the next stage which is you actually X tract that text in the text inference",
    "start": "2874089",
    "end": "2880110"
  },
  {
    "text": "stage and all those models are again served by an MX net server so we set up",
    "start": "2880110",
    "end": "2885570"
  },
  {
    "text": "that MX net server which just takes in the model takes in input parameters",
    "start": "2885570",
    "end": "2891420"
  },
  {
    "text": "which can be image or the coordinates of the image does the compute magic and returns back in the first stage it",
    "start": "2891420",
    "end": "2899580"
  },
  {
    "text": "returns back the coordinates where those small boxes are in the second stage it returns a JSON of all the text and the",
    "start": "2899580",
    "end": "2906630"
  },
  {
    "text": "third one essentially is the parser which is the ensemble strategy that Henry was talking about that again uses",
    "start": "2906630",
    "end": "2913740"
  },
  {
    "text": "the M excellent service that feeds in all the text and specifically in here's",
    "start": "2913740",
    "end": "2919230"
  },
  {
    "text": "where the business part comes in we are only interested in say for example the amount or the much name or the date we",
    "start": "2919230",
    "end": "2927660"
  },
  {
    "text": "don't care about other text so the parser is what basically extracts all that and puts it back in Kafka and then",
    "start": "2927660",
    "end": "2934440"
  },
  {
    "text": "we return that back to the application the workday finance application that is",
    "start": "2934440",
    "end": "2940260"
  },
  {
    "text": "consuming those results and showing it back to the end-user one of the key",
    "start": "2940260",
    "end": "2945960"
  },
  {
    "text": "learnings from this first we found out there's a lot of value in building",
    "start": "2945960",
    "end": "2951780"
  },
  {
    "start": "2947000",
    "end": "2947000"
  },
  {
    "text": "models specifically for our own business or product use case so customized models",
    "start": "2951780",
    "end": "2957390"
  },
  {
    "text": "meant far more in especially in the enterprise case we were able to achieve production accuracies of 95 percent",
    "start": "2957390",
    "end": "2963830"
  },
  {
    "text": "which is pretty amazing and you know our customers are pretty happy with that the",
    "start": "2963830",
    "end": "2969930"
  },
  {
    "text": "second one is there is a lot of difference between running a model a",
    "start": "2969930",
    "end": "2977220"
  },
  {
    "text": "training a model you know writing some experimentation code not knowing which one to pick doing that quote-unquote",
    "start": "2977220",
    "end": "2983910"
  },
  {
    "text": "research but when you actually want to put it in production it's a whole different ballgame because now you're",
    "start": "2983910",
    "end": "2989760"
  },
  {
    "text": "talking about you know customer facing application you can't willy-nilly go change things so fast so so that was one",
    "start": "2989760",
    "end": "2997770"
  },
  {
    "text": "big challenge that in machine learning application everybody focuses a lot on",
    "start": "2997770",
    "end": "3002870"
  },
  {
    "text": "the model and ái part of the m/l part which is great but the supporting systems also have to",
    "start": "3002870",
    "end": "3009650"
  },
  {
    "text": "be built to actually make it work in scale and that's something we learnt by",
    "start": "3009650",
    "end": "3015980"
  },
  {
    "text": "developing this particular feature and the third one was I think Henry alluded to this we pretty much had like daily",
    "start": "3015980",
    "end": "3023630"
  },
  {
    "text": "scrums before go live at the awsm x net team in February so this meant live",
    "start": "3023630",
    "end": "3029030"
  },
  {
    "text": "March of this year and they were really helping us because we were one of the",
    "start": "3029030",
    "end": "3034310"
  },
  {
    "text": "first adopters of their Scala API so so our back-end is entirely in Scala so you",
    "start": "3034310",
    "end": "3040520"
  },
  {
    "text": "know just hashing out issues that we have faced or we uncovered while we were",
    "start": "3040520",
    "end": "3045860"
  },
  {
    "text": "prioritizing the MX net service so so yeah and they were available and that",
    "start": "3045860",
    "end": "3052550"
  },
  {
    "text": "that's that was great that's it that's the end of our talk and I open it to",
    "start": "3052550",
    "end": "3058400"
  },
  {
    "text": "questions yeah you can use them Mike if you don't mind so hey thanks for the",
    "start": "3058400",
    "end": "3069590"
  },
  {
    "text": "call talk quick couple of questions what do you do with handwritten totals on",
    "start": "3069590",
    "end": "3077300"
  },
  {
    "text": "receipts especially adding tips obvious",
    "start": "3077300",
    "end": "3082940"
  },
  {
    "text": "to extract secondly is there a mechanism for you to do a be testing on the",
    "start": "3082940",
    "end": "3089780"
  },
  {
    "text": "machine learning models because you have customer facing service right is there a",
    "start": "3089780",
    "end": "3095510"
  },
  {
    "text": "possibility of doing that with the frameworks selected sure yeah so in",
    "start": "3095510",
    "end": "3103610"
  },
  {
    "text": "terms of handwriting models so essentially we're looking at a second problem which is what the what the texts",
    "start": "3103610",
    "end": "3110510"
  },
  {
    "text": "are right and that is already a quite well traversed problem so currently at",
    "start": "3110510",
    "end": "3117470"
  },
  {
    "text": "our MVP stage we did not support it but the model is actually again this is this",
    "start": "3117470",
    "end": "3124580"
  },
  {
    "text": "is a problem where I would place it as it's very well traversed we don't have to do a lot of customization so it's a",
    "start": "3124580",
    "end": "3131750"
  },
  {
    "text": "matter of essentially another release and to take a second question",
    "start": "3131750",
    "end": "3137430"
  },
  {
    "text": "if you look at the product ization part here so if you look at the ml MX net ml",
    "start": "3137430",
    "end": "3145080"
  },
  {
    "text": "engine and you see the model store that's basically where we allow a be",
    "start": "3145080",
    "end": "3150480"
  },
  {
    "text": "testing our models so you can put your models so this is this framework or the system you built your model store can",
    "start": "3150480",
    "end": "3156090"
  },
  {
    "text": "have different versions of the model for the same application and just through REST API calls you can actually retrieve",
    "start": "3156090",
    "end": "3161790"
  },
  {
    "text": "that specific model send the same data and test it and compare and then you don't do a switcheroo of which one you",
    "start": "3161790",
    "end": "3168300"
  },
  {
    "text": "want to serve in production thank you so",
    "start": "3168300",
    "end": "3183720"
  },
  {
    "text": "the mercial any models are not 100% what do you do",
    "start": "3183720",
    "end": "3191000"
  },
  {
    "text": "85% what do you do with the 15% and in the production environment how do you",
    "start": "3191750",
    "end": "3198570"
  },
  {
    "text": "identify that I image is part of the 85 or part of the 15% either of us yeah",
    "start": "3198570",
    "end": "3210900"
  },
  {
    "text": "so essentially that's a very good question in at least an in production",
    "start": "3210900",
    "end": "3217050"
  },
  {
    "text": "side of things right we have mechanisms in place where when a user corrects the",
    "start": "3217050",
    "end": "3224820"
  },
  {
    "text": "value that we have returned we capture that action and that for us becomes a",
    "start": "3224820",
    "end": "3230610"
  },
  {
    "text": "feedback loop right where we take that input and then retrain the model and improve the model itself right so part",
    "start": "3230610",
    "end": "3240540"
  },
  {
    "text": "of that feedback loop is also getting the image and checking basically if we",
    "start": "3240540",
    "end": "3246210"
  },
  {
    "text": "have trained models on that so so that's kind of how we do it today maybe get",
    "start": "3246210",
    "end": "3255180"
  },
  {
    "text": "that data of what the user has entered",
    "start": "3255180",
    "end": "3259040"
  },
  {
    "text": "sorry there's a verification like a manual process um no it's automated in the world.we",
    "start": "3261530",
    "end": "3268980"
  },
  {
    "text": "product itself when there's a value which is are you talking about comparing to what the actual ground truth was fear",
    "start": "3268980",
    "end": "3283010"
  },
  {
    "text": "so I think what the recognition is that we can certainly get a feedback loop and",
    "start": "3286190",
    "end": "3291510"
  },
  {
    "text": "train the model further and I think the accuracy will increase over time but I think your question is that it will",
    "start": "3291510",
    "end": "3297420"
  },
  {
    "text": "never reach a hundred percent and what do we do when it fails right so I think this has something to do with our vision",
    "start": "3297420",
    "end": "3304680"
  },
  {
    "text": "of how machine learning fits into enterprise software so it's never meant to replace people completely but it's",
    "start": "3304680",
    "end": "3312720"
  },
  {
    "text": "meant to exist you so I would actually say this is more of a product design",
    "start": "3312720",
    "end": "3317760"
  },
  {
    "text": "right so when you design a product do you make machine learning your default or do you make machine learning",
    "start": "3317760",
    "end": "3323400"
  },
  {
    "text": "something where it's gonna help but then in the end the user has to verify and make sure hey this is not giving me this",
    "start": "3323400",
    "end": "3331170"
  },
  {
    "text": "is not giving me results that that's essentially nonsense right so and and",
    "start": "3331170",
    "end": "3336300"
  },
  {
    "text": "actually I want to add on top of that and there's it's a heavy researched heavily researched topic right now is",
    "start": "3336300",
    "end": "3342540"
  },
  {
    "text": "that and we have been doing testing on our side as well is if you send in a",
    "start": "3342540",
    "end": "3347670"
  },
  {
    "text": "photo of a cat instead of a receipt or an invoice right or if you send in can you break it right and this is actually",
    "start": "3347670",
    "end": "3354480"
  },
  {
    "text": "a very heavily researched topic and because of that you never know if it is possible that you send in something that",
    "start": "3354480",
    "end": "3360990"
  },
  {
    "text": "it's going to you know get the deep learning model to do something that's unexpected so that being said we do not",
    "start": "3360990",
    "end": "3368369"
  },
  {
    "text": "you know at least for enterprise and this is our vision we don't want to machine learning to be a replacement of",
    "start": "3368369",
    "end": "3374280"
  },
  {
    "text": "what human do but rather to help an exist thank you",
    "start": "3374280",
    "end": "3381380"
  },
  {
    "text": "like Chanel was going to ask the same question if you were using average circular networks to check to test your model and also whether you have",
    "start": "3384420",
    "end": "3391890"
  },
  {
    "text": "incorporated in your results a confidence interval of the of the",
    "start": "3391890",
    "end": "3397210"
  },
  {
    "text": "prediction and whether you use exception handling as part of your workflow to bring humans into the loop so today in",
    "start": "3397210",
    "end": "3410140"
  },
  {
    "text": "the product we don't have any humans in the loop to rectify tapes right we directly expose let's talk about the",
    "start": "3410140",
    "end": "3416380"
  },
  {
    "text": "receipts use case we directly exposed to the end user and the end user can go change the value right with the kind of",
    "start": "3416380",
    "end": "3423250"
  },
  {
    "text": "accuracy we've been hitting we haven't had a lot of support tickets come our way so I'm happy about it but but yeah",
    "start": "3423250",
    "end": "3429520"
  },
  {
    "text": "this is absolutely zero human in the loop in production yeah so yeah so well",
    "start": "3429520",
    "end": "3448030"
  },
  {
    "text": "that story is actually on our backlog the reason I have hesitancy of using",
    "start": "3448030",
    "end": "3454060"
  },
  {
    "text": "that is because as for enterprise things have to work right so I personally have",
    "start": "3454060",
    "end": "3461260"
  },
  {
    "text": "like I would say this is something we definitely should research but at this moment and and I think there was just",
    "start": "3461260",
    "end": "3467320"
  },
  {
    "text": "recently a breakthrough maybe two months ago about image generation from using using a general using GaN but I I think",
    "start": "3467320",
    "end": "3480070"
  },
  {
    "text": "in the near say a year or so there's there it's it might become a reality but",
    "start": "3480070",
    "end": "3485650"
  },
  {
    "text": "right now for us to generate those images I I have some doubts on how on",
    "start": "3485650",
    "end": "3491320"
  },
  {
    "text": "the quality of the training data from that Mary just bought into that so usually what you're lacking in the data",
    "start": "3491320",
    "end": "3498010"
  },
  {
    "text": "generated by GaN is lack of entre P so the real data I get from the from the",
    "start": "3498010",
    "end": "3504580"
  },
  {
    "text": "world it's good entre P what the stuff that Gann produces is very much focused on whatever it is that is supposed to do",
    "start": "3504580",
    "end": "3511690"
  },
  {
    "text": "there is very little extra information in there are being a scanning for research around",
    "start": "3511690",
    "end": "3517509"
  },
  {
    "text": "there are research about how to introduce entrepreneur gun generates a data Cochlear's maybe we don't know how",
    "start": "3517509",
    "end": "3523449"
  },
  {
    "text": "long but there is that people are seriously thinking about it and if you want to research that area look for",
    "start": "3523449",
    "end": "3529779"
  },
  {
    "text": "introduction of entre p2 gun data and then you might come across a paper that",
    "start": "3529779",
    "end": "3536199"
  },
  {
    "text": "has similarities to what you want to do but that's your major problem that you know that you might not be able to",
    "start": "3536199",
    "end": "3542229"
  },
  {
    "text": "create data that is very similar to what you have there is research Paris is God",
    "start": "3542229",
    "end": "3552130"
  },
  {
    "text": "Karras has a Karass fit where you can do",
    "start": "3552130",
    "end": "3556258"
  },
  {
    "text": "sorry what is the incremental update where you could take your model and add additional training to it with all",
    "start": "3559319",
    "end": "3565239"
  },
  {
    "text": "starting from scratch can you explain how it works I'm not very familiar I'm",
    "start": "3565239",
    "end": "3570249"
  },
  {
    "text": "not very deeply familiar with Karis but what is the task that you do the ideas",
    "start": "3570249",
    "end": "3575559"
  },
  {
    "text": "to to improve your accuracy by adding additional samples into it but I'm not so straight smokers are not used to",
    "start": "3575559",
    "end": "3581319"
  },
  {
    "text": "directly myself emailed me I'll figure a",
    "start": "3581319",
    "end": "3586359"
  },
  {
    "text": "dancer for you I don't want times or something I'm not very well aware of thank you okay",
    "start": "3586359",
    "end": "3593669"
  },
  {
    "text": "thanks for coming guys [Applause]",
    "start": "3593669",
    "end": "3599760"
  }
]
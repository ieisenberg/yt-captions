[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "in this talk I'm going to dive quite deep on a specific aspect of sage maker",
    "start": "0",
    "end": "8599"
  },
  {
    "text": "and namely the built-in algorithms which I believe are a very interesting way to",
    "start": "8599",
    "end": "16850"
  },
  {
    "text": "to apply machine learning even when you don't have a lot of machine learning",
    "start": "16850",
    "end": "22230"
  },
  {
    "text": "skill okay so let's get started so just in case you missed the the first session",
    "start": "22230",
    "end": "29010"
  },
  {
    "start": "24000",
    "end": "93000"
  },
  {
    "text": "I just want to remind you that sage maker is a collection of modules that",
    "start": "29010",
    "end": "34500"
  },
  {
    "text": "you can combine or wear or that you can just pick you know just pick whatever",
    "start": "34500",
    "end": "39750"
  },
  {
    "text": "you like in there so we start with notebook instances fully managed",
    "start": "39750",
    "end": "46129"
  },
  {
    "text": "instances pre-installed with everything you need to do machine learning and deep",
    "start": "46129",
    "end": "51690"
  },
  {
    "text": "learning and the interface to those instances will actually be a jupiter notebook then you are multiple options",
    "start": "51690",
    "end": "60030"
  },
  {
    "text": "for training you can pick from those scaleable machine learning algorithm tin",
    "start": "60030",
    "end": "67830"
  },
  {
    "text": "a minute or you can pick a pre-built environment for python tensorflow and x",
    "start": "67830",
    "end": "73049"
  },
  {
    "text": "netic cetera and it's very easy to train at scale without managing an infrastructure okay then you can deploy",
    "start": "73049",
    "end": "79979"
  },
  {
    "text": "in a very similar and very easy fashion as well just deploy your model behind an",
    "start": "79979",
    "end": "86460"
  },
  {
    "text": "HTTP endpoint to serve predictions to your apps okay so that's the big picture",
    "start": "86460",
    "end": "92280"
  },
  {
    "text": "and if we zoom in on on your algo and",
    "start": "92280",
    "end": "98369"
  },
  {
    "start": "93000",
    "end": "177000"
  },
  {
    "text": "your model options when it comes to using sage maker okay so once again you can pick from a list of built-in algos",
    "start": "98369",
    "end": "105960"
  },
  {
    "text": "and this is the ones i'm going to talk about today but please be be aware that",
    "start": "105960",
    "end": "111810"
  },
  {
    "text": "you can also use you can bring your own script bring your own training code for",
    "start": "111810",
    "end": "117780"
  },
  {
    "text": "MX net and turns of flu and my colleague guy earnest has a session letter this",
    "start": "117780",
    "end": "122880"
  },
  {
    "text": "afternoon on tensorflow so i think it's going to dive quite deep on tensorflow",
    "start": "122880",
    "end": "128369"
  },
  {
    "text": "here you can also use integrate sage maker",
    "start": "128369",
    "end": "133859"
  },
  {
    "text": "on apache spark okay so if you do machine learning on spark if you have",
    "start": "133859",
    "end": "139500"
  },
  {
    "text": "sparked pipelines you can actually add sage maker steps to your machine",
    "start": "139500",
    "end": "145500"
  },
  {
    "text": "learning pipeline and last but not least if you have any other kind of",
    "start": "145500",
    "end": "150810"
  },
  {
    "text": "requirement let's say you want to use a deep learning library that isn't supported yet by a by Sage maker or you",
    "start": "150810",
    "end": "158790"
  },
  {
    "text": "want to bring your own custom code for training and prediction because that's what you built over the years then you",
    "start": "158790",
    "end": "165389"
  },
  {
    "text": "you encapsulate all of that into a docker container and sage maker is going",
    "start": "165389",
    "end": "170609"
  },
  {
    "text": "to use that okay but I'm going to focus on that left-hand side thing so the",
    "start": "170609",
    "end": "179040"
  },
  {
    "start": "177000",
    "end": "284000"
  },
  {
    "text": "purpose of those algos is simply to be ten times better than whatever else is",
    "start": "179040",
    "end": "185579"
  },
  {
    "text": "available today that's the target that's the goal we set for ourselves and you",
    "start": "185579",
    "end": "191639"
  },
  {
    "text": "will see in some cases we hit and actually we do exceed that 10x improvement so we have a few key",
    "start": "191639",
    "end": "200940"
  },
  {
    "text": "principles here it's important to to understand them first of all those algos",
    "start": "200940",
    "end": "208489"
  },
  {
    "text": "are streaming algos okay so typical machine learning our goals will maybe",
    "start": "208489",
    "end": "215010"
  },
  {
    "text": "load the whole data set in memory and then process it which pretty much restricts how big your",
    "start": "215010",
    "end": "223139"
  },
  {
    "text": "dataset can be or they're going to load from this can feel a memory and move on to the next batch etc etc and again this",
    "start": "223139",
    "end": "231000"
  },
  {
    "text": "is not the fastest and most efficient way to train so we use streaming algos",
    "start": "231000",
    "end": "236340"
  },
  {
    "text": "and we'll see what benefits this brings we just generally want to train faster",
    "start": "236340",
    "end": "241680"
  },
  {
    "text": "we want to train in a single pass and that's another streaming benefit those algos will only see a data point once",
    "start": "241680",
    "end": "248939"
  },
  {
    "text": "and change their internal state to reflect that so they don't need to see data or again and again and again and",
    "start": "248939",
    "end": "256079"
  },
  {
    "text": "again to learn from it this will yield really good reliability even if we have",
    "start": "256079",
    "end": "264560"
  },
  {
    "text": "crazy big data sets you could have terabytes tens",
    "start": "264560",
    "end": "270100"
  },
  {
    "text": "of terabytes hundreds of terabytes it doesn't really matter because again we're streaming data we're not reloading",
    "start": "270100",
    "end": "276490"
  },
  {
    "text": "it and well we try to provide as much as much choice as possible when it comes to",
    "start": "276490",
    "end": "282520"
  },
  {
    "text": "algorithms so you know we try to put our money where our mouth is and we call",
    "start": "282520",
    "end": "290020"
  },
  {
    "start": "284000",
    "end": "306000"
  },
  {
    "text": "them infinitely scalable algorithms and this collection of algorithms that I",
    "start": "290020",
    "end": "295300"
  },
  {
    "text": "will present has been implemented by Amazon and it's being used every day by",
    "start": "295300",
    "end": "300880"
  },
  {
    "text": "Amazon and AWS internally you know for our own purposes so like I said we're",
    "start": "300880",
    "end": "308500"
  },
  {
    "start": "306000",
    "end": "335000"
  },
  {
    "text": "streaming data to the algos okay so every single data point in your data set",
    "start": "308500",
    "end": "314110"
  },
  {
    "text": "will only be seen once by the alga and that's again the only way you could work",
    "start": "314110",
    "end": "319330"
  },
  {
    "text": "with arbitrarily large data sets there is no limit to the amount of data that",
    "start": "319330",
    "end": "325510"
  },
  {
    "text": "this algorithm can can support can process because we're streaming data through the algos managing the state and",
    "start": "325510",
    "end": "332620"
  },
  {
    "text": "building the model so the benefit from that is memory consumption is now",
    "start": "332620",
    "end": "340270"
  },
  {
    "start": "335000",
    "end": "384000"
  },
  {
    "text": "completely independent of the of the data set size right because we don't",
    "start": "340270",
    "end": "346060"
  },
  {
    "text": "have to load stuff in memory before we can train on it we can just stream the data through the algo and the algo",
    "start": "346060",
    "end": "352240"
  },
  {
    "text": "learns as it goes right so there is no limit again to the size when it comes to",
    "start": "352240",
    "end": "359310"
  },
  {
    "text": "to a time and cost well it's going to be fully linear right the cost to train on",
    "start": "359310",
    "end": "365440"
  },
  {
    "text": "10 terabytes and the time to train on 10 terabytes will just be 10 times the cost",
    "start": "365440",
    "end": "371140"
  },
  {
    "text": "and the time to Train on 1 terabyte so even if you go to petabyte scale data set it will just go linearly and and",
    "start": "371140",
    "end": "378880"
  },
  {
    "text": "scale linearly you will not experience any kind of degradation obviously when",
    "start": "378880",
    "end": "385450"
  },
  {
    "text": "you talk about data sets this large distributed training is important and these algo support that so we can",
    "start": "385450",
    "end": "392470"
  },
  {
    "text": "actually split the data set across across multiple instances and once again",
    "start": "392470",
    "end": "397540"
  },
  {
    "text": "this will be fully managed by sage maker just fire them up and they do their job and then they",
    "start": "397540",
    "end": "403860"
  },
  {
    "text": "terminate automatically you don't have to manage them at all so each instance is going to work on its",
    "start": "403860",
    "end": "410460"
  },
  {
    "text": "own part of the data set managing its own local state and then we have a",
    "start": "410460",
    "end": "417539"
  },
  {
    "start": "415000",
    "end": "443000"
  },
  {
    "text": "counter component that's going to actually make sure that the different",
    "start": "417539",
    "end": "422819"
  },
  {
    "text": "local states are constantly dated into a shared state okay so we can do distributed training at scale and again",
    "start": "422819",
    "end": "428909"
  },
  {
    "text": "there's no limit probably to the amount of GPU or CPU instances you could fire",
    "start": "428909",
    "end": "434909"
  },
  {
    "text": "up for a given job okay giving you even more speed for training speed for large",
    "start": "434909",
    "end": "441300"
  },
  {
    "text": "data sets and so the results of this is",
    "start": "441300",
    "end": "447409"
  },
  {
    "start": "443000",
    "end": "549000"
  },
  {
    "text": "you don't have to accept any trade-off right typically you probably you're",
    "start": "447620",
    "end": "456449"
  },
  {
    "text": "probably in a situation like that dotted blue line right you have to compromise",
    "start": "456449",
    "end": "462569"
  },
  {
    "text": "between cost and training speed so if",
    "start": "462569",
    "end": "468360"
  },
  {
    "text": "you want to train super fast you need to throw a lot of hardware at the problem okay and that's gonna probably cost more",
    "start": "468360",
    "end": "475919"
  },
  {
    "text": "you know just way more there's a premium to that speed-up and if you're if you",
    "start": "475919",
    "end": "482969"
  },
  {
    "text": "have a small budget then the only thing you can do is accept lower training",
    "start": "482969",
    "end": "488009"
  },
  {
    "text": "times right but sage maker actually with",
    "start": "488009",
    "end": "494039"
  },
  {
    "text": "the built-in algos and the performance that they bring sage maker really lowers the cost and it's it's it stays linear",
    "start": "494039",
    "end": "504210"
  },
  {
    "text": "for a very long time right so an almost flat as you can see so you can actually",
    "start": "504210",
    "end": "509759"
  },
  {
    "text": "get extreme speed up with those built-in algos without your costs increasing like",
    "start": "509759",
    "end": "516899"
  },
  {
    "text": "they would increase with other solutions okay because once again the the",
    "start": "516899",
    "end": "522300"
  },
  {
    "text": "streaming nature of these algorithms the fact that they support distributed training",
    "start": "522300",
    "end": "528430"
  },
  {
    "text": "we'll let you just scale at flat cost unless you really really want you know",
    "start": "528430",
    "end": "534760"
  },
  {
    "text": "very very low training times like like minutes and then yes maybe increases a bit but moving from weeks to days is not",
    "start": "534760",
    "end": "543400"
  },
  {
    "text": "going to require a significant increase of your training budget so let's look at",
    "start": "543400",
    "end": "550060"
  },
  {
    "start": "549000",
    "end": "690000"
  },
  {
    "text": "some examples okay and we're going to take some time because I know these are pretty heavy slides so the first I'll go",
    "start": "550060",
    "end": "555339"
  },
  {
    "text": "is probably the king of all machine learning I'll go sit called linear regression and so we have an",
    "start": "555339",
    "end": "560620"
  },
  {
    "text": "implementation of this so here we tested it on two data set a URL data set and a",
    "start": "560620",
    "end": "568060"
  },
  {
    "text": "spam data set okay so what you need to compare here is the green line versus",
    "start": "568060",
    "end": "573880"
  },
  {
    "text": "the purple line right and as you can see there is a huge cost reduction when you",
    "start": "573880",
    "end": "581529"
  },
  {
    "text": "train with sage maker right it's pretty it's pretty fast and you never actually",
    "start": "581529",
    "end": "586660"
  },
  {
    "text": "end up training for a long time and if you compare the orange one with the",
    "start": "586660",
    "end": "591790"
  },
  {
    "text": "light blue one it's pretty much the same story right these are reasonably large",
    "start": "591790",
    "end": "597790"
  },
  {
    "text": "data sets and and not only stage maker faster it's significantly cheaper as",
    "start": "597790",
    "end": "603820"
  },
  {
    "text": "well right so you win on both on both counts which which is not typical",
    "start": "603820",
    "end": "611260"
  },
  {
    "text": "because usually we always knew that there was this trade-off between time and costs right so one or the other but",
    "start": "611260",
    "end": "618790"
  },
  {
    "text": "actually here we can get both and that's that's not typical if we look at",
    "start": "618790",
    "end": "624370"
  },
  {
    "text": "accuracy because you know accuracy would not mean sage maker would not mean anything it was unexpensive and fast but",
    "start": "624370",
    "end": "631680"
  },
  {
    "text": "imprecise if we look at a regression model for linear regression well we can",
    "start": "631680",
    "end": "639070"
  },
  {
    "text": "see actually you know we're doing were comparable to two other implementations even though we stream data which is",
    "start": "639070",
    "end": "645550"
  },
  {
    "text": "quite different and when we run a classification task you know again we're",
    "start": "645550",
    "end": "651459"
  },
  {
    "text": "doing we're doing quite okay we're pretty close to and even exceed the",
    "start": "651459",
    "end": "656620"
  },
  {
    "text": "accuracy of a reference implementation patience okay so this example here in a",
    "start": "656620",
    "end": "661770"
  },
  {
    "text": "nutshell tells you you will train five at least five times faster right if we",
    "start": "661770",
    "end": "668130"
  },
  {
    "text": "compare that you don't see my pointer here that rightmost purple points to the",
    "start": "668130",
    "end": "674340"
  },
  {
    "text": "rightmost green point that's really the same data point right so it's let's say six seven minutes on sage maker and",
    "start": "674340",
    "end": "681150"
  },
  {
    "text": "maybe twenty seven minutes with the other technology and cost is a two to three times lower as well okay so very",
    "start": "681150",
    "end": "688530"
  },
  {
    "text": "very efficient here's another one factorization machine which is a generalization of linear regression and",
    "start": "688530",
    "end": "695880"
  },
  {
    "start": "690000",
    "end": "783000"
  },
  {
    "text": "don't be scared by the by the equations here so factorization machines are",
    "start": "695880",
    "end": "702620"
  },
  {
    "text": "popular for recommendation building recommendation engines and I'll show you a demo in a few a few minutes so here we",
    "start": "702620",
    "end": "710400"
  },
  {
    "text": "trained on one terabyte of advert of advertising data trying to do click",
    "start": "710400",
    "end": "716550"
  },
  {
    "text": "prediction okay and that's not an easy problem it's a one of the harder problems okay and we tested it on ten",
    "start": "716550",
    "end": "723210"
  },
  {
    "text": "machines 20 machines all the way to 50 machines okay and you can see the cost is almost completely flat okay and you",
    "start": "723210",
    "end": "732390"
  },
  {
    "text": "have pretty much linear scaling as well right with it takes almost eight minutes on ten machines a little less takes",
    "start": "732390",
    "end": "739890"
  },
  {
    "text": "about four minutes on 20 machines it takes two minutes on 40 machines so as",
    "start": "739890",
    "end": "744990"
  },
  {
    "text": "you double hardware you divide by 2 your training time okay so flat cost and",
    "start": "744990",
    "end": "753560"
  },
  {
    "text": "linear perfectly linear scaling okay very cool if we look at precision again",
    "start": "753560",
    "end": "760910"
  },
  {
    "text": "if you look at loss and the f1 score which is a measure of how well our our",
    "start": "760910",
    "end": "766430"
  },
  {
    "text": "classifier is doing what we can see there again very close or even better",
    "start": "766430",
    "end": "771660"
  },
  {
    "text": "than reference implementations who would train for much much longer right so in",
    "start": "771660",
    "end": "777270"
  },
  {
    "text": "in very little time we actually get to almost state-of-the-art results okay so",
    "start": "777270",
    "end": "784020"
  },
  {
    "start": "783000",
    "end": "1509000"
  },
  {
    "text": "let's quickly look what what it means to",
    "start": "784020",
    "end": "789030"
  },
  {
    "text": "to use one so I'm not going to go through every single line of code I will share the links to those demos and you can you can",
    "start": "789030",
    "end": "796980"
  },
  {
    "text": "read them in detail okay because I really want to go through everything here so this is a notebook instance and",
    "start": "796980",
    "end": "804300"
  },
  {
    "text": "I have my jupiter notebook i'm using a famous data set for movie recommendation",
    "start": "804300",
    "end": "809879"
  },
  {
    "text": "called movie land's you're probably familiar with it so first of all of course i need to download it okay and",
    "start": "809879",
    "end": "816809"
  },
  {
    "text": "this is how it looks okay so the first column is a user ID the second column is",
    "start": "816809",
    "end": "823769"
  },
  {
    "text": "a movie ID and the third column is a rating between 1 and 5 then the last",
    "start": "823769",
    "end": "829709"
  },
  {
    "text": "column is a timestamp and I'm just ignoring it okay so this is what I would like to build a recommender on okay so I",
    "start": "829709",
    "end": "838230"
  },
  {
    "text": "need to import some Python libraries here including the sage maker SDK it's a",
    "start": "838230",
    "end": "843959"
  },
  {
    "text": "Python SDK it's available on github it's obviously pre-installed here okay",
    "start": "843959",
    "end": "850079"
  },
  {
    "text": "so in this data set I've got just under a thousand users about 1,600 1,700",
    "start": "850079",
    "end": "856139"
  },
  {
    "text": "movies and I've got about I've got",
    "start": "856139",
    "end": "861480"
  },
  {
    "text": "100,000 our ratings actually so the data",
    "start": "861480",
    "end": "866549"
  },
  {
    "text": "set is split between tests and training okay so I just need to load them from",
    "start": "866549",
    "end": "872600"
  },
  {
    "text": "from file into into a dictionary here",
    "start": "872600",
    "end": "877769"
  },
  {
    "text": "that's strictly Python stuff you know we don't really care okay so I need to load my two data sets from the files into",
    "start": "877769",
    "end": "884730"
  },
  {
    "text": "memory I'm going to check the sizes here so I've got over 90 case ampuls for",
    "start": "884730",
    "end": "892639"
  },
  {
    "text": "training here and I've got about 10k samples for testing okay okay so now my",
    "start": "892639",
    "end": "901169"
  },
  {
    "text": "data set is loaded and what I want to do is put it in s3 because this is where sage maker will pick it up but as we",
    "start": "901169",
    "end": "908339"
  },
  {
    "text": "work with built-in Argos we have to make sure we provide the data in a format that the algo understands okay so it's",
    "start": "908339",
    "end": "915419"
  },
  {
    "text": "in the documentation this factorization machines implementation",
    "start": "915419",
    "end": "921690"
  },
  {
    "text": "expects data to be in protobuf format which is a popular serialization format",
    "start": "921690",
    "end": "927210"
  },
  {
    "text": "so I need to take my Python data my training set and I need to write it to",
    "start": "927210",
    "end": "933660"
  },
  {
    "text": "the protobuf on that and copy to s3 and that's what I'm doing in that next cell",
    "start": "933660",
    "end": "939770"
  },
  {
    "text": "okay using a sage maker a function called write sparse matrix - sparse tensor copy",
    "start": "939770",
    "end": "949260"
  },
  {
    "text": "that stuff into into a local buffer and then upload that to s3 okay and I do",
    "start": "949260",
    "end": "955140"
  },
  {
    "text": "this both for the training set and the test set okay so now my data is nest 3",
    "start": "955140",
    "end": "960510"
  },
  {
    "text": "it's in the right format that the algo expects I can get I can get on with my",
    "start": "960510",
    "end": "966990"
  },
  {
    "text": "training job so you heard me set containers containers containers right it's like yeah I really mean containers",
    "start": "966990",
    "end": "972480"
  },
  {
    "text": "like in docker containers okay because all the prediction all the training and",
    "start": "972480",
    "end": "977730"
  },
  {
    "text": "prediction work here under the hood happens using docker containers okay so",
    "start": "977730",
    "end": "983190"
  },
  {
    "text": "sage maker right now is available in those four regions so I need to select the factorization machines container",
    "start": "983190",
    "end": "989820"
  },
  {
    "text": "that corresponds to the region I'm running in I'm running in the US region here okay and I'm going to create that",
    "start": "989820",
    "end": "996390"
  },
  {
    "text": "estimator object which is a in the sage maker SDK passing the the actual",
    "start": "996390",
    "end": "1001520"
  },
  {
    "text": "container storing the code okay for factorization machines and once again as",
    "start": "1001520",
    "end": "1006560"
  },
  {
    "text": "you see we don't write a single line of machine learning code we pick an off-the-shelf container storing that",
    "start": "1006560",
    "end": "1012920"
  },
  {
    "text": "implementation we pass a role we pass the session we pass the output terrific",
    "start": "1012920",
    "end": "1019430"
  },
  {
    "text": "switch is where sage maker should copy the trained model and when it comes to",
    "start": "1019430",
    "end": "1024890"
  },
  {
    "text": "training infrastructure the only thing that we have to say is please train on one C for Excel instance that's it you",
    "start": "1024890",
    "end": "1032480"
  },
  {
    "text": "don't have to start any kind of infrastructure you don't have to manage it you don't have to install anything",
    "start": "1032480",
    "end": "1037790"
  },
  {
    "text": "you tell it okay please just give me one C for Excel and if I said hey please give me ten I would just put ten instead",
    "start": "1037790",
    "end": "1045170"
  },
  {
    "text": "of one right if I wanted P three instances I would just replace C four by",
    "start": "1045170",
    "end": "1050630"
  },
  {
    "text": "P three and that's it okay so machine running at scale is zero infrastructure work literally zero",
    "start": "1050630",
    "end": "1057160"
  },
  {
    "text": "okay then I need to set some hyper parameters for my job these are algo specific so I'm not gonna",
    "start": "1057160",
    "end": "1064450"
  },
  {
    "text": "go into the theory of factorization machines you would run away but these",
    "start": "1064450",
    "end": "1070090"
  },
  {
    "text": "are documented I want to build a classifier bla bla bla bla bla and then I call that last API fit okay which is",
    "start": "1070090",
    "end": "1079780"
  },
  {
    "text": "the one that gets the training going okay that's it the rest is just my",
    "start": "1079780",
    "end": "1085420"
  },
  {
    "text": "training log okay so it's gonna run it runs for a bit and then I get my model okay and next thing I want to do is",
    "start": "1085420",
    "end": "1094180"
  },
  {
    "text": "maybe run some predictions so would it be complicated to actually take this",
    "start": "1094180",
    "end": "1100510"
  },
  {
    "text": "model and deploy it on the web server somewhere or many web servers that can serve predictions well it's as",
    "start": "1100510",
    "end": "1106870"
  },
  {
    "text": "complicated as this again called deploy the deploy API on that model and say",
    "start": "1106870",
    "end": "1111970"
  },
  {
    "text": "please deploy on a C for Excel job done right if you tried doing the same thing",
    "start": "1111970",
    "end": "1117610"
  },
  {
    "text": "manually using any of those machine learning a deep-lying libraries building a web app to encapsulate your model and",
    "start": "1117610",
    "end": "1125590"
  },
  {
    "text": "serve some predictions you know you know it's a lot of work okay here it's just one API call and you can predict okay",
    "start": "1125590",
    "end": "1132610"
  },
  {
    "text": "and then I've got an HTTP endpoint that I can invoke and predict I'm predicting",
    "start": "1132610",
    "end": "1138400"
  },
  {
    "text": "some new samples with it okay when I say zero infrastructure I mean zero okay so",
    "start": "1138400",
    "end": "1148590"
  },
  {
    "text": "I've got a blog a detailed blog post on this you'll get the slides of course and you can go through all the steps and run",
    "start": "1148590",
    "end": "1155200"
  },
  {
    "text": "this yourself let's move on to another algo this one is a the k-means",
    "start": "1155200",
    "end": "1160990"
  },
  {
    "text": "clustering I'll go so it's unsupervised learning just pass a lot of data points",
    "start": "1160990",
    "end": "1166300"
  },
  {
    "text": "and ask the algo to classify to cluster them to group them into a number of",
    "start": "1166300",
    "end": "1171520"
  },
  {
    "text": "clusters so here once again we compared this implementation to the best",
    "start": "1171520",
    "end": "1177340"
  },
  {
    "text": "implementation we could find out there and as you can see the the billable time",
    "start": "1177340",
    "end": "1184210"
  },
  {
    "text": "in minutes so the actual cost and time again which is the same thing for us because you pay for this by seconds",
    "start": "1184210",
    "end": "1190450"
  },
  {
    "text": "right so time and cost are strictly equivalent for a sage maker well we see that there is a huge cost reduction for",
    "start": "1190450",
    "end": "1200519"
  },
  {
    "text": "for the for the building for the training of those clusters right and we",
    "start": "1200519",
    "end": "1207820"
  },
  {
    "text": "see some good scalability as well because when we move from 10 clusters to 500 clusters there's a bit of a bump but",
    "start": "1207820",
    "end": "1214749"
  },
  {
    "text": "nothing like the other one okay and when it comes to precision the numbers that",
    "start": "1214749",
    "end": "1219759"
  },
  {
    "text": "you see here are the actual the total sum of squared distances sorry the total",
    "start": "1219759",
    "end": "1225669"
  },
  {
    "text": "sum of squared distances between the points and their respective Center okay which is how clustering works and we can",
    "start": "1225669",
    "end": "1233289"
  },
  {
    "text": "see that for pretty much every configuration we either really close or",
    "start": "1233289",
    "end": "1239799"
  },
  {
    "text": "we even exceed that best implementation and more interestingly when we move to",
    "start": "1239799",
    "end": "1244809"
  },
  {
    "text": "very large data sets like the two lower ones for advertising and the synthetic one when we move to big data sets the",
    "start": "1244809",
    "end": "1253029"
  },
  {
    "text": "other the other solution drops out right we can't even train okay and sage maker",
    "start": "1253029",
    "end": "1259869"
  },
  {
    "text": "just goes on and it would go on forever because again we're streaming data so it doesn't matter how large the data set is",
    "start": "1259869",
    "end": "1268049"
  },
  {
    "text": "here's another one it's a the The Godfather of machine learning all goes",
    "start": "1268049",
    "end": "1274029"
  },
  {
    "text": "it's called PCA and PCA is used to reduce dimensionality so let's say you have a thousand features in your data",
    "start": "1274029",
    "end": "1280059"
  },
  {
    "text": "set and that's way too much and you want to automatically reduce that to you know",
    "start": "1280059",
    "end": "1285399"
  },
  {
    "text": "50 10 whatever whatever number of features is really needed for your model removing correlation etc that's what PCA",
    "start": "1285399",
    "end": "1292450"
  },
  {
    "text": "does okay so here again we tested it there are two modes for a deterministic",
    "start": "1292450",
    "end": "1298629"
  },
  {
    "text": "and randomized but never mind and this is very spectacular right the the",
    "start": "1298629",
    "end": "1304029"
  },
  {
    "text": "speed-up and the cost is just insanely lower using our own implementation",
    "start": "1304029",
    "end": "1310450"
  },
  {
    "text": "compared to the best implementation you're looking at here the blue one okay and when you look at throughput and",
    "start": "1310450",
    "end": "1317120"
  },
  {
    "text": "scalability well you can see that as we add machines right for the green and and",
    "start": "1317120",
    "end": "1324770"
  },
  {
    "text": "orange bars as we add machines we keep we maintain the cell the same level of",
    "start": "1324770",
    "end": "1331760"
  },
  {
    "text": "throughput right so more Hardware maintains the same throughput the same",
    "start": "1331760",
    "end": "1337580"
  },
  {
    "text": "amount of data we can process with PCA okay so if you want to go faster just",
    "start": "1337580",
    "end": "1343250"
  },
  {
    "text": "add more machines it will go faster and and scale linearly another one this one",
    "start": "1343250",
    "end": "1352040"
  },
  {
    "text": "is the new rule topic modeling it's a popular way it's a popular I'll go for",
    "start": "1352040",
    "end": "1357260"
  },
  {
    "text": "natural language processing and you could build topics with it like comprehend does",
    "start": "1357260",
    "end": "1362870"
  },
  {
    "text": "and here again we tried it against the best implementation we could find and it's it gets to significantly lower",
    "start": "1362870",
    "end": "1372530"
  },
  {
    "text": "perplexity perplexity is the quality measure you use when you're working with",
    "start": "1372530",
    "end": "1378200"
  },
  {
    "text": "a natural language processing right when you do translations or or you build topics okay so it's we get you know 20%",
    "start": "1378200",
    "end": "1386990"
  },
  {
    "text": "better perplexity which is a very significant significant performance improvement it goes on so this is one of",
    "start": "1386990",
    "end": "1395540"
  },
  {
    "text": "the newer ones called deep AR and you can work with time series okay so a time",
    "start": "1395540",
    "end": "1403370"
  },
  {
    "text": "series is a popular use case so here we tried it on traffic data electricity data website traffic etc and we compared",
    "start": "1403370",
    "end": "1413600"
  },
  {
    "text": "it to the best implementation we could find out there which is using the our language right and well as you can see",
    "start": "1413600",
    "end": "1421120"
  },
  {
    "text": "we get again we tend to beat pretty much",
    "start": "1421120",
    "end": "1427250"
  },
  {
    "text": "all the time the the reference implementation just delivering lower",
    "start": "1427250",
    "end": "1432590"
  },
  {
    "text": "percentage error and lower loss so this is a super not only a super accurate",
    "start": "1432590",
    "end": "1438260"
  },
  {
    "text": "algo it's a super scalable I'll go right that's what you want you want something scalable something unexpensive",
    "start": "1438260",
    "end": "1446180"
  },
  {
    "text": "and something accurate right and we always knew remember that Iron Triangle",
    "start": "1446180",
    "end": "1452200"
  },
  {
    "text": "costs quality and budget pick - yeah",
    "start": "1452200",
    "end": "1457400"
  },
  {
    "text": "it's the number-one rule in project management you can't have all three well",
    "start": "1457400",
    "end": "1463250"
  },
  {
    "text": "somebody worked some magic because here for those algos we seem to be getting all three we maintain quality while",
    "start": "1463250",
    "end": "1470180"
  },
  {
    "text": "cutting significantly training times and thus the spent associated so it's a bit",
    "start": "1470180",
    "end": "1476060"
  },
  {
    "text": "of a magic service this one so actually DPR has been so it's been invented by",
    "start": "1476060",
    "end": "1485080"
  },
  {
    "text": "Amazon and a SS engineers the the research paper is available out there",
    "start": "1485080",
    "end": "1490310"
  },
  {
    "text": "she want to read it it's pretty involved but if you're into the computer science",
    "start": "1490310",
    "end": "1495830"
  },
  {
    "text": "side of things and machine learning you're gonna like that okay so not only",
    "start": "1495830",
    "end": "1500990"
  },
  {
    "text": "popular route goes like linear regression and factorization machines but also new stuff that we like to",
    "start": "1500990",
    "end": "1506660"
  },
  {
    "text": "invent it ok let's quickly look at a demo here moving on to a new notebook",
    "start": "1506660",
    "end": "1520450"
  },
  {
    "start": "1509000",
    "end": "1869000"
  },
  {
    "text": "oops ok so here I'm using a data set from Berkeley University this data set",
    "start": "1520450",
    "end": "1527570"
  },
  {
    "text": "has a global temperature measure for the globe everyday since 1880 okay and so",
    "start": "1527570",
    "end": "1535520"
  },
  {
    "text": "I'm going to build time series one time series for each year so hopefully 365",
    "start": "1535520",
    "end": "1541610"
  },
  {
    "text": "points per time series and I want to learn from that and predict from that ok that's what I'm trying to do so once",
    "start": "1541610",
    "end": "1548840"
  },
  {
    "text": "again I need to download my data set nothing spectacular so it goes from 1880",
    "start": "1548840",
    "end": "1555770"
  },
  {
    "text": "to 2014 and I want to I want to be able to",
    "start": "1555770",
    "end": "1561230"
  },
  {
    "text": "predict 30 days right when you work with Time series one important parameter is",
    "start": "1561230",
    "end": "1566870"
  },
  {
    "text": "how long is the time series that you want to predict ok so here at any given",
    "start": "1566870",
    "end": "1572690"
  },
  {
    "text": "point in my time cereal I would be able to say ok give me the temperature for the next 30 days ok it's a parameter",
    "start": "1572690",
    "end": "1579140"
  },
  {
    "text": "that I that I picked okay so I will load my data once again put it in a dictionary",
    "start": "1579140",
    "end": "1585390"
  },
  {
    "text": "bla bla bla buy some stuff I want to plot it okay this is what it looks like",
    "start": "1585390",
    "end": "1590510"
  },
  {
    "text": "world temperature from 1880 to 2014 so you come up with your own conclusions",
    "start": "1590510",
    "end": "1597720"
  },
  {
    "text": "right I'm not here to talk about politics and then so I need to prepare",
    "start": "1597720",
    "end": "1607020"
  },
  {
    "text": "my data set for four for training okay so the way you train on time series is a",
    "start": "1607020",
    "end": "1612960"
  },
  {
    "text": "bit different than traditional machine learning data sets the training set will be the all the time series - the last 30",
    "start": "1612960",
    "end": "1622710"
  },
  {
    "text": "days okay so I will actually catch the world the month of December okay from all",
    "start": "1622710",
    "end": "1627750"
  },
  {
    "text": "those years and the test set is the full data set okay that's how you work with Time series so I have to prepare for",
    "start": "1627750",
    "end": "1634590"
  },
  {
    "text": "that okay once again I need to write my",
    "start": "1634590",
    "end": "1639630"
  },
  {
    "text": "data set in a format that the algo understands this case DPR expects JSON",
    "start": "1639630",
    "end": "1645929"
  },
  {
    "text": "data JSON lines so one line for each year as you can see with the full 365",
    "start": "1645929",
    "end": "1654559"
  },
  {
    "text": "temperature for that year okay so I need to convert my data to that format and write it to s3 basically okay",
    "start": "1654559",
    "end": "1662039"
  },
  {
    "text": "upload it to a3 like I'm doing here and then once again I can configure my",
    "start": "1662039",
    "end": "1667049"
  },
  {
    "text": "training job so same story exact same story as before I'm going to pick the",
    "start": "1667049",
    "end": "1672120"
  },
  {
    "text": "deep layer container for the region I'm running in the role the output path blah",
    "start": "1672120",
    "end": "1677190"
  },
  {
    "text": "blah blah and I'm just asking here to train on one c48 excel instance I'm",
    "start": "1677190",
    "end": "1683640"
  },
  {
    "text": "gonna say it again you're going to get tired of it but it's zero infrastructure work then I need to define some",
    "start": "1683640",
    "end": "1689909"
  },
  {
    "text": "parameters for my job once again these are algo specific the the time frag",
    "start": "1689909",
    "end": "1695220"
  },
  {
    "text": "parameter says I am working with daily series right I've got one data point per day the context the prediction length is",
    "start": "1695220",
    "end": "1702780"
  },
  {
    "text": "the number of days I want to predict so 30 days and then I've got some crazy machine learning parameters and you can",
    "start": "1702780",
    "end": "1709350"
  },
  {
    "text": "read about those in the doc okay I said those parameters I define",
    "start": "1709350",
    "end": "1714679"
  },
  {
    "text": "where my training set and my test sets live and then I just called fit and I'm",
    "start": "1714679",
    "end": "1719720"
  },
  {
    "text": "training again okay and after a while I get to the end of training and now I",
    "start": "1719720",
    "end": "1727130"
  },
  {
    "text": "want to do some predictions so I'm gonna save that model into sage maker using the I'm sorry I saved it before so here",
    "start": "1727130",
    "end": "1735590"
  },
  {
    "text": "I'm deploying the model so I'm creating a deployment configuration it's called",
    "start": "1735590",
    "end": "1741110"
  },
  {
    "text": "an endpoint configuration with 1m for Excel instance okay and then I'm",
    "start": "1741110",
    "end": "1747049"
  },
  {
    "text": "creating I use it that real time predictor object I'm creating my actual and endpoint okay so this will fire up",
    "start": "1747049",
    "end": "1753470"
  },
  {
    "text": "the m4 Excel instance pull the container to it deploy my model etc etc so now I",
    "start": "1753470",
    "end": "1761240"
  },
  {
    "text": "could predict so I need to build a prediction request with that same JSON",
    "start": "1761240",
    "end": "1766940"
  },
  {
    "text": "format that the algo understands okay and some utility functions okay let's",
    "start": "1766940",
    "end": "1774080"
  },
  {
    "text": "just look at this one really quick so I'm going to I want to compare my",
    "start": "1774080",
    "end": "1781750"
  },
  {
    "text": "predictions with the actual with the actual value so here I use 1984 right",
    "start": "1781750",
    "end": "1788409"
  },
  {
    "text": "and I'm comparing the last 30 days of",
    "start": "1788409",
    "end": "1793899"
  },
  {
    "text": "1984 with the values that I predict okay so the the actual predict yeah the real",
    "start": "1793899",
    "end": "1800870"
  },
  {
    "text": "values are the purple values here right the the truth okay and then when you",
    "start": "1800870",
    "end": "1808580"
  },
  {
    "text": "predict with time see residual you just you don't just predict one data point",
    "start": "1808580",
    "end": "1814760"
  },
  {
    "text": "you actually predict many different data points and and then start statistically",
    "start": "1814760",
    "end": "1820580"
  },
  {
    "text": "you can compute the 19th percentile the 10th percentile the mean etc etc that's",
    "start": "1820580",
    "end": "1826340"
  },
  {
    "text": "what I'm doing here okay so I see the mean is the blue line and it's quite close to my Purple Line so I'm actually",
    "start": "1826340",
    "end": "1833390"
  },
  {
    "text": "doing a pretty good job at learning here and the the the the yellow and green channel are",
    "start": "1833390",
    "end": "1841840"
  },
  {
    "text": "the 10th percentile in the 90s percentile and the red line is just one of those samples that I predicted I",
    "start": "1841840",
    "end": "1847600"
  },
  {
    "text": "selected a random one okay so my prediction is not too not too bad right",
    "start": "1847600",
    "end": "1853150"
  },
  {
    "text": "and remember 1984 he who controls the past controls the future right that's",
    "start": "1853150",
    "end": "1859300"
  },
  {
    "text": "what time series are all about okay all right so time series not too difficult",
    "start": "1859300",
    "end": "1868289"
  },
  {
    "start": "1869000",
    "end": "2209000"
  },
  {
    "text": "so that's pretty good right this collection of infinitely scalable our",
    "start": "1869580",
    "end": "1874720"
  },
  {
    "text": "goals but customers want it more right you always want more so we decided to",
    "start": "1874720",
    "end": "1881080"
  },
  {
    "text": "add more algos to Sage maker more built-in algos so these are not infinitely scalable these are not based",
    "start": "1881080",
    "end": "1888370"
  },
  {
    "text": "on the same design principles that I mentioned before but they're still quite good and they they're pretty useful so",
    "start": "1888370",
    "end": "1895540"
  },
  {
    "text": "let's look at some use cases one of those is called LGA and Lda is another",
    "start": "1895540",
    "end": "1902200"
  },
  {
    "text": "topic modeling I'll go and this is actually the algo that Amazon comprehend uses okay remember we talked about this",
    "start": "1902200",
    "end": "1909790"
  },
  {
    "text": "one this morning and and the ian is going to do a cool session on comprehend",
    "start": "1909790",
    "end": "1914920"
  },
  {
    "text": "after this I think and well in a nutshell this is the algo that that's",
    "start": "1914920",
    "end": "1920290"
  },
  {
    "text": "being used so if you would if you wanted to build your own topic modeling application you could you could try this",
    "start": "1920290",
    "end": "1926970"
  },
  {
    "text": "okay so here once again you have to compare compare the the orange one with",
    "start": "1926970",
    "end": "1933850"
  },
  {
    "text": "the light blue one okay and you see on the number of topics that training time",
    "start": "1933850",
    "end": "1940450"
  },
  {
    "text": "is is much much lower than than the reference implementation and you see you",
    "start": "1940450",
    "end": "1947260"
  },
  {
    "text": "know it's fair to say that the scalability is is quite linear but you",
    "start": "1947260",
    "end": "1953860"
  },
  {
    "text": "know there's obviously much more work involved in building harder topics than twenty okay so it's more costly but you",
    "start": "1953860",
    "end": "1961750"
  },
  {
    "text": "know it skills it gives pretty well and then if you compare the green one to the purple one",
    "start": "1961750",
    "end": "1968020"
  },
  {
    "text": "it's about the same thing okay so just the training time is just so much lower",
    "start": "1968020",
    "end": "1973460"
  },
  {
    "text": "right look at the scale over there right there each square is 50 minutes so we",
    "start": "1973460",
    "end": "1979520"
  },
  {
    "text": "literally save hours right on each job here well this is the one that everybody",
    "start": "1979520",
    "end": "1987110"
  },
  {
    "text": "uses I guess XJ boost it's probably the most common classifier out there to do",
    "start": "1987110",
    "end": "1993530"
  },
  {
    "text": "binary classification or multi-class classification it's an open source project so we just took that probably",
    "start": "1993530",
    "end": "2000670"
  },
  {
    "text": "tweaked it a bit and and now it's available as a built-in I'll go on AWS okay and as you can see here once again",
    "start": "2000670",
    "end": "2007570"
  },
  {
    "text": "we see almost linear scaling when it comes to a number of machines versus",
    "start": "2007570",
    "end": "2013930"
  },
  {
    "text": "throughput okay so if you just want to go twice faster and you had twice number of machines you'll be pretty close to",
    "start": "2013930",
    "end": "2020740"
  },
  {
    "text": "linear scalability okay super popular I'll go sure some people you are using this another one is called sequence to",
    "start": "2020740",
    "end": "2030130"
  },
  {
    "text": "sequence it's it's a natural language processing I'll go and we use it for",
    "start": "2030130",
    "end": "2037560"
  },
  {
    "text": "neural machine translation actually last year we published an open source project",
    "start": "2037560",
    "end": "2044830"
  },
  {
    "text": "called Sakai and the Sakai lets you train translation models so once again",
    "start": "2044830",
    "end": "2051129"
  },
  {
    "text": "if if you wanted to translate again let's say Hebrew to Russian which is not",
    "start": "2051130",
    "end": "2056530"
  },
  {
    "text": "available to inside of Amazon translate for now well you could probably try to",
    "start": "2056530",
    "end": "2062800"
  },
  {
    "text": "build a model using sequence to sequence on Amazon sage maker or you could go and",
    "start": "2062800",
    "end": "2068440"
  },
  {
    "text": "grab the Sakai open source project if you didn't want to use an AWS service and you could run Sakai even on your own",
    "start": "2068440",
    "end": "2074889"
  },
  {
    "text": "machines and train your model okay so this is based on Sakai and Amazon",
    "start": "2074890",
    "end": "2082148"
  },
  {
    "text": "translate is also based on this so many options to get to the same result so as",
    "start": "2082149",
    "end": "2088960"
  },
  {
    "text": "you can see you know how good a good is that thing it's pretty good when it comes to measuring Qualtrics relation",
    "start": "2088960",
    "end": "2094960"
  },
  {
    "text": "quality my researchers use the blue score which it's a quality metric and",
    "start": "2094960",
    "end": "2100770"
  },
  {
    "text": "and here training English to German depending on the instance size that we",
    "start": "2100770",
    "end": "2106570"
  },
  {
    "text": "use obviously we get reasonably quickly to the state-of-the-art result and in",
    "start": "2106570",
    "end": "2114280"
  },
  {
    "text": "some cases you know it's fair to say we slightly exceeded okay I don't want to",
    "start": "2114280",
    "end": "2119440"
  },
  {
    "text": "brag so Sakai again has been published",
    "start": "2119440",
    "end": "2124690"
  },
  {
    "text": "okay so you can grab you can grab that article and of course you can grab the sauces on github",
    "start": "2124690",
    "end": "2129940"
  },
  {
    "text": "okay this is a amazon amazon invented and we're happy to share it with",
    "start": "2129940",
    "end": "2135460"
  },
  {
    "text": "everybody okay one more I've got some more time",
    "start": "2135460",
    "end": "2140950"
  },
  {
    "text": "image classification so image classification is pretty much what you",
    "start": "2140950",
    "end": "2146590"
  },
  {
    "text": "could do with Amazon recognition okay except like I said the earlier if you",
    "start": "2146590",
    "end": "2152440"
  },
  {
    "text": "need to classify very domain specific images you know medical images car part",
    "start": "2152440",
    "end": "2159550"
  },
  {
    "text": "images whatever you know just specific things it's fair to say recognition is not going to do a very good job at that",
    "start": "2159550",
    "end": "2165700"
  },
  {
    "text": "because it's been only trained on general data so here we bring you a built in algo it's based on the",
    "start": "2165700",
    "end": "2172300"
  },
  {
    "text": "resonance architecture so ResNet is the state of the art image classification",
    "start": "2172300",
    "end": "2177750"
  },
  {
    "text": "deep learning model so what you do here I'm going to show you a demo in a second you can just grab that container and and",
    "start": "2177750",
    "end": "2185590"
  },
  {
    "text": "select a model and and get to work right you don't have to actually design",
    "start": "2185590",
    "end": "2190780"
  },
  {
    "text": "anything just like in the other cases and when we look at performance once again we see almost linear scaling okay",
    "start": "2190780",
    "end": "2198670"
  },
  {
    "text": "which is very desirable if you want to train on a huge data set okay so really",
    "start": "2198670",
    "end": "2205240"
  },
  {
    "text": "quick how would we do this okay",
    "start": "2205240",
    "end": "2214030"
  },
  {
    "text": "import some stuff well now you know the story I'm just going to repeat myself select a container okay in the region",
    "start": "2214030",
    "end": "2220420"
  },
  {
    "text": "where I'm running okay so here I'm not going to train from scratch my image classifier I'm going to take a pre",
    "start": "2220420",
    "end": "2226930"
  },
  {
    "text": "trained network a pre trained version of ResNet and I'm just going to find units just to train it a little more on",
    "start": "2226930",
    "end": "2232930"
  },
  {
    "text": "another image data set okay so I need to download that dataset",
    "start": "2232930",
    "end": "2238010"
  },
  {
    "text": "put everything in s3 define some parameters for for the ResNet model okay",
    "start": "2238010",
    "end": "2247900"
  },
  {
    "text": "put all that stuff in a JSON document blah blah blah create my training job",
    "start": "2247900",
    "end": "2254890"
  },
  {
    "text": "okay and this is the low-level stage maker API so it has a little more raw code but it's a little more flexible at",
    "start": "2254890",
    "end": "2261980"
  },
  {
    "text": "times right so you don't use that estimator object that you that I showed you before but it's the same thing so",
    "start": "2261980",
    "end": "2268040"
  },
  {
    "text": "you create the training job and then you wait for training to complete okay I can",
    "start": "2268040",
    "end": "2275420"
  },
  {
    "text": "grab the training information from cloud watch logs okay so the training accuracy the validation accuracy plot everything",
    "start": "2275420",
    "end": "2282350"
  },
  {
    "text": "I just trained for 10 epochs which is very short but I remember I was only fine-tuning not training from scratch",
    "start": "2282350",
    "end": "2288920"
  },
  {
    "text": "and then once again I can create an endpoint endpoint configurations I'm",
    "start": "2288920",
    "end": "2298370"
  },
  {
    "text": "going to deploy to 1m for excel creating the endpoint right and now I can run",
    "start": "2298370",
    "end": "2306680"
  },
  {
    "text": "some prediction so I can grab some random images from the web okay in this case a truck and predict them with my",
    "start": "2306680",
    "end": "2314750"
  },
  {
    "text": "model and my model has ten classes including trucks and I get 99.9",
    "start": "2314750",
    "end": "2320480"
  },
  {
    "text": "confidence this is actually a truck okay so again deep learning at scale image classification at scale you didn't",
    "start": "2320480",
    "end": "2327050"
  },
  {
    "text": "write a line of machine learning code just helper code to configure and run the training job there's another one",
    "start": "2327050",
    "end": "2339920"
  },
  {
    "text": "that got added recently it's called blazing text it's another natural language processing algorithm it builds",
    "start": "2339920",
    "end": "2346940"
  },
  {
    "text": "word vectors which is a popular technique for a lot of NLP applications",
    "start": "2346940",
    "end": "2353470"
  },
  {
    "text": "there are some benchmarks against fast text which is Facebook's implementation",
    "start": "2353470",
    "end": "2359300"
  },
  {
    "text": "and they're quite good right I didn't want to add more stuff to this presentation but if you work with NLP",
    "start": "2359300",
    "end": "2366550"
  },
  {
    "text": "models and LP apps this once again a very very scalable way on using distributed training and",
    "start": "2366550",
    "end": "2373480"
  },
  {
    "text": "distribute multiple GPUs to build word embeddings at scale okay",
    "start": "2373480",
    "end": "2378790"
  },
  {
    "text": "all right some resources so the obviously the machine learning website",
    "start": "2378790",
    "end": "2385000"
  },
  {
    "text": "the a I'll blog that has a lot of code and customer stories etc the sage maker",
    "start": "2385000",
    "end": "2391230"
  },
  {
    "text": "service page and there's a free tier available for sage maker so you can you can go and and actually try to for free",
    "start": "2391230",
    "end": "2398970"
  },
  {
    "text": "there are a lot of notebook examples on github so you can also find them on the",
    "start": "2398970",
    "end": "2404830"
  },
  {
    "text": "notebook instances that you fire up in sage maker but if you just want to read them quickly just go to get up and and",
    "start": "2404830",
    "end": "2411490"
  },
  {
    "text": "look at look for all these algos and of course all the other ways you can use sage maker and again guy will talk about",
    "start": "2411490",
    "end": "2417280"
  },
  {
    "text": "that later today if you'd like to see more about sage maker I recorded a YouTube video showing you the different",
    "start": "2417280",
    "end": "2423220"
  },
  {
    "text": "ways you can use it so built-in algo bring your own code bring your own model bring your own container seems to be",
    "start": "2423220",
    "end": "2430180"
  },
  {
    "text": "quite popular so probably you'll like that and well finally I'm blogging on medium posting some quite a lot of stuff",
    "start": "2430180",
    "end": "2438220"
  },
  {
    "text": "actually on the machine learning deep learning Apache MX net stage maker etc",
    "start": "2438220",
    "end": "2443410"
  },
  {
    "text": "and actually the the three demos I showed you today are straight out of that blog so again you might enjoy that",
    "start": "2443410",
    "end": "2449230"
  },
  {
    "text": "okay well thanks again thank you very much [Applause]",
    "start": "2449230",
    "end": "2461020"
  }
]
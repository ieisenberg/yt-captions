[
  {
    "start": "0",
    "end": "42000"
  },
  {
    "text": "hi everyone welcome today's webinar accelerate decision-making with real-time analytics on AWS so my name is",
    "start": "30",
    "end": "7049"
  },
  {
    "text": "Ryan Deiss I'm a senior product manager at AWS and I'll be the speaker and moderator for today's webinar with me",
    "start": "7049",
    "end": "13710"
  },
  {
    "text": "we'll have several of our great partners at AWS from data bricks brian turkey from MC pool mic or our ski as a resume",
    "start": "13710",
    "end": "22619"
  },
  {
    "text": "data sam diner we'll start off with a quick kick off of sort of what we think",
    "start": "22619",
    "end": "28920"
  },
  {
    "text": "about real-time analytics on AWS and an instruction to our partners and each of our partners will go through the various",
    "start": "28920",
    "end": "35190"
  },
  {
    "text": "offerings that they can provide you for real-time analytics on AWS so with that",
    "start": "35190",
    "end": "40379"
  },
  {
    "text": "let's go ahead and get started so what is streaming and I what it what does it",
    "start": "40379",
    "end": "45510"
  },
  {
    "start": "42000",
    "end": "42000"
  },
  {
    "text": "mean to real-time analytics so all of the solutions concluded in the last poll",
    "start": "45510",
    "end": "51120"
  },
  {
    "text": "have a streaming component to them for Apache spark it's Apache spark streaming patchy Frank is a continuous stream",
    "start": "51120",
    "end": "58980"
  },
  {
    "text": "processing engine Amazon Kinesis is a set of course streaming capabilities on AWS but what does that mean to real-time",
    "start": "58980",
    "end": "66270"
  },
  {
    "text": "analytics so when we talk about streaming to customers what we like to",
    "start": "66270",
    "end": "71820"
  },
  {
    "text": "what I like to say is it's not necessarily the specific data that makes it streaming it's what you do with the",
    "start": "71820",
    "end": "79110"
  },
  {
    "text": "data that makes good stream so there's a lot of data that's we think most data is continuously generated via video data or",
    "start": "79110",
    "end": "86850"
  },
  {
    "text": "log data or click stream events coming from a website a mobile phone it's",
    "start": "86850",
    "end": "92850"
  },
  {
    "text": "continuously generated what makes it streaming is acting on that data now in",
    "start": "92850",
    "end": "97890"
  },
  {
    "text": "real-time or near real-time instead of waiting and a good example that I",
    "start": "97890",
    "end": "102960"
  },
  {
    "text": "provide for this is you say if you have an Apache web server or an ec2 instance",
    "start": "102960",
    "end": "108630"
  },
  {
    "text": "or something along those lines and you're logging information about either customer behavior or your applications",
    "start": "108630",
    "end": "114680"
  },
  {
    "text": "what makes it streaming is if you can as the data is continuously generated you continuously send it to a durable",
    "start": "114680",
    "end": "122009"
  },
  {
    "text": "storage mechanism like Apache Kafka or Amazon Kinesis process it continuously",
    "start": "122009",
    "end": "127140"
  },
  {
    "text": "in real time and then either react to it or persist to it to a long-term store like say a data link",
    "start": "127140",
    "end": "133810"
  },
  {
    "text": "what makes it the same thing and not streaming is for example if you were to write the data to disk and wake up a",
    "start": "133810",
    "end": "141370"
  },
  {
    "text": "scheduled job every couple hours to send the data to some centralized storage system or if you were to",
    "start": "141370",
    "end": "147880"
  },
  {
    "text": "periodically updated database maybe every couple minutes with new results instead of streaming that data and then",
    "start": "147880",
    "end": "153580"
  },
  {
    "text": "updating that database in real time so that fundamentally makes when we talk about streaming that's fundamentally",
    "start": "153580",
    "end": "159160"
  },
  {
    "text": "what we're talking about and there's a lot of examples from it I mentioned application logs but streaming solutions",
    "start": "159160",
    "end": "165250"
  },
  {
    "text": "are very popular in for video security and home camera feeds for IOT sensor",
    "start": "165250",
    "end": "171730"
  },
  {
    "text": "data for clique streams from mobile devices and websites so it's very",
    "start": "171730",
    "end": "178720"
  },
  {
    "text": "popular for the lot of different areas so there's a simple pattern that I want",
    "start": "178720",
    "end": "184690"
  },
  {
    "start": "181000",
    "end": "181000"
  },
  {
    "text": "you to think about as we go through and each of our partners go through each of their solutions and offerings in the",
    "start": "184690",
    "end": "190960"
  },
  {
    "text": "real-time analytics space especially as it relates to streaming data so you can",
    "start": "190960",
    "end": "196630"
  },
  {
    "text": "think of it there's a data producer I mentioned a bunch of them on the last slide it continuously creates the data",
    "start": "196630",
    "end": "203080"
  },
  {
    "text": "and it's the first step in this sort of the streaming or real-time analytics pipeline it continuously writes that",
    "start": "203080",
    "end": "209050"
  },
  {
    "text": "data to a stream you can use a streaming service like Amazon Kinesis which would durably ingest those messages a high",
    "start": "209050",
    "end": "215560"
  },
  {
    "text": "volume efficiently reliably stores the data and provides this temporary buffer Apache Kafka is another phenomenal",
    "start": "215560",
    "end": "222730"
  },
  {
    "text": "example for what you could do for this middle layer this streaming service the key is that it supports very high",
    "start": "222730",
    "end": "228280"
  },
  {
    "text": "throughput efficiently and provides that temporary durable buffer and the second piece is a data consumer again the",
    "start": "228280",
    "end": "235090"
  },
  {
    "text": "continuous word were continuously processing data as it arrives on the street these data consumers will do",
    "start": "235090",
    "end": "240940"
  },
  {
    "text": "everything from very simple buffering so turning small raw records into larger",
    "start": "240940",
    "end": "246010"
  },
  {
    "text": "files before persisting it to destination like Amazon s3 or HDFS so",
    "start": "246010",
    "end": "252970"
  },
  {
    "text": "that they can be consumed more easily by batch processing tools to perform real-time machine learning and",
    "start": "252970",
    "end": "259000"
  },
  {
    "text": "visualizations and leaderboards and you'll see a lot of examples today with our partners covering that so Amazon",
    "start": "259000",
    "end": "267550"
  },
  {
    "start": "265000",
    "end": "265000"
  },
  {
    "text": "offers a set of streaming services underneath Amazon Kinesis at AWS the four services that we offer first are",
    "start": "267550",
    "end": "273760"
  },
  {
    "text": "Kinesis video streams it's a newest service it was recently launched at reinvent last year it allows you to",
    "start": "273760",
    "end": "280690"
  },
  {
    "text": "capture process and store video streams in real time the core use cases for are",
    "start": "280690",
    "end": "286360"
  },
  {
    "text": "things like ingesting home camera feeds security cameras these types of things",
    "start": "286360",
    "end": "293080"
  },
  {
    "text": "in not only doesn't allow you to capture and store that data but it also has good integrations with Amazon machine",
    "start": "293080",
    "end": "298210"
  },
  {
    "text": "learning services so you can do things like image recognition Amazon Kinesis",
    "start": "298210",
    "end": "303400"
  },
  {
    "text": "data streams is our earliest service it allows you to capture and process and store those data streams and from the",
    "start": "303400",
    "end": "310630"
  },
  {
    "text": "last line it's the middle layer it's a core infrastructure product that a lot of AWS services use a large number of",
    "start": "310630",
    "end": "317169"
  },
  {
    "text": "AWS customers use to basically connect the dots between a high-volume data stream and downstream AWS analytics",
    "start": "317169",
    "end": "325000"
  },
  {
    "text": "services can use this data firehose is the second service that we launched",
    "start": "325000",
    "end": "330070"
  },
  {
    "text": "under the kinis family and it solves a specific problem with very very well and",
    "start": "330070",
    "end": "336070"
  },
  {
    "text": "that's how do I move data from point A to point B so there's no code required",
    "start": "336070",
    "end": "341710"
  },
  {
    "text": "you write data at a high volume you can use this data firehose and they configure your firehose delivery stream",
    "start": "341710",
    "end": "347830"
  },
  {
    "text": "to deliver data to a configured destination the destinations we support are Amazon s3 Amazon Elastic search",
    "start": "347830",
    "end": "354580"
  },
  {
    "text": "service Amazon redshift our data warehouse service and Splunk and what",
    "start": "354580",
    "end": "360430"
  },
  {
    "text": "you can do is you can configure different parameters associated with the delivery things like encryption compression even performing simple",
    "start": "360430",
    "end": "366790"
  },
  {
    "text": "transforms on the way from generating the data at point a to delivering the data to point B requires no code no",
    "start": "366790",
    "end": "374010"
  },
  {
    "text": "application the primary difference between it and can uses data streams is firehose is provides a lot of removal of",
    "start": "374010",
    "end": "380500"
  },
  {
    "text": "complexity there's no need to run a code but you lose some flexibility when you use them can you sustain an oasis the",
    "start": "380500",
    "end": "386770"
  },
  {
    "text": "last service that I'd like to mention and it's a sequel based product for writing real-time queries that operate",
    "start": "386770",
    "end": "392740"
  },
  {
    "text": "continuously on can uses data streams it can use data files and the easiest way for me to describe what the service does is to come up with",
    "start": "392740",
    "end": "398550"
  },
  {
    "text": "an example so as an example if you would like to stream clickstream data from say your mobile application and compute live",
    "start": "398550",
    "end": "407639"
  },
  {
    "text": "leaderboards so how many web how many views and clicks am I getting on",
    "start": "407639",
    "end": "414030"
  },
  {
    "text": "specific pages or specific parts of my page and then react to that in real time maybe change your ad strategy or maybe",
    "start": "414030",
    "end": "421469"
  },
  {
    "text": "in real time as the customer comes in if they follow a specific pattern of viewing your website you give them a",
    "start": "421469",
    "end": "428280"
  },
  {
    "text": "promotional ad that type of thing it's really about reacting to the data as it's being generated so a very similar",
    "start": "428280",
    "end": "438990"
  },
  {
    "start": "435000",
    "end": "435000"
  },
  {
    "text": "sort of example that I just provided with can uses data analytics let's just walk through and an example of what",
    "start": "438990",
    "end": "446219"
  },
  {
    "text": "real-time analytics would mean in the streaming context so imagine loading a social media stream from commuters data",
    "start": "446219",
    "end": "452430"
  },
  {
    "text": "stream will the Kinesis data stream will ingest and durably store that data making it available for real-time",
    "start": "452430",
    "end": "458550"
  },
  {
    "text": "processing one example of a consumer is a Kinesis data analytics consumer but",
    "start": "458550",
    "end": "464190"
  },
  {
    "text": "there's a number of other open source libraries apache spark streaming is one of them a number of our partners provide",
    "start": "464190",
    "end": "469199"
  },
  {
    "text": "them for generating hash tag trends on those data in real time you might use a",
    "start": "469199",
    "end": "475259"
  },
  {
    "text": "database lambda function to load which is our server list compute service to",
    "start": "475259",
    "end": "481500"
  },
  {
    "text": "take that sequel result and write it to a dynamo DB table updating a specific item which then feeds a real-time",
    "start": "481500",
    "end": "488699"
  },
  {
    "text": "dashboard and Amazon DynamoDB is our no sequel database offering all of these",
    "start": "488699",
    "end": "494279"
  },
  {
    "text": "integrations are very very seamless and easy to build so are the integrations with our partners so this is just one",
    "start": "494279",
    "end": "501779"
  },
  {
    "text": "example of a particle solution that you would build for social media analytics",
    "start": "501779",
    "end": "508310"
  },
  {
    "start": "507000",
    "end": "507000"
  },
  {
    "text": "we have a lot of customers building real-time solutions on AWS the one",
    "start": "508310",
    "end": "513510"
  },
  {
    "text": "specific example I'll call out is red fin which does real-time home recommendations so as users brown a red",
    "start": "513510",
    "end": "519959"
  },
  {
    "text": "fin is a home search and discovery tool is also a real estate company well one",
    "start": "519959",
    "end": "525930"
  },
  {
    "text": "of the things they do with Amazon Kinesis in real-time analytics is to ingest customers behavior on the",
    "start": "525930",
    "end": "532350"
  },
  {
    "text": "website and provide that customer based off of their search criteria as well as their their website browsing patterns",
    "start": "532350",
    "end": "538770"
  },
  {
    "text": "provide them as real-time of home recommendations with the end goal trying to find the home for the consumer that",
    "start": "538770",
    "end": "544710"
  },
  {
    "text": "they want to purchase or more interested in but the only other comment I'll have",
    "start": "544710",
    "end": "550230"
  },
  {
    "text": "on the slides you can see that these real-time analytics and streaming examples they're covered across a wide",
    "start": "550230",
    "end": "556680"
  },
  {
    "text": "variety of verticals and it's because turning raw data into information quickly is very very valuable to any",
    "start": "556680",
    "end": "564000"
  },
  {
    "text": "business as we go through the partner",
    "start": "564000",
    "end": "570840"
  },
  {
    "text": "presentations it's helpful to sort of understand where in the stack each of",
    "start": "570840",
    "end": "575850"
  },
  {
    "text": "these partners play so you can see that on the left-hand side we have that",
    "start": "575850",
    "end": "580980"
  },
  {
    "text": "pattern that I mentioned the data producers and then a durable storage for",
    "start": "580980",
    "end": "586380"
  },
  {
    "text": "collecting that data like Amazon can uses data streams and Apache Kafka a lot",
    "start": "586380",
    "end": "591690"
  },
  {
    "text": "of our partners offer solutions for durable storage as well as processing and analyzing and they each have their own value proposition around how you can",
    "start": "591690",
    "end": "599610"
  },
  {
    "text": "build your own real-time analytics solutions on AWS using these partners so",
    "start": "599610",
    "end": "606600"
  },
  {
    "text": "with that I'm going to pass it off to our first presenter Brian from data bricks who's going to talk about",
    "start": "606600",
    "end": "612540"
  },
  {
    "text": "accelerating innovation with big data and unified analytics on data bricks",
    "start": "612540",
    "end": "618980"
  },
  {
    "text": "great thanks Ryan a dative bricks let me just get my slide here never recover at data bricks our",
    "start": "619640",
    "end": "627450"
  },
  {
    "text": "vision is to accelerate innovation by unifying data science and engineering in business and we provide the unified",
    "start": "627450",
    "end": "633750"
  },
  {
    "text": "analytics platform which is powered by Apache spark data bricks was founded by the creators of Apache spark and we",
    "start": "633750",
    "end": "640470"
  },
  {
    "text": "contribute 75% of the open source code ten times more than any other company and we've trained more than 40,000 spark",
    "start": "640470",
    "end": "648000"
  },
  {
    "text": "users on the data bricks platform so if you're not familiar with spark and it looks like you know over half of our",
    "start": "648000",
    "end": "653370"
  },
  {
    "text": "audience is familiar with spark but if you're not familiar with it it's it's widely recognized as the top engine for",
    "start": "653370",
    "end": "658830"
  },
  {
    "text": "high scale computing and analytics",
    "start": "658830",
    "end": "662360"
  },
  {
    "text": "let me get my there we go sorry too many so data bricks is a cloud implementation",
    "start": "664930",
    "end": "671810"
  },
  {
    "start": "667000",
    "end": "667000"
  },
  {
    "text": "of Apache spark that's been optimized by the team that originally created spark and data bricks is run on AWS since its",
    "start": "671810",
    "end": "678590"
  },
  {
    "text": "inception so what you see on this slide is a subset of many customers running data bricks on AWS and as you can see",
    "start": "678590",
    "end": "685610"
  },
  {
    "text": "they're in a lot of different industries and they have many different use cases many of these different industries are",
    "start": "685610",
    "end": "691730"
  },
  {
    "text": "using streaming analytics for things like streaming IOT where you want to be able to have devices stream back data in",
    "start": "691730",
    "end": "698570"
  },
  {
    "text": "some cases that can be used for a use case such as maintenance being able to you know to watch for when a an item",
    "start": "698570",
    "end": "705830"
  },
  {
    "text": "needs to be replaced and when it's starting to fail another example is intrusion detection",
    "start": "705830",
    "end": "711530"
  },
  {
    "text": "and security you know a lot of folks are using data bricks on AWS for being able",
    "start": "711530",
    "end": "716870"
  },
  {
    "text": "to determine different types of attacks that are coming in or or even physical events where people are intruding and so",
    "start": "716870",
    "end": "724790"
  },
  {
    "text": "you see a lot of different streaming examples there in those industries so",
    "start": "724790",
    "end": "731930"
  },
  {
    "start": "729000",
    "end": "729000"
  },
  {
    "text": "while everyone's excited about the capabilities of AI and machine learning you can't take advantage of great",
    "start": "731930",
    "end": "737180"
  },
  {
    "text": "analytics models unless you can get the data and spark was the first analytics engine that truly unified data and",
    "start": "737180",
    "end": "743540"
  },
  {
    "text": "analytics enabling data engineers perform ETL tasks and data scientists to",
    "start": "743540",
    "end": "748700"
  },
  {
    "text": "create analytic models to run on one engine and the data bricks unified",
    "start": "748700",
    "end": "755960"
  },
  {
    "start": "752000",
    "end": "752000"
  },
  {
    "text": "analytics platform increases the productivity of these teams by providing a collaborative workspace so data",
    "start": "755960",
    "end": "761870"
  },
  {
    "text": "engineers and data scientists and and business analysts can work together on notebooks iterating on data sets and",
    "start": "761870",
    "end": "768440"
  },
  {
    "text": "models to perfect them quickly you know when you think about how you do analytics and the people that are",
    "start": "768440",
    "end": "773600"
  },
  {
    "text": "involved and how much the question that you're trying to answer changes as you go through the process of working on a",
    "start": "773600",
    "end": "779660"
  },
  {
    "text": "particular problem you know where you find some data and then you find an answer and then suddenly you say hey we",
    "start": "779660",
    "end": "785090"
  },
  {
    "text": "need to get this other data set over here for more context you know we need to pivot our question a little bit and",
    "start": "785090",
    "end": "790820"
  },
  {
    "text": "you think about that process and how quickly you can do that if everybody's integrated in a single notebook where they can see",
    "start": "790820",
    "end": "797490"
  },
  {
    "text": "each other's work they can comment they can make changes you know real-time and then they could see results that's",
    "start": "797490",
    "end": "803760"
  },
  {
    "text": "really a huge part of the productivity that we see in the data science seems you know increasing by at least four to",
    "start": "803760",
    "end": "809100"
  },
  {
    "text": "five X so then with the click of the button you know you can take those notebooks and schedule them as job so",
    "start": "809100",
    "end": "815790"
  },
  {
    "text": "you're in able to immediately go into production with the same work and the",
    "start": "815790",
    "end": "820950"
  },
  {
    "text": "data bricks runtime is an optimized version of SPARC that increases performance and reduces total cost of",
    "start": "820950",
    "end": "826110"
  },
  {
    "text": "ownership data breaks serverless and auto scaling can add and shutdown clusters as needed so if you put in a",
    "start": "826110",
    "end": "832800"
  },
  {
    "text": "job and that job is gonna need to scale up significantly and then scale back down what it's done data bricks takes",
    "start": "832800",
    "end": "839070"
  },
  {
    "text": "care of that for you automatically so this allows data scientists and data engineers to focus on where they add the",
    "start": "839070",
    "end": "844650"
  },
  {
    "text": "most value you know by being able to focus on the problems that they're trying to solve",
    "start": "844650",
    "end": "849770"
  },
  {
    "text": "so all this integrates with AWS security and compliance allowing you to really reduce risk as well as part of this",
    "start": "849770",
    "end": "856020"
  },
  {
    "text": "process okay so let's talk a little bit",
    "start": "856020",
    "end": "864720"
  },
  {
    "text": "about streaming and and some of the process that goes on here in the data",
    "start": "864720",
    "end": "871020"
  },
  {
    "start": "866000",
    "end": "866000"
  },
  {
    "text": "breaks runtime you know we support the AWS Kinesis connector as a source to read streams from there's a number of",
    "start": "871020",
    "end": "877470"
  },
  {
    "text": "different processes that we have that allow you to take that data apart so even if your Kinesis records map to you",
    "start": "877470",
    "end": "885150"
  },
  {
    "text": "know an apache spark data frame with named columns and associated types you could select the desired payload from",
    "start": "885150",
    "end": "891030"
  },
  {
    "text": "the Kinesis record by accessing columns from the resulting data frame and employing the data frame api's so as one",
    "start": "891030",
    "end": "898110"
  },
  {
    "text": "example if you have a json encoded you know a set of data you can use the data frame api method as a cast to the json",
    "start": "898110",
    "end": "905190"
  },
  {
    "text": "data and deserialize your binary payload into a json string and then you can go ahead and take that string and run",
    "start": "905190",
    "end": "911460"
  },
  {
    "text": "different sequel utility functions so it helps to really know that that Kinesis",
    "start": "911460",
    "end": "916620"
  },
  {
    "text": "schema and then how it maps to the data frame and allows you to really stream that ETL stream that data in whether",
    "start": "916620",
    "end": "924150"
  },
  {
    "text": "your data is simple such as words or structuring complex such as nest J son and then just as important as",
    "start": "924150",
    "end": "930240"
  },
  {
    "text": "understanding the Kinesis record and it's schema is knowing the right configuration parameters and options to",
    "start": "930240",
    "end": "935370"
  },
  {
    "text": "supply in your Kinesis connector code so things like functions that we have including like the stream name the",
    "start": "935370",
    "end": "941610"
  },
  {
    "text": "initial physician the max record per fetch our you know things that you would commonly see that allow you to determine",
    "start": "941610",
    "end": "947249"
  },
  {
    "text": "exactly what strings or sections of the data you're trying to to get and so you",
    "start": "947249",
    "end": "952559"
  },
  {
    "text": "can find out more about this and how this works in this blog post bitly / DB Kinesis takes you through a little bit",
    "start": "952559",
    "end": "959759"
  },
  {
    "text": "more detail about exactly how data bricks works with streaming data so I",
    "start": "959759",
    "end": "970350"
  },
  {
    "start": "965000",
    "end": "965000"
  },
  {
    "text": "wanted to talk a little bit more before I close out about some of our customers in their use cases by a common",
    "start": "970350",
    "end": "976199"
  },
  {
    "text": "particularly R they're leveraging streaming data through the data bricks unified analytics platform and and they",
    "start": "976199",
    "end": "981930"
  },
  {
    "text": "needed to be able to optimize video streaming experience and so as they're streaming out video they're also getting",
    "start": "981930",
    "end": "988949"
  },
  {
    "text": "data back in a streaming method in terms of the experience the customers are having and quite often what would happen",
    "start": "988949",
    "end": "995910"
  },
  {
    "text": "is people would have problems where you know video was buffering or they weren't able to see the video or it would freeze",
    "start": "995910",
    "end": "1001459"
  },
  {
    "text": "up on the on the read-back device and so using data breaks they were able to start to understand things like",
    "start": "1001459",
    "end": "1007339"
  },
  {
    "text": "rerouting the data into different neo Center servers in order to get it to optimally to the customer and so they",
    "start": "1007339",
    "end": "1014600"
  },
  {
    "text": "were able to improve the quality of their service by 33% and they improve their customer retention by five to",
    "start": "1014600",
    "end": "1019879"
  },
  {
    "text": "seven X so we see data bricks used in many web and customer analytics use",
    "start": "1019879",
    "end": "1025490"
  },
  {
    "text": "cases as you see here on the slide with rule Allah they were able to reduce their ETL time by 60% and accelerate",
    "start": "1025490",
    "end": "1032959"
  },
  {
    "text": "their model training by 25 X you know so what we see over and over is improvements in how how much data can be",
    "start": "1032959",
    "end": "1040220"
  },
  {
    "text": "processed where organizations before using data bricks weren't able to process their entire data set in a",
    "start": "1040220",
    "end": "1046159"
  },
  {
    "text": "timely manner and suddenly now they can they can do that how much more productive the teams are because they",
    "start": "1046159",
    "end": "1052580"
  },
  {
    "text": "don't have to manage things like clusters and then how they're able to iterate faster in a collaborative",
    "start": "1052580",
    "end": "1058130"
  },
  {
    "text": "environment so they can accelerate innovation which is really the goal here so for",
    "start": "1058130",
    "end": "1063429"
  },
  {
    "text": "more information go to data bricks comm slash AWS and you can learn more about how data bricks runs on AWS and with",
    "start": "1063429",
    "end": "1071740"
  },
  {
    "text": "that I will pass it over to Mike some",
    "start": "1071740",
    "end": "1077080"
  },
  {
    "text": "excellent thanks Ryan and this is my query from M sequel I'm going to talk to",
    "start": "1077080",
    "end": "1082390"
  },
  {
    "text": "you today about the database platform for real-time analytics okay great just",
    "start": "1082390",
    "end": "1091120"
  },
  {
    "start": "1089000",
    "end": "1089000"
  },
  {
    "text": "a quick overview of mem sequel if you have not heard of us before we are a company that's focused on enabling any",
    "start": "1091120",
    "end": "1097539"
  },
  {
    "text": "company to become a real-time enterprise and part of that is our unique capability of essentially unifying a",
    "start": "1097539",
    "end": "1105250"
  },
  {
    "text": "database and data warehouse workloads into a single application or single",
    "start": "1105250",
    "end": "1110710"
  },
  {
    "text": "environment so we are a top-ranked database and data warehouse by Gartner",
    "start": "1110710",
    "end": "1115750"
  },
  {
    "text": "and so part of this is come through the experience of our founders they did meet",
    "start": "1115750",
    "end": "1121750"
  },
  {
    "text": "while at Facebook working on distributed data processing platforms they also spent some time at Microsoft on the",
    "start": "1121750",
    "end": "1129309"
  },
  {
    "text": "sequel server database and the result is what we have today is customers that really span the spectrum between being",
    "start": "1129309",
    "end": "1136779"
  },
  {
    "text": "digital or web native companies this is in Pandora uber Pinterest but also",
    "start": "1136779",
    "end": "1142779"
  },
  {
    "text": "larger enterprises that are going through a digital transformation initiative such as Comcast Kellogg these",
    "start": "1142779",
    "end": "1149950"
  },
  {
    "text": "are companies that are essentially using real-time for advantage so to get into",
    "start": "1149950",
    "end": "1156490"
  },
  {
    "start": "1154000",
    "end": "1154000"
  },
  {
    "text": "the structure and has in sort of the understanding as to why mem Siegel",
    "start": "1156490",
    "end": "1161820"
  },
  {
    "text": "delivers value to organizations we have to spend a little bit of time on some of the challenges that we commonly see the",
    "start": "1161820",
    "end": "1169330"
  },
  {
    "text": "first is that the slow query execution is typically one of the big pain points most database users experience so",
    "start": "1169330",
    "end": "1177789"
  },
  {
    "text": "whether the query response of their reports or dashboards are slow maybe they're not getting live data into their",
    "start": "1177789",
    "end": "1184419"
  },
  {
    "text": "views another challenge is the data loading process a lot of databases that",
    "start": "1184419",
    "end": "1190480"
  },
  {
    "text": "were designed 20 30 years ago where for batch loading or Det batch processing and so the ability to do sort",
    "start": "1190480",
    "end": "1198900"
  },
  {
    "text": "of real or continuous loading ultimately locks or slows down the performance of those environment and lastly we also see",
    "start": "1198900",
    "end": "1207330"
  },
  {
    "text": "a lot of concurrency limitations the reality is that as more applications are",
    "start": "1207330",
    "end": "1212580"
  },
  {
    "text": "driving data supporting data the number of users that need to connect to those databases is increasing and the result",
    "start": "1212580",
    "end": "1221220"
  },
  {
    "text": "of that is when you add more folks to your database you typically experience a slowdown or you have to throttle that",
    "start": "1221220",
    "end": "1228840"
  },
  {
    "text": "environment so these are sort of the three core sort of challenges that we see a lot of customers facing and so",
    "start": "1228840",
    "end": "1236340"
  },
  {
    "start": "1233000",
    "end": "1233000"
  },
  {
    "text": "what the what we have designed what we're focused on here at mem sequel is the ability to do these three things",
    "start": "1236340",
    "end": "1241799"
  },
  {
    "text": "really well and this is ultimately the sort of why organisations look to mem sequel for their data management",
    "start": "1241799",
    "end": "1248100"
  },
  {
    "text": "problems the first is the live loading so the fact that you can be able to",
    "start": "1248100",
    "end": "1253200"
  },
  {
    "text": "stream data into a relational database and at the core memc quo is a relational",
    "start": "1253200",
    "end": "1259650"
  },
  {
    "text": "sequel driven database and so the ability to do live loading of your data",
    "start": "1259650",
    "end": "1264840"
  },
  {
    "text": "without impacting performance of existing queries existing user access etc gives you that ultimate view of data",
    "start": "1264840",
    "end": "1273360"
  },
  {
    "text": "that's happening throughout the day this also gives the ability to do on-the-fly",
    "start": "1273360",
    "end": "1279750"
  },
  {
    "text": "transformations because we support and are optimized in memory as well as",
    "start": "1279750",
    "end": "1284850"
  },
  {
    "text": "optimized for disk we have this unique capability of doing live transformation",
    "start": "1284850",
    "end": "1289860"
  },
  {
    "text": "of your data as it lands into the system and that's one of the key advantages of",
    "start": "1289860",
    "end": "1295530"
  },
  {
    "text": "our platform the other attribute is that scalability is a big part of distributed",
    "start": "1295530",
    "end": "1302730"
  },
  {
    "text": "systems and that's something that mem sequel supports natively so we are a scale out distributed platform the",
    "start": "1302730",
    "end": "1309540"
  },
  {
    "text": "result of that is the ability to support a number of concurrent users or current",
    "start": "1309540",
    "end": "1314790"
  },
  {
    "text": "applications that need access to this data so scalability distributed processing all powered by sequel is",
    "start": "1314790",
    "end": "1321720"
  },
  {
    "text": "something that is uniquely a characteristic of M sequel",
    "start": "1321720",
    "end": "1326820"
  },
  {
    "text": "lastly also the ability to handle transactions so the in many real-time workloads we see the need to do updates",
    "start": "1326820",
    "end": "1333659"
  },
  {
    "text": "you know deduplication of data transactions of the data in real time",
    "start": "1333659",
    "end": "1339269"
  },
  {
    "text": "but then also concurrently do queries do analytic lookups group eyes etc of the",
    "start": "1339269",
    "end": "1346500"
  },
  {
    "text": "data as it's landing in the system so it's the combination of these two workloads in a single scalable system",
    "start": "1346500",
    "end": "1354120"
  },
  {
    "text": "that gives em sequel it's key advantage and lastly performance the fact that you",
    "start": "1354120",
    "end": "1360570"
  },
  {
    "text": "want to get your queries your results as quickly as possible scalable sequel is possible in this new",
    "start": "1360570",
    "end": "1367350"
  },
  {
    "text": "sort of architecture so that can deliver to you a real-time experience whether it's dashboards reports etc just a",
    "start": "1367350",
    "end": "1376500"
  },
  {
    "start": "1374000",
    "end": "1374000"
  },
  {
    "text": "couple of our customers in terms of this skill that they're seeing with mem sequel Kellogg saw a 20x faster ETL",
    "start": "1376500",
    "end": "1382710"
  },
  {
    "text": "processing improvement by essentially eliminating the ETL process entirely and",
    "start": "1382710",
    "end": "1388620"
  },
  {
    "text": "moving all of the data into our in memory engine and doing transformations there before landing it on to their disk",
    "start": "1388620",
    "end": "1394980"
  },
  {
    "text": "based architecture Pinterest ingesting a lot of data throughout the day for a/b",
    "start": "1394980",
    "end": "1400139"
  },
  {
    "text": "testing of their advertising campaigns and lastly Akamai doing a number of",
    "start": "1400139",
    "end": "1406490"
  },
  {
    "text": "updates insert six million per second this is for a billing application and",
    "start": "1406490",
    "end": "1413159"
  },
  {
    "text": "this allowed them to go from weekly billing into daily billing so I wanted",
    "start": "1413159",
    "end": "1419580"
  },
  {
    "start": "1417000",
    "end": "1417000"
  },
  {
    "text": "to quickly outline a traditional approach that we see a lot of customers embarking and I noticed that many of you",
    "start": "1419580",
    "end": "1426990"
  },
  {
    "text": "are in the planning phase of your real-time projects or real-time analytics projects it typically has this",
    "start": "1426990",
    "end": "1433769"
  },
  {
    "text": "flow where you have your data sources your events landing into a transactional system whether it's a Arora or or Oracle",
    "start": "1433769",
    "end": "1442080"
  },
  {
    "text": "or sequel server in some cases that data that is then pulled or a parallel loaded",
    "start": "1442080",
    "end": "1447870"
  },
  {
    "text": "into a spark or Kafka or Kinesis environment where you can transform and",
    "start": "1447870",
    "end": "1453659"
  },
  {
    "text": "then load that data again into different data stores whether these are data Mart's whether",
    "start": "1453659",
    "end": "1459140"
  },
  {
    "text": "this is a replicated data or operational data store or even a data Lake and then",
    "start": "1459140",
    "end": "1465200"
  },
  {
    "text": "from here is where you get your analytic view with your bi tool of choice what we",
    "start": "1465200",
    "end": "1471530"
  },
  {
    "text": "see typically is in terms of two areas of challenges is that the loading of the data from the message queue into a",
    "start": "1471530",
    "end": "1478760"
  },
  {
    "text": "database is batched and/or slow and therefore we see a number of data mark",
    "start": "1478760",
    "end": "1484370"
  },
  {
    "text": "Pullip proliferations or data store proliferations to avoid some of these bottlenecks and that creates cost",
    "start": "1484370",
    "end": "1491020"
  },
  {
    "text": "complexity challenges in terms of replicating data throughout your organization the other challenges that",
    "start": "1491020",
    "end": "1498320"
  },
  {
    "text": "we see when you access and want to do queries of your data those query results are slow they take",
    "start": "1498320",
    "end": "1503990"
  },
  {
    "text": "there's bottlenecks because the environment may be getting updated continuously and/or the fact that you",
    "start": "1503990",
    "end": "1509750"
  },
  {
    "text": "have multiple users that want to have access to these systems and they're running into concurrency issues and so",
    "start": "1509750",
    "end": "1515810"
  },
  {
    "start": "1515000",
    "end": "1515000"
  },
  {
    "text": "what we see now is a more streamlined architecture the more modern approach to real-time analytics and that is using",
    "start": "1515810",
    "end": "1523780"
  },
  {
    "text": "the combination of Kinesis and or data bricks park or Kafka loading that data",
    "start": "1523780",
    "end": "1531380"
  },
  {
    "text": "into MEMC kwill and then consolidating your data stores into one scalable system so one relational environment",
    "start": "1531380",
    "end": "1538550"
  },
  {
    "text": "that can manage all of your end-user needs as well as provide that transactional consistency at durability",
    "start": "1538550",
    "end": "1546230"
  },
  {
    "text": "and then ultimately the query performance that you want for your end-users so this is where we see",
    "start": "1546230",
    "end": "1552370"
  },
  {
    "text": "scalable sequel providing the ultimate benefit of simplification consolidation",
    "start": "1552370",
    "end": "1558410"
  },
  {
    "text": "of your data stores when you have a scale out architecture you can ultimately support them different",
    "start": "1558410",
    "end": "1564530"
  },
  {
    "text": "workloads that may be required across data science data analysts and/or other",
    "start": "1564530",
    "end": "1570170"
  },
  {
    "text": "applications so this is the ultimate benefit in a scalable environment and then lastly our",
    "start": "1570170",
    "end": "1576340"
  },
  {
    "text": "high-performance queries the fact that we can deliver because we have a column",
    "start": "1576340",
    "end": "1582020"
  },
  {
    "text": "store engine that's inside of my sequel that gives you really fast analytic results so we can query we just showcase",
    "start": "1582020",
    "end": "1589550"
  },
  {
    "text": "our benchmark of scanning a trillion rows data per second and so we're very very",
    "start": "1589550",
    "end": "1596149"
  },
  {
    "text": "proud to showcase the power of M sequel through our analytic performance I also",
    "start": "1596149",
    "end": "1602509"
  },
  {
    "text": "want to just finalize by highlighting one of our customers and emphasis with their taking advantage of mem sequel",
    "start": "1602509",
    "end": "1609619"
  },
  {
    "text": "Amazon AWS to deliver a managed scalable",
    "start": "1609619",
    "end": "1614779"
  },
  {
    "text": "IOT analytic solution and in this case they're helping agriculture customers optimize their costs and improve crop",
    "start": "1614779",
    "end": "1621950"
  },
  {
    "start": "1621000",
    "end": "1621000"
  },
  {
    "text": "production and so the reason why they chose Memphis equal and Amazon was to deliver fast IOT analytics with a price",
    "start": "1621950",
    "end": "1630080"
  },
  {
    "text": "performance requirement of mind so they didn't want to see proliferation of data stores and they really wanted to",
    "start": "1630080",
    "end": "1636049"
  },
  {
    "text": "optimize cost they wanted to also maintain their expertise in their sequel",
    "start": "1636049",
    "end": "1643749"
  },
  {
    "text": "expertise as well as the my sequel interoperability we do support the my",
    "start": "1643749",
    "end": "1649070"
  },
  {
    "text": "sequel wire protocol so for those applications that are written to my sequel we can seamlessly work with those",
    "start": "1649070",
    "end": "1655940"
  },
  {
    "text": "applications they also wanted reliability so the fact that they have changing workloads and changing sort of",
    "start": "1655940",
    "end": "1664729"
  },
  {
    "text": "performance characteristics and they needed a platform that could scant span two different sets of workloads and that",
    "start": "1664729",
    "end": "1672139"
  },
  {
    "text": "was something they could get with their distributed platform of M sequel as well as AWS and lastly they needed rich",
    "start": "1672139",
    "end": "1678440"
  },
  {
    "text": "sequel they needed the analytics that their end users needed and that is",
    "start": "1678440",
    "end": "1684309"
  },
  {
    "text": "relational sequel is always the best way to get the best type of analytics from your data and some of the technical",
    "start": "1684309",
    "end": "1691399"
  },
  {
    "start": "1689000",
    "end": "1689000"
  },
  {
    "text": "benefits just to summarize is that they were able to see ingestion rates that met or exceeded many of these sort of no",
    "start": "1691399",
    "end": "1698869"
  },
  {
    "text": "sequel environments are very popular for their high ingestion high transactionality performance they saw",
    "start": "1698869",
    "end": "1705859"
  },
  {
    "text": "10x query performance improvements over competing solutions so again that analytic performance is just as strong",
    "start": "1705859",
    "end": "1713119"
  },
  {
    "text": "as our update performance and then the data compression was something that they really appreciated because of the volume",
    "start": "1713119",
    "end": "1719479"
  },
  {
    "text": "of data that they were storing so we stuck they saw data compression through our column store engine being very",
    "start": "1719479",
    "end": "1725690"
  },
  {
    "text": "efficient and then the transactional consistency they needed accurate data some of this",
    "start": "1725690",
    "end": "1731750"
  },
  {
    "text": "being financial related data very important to have transactional consistency of your data store and",
    "start": "1731750",
    "end": "1738860"
  },
  {
    "text": "lastly because this was running on Amazon's platform they were able to see the scale",
    "start": "1738860",
    "end": "1744560"
  },
  {
    "text": "out provisioning that they needed to adopt to the changing again conditions",
    "start": "1744560",
    "end": "1750020"
  },
  {
    "text": "of their customers so the ability to quickly and rapidly scale up and down their environment that made this",
    "start": "1750020",
    "end": "1756110"
  },
  {
    "text": "solution a great set so hopefully that gives you all a good overview if you've got any questions by all means submit",
    "start": "1756110",
    "end": "1763190"
  },
  {
    "text": "them into the chat box and I will now hand it off to Sam is going to give you all a quick run-through of zoom data",
    "start": "1763190",
    "end": "1770860"
  },
  {
    "text": "well thank you very much my name is Sam gainer I run strategic accounts",
    "start": "1770860",
    "end": "1776540"
  },
  {
    "text": "technology for zoom data so what I've done for you today is to build a",
    "start": "1776540",
    "end": "1782920"
  },
  {
    "text": "demonstration using some of the technologies in our in our partner ecosystem obviously the Amazon Kinesis",
    "start": "1782920",
    "end": "1790730"
  },
  {
    "start": "1783000",
    "end": "1783000"
  },
  {
    "text": "streaming framework as well as mem sequel and what zoom data allows for you to do is from a visualization standpoint",
    "start": "1790730",
    "end": "1798290"
  },
  {
    "text": "be able to see and take action on the data that is in motion right being able",
    "start": "1798290",
    "end": "1803930"
  },
  {
    "text": "to take a look at not only the data that's coming in but look at historical data be able to act and then move",
    "start": "1803930",
    "end": "1811670"
  },
  {
    "text": "forward on that and then to be able to share those insights with other people so once again the the demonstration that",
    "start": "1811670",
    "end": "1817430"
  },
  {
    "text": "I'm going to show you today is built using an Amazon Kinesis pipeline with",
    "start": "1817430",
    "end": "1822620"
  },
  {
    "text": "synthetic ecommerce data the data is going to be streaming in through zoom data server running and landing in mem",
    "start": "1822620",
    "end": "1830030"
  },
  {
    "text": "sequel which is as you know a high-performance read and writes store and then it's going to be showing in",
    "start": "1830030",
    "end": "1835340"
  },
  {
    "text": "zoom data in an interactive environment so I'm gonna go ahead without further ado and jump into that demo all right",
    "start": "1835340",
    "end": "1843710"
  },
  {
    "text": "you should all be able to see my screen now so what you see is a zoom data",
    "start": "1843710",
    "end": "1850310"
  },
  {
    "text": "dashboard showing a hypothetical environment of bringing in synthetic",
    "start": "1850310",
    "end": "1857060"
  },
  {
    "text": "transactions from an e-commerce store you can imagine am I I'm calm or Ebay or a Shopify or",
    "start": "1857060",
    "end": "1863509"
  },
  {
    "text": "something like that and the idea here is that you have data that's coming in live",
    "start": "1863509",
    "end": "1869529"
  },
  {
    "text": "and you're able to see real insights as soon as they as soon as they hit the",
    "start": "1869529",
    "end": "1874850"
  },
  {
    "text": "system this is obviously a much different approach than your batch approach to looking at analytics on your",
    "start": "1874850",
    "end": "1881360"
  },
  {
    "text": "data you don't have to wait a week to get your historical trends what happened",
    "start": "1881360",
    "end": "1887119"
  },
  {
    "text": "in the in the store and wait a week for that type of insight you don't have to wait on your analysts to turn through",
    "start": "1887119",
    "end": "1893659"
  },
  {
    "text": "the the information that's coming in for you to be able to make decisions and so zoom data allows you to see these",
    "start": "1893659",
    "end": "1900019"
  },
  {
    "text": "real-time streaming pipelines in real time and it also allows you to work on",
    "start": "1900019",
    "end": "1905629"
  },
  {
    "text": "billions and billions of records of data as well today the focus is real-time but there's also this this capability and",
    "start": "1905629",
    "end": "1912019"
  },
  {
    "text": "zoom date and work on billions of Records upwards of ten to a hundred billion records now the idea here is",
    "start": "1912019",
    "end": "1918169"
  },
  {
    "text": "that zoom data is displaying what's happening in the underlying data store and you can see that there's a time bar",
    "start": "1918169",
    "end": "1924889"
  },
  {
    "text": "at the bottom that shows us exactly what's happening you'll see that the the data is coming in alive and that the",
    "start": "1924889",
    "end": "1932210"
  },
  {
    "text": "chart is the charts are updating simultaneously with all of that now the",
    "start": "1932210",
    "end": "1937759"
  },
  {
    "text": "idea is that I might want to be able to not only look at live data but I might want to be able to to pause this this",
    "start": "1937759",
    "end": "1946039"
  },
  {
    "text": "input and be able to rewind the the playback and be able to see exactly",
    "start": "1946039",
    "end": "1953720"
  },
  {
    "text": "what's happening on my data as well now you'll see that",
    "start": "1953720",
    "end": "1959320"
  },
  {
    "text": "you'll see that you have the ability to not only play the data that's coming in",
    "start": "1963690",
    "end": "1968789"
  },
  {
    "text": "live but you also have this ability to rewind and play back the data as it happened so it much like you would take",
    "start": "1968789",
    "end": "1975539"
  },
  {
    "text": "a DVR at home record your favorite NFL football game or college basketball game",
    "start": "1975539",
    "end": "1981299"
  },
  {
    "text": "or reality TV show you're able to rewind the data there rewind the playback and",
    "start": "1981299",
    "end": "1988080"
  },
  {
    "text": "and make that appear live once again so if you think about the ability to work",
    "start": "1988080",
    "end": "1994620"
  },
  {
    "text": "in a network operation center or in a bank and be able to not only take a look at what's happening live but be able to",
    "start": "1994620",
    "end": "2001070"
  },
  {
    "text": "go back historically and see what happened over a previous time period that capability also happens and is",
    "start": "2001070",
    "end": "2007519"
  },
  {
    "text": "available with zoom data now zoom data's not only focused on showing you what's",
    "start": "2007519",
    "end": "2013450"
  },
  {
    "text": "right in front of you on the dashboard but also allowing for you to be able to interact in multiple different ways so",
    "start": "2013450",
    "end": "2020360"
  },
  {
    "text": "for example let's say I want to dive deep into this data I see that the science category is selling a lot what I",
    "start": "2020360",
    "end": "2027559"
  },
  {
    "text": "can do is that I can click on on any given point on the on the visualization and I can either zoom down into the data",
    "start": "2027559",
    "end": "2034909"
  },
  {
    "text": "I can look at the individual aggregate details I can look at a trend and I can",
    "start": "2034909",
    "end": "2040009"
  },
  {
    "text": "do this either on historical data or live data once again millions of historical records or real-time data",
    "start": "2040009",
    "end": "2045740"
  },
  {
    "text": "flowing through a Kinesis pipeline in mmm sequel and so what I'll do is I'll pause this let's say I want to look at",
    "start": "2045740",
    "end": "2051740"
  },
  {
    "text": "the science data as it exists between the two times on the time-bar I can go",
    "start": "2051740",
    "end": "2057319"
  },
  {
    "text": "ahead and click on the zoom button say ok I want to drill down and look at for example the skews being sold in the",
    "start": "2057319",
    "end": "2063108"
  },
  {
    "text": "science category and then I could see those individual skews then I can for",
    "start": "2063109",
    "end": "2068300"
  },
  {
    "text": "example highlight that's the specific set of skews and drill down even further and take a look at the zip codes where",
    "start": "2068300",
    "end": "2074450"
  },
  {
    "text": "they're being sold right all of this on data that I've literally pause that was streaming two seconds ago right the",
    "start": "2074450",
    "end": "2081648"
  },
  {
    "text": "power here to be able to make decisions from this this insight is is is is is",
    "start": "2081649",
    "end": "2089138"
  },
  {
    "text": "unbelievable and so then I can get down to really any any record and look it",
    "start": "2089139",
    "end": "2094520"
  },
  {
    "text": "down at the individual record so what I've done is I've gone from a streaming set of data been able",
    "start": "2094520",
    "end": "2100249"
  },
  {
    "text": "to rewind to play it back but then also been able to pause it and look at the data at a time period and then isolate",
    "start": "2100249",
    "end": "2106940"
  },
  {
    "text": "the records that are creating a trend for me and so this ends up being a very powerful set of functionality now as I",
    "start": "2106940",
    "end": "2114289"
  },
  {
    "text": "said this is not just for real-time streaming data it's also for for",
    "start": "2114289",
    "end": "2119329"
  },
  {
    "text": "historical data and and many different big data types of sources but that is",
    "start": "2119329",
    "end": "2125809"
  },
  {
    "text": "what I wanted to quickly highlight in my demonstration today so to wrap up on on",
    "start": "2125809",
    "end": "2130849"
  },
  {
    "text": "zoom data so zoom data is a modern bi toolset specifically focused on modern data we",
    "start": "2130849",
    "end": "2137239"
  },
  {
    "start": "2132000",
    "end": "2132000"
  },
  {
    "text": "are optimized as I said for for big data for streaming and for search sources and",
    "start": "2137239",
    "end": "2142730"
  },
  {
    "text": "we can join lots of different data sources together across across different",
    "start": "2142730",
    "end": "2148190"
  },
  {
    "text": "data warehouses we allow you to work at the speed of thought and allow you to do",
    "start": "2148190",
    "end": "2153859"
  },
  {
    "text": "interactive analysis on huge data volumes and we don't require you to move the data out of the underlying data",
    "start": "2153859",
    "end": "2159950"
  },
  {
    "text": "store that's actually something I didn't mention the idea that is that you don't want to batch move data from system to",
    "start": "2159950",
    "end": "2165859"
  },
  {
    "text": "system and we talked about that earlier today but zoom data connects to the data where it lies leaves it there and then",
    "start": "2165859",
    "end": "2171799"
  },
  {
    "text": "provides it back into the interface without ever doing any replication so",
    "start": "2171799",
    "end": "2176930"
  },
  {
    "text": "that allows you to scale your your infrastructure underneath the visualization layer without ever having",
    "start": "2176930",
    "end": "2182269"
  },
  {
    "text": "to do duplicate scaling in the in the visualization layer like you were having",
    "start": "2182269",
    "end": "2187279"
  },
  {
    "text": "to do previously in bi we are a micro service we run on the from on-premise or",
    "start": "2187279",
    "end": "2192739"
  },
  {
    "text": "in the cloud or in hybrid environments and we're very very easy who were very easy to embed as well as to extend into",
    "start": "2192739",
    "end": "2199130"
  },
  {
    "text": "other environments so with that I'm going to pass that back to our to our moderators to go ahead and take",
    "start": "2199130",
    "end": "2205309"
  },
  {
    "text": "questions great thank you every for each of the partners the presenters very very informative thanks",
    "start": "2205309",
    "end": "2213230"
  },
  {
    "start": "2208000",
    "end": "2208000"
  },
  {
    "text": "Sam especially for braving a live demo I know those things can be pretty difficult so we're now going to",
    "start": "2213230",
    "end": "2218839"
  },
  {
    "text": "transition into our live Q&A as a reminder you'll be able to submit any written questions through the questions",
    "start": "2218839",
    "end": "2224210"
  },
  {
    "text": "panel in the event that we are not able to answer your questions today we will follow up with everyone individually the",
    "start": "2224210",
    "end": "2231060"
  },
  {
    "text": "so with fact there's a lot of questions that I try to answer while we're going",
    "start": "2231060",
    "end": "2236980"
  },
  {
    "text": "through the while the other partners were speaking one of the things that I",
    "start": "2236980",
    "end": "2243790"
  },
  {
    "text": "want to elaborate on is I would love for",
    "start": "2243790",
    "end": "2249150"
  },
  {
    "text": "data breaks Brian today tricks to speak about integrating spark or spark",
    "start": "2249660",
    "end": "2255550"
  },
  {
    "text": "streaming with Kinesis and or Kafka and what that looks like on the data breaks platform sounds like Ryan might have",
    "start": "2255550",
    "end": "2262120"
  },
  {
    "text": "some difficulty so we'll move on to another question there this one's good",
    "start": "2262120",
    "end": "2267130"
  },
  {
    "text": "for Mike so Mike one question came in is any historical data stored in zoom data",
    "start": "2267130",
    "end": "2274000"
  },
  {
    "text": "or is this just the visualization tool that third-party store and I basically it's good for Sam that Mike I'm sorry",
    "start": "2274000",
    "end": "2282490"
  },
  {
    "text": "can you repeat the question and we're time sure thing any historical data stored in zoom data or is it just a",
    "start": "2282490",
    "end": "2288850"
  },
  {
    "text": "visualization tool connected to a third-party data store yeah so it's a great question and thank you for that",
    "start": "2288850",
    "end": "2295240"
  },
  {
    "text": "the answer is that the that data is not stored in zoom data we don't do any data movement and so historical data is",
    "start": "2295240",
    "end": "2302530"
  },
  {
    "text": "stored in an infrastructure that is meant to store lots of data whether it's",
    "start": "2302530",
    "end": "2307750"
  },
  {
    "text": "a dupe or mem sequel or something of that nature and so by leveraging the power of those you end up being able to",
    "start": "2307750",
    "end": "2314860"
  },
  {
    "text": "have a much lighter UI framework what I would caution you with is that many",
    "start": "2314860",
    "end": "2320230"
  },
  {
    "text": "different tool sets do that say that they're able to connect and work with these next-generation data stores and",
    "start": "2320230",
    "end": "2326260"
  },
  {
    "text": "they're not optimized to work with these next variations stores so they might have a JDBC connector that issues",
    "start": "2326260",
    "end": "2332620"
  },
  {
    "text": "standard sequel to those underlying data stores and that's not the way that those data stores were meant to be queried so",
    "start": "2332620",
    "end": "2338440"
  },
  {
    "text": "zoom data what we did was we built up queries or built up connectors from the",
    "start": "2338440",
    "end": "2344200"
  },
  {
    "text": "ground up and really made sure that everything that we connect to is optimized in a way that most tool sets",
    "start": "2344200",
    "end": "2351490"
  },
  {
    "text": "don't don't take advantage of thank you for the question and here's another good follow-up question for you Sam so how",
    "start": "2351490",
    "end": "2358660"
  },
  {
    "text": "would you use in your words a zoom data different from tableau yes what I would say is",
    "start": "2358660",
    "end": "2364130"
  },
  {
    "text": "a lot of architectural differences as well as UI differences probably too many to go into today what we see is that we",
    "start": "2364130",
    "end": "2372350"
  },
  {
    "text": "succeed where other BI tools fail so very frequently what we're we're we're",
    "start": "2372350",
    "end": "2377390"
  },
  {
    "text": "coming in is that a an organization has tried and tried with tableau to get",
    "start": "2377390",
    "end": "2382520"
  },
  {
    "text": "performance to get scalability and it's just not worked this happens in many",
    "start": "2382520",
    "end": "2387560"
  },
  {
    "text": "banks that happens in the federal government helps it happens in health quick care and we just repeatedly hear",
    "start": "2387560",
    "end": "2392860"
  },
  {
    "text": "you know we can't make tableau scale and the way that we want and that's both from a from an architectural standpoint",
    "start": "2392860",
    "end": "2398750"
  },
  {
    "text": "from a UI perspective but also from a pricing standpoint so I'm happy to have",
    "start": "2398750",
    "end": "2404150"
  },
  {
    "text": "a deeper conversation with the question need the question that person asking the",
    "start": "2404150",
    "end": "2410210"
  },
  {
    "text": "question and I encourage that person to reach out to me good thanks n so here's your question",
    "start": "2410210",
    "end": "2415820"
  },
  {
    "text": "for microphones people so what is the data storage is it using them Siebel or",
    "start": "2415820",
    "end": "2421520"
  },
  {
    "text": "AWS storage yeah so that it that's a",
    "start": "2421520",
    "end": "2426590"
  },
  {
    "text": "good question and it kind of depends on where the data flow is is processing so",
    "start": "2426590",
    "end": "2431930"
  },
  {
    "text": "ultimately the data can land and be stored on Amazon's s3 EBS etc mem sequel",
    "start": "2431930",
    "end": "2441890"
  },
  {
    "text": "when we're running our queries of the data when we are structuring the data we",
    "start": "2441890",
    "end": "2446990"
  },
  {
    "text": "recommend an EBS a storage environment that gives you the best performance and",
    "start": "2446990",
    "end": "2452540"
  },
  {
    "text": "that's something that we see our customers needing so it's a sort of dependency on where the performance",
    "start": "2452540",
    "end": "2459620"
  },
  {
    "text": "requirements are and what you're sort of looking for from an output to your application but then in terms of today's",
    "start": "2459620",
    "end": "2467450"
  },
  {
    "text": "discussion I think with mem sequel and the examples that I showcase those were BBS based stored data files perfect then",
    "start": "2467450",
    "end": "2478880"
  },
  {
    "text": "I guess boa pressured me to Mike do you have characters from in sequel to Kinesis C we do yeah we work with with",
    "start": "2478880",
    "end": "2487370"
  },
  {
    "text": "Kinesis streams and are able to we have a cus customer and Disney that's",
    "start": "2487370",
    "end": "2493400"
  },
  {
    "text": "showcased their application at strata San Jose recommend you know looking at that that",
    "start": "2493400",
    "end": "2501289"
  },
  {
    "text": "presentation where they're using Kinesis landing into mem sequel for managing",
    "start": "2501289",
    "end": "2507140"
  },
  {
    "text": "media delivery to their to their own customers I guess is a question for many",
    "start": "2507140",
    "end": "2512720"
  },
  {
    "text": "both Mike and Sam can you connect zoom data directly to date of bricks kinases",
    "start": "2512720",
    "end": "2517760"
  },
  {
    "text": "and or mem sequel and then you offer connections for redshift so this is Sam so yes to all of the above so we can",
    "start": "2517760",
    "end": "2526910"
  },
  {
    "text": "connect to or wide variety of data sources and that those list those connectors are listed on our on our web",
    "start": "2526910",
    "end": "2533539"
  },
  {
    "text": "page at zoom datacom if you want to discuss that further and happy to happy",
    "start": "2533539",
    "end": "2538910"
  },
  {
    "text": "to take that offline yeah I'm from the mem sequel side we can ingest data from a variety of sources as well in terms of",
    "start": "2538910",
    "end": "2545720"
  },
  {
    "text": "live loading you know we we recommend a whether it's a data brick whether it's",
    "start": "2545720",
    "end": "2551359"
  },
  {
    "text": "Kafka whether it's Kinesis and then in terms of further sort of loading into",
    "start": "2551359",
    "end": "2556519"
  },
  {
    "text": "other environments for other applications and requirements we can also support you know loading of data",
    "start": "2556519",
    "end": "2563690"
  },
  {
    "text": "for from redshift environments but you know at the end of the day we're we're a",
    "start": "2563690",
    "end": "2569180"
  },
  {
    "text": "JDBC ODBC compliant interface that can load data from a variety of sources we",
    "start": "2569180",
    "end": "2576410"
  },
  {
    "text": "have more questions coming in soon we have a nice general question of how how",
    "start": "2576410",
    "end": "2582769"
  },
  {
    "text": "80 bits and partners work together I think this is a good opportunity for maybe Egypt mikan-san to kind of",
    "start": "2582769",
    "end": "2588109"
  },
  {
    "text": "summarize how you guys partner well with AWS and kind of process works yeah so",
    "start": "2588109",
    "end": "2593869"
  },
  {
    "text": "I'll start here this is on the mem sequel side so we you know roughly 30 to",
    "start": "2593869",
    "end": "2599690"
  },
  {
    "text": "40 percent of our customers today run on an AWS environment many of those",
    "start": "2599690",
    "end": "2605000"
  },
  {
    "text": "customers are taking advantage of ec2 instances taking advantage of the the",
    "start": "2605000",
    "end": "2610130"
  },
  {
    "text": "various managed service components from there we also have a marketplace version",
    "start": "2610130",
    "end": "2618799"
  },
  {
    "text": "of our product we we recommend downloading our product from our from our website at MC cool calm slash",
    "start": "2618799",
    "end": "2624859"
  },
  {
    "text": "download we have a 30-day trial there and that can be we have some QuickStart",
    "start": "2624859",
    "end": "2629930"
  },
  {
    "text": "that can help you deploy mence equal to AWS environments and this",
    "start": "2629930",
    "end": "2637100"
  },
  {
    "text": "is all in an effort to just streamline and accelerate the provisioning and use",
    "start": "2637100",
    "end": "2642350"
  },
  {
    "text": "of mem sequel on the EWS platform and then again we have pretty proven",
    "start": "2642350",
    "end": "2649160"
  },
  {
    "text": "technology and that we've been battle tested with a number of significant customers that take advantage of the AWS",
    "start": "2649160",
    "end": "2656210"
  },
  {
    "text": "platform and this is same from zoom data we are able to deploy in an AWS native",
    "start": "2656210",
    "end": "2665540"
  },
  {
    "text": "environment and we connect to a wide variety of the different data sources that are built for AWS so we have a",
    "start": "2665540",
    "end": "2676400"
  },
  {
    "text": "number of customers who are using zoom data up when they open the cloud and we",
    "start": "2676400",
    "end": "2681730"
  },
  {
    "text": "have a lot of success in that environment another couple questions about more",
    "start": "2681730",
    "end": "2689510"
  },
  {
    "text": "connectors so can do be a connect directly to dynamo DB or doesn.t they",
    "start": "2689510",
    "end": "2694790"
  },
  {
    "text": "have to move B moves through something like s3 yes it's a great question it",
    "start": "2694790",
    "end": "2701420"
  },
  {
    "text": "kind of gets to a little bit more of the the technical architecture behind zoom data and the way that zoom data works is",
    "start": "2701420",
    "end": "2708080"
  },
  {
    "text": "that it issues specialized sequel to the underlying data store and so we require",
    "start": "2708080",
    "end": "2714590"
  },
  {
    "text": "a data store that handles or can can process that type of sequel query and",
    "start": "2714590",
    "end": "2722710"
  },
  {
    "text": "and there are some extra mechanisms to redirect in that sequel query that we",
    "start": "2722710",
    "end": "2728480"
  },
  {
    "text": "issue into a data source specific language what we found with connecting",
    "start": "2728480",
    "end": "2734120"
  },
  {
    "text": "directly to dynamodb is that it doesn't support those direct queries so we've usually integrated into something that",
    "start": "2734120",
    "end": "2740690"
  },
  {
    "text": "does have a query engine whether it be presto on have s3 or or redshift on top",
    "start": "2740690",
    "end": "2748850"
  },
  {
    "text": "of s3 or something of that nature you know on top of that with regards to",
    "start": "2748850",
    "end": "2755860"
  },
  {
    "text": "connecting directly to s3 or or storage",
    "start": "2755860",
    "end": "2761840"
  },
  {
    "text": "at rest the the problem with with that approach",
    "start": "2761840",
    "end": "2767050"
  },
  {
    "text": "really tends to be that it goes again zoom data's core operating concept which",
    "start": "2767050",
    "end": "2772330"
  },
  {
    "text": "is to leave the data in place now if you think about trying to achieve performance on data that's stored in a a",
    "start": "2772330",
    "end": "2780160"
  },
  {
    "text": "non structured way like it is in s3 for example then you have to figure out how",
    "start": "2780160",
    "end": "2785410"
  },
  {
    "text": "to get performance somewhere so by connecting directly to s3 the only way to do that would be to ingest that in",
    "start": "2785410",
    "end": "2791650"
  },
  {
    "text": "the zoom data and and suck all the data in which goes against our core our core",
    "start": "2791650",
    "end": "2797050"
  },
  {
    "text": "kind of core belief that we shouldn't move the data and in a case like that",
    "start": "2797050",
    "end": "2802210"
  },
  {
    "text": "you might use something like Athena which is able to do high performance",
    "start": "2802210",
    "end": "2807850"
  },
  {
    "text": "scans of s3 and then provide us the data that we need so we do have some models",
    "start": "2807850",
    "end": "2813340"
  },
  {
    "text": "for connecting directly to dynamo we do have a model to connect directly to s3",
    "start": "2813340",
    "end": "2819270"
  },
  {
    "text": "but we have some some interesting ways to scale and be even more performant and",
    "start": "2819270",
    "end": "2824410"
  },
  {
    "text": "and once again deeper technical conversation probably would follow and I'm happy to have that offline with the",
    "start": "2824410",
    "end": "2829900"
  },
  {
    "text": "question asker I guess yeah a good follow-up question that is do you have",
    "start": "2829900",
    "end": "2835180"
  },
  {
    "text": "connections directly to cop that would keep equal yes that's something we're efforting at the moment you know the",
    "start": "2835180",
    "end": "2841560"
  },
  {
    "text": "question obviously becomes whether you keep Kafka as a as a data storage layer",
    "start": "2841560",
    "end": "2846790"
  },
  {
    "text": "or if it is in fact just a pipe right what we've always thought of Kafka's as",
    "start": "2846790",
    "end": "2852790"
  },
  {
    "text": "being is more of a pipe and you know this case equal part of their technology",
    "start": "2852790",
    "end": "2858900"
  },
  {
    "text": "really does give more credence to the fact that this might be moving towards the storage layer what I would say about",
    "start": "2858900",
    "end": "2866460"
  },
  {
    "text": "connecting to the pipe is that you obviously don't want to drink from a",
    "start": "2866460",
    "end": "2872200"
  },
  {
    "text": "fire hose right so zoom data is a UI tool and we we tend to try to focus",
    "start": "2872200",
    "end": "2878640"
  },
  {
    "text": "specifically on on working with manageable chunks of data the real time",
    "start": "2878640",
    "end": "2884050"
  },
  {
    "text": "visualizations that I show you showed you operate off of a an architecture",
    "start": "2884050",
    "end": "2889480"
  },
  {
    "text": "that is specifically crafted to allow visualizations to occur on that real time stream so I guess the short answer",
    "start": "2889480",
    "end": "2896320"
  },
  {
    "text": "your question is yes we were working on some connectivity the case equal the second part to that is that",
    "start": "2896320",
    "end": "2901990"
  },
  {
    "text": "connecting directly to Kafka is not something that we tend to do we generally see it go through a streaming",
    "start": "2901990",
    "end": "2908019"
  },
  {
    "text": "pipeline or lambda type architecture and landed into something like mem sequel and then we connect to it",
    "start": "2908019",
    "end": "2914980"
  },
  {
    "text": "I think we have time for about one more question so Mike how does MEMS equal",
    "start": "2914980",
    "end": "2921849"
  },
  {
    "text": "binary other notes equal scores like dynamo or MongoDB yes sure the no sequel",
    "start": "2921849",
    "end": "2927339"
  },
  {
    "text": "and mmm sequel there's some some differences and then some similarities",
    "start": "2927339",
    "end": "2932740"
  },
  {
    "text": "so the similarities are that were both distributed so scale out architecture so",
    "start": "2932740",
    "end": "2939130"
  },
  {
    "text": "you can do a lot of parallel processing of data the main difference is that worst of relational structured",
    "start": "2939130",
    "end": "2945819"
  },
  {
    "text": "environment so a lot of customers will say well wait a minute I have JSON data and can you really put that into a",
    "start": "2945819",
    "end": "2952269"
  },
  {
    "text": "relational format and how does that work mmm sequel does support JSON as a data type so that's something that we can",
    "start": "2952269",
    "end": "2958450"
  },
  {
    "text": "very efficiently store the in a color in our column store environment and then you can do clever things around turning",
    "start": "2958450",
    "end": "2965410"
  },
  {
    "text": "that into a computed column for analytics the reason why structure and we release reason why relational is",
    "start": "2965410",
    "end": "2971769"
  },
  {
    "text": "great for many applications is that you can do real analytics some of the no sequel environments doing analytics",
    "start": "2971769",
    "end": "2978430"
  },
  {
    "text": "requires different layers and different sort of sequel like syntax and we are an",
    "start": "2978430",
    "end": "2985480"
  },
  {
    "text": "ANSI sequel database so we provide sort of the scalability and performance of an",
    "start": "2985480",
    "end": "2990609"
  },
  {
    "text": "ode sequel store but with the structure and analytics of a relational data store",
    "start": "2990609",
    "end": "2997569"
  },
  {
    "text": "so that's sort of the synopsis there great thanks mate so I think that's all the time we have",
    "start": "2997569",
    "end": "3003329"
  },
  {
    "text": "today so again anyone that didn't have their questions answered live we will be able to answer your email really big",
    "start": "3003329",
    "end": "3010410"
  },
  {
    "text": "thank you to all of our speakers for taking the time out today thanks everyone",
    "start": "3010410",
    "end": "3015859"
  }
]
[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "hello everyone I'm Lee pang a genomic",
    "start": "30",
    "end": "2879"
  },
  {
    "text": "specialist with Amazon Web Services hey",
    "start": "2879",
    "end": "5279"
  },
  {
    "text": "everybody I'm Ruchi moonshee a product",
    "start": "5279",
    "end": "8099"
  },
  {
    "text": "manager over at the Byrd Institute and",
    "start": "8099",
    "end": "10080"
  },
  {
    "text": "in this video we're gonna give you a",
    "start": "10080",
    "end": "11490"
  },
  {
    "text": "couple demonstrations of running",
    "start": "11490",
    "end": "13110"
  },
  {
    "text": "Cromwell on AWS if you haven't already I",
    "start": "13110",
    "end": "15990"
  },
  {
    "text": "recommend that you watch our webinar",
    "start": "15990",
    "end": "17789"
  },
  {
    "text": "that goes into the details of genomics",
    "start": "17789",
    "end": "20160"
  },
  {
    "text": "workflows patterns and services and how",
    "start": "20160",
    "end": "23130"
  },
  {
    "text": "to use Cromwell as we covered in our",
    "start": "23130",
    "end": "26939"
  },
  {
    "text": "webinar here are key considerations when",
    "start": "26939",
    "end": "30480"
  },
  {
    "text": "working with genomic data first genomic",
    "start": "30480",
    "end": "33000"
  },
  {
    "text": "data sets are big depending on the",
    "start": "33000",
    "end": "35760"
  },
  {
    "text": "amount of date detail a single genomics",
    "start": "35760",
    "end": "37770"
  },
  {
    "text": "experiment can range from tens of",
    "start": "37770",
    "end": "39270"
  },
  {
    "text": "gigabytes to several petabytes second",
    "start": "39270",
    "end": "42030"
  },
  {
    "text": "converting raw DNA sequencer data to",
    "start": "42030",
    "end": "44489"
  },
  {
    "text": "scientific insight takes a lot of",
    "start": "44489",
    "end": "46140"
  },
  {
    "text": "computational steps each with their own",
    "start": "46140",
    "end": "48809"
  },
  {
    "text": "unique resource requirements handling",
    "start": "48809",
    "end": "52860"
  },
  {
    "text": "genomic data involves processing",
    "start": "52860",
    "end": "54300"
  },
  {
    "text": "pipelines or workflows so for example",
    "start": "54300",
    "end": "56730"
  },
  {
    "text": "here is the broast genome and analysis",
    "start": "56730",
    "end": "59370"
  },
  {
    "text": "best practices workflow as you can see",
    "start": "59370",
    "end": "61710"
  },
  {
    "text": "there are many steps to get the data to",
    "start": "61710",
    "end": "64619"
  },
  {
    "text": "get to the data that scientists would",
    "start": "64619",
    "end": "66990"
  },
  {
    "text": "use for analysis this is where chrome",
    "start": "66990",
    "end": "70619"
  },
  {
    "text": "bell comes into play Cromwell is an open",
    "start": "70619",
    "end": "73049"
  },
  {
    "text": "source workflow orchestration engine",
    "start": "73049",
    "end": "74700"
  },
  {
    "text": "that runs both on local machines",
    "start": "74700",
    "end": "76740"
  },
  {
    "text": "and in the cloud Cromwell",
    "start": "76740",
    "end": "79770"
  },
  {
    "text": "reads workflow definitions written in",
    "start": "79770",
    "end": "82020"
  },
  {
    "text": "languages like wdl or Whittle and cwl",
    "start": "82020",
    "end": "86009"
  },
  {
    "text": "and then launches the resources needed",
    "start": "86009",
    "end": "88829"
  },
  {
    "text": "to run the jobs defined with AWS",
    "start": "88829",
    "end": "93500"
  },
  {
    "text": "Cromwell acts as an interface to AWS",
    "start": "93500",
    "end": "96150"
  },
  {
    "text": "batch workflow jobs are submitted to",
    "start": "96150",
    "end": "99479"
  },
  {
    "text": "batch queues and run on batch compute",
    "start": "99479",
    "end": "101909"
  },
  {
    "text": "environments in the next few minutes I'm",
    "start": "101909",
    "end": "104640"
  },
  {
    "text": "gonna walk you through setting up",
    "start": "104640",
    "end": "106110"
  },
  {
    "text": "Cromwell on AWS and running a simple",
    "start": "106110",
    "end": "108420"
  },
  {
    "text": "workflow to start you're gonna need the",
    "start": "108420",
    "end": "112350"
  },
  {
    "start": "109000",
    "end": "131000"
  },
  {
    "text": "following things an ec2 instance to",
    "start": "112350",
    "end": "115590"
  },
  {
    "text": "serve as your Cromwell server a custom",
    "start": "115590",
    "end": "118320"
  },
  {
    "text": "ami for running genomic workflow jobs",
    "start": "118320",
    "end": "120780"
  },
  {
    "text": "and talking with Cromwell an s3 bucket",
    "start": "120780",
    "end": "123710"
  },
  {
    "text": "for workflow inputs and outputs and a",
    "start": "123710",
    "end": "127890"
  },
  {
    "text": "batch compute environment and job queue",
    "start": "127890",
    "end": "132050"
  },
  {
    "start": "131000",
    "end": "331000"
  },
  {
    "text": "the first thing you're going to need to",
    "start": "134210",
    "end": "136140"
  },
  {
    "text": "do is create a custom ami so if you head",
    "start": "136140",
    "end": "138720"
  },
  {
    "text": "over to our documentation site for",
    "start": "138720",
    "end": "140550"
  },
  {
    "text": "genomics workflows on AWS and go to the",
    "start": "140550",
    "end": "143670"
  },
  {
    "text": "section on creating a custom ami you'll",
    "start": "143670",
    "end": "147120"
  },
  {
    "text": "find a couple of cloud formation",
    "start": "147120",
    "end": "148560"
  },
  {
    "text": "templates that you can use to walk you",
    "start": "148560",
    "end": "150390"
  },
  {
    "text": "through the process connects",
    "start": "150390",
    "end": "159530"
  },
  {
    "text": "pick your ami type in this case you want",
    "start": "159530",
    "end": "162540"
  },
  {
    "text": "to pick Cromwell and specify the scratch",
    "start": "162540",
    "end": "165450"
  },
  {
    "text": "mount point as Cromwell root and hit",
    "start": "165450",
    "end": "172590"
  },
  {
    "text": "next again and next one last time",
    "start": "172590",
    "end": "178519"
  },
  {
    "text": "and click the checkbox to acknowledge",
    "start": "181150",
    "end": "184090"
  },
  {
    "text": "that AWS cloud formation will create I",
    "start": "184090",
    "end": "187150"
  },
  {
    "text": "am resources and hit create when the",
    "start": "187150",
    "end": "195640"
  },
  {
    "text": "process completes select the stack and",
    "start": "195640",
    "end": "198989"
  },
  {
    "text": "take note of the ami ID on the outputs",
    "start": "198989",
    "end": "202090"
  },
  {
    "text": "tag you'll use this ID later when you",
    "start": "202090",
    "end": "205629"
  },
  {
    "text": "set up your batch environment to create",
    "start": "205629",
    "end": "212890"
  },
  {
    "text": "the remaining resources you need you can",
    "start": "212890",
    "end": "215590"
  },
  {
    "text": "use the cloud formation stacks that",
    "start": "215590",
    "end": "217000"
  },
  {
    "text": "we've provided in our genomics workflows",
    "start": "217000",
    "end": "219459"
  },
  {
    "text": "documentation you can either use the",
    "start": "219459",
    "end": "222459"
  },
  {
    "text": "full stack which creates your s3 bucket",
    "start": "222459",
    "end": "225150"
  },
  {
    "text": "VPC I am roles and batch job queue in",
    "start": "225150",
    "end": "230410"
  },
  {
    "text": "compute environments or you can use a",
    "start": "230410",
    "end": "234220"
  },
  {
    "text": "cloud formation template that will",
    "start": "234220",
    "end": "236709"
  },
  {
    "text": "launch these resources in an existing",
    "start": "236709",
    "end": "238480"
  },
  {
    "text": "vbc or you can use individual templates",
    "start": "238480",
    "end": "241989"
  },
  {
    "text": "for creating the s3 bucket by itself",
    "start": "241989",
    "end": "244780"
  },
  {
    "text": "I am rules roles and the AWS batch",
    "start": "244780",
    "end": "249569"
  },
  {
    "text": "environment independently to use these",
    "start": "249569",
    "end": "256539"
  },
  {
    "text": "simply click on the button",
    "start": "256539",
    "end": "259500"
  },
  {
    "text": "click Next",
    "start": "260910",
    "end": "264019"
  },
  {
    "text": "specify your AWS bucket",
    "start": "266180",
    "end": "270100"
  },
  {
    "text": "keep air availability zones",
    "start": "274380",
    "end": "280670"
  },
  {
    "text": "and provide the ami ID use the ami ID",
    "start": "282650",
    "end": "286699"
  },
  {
    "text": "that you created using the custom ami",
    "start": "286699",
    "end": "290030"
  },
  {
    "text": "script next and next again to create",
    "start": "290030",
    "end": "297669"
  },
  {
    "text": "your infrastructure when your",
    "start": "297669",
    "end": "305090"
  },
  {
    "text": "infrastructure is complete go to the",
    "start": "305090",
    "end": "308240"
  },
  {
    "text": "batch stack go to outputs and record or",
    "start": "308240",
    "end": "315949"
  },
  {
    "text": "take note of the two job queues that",
    "start": "315949",
    "end": "318590"
  },
  {
    "text": "were created in this walkthrough we're",
    "start": "318590",
    "end": "321470"
  },
  {
    "text": "going to use the high priority job queue",
    "start": "321470",
    "end": "324639"
  },
  {
    "text": "copy this value for later",
    "start": "324639",
    "end": "328570"
  },
  {
    "start": "331000",
    "end": "507000"
  },
  {
    "text": "next you're going to need to create an",
    "start": "331889",
    "end": "334600"
  },
  {
    "text": "ec2 instance that will act as your",
    "start": "334600",
    "end": "336370"
  },
  {
    "text": "cromwell server go to IAM management",
    "start": "336370",
    "end": "339130"
  },
  {
    "text": "console and create an instance profile",
    "start": "339130",
    "end": "341289"
  },
  {
    "text": "that this instance will use to access",
    "start": "341289",
    "end": "343630"
  },
  {
    "text": "AWS services",
    "start": "343630",
    "end": "346710"
  },
  {
    "text": "you",
    "start": "358009",
    "end": "360069"
  },
  {
    "text": "attached in-line policies to this role",
    "start": "364529",
    "end": "366689"
  },
  {
    "text": "to allow it to create jobs and job",
    "start": "366689",
    "end": "368879"
  },
  {
    "text": "definitions in batch",
    "start": "368879",
    "end": "371809"
  },
  {
    "text": "you",
    "start": "377289",
    "end": "379349"
  },
  {
    "text": "and allow read-only access to your",
    "start": "402670",
    "end": "405760"
  },
  {
    "text": "bucket in s3",
    "start": "405760",
    "end": "408780"
  },
  {
    "text": "you",
    "start": "412810",
    "end": "414870"
  },
  {
    "text": "next go to your ec2 console and launch",
    "start": "450430",
    "end": "453349"
  },
  {
    "text": "an instance specifying the instance role",
    "start": "453349",
    "end": "455569"
  },
  {
    "text": "you just created",
    "start": "455569",
    "end": "458229"
  },
  {
    "text": "you",
    "start": "463849",
    "end": "465909"
  },
  {
    "text": "when your instance is available connect",
    "start": "498889",
    "end": "501389"
  },
  {
    "text": "to it via SSH",
    "start": "501389",
    "end": "504440"
  },
  {
    "start": "507000",
    "end": "621000"
  },
  {
    "text": "once you can",
    "start": "507870",
    "end": "509350"
  },
  {
    "text": "to your server download the most recent",
    "start": "509350",
    "end": "511780"
  },
  {
    "text": "version of Cromwell",
    "start": "511780",
    "end": "514830"
  },
  {
    "text": "and create a config file",
    "start": "522040",
    "end": "525449"
  },
  {
    "text": "replace the placeholders for s3 bucket",
    "start": "535980",
    "end": "541498"
  },
  {
    "text": "and batch QR",
    "start": "555930",
    "end": "559220"
  },
  {
    "text": "creet the following files the hello",
    "start": "581290",
    "end": "584769"
  },
  {
    "text": "Widow file with a single task called",
    "start": "584769",
    "end": "587589"
  },
  {
    "text": "hello and a workflow WF underscore hello",
    "start": "587589",
    "end": "591880"
  },
  {
    "text": "that calls that task this task will",
    "start": "591880",
    "end": "595600"
  },
  {
    "text": "simply echo the command hello and",
    "start": "595600",
    "end": "598170"
  },
  {
    "text": "addressee welcome to Cromwell on AWS",
    "start": "598170",
    "end": "601620"
  },
  {
    "text": "it'll use the another file for inputs in",
    "start": "601620",
    "end": "605470"
  },
  {
    "text": "this input file put this JSON formatted",
    "start": "605470",
    "end": "610089"
  },
  {
    "text": "data WF hello dot hello",
    "start": "610089",
    "end": "613810"
  },
  {
    "text": "addressee and world",
    "start": "613810",
    "end": "617730"
  },
  {
    "start": "621000",
    "end": "829000"
  },
  {
    "text": "you mean I start the Cromwell server on",
    "start": "623279",
    "end": "625620"
  },
  {
    "text": "your ec2 instance",
    "start": "625620",
    "end": "628459"
  },
  {
    "text": "in this case I'm using an SSH tunnel",
    "start": "644570",
    "end": "647950"
  },
  {
    "text": "between my local machine and the remote",
    "start": "647950",
    "end": "651770"
  },
  {
    "text": "instance on port 8000 so I can navigate",
    "start": "651770",
    "end": "658550"
  },
  {
    "text": "in a web browser to localhost port 8000",
    "start": "658550",
    "end": "663400"
  },
  {
    "text": "and see cromwell's swagger UI",
    "start": "663400",
    "end": "668650"
  },
  {
    "text": "we can use this to submit the workflow",
    "start": "671570",
    "end": "674209"
  },
  {
    "text": "that we created in the previous step",
    "start": "674209",
    "end": "678040"
  },
  {
    "text": "while this workflow runs you can monitor",
    "start": "704140",
    "end": "706720"
  },
  {
    "text": "its status in the logs or via the AWS",
    "start": "706720",
    "end": "713710"
  },
  {
    "text": "batch console",
    "start": "713710",
    "end": "716400"
  },
  {
    "text": "seriously one job has been submitted and",
    "start": "720850",
    "end": "723520"
  },
  {
    "text": "is in the runnable State",
    "start": "723520",
    "end": "726540"
  },
  {
    "text": "you should see that the desired CPU",
    "start": "741130",
    "end": "744130"
  },
  {
    "text": "count increases when the job is ready to",
    "start": "744130",
    "end": "747580"
  },
  {
    "text": "start and that in the ec2 instance or",
    "start": "747580",
    "end": "752980"
  },
  {
    "text": "ec2 management console you should see",
    "start": "752980",
    "end": "755800"
  },
  {
    "text": "instances queuing up",
    "start": "755800",
    "end": "758880"
  },
  {
    "text": "when the workflow successfully completes",
    "start": "778010",
    "end": "780440"
  },
  {
    "text": "you should receive a notification and",
    "start": "780440",
    "end": "786710"
  },
  {
    "text": "you should be able to see successful",
    "start": "786710",
    "end": "790130"
  },
  {
    "text": "completion in the logs",
    "start": "790130",
    "end": "795100"
  },
  {
    "text": "you should also be able to find outputs",
    "start": "812970",
    "end": "815560"
  },
  {
    "text": "that the workflow generated in your s3",
    "start": "815560",
    "end": "817900"
  },
  {
    "text": "bucket",
    "start": "817900",
    "end": "820230"
  },
  {
    "start": "829000",
    "end": "1073000"
  },
  {
    "text": "so that concludes my part of the demo",
    "start": "829240",
    "end": "831550"
  },
  {
    "text": "I'm gonna hand it over to Ruchi who's",
    "start": "831550",
    "end": "833470"
  },
  {
    "text": "going to show you something a little bit",
    "start": "833470",
    "end": "834879"
  },
  {
    "text": "more complicated so the next workflow",
    "start": "834879",
    "end": "838179"
  },
  {
    "text": "we're going to demonstrate in terms of",
    "start": "838179",
    "end": "840160"
  },
  {
    "text": "running Chrome wall on the AWS patch",
    "start": "840160",
    "end": "842519"
  },
  {
    "text": "back-end is a hap type what we call a",
    "start": "842519",
    "end": "846309"
  },
  {
    "text": "haplotype color workflow and the habitat",
    "start": "846309",
    "end": "850149"
  },
  {
    "text": "color is the gatk s leading germline",
    "start": "850149",
    "end": "853389"
  },
  {
    "text": "color tool and with a focus on short",
    "start": "853389",
    "end": "856540"
  },
  {
    "text": "variant discovery so in the case of this",
    "start": "856540",
    "end": "858730"
  },
  {
    "text": "workflow the input is a band file that",
    "start": "858730",
    "end": "862179"
  },
  {
    "text": "goes through two specific tasks where",
    "start": "862179",
    "end": "866170"
  },
  {
    "text": "help type color which performs short",
    "start": "866170",
    "end": "868509"
  },
  {
    "text": "bearing discovery on a single sample",
    "start": "868509",
    "end": "871569"
  },
  {
    "text": "across multiple genomic intervals so we",
    "start": "871569",
    "end": "874300"
  },
  {
    "text": "see a scatter step taking place which",
    "start": "874300",
    "end": "877619"
  },
  {
    "text": "splits up the genomic data into various",
    "start": "877619",
    "end": "880839"
  },
  {
    "text": "shards and then performs haplotype or",
    "start": "880839",
    "end": "884230"
  },
  {
    "text": "runs haplotype color or variant",
    "start": "884230",
    "end": "886179"
  },
  {
    "text": "discovery across those shards and then",
    "start": "886179",
    "end": "888639"
  },
  {
    "text": "there is a final step to merge that",
    "start": "888639",
    "end": "890800"
  },
  {
    "text": "those various shards into a final gbcm",
    "start": "890800",
    "end": "893949"
  },
  {
    "text": "file so that's the sort of flow for this",
    "start": "893949",
    "end": "897069"
  },
  {
    "text": "workflow and and this is available for",
    "start": "897069",
    "end": "901240"
  },
  {
    "text": "this is a publicly available workflow",
    "start": "901240",
    "end": "903579"
  },
  {
    "text": "for provided by the gatk in addition in",
    "start": "903579",
    "end": "907660"
  },
  {
    "text": "in this case I've collected all the",
    "start": "907660",
    "end": "910839"
  },
  {
    "text": "required input files needed for this",
    "start": "910839",
    "end": "912730"
  },
  {
    "text": "workflow such as a sample input BAM all",
    "start": "912730",
    "end": "915610"
  },
  {
    "text": "the reference files the Dockers or the",
    "start": "915610",
    "end": "918459"
  },
  {
    "text": "command is encapsulated and sort of the",
    "start": "918459",
    "end": "921279"
  },
  {
    "text": "other optimization parameters in",
    "start": "921279",
    "end": "924999"
  },
  {
    "text": "addition in order to be able to run",
    "start": "924999",
    "end": "927009"
  },
  {
    "text": "crombel on AWS i also require an AWS",
    "start": "927009",
    "end": "929589"
  },
  {
    "text": "config so this is very similar to the",
    "start": "929589",
    "end": "933369"
  },
  {
    "text": "config we presented earlier except I",
    "start": "933369",
    "end": "935649"
  },
  {
    "text": "have my own execution directory as well",
    "start": "935649",
    "end": "938379"
  },
  {
    "text": "as my own batch queue that's been",
    "start": "938379",
    "end": "940749"
  },
  {
    "text": "configured for use so now I'll jump over",
    "start": "940749",
    "end": "944230"
  },
  {
    "text": "to my terminal window to show you what",
    "start": "944230",
    "end": "946720"
  },
  {
    "text": "it's like running krummel from the",
    "start": "946720",
    "end": "948819"
  },
  {
    "text": "command line mode to run the haplotype",
    "start": "948819",
    "end": "951490"
  },
  {
    "text": "caller workflow for the purposes of this",
    "start": "951490",
    "end": "955360"
  },
  {
    "text": "demo I've collected all the files that",
    "start": "955360",
    "end": "959169"
  },
  {
    "text": "will be required to be able to run a",
    "start": "959169",
    "end": "961329"
  },
  {
    "text": "workflow",
    "start": "961329",
    "end": "962240"
  },
  {
    "text": "Cromwell on AWS so for example I have",
    "start": "962240",
    "end": "965089"
  },
  {
    "text": "the inputs JSON we just looked at which",
    "start": "965089",
    "end": "967820"
  },
  {
    "text": "are all the inputs files required for",
    "start": "967820",
    "end": "969770"
  },
  {
    "text": "the workflow the actual will file which",
    "start": "969770",
    "end": "972500"
  },
  {
    "text": "is the workflow descriptor file the AWS",
    "start": "972500",
    "end": "975440"
  },
  {
    "text": "config which includes information about",
    "start": "975440",
    "end": "978170"
  },
  {
    "text": "the queue where these jobs are going to",
    "start": "978170",
    "end": "981860"
  },
  {
    "text": "be dispatched I have a Cromwell jar that",
    "start": "981860",
    "end": "984860"
  },
  {
    "text": "I've downloaded so that's all that's",
    "start": "984860",
    "end": "987770"
  },
  {
    "text": "needed to get started so what I'm going",
    "start": "987770",
    "end": "990709"
  },
  {
    "text": "to do is string together the various",
    "start": "990709",
    "end": "992149"
  },
  {
    "text": "components into the required command for",
    "start": "992149",
    "end": "994700"
  },
  {
    "text": "Cromwell",
    "start": "994700",
    "end": "995360"
  },
  {
    "text": "so the first thing I'm going to do is",
    "start": "995360",
    "end": "997550"
  },
  {
    "text": "point to the appropriate config file and",
    "start": "997550",
    "end": "1001110"
  },
  {
    "text": "then the appropriate Java file and then",
    "start": "1001110",
    "end": "1006970"
  },
  {
    "text": "the next required component for running",
    "start": "1006970",
    "end": "1010480"
  },
  {
    "text": "Cromwell on the run mode or what we call",
    "start": "1010480",
    "end": "1013450"
  },
  {
    "text": "command line mode is the path to the",
    "start": "1013450",
    "end": "1017080"
  },
  {
    "text": "Whittle in this case it's available",
    "start": "1017080",
    "end": "1019260"
  },
  {
    "text": "right within the same directory along",
    "start": "1019260",
    "end": "1021490"
  },
  {
    "text": "with an inputs file which uses a - I",
    "start": "1021490",
    "end": "1024610"
  },
  {
    "text": "parameter and the fault has - the inputs",
    "start": "1024610",
    "end": "1028660"
  },
  {
    "text": "JSON in this case and that's all that",
    "start": "1028660",
    "end": "1031870"
  },
  {
    "text": "should be needed to start off the run",
    "start": "1031870",
    "end": "1034319"
  },
  {
    "text": "you'll notice from observing the screen",
    "start": "1034319",
    "end": "1037900"
  },
  {
    "text": "in a couple of seconds that the crumble",
    "start": "1037900",
    "end": "1040688"
  },
  {
    "text": "logs can be quite verbose but we'll see",
    "start": "1040689",
    "end": "1044980"
  },
  {
    "text": "sort of a color shift when jobs have",
    "start": "1044980",
    "end": "1048820"
  },
  {
    "text": "been initialized prepared and dispatched",
    "start": "1048820",
    "end": "1051460"
  },
  {
    "text": "to the AWS batch beckoned I'm starting",
    "start": "1051460",
    "end": "1056470"
  },
  {
    "text": "to see the this is the actual task",
    "start": "1056470",
    "end": "1061059"
  },
  {
    "text": "definition that was written inside of",
    "start": "1061059",
    "end": "1063610"
  },
  {
    "text": "the workflow so I'm seeing instantiation",
    "start": "1063610",
    "end": "1066309"
  },
  {
    "text": "of it being sent to the batch back-end",
    "start": "1066309",
    "end": "1070289"
  },
  {
    "start": "1073000",
    "end": "1380000"
  },
  {
    "text": "and jobs that have started running",
    "start": "1073830",
    "end": "1078700"
  },
  {
    "text": "so while this workflow runs in the",
    "start": "1078700",
    "end": "1081039"
  },
  {
    "text": "background and since this is a fairly",
    "start": "1081039",
    "end": "1083289"
  },
  {
    "text": "computationally intensive workflow even",
    "start": "1083289",
    "end": "1085629"
  },
  {
    "text": "when running on a downsampled data set",
    "start": "1085629",
    "end": "1088470"
  },
  {
    "text": "it's going to take quite some time to",
    "start": "1088470",
    "end": "1092139"
  },
  {
    "text": "finish so what have what I've done in",
    "start": "1092139",
    "end": "1094570"
  },
  {
    "text": "lieu in place for this demo is to copy",
    "start": "1094570",
    "end": "1099700"
  },
  {
    "text": "down the results from the s3 bucket so I",
    "start": "1099700",
    "end": "1102850"
  },
  {
    "text": "have a results directory here which",
    "start": "1102850",
    "end": "1105940"
  },
  {
    "text": "includes all the outputs files generated",
    "start": "1105940",
    "end": "1108009"
  },
  {
    "text": "by one of the tasks in the workflow so",
    "start": "1108009",
    "end": "1110919"
  },
  {
    "text": "if you're wondering how you would find",
    "start": "1110919",
    "end": "1112210"
  },
  {
    "text": "these outputs themselves in the a double",
    "start": "1112210",
    "end": "1114429"
  },
  {
    "text": "a socket as well then inside of your",
    "start": "1114429",
    "end": "1117580"
  },
  {
    "text": "crumble config itself you've declared",
    "start": "1117580",
    "end": "1121690"
  },
  {
    "text": "the s3 bucket used to store your outputs",
    "start": "1121690",
    "end": "1127289"
  },
  {
    "text": "so if you look at your AWS config",
    "start": "1127289",
    "end": "1130379"
  },
  {
    "text": "there's a line there's a key called a",
    "start": "1130379",
    "end": "1133269"
  },
  {
    "text": "root which includes an s3 file path so",
    "start": "1133269",
    "end": "1136869"
  },
  {
    "text": "in this case all the all the various",
    "start": "1136869",
    "end": "1140369"
  },
  {
    "text": "work flex accuse performed using this",
    "start": "1140369",
    "end": "1143710"
  },
  {
    "text": "config file all fall within that",
    "start": "1143710",
    "end": "1146730"
  },
  {
    "text": "structure and within that bucket in s3",
    "start": "1146730",
    "end": "1151590"
  },
  {
    "text": "so what I'm going to do is list this",
    "start": "1152070",
    "end": "1156279"
  },
  {
    "text": "directory that I've specified in my kws",
    "start": "1156279",
    "end": "1161139"
  },
  {
    "text": "config file to make sure that the",
    "start": "1161139",
    "end": "1163690"
  },
  {
    "text": "workflow outputs are being added there",
    "start": "1163690",
    "end": "1166210"
  },
  {
    "text": "as I would expect so using the AWS CLI I",
    "start": "1166210",
    "end": "1171480"
  },
  {
    "text": "can Ellis this this directory structure",
    "start": "1171480",
    "end": "1178920"
  },
  {
    "text": "half tech collar is the name of my",
    "start": "1178920",
    "end": "1180360"
  },
  {
    "text": "workflow I can take an example run in",
    "start": "1180360",
    "end": "1186630"
  },
  {
    "text": "the past I can look specifically at the",
    "start": "1186630",
    "end": "1191130"
  },
  {
    "text": "outputs of the haplotype collar job or",
    "start": "1191130",
    "end": "1194160"
  },
  {
    "text": "the merge",
    "start": "1194160",
    "end": "1195480"
  },
  {
    "text": "GBCs job and since this job was charted",
    "start": "1195480",
    "end": "1203760"
  },
  {
    "text": "across the single sample over various",
    "start": "1203760",
    "end": "1205530"
  },
  {
    "text": "genomic intervals I'm just going to take",
    "start": "1205530",
    "end": "1207210"
  },
  {
    "text": "the first one and here are the various",
    "start": "1207210",
    "end": "1211500"
  },
  {
    "text": "output files generated by this",
    "start": "1211500",
    "end": "1213809"
  },
  {
    "text": "particular task there is something",
    "start": "1213809",
    "end": "1217350"
  },
  {
    "text": "called there's something which is the RC",
    "start": "1217350",
    "end": "1220380"
  },
  {
    "text": "text which is the return code file which",
    "start": "1220380",
    "end": "1223140"
  },
  {
    "text": "represents the return code essentially",
    "start": "1223140",
    "end": "1226950"
  },
  {
    "text": "returned behind a program that was",
    "start": "1226950",
    "end": "1228390"
  },
  {
    "text": "executed inside of the command the",
    "start": "1228390",
    "end": "1230250"
  },
  {
    "text": "standard error and standard out produced",
    "start": "1230250",
    "end": "1232200"
  },
  {
    "text": "by the command as well along with any",
    "start": "1232200",
    "end": "1234510"
  },
  {
    "text": "final @lm with any outputs declared in",
    "start": "1234510",
    "end": "1237179"
  },
  {
    "text": "the task definition so since we have",
    "start": "1237179",
    "end": "1240660"
  },
  {
    "text": "local copies of the results we can start",
    "start": "1240660",
    "end": "1245130"
  },
  {
    "text": "off by checking out the contents of the",
    "start": "1245130",
    "end": "1246960"
  },
  {
    "text": "RC file so if a job succeeds at least",
    "start": "1246960",
    "end": "1251040"
  },
  {
    "text": "one using gatk the expected return code",
    "start": "1251040",
    "end": "1253290"
  },
  {
    "text": "is zero and this is something that can",
    "start": "1253290",
    "end": "1255330"
  },
  {
    "text": "differ from various tools but in this",
    "start": "1255330",
    "end": "1257610"
  },
  {
    "text": "case assuming that my job succeeded I",
    "start": "1257610",
    "end": "1261030"
  },
  {
    "text": "expect the contents of the return code",
    "start": "1261030",
    "end": "1262620"
  },
  {
    "text": "file to be zero and in case of debugging",
    "start": "1262620",
    "end": "1265890"
  },
  {
    "text": "any kinds of failures the return code",
    "start": "1265890",
    "end": "1268290"
  },
  {
    "text": "file is vertically to start to",
    "start": "1268290",
    "end": "1269850"
  },
  {
    "text": "understand what was the final outcome of",
    "start": "1269850",
    "end": "1272669"
  },
  {
    "text": "a command secondarily it can also help",
    "start": "1272669",
    "end": "1275970"
  },
  {
    "text": "when debugging to look at the any",
    "start": "1275970",
    "end": "1279419"
  },
  {
    "text": "contents inside of the standard error",
    "start": "1279419",
    "end": "1281070"
  },
  {
    "text": "Wow so in this case the gatk outputted",
    "start": "1281070",
    "end": "1284700"
  },
  {
    "text": "the actual command the full command",
    "start": "1284700",
    "end": "1287700"
  },
  {
    "text": "being run by the gatk along with any",
    "start": "1287700",
    "end": "1289770"
  },
  {
    "text": "default parameters that are being",
    "start": "1289770",
    "end": "1291960"
  },
  {
    "text": "applied which can be helpful along with",
    "start": "1291960",
    "end": "1295350"
  },
  {
    "text": "a standardized file which includes which",
    "start": "1295350",
    "end": "1301710"
  },
  {
    "text": "includes just a lot of information being",
    "start": "1301710",
    "end": "1303360"
  },
  {
    "text": "emitted by the tool and it can be",
    "start": "1303360",
    "end": "1306900"
  },
  {
    "text": "verbose they cannot be it just really",
    "start": "1306900",
    "end": "1308700"
  },
  {
    "text": "depends on the kind of toolkit you're",
    "start": "1308700",
    "end": "1310380"
  },
  {
    "text": "using",
    "start": "1310380",
    "end": "1311580"
  },
  {
    "text": "and in this particular case since my",
    "start": "1311580",
    "end": "1313710"
  },
  {
    "text": "sample succeeded I'm not going to dig",
    "start": "1313710",
    "end": "1315720"
  },
  {
    "text": "too far into my standard out file but",
    "start": "1315720",
    "end": "1318450"
  },
  {
    "text": "instead what I want to be able to do is",
    "start": "1318450",
    "end": "1321180"
  },
  {
    "text": "just investigate the file contents of",
    "start": "1321180",
    "end": "1324240"
  },
  {
    "text": "the actual output valve generated so I",
    "start": "1324240",
    "end": "1327450"
  },
  {
    "text": "see that the VCF produced is right here",
    "start": "1327450",
    "end": "1332190"
  },
  {
    "text": "I'm going to since this is AG zipped",
    "start": "1332190",
    "end": "1338340"
  },
  {
    "text": "file I can simply gun zip and extract",
    "start": "1338340",
    "end": "1341670"
  },
  {
    "text": "the VCF inside of this I'll and I should",
    "start": "1341670",
    "end": "1346710"
  },
  {
    "text": "be able to head and look at the header",
    "start": "1346710",
    "end": "1349890"
  },
  {
    "text": "of the museum so I know that my VCF was",
    "start": "1349890",
    "end": "1353400"
  },
  {
    "text": "generated the header looks as if",
    "start": "1353400",
    "end": "1355170"
  },
  {
    "text": "expected with some of the sort of normal",
    "start": "1355170",
    "end": "1357930"
  },
  {
    "text": "attributes for it and so this gives me",
    "start": "1357930",
    "end": "1360720"
  },
  {
    "text": "confidence that my job succeeded and",
    "start": "1360720",
    "end": "1362790"
  },
  {
    "text": "then you can take this VCF or the cheese",
    "start": "1362790",
    "end": "1366060"
  },
  {
    "text": "up to VCF and pass it down to a tool",
    "start": "1366060",
    "end": "1368280"
  },
  {
    "text": "downstream so while this job runs the",
    "start": "1368280",
    "end": "1373920"
  },
  {
    "text": "workflows presented here should simply",
    "start": "1373920",
    "end": "1376770"
  },
  {
    "text": "reach success on the order of minutes",
    "start": "1376770",
    "end": "1379940"
  },
  {
    "text": "thanks Richie that was an awesome",
    "start": "1379940",
    "end": "1381930"
  },
  {
    "start": "1380000",
    "end": "1429000"
  },
  {
    "text": "demonstration thanks Lee I hope you all",
    "start": "1381930",
    "end": "1384600"
  },
  {
    "text": "get a chance to try out the various",
    "start": "1384600",
    "end": "1386370"
  },
  {
    "text": "tutorials and we would love to hear any",
    "start": "1386370",
    "end": "1388710"
  },
  {
    "text": "feedback you have so that concludes our",
    "start": "1388710",
    "end": "1391890"
  },
  {
    "text": "demonstrations if you'd like to learn",
    "start": "1391890",
    "end": "1393750"
  },
  {
    "text": "more I recommend checking out the docs",
    "start": "1393750",
    "end": "1395460"
  },
  {
    "text": "for Cromwell and running genomics",
    "start": "1395460",
    "end": "1397470"
  },
  {
    "text": "workflows on AWS taking a look at",
    "start": "1397470",
    "end": "1400200"
  },
  {
    "text": "Cromwell's github repository and looking",
    "start": "1400200",
    "end": "1402750"
  },
  {
    "text": "at what you can do with wittle' at Open",
    "start": "1402750",
    "end": "1404880"
  },
  {
    "text": "wittle detto RG if you'd like to learn",
    "start": "1404880",
    "end": "1407130"
  },
  {
    "text": "more about other scientific workloads on",
    "start": "1407130",
    "end": "1408870"
  },
  {
    "text": "AWS I recommend you check out our pages",
    "start": "1408870",
    "end": "1411420"
  },
  {
    "text": "on research and technical computing take",
    "start": "1411420",
    "end": "1416010"
  },
  {
    "text": "a look at our research cloud and cloud",
    "start": "1416010",
    "end": "1418860"
  },
  {
    "text": "credits for research programs and",
    "start": "1418860",
    "end": "1420500"
  },
  {
    "text": "explore datasets we host on a registry",
    "start": "1420500",
    "end": "1423300"
  },
  {
    "text": "of open data and with that I want to",
    "start": "1423300",
    "end": "1425370"
  },
  {
    "text": "thank everyone for watching I'm Lea I'm",
    "start": "1425370",
    "end": "1427500"
  },
  {
    "text": "Ruchi go build",
    "start": "1427500",
    "end": "1430820"
  }
]
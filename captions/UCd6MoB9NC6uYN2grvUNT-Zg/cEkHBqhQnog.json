[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "what's cooler than a million users anybody a billion users right um that's",
    "start": "840",
    "end": "7200"
  },
  {
    "text": "why we're here today either you're building the next social experience the next gaming experience you're building the next",
    "start": "7200",
    "end": "13719"
  },
  {
    "text": "platform that needs to scale Beyond conventional means and",
    "start": "13719",
    "end": "19000"
  },
  {
    "text": "you're here to build that experience and today we're going to talk about the most go-to mechanism that you're going to",
    "start": "19000",
    "end": "24320"
  },
  {
    "text": "have to use to achieve that we here to talk about elasticache my name is Sami zorine I'm a architect with Amazon web",
    "start": "24320",
    "end": "31439"
  },
  {
    "text": "services and I'm joined today by Frank wee principal scientist from Adobe who's going to join me on stage",
    "start": "31439",
    "end": "36960"
  },
  {
    "text": "shortly so let's go back to that you are here because there are",
    "start": "36960",
    "end": "42520"
  },
  {
    "start": "40000",
    "end": "60000"
  },
  {
    "text": "certain problems that don't get solved unless you move to the right of the time Horizon if you don't move in order of magnitude over you won't get the speed",
    "start": "42520",
    "end": "50000"
  },
  {
    "text": "and subsequent scale that you need for re application so this is the problem that we're trying to solve and a caching",
    "start": "50000",
    "end": "56640"
  },
  {
    "text": "solution frankly is the way to do that elastic cach specifically is a",
    "start": "56640",
    "end": "61800"
  },
  {
    "start": "60000",
    "end": "82000"
  },
  {
    "text": "managed service that helps you do that and everything that a managed service is expected to do is provided by elastic",
    "start": "61800",
    "end": "68400"
  },
  {
    "text": "cache you pay for what you use you provision as you need it you size it you scale it you instantiate it and you get",
    "start": "68400",
    "end": "75159"
  },
  {
    "text": "it and for elastic cach we provide two flavors mcash D and",
    "start": "75159",
    "end": "81320"
  },
  {
    "text": "redis most of you are going to know this but for those who don't we'll just take a quick walk through the park with redis and mcash",
    "start": "81320",
    "end": "87880"
  },
  {
    "start": "82000",
    "end": "167000"
  },
  {
    "text": "D first off redis is a me uh inmemory key value data store and key value data store is like",
    "start": "87880",
    "end": "95759"
  },
  {
    "text": "having a database with two things a key and a value it operates a lot more like a",
    "start": "95759",
    "end": "100920"
  },
  {
    "text": "nosql database if you take a look at the reddest commands there's just um a wealth of commands there it's quite",
    "start": "100920",
    "end": "106320"
  },
  {
    "text": "exhaustive and so you can really use it more like a ni nosql database supports data types more than just strings it",
    "start": "106320",
    "end": "113280"
  },
  {
    "text": "supports uh hashes sets sorted sets and a variety of other things it is single",
    "start": "113280",
    "end": "119000"
  },
  {
    "text": "threaded and and that isn't really a deterrent that actually gives way to really some interesting positives in the",
    "start": "119000",
    "end": "124759"
  },
  {
    "text": "way that it behaves one of those is that you can achieve Atomic operations using redus essentially gives it an acid-like",
    "start": "124759",
    "end": "131840"
  },
  {
    "text": "feel um and you don't have to worry about things like thread locking and and",
    "start": "131840",
    "end": "137160"
  },
  {
    "text": "whatnot supports read replicas so you can have sort of a primary that we'll show in a minute and several read",
    "start": "137160",
    "end": "142840"
  },
  {
    "text": "replicas if you're already using RDS with read replicas this sort of brings it up into your cach layer this is natively supported out of Rus a huge one",
    "start": "142840",
    "end": "150239"
  },
  {
    "text": "is that there's a persistence aspect you can essentially take snapshots backups and save that uh state of your datab or",
    "start": "150239",
    "end": "157360"
  },
  {
    "text": "state of your cash to dis it has Pub sub functionality that we'll demonstrate in a little",
    "start": "157360",
    "end": "163760"
  },
  {
    "text": "bit and it's ridiculously fast moving on to mcash D it's again a me in uh",
    "start": "163760",
    "end": "169959"
  },
  {
    "start": "167000",
    "end": "218000"
  },
  {
    "text": "inmemory uh key value data store it's a slab allocator model um",
    "start": "169959",
    "end": "175480"
  },
  {
    "text": "we'll talk in a minute about what that means to to deal with slabs supports more more simplistic uh data structures",
    "start": "175480",
    "end": "181640"
  },
  {
    "text": "essentially strings and then uh objects that you can serialize and deserialize in and out of the cache it's",
    "start": "181640",
    "end": "186760"
  },
  {
    "text": "multi-threaded in reality it's actually several caches under one umbrella um it's very established it's been around",
    "start": "186760",
    "end": "192280"
  },
  {
    "text": "for a long time the patterns are very established the libraries are very established it does not have persistence",
    "start": "192280",
    "end": "198000"
  },
  {
    "text": "you'd have to engineer that yourself and there's a there's several strategies that exist currently to be able to",
    "start": "198000",
    "end": "204120"
  },
  {
    "text": "spread across several MCD uh instances uh and then we'll go into that soon",
    "start": "204120",
    "end": "210640"
  },
  {
    "text": "just like Rus it's insanely fast so let's walk through that now that you get an orientation of the landscape what are",
    "start": "210640",
    "end": "216519"
  },
  {
    "text": "you launching let's talk about launching a cluster within the elasticas",
    "start": "216519",
    "end": "223040"
  },
  {
    "start": "218000",
    "end": "313000"
  },
  {
    "text": "context you simply do a few very simplistic things number one decide on your cache engine I won't be prescripted",
    "start": "223040",
    "end": "229959"
  },
  {
    "text": "about what cache engine to use but we'll talk about some patterns in a few moments that will maybe give you ideas about how and what you want to",
    "start": "229959",
    "end": "237599"
  },
  {
    "text": "implement pick some of the essentials that go with the engine that you're going with the version uh the port",
    "start": "237599",
    "end": "242760"
  },
  {
    "text": "number parameter groups parameter groups are ways to sort of specify extra configuration special",
    "start": "242760",
    "end": "248120"
  },
  {
    "text": "configuration multiz this is a huge part of the elasticache managed service is that when you start a reddish uh",
    "start": "248120",
    "end": "255280"
  },
  {
    "text": "replication group or you launch a a reddish cluster you can specify any",
    "start": "255280",
    "end": "260440"
  },
  {
    "text": "number of read replicas where they exist and specify them across availability zones we take care of things like autof",
    "start": "260440",
    "end": "266440"
  },
  {
    "text": "failover and whatnot for you it's a huge value ad if you've had had to do this yourself it's quite a bit to instrument",
    "start": "266440",
    "end": "272240"
  },
  {
    "text": "and like having a managed service essentially with a few API calls this is done for",
    "start": "272240",
    "end": "277800"
  },
  {
    "text": "you we also on that previous point we give you the ab ability to take an existing reddis dump uh export and Seed",
    "start": "278479",
    "end": "286919"
  },
  {
    "text": "your data uh seed your data or your new cluster based on existing reddis cluster's",
    "start": "286919",
    "end": "293680"
  },
  {
    "text": "backup lastly choose your security your subnet group where is this cluster going to go um enable backups this is",
    "start": "293680",
    "end": "299440"
  },
  {
    "text": "something we can do for you uh as part of the manage service it just really makes it turn key to be able to launch a cluster back up the cluster maintain the",
    "start": "299440",
    "end": "306199"
  },
  {
    "text": "cluster that's pretty much it just launch your cluster after that and then within a few minutes you have a",
    "start": "306199",
    "end": "311720"
  },
  {
    "text": "cluster uh for those of us that are more CLI inclined programmatically inclined you can do the same thing at the end of",
    "start": "311720",
    "end": "316960"
  },
  {
    "start": "313000",
    "end": "337000"
  },
  {
    "text": "the day uh elasticache and all of AWS is an apid driven infrastructure you're",
    "start": "316960",
    "end": "322280"
  },
  {
    "text": "just calling the API whether you do it through the Management console do it through our command line do it through cloud formation you're sending commands",
    "start": "322280",
    "end": "329080"
  },
  {
    "text": "off to our Pi this is a probably a more friendly way to do it for those of us that are doing the infrastructure as",
    "start": "329080",
    "end": "334240"
  },
  {
    "text": "code um model in our environments whatever it is now you've launched a cluster takes a few minutes it's really",
    "start": "334240",
    "end": "341039"
  },
  {
    "start": "337000",
    "end": "391000"
  },
  {
    "text": "not that long what do you need out of that what's the what's the information that you want to derive out of launching your cluster uh we call those endpoints",
    "start": "341039",
    "end": "348080"
  },
  {
    "text": "endpoints refer to the individual nodes within your cluster there's also a few special",
    "start": "348080",
    "end": "354039"
  },
  {
    "text": "endpoints one of them in the reddest sense is called uh your primary endpoints your primary in point refers",
    "start": "354039",
    "end": "360520"
  },
  {
    "text": "to where the master of your your reddest cluster it's where you going to send all your rights and it's a consistent name",
    "start": "360520",
    "end": "366680"
  },
  {
    "text": "it's never going to change in the McD scenario there's a configuration endpoint configuration",
    "start": "366680",
    "end": "372919"
  },
  {
    "text": "endpoint again is a consistent DNS name that you can hit and retrieve a special key that contains essentially the",
    "start": "372919",
    "end": "378520"
  },
  {
    "text": "description of your cluster all the members of your cluster and what do you do with end",
    "start": "378520",
    "end": "383680"
  },
  {
    "text": "points um the main thing you do is you connect to your cluster so if this is",
    "start": "383680",
    "end": "389240"
  },
  {
    "text": "the iCal representation in your cluster this is sort of the physical representation of the cluster you've launched a cluster you have the",
    "start": "389240",
    "end": "394440"
  },
  {
    "text": "configuration endpoints where do you plug them in what do they represent when they plug them into your into your",
    "start": "394440",
    "end": "400039"
  },
  {
    "text": "code well again using the primary endpoint you're going to send all your re all your rights to uh your primary",
    "start": "400039",
    "end": "408199"
  },
  {
    "text": "reddest node and for that you're going to use the primary endpoint that endpoint is never going to",
    "start": "408199",
    "end": "413240"
  },
  {
    "text": "change additionally you're going to send all your reads um in order to spread",
    "start": "413240",
    "end": "418360"
  },
  {
    "text": "them out or perhaps send them AC Ross different A's you're going to send all your reads using any number of the read",
    "start": "418360",
    "end": "423400"
  },
  {
    "text": "end points of your cluster in the Redd scenario there's a",
    "start": "423400",
    "end": "428960"
  },
  {
    "text": "constant replication an asynchronous replication that's happening between the master and the and the replicas uh they are there's a",
    "start": "428960",
    "end": "436520"
  },
  {
    "text": "continuous sort of uh asynchronous process that is sending all the transactions happening from the master to the to the backup what's important to",
    "start": "436520",
    "end": "443000"
  },
  {
    "text": "note is that this is asynchronous so there could be a bit of a delay um that's called replication lag in reality",
    "start": "443000",
    "end": "448879"
  },
  {
    "text": "it's it's it's tribally small but the important thing to know about the replication lag is we use that to figure",
    "start": "448879",
    "end": "454759"
  },
  {
    "text": "out autof failover so autof failover something uh recently announced for us",
    "start": "454759",
    "end": "460080"
  },
  {
    "text": "we will automatically promote a replica in the event of a instance failure an AZ",
    "start": "460080",
    "end": "465720"
  },
  {
    "text": "failure um a network issue we'll go ahead and detect that we'll figure out which of your replicas has the shortest",
    "start": "465720",
    "end": "471520"
  },
  {
    "text": "lag behind the master and go ahead and promote that in and we'll replace the replica that came out of it all this",
    "start": "471520",
    "end": "477400"
  },
  {
    "text": "happens without any changes to your configuration it's it's a consistent DNS uh experience and to enable that all you",
    "start": "477400",
    "end": "484199"
  },
  {
    "text": "have to do is when you launch your cluster just check the box that says",
    "start": "484199",
    "end": "488319"
  },
  {
    "start": "489000",
    "end": "504000"
  },
  {
    "text": "multi so connecting to your cluster you've launched a cluster you have the needed information out of out of the AWS",
    "start": "489560",
    "end": "494960"
  },
  {
    "text": "service meaning the endpoints on how to connect to it and you understand sort of how it's",
    "start": "494960",
    "end": "500400"
  },
  {
    "text": "physically set up so logically we want to connect to your cluster most primitive waves is just to",
    "start": "500400",
    "end": "507080"
  },
  {
    "start": "504000",
    "end": "554000"
  },
  {
    "text": "issue a T net command to the to the primary endpoint in this case and um and the port um you can start issuing",
    "start": "507080",
    "end": "514039"
  },
  {
    "text": "commands based on the reddis command set you can look at the reddis website for that red.i uh you can also use the",
    "start": "514039",
    "end": "519640"
  },
  {
    "text": "reddis CLI uh you can download that and uh and build that it gives you some niceties it",
    "start": "519640",
    "end": "525680"
  },
  {
    "text": "gives you command history uh it gives you ability to take backups and things like that but most of the time we're not",
    "start": "525680",
    "end": "531200"
  },
  {
    "text": "going to use sort of raw socket level communication work they're going to incorporate client libraries that's a",
    "start": "531200",
    "end": "536240"
  },
  {
    "text": "sampling of the the reddish client libraries that uh that are available there or more than that question might have come up in the",
    "start": "536240",
    "end": "542880"
  },
  {
    "text": "last slide is there is a primary endpoint that gives them the the the the",
    "start": "542880",
    "end": "548519"
  },
  {
    "text": "Master's uh DNS name so you can send your rights how do I know read replicas are local to my a well again we're a",
    "start": "548519",
    "end": "555519"
  },
  {
    "text": "programmatic infrastructure who um you could do a couple things here you could take an",
    "start": "555519",
    "end": "561079"
  },
  {
    "text": "instance and from the instance you can interrogate the local metadata and find out what availability Zone you're in and",
    "start": "561079",
    "end": "566839"
  },
  {
    "text": "then interrogate our apis and find out what are the replicas in my in my replication group and which ones are",
    "start": "566839",
    "end": "572720"
  },
  {
    "text": "local to my a this is a Java example but you can essentially do this in any language and in this sense you always",
    "start": "572720",
    "end": "579399"
  },
  {
    "text": "know that you're talking to a replica that's local to your a similarly connecting to mcash um you",
    "start": "579399",
    "end": "586240"
  },
  {
    "start": "583000",
    "end": "616000"
  },
  {
    "text": "can again be raw uh use tnet uh set Keys get keys um the first example there is",
    "start": "586240",
    "end": "594920"
  },
  {
    "text": "the command you'd use the special command you use or the special key you'd use in mcash cluster You' use the",
    "start": "594920",
    "end": "600640"
  },
  {
    "text": "configuration endpoint that was shown uh in the list of endpoints you'd use that endpoint to connect and issue the config",
    "start": "600640",
    "end": "606920"
  },
  {
    "text": "get cluster command that will tell you consistently at any time what mcash d uh",
    "start": "606920",
    "end": "612839"
  },
  {
    "text": "nodes are inside of your MCD cluster again most of the time you're",
    "start": "612839",
    "end": "618480"
  },
  {
    "start": "616000",
    "end": "633000"
  },
  {
    "text": "not going to do that via you know kind of raw sockets you're going to use client libraries in the McD scenario we",
    "start": "618480",
    "end": "624640"
  },
  {
    "text": "do have libraries provided by our service by elastic cache we have packaged",
    "start": "624640",
    "end": "629760"
  },
  {
    "text": "certain libraries that take care of certain niceties for you so the libraries we offer number one you can",
    "start": "629760",
    "end": "636079"
  },
  {
    "start": "633000",
    "end": "669000"
  },
  {
    "text": "get them by going to our console uh go to the left and at the bottom um you'll see the clients we have for java.net and",
    "start": "636079",
    "end": "643399"
  },
  {
    "text": "uh php.net was a recent addition our libraries um similar to many of the",
    "start": "643399",
    "end": "649279"
  },
  {
    "text": "libraries that are offer uh take care of autodiscovery for you every 60 seconds they'll pull the apis and figure out if",
    "start": "649279",
    "end": "654560"
  },
  {
    "text": "there's any changes to your cluster they'll also provide for consistent hashing that we'll talk about in a",
    "start": "654560",
    "end": "660200"
  },
  {
    "text": "minute and the benefit here is that you really don't need to do anything behind the scenes if you're using our clusters and there's a our clients and there's a",
    "start": "660200",
    "end": "666600"
  },
  {
    "text": "change to your uh configuration what does that look like from a code perspective here's a PHP example you",
    "start": "666600",
    "end": "672519"
  },
  {
    "start": "669000",
    "end": "722000"
  },
  {
    "text": "really only need to plug in the configuration endpoint that's it other than that you just set some options on",
    "start": "672519",
    "end": "677680"
  },
  {
    "text": "the cache object um and uh say that this is this is dynamic that means that in",
    "start": "677680",
    "end": "682720"
  },
  {
    "text": "the background what's happening is that the client library is just figuring out if there's any changes every 60 seconds and that's the list it's going to use",
    "start": "682720",
    "end": "690279"
  },
  {
    "text": "now what happens is when you have multiple in this case multiple mcash d uh servers and you have a common",
    "start": "690279",
    "end": "696079"
  },
  {
    "text": "keyspace it's just one uh keyspace and you're going to need to send it to any number of MCD servers the McD servers",
    "start": "696079",
    "end": "703120"
  },
  {
    "text": "are not you know truly a cluster there's no sort of inner communication that's going on between them the strategy for which keys are going to go on which MCD",
    "start": "703120",
    "end": "710079"
  },
  {
    "text": "server is something that's actually taken care of on the client side and done so by sharding and so the question",
    "start": "710079",
    "end": "715639"
  },
  {
    "text": "becomes what are some some avenues for sharting um",
    "start": "715639",
    "end": "721240"
  },
  {
    "start": "722000",
    "end": "763000"
  },
  {
    "text": "one strategy you could use is to Simply take the list of of mecd servers you",
    "start": "723600",
    "end": "728720"
  },
  {
    "text": "have and use that enumerate that list and then hash your key and then do a modulo based on the on the number of",
    "start": "728720",
    "end": "734440"
  },
  {
    "text": "servers and figure out which server to talk to this is generally heavily deprecated nobody really does this",
    "start": "734440",
    "end": "739760"
  },
  {
    "text": "anymore because it's very impactful you're always going to have some amount of key reshuffling when you add or",
    "start": "739760",
    "end": "746079"
  },
  {
    "text": "remove a MCD node that's just that's the fact of life objective is to minimize that impact uh as much as possible and",
    "start": "746079",
    "end": "752440"
  },
  {
    "text": "in this scenario this is heavily impactful so most F most folks don't do this anymore and that goes back to the",
    "start": "752440",
    "end": "757880"
  },
  {
    "text": "consistent hashing aspect of most libraries and specifically elastic hash libraries consistent hashing is",
    "start": "757880",
    "end": "764639"
  },
  {
    "start": "763000",
    "end": "786000"
  },
  {
    "text": "something that you can go and read about and take a very long time to read about it's a it's a fascinating complex",
    "start": "764639",
    "end": "769920"
  },
  {
    "text": "subject if you can't sleep at night go ahead and read about it um here's my 30 second view on uh consistent hashing uh",
    "start": "769920",
    "end": "776920"
  },
  {
    "text": "picture a ring okay um it's or sometimes it's called a",
    "start": "776920",
    "end": "784680"
  },
  {
    "text": "Continuum go ahead and divide that ring into some number of slots um in this case it's 16 slots two to the four",
    "start": "784680",
    "end": "790440"
  },
  {
    "start": "786000",
    "end": "870000"
  },
  {
    "text": "usually the ring is divided into into manyu Min or slots U the the library is doing this your library is doing this",
    "start": "790440",
    "end": "795800"
  },
  {
    "text": "for you um and now when you have three servers let's say you have me you know node a node B node C you'd spread them",
    "start": "795800",
    "end": "801720"
  },
  {
    "text": "around around this ring um I'm not spreading them all the way around because the PowerPoint would get ugly um",
    "start": "801720",
    "end": "807279"
  },
  {
    "text": "but you can imagine them being spread all the way around and in fact they'd actually not be spread evenly around you'd sort of have pockets the library",
    "start": "807279",
    "end": "813000"
  },
  {
    "text": "sort of takes care of this for you it basically just takes care of spreading them and occupying different slots around so now you have a key and what",
    "start": "813000",
    "end": "819320"
  },
  {
    "text": "the library does takes the key hashes the key and puts it somewhere on the ring if that particular spot it put it",
    "start": "819320",
    "end": "825120"
  },
  {
    "text": "on didn't have a server sitting on it it sort of just goes clockwise until it finds until it finds a server now the",
    "start": "825120",
    "end": "831160"
  },
  {
    "text": "reason to do this is because that key shuffling that invalidation uh because of the fact you've added a node is",
    "start": "831160",
    "end": "837240"
  },
  {
    "text": "greatly minimized in this approach in fact it improves as you add um more keys",
    "start": "837240",
    "end": "842800"
  },
  {
    "text": "all right so that's why you want use our libraries um or any library that provides consistent hashing not just the",
    "start": "842800",
    "end": "848600"
  },
  {
    "text": "elastic cash libraries you want to make sure using consistent hashing the benefit again of the elastic cash libraries is they hand handle not only",
    "start": "848600",
    "end": "855079"
  },
  {
    "text": "this but they handle the autodiscovery aspect also we'll talk in a minute in in a few minutes about strategies for",
    "start": "855079",
    "end": "861160"
  },
  {
    "text": "handling autodiscovery if you're not if you're not able to use our our clients all right so memory and monitoring um",
    "start": "861160",
    "end": "868320"
  },
  {
    "text": "let's talk about the internals of of MCD I said before it's a slab allocator model this is what uh MCD is under the",
    "start": "868320",
    "end": "874279"
  },
  {
    "start": "870000",
    "end": "898000"
  },
  {
    "text": "hood it's really several small caches it's a they're called slabs uh the slabs are essentially just",
    "start": "874279",
    "end": "881079"
  },
  {
    "text": "devoted to a slab of memory uh is devoted to a particular size of an",
    "start": "881079",
    "end": "886759"
  },
  {
    "text": "object and what MCD does is as objects are coming in it's sort of bucketization",
    "start": "886759",
    "end": "892079"
  },
  {
    "start": "898000",
    "end": "962000"
  },
  {
    "text": "you get to the point where you can look at that information issue a command called stat slabs and it will give you a",
    "start": "899160",
    "end": "904880"
  },
  {
    "text": "breakdown of how many slabs it's created and the chunk size that's allocated to each slab now you might notice something",
    "start": "904880",
    "end": "912000"
  },
  {
    "text": "these chunk sizes are pretty discreet so if it can fit in that chunk size grade if kind of if not it goes to the next one and the next one and the next one",
    "start": "912000",
    "end": "917560"
  },
  {
    "text": "and and the chunk SI and the object you're the that you're putting in the key the value and a little bit of overhead if it doesn't fit in that uh",
    "start": "917560",
    "end": "924880"
  },
  {
    "text": "chunk size perfectly meaning that it fits in its maybe in the first case 80k and that first slab size is 96 you're",
    "start": "924880",
    "end": "931040"
  },
  {
    "text": "actually going to end up wasting 96 uh 16 bytes and so you'll always have this notion of some some bite wastage some",
    "start": "931040",
    "end": "938000"
  },
  {
    "text": "space wastage that's okay that's the trade-off you make for the speed and so what begins happening is a mcash process",
    "start": "938000",
    "end": "944759"
  },
  {
    "text": "will sit there and hand out one megabyte pages to each slab as they need",
    "start": "944759",
    "end": "950360"
  },
  {
    "text": "them eventually you get to the point where mcash doesn't have any more memory um so it's very important to to think",
    "start": "950360",
    "end": "957040"
  },
  {
    "text": "about how you're managing memory and how you're managing uh your MCD",
    "start": "957040",
    "end": "962240"
  },
  {
    "start": "962000",
    "end": "1053000"
  },
  {
    "text": "cluster that's because there's no background Reaper process in mecd that actually goes and kind of throws things",
    "start": "962240",
    "end": "968560"
  },
  {
    "text": "away when they're they're no longer needed um that doesn't happen instead there's something called eviction",
    "start": "968560",
    "end": "974639"
  },
  {
    "text": "eviction is basically MD's way of saying hey I've run out of space in this particular slab I need to get rid of",
    "start": "974639",
    "end": "980839"
  },
  {
    "text": "something what can I get rid of and it goes and uses an algorithm lru uh uh",
    "start": "980839",
    "end": "986000"
  },
  {
    "text": "least recently use and it sort of just keeps track of every time an object's been accessed and and in a particular slab if it needs more memory it'll go",
    "start": "986000",
    "end": "991880"
  },
  {
    "text": "like to the back of whatever's been accessed and start throwing it out uh and then the question becomes hey",
    "start": "991880",
    "end": "997920"
  },
  {
    "text": "when I I thought when I set an object I set an expiration when I set a key um the key the the misnomer the expiry",
    "start": "997920",
    "end": "1004880"
  },
  {
    "text": "really has to do with um this data is valid up until this point it's not keep this data until this",
    "start": "1004880",
    "end": "1011600"
  },
  {
    "text": "point and what that does is if I request that key after that expiration Point MC goes hey that's not valid that's past",
    "start": "1011600",
    "end": "1017880"
  },
  {
    "text": "the expiration date this this Key's gone bad we have to throw it out and the example to the right really",
    "start": "1017880",
    "end": "1023680"
  },
  {
    "text": "is just showing that there is no Reaper process there's no process that goes through and sort of garbage collects out the memory out of out of your mcash",
    "start": "1023680",
    "end": "1030558"
  },
  {
    "text": "process if you turn off eviction you'll notice that this happens you're going to sit on keys and you could sort of list all the keys in a particular slab say",
    "start": "1030559",
    "end": "1037120"
  },
  {
    "text": "hey there's this key that's sitting there and it's long since expired that time stamp is way in the past let me go get it and see what it was and mcash",
    "start": "1037120",
    "end": "1043319"
  },
  {
    "text": "says ha fooled you I'm not giving it to you but it also says thank you because now I realized this key was just sitting",
    "start": "1043319",
    "end": "1049200"
  },
  {
    "text": "around doing nothing it will take that moment to clear out the key that's going to be a lot to keep",
    "start": "1049200",
    "end": "1054919"
  },
  {
    "start": "1053000",
    "end": "1087000"
  },
  {
    "text": "track of so use some use some aids to help you with that use some uh use some some tools uh PHP mcash admin is is a",
    "start": "1054919",
    "end": "1061640"
  },
  {
    "text": "really um handy tool that you can sit there and kind of uh download it gets really specific to the slabs and how",
    "start": "1061640",
    "end": "1067120"
  },
  {
    "text": "many slabs are running and the wastage in each slab and all that stuff and of course there's cloudwatch Amazon cloudwatch keeps track of all the",
    "start": "1067120",
    "end": "1072600"
  },
  {
    "text": "metrics and monitor uh and monitors all the aspects of your nodes anything that you put in Cloud watch you can set set",
    "start": "1072600",
    "end": "1078919"
  },
  {
    "text": "an alarm for any kind of breach of any kind of metric so I'd like to go into basically",
    "start": "1078919",
    "end": "1085559"
  },
  {
    "text": "what i' call um the lightning round um of use cases now I've come up with use",
    "start": "1085559",
    "end": "1091679"
  },
  {
    "start": "1087000",
    "end": "1106000"
  },
  {
    "text": "cases here this is a sampling um every no no two environments are exactly the same everybody's got a slightly",
    "start": "1091679",
    "end": "1096760"
  },
  {
    "text": "different environment and uh so use these as sort of a model to think about how you might",
    "start": "1096760",
    "end": "1103159"
  },
  {
    "text": "plug these in into your environment um so let's start with a model that you can sort of all relate to which is just your",
    "start": "1103159",
    "end": "1108919"
  },
  {
    "start": "1106000",
    "end": "1124000"
  },
  {
    "text": "classic uh web application um hosting infrastructure you've got a database",
    "start": "1108919",
    "end": "1114200"
  },
  {
    "text": "maybe you've got some external apis maybe you're providing the external apis and you want to drop in a cache and the",
    "start": "1114200",
    "end": "1119640"
  },
  {
    "text": "reality is dropping in a cache uh is quite easy start with something called lazy",
    "start": "1119640",
    "end": "1125360"
  },
  {
    "start": "1124000",
    "end": "1174000"
  },
  {
    "text": "caching this essentially says your your application call Flow calls out to a",
    "start": "1125360",
    "end": "1131200"
  },
  {
    "text": "database simply add a few uh a few lines in that uh call and every time it hits",
    "start": "1131200",
    "end": "1136600"
  },
  {
    "text": "the database or every and instead of hitting the database it's going to go and intercept and see if it can get that",
    "start": "1136600",
    "end": "1142000"
  },
  {
    "text": "key from a cache if it can't get the key from the cache it'll still get it from the database but now it's going to shove it",
    "start": "1142000",
    "end": "1147679"
  },
  {
    "text": "in the cache what I think this means is for all of you here who realize",
    "start": "1147679",
    "end": "1153640"
  },
  {
    "text": "I'm not really going to have any jokes in this presentation and are starting to fire up their laptops you can take five minutes to",
    "start": "1153640",
    "end": "1159919"
  },
  {
    "text": "fire up a mcash cluster or less and you can implement this in your code by the time you walk out of this room you can",
    "start": "1159919",
    "end": "1165720"
  },
  {
    "text": "have a fully uh functioning caching scenario and I do see a number of laptops opening",
    "start": "1165720",
    "end": "1171000"
  },
  {
    "text": "so that's that's totally fine um the opposite is what about crud",
    "start": "1171000",
    "end": "1176120"
  },
  {
    "start": "1174000",
    "end": "1219000"
  },
  {
    "text": "operations create you read update delete um and and how do you deal with C uh changes to the key or or timing uh uh",
    "start": "1176120",
    "end": "1184200"
  },
  {
    "text": "time issues where you want to deal with the changes to to the values you can do the same thing intercept those requests",
    "start": "1184200",
    "end": "1189640"
  },
  {
    "text": "to the database on the way in uh for any recut operations this basically gives you zero lag um between the time that uh",
    "start": "1189640",
    "end": "1198280"
  },
  {
    "text": "a key is put into the cach you're not having to wait for the uh lazy caching scenario and uh the other benefit here",
    "start": "1198280",
    "end": "1205520"
  },
  {
    "text": "is that if this is this is really powerful if you're looking for a way to sort of keep your database from getting thrashed if somebody starts to just you",
    "start": "1205520",
    "end": "1212200"
  },
  {
    "text": "know if you're hosting an API and it's being killed uh this keeps your database from just getting uh",
    "start": "1212200",
    "end": "1218520"
  },
  {
    "text": "hammered now again going back to that web example and specifically in an AWS",
    "start": "1218520",
    "end": "1224039"
  },
  {
    "start": "1219000",
    "end": "1278000"
  },
  {
    "text": "specific context where we have something called autoscaling where servers are dynamically being added and and and uh",
    "start": "1224039",
    "end": "1230000"
  },
  {
    "text": "being taken down based on some Auto scaling policy or based on a schedule then a common problem becomes well if I",
    "start": "1230000",
    "end": "1235320"
  },
  {
    "text": "have a shopping cart experience or a user experience that's running on that particular instance what do I do",
    "start": "1235320",
    "end": "1242120"
  },
  {
    "text": "um I'm going to lose my session data so a very common pattern is to externalize the session data so it really doesn't matter what instance you come into what",
    "start": "1242120",
    "end": "1248400"
  },
  {
    "text": "ec2 instance you come into you're all going to have access to the the same session data this is an example of",
    "start": "1248400",
    "end": "1253799"
  },
  {
    "text": "basically a few steps you can take um to modify your your R stack um to take",
    "start": "1253799",
    "end": "1261400"
  },
  {
    "text": "advantage of pushing in your your session data into mcash now you don't need to use sticky sessions you don't",
    "start": "1261400",
    "end": "1267600"
  },
  {
    "text": "need to always hit the same server any server that a client comes into if that if that instance dies if a new instance",
    "start": "1267600",
    "end": "1273200"
  },
  {
    "text": "comes up it doesn't matter you have a very flat linear pool of servers doing the same thing using a",
    "start": "1273200",
    "end": "1280279"
  },
  {
    "start": "1278000",
    "end": "1307000"
  },
  {
    "text": "python example and in this case reddis um you can do the same thing this is a",
    "start": "1280279",
    "end": "1285360"
  },
  {
    "text": "very popular um uh Jen redis uh example",
    "start": "1285360",
    "end": "1290640"
  },
  {
    "text": "uh you can specify sort of the prefix to all your sessions and now the same thing anytime you're going to hit this uh",
    "start": "1290640",
    "end": "1295880"
  },
  {
    "text": "server running uh D Jango framework all your session data is going to be",
    "start": "1295880",
    "end": "1301039"
  },
  {
    "text": "externalized now going back to our web example let's say you're the guy you're the person hosting that",
    "start": "1301039",
    "end": "1306679"
  },
  {
    "text": "API and somehow you want to use the cach to your advantage to limit how many folks can hit that API in a given",
    "start": "1306679",
    "end": "1313799"
  },
  {
    "start": "1307000",
    "end": "1380000"
  },
  {
    "text": "second this is a great use case it's such a great use case it's actually on Reedus's website um so I blatantly stole",
    "start": "1313799",
    "end": "1319840"
  },
  {
    "text": "it um but it's a it's a powerful use case because if you're going to host something and somebody wants to abuse",
    "start": "1319840",
    "end": "1325360"
  },
  {
    "text": "that or somebody wants to or maybe you want to have a tiered model where at a free tier you're offering a certain level of service and somebody kind of",
    "start": "1325360",
    "end": "1331640"
  },
  {
    "text": "Premium kind of moves up the stack and can pay for larger and larger access to your API this is one way to do it redus",
    "start": "1331640",
    "end": "1337279"
  },
  {
    "text": "is so incredibly fast that every single request could sort of be routed through to check where they are with regards to",
    "start": "1337279",
    "end": "1342440"
  },
  {
    "text": "their usage and uh increment that and uh if they exceed whatever",
    "start": "1342440",
    "end": "1348960"
  },
  {
    "text": "Target you've set for them you can send them back a message what you'll notice here is there's also something called expire so redus does have the ability to",
    "start": "1348960",
    "end": "1356679"
  },
  {
    "text": "said something and this is truly the expiration as opposed to eviction after 10 seconds in this case rdus will go",
    "start": "1356679",
    "end": "1362480"
  },
  {
    "text": "ahead and delete uh uh these Keys now the benefit here is that",
    "start": "1362480",
    "end": "1367919"
  },
  {
    "text": "anytime you have interaction somebody exceeds it um you really don't have to do",
    "start": "1367919",
    "end": "1373400"
  },
  {
    "text": "anything um it's taken care of for you um this logic generally if you try to implement on yourself can be quite",
    "start": "1373400",
    "end": "1379520"
  },
  {
    "text": "difficult now let's say that API you're hosting is something like hey kick off",
    "start": "1379520",
    "end": "1384640"
  },
  {
    "text": "an image resizing um resample some data uh do some code markup do some code",
    "start": "1384640",
    "end": "1391440"
  },
  {
    "text": "beautification whatever it is there's some asynchronous process you have in today's context you have single page",
    "start": "1391440",
    "end": "1397039"
  },
  {
    "text": "applications where it's just one page you don't really want to have the user wait for anything you don't want to have them sort of um be bottlenecked you want",
    "start": "1397039",
    "end": "1404360"
  },
  {
    "text": "to kick off some asynchronous process but yet have it complete very fast right this is a great place to drop uh that uh",
    "start": "1404360",
    "end": "1410640"
  },
  {
    "text": "that task drop that que or drop that uh task into a queue when that task finishes you can push it back into uh a",
    "start": "1410640",
    "end": "1417840"
  },
  {
    "text": "particular div or what have you uh there was a talk yesterday uh getting into your genes",
    "start": "1417840",
    "end": "1424960"
  },
  {
    "start": "1422000",
    "end": "1481000"
  },
  {
    "text": "where uh thermal Fisher got on stage and talked about how elasticache really has",
    "start": "1424960",
    "end": "1431000"
  },
  {
    "text": "turned into a way to externalize their memory between several discret components they go between EMR and inst",
    "start": "1431000",
    "end": "1438720"
  },
  {
    "text": "es and S3 and and a variety of ecosystems they sort of match the infrastructure component based on the",
    "start": "1438720",
    "end": "1444200"
  },
  {
    "text": "characteristics of the job that's being requested and they may have a scientist that's sitting there and sort of looking at genomic data and needs to slide",
    "start": "1444200",
    "end": "1450840"
  },
  {
    "text": "between different samples the only thing that can keep up with that is elastic cache the only thing that can keep up",
    "start": "1450840",
    "end": "1456320"
  },
  {
    "text": "with that is an in-memory solution and you can apply that to other scenarios too you may have a video scenario where",
    "start": "1456320",
    "end": "1461360"
  },
  {
    "text": "you're shoving if frames millions of if frames into a particular uh memory segment and then somebody could be",
    "start": "1461360",
    "end": "1467399"
  },
  {
    "text": "sliding around and saying i' like from this point to this point and you may say okay now send this off to rendering to",
    "start": "1467399",
    "end": "1473640"
  },
  {
    "text": "be able to ship that information as fast as you can you can think of elasticache as being sort of the Grand Central stration of that",
    "start": "1473640",
    "end": "1480960"
  },
  {
    "text": "experience I mentioned before Redd supports Pub sub um some common examples",
    "start": "1480960",
    "end": "1486279"
  },
  {
    "start": "1481000",
    "end": "1609000"
  },
  {
    "text": "would be chat inapp messaging online gaming whatever it is there's some scenarios here um it's supported right",
    "start": "1486279",
    "end": "1492360"
  },
  {
    "text": "out of the box this is something that you can run with right now you got multiple clients connecting um they all issue a subscribe command",
    "start": "1492360",
    "end": "1500320"
  },
  {
    "text": "subscribe command uh is the only subscribe and only and unsubscribe is the only thing they can do in that session but what can happen after that",
    "start": "1500360",
    "end": "1507520"
  },
  {
    "text": "is then you presumably have somebody else connecting sort of controlling messages and can issue a publish command",
    "start": "1507520",
    "end": "1514000"
  },
  {
    "text": "this scales Millions this can scale to Millions so you can facilitate uh a",
    "start": "1514000",
    "end": "1519880"
  },
  {
    "text": "great chat experience in inapp messaging experience whatever it is just with with what reddis has to offer out of the gate",
    "start": "1519880",
    "end": "1527120"
  },
  {
    "text": "a real popular use case of this um is with websockets if you think about our elastic uh our autoscaling example and",
    "start": "1527120",
    "end": "1534399"
  },
  {
    "text": "the difficulty of nodes coming in and out and maybe being provisioned on the Fly um are",
    "start": "1534399",
    "end": "1540679"
  },
  {
    "text": "crashing how do you scale that how do you scale that in a websocket context well the example on the left would be if",
    "start": "1540679",
    "end": "1547039"
  },
  {
    "text": "somebody was to uh communicate uh locally uh that message that's being",
    "start": "1547039",
    "end": "1552080"
  },
  {
    "text": "published to that particular in this case nodejs server um would only reach the clients that are connected to that",
    "start": "1552080",
    "end": "1557440"
  },
  {
    "text": "server how do you spread that across several instances especially when you have maybe an autoscaling um scenario",
    "start": "1557440",
    "end": "1562480"
  },
  {
    "text": "going on but with the same technique you're essentially externalizing that that communication",
    "start": "1562480",
    "end": "1568399"
  },
  {
    "text": "between the clients so you bring in you install uh node reddis and in this case",
    "start": "1568399",
    "end": "1574039"
  },
  {
    "text": "you instantiate a publish and a subscribe and now you move your your",
    "start": "1574039",
    "end": "1579720"
  },
  {
    "text": "message publishing out of of your uh normal Loop so now whenever there's",
    "start": "1579720",
    "end": "1585159"
  },
  {
    "text": "anybody publishes a message on that channel now you'll publish this to everybody",
    "start": "1585159",
    "end": "1590840"
  },
  {
    "text": "that's uh every client that's connected to that server and the last thing you have to do simply is to say when there",
    "start": "1590840",
    "end": "1597159"
  },
  {
    "text": "is a publish um instead of actually publishing it to my local client send it to the cach that'll turn around and",
    "start": "1597159",
    "end": "1602960"
  },
  {
    "text": "anybody else listening on that channel we'll get that",
    "start": "1602960",
    "end": "1607720"
  },
  {
    "text": "information reeda supports a lot of commands uh one of them is sorted sets",
    "start": "1608880",
    "end": "1615120"
  },
  {
    "start": "1609000",
    "end": "1659000"
  },
  {
    "text": "sorted set gives you the ability that whenever you add something into to a sorted set it's guaranteed uniqueness",
    "start": "1615120",
    "end": "1620600"
  },
  {
    "text": "and ordering real popular use cases is leaderboards I realize not everybody here is making",
    "start": "1620600",
    "end": "1626320"
  },
  {
    "text": "games they might be playing games right now but they're not making games but any business any business even a a business",
    "start": "1626320",
    "end": "1633880"
  },
  {
    "text": "like a retail business um has a critical metric everybody's sitting on some critical metric that drives their",
    "start": "1633880",
    "end": "1639960"
  },
  {
    "text": "business um usually you can come up surprising in any organization you come up with one critical metric that",
    "start": "1639960",
    "end": "1645200"
  },
  {
    "text": "everybody wants to know at that moment because it's sort of the pulse of the organization the closer you can get to reality or",
    "start": "1645200",
    "end": "1650360"
  },
  {
    "text": "Real Time with that metric uh the better nothing is going to be as fast as",
    "start": "1650360",
    "end": "1656120"
  },
  {
    "start": "1659000",
    "end": "1676000"
  },
  {
    "text": "this um I talked before about what if you're not running our our clients or what if there's a different",
    "start": "1660159",
    "end": "1667080"
  },
  {
    "text": "scenario um or what if you're using ingenic so one use case could be if you",
    "start": "1667080",
    "end": "1672640"
  },
  {
    "text": "if you are running ingenic to compile in the MC ingenic module you can take for any given URI",
    "start": "1672640",
    "end": "1678720"
  },
  {
    "text": "segment and move that entire thing into mcash D if you think back to that video example I mentioned suppose you have a",
    "start": "1678720",
    "end": "1685880"
  },
  {
    "text": "service where you got video cameras or some sort of instrumentation sitting in a variety of locations and multiple",
    "start": "1685880",
    "end": "1692960"
  },
  {
    "text": "parties potentially thousands of parties need access to that data that particular endpoint is not designed to be a server",
    "start": "1692960",
    "end": "1699039"
  },
  {
    "text": "you need to somehow fetch data off of that device and provide it in a scalable way in the case of video that might be",
    "start": "1699039",
    "end": "1706200"
  },
  {
    "text": "you know streams of data or streams of video information so instead now you can go and fetch that data from some endpoint take it break it into its",
    "start": "1706200",
    "end": "1713279"
  },
  {
    "text": "either individual time series or frame information and instead of actually putting that on dis potentially it's",
    "start": "1713279",
    "end": "1718640"
  },
  {
    "text": "millions of frames or individual frames maybe it's um millions of uh files",
    "start": "1718640",
    "end": "1723720"
  },
  {
    "text": "coming out of sequencing data whatever it is instead of putting it on disk you can put it directly into memory so now",
    "start": "1723720",
    "end": "1728919"
  },
  {
    "text": "when everybody whenever somebody requests a particular key space or URI um pattern that data can come straight",
    "start": "1728919",
    "end": "1735039"
  },
  {
    "text": "out of mcash now this approach will scale um truly you know to several million if not",
    "start": "1735039",
    "end": "1742240"
  },
  {
    "text": "further soenix is not one of those clients that we said supports uh autodiscovery how could you facilitate",
    "start": "1742240",
    "end": "1749279"
  },
  {
    "text": "that well one of the things you can do with the elastic cache platform is subscribe to Notifications notifications",
    "start": "1749279",
    "end": "1754600"
  },
  {
    "text": "about events in your cluster adding REM adding nodes removing nodes let's use that with our ingenic example to sort of",
    "start": "1754600",
    "end": "1761080"
  },
  {
    "text": "derive a um an example of what how you could",
    "start": "1761080",
    "end": "1766200"
  },
  {
    "start": "1763000",
    "end": "1822000"
  },
  {
    "text": "facilitate autodiscovery so let's say you add a node or you remove a node that publishes to an SNS topic which you",
    "start": "1766200",
    "end": "1772640"
  },
  {
    "text": "configure with the service that puts that message into a message cue and that queue is now",
    "start": "1772640",
    "end": "1778399"
  },
  {
    "text": "waiting so inside of your Autos scaling group you can run a very lightweight python script a python script can say",
    "start": "1778399",
    "end": "1783600"
  },
  {
    "text": "hey have there been any changes to my cluster have there been any changes to my Autos scaling group and if so it can",
    "start": "1783600",
    "end": "1790360"
  },
  {
    "text": "turn around and notify surf surf is is pretty popular right now how many folks any anybody using surf currently a few",
    "start": "1790360",
    "end": "1796440"
  },
  {
    "text": "folks out there what that can do is it can publish a message inside of the surf Network this whole Loop takes about a",
    "start": "1796440",
    "end": "1802240"
  },
  {
    "text": "second so you can re reconfigure your entire cluster in about a second this is just a sampling of the code basically",
    "start": "1802240",
    "end": "1808360"
  },
  {
    "text": "checking checking in sqsq um",
    "start": "1808360",
    "end": "1813799"
  },
  {
    "text": "sqsq it's checking sqs um for a message checking the apis for any",
    "start": "1813799",
    "end": "1819559"
  },
  {
    "text": "changes and then publishing that uh notifying the surf agent to wrap up uh from my side before I bring Frank on",
    "start": "1819559",
    "end": "1826080"
  },
  {
    "start": "1822000",
    "end": "1859000"
  },
  {
    "text": "stage is remember there's no real kind of serious authentication or really any encryption that happens between the",
    "start": "1826080",
    "end": "1832200"
  },
  {
    "text": "clients and the mcash servers mcash D servers are Reddit servers uh put them in private subnets secure them make sure",
    "start": "1832200",
    "end": "1837799"
  },
  {
    "text": "that the security groups are set up appropriately so that only access from whatever tier needs access gets access",
    "start": "1837799",
    "end": "1842960"
  },
  {
    "text": "to them um and where do you go from here think about your use cases that we went through look for uh make sure to take",
    "start": "1842960",
    "end": "1850159"
  },
  {
    "text": "advantage of multi-az use monitoring to figure out what's going on with your cluster so with that I'm going to invite Frank",
    "start": "1850159",
    "end": "1856080"
  },
  {
    "text": "upstage to to talk about uh cobby [Applause]",
    "start": "1856080",
    "end": "1866440"
  },
  {
    "start": "1859000",
    "end": "1893000"
  },
  {
    "text": "Frank good afternoon everyone thank you Sammy oh I'm getting used to this microphone sound even louder than normal",
    "start": "1866440",
    "end": "1872960"
  },
  {
    "text": "anyways um so I'm Frank weeb I'm a principal scientist with Adobe uh I'm part of a devops team that is uh",
    "start": "1872960",
    "end": "1879559"
  },
  {
    "text": "building has been developing and building an API management platform for about the last year or so so that'll be",
    "start": "1879559",
    "end": "1885519"
  },
  {
    "text": "one of the use cases we're going to talk about and I'm also going to talk about another one uh within what we call our shared Cloud which is part of Creative",
    "start": "1885519",
    "end": "1891440"
  },
  {
    "text": "Cloud so let's just kind of give you guys an overview of what else will be talking about so I'm going to just",
    "start": "1891440",
    "end": "1896720"
  },
  {
    "start": "1893000",
    "end": "1923000"
  },
  {
    "text": "quickly give everybody just a really brief overview of of what Adobe is and what we do and then I'm going to jump",
    "start": "1896720",
    "end": "1902080"
  },
  {
    "text": "into our two use cases that I want to share there's one each for mimc d as well as redus uh full disclosure I'll",
    "start": "1902080",
    "end": "1908639"
  },
  {
    "text": "spend more time on the redus than the mimc D one that's the one I'm more familiar with that's what we use on the API platform and then just some overall",
    "start": "1908639",
    "end": "1915840"
  },
  {
    "text": "best practices and lessons learned that we've used that we've learned over the last couple years of using elastic cache",
    "start": "1915840",
    "end": "1922760"
  },
  {
    "text": "so so what is Adobe well for those you not familiar with it uh our two primary",
    "start": "1922760",
    "end": "1927840"
  },
  {
    "start": "1923000",
    "end": "1969000"
  },
  {
    "text": "offerings are Creative Cloud and the digital marketing cloud and between those two really we are the only company",
    "start": "1927840",
    "end": "1933159"
  },
  {
    "text": "that in the world we believe that managers or delivers a set of feature-rich services to our customers",
    "start": "1933159",
    "end": "1939279"
  },
  {
    "text": "that allow them to to manage through everything through the creation through the production measuring and monetizing",
    "start": "1939279",
    "end": "1945399"
  },
  {
    "text": "of content uh to their customers so so that's that's the proposition that we offer to our customers is those two",
    "start": "1945399",
    "end": "1951480"
  },
  {
    "text": "things in from an API platform perspective we actually hope that as part of that is the need to integrate",
    "start": "1951480",
    "end": "1958120"
  },
  {
    "text": "those two clouds and we hope that we can become the glue that actually says that the way integration can occur between",
    "start": "1958120",
    "end": "1963480"
  },
  {
    "text": "those two clouds is through the use of apis and and apis exposed through the API",
    "start": "1963480",
    "end": "1968880"
  },
  {
    "text": "platform so if you if you look at you know overall corporately if you read some of the statistics so I I think a",
    "start": "1968880",
    "end": "1974080"
  },
  {
    "start": "1969000",
    "end": "2008000"
  },
  {
    "text": "few of them are pretty impressive we started our journey to as a software as a Service Company in terms of Creative",
    "start": "1974080",
    "end": "1979240"
  },
  {
    "text": "Cloud about 3 years ago so today we have just over 2.8 million uh paying subscribers to that on a digital",
    "start": "1979240",
    "end": "1986360"
  },
  {
    "text": "marketing perspective 64% of the excuse me Fortune 50 companies in the world use",
    "start": "1986360",
    "end": "1992039"
  },
  {
    "text": "our marketing Cloud to help them understand what their customers are are doing and their engagement models you",
    "start": "1992039",
    "end": "1998039"
  },
  {
    "text": "overall at the end of fy13 we're a little over 12,000 employees with just over $4 billion in Revenue so pretty",
    "start": "1998039",
    "end": "2005440"
  },
  {
    "text": "substantial company so in terms of the two use cases I'm",
    "start": "2005440",
    "end": "2010679"
  },
  {
    "start": "2008000",
    "end": "2116000"
  },
  {
    "text": "going to talk about today uh the first one is is something called uh shared Cloud so underneath that Creative Cloud",
    "start": "2010679",
    "end": "2017399"
  },
  {
    "text": "there's there's actually an underlying facilitating layer that we call shared Cloud it's actually the the mechanism",
    "start": "2017399",
    "end": "2022760"
  },
  {
    "text": "that actually manages all those assets for all the the subscribers to Creative Cloud and moving them back and forth",
    "start": "2022760",
    "end": "2028320"
  },
  {
    "text": "between for example their desktop and the storage that's in the cloud so as",
    "start": "2028320",
    "end": "2033399"
  },
  {
    "text": "part of um as part of that need of course is you could think that one of the key found ational services that",
    "start": "2033399",
    "end": "2039080"
  },
  {
    "text": "shared Cloud needs to offer is a synchronization service how do I synchronize uh assets that might be on a",
    "start": "2039080",
    "end": "2044320"
  },
  {
    "text": "user's desktop with assets their assets that are in the cloud so part of doing that says they need to keep track of",
    "start": "2044320",
    "end": "2049760"
  },
  {
    "text": "changes what changes occurred what what changes have actually happened against the actual cloud-based storage so they",
    "start": "2049760",
    "end": "2056240"
  },
  {
    "text": "need to keep they need to keep a properly sorted list of or Journal of changes that have occurred so the",
    "start": "2056240",
    "end": "2061320"
  },
  {
    "text": "synchronization Services understand what what state the assets are in both on the desktop and in the cloud so in order to",
    "start": "2061320",
    "end": "2067960"
  },
  {
    "text": "do that they they identified they needed a an atomic way to increment counters um",
    "start": "2067960",
    "end": "2073638"
  },
  {
    "text": "to be able to keep track of all of that and but they said we don't need to persist this data because at the end of the day we could actually go to the",
    "start": "2073639",
    "end": "2079280"
  },
  {
    "text": "databases and actually figure out what where this state actually was so so between that and the the uh the need for",
    "start": "2079280",
    "end": "2085839"
  },
  {
    "text": "availability they said we're going to use the elastic cach for me for MC D service so they they implemented",
    "start": "2085839",
    "end": "2091800"
  },
  {
    "text": "multiple clusters uh across different uh multiple azs and um they use this to",
    "start": "2091800",
    "end": "2097720"
  },
  {
    "text": "keep track of those counters that basically facilitate a a very uh well performing synchronization between the",
    "start": "2097720",
    "end": "2104079"
  },
  {
    "text": "desktop and the shared cloud storage itself so so that was their use case um I want to just overall just sort of say",
    "start": "2104079",
    "end": "2110760"
  },
  {
    "text": "it's basically a database offload use case at the end of the day right which is a very classic caching kind of",
    "start": "2110760",
    "end": "2116079"
  },
  {
    "start": "2116000",
    "end": "2124000"
  },
  {
    "text": "scenario so let's delve a little bit more into uh elastic cach for Rus so this is like I mentioned what we use uh",
    "start": "2116079",
    "end": "2123000"
  },
  {
    "text": "in the API platform and so of course this wouldn't be complete if I didn't throw up a one of our architecture",
    "start": "2123000",
    "end": "2128599"
  },
  {
    "start": "2124000",
    "end": "2176000"
  },
  {
    "text": "diagrams here so overall does this represents if you wish what how the API platform is sort of constructed and the",
    "start": "2128599",
    "end": "2135000"
  },
  {
    "text": "big box in the middle of there course is an API Gateway and you'll notice that sort of in a bar that's Crossing uh",
    "start": "2135000",
    "end": "2141359"
  },
  {
    "text": "every uh every one of the ec2 instances is a shared cach layer that's what we're talking about here that's what we use",
    "start": "2141359",
    "end": "2146920"
  },
  {
    "text": "elastic cache for redus for is to operate as that shared cach layer so we have an autoscaling group of ec2",
    "start": "2146920",
    "end": "2153319"
  },
  {
    "text": "instances I want to be able to share information across all of them and I want to make make sure that I can so I",
    "start": "2153319",
    "end": "2158520"
  },
  {
    "text": "can maintain High availability we want low latency obviously through the Gateway uh we have deployments in",
    "start": "2158520",
    "end": "2164319"
  },
  {
    "text": "multiple regions around the world and within each region of course we have multiple azs in each region and we use a",
    "start": "2164319",
    "end": "2169680"
  },
  {
    "text": "lot of VPC and VPC peering so that's sort of like the overall architecture of the API uh platform itself so again so",
    "start": "2169680",
    "end": "2178640"
  },
  {
    "start": "2176000",
    "end": "2268000"
  },
  {
    "text": "our use case was a little bit different than shared clouds uh so number one is we we actually were concerned about um",
    "start": "2178640",
    "end": "2185839"
  },
  {
    "text": "having uh more complex operations are performed in the cache yes we need to have incr Atomic incremental units but",
    "start": "2185839",
    "end": "2192359"
  },
  {
    "text": "we also wanted to be able to do sorted list and things like that we also wanted to be able to have something that would be able to persist if you wish to some",
    "start": "2192359",
    "end": "2199200"
  },
  {
    "text": "degree the contents of the cache between basically a primary cluster and a read replica cluster we are concerned about",
    "start": "2199200",
    "end": "2205680"
  },
  {
    "text": "availability and and read performance uh across multiple azs so we delve into the",
    "start": "2205680",
    "end": "2211400"
  },
  {
    "text": "the next set of slides around the architecture you'll see that we have multiple read replicas that we use and",
    "start": "2211400",
    "end": "2216480"
  },
  {
    "text": "we actually make sure that we use those for reads and we only do rights to the primary so because of these needs we",
    "start": "2216480",
    "end": "2222440"
  },
  {
    "text": "actually that's how we got to the decision around why are we going to which elastic cast service that we're going to use we chose redus for that",
    "start": "2222440",
    "end": "2229119"
  },
  {
    "text": "reason so our standard deployment in each of the regions looks like a primary cluster with uh at least one re replica",
    "start": "2229119",
    "end": "2236760"
  },
  {
    "text": "cluster in each of the A's that we have in that region so it's a much more complicated a little bit more",
    "start": "2236760",
    "end": "2243079"
  },
  {
    "text": "complicated kind of design and because of that design though because of our use of redus you you can see that we've been",
    "start": "2243079",
    "end": "2248240"
  },
  {
    "text": "able to scale our request load so starting back in March of this year we were handling about 1 million API",
    "start": "2248240",
    "end": "2253599"
  },
  {
    "text": "requests a day and by the end of October we're sitting at over 21 million requests per day that we're handling and",
    "start": "2253599",
    "end": "2259160"
  },
  {
    "text": "part of that reason that we're able to sustain that and live up with the low latency and the availability that we want is through the use of elasticas or",
    "start": "2259160",
    "end": "2265720"
  },
  {
    "text": "redus service so what does it look like architecturally well so we what we",
    "start": "2265720",
    "end": "2271880"
  },
  {
    "start": "2268000",
    "end": "2419000"
  },
  {
    "text": "started with out on the left actually is where we actually sort of started our journey with redus which was I think a a fairly simple model we actually",
    "start": "2271880",
    "end": "2278680"
  },
  {
    "text": "initially we started out with only uh so multi-az deployment Auto scaling groups for E2 instances and we actually",
    "start": "2278680",
    "end": "2285800"
  },
  {
    "text": "initially started with only the primary cluster we didn't even have the read replicas initially when we started down this path and so all the reads and wrs",
    "start": "2285800",
    "end": "2293000"
  },
  {
    "text": "were going to a single node and it's important as as Sammy mentioned is that these uh these clusters are actually a",
    "start": "2293000",
    "end": "2298240"
  },
  {
    "text": "cluster of one so there's not like there's multiple nodes in a cluster there clusters of one so we started",
    "start": "2298240",
    "end": "2304640"
  },
  {
    "text": "there and then quickly realized that you know that was really wasn't a very highly available scenario so we said we need read replicas so we then spun up a",
    "start": "2304640",
    "end": "2312240"
  },
  {
    "text": "read replica in the alternate AZ where um where we had the Gateway deployed and",
    "start": "2312240",
    "end": "2317520"
  },
  {
    "text": "we used asynch replication groups between the primary and the read replica in order to keep the read replica in",
    "start": "2317520",
    "end": "2322839"
  },
  {
    "text": "sync of course again that is an asynchronous operation whatever so in any moment in time the read replica",
    "start": "2322839",
    "end": "2328839"
  },
  {
    "text": "might be a little bit behind uh and one of the primary reasons might be behind is activity on the primary how much",
    "start": "2328839",
    "end": "2334280"
  },
  {
    "text": "activity is going on on the primary and how fast can replicated across so that's sort of where we started but then as we",
    "start": "2334280",
    "end": "2340880"
  },
  {
    "text": "started to do our performance and Benchmark testing on the Gateway we said you know we need to be able to evolve that we actually want to get every ounce",
    "start": "2340880",
    "end": "2346920"
  },
  {
    "text": "of performance we can uh out of our Gateway so we said what what can we do so we decided that we'd actually",
    "start": "2346920",
    "end": "2352880"
  },
  {
    "text": "Implement number one not only a two-tier caching architecture but also the idea of Now using multiple read replicas and",
    "start": "2352880",
    "end": "2359680"
  },
  {
    "text": "isolating the re a read replica in each of the azs and then actually writing",
    "start": "2359680",
    "end": "2365319"
  },
  {
    "text": "code we actually wrote some code on our gateways that actually looks at a preferred and Alternate read replica so",
    "start": "2365319",
    "end": "2371160"
  },
  {
    "text": "it's it we actually any we can actually take we can sustain an outage to a read replica in one availability Zone because",
    "start": "2371160",
    "end": "2377280"
  },
  {
    "text": "we actually know about the other one as well and we will switch back and forth between them automatically so that that not only",
    "start": "2377280",
    "end": "2384119"
  },
  {
    "text": "helps our availability and then but we also built in code as well that says that let's detect if that re that read replica my my normal read replica is now",
    "start": "2384119",
    "end": "2391720"
  },
  {
    "text": "available again and then switch back so that was additional service code that we wrote inside the Gateway itself so it",
    "start": "2391720",
    "end": "2397079"
  },
  {
    "text": "can manage between these multiple read replicas and then of course the primary is always there so all the wrs always go",
    "start": "2397079",
    "end": "2402680"
  },
  {
    "text": "to the primary and then the read replicas are asynchronously uh updated so so again an evolution so start maybe",
    "start": "2402680",
    "end": "2409319"
  },
  {
    "text": "where you need to and then sort of evolve based on what your needs are and and don't be afraid to actually write",
    "start": "2409319",
    "end": "2414599"
  },
  {
    "text": "some some custom code in there as well to be able to manage the re replicas themselves so couple really simple code",
    "start": "2414599",
    "end": "2422359"
  },
  {
    "start": "2419000",
    "end": "2475000"
  },
  {
    "text": "examples just again just to build on what Sammy talked about earlier it's not hard to actually use these at all as a service right I mean this is a code to",
    "start": "2422359",
    "end": "2428880"
  },
  {
    "text": "basically retrieve an API key from the cache it's very very simple it's just a few lines of code and and you're of and",
    "start": "2428880",
    "end": "2434880"
  },
  {
    "text": "running so that's that made our development that really accelerated our development by using elastic cache",
    "start": "2434880",
    "end": "2440160"
  },
  {
    "text": "versus doing it ourselves you know and here's a piece of the uh code that we actually use to basically test whether",
    "start": "2440160",
    "end": "2445880"
  },
  {
    "text": "or not our preferred read replica is actually available basically it's pinging to say is that read replica",
    "start": "2445880",
    "end": "2451680"
  },
  {
    "text": "available or not and the rest of the code would tell you that if it says it's not available it actually would flip the",
    "start": "2451680",
    "end": "2456720"
  },
  {
    "text": "status from let's say preferred to alternate and then continue using the alternate until another process came",
    "start": "2456720",
    "end": "2462599"
  },
  {
    "text": "around and said hey your normal preferred is now available let's go let's go convert it back because we always wanted to try and keep the the",
    "start": "2462599",
    "end": "2469359"
  },
  {
    "text": "traffic or the read traffic localized to the AZ itself so that was really what the purpose of of this",
    "start": "2469359",
    "end": "2475280"
  },
  {
    "start": "2475000",
    "end": "2483000"
  },
  {
    "text": "was so along the way again we learned a lot of things and uh I got feedback from",
    "start": "2475280",
    "end": "2480560"
  },
  {
    "text": "our shared Cloud team and then I'll ask I'll add ours as well so first of all just some general planning thoughts um",
    "start": "2480560",
    "end": "2487720"
  },
  {
    "start": "2483000",
    "end": "2588000"
  },
  {
    "text": "so number one remember one of the important things about using the elastic cast Services the no sizing your nodes",
    "start": "2487720",
    "end": "2493000"
  },
  {
    "text": "is very very important because number one when it to change your node size it's a disruptive operation right if you",
    "start": "2493000",
    "end": "2500440"
  },
  {
    "text": "start out with a a 16 Meg node or 16 gigabyte uh node and you decide you need to go to 32 gigb node you need to that's",
    "start": "2500440",
    "end": "2506640"
  },
  {
    "text": "a disruptive operation you need to make and change into your it's going to affect your software so so that's disruptive so size your nodes based on",
    "start": "2506640",
    "end": "2513839"
  },
  {
    "text": "not only what you think you need today but actually look forward a little bit in the future uh tuning is different uh",
    "start": "2513839",
    "end": "2519599"
  },
  {
    "text": "between the two things redus is a single-threaded uh environment or single threaded uh solution whatever so",
    "start": "2519599",
    "end": "2526160"
  },
  {
    "text": "remember that when you're choosing your node sizes so look for the right not only the right capacity node size but",
    "start": "2526160",
    "end": "2531800"
  },
  {
    "text": "also the performance of a single of a single CPU as well uh for that node size",
    "start": "2531800",
    "end": "2537119"
  },
  {
    "text": "um when you're talking about your cross cross a deployments again think about how you're going to deploy that think",
    "start": "2537119",
    "end": "2542319"
  },
  {
    "text": "about your read replicas where they're going to go think about how you're going to distribute your nodes and your MC",
    "start": "2542319",
    "end": "2547359"
  },
  {
    "text": "clusters so that you can properly plan these uh properly plan these as well so",
    "start": "2547359",
    "end": "2553119"
  },
  {
    "text": "and one other thing I want to harping back to what Sammy mentioned remember that there's really limits amount of security security authentication uh for",
    "start": "2553119",
    "end": "2560359"
  },
  {
    "text": "either of these uh Services right put them in private subnets in your VPC uh if you need to have external uh forces",
    "start": "2560359",
    "end": "2567680"
  },
  {
    "text": "like for us when we need to push an API key into a cache for example there's a separate command to control uh data flow",
    "start": "2567680",
    "end": "2573440"
  },
  {
    "text": "that we actually use that can come in and securely update the cache so again think about that as well if you if you",
    "start": "2573440",
    "end": "2578920"
  },
  {
    "text": "need to be able to basically influence something from in the cach from outside think about a secure command and control",
    "start": "2578920",
    "end": "2584160"
  },
  {
    "text": "mechanism at a li to get in there and do that so and then from from our shared",
    "start": "2584160",
    "end": "2591400"
  },
  {
    "text": "Cloud team uh one of the things that they actually did for their implementation was they actually didn't",
    "start": "2591400",
    "end": "2596440"
  },
  {
    "text": "they actually wrapped the the interactions with the uh elasticache for me mcash D around the historics command",
    "start": "2596440",
    "end": "2602960"
  },
  {
    "text": "which is actually open sourced uh through Netflix and they they did this because they actually wanted to be able",
    "start": "2602960",
    "end": "2608079"
  },
  {
    "text": "to handle things about how to handle an event that a timeout occurred on the cach or actually act as a circuit breakers they say if that in fact that",
    "start": "2608079",
    "end": "2614280"
  },
  {
    "text": "they've actually overloaded they think they're overloading the amount of uh work they're putting into the cach they wanted to be able to stop that as a",
    "start": "2614280",
    "end": "2619880"
  },
  {
    "text": "circuit breaker so they actually went to they actually wrappered if you wish the the references to mcash D actually",
    "start": "2619880",
    "end": "2626000"
  },
  {
    "text": "underneath the histri command uh as part of the synchron synchronization service I'm sorry they wrote the other thing",
    "start": "2626000",
    "end": "2632200"
  },
  {
    "text": "that they learned too is try wherever you can to use asynchronous type of API taxes versus synchronous",
    "start": "2632200",
    "end": "2638040"
  },
  {
    "text": "sometimes you experience uh situations where there might be timeouts against the the cach and when this happens think",
    "start": "2638040",
    "end": "2643640"
  },
  {
    "text": "about using that asynchronously and then also program in retries so that it automatically will retry as part of your",
    "start": "2643640",
    "end": "2649720"
  },
  {
    "text": "service that's accessing the cache so you way that way you can kind of handle gracefully handle a problem in the event",
    "start": "2649720",
    "end": "2655160"
  },
  {
    "text": "that you do get the occasional timeout uh from the cash and again they continue to constantly evolve this uh this",
    "start": "2655160",
    "end": "2660920"
  },
  {
    "text": "approach in this architecture along the way uh one so just to give you guys some",
    "start": "2660920",
    "end": "2666319"
  },
  {
    "start": "2663000",
    "end": "2689000"
  },
  {
    "text": "idea of the key metrics from cloud watch that they that they watch the shared Cloud team watches so this is their",
    "start": "2666319",
    "end": "2671400"
  },
  {
    "text": "standard list I'm not going to uh read them all I don't think there's going to be a big lot of surprises here but this is what they watch when they want to",
    "start": "2671400",
    "end": "2677559"
  },
  {
    "text": "measure the health of their of their C of their MCD cash clusters uh to be able to sort of say how am I performing",
    "start": "2677559",
    "end": "2683599"
  },
  {
    "text": "that's where they look against it for patterns Etc to say how is how is the cash behaving",
    "start": "2683599",
    "end": "2689280"
  },
  {
    "start": "2689000",
    "end": "2841000"
  },
  {
    "text": "overall so from the elasticas shetta side um one of the things that uh that",
    "start": "2689280",
    "end": "2695119"
  },
  {
    "text": "Amazon offers actually Amazon web service offer is the automated recovery in the event that a primary node a",
    "start": "2695119",
    "end": "2700880"
  },
  {
    "text": "primary cluster itself fails so again remember it is a cluster of one so the fact that is great that Amazon handles",
    "start": "2700880",
    "end": "2707440"
  },
  {
    "text": "the automated recovery of that but it does take time so when we did some our initial benchmarking all of which by the",
    "start": "2707440",
    "end": "2713400"
  },
  {
    "text": "way was prior to the their announcements on 1024 we haven't gone back yet and re benchmarked is that it could take up to",
    "start": "2713400",
    "end": "2719200"
  },
  {
    "text": "10 minutes before that primary Comes Back available again so that was another reason why we looked at the two-tier",
    "start": "2719200",
    "end": "2725000"
  },
  {
    "text": "caching models we could actually cach those up dates even at inside a local caching tier inside the Gateway nodes",
    "start": "2725000",
    "end": "2731559"
  },
  {
    "text": "themselves until we recognize that the primary is available so again just plan for that if you're if you're having to",
    "start": "2731559",
    "end": "2737000"
  },
  {
    "text": "deal with that from an availability perspective plan for the fact that a node might be unavailable because it",
    "start": "2737000",
    "end": "2742119"
  },
  {
    "text": "could be in recovery it's great that it gets Auto recovered but just remember that it does take a little bit of time I",
    "start": "2742119",
    "end": "2747440"
  },
  {
    "text": "know in discussions with Amazon that one of the as a result of the work they did in October that this failover time should be much faster now so again we",
    "start": "2747440",
    "end": "2754000"
  },
  {
    "text": "just need to re Benchmark it ourselves and then always remember at least uh as of 1024 is that if you decided you ever",
    "start": "2754000",
    "end": "2760520"
  },
  {
    "text": "wanted to promote a read replica to become a primary that is a manual operation and again it takes time",
    "start": "2760520",
    "end": "2766800"
  },
  {
    "text": "because it has to handle all the any of the replication lag that goes on and because it has to be brought back up in",
    "start": "2766800",
    "end": "2772079"
  },
  {
    "text": "the sink before it again can be available to start processing operations so again great opportunity here for uh",
    "start": "2772079",
    "end": "2779160"
  },
  {
    "text": "maximizing your availability and not losing data but on the other hand remember that there may be times when",
    "start": "2779160",
    "end": "2784440"
  },
  {
    "text": "you have to deal with the fact that it might be unavailable for a short period of time uh and that really is what led",
    "start": "2784440",
    "end": "2790079"
  },
  {
    "text": "us into our two-tier caching approach and and leveraging multiple read replicas we wanted to address uh to try",
    "start": "2790079",
    "end": "2796359"
  },
  {
    "text": "and address anyways all these issues around what happens if we kind of Frank put on the hat saying what happens if",
    "start": "2796359",
    "end": "2801680"
  },
  {
    "text": "this a fails what happens if this read replica fails what happens if a primary fails and we're in the middle of trying",
    "start": "2801680",
    "end": "2806720"
  },
  {
    "text": "to do a fail over or Amazon's the middle of doing a fail over for all that we said how can we make sure that the",
    "start": "2806720",
    "end": "2811960"
  },
  {
    "text": "Gateway itself can continue to operate at as much as a Peak Performance as it can and that led us to the idea of not",
    "start": "2811960",
    "end": "2818520"
  },
  {
    "text": "only the two-tiered cache but the idea that we actually track a primary and an alternate read replica for handling read",
    "start": "2818520",
    "end": "2824480"
  },
  {
    "text": "operations and then the local buffering of right operations within a node until the primary is available again so again",
    "start": "2824480",
    "end": "2831599"
  },
  {
    "text": "all of this this stuff I'm telling you here right now it is it is prior to the 1024 announcements from uh from Amazon",
    "start": "2831599",
    "end": "2837800"
  },
  {
    "text": "on elasticache autof failover improvements in terms of the cloud watch",
    "start": "2837800",
    "end": "2843319"
  },
  {
    "start": "2841000",
    "end": "2883000"
  },
  {
    "text": "message that we most particularly watch uh this is our list the one I think Sammy mentioned earlier the one to watch",
    "start": "2843319",
    "end": "2849119"
  },
  {
    "text": "that we're most interested in is replication lag uh so that to us is really an indicator about not only how",
    "start": "2849119",
    "end": "2855040"
  },
  {
    "text": "much activity is occurring on the right but how quickly all of those are getting moved over to the read replica we've not",
    "start": "2855040",
    "end": "2861520"
  },
  {
    "text": "we've noticed this usually very very fast but when when we did some testing when we do some high performance testing",
    "start": "2861520",
    "end": "2866920"
  },
  {
    "text": "on it we we're trying to Benchmark the Gateway we do notice that you know so that replication lag might increase a",
    "start": "2866920",
    "end": "2872440"
  },
  {
    "text": "little bit so just watch it just be careful about it just watch that as a normal function of your your daily operations especially if you have spiky",
    "start": "2872440",
    "end": "2878800"
  },
  {
    "text": "workloads because then you might actually see a trail lots of Rights and with that that is uh that is",
    "start": "2878800",
    "end": "2886520"
  },
  {
    "text": "our presentation this afternoon Sammy and I will be available outside the um outside the conference room thank you",
    "start": "2886520",
    "end": "2891680"
  },
  {
    "text": "very much for your time and attendance for [Music]",
    "start": "2891680",
    "end": "2897640"
  }
]
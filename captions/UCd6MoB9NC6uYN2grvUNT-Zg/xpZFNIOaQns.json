[
  {
    "start": "0",
    "end": "102000"
  },
  {
    "text": "hi my name is Emily Weber and I'm a",
    "start": "30",
    "end": "2700"
  },
  {
    "text": "machine learning specialist at Amazon",
    "start": "2700",
    "end": "4770"
  },
  {
    "text": "Web Services today we're going to learn",
    "start": "4770",
    "end": "6720"
  },
  {
    "text": "about hyper parameter tuning which is",
    "start": "6720",
    "end": "8580"
  },
  {
    "text": "also known as automatic model tuning",
    "start": "8580",
    "end": "10500"
  },
  {
    "text": "this is your deep dive",
    "start": "10500",
    "end": "14090"
  },
  {
    "text": "so first we're gonna quickly recap on",
    "start": "15009",
    "end": "18550"
  },
  {
    "text": "training jobs so if you remember from",
    "start": "18550",
    "end": "20380"
  },
  {
    "text": "our previous videos we we introduced",
    "start": "20380",
    "end": "22840"
  },
  {
    "text": "training jobs right it starts off with",
    "start": "22840",
    "end": "24400"
  },
  {
    "text": "most commonly your notebook instance you",
    "start": "24400",
    "end": "26050"
  },
  {
    "text": "got your ec2 instance that's situated on",
    "start": "26050",
    "end": "28300"
  },
  {
    "text": "top of your EBS volume and then in",
    "start": "28300",
    "end": "30009"
  },
  {
    "text": "common practices will call model dot fit",
    "start": "30009",
    "end": "32168"
  },
  {
    "text": "right and when we call model dot fit say",
    "start": "32169",
    "end": "34510"
  },
  {
    "text": "Jamaica it's gonna shoot our data out to",
    "start": "34510",
    "end": "36430"
  },
  {
    "text": "an s3 bucket either we're gonna do this",
    "start": "36430",
    "end": "39370"
  },
  {
    "text": "ourselves or sage maker is gonna copy it",
    "start": "39370",
    "end": "41290"
  },
  {
    "text": "over for us after that sage maker is",
    "start": "41290",
    "end": "44800"
  },
  {
    "text": "going to spin up additional ec2",
    "start": "44800",
    "end": "47410"
  },
  {
    "text": "instances and remember this is an",
    "start": "47410",
    "end": "49120"
  },
  {
    "text": "ephemeral cluster that is dedicated not",
    "start": "49120",
    "end": "51670"
  },
  {
    "text": "just to us but to this specific model",
    "start": "51670",
    "end": "54039"
  },
  {
    "text": "and so this ephemeral cluster comes",
    "start": "54039",
    "end": "56050"
  },
  {
    "text": "online additionally we're gonna have our",
    "start": "56050",
    "end": "58809"
  },
  {
    "text": "image living in an elastic container",
    "start": "58809",
    "end": "61600"
  },
  {
    "text": "registered right that's the actual code",
    "start": "61600",
    "end": "63309"
  },
  {
    "text": "that's gonna both train and run",
    "start": "63309",
    "end": "65320"
  },
  {
    "text": "inference on your model so you've got",
    "start": "65320",
    "end": "66580"
  },
  {
    "text": "your EC our registry sage maker will",
    "start": "66580",
    "end": "68830"
  },
  {
    "text": "copy that image onto that cluster right",
    "start": "68830",
    "end": "73119"
  },
  {
    "text": "so that's either one or a number of",
    "start": "73119",
    "end": "74890"
  },
  {
    "text": "docker containers that are copied onto",
    "start": "74890",
    "end": "77410"
  },
  {
    "text": "those instances and this process is",
    "start": "77410",
    "end": "79149"
  },
  {
    "text": "going to train after that training has",
    "start": "79149",
    "end": "81190"
  },
  {
    "text": "finished Sage Maker is gonna write the",
    "start": "81190",
    "end": "83380"
  },
  {
    "text": "trained model back to s3 right so you've",
    "start": "83380",
    "end": "86349"
  },
  {
    "text": "got that model artifact that's living in",
    "start": "86349",
    "end": "88240"
  },
  {
    "text": "your s3 bucket and best of all it is",
    "start": "88240",
    "end": "90160"
  },
  {
    "text": "after that model has finished training",
    "start": "90160",
    "end": "92770"
  },
  {
    "text": "down to the second that process comes",
    "start": "92770",
    "end": "95170"
  },
  {
    "text": "down right and so that's why we love",
    "start": "95170",
    "end": "96910"
  },
  {
    "text": "Sage Maker training jobs is because it's",
    "start": "96910",
    "end": "98800"
  },
  {
    "text": "scalable and cost efficient but wait",
    "start": "98800",
    "end": "101729"
  },
  {
    "text": "what's a tuning job right that's what",
    "start": "101729",
    "end": "104500"
  },
  {
    "start": "102000",
    "end": "374000"
  },
  {
    "text": "we're here to learn about let's check it",
    "start": "104500",
    "end": "105849"
  },
  {
    "text": "out",
    "start": "105849",
    "end": "106149"
  },
  {
    "text": "ISO hyper parameter tuning jobs let's",
    "start": "106149",
    "end": "109929"
  },
  {
    "text": "let's really own that term let's really",
    "start": "109929",
    "end": "111819"
  },
  {
    "text": "understand what's going on here so when",
    "start": "111819",
    "end": "113950"
  },
  {
    "text": "we're developing a hyper parameter",
    "start": "113950",
    "end": "115750"
  },
  {
    "text": "tuning job again most commonly we'll",
    "start": "115750",
    "end": "118300"
  },
  {
    "text": "start with the notebook instance right",
    "start": "118300",
    "end": "119890"
  },
  {
    "text": "and we're getting everything configured",
    "start": "119890",
    "end": "120970"
  },
  {
    "text": "we'll create what's called a tuner and",
    "start": "120970",
    "end": "123580"
  },
  {
    "text": "then we'll call tuner dot fit similar",
    "start": "123580",
    "end": "126670"
  },
  {
    "text": "flow here Sage makers gonna copy our",
    "start": "126670",
    "end": "129039"
  },
  {
    "text": "data out to s3 or we can push it over",
    "start": "129039",
    "end": "131500"
  },
  {
    "text": "either or after that we're gonna think",
    "start": "131500",
    "end": "134260"
  },
  {
    "text": "about model training in terms of rounds",
    "start": "134260",
    "end": "136900"
  },
  {
    "text": "actually we're gonna have multiple",
    "start": "136900",
    "end": "138250"
  },
  {
    "text": "rounds that we're gonna walk through for",
    "start": "138250",
    "end": "140050"
  },
  {
    "text": "the first round stage maker is gonna",
    "start": "140050",
    "end": "142420"
  },
  {
    "text": "spin up three different versions of our",
    "start": "142420",
    "end": "145480"
  },
  {
    "text": "model right and three we can specify",
    "start": "145480",
    "end": "148010"
  },
  {
    "text": "that but we're gonna get three different",
    "start": "148010",
    "end": "149540"
  },
  {
    "text": "hyper parameter settings and those are",
    "start": "149540",
    "end": "152090"
  },
  {
    "text": "all gonna live as separate training jobs",
    "start": "152090",
    "end": "154569"
  },
  {
    "text": "that the hyper parameter tuner is",
    "start": "154569",
    "end": "156799"
  },
  {
    "text": "actually operating as an Orchestrator so",
    "start": "156799",
    "end": "159440"
  },
  {
    "text": "it's gonna be running a large number of",
    "start": "159440",
    "end": "161239"
  },
  {
    "text": "sub training jobs and so those three",
    "start": "161239",
    "end": "163700"
  },
  {
    "text": "training jobs are gonna run again same",
    "start": "163700",
    "end": "165799"
  },
  {
    "text": "data same model just different settings",
    "start": "165799",
    "end": "169010"
  },
  {
    "text": "of the hyper parameters that process is",
    "start": "169010",
    "end": "171170"
  },
  {
    "text": "gonna train after that's finished the",
    "start": "171170",
    "end": "173569"
  },
  {
    "text": "results from that are going to be pulled",
    "start": "173569",
    "end": "175099"
  },
  {
    "text": "into a Bayesian optimizer and so that",
    "start": "175099",
    "end": "177920"
  },
  {
    "text": "Bayesian optimizer is coming out of the",
    "start": "177920",
    "end": "179540"
  },
  {
    "text": "Amazon Labs you can absolutely read a",
    "start": "179540",
    "end": "181099"
  },
  {
    "text": "couple of white papers to walk you",
    "start": "181099",
    "end": "182239"
  },
  {
    "text": "through how we're thinking about it and",
    "start": "182239",
    "end": "183560"
  },
  {
    "text": "so that is basically pulling in the",
    "start": "183560",
    "end": "186829"
  },
  {
    "text": "objective performance of that model",
    "start": "186829",
    "end": "188780"
  },
  {
    "text": "right so if we're interested in a you",
    "start": "188780",
    "end": "190700"
  },
  {
    "text": "see for example for operating under",
    "start": "190700",
    "end": "193160"
  },
  {
    "text": "class imbalance or if we're interested",
    "start": "193160",
    "end": "195049"
  },
  {
    "text": "in precision or recall or accuracy or",
    "start": "195049",
    "end": "197379"
  },
  {
    "text": "objective metrics star you can plug that",
    "start": "197379",
    "end": "200390"
  },
  {
    "text": "into the Bayesian optimizer so that's",
    "start": "200390",
    "end": "202099"
  },
  {
    "text": "round one round two is gonna start with",
    "start": "202099",
    "end": "205220"
  },
  {
    "text": "the Bayesian optimizer right it's",
    "start": "205220",
    "end": "206750"
  },
  {
    "text": "cognizant it's knowledgeable about what",
    "start": "206750",
    "end": "209959"
  },
  {
    "text": "happens the last round it's gonna look",
    "start": "209959",
    "end": "212419"
  },
  {
    "text": "at that objective criteria again for",
    "start": "212419",
    "end": "214280"
  },
  {
    "text": "example AUC and then the optimizer is",
    "start": "214280",
    "end": "216859"
  },
  {
    "text": "going to reinitialize three more models",
    "start": "216859",
    "end": "219500"
  },
  {
    "text": "right and these are different hyper",
    "start": "219500",
    "end": "221660"
  },
  {
    "text": "parameter settings right so not just",
    "start": "221660",
    "end": "224389"
  },
  {
    "text": "different from each other but different",
    "start": "224389",
    "end": "225919"
  },
  {
    "text": "from those first three models that we",
    "start": "225919",
    "end": "227630"
  },
  {
    "text": "ran and this is round two right and so",
    "start": "227630",
    "end": "230090"
  },
  {
    "text": "round two is reinitializing those three",
    "start": "230090",
    "end": "232519"
  },
  {
    "text": "separate models and so at this point",
    "start": "232519",
    "end": "233840"
  },
  {
    "text": "we've trained six separate models all on",
    "start": "233840",
    "end": "236959"
  },
  {
    "text": "different hyper parameters to identify",
    "start": "236959",
    "end": "238669"
  },
  {
    "text": "the best one and so in total we're gonna",
    "start": "238669",
    "end": "242120"
  },
  {
    "text": "walk through a large number of jobs",
    "start": "242120",
    "end": "243980"
  },
  {
    "text": "right and when you get to the end of",
    "start": "243980",
    "end": "245480"
  },
  {
    "text": "this we'll actually get a graph that's",
    "start": "245480",
    "end": "247489"
  },
  {
    "text": "gonna help us analyze it so down on that",
    "start": "247489",
    "end": "249470"
  },
  {
    "text": "x-axis right we have time in seconds",
    "start": "249470",
    "end": "251450"
  },
  {
    "text": "y-axis that's just your AUC and again",
    "start": "251450",
    "end": "253639"
  },
  {
    "text": "you can customize that AUC based on the",
    "start": "253639",
    "end": "256070"
  },
  {
    "text": "objective metric that you're trying to",
    "start": "256070",
    "end": "257389"
  },
  {
    "text": "optimize and so for that first period",
    "start": "257389",
    "end": "260000"
  },
  {
    "text": "stage maker is initializing those three",
    "start": "260000",
    "end": "262479"
  },
  {
    "text": "training jobs again under one umbrella",
    "start": "262479",
    "end": "265010"
  },
  {
    "text": "tuning job we're gonna pull that",
    "start": "265010",
    "end": "267440"
  },
  {
    "text": "objective criteria out so we're looking",
    "start": "267440",
    "end": "269360"
  },
  {
    "text": "at that AUC and then we're gonna",
    "start": "269360",
    "end": "271280"
  },
  {
    "text": "reinitialize three more models right and",
    "start": "271280",
    "end": "274280"
  },
  {
    "text": "hopefully that maximum and you see is",
    "start": "274280",
    "end": "276440"
  },
  {
    "text": "going to be slightly higher for each",
    "start": "276440",
    "end": "278599"
  },
  {
    "text": "period but the Bayesian optimizer it has",
    "start": "278599",
    "end": "281240"
  },
  {
    "text": "it's gonna be able to both explore and",
    "start": "281240",
    "end": "284110"
  },
  {
    "text": "maximize based on what it's learned and",
    "start": "284110",
    "end": "286520"
  },
  {
    "text": "so it's gonna be looking through",
    "start": "286520",
    "end": "288259"
  },
  {
    "text": "multiple areas in the hypothesis space",
    "start": "288259",
    "end": "290900"
  },
  {
    "text": "until it ultimately finds the best model",
    "start": "290900",
    "end": "293569"
  },
  {
    "text": "and so that's how we actually get to",
    "start": "293569",
    "end": "295310"
  },
  {
    "text": "those seven full rounds right so in this",
    "start": "295310",
    "end": "297740"
  },
  {
    "text": "case we actually trained 20 models total",
    "start": "297740",
    "end": "301370"
  },
  {
    "text": "and found the ultimate best one and so",
    "start": "301370",
    "end": "304639"
  },
  {
    "text": "how do we set up a hyper parameter",
    "start": "304639",
    "end": "306860"
  },
  {
    "text": "tuning job well the good news is that",
    "start": "306860",
    "end": "308180"
  },
  {
    "text": "it's easy to do might sound scary but",
    "start": "308180",
    "end": "310849"
  },
  {
    "text": "it's actually pretty accessible so the",
    "start": "310849",
    "end": "313130"
  },
  {
    "text": "first thing we're gonna need is that",
    "start": "313130",
    "end": "314509"
  },
  {
    "text": "objective metric right and that's going",
    "start": "314509",
    "end": "316520"
  },
  {
    "text": "to be a you see on your validation data",
    "start": "316520",
    "end": "318889"
  },
  {
    "text": "that's your binary classification",
    "start": "318889",
    "end": "320240"
  },
  {
    "text": "accuracy that's your precision that's",
    "start": "320240",
    "end": "322370"
  },
  {
    "text": "your recall there there's a lot of",
    "start": "322370",
    "end": "324830"
  },
  {
    "text": "content out there for evaluating machine",
    "start": "324830",
    "end": "326870"
  },
  {
    "text": "learning models and so you want to pick",
    "start": "326870",
    "end": "328159"
  },
  {
    "text": "one and then plug that into your tuner",
    "start": "328159",
    "end": "329990"
  },
  {
    "text": "the second thing you need to identify",
    "start": "329990",
    "end": "331699"
  },
  {
    "text": "are the actual hyper parameters and the",
    "start": "331699",
    "end": "335090"
  },
  {
    "text": "ranges that you wanted to so in the case",
    "start": "335090",
    "end": "337220"
  },
  {
    "text": "of X you boost a hyper parameter might",
    "start": "337220",
    "end": "339919"
  },
  {
    "text": "be the maximum depth to your tree in the",
    "start": "339919",
    "end": "342259"
  },
  {
    "text": "case of a deep learning model it might",
    "start": "342259",
    "end": "344120"
  },
  {
    "text": "be the actual learning rate and then for",
    "start": "344120",
    "end": "346669"
  },
  {
    "text": "all of those hyper parameters that you",
    "start": "346669",
    "end": "348740"
  },
  {
    "text": "pick you just want to check the ranges",
    "start": "348740",
    "end": "351139"
  },
  {
    "text": "on those so if you're doing maximum",
    "start": "351139",
    "end": "352639"
  },
  {
    "text": "depth through your trees you might be",
    "start": "352639",
    "end": "354469"
  },
  {
    "text": "going from a maximum depth of one out to",
    "start": "354469",
    "end": "356449"
  },
  {
    "text": "say ten fifteen or twenty and again each",
    "start": "356449",
    "end": "359240"
  },
  {
    "text": "of those is gonna slightly modify the",
    "start": "359240",
    "end": "361880"
  },
  {
    "text": "performance of that model the last thing",
    "start": "361880",
    "end": "363770"
  },
  {
    "text": "you need to set up are really just the",
    "start": "363770",
    "end": "364969"
  },
  {
    "text": "job spec so you want to be thinking",
    "start": "364969",
    "end": "366349"
  },
  {
    "text": "about the total number of jobs you want",
    "start": "366349",
    "end": "368240"
  },
  {
    "text": "to run against the number of jobs are",
    "start": "368240",
    "end": "370069"
  },
  {
    "text": "going to run in parallel right so",
    "start": "370069",
    "end": "371630"
  },
  {
    "text": "periods of time and so the good news is",
    "start": "371630",
    "end": "375229"
  },
  {
    "start": "374000",
    "end": "656000"
  },
  {
    "text": "that you can absolutely",
    "start": "375229",
    "end": "376940"
  },
  {
    "text": "use Hyper parameter tuning with your own",
    "start": "376940",
    "end": "379009"
  },
  {
    "text": "model right so you can first off you can",
    "start": "379009",
    "end": "381289"
  },
  {
    "text": "use hyper parameter tuning with those",
    "start": "381289",
    "end": "382909"
  },
  {
    "text": "built-in algorithms again the 17",
    "start": "382909",
    "end": "385550"
  },
  {
    "text": "built-in algorithms that come off the",
    "start": "385550",
    "end": "387080"
  },
  {
    "text": "shelf with sage maker those are",
    "start": "387080",
    "end": "388490"
  },
  {
    "text": "absolutely available to perform hyper",
    "start": "388490",
    "end": "391099"
  },
  {
    "text": "parameter tuning on but for both",
    "start": "391099",
    "end": "393409"
  },
  {
    "text": "bringing your own model in docker and",
    "start": "393409",
    "end": "395719"
  },
  {
    "text": "with bringing your own model in the",
    "start": "395719",
    "end": "397430"
  },
  {
    "text": "script mode you can utilize the hyper",
    "start": "397430",
    "end": "399440"
  },
  {
    "text": "parameter tuner in a fully customizable",
    "start": "399440",
    "end": "401900"
  },
  {
    "text": "manner so we're gonna walk through how",
    "start": "401900",
    "end": "403699"
  },
  {
    "text": "to set that up so really what we need to",
    "start": "403699",
    "end": "406159"
  },
  {
    "text": "set up is just a single dictionary right",
    "start": "406159",
    "end": "408680"
  },
  {
    "text": "that's one JSON object that's called",
    "start": "408680",
    "end": "410870"
  },
  {
    "text": "your hyper parameters in this case we're",
    "start": "410870",
    "end": "412880"
  },
  {
    "text": "looking at batch size data augmentation",
    "start": "412880",
    "end": "415070"
  },
  {
    "text": "earning rate so we're picking again",
    "start": "415070",
    "end": "416990"
  },
  {
    "text": "those hyper parameters and then we're",
    "start": "416990",
    "end": "419000"
  },
  {
    "text": "thinking about what the ranges and the",
    "start": "419000",
    "end": "420440"
  },
  {
    "text": "initial settings are going to be and so",
    "start": "420440",
    "end": "423200"
  },
  {
    "text": "also if you're thinking well hey I",
    "start": "423200",
    "end": "425090"
  },
  {
    "text": "really like the tuner but I'm not trying",
    "start": "425090",
    "end": "427520"
  },
  {
    "text": "to wait for you know seven rounds I",
    "start": "427520",
    "end": "429830"
  },
  {
    "text": "actually want all those jobs tuned at",
    "start": "429830",
    "end": "431570"
  },
  {
    "text": "the same time and so the good news for",
    "start": "431570",
    "end": "433190"
  },
  {
    "text": "you is that we have random search",
    "start": "433190",
    "end": "434900"
  },
  {
    "text": "so the Bayesian optimizer over there on",
    "start": "434900",
    "end": "437030"
  },
  {
    "text": "the left hand side that's going to be",
    "start": "437030",
    "end": "438530"
  },
  {
    "text": "running through periods right so you",
    "start": "438530",
    "end": "440060"
  },
  {
    "text": "have to wait until that entire process",
    "start": "440060",
    "end": "442550"
  },
  {
    "text": "is finished or until the performance on",
    "start": "442550",
    "end": "445250"
  },
  {
    "text": "your model has stopped increasing right",
    "start": "445250",
    "end": "447620"
  },
  {
    "text": "you can actually enable early staffing",
    "start": "447620",
    "end": "449150"
  },
  {
    "text": "but so the Bayesian search is gonna take",
    "start": "449150",
    "end": "450590"
  },
  {
    "text": "some period in time and that's because",
    "start": "450590",
    "end": "452570"
  },
  {
    "text": "for each round it's explicitly getting",
    "start": "452570",
    "end": "455240"
  },
  {
    "text": "more intelligent right it's utilized in",
    "start": "455240",
    "end": "457070"
  },
  {
    "text": "that Bayesian search but over there on",
    "start": "457070",
    "end": "458300"
  },
  {
    "text": "the right hand side you've also got",
    "start": "458300",
    "end": "460070"
  },
  {
    "text": "random search and so random search is",
    "start": "460070",
    "end": "461810"
  },
  {
    "text": "gonna unsurprisingly use random right so",
    "start": "461810",
    "end": "464480"
  },
  {
    "text": "it's randomly picking the hyper",
    "start": "464480",
    "end": "465860"
  },
  {
    "text": "parameters but the cool thing is that",
    "start": "465860",
    "end": "467840"
  },
  {
    "text": "it's gonna be able to do that all at the",
    "start": "467840",
    "end": "469310"
  },
  {
    "text": "same time right so if you've got a use",
    "start": "469310",
    "end": "471230"
  },
  {
    "text": "case where you need to literally find",
    "start": "471230",
    "end": "472850"
  },
  {
    "text": "the best model and you have 30 minutes",
    "start": "472850",
    "end": "475700"
  },
  {
    "text": "to do it right or maybe you'll have less",
    "start": "475700",
    "end": "477440"
  },
  {
    "text": "than that maybe you've got ten minutes",
    "start": "477440",
    "end": "478610"
  },
  {
    "text": "and so each of your models can train",
    "start": "478610",
    "end": "480680"
  },
  {
    "text": "within ten minutes but you actually want",
    "start": "480680",
    "end": "482150"
  },
  {
    "text": "to test out 50 different hyper parameter",
    "start": "482150",
    "end": "485210"
  },
  {
    "text": "settings random search is going to be",
    "start": "485210",
    "end": "487580"
  },
  {
    "text": "the method to use for that and so the",
    "start": "487580",
    "end": "490400"
  },
  {
    "text": "way you specify that is is actually",
    "start": "490400",
    "end": "492290"
  },
  {
    "text": "pretty accessible right so on the right",
    "start": "492290",
    "end": "494060"
  },
  {
    "text": "hand side that's setting up a tuner",
    "start": "494060",
    "end": "495650"
  },
  {
    "text": "right that's just a call from the hyper",
    "start": "495650",
    "end": "497390"
  },
  {
    "text": "parameter tuner we're gonna plug in our",
    "start": "497390",
    "end": "499820"
  },
  {
    "text": "stage maker estimator we've got that",
    "start": "499820",
    "end": "501620"
  },
  {
    "text": "objective metric name we've got the",
    "start": "501620",
    "end": "503120"
  },
  {
    "text": "hyper parameter ranges the maximum",
    "start": "503120",
    "end": "505250"
  },
  {
    "text": "number of jobs rates that's 20 jobs and",
    "start": "505250",
    "end": "507410"
  },
  {
    "text": "then the max parallel jobs and you can",
    "start": "507410",
    "end": "509300"
  },
  {
    "text": "just switch out your strategy so you can",
    "start": "509300",
    "end": "512030"
  },
  {
    "text": "just change your strategy to random",
    "start": "512030",
    "end": "513830"
  },
  {
    "text": "versus the default and so again early",
    "start": "513830",
    "end": "517039"
  },
  {
    "text": "stopping you can absolutely stop a model",
    "start": "517040",
    "end": "519800"
  },
  {
    "text": "early if it is not getting better in",
    "start": "519800",
    "end": "522229"
  },
  {
    "text": "this case we're setting up a tuner that",
    "start": "522229",
    "end": "523610"
  },
  {
    "text": "is an image classification tuner still",
    "start": "523610",
    "end": "527180"
  },
  {
    "text": "has that objective metric along with the",
    "start": "527180",
    "end": "528830"
  },
  {
    "text": "hyper parameter ranges and what here",
    "start": "528830",
    "end": "531830"
  },
  {
    "text": "we're gonna do is actually enable Auto",
    "start": "531830",
    "end": "533740"
  },
  {
    "text": "early stopping so you can just set that",
    "start": "533740",
    "end": "535970"
  },
  {
    "text": "Auto key and basically what it's going",
    "start": "535970",
    "end": "539150"
  },
  {
    "text": "to do is look at a number of jobs that",
    "start": "539150",
    "end": "542420"
  },
  {
    "text": "you've ran previously and it's going to",
    "start": "542420",
    "end": "544760"
  },
  {
    "text": "evaluate that objective metric and if",
    "start": "544760",
    "end": "546440"
  },
  {
    "text": "you're telling it to max",
    "start": "546440",
    "end": "548010"
  },
  {
    "text": "then the early stopping is going to say",
    "start": "548010",
    "end": "549660"
  },
  {
    "text": "well hey if that model has an increased",
    "start": "549660",
    "end": "552029"
  },
  {
    "text": "within a certain number of periods and I",
    "start": "552029",
    "end": "553890"
  },
  {
    "text": "definitely want to cut off that job and",
    "start": "553890",
    "end": "555390"
  },
  {
    "text": "so that's a way that you can both save",
    "start": "555390",
    "end": "557279"
  },
  {
    "text": "money and get better models because it's",
    "start": "557279",
    "end": "559650"
  },
  {
    "text": "gonna prevent your models from",
    "start": "559650",
    "end": "560820"
  },
  {
    "text": "overfitting and also is you can maximize",
    "start": "560820",
    "end": "565680"
  },
  {
    "text": "efficiency across tuning jobs by",
    "start": "565680",
    "end": "568230"
  },
  {
    "text": "utilizing warm start right so let's say",
    "start": "568230",
    "end": "571020"
  },
  {
    "text": "I am interested in training a model and",
    "start": "571020",
    "end": "573510"
  },
  {
    "text": "what I want to do is first run a parent",
    "start": "573510",
    "end": "576810"
  },
  {
    "text": "tuning job but then after that parent",
    "start": "576810",
    "end": "579270"
  },
  {
    "text": "doing tuning job has completed let's say",
    "start": "579270",
    "end": "581490"
  },
  {
    "text": "I still need to train my models right",
    "start": "581490",
    "end": "583140"
  },
  {
    "text": "because my objective performance just",
    "start": "583140",
    "end": "584400"
  },
  {
    "text": "isn't quite there yet rather than",
    "start": "584400",
    "end": "586860"
  },
  {
    "text": "starting from scratch you can actually",
    "start": "586860",
    "end": "588810"
  },
  {
    "text": "inherit that parent tuning job and that",
    "start": "588810",
    "end": "591750"
  },
  {
    "text": "parent tuning job is going to look at",
    "start": "591750",
    "end": "593190"
  },
  {
    "text": "everything that that Bayesian optimizer",
    "start": "593190",
    "end": "594900"
  },
  {
    "text": "found in the first case and then it's",
    "start": "594900",
    "end": "596850"
  },
  {
    "text": "going to apply that to the new tuning",
    "start": "596850",
    "end": "598920"
  },
  {
    "text": "job so in the case of warm start you're",
    "start": "598920",
    "end": "600870"
  },
  {
    "text": "still gonna need an identical algorithm",
    "start": "600870",
    "end": "602970"
  },
  {
    "text": "an identical data right so both of those",
    "start": "602970",
    "end": "605190"
  },
  {
    "text": "need to be the same so that means in the",
    "start": "605190",
    "end": "607350"
  },
  {
    "text": "new case when you're trying it out if",
    "start": "607350",
    "end": "608880"
  },
  {
    "text": "you took the log right or did some new",
    "start": "608880",
    "end": "610980"
  },
  {
    "text": "scaling you want to set up a separate",
    "start": "610980",
    "end": "613290"
  },
  {
    "text": "tuning job for that right but your",
    "start": "613290",
    "end": "614940"
  },
  {
    "text": "parent will be applied on new tuning",
    "start": "614940",
    "end": "618330"
  },
  {
    "text": "jobs that are still using that original",
    "start": "618330",
    "end": "620430"
  },
  {
    "text": "ETL process however you can also set up",
    "start": "620430",
    "end": "623940"
  },
  {
    "text": "transfer learning right so if you are",
    "start": "623940",
    "end": "625620"
  },
  {
    "text": "running a parent tuning job and then you",
    "start": "625620",
    "end": "627930"
  },
  {
    "text": "want to set up a child tuning job but",
    "start": "627930",
    "end": "630900"
  },
  {
    "text": "you want to add more data right because",
    "start": "630900",
    "end": "632940"
  },
  {
    "text": "maybe you got additional data sets or",
    "start": "632940",
    "end": "634890"
  },
  {
    "text": "maybe you did a different ETL strategy",
    "start": "634890",
    "end": "636750"
  },
  {
    "text": "but you still want to leverage those",
    "start": "636750",
    "end": "638610"
  },
  {
    "text": "previous jobs that you ran so today in",
    "start": "638610",
    "end": "641160"
  },
  {
    "text": "Amazon Sage maker you can leverage",
    "start": "641160",
    "end": "642720"
  },
  {
    "text": "transfer learning as it's called right",
    "start": "642720",
    "end": "645510"
  },
  {
    "text": "in order to pick up where a previous",
    "start": "645510",
    "end": "647580"
  },
  {
    "text": "parent tuning job left off and apply",
    "start": "647580",
    "end": "650310"
  },
  {
    "text": "that to a new child tuning job",
    "start": "650310",
    "end": "653510"
  },
  {
    "text": "leveraging more data which is pretty",
    "start": "653510",
    "end": "655620"
  },
  {
    "text": "awesome and then we can also compare",
    "start": "655620",
    "end": "659370"
  },
  {
    "start": "656000",
    "end": "1093000"
  },
  {
    "text": "results across tuning jobs right so that",
    "start": "659370",
    "end": "662070"
  },
  {
    "text": "parent child is gonna be really great at",
    "start": "662070",
    "end": "664020"
  },
  {
    "text": "letting us set up kind of a single flow",
    "start": "664020",
    "end": "666480"
  },
  {
    "text": "where we're thinking about one model and",
    "start": "666480",
    "end": "669000"
  },
  {
    "text": "helping it get better and better over",
    "start": "669000",
    "end": "670529"
  },
  {
    "text": "time but let's say you've been working",
    "start": "670529",
    "end": "671820"
  },
  {
    "text": "in a project for a month maybe a couple",
    "start": "671820",
    "end": "674339"
  },
  {
    "text": "weeks and you just want to pull the",
    "start": "674339",
    "end": "677220"
  },
  {
    "text": "results from all of your models right so",
    "start": "677220",
    "end": "679079"
  },
  {
    "text": "today you can use sage maker search",
    "start": "679079",
    "end": "681300"
  },
  {
    "text": "in order to do that this process is",
    "start": "681300",
    "end": "683160"
  },
  {
    "text": "basically setting that up this is",
    "start": "683160",
    "end": "685290"
  },
  {
    "text": "looking at an s3 URI right so as you",
    "start": "685290",
    "end": "687720"
  },
  {
    "text": "remember in sage maker we need to supply",
    "start": "687720",
    "end": "689640"
  },
  {
    "text": "an s3 location for our data in order to",
    "start": "689640",
    "end": "693270"
  },
  {
    "text": "run on Sage maker and so sage maker",
    "start": "693270",
    "end": "695070"
  },
  {
    "text": "search is gonna look at the s3 you are",
    "start": "695070",
    "end": "697800"
  },
  {
    "text": "eyes of all of our training jobs and",
    "start": "697800",
    "end": "699840"
  },
  {
    "text": "it's gonna see which ones have the word",
    "start": "699840",
    "end": "702270"
  },
  {
    "text": "that we are trying to identify within",
    "start": "702270",
    "end": "703920"
  },
  {
    "text": "that s3 URI and then it's gonna search",
    "start": "703920",
    "end": "706770"
  },
  {
    "text": "for him",
    "start": "706770",
    "end": "707250"
  },
  {
    "text": "you can look for where Training jobs",
    "start": "707250",
    "end": "709620"
  },
  {
    "text": "have completed versus not completed and",
    "start": "709620",
    "end": "712350"
  },
  {
    "text": "then you can also pull based on your",
    "start": "712350",
    "end": "715940"
  },
  {
    "text": "descending objective criteria right so",
    "start": "715940",
    "end": "718260"
  },
  {
    "text": "you can get the best performing models",
    "start": "718260",
    "end": "719870"
  },
  {
    "text": "utilizing sage maker search okay let's",
    "start": "719870",
    "end": "724500"
  },
  {
    "text": "check out an example all right",
    "start": "724500",
    "end": "729300"
  },
  {
    "text": "so over here this is our sage maker",
    "start": "729300",
    "end": "732090"
  },
  {
    "text": "notebook and just to orient you here",
    "start": "732090",
    "end": "733440"
  },
  {
    "text": "right this is the AWS console this is",
    "start": "733440",
    "end": "736740"
  },
  {
    "text": "Amazon sage maker",
    "start": "736740",
    "end": "737760"
  },
  {
    "text": "these are notebook instances this is one",
    "start": "737760",
    "end": "740220"
  },
  {
    "text": "I have online and then we're gonna jump",
    "start": "740220",
    "end": "742500"
  },
  {
    "text": "over to that open Jupiter here and",
    "start": "742500",
    "end": "746130"
  },
  {
    "text": "that's gonna take us to this location",
    "start": "746130",
    "end": "747780"
  },
  {
    "text": "and so this is our this is our Jupiter",
    "start": "747780",
    "end": "750180"
  },
  {
    "text": "home base right so let's check out this",
    "start": "750180",
    "end": "752610"
  },
  {
    "text": "first one so this is image",
    "start": "752610",
    "end": "753870"
  },
  {
    "text": "classification warm start and so this",
    "start": "753870",
    "end": "756810"
  },
  {
    "text": "notebook is available in the sage maker",
    "start": "756810",
    "end": "759870"
  },
  {
    "text": "examples right all of the demos that",
    "start": "759870",
    "end": "761490"
  },
  {
    "text": "we're gonna be looking at are available",
    "start": "761490",
    "end": "763320"
  },
  {
    "text": "publicly so you can always check them",
    "start": "763320",
    "end": "764730"
  },
  {
    "text": "out and then let's let's just give this",
    "start": "764730",
    "end": "766740"
  },
  {
    "text": "a click alright so automatic model",
    "start": "766740",
    "end": "771300"
  },
  {
    "text": "tuning here we go so this is an",
    "start": "771300",
    "end": "773190"
  },
  {
    "text": "end-to-end example that's gonna let us",
    "start": "773190",
    "end": "775740"
  },
  {
    "text": "perform image classification so this",
    "start": "775740",
    "end": "779250"
  },
  {
    "text": "should feel pretty familiar right we're",
    "start": "779250",
    "end": "780570"
  },
  {
    "text": "importing sage maker we've got our",
    "start": "780570",
    "end": "782070"
  },
  {
    "text": "execution role we've got our default",
    "start": "782070",
    "end": "784440"
  },
  {
    "text": "buckets okay we're gonna set up our",
    "start": "784440",
    "end": "787320"
  },
  {
    "text": "client here using photo 3 and then we're",
    "start": "787320",
    "end": "790020"
  },
  {
    "text": "gonna get the image right that's that",
    "start": "790020",
    "end": "791880"
  },
  {
    "text": "get image URI function that takes the",
    "start": "791880",
    "end": "793890"
  },
  {
    "text": "name of the built in algorithm that",
    "start": "793890",
    "end": "797190"
  },
  {
    "text": "we're going to be leveraging here all",
    "start": "797190",
    "end": "799650"
  },
  {
    "text": "right",
    "start": "799650",
    "end": "800520"
  },
  {
    "text": "pretty common flow we're gonna download",
    "start": "800520",
    "end": "802500"
  },
  {
    "text": "some data so this is from MX net right",
    "start": "802500",
    "end": "805800"
  },
  {
    "text": "and we're just going to be downloading",
    "start": "805800",
    "end": "807270"
  },
  {
    "text": "that using URL Lib in Python then we",
    "start": "807270",
    "end": "811470"
  },
  {
    "text": "have multiple channels here",
    "start": "811470",
    "end": "812970"
  },
  {
    "text": "that's our train and validation channel",
    "start": "812970",
    "end": "814889"
  },
  {
    "text": "and then this is going to use that AWS",
    "start": "814889",
    "end": "817740"
  },
  {
    "text": "CLI right so that's using AWS s3 copy",
    "start": "817740",
    "end": "821160"
  },
  {
    "text": "from our local notebook instance to our",
    "start": "821160",
    "end": "825420"
  },
  {
    "text": "s3 bucket there we go and then we're",
    "start": "825420",
    "end": "829470"
  },
  {
    "text": "gonna set up our output location because",
    "start": "829470",
    "end": "831089"
  },
  {
    "text": "again everything's gonna go back to into",
    "start": "831089",
    "end": "832889"
  },
  {
    "text": "s3 and so we've got our Apple location",
    "start": "832889",
    "end": "836069"
  },
  {
    "text": "we've got an s3 input here and so the s3",
    "start": "836069",
    "end": "839069"
  },
  {
    "text": "input is really combining all of those",
    "start": "839069",
    "end": "841259"
  },
  {
    "text": "steps that's gonna let us specify a few",
    "start": "841259",
    "end": "844079"
  },
  {
    "text": "other pieces there then let's set up the",
    "start": "844079",
    "end": "846120"
  },
  {
    "text": "hyper parameter tuning job so this is a",
    "start": "846120",
    "end": "850350"
  },
  {
    "text": "deep learning model and in particular",
    "start": "850350",
    "end": "852629"
  },
  {
    "text": "this is an image classification model so",
    "start": "852629",
    "end": "855029"
  },
  {
    "text": "there are couple hyper parameters that",
    "start": "855029",
    "end": "856620"
  },
  {
    "text": "we know right off the bat are going to",
    "start": "856620",
    "end": "858060"
  },
  {
    "text": "be really key here but let's start with",
    "start": "858060",
    "end": "860579"
  },
  {
    "text": "just the estimator right so we're set up",
    "start": "860579",
    "end": "862170"
  },
  {
    "text": "the estimator we've got our training",
    "start": "862170",
    "end": "864060"
  },
  {
    "text": "image and again that's just the code for",
    "start": "864060",
    "end": "866009"
  },
  {
    "text": "the algorithm saij make a roll that's",
    "start": "866009",
    "end": "868740"
  },
  {
    "text": "our resource convict right so that's one",
    "start": "868740",
    "end": "870750"
  },
  {
    "text": "p3 to excel that's three out pass sage",
    "start": "870750",
    "end": "873870"
  },
  {
    "text": "maker session all looking good and now",
    "start": "873870",
    "end": "876060"
  },
  {
    "text": "we're gonna set the hyper parameters so",
    "start": "876060",
    "end": "878100"
  },
  {
    "text": "this right here this is the number of",
    "start": "878100",
    "end": "880500"
  },
  {
    "text": "layers that are in our deep learning",
    "start": "880500",
    "end": "882509"
  },
  {
    "text": "model image shape right those are the",
    "start": "882509",
    "end": "884879"
  },
  {
    "text": "the channels that's RGB that's our pixel",
    "start": "884879",
    "end": "887100"
  },
  {
    "text": "height and width we're gonna be",
    "start": "887100",
    "end": "889500"
  },
  {
    "text": "identifying 257 different classes so",
    "start": "889500",
    "end": "892050"
  },
  {
    "text": "we'll specify that here we've got the",
    "start": "892050",
    "end": "894720"
  },
  {
    "text": "the number of samples in our training",
    "start": "894720",
    "end": "896430"
  },
  {
    "text": "data sets or just over 150,000 mini",
    "start": "896430",
    "end": "899670"
  },
  {
    "text": "batch size right if you've if you've",
    "start": "899670",
    "end": "902160"
  },
  {
    "text": "ever struggled as I have you'll you'll",
    "start": "902160",
    "end": "904589"
  },
  {
    "text": "figure out that your mini batch size",
    "start": "904589",
    "end": "905790"
  },
  {
    "text": "does need to be smaller than the number",
    "start": "905790",
    "end": "907949"
  },
  {
    "text": "of training samples you're utilizing",
    "start": "907949",
    "end": "909959"
  },
  {
    "text": "that that's key number of epochs right",
    "start": "909959",
    "end": "912899"
  },
  {
    "text": "so that's our full passes through the",
    "start": "912899",
    "end": "914160"
  },
  {
    "text": "data set SGD or right that's our",
    "start": "914160",
    "end": "916829"
  },
  {
    "text": "gradient descent optimizer and on we go",
    "start": "916829",
    "end": "919699"
  },
  {
    "text": "alright so now we're gonna set up the",
    "start": "919699",
    "end": "921720"
  },
  {
    "text": "hyper parameter tuner so first off we're",
    "start": "921720",
    "end": "925470"
  },
  {
    "text": "going to import a few things from stage",
    "start": "925470",
    "end": "927689"
  },
  {
    "text": "maker we've got the integer parameters",
    "start": "927689",
    "end": "930269"
  },
  {
    "text": "categorical continuous and hyper",
    "start": "930269",
    "end": "932339"
  },
  {
    "text": "parameter tuner so all those things we",
    "start": "932339",
    "end": "934199"
  },
  {
    "text": "need and here are the ranges right so",
    "start": "934199",
    "end": "937439"
  },
  {
    "text": "that's that's that one dictionary where",
    "start": "937439",
    "end": "939779"
  },
  {
    "text": "we have three hyper parameters we're",
    "start": "939779",
    "end": "941639"
  },
  {
    "text": "evaluating we know that they are",
    "start": "941639",
    "end": "944040"
  },
  {
    "text": "continuous parameters",
    "start": "944040",
    "end": "945500"
  },
  {
    "text": "and then we have the ranges right down",
    "start": "945500",
    "end": "948050"
  },
  {
    "text": "here that's our objective metric name",
    "start": "948050",
    "end": "949730"
  },
  {
    "text": "and if you're thinking well how do I",
    "start": "949730",
    "end": "951920"
  },
  {
    "text": "pick an objective metric first off",
    "start": "951920",
    "end": "954470"
  },
  {
    "text": "you'll probably have a personal",
    "start": "954470",
    "end": "955820"
  },
  {
    "text": "preference and if you've got a",
    "start": "955820",
    "end": "956780"
  },
  {
    "text": "preference you can write your own when",
    "start": "956780",
    "end": "958250"
  },
  {
    "text": "you're bringing your own model for the",
    "start": "958250",
    "end": "960020"
  },
  {
    "text": "built-in so you can just select it from",
    "start": "960020",
    "end": "961250"
  },
  {
    "text": "the documentation then we've got the",
    "start": "961250",
    "end": "963260"
  },
  {
    "text": "hyper parameter tuner all right that's",
    "start": "963260",
    "end": "965210"
  },
  {
    "text": "gonna take our estimator objective",
    "start": "965210",
    "end": "967130"
  },
  {
    "text": "metric named ranges trying to maximize",
    "start": "967130",
    "end": "970130"
  },
  {
    "text": "because in this case we're looking at",
    "start": "970130",
    "end": "971480"
  },
  {
    "text": "accuracy maximum is going to be doing",
    "start": "971480",
    "end": "973970"
  },
  {
    "text": "five jobs and we're looking at two",
    "start": "973970",
    "end": "975770"
  },
  {
    "text": "parallel okay then we call tuner dot",
    "start": "975770",
    "end": "978410"
  },
  {
    "text": "fits and that's tricky",
    "start": "978410",
    "end": "980360"
  },
  {
    "text": "taking our train and validation channels",
    "start": "980360",
    "end": "983090"
  },
  {
    "text": "right as 3 input terrine as 3 input",
    "start": "983090",
    "end": "985790"
  },
  {
    "text": "validation okay and so fortunately I",
    "start": "985790",
    "end": "989300"
  },
  {
    "text": "already ran this job and so when that",
    "start": "989300",
    "end": "991760"
  },
  {
    "text": "job finishes will pull that name in and",
    "start": "991760",
    "end": "993710"
  },
  {
    "text": "so that that's right down here so the",
    "start": "993710",
    "end": "995840"
  },
  {
    "text": "image classification project will pull",
    "start": "995840",
    "end": "998540"
  },
  {
    "text": "that in and then we're going to create a",
    "start": "998540",
    "end": "1002470"
  },
  {
    "text": "data frame on there is those results and",
    "start": "1002470",
    "end": "1005620"
  },
  {
    "text": "so these are the five jobs that we ran",
    "start": "1005620",
    "end": "1008860"
  },
  {
    "text": "previously pretty low objective metrics",
    "start": "1008860",
    "end": "1011800"
  },
  {
    "text": "right but those a low EPOC numbers so",
    "start": "1011800",
    "end": "1013690"
  },
  {
    "text": "this is this is purposes of a demo of",
    "start": "1013690",
    "end": "1016020"
  },
  {
    "text": "different learning rates here different",
    "start": "1016020",
    "end": "1018339"
  },
  {
    "text": "Momentum's different way decays alright",
    "start": "1018339",
    "end": "1021880"
  },
  {
    "text": "and so now we're gonna plot this and so",
    "start": "1021880",
    "end": "1025300"
  },
  {
    "text": "here we've got two models right and then",
    "start": "1025300",
    "end": "1028300"
  },
  {
    "text": "for the next period we ran a few more",
    "start": "1028300",
    "end": "1030130"
  },
  {
    "text": "models and that objective metric went up",
    "start": "1030130",
    "end": "1032100"
  },
  {
    "text": "considerably right even though it's it's",
    "start": "1032100",
    "end": "1034900"
  },
  {
    "text": "a pretty small scale so those the zoom",
    "start": "1034900",
    "end": "1037089"
  },
  {
    "text": "definitely makes it seem a little bit",
    "start": "1037089",
    "end": "1038290"
  },
  {
    "text": "bigger but it's still still pretty",
    "start": "1038290",
    "end": "1039459"
  },
  {
    "text": "helpful we'll take everything we can get",
    "start": "1039459",
    "end": "1041438"
  },
  {
    "text": "all right and so now we're gonna set up",
    "start": "1041439",
    "end": "1044230"
  },
  {
    "text": "using that warm start config right so",
    "start": "1044230",
    "end": "1046569"
  },
  {
    "text": "here's the parent tuning job name and",
    "start": "1046569",
    "end": "1048520"
  },
  {
    "text": "here's the warm start config so again",
    "start": "1048520",
    "end": "1051580"
  },
  {
    "text": "that's just an import from the sage",
    "start": "1051580",
    "end": "1053140"
  },
  {
    "text": "maker SDK we've got our identical",
    "start": "1053140",
    "end": "1055480"
  },
  {
    "text": "identical data and algorithm right and",
    "start": "1055480",
    "end": "1057940"
  },
  {
    "text": "then that takes the parent tuning job",
    "start": "1057940",
    "end": "1059890"
  },
  {
    "text": "name for this one and then we're gonna",
    "start": "1059890",
    "end": "1063010"
  },
  {
    "text": "set this up right just as a normal hyper",
    "start": "1063010",
    "end": "1065290"
  },
  {
    "text": "parameter tuner with everything else",
    "start": "1065290",
    "end": "1067930"
  },
  {
    "text": "pretty comparable and there we go and",
    "start": "1067930",
    "end": "1071380"
  },
  {
    "text": "the warm start config has been applied",
    "start": "1071380",
    "end": "1074100"
  },
  {
    "text": "right so now we know that this is going",
    "start": "1074100",
    "end": "1076990"
  },
  {
    "text": "to be utilizing everything that are",
    "start": "1076990",
    "end": "1078850"
  },
  {
    "text": "modeled",
    "start": "1078850",
    "end": "1079270"
  },
  {
    "text": "just learned in that previous tuning job",
    "start": "1079270",
    "end": "1081480"
  },
  {
    "text": "and so there we go you can keep walking",
    "start": "1081480",
    "end": "1085450"
  },
  {
    "text": "through this example it's gonna get you",
    "start": "1085450",
    "end": "1086980"
  },
  {
    "text": "the best model and then ultimately help",
    "start": "1086980",
    "end": "1089950"
  },
  {
    "text": "you set this up utilizing transfer",
    "start": "1089950",
    "end": "1091480"
  },
  {
    "text": "learning as well so let's let's switch",
    "start": "1091480",
    "end": "1093640"
  },
  {
    "start": "1093000",
    "end": "1192000"
  },
  {
    "text": "back so some pro tips right some some",
    "start": "1093640",
    "end": "1096430"
  },
  {
    "text": "some tricks of the trade here it is",
    "start": "1096430",
    "end": "1098800"
  },
  {
    "text": "definitely helpful to have one s3 bucket",
    "start": "1098800",
    "end": "1101620"
  },
  {
    "text": "per project that you are working on the",
    "start": "1101620",
    "end": "1103990"
  },
  {
    "text": "reason being if you have one s3 bucket",
    "start": "1103990",
    "end": "1106060"
  },
  {
    "text": "dedicated to your project it is a",
    "start": "1106060",
    "end": "1107980"
  },
  {
    "text": "million times easier to search for all",
    "start": "1107980",
    "end": "1110620"
  },
  {
    "text": "the models that are associated with that",
    "start": "1110620",
    "end": "1112360"
  },
  {
    "text": "project right just pull it in through",
    "start": "1112360",
    "end": "1113950"
  },
  {
    "text": "Sage maker search based on that s3 URI",
    "start": "1113950",
    "end": "1115960"
  },
  {
    "text": "you can certainly modify sage maker circ",
    "start": "1115960",
    "end": "1118780"
  },
  {
    "text": "utilising tags it's just there's less",
    "start": "1118780",
    "end": "1121660"
  },
  {
    "text": "work when it's already there and you",
    "start": "1121660",
    "end": "1123100"
  },
  {
    "text": "didn't have to add the tags and we like",
    "start": "1123100",
    "end": "1124450"
  },
  {
    "text": "that second Pro tip is that tuning jobs",
    "start": "1124450",
    "end": "1128080"
  },
  {
    "text": "are super parallelizable right so in",
    "start": "1128080",
    "end": "1131470"
  },
  {
    "text": "addition to one tuning job acting as an",
    "start": "1131470",
    "end": "1134470"
  },
  {
    "text": "Orchestrator right where that's gonna be",
    "start": "1134470",
    "end": "1136120"
  },
  {
    "text": "running 20 jobs for example with three",
    "start": "1136120",
    "end": "1138010"
  },
  {
    "text": "at a time there's no reason why you",
    "start": "1138010",
    "end": "1140230"
  },
  {
    "text": "can't run multiple tuning jobs at a",
    "start": "1140230",
    "end": "1142960"
  },
  {
    "text": "single time right so if you're trying to",
    "start": "1142960",
    "end": "1144280"
  },
  {
    "text": "tune a linear model also trying to tune",
    "start": "1144280",
    "end": "1147700"
  },
  {
    "text": "and actually boost also trying to tune K",
    "start": "1147700",
    "end": "1150370"
  },
  {
    "text": "nearest neighbors you can run all three",
    "start": "1150370",
    "end": "1152680"
  },
  {
    "text": "of those tuning jobs literally at the",
    "start": "1152680",
    "end": "1154360"
  },
  {
    "text": "same time and that's because there's no",
    "start": "1154360",
    "end": "1156010"
  },
  {
    "text": "dependency between those notes right",
    "start": "1156010",
    "end": "1157630"
  },
  {
    "text": "they're all just operating and then the",
    "start": "1157630",
    "end": "1159820"
  },
  {
    "text": "last pro tip for you is obviously",
    "start": "1159820",
    "end": "1160930"
  },
  {
    "text": "utilizing warm start right if you",
    "start": "1160930",
    "end": "1163090"
  },
  {
    "text": "previously learned about how your models",
    "start": "1163090",
    "end": "1165070"
  },
  {
    "text": "operating you definitely want to pull",
    "start": "1165070",
    "end": "1166780"
  },
  {
    "text": "that back in for the next time you run",
    "start": "1166780",
    "end": "1168550"
  },
  {
    "text": "your tuning job and so with that thank",
    "start": "1168550",
    "end": "1172120"
  },
  {
    "text": "you very much my name is Emily Weber I'm",
    "start": "1172120",
    "end": "1174250"
  },
  {
    "text": "a machine learning on web services and",
    "start": "1174250",
    "end": "1176590"
  },
  {
    "text": "I'm happy to talk with you today about",
    "start": "1176590",
    "end": "1178660"
  },
  {
    "text": "automatic model tuning and hyper",
    "start": "1178660",
    "end": "1181360"
  },
  {
    "text": "parameter tuning on Amazon Sage Maker",
    "start": "1181360",
    "end": "1182890"
  },
  {
    "text": "thank you",
    "start": "1182890",
    "end": "1185730"
  },
  {
    "text": "you",
    "start": "1191710",
    "end": "1193770"
  }
]
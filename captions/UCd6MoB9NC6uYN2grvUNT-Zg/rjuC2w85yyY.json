[
  {
    "start": "0",
    "end": "142000"
  },
  {
    "text": "hello and welcome to the session about how Disney streaming services and",
    "start": "1970",
    "end": "8040"
  },
  {
    "text": "TrueCar deliver web application for scale performance and availability my",
    "start": "8040",
    "end": "16020"
  },
  {
    "text": "name is Paul Shalom I'm senior Solutions Architect with AWS specialized in edge",
    "start": "16020",
    "end": "22910"
  },
  {
    "text": "services and perimeter protection we have an exciting session for you today",
    "start": "22910",
    "end": "28590"
  },
  {
    "text": "with two of our customers coming from different industries and presenting",
    "start": "28590",
    "end": "34559"
  },
  {
    "text": "different use cases both are dealing with scale challenges and migration",
    "start": "34559",
    "end": "41850"
  },
  {
    "text": "concerns so before we dive into the solutions let's meet our presenters hi",
    "start": "41850",
    "end": "51149"
  },
  {
    "text": "my name is Regis Wilson I work with chukar and my site reliability engineer for about four years",
    "start": "51149",
    "end": "56760"
  },
  {
    "text": "TrueCar is a digital marketplace for automobiles and we allow consumers to search and find their perfect used or",
    "start": "56760",
    "end": "63690"
  },
  {
    "text": "new car we certainly have been responsible for about 5% of used car",
    "start": "63690",
    "end": "69119"
  },
  {
    "text": "sales in the United States last year so very happy to be here thanks Thank You",
    "start": "69119",
    "end": "74520"
  },
  {
    "text": "regice and from business streaming services a Chindia a shock it's a",
    "start": "74520",
    "end": "80430"
  },
  {
    "text": "pleasure to be here I'm a Qin Tia I work in the content discovery team at Disney streaming services Disney streaming",
    "start": "80430",
    "end": "87509"
  },
  {
    "text": "services is Disney's arm of creating its flagship direct to consumer video",
    "start": "87509",
    "end": "92520"
  },
  {
    "text": "streaming platform prior to being Disney streaming services we were formerly",
    "start": "92520",
    "end": "97530"
  },
  {
    "text": "known as bamdeck where we were pioneers in the streaming and the live streaming space and we created solutions for likes",
    "start": "97530",
    "end": "104579"
  },
  {
    "text": "of MLB MLB TV Eurosport and HL and ESPN so it's been a long transition but we're",
    "start": "104579",
    "end": "111479"
  },
  {
    "text": "excited to bring a lot of the new stuff to your devices this is great thanks for",
    "start": "111479",
    "end": "117420"
  },
  {
    "text": "being up being here with us so while we have you here let's start with your solution so you're adding our more",
    "start": "117420",
    "end": "126659"
  },
  {
    "text": "premium content like life sports new shows and TV that brings",
    "start": "126659",
    "end": "133290"
  },
  {
    "text": "a lot more traffic to your site can you tell us what is your team responsible",
    "start": "133290",
    "end": "138420"
  },
  {
    "text": "for within the entire content delivery chain yeah absolutely I mean this needs a pretty large company so I think that",
    "start": "138420",
    "end": "145079"
  },
  {
    "start": "142000",
    "end": "224000"
  },
  {
    "text": "that's a good place to start delve deeper into exactly what I do and what the team does so again I'm on a",
    "start": "145079",
    "end": "150959"
  },
  {
    "text": "team called content discovery which primarily deals with all the metadata required for you know presenting",
    "start": "150959",
    "end": "159349"
  },
  {
    "text": "knowledge about the catalog that's available anything pertaining to recommendations delivering",
    "start": "159349",
    "end": "165060"
  },
  {
    "text": "recommendations at scale specifically one of the api's that we build is called a Search API and this API is kind of the",
    "start": "165060",
    "end": "173400"
  },
  {
    "text": "primary metadata service that all end-user applications will hit to load anything on their devices so it doesn't",
    "start": "173400",
    "end": "181169"
  },
  {
    "text": "matter what platform you are if you have if you have an apple app or you have an Android app Samsung Apple TV whatever it",
    "start": "181169",
    "end": "188310"
  },
  {
    "text": "may be at some point in the lifecycle of the device the application is going to hit the Search API and that's gonna be",
    "start": "188310",
    "end": "194220"
  },
  {
    "text": "its trigger for loading any content on its page so suffice to say it's a pretty critical thing if it doesn't work then",
    "start": "194220",
    "end": "201239"
  },
  {
    "text": "you're gonna see a lot of degradation in your application and in fact you're not gonna see anything so we serve anywhere",
    "start": "201239",
    "end": "207959"
  },
  {
    "text": "between a few hundred thousand requests per minute to serving over several million requests per minute depending on",
    "start": "207959",
    "end": "214440"
  },
  {
    "text": "the scale and depending on how many users are currently using the service so user experience just depends critically",
    "start": "214440",
    "end": "221010"
  },
  {
    "text": "on this being fast and reliable so with this newly added content and the",
    "start": "221010",
    "end": "227459"
  },
  {
    "start": "224000",
    "end": "405000"
  },
  {
    "text": "increase in traffic can you share with us what was the starting point what were",
    "start": "227459",
    "end": "235079"
  },
  {
    "text": "the challenges of the existing architecture yeah let's step back a",
    "start": "235079",
    "end": "240599"
  },
  {
    "text": "little bit because Search API and content discovery wasn't as big or",
    "start": "240599",
    "end": "245849"
  },
  {
    "text": "important as it is currently so where we started our humble beginnings was basically acting as the search service",
    "start": "245849",
    "end": "253109"
  },
  {
    "text": "for a subset of our partners and by partner I mean MLB TV euros for ESPN",
    "start": "253109",
    "end": "259979"
  },
  {
    "text": "whatever it may be but as we started to see this consolidation as our responsibility",
    "start": "259979",
    "end": "265760"
  },
  {
    "text": "within the company we became the primary meditator service the primary line of fire for this page load metadata so",
    "start": "265760",
    "end": "273740"
  },
  {
    "text": "we've basically transitioned from being basic a pretty simple REST API to having",
    "start": "273740",
    "end": "279890"
  },
  {
    "text": "to deal with all of these different platforms with all this relevant data that they need so we've had two",
    "start": "279890",
    "end": "286250"
  },
  {
    "text": "architecture API using graph QL which gives us the capability of creating a",
    "start": "286250",
    "end": "291350"
  },
  {
    "text": "schema of all the data that's available and allowing any platform to really choose to pick and choose what content",
    "start": "291350",
    "end": "297620"
  },
  {
    "text": "they actually want to get so that's what graph QL gives us in terms of flexibility however with that it also",
    "start": "297620",
    "end": "303470"
  },
  {
    "text": "has a darker side so graph QL is pretty CPU intensive which we'll get into how",
    "start": "303470",
    "end": "308510"
  },
  {
    "text": "that's influenced our architecture influenced your design and influenced the way in which we scale but coming",
    "start": "308510",
    "end": "314630"
  },
  {
    "text": "back to it we were serving anywhere between 30 to 50,000 requests per minute which isn't a small number but it isn't",
    "start": "314630",
    "end": "321770"
  },
  {
    "text": "a gigantic number either there other services out there that do far larger volumes but we started to move towards",
    "start": "321770",
    "end": "328130"
  },
  {
    "text": "this setting where we started to see started predicted we'd be servicing upwards of five million requests per",
    "start": "328130",
    "end": "334370"
  },
  {
    "text": "minute which is more than a few magnitudes larger than 50,000 requests per minute we were also in a single pool",
    "start": "334370",
    "end": "341750"
  },
  {
    "text": "in a single region because we weren't that critical of a service but now that we had the service ahead that had to",
    "start": "341750",
    "end": "348320"
  },
  {
    "text": "stay up that had to remain extremely low latency we had to basically develop a pattern in which we could stay up by",
    "start": "348320",
    "end": "355400"
  },
  {
    "text": "having our API housed in multiple pools across multiple regions in case if one",
    "start": "355400",
    "end": "360830"
  },
  {
    "text": "region fails we still have other regions one pool fails we still have other pools and finally you know we had pretty",
    "start": "360830",
    "end": "367370"
  },
  {
    "text": "variable latency but now given this critical standpoint we had to stay within the limits of servicing the life",
    "start": "367370",
    "end": "373970"
  },
  {
    "text": "cycle of a request within 100 milliseconds and the last point is that",
    "start": "373970",
    "end": "379510"
  },
  {
    "text": "initially we didn't have any form of personalization happening but now that we saw users coming in from multiple",
    "start": "379510",
    "end": "385490"
  },
  {
    "text": "different countries from you know multiple other variables influencing what metadata that should that they",
    "start": "385490",
    "end": "391370"
  },
  {
    "text": "should get our API basically had to be reor connected in such a fashion as to deliver about semi personalised and",
    "start": "391370",
    "end": "398300"
  },
  {
    "text": "personal content such as recommendations so suffice to say there was a long road",
    "start": "398300",
    "end": "403610"
  },
  {
    "text": "ahead these are ambitious goals I wonder what was the starting point from a",
    "start": "403610",
    "end": "410030"
  },
  {
    "start": "405000",
    "end": "507000"
  },
  {
    "text": "design perspective and how those challenges reflects into the actual",
    "start": "410030",
    "end": "416750"
  },
  {
    "text": "architecture you started off yeah let's actually dive a little deeper because we need to kind of understand",
    "start": "416750",
    "end": "423949"
  },
  {
    "text": "the architecture of this entire thing so the diagram on the right and basically depict the overall structure of my",
    "start": "423949",
    "end": "431479"
  },
  {
    "text": "initial application at the top we had route 53 handling all the DNS all the",
    "start": "431479",
    "end": "436940"
  },
  {
    "text": "requests would go through there they would end up at a load balancer level which would then split up those requests",
    "start": "436940",
    "end": "442100"
  },
  {
    "text": "across multiple origin servers denoted by the the search api boxes and the",
    "start": "442100",
    "end": "447289"
  },
  {
    "text": "search api instance itself lived on ec2 notes below that we actually had a data layer comprised of both Redis in the",
    "start": "447289",
    "end": "455150"
  },
  {
    "text": "form of ElastiCache and also elastic search as a true source of data now if",
    "start": "455150",
    "end": "460430"
  },
  {
    "text": "we talk about kind of the behavioral patterns that we saw with these incoming requests you have to remember that we",
    "start": "460430",
    "end": "466400"
  },
  {
    "text": "were live streaming a lot of live events so think of it as then the English Premier League is happening and there's",
    "start": "466400",
    "end": "472669"
  },
  {
    "text": "a match between Manchester United and Chelsea a lot of people are gonna sign on five minutes before the actual event",
    "start": "472669",
    "end": "479030"
  },
  {
    "text": "starts fortunately or unfortunately for us we have to deal with that and what this produces is basically a huge influx",
    "start": "479030",
    "end": "486169"
  },
  {
    "text": "of requests coming in at exactly the same time so we call this a thundering heart problem you probably know it is",
    "start": "486169",
    "end": "492320"
  },
  {
    "text": "something different but basically we're to contend with this and given the fact that were a pretty experimental team we",
    "start": "492320",
    "end": "499789"
  },
  {
    "text": "kind of followed a pattern of experimentation at this application layer and this data layer as to how we",
    "start": "499789",
    "end": "505280"
  },
  {
    "text": "could scale that's interesting so it sounds like you needed some more compute",
    "start": "505280",
    "end": "511280"
  },
  {
    "start": "507000",
    "end": "662000"
  },
  {
    "text": "power at the API layer wouldn't be just adding auto-scaling the API layer and",
    "start": "511280",
    "end": "519529"
  },
  {
    "text": "maybe scale horizontally to accommodate those spikes of thundering herd or some",
    "start": "519529",
    "end": "524900"
  },
  {
    "text": "others might know it as a flash crowd as a different term for that",
    "start": "524900",
    "end": "530360"
  },
  {
    "text": "that sounds very optimistic but in reality that's not how it works you can't just throw an in-built",
    "start": "530360",
    "end": "537319"
  },
  {
    "text": "solution at something that's a little more complicated a little more involved like this is so they're basically two",
    "start": "537319",
    "end": "544040"
  },
  {
    "text": "forms of scaling you can do any application layer one is vertical scaling and the second is horizontal",
    "start": "544040",
    "end": "550130"
  },
  {
    "text": "scaling so in terms of vertical scaling what this actually means is that if you're say is your bottleneck is CPU",
    "start": "550130",
    "end": "557149"
  },
  {
    "text": "then you're going to add more CPU units to your resources to allow maybe each of",
    "start": "557149",
    "end": "562910"
  },
  {
    "text": "those instances of the API to handle a larger volume of requests so initially what we did or naive approach was okay",
    "start": "562910",
    "end": "569449"
  },
  {
    "text": "we're running on C force let's make it a C for to Excel let's make it a for Excel",
    "start": "569449",
    "end": "574610"
  },
  {
    "text": "and eight Excel or sixteen Excel but as you can imagine there's a there's a limit to how many different types of",
    "start": "574610",
    "end": "580370"
  },
  {
    "text": "excels you have available to you unfortunately and moreover this is a",
    "start": "580370",
    "end": "585709"
  },
  {
    "text": "solution that doesn't really scale well with a variable number of requests coming in because you might provision a",
    "start": "585709",
    "end": "591769"
  },
  {
    "text": "really big node but then at some point you might just have a trickle of requests coming in which means you have",
    "start": "591769",
    "end": "597680"
  },
  {
    "text": "over provisioned you're overpaying and it's a solution that's not feasible the second form of scaling that we",
    "start": "597680",
    "end": "604610"
  },
  {
    "text": "started to experiment with was horizontal scaling and essentially what that means in a nutshell is below this",
    "start": "604610",
    "end": "610639"
  },
  {
    "text": "load balancer level that's splitting requests across the API you basically add more nodes so in this in this",
    "start": "610639",
    "end": "617750"
  },
  {
    "text": "depiction we have three different instances of API running on ec2 notes so",
    "start": "617750",
    "end": "623480"
  },
  {
    "text": "rather than three we scaled up to six maybe twelve maybe 72 but again you run",
    "start": "623480",
    "end": "628519"
  },
  {
    "text": "into the same sorts of issues where you're over provisioning for a lot of the time that you don't need that over",
    "start": "628519",
    "end": "633740"
  },
  {
    "text": "provisioning and secondly bringing up each new instance of our Search API was",
    "start": "633740",
    "end": "639199"
  },
  {
    "text": "a life cycle of about 10 minutes so when you when you're under duress when you have this thundering heart problem and",
    "start": "639199",
    "end": "644360"
  },
  {
    "text": "it takes 10 minutes to add each new node it's just not feasible because but it and that note comes up either the",
    "start": "644360",
    "end": "650720"
  },
  {
    "text": "traffic is gone or you have a lot of unhappy customers so it doesn't work out so basically neither vertical or",
    "start": "650720",
    "end": "657920"
  },
  {
    "text": "horizontal scaling on this application layer was a feasible solution that's interesting so we still have the problem",
    "start": "657920",
    "end": "664490"
  },
  {
    "start": "662000",
    "end": "810000"
  },
  {
    "text": "there I also wonder about the data layer itself but say you get more requests or",
    "start": "664490",
    "end": "671600"
  },
  {
    "text": "this spike was the data layer ready to for that load for that scale to support",
    "start": "671600",
    "end": "677960"
  },
  {
    "text": "that scale in an ideal world even if your application layer scales you've",
    "start": "677960",
    "end": "683750"
  },
  {
    "text": "uncovered a good point at the end of the day it's gonna have to go to this data layer it's gonna have to get the data",
    "start": "683750",
    "end": "689060"
  },
  {
    "text": "from somewhere the API doesn't have any concept of some ephemeral storage so the",
    "start": "689060",
    "end": "694850"
  },
  {
    "text": "way that we architected our application was Redis was a key value data store for us in which we basically had an l1 cache",
    "start": "694850",
    "end": "702830"
  },
  {
    "text": "of our data so a request would come in and goes to Redis if we can find an appropriate response it bubbles it back",
    "start": "702830",
    "end": "709460"
  },
  {
    "text": "up to the user if it if there's a cache miss then we go to elastic search which is our true source of data fetch the",
    "start": "709460",
    "end": "716480"
  },
  {
    "text": "metadata cached in Redis and in bubble it bubble it up again to the user but we",
    "start": "716480",
    "end": "721700"
  },
  {
    "text": "run to this into the similar horizontal and scaling issues for Redis the way that you provision Redis is you can",
    "start": "721700",
    "end": "727130"
  },
  {
    "text": "specify a number of nodes that you would like to have an ArrayList cluster adding",
    "start": "727130",
    "end": "732200"
  },
  {
    "text": "nodes is not that simple because again it takes some time to actually spin up those nodes and get it into the cluster",
    "start": "732200",
    "end": "737630"
  },
  {
    "text": "and second just changing the instance types of your Redis knows themselves",
    "start": "737630",
    "end": "742670"
  },
  {
    "text": "takes a lot of time to provision and sometimes you might need to provision an entirely new elastic elastic cache cluster or wait until it's ready with",
    "start": "742670",
    "end": "749840"
  },
  {
    "text": "the new node so even that isn't feasible with elastic search unfortunately the",
    "start": "749840",
    "end": "755930"
  },
  {
    "text": "problem gets even worse elastic search is great for for just doing a fuzzy search and things and the way that it's",
    "start": "755930",
    "end": "763430"
  },
  {
    "text": "basically architected is that it distributes the data by shorting the data across the number of nodes that are",
    "start": "763430",
    "end": "769970"
  },
  {
    "text": "available in real time if you add new nodes elastic search has to go through a",
    "start": "769970",
    "end": "776000"
  },
  {
    "text": "process of rebalancing the data across the new nodes and that V balancing process itself is blocking so elastic",
    "start": "776000",
    "end": "783500"
  },
  {
    "text": "search will start blocking some of those incoming requests while it executes this action of rebalancing the nodes so if",
    "start": "783500",
    "end": "789860"
  },
  {
    "text": "you start to rebalance your elastic search cluster under duress you're certainly going to exacerbate your",
    "start": "789860",
    "end": "794870"
  },
  {
    "text": "problem even so with this you know we saw red red is throttling we sell a sixer straddling",
    "start": "794870",
    "end": "801250"
  },
  {
    "text": "and then we saw a response times to shoot up beyond 100 milliseconds so there are a lot of problems even with",
    "start": "801250",
    "end": "808540"
  },
  {
    "text": "the data layer I see so if I summarized up to this point your team took an",
    "start": "808540",
    "end": "814270"
  },
  {
    "start": "810000",
    "end": "1033000"
  },
  {
    "text": "experimental approach to look where they're throwing more compute resources",
    "start": "814270",
    "end": "822130"
  },
  {
    "text": "the API layer might not be the optimal solution and then still supporting this",
    "start": "822130",
    "end": "827920"
  },
  {
    "text": "spike at the data layer my create a bottleneck which will impact the latency",
    "start": "827920",
    "end": "833170"
  },
  {
    "text": "on a request respond time affect the user experience and at the end might",
    "start": "833170",
    "end": "838300"
  },
  {
    "text": "hurt the business yeah absolutely so those tactical solutions seems that",
    "start": "838300",
    "end": "843640"
  },
  {
    "text": "not feasible and you needed more of a strategic direction to take here so I",
    "start": "843640",
    "end": "850030"
  },
  {
    "text": "wonder you know what was the next step what was the strategic direction so I",
    "start": "850030",
    "end": "856030"
  },
  {
    "text": "mean as we've shown here scaling is not it's you can't just throw out of scaling at this it doesn't work so we knew that",
    "start": "856030",
    "end": "863170"
  },
  {
    "text": "we had to basically push compute to a layer above all of this if we could push compute to a labor layer above our API",
    "start": "863170",
    "end": "870339"
  },
  {
    "text": "is above our data layer we could enable ourselves to basically handle a request at this compute lair without ever going",
    "start": "870339",
    "end": "876790"
  },
  {
    "text": "back without ever exacerbating CPU data graph QL without ever exacerbating this",
    "start": "876790",
    "end": "882010"
  },
  {
    "text": "this issue with rebalancing in elasticsearch so basically for us to",
    "start": "882010",
    "end": "887140"
  },
  {
    "text": "adopt the solution it had to satisfy three basic needs one was some form of",
    "start": "887140",
    "end": "893140"
  },
  {
    "text": "edge caching so edge caching in which the request comes in and you immediately",
    "start": "893140",
    "end": "898150"
  },
  {
    "text": "have a cache hit on whatever this computed layer has and the returns back the response without ever going back to",
    "start": "898150",
    "end": "903490"
  },
  {
    "text": "an Origin server second was our token validation so essentially we're passing",
    "start": "903490",
    "end": "909640"
  },
  {
    "text": "user information in part through an arts token in which we extract information",
    "start": "909640",
    "end": "915100"
  },
  {
    "text": "such as the location for the user so we need some some fashion bye-bye which in",
    "start": "915100",
    "end": "920170"
  },
  {
    "text": "this computer we can crack the token we can validate the token and we can also extract out meaningful details to return",
    "start": "920170",
    "end": "927670"
  },
  {
    "text": "back a response pertinent to the user vacation and finally you know we'd move through this to the setting in which we",
    "start": "927670",
    "end": "934660"
  },
  {
    "text": "no longer had a single pool and in an API or in a single region we had multiple pools in multiple regions so we",
    "start": "934660",
    "end": "941229"
  },
  {
    "text": "had to have some intelligent fashion by by which we could dynamically select the origin all of this while basically",
    "start": "941229",
    "end": "948369"
  },
  {
    "text": "keeping it in terms of a global availability highly available and also keeping that that response time that",
    "start": "948369",
    "end": "954489"
  },
  {
    "text": "critical metric that we had below 100 milliseconds so given all of this given",
    "start": "954489",
    "end": "960249"
  },
  {
    "text": "a little further research that we did the solution that we landed upon was in",
    "start": "960249",
    "end": "965349"
  },
  {
    "text": "fact CloudFront with the addition of lambda reg the reason being is that",
    "start": "965349",
    "end": "970599"
  },
  {
    "text": "CloudFront basically acts for us as an etch cache so you know a request comes",
    "start": "970599",
    "end": "976059"
  },
  {
    "text": "in if it can get handled through this CDN it gets handled in addition we can",
    "start": "976059",
    "end": "981069"
  },
  {
    "text": "do a lot of computation through lambda reg when it's applied in cloud front so we can do all of that token validation",
    "start": "981069",
    "end": "987909"
  },
  {
    "text": "token data extraction and also dynamic origin selection directly add the club from layer the other thing was",
    "start": "987909",
    "end": "994919"
  },
  {
    "text": "CloudFront was simple for us to set up because we only had to set up a single distribution and it was globally",
    "start": "994919",
    "end": "1001319"
  },
  {
    "text": "available immediately so it's not a solution in which oh no we're now servicing users and France set up a CDN",
    "start": "1001319",
    "end": "1008339"
  },
  {
    "text": "in France luckily CloudFront took care that took care of all of that for us and a very simple approach and there was",
    "start": "1008339",
    "end": "1015779"
  },
  {
    "text": "no manual scaling required so as I mentioned you know you might have scenarios in which you have a trickle of",
    "start": "1015779",
    "end": "1020850"
  },
  {
    "text": "requests and then you might have scenarios in which you have an extremely high volume of requests coming in within",
    "start": "1020850",
    "end": "1026699"
  },
  {
    "text": "the span of five minutes so CloudFront was able to basically handle this very",
    "start": "1026699",
    "end": "1031769"
  },
  {
    "text": "gracefully you basically took the approach of server less and you pushed",
    "start": "1031769",
    "end": "1037620"
  },
  {
    "start": "1033000",
    "end": "1367000"
  },
  {
    "text": "it to the edge push put some functionality to to the edge as well as",
    "start": "1037620",
    "end": "1043889"
  },
  {
    "text": "taking the benefits of cloud front scale and offloading a lot of those requests",
    "start": "1043889",
    "end": "1050009"
  },
  {
    "text": "to a caching layer at the edge closer to the user so I'm very interested with the",
    "start": "1050009",
    "end": "1057179"
  },
  {
    "text": "implementation itself of the knotti in lambda at edge that you did",
    "start": "1057179",
    "end": "1063160"
  },
  {
    "text": "but before we dive into that let me take a moment just to explain what is lambda",
    "start": "1063160",
    "end": "1069190"
  },
  {
    "text": "at edge how is it different than AWS lambda and how it works with cloud from",
    "start": "1069190",
    "end": "1077040"
  },
  {
    "text": "so lambda the edge is actually an extension of AWS lambda it allows you to",
    "start": "1077040",
    "end": "1082960"
  },
  {
    "text": "take your server less solution to the edge and execute functions that can",
    "start": "1082960",
    "end": "1090520"
  },
  {
    "text": "customize your content closer to your viewers rather than all the way back at",
    "start": "1090520",
    "end": "1097240"
  },
  {
    "text": "your origin servers the functions can be",
    "start": "1097240",
    "end": "1104200"
  },
  {
    "text": "associate with cloud front you basically write the function in US east one region",
    "start": "1104200",
    "end": "1113140"
  },
  {
    "text": "and once you publish the function it's automatically replicated to other",
    "start": "1113140",
    "end": "1119290"
  },
  {
    "text": "locations globally and then once it's associated with cloud front you can",
    "start": "1119290",
    "end": "1125800"
  },
  {
    "text": "trigger the function in four different spots within the request response flow",
    "start": "1125800",
    "end": "1131860"
  },
  {
    "text": "the first one is viewer request that's when cloud phone received a request from",
    "start": "1131860",
    "end": "1138630"
  },
  {
    "text": "the user and then before it hits the cache layer and then the second is at",
    "start": "1138630",
    "end": "1145630"
  },
  {
    "text": "the origin request if most likely was a cache miss so you can trigger the",
    "start": "1145630",
    "end": "1152830"
  },
  {
    "text": "function at that point and then similarly on the way back on the respond",
    "start": "1152830",
    "end": "1159010"
  },
  {
    "text": "on origin respond before it actually gets to the cache layer and at the",
    "start": "1159010",
    "end": "1165250"
  },
  {
    "text": "viewer response before cloud front handing back the response to the viewer",
    "start": "1165250",
    "end": "1172530"
  },
  {
    "text": "so I wonder which one of the triggers did you choose and what functionality",
    "start": "1172530",
    "end": "1179650"
  },
  {
    "text": "you implemented with lambda attack out of the 4 triggers that you've mentioned",
    "start": "1179650",
    "end": "1184870"
  },
  {
    "text": "here we basically used of them one was a viewer-request and the",
    "start": "1184870",
    "end": "1190200"
  },
  {
    "text": "and the other one was the origin request so let's get into it specifically why we",
    "start": "1190200",
    "end": "1195870"
  },
  {
    "text": "utilized that you the viewer request so again as a recap the viewer request is the one that gets invoked when a request",
    "start": "1195870",
    "end": "1202920"
  },
  {
    "text": "immediately gets handled by CloudFront it invokes this viewer request lambda so",
    "start": "1202920",
    "end": "1207960"
  },
  {
    "text": "as I mentioned before we were passing some user information through the OTT still can write so think of the auth",
    "start": "1207960",
    "end": "1214830"
  },
  {
    "text": "token is basically just a header on this request it's an authorization header and the",
    "start": "1214830",
    "end": "1221780"
  },
  {
    "text": "value for that header is going to basically be adjacent payload that's encrypted in some format so what we do",
    "start": "1221780",
    "end": "1227910"
  },
  {
    "text": "is in the viewer request the first thing we do is validate this token is it coming from a knowledgeable resource or",
    "start": "1227910",
    "end": "1233610"
  },
  {
    "text": "is it coming from some bad actor secondly what we do is we're passing a",
    "start": "1233610",
    "end": "1239220"
  },
  {
    "text": "two letter country code in this token as to where the user is coming from so if",
    "start": "1239220",
    "end": "1245220"
  },
  {
    "text": "the user is making their requests from France there will be a Geo code of F far within the token and if the users coming",
    "start": "1245220",
    "end": "1252270"
  },
  {
    "text": "from Germany there's gonna be a Geo code of de within the token itself the question naturally arises what are we",
    "start": "1252270",
    "end": "1258780"
  },
  {
    "text": "doing with this with this information so I'd like to point out an example in which let's say that you're trying to",
    "start": "1258780",
    "end": "1267000"
  },
  {
    "text": "load the Bundesliga schedule so as a user in Germany you would expect to see",
    "start": "1267000",
    "end": "1272400"
  },
  {
    "text": "all of your titles and descriptions and any other metadata in German because German is the language that you",
    "start": "1272400",
    "end": "1278130"
  },
  {
    "text": "naturally attuned to understanding and speaking as opposed to if you're a user",
    "start": "1278130",
    "end": "1283500"
  },
  {
    "text": "in France if you saw something in German you probably wouldn't know what's going on so you should see that same data in",
    "start": "1283500",
    "end": "1290250"
  },
  {
    "text": "French so what we do is we take this this geo code and we map it to an actual cached piece of metadata and we return",
    "start": "1290250",
    "end": "1298680"
  },
  {
    "text": "back the cached metadata pertinent to the region this way we're basically semi",
    "start": "1298680",
    "end": "1303720"
  },
  {
    "text": "personalizing the response to the user directly at CloudFront so that's enabled",
    "start": "1303720",
    "end": "1308790"
  },
  {
    "text": "there's a lot of flexibility to basically semi personalized responses on the fly and the computer itself requests",
    "start": "1308790",
    "end": "1315180"
  },
  {
    "text": "never goes back to the origin the second way we use this is through a concept of something that",
    "start": "1315180",
    "end": "1320850"
  },
  {
    "text": "we refer to as meteorites think of this as essentially you as a user you've",
    "start": "1320850",
    "end": "1326850"
  },
  {
    "text": "purchased a subscription to the English Premier League so you should have access to anything that's in the English",
    "start": "1326850",
    "end": "1332490"
  },
  {
    "text": "Premier League you should be able to stream the events you should be able to see the catalogue of stuff but if you don't if you haven't purchased it if you",
    "start": "1332490",
    "end": "1338730"
  },
  {
    "text": "don't have access then maybe you should instead see a message saying hey you don't have access to this go ahead and",
    "start": "1338730",
    "end": "1344220"
  },
  {
    "text": "purchase it and then you'll get access so we use this meteorite information again stored on the Arts token to",
    "start": "1344220",
    "end": "1350879"
  },
  {
    "text": "determine whether the other user has access or doesn't have access and we either return back to them the metadata",
    "start": "1350879",
    "end": "1356429"
  },
  {
    "text": "for the content they're requesting or some response indicating that they don't have access and the applications can",
    "start": "1356429",
    "end": "1363120"
  },
  {
    "text": "take care of displaying that logic whichever way they please got it so you mentioned before that you use viewer",
    "start": "1363120",
    "end": "1370559"
  },
  {
    "text": "request and origin request functions and you request basically you're hitting",
    "start": "1370559",
    "end": "1377159"
  },
  {
    "text": "with every request so you can do different manipulations but why did you",
    "start": "1377159",
    "end": "1382679"
  },
  {
    "text": "need an additional function on the origin respond right as you mentioned",
    "start": "1382679",
    "end": "1388080"
  },
  {
    "text": "the viewer request gets invoked on every single request but the origin request only gets invoked when there's a cache",
    "start": "1388080",
    "end": "1393690"
  },
  {
    "text": "miss on CloudFront so let's say that you don't have a cache hit on CloudFront it's going to invoke this lambda which",
    "start": "1393690",
    "end": "1399600"
  },
  {
    "text": "is going to basically say where should I write should i route this request to to what origin server should I route this",
    "start": "1399600",
    "end": "1405450"
  },
  {
    "text": "request you to get back a response and so now that we're in this scenario in",
    "start": "1405450",
    "end": "1410460"
  },
  {
    "text": "which we have multiple pools of api's in multiple regions depending on on how our",
    "start": "1410460",
    "end": "1416070"
  },
  {
    "text": "development processes we basically follow a continuous integration approach in which we basically roll out changes",
    "start": "1416070",
    "end": "1422460"
  },
  {
    "text": "pretty frequently so a scenario might arise in which a pool a of our API has",
    "start": "1422460",
    "end": "1428340"
  },
  {
    "text": "some feature enabled and a pool B of our API doesn't have that feature enabled now it's it's perfectly predictable for",
    "start": "1428340",
    "end": "1435509"
  },
  {
    "text": "the requests to be routed to either one of those things if all else is equal so what will happen is to all of you come",
    "start": "1435509",
    "end": "1442200"
  },
  {
    "text": "in and you make a request saying you want to watch you know the latest English Premier League match which is usually pretty exciting I will watch it",
    "start": "1442200",
    "end": "1448379"
  },
  {
    "text": "to you make a request that request comes into lay and you get back piece of metadata",
    "start": "1448379",
    "end": "1454799"
  },
  {
    "text": "if your subsequent request goes to pool B which doesn't have that feature enabled suddenly you'll see a difference",
    "start": "1454799",
    "end": "1460919"
  },
  {
    "text": "in the metadata your behavior and your app will change you will have an inconsistent flow on your app resulting",
    "start": "1460919",
    "end": "1466799"
  },
  {
    "text": "in a decorated user experience so we have to certify me saying that you as a user of you come in we're always gonna",
    "start": "1466799",
    "end": "1472650"
  },
  {
    "text": "send you back to the same pool so that your behavior so that the interpretation of your application doesn't change so",
    "start": "1472650",
    "end": "1479010"
  },
  {
    "text": "what we do is we basically follow the canonical hashmap approach we have all of our load balancers all of our origins",
    "start": "1479010",
    "end": "1485820"
  },
  {
    "text": "and basically a bunch of buckets we take an IP that's available to us within the",
    "start": "1485820",
    "end": "1490950"
  },
  {
    "text": "origin request and we hash it across all of these buckets and so we can always using this one-way hash function always",
    "start": "1490950",
    "end": "1496650"
  },
  {
    "text": "guarantee that you're gonna end up at the same origin server and by that way we basically mitigate this this scenario",
    "start": "1496650",
    "end": "1503820"
  },
  {
    "text": "that could arise so this is also easier for us to do rather than handling DNS",
    "start": "1503820",
    "end": "1510210"
  },
  {
    "text": "records so DNS records why they're vital to the to the whole flow of the internet it takes time to propagate a change in",
    "start": "1510210",
    "end": "1517470"
  },
  {
    "text": "DNS it takes time to update a DNS record based on the TTL zuv the DNS record so",
    "start": "1517470",
    "end": "1522780"
  },
  {
    "text": "through the origin request and we could we could basically publish a new origin request lambda with an added region or a",
    "start": "1522780",
    "end": "1529650"
  },
  {
    "text": "removed region or removed pool rather to basically dictate what what's available",
    "start": "1529650",
    "end": "1535020"
  },
  {
    "text": "for a request to go to rather than having to make any changes that had the dns layer so it gave us a lot of",
    "start": "1535020",
    "end": "1540750"
  },
  {
    "text": "flexibility in that regard too and so it worked really well for us interesting so we see here two main uses for lambda at",
    "start": "1540750",
    "end": "1548669"
  },
  {
    "start": "1544000",
    "end": "1756000"
  },
  {
    "text": "edge one is inspecting and auth token and personalizing content and also",
    "start": "1548669",
    "end": "1556160"
  },
  {
    "text": "dynamically dynamically divert the request to a specific origin server",
    "start": "1556160",
    "end": "1563660"
  },
  {
    "text": "there are many other use cases that you can use with lambda edge like a be",
    "start": "1563660",
    "end": "1570000"
  },
  {
    "text": "testing you can do Network calls to other services and you can even generate",
    "start": "1570000",
    "end": "1575820"
  },
  {
    "text": "a page you can generate a respond right at the edge so looking at you know",
    "start": "1575820",
    "end": "1582419"
  },
  {
    "text": "what you're currently doing at the edge itself I wonder what are the performance",
    "start": "1582419",
    "end": "1589549"
  },
  {
    "text": "that you saw after implementing that and was there any event that you actually",
    "start": "1589549",
    "end": "1596450"
  },
  {
    "text": "use that architecture so far yeah so this is a fancy new architecture and as",
    "start": "1596450",
    "end": "1603330"
  },
  {
    "text": "an engineer always attracted to shiny new things you always want to test out new things talk about the new things",
    "start": "1603330",
    "end": "1609149"
  },
  {
    "text": "you've worked on but at the end of the day no matter how fancy any architecture might be at the end of the day it needs",
    "start": "1609149",
    "end": "1615809"
  },
  {
    "text": "to perform otherwise it's a non solution so I'm happy to say that even with this new architecture we basically verified",
    "start": "1615809",
    "end": "1623340"
  },
  {
    "text": "that it gave us significantly improved performance the way that that be",
    "start": "1623340",
    "end": "1628799"
  },
  {
    "text": "elicited this information was when we had two really major events happening at the same time you know one was the 2018",
    "start": "1628799",
    "end": "1635700"
  },
  {
    "text": "Winter Olympics and the other one was one of the most highly trafficked Bundesliga events this year and despite",
    "start": "1635700",
    "end": "1642090"
  },
  {
    "text": "having these two things happening not you know on their own but simultaneously we saw a zero percent down time we saw",
    "start": "1642090",
    "end": "1649320"
  },
  {
    "text": "our latency is well below 100 milliseconds and I think what best affects depicts this or the two graphs",
    "start": "1649320",
    "end": "1655529"
  },
  {
    "text": "so the graph on top is basically the number of lambda invitations happening",
    "start": "1655529",
    "end": "1661230"
  },
  {
    "text": "and the graph on the bottom basically depicts the number of requests being",
    "start": "1661230",
    "end": "1666330"
  },
  {
    "text": "handled at the API layer so that large amplitude that you see in the middle is one of those thundering herd issues",
    "start": "1666330",
    "end": "1672659"
  },
  {
    "text": "where everyone is signing on at the same time the massive spike it looks like a massive anomaly within the graph but",
    "start": "1672659",
    "end": "1677970"
  },
  {
    "text": "it's a perfectly normal normal scenario for us to handle and what you see is that lambda",
    "start": "1677970",
    "end": "1683070"
  },
  {
    "text": "edge is handling a significantly higher magnitude of requests than the API is so",
    "start": "1683070",
    "end": "1689190"
  },
  {
    "text": "it's basically eating up a lot of the load and preventing their load from even going down to the application layer and with this we essentially saw that our",
    "start": "1689190",
    "end": "1696929"
  },
  {
    "text": "cpu for in our API layer remained well below 5% which was at our target we saw",
    "start": "1696929",
    "end": "1703919"
  },
  {
    "text": "our average latency below 30 milliseconds despite these new lambda - triggers they add they added about",
    "start": "1703919",
    "end": "1710879"
  },
  {
    "text": "between 5 to 10 milliseconds in terms of response time but given the way",
    "start": "1710879",
    "end": "1716110"
  },
  {
    "text": "that cloud phone is architected it takes advantage of the geographical nature of where the request is occurring by",
    "start": "1716110",
    "end": "1722740"
  },
  {
    "text": "routing it to the closest node and handling it at that closest node which also gives you a geographical advantage",
    "start": "1722740",
    "end": "1727960"
  },
  {
    "text": "so that's something we didn't really think about and but it gave us so it was a nice thing to discover so we had a",
    "start": "1727960",
    "end": "1735970"
  },
  {
    "text": "scenario in which we had 48 API instances handling between you know a hundred thousand requests to several",
    "start": "1735970",
    "end": "1741610"
  },
  {
    "text": "millions of requests and it didn't have to do anything in terms of scaling so to us this was the perfect solution to get",
    "start": "1741610",
    "end": "1749500"
  },
  {
    "text": "us out the door and this is what we currently use and we'll be launching with at the start of Disney class",
    "start": "1749500",
    "end": "1756150"
  },
  {
    "start": "1756000",
    "end": "1898000"
  },
  {
    "text": "amazing so you took the approach of serverless at the edge leveraging cloud",
    "start": "1756150",
    "end": "1763690"
  },
  {
    "text": "front scale leveraging the fact that lambda edge can scale automatically",
    "start": "1763690",
    "end": "1769419"
  },
  {
    "text": "without you needing to provision those resources and offloading a lot of the",
    "start": "1769419",
    "end": "1777130"
  },
  {
    "text": "stress from your API layer Thank You cinta I know you can keep talking dive",
    "start": "1777130",
    "end": "1784240"
  },
  {
    "text": "further and further into the solution and we'd love to hear more about future",
    "start": "1784240",
    "end": "1790559"
  },
  {
    "text": "expansion let's keep that to the end of the session and let's change gears and talk",
    "start": "1790559",
    "end": "1796750"
  },
  {
    "text": "a little bit about cars or I should say true car hi everybody",
    "start": "1796750",
    "end": "1802780"
  },
  {
    "text": "yeah my name is regis Wilson I work at true car through our membership and",
    "start": "1802780",
    "end": "1807820"
  },
  {
    "text": "partner benefits that we offer we reach about half of new and used car buyers in",
    "start": "1807820",
    "end": "1813070"
  },
  {
    "text": "the United States so Reggie I know your platform was fully implemented",
    "start": "1813070",
    "end": "1820530"
  },
  {
    "text": "on-premises can you share with us what was the trigger to make the decision to",
    "start": "1820530",
    "end": "1827580"
  },
  {
    "text": "deploy on AWS sure our company goes back",
    "start": "1827580",
    "end": "1833080"
  },
  {
    "text": "about 10 years or more we have a legacy platform that was developed organically and it's grown we had multiple versions",
    "start": "1833080",
    "end": "1840370"
  },
  {
    "text": "of apps multiple applications we have multiple teams working on those",
    "start": "1840370",
    "end": "1845410"
  },
  {
    "text": "applications over many years and was just very difficult to create and build new applications to develop her",
    "start": "1845410",
    "end": "1851840"
  },
  {
    "text": "new features we also had a lot of problems trying to coordinate all of our different 500 more than 500 partners",
    "start": "1851840",
    "end": "1858980"
  },
  {
    "text": "that we work with some of them have a shared brand where we serve this benefit",
    "start": "1858980",
    "end": "1865039"
  },
  {
    "text": "through true car branding say if you're a member of Penn Fed credit or credit union or Sam's Club we offer it under",
    "start": "1865039",
    "end": "1872389"
  },
  {
    "text": "the true car brand but if you're under a if you're a member of USA for example we",
    "start": "1872389",
    "end": "1877940"
  },
  {
    "text": "serve that under their brand so we're not able to make changes or change these things very quickly so given all of",
    "start": "1877940",
    "end": "1885200"
  },
  {
    "text": "these challenges and problems that we were having at the time we decided we needed to take some time to move to the",
    "start": "1885200",
    "end": "1891440"
  },
  {
    "text": "cloud we not just move everything but actually rewrite it and sort of impress sort of it from scratch basically",
    "start": "1891440",
    "end": "1898159"
  },
  {
    "start": "1898000",
    "end": "1992000"
  },
  {
    "text": "looking at this architecture on-trend it seems like you could basically deploy",
    "start": "1898159",
    "end": "1904100"
  },
  {
    "text": "the same services on AWS and in a way of lift and shift move it over and then",
    "start": "1904100",
    "end": "1912019"
  },
  {
    "text": "maybe create a template for the migration of your partners and and",
    "start": "1912019",
    "end": "1918110"
  },
  {
    "text": "migrate them over again from this diagram it seems like the feasible",
    "start": "1918110",
    "end": "1924049"
  },
  {
    "text": "solution what were the challenges with that yeah I'm glad to see the myth of",
    "start": "1924049",
    "end": "1930080"
  },
  {
    "text": "lift and shift is alive and well yeah you can actually lift and shift this there's way too many complex moving",
    "start": "1930080",
    "end": "1935990"
  },
  {
    "text": "parts and too many pieces going back too far that diagram is too simple to be accurate we have another problem is if",
    "start": "1935990",
    "end": "1944480"
  },
  {
    "text": "we need to move the whole ecosystem if we rewrite parts of it if we have different teams working at different",
    "start": "1944480",
    "end": "1950059"
  },
  {
    "text": "time lines it wouldn't be feasible to lift and shift and change it in a night or even a month we need to move all of our",
    "start": "1950059",
    "end": "1956869"
  },
  {
    "text": "pipelines we do a lot of data ingestion processing the partners need to approve",
    "start": "1956869",
    "end": "1962869"
  },
  {
    "text": "changes in some cases we aren't able to just release new changes without consulting and testing we also need to",
    "start": "1962869",
    "end": "1969559"
  },
  {
    "text": "be able to a be test the new code if it works properly we have you know we have to pay attention to PageSpeed load times",
    "start": "1969559",
    "end": "1976500"
  },
  {
    "text": "conversion rates we have to make sure our SEO and engagement is up to snuff in",
    "start": "1976500",
    "end": "1982620"
  },
  {
    "text": "some cases we can roll out and then maybe we find that it's not working properly or we need to test another",
    "start": "1982620",
    "end": "1988140"
  },
  {
    "text": "direction so we might need to roll it back so was the approach to migrate partner",
    "start": "1988140",
    "end": "1995370"
  },
  {
    "start": "1992000",
    "end": "2041000"
  },
  {
    "text": "by partner or a batch of partners or maybe you know test at first and then",
    "start": "1995370",
    "end": "2002000"
  },
  {
    "text": "just full migration did you experiment any of that yeah absolutely so we",
    "start": "2002000",
    "end": "2009080"
  },
  {
    "text": "initially brainstorm some ideas here we might want to move one application to a new application location we might go one",
    "start": "2009080",
    "end": "2017030"
  },
  {
    "text": "partner in one application maybe one partner with a group of applications maybe batches of partners using an",
    "start": "2017030",
    "end": "2023840"
  },
  {
    "text": "application but one of the use cases that the business won it was to be able to do a traffic split so take one",
    "start": "2023840",
    "end": "2030860"
  },
  {
    "text": "partner in one application split off 50% of the traffic maybe for taking the",
    "start": "2030860",
    "end": "2036530"
  },
  {
    "text": "whole application across all partners and moving that by a certain percentage traffic so if I'm looking at those",
    "start": "2036530",
    "end": "2044470"
  },
  {
    "text": "options it that this complexity calls out for some sort of a routing engine",
    "start": "2044470",
    "end": "2051850"
  },
  {
    "text": "and if you use each partner domain I would think that using a DNS as your",
    "start": "2051850",
    "end": "2059750"
  },
  {
    "text": "routing engine and just pointing to the right application might be the solution",
    "start": "2059750",
    "end": "2064760"
  },
  {
    "text": "did you guys consider that well sure there several typical migration paths",
    "start": "2064760",
    "end": "2069950"
  },
  {
    "text": "DNS is certainly one of them it's the first one we looked at the problem is that it moves an entire partners traffic",
    "start": "2069950",
    "end": "2076429"
  },
  {
    "text": "all at once and so for some of our very big partners we can just switch them over and then hope that it worked and",
    "start": "2076429",
    "end": "2082310"
  },
  {
    "text": "then if we needed to rollback it would be very tricky to rollback and take a long time we looked at some other",
    "start": "2082310",
    "end": "2088429"
  },
  {
    "text": "application migrations which is to do it at the application layer say we're using",
    "start": "2088429",
    "end": "2094128"
  },
  {
    "text": "nginx or some sort of proxy typically the problem here is you have good",
    "start": "2094129",
    "end": "2099590"
  },
  {
    "text": "control over the application layer but by the time you've hit this application or this routing",
    "start": "2099590",
    "end": "2105810"
  },
  {
    "text": "engine or this proxy lair somewhere it's usually too late maybe you've already",
    "start": "2105810",
    "end": "2110850"
  },
  {
    "text": "hit a cloud endpoint or you've hit a data center and then you have to go route it back out to the cloud or back",
    "start": "2110850",
    "end": "2116880"
  },
  {
    "text": "to the data center this is usually too late we also looked at using cloud front roles we could use alb target groups",
    "start": "2116880",
    "end": "2124860"
  },
  {
    "text": "perhaps to map traffic correctly but it takes a long time to roll the cloud front behaviors out if you imagine we",
    "start": "2124860",
    "end": "2132180"
  },
  {
    "text": "have more than 500 partners even if we bucketed the partners into distributions",
    "start": "2132180",
    "end": "2138030"
  },
  {
    "text": "we might have 10 or 20 distributions for each application we would need to",
    "start": "2138030",
    "end": "2143280"
  },
  {
    "text": "migrate and change those application rules for each distribution across multiple distributions and it takes a",
    "start": "2143280",
    "end": "2149850"
  },
  {
    "text": "long time to roll out it takes a long time to roll back and you can't split the traffic that way see but I still see",
    "start": "2149850",
    "end": "2155880"
  },
  {
    "start": "2154000",
    "end": "2229000"
  },
  {
    "text": "that you have the legacy platform active and you have the new platform and I",
    "start": "2155880",
    "end": "2162780"
  },
  {
    "text": "understand that you're migrating you know either partner my partner or a few partners but you still need to control",
    "start": "2162780",
    "end": "2170310"
  },
  {
    "text": "the routing between the on-premise platform to the AWS deployment and by",
    "start": "2170310",
    "end": "2177720"
  },
  {
    "text": "this you know architecture it's in like cloud fund is in that you know natural",
    "start": "2177720",
    "end": "2184050"
  },
  {
    "text": "solution looking at that as two origin endpoints one is a custom and one is",
    "start": "2184050",
    "end": "2190140"
  },
  {
    "text": "within AWS itself so what was the exact",
    "start": "2190140",
    "end": "2196080"
  },
  {
    "text": "challenge when you used cloth for sure so we came up with this idea that we",
    "start": "2196080",
    "end": "2201840"
  },
  {
    "text": "could use land at the edge to make decisions on the fly to route to new",
    "start": "2201840",
    "end": "2207330"
  },
  {
    "text": "origins we would implement some sort of routing rules engine that we could update in real-time and then just as you",
    "start": "2207330",
    "end": "2214350"
  },
  {
    "text": "mentioned the origin request function could make a decision when the request came past the cache miss and it would go",
    "start": "2214350",
    "end": "2221670"
  },
  {
    "text": "to make a decision she'll be route to energy endpoint hey or be and this was the architecture",
    "start": "2221670",
    "end": "2227650"
  },
  {
    "text": "that we designed so looking at this architecture this is a great idea to use",
    "start": "2227650",
    "end": "2233910"
  },
  {
    "start": "2229000",
    "end": "2323000"
  },
  {
    "text": "dynamodb as your object for taking",
    "start": "2233910",
    "end": "2239020"
  },
  {
    "text": "parameters making decisions particularly using lumber that edge to make a network whoa to DynamoDB where you can update",
    "start": "2239020",
    "end": "2248190"
  },
  {
    "text": "faster and you don't need to rely on updating the lambda h function itself",
    "start": "2248190",
    "end": "2255280"
  },
  {
    "text": "and the solution seems like it can be used in many different use cases and",
    "start": "2255280",
    "end": "2261910"
  },
  {
    "text": "different industries can you dive a little deeper about the how the decision",
    "start": "2261910",
    "end": "2269080"
  },
  {
    "text": "making object looked on DynamoDB how it interact that I interact with the",
    "start": "2269080",
    "end": "2275100"
  },
  {
    "text": "dynamodb and how it executes it sure so if we zoom in on the dynamodb design we",
    "start": "2275100",
    "end": "2282880"
  },
  {
    "text": "have to support traffic in the United States at least in the west coast typically so we create used global",
    "start": "2282880",
    "end": "2289300"
  },
  {
    "text": "tables DynamoDB global tables this allows us to write to one region let's",
    "start": "2289300",
    "end": "2294580"
  },
  {
    "text": "say on the east coast or the west coast and it automatically replicates their master masters so we can write to either",
    "start": "2294580",
    "end": "2299980"
  },
  {
    "text": "one any request that comes in on the edge it can execute and land at the edge",
    "start": "2299980",
    "end": "2305380"
  },
  {
    "text": "where ever the the end user is located so in this example US East one in u.s.",
    "start": "2305380",
    "end": "2310450"
  },
  {
    "text": "seas - pretty close to us seas one so they share that dynamodb region if the",
    "start": "2310450",
    "end": "2315940"
  },
  {
    "text": "request comes on the west coast US west - then we route to the closest dynamodb",
    "start": "2315940",
    "end": "2321250"
  },
  {
    "text": "table in u.s. west - interesting so you're using lambda edge as your routing",
    "start": "2321250",
    "end": "2326290"
  },
  {
    "start": "2323000",
    "end": "2401000"
  },
  {
    "text": "engine but you take the parameters from dynamodb where you can update that and",
    "start": "2326290",
    "end": "2332290"
  },
  {
    "text": "that's on a global table so you have the option to access in different regions",
    "start": "2332290",
    "end": "2339510"
  },
  {
    "text": "can we dive in into the actual object I know you wanted to share with us some of",
    "start": "2339510",
    "end": "2346000"
  },
  {
    "text": "the code examples how the object looks like yeah we're gonna take a deep dive into the technical details here so this",
    "start": "2346000",
    "end": "2354010"
  },
  {
    "text": "is a JSON blob which stores very well and Oh DB we take the host which is the",
    "start": "2354010",
    "end": "2359630"
  },
  {
    "text": "partner name or the brand possibly that's the hash that's the hash table",
    "start": "2359630",
    "end": "2365359"
  },
  {
    "text": "and we take the URI which is the path of the request or the application name that",
    "start": "2365359",
    "end": "2370760"
  },
  {
    "text": "would be the range key so taking the hash on the range key we get a unique action and you can see there in the",
    "start": "2370760",
    "end": "2377090"
  },
  {
    "text": "green we have a possibility of setting the origin we can set it to the cloud or the or the legacy sites and in red you",
    "start": "2377090",
    "end": "2384800"
  },
  {
    "text": "can see we can change the UI on the fly we can rewrite it to index that HTML for",
    "start": "2384800",
    "end": "2389930"
  },
  {
    "text": "the Lexie or maybe something more modern like /home we also have a wait there I'm sorry this that part okay yeah we have a",
    "start": "2389930",
    "end": "2397369"
  },
  {
    "text": "week so we can evenly distribute traffic 5050 in this scenario got it so this is",
    "start": "2397369",
    "end": "2403730"
  },
  {
    "text": "the parameters and then the execution yes this is a code example is written in",
    "start": "2403730",
    "end": "2408830"
  },
  {
    "text": "nodejs we have three matches that we can do in hierarchy so the first match may",
    "start": "2408830",
    "end": "2415130"
  },
  {
    "text": "be the most specific match is the one we want to do first the X exact the exact match we can do a partial match on the",
    "start": "2415130",
    "end": "2421940"
  },
  {
    "text": "on the URI which might be part of the application name then we can have a default or a fallback if you look at in",
    "start": "2421940",
    "end": "2428600"
  },
  {
    "text": "the fuchsia there's like a execute action this is where we actually make a decision on which result to return and",
    "start": "2428600",
    "end": "2434840"
  },
  {
    "text": "then based on that we can do a response in the green we can actually generate a",
    "start": "2434840",
    "end": "2440420"
  },
  {
    "text": "response back to the client on the fly without going to the back end we could send a 301 or 302 we could send out even",
    "start": "2440420",
    "end": "2448250"
  },
  {
    "text": "a page saying go check this out or we can send the request back to the back end and then going further zooming",
    "start": "2448250",
    "end": "2456650"
  },
  {
    "text": "in to the execute action we have three actions here just as an example we can",
    "start": "2456650",
    "end": "2461869"
  },
  {
    "text": "set the URI to a new value if it's if it's present in the JSON if it says to",
    "start": "2461869",
    "end": "2467180"
  },
  {
    "text": "set the headers we can set arbitrary headers and response codes and then in",
    "start": "2467180",
    "end": "2472190"
  },
  {
    "text": "the the most critical case if there's a set origin parameter there we can change the origin as well",
    "start": "2472190",
    "end": "2477890"
  },
  {
    "text": "I see so before you mentioned that there's the option to do weighted routing and you using lambda",
    "start": "2477890",
    "end": "2486230"
  },
  {
    "start": "2478000",
    "end": "2594000"
  },
  {
    "text": "edge at your request so every request that comes in you're making that check",
    "start": "2486230",
    "end": "2491480"
  },
  {
    "text": "how do you keep each user to go you know to the same origin are you using any",
    "start": "2491480",
    "end": "2498770"
  },
  {
    "text": "type of a session cookie that you track is there any mechanism yeah absolutely",
    "start": "2498770",
    "end": "2505580"
  },
  {
    "text": "as Cynthia mentioned a little bit earlier let's say you go to our website and we pass you along to one of our",
    "start": "2505580",
    "end": "2511880"
  },
  {
    "text": "experiences we need to be able to make sure that their next requests will go to the same experience not a different one",
    "start": "2511880",
    "end": "2517900"
  },
  {
    "text": "and so we were using a feature called launch Darkly in our application already",
    "start": "2517900",
    "end": "2524020"
  },
  {
    "text": "software engineers use launch directly to create feature flags the feature flag",
    "start": "2524020",
    "end": "2529280"
  },
  {
    "text": "allows you to say this experience is turned on or this experience it turned off make this button red or this button",
    "start": "2529280",
    "end": "2535130"
  },
  {
    "text": "green and we were able to leverage that in lambda at the edge we use the same",
    "start": "2535130",
    "end": "2540530"
  },
  {
    "text": "Flags that the software engineers use and build in their new applications and their experiences so when the request",
    "start": "2540530",
    "end": "2546650"
  },
  {
    "text": "comes in let's say user token has already been targeted to experience a the request will come into a lambda at",
    "start": "2546650",
    "end": "2553730"
  },
  {
    "text": "the edge we'll see that same flag is enabled for that users set to experience a and then we'll choose experience a you",
    "start": "2553730",
    "end": "2559910"
  },
  {
    "text": "can see in the green if the flag matched we would go to the first one and if it",
    "start": "2559910",
    "end": "2565250"
  },
  {
    "text": "didn't match we would go to the default IC and here's an example of how we",
    "start": "2565250",
    "end": "2570800"
  },
  {
    "text": "rewrite this JSON blob in this case we can take the in the green launch Darkly",
    "start": "2570800",
    "end": "2577250"
  },
  {
    "text": "key that's the name of the key so this feature says this partner home has living launched if we see the value as",
    "start": "2577250",
    "end": "2583700"
  },
  {
    "text": "challenger one then we go ahead and route that request to the origin to the cloud and if it was control or",
    "start": "2583700",
    "end": "2590870"
  },
  {
    "text": "challenger 2 we would just send it to the default register is a lot going on",
    "start": "2590870",
    "end": "2596570"
  },
  {
    "start": "2594000",
    "end": "2705000"
  },
  {
    "text": "at the edge you know with this implementation you have a call to dynamo",
    "start": "2596570",
    "end": "2601940"
  },
  {
    "text": "DB you have another call it goes to an external service to",
    "start": "2601940",
    "end": "2607540"
  },
  {
    "text": "get those feature flags and all this process at the edge you also mentioned",
    "start": "2607540",
    "end": "2613960"
  },
  {
    "text": "that you wanted to maintain a low latency and wonder how much you know",
    "start": "2613960",
    "end": "2620320"
  },
  {
    "text": "this impact and affect the overall latency yeah we we also had a hundred",
    "start": "2620320",
    "end": "2626980"
  },
  {
    "text": "millisecond budget similarly as the chin team mentioned when I first wrote the original proof-of-concept it came back",
    "start": "2626980",
    "end": "2634420"
  },
  {
    "text": "in response times of 300 milliseconds or more which is a third of a second there's way too much that's way too long",
    "start": "2634420",
    "end": "2640690"
  },
  {
    "text": "for a user to wait for a page to even be returned so we were able to find out",
    "start": "2640690",
    "end": "2645730"
  },
  {
    "text": "searching on the internet and asking for enterprise support if you scale the size of the lambda memory you get more CPU",
    "start": "2645730",
    "end": "2652480"
  },
  {
    "text": "slices you also get less less yielding in your code and so as we scaled the",
    "start": "2652480",
    "end": "2657880"
  },
  {
    "text": "size of land up to one gigabyte we're able to bring response times below 50 milliseconds and here the actual results",
    "start": "2657880",
    "end": "2665710"
  },
  {
    "text": "from production you can see our average run and the latency is err I should say the average runtime of the of the lambda",
    "start": "2665710",
    "end": "2673230"
  },
  {
    "text": "execution which turns into latency for the end user but in this case it's less",
    "start": "2673230",
    "end": "2678250"
  },
  {
    "text": "than 50 milliseconds our 95th and 99th percentile czar we're right where we need them to be you can see that USA's 2",
    "start": "2678250",
    "end": "2685630"
  },
  {
    "text": "is a little bit higher than us East 1 that's because it's a little further away and that diagram I showed you",
    "start": "2685630",
    "end": "2691630"
  },
  {
    "text": "that's an important point to mention when you do request to a failover",
    "start": "2691630",
    "end": "2696870"
  },
  {
    "text": "location that might increase a little bit the latency but still as we can see",
    "start": "2696870",
    "end": "2702760"
  },
  {
    "text": "you're under your 100 millisecond budget so regice this is great I mean seeing",
    "start": "2702760",
    "end": "2711760"
  },
  {
    "start": "2705000",
    "end": "2983000"
  },
  {
    "text": "that migration over taking approach of you know server less architecture",
    "start": "2711760",
    "end": "2718540"
  },
  {
    "text": "pushing functionality to the edge Chindia why would you join us again and",
    "start": "2718540",
    "end": "2725740"
  },
  {
    "text": "let's let's talk a little bit about the future what you know what are you",
    "start": "2725740",
    "end": "2731620"
  },
  {
    "text": "planning for future expansion and you know which features are you looking",
    "start": "2731620",
    "end": "2739030"
  },
  {
    "text": "to implement yeah so we are basically trying to figure out the right now",
    "start": "2739030",
    "end": "2745630"
  },
  {
    "text": "Oliver routing rules are set up in JSON so there's no requirement for a business",
    "start": "2745630",
    "end": "2751390"
  },
  {
    "text": "person to ask for my intervention when we make changes to our routing but in order for new routes to be created and",
    "start": "2751390",
    "end": "2757599"
  },
  {
    "text": "someone needs to be doing that usually usually me we want to create an administrative UI it allows non-text and",
    "start": "2757599",
    "end": "2764380"
  },
  {
    "text": "maybe business owners to actually maybe even just a view that rules that are in place but also at some point you'll be",
    "start": "2764380",
    "end": "2770680"
  },
  {
    "text": "able to click new and add a role and add a new route to new application that you're building we would like to be able",
    "start": "2770680",
    "end": "2777010"
  },
  {
    "text": "to roll out these changes in a controlled manner or maybe on a schedule and then be able to but roll them back",
    "start": "2777010",
    "end": "2783099"
  },
  {
    "text": "with one button let's say we'd also like to be able to see all of our environments in one place so if you have",
    "start": "2783099",
    "end": "2789040"
  },
  {
    "text": "a QA and a staging production set of rules you'd want to be able to view those together and maybe you have like",
    "start": "2789040",
    "end": "2795880"
  },
  {
    "text": "approvals and workflows that kind of thing we need to increase the unit tests for our code functional tests so that we",
    "start": "2795880",
    "end": "2803170"
  },
  {
    "text": "don't break anything right now we have scripts that check things are working correctly and we have monitoring but",
    "start": "2803170",
    "end": "2808990"
  },
  {
    "text": "it's still relatively manual to make sure that everything's running perfectly and then lastly if we had better",
    "start": "2808990",
    "end": "2815530"
  },
  {
    "text": "visibility on which routes were being matched and how those writing behaviors were occurring and what the current",
    "start": "2815530",
    "end": "2820810"
  },
  {
    "text": "status was we'd like to be able to see that thank you for sharing that with us Reggie's and know what you do know I",
    "start": "2820810",
    "end": "2829480"
  },
  {
    "text": "stopped you before because I wanted to keep that last point about future expansion right what do you guys have in",
    "start": "2829480",
    "end": "2836020"
  },
  {
    "text": "plan well first of all we just just gonna give you fair warning though we're definitely stealing some of your ideas",
    "start": "2836020",
    "end": "2842460"
  },
  {
    "text": "thank you some good stuff there but more than that you know I think one of the",
    "start": "2842460",
    "end": "2849369"
  },
  {
    "text": "largest things that we've seen even over the past 10 years is we've gone from a scenario in which who have had to",
    "start": "2849369",
    "end": "2856089"
  },
  {
    "text": "provision some form of a host whether that's local to you or on some cloud provider with the perfect environment",
    "start": "2856089",
    "end": "2863859"
  },
  {
    "text": "variable is a perfect setup for your application then we moved on to a phase in which we were using the",
    "start": "2863859",
    "end": "2868960"
  },
  {
    "text": "we had multiple VMs running on a host where maybe one VM really was tuned to the per to your application specifically",
    "start": "2868960",
    "end": "2876119"
  },
  {
    "text": "now I'm happy to say you know we've moved to a level even above that where we have this atomic unit this container",
    "start": "2876119",
    "end": "2882819"
  },
  {
    "text": "that can run on any host regardless of where that host is regardless if any factors on that host so we've really",
    "start": "2882819",
    "end": "2890140"
  },
  {
    "text": "adopted this you know we feel that Dhaka is a future with adopted containerization across the board in",
    "start": "2890140",
    "end": "2896410"
  },
  {
    "text": "content discovery and there's a push towards then in the large organization of Disney streaming with that I think",
    "start": "2896410",
    "end": "2903400"
  },
  {
    "text": "the next step forward it for us is really figuring out what the right format of container orchestration is how",
    "start": "2903400",
    "end": "2910180"
  },
  {
    "text": "do you roll out updates to your app now that it's in this container in this atomic format how do you roll it out",
    "start": "2910180",
    "end": "2916170"
  },
  {
    "text": "based on a regional basis based on feature basis how do you roll back so",
    "start": "2916170",
    "end": "2921670"
  },
  {
    "text": "all of these things are a container solution that we need to adopt so we use ECS currently to do that and we can",
    "start": "2921670",
    "end": "2929589"
  },
  {
    "text": "really see a lot of growth and continue to use they're continuing to adopt that or maybe any other orchestration format",
    "start": "2929589",
    "end": "2935230"
  },
  {
    "text": "that there may be out there the second is we've moved towards a scenario in which there's a lot of",
    "start": "2935230",
    "end": "2941109"
  },
  {
    "text": "event-driven processing happening across the board you have these discrete events happening in real time and you have to",
    "start": "2941109",
    "end": "2947559"
  },
  {
    "text": "respond to it gracefully with in a graceful time period and that's not to say that you should provision an",
    "start": "2947559",
    "end": "2953710"
  },
  {
    "text": "application that keeps polling waiting for these messages but maybe you needed a complete event-driven architecture we",
    "start": "2953710",
    "end": "2959710"
  },
  {
    "text": "use Kinesis a lot within disney class within disney streaming and we use lambda a lot as well so I think you know",
    "start": "2959710",
    "end": "2967240"
  },
  {
    "text": "lambda is really tuned towards this event-driven format of information being passed to and fro and I think we're",
    "start": "2967240",
    "end": "2973990"
  },
  {
    "text": "gonna see a lot more adoption in Disney streaming of lambda specifically so there's a lot of growth out there and",
    "start": "2973990",
    "end": "2980170"
  },
  {
    "text": "there's a lot of stuff that we want to look into super Cynthia register thank",
    "start": "2980170",
    "end": "2986170"
  },
  {
    "start": "2983000",
    "end": "3061000"
  },
  {
    "text": "you for sharing with us your journey for scale your journey for migration",
    "start": "2986170",
    "end": "2993900"
  },
  {
    "text": "this is very beneficial for the community any last remarks yeah I'll go",
    "start": "2993900",
    "end": "3003000"
  },
  {
    "text": "first so the just wanted to say thank you to you a base and you guys in the",
    "start": "3003000",
    "end": "3009270"
  },
  {
    "text": "audience for coming and listening me speak it's been a great honor for me a true car to work on new technologies to",
    "start": "3009270",
    "end": "3015600"
  },
  {
    "text": "be able to present information out to the community to share all of our solutions this talk originally came out",
    "start": "3015600",
    "end": "3022890"
  },
  {
    "text": "as a result of a blog post that I wrote for AWS which is going to be published on their cloud the cloud front site",
    "start": "3022890",
    "end": "3029100"
  },
  {
    "text": "so you bit or dive into it more also you know you can feel free to contact me at",
    "start": "3029100",
    "end": "3035460"
  },
  {
    "text": "any of these locations that I've mentioned here I think you can see that we have some people with a lot of team",
    "start": "3035460",
    "end": "3041220"
  },
  {
    "text": "spirit in the front row and this isn't just marketing I actually do drive a car",
    "start": "3041220",
    "end": "3047770"
  },
  {
    "text": "[Laughter] so thanks again for coming out and",
    "start": "3047770",
    "end": "3053400"
  },
  {
    "text": "listening really appreciate it",
    "start": "3053400",
    "end": "3056539"
  },
  {
    "text": "thank you love that's Cynthia I mean I can I can't talk the last statement yes",
    "start": "3060690",
    "end": "3066210"
  },
  {
    "start": "3061000",
    "end": "3202000"
  },
  {
    "text": "let me just say that no the the presence that you guys have that's great I've Jim who's an and Brandon as well so a lot of",
    "start": "3066210",
    "end": "3073890"
  },
  {
    "text": "great people from Disney over here but first of all I want to thank the both of you Ptolemy's just for for being here",
    "start": "3073890",
    "end": "3080610"
  },
  {
    "text": "for having discussion and of course everyone in the audience who's shown up here who has some interest in this and I",
    "start": "3080610",
    "end": "3086790"
  },
  {
    "text": "really hope that you've come away at least learning something instead of the technological side the technical side or",
    "start": "3086790",
    "end": "3093480"
  },
  {
    "text": "maybe even about Disney you know another thing is I've been using the word we",
    "start": "3093480",
    "end": "3099390"
  },
  {
    "text": "because this has been a very team oriented approach and very team oriented",
    "start": "3099390",
    "end": "3104400"
  },
  {
    "text": "effort in content discovery and along with a lot of experimentation and",
    "start": "3104400",
    "end": "3109770"
  },
  {
    "text": "testing and and trying to play with new stuff that's the sort of format that we work in at Disney and it's very",
    "start": "3109770",
    "end": "3116760"
  },
  {
    "text": "important to us lastly I want to say that I you know feel free to get in touch with me any",
    "start": "3116760",
    "end": "3124710"
  },
  {
    "text": "way that you want I think there's a few few options listed here I'd love to hear from you and finally there is a Disney",
    "start": "3124710",
    "end": "3131670"
  },
  {
    "text": "Plus tech blog that I would encourage anyone here to visit if they're interested in learning more about the",
    "start": "3131670",
    "end": "3137340"
  },
  {
    "text": "solutions that we're doing here not only on the content discovery team but on all sorts of teams such as the Ad Tech team",
    "start": "3137340",
    "end": "3144000"
  },
  {
    "text": "so you know in short as a person who uses a lot of stuff that's out there lot",
    "start": "3144000",
    "end": "3151200"
  },
  {
    "text": "of apps out there I'm always curious about kind of pulling back the curtains seeing what's behind it and now when",
    "start": "3151200",
    "end": "3158250"
  },
  {
    "text": "Disney Plus launches next year and you all get on the service as I know you will after this talk and you'll enjoy",
    "start": "3158250",
    "end": "3165930"
  },
  {
    "text": "all of your Star Wars stuff all of your Marvel stuff and all of the other great stuff that Disney Plus will offer and",
    "start": "3165930",
    "end": "3171690"
  },
  {
    "text": "now you'll also have some idea as to what exactly is powering it so I'm glad",
    "start": "3171690",
    "end": "3177360"
  },
  {
    "text": "to be able to share that and thank you so much very cool thank you thank you so much I hope you",
    "start": "3177360",
    "end": "3185210"
  },
  {
    "text": "find this valuable for your next deployment keep sharing with the",
    "start": "3185210",
    "end": "3190550"
  },
  {
    "text": "community thank you again Reggie's cinta and don't forget to",
    "start": "3190550",
    "end": "3195620"
  },
  {
    "text": "complete the session survey in your Brandon mobile app thank you",
    "start": "3195620",
    "end": "3203920"
  }
]
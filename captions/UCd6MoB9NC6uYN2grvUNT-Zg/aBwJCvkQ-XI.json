[
  {
    "start": "0",
    "end": "114000"
  },
  {
    "text": "hello and welcome my name is juu poo I",
    "start": "359",
    "end": "3280"
  },
  {
    "text": "an associate specialist Solutions",
    "start": "3280",
    "end": "5120"
  },
  {
    "text": "architect at AWS and in this video we",
    "start": "5120",
    "end": "7600"
  },
  {
    "text": "are going to present to you a public",
    "start": "7600",
    "end": "9320"
  },
  {
    "text": "preview demo of Amazon Aurora postgress",
    "start": "9320",
    "end": "11759"
  },
  {
    "text": "SQL zero ETL integration with Amazon red",
    "start": "11759",
    "end": "14559"
  },
  {
    "text": "shift this feature was announced during",
    "start": "14559",
    "end": "16720"
  },
  {
    "text": "reinvent 2023 and is currently on public",
    "start": "16720",
    "end": "19480"
  },
  {
    "text": "preview",
    "start": "19480",
    "end": "20960"
  },
  {
    "text": "stage one of the biggest challenges that",
    "start": "20960",
    "end": "23320"
  },
  {
    "text": "customer face is the inje of multiple",
    "start": "23320",
    "end": "25760"
  },
  {
    "text": "sources of data into their analytic",
    "start": "25760",
    "end": "28279"
  },
  {
    "text": "systems this spans across databases data",
    "start": "28279",
    "end": "31400"
  },
  {
    "text": "Lakes operational data streams for",
    "start": "31400",
    "end": "33320"
  },
  {
    "text": "multiple sources and also S3 buckets",
    "start": "33320",
    "end": "35920"
  },
  {
    "text": "that store multiple file formats",
    "start": "35920",
    "end": "38800"
  },
  {
    "text": "companies need to build and maintain",
    "start": "38800",
    "end": "40520"
  },
  {
    "text": "manual data pipelines that requires data",
    "start": "40520",
    "end": "43000"
  },
  {
    "text": "Engineers for weeks or months to build",
    "start": "43000",
    "end": "44920"
  },
  {
    "text": "them and also maintenance can be very",
    "start": "44920",
    "end": "46879"
  },
  {
    "text": "complex and",
    "start": "46879",
    "end": "48239"
  },
  {
    "text": "costly a common architecture that we see",
    "start": "48239",
    "end": "50800"
  },
  {
    "text": "with customers is using Amazon Aurora as",
    "start": "50800",
    "end": "53120"
  },
  {
    "text": "their operational database and Amazon",
    "start": "53120",
    "end": "55079"
  },
  {
    "text": "red shift as their analytic system so in",
    "start": "55079",
    "end": "57879"
  },
  {
    "text": "order to make it easy to replicate data",
    "start": "57879",
    "end": "59719"
  },
  {
    "text": "from from Amazon Aurora databases to",
    "start": "59719",
    "end": "61680"
  },
  {
    "text": "Amazon red shift in reinvent 2023 AWS",
    "start": "61680",
    "end": "65158"
  },
  {
    "text": "introduced the preview of Amazon Aurora",
    "start": "65159",
    "end": "67520"
  },
  {
    "text": "post SQL zero ETL integration to Amazon",
    "start": "67520",
    "end": "70280"
  },
  {
    "text": "red shift this feature syncs",
    "start": "70280",
    "end": "73240"
  },
  {
    "text": "transactional data from Amazon Aurora",
    "start": "73240",
    "end": "75600"
  },
  {
    "text": "into Amazon red shift with change data",
    "start": "75600",
    "end": "78400"
  },
  {
    "text": "capture in near real time you can",
    "start": "78400",
    "end": "81280"
  },
  {
    "text": "replicate data from multiple Amazon",
    "start": "81280",
    "end": "83119"
  },
  {
    "text": "Aurora database clusters into the same",
    "start": "83119",
    "end": "85240"
  },
  {
    "text": "Amazon red shift instance to derive",
    "start": "85240",
    "end": "87200"
  },
  {
    "text": "holistic insights across several",
    "start": "87200",
    "end": "89000"
  },
  {
    "text": "applications",
    "start": "89000",
    "end": "90439"
  },
  {
    "text": "this integration enables Amazon Aurora",
    "start": "90439",
    "end": "92759"
  },
  {
    "text": "customers to run near realtime analytics",
    "start": "92759",
    "end": "95399"
  },
  {
    "text": "and machine learning on petabytes of",
    "start": "95399",
    "end": "97360"
  },
  {
    "text": "transactional data by offering a fully",
    "start": "97360",
    "end": "99600"
  },
  {
    "text": "managed solution for making",
    "start": "99600",
    "end": "101200"
  },
  {
    "text": "transactional data available in Amazon",
    "start": "101200",
    "end": "103840"
  },
  {
    "text": "red shift within seconds of being ridden",
    "start": "103840",
    "end": "106240"
  },
  {
    "text": "into Amazon Aurora this eliminates the",
    "start": "106240",
    "end": "109280"
  },
  {
    "text": "need for customers to build and maintain",
    "start": "109280",
    "end": "111880"
  },
  {
    "text": "complex ETL",
    "start": "111880",
    "end": "113719"
  },
  {
    "text": "pipelines the purpose of this video is",
    "start": "113719",
    "end": "116079"
  },
  {
    "start": "114000",
    "end": "159000"
  },
  {
    "text": "to show a demo of how to set up this",
    "start": "116079",
    "end": "118200"
  },
  {
    "text": "public preview zero ETL integr ation",
    "start": "118200",
    "end": "120439"
  },
  {
    "text": "step by step and see how is replicating",
    "start": "120439",
    "end": "123079"
  },
  {
    "text": "data in near real time during the demo",
    "start": "123079",
    "end": "125880"
  },
  {
    "text": "we are going to show you how to",
    "start": "125880",
    "end": "127240"
  },
  {
    "text": "correctly set up the zero ETL",
    "start": "127240",
    "end": "129039"
  },
  {
    "text": "integration which is represented in this",
    "start": "129039",
    "end": "131120"
  },
  {
    "text": "diagram there are several prerequisites",
    "start": "131120",
    "end": "133680"
  },
  {
    "text": "to fulfill in order to set up the zero",
    "start": "133680",
    "end": "135720"
  },
  {
    "text": "ETL integration first configure the",
    "start": "135720",
    "end": "138640"
  },
  {
    "text": "Aurora postare SQL source with a",
    "start": "138640",
    "end": "140680"
  },
  {
    "text": "customized DP cluster parameter group",
    "start": "140680",
    "end": "143120"
  },
  {
    "text": "second configure the Amazon red",
    "start": "143120",
    "end": "145040"
  },
  {
    "text": "serverless destination with a required",
    "start": "145040",
    "end": "147120"
  },
  {
    "text": "resource policy for its Nam space thirdd",
    "start": "147120",
    "end": "149959"
  },
  {
    "text": "third update the Reds serverless work",
    "start": "149959",
    "end": "151840"
  },
  {
    "text": "group to enable case sensitive",
    "start": "151840",
    "end": "154040"
  },
  {
    "text": "identifiers and finally configure the",
    "start": "154040",
    "end": "156239"
  },
  {
    "text": "required I IM",
    "start": "156239",
    "end": "159200"
  },
  {
    "start": "159000",
    "end": "209000"
  },
  {
    "text": "permissions there are two options for",
    "start": "159360",
    "end": "161480"
  },
  {
    "text": "setting up all the prerequisites listed",
    "start": "161480",
    "end": "163519"
  },
  {
    "text": "before first manually configuring all",
    "start": "163519",
    "end": "166400"
  },
  {
    "text": "the source and Target parameters and the",
    "start": "166400",
    "end": "168760"
  },
  {
    "text": "second option would be fix it for me",
    "start": "168760",
    "end": "170800"
  },
  {
    "text": "option this pops up when creating the",
    "start": "170800",
    "end": "172959"
  },
  {
    "text": "zero ETL integration we will see it",
    "start": "172959",
    "end": "175040"
  },
  {
    "text": "later in the video and this way the AWS",
    "start": "175040",
    "end": "177959"
  },
  {
    "text": "console will make all the necessary API",
    "start": "177959",
    "end": "180480"
  },
  {
    "text": "calls under the hood for",
    "start": "180480",
    "end": "182440"
  },
  {
    "text": "you as a very important note for this",
    "start": "182440",
    "end": "185560"
  },
  {
    "text": "preview version of this integration you",
    "start": "185560",
    "end": "187959"
  },
  {
    "text": "must associate the cluster with the",
    "start": "187959",
    "end": "190000"
  },
  {
    "text": "custom DB cluster parameter group while",
    "start": "190000",
    "end": "192560"
  },
  {
    "text": "creating the cluster you cannot perform",
    "start": "192560",
    "end": "195200"
  },
  {
    "text": "this action after the source Aurora",
    "start": "195200",
    "end": "197080"
  },
  {
    "text": "posare SQL database cluster is already",
    "start": "197080",
    "end": "199760"
  },
  {
    "text": "created this means that the fix it for",
    "start": "199760",
    "end": "202000"
  },
  {
    "text": "me option will only work for the retive",
    "start": "202000",
    "end": "204519"
  },
  {
    "text": "data warehouse Target for this preview",
    "start": "204519",
    "end": "207159"
  },
  {
    "text": "version of the",
    "start": "207159",
    "end": "208760"
  },
  {
    "text": "integration let's get started with the",
    "start": "208760",
    "end": "211720"
  },
  {
    "start": "209000",
    "end": "415000"
  },
  {
    "text": "demo to set up the zero ETL integration",
    "start": "211720",
    "end": "214840"
  },
  {
    "text": "since it is in public preview you must",
    "start": "214840",
    "end": "216760"
  },
  {
    "text": "create an aurora postgress SQL database",
    "start": "216760",
    "end": "218840"
  },
  {
    "text": "provision cluster within the Amazon",
    "start": "218840",
    "end": "220760"
  },
  {
    "text": "rda's database preview environment in",
    "start": "220760",
    "end": "223200"
  },
  {
    "text": "the US East to Ohio region in the AWS",
    "start": "223200",
    "end": "227680"
  },
  {
    "text": "console navigate to RDS and then scroll",
    "start": "227680",
    "end": "230599"
  },
  {
    "text": "down and click on preview",
    "start": "230599",
    "end": "233680"
  },
  {
    "text": "environment first step to set up the",
    "start": "233680",
    "end": "236040"
  },
  {
    "text": "zero ETL integration is to create a",
    "start": "236040",
    "end": "238120"
  },
  {
    "text": "cluster parameter group so the Amazon",
    "start": "238120",
    "end": "240280"
  },
  {
    "text": "rdas preview console left menu click on",
    "start": "240280",
    "end": "244079"
  },
  {
    "text": "parameter groups then click on create",
    "start": "244079",
    "end": "246400"
  },
  {
    "text": "new parameter",
    "start": "246400",
    "end": "249040"
  },
  {
    "text": "group select postgress SQL DB family",
    "start": "249360",
    "end": "253000"
  },
  {
    "text": "Aurora postgressql 15 the type DB",
    "start": "253000",
    "end": "256560"
  },
  {
    "text": "cluster parameter group another",
    "start": "256560",
    "end": "258440"
  },
  {
    "text": "description and click",
    "start": "258440",
    "end": "261519"
  },
  {
    "text": "create select the new parameter group",
    "start": "261960",
    "end": "264520"
  },
  {
    "text": "and under actions choose edit then set",
    "start": "264520",
    "end": "267440"
  },
  {
    "text": "the following Aurora postgress SQL",
    "start": "267440",
    "end": "269280"
  },
  {
    "text": "cluster parameter settings RDS logical",
    "start": "269280",
    "end": "271919"
  },
  {
    "text": "replication to one Aurora enhanced",
    "start": "271919",
    "end": "275080"
  },
  {
    "text": "logical replication to one Aurora",
    "start": "275080",
    "end": "277680"
  },
  {
    "text": "logical replication backup to zero and",
    "start": "277680",
    "end": "280080"
  },
  {
    "text": "then Aurora logical replication Global",
    "start": "280080",
    "end": "282400"
  },
  {
    "text": "DB to",
    "start": "282400",
    "end": "285440"
  },
  {
    "text": "zero enabling an enhanced logical",
    "start": "285440",
    "end": "288000"
  },
  {
    "text": "replication automatically sets the",
    "start": "288000",
    "end": "289919"
  },
  {
    "text": "replica identity parameter to full which",
    "start": "289919",
    "end": "292320"
  },
  {
    "text": "means that all colume volumes are",
    "start": "292320",
    "end": "294360"
  },
  {
    "text": "written to the right ahead log after",
    "start": "294360",
    "end": "297400"
  },
  {
    "text": "changing the parameters click on Save",
    "start": "297400",
    "end": "299440"
  },
  {
    "text": "change es and now is the turn to create",
    "start": "299440",
    "end": "302080"
  },
  {
    "text": "database choose databases in the",
    "start": "302080",
    "end": "304120"
  },
  {
    "text": "navigation pane then choose create",
    "start": "304120",
    "end": "305960"
  },
  {
    "text": "database and for engine options choose",
    "start": "305960",
    "end": "308280"
  },
  {
    "text": "Amazon Aurora for Edition choose Amazon",
    "start": "308280",
    "end": "310720"
  },
  {
    "text": "Aurora post SQL compatible Edition and",
    "start": "310720",
    "end": "313199"
  },
  {
    "text": "for available version choose Aurora poql",
    "start": "313199",
    "end": "315560"
  },
  {
    "text": "compatible with post SQL 15.4 and Zer",
    "start": "315560",
    "end": "318600"
  },
  {
    "text": "ETL support for templates select produ",
    "start": "318600",
    "end": "321639"
  },
  {
    "text": "production then enter a DV cluster",
    "start": "321639",
    "end": "326720"
  },
  {
    "text": "identifier under credential settings set",
    "start": "327360",
    "end": "330080"
  },
  {
    "text": "the master password or you can also use",
    "start": "330080",
    "end": "332520"
  },
  {
    "text": "the option to a autogenerate the",
    "start": "332520",
    "end": "334440"
  },
  {
    "text": "password for",
    "start": "334440",
    "end": "335919"
  },
  {
    "text": "you under instance configuration memory",
    "start": "335919",
    "end": "339039"
  },
  {
    "text": "optimized classes has been chosen for",
    "start": "339039",
    "end": "341199"
  },
  {
    "text": "this demo selecting DB r6g 2x large",
    "start": "341199",
    "end": "345160"
  },
  {
    "text": "instance side scroll down to additional",
    "start": "345160",
    "end": "348479"
  },
  {
    "text": "configuration and for DB classer",
    "start": "348479",
    "end": "350840"
  },
  {
    "text": "parameter group choose the parameter",
    "start": "350840",
    "end": "352759"
  },
  {
    "text": "group that you created",
    "start": "352759",
    "end": "355880"
  },
  {
    "text": "earlier after that scroll down and click",
    "start": "356000",
    "end": "358720"
  },
  {
    "text": "on create database in a few minutes this",
    "start": "358720",
    "end": "361000"
  },
  {
    "text": "should spin up an aurora pogress SQL",
    "start": "361000",
    "end": "362880"
  },
  {
    "text": "cluster with one writer and one reader",
    "start": "362880",
    "end": "365039"
  },
  {
    "text": "instance with the status changing from",
    "start": "365039",
    "end": "367240"
  },
  {
    "text": "creating to available this Aurora",
    "start": "367240",
    "end": "369840"
  },
  {
    "text": "postgress SQL cluster that we just",
    "start": "369840",
    "end": "371599"
  },
  {
    "text": "created will be the source from the zero",
    "start": "371599",
    "end": "373680"
  },
  {
    "text": "ETL",
    "start": "373680",
    "end": "375160"
  },
  {
    "text": "integration next thing we need to do is",
    "start": "375160",
    "end": "377400"
  },
  {
    "text": "to create a named database in the Aurora",
    "start": "377400",
    "end": "379919"
  },
  {
    "text": "postgress SQL cluster when setting up",
    "start": "379919",
    "end": "382680"
  },
  {
    "text": "postgress SQL you get three standard",
    "start": "382680",
    "end": "384800"
  },
  {
    "text": "databases out of the box template zero",
    "start": "384800",
    "end": "387280"
  },
  {
    "text": "template one and postgress then named",
    "start": "387280",
    "end": "390039"
  },
  {
    "text": "database for the zero ETL integration is",
    "start": "390039",
    "end": "392560"
  },
  {
    "text": "required to be created using template",
    "start": "392560",
    "end": "394639"
  },
  {
    "text": "one and not template zero which is the",
    "start": "394639",
    "end": "396680"
  },
  {
    "text": "default one when creating the named",
    "start": "396680",
    "end": "398720"
  },
  {
    "text": "database in the classer creation step so",
    "start": "398720",
    "end": "402120"
  },
  {
    "text": "to create a new named database using the",
    "start": "402120",
    "end": "404840"
  },
  {
    "text": "creat database statement within the",
    "start": "404840",
    "end": "407520"
  },
  {
    "text": "Aurora postare SQL cluster we need to",
    "start": "407520",
    "end": "409919"
  },
  {
    "text": "connect to the cluster right at endpoint",
    "start": "409919",
    "end": "412160"
  },
  {
    "text": "and run the SQL",
    "start": "412160",
    "end": "414319"
  },
  {
    "text": "Commander the following instructions",
    "start": "414319",
    "end": "416520"
  },
  {
    "start": "415000",
    "end": "460000"
  },
  {
    "text": "from the AWS official documentation",
    "start": "416520",
    "end": "418879"
  },
  {
    "text": "shows in detail how to create an ec2",
    "start": "418879",
    "end": "421479"
  },
  {
    "text": "instance in a public subnet within the",
    "start": "421479",
    "end": "423720"
  },
  {
    "text": "same PPC as the Aurora postgress cluster",
    "start": "423720",
    "end": "426680"
  },
  {
    "text": "this way you can SSH the ec2 instance",
    "start": "426680",
    "end": "429759"
  },
  {
    "text": "from your local machine and safely",
    "start": "429759",
    "end": "431680"
  },
  {
    "text": "connect to the Aurora postest SQL",
    "start": "431680",
    "end": "433960"
  },
  {
    "text": "cluster to create that name database",
    "start": "433960",
    "end": "436360"
  },
  {
    "text": "that we",
    "start": "436360",
    "end": "438520"
  },
  {
    "text": "need now from a terminal or using AWS",
    "start": "438520",
    "end": "441759"
  },
  {
    "text": "Cloud shell SSH into the postle cluster",
    "start": "441759",
    "end": "444800"
  },
  {
    "text": "and then run the following commands",
    "start": "444800",
    "end": "446680"
  },
  {
    "text": "stated on the blog to install psql and",
    "start": "446680",
    "end": "450039"
  },
  {
    "text": "then create the new",
    "start": "450039",
    "end": "452879"
  },
  {
    "text": "database next step is to create the",
    "start": "459120",
    "end": "461440"
  },
  {
    "start": "460000",
    "end": "585000"
  },
  {
    "text": "target data warehouse we will be",
    "start": "461440",
    "end": "463280"
  },
  {
    "text": "creating a data warehouse using Amazon",
    "start": "463280",
    "end": "465479"
  },
  {
    "text": "Redi serverless in preview two",
    "start": "465479",
    "end": "468039"
  },
  {
    "text": "requisites for that you must create your",
    "start": "468039",
    "end": "470120"
  },
  {
    "text": "target Data Warehouse in preview on the",
    "start": "470120",
    "end": "472000"
  },
  {
    "text": "preview 2023 tag and also you must",
    "start": "472000",
    "end": "474919"
  },
  {
    "text": "create your target Data Warehouse in the",
    "start": "474919",
    "end": "476840"
  },
  {
    "text": "US East Ohio AWS region",
    "start": "476840",
    "end": "480199"
  },
  {
    "text": "to create the warehouse navigate to the",
    "start": "480199",
    "end": "482000"
  },
  {
    "text": "Amazon Rift console on the left pane",
    "start": "482000",
    "end": "484159"
  },
  {
    "text": "select serverless dashboard and then",
    "start": "484159",
    "end": "486240"
  },
  {
    "text": "select button create preview work group",
    "start": "486240",
    "end": "488400"
  },
  {
    "text": "within the serverless dashboard set the",
    "start": "488400",
    "end": "490680"
  },
  {
    "text": "name of the work group you can also set",
    "start": "490680",
    "end": "492680"
  },
  {
    "text": "the maximum capacity of the work group",
    "start": "492680",
    "end": "494280"
  },
  {
    "text": "in increments of eight for this case we",
    "start": "494280",
    "end": "496479"
  },
  {
    "text": "chose eight rpu then you create a new",
    "start": "496479",
    "end": "500199"
  },
  {
    "text": "namespace you set the name of the new",
    "start": "500199",
    "end": "502919"
  },
  {
    "text": "namespace and finally click next and in",
    "start": "502919",
    "end": "505759"
  },
  {
    "text": "the review and create step click on",
    "start": "505759",
    "end": "508120"
  },
  {
    "text": "create work group",
    "start": "508120",
    "end": "511440"
  },
  {
    "text": "once the word group and namespace are",
    "start": "511800",
    "end": "513680"
  },
  {
    "text": "available navigate to the namespace",
    "start": "513680",
    "end": "515880"
  },
  {
    "text": "configuration and select the resource",
    "start": "515880",
    "end": "517719"
  },
  {
    "text": "policy",
    "start": "517719",
    "end": "519279"
  },
  {
    "text": "tab then choose add authorized principle",
    "start": "519279",
    "end": "523560"
  },
  {
    "text": "you can enter the Arn of the AWS user or",
    "start": "523560",
    "end": "527160"
  },
  {
    "text": "role or the ID of the AWS account that",
    "start": "527160",
    "end": "529440"
  },
  {
    "text": "you want to Grant access to the to",
    "start": "529440",
    "end": "531600"
  },
  {
    "text": "create zero ETL Integrations next click",
    "start": "531600",
    "end": "535399"
  },
  {
    "text": "on ADD authorized integration Source",
    "start": "535399",
    "end": "538240"
  },
  {
    "text": "specify the Arn of the Aurora postgress",
    "start": "538240",
    "end": "540839"
  },
  {
    "text": "SQL cluster as the authorized",
    "start": "540839",
    "end": "542640"
  },
  {
    "text": "integration Source since it's the source",
    "start": "542640",
    "end": "544800"
  },
  {
    "text": "of the zero ETL",
    "start": "544800",
    "end": "547839"
  },
  {
    "text": "integration Amazon Aurora poql is case",
    "start": "549240",
    "end": "552480"
  },
  {
    "text": "sensitive by default and Amazon red",
    "start": "552480",
    "end": "554640"
  },
  {
    "text": "shift is case insensitive by default in",
    "start": "554640",
    "end": "557519"
  },
  {
    "text": "order to set up the zero ETL integration",
    "start": "557519",
    "end": "560000"
  },
  {
    "text": "we need to make our Rive serverless work",
    "start": "560000",
    "end": "562320"
  },
  {
    "text": "group casee sensitive we can modify the",
    "start": "562320",
    "end": "565079"
  },
  {
    "text": "parameter using the AWS CLI since the",
    "start": "565079",
    "end": "567839"
  },
  {
    "text": "Amazon rief console does doesn't",
    "start": "567839",
    "end": "569600"
  },
  {
    "text": "currently support modifying Redi",
    "start": "569600",
    "end": "571320"
  },
  {
    "text": "serverless parameters values the command",
    "start": "571320",
    "end": "574200"
  },
  {
    "text": "line to change the parameter value is",
    "start": "574200",
    "end": "575800"
  },
  {
    "text": "provided in the AWS official",
    "start": "575800",
    "end": "577240"
  },
  {
    "text": "documentation as seen in the demo and in",
    "start": "577240",
    "end": "579640"
  },
  {
    "text": "this case I am using AWS Cloud shell to",
    "start": "579640",
    "end": "582160"
  },
  {
    "text": "modify the",
    "start": "582160",
    "end": "584720"
  },
  {
    "text": "parameter as a next step to create a",
    "start": "584720",
    "end": "587240"
  },
  {
    "start": "585000",
    "end": "678000"
  },
  {
    "text": "zero ETL integration your user or role",
    "start": "587240",
    "end": "590200"
  },
  {
    "text": "must have attached an identity based",
    "start": "590200",
    "end": "592200"
  },
  {
    "text": "policy with the appropriate IIM",
    "start": "592200",
    "end": "594120"
  },
  {
    "text": "permissions the following sample policy",
    "start": "594120",
    "end": "596440"
  },
  {
    "text": "from the AWS documentation allows the",
    "start": "596440",
    "end": "598760"
  },
  {
    "text": "associated principle to perform the",
    "start": "598760",
    "end": "600519"
  },
  {
    "text": "following actions first to create zero",
    "start": "600519",
    "end": "603120"
  },
  {
    "text": "ETL Integrations for the Aurora DB",
    "start": "603120",
    "end": "605760"
  },
  {
    "text": "cluster View and delete all the zero ETL",
    "start": "605760",
    "end": "609240"
  },
  {
    "text": "Integrations and also create inbound",
    "start": "609240",
    "end": "611680"
  },
  {
    "text": "Integrations into the target data",
    "start": "611680",
    "end": "613440"
  },
  {
    "text": "warehouse you can go ahead and copy the",
    "start": "613440",
    "end": "616320"
  },
  {
    "text": "provided sample",
    "start": "616320",
    "end": "617839"
  },
  {
    "text": "policy let's create the policy in the",
    "start": "617839",
    "end": "620160"
  },
  {
    "text": "AWS account navigate to the I am console",
    "start": "620160",
    "end": "623560"
  },
  {
    "text": "and on the left menu click on policies",
    "start": "623560",
    "end": "626240"
  },
  {
    "text": "next click on create policy we are going",
    "start": "626240",
    "end": "629519"
  },
  {
    "text": "to modify the Json code directly and now",
    "start": "629519",
    "end": "632560"
  },
  {
    "text": "you can paste the sample policy from the",
    "start": "632560",
    "end": "634800"
  },
  {
    "text": "AWS documentation that we just copied we",
    "start": "634800",
    "end": "637959"
  },
  {
    "text": "have to modify the region AWS account",
    "start": "637959",
    "end": "640440"
  },
  {
    "text": "red shift endpoint and aora cluster",
    "start": "640440",
    "end": "642320"
  },
  {
    "text": "endpoint from the",
    "start": "642320",
    "end": "643720"
  },
  {
    "text": "sample important note from the AWS",
    "start": "643720",
    "end": "646200"
  },
  {
    "text": "documentation make sure you include the",
    "start": "646200",
    "end": "648360"
  },
  {
    "text": "preview prefix in the RDS Arn and also",
    "start": "648360",
    "end": "651600"
  },
  {
    "text": "note that the Arns from Red provision",
    "start": "651600",
    "end": "654519"
  },
  {
    "text": "and red serverless and are",
    "start": "654519",
    "end": "657200"
  },
  {
    "text": "different now click on next set a name",
    "start": "657200",
    "end": "660000"
  },
  {
    "text": "and a description for the",
    "start": "660000",
    "end": "661800"
  },
  {
    "text": "policy you may see errors related to the",
    "start": "661800",
    "end": "664519"
  },
  {
    "text": "preview prefix that I mentioned before",
    "start": "664519",
    "end": "666399"
  },
  {
    "text": "but that's completely normal and now you",
    "start": "666399",
    "end": "668800"
  },
  {
    "text": "can attach this policy to any user or",
    "start": "668800",
    "end": "670880"
  },
  {
    "text": "role that needs to have permissions to",
    "start": "670880",
    "end": "672760"
  },
  {
    "text": "create Aurora post equal Z ETL",
    "start": "672760",
    "end": "677079"
  },
  {
    "start": "678000",
    "end": "789000"
  },
  {
    "text": "Integrations as we mentioned at the",
    "start": "678279",
    "end": "680160"
  },
  {
    "text": "beginning of this demo for this preview",
    "start": "680160",
    "end": "682240"
  },
  {
    "text": "version of the integration you must",
    "start": "682240",
    "end": "684000"
  },
  {
    "text": "associate the Aurora postgress cluster",
    "start": "684000",
    "end": "686000"
  },
  {
    "text": "with the custom DB parameter group when",
    "start": "686000",
    "end": "688120"
  },
  {
    "text": "creating the cluster you cannot perform",
    "start": "688120",
    "end": "690440"
  },
  {
    "text": "this action after the source DB cluster",
    "start": "690440",
    "end": "692360"
  },
  {
    "text": "is already created that's why we need",
    "start": "692360",
    "end": "695000"
  },
  {
    "text": "all this manually configuration for the",
    "start": "695000",
    "end": "696839"
  },
  {
    "text": "cluster parameter group for the source",
    "start": "696839",
    "end": "699639"
  },
  {
    "text": "however the target data warehouse",
    "start": "699639",
    "end": "701040"
  },
  {
    "text": "parameter could be fixed automatically",
    "start": "701040",
    "end": "703000"
  },
  {
    "text": "by the AWS console so first let's see",
    "start": "703000",
    "end": "705880"
  },
  {
    "text": "how this fix it for me option",
    "start": "705880",
    "end": "708639"
  },
  {
    "text": "works navigate to the RDS previous",
    "start": "708639",
    "end": "711320"
  },
  {
    "text": "console and select create zero ETL",
    "start": "711320",
    "end": "713760"
  },
  {
    "text": "integration give the integration a name",
    "start": "713760",
    "end": "716200"
  },
  {
    "text": "and click",
    "start": "716200",
    "end": "717600"
  },
  {
    "text": "next for the sources select browse RDA",
    "start": "717600",
    "end": "720800"
  },
  {
    "text": "databases and select the Aurora",
    "start": "720800",
    "end": "722240"
  },
  {
    "text": "postgress cluster and also enter the",
    "start": "722240",
    "end": "724920"
  },
  {
    "text": "name database that we previously",
    "start": "724920",
    "end": "727040"
  },
  {
    "text": "created next select the target redip",
    "start": "727040",
    "end": "729880"
  },
  {
    "text": "data warehouse I created a test Target",
    "start": "729880",
    "end": "732160"
  },
  {
    "text": "data warehouse that do not have the",
    "start": "732160",
    "end": "733600"
  },
  {
    "text": "parameters fixed just for the purpose of",
    "start": "733600",
    "end": "735760"
  },
  {
    "text": "the",
    "start": "735760",
    "end": "737680"
  },
  {
    "text": "demo you will see this message that asks",
    "start": "737680",
    "end": "740360"
  },
  {
    "text": "you to fix the resource policy and the",
    "start": "740360",
    "end": "742440"
  },
  {
    "text": "case sensitivity parameter so let's",
    "start": "742440",
    "end": "744839"
  },
  {
    "text": "select fix it for",
    "start": "744839",
    "end": "746639"
  },
  {
    "text": "me with the fix it for me option the AWS",
    "start": "746639",
    "end": "750040"
  },
  {
    "text": "console will make all the necessary IPI",
    "start": "750040",
    "end": "752360"
  },
  {
    "text": "calls under the hood for you so you",
    "start": "752360",
    "end": "754040"
  },
  {
    "text": "don't have to manually modify the target",
    "start": "754040",
    "end": "758000"
  },
  {
    "text": "parameters after reviewing all the",
    "start": "761760",
    "end": "763839"
  },
  {
    "text": "configuration options click on create",
    "start": "763839",
    "end": "765959"
  },
  {
    "text": "zero ETL integration you will need to",
    "start": "765959",
    "end": "768760"
  },
  {
    "text": "wait until the retive target is fully",
    "start": "768760",
    "end": "770680"
  },
  {
    "text": "configured to actually create the",
    "start": "770680",
    "end": "774399"
  },
  {
    "text": "integration",
    "start": "778120",
    "end": "779959"
  },
  {
    "text": "now you can see that the integration is",
    "start": "779959",
    "end": "781519"
  },
  {
    "text": "creating successfully and it'll take",
    "start": "781519",
    "end": "783519"
  },
  {
    "text": "around 20 to 30 minutes for the",
    "start": "783519",
    "end": "785120"
  },
  {
    "text": "integration to be",
    "start": "785120",
    "end": "787920"
  },
  {
    "start": "789000",
    "end": "1038000"
  },
  {
    "text": "active now that we have covered how the",
    "start": "789399",
    "end": "791880"
  },
  {
    "text": "fix it for me Works let's create an",
    "start": "791880",
    "end": "793959"
  },
  {
    "text": "integration using the original Source",
    "start": "793959",
    "end": "796000"
  },
  {
    "text": "cluster and Target work group since we",
    "start": "796000",
    "end": "798160"
  },
  {
    "text": "have worked on the requirements manually",
    "start": "798160",
    "end": "799959"
  },
  {
    "text": "on the",
    "start": "799959",
    "end": "801000"
  },
  {
    "text": "video navigate to the rdas preview",
    "start": "801000",
    "end": "803680"
  },
  {
    "text": "console and from the left menu click on",
    "start": "803680",
    "end": "805880"
  },
  {
    "text": "zero ETL Integrations select create zero",
    "start": "805880",
    "end": "809079"
  },
  {
    "text": "ETL",
    "start": "809079",
    "end": "811160"
  },
  {
    "text": "integration give the integration a name",
    "start": "811160",
    "end": "813519"
  },
  {
    "text": "and click next for the sources select",
    "start": "813519",
    "end": "816639"
  },
  {
    "text": "Bros RDS databases and select the aota",
    "start": "816639",
    "end": "819360"
  },
  {
    "text": "postgress SQL cluster also enter the",
    "start": "819360",
    "end": "821959"
  },
  {
    "text": "named database that we previously",
    "start": "821959",
    "end": "824279"
  },
  {
    "text": "created next select the target R of data",
    "start": "824279",
    "end": "829240"
  },
  {
    "text": "warehouse after review the configuration",
    "start": "831639",
    "end": "834360"
  },
  {
    "text": "click on create zero ETL integration it",
    "start": "834360",
    "end": "837240"
  },
  {
    "text": "takes around 20 to 30 minutes for the",
    "start": "837240",
    "end": "839320"
  },
  {
    "text": "integration to be active on your",
    "start": "839320",
    "end": "842880"
  },
  {
    "text": "account now that the integration is",
    "start": "844560",
    "end": "846759"
  },
  {
    "text": "active let's create a database in",
    "start": "846759",
    "end": "848480"
  },
  {
    "text": "redshift and query the data replicated",
    "start": "848480",
    "end": "850399"
  },
  {
    "text": "from the Aurora database navigate to the",
    "start": "850399",
    "end": "852800"
  },
  {
    "text": "query editor V2 in redshift and connect",
    "start": "852800",
    "end": "855000"
  },
  {
    "text": "to the r of serers work group we are",
    "start": "855000",
    "end": "857160"
  },
  {
    "text": "going to use the svv integration system",
    "start": "857160",
    "end": "859480"
  },
  {
    "text": "table to obtain the integration ID to",
    "start": "859480",
    "end": "862079"
  },
  {
    "text": "create a database in red shift where the",
    "start": "862079",
    "end": "863880"
  },
  {
    "text": "data will be replicated from the Aurora",
    "start": "863880",
    "end": "865839"
  },
  {
    "text": "DV",
    "start": "865839",
    "end": "867680"
  },
  {
    "text": "cluster query the svv integration table",
    "start": "867680",
    "end": "871040"
  },
  {
    "text": "get the integration ID and use the",
    "start": "871040",
    "end": "873279"
  },
  {
    "text": "create database command as shown in the",
    "start": "873279",
    "end": "875440"
  },
  {
    "text": "video if we navigate in the left menu we",
    "start": "875440",
    "end": "878160"
  },
  {
    "text": "can see that the database has been",
    "start": "878160",
    "end": "879759"
  },
  {
    "text": "created as",
    "start": "879759",
    "end": "882480"
  },
  {
    "text": "expected let's generate some data in the",
    "start": "883000",
    "end": "885519"
  },
  {
    "text": "Aurora postgress SQL database that can",
    "start": "885519",
    "end": "887399"
  },
  {
    "text": "be replicated into the redip warehouse",
    "start": "887399",
    "end": "889959"
  },
  {
    "text": "use your local terminal to connect to",
    "start": "889959",
    "end": "891639"
  },
  {
    "text": "the Aurora postgress cluster as we did",
    "start": "891639",
    "end": "893600"
  },
  {
    "text": "before using the following command",
    "start": "893600",
    "end": "895800"
  },
  {
    "text": "create the table",
    "start": "895800",
    "end": "897199"
  },
  {
    "text": "Nation with the primary key key Nation",
    "start": "897199",
    "end": "900000"
  },
  {
    "text": "key now let's enter some dami data as",
    "start": "900000",
    "end": "903079"
  },
  {
    "text": "shown in the",
    "start": "903079",
    "end": "904560"
  },
  {
    "text": "video navigate back to the Redi console",
    "start": "904560",
    "end": "907440"
  },
  {
    "text": "and refresh the database in Redi to see",
    "start": "907440",
    "end": "909480"
  },
  {
    "text": "what happens the table Nation now is",
    "start": "909480",
    "end": "911959"
  },
  {
    "text": "replicated and if we query the table we",
    "start": "911959",
    "end": "914440"
  },
  {
    "text": "can see that the data that we just",
    "start": "914440",
    "end": "915880"
  },
  {
    "text": "entered in the Aurora postgress SQL",
    "start": "915880",
    "end": "917839"
  },
  {
    "text": "cluster is now in red shift the system",
    "start": "917839",
    "end": "920440"
  },
  {
    "text": "table svv integration activity displays",
    "start": "920440",
    "end": "923360"
  },
  {
    "text": "details about completed integration",
    "start": "923360",
    "end": "925199"
  },
  {
    "text": "Bruns that happens under the hood as a",
    "start": "925199",
    "end": "928199"
  },
  {
    "text": "final check that the replication happens",
    "start": "928199",
    "end": "930040"
  },
  {
    "text": "in near real time let's add a new value",
    "start": "930040",
    "end": "932880"
  },
  {
    "text": "in our Aurora postra SQL Nation table",
    "start": "932880",
    "end": "935480"
  },
  {
    "text": "and query the table again in Redi query",
    "start": "935480",
    "end": "938040"
  },
  {
    "text": "editor V2 the new row is in red shift",
    "start": "938040",
    "end": "941040"
  },
  {
    "text": "seconds after inserting it in the source",
    "start": "941040",
    "end": "944040"
  },
  {
    "text": "this data replicated from Aurora can be",
    "start": "944040",
    "end": "946000"
  },
  {
    "text": "used in queries that join tables from",
    "start": "946000",
    "end": "947959"
  },
  {
    "text": "other red ship databases",
    "start": "947959",
    "end": "950560"
  },
  {
    "text": "too regarding monitoring the state of",
    "start": "950560",
    "end": "953120"
  },
  {
    "text": "the zero ETL integration there are",
    "start": "953120",
    "end": "955160"
  },
  {
    "text": "several options to obtain metrics on the",
    "start": "955160",
    "end": "957079"
  },
  {
    "text": "performance and status of the",
    "start": "957079",
    "end": "958440"
  },
  {
    "text": "integration",
    "start": "958440",
    "end": "959440"
  },
  {
    "text": "navigate to the Amazon red shift console",
    "start": "959440",
    "end": "961399"
  },
  {
    "text": "select zero ETL Integrations and there",
    "start": "961399",
    "end": "963800"
  },
  {
    "text": "you can choose the zero ETL integration",
    "start": "963800",
    "end": "965680"
  },
  {
    "text": "you want to display Amazon cloudwatch",
    "start": "965680",
    "end": "968079"
  },
  {
    "text": "metrics related to that integration",
    "start": "968079",
    "end": "970440"
  },
  {
    "text": "these metrics are also directly",
    "start": "970440",
    "end": "972079"
  },
  {
    "text": "available on Amazon cloudwatch for each",
    "start": "972079",
    "end": "974959"
  },
  {
    "text": "integration there are two tabes with",
    "start": "974959",
    "end": "976480"
  },
  {
    "text": "information available integration",
    "start": "976480",
    "end": "978240"
  },
  {
    "text": "metrics with metrics such as the number",
    "start": "978240",
    "end": "980079"
  },
  {
    "text": "of tables successfully replicated and",
    "start": "980079",
    "end": "982279"
  },
  {
    "text": "lack details and also table statistics",
    "start": "982279",
    "end": "985880"
  },
  {
    "text": "with details about each table replicated",
    "start": "985880",
    "end": "987959"
  },
  {
    "text": "from the Aurora post SQL to Amazon red",
    "start": "987959",
    "end": "992160"
  },
  {
    "text": "shift in addition to the Amazon",
    "start": "993279",
    "end": "995600"
  },
  {
    "text": "cloudwatch metrics you can query the",
    "start": "995600",
    "end": "997639"
  },
  {
    "text": "following system views and tables which",
    "start": "997639",
    "end": "1000240"
  },
  {
    "text": "provide information about the",
    "start": "1000240",
    "end": "1001880"
  },
  {
    "text": "Integrations svv integration which",
    "start": "1001880",
    "end": "1004680"
  },
  {
    "text": "displays details about the configuration",
    "start": "1004680",
    "end": "1007120"
  },
  {
    "text": "of the Integrations C integration",
    "start": "1007120",
    "end": "1009759"
  },
  {
    "text": "activity which displays details about",
    "start": "1009759",
    "end": "1011920"
  },
  {
    "text": "completed integration",
    "start": "1011920",
    "end": "1013600"
  },
  {
    "text": "runs and finally sbv integration table",
    "start": "1013600",
    "end": "1016920"
  },
  {
    "text": "state which displays details about table",
    "start": "1016920",
    "end": "1019319"
  },
  {
    "text": "level integration",
    "start": "1019319",
    "end": "1021839"
  },
  {
    "text": "information this concludes our demo on",
    "start": "1021839",
    "end": "1024319"
  },
  {
    "text": "Zer ETL integration from Amazon Aurora",
    "start": "1024319",
    "end": "1026880"
  },
  {
    "text": "post SQL to Amazon red shift in public",
    "start": "1026880",
    "end": "1029319"
  },
  {
    "text": "preview hope you like this feature as",
    "start": "1029319",
    "end": "1031480"
  },
  {
    "text": "much as we do and thank you so much for",
    "start": "1031480",
    "end": "1035480"
  },
  {
    "text": "watching",
    "start": "1037039",
    "end": "1040038"
  }
]
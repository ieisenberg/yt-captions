[
  {
    "start": "0",
    "end": "79000"
  },
  {
    "text": "- [John] Hi, this is\nJohn Standish with AWS.",
    "start": "1860",
    "end": "4810"
  },
  {
    "text": "This is part four in our video series",
    "start": "4810",
    "end": "6540"
  },
  {
    "text": "about modernizing applications on AWS.",
    "start": "6540",
    "end": "9197"
  },
  {
    "text": "In this video series,",
    "start": "10570",
    "end": "12679"
  },
  {
    "text": "our customer, Acme Financial Data Service,",
    "start": "12680",
    "end": "15000"
  },
  {
    "text": "has been going through a process\nof moving their application",
    "start": "15000",
    "end": "17430"
  },
  {
    "text": "from a legacy monolith on premises",
    "start": "17430",
    "end": "20010"
  },
  {
    "text": "to modern architecture on AWS.",
    "start": "20010",
    "end": "21977"
  },
  {
    "text": "Let's take a quick recap\nwhere our customer,",
    "start": "24330",
    "end": "26750"
  },
  {
    "text": "Acme Financial Data Service,\nis at in their journey.",
    "start": "26750",
    "end": "29713"
  },
  {
    "text": "In the previous video series,",
    "start": "33580",
    "end": "35090"
  },
  {
    "text": "Acme Financial Data Service was able",
    "start": "35090",
    "end": "36940"
  },
  {
    "text": "to segment out functionality",
    "start": "36940",
    "end": "38219"
  },
  {
    "text": "of their monolithic application.",
    "start": "38220",
    "end": "39863"
  },
  {
    "text": "They were able to convert\ntheir existing application",
    "start": "41210",
    "end": "44739"
  },
  {
    "text": "to .NET Core, and they're able to package",
    "start": "44740",
    "end": "48010"
  },
  {
    "text": "and containerize their\napplications with Docker.",
    "start": "48010",
    "end": "50410"
  },
  {
    "text": "Currently, all their\ndata is largely stored",
    "start": "51740",
    "end": "54060"
  },
  {
    "text": "in a single database cluster.",
    "start": "54060",
    "end": "56003"
  },
  {
    "text": "With the increased load on the account",
    "start": "57060",
    "end": "58680"
  },
  {
    "text": "and inventory databases,\nthey've been unable to scale.",
    "start": "58680",
    "end": "61793"
  },
  {
    "text": "Data domains should ultimately\nnow scale in relationship",
    "start": "63110",
    "end": "66790"
  },
  {
    "text": "to their domains and their\napplication domains they're in.",
    "start": "66790",
    "end": "70063"
  },
  {
    "text": "Data models are also increasingly diverse",
    "start": "70960",
    "end": "74190"
  },
  {
    "text": "and not one size is fitting all.",
    "start": "74190",
    "end": "76163"
  },
  {
    "start": "79000",
    "end": "79000"
  },
  {
    "text": "The goal of this session are as follows,",
    "start": "79000",
    "end": "83083"
  },
  {
    "text": "create a data landing zone\nwhere data can be brought in,",
    "start": "84060",
    "end": "89000"
  },
  {
    "text": "transformed and ultimately\nsent to other data sources.",
    "start": "89000",
    "end": "94000"
  },
  {
    "text": "This will enable product teams",
    "start": "95370",
    "end": "96960"
  },
  {
    "text": "to curate diverse data models\nacross different data sources",
    "start": "96960",
    "end": "100430"
  },
  {
    "text": "that they previously had in data silos.",
    "start": "100430",
    "end": "102933"
  },
  {
    "text": "This will also ease in data governance",
    "start": "104430",
    "end": "106360"
  },
  {
    "text": "and being able to quickly identify areas",
    "start": "106360",
    "end": "109590"
  },
  {
    "text": "of concern of where\nmore security is needed,",
    "start": "109590",
    "end": "112522"
  },
  {
    "text": "increase your security posture",
    "start": "113370",
    "end": "115370"
  },
  {
    "text": "with encryption at rest across data",
    "start": "115370",
    "end": "117670"
  },
  {
    "text": "from data sources you previously\nmay not have access to,",
    "start": "117670",
    "end": "120503"
  },
  {
    "text": "and have tight grain\ncontrols over sensitive data.",
    "start": "121440",
    "end": "125643"
  },
  {
    "text": "The other goal is to democratize data",
    "start": "128070",
    "end": "129710"
  },
  {
    "text": "to fit an ever-growing feature set.",
    "start": "129710",
    "end": "132270"
  },
  {
    "text": "As customers request new features,",
    "start": "132270",
    "end": "134623"
  },
  {
    "text": "the number of different data sources",
    "start": "135470",
    "end": "137010"
  },
  {
    "text": "that may be brought in\nwill rapidly increase.",
    "start": "137010",
    "end": "139823"
  },
  {
    "text": "This will also enable advanced use-cases",
    "start": "141590",
    "end": "143569"
  },
  {
    "text": "against structured and unstructured data,",
    "start": "143570",
    "end": "146200"
  },
  {
    "text": "such as advanced analytics\nand machine learning.",
    "start": "146200",
    "end": "149303"
  },
  {
    "text": "It will optimize its data performance",
    "start": "151030",
    "end": "152959"
  },
  {
    "text": "and scale based on the\ndata's access patterns,",
    "start": "152960",
    "end": "156990"
  },
  {
    "text": "not just the underlying\nstorage mechanisms.",
    "start": "156990",
    "end": "159143"
  },
  {
    "text": "So quickly, let's look",
    "start": "161270",
    "end": "163320"
  },
  {
    "text": "at what Acme Financial Data\nServices data landscape,",
    "start": "163320",
    "end": "166063"
  },
  {
    "text": "see what it really looks like.",
    "start": "167260",
    "end": "168760"
  },
  {
    "text": "Currently, all of Acme's data lives",
    "start": "171240",
    "end": "175270"
  },
  {
    "text": "in a single monolithic data hub.",
    "start": "175270",
    "end": "179400"
  },
  {
    "text": "This encompasses account,\ninvoicing, inventory,",
    "start": "179400",
    "end": "183340"
  },
  {
    "text": "shopping, payroll, reporting, and logging.",
    "start": "183340",
    "end": "186773"
  },
  {
    "text": "If we dive a little deeper",
    "start": "188720",
    "end": "190200"
  },
  {
    "start": "189000",
    "end": "189000"
  },
  {
    "text": "and look at the size of these databases,",
    "start": "191050",
    "end": "193430"
  },
  {
    "text": "you'll see that some are\nsimilar to each other.",
    "start": "193430",
    "end": "195853"
  },
  {
    "text": "And though its size may be an indicator",
    "start": "196950",
    "end": "199400"
  },
  {
    "text": "of how frequently accessed this data is,",
    "start": "199400",
    "end": "203560"
  },
  {
    "text": "it may be misleading.",
    "start": "203560",
    "end": "204783"
  },
  {
    "text": "For instance, the most used systems here",
    "start": "205910",
    "end": "209750"
  },
  {
    "text": "are account and inventory.",
    "start": "209750",
    "end": "211890"
  },
  {
    "text": "The amount of transactions\nper second happening",
    "start": "211890",
    "end": "214150"
  },
  {
    "text": "within the account system\nare disproportionate",
    "start": "214150",
    "end": "217280"
  },
  {
    "text": "to any other part of the system.",
    "start": "217280",
    "end": "218867"
  },
  {
    "text": "And we'll go into in a\nsecond why that happens.",
    "start": "218867",
    "end": "222833"
  },
  {
    "text": "The inventory system is\ndesigned as a ledger system,",
    "start": "224100",
    "end": "227370"
  },
  {
    "text": "and thus it must\ncontinuously grow over time.",
    "start": "227370",
    "end": "231069"
  },
  {
    "text": "Inventory is done as a summation over time",
    "start": "231070",
    "end": "235100"
  },
  {
    "text": "and it's restocked by a new entry.",
    "start": "235100",
    "end": "237563"
  },
  {
    "text": "For instance, think of it this way.",
    "start": "238470",
    "end": "240460"
  },
  {
    "text": "If I get do items,",
    "start": "240460",
    "end": "241890"
  },
  {
    "text": "I will add a record to say\nthere are 100 new items,",
    "start": "241890",
    "end": "244930"
  },
  {
    "text": "for every item being\ntaken out of inventory,",
    "start": "244930",
    "end": "247430"
  },
  {
    "text": "I will decrement by the\namount to be taken out.",
    "start": "247430",
    "end": "250620"
  },
  {
    "text": "Maybe it's one or two items,\nand that will build over time.",
    "start": "250620",
    "end": "255290"
  },
  {
    "text": "I know given time, can I\ntruly prune those records,",
    "start": "255290",
    "end": "258720"
  },
  {
    "text": "I ultimately must have record\na in there as a stop record,",
    "start": "258720",
    "end": "263720"
  },
  {
    "text": "meaning it will take the\nprevious amount, sum them up,",
    "start": "264200",
    "end": "267880"
  },
  {
    "text": "and that is my new record,",
    "start": "267880",
    "end": "268960"
  },
  {
    "text": "and I can delete everything past that,",
    "start": "268960",
    "end": "271460"
  },
  {
    "text": "but that's a labor-intensive process.",
    "start": "271460",
    "end": "273383"
  },
  {
    "text": "The account I had mentioned earlier,",
    "start": "274920",
    "end": "277670"
  },
  {
    "text": "it's not as large as some\nof the other databases,",
    "start": "277670",
    "end": "279520"
  },
  {
    "text": "such as reporting or inventory,",
    "start": "279520",
    "end": "282623"
  },
  {
    "text": "yet every request hits\nthe accounting system.",
    "start": "283740",
    "end": "287763"
  },
  {
    "text": "We'll go into a little\nbit more use cases later.",
    "start": "288660",
    "end": "291620"
  },
  {
    "text": "If you look at the reporting database,",
    "start": "291620",
    "end": "293520"
  },
  {
    "text": "it's large, it's 48 gigs\nand is a star schema",
    "start": "293520",
    "end": "296990"
  },
  {
    "text": "that is built for reporting,",
    "start": "296990",
    "end": "298860"
  },
  {
    "text": "and a scheduled job runs at\n3:00 a.m. to update the report.",
    "start": "298860",
    "end": "302973"
  },
  {
    "text": "We could probably take this further,",
    "start": "304470",
    "end": "306610"
  },
  {
    "text": "which we'll explore in the next use case.",
    "start": "306610",
    "end": "308659"
  },
  {
    "start": "309000",
    "end": "309000"
  },
  {
    "text": "So let's talk about some\ncharacteristic issues",
    "start": "311530",
    "end": "314520"
  },
  {
    "text": "that we're identifying here.",
    "start": "314520",
    "end": "315919"
  },
  {
    "text": "You have account as an object\nstyle with relationships.",
    "start": "317410",
    "end": "321970"
  },
  {
    "text": "There's edges to the\ndifferent types of accounts.",
    "start": "321970",
    "end": "325360"
  },
  {
    "text": "For instance, a profile\nmay have a connection",
    "start": "325360",
    "end": "328280"
  },
  {
    "text": "to a credit card or a relationship",
    "start": "328280",
    "end": "331530"
  },
  {
    "text": "to account update, an\naccount audit history.",
    "start": "331530",
    "end": "335223"
  },
  {
    "text": "The inventory, as mentioned earlier,",
    "start": "336740",
    "end": "338370"
  },
  {
    "text": "is a ledger style system.",
    "start": "338370",
    "end": "340650"
  },
  {
    "text": "And this is why we want",
    "start": "340650",
    "end": "342470"
  },
  {
    "text": "to separate these databases to begin with.",
    "start": "342470",
    "end": "345570"
  },
  {
    "text": "The residents within this database",
    "start": "345570",
    "end": "348020"
  },
  {
    "text": "makes it dramatically difficult to scale",
    "start": "348020",
    "end": "350629"
  },
  {
    "text": "and is ultimately only\nfeasible to scale vertically.",
    "start": "351589",
    "end": "355142"
  },
  {
    "text": "You can partition, shard,\nreplicate co-locate data,",
    "start": "356040",
    "end": "360240"
  },
  {
    "text": "yet you still have to decouple",
    "start": "360240",
    "end": "362449"
  },
  {
    "text": "between the schema, compute and\nstorage to ultimately scale.",
    "start": "362450",
    "end": "366363"
  },
  {
    "text": "Because of all these\ndiverse characteristics,",
    "start": "368500",
    "end": "370810"
  },
  {
    "text": "each database will scale differently.",
    "start": "370810",
    "end": "373663"
  },
  {
    "text": "Let's think about that for a second.",
    "start": "375100",
    "end": "376610"
  },
  {
    "text": "The lead system will scale differently",
    "start": "376610",
    "end": "379240"
  },
  {
    "text": "because remember, it builds over time.",
    "start": "379240",
    "end": "381182"
  },
  {
    "text": "The account system will scale based",
    "start": "382890",
    "end": "385050"
  },
  {
    "text": "on the number of users that are in it,",
    "start": "385050",
    "end": "387690"
  },
  {
    "text": "which is a different\nscaling characteristic.",
    "start": "387690",
    "end": "390053"
  },
  {
    "text": "The reporting will scale\nbased on the amount",
    "start": "391080",
    "end": "394090"
  },
  {
    "text": "of data that we want\nto generate reports on",
    "start": "394090",
    "end": "396790"
  },
  {
    "text": "or the types of reports\nwe wanna curate on.",
    "start": "396790",
    "end": "399123"
  },
  {
    "text": "So to ease the pressure on this database",
    "start": "400200",
    "end": "402717"
  },
  {
    "text": "and to scale elastically with our users",
    "start": "402717",
    "end": "404880"
  },
  {
    "text": "and our backend systems,",
    "start": "404880",
    "end": "406323"
  },
  {
    "text": "Acme Financial Data Services\nneeds to move inventory",
    "start": "407290",
    "end": "409783"
  },
  {
    "text": "and the account database somewhere else.",
    "start": "409783",
    "end": "412919"
  },
  {
    "text": "And as a bonus, it'd be nice\nto move the reporting database",
    "start": "412920",
    "end": "416400"
  },
  {
    "text": "to something else that was\nmore purpose-built for this.",
    "start": "416400",
    "end": "419520"
  },
  {
    "text": "Acme Financial Data\nServices has been trying",
    "start": "419520",
    "end": "421470"
  },
  {
    "text": "to get streaming data and\nnear-real time reporting,",
    "start": "421470",
    "end": "424380"
  },
  {
    "text": "not the 3:00 a.m. batch process.",
    "start": "424380",
    "end": "427183"
  },
  {
    "start": "429000",
    "end": "429000"
  },
  {
    "text": "So now that we know the issue, we need",
    "start": "429340",
    "end": "433290"
  },
  {
    "text": "to target the data characteristic to use.",
    "start": "433290",
    "end": "437333"
  },
  {
    "text": "As mentioned earlier,",
    "start": "438670",
    "end": "440080"
  },
  {
    "text": "the account as a single unit,\nit's a person, it's a thing.",
    "start": "440080",
    "end": "444470"
  },
  {
    "text": "The inventory is clearly a ledger",
    "start": "444470",
    "end": "447600"
  },
  {
    "text": "and it increases and\ndecreases for a unit or item.",
    "start": "447600",
    "end": "451503"
  },
  {
    "text": "Reporting is temporal in nature\nas data changes over time.",
    "start": "452710",
    "end": "457093"
  },
  {
    "text": "So now let's get into how we're\ngoing to solve that issue.",
    "start": "458470",
    "end": "463470"
  },
  {
    "text": "What ADFS will need to\nset up is a data lake.",
    "start": "463760",
    "end": "468613"
  },
  {
    "text": "Now that we have so many\nchoices on how to load",
    "start": "470440",
    "end": "473040"
  },
  {
    "text": "and sync and migrate data,",
    "start": "473040",
    "end": "475560"
  },
  {
    "text": "let's talk about where it gets stored",
    "start": "475560",
    "end": "477360"
  },
  {
    "text": "and how ADFS will organize,\nmanage and prepare its data",
    "start": "477360",
    "end": "482360"
  },
  {
    "text": "for analytics and purpose-built databases.",
    "start": "482380",
    "end": "485533"
  },
  {
    "text": "The data itself will be stored on S3.",
    "start": "486490",
    "end": "489272"
  },
  {
    "text": "S3 is an object storage\nwith 11 nines of durability",
    "start": "490640",
    "end": "494480"
  },
  {
    "text": "and will meet ADFS's security requirements",
    "start": "494480",
    "end": "496870"
  },
  {
    "text": "for encryption at rest and in transit,",
    "start": "496870",
    "end": "499850"
  },
  {
    "text": "as well as for DR and\ncost control requirements.",
    "start": "499850",
    "end": "502953"
  },
  {
    "text": "We will also use this",
    "start": "504340",
    "end": "505830"
  },
  {
    "text": "to start a data democratization effort,",
    "start": "505830",
    "end": "508370"
  },
  {
    "text": "which will accelerate ADFS's move",
    "start": "508370",
    "end": "510840"
  },
  {
    "text": "to purpose-built databases we\nwill cover in the next module.",
    "start": "510840",
    "end": "514253"
  },
  {
    "text": "Lake Formation will set\nup a secure data lake",
    "start": "516150",
    "end": "519000"
  },
  {
    "text": "with a data catalog.",
    "start": "519000",
    "end": "520700"
  },
  {
    "text": "ETL transforms, also known as\nextract, transform and load,",
    "start": "520700",
    "end": "524193"
  },
  {
    "text": "and security controls all\nwithin a matter of minutes.",
    "start": "525160",
    "end": "528823"
  },
  {
    "text": "We will also use Glue to\nmanage our ETL process",
    "start": "530900",
    "end": "534320"
  },
  {
    "text": "for ADFS using their\nexisting Spark scripts.",
    "start": "534320",
    "end": "537893"
  },
  {
    "text": "As a definition, a data lake\nis the new information hub.",
    "start": "540820",
    "end": "545370"
  },
  {
    "text": "It's a central secure repository\nthat enables you to govern,",
    "start": "545370",
    "end": "549050"
  },
  {
    "text": "discover, share, analyze structured",
    "start": "549050",
    "end": "551750"
  },
  {
    "text": "and unstructured data at any scale.",
    "start": "551750",
    "end": "554223"
  },
  {
    "text": "And as the amount of data\naccumulated for ADFS,",
    "start": "555410",
    "end": "559100"
  },
  {
    "text": "they stored their data in different silos,",
    "start": "559100",
    "end": "561000"
  },
  {
    "text": "making it difficult to do\nanalytics and enhancements.",
    "start": "561000",
    "end": "566000"
  },
  {
    "text": "To make it easier, ADFS will want",
    "start": "566260",
    "end": "568783"
  },
  {
    "text": "to move their data.",
    "start": "573640",
    "end": "574883"
  },
  {
    "text": "To make it easier,",
    "start": "576600",
    "end": "577690"
  },
  {
    "text": "ADFS will want to move their data",
    "start": "577690",
    "end": "579670"
  },
  {
    "text": "into a single repository,\nthus a data lake.",
    "start": "579670",
    "end": "583573"
  },
  {
    "start": "585000",
    "end": "585000"
  },
  {
    "text": "Well, why should we be\nlooking at a data lake?",
    "start": "585190",
    "end": "589360"
  },
  {
    "text": "ADFS will need to store\ntheir data securely",
    "start": "589360",
    "end": "592160"
  },
  {
    "text": "at any scale and at low cost,",
    "start": "592160",
    "end": "595100"
  },
  {
    "text": "using standard based data\nformats of their choice,",
    "start": "595100",
    "end": "598962"
  },
  {
    "text": "ADFS will need to find a way",
    "start": "600190",
    "end": "602520"
  },
  {
    "text": "to analyze their data\nin a variety of ways,",
    "start": "602520",
    "end": "606200"
  },
  {
    "text": "using a broad set of analytic engines,",
    "start": "606200",
    "end": "608610"
  },
  {
    "text": "ensuring their needs will be met",
    "start": "608610",
    "end": "610339"
  },
  {
    "text": "for their existing and\nfuture analytics use cases.",
    "start": "610340",
    "end": "614090"
  },
  {
    "text": "And it will also enable them",
    "start": "614090",
    "end": "616520"
  },
  {
    "text": "to move towards purpose-built\nDBs in the next module.",
    "start": "616520",
    "end": "620163"
  },
  {
    "text": "ADFS will also need to go beyond insights,",
    "start": "622540",
    "end": "625310"
  },
  {
    "text": "from operational reporting\nand historical data",
    "start": "625310",
    "end": "628200"
  },
  {
    "text": "to being able to perform machine learning",
    "start": "628200",
    "end": "630100"
  },
  {
    "text": "in the future in real-time analytics",
    "start": "630100",
    "end": "632449"
  },
  {
    "text": "to accurately predict future outcomes.",
    "start": "632450",
    "end": "634803"
  },
  {
    "text": "While we won't cover machine\nlearning integrations",
    "start": "637210",
    "end": "640630"
  },
  {
    "text": "in this module, enabling\nADFS to land their data",
    "start": "640630",
    "end": "645340"
  },
  {
    "text": "in a central data repository, such as S3,",
    "start": "645340",
    "end": "648450"
  },
  {
    "text": "unblocks data scientists within ADFS",
    "start": "648450",
    "end": "651950"
  },
  {
    "text": "to use high level ML services,",
    "start": "651950",
    "end": "655030"
  },
  {
    "text": "such as Comprehend for sentiment analysis",
    "start": "655030",
    "end": "657770"
  },
  {
    "text": "and Forecast to predict\ninventory more easily.",
    "start": "657770",
    "end": "661060"
  },
  {
    "text": "This also puts machine\nlearning and AI services",
    "start": "661060",
    "end": "665140"
  },
  {
    "text": "in the hands of developers,\nproduct and data scientists.",
    "start": "665140",
    "end": "670140"
  },
  {
    "text": "The data scientists could use SageMaker",
    "start": "671210",
    "end": "673220"
  },
  {
    "text": "for experimentation, development, training",
    "start": "673220",
    "end": "676089"
  },
  {
    "text": "and deploying of custom\npurpose-built ML models",
    "start": "676090",
    "end": "679150"
  },
  {
    "text": "that give ADFS an edge in their industry.",
    "start": "679150",
    "end": "682763"
  },
  {
    "text": "These all were constrained\nby having data silos",
    "start": "684600",
    "end": "688259"
  },
  {
    "text": "which made it difficult to\ncorrelate across those silos,",
    "start": "688260",
    "end": "691610"
  },
  {
    "text": "trace data lineage and curate data",
    "start": "691610",
    "end": "693839"
  },
  {
    "text": "for new and innovative products.",
    "start": "693840",
    "end": "696870"
  },
  {
    "text": "With using Glue as part of our pipeline,",
    "start": "696870",
    "end": "699350"
  },
  {
    "start": "697000",
    "end": "697000"
  },
  {
    "text": "we wanna target the three\ndatabases we mentioned earlier,",
    "start": "699350",
    "end": "703250"
  },
  {
    "text": "account, inventory and reporting.",
    "start": "703250",
    "end": "706690"
  },
  {
    "text": "The pipeline underneath Lake\nFormation which we will use",
    "start": "706690",
    "end": "710600"
  },
  {
    "text": "looks something similar to this.",
    "start": "710600",
    "end": "712560"
  },
  {
    "text": "We'll want to create a catalog,\nwhich is essentially tables",
    "start": "712560",
    "end": "717020"
  },
  {
    "text": "that are assigned to a database.",
    "start": "717020",
    "end": "718850"
  },
  {
    "text": "Account has tables, inventory,\nreporting, et cetera.",
    "start": "718850",
    "end": "721902"
  },
  {
    "text": "That catalog gets started\nin the Glue catalog",
    "start": "724150",
    "end": "727220"
  },
  {
    "text": "which are essential metadata repository.",
    "start": "727220",
    "end": "729423"
  },
  {
    "text": "Glue also includes an ETL engine",
    "start": "731510",
    "end": "733840"
  },
  {
    "text": "that'll automatically\ngenerate Python or Scala code",
    "start": "733840",
    "end": "737380"
  },
  {
    "text": "and can be used to ingest transform data.",
    "start": "737380",
    "end": "739533"
  },
  {
    "text": "Lake Formation will\nautomatically do this for us.",
    "start": "740430",
    "end": "743480"
  },
  {
    "text": "We will then ingest using standard JDBC",
    "start": "743480",
    "end": "747699"
  },
  {
    "text": "or ODBC data sources today.",
    "start": "747700",
    "end": "750913"
  },
  {
    "text": "The ODBC driver we'll be using",
    "start": "752300",
    "end": "754110"
  },
  {
    "text": "is to connect to SQL\nServer in our data hub.",
    "start": "754110",
    "end": "756383"
  },
  {
    "text": "Glue Crawlers automatically\nupdate the metadata store",
    "start": "757720",
    "end": "761279"
  },
  {
    "text": "as new data is ingested.",
    "start": "761280",
    "end": "763053"
  },
  {
    "text": "The data in the consumption layer is used",
    "start": "764950",
    "end": "767070"
  },
  {
    "text": "by analytics teams for\nserverless analytics,",
    "start": "767070",
    "end": "770080"
  },
  {
    "text": "such as Athena or Redshift,\nour data warehouse,",
    "start": "770080",
    "end": "772920"
  },
  {
    "text": "which we may land in in the future.",
    "start": "772920",
    "end": "774670"
  },
  {
    "text": "It will also be used to consume data",
    "start": "775560",
    "end": "778290"
  },
  {
    "text": "into our purpose-built\ndatabases in the next module.",
    "start": "778290",
    "end": "781883"
  },
  {
    "text": "Landing the data in S3 then begins",
    "start": "783620",
    "end": "786080"
  },
  {
    "text": "to democratize the data for ADFS.",
    "start": "786080",
    "end": "788223"
  },
  {
    "text": "This enables them and\ntheir engineering teams",
    "start": "789100",
    "end": "792690"
  },
  {
    "text": "to come up with new innovative products",
    "start": "793780",
    "end": "796240"
  },
  {
    "text": "across the entire organization's portfolio",
    "start": "797130",
    "end": "800460"
  },
  {
    "text": "versus the individual data\nsilos that were defined earlier.",
    "start": "800460",
    "end": "804143"
  },
  {
    "start": "806000",
    "end": "806000"
  },
  {
    "text": "Now going into what Lake Formation is",
    "start": "807750",
    "end": "811530"
  },
  {
    "text": "and what it will set up\nthat pipeline for us,",
    "start": "812730",
    "end": "815480"
  },
  {
    "text": "Lake Formation encompasses\nfive separate pieces,",
    "start": "815480",
    "end": "820480"
  },
  {
    "text": "Glue, which we talked about earlier,",
    "start": "820480",
    "end": "822589"
  },
  {
    "text": "which is our managed\nETL process, blueprints,",
    "start": "822590",
    "end": "826700"
  },
  {
    "text": "which point to a specific database type",
    "start": "826700",
    "end": "830940"
  },
  {
    "text": "and handle the extraction\nfor us, ML transforms,",
    "start": "830940",
    "end": "834360"
  },
  {
    "text": "which can use machine\nlearning to do deduplication,",
    "start": "834360",
    "end": "838293"
  },
  {
    "text": "the data catalog,",
    "start": "839500",
    "end": "840780"
  },
  {
    "text": "which is metadata about the tables, types",
    "start": "840780",
    "end": "844530"
  },
  {
    "text": "and locations of the data\nthat is living in S3,",
    "start": "844530",
    "end": "847733"
  },
  {
    "text": "as well as access controls around who",
    "start": "848850",
    "end": "852420"
  },
  {
    "text": "and what can access\nspecific pieces of data.",
    "start": "852420",
    "end": "855750"
  },
  {
    "text": "All of this is set up for\nus with Lake Formation.",
    "start": "855750",
    "end": "858200"
  },
  {
    "start": "861000",
    "end": "861000"
  },
  {
    "text": "So the next question",
    "start": "861010",
    "end": "861843"
  },
  {
    "text": "is how do we load data in\nusing ADFS's SQL Server?",
    "start": "861843",
    "end": "865800"
  },
  {
    "text": "Right now, it's living on RDS.",
    "start": "865800",
    "end": "867910"
  },
  {
    "text": "RDS can be a target for Lake Formation.",
    "start": "867910",
    "end": "871480"
  },
  {
    "text": "There are two ways we can\ndo this with the blueprints.",
    "start": "871480",
    "end": "873959"
  },
  {
    "text": "We can decide we want to\ndo a one-time migration",
    "start": "873960",
    "end": "877710"
  },
  {
    "text": "or incremental using change data capture.",
    "start": "877710",
    "end": "880053"
  },
  {
    "text": "Considering the different tables",
    "start": "881290",
    "end": "882970"
  },
  {
    "text": "that we'll be using, account,\ninventory and reporting,",
    "start": "882970",
    "end": "887610"
  },
  {
    "text": "we'll want to use a\ncombination of the two,",
    "start": "887610",
    "end": "891420"
  },
  {
    "text": "depending on the use case.",
    "start": "891420",
    "end": "893019"
  },
  {
    "text": "For instance, with accounts,",
    "start": "893020",
    "end": "894180"
  },
  {
    "text": "we could do one-shot, with inventory,",
    "start": "894180",
    "end": "897460"
  },
  {
    "text": "it may be incremental as\nit's changing over time,",
    "start": "897460",
    "end": "901050"
  },
  {
    "text": "and the reporting also could go back",
    "start": "901050",
    "end": "902640"
  },
  {
    "text": "to one-shot or one-shot\nat a periodic basis.",
    "start": "902640",
    "end": "906060"
  },
  {
    "text": "There's other information we can bring in,",
    "start": "906060",
    "end": "909050"
  },
  {
    "text": "such as Kinesis Data Firehose",
    "start": "909050",
    "end": "911660"
  },
  {
    "text": "for streaming data, CloudTrail,",
    "start": "911660",
    "end": "914019"
  },
  {
    "text": "Elastic Load Balancing,\nlogs, or CloudFront.",
    "start": "914020",
    "end": "916400"
  },
  {
    "text": "While we won't cover those\nimmediately in this module,",
    "start": "916400",
    "end": "919360"
  },
  {
    "text": "it's important to point\nout that streaming data",
    "start": "919360",
    "end": "922339"
  },
  {
    "text": "or data that's changing\nrapidly over a series of time",
    "start": "922340",
    "end": "926530"
  },
  {
    "text": "is also a target for a data lake",
    "start": "926530",
    "end": "928580"
  },
  {
    "text": "and could be handled accordingly.",
    "start": "928580",
    "end": "930930"
  },
  {
    "text": "A good use case for this",
    "start": "930930",
    "end": "932149"
  },
  {
    "text": "would be as data changes in SQL Server,",
    "start": "932150",
    "end": "935163"
  },
  {
    "text": "we push those changes into a stream",
    "start": "936010",
    "end": "939960"
  },
  {
    "text": "so they could be processed\nin near-real time",
    "start": "939960",
    "end": "942130"
  },
  {
    "text": "by another data store\nand or landing in S3.",
    "start": "942130",
    "end": "946203"
  },
  {
    "text": "Think about it this way,",
    "start": "947210",
    "end": "949250"
  },
  {
    "text": "if we have an account that is changing",
    "start": "949250",
    "end": "952320"
  },
  {
    "text": "in our original data store in SQL Server",
    "start": "952320",
    "end": "955080"
  },
  {
    "text": "and we want to process that\nrecord in near-real time",
    "start": "956410",
    "end": "960120"
  },
  {
    "text": "into our now purpose-built database,",
    "start": "960120",
    "end": "962820"
  },
  {
    "text": "that is where Kinesis\nwould come into play.",
    "start": "962820",
    "end": "965820"
  },
  {
    "text": "We would take the change,\npush this into Kinesis,",
    "start": "965820",
    "end": "968650"
  },
  {
    "text": "use a tool such as Glue or\nHadoop, and process that",
    "start": "968650",
    "end": "972390"
  },
  {
    "text": "and store it in our\npurpose-built database.",
    "start": "972390",
    "end": "974870"
  },
  {
    "text": "We'll go into that in our next module",
    "start": "974870",
    "end": "976810"
  },
  {
    "text": "around purpose-built databases\nand getting ADFS into there.",
    "start": "976810",
    "end": "980453"
  },
  {
    "start": "982000",
    "end": "982000"
  },
  {
    "text": "So a little bit of a\ndefinition on blueprints,",
    "start": "983470",
    "end": "987199"
  },
  {
    "text": "blueprints heavily leverage\nfunctionality in Glue.",
    "start": "987200",
    "end": "991110"
  },
  {
    "text": "We use Glue Crawlers and\nconnections to connect",
    "start": "991110",
    "end": "993550"
  },
  {
    "text": "and discover the raw data\nthat needs to be ingested.",
    "start": "993550",
    "end": "996149"
  },
  {
    "text": "Then Glue generates code for us",
    "start": "997800",
    "end": "1000890"
  },
  {
    "text": "and Glue jobs for us to ingest\nthe data into the data lake.",
    "start": "1000890",
    "end": "1005740"
  },
  {
    "text": "It will handle the transform\nand load into S3 for us.",
    "start": "1005740",
    "end": "1009423"
  },
  {
    "text": "Then we leverage the data\ncatalog to organize the metadata.",
    "start": "1010500",
    "end": "1014233"
  },
  {
    "text": "Then the workflows construct",
    "start": "1016120",
    "end": "1018380"
  },
  {
    "text": "to stitch together Crawlers and jobs,",
    "start": "1018380",
    "end": "1020370"
  },
  {
    "text": "allowing for monitoring\nof individual workflows.",
    "start": "1020370",
    "end": "1023070"
  },
  {
    "text": "These individual\nworkflows will be targeted",
    "start": "1023070",
    "end": "1026060"
  },
  {
    "text": "at a specific database",
    "start": "1026060",
    "end": "1027699"
  },
  {
    "text": "so that we can control them independently.",
    "start": "1027700",
    "end": "1030319"
  },
  {
    "text": "These are all natural extensions\nof Glue's capabilities.",
    "start": "1030320",
    "end": "1034022"
  },
  {
    "text": "Now let's go over and see how\nwe're using Lake Formation",
    "start": "1035250",
    "end": "1040250"
  },
  {
    "text": "to enable ADFS to move the data",
    "start": "1041150",
    "end": "1044150"
  },
  {
    "text": "from those different\ndatabases into a data lake.",
    "start": "1044150",
    "end": "1048023"
  },
  {
    "text": "So we're in here in the AWS console",
    "start": "1050670",
    "end": "1053110"
  },
  {
    "text": "and we're looking at RDS,\nRelational Data Service,",
    "start": "1054190",
    "end": "1058129"
  },
  {
    "text": "and we have a SQL Server set up",
    "start": "1058130",
    "end": "1060540"
  },
  {
    "text": "that is running standard edition,",
    "start": "1061690",
    "end": "1063403"
  },
  {
    "text": "that is running a replicate\nof the data service",
    "start": "1064750",
    "end": "1068760"
  },
  {
    "text": "that we about earlier.",
    "start": "1068760",
    "end": "1069983"
  },
  {
    "text": "So you have one database\nhere, as you can see,",
    "start": "1070960",
    "end": "1073159"
  },
  {
    "text": "it is SQL Server Standard edition.",
    "start": "1073160",
    "end": "1075333"
  },
  {
    "text": "I drill into that, and\nthere's one active session,",
    "start": "1077100",
    "end": "1079720"
  },
  {
    "text": "and we'll go into what\nthat active session is",
    "start": "1079720",
    "end": "1081659"
  },
  {
    "text": "in a little bit.",
    "start": "1081660",
    "end": "1082573"
  },
  {
    "text": "But everything here is\nstandard configuration.",
    "start": "1083720",
    "end": "1086173"
  },
  {
    "text": "Let's hop over to Lake Formation",
    "start": "1088040",
    "end": "1089470"
  },
  {
    "text": "and see what information Lake Formation",
    "start": "1089470",
    "end": "1092440"
  },
  {
    "text": "was able to pull out once it was set up.",
    "start": "1092440",
    "end": "1094490"
  },
  {
    "text": "Now if we go into the ADFS database here,",
    "start": "1094490",
    "end": "1098132"
  },
  {
    "text": "you'll see it's pointed to\na very specific S3 location",
    "start": "1101160",
    "end": "1104930"
  },
  {
    "text": "where the data's being saved.",
    "start": "1104930",
    "end": "1107210"
  },
  {
    "text": "It's actually being pulled out",
    "start": "1107210",
    "end": "1108480"
  },
  {
    "text": "of our relational data service.",
    "start": "1108480",
    "end": "1110622"
  },
  {
    "text": "And we'll go into that in a little bit.",
    "start": "1111540",
    "end": "1113020"
  },
  {
    "text": "Now I'm gonna go to View Tables.",
    "start": "1113020",
    "end": "1114620"
  },
  {
    "text": "And what you're gonna see",
    "start": "1116320",
    "end": "1117710"
  },
  {
    "text": "is all these tables that were able",
    "start": "1118940",
    "end": "1120769"
  },
  {
    "text": "to be pulled out of the database.",
    "start": "1120770",
    "end": "1122463"
  },
  {
    "text": "The question is how was that done?",
    "start": "1124510",
    "end": "1126480"
  },
  {
    "text": "That was done with this\nthing called Blueprints,",
    "start": "1126480",
    "end": "1128880"
  },
  {
    "text": "which creates a workflow.",
    "start": "1129770",
    "end": "1131350"
  },
  {
    "text": "If we look at blueprints here,",
    "start": "1131350",
    "end": "1133593"
  },
  {
    "text": "this blueprint has run multiple times",
    "start": "1135080",
    "end": "1138640"
  },
  {
    "text": "against our RDS database.",
    "start": "1138640",
    "end": "1142763"
  },
  {
    "text": "That blueprint is exporting the data",
    "start": "1145380",
    "end": "1148450"
  },
  {
    "text": "from SQL Server into our data lake.",
    "start": "1148450",
    "end": "1152190"
  },
  {
    "text": "It can be done as a one-time",
    "start": "1152190",
    "end": "1154600"
  },
  {
    "text": "or it can be done as a\ncontinuous replication.",
    "start": "1154600",
    "end": "1157823"
  },
  {
    "text": "Now that the data is\nliving in Lake Formation,",
    "start": "1159430",
    "end": "1164430"
  },
  {
    "text": "how would we query it?",
    "start": "1164540",
    "end": "1165610"
  },
  {
    "text": "How would we use it in other systems?",
    "start": "1165610",
    "end": "1167653"
  },
  {
    "text": "That's where Athena comes in.",
    "start": "1168740",
    "end": "1170630"
  },
  {
    "text": "So we have the ADFS database",
    "start": "1170630",
    "end": "1172340"
  },
  {
    "text": "that we had previously in Lake Formation,",
    "start": "1172340",
    "end": "1175130"
  },
  {
    "text": "we have all of our tables.",
    "start": "1175130",
    "end": "1178530"
  },
  {
    "text": "So I go in here, I'm going to look",
    "start": "1178530",
    "end": "1182570"
  },
  {
    "text": "at a specific salesperson.",
    "start": "1182570",
    "end": "1184000"
  },
  {
    "text": "I'm gonna use this V, this is a view",
    "start": "1184000",
    "end": "1185960"
  },
  {
    "text": "that is able to pull that information,",
    "start": "1185960",
    "end": "1188100"
  },
  {
    "text": "going ahead and preview that table.",
    "start": "1188100",
    "end": "1189882"
  },
  {
    "text": "And it's now queried that data.",
    "start": "1191280",
    "end": "1193420"
  },
  {
    "text": "That data is protected",
    "start": "1193420",
    "end": "1196790"
  },
  {
    "text": "by Lake Formation, living in Amazon S3",
    "start": "1196790",
    "end": "1201060"
  },
  {
    "text": "and put into Parquet format,\nParquet format for performance.",
    "start": "1203010",
    "end": "1206853"
  },
  {
    "text": "So as you can see, all\nthe data that was in RDS",
    "start": "1207800",
    "end": "1212680"
  },
  {
    "text": "is now living in Lake Formation",
    "start": "1212680",
    "end": "1215490"
  },
  {
    "text": "and being replicated up as things change.",
    "start": "1215490",
    "end": "1218223"
  },
  {
    "text": "Now, being replicated as things change",
    "start": "1219820",
    "end": "1223169"
  },
  {
    "text": "from a continuous replication mechanism",
    "start": "1223170",
    "end": "1226350"
  },
  {
    "text": "is done on a timed\nfashion in Lake Formation.",
    "start": "1227790",
    "end": "1231120"
  },
  {
    "text": "In Lake Formation,",
    "start": "1231120",
    "end": "1232320"
  },
  {
    "text": "there is no concept of\ncontinuous streaming.",
    "start": "1232320",
    "end": "1235149"
  },
  {
    "text": "We would want to capture\nthose continuous changes out",
    "start": "1235150",
    "end": "1238530"
  },
  {
    "text": "of the database and process\nthem in near-real time.",
    "start": "1238530",
    "end": "1241283"
  },
  {
    "text": "That is where Database\nMigration Service comes in.",
    "start": "1242970",
    "end": "1246403"
  },
  {
    "text": "Database Migration Service can listen",
    "start": "1248090",
    "end": "1250480"
  },
  {
    "text": "for changes inside our\nrelational data store,",
    "start": "1250480",
    "end": "1254890"
  },
  {
    "text": "take the change and replicate it up,",
    "start": "1254890",
    "end": "1257710"
  },
  {
    "text": "either into another data system",
    "start": "1257710",
    "end": "1260929"
  },
  {
    "text": "or into a streaming technology.",
    "start": "1260930",
    "end": "1262853"
  },
  {
    "text": "In this particular case,",
    "start": "1264005",
    "end": "1264950"
  },
  {
    "text": "we have a ongoing replication\npointed at a target,",
    "start": "1264950",
    "end": "1269769"
  },
  {
    "text": "in that target, here is database\none, which is SQL Server,",
    "start": "1269770",
    "end": "1274173"
  },
  {
    "text": "and the target is a Kinesis stream.",
    "start": "1278430",
    "end": "1280930"
  },
  {
    "text": "Now the target could be another database,",
    "start": "1280930",
    "end": "1283350"
  },
  {
    "text": "it could be a data warehouse.",
    "start": "1283350",
    "end": "1286309"
  },
  {
    "text": "We're streaming it into Kinesis",
    "start": "1286310",
    "end": "1288210"
  },
  {
    "text": "because we're gonna use that later",
    "start": "1288210",
    "end": "1290090"
  },
  {
    "text": "to do near-real time transformation",
    "start": "1290090",
    "end": "1293159"
  },
  {
    "text": "into a purpose-built DB\nbased on the use cases",
    "start": "1293160",
    "end": "1297550"
  },
  {
    "text": "of how the data will need to be used",
    "start": "1297550",
    "end": "1299620"
  },
  {
    "text": "for the microservice\nthat we're pulling off.",
    "start": "1299620",
    "end": "1302113"
  },
  {
    "text": "Let's go back into the source database",
    "start": "1305630",
    "end": "1308550"
  },
  {
    "text": "so we can show you how\nthe configuration worked.",
    "start": "1308550",
    "end": "1311000"
  },
  {
    "text": "We have a username, we have a\ndatabase that we're targeting.",
    "start": "1311000",
    "end": "1314513"
  },
  {
    "text": "We then have a server name",
    "start": "1315350",
    "end": "1317230"
  },
  {
    "text": "and some other connection information.",
    "start": "1318750",
    "end": "1320650"
  },
  {
    "text": "Now let's go over to the migration task",
    "start": "1326680",
    "end": "1328430"
  },
  {
    "text": "that's handling the migration\nitself for our target.",
    "start": "1328430",
    "end": "1331053"
  },
  {
    "text": "So we have one here called sales public",
    "start": "1332190",
    "end": "1334080"
  },
  {
    "text": "that's an ongoing replication.",
    "start": "1334080",
    "end": "1336409"
  },
  {
    "text": "Let's drill to that a little deeper.",
    "start": "1336410",
    "end": "1338210"
  },
  {
    "text": "If we look at mapping rules,\nwe have a selection rule.",
    "start": "1341409",
    "end": "1344990"
  },
  {
    "text": "The selection rule says\nonly use schema called Sales",
    "start": "1344990",
    "end": "1347910"
  },
  {
    "text": "and only a table name called\nSalesPersonQuotaHistory.",
    "start": "1347910",
    "end": "1352650"
  },
  {
    "text": "This means that we can",
    "start": "1352650",
    "end": "1353960"
  },
  {
    "text": "have individual migration\ntasks targeting a single",
    "start": "1353960",
    "end": "1358960"
  },
  {
    "text": "or multiple pieces to replicate",
    "start": "1359540",
    "end": "1363300"
  },
  {
    "text": "on a ongoing or one-time basis.",
    "start": "1363300",
    "end": "1367100"
  },
  {
    "text": "What this will enable us\nto do is capture changes",
    "start": "1367100",
    "end": "1370590"
  },
  {
    "text": "for this table or multiple tables",
    "start": "1370590",
    "end": "1373380"
  },
  {
    "text": "and process them to our data lake,",
    "start": "1373380",
    "end": "1376010"
  },
  {
    "text": "to another database or to a stream",
    "start": "1376010",
    "end": "1378300"
  },
  {
    "text": "to be handled in a multitude of use cases.",
    "start": "1378300",
    "end": "1381393"
  },
  {
    "text": "Now let's hop over to Athena",
    "start": "1382770",
    "end": "1385400"
  },
  {
    "text": "and show you what else you can do.",
    "start": "1385400",
    "end": "1387750"
  },
  {
    "text": "Now we have a salesperson\nI could cross-join",
    "start": "1387750",
    "end": "1390840"
  },
  {
    "text": "to any other table or database",
    "start": "1390840",
    "end": "1393669"
  },
  {
    "text": "that's living in Lake Formation.",
    "start": "1393670",
    "end": "1396523"
  },
  {
    "text": "For instance, we could query",
    "start": "1398300",
    "end": "1399580"
  },
  {
    "text": "for salesperson and join by vendor",
    "start": "1399580",
    "end": "1403080"
  },
  {
    "text": "or by person, the root object,",
    "start": "1404184",
    "end": "1407970"
  },
  {
    "text": "or by human resource information",
    "start": "1407970",
    "end": "1410049"
  },
  {
    "text": "if we wanna do some salary information.",
    "start": "1410050",
    "end": "1412750"
  },
  {
    "text": "Now that the data is living in a data lake",
    "start": "1412750",
    "end": "1416960"
  },
  {
    "text": "and being replicated up,\nyou now have the ability",
    "start": "1416960",
    "end": "1420210"
  },
  {
    "text": "to apply any technique you can think of,",
    "start": "1420210",
    "end": "1423770"
  },
  {
    "text": "be it machine learning,\ndatabase transformation,",
    "start": "1423770",
    "end": "1427470"
  },
  {
    "text": "database modernization, and\nadvanced use cases beyond that.",
    "start": "1427470",
    "end": "1432223"
  },
  {
    "text": "Now let's recap what we've observed.",
    "start": "1434680",
    "end": "1437260"
  },
  {
    "start": "1436000",
    "end": "1436000"
  },
  {
    "text": "Acme has now moved their data",
    "start": "1437260",
    "end": "1439240"
  },
  {
    "text": "from SQL Server to a data lake",
    "start": "1439240",
    "end": "1441670"
  },
  {
    "text": "which has enabled them",
    "start": "1441670",
    "end": "1443330"
  },
  {
    "text": "to query across different data sources",
    "start": "1443330",
    "end": "1446440"
  },
  {
    "text": "and enable a database\ntransformation effort.",
    "start": "1446440",
    "end": "1449252"
  },
  {
    "text": "Acme is also replicating\ntheir changes from SQL Server",
    "start": "1450410",
    "end": "1454210"
  },
  {
    "text": "to a stream for real time processing,",
    "start": "1454210",
    "end": "1457770"
  },
  {
    "text": "this allowing for\nnear-real time replication",
    "start": "1457770",
    "end": "1460260"
  },
  {
    "text": "and transformation into a\npurpose-built data store.",
    "start": "1460260",
    "end": "1463653"
  },
  {
    "text": "Data is now being queried without impact",
    "start": "1465100",
    "end": "1467870"
  },
  {
    "text": "on the source database",
    "start": "1467870",
    "end": "1469550"
  },
  {
    "text": "since the data is being queried in S3,",
    "start": "1469550",
    "end": "1472093"
  },
  {
    "text": "not the source database.",
    "start": "1473010",
    "end": "1475003"
  },
  {
    "text": "This has enabled database\ntransformation efforts",
    "start": "1476150",
    "end": "1478520"
  },
  {
    "text": "and enabled machine\nlearning that previously",
    "start": "1478520",
    "end": "1482060"
  },
  {
    "text": "was unable to be done.",
    "start": "1482060",
    "end": "1483463"
  },
  {
    "text": "Thank you, and continue to part five",
    "start": "1484780",
    "end": "1487490"
  },
  {
    "text": "on purpose-built databases.",
    "start": "1487490",
    "end": "1489193"
  }
]
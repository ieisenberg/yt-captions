[
  {
    "start": "0",
    "end": "44000"
  },
  {
    "text": "so my name is Ryan Deiss I'm a Technical Program product manager for Amazon",
    "start": "1280",
    "end": "6450"
  },
  {
    "text": "Kinesis today we're gonna be talking about building a streaming data platform on AWS we have one of our longtime",
    "start": "6450",
    "end": "12780"
  },
  {
    "text": "customers rob with us who's the one of the cofounders of beeswax and I'm really",
    "start": "12780",
    "end": "18539"
  },
  {
    "text": "excited about this presentations because they've they helped us build the platform so the feedback that they",
    "start": "18539",
    "end": "25170"
  },
  {
    "text": "provided directly impacted the features that we worked on and they really evolved with the service so Amazon",
    "start": "25170",
    "end": "31859"
  },
  {
    "text": "Canisius streams has been out for three years and will go into the services that Amazon provides but they were their",
    "start": "31859",
    "end": "37770"
  },
  {
    "text": "feedback definitely impacted how we built and what we built over the last couple years",
    "start": "37770",
    "end": "43670"
  },
  {
    "text": "so what are we gonna cover today we're gonna go over this is an expert level talk but we'll cover some introductory",
    "start": "43670",
    "end": "50550"
  },
  {
    "start": "44000",
    "end": "44000"
  },
  {
    "text": "material for those of you don't have context just so you can ramp up on what is Amazon Kinesis I'll mention some best",
    "start": "50550",
    "end": "57870"
  },
  {
    "text": "practices and key considerations for each part of a streaming data platform on AWS so streaming data ingest data",
    "start": "57870",
    "end": "65518"
  },
  {
    "text": "processing and sort of end-to-end best practices and then after that I'll transition to Rahm who's going to go",
    "start": "65519",
    "end": "71909"
  },
  {
    "text": "over what beeswax does as a business and how they use streaming data and real time data to differentiate themselves",
    "start": "71909",
    "end": "78450"
  },
  {
    "text": "from their competitors and how they built that service on AWS so before we",
    "start": "78450",
    "end": "84299"
  },
  {
    "text": "get started let's just by a show of hands who has used the streaming data product before it doesn't have to be",
    "start": "84299",
    "end": "90420"
  },
  {
    "text": "Amazon Kinesis who is currently using Amazon Kinesis great what I'd love to see is every year",
    "start": "90420",
    "end": "97409"
  },
  {
    "text": "we give presentations we see more and more hands so a lot of the practices best practices that we have are",
    "start": "97409",
    "end": "103079"
  },
  {
    "text": "generally applicable whether you're using Apache Kafka or Kinesis streams or even some queueing technologies so",
    "start": "103079",
    "end": "109229"
  },
  {
    "text": "you'll get something out of it whether or not you're a customer but if you've never used Amazon Kinesis this will be a good introduction into the types of",
    "start": "109229",
    "end": "115530"
  },
  {
    "text": "challenges customers have when they implement an end-to-end streaming data solution on AWS",
    "start": "115530",
    "end": "121729"
  },
  {
    "text": "so I like to start out just after premise what is streaming data because everyone has a different definition and",
    "start": "121729",
    "end": "127380"
  },
  {
    "start": "122000",
    "end": "122000"
  },
  {
    "text": "ours is intentionally vague this is unbounded sequence of events that is continuously capture them with low",
    "start": "127380",
    "end": "133680"
  },
  {
    "text": "latency I think the most important aspect of this is continuous so the data",
    "start": "133680",
    "end": "140100"
  },
  {
    "text": "is moving through a set of services to an eventual destination and that destination could be a database it could",
    "start": "140100",
    "end": "148290"
  },
  {
    "text": "be Amazon s3 could be storage it could be real-time alarms and event notifications through your operational",
    "start": "148290",
    "end": "155030"
  },
  {
    "text": "monitoring solutions the key aspect of is that data is continuously generated you're continuously capturing it and",
    "start": "155030",
    "end": "161880"
  },
  {
    "text": "continue continuously reacting to the data and delivering it in real-time to eventual destination",
    "start": "161880",
    "end": "167780"
  },
  {
    "text": "so Amazon Kinesis is made up of three services Amazon Kinesis streams",
    "start": "167780",
    "end": "172910"
  },
  {
    "start": "168000",
    "end": "168000"
  },
  {
    "text": "Amazon cases fire hose and Kinesis analytics and from left to right is sort of the order in which we release the",
    "start": "172910",
    "end": "178500"
  },
  {
    "text": "three services konista streams was the first product that we released is then every single every WS region except for",
    "start": "178500",
    "end": "183930"
  },
  {
    "text": "gov cloud which will be very soon and then it's sort of like a core infrastructure service it's what we'll",
    "start": "183930",
    "end": "190260"
  },
  {
    "text": "be talking about most today you write data to a Canisius stream and read data off of it needs to stream through a custom application that you build",
    "start": "190260",
    "end": "196410"
  },
  {
    "text": "yourself Kinesis firehose takes the number one use case for streaming data and that's",
    "start": "196410",
    "end": "203510"
  },
  {
    "text": "capture and aggregation and persist to a destination and makes it super easy to",
    "start": "203510",
    "end": "208530"
  },
  {
    "text": "use through UI some basic configurations we have some exciting features coming up in the next couple weeks for that",
    "start": "208530",
    "end": "214580"
  },
  {
    "text": "uses analytics we launched three months ago at the New York City summit and",
    "start": "214580",
    "end": "220050"
  },
  {
    "text": "allows you to write standard sequel over streaming data sources such as konista streams and firehose it look what it",
    "start": "220050",
    "end": "226320"
  },
  {
    "text": "does is it basically presents what almost looks like a relational table on top of your stream for you to query against and do things like real time",
    "start": "226320",
    "end": "233700"
  },
  {
    "text": "alarms and notifications time series analytics we're feeding a real-time dashboard",
    "start": "233700",
    "end": "239750"
  },
  {
    "text": "so amazon can use your streams so the primary value proposition for Kenya streams is that it's very easy to get",
    "start": "240920",
    "end": "247230"
  },
  {
    "text": "started you can choose the framework of your choice be it spark streaming Apache",
    "start": "247230",
    "end": "253110"
  },
  {
    "text": "storm or we ship our own libraries like the Kinesis client library but the the",
    "start": "253110",
    "end": "258570"
  },
  {
    "text": "big emphasis is does easy to use but it gives you that flexibility at a fairly low cost",
    "start": "258570",
    "end": "265790"
  },
  {
    "start": "265000",
    "end": "265000"
  },
  {
    "text": "Kinesis fire hose it is zero or very very little in administration the only",
    "start": "266099",
    "end": "272800"
  },
  {
    "text": "thing you really have to worry about is making sure that your IIM configuration is correct between your stream or your",
    "start": "272800",
    "end": "280150"
  },
  {
    "text": "fire hose delivery stream and your destination and then just writing data at any rate we scale the stream for you",
    "start": "280150",
    "end": "286360"
  },
  {
    "text": "there's no concept of harder to comprehend aspects like shards or",
    "start": "286360",
    "end": "292539"
  },
  {
    "text": "partitions and it just gets the data in as quick as a minute sometimes lower to the",
    "start": "292539",
    "end": "299680"
  },
  {
    "text": "destination of your choice it's very fire-and-forget the we're not going to talk about fire",
    "start": "299680",
    "end": "307030"
  },
  {
    "text": "hose too much today but the one thing I will say is a lot of customers use streams and fire hose for different use",
    "start": "307030",
    "end": "312340"
  },
  {
    "text": "cases or in conjunction so it's very common to take data written to a stream and also",
    "start": "312340",
    "end": "317979"
  },
  {
    "text": "write it to a fire hose or attach an application that's just forwarding it to a fire hose to get it to those destinations",
    "start": "317979",
    "end": "325139"
  },
  {
    "start": "324000",
    "end": "324000"
  },
  {
    "text": "so Kinesis analytics allows you to build real time applications using sequel you",
    "start": "325530",
    "end": "330610"
  },
  {
    "text": "basically define a source configuration and schema associated with it your",
    "start": "330610",
    "end": "336430"
  },
  {
    "text": "application code which is a set of sequel queries that you can run in parallel or serial on that streaming",
    "start": "336430",
    "end": "342550"
  },
  {
    "text": "data source and then a destination or a set of destinations of what you want to emit your metrics very common use cases",
    "start": "342550",
    "end": "349090"
  },
  {
    "text": "are I want to compute averages mins maxes over a one minute period and MIT the data to redshift or emit the data to",
    "start": "349090",
    "end": "355960"
  },
  {
    "text": "my sequel database another very common use case for it is doing message based",
    "start": "355960",
    "end": "361090"
  },
  {
    "text": "filtering so I'm looking for something using a very simple where clause and then emitting it to for a venting or",
    "start": "361090",
    "end": "367750"
  },
  {
    "text": "alarming but it also supports advanced use cases so we have some machine learning algorithms built into it one of",
    "start": "367750",
    "end": "372849"
  },
  {
    "text": "them is an anomaly detection algorithm that will detect anomalies on your stream and it's exposed to you through a simple standard sequel function",
    "start": "372849",
    "end": "380789"
  },
  {
    "text": "so the bulk of this presentation is going to be about Amazon Kinesis streams so I'm gonna go into some best practices",
    "start": "384180",
    "end": "391540"
  },
  {
    "text": "about working with the service and I'll provide some context of just high-level about what the api's are",
    "start": "391540",
    "end": "398460"
  },
  {
    "start": "403000",
    "end": "403000"
  },
  {
    "text": "so this is a typical very architecture diagram for Canisius streams you've got",
    "start": "404550",
    "end": "410080"
  },
  {
    "text": "a set of data producers writing to a stream and then a number of data",
    "start": "410080",
    "end": "415600"
  },
  {
    "text": "consumers reading off of the stream to power different use cases and if you go from the top to the bottom of those data",
    "start": "415600",
    "end": "421360"
  },
  {
    "text": "consumers you really see what we see typical customers do in their evolution of implementing streaming data use cases",
    "start": "421360",
    "end": "427570"
  },
  {
    "text": "they start with simple use cases like aggregation deduplication and persisting to Amazon s3 for either later analysis",
    "start": "427570",
    "end": "434740"
  },
  {
    "text": "in batch analytics tools or just archival and they progress to more",
    "start": "434740",
    "end": "440500"
  },
  {
    "text": "sophisticated the use cases like machine learning the key concept in Kinesis is a stream",
    "start": "440500",
    "end": "447580"
  },
  {
    "text": "you print you provision a stream by creating it specifying the name and a number of charts and that's sort of our",
    "start": "447580",
    "end": "454480"
  },
  {
    "text": "unit of scalability and it's also our unit of parallelism so if you need ten megabytes per second you create a stream",
    "start": "454480",
    "end": "461290"
  },
  {
    "text": "with ten charts if you need 100 megabytes per second you can scale your stream up through very simple api's by",
    "start": "461290",
    "end": "466420"
  },
  {
    "text": "just putting 100 and we'll scale you up to 100 charts another note on this slide is that the",
    "start": "466420",
    "end": "473350"
  },
  {
    "text": "variety of data producers so there are several different approaches that we'll talk about that in the presentation",
    "start": "473350",
    "end": "480520"
  },
  {
    "text": "about how people use streams so some customers will logically separate their",
    "start": "480520",
    "end": "485860"
  },
  {
    "text": "data into separate streams so they'll have their application logs going into one stream their clickstream data going",
    "start": "485860",
    "end": "492970"
  },
  {
    "text": "to another stream their operational metrics going to a third stream other customers use a single big ingestion",
    "start": "492970",
    "end": "499480"
  },
  {
    "text": "pipeline and there's pros and cons associated with that but the point is that there's a lot of",
    "start": "499480",
    "end": "505750"
  },
  {
    "text": "people use Kinesis streams and other streaming technologies to ingest a very large variety of data and that's really",
    "start": "505750",
    "end": "511390"
  },
  {
    "text": "one aspect of big data where streaming data is focused on this variety of data",
    "start": "511390",
    "end": "516810"
  },
  {
    "text": "so a Canisius stream I mentioned streams are made of chard and it's our unit of parallelism and throughput so each shard",
    "start": "517409",
    "end": "524710"
  },
  {
    "text": "gets you one megabyte per second in or 1000 records per second in so write two",
    "start": "524710",
    "end": "530230"
  },
  {
    "text": "megabytes per second out and five reads per second out so Anna Reed",
    "start": "530230",
    "end": "535480"
  },
  {
    "text": "will give you a batch or a bunch of records to read off of it you data is stored in the stream as a",
    "start": "535480",
    "end": "541570"
  },
  {
    "text": "temporal buffer so we it's configurable by default that's one day it's configurable up to seven days",
    "start": "541570",
    "end": "548850"
  },
  {
    "text": "and you scale a shard by splitting and merging shards but these are the two",
    "start": "548850",
    "end": "553930"
  },
  {
    "text": "api's we launched with we recently launched a new API where you just choose the number of shards to scale to and we",
    "start": "553930",
    "end": "560020"
  },
  {
    "text": "will scale you up to the number of shards and will maintain the lineage of the shards which for processing locality",
    "start": "560020",
    "end": "567430"
  },
  {
    "text": "which I'll get into in a couple slides is very important this is a very top feature request with customers because",
    "start": "567430",
    "end": "573880"
  },
  {
    "text": "they want in an easy way of just while the stream is live while you're writing to it while you're reading from it without any downtime can I please just",
    "start": "573880",
    "end": "580959"
  },
  {
    "text": "scale from n number of shards to M number of shards very quickly so we had",
    "start": "580959",
    "end": "586150"
  },
  {
    "text": "a library that used to that still does it still one of the most popular libraries on github is called Kinesis scaling utils but the customers use that",
    "start": "586150",
    "end": "593890"
  },
  {
    "text": "library to scale their streams up and down because it called these split and merge api is under the covers but recently two weeks ago we released an",
    "start": "593890",
    "end": "601420"
  },
  {
    "text": "api will you just go to the console enter the number of shards you want to scale to and it scales you very very",
    "start": "601420",
    "end": "607510"
  },
  {
    "text": "quickly typically in seconds sometimes in minutes depending on house side largest the stream is with very little",
    "start": "607510",
    "end": "613959"
  },
  {
    "text": "thought or process or thought or complexity on your end so how do you write data to a kanesha",
    "start": "613959",
    "end": "620770"
  },
  {
    "start": "618000",
    "end": "618000"
  },
  {
    "text": "stream so we have two AP is put record which is an individual record and put records",
    "start": "620770",
    "end": "626220"
  },
  {
    "text": "each record can be up to one megabyte in size all right the put records or the batch",
    "start": "626220",
    "end": "633400"
  },
  {
    "text": "put mechanism is typically used on data producers that are very large so I'd have a super large ec2 instances that's",
    "start": "633400",
    "end": "640959"
  },
  {
    "text": "producing one megabyte per second of logs so pretty extreme or another use",
    "start": "640959",
    "end": "647740"
  },
  {
    "text": "case is that a lot customers and Rahm will go into this because they typically implement this use case they have a",
    "start": "647740",
    "end": "653339"
  },
  {
    "text": "buffering fleet or fleet that's sole job is to basically get the data and then write date it to the Kenichi stream in",
    "start": "653339",
    "end": "659790"
  },
  {
    "text": "that case using put records gives you a higher throughput API when you write data you specify a blob",
    "start": "659790",
    "end": "666420"
  },
  {
    "text": "of data the stream name and a partition key the partition key determines which",
    "start": "666420",
    "end": "672120"
  },
  {
    "text": "shard the data record will be stored in we take that record we put it through a very simple md5 hash and then it just",
    "start": "672120",
    "end": "679920"
  },
  {
    "text": "ends up on this in that chart choosing a partition key is very important most of",
    "start": "679920",
    "end": "686580"
  },
  {
    "text": "our customers choose a random number all right just so that the traffic is evenly",
    "start": "686580",
    "end": "692070"
  },
  {
    "text": "distributed across all shards in the stream however there are customers that need processing locality so meaning that",
    "start": "692070",
    "end": "697950"
  },
  {
    "text": "they need all records associated with particular logical identifiers are sent to the same thread that's processing it",
    "start": "697950",
    "end": "704370"
  },
  {
    "text": "right this is for streaming MapReduce use cases if you're trying to aggregate events on a specific safety using an ec2",
    "start": "704370",
    "end": "711540"
  },
  {
    "text": "instance ID ran a great events on that specific ec2 instance you need to use the logical ID the key is though is that",
    "start": "711540",
    "end": "717720"
  },
  {
    "text": "you want a very high cardinality between number of keys and number of charts so",
    "start": "717720",
    "end": "722820"
  },
  {
    "text": "one hundred to one one thousand two one ten thousand to one so very very high cardinality because this",
    "start": "722820",
    "end": "728810"
  },
  {
    "text": "makes it more likely that traffic is evenly distributed through the through",
    "start": "728810",
    "end": "735870"
  },
  {
    "text": "your stream an example of a bad partition key would be I'm a I'm a service I have ten customers",
    "start": "735870",
    "end": "742350"
  },
  {
    "text": "one customer is 50 X larger than the other nine so and I'm putting all that",
    "start": "742350",
    "end": "747660"
  },
  {
    "text": "throughput to a single shard that's an example of a bad key if there's a low cardinality between the keys and shards",
    "start": "747660",
    "end": "754440"
  },
  {
    "text": "as well as one of the keys is a lot more throughput than the other keys for options of interacting with the",
    "start": "754440",
    "end": "761790"
  },
  {
    "text": "api's very few people actually interact directly with the api's it is done but a lot of people use one of our agents",
    "start": "761790",
    "end": "768470"
  },
  {
    "text": "we have the Kinesis producer library was just meant for very high throughput producers like those big ec2 instances I",
    "start": "768470",
    "end": "775680"
  },
  {
    "text": "was mentioning we have the Kinesis agent which just tails the log file and writes data to the Kinesis stream or fire hose",
    "start": "775680",
    "end": "781339"
  },
  {
    "text": "we also have open-source project with fluency loom and a lot of other tools",
    "start": "781339",
    "end": "786480"
  },
  {
    "text": "choose the solution that meets your use case that your developers are most comfortable with because as I mentioned",
    "start": "786480",
    "end": "792430"
  },
  {
    "text": "those data producers there's a lot of variety of them we have a lot of options for you because of that",
    "start": "792430",
    "end": "798690"
  },
  {
    "start": "798000",
    "end": "798000"
  },
  {
    "text": "so key considerations with data producers so almost all data producers are",
    "start": "798690",
    "end": "805840"
  },
  {
    "text": "stateless and they're typically not very reliable like it can go down for any reason and an example is an IOT sensor",
    "start": "805840",
    "end": "813430"
  },
  {
    "text": "or a mobile device or a web browser so you need them to get data off of those",
    "start": "813430",
    "end": "818470"
  },
  {
    "text": "machines very very quickly and very very efficiently most cost the audition is you get some",
    "start": "818470",
    "end": "825370"
  },
  {
    "text": "benefit and costs as well as some benefit and efficiency by buffering a small amount of time so for example",
    "start": "825370",
    "end": "830620"
  },
  {
    "text": "instead of writing and every single event to the stream writing waiting a hundred milliseconds or 50 milliseconds",
    "start": "830620",
    "end": "837460"
  },
  {
    "text": "or 10 milliseconds to buffer records for a very small period of time before you write using that put records API where a",
    "start": "837460",
    "end": "843730"
  },
  {
    "text": "batch put",
    "start": "843730",
    "end": "846300"
  },
  {
    "start": "850000",
    "end": "850000"
  },
  {
    "text": "so there's a writing data the stream there's also reading data to the stream the mechanism to read data from the",
    "start": "851180",
    "end": "857180"
  },
  {
    "text": "stream is basically call an API to define where you want to read and this is called get shard iterator and then",
    "start": "857180",
    "end": "863660"
  },
  {
    "text": "start iterating using get records and continuously reading data from the stream you can call get charter trader",
    "start": "863660",
    "end": "869990"
  },
  {
    "text": "from the oldest data in the stream from the latest data in the stream or we have time indexes as you can say I want to",
    "start": "869990",
    "end": "875450"
  },
  {
    "text": "start reading from an hour ago two hours ago 99% of use cases are reading from the",
    "start": "875450",
    "end": "880940"
  },
  {
    "text": "tip or reading from the latest data in the stream there are and then most customers have some replay scenario",
    "start": "880940",
    "end": "887420"
  },
  {
    "text": "where they want to go back a couple hours for a particular set of data may be processing failed or their processing",
    "start": "887420",
    "end": "893510"
  },
  {
    "text": "logic did not work as expected than you need to reprocess data",
    "start": "893510",
    "end": "898690"
  },
  {
    "text": "a key point on this slide is I've mentioned processing locality a couple times so increasing number of shards",
    "start": "903520",
    "end": "909920"
  },
  {
    "text": "will both increase throughput as well as make your processing scale more because you're increasing parallelism but you",
    "start": "909920",
    "end": "915440"
  },
  {
    "text": "lose processing locality the more shards that you the more shards that you add so",
    "start": "915440",
    "end": "920750"
  },
  {
    "text": "the example that I gave earlier about an instance idea ID if you have if you need",
    "start": "920750",
    "end": "926720"
  },
  {
    "text": "to correlate across multiple partition keys you lose that as you as you scale up",
    "start": "926720",
    "end": "931900"
  },
  {
    "text": "again there's a lot of options to read data off of the stream but almost all of",
    "start": "931900",
    "end": "938390"
  },
  {
    "text": "them use the Kinesis client library in some way there another which is the number one thing to read data off of a konista stream and it's both our low",
    "start": "938390",
    "end": "944990"
  },
  {
    "text": "level and high level API for consuming records off the stream it handles things like leased management the load",
    "start": "944990",
    "end": "952460"
  },
  {
    "text": "balancing and allows you to focus on just the record",
    "start": "952460",
    "end": "957980"
  },
  {
    "text": "processing logic so there's t two key components to it there's the worker the workers one worker per one g j VN and",
    "start": "957980",
    "end": "965050"
  },
  {
    "text": "then one record processor for one shark it also provides a lot of monitoring for",
    "start": "965050",
    "end": "973730"
  },
  {
    "text": "you and this is key to diagnosing issues we find that a lot of people don't look at this monitoring until they run into",
    "start": "973730",
    "end": "979220"
  },
  {
    "text": "an operational issue but when they do they're happy that it's there the most important metric that the emits is a per",
    "start": "979220",
    "end": "986540"
  },
  {
    "text": "application per shard Millie's behind latest metric it just",
    "start": "986540",
    "end": "993080"
  },
  {
    "text": "means how far behind the stream I am am i keeping up with every partition that I'm reading from the stream so when we",
    "start": "993080",
    "end": "999080"
  },
  {
    "text": "talk to customers about what to do from an operational context the most important thing is set an alarm on that metric you can set it up the stream",
    "start": "999080",
    "end": "1005950"
  },
  {
    "text": "level you can set it at the shard level but it basically tells you whether my stream is healthy whether my consuming",
    "start": "1005950",
    "end": "1011260"
  },
  {
    "text": "applet is healthy or not whether I'm keeping up with data in the stream or they're reading the latest data",
    "start": "1011260",
    "end": "1016650"
  },
  {
    "text": "often we find a lot of customers don't procced don't like still go to the next night don't",
    "start": "1016650",
    "end": "1024040"
  },
  {
    "start": "1023000",
    "end": "1023000"
  },
  {
    "text": "test scale before they go into production I don't know why this is but like it happens very often where their",
    "start": "1024040",
    "end": "1029890"
  },
  {
    "text": "record processing logic doesn't scale linearly with the amount of throughput and they it's a very easy test so you just need to test your record processing",
    "start": "1029890",
    "end": "1035949"
  },
  {
    "text": "logic scales with up to one megabyte per second it can be done locally on a developer's desktop do it before you go",
    "start": "1035949",
    "end": "1041829"
  },
  {
    "text": "into production all right it is extremely easy test to do and the reason why I'm suggesting to do is because a",
    "start": "1041829",
    "end": "1048250"
  },
  {
    "text": "lot of customers they might be utilizing their shards at 10% or 20% when they",
    "start": "1048250",
    "end": "1053410"
  },
  {
    "text": "first go into production and as their throughput scales or they get a huge influx in traffic by some event coming",
    "start": "1053410",
    "end": "1058690"
  },
  {
    "text": "in and then all of a sudden they're utilizing their shard to 80% and they're processing isn't scaling linearly and",
    "start": "1058690",
    "end": "1064120"
  },
  {
    "text": "this is an easy test that could have implemented from the very beginning which would save them a lot of time",
    "start": "1064120",
    "end": "1070770"
  },
  {
    "text": "and the other thing I'll mention this site is replay so have a retry strategy there are several different strategies",
    "start": "1072810",
    "end": "1079090"
  },
  {
    "text": "to implement the most common one is since we offer a time index just if you",
    "start": "1079090",
    "end": "1085720"
  },
  {
    "text": "fail processing or if the downstream destination is down or something other errors happen with your stream have a",
    "start": "1085720",
    "end": "1091510"
  },
  {
    "text": "strategy to dynamically update your application to start reading from the specific point in time where this event",
    "start": "1091510",
    "end": "1097420"
  },
  {
    "text": "occurred which the KCl supports another strategy is to just bounce your application with the the old time their",
    "start": "1097420",
    "end": "1104890"
  },
  {
    "text": "time that you want to start reading or reprocessing another strategy is to use historical or batch based processing on",
    "start": "1104890",
    "end": "1111250"
  },
  {
    "text": "Amazon s3 the point is there's a lot of different options here just make sure that you think about this before you go",
    "start": "1111250",
    "end": "1116680"
  },
  {
    "text": "to production so this is my last slide and this is",
    "start": "1116680",
    "end": "1124730"
  },
  {
    "start": "1119000",
    "end": "1119000"
  },
  {
    "text": "before I pass it off to rob and there's just key considerations to talk about for the end and streaming data solution",
    "start": "1124730",
    "end": "1133960"
  },
  {
    "text": "most customers are successful by implementing the simplest use case possible in that first slide I presented",
    "start": "1133960",
    "end": "1141049"
  },
  {
    "text": "on Amazon Kinesis streams key concepts this was aggregation and D duping and then writing it to s3 so if you haven't",
    "start": "1141049",
    "end": "1147289"
  },
  {
    "text": "used the streaming technology before we recommend you start with the simple one first and you'll run that app forever",
    "start": "1147289",
    "end": "1153470"
  },
  {
    "text": "the number one app for running even if you as you progress the more sophisticated use cases is streaming",
    "start": "1153470",
    "end": "1159140"
  },
  {
    "text": "data archival because it allows that replay scenario if anything goes wrong and even if you move on to more",
    "start": "1159140",
    "end": "1164360"
  },
  {
    "text": "sophisticated most customers will always have that app running",
    "start": "1164360",
    "end": "1169690"
  },
  {
    "text": "being able to support the variety of data that comes through it's something",
    "start": "1170320",
    "end": "1175520"
  },
  {
    "text": "you need to think about as well there are two different strategies that we generally see one is to do so in sort of",
    "start": "1175520",
    "end": "1181610"
  },
  {
    "text": "any sort of central way where you have a schema registry a consumer app calls an API reads the schema down and then",
    "start": "1181610",
    "end": "1188659"
  },
  {
    "text": "process the record based on for that schema registry it's one approach that works if you want tight data management",
    "start": "1188659",
    "end": "1195799"
  },
  {
    "text": "across your organization however if you want to give flexibility to individual developers a lot of people will just do",
    "start": "1195799",
    "end": "1202700"
  },
  {
    "text": "so locally and force every single any consumer that they attach to a stream it's their responsibility to handle the",
    "start": "1202700",
    "end": "1207919"
  },
  {
    "text": "different data formats it allows you that flexibility but also introduces",
    "start": "1207919",
    "end": "1213169"
  },
  {
    "text": "some problems if say someone developing your mobile app pushes a schema change and your record",
    "start": "1213169",
    "end": "1219770"
  },
  {
    "text": "processing logic can't handle it so there's some cost to that flexibility",
    "start": "1219770",
    "end": "1224919"
  },
  {
    "text": "integration so determine there will be either internal or external customers",
    "start": "1226030",
    "end": "1232970"
  },
  {
    "text": "that are going to depend on this data arriving and dependent on it in a certain with certain SLA it could be",
    "start": "1232970",
    "end": "1239059"
  },
  {
    "text": "you're giving them once a day you're updating on my sequel database or it could be once a second you're updating",
    "start": "1239059",
    "end": "1245919"
  },
  {
    "text": "Amazon s3 with new data understand those guarantees and",
    "start": "1245919",
    "end": "1251059"
  },
  {
    "text": "understand where to apply back pressure if necessary so what do you do if that",
    "start": "1251059",
    "end": "1256909"
  },
  {
    "text": "destination is down what do you do if there's a product there's something wrong with your ended end streaming data pipeline make sure that you understand",
    "start": "1256909",
    "end": "1264289"
  },
  {
    "text": "the guarantees you're offering you both the internal and external customers and then the last point I mentioned this",
    "start": "1264289",
    "end": "1272330"
  },
  {
    "text": "a little bit previously but determine whether you want to use multiple consumers or one monolithic application",
    "start": "1272330",
    "end": "1279370"
  },
  {
    "text": "ROM will go into their choice of using one monolithic application and both have advantages and disadvantages if you have",
    "start": "1279370",
    "end": "1286669"
  },
  {
    "text": "a lot of changes to various use cases very frequently there's a disadvantage for using one monolithic application but",
    "start": "1286669",
    "end": "1294200"
  },
  {
    "text": "it allows you to implement all of your use cases at the cheapest possible cost because you have these processing",
    "start": "1294200",
    "end": "1300320"
  },
  {
    "text": "framework each of them are going to state take a certain amount of compute attaching additional instances means reading more from the stream and",
    "start": "1300320",
    "end": "1305929"
  },
  {
    "text": "processing it thank you guys very much I'm really",
    "start": "1305929",
    "end": "1311600"
  },
  {
    "text": "excited about the next part of the presentation with that I'll pass it off to rob",
    "start": "1311600",
    "end": "1316120"
  },
  {
    "text": "thanks man good afternoon i'm rom CTO of beeswax",
    "start": "1321270",
    "end": "1328990"
  },
  {
    "text": "and today i wanted to share with you our experiences of building a streaming application on top of Kinesis so before",
    "start": "1328990",
    "end": "1336790"
  },
  {
    "text": "we get started a quick introduction to beeswax this is a company that I started with two of my former colleagues from",
    "start": "1336790",
    "end": "1342130"
  },
  {
    "text": "Google we started the company in 2014 it's based out of New York and our first product was released in summer of 2015",
    "start": "1342130",
    "end": "1349630"
  },
  {
    "text": "it's called beeswax barrel as a service I'll talk more about barrel as a service in my following slides we just recently",
    "start": "1349630",
    "end": "1356440"
  },
  {
    "text": "closed our a round and I'm now really looking to grow our team business and infrastructure and so if you're",
    "start": "1356440",
    "end": "1362650"
  },
  {
    "text": "interested in working on really large scale high-performance distributed systems devops on AWS or machine",
    "start": "1362650",
    "end": "1368860"
  },
  {
    "text": "learning feel free to reach out to me after the stock or please go check out our website",
    "start": "1368860",
    "end": "1374460"
  },
  {
    "start": "1374000",
    "end": "1374000"
  },
  {
    "text": "so what we do at beeswax is real time bidding now the programmatic digital",
    "start": "1374460",
    "end": "1380500"
  },
  {
    "text": "advertising these days is transacted on this really large online marketplaces called ad exchanges ad exchanges bring",
    "start": "1380500",
    "end": "1387700"
  },
  {
    "text": "together publishers and advertisers publishers are sellers on this marketplace they are selling placements",
    "start": "1387700",
    "end": "1394300"
  },
  {
    "text": "a placement is a place where you can show an ad and the advertisers are buyers they're buying this placement in",
    "start": "1394300",
    "end": "1400090"
  },
  {
    "text": "order to show an ad a transaction on this exchange is initiated whenever a user visits website",
    "start": "1400090",
    "end": "1406630"
  },
  {
    "text": "or uses an app that sends an ad request to the exchange this ad request will",
    "start": "1406630",
    "end": "1412120"
  },
  {
    "text": "contain some information about the placement such as the name of the app are the the domain of the site along",
    "start": "1412120",
    "end": "1418510"
  },
  {
    "text": "with the information about the user ID such as the cookie or the mobile device identifier and the exchange receives",
    "start": "1418510",
    "end": "1424660"
  },
  {
    "text": "this and then broadcasts it to a set of bidders now a bidder is a piece of",
    "start": "1424660",
    "end": "1430450"
  },
  {
    "text": "software that's deployed on behalf of an advertiser to help them execute their advertising campaigns and the bidder",
    "start": "1430450",
    "end": "1436990"
  },
  {
    "text": "responds back with a bid price and the mark-up of the ad and then the exchange waits to get back the responses from all",
    "start": "1436990",
    "end": "1444160"
  },
  {
    "text": "the different bidders runs the second price auction picks a winner and the winners dad gets shown to the user so",
    "start": "1444160",
    "end": "1449440"
  },
  {
    "text": "this is what happens behind the scenes every time you see an ad on a website this whole transaction lasts for less",
    "start": "1449440",
    "end": "1455559"
  },
  {
    "text": "than 200 milliseconds and it's done many million times per second and the industry term for the process that I",
    "start": "1455559",
    "end": "1461620"
  },
  {
    "text": "just described is real-time bidding now it turns out that building a bidder is a",
    "start": "1461620",
    "end": "1467950"
  },
  {
    "start": "1465000",
    "end": "1465000"
  },
  {
    "text": "really hard technical problem so for advertising campaigns to be successful they need to reach a really large",
    "start": "1467950",
    "end": "1473679"
  },
  {
    "text": "audience and often this audience is located in different parts of the world such as North America Europe Asia etc",
    "start": "1473679",
    "end": "1482140"
  },
  {
    "text": "and so a bidder has to be able to scale up to receive and process at least a",
    "start": "1482140",
    "end": "1488289"
  },
  {
    "text": "million queries per second in order to be able to find the users that are relevant for a particular campaign",
    "start": "1488289",
    "end": "1493950"
  },
  {
    "text": "furthermore the bidder has to be deployed in different regions such as US East US West US and the state amongst",
    "start": "1493950",
    "end": "1501940"
  },
  {
    "text": "these different deployments has to be carefully coordinated and so building such a large-scale distributed system is",
    "start": "1501940",
    "end": "1508000"
  },
  {
    "text": "really hard and and operating it is an even harder challenge and in terms of performance as I mentioned an ad",
    "start": "1508000",
    "end": "1514120"
  },
  {
    "text": "transaction on the exchange lasts for only 200 milliseconds and out of that the exchange is set time out of 100",
    "start": "1514120",
    "end": "1521380"
  },
  {
    "text": "milliseconds to the bidder within which they expect to get back response in reality the bidders only get 20",
    "start": "1521380",
    "end": "1527260"
  },
  {
    "text": "milliseconds to process a request because a large fraction of the time is spent in round-trip over the Internet so",
    "start": "1527260",
    "end": "1533140"
  },
  {
    "text": "building a bidder requires aggressive optimisation which is again a non-trivial engineering task and finally",
    "start": "1533140",
    "end": "1540789"
  },
  {
    "text": "bidders operate in a in a complex ecosystem where they are plugged into multiple supply vendors data vendors",
    "start": "1540789",
    "end": "1547630"
  },
  {
    "text": "that provide signals for viewability fraud detection etcetera and putting together all of this is it requires a",
    "start": "1547630",
    "end": "1554289"
  },
  {
    "text": "lot of domain expertise and so for the reasons that I just described building a bidder is a really hard problem",
    "start": "1554289",
    "end": "1561299"
  },
  {
    "start": "1561000",
    "end": "1561000"
  },
  {
    "text": "so advertisers that wish to embrace RTB currently have two options they could go",
    "start": "1561299",
    "end": "1567490"
  },
  {
    "text": "ahead and build up on bidder but it's a very risky investment of time and money the other option is to use this platform",
    "start": "1567490",
    "end": "1575400"
  },
  {
    "text": "software called demand side platform or DSPs a DSP is like an online broker in a",
    "start": "1575400",
    "end": "1582669"
  },
  {
    "text": "financial marketplace the good part of using a DSP is that it just works however it provides very",
    "start": "1582669",
    "end": "1588850"
  },
  {
    "text": "limited opportunities for customization and so now with the beeswax bitter as a",
    "start": "1588850",
    "end": "1594970"
  },
  {
    "start": "1592000",
    "end": "1592000"
  },
  {
    "text": "service the advertisers that wish to use RTB have a third option",
    "start": "1594970",
    "end": "1600840"
  },
  {
    "text": "beeswax bitter as a service is a fully managed ad tech platform built on top of AWS we are already integrated into all",
    "start": "1600840",
    "end": "1608740"
  },
  {
    "text": "the supply sources and the third-party data vendors we provide a rich set of features such as campaign management",
    "start": "1608740",
    "end": "1615510"
  },
  {
    "text": "budgeting frequency capping reporting targeting etc and we also provide",
    "start": "1615510",
    "end": "1621010"
  },
  {
    "text": "optimization features in the form of pacing and click prediction so by using",
    "start": "1621010",
    "end": "1626530"
  },
  {
    "text": "this platform a customer can get up and running with their campaigns as they get access to a full feature UI is basically",
    "start": "1626530",
    "end": "1633250"
  },
  {
    "text": "a DSP on day 0 however the real power of the platform lies in the rich set of API",
    "start": "1633250",
    "end": "1639040"
  },
  {
    "text": "is that we provide that really enable our customers to build custom billing solutions on top of this so for example",
    "start": "1639040",
    "end": "1646000"
  },
  {
    "text": "we provide an augmentation API that lets our customers augment a bid request with",
    "start": "1646000",
    "end": "1651340"
  },
  {
    "text": "their own signal they can bring their own data so an example of this could be for example if there's a customer that",
    "start": "1651340",
    "end": "1657010"
  },
  {
    "text": "has rich location data they can look up the latitude and the longitude in the request and then augment the request",
    "start": "1657010",
    "end": "1662860"
  },
  {
    "text": "with you know where the user is present and then target adds to them based on that similarly we provide a bidding API",
    "start": "1662860",
    "end": "1669520"
  },
  {
    "text": "that lets advertisers choose a creative and also a bit price on a per request",
    "start": "1669520",
    "end": "1675130"
  },
  {
    "text": "basis and this is again a level of flexibility that is not supported by any DSP so for example a big online retailer",
    "start": "1675130",
    "end": "1682179"
  },
  {
    "text": "could use this product and then recommend products out of their inventory as they see the users are on",
    "start": "1682179",
    "end": "1688210"
  },
  {
    "text": "the web so really the the focus here is on the advertiser to sort of build a",
    "start": "1688210",
    "end": "1693670"
  },
  {
    "text": "differentiated aspect of the bidder by bringing their own data their own strategy and leaving the non",
    "start": "1693670",
    "end": "1699550"
  },
  {
    "text": "differentiated aspects of like integration to supply sources scaling etcetera to beeswax",
    "start": "1699550",
    "end": "1706230"
  },
  {
    "start": "1706000",
    "end": "1706000"
  },
  {
    "text": "so with this introduction to beeswax and RTB in the rest of the talk I'll cover this is some architecture go over the",
    "start": "1706230",
    "end": "1713350"
  },
  {
    "text": "reasons for why we chose Kinesis and then talk about some of the challenges that we faced while building our",
    "start": "1713350",
    "end": "1719320"
  },
  {
    "text": "application and then discuss some of the trade-offs that we had to evaluate to arrive at the solution",
    "start": "1719320",
    "end": "1726179"
  },
  {
    "start": "1726000",
    "end": "1726000"
  },
  {
    "text": "so the following is a stream centric view of our application so on the Left",
    "start": "1726179",
    "end": "1732820"
  },
  {
    "text": "we have the data producers the big data producer is a set of servers that are",
    "start": "1732820",
    "end": "1738279"
  },
  {
    "text": "deployed on AWS ec2 auto-scale groups and they process the receive and process",
    "start": "1738279",
    "end": "1744090"
  },
  {
    "text": "you know millions of queries per second from the different ad exchanges the real",
    "start": "1744090",
    "end": "1749500"
  },
  {
    "text": "challenge for us in implementing the bid data producers was to be able to scale",
    "start": "1749500",
    "end": "1754690"
  },
  {
    "text": "up data collection to such a high volume the impression and the Kliq data",
    "start": "1754690",
    "end": "1761110"
  },
  {
    "text": "producers receive events from low QPS sources such as notifications of a win",
    "start": "1761110",
    "end": "1768010"
  },
  {
    "text": "from an exchange or when a user clicks on an ad all those events from the browser end up with this data producer",
    "start": "1768010",
    "end": "1774159"
  },
  {
    "text": "the challenge with this data producer was to be able to perform lossless data",
    "start": "1774159",
    "end": "1779799"
  },
  {
    "text": "collection all the producers log the events that they receive into a common",
    "start": "1779799",
    "end": "1786250"
  },
  {
    "text": "event stream and we use protocol buffers for encoding the payload of the the",
    "start": "1786250",
    "end": "1792010"
  },
  {
    "text": "event itself the core of our architecture is this",
    "start": "1792010",
    "end": "1797019"
  },
  {
    "text": "application called the streaming message hub that is responsible for reading events from the stream and processing",
    "start": "1797019",
    "end": "1802990"
  },
  {
    "text": "them we expose a REST API to our customers that lets them program the",
    "start": "1802990",
    "end": "1808539"
  },
  {
    "text": "streaming message app so as to be able to aggregate transform and then deliver",
    "start": "1808539",
    "end": "1814419"
  },
  {
    "text": "records to a destination of their choice we currently support delivery to s3",
    "start": "1814419",
    "end": "1820179"
  },
  {
    "text": "buckets Kinesis streams data warehouse solutions such as redshift are also a real-time HTTP POST to a server that",
    "start": "1820179",
    "end": "1827470"
  },
  {
    "text": "they might have deployed so now i want to go over the reasons for",
    "start": "1827470",
    "end": "1832840"
  },
  {
    "start": "1830000",
    "end": "1830000"
  },
  {
    "text": "why we choose Kinesis so the infrastructure requirements were really",
    "start": "1832840",
    "end": "1838149"
  },
  {
    "text": "motivated by our TB use cases so we clearly needed to support ingestion at a very large scale also we needed an",
    "start": "1838149",
    "end": "1846130"
  },
  {
    "text": "infrastructure that we could depend upon for reliable storage as well as being able to deliver events with low latency",
    "start": "1846130",
    "end": "1852610"
  },
  {
    "text": "and finally we also needed to rely upon sequence retrieval of events and I'll",
    "start": "1852610",
    "end": "1857830"
  },
  {
    "text": "talk more about this when I talk about event joints in my later part of the talk and so it's possible theoretically",
    "start": "1857830",
    "end": "1865389"
  },
  {
    "text": "that we could have avoided streaming altogether and build this on top of s3",
    "start": "1865389",
    "end": "1870419"
  },
  {
    "text": "but that would have been a really bad design choice because we would have ended up with a large number of really",
    "start": "1870419",
    "end": "1876159"
  },
  {
    "text": "small files in s3 that we would have had to manage ourselves in order to minimize latency and furthermore it's not really",
    "start": "1876159",
    "end": "1883090"
  },
  {
    "text": "clear how we could have built sequence retrieval with files raw files on s3 so",
    "start": "1883090",
    "end": "1889480"
  },
  {
    "text": "at the time when we were building this system we really had a couple of choices",
    "start": "1889480",
    "end": "1894700"
  },
  {
    "text": "on AWS we could choose Kinesis or we could roll our own apache cough our",
    "start": "1894700",
    "end": "1901389"
  },
  {
    "text": "cluster on an order scale ec2 in the end we decided to choose Kinesis",
    "start": "1901389",
    "end": "1907179"
  },
  {
    "text": "mainly because it's a service that's fully managed by AWS and I cannot emphasize this aspect enough",
    "start": "1907179",
    "end": "1913570"
  },
  {
    "text": "particularly for small engineering teams such as ours because Kinesis that does a really good job of replicating data to",
    "start": "1913570",
    "end": "1921639"
  },
  {
    "text": "multiple availability zones and and makes the data available and trying to",
    "start": "1921639",
    "end": "1926919"
  },
  {
    "text": "do this ourselves and meeting that level like the operational overhead of trying to do this ourselves ourselves and like",
    "start": "1926919",
    "end": "1933100"
  },
  {
    "text": "meeting this level of reliability is something that we just simply could not have afforded to do",
    "start": "1933100",
    "end": "1941129"
  },
  {
    "text": "also based on our early sort of communication with the team and reading",
    "start": "1941129",
    "end": "1946600"
  },
  {
    "text": "the documentation etc it was pretty clear that the infrastructure could scale to meet the requirements of our TB",
    "start": "1946600",
    "end": "1952450"
  },
  {
    "text": "and also finally the pricing model of Kinesis offered us with a lot of opportunities to perform cost",
    "start": "1952450",
    "end": "1959110"
  },
  {
    "text": "optimization so really in the end it wasn't that difficult a choice for us to",
    "start": "1959110",
    "end": "1964990"
  },
  {
    "text": "make for going ahead with Kinesis so now I'd like to talk about some of",
    "start": "1964990",
    "end": "1972100"
  },
  {
    "start": "1968000",
    "end": "1968000"
  },
  {
    "text": "the challenges that we faced in building our application so one of the features that we provide in our platform is",
    "start": "1972100",
    "end": "1979980"
  },
  {
    "text": "listening better a listening bidder is a bidder that doesn't actually bid but",
    "start": "1979980",
    "end": "1985330"
  },
  {
    "text": "instead is only interested in listening to a filtered stream of bid requests the",
    "start": "1985330",
    "end": "1991210"
  },
  {
    "text": "filtering criteria itself can be specified as a boolean expression on the attributes of the bid request and really",
    "start": "1991210",
    "end": "1998350"
  },
  {
    "text": "for us the main challenge here was to be able to build a data producer that can",
    "start": "1998350",
    "end": "2003360"
  },
  {
    "text": "collect events at a such a at a very high scale while also making sure that the costs are managed",
    "start": "2003360",
    "end": "2010700"
  },
  {
    "text": "and now I want to cover some of the optimizations that we performed in the",
    "start": "2010700",
    "end": "2017760"
  },
  {
    "start": "2012000",
    "end": "2012000"
  },
  {
    "text": "design of our producers in order to implement features such as the listening bidder so one of the",
    "start": "2017760",
    "end": "2025140"
  },
  {
    "text": "dimensions of the Kinesis pricing model is the number of put payloads that are uploaded into this stream put payload is",
    "start": "2025140",
    "end": "2033000"
  },
  {
    "text": "a 25 kilobyte chunk of data so in order to minimize cost it made sense for us to",
    "start": "2033000",
    "end": "2038160"
  },
  {
    "text": "pack more of the records the bid requests into a single put payload and and uploaded however this reduces the",
    "start": "2038160",
    "end": "2046200"
  },
  {
    "text": "reliability of the application because now it's vulnerable to data loss in case",
    "start": "2046200",
    "end": "2052169"
  },
  {
    "text": "the producer crashes before it gets chance to persist then you end up with the situation where you've lost some data",
    "start": "2052169",
    "end": "2058310"
  },
  {
    "text": "unfortunately I don't think that there is an inexpensive way to perform reliable data collection at scale",
    "start": "2058310",
    "end": "2065450"
  },
  {
    "text": "however for some of our loki's producers we were able to come up with a few",
    "start": "2065450",
    "end": "2070950"
  },
  {
    "text": "creative things so and I'd like to share one of them with you so for the low QPS",
    "start": "2070950",
    "end": "2076408"
  },
  {
    "text": "data producers that we have we front them with a Amazon load balancer and ELB and ELB has this feature called requests",
    "start": "2076409",
    "end": "2084628"
  },
  {
    "text": "logging that actually logs the URL of the get request and makes it available on s3 few minutes later so keep in mind",
    "start": "2084629",
    "end": "2091560"
  },
  {
    "text": "that this is not streaming data from ELB but it's actually data that's batch put into files and then and made available",
    "start": "2091560",
    "end": "2098630"
  },
  {
    "text": "so in the event of data loss what we do we have a mechanism in place to replay",
    "start": "2098630",
    "end": "2104100"
  },
  {
    "text": "these logs from s3 and we ingest they re sort of inject data into the stream this",
    "start": "2104100",
    "end": "2111870"
  },
  {
    "text": "enables us to perform lossless zero loss collection and I also want to",
    "start": "2111870",
    "end": "2118109"
  },
  {
    "text": "point out that this is only possible if the attributes of your could be encoded within the URL of a get",
    "start": "2118109",
    "end": "2124950"
  },
  {
    "text": "request will be so my point is that there could be many interesting ways to sort of work around some limitations",
    "start": "2124950",
    "end": "2131990"
  },
  {
    "text": "also while performing optimizations it's important to consider the overall system",
    "start": "2131990",
    "end": "2137700"
  },
  {
    "text": "cost so compression for example reduces the amount of data that's put into the",
    "start": "2137700",
    "end": "2143190"
  },
  {
    "text": "stream thereby reducing the infrastructure costs of Kinesis however compression obviously also increases the",
    "start": "2143190",
    "end": "2149400"
  },
  {
    "text": "CPU utilization of the producers and consumers so it's really important to",
    "start": "2149400",
    "end": "2155130"
  },
  {
    "text": "experiment and make sure that to make sure the compression makes sense and what compression technology to use so in",
    "start": "2155130",
    "end": "2162630"
  },
  {
    "text": "our experiments we found that using snappy instead of gzip actually resulted",
    "start": "2162630",
    "end": "2167910"
  },
  {
    "text": "in the reduction of our overall cost even though snappy has a lower compression ratio as compared to gzip so",
    "start": "2167910",
    "end": "2174480"
  },
  {
    "text": "it's really important again to just keep the overall system cost in mind",
    "start": "2174480",
    "end": "2180650"
  },
  {
    "text": "buffering of data obviously leads to an increase in throughput because more data can be uploaded per API call",
    "start": "2180829",
    "end": "2187579"
  },
  {
    "text": "however it increases latency because data is being buffered but a simple workaround for that is to periodically",
    "start": "2187579",
    "end": "2193380"
  },
  {
    "text": "flush your buffers so as to have a cap on on the latency and finally as Ryan mentioned in this talk",
    "start": "2193380",
    "end": "2200579"
  },
  {
    "text": "it's really important to choose the right partition key and it's particularly important to choose a",
    "start": "2200579",
    "end": "2206640"
  },
  {
    "text": "partition key I feel that's uniformly distributed over the shards if your application permits and in sort of the",
    "start": "2206640",
    "end": "2214829"
  },
  {
    "text": "scenario such as ours where we're doing data collection at a really large scale it's it becomes particularly important",
    "start": "2214829",
    "end": "2221160"
  },
  {
    "text": "because you don't want to end up with the situation where a single shard becomes a hotspot and a single point of",
    "start": "2221160",
    "end": "2226260"
  },
  {
    "text": "failure and in our application we choose the auction ID of the incoming bid",
    "start": "2226260",
    "end": "2233130"
  },
  {
    "text": "request as the partition key and as I'll talk about it later it also is sort of a",
    "start": "2233130",
    "end": "2238740"
  },
  {
    "text": "join key between correlated events in our stream",
    "start": "2238740",
    "end": "2243650"
  },
  {
    "start": "2244000",
    "end": "2244000"
  },
  {
    "text": "the second challenge that we had to address was of data transformation and",
    "start": "2244130",
    "end": "2249390"
  },
  {
    "text": "fan-out so the platform the beeswax platform produces a continuous stream of",
    "start": "2249390",
    "end": "2255330"
  },
  {
    "text": "data that needs to be constantly fed to our customers so us so that they could build their their own strategies and so",
    "start": "2255330",
    "end": "2262980"
  },
  {
    "text": "we provide an API to our customers that lets them configure both the format of the data as",
    "start": "2262980",
    "end": "2268860"
  },
  {
    "text": "well as the destination where they'd like to receive it and this really enables them to ingest data more easily",
    "start": "2268860",
    "end": "2275970"
  },
  {
    "text": "into their systems and so the main challenge for us here was to architect a",
    "start": "2275970",
    "end": "2281310"
  },
  {
    "text": "config driven system that can determine the the format the schema and the",
    "start": "2281310",
    "end": "2286800"
  },
  {
    "text": "destination of every record and also from a production standpoint we wanted",
    "start": "2286800",
    "end": "2292650"
  },
  {
    "text": "to make sure that our deployments were elastically scalable based on the number of events in the Kinesis stream",
    "start": "2292650",
    "end": "2300500"
  },
  {
    "start": "2300000",
    "end": "2300000"
  },
  {
    "text": "so our solution called the streaming message hub is built on top of KCl as",
    "start": "2300860",
    "end": "2306750"
  },
  {
    "text": "Ryan mentioned KCl already handles load balancing as well as a stream",
    "start": "2306750",
    "end": "2313170"
  },
  {
    "text": "checkpointing also it uses dynamodb under the hood to store some of its state however the DynamoDB resource",
    "start": "2313170",
    "end": "2321030"
  },
  {
    "text": "utilization is very minimal it doesn't really add a lot to the overall cost and it provides this abstraction called",
    "start": "2321030",
    "end": "2327750"
  },
  {
    "text": "record processor which is mapped to every single shard in the stream and so you know if you're building scalable",
    "start": "2327750",
    "end": "2335700"
  },
  {
    "text": "reader applications KCl is the right place to start unless there is something",
    "start": "2335700",
    "end": "2341130"
  },
  {
    "text": "esoteric about the application I really cannot imagine a good reason for not using KCl",
    "start": "2341130",
    "end": "2347240"
  },
  {
    "text": "so in our application the KCl record processor receives a batch of records it",
    "start": "2347240",
    "end": "2352590"
  },
  {
    "text": "uncompressed it and then does unperson on the serial serially encoded binary",
    "start": "2352590",
    "end": "2358350"
  },
  {
    "text": "protocol buffer data at this point we know the type of the event that we're handling it could be a bit event a win",
    "start": "2358350",
    "end": "2366150"
  },
  {
    "text": "event or a click event and then based on the type of the event we routed to the appropriate adapter the job of the",
    "start": "2366150",
    "end": "2373080"
  },
  {
    "text": "adapter is to perform a schema or format transformations and it's again driven by the config the customer config whatever",
    "start": "2373080",
    "end": "2380520"
  },
  {
    "text": "they want and they told us into the API once the adapter is done transforming",
    "start": "2380520",
    "end": "2387510"
  },
  {
    "text": "the records it sent to a string of emitters the job of the emitter is to",
    "start": "2387510",
    "end": "2393400"
  },
  {
    "text": "again copy the records based on the configs and and copy them into an",
    "start": "2393400",
    "end": "2398470"
  },
  {
    "text": "in-memory data buffer and then periodically flush this data buffer to wherever it's trying to persist the data",
    "start": "2398470",
    "end": "2404890"
  },
  {
    "text": "and so we currently support emitters for s3 Kinesis HTTP endpoints etcetera and",
    "start": "2404890",
    "end": "2410890"
  },
  {
    "text": "we you know buffer and flush so as to increase throughput and also one of the",
    "start": "2410890",
    "end": "2416830"
  },
  {
    "text": "key aspects of the application is that it checkpoints data only after an emitter has successfully delivered the",
    "start": "2416830",
    "end": "2424390"
  },
  {
    "text": "data to the destination and by doing this we are able to guarantee at least",
    "start": "2424390",
    "end": "2430000"
  },
  {
    "text": "one semantics which means that we'll process every record in the stream at least once also since this application is deployed",
    "start": "2430000",
    "end": "2437140"
  },
  {
    "text": "on an auto scale ec2 group we were also able to achieve our goal of having an",
    "start": "2437140",
    "end": "2442930"
  },
  {
    "text": "elastically scalable deployment because we make use of CPU utilization alarms from cloud watch to scale up and scale",
    "start": "2442930",
    "end": "2449920"
  },
  {
    "text": "down our fleet so now I want to go over some of the",
    "start": "2449920",
    "end": "2455050"
  },
  {
    "start": "2452000",
    "end": "2452000"
  },
  {
    "text": "trade-offs that we considered in the design of the streaming message hub we went ahead with the design where we",
    "start": "2455050",
    "end": "2461530"
  },
  {
    "text": "have a single reader for every combination of format and destination as opposed to having multiple readers",
    "start": "2461530",
    "end": "2467850"
  },
  {
    "text": "having multiple readers obviously increases the fault tolerance of the system there's no more a single point of",
    "start": "2467850",
    "end": "2473980"
  },
  {
    "text": "failure however in our application it turned out that the CPU cost of uncompressing and",
    "start": "2473980",
    "end": "2481380"
  },
  {
    "text": "unperson protocol buffers was pretty significant and we really couldn't justify paying the cost for it multiple",
    "start": "2481380",
    "end": "2488740"
  },
  {
    "text": "times in different readers also the goal of having a scalable",
    "start": "2488740",
    "end": "2494380"
  },
  {
    "text": "elastically scalable compute could have been realized using lambda as opposed to ec2 autoscale the advantage of using",
    "start": "2494380",
    "end": "2502420"
  },
  {
    "text": "lambda is that it's managed by AWS however we recently moved to using spot",
    "start": "2502420",
    "end": "2509350"
  },
  {
    "text": "instances which significantly cut down the cost of this self-manage solution",
    "start": "2509350",
    "end": "2514900"
  },
  {
    "text": "and also the rich set of metrics that are provided by KCl and an Kinesis stream we made the",
    "start": "2514900",
    "end": "2522540"
  },
  {
    "text": "task of monitoring and operating the service a whole lot simpler so in the end we really couldn't justify the the",
    "start": "2522540",
    "end": "2530200"
  },
  {
    "text": "cost overhead of moving to lambda but then again this is something that really depends on the application",
    "start": "2530200",
    "end": "2535710"
  },
  {
    "text": "and as Ryan mentioned in his presentation Kinesis fire hose is",
    "start": "2535710",
    "end": "2541900"
  },
  {
    "text": "another service that we considered and this was very early on when fire hose was just announced and at the time when",
    "start": "2541900",
    "end": "2547810"
  },
  {
    "text": "we were looking at fire hose it did not support record level fan out of data to multiple destinations and also sort of",
    "start": "2547810",
    "end": "2555010"
  },
  {
    "text": "arbitrary data transformation as I mentioned we have protocol buffer as the data format in our stream and there was",
    "start": "2555010",
    "end": "2561190"
  },
  {
    "text": "no easy way for us to convert from protobufs to something else using fire hose but then based on feedback from us",
    "start": "2561190",
    "end": "2567880"
  },
  {
    "text": "and I'm sure other customers the team is coming up with a bunch of new interesting features at which point I",
    "start": "2567880",
    "end": "2574180"
  },
  {
    "text": "think it would be a very interesting alternative over a self-managed ec2 solution",
    "start": "2574180",
    "end": "2581040"
  },
  {
    "start": "2581000",
    "end": "2581000"
  },
  {
    "text": "the final so one the other aspect that I wanted to touch upon is operating the",
    "start": "2581040",
    "end": "2588910"
  },
  {
    "text": "streaming message app so in terms of scale we're currently you know in operating with more than 300 shards in a",
    "start": "2588910",
    "end": "2595210"
  },
  {
    "text": "given region and consuming about 250 megabytes per second we make use of the",
    "start": "2595210",
    "end": "2601450"
  },
  {
    "text": "cloud watch alarms on metrics that Kinesis streams directly export so the",
    "start": "2601450",
    "end": "2608860"
  },
  {
    "text": "Kinesis capacity alert is set up in our system to trigger whenever the number of",
    "start": "2608860",
    "end": "2613930"
  },
  {
    "text": "bytes in the stream reaches 80% of the overall capacity of the stream and whenever this alert fires what we do is",
    "start": "2613930",
    "end": "2621100"
  },
  {
    "text": "go ahead and manually recharge the stream using the Kinesis scaling utils that that ryan mentioned however there",
    "start": "2621100",
    "end": "2627610"
  },
  {
    "text": "is a new API that was recently introduced and by making use of the API the actions that we perform when this",
    "start": "2627610",
    "end": "2634090"
  },
  {
    "text": "alarm fires can be completely automated the other alert that we pay a lot of",
    "start": "2634090",
    "end": "2639400"
  },
  {
    "text": "attention to is how many seconds behind real time is the current I traitor and",
    "start": "2639400",
    "end": "2644560"
  },
  {
    "text": "if this goes behind 20 seconds for instance we raise an alarm this alarm is",
    "start": "2644560",
    "end": "2650650"
  },
  {
    "text": "pretty critical for us in order to maintain our latency SLS with our customer and usually when this alarm",
    "start": "2650650",
    "end": "2656870"
  },
  {
    "text": "fires it means that there's a problem in the reader application that requires immediate triage in terms of overhead of",
    "start": "2656870",
    "end": "2664370"
  },
  {
    "text": "management I would say we roughly receive about two alarms in a month and most of the times it's the capacity",
    "start": "2664370",
    "end": "2670460"
  },
  {
    "text": "alert because our service is growing and therefore we're basically running out of capacity on the stream",
    "start": "2670460",
    "end": "2677410"
  },
  {
    "start": "2677000",
    "end": "2677000"
  },
  {
    "text": "the final challenge that I want to talk about is joining streams now joining",
    "start": "2677410",
    "end": "2683030"
  },
  {
    "text": "refers to taking putting together correlated events into a single record",
    "start": "2683030",
    "end": "2689300"
  },
  {
    "text": "and this is a high-level service that we wanted to provide to our customers so that they don't have to do the join",
    "start": "2689300",
    "end": "2695570"
  },
  {
    "text": "themselves and they could directly consume this joint data to feed into their ETL pipelines or their machine",
    "start": "2695570",
    "end": "2701690"
  },
  {
    "text": "learning systems and there are a lot of challenges in implementing joints correctly so with joints you have to",
    "start": "2701690",
    "end": "2709280"
  },
  {
    "text": "support exactly ones semantics now as you may recall that in our producer in",
    "start": "2709280",
    "end": "2717200"
  },
  {
    "text": "art in order to guarantee a lossless collection sometimes you end up replaying data and re-injecting data",
    "start": "2717200",
    "end": "2725360"
  },
  {
    "text": "into the stream also with the readers it is possible that they could crash before",
    "start": "2725360",
    "end": "2731870"
  },
  {
    "text": "the reader gets a gets an opportunity to to checkpoint so that means that there",
    "start": "2731870",
    "end": "2738950"
  },
  {
    "text": "are going to be duplicate events and so in order to perform joints accurately",
    "start": "2738950",
    "end": "2744350"
  },
  {
    "text": "it's really important to guarantee that we process every record exactly once also we wanted to minimize the",
    "start": "2744350",
    "end": "2751490"
  },
  {
    "text": "end-to-end latency from the time when we capture an event to when it's actually available for consumption by our",
    "start": "2751490",
    "end": "2758030"
  },
  {
    "text": "customers and the last part the last challenge is to be able to be robust to",
    "start": "2758030",
    "end": "2763790"
  },
  {
    "text": "delays between the arrival time of correlated events in our tech what",
    "start": "2763790",
    "end": "2768860"
  },
  {
    "text": "happens sometimes is that people load a website but they don't click on the ad",
    "start": "2768860",
    "end": "2775190"
  },
  {
    "text": "like till 2 or 3 hours later so this means that the correlated event which is you know click is correlated to an",
    "start": "2775190",
    "end": "2781160"
  },
  {
    "text": "impression which is correlated to the bid happen at many it's sort of like a",
    "start": "2781160",
    "end": "2786590"
  },
  {
    "text": "there's a lot of delay between when these events actually happen and building a system that's robust to the",
    "start": "2786590",
    "end": "2792490"
  },
  {
    "text": "large delay between the arrival of the correlated events is a really hard problem because this directly translates",
    "start": "2792490",
    "end": "2799420"
  },
  {
    "text": "into hama how much state you want to store in memory are somewhere else to be able to do the joins effectively and our",
    "start": "2799420",
    "end": "2808090"
  },
  {
    "start": "2807000",
    "end": "2807000"
  },
  {
    "text": "solution makes use of redshift under the hood to do the joints so",
    "start": "2808090",
    "end": "2813390"
  },
  {
    "text": "we make use of for streaming message hub that collects data for different event",
    "start": "2813390",
    "end": "2819700"
  },
  {
    "text": "types and then puts them into files on s3 we make use of data pipeline which is",
    "start": "2819700",
    "end": "2825250"
  },
  {
    "text": "an AWS managed service for picking up these files from s3 and then injecting",
    "start": "2825250",
    "end": "2830980"
  },
  {
    "text": "them into a data warehouse as redshift and then",
    "start": "2830980",
    "end": "2836610"
  },
  {
    "text": "we end up having separate tables for each event type in redshift and we make",
    "start": "2836610",
    "end": "2842920"
  },
  {
    "text": "use of the auction key as the primary key for each one of this table and if",
    "start": "2842920",
    "end": "2848020"
  },
  {
    "text": "you may if you recollect the auction ID was also the partition key that we use in our streams",
    "start": "2848020",
    "end": "2854730"
  },
  {
    "text": "we have two modes in which we operate these joints we have a fast path in",
    "start": "2854730",
    "end": "2860470"
  },
  {
    "text": "which the events are joined within fifteen minutes and made available to the customer but it's",
    "start": "2860470",
    "end": "2868420"
  },
  {
    "text": "inaccurate because sometimes you will miss events that correlated events which might appear a little bit later we also",
    "start": "2868420",
    "end": "2875140"
  },
  {
    "text": "have a slow path which makes data available full 24 hours after the event",
    "start": "2875140",
    "end": "2880690"
  },
  {
    "text": "has occurred but this is more accurate because we have a larger window over which we could run our joints",
    "start": "2880690",
    "end": "2887970"
  },
  {
    "text": "so in terms of trade-offs one of the things that I'd like to point out is that our solution for joints is not",
    "start": "2887970",
    "end": "2895240"
  },
  {
    "start": "2888000",
    "end": "2888000"
  },
  {
    "text": "truly streaming we are in fact batching data in 15 minute chunks and then uploading it into redshift and this 15",
    "start": "2895240",
    "end": "2903010"
  },
  {
    "text": "minute interval is currently dictated mainly by limitation of AWS pipeline so",
    "start": "2903010",
    "end": "2908170"
  },
  {
    "text": "how often you can have recurring pipelines be scheduled and we can easily work around that by moving to lambda but",
    "start": "2908170",
    "end": "2916660"
  },
  {
    "text": "the other sort of issue I feel with our approach is that once data gets into red shift it's not easy to take it out of",
    "start": "2916660",
    "end": "2924769"
  },
  {
    "text": "redshift and stream it to a destination it's possible to have you know data from",
    "start": "2924769",
    "end": "2930950"
  },
  {
    "text": "the redshift be unloaded in to files in s3 and then set up a lambda that sort of writes into Kinesis but all of that is",
    "start": "2930950",
    "end": "2938150"
  },
  {
    "text": "expensive and and really doesn't feel correct and so that I feel currently is",
    "start": "2938150",
    "end": "2944660"
  },
  {
    "text": "one of the issues with our current approach however I do want to point out",
    "start": "2944660",
    "end": "2950150"
  },
  {
    "text": "that our current approach scales really well it's fully managed by AWS and it",
    "start": "2950150",
    "end": "2955220"
  },
  {
    "text": "supports many of our use cases so now looking into the future we are",
    "start": "2955220",
    "end": "2960289"
  },
  {
    "start": "2958000",
    "end": "2958000"
  },
  {
    "text": "looking at what are the different alternatives that we could explore for performing stream joints and currently I",
    "start": "2960289",
    "end": "2969259"
  },
  {
    "text": "feel there are a couple of options that are interesting one is to use spark streaming on top of EMR or the other one",
    "start": "2969259",
    "end": "2977029"
  },
  {
    "text": "which is recently announced by the Kinesis team is to use Kinesis analytics so here are some of my early thoughts on",
    "start": "2977029",
    "end": "2983930"
  },
  {
    "text": "this the advantage of SPARC is that it provides it can do any arbitrary data",
    "start": "2983930",
    "end": "2990109"
  },
  {
    "text": "format or transformation you're basically running your own code however from an operational standpoint it's not",
    "start": "2990109",
    "end": "2997039"
  },
  {
    "text": "clear how much of an overhead it would be to really run your own spark cluster it seems like it might be a big overhead",
    "start": "2997039",
    "end": "3005400"
  },
  {
    "text": "the advantage of using Kinesis analytics is that it provides a sequel like interface to streams and our joints",
    "start": "3005400",
    "end": "3012759"
  },
  {
    "text": "could basically simply be expressed as a sql-like query and also since it's managed by AWS and it's elastic you know",
    "start": "3012759",
    "end": "3020049"
  },
  {
    "text": "you don't have to worry about issues such as capacity planning etc however it's pretty early stages in",
    "start": "3020049",
    "end": "3027160"
  },
  {
    "text": "terms of evaluating Kinesis analytics for us so we really want to make sure if it can scale to RT be like workloads and",
    "start": "3027160",
    "end": "3033579"
  },
  {
    "text": "support arbitrary data format transformations it set before we jump on to it and",
    "start": "3033579",
    "end": "3039569"
  },
  {
    "text": "so therefore to conclude my talk in summary I talked about why building our",
    "start": "3039569",
    "end": "3045069"
  },
  {
    "start": "3040000",
    "end": "3040000"
  },
  {
    "text": "TB applications is really challenging and how by using the beeswax better as a service it's really easy for customers",
    "start": "3045069",
    "end": "3050920"
  },
  {
    "text": "to build custom bidders on our platform use Kinesis as our infrastructure under",
    "start": "3050920",
    "end": "3056990"
  },
  {
    "text": "the hood for all our streaming data needs and in our application we solved",
    "start": "3056990",
    "end": "3062180"
  },
  {
    "text": "some of the key challenges that we faced and I discuss some of the trade-offs that we considered so one point I want",
    "start": "3062180",
    "end": "3069080"
  },
  {
    "text": "to make the final point here is that the beeswax platform is optimized for RTB all the decisions that we arrived at",
    "start": "3069080",
    "end": "3075560"
  },
  {
    "text": "after looking at the trade-offs were really with the with RTB in our mind and it's possible that based on your",
    "start": "3075560",
    "end": "3081400"
  },
  {
    "text": "application you might arrive at a different conclusions when you're looking at the same set of trade-offs",
    "start": "3081400",
    "end": "3086980"
  },
  {
    "text": "so that concludes my presentation thank you very much [Applause]",
    "start": "3086980",
    "end": "3099020"
  }
]
[
  {
    "text": "good afternoon everybody that's pretty loud is it too loud or is it",
    "start": "480",
    "end": "5640"
  },
  {
    "text": "good awesome my name is Miles Ward I'm a Solutions architect with Amazon web",
    "start": "5640",
    "end": "11719"
  },
  {
    "text": "services uh big fan of mongod DB uh if you are not interested in the mongod DB",
    "start": "11719",
    "end": "17359"
  },
  {
    "text": "this is the wrong room and you should bail because we're going to talk about that for about the next hour uh uh there",
    "start": "17359",
    "end": "23320"
  },
  {
    "text": "is plenty of chairs so if you want to say on the internet that I've heard of that this talk is going great uh or",
    "start": "23320",
    "end": "30160"
  },
  {
    "text": "that's it's going terrible just put that out there and we'll see if we can fill in the rest of the chairs because I think this is going to be a valuable uh",
    "start": "30160",
    "end": "36640"
  },
  {
    "text": "set of information also like to introduce Chris Chris boo mongod DB uh",
    "start": "36640",
    "end": "42480"
  },
  {
    "text": "principal technologist and technical director been working in databases for about 10 years and pedabytes just get me",
    "start": "42480",
    "end": "49680"
  },
  {
    "text": "jaed pedabytes sound good to me too so um without further Ado we just want we",
    "start": "49680",
    "end": "54719"
  },
  {
    "text": "want to run one little quick chunk of code so",
    "start": "54719",
    "end": "59800"
  },
  {
    "text": "so we'll kick it off and describe a little later exactly what we're doing",
    "start": "61920",
    "end": "67119"
  },
  {
    "text": "here those of you who know the terminology will also already be able to",
    "start": "67840",
    "end": "73880"
  },
  {
    "text": "guess so uh let's talk about first uh mongod DB on AWS best practices for that",
    "start": "73880",
    "end": "82479"
  },
  {
    "text": "uh so that maybe uh when you go home uh you can build something that's uh going to run quite as big as this uh I'll talk",
    "start": "82479",
    "end": "90439"
  },
  {
    "text": "through the current uh newest updated guidance about how to run at scale",
    "start": "90439",
    "end": "96320"
  },
  {
    "text": "uh how to deliver high performance to your customers uh and how to do that on AWS so um we've done a lot to try and",
    "start": "96320",
    "end": "104360"
  },
  {
    "text": "simplify this process we've published a white paper that describes all of this in long form English if you really like",
    "start": "104360",
    "end": "111560"
  },
  {
    "text": "papers uh and maybe have long international flights this is the way to go uh the white paper has been",
    "start": "111560",
    "end": "118960"
  },
  {
    "text": "summarized into a series of marketplace listings so how many folks familiar with",
    "start": "118960",
    "end": "125039"
  },
  {
    "text": "the AWS Marketplace awesome so in the marketplace without any kind of setup",
    "start": "125039",
    "end": "131640"
  },
  {
    "text": "work without any configuration changes you can launch aodb ec2 instance at a",
    "start": "131640",
    "end": "138400"
  },
  {
    "text": "thousand iops of performance 2,000 iops or 4,000 iops on a single node so that",
    "start": "138400",
    "end": "145120"
  },
  {
    "text": "gets you a pre-built pre-described 10 gen now DB Incorporated blessed uh",
    "start": "145120",
    "end": "152360"
  },
  {
    "text": "system that is ready to run production workloads except for that whole part where I said single node how many folks",
    "start": "152360",
    "end": "158440"
  },
  {
    "text": "in here love running mongod DB on just one computer there should be no hands no hands from you no that's the wrong",
    "start": "158440",
    "end": "165760"
  },
  {
    "text": "answer don't do that don't do that uh so uh the correct way to run mongodb as you",
    "start": "165760",
    "end": "171440"
  },
  {
    "text": "know is in a uh is in a clustered mode is in a sharded replica set node so uh",
    "start": "171440",
    "end": "177319"
  },
  {
    "text": "how would you do that how would you build up a system that allows you to take advantage not only of the",
    "start": "177319",
    "end": "183239"
  },
  {
    "text": "networking power and the performance of ec2 but also uh the provisioned iops volumes that are so critical to",
    "start": "183239",
    "end": "189920"
  },
  {
    "text": "consistent performance from mongodb so uh We've released a series of cloud",
    "start": "189920",
    "end": "196200"
  },
  {
    "text": "formation templates how many folks are using cloud formation today there should be way more people using cloud formation",
    "start": "196200",
    "end": "201879"
  },
  {
    "text": "than Marketplace I'm just throwing it out there as a personal value judgment so cloud formation gives you a way to",
    "start": "201879",
    "end": "208480"
  },
  {
    "text": "launch an a iic command one message that builds a cluster distributes ec2",
    "start": "208480",
    "end": "214760"
  },
  {
    "text": "instances configures their storage and in this template uh actually has a pair",
    "start": "214760",
    "end": "220319"
  },
  {
    "text": "of templates one that creates the storage and another that joins them together so cloud formation lets you",
    "start": "220319",
    "end": "226680"
  },
  {
    "text": "take the configuration decisions that you've made and reduce them to code so",
    "start": "226680",
    "end": "232239"
  },
  {
    "text": "they can go in your Source control your infrastructure should in fact really be artifacts in Source control rather than",
    "start": "232239",
    "end": "238680"
  },
  {
    "text": "wires and cables and stuff plugged in so we've also seen lots of different",
    "start": "238680",
    "end": "244879"
  },
  {
    "text": "implementations for mongodb on AWS uh we have several different block storage systems all of them expose different",
    "start": "244879",
    "end": "252360"
  },
  {
    "text": "kinds of performance I just got done about an hour and a half ago doing a detailed talk on EBS storage performance",
    "start": "252360",
    "end": "259320"
  },
  {
    "text": "o lookie we're building instances fulfillment all right so uh EBS",
    "start": "259320",
    "end": "266840"
  },
  {
    "text": "provisioned IO provides the most consistent storage performance for",
    "start": "266840",
    "end": "272199"
  },
  {
    "text": "structured data storage workloads uh EBS provision diaps is designed to provide within 10% of what you provision",
    "start": "272199",
    "end": "280160"
  },
  {
    "text": "99.9% of the time which is a lot of the time uh in comparison to standard EVS",
    "start": "280160",
    "end": "286000"
  },
  {
    "text": "that's like a rock so um provisioned iops EBS volumes also allow you to build",
    "start": "286000",
    "end": "291360"
  },
  {
    "text": "clusters Beyond just the iops performance of standard EBS they allow",
    "start": "291360",
    "end": "296520"
  },
  {
    "text": "you to go to 4,000 iops per dis and since you can have multiple EBS volumes",
    "start": "296520",
    "end": "301600"
  },
  {
    "text": "per host we have tests showing EBS performance per node in excess of 90,000",
    "start": "301600",
    "end": "308320"
  },
  {
    "text": "iops does anybody want their database to go slower oh stop it you don't so uh since",
    "start": "308320",
    "end": "317960"
  },
  {
    "text": "that's available uh we do and we have seen quite a few customers building large scale systems around the",
    "start": "317960",
    "end": "324120"
  },
  {
    "text": "combination of mongodb and provision IO we also see a lot of customers very",
    "start": "324120",
    "end": "329199"
  },
  {
    "text": "successful deploying mongodb on the high1 Forex large instances with local SSD uh the SSD instances work great in",
    "start": "329199",
    "end": "337560"
  },
  {
    "text": "combination as a part of a replica set system so uh I'll show an example of",
    "start": "337560",
    "end": "343520"
  },
  {
    "text": "what that looks like shortly uh standard EBS again is going to provide on the order of a couple of hundred Ops",
    "start": "343520",
    "end": "351199"
  },
  {
    "text": "with pretty high relatively High variability given the design of that system around larger block operations",
    "start": "351199",
    "end": "358479"
  },
  {
    "text": "provision doops volume targeted at smaller block operations at lower latency will deliver significantly",
    "start": "358479",
    "end": "365199"
  },
  {
    "text": "higher density that's not a typo going from 200 to 4,000 by changing one",
    "start": "365199",
    "end": "370319"
  },
  {
    "text": "configuration setting is a pretty important shift in the overall performance of a mongod DB",
    "start": "370319",
    "end": "376240"
  },
  {
    "text": "infrastructure and since you can use our cluster compute that's CC1 cc2 cg1 cr1",
    "start": "376240",
    "end": "383880"
  },
  {
    "text": "8xl high1 4XL hs1 8xl instances those",
    "start": "383880",
    "end": "389199"
  },
  {
    "text": "instan offer up to 800 megabytes not bits megabytes a second of throughput to",
    "start": "389199",
    "end": "396080"
  },
  {
    "text": "network to storage and there's a result you can get in excess of 880,000 iops",
    "start": "396080",
    "end": "401199"
  },
  {
    "text": "even 990,000 iops uh we printed 880,000 back when I hadn't done a couple more",
    "start": "401199",
    "end": "406639"
  },
  {
    "text": "tests so that's higher particularly it's higher on the right side than the SSD",
    "start": "406639",
    "end": "413280"
  },
  {
    "text": "based instances from AWS so at 880,000 right transactions per second uh in",
    "start": "413280",
    "end": "419960"
  },
  {
    "text": "mongodb you're able to do uh at a density on instances that's very different than uh than some other",
    "start": "419960",
    "end": "427280"
  },
  {
    "text": "designs so to compare the SSD devices to the storage service of ec2 and EBS",
    "start": "427280",
    "end": "434680"
  },
  {
    "text": "together using EBS optimized as a flag standard EBS provides lots and lots and",
    "start": "434680",
    "end": "441240"
  },
  {
    "text": "lots of variability in comparison to the relatively oo we're building even more",
    "start": "441240",
    "end": "447000"
  },
  {
    "text": "instances we are fulfilled o much of a filling so uh the uh the provision iops",
    "start": "447000",
    "end": "454520"
  },
  {
    "text": "is in the center column at uh less than really a tenth of a percent variability",
    "start": "454520",
    "end": "460160"
  },
  {
    "text": "uh and the SSD instances on the right hand side while very very fast very high density if you're going to build a high",
    "start": "460160",
    "end": "466680"
  },
  {
    "text": "scale system that's a useful tool to use but they also show in the order of five",
    "start": "466680",
    "end": "471840"
  },
  {
    "text": "and 10% variability on rights to disk so if the transactions you do in mongod DB",
    "start": "471840",
    "end": "479120"
  },
  {
    "text": "if each individual event is something that an End customer experiences it can make a lot of sense",
    "start": "479120",
    "end": "485199"
  },
  {
    "text": "to have each one of those Rights happen at a uniform latency so that you have a uniform good experience for customers",
    "start": "485199",
    "end": "491520"
  },
  {
    "text": "provision iops helps with that as well as you're building uh uh E2 systems for",
    "start": "491520",
    "end": "497840"
  },
  {
    "text": "mongodb certainly recommend the use of either ext4 or xfs uh turning off the",
    "start": "497840",
    "end": "503840"
  },
  {
    "text": "file system flags that don't add value for no SQL Data Systems like no dur time and no a Time",
    "start": "503840",
    "end": "510680"
  },
  {
    "text": "raising the file descriptor limits so that there's enough access to memory and uh uh storage utilities you also want to",
    "start": "510680",
    "end": "517479"
  },
  {
    "text": "set the rate sorry set the disc read ahead high enough or sorry low enough uh",
    "start": "517479",
    "end": "523039"
  },
  {
    "text": "down typically to 16k uh in order to eliminate overc consumption of",
    "start": "523039",
    "end": "528120"
  },
  {
    "text": "provisioned iops throttled storage uh you also don't want to have uh large",
    "start": "528120",
    "end": "533800"
  },
  {
    "text": "virtual memory Pages that's a problem and it's not a typo and the italics are not for joking you do need to snapshot",
    "start": "533800",
    "end": "541200"
  },
  {
    "text": "volumes I promise it's a great idea backups are awesome so uh that process",
    "start": "541200",
    "end": "547720"
  },
  {
    "text": "also interestingly increases the durability of EBS the more often you snapshot the less often you'll need the",
    "start": "547720",
    "end": "554720"
  },
  {
    "text": "snapshots how weird is that so uh for the maximum scale production workloads",
    "start": "554720",
    "end": "560880"
  },
  {
    "text": "that we're seeing uh that are sort of standard topologies let's call it uh",
    "start": "560880",
    "end": "566320"
  },
  {
    "text": "you're typically seeing SSD instances used as two out of the three of a replica set so this can be multiplied by",
    "start": "566320",
    "end": "575360"
  },
  {
    "text": "way of sharding to dozens and dozens and dozens of machines we have customers that are operating today on AWS at Peta",
    "start": "575360",
    "end": "583320"
  },
  {
    "text": "scale which is pretty outstanding if you think about that the component of provisioned iops in this pattern is",
    "start": "583320",
    "end": "591279"
  },
  {
    "text": "there so that when you run a cluster of this size you still have the ability to snapshot to S3 having your data at 11",
    "start": "591279",
    "end": "598600"
  },
  {
    "text": "nines of durab ility is good news you should like it so um snapshots also now",
    "start": "598600",
    "end": "605760"
  },
  {
    "text": "allow cross Regional migration so you can take the data that you have in Us East and ship it over to Singapore just",
    "start": "605760",
    "end": "613160"
  },
  {
    "text": "because it seems like a fun idea so uh on top of again this replicated pattern",
    "start": "613160",
    "end": "619680"
  },
  {
    "text": "you would charge for additional read or write performance for scale so another",
    "start": "619680",
    "end": "625440"
  },
  {
    "text": "option another area U most of the work and optimization around most",
    "start": "625440",
    "end": "630480"
  },
  {
    "text": "workloads focuses on the storage component U because most users tend to",
    "start": "630480",
    "end": "636399"
  },
  {
    "text": "run in a let's call it a lean design where you've rapidly overloaded the",
    "start": "636399",
    "end": "641839"
  },
  {
    "text": "memory available on the instance that's because memory is pretty expensive in comparison to",
    "start": "641839",
    "end": "647279"
  },
  {
    "text": "storage in contrast to that the cr1 instance at 244 gigs of RAM lets you",
    "start": "647279",
    "end": "654440"
  },
  {
    "text": "build clusters where you can easily get to terabytes of data in memory which offers a totally different performance",
    "start": "654440",
    "end": "661000"
  },
  {
    "text": "characteristic in comparison to interaction with any kind of storage no matter how Snappy that storage is so",
    "start": "661000",
    "end": "666959"
  },
  {
    "text": "strongly recommend if you're looking at workloads where again every transaction is interacting with an end user U",
    "start": "666959",
    "end": "673720"
  },
  {
    "text": "is strongly designed around the context of memory resident data uh and uh and",
    "start": "673720",
    "end": "679399"
  },
  {
    "text": "the cr1 instances are offering a kind of performance that's totally totally",
    "start": "679399",
    "end": "684639"
  },
  {
    "text": "unreasonable in comparison to other ways of doing the job so with that I'd like to introduce Chris uh Chris is uh",
    "start": "684639",
    "end": "691959"
  },
  {
    "text": "helping us build some pretty interesting systems uh on E2 and",
    "start": "691959",
    "end": "697720"
  },
  {
    "text": "mongodb Miles thank",
    "start": "697720",
    "end": "701319"
  },
  {
    "text": "you so this came up uh about six months",
    "start": "703320",
    "end": "708519"
  },
  {
    "text": "ago uh shortly after I joined mongodb wanting to bring things up to a",
    "start": "708519",
    "end": "714760"
  },
  {
    "text": "higher level of scalability uh and the idea which I",
    "start": "714760",
    "end": "720279"
  },
  {
    "text": "believe you termed red was to initially",
    "start": "720279",
    "end": "725399"
  },
  {
    "text": "take uh a fairly inexpensive approach using the spot market I'll go into some detail on what the spot Market is but",
    "start": "725399",
    "end": "732279"
  },
  {
    "text": "using the smallest real instances where you have uh reliable access to some",
    "start": "732279",
    "end": "737959"
  },
  {
    "text": "cores the M1 Smalls doing that over oh I don't know how are you going to divide up a petabyte one out a th shards uh one",
    "start": "737959",
    "end": "745680"
  },
  {
    "text": "out a terabyte of each uh on each shard that would equal a p a",
    "start": "745680",
    "end": "751199"
  },
  {
    "text": "petabyte uh a reader to test the query capability based on power",
    "start": "751199",
    "end": "757440"
  },
  {
    "text": "bench and this shows some aggregation queries what what we could do uh one of the sweet spots for mongod DB is the",
    "start": "757440",
    "end": "764399"
  },
  {
    "text": "ability to use secondary indexes to provide fast typically second or so",
    "start": "764399",
    "end": "769880"
  },
  {
    "text": "response to the end user to the application uh where and this is key uh",
    "start": "769880",
    "end": "776720"
  },
  {
    "text": "miles was talking about you're looking with conod DB generally for your working set to fit in Ram this doesn't mean the",
    "start": "776720",
    "end": "783440"
  },
  {
    "text": "entire database fits in Ram obviously we don't have a terabyte of ram per M1 small we have 1.7 gbt so we choose",
    "start": "783440",
    "end": "790959"
  },
  {
    "text": "something where that aperture about 1.7 gabt would describe what needs to be in",
    "start": "790959",
    "end": "797480"
  },
  {
    "text": "memory and then as many as the py Ops will uh uh deliver well get to that in a",
    "start": "797480",
    "end": "802959"
  },
  {
    "text": "minute as many as a local disc will deliver in this case within about a second for anything that's not already",
    "start": "802959",
    "end": "808480"
  },
  {
    "text": "available out of of indexes uh developed that a little bit and Miles",
    "start": "808480",
    "end": "816959"
  },
  {
    "text": "uh went to some of his people who wanted to show what PS could do since my idea was primarily based on doing things",
    "start": "816959",
    "end": "823720"
  },
  {
    "text": "inexpensively quantify that in a minute and mil said well if if we give you some",
    "start": "823720",
    "end": "828839"
  },
  {
    "text": "py Ops what if you use larger machines probably not so quite so many of them uh",
    "start": "828839",
    "end": "834240"
  },
  {
    "text": "we finally wound up with a formula of 44 instances of the CC 28x large 60 GB of",
    "start": "834240",
    "end": "842880"
  },
  {
    "text": "RAM uh and very importantly as we're trying to uh load quickly 10 gbits per",
    "start": "842880",
    "end": "850440"
  },
  {
    "text": "second interconnectivity uh if you put them in a single group on each of these instances then uh",
    "start": "850440",
    "end": "857800"
  },
  {
    "text": "there would be 24 1 terabyte mounts uh 1,000 Pi Ops per and in this",
    "start": "857800",
    "end": "865720"
  },
  {
    "text": "case we were using ycsb the Yahoo cloud serving Benchmark as our data source uh",
    "start": "865720",
    "end": "872839"
  },
  {
    "text": "difference between the two I'll get to later power bench scales out better I wouldn't want to try use ycsb across a",
    "start": "872839",
    "end": "879199"
  },
  {
    "text": "thousand nodes and again some sort of an aggregation query payload uh this has to be uh this this",
    "start": "879199",
    "end": "887199"
  },
  {
    "text": "talk I'm giving had to go through uh an editor here one of their primary functions is to be trademark police so",
    "start": "887199",
    "end": "894440"
  },
  {
    "text": "if I uh simplify or change any of the key Amazon prod product terms I I want",
    "start": "894440",
    "end": "900120"
  },
  {
    "text": "to credit it so uh py Ops are short for provisioned iops uh ec2 short for",
    "start": "900120",
    "end": "907120"
  },
  {
    "text": "Amazon's elastic compute cloud and spot instances uh we'll get to uh sentiment",
    "start": "907120",
    "end": "912720"
  },
  {
    "text": "and spot instances later but we'll just call them spots uh autoscaling groups are going to be one of the key",
    "start": "912720",
    "end": "918440"
  },
  {
    "text": "capabilities in fact it's what I was just showing you there if you watched as it uh went by quickly we'll go over it uh more slowly uh those are a good way",
    "start": "918440",
    "end": "927040"
  },
  {
    "text": "not only of as it would apply automatically scaling the size of a group but also just instantiating a",
    "start": "927040",
    "end": "932920"
  },
  {
    "text": "group and push to the cloud the management of that",
    "start": "932920",
    "end": "937720"
  },
  {
    "text": "group so I'm going to back up a little bit and talk about why miles and I are",
    "start": "938920",
    "end": "944360"
  },
  {
    "text": "up here on stage together uh there's quite a uh",
    "start": "944360",
    "end": "949639"
  },
  {
    "text": "complementarity or Synergy between mongod DB and AWS uh mongodb itself for those who may",
    "start": "949639",
    "end": "956880"
  },
  {
    "text": "not be familiar with it is a a document model database within the overall nosql",
    "start": "956880",
    "end": "963360"
  },
  {
    "text": "database movement uh key for us is developer adoption our core strategy has since",
    "start": "963360",
    "end": "971800"
  },
  {
    "text": "Inception of the company been adoption over trying to for example go after",
    "start": "971800",
    "end": "976920"
  },
  {
    "text": "revenue and going that and doing that through developers we're complimentary AWS",
    "start": "976920",
    "end": "983959"
  },
  {
    "text": "because one of the things we don't want as uh at least traditionally a fairly lean startup and we're still going to",
    "start": "983959",
    "end": "989800"
  },
  {
    "text": "run lean after getting a large funding round is we actually own next to no",
    "start": "989800",
    "end": "995440"
  },
  {
    "text": "Hardware uh we almost everything that we do internally is hosted on",
    "start": "995440",
    "end": "1002519"
  },
  {
    "text": "AWS like other nosql databases we take an approach of scaling up with uh",
    "start": "1002519",
    "end": "1008040"
  },
  {
    "text": "commodity Hardware as far as the power performance price point makes sense and",
    "start": "1008040",
    "end": "1013959"
  },
  {
    "text": "then scaling out using multiple shards to keep that at a reasonable price point",
    "start": "1013959",
    "end": "1020199"
  },
  {
    "text": "uh additionally what I'll call scale around is the ability to use replication not shown here because we were simply",
    "start": "1020199",
    "end": "1025839"
  },
  {
    "text": "going for that scale out uh there's absolutely no replication no high availability in what I'm standing up",
    "start": "1025839",
    "end": "1030880"
  },
  {
    "text": "here because the purpose of this was to sort of stress those uh those limits um",
    "start": "1030880",
    "end": "1036959"
  },
  {
    "text": "go back one second uh there's a lot of hype about many of these new",
    "start": "1036959",
    "end": "1042720"
  },
  {
    "text": "technologies uh that have changed our world the last five years no SQL and Hadoop uh it",
    "start": "1042720",
    "end": "1050440"
  },
  {
    "text": "both what's interesting is that although you'll see the balance of the hype",
    "start": "1050440",
    "end": "1055760"
  },
  {
    "text": "particularly from the analysts on the Hadoop side the developer activity shows",
    "start": "1055760",
    "end": "1061919"
  },
  {
    "text": "something that's much more evenly balanced uh just to Google terms you see",
    "start": "1061919",
    "end": "1067600"
  },
  {
    "text": "mongodb uh trailing by all of a few months the increased curve of uh Hadoop",
    "start": "1067600",
    "end": "1074600"
  },
  {
    "text": "and if you look at what developers are actually doing and maybe we have an unfair advantage here that we have a",
    "start": "1074600",
    "end": "1079720"
  },
  {
    "text": "developer first strategy developers appear to be spending more of their time producing",
    "start": "1079720",
    "end": "1086159"
  },
  {
    "text": "more of their applications and I don't have a way to prove this but I think driving more business value than they're actually doing with to do so we won't",
    "start": "1086159",
    "end": "1093360"
  },
  {
    "text": "compete on the hype uh we definitely will compete for your",
    "start": "1093360",
    "end": "1098158"
  },
  {
    "text": "time py Ops are key I think for almost any database that you would want to run",
    "start": "1099360",
    "end": "1105039"
  },
  {
    "text": "on the cloud uh as a general rule the database world is rather queasy about",
    "start": "1105039",
    "end": "1110919"
  },
  {
    "text": "shared storage it usually doesn't work out well it's usually over-provisioned",
    "start": "1110919",
    "end": "1116400"
  },
  {
    "text": "and the economic model behind it usually creates a tragedy of the commons where",
    "start": "1116400",
    "end": "1121799"
  },
  {
    "text": "uh well actually recent uh major news story has as one of its elements a badly",
    "start": "1121799",
    "end": "1127159"
  },
  {
    "text": "over-provisioned back-end storage system py Ops get you away from any concern",
    "start": "1127159",
    "end": "1132919"
  },
  {
    "text": "with that and a lot of applications don't need them if you're running a mail server with the occasional spiky load uh",
    "start": "1132919",
    "end": "1139280"
  },
  {
    "text": "that Commons with uh the storage a little bit over subscribed works well you don't want to pay for py Ops and if you don't want to don't cuz piy Ops are",
    "start": "1139280",
    "end": "1146000"
  },
  {
    "text": "expensive but when you're running a high performance database you're typically going to be limited by IO you're",
    "start": "1146000",
    "end": "1151840"
  },
  {
    "text": "certainly going to be on right and depending upon read uh if you're doing scattered reads almost all databases are",
    "start": "1151840",
    "end": "1158440"
  },
  {
    "text": "going to line up the same way there uh you're going to be limited by your IO so",
    "start": "1158440",
    "end": "1164240"
  },
  {
    "text": "I I'm not sure which was chicken and egg between AWS and ourselves on P s but the",
    "start": "1164240",
    "end": "1169840"
  },
  {
    "text": "two were basically built for each other uh to this day about 40% of all mongodb",
    "start": "1169840",
    "end": "1176480"
  },
  {
    "text": "customer usage is on AWS internally I said we have next to no Hardware uh",
    "start": "1176480",
    "end": "1182200"
  },
  {
    "text": "about 90% of our usage is on AWS and if you were to scan the ports",
    "start": "1182200",
    "end": "1189280"
  },
  {
    "text": "within AWS Maybe by accident uh you'd actually find that there are more mongodb ports open than Oracle ports",
    "start": "1189280",
    "end": "1198280"
  },
  {
    "text": "it's that prevalent the two really fit together it's peanut butter and chocolate differentiators why why does",
    "start": "1198280",
    "end": "1205400"
  },
  {
    "text": "this make so much sense how is the adoption followed so far uh both of them",
    "start": "1205400",
    "end": "1210760"
  },
  {
    "text": "provide fast time to solution you've got the ability with a document database model that scales well scales up as much",
    "start": "1210760",
    "end": "1217960"
  },
  {
    "text": "as you to the uh cost level that makes sense there scales out well you can get to your Solutions fast I would urge",
    "start": "1217960",
    "end": "1225360"
  },
  {
    "text": "everybody not too fast one of the hazards of a developer adoption model is",
    "start": "1225360",
    "end": "1231120"
  },
  {
    "text": "uh standard anecdote developer been stuck for six months trying to solve a problem on a relational database reads",
    "start": "1231120",
    "end": "1238039"
  },
  {
    "text": "something on stack Overflow tries mongod DB half an hour later maybe pass that",
    "start": "1238039",
    "end": "1243200"
  },
  {
    "text": "problem what scares me is going to production the next day it's still a database still requires some discipline",
    "start": "1243200",
    "end": "1250280"
  },
  {
    "text": "uh and that's often where we come in so with that caveat don't go too fast with the two you can get to your solution",
    "start": "1250280",
    "end": "1256200"
  },
  {
    "text": "very fast you're not waiting for Hardware you're not waiting for software and you've got a type of database that solves some problems that have",
    "start": "1256200",
    "end": "1262280"
  },
  {
    "text": "traditionally been very difficult uh you can easily distribute",
    "start": "1262280",
    "end": "1267320"
  },
  {
    "text": "your data globally on both sides with the replication uh within mongodb and",
    "start": "1267320",
    "end": "1274000"
  },
  {
    "text": "using the various uh regions careful not to say zones the various regions of AWS",
    "start": "1274000",
    "end": "1280480"
  },
  {
    "text": "the two of those fit together very nicely with respect to IO patterns Etc",
    "start": "1280480",
    "end": "1285600"
  },
  {
    "text": "the document model allows the freedom to get away from problems that have traditionally been difficult using the",
    "start": "1285600",
    "end": "1294080"
  },
  {
    "text": "relational model the tables and columns if you find yourself doing violence to your data to squeeze them into table and",
    "start": "1294080",
    "end": "1300400"
  },
  {
    "text": "columns you're probably using the wrong type of database certainly there are application domains where relational",
    "start": "1300400",
    "end": "1306039"
  },
  {
    "text": "databases make sense but when you're spending most of your time messing with your schema afraid to make changes",
    "start": "1306039",
    "end": "1311880"
  },
  {
    "text": "because they'll destroy the schema and cause you to re-engineer that's where the document uh model database fits",
    "start": "1311880",
    "end": "1318080"
  },
  {
    "text": "mongod B uh in addition to our core strategy uh our differentiators technically are the use of secondary",
    "start": "1318080",
    "end": "1324520"
  },
  {
    "text": "indexes to provide subsec response to the m user and this extends to",
    "start": "1324520",
    "end": "1330120"
  },
  {
    "text": "geospatial indexes text indexes and a very granular type of security that uh",
    "start": "1330120",
    "end": "1337640"
  },
  {
    "text": "the US Department of Defense and intelligence Community has pushed us toward where within a document you want",
    "start": "1337640",
    "end": "1343120"
  },
  {
    "text": "to be able to determine who can see what when and have levers to turn that on and off",
    "start": "1343120",
    "end": "1348919"
  },
  {
    "text": "finally in the package is the ability to do analytics there's a dividing line here there are analytics you're going to",
    "start": "1348919",
    "end": "1354760"
  },
  {
    "text": "run with had doop if they're not going to benefit from indexes if you're going to be scanning your full data anyway if",
    "start": "1354760",
    "end": "1360640"
  },
  {
    "text": "they're going to run overnight anyway that's probably the realm of Hadoop but we're going to put as much as we can and",
    "start": "1360640",
    "end": "1366720"
  },
  {
    "text": "progressively with our road map over future versions into that subse realm deliverable to the end user the online",
    "start": "1366720",
    "end": "1373600"
  },
  {
    "text": "the operational database versus the offline analytic so where this whole",
    "start": "1373600",
    "end": "1379360"
  },
  {
    "text": "conversation started with Miles and myself it would be cool if we could",
    "start": "1379360",
    "end": "1384400"
  },
  {
    "text": "really test the uh scale out of mongodb uh we we we tend to drive",
    "start": "1384400",
    "end": "1390400"
  },
  {
    "text": "ourselves what we do internally based on what our customers do and we have customers in this realm the problem is",
    "start": "1390400",
    "end": "1396880"
  },
  {
    "text": "they generally don't talk to us won't tell us what they're doing until they have a problem and then they still sometimes won't tell us what they're",
    "start": "1396880",
    "end": "1402880"
  },
  {
    "text": "doing so I wanted to have a tool where we could quickly say okay we'll stand up a petabyte database uh customer case",
    "start": "1402880",
    "end": "1409159"
  },
  {
    "text": "would have to justify it but that happens wanted to learn to do that specifically on AWS given that it can be",
    "start": "1409159",
    "end": "1415640"
  },
  {
    "text": "done economically I'll quantify that in a minute uh and also uh wanted to build",
    "start": "1415640",
    "end": "1421679"
  },
  {
    "text": "this on some customer data we're still working on that this is a a project in progress and you'll see updates I'll",
    "start": "1421679",
    "end": "1428640"
  },
  {
    "text": "tweet them as they come along as we apply this to something other than the sythetic documents of Yahoo Cloud",
    "start": "1428640",
    "end": "1434720"
  },
  {
    "text": "serving Benchmark and then finally wanted to get past that P petabyte barrier so the inexpensive approach is",
    "start": "1434720",
    "end": "1442760"
  },
  {
    "text": "to use these spot instances this is a quick look across all of us East one all",
    "start": "1442760",
    "end": "1449360"
  },
  {
    "text": "of the zones in that region at the spot Market over a period of several days uh",
    "start": "1449360",
    "end": "1456720"
  },
  {
    "text": "you'll notice our Us East 1B won't be your 1B you may have a 1A we don't this",
    "start": "1456720",
    "end": "1461960"
  },
  {
    "text": "varies by account the actual uh zones are randomized over accounts but for the",
    "start": "1461960",
    "end": "1467480"
  },
  {
    "text": "three that are has access to uh well pretty quick look at this doesn't look like we want to compete in 1B the scale",
    "start": "1467480",
    "end": "1474799"
  },
  {
    "text": "here is a little hard to see but uh you're you're looking at people who are bidding don't ask me why $5 per hour for",
    "start": "1474799",
    "end": "1482080"
  },
  {
    "text": "these spot instances the Baseline down there at the bottom is seven Mills",
    "start": "1482080",
    "end": "1487360"
  },
  {
    "text": "7/10ths of a cent per hour and in fact outside of 1B during this particular week uh you were going to pretty much be",
    "start": "1487360",
    "end": "1494520"
  },
  {
    "text": "paying 7 Ms per hour per spot instance as a you had the sity to stay out of",
    "start": "1494520",
    "end": "1499799"
  },
  {
    "text": "East 1B now this is the way it looked a few months ago uh coming up on AWS yeah",
    "start": "1499799",
    "end": "1505200"
  },
  {
    "text": "the market heats up a bit so we picked the 1D market and drill in on that a",
    "start": "1505200",
    "end": "1510520"
  },
  {
    "text": "little bit now the scale is not so expanded here that little blip you see at 2 cents versus 7/10 of a cent uh",
    "start": "1510520",
    "end": "1518240"
  },
  {
    "text": "don't confuse that with the order of magnitude we had in the previous graph so yeah if we're in 1D and we don't",
    "start": "1518240",
    "end": "1524080"
  },
  {
    "text": "really mind occasionally losing our instances and if one of these runs doesn't work right other than the one that I just did in front of you which I",
    "start": "1524080",
    "end": "1529799"
  },
  {
    "text": "didn't want to lose uh yeah I just run it again so we're actually going to be able",
    "start": "1529799",
    "end": "1536080"
  },
  {
    "text": "to rent instances at 7 Ms per hour uh that's a kilos Shard for $7 an",
    "start": "1536080",
    "end": "1543760"
  },
  {
    "text": "hour that's the proposal so uh wanted to see how cheaply I could do this and got",
    "start": "1543760",
    "end": "1549159"
  },
  {
    "text": "it notionally under $200 uh we're going to need a few extras some of these instances will be",
    "start": "1549159",
    "end": "1555399"
  },
  {
    "text": "stillborn some of them May respond slowly over n working and uh if you look at the run I just did actually I don't",
    "start": "1555399",
    "end": "1562360"
  },
  {
    "text": "know if we rejected any some of the runs I I just reject some because they're responding a little too slowly not sure why so we'll start actually 1050 to get",
    "start": "1562360",
    "end": "1569880"
  },
  {
    "text": "a full 1024 kilos Shard uh the configuration servers which I'll explain",
    "start": "1569880",
    "end": "1575039"
  },
  {
    "text": "in a moment I'm going to use three of those and I don't want them to be bottlenecks since they're metadata for the entire cluster I'll run them on M1",
    "start": "1575039",
    "end": "1581240"
  },
  {
    "text": "larges keep them up for a couple of days while I'm messing around uh we'll put our terabyte out as a snapshot on",
    "start": "1581240",
    "end": "1588840"
  },
  {
    "text": "S3 and then make 1,024 copies of it on",
    "start": "1588840",
    "end": "1594559"
  },
  {
    "text": "EBS uh this after all is a test database uh and as yet we're not running this on",
    "start": "1594559",
    "end": "1600159"
  },
  {
    "text": "real customer data and one ycsb document is about as pretty as the next so this is reasonable for the purpose that we're",
    "start": "1600159",
    "end": "1606399"
  },
  {
    "text": "trying to do here now are we really moving a full petabyte around uh actually not this is optimized",
    "start": "1606399",
    "end": "1614640"
  },
  {
    "text": "out by the way AWS lazily provisions the elastic block storage from the S3",
    "start": "1614640",
    "end": "1622159"
  },
  {
    "text": "snapshot uh it looks to us like a somewhat slower read anytime we pull a",
    "start": "1622159",
    "end": "1628279"
  },
  {
    "text": "block off of disc that hasn't uh already made it over to the EBS side but within an hour Run for the types of queries",
    "start": "1628279",
    "end": "1635000"
  },
  {
    "text": "that we're doing it actually looks to mongodb to all those shards as if they",
    "start": "1635000",
    "end": "1640600"
  },
  {
    "text": "have that full petabyte even though they'll never entirely pull it across during that hour before they shut down",
    "start": "1640600",
    "end": "1647440"
  },
  {
    "text": "and does a good job of simulation with the occasional slow iio uh cost to move it to EBS actually",
    "start": "1647440",
    "end": "1654919"
  },
  {
    "text": "is zero as long as you do it within the same region so started off on this uh trying",
    "start": "1654919",
    "end": "1662760"
  },
  {
    "text": "to realize the cool um learning about the M1 small Market uh mostly stayed in",
    "start": "1662760",
    "end": "1669559"
  },
  {
    "text": "the zone I just showed you our Zone D of us uh East one and basically had I've",
    "start": "1669559",
    "end": "1676000"
  },
  {
    "text": "got many hours now of running killer instances at $7 an hour that fits nicely",
    "start": "1676000",
    "end": "1681760"
  },
  {
    "text": "on the budget uh I'm particularly when I'm dealing with unknowns I like to hack",
    "start": "1681760",
    "end": "1687679"
  },
  {
    "text": "about in Pearl because it's got the clumsy someone aged language in some respects but also has the Swiss army",
    "start": "1687679",
    "end": "1694039"
  },
  {
    "text": "knife for absolutely everything particularly if you have to go parse random stuff you weren't expecting uh started out with the net",
    "start": "1694039",
    "end": "1701559"
  },
  {
    "text": "Amazon ec2 package uh learned better I'll go into that in a minute and then",
    "start": "1701559",
    "end": "1706760"
  },
  {
    "text": "where that package didn't cover some of the things I wanted to do just went to the ec2 command line and parsed the",
    "start": "1706760",
    "end": "1712760"
  },
  {
    "text": "responses did not initially start with anything on the level of Chef or puppet",
    "start": "1712760",
    "end": "1718440"
  },
  {
    "text": "or cloud formation because I knew I was going into uh an attempt to just scale out sacrifice High availability or",
    "start": "1718440",
    "end": "1726039"
  },
  {
    "text": "reliability for that horizontal scale shows ycsb because it's actually a",
    "start": "1726039",
    "end": "1731679"
  },
  {
    "text": "terrible Benchmark for document database uh it's it's a bunch of random noise fields and uh primary ID really meant",
    "start": "1731679",
    "end": "1739200"
  },
  {
    "text": "for key value databases but it's sort of the only game in town nobody's standardized on anything else and at a",
    "start": "1739200",
    "end": "1746080"
  },
  {
    "text": "certain level for the purposes I had bytes is bytes modified ycsb just a little bit to add some numeric Fields so",
    "start": "1746080",
    "end": "1751840"
  },
  {
    "text": "we could do aggregations on those uh userd dat. sh is a script that",
    "start": "1751840",
    "end": "1758640"
  },
  {
    "text": "you can hand to the instance that you launch on AWS uh at least with the Amazon Linux uh and and iunu I believe",
    "start": "1758640",
    "end": "1766880"
  },
  {
    "text": "very handy and something learned as I did this push as much of the processing you can to this Mega cluster You're",
    "start": "1766880",
    "end": "1773840"
  },
  {
    "text": "Building let those instances do the work for you as much as possible and then check",
    "start": "1773840",
    "end": "1779600"
  },
  {
    "text": "in uh looked across the options T1 micro",
    "start": "1779600",
    "end": "1784640"
  },
  {
    "text": "uh some previous work I had done micro instances are great uh matter of fact there is a little old uh server called",
    "start": "1784640",
    "end": "1791519"
  },
  {
    "text": "SMTP b.org that handles my personal email and my wife's gardening business",
    "start": "1791519",
    "end": "1798159"
  },
  {
    "text": "website just fine on micro but when you're doing something that is IO and CPU intensive micro instances not so",
    "start": "1798159",
    "end": "1805720"
  },
  {
    "text": "good uh you notionally have a couple of cores you use them for a few seconds and they go away for a while so the M1",
    "start": "1805720",
    "end": "1811919"
  },
  {
    "text": "Smalls were really The Sweet Spot for this purpose talk about how mongod DB itself",
    "start": "1811919",
    "end": "1818399"
  },
  {
    "text": "is put together I'm not going to go into a lot of detail but just try to explain what I was showing uh when you have a",
    "start": "1818399",
    "end": "1824080"
  },
  {
    "text": "mongod DB sharded cluster there are by uh in a production environment three",
    "start": "1824080",
    "end": "1830200"
  },
  {
    "text": "configuration servers the one thing that mongodb does in a two-phase commit fully",
    "start": "1830200",
    "end": "1836440"
  },
  {
    "text": "transactional cross document basis has managed its database that's done among the three configuration",
    "start": "1836440",
    "end": "1842559"
  },
  {
    "text": "servers uh the second type of server is called s uh s for charting or",
    "start": "1842559",
    "end": "1848360"
  },
  {
    "text": "routing that points to the configuration database on the A and C configuration",
    "start": "1848360",
    "end": "1853799"
  },
  {
    "text": "servers and also routes across the various shards",
    "start": "1853799",
    "end": "1858880"
  },
  {
    "text": "replica sets are the dimension of mongod DB that allows you to go to High",
    "start": "1858880",
    "end": "1864360"
  },
  {
    "text": "availability I've already said that was not a goal here someday I'd like to do uh actually probably two or three",
    "start": "1864360",
    "end": "1870000"
  },
  {
    "text": "pedabytes with high availability that's not something I'm doing right now but it is a core dimension in a production",
    "start": "1870000",
    "end": "1875240"
  },
  {
    "text": "mongodb system you're going to be using replica sets uh shards are the scale out",
    "start": "1875240",
    "end": "1881200"
  },
  {
    "text": "Dimension each Shard and in some cases you'll have multiple shards per server we did this on the high-end approach the",
    "start": "1881200",
    "end": "1887559"
  },
  {
    "text": "V fast uh each of those is served by a single mongod D process it's a a demon",
    "start": "1887559",
    "end": "1894440"
  },
  {
    "text": "the s's then learn which of the mongod Demons which of the shards have",
    "start": "1894440",
    "end": "1899919"
  },
  {
    "text": "which data I'll explore that a little bit later and Route the queries appropriately for client load uh running",
    "start": "1899919",
    "end": "1907480"
  },
  {
    "text": "ycsb is about as simple as you see there except for many lines of class path just like any decent Java system",
    "start": "1907480",
    "end": "1915960"
  },
  {
    "text": "today so here's a pictorial of uh what a mongodb sharted cluster looks like your",
    "start": "1916279",
    "end": "1922399"
  },
  {
    "text": "three configuration servers there on the right uh n number of routers uh up on",
    "start": "1922399",
    "end": "1928039"
  },
  {
    "text": "top those are the S's and N number of shards at the",
    "start": "1928039",
    "end": "1933919"
  },
  {
    "text": "bottom the default type of uh sharding approach used by mongod DB is to do it",
    "start": "1936880",
    "end": "1943720"
  },
  {
    "text": "based upon range this works very well for certain patterns uh I'm not going to",
    "start": "1943720",
    "end": "1948880"
  },
  {
    "text": "go into picking A Shard key here it's one of the most key decisions you make when you use mongodb because it allows",
    "start": "1948880",
    "end": "1955600"
  },
  {
    "text": "you to have your queries Focus only on certain chards uh example would be a",
    "start": "1955600",
    "end": "1961840"
  },
  {
    "text": "twitter-like system we have a number of large companies building their internal twitter- like systems on us you have",
    "start": "1961840",
    "end": "1967559"
  },
  {
    "text": "lots of choices there about how you do fan out on read fan out on write we actually have a benchmark uh in work to",
    "start": "1967559",
    "end": "1974200"
  },
  {
    "text": "help our customers make those decisions uh this is where where you would use range based charting and make it",
    "start": "1974200",
    "end": "1980159"
  },
  {
    "text": "something intelligent so I can say oh this is user X User X everything that I'm going to need to respond to their",
    "start": "1980159",
    "end": "1986559"
  },
  {
    "text": "query is over here on this chard the other approach and the one that I used largely for Simplicity is",
    "start": "1986559",
    "end": "1992960"
  },
  {
    "text": "Hash based charting hash based sharding forfeits the option of concentrating a",
    "start": "1992960",
    "end": "1999039"
  },
  {
    "text": "given query only on one or a few shards in fact it just about guarantees that any query will be flooded to all the",
    "start": "1999039",
    "end": "2005320"
  },
  {
    "text": "shards but for the purposes that I'm using here this is adequate uh and the great thing about it is it also floods",
    "start": "2005320",
    "end": "2011960"
  },
  {
    "text": "all your rights uh so that we can get to that petabyte in a reasonable amount of time it ensures essentially Fair random",
    "start": "2011960",
    "end": "2018399"
  },
  {
    "text": "distribution so here we're taking a primary ID uh uh mongodb that's always",
    "start": "2018399",
    "end": "2024240"
  },
  {
    "text": "under bar ID and we are hashing it and then Distributing it among a certain number of chunks I'll show you what a",
    "start": "2024240",
    "end": "2031000"
  },
  {
    "text": "chunk table looks like later based on what I just ran so the process of building this whole",
    "start": "2031000",
    "end": "2037960"
  },
  {
    "text": "system up using the spot instances looks like this you start out with a spot instance request and based upon the",
    "start": "2037960",
    "end": "2045159"
  },
  {
    "text": "price you bid against that market you may get any of these results it may out and out get rejected go home bid more",
    "start": "2045159",
    "end": "2052240"
  },
  {
    "text": "not going to happen this weekend uh it will spend a certain amount of time awaiting a valuation prior to being",
    "start": "2052240",
    "end": "2058079"
  },
  {
    "text": "rejected or not there's then after being accepted some time awaiting fulfillment",
    "start": "2058079",
    "end": "2063358"
  },
  {
    "text": "uh the Fulfillment may be partial and there are discret launch intervals again not going to go into a lot of complexity about how the spot Market is handled",
    "start": "2063359",
    "end": "2070079"
  },
  {
    "text": "you'll find both official pronouncements by Amazon and a lot of reverse engineering uh trying to understand what",
    "start": "2070079",
    "end": "2075480"
  },
  {
    "text": "happens but at the level we're talking here it tends to come in bursts and you'll see that on the run I just did as",
    "start": "2075480",
    "end": "2080679"
  },
  {
    "text": "we look through it and then finally fulfillment ah now we have our",
    "start": "2080679",
    "end": "2086520"
  },
  {
    "text": "instances uh after that we go through a series actually the instances at the point which are fulfilled don't haven't",
    "start": "2086520",
    "end": "2093240"
  },
  {
    "text": "quite yet started up they're just guaranteed to be provisioned they go into request queue they go through an initializing stage and then within my",
    "start": "2093240",
    "end": "2100960"
  },
  {
    "text": "own uh cluster Builder that you just saw uh we select certain ones to be",
    "start": "2100960",
    "end": "2106119"
  },
  {
    "text": "configuration servers in this case I pre- started my configuration servers so as to simplify things they add a little bit of reliability since I'm doing this",
    "start": "2106119",
    "end": "2112640"
  },
  {
    "text": "live uh we choose some s's uh we watch them start we find that they're",
    "start": "2112640",
    "end": "2119520"
  },
  {
    "text": "running and answering up as the mongod DS uh come up they actually call into",
    "start": "2119520",
    "end": "2126160"
  },
  {
    "text": "the configuration server via their local  S's and say Make Me A Shard I'm",
    "start": "2126160",
    "end": "2131520"
  },
  {
    "text": "here I'm available and then finally some of them I'm not sure if I had any of this run I I will reject if they time",
    "start": "2131520",
    "end": "2137280"
  },
  {
    "text": "out uh I'd rather they not be in my non-high availability uh negative redundancy",
    "start": "2137280",
    "end": "2143160"
  },
  {
    "text": "cluster so the uh flow goes something like this bot instance request on the",
    "start": "2143160",
    "end": "2148240"
  },
  {
    "text": "left uh again I prestarted my configuration servers and this case uh",
    "start": "2148240",
    "end": "2153319"
  },
  {
    "text": "and then uh the conditionally I start um  s's the routers and the mongod D's",
    "start": "2153319",
    "end": "2161400"
  },
  {
    "text": "join in as charts so where we've gotten uh learned",
    "start": "2161400",
    "end": "2167640"
  },
  {
    "text": "a lot as I expected I would scaling out uh figured I would do this by orders of magnitude",
    "start": "2167640",
    "end": "2173560"
  },
  {
    "text": "four uh at 4 uh probably about half of the coding was required up to that point",
    "start": "2173560",
    "end": "2179560"
  },
  {
    "text": "just functionally to make it work uh mov to uh 16 started to see some variations",
    "start": "2179560",
    "end": "2185960"
  },
  {
    "text": "and this is where a lot of ception handling and lessons learned that I'll get to later ways to do things more",
    "start": "2185960",
    "end": "2191560"
  },
  {
    "text": "easily so that you're not having to write Pearl uh I think I wrote a total about 900 lines of pearl about 500 of",
    "start": "2191560",
    "end": "2197880"
  },
  {
    "text": "those are dead now because I found better ways to do things uh going to 64 everything just",
    "start": "2197880",
    "end": "2203839"
  },
  {
    "text": "worked okay only two more IAS of magnitude and everything's going to be fine I'm not going to have to write anymore uh well okay at",
    "start": "2203839",
    "end": "2210400"
  },
  {
    "text": "256 uh chunk distribution time uh for my purposes was significant you only do",
    "start": "2210400",
    "end": "2216520"
  },
  {
    "text": "this once ever when you stand up a cluster you go through the initial chunk distribution so the fact that it takes",
    "start": "2216520",
    "end": "2222400"
  },
  {
    "text": "uh you know 20 or 30 minutes with a huge cluster is okay for me it's not uh so I",
    "start": "2222400",
    "end": "2228680"
  },
  {
    "text": "decid okay I'm I'm not going high available in any way single configuration server kind of helped there and then at 1024 uh you are really",
    "start": "2228680",
    "end": "2236280"
  },
  {
    "text": "at the whim of the market uh you you'll get a cluster 3/4s of the way there somebody out bids you uh lots of",
    "start": "2236280",
    "end": "2242319"
  },
  {
    "text": "interesting Behavior there uh I also found wire saturation with ycsb",
    "start": "2242319",
    "end": "2248160"
  },
  {
    "text": "uh which is why I went to bench press which I'll address definitely learn defensive",
    "start": "2248160",
    "end": "2254319"
  },
  {
    "text": "coding uh expect error conditions that you didn't think of upfront monitor",
    "start": "2254319",
    "end": "2261200"
  },
  {
    "text": "everything so that you could do post-mortems and figure out what went wrong mongodb Management Service is uh a",
    "start": "2261200",
    "end": "2269040"
  },
  {
    "text": "uh particularly useful tool here where it's free uh something that we offer on",
    "start": "2269040",
    "end": "2274280"
  },
  {
    "text": "the cloud to anyone running mongod DB it will allow you to see uh oh about three",
    "start": "2274280",
    "end": "2280000"
  },
  {
    "text": "dozen metrics per server some of the gross stuff like CPU I8 Etc some of the",
    "start": "2280000",
    "end": "2285640"
  },
  {
    "text": "fine stuff like uh database lock percentages Etc uh one of the things that we both",
    "start": "2285640",
    "end": "2292280"
  },
  {
    "text": "learned uh despite our Tendencies to the contrary is don't get sentimentally attached to uh these little spot",
    "start": "2292280",
    "end": "2299000"
  },
  {
    "text": "instances even if they have really cool instance names like bad",
    "start": "2299000",
    "end": "2304520"
  },
  {
    "text": "B keep refactoring uh try things out and be ready to throw away as I said most of",
    "start": "2306240",
    "end": "2312440"
  },
  {
    "text": "your code and then throw everything you can to the side of the instances so they do the work up front uh and the chunk",
    "start": "2312440",
    "end": "2320560"
  },
  {
    "text": "migration wound up again because I'm standing up a thousand servers I don't want to take 20 minutes to Shard them uh",
    "start": "2320560",
    "end": "2326760"
  },
  {
    "text": "out uh that actually mattered to me where it probably wouldn't if you were a data center standing up a thousand uh",
    "start": "2326760",
    "end": "2332560"
  },
  {
    "text": "for business use the refactoring led me to move from ycsb to at least for the",
    "start": "2332560",
    "end": "2338079"
  },
  {
    "text": "killard distributed uh cluster uh bench press from palamina Labs it's a fairly",
    "start": "2338079",
    "end": "2344440"
  },
  {
    "text": "early uh 0.1 is level but works very nicely has its own uh little server",
    "start": "2344440",
    "end": "2350880"
  },
  {
    "text": "using zookeeper internally and quite a bit of Apache software to distribute the",
    "start": "2350880",
    "end": "2356400"
  },
  {
    "text": "load and then you have a an individual load Runner uh at each of the shards so",
    "start": "2356400",
    "end": "2363160"
  },
  {
    "text": "that you aren't dragging all of that traffic across the network the database the documents are being generated",
    "start": "2363160",
    "end": "2369040"
  },
  {
    "text": "locally uh as I said more and more of my Pearl went away and moved to server side",
    "start": "2369040",
    "end": "2374400"
  },
  {
    "text": "uh something like uh Global shell very helpful so that you can address any named subset of your cluster or the",
    "start": "2374400",
    "end": "2381160"
  },
  {
    "text": "entire cluster and send commands and just have them uh take care of everything for instance Health I've",
    "start": "2381160",
    "end": "2386599"
  },
  {
    "text": "started moving away from polling to a very new 0. oneish uh open source",
    "start": "2386599",
    "end": "2391680"
  },
  {
    "text": "project called surf which provides uh I think I was the first one to take any",
    "start": "2391680",
    "end": "2397400"
  },
  {
    "text": "we're near a thousand shards and it scaled out quite nicely allowing each of the shards to share heartbeat with all",
    "start": "2397400",
    "end": "2403560"
  },
  {
    "text": "the others uses a gossip protocol and uh requires a little bit of tweaking as you scale out but allows you from an any",
    "start": "2403560",
    "end": "2410040"
  },
  {
    "text": "Shard to see how the rest of the cluster is doing also did a little bit of work with",
    "start": "2410040",
    "end": "2415920"
  },
  {
    "text": "Union Bay networks uh they are a value added uh service on top of AWS and Miles",
    "start": "2415920",
    "end": "2423319"
  },
  {
    "text": "you want to take this one sure absolutely so uh ubn uh is a part of a team uniquely",
    "start": "2423319",
    "end": "2432640"
  },
  {
    "text": "named in Union Bay uh in Seattle they've built a tool for a wide area network uh",
    "start": "2432640",
    "end": "2439520"
  },
  {
    "text": "Network construction and network optimization so uh that also makes much",
    "start": "2439520",
    "end": "2445119"
  },
  {
    "text": "easier to implement uh the security of that connectivity so um we built these",
    "start": "2445119",
    "end": "2450520"
  },
  {
    "text": "systems inside of VPC to ensure that we had networking grass egress control uh and uh ubn allowed allowed us to connect",
    "start": "2450520",
    "end": "2458880"
  },
  {
    "text": "one region to the other region with a lot less configuration steps uh without the VPN Hardware devices from uh AWS and",
    "start": "2458880",
    "end": "2465920"
  },
  {
    "text": "with uh with a sort of a push button deployment so pretty useful tool for us and made uh made all this get done fast",
    "start": "2465920",
    "end": "2472880"
  },
  {
    "text": "uh there are folks here from ubn so uh and they're good-looking so uh if you",
    "start": "2472880",
    "end": "2478440"
  },
  {
    "text": "come in after I think they have a survey and a gift card if you're interested so um they were they were awesome so thanks",
    "start": "2478440",
    "end": "2485400"
  },
  {
    "text": "guys so helpful in giving here manageable Communications as we're working to apply this across the",
    "start": "2485400",
    "end": "2494000"
  },
  {
    "text": "regions uh here's uh wouldn't be complete without some charts showing load rate I talked a little bit before",
    "start": "2494000",
    "end": "2501359"
  },
  {
    "text": "about your working set fitting in Ram uh any database obviously is going to be",
    "start": "2501359",
    "end": "2506599"
  },
  {
    "text": "happier when everything fits in Ram so it was interesting to see that uh from a load perspective there's a little bit of",
    "start": "2506599",
    "end": "2513000"
  },
  {
    "text": "a dwell at 1X Ram basically this is the point at which we can no longer map every everything uh and flush it lazily",
    "start": "2513000",
    "end": "2519400"
  },
  {
    "text": "to disk and we need to uh actually ensure we do a transactional commit to disk so you see a little bit of a dwell",
    "start": "2519400",
    "end": "2525960"
  },
  {
    "text": "there and a slightly lesser slope once we hit 1X Ram now this is another case where I'm going to change by order of",
    "start": "2525960",
    "end": "2532520"
  },
  {
    "text": "magnitude the scale this time in the horizontal so here we're looking at the first what about 2 and a half",
    "start": "2532520",
    "end": "2539960"
  },
  {
    "text": "hours uh to get to uh 1.2 billion here's",
    "start": "2539960",
    "end": "2546599"
  },
  {
    "text": "the path uh I'm sorry that was yeah 1.2 billion",
    "start": "2546599",
    "end": "2552359"
  },
  {
    "text": "here's the path uh over almost 12 hours so you see a few of those uh",
    "start": "2552359",
    "end": "2559040"
  },
  {
    "text": "dwells there where you've got uh some some additional map flushing activity going on but it was quite happy you",
    "start": "2559040",
    "end": "2566160"
  },
  {
    "text": "expect over time as the proportion in Ram uh declines for the slope to become",
    "start": "2566160",
    "end": "2571760"
  },
  {
    "text": "a little bit less and was quite happy with that actually uh particularly as it scaled out across this number of shards",
    "start": "2571760",
    "end": "2579160"
  },
  {
    "text": "so now uh the deluxe proposal uh miles you want to talk about your uh thinking",
    "start": "2579160",
    "end": "2585839"
  },
  {
    "text": "there we've worked with a lot of customers and and and I we were excited about the Thousand node implementation",
    "start": "2585839",
    "end": "2592520"
  },
  {
    "text": "as a as a prototype as a way to push the outer boundaries of the automation tools",
    "start": "2592520",
    "end": "2597680"
  },
  {
    "text": "and the bench testing tools and uh the other pieces that uh that are are helping mongod DB customers experiment",
    "start": "2597680",
    "end": "2604559"
  },
  {
    "text": "at these kinds of scales um but we also know that in production uh with most end users that operations at that wide and",
    "start": "2604559",
    "end": "2612280"
  },
  {
    "text": "that small is a little weird um most folks don't do that uh and they don't do",
    "start": "2612280",
    "end": "2617359"
  },
  {
    "text": "it for a couple of different reasons so um part of that has to do with uh the",
    "start": "2617359",
    "end": "2622400"
  },
  {
    "text": "density of uh manageable resources uh the other part of it is uh this example",
    "start": "2622400",
    "end": "2628240"
  },
  {
    "text": "uses the spot Market but to do this in the normal Market is easily 10 times as expensive um and and that makes that",
    "start": "2628240",
    "end": "2636480"
  },
  {
    "text": "kind of an implement mation not cost efficient uh provision to iops also allows you to radically increase the",
    "start": "2636480",
    "end": "2643079"
  },
  {
    "text": "storage performance of the individual instances so if the uh local ephemeral",
    "start": "2643079",
    "end": "2648319"
  },
  {
    "text": "disc on those M1 Smalls uh can grind out about a 100 iops the provision I storage",
    "start": "2648319",
    "end": "2653520"
  },
  {
    "text": "like we talked about before can grind out 40 times as much per volume and you",
    "start": "2653520",
    "end": "2659040"
  },
  {
    "text": "have 24 times as many volumes on each instance so it's much much much higher",
    "start": "2659040",
    "end": "2664599"
  },
  {
    "text": "performance uh at a much smaller more manageable cluster size which also lets you do uh the mathematics around uh",
    "start": "2664599",
    "end": "2672200"
  },
  {
    "text": "Regional distribution as well as a distribution um with uh with easier",
    "start": "2672200",
    "end": "2677400"
  },
  {
    "text": "building blocks so this one much more applicable to actual production use uh a thousand",
    "start": "2677400",
    "end": "2683839"
  },
  {
    "text": "shards with negative redundancy probably not the way you would do anything for more than an hour uh some results here",
    "start": "2683839",
    "end": "2690160"
  },
  {
    "text": "we went with the cc2 adx large instances uh 24 terabyte mounts this particular one",
    "start": "2690160",
    "end": "2698280"
  },
  {
    "text": "was 4,000 Pi Ops provisioned for each of those uh and again you're you're looking",
    "start": "2698280",
    "end": "2704720"
  },
  {
    "text": "at uh let's see what's this about 2 and a half hours to get to uh the first",
    "start": "2704720",
    "end": "2711480"
  },
  {
    "text": "three million notice these are much larger uh documents these are 64 kilobyte documents whereas previously",
    "start": "2711480",
    "end": "2717119"
  },
  {
    "text": "some of the trials I was running was with uh 1 kilobyte a pyop gives you 16 kilobytes it's kind of a shame to waste",
    "start": "2717119",
    "end": "2723920"
  },
  {
    "text": "it on a kilobyte so made a little more sense to pick somewhat beefier documents here again you'll notice a uh rather",
    "start": "2723920",
    "end": "2731119"
  },
  {
    "text": "brief uh L right around 100% RAM and I'm sorry this is the one where I'm really going to take out the horizontal axis",
    "start": "2731119",
    "end": "2737640"
  },
  {
    "text": "this is the first 3 million over two and a half hours uh here we go all the way",
    "start": "2737640",
    "end": "2742960"
  },
  {
    "text": "to 100 just south of 100 million uh again this is one server uh over about",
    "start": "2742960",
    "end": "2749960"
  },
  {
    "text": "five hours one of those nice straight lines I",
    "start": "2749960",
    "end": "2756520"
  },
  {
    "text": "like those a lot so we've also done a lot of looking at um mongod DB's",
    "start": "2756520",
    "end": "2761720"
  },
  {
    "text": "interaction with storage is is different than a relational database uh it does work to serialize IO as a result can uh",
    "start": "2761720",
    "end": "2771480"
  },
  {
    "text": "can grow in IO size and a document size larger than the individual sort of typical 4K operations that it does to",
    "start": "2771480",
    "end": "2778160"
  },
  {
    "text": "the storage system so this is a right throughput in uh kilobytes uh per second",
    "start": "2778160",
    "end": "2785359"
  },
  {
    "text": "against uh each of the individual discs so it's not uh 1200 k a second for the",
    "start": "2785359",
    "end": "2790800"
  },
  {
    "text": "whole dis system it's for each of 24 distinct discs uh that are attached to",
    "start": "2790800",
    "end": "2796040"
  },
  {
    "text": "that tool so um as we got up to full load you can see that's a pretty steady state over the course of uh the period",
    "start": "2796040",
    "end": "2803079"
  },
  {
    "text": "of time there so couple U 15 minutes or so so the provision iops data storage",
    "start": "2803079",
    "end": "2809200"
  },
  {
    "text": "system U really allowed this tool to really really increase the density of",
    "start": "2809200",
    "end": "2814599"
  },
  {
    "text": "that deployment maybe make the management a little more straightforward um uh and reduce the aggregate cost for",
    "start": "2814599",
    "end": "2820800"
  },
  {
    "text": "operations over time and to be clear the variation here is a question of load uh",
    "start": "2820800",
    "end": "2827160"
  },
  {
    "text": "the provisioned iops could have been absolutely flat if we're able to fully load them turns out moving a petabyte of",
    "start": "2827160",
    "end": "2834520"
  },
  {
    "text": "even uh synthetic data around even at 10 gbits per second you you hit Network",
    "start": "2834520",
    "end": "2840000"
  },
  {
    "text": "bottlenecks fairly easily and a lot of the tuning and plumbing had to do with that PS performed flawlessly here uh",
    "start": "2840000",
    "end": "2846160"
  },
  {
    "text": "you'll notice this is one machine 24 volumes attached and I think cloudwatch lost patience with us after what's the",
    "start": "2846160",
    "end": "2853640"
  },
  {
    "text": "first 10 so yeah I mean that um how many folks have done that thing where you",
    "start": "2853640",
    "end": "2859119"
  },
  {
    "text": "shoot the dart at the dart board and if you get all of them right in exactly the same spot they say oh that's a nice",
    "start": "2859119",
    "end": "2864760"
  },
  {
    "text": "tight grouping this is a really really tight grouping it means that uh each of",
    "start": "2864760",
    "end": "2870319"
  },
  {
    "text": "the volumes is performing at almost exactly the same rate in many other systems all sorts of other charts if you",
    "start": "2870319",
    "end": "2876400"
  },
  {
    "text": "do this with standard EBS you do this on local ephemeral dis you'd see a wide stripe not a skinny stripe because each",
    "start": "2876400",
    "end": "2883480"
  },
  {
    "text": "of those lines there are 10 lines consumed in that one row so um you're",
    "start": "2883480",
    "end": "2888599"
  },
  {
    "text": "watching really direct uh performance against the demanded work",
    "start": "2888599",
    "end": "2894640"
  },
  {
    "text": "Club so more work to do uh as I mentioned uh want to drive this in all",
    "start": "2895520",
    "end": "2900920"
  },
  {
    "text": "of these Dimensions uh across the paby boundary uh do it with replication uh",
    "start": "2900920",
    "end": "2907280"
  },
  {
    "text": "I thank very much the py Ops Gods whom I know not by name but who granted uh this",
    "start": "2907280",
    "end": "2913040"
  },
  {
    "text": "last week I I guess Amazon has a little extra inventory in getting ready for the holiday season so I was given uh access",
    "start": "2913040",
    "end": "2920319"
  },
  {
    "text": "to it uh to just go to town uh spent most of the weekend doing it and I don't",
    "start": "2920319",
    "end": "2925480"
  },
  {
    "text": "want to spend every weekend entirely on pups there other activities but it was a lot of",
    "start": "2925480",
    "end": "2931280"
  },
  {
    "text": "fun uh right now as I say everything's negatively rone it would be interesting to look at selfhealing without into a",
    "start": "2931280",
    "end": "2937119"
  },
  {
    "text": "full replicated redundancy uh can I automate the cluster so again we keep a spare pool and if a node goes down uh",
    "start": "2937119",
    "end": "2944319"
  },
  {
    "text": "it's a function just gets picked up by one of the spares we definitely want to move away from ycsb it has the benefit",
    "start": "2944319",
    "end": "2952359"
  },
  {
    "text": "of familiarity but it's just a wretched data set for a document database so",
    "start": "2952359",
    "end": "2957440"
  },
  {
    "text": "we're developing some uh benchmarks particularly that twitter- like uh application uh very interested in using",
    "start": "2957440",
    "end": "2964079"
  },
  {
    "text": "customer data customers tend to be rather closed mouth about their pedabytes uh if anyone out here has paby",
    "start": "2964079",
    "end": "2970720"
  },
  {
    "text": "scale data that they would be willing to share with me I'd be very interested uh in incorporating it uh that's something",
    "start": "2970720",
    "end": "2976960"
  },
  {
    "text": "I think someday for a press release we'd like to say it was with customer X and here's the business case rather than my",
    "start": "2976960",
    "end": "2983559"
  },
  {
    "text": "admittedly synthetic approach uh and then I would like all of my Pearl script to go away so it's completely",
    "start": "2983559",
    "end": "2989319"
  },
  {
    "text": "self-hosting using many of the tools uh that Miles talked about so I'll close very quickly going back to the demo and",
    "start": "2989319",
    "end": "2996319"
  },
  {
    "text": "explain what the heck we were just looking",
    "start": "2996319",
    "end": "3000280"
  },
  {
    "text": "at if my console cooperates uh oh five right yeah I hit",
    "start": "3005240",
    "end": "3012480"
  },
  {
    "text": "six ah Precision so what we saw here was the launch of an autoscaling group right",
    "start": "3012480",
    "end": "3019200"
  },
  {
    "text": "here at the top uh launch configuration describes the individual units uh the",
    "start": "3019200",
    "end": "3025319"
  },
  {
    "text": "instance what will become instance the autoscaling group describes uh how many of them and where they're going to",
    "start": "3025319",
    "end": "3031799"
  },
  {
    "text": "be uh I it's purely an API out of the box with a few languages supporting it",
    "start": "3031799",
    "end": "3037640"
  },
  {
    "text": "uh I do recommend if you're going to mess with Autos scaling groups easy autoscaling very inexpense valuated",
    "start": "3037640",
    "end": "3042680"
  },
  {
    "text": "service on AWS has helped me a lot to see what I'm doing so I don't have to create a restful query to figure it",
    "start": "3042680",
    "end": "3050040"
  },
  {
    "text": "out uh having registered the two of those the autoscaling group specified a certain size in this case 80 servers of",
    "start": "3050040",
    "end": "3057880"
  },
  {
    "text": "which I wanted to harvest at least 64 to create a 64 Shard instance uh 64 Shard cluster you'll",
    "start": "3057880",
    "end": "3065520"
  },
  {
    "text": "notice these are roughly 30 second intervals uh I sleep until the next interval uh it takes a few minutes for",
    "start": "3065520",
    "end": "3071760"
  },
  {
    "text": "the first one to actually become fulfilled not yet actually available and it continue in an idle Loop here until",
    "start": "3071760",
    "end": "3078359"
  },
  {
    "text": "we get at least 64 of them fulfilled uh sufficient to build the",
    "start": "3078359",
    "end": "3083440"
  },
  {
    "text": "size cluster I want we wound actually with 71 of them enumerated here these",
    "start": "3083440",
    "end": "3089319"
  },
  {
    "text": "ticks then are individual reports in from these uh shards aborning saying",
    "start": "3089319",
    "end": "3097079"
  },
  {
    "text": "that they've been instantiated the eyes U they're up d uh mongod D has been",
    "start": "3097079",
    "end": "3103280"
  },
  {
    "text": "started s s has been started uh at least the lowercase ones and then you'll",
    "start": "3103280",
    "end": "3110000"
  },
  {
    "text": "notice uh the numbers initializing at first it's just a few uh sorry no",
    "start": "3110000",
    "end": "3115440"
  },
  {
    "text": "actually the first pass we have we've got 58 of them already started these came up fairly",
    "start": "3115440",
    "end": "3120640"
  },
  {
    "text": "quickly uh the capital S there initially starting only one s which is",
    "start": "3120640",
    "end": "3126359"
  },
  {
    "text": "required to get the cluster initiated uh and then finally the mongod DS you'll notice all coming online",
    "start": "3126359",
    "end": "3133319"
  },
  {
    "text": "finally we've got the 64 that we wanted the cluster at this point is definitionally up and the last thing we",
    "start": "3133319",
    "end": "3140079"
  },
  {
    "text": "have to do is that actual sharding where all of these mongod that have volunteered to become shards in our",
    "start": "3140079",
    "end": "3145160"
  },
  {
    "text": "database now are given their assignment of chunks of that hash space that they",
    "start": "3145160",
    "end": "3150359"
  },
  {
    "text": "cover so uh that's the tadada moment um I",
    "start": "3150359",
    "end": "3155880"
  },
  {
    "text": "guess we can take a look in this Shard on this cluster let's see if it's still up oh yes it is so this is a report on",
    "start": "3155880",
    "end": "3163640"
  },
  {
    "text": "the uh sharding activity these are the individual uh Shard numbers you'll notice that there are 64",
    "start": "3163640",
    "end": "3172480"
  },
  {
    "text": "of them uh each of those shards has two chunks of with the exception of the one at the top there that already started",
    "start": "3172480",
    "end": "3179040"
  },
  {
    "text": "dividing its chunks it got a little overeager for some reason because I haven't given it any data yet and then these are uh the chunks within the",
    "start": "3179040",
    "end": "3186359"
  },
  {
    "text": "shards uh those those offsets within the hash Bas that each is responsible for uh",
    "start": "3186359",
    "end": "3192720"
  },
  {
    "text": "that's a look into uh the one that I just created here's a look into the one",
    "start": "3192720",
    "end": "3200040"
  },
  {
    "text": "built on the uh larger instances again",
    "start": "3200040",
    "end": "3205440"
  },
  {
    "text": "uh because we have uh what is it 20 I'm sorry eight",
    "start": "3205440",
    "end": "3210520"
  },
  {
    "text": "shards per instance uh we wind up with a total of",
    "start": "3210520",
    "end": "3215559"
  },
  {
    "text": "111 shards and again you got two chunks per Shard so any final remarks sure first",
    "start": "3215559",
    "end": "3223280"
  },
  {
    "text": "off thank you very much for not buying thousands and thousands of M1 Smalls while we were talking about this if you",
    "start": "3223280",
    "end": "3229880"
  },
  {
    "text": "had in the spot Market the demo would have crashed uh because The Spar market price would have gone up so that was",
    "start": "3229880",
    "end": "3235280"
  },
  {
    "text": "awesome um any other questions that you've got about about this process and maybe",
    "start": "3235280",
    "end": "3241680"
  },
  {
    "text": "questions or AWS questions or the stuff we're working on go ahead what say ah no that's spectacular yeah",
    "start": "3241680",
    "end": "3251280"
  },
  {
    "text": "we have a we have a screenshot about this so uh so so trusted advisor uh at",
    "start": "3251280",
    "end": "3258280"
  },
  {
    "text": "this time where is this thing uh it shows that we have 677 EBS volumes",
    "start": "3258280",
    "end": "3263640"
  },
  {
    "text": "running and that only three of them are not slammed right now which is great news it means we're actually beating up",
    "start": "3263640",
    "end": "3269839"
  },
  {
    "text": "dis uh trusted adviser doesn't like it from an instance count standpoint",
    "start": "3269839",
    "end": "3275960"
  },
  {
    "text": "against compute utilization right so there are some monthly savings that could be had uh were you to say for",
    "start": "3275960",
    "end": "3283319"
  },
  {
    "text": "example buy an r on said CCS um uh security has also got a couple of red",
    "start": "3283319",
    "end": "3289319"
  },
  {
    "text": "dots because you know we just sort of put it in a box any other questions but trust advisor doesn't call me weird only",
    "start": "3289319",
    "end": "3295319"
  },
  {
    "text": "miles does that definitely calls me weird uh",
    "start": "3295319",
    "end": "3300440"
  },
  {
    "text": "sure",
    "start": "3300440",
    "end": "3303440"
  },
  {
    "text": "iens when there's no processing available in your oh like when yeah uh",
    "start": "3309480",
    "end": "3315960"
  },
  {
    "text": "you don't get your instances yeah so there's there's actually a",
    "start": "3315960",
    "end": "3323200"
  },
  {
    "text": "couple of really great um full full walk through of this if uh you heard of Vimeo",
    "start": "3323200",
    "end": "3328520"
  },
  {
    "text": "you watch video on Vimeo Vimeo pattern is seven different bids at different",
    "start": "3328520",
    "end": "3334920"
  },
  {
    "text": "price levels right and if at any of those different price levels across the different availability zones in the",
    "start": "3334920",
    "end": "3340319"
  },
  {
    "text": "region where they want to operate don't work then they're bidding in on demand so you can pay the full rate for",
    "start": "3340319",
    "end": "3347240"
  },
  {
    "text": "instances the whole point of having access to spot is opportunistically getting the cheap stuff right so you do",
    "start": "3347240",
    "end": "3353559"
  },
  {
    "text": "have to be able to pattern back and forth between the two uh and there are plenty of workloads where uh you're",
    "start": "3353559",
    "end": "3358880"
  },
  {
    "text": "running integration testing against a mongod DB Warehouse you want to do that at once every day because you build",
    "start": "3358880",
    "end": "3366359"
  },
  {
    "text": "software really really quickly so you run it on spot if two out of the ones that you do that week don't run but",
    "start": "3366359",
    "end": "3372079"
  },
  {
    "text": "instead you've changed the cost from $70 to $7 your boss might like",
    "start": "3372079",
    "end": "3378760"
  },
  {
    "text": "it and internally customer comes to us and says yeah we're looking at this",
    "start": "3378760",
    "end": "3384119"
  },
  {
    "text": "number of shards how's that going to perform how's it going to stand up this allows us to just go do it uh say don't",
    "start": "3384119",
    "end": "3391240"
  },
  {
    "text": "get sentimentally attached you may get half your instances and then you get outbid but for testing purposes that I",
    "start": "3391240",
    "end": "3397240"
  },
  {
    "text": "originally architected this it's great uh a 59 business on a thousand",
    "start": "3397240",
    "end": "3405280"
  },
  {
    "text": "non- highly availability negatively redundant shards no it's bad uh another",
    "start": "3405280",
    "end": "3412000"
  },
  {
    "text": "thing that we have seen folks do is um imagine that you have a replica set",
    "start": "3412000",
    "end": "3417520"
  },
  {
    "text": "established on in reserved instance high performance instances you have three of those in three different A's you're",
    "start": "3417520",
    "end": "3423559"
  },
  {
    "text": "following all the best practices and you know you're going to do more reads in a given period of time so You' bid for new",
    "start": "3423559",
    "end": "3430280"
  },
  {
    "text": "spot instances go from three to five and then be able to query against all of those if they don't come up your reads",
    "start": "3430280",
    "end": "3436079"
  },
  {
    "text": "go a little slower if they do come up awesome you can get a little more higher performance on",
    "start": "3436079",
    "end": "3441359"
  },
  {
    "text": "read over here what happens when for whatever",
    "start": "3441359",
    "end": "3448760"
  },
  {
    "text": "reason it's a good one that actually is a design goal of ours in large part yeah",
    "start": "3454799",
    "end": "3460760"
  },
  {
    "text": "you do want to spread the activity but you want individual queries to the degree possible going to one or a few",
    "start": "3460760",
    "end": "3466880"
  },
  {
    "text": "shards and that the trade-off for that is you get hotspots uh if you're dealing with",
    "start": "3466880",
    "end": "3472559"
  },
  {
    "text": "Justin Bieber's tweet and Justin Bieber winds up on a Shard that's going to be a hot Shard so maybe you spread his uh but",
    "start": "3472559",
    "end": "3479240"
  },
  {
    "text": "we will actually tend a little bit in design toward allowing hot spots so that we concentrate our load that helps us",
    "start": "3479240",
    "end": "3486200"
  },
  {
    "text": "when you have a great deal of concurrency because the concurrency will spread things the other option if you",
    "start": "3486200",
    "end": "3492039"
  },
  {
    "text": "don't want that to happen is what I actually did here which is used hash sharding and now there's no reason you",
    "start": "3492039",
    "end": "3497760"
  },
  {
    "text": "should get a hot spot unless a single document causes a ridiculous load the only way I know to do that is with uh",
    "start": "3497760",
    "end": "3504760"
  },
  {
    "text": "unreasonably large array which is why I would not recommend more than about a 10,000 element array and a",
    "start": "3504760",
    "end": "3512599"
  },
  {
    "text": "document any other questions thank you very much everybody",
    "start": "3513160",
    "end": "3518400"
  },
  {
    "text": "I really appreciate you taking the time uh it is thank",
    "start": "3518400",
    "end": "3524079"
  },
  {
    "text": "you uh it is BDT 307 uh the more feedback we get the more we make this",
    "start": "3524079",
    "end": "3529400"
  },
  {
    "text": "rock next year so uh click the buttons for us and we'll try to make it even more awesome have a good time at the",
    "start": "3529400",
    "end": "3535000"
  },
  {
    "text": "rest of the day than",
    "start": "3535000",
    "end": "3539200"
  }
]
[
  {
    "text": "(soft electronic music)",
    "start": "224",
    "end": "3660"
  },
  {
    "text": "- Hey, hey!\n(atmosphere humming)",
    "start": "3660",
    "end": "4493"
  },
  {
    "text": "This is Dr. Nashlie Sephus,",
    "start": "4493",
    "end": "5940"
  },
  {
    "text": "and I'm a Principal AI Scientist\nat Amazon Web Services.",
    "start": "5940",
    "end": "9510"
  },
  {
    "text": "I specialize in responsible AI.",
    "start": "9510",
    "end": "11610"
  },
  {
    "text": "And today, we're gonna\ntalk to Alicia, Mia,",
    "start": "11610",
    "end": "14580"
  },
  {
    "text": "as well as Valeria, who work\non the responsible AI team",
    "start": "14580",
    "end": "17700"
  },
  {
    "text": "about the work that they've done.",
    "start": "17700",
    "end": "19170"
  },
  {
    "text": "And we're gonna show you",
    "start": "19170",
    "end": "20100"
  },
  {
    "text": "how you can get more involved as well.",
    "start": "20100",
    "end": "22000"
  },
  {
    "text": "(soft music)",
    "start": "23298",
    "end": "24131"
  },
  {
    "text": "Love to see how you've been doing the work",
    "start": "24131",
    "end": "26310"
  },
  {
    "text": "with Machine Learning University",
    "start": "26310",
    "end": "27990"
  },
  {
    "text": "and all the courses that you\nhelped to initiate and create.",
    "start": "27990",
    "end": "31770"
  },
  {
    "text": "I want to dive in a little bit deeper",
    "start": "31770",
    "end": "33750"
  },
  {
    "text": "into some of the specifics,\nso we can help others",
    "start": "33750",
    "end": "36420"
  },
  {
    "text": "who are maybe not in this space\nunderstand a little bit more",
    "start": "36420",
    "end": "39359"
  },
  {
    "text": "about what we're talkin' about.",
    "start": "39360",
    "end": "40650"
  },
  {
    "text": "- I've been working on\nmachine learning problems",
    "start": "40650",
    "end": "43170"
  },
  {
    "text": "and solutions for many years,",
    "start": "43170",
    "end": "44760"
  },
  {
    "text": "but I never really thought about",
    "start": "44760",
    "end": "45960"
  },
  {
    "text": "a systematic way of actually analyzing",
    "start": "45960",
    "end": "48090"
  },
  {
    "text": "all the potential risks",
    "start": "48090",
    "end": "49080"
  },
  {
    "text": "that I could face before building it.",
    "start": "49080",
    "end": "50640"
  },
  {
    "text": "So, then I found this\nrisk management framework,",
    "start": "50640",
    "end": "53340"
  },
  {
    "text": "and this is actually something",
    "start": "53340",
    "end": "54540"
  },
  {
    "text": "that we've adopted",
    "start": "54540",
    "end": "55470"
  },
  {
    "text": "from the National Institute\nof Standards and Technology.",
    "start": "55470",
    "end": "58140"
  },
  {
    "text": "They actually came up\nwith a guidance booklet",
    "start": "58140",
    "end": "60960"
  },
  {
    "text": "that organizations can take,",
    "start": "60960",
    "end": "62250"
  },
  {
    "text": "and then apply to their own\nAI use cases and applications.",
    "start": "62250",
    "end": "65460"
  },
  {
    "text": "And then, we converted that\ninto a course, actually.",
    "start": "65460",
    "end": "68370"
  },
  {
    "text": "So, now we're teaching the\nrisk management framework.",
    "start": "68370",
    "end": "70650"
  },
  {
    "text": "- How do you assess risk\nfor a particular use case?",
    "start": "70650",
    "end": "74070"
  },
  {
    "text": "- It's really three steps.",
    "start": "74070",
    "end": "75630"
  },
  {
    "text": "So first, you want to\ndescribe the use case",
    "start": "75630",
    "end": "78119"
  },
  {
    "text": "that you're working on in\nas much detail as possible.",
    "start": "78120",
    "end": "81000"
  },
  {
    "text": "- [Nashlie] A use case\nwould specifically define",
    "start": "81000",
    "end": "83190"
  },
  {
    "text": "who the target demographic is,",
    "start": "83190",
    "end": "85290"
  },
  {
    "text": "and we'd also want to\nidentify what that demographic",
    "start": "85290",
    "end": "88620"
  },
  {
    "text": "does not include.",
    "start": "88620",
    "end": "89910"
  },
  {
    "text": "For example, testing voices of children,",
    "start": "89910",
    "end": "92280"
  },
  {
    "text": "checking in and out of class",
    "start": "92280",
    "end": "93900"
  },
  {
    "text": "be different than a system\nwe would build for adults.",
    "start": "93900",
    "end": "96990"
  },
  {
    "text": "- And then, the next step,\nactually the hardest one,",
    "start": "96990",
    "end": "98820"
  },
  {
    "text": "you want to think about\nall the potential things",
    "start": "98820",
    "end": "101010"
  },
  {
    "text": "that could go wrong,",
    "start": "101010",
    "end": "102600"
  },
  {
    "text": "and then you can actually\nquantify it as well.",
    "start": "102600",
    "end": "105030"
  },
  {
    "text": "So you take,",
    "start": "105030",
    "end": "105863"
  },
  {
    "text": "what is the probability\nof the event occurring",
    "start": "105863",
    "end": "108659"
  },
  {
    "text": "times how bad is it if it happens?",
    "start": "108660",
    "end": "110790"
  },
  {
    "text": "And then obviously, it will be\nup to your own risk tolerance",
    "start": "110790",
    "end": "113580"
  },
  {
    "text": "on whether to proceed or not.",
    "start": "113580",
    "end": "115080"
  },
  {
    "text": "- Let me get this straight.",
    "start": "115080",
    "end": "116430"
  },
  {
    "text": "First, you want to find\nout what your use case is,",
    "start": "116430",
    "end": "119370"
  },
  {
    "text": "and then you want to figure\nout what is your risk",
    "start": "119370",
    "end": "122250"
  },
  {
    "text": "in each of those areas-\n- [Mia] Yes.",
    "start": "122250",
    "end": "124260"
  },
  {
    "text": "And then assign a number to it.",
    "start": "124260",
    "end": "125850"
  },
  {
    "text": "- [Mia] Mm-hmm!",
    "start": "125850",
    "end": "126683"
  },
  {
    "text": "- [Nashlie] Then learn how\nto prioritize from there.",
    "start": "126683",
    "end": "128340"
  },
  {
    "text": "So that's a great way-\n- [Mia] Yeah.",
    "start": "128340",
    "end": "129300"
  },
  {
    "text": "- To help us figure out the trade-offs,",
    "start": "129300",
    "end": "131340"
  },
  {
    "text": "and go straight to minimizing the risk.",
    "start": "131340",
    "end": "133230"
  },
  {
    "text": "- Exactly.",
    "start": "133230",
    "end": "134069"
  },
  {
    "text": "You will have some\nrisks that are very high",
    "start": "134070",
    "end": "136020"
  },
  {
    "text": "or critical depending\non what numbers you get",
    "start": "136020",
    "end": "138000"
  },
  {
    "text": "from the analysis itself.",
    "start": "138000",
    "end": "139680"
  },
  {
    "text": "And it could be the case\nthat maybe if you find",
    "start": "139680",
    "end": "141780"
  },
  {
    "text": "too many critical risks, that\nyou just stop right there.",
    "start": "141780",
    "end": "145110"
  },
  {
    "text": "Not every application is\nnecessarily a good application",
    "start": "145110",
    "end": "148200"
  },
  {
    "text": "to put out there.",
    "start": "148200",
    "end": "149032"
  },
  {
    "text": "If the risk is too high,\nwell then you stop.",
    "start": "149033",
    "end": "151773"
  }
]
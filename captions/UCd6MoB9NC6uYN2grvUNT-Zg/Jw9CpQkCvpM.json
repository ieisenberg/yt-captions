[
  {
    "text": "like good evening my name is asif i'm gonna take miss Deb manager for",
    "start": "0",
    "end": "5580"
  },
  {
    "text": "containers and and I'm a hobby coder at night these days but the idea behind",
    "start": "5580",
    "end": "12960"
  },
  {
    "text": "this session is to talk about machine learning and how do we deploy machine",
    "start": "12960",
    "end": "18150"
  },
  {
    "text": "learning applications on containers this is a blog the first part of this session",
    "start": "18150",
    "end": "23430"
  },
  {
    "text": "would be a blog that that I built and we published this last year in January about how do you do this",
    "start": "23430",
    "end": "30119"
  },
  {
    "text": "I have also got with me akuto and ushiro from goopad who is going to talk about",
    "start": "30119",
    "end": "36690"
  },
  {
    "text": "how do they use machine learning to power cook pad on containers so thank",
    "start": "36690",
    "end": "42660"
  },
  {
    "text": "you for coming in so late it really shows that you care about the topic so",
    "start": "42660",
    "end": "48690"
  },
  {
    "text": "that's awesome so let's get started what we're going to cover in the next 45",
    "start": "48690",
    "end": "54420"
  },
  {
    "text": "minutes and then open up for Q&A is what is deep learning why should we care about deep learning when we say deep",
    "start": "54420",
    "end": "62489"
  },
  {
    "text": "learning it's a pretty loaded term scientists data scientists train the models but how do we apply this and",
    "start": "62489",
    "end": "69299"
  },
  {
    "text": "where is machine learning today in our lives and then we'll look at a reference",
    "start": "69299",
    "end": "74310"
  },
  {
    "text": "architecture of how do you deploy deep learning functions on Amazon ECS and what ECS does and then we'll go deep",
    "start": "74310",
    "end": "81210"
  },
  {
    "text": "into the cook pad usage so let's get started",
    "start": "81210",
    "end": "86810"
  },
  {
    "text": "machine learning has been in our life in different formats for the last couple of",
    "start": "86810",
    "end": "93630"
  },
  {
    "text": "decades maybe I'm more like the machine learning was coined probably in the 50s the first time it was coined but the",
    "start": "93630",
    "end": "101460"
  },
  {
    "text": "idea is we have all learned math in school we've done linear regression logistic regression and those way those",
    "start": "101460",
    "end": "108720"
  },
  {
    "text": "need compute to run as the cloud evolved",
    "start": "108720",
    "end": "114030"
  },
  {
    "text": "in the last 10 years it made very ease very easy to run compute cycles so when",
    "start": "114030",
    "end": "122310"
  },
  {
    "text": "you run deep learning functions are the artificial intelligence side of the",
    "start": "122310",
    "end": "127409"
  },
  {
    "text": "house you need compute power because you're running n number of cycles and n",
    "start": "127409",
    "end": "132690"
  },
  {
    "text": "is a very large number deep learning is is is a is a",
    "start": "132690",
    "end": "138560"
  },
  {
    "text": "branch of artificial intelligence and it has four broad categories the first",
    "start": "138560",
    "end": "144810"
  },
  {
    "text": "being image recognition so when we walk in into a JetBlue kiosk and I can check",
    "start": "144810",
    "end": "151890"
  },
  {
    "text": "in with my face and how many of us have actually seen it or checked in with our",
    "start": "151890",
    "end": "157200"
  },
  {
    "text": "face at JetBlue kiosks okay nobody cool but but when you go it's okay that's",
    "start": "157200",
    "end": "163980"
  },
  {
    "text": "always a good question so it's fascinating that you you you can walk up",
    "start": "163980",
    "end": "172050"
  },
  {
    "text": "to a kiosk and stand there and it knows you and it checks you and prints a boarding pass for you similarly let me ask a simpler question",
    "start": "172050",
    "end": "179910"
  },
  {
    "text": "how many of us go through clear at airports some good I go through clear",
    "start": "179910",
    "end": "186300"
  },
  {
    "text": "it's super easy because I they have my biometric identity and I can go through and that's the clear is a different",
    "start": "186300",
    "end": "193290"
  },
  {
    "text": "biometric identification but JetBlue is more of a machine learning part then we",
    "start": "193290",
    "end": "198330"
  },
  {
    "text": "have natural language processing which is basically speech to text text to speech when you look at Alexa when you",
    "start": "198330",
    "end": "204959"
  },
  {
    "text": "home assistance at home you can talk to them I can send a text to my son from a",
    "start": "204959",
    "end": "210780"
  },
  {
    "text": "plane or from like an airport and Alexa or the echoed transcribes it and reads",
    "start": "210780",
    "end": "218850"
  },
  {
    "text": "it back to my son which is an amazing experience I have because my life or my interaction with my son has elevated",
    "start": "218850",
    "end": "226190"
  },
  {
    "text": "miles away where I have a busy lifestyle so I could communicate in a different",
    "start": "226190",
    "end": "232680"
  },
  {
    "text": "fashion and and the other classification is autonomous car autonomy autonomous",
    "start": "232680",
    "end": "239430"
  },
  {
    "text": "robos autonomous driving and things like that so that's primarily where deep",
    "start": "239430",
    "end": "244980"
  },
  {
    "text": "learning is today and many more algorithms are getting made so I give you a couple of example why machine",
    "start": "244980",
    "end": "251100"
  },
  {
    "text": "learning is important or why deep learning where is deep learning let's look at a couple more so when you or",
    "start": "251100",
    "end": "258450"
  },
  {
    "text": "when we are shopping on websites for clothing",
    "start": "258450",
    "end": "263690"
  },
  {
    "text": "there's machine learning or deep learning being used give us better options to identify our",
    "start": "263690",
    "end": "270639"
  },
  {
    "text": "needs so that we don't waste sighs waste cycles browsing through catalogs and",
    "start": "270639",
    "end": "275860"
  },
  {
    "text": "finding random items that's one thing Amazon goo is another novel concept",
    "start": "275860",
    "end": "282669"
  },
  {
    "text": "where it's a cashless grocery shop where you can actually go in pick up your item",
    "start": "282669",
    "end": "288520"
  },
  {
    "text": "and walk out without a queue and you get a bill on your Amazon app that is user",
    "start": "288520",
    "end": "296470"
  },
  {
    "text": "experience and when I've tried this with AD ghost shops is you pick up stuff you",
    "start": "296470",
    "end": "303490"
  },
  {
    "text": "pick down stuff and amazingly the bill that I get is always correct and that's",
    "start": "303490",
    "end": "309880"
  },
  {
    "text": "a lot of deep learning being used behind the scene but building deep learning",
    "start": "309880",
    "end": "316389"
  },
  {
    "text": "apps is still an art and when I say art I mean there's a lot of magic that you",
    "start": "316389",
    "end": "324190"
  },
  {
    "text": "need to build or invent we want with",
    "start": "324190",
    "end": "329650"
  },
  {
    "text": "this talk and the blogs we published and what we are doing in the AI and the container space it has to become a science it has to become repeatable and",
    "start": "329650",
    "end": "337240"
  },
  {
    "text": "everybody should be able to deploy machine learning algorithms into their",
    "start": "337240",
    "end": "343120"
  },
  {
    "text": "apps so when I go to Zillow for example as an example I look at the home",
    "start": "343120",
    "end": "349240"
  },
  {
    "text": "estimate as a user I want to look at the home estimate I don't want to look at",
    "start": "349240",
    "end": "354820"
  },
  {
    "text": "the details I want that clean experience but I also want the home estimate to be",
    "start": "354820",
    "end": "360940"
  },
  {
    "text": "correct or within an error margin so when you look at that there's a bunch of",
    "start": "360940",
    "end": "368289"
  },
  {
    "text": "scientists at the back end who are developing data models data crunching to",
    "start": "368289",
    "end": "373690"
  },
  {
    "text": "make sure the predictions are correct and and and gave us those models that",
    "start": "373690",
    "end": "379300"
  },
  {
    "text": "could be used so that's the line the horizontal lying word the diagonal line",
    "start": "379300",
    "end": "385979"
  },
  {
    "text": "below that that the machine learning data scientists sit there and they crunch numbers and do they do fabulous",
    "start": "385979",
    "end": "392800"
  },
  {
    "text": "mathematic pieces and they come up with algorithms but for an end user like me",
    "start": "392800",
    "end": "398430"
  },
  {
    "text": "to have find the estimate of a home for example it's super",
    "start": "398430",
    "end": "403550"
  },
  {
    "text": "important for me the experience is clean this experience is seamless so there's a",
    "start": "403550",
    "end": "409190"
  },
  {
    "text": "team sitting there which is DevOps which is tasked with taking these data models",
    "start": "409190",
    "end": "414850"
  },
  {
    "text": "applications and moving into production there's another set of developers which is app developers mobile front-end",
    "start": "414850",
    "end": "421430"
  },
  {
    "text": "developers back-end developers and they worry about how do I give the best",
    "start": "421430",
    "end": "426500"
  },
  {
    "text": "experience to my customer how do i scale this application how when I have a spike",
    "start": "426500",
    "end": "432110"
  },
  {
    "text": "from zero to ten million requests on that API that API doesn't fall down those are very valid concerns and you",
    "start": "432110",
    "end": "439880"
  },
  {
    "text": "need to give that experience back to your end user for him to stay with with",
    "start": "439880",
    "end": "446090"
  },
  {
    "text": "things these things with that let's go into how would you build such a solution",
    "start": "446090",
    "end": "452480"
  },
  {
    "text": "that is working in harmony using really advanced complex algorithms giving you",
    "start": "452480",
    "end": "459920"
  },
  {
    "text": "great prediction predictive results but at the same time having an experience which is seamless and which can be",
    "start": "459920",
    "end": "466940"
  },
  {
    "text": "deployed very rapidly so with Amazon AI",
    "start": "466940",
    "end": "472040"
  },
  {
    "text": "portfolio of services you get multiple layers of services if I am developing a",
    "start": "472040",
    "end": "482510"
  },
  {
    "text": "machine learning application and if I have the promise I might go in the engine level and write code intensive",
    "start": "482510",
    "end": "490160"
  },
  {
    "text": "flow build my own model or MX net and things like that but if I want to use",
    "start": "490160",
    "end": "495530"
  },
  {
    "text": "something more abstracted at a platform level I could go use Amazon EMR smart ml",
    "start": "495530",
    "end": "501919"
  },
  {
    "text": "spark and things like that that is for",
    "start": "501919",
    "end": "507050"
  },
  {
    "text": "me if I want to go really deep and build stuff but there are tons of use cases",
    "start": "507050",
    "end": "512479"
  },
  {
    "text": "where the abstraction has to be an API call I don't want to build that model it's an image recognition problem and",
    "start": "512479",
    "end": "519849"
  },
  {
    "text": "Amazon recognition has a vast data set train and if I try to build it it will",
    "start": "519849",
    "end": "525500"
  },
  {
    "text": "take me time I'll get there but it'll take me time so I could use an API like Amazon recognition and go with eight",
    "start": "525500",
    "end": "533720"
  },
  {
    "text": "different type of image classifications I get I can even read text now like recently",
    "start": "533720",
    "end": "540410"
  },
  {
    "text": "Amazon recognition announced that you can read text like license plates and things like that",
    "start": "540410",
    "end": "545560"
  },
  {
    "text": "imagine the use cases it enables from just that takes text reading the other",
    "start": "545560",
    "end": "553370"
  },
  {
    "text": "primitive that I need to build my service is a container deploying one",
    "start": "553370",
    "end": "559430"
  },
  {
    "text": "container is super easy docker did that you can say docker run on your laptop and it works but imagined deploying",
    "start": "559430",
    "end": "567470"
  },
  {
    "text": "thousands of containers on thousands of nodes so you are deploying mmm",
    "start": "567470",
    "end": "574730"
  },
  {
    "text": "containers on end nodes and you're trying to solve now an O of N squared",
    "start": "574730",
    "end": "581150"
  },
  {
    "text": "problem which is a really hard problem to solve which is called cluster management so at Amazon we build Amazon",
    "start": "581150",
    "end": "588650"
  },
  {
    "text": "elastic container service which basically is a cluster management engine",
    "start": "588650",
    "end": "595190"
  },
  {
    "text": "where we know or we keep track of the state of your containers what container is deployed where what are the",
    "start": "595190",
    "end": "602480"
  },
  {
    "text": "configurations for it what other what are the parameters how should it scale all of that we put in the cluster",
    "start": "602480",
    "end": "609680"
  },
  {
    "text": "management server engine we have an API that you can access this wire and we",
    "start": "609680",
    "end": "614870"
  },
  {
    "text": "also have an agent communications service which talks to the instances or the nodes where the Aged containers are",
    "start": "614870",
    "end": "621770"
  },
  {
    "text": "deployed so the easiest agent every instance that you launch has an ECS",
    "start": "621770",
    "end": "627230"
  },
  {
    "text": "agent which is my communication channel back to the cluster management service i",
    "start": "627230",
    "end": "633040"
  },
  {
    "text": "group a bunch of containers and call it a task a task is a logical unit which",
    "start": "633040",
    "end": "639740"
  },
  {
    "text": "very roughly could translate to an app or a service and i can scale it horizontally and say I want to run",
    "start": "639740",
    "end": "646310"
  },
  {
    "text": "hundred copies of this app and it just does it for me I confront this with a",
    "start": "646310",
    "end": "652070"
  },
  {
    "text": "load balancer so if I have a spike I need a shock absorber I need to be able",
    "start": "652070",
    "end": "657890"
  },
  {
    "text": "to take that 1 million requests per second and distribute it down to the",
    "start": "657890",
    "end": "663980"
  },
  {
    "text": "containers and service those requests so the load balancer gives you that and it's a fully managed service that",
    "start": "663980",
    "end": "670879"
  },
  {
    "text": "you do not have to do the cluster management you just launch the cluster and it works one of the things that I",
    "start": "670879",
    "end": "678649"
  },
  {
    "text": "always talk to developers about and how we have a conversation is this is not an",
    "start": "678649",
    "end": "684439"
  },
  {
    "text": "easy problem and as a developer I don't care only when the development platform does",
    "start": "684439",
    "end": "692029"
  },
  {
    "text": "not break ask yourself and how many of us have been in that situation in our",
    "start": "692029",
    "end": "698089"
  },
  {
    "text": "development lives when the platform breaks that's a whole different emotion",
    "start": "698089",
    "end": "704239"
  },
  {
    "text": "that we go through and and what we come out with but that's what Amazon ECS is built for operational efficiency deep",
    "start": "704239",
    "end": "710749"
  },
  {
    "text": "integrations into the platform security logging monitoring all of that all the",
    "start": "710749",
    "end": "716599"
  },
  {
    "text": "goodness of the ablest platform that you are used to so I talked about the AI",
    "start": "716599",
    "end": "723769"
  },
  {
    "text": "engineer or the data scientist what he uses I talked about the app the DevOps",
    "start": "723769",
    "end": "729409"
  },
  {
    "text": "and the application development part of it but what about building a pipeline which releases superfast if I have a new",
    "start": "729409",
    "end": "737209"
  },
  {
    "text": "model which I train tonight I want that model to be consumed tomorrow morning or maybe during the",
    "start": "737209",
    "end": "743089"
  },
  {
    "text": "night to give me better predictions kind of a continuous predictive model and for",
    "start": "743089",
    "end": "749359"
  },
  {
    "text": "that we have a set of tools we call as developer tools like code commit is a",
    "start": "749359",
    "end": "754699"
  },
  {
    "text": "manage private git repository code pipeline is our pipeline tool and code build is a managed build environment and",
    "start": "754699",
    "end": "762229"
  },
  {
    "text": "code deploy automates deployments you can take this primitives and build your very custom or specific developer",
    "start": "762229",
    "end": "769459"
  },
  {
    "text": "workflow but let's say you're getting started or you want a templatized approach you can go code start and you",
    "start": "769459",
    "end": "776959"
  },
  {
    "text": "can say this is my app do this for me and it just does it so enough of products and primitives that we needed",
    "start": "776959",
    "end": "784699"
  },
  {
    "text": "to understand by when we get it into the into the into how we are building this so let's get into into how to do this so",
    "start": "784699",
    "end": "793279"
  },
  {
    "text": "I'm a data scientist I am working on amazing algorithms I have a large data",
    "start": "793279",
    "end": "798379"
  },
  {
    "text": "set I'm crunching and I live on an ec2 instance and i live in the",
    "start": "798379",
    "end": "804889"
  },
  {
    "text": "jupiter notebook which is pretty popular as a data science tool i trained my model continuously and i run those model",
    "start": "804889",
    "end": "813079"
  },
  {
    "text": "models and amazon has opened so or",
    "start": "813079",
    "end": "818179"
  },
  {
    "text": "published armies that you can just click and it comes up with a jupiter notebook so you do not have to install it but",
    "start": "818179",
    "end": "824749"
  },
  {
    "text": "that's where i live and i might be uploading my models which is basically the the templates that get generated",
    "start": "824749",
    "end": "830920"
  },
  {
    "text": "into Amazon s3 which is a durable scalable data store because I have more",
    "start": "830920",
    "end": "837799"
  },
  {
    "text": "models not to get lost or not to get deleted and things like that as an",
    "start": "837799",
    "end": "842959"
  },
  {
    "text": "application developer my life is I want to write code on my laptop on my local",
    "start": "842959",
    "end": "850819"
  },
  {
    "text": "environment and push this code to a code repository package it push it",
    "start": "850819",
    "end": "857059"
  },
  {
    "text": "write the docker file and push it that's where like that's nirvana for me and magically the app should use it I also",
    "start": "857059",
    "end": "865549"
  },
  {
    "text": "have a mobile client so I have mobile developers who needs to use it but to",
    "start": "865549",
    "end": "872089"
  },
  {
    "text": "make this all real I need a container management solution a platform that",
    "start": "872089",
    "end": "878329"
  },
  {
    "text": "scales that I can deploy my applications to the compute where I can run so what",
    "start": "878329",
    "end": "884899"
  },
  {
    "text": "you see on this box that came out Amazon",
    "start": "884899",
    "end": "891079"
  },
  {
    "text": "ECS clusters are provisioned when you say create cluster you can provision those clusters put them on auto scaling",
    "start": "891079",
    "end": "896959"
  },
  {
    "text": "you can have different type of instances on-demand instances spot instances you",
    "start": "896959",
    "end": "903379"
  },
  {
    "text": "confront it with an application load balancer which I talked about which is a shock absorber kind of a deal and you",
    "start": "903379",
    "end": "909139"
  },
  {
    "text": "can put a DNS in front which gives you a friendly name and I also have a private",
    "start": "909139",
    "end": "914899"
  },
  {
    "text": "image repository that I can use to store my docker images I don't want my images",
    "start": "914899",
    "end": "921139"
  },
  {
    "text": "to be stored on a public repo I want them to be controlled in a secure environment I also want to log all my",
    "start": "921139",
    "end": "928009"
  },
  {
    "text": "metrics and logs into cloud watch because monitoring and logging is super important for me now all of this you can",
    "start": "928009",
    "end": "935149"
  },
  {
    "text": "go to the Western experience and create this as you go or download a CloudFormation",
    "start": "935149",
    "end": "941600"
  },
  {
    "text": "template from github we have open sourced a bunch of projects and deploy",
    "start": "941600",
    "end": "946730"
  },
  {
    "text": "this there's also the DevOps part of the",
    "start": "946730",
    "end": "951950"
  },
  {
    "text": "ops part of this which basically is worried about creating the cluster which",
    "start": "951950",
    "end": "957110"
  },
  {
    "text": "we went into details about but also building a fast release cycle which is",
    "start": "957110",
    "end": "962570"
  },
  {
    "text": "how do I build my pipeline so my developers can push code and it gets deployed by the second or the minute",
    "start": "962570",
    "end": "968830"
  },
  {
    "text": "build it in a scalable way so that I am not running build servers on my side and",
    "start": "968830",
    "end": "975710"
  },
  {
    "text": "spending money for idle time so if I've",
    "start": "975710",
    "end": "981920"
  },
  {
    "text": "done this right what I do is I I upload my model into Amazon s3 on the App side",
    "start": "981920",
    "end": "989510"
  },
  {
    "text": "I write a docker file which I kind of extend from MX net and I do my own",
    "start": "989510",
    "end": "994640"
  },
  {
    "text": "Python app that I can inject in and basically said docker copy here on an",
    "start": "994640",
    "end": "1000700"
  },
  {
    "text": "entry point as such and things and I build that image honor on a on a build",
    "start": "1000700",
    "end": "1006010"
  },
  {
    "text": "server like code build and I push that image into a repository like Amazon ECR",
    "start": "1006010",
    "end": "1011940"
  },
  {
    "text": "that's the that's the happy part of the workflow the CloudFormation provisioned",
    "start": "1011940",
    "end": "1017680"
  },
  {
    "text": "my cluster my application developer pushed his code and my devops has built",
    "start": "1017680",
    "end": "1023500"
  },
  {
    "text": "a pipeline where which gets triggered every time code is committed a pipeline is triggered and the pipeline does build",
    "start": "1023500",
    "end": "1031030"
  },
  {
    "text": "and from the build environment I can push code to amazon ECR one of the things I love about code billed as a",
    "start": "1031030",
    "end": "1037600"
  },
  {
    "text": "developer is I can script things into it I can have a pre command a build comma",
    "start": "1037600",
    "end": "1043300"
  },
  {
    "text": "build stage and a post build stage and what I can do is I can call other api's I can call an image scanning API in this",
    "start": "1043300",
    "end": "1051490"
  },
  {
    "text": "case I'm calling an EC s API and you see our API which is dhaka push right from",
    "start": "1051490",
    "end": "1057310"
  },
  {
    "text": "my build script so what does this look at the end of the day so on the mobile",
    "start": "1057310",
    "end": "1063370"
  },
  {
    "text": "developer side I'm calling an API that's all I'm calling I'm calling",
    "start": "1063370",
    "end": "1069280"
  },
  {
    "text": "my product calm / predict and what I get what I'm trying to do here is I'm trying",
    "start": "1069280",
    "end": "1074680"
  },
  {
    "text": "to predict what is this picture that this guy is taking or standing in front",
    "start": "1074680",
    "end": "1079930"
  },
  {
    "text": "of and soda I can give him valuable deals or maybe give some facts around it",
    "start": "1079930",
    "end": "1087010"
  },
  {
    "text": "and I've used my machine learning algorithm to predict with like in this",
    "start": "1087010",
    "end": "1093700"
  },
  {
    "text": "case around eleven percent probability this is the suspension bridge that's",
    "start": "1093700",
    "end": "1099490"
  },
  {
    "text": "valuable information to know from a mobile app experience that I'm near the Golden Gate Bridge and then you can",
    "start": "1099490",
    "end": "1106840"
  },
  {
    "text": "build many experiences around it so that's the happy path I've uploaded my",
    "start": "1106840",
    "end": "1112210"
  },
  {
    "text": "model my model gets getting consumed my code what if let's talk about tonight I ran a",
    "start": "1112210",
    "end": "1118570"
  },
  {
    "text": "new prediction algorithm or training algorithm and I have a new model that",
    "start": "1118570",
    "end": "1123990"
  },
  {
    "text": "model gets uploaded to s3 and the change is literally let me go back is your code",
    "start": "1123990",
    "end": "1132570"
  },
  {
    "text": "reading the new model from SC MX net has api's for s3 and you can go tensorflow",
    "start": "1132570",
    "end": "1139750"
  },
  {
    "text": "and other things you for your code can read the new model and if you have a new",
    "start": "1139750",
    "end": "1146380"
  },
  {
    "text": "application perspective you can go through the same pipeline and trigger it and build deploy that on ECR in a",
    "start": "1146380",
    "end": "1155860"
  },
  {
    "text": "rolling fashion like one two three four and all your applications are or",
    "start": "1155860",
    "end": "1161170"
  },
  {
    "text": "containers scale with the same image so you've made it a repeatable process to",
    "start": "1161170",
    "end": "1167500"
  },
  {
    "text": "deploy AI enable applications and I also believe that today a big barrier of",
    "start": "1167500",
    "end": "1176520"
  },
  {
    "text": "communication is the language our data scientist speaks a different language than a DevOps engineer versus an app",
    "start": "1176520",
    "end": "1183610"
  },
  {
    "text": "developer we could use s3 as that communication model or the communication",
    "start": "1183610",
    "end": "1190690"
  },
  {
    "text": "hub where I can read the model and let my code do the translation for me I read",
    "start": "1190690",
    "end": "1197800"
  },
  {
    "text": "a new model using a Mac Schneider API it understands the model and moves on you still need to talk to the",
    "start": "1197800",
    "end": "1203630"
  },
  {
    "text": "data scientist you still need to talk to DevOps engineer people have to collaborate to make it happen but your",
    "start": "1203630",
    "end": "1209030"
  },
  {
    "text": "code can interpret models and the pipeline in a much more efficient manner",
    "start": "1209030",
    "end": "1214190"
  },
  {
    "text": "and what you end up with is this fast efficient life cycle of your AI app",
    "start": "1214190",
    "end": "1221150"
  },
  {
    "text": "enabled application on containers that you can release by the hour if possible",
    "start": "1221150",
    "end": "1226640"
  },
  {
    "text": "or even even shorter I talked and when I",
    "start": "1226640",
    "end": "1232040"
  },
  {
    "text": "push this new code let me go back when I push this new model and I've changed my",
    "start": "1232040",
    "end": "1238370"
  },
  {
    "text": "code and I want to update the service I want to say okay I've written a new",
    "start": "1238370",
    "end": "1244040"
  },
  {
    "text": "feature released a new feature which uses this new model all I do is called the update service API on ECS what it",
    "start": "1244040",
    "end": "1253340"
  },
  {
    "text": "does is it takes the new image that was formed or built and it deploys it on all",
    "start": "1253340",
    "end": "1260300"
  },
  {
    "text": "the containers and it scales it to the number of tasks that you wanted and based on your spike of your traffic as",
    "start": "1260300",
    "end": "1267890"
  },
  {
    "text": "you go now going back five years from now before this all this was really",
    "start": "1267890",
    "end": "1274940"
  },
  {
    "text": "black magic to me personally but today machine learning is a part of our lives",
    "start": "1274940",
    "end": "1280250"
  },
  {
    "text": "deep learning is a part of our lives and I am an optimist I believe deep learning",
    "start": "1280250",
    "end": "1286610"
  },
  {
    "text": "will make our lives better as we go and will help us do those things that we",
    "start": "1286610",
    "end": "1292220"
  },
  {
    "text": "wanted to do because we have spare brain",
    "start": "1292220",
    "end": "1297320"
  },
  {
    "text": "cycles that we can spend on them and I have discussed this at length with many of many of my friends I would like to",
    "start": "1297320",
    "end": "1305990"
  },
  {
    "text": "invite you to give it a spin this is a blog which is published a bunch of",
    "start": "1305990",
    "end": "1311030"
  },
  {
    "text": "customers have used it there's a QR code which makes it a little easier to go",
    "start": "1311030",
    "end": "1316370"
  },
  {
    "text": "there but and this reference in the blog you will also find a reference architecture the whole code is open",
    "start": "1316370",
    "end": "1322640"
  },
  {
    "text": "sourced the CloudFormation template the app and all of it give it a spin launch",
    "start": "1322640",
    "end": "1327980"
  },
  {
    "text": "it in your AWS account and see if you can build AI AI based applications and",
    "start": "1327980",
    "end": "1334430"
  },
  {
    "text": "put AI into the patience you have with that I would like to invite akuto from cook pad to talk",
    "start": "1334430",
    "end": "1342420"
  },
  {
    "text": "about what did cook Pat do for machine learning on containers so I'll switch",
    "start": "1342420",
    "end": "1348240"
  },
  {
    "text": "over to Aikido Hokuto thank you Steve hello thanks for coming",
    "start": "1348240",
    "end": "1357270"
  },
  {
    "text": "to our session my name is hook - Hoshi I'm the head of",
    "start": "1357270",
    "end": "1362370"
  },
  {
    "text": "the infrastructure to cook fred and responsible for site reliability engineering today we are going to share",
    "start": "1362370",
    "end": "1371910"
  },
  {
    "text": "the story or how we breathe the containerized machine learning workload",
    "start": "1371910",
    "end": "1376919"
  },
  {
    "text": "on AWS how many of you know good but ok",
    "start": "1376919",
    "end": "1385500"
  },
  {
    "text": "yeah first let me introduce our company do like cooking they're cooking",
    "start": "1385500",
    "end": "1393200"
  },
  {
    "text": "cook Fatih is an all-round SP sharing and such service we are best in Japan",
    "start": "1393200",
    "end": "1400230"
  },
  {
    "text": "and were founded in 1998 since 1998 COO",
    "start": "1400230",
    "end": "1406140"
  },
  {
    "text": "Claude has been providing online despairing and such services our",
    "start": "1406140",
    "end": "1411360"
  },
  {
    "text": "corporate mission is make everyday cooking fun and our services currently",
    "start": "1411360",
    "end": "1417510"
  },
  {
    "text": "hosts over 2.7 million user generated base piece and with about 60 million",
    "start": "1417510",
    "end": "1424590"
  },
  {
    "text": "users in Japan visiting us each month it is the largest online recipe sharing and",
    "start": "1424590",
    "end": "1431549"
  },
  {
    "text": "search service in Japan earned via global we are operating in 67 countries",
    "start": "1431549",
    "end": "1439290"
  },
  {
    "text": "and support 21 languages for the United States you can access our service at",
    "start": "1439290",
    "end": "1445710"
  },
  {
    "text": "koco.com rush us we have offices in Japan and UK and Spain",
    "start": "1445710",
    "end": "1452760"
  },
  {
    "text": "Indonesia and so on we have about 150",
    "start": "1452760",
    "end": "1459210"
  },
  {
    "text": "developers to host the services with a 9sr is and 9 machine learning engineers",
    "start": "1459210",
    "end": "1466140"
  },
  {
    "text": "to support we have been learning all systems on a SS since 2011 we are",
    "start": "1466140",
    "end": "1474660"
  },
  {
    "text": "using SES for our service and we learned over 200 CCS services now let us explain",
    "start": "1474660",
    "end": "1483960"
  },
  {
    "text": "cooking log in Japanese geology local which is our first deep learning part",
    "start": "1483960",
    "end": "1489810"
  },
  {
    "text": "feature have you taken photos when you cook some",
    "start": "1489810",
    "end": "1496440"
  },
  {
    "text": "people take photos or what they cook and eat to record and look back on the",
    "start": "1496440",
    "end": "1502890"
  },
  {
    "text": "memories that is to moisture the dietary habit or to share them with family and",
    "start": "1502890",
    "end": "1510210"
  },
  {
    "text": "friends and communities however sometimes it is troublesome to find such",
    "start": "1510210",
    "end": "1517110"
  },
  {
    "text": "real photos from your smartphone camera memory in order to make that process",
    "start": "1517110",
    "end": "1524640"
  },
  {
    "text": "easier we developed cooking log which automatically finds food photos from",
    "start": "1524640",
    "end": "1530370"
  },
  {
    "text": "your camera roll it is prod by convolutional neural network which is",
    "start": "1530370",
    "end": "1535860"
  },
  {
    "text": "one of their logics for machine learning so let's watch a demo video of this",
    "start": "1535860",
    "end": "1542340"
  },
  {
    "text": "picture this is a bureau run under a",
    "start": "1542340",
    "end": "1548310"
  },
  {
    "text": "smartphone as we can see there are many",
    "start": "1548310",
    "end": "1555300"
  },
  {
    "text": "kinds of photos in the camera roll and there are some food photos however there",
    "start": "1555300",
    "end": "1562710"
  },
  {
    "text": "are also other kind or photos like a Korean and flower and scenery and so on",
    "start": "1562710",
    "end": "1571610"
  },
  {
    "text": "yeah it is yeah this is a new Mona which",
    "start": "1571610",
    "end": "1578820"
  },
  {
    "text": "is one of my favorite Japanese fruits people who want to keep a record of the",
    "start": "1578820",
    "end": "1584970"
  },
  {
    "text": "dishes I launched a quick cut off unsearched the cooking log so loading",
    "start": "1584970",
    "end": "1594890"
  },
  {
    "text": "photos from coming low yeah",
    "start": "1594890",
    "end": "1601860"
  },
  {
    "text": "as we just saw their food photos were automatically uploaded and are covered",
    "start": "1601860",
    "end": "1607760"
  },
  {
    "text": "this is a future this which is now used",
    "start": "1607760",
    "end": "1613049"
  },
  {
    "text": "by many users today over 140,000 users",
    "start": "1613049",
    "end": "1618090"
  },
  {
    "text": "have stood over 12 million food photos let me introduce this feature from the",
    "start": "1618090",
    "end": "1625740"
  },
  {
    "text": "technical side it is our first feature that that is using deep learning so",
    "start": "1625740",
    "end": "1632700"
  },
  {
    "text": "there are some challenges it was the first time for us to run a similar time",
    "start": "1632700",
    "end": "1639179"
  },
  {
    "text": "mesh classification with production and thus workload was different from common",
    "start": "1639179",
    "end": "1644909"
  },
  {
    "text": "web applications what we especially needed in developing such features was",
    "start": "1644909",
    "end": "1651120"
  },
  {
    "text": "the Scarab infrastructure for new workers and our isolated environments for new challenges",
    "start": "1651120",
    "end": "1658250"
  },
  {
    "text": "we bred it using AWS and containers I",
    "start": "1658250",
    "end": "1663919"
  },
  {
    "text": "will explain what careful infrastructure is first we needed a scalable",
    "start": "1663919",
    "end": "1670649"
  },
  {
    "text": "infrastructure that enabled massive photo uploading and semi their time image classification because clients",
    "start": "1670649",
    "end": "1679169"
  },
  {
    "text": "send a lot of tiny summoners every time they take photos this traffic is",
    "start": "1679169",
    "end": "1685320"
  },
  {
    "text": "difficult to predict there is also the possibility that topic could spike when",
    "start": "1685320",
    "end": "1692970"
  },
  {
    "text": "this feature was introduced on television for beta user experience we",
    "start": "1692970",
    "end": "1699360"
  },
  {
    "text": "have to keep this feature at a constant performance at all times so we choose",
    "start": "1699360",
    "end": "1707250"
  },
  {
    "text": "some asynchronous architecture uploading and classification takes a few",
    "start": "1707250",
    "end": "1712830"
  },
  {
    "text": "milliseconds or longer and it's sometimes Brooks our application processing that was",
    "start": "1712830",
    "end": "1718470"
  },
  {
    "text": "written by Ruby on Rails we decided to use the pre signed URL of Amazon s3 and",
    "start": "1718470",
    "end": "1725010"
  },
  {
    "text": "upload the image directory from the client to s3 also we enabled SEO notification",
    "start": "1725010",
    "end": "1734970"
  },
  {
    "text": "it has requests of classification for uploaded thumbnails to us s qsq in order",
    "start": "1734970",
    "end": "1743940"
  },
  {
    "text": "to carry out deep running in production isolation of the environment was also",
    "start": "1743940",
    "end": "1749730"
  },
  {
    "text": "necessary image classification was a three men stratification software was",
    "start": "1749730",
    "end": "1756750"
  },
  {
    "text": "written using a different language than we used and it has a different worker from web application finally in many",
    "start": "1756750",
    "end": "1765360"
  },
  {
    "text": "cases software for deep learning demand GPUs this is a clearly different point",
    "start": "1765360",
    "end": "1772680"
  },
  {
    "text": "from the web application that we have developed in the past so we decided to",
    "start": "1772680",
    "end": "1780000"
  },
  {
    "text": "create such an environment in a container containers can isolate new",
    "start": "1780000",
    "end": "1786900"
  },
  {
    "text": "language impairment and GPU driver and various settings we ran this continuum",
    "start": "1786900",
    "end": "1793770"
  },
  {
    "text": "in CS with jitter extra large instances in addition Amazon ECS provides managed",
    "start": "1793770",
    "end": "1802410"
  },
  {
    "text": "and scalable toka environment which makes it easy to scare also we have",
    "start": "1802410",
    "end": "1809040"
  },
  {
    "text": "already learned a lot of containers on PCs let me introduce the architecture of",
    "start": "1809040",
    "end": "1816180"
  },
  {
    "text": "this feature using figures at first the client requests our API server to issue",
    "start": "1816180",
    "end": "1823590"
  },
  {
    "text": "a pre signed URL or a three the API generates and returns it to the client",
    "start": "1823590",
    "end": "1832010"
  },
  {
    "text": "next the client approached a very small thumbnails to the s3 pocket at the",
    "start": "1832010",
    "end": "1840000"
  },
  {
    "text": "mention area we enabled s3 notification so the s3 include the event to ask us",
    "start": "1840000",
    "end": "1847800"
  },
  {
    "text": "when the image approach is completed the",
    "start": "1847800",
    "end": "1852870"
  },
  {
    "text": "image classification that is learning on ECS they choose the event from sqs and",
    "start": "1852870",
    "end": "1857970"
  },
  {
    "text": "download the thumbnail and classifies it after that dessert of classification are",
    "start": "1857970",
    "end": "1865140"
  },
  {
    "text": "sent to the API server the API server removes numerous images",
    "start": "1865140",
    "end": "1871430"
  },
  {
    "text": "that is not classified as food this is",
    "start": "1871430",
    "end": "1877130"
  },
  {
    "text": "my architecture with direct upload to s3 and using SQS we could create a scalable",
    "start": "1877130",
    "end": "1883910"
  },
  {
    "text": "architecture without preparing image approach server even if a Bronto of",
    "start": "1883910",
    "end": "1891260"
  },
  {
    "text": "uploaded images increases the image classification that is learning on ECS",
    "start": "1891260",
    "end": "1896390"
  },
  {
    "text": "scales that quickly and depending on the queue length of sqs the api server only",
    "start": "1896390",
    "end": "1904250"
  },
  {
    "text": "needs to issue the resign URL of s3 at first and then wait for classification",
    "start": "1904250",
    "end": "1911120"
  },
  {
    "text": "results from ICS so what is happening in",
    "start": "1911120",
    "end": "1917690"
  },
  {
    "text": "the container I will hand it off to you and he will explain the image",
    "start": "1917690",
    "end": "1923540"
  },
  {
    "text": "classification in detail its monochrome",
    "start": "1923540",
    "end": "1933050"
  },
  {
    "text": "cool thanks octo hey I'm going to take",
    "start": "1933050",
    "end": "1938750"
  },
  {
    "text": "over session and then I'll talk about a bit more detail about what is happening inside the container",
    "start": "1938750",
    "end": "1946450"
  },
  {
    "text": "well I mutual yeah I'm so excited to be here on stage I bought a new jacket for",
    "start": "1946450",
    "end": "1954170"
  },
  {
    "text": "today then and I've been working for cook pad for one and a half year and I'm",
    "start": "1954170",
    "end": "1962870"
  },
  {
    "text": "working as an engineer in research and our research and development division",
    "start": "1962870",
    "end": "1969340"
  },
  {
    "text": "which means that my speciality is that I'm in charge of making sure that our",
    "start": "1969340",
    "end": "1974840"
  },
  {
    "text": "researchers can access our data or GPU computational environments easily and",
    "start": "1974840",
    "end": "1980480"
  },
  {
    "text": "fast consider it concentrate on their creativity this is yeah anyways first",
    "start": "1980480",
    "end": "1989210"
  },
  {
    "text": "I'm going to explain what that the actual task in a CAS cluster is",
    "start": "1989210",
    "end": "1995090"
  },
  {
    "text": "container is actually doing from the access token to realization of",
    "start": "1995090",
    "end": "2001420"
  },
  {
    "text": "running well as hock to explain before",
    "start": "2001420",
    "end": "2008610"
  },
  {
    "text": "the task that the things tasks doing is that task first gets the image from this",
    "start": "2008610",
    "end": "2015370"
  },
  {
    "text": "Li and also tasks will they cure the the the message from the SKS and also to get",
    "start": "2015370",
    "end": "2024040"
  },
  {
    "text": "a sorry the the death task first download the classifier yeah",
    "start": "2024040",
    "end": "2029920"
  },
  {
    "text": "the model from s3 and they set it up and it has to also the acute message from",
    "start": "2029920",
    "end": "2035620"
  },
  {
    "text": "the sqs and downloaded emails from nicely yes that's right and the test",
    "start": "2035620",
    "end": "2040870"
  },
  {
    "text": "next doing the actual image classification and we'll send the result back to the IPS server that's it",
    "start": "2040870",
    "end": "2049530"
  },
  {
    "text": "so what we need to develop is are",
    "start": "2050190",
    "end": "2056980"
  },
  {
    "text": "basically two things to make it a whole system work which is a classifier of",
    "start": "2056980",
    "end": "2062530"
  },
  {
    "text": "course and the the the doc image which actually doing that the the procedure I",
    "start": "2062530",
    "end": "2069940"
  },
  {
    "text": "explained and maybe as as if explains",
    "start": "2069940",
    "end": "2076210"
  },
  {
    "text": "the classical classifier could be set to large file so it it's better to store",
    "start": "2076210",
    "end": "2081429"
  },
  {
    "text": "the Nestle which is a scalable durable and capable of handling the large files",
    "start": "2081429",
    "end": "2087899"
  },
  {
    "text": "yeah and the blog posts or researchers to build their model train it and save",
    "start": "2087900",
    "end": "2094870"
  },
  {
    "text": "it to the to the SC that's the first thing to do and the developer also needs",
    "start": "2094870",
    "end": "2100450"
  },
  {
    "text": "to do to implement the task itself yeah and and also when we use the easiest we",
    "start": "2100450",
    "end": "2112720"
  },
  {
    "text": "need a task definition of course the for",
    "start": "2112720",
    "end": "2119800"
  },
  {
    "text": "tasks easiest task definitions we like to we light it to make it easy to manage",
    "start": "2119800",
    "end": "2129370"
  },
  {
    "text": "or easy to write also so that the each developer can write it",
    "start": "2129370",
    "end": "2135280"
  },
  {
    "text": "for their own applications and with that communicating with asperity it's already",
    "start": "2135280",
    "end": "2141430"
  },
  {
    "text": "team for example there is an open-source Ruby library code Jaco Haq which is",
    "start": "2141430",
    "end": "2148990"
  },
  {
    "text": "loved by one of our engineers and we are utilizing it to to write a task",
    "start": "2148990",
    "end": "2155740"
  },
  {
    "text": "definition down yamo format file and manage it it on the version control",
    "start": "2155740",
    "end": "2161950"
  },
  {
    "text": "systems yeah on the right right hand side we you can say the one example the",
    "start": "2161950",
    "end": "2168160"
  },
  {
    "text": "hackle the task definition file for easy s yeah and I'm going to explain the",
    "start": "2168160",
    "end": "2177310"
  },
  {
    "text": "reason why we don't directly call the ACS API but instead we use hackle and",
    "start": "2177310",
    "end": "2182880"
  },
  {
    "text": "that called the EC s AP in directory first of all we needed to perform high",
    "start": "2182880",
    "end": "2191349"
  },
  {
    "text": "level operations on the ec s like deployed a new version of application or",
    "start": "2191349",
    "end": "2196420"
  },
  {
    "text": "rollback yet and according to that for example the gate commit hash a revision",
    "start": "2196420",
    "end": "2204220"
  },
  {
    "text": "or whatever you want to refer and you",
    "start": "2204220",
    "end": "2209339"
  },
  {
    "text": "when you decide which version to deploy or rollback and we also have a common or",
    "start": "2209339",
    "end": "2215349"
  },
  {
    "text": "repetitive common common and repeated operations like injecting sake security",
    "start": "2215349",
    "end": "2223770"
  },
  {
    "text": "environment variables or or maybe the",
    "start": "2223770",
    "end": "2228820"
  },
  {
    "text": "resistor in the service to our own local DNS or we may use another proxy",
    "start": "2228820",
    "end": "2236859"
  },
  {
    "text": "container we may need another proxy container for logging those kind of the",
    "start": "2236859",
    "end": "2243160"
  },
  {
    "text": "comma and repeated the operation operation is is it is frequent reappears",
    "start": "2243160",
    "end": "2249460"
  },
  {
    "text": "right and yeah I think it's it's also I",
    "start": "2249460",
    "end": "2255460"
  },
  {
    "text": "think the in the most case each company where each team has this kind of you",
    "start": "2255460",
    "end": "2261609"
  },
  {
    "text": "know operations set of operations we need to perform every time a deployed",
    "start": "2261609",
    "end": "2267310"
  },
  {
    "text": "new version of application yeah things like that so for these",
    "start": "2267310",
    "end": "2275289"
  },
  {
    "text": "reasons we use the hackls functionality to perform deploying aerobic operations",
    "start": "2275289",
    "end": "2280869"
  },
  {
    "text": "and also making use of pluggable scraped up architecture where we can trigger and",
    "start": "2280869",
    "end": "2288579"
  },
  {
    "text": "the arbitrary operations before or after deployment and it adds a result our",
    "start": "2288579",
    "end": "2297420"
  },
  {
    "text": "process of a deploying new application or new version is it's very easy so that",
    "start": "2297420",
    "end": "2305470"
  },
  {
    "text": "a each developer can can can do it with it without much communication with infra team now we have a test implementation",
    "start": "2305470",
    "end": "2316450"
  },
  {
    "text": "and it's docker image on the task definition file all set up and now are",
    "start": "2316450",
    "end": "2324849"
  },
  {
    "text": "going to be a little bit more detailed about about the task itself since those",
    "start": "2324849",
    "end": "2334049"
  },
  {
    "text": "gpu-accelerated instances had much higher throughput of image classification compared to the other CPU",
    "start": "2334049",
    "end": "2341470"
  },
  {
    "text": "instances in the you know in a similar price ranges so the reason we decided to",
    "start": "2341470",
    "end": "2347950"
  },
  {
    "text": "use a GPU accelerated instances for this workload and I'm talking about the in",
    "start": "2347950",
    "end": "2353619"
  },
  {
    "text": "furnaces and their own production application and we would we will show",
    "start": "2353619",
    "end": "2358809"
  },
  {
    "text": "you some tips or practices from our experiences running GP workers on the",
    "start": "2358809",
    "end": "2365440"
  },
  {
    "text": "ACS for a while well the first of all to run GPU workers on the ACS we first need",
    "start": "2365440",
    "end": "2372910"
  },
  {
    "text": "to configure the dedicated Mui for a cluster because Nvidia driver of a GPU",
    "start": "2372910",
    "end": "2379359"
  },
  {
    "text": "consists of a user library such as shared object or kind of modules which I",
    "start": "2379359",
    "end": "2387460"
  },
  {
    "text": "needed to be installed to the cluster not in the container yeah and because",
    "start": "2387460",
    "end": "2395200"
  },
  {
    "text": "both kernel module around the user level they are tightly bound I mean talking about the Nvidia driver",
    "start": "2395200",
    "end": "2402240"
  },
  {
    "text": "it's titled bounding in their version so it is better to install both kernel",
    "start": "2402240",
    "end": "2407280"
  },
  {
    "text": "module on the use of liabilities together to the cluster and it's supported me I mean together go to the",
    "start": "2407280",
    "end": "2415170"
  },
  {
    "text": "clusters this is yes and the only other",
    "start": "2415170",
    "end": "2423990"
  },
  {
    "text": "hand the things like a CUDA toolkit can be placed on the task there's the kind",
    "start": "2423990",
    "end": "2430560"
  },
  {
    "text": "of practice since it could be you know CUDA toolkit it's things like that could",
    "start": "2430560",
    "end": "2437430"
  },
  {
    "text": "be changed in the universal depend on a task so that's that's better to store in",
    "start": "2437430",
    "end": "2444300"
  },
  {
    "text": "the in in the container in stove in the container yeah this practice is is is",
    "start": "2444300",
    "end": "2450030"
  },
  {
    "text": "well explained in and builders and video documentation yeah you can check the",
    "start": "2450030",
    "end": "2455339"
  },
  {
    "text": "parameter and at last in ECS when we using the container with GPU we need to",
    "start": "2455339",
    "end": "2462740"
  },
  {
    "text": "set a previous to flag that would open the provision access to the GPU device",
    "start": "2462740",
    "end": "2469530"
  },
  {
    "text": "right and we need to set that flag and",
    "start": "2469530",
    "end": "2475160"
  },
  {
    "text": "actually that was the situation at that time we have we first we first release",
    "start": "2475160",
    "end": "2482670"
  },
  {
    "text": "this application now we have more detailed option like Linux parameters",
    "start": "2482670",
    "end": "2488240"
  },
  {
    "text": "Linux parameters devices options so a year now kind of working on a migrating",
    "start": "2488240",
    "end": "2495030"
  },
  {
    "text": "from the previous boss to do to relax parameters options all right",
    "start": "2495030",
    "end": "2502670"
  },
  {
    "text": "so now we have almost everything set up I'm going to continue with data explanation on how we built food or no",
    "start": "2503010",
    "end": "2511740"
  },
  {
    "text": "food image classifier in our project so I'm gonna talk it about the machine learning from now well alright so some",
    "start": "2511740",
    "end": "2528359"
  },
  {
    "text": "of you may already know that image classification in in in the area of deep",
    "start": "2528359",
    "end": "2535560"
  },
  {
    "text": "learning it's it's may be said to be the",
    "start": "2535560",
    "end": "2541890"
  },
  {
    "text": "sole program which means that regarding to the result from the recent academic",
    "start": "2541890",
    "end": "2548990"
  },
  {
    "text": "competitions the models can distinguish things better than human so it is true",
    "start": "2548990",
    "end": "2559740"
  },
  {
    "text": "that we can build working classifier by just collect enough number of labor the",
    "start": "2559740",
    "end": "2565200"
  },
  {
    "text": "data set and this time food photos from cook pet and no food photos know for the photos",
    "start": "2565200",
    "end": "2570330"
  },
  {
    "text": "will run down food from the open dataset yeah they may include some food photos",
    "start": "2570330",
    "end": "2576359"
  },
  {
    "text": "but it's it's only a few and then and we can just perform a supervised learning",
    "start": "2576359",
    "end": "2582840"
  },
  {
    "text": "by using the data set the model could be one of those famous",
    "start": "2582840",
    "end": "2588630"
  },
  {
    "text": "pre-training the model like an inception from Google or ResNet or vzz for example",
    "start": "2588630",
    "end": "2593900"
  },
  {
    "text": "yeah it sounds like working but after we",
    "start": "2593900",
    "end": "2602010"
  },
  {
    "text": "shaped out our first version of the classifier we gradually got dialect",
    "start": "2602010",
    "end": "2609270"
  },
  {
    "text": "feedback from our users which says that there is still notable number of non-food photos mistaken as food which",
    "start": "2609270",
    "end": "2617880"
  },
  {
    "text": "means that we that the user has the affordable plushes on the calendar yeah",
    "start": "2617880",
    "end": "2624000"
  },
  {
    "text": "we got this kind of feedback and the yeah are gonna be more detail about that",
    "start": "2624000",
    "end": "2631380"
  },
  {
    "text": "problem that that gland of this problem is called open set problem",
    "start": "2631380",
    "end": "2636490"
  },
  {
    "text": "which means like limitation of the domain of the desert yeah I have much",
    "start": "2636490",
    "end": "2642520"
  },
  {
    "text": "things to discuss about it but I don't know though won't really go details",
    "start": "2642520",
    "end": "2647560"
  },
  {
    "text": "about it right now on the stage so we can discuss about it later and then let's say it's easy to",
    "start": "2647560",
    "end": "2654550"
  },
  {
    "text": "construct a food data set we can just collect the food photos but for no food",
    "start": "2654550",
    "end": "2660210"
  },
  {
    "text": "it's hard for us to construct that that they set for every single thing other",
    "start": "2660210",
    "end": "2665890"
  },
  {
    "text": "foods like curved chairs humans and instead we it is the user practice that",
    "start": "2665890",
    "end": "2673210"
  },
  {
    "text": "we have only one model lovin on food which is called opposite here and then",
    "start": "2673210",
    "end": "2680560"
  },
  {
    "text": "the the put random photos into the data set know for the dataset and let's say",
    "start": "2680560",
    "end": "2688720"
  },
  {
    "text": "we have no photos of plushies in a data set no specific this photo no no no",
    "start": "2688720",
    "end": "2694869"
  },
  {
    "text": "pastures in this set the model could be to checking about this here his answer",
    "start": "2694869",
    "end": "2701220"
  },
  {
    "text": "when the model account the the motor",
    "start": "2701220",
    "end": "2707440"
  },
  {
    "text": "gets that photos of plushies the model could be shaky in his answer so that is",
    "start": "2707440",
    "end": "2715180"
  },
  {
    "text": "a background of a program and so what we did is by investigating the results from",
    "start": "2715180",
    "end": "2721270"
  },
  {
    "text": "our local test set hopefully we have the various things which is looks like food",
    "start": "2721270",
    "end": "2726460"
  },
  {
    "text": "and we will rebuild a date set I will",
    "start": "2726460",
    "end": "2732369"
  },
  {
    "text": "leave it the big data set according to the investigation most physically we put",
    "start": "2732369",
    "end": "2738700"
  },
  {
    "text": "the brushes as a one you know I'll say first a blah blah for example yeah I",
    "start": "2738700",
    "end": "2746220"
  },
  {
    "text": "think this is not that simple but yeah and we succeeded to increase the",
    "start": "2746220",
    "end": "2752230"
  },
  {
    "text": "accuracy in the model yeah ninety seven point nine percent",
    "start": "2752230",
    "end": "2757530"
  },
  {
    "text": "accurate that's good and all right",
    "start": "2757530",
    "end": "2763420"
  },
  {
    "text": "so I'm gonna move on the next topic as",
    "start": "2763420",
    "end": "2768610"
  },
  {
    "text": "as I introduce myself before as I am an engineer in the research and development",
    "start": "2768610",
    "end": "2773870"
  },
  {
    "text": "division I've been interested in making it possible for our researchers data",
    "start": "2773870",
    "end": "2779690"
  },
  {
    "text": "scientists do their work easier the faster now I'm gonna talk about our talk",
    "start": "2779690",
    "end": "2786200"
  },
  {
    "text": "about our infrastructure where we of doing using the databases GPU instances",
    "start": "2786200",
    "end": "2791720"
  },
  {
    "text": "for various experiences experiments sorry let me move on the ask yes okay",
    "start": "2791720",
    "end": "2809880"
  },
  {
    "text": "so we are using an easy to GPX alighted the instances like g23 or PT 2 3 4",
    "start": "2809880",
    "end": "2819030"
  },
  {
    "text": "expect experiments on the data saying of this Sciences not only in the production of course and we wanted those instances",
    "start": "2819030",
    "end": "2827610"
  },
  {
    "text": "on demand so that our researchers conduct their experiments in Perl more",
    "start": "2827610",
    "end": "2835290"
  },
  {
    "text": "multiple resources can conduct the multiple experiments in Perl",
    "start": "2835290",
    "end": "2842120"
  },
  {
    "text": "that's that's the spec and because of that we make use of them and as an",
    "start": "2842120",
    "end": "2847770"
  },
  {
    "text": "machine images - - we are isolated the provisioning of those commonly used components like GPU driver or CUDA",
    "start": "2847770",
    "end": "2855660"
  },
  {
    "text": "toolkit or C UDN and maybe and then we",
    "start": "2855660",
    "end": "2860670"
  },
  {
    "text": "are also making the bikinis or chatbot on slack as an interface where anyone in",
    "start": "2860670",
    "end": "2868350"
  },
  {
    "text": "the channel can create start/stop instances using those same eyes yep and",
    "start": "2868350",
    "end": "2876960"
  },
  {
    "text": "one more thing here is so using Parker by husk hash cope we can automate that",
    "start": "2876960",
    "end": "2884700"
  },
  {
    "text": "the provisioning steps as I said restoring at the Nvidia driver or CUDA to the kit so that we can update my fast",
    "start": "2884700",
    "end": "2895440"
  },
  {
    "text": "and stable ways yeah like this",
    "start": "2895440",
    "end": "2900950"
  },
  {
    "text": "and of course there is",
    "start": "2903440",
    "end": "2908549"
  },
  {
    "text": "there's managed my 4d planning yeah somewhere you may already know that the",
    "start": "2908549",
    "end": "2915000"
  },
  {
    "text": "database it obviously hasn't managed to my fault for the latest version of CUDA",
    "start": "2915000",
    "end": "2922549"
  },
  {
    "text": "for example so which is actually not other was another available at the time",
    "start": "2922549",
    "end": "2929760"
  },
  {
    "text": "we started using CPU so we are now you know on the way to migrating from our",
    "start": "2929760",
    "end": "2935910"
  },
  {
    "text": "in-house ami student managed egg whites anyways alright that's it so so I gonna",
    "start": "2935910",
    "end": "2948839"
  },
  {
    "text": "wrap up session we introduce cooking look using deep learning at scale",
    "start": "2948839",
    "end": "2954890"
  },
  {
    "text": "adopted asynchronous and isolated architecture with ECS yeah and we also",
    "start": "2954890",
    "end": "2962430"
  },
  {
    "text": "make make great great use of databases GPU accelerated the instances for our",
    "start": "2962430",
    "end": "2969180"
  },
  {
    "text": "experience alright so yeah I know you're",
    "start": "2969180",
    "end": "2976319"
  },
  {
    "text": "hiring yeah we have too many offices in Japan and the UK please so yeah if your",
    "start": "2976319",
    "end": "2982109"
  },
  {
    "text": "range those interested in our you know much about infrastructure you know you",
    "start": "2982109",
    "end": "2988890"
  },
  {
    "text": "can contact us yeah thank you [Applause]",
    "start": "2988890",
    "end": "2995689"
  },
  {
    "text": "well thank you akuto Ichiro for sharing the cook pad use-case thank you for attending the session we can take a few",
    "start": "2996810",
    "end": "3004320"
  },
  {
    "text": "questions I think we still have a few minutes we're counting down to ten seconds but I think I can take two more",
    "start": "3004320",
    "end": "3010350"
  },
  {
    "text": "two more questions yeah yeah so very",
    "start": "3010350",
    "end": "3019740"
  },
  {
    "text": "good question the question was why did I choose or why did cook pad choose a container management platform and not a",
    "start": "3019740",
    "end": "3025560"
  },
  {
    "text": "civil as platform so I'll answered from the more architecture perspective and Acuto and you yuujiro can talk about why",
    "start": "3025560",
    "end": "3032070"
  },
  {
    "text": "they chose it so when you go to a server list model you have to live with good citizens rules which is a number of CPUs",
    "start": "3032070",
    "end": "3041280"
  },
  {
    "text": "that you get number of memory you get but with containers you get the horsepower you need so if your",
    "start": "3041280",
    "end": "3048570"
  },
  {
    "text": "prediction algorithm or the prediction inference API is very lightweight and it can live within those boundaries",
    "start": "3048570",
    "end": "3054350"
  },
  {
    "text": "absolutely but if your inference algorithm does a lot of things it's an app it has caching it has done things",
    "start": "3054350",
    "end": "3060690"
  },
  {
    "text": "and it needs that high throughput and latency there are like low latency then",
    "start": "3060690",
    "end": "3066180"
  },
  {
    "text": "you containers kind of give you that edge we have a reference architecture",
    "start": "3066180",
    "end": "3072060"
  },
  {
    "text": "even for several less published if you want to try that yeah I know you've seen that so if you you can try that but what",
    "start": "3072060",
    "end": "3079290"
  },
  {
    "text": "we've seen from customers is a lot of machine learning inferences are running on containers we've we've also started",
    "start": "3079290",
    "end": "3085950"
  },
  {
    "text": "seeing training running on containers which is very early days right now but a lot of training is still running on ec2",
    "start": "3085950",
    "end": "3092100"
  },
  {
    "text": "s because training on containers is still like happening and yeah yeah sure",
    "start": "3092100",
    "end": "3102200"
  },
  {
    "text": "good question so the question was really how do you get from lead reduce the lag",
    "start": "3150820",
    "end": "3156770"
  },
  {
    "text": "between training a model to deploying it that's in a sense the question so when",
    "start": "3156770",
    "end": "3162740"
  },
  {
    "text": "you look at the architecture that could Pat showed and I walked you through the whole idea is to build an efficient",
    "start": "3162740",
    "end": "3169670"
  },
  {
    "text": "pipeline and as as the model is getting upload in an s3 let's say tonight",
    "start": "3169670",
    "end": "3175430"
  },
  {
    "text": "I ran a training algorithm and it got uploaded into s3 my code that is",
    "start": "3175430",
    "end": "3181220"
  },
  {
    "text": "deployed is calling the MX net API MX Annette is calling the s3 API where I'm",
    "start": "3181220",
    "end": "3187640"
  },
  {
    "text": "pulling the latest code from within the code so I'm doing saying MX that get and",
    "start": "3187640",
    "end": "3193700"
  },
  {
    "text": "I'm always pulling the latest model the model is not in the container we are not caching the model we are at",
    "start": "3193700",
    "end": "3200780"
  },
  {
    "text": "runtime I'm sitting in the same V PC I'm not going outside the V PC I have known",
    "start": "3200780",
    "end": "3206000"
  },
  {
    "text": "Internet connectivity if I do if I choose to and I can always get the latest model if I choose to or I can",
    "start": "3206000",
    "end": "3212420"
  },
  {
    "text": "cache it if I wanted to run even faster so that problem kind of becomes",
    "start": "3212420",
    "end": "3218150"
  },
  {
    "text": "non-existent if you have used the API is correctly and you build a really efficient deployment pipeline with that",
    "start": "3218150",
    "end": "3224810"
  },
  {
    "text": "the reason is why I especially mentioned is the classification is either top predictors and out on the hackers the",
    "start": "3224810",
    "end": "3241070"
  },
  {
    "text": "hackers or some whatever we do in our agencies okay the problem is by the time we send the model 2d to the production",
    "start": "3241070",
    "end": "3248510"
  },
  {
    "text": "deployed to the production environment the hacker or somebody already changed everything so the algorithms are not working so we",
    "start": "3248510",
    "end": "3255860"
  },
  {
    "text": "are trying to figure it out how to solve that problem so you train the model first am i right",
    "start": "3255860",
    "end": "3261080"
  },
  {
    "text": "is there any way you can do dynamically try in the model in the production itself especially that is the main",
    "start": "3261080",
    "end": "3267500"
  },
  {
    "text": "problem I was thinking deep learning can do something on that and if you really look",
    "start": "3267500",
    "end": "3273050"
  },
  {
    "text": "at a very sensitive projects like not civilian projects some other",
    "start": "3273050",
    "end": "3278450"
  },
  {
    "text": "projects which we work on those projects have those problems I'm trying to understand how really you can solve that",
    "start": "3278450",
    "end": "3284960"
  },
  {
    "text": "type of problem not the fan I said usually this classification I'll get them I'm talking about that by the time",
    "start": "3284960",
    "end": "3291680"
  },
  {
    "text": "you change something the hacker already changes everything and whatever we're trying to predict is not it's not valid",
    "start": "3291680",
    "end": "3298010"
  },
  {
    "text": "you know me yeah",
    "start": "3298010",
    "end": "3304330"
  },
  {
    "text": "but the apron on because training is done on the not on the production data",
    "start": "3305110",
    "end": "3310310"
  },
  {
    "text": "so that's why there's a product called a patchy defeat I don't know whether you know attached in if you are it can",
    "start": "3310310",
    "end": "3315470"
  },
  {
    "text": "stream the data into the engines and does the prediction on the on the fly yeah that is the what I'm trying to",
    "start": "3315470",
    "end": "3322610"
  },
  {
    "text": "understand in the deep learning how you guys are trying to do but that's fine okay I can ask you later on yeah we can",
    "start": "3322610",
    "end": "3327710"
  },
  {
    "text": "take this offline but to answer the question quickly when you talk about lag what we are really talking about the lag",
    "start": "3327710",
    "end": "3334310"
  },
  {
    "text": "between data and deploying the model that's what we are talking about it really depends on how you how you're",
    "start": "3334310",
    "end": "3341870"
  },
  {
    "text": "pulling the model are you caching the model in containers at runtime in production are you pulling it yeah I",
    "start": "3341870",
    "end": "3347990"
  },
  {
    "text": "will take offline any other questions I can take okay",
    "start": "3347990",
    "end": "3352690"
  },
  {
    "text": "you want to take that question sorry can you repeat your question visual images",
    "start": "3359810",
    "end": "3366410"
  },
  {
    "text": "the assignment of individual images to be classified by your model that is",
    "start": "3366410",
    "end": "3371460"
  },
  {
    "text": "running inside of that that cluster of GPU machines is that assignment to an individual machine is that handled by",
    "start": "3371460",
    "end": "3377640"
  },
  {
    "text": "the sqs well oh you mean the images this is a photos right yes well that your",
    "start": "3377640",
    "end": "3386700"
  },
  {
    "text": "question is sorry I didn't get it so if I can paraphrase so when you your",
    "start": "3386700",
    "end": "3394230"
  },
  {
    "text": "images come on like from the phone upload to sqs yeah and you deploy it on",
    "start": "3394230",
    "end": "3400410"
  },
  {
    "text": "on the GPUs to train it is that handle the sqs pulling and training also handed",
    "start": "3400410",
    "end": "3406560"
  },
  {
    "text": "by the worker nodes you know that was not for training but for the production classification for the production for the classification so I got a photo",
    "start": "3406560",
    "end": "3413640"
  },
  {
    "text": "landing on on s3 yes I have an sqs from where I pull like pull the photo and",
    "start": "3413640",
    "end": "3420150"
  },
  {
    "text": "then I try to predict it or run the inference API yeah does your worker know",
    "start": "3420150",
    "end": "3427350"
  },
  {
    "text": "do that or do you have that separately you mean the training and the inferences",
    "start": "3427350",
    "end": "3432810"
  },
  {
    "text": "the introduces oh yeah if our says the worker is just working like the",
    "start": "3432810",
    "end": "3441560"
  },
  {
    "text": "continuously working as a process and the just pouring forth for the sks for",
    "start": "3442790",
    "end": "3449750"
  },
  {
    "text": "the searching for the new message coming and the the classifier to the image and",
    "start": "3449750",
    "end": "3455760"
  },
  {
    "text": "the doing any inferences also also reporting in the results back to the API",
    "start": "3455760",
    "end": "3460800"
  },
  {
    "text": "now all the other things is to do anyone implement a set of information of of the",
    "start": "3460800",
    "end": "3466320"
  },
  {
    "text": "worker and how does it set to scale as demand abs and flows there's our scaling",
    "start": "3466320",
    "end": "3473670"
  },
  {
    "text": "groups the scale you receive so when when you're you have uploading a lot of",
    "start": "3473670",
    "end": "3480960"
  },
  {
    "text": "photos yes so initially let's say I upload 100 photos so that has an SPF you depth and",
    "start": "3480960",
    "end": "3486750"
  },
  {
    "text": "scaling but supposedly my app is used by and users and now I'm getting a lot more",
    "start": "3486750",
    "end": "3493170"
  },
  {
    "text": "photos yeah how do you handle the scaling how do you trigger it what does easiest do or how do you scale that",
    "start": "3493170",
    "end": "3499860"
  },
  {
    "text": "containers oh yeah the skill tour guide is basically that there is one metrics",
    "start": "3499860",
    "end": "3505230"
  },
  {
    "text": "on the sqs is what it's called Africa's approximate max age of the message and",
    "start": "3505230",
    "end": "3510900"
  },
  {
    "text": "then we use that to making sure that the we we won't get the message waiting",
    "start": "3510900",
    "end": "3518910"
  },
  {
    "text": "longer than the dial thresholds okay yeah thank you last question have you considered Amazon",
    "start": "3518910",
    "end": "3525030"
  },
  {
    "text": "batch for this kind of workload there's a good question so if I can take that right so Amazon",
    "start": "3525030",
    "end": "3532800"
  },
  {
    "text": "batch is service which turns on the under with ECS under the hood right it",
    "start": "3532800",
    "end": "3539340"
  },
  {
    "text": "has a queuing mechanism all of that so the batch construct is a HPC construct",
    "start": "3539340",
    "end": "3545520"
  },
  {
    "text": "and you can use batch absolutely but sometimes for bad jobs you need lower level control and I do know of customers",
    "start": "3545520",
    "end": "3553920"
  },
  {
    "text": "who are trying to use batch but as cook pad future talked about when they",
    "start": "3553920",
    "end": "3559980"
  },
  {
    "text": "started the journey probably a SS batch was not there so they made the decisions and running bad jobs on your own is",
    "start": "3559980",
    "end": "3567780"
  },
  {
    "text": "absolutely fine because you might have certain semantics and concerta constructs that you would want to",
    "start": "3567780",
    "end": "3573600"
  },
  {
    "text": "control but with AWS batch you can totally run those those APR the pita",
    "start": "3573600",
    "end": "3579000"
  },
  {
    "text": "Buhl's if they fit your need so I would go back to say what am i running as a bad job look at it if that solves the",
    "start": "3579000",
    "end": "3585480"
  },
  {
    "text": "problem from an abstraction perspective and then make the decision does that make sense yeah and the huge difference",
    "start": "3585480",
    "end": "3593160"
  },
  {
    "text": "between the database and how I see SME budget is that we need that application performance a my real-time inferences we",
    "start": "3593160",
    "end": "3601440"
  },
  {
    "text": "need to making sure that the message waited no wrong under Daniel's the batch",
    "start": "3601440",
    "end": "3606930"
  },
  {
    "text": "is kind of you know the waiting for that the tons of the tasks and perform the",
    "start": "3606930",
    "end": "3612300"
  },
  {
    "text": "inferences in at scale it's a bit there's an a bit gap",
    "start": "3612300",
    "end": "3617610"
  },
  {
    "text": "between her architectures absolutely any other questions we can take we can take this",
    "start": "3617610",
    "end": "3623609"
  },
  {
    "text": "and then go their scope but how do you",
    "start": "3623609",
    "end": "3629579"
  },
  {
    "text": "manage intercontinental and intercontinental regulations if you're",
    "start": "3629579",
    "end": "3635069"
  },
  {
    "text": "para processing on the server side do you have any kind of pre-processing within a particular region before you",
    "start": "3635069",
    "end": "3642690"
  },
  {
    "text": "even transfer the photo outside well you mean that you mean the the variation",
    "start": "3642690",
    "end": "3648599"
  },
  {
    "text": "between the between the input from the yeah so your source could potentially be",
    "start": "3648599",
    "end": "3654960"
  },
  {
    "text": "from the US your destiny your your region could potentially be outside of the RIA your cluster could be outside of the US",
    "start": "3654960",
    "end": "3661740"
  },
  {
    "text": "do you have any kind of pre-processing within a local region prior to you and",
    "start": "3661740",
    "end": "3667319"
  },
  {
    "text": "actually well actually we have the the Tuesday pension system for for the image",
    "start": "3667319",
    "end": "3675869"
  },
  {
    "text": "classification in Japan and those and in its creation outside of Japan yeah we",
    "start": "3675869",
    "end": "3681599"
  },
  {
    "text": "had only those two basically the barge on the model and then we don't care so",
    "start": "3681599",
    "end": "3688020"
  },
  {
    "text": "much about the deep variation between the countries of a continued continent",
    "start": "3688020",
    "end": "3694140"
  },
  {
    "text": "about above about the the kind of input",
    "start": "3694140",
    "end": "3699660"
  },
  {
    "text": "we get so you know that's a good question",
    "start": "3699660",
    "end": "3704819"
  },
  {
    "text": "well it's it's more of well let's just say that images that could be legal in the US may not be legal in Europe yeah",
    "start": "3704819",
    "end": "3712260"
  },
  {
    "text": "so the question is whether or not you can stop those images prior to transfer to your yeah that's a good question it's",
    "start": "3712260",
    "end": "3720569"
  },
  {
    "text": "almost borders on the line of data residency data processing local level",
    "start": "3720569",
    "end": "3725599"
  },
  {
    "text": "residency I'd love to talk to you offline about that so absolutely I think there was one more question here",
    "start": "3725599",
    "end": "3732529"
  },
  {
    "text": "well I mean even the deployment pipeline diplomat from coke meat to you know coke",
    "start": "3740549",
    "end": "3753910"
  },
  {
    "text": "build and deploy the whole passes do you use any tools well yeah you mean the deployment over",
    "start": "3753910",
    "end": "3760299"
  },
  {
    "text": "the new version the model maybe oh yeah we we used yeah we of course is a CI and",
    "start": "3760299",
    "end": "3767530"
  },
  {
    "text": "we'll the Co which does the building the toka image and also we can have a we can",
    "start": "3767530",
    "end": "3773589"
  },
  {
    "text": "make in usable Rhonda we can fire the any kind of specs we will be using for",
    "start": "3773589",
    "end": "3779950"
  },
  {
    "text": "the development a deployment of a row backing so we just searching the power",
    "start": "3779950",
    "end": "3785530"
  },
  {
    "text": "for jobs and a quake to deploy and then we will get the new version of model",
    "start": "3785530",
    "end": "3791520"
  },
  {
    "text": "thank you so much for coming we are like three minutes overtime so like thank you for coming [Applause]",
    "start": "3791520",
    "end": "3802319"
  }
]
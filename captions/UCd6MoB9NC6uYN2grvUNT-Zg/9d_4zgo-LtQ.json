[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "[Music] name's Elaine I work at a company",
    "start": "5020",
    "end": "10769"
  },
  {
    "text": "holitzer and when we talk to you all about infrastructure event readiness so",
    "start": "10769",
    "end": "15900"
  },
  {
    "text": "first of all a little bit of a review about what a firm does our mission is to deliver your honest financial products",
    "start": "15900",
    "end": "22320"
  },
  {
    "text": "that improve lives so practically what that means is our main product right now is a point-of-sale installment loan so",
    "start": "22320",
    "end": "29910"
  },
  {
    "text": "we're partnered with the number of merchants in the e-commerce as well as in-store retail space basically we're a",
    "start": "29910",
    "end": "37530"
  },
  {
    "text": "loan that's offered as a payment payment option on their site so if you like",
    "start": "37530",
    "end": "42690"
  },
  {
    "text": "check out with say Expedia you might see say or pay out over time with the forum",
    "start": "42690",
    "end": "48000"
  },
  {
    "text": "as a payment option you get out a few pieces of information we underwrite you and output a decision what we think",
    "start": "48000",
    "end": "54750"
  },
  {
    "text": "we're really improving in this area is that our loans have no late fees no",
    "start": "54750",
    "end": "60510"
  },
  {
    "text": "hidden fees no deferred interest this is the honest finance part of our mission when you check out with us we'll tell",
    "start": "60510",
    "end": "67020"
  },
  {
    "text": "you exactly what you're paying every month how much of is principle how much is interest so you can really make an",
    "start": "67020",
    "end": "72150"
  },
  {
    "text": "informed decision about whether taking out a loan is for you also we underwrite using she and",
    "start": "72150",
    "end": "79530"
  },
  {
    "text": "learning moderate models and some alternative data sources so we're able to approve some people who may not be",
    "start": "79530",
    "end": "84990"
  },
  {
    "text": "deemed credit worthy based on only their credit score Black Friday Cyber Monday the whole cyber weekend is like a huge",
    "start": "84990",
    "end": "92040"
  },
  {
    "start": "88000",
    "end": "88000"
  },
  {
    "text": "deal for us last year's cyber weekend between last Thanksgiving and Cyber Monday over 165",
    "start": "92040",
    "end": "99840"
  },
  {
    "text": "million Americans shopped and 130 million Americans shopped online so this",
    "start": "99840",
    "end": "105000"
  },
  {
    "text": "is a pretty wild number if you think about it that's like fully half of America was shopping during these days which means that it's really critical",
    "start": "105000",
    "end": "111810"
  },
  {
    "text": "for our site to be up as much as possible as well as performing at its best and this is so that we provide the best",
    "start": "111810",
    "end": "118170"
  },
  {
    "text": "possible experience for our customers as well as the merchants we work with so this is what actually ended up happening",
    "start": "118170",
    "end": "124229"
  },
  {
    "start": "123000",
    "end": "123000"
  },
  {
    "text": "last November this is the traffic increase we saw in terms of authorized low",
    "start": "124229",
    "end": "130039"
  },
  {
    "text": "so you can see those two huge spikes our Black Friday and Cyber Monday and we",
    "start": "130039",
    "end": "135170"
  },
  {
    "text": "managed to handle this traffic increase this year without any downtime for a check out product so in terms of how we",
    "start": "135170",
    "end": "141890"
  },
  {
    "start": "141000",
    "end": "141000"
  },
  {
    "text": "thought about planning for cyber weekend this year we really started thinking about it in 2017 right after last year",
    "start": "141890",
    "end": "150980"
  },
  {
    "text": "that that year's Black Friday and Cyber Monday so what we were thinking about there is long term projects we would",
    "start": "150980",
    "end": "156950"
  },
  {
    "text": "need to execute on to make sure we could handle the traffic increases we worked on those projects throughout 2018 landed",
    "start": "156950",
    "end": "164329"
  },
  {
    "text": "most of them in around mid-october and at that point started scaling up our infrastructure to handle additional scale as well as making sure we have",
    "start": "164329",
    "end": "171860"
  },
  {
    "text": "redundant infrastructure to handle every failure condition finally the weekend of cyber weekend we had people on call",
    "start": "171860",
    "end": "179329"
  },
  {
    "text": "ready to deal with any issues and people actively monitoring dashboards to make sure nothing was going wrong so the",
    "start": "179329",
    "end": "186019"
  },
  {
    "text": "first step of our planning process was long term project planning when we thought about this we looked back at",
    "start": "186019",
    "end": "191780"
  },
  {
    "start": "191000",
    "end": "191000"
  },
  {
    "text": "what happened during Black Friday 2017 and thought about systems that we might have gotten close to capacity or places",
    "start": "191780",
    "end": "198440"
  },
  {
    "text": "where we saw like clear bottlenecks where we couldn't scale indefinitely and we got traffic projections from our",
    "start": "198440",
    "end": "204109"
  },
  {
    "text": "analytics teams just to make sure we knew approximately what goal we were aiming for in 2018 so some of the",
    "start": "204109",
    "end": "212060"
  },
  {
    "text": "projects we actually worked on the first clear issue we identified that we'd have to deal with in 2018 was database",
    "start": "212060",
    "end": "219109"
  },
  {
    "start": "214000",
    "end": "214000"
  },
  {
    "text": "connection limits we use IDs or my sequel for most of our databases in prod",
    "start": "219109",
    "end": "224209"
  },
  {
    "text": "and my sequel has an issue with performance degradation when you have too many connections basically every",
    "start": "224209",
    "end": "230930"
  },
  {
    "text": "time you make a new connection to my sequel it creates a new thread to handle that so well you create too many",
    "start": "230930",
    "end": "235940"
  },
  {
    "text": "connections there's a lot of resource overhead for red scheduling and things like that in addition AWS actually does",
    "start": "235940",
    "end": "242989"
  },
  {
    "text": "have like a hard limit of 16,000 connections for an RDS instance so we were gonna get pretty close to having",
    "start": "242989",
    "end": "249500"
  },
  {
    "text": "that much traffic so before cyber weekend 2018 we knew we had to do some sort of connection",
    "start": "249500",
    "end": "255440"
  },
  {
    "text": "pooling and the solution we picked for that after debating a few options was",
    "start": "255440",
    "end": "260750"
  },
  {
    "start": "257000",
    "end": "257000"
  },
  {
    "text": "proxy sequel in addition to connection pooling proxy sequel so as a",
    "start": "260750",
    "end": "266270"
  },
  {
    "text": "bunch of other cool features it does query routing if you want to like route phrase to different databases or read",
    "start": "266270",
    "end": "271520"
  },
  {
    "text": "replicas you can also do query caching for improving performance for your common queries so proxy sequel is a",
    "start": "271520",
    "end": "277699"
  },
  {
    "text": "really long-term project for us first the planning's mate phase we wanted to make sure we chose the right",
    "start": "277699",
    "end": "283789"
  },
  {
    "text": "technologies that we could use for years into the future without any issues we",
    "start": "283789",
    "end": "288800"
  },
  {
    "text": "wanted to make sure that we were really careful about the rollout for this so we put it on stage left it there for awhile",
    "start": "288800",
    "end": "295099"
  },
  {
    "text": "put it on canary where we send 1% of your traffic left it there for a while and there are a few road bumps along the",
    "start": "295099",
    "end": "301789"
  },
  {
    "text": "way but eventually we did get it out in all of pron that's very few months work",
    "start": "301789",
    "end": "306830"
  },
  {
    "start": "303000",
    "end": "303000"
  },
  {
    "text": "and the results we saw we're pretty awesome so you can see on the graphs here the client connections which are",
    "start": "306830",
    "end": "314060"
  },
  {
    "text": "the connections that our Python code is trying to make to the database the ratio there is around 5 to 15% this really",
    "start": "314060",
    "end": "321319"
  },
  {
    "text": "means that we can scale our platform 5 to 10 more times before we have to deal with database connection issues again",
    "start": "321319",
    "end": "326930"
  },
  {
    "text": "this was a place where we may have actually ran into problems during cyber weekends so I'm setting up the system to",
    "start": "326930",
    "end": "333860"
  },
  {
    "text": "allow us to scale farther without issues was a huge deal second problem we knew",
    "start": "333860",
    "end": "338900"
  },
  {
    "start": "338000",
    "end": "338000"
  },
  {
    "text": "we would have to deal with in 2018 is how we provision servers in production",
    "start": "338900",
    "end": "344020"
  },
  {
    "text": "before 2018 our way of adding machines was pretty low-tech we had like this",
    "start": "344020",
    "end": "350449"
  },
  {
    "text": "cloud formation script we ran and then basically like a Google Doc of commands you were supposed to run after that to",
    "start": "350449",
    "end": "356840"
  },
  {
    "text": "finish server setup so that was for things like setting up the supervisor prophecies to you know actually run code",
    "start": "356840",
    "end": "364069"
  },
  {
    "text": "as well as I'm sending out blogger at 8:00 some monitoring software etc so this process worked well for us for a",
    "start": "364069",
    "end": "370699"
  },
  {
    "text": "while because we had like a pretty lean architecture but it was also slow they're all in manual steps which means",
    "start": "370699",
    "end": "376400"
  },
  {
    "text": "it's pretty easy to maybe skip one or mess things up it was also kind of",
    "start": "376400",
    "end": "382280"
  },
  {
    "text": "knowledge that was consolidated into only a few people on our team which as a",
    "start": "382280",
    "end": "387620"
  },
  {
    "text": "team grew and more people wanted to set up their own servers was kind of a tough",
    "start": "387620",
    "end": "392900"
  },
  {
    "text": "issue so in 2018 we switch to use aw with all the scaling groups for",
    "start": "392900",
    "end": "398920"
  },
  {
    "start": "394000",
    "end": "394000"
  },
  {
    "text": "adding new servers so we split up our machines into the machines of like different roles so like web servers",
    "start": "398920",
    "end": "405210"
  },
  {
    "text": "workers batch nodes and we made a separate auto scaling group for each of them and then we set up a salt reactor",
    "start": "405210",
    "end": "413470"
  },
  {
    "text": "so salt like heard of it is like an infrastructure as code software similar to ansible or puppet and the salt",
    "start": "413470",
    "end": "420370"
  },
  {
    "text": "reactor is something that runs a series of commands after some trigger occurs so",
    "start": "420370",
    "end": "425740"
  },
  {
    "text": "we set up a salt reactor for running all these steps we used to run manually after the machine was created",
    "start": "425740",
    "end": "432130"
  },
  {
    "text": "so with this salt reactor and run everything up until you know actually",
    "start": "432130",
    "end": "438160"
  },
  {
    "text": "adding machines to the load balancer or actually putting them in production so after this changed your systems to",
    "start": "438160",
    "end": "445060"
  },
  {
    "text": "add new servers all we have to do is either update the number of servers and terraform or in the AWS console and",
    "start": "445060",
    "end": "451780"
  },
  {
    "text": "everything else happens automatically including the machines actually starting running in production we also took the",
    "start": "451780",
    "end": "458200"
  },
  {
    "start": "458000",
    "end": "458000"
  },
  {
    "text": "opportunity during this project to make some other system changes so the first one was switching to newer generation",
    "start": "458200",
    "end": "464770"
  },
  {
    "text": "ec2 instances we up until last year were using c3s sure a couple years old and we",
    "start": "464770",
    "end": "471880"
  },
  {
    "text": "just stuck with it because we had reserved instances and it would have been a hassle to switch over but we took",
    "start": "471880",
    "end": "477490"
  },
  {
    "text": "this opportunity to switch over to c5 and we were pretty shocked at the improvements we saw on this graph I",
    "start": "477490",
    "end": "484360"
  },
  {
    "text": "don't know if you can see the axis but for our under adding tasks we had around",
    "start": "484360",
    "end": "489940"
  },
  {
    "text": "a 25% decrease in latency just from switching machines we also saw similar",
    "start": "489940",
    "end": "495220"
  },
  {
    "text": "improvements across our platform um so it was a really awesome result I was so excited about it was basically like just",
    "start": "495220",
    "end": "501610"
  },
  {
    "text": "everything's faster and we didn't have to do anything in addition to being way faster newer generation instances are",
    "start": "501610",
    "end": "509410"
  },
  {
    "text": "also cheaper so if any of you haven't are still running older generation instances highly recommend to switch",
    "start": "509410",
    "end": "515680"
  },
  {
    "text": "over the other system improvement we made during this process was switching from classic load balancers to",
    "start": "515680",
    "end": "522159"
  },
  {
    "start": "517000",
    "end": "517000"
  },
  {
    "text": "application load balancers this is also you know the new thing in AWS that they",
    "start": "522160",
    "end": "527770"
  },
  {
    "text": "recommend application rolled balancers for HTTP request and network load bouncers for",
    "start": "527770",
    "end": "533430"
  },
  {
    "text": "TCP requests the most useful thing for us with application with little bouncers as you can do routing based on the path",
    "start": "533430",
    "end": "539850"
  },
  {
    "text": "and the host in the URL to route like different workloads two different sets",
    "start": "539850",
    "end": "545040"
  },
  {
    "text": "of web servers we used to do this in cloud front and then we have separate i/o bees for each group of web servers",
    "start": "545040",
    "end": "551040"
  },
  {
    "text": "and it was kind of just the more confusing architectures so this allowed us to simplify our routing rules elby's",
    "start": "551040",
    "end": "557160"
  },
  {
    "text": "are also supposed to have improved performance and some other cool features that we don't use are you can have",
    "start": "557160",
    "end": "562350"
  },
  {
    "text": "lambda functions as targets so you can have like a surrealist architecture behind your load balancer and you can",
    "start": "562350",
    "end": "567900"
  },
  {
    "text": "also register targets by IP address so like points is something cross region or",
    "start": "567900",
    "end": "573240"
  },
  {
    "text": "something in an external data center stuff like that so the results of this",
    "start": "573240",
    "end": "578310"
  },
  {
    "text": "project now instead of the painful manual process we can spin up new machines in five to ten minutes and",
    "start": "578310",
    "end": "585270"
  },
  {
    "text": "they'll all be uniform there's no risk of human error and set up due to switching to newer generation instances",
    "start": "585270",
    "end": "591060"
  },
  {
    "text": "we have latency improvements across their platform and we simplify their routing rules by doing everything in alb",
    "start": "591060",
    "end": "597420"
  },
  {
    "text": "the final project I want to talk about that we tackled in 2018 was just slow",
    "start": "597420",
    "end": "603120"
  },
  {
    "start": "598000",
    "end": "598000"
  },
  {
    "text": "code I think in early 2018 we spent a little more time working on new products",
    "start": "603120",
    "end": "608250"
  },
  {
    "text": "and new features and less on dealing with tech debt service systems start slowing down a little bit when that",
    "start": "608250",
    "end": "614310"
  },
  {
    "text": "happens it's bad user experience especially from us we're pretty concerned with timing for underwriting",
    "start": "614310",
    "end": "621210"
  },
  {
    "text": "and check out because if users if it takes too long for users to get a result they might just drop out of the checkout",
    "start": "621210",
    "end": "628440"
  },
  {
    "text": "flow when things slow down is also an inefficient use of your resources you can't do as much work with the same",
    "start": "628440",
    "end": "634040"
  },
  {
    "text": "number of servers and also as we've grown we started signing more check out timing s always with our merchants",
    "start": "634040",
    "end": "641130"
  },
  {
    "text": "merchants in addition to uptime SLA so ensuring we kept meeting those we wanted",
    "start": "641130",
    "end": "646380"
  },
  {
    "text": "to focus on reducing tech debt for a little bit so the way we dealt with that project is what we call tech that burned",
    "start": "646380",
    "end": "652830"
  },
  {
    "start": "650000",
    "end": "650000"
  },
  {
    "text": "down they basically wrote up a big list of projects that would be like doable in a",
    "start": "652830",
    "end": "659100"
  },
  {
    "text": "short period of time but that could have big results in terms of improving latency check that and then we had a major",
    "start": "659100",
    "end": "664800"
  },
  {
    "text": "initiative across engineering everyone every team would stop working on futures first sprint and focus on these projects",
    "start": "664800",
    "end": "671850"
  },
  {
    "text": "instead so some examples of projects we worked on here a big one was adding",
    "start": "671850",
    "end": "677520"
  },
  {
    "start": "674000",
    "end": "674000"
  },
  {
    "text": "caching across our platform this was especially a big deal for our promo servers you can see an example of a",
    "start": "677520",
    "end": "684420"
  },
  {
    "text": "promo at the bottom of this screen it's basically an ad on the merchants site for us but we actually make a lot",
    "start": "684420",
    "end": "692010"
  },
  {
    "text": "of data visit based queries to get this result because we wanted to personalize the number like the 44 here based on the",
    "start": "692010",
    "end": "698850"
  },
  {
    "text": "merchants and the user information if possible so while we made those changes for personalization everything started",
    "start": "698850",
    "end": "705000"
  },
  {
    "text": "slowing down a bunch so just by adding caching for these common database queries we're able to make huge",
    "start": "705000",
    "end": "710790"
  },
  {
    "text": "improvements in latency for this endpoint on the infrastructure side we also did a lot of work with tuning cloud",
    "start": "710790",
    "end": "717870"
  },
  {
    "text": "front this included adding caching for more things and CloudFront increasing",
    "start": "717870",
    "end": "723030"
  },
  {
    "text": "our cache timeouts we started serving some pages that used to hit our Python app just from cloud",
    "start": "723030",
    "end": "728910"
  },
  {
    "text": "run itself we also did some works to reduce redirects and CloudFront on the platform",
    "start": "728910",
    "end": "735180"
  },
  {
    "text": "so another thing we worked on was removing unnecessary data fetching we",
    "start": "735180",
    "end": "740250"
  },
  {
    "text": "had a bunch of places where we were just fetching too much data from the database fetching too many rows or too many",
    "start": "740250",
    "end": "745290"
  },
  {
    "text": "columns and there's a couple couple issues first of all that make sure my sequel queries slower and second of all",
    "start": "745290",
    "end": "752370"
  },
  {
    "text": "depending on how much data are you loading the overhead of loading all this data data and Python can be pretty high",
    "start": "752370",
    "end": "758250"
  },
  {
    "text": "so by narrowed down our data fetching to only exactly what we needed we made some",
    "start": "758250",
    "end": "763980"
  },
  {
    "text": "nicely and see improvements we also had some places where we were like validating our data multiple times in",
    "start": "763980",
    "end": "769770"
  },
  {
    "text": "series so but making sure we're only doing that once was a big way of",
    "start": "769770",
    "end": "775890"
  },
  {
    "text": "improving things and finally just improving our sequel queries making me head making sure we had indices",
    "start": "775890",
    "end": "782480"
  },
  {
    "text": "everywhere we wanted them it's another way to make big improvements in our latencies and then one thing we did to",
    "start": "782480",
    "end": "789390"
  },
  {
    "text": "reduce tech debt was make sure we had consistent timeouts for all of our third",
    "start": "789390",
    "end": "795690"
  },
  {
    "text": "party we fetch a lot of data from different places and underwriting and we had time",
    "start": "795690",
    "end": "802030"
  },
  {
    "text": "outs for some of them but not all which meant that if if one of these third parties slow down a lot had some issue",
    "start": "802030",
    "end": "808870"
  },
  {
    "text": "on their side our latency is could also increase it's on and that could potentially even overload our servers so",
    "start": "808870",
    "end": "815350"
  },
  {
    "text": "we made sure we had consistent timeouts for all these to protect us against that vulnerability so the results of the tech",
    "start": "815350",
    "end": "821560"
  },
  {
    "text": "that burned down projects we saw latency improvements in a ton of places one of the ones we care about the most is",
    "start": "821560",
    "end": "827920"
  },
  {
    "text": "called application response time which is the time between when a user finishes",
    "start": "827920",
    "end": "833080"
  },
  {
    "text": "entering all their information and when they get a loan terms result from us so in terms of that we sound saw around a",
    "start": "833080",
    "end": "840010"
  },
  {
    "text": "40% improvement in median application response time which was like an enormous",
    "start": "840010",
    "end": "846190"
  },
  {
    "text": "improvement it took work from everyone across engineering to get here and we were really excited about it those are",
    "start": "846190",
    "end": "853000"
  },
  {
    "text": "some of the long-term projects we worked on there were a few others as well but those are some of the major ones and we",
    "start": "853000",
    "end": "858940"
  },
  {
    "text": "finished all those around mid-october at that point is time for us to actually scale up our infrastructure this is",
    "start": "858940",
    "end": "866440"
  },
  {
    "start": "866000",
    "end": "866000"
  },
  {
    "text": "something you don't really want to do too early because then you're just throwing away money on extra servers but you also don't want to do it too late so",
    "start": "866440",
    "end": "873190"
  },
  {
    "text": "it's time to double check your work and make sure everything's in place so when we were thinking about scale up",
    "start": "873190",
    "end": "879370"
  },
  {
    "text": "our requirements were first handle up to five times in normal days traffic we're",
    "start": "879370",
    "end": "885130"
  },
  {
    "text": "actually expecting like three times the normal days traffic on cyber monday which is the you know higher traffic",
    "start": "885130",
    "end": "892510"
  },
  {
    "text": "they usually but we wanted to overestimate and make sure we're prepared for the worst case scenario in",
    "start": "892510",
    "end": "899560"
  },
  {
    "text": "addition we wanted to make sure we had redundant infrastructure for everything critical including machines",
    "start": "899560",
    "end": "905400"
  },
  {
    "text": "infrastructure across availability zones and infrastructure across AWS regions so",
    "start": "905400",
    "end": "910810"
  },
  {
    "text": "in terms of handling five times traffic this is pretty easy in AWS a lot of",
    "start": "910810",
    "end": "916240"
  },
  {
    "start": "914000",
    "end": "914000"
  },
  {
    "text": "things are you know just pressing a button so like for ec2 just adjusted all",
    "start": "916240",
    "end": "921250"
  },
  {
    "text": "those scaling groups to our machines for RDS instances you can increase the size elastic surge ElastiCache just add more",
    "start": "921250",
    "end": "928270"
  },
  {
    "text": "machines to your cluster or scale up the machine sizes depending on what you want DynamoDB increase the",
    "start": "928270",
    "end": "935550"
  },
  {
    "text": "provision throughput so in addition to just increasing these parts of your systems manually we also worked with our",
    "start": "935550",
    "end": "942720"
  },
  {
    "start": "937000",
    "end": "937000"
  },
  {
    "text": "AWS enterprise support team to create an infrastructure event management plan so",
    "start": "942720",
    "end": "948000"
  },
  {
    "text": "how that works was we just compiled a big list of every component in our system that we expected to have that",
    "start": "948000",
    "end": "954930"
  },
  {
    "text": "time scale and we went through it with them one by one most of the things we came up with other than want the ones",
    "start": "954930",
    "end": "960420"
  },
  {
    "text": "I've already mentioned are managed by AWS automatically so there's nothing we",
    "start": "960420",
    "end": "966540"
  },
  {
    "text": "had to do there the one exception is load balancers load balancers are really",
    "start": "966540",
    "end": "971700"
  },
  {
    "text": "good at handling you know gradual scale-up workloads but for spiky",
    "start": "971700",
    "end": "977060"
  },
  {
    "text": "increases in traffic they have some problems so you're gonna ask us or",
    "start": "977060",
    "end": "982890"
  },
  {
    "text": "create a support ticket to pre-warm your load bouncers which is they'll scale",
    "start": "982890",
    "end": "988110"
  },
  {
    "text": "them up beforehand for you and make sure they're warm and ready to handle your workload beforehand so I mean it was",
    "start": "988110",
    "end": "993960"
  },
  {
    "text": "really helpful just to make sure that we had everything in place and then one other thing we did was contact all our",
    "start": "993960",
    "end": "1000920"
  },
  {
    "start": "998000",
    "end": "998000"
  },
  {
    "text": "third-party vendors to make sure they knew we were having the scaling event as well as make sure that they were ready",
    "start": "1000920",
    "end": "1007070"
  },
  {
    "text": "to handle the traffic increases so after we scaled everything up we did do a bit",
    "start": "1007070",
    "end": "1012200"
  },
  {
    "start": "1010000",
    "end": "1010000"
  },
  {
    "text": "of load testing to make sure all of our systems were ready this isn't something we have the infrastructure in place to",
    "start": "1012200",
    "end": "1018560"
  },
  {
    "text": "do and all of our platform but we can do it for our promo servers which are what I talked about before they're really",
    "start": "1018560",
    "end": "1025790"
  },
  {
    "text": "easy to load tests because they have a read-only workload they don't cause any third-party sources we use locust io to",
    "start": "1025790",
    "end": "1033699"
  },
  {
    "text": "mock out the traffic for promo servers and just increase the traffic and still",
    "start": "1033699",
    "end": "1039500"
  },
  {
    "text": "we started seeing latency increases and Roo metrics and then use that data to",
    "start": "1039500",
    "end": "1045160"
  },
  {
    "text": "figure out how many servers we wanted to have during cyber weekend and then the other thing we wanted to consider it was",
    "start": "1045160",
    "end": "1051950"
  },
  {
    "text": "making sure we had redundant infrastructure to handle any sort of failure that my happen in our system so the first thing",
    "start": "1051950",
    "end": "1058370"
  },
  {
    "start": "1058000",
    "end": "1058000"
  },
  {
    "text": "we considered was redundancy within an AWS region so it's meant for every machine that handles a critical workload",
    "start": "1058370",
    "end": "1064520"
  },
  {
    "text": "we want to have more than one of them doing the same thing in case there's a hardware failure we also want to make",
    "start": "1064520",
    "end": "1069860"
  },
  {
    "text": "sure we have multi enabled easy here is availability zones so that's essentially",
    "start": "1069860",
    "end": "1075559"
  },
  {
    "text": "just a different data center within an AWS region so it's really important to have multi HD because if there's some",
    "start": "1075559",
    "end": "1082669"
  },
  {
    "text": "sort of like natural disaster that affects the data center or a power outage due the way it'll be us to set",
    "start": "1082669",
    "end": "1088909"
  },
  {
    "text": "these up it's likely to only affect one ad in a region so in terms of enabling",
    "start": "1088909",
    "end": "1094700"
  },
  {
    "text": "multi is II kind of just like set up machines and different AZ's you can set up cross region sorry cross AZ read",
    "start": "1094700",
    "end": "1101480"
  },
  {
    "text": "replicas your databases and then just enable it for elastic cache elastic",
    "start": "1101480",
    "end": "1106700"
  },
  {
    "text": "search so button YouTube multi easy already gets you really far in terms of",
    "start": "1106700",
    "end": "1111890"
  },
  {
    "start": "1110000",
    "end": "1110000"
  },
  {
    "text": "up time especially for cyber weekend we want to be very sure that we've handled every failure case which is why we do",
    "start": "1111890",
    "end": "1118880"
  },
  {
    "text": "have multi region infrastructure we currently have active passive multi-region infrastructure this means",
    "start": "1118880",
    "end": "1125330"
  },
  {
    "text": "that our we have live servers in an East Coast AWS region so those are the only",
    "start": "1125330",
    "end": "1130909"
  },
  {
    "text": "servers that are actually handling traffic but in a West Coast region we have duplicates standby servers we",
    "start": "1130909",
    "end": "1137779"
  },
  {
    "text": "deploy to them every time we deploy to East Coast so they're completely ready to go but we just aren't handling any",
    "start": "1137779",
    "end": "1143360"
  },
  {
    "text": "traffic with them so in terms of setting up multi-region infrastructure that you",
    "start": "1143360",
    "end": "1148399"
  },
  {
    "text": "kind of like different strategies for different components ec2 you just",
    "start": "1148399",
    "end": "1153740"
  },
  {
    "start": "1153000",
    "end": "1153000"
  },
  {
    "text": "duplicate your machines duplicate your load balancers and then you have to consider and plan out how you would",
    "start": "1153740",
    "end": "1159590"
  },
  {
    "text": "actually handle a failover so what we do here is we prefer to over load balancers",
    "start": "1159590",
    "end": "1165200"
  },
  {
    "text": "with a DNS entry and we use a rate weighted routing policy with this DNS entry with both the load balancers for",
    "start": "1165200",
    "end": "1173000"
  },
  {
    "text": "the East and the west coast behind it and right now we have East Coast 100 West Coast at zero if we wanted to",
    "start": "1173000",
    "end": "1179390"
  },
  {
    "text": "failover we would just change these numbers to reroute traffic for RDS Aurora supports across region read",
    "start": "1179390",
    "end": "1185570"
  },
  {
    "start": "1183000",
    "end": "1183000"
  },
  {
    "text": "replicas so we set up that for everything and then if you want to they just promote my sequel instance in",
    "start": "1185570",
    "end": "1193070"
  },
  {
    "text": "the other region to master one thing we realized a couple weeks in advance to",
    "start": "1193070",
    "end": "1198650"
  },
  {
    "text": "cyber weekend was that we had made changes to our parameter groups for our live servers to increase the maximum",
    "start": "1198650",
    "end": "1203840"
  },
  {
    "text": "number of connections but we hadn't duplicated those those changes in the West Coast so that's a bit of a thing",
    "start": "1203840",
    "end": "1212930"
  },
  {
    "text": "you should double-check is that your parameter groups in both regions are the same dynamodb has global",
    "start": "1212930",
    "end": "1218510"
  },
  {
    "start": "1218000",
    "end": "1218000"
  },
  {
    "text": "tables which is multi region active active database we had to replicate all of our data from our DB tables in East",
    "start": "1218510",
    "end": "1226940"
  },
  {
    "text": "Coast into these global tables are a couple steps for that AWS does have documentation about how to do all this",
    "start": "1226940",
    "end": "1233600"
  },
  {
    "text": "first step is a bulk upload using elastic MapReduce and data pipeline so",
    "start": "1233600",
    "end": "1239840"
  },
  {
    "text": "with that you can do a one-time upload of all the data in your table to s3 and then upload from s3 to global tables so",
    "start": "1239840",
    "end": "1247160"
  },
  {
    "text": "while that's happening you need to make sure that updates after the bulk upload started or replicated to the table also",
    "start": "1247160",
    "end": "1255370"
  },
  {
    "text": "so for that AWS has a dynamo DB cross region replication library where you",
    "start": "1255370",
    "end": "1260860"
  },
  {
    "text": "send updates to the table to a Kinesis stream then once the bulk upload",
    "start": "1260860",
    "end": "1267470"
  },
  {
    "text": "finishes you can sync those updates to the table to get all the new data and",
    "start": "1267470",
    "end": "1272510"
  },
  {
    "text": "that's also how you keep your tables and sync afterwards one issue with this process is if it takes over 24 hours for",
    "start": "1272510",
    "end": "1280130"
  },
  {
    "text": "you both upload to finish which happened to us for a few of our tables and the reason that doesn't work as a Kinesis",
    "start": "1280130",
    "end": "1286400"
  },
  {
    "text": "stream can only handle up to 24 hours of data so in that case we while the bulk upload was happening we just sent the",
    "start": "1286400",
    "end": "1293450"
  },
  {
    "text": "real-time updates into a temporary table in global tables after the bulk upload",
    "start": "1293450",
    "end": "1298520"
  },
  {
    "text": "was done we moved all that data from the temporary table to the main table and",
    "start": "1298520",
    "end": "1303950"
  },
  {
    "text": "then the switch that's keep the stream over to actually Sunday that's our target table so that process is decently",
    "start": "1303950",
    "end": "1310640"
  },
  {
    "text": "straightforward but a little grimy have to do it for every table separately so I actually took a while to do for us but",
    "start": "1310640",
    "end": "1317360"
  },
  {
    "text": "got it done our last Akash we use memcache and Redis and RM for sure",
    "start": "1317360",
    "end": "1323020"
  },
  {
    "start": "1319000",
    "end": "1319000"
  },
  {
    "text": "for a couple different things like I was talking about with promos earlier we do catch some data based queries for",
    "start": "1323020",
    "end": "1329260"
  },
  {
    "text": "improved performance and we also use memcache there's a celery result story celery is a Python library which we use",
    "start": "1329260",
    "end": "1336160"
  },
  {
    "text": "for like a synchronous test processing so when a celery test finishes it can upload results this results store and",
    "start": "1336160",
    "end": "1342970"
  },
  {
    "text": "then other processes can read the results so for ElastiCache we duplicated our",
    "start": "1342970",
    "end": "1348730"
  },
  {
    "text": "clusters in the u.s. west region and then we actually didn't do any data replication for ElastiCache because of",
    "start": "1348730",
    "end": "1354880"
  },
  {
    "text": "our use cases just having our database queries hit the databases directly with",
    "start": "1354880",
    "end": "1359980"
  },
  {
    "text": "slow things down a little but ultimately be ok as the cache warmed up and for a celery result story you only really need",
    "start": "1359980",
    "end": "1366790"
  },
  {
    "text": "the results a very short time period after they're written so losing a little",
    "start": "1366790",
    "end": "1371860"
  },
  {
    "text": "data in that case is ok finally s/3 s/3 supports across region replication the",
    "start": "1371860",
    "end": "1377650"
  },
  {
    "start": "1374000",
    "end": "1374000"
  },
  {
    "text": "only complication here is unlike all of our other infrastructure we don't refer to as 3 put DNS so instead we had to",
    "start": "1377650",
    "end": "1385240"
  },
  {
    "text": "prepare a code change for switching so something we had ready in advance for a native boy in case we needed it so that",
    "start": "1385240",
    "end": "1393070"
  },
  {
    "text": "was all we did for scaling up our infrastructure in addition to that before the weekend itself we thought a",
    "start": "1393070",
    "end": "1399850"
  },
  {
    "text": "lot about the processes we needed to have in place to handle this traffic",
    "start": "1399850",
    "end": "1405310"
  },
  {
    "text": "increase first thing super important is code freeze this is also my favorite",
    "start": "1405310",
    "end": "1410620"
  },
  {
    "start": "1407000",
    "end": "1407000"
  },
  {
    "text": "time of the year no one breaks anything so we do a code freeze from the Friday before Black Friday to the Tuesday",
    "start": "1410620",
    "end": "1417370"
  },
  {
    "text": "afterwards in order to ensure that our system is stable before cyber weekend that no one last-minute pushes some",
    "start": "1417370",
    "end": "1424120"
  },
  {
    "text": "breaking change and we take it pretty seriously we do allow hot fixes and occasionally releases that have been",
    "start": "1424120",
    "end": "1431260"
  },
  {
    "text": "thoroughly vetted by our CTO and buyer infrastructure team we only really allow",
    "start": "1431260",
    "end": "1436330"
  },
  {
    "text": "things that are very important to get out in that time period and are unlikely to affect their main check out product",
    "start": "1436330",
    "end": "1443530"
  },
  {
    "text": "so like one example this year is we allow the change to our marketing email templates so that we could send out an",
    "start": "1443530",
    "end": "1449710"
  },
  {
    "text": "email blast during Black Friday so this is something that was important to get out to drive traffic during sever weekend",
    "start": "1449710",
    "end": "1456230"
  },
  {
    "text": "and also something that was unlikely to affect our main checkout products since it was kind of different system we also",
    "start": "1456230",
    "end": "1463910"
  },
  {
    "text": "worked on a ton of documentation before cyber weekends so one of the most",
    "start": "1463910",
    "end": "1469340"
  },
  {
    "start": "1464000",
    "end": "1464000"
  },
  {
    "text": "important ones is having a fail overrun book for each component when we thought",
    "start": "1469340",
    "end": "1474590"
  },
  {
    "text": "about that we really tried to make everything as detailed as possible so this includes like the exact sequence",
    "start": "1474590",
    "end": "1479840"
  },
  {
    "text": "of command you would have to run or the exact code you would have to deploy so knowing exactly what you have to do and",
    "start": "1479840",
    "end": "1485600"
  },
  {
    "text": "having it all laid out for you makes things go smoother that makes it easier on these people who are on call they",
    "start": "1485600",
    "end": "1491990"
  },
  {
    "text": "also wrote up documentation on component criticality to determine like if we had to fill something over if multiple",
    "start": "1491990",
    "end": "1498950"
  },
  {
    "text": "things we're breaking what do we fail over first what can maybe we like leave for a while in a broken state so it'd be things like",
    "start": "1498950",
    "end": "1505430"
  },
  {
    "text": "you know like internal tools used by like other teams of the firm those are probably okay to go down for a little",
    "start": "1505430",
    "end": "1511220"
  },
  {
    "text": "bit but our main checkout process that's one thing that we have to failover as fast as possible to make sure it's",
    "start": "1511220",
    "end": "1516680"
  },
  {
    "text": "working this is also useful if there's like multiple incidents for some reason going on at the same time figuring out",
    "start": "1516680",
    "end": "1522470"
  },
  {
    "text": "what's prioritized it's really important we also wrote up a chain of command in terms of like who",
    "start": "1522470",
    "end": "1529820"
  },
  {
    "text": "would make the decisions if something went wrong and we broadcasted that to everyone who's gonna be on call having",
    "start": "1529820",
    "end": "1536090"
  },
  {
    "text": "someone who's like clearly on call can make things more efficient in that type of situation something we also put a lot",
    "start": "1536090",
    "end": "1542150"
  },
  {
    "text": "of work into in 2018 was our incident communication process this is documentation for when something goes",
    "start": "1542150",
    "end": "1549440"
  },
  {
    "text": "wrong who does engineering need to tell about it how often do we need to provide",
    "start": "1549440",
    "end": "1555470"
  },
  {
    "text": "them with updates and through what channel do we need to tell them about the issue and this is really important",
    "start": "1555470",
    "end": "1560900"
  },
  {
    "text": "because when we go down our merchants really want to know and they want to know that we're actively working on it",
    "start": "1560900",
    "end": "1566270"
  },
  {
    "text": "and making progress so we have a process where engineering contexts our partner",
    "start": "1566270",
    "end": "1571520"
  },
  {
    "text": "engineering team who works directly with merchants tells them what's going on gives them updates and a time frame",
    "start": "1571520",
    "end": "1579140"
  },
  {
    "text": "depending on the criticality of the issue and then they brought the cast that elsewhere it's also important for",
    "start": "1579140",
    "end": "1585260"
  },
  {
    "text": "us to broadcast issues turn aliso that for instance like our operations team if they're getting",
    "start": "1585260",
    "end": "1591330"
  },
  {
    "text": "escalations for customers because some things down it's important that they're kept in the loop there's an active issue",
    "start": "1591330",
    "end": "1598500"
  },
  {
    "text": "after that I was still pretty terrified honestly there's always the fear of like something you haven't hadn't thought",
    "start": "1598500",
    "end": "1604830"
  },
  {
    "text": "about or something you don't know about going wrong but we kind of felt that we had done everything we could and given",
    "start": "1604830",
    "end": "1610080"
  },
  {
    "text": "the timeframe and the resources we had so what we actually did on cyber weekend first thing is eight-hour on-call shifts",
    "start": "1610080",
    "end": "1616680"
  },
  {
    "start": "1613000",
    "end": "1613000"
  },
  {
    "text": "usually a much longer on-call shifts but we really wanted to make sure everyone was fresh as fresh and ready to go as",
    "start": "1616680",
    "end": "1623220"
  },
  {
    "text": "possible during cyber weekend we also collected phone numbers for everyone who's on call for teams all our",
    "start": "1623220",
    "end": "1629520"
  },
  {
    "text": "engineering managers and our AWS reps to make sure that we could escalate issues",
    "start": "1629520",
    "end": "1634950"
  },
  {
    "text": "quickly if necessary so on Black Friday itself and Cyber Monday itself pretty",
    "start": "1634950",
    "end": "1641400"
  },
  {
    "start": "1637000",
    "end": "1637000"
  },
  {
    "text": "much what I did all day and a bunch of other people did was just stare at roll bar which we used for arrow tracking as",
    "start": "1641400",
    "end": "1647910"
  },
  {
    "text": "well as our Griffin eye dashboards so this is like an example dashboard here which we use to track system stats like",
    "start": "1647910",
    "end": "1654240"
  },
  {
    "text": "CPU memory disk space etc I think it's really important on especially",
    "start": "1654240",
    "end": "1661350"
  },
  {
    "text": "high-traffic days to have some people are actively mind these dashboards we",
    "start": "1661350",
    "end": "1667080"
  },
  {
    "text": "have pretty good alerting and affirm for situations but sometimes your alerts can be delayed sometimes you don't hit it",
    "start": "1667080",
    "end": "1672720"
  },
  {
    "text": "thresholds but you're still having an issue so you can almost always catch things faster if you're looking at a",
    "start": "1672720",
    "end": "1678870"
  },
  {
    "text": "dashboard than if you wait for an alert so although I said we had a hundred percent uptime for check out we did",
    "start": "1678870",
    "end": "1685770"
  },
  {
    "start": "1681000",
    "end": "1681000"
  },
  {
    "text": "actually have one small issue during Black Friday which we were able to catch we accidentally on a couple of our auto",
    "start": "1685770",
    "end": "1692910"
  },
  {
    "text": "scanning machines enabled a kind of like an experiment so config which had us",
    "start": "1692910",
    "end": "1698820"
  },
  {
    "text": "hitting AWS STS a lot we end up getting rate limited for that but since we were",
    "start": "1698820",
    "end": "1704310"
  },
  {
    "text": "watching roll bar we found this after only one occurrence and we were able to fix it really quickly",
    "start": "1704310",
    "end": "1709680"
  },
  {
    "text": "this happened at like 9:00 a.m. before our traffic had fully ramped up so this",
    "start": "1709680",
    "end": "1715230"
  },
  {
    "text": "is something if we hadn't been monitoring we might not have noticed it until there were a bunch more errors and",
    "start": "1715230",
    "end": "1720300"
  },
  {
    "text": "since it was would have been a more high-traffic time it might have spiraled out of control or more so fortunately",
    "start": "1720300",
    "end": "1727440"
  },
  {
    "text": "this issue also did not effect checkouts so we've still overall really happy about our performance during cyber",
    "start": "1727440",
    "end": "1734340"
  },
  {
    "text": "weekend do the 100% success rate for check outs that was how cyber weekend",
    "start": "1734340",
    "end": "1739740"
  },
  {
    "text": "went for us in 2018 afterwards we pretty much immediately started thinking about",
    "start": "1739740",
    "end": "1745260"
  },
  {
    "text": "what we needed to do in 2019 some of the things we've been thinking about first one is database connections as well as",
    "start": "1745260",
    "end": "1752790"
  },
  {
    "start": "1748000",
    "end": "1748000"
  },
  {
    "text": "just database contention so we're thinking about restarting our databases to spread out data data more",
    "start": "1752790",
    "end": "1758520"
  },
  {
    "text": "also potentially moving individual databases around to different artists",
    "start": "1758520",
    "end": "1765090"
  },
  {
    "text": "hosts to split out workloads at peak traffic on Cyber Monday for like 30",
    "start": "1765090",
    "end": "1770970"
  },
  {
    "text": "minutes we started seeing a little bit of contention on our rabid mq broker which we use with celery as a message",
    "start": "1770970",
    "end": "1778260"
  },
  {
    "text": "broker so we're planning to separate our brokers have multiple brokers for",
    "start": "1778260",
    "end": "1784260"
  },
  {
    "text": "different services to avoid that contention we're also looking to improve",
    "start": "1784260",
    "end": "1789620"
  },
  {
    "text": "the auto scaling project by making things more automatic instead of having",
    "start": "1789620",
    "end": "1795480"
  },
  {
    "text": "to go into AWS and update a number we wanted to just scale automatically without any human input at all we're",
    "start": "1795480",
    "end": "1802530"
  },
  {
    "text": "also thinking a lot about what we need to do for multi region making all the failover steps more automatic right now",
    "start": "1802530",
    "end": "1809070"
  },
  {
    "text": "there's still a bunch of manual steps we have to do which can be slower and more",
    "start": "1809070",
    "end": "1814530"
  },
  {
    "text": "error-prone then automating things so really want to do that so some takeaways",
    "start": "1814530",
    "end": "1820020"
  },
  {
    "text": "from what we learned first things one thing that worked really well for us was",
    "start": "1820020",
    "end": "1825090"
  },
  {
    "start": "1823000",
    "end": "1823000"
  },
  {
    "text": "planning ahead a long time in advance for projects you have to do we really want to been able to handle cyber",
    "start": "1825090",
    "end": "1832260"
  },
  {
    "text": "weekend traffic without proxy sequel and we've been a lot tougher without all the scaling and tech that burned down to so",
    "start": "1832260",
    "end": "1838860"
  },
  {
    "text": "identifying these projects in advance make sure you can do a really good job of them do things the right way and not",
    "start": "1838860",
    "end": "1845130"
  },
  {
    "text": "rush through it look at every component your system separately and plan your scaling strategy and your fail failover",
    "start": "1845130",
    "end": "1852030"
  },
  {
    "text": "strategy based on what it is how critical it is there were a lot of parts of our system where since we knew",
    "start": "1852030",
    "end": "1858360"
  },
  {
    "text": "we could handle a bit of downtime we didn't even plan a failover strategy for",
    "start": "1858360",
    "end": "1863970"
  },
  {
    "text": "it we just said this will go down but we're gonna fix checkout and that's the most important thing third thing this is something we could",
    "start": "1863970",
    "end": "1870420"
  },
  {
    "text": "have done a little bit better on is double-check everything obviously we miss the config issue on",
    "start": "1870420",
    "end": "1876840"
  },
  {
    "text": "the auto scaling workers before the date make sure you've actually scaled up everything as much as you want to make",
    "start": "1876840",
    "end": "1882900"
  },
  {
    "text": "sure everything's configured properly really and a corollary that one is scale up your infrastructure in advance so you",
    "start": "1882900",
    "end": "1888720"
  },
  {
    "text": "have time to do that and so you're not rushing too much in terms of the event",
    "start": "1888720",
    "end": "1895050"
  },
  {
    "text": "itself I think thorough documentation is really important to have for people who are on-call people can panic a lot in",
    "start": "1895050",
    "end": "1901470"
  },
  {
    "text": "high-stress situations like when you go down the most important day of the year so having exact steps laid up laid out",
    "start": "1901470",
    "end": "1909600"
  },
  {
    "text": "for them for what to do really makes their lives a lot easier and reduces the possibility of errors finally for your",
    "start": "1909600",
    "end": "1917940"
  },
  {
    "text": "high-traffic days active monitoring I think is really important for making sure you catch issues as quickly as",
    "start": "1917940",
    "end": "1923730"
  },
  {
    "text": "possible thank you guys so much for coming",
    "start": "1923730",
    "end": "1927679"
  },
  {
    "text": "you",
    "start": "1930110",
    "end": "1932170"
  }
]
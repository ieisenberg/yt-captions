[
  {
    "start": "0",
    "end": "46000"
  },
  {
    "text": "good afternoon everybody thank you for coming out uh to this this session this the last session today in the in the",
    "start": "160",
    "end": "5400"
  },
  {
    "text": "research track uh here at the summit I've been here all day so in case",
    "start": "5400",
    "end": "11480"
  },
  {
    "text": "any of you have been in the room with me all day uh I'm sorry to I'm going to introduce myself again but my name is Jed sundwall and I run the open data",
    "start": "11480",
    "end": "18720"
  },
  {
    "text": "program in Amazon web services and uh I get to work with a lot of organizations a lot of government agencies a lot of",
    "start": "18720",
    "end": "25160"
  },
  {
    "text": "research institutions that that work with really really large volumes of data in the cloud and share share data",
    "start": "25160",
    "end": "30320"
  },
  {
    "text": "collaborative collaboratively in the in the cloud uh I'm very excited today that we have Ralph perco and Mike gardelli",
    "start": "30320",
    "end": "37719"
  },
  {
    "text": "from pnnl to come talk about how they use AWS to Foster largescale",
    "start": "37719",
    "end": "43320"
  },
  {
    "text": "collaboration uh and research on the cloud so there's a quote that I really love that describes the value of AWS",
    "start": "43320",
    "end": "50960"
  },
  {
    "start": "46000",
    "end": "113000"
  },
  {
    "text": "really concisely this is a quote from Andy jasse who's the CEO of aw uh where he says invention requires",
    "start": "50960",
    "end": "56480"
  },
  {
    "text": "two things the ability to try a lot of experiments and not having to live with collateral damage of failed experiments",
    "start": "56480",
    "end": "62879"
  },
  {
    "text": "and it's it's a really wonderful quote that he often gives when he's talking about how the cloud has enabled a lot of startups to try very audacious things",
    "start": "62879",
    "end": "69680"
  },
  {
    "text": "without a lot of risk because they're able to try something crazy and new without buying a ton of hardware and",
    "start": "69680",
    "end": "74720"
  },
  {
    "text": "infrastructure uh but of course any scientist understands that science is all about trying you know running lots",
    "start": "74720",
    "end": "80000"
  },
  {
    "text": "and lots of experiments now if you have to run a lot of experiments and you have to buy Computing resources every time",
    "start": "80000",
    "end": "86439"
  },
  {
    "text": "you try to do that it can become really expensive and cost prohibitive to try things and to ask questions that might be expensive to ask uh so what's really",
    "start": "86439",
    "end": "95040"
  },
  {
    "text": "exciting as organizations like pnnl start using AWS is that they're finding they're able to run much larger",
    "start": "95040",
    "end": "100640"
  },
  {
    "text": "experiments much more cheaply which much with much less risk and then also do that collaboratively and Ralph and",
    "start": "100640",
    "end": "107479"
  },
  {
    "text": "Michael have great experience in this and so I'm very happy to Welcome to the stage this afternoon thank you come on",
    "start": "107479",
    "end": "114920"
  },
  {
    "start": "113000",
    "end": "219000"
  },
  {
    "text": "up is that the clicker I can just use this smck all right so thanks Jed um and",
    "start": "115079",
    "end": "121119"
  },
  {
    "text": "thanks everybody for coming today so uh my name is Mike garelli I'm a software engineer at pnnl and in so Ralph uh we",
    "start": "121119",
    "end": "127960"
  },
  {
    "text": "both have been at the lab for about seven years now we both join the lab about the same time and we lead a bunch",
    "start": "127960",
    "end": "133280"
  },
  {
    "text": "of development efforts uh Drive capabilities and try to push for the adoption of new and emerging",
    "start": "133280",
    "end": "139080"
  },
  {
    "text": "Technologies all in the support of the government missions and problems that we support and it's a constantly evolving",
    "start": "139080",
    "end": "144959"
  },
  {
    "text": "environment as Jed alluded to and we are now really trying to push for",
    "start": "144959",
    "end": "150599"
  },
  {
    "text": "other opportunities and cases where we can drive better collaboration among the researchers that we work with and then",
    "start": "150599",
    "end": "157080"
  },
  {
    "text": "the research and engineer collaborations and then find other ways for folks to collaborate even outside of p&l directly",
    "start": "157080",
    "end": "163879"
  },
  {
    "text": "and and that's what AWS is is absolutely helping us do and that's what we're going to talk about today uh is how it",
    "start": "163879",
    "end": "169800"
  },
  {
    "text": "has really pushed the envelope for the lab in that way along with just the use",
    "start": "169800",
    "end": "175959"
  },
  {
    "text": "of specific tools and the standardization of tools uh and given people are reason to do it and because",
    "start": "175959",
    "end": "181640"
  },
  {
    "text": "that's often times at least in the space where we work something that's really difficult is not just new things but the",
    "start": "181640",
    "end": "187720"
  },
  {
    "text": "adoption of them and when Ralph and I are first pushing for this in some of the solutions and things that we were",
    "start": "187720",
    "end": "192920"
  },
  {
    "text": "building we were getting a lot of just uncertainty and reservations about us doing it simply a lot of times just",
    "start": "192920",
    "end": "198440"
  },
  {
    "text": "because people didn't know and didn't understand it uh instead of in some of the cases instead of just asking for",
    "start": "198440",
    "end": "204799"
  },
  {
    "text": "permission and waiting for some of that we kind of just pushed it Forward uh fairly aggressively just to kind of see",
    "start": "204799",
    "end": "211000"
  },
  {
    "text": "what kind of feedback we'd get both from the solu the solutions and things that we were building and then also the people that were involved and it it's",
    "start": "211000",
    "end": "217000"
  },
  {
    "text": "actually been fairly positive for the most part so we're going to just briefly go over p&l in general in the lab",
    "start": "217000",
    "end": "223360"
  },
  {
    "start": "219000",
    "end": "270000"
  },
  {
    "text": "environment just to give people an idea of who we are that happens a lot we say pnl and people say who and then we say",
    "start": "223360",
    "end": "229319"
  },
  {
    "text": "where and they they don't know where it's at and all that kind of stuff and then Ralph's going to talk a little bit about software engineering in general at",
    "start": "229319",
    "end": "235200"
  },
  {
    "text": "pnl go through just like a basic uh data flow uh and the intent with just kind of",
    "start": "235200",
    "end": "240319"
  },
  {
    "text": "show a lot of what our researchers go through to do some of the work they have and even though it seems painless a lot",
    "start": "240319",
    "end": "245480"
  },
  {
    "text": "of times it can take a lot of time and effort just to stand something basing up so they can do their work uh and then",
    "start": "245480",
    "end": "250959"
  },
  {
    "text": "we're going to go through an actual use case or example of how we've brought all these things together the improved",
    "start": "250959",
    "end": "256680"
  },
  {
    "text": "collaboration the standardization of the tools and then the use of the AWS AWS environment that's really improved our",
    "start": "256680",
    "end": "263680"
  },
  {
    "text": "access to resources and reduce the time it takes to get them and then we'll do a quick wrap up and and open it up for for",
    "start": "263680",
    "end": "269800"
  },
  {
    "text": "a few questions so the LA this is just a bit about the lab system so p&l is one of 17",
    "start": "269800",
    "end": "276400"
  },
  {
    "start": "270000",
    "end": "323000"
  },
  {
    "text": "doe Labs uh in the doe complex it's been around for about 60 years and the",
    "start": "276400",
    "end": "282600"
  },
  {
    "text": "primary reason that they that they had the lab or they brought the labs in was they they have a need to drive large",
    "start": "282600",
    "end": "288360"
  },
  {
    "text": "scale long-term R&D efforts that is typically beyond the scope of Academia in Private Industry and then the other",
    "start": "288360",
    "end": "295880"
  },
  {
    "text": "part of it is that one of the other primary reasons that they were created was they wanted to find a way that these",
    "start": "295880",
    "end": "301080"
  },
  {
    "text": "Labs could complement the roles and capabilities again of Academia and Industry and then a lot of the research",
    "start": "301080",
    "end": "306960"
  },
  {
    "text": "that gets done at the labs is requires specific fa or certain facilities specific or unique instrumentation that",
    "start": "306960",
    "end": "314560"
  },
  {
    "text": "is just outside the bounds of of Academia and then beyond or typically beyond the risk tolerance for uh",
    "start": "314560",
    "end": "320960"
  },
  {
    "text": "corporate research Labs so then just a brief bit about p&l",
    "start": "320960",
    "end": "326479"
  },
  {
    "start": "323000",
    "end": "380000"
  },
  {
    "text": "specifically so we're located in Richland Washington that's when I ever whenever I say where people are or we say Rich when they're like where um so",
    "start": "326479",
    "end": "332919"
  },
  {
    "text": "anyways Eastern Washington we have offices in other locations so Seattle squim Portland we have folks in the DC",
    "start": "332919",
    "end": "339840"
  },
  {
    "text": "area and then other various remote locations uh and then these were just stats from 2016 so we had about a",
    "start": "339840",
    "end": "346039"
  },
  {
    "text": "billion dollars in R&D expenditures which is what funds our research uh and then from that we had a little over a",
    "start": "346039",
    "end": "352240"
  },
  {
    "text": "thousand Publications a little over 100 public uh patents and then and some various other Awards and then just a few",
    "start": "352240",
    "end": "359319"
  },
  {
    "text": "key inventions to note is that uh pnl pioneered a few few Technologies so they",
    "start": "359319",
    "end": "364960"
  },
  {
    "text": "they were at the Forefront of the technology that led to CDs and DVDs uh and then also the technology that is the",
    "start": "364960",
    "end": "371400"
  },
  {
    "text": "millimeter wave that's deployed at airports the scanner where you got to put your hands up and all that um we're",
    "start": "371400",
    "end": "376680"
  },
  {
    "text": "not big fans of it but we at least are proud that we made it and so the the lab has three core",
    "start": "376680",
    "end": "384039"
  },
  {
    "start": "380000",
    "end": "410000"
  },
  {
    "text": "capabilities that it focuses on data analytics chemistry and environmental science and these core capabilities are",
    "start": "384039",
    "end": "390360"
  },
  {
    "text": "really directed at trying to provide Innovation and improvements towards National Security power grid climate and",
    "start": "390360",
    "end": "397759"
  },
  {
    "text": "environmental remediation and so with that Ralph's going to now step in and talk a bit about software engineering uh let's go",
    "start": "397759",
    "end": "404800"
  },
  {
    "text": "over some of these basic data flows and the data tooling that's part of these",
    "start": "404800",
    "end": "410039"
  },
  {
    "start": "410000",
    "end": "497000"
  },
  {
    "text": "Solutions thanks Mike as Mike said we're software engineers at pnnl and um the the purpose",
    "start": "410039",
    "end": "417800"
  },
  {
    "text": "of this talk is to really talk about collaboration with researchers we that's what we do is we help enable the",
    "start": "417800",
    "end": "423520"
  },
  {
    "text": "researchers by working with them and by researchers in this context we're we're talking about data right and so uh this",
    "start": "423520",
    "end": "430120"
  },
  {
    "text": "could be the data from a physical science experiment but more often than not well that that could be where the data comes from but then we're working",
    "start": "430120",
    "end": "436560"
  },
  {
    "text": "with data scientists and analysts and whatnot to to get the data through the system and make make it available for them to do what it is what they want to",
    "start": "436560",
    "end": "443360"
  },
  {
    "text": "do uh software engineering at the lab largely we we try to be really agile um",
    "start": "443360",
    "end": "448599"
  },
  {
    "text": "and very iterative in our our approaches and uh taking a fail fast method so we have you know twoe Sprints gives us",
    "start": "448599",
    "end": "453840"
  },
  {
    "text": "opportunity to to try new things um and then if it works great fantastic let's move forward with that approach",
    "start": "453840",
    "end": "459400"
  },
  {
    "text": "otherwise let's throw that away and let's move on and and try the next thing and AWS has been really critical in",
    "start": "459400",
    "end": "464919"
  },
  {
    "text": "helping with that um like I'm sure some folks in this room uh we have often",
    "start": "464919",
    "end": "470080"
  },
  {
    "text": "limited resources both hardware and people right so first of all even if you have you know if even if you have a",
    "start": "470080",
    "end": "475560"
  },
  {
    "text": "budget for Hardware actually procuring it finding space for it making sure you have the right Power Cooling whatnot",
    "start": "475560",
    "end": "481520"
  },
  {
    "text": "rack space uh that can be an effort and that can take weeks if not months to get your your your uh Hardware stood up and",
    "start": "481520",
    "end": "488400"
  },
  {
    "text": "that that we just we want to move faster than that right and that's where AWS has just been a real game changer for us and",
    "start": "488400",
    "end": "493639"
  },
  {
    "text": "has helped us to focus on the on the mission so talking about collaboration",
    "start": "493639",
    "end": "499360"
  },
  {
    "start": "497000",
    "end": "574000"
  },
  {
    "text": "today and uh working with researchers so the problem is the opposite of collaboration is isolated research and",
    "start": "499360",
    "end": "505440"
  },
  {
    "text": "so in this context we're talking about you know at the lab researchers will get funds uh from a from a what we call a",
    "start": "505440",
    "end": "511800"
  },
  {
    "text": "sponsor and that corresponds to a government agency that's contracted us that was working with us to do some",
    "start": "511800",
    "end": "517120"
  },
  {
    "text": "piece of work with them and they uh if they're not plugged in with um with uh",
    "start": "517120",
    "end": "522240"
  },
  {
    "text": "engineering for whatever reason uh within the appropriate at the at when they are starting their work they'll",
    "start": "522240",
    "end": "528720"
  },
  {
    "text": "just start working independently which you can't blame them of course um and you know they they'll use whatever resources they have available to them",
    "start": "528720",
    "end": "535279"
  },
  {
    "text": "laptops you know whatever uh project servers from another project um they'll work on their algorithms or whatever it",
    "start": "535279",
    "end": "541680"
  },
  {
    "text": "is that they're they're wanting to uh to to do they'll they'll demo it to a",
    "start": "541680",
    "end": "546720"
  },
  {
    "text": "sponsor and sure enough the sponsor loves it and then they approach um engineering and they say hey I need to",
    "start": "546720",
    "end": "553000"
  },
  {
    "text": "deploy this oh by the way I need to scale it up and uh we need to harden it and we need it in a month and by that",
    "start": "553000",
    "end": "558600"
  },
  {
    "text": "time you know engineering we're you know we're often caught you know we're not up to speed on what it is they're trying to do uh and and while we can help them it'",
    "start": "558600",
    "end": "566600"
  },
  {
    "text": "be much more efficient and helpful if we can uh work with them earlier in the process and so that's largely what we um",
    "start": "566600",
    "end": "574079"
  },
  {
    "start": "574000",
    "end": "620000"
  },
  {
    "text": "uh are discussing today is that collaboration between the researchers and the and the engineers and how it",
    "start": "574079",
    "end": "579920"
  },
  {
    "text": "allows us to um work together to create uh a better solution ultimately for our",
    "start": "579920",
    "end": "585480"
  },
  {
    "text": "sponsors um the focus on here of course is AWS and how we're able to collaborate",
    "start": "585480",
    "end": "591240"
  },
  {
    "text": "through that you know research is the lifeblood of the lab um but AWS has really helped remove a lot of the",
    "start": "591240",
    "end": "597920"
  },
  {
    "text": "barriers at least in our our division where we um are we have influence and",
    "start": "597920",
    "end": "602959"
  },
  {
    "text": "are working together uh it's provided you know better capabilities new capabilities better products what kind",
    "start": "602959",
    "end": "608600"
  },
  {
    "text": "of products do we you know put out it it depends you know on the research effort it could be uh simply a paper uh some",
    "start": "608600",
    "end": "614240"
  },
  {
    "text": "new algorithms or concepts or a a Deployable",
    "start": "614240",
    "end": "619839"
  },
  {
    "start": "620000",
    "end": "663000"
  },
  {
    "text": "solution so with that we've you know come up with this notion of data flows right and data flows aren't anything unique and in fact you've probably seen",
    "start": "620800",
    "end": "627399"
  },
  {
    "text": "a diagram similar to this sometime in the last two days talking about we're bringing data in right and who knows",
    "start": "627399",
    "end": "633399"
  },
  {
    "text": "what the data is we got to do something with it we got to process it go through ETL with uh extract transform load",
    "start": "633399",
    "end": "639600"
  },
  {
    "text": "phases uh Rich the data and we have to store the data and and share the data and this is all use case driven and",
    "start": "639600",
    "end": "645800"
  },
  {
    "text": "you'll hear us say that a lot you know it's it depends on the use case what is the use case because that depends on",
    "start": "645800",
    "end": "651480"
  },
  {
    "text": "what we do with the data typically if we try to do anything try to pre- optimize any of our data pipeline it ends up uh",
    "start": "651480",
    "end": "658040"
  },
  {
    "text": "uh we have to undo that and you know either doesn't get used or we we have to redo it",
    "start": "658040",
    "end": "663399"
  },
  {
    "start": "663000",
    "end": "854000"
  },
  {
    "text": "so so we've kind of converged on this notion of a data flow toolbox clearly Mike and I neither of us work in",
    "start": "663399",
    "end": "669560"
  },
  {
    "text": "marketing and that's the best name we could come up with data flow toolbox so uh you know here we got your inest and",
    "start": "669560",
    "end": "675079"
  },
  {
    "text": "processing data delivery and storage um we're big fans starting from the left on the injest and processing of Apache kni",
    "start": "675079",
    "end": "682600"
  },
  {
    "text": "we've really converged on that technology for our ETL if you're not familiar with it really encourage you to go out and check it out um uh pretty",
    "start": "682600",
    "end": "690320"
  },
  {
    "text": "much anywhere in our system that data is going in or out there's going to be a kni there and its ability to scale out",
    "start": "690320",
    "end": "696519"
  },
  {
    "text": "is is really remarkable uh for delivery uh it's very again it's use case driven",
    "start": "696519",
    "end": "702079"
  },
  {
    "text": "uh the tools we lean on the most are going to be uh paty kofka S3 and sqs um",
    "start": "702079",
    "end": "707440"
  },
  {
    "text": "you know we used to do everything in Kafka and uh and that and that worked that worked well um but then as we",
    "start": "707440",
    "end": "713480"
  },
  {
    "text": "started working with more researchers and and talking to folks it was just you know the idea really do do you really",
    "start": "713480",
    "end": "719279"
  },
  {
    "text": "need streaming data right and is this something that we can put in S3 instead and so so now more times than not we do",
    "start": "719279",
    "end": "724920"
  },
  {
    "text": "try to push people to S3 for a delivery mechanism uh and then um sqs as well",
    "start": "724920",
    "end": "730560"
  },
  {
    "text": "we've been more and more leaning on uh Amazon uh web services and in the building capabilities then of course",
    "start": "730560",
    "end": "736720"
  },
  {
    "text": "storage right what is again I said it already what is the use case you know uh so if a if a researcher comes in and",
    "start": "736720",
    "end": "742959"
  },
  {
    "text": "they have uh data that they they need brought into the system it's not uncommon for them not even to know what",
    "start": "742959",
    "end": "748000"
  },
  {
    "text": "they want to do with the data yet so we just need to park it somewhere but we know we want to start Gathering and accumulating it so we'll just put it in",
    "start": "748000",
    "end": "754320"
  },
  {
    "text": "Amazon S3 we also used lastic search quite a bit uh for uh search capability",
    "start": "754320",
    "end": "759600"
  },
  {
    "text": "and some analytics uh Dynamo DB and Cassandra uh for no SQL based systems um",
    "start": "759600",
    "end": "765480"
  },
  {
    "text": "and then Hadoop we have uh internally a lot of data comes in into the network where we have Hadoop infrastructure we",
    "start": "765480",
    "end": "771639"
  },
  {
    "text": "run spark you know python um map reduce jobs Hive and whatnot uh the",
    "start": "771639",
    "end": "777399"
  },
  {
    "text": "technologies that are in the small print though there those are technologies that we have used in the past but um don't",
    "start": "777399",
    "end": "783199"
  },
  {
    "text": "we're not you know kind of currently part of our our primary toolbox there um in addition to",
    "start": "783199",
    "end": "791120"
  },
  {
    "text": "that sorry uh there's there's other Technologies on here that we're we're not showing um we we still use",
    "start": "791120",
    "end": "797760"
  },
  {
    "text": "relational databases you know we're we use RDS on AWS with postgress that works",
    "start": "797760",
    "end": "803519"
  },
  {
    "text": "pretty well for us and then we Cabana quite a bit with elastic search and a myriad of other tools and this isn't to",
    "start": "803519",
    "end": "809839"
  },
  {
    "text": "be you know like hey you only can use these tools that's not at all what this is these are the tools that we've been using that we've converged on that have",
    "start": "809839",
    "end": "816360"
  },
  {
    "text": "been really helpful for us to create these this idea of these um uh reusable data flows for example so by cobbling",
    "start": "816360",
    "end": "823199"
  },
  {
    "text": "these tools together in various combinations we're able to really you know get data transform it do",
    "start": "823199",
    "end": "829160"
  },
  {
    "text": "enrichments on it do really uh some real analysis on that data and then provide it to the researchers to do what it is",
    "start": "829160",
    "end": "836320"
  },
  {
    "text": "that they want to do and and often times that you know that that trans that ETL that extraction transfer load phase",
    "start": "836320",
    "end": "843240"
  },
  {
    "text": "we'll do some analysis even in there for the researchers so by the time they get it it's been uh kind of pre-populated",
    "start": "843240",
    "end": "849160"
  },
  {
    "text": "with what they're looking for so uh let's see with that said uh Mike's going to come back and",
    "start": "849160",
    "end": "856079"
  },
  {
    "start": "854000",
    "end": "1195000"
  },
  {
    "text": "he's going to walk through an actual use case of of how we work with data and and what a data flow uh will look like and",
    "start": "856079",
    "end": "863399"
  },
  {
    "text": "using the tools we just uh talked about so M thanks so as Ralph said we we",
    "start": "863399",
    "end": "868519"
  },
  {
    "text": "actually wanted to go through a real life example a real life use case where we brought all these pieces together so",
    "start": "868519",
    "end": "874279"
  },
  {
    "text": "where we were trying to improve the collaboration amongst the researchers and Engineers uh how we tried to at",
    "start": "874279",
    "end": "879720"
  },
  {
    "text": "least enforce a little bit of standardization on the tools and components platforms that are used uh",
    "start": "879720",
    "end": "884959"
  },
  {
    "text": "and then just highlight or show the power of the AWS environment in our ability to make this happen and so with",
    "start": "884959",
    "end": "891519"
  },
  {
    "text": "this with this this primary reason for this use case is that our researchers wanted to establish an environment or a",
    "start": "891519",
    "end": "896680"
  },
  {
    "text": "pipeline where images could be brought in and they could attach classifiers to them so they could actually physically",
    "start": "896680",
    "end": "902600"
  },
  {
    "text": "classify images and some of the challenges that if we were have done this in our in our pnl or our physical",
    "start": "902600",
    "end": "908839"
  },
  {
    "text": "environment we would have rent into all kinds of problems so we would have had limitations with the hardware it would",
    "start": "908839",
    "end": "914000"
  },
  {
    "text": "have probably been difficult to scale it out it probably would have been difficult for us to make sure that others had access to it uh and then even",
    "start": "914000",
    "end": "921399"
  },
  {
    "text": "just some of the more basic things like just some of the trying to figure out what technical components would make",
    "start": "921399",
    "end": "926839"
  },
  {
    "text": "sense and all that could be difficult and so we came into this with two two primary goals so we had engineering",
    "start": "926839",
    "end": "932440"
  },
  {
    "text": "goals and then the researchers had goals uh so the ones that you see here are the engineering goals and and I'll get to",
    "start": "932440",
    "end": "937519"
  },
  {
    "text": "the research on so for the engineering side we really wanted to establish this pipeline where researchers could hand us",
    "start": "937519",
    "end": "944079"
  },
  {
    "text": "references to images and when they did that the pipeline would go and retrieve the images strip out some metadata and",
    "start": "944079",
    "end": "951079"
  },
  {
    "text": "then store them so that they could be used at a different part in the process and then we also needed to make sure",
    "start": "951079",
    "end": "957360"
  },
  {
    "text": "that as images were brought in they were brought in or or retrieved or they were just landed somewhere that the the",
    "start": "957360",
    "end": "964560"
  },
  {
    "text": "addition of these images would create notifications so that the researchers and their processes could be notified of",
    "start": "964560",
    "end": "970759"
  },
  {
    "text": "those new images and then they could take them through their classification process and then just like the images",
    "start": "970759",
    "end": "977600"
  },
  {
    "text": "themselves any metadata that gets generated so the actual classifications of the images or the labeling that occurred we want to make sure that both",
    "start": "977600",
    "end": "984959"
  },
  {
    "text": "the reference to the original image and any classification data that got gathered was stored in a way that could",
    "start": "984959",
    "end": "990600"
  },
  {
    "text": "be easily retrieved analyzed and reviewed both both for just demonstration purposes and also for",
    "start": "990600",
    "end": "996399"
  },
  {
    "text": "Effectiveness and things like that and then lastly at least for the engineers is we want to make sure that it was a",
    "start": "996399",
    "end": "1001759"
  },
  {
    "text": "collaborative environment meaning other Engineers could jump in and see what was done so we could maybe reuse certain",
    "start": "1001759",
    "end": "1007040"
  },
  {
    "text": "components other researchers could jump in and actually use the data or reference the data or look at just the",
    "start": "1007040",
    "end": "1012720"
  },
  {
    "text": "outcomes of the classifications and then from the research side they of course had very similar needs but also wanted",
    "start": "1012720",
    "end": "1019519"
  },
  {
    "text": "to make sure that it was extensible but not necessarily extensible in terms of scalability they which was one of them",
    "start": "1019519",
    "end": "1025360"
  },
  {
    "text": "but they they wanted to make sure that they could easily drop in other models so classification models or even just",
    "start": "1025360",
    "end": "1030798"
  },
  {
    "text": "different classifiers so that they could see or compare things in the way that things are being classified and see how",
    "start": "1030799",
    "end": "1036079"
  },
  {
    "text": "effective they were they of course did care about the scalability given that there could be an unknown set of images",
    "start": "1036079",
    "end": "1041720"
  },
  {
    "text": "or references that they want to handoff uh so often times in the research space we'll get a collection of data whether",
    "start": "1041720",
    "end": "1047839"
  },
  {
    "text": "that be just a hand off from one of our sponsors or even just internal source stuff and they wanted to be able to",
    "start": "1047839",
    "end": "1053600"
  },
  {
    "text": "retrain Andor handle uh the addition of new images uh and then lastly just like",
    "start": "1053600",
    "end": "1058919"
  },
  {
    "text": "the engineering side they wanted to make sure it was collaborative where it was easy for other researchers to come in get access to the images and get access",
    "start": "1058919",
    "end": "1065440"
  },
  {
    "text": "to the classification data so this image is a is a depiction",
    "start": "1065440",
    "end": "1070679"
  },
  {
    "text": "of the actual pipeline that was built and what you can see is a mix of things so there is an actual mix of AWS",
    "start": "1070679",
    "end": "1076960"
  },
  {
    "text": "services and Technical components that was used to construct this Pipeline and we'll actually walk through each one of",
    "start": "1076960",
    "end": "1083440"
  },
  {
    "text": "the technical components and and why we chose those at least as part of this initial solution uh but before we get to",
    "start": "1083440",
    "end": "1090520"
  },
  {
    "text": "that we did want to highlight because we've been talking about it a lot we wanted to highlight how the collaboration happened and where where",
    "start": "1090520",
    "end": "1096280"
  },
  {
    "text": "the two groups physically sat in this process so the engineering side is on the left uh and the primary goals were",
    "start": "1096280",
    "end": "1102480"
  },
  {
    "text": "reflected in what I just mentioned but the engineers built the systems the processing and then the delivery of the",
    "start": "1102480",
    "end": "1108960"
  },
  {
    "text": "images and they used the components or built the components in a way that could be scalable and then also meet the needs",
    "start": "1108960",
    "end": "1114880"
  },
  {
    "text": "of the environment and then on the right side the researchers wanted to of course be notified of those new images so that",
    "start": "1114880",
    "end": "1121640"
  },
  {
    "text": "they could attach their classifiers and in this case it's a tensorflow serving classifier that they they built and",
    "start": "1121640",
    "end": "1127720"
  },
  {
    "text": "packaged so that all the images once they came in could be passed through there they could classify them and the",
    "start": "1127720",
    "end": "1133280"
  },
  {
    "text": "resorts could be sto or the results could be stored and then we made sure that they of course met in the middle",
    "start": "1133280",
    "end": "1139120"
  },
  {
    "text": "where the notifications the physical images and the metadata from those classifications could coexist so that",
    "start": "1139120",
    "end": "1145559"
  },
  {
    "text": "people could come in at different points in the solution or in the pipeline and do various things with",
    "start": "1145559",
    "end": "1151240"
  },
  {
    "text": "it so the the first component in the pipeline is a patching II and and as",
    "start": "1151240",
    "end": "1156400"
  },
  {
    "text": "Ralph mentioned it is usually or typically now one of the primary starting points of any data process that",
    "start": "1156400",
    "end": "1161720"
  },
  {
    "text": "we build uh now that's not to say that we won't change that at some point but right now it it is used quite heavily",
    "start": "1161720",
    "end": "1168400"
  },
  {
    "text": "and we went through a lot of Evolutions to get to the point where where we standardized on nii so we built",
    "start": "1168400",
    "end": "1174120"
  },
  {
    "text": "proprietary Frameworks uh within the lab and those were those those worked well but then they would get outdated or they",
    "start": "1174120",
    "end": "1180080"
  },
  {
    "text": "wouldn't be maintained we used uh active mq and storm for various pipelines that",
    "start": "1180080",
    "end": "1185400"
  },
  {
    "text": "were similar to this but they had their own complexities and challenge challenges uh but once we adopted nii",
    "start": "1185400",
    "end": "1191679"
  },
  {
    "text": "and started using it it really did make a huge difference for us so a little bit about nii so nii was created by the NS",
    "start": "1191679",
    "end": "1199000"
  },
  {
    "start": "1195000",
    "end": "1454000"
  },
  {
    "text": "about 10 years ago so it's definitely been battle tested uh it was open sourced a couple years ago and is now an",
    "start": "1199000",
    "end": "1204559"
  },
  {
    "text": "Apache project uh and it really is just phenomenal for things like data routing",
    "start": "1204559",
    "end": "1211520"
  },
  {
    "text": "ETL delivery all those things and it's really painless from multiple aspects so",
    "start": "1211520",
    "end": "1217679"
  },
  {
    "text": "not only is it really easy to install configure and scale uh but it's also very easy to use meaning like to just",
    "start": "1217679",
    "end": "1224280"
  },
  {
    "text": "build out pipelines and manipulate pipelines and this is we get this kind of feed back from all kinds of different",
    "start": "1224280",
    "end": "1229960"
  },
  {
    "text": "groups not just our engineers and researchers but this also comes from our testers uh even some analysts uh and",
    "start": "1229960",
    "end": "1235919"
  },
  {
    "text": "even some some other folks like outside of some of those groups that have used it just to template flows um so just",
    "start": "1235919",
    "end": "1241760"
  },
  {
    "text": "quickly walking down some of these features because there's a lot more than what we listed here but these are the ones that we find of value and some of",
    "start": "1241760",
    "end": "1247720"
  },
  {
    "text": "these are repeated so the data routing is extremely robust the ETL is is awesome I touched on the installation",
    "start": "1247720",
    "end": "1254360"
  },
  {
    "text": "and the barrier of Entry but there's a couple other things that are really nice about kni and one of of them is the visual aspect so you can physically see",
    "start": "1254360",
    "end": "1261799"
  },
  {
    "text": "in operation or in process how much data is flowing through your pipelines you can see when you have Hang-Ups or",
    "start": "1261799",
    "end": "1267480"
  },
  {
    "text": "bottlenecks so you can physically see where things are being held up by some process or some dependency that's in the",
    "start": "1267480",
    "end": "1273679"
  },
  {
    "text": "flow and there's all these metrics that you can Vis visually see visually see and then the back pressure and queuing",
    "start": "1273679",
    "end": "1280039"
  },
  {
    "text": "is also phenomenal so we have at least in our physical environments we don't run into this as much not or not nearly",
    "start": "1280039",
    "end": "1286039"
  },
  {
    "text": "as much in the AWS space But we would often times run into cases where Downstream repositories so like our",
    "start": "1286039",
    "end": "1292240"
  },
  {
    "text": "elastic search clusters or our postgress clusters or whatever were down or unavailable or they were being P patched",
    "start": "1292240",
    "end": "1298679"
  },
  {
    "text": "or bounced and when once we dropped in nii we didn't have to worry about it anymore we would just let the back pressure and queing handle it and once",
    "start": "1298679",
    "end": "1305640"
  },
  {
    "text": "they became available again stuff would just start flowing it's it's really been a GameChanger for us in terms of both",
    "start": "1305640",
    "end": "1312000"
  },
  {
    "text": "complexity and the pipelines we build and then the resiliency that it has to unknown conditions or even known",
    "start": "1312000",
    "end": "1317080"
  },
  {
    "text": "conditions again like like patch systems so this is a visual of the",
    "start": "1317080",
    "end": "1322600"
  },
  {
    "text": "initial part of the flow or the pipeline that that we just described and what you see is is a few things so you see three",
    "start": "1322600",
    "end": "1328840"
  },
  {
    "text": "processors are what are called processors and those are the consume Kafka the image cache filter and the put",
    "start": "1328840",
    "end": "1334880"
  },
  {
    "text": "SNS now the C the consumed kofka and put SNS are out of the box processor so nii",
    "start": "1334880",
    "end": "1341080"
  },
  {
    "text": "comes with a ton of processors that you can drop right into your flows that are out of the box um and you can connect to",
    "start": "1341080",
    "end": "1348120"
  },
  {
    "text": "all kind kinds of data repositories message cues file systems and then a bunch of AWS Services it's why it works",
    "start": "1348120",
    "end": "1354559"
  },
  {
    "text": "really well in AWS because you can easily attach it to sqs S3 all kinds of things and then the image cache filter",
    "start": "1354559",
    "end": "1361480"
  },
  {
    "text": "is a custom processor that we wrote uh and this was something that we've kind of gone back and forth on when we build",
    "start": "1361480",
    "end": "1367200"
  },
  {
    "text": "out these flows and kind of converged on that we will oftentimes build custom processors because we don't want to",
    "start": "1367200",
    "end": "1374279"
  },
  {
    "text": "overly complex or overly complicate or bloat the flows uh and so we'll just",
    "start": "1374279",
    "end": "1379360"
  },
  {
    "text": "custom write something to do something specific uh so some some of what we found is if you if you drop too many",
    "start": "1379360",
    "end": "1386039"
  },
  {
    "text": "processors in a flow it'll overwhelm the resources and things and your concurrency and some of those other things won't work well so that one's",
    "start": "1386039",
    "end": "1392120"
  },
  {
    "text": "custom and then the other things you see are the connectors and the connectors are what actually are of course the",
    "start": "1392120",
    "end": "1397600"
  },
  {
    "text": "routing but they're also the backing cues so if a processor start a processor starts to get behind or you stop it or",
    "start": "1397600",
    "end": "1403960"
  },
  {
    "text": "pause it things will just start to back up on your cues there are also logic points to where you can of course derive",
    "start": "1403960",
    "end": "1410760"
  },
  {
    "text": "things that happen on failure or success but you can also write custom logic so that you can reroute Things based on",
    "start": "1410760",
    "end": "1416880"
  },
  {
    "text": "various criteria that you identify in the flow it's extremely powerful and then of course as you can see the visual",
    "start": "1416880",
    "end": "1422159"
  },
  {
    "text": "aspect is really nice now one thing I want to highlight is a both of benefit and a danger is that in operation in",
    "start": "1422159",
    "end": "1429400"
  },
  {
    "text": "something running you can physically rerat on the Fly you can easily grab onto or attach to a operating processor",
    "start": "1429400",
    "end": "1436039"
  },
  {
    "text": "and redirect the data you can also inspect the data that's going through now the danger there is that we've had",
    "start": "1436039",
    "end": "1441840"
  },
  {
    "text": "Ralph and I have had this happen a couple times where one of our Engineers just wanted to check something out and when they did that they inadvertently",
    "start": "1441840",
    "end": "1447799"
  },
  {
    "text": "broke the flow so we had to apply some other restrictions once we found that that was kind of becoming a",
    "start": "1447799",
    "end": "1454440"
  },
  {
    "text": "problem and so this is this is just a really basic example of that part of the flow where the data that we're pulling",
    "start": "1454440",
    "end": "1460840"
  },
  {
    "text": "off the queue is images or references to images that the the researchers wanted us to process uh and then it hits the",
    "start": "1460840",
    "end": "1468399"
  },
  {
    "text": "ual filter the image cache filter processor and they're applying specific criteria in this case a koala image that",
    "start": "1468399",
    "end": "1474640"
  },
  {
    "text": "they want to extract from the stream and then pass it down to the SNS notification which is what's notifying",
    "start": "1474640",
    "end": "1481360"
  },
  {
    "text": "the other processing points Lambda in this case that's that work needs to happen and so what we did is of course",
    "start": "1481360",
    "end": "1486880"
  },
  {
    "text": "we're extracting the data from Kafka we're filtering the data with our custom processor and then we're writing a",
    "start": "1486880",
    "end": "1491960"
  },
  {
    "text": "custom SNS payload that then is the the starting point for the Lambda expression",
    "start": "1491960",
    "end": "1497039"
  },
  {
    "text": "uh and so just a quick visual back on the actual pipeline itself so nii was the inest point we built the SNS P or",
    "start": "1497039",
    "end": "1504679"
  },
  {
    "text": "the SNS uh payload and then we pass it to Lambda and then this is just a a full example of what the SNS payload looks",
    "start": "1504679",
    "end": "1511039"
  },
  {
    "text": "like the blue of course being the piece that we constructed in our nii processor uh so with that R's going to",
    "start": "1511039",
    "end": "1517000"
  },
  {
    "text": "actually continue the the discussion and the breakdown of the work that was done all through the rest of the components",
    "start": "1517000",
    "end": "1524679"
  },
  {
    "text": "so thanks Mike yes so just to review where we're at you know the point of this is to show",
    "start": "1524679",
    "end": "1531399"
  },
  {
    "text": "how we're enabling research how we're enabling collaboration and so we're walking through this flow where the goal",
    "start": "1531399",
    "end": "1536600"
  },
  {
    "text": "is there's Json Dating coming in there's references to images in that Json we want to be able to pull out those",
    "start": "1536600",
    "end": "1541679"
  },
  {
    "text": "references actually download the images and provide them to the researchers so they can do what do the work they want",
    "start": "1541679",
    "end": "1547200"
  },
  {
    "text": "to do on that um Lambda is uh you know it's an event driven serverless",
    "start": "1547200",
    "end": "1552600"
  },
  {
    "text": "Computing platform and it's a it's a really powerful way to scale out um functions called On Demand",
    "start": "1552600",
    "end": "1558880"
  },
  {
    "text": "uh we're going to dive a little bit more into this and also talk about uh why we chose the components we did and uh sort",
    "start": "1558880",
    "end": "1565279"
  },
  {
    "text": "of our our path I guess to adopting um more and more AWS Services uh just going",
    "start": "1565279",
    "end": "1571840"
  },
  {
    "text": "through this flow a little bit so as Mike Mike talked about the Amazon SNS uh portion we get the message off uh the",
    "start": "1571840",
    "end": "1579360"
  },
  {
    "text": "process notification first thing we do is we check Dynamo to see if that that uh record that image had been uh seen",
    "start": "1579360",
    "end": "1585520"
  },
  {
    "text": "before if not we go ahead and download that image from the internet and then we uh convert it to JPEG and strip out all",
    "start": "1585520",
    "end": "1590880"
  },
  {
    "text": "the exf data from there the metadata is written back to Dynamo is written to Dynamo uh we use sqs to notify uh who in",
    "start": "1590880",
    "end": "1598799"
  },
  {
    "text": "this case the researchers that there's a new image available and the then the um image is written to an S3 bucket so why",
    "start": "1598799",
    "end": "1606159"
  },
  {
    "text": "we chose these components SNS was really pretty functional um only certain",
    "start": "1606159",
    "end": "1611480"
  },
  {
    "text": "services will trigger an AWS Lambda call and in this case SNS was the the one we",
    "start": "1611480",
    "end": "1617559"
  },
  {
    "text": "chose to use um and nii has built in uh AWS SNS",
    "start": "1617559",
    "end": "1622720"
  },
  {
    "text": "capability so that worked easily enough the Amazon Dynamo DB we wanted a nosql solution uh for that because the data",
    "start": "1622720",
    "end": "1630000"
  },
  {
    "text": "we're just hashing the URL and we're just doing lookups on the on the metadata we're not actually enabling any kind of search capability so we didn't",
    "start": "1630000",
    "end": "1636559"
  },
  {
    "text": "need like a relational database for example in this case and we were going for like a pure AWS solution here right",
    "start": "1636559",
    "end": "1642360"
  },
  {
    "text": "so that's you you'll notice that about this as well this particular piece s sqs",
    "start": "1642360",
    "end": "1648200"
  },
  {
    "text": "to notify and then uh Amazon S3 to store the images of course um sqs you may if",
    "start": "1648200",
    "end": "1653880"
  },
  {
    "text": "you're familiar with S3 and sqs you may be thinking well why didn't you just notify off the S3 bucket and that that",
    "start": "1653880",
    "end": "1660120"
  },
  {
    "text": "is an option we could have done that we do that elsewhere but in this case there was a specific condition where that",
    "start": "1660120",
    "end": "1665399"
  },
  {
    "text": "wasn't going to work as well and so um we just it was easier for us to manually just handle the notifications there um",
    "start": "1665399",
    "end": "1673080"
  },
  {
    "text": "now y Lambda so a little bit more about that so we know it's a great service and this is kind of getting a little bit",
    "start": "1673080",
    "end": "1678200"
  },
  {
    "text": "into our adoption uh into more and more Cloud features um this was a big step",
    "start": "1678200",
    "end": "1684159"
  },
  {
    "text": "for us when uh you know we started dipping our toe into the into the cloud",
    "start": "1684159",
    "end": "1689360"
  },
  {
    "text": "we like a lot of folks were you know we're concerned about two things primarily cost and then vendor lock in",
    "start": "1689360",
    "end": "1694840"
  },
  {
    "text": "right and so um what you know are we just going to lose all our money and are we going to write a bunch of code that's",
    "start": "1694840",
    "end": "1700080"
  },
  {
    "text": "only going to run on AWS and therefore all this work that we've done is not going to be portable um and so uh as far",
    "start": "1700080",
    "end": "1708360"
  },
  {
    "text": "and Lambda was a big step in that direction um as far as us trying this U method out um we started like a lot of",
    "start": "1708360",
    "end": "1715480"
  },
  {
    "text": "folks we started with infrastructure of a service we just kind of did the I heard someone refer to it as the the the",
    "start": "1715480",
    "end": "1720519"
  },
  {
    "text": "forklift model right where we basically just forklifted our infrastructure off Prem and just dropped it into uh AWS and",
    "start": "1720519",
    "end": "1727679"
  },
  {
    "text": "uh that that's how we started and it it worked fine we spun up ec2 instances uh use I am um S3 you know but we purposely",
    "start": "1727679",
    "end": "1736799"
  },
  {
    "text": "stayed away from any AWS specific Services cuz we didn't want to get locked in right and now that we've been",
    "start": "1736799",
    "end": "1742799"
  },
  {
    "text": "out there for several years and we've been using these Services more and more we know uh some of those fears are",
    "start": "1742799",
    "end": "1748240"
  },
  {
    "text": "unfounded really quite honestly and um es especially the a little bit on the",
    "start": "1748240",
    "end": "1753880"
  },
  {
    "text": "vender lockin part so this is where the combination of Apache nii and AWS has been really powerful because it because",
    "start": "1753880",
    "end": "1760640"
  },
  {
    "text": "Apache nii comes with all this great AWS integration built in for us to write to",
    "start": "1760640",
    "end": "1768440"
  },
  {
    "text": "sqs versus writing a Kafka or some other messaging system or to um read from a",
    "start": "1768440",
    "end": "1774559"
  },
  {
    "text": "relational database or write data to hdfs it's all it's pretty baked in and it's really pretty easy just as Mike",
    "start": "1774559",
    "end": "1780919"
  },
  {
    "text": "talked about just you can you know let's say your C your kofka cluster went down you can point it you can drag your arrow",
    "start": "1780919",
    "end": "1787679"
  },
  {
    "text": "to an S3 bucket and say you know what just drop it all on S3 until we figure this out if you want to do something like",
    "start": "1787679",
    "end": "1794679"
  },
  {
    "text": "that uh to to another question maybe about why we chose Lambda so we we love",
    "start": "1795720",
    "end": "1801799"
  },
  {
    "text": "nii as Mike gave a good introduction to that and we actually did this in nii first we took all that logic that was in",
    "start": "1801799",
    "end": "1807200"
  },
  {
    "text": "the in the center there and we rode a processor and we deployed it in Apache nii and it it worked well we we but we",
    "start": "1807200",
    "end": "1814279"
  },
  {
    "text": "had to scale it out quite a bit we had to stand up four pretty beefy ec2 instances running Apache kni and um it",
    "start": "1814279",
    "end": "1820679"
  },
  {
    "text": "it did work and it it and but the problem with that approach was it uh turned out to be a lot more costly to",
    "start": "1820679",
    "end": "1827080"
  },
  {
    "text": "run those EC two instances with the EBS storage backing it than it was just to use AWS L Lambda and that was really",
    "start": "1827080",
    "end": "1833679"
  },
  {
    "text": "compelling for us and a and a good primary reason we went with this approach and we don't regret it it it",
    "start": "1833679",
    "end": "1839200"
  },
  {
    "text": "it's worked really well for us and the other thing as well um anytime you have a cluster anywhere well someone's got to",
    "start": "1839200",
    "end": "1846080"
  },
  {
    "text": "maintain that and operate it and things like that and that gets back to kind of what we talked about in the middle about how AWS is helping us collaborate",
    "start": "1846080",
    "end": "1852120"
  },
  {
    "text": "helping us focus on the mission and not uh Focus so much on all this infrastructure that we're having to maintain and continue to uh work",
    "start": "1852120",
    "end": "1860760"
  },
  {
    "start": "1860000",
    "end": "1899000"
  },
  {
    "text": "on so this slide here is just to kind of talk about the the vendor lock in or lack thereof with the AWS um uh with the",
    "start": "1860760",
    "end": "1868320"
  },
  {
    "text": "with the Lambda function it's just pure Java um and we're using standard uh Java",
    "start": "1868320",
    "end": "1873960"
  },
  {
    "text": "libraries Apache HTTP components to download the image we're using image magic to convert and strip the images",
    "start": "1873960",
    "end": "1880399"
  },
  {
    "text": "there are a few API calls to Amazon Services of course but they're not very intrusive um so it's just just plain",
    "start": "1880399",
    "end": "1887519"
  },
  {
    "text": "Java we use Maven as our build you know we use the shade plugin to to create an Uber jar and and deploy it out there and",
    "start": "1887519",
    "end": "1894919"
  },
  {
    "text": "that works well um okay so now we're back onto our road",
    "start": "1894919",
    "end": "1901440"
  },
  {
    "start": "1899000",
    "end": "1916000"
  },
  {
    "text": "map about uh image retrieval and classification this is our collaboration part so we've we've got the images",
    "start": "1901440",
    "end": "1907480"
  },
  {
    "text": "they've been downloaded um they've been stored the metadata has been stored and uh now this is the point where we the",
    "start": "1907480",
    "end": "1913799"
  },
  {
    "text": "research engages and uh we move on to there so um on this slide here this is what the",
    "start": "1913799",
    "end": "1920120"
  },
  {
    "start": "1916000",
    "end": "2133000"
  },
  {
    "text": "researchers are doing and to walk through this flow a little bit they get a notification that there's a new image",
    "start": "1920120",
    "end": "1925279"
  },
  {
    "text": "available so they go out to Amazon uh to to Dynamo DB they retrieve the metadata information about it then they go out to",
    "start": "1925279",
    "end": "1931519"
  },
  {
    "text": "Amazon S3 actually fetch the image pass it on to tensorflow serving to do the categorization um classification and",
    "start": "1931519",
    "end": "1938519"
  },
  {
    "text": "then that information gets brought back and they persist that to um elastic",
    "start": "1938519",
    "end": "1944799"
  },
  {
    "text": "search we helped them set a lot of this up we didn't just kind of say hey here's some tech and go knock yourself out it",
    "start": "1946840",
    "end": "1953840"
  },
  {
    "text": "was it was really that collaborative effort working with these Technologies the Apache nii we wrote a custom processor for them in nii to interact",
    "start": "1953840",
    "end": "1961720"
  },
  {
    "text": "with the tensorflow serving um a little bit about the",
    "start": "1961720",
    "end": "1968279"
  },
  {
    "text": "research so that isn't so we're not doing the research so I can't at all speak authoritatively of this but I can",
    "start": "1968279",
    "end": "1974679"
  },
  {
    "text": "just tell you a little bit about what they're doing they're do doing deep learning uh they're creating custom models uh and they're training them um",
    "start": "1974679",
    "end": "1981279"
  },
  {
    "text": "and that's why they're using the tensorflow serving this is running on Amazon uh E2 and GPU instances as well",
    "start": "1981279",
    "end": "1988000"
  },
  {
    "text": "um some of the custom models they're working on on the research side one is a not safe for work uh classifier which",
    "start": "1988000",
    "end": "1994120"
  },
  {
    "text": "you can imagine what that one does and then the Geo a Geo interesting one a Geo inferencing one so given an image can",
    "start": "1994120",
    "end": "2000760"
  },
  {
    "text": "you uh determine what perhaps what region of of the world that that photograph was taken in so just a couple",
    "start": "2000760",
    "end": "2006880"
  },
  {
    "text": "examples and actually that research there they'll have a paper out probably by the end of the year um elastic search has has been a",
    "start": "2006880",
    "end": "2013639"
  },
  {
    "text": "great collaboration point for us as well in this case they're persisting that data to elastic search and they have a",
    "start": "2013639",
    "end": "2018840"
  },
  {
    "text": "UI that they wrote that interfaces with elastic search so they're able to do the searching uh on the image",
    "start": "2018840",
    "end": "2024120"
  },
  {
    "text": "classifications using elastic search and then there's a service it's not Illustrated here but in front of Amazon",
    "start": "2024120",
    "end": "2029360"
  },
  {
    "text": "S3 that they're able then to pull down the images and actually see them and that also is a great collaboration Point",
    "start": "2029360",
    "end": "2034639"
  },
  {
    "text": "as well for not just uh for the individual researcher but they can show that then the sponsors and uh see that",
    "start": "2034639",
    "end": "2040440"
  },
  {
    "text": "the how the research is going and how those things are are working so a couple questions you may have on this or one is",
    "start": "2040440",
    "end": "2047600"
  },
  {
    "text": "why did we do it this way right so if you're if you're looking at this and and you're following the flow like wow",
    "start": "2047600",
    "end": "2052960"
  },
  {
    "text": "that's a lot of work right why don't you just dump it into S3 and then go and batch load it and then do your",
    "start": "2052960",
    "end": "2059520"
  },
  {
    "text": "classification and do it that way why are you doing these notifications and all this other stuff this comes back to what we were talking about in the",
    "start": "2059520",
    "end": "2065240"
  },
  {
    "text": "beginning about research at aw at uh p L where we typically don't do research for",
    "start": "2065240",
    "end": "2071000"
  },
  {
    "text": "research sake but rather applied Solutions need to come out of it and this this is an example of this where we",
    "start": "2071000",
    "end": "2076638"
  },
  {
    "text": "what we have is really a live streaming system where our sponsor wants on demand",
    "start": "2076639",
    "end": "2082118"
  },
  {
    "text": "um classification uh and of of imagery coming in and we're able to scale that",
    "start": "2082119",
    "end": "2088398"
  },
  {
    "text": "out using AWS uh quite well and it's to the you know this whole flow from the",
    "start": "2088399",
    "end": "2094919"
  },
  {
    "text": "from the time it takes to get a Json message and go fetch it from the internet do all do all the work that you're seeing here and have it land in",
    "start": "2094919",
    "end": "2101800"
  },
  {
    "text": "elastic search um can take under 5 seconds with the biggest bottlenecks being fetching it from the internet and",
    "start": "2101800",
    "end": "2107800"
  },
  {
    "text": "then uh the the classification right and that and really the only bottleneck on the classification is how how much money",
    "start": "2107800",
    "end": "2113720"
  },
  {
    "text": "do you want to spend on GPU instances so um because the more you have the the faster it goes so this is it's an",
    "start": "2113720",
    "end": "2119560"
  },
  {
    "text": "impressive flow and it runs at scale uh and at scale you know meaning thousands of requests per second and it um it it",
    "start": "2119560",
    "end": "2126880"
  },
  {
    "text": "it runs well um trying to think here all",
    "start": "2126880",
    "end": "2133000"
  },
  {
    "start": "2133000",
    "end": "2194000"
  },
  {
    "text": "right with that you know collaboration researchers and Engineers are happy um",
    "start": "2133000",
    "end": "2138359"
  },
  {
    "text": "we're able to collaborate with researchers and get them engaged early in the process I it been would have been",
    "start": "2138359",
    "end": "2144560"
  },
  {
    "text": "much different if they had set up tensor flow serving on somebody's desktop and",
    "start": "2144560",
    "end": "2149839"
  },
  {
    "text": "then or GPU rather and and then uh they had uh uh you know had Python scripts run in and said hey we need to you know",
    "start": "2149839",
    "end": "2156359"
  },
  {
    "text": "we need to scale this out and have it be streaming like uh okay that's a lot of work but in this case here because we",
    "start": "2156359",
    "end": "2161560"
  },
  {
    "text": "were able to engage with them uh much earlier on we already had that flow worked out and by the time they were ready to get more uh towards a",
    "start": "2161560",
    "end": "2169880"
  },
  {
    "text": "Deployable solution we were pretty well uh set up for that um these repeatable",
    "start": "2169880",
    "end": "2175880"
  },
  {
    "text": "you know data this is just an example of a data flow pattern repeatable data flow patterns we take these tools and we mix",
    "start": "2175880",
    "end": "2181880"
  },
  {
    "text": "and match them and we can do a lot of different work with them to help enable that research um it's really improved",
    "start": "2181880",
    "end": "2187040"
  },
  {
    "text": "our collaboration and um shorter time to deployments and capability development so with",
    "start": "2187040",
    "end": "2193760"
  },
  {
    "text": "that we uh certainly don't work alone there are dozens of us who are help that working on these things and and and um",
    "start": "2193760",
    "end": "2200680"
  },
  {
    "text": "putting these things together helping with the research so just few names out there just wanting to thank some folks",
    "start": "2200680",
    "end": "2206880"
  },
  {
    "text": "um and thank you any questions [Applause]",
    "start": "2206880",
    "end": "2219719"
  },
  {
    "text": "as your work incre do you have to manually in and increase number",
    "start": "2228359",
    "end": "2234359"
  },
  {
    "text": "of yeah we're not doing any type of oh sure sure she's asking how we",
    "start": "2237680",
    "end": "2242880"
  },
  {
    "start": "2238000",
    "end": "2354000"
  },
  {
    "text": "scale out the nii whether it's autoscaling or if we do that's how I'm interpreting yeah whether we autoscaling",
    "start": "2242880",
    "end": "2248119"
  },
  {
    "text": "it this manual um so typically the flows that we get in are pretty constant and so there'll be some variations so we we",
    "start": "2248119",
    "end": "2254800"
  },
  {
    "text": "were not currently doing any auto scaling uh with the nii instances we scale it out based on what we what the",
    "start": "2254800",
    "end": "2260920"
  },
  {
    "text": "average uh volume of the flow will be um but we've toyed around with the idea I",
    "start": "2260920",
    "end": "2267200"
  },
  {
    "text": "think we could um you have to specify in the configuration files the IP addresses ahead of time but if you it's possible",
    "start": "2267200",
    "end": "2274720"
  },
  {
    "text": "we're just not doing it so it's a it's it actually is kind of one of the limitations or things that we've looked",
    "start": "2274720",
    "end": "2280200"
  },
  {
    "text": "at maybe changing for certain parts of our flows is for that very reason is that you kind of have to do too much or",
    "start": "2280200",
    "end": "2285800"
  },
  {
    "text": "more predictive understanding of your scale just simply to prevent that just because you can't easily autoscale it or",
    "start": "2285800",
    "end": "2293000"
  },
  {
    "text": "as easily as other things if you want to so and then one of the other current challenges that we have with it is that",
    "start": "2293000",
    "end": "2299440"
  },
  {
    "text": "all the backing cues are really powerful but they back locally so that's one of",
    "start": "2299440",
    "end": "2304640"
  },
  {
    "text": "the problems with it is if you have a node offline or a node goes down you can't recover the data in that queue till it's back back online now they're",
    "start": "2304640",
    "end": "2311119"
  },
  {
    "text": "working on changing that so backing it was something else like a Kafka or an hdfs or something like that uh but right",
    "start": "2311119",
    "end": "2316920"
  },
  {
    "text": "now the cues the backing storage is local so my point is that if if you have",
    "start": "2316920",
    "end": "2322640"
  },
  {
    "text": "flows running and you have like 10,000 messages in flight on an individual instance and that instance goes down you",
    "start": "2322640",
    "end": "2328400"
  },
  {
    "text": "can't recover those IM those messages in Flight until the machine's back online so there's some scalability pieces of it",
    "start": "2328400",
    "end": "2334960"
  },
  {
    "text": "that that they're trying to work on so good question",
    "start": "2334960",
    "end": "2339440"
  },
  {
    "text": "he scient experiment",
    "start": "2345160",
    "end": "2350119"
  },
  {
    "text": "being for no the projects pay for it so the contracts pay for it as far as a VPC",
    "start": "2352960",
    "end": "2358040"
  },
  {
    "start": "2354000",
    "end": "2417000"
  },
  {
    "text": "is concerned so the way the lab is set up is that each project can have a separate um AWS sub account we have a",
    "start": "2358040",
    "end": "2364599"
  },
  {
    "text": "single master account right and then each project currently will get a sub account and then the vpcs uh within",
    "start": "2364599",
    "end": "2370680"
  },
  {
    "text": "those sub accounts it it's really up to the project to how they want to set that up uh and and how they want to secure",
    "start": "2370680",
    "end": "2376400"
  },
  {
    "text": "that with some oversight of course from the lab but there are cases like this one where we've have projects",
    "start": "2376400",
    "end": "2383079"
  },
  {
    "text": "collaborate together so that like for example other scientists that are on even other projects can have access to",
    "start": "2383079",
    "end": "2388839"
  },
  {
    "text": "the images and things like that so that they can collaborate on the capabilities right it's a great question we actually struggle with that one a little bit and",
    "start": "2388839",
    "end": "2395319"
  },
  {
    "text": "that's where the policies come in really handy too with I IM policies just to Mike's Point about the collaboration we",
    "start": "2395319",
    "end": "2401079"
  },
  {
    "text": "can give folks access to the to to the resources and data they're interested",
    "start": "2401079",
    "end": "2406720"
  },
  {
    "text": "in so once your research is all done arive the results yeah",
    "start": "2408079",
    "end": "2416160"
  },
  {
    "text": "yeah well I think in this case here this is applied research so the research when it's done will go live and this will be",
    "start": "2416160",
    "end": "2423040"
  },
  {
    "start": "2417000",
    "end": "2451000"
  },
  {
    "text": "a running system and the the results will be you know maybe the development or initial research that would would be up to the individual researchers to",
    "start": "2423040",
    "end": "2428839"
  },
  {
    "text": "decide how they wanted to persist",
    "start": "2428839",
    "end": "2432200"
  },
  {
    "text": "that if you're government I think there is that possibility can sorry sorry",
    "start": "2450920",
    "end": "2457800"
  },
  {
    "start": "2451000",
    "end": "2476000"
  },
  {
    "text": "he was asking dndo is that what you said if they could use some of our services um that would be a conversation I think",
    "start": "2457800",
    "end": "2463599"
  },
  {
    "text": "with the lab right",
    "start": "2463599",
    "end": "2467000"
  },
  {
    "text": "yeah yeah get let's exchange contact information we can follow up on that right we're we're always looking for",
    "start": "2475839",
    "end": "2481839"
  },
  {
    "start": "2476000",
    "end": "2501000"
  },
  {
    "text": "opportunity to do those kinds of things um which is another reason why we've been trying to push for the builds of",
    "start": "2481839",
    "end": "2487359"
  },
  {
    "text": "these kinds of things so that we can have other people contribute and collaborate as part of the process right so yeah good",
    "start": "2487359",
    "end": "2493800"
  },
  {
    "text": "question another question theb made as many",
    "start": "2493800",
    "end": "2500720"
  },
  {
    "text": "as so the question was have the other 16 Doe Labs made uh the same amount or similar strides I I believe a lot of",
    "start": "2500720",
    "end": "2507400"
  },
  {
    "start": "2501000",
    "end": "2549000"
  },
  {
    "text": "them are I believe a lot of them are actually moving in the same direction as us uh and a lot probably a lot for the",
    "start": "2507400",
    "end": "2512680"
  },
  {
    "text": "same reasons just simply that the physical environments are very limiting to them and then also you know one of",
    "start": "2512680",
    "end": "2517960"
  },
  {
    "text": "the key things that the labs want to do or be better about is collaborating amongst themselves right and not just",
    "start": "2517960",
    "end": "2523319"
  },
  {
    "text": "even amongst themselves but other for other collaborative reasons right like when you're working through power grid",
    "start": "2523319",
    "end": "2528440"
  },
  {
    "text": "or cyber or other things right and it's really difficult right now just given like trying to even share data or",
    "start": "2528440",
    "end": "2534200"
  },
  {
    "text": "content and all that so yeah question how do you",
    "start": "2534200",
    "end": "2540800"
  },
  {
    "text": "manage workflows do you use any of the Amazon tools like commit",
    "start": "2540800",
    "end": "2547480"
  },
  {
    "text": "and so for go ahead so she was asking how we we manage the and you're talking",
    "start": "2547480",
    "end": "2552640"
  },
  {
    "start": "2549000",
    "end": "2637000"
  },
  {
    "text": "about the flows right in AWS so so the flows and the management of the flows",
    "start": "2552640",
    "end": "2557800"
  },
  {
    "text": "has actually been one of the other key challenges with them so versioning the code behind the flows so like our custom",
    "start": "2557800",
    "end": "2563839"
  },
  {
    "text": "Nars or custom processors and all that is easy you can use your normal git flow so we we don't use a lot of the AWS",
    "start": "2563839",
    "end": "2569839"
  },
  {
    "text": "tooling yet we use git and Jenkins and all that stuff but then we do use like code deploy and stuff to push stuff out",
    "start": "2569839",
    "end": "2575760"
  },
  {
    "text": "but for the flows the templates themselves they're not nearly as easy to Version Control because they're really",
    "start": "2575760",
    "end": "2581920"
  },
  {
    "text": "backed by some complex XML um now with that said I know that uh the creators of",
    "start": "2581920",
    "end": "2587880"
  },
  {
    "text": "the folks that are developing nii have made a lot of strides in being able to do key Replacements or item Replacements",
    "start": "2587880",
    "end": "2593800"
  },
  {
    "text": "within the templates themselves so you could actually follow a similar pattern right so like here's an example one of",
    "start": "2593800",
    "end": "2599599"
  },
  {
    "text": "the challenges we have with the flows we don't make a lot of modifications between environments right like you wouldn't be changing something in Dev",
    "start": "2599599",
    "end": "2606240"
  },
  {
    "text": "test prod but the pointers or the properties for things like databases and",
    "start": "2606240",
    "end": "2611359"
  },
  {
    "text": "cues and all that stuff you would change and that's actually somewhat of a painful processor at least it was in the",
    "start": "2611359",
    "end": "2616760"
  },
  {
    "text": "1.2 version that we're using but they're making changes there so I guess to answer your question we don't do a lot with that right now but part of it is",
    "start": "2616760",
    "end": "2623520"
  },
  {
    "text": "the template limitations themselves the flow",
    "start": "2623520",
    "end": "2627559"
  },
  {
    "text": "limitations is a very good tool how does it do uh uh if it has multiple inputs",
    "start": "2630400",
    "end": "2635880"
  },
  {
    "text": "that to be join oh you like so she was asking how you can merge multiple end points so there's",
    "start": "2635880",
    "end": "2642040"
  },
  {
    "start": "2637000",
    "end": "2719000"
  },
  {
    "text": "funnels inside or the concept of a funnel inside the kni flows where you can attempt to join data together now",
    "start": "2642040",
    "end": "2647720"
  },
  {
    "text": "but it's not like um it's not like what you'd expect in terms of correlation now",
    "start": "2647720",
    "end": "2653280"
  },
  {
    "text": "that's again I think another feature that they've added that recently where you can actually use a correlation ID or",
    "start": "2653280",
    "end": "2658640"
  },
  {
    "text": "some equivalent to actually attach things together in the flow so pull from two dispar sources and bring them",
    "start": "2658640",
    "end": "2664040"
  },
  {
    "text": "together so the funnel I was talking about is simply just funneling things together and adding priorities and all that stuff the actual correlating of",
    "start": "2664040",
    "end": "2670760"
  },
  {
    "text": "multiple content from disparate sources I think is something that's either maybe there now or in the works I haven't used",
    "start": "2670760",
    "end": "2676520"
  },
  {
    "text": "it though have you I'm not I'm not entirely sure if they've made that available yet but I think it was at least on their road map",
    "start": "2676520",
    "end": "2683920"
  },
  {
    "text": "yeah another question in the backb from the Census so one of the",
    "start": "2683920",
    "end": "2689520"
  },
  {
    "text": "questions I had is glad you mention the other 16 Labs that you work with one of the things that we struggle with is how",
    "start": "2689520",
    "end": "2696160"
  },
  {
    "text": "collaborate agencies so have you put any thought into if you had to collaborate would you",
    "start": "2696160",
    "end": "2703960"
  },
  {
    "text": "use an external space where everybody would use that as as an Enterprise level",
    "start": "2703960",
    "end": "2709200"
  },
  {
    "text": "service and you know then you have to work dat sharing you put more that and talk later",
    "start": "2709200",
    "end": "2719599"
  },
  {
    "start": "2719000",
    "end": "2805000"
  },
  {
    "text": "yeah so the question and hopefully I get it right so the question was have we put more thought into finding better ways externally to collaborate with even uh",
    "start": "2719599",
    "end": "2727240"
  },
  {
    "text": "entities even outside the the lab system right is that correct so so we have put",
    "start": "2727240",
    "end": "2732800"
  },
  {
    "text": "a lot of thought in the types of things we build that would lead to that a lot of the challenges that we have in being",
    "start": "2732800",
    "end": "2738480"
  },
  {
    "text": "able to enable those kinds of things is just the physical environments and then the other items you brought up we should absolutely talk because we would be open",
    "start": "2738480",
    "end": "2745359"
  },
  {
    "text": "to suggestions there because we absolutely want to be part of that it's a lot of the limitations we have are just things outside of our control you",
    "start": "2745359",
    "end": "2751640"
  },
  {
    "text": "know like okay if you if you want to create a collaborative environment under what funding and under what project",
    "start": "2751640",
    "end": "2757040"
  },
  {
    "text": "under what account right do you do that that kind of stuff it's not that we don't have or other labs for that matter",
    "start": "2757040",
    "end": "2762960"
  },
  {
    "text": "don't have the tooling or Solutions in place to do it it's just finding the physical environments and I think that's",
    "start": "2762960",
    "end": "2768319"
  },
  {
    "text": "where we need to try to converge and we do collaborate outside the lab in some cases right so it's not like that that",
    "start": "2768319",
    "end": "2774440"
  },
  {
    "text": "the infrastructure you saw only pnnl uses that that's not the case at all we have external partners that are able to",
    "start": "2774440",
    "end": "2780200"
  },
  {
    "text": "access those systems and we're able to use AWS the IM policies and whatnot to to to help configure that so but it",
    "start": "2780200",
    "end": "2786119"
  },
  {
    "text": "would be a conversation we' want to have",
    "start": "2786119",
    "end": "2790200"
  },
  {
    "start": "2805000",
    "end": "2955000"
  },
  {
    "text": "yeah he asked how long did it take to build the uh that particular flow and how long how big was the what the team",
    "start": "2805040",
    "end": "2811280"
  },
  {
    "text": "oh the dev team so we have a Dev team like probably on that flow what about three to five somewhere in there five",
    "start": "2811280",
    "end": "2817119"
  },
  {
    "text": "maybe uh developers and so that that flow actually didn't take that long",
    "start": "2817119",
    "end": "2822559"
  },
  {
    "text": "because there's a bunch of hard work that went into before that to learning",
    "start": "2822559",
    "end": "2827680"
  },
  {
    "text": "to do that right to create that particular flow right and so what was you know we showed the data coming off",
    "start": "2827680",
    "end": "2832920"
  },
  {
    "text": "kofka what's not being shown on there is is how the data is coming into the system and that you know is a big big",
    "start": "2832920",
    "end": "2840040"
  },
  {
    "text": "dependency on where that data is coming from how we need to bring it in consume it you know and before it even ends up",
    "start": "2840040",
    "end": "2845400"
  },
  {
    "text": "on kofka so sorry not to be vague to your question um but I would say it took",
    "start": "2845400",
    "end": "2850920"
  },
  {
    "text": "um I don't know what 3 months maybe yeah the the the most of the pipeline was trivial right I'm not trying to",
    "start": "2850920",
    "end": "2857160"
  },
  {
    "text": "oversimplify it but it wasn't all that complex simply for what Ralph said we've gone through a lot of pains and doing things wrong or picking the wrong tools",
    "start": "2857160",
    "end": "2863599"
  },
  {
    "text": "or right or whatever the part that's taken quite a while is trying to optimize the tensor flow yes and so",
    "start": "2863599",
    "end": "2869280"
  },
  {
    "text": "because one of the things that are are our researchers are trying to do is trying to build Docker images for the",
    "start": "2869280",
    "end": "2875160"
  },
  {
    "text": "bundling of the tensor flow service in pieces because they don't want to use the out of the box stuff because then they can't write their custom models",
    "start": "2875160",
    "end": "2881319"
  },
  {
    "text": "that in addition to the custom models themselves so really a lot of our challenges or their challenges was",
    "start": "2881319",
    "end": "2886520"
  },
  {
    "text": "outside the basic pipelines and then part of that is just our learning the learning process for from other things",
    "start": "2886520",
    "end": "2892359"
  },
  {
    "text": "and then just how easy some of the Amazon services are to use right I mean they really are just attaching a KN fire",
    "start": "2892359",
    "end": "2897559"
  },
  {
    "text": "and equivalent is not all that difficult and and just be clear we we know there's some really cool ways we could do a lot of that in nii in a in AWS um in our",
    "start": "2897559",
    "end": "2905960"
  },
  {
    "text": "environment we often because we have to deploy Solutions there's cases where where",
    "start": "2905960",
    "end": "2912440"
  },
  {
    "text": "we're deploying it AWS is not available so we use a lot of AWS Services where we're able to but we always have to be",
    "start": "2912440",
    "end": "2917680"
  },
  {
    "text": "cognizant of where this is going to end up and what technologies we're going to have to end up using in that space so",
    "start": "2917680",
    "end": "2922880"
  },
  {
    "text": "just a quick note as well and to Mike's Point the flow was really actually pretty quick to create",
    "start": "2922880",
    "end": "2928800"
  },
  {
    "text": "it's the it's the tensor flow serving it's the Lambda function iterating on that making sure we're getting that",
    "start": "2928800",
    "end": "2933839"
  },
  {
    "text": "right and that was the hard part right so yeah all right well we're uh we're at",
    "start": "2933839",
    "end": "2940359"
  },
  {
    "text": "time I just want to really thank both of you so much for being so generous with your time and expertise this was a deep",
    "start": "2940359",
    "end": "2946880"
  },
  {
    "text": "but very practical session so thank you so much for for coming to be with us today thank prise thank you",
    "start": "2946880",
    "end": "2956240"
  }
]
[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "hi my name is Emily Weber I'm the",
    "start": "30",
    "end": "2760"
  },
  {
    "text": "machine learning specialist at Amazon",
    "start": "2760",
    "end": "4410"
  },
  {
    "text": "Web Services I hope you've been enjoying",
    "start": "4410",
    "end": "6240"
  },
  {
    "text": "our videos we've learned a lot about",
    "start": "6240",
    "end": "8069"
  },
  {
    "text": "notebook instances built in algorithms",
    "start": "8069",
    "end": "11070"
  },
  {
    "text": "using machine learning marketplace",
    "start": "11070",
    "end": "12870"
  },
  {
    "text": "algorithms bringing your own we learned",
    "start": "12870",
    "end": "15150"
  },
  {
    "text": "about training and tuning jobs now we're",
    "start": "15150",
    "end": "17880"
  },
  {
    "text": "gonna learn about deployment options on",
    "start": "17880",
    "end": "19740"
  },
  {
    "text": "Amazon sage maker and this is your deep",
    "start": "19740",
    "end": "21810"
  },
  {
    "text": "dive so first off there's a thing that's",
    "start": "21810",
    "end": "24750"
  },
  {
    "start": "23000",
    "end": "156000"
  },
  {
    "text": "called an endpoint the sage maker",
    "start": "24750",
    "end": "26369"
  },
  {
    "text": "endpoint what is this this is multiple",
    "start": "26369",
    "end": "29220"
  },
  {
    "text": "can be multiple ec2 instances in case of",
    "start": "29220",
    "end": "31980"
  },
  {
    "text": "multiple ec2 instances there are over",
    "start": "31980",
    "end": "33840"
  },
  {
    "text": "different availability zones in order to",
    "start": "33840",
    "end": "36120"
  },
  {
    "text": "increase your high availability when you",
    "start": "36120",
    "end": "38550"
  },
  {
    "text": "specify model deploy in the sage maker",
    "start": "38550",
    "end": "41879"
  },
  {
    "text": "Python SDK that is a single line of code",
    "start": "41879",
    "end": "44100"
  },
  {
    "text": "that you're gonna get to run right just",
    "start": "44100",
    "end": "45989"
  },
  {
    "text": "one time run that cell that's gonna spin",
    "start": "45989",
    "end": "48960"
  },
  {
    "text": "up a managed end point and your endpoint",
    "start": "48960",
    "end": "51960"
  },
  {
    "text": "that's multiple ec2 instances each ec2",
    "start": "51960",
    "end": "54449"
  },
  {
    "text": "instance is gonna have a webserver",
    "start": "54449",
    "end": "56760"
  },
  {
    "text": "that's gonna be able to respond to",
    "start": "56760",
    "end": "58170"
  },
  {
    "text": "requests and it's gonna have your model",
    "start": "58170",
    "end": "60570"
  },
  {
    "text": "artifact and so each instance is going",
    "start": "60570",
    "end": "63120"
  },
  {
    "text": "to be serving prediction responses those",
    "start": "63120",
    "end": "65309"
  },
  {
    "text": "are gonna be handled by a load balancer",
    "start": "65309",
    "end": "67140"
  },
  {
    "text": "so your load balancer is taking care of",
    "start": "67140",
    "end": "69780"
  },
  {
    "text": "health checks making sure that your",
    "start": "69780",
    "end": "71369"
  },
  {
    "text": "instances are up all of those are gonna",
    "start": "71369",
    "end": "73650"
  },
  {
    "text": "be sitting behind your model endpoint",
    "start": "73650",
    "end": "75930"
  },
  {
    "text": "your endpoint is a restful api stage",
    "start": "75930",
    "end": "79409"
  },
  {
    "text": "maker is automatically creating a",
    "start": "79409",
    "end": "81659"
  },
  {
    "text": "restful api for your specific model for",
    "start": "81659",
    "end": "84869"
  },
  {
    "text": "every model that you deploy on Sage",
    "start": "84869",
    "end": "87030"
  },
  {
    "text": "Maker and so this gonna operate like any",
    "start": "87030",
    "end": "89369"
  },
  {
    "text": "restful api you've got json accepts and",
    "start": "89369",
    "end": "91920"
  },
  {
    "text": "responses we see customers very commonly",
    "start": "91920",
    "end": "95040"
  },
  {
    "text": "using lambda to connect between your two",
    "start": "95040",
    "end": "98130"
  },
  {
    "text": "points you've got your api gateway when",
    "start": "98130",
    "end": "100920"
  },
  {
    "text": "you need information coming from the",
    "start": "100920",
    "end": "102600"
  },
  {
    "text": "internet to hit your AWS services and so",
    "start": "102600",
    "end": "105390"
  },
  {
    "text": "most commonly you're going to be",
    "start": "105390",
    "end": "106979"
  },
  {
    "text": "securing your services with a V PC so a",
    "start": "106979",
    "end": "109950"
  },
  {
    "text": "virtual private cloud that's making sure",
    "start": "109950",
    "end": "112560"
  },
  {
    "text": "that your resources are secure you're",
    "start": "112560",
    "end": "115259"
  },
  {
    "text": "gonna open up access between that cloud",
    "start": "115259",
    "end": "117960"
  },
  {
    "text": "and the Internet using the API gateway",
    "start": "117960",
    "end": "120420"
  },
  {
    "text": "and then AWS lambda can be a reference",
    "start": "120420",
    "end": "122759"
  },
  {
    "text": "point you're not locked into lambda you",
    "start": "122759",
    "end": "124710"
  },
  {
    "text": "can actually go straight from your",
    "start": "124710",
    "end": "126149"
  },
  {
    "text": "endpoint to the API gateway or you can",
    "start": "126149",
    "end": "128729"
  },
  {
    "text": "use what's called an inference pipeline",
    "start": "128729",
    "end": "130709"
  },
  {
    "text": "which we're going to learn about in a",
    "start": "130709",
    "end": "131970"
  },
  {
    "text": "second here to actually set that up",
    "start": "131970",
    "end": "134200"
  },
  {
    "text": "Landa just gives you lots of flexibility",
    "start": "134200",
    "end": "136090"
  },
  {
    "text": "and customers love it so that is your",
    "start": "136090",
    "end": "138730"
  },
  {
    "text": "sage maker end point so your sage maker",
    "start": "138730",
    "end": "140650"
  },
  {
    "text": "end point is best for cases of online",
    "start": "140650",
    "end": "142720"
  },
  {
    "text": "inferencing when you have data that's",
    "start": "142720",
    "end": "144580"
  },
  {
    "text": "coming in from the internet and you need",
    "start": "144580",
    "end": "146770"
  },
  {
    "text": "to serve prediction responses in real",
    "start": "146770",
    "end": "148780"
  },
  {
    "text": "time so we're talking sub-second latency",
    "start": "148780",
    "end": "150819"
  },
  {
    "text": "right you need your responses to be fast",
    "start": "150819",
    "end": "152709"
  },
  {
    "text": "and that's what your sage make your",
    "start": "152709",
    "end": "154239"
  },
  {
    "text": "endpoint is gonna be for let's check out",
    "start": "154239",
    "end": "155860"
  },
  {
    "text": "an example so over here this training",
    "start": "155860",
    "end": "158620"
  },
  {
    "start": "156000",
    "end": "323000"
  },
  {
    "text": "job was from a one that we ran",
    "start": "158620",
    "end": "161140"
  },
  {
    "text": "previously so this was for a blazing",
    "start": "161140",
    "end": "163630"
  },
  {
    "text": "text so essentially the scenario here",
    "start": "163630",
    "end": "166900"
  },
  {
    "text": "right we've got those wikipedia articles",
    "start": "166900",
    "end": "169080"
  },
  {
    "text": "and those wikipedia articles are labeled",
    "start": "169080",
    "end": "172090"
  },
  {
    "text": "based on the content of that article and",
    "start": "172090",
    "end": "174190"
  },
  {
    "text": "then we plug those into the sage maker",
    "start": "174190",
    "end": "178150"
  },
  {
    "text": "built an algorithm called blazing text",
    "start": "178150",
    "end": "180489"
  },
  {
    "text": "and just to recap here so that happened",
    "start": "180489",
    "end": "184470"
  },
  {
    "text": "down here right that's our container",
    "start": "184470",
    "end": "187890"
  },
  {
    "text": "that's our role that's our resource",
    "start": "187890",
    "end": "190600"
  },
  {
    "text": "utilization and then we specified our",
    "start": "190600",
    "end": "193989"
  },
  {
    "text": "channels we've got our train of",
    "start": "193989",
    "end": "195430"
  },
  {
    "text": "validation channel we set those up down",
    "start": "195430",
    "end": "197799"
  },
  {
    "text": "here then we called model dot fit and in",
    "start": "197799",
    "end": "201220"
  },
  {
    "text": "this case we got all the logs printed",
    "start": "201220",
    "end": "202810"
  },
  {
    "text": "out down here",
    "start": "202810",
    "end": "206680"
  },
  {
    "text": "we're gonna hit model dot deploy and so",
    "start": "206680",
    "end": "210280"
  },
  {
    "text": "this is another cluster right it's",
    "start": "210280",
    "end": "212109"
  },
  {
    "text": "another ec2 instance this was is an m4",
    "start": "212109",
    "end": "215170"
  },
  {
    "text": "Excel and then we're gonna reference",
    "start": "215170",
    "end": "217570"
  },
  {
    "text": "that classifier right here and so when",
    "start": "217570",
    "end": "220239"
  },
  {
    "text": "we want prediction responses those are",
    "start": "220239",
    "end": "224049"
  },
  {
    "text": "actually gonna go up and hit our",
    "start": "224049",
    "end": "225370"
  },
  {
    "text": "endpoint let me show you so in the",
    "start": "225370",
    "end": "226810"
  },
  {
    "text": "console we can cruise down and look at",
    "start": "226810",
    "end": "229120"
  },
  {
    "text": "endpoints and so this is our blazing",
    "start": "229120",
    "end": "232450"
  },
  {
    "text": "text endpoint it's status is up this is",
    "start": "232450",
    "end": "235660"
  },
  {
    "text": "the URL so that's actually the one that",
    "start": "235660",
    "end": "237400"
  },
  {
    "text": "you're gonna hit when you're making",
    "start": "237400",
    "end": "239109"
  },
  {
    "text": "calls and here's our invocation metrics",
    "start": "239109",
    "end": "242230"
  },
  {
    "text": "right so we've got we've got these nice",
    "start": "242230",
    "end": "244090"
  },
  {
    "text": "charts here they're gonna tell us how",
    "start": "244090",
    "end": "245680"
  },
  {
    "text": "its performing that's the name of our",
    "start": "245680",
    "end": "249069"
  },
  {
    "text": "model our model is gonna have a",
    "start": "249069",
    "end": "250750"
  },
  {
    "text": "production variant that production",
    "start": "250750",
    "end": "252819"
  },
  {
    "text": "variant tells us what percentage of",
    "start": "252819",
    "end": "255040"
  },
  {
    "text": "traffic is going to be hitting that",
    "start": "255040",
    "end": "256510"
  },
  {
    "text": "model for every point in time and so",
    "start": "256510",
    "end": "259539"
  },
  {
    "text": "over here the two examples that we're",
    "start": "259539",
    "end": "262360"
  },
  {
    "text": "sending up one is about convair and",
    "start": "262360",
    "end": "264099"
  },
  {
    "text": "another is Berwick Secondary College and",
    "start": "264099",
    "end": "267720"
  },
  {
    "text": "both of those come back with different",
    "start": "267720",
    "end": "269670"
  },
  {
    "text": "classification responses right so the",
    "start": "269670",
    "end": "271230"
  },
  {
    "text": "first one has a probability of 99",
    "start": "271230",
    "end": "273660"
  },
  {
    "text": "percent and that label is a company the",
    "start": "273660",
    "end": "276540"
  },
  {
    "text": "second one down here is a probability of",
    "start": "276540",
    "end": "278280"
  },
  {
    "text": "also over 99% and the label is an",
    "start": "278280",
    "end": "280620"
  },
  {
    "text": "educational institution let's have some",
    "start": "280620",
    "end": "282660"
  },
  {
    "text": "fun right so I'm gonna I'm gonna delete",
    "start": "282660",
    "end": "284370"
  },
  {
    "text": "these sentences and I'm gonna paste in",
    "start": "284370",
    "end": "287970"
  },
  {
    "text": "I'm gonna say all right there we go",
    "start": "287970",
    "end": "301440"
  },
  {
    "text": "so that is hitting our end point right",
    "start": "301440",
    "end": "304080"
  },
  {
    "text": "that's actually um being packaged up",
    "start": "304080",
    "end": "307230"
  },
  {
    "text": "it's a RESTful API so we have to",
    "start": "307230",
    "end": "308820"
  },
  {
    "text": "actually dump it into JSON then we just",
    "start": "308820",
    "end": "311190"
  },
  {
    "text": "called text classifier dot predict right",
    "start": "311190",
    "end": "314610"
  },
  {
    "text": "that hits the end point we get the",
    "start": "314610",
    "end": "316410"
  },
  {
    "text": "response back which is another JSON",
    "start": "316410",
    "end": "318450"
  },
  {
    "text": "object so we have to decode it and then",
    "start": "318450",
    "end": "320520"
  },
  {
    "text": "we can actually look at the prediction",
    "start": "320520",
    "end": "321660"
  },
  {
    "text": "responses so some clothes some pro tips",
    "start": "321660",
    "end": "325560"
  },
  {
    "start": "323000",
    "end": "472000"
  },
  {
    "text": "here just to close things out right",
    "start": "325560",
    "end": "327120"
  },
  {
    "text": "definitely turn your endpoints off when",
    "start": "327120",
    "end": "329550"
  },
  {
    "text": "you're when you're not actually using",
    "start": "329550",
    "end": "330780"
  },
  {
    "text": "them you can write lambda functions to",
    "start": "330780",
    "end": "333450"
  },
  {
    "text": "do this definitely leverage the",
    "start": "333450",
    "end": "336120"
  },
  {
    "text": "servantless architecture that you have",
    "start": "336120",
    "end": "337590"
  },
  {
    "text": "in order to turn your instances off when",
    "start": "337590",
    "end": "339780"
  },
  {
    "text": "you're not actually using them you can",
    "start": "339780",
    "end": "341610"
  },
  {
    "text": "also use what are called inference",
    "start": "341610",
    "end": "343440"
  },
  {
    "text": "pipelines to manage both pre and",
    "start": "343440",
    "end": "345570"
  },
  {
    "text": "post-processing so that's where you can",
    "start": "345570",
    "end": "348480"
  },
  {
    "text": "create a number of containers up to five",
    "start": "348480",
    "end": "351240"
  },
  {
    "text": "containers and then actually just run",
    "start": "351240",
    "end": "353400"
  },
  {
    "text": "them sequence to sequence so you'll have",
    "start": "353400",
    "end": "355050"
  },
  {
    "text": "in a one container that's managing your",
    "start": "355050",
    "end": "357810"
  },
  {
    "text": "feature pre-processing that's gonna pass",
    "start": "357810",
    "end": "360360"
  },
  {
    "text": "it into another container where you're",
    "start": "360360",
    "end": "361890"
  },
  {
    "text": "doing your model inferencing which will",
    "start": "361890",
    "end": "363720"
  },
  {
    "text": "then pass it out to a post processing",
    "start": "363720",
    "end": "365490"
  },
  {
    "text": "and that's gonna be your if-then-else",
    "start": "365490",
    "end": "367650"
  },
  {
    "text": "statement based on the confidence level",
    "start": "367650",
    "end": "369450"
  },
  {
    "text": "that your model actually identified so",
    "start": "369450",
    "end": "371460"
  },
  {
    "text": "you can deploy that entire inference",
    "start": "371460",
    "end": "374010"
  },
  {
    "text": "pipeline as a single endpoint those",
    "start": "374010",
    "end": "376860"
  },
  {
    "text": "containers are going to be co-located on",
    "start": "376860",
    "end": "379200"
  },
  {
    "text": "the same ec2 instance so just make sure",
    "start": "379200",
    "end": "381480"
  },
  {
    "text": "you're picking your resource correctly",
    "start": "381480",
    "end": "383100"
  },
  {
    "text": "so that you're not gonna run into any",
    "start": "383100",
    "end": "384870"
  },
  {
    "text": "memory or disk errors you can also have",
    "start": "384870",
    "end": "387660"
  },
  {
    "text": "more models in a single docker container",
    "start": "387660",
    "end": "389850"
  },
  {
    "text": "right so even though a docker can it's",
    "start": "389850",
    "end": "391770"
  },
  {
    "text": "one docker container per training",
    "start": "391770",
    "end": "393630"
  },
  {
    "text": "cluster you can definitely have multiple",
    "start": "393630",
    "end": "395550"
  },
  {
    "text": "models in that container you just have",
    "start": "395550",
    "end": "399000"
  },
  {
    "text": "to write the code you know",
    "start": "399000",
    "end": "400439"
  },
  {
    "text": "in a way that in the way that does the",
    "start": "400439",
    "end": "401849"
  },
  {
    "text": "job and also making sure that you have",
    "start": "401849",
    "end": "404309"
  },
  {
    "text": "sufficient infrastructure to get that",
    "start": "404309",
    "end": "405839"
  },
  {
    "text": "done",
    "start": "405839",
    "end": "406319"
  },
  {
    "text": "I definitely think about the amount of",
    "start": "406319",
    "end": "407909"
  },
  {
    "text": "data that's hitting a single end point",
    "start": "407909",
    "end": "409979"
  },
  {
    "text": "some of the limitations there are such",
    "start": "409979",
    "end": "412769"
  },
  {
    "text": "that you want to not be sending too much",
    "start": "412769",
    "end": "414839"
  },
  {
    "text": "data for an end point if you've got you",
    "start": "414839",
    "end": "417419"
  },
  {
    "text": "know more than a handful of megabytes",
    "start": "417419",
    "end": "419699"
  },
  {
    "text": "and definitely you want to be sending",
    "start": "419699",
    "end": "420809"
  },
  {
    "text": "that up against the batch transform",
    "start": "420809",
    "end": "422129"
  },
  {
    "text": "rather than the end point um and just to",
    "start": "422129",
    "end": "425039"
  },
  {
    "text": "hit this home you can absolutely train",
    "start": "425039",
    "end": "427349"
  },
  {
    "text": "your model somewhere else and then host",
    "start": "427349",
    "end": "429360"
  },
  {
    "text": "it in Sage Maker right so you're not",
    "start": "429360",
    "end": "430830"
  },
  {
    "text": "locked in on doing this step by step if",
    "start": "430830",
    "end": "433079"
  },
  {
    "text": "you like your training platform on your",
    "start": "433079",
    "end": "435869"
  },
  {
    "text": "DAP on your laptop or you like your",
    "start": "435869",
    "end": "437610"
  },
  {
    "text": "training platform somewhere else look at",
    "start": "437610",
    "end": "440279"
  },
  {
    "text": "some of the information on our blog",
    "start": "440279",
    "end": "441809"
  },
  {
    "text": "series about getting that into the right",
    "start": "441809",
    "end": "444269"
  },
  {
    "text": "format and then actually just hosting it",
    "start": "444269",
    "end": "446639"
  },
  {
    "text": "in Sage maker so you can use the",
    "start": "446639",
    "end": "448379"
  },
  {
    "text": "endpoints or the batch transforms and so",
    "start": "448379",
    "end": "451050"
  },
  {
    "text": "thank you that's all got my name is",
    "start": "451050",
    "end": "452969"
  },
  {
    "text": "Emily Webber I'm a machine learning",
    "start": "452969",
    "end": "454589"
  },
  {
    "text": "specialist at Amazon Web Services we",
    "start": "454589",
    "end": "456779"
  },
  {
    "text": "just learned about deployment options",
    "start": "456779",
    "end": "458279"
  },
  {
    "text": "and if you're interested definitely",
    "start": "458279",
    "end": "459509"
  },
  {
    "text": "check out our github sites thank you",
    "start": "459509",
    "end": "461519"
  },
  {
    "text": "very much",
    "start": "461519",
    "end": "463819"
  },
  {
    "text": "you",
    "start": "469770",
    "end": "471830"
  }
]
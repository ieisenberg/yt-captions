[
  {
    "text": "Hello. This is Yongjin Cho \nfrom Amazon Web Services.",
    "start": "6929",
    "end": "10042"
  },
  {
    "text": "In this 'This is My Architecture', we've invited \nYousu Mok, who built the BI platform",
    "start": "10042",
    "end": "15757"
  },
  {
    "text": "on Lotte ON, the new e-commerce platform \nof the Lotte Group.",
    "start": "15757",
    "end": "20487"
  },
  {
    "text": "Hello.",
    "start": "20488",
    "end": "22149"
  },
  {
    "text": "Thank you for coming today. ",
    "start": "22149",
    "end": "23597"
  },
  {
    "text": "First, please introduce yourself.",
    "start": "23597",
    "end": "25870"
  },
  {
    "text": "I'm Yousu Mok from the Big Data Business Team \nof Lotte Information Communication. ",
    "start": "25870",
    "end": "30656"
  },
  {
    "text": "Thank you for inviting me.",
    "start": "30656",
    "end": "32155"
  },
  {
    "text": "The architecture that I will introduce today \nis Lotte ON's BI platform.",
    "start": "32912",
    "end": "37344"
  },
  {
    "text": "Our platform provides sales, link traffic, and \nmultidimensional analysis results of online stores",
    "start": "37345",
    "end": "45675"
  },
  {
    "text": "or open market sellers of Lotte affiliates \nin the semi-real time.",
    "start": "45675",
    "end": "47843"
  },
  {
    "text": "BI platforms have various characteristics \ndepending on the purpose of use.",
    "start": "47844",
    "end": "56284"
  },
  {
    "text": "What was the most important thing \nwhen you were designing this platform?",
    "start": "56284",
    "end": "61316"
  },
  {
    "text": "When I planned and designed the platform, we aimed \nto integrate the platform with business data within the affiliates.",
    "start": "61316",
    "end": "71830"
  },
  {
    "text": "The users in our platform are salesmen, \nmarketers of affiliated distributors,",
    "start": "71830",
    "end": "77991"
  },
  {
    "text": "and executives.",
    "start": "77991",
    "end": "79612"
  },
  {
    "text": "By providing the integrated management \nof affiliated distributors and indicators for each affiliate,",
    "start": "79612",
    "end": "87214"
  },
  {
    "text": "the management visibility of the e-commerce business is increased, ",
    "start": "87214",
    "end": "89978"
  },
  {
    "text": "and various linkage systems are added \ncentering on Lotte ON ",
    "start": "89978",
    "end": "95185"
  },
  {
    "text": "to provide the data analysis in web and mobile formats.",
    "start": "95185",
    "end": "99911"
  },
  {
    "text": "So, the platform itself was designed to be very flexible,",
    "start": "99912",
    "end": "105479"
  },
  {
    "text": "and highly scalable.",
    "start": "105479",
    "end": "108671"
  },
  {
    "text": "It also has high performance \nbecause you considered the various affiliates and users.",
    "start": "108671",
    "end": "112475"
  },
  {
    "text": "Then, would you please explain what kind of data analysis\n you use through this platform and how you get insights.",
    "start": "112475",
    "end": "119514"
  },
  {
    "text": "First, let me explain by looking at the diagram.",
    "start": "119514",
    "end": "122054"
  },
  {
    "text": "We have various data sources such as traffic DB, \nDynamoDB, RDS, Redshift, and Elasticsearch.",
    "start": "123210",
    "end": "136497"
  },
  {
    "text": "The structured and unstructured data \nis stored in the Data Lake",
    "start": "136497",
    "end": "140765"
  },
  {
    "text": "by using the third-party ETL tools and Glue.",
    "start": "140765",
    "end": "145941"
  },
  {
    "text": "This stored data is purified in Glue by using \nSpark, Python, Redshift Spectrum and Procedure,",
    "start": "145941",
    "end": "158872"
  },
  {
    "text": "and then the purified data is stored in Redshift.",
    "start": "158873",
    "end": "163371"
  },
  {
    "text": "This stored data is provided to customers \nby using BI tools.",
    "start": "163371",
    "end": "168304"
  },
  {
    "text": "In order to provide as much real-time data as possible, \ndifferent pipelines such as 10 minutes, 1 hour, and daily",
    "start": "168304",
    "end": "176090"
  },
  {
    "text": "are configured and utilized according to the task.",
    "start": "176090",
    "end": "177842"
  },
  {
    "text": "Yes, I think they are providing data analysis results \nin different time units.",
    "start": "178604",
    "end": "183113"
  },
  {
    "text": "In that case, ",
    "start": "183113",
    "end": "185807"
  },
  {
    "text": "if you have to process data every 10 minutes, \nit will be difficult when the amount of data is huge.",
    "start": "185807",
    "end": "191223"
  },
  {
    "text": "How did you configure it?",
    "start": "191223",
    "end": "193060"
  },
  {
    "text": "First, we used Redshift's Spectrum feature",
    "start": "193060",
    "end": "196500"
  },
  {
    "text": "to process data every 10 minutes.",
    "start": "196501",
    "end": "200079"
  },
  {
    "text": "The Redshift Spectrum's SQL \nis used by directly accessing data.",
    "start": "200079",
    "end": "206978"
  },
  {
    "text": "In the case of the contrast indicators \nsuch as yesterday, last month, and last year,",
    "start": "206978",
    "end": "213051"
  },
  {
    "text": "the daily batch is configured and used in advance.",
    "start": "213051",
    "end": "215810"
  },
  {
    "text": "Yes, when I look at the architecture, \nthe next part seems more complicated.",
    "start": "216561",
    "end": "220891"
  },
  {
    "text": "There seem different data sources.",
    "start": "220891",
    "end": "222720"
  },
  {
    "text": "Those different data sources would have different formats.",
    "start": "222720",
    "end": "226352"
  },
  {
    "text": "How did you integrate them? ",
    "start": "226352",
    "end": "229790"
  },
  {
    "text": "Yes, first, we are taking Parquet format as the data format. ",
    "start": "229790",
    "end": "235364"
  },
  {
    "text": "And, in the case of overlapping data \nsuch as traffic DB and DynamoDB,",
    "start": "235365",
    "end": "241446"
  },
  {
    "text": "we do that in Parsing.",
    "start": "241446",
    "end": "243980"
  },
  {
    "text": "First, in the case of traffic DB, \nit is saved in the Data Lake",
    "start": "243980",
    "end": "248456"
  },
  {
    "text": "as Avro format.",
    "start": "248456",
    "end": "250312"
  },
  {
    "text": "The saved data is converted to Parquet format \nand used in Parsing by utilizing ",
    "start": "250313",
    "end": "257153"
  },
  {
    "text": "the Redshift Spectrum function. ",
    "start": "257153",
    "end": "258834"
  },
  {
    "text": "In the case of DynamoDB, \nthe columns of nested data are declared as streams,",
    "start": "258834",
    "end": "264793"
  },
  {
    "text": "the declared data is stored in Redshift, \nand the JSON function in Redshift is used",
    "start": "264793",
    "end": "271313"
  },
  {
    "text": "in Parsing. ",
    "start": "271313",
    "end": "272832"
  },
  {
    "text": "Thank you for the explanation. ",
    "start": "272833",
    "end": "275315"
  },
  {
    "text": "You've explained how to integrate data,\nand the current architecture.",
    "start": "275315",
    "end": "283562"
  },
  {
    "text": "What's your plan to evolve \nthis architecture in the future?",
    "start": "283562",
    "end": "287777"
  },
  {
    "text": "Yes, we plan to provide forecasting insights \nby using the AWS Forecast service ",
    "start": "287777",
    "end": "293091"
  },
  {
    "text": "and expand real-time analytics \nthrough streaming data collection. ",
    "start": "293091",
    "end": "298619"
  },
  {
    "text": "I understand that you are going to use AI \nor machine learning to advance the analysis results",
    "start": "298619",
    "end": "304850"
  },
  {
    "text": "and the construction of a streaming data pipeline \nthat take less time.",
    "start": "304851",
    "end": "310577"
  },
  {
    "text": "Thanks for your explanation in detail.",
    "start": "310577",
    "end": "313151"
  },
  {
    "text": "Today, we have introduced the architecture \nof Lotte ON's BI platform.",
    "start": "314772",
    "end": "319285"
  },
  {
    "text": "Thank you, Yousu Mok, \nfor providing such a detailed introduction.",
    "start": "319285",
    "end": "323236"
  },
  {
    "text": "This has been 'This is My Architecture'.",
    "start": "323236",
    "end": "326145"
  },
  {
    "text": "Thank you.",
    "start": "326145",
    "end": "327034"
  }
]
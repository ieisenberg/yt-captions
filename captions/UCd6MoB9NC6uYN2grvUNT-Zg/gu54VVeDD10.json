[
  {
    "text": "Hi, welcome to another episode \nof 'This Is My Architecture'.",
    "start": "7223",
    "end": "10434"
  },
  {
    "text": "I'm David John and I have \nwith me Swarup from FPL Technologies.",
    "start": "10700",
    "end": "13837"
  },
  {
    "text": "Hi Swarup, welcome to the show.",
    "start": "14451",
    "end": "16243"
  },
  {
    "text": "Hello David, thank you for inviting me.",
    "start": "16243",
    "end": "18310"
  },
  {
    "text": "So let's get started, tell us \nsomething about FPL Technologies.",
    "start": "18505",
    "end": "21831"
  },
  {
    "text": "Well, FPL Technologies\nis on a mission to reimagine credit card ",
    "start": "22010",
    "end": "25348"
  },
  {
    "text": "and payments from First Principle",
    "start": "25348",
    "end": "27024"
  },
  {
    "text": "and we at FPL are building \na mobile-first credit card in India.",
    "start": "27024",
    "end": "30310"
  },
  {
    "text": "We have two amazing application\nthat is OneScore and OneCard,",
    "start": "30515",
    "end": "33406"
  },
  {
    "text": "and we have about millions \nof customer for each of the apps.",
    "start": "33413",
    "end": "36306"
  },
  {
    "text": "Wonderful. So what do we have here? \nWhat does this platform do?",
    "start": "36660",
    "end": "39960"
  },
  {
    "text": "Well, this platform is all about \nhow we can build",
    "start": "40312",
    "end": "43172"
  },
  {
    "text": "on demand, serverless\n and secure ML Workbenches,",
    "start": "43278",
    "end": "46853"
  },
  {
    "text": "because this is the platform\n that is used by our data scientist ",
    "start": "46971",
    "end": "49701"
  },
  {
    "text": "to ingest process and transform \nlarge volumes of data. ",
    "start": "49701",
    "end": "52882"
  },
  {
    "text": "The transformed data is then used by rule engines \nto perform critical business decisioning.",
    "start": "53187",
    "end": "57073"
  },
  {
    "text": "Prior to this platform, since we are scaling\n rapidly in terms of customer",
    "start": "57716",
    "end": "61795"
  },
  {
    "text": "and internal teams, we always used to face ",
    "start": "61796",
    "end": "64269"
  },
  {
    "text": "problems like, infrastructure management, \nresource allocation,",
    "start": "64270",
    "end": "67711"
  },
  {
    "text": "and most of all security.",
    "start": "67711",
    "end": "69341"
  },
  {
    "text": "Well, this platform solves\n all of the problems for us.",
    "start": "69342",
    "end": "72274"
  },
  {
    "text": "Impressive, you seem to have \nsolved some key challenges ",
    "start": "72552",
    "end": "75614"
  },
  {
    "text": "frequently faced by data scientists.",
    "start": "75614",
    "end": "77478"
  },
  {
    "text": "So let's dive a bit deeper. ",
    "start": "77737",
    "end": "79396"
  },
  {
    "text": "How does a data scientist \ninteract with this platform?",
    "start": "79396",
    "end": "82031"
  },
  {
    "text": "Well, a data scientist typically prepares",
    "start": "82588",
    "end": "84840"
  },
  {
    "text": "a Jupyter Notebook.",
    "start": "84841",
    "end": "86714"
  },
  {
    "text": "And this Jupyter Notebook \nbasically ingests some raw data,",
    "start": "87635",
    "end": "91566"
  },
  {
    "text": "applies some transformation ",
    "start": "91566",
    "end": "93135"
  },
  {
    "text": "and using machine learning models, \nit generates some scores and labels.",
    "start": "93135",
    "end": "96395"
  },
  {
    "text": "Now let's say a data scientist wants to run \nthis notebook inside the SageMaker Studio.",
    "start": "96740",
    "end": "100780"
  },
  {
    "text": "They can simply log into the studio",
    "start": "101169",
    "end": "103941"
  },
  {
    "text": "using the appropriate IAM role.",
    "start": "103941",
    "end": "106311"
  },
  {
    "text": "Now different user groups are there inside \nthe SageMaker Studio domain.",
    "start": "106491",
    "end": "110573"
  },
  {
    "text": " The data scientist needs \nto identify which user groups ",
    "start": "110573",
    "end": "113119"
  },
  {
    "text": "he or she is suitable to log in with.",
    "start": "113120",
    "end": "115094"
  },
  {
    "text": "Now, once the user logs in, ",
    "start": "115467",
    "end": "117410"
  },
  {
    "text": "into the SageMaker Studio,",
    "start": "117410",
    "end": "118948"
  },
  {
    "text": "the next, they need to specify",
    "start": "118948",
    "end": "121104"
  },
  {
    "text": "what is the instance size they want\nand what are the job specific parameters.",
    "start": "121105",
    "end": "124939"
  },
  {
    "text": "And then when we are done with that, \nthey can submit for a processing job.",
    "start": "125162",
    "end": "129020"
  },
  {
    "text": "Now, once the request goes for a processing job,",
    "start": "129454",
    "end": "131995"
  },
  {
    "text": "the request actually comes to a Lambda, ",
    "start": "131995",
    "end": "133978"
  },
  {
    "text": "which in turn calls the ECR,",
    "start": "133978",
    "end": "136715"
  },
  {
    "text": "where we have our containers.",
    "start": "137009",
    "end": "138927"
  },
  {
    "text": "So from the ECR repository,",
    "start": "139094",
    "end": "141107"
  },
  {
    "text": "we fetch a custom container \nthat contains all the libraries",
    "start": "141107",
    "end": "143991"
  },
  {
    "text": "that are pre-installed and that are necessary",
    "start": "143991",
    "end": "146207"
  },
  {
    "text": "for the notebook to complete an execution.",
    "start": "146207",
    "end": "148306"
  },
  {
    "text": "We also use Papermill \nthat allows us to inject",
    "start": "148306",
    "end": "151531"
  },
  {
    "text": "parameters into the notebooks \non a dynamic basis. ",
    "start": "151531",
    "end": "154171"
  },
  {
    "text": "So the output of this processing jobs is directly dumped ",
    "start": "154482",
    "end": "157269"
  },
  {
    "text": "into a data lake in S3.",
    "start": "157269",
    "end": "158958"
  },
  {
    "text": "Impressive automation, I should say.",
    "start": "159765",
    "end": "161527"
  },
  {
    "text": "So we use SageMaker Studio, \nSageMaker processing jobs, ",
    "start": "161527",
    "end": "164769"
  },
  {
    "text": "Lambda, and IAM to provide scalable,",
    "start": "165062",
    "end": "167573"
  },
  {
    "text": "secure, and isolated \nML Workbenches for your data scientists.",
    "start": "167573",
    "end": "170936"
  },
  {
    "text": "I assume that SageMaker processing jobs",
    "start": "171023",
    "end": "173834"
  },
  {
    "text": "uses the data from your data lake.",
    "start": "173835",
    "end": "175486"
  },
  {
    "text": "Can you talk a little bit about your data lake, ",
    "start": "175486",
    "end": "177555"
  },
  {
    "text": "how it is hydrated, and how do you \nenforce data access controls?",
    "start": "177555",
    "end": "180655"
  },
  {
    "text": "So, yes, we have S3 as a data lake",
    "start": "181110",
    "end": "183619"
  },
  {
    "text": "and our data is coming in from Amazon RDS,",
    "start": "183619",
    "end": "186020"
  },
  {
    "text": "our data is coming in from the BigQuery,",
    "start": "186020",
    "end": "187992"
  },
  {
    "text": "our data is stored in Kinesis Streams.",
    "start": "187992",
    "end": "191014"
  },
  {
    "text": "Now all of this data is actually funneled",
    "start": "191608",
    "end": "194699"
  },
  {
    "text": "through our Glue jobs, \nwhich are essentially PySpark jobs",
    "start": "194699",
    "end": "197853"
  },
  {
    "text": "that anonymizes, transforms,",
    "start": "197853",
    "end": "199780"
  },
  {
    "text": "and all the synthesized data is stored into S3 ",
    "start": "199781",
    "end": "203398"
  },
  {
    "text": "as domain specific data marts.",
    "start": "203398",
    "end": "205178"
  },
  {
    "text": "Now we dump all the data \ninto S3, which is our data lake.",
    "start": "205178",
    "end": "208377"
  },
  {
    "text": "One important thing to note here is that we do ",
    "start": "208516",
    "end": "211083"
  },
  {
    "text": "keep our data lake ACID compliant.",
    "start": "211439",
    "end": "213455"
  },
  {
    "text": "So we use Apache Hudi to ensure\n that RDS and data lake are in sync.",
    "start": "213455",
    "end": "218326"
  },
  {
    "text": "As a FinTech company, \nsecurity is a very big concern for us",
    "start": "218663",
    "end": "221851"
  },
  {
    "text": "and we try to harden it wherever possible.",
    "start": "221852",
    "end": "223925"
  },
  {
    "text": "On a primary layer, ",
    "start": "224174",
    "end": "225611"
  },
  {
    "text": "everything inside the SageMaker \nis running inside our own VPC.",
    "start": "226250",
    "end": "230373"
  },
  {
    "text": "Now, this VPC is our own private VPC",
    "start": "231232",
    "end": "233974"
  },
  {
    "text": "with a very controlled egress and ingress.",
    "start": "233975",
    "end": "236330"
  },
  {
    "text": "On a secondary level, we have IAM",
    "start": "236759",
    "end": "239094"
  },
  {
    "text": "where we have specified\n separate execution rules",
    "start": "239094",
    "end": "241623"
  },
  {
    "text": "for different data science user groups.",
    "start": "241623",
    "end": "243440"
  },
  {
    "text": "So for example, \nwe have data science user group one",
    "start": "244242",
    "end": "247931"
  },
  {
    "text": "where the user group one \ncan only access the data of customers.",
    "start": "247931",
    "end": "250792"
  },
  {
    "text": "And we have data science user group two,",
    "start": "250792",
    "end": "252360"
  },
  {
    "text": "where the user group two \ncan only access the data of applications.",
    "start": "252360",
    "end": "255109"
  },
  {
    "text": "Now creating separate execution rules \nfor each of these data science user groups ",
    "start": "255333",
    "end": "259357"
  },
  {
    "text": " allows us to invoke a sense \nof workspace isolation,",
    "start": "259357",
    "end": "262587"
  },
  {
    "text": "which helps us harden our security.",
    "start": "262587",
    "end": "264443"
  },
  {
    "text": "Makes sense on how you've used\n S3 and RDS as your data stores,",
    "start": "264978",
    "end": "269209"
  },
  {
    "text": "and also how you've leveraged IAM\n to enforce your data access controls.",
    "start": "269439",
    "end": "272959"
  },
  {
    "text": "So what were some key challenges you faced, \nand how does this platform address them?",
    "start": "273184",
    "end": "277156"
  },
  {
    "text": "Well, the first key challenge was security \nbecause prior to this architecture,",
    "start": "277505",
    "end": "281017"
  },
  {
    "text": "we only used to have a single \nSageMaker Notebook instance.",
    "start": "281017",
    "end": "284307"
  },
  {
    "text": "And as we keep down scaling \nmultiple data scientists",
    "start": "284307",
    "end": "287112"
  },
  {
    "text": "joined us, and they logged on\n to the same notebook instance.",
    "start": "287112",
    "end": "289687"
  },
  {
    "text": "So there was absolutely \nno workspace isolation.",
    "start": "289870",
    "end": "292330"
  },
  {
    "text": "Moreover, there was resource starvation \ndue to so much traffic on a single notebook instance.",
    "start": "292330",
    "end": "296538"
  },
  {
    "text": "So this architecture allows us",
    "start": "296805",
    "end": "299296"
  },
  {
    "text": "to run our notebooks\nas SageMaker processing jobs,",
    "start": "299296",
    "end": "302199"
  },
  {
    "text": "which brings in the much more required agility",
    "start": "302200",
    "end": "304885"
  },
  {
    "text": "along with security, scale, \nand an on demand infrastructure.",
    "start": "304885",
    "end": "308263"
  },
  {
    "text": "We need not worry about the instances \nbecause instances are created",
    "start": "308263",
    "end": "311906"
  },
  {
    "text": "and, torn down on the fly.",
    "start": "311906",
    "end": "314251"
  },
  {
    "text": "Moreover, this also comes with a UI",
    "start": "314251",
    "end": "316606"
  },
  {
    "text": "that empowers our data scientists \nto run their data pipelines",
    "start": "316606",
    "end": "320388"
  },
  {
    "text": "on production workloads, without the help \nof any infrastructure engineer.",
    "start": "320388",
    "end": "323938"
  },
  {
    "text": "With the adoption of this architecture,",
    "start": "324113",
    "end": "326080"
  },
  {
    "text": "I think 75% of our workloads are now running",
    "start": "326080",
    "end": "329306"
  },
  {
    "text": "inside SageMaker Studios processing jobs.",
    "start": "329307",
    "end": "331563"
  },
  {
    "text": "And this is looking really well for us \nbecause we were able to launch ",
    "start": "331563",
    "end": "334835"
  },
  {
    "text": "a lot of customer facing \nand as well as internal products",
    "start": "334835",
    "end": "337637"
  },
  {
    "text": "way sooner than planned.",
    "start": "337637",
    "end": "339611"
  },
  {
    "text": "That's a great story. ",
    "start": "339897",
    "end": "341424"
  },
  {
    "text": "Thank you Swarup \nfor being here on the show.",
    "start": "341424",
    "end": "343523"
  },
  {
    "text": "Thank you for watching 'This Is My Architecture'.",
    "start": "343927",
    "end": "346927"
  }
]
[
  {
    "text": "Hello, My name is Esteban Serna",
    "start": "5233",
    "end": "7500"
  },
  {
    "text": "I am a Sr. DynamoDB Specialist Solution Architect",
    "start": "7500",
    "end": "11033"
  },
  {
    "text": "and I help customers to choose \nthe right DynamoDB features",
    "start": "12566",
    "end": "16733"
  },
  {
    "text": "that are the best fit for their needs",
    "start": "16733",
    "end": "20400"
  },
  {
    "text": "Today we will discuss about \nchange data capture",
    "start": "21300",
    "end": "26633"
  },
  {
    "text": "with Amazon DynamoDB and\nwhat are the options",
    "start": "26633",
    "end": "30366"
  },
  {
    "text": "to process these events.",
    "start": "30366",
    "end": "34033"
  },
  {
    "text": "First, we will discuss",
    "start": "34166",
    "end": "37500"
  },
  {
    "text": "what is inside a DynamoDB Streams event",
    "start": "38600",
    "end": "42365"
  },
  {
    "text": "in Amazon DynamoDB",
    "start": "42366",
    "end": "44766"
  },
  {
    "text": "Streams",
    "start": "46200",
    "end": "48600"
  },
  {
    "text": "In simple terms, it is a JSON \nthat contains some information",
    "start": "48600",
    "end": "53100"
  },
  {
    "text": "about the event that\njust occured in the table",
    "start": "53100",
    "end": "57466"
  },
  {
    "text": "any mutation, meaning, any \nmodification in the DynamoDB table",
    "start": "58300",
    "end": "62200"
  },
  {
    "text": "elements. It will generate a Data Stream",
    "start": "62433",
    "end": "67500"
  },
  {
    "text": "and when we say, any  change, \nit could be an update operation",
    "start": "67833",
    "end": "72233"
  },
  {
    "text": "or a create item, or \na delete operation",
    "start": "72233",
    "end": "75666"
  },
  {
    "text": "it generates an event",
    "start": "76400",
    "end": "78000"
  },
  {
    "text": "this event will look\nlike the one we have in the screen",
    "start": "78000",
    "end": "81800"
  },
  {
    "text": "and the information that we \ncan identify, we can see",
    "start": "82500",
    "end": "84633"
  },
  {
    "text": "Event Source of this data",
    "start": "84633",
    "end": "88133"
  },
  {
    "text": "what type of event happened (Modify)",
    "start": "89066",
    "end": "91466"
  },
  {
    "text": "in which region, and the \napproximate creation date time of when",
    "start": "91466",
    "end": "95966"
  },
  {
    "text": "this event was created, and this \nApproximateCreationDateTime parameter",
    "start": "95966",
    "end": "99666"
  },
  {
    "text": "represents when it was created \nmeasured in milliseconds",
    "start": "100200",
    "end": "104700"
  },
  {
    "text": "We also have the New ",
    "start": "105800",
    "end": "106800"
  },
  {
    "text": "Image and really this parameter\ndepends on the",
    "start": "106800",
    "end": "110366"
  },
  {
    "text": "configuration options for the \ndata stream",
    "start": "110600",
    "end": "113933"
  },
  {
    "text": "It could be you only care about the \nold values with the OLD value",
    "start": "114300",
    "end": "118600"
  },
  {
    "text": "all the new events\n with the NEW value",
    "start": "118633",
    "end": "123266"
  },
  {
    "text": "and the new and old images\nthat means the before and after picture",
    "start": "123266",
    "end": "126465"
  },
  {
    "text": "and finally we can also just \nsend the keys only",
    "start": "127700",
    "end": "131333"
  },
  {
    "text": "It means, regardless of ",
    "start": "131566",
    "end": "134032"
  },
  {
    "text": "what has changed",
    "start": "134033",
    "end": "135000"
  },
  {
    "text": "I only want to see the keys in the stream of data",
    "start": "135000",
    "end": "137666"
  },
  {
    "text": "Now. [Pause] \nLet’s have a look to DynamoDB Streams",
    "start": "139300",
    "end": "142866"
  },
  {
    "text": "DynamoDB Streams will\ncapture all the table modifications",
    "start": "143433",
    "end": "147900"
  },
  {
    "text": "all the mutations\nas we said previously",
    "start": "148666",
    "end": "151733"
  },
  {
    "text": "and assuming we use AWS Lambda, \nthe lambda function",
    "start": "151733",
    "end": "155166"
  },
  {
    "text": "will poll DynamoDB streams \nfour times per second",
    "start": "155866",
    "end": "160532"
  },
  {
    "text": "to see if there are new records,\nIn case there is new data",
    "start": "160900",
    "end": "164633"
  },
  {
    "text": "and the event filter matches",
    "start": "165366",
    "end": "169400"
  },
  {
    "text": "the lambda function will be executed",
    "start": "169833",
    "end": "171400"
  },
  {
    "text": "wtih lambda",
    "start": "173400",
    "end": "174066"
  },
  {
    "text": "we have up to ... \n[Pause]",
    "start": "174066",
    "end": "176733"
  },
  {
    "text": "With DynamoDB Streams, sorry; We have up to two subscribers that can be registered to the same data stream",
    "start": "177133",
    "end": "183233"
  },
  {
    "text": "In this case it could be \ntwo lambda functions",
    "start": "183233",
    "end": "185600"
  },
  {
    "text": "but you can’t have more than two",
    "start": "185600",
    "end": "188366"
  },
  {
    "text": "On the Other side. \nWe have Kinesis Data Streams",
    "start": "188400",
    "end": "190765"
  },
  {
    "text": "So, With Kinesis Data Streams",
    "start": "191600",
    "end": "193566"
  },
  {
    "text": "There is a service that replicates the data",
    "start": "193566",
    "end": "196700"
  },
  {
    "text": "into the Kinesis Data Stream, \nevery time there is new records",
    "start": "196700",
    "end": "199800"
  },
  {
    "text": "and, assuming we use lambda\nfor processing, every second it will",
    "start": "200800",
    "end": "204400"
  },
  {
    "text": "check if there are records available",
    "start": "205566",
    "end": "207833"
  },
  {
    "text": "from the lambda perspective",
    "start": "209066",
    "end": "210700"
  },
  {
    "text": "and exactly the same as with DynamoDB streams",
    "start": "210700",
    "end": "213765"
  },
  {
    "text": "If",
    "start": "213766",
    "end": "214633"
  },
  {
    "text": "If the filter event matches",
    "start": "214633",
    "end": "217433"
  },
  {
    "text": "the lambda function will be executed",
    "start": "217466",
    "end": "221200"
  },
  {
    "text": "In the case of Kinesis Data Streams, \nwe can subscribe up to 5 clients",
    "start": "221200",
    "end": "224599"
  },
  {
    "text": "lambda functions in this case",
    "start": "225733",
    "end": "228500"
  },
  {
    "text": "And if for example I have a lambda function",
    "start": "230233",
    "end": "232800"
  },
  {
    "text": "and a client that it is Kinesis Data Firehose",
    "start": "233366",
    "end": "238599"
  },
  {
    "text": "this Kinesis Data Firehose will count\nas an additional client",
    "start": "238600",
    "end": "241133"
  },
  {
    "text": "So I could have my Kinesis \nFirehose and ",
    "start": "241400",
    "end": "245066"
  },
  {
    "text": "additional lambda functions but up to 5 subscribers",
    "start": "245066",
    "end": "248032"
  },
  {
    "text": "something",
    "start": "249433",
    "end": "250033"
  },
  {
    "text": "something very important that differenciates \nKinesis Data Streams vs",
    "start": "250166",
    "end": "253800"
  },
  {
    "text": "DynamoDB Strings is that ,when you\nput your data in Kinesis",
    "start": "254166",
    "end": "259100"
  },
  {
    "text": "You might loose order",
    "start": "259100",
    "end": "261366"
  },
  {
    "text": "Esto es debido a las API PutRecord\nfor KDS ",
    "start": "261366",
    "end": "264966"
  },
  {
    "text": "doesn’t mantaint the order",
    "start": "265000",
    "end": "267500"
  },
  {
    "text": "but we can use the parameter\nas we saw earlier",
    "start": "267500",
    "end": "271200"
  },
  {
    "text": "AproximateCreationDateTime \nto reorder them",
    "start": "271200",
    "end": "275700"
  },
  {
    "text": "This needs to be done by the client \napplication and it is not done automtically",
    "start": "275900",
    "end": "280266"
  },
  {
    "text": "not by Kinesis Data Streems",
    "start": "280266",
    "end": "283233"
  },
  {
    "text": "either by the client that put \nthe registers in the Stream",
    "start": "283300",
    "end": "285432"
  },
  {
    "text": "this is when you will \nconsume the registers",
    "start": "285866",
    "end": "287633"
  },
  {
    "text": "So, side to side",
    "start": "289266",
    "end": "291866"
  },
  {
    "text": "we have",
    "start": "291900",
    "end": "293633"
  },
  {
    "text": "with DynamoDB Streams we will \nensure the order of the events",
    "start": "293633",
    "end": "296533"
  },
  {
    "text": "For example in the left side",
    "start": "297300",
    "end": "299800"
  },
  {
    "text": "I have an order #1 with a status NEW\n in a time T0",
    "start": "299800",
    "end": "304099"
  },
  {
    "text": "and then there will be an order update",
    "start": "304833",
    "end": "307766"
  },
  {
    "text": "and this order will be with status, for example #1",
    "start": "307966",
    "end": "310666"
  },
  {
    "text": "sorry, the order is already #1, ",
    "start": "311100",
    "end": "313700"
  },
  {
    "text": "but the status will be in Picking",
    "start": "313700",
    "end": "317333"
  },
  {
    "text": "and now we have time T1 which is a different time",
    "start": "318533",
    "end": "321932"
  },
  {
    "text": "This means the orders of the events will be maintained",
    "start": "321933",
    "end": "324333"
  },
  {
    "text": "and they will be always in order",
    "start": "324900",
    "end": "326733"
  },
  {
    "text": "When we use Kinesis Data Streams \nas we have to the right side of the screen",
    "start": "326733",
    "end": "329766"
  },
  {
    "text": "the events can loose the order",
    "start": "330233",
    "end": "333766"
  },
  {
    "text": "and we can use the paramter \nApproximateCreationDatetime to re-order",
    "start": "334566",
    "end": "338866"
  },
  {
    "text": "Remember, this parameter is valid up to the milisecond",
    "start": "340033",
    "end": "343332"
  },
  {
    "text": "it is a very precise value",
    "start": "343333",
    "end": "345533"
  },
  {
    "text": "If we compare side to side \nDynamoDB Streams with Kinesis Data Streams",
    "start": "345533",
    "end": "348599"
  },
  {
    "text": "Data retention period, \nwith kinesis",
    "start": "349500",
    "end": "351900"
  },
  {
    "text": "data stream we could have \nthe data up to a year",
    "start": "351900",
    "end": "354900"
  },
  {
    "text": "with DynamoDB streams is \nonly 24 hours",
    "start": "355433",
    "end": "359066"
  },
  {
    "text": "At this point is very important understand\n the requirements to choose the right solution",
    "start": "359300",
    "end": "362400"
  },
  {
    "text": "from the data analysis of the data in the stream",
    "start": "362400",
    "end": "365866"
  },
  {
    "text": "in the DynamoDB table you will still have",
    "start": "366566",
    "end": "368400"
  },
  {
    "text": "the data until you decide to delete them",
    "start": "368400",
    "end": "373400"
  },
  {
    "text": "and you define when you need to consume them. \nWith Kinesis Data Stream",
    "start": "373433",
    "end": "377066"
  },
  {
    "text": "you can have them for a year,\nwith DynamoDB Stream only 24 hours",
    "start": "377066",
    "end": "379633"
  },
  {
    "text": "Consumers, with Kinesis Data Streams",
    "start": "380233",
    "end": "383633"
  },
  {
    "text": "you can have up to five",
    "start": "383866",
    "end": "384966"
  },
  {
    "text": "per shard or you can get up to \n20 simultaneous consumers",
    "start": "386100",
    "end": "389700"
  },
  {
    "text": "as long as you use the enhanced\nfan-out functionality",
    "start": "389700",
    "end": "393033"
  },
  {
    "text": "With DynamoDB Streams you can \nonly have two consumers",
    "start": "393800",
    "end": "397832"
  },
  {
    "text": "Service quotas,  with KDS",
    "start": "398900",
    "end": "401932"
  },
  {
    "text": "there is no limit",
    "start": "402066",
    "end": "403166"
  },
  {
    "text": "On the DynamoDB Streams\nside, there are service quotas",
    "start": "403166",
    "end": "406866"
  },
  {
    "text": "per table and and AWS region.",
    "start": "407500",
    "end": "411533"
  },
  {
    "text": "These quotas can be increased, ",
    "start": "411900",
    "end": "414733"
  },
  {
    "text": "but you need to be aware of them.\nFrom the durability side ",
    "start": "414733",
    "end": "418933"
  },
  {
    "text": "both services",
    "start": "419433",
    "end": "422466"
  },
  {
    "text": "are replicated across \ndiferent availabiity zones",
    "start": "422466",
    "end": "425333"
  },
  {
    "text": "to provide an automatic failover",
    "start": "425900",
    "end": "429932"
  },
  {
    "text": "In case there is any error, \nthis happens without interruptions",
    "start": "430600",
    "end": "432866"
  },
  {
    "text": "For the data delivery model",
    "start": "434100",
    "end": "437200"
  },
  {
    "text": "they both use HTTP",
    "start": "437200",
    "end": "439500"
  },
  {
    "text": "with Kinesis Data Streams we have\nHTTP via GetRecords",
    "start": "440000",
    "end": "444333"
  },
  {
    "text": "and if we use enhanced \nfan-out we will use SubscribeToShard",
    "start": "444333",
    "end": "448933"
  },
  {
    "text": "with DynamoDB Streams,",
    "start": "450633",
    "end": "451866"
  },
  {
    "text": "we will use GetRecords",
    "start": "451866",
    "end": "455700"
  },
  {
    "text": "In terms of compatibility",
    "start": "455700",
    "end": "457633"
  },
  {
    "text": "with Kinesis Client Library (KCL) .\nKinesis Data Streams supports",
    "start": "457633",
    "end": "461300"
  },
  {
    "text": "Version one and two, but \nDynamoDB Streams supports only version one.",
    "start": "461400",
    "end": "466133"
  },
  {
    "text": "We already mention this, but with \nKinesys Data Streams ",
    "start": "466633",
    "end": "469766"
  },
  {
    "text": "There is a chance of \nduplicated data in the stream",
    "start": "469766",
    "end": "472300"
  },
  {
    "text": "so your client application is responsible of",
    "start": "473033",
    "end": "475800"
  },
  {
    "text": "deduplicating these records",
    "start": "476700",
    "end": "479833"
  },
  {
    "text": "with DynamoDB Streams there\nis no duplicate data",
    "start": "480000",
    "end": "483233"
  },
  {
    "text": "Now, in terms of data order",
    "start": "484666",
    "end": "487599"
  },
  {
    "text": "Kinesis Data Streams does\nnot keep the order",
    "start": "487600",
    "end": "489900"
  },
  {
    "text": "but you can re-order them by using \nthe parameter ApproximateCreationDateTime",
    "start": "490900",
    "end": "494199"
  },
  {
    "start": "494666",
    "end": "497099"
  },
  {
    "text": "This has to be done by the client \napplication that consumes the data",
    "start": "497533",
    "end": "501599"
  },
  {
    "text": "with DynamoDB streams \nthe order is strict, provided by the service",
    "start": "502000",
    "end": "505766"
  },
  {
    "text": "In both cases you have different\noptions to process data",
    "start": "507166",
    "end": "510099"
  },
  {
    "text": "with Kinesis Data Streams",
    "start": "510300",
    "end": "512200"
  },
  {
    "text": "You can use AWS Lambda, with Kinesis \nData Analytics or Kinesis Firehose",
    "start": "512200",
    "end": "516266"
  },
  {
    "text": "or to integrate with an ETL streaming\nwith AWS Glue",
    "start": "516266",
    "end": "520466"
  },
  {
    "text": "and with DynamoDB Streams",
    "start": "521700",
    "end": "523533"
  },
  {
    "text": "You could consume the data \nwith an AWS Lambda function",
    "start": "523533",
    "end": "527933"
  },
  {
    "text": "or you can also use Kinesis\n Data Streams Adapters",
    "start": "527933",
    "end": "531000"
  },
  {
    "text": "This guide us to this point",
    "start": "532800",
    "end": "534700"
  },
  {
    "text": "Well, when I will use this\ntype of solutions?",
    "start": "534700",
    "end": "536900"
  },
  {
    "text": "The answer is: \nto drive event driven architectures",
    "start": "537400",
    "end": "540900"
  },
  {
    "text": "One of them,",
    "start": "541900",
    "end": "543100"
  },
  {
    "text": "And this is a DynamoDB\nFunctionality",
    "start": "543100",
    "end": "545199"
  },
  {
    "text": "and it is",
    "start": "545200",
    "end": "549100"
  },
  {
    "text": "time to live",
    "start": "549100",
    "end": "550365"
  },
  {
    "text": "you will configure in a table",
    "start": "550966",
    "end": "553666"
  },
  {
    "text": "a specific register, \nsorry, a specific attribute",
    "start": "554100",
    "end": "557466"
  },
  {
    "text": "for all the items, In an EPOCH \ntimestamp format",
    "start": "557466",
    "end": "561300"
  },
  {
    "text": "and this, ",
    "start": "562866",
    "end": "563433"
  },
  {
    "text": "this attribute will define when \nthis element will be deleted",
    "start": "563433",
    "end": "567333"
  },
  {
    "text": "it is very important this parameter\nis a number. Then DynamoDB ",
    "start": "568100",
    "end": "572466"
  },
  {
    "text": "behind scenes, it will ",
    "start": "572566",
    "end": "576300"
  },
  {
    "text": "lookup the tables",
    "start": "577433",
    "end": "579833"
  },
  {
    "text": "and define if one or more \nitems needs to be deleted",
    "start": "580233",
    "end": "583699"
  },
  {
    "text": "It is not an Scan as in the \nDynamoDB Scan operation",
    "start": "584333",
    "end": "587433"
  },
  {
    "text": "It is a background process that \nis totally free for users.",
    "start": "587500",
    "end": "591533"
  },
  {
    "text": "there is no cost",
    "start": "591733",
    "end": "594165"
  },
  {
    "text": "but is a process that executes in best effort",
    "start": "594633",
    "end": "597700"
  },
  {
    "text": "the it doesn’t guarantees, that when you \nset the TTL date, ",
    "start": "597866",
    "end": "601800"
  },
  {
    "text": "If you have define that the item\nwill be deleted on",
    "start": "602200",
    "end": "606100"
  },
  {
    "text": "May 20th 2024 at 12:35 pm in the TTL attribute",
    "start": "606100",
    "end": "609300"
  },
  {
    "text": "It doesn’t means that at 12:35:01\n the item will not longer be there",
    "start": "610000",
    "end": "613166"
  },
  {
    "text": "because this TTL process",
    "start": "614200",
    "end": "618166"
  },
  {
    "text": "will delete the items in between 24 and 48 hours",
    "start": "619066",
    "end": "622933"
  },
  {
    "text": "The deletion windows is up to 48 hours",
    "start": "623300",
    "end": "626399"
  },
  {
    "text": "in reality all this process happens\nin parallel ",
    "start": "627233",
    "end": "631165"
  },
  {
    "text": "for different tables in the region",
    "start": "632966",
    "end": "635766"
  },
  {
    "text": "Back to the point, the important fact",
    "start": "635966",
    "end": "638366"
  },
  {
    "text": "and this is the reason why we are \ntalking about TTL ",
    "start": "638400",
    "end": "641500"
  },
  {
    "text": "is because the TTL will generate a \ndeletion event",
    "start": "642000",
    "end": "646500"
  },
  {
    "text": "and you can capture \nthis deletion event",
    "start": "646900",
    "end": "648400"
  },
  {
    "text": "and store the data \nin a solution like S3",
    "start": "648400",
    "end": "652566"
  },
  {
    "text": "for",
    "start": "652566",
    "end": "653966"
  },
  {
    "text": "long term storage or a solution like",
    "start": "655133",
    "end": "658666"
  },
  {
    "text": "Elastic Search or other solutions,\n that you might be using",
    "start": "658666",
    "end": "662733"
  },
  {
    "text": "We keep in DynamoDB the “hot data”, \nmeaning the data that you ",
    "start": "663233",
    "end": "667100"
  },
  {
    "text": "really search on \nand in other solutions the ",
    "start": "667100",
    "end": "670365"
  },
  {
    "text": "the information ",
    "start": "670366",
    "end": "672166"
  },
  {
    "text": "the information in long term archival",
    "start": "673366",
    "end": "676800"
  },
  {
    "text": "With event driven architectures\nwe also have",
    "start": "677466",
    "end": "681100"
  },
  {
    "text": "that when the events are \ncaptured you could execute",
    "start": "681100",
    "end": "684933"
  },
  {
    "text": "a lambda function to perform\nreal time aggregations",
    "start": "685200",
    "end": "688866"
  },
  {
    "text": "as long as these aggregations\nare not very complex and know up front",
    "start": "689900",
    "end": "693900"
  },
  {
    "text": "the result can be stored again \nin the same DynamoDB table",
    "start": "693900",
    "end": "697433"
  },
  {
    "text": "the aggregation results\nas part of their queries",
    "start": "697433",
    "end": "701233"
  },
  {
    "text": "You could also send the information to \nsolutions like Elastic Search",
    "start": "701833",
    "end": "705066"
  },
  {
    "text": "or open Search to perform\nfull text lookups",
    "start": "705066",
    "end": "708500"
  },
  {
    "text": "or you could also send to",
    "start": "709933",
    "end": "712500"
  },
  {
    "text": "Kinesis Firehose, then S3 and query with Athena",
    "start": "712500",
    "end": "717133"
  },
  {
    "text": "To execute some aggregated queries",
    "start": "718000",
    "end": "721700"
  },
  {
    "text": "maybe to perform data analysis",
    "start": "721733",
    "end": "724233"
  },
  {
    "text": "In this video we learned the difference between \nKinesis Data Streams and DynamoDB Streams",
    "start": "725100",
    "end": "728199"
  },
  {
    "text": "and we saw the differents",
    "start": "728200",
    "end": "731300"
  },
  {
    "text": "the differentes benefits that have \nboth services",
    "start": "731566",
    "end": "735333"
  },
  {
    "text": "depending on your application requirements\nyou could make the right choice",
    "start": "735366",
    "end": "739366"
  },
  {
    "text": "My Name is Esteban Serna \nI am a Sr DynamoDB Specialst SA",
    "start": "739833",
    "end": "743500"
  },
  {
    "text": "and thans for listening!",
    "start": "744500",
    "end": "745333"
  }
]
[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "all right well hopefully you are join us here on Twitch to see me I guess that's a yes glad",
    "start": "30",
    "end": "7049"
  },
  {
    "text": "you're here today I'd like to introduce you to Bob he's here tomorrow right Bob McKinney is one of our STS for",
    "start": "7049",
    "end": "13830"
  },
  {
    "text": "emphasizing that gateway and he'll be joining us today from building happy little api's I'm so excited you're here",
    "start": "13830",
    "end": "21080"
  },
  {
    "text": "today we're going to be diving it deep on on troubleshooting on fixing problems",
    "start": "21080",
    "end": "26820"
  },
  {
    "text": "may be a gateway fixing problems in our application and in how best to",
    "start": "26820",
    "end": "31949"
  },
  {
    "text": "troubleshoot and Bob is is the extra on that Bob you want to say hi and say a little bit about yourself sure yeah so",
    "start": "31949",
    "end": "38629"
  },
  {
    "text": "like Eric said my name's Bob I'm an ste nan API gateway I've been with the team basically since the launch of a service",
    "start": "38629",
    "end": "45300"
  },
  {
    "text": "been with Amazon for a little over seven years and now really happy to show",
    "start": "45300",
    "end": "51120"
  },
  {
    "text": "people how to use the services that we built now I gotta jump in here and I",
    "start": "51120",
    "end": "56670"
  },
  {
    "text": "gotta be honest I was very reticent about having Bob on the show one of the main comments I've been getting about",
    "start": "56670",
    "end": "61949"
  },
  {
    "text": "the show other than the technical acuity in you know in geniusness that's happening here is the beauty of my beard",
    "start": "61949",
    "end": "68100"
  },
  {
    "text": "and unfortunately I will never come close to what Bob got going on there but",
    "start": "68100",
    "end": "74220"
  },
  {
    "text": "I am jealous but yeah so it's it's a battle of beards here so Bob we are",
    "start": "74220",
    "end": "80130"
  },
  {
    "text": "going to have you excited so we're gonna use kind of jump in and today is going",
    "start": "80130",
    "end": "85619"
  },
  {
    "start": "85000",
    "end": "303000"
  },
  {
    "text": "to be mostly a live code day you're gonna see examples of code and in and how to approach different problems and",
    "start": "85619",
    "end": "92729"
  },
  {
    "text": "we want to talk a little bit about you know what what services what we're going to be dealing with so this episode is",
    "start": "92729",
    "end": "99270"
  },
  {
    "text": "called the all-seeing eye over Amazon API gateway and this is really looking",
    "start": "99270",
    "end": "104610"
  },
  {
    "text": "at how to you know monitor troubleshoot all the things so last week if you",
    "start": "104610",
    "end": "110310"
  },
  {
    "text": "remember we had tor or last episode when we are gorge with there's been a very simple architecture and the arc",
    "start": "110310",
    "end": "116520"
  },
  {
    "text": "essential look like this is you and your clients you had an Amazon API gateway and you have lambda function and we",
    "start": "116520",
    "end": "122369"
  },
  {
    "text": "talked about how to build a business simple REST API",
    "start": "122369",
    "end": "127869"
  },
  {
    "text": "using proxy using integration different things like that today we're going to",
    "start": "127869",
    "end": "133180"
  },
  {
    "text": "take this so we're going to add on it a little bit to where it looks like this and you'll notice that we've added to",
    "start": "133180",
    "end": "139959"
  },
  {
    "text": "this one in Amazon DynamoDB which is which is you know no sequel surplice",
    "start": "139959",
    "end": "147910"
  },
  {
    "text": "database and we're going to be using that to collect data the second thing we're adding is Amazon CloudWatch",
    "start": "147910",
    "end": "153940"
  },
  {
    "text": "an AWS x-ray that's kind of monitor over the whole system a Bob will be kind of",
    "start": "153940",
    "end": "159580"
  },
  {
    "text": "watching through that but I want to kind of break down what are these services before we go too far Amazon CloudWatch",
    "start": "159580",
    "end": "167700"
  },
  {
    "text": "it allows you to access all your data from a single platform it's really the easiest way to collect customer customer",
    "start": "167700",
    "end": "174280"
  },
  {
    "text": "granular metrics for a diverse resources and I say custom because you don't have to just take what all right the system",
    "start": "174280",
    "end": "180340"
  },
  {
    "text": "is pushing data to them to cloud on watch but you can also pushed into cloud watch as well to trigger events to",
    "start": "180340",
    "end": "187450"
  },
  {
    "text": "trigger alarms all kinds of things it's visible across your applications infrastructure and services and it",
    "start": "187450",
    "end": "194260"
  },
  {
    "text": "drives you can derive actual insights from logs no Bob we're going to look at some of the insights they are we we are",
    "start": "194260",
    "end": "200530"
  },
  {
    "text": "we are going to take a look at all sort of the the various aspects of this API okay so one of the cool things is is is",
    "start": "200530",
    "end": "207519"
  },
  {
    "text": "the insights itself and the ability to build custom reports and things like that buzz can be kind of walking us",
    "start": "207519",
    "end": "213190"
  },
  {
    "text": "through that but with cloud watch you're able to again do alarms events time-based events there's just any",
    "start": "213190",
    "end": "220870"
  },
  {
    "text": "number of things that can be done the second thing we're going to dive dive deep into is Amazon x-ray an x-ray is",
    "start": "220870",
    "end": "229390"
  },
  {
    "text": "fairly new service spending about two years and it allows you to do to review",
    "start": "229390",
    "end": "235480"
  },
  {
    "text": "request behavior discover application issues and then helps you find bottlenecks to improve application",
    "start": "235480",
    "end": "240970"
  },
  {
    "text": "performance this is this it does a lot more than this up it's very powerful",
    "start": "240970",
    "end": "246040"
  },
  {
    "text": "system you kind of see the idea here where it gives me feedback if different client I have a client that's hitting my",
    "start": "246040",
    "end": "251859"
  },
  {
    "text": "80s and then singing the function it's gonna tell me hey lay in the service itself",
    "start": "251859",
    "end": "257859"
  },
  {
    "text": "and you see by the example here is 136 milliseconds where is the land itself has a three millisecond latency or",
    "start": "257860",
    "end": "265690"
  },
  {
    "text": "response time and so a great way to look at you know where are things happening then it also breaks it down these are",
    "start": "265690",
    "end": "272530"
  },
  {
    "text": "just quick examples of Tracy and how that looks as well so again a lot of",
    "start": "272530",
    "end": "278920"
  },
  {
    "text": "power here and we're going to use these two services and probably throw anything else or miss anything well I don't think",
    "start": "278920",
    "end": "284710"
  },
  {
    "text": "so would and if we if we didn't miss anything I'm sure it'll probably come up in the in the demos alrighty so what",
    "start": "284710",
    "end": "290770"
  },
  {
    "text": "we're gonna do is is as most movers and find out a lot of change show me the code so this point I'm going",
    "start": "290770",
    "end": "296980"
  },
  {
    "text": "to turn it over to Bob and Bob and Prague and interrupt you but a lot of questions and stuff so turn over to you",
    "start": "296980",
    "end": "303180"
  },
  {
    "start": "303000",
    "end": "464000"
  },
  {
    "text": "okay so Eric mentioned that it's going to be largely a live code so this will",
    "start": "303180",
    "end": "311350"
  },
  {
    "text": "be more think about it as live ops so one of my roles here at at AWS and",
    "start": "311350",
    "end": "317680"
  },
  {
    "text": "specifically our API gateway is a little bit of a operations long so I'm oftentimes the guy that gets called when",
    "start": "317680",
    "end": "323260"
  },
  {
    "text": "there is a large-scale event for for the service I mean get engaged so I am very",
    "start": "323260",
    "end": "328660"
  },
  {
    "text": "focused on on sort of how to figure out how do we dive deep into problem we problem API is figuring out what the",
    "start": "328660",
    "end": "335500"
  },
  {
    "text": "root cause is finding mitigations for that root cause and so that we can get the API back up and running at a hundred",
    "start": "335500",
    "end": "341680"
  },
  {
    "text": "percent so what I'm going to try to walk through right now is sort of a simulated exercise that you as a server list API",
    "start": "341680",
    "end": "348970"
  },
  {
    "text": "owner might experience so what I've got here open now is just a is just a Gmail",
    "start": "348970",
    "end": "354400"
  },
  {
    "text": "inbox so I set up a test a test gmail account for for this purpose I'm in I've",
    "start": "354400",
    "end": "359620"
  },
  {
    "text": "already got a boo-boo excuse me a notification alarm from the cloud watch service so beforehand I",
    "start": "359620",
    "end": "365620"
  },
  {
    "text": "started up a a load generator against my API and set up a clog watch alarm and",
    "start": "365620",
    "end": "371140"
  },
  {
    "text": "this is notifying me that this alarm is now in any an alarm state and that I should actually take action on it so I'm",
    "start": "371140",
    "end": "377710"
  },
  {
    "text": "going to go ahead and switch over to my cloud watch dashboard so cloud watch",
    "start": "377710",
    "end": "382900"
  },
  {
    "text": "supports not only metrics and a warming as well as logs they have this great",
    "start": "382900",
    "end": "388210"
  },
  {
    "text": "little dashboard feature that you can actually build in a dashboard and track a bunch of metrics in a simple",
    "start": "388210",
    "end": "393760"
  },
  {
    "text": "convenient dashboard that you can quickly look at so this is a very common practice that we inside of AWS use all",
    "start": "393760",
    "end": "400300"
  },
  {
    "text": "the time so when an operator is actually engaged on a problem they go right to",
    "start": "400300",
    "end": "405520"
  },
  {
    "text": "the dashboard and start looking at the metrics that are going to show the actual customer experience and so what",
    "start": "405520",
    "end": "411280"
  },
  {
    "text": "I've got here on my dashboard right now is just a few different graphs and a excuse me the insights query that I'll",
    "start": "411280",
    "end": "417670"
  },
  {
    "text": "get to in a second and so the first graph that we see here is a RPS",
    "start": "417670",
    "end": "423040"
  },
  {
    "text": "utilization graph and this is a great way to kind of break down your account",
    "start": "423040",
    "end": "428620"
  },
  {
    "text": "level usage for API gateways so API gateway by default comes with a 10,000 RPS limit for an account now that is a",
    "start": "428620",
    "end": "436810"
  },
  {
    "text": "limit that is is soft we can definitely increase that if you have workloads that",
    "start": "436810",
    "end": "441820"
  },
  {
    "text": "are gonna be higher than 10,000 RPS please let us know we'd love to hear from you but with inside of that you",
    "start": "441820",
    "end": "450400"
  },
  {
    "text": "have your individual api's could use a portion of that of that limit so this is",
    "start": "450400",
    "end": "455530"
  },
  {
    "text": "a nice way to kind of see if you have multiple API is in your account how much each API is contributing towards that",
    "start": "455530",
    "end": "462580"
  },
  {
    "text": "overall goal then on my next my next graph here on my dashboard is the RPS or",
    "start": "462580",
    "end": "470260"
  },
  {
    "start": "464000",
    "end": "900000"
  },
  {
    "text": "my little happy little api's API that I set up as well as the 5x X + 4 xx",
    "start": "470260",
    "end": "476620"
  },
  {
    "text": "percentages that my API is generating and so that my alarm was that I was",
    "start": "476620",
    "end": "482140"
  },
  {
    "text": "receiving a high number of 5x X errors so that just means that any status code five hundred or above API gateway is",
    "start": "482140",
    "end": "489250"
  },
  {
    "text": "returning that for my API and so I can see that compared with in RPS rate for",
    "start": "489250",
    "end": "496510"
  },
  {
    "text": "my API so I can see right now that my API is generating 89% 5 xx RS that's",
    "start": "496510",
    "end": "501729"
  },
  {
    "text": "crazy crazy high then right below that I have a what we call a insights query and",
    "start": "501729",
    "end": "509590"
  },
  {
    "text": "so this is a query over access logs that will then pull out a subset of requests",
    "start": "509590",
    "end": "516070"
  },
  {
    "text": "that are that are matching the query so this query is showing me all of my 500 requests for this API within the",
    "start": "516070",
    "end": "524899"
  },
  {
    "text": "last hour and so the most recent ones are queued up at the top and so I can see a request time the requests I need",
    "start": "524899",
    "end": "532819"
  },
  {
    "text": "which is going to be the API gateway request ID for this for this request the",
    "start": "532819",
    "end": "537889"
  },
  {
    "text": "status that API gateway is returning the integration request ID which will be the lamda request ID for this API call that",
    "start": "537889",
    "end": "546980"
  },
  {
    "text": "is if we've made a call to lamda and well as well as the lamda response code for my for my API call so now now that I",
    "start": "546980",
    "end": "555199"
  },
  {
    "text": "have this information I can say okay I haven't have a request ID now how do I",
    "start": "555199",
    "end": "560360"
  },
  {
    "text": "figure out what's actually happening with that request so I'm going to go ahead and grab that request ID go ahead",
    "start": "560360",
    "end": "568910"
  },
  {
    "text": "and copy it to my clipboard and then I'm going to go over to the logs dashboard the large logs portion of the cloud",
    "start": "568910",
    "end": "575029"
  },
  {
    "text": "watch dashboard and start looking for my request so the first thing I'm going to do is I'm going to go to the execution",
    "start": "575029",
    "end": "581300"
  },
  {
    "text": "logs for the API gateway API I'm going to search my log group and when I search",
    "start": "581300",
    "end": "588769"
  },
  {
    "text": "for this event for this request ID making sure to enclose it in quotes because otherwise cloud watch will",
    "start": "588769",
    "end": "594380"
  },
  {
    "text": "consider that a partial query and we'll get some live delay here and so what I",
    "start": "594380",
    "end": "604009"
  },
  {
    "text": "should be seeing here at this point unfortunately I'm getting a little bit of a propagation delay is a is the",
    "start": "604009",
    "end": "609470"
  },
  {
    "text": "request ID the logs for this request ID I'll try grabbing a slightly older",
    "start": "609470",
    "end": "614810"
  },
  {
    "text": "request so that we can get perhaps less of a chance a propagation delay about",
    "start": "614810",
    "end": "623269"
  },
  {
    "text": "why you're doing this also are you going to or can you show us how you built one of those charts and graphs yeah we will",
    "start": "623269",
    "end": "630620"
  },
  {
    "text": "actually be adding some additional graphs to this to this dashboard as a as",
    "start": "630620",
    "end": "636050"
  },
  {
    "text": "a way to demonstrate that functionality okay all right so we are having some",
    "start": "636050",
    "end": "643490"
  },
  {
    "text": "problems here good [Applause]",
    "start": "643490",
    "end": "648999"
  },
  {
    "text": "all right so rather than trying to search by even request idea which unfortunately doesn't seem to want to",
    "start": "653690",
    "end": "659600"
  },
  {
    "text": "work today we'll go to one of our",
    "start": "659600",
    "end": "664630"
  },
  {
    "text": "boo-boos using one of our log streams and the API gateway execution logs will",
    "start": "664630",
    "end": "673730"
  },
  {
    "text": "have multiple events per execution so this will give you a basically a",
    "start": "673730",
    "end": "680420"
  },
  {
    "text": "breakdown of the various transformations authorization throttling etc that might",
    "start": "680420",
    "end": "686390"
  },
  {
    "text": "happen during the course of your API invocation so I'm going to go ahead and look for this here we go so here's one",
    "start": "686390",
    "end": "693080"
  },
  {
    "text": "that's a 502 confer 500 okay so that",
    "start": "693080",
    "end": "701990"
  },
  {
    "text": "here we go here's a request ID for the 500 someone's gonna grab this guy and",
    "start": "701990",
    "end": "707410"
  },
  {
    "text": "quickly pull up just its logs okay so",
    "start": "707410",
    "end": "713720"
  },
  {
    "text": "now I'm just getting the logs for this request ID that generated a 500 because",
    "start": "713720",
    "end": "719510"
  },
  {
    "text": "I have extreme for both logging turned on and so I'm getting for what we call full request response logging enabled I",
    "start": "719510",
    "end": "726950"
  },
  {
    "text": "can see I'm sort of everything that's happening with inside of the context of my API I can see that the what request",
    "start": "726950",
    "end": "733940"
  },
  {
    "text": "is actually being sent in so this is a weather API and it's it takes us in",
    "start": "733940",
    "end": "739100"
  },
  {
    "text": "putting in zip code excuse me and so then it passes that off to our",
    "start": "739100",
    "end": "744830"
  },
  {
    "text": "lambda function transforms it into a",
    "start": "744830",
    "end": "750860"
  },
  {
    "text": "format that that our lambda function will understand and then processes hands it off to the lambda function to execute",
    "start": "750860",
    "end": "759100"
  },
  {
    "text": "then I can see the response as well the",
    "start": "759100",
    "end": "764720"
  },
  {
    "text": "full the full response from from my lambda function so I can see here that lambda returned a 200 but I'm using the",
    "start": "764720",
    "end": "772100"
  },
  {
    "text": "proxy format that you learned about in the previous session of happy little api's and my lambda function is actually",
    "start": "772100",
    "end": "778340"
  },
  {
    "text": "self is actually sending telling API a gateway to send back a 500 so it is",
    "start": "778340",
    "end": "783410"
  },
  {
    "text": "considering this a fatal error and error message the body that that's",
    "start": "783410",
    "end": "788689"
  },
  {
    "text": "actually going back to the customer just says that there's no results in my database for this zip code now that",
    "start": "788689",
    "end": "795709"
  },
  {
    "text": "seems like an odd thing to return a 504 normally you might expect that like a an",
    "start": "795709",
    "end": "801199"
  },
  {
    "text": "unexpected or a not found error over to return a 400 class error or a 404 specifically so let's just take a quick",
    "start": "801199",
    "end": "808819"
  },
  {
    "text": "peek at this function code and see if we can figure out what might be happening here so this is a really really simple",
    "start": "808819",
    "end": "816639"
  },
  {
    "text": "Python Python lambda function that is creating the DynamoDB database based on",
    "start": "816639",
    "end": "822860"
  },
  {
    "text": "the input that is coming in from our our clients and so you can see here that if",
    "start": "822860",
    "end": "829429"
  },
  {
    "text": "I have a type error or a generic exception or these are the these are the",
    "start": "829429",
    "end": "835959"
  },
  {
    "text": "conditions in which that the the lambda function would say generate a 500 for",
    "start": "835959",
    "end": "841069"
  },
  {
    "text": "this API and then if I scroll back up here I see that my my find data function",
    "start": "841069",
    "end": "848329"
  },
  {
    "text": "is returning a type error for this error message and so this is where this is the",
    "start": "848329",
    "end": "853939"
  },
  {
    "text": "bug in my code that is generating the 500 errors to my customers so if I change this instead to a value error so",
    "start": "853939",
    "end": "864619"
  },
  {
    "text": "you can function pick off a build and deploy while that's building well we'll",
    "start": "864619",
    "end": "872689"
  },
  {
    "text": "talk about some other things and so what should happen here is is that I've made that change I've deployed my lambda",
    "start": "872689",
    "end": "877970"
  },
  {
    "text": "function and I should immediately be able to see a recovery in those metrics and so instead of a 5 X X error my",
    "start": "877970",
    "end": "884029"
  },
  {
    "text": "customers will get in a more appropriate for X X error my alarm will clear my operator can go back to bed",
    "start": "884029",
    "end": "890419"
  },
  {
    "text": "and so that's how we can respond to sort of an event in the case of a in a case",
    "start": "890419",
    "end": "898999"
  },
  {
    "text": "of a norm so let's take a look at a little bit about how we actually constructed these graphs and how we can",
    "start": "898999",
    "end": "905059"
  },
  {
    "text": "add additional information to our dashboard that will be useful for other kinds of operational events so if I if I",
    "start": "905059",
    "end": "913100"
  },
  {
    "text": "hover over here on any one of these graphs I can go to the edit button which will open up an edit tab in the cloud",
    "start": "913100",
    "end": "919699"
  },
  {
    "text": "watch dash and I can see sort of the breakdown of what all of my lines inside of my line",
    "start": "919699",
    "end": "925160"
  },
  {
    "start": "920000",
    "end": "1000000"
  },
  {
    "text": "graph are and so I have to here or I have four metrics that are actually two",
    "start": "925160",
    "end": "933380"
  },
  {
    "text": "that I'm writing and then to that I'm actually showing and so the reason I'm doing that is because it Gateway emits a",
    "start": "933380",
    "end": "940790"
  },
  {
    "text": "rock-type metric but I'm not interested in sort of seeing an aggregate or PDF and so I added health metrics for my",
    "start": "940790",
    "end": "949430"
  },
  {
    "text": "account level so that's no API dimension and then just the API that I am running",
    "start": "949430",
    "end": "956660"
  },
  {
    "text": "against so the happy little APS I then hide those those metrics and then add",
    "start": "956660",
    "end": "962779"
  },
  {
    "text": "what's called metric math grass and so these ones I then just say okay these",
    "start": "962779",
    "end": "968360"
  },
  {
    "text": "are one minute metrics an average RPS for women at metric would be that value of that metric divide it by 60 and so",
    "start": "968360",
    "end": "975320"
  },
  {
    "text": "then I literally just say that the overall RPS is m1 which is our account level metric divided by 60 our happy",
    "start": "975320",
    "end": "982130"
  },
  {
    "text": "little API RP s is the m2 which is our happy little api's API count divided by",
    "start": "982130",
    "end": "989240"
  },
  {
    "text": "60 so that way you can easily get a an RPS graph and then do whatever you would",
    "start": "989240",
    "end": "995269"
  },
  {
    "text": "like with it so that's that's that one so let's take a look at this moment where we actually have two different kinds of metrics and you can actually",
    "start": "995269",
    "end": "1001959"
  },
  {
    "start": "1000000",
    "end": "1170000"
  },
  {
    "text": "already see that my five x axes are starting to drop my four X X's are increasing which is exactly what we'd",
    "start": "1001959",
    "end": "1007240"
  },
  {
    "text": "expect for that for that change that we made so on this one I took advantage of",
    "start": "1007240",
    "end": "1015579"
  },
  {
    "text": "the fact that we can actually have two axes on our graphs inside of cloud watch and so on our left hand side we have our",
    "start": "1015579",
    "end": "1022930"
  },
  {
    "text": "RPS for our API and on the right hand side we have a percentage of our 4x X +",
    "start": "1022930",
    "end": "1028720"
  },
  {
    "text": "5 X X errors and so again I'm using I'm using metric math not only to calculate",
    "start": "1028720",
    "end": "1035380"
  },
  {
    "text": "the RPS but then also for the percentages to make them a little bit more human readable and easy to read so",
    "start": "1035380",
    "end": "1041470"
  },
  {
    "text": "the metrics that we are actually looking at are the 5x X error and the 4x X error that are emitted by epi Gateway now for",
    "start": "1041470",
    "end": "1048428"
  },
  {
    "text": "every request we will emit a metric either a 0 or 1 if it is a 5x X or",
    "start": "1048429",
    "end": "1053980"
  },
  {
    "text": "or xx errors so if it's a 200 error both of those metrics will be 0 if it is a 5",
    "start": "1053980",
    "end": "1059110"
  },
  {
    "text": "xx error if a 500 error then it would be 5 xx 1 4 xx 0 etc so what that allows us",
    "start": "1059110",
    "end": "1066190"
  },
  {
    "text": "to do is say that if we average that metric that is the percentage or the ratio of those metrics of that metric",
    "start": "1066190",
    "end": "1074110"
  },
  {
    "text": "that is for my requests that are coming in so that if I multiply that ratio by a hundred I get a percentage and so that's",
    "start": "1074110",
    "end": "1081130"
  },
  {
    "text": "all I've done here is so I have my 5 xx percentage of my 4 xx percentage and an RPS and then these little Y access knobs",
    "start": "1081130",
    "end": "1088390"
  },
  {
    "text": "allow me to then push the VAR PS over to one side and the percentage is off to the other so I'm gonna interrupt you",
    "start": "1088390",
    "end": "1094960"
  },
  {
    "text": "real quick here so and I know now because I asked you earlier and that  I'm silly but before I look it",
    "start": "1094960",
    "end": "1100090"
  },
  {
    "text": "will see it as well in the details you do in the end two times 100 where does the into come from right so the m2 is our ID which is",
    "start": "1100090",
    "end": "1107440"
  },
  {
    "text": "literally just this little ID column in our dashboard so whenever you add a new metric it'll show up as a new M counter",
    "start": "1107440",
    "end": "1114549"
  },
  {
    "text": "and the expressions get these little e counters obsidian is automatically",
    "start": "1114549",
    "end": "1120220"
  },
  {
    "text": "assigned yes the actually I think you might even be able to modify it looks",
    "start": "1120220",
    "end": "1125410"
  },
  {
    "text": "like it I can I've never tried but certainly if you wanted to do that you could but yeah that's that's where those",
    "start": "1125410",
    "end": "1131740"
  },
  {
    "text": "values come from excellent and then at that point I can just imagine math in in listing it out on the details that's",
    "start": "1131740",
    "end": "1137980"
  },
  {
    "text": "where it's gonna figure out my algorithm so speak to think of what I want to show for that particular data point yeah",
    "start": "1137980",
    "end": "1145150"
  },
  {
    "text": "absolutely and so that you can set so you can obviously graph the the the",
    "start": "1145150",
    "end": "1150580"
  },
  {
    "text": "metric math but you can also set up alarms on metric math so if you're looking for something where there's a",
    "start": "1150580",
    "end": "1155679"
  },
  {
    "text": "high Delta between two metrics you can actually look at that you can actually say that I want to alarm when the",
    "start": "1155679",
    "end": "1161470"
  },
  {
    "text": "difference between two values is 2i and so that's actually a really powerful way",
    "start": "1161470",
    "end": "1166600"
  },
  {
    "text": "to set up set up alarms if you're interested yeah definitely so we had",
    "start": "1166600",
    "end": "1171730"
  },
  {
    "start": "1170000",
    "end": "1280000"
  },
  {
    "text": "another question here and thought you might we could answer real quick sentence so because the area code 500",
    "start": "1171730",
    "end": "1177100"
  },
  {
    "text": "was an odd error to the scene that's how we determined it was a change in the code that was",
    "start": "1177100",
    "end": "1182779"
  },
  {
    "text": "and I'll jump on their debt that was how we generate the ears and yes obviously he knew what the year was but that's",
    "start": "1182779",
    "end": "1188659"
  },
  {
    "text": "where you start you know you look at that and go okay what what are the errors I get you walked in one of the",
    "start": "1188659",
    "end": "1194210"
  },
  {
    "text": "years that I'm receiving and what should or and what should I be seen and so I",
    "start": "1194210",
    "end": "1199399"
  },
  {
    "text": "don't know if you want to add anything to that but as an example he generated out of five hundred instead of a four",
    "start": "1199399",
    "end": "1204710"
  },
  {
    "text": "hundred to show you know that that was a different type of error that we should be receiving right yeah so it's more",
    "start": "1204710",
    "end": "1211820"
  },
  {
    "text": "about sort of like looking at the the status code and then diving where that status code is actually being surfaced",
    "start": "1211820",
    "end": "1218149"
  },
  {
    "text": "so again it was it was looking for that five hundred error code looking the fact",
    "start": "1218149",
    "end": "1223190"
  },
  {
    "text": "that I was returning that five hundred from my lambda function and then looking at my lambda function to then say okay",
    "start": "1223190",
    "end": "1229279"
  },
  {
    "text": "what would generate a five what would cause my lambda function to return that five hundred now obviously this is a",
    "start": "1229279",
    "end": "1234950"
  },
  {
    "text": "little bit of a contrived example sure but but certainly you can use that kind",
    "start": "1234950",
    "end": "1241279"
  },
  {
    "text": "of methodology for finding sort of any of your any of your errors so it's look for the look for a request ID that is",
    "start": "1241279",
    "end": "1248600"
  },
  {
    "text": "generating a certain status code look for the logs for that for that request ID and then figure out from the Loews",
    "start": "1248600",
    "end": "1255710"
  },
  {
    "text": "logs what is actually generating the aberrant behavior and when we're tracing this when I climb into that a little",
    "start": "1255710",
    "end": "1261529"
  },
  {
    "text": "more right yeah so we'll talk a little bit about tracing within the context of some other stuff but so we'll get to",
    "start": "1261529",
    "end": "1269570"
  },
  {
    "text": "that in just a minute so the last thing I wanted to kind of quickly highlight before we start adding some stuff is",
    "start": "1269570",
    "end": "1275600"
  },
  {
    "text": "this how this how this this insights part is actually generated and so this",
    "start": "1275600",
    "end": "1283609"
  },
  {
    "text": "is this is using cloud watch insights which is this great feature that allows you to run basically sequel like queries",
    "start": "1283609",
    "end": "1291429"
  },
  {
    "text": "that against your against your logs and it works really really great against",
    "start": "1291429",
    "end": "1297529"
  },
  {
    "text": "things like structured logs which happens to be what our access logs for API gateway and look like and so",
    "start": "1297529",
    "end": "1304100"
  },
  {
    "text": "actually I'll quickly kind of look at that first so you can see here inside of the API gateway a stick",
    "start": "1304100",
    "end": "1311550"
  },
  {
    "text": "the logging the tracing functionality that I have available to me inside of a",
    "start": "1311550",
    "end": "1317130"
  },
  {
    "text": "PA gateway so these tough settings here all for those execution logs that I was talking about earlier that we were",
    "start": "1317130",
    "end": "1323040"
  },
  {
    "text": "looking at where we actually see multiple log entries for every request",
    "start": "1323040",
    "end": "1328170"
  },
  {
    "text": "where we see the breakdown of the request as employees of the service we have a different you know sort of",
    "start": "1328170",
    "end": "1334140"
  },
  {
    "text": "bubbles that you can choose so the error message the error level log in literally only log anything that is",
    "start": "1334140",
    "end": "1340590"
  },
  {
    "text": "actually generating an error and then I have this term on here for for",
    "start": "1340590",
    "end": "1347700"
  },
  {
    "text": "demonstration purposes this is not something that I would necessarily recommend for a live API just because",
    "start": "1347700",
    "end": "1355530"
  },
  {
    "text": "the contents of your API may be sensitive could be a gateway does not",
    "start": "1355530",
    "end": "1361020"
  },
  {
    "text": "currently support any sort of the mechanism or scrubbing that data so bear that in mind if you if you're if you're",
    "start": "1361020",
    "end": "1368190"
  },
  {
    "text": "using this but it is a great way to sort of quickly a bob yes we're gonna Rob the",
    "start": "1368190",
    "end": "1374670"
  },
  {
    "text": "sound is is really bad again complains",
    "start": "1374670",
    "end": "1387870"
  },
  {
    "text": "that it's almost too loud to hear him alrighty",
    "start": "1387870",
    "end": "1393470"
  },
  {
    "text": "Bob are you with me still I'm still here can you hear up getting my a little softer now yeah it sounds like sounds",
    "start": "1393470",
    "end": "1400500"
  },
  {
    "text": "like we're a little better a little better now so okay I apologize for",
    "start": "1400500",
    "end": "1406830"
  },
  {
    "text": "interrupting you yo its let's try to continue I apologize to the audience we're trying possible so I'll try to be",
    "start": "1406830",
    "end": "1414750"
  },
  {
    "text": "I'll try to use my indoor voice rather than my outdoor voice I do a lot of outdoor realize eating so sometimes I",
    "start": "1414750",
    "end": "1421050"
  },
  {
    "text": "have a tendency to project so I apologize for that yeah so again so just kind of like",
    "start": "1421050",
    "end": "1428400"
  },
  {
    "text": "summarizing the these top section top section is for the request logs and the",
    "start": "1428400",
    "end": "1434070"
  },
  {
    "text": "for request response data is not something I would necessarily recommend for production api's but it is really",
    "start": "1434070",
    "end": "1440880"
  },
  {
    "text": "great for using in an event so you quickly turn that on it's just a checkbox in the save",
    "start": "1440880",
    "end": "1446710"
  },
  {
    "text": "settings inside of the Gateway dashboard so if you're literally in the middle of an event and it is something that you",
    "start": "1446710",
    "end": "1453130"
  },
  {
    "text": "can use to try to eat Li diagnose a problem additionally as well we also",
    "start": "1453130",
    "end": "1460120"
  },
  {
    "text": "have what we call detailed watch metrics so all of the metrics that I was showing on the dashboard we're all API aggregate",
    "start": "1460120",
    "end": "1467080"
  },
  {
    "text": "level metrics and that's only because my API is really simple would only have one method associated with it if you had a",
    "start": "1467080",
    "end": "1472870"
  },
  {
    "text": "more complex API and lots of methods and lots of resources you can actually get the same sort of metrics at a resource",
    "start": "1472870",
    "end": "1480730"
  },
  {
    "text": "basis sort of like if you had a different get or put method and you wanted to sort of see the breakdown of",
    "start": "1480730",
    "end": "1486280"
  },
  {
    "text": "the agency of those definitely there is a cost associated with that so that",
    "start": "1486280",
    "end": "1492730"
  },
  {
    "text": "something's just to bear in mind so each additional method that you enable this",
    "start": "1492730",
    "end": "1497920"
  },
  {
    "text": "on that that incurs a cost after that is",
    "start": "1497920",
    "end": "1504190"
  },
  {
    "text": "the access logs that I wanted to kind of cut talked about within the context of insights so I've enabled access logs and",
    "start": "1504190",
    "end": "1510760"
  },
  {
    "text": "I have a JSON format now this is slightly different than the default JSON",
    "start": "1510760",
    "end": "1516040"
  },
  {
    "text": "format that you get if you just clicked on this button I've added additional logs additional context variables from",
    "start": "1516040",
    "end": "1525190"
  },
  {
    "text": "my list of available variables that they're going to be useful for me while I'm debugging while on the buggy events",
    "start": "1525190",
    "end": "1533140"
  },
  {
    "text": "and so the things that I would be things that I would be interested in are like things like our response latency or",
    "start": "1533140",
    "end": "1540370"
  },
  {
    "text": "integration latency as well as the integration request items that we saw earlier when we were looking up to 5 xx",
    "start": "1540370",
    "end": "1546640"
  },
  {
    "text": "errors so because I have this structured format where I literally have a field",
    "start": "1546640",
    "end": "1554020"
  },
  {
    "text": "name and then a field value cloud watching sites is smart enough to actually figure out what all of my",
    "start": "1554020",
    "end": "1560260"
  },
  {
    "text": "variables apart so when I'm actually running the query against them it auto discovered all of these fields",
    "start": "1560260",
    "end": "1566830"
  },
  {
    "text": "that I've that I put in my access logs and cement out that will still work with",
    "start": "1566830",
    "end": "1572650"
  },
  {
    "text": "XML or CSV right yeah so any so I'm not sure about CSB so because the",
    "start": "1572650",
    "end": "1580539"
  },
  {
    "text": "information is not encapsulated in every log line so XML would definitely work",
    "start": "1580539",
    "end": "1586269"
  },
  {
    "text": "because again it would follow that sort of format where each tag would be visible inside of the individual log",
    "start": "1586269",
    "end": "1592059"
  },
  {
    "text": "entry from a CSV you might have to actually provide a format as part of",
    "start": "1592059",
    "end": "1598509"
  },
  {
    "text": "your query to say that field one is X field y is filled two is y and and so on",
    "start": "1598509",
    "end": "1604389"
  },
  {
    "text": "but with this format with the JSON or an XML format insects is able to add a",
    "start": "1604389",
    "end": "1609940"
  },
  {
    "text": "discovery this gives for us common and so literally all I'm doing here is actually saying okay my status code I",
    "start": "1609940",
    "end": "1616539"
  },
  {
    "text": "want it to be a 5 X X so that's literally just a regex with five followed by two digits then I use this",
    "start": "1616539",
    "end": "1623289"
  },
  {
    "text": "pipe character to say that I want to select only a certain number of fields I want to sort those results by the",
    "start": "1623289",
    "end": "1629320"
  },
  {
    "text": "timestamp which is the timestamp associated with the actual blog entry and then limit those results to about",
    "start": "1629320",
    "end": "1635830"
  },
  {
    "text": "200 so that basically just gave me the top 200 and so literally I can I can",
    "start": "1635830",
    "end": "1642250"
  },
  {
    "text": "modify this query if I want I can add additional fields and then save those changes to my dashboard but what I'm",
    "start": "1642250",
    "end": "1649509"
  },
  {
    "text": "actually going to do now is go ahead and walk through so now now our API is is is",
    "start": "1649509",
    "end": "1656889"
  },
  {
    "start": "1650000",
    "end": "1670000"
  },
  {
    "text": "stable at least in the sense that it's no longer generating 5 X X's but we want",
    "start": "1656889",
    "end": "1661960"
  },
  {
    "text": "to understand a little bit more about sort of the customer experience so like how fast is our API operating so what",
    "start": "1661960",
    "end": "1667509"
  },
  {
    "text": "I'm going to go ahead and do is actually add some graphs that will reflect the",
    "start": "1667509",
    "end": "1673179"
  },
  {
    "text": "customer experience for our customers calling our API so I went ahead and",
    "start": "1673179",
    "end": "1678250"
  },
  {
    "text": "created a new widget a new language it and then I'm just selecting metrics that I'm going to want to include in my API",
    "start": "1678250",
    "end": "1684850"
  },
  {
    "text": "starting in my grass so I selected API gateway I'm going to select the by stage because I'm only interested in my Prada",
    "start": "1684850",
    "end": "1690909"
  },
  {
    "text": "and then I'm gonna be grabbing the to latency metrics that API gateway",
    "start": "1690909",
    "end": "1697720"
  },
  {
    "text": "publishes so that there's an important distinction with these two metrics and that the latency is the the latency from",
    "start": "1697720",
    "end": "1706029"
  },
  {
    "text": "the first start at the time from when API gave me receives the request it generates a response now obviously on",
    "start": "1706029",
    "end": "1712930"
  },
  {
    "text": "the back end there are gonna be a lot of stuff going on that could be included being doing an authorization check that",
    "start": "1712930",
    "end": "1719950"
  },
  {
    "text": "could be calling the integration which is what we're kind of interested in here so calling our lambda function and so",
    "start": "1719950",
    "end": "1726220"
  },
  {
    "text": "we've broken out the integration latency so you can kind of see the difference and sort of where the time is going and",
    "start": "1726220",
    "end": "1733030"
  },
  {
    "text": "so in this case our integration latency is roughly going to be analogous to our lambda duration plus lambda overhead",
    "start": "1733030",
    "end": "1740880"
  },
  {
    "text": "this front one it leaves from back to the API and hits whatever service dinamo",
    "start": "1740880",
    "end": "1746530"
  },
  {
    "text": "to lambda whatever yeah so it's literally just the time from when API gateway sends the request to the",
    "start": "1746530",
    "end": "1752500"
  },
  {
    "text": "integration in our case lambda Johanna gets a response back good and then again",
    "start": "1752500",
    "end": "1758860"
  },
  {
    "text": "I'm going to graph this with my count because again I'm going to be interested",
    "start": "1758860",
    "end": "1764860"
  },
  {
    "text": "to see if there's going to be any changes in the latency as the call rate goes up or down again this is a very",
    "start": "1764860",
    "end": "1771190"
  },
  {
    "text": "common practice that we use inside of Amazon I am again going to turn that",
    "start": "1771190",
    "end": "1779350"
  },
  {
    "text": "count into an RPS so that's three so you",
    "start": "1779350",
    "end": "1784750"
  },
  {
    "text": "haven't hit that math expression for the IDS to show up okay that sure I probably",
    "start": "1784750",
    "end": "1791650"
  },
  {
    "text": "had your prospective or no you probably do though don't think so yeah that's stuff you don't see IDs pop up hit the",
    "start": "1791650",
    "end": "1798400"
  },
  {
    "text": "add math expression of that that gives you the options obviously okay and so then we're gonna do m3 divided by 60 and",
    "start": "1798400",
    "end": "1806590"
  },
  {
    "text": "I'm gonna make sure that we turn all of our metrics into one minute metrics so",
    "start": "1806590",
    "end": "1812520"
  },
  {
    "text": "one minute metrics is the finest granularity that EPA Gateway currently supports for four metrics so there are",
    "start": "1812520",
    "end": "1819220"
  },
  {
    "text": "options for you know one to thirty seconds unfortunately those don't function correctly inside of a console",
    "start": "1819220",
    "end": "1826620"
  },
  {
    "text": "okay so that's our RPS we're gonna hide our count we are going to move our",
    "start": "1826620",
    "end": "1832210"
  },
  {
    "text": "latency graphs over to one side then I'm going to go ahead and add my left axis",
    "start": "1832210",
    "end": "1840730"
  },
  {
    "text": "is our PS I write accesses latency and it's that and so I'm graphing the",
    "start": "1840730",
    "end": "1850120"
  },
  {
    "text": "average latency now I'm actually going to go ahead and change that before I put",
    "start": "1850120",
    "end": "1855400"
  },
  {
    "text": "it on the dashboard so the average is is a good representation of average of the",
    "start": "1855400",
    "end": "1861250"
  },
  {
    "text": "average experience but oftentimes particularly internally in Amazon we often think about what we call",
    "start": "1861250",
    "end": "1867070"
  },
  {
    "text": "percentiles and so that just is sort of outlier requests and so we often usually",
    "start": "1867070",
    "end": "1872800"
  },
  {
    "text": "target the p99 which is sort of in think about it as the maximum requests time or",
    "start": "1872800",
    "end": "1878530"
  },
  {
    "text": "the maximum of a value after you throw away the one top one percent of the outliers and so on",
    "start": "1878530",
    "end": "1886810"
  },
  {
    "text": "API gateway metrics for the Legion sees actually I need to turn this to a sum first as well and support the",
    "start": "1886810",
    "end": "1895960"
  },
  {
    "text": "percentiles so I can actually also create custom percentiles but thought watch has given me this nice handy-dandy",
    "start": "1895960",
    "end": "1902260"
  },
  {
    "text": "p99 value so I'm going to go ahead and select that and so now I can see sort of",
    "start": "1902260",
    "end": "1907960"
  },
  {
    "text": "the p99 value of my API request rate",
    "start": "1907960",
    "end": "1913290"
  },
  {
    "text": "with the PMF this represents 99% of our calls but in throw away kind of the highest",
    "start": "1913290",
    "end": "1919660"
  },
  {
    "text": "and lowest it threw away the highest its throwing away sort of the highest the",
    "start": "1919660",
    "end": "1927010"
  },
  {
    "text": "highest one percent of the data because so your low values you're really fast",
    "start": "1927010",
    "end": "1933220"
  },
  {
    "text": "values are going to are going to pollute your valid sorry your average just as",
    "start": "1933220",
    "end": "1938590"
  },
  {
    "text": "much as your high ones are there this is that this is just think about it again as like the maximum after you've",
    "start": "1938590",
    "end": "1944530"
  },
  {
    "text": "discarded some amount of large outliers ok and then I'm going to go ahead and",
    "start": "1944530",
    "end": "1950260"
  },
  {
    "text": "give this a name RPS versus API latency",
    "start": "1950260",
    "end": "1956010"
  },
  {
    "text": "and go ahead and create this widget",
    "start": "1956010",
    "end": "1961350"
  },
  {
    "text": "space and then always the number one thing that even sometimes I forget to do",
    "start": "1962250",
    "end": "1968200"
  },
  {
    "text": "is make sure to save that dashboard and so that you don't lose those changes",
    "start": "1968200",
    "end": "1973300"
  },
  {
    "text": "later so now I have a latency - or that I can look at inside of my API",
    "start": "1973300",
    "end": "1979549"
  },
  {
    "text": "and so you can see that my my p99 is actually section pretty pretty darn high",
    "start": "1979549",
    "end": "1984899"
  },
  {
    "text": "so that's the 300 milliseconds 3 3 seconds and really all I should be doing",
    "start": "1984899",
    "end": "1989970"
  },
  {
    "text": "is is is querying a database to return some some weather data about a locality",
    "start": "1989970",
    "end": "1995370"
  },
  {
    "text": "so that seems seems awfully high to me so let's let's go ahead and add another",
    "start": "1995370",
    "end": "2001809"
  },
  {
    "text": "another widget which will give us some request IDs that are showing higher",
    "start": "2001809",
    "end": "2007190"
  },
  {
    "start": "2004000",
    "end": "2098000"
  },
  {
    "text": "latency so we're going to go ahead and just let the query results make sure",
    "start": "2007190",
    "end": "2012980"
  },
  {
    "text": "that I select my access logs and then",
    "start": "2012980",
    "end": "2018740"
  },
  {
    "text": "I'm going to save some time and select a query I've already pre-built and so again just",
    "start": "2018740",
    "end": "2027559"
  },
  {
    "text": "going over this this query again I'm looking at the latency value and I'm going to be looking only at the things",
    "start": "2027559",
    "end": "2032779"
  },
  {
    "text": "that are where the latency is over 1,000 so the the metric is recorded in milliseconds so this is requests that",
    "start": "2032779",
    "end": "2039049"
  },
  {
    "text": "are taking longer than one second and then I'm going to pull out a few key fields that I'm going to be interested",
    "start": "2039049",
    "end": "2045169"
  },
  {
    "text": "in in my API so the request time the request ID the to latency values the to",
    "start": "2045169",
    "end": "2052580"
  },
  {
    "text": "request IDs and then finally this little bag right here which is our trace ID so",
    "start": "2052580",
    "end": "2057618"
  },
  {
    "text": "this is going to be our link into quickly finding a trace inside of the X ray console so I'm gonna go ahead and",
    "start": "2057619",
    "end": "2065839"
  },
  {
    "text": "run that query and we can see the results and I'll go ahead and create",
    "start": "2065839",
    "end": "2072080"
  },
  {
    "text": "this widget and add it to my dashboard and so now I have this quickly available",
    "start": "2072080",
    "end": "2078679"
  },
  {
    "text": "to me if I wanted to if I wanted to take action on it once again I make sure that",
    "start": "2078679",
    "end": "2084648"
  },
  {
    "text": "I saved my dashboard and actually before we dive into the X ray stuff one more",
    "start": "2084649",
    "end": "2090589"
  },
  {
    "text": "thing that we should probably talk about is how we can set up the alarms after we've set this up so the under the Edit",
    "start": "2090589",
    "end": "2098119"
  },
  {
    "start": "2098000",
    "end": "2313000"
  },
  {
    "text": "tab I don't have the additional action to sort of add metrics and modified but",
    "start": "2098119",
    "end": "2105840"
  },
  {
    "text": "if I go ahead and say show this in the metrics console I have this nice little",
    "start": "2105840",
    "end": "2113730"
  },
  {
    "text": "new icon or a bell and so any one of these values I can click this Bell icon",
    "start": "2113730",
    "end": "2121080"
  },
  {
    "text": "and actually set a new alarm and so they'll be on the alarm on that metric",
    "start": "2121080",
    "end": "2127350"
  },
  {
    "text": "so I'm less so I'm looking at the latency in 1899 I'm looking at one period one minute period and then I'm",
    "start": "2127350",
    "end": "2133680"
  },
  {
    "text": "interested in when when I want to alarm on that Valve now my my query that I'm",
    "start": "2133680",
    "end": "2139770"
  },
  {
    "text": "looking for in my dashboard is one second so that seems like a reasonable threshold to go ahead and set as my alarm freshmen under the advanced",
    "start": "2139770",
    "end": "2148470"
  },
  {
    "text": "configuration there are a few other options that are particularly useful if you're using percentile metrics or",
    "start": "2148470",
    "end": "2154350"
  },
  {
    "text": "things that you mean things that might not are very often so you can treat the",
    "start": "2154350",
    "end": "2160350"
  },
  {
    "text": "data as missing not breaching I usually tend to choose not reaching so that sort",
    "start": "2160350",
    "end": "2166530"
  },
  {
    "text": "of Dien no news is good news kind of situation so you'd want to get your alarm if you're if you're not if you're",
    "start": "2166530",
    "end": "2173160"
  },
  {
    "text": "guys not getting called it's not going to fall over but obviously if you have a",
    "start": "2173160",
    "end": "2178170"
  },
  {
    "text": "use case where if you're not receiving API calls that is an event you want to you want to take a take note up you can",
    "start": "2178170",
    "end": "2185760"
  },
  {
    "text": "obviously treat missing data as reaching and then additionally as well for the",
    "start": "2185760",
    "end": "2191220"
  },
  {
    "text": "percentile metrics there's an evaluator or anymore so typically when you're",
    "start": "2191220",
    "end": "2196290"
  },
  {
    "text": "talking about percentile metrics you need to have enough requests for it to be able to calculate a proper percentile",
    "start": "2196290",
    "end": "2203160"
  },
  {
    "text": "if you don't have sort of that data that RPS great drops low enough that there's",
    "start": "2203160",
    "end": "2208590"
  },
  {
    "text": "not enough data points you can either again decide whether or not to evaluate that or not I'm going to leave it that",
    "start": "2208590",
    "end": "2214290"
  },
  {
    "text": "as evaluate then from my alarm I have",
    "start": "2214290",
    "end": "2220740"
  },
  {
    "text": "the ability to trigger an action and so I'm going to say that I want to send a",
    "start": "2220740",
    "end": "2228810"
  },
  {
    "text": "notification to my SMS topic which is wired up already to my email",
    "start": "2228810",
    "end": "2233990"
  },
  {
    "text": "but I setup for the for the demo and so",
    "start": "2233990",
    "end": "2240170"
  },
  {
    "text": "it's just shows up in a drop-down and then I can see all of the all of the emails orestes that are actually",
    "start": "2240170",
    "end": "2246470"
  },
  {
    "text": "notified on this notification because it is going to an SMS topic you can link",
    "start": "2246470",
    "end": "2252410"
  },
  {
    "text": "that topic to anything else that you want that could be an sqs queue that you process later that can even be a limit",
    "start": "2252410",
    "end": "2257930"
  },
  {
    "text": "of function if you had if you wanted to sort of have an automated media mitigation so if you knew sort of a",
    "start": "2257930",
    "end": "2264170"
  },
  {
    "text": "common pattern that happened in your API and an easy way to mitigate it you can even try to automate that with a lambda",
    "start": "2264170",
    "end": "2270320"
  },
  {
    "text": "function I'm not going to add any other additional actions and then I wanted to",
    "start": "2270320",
    "end": "2277790"
  },
  {
    "text": "call this happy little c9 and create my",
    "start": "2277790",
    "end": "2289609"
  },
  {
    "text": "alarm and so there we go so now I have an alarm and we already",
    "start": "2289609",
    "end": "2295609"
  },
  {
    "text": "know that Leon are based on our data that eventually this is going to this is eventually going to fire right now",
    "start": "2295609",
    "end": "2301130"
  },
  {
    "text": "because it's it's too new and showing this insufficient data state eventually it will fire and I'll get another email",
    "start": "2301130",
    "end": "2307280"
  },
  {
    "text": "in my account telling me that my API is pretty slow okay so now let's go back",
    "start": "2307280",
    "end": "2313670"
  },
  {
    "text": "over to our dashboard it's not I have these these um these requests and these",
    "start": "2313670",
    "end": "2319280"
  },
  {
    "text": "trace IDs now it's a great time to go over to the x-ray console and actually see a breakdown of my API and where we",
    "start": "2319280",
    "end": "2326300"
  },
  {
    "text": "might be going wrong so I'm going to go ahead and take one of these trees IDs we won't get a propagation delay again go",
    "start": "2326300",
    "end": "2336380"
  },
  {
    "text": "ahead and open up the x-ray dashboard traces then already see a bunch of",
    "start": "2336380",
    "end": "2343310"
  },
  {
    "text": "traces already I've again I've enabled a hundred percent tracing rate in my CI",
    "start": "2343310",
    "end": "2349190"
  },
  {
    "text": "that may not be something you want to do in a production level API you may you",
    "start": "2349190",
    "end": "2355310"
  },
  {
    "text": "may only want to sample so if I default I believe the to the default is ten percent but you can configure that",
    "start": "2355310",
    "end": "2361670"
  },
  {
    "text": "however you choose you can even choose different sampling rates based on any number of factors so I'm going to go",
    "start": "2361670",
    "end": "2368450"
  },
  {
    "text": "ahead and take this trace ID and boom we got it great perfect and so now I can",
    "start": "2368450",
    "end": "2374180"
  },
  {
    "text": "see inside of my trace ID a breakdown of sort of all of the in between steps of",
    "start": "2374180",
    "end": "2379910"
  },
  {
    "text": "my of my API so by default if you just",
    "start": "2379910",
    "end": "2385430"
  },
  {
    "text": "enabled tracing on your API gateway API and Atlantica pretty much all you would",
    "start": "2385430",
    "end": "2391730"
  },
  {
    "text": "get would be these these top two sub segments so you would see the API gated",
    "start": "2391730",
    "end": "2397700"
  },
  {
    "text": "stage and the US and so we can see that our request is taking three seconds and",
    "start": "2397700",
    "end": "2405319"
  },
  {
    "text": "then it's invoking the lambda function again the lambda function is still taking three points in seconds so the",
    "start": "2405319",
    "end": "2410930"
  },
  {
    "text": "front end is not problem we're not having any problems with with that sort of thing the landis service overall so how do we",
    "start": "2410930",
    "end": "2419630"
  },
  {
    "text": "figure out where we want to go from there thankfully the extra team actually built",
    "start": "2419630",
    "end": "2424759"
  },
  {
    "text": "this really kami SDK that you can actually drop into your lambda function and they actually have common SDKs for a",
    "start": "2424759",
    "end": "2432289"
  },
  {
    "text": "lot of the popular runtimes so Python node as well as Java that you can just",
    "start": "2432289",
    "end": "2438470"
  },
  {
    "text": "kind of drop in to your API your function code inside of lambda and get these great little sub traces or sub",
    "start": "2438470",
    "end": "2445910"
  },
  {
    "text": "segments inside of my trace so I can see that that inside of my inside of my",
    "start": "2445910",
    "end": "2450920"
  },
  {
    "text": "lambda function the initialization took about four hundred forty-four seconds that's something that we don't really",
    "start": "2450920",
    "end": "2455960"
  },
  {
    "text": "control a hundred percent we can do some optimization to to try to improve that",
    "start": "2455960",
    "end": "2461930"
  },
  {
    "text": "by increasing our pack size and our lambda function but that's not really",
    "start": "2461930",
    "end": "2467059"
  },
  {
    "text": "doesn't even mean that doesn't seem to be the majority of our our latency so",
    "start": "2467059",
    "end": "2474289"
  },
  {
    "text": "we're seems to be most of it is the validating prep method or the sub trace",
    "start": "2474289",
    "end": "2480019"
  },
  {
    "text": "in my function as well as the line data scan which is taking 500 milliseconds",
    "start": "2480019",
    "end": "2486289"
  },
  {
    "text": "overall and calling 400 milliseconds now this feels like an",
    "start": "2486289",
    "end": "2491670"
  },
  {
    "text": "awfully long time again so remember that my API is taking in as input a single",
    "start": "2491670",
    "end": "2498059"
  },
  {
    "text": "zip code and returning the results of that zip code or weather from that zip back to my collar so it seems awfully",
    "start": "2498059",
    "end": "2505440"
  },
  {
    "text": "odd that we would one that we would take 400 milliseconds to return and to that",
    "start": "2505440",
    "end": "2510869"
  },
  {
    "text": "we might be using this scan operation and then as well we might want to take a look at this as validating prep method",
    "start": "2510869",
    "end": "2518040"
  },
  {
    "text": "for potential bottlenecks or bugs that might be causing some thread contention",
    "start": "2518040",
    "end": "2523589"
  },
  {
    "text": "or something else so let's go ahead and switch back over to our our code and",
    "start": "2523589",
    "end": "2529500"
  },
  {
    "start": "2528000",
    "end": "2783000"
  },
  {
    "text": "quickly take a look at these two functions so first let's take a look at",
    "start": "2529500",
    "end": "2535020"
  },
  {
    "text": "our scam function it's again it's really straightforward really simple I'm all I'm doing is using photo to actually",
    "start": "2535020",
    "end": "2542520"
  },
  {
    "text": "query or sorry Stan the dynamo DD table and I'm looking I'm doing these skin and",
    "start": "2542520",
    "end": "2549660"
  },
  {
    "text": "looking for a field that matches my zip code now I've got zip codes for every",
    "start": "2549660",
    "end": "2555210"
  },
  {
    "text": "ZIP code in the entirety of the United States that means that every time I want to to check to see entry to look for I'm",
    "start": "2555210",
    "end": "2563280"
  },
  {
    "text": "actually scanning over the entire table so that's really inefficient so it's really in a fusion inefficient use of",
    "start": "2563280",
    "end": "2569540"
  },
  {
    "text": "dynamodb throughput because every one of those items that is checked is going to",
    "start": "2569540",
    "end": "2574829"
  },
  {
    "text": "count against when our vision capacity and and literally I'm just I'm going through all of those entries every",
    "start": "2574829",
    "end": "2580890"
  },
  {
    "text": "single time the the table was actually set up such that it was where the zip",
    "start": "2580890",
    "end": "2587250"
  },
  {
    "text": "code was actually the index so there's far more efficient ways for us to actually get that data out rather than",
    "start": "2587250",
    "end": "2593760"
  },
  {
    "text": "doing a scan and again apologies for a bit of the contrived example but we do",
    "start": "2593760",
    "end": "2600240"
  },
  {
    "text": "have a sort of an example code here where we can actually change this so that we would actually use a more",
    "start": "2600240",
    "end": "2605579"
  },
  {
    "text": "efficient efficient algorithm to actually get that data out where rather than using a scan where it actually have",
    "start": "2605579",
    "end": "2611640"
  },
  {
    "text": "to read through the entirety contents of the table I am I can just do a get items so I'm literally just going to dynamo de",
    "start": "2611640",
    "end": "2618240"
  },
  {
    "text": "telling them telling dynamodb give me this one item and only this one item if it exists",
    "start": "2618240",
    "end": "2623589"
  },
  {
    "text": "and then return that back to the user so that'll be a much more efficient use of time and resources so I'm going to go",
    "start": "2623589",
    "end": "2630490"
  },
  {
    "text": "ahead and make a small change to say use the find data item method instead of the",
    "start": "2630490",
    "end": "2638470"
  },
  {
    "text": "find data scan method and then I'm about tonight tomorrow just to say can you",
    "start": "2638470",
    "end": "2644890"
  },
  {
    "text": "explain the extra quarter capture call that's right above that sure so that's",
    "start": "2644890",
    "end": "2651670"
  },
  {
    "text": "actually the the x-ray SDK so that's the method that you can use to easily",
    "start": "2651670",
    "end": "2657630"
  },
  {
    "text": "annotate the sub traces so you'll see here that these these captures with the",
    "start": "2657630",
    "end": "2664660"
  },
  {
    "text": "data are exactly what shows up in the x-ray console under my sub traces yes so",
    "start": "2664660",
    "end": "2671220"
  },
  {
    "text": "annotating these these subroutines or",
    "start": "2671220",
    "end": "2675960"
  },
  {
    "text": "functions basically allows me to say that I want to do a a a sub segment",
    "start": "2676920",
    "end": "2682599"
  },
  {
    "text": "trace over over that function and so you can also do if you don't want it if you",
    "start": "2682599",
    "end": "2688720"
  },
  {
    "text": "don't want to annotate the function you can also do next Blissett start trace and stop trace inside of a function if",
    "start": "2688720",
    "end": "2695500"
  },
  {
    "text": "you wanted to get even more regular on top of that for for these purposes it was it was really useful for me to use",
    "start": "2695500",
    "end": "2702970"
  },
  {
    "text": "these these annotations okay so then so",
    "start": "2702970",
    "end": "2709119"
  },
  {
    "text": "let's take a look at our validate and prep again apologize but you know the",
    "start": "2709119",
    "end": "2714790"
  },
  {
    "text": "contract examples are really easy to show and really easy demonstrate but I can see right here",
    "start": "2714790",
    "end": "2719859"
  },
  {
    "text": "a real glaring red flag that says this",
    "start": "2719859",
    "end": "2725530"
  },
  {
    "text": "is where my time is going so I'm literally have some some random sleep baked into my function so that I leave a",
    "start": "2725530",
    "end": "2732700"
  },
  {
    "text": "random amount of time somewhere between 100 and 2,000 milliseconds so obviously",
    "start": "2732700",
    "end": "2738490"
  },
  {
    "text": "that's not going to be a very efficient use of our time lambda bills based on our execution time so I'm literally",
    "start": "2738490",
    "end": "2744880"
  },
  {
    "text": "throwing pennies away so I'm going to go ahead and comment that out so good",
    "start": "2744880",
    "end": "2753070"
  },
  {
    "text": "has to actually brighten issues yeah and I wouldn't go that far but at least for",
    "start": "2753070",
    "end": "2759880"
  },
  {
    "text": "today that's where we're gonna do we're gonna say so now I have may go ahead and make those changes I'm gonna go ahead",
    "start": "2759880",
    "end": "2764890"
  },
  {
    "text": "again and start up a build package and deploy step which will deploy those",
    "start": "2764890",
    "end": "2771550"
  },
  {
    "text": "changes back out to lambda and I should hopefully see a pretty much almost",
    "start": "2771550",
    "end": "2776680"
  },
  {
    "text": "immediate change again in my metrics and so while I'm waiting for that I'll kind",
    "start": "2776680",
    "end": "2781810"
  },
  {
    "text": "of walk through some of the stuff inside of the X ray dashboard that might also be of interest and so you saw this in",
    "start": "2781810",
    "end": "2789250"
  },
  {
    "start": "2783000",
    "end": "2913000"
  },
  {
    "text": "Eric's slides at the very beginning but this is what X ray calls the service mount and unfortunately my my API is",
    "start": "2789250",
    "end": "2797080"
  },
  {
    "text": "very simple so there's not a lot of sort of different paths through my graph but",
    "start": "2797080",
    "end": "2803370"
  },
  {
    "text": "you can quickly see sort of the breakdown not only of errors but like",
    "start": "2803370",
    "end": "2809830"
  },
  {
    "text": "time spent you can actually changed the period of traces that it's looking at",
    "start": "2809830",
    "end": "2814900"
  },
  {
    "text": "over time so right now I'm only looking at the last five minutes but these got this yellow line is an",
    "start": "2814900",
    "end": "2821440"
  },
  {
    "text": "indicator of where errors are occurring so you can see that API gateway is generate is generating the errors and so",
    "start": "2821440",
    "end": "2829300"
  },
  {
    "text": "again that's because my lambda function is saying API gateway return of 402 the call are telling them that they've sent",
    "start": "2829300",
    "end": "2835450"
  },
  {
    "text": "that data and we can tell that largely because the green circle is you know",
    "start": "2835450",
    "end": "2841330"
  },
  {
    "text": "that the lambda circle is 100% green so lambda itself is not generating any errors API gateway is it's another",
    "start": "2841330",
    "end": "2848320"
  },
  {
    "text": "partial indicator that that that is going to be the cause of our potential",
    "start": "2848320",
    "end": "2853450"
  },
  {
    "text": "problems or where to look for where there might be potential problems if I select any one of these I can get sort",
    "start": "2853450",
    "end": "2861580"
  },
  {
    "text": "of a breakdown with some additional graphs and then the thing also to notice",
    "start": "2861580",
    "end": "2866920"
  },
  {
    "text": "is you can see sort of the average Layton sees within within those traces",
    "start": "2866920",
    "end": "2872110"
  },
  {
    "text": "and so if I if I start looking at for",
    "start": "2872110",
    "end": "2882280"
  },
  {
    "text": "instance the last 1 minute I can start to see already that the the times are actually already dropping",
    "start": "2882280",
    "end": "2890060"
  },
  {
    "text": "even from the x-ray from the expert perspective so the tracing is happening on a hard percent of our bus if I move",
    "start": "2890060",
    "end": "2897620"
  },
  {
    "text": "that out to five minutes per se you can see requests in the last minute which",
    "start": "2897620",
    "end": "2908090"
  },
  {
    "text": "means even better so then if I go back over to my watch death or so you'll see",
    "start": "2908090",
    "end": "2920720"
  },
  {
    "start": "2913000",
    "end": "2998000"
  },
  {
    "text": "a couple of really interesting effects um so my load generator is a single is a",
    "start": "2920720",
    "end": "2927500"
  },
  {
    "text": "single threaded application and so it is sending a request waiting for the response and then sending a next request",
    "start": "2927500",
    "end": "2933350"
  },
  {
    "text": "I improve the latency so much on this API by removing by switching to the",
    "start": "2933350",
    "end": "2939710"
  },
  {
    "text": "dynamodb jet item and by removing that sleep but I'm now actually generating four times as much traffic from that",
    "start": "2939710",
    "end": "2946010"
  },
  {
    "text": "single thread because it is getting the responses that much faster so you can about yeah so you can see the the the",
    "start": "2946010",
    "end": "2958100"
  },
  {
    "text": "latency drops pretty much through the floor the RPS goes up because our our",
    "start": "2958100",
    "end": "2963920"
  },
  {
    "text": "load generator is getting faster results and so that was pretty much all I wanted",
    "start": "2963920",
    "end": "2971450"
  },
  {
    "text": "to talk talk through today so gives you hopefully gives you a good basis for sort of understanding how you can build",
    "start": "2971450",
    "end": "2978610"
  },
  {
    "text": "monitoring alerting and and diagnose problems using the AWS tools to improve",
    "start": "2978610",
    "end": "2986300"
  },
  {
    "text": "your guys performance and reliability so with that I'll hand back over to Erica",
    "start": "2986300",
    "end": "2992420"
  },
  {
    "text": "to finish this out awesome thank you so",
    "start": "2992420",
    "end": "2997750"
  },
  {
    "text": "one thing you might have to apply x-ray to our sound system here I apologize for the sound issues hopefully we're able to",
    "start": "2997750",
    "end": "3004450"
  },
  {
    "text": "hear Bob's you know that is he was walking through that the bottom line is",
    "start": "3004450",
    "end": "3009900"
  },
  {
    "text": "what when you employ tools like cloud watch an x-ray and you can you start looking",
    "start": "3009900",
    "end": "3016720"
  },
  {
    "text": "at why you why your application may be working now originally it wasn't working and Bob was getting a 500 back and then",
    "start": "3016720",
    "end": "3023290"
  },
  {
    "text": "he was able to do some added you get to be a 400 which was a proper response for not fighting right the right data but",
    "start": "3023290",
    "end": "3029170"
  },
  {
    "text": "it's still a working API however as as you start to to look at at",
    "start": "3029170",
    "end": "3036100"
  },
  {
    "text": "bottlenecks you realize them what you saw something like four time increase",
    "start": "3036100",
    "end": "3042430"
  },
  {
    "text": "are up to 4000 mils well anyway a large decrease on the throughput with a huge decrease on the",
    "start": "3042430",
    "end": "3050680"
  },
  {
    "text": "on the latency and so the more efficient your application applications get",
    "start": "3050680",
    "end": "3056290"
  },
  {
    "text": "obviously the less money they cost the more they are responsive to customers and so it's when an application isn't",
    "start": "3056290",
    "end": "3063100"
  },
  {
    "text": "this setting broken it could still be improved upon and I'm really encouraged you've looked at these tools one use an",
    "start": "3063100",
    "end": "3068980"
  },
  {
    "text": "API gateway and even when you use it you know salame the subsequent systems because it you know come watch the next",
    "start": "3068980",
    "end": "3074980"
  },
  {
    "text": "are going to work through and I don't want to be and many other services Bob I really appreciate you take your time to",
    "start": "3074980",
    "end": "3081040"
  },
  {
    "text": "talk to this actually Bob's gonna be joining us in two weeks as we continue our series the next thing is security",
    "start": "3081040",
    "end": "3088360"
  },
  {
    "text": "we're in time I'll shut the front door but actually broken security down into two things this first one is on the front door securing access to Amazon API",
    "start": "3088360",
    "end": "3095440"
  },
  {
    "text": "gateway and we're gonna be talking about how do you lock it down how do you protect your area getting services like",
    "start": "3095440",
    "end": "3102040"
  },
  {
    "text": "like laugh and I am and different things like that sometimes you don't want man",
    "start": "3102040",
    "end": "3107890"
  },
  {
    "text": "as a developer and I first started developing cores was a pain in the rear",
    "start": "3107890",
    "end": "3113260"
  },
  {
    "text": "and guess what it still is its course it's a tough thing but it was a gateway",
    "start": "3113260",
    "end": "3118900"
  },
  {
    "text": "helps you out on a lot different things like I get lucky locking down your security so I encourage you to join us",
    "start": "3118900",
    "end": "3125650"
  },
  {
    "text": "we will be again that date let me go back here is May 28 same time same place",
    "start": "3125650",
    "end": "3131110"
  },
  {
    "text": "different room for Bob someone we shouldn't have any sound issues I",
    "start": "3131110",
    "end": "3137410"
  },
  {
    "text": "apologize we had that squared away so apparently right started so we'll be starting that again",
    "start": "3137410",
    "end": "3142530"
  },
  {
    "text": "on the air Johnson you can find me an e DJ geek and this is Bob kitty and say",
    "start": "3142530",
    "end": "3148650"
  },
  {
    "text": "say that handle Toronto Toronto is how you pronounce it it's a it's a it's a",
    "start": "3148650",
    "end": "3154080"
  },
  {
    "text": "garbled crud bunch of characters but I usually pronounce it track not okay track my and you'll have to ask Bob how",
    "start": "3154080",
    "end": "3160800"
  },
  {
    "text": "it came around of that sometime guys I appreciate it I hope you have a great day thank you thanks a lot see in a",
    "start": "3160800",
    "end": "3168300"
  },
  {
    "text": "couple weeks I guess",
    "start": "3168300",
    "end": "3172340"
  }
]
[
  {
    "text": "In this video, you'll see how you can use\nKubernetes-based Event Driven Autoscaler",
    "start": "302",
    "end": "4295"
  },
  {
    "text": "(KEDA) to proactively scale \nyour Kubernetes workloads.",
    "start": "4295",
    "end": "7241"
  },
  {
    "text": "With this solution, you can define the \nevents that drive the autoscaling response ",
    "start": "7682",
    "end": "11281"
  },
  {
    "text": "and employ horizontal pod autoscaling \nto deploy Amazon Elastic Kubernetes ",
    "start": "11281",
    "end": "15000"
  },
  {
    "text": "Service (Amazon EKS) clusters \nefficiently and cost effectively.",
    "start": "15000",
    "end": "18776"
  },
  {
    "text": "To get started, let’s create \nan Amazon EKS cluster.",
    "start": "20931",
    "end": "23713"
  },
  {
    "text": "We’ll work in the AWS Cloud9 \nintegrated development environment.",
    "start": "24275",
    "end": "27571"
  },
  {
    "text": "Let's access the configuration file we'll use.",
    "start": "28582",
    "end": "30804"
  },
  {
    "text": "The file creates a cluster and \na service account with query",
    "start": "31676",
    "end": "34136"
  },
  {
    "text": "access to Amazon Managed \nService for Prometheus.",
    "start": "34136",
    "end": "36694"
  },
  {
    "text": "This is the service account \nthe KEDA operator will use.",
    "start": "37222",
    "end": "39789"
  },
  {
    "text": "It also creates an AWS Fargate\nprofile with four namespaces.",
    "start": "40574",
    "end": "44055"
  },
  {
    "text": "Let's configure the cluster.",
    "start": "45000",
    "end": "46151"
  },
  {
    "text": "It will take a few minutes for\nthe cluster to come online.",
    "start": "47142",
    "end": "49378"
  },
  {
    "text": "Let's go to the Amazon EKS console\nto check the cluster’s progress.",
    "start": "50426",
    "end": "53774"
  },
  {
    "text": "The cluster now has a Fargate profile\nprovisioned with namespaces.",
    "start": "56861",
    "end": "59798"
  },
  {
    "text": "Let's return to the Cloud9 terminal.",
    "start": "59876",
    "end": "61369"
  },
  {
    "text": "The cluster has been created.",
    "start": "63516",
    "end": "64744"
  },
  {
    "text": "Again, this is the configuration file we used.",
    "start": "65655",
    "end": "67928"
  },
  {
    "text": "Let’s confirm that the pods are \nrunning in the Fargate infrastructure.",
    "start": "69730",
    "end": "72446"
  },
  {
    "text": "We can see that the pods have Fargate IPs.",
    "start": "73366",
    "end": "75695"
  },
  {
    "text": "Next, we’ll need to deploy the KETA operator.",
    "start": "76734",
    "end": "79000"
  },
  {
    "text": "First, let's check whether the KEDA Helm \nchart is part of the cluster's repositories.",
    "start": "79696",
    "end": "83287"
  },
  {
    "text": "It is, so let's access the configuration \nfile for the KEDA operator.",
    "start": "84457",
    "end": "87708"
  },
  {
    "text": "The file sets the security context.",
    "start": "88869",
    "end": "90818"
  },
  {
    "text": "Let's deploy the KEDA operator\nto the KEDA namespace.",
    "start": "91913",
    "end": "94504"
  },
  {
    "text": "We'll confirm by calling for the pods.",
    "start": "95661",
    "end": "97333"
  },
  {
    "text": "The status for the new containers is \"pending.\"",
    "start": "98473",
    "end": "100450"
  },
  {
    "text": "Let's continue checking until they\nachieve a \"running\" status.",
    "start": "101031",
    "end": "103626"
  },
  {
    "text": "Next, we'll provision a workspace in\nAmazon Managed Service for Prometheus.",
    "start": "109344",
    "end": "112954"
  },
  {
    "text": "Now let's visit Amazon Managed Service for\nPrometheus console to view the workspace.",
    "start": "114705",
    "end": "118592"
  },
  {
    "text": "The workspace is active.",
    "start": "124825",
    "end": "125938"
  },
  {
    "text": "Let's return to the Cloud9 terminal.",
    "start": "126361",
    "end": "128011"
  },
  {
    "text": "Next, we'll deploy a sample \napplication called “ho11y”",
    "start": "130158",
    "end": "132686"
  },
  {
    "text": "that we can use to scrape \nmetrics into the workspace.",
    "start": "132686",
    "end": "135154"
  },
  {
    "text": "To install the application, we’ll \nclone a repository from GitHub.",
    "start": "136325",
    "end": "139461"
  },
  {
    "text": "Let's enter the ho11y directory.",
    "start": "140222",
    "end": "141759"
  },
  {
    "text": "Before we can build the image, we'll establish\nthe AWS environment for the application.",
    "start": "142989",
    "end": "147000"
  },
  {
    "text": "Let's go to a new terminal\nto find the AWS Account ID.",
    "start": "148266",
    "end": "151090"
  },
  {
    "text": "Let's copy the ID and \nreturn to the main terminal.",
    "start": "153864",
    "end": "156071"
  },
  {
    "text": "We'll also define the AWS Region,\nusing the location of our EKS cluster.",
    "start": "160543",
    "end": "164624"
  },
  {
    "text": "Let's run the command to build\na Docker image of the application.",
    "start": "165815",
    "end": "168593"
  },
  {
    "text": "Now we'll upload the image to the Amazon\nElastic Container Registry (Amazon ECR).",
    "start": "170432",
    "end": "174877"
  },
  {
    "text": "Let's log in.",
    "start": "175067",
    "end": "175839"
  },
  {
    "text": "We'll create a repository \nfor the sample application.",
    "start": "177046",
    "end": "179519"
  },
  {
    "text": "In this case, the repository already exists.",
    "start": "180710",
    "end": "183000"
  },
  {
    "text": "Let’s proceed.",
    "start": "183123",
    "end": "183758"
  },
  {
    "text": "Let’s go to the Amazon ECR repository to\nconfirm that the Docker image was pushed.",
    "start": "184946",
    "end": "188948"
  },
  {
    "text": "Here's the repository.",
    "start": "191831",
    "end": "192831"
  },
  {
    "text": "Here’s the Docker image.",
    "start": "196459",
    "end": "197665"
  },
  {
    "text": "Now we can deploy the sample application.",
    "start": "198154",
    "end": "200022"
  },
  {
    "text": "Let's return to the Cloud9 terminal.",
    "start": "200667",
    "end": "202317"
  },
  {
    "text": "We'll build a \"ho11y\" namespace first, which \nis where the application will be deployed.",
    "start": "207146",
    "end": "211056"
  },
  {
    "text": "Let's access the configuration file.",
    "start": "215433",
    "end": "217175"
  },
  {
    "text": "The sample application deploys \na frontend and two backends",
    "start": "219567",
    "end": "222131"
  },
  {
    "text": "to the ho11y namespace.",
    "start": "222131",
    "end": "223504"
  },
  {
    "text": "Let’s deploy it.",
    "start": "224685",
    "end": "225525"
  },
  {
    "text": "Now let's check the pods\nto monitor the deployment.",
    "start": "227481",
    "end": "229737"
  },
  {
    "text": "Once all three pods are in a\n\"running\" status, we can proceed.",
    "start": "233373",
    "end": "236155"
  },
  {
    "text": "Next, we'll deploy the AWS Distro for \nOpenTelemetry (ADOT) to scrape the ",
    "start": "239921",
    "end": "244093"
  },
  {
    "text": "metrics and send them to the Amazon \nManaged Service for Prometheus workspace.",
    "start": "244093",
    "end": "247779"
  },
  {
    "text": "We'll set up some environment variables first.",
    "start": "249109",
    "end": "251069"
  },
  {
    "text": "Let's export the EKS cluster.",
    "start": "251274",
    "end": "252914"
  },
  {
    "text": "We'll also deploy an AWS Identity and\nAccess Management service account",
    "start": "254183",
    "end": "257754"
  },
  {
    "text": "with remote-write access to Amazon \nManaged Service for Prometheus.",
    "start": "257754",
    "end": "260909"
  },
  {
    "text": "The service account has \nbeen successfully created.",
    "start": "262313",
    "end": "264307"
  },
  {
    "text": "Now let’s set up some \nmore environment variables.",
    "start": "265480",
    "end": "267605"
  },
  {
    "text": "Let's capture the workspace URL.",
    "start": "270277",
    "end": "271985"
  },
  {
    "text": "Let's go to the Amazon Managed Service for\nPrometheus console to verify it's correct.",
    "start": "273907",
    "end": "277919"
  },
  {
    "text": "On the workspace page, we \ncan verify that the Endpoint",
    "start": "284203",
    "end": "286727"
  },
  {
    "text": "remote-write URL matches the one we used.",
    "start": "286727",
    "end": "289112"
  },
  {
    "text": "Let's go back to the terminal.",
    "start": "289322",
    "end": "290379"
  },
  {
    "text": "Let's access the configuration file for \ndeploying the AWS Distro for OpenTelemetry.",
    "start": "292547",
    "end": "296832"
  },
  {
    "text": "The file contains parameters for \nscraping the ho11y sample application.",
    "start": "298290",
    "end": "301584"
  },
  {
    "text": "Let's copy the file onto the\nkubectl CLI to put it into effect.",
    "start": "302214",
    "end": "305805"
  },
  {
    "text": "Let's review the file once more and \nconfirm the remote-write endpoint.",
    "start": "311362",
    "end": "314417"
  },
  {
    "text": "The endpoint was correctly placed.",
    "start": "315747",
    "end": "317271"
  },
  {
    "text": "Now, let's go back and apply\nthe file in the ho11y namespace.",
    "start": "320119",
    "end": "323138"
  },
  {
    "text": "Let's check on the pods to confirm they've\nbeen provisioned and are all running.",
    "start": "324269",
    "end": "327253"
  },
  {
    "text": "Next, we'll configure AWS \nSignature Version 4 (sigv4)",
    "start": "328629",
    "end": "332141"
  },
  {
    "text": "authentication for querying the workspace.",
    "start": "332141",
    "end": "334305"
  },
  {
    "text": "Since KEDA doesn’t support \nsigv4, we'll deploy a proxy.",
    "start": "334749",
    "end": "337702"
  },
  {
    "text": "Let's access and then apply\nthe sigv4 proxy configuration file.",
    "start": "338139",
    "end": "341626"
  },
  {
    "text": "We'll check the pods to \nmonitor the deployment.",
    "start": "342849",
    "end": "344852"
  },
  {
    "text": "The configuration was successful.",
    "start": "355650",
    "end": "357102"
  },
  {
    "text": "Now we'll apply a ScaledObject \nspecification to define how KEDA ",
    "start": "359219",
    "end": "362397"
  },
  {
    "text": "should scale the querying application.",
    "start": "362397",
    "end": "364271"
  },
  {
    "text": "It builds a ScaledObject and creates a \nHorizontal Pod Autoscaler (HPA) object.",
    "start": "365550",
    "end": "370194"
  },
  {
    "text": "Before we move on, let's check our pods.",
    "start": "370816",
    "end": "372689"
  },
  {
    "text": "We want to configure one of the \nbackend pods, \"downstream zero,\" ",
    "start": "373881",
    "end": "376997"
  },
  {
    "text": "as our target for ADOT \nwhen scraping the metrics.",
    "start": "376997",
    "end": "379397"
  },
  {
    "text": "Let's recall the workspace\nand copy the server address.",
    "start": "380580",
    "end": "383266"
  },
  {
    "text": "We'll view the YAML file again.",
    "start": "384444",
    "end": "386012"
  },
  {
    "text": "Let's edit the server address\nwe just copied so they match.",
    "start": "386913",
    "end": "389604"
  },
  {
    "text": "We're ready to apply the ScaledObject.",
    "start": "392826",
    "end": "394638"
  },
  {
    "text": "Let's call for the ho11y namespace on the HPA.",
    "start": "395907",
    "end": "398117"
  },
  {
    "text": "We'll also call the ScaledObject.",
    "start": "399342",
    "end": "400993"
  },
  {
    "text": "We can see its target, configured \nminimum and maximum values,",
    "start": "402150",
    "end": "405089"
  },
  {
    "text": "and that our Prometheus \nworkspace is the trigger.",
    "start": "405089",
    "end": "407212"
  },
  {
    "text": "Let's also view the HPA.",
    "start": "407714",
    "end": "409102"
  },
  {
    "text": "Here we see the name of the target metric,\nthe replica counts, and its average value.",
    "start": "410359",
    "end": "414089"
  },
  {
    "text": "We're ready to apply some \nload to the ho11y application.",
    "start": "414949",
    "end": "417388"
  },
  {
    "text": "Before we run the command, let's \ngo to Amazon Managed Grafana.",
    "start": "418391",
    "end": "421584"
  },
  {
    "text": "We'll connect a Grafana dashboard with \nAmazon Managed Service for Prometheus",
    "start": "422800",
    "end": "426271"
  },
  {
    "text": "to visualize the metrics we're loading.",
    "start": "426272",
    "end": "427906"
  },
  {
    "text": "Let's view our workspaces.",
    "start": "429200",
    "end": "430554"
  },
  {
    "text": "We'll use an existing workspace.",
    "start": "433795",
    "end": "435366"
  },
  {
    "text": "Let's log in.",
    "start": "438478",
    "end": "439227"
  },
  {
    "text": "We'll view our AWS Data Sources.",
    "start": "441690",
    "end": "443752"
  },
  {
    "text": "We'll add an Amazon Managed \nService for Prometheus data source.",
    "start": "446375",
    "end": "449396"
  },
  {
    "text": "Let's supply the Region where\nwe've provisioned our resources.",
    "start": "452798",
    "end": "455477"
  },
  {
    "text": "Now we can see the workspace we built earlier.",
    "start": "459417",
    "end": "461388"
  },
  {
    "text": "Let's add the data source.",
    "start": "461537",
    "end": "462707"
  },
  {
    "text": "Now we'll go to the Explore page.",
    "start": "464700",
    "end": "466408"
  },
  {
    "text": "We’ll select the data source we just added.",
    "start": "469286",
    "end": "471143"
  },
  {
    "text": "On the left side of the panel, we \ncan review the observable metrics.",
    "start": "474000",
    "end": "477124"
  },
  {
    "text": "Let's return to the Cloud9 terminal\nand put some load on the application.",
    "start": "477738",
    "end": "480885"
  },
  {
    "text": "We can see some trace IDs generating.",
    "start": "483973",
    "end": "485830"
  },
  {
    "text": "In the second terminal, let's \nmonitor the ho11y namespace.",
    "start": "487079",
    "end": "489929"
  },
  {
    "text": "The target average value \ncount, which had been zero,",
    "start": "492993",
    "end": "495291"
  },
  {
    "text": "is now very high, indicating the \napplication is accepting load.",
    "start": "495291",
    "end": "498533"
  },
  {
    "text": "Let’s go back to the Grafana console.",
    "start": "498899",
    "end": "500607"
  },
  {
    "text": "We'll select a metric.",
    "start": "502622",
    "end": "503622"
  },
  {
    "text": "Let's revise the query to give the sum \nof the rate for a one-minute period,",
    "start": "509529",
    "end": "512860"
  },
  {
    "text": "which was provided in the \nScaledObject configuration file.",
    "start": "512861",
    "end": "515730"
  },
  {
    "text": "The graph shows that the value\nis within the desired range.",
    "start": "517992",
    "end": "520578"
  },
  {
    "text": "Let's return to the terminal and apply \nmore load until the value exceeds 20,000.",
    "start": "521389",
    "end": "525506"
  },
  {
    "text": "We'll call for the HPA.",
    "start": "526737",
    "end": "528000"
  },
  {
    "text": "The value is 19,000, which \nis also in the desired range.",
    "start": "529315",
    "end": "532473"
  },
  {
    "text": "We'll keep applying load.",
    "start": "533657",
    "end": "534885"
  },
  {
    "text": "In a new tab, let's monitor the count.",
    "start": "537509",
    "end": "539524"
  },
  {
    "text": "Now the value has exceeded the range.",
    "start": "551396",
    "end": "553287"
  },
  {
    "text": "This initiated a successful \nre-scale event, as shown by the HPA ",
    "start": "553454",
    "end": "556625"
  },
  {
    "text": "size increasing from one to two.",
    "start": "556625",
    "end": "558549"
  },
  {
    "text": "Let's also view the pods.",
    "start": "559006",
    "end": "560256"
  },
  {
    "text": "There are now two \"downstream zero\"\npods in \"running\" status, confirming ",
    "start": "562260",
    "end": "565951"
  },
  {
    "text": "that KEDA could successfully scale the \napplication using the metrics ingested",
    "start": "565951",
    "end": "569463"
  },
  {
    "text": "into Amazon Managed Service for Prometheus.",
    "start": "569463",
    "end": "571770"
  },
  {
    "text": "We can also confirm this by going to\nthe Amazon Managed Grafana console.",
    "start": "572201",
    "end": "575404"
  },
  {
    "text": "The graph shows that the 20,000-value\nthreshold has been exceeded.",
    "start": "578565",
    "end": "581552"
  },
  {
    "text": "You've just seen how you can use KEDA to \nproactively scale your Kubernetes workloads.",
    "start": "584852",
    "end": "588593"
  },
  {
    "text": "You can learn more about this topic in\nthe description and links for this video.",
    "start": "589638",
    "end": "592694"
  },
  {
    "text": "Thanks for watching.",
    "start": "592924",
    "end": "593830"
  },
  {
    "text": "Now it's your turn to try.",
    "start": "593830",
    "end": "594876"
  }
]
[
  {
    "start": "0",
    "end": "92000"
  },
  {
    "text": "welcome to today's session on uh best practices with Amazon Aurora uh just a bit of clarification we",
    "start": "799",
    "end": "8080"
  },
  {
    "text": "are only going to be talking about Amazon Aurora for MySQL when we were actually planning this talk we had no",
    "start": "8080",
    "end": "14599"
  },
  {
    "text": "idea that we were going to release Amazon Aurora for post rest today so it was a a top secret and even AWS guys",
    "start": "14599",
    "end": "21359"
  },
  {
    "text": "didn't know so everything that we are going to be talking about today uh is about Amazon Aurora for my SQL and we",
    "start": "21359",
    "end": "29199"
  },
  {
    "text": "will just talk about it as Amazon Aurora um and thanks for joining us for",
    "start": "29199",
    "end": "34440"
  },
  {
    "text": "this session I think uh pub crawl just started um so so love your enthusiasm",
    "start": "34440",
    "end": "40000"
  },
  {
    "text": "for for Aurora um so my name is Punit agrawal and I'm a Solutions architect at AWS in",
    "start": "40000",
    "end": "47800"
  },
  {
    "text": "my role I help customers like yourselves uh architect applications on top of AWS",
    "start": "47800",
    "end": "54000"
  },
  {
    "text": "I also help customers adopt Amazon Aurora and other big data platforms with",
    "start": "54000",
    "end": "59359"
  },
  {
    "text": "me today I have uh Steve Abrahim Steve is also a Solutions architect at AWS and",
    "start": "59359",
    "end": "65960"
  },
  {
    "text": "he has uh quite a long background in uh databases and Amazon Aurora and then we",
    "start": "65960",
    "end": "72439"
  },
  {
    "text": "have Mario costell all the way from Ireland joining us today uh to talk",
    "start": "72439",
    "end": "77520"
  },
  {
    "text": "about his orora experience Mario is a product engineer at intercom and well he",
    "start": "77520",
    "end": "83560"
  },
  {
    "text": "just got mered last week so let's give him a round of applause to",
    "start": "83560",
    "end": "88720"
  },
  {
    "text": "congratulated thank thanks for joining us Mar so um we have 60 Minutes of time we",
    "start": "88720",
    "end": "96479"
  },
  {
    "start": "92000",
    "end": "173000"
  },
  {
    "text": "will try to leave some time in the end uh to answer your questions but all of us kind of get excited when talking",
    "start": "96479",
    "end": "102399"
  },
  {
    "text": "about this stuff so if we don't leave any time uh in the end uh please still",
    "start": "102399",
    "end": "108040"
  },
  {
    "text": "we'll be still around so please come up and ask any questions that you have so",
    "start": "108040",
    "end": "113240"
  },
  {
    "text": "the purpose of today's talk is to give you Amazon Aurora best practices this is",
    "start": "113240",
    "end": "118280"
  },
  {
    "text": "a level 300 session so we are going to assume that you already know about Amazon Aurora you're already using",
    "start": "118280",
    "end": "124640"
  },
  {
    "text": "Amazon Aurora and you just want uh to know some of the best practices with Amazon Aurora so we won't spend a lot of",
    "start": "124640",
    "end": "131640"
  },
  {
    "text": "time in giving you a high level overview um I'll basically talk about some of the migration best practices and performance",
    "start": "131640",
    "end": "138319"
  },
  {
    "text": "best practices Steve is going to cover uh some of our Advanced use cases with Amazon Aurora he's going to talk about",
    "start": "138319",
    "end": "145680"
  },
  {
    "text": "realtime reporting and analytics he'll also cover concurrent events stor use case and he'll also talk about how our",
    "start": "145680",
    "end": "153400"
  },
  {
    "text": "customers are integrating Amazon Aurora with other AWS services to create some",
    "start": "153400",
    "end": "158680"
  },
  {
    "text": "really interesting and cool architectures um and then we'll welcome Mario from intercom who will talk about",
    "start": "158680",
    "end": "165560"
  },
  {
    "text": "their journey to Amazon Aurora from my SQL and what types of challenges they faced and how they overcame those",
    "start": "165560",
    "end": "173159"
  },
  {
    "start": "173000",
    "end": "294000"
  },
  {
    "text": "challenges so just to recap very quickly what Amazon Aurora is it's a MySQL",
    "start": "173159",
    "end": "179360"
  },
  {
    "text": "compatible relational database store right now it's compatible with myql 5.6",
    "start": "179360",
    "end": "184560"
  },
  {
    "text": "it offers performance and availability of commercial database engines you can",
    "start": "184560",
    "end": "189959"
  },
  {
    "text": "do about 600,000 reads per second you can do about 100,000 writes per second",
    "start": "189959",
    "end": "195280"
  },
  {
    "text": "with R38 extra large box um and it offers you this performance at",
    "start": "195280",
    "end": "201360"
  },
  {
    "text": "Simplicity and cost effectiveness of Open Source database engines um if you watch the keynote",
    "start": "201360",
    "end": "208599"
  },
  {
    "text": "today morning you prob probably heard uh that we have 70 services and AWS is growing really fast Amazon Aurora has",
    "start": "208599",
    "end": "216720"
  },
  {
    "text": "been our fastest growing service um for quite a few months now so and that's really because it is",
    "start": "216720",
    "end": "224360"
  },
  {
    "text": "delivered as a managed service there are no contracts to sign if you want to Enterprise class database uh you get",
    "start": "224360",
    "end": "230239"
  },
  {
    "text": "your first database in less than 10 minutes uh you pay as you go standard AWS",
    "start": "230239",
    "end": "235280"
  },
  {
    "text": "stuff uh so we see white customer adoption for this in fact",
    "start": "235280",
    "end": "240360"
  },
  {
    "text": "top head top 100 AWS customers out of that 23 of them are using Amazon Aurora",
    "start": "240360",
    "end": "246599"
  },
  {
    "text": "right now so so very popular database across",
    "start": "246599",
    "end": "251680"
  },
  {
    "text": "AWS so when it comes to Aurora and best practices we don't really see a lot of",
    "start": "251680",
    "end": "257560"
  },
  {
    "text": "questions from our customers around well how should we use the database it's Aurora is pretty simple to use it's msql",
    "start": "257560",
    "end": "264400"
  },
  {
    "text": "compatible uh and it just works for most of the customers the only time we C questions",
    "start": "264400",
    "end": "270840"
  },
  {
    "text": "coming from customers is well the first category is they want to understand how do they migrate to Aurora right so so",
    "start": "270840",
    "end": "277440"
  },
  {
    "text": "they want some guidance there and when it comes to Performance they want to know how they should architect their",
    "start": "277440",
    "end": "284160"
  },
  {
    "text": "applications to get most out of Aurora database so I'll briefly cover uh those",
    "start": "284160",
    "end": "289960"
  },
  {
    "text": "two points so let's talk about migrations first the choice of migration tool is",
    "start": "289960",
    "end": "298199"
  },
  {
    "start": "294000",
    "end": "365000"
  },
  {
    "text": "very critical when you're moving to aora or when you're moving to any other database right um the choice of the",
    "start": "298199",
    "end": "305039"
  },
  {
    "text": "tools will decide how much time does it take for you to migrate to Amazon Aurora and how successful your migration",
    "start": "305039",
    "end": "311639"
  },
  {
    "text": "project is how much work you have to do in order to do that migration so for example you could be migrating from RDS",
    "start": "311639",
    "end": "319319"
  },
  {
    "text": "MySQL there are bunch of tools to help you with that you could be migrating from uh MySQL or Maria DB or any other",
    "start": "319319",
    "end": "328080"
  },
  {
    "text": "um MySQL compatible databases from ec2 or from your own data centers to Aurora",
    "start": "328080",
    "end": "334080"
  },
  {
    "text": "and we have another set of tools for that to help you with it um you could be migrating from Oracle or SQL Server to",
    "start": "334080",
    "end": "340680"
  },
  {
    "text": "aora which we see with lot of customers and we have other set of services that",
    "start": "340680",
    "end": "345759"
  },
  {
    "text": "help you with that outside these Services you could still use native MySQL tools for migrations or you could",
    "start": "345759",
    "end": "353280"
  },
  {
    "text": "still do manual migration or you could still use third party tools so this is not an exhaustive list of your options",
    "start": "353280",
    "end": "360720"
  },
  {
    "text": "but these are the options we think help our customers in successful migrations",
    "start": "360720",
    "end": "366160"
  },
  {
    "start": "365000",
    "end": "444000"
  },
  {
    "text": "so let's talk about these options U quickly if you are an RDS MySQL customer",
    "start": "366160",
    "end": "373240"
  },
  {
    "text": "the best and easiest way for you to adopt Amazon Aurora is uh you can use",
    "start": "373240",
    "end": "380360"
  },
  {
    "text": "database snapshot migration process so what you do in this process is you just",
    "start": "380360",
    "end": "385479"
  },
  {
    "text": "take a snapshot of your RDS mySQL database and then you click a but Buton and convert that snapshot into Amazon",
    "start": "385479",
    "end": "392319"
  },
  {
    "text": "Aurora cluster right so the only thing you had to do you probably probably already had a snapshot because you take",
    "start": "392319",
    "end": "398639"
  },
  {
    "text": "backups everybody's a good citizen um and uh you just click a button and you create a new",
    "start": "398639",
    "end": "404960"
  },
  {
    "text": "cluster now if you wanted to uh do a near zero downtime migration you can",
    "start": "404960",
    "end": "411280"
  },
  {
    "text": "also set up bin log replication from your Source database to the Target database and that's something that our",
    "start": "411280",
    "end": "417080"
  },
  {
    "text": "customers do right now by hand in next two weeks we will have a",
    "start": "417080",
    "end": "422520"
  },
  {
    "text": "functionality that will let you set up that bin log replication automatically",
    "start": "422520",
    "end": "428000"
  },
  {
    "text": "by a click off button so by a click off button you were able to migrate before",
    "start": "428000",
    "end": "433440"
  },
  {
    "text": "but now if you wanted to set up a bin log replication stream from your source to Target database you would be able to",
    "start": "433440",
    "end": "438479"
  },
  {
    "text": "do that automatically uh and I think we're launching that feature in second week of",
    "start": "438479",
    "end": "444560"
  },
  {
    "start": "444000",
    "end": "664000"
  },
  {
    "text": "December so let's say now you're running your MySQL databases on ec2 or in your",
    "start": "444960",
    "end": "451120"
  },
  {
    "text": "own data centers what our customers traditionally did in this case was they used Native",
    "start": "451120",
    "end": "457319"
  },
  {
    "text": "myql tools so they used uh MySQL dump MySQL loader MySQL dumper and other",
    "start": "457319",
    "end": "463800"
  },
  {
    "text": "third party tools but what they saw was if their Source database was big like",
    "start": "463800",
    "end": "469479"
  },
  {
    "text": "more than 1 terabyte uh the migration time is significant so they asked us to",
    "start": "469479",
    "end": "475280"
  },
  {
    "text": "come up with some ways to speed up that migration what we really couple of months ago was binary snapshot ingestion",
    "start": "475280",
    "end": "483400"
  },
  {
    "text": "feature for Amazon Aurora so what you do in this feature is you install perona's",
    "start": "483400",
    "end": "489400"
  },
  {
    "text": "extra backup utility on your Source database ec2 or data center you run a backup of your data",
    "start": "489400",
    "end": "497159"
  },
  {
    "text": "files right IB data zero or what however you name your files uh it will take a",
    "start": "497159",
    "end": "503159"
  },
  {
    "text": "backup of your of your data files you upload that backup to Amazon S3 and then",
    "start": "503159",
    "end": "508720"
  },
  {
    "text": "you restore your database from that backup and it's significantly faster than MySQL dub for example because it is",
    "start": "508720",
    "end": "515719"
  },
  {
    "text": "not really replaying all of your ddl statements on Aurora so I'll give you a",
    "start": "515719",
    "end": "521479"
  },
  {
    "text": "quick demo of this I think the font may not be",
    "start": "521479",
    "end": "528200"
  },
  {
    "text": "readable so just bear with me um what I'm doing here is I have a RDS I have a",
    "start": "528200",
    "end": "534760"
  },
  {
    "text": "mySQL database on ec2 I'm creating a database in it",
    "start": "534760",
    "end": "540000"
  },
  {
    "text": "I already have uh Bin log enabled so I just created a",
    "start": "540000",
    "end": "545160"
  },
  {
    "text": "database now I will download perona's extra backup",
    "start": "545160",
    "end": "550399"
  },
  {
    "text": "utility so right now I'm installing the",
    "start": "550399",
    "end": "554560"
  },
  {
    "text": "repo I'm installing the utility uh perona extra backup and now I run the",
    "start": "557360",
    "end": "563480"
  },
  {
    "text": "backup command to actually take the backup of my mySQL database",
    "start": "563480",
    "end": "569760"
  },
  {
    "text": "and now I upload that back up to S3 so I'm just doing it from command",
    "start": "573959",
    "end": "579959"
  },
  {
    "text": "line it is at S3 now so I go back to my console I click a button restore Aurora",
    "start": "580320",
    "end": "586959"
  },
  {
    "text": "DB from S3 on the next page I specified The Source version so right now this utility",
    "start": "586959",
    "end": "594160"
  },
  {
    "text": "uh supports Source database 5.5 and 5.6 as select the S3",
    "start": "594160",
    "end": "600760"
  },
  {
    "text": "location I specify an IM role so that Aurora can access that S3 location and",
    "start": "600760",
    "end": "606920"
  },
  {
    "text": "then rest a standard right you just specify database identifier Master username and password um you specify",
    "start": "606920",
    "end": "614920"
  },
  {
    "text": "your VPC uh security",
    "start": "614920",
    "end": "618839"
  },
  {
    "text": "groups database name port and other settings and then you hit next it will",
    "start": "621440",
    "end": "627839"
  },
  {
    "text": "create your database it will restore your database from S3 um of course the restore time will depend on the size of",
    "start": "627839",
    "end": "634279"
  },
  {
    "text": "your database but it is significantly faster than uh than native MySQL tools",
    "start": "634279",
    "end": "639680"
  },
  {
    "text": "so if you're looking to do a migration like this definitely use uh perona extra backup and this uh binary snapshot",
    "start": "639680",
    "end": "647360"
  },
  {
    "text": "inje if you wanted so now database is being created and you could still do",
    "start": "647360",
    "end": "653800"
  },
  {
    "text": "replication from your Source database to Target database right after a database has been created you can start log",
    "start": "653800",
    "end": "659680"
  },
  {
    "text": "replication and uh you can still do zero downtime",
    "start": "659680",
    "end": "664680"
  },
  {
    "start": "664000",
    "end": "728000"
  },
  {
    "text": "migration couple of best practices with this method use file splitting and",
    "start": "664720",
    "end": "671120"
  },
  {
    "text": "compression if your Source database is Big um the compression format supported",
    "start": "671120",
    "end": "676519"
  },
  {
    "text": "by this tool is gzip and perona XB stream uh there's a sample command on",
    "start": "676519",
    "end": "681760"
  },
  {
    "text": "how to split that backup and how to Gip it one thing that is important to note",
    "start": "681760",
    "end": "687680"
  },
  {
    "text": "with this method is this method will move your schema and your data but it won't move your user accounts functions",
    "start": "687680",
    "end": "694880"
  },
  {
    "text": "and stored procedures automatically so that's something that you will still need to export yourself and and import",
    "start": "694880",
    "end": "701320"
  },
  {
    "text": "into your mySQL database which doesn't really take much time right maybe 5 minutes so that was about moving from",
    "start": "701320",
    "end": "709320"
  },
  {
    "text": "MySQL compatible databases to Amazon orora what if you wanted to move from",
    "start": "709320",
    "end": "714880"
  },
  {
    "text": "Oracle or SQL Server to Amazon orora how does that look like how many of you have",
    "start": "714880",
    "end": "720440"
  },
  {
    "text": "done crossplatform migrations before so quite a few people and so you",
    "start": "720440",
    "end": "726279"
  },
  {
    "text": "know it's not a simple process right there are essentially two things that you need to do the first thing is you",
    "start": "726279",
    "end": "732880"
  },
  {
    "start": "728000",
    "end": "873000"
  },
  {
    "text": "need to convert your schema from The Source database to the Target database and that's where most of the work is",
    "start": "732880",
    "end": "738800"
  },
  {
    "text": "involved right many man days months and hours you spend in optimizing your schema and the second part is once you",
    "start": "738800",
    "end": "746320"
  },
  {
    "text": "have moved your schema over you have to restore your data from your Source database to your target database right",
    "start": "746320",
    "end": "752519"
  },
  {
    "text": "so the two steps so of course you can use native tools to do it or third party tools to",
    "start": "752519",
    "end": "759199"
  },
  {
    "text": "do it uh we see a lot of customers who do this manually uhu which has been done traditionally or you can use couple of",
    "start": "759199",
    "end": "765560"
  },
  {
    "text": "utilities couple of services that we we make available for you so the first one",
    "start": "765560",
    "end": "771120"
  },
  {
    "text": "is AWS schema conversion tool this tool connects to your Source database it will",
    "start": "771120",
    "end": "776279"
  },
  {
    "text": "connect to your target Aurora database and it will automatically convert your schema um I'll give you a demo of that",
    "start": "776279",
    "end": "782680"
  },
  {
    "text": "so I'll explain more and the second service is AWS database migration",
    "start": "782680",
    "end": "787920"
  },
  {
    "text": "service and this is a really cool service for what it does this service can copy your data",
    "start": "787920",
    "end": "796560"
  },
  {
    "text": "from your Source database let's say it's an Oracle database and it can apply that data restore that data into your target",
    "start": "796560",
    "end": "803760"
  },
  {
    "text": "database which could be Aurora or postgress database so it will take care of all the",
    "start": "803760",
    "end": "810120"
  },
  {
    "text": "data type conversions and everything right you could do table level copy there are a bunch of options",
    "start": "810120",
    "end": "815839"
  },
  {
    "text": "there the interesting thing is this tool can also do live replication from your",
    "start": "815839",
    "end": "822199"
  },
  {
    "text": "Source database to the Target database so let's say I'm an oracle user and I'm running Oracle in production if you tell",
    "start": "822199",
    "end": "828600"
  },
  {
    "text": "me to use Aurora I'll say that I I'll really need to test it for at least a month right so what I want to do in that",
    "start": "828600",
    "end": "835920"
  },
  {
    "text": "case is I let my uh production database uh running on Oracle I'll do this",
    "start": "835920",
    "end": "841120"
  },
  {
    "text": "migration I'll set up replication from Oracle to Aurora and then I'll test Aurora in parallel right so I'm testing",
    "start": "841120",
    "end": "848600"
  },
  {
    "text": "my database on live data on latest data and after a month if I feel comfortable",
    "start": "848600",
    "end": "854440"
  },
  {
    "text": "I can just stop the application and point my applications to Amazon Aurora of course your application may need to",
    "start": "854440",
    "end": "860320"
  },
  {
    "text": "change because you're changing your database platform but this tools makes it really easy for you to do this um if",
    "start": "860320",
    "end": "866720"
  },
  {
    "text": "you're interested in these tools uh there is a deep dive talk tomorrow on this so definitely check that",
    "start": "866720",
    "end": "873240"
  },
  {
    "start": "873000",
    "end": "1076000"
  },
  {
    "text": "out so let's do a quick demo of uh schema conversion tool how does that",
    "start": "873240",
    "end": "880040"
  },
  {
    "text": "look so I have an aurora and Oracle database in my console I will just show you that I have",
    "start": "880040",
    "end": "887920"
  },
  {
    "text": "a DMS sample schema in my Oracle database which is about 8 gig in",
    "start": "887920",
    "end": "894240"
  },
  {
    "text": "size and then I'll connect to my Aurora database to show you that that I don't",
    "start": "894240",
    "end": "899440"
  },
  {
    "text": "have that DMS sample schema right now in my database I opened schema conversion tool",
    "start": "899440",
    "end": "905880"
  },
  {
    "text": "which is a desktop utility it's a free utility there are no charges for it I connect to my source Oracle",
    "start": "905880",
    "end": "913759"
  },
  {
    "text": "database so I specify my username and password of course your desktop needs to be able to connect to your Source",
    "start": "913759",
    "end": "919839"
  },
  {
    "text": "database and it could be anywhere it could be uh in your data center or on ec2 it could be",
    "start": "919839",
    "end": "925480"
  },
  {
    "text": "anywhere I'm testing the connection",
    "start": "925480",
    "end": "930160"
  },
  {
    "text": "I hit next and when I do that the tool looks into the Oracle database looks at",
    "start": "933920",
    "end": "939680"
  },
  {
    "text": "all the schemas I will select the schema that I want to migrate to",
    "start": "939680",
    "end": "944839"
  },
  {
    "text": "Aurora and then it goes through all the database objects in the source Oracle",
    "start": "944839",
    "end": "949920"
  },
  {
    "text": "database and figures out how well it can convert those things into Amazon orora",
    "start": "949920",
    "end": "957720"
  },
  {
    "text": "so this thing takes about 2 minutes um and this is uh it really depends on how many objects you have but 2 to 5 minutes",
    "start": "959680",
    "end": "967079"
  },
  {
    "text": "maximum now this is really important this tool will give you a complete report of how well it will do when it",
    "start": "967079",
    "end": "974680"
  },
  {
    "text": "migrates your code or converts your code so this report you can save it um this",
    "start": "974680",
    "end": "981079"
  },
  {
    "text": "says that it can uh convert all your tables but you will still need to make certain changes for your sto",
    "start": "981079",
    "end": "987199"
  },
  {
    "text": "procedures so now I can connect to Amazon Aurora database I see Amazon Aurora database to",
    "start": "987199",
    "end": "993880"
  },
  {
    "text": "my right and Oracle to the left I can convert that schema",
    "start": "993880",
    "end": "1002399"
  },
  {
    "text": "now and when it converts the schema it will tell me at what places exactly it",
    "start": "1005120",
    "end": "1011600"
  },
  {
    "text": "wasn't able to convert the schema automatically because of course Oracle and MySQL has different features so for",
    "start": "1011600",
    "end": "1018079"
  },
  {
    "text": "this stor procedure it is telling me that it doesn't support Amazon orora doesn't support user types uh so you",
    "start": "1018079",
    "end": "1024918"
  },
  {
    "text": "directly know that this is what you need to do before you can migrate your schema",
    "start": "1024919",
    "end": "1030280"
  },
  {
    "text": "so well let's say I've done that and I apply the schema now I have transferred my schema to Amazon Aurora and if I look",
    "start": "1030280",
    "end": "1038959"
  },
  {
    "text": "at the databases to Amazon Aurora I see DMS sample",
    "start": "1038959",
    "end": "1044199"
  },
  {
    "text": "database and if I list all the tables",
    "start": "1044199",
    "end": "1049360"
  },
  {
    "text": "I will see all the tables from from from that Source Oracle database um so of course it's not very",
    "start": "1049360",
    "end": "1056640"
  },
  {
    "text": "straightforward uh in terms of moving from you know oracle or SQL Server to Amazon Aurora as it is when you move",
    "start": "1056640",
    "end": "1063200"
  },
  {
    "text": "from MySQL to Amazon Aurora but this tool goes a long way in helping you",
    "start": "1063200",
    "end": "1069440"
  },
  {
    "text": "decide if uh how much time it will take you to move to Amazon or AA so very helpful for our",
    "start": "1069440",
    "end": "1076559"
  },
  {
    "start": "1076000",
    "end": "1193000"
  },
  {
    "text": "customers some of the other migration best practices um use the right migration approach this will go a long",
    "start": "1076559",
    "end": "1083440"
  },
  {
    "text": "way uh we still see a lot of customers using uh you know native MySQL tools or",
    "start": "1083440",
    "end": "1089039"
  },
  {
    "text": "other tools start with these tools the recommended tools and see if that works for",
    "start": "1089039",
    "end": "1094600"
  },
  {
    "text": "you you will be surprised uh how many customers we see who do not test their",
    "start": "1094600",
    "end": "1100320"
  },
  {
    "text": "migration process we see a lot of customers just migrating their production databases right away uh and",
    "start": "1100320",
    "end": "1105720"
  },
  {
    "text": "then they would have issues and they'll open the tickets and all that so uh it's great we are happy to help our customers",
    "start": "1105720",
    "end": "1111640"
  },
  {
    "text": "but uh do migration and and do testing off your migration process before you",
    "start": "1111640",
    "end": "1118240"
  },
  {
    "text": "actually do production migration another best practice is you can consolidate your shards on Amazon",
    "start": "1118240",
    "end": "1124840"
  },
  {
    "text": "Aurora how many of you are running my SQL with multiple shards so few people since Aurora has a",
    "start": "1124840",
    "end": "1133640"
  },
  {
    "text": "better scalability performance you know the the the number of uh it's for up to",
    "start": "1133640",
    "end": "1139159"
  },
  {
    "text": "64 tab of storage it really allows you to consolidate multiple shards on a",
    "start": "1139159",
    "end": "1144480"
  },
  {
    "text": "single instance or you can consolidate multiple smaller database on an aurora instance um of course that improves your",
    "start": "1144480",
    "end": "1151400"
  },
  {
    "text": "application logic uh you don't have to manage multiple servers so on and so",
    "start": "1151400",
    "end": "1156799"
  },
  {
    "text": "forth when you're doing schema conversion after the conversion look at",
    "start": "1156799",
    "end": "1162120"
  },
  {
    "text": "your target schema and see if that schema needs further optimization there are a couple of uh use cases where you",
    "start": "1162120",
    "end": "1169200"
  },
  {
    "text": "may want to look at that schema and make some changes for example if you had any tables in the source database with the",
    "start": "1169200",
    "end": "1175960"
  },
  {
    "text": "longer columns uh you may have to choose Dynamic row format on on Aurora um the",
    "start": "1175960",
    "end": "1181960"
  },
  {
    "text": "way primary key is implemented in in my SQL and Aurora is a little bit different than Oracle and SQL Server so you may",
    "start": "1181960",
    "end": "1188640"
  },
  {
    "text": "have to look into that as well so that's why testing is really important uh let's talk about",
    "start": "1188640",
    "end": "1196360"
  },
  {
    "start": "1193000",
    "end": "1300000"
  },
  {
    "text": "performance best practices in order to get better performance out of your database uh especially Amazon",
    "start": "1196360",
    "end": "1203960"
  },
  {
    "text": "Aurora you really need to understand what it is designed for what are its performance",
    "start": "1203960",
    "end": "1209440"
  },
  {
    "text": "characteristics so Aurora is designed for highly concurrent Random Access oltp",
    "start": "1209440",
    "end": "1216919"
  },
  {
    "text": "workloads as you increase the number of connections uh your performance should scale with number of connections so you",
    "start": "1216919",
    "end": "1223240"
  },
  {
    "text": "can throw hundreds and thousands of connections to Amazon Aurora the performance remains consist consent as",
    "start": "1223240",
    "end": "1229400"
  },
  {
    "text": "you increase the number of tables you increase the number of databases as you increase your data",
    "start": "1229400",
    "end": "1234559"
  },
  {
    "text": "set the performance also remains consistent when you increase the number of Aurora read replicas and these are",
    "start": "1234559",
    "end": "1241080"
  },
  {
    "text": "some of the counterintuitive things if you're coming from my SQL right in my SQL when you increase these things",
    "start": "1241080",
    "end": "1246840"
  },
  {
    "text": "performance usually degrades and Aurora offers really low replication lag almost",
    "start": "1246840",
    "end": "1252640"
  },
  {
    "text": "negligible so you can actually utilize your read replicas for your read workloads",
    "start": "1252640",
    "end": "1258760"
  },
  {
    "text": "so customers ask us well how should we performance test uh aora database we",
    "start": "1258760",
    "end": "1264559"
  },
  {
    "text": "have a white paper on this topic the basic advice here is don't use just one",
    "start": "1264559",
    "end": "1270200"
  },
  {
    "text": "client machine use multiple CL client machines open hundreds and thousands of connections uh from those machines uh",
    "start": "1270200",
    "end": "1277240"
  },
  {
    "text": "use enhanced networking make sure that you have good Linux kernel parameters and then you can run your synthetic",
    "start": "1277240",
    "end": "1282799"
  },
  {
    "text": "benchmarks right sis bench or or anything else but this also gives you a very good idea of",
    "start": "1282799",
    "end": "1289080"
  },
  {
    "text": "how you should configure your applications to talk to Aurora to get best performance out of the database so",
    "start": "1289080",
    "end": "1295000"
  },
  {
    "text": "I would recommend looking at this white paper and and going through some of the best practices",
    "start": "1295000",
    "end": "1300440"
  },
  {
    "start": "1300000",
    "end": "1486000"
  },
  {
    "text": "there now some general performance best practices since Aurora is my SQL",
    "start": "1300440",
    "end": "1306559"
  },
  {
    "text": "compatible U and uh it's delivered as a managed service you don't really have to do a lot to get best performance out of",
    "start": "1306559",
    "end": "1313480"
  },
  {
    "text": "the database General database best practices still apply you still want to create good index es you still want to",
    "start": "1313480",
    "end": "1319880"
  },
  {
    "text": "run explain plans you still want to use performance schema all that stuff is still",
    "start": "1319880",
    "end": "1325559"
  },
  {
    "text": "there the important thing is you should leverage High concurrency with Aurora if",
    "start": "1325559",
    "end": "1332760"
  },
  {
    "text": "your application opens 10 connections to the Aurora database you won't really unleash the the power of the engine if",
    "start": "1332760",
    "end": "1339679"
  },
  {
    "text": "you have an opportunity to change your applications or re architect your applications a little bit to open",
    "start": "1339679",
    "end": "1346159"
  },
  {
    "text": "hundreds and thousands of connections and you know increase the total throughput of your application that's",
    "start": "1346159",
    "end": "1351360"
  },
  {
    "text": "when you will see huge performance improvements over my SQL in Amazon Aurora so so that's probably one of the",
    "start": "1351360",
    "end": "1358039"
  },
  {
    "text": "most important points uh in getting the best performance out of Aurora read scaling we already talked",
    "start": "1358039",
    "end": "1364279"
  },
  {
    "text": "about it almost negligible replication lag you don't have to overload your master databases uh with all your read",
    "start": "1364279",
    "end": "1371159"
  },
  {
    "text": "queries you can use uh read replicas for your read workloads parameter tuning this is",
    "start": "1371159",
    "end": "1378039"
  },
  {
    "text": "interesting thing so a lot of customers and this is intuitive right if you're moving from MySQL to Aurora you would",
    "start": "1378039",
    "end": "1384840"
  },
  {
    "text": "want to move your configuration parameters from RDS M SQL to Aurora Our advice is try not to do that",
    "start": "1384840",
    "end": "1393000"
  },
  {
    "text": "some of the configuration parameters have different context in Aurora and some of the configuration parameters do",
    "start": "1393000",
    "end": "1399120"
  },
  {
    "text": "not even apply in Aurora and that's because of the engine layer changes and the infrastructure layer changes that we",
    "start": "1399120",
    "end": "1405240"
  },
  {
    "text": "have done uh in Aurora so when you start an aurora database use the default",
    "start": "1405240",
    "end": "1412120"
  },
  {
    "text": "parameters and chances are you won't have to change those parameters of course you can enable and disable",
    "start": "1412120",
    "end": "1417480"
  },
  {
    "text": "certain features like bin log and all that using those parameters but try not to change the performance related",
    "start": "1417480",
    "end": "1423159"
  },
  {
    "text": "parameters too much when you are doing performance comparison try not to look at CPU memory",
    "start": "1423159",
    "end": "1431640"
  },
  {
    "text": "iops don't try to look at the system level metrics when you're comparing performance between MySQL and Aurora RDS",
    "start": "1431640",
    "end": "1438760"
  },
  {
    "text": "MySQL and Aurora or MySQL on ec2 and Aurora focus on what really matters to",
    "start": "1438760",
    "end": "1445000"
  },
  {
    "text": "the application so take a look at transactions per second U think about selects per second how many ddl and DML",
    "start": "1445000",
    "end": "1451600"
  },
  {
    "text": "statements are going in per second and you can do that you can take a look at those metrics using using cloudwatch it",
    "start": "1451600",
    "end": "1458080"
  },
  {
    "text": "gives you very good visibility into both system and database level metrics uh another best practice I will",
    "start": "1458080",
    "end": "1464960"
  },
  {
    "text": "mention keep query cache on uh we have redesigned the query cache in Aurora so",
    "start": "1464960",
    "end": "1471200"
  },
  {
    "text": "it works really really well as compared to my SQL so most customers keep their query cache on uh with Amazon Aurora but",
    "start": "1471200",
    "end": "1479520"
  },
  {
    "text": "outside of these best practices uh if you have highly concurrent workload Aurora should just should should just",
    "start": "1479520",
    "end": "1485240"
  },
  {
    "text": "work for you with that let me hand it over to Steve uh who will talk about some of the advanced use cases with",
    "start": "1485240",
    "end": "1491919"
  },
  {
    "start": "1486000",
    "end": "1799000"
  },
  {
    "text": "Amazon or all right",
    "start": "1491919",
    "end": "1498880"
  },
  {
    "text": "well thank you Pan um so like pan said we're going to get into some of the actual use cases and best practices",
    "start": "1498880",
    "end": "1505880"
  },
  {
    "text": "around use cases using Amazon Aurora so I'd like to start with the scenario we have a customer this is an",
    "start": "1505880",
    "end": "1513200"
  },
  {
    "text": "actual customer uh that we've worked with it's a travel and booking industry customer uh what they need is live",
    "start": "1513200",
    "end": "1520200"
  },
  {
    "text": "contextual product recommendations they need things like you know uh recent Airline airfare hotel prices things like",
    "start": "1520200",
    "end": "1528080"
  },
  {
    "text": "that they need to be able to deliver that in close to real time to their customers uh we also have users that are",
    "start": "1528080",
    "end": "1534919"
  },
  {
    "text": "on the other side analyst people that need to run reports and are interested in also getting this real-time",
    "start": "1534919",
    "end": "1541039"
  },
  {
    "text": "information as well they've got about 700 plus users internally in addition to the users that are out on the internet",
    "start": "1541039",
    "end": "1547760"
  },
  {
    "text": "that are hitting this database over and over again we have about an 8 terabyte data set and then another thing that's",
    "start": "1547760",
    "end": "1554880"
  },
  {
    "text": "interesting to note is that the usage Cycles over a 24-hour period so you know",
    "start": "1554880",
    "end": "1560080"
  },
  {
    "text": "people are at work during the day and that's when the analysts are there these 700 people that are running reports uh",
    "start": "1560080",
    "end": "1566000"
  },
  {
    "text": "there's usually a higher number of people that are shopping and engaged during the day and then we also want to",
    "start": "1566000",
    "end": "1572279"
  },
  {
    "text": "take into consideration the cost I mean cost is something that always applies um",
    "start": "1572279",
    "end": "1577520"
  },
  {
    "text": "that in being able to maximize the efficiency of the resources that we use enables us to save a lot of the cost so",
    "start": "1577520",
    "end": "1585480"
  },
  {
    "text": "this is the original design it's a pretty common thing that you would see anywhere else",
    "start": "1585480",
    "end": "1590520"
  },
  {
    "text": "where we have a storage back end with a database engine in front of it you can see we have our application users here",
    "start": "1590520",
    "end": "1596440"
  },
  {
    "text": "and everything's going well and they're running the reports and people are looking up Airline airfare airfare",
    "start": "1596440",
    "end": "1602799"
  },
  {
    "text": "online Etc and then what happens is that when more people come online that we",
    "start": "1602799",
    "end": "1609200"
  },
  {
    "text": "actually see that the you know we start to you know overwhelm the database engine and so the database engine itself",
    "start": "1609200",
    "end": "1616840"
  },
  {
    "text": "has difficulty sometimes keep keeping up and likewise when those people leave when they go home then we still have",
    "start": "1616840",
    "end": "1624440"
  },
  {
    "text": "this provisioned database infrastructure that no one is using and it's sitting idle so in that we have wasted cost so",
    "start": "1624440",
    "end": "1632520"
  },
  {
    "text": "then what we do is we introduce Amazon Aurora and Aurora clusters and so in this scenario what we've done is we've",
    "start": "1632520",
    "end": "1639000"
  },
  {
    "text": "replaced this with a DNS endpoint that's load balanced and pun touched on this earlier in that you can specify a single",
    "start": "1639000",
    "end": "1646480"
  },
  {
    "text": "DNS endpoint for your read replicas and with Aurora you can have up to 15 Read",
    "start": "1646480",
    "end": "1651559"
  },
  {
    "text": "replicas behind that and so it does load balancing you can think of it as something similar to but not the same",
    "start": "1651559",
    "end": "1657720"
  },
  {
    "text": "thing as an elastic load balancer in that it's a load balancer for your read-based queries you still have a",
    "start": "1657720",
    "end": "1664039"
  },
  {
    "text": "single read write uh input for you know writing data to the database but when we're talking about our analysts that",
    "start": "1664039",
    "end": "1670640"
  },
  {
    "text": "want to run these queries against the database throughout the day then that gives us an opportunity to do that so as",
    "start": "1670640",
    "end": "1678559"
  },
  {
    "text": "we are working with our analysts and as our traffic increases so they come online and so then what do we need to do",
    "start": "1678559",
    "end": "1685919"
  },
  {
    "text": "from there we need to scale up and so we can add additional read replicas behind",
    "start": "1685919",
    "end": "1691039"
  },
  {
    "text": "that read only endpoint and how do you do that you could do it manually or you could use cloud watch and with Cloud",
    "start": "1691039",
    "end": "1698320"
  },
  {
    "text": "watch you could automatically trigger the addition of these additional read",
    "start": "1698320",
    "end": "1703600"
  },
  {
    "text": "replicas something that's unique and I think very powerful about a Aurora is",
    "start": "1703600",
    "end": "1708640"
  },
  {
    "text": "given the Aurora storage engine is one shared storage engine that spans the entire region when you bring on a read",
    "start": "1708640",
    "end": "1715080"
  },
  {
    "text": "replica you're just adding a compute head to already existing storage that storage is the same you don't have to",
    "start": "1715080",
    "end": "1721640"
  },
  {
    "text": "replicate an additional copy of that data it is the same data that's been replicated into six different locations",
    "start": "1721640",
    "end": "1728720"
  },
  {
    "text": "across three different availability zones so that gives you a great deal of read scalability and then with this DNS",
    "start": "1728720",
    "end": "1736240"
  },
  {
    "text": "endpoint that does the load balancing for you it allows you to simplify your",
    "start": "1736240",
    "end": "1741399"
  },
  {
    "text": "code by having your application always hit that same end point so now when those users go home then what we can do",
    "start": "1741399",
    "end": "1749159"
  },
  {
    "text": "is we can scale down our Aurora cluster and save money during the off hours and so that means that that line between",
    "start": "1749159",
    "end": "1756279"
  },
  {
    "text": "resource allocation and resource consumption that we are so familiar with becomes much more closely matched with",
    "start": "1756279",
    "end": "1763480"
  },
  {
    "text": "fewer gaps in between so this is generally how this",
    "start": "1763480",
    "end": "1769039"
  },
  {
    "text": "how you would implement this is with this Fleet scaling as I just kind of described so you can either use a",
    "start": "1769039",
    "end": "1774519"
  },
  {
    "text": "scheduled job that reads the instance load metrics and calls Lambda or you can create an alert perhaps uh but like I",
    "start": "1774519",
    "end": "1782399"
  },
  {
    "text": "said just tying back into Cloud watch and monitoring you know the load that's on your Aurora instances and those",
    "start": "1782399",
    "end": "1789159"
  },
  {
    "text": "additional instances are added or removed and then our desired scale is achieved and you can see that the the",
    "start": "1789159",
    "end": "1796080"
  },
  {
    "text": "allocation and the consumption lines are very closely matched so moving on from there let's",
    "start": "1796080",
    "end": "1802039"
  },
  {
    "start": "1799000",
    "end": "2001000"
  },
  {
    "text": "take a look at massively concurrent event stores so in this scenario we have",
    "start": "1802039",
    "end": "1807320"
  },
  {
    "text": "a gaming industry customer and this gaming industry customer needs to handle millions of requests per second right so",
    "start": "1807320",
    "end": "1814039"
  },
  {
    "text": "they need to be able to scale very high they need to have consistent latency so whether they have a lot of users online",
    "start": "1814039",
    "end": "1820880"
  },
  {
    "text": "at one time or a few users they need to make sure that they have a consistent gaming experience for their customers",
    "start": "1820880",
    "end": "1826799"
  },
  {
    "text": "and of course they're also concerned with cost as well so traditionally when",
    "start": "1826799",
    "end": "1832840"
  },
  {
    "text": "we're talking about this type of scenario no sequel is where most people's minds go and nosql is a good",
    "start": "1832840",
    "end": "1840760"
  },
  {
    "text": "option it certainly no one will fault you for using nosql and it works very well under you know a moderate or",
    "start": "1840760",
    "end": "1847480"
  },
  {
    "text": "expected load but then what happens sometimes with no SQL is due to the way",
    "start": "1847480",
    "end": "1853679"
  },
  {
    "text": "that no SQL databases are partitioned or sharded you can occasionally get a hot",
    "start": "1853679",
    "end": "1858840"
  },
  {
    "text": "partition and that means that you also have sometimes the cold partitions and in that scenario that can impact the",
    "start": "1858840",
    "end": "1865240"
  },
  {
    "text": "latency of your requests and so you know you can in that specific instance can",
    "start": "1865240",
    "end": "1871240"
  },
  {
    "text": "actually degrade your performance so with Aurora Aurora like Punit was saying",
    "start": "1871240",
    "end": "1876760"
  },
  {
    "text": "is designed to handle massive parallel queries so we're talking about hundreds",
    "start": "1876760",
    "end": "1882200"
  },
  {
    "text": "or thousands of active Connections in upwards of 500,000 selects per second",
    "start": "1882200",
    "end": "1887360"
  },
  {
    "text": "100,000 rights per second so it it can handle you know what traditionally has",
    "start": "1887360",
    "end": "1892720"
  },
  {
    "text": "fallen under the nosql category but one of the nice things about Aurora is that you get consistent performance that you",
    "start": "1892720",
    "end": "1899159"
  },
  {
    "text": "don't have that hot partition issue that you would sometimes have with a nosql",
    "start": "1899159",
    "end": "1905039"
  },
  {
    "text": "database so another thing to consider uh with this is the cost of no SQL so with",
    "start": "1905039",
    "end": "1912880"
  },
  {
    "text": "no SQL uh you generally pay for and provision read and write capacity units",
    "start": "1912880",
    "end": "1919399"
  },
  {
    "text": "when you're when you're talking about that and so that means that every time that you read and write from that nosql data store you are consuming those",
    "start": "1919399",
    "end": "1927919"
  },
  {
    "text": "reads um with Aurora it's a little bit different",
    "start": "1927919",
    "end": "1933200"
  },
  {
    "text": "because Aurora has a couple of things going for it one of them is is that it has a buffer pool it has memory and so",
    "start": "1933200",
    "end": "1940240"
  },
  {
    "text": "it's essentially a cache that's built right into Aurora just like just like many other relational engines and so",
    "start": "1940240",
    "end": "1946919"
  },
  {
    "text": "your queries are not necessarily going to hit the disc when you query Aurora a lot of those queries could be served up",
    "start": "1946919",
    "end": "1952919"
  },
  {
    "text": "directly out of memory and so that reduces the need that you have for disc iio within",
    "start": "1952919",
    "end": "1959279"
  },
  {
    "text": "Aurora another thing about Aurora is that you don't pre-provision storage or",
    "start": "1959279",
    "end": "1965120"
  },
  {
    "text": "storage throughput the storage throughput is delivered to you on an as-needed basis and you're charged for",
    "start": "1965120",
    "end": "1970919"
  },
  {
    "text": "it on an as needed basis so if you have low traffic and you are not consuming",
    "start": "1970919",
    "end": "1976279"
  },
  {
    "text": "very many iops or if the majority of your your requests are being satisfied",
    "start": "1976279",
    "end": "1982679"
  },
  {
    "text": "through uh what's in cash already then you're not paying for or consuming any of those iops and if your load increases",
    "start": "1982679",
    "end": "1990600"
  },
  {
    "text": "and then you do need to go to disk well then you'll pay for it then so it gives you an opportunity to both save on cost",
    "start": "1990600",
    "end": "1997919"
  },
  {
    "text": "and performance when dealing with these massively concurrent workloads so another thing that's unique",
    "start": "1997919",
    "end": "2005519"
  },
  {
    "start": "2001000",
    "end": "2174000"
  },
  {
    "text": "about AWS and Aurora is that that the services a lot of services that we've",
    "start": "2005519",
    "end": "2011120"
  },
  {
    "text": "developed at AWS we build them with the mind that we have this whole AWS",
    "start": "2011120",
    "end": "2016480"
  },
  {
    "text": "ecosystem and we ask ourselves the question how can we integrate with these so that we can provide a better service",
    "start": "2016480",
    "end": "2022600"
  },
  {
    "text": "for our customers so one of those ways as it pertains to Aurora is an an event driven",
    "start": "2022600",
    "end": "2028720"
  },
  {
    "text": "data pipeline so on the left here you can see that we have some AWS services that are generating data maybe those are",
    "start": "2028720",
    "end": "2036000"
  },
  {
    "text": "web servers that are generating log data Maybe it's customer data that you're collecting however you're generating",
    "start": "2036000",
    "end": "2041960"
  },
  {
    "text": "your data it's being generated on the left and then as we move from left to right we have we're putting that data",
    "start": "2041960",
    "end": "2048599"
  },
  {
    "text": "into Amazon S3 which will serve as the basis for our data Lake when that data",
    "start": "2048599",
    "end": "2054440"
  },
  {
    "text": "hits when that file hits S3 then S3 can then fire a Lambda function and that",
    "start": "2054440",
    "end": "2061320"
  },
  {
    "text": "Lambda function that you can see there will then trigger Amazon Aurora to load that data directly from S3 three into",
    "start": "2061320",
    "end": "2068520"
  },
  {
    "text": "Aurora so that means that automatically as data is coming into your data Lake it can be you can automate the loading of",
    "start": "2068520",
    "end": "2076040"
  },
  {
    "text": "that data into S3 and you can also notify any pertinent users anyone that",
    "start": "2076040",
    "end": "2082000"
  },
  {
    "text": "might need to know hey we just got the latest dump of this data Maybe we just got it from a customer maybe it's you",
    "start": "2082000",
    "end": "2088560"
  },
  {
    "text": "know some data that we've been waiting for and so now we know that that's online and that the S3 load has been",
    "start": "2088560",
    "end": "2094919"
  },
  {
    "text": "completed another uh nice feature is the",
    "start": "2094919",
    "end": "2101520"
  },
  {
    "text": "event-driven audit notification so recently it's been a few weeks now uh we",
    "start": "2101520",
    "end": "2106680"
  },
  {
    "text": "announced the integration of AWS Lambda with Amazon Aurora and so what that",
    "start": "2106680",
    "end": "2112880"
  },
  {
    "text": "means is that you can invoke a Lambda function from within the context of SQL statements inside of",
    "start": "2112880",
    "end": "2119680"
  },
  {
    "text": "Aurora so sounds interesting but maybe you'd say why would I use that what",
    "start": "2119680",
    "end": "2125000"
  },
  {
    "text": "would be the use case for that here is an example of one use case for that let's say that you have uh a user modifi",
    "start": "2125000",
    "end": "2132760"
  },
  {
    "text": "you have a monitored table maybe it's an important table because it has application settings in it and you need",
    "start": "2132760",
    "end": "2138839"
  },
  {
    "text": "to be notified if someone changes those application settings maybe in the like",
    "start": "2138839",
    "end": "2144160"
  },
  {
    "text": "in the example that we're going to see in uh the upcoming slides you have a customer review table and you want to",
    "start": "2144160",
    "end": "2150800"
  },
  {
    "text": "know in close to real time you know when customers are leaving you reviews and giving you feedback about uh your your",
    "start": "2150800",
    "end": "2157920"
  },
  {
    "text": "company or your service and so what you can do is you could put a trigger on that table in Amazon Aurora and when",
    "start": "2157920",
    "end": "2165400"
  },
  {
    "text": "that trigger is fired then it can invoke that Lambda function which can then notify you or take any sort of custom",
    "start": "2165400",
    "end": "2174720"
  },
  {
    "start": "2174000",
    "end": "2559000"
  },
  {
    "text": "action so let's take a look at a quick demo here about Lambda integration I'd",
    "start": "2174720",
    "end": "2180520"
  },
  {
    "text": "like to first before we get into the demo describe what the architecture looks like for this demo so on the left",
    "start": "2180520",
    "end": "2186839"
  },
  {
    "text": "we have our Aurora a cluster and then we have our table in that cluster and it's our customer table and we have a trigger",
    "start": "2186839",
    "end": "2193480"
  },
  {
    "text": "on that table when that trigger is fired it's going to call into AWS Lambda right",
    "start": "2193480",
    "end": "2199880"
  },
  {
    "text": "now one thing to note about my SQL and Aurora in general is that the triggers are row based rather than statement",
    "start": "2199880",
    "end": "2206000"
  },
  {
    "text": "based and so that means that it's going to iterate through each one of those rows that change so if you have if you",
    "start": "2206000",
    "end": "2214160"
  },
  {
    "text": "make a change and you update a thousand rows in your t that will translate into a th000 Lambda",
    "start": "2214160",
    "end": "2220319"
  },
  {
    "text": "invocations so I would caution you to just keep that in mind while you're doing this there's nothing necessarily",
    "start": "2220319",
    "end": "2226319"
  },
  {
    "text": "wrong with that but just be aware that that is uh how that works so for us what",
    "start": "2226319",
    "end": "2231960"
  },
  {
    "text": "we want to know is we want to know when a customer leaves us a review in our table we want to be notified but if we",
    "start": "2231960",
    "end": "2238000"
  },
  {
    "text": "have several of them that happen rapidly we don't want to get you know five 10 100 a thousand emails all at once",
    "start": "2238000",
    "end": "2244480"
  },
  {
    "text": "instead we'd rather sort of batch those up and just get periodic emails so what we're going to do is when the trigger",
    "start": "2244480",
    "end": "2250720"
  },
  {
    "text": "fires it will call AWS Lambda which will then put that record into sqs and then",
    "start": "2250720",
    "end": "2256800"
  },
  {
    "text": "down on the parallel track we have Amazon Cloud watch that is scheduling an",
    "start": "2256800",
    "end": "2262480"
  },
  {
    "text": "AWS Lambda function that runs once per minute and then that will go back to sqs",
    "start": "2262480",
    "end": "2268280"
  },
  {
    "text": "grab the batch of those requests that have been put in there and then it will send out a notification via",
    "start": "2268280",
    "end": "2275680"
  },
  {
    "text": "SNS so right here we're going to go ahead and create our SNS Topic in this",
    "start": "2275680",
    "end": "2281119"
  },
  {
    "text": "case we're going to have it create uh it's called Aurora mods is our",
    "start": "2281119",
    "end": "2287400"
  },
  {
    "text": "topic once we have a topic we create subscriptions in this case I'm just going to do an email subscription to my",
    "start": "2287400",
    "end": "2294319"
  },
  {
    "text": "email address but there are different mechanisms you can send it through HTTP you can send SMS messages email but",
    "start": "2294319",
    "end": "2301880"
  },
  {
    "text": "we're just going to do my email address here we're going to wait until I receive that email and confirm the",
    "start": "2301880",
    "end": "2309440"
  },
  {
    "text": "subscription so now I've confirmed it and so you can see there's now a subscription ID that indicates that that",
    "start": "2310440",
    "end": "2316800"
  },
  {
    "text": "is a valid subscription up here we want to take note of this topic earn and",
    "start": "2316800",
    "end": "2322040"
  },
  {
    "text": "we're going to reference this later on in our Lambda function and that's how we know we're going to publish to this",
    "start": "2322040",
    "end": "2327160"
  },
  {
    "text": "particular SNS topic so now that we've created that let's go to",
    "start": "2327160",
    "end": "2334160"
  },
  {
    "text": "sqs we're just going to create a simple queue here here where we're going to queue up those messages you can in this",
    "start": "2334240",
    "end": "2341160"
  },
  {
    "text": "particular use case keep the default",
    "start": "2341160",
    "end": "2344920"
  },
  {
    "text": "settings we'll create the que and here we want to take note of the",
    "start": "2346520",
    "end": "2352920"
  },
  {
    "text": "URL which we will also use in our Lambda function in order to put those messages into that",
    "start": "2352920",
    "end": "2360440"
  },
  {
    "text": "sqsq all right so now we've created our SNS topic a subscriber we've created our",
    "start": "2362280",
    "end": "2368079"
  },
  {
    "text": "sqsq so now let's get into Lambda the first Lambda function we want to create",
    "start": "2368079",
    "end": "2373280"
  },
  {
    "text": "is going to be the one that's going to respond to those trigger events so we'll",
    "start": "2373280",
    "end": "2378520"
  },
  {
    "text": "zoom in a little bit here on the screen so you can read it hopefully and so starting at the top we're just going to",
    "start": "2378520",
    "end": "2384040"
  },
  {
    "text": "do a couple of imports we'll create an S3 client because we're using Bodo 3 with python here and then we're just",
    "start": "2384040",
    "end": "2390560"
  },
  {
    "text": "going to send a message to that URL the sqs URL that we just got from the previous step that's all it is we want",
    "start": "2390560",
    "end": "2397839"
  },
  {
    "text": "to keep this function very lightweight so it can execute quickly and get out of there in return so the next thing we're",
    "start": "2397839",
    "end": "2404480"
  },
  {
    "text": "going to do so we're going to create the second Lambda function and this one is the one that's going to be run on a",
    "start": "2404480",
    "end": "2410520"
  },
  {
    "text": "regular schedule the once per minute schedule so again here we import Bodo 3",
    "start": "2410520",
    "end": "2416119"
  },
  {
    "text": "we create an sqs and an SNS client now we're going to pull the",
    "start": "2416119",
    "end": "2422359"
  },
  {
    "text": "messages out of the sqsq if there are no messages then we'll return turn if there are we'll create a",
    "start": "2422359",
    "end": "2429400"
  },
  {
    "text": "buffer to accumulate the string that we'll be sending in our message we're going to accumulate the messages that we",
    "start": "2429400",
    "end": "2434880"
  },
  {
    "text": "just pulled out of that sqsq and then we're going to publish",
    "start": "2434880",
    "end": "2440319"
  },
  {
    "text": "that to the SNS topic you can see it's that Arn that we captured in the very first step that we did when we started",
    "start": "2440319",
    "end": "2446720"
  },
  {
    "text": "all of this okay so now that we've created that now we need to schedule with Cloud watch",
    "start": "2446720",
    "end": "2453640"
  },
  {
    "text": "so we'll add a trigger and we will select cloudwatch youve events",
    "start": "2453640",
    "end": "2458880"
  },
  {
    "text": "schedule we'll give it a rule name so happens they have one called",
    "start": "2458880",
    "end": "2464680"
  },
  {
    "text": "every 1 minute already we'll give it a brief description executes every one",
    "start": "2464680",
    "end": "2470560"
  },
  {
    "text": "minute and then we will specify a Chron expression that says it's going to run",
    "start": "2470560",
    "end": "2476800"
  },
  {
    "text": "once a minute enable the trigger and so now this Lambda function will run every minute and it will pull that sqsq and",
    "start": "2476800",
    "end": "2483960"
  },
  {
    "text": "we'll look for messages here we're going to create our table in Aurora it's got two columns customer name customer",
    "start": "2483960",
    "end": "2491720"
  },
  {
    "text": "feedback we create our trigger it's fairly standard uh but if you look down",
    "start": "2491720",
    "end": "2497800"
  },
  {
    "text": "here this is where we're calling MySQL Lambda async and we're calling using the Arn to that first Lambda function and",
    "start": "2497800",
    "end": "2504560"
  },
  {
    "text": "we're creating a Json string with the customer name and the customer",
    "start": "2504560",
    "end": "2509720"
  },
  {
    "text": "feedback and so for each row it will call that Lambda function and pass that into the Lambda function",
    "start": "2509720",
    "end": "2518000"
  },
  {
    "text": "and now we're going to go ahead and add a couple of rows to that table and so when we execute this it'll",
    "start": "2518000",
    "end": "2524720"
  },
  {
    "text": "put two rows into the table one from customer one and two and then right here you can see that we've got a message",
    "start": "2524720",
    "end": "2531359"
  },
  {
    "text": "from Aurora mods which was our topic and it we have concatenated those two",
    "start": "2531359",
    "end": "2536599"
  },
  {
    "text": "customer reviews into a single email like I said it's worth noting that this",
    "start": "2536599",
    "end": "2541760"
  },
  {
    "text": "case we're just showing that it is an email but it could also just as easily go to an SMS you could receive it on",
    "start": "2541760",
    "end": "2548400"
  },
  {
    "text": "your phone you could hit an HTTP endpoint if you needed to take some other action when this happened this",
    "start": "2548400",
    "end": "2554880"
  },
  {
    "text": "would be an opportunity to bake that into the code as well and so with that I'd like to hand",
    "start": "2554880",
    "end": "2561280"
  },
  {
    "start": "2559000",
    "end": "2651000"
  },
  {
    "text": "it over to",
    "start": "2561280",
    "end": "2564119"
  },
  {
    "text": "Mario thanks",
    "start": "2568480",
    "end": "2572480"
  },
  {
    "text": "hi everybody um how many of you are you actually running Aurora in",
    "start": "2577720",
    "end": "2583960"
  },
  {
    "text": "production okay how many of you are actually thinking about running it",
    "start": "2583960",
    "end": "2589480"
  },
  {
    "text": "soon okay great um as you can see my name is Mario uh I like to believe that",
    "start": "2589480",
    "end": "2595839"
  },
  {
    "text": "my job in intercom is to solve problems it seems that they don't agree my uh position is actually a product engineer",
    "start": "2595839",
    "end": "2603400"
  },
  {
    "text": "I'm here today to talk about how the biggest MySQL box just became too small",
    "start": "2603400",
    "end": "2610000"
  },
  {
    "text": "for us um how we evaluated if Aurora is a good fit for us and how we migrated",
    "start": "2610000",
    "end": "2616760"
  },
  {
    "text": "there and what we learned on the way there so let's start with a very simple",
    "start": "2616760",
    "end": "2623599"
  },
  {
    "text": "question what is intercom how many people actually know for intercom here okay sad um so we are a product",
    "start": "2623599",
    "end": "2632480"
  },
  {
    "text": "company we are building a software or to phrase this a little bit better and more",
    "start": "2632480",
    "end": "2638800"
  },
  {
    "text": "correct we're building a really good software that simplifies communication between your business and your customers",
    "start": "2638800",
    "end": "2644359"
  },
  {
    "text": "so we are making it uh better simpler faster more sexy whatever you",
    "start": "2644359",
    "end": "2651119"
  },
  {
    "start": "2651000",
    "end": "3107000"
  },
  {
    "text": "want so how we actually started using Aurora when intercon was small something",
    "start": "2651119",
    "end": "2658520"
  },
  {
    "text": "really weird happened to us people actually started using our",
    "start": "2658520",
    "end": "2664240"
  },
  {
    "text": "product and uh they started even paying for that so they started sending",
    "start": "2664240",
    "end": "2671319"
  },
  {
    "text": "messages to our C to their customers and as we wanted them to send more messages",
    "start": "2671319",
    "end": "2678240"
  },
  {
    "text": "we actually developed different channels of communication so at first you just had a messenger that you could embed in your website then we added a support for",
    "start": "2678240",
    "end": "2684760"
  },
  {
    "text": "email communication we added support for mobile thec so you can embed the messenger in your mobile app and then we",
    "start": "2684760",
    "end": "2692000"
  },
  {
    "text": "integrated with Twitter Facebook whatever Channel you want so there is one problem that arises here",
    "start": "2692000",
    "end": "2700000"
  },
  {
    "text": "actually we are not Snapchat all these messages people send they don't have a",
    "start": "2700000",
    "end": "2706720"
  },
  {
    "text": "TTL we have to store them in a database and keep them there forever so if you",
    "start": "2706720",
    "end": "2713160"
  },
  {
    "text": "had started building your product the same time we",
    "start": "2713160",
    "end": "2718319"
  },
  {
    "text": "have started you would probably chose the same stack so it's rails for backend",
    "start": "2718319",
    "end": "2724240"
  },
  {
    "text": "whatever JS for front end and then you choose my equal pogress for database so",
    "start": "2724240",
    "end": "2729640"
  },
  {
    "text": "everything was quite simple at start uh we had one rails database connecting to",
    "start": "2729640",
    "end": "2734800"
  },
  {
    "text": "just one MyQ box and our customers were happy with our product our database got",
    "start": "2734800",
    "end": "2741480"
  },
  {
    "text": "on fire actually so as the best solution um what we did is we moved to",
    "start": "2741480",
    "end": "2749280"
  },
  {
    "text": "something that was massively parallel right now we actually got a bigger box so our customers were even happier",
    "start": "2749280",
    "end": "2757880"
  },
  {
    "text": "with our product uh it was fast again it was reliable and then our database got",
    "start": "2757880",
    "end": "2763200"
  },
  {
    "text": "on fire Again Naturally we got a bigger box again",
    "start": "2763200",
    "end": "2770119"
  },
  {
    "text": "so the problem with that box was that it was actually R38 XEL so I'm not sure if",
    "start": "2771000",
    "end": "2777079"
  },
  {
    "text": "you know but until today it was actually the bigger Bo box of my",
    "start": "2777079",
    "end": "2784119"
  },
  {
    "text": "CLE so what we did we analyzed the table we analy the database and we figured out",
    "start": "2785920",
    "end": "2791520"
  },
  {
    "text": "that one particular table was far more used than all other tables and that was exactly the table that distinguishes us",
    "start": "2791520",
    "end": "2798800"
  },
  {
    "text": "and Snapchat it was a table where we store all these messages so what we did is we actually just split one database",
    "start": "2798800",
    "end": "2806240"
  },
  {
    "text": "into two so we had one rail app connecting to two different databases and in one",
    "start": "2806240",
    "end": "2812599"
  },
  {
    "text": "database it was one table no joints all is index just",
    "start": "2812599",
    "end": "2818520"
  },
  {
    "text": "that um unicorns came back and they were flying or whatever they do around um and",
    "start": "2818520",
    "end": "2826359"
  },
  {
    "text": "solution was working great for us for next year and then same",
    "start": "2826359",
    "end": "2832839"
  },
  {
    "text": "problem so what's so slow now right um all the queries are IND indexed it's",
    "start": "2832839",
    "end": "2839359"
  },
  {
    "text": "it's almost like a key value store and then we did a very simple thing we just run a simple count on the whole table",
    "start": "2839359",
    "end": "2847400"
  },
  {
    "text": "and we got a number that was actually bigger than two billion so when you think about two",
    "start": "2847400",
    "end": "2853680"
  },
  {
    "text": "billion rows problem in a single myle table the first problem is that your",
    "start": "2853680",
    "end": "2859280"
  },
  {
    "text": "data very possibly can't fit in Ram and your second problem is also that your",
    "start": "2859280",
    "end": "2865119"
  },
  {
    "text": "data can't can't fit in Ram so because your data can't fit in Ram eventually",
    "start": "2865119",
    "end": "2870480"
  },
  {
    "text": "you have to go to disk because you have to go to disk you actually have to read",
    "start": "2870480",
    "end": "2875520"
  },
  {
    "text": "from something that's far slower than Ram which means that your performance is far more unpredictable than you would",
    "start": "2875520",
    "end": "2882480"
  },
  {
    "text": "expect and we were able to leave with that um because the nature of the data",
    "start": "2882480",
    "end": "2888520"
  },
  {
    "text": "that was stored there is that you have part of the data set that's actually hot and that's like recent",
    "start": "2888520",
    "end": "2894599"
  },
  {
    "text": "messages recent conversations and then you have all the old conversations that are very infrequent infrequently access",
    "start": "2894599",
    "end": "2901800"
  },
  {
    "text": "but big problem that we had was that we weren't able to change our table scheme at all and we last year shipped around",
    "start": "2901800",
    "end": "2909800"
  },
  {
    "text": "100 features and you don't want to block any progress of the company just because",
    "start": "2909800",
    "end": "2915680"
  },
  {
    "text": "you can't move one table to a new schema so you could ask yourself what is so",
    "start": "2915680",
    "end": "2921119"
  },
  {
    "text": "special about us why how other people are doing that so when you start working with relational databases what you",
    "start": "2921119",
    "end": "2926839"
  },
  {
    "text": "usually do is you start with alter table statements that's that's how change the table schema yeah it's great until you",
    "start": "2926839",
    "end": "2934480"
  },
  {
    "text": "figure out that you use a row based storage and that every time you add a new column you actually have to copy the",
    "start": "2934480",
    "end": "2941000"
  },
  {
    "text": "whole table somewhere else that's all done automatically by the engine so it means actually that the more table you",
    "start": "2941000",
    "end": "2946920"
  },
  {
    "text": "have the longer it takes for migration to happen and during that time your",
    "start": "2946920",
    "end": "2952960"
  },
  {
    "text": "table is actually locked which means that nobody except the migration can access the data and it's totally",
    "start": "2952960",
    "end": "2958480"
  },
  {
    "text": "acceptable when you start because it takes what few seconds but for us it",
    "start": "2958480",
    "end": "2964880"
  },
  {
    "text": "would cause an outage every single time so that just wasn't an option when people usually come to the same scale of",
    "start": "2964880",
    "end": "2971400"
  },
  {
    "text": "data set we are talking about terabyte uh or",
    "start": "2971400",
    "end": "2976640"
  },
  {
    "text": "or a few terabytes data set they use trigger based migrations like perona toolkit or something",
    "start": "2976640",
    "end": "2982920"
  },
  {
    "text": "similar and that does some magic in the background not to go into details but",
    "start": "2982920",
    "end": "2989640"
  },
  {
    "text": "the problem of that approach is that it actually doubles the load on your database and it was also working for us",
    "start": "2989640",
    "end": "2997559"
  },
  {
    "text": "for uh some decent time but at some point our database wasn't able to man to",
    "start": "2997559",
    "end": "3003400"
  },
  {
    "text": "handle production load and migration load and we weren't too concerned except",
    "start": "3003400",
    "end": "3009599"
  },
  {
    "text": "the fact that the whole company was a little bit slowing down because of my",
    "start": "3009599",
    "end": "3014760"
  },
  {
    "text": "team but the problem was that we knew that our database is not able to",
    "start": "3014760",
    "end": "3020799"
  },
  {
    "text": "handle 2x load and 2x load for us it's not something that happens in 10 years it's something that happens in six",
    "start": "3020799",
    "end": "3027040"
  },
  {
    "text": "months so we had to we we had to solve that problem and",
    "start": "3027040",
    "end": "3032680"
  },
  {
    "text": "actually that's the time when I joined so all the things you heard it",
    "start": "3032680",
    "end": "3040040"
  },
  {
    "text": "could totally be a lie you wouldn't know I wouldn't know that's like it okay so when I",
    "start": "3040040",
    "end": "3048400"
  },
  {
    "text": "joined uh my first task was actually to replace that massive database with something else and we were thinking",
    "start": "3048400",
    "end": "3054960"
  },
  {
    "text": "about few different options the first one was was dyam DB um and that's kind",
    "start": "3054960",
    "end": "3060720"
  },
  {
    "text": "of a database from our Dream it's fully managed we don't have to do anything uh we truly believe that we can uh spend",
    "start": "3060720",
    "end": "3067359"
  },
  {
    "text": "our time better than running databases the problem with that approach was that everything in that service",
    "start": "3067359",
    "end": "3074000"
  },
  {
    "text": "would have to change except the interface itself and we didn't have enough time to go that way so the second",
    "start": "3074000",
    "end": "3080240"
  },
  {
    "text": "solution that naturally comes to the problem is partition your data if you can and we are able to partition our",
    "start": "3080240",
    "end": "3087480"
  },
  {
    "text": "data but at that point there was no version of my cql that RDS was offering",
    "start": "3087480",
    "end": "3093599"
  },
  {
    "text": "that support native partitioning we could do that on a application Level but",
    "start": "3093599",
    "end": "3099200"
  },
  {
    "text": "it's just something we don't want to to do if we don't have to and around that time Amazon actually started advertising",
    "start": "3099200",
    "end": "3106799"
  },
  {
    "text": "Aurora so the question of course you have to ask yourself is is Aurora a good fit for us they were advertising stuff",
    "start": "3106799",
    "end": "3114200"
  },
  {
    "start": "3107000",
    "end": "3599000"
  },
  {
    "text": "like it's a 10x better for a load of some of their customers but I don't care",
    "start": "3114200",
    "end": "3119359"
  },
  {
    "text": "about other customers of AWS I just care about our database so let's see what they actually advertised oh I'm pretty",
    "start": "3119359",
    "end": "3125839"
  },
  {
    "text": "sure actually that slide changed today uh so they advertise fast available and",
    "start": "3125839",
    "end": "3131000"
  },
  {
    "text": "durable highly scalable do we know any other database that's not advertising",
    "start": "3131000",
    "end": "3137920"
  },
  {
    "text": "that I don't know for any except maybe jble okay um so that was all good but",
    "start": "3137920",
    "end": "3144839"
  },
  {
    "text": "the biggest the biggest thing for us was actually it was MySQL 5.6 compatible and",
    "start": "3144839",
    "end": "3151119"
  },
  {
    "text": "that was the exact version of the database that we were running in production what that meant for us is you",
    "start": "3151119",
    "end": "3157480"
  },
  {
    "text": "know all these problems of previous approaches like DB or sharding it on our",
    "start": "3157480",
    "end": "3162559"
  },
  {
    "text": "layer so if we could just migrate from my cql to something that looks like MySQL we don't have to do anything",
    "start": "3162559",
    "end": "3169160"
  },
  {
    "text": "that's great right so we would just flip DNS pointers from the old database to",
    "start": "3169160",
    "end": "3174599"
  },
  {
    "text": "new one and hope that everything goes well so not really when you end in",
    "start": "3174599",
    "end": "3181000"
  },
  {
    "text": "situation like that you have to test your load and um PR need actually",
    "start": "3181000",
    "end": "3186599"
  },
  {
    "text": "mentioned that they published a white paper on benchmarking Aurora but all these tests are synthetic I still don't",
    "start": "3186599",
    "end": "3195880"
  },
  {
    "text": "get an answer like is it good for me and my company or not so I found that oh",
    "start": "3195880",
    "end": "3202160"
  },
  {
    "text": "actually it's me um the only test that should matter to you is testing against your production",
    "start": "3202160",
    "end": "3209480"
  },
  {
    "text": "load especially for relational databases your access patterns could be quite",
    "start": "3209480",
    "end": "3215000"
  },
  {
    "text": "complex if you're testing key value store it's very likely that you could reuse results from somebody else it's",
    "start": "3215000",
    "end": "3221200"
  },
  {
    "text": "very likely that your performance could I don't know it could depend on the size of the key and size the hotness of all",
    "start": "3221200",
    "end": "3228640"
  },
  {
    "text": "keys and size of the Val so we had to to test our database how do you do that so",
    "start": "3228640",
    "end": "3235160"
  },
  {
    "text": "the first thing you have to do is actually to test your tools and maybe it's not completely",
    "start": "3235160",
    "end": "3240839"
  },
  {
    "text": "intuitive but the fact that testing tools are just just have test in their names it doesn't mean that they work I",
    "start": "3240839",
    "end": "3247880"
  },
  {
    "text": "had no idea what should I expect from these tools I had no idea should it just",
    "start": "3247880",
    "end": "3253480"
  },
  {
    "text": "produce many log lines Hammer the database have an iron cat flying",
    "start": "3253480",
    "end": "3259839"
  },
  {
    "text": "around no idea so what I did is I actually downloaded white paper from",
    "start": "3259839",
    "end": "3266079"
  },
  {
    "text": "Amazon and I wanted to just reproduce results they got that would mean that I'm",
    "start": "3266079",
    "end": "3272480"
  },
  {
    "text": "actually capable of reproducing it and maybe using it for something else so",
    "start": "3272480",
    "end": "3278079"
  },
  {
    "text": "downloaded the paper first time it actually crashed but then I got eight uh",
    "start": "3278079",
    "end": "3283640"
  },
  {
    "text": "art R Excel instances shoting queries at single uh Aurora uh cluster and it is",
    "start": "3283640",
    "end": "3290480"
  },
  {
    "text": "slightly slower uh I got to the point where I was able to reproduce 100,000",
    "start": "3290480",
    "end": "3295599"
  },
  {
    "text": "reads per second for the biggest instance of Aurora but it was it was close enough so then I",
    "start": "3295599",
    "end": "3303000"
  },
  {
    "text": "thought okay I have to test for my load because that's why I'm here right so the",
    "start": "3303000",
    "end": "3308599"
  },
  {
    "text": "ideal way of testing would be getting a snapshot of your database",
    "start": "3308599",
    "end": "3315760"
  },
  {
    "text": "creating database from that snapshot recording queries that are going through your database and then somehow",
    "start": "3315760",
    "end": "3322079"
  },
  {
    "text": "replicating them and that's really good as long as long as one node can",
    "start": "3322079",
    "end": "3328280"
  },
  {
    "text": "replicate all these saries in correct no in in like at at the correct uh pace so",
    "start": "3328280",
    "end": "3335400"
  },
  {
    "text": "the problem arises when you need two or more notes and when you enter that area",
    "start": "3335400",
    "end": "3340880"
  },
  {
    "text": "problem gets really messy and I'm not sure about you but that wasn't the problem I wanted to solve replicating",
    "start": "3340880",
    "end": "3346760"
  },
  {
    "text": "all these queries distributed in correct order good luck with that so",
    "start": "3346760",
    "end": "3355480"
  },
  {
    "text": "when you can't have exact results you approximate right so we created an image of our load uh internally we have a tool",
    "start": "3356760",
    "end": "3365119"
  },
  {
    "text": "that for every query ever run in production records how many times it was run where from and what was the",
    "start": "3365119",
    "end": "3371559"
  },
  {
    "text": "execution plan of the query it's not actually every query it's the shape of the query so all values are off",
    "start": "3371559",
    "end": "3377240"
  },
  {
    "text": "fiscated having that tool I took top three queries for all all types like top",
    "start": "3377240",
    "end": "3382920"
  },
  {
    "text": "three selects top three inserts top three updates I calculated ratios uh in in the overall",
    "start": "3382920",
    "end": "3391520"
  },
  {
    "text": "load and then I just played with some random number generators to make sure that they're represented in in correct",
    "start": "3391520",
    "end": "3396599"
  },
  {
    "text": "ratios and then I just have to somehow shoot them so the thing is as I said CIS",
    "start": "3396599",
    "end": "3404559"
  },
  {
    "text": "bench the tool that actually that's used in the white paper provided by Amazon it crashed it crashed because I had to",
    "start": "3404559",
    "end": "3411839"
  },
  {
    "text": "tweak some kernel limits to make sure that all CPU chords are part of network processing and because of that and the",
    "start": "3411839",
    "end": "3418240"
  },
  {
    "text": "fact that CIS bench had some race condition it would never stop I would never never never would get I would",
    "start": "3418240",
    "end": "3423400"
  },
  {
    "text": "never get all the results and during that I figured out that the plan for",
    "start": "3423400",
    "end": "3430680"
  },
  {
    "text": "queries in six bench is actually just a Lu script so what I did I created a luas",
    "start": "3430680",
    "end": "3436880"
  },
  {
    "text": "script that represents our load all these nine queries that I had I just",
    "start": "3436880",
    "end": "3442640"
  },
  {
    "text": "played with low number uh random number generator and you can ask yourself why nine so",
    "start": "3442640",
    "end": "3449680"
  },
  {
    "text": "these nine queries actually represented more than 97% of our load",
    "start": "3449680",
    "end": "3455520"
  },
  {
    "text": "okay so after we were sure that we can run it",
    "start": "3455520",
    "end": "3460599"
  },
  {
    "text": "in production or after we believe that we would be able to run it in production what we did is actually we established",
    "start": "3460599",
    "end": "3467079"
  },
  {
    "text": "replication between our original production box and aora box that we wanted to move on uh you can use binary",
    "start": "3467079",
    "end": "3474000"
  },
  {
    "text": "lcks for that it's pretty straightforward the um initial creation of the database",
    "start": "3474000",
    "end": "3480920"
  },
  {
    "text": "doesn't take less than an hour like Punit said it actually took 12 hours um",
    "start": "3480920",
    "end": "3487400"
  },
  {
    "text": "and then just to stay on the safe side we enabled the replication from that Aurora box to a third mycle box and the",
    "start": "3487400",
    "end": "3495559"
  },
  {
    "text": "reason why we had that is because we wanted to stay on the safe side we wanted to be able to roll back to the",
    "start": "3495559",
    "end": "3501680"
  },
  {
    "text": "old engine it is something that looks like my seill but you never know what could happen happen on the way",
    "start": "3501680",
    "end": "3507319"
  },
  {
    "text": "there so one thing that I learned um as as young engineer during that action is",
    "start": "3507319",
    "end": "3514880"
  },
  {
    "text": "writing a r a run book you should write a run book because people make really",
    "start": "3514880",
    "end": "3520960"
  },
  {
    "text": "bad decisions when they are under under stress um the other stuff that I learned",
    "start": "3520960",
    "end": "3526760"
  },
  {
    "text": "during that is write a really detailed run",
    "start": "3526760",
    "end": "3532240"
  },
  {
    "text": "book so this is is of course not the whole run book it's just the part of it",
    "start": "3533720",
    "end": "3539359"
  },
  {
    "text": "it actually consisted of I think more than 70 steps um and for example one of the",
    "start": "3539359",
    "end": "3545079"
  },
  {
    "text": "steps was we started the action on Friday we had to put database in certain",
    "start": "3545079",
    "end": "3551119"
  },
  {
    "text": "security groups and on Monday we had to check that security groups are actually",
    "start": "3551119",
    "end": "3556440"
  },
  {
    "text": "still attached to datab base why because all developers actually have the access to AWS console so it's not that somebody",
    "start": "3556440",
    "end": "3564520"
  },
  {
    "text": "would like to just aort dire action it's people do random stuff because they",
    "start": "3564520",
    "end": "3570160"
  },
  {
    "text": "don't know what they're doing uh and they're clicking around you know mouses are not really the most accurate uh",
    "start": "3570160",
    "end": "3576799"
  },
  {
    "text": "pointers that you have so the other thing for example it was so detailed that you had a number of tabs you have",
    "start": "3576799",
    "end": "3584799"
  },
  {
    "text": "to open in the console so we migrated uh successfully",
    "start": "3584799",
    "end": "3591799"
  },
  {
    "text": "in eight time eight minutes of of a downtime we lost no records and we had I",
    "start": "3591799",
    "end": "3599359"
  },
  {
    "text": "don't know I think less than 500 less than 100 uh 500 status codes but that's",
    "start": "3599359",
    "end": "3604440"
  },
  {
    "text": "not because we don't have enough traffic it's actually just because we coordinated the action really",
    "start": "3604440",
    "end": "3610280"
  },
  {
    "text": "well so how does it work for us it does work uh we are running on 30 to 40% of",
    "start": "3610280",
    "end": "3618200"
  },
  {
    "text": "our CPU uh we had few bucks that Amazon fixed in the meantime for example one of",
    "start": "3618200",
    "end": "3624079"
  },
  {
    "text": "them was um during migrations that would be small enough that we could be able to",
    "start": "3624079",
    "end": "3630079"
  },
  {
    "text": "run alter table statements the metadata table would lock and it would never be unlocked that would also cause an outage",
    "start": "3630079",
    "end": "3637319"
  },
  {
    "text": "um I think that's fixed now we haven't seen that uh I think we saw that twice",
    "start": "3637319",
    "end": "3642960"
  },
  {
    "text": "and after that we never saw that uh and now I'll actually just show you",
    "start": "3642960",
    "end": "3648760"
  },
  {
    "text": "some stuff that seems very obvious but changes in the land of Aurora so one",
    "start": "3648760",
    "end": "3654079"
  },
  {
    "text": "thing is use secondaries when you can and of course everybody uses secondaries",
    "start": "3654079",
    "end": "3659119"
  },
  {
    "text": "when they can but the difference is that replication lag is now below 30 milliseconds for us when we were using",
    "start": "3659119",
    "end": "3665760"
  },
  {
    "text": "our MyQ the problem we had was during a peak time replication leg would actually go",
    "start": "3665760",
    "end": "3673079"
  },
  {
    "text": "above half an hour so that means if your master goes",
    "start": "3673079",
    "end": "3679720"
  },
  {
    "text": "down you better cry the other thing is that you can use",
    "start": "3679720",
    "end": "3685960"
  },
  {
    "text": "so Aurora is actually so powerful that very often we don't even need uh to run",
    "start": "3685960",
    "end": "3691680"
  },
  {
    "text": "our offline queries on red shift we can have a secondary that has a lower",
    "start": "3691680",
    "end": "3697559"
  },
  {
    "text": "priority for a failover and we can run ad hog peries there it's uh mostly useful for developers not for analytics",
    "start": "3697559",
    "end": "3704280"
  },
  {
    "text": "the second thing is you should check your drivers so R fil over actually depends on DNS and some drivers cash the",
    "start": "3704280",
    "end": "3712079"
  },
  {
    "text": "resolution of that that means that your application will not be able to detect",
    "start": "3712079",
    "end": "3718079"
  },
  {
    "text": "new master as soon as it should be so before you go there you can ask people",
    "start": "3718079",
    "end": "3724240"
  },
  {
    "text": "who actually are running the same setup or even better you can test failovers it's possible aora has a support just to",
    "start": "3724240",
    "end": "3730079"
  },
  {
    "text": "induce failovers yourselves yourself and the third thing is build your tooling or",
    "start": "3730079",
    "end": "3736720"
  },
  {
    "text": "buy it for example we use VI cortex uh recently we upgraded to 1.9 performance",
    "start": "3736720",
    "end": "3744400"
  },
  {
    "text": "schema was not fast enough before for us to attach FID cortex with full",
    "start": "3744400",
    "end": "3750119"
  },
  {
    "text": "Diagnostics now it is uh the other thing is it's still a database it's still a",
    "start": "3750119",
    "end": "3756440"
  },
  {
    "text": "database with extraordinary uh freedom of defining",
    "start": "3756440",
    "end": "3762760"
  },
  {
    "text": "queries so if you acquire some luck that blocks the database it's going to go",
    "start": "3762760",
    "end": "3769520"
  },
  {
    "text": "down so build your tooling to protect protect yourself from from developers and yourself",
    "start": "3769520",
    "end": "3775960"
  },
  {
    "text": "so what we don't have to do",
    "start": "3775960",
    "end": "3778960"
  },
  {
    "text": "anymore cluster monitoring got far simpler if you remember I said that our",
    "start": "3781880",
    "end": "3787960"
  },
  {
    "text": "replication lag was sometimes more than half harder than half an hour and because of that we actually needed some",
    "start": "3787960",
    "end": "3794559"
  },
  {
    "text": "monitoring in place to make sure that certain secondaries are pulled out from the from the cluster since replication",
    "start": "3794559",
    "end": "3801400"
  },
  {
    "text": "lag is not a problem we don't need we we we don't need classes of cluster",
    "start": "3801400",
    "end": "3806760"
  },
  {
    "text": "monitoring anymore the other problem is parameter twe tweaking it's not a problem anymore we actually had a guy",
    "start": "3806760",
    "end": "3813279"
  },
  {
    "text": "his name was Denny and he was tweaking myle parameters for us now we don't need",
    "start": "3813279",
    "end": "3818839"
  },
  {
    "text": "Danny anymore Denny is no harm done to to Danny he just moved to another team",
    "start": "3818839",
    "end": "3824319"
  },
  {
    "text": "he's still part of the company Aurora is just so more forgiving than my SQL that",
    "start": "3824319",
    "end": "3832119"
  },
  {
    "text": "we don't need to tweak these things so after all of that you could say that",
    "start": "3832119",
    "end": "3838880"
  },
  {
    "text": "it's impossible to break it right we have so many records our load is pretty high and of course it's possible to",
    "start": "3838880",
    "end": "3845640"
  },
  {
    "text": "break it it's software that's first and the second thing it's a database you can always break a database so in order to",
    "start": "3845640",
    "end": "3852400"
  },
  {
    "text": "actually make it less probable really try to do all of these things try to",
    "start": "3852400",
    "end": "3859000"
  },
  {
    "text": "test your load try to run write a run book to have a seamless migration try to",
    "start": "3859000",
    "end": "3864240"
  },
  {
    "text": "use secondaries it will you'll have far more features that will be enabled to",
    "start": "3864240",
    "end": "3869480"
  },
  {
    "text": "use secondary than you had before check your drivers because that's what talks with your",
    "start": "3869480",
    "end": "3874960"
  },
  {
    "text": "database and at the end build your tooling to protect protect yourself from",
    "start": "3874960",
    "end": "3880039"
  },
  {
    "text": "yourself thank you",
    "start": "3880039",
    "end": "3884240"
  }
]
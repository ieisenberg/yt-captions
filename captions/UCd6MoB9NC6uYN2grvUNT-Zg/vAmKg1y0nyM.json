[
  {
    "start": "0",
    "end": "89000"
  },
  {
    "text": "so our plan here is to get you up on top by giving you all the tools and best",
    "start": "30",
    "end": "5790"
  },
  {
    "text": "practices you need to run efficiently on Amazon or so before I head on though I",
    "start": "5790",
    "end": "12719"
  },
  {
    "text": "do want to get a sense from you all so I'm going to do a quick poll how many of",
    "start": "12719",
    "end": "18720"
  },
  {
    "text": "you are aware of our familiar with Aurora alright fair number of hands go",
    "start": "18720",
    "end": "23939"
  },
  {
    "text": "up there's a great deal of innovation that has gone into building this relational database and there are two",
    "start": "23939",
    "end": "31140"
  },
  {
    "text": "sessions I would really highly recommend you to go either view or attend first one as that 2:02",
    "start": "31140",
    "end": "37710"
  },
  {
    "text": "it's getting started with Aurora and that session the recording for it is now",
    "start": "37710",
    "end": "43469"
  },
  {
    "text": "available online so you can go and watch it now this session is that three zero one and the repeat of that session is",
    "start": "43469",
    "end": "50940"
  },
  {
    "text": "happening tomorrow at 11:30 a.m. so I highly encourage you to attend or a few count then in that case you can watch",
    "start": "50940",
    "end": "57239"
  },
  {
    "text": "the recording in a few days all right so let me continue with the polling a",
    "start": "57239",
    "end": "63180"
  },
  {
    "text": "little bit more so bear with me how many of you are thinking of migrating to Aurora fair number of hands great and",
    "start": "63180",
    "end": "71600"
  },
  {
    "text": "how many of you are thinking are currently using Aurora just a few all",
    "start": "71600",
    "end": "78240"
  },
  {
    "text": "right so hopefully by the time we are done this this ratio would change we have content for that's a broad mix of",
    "start": "78240",
    "end": "84509"
  },
  {
    "text": "audience here right so we have content that would appeal to every one of you right so let's look at what we are going",
    "start": "84509",
    "end": "91020"
  },
  {
    "start": "89000",
    "end": "184000"
  },
  {
    "text": "to you know show you in this session so forcely will give you a quick overview",
    "start": "91020",
    "end": "96600"
  },
  {
    "text": "of Amazon Aurora and then we'll move on to see different sources from there you",
    "start": "96600",
    "end": "104340"
  },
  {
    "text": "can mag migrate to Amazon or Orem alright so we'll start off with the simplest scenarios which is let's say a",
    "start": "104340",
    "end": "110280"
  },
  {
    "text": "my sequel compatible database maria review or my sequel and we'll also call",
    "start": "110280",
    "end": "115979"
  },
  {
    "text": "them homogeneous migrations and then it's possible that you are probably not running a my sequel database today right",
    "start": "115979",
    "end": "122040"
  },
  {
    "text": "so if you are running a commercial database or you're running a non relational database like no sequel",
    "start": "122040",
    "end": "128220"
  },
  {
    "text": "database then how you can migrate your data from those sources into Aurora",
    "start": "128220",
    "end": "133410"
  },
  {
    "text": "look at tooling and automation that is available to you for all these scenarios as as a builder as an application",
    "start": "133410",
    "end": "141570"
  },
  {
    "text": "developer as a database administrator your job doesn't end when you are done",
    "start": "141570",
    "end": "146730"
  },
  {
    "text": "with migrations right you want to make sure that you're optimizing your workloads on Aurora so that you are",
    "start": "146730",
    "end": "152700"
  },
  {
    "text": "running very efficiently so we'll look at ways you can improve the performance of your workloads and finally once you",
    "start": "152700",
    "end": "161400"
  },
  {
    "text": "have everything up and running you probably also want to maintain be visibility into what's going on in your",
    "start": "161400",
    "end": "167370"
  },
  {
    "text": "databases what kind of activity is happening so we have certain capabilities that we'll talk about that",
    "start": "167370",
    "end": "173040"
  },
  {
    "text": "you can use for that purpose our objective here finally is to help you",
    "start": "173040",
    "end": "178590"
  },
  {
    "text": "make the most of Aurora right so let's dive right in so what is Amazon Aurora",
    "start": "178590",
    "end": "187020"
  },
  {
    "start": "184000",
    "end": "225000"
  },
  {
    "text": "Amazon Aurora is a relational database born in the cloud designed to give you",
    "start": "187020",
    "end": "192810"
  },
  {
    "text": "the performance and availability of commercial databases with the simplicity",
    "start": "192810",
    "end": "198720"
  },
  {
    "text": "and cost-effectiveness of open cells databases so what you get is the best of",
    "start": "198720",
    "end": "204540"
  },
  {
    "text": "both worlds today my sequel is drop-in compatible well today Aurora is drop-in",
    "start": "204540",
    "end": "212130"
  },
  {
    "text": "compatible but my sequel and PostgreSQL so if you have any applications running",
    "start": "212130",
    "end": "217290"
  },
  {
    "text": "on my sequel or running on PostgreSQL you can simply lift and shift and point tour around because it should idle walk",
    "start": "217290",
    "end": "226370"
  },
  {
    "start": "225000",
    "end": "288000"
  },
  {
    "text": "now this Lord of innovation that has gone n to building Aurora but if there's",
    "start": "226370",
    "end": "231570"
  },
  {
    "text": "one fundamental key innovation then I'm going to talk about it's going to be the storage layer so in a traditional",
    "start": "231570",
    "end": "237420"
  },
  {
    "text": "database you have different layers there's query processing there's caching",
    "start": "237420",
    "end": "243030"
  },
  {
    "text": "there's logging and there storage right so what we have done is we have taken the the logging ant storage layers and",
    "start": "243030",
    "end": "249480"
  },
  {
    "text": "created a purpose-built scaled out distributed log structured storage",
    "start": "249480",
    "end": "255690"
  },
  {
    "text": "volume now what this does is takes your car and data copies it over six times",
    "start": "255690",
    "end": "261380"
  },
  {
    "text": "into 3 availability zones and availability zone and ews you",
    "start": "261380",
    "end": "267160"
  },
  {
    "text": "and think of it as a cluster of the data centers so that gives you high availability your data depending on the",
    "start": "267160",
    "end": "274150"
  },
  {
    "text": "size of your database also get striped across hundreds or sometimes thousands",
    "start": "274150",
    "end": "279310"
  },
  {
    "text": "of nodes so with that you also get very high performance how much you might ask it's five times the performance of my",
    "start": "279310",
    "end": "286240"
  },
  {
    "text": "sequel so but or a continues to be the",
    "start": "286240",
    "end": "292000"
  },
  {
    "text": "fastest growing service in AWS history today three fourths of top 100 AWS",
    "start": "292000",
    "end": "298840"
  },
  {
    "text": "customers use Aurora this is just a sampling of those customers that we can reference we have tens of thousands of",
    "start": "298840",
    "end": "305950"
  },
  {
    "text": "customers using a roller today okay so with that context let's look at the",
    "start": "305950",
    "end": "312310"
  },
  {
    "start": "308000",
    "end": "343000"
  },
  {
    "text": "various sources that you can migrate from and what kind of tuning and automation is available to you for that",
    "start": "312310",
    "end": "318930"
  },
  {
    "text": "so we'll start looking at force from the simplest scenario wherein you're running your my sequel database potentially in",
    "start": "318930",
    "end": "325660"
  },
  {
    "text": "RDS and then work our way towards more involved setups so commercial databases",
    "start": "325660",
    "end": "332890"
  },
  {
    "text": "and non-relational databases and look at different to link that is available to",
    "start": "332890",
    "end": "338920"
  },
  {
    "text": "you automation that we make available to you to migrate to Amazon Aurora I'm",
    "start": "338920",
    "end": "344140"
  },
  {
    "start": "343000",
    "end": "371000"
  },
  {
    "text": "going to use the schematic actually to walk through the different options and",
    "start": "344140",
    "end": "349690"
  },
  {
    "text": "methods that are available to you so on the top are the different sources and on the side we have the different methods",
    "start": "349690",
    "end": "355570"
  },
  {
    "text": "you can use to migrate to Amazon Aurora the options that are highlighted are the",
    "start": "355570",
    "end": "361690"
  },
  {
    "text": "ones which we recommend of course the ones where techs are the ones which are supported so let's dive into this right",
    "start": "361690",
    "end": "371669"
  },
  {
    "start": "371000",
    "end": "432000"
  },
  {
    "text": "RDS snapshot of course is available to you and if you are running your database",
    "start": "371940",
    "end": "377740"
  },
  {
    "text": "and in RDS and the migration from RDS if you are using the snapshot is very",
    "start": "377740",
    "end": "383919"
  },
  {
    "text": "simple it's a point-and-click operation and it's also the fastest approach right so on the console if you go in you can",
    "start": "383919",
    "end": "390430"
  },
  {
    "text": "simply click migrate mainly the snapshot and restore that snapshot into an Aurora",
    "start": "390430",
    "end": "395500"
  },
  {
    "text": "cluster and that's it your migration gets completed at that point now you might want",
    "start": "395500",
    "end": "401080"
  },
  {
    "text": "to do this with minimal downtime so that's an option for that too what you",
    "start": "401080",
    "end": "406900"
  },
  {
    "text": "can do now is you can create an Aurora read replica this will set up binary log",
    "start": "406900",
    "end": "413409"
  },
  {
    "text": "based replication between your source RDS my sequel database and your destination",
    "start": "413409",
    "end": "418900"
  },
  {
    "text": "Aurora cluster and as soon as their application completes at that point you",
    "start": "418900",
    "end": "424120"
  },
  {
    "text": "can cut over and essentially take a very minimal downtime while do the doing this",
    "start": "424120",
    "end": "429400"
  },
  {
    "text": "migration now it's possible that your",
    "start": "429400",
    "end": "435340"
  },
  {
    "text": "database that you're running today my sequel database you are running today it's not on RDS maybe you're running it",
    "start": "435340",
    "end": "441969"
  },
  {
    "text": "on premises in your data center or maybe you are self managing it and ec2 so for",
    "start": "441969",
    "end": "448240"
  },
  {
    "text": "that there are two options one is a binary backup of your database the other",
    "start": "448240",
    "end": "454270"
  },
  {
    "text": "one is set of my sequel tools so let me elaborate a little bit more on that you",
    "start": "454270",
    "end": "459610"
  },
  {
    "text": "would see there are two arrows going back and forth there the reason is web backup see essentially restore your",
    "start": "459610",
    "end": "465520"
  },
  {
    "text": "entire database in scenarios where let's say you want only parts or portions of",
    "start": "465520",
    "end": "471520"
  },
  {
    "text": "your database to be migrated so you want more control and flexibility and how you do your migration my sequel tools are",
    "start": "471520",
    "end": "478000"
  },
  {
    "text": "going to be probably more useful for you and we'll dive into each one of those are deeper and walk through when that",
    "start": "478000",
    "end": "484180"
  },
  {
    "text": "can come in handy right so first off I'll take the backup set up and walk",
    "start": "484180",
    "end": "490690"
  },
  {
    "start": "489000",
    "end": "567000"
  },
  {
    "text": "through it so how can you take your backups there are open source tools available such as Percona extra backup",
    "start": "490690",
    "end": "497529"
  },
  {
    "text": "it will create a binary coffee or be off your database what that means is your migration is really high-performance",
    "start": "497529",
    "end": "503440"
  },
  {
    "text": "because you don't have to take your logical terms replace the replay replay",
    "start": "503440",
    "end": "508810"
  },
  {
    "text": "those statements on your source database Amazon Aurora cluster it's just a binary",
    "start": "508810",
    "end": "514360"
  },
  {
    "text": "copy that gets restored in an Aurora cluster for add to what you have to do",
    "start": "514360",
    "end": "520328"
  },
  {
    "text": "is that you have to create a backup and store it in an s3 bucket once it's in an s3 bucket beyond that",
    "start": "520329",
    "end": "527050"
  },
  {
    "text": "RDS automation helps you there all right so on the console there's point-and-click operation you can select",
    "start": "527050",
    "end": "533350"
  },
  {
    "text": "your back and restore it to an Aurora classroom straightforward done now you want to ask",
    "start": "533350",
    "end": "539480"
  },
  {
    "text": "how do I now achieve minimal downtime while doing their up while doing the",
    "start": "539480",
    "end": "544519"
  },
  {
    "text": "migration the process is similar to what we discussed in the previous step so you",
    "start": "544519",
    "end": "549740"
  },
  {
    "text": "can in this in this tab set up replication binary log or bin log base",
    "start": "549740",
    "end": "554990"
  },
  {
    "text": "your application between your source database and target Aurora fluster once their application completes the process",
    "start": "554990",
    "end": "560720"
  },
  {
    "text": "is similar right you just got over your application to your target Aurora fluster so that's great and this set up",
    "start": "560720",
    "end": "572120"
  },
  {
    "start": "567000",
    "end": "591000"
  },
  {
    "text": "as I said and here with the backup your entire database gets restored what if",
    "start": "572120",
    "end": "577760"
  },
  {
    "text": "you only want certain tables to be migrated to Aurora or let's say you want only certain portions of your table or",
    "start": "577760",
    "end": "584149"
  },
  {
    "text": "certain partitions of your tables to be migrated to Aurora so that's where my sequel tools come in handy and those",
    "start": "584149",
    "end": "591829"
  },
  {
    "start": "591000",
    "end": "689000"
  },
  {
    "text": "tools will give you the flexibility to achieve this so which tools am I talking about so whether you're my single",
    "start": "591829",
    "end": "597529"
  },
  {
    "text": "installation you would get my sequel dump and my sequel import these come",
    "start": "597529",
    "end": "602720"
  },
  {
    "text": "with your my sequel installation and you can use this to take a logical dump of",
    "start": "602720",
    "end": "607730"
  },
  {
    "text": "your data and then import data logical dump now one limitation with these tools",
    "start": "607730",
    "end": "613370"
  },
  {
    "text": "is that they're single threaded so if your client machine has a let's say 16 B",
    "start": "613370",
    "end": "618589"
  },
  {
    "text": "CPUs this is going to run only one thread to take the back up and take the logical dump so for that you have",
    "start": "618589",
    "end": "626540"
  },
  {
    "text": "alternatives if you really want to utilize the compute capacity on your",
    "start": "626540",
    "end": "631910"
  },
  {
    "text": "client instances in that case you can use third-party tools such as my dumper and my loader these are open source and",
    "start": "631910",
    "end": "638690"
  },
  {
    "text": "freely available and what this allows you to do these tools allow you to do is you can create multiple threads for",
    "start": "638690",
    "end": "644660"
  },
  {
    "text": "taking dumps of your database and then restoring those tons back onto our cluster their application process is",
    "start": "644660",
    "end": "651860"
  },
  {
    "text": "similar as we described before so you set up in log replication replication catches up you've gotta work",
    "start": "651860",
    "end": "657760"
  },
  {
    "text": "in addition of course you can use regular by sequel commands right so",
    "start": "657760",
    "end": "663110"
  },
  {
    "text": "these are select and to unload from flat files in addition to that what is available to you with Aurora is",
    "start": "663110",
    "end": "670009"
  },
  {
    "text": "that you can load from an s3 bucket so you can place a flat file and an Astra bucket like a sequel regular signal",
    "start": "670009",
    "end": "677029"
  },
  {
    "text": "statement right load from that file in the s3 bucket same way you can also export out to an X through s3 bucket",
    "start": "677029",
    "end": "683839"
  },
  {
    "text": "with select into s3 okay so I've been",
    "start": "683839",
    "end": "691720"
  },
  {
    "start": "689000",
    "end": "954000"
  },
  {
    "text": "partially you know referring to something all as a client the client is essentially the machine that you are",
    "start": "691720",
    "end": "697069"
  },
  {
    "text": "using for either importing data into your source database or extracting data",
    "start": "697069",
    "end": "702889"
  },
  {
    "text": "out of your sorry importing data into your target database or extracting database data out of your source",
    "start": "702889",
    "end": "708560"
  },
  {
    "text": "database so there are some consideration that you must keep in mind first one is",
    "start": "708560",
    "end": "714079"
  },
  {
    "text": "that these client machines should be as close as possible to your source and target database respectively why is that",
    "start": "714079",
    "end": "720680"
  },
  {
    "text": "a case so let's say you are running your database in ec2 and if your client",
    "start": "720680",
    "end": "727189"
  },
  {
    "text": "machine is not on the same V PC or not on the same availability zone you are essentially anchoring additional network",
    "start": "727189",
    "end": "733639"
  },
  {
    "text": "latency all right so our recommendation is to clear up place it in the same V PC as the source or as the destination",
    "start": "733639",
    "end": "741620"
  },
  {
    "text": "database right now what happens in case you are running your database",
    "start": "741620",
    "end": "747199"
  },
  {
    "text": "on-premises and that case our recommendation is you use at least two clients first one would be of course in",
    "start": "747199",
    "end": "753290"
  },
  {
    "text": "your data center closest to your source database take the dump locate into an s3 bucket and from there",
    "start": "753290",
    "end": "760160"
  },
  {
    "text": "you have another client machine which will be in the same V PC as your Aurora cluster and that will ingest the data",
    "start": "760160",
    "end": "766970"
  },
  {
    "text": "from this three bucket and restore it into your target Aurora cluster some of",
    "start": "766970",
    "end": "774709"
  },
  {
    "text": "the other considerations with respect to client instances that you might want to keep in mind are many times when",
    "start": "774709",
    "end": "779959"
  },
  {
    "text": "customers contact us they say that why should the client matter is the server that really matters well in case of",
    "start": "779959",
    "end": "785930"
  },
  {
    "text": "migrations clients are also going to play an important role in terms of the amount of time it is going to take you",
    "start": "785930",
    "end": "791660"
  },
  {
    "text": "to migrate right so what we recommend or suggest is that you provision a client",
    "start": "791660",
    "end": "797420"
  },
  {
    "text": "machine or or instance in case of ec2 that has at least one C pyew for export or import thread and",
    "start": "797420",
    "end": "806350"
  },
  {
    "text": "especially in scenarios where you have you are doing real-time processing let's say you have compressed your data and",
    "start": "806350",
    "end": "812089"
  },
  {
    "text": "you are doing compression and decompression and those scenarios we would want at least one CPU per thread",
    "start": "812089",
    "end": "818589"
  },
  {
    "text": "ec2 instances also support enhanced networking so make sure you go for those",
    "start": "818589",
    "end": "824709"
  },
  {
    "text": "instances and depending on the size of the instance you choose you could get up to 25 Gbps of network bandwidth",
    "start": "824709",
    "end": "833510"
  },
  {
    "text": "similarly the DCT will attach an EBS volume those volumes can support certain level of AI ops so depending on your",
    "start": "833510",
    "end": "841220"
  },
  {
    "text": "migration let's say you are trying to do a migration ad of 100 mega bytes per",
    "start": "841220",
    "end": "846440"
  },
  {
    "text": "second so makes sure that your EBS volume supports 800 megabits of AI ops",
    "start": "846440",
    "end": "851660"
  },
  {
    "text": "at least right similarly if you find that your machine's not really keeping",
    "start": "851660",
    "end": "857930"
  },
  {
    "text": "up there's you know the migrations taking too long what you can do is you can look at voice Diagnostics and some",
    "start": "857930",
    "end": "864980"
  },
  {
    "text": "of these metrics if you are using an ec2 instance are in fact by default available in cloud watt so you think",
    "start": "864980",
    "end": "871519"
  },
  {
    "text": "about CPU utilization or memory utilization that's going to be available in cloud watch for you and you can watch",
    "start": "871519",
    "end": "876829"
  },
  {
    "text": "what's going on right then maybe providing a larger instance now let's",
    "start": "876829",
    "end": "883579"
  },
  {
    "text": "look at the destination in this case as rora instance right so how much should you",
    "start": "883579",
    "end": "890120"
  },
  {
    "text": "provision for it of course it's obvious that you have to prove a provision enough capacity to be able to ingest or",
    "start": "890120",
    "end": "896779"
  },
  {
    "text": "dump data if you're exporting out and feroro what we recommend is that you provision at least 2 CPUs per thread for",
    "start": "896779",
    "end": "904670"
  },
  {
    "text": "imports and one CPU per thread for exports if I point back to the storage",
    "start": "904670",
    "end": "913430"
  },
  {
    "text": "volume that I described at the start of the presentation what what it allows us",
    "start": "913430",
    "end": "918649"
  },
  {
    "text": "to do is that networking is typically not out of network or rather storage IO is not typically the problem the reason",
    "start": "918649",
    "end": "925190"
  },
  {
    "text": "being you your data is getting striped across hundreds or thousands of nodes so that usually is not the bottleneck and",
    "start": "925190",
    "end": "932500"
  },
  {
    "text": "in terms of your capacity of course if you find that your database instance is not you know scale",
    "start": "932500",
    "end": "941370"
  },
  {
    "text": "up to the point that you need there's point and scale operations available on the AWS console so you can",
    "start": "941370",
    "end": "947819"
  },
  {
    "text": "just go in and increase the size of your database instance if you want to or scale it back if you need to",
    "start": "947819",
    "end": "954499"
  },
  {
    "start": "954000",
    "end": "1027000"
  },
  {
    "text": "another question that many questioners ask us is that hey I have this huge large table and it's taking me you know",
    "start": "954499",
    "end": "962550"
  },
  {
    "text": "days along or our so long to import or export out what do I do so I'll refer",
    "start": "962550",
    "end": "968579"
  },
  {
    "text": "back to the third-party tools my dumper because these are multi-threaded they",
    "start": "968579",
    "end": "974459"
  },
  {
    "text": "provide you more flexibility and one of the options with my dumper is that you can use the ROS parameter in it to",
    "start": "974459",
    "end": "981389"
  },
  {
    "text": "specify how many rows should be in per chunk of your flat file so you can take",
    "start": "981389",
    "end": "988439"
  },
  {
    "text": "a large table and chunk it up into a certain number of you know smaller pieces so your exports become foster",
    "start": "988439",
    "end": "994680"
  },
  {
    "text": "because they are going through multiple threads similarly when you ingest it with my loader you can specify the",
    "start": "994680",
    "end": "1000230"
  },
  {
    "text": "number of threads you want to use for importing your data right now by default",
    "start": "1000230",
    "end": "1007009"
  },
  {
    "text": "my dumper and my loader will spin up only for threads so our recommendation",
    "start": "1007009",
    "end": "1012379"
  },
  {
    "text": "is if you are using larger instances for example and are for to excel to extra-large you would want to increase",
    "start": "1012379",
    "end": "1018290"
  },
  {
    "text": "the number of threads adjusted to the number of CPUs you have available so that you are making the most use of",
    "start": "1018290",
    "end": "1023389"
  },
  {
    "text": "compute capacity available to you another tweak that you should absolutely",
    "start": "1023389",
    "end": "1030860"
  },
  {
    "start": "1027000",
    "end": "1072000"
  },
  {
    "text": "consider as setting up RPS or a sieve packet steering and RFS order received",
    "start": "1030860",
    "end": "1036949"
  },
  {
    "text": "flows cheering on your instances what do these mean essentially at a high level RPS means that it will allow you to",
    "start": "1036949",
    "end": "1043730"
  },
  {
    "text": "process your incoming packets through multiple CPUs right so better utilization of your CPUs and RFS is an",
    "start": "1043730",
    "end": "1051409"
  },
  {
    "text": "extension or of RPS which essentially ensures that your incoming packets are",
    "start": "1051409",
    "end": "1057140"
  },
  {
    "text": "being processed by the same CPU their CPU affinity so that your cache is being utilized better all these slides and the",
    "start": "1057140",
    "end": "1066289"
  },
  {
    "text": "content will be made available to you offline so no need to know you will have access to all this alright",
    "start": "1066289",
    "end": "1072169"
  },
  {
    "start": "1072000",
    "end": "1097000"
  },
  {
    "text": "so that's about vibrations from sources which are compatible with my Sigma my",
    "start": "1072169",
    "end": "1078450"
  },
  {
    "text": "sequel what about situations where you are not running a my sequel database maybe you're running a commercial",
    "start": "1078450",
    "end": "1085289"
  },
  {
    "text": "database maybe you're running a no sequel database such as MongoDB so for that you might want to consider",
    "start": "1085289",
    "end": "1092090"
  },
  {
    "text": "AWS data migration service and let's dive deeper into it so what is EWS data",
    "start": "1092090",
    "end": "1099570"
  },
  {
    "text": "migration service it is a managed service that allows you to easily migrate your data from most of the",
    "start": "1099570",
    "end": "1107399"
  },
  {
    "text": "widely used sources and they are all listed here to a target destination right so in this case Ora as well now",
    "start": "1107399",
    "end": "1118100"
  },
  {
    "start": "1117000",
    "end": "1201000"
  },
  {
    "text": "the process involved in migrations from these non my sequel compatible sources",
    "start": "1118100",
    "end": "1124259"
  },
  {
    "text": "is to stocks because not all databases are made equal not all data types are",
    "start": "1124259",
    "end": "1129419"
  },
  {
    "text": "going to be equal for step that you need to take is to change your schema or",
    "start": "1129419",
    "end": "1134519"
  },
  {
    "text": "migrate your schema so you can use either native tools available with your you know source database or you can use",
    "start": "1134519",
    "end": "1141899"
  },
  {
    "text": "the AWS schema conversion tool to convert your schema once the schema is",
    "start": "1141899",
    "end": "1147950"
  },
  {
    "text": "migrated over DMS can take over DMS can take your data and to change data",
    "start": "1147950",
    "end": "1154440"
  },
  {
    "text": "capture migrate your data into the target database so how does this work so",
    "start": "1154440",
    "end": "1161429"
  },
  {
    "text": "essentially you first provision replication instance once this instance",
    "start": "1161429",
    "end": "1167759"
  },
  {
    "text": "is created you would connected to the source and destination databases so that",
    "start": "1167759",
    "end": "1173369"
  },
  {
    "text": "it knows you know where to move the data from and create tasks to us define what",
    "start": "1173369",
    "end": "1179309"
  },
  {
    "text": "kind of data that you want to migrate from your source database to destination database and that's it",
    "start": "1179309",
    "end": "1185330"
  },
  {
    "text": "BMS then takes care of through change data capture migrating your data into your destination database and once you",
    "start": "1185330",
    "end": "1193080"
  },
  {
    "text": "are done at that point you just point your application back to your destination or a cluster now many times",
    "start": "1193080",
    "end": "1201019"
  },
  {
    "start": "1201000",
    "end": "1234000"
  },
  {
    "text": "customers are ok this is great for heterogeneous migrations but I have a my sequel",
    "start": "1201019",
    "end": "1206910"
  },
  {
    "text": "database where I've charted my data across multiple my sequel shots is there",
    "start": "1206910",
    "end": "1213000"
  },
  {
    "text": "a way I can consolidate that into Aurora my sequel cluster because I get more",
    "start": "1213000",
    "end": "1218070"
  },
  {
    "text": "performance I can potentially do that and achieve that so what level of automation and what processes are",
    "start": "1218070",
    "end": "1223310"
  },
  {
    "text": "available to you Steve is going to walk us through that it's a Steve after year all right so",
    "start": "1223310",
    "end": "1235490"
  },
  {
    "start": "1234000",
    "end": "1261000"
  },
  {
    "text": "like Ryan said a lot of times you find yourself you have a my sequel database and it's too big to fit on a single",
    "start": "1235490",
    "end": "1242100"
  },
  {
    "text": "instance so you've taken to charting this across multiple instances which will give you the performance you need",
    "start": "1242100",
    "end": "1248340"
  },
  {
    "text": "the throughput that you need but it can introduce additional management headaches right you now have multiple",
    "start": "1248340",
    "end": "1254190"
  },
  {
    "text": "servers to take care of you have to have a mapping function of some type that will route your traffic to the appropriate instances etc so let's take",
    "start": "1254190",
    "end": "1262590"
  },
  {
    "start": "1261000",
    "end": "1347000"
  },
  {
    "text": "a look at what we have right here on the Left what we have is our initial setup all right we have four shards the first",
    "start": "1262590",
    "end": "1270090"
  },
  {
    "text": "shard contains what we call our reference data this would be small tables that we use for lookups things",
    "start": "1270090",
    "end": "1275220"
  },
  {
    "text": "like that the other three shards are going to have very large tables or maybe even one very",
    "start": "1275220",
    "end": "1281040"
  },
  {
    "text": "large table that has just essentially partitioned across multiple servers so",
    "start": "1281040",
    "end": "1286080"
  },
  {
    "text": "the first thing that we're going to want to do in a migration to Aurora is to establish a beachhead and so what do I",
    "start": "1286080",
    "end": "1291660"
  },
  {
    "text": "mean by a beachhead well our goal is to move everything into a single Aurora instance write a single Aurora cluster",
    "start": "1291660",
    "end": "1299310"
  },
  {
    "text": "and so what we're gonna do is we're gonna create that Aurora cluster and we're going to move the reference data",
    "start": "1299310",
    "end": "1304650"
  },
  {
    "text": "first because that is central to everything else and it's also generally the smaller of all of the shards so once",
    "start": "1304650",
    "end": "1313200"
  },
  {
    "text": "we've done that I think it's important to note that Aurora my sequel as it stands today is wire compatible with my",
    "start": "1313200",
    "end": "1319470"
  },
  {
    "text": "sequel five point six so when we're looking at the picture on the on the right hand side we still have for my",
    "start": "1319470",
    "end": "1326100"
  },
  {
    "text": "sequel databases as far as your application is concerned so once we've done this and we have migrated that data",
    "start": "1326100",
    "end": "1332370"
  },
  {
    "text": "over the next thing that we want to do and so we end up in this state right here so once we're in this state then it's",
    "start": "1332370",
    "end": "1338190"
  },
  {
    "text": "time to validate like I said you have your application it still doesn't know the difference between which one is your",
    "start": "1338190",
    "end": "1343590"
  },
  {
    "text": "Aurora instance in which one are your other shards from here we can then",
    "start": "1343590",
    "end": "1349460"
  },
  {
    "start": "1347000",
    "end": "1395000"
  },
  {
    "text": "one-by-one start folding these shards into that Aurora cluster we don't have",
    "start": "1349460",
    "end": "1355980"
  },
  {
    "text": "to do everything all at once you know we're gonna just move the next shard and then we'll validate and we'll repeat",
    "start": "1355980",
    "end": "1361200"
  },
  {
    "text": "until we end up with the single Aurora cluster and at this point even though we",
    "start": "1361200",
    "end": "1367500"
  },
  {
    "text": "still show a mapping function up here you really don't need one at this point because you're just talking to a single",
    "start": "1367500",
    "end": "1373650"
  },
  {
    "text": "end point you have one thing to maintain in with Aurora being a managed service a lot of that undifferentiated heavy",
    "start": "1373650",
    "end": "1380400"
  },
  {
    "text": "lifting like backups like high availability and scalability is managed",
    "start": "1380400",
    "end": "1385440"
  },
  {
    "text": "automatically for you so this all sounds great in concept but what if we were to",
    "start": "1385440",
    "end": "1392490"
  },
  {
    "text": "take a look at a demo and see this actually in practice what I have here is I have a database for a ticketing system",
    "start": "1392490",
    "end": "1400260"
  },
  {
    "start": "1395000",
    "end": "1601000"
  },
  {
    "text": "for sporting events if you look on the Left we have our reference data this is the master shard and so you can tell by",
    "start": "1400260",
    "end": "1407040"
  },
  {
    "text": "looking at the tables in here these are the reference tables they don't generally have a lot of data in them",
    "start": "1407040",
    "end": "1412650"
  },
  {
    "text": "relative to the other two shards which have ticket data and Purchase History data in them so those are very large and",
    "start": "1412650",
    "end": "1419970"
  },
  {
    "text": "you they may be partition maybe one of them is for baseball you know on the first shard and football on the second",
    "start": "1419970",
    "end": "1426240"
  },
  {
    "text": "shard or you know however however you decided to carve up the data so that you can distribute that load for your reads",
    "start": "1426240",
    "end": "1432150"
  },
  {
    "text": "and for your rights so right here we have our three shards the first one the",
    "start": "1432150",
    "end": "1438840"
  },
  {
    "text": "top one is the master shard the first thing we're going to do is we're gonna select that and as China was talking",
    "start": "1438840",
    "end": "1444750"
  },
  {
    "text": "about earlier we can say create an Aurora read replica so in here we want to go ahead and select the size of the",
    "start": "1444750",
    "end": "1451050"
  },
  {
    "text": "instance we're going to use for now we won't make it multi AZ we're gonna give it a name and then we're gonna scroll",
    "start": "1451050",
    "end": "1457980"
  },
  {
    "text": "down we'll select the VPC security group that it's in for now default and then we're going to accept the rest of these",
    "start": "1457980",
    "end": "1464010"
  },
  {
    "text": "default values for the time being in your case you may choose different values depending on your circumstance",
    "start": "1464010",
    "end": "1470280"
  },
  {
    "text": "we're now launching the replica you can see it's currently creating now it's available but now it's available and",
    "start": "1470280",
    "end": "1477390"
  },
  {
    "text": "it's in sync with my current master so now that that is in sync the next thing",
    "start": "1477390",
    "end": "1482520"
  },
  {
    "text": "we're going to do is we're going to promote that read replica and at this",
    "start": "1482520",
    "end": "1487800"
  },
  {
    "text": "point we now have our beachhead we've now migrated that master shard from our TS my sequel into our Aurora my",
    "start": "1487800",
    "end": "1495600"
  },
  {
    "text": "sequel cluster and we have an Aurora my sequel cluster to work with now in here",
    "start": "1495600",
    "end": "1501300"
  },
  {
    "text": "what we're gonna do is we're going to just stop that master in the previous master and the reason why is we still",
    "start": "1501300",
    "end": "1507300"
  },
  {
    "text": "want to hold onto that data until we're done with our migration it gives us you know a little bit of safe feeling to be",
    "start": "1507300",
    "end": "1512310"
  },
  {
    "text": "able to rollback if we should need to at this point the master is stopped and the next thing we're gonna do is we're gonna",
    "start": "1512310",
    "end": "1518400"
  },
  {
    "text": "create a parameter group and a parameter group is how you set a lot of things that you would normally set through",
    "start": "1518400",
    "end": "1523530"
  },
  {
    "text": "startup configurations and things like that in my sequel in this case what we want to do is we want to be able to",
    "start": "1523530",
    "end": "1528930"
  },
  {
    "text": "enable CDC change data capture within our within our other two shards and so",
    "start": "1528930",
    "end": "1535590"
  },
  {
    "text": "the way that we do that with with my sequel is we're gonna do that with bin log so we're gonna go ahead and turn off",
    "start": "1535590",
    "end": "1541530"
  },
  {
    "text": "the bin log checksum and we're gonna change the bin log format from mixed to row and Save Changes and so we now have",
    "start": "1541530",
    "end": "1551010"
  },
  {
    "text": "a new parameter group so now we're gonna go to each one of our shards shard 1 & 2",
    "start": "1551010",
    "end": "1556080"
  },
  {
    "text": "and we're gonna change the database parameter group and we want to check",
    "start": "1556080",
    "end": "1561450"
  },
  {
    "text": "apply immediately if you don't do this then this won't happen until your next maintenance cycle in RDS so we've just",
    "start": "1561450",
    "end": "1570570"
  },
  {
    "text": "we've just applied that for the first shard and so we're gonna go ahead we'll do that for the second shard now as well",
    "start": "1570570",
    "end": "1576090"
  },
  {
    "text": "again check apply immediately alright so",
    "start": "1576090",
    "end": "1581400"
  },
  {
    "text": "we've now applied that parameter group to both shards with some parameters depending on the parameter in question",
    "start": "1581400",
    "end": "1588420"
  },
  {
    "text": "you need to reboot the instances as well in this case when we're enabling bin log replication on RDS my sequel you do need",
    "start": "1588420",
    "end": "1595500"
  },
  {
    "text": "to reboot them so right now they're rebooting and now they're available",
    "start": "1595500",
    "end": "1600950"
  },
  {
    "text": "alright so now what we're going to do is we're connect to each one of those shards",
    "start": "1600950",
    "end": "1605990"
  },
  {
    "start": "1601000",
    "end": "1654000"
  },
  {
    "text": "right we've enabled bin log replication on both of those shards and so we need to make sure that we can we can keep the",
    "start": "1605990",
    "end": "1614180"
  },
  {
    "text": "bin logs on there for 24 hours right so that we don't we don't lose those and fall out of sync and so all we're doing",
    "start": "1614180",
    "end": "1621350"
  },
  {
    "text": "here normally you would need super privileges to modify how long you're maintaining bin logs since we don't",
    "start": "1621350",
    "end": "1627530"
  },
  {
    "text": "expose super privileges in RDS we instead have these helper functions like",
    "start": "1627530",
    "end": "1632840"
  },
  {
    "text": "this one right here that allows you to just set you know whatever that bin log retention period is that you need so in",
    "start": "1632840",
    "end": "1640190"
  },
  {
    "text": "this case we're just connecting to each one of them and we're just calling my sequel to RDS set configuration bin log",
    "start": "1640190",
    "end": "1646550"
  },
  {
    "text": "retention hours and setting it to 24 the net result is that both of those will keep those bin logs for 24 hours and we",
    "start": "1646550",
    "end": "1654950"
  },
  {
    "start": "1654000",
    "end": "1774000"
  },
  {
    "text": "exit from there and now we're into the DMS console in DMS we're gonna create a",
    "start": "1654950",
    "end": "1659990"
  },
  {
    "text": "replication instance we'll go ahead and give it a name we'll name it arora migration give it a description and then",
    "start": "1659990",
    "end": "1667340"
  },
  {
    "text": "we're gonna just accept the defaults for the time being we'll click create",
    "start": "1667340",
    "end": "1673840"
  },
  {
    "text": "replication instance it's creating and now it's available the next thing we",
    "start": "1673840",
    "end": "1679820"
  },
  {
    "text": "need to do is we need to create endpoints so it's important to note that this replication instance is really just",
    "start": "1679820",
    "end": "1685130"
  },
  {
    "text": "a special purpose ec2 instance whose job it is to move the data from your source",
    "start": "1685130",
    "end": "1690440"
  },
  {
    "text": "to your targets once we have this replication instance we are creating these endpoints in this case we're",
    "start": "1690440",
    "end": "1696440"
  },
  {
    "text": "creating a source endpoint for the first shard we're specifying that it's a my sequel source engine we give it the",
    "start": "1696440",
    "end": "1702920"
  },
  {
    "text": "server name the port to connect to optionally you can specify to use SSL so",
    "start": "1702920",
    "end": "1709040"
  },
  {
    "text": "that you're encrypting your data in flight and then we're going to click on run tests at the bottom and what this is",
    "start": "1709040",
    "end": "1715130"
  },
  {
    "text": "doing is establishing that that the replication instance can talk to that source so once that test is completed",
    "start": "1715130",
    "end": "1722240"
  },
  {
    "text": "and it's successful you know that we've now established that leg from your source database to the replication",
    "start": "1722240",
    "end": "1728600"
  },
  {
    "text": "instance so we're gonna go back in and we're gonna do the same thing again this time for the second shard the only thing",
    "start": "1728600",
    "end": "1735320"
  },
  {
    "text": "that's changing here really is we're a different endpoint identifier or name and we are giving it a different end",
    "start": "1735320",
    "end": "1742090"
  },
  {
    "text": "point but again run the test so at this point we now have our replication instance in place we have created end",
    "start": "1742090",
    "end": "1749260"
  },
  {
    "text": "points to both of the sources and now we need to create another end point to the target this one of course will point to",
    "start": "1749260",
    "end": "1755710"
  },
  {
    "text": "our newly created Aurora cluster specify the target engine as Aurora specify the server name the port",
    "start": "1755710",
    "end": "1763080"
  },
  {
    "text": "optionally ssl username and password and",
    "start": "1763080",
    "end": "1769980"
  },
  {
    "text": "then again we'll want to test this one as well so at this point we've",
    "start": "1769980",
    "end": "1776140"
  },
  {
    "start": "1774000",
    "end": "1892000"
  },
  {
    "text": "established connectivity all the way from both of our sources to the replication instance and from a replication instance to the target the",
    "start": "1776140",
    "end": "1782650"
  },
  {
    "text": "next thing we're going to do is create the task the task is what is actually going to move the data the task executes",
    "start": "1782650",
    "end": "1790150"
  },
  {
    "text": "on the replication instance and will actually move the data from it will read it from the source and write it to the",
    "start": "1790150",
    "end": "1795970"
  },
  {
    "text": "destination in this case we're saying migrate existing data and replicate ongoing changes we get a warning telling",
    "start": "1795970",
    "end": "1802630"
  },
  {
    "text": "us to go ahead and extend the bin log retention period for 24 hours we did",
    "start": "1802630",
    "end": "1807820"
  },
  {
    "text": "that just a couple of steps ago when we logged into those instances and in call that function we want to make sure that",
    "start": "1807820",
    "end": "1814810"
  },
  {
    "text": "we enable logging so DMS is very reliable works very well but in the off",
    "start": "1814810",
    "end": "1820240"
  },
  {
    "text": "chance that there something goes sideways you want to make sure that you're able to look through the log and find out exactly what happened what",
    "start": "1820240",
    "end": "1827140"
  },
  {
    "text": "we're doing here is we're saying that we're defining the tables that we want",
    "start": "1827140",
    "end": "1832630"
  },
  {
    "text": "to migrate so we're saying we're the schema name is DMS sample and well first before that we said where the DMS name",
    "start": "1832630",
    "end": "1839170"
  },
  {
    "text": "is DMS sample and then the table name is like a wild card so that means go ahead",
    "start": "1839170",
    "end": "1844420"
  },
  {
    "text": "and include everything then we want to move that so we want to move everything every table but then you saw we went",
    "start": "1844420",
    "end": "1850480"
  },
  {
    "text": "through we added another one that said except for where the table name is like person so now we've created one task for",
    "start": "1850480",
    "end": "1857920"
  },
  {
    "text": "shard number one so that's up it's running it's actively replicating data right now we're going back in we're",
    "start": "1857920",
    "end": "1864160"
  },
  {
    "text": "doing the same thing again for shard number two and we'll go through we're",
    "start": "1864160",
    "end": "1869260"
  },
  {
    "text": "going to enable logging again we come down to the table mappings this is where we're going to say schema",
    "start": "1869260",
    "end": "1875570"
  },
  {
    "text": "name is DMS sample table name is like wildcard add that in we're gonna again",
    "start": "1875570",
    "end": "1881000"
  },
  {
    "text": "say we're schema name is like DMS sample and the table name is like person then",
    "start": "1881000",
    "end": "1886970"
  },
  {
    "text": "we're gonna say exclude so do not include that create that task at this",
    "start": "1886970",
    "end": "1892910"
  },
  {
    "text": "point you see that there's one that's starting one that's creating now they're both in the starting status we'll give",
    "start": "1892910",
    "end": "1898940"
  },
  {
    "text": "it another second here and now they are both in the running status running and starting and eventually they both move",
    "start": "1898940",
    "end": "1906410"
  },
  {
    "text": "into the running state you can see the progress bar on the right indicating how far we've come along so now we're",
    "start": "1906410",
    "end": "1913370"
  },
  {
    "text": "capturing the ongoing changes here right it's not just a dump copy and load we want to we're gonna generate some other",
    "start": "1913370",
    "end": "1919370"
  },
  {
    "text": "traffic so what we're doing here is we've created a function on the on one of the shards to generate random ticket",
    "start": "1919370",
    "end": "1927169"
  },
  {
    "text": "activity so it's going to just create a whole bunch of new ticket orders in our",
    "start": "1927169",
    "end": "1932660"
  },
  {
    "text": "ticket ordering system so you can see that that's up and running and so now when we look at the table statistics you",
    "start": "1932660",
    "end": "1939200"
  },
  {
    "start": "1934000",
    "end": "1975000"
  },
  {
    "text": "can see in the table statistics on the all the way to the right you can see the total number of rows that have been",
    "start": "1939200",
    "end": "1944750"
  },
  {
    "text": "migrated and then what you can see is that the numbers under inserts and updates are also changing every time we",
    "start": "1944750",
    "end": "1952040"
  },
  {
    "text": "refresh and the reason for that is because we've already you can see in this in the percent complete at the top",
    "start": "1952040",
    "end": "1957679"
  },
  {
    "text": "we've moved a hundred percent of the original data and now we're capturing additional changes that are coming into",
    "start": "1957679",
    "end": "1964160"
  },
  {
    "text": "the system at this point we're ready to go ahead and shut down those other two",
    "start": "1964160",
    "end": "1969679"
  },
  {
    "text": "shards and start running all of our traffic off of the arora cluster itself",
    "start": "1969679",
    "end": "1975580"
  },
  {
    "start": "1975000",
    "end": "1991000"
  },
  {
    "text": "we have additional resources available to you online the Arora migration",
    "start": "1975580",
    "end": "1981230"
  },
  {
    "text": "handbook another one that's migrating your databases to Aurora and then an absolute must-read is the best practices",
    "start": "1981230",
    "end": "1988520"
  },
  {
    "text": "for my sequel to Aurora migrations so now that we've we have moved our data",
    "start": "1988520",
    "end": "1995059"
  },
  {
    "text": "into Amazon Aurora and we've consolidated our shards we've folded them all into a single Amazon Aurora",
    "start": "1995059",
    "end": "2001330"
  },
  {
    "text": "cluster now we now we have our database on there and our applique is running on there so the question now",
    "start": "2001330",
    "end": "2006850"
  },
  {
    "text": "is how do we optimize that workload that's running on Amazon Aurora I wanted",
    "start": "2006850",
    "end": "2014110"
  },
  {
    "start": "2012000",
    "end": "2076000"
  },
  {
    "text": "to use this slide again I know that we saw it earlier but I think that it's important to to reiterate the Amazon",
    "start": "2014110",
    "end": "2020260"
  },
  {
    "text": "Aurora is fundamentally different than stock my sequel in in many ways but",
    "start": "2020260",
    "end": "2025900"
  },
  {
    "text": "primarily in in the way that we handle the storage so when you're looking at an",
    "start": "2025900",
    "end": "2031330"
  },
  {
    "text": "Aurora instance you need to know that we don't store the pages or any data on the",
    "start": "2031330",
    "end": "2037660"
  },
  {
    "text": "instance itself all of that data is sent down to this shared storage volume and since we handle this very differently in",
    "start": "2037660",
    "end": "2045670"
  },
  {
    "text": "fact we don't even write pages out from from the master where you're doing the writes the only thing that we're writing",
    "start": "2045670",
    "end": "2051070"
  },
  {
    "text": "down to this storage volume are redo logs and then these these store it the storage volumes the nodes that make up",
    "start": "2051070",
    "end": "2057550"
  },
  {
    "text": "the storage volume are intelligent enough to take those redo logs and create pages on the fly as needed and so",
    "start": "2057550",
    "end": "2065138"
  },
  {
    "text": "since we're handling the i/o in such a completely different way you know when",
    "start": "2065139",
    "end": "2070300"
  },
  {
    "text": "you're when you're thinking about how do I normally tune and performance tune of my sequel database those things don't",
    "start": "2070300",
    "end": "2078280"
  },
  {
    "start": "2076000",
    "end": "2105000"
  },
  {
    "text": "apply so the settings that we have listed up here our settings that if you",
    "start": "2078280",
    "end": "2083770"
  },
  {
    "text": "were otherwise running a my sequel database that was running on a block store instance EBS volumes ephemeral",
    "start": "2083770",
    "end": "2091450"
  },
  {
    "text": "volumes on-premise these would be these would be parameters that you very well",
    "start": "2091450",
    "end": "2097030"
  },
  {
    "text": "may be interested in tuning they'd have they have zero impact on Amazon Aurora because of how we handle that data",
    "start": "2097030",
    "end": "2104230"
  },
  {
    "text": "differently additionally we have you know we have the advantage of running an",
    "start": "2104230",
    "end": "2110470"
  },
  {
    "text": "enormous fleet right of databases we have all these Aurora instances that are",
    "start": "2110470",
    "end": "2115510"
  },
  {
    "text": "that you know are running all of the time and you know we we know that you",
    "start": "2115510",
    "end": "2120550"
  },
  {
    "text": "know if the performance you know what the performance profile looks like right and how to best tune an Aurora instance",
    "start": "2120550",
    "end": "2127810"
  },
  {
    "text": "and so we've done that we've taken those best practices and we have pre tuned these settings that you would otherwise",
    "start": "2127810",
    "end": "2134700"
  },
  {
    "text": "normally tune and these settings are the way they're tuned has a lot to do with the instance type",
    "start": "2134700",
    "end": "2140650"
  },
  {
    "text": "in the instance size and so you'll find if you look at these that depending on what type of instance you have in the",
    "start": "2140650",
    "end": "2147369"
  },
  {
    "text": "size which has a direct impact of course on how much memory CPUs etc that are",
    "start": "2147369",
    "end": "2152860"
  },
  {
    "text": "part of that instance these will be tuned specifically for those now when",
    "start": "2152860",
    "end": "2160210"
  },
  {
    "text": "we're talking about the subject of debugging or performance tuning I think",
    "start": "2160210",
    "end": "2166270"
  },
  {
    "text": "that it's it's very important to ask yourself the very first question ask yourself is is the application running",
    "start": "2166270",
    "end": "2172390"
  },
  {
    "text": "well right a lot of times you know people will have a tendency to sort of",
    "start": "2172390",
    "end": "2178600"
  },
  {
    "text": "preemptively tune a database engine or an application or anything else so I",
    "start": "2178600",
    "end": "2183730"
  },
  {
    "text": "would suggest that you know the very first thing you ask is is the application running well if it is well",
    "start": "2183730",
    "end": "2189310"
  },
  {
    "text": "then we're good we don't really need to change anything at all right if it's not then the next question you",
    "start": "2189310",
    "end": "2194410"
  },
  {
    "text": "want to ask yourself is is the application not performing well because of the database because there of course",
    "start": "2194410",
    "end": "2200320"
  },
  {
    "text": "a number of different moving parts and so we want to isolate you know that it is in fact the database that is the",
    "start": "2200320",
    "end": "2207070"
  },
  {
    "text": "source of the problem so how do you do that well you know the database you know at the end of the day the the point of",
    "start": "2207070",
    "end": "2213609"
  },
  {
    "text": "the database is to is to store data in to retrieve data right and so the metrics that that will give you probably",
    "start": "2213609",
    "end": "2220780"
  },
  {
    "text": "the best if for most workloads give you the best idea of how efficiently your database is doing that is select latency",
    "start": "2220780",
    "end": "2227170"
  },
  {
    "text": "select throughput DML latency and DML throughput well these are saying is how",
    "start": "2227170",
    "end": "2233020"
  },
  {
    "text": "quickly when I do a selector or a DML statement how quickly is that coming back that's the latency of course right",
    "start": "2233020",
    "end": "2240040"
  },
  {
    "text": "and then the throughput is how many of these commands how many of these queries are being executed in parallel right and",
    "start": "2240040",
    "end": "2247359"
  },
  {
    "text": "so since we have these numbers then the next question is well what are good numbers you know what what is a good",
    "start": "2247359",
    "end": "2253720"
  },
  {
    "text": "select latency for example and again that will depend very much on what your particular workload is so what I would",
    "start": "2253720",
    "end": "2260440"
  },
  {
    "text": "suggest is that when you when your application is up and running and is performing well to baseline the system",
    "start": "2260440",
    "end": "2268210"
  },
  {
    "text": "to say this is what my select latency is when the vacation is running well this is what my",
    "start": "2268210",
    "end": "2274190"
  },
  {
    "text": "throughput looks like when the application is running well so in that way if the number deviates significantly",
    "start": "2274190",
    "end": "2279650"
  },
  {
    "text": "from what you know to be a good number then you know okay now we've got a",
    "start": "2279650",
    "end": "2285380"
  },
  {
    "text": "problem right so if we've determined that we actually do have a problem we want to look into it then we need to",
    "start": "2285380",
    "end": "2292070"
  },
  {
    "text": "locate the bottleneck right and so frequently there are four you'll notice",
    "start": "2292070",
    "end": "2297620"
  },
  {
    "text": "there are only three listed up here but there are typically four points of contention right one is the CPU",
    "start": "2297620",
    "end": "2303730"
  },
  {
    "text": "sometimes you have workloads that drive the CPU through the roof and and so in",
    "start": "2303730",
    "end": "2309590"
  },
  {
    "text": "the workload is very CPU bound sometimes it's memory you're you're you don't have",
    "start": "2309590",
    "end": "2314930"
  },
  {
    "text": "enough memory to you know for your buffer pool or for your results cache or",
    "start": "2314930",
    "end": "2320030"
  },
  {
    "text": "for anything else right sometimes it's the network and then the fourth one that",
    "start": "2320030",
    "end": "2326000"
  },
  {
    "text": "you don't see on here is disk i/o you're not going to have disk i/o as is a",
    "start": "2326000",
    "end": "2333020"
  },
  {
    "text": "bottleneck with Amazon Arora because like chyann was saying if you have a cluster you know your data is actually",
    "start": "2333020",
    "end": "2341120"
  },
  {
    "text": "split off into ten gigabytes segments in each one of those ten gigabytes segments",
    "start": "2341120",
    "end": "2346280"
  },
  {
    "text": "is split across six different actual storage nodes so depending on the size",
    "start": "2346280",
    "end": "2352040"
  },
  {
    "text": "of your cluster you very likely have hundreds if not thousands of storage",
    "start": "2352040",
    "end": "2357230"
  },
  {
    "text": "nodes that have locally attached SSD storage that is very rapidly able to",
    "start": "2357230",
    "end": "2363500"
  },
  {
    "text": "serve up your your disk i/o needs what's more likely is perhaps the network",
    "start": "2363500",
    "end": "2369080"
  },
  {
    "text": "throughput because again Amazon Arora is communicating with all these storage nodes across the network and that's why",
    "start": "2369080",
    "end": "2375050"
  },
  {
    "text": "I personally was particularly most excited about the release of the are four types just a few weeks ago because",
    "start": "2375050",
    "end": "2382400"
  },
  {
    "text": "the are for the r4 16 Excel yes it does have twice the met twice the memory and",
    "start": "2382400",
    "end": "2388190"
  },
  {
    "text": "twice the CPU of the r38 Excel but it also has two and a half times as much",
    "start": "2388190",
    "end": "2393230"
  },
  {
    "text": "network throughput 25 gigabits per second and so that allows us to drive",
    "start": "2393230",
    "end": "2398410"
  },
  {
    "text": "nearly nearly a quarter million writes per second on a single hour force",
    "start": "2398410",
    "end": "2405410"
  },
  {
    "text": "sixteen Excel that is due in very large part to that very large pipe that we have and so when you're looking at these",
    "start": "2405410",
    "end": "2412850"
  },
  {
    "text": "you know there are two ways to go one way that you can address these if you identify that any one of these is your",
    "start": "2412850",
    "end": "2417950"
  },
  {
    "text": "bottleneck is to resize the instance right you can you can go up in instant size and that's sort of the quick way",
    "start": "2417950",
    "end": "2424550"
  },
  {
    "text": "the easy way to address one of these bottlenecks sometimes though it's",
    "start": "2424550",
    "end": "2429680"
  },
  {
    "text": "important to actually identify what the problematic queries are or what it is that is driving that that resource",
    "start": "2429680",
    "end": "2437540"
  },
  {
    "text": "utilization and in your pushing it and so for that you know we generally suggest that you would use the same my",
    "start": "2437540",
    "end": "2444710"
  },
  {
    "text": "sequel tools that you use today to diagnose performance problems in your existing my sequel environment again",
    "start": "2444710",
    "end": "2451130"
  },
  {
    "text": "it's very important to remember that Aurora my sequel is as far as the application is concerned my sequel five",
    "start": "2451130",
    "end": "2458810"
  },
  {
    "text": "point six do we do a lot of stuff on the backend that really improves performance but as far as the wire compatibility and",
    "start": "2458810",
    "end": "2466910"
  },
  {
    "text": "the tools that work with it it's it is still my sequel five point six so when",
    "start": "2466910",
    "end": "2473990"
  },
  {
    "start": "2472000",
    "end": "2658000"
  },
  {
    "text": "were some other things to consider you know chyann was talking about doing migrations and he talked a lot about",
    "start": "2473990",
    "end": "2480070"
  },
  {
    "text": "tuning the client those settings are great for migrations but they're also",
    "start": "2480070",
    "end": "2485270"
  },
  {
    "text": "just as equally as important for running your ongoing workloads so you want to",
    "start": "2485270",
    "end": "2491240"
  },
  {
    "text": "make sure that you tune the client network right with the RPS you know it",
    "start": "2491240",
    "end": "2496250"
  },
  {
    "text": "you want it you want to make sure that you have those settings configured so that you are maximizing the throughput",
    "start": "2496250",
    "end": "2501740"
  },
  {
    "text": "from your client you want to make sure that you batch statements to the server and what do I mean by that I don't mean",
    "start": "2501740",
    "end": "2508040"
  },
  {
    "text": "that every statement needs to be you know a thousand you know records at a",
    "start": "2508040",
    "end": "2513080"
  },
  {
    "text": "time they're being put in but you know with any relational database system you know they they work best on sets of data",
    "start": "2513080",
    "end": "2520070"
  },
  {
    "text": "a great example would be if you are going to insert a bunch of data into a table in a relational engine you",
    "start": "2520070",
    "end": "2526880"
  },
  {
    "text": "obviously want to do that with a number of them at once rather than singleton inserts the singleton inserts on really",
    "start": "2526880",
    "end": "2532910"
  },
  {
    "text": "any relational engine will always be slower and you also want to minimize that network chattiness that's",
    "start": "2532910",
    "end": "2538750"
  },
  {
    "text": "something else that you can address by when possible batching commands together",
    "start": "2538750",
    "end": "2544020"
  },
  {
    "text": "another thing to look at when we when we are considering a memory which was one of the other potential bottlenecks is",
    "start": "2544020",
    "end": "2550720"
  },
  {
    "text": "the query cache so in my sequel 5.6 in my sequel and also in Aurora there is a",
    "start": "2550720",
    "end": "2557800"
  },
  {
    "text": "query cache where when you issue a select query the data is retrieved the query is satisfied it's returned to the",
    "start": "2557800",
    "end": "2564280"
  },
  {
    "text": "client and then that that result that query and that result are stored in",
    "start": "2564280",
    "end": "2569350"
  },
  {
    "text": "memory and in some cases where that query is likely to be issued again",
    "start": "2569350",
    "end": "2574860"
  },
  {
    "text": "that's a good thing because the next time that that exact query byte for byte is issued to the server then there's no",
    "start": "2574860",
    "end": "2582760"
  },
  {
    "text": "reason for the server to query the server doesn't go back in to the engine and query anything it just returns the",
    "start": "2582760",
    "end": "2589090"
  },
  {
    "text": "same result set back a lot of times but you don't you don't you don't get that",
    "start": "2589090",
    "end": "2595150"
  },
  {
    "text": "back maybe your workload is not one that that works well with that maybe you you",
    "start": "2595150",
    "end": "2601300"
  },
  {
    "text": "have a very write heavy workload maybe there is a high degree of change in your",
    "start": "2601300",
    "end": "2606400"
  },
  {
    "text": "queries or select queries that are coming in and so when you're looking at the query cache you have to ask yourself",
    "start": "2606400",
    "end": "2613420"
  },
  {
    "text": "the question what is the payback that I'm getting out of using the query cache memory is like gold in a relational",
    "start": "2613420",
    "end": "2620950"
  },
  {
    "text": "database engine because pages database pages that are read off the disk are kept in memory in a buffer pool until",
    "start": "2620950",
    "end": "2628380"
  },
  {
    "text": "until they need to be flushed out usually it's because of memory pressure you don't have enough memory when you're",
    "start": "2628380",
    "end": "2634390"
  },
  {
    "text": "using the query cache you're carving off a chunk of your memory to handle that",
    "start": "2634390",
    "end": "2639490"
  },
  {
    "text": "query cache and if you're not getting your return on investment from that query cache you may want to consider",
    "start": "2639490",
    "end": "2645880"
  },
  {
    "text": "disabling the query cache and then releasing that memory back to the buffer pool where those database pages that",
    "start": "2645880",
    "end": "2651670"
  },
  {
    "text": "you're reading in can be stored which will in turn mean less trips back to disk index statistics with my sequel",
    "start": "2651670",
    "end": "2662140"
  },
  {
    "start": "2658000",
    "end": "2742000"
  },
  {
    "text": "there is an option to use persistent statistics and we recommend that you do this and we also recommend that you",
    "start": "2662140",
    "end": "2669340"
  },
  {
    "text": "adjust the sample page eyes that you use when you create these persistent statistics the default is 20",
    "start": "2669340",
    "end": "2676700"
  },
  {
    "text": "pages if you have a 20 page table that's fantastic you'll have a very",
    "start": "2676700",
    "end": "2681890"
  },
  {
    "text": "representative measure of you know what what statistics are for your table if",
    "start": "2681890",
    "end": "2686900"
  },
  {
    "text": "you have a 5 terabyte table then those",
    "start": "2686900",
    "end": "2691940"
  },
  {
    "text": "20 pages may not be very representative of the actual data in that table and so",
    "start": "2691940",
    "end": "2697280"
  },
  {
    "text": "you know you wanna you want to play around with that number a little bit but don't be afraid to dial that up from its",
    "start": "2697280",
    "end": "2703610"
  },
  {
    "text": "default of 20 so that you can get what you feel is an adequate representation of the of the data that's in your actual",
    "start": "2703610",
    "end": "2711020"
  },
  {
    "text": "tables query plans we want to make sure I mean this is old-school you know sort",
    "start": "2711020",
    "end": "2717020"
  },
  {
    "text": "of 101 DBA managing database you want to look at the the explained plan for your",
    "start": "2717020",
    "end": "2722120"
  },
  {
    "text": "queries especially if you're able to identify that there is a problematic query you're gonna want to take a look",
    "start": "2722120",
    "end": "2727430"
  },
  {
    "text": "at that and find out why is it problematic am I missing an index is there something else that I could do to",
    "start": "2727430",
    "end": "2733100"
  },
  {
    "text": "improve the performance here which might save me CPU or i/o or whatever and then",
    "start": "2733100",
    "end": "2738560"
  },
  {
    "text": "if necessary don't be afraid to use optimizer hints as well for i/o bound",
    "start": "2738560",
    "end": "2745070"
  },
  {
    "start": "2742000",
    "end": "2893000"
  },
  {
    "text": "workloads the buffer cache hit ratio is the metric you want to look at like I was saying earlier the buffer cache or",
    "start": "2745070",
    "end": "2751910"
  },
  {
    "text": "buffer pool is a segment of memory usually the largest segment of memory in",
    "start": "2751910",
    "end": "2757520"
  },
  {
    "text": "a database system like this where when those pages are read off of the disk they're stored in memory so that the",
    "start": "2757520",
    "end": "2764390"
  },
  {
    "text": "database server just has to hit them from memory and doesn't have to make that expensive trip back to disk",
    "start": "2764390",
    "end": "2769750"
  },
  {
    "text": "regardless of the the engine that you're running on the buffer cache a ratio is says this is the percentage of times I",
    "start": "2769750",
    "end": "2777020"
  },
  {
    "text": "was able to find those pages in memory and did not have to go back to disk to satisfy the query we generally look at",
    "start": "2777020",
    "end": "2783440"
  },
  {
    "text": "numbers 99% or higher is what we're looking for are on that maybe ninety",
    "start": "2783440",
    "end": "2788810"
  },
  {
    "text": "nine and a half percent or higher a very high number in there if you when we say",
    "start": "2788810",
    "end": "2794240"
  },
  {
    "text": "upgrade if needed we're saying maybe you need to use a larger instance if you use a larger instance you have more memory",
    "start": "2794240",
    "end": "2800390"
  },
  {
    "text": "your buffer pool is larger you can fit more pages into memory and so you will",
    "start": "2800390",
    "end": "2805609"
  },
  {
    "text": "likely have a higher buffer cache hit ratio there are a number of features",
    "start": "2805609",
    "end": "2811700"
  },
  {
    "text": "that come with my sequel and a lot of those features are still available in Aurora binary logging general logs and a",
    "start": "2811700",
    "end": "2819259"
  },
  {
    "text": "number of other features they have different purposes I would caution you",
    "start": "2819259",
    "end": "2825710"
  },
  {
    "text": "to consider why you're enabling or using a given feature before you do so a lot",
    "start": "2825710",
    "end": "2831230"
  },
  {
    "text": "of times they have additional impact to performance if you are using Aurora by",
    "start": "2831230",
    "end": "2838009"
  },
  {
    "text": "itself and you're using Aurora replicas rather than replica is outside of the",
    "start": "2838009",
    "end": "2843109"
  },
  {
    "text": "cluster you don't need to use bin log replication Aurora does not use bin log",
    "start": "2843109",
    "end": "2848239"
  },
  {
    "text": "replication to to communicate with the read replicas in an Aurora cluster the",
    "start": "2848239",
    "end": "2853849"
  },
  {
    "text": "only time that you need to use bin log replication or enable it is if you're copying data outside of the cluster and",
    "start": "2853849",
    "end": "2860869"
  },
  {
    "text": "you might be doing that because you are replicating to another my sequel instance maybe you're replicating to another Aurora cluster there are",
    "start": "2860869",
    "end": "2867200"
  },
  {
    "text": "different reasons for that but generally you don't need it if you're just operating within one cluster logs take",
    "start": "2867200",
    "end": "2874369"
  },
  {
    "text": "advantage of the slow query log move long-running queries to the read replicas rather than running them on the",
    "start": "2874369",
    "end": "2880940"
  },
  {
    "text": "master those are just a couple of other ideas that you can use to to offload",
    "start": "2880940",
    "end": "2886670"
  },
  {
    "text": "some of that traffic into you know identify what are some of the problematic queries as far as the",
    "start": "2886670",
    "end": "2895880"
  },
  {
    "start": "2893000",
    "end": "3021000"
  },
  {
    "text": "queries and transactions you can use show process list and show nodb status just like you would with my sequel like",
    "start": "2895880",
    "end": "2902749"
  },
  {
    "text": "I said you know we're still working with the nodb engine it's still you know my sequel wire compatible and then another",
    "start": "2902749",
    "end": "2910009"
  },
  {
    "text": "thing that I think is frequently overlooked is reaaargh attacking the application and that sounds perhaps a",
    "start": "2910009",
    "end": "2916640"
  },
  {
    "text": "little bit daunting but it doesn't have to be sometimes I've worked with some customers that you know they are they're",
    "start": "2916640",
    "end": "2923450"
  },
  {
    "text": "using they're using a relational engine in a way that maybe that that particular",
    "start": "2923450",
    "end": "2928579"
  },
  {
    "text": "workload would be better suited on a different type of database engine maybe a no sequel engine maybe a data",
    "start": "2928579",
    "end": "2934519"
  },
  {
    "text": "warehouse you know something else so you know consider that consider you know how you're using",
    "start": "2934519",
    "end": "2939800"
  },
  {
    "text": "it Amazon Arora where it really shines where it really excels is with a lot of",
    "start": "2939800",
    "end": "2946340"
  },
  {
    "text": "parallel queries you know the benchmark we talk about when we talk about the performance being five times better than",
    "start": "2946340",
    "end": "2951860"
  },
  {
    "text": "stock my sequel we're not saying that a single query is faster we're saying that we can handle five times the query",
    "start": "2951860",
    "end": "2959420"
  },
  {
    "text": "throughput in parallel so five hundred six hundred thousand selects per second",
    "start": "2959420",
    "end": "2965090"
  },
  {
    "text": "in parallel two hundred two hundred and thirty thousand in DML statements you",
    "start": "2965090",
    "end": "2970190"
  },
  {
    "text": "know writes per second in parallel right that's that's where Amazon Arora really",
    "start": "2970190",
    "end": "2975830"
  },
  {
    "text": "shines and that's that you know we always want to use the best tool for the best job right transaction isolation",
    "start": "2975830",
    "end": "2982970"
  },
  {
    "text": "level this is another thing to consider out of out of the box Arora uses repeatable read for most cases that's",
    "start": "2982970",
    "end": "2992119"
  },
  {
    "text": "that's fine depending on your application and your needs you may use a",
    "start": "2992119",
    "end": "2997130"
  },
  {
    "text": "lower transaction isolation level maybe read committed read uncommitted I would",
    "start": "2997130",
    "end": "3002380"
  },
  {
    "text": "stress that like with any other feature that that deviates from you know the",
    "start": "3002380",
    "end": "3007960"
  },
  {
    "text": "defaults that you you fully understand what it means to change the transaction isolation level and what impact that",
    "start": "3007960",
    "end": "3013990"
  },
  {
    "text": "will have your application but in many scenarios that can actually lead to a performance improvement as well so we've",
    "start": "3013990",
    "end": "3023050"
  },
  {
    "start": "3021000",
    "end": "3036000"
  },
  {
    "text": "moved all of our data into Aurora we're up and running we have we've got everything tuned everything is coming",
    "start": "3023050",
    "end": "3029440"
  },
  {
    "text": "along the next thing we want to do is look at auditing monitoring in managing",
    "start": "3029440",
    "end": "3034510"
  },
  {
    "text": "this Aurora cluster on an ongoing basis right so database activity monitoring",
    "start": "3034510",
    "end": "3039910"
  },
  {
    "start": "3036000",
    "end": "3099000"
  },
  {
    "text": "you know currently with Amazon Aurora audit logs can be written directly to",
    "start": "3039910",
    "end": "3046000"
  },
  {
    "text": "cloud watch and when they're written a cloud watch if you are familiar with have used cloud watch before you know",
    "start": "3046000",
    "end": "3051700"
  },
  {
    "text": "the cloud watch logs also integrates with AWS lambda so lambda could allow",
    "start": "3051700",
    "end": "3057910"
  },
  {
    "text": "you you could potentially respond to specific events that are happening in",
    "start": "3057910",
    "end": "3063010"
  },
  {
    "text": "your logs in your audit logs programmatically without having to do anything manually in addition you can",
    "start": "3063010",
    "end": "3070240"
  },
  {
    "text": "create alerts just as part of cloud watch itself so that maybe you receive alerts through SNS when a",
    "start": "3070240",
    "end": "3077230"
  },
  {
    "text": "certain event happens in your logs so you can automate a lot of that you can also take those logs and export them to",
    "start": "3077230",
    "end": "3084849"
  },
  {
    "text": "s3 and when you export them to s3 then you can use Amazon Athena or Amazon",
    "start": "3084849",
    "end": "3090880"
  },
  {
    "text": "quick site to further analyze those logs and you know maybe extract other",
    "start": "3090880",
    "end": "3096430"
  },
  {
    "text": "information out of those as as you need this right here you know I know that",
    "start": "3096430",
    "end": "3102280"
  },
  {
    "text": "it's a lot of text like Cheyenne was saying this will all be available online for you to to view at your leisure but",
    "start": "3102280",
    "end": "3109690"
  },
  {
    "text": "this is just a simple bash script that exports those cloud watch logs into an",
    "start": "3109690",
    "end": "3115330"
  },
  {
    "text": "s3 bucket it's pretty straightforward it's not that many lines of code and it has comments in it so it's it's a pretty",
    "start": "3115330",
    "end": "3121930"
  },
  {
    "text": "pretty easy thing to do to export those audit logs into s3 we have a couple of",
    "start": "3121930",
    "end": "3129040"
  },
  {
    "start": "3127000",
    "end": "3152000"
  },
  {
    "text": "blogs that I would recommend that you look into that will detail this a little",
    "start": "3129040",
    "end": "3134140"
  },
  {
    "text": "bit more the first one it is monitoring Amazon Aurora audit events with Amazon Cloud Watch the second one is you can",
    "start": "3134140",
    "end": "3142300"
  },
  {
    "text": "all the treat it yourself it's I don't want to read it out loud it's it's a long title but in short this will show",
    "start": "3142300",
    "end": "3148089"
  },
  {
    "text": "you how to do exactly what we were just discussing in the previous slide the",
    "start": "3148089",
    "end": "3153910"
  },
  {
    "start": "3152000",
    "end": "3465000"
  },
  {
    "text": "next thing I want to talk about is Aurora read replicas right so you know there's that picture again with the",
    "start": "3153910",
    "end": "3159760"
  },
  {
    "text": "shared storage volume and we've got the primary and the replicas on there I can't emphasize enough you know what a",
    "start": "3159760",
    "end": "3167140"
  },
  {
    "text": "game-changer this is for a lot of our customers because traditionally in this",
    "start": "3167140",
    "end": "3172480"
  },
  {
    "text": "type of a scenario you would have a primary and then you would have some read replicas and so what happens if you",
    "start": "3172480",
    "end": "3179230"
  },
  {
    "text": "want to have a read replicas with my sequel well you need to do a dump of the data you need to copy it to that read",
    "start": "3179230",
    "end": "3184869"
  },
  {
    "text": "replica you need to load it and then you need to apply bin logs to it until it gets caught up in depending on the size",
    "start": "3184869",
    "end": "3191020"
  },
  {
    "text": "of the initial data set depending on the volume of write activity you know which",
    "start": "3191020",
    "end": "3196119"
  },
  {
    "text": "then impacts the size of the binary logs that could take hours it could take days",
    "start": "3196119",
    "end": "3202330"
  },
  {
    "text": "it could take a very long time that means that you have to have those reed replicas online all of the",
    "start": "3202330",
    "end": "3208329"
  },
  {
    "text": "time you don't you don't just arbitrarily spin up reed replicas and tear them down because it takes too much",
    "start": "3208329",
    "end": "3215319"
  },
  {
    "text": "effort to spin them up to begin with additionally depending on how much right",
    "start": "3215319",
    "end": "3221380"
  },
  {
    "text": "throughput you have how many changes are being made to that database the binary log could fall very far behind binary",
    "start": "3221380",
    "end": "3227950"
  },
  {
    "text": "log application and 5.6 is a single threaded operation so if you're generating a bunch of traffic on your",
    "start": "3227950",
    "end": "3234069"
  },
  {
    "text": "master and you copy all those bin logs over to your reed replicas you're still applying them one at a time in a single",
    "start": "3234069",
    "end": "3241479"
  },
  {
    "text": "thread on that reed replica and so that you know it's not uncommon for redraft",
    "start": "3241479",
    "end": "3246729"
  },
  {
    "text": "Lucas to be minutes where hours or again potentially days behind depending on",
    "start": "3246729",
    "end": "3252279"
  },
  {
    "text": "what that right throughput is with Amazon Aurora we don't use BIM logs instead we write to the shared storage",
    "start": "3252279",
    "end": "3257410"
  },
  {
    "text": "volume and so when we bring a read replicas online when we bring an Amazon replicas online it's just a compute head",
    "start": "3257410",
    "end": "3265349"
  },
  {
    "text": "so the time that it takes to bring an Amazon replica an Aurora replica online",
    "start": "3265349",
    "end": "3271450"
  },
  {
    "text": "is the time that it takes to boot up that ec2 instance because when that instance comes online it just attaches",
    "start": "3271450",
    "end": "3278410"
  },
  {
    "text": "to that already existing shared storage volume and is able to start taking traffic usually within we'll call it a",
    "start": "3278410",
    "end": "3285999"
  },
  {
    "text": "minute so we've just gone from taking you know hours to set up a read replicas",
    "start": "3285999",
    "end": "3292210"
  },
  {
    "text": "to about a minute so that's very powerful another thing is is that since",
    "start": "3292210",
    "end": "3297789"
  },
  {
    "text": "we're using this shared storage volume we're not dependent on the bin log our our average read our average Amazon",
    "start": "3297789",
    "end": "3305380"
  },
  {
    "text": "Aurora replicas latency is 10 to 20 milliseconds that is regardless of what",
    "start": "3305380",
    "end": "3312519"
  },
  {
    "text": "your write throughput is so you could have as your master an hour for 16x large and just be hammering that with",
    "start": "3312519",
    "end": "3319479"
  },
  {
    "text": "tons of traffic tons of write activity and then have your replicas be only a",
    "start": "3319479",
    "end": "3325869"
  },
  {
    "text": "handful of milliseconds behind I mean that that enables entirely new workloads",
    "start": "3325869",
    "end": "3332019"
  },
  {
    "text": "altogether I have some customers that have said you know we couldn't leave Aurora not because we can't get our data out",
    "start": "3332019",
    "end": "3338289"
  },
  {
    "text": "but because there's no another tool around that will give us read replicas with that that small of",
    "start": "3338289",
    "end": "3345840"
  },
  {
    "text": "replicas lag now to add on top of this we just recently added auto scaling for",
    "start": "3345840",
    "end": "3353980"
  },
  {
    "text": "Aurora replicas and so you know again it wouldn't be practical to auto scale my",
    "start": "3353980",
    "end": "3360430"
  },
  {
    "text": "sequel read replicas because it takes so long to spin them up since it only takes about a minute or two to spin up a",
    "start": "3360430",
    "end": "3368800"
  },
  {
    "text": "replica in Aurora then we're able to automatically scale those and add",
    "start": "3368800",
    "end": "3374200"
  },
  {
    "text": "additional read replicas behind a load balanced reader endpoint when I say load",
    "start": "3374200",
    "end": "3379450"
  },
  {
    "text": "balance we use DNS round robin so every time that you hit that end point you'll",
    "start": "3379450",
    "end": "3384850"
  },
  {
    "text": "get a different IP address it is worth noting that in you know going back to",
    "start": "3384850",
    "end": "3390580"
  },
  {
    "text": "the configuring the client configuration DNS caching is something to pay very",
    "start": "3390580",
    "end": "3396520"
  },
  {
    "text": "close attention to when you're using Aurora because you know we manage the DNS for you with that reader endpoint",
    "start": "3396520",
    "end": "3402940"
  },
  {
    "text": "for example it's it's an alias it's a dns alias we have all of the nodes that sit behind it and our TTL is very short",
    "start": "3402940",
    "end": "3410470"
  },
  {
    "text": "it's only a couple of seconds but if your client application is caching dns",
    "start": "3410470",
    "end": "3415540"
  },
  {
    "text": "entries for you know 30 seconds a minute or whatever it is then that will make it",
    "start": "3415540",
    "end": "3421150"
  },
  {
    "text": "difficult when we're dynamically you know adding additional readers or in the event of a failover because in the event",
    "start": "3421150",
    "end": "3427930"
  },
  {
    "text": "of a failover we're going to take one of your read replicas that you specify you can specify the failover order and we",
    "start": "3427930",
    "end": "3434380"
  },
  {
    "text": "will swap that in as the new master so it's important that you're that you're either not caching dns on your client or",
    "start": "3434380",
    "end": "3441850"
  },
  {
    "text": "that you are dialing that number down to a very low number and that is all that",
    "start": "3441850",
    "end": "3450430"
  },
  {
    "text": "we have for today I would encourage you to fill out your your surveys for this session and China",
    "start": "3450430",
    "end": "3458260"
  },
  {
    "text": "and I will be around to answer any questions if anybody has any questions thank you [Applause]",
    "start": "3458260",
    "end": "3467450"
  }
]
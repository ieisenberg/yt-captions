[
  {
    "text": "good afternoon and welcome to day three of green when 2016 we have delighted to be here to talk",
    "start": "1879",
    "end": "8970"
  },
  {
    "text": "about building real-time streaming analytics using AWS services my name is",
    "start": "8970",
    "end": "15210"
  },
  {
    "text": "Radhika Ravi Rana I'm a Solutions Architect based in Atlanta and joining me today on stage is Nabil Zaman",
    "start": "15210",
    "end": "21769"
  },
  {
    "text": "software engineer from Quantcast I'd",
    "start": "21769",
    "end": "28170"
  },
  {
    "text": "like to begin this session with a quick poll how many of you are currently using",
    "start": "28170",
    "end": "33980"
  },
  {
    "text": "Kinesis in your environments today Wow",
    "start": "33980",
    "end": "39660"
  },
  {
    "text": "it's almost half the room it's exciting guys I'm sure you'll find this in session informated so I'd like to start",
    "start": "39660",
    "end": "46260"
  },
  {
    "text": "the session by giving you a quick primer on the Amazon Kinesis platform and then",
    "start": "46260",
    "end": "53760"
  },
  {
    "text": "really expose you to some real-time architectures billed by some customers using AWS services and then Nabil will",
    "start": "53760",
    "end": "62010"
  },
  {
    "text": "walk through a journey that they have gone through building real-time streaming campaign analytics using AWS services",
    "start": "62010",
    "end": "69299"
  },
  {
    "text": "from the lens of a practitioner so with that let's get started",
    "start": "69299",
    "end": "75649"
  },
  {
    "text": "Amazon Kinesis started off as a single service launched back in 2013 and has",
    "start": "75770",
    "end": "82439"
  },
  {
    "text": "evolved into a platform now comprising of three different services we have",
    "start": "82439",
    "end": "88439"
  },
  {
    "text": "Amazon Kinesis streams which is a service that lets you continuously",
    "start": "88439",
    "end": "93630"
  },
  {
    "text": "capture terabytes of data per hour from hundreds of sources and process the data",
    "start": "93630",
    "end": "99930"
  },
  {
    "text": "in real time and also specify a destination if that's what you choose to",
    "start": "99930",
    "end": "105750"
  },
  {
    "text": "do for developers who really appreciate",
    "start": "105750",
    "end": "111119"
  },
  {
    "text": "or like the convenience of their data being sent to a specific destination we",
    "start": "111119",
    "end": "118229"
  },
  {
    "text": "have built Kinesis firehose and the newest member of the Kinesis family is",
    "start": "118229",
    "end": "123990"
  },
  {
    "text": "Amazon analytics that lets you run sequel queries ANSI standard sequel",
    "start": "123990",
    "end": "129450"
  },
  {
    "text": "queries on streaming data so let's stick look at some of the highlights of each",
    "start": "129450",
    "end": "134970"
  },
  {
    "text": "of these services kinases streams is actually designed with the goal of",
    "start": "134970",
    "end": "140700"
  },
  {
    "text": "making it really simple and easy for developers to start writing streaming applications it's a service that lets",
    "start": "140700",
    "end": "149640"
  },
  {
    "text": "you create a stream and simply set a capacity that you wish in terms of",
    "start": "149640",
    "end": "156150"
  },
  {
    "text": "shards and once you set your capacity you can scale up or scale down the",
    "start": "156150",
    "end": "161670"
  },
  {
    "text": "capacity by simply increasing or decreasing the number of shards that you have defined it's a system that's",
    "start": "161670",
    "end": "168989"
  },
  {
    "text": "designed to allow you to write real time applications whether you're using Apache",
    "start": "168989",
    "end": "176100"
  },
  {
    "text": "spark or Strom or going the serverless way with AWS lambda it's also engineered",
    "start": "176100",
    "end": "184680"
  },
  {
    "text": "with cost in mind meaning that like many",
    "start": "184680",
    "end": "190319"
  },
  {
    "text": "AWS services AWS Kinesis is a cost efficient solution for workloads of any",
    "start": "190319",
    "end": "198209"
  },
  {
    "text": "scale a lot of developers have told us",
    "start": "198209",
    "end": "203489"
  },
  {
    "text": "that they like the convenience of micro bashing their data and that data being",
    "start": "203489",
    "end": "209310"
  },
  {
    "text": "delivered to a destination of their choice namely either s3 redshift or",
    "start": "209310",
    "end": "215959"
  },
  {
    "text": "Amazon Elastic search for those developers we have built a service",
    "start": "215959",
    "end": "220980"
  },
  {
    "text": "called Kinesis firehose deliver stream which allows you to capture and deliver",
    "start": "220980",
    "end": "226109"
  },
  {
    "text": "data to these destinations without having to write any code or manage any",
    "start": "226109",
    "end": "232769"
  },
  {
    "text": "infrastructure in addition to capturing the data you can optionally compress as",
    "start": "232769",
    "end": "239370"
  },
  {
    "text": "well as encrypt your data before it makes it to the destination in addition",
    "start": "239370",
    "end": "244650"
  },
  {
    "text": "it allows seamless elasticity you don't have to worry about increasing or",
    "start": "244650",
    "end": "250290"
  },
  {
    "text": "decreasing your shards we take care of that seamlessly underneath the hood for you so there's a lot of automation built",
    "start": "250290",
    "end": "257700"
  },
  {
    "text": "in a lot of administration that is taken care of us behind the curtains and the",
    "start": "257700",
    "end": "264680"
  },
  {
    "text": "newest member of the family is Kinesis analytics in simple terms",
    "start": "264680",
    "end": "269930"
  },
  {
    "text": "Kinesis analytics is a service that lets you run sequel ansi standard sequel on",
    "start": "269930",
    "end": "278550"
  },
  {
    "text": "your streaming data it's a real-time streaming sequel engine that can run your queries",
    "start": "278550",
    "end": "285690"
  },
  {
    "text": "in sub-second processing time like the other four services it's built with a",
    "start": "285690",
    "end": "292140"
  },
  {
    "text": "lot of good design goals for example once you start streaming your data",
    "start": "292140",
    "end": "298880"
  },
  {
    "text": "Kinesis analytics can automatically infer the schema and it'll let you",
    "start": "298880",
    "end": "305160"
  },
  {
    "text": "either edit that schema or import the schema of your choice and you can start",
    "start": "305160",
    "end": "310440"
  },
  {
    "text": "running your sequel queries in addition to running ANSI standard sequel they've",
    "start": "310440",
    "end": "315570"
  },
  {
    "text": "also extended that functionality to include many windows functions the reason for that is stream as you all",
    "start": "315570",
    "end": "323520"
  },
  {
    "text": "know is unbounded and having a window function will allow users to compute",
    "start": "323520",
    "end": "330030"
  },
  {
    "text": "that your queries within a certain window like Kinesis firehose it",
    "start": "330030",
    "end": "336720"
  },
  {
    "text": "elastically scales to match your data throughput a lot of times your data throughput your data rate flow changes",
    "start": "336720",
    "end": "344400"
  },
  {
    "text": "your complexity of the query also changes we increase the capacity the CPU",
    "start": "344400",
    "end": "350820"
  },
  {
    "text": "needed to run a process your query underneath the hood without having",
    "start": "350820",
    "end": "355890"
  },
  {
    "text": "without you having to intervene for anything so let's take a look at some of",
    "start": "355890",
    "end": "361530"
  },
  {
    "text": "the architectures real-time architectures our customers have built using these technologies so a colleague",
    "start": "361530",
    "end": "369750"
  },
  {
    "text": "of mine once said a journey to building a good real-time pipeline starts with a",
    "start": "369750",
    "end": "375180"
  },
  {
    "text": "simple one so here is a simple architecture built by one of our customers first corporation first",
    "start": "375180",
    "end": "382200"
  },
  {
    "text": "corporation have multiple digital properties if you are familiar with cosmopolitan and other magazines they",
    "start": "382200",
    "end": "389370"
  },
  {
    "text": "are behind those magazines they analyze a lot of data to make recommendations or",
    "start": "389370",
    "end": "397080"
  },
  {
    "text": "deliver useful stories to their custom their architecture consists of streaming",
    "start": "397080",
    "end": "402550"
  },
  {
    "text": "data from their browsers as well as from their mobile apps into a Kinesis stream",
    "start": "402550",
    "end": "408070"
  },
  {
    "text": "that data is processed by an EMR cluster with the spar planning on EMR and the",
    "start": "408070",
    "end": "415450"
  },
  {
    "text": "process results are sent to s3 for downstream consumption they also have a",
    "start": "415450",
    "end": "421810"
  },
  {
    "text": "need to capture this real-time data as it is coming and archive it to meet",
    "start": "421810",
    "end": "428380"
  },
  {
    "text": "their requirements or the regulatory requirements to satisfy that requirement",
    "start": "428380",
    "end": "433470"
  },
  {
    "text": "these the streaming data this push to Keeney's streams is also consumed into a",
    "start": "433470",
    "end": "440950"
  },
  {
    "text": "Kinesis delivery stream shown below VL AWS lambda function and sent to s3",
    "start": "440950",
    "end": "447400"
  },
  {
    "text": "for long-term storage so here is another design built in a truly serverless",
    "start": "447400",
    "end": "454980"
  },
  {
    "text": "fashion by just giving who are the world's largest social platforms",
    "start": "454980",
    "end": "461800"
  },
  {
    "text": "forgiving this is a time series analysis almost on a stream of web events what",
    "start": "461800",
    "end": "470470"
  },
  {
    "text": "you see here is a number of producers putting or writing data into a Kinesis",
    "start": "470470",
    "end": "477220"
  },
  {
    "text": "streams that data is picked up by a lambda function to perform in memory",
    "start": "477220",
    "end": "484270"
  },
  {
    "text": "calculations on the reel on the real-time data for Kenya for time series",
    "start": "484270",
    "end": "490390"
  },
  {
    "text": "and that running counts is sent to a dynamodb into a summary table little",
    "start": "490390",
    "end": "495640"
  },
  {
    "text": "dynamodb table as soon as the data lands in DynamoDB another lambda function",
    "start": "495640",
    "end": "501310"
  },
  {
    "text": "picks up the data and processes the data and sensitive cloud watch for",
    "start": "501310",
    "end": "508870"
  },
  {
    "text": "dashboarding so this is a little more involved architecture but yet it's very",
    "start": "508870",
    "end": "516310"
  },
  {
    "text": "simple because it uses lambda and dynamodb which are truly server less",
    "start": "516310",
    "end": "522479"
  },
  {
    "text": "services for many systems",
    "start": "522479",
    "end": "528910"
  },
  {
    "text": "location where the event occurred is highly important for example think about",
    "start": "528910",
    "end": "534590"
  },
  {
    "text": "a scenario where an alarm goes off in one of the warehouses maybe around the",
    "start": "534590",
    "end": "540110"
  },
  {
    "text": "world that event or is of no use if you cannot pinpoint exactly where that even",
    "start": "540110",
    "end": "547190"
  },
  {
    "text": "occurred to accommodate such scenarios we have built a solution engineer from",
    "start": "547190",
    "end": "556460"
  },
  {
    "text": "Amazon built a solution architecture that'll combine real-time streaming data",
    "start": "556460",
    "end": "563180"
  },
  {
    "text": "and a references the geographic data residing in a Redis cluster and makes it",
    "start": "563180",
    "end": "570140"
  },
  {
    "text": "available to a web server Lord our jeaious web server running on elastic",
    "start": "570140",
    "end": "576230"
  },
  {
    "text": "beanstalk combining those two data i love customers to really create good",
    "start": "576230",
    "end": "586460"
  },
  {
    "text": "visualizations like the one you see on the right it's a heat map showing where the events occurred over a period of",
    "start": "586460",
    "end": "592970"
  },
  {
    "text": "time and there are many times customers",
    "start": "592970",
    "end": "599060"
  },
  {
    "text": "want to include both batch analysis and real-time analysis in their systems an",
    "start": "599060",
    "end": "606620"
  },
  {
    "text": "example of that nature is built by smart news smart news is the news discovery",
    "start": "606620",
    "end": "613790"
  },
  {
    "text": "app that delivers best stories to their 18 million plus users around the world",
    "start": "613790",
    "end": "622360"
  },
  {
    "text": "they have multiple themes processing processing real-time data for various",
    "start": "622360",
    "end": "629150"
  },
  {
    "text": "purposes now to meet the goals of these teams they have build a sustainable data",
    "start": "629150",
    "end": "637760"
  },
  {
    "text": "platform that can serve all these teams with the data they require in this",
    "start": "637760",
    "end": "646910"
  },
  {
    "text": "example they have built a lambda architecture that that serves their news",
    "start": "646910",
    "end": "653240"
  },
  {
    "text": "division as well as their product division their architecture comprises of",
    "start": "653240",
    "end": "658780"
  },
  {
    "text": "by the ways everybody familiar with lambda so lambda architecture is a is a data",
    "start": "658780",
    "end": "665220"
  },
  {
    "text": "processing architecture that allows you to combine both batch analysis and",
    "start": "665220",
    "end": "671070"
  },
  {
    "text": "real-time analysis in a single system their architecture comprises of",
    "start": "671070",
    "end": "676680"
  },
  {
    "text": "collecting user activity data that you see on the left hand side generated by",
    "start": "676680",
    "end": "682680"
  },
  {
    "text": "their mobile applications and also collecting data residing in their tables",
    "start": "682680",
    "end": "689279"
  },
  {
    "text": "the RTS instances residing in many of their databases the log data the user",
    "start": "689279",
    "end": "696029"
  },
  {
    "text": "activity data is sent to fluent D which",
    "start": "696029",
    "end": "701820"
  },
  {
    "text": "is exported to s3 as well as Kinesis the data residing in their tables is",
    "start": "701820",
    "end": "707700"
  },
  {
    "text": "exported via an OSS bulk loader into s3",
    "start": "707700",
    "end": "713209"
  },
  {
    "text": "now as you can see in their batch layer they are taking the data and processing",
    "start": "713209",
    "end": "719579"
  },
  {
    "text": "ETL performing ETL tasks to convert their text files into columnar format",
    "start": "719579",
    "end": "726000"
  },
  {
    "text": "and making it available in s3 they also",
    "start": "726000",
    "end": "731430"
  },
  {
    "text": "have a serving layer that in creates views and indexes them and makes it",
    "start": "731430",
    "end": "737790"
  },
  {
    "text": "available for querying via trusts all coming to the speed layer the data sent",
    "start": "737790",
    "end": "745079"
  },
  {
    "text": "to Kinesis streams is consumed to look",
    "start": "745079",
    "end": "750600"
  },
  {
    "text": "at the trends the articles that the customers are looking at and deliver the",
    "start": "750600",
    "end": "757649"
  },
  {
    "text": "most relevant or the most appropriate article to the end user",
    "start": "757649",
    "end": "763430"
  },
  {
    "text": "so because we are talking about ad campaigns let's look at another real",
    "start": "764930",
    "end": "770820"
  },
  {
    "text": "time architecture that comprises of looking at anomaly detection using",
    "start": "770820",
    "end": "776520"
  },
  {
    "text": "Kinesis analytics so in the digital advertising world analyzing real-time",
    "start": "776520",
    "end": "784260"
  },
  {
    "text": "clickstream data immediately is of immense value one way Digital",
    "start": "784260",
    "end": "791520"
  },
  {
    "text": "advertisers or marketers make sense or monitor their ad effectiveness is by",
    "start": "791520",
    "end": "797880"
  },
  {
    "text": "monitoring their click rate so for those",
    "start": "797880",
    "end": "803400"
  },
  {
    "text": "of you who are familiar with click rate great but for those of you who don't know whenever when a ad appears on a",
    "start": "803400",
    "end": "813330"
  },
  {
    "text": "website it's called an impression and when an user clicks on impression then",
    "start": "813330",
    "end": "819480"
  },
  {
    "text": "it's called a click so the click rate is computed as a ratio of the clicks to",
    "start": "819480",
    "end": "826050"
  },
  {
    "text": "impressions click rate can be computed",
    "start": "826050",
    "end": "831350"
  },
  {
    "text": "using the Kinesis analytics service here and we'll walk through the architecture",
    "start": "831350",
    "end": "837390"
  },
  {
    "text": "right now so one of the things that I want to touch upon before we go into the",
    "start": "837390",
    "end": "845190"
  },
  {
    "text": "architecture is that what we are doing here is that a click rate demonstrates",
    "start": "845190",
    "end": "852870"
  },
  {
    "text": "the ad performance the higher the click click rate the better the ad is performing but advertisers also want to",
    "start": "852870",
    "end": "861330"
  },
  {
    "text": "look at the low end click rates which might indicate a bad image or maybe a",
    "start": "861330",
    "end": "868800"
  },
  {
    "text": "bad bidding model so here is the architecture users send their traffic in",
    "start": "868800",
    "end": "877440"
  },
  {
    "text": "the form of HTTP GET request with a query string and a header that requests",
    "start": "877440",
    "end": "884400"
  },
  {
    "text": "are consumed by Amazon API Jaitley api gateway is a fully managed service that",
    "start": "884400",
    "end": "891570"
  },
  {
    "text": "lets developers create public monitor and secure their api's now in",
    "start": "891570",
    "end": "897549"
  },
  {
    "text": "this example API gateway is acting as a proxy service to Kinesis streams it",
    "start": "897549",
    "end": "905379"
  },
  {
    "text": "actually takes the HTTP request and converts the HTTP GET request and query",
    "start": "905379",
    "end": "912939"
  },
  {
    "text": "string into a JSON message that JSON message ends up in a Kinesis stream",
    "start": "912939",
    "end": "919269"
  },
  {
    "text": "which is consumed by the Kinesis analytics application now the kinases",
    "start": "919269",
    "end": "924759"
  },
  {
    "text": "analytic application is actually keeping track of the count of clicks and",
    "start": "924759",
    "end": "930519"
  },
  {
    "text": "impressions in ten-second tumbling window intervals once it computes the",
    "start": "930519",
    "end": "938910"
  },
  {
    "text": "clicks and impressions it calculates the click rate but is simply taking a ratio",
    "start": "938910",
    "end": "944799"
  },
  {
    "text": "of that and then it passes the click rate to what we call is a random cut",
    "start": "944799",
    "end": "952689"
  },
  {
    "text": "forest function this is an analytical function used in machine learning by many companies and it lets you detect",
    "start": "952689",
    "end": "960429"
  },
  {
    "text": "anomalies and the very detect anomalies is as the data is flowing this function",
    "start": "960429",
    "end": "967059"
  },
  {
    "text": "random cut forests computes the score for the incoming data it identifies a",
    "start": "967059",
    "end": "973149"
  },
  {
    "text": "pattern and anything that doesn't fit the pattern has a lower score so the clickstream",
    "start": "973149",
    "end": "980290"
  },
  {
    "text": "data the click rate is passed to a random cut forests within Kinesis",
    "start": "980290",
    "end": "985509"
  },
  {
    "text": "analytics application and that score is put back in is picked up by a lambda",
    "start": "985509",
    "end": "992589"
  },
  {
    "text": "function now the lambda function has the logic built-in to detect the anomalous",
    "start": "992589",
    "end": "999039"
  },
  {
    "text": "data in that results that are being sent and it immediately sends a notification",
    "start": "999039",
    "end": "1005910"
  },
  {
    "text": "via SNS to the end user to take some",
    "start": "1005910",
    "end": "1011669"
  },
  {
    "text": "kind of an action based on that so this is the story of different types of",
    "start": "1011669",
    "end": "1017689"
  },
  {
    "text": "real-time applications that you can build I encourage you to build your own real-time streaming application",
    "start": "1017689",
    "end": "1024160"
  },
  {
    "text": "and share it with us with that I hand it over to Nabil to walk us through their journey cool thank you very good so hi",
    "start": "1024160",
    "end": "1039280"
  },
  {
    "text": "my name is middle Zaman I'm a software engineer at Quantcast and before I get",
    "start": "1039280",
    "end": "1045400"
  },
  {
    "text": "started on the actual main topic I wanted to introduce a little bit but who we are at Quantcast what we do to frame the rest of this talk so Quan Casas",
    "start": "1045400",
    "end": "1053020"
  },
  {
    "text": "leader in digital advertising we have partnerships with millions of publishers across the world and we're able to",
    "start": "1053020",
    "end": "1061000"
  },
  {
    "text": "leverage those partnerships to see really deep insights into the Internet activity of users at a really frequent",
    "start": "1061000",
    "end": "1068080"
  },
  {
    "text": "rate I think the average u.s. internet user we get hit song about 50 times a",
    "start": "1068080",
    "end": "1074410"
  },
  {
    "text": "month and so tracking that activity lets us really improve the relevancy of the",
    "start": "1074410",
    "end": "1079870"
  },
  {
    "text": "digital advertising the world to provide on behalf of our clients so we consume",
    "start": "1079870",
    "end": "1085350"
  },
  {
    "text": "about 100 million bid requests per day and about 40 petabytes of data is",
    "start": "1085350",
    "end": "1090490"
  },
  {
    "text": "processed our compute cluster to you know meet our business needs we have a",
    "start": "1090490",
    "end": "1095590"
  },
  {
    "text": "hundred eighty engineers globally and four offices and we're hiring I'm contractually obligated to let you know that we are hiring you can reach us at",
    "start": "1095590",
    "end": "1104140"
  },
  {
    "text": "reinvented podcast.com we'd love to hear from you if anything today sounds interesting if you want to learn more",
    "start": "1104140",
    "end": "1109750"
  },
  {
    "text": "stuff like that so come on Cass has a lot of on-site infrastructure to support",
    "start": "1109750",
    "end": "1115480"
  },
  {
    "text": "our business needs but we've been making a push this last year so to move a lot of things into AWS and there are a few",
    "start": "1115480",
    "end": "1121000"
  },
  {
    "text": "reasons why firstly Amazon s3 is a business continuity solution for",
    "start": "1121000",
    "end": "1127000"
  },
  {
    "text": "quantcast we have business critical data we rely on to continue serving ads and earning",
    "start": "1127000",
    "end": "1134170"
  },
  {
    "text": "money but if there is a disaster scenario we need to be able to fall back on something to be able to continue",
    "start": "1134170",
    "end": "1141220"
  },
  {
    "text": "while we recover and s3 provides that Avenue we have eight petabytes of data backed up there",
    "start": "1141220",
    "end": "1146730"
  },
  {
    "text": "additionally AWS I think this is a reason why a lot of people try to use it",
    "start": "1146730",
    "end": "1152020"
  },
  {
    "text": "and let's this experiment with new products a lot better a lot faster it really",
    "start": "1152020",
    "end": "1157639"
  },
  {
    "text": "through is better um what I mean by that is normally in order to build out the",
    "start": "1157639",
    "end": "1163159"
  },
  {
    "text": "architecture the infrastructure to support a new product you have to make a huge devotion of resources and really",
    "start": "1163159",
    "end": "1170389"
  },
  {
    "text": "with AWS you can move a lot more quickly experiment with things that really you're not sure yet if will be worth it",
    "start": "1170389",
    "end": "1178159"
  },
  {
    "text": "at the end but you can move rapidly enough to make those experiments and make those pivoting decisions as you go",
    "start": "1178159",
    "end": "1184190"
  },
  {
    "text": "along we also provide our teams with total ownership so you don't have to interface with another team that owns",
    "start": "1184190",
    "end": "1190339"
  },
  {
    "text": "the hardware that your services are running on because you own it from end to end any problems any like new tweaks",
    "start": "1190339",
    "end": "1197749"
  },
  {
    "text": "they don't have to deal with that extra barrier and in general working in the",
    "start": "1197749",
    "end": "1203419"
  },
  {
    "text": "cloud solves a lot of headaches but it comes with its unique set of challenges that I kind of want to emphasize as I go",
    "start": "1203419",
    "end": "1209389"
  },
  {
    "text": "along so before I take too long let's move on to the journey that my team and I took",
    "start": "1209389",
    "end": "1215690"
  },
  {
    "text": "over the past year building a real-time campaign analytics product in AWS so",
    "start": "1215690",
    "end": "1222169"
  },
  {
    "text": "what is the problem that we're trying to solve we have like I said these servers",
    "start": "1222169",
    "end": "1227450"
  },
  {
    "text": "that we own that are performing real-time bidding on ad exchanges around the world to serve ads on lots of",
    "start": "1227450",
    "end": "1234950"
  },
  {
    "text": "different websites we have that you know 2,000 servers performing these activities and they're dealing across",
    "start": "1234950",
    "end": "1242119"
  },
  {
    "text": "the mall about two million bids per second as these bids occur we update",
    "start": "1242119",
    "end": "1247729"
  },
  {
    "text": "various metrics internal to our bidding processes to get a look at how the",
    "start": "1247729",
    "end": "1253129"
  },
  {
    "text": "bidding is proceeding whether we're going too slowly or too quickly or if some issues come up along the way so a",
    "start": "1253129",
    "end": "1260809"
  },
  {
    "text": "number of metrics get incremented or decremented or so on and we want insight into these metrics close to real-time so",
    "start": "1260809",
    "end": "1268639"
  },
  {
    "text": "about 50,000 unique records so for some numbers are being aggregated in each of",
    "start": "1268639",
    "end": "1275450"
  },
  {
    "text": "our bidding servers you know but two thousand servers it's about a hundred million records that means we collect",
    "start": "1275450",
    "end": "1281029"
  },
  {
    "text": "and provide some view on so how do we",
    "start": "1281029",
    "end": "1286039"
  },
  {
    "text": "get that data from our servers to downstream users and services of course with AWS so the first approach",
    "start": "1286039",
    "end": "1294780"
  },
  {
    "text": "that we took starting in our data centers we decide that these metrics are",
    "start": "1294780",
    "end": "1301470"
  },
  {
    "text": "being stored internally and monitored and we're going to admit like a dump",
    "start": "1301470",
    "end": "1306600"
  },
  {
    "text": "state every periodic interval 10 seconds or so gives us roughly the real-time",
    "start": "1306600",
    "end": "1313730"
  },
  {
    "text": "view that we want so when a bid happens at most 10 seconds later it's reflected",
    "start": "1313730",
    "end": "1318960"
  },
  {
    "text": "in a new message that the server emits to some centralized location the record",
    "start": "1318960",
    "end": "1326640"
  },
  {
    "text": "that exists for these set of metrics for every active ad campaign we have a",
    "start": "1326640",
    "end": "1333590"
  },
  {
    "text": "record or some number of records based on some additional factors but before we",
    "start": "1333590",
    "end": "1339930"
  },
  {
    "text": "send it along an important feature is we choose to bundle these records and compress them so we're not sending",
    "start": "1339930",
    "end": "1346320"
  },
  {
    "text": "50,000 individual messages across the wire we send a lot fewer larger messages",
    "start": "1346320",
    "end": "1351660"
  },
  {
    "text": "because we see really good compression characteristics in our data and this ends up being important as we go along",
    "start": "1351660",
    "end": "1358350"
  },
  {
    "text": "so from our data centers entering into the AWS realm we enter Amazon Kinesis",
    "start": "1358350",
    "end": "1365810"
  },
  {
    "text": "ravika Rd did an excellent job explaining Kinesis we're using connexxus streaming specifically but these are",
    "start": "1365810",
    "end": "1371760"
  },
  {
    "text": "some of the reasons that we chose to go with it cases persists data I think by",
    "start": "1371760",
    "end": "1376980"
  },
  {
    "text": "default 24 hours but you can expand that to up to seven out of seven days for additional cost but this means that in",
    "start": "1376980",
    "end": "1383010"
  },
  {
    "text": "the event of any failure you can recover by replaying that data multiple",
    "start": "1383010",
    "end": "1388230"
  },
  {
    "text": "applications can read from a single stream the consumption of data off the stream is non-destructive so if there's",
    "start": "1388230",
    "end": "1394500"
  },
  {
    "text": "some really important data that's being passed through a stream you can have multiple applications that are interested in consuming it due so you",
    "start": "1394500",
    "end": "1401690"
  },
  {
    "text": "can scale the data rapidly by just increasing the number of shards this",
    "start": "1401690",
    "end": "1407700"
  },
  {
    "text": "without any real interruption of service this gives us a lot of flexibility to expand the product in the future and",
    "start": "1407700",
    "end": "1415010"
  },
  {
    "text": "pertinent to our particular design since you have to shard each message before it",
    "start": "1415010",
    "end": "1420390"
  },
  {
    "text": "can know where to end up in case we're actually sharding by the server identity so each of our 2000 servers",
    "start": "1420390",
    "end": "1427300"
  },
  {
    "text": "would ever know what their own identity is and tags a message with it",
    "start": "1427300",
    "end": "1432670"
  },
  {
    "text": "the reason we're choosing the shard by this particular value is because if we were to discharge by something like the",
    "start": "1432670",
    "end": "1439510"
  },
  {
    "text": "campaign ID which has a more logical meaning we would have to actually split",
    "start": "1439510",
    "end": "1444850"
  },
  {
    "text": "that up into a single message for each of those IDs because you can't you can't",
    "start": "1444850",
    "end": "1450820"
  },
  {
    "text": "give multiple shard keys to the same message so we're able to send a lot",
    "start": "1450820",
    "end": "1457030"
  },
  {
    "text": "fewer messages get better compression by just tagging each message we send with",
    "start": "1457030",
    "end": "1462070"
  },
  {
    "text": "the server identity and moving on the data is then consumed by consumers Reena",
    "start": "1462070",
    "end": "1467559"
  },
  {
    "text": "running in ec2 and they that data has been written to DynamoDB we have a time",
    "start": "1467559",
    "end": "1473980"
  },
  {
    "text": "series database that provides historical views on this data and then we run a query service on top of this and",
    "start": "1473980",
    "end": "1480309"
  },
  {
    "text": "downstream users and services are able to access that data through an API",
    "start": "1480309",
    "end": "1486640"
  },
  {
    "text": "endpoint that we expose and the crew services goes back into dynamo to provide the particular insights that the",
    "start": "1486640",
    "end": "1492220"
  },
  {
    "text": "users are interested in so to stop here I want to go into a little how much is",
    "start": "1492220",
    "end": "1498250"
  },
  {
    "text": "it costing us right now we have to collect about 10 million records per second 100 million divided by 10 because",
    "start": "1498250",
    "end": "1504670"
  },
  {
    "text": "it's every 10 seconds and the monthly cost for Canisius and ec2 is fairly",
    "start": "1504670",
    "end": "1511179"
  },
  {
    "text": "small we don't have very demanding uses there but dynamodb ends up being really expensive here to write at the rate that",
    "start": "1511179",
    "end": "1517929"
  },
  {
    "text": "we need to the provision write throughput is a lot of money and we need",
    "start": "1517929",
    "end": "1523300"
  },
  {
    "text": "to justify this and we can't so we need to try to make dynamo cheaper so in",
    "start": "1523300",
    "end": "1530800"
  },
  {
    "text": "order to make time wood cheaper we do some digging and find that our actual problem isn't quite as hard as we might",
    "start": "1530800",
    "end": "1537820"
  },
  {
    "text": "initially think only a small subset of the metrics that we're collecting need to be accessed really rapidly the rest",
    "start": "1537820",
    "end": "1545380"
  },
  {
    "text": "of the metrics we can expect a little more lag and latency excuse me and that",
    "start": "1545380",
    "end": "1552460"
  },
  {
    "text": "is totally fine so you because we want to say costume Dinamo",
    "start": "1552460",
    "end": "1559830"
  },
  {
    "text": "one of the simplest things we can do is reduce the rate at which we write the data so every 60 seconds instead of",
    "start": "1559830",
    "end": "1565410"
  },
  {
    "text": "every 10 seconds we write data in thickness it gets picked up at the consumer is the exact same process we write a sixth as frequently into dynamo",
    "start": "1565410",
    "end": "1571950"
  },
  {
    "text": "and spend a sixth as much money it's pretty simple math but that won't cut it",
    "start": "1571950",
    "end": "1580230"
  },
  {
    "text": "for some of our metrics solver metrics like how much money we're spending how many impressions we've served really",
    "start": "1580230",
    "end": "1587160"
  },
  {
    "text": "vital things like that need to be available more frequently so at the same 10-second interval we initially intended we have a second",
    "start": "1587160",
    "end": "1593550"
  },
  {
    "text": "stream that is much smaller because we have fewer numbers really that need to track and we're writing it to",
    "start": "1593550",
    "end": "1600330"
  },
  {
    "text": "ElastiCache Rattus Rattus if you're unfamiliar is another data store in WS",
    "start": "1600330",
    "end": "1606060"
  },
  {
    "text": "or ElastiCache Pettis is at least um and it provides us with basically in-memory",
    "start": "1606060",
    "end": "1612060"
  },
  {
    "text": "data store and it's really fast but it's fairly feature light but because it's",
    "start": "1612060",
    "end": "1618090"
  },
  {
    "text": "all in memory we can't store too much we have a rolling window about the last hour of data that we care about in Redis",
    "start": "1618090",
    "end": "1624510"
  },
  {
    "text": "and this works fine because it doesn't charge you by your rights which is great",
    "start": "1624510",
    "end": "1629700"
  },
  {
    "text": "so our architecture now looks like this and this is how much we now have to",
    "start": "1629700",
    "end": "1635970"
  },
  {
    "text": "spend you know we're still spending we're still collecting 10 million records per second or so now into Redis",
    "start": "1635970",
    "end": "1642540"
  },
  {
    "text": "and a sixth of that larger records into dynamodb about 1.6 million and the total",
    "start": "1642540",
    "end": "1649620"
  },
  {
    "text": "monthly costs are significant reduce Dinamo's the sixth is expensive we add another piece of stream so it's a little",
    "start": "1649620",
    "end": "1655590"
  },
  {
    "text": "bit more they're a little bit more ec2 we're also paying for Redis but this is better less than half as much but we",
    "start": "1655590",
    "end": "1663480"
  },
  {
    "text": "notice something strange as we started scaling out and gonna try to explain why",
    "start": "1663480",
    "end": "1668900"
  },
  {
    "text": "the way Kinesis works is when you send data into Kinesis again it's sharted so",
    "start": "1668900",
    "end": "1674700"
  },
  {
    "text": "every message ends up being sent into a single shard and the guarantee here is",
    "start": "1674700",
    "end": "1679890"
  },
  {
    "text": "that for any given shard key that shard key will only appeal up here in a single shard so using the KP on the KCl the the",
    "start": "1679890",
    "end": "1688240"
  },
  {
    "text": "as libraries that are provided for reading and writing to Kinesis and I strongly recommend you use these because",
    "start": "1688240",
    "end": "1693429"
  },
  {
    "text": "they're great they have a lot of features and they solve a lot of the problems that you have to solve yourselves the KCl creates a single",
    "start": "1693429",
    "end": "1701260"
  },
  {
    "text": "process for every consumer for every chart that needs to be consumed from so",
    "start": "1701260",
    "end": "1706960"
  },
  {
    "text": "we have about 50 shards so there are 50 consumer processes like Java processes that are running independently not",
    "start": "1706960",
    "end": "1712900"
  },
  {
    "text": "sharing any memory and so what that means is we are having each of our",
    "start": "1712900",
    "end": "1721360"
  },
  {
    "text": "consumers read basically all 50 unique 50,000 unique keys and writing all",
    "start": "1721360",
    "end": "1727690"
  },
  {
    "text": "30,000 unique keys into DynamoDB in parallel so instead of writing all those",
    "start": "1727690",
    "end": "1732820"
  },
  {
    "text": "keys exactly once we write them all 50 times and have about two and a half million writes per minute",
    "start": "1732820",
    "end": "1738610"
  },
  {
    "text": "not what we originally intended this is simply because when we're starting the data initially each server has all of",
    "start": "1738610",
    "end": "1745870"
  },
  {
    "text": "these records in it it's sending them into a random shard based on its own identity and so the data isn't organized",
    "start": "1745870",
    "end": "1753550"
  },
  {
    "text": "by these keys we can't expect the keys to only show up in a single shard so",
    "start": "1753550",
    "end": "1759520"
  },
  {
    "text": "this is a problem the way we can get around it is by reorganizing our data",
    "start": "1759520",
    "end": "1765760"
  },
  {
    "text": "just shuffling it is that thought we had we can actually employ more Kinesis to",
    "start": "1765760",
    "end": "1771040"
  },
  {
    "text": "get this to happen but before I move on what I thought was about $4,200 for per",
    "start": "1771040",
    "end": "1779230"
  },
  {
    "text": "month for this product actually is well over a hundred thousand dollars and you also can't even provision this much",
    "start": "1779230",
    "end": "1786250"
  },
  {
    "text": "throughput in dynamo without getting like super special permission so it's not a good idea",
    "start": "1786250",
    "end": "1793110"
  },
  {
    "text": "so our architecture before looked like this with two streams two sets of",
    "start": "1793110",
    "end": "1799000"
  },
  {
    "text": "consumers reading from those streams writing to do disparate data stores and a crew service on top of them and there",
    "start": "1799000",
    "end": "1805000"
  },
  {
    "text": "was this complete conspicuous gap there this whole time we can feel that conspicuous gap to make our lives a",
    "start": "1805000",
    "end": "1812350"
  },
  {
    "text": "little better with another set of consumers and another Kinesis stream and these quote-unquote shuffling consumers",
    "start": "1812350",
    "end": "1818500"
  },
  {
    "text": "end up reading the data which originally organized by server identity",
    "start": "1818500",
    "end": "1824070"
  },
  {
    "text": "aggregating it and resending into Kinesis by the actual key in dynamo that",
    "start": "1824070",
    "end": "1830139"
  },
  {
    "text": "will be writing by writing to a prefix of that key actually but what that means is for any given key that we want to",
    "start": "1830139",
    "end": "1838570"
  },
  {
    "text": "write to only a single shard will contain that key and so our consumers",
    "start": "1838570",
    "end": "1843789"
  },
  {
    "text": "that second set of consumers are responsible for a disjoint subsets of our key space this means there isn't",
    "start": "1843789",
    "end": "1850840"
  },
  {
    "text": "that nasty overlapping that amounts to wasted writes we get to write exactly",
    "start": "1850840",
    "end": "1856330"
  },
  {
    "text": "once for every single campaign we run and again writes in dynamo are really expensive so this is important and we do",
    "start": "1856330",
    "end": "1863740"
  },
  {
    "text": "it and we test it out and it's it actually costs will be about a cost and",
    "start": "1863740",
    "end": "1869799"
  },
  {
    "text": "it's good so these are the updated numbers roughly you know we have",
    "start": "1869799",
    "end": "1876220"
  },
  {
    "text": "additional Kinesis costs additional ec2 costs but it's a lot better than",
    "start": "1876220",
    "end": "1883869"
  },
  {
    "text": "spending a hundred thousand dollars in dynamo so you know we're pretty good here we kind of have a product that's",
    "start": "1883869",
    "end": "1890049"
  },
  {
    "text": "working but we want to kind of explore some other opportunities now there were a native lead us to make this a little",
    "start": "1890049",
    "end": "1895869"
  },
  {
    "text": "better so amazon are able lambda is a really cool service i think has already",
    "start": "1895869",
    "end": "1901779"
  },
  {
    "text": "talked a little bit about it but it has this whole concept of server this",
    "start": "1901779",
    "end": "1906960"
  },
  {
    "text": "architecture you don't have to manage your own ec2 instances you don't have to care about how they come up or when they",
    "start": "1906960",
    "end": "1912340"
  },
  {
    "text": "come down or memory or CPU when under this monitoring this stuff it's just a",
    "start": "1912340",
    "end": "1918309"
  },
  {
    "text": "huge boon to operations it's a little more expensive for our use case just in",
    "start": "1918309",
    "end": "1924549"
  },
  {
    "text": "general if you have a fairly slow or bursty stream that isn't going to get",
    "start": "1924549",
    "end": "1930549"
  },
  {
    "text": "data very often and English lambda can be really good because it comes up",
    "start": "1930549",
    "end": "1935950"
  },
  {
    "text": "consumes the data shuts down you're not paying for when it's not active but our",
    "start": "1935950",
    "end": "1941049"
  },
  {
    "text": "stream is constantly running we have lots of data throwing it through the entire time so it's little more expensive we expect it out but this we",
    "start": "1941049",
    "end": "1947259"
  },
  {
    "text": "you know justified by the operational overhead so we have this completely serverless",
    "start": "1947259",
    "end": "1953859"
  },
  {
    "text": "architecture here it's just replacing all the consumers with lambda consumers instead it's really easy to implement",
    "start": "1953859",
    "end": "1960839"
  },
  {
    "text": "but trying it out and scaling up the data we noticed that it wasn't able to",
    "start": "1960839",
    "end": "1968139"
  },
  {
    "text": "keep up with our Kinesis screens and we don't know why and we poked around the",
    "start": "1968139",
    "end": "1973210"
  },
  {
    "text": "CloudWatch metrics and that didn't really tell us too much and are like force impulse and it's SSH onto the box",
    "start": "1973210",
    "end": "1979659"
  },
  {
    "text": "and profile it and figure out what's going on and none of that's possible I think there is an avenue of",
    "start": "1979659",
    "end": "1986799"
  },
  {
    "text": "Investigation through opening a support ticket with a lambda team pursuing that but we already had a working solution so",
    "start": "1986799",
    "end": "1992229"
  },
  {
    "text": "we kind of just moved on it's a little sad but lambda does not appear in our",
    "start": "1992229",
    "end": "1997629"
  },
  {
    "text": "final design some additional optimizations that we've made along the way we have our consumers continually",
    "start": "1997629",
    "end": "2004799"
  },
  {
    "text": "consuming data off of the commutes the stream but not actually writing every batch they have an internal timer that",
    "start": "2004799",
    "end": "2010619"
  },
  {
    "text": "they wait to aggregate this just lets us have a configurable knob that we can",
    "start": "2010619",
    "end": "2015779"
  },
  {
    "text": "turn where we can trade off data freshness for cost we can write less frequently to dynamodb but at the cost",
    "start": "2015779",
    "end": "2022019"
  },
  {
    "text": "of having the data appear later or vice versa this is a really nice thing to be able to present to your customers like",
    "start": "2022019",
    "end": "2028889"
  },
  {
    "text": "we can make this better if you are willing to pay the additional cost this",
    "start": "2028889",
    "end": "2035940"
  },
  {
    "text": "next point and I wish I really had a diagram for this but I don't because it's really hard to draw so what we're",
    "start": "2035940",
    "end": "2044820"
  },
  {
    "text": "doing is what is actually happening underneath the scenes with the K PL the Kinesis producer library is when you're",
    "start": "2044820",
    "end": "2051628"
  },
  {
    "text": "sending a message a king sis record to Kinesis to be you know consumed and",
    "start": "2051629",
    "end": "2059460"
  },
  {
    "text": "stored you assign a shard key and the shard key gets hashed using some hash",
    "start": "2059460",
    "end": "2065730"
  },
  {
    "text": "function that has good balancing and that shard that that hash is actually",
    "start": "2065730",
    "end": "2072358"
  },
  {
    "text": "what's used in a map to identify what shard it really ends up in so you give it some key based on your data it passes",
    "start": "2072359",
    "end": "2080250"
  },
  {
    "text": "it and you're golden the thing is because this shuffling step",
    "start": "2080250",
    "end": "2086480"
  },
  {
    "text": "involved sharding the second stream by the actual key in dynamo that we",
    "start": "2086480",
    "end": "2093169"
  },
  {
    "text": "eventually write to there are a lot of those keys before we're writing only a few messages few large messages into",
    "start": "2093169",
    "end": "2099140"
  },
  {
    "text": "Kinesis from each of our servers but now our consumers are writing you know like fifty thousand different messages all",
    "start": "2099140",
    "end": "2105260"
  },
  {
    "text": "fairly small we don't get the same compression that we want it's not as good we can still manage it we we did",
    "start": "2105260",
    "end": "2112579"
  },
  {
    "text": "initially but what you can do instead is look up the shard the shard hash to the",
    "start": "2112579",
    "end": "2122029"
  },
  {
    "text": "explicit hash to shard mapping in cases the thing that underneath the surface the kpl is handling for you you can",
    "start": "2122029",
    "end": "2127970"
  },
  {
    "text": "create the API and get that mapping yourself and any messages that would",
    "start": "2127970",
    "end": "2133099"
  },
  {
    "text": "appear in the same shard you can just bundle them together and give them the same shard key it doesn't have to mean",
    "start": "2133099",
    "end": "2138410"
  },
  {
    "text": "anything you'll just guarantee they end up in a shain shard which is what you wanted in the first place which is what we wanted",
    "start": "2138410",
    "end": "2143539"
  },
  {
    "text": "in the first place we want to make sure the same data doesn't appear in multiple shards and we can guarantee that while",
    "start": "2143539",
    "end": "2150799"
  },
  {
    "text": "having fewer messages by just bundling things together that normally wouldn't get bundled by looking at this now it's",
    "start": "2150799",
    "end": "2158089"
  },
  {
    "text": "cool and hard to explain so the last optimization is simply we did some rate",
    "start": "2158089",
    "end": "2165140"
  },
  {
    "text": "limiting on the consumers rights to prevent dynamo write failures this is",
    "start": "2165140",
    "end": "2170750"
  },
  {
    "text": "something you can configure as you provision your your can your dynamo",
    "start": "2170750",
    "end": "2176750"
  },
  {
    "text": "usage but yeah so to do a final check point see where we are these",
    "start": "2176750",
    "end": "2183440"
  },
  {
    "text": "optimizations and saves a little bit of money we're about a five thousand dollars spent to build this product out",
    "start": "2183440",
    "end": "2188720"
  },
  {
    "text": "a sticker price so where do we end up this is our final architecture things",
    "start": "2188720",
    "end": "2196549"
  },
  {
    "text": "are in auto scaling groups writing into these two data stores that I've been talking about the query services behind",
    "start": "2196549",
    "end": "2204049"
  },
  {
    "text": "the elastic load balancer all fairly same things to do and it works pretty",
    "start": "2204049",
    "end": "2211099"
  },
  {
    "text": "great in terms of deploying all of this we use a few different tools that",
    "start": "2211099",
    "end": "2216670"
  },
  {
    "text": "I kinda want to plug terraform by Hacha Corp is a really neat tool to be able to",
    "start": "2216670",
    "end": "2224020"
  },
  {
    "text": "codify all of your architecture you can represent everything in terms of scripts this is very similar to cloud formation",
    "start": "2224020",
    "end": "2233170"
  },
  {
    "text": "but there are some differences that we enjoyed from terraform so we've been",
    "start": "2233170",
    "end": "2238750"
  },
  {
    "text": "running with that but to be 1.0 and doesn't provide support for everyone of",
    "start": "2238750",
    "end": "2244480"
  },
  {
    "text": "AWS services so you know if it doesn't work for you it might not but I strongly",
    "start": "2244480",
    "end": "2249700"
  },
  {
    "text": "recommend you look into it each of our services are completely containerized in docker this is huge we can do complete",
    "start": "2249700",
    "end": "2257200"
  },
  {
    "text": "replication of staging and tests and production environments by just you know having everything encoded in docker",
    "start": "2257200",
    "end": "2264010"
  },
  {
    "text": "images its docker is awesome and we initially set out to use docker and we",
    "start": "2264010",
    "end": "2270760"
  },
  {
    "text": "ran with docker we've never looked back Jenkins we have our own Jenkins build",
    "start": "2270760",
    "end": "2276190"
  },
  {
    "text": "system set up to build them to play all of this it's nice multiple availability zones is",
    "start": "2276190",
    "end": "2282339"
  },
  {
    "text": "really easy to configure throughout all the kinds of things that we've done just you say you want it and you say which",
    "start": "2282339",
    "end": "2289089"
  },
  {
    "text": "ones you want there's some PPC configuring but it's pretty simple but",
    "start": "2289089",
    "end": "2294510"
  },
  {
    "text": "multi-region is a little harder and it becomes more expensive because you have to transfer the data across regions so",
    "start": "2294510",
    "end": "2301210"
  },
  {
    "text": "we're not really running with that high availability is achieved through availability zones sufficiently because availabilities in the name some possible",
    "start": "2301210",
    "end": "2309490"
  },
  {
    "text": "huge directions we've considered going with incorporating Apache spark some of the consumer operations that we're doing",
    "start": "2309490",
    "end": "2315910"
  },
  {
    "text": "can be done in memory actually the shuffling in particular is very reminiscent of MapReduce and spark",
    "start": "2315910",
    "end": "2322690"
  },
  {
    "text": "streaming could do something very similar without introducing a second consumer step but we've only played",
    "start": "2322690",
    "end": "2328359"
  },
  {
    "text": "around with spark so far and haven't really dived into the realities of that yet our scale will continue to grow we",
    "start": "2328359",
    "end": "2334839"
  },
  {
    "text": "have a bunch of plans for incorporating much larger data sets we have about 50 shards in our largest stream and about",
    "start": "2334839",
    "end": "2342730"
  },
  {
    "text": "like you know 30 stards and the other one [Music] the that other data sets we plan on",
    "start": "2342730",
    "end": "2349570"
  },
  {
    "text": "passing through Kinesis another ones close to 300 shards and that another one would be closer to 5000 shards not",
    "start": "2349570",
    "end": "2357880"
  },
  {
    "text": "entirely sure all of those will fly in terms of if that's the best way to solve those problems but it's really exciting",
    "start": "2357880",
    "end": "2365140"
  },
  {
    "text": "to try to push this once we have this kind of prototype working and getting value from this we can really push the",
    "start": "2365140",
    "end": "2371500"
  },
  {
    "text": "scale and then there are a number of AWS features that have been coming out can you send all the dicks launched while we were building this all out so",
    "start": "2371500",
    "end": "2378790"
  },
  {
    "text": "we haven't really played with it too much and then there's cases firehose that might actually make sense if Redis",
    "start": "2378790",
    "end": "2385420"
  },
  {
    "text": "or dynamo DB end up as destination possibilities and then there are some",
    "start": "2385420",
    "end": "2391060"
  },
  {
    "text": "failure cases that you need to be able to handle and any sort of you know have available system one of our servers goes",
    "start": "2391060",
    "end": "2398530"
  },
  {
    "text": "down we have auto scaling groups the Kinesis client library the KCl is really",
    "start": "2398530",
    "end": "2405280"
  },
  {
    "text": "really nice in that I'll Reese chart automatically for you if it notices one of the commute consumers has dropped off",
    "start": "2405280",
    "end": "2410440"
  },
  {
    "text": "it'll reallocate the labor so everyone all the data is still being handled it's",
    "start": "2410440",
    "end": "2416110"
  },
  {
    "text": "great that server will eventually recover and everything is kind of fine last cache Redis we worried for a while",
    "start": "2416110",
    "end": "2423160"
  },
  {
    "text": "that a failure here because everything is in memory just means a complete loss",
    "start": "2423160",
    "end": "2428500"
  },
  {
    "text": "of data and we played around with it we have you know replication so that it's",
    "start": "2428500",
    "end": "2434620"
  },
  {
    "text": "not very likely but if the entire replication group fails you lose data but we can change our we've configured",
    "start": "2434620",
    "end": "2443020"
  },
  {
    "text": "our query service to be able to handle this kind of failure in that if Redis is unavailable DynamoDB contains basically",
    "start": "2443020",
    "end": "2449680"
  },
  {
    "text": "the same data just less frequently and so we can add some delay but eventually",
    "start": "2449680",
    "end": "2456640"
  },
  {
    "text": "when Redis does recover we'll resume full service and then we have some we",
    "start": "2456640",
    "end": "2462190"
  },
  {
    "text": "had some issues for awhile with the presence of gaps and duplicates in our data we have all of our data centers",
    "start": "2462190",
    "end": "2469620"
  },
  {
    "text": "sending their data into AWS we have several across the world and",
    "start": "2469620",
    "end": "2476040"
  },
  {
    "text": "the services that are doing that aren't super reliable and we can't be sure that all of our messages are being counted",
    "start": "2476040",
    "end": "2482250"
  },
  {
    "text": "and so gaps are an issue we worried about with Kinesis there was an",
    "start": "2482250",
    "end": "2488640"
  },
  {
    "text": "additional concern because Kinesis has the opposite problem where it's at least",
    "start": "2488640",
    "end": "2494070"
  },
  {
    "text": "once delivery so duplicates can occur and you need to engineer around being",
    "start": "2494070",
    "end": "2499650"
  },
  {
    "text": "able to handle that if your data needs to be exactly once you need to figure out how to do that well we have some we",
    "start": "2499650",
    "end": "2508260"
  },
  {
    "text": "spent some engineering time to figure this out we have all of our messages numbered and we can identify when gaps",
    "start": "2508260",
    "end": "2515340"
  },
  {
    "text": "and duplicates appear by keeping like hashing some degree of some history of",
    "start": "2515340",
    "end": "2521070"
  },
  {
    "text": "the messages that each consumer has seen and then you can get rid of duplicates and you can only monitor gaps once the",
    "start": "2521070",
    "end": "2527370"
  },
  {
    "text": "message is gone it's kind of gone but we've found that it's well within the amount that's we can handle",
    "start": "2527370",
    "end": "2535040"
  },
  {
    "text": "so to summarize with some of the lessons that we've learned in particular with respect to each of the AWS services that",
    "start": "2535040",
    "end": "2541920"
  },
  {
    "text": "we've used DynamoDB is very versatile and a reliable key value store it has a",
    "start": "2541920",
    "end": "2549660"
  },
  {
    "text": "lot of nice features it's very highly available and we haven't had that many issues with the cost of storage but",
    "start": "2549660",
    "end": "2557280"
  },
  {
    "text": "provisioning reads and writes will be an issue if you're not careful about it if",
    "start": "2557280",
    "end": "2562980"
  },
  {
    "text": "you are writing a lot into dynamodb it will cost you so what we found is it may",
    "start": "2562980",
    "end": "2569760"
  },
  {
    "text": "be best for larger data sets with less provision throughput ElastiCache Redis has a fast feature like datastore you",
    "start": "2569760",
    "end": "2579980"
  },
  {
    "text": "scale the amount that you want to store in RAM the number of I ops are",
    "start": "2579980",
    "end": "2587010"
  },
  {
    "text": "performing in CPU but large volumes of data isn't feasible especially because",
    "start": "2587010",
    "end": "2593130"
  },
  {
    "text": "if it goes down the large volumes of data are just all gone but the small",
    "start": "2593130",
    "end": "2599910"
  },
  {
    "text": "data sets that need to be frequently and updated frequently a moving time window in particular makes a lot of sense right Kinesis I've",
    "start": "2599910",
    "end": "2611410"
  },
  {
    "text": "already heard a lot about Kinesis but in particular checkpointing we found to be very useful we've played around using",
    "start": "2611410",
    "end": "2617980"
  },
  {
    "text": "multiple applications with really with streams that a lot of our teams internally are interested in they can",
    "start": "2617980",
    "end": "2624370"
  },
  {
    "text": "just write their own applications to consume that stream and none of them interfere with each other and that's wonderful",
    "start": "2624370",
    "end": "2630640"
  },
  {
    "text": "additionally the libraries are great we had some issues with the amount of CPU that was being used but from what I've",
    "start": "2630640",
    "end": "2637210"
  },
  {
    "text": "heard more recent versions that we haven't upgraded to yet have solved that problem lambda is a really like",
    "start": "2637210",
    "end": "2646600"
  },
  {
    "text": "theoretically great way of transitioning computing I would love to not manage my",
    "start": "2646600",
    "end": "2653140"
  },
  {
    "text": "own servers but investigating issues was difficult and if you can't do that",
    "start": "2653140",
    "end": "2658960"
  },
  {
    "text": "reliably because issues will always occur it has limited utility and so just",
    "start": "2658960",
    "end": "2664990"
  },
  {
    "text": "in general AWS I've already mentioned rapidly wrapped mobility in experimenting with",
    "start": "2664990",
    "end": "2671230"
  },
  {
    "text": "products having teams have complete ownership of their own infrastructure is great",
    "start": "2671230",
    "end": "2676510"
  },
  {
    "text": "built in tooling and monitoring like like having auto scaling and elastic load balancing just provided for you is",
    "start": "2676510",
    "end": "2682680"
  },
  {
    "text": "really important features that we take advantage of but some of the costs to",
    "start": "2682680",
    "end": "2688450"
  },
  {
    "text": "working AWS include you need to really carefully manage your resource utilization basically when you have this",
    "start": "2688450",
    "end": "2696490"
  },
  {
    "text": "is kind of a growing pains that we've had a podcast where we have our own internal infrastructure and we're",
    "start": "2696490",
    "end": "2702340"
  },
  {
    "text": "transitioning into AWS but as we do so we can't take the band or take for",
    "start": "2702340",
    "end": "2707860"
  },
  {
    "text": "granted the same things we did before you've already bought your servers you're not paying anything more for them",
    "start": "2707860",
    "end": "2713850"
  },
  {
    "text": "so you can kind of be haphazard with how you use them that's not true in AWS and",
    "start": "2713850",
    "end": "2719250"
  },
  {
    "text": "if you're not careful about how much you're consuming you will very quickly spend too much money so engineering",
    "start": "2719250",
    "end": "2726780"
  },
  {
    "text": "problems arise around cost optimization that didn't before which was interesting to us",
    "start": "2726780",
    "end": "2732250"
  },
  {
    "text": "and there was a surprising amount of opacity in particular with the limits that on your account these like hidden",
    "start": "2732250",
    "end": "2737789"
  },
  {
    "text": "speed limits that I exist especially you know if there's something that you need",
    "start": "2737789",
    "end": "2743160"
  },
  {
    "text": "to do rapidly there was some scale you didn't anticipate you to quickly expand out some your architecture to",
    "start": "2743160",
    "end": "2749369"
  },
  {
    "text": "accommodate like Friday or something you should have anticipated coming there's a",
    "start": "2749369",
    "end": "2755369"
  },
  {
    "text": "real risk of the the scale not being",
    "start": "2755369",
    "end": "2761099"
  },
  {
    "text": "available because of these account limits I think meant to protect you that can",
    "start": "2761099",
    "end": "2767369"
  },
  {
    "text": "really bite you if you don't plan around them so yeah that's pretty much all that",
    "start": "2767369",
    "end": "2772529"
  },
  {
    "text": "I have prepared thank you for the time",
    "start": "2772529",
    "end": "2781190"
  },
  {
    "text": "really quick again I'm crash the obligated to let you know that you can apply to reinvent qualcast calm please",
    "start": "2781190",
    "end": "2788670"
  },
  {
    "text": "we'd love to talk to you additionally complete your evaluations please tell the world I'm great and",
    "start": "2788670",
    "end": "2794700"
  },
  {
    "text": "ready cos great and here are some related sessions for you to maybe explore if you liked what you saw today",
    "start": "2794700",
    "end": "2802010"
  },
  {
    "text": "but happy to answer any questions if you have any yeah for sure we're gonna be sticking around for at least 15 minutes",
    "start": "2802010",
    "end": "2807510"
  },
  {
    "text": "yes",
    "start": "2807510",
    "end": "2810020"
  }
]
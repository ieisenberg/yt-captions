[
  {
    "start": "0",
    "end": "134000"
  },
  {
    "text": "hello everyone in this session we will be talking about simplifying capacity management using auto scaling just to",
    "start": "60",
    "end": "7919"
  },
  {
    "text": "help me out just so I can understand what the experience for scaling is in the room if I can just get a quick show",
    "start": "7919",
    "end": "14009"
  },
  {
    "text": "of hands how many of you plan on using auto scaling for the very first time and",
    "start": "14009",
    "end": "20180"
  },
  {
    "text": "how many of you have been using auto scaling but are here to learn about the end-to-end capabilities and the new",
    "start": "20180",
    "end": "28439"
  },
  {
    "text": "features that we've launched and how many I hear to hear Netflix as to how",
    "start": "28439",
    "end": "34500"
  },
  {
    "text": "they are using auto scaling well ok so it looks like we do have content that's",
    "start": "34500",
    "end": "40890"
  },
  {
    "text": "going to satisfy pretty much all of you so super excited I'm always excited to",
    "start": "40890",
    "end": "47250"
  },
  {
    "text": "be talking about this topic since there are a few dimensions to the elasticity that the AWS cloud provides one of them",
    "start": "47250",
    "end": "54360"
  },
  {
    "text": "is the ability to provision hundreds and thousands of servers in no time without",
    "start": "54360",
    "end": "60300"
  },
  {
    "text": "any upfront capital expenditure another dimension is the one that we will be talking about in this session that is",
    "start": "60300",
    "end": "67080"
  },
  {
    "text": "around automating the provisioning and capacity management of your ec2",
    "start": "67080",
    "end": "72119"
  },
  {
    "text": "instances our auto scaling is not just about adding or removing capacity as in",
    "start": "72119",
    "end": "77580"
  },
  {
    "text": "when the traffic to your application changes but there's a lot more to it than that a number of our customers they",
    "start": "77580",
    "end": "85170"
  },
  {
    "text": "manage all their ec2 capacity using auto scaling whether they are whether their",
    "start": "85170",
    "end": "90840"
  },
  {
    "text": "application has one instance or 10 or even more my name is Anil Kapoor I'm the",
    "start": "90840",
    "end": "97229"
  },
  {
    "text": "senior product manager for the auto scaling service and I help our customers with maximizing their application",
    "start": "97229",
    "end": "102869"
  },
  {
    "text": "performance while at the same time lowering the cost I'm also super excited",
    "start": "102869",
    "end": "108270"
  },
  {
    "text": "to have Netflix here with us who will be sharing how they use auto scaling before",
    "start": "108270",
    "end": "116310"
  },
  {
    "text": "we get started I just wanted to quickly go over the three offerings that we have for auto scaling the first one is ec2",
    "start": "116310",
    "end": "124590"
  },
  {
    "text": "auto scaling that we launched back in 2009 which helps with the capacity management of ec2 instances",
    "start": "124590",
    "end": "132319"
  },
  {
    "text": "the second one is application auto-scaling",
    "start": "132319",
    "end": "137450"
  },
  {
    "start": "134000",
    "end": "134000"
  },
  {
    "text": "which we launched in 2016 when we started to extend the automatic",
    "start": "137450",
    "end": "144049"
  },
  {
    "text": "provisioning capacitor automatic provisioning of capacity to services beyond ec2 today we support seven",
    "start": "144049",
    "end": "151879"
  },
  {
    "text": "services for compute we support ec2 container service for databases or rora",
    "start": "151879",
    "end": "157700"
  },
  {
    "text": "and DynamoDB for machine learning Sage Maker we also support app stream 2.0 the",
    "start": "157700",
    "end": "165620"
  },
  {
    "text": "third is AWS Water scaling this is something we launched earlier this year which allows you to scale a number of",
    "start": "165620",
    "end": "172909"
  },
  {
    "text": "services at the same time in a very simple fashion so say for example you have an application that is using ec2",
    "start": "172909",
    "end": "181010"
  },
  {
    "text": "instances and DynamoDB tables you can set up the automatic provisioning and",
    "start": "181010",
    "end": "186260"
  },
  {
    "text": "scaling of all these resources from one single interface but in this session we",
    "start": "186260",
    "end": "193040"
  },
  {
    "start": "192000",
    "end": "192000"
  },
  {
    "text": "will be doing a deep dive on ec2 auto scaling this is not a trick question the",
    "start": "193040",
    "end": "198799"
  },
  {
    "text": "answer is e whenever I see an option which has all of the above I always end",
    "start": "198799",
    "end": "203900"
  },
  {
    "text": "up choosing that so to begin with I will be sharing with you how to get started",
    "start": "203900",
    "end": "209810"
  },
  {
    "text": "with auto scaling and how to get the right software on your ec2 instances",
    "start": "209810",
    "end": "215180"
  },
  {
    "text": "when I use when you are using them with auto scaling second is once you have the",
    "start": "215180",
    "end": "220910"
  },
  {
    "text": "software installed on these instances how can we work so that the effort",
    "start": "220910",
    "end": "226699"
  },
  {
    "text": "required around maintaining the instant these instances is minimized and once",
    "start": "226699",
    "end": "233000"
  },
  {
    "text": "we've done that then we'll take a look at how to optimize the provisioning so that we can optimize for the",
    "start": "233000",
    "end": "240199"
  },
  {
    "text": "availability and cost but before we get started I quickly want to go over what",
    "start": "240199",
    "end": "248030"
  },
  {
    "start": "243000",
    "end": "243000"
  },
  {
    "text": "an auto scaling droop or nes years as this is a term that you will be hearing",
    "start": "248030",
    "end": "253280"
  },
  {
    "text": "and using over and over again and ASG is a logical group of instances so for",
    "start": "253280",
    "end": "259820"
  },
  {
    "text": "example you have you have an application that is being powered by a number of ec2 instances all those easy",
    "start": "259820",
    "end": "266240"
  },
  {
    "text": "ec2 instances are going to be a part of a single ASG it is bound by the minimum",
    "start": "266240",
    "end": "271940"
  },
  {
    "text": "and maximum capacity so the number of instances running in the ASG is not",
    "start": "271940",
    "end": "277310"
  },
  {
    "text": "going to go beyond the maximum so you don't have to worry about cost overruns",
    "start": "277310",
    "end": "282800"
  },
  {
    "text": "or runaway scaling and the same concept applies with the minimum capacity as",
    "start": "282800",
    "end": "288080"
  },
  {
    "text": "well desired capacity is what determines the number of instances that should be",
    "start": "288080",
    "end": "294770"
  },
  {
    "text": "running in the ASG at any given time so the ASG is going to eat the launch",
    "start": "294770",
    "end": "299870"
  },
  {
    "text": "instances or terminate instances so as to meet the desired capacity now one of",
    "start": "299870",
    "end": "306410"
  },
  {
    "text": "the questions is that when the instance has come up what are the properties of these instances going to be so that's",
    "start": "306410",
    "end": "314270"
  },
  {
    "text": "determined by the launch template and this is something that you are saying with the ASG when you configure or",
    "start": "314270",
    "end": "321470"
  },
  {
    "text": "create one so what is the instance type that's going to be launched whether it's a c3 large",
    "start": "321470",
    "end": "327470"
  },
  {
    "text": "a c4 large what the Amazon machine image that's going to be associated with the",
    "start": "327470",
    "end": "334310"
  },
  {
    "text": "instances at a launch so all this data is contained and B launch template with",
    "start": "334310",
    "end": "342800"
  },
  {
    "text": "that let's get to the first use case of automating the provisioning of these ec2",
    "start": "342800",
    "end": "347960"
  },
  {
    "text": "instances so when the instances come up they need to have the software and all",
    "start": "347960",
    "end": "353449"
  },
  {
    "start": "350000",
    "end": "350000"
  },
  {
    "text": "the application code installed on them so that they can start accepting the traffic or start doing the work one of",
    "start": "353449",
    "end": "360080"
  },
  {
    "text": "the more popular ways that we've seen is using a golden image or a golden ami",
    "start": "360080",
    "end": "365870"
  },
  {
    "text": "which has all the software and configuration already pre-baked into the",
    "start": "365870",
    "end": "371389"
  },
  {
    "text": "ami and that's what you specify in the launch template that that we saw before so when the instance comes up it already",
    "start": "371389",
    "end": "378949"
  },
  {
    "text": "has all the chord and application installed on it the instances ready to start accepting the traffic the second",
    "start": "378949",
    "end": "387349"
  },
  {
    "text": "is where you specify a base ami and then the the instance is going to launch with",
    "start": "387349",
    "end": "393860"
  },
  {
    "text": "the base EMI and then you end up installing the court all the application as in when needed",
    "start": "393860",
    "end": "399720"
  },
  {
    "text": "after the instance has launched so one of the ways to achieve that is you think the user data which is in the launch",
    "start": "399720",
    "end": "407070"
  },
  {
    "text": "template so you can specify your scripts and then as the instance launches it's going to end up running the scripts and",
    "start": "407070",
    "end": "414180"
  },
  {
    "text": "installing the code ASG is also integrated with core deploy and Systems Manager also if you're using",
    "start": "414180",
    "end": "422400"
  },
  {
    "text": "one of the configuration management tools such as ansible puppet chef you",
    "start": "422400",
    "end": "427920"
  },
  {
    "text": "can use those as well so as to pull or push the configuration as the instances",
    "start": "427920",
    "end": "433140"
  },
  {
    "text": "come up this is what user data script",
    "start": "433140",
    "end": "439290"
  },
  {
    "text": "looks like so in this case what I'm doing is I whenever the instance comes up I want to install the system updates",
    "start": "439290",
    "end": "446730"
  },
  {
    "text": "I'm doing that using the yum update and once that's done I want to install the core deploy agent so whenever the",
    "start": "446730",
    "end": "453090"
  },
  {
    "text": "instance comes up it already has the code deploy agent installed ready to go",
    "start": "453090",
    "end": "458730"
  },
  {
    "text": "and the core deploy service can start interacting with the the instances that",
    "start": "458730",
    "end": "464760"
  },
  {
    "text": "just launched and then push the code as and when needed another use case which",
    "start": "464760",
    "end": "472830"
  },
  {
    "start": "470000",
    "end": "470000"
  },
  {
    "text": "we see is that winds when the instance is coming up you wanted to take additional actions such as you want to",
    "start": "472830",
    "end": "479580"
  },
  {
    "text": "attach an elastic IP address you want to install a lasting network interfaces or",
    "start": "479580",
    "end": "485820"
  },
  {
    "text": "when the instance is terminating you want to download the logs or you want to persist the state of the instance so",
    "start": "485820",
    "end": "493830"
  },
  {
    "text": "this is what the the lifecycle of an instance in an ESG looks like when the",
    "start": "493830",
    "end": "499950"
  },
  {
    "text": "instance has to be added first it goes into the pending state once all the work is done then the second step is to go",
    "start": "499950",
    "end": "507480"
  },
  {
    "text": "into the in-service State so with lifecycle hooks what you can do is you can pause the the transition of",
    "start": "507480",
    "end": "514590"
  },
  {
    "text": "the state from pending to end service and while it's paused you can take the",
    "start": "514590",
    "end": "519960"
  },
  {
    "text": "actions such as attaching an elastic IP address using automated lambda functions",
    "start": "519960",
    "end": "525840"
  },
  {
    "text": "and similarly we're even with the terminating State so when it goes into the terminating state you make it pause",
    "start": "525840",
    "end": "532140"
  },
  {
    "text": "there your lambda functions download your logs down will persist the state of the",
    "start": "532140",
    "end": "537280"
  },
  {
    "text": "instance and then move on to the terminated state instead of using",
    "start": "537280",
    "end": "542880"
  },
  {
    "text": "lifecycle hooks you can also choose to receive event notifications when these",
    "start": "542880",
    "end": "548850"
  },
  {
    "text": "state transitions happen so for example when the instance launch is successful",
    "start": "548850",
    "end": "554110"
  },
  {
    "text": "or our termination is successful we have full integration with simple notification service and cloud watch",
    "start": "554110",
    "end": "560560"
  },
  {
    "text": "events so say if you want to receive notifications and you want to send it to",
    "start": "560560",
    "end": "566080"
  },
  {
    "text": "a page or alias whenever launch is unsuccessful you can do so and then",
    "start": "566080",
    "end": "571450"
  },
  {
    "text": "someone can manually check in or if you're using another system to do all",
    "start": "571450",
    "end": "576580"
  },
  {
    "text": "the event logging you can send all your events to that system and do your event",
    "start": "576580",
    "end": "581710"
  },
  {
    "text": "logging we also have full integration with elastic load balancing with all",
    "start": "581710",
    "end": "587620"
  },
  {
    "start": "584000",
    "end": "584000"
  },
  {
    "text": "three the classic load balancer the application load balancer and the network load balancer so all you've got",
    "start": "587620",
    "end": "595360"
  },
  {
    "text": "to do is when you're setting up the ASG or creating the ASG you specify the load balancer or the",
    "start": "595360",
    "end": "601150"
  },
  {
    "text": "target crew and then when the instance comes up it is automatically going to be end up getting registered behind the",
    "start": "601150",
    "end": "608200"
  },
  {
    "text": "load balancer so once we have the instance up and running and the ASG set",
    "start": "608200",
    "end": "615280"
  },
  {
    "text": "up we want to ensure that the the work around maintaining this fleet is minimized what that means is if anything",
    "start": "615280",
    "end": "622750"
  },
  {
    "text": "were to happen to my instances I want the remediation to happen automatically",
    "start": "622750",
    "end": "628540"
  },
  {
    "text": "without any manual intervention so we have integration with both ec2 health",
    "start": "628540",
    "end": "636040"
  },
  {
    "text": "checks and ELB health checks so say for example you very popular set up where",
    "start": "636040",
    "end": "642250"
  },
  {
    "text": "the ASG is running behind a load balancer and you have it configured so as to honor the alb health checks say if",
    "start": "642250",
    "end": "650260"
  },
  {
    "text": "the alb health checks hell check fails ASG is automatically going to end up",
    "start": "650260",
    "end": "656890"
  },
  {
    "text": "launching a replacement instance now",
    "start": "656890",
    "end": "662230"
  },
  {
    "text": "from AWS while architected perspective one of the best practices is that your",
    "start": "662230",
    "end": "667950"
  },
  {
    "text": "ec2 capacity should be distributed across availability zones so in this",
    "start": "667950",
    "end": "674340"
  },
  {
    "text": "particular example I have behind my ASG I've selected two AZ's and the desired",
    "start": "674340",
    "end": "682890"
  },
  {
    "text": "capacity is at this time six instances so ASG is going to launch three",
    "start": "682890",
    "end": "688170"
  },
  {
    "text": "instances and 1az and the other three and the other AC so it's going to balance the capacity and say if anything",
    "start": "688170",
    "end": "695820"
  },
  {
    "text": "were to go wrong with one of the Aces ASG is automatically going to end up",
    "start": "695820",
    "end": "702200"
  },
  {
    "text": "retargeting the capacity to another AC which is available and once it does so",
    "start": "702200",
    "end": "707910"
  },
  {
    "text": "it's going to end up launching one instance it's going to try and hope the",
    "start": "707910",
    "end": "713220"
  },
  {
    "text": "the AC that was constrained and as soon as that instance launch is successful once again it's going to end up",
    "start": "713220",
    "end": "719520"
  },
  {
    "text": "rebalancing the capacity across the a sees that you have specified with your",
    "start": "719520",
    "end": "724620"
  },
  {
    "text": "ASG now we've made it easier than ever",
    "start": "724620",
    "end": "731130"
  },
  {
    "text": "to use spot instances with your aSG's so that you can get the benefit of spot instances lower your cost by up to",
    "start": "731130",
    "end": "738060"
  },
  {
    "text": "ninety percent with using spot instances this is something we just launched two",
    "start": "738060",
    "end": "743160"
  },
  {
    "text": "weeks ago so earlier your ASG was homogeneous it could only have one",
    "start": "743160",
    "end": "749220"
  },
  {
    "text": "instance type and it could be only one pricing option now you can create an ESG",
    "start": "749220",
    "end": "755610"
  },
  {
    "text": "which spans across pricing options which are for example spot instances on demand",
    "start": "755610",
    "end": "761640"
  },
  {
    "text": "reserved instances and you can span them across instance types so before you had",
    "start": "761640",
    "end": "768480"
  },
  {
    "text": "to create one ASG per instance type and one pricing option now when you're",
    "start": "768480",
    "end": "774360"
  },
  {
    "text": "creating an ESG all you've got to do is specify how much of your capacity should",
    "start": "774360",
    "end": "779370"
  },
  {
    "text": "be fulfilled with on-demand instances and how much of your capacity or in in in percentage terms should be fulfilled",
    "start": "779370",
    "end": "786450"
  },
  {
    "text": "with on-demand instances and you also specify which instance types work for you from there ASG is going to",
    "start": "786450",
    "end": "794010"
  },
  {
    "text": "automatically mix and match these combinations so as to provision capacity for you at the lowest price if",
    "start": "794010",
    "end": "802179"
  },
  {
    "text": "you have arrays for the instance types that you have specified you will end up",
    "start": "802179",
    "end": "807349"
  },
  {
    "text": "getting the other benefit we will be doing a deep dive on this topic or later",
    "start": "807349",
    "end": "812929"
  },
  {
    "text": "this afternoon in a chalk talk and we will have a repeat for that this first day as well",
    "start": "812929",
    "end": "819879"
  },
  {
    "text": "the last use case I want to talk about is that I want to draw or shrink my",
    "start": "819879",
    "end": "824929"
  },
  {
    "text": "capacity automatically as the load to my application changes what that means is I",
    "start": "824929",
    "end": "831019"
  },
  {
    "text": "do not want to provision for peak capacity at all times so as to ensure that the application behavior is going",
    "start": "831019",
    "end": "839359"
  },
  {
    "text": "to be fine so in other words I don't want to be paying for capacity that I'm",
    "start": "839359",
    "end": "844669"
  },
  {
    "text": "not using and I do not want my application to have sluggish behavior if",
    "start": "844669",
    "end": "849909"
  },
  {
    "text": "I don't have enough capacity so this all",
    "start": "849909",
    "end": "855799"
  },
  {
    "text": "goes back to the concept that we discussed earlier about the men max and the desired size of the ASG",
    "start": "855799",
    "end": "861889"
  },
  {
    "text": "so the question becomes is how and when to each of these parameters need to",
    "start": "861889",
    "end": "866929"
  },
  {
    "text": "change the easiest way of achieving this is you simply go into the ASG and update",
    "start": "866929",
    "end": "874369"
  },
  {
    "start": "869000",
    "end": "869000"
  },
  {
    "text": "one of these parameters as soon as you enter them the ASG is going to end up",
    "start": "874369",
    "end": "879559"
  },
  {
    "text": "getting to the new state if you have a known pattern for example a 9 to 5",
    "start": "879559",
    "end": "884989"
  },
  {
    "text": "pattern where you want to bring up the capacity in the morning at 9:00 a.m. and you want to bring it down at 5:00 p.m.",
    "start": "884989",
    "end": "891649"
  },
  {
    "text": "in the afternoon you can do so using schedule scaling if you have more complex patterns you can do all that",
    "start": "891649",
    "end": "898999"
  },
  {
    "text": "with schedule scaling the third is dynamic scaling with target tracking",
    "start": "898999",
    "end": "904879"
  },
  {
    "start": "902000",
    "end": "902000"
  },
  {
    "text": "target tracking is something we launched last year it's gained a lot of popularity it works just like a",
    "start": "904879",
    "end": "911059"
  },
  {
    "text": "thermostat or a cruise control in your car all you've got to do is you want to",
    "start": "911059",
    "end": "916249"
  },
  {
    "text": "pick the metric that you want to scale on so for example the average CPU utilization of the ASG and you end up",
    "start": "916249",
    "end": "924169"
  },
  {
    "text": "selecting the target that you want to maintain so if you know that yes your",
    "start": "924169",
    "end": "930649"
  },
  {
    "text": "application works just fine as as the CPU utilization is below 50% that's what you end up setting the",
    "start": "930649",
    "end": "936200"
  },
  {
    "text": "target at so in this example we have traffic coming to the load balancer which goes forward to the instances and",
    "start": "936200",
    "end": "943339"
  },
  {
    "text": "we see that the average CPU utilization is at 50% as more traffic starts to come",
    "start": "943339",
    "end": "950690"
  },
  {
    "text": "into the load balancer more work has to be done by the instances and the CPU utilization goes up in this case target",
    "start": "950690",
    "end": "959029"
  },
  {
    "text": "tracking determines how many more instances does it need to launch so as to bring the CPU utilization back to the",
    "start": "959029",
    "end": "965660"
  },
  {
    "text": "normal level so in this case there determines it needs another five instances so as soon as target tracking",
    "start": "965660",
    "end": "972440"
  },
  {
    "text": "is able to launch another five instances the CPU utilization goes back to the",
    "start": "972440",
    "end": "977450"
  },
  {
    "text": "normal level and once again everything is fine you can also set up dynamic",
    "start": "977450",
    "end": "986180"
  },
  {
    "start": "984000",
    "end": "984000"
  },
  {
    "text": "scaling with step scaling policies while target tracking does all this work for you if for any reason you want to have",
    "start": "986180",
    "end": "993649"
  },
  {
    "text": "finer drain control of the steps and of the alarms that need to be defined you",
    "start": "993649",
    "end": "998779"
  },
  {
    "text": "can do so you can configure the alarms manually you can configure the thresholds associated with those alarms",
    "start": "998779",
    "end": "1004660"
  },
  {
    "text": "and then you can set up the step so for example you want to say if the alarm is preached by at 50 percent of CPU",
    "start": "1004660",
    "end": "1013270"
  },
  {
    "text": "utilization I want to act two instances if it reaches sixty percent I want to",
    "start": "1013270",
    "end": "1018520"
  },
  {
    "text": "add four instances if it reaches 70 percent I want to add six instances the",
    "start": "1018520",
    "end": "1023560"
  },
  {
    "text": "same concept applies with scaling in or removing instances as well the last is",
    "start": "1023560",
    "end": "1032290"
  },
  {
    "start": "1030000",
    "end": "1030000"
  },
  {
    "text": "predictive scaling this is something we launched just last week there's another session going on at this time talking",
    "start": "1032290",
    "end": "1038380"
  },
  {
    "text": "about this so with target tracking what we saw was target tracking adds or removes capacity",
    "start": "1038380",
    "end": "1046270"
  },
  {
    "text": "in response to the changing load to your application with predictive scaling it",
    "start": "1046270",
    "end": "1052270"
  },
  {
    "text": "uses machine learning and the models that we have been able to train with the billions of data points that we have",
    "start": "1052270",
    "end": "1058750"
  },
  {
    "text": "from amazon.com and what it does is it looks at your historical traffic coming",
    "start": "1058750",
    "end": "1064179"
  },
  {
    "text": "into ASG and then based on that it predicts what the traffic in the future is going",
    "start": "1064179",
    "end": "1069669"
  },
  {
    "text": "to be at the same time it also runs a regression model to understand how many",
    "start": "1069669",
    "end": "1076390"
  },
  {
    "text": "instances need to be provisioned so as to cater the traffic that's going to be",
    "start": "1076390",
    "end": "1083169"
  },
  {
    "text": "coming in based on the prediction so",
    "start": "1083169",
    "end": "1088600"
  },
  {
    "text": "target tracking and predictive scaling they are complimentary to each other and their work extremely well when used in",
    "start": "1088600",
    "end": "1095770"
  },
  {
    "text": "combination with that now I would love for Netflix to come up and share how",
    "start": "1095770",
    "end": "1101980"
  },
  {
    "text": "Netflix operates at the scale at which they do using auto scaling speaking of the",
    "start": "1101980",
    "end": "1122230"
  },
  {
    "text": "Netflix scale we operate a global service we have more than 137 million",
    "start": "1122230",
    "end": "1129700"
  },
  {
    "text": "subscribers as of q3 it's a little bit more now one statistic that is not very",
    "start": "1129700",
    "end": "1137919"
  },
  {
    "text": "often quoted but I think is a very very indicative of our scale is the fact that",
    "start": "1137919",
    "end": "1143620"
  },
  {
    "text": "we support over 1,700 device types including TVs mobile tablets set-top",
    "start": "1143620",
    "end": "1152890"
  },
  {
    "text": "boxes you name it if it has a screen and HDMI out likely it can run Netflix we",
    "start": "1152890",
    "end": "1161710"
  },
  {
    "text": "deploy in three AWS regions we have over quarter-million reserved instances and",
    "start": "1161710",
    "end": "1169419"
  },
  {
    "text": "over 20,000 aSG's across three regions we operate a massive network of open",
    "start": "1169419",
    "end": "1177580"
  },
  {
    "text": "connect appliances over 10,000 boxes with exabyte level storage our data",
    "start": "1177580",
    "end": "1184630"
  },
  {
    "text": "warehouse size is over 100 terabytes I think this estimate is a little bit on",
    "start": "1184630",
    "end": "1190419"
  },
  {
    "text": "the conservative side and will run hundreds of a B tests per year how do we",
    "start": "1190419",
    "end": "1197020"
  },
  {
    "text": "support this scale well with help of AWS auto-scaling it all",
    "start": "1197020",
    "end": "1204060"
  },
  {
    "text": "starts with provisioning and when it comes to provisioning or the scaling gives us plenty of options we can choose",
    "start": "1204060",
    "end": "1210840"
  },
  {
    "text": "from instance bootstrapping options we can choose from rebalancing options health check options so on so forth",
    "start": "1210840",
    "end": "1218460"
  },
  {
    "text": "also order scale and gives us a lot of api's and integration points we use",
    "start": "1218460",
    "end": "1227390"
  },
  {
    "text": "spinnaker this is an open source software that was developed primarily by",
    "start": "1227390",
    "end": "1232680"
  },
  {
    "text": "Netflix we use it internally we use it as a continuous delivery and it's the",
    "start": "1232680",
    "end": "1238380"
  },
  {
    "text": "next layer on the top of AWS provided features on the top of AWS auto-scaling",
    "start": "1238380",
    "end": "1245390"
  },
  {
    "text": "spinnaker gives us abstractions for managing order scale and groups for",
    "start": "1245390",
    "end": "1251610"
  },
  {
    "text": "example spinnaker has an atomic operation for cloning and ASG we're",
    "start": "1251610",
    "end": "1256920"
  },
  {
    "text": "talking about deep cloning with security groups killing pulses and so on so forth",
    "start": "1256920",
    "end": "1262430"
  },
  {
    "text": "based on this abstractions based on this building block spinnaker allows us to",
    "start": "1262430",
    "end": "1267540"
  },
  {
    "text": "create various automation and pipelines and to automate our deployment process",
    "start": "1267540",
    "end": "1274200"
  },
  {
    "text": "and lastly spinnaker integrates with a lot of other Netflix tools for telemetry reporting so on so forth on the top of",
    "start": "1274200",
    "end": "1282900"
  },
  {
    "text": "spinnaker we build something that we called immutable infrastructure we",
    "start": "1282900",
    "end": "1289020"
  },
  {
    "text": "bootstrap our instances with pre-baked golden ami we never change the software",
    "start": "1289020",
    "end": "1295020"
  },
  {
    "text": "on the instances we never patch them during their lifetime when we need to",
    "start": "1295020",
    "end": "1300510"
  },
  {
    "text": "deploy a new version of the code we use red-black deploys the industry standard",
    "start": "1300510",
    "end": "1306570"
  },
  {
    "text": "name for this as blue green but I'll stick with Netflix nomenclature that's what we call it internally red black",
    "start": "1306570",
    "end": "1312870"
  },
  {
    "text": "deploys basically it refers to the pattern of spinning up in USG with the",
    "start": "1312870",
    "end": "1319590"
  },
  {
    "text": "new ami that has a new version of the code then shifting the traffic over to",
    "start": "1319590",
    "end": "1324930"
  },
  {
    "text": "that new ASG and then destroying the old ASG and lastly in each region we deploy",
    "start": "1324930",
    "end": "1331590"
  },
  {
    "text": "across three availability zones and we rely on auto scaling to balance us evenly across",
    "start": "1331590",
    "end": "1337559"
  },
  {
    "text": "ACS replacing unhealthy instances or",
    "start": "1337559",
    "end": "1343440"
  },
  {
    "start": "1341000",
    "end": "1341000"
  },
  {
    "text": "fleet management this refers to the feature of auto scaling that guarantees",
    "start": "1343440",
    "end": "1349500"
  },
  {
    "text": "that auto scaling will maintain desired capacity and replace instances that",
    "start": "1349500",
    "end": "1355170"
  },
  {
    "text": "either failed health check or were terminated externally or otherwise disappears a few years ago we developed",
    "start": "1355170",
    "end": "1364620"
  },
  {
    "text": "chaos monkey some of you might be familiar with this tool maybe some of",
    "start": "1364620",
    "end": "1369720"
  },
  {
    "text": "you run it in your environment as well the premise is simple chaos monkey",
    "start": "1369720",
    "end": "1375260"
  },
  {
    "text": "terminates instances at random with a certain frequency of course we did it to",
    "start": "1375260",
    "end": "1382830"
  },
  {
    "text": "ensure that our software is resilient to failures we did it to ensure that a lot",
    "start": "1382830",
    "end": "1390270"
  },
  {
    "text": "of any single instance doesn't affect our service we refer to it as a continuous resiliency testing but this",
    "start": "1390270",
    "end": "1398100"
  },
  {
    "text": "tool was made possible by the fact that auto scaling replaces those instances",
    "start": "1398100",
    "end": "1404970"
  },
  {
    "text": "that callous monkey terminates and allows allows our service to move on a",
    "start": "1404970",
    "end": "1410929"
  },
  {
    "text": "more pragmatic approach alerting we have",
    "start": "1410929",
    "end": "1416550"
  },
  {
    "text": "a system that supports both threshold based alerts and outlier detection alerts when we detect that a particular",
    "start": "1416550",
    "end": "1424440"
  },
  {
    "text": "instance have a higher error rate higher CPU utilization or any other conditions",
    "start": "1424440",
    "end": "1430260"
  },
  {
    "text": "that might be adverse to the service of overall we can choose to terminate that",
    "start": "1430260",
    "end": "1435360"
  },
  {
    "text": "instance and AWS replaces it with a brand-new healthy instance lifecycle",
    "start": "1435360",
    "end": "1445140"
  },
  {
    "start": "1443000",
    "end": "1443000"
  },
  {
    "text": "hooks lifecycle hooks allow you to get",
    "start": "1445140",
    "end": "1451220"
  },
  {
    "text": "notifications and to run your own commands or code based based on the life",
    "start": "1451220",
    "end": "1459600"
  },
  {
    "text": "cycle of the instance when it transitions from pending to in service to terminating to final",
    "start": "1459600",
    "end": "1466290"
  },
  {
    "text": "terminated at Netflix we use something that we call a discovery service you can",
    "start": "1466290",
    "end": "1474060"
  },
  {
    "text": "think of it as an application-level DNS every instance when it comes up it",
    "start": "1474060",
    "end": "1479910"
  },
  {
    "text": "registers in the application discovery service and it becomes discoverable by",
    "start": "1479910",
    "end": "1485250"
  },
  {
    "text": "any other instances it's exactly the premise of the DNS so when we terminate",
    "start": "1485250",
    "end": "1491280"
  },
  {
    "text": "an instance or when it gets terminated by dynamic skill in the instance Dee registers from discovery",
    "start": "1491280",
    "end": "1498410"
  },
  {
    "text": "the problem is discovery has a propagation delay and sometimes the",
    "start": "1498410",
    "end": "1504960"
  },
  {
    "text": "propagation delay could be longer that the time it takes for the instance to",
    "start": "1504960",
    "end": "1510480"
  },
  {
    "text": "terminate what it results in is that some instances within that region might",
    "start": "1510480",
    "end": "1516570"
  },
  {
    "text": "attempt to some traffic to the instance that was terminated already well that",
    "start": "1516570",
    "end": "1521820"
  },
  {
    "text": "obviously leads to errors how do we deal with this problem with lifecycle hooks",
    "start": "1521820",
    "end": "1528030"
  },
  {
    "text": "we have a life cycle who can termination we send the the register event to",
    "start": "1528030",
    "end": "1533940"
  },
  {
    "text": "discovery when the life cycle hook just just kicks in and then we wait week we",
    "start": "1533940",
    "end": "1541050"
  },
  {
    "text": "as the instance with drain all the traffic we made sure that the state is propagated throughout the entire region",
    "start": "1541050",
    "end": "1547860"
  },
  {
    "text": "and then we proceed with terminations",
    "start": "1547860",
    "end": "1552290"
  },
  {
    "start": "1553000",
    "end": "1553000"
  },
  {
    "text": "dynamic scaling so about three slides ago I said that Netflix have over",
    "start": "1554690",
    "end": "1561150"
  },
  {
    "text": "quarter-million of reserved instances so you might be asking well why do you even",
    "start": "1561150",
    "end": "1566250"
  },
  {
    "text": "need dynamic scaling right provision everything for peek that's it done ok",
    "start": "1566250",
    "end": "1572370"
  },
  {
    "text": "let me make a case for dynamic scaling take a look at these two images they",
    "start": "1572370",
    "end": "1577980"
  },
  {
    "text": "look identical even though if you look at it pixel by pixel you'll see",
    "start": "1577980",
    "end": "1583620"
  },
  {
    "text": "differences these are steel frames from one of our originals altered carbon the",
    "start": "1583620",
    "end": "1591570"
  },
  {
    "text": "difference between these two images is that one of them was captured from a",
    "start": "1591570",
    "end": "1597120"
  },
  {
    "text": "stream at hundred seventy I I'm sorry at 790 kilobit per second",
    "start": "1597120",
    "end": "1602880"
  },
  {
    "text": "while the other image the image on the right was captured from a stream encoded",
    "start": "1602880",
    "end": "1609210"
  },
  {
    "text": "at 383 kilobits per second that's less than a half of their original bitrate",
    "start": "1609210",
    "end": "1616280"
  },
  {
    "text": "Netflix employs something that we call encoding optimization to compress our",
    "start": "1616280",
    "end": "1621660"
  },
  {
    "text": "streams without the perceived loss in quality video encoding itself requires a",
    "start": "1621660",
    "end": "1628830"
  },
  {
    "text": "lot of compute power and a lot of capacity and running the encoding optimization requires even more capacity",
    "start": "1628830",
    "end": "1635250"
  },
  {
    "text": "where does it come from let's take a look the bottom graph the blue area",
    "start": "1635250",
    "end": "1644300"
  },
  {
    "start": "1641000",
    "end": "1641000"
  },
  {
    "text": "represents our capacity usage for a particular region for a particular",
    "start": "1644300",
    "end": "1649440"
  },
  {
    "text": "instance type you can clearly see the daily pattern here at 7:00 p.m. a lot of",
    "start": "1649440",
    "end": "1656010"
  },
  {
    "text": "people watching Netflix a lot of people streaming at 3 a.m. not so much well",
    "start": "1656010",
    "end": "1661260"
  },
  {
    "text": "still surprisingly a lot of people but not as much as at 7 p.m. so we don't",
    "start": "1661260",
    "end": "1667530"
  },
  {
    "text": "need as much capacity to support streaming at 3 a.m. as we need at our",
    "start": "1667530",
    "end": "1672900"
  },
  {
    "text": "peak at 7 p.m. so we scale up and down and that unused capacity can be used for",
    "start": "1672900",
    "end": "1682200"
  },
  {
    "text": "encoding and the graph on the top the yellow area on the top represents the",
    "start": "1682200",
    "end": "1687480"
  },
  {
    "text": "capacity that we used for encoding job we built a pipeline that harvests the",
    "start": "1687480",
    "end": "1693660"
  },
  {
    "text": "capacity that is unused during our off-peak hours and uses it for encoding",
    "start": "1693660",
    "end": "1701390"
  },
  {
    "text": "other benefits and usages of dynamic skill and recommendations our catalog is",
    "start": "1701390",
    "end": "1707190"
  },
  {
    "start": "1702000",
    "end": "1702000"
  },
  {
    "text": "always expanding our subscriber base is always expanding and we need better",
    "start": "1707190",
    "end": "1713900"
  },
  {
    "text": "recommendations better recommendations a lot of times require more sophisticated",
    "start": "1713900",
    "end": "1720390"
  },
  {
    "text": "algorithms and they require more capacity to implement the bulk of",
    "start": "1720390",
    "end": "1726030"
  },
  {
    "text": "recommendations we're running it during off-peak hours as well reusing the same capacity that we normally",
    "start": "1726030",
    "end": "1732740"
  },
  {
    "text": "use for streaming red-black deploys how does what a scale and play into that",
    "start": "1732740",
    "end": "1739220"
  },
  {
    "text": "well imagine if we provision it statically for peak when we do a red-black deploy we have to clone the",
    "start": "1739220",
    "end": "1745820"
  },
  {
    "text": "ASG we have to double up the capacity if we were statically provisioned we would",
    "start": "1745820",
    "end": "1752030"
  },
  {
    "text": "have to double up our peak capacity we usually do deploys in the morning hours",
    "start": "1752030",
    "end": "1757700"
  },
  {
    "text": "when our ASG is maybe at the half size or maybe even less than that that allows",
    "start": "1757700",
    "end": "1763280"
  },
  {
    "text": "us to save capacity on red-black deploys",
    "start": "1763280",
    "end": "1768490"
  },
  {
    "text": "this is an interesting use case regional failover internal codename Kong hence",
    "start": "1768640",
    "end": "1775580"
  },
  {
    "text": "the picture of Kong Netflix deploys in three regions and we",
    "start": "1775580",
    "end": "1780620"
  },
  {
    "text": "we developed a system that can evacuate any single region and we can still serve",
    "start": "1780620",
    "end": "1787220"
  },
  {
    "text": "traffic from the remaining two AWS regions how does auto scale and help with that",
    "start": "1787220",
    "end": "1793240"
  },
  {
    "text": "well if you think about for example North Virginia versus Ireland we see the",
    "start": "1793240",
    "end": "1800000"
  },
  {
    "text": "same daily patterns of peaks and troughs in each region but the peaks are shifted",
    "start": "1800000",
    "end": "1807770"
  },
  {
    "text": "roughly seven eight hours so when there is a peak in North Virginia there's",
    "start": "1807770",
    "end": "1813230"
  },
  {
    "text": "plenty of spare capacity in Ireland someone we're shifting traffic we don't",
    "start": "1813230",
    "end": "1818360"
  },
  {
    "text": "have to provision Ireland for the peak of peaks we have to provision it much",
    "start": "1818360",
    "end": "1823460"
  },
  {
    "text": "less than that you can think of it as adding two sine waves that are shifted",
    "start": "1823460",
    "end": "1828679"
  },
  {
    "text": "in time when you're adding them the overall the local peak is not doubling up it's much less let's talk about",
    "start": "1828679",
    "end": "1839240"
  },
  {
    "start": "1838000",
    "end": "1838000"
  },
  {
    "text": "dynamic scaling what it is and how to set it up in a nutshell dynamic scaling",
    "start": "1839240",
    "end": "1845750"
  },
  {
    "text": "is a feedback loop it's a system with a feedback loop managed is G sans metrics",
    "start": "1845750",
    "end": "1853070"
  },
  {
    "text": "the cloud watch cloud watch sends a notification when the metric breeches a",
    "start": "1853070",
    "end": "1859130"
  },
  {
    "text": "trash hold and scaling policy receives a notification and acts upon it either",
    "start": "1859130",
    "end": "1865260"
  },
  {
    "text": "or removing the capacity and feedback lupus does complete and then it repeats",
    "start": "1865260",
    "end": "1870440"
  },
  {
    "text": "each of these components have a few tuna balls well obviously the most important",
    "start": "1870440",
    "end": "1876059"
  },
  {
    "text": "one is probably the metric and the trash hold there is a number of other tunable we'll go through it later in the",
    "start": "1876059",
    "end": "1882330"
  },
  {
    "text": "presentation there is also three fundamental properties of dynamic",
    "start": "1882330",
    "end": "1889679"
  },
  {
    "start": "1885000",
    "end": "1885000"
  },
  {
    "text": "scaling that I wanted you to be aware of first is a delayed reaction as any",
    "start": "1889679",
    "end": "1896429"
  },
  {
    "text": "system with a feedback loop or the scaling dynamic scaling inherently has a",
    "start": "1896429",
    "end": "1902130"
  },
  {
    "text": "stern lag associated with it it's not good it's not bad it's a fact again any system with a feedback loop",
    "start": "1902130",
    "end": "1909059"
  },
  {
    "text": "has it and going back to what Anoop said one of the ways it could be addressed is",
    "start": "1909059",
    "end": "1916440"
  },
  {
    "text": "with introduction of predictive scale and we don't use it at Netflix not yet",
    "start": "1916440",
    "end": "1921809"
  },
  {
    "text": "it was released on the last week but it sounds very promising in the sense that",
    "start": "1921809",
    "end": "1927059"
  },
  {
    "text": "it could address the delayed reaction in addition to what target tracking already",
    "start": "1927059",
    "end": "1932160"
  },
  {
    "text": "does another property is that auto scaling dynamic scaling is comprised of",
    "start": "1932160",
    "end": "1939570"
  },
  {
    "text": "multiple policies you set them up individually they act individually but",
    "start": "1939570",
    "end": "1945150"
  },
  {
    "text": "the result the end result is a combined result of multiple policies acting",
    "start": "1945150",
    "end": "1951480"
  },
  {
    "text": "together and lastly dynamic scaling is always",
    "start": "1951480",
    "end": "1957059"
  },
  {
    "text": "bound by mean and Max SG size it only ever changes desired size it never ever",
    "start": "1957059",
    "end": "1964440"
  },
  {
    "text": "changes mean or max size",
    "start": "1964440",
    "end": "1968509"
  },
  {
    "text": "so let's see how we go about setting up dynamic scaling first we need to pick",
    "start": "1972470",
    "end": "1978350"
  },
  {
    "start": "1973000",
    "end": "1973000"
  },
  {
    "text": "the metric then we need to set the target or our scale and threshold after",
    "start": "1978350",
    "end": "1984920"
  },
  {
    "text": "that is done we usually look at our traffic patterns and see if we need to",
    "start": "1984920",
    "end": "1990890"
  },
  {
    "text": "adjust our targets or any parameters of our scale and based on our traffic patterns and lastly one once we get",
    "start": "1990890",
    "end": "1999280"
  },
  {
    "text": "everything we set up policies let's go through this step by step into in more",
    "start": "1999280",
    "end": "2006520"
  },
  {
    "text": "details what metric this is as such this is such a popular question that I even",
    "start": "2006520",
    "end": "2013750"
  },
  {
    "text": "made an xkcd style comic about it the guy on the right is me the guy on the",
    "start": "2013750",
    "end": "2019330"
  },
  {
    "text": "left is a service owner that comes to me and asked which metrics should I scale",
    "start": "2019330",
    "end": "2024460"
  },
  {
    "text": "on the answer is usually you should scale on something that shows how busy your instances at something that changes",
    "start": "2024460",
    "end": "2031960"
  },
  {
    "text": "proportionately to the number of instances in the ASG",
    "start": "2031960",
    "end": "2037110"
  },
  {
    "text": "well this answer probably is not good enough because a lot of times service",
    "start": "2037110",
    "end": "2042400"
  },
  {
    "text": "owners tell me how important the service is what it does what frameworks it uses",
    "start": "2042400",
    "end": "2047500"
  },
  {
    "text": "and business use case and repeat the question so now that you know all of",
    "start": "2047500",
    "end": "2052960"
  },
  {
    "text": "this can you please tell me what to scale on ok to explain it I prepared",
    "start": "2052960",
    "end": "2060190"
  },
  {
    "start": "2058000",
    "end": "2058000"
  },
  {
    "text": "this slide generally metrics fall under two two categories it's true put like",
    "start": "2060190",
    "end": "2067090"
  },
  {
    "text": "metrics and resource utilization like metrics it's very easy to relate to this",
    "start": "2067090",
    "end": "2072550"
  },
  {
    "text": "that's how human humans assess the work that we do as well you can think of it",
    "start": "2072550",
    "end": "2079389"
  },
  {
    "text": "in terms of how many miles I run or how many widgets I make and that would be",
    "start": "2079390",
    "end": "2084940"
  },
  {
    "text": "the true put or you can think of it in terms of how tired I am and use for",
    "start": "2084940",
    "end": "2090159"
  },
  {
    "text": "example a heart rate as a proxy of that and that would be resource utilization",
    "start": "2090160",
    "end": "2096629"
  },
  {
    "text": "AWS provides a few metrics that that satisfy that that fall under these",
    "start": "2096630",
    "end": "2102730"
  },
  {
    "text": "categories request count per target as a metric published by lb that shows the number of",
    "start": "2102730",
    "end": "2108640"
  },
  {
    "text": "instances that the number of requests that each instance processes and average",
    "start": "2108640",
    "end": "2114430"
  },
  {
    "text": "CPU utilization is a metric that is published by ASG that shows average CPU",
    "start": "2114430",
    "end": "2121300"
  },
  {
    "text": "utilization / SG there's pros and cons in this approach as both of them are",
    "start": "2121300",
    "end": "2127180"
  },
  {
    "text": "suitable for setting up dynamic scaling I really really liked throughput because",
    "start": "2127180",
    "end": "2132670"
  },
  {
    "text": "it's very intuitive it's very easy to do math on it if you have an estimate of",
    "start": "2132670",
    "end": "2138580"
  },
  {
    "text": "how much traffic you're going to get and if you know your threshold your target you can divide one by another and get an",
    "start": "2138580",
    "end": "2146500"
  },
  {
    "text": "estimate of how much capacity you would need to to hold this this traffic",
    "start": "2146500",
    "end": "2151960"
  },
  {
    "text": "the downside of throughput is it tends to drift over time as we develop and",
    "start": "2151960",
    "end": "2157870"
  },
  {
    "text": "deploy new features as we introduce different request types and the mix between request type changes it's",
    "start": "2157870",
    "end": "2164110"
  },
  {
    "text": "somewhat of a moving target CPU utilization on the other hand doesn't have these problems we can set CPU",
    "start": "2164110",
    "end": "2172780"
  },
  {
    "text": "utilization we can normalize our workload at the set CPU utilization if let's say you want to scale at 50",
    "start": "2172780",
    "end": "2179740"
  },
  {
    "text": "percent CPU utilization and if you deploy a new version of code that has heavier requests that has new features",
    "start": "2179740",
    "end": "2186850"
  },
  {
    "text": "that consume more CPU the ASG would simply scale up accordingly to",
    "start": "2186850",
    "end": "2192730"
  },
  {
    "text": "accommodate to keep you at the same CPU level or the scaling on multiple metrics",
    "start": "2192730",
    "end": "2200050"
  },
  {
    "start": "2198000",
    "end": "2198000"
  },
  {
    "text": "is something that AWS support and sometimes it might be tempting to do",
    "start": "2200050",
    "end": "2206550"
  },
  {
    "text": "however in our experience we found that setting up dynamic scaling on multiple",
    "start": "2206550",
    "end": "2214390"
  },
  {
    "text": "metrics makes it a little bit harder to reason about scale and behavior it also",
    "start": "2214390",
    "end": "2220300"
  },
  {
    "text": "easier to get in a situation 1 different metrics point in a different directions",
    "start": "2220300",
    "end": "2225790"
  },
  {
    "text": "and make auto scale and oscillate scale up and down repeatedly at Netflix our",
    "start": "2225790",
    "end": "2233080"
  },
  {
    "text": "common set up our typical Netflix setup involves scale and up and down",
    "start": "2233080",
    "end": "2238140"
  },
  {
    "text": "on throughput we also have emergency scale-up policy on CPU we call it the",
    "start": "2238140",
    "end": "2245640"
  },
  {
    "text": "hammer rule for example if we have an influx of requests we can drop the",
    "start": "2245640",
    "end": "2250680"
  },
  {
    "text": "hammer scale-up by fifty or hundred percent and survive this sudden surge in",
    "start": "2250680",
    "end": "2256680"
  },
  {
    "text": "requests another option is to scale straight on CPU and especially with",
    "start": "2256680",
    "end": "2262349"
  },
  {
    "text": "target tracking this option works really really well what is my target that is",
    "start": "2262349",
    "end": "2270839"
  },
  {
    "text": "probably the most influential decision you will make when setting up auto",
    "start": "2270839",
    "end": "2276329"
  },
  {
    "text": "scaling there's plenty of tools that can generate synthetic load to to load test",
    "start": "2276329",
    "end": "2283200"
  },
  {
    "text": "your service you can see some of these tools on the screen well I know curl is",
    "start": "2283200",
    "end": "2288509"
  },
  {
    "text": "not a load testing tool but I've seen it being used as such and why not if you",
    "start": "2288509",
    "end": "2293880"
  },
  {
    "text": "have to generate five requests per second it works there is also plenty of",
    "start": "2293880",
    "end": "2299400"
  },
  {
    "text": "free and commercial tools that can capture the traffic in your production",
    "start": "2299400",
    "end": "2304619"
  },
  {
    "text": "environment and replace it in your stage and/or test environment all these solutions come with certain",
    "start": "2304619",
    "end": "2310829"
  },
  {
    "text": "disadvantages when you talking about replaying the traffic you have to synchronize your prod and test",
    "start": "2310829",
    "end": "2317430"
  },
  {
    "text": "environments at Netflix scale it simply it becomes a nightmare it quickly grows",
    "start": "2317430",
    "end": "2322559"
  },
  {
    "text": "out of hand so what is our answer to this our answer is squeeze testing",
    "start": "2322559",
    "end": "2329789"
  },
  {
    "text": "squeeze testing is a Netflix term that refers to load testing with live",
    "start": "2329789",
    "end": "2335960"
  },
  {
    "text": "production traffic how do we do this here's how here's an example of mid-tier",
    "start": "2335960",
    "end": "2343529"
  },
  {
    "text": "services the service on the right serves traffic to a bunch of clients on the",
    "start": "2343529",
    "end": "2349049"
  },
  {
    "text": "Left this is a normal flow of traffic what we do is we clone the same the",
    "start": "2349049",
    "end": "2356339"
  },
  {
    "text": "server ASG with the same ami and we create a separate ASG with the same mi",
    "start": "2356339",
    "end": "2361859"
  },
  {
    "text": "with a single instance in it that would be our system under squeeze then we",
    "start": "2361859",
    "end": "2367739"
  },
  {
    "text": "create an instance of proxy that would help us to our traffic to divert the traffic then",
    "start": "2367739",
    "end": "2375420"
  },
  {
    "text": "we divert a portion of the traffic from our clients to proxy than proxy measures",
    "start": "2375420",
    "end": "2381210"
  },
  {
    "text": "a controlled throughput and sons' it to the system under squeeze and the excess",
    "start": "2381210",
    "end": "2386369"
  },
  {
    "text": "of traffic goes back to the server ASG this is live traffic we don't lose",
    "start": "2386369",
    "end": "2392010"
  },
  {
    "text": "any single requests it goes either to system under squeeze or it goes back to",
    "start": "2392010",
    "end": "2397650"
  },
  {
    "text": "the server ASG ultimately by turning this knob the",
    "start": "2397650",
    "end": "2403140"
  },
  {
    "text": "controlled throughput we can see how our service behaves under load the good",
    "start": "2403140",
    "end": "2411030"
  },
  {
    "text": "thing about this approach is that we're not squeezing the entire ASG were only",
    "start": "2411030",
    "end": "2416220"
  },
  {
    "text": "squeezin a single instance so that minimizes the blast radius and that also",
    "start": "2416220",
    "end": "2422460"
  },
  {
    "text": "allows us to see how the service fails",
    "start": "2422460",
    "end": "2428240"
  },
  {
    "text": "we have other mechanisms place such as retries to deal with failures and we",
    "start": "2428240",
    "end": "2434670"
  },
  {
    "text": "feel confident that the information we get out of this experiment is worth it",
    "start": "2434670",
    "end": "2441380"
  },
  {
    "text": "speaking of failures I think it's extremely important to understand the",
    "start": "2441380",
    "end": "2447569"
  },
  {
    "start": "2442000",
    "end": "2442000"
  },
  {
    "text": "failures I know nobody nobody likes to think about it nobody likes to talk",
    "start": "2447569",
    "end": "2453450"
  },
  {
    "text": "about it but as a performance and reliability engineer I have to deal with",
    "start": "2453450",
    "end": "2458490"
  },
  {
    "text": "failures quite often here is an example the service on the Left exhibit normal",
    "start": "2458490",
    "end": "2466980"
  },
  {
    "text": "normal pattern normal behavior the true put doubles up from roughly 90 280",
    "start": "2466980",
    "end": "2472859"
  },
  {
    "text": "requests per second CPU roughly doubles up from 40 to 80% latency almost doubles",
    "start": "2472859",
    "end": "2481079"
  },
  {
    "text": "up less than that from 30 to 50 milliseconds but this service keeps",
    "start": "2481079",
    "end": "2487319"
  },
  {
    "text": "going it keeps service it keeps keep servicing requests the service on the",
    "start": "2487319",
    "end": "2493530"
  },
  {
    "text": "right exhibit a very very different pattern at some point when RPS when our",
    "start": "2493530",
    "end": "2499440"
  },
  {
    "text": "throughput reaches a certain certain threshold this service simply breaks down the cpu",
    "start": "2499440",
    "end": "2506690"
  },
  {
    "text": "goes from 40 to over 80% close to 100% utilization latency jumps from",
    "start": "2506690",
    "end": "2514910"
  },
  {
    "text": "milliseconds to over second and throughput drops this service fails here",
    "start": "2514910",
    "end": "2521210"
  },
  {
    "text": "this illustrates this two patterns the service on the Left keeps going the",
    "start": "2521210",
    "end": "2526400"
  },
  {
    "text": "service on the right fails how is it related to auto scaling here's how if",
    "start": "2526400",
    "end": "2532520"
  },
  {
    "text": "you operate a service on the left the good service then it's a business decision it's a trade don't you have a",
    "start": "2532520",
    "end": "2539450"
  },
  {
    "text": "choice if you have an SLA for latency run the service cooler pay a little bit",
    "start": "2539450",
    "end": "2545150"
  },
  {
    "text": "more for the capacity and meet the SLA if you don't have the SLA and you're",
    "start": "2545150",
    "end": "2550670"
  },
  {
    "text": "perfectly fine with running it at 60 millisecond response time as opposed to",
    "start": "2550670",
    "end": "2555770"
  },
  {
    "text": "30 millisecond then you can run the service a little bit hotter and save on capacity when you operate a service on",
    "start": "2555770",
    "end": "2563750"
  },
  {
    "text": "the right you don't have this luxury you don't have this choice you have to make sure that your scale and target is way",
    "start": "2563750",
    "end": "2572569"
  },
  {
    "text": "below that point at which this service breaks",
    "start": "2572569",
    "end": "2577630"
  },
  {
    "start": "2579000",
    "end": "2579000"
  },
  {
    "text": "speaking of traffic patterns this is a traffic pattern for our typical mid tier",
    "start": "2580180",
    "end": "2587660"
  },
  {
    "text": "service comparing Friday morning versus Saturday morning usually when",
    "start": "2587660",
    "end": "2594829"
  },
  {
    "text": "people talk about Auto scale in the question is will auto scale and give me",
    "start": "2594829",
    "end": "2600230"
  },
  {
    "text": "enough instances to sustain my traffic at peak and usually my answer is yes do",
    "start": "2600230",
    "end": "2608000"
  },
  {
    "text": "not worry about your peak order scale and we'll give you instances up to your",
    "start": "2608000",
    "end": "2613460"
  },
  {
    "text": "max size the peak is not a problem we found out that the morning hours are",
    "start": "2613460",
    "end": "2620630"
  },
  {
    "text": "more dangerous from auto-scaling perspective than the peak hours here is why usually the ASG is at the lowest",
    "start": "2620630",
    "end": "2627619"
  },
  {
    "text": "lowest size we have less instances to deal with that with the incoming traffic",
    "start": "2627619",
    "end": "2633290"
  },
  {
    "text": "and the rapid increase incoming traffic can make it hard for",
    "start": "2633290",
    "end": "2639900"
  },
  {
    "text": "autoscale and to keep up another pattern",
    "start": "2639900",
    "end": "2645900"
  },
  {
    "text": "another anti pattern I should say is mixin interactive and batch traffic in",
    "start": "2645900",
    "end": "2652949"
  },
  {
    "text": "this example you can see that batch service came in and started sending",
    "start": "2652949",
    "end": "2658369"
  },
  {
    "text": "roughly thirty percent of the overall traffic to this particular ASG that's a",
    "start": "2658369",
    "end": "2665880"
  },
  {
    "text": "lot and this traffic ramped up in virtually no time in a couple of minutes and that could put a lot of strain on",
    "start": "2665880",
    "end": "2672929"
  },
  {
    "text": "auto scaling or the scale might not be able to keep up with that so the way I",
    "start": "2672929",
    "end": "2680669"
  },
  {
    "text": "think about it is that rate of change of your metric of your true put of your",
    "start": "2680669",
    "end": "2687660"
  },
  {
    "text": "whatever metric you're monitoring is more important than the peak volume you can think of it as the law City versus",
    "start": "2687660",
    "end": "2695160"
  },
  {
    "text": "acceleration a constant velocity no matter how high it is do you no harm",
    "start": "2695160",
    "end": "2702079"
  },
  {
    "text": "however a high acceleration can do can do some damage alright at this point we",
    "start": "2702079",
    "end": "2712109"
  },
  {
    "start": "2710000",
    "end": "2710000"
  },
  {
    "text": "have our metric we have our target we understand the traffic patterns and now",
    "start": "2712109",
    "end": "2719309"
  },
  {
    "text": "it's time to set up scale and policies these graphs represent a service that",
    "start": "2719309",
    "end": "2727259"
  },
  {
    "text": "scales on throughput the graph on the top shows the capacity the SG size",
    "start": "2727259",
    "end": "2732900"
  },
  {
    "text": "that's the gray area versus the income and traffic that's the pink line you can",
    "start": "2732900",
    "end": "2738269"
  },
  {
    "text": "see that the shapes of SG size and incoming traffic are roughly the same as traffic goes up and down",
    "start": "2738269",
    "end": "2744929"
  },
  {
    "text": "SG scales up and down to accommodate this traffic the bottom graph however is",
    "start": "2744929",
    "end": "2752579"
  },
  {
    "text": "more talent and it shows the essence of how dynamic scaling works",
    "start": "2752579",
    "end": "2759150"
  },
  {
    "text": "it shows per instance throughput this is the metric with scale on average",
    "start": "2759150",
    "end": "2765299"
  },
  {
    "text": "throughput per instance and you can see that we bind the triplet we create this",
    "start": "2765299",
    "end": "2772709"
  },
  {
    "text": "the band between scale up and scale down threshold when the metric goes above",
    "start": "2772709",
    "end": "2779619"
  },
  {
    "text": "scale up trash hold s G adds capacity and you can see as our traffic ramps up",
    "start": "2779619",
    "end": "2785890"
  },
  {
    "text": "the metric keeps bumping up against the scale up threshold against the ceiling",
    "start": "2785890",
    "end": "2791349"
  },
  {
    "text": "and SG keeps adding capacity on the way down when the traffic dwindles it keeps",
    "start": "2791349",
    "end": "2798880"
  },
  {
    "text": "bumping against the floor against our scale down threshold and as G keeps",
    "start": "2798880",
    "end": "2804549"
  },
  {
    "text": "removing capacity also some people prefer to think about this band as a",
    "start": "2804549",
    "end": "2811359"
  },
  {
    "text": "dead zone that is because for as long as the metric is within that band as G",
    "start": "2811359",
    "end": "2817599"
  },
  {
    "text": "takes no action if you're below your scale up threshold and above your scale",
    "start": "2817599",
    "end": "2823150"
  },
  {
    "text": "down threshold it's a no action well sounds simple let's see what could go wrong",
    "start": "2823150",
    "end": "2829539"
  },
  {
    "text": "with that this is an example of Norrish scaling I",
    "start": "2829539",
    "end": "2834729"
  },
  {
    "text": "have a couple of this examples and each of them come with a little story in this particular case you can see that a is G",
    "start": "2834729",
    "end": "2842769"
  },
  {
    "text": "scales too slowly it doesn't it doesn't follow there the income in traffic it's",
    "start": "2842769",
    "end": "2849009"
  },
  {
    "text": "much slower than that you can see that that average throughput per instance",
    "start": "2849009",
    "end": "2854589"
  },
  {
    "text": "goes way below scale down threshold which means we're wasting capacity and it goes above the scale up threshold",
    "start": "2854589",
    "end": "2861519"
  },
  {
    "text": "sometimes which means that these instances runs dangerously hot so the",
    "start": "2861519",
    "end": "2867249"
  },
  {
    "text": "story is instead of setting the scale and amount in terms of percentage of ASG",
    "start": "2867249",
    "end": "2874349"
  },
  {
    "text": "the team used the number of instances so this ASG has a side roughly between",
    "start": "2874349",
    "end": "2880719"
  },
  {
    "text": "three and four hundred instances so five percent versus five instances makes",
    "start": "2880719",
    "end": "2885789"
  },
  {
    "text": "difference in this case the remedy was to increase scale and amounts or migrate",
    "start": "2885789",
    "end": "2891519"
  },
  {
    "text": "to target tracking target tracking doesn't have this problem another example twitches scaling quite",
    "start": "2891519",
    "end": "2900039"
  },
  {
    "start": "2897000",
    "end": "2897000"
  },
  {
    "text": "the opposite in this particular case the service owners wasn't sure what is a good skill and amount so they decided to",
    "start": "2900039",
    "end": "2907450"
  },
  {
    "text": "scale up by hundred percent every time essentially one when the average",
    "start": "2907450",
    "end": "2912730"
  },
  {
    "text": "throughput reaches the scale-up threshold SG doubles up that's why you",
    "start": "2912730",
    "end": "2918040"
  },
  {
    "text": "see the spikes but what happens is as soon as it doubles up the average",
    "start": "2918040",
    "end": "2923650"
  },
  {
    "text": "throughput drops below the scaled down threshold and SG immediately start",
    "start": "2923650",
    "end": "2929050"
  },
  {
    "text": "scaling down this leads to unnecessary capacity churn and again in this case",
    "start": "2929050",
    "end": "2936280"
  },
  {
    "text": "target tracking would have prevented it from happening target tracking manages everything automatically last example",
    "start": "2936280",
    "end": "2945940"
  },
  {
    "text": "actually my favorite example should I stay or should I go here's the story",
    "start": "2945940",
    "end": "2951220"
  },
  {
    "text": "behind this example one of the teams discovered a performance regressions",
    "start": "2951220",
    "end": "2956310"
  },
  {
    "text": "performance regression on their service they discovered this on Friday afternoon",
    "start": "2956310",
    "end": "2961600"
  },
  {
    "text": "so basically they have a choice either to push a fix going into the weekend or",
    "start": "2961600",
    "end": "2966790"
  },
  {
    "text": "scale-up and survive the weekend and deal with it on Monday generally we do",
    "start": "2966790",
    "end": "2973060"
  },
  {
    "text": "not endorse deploying code changes on Friday going into the weekend that's it just safe reliability practice so the",
    "start": "2973060",
    "end": "2981010"
  },
  {
    "text": "team followed this practice they chose not to deploy the fix they chose to scale their service up how do you do",
    "start": "2981010",
    "end": "2988300"
  },
  {
    "text": "this well you can scale your service up by reducing your scale-up threshold",
    "start": "2988300",
    "end": "2993510"
  },
  {
    "text": "reducing your scale up trash hold make sure that SG start scaling up sooner and",
    "start": "2993510",
    "end": "2999130"
  },
  {
    "text": "that's what they did but if you think about it when they reduce there is scale up threshold they",
    "start": "2999130",
    "end": "3007950"
  },
  {
    "text": "they got rid of the band they used to have the band then they reduce their scale up threshold now scale up and",
    "start": "3007950",
    "end": "3015450"
  },
  {
    "text": "scale down are at the same value there is no more band there is no more dead zone the auto scaling cannot stabilize",
    "start": "3015450",
    "end": "3023850"
  },
  {
    "text": "and that is why you see that average throughput keeps oscillating and in the",
    "start": "3023850",
    "end": "3030570"
  },
  {
    "text": "top graph you see that SG size keeps oscillating as well that",
    "start": "3030570",
    "end": "3035980"
  },
  {
    "text": "what happens when you remove this band well again you guessed it target tracking has none",
    "start": "3035980",
    "end": "3043420"
  },
  {
    "text": "of these problems if the service use target tracking they wouldn't have this problem but if you use a step scale and",
    "start": "3043420",
    "end": "3050800"
  },
  {
    "text": "make sure that you have this band and it's wide enough to avoid oscillations",
    "start": "3050800",
    "end": "3057060"
  },
  {
    "text": "target tracking has a Newton it's a thermostat and this is a perfect analogy",
    "start": "3057420",
    "end": "3063930"
  },
  {
    "text": "you can set the thermostat and let it do the rest but if you're using step",
    "start": "3063930",
    "end": "3070600"
  },
  {
    "text": "policies you can also think of it as a step policy with automatic unlimited",
    "start": "3070600",
    "end": "3077109"
  },
  {
    "text": "steps target tracking has all the benefits of step scaling without the",
    "start": "3077109",
    "end": "3083170"
  },
  {
    "text": "complexity of setting up each individual step in addition to that target tracking",
    "start": "3083170",
    "end": "3090700"
  },
  {
    "text": "gives you sensitivity to the rate of change when the traffic is changing",
    "start": "3090700",
    "end": "3096760"
  },
  {
    "text": "slowly target tracking gives you less capacity and saves cost when the traffic",
    "start": "3096760",
    "end": "3103000"
  },
  {
    "text": "is changing rapidly target tracking gives you more capacity and saves you",
    "start": "3103000",
    "end": "3108190"
  },
  {
    "text": "from trouble easy setup in my personal opinion easy setup alone is worth is",
    "start": "3108190",
    "end": "3117400"
  },
  {
    "text": "worth for my gradient to target tracking for considering target tracking you've",
    "start": "3117400",
    "end": "3122470"
  },
  {
    "text": "seen the examples you've seen how auto scaling could be misconfigured target tracking takes care of it but in",
    "start": "3122470",
    "end": "3128920"
  },
  {
    "text": "addition to that target tracking also has a better adaptability to incoming",
    "start": "3128920",
    "end": "3134140"
  },
  {
    "text": "traffic and it learns over time and all these features help to reduce cost and",
    "start": "3134140",
    "end": "3140250"
  },
  {
    "text": "increase availability it's not a zero-sum game innovations like target",
    "start": "3140250",
    "end": "3146230"
  },
  {
    "text": "tracking can address both and lastly whether you have 25 or 250,000 instances",
    "start": "3146230",
    "end": "3157170"
  },
  {
    "text": "auto scaling has features for everyone Netflix uses or the scale and",
    "start": "3157170",
    "end": "3163480"
  },
  {
    "text": "extensively it helps us to focus on our business needs and think less about in",
    "start": "3163480",
    "end": "3169240"
  },
  {
    "text": "first structure thank you thank you so much",
    "start": "3169240",
    "end": "3178690"
  },
  {
    "text": "for team for sharing all your experience at Netflix and with that I'd like to say",
    "start": "3178690",
    "end": "3183970"
  },
  {
    "text": "that if you haven't been using water scaling I would definitely encourage you to create an ESD and start getting the",
    "start": "3183970",
    "end": "3189970"
  },
  {
    "text": "benefit of automatic provisioning if you've already been doing that definitely start using dynamic scaling",
    "start": "3189970",
    "end": "3196540"
  },
  {
    "text": "using target tracking and if you've already been doing that as well then definitely take a look at the new",
    "start": "3196540",
    "end": "3202030"
  },
  {
    "text": "features that we've launched get the benefits of sport instances save up to 90% and use predictive scaling thank you",
    "start": "3202030",
    "end": "3210280"
  },
  {
    "text": "so much for your time the and we will be around if you have any questions would love to talk to you and if you don't",
    "start": "3210280",
    "end": "3217300"
  },
  {
    "text": "mind just take a couple of minutes to enter the session survey you know that",
    "start": "3217300",
    "end": "3223060"
  },
  {
    "text": "we do these sessions for you for our customers so those feedback is really helpful for us to improve on thank you",
    "start": "3223060",
    "end": "3230240"
  },
  {
    "text": "[Applause]",
    "start": "3230240",
    "end": "3233060"
  }
]
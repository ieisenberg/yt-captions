[
  {
    "text": "my name's James Bezeq I'm a senior",
    "start": "210",
    "end": "2340"
  },
  {
    "text": "developer advocate here at AWS service",
    "start": "2340",
    "end": "4709"
  },
  {
    "text": "this series is about the s3 2 lambda",
    "start": "4709",
    "end": "7289"
  },
  {
    "text": "serverless design pattern and how can",
    "start": "7289",
    "end": "9660"
  },
  {
    "text": "become a flexible core for your service",
    "start": "9660",
    "end": "11670"
  },
  {
    "text": "applications in this video I'll show you",
    "start": "11670",
    "end": "14370"
  },
  {
    "text": "how you can load large amounts of data",
    "start": "14370",
    "end": "15960"
  },
  {
    "text": "into your dynamo DB tables by staging it",
    "start": "15960",
    "end": "19020"
  },
  {
    "text": "in s3 first and then uploading with",
    "start": "19020",
    "end": "21240"
  },
  {
    "text": "lambda Amazon DynamoDB is a fast web",
    "start": "21240",
    "end": "25260"
  },
  {
    "text": "scale no sequel database that is central",
    "start": "25260",
    "end": "27779"
  },
  {
    "text": "to many service applications with its on",
    "start": "27779",
    "end": "30480"
  },
  {
    "text": "demand capacity feature it can ingest",
    "start": "30480",
    "end": "32758"
  },
  {
    "text": "enormous amounts of data without you",
    "start": "32759",
    "end": "34380"
  },
  {
    "text": "needing to manage shards or scale up a",
    "start": "34380",
    "end": "36540"
  },
  {
    "text": "fleet of servers by connecting s3 to the",
    "start": "36540",
    "end": "39360"
  },
  {
    "text": "lambda to dynamodb we're using three",
    "start": "39360",
    "end": "41730"
  },
  {
    "text": "highly scalable services let's see how",
    "start": "41730",
    "end": "44610"
  },
  {
    "text": "we can use this in combination to load",
    "start": "44610",
    "end": "46170"
  },
  {
    "text": "data in parallel so the first thing",
    "start": "46170",
    "end": "48719"
  },
  {
    "text": "we're going to do is get clone the repo",
    "start": "48719",
    "end": "51260"
  },
  {
    "text": "the s3 the Lambert repo and we can see",
    "start": "51260",
    "end": "54989"
  },
  {
    "text": "there there's the third example DynamoDB",
    "start": "54989",
    "end": "57000"
  },
  {
    "text": "I'll just CD into that directory and",
    "start": "57000",
    "end": "61320"
  },
  {
    "text": "then there there's a Sam template",
    "start": "61320",
    "end": "63390"
  },
  {
    "text": "template yeah more I'm going to deploy",
    "start": "63390",
    "end": "67549"
  },
  {
    "text": "there's some template using Sam deploy",
    "start": "67549",
    "end": "70049"
  },
  {
    "text": "using the new guided deploy method for a",
    "start": "70049",
    "end": "74280"
  },
  {
    "text": "stack name I'm going to use jay-bez Road",
    "start": "74280",
    "end": "76770"
  },
  {
    "text": "DynamoDB we're working in u.s. West to",
    "start": "76770",
    "end": "80810"
  },
  {
    "text": "the input bucket name will be J besra",
    "start": "80810",
    "end": "84140"
  },
  {
    "text": "dynamodb and then I'll just accept the",
    "start": "84140",
    "end": "87900"
  },
  {
    "text": "defaults in the deployment and that's",
    "start": "87900",
    "end": "90119"
  },
  {
    "text": "now being deployed so let's look at the",
    "start": "90119",
    "end": "92939"
  },
  {
    "text": "template first there's an input bucket",
    "start": "92939",
    "end": "97229"
  },
  {
    "text": "name at the top with a default and then",
    "start": "97229",
    "end": "99570"
  },
  {
    "text": "in the resources section there is the s3",
    "start": "99570",
    "end": "101520"
  },
  {
    "text": "bucket using that parameter there's a",
    "start": "101520",
    "end": "104340"
  },
  {
    "text": "dynamo DB table configured using the",
    "start": "104340",
    "end": "106890"
  },
  {
    "text": "on-demand billing and then finally we",
    "start": "106890",
    "end": "110579"
  },
  {
    "text": "have the import function itself with the",
    "start": "110579",
    "end": "113009"
  },
  {
    "text": "code in the import function folder it's",
    "start": "113009",
    "end": "114810"
  },
  {
    "text": "a node.js application using 512 Meg's of",
    "start": "114810",
    "end": "118229"
  },
  {
    "text": "RAM and those are the IM policies that",
    "start": "118229",
    "end": "121259"
  },
  {
    "text": "give access to the table of the bucket",
    "start": "121259",
    "end": "122850"
  },
  {
    "text": "and it will respond to JSON files when",
    "start": "122850",
    "end": "125579"
  },
  {
    "text": "they arrive in this bucket",
    "start": "125579",
    "end": "128630"
  },
  {
    "text": "so let's take a look at the code behind",
    "start": "130250",
    "end": "133710"
  },
  {
    "text": "this in the import function directory",
    "start": "133710",
    "end": "136200"
  },
  {
    "text": "there's an is file now this is a",
    "start": "136200",
    "end": "140160"
  },
  {
    "text": "standard lambda handler passing in an",
    "start": "140160",
    "end": "142350"
  },
  {
    "text": "event that could contain multiple files",
    "start": "142350",
    "end": "145610"
  },
  {
    "text": "so what this does is it iterates through",
    "start": "145610",
    "end": "147780"
  },
  {
    "text": "the list of all of those and it gets the",
    "start": "147780",
    "end": "151800"
  },
  {
    "text": "text from each object in the incoming",
    "start": "151800",
    "end": "153750"
  },
  {
    "text": "event and it's going to parse that JSON",
    "start": "153750",
    "end": "158840"
  },
  {
    "text": "and then upload it into DynamoDB using",
    "start": "158840",
    "end": "162990"
  },
  {
    "text": "this function now that function down",
    "start": "162990",
    "end": "164940"
  },
  {
    "text": "there",
    "start": "164940",
    "end": "165510"
  },
  {
    "text": "it actually batches the contents that",
    "start": "165510",
    "end": "167340"
  },
  {
    "text": "file into 25 at the time and then it",
    "start": "167340",
    "end": "171750"
  },
  {
    "text": "stores those into DynamoDB so this is",
    "start": "171750",
    "end": "175260"
  },
  {
    "text": "just a mechanism for batching out the",
    "start": "175260",
    "end": "176880"
  },
  {
    "text": "contents of the json checking make sure",
    "start": "176880",
    "end": "179400"
  },
  {
    "text": "that all the attributes are there and",
    "start": "179400",
    "end": "182730"
  },
  {
    "text": "then we use a random ID in this case we",
    "start": "182730",
    "end": "185190"
  },
  {
    "text": "don't need to necessarily do that and",
    "start": "185190",
    "end": "186810"
  },
  {
    "text": "then it calls bat write of the doc write",
    "start": "186810",
    "end": "189900"
  },
  {
    "text": "client okay so the deployment has now",
    "start": "189900",
    "end": "193020"
  },
  {
    "text": "finished so let's take a look at how",
    "start": "193020",
    "end": "194430"
  },
  {
    "text": "this works",
    "start": "194430",
    "end": "196849"
  },
  {
    "text": "so in DynamoDB we can see we now have a",
    "start": "203640",
    "end": "206670"
  },
  {
    "text": "new table as part of our deployment and",
    "start": "206670",
    "end": "209160"
  },
  {
    "text": "currently there's nothing in there",
    "start": "209160",
    "end": "212090"
  },
  {
    "text": "back in s3 I'll just refresh so we can",
    "start": "212090",
    "end": "215700"
  },
  {
    "text": "see our new bucket and this is currently",
    "start": "215700",
    "end": "219420"
  },
  {
    "text": "an empty bucket I'm going to upload a",
    "start": "219420",
    "end": "222210"
  },
  {
    "text": "JSON file I'll start with a smaller one",
    "start": "222210",
    "end": "225270"
  },
  {
    "text": "it's just a list of locations of a",
    "start": "225270",
    "end": "227520"
  },
  {
    "text": "popular coffee chain I'm gonna upload",
    "start": "227520",
    "end": "230490"
  },
  {
    "text": "this file now that's now been uploaded",
    "start": "230490",
    "end": "234770"
  },
  {
    "text": "if I go back to dynamo DB and refresh",
    "start": "234770",
    "end": "237510"
  },
  {
    "text": "you can see there's 36 items now in the",
    "start": "237510",
    "end": "239700"
  },
  {
    "text": "table that's the small list of locations",
    "start": "239700",
    "end": "245120"
  },
  {
    "text": "and those are all the different items",
    "start": "246230",
    "end": "248550"
  },
  {
    "text": "that have been stored and extracted from",
    "start": "248550",
    "end": "250290"
  },
  {
    "text": "the file",
    "start": "250290",
    "end": "252739"
  },
  {
    "text": "now the next thing I can do is I've got",
    "start": "258470",
    "end": "260299"
  },
  {
    "text": "the larger list of earth locations it",
    "start": "260299",
    "end": "262430"
  },
  {
    "text": "has a list of every single Starbucks in",
    "start": "262430",
    "end": "264050"
  },
  {
    "text": "the whole of the US which I found on",
    "start": "264050",
    "end": "266090"
  },
  {
    "text": "github so I'm going to use this larger",
    "start": "266090",
    "end": "269630"
  },
  {
    "text": "list of examples you'd show you how fast",
    "start": "269630",
    "end": "271820"
  },
  {
    "text": "this can run so let's take a look at",
    "start": "271820",
    "end": "274640"
  },
  {
    "text": "this locations JSON file the larger",
    "start": "274640",
    "end": "277040"
  },
  {
    "text": "version as you can see this file",
    "start": "277040",
    "end": "280190"
  },
  {
    "text": "contains well nearly 60,000 different",
    "start": "280190",
    "end": "284300"
  },
  {
    "text": "lines in the JSON files well let's",
    "start": "284300",
    "end": "286040"
  },
  {
    "text": "upload that I'll go back to the s3",
    "start": "286040",
    "end": "289460"
  },
  {
    "text": "bucket and upload I'll just pull that in",
    "start": "289460",
    "end": "293960"
  },
  {
    "text": "and upload this file okay so that's now",
    "start": "293960",
    "end": "303290"
  },
  {
    "text": "that's now uploaded successfully",
    "start": "303290",
    "end": "304910"
  },
  {
    "text": "so back in the dynamodb table if i",
    "start": "304910",
    "end": "307580"
  },
  {
    "text": "refresh what you can see is now we have",
    "start": "307580",
    "end": "310580"
  },
  {
    "text": "hundreds and hundreds of items that have",
    "start": "310580",
    "end": "312350"
  },
  {
    "text": "appeared in fact this file has something",
    "start": "312350",
    "end": "314840"
  },
  {
    "text": "along the lines of 8,000 different",
    "start": "314840",
    "end": "316880"
  },
  {
    "text": "locations these have all been loaded to",
    "start": "316880",
    "end": "319700"
  },
  {
    "text": "our table and there's some more of them",
    "start": "319700",
    "end": "324910"
  },
  {
    "text": "so now I can upload multiple of these at",
    "start": "324910",
    "end": "327500"
  },
  {
    "text": "once you don't need to do this one at a",
    "start": "327500",
    "end": "328880"
  },
  {
    "text": "time so I'll just add files now put both",
    "start": "328880",
    "end": "331310"
  },
  {
    "text": "of these along with some other JSON",
    "start": "331310",
    "end": "333410"
  },
  {
    "text": "files I have back into this bucket those",
    "start": "333410",
    "end": "338120"
  },
  {
    "text": "are all uploaded and again you can see",
    "start": "338120",
    "end": "339710"
  },
  {
    "text": "that the table is just ingested these",
    "start": "339710",
    "end": "341840"
  },
  {
    "text": "lists of items very easily so you could",
    "start": "341840",
    "end": "344930"
  },
  {
    "text": "potentially upload dozens or hundreds of",
    "start": "344930",
    "end": "346820"
  },
  {
    "text": "different files this way just by",
    "start": "346820",
    "end": "348260"
  },
  {
    "text": "dropping them into your bucket let's",
    "start": "348260",
    "end": "353240"
  },
  {
    "text": "take a quick look at the lambda function",
    "start": "353240",
    "end": "354860"
  },
  {
    "text": "that is doing the work this is the",
    "start": "354860",
    "end": "358970"
  },
  {
    "text": "importer function that was deployed as",
    "start": "358970",
    "end": "360590"
  },
  {
    "text": "part of our Sam deployment let's take a",
    "start": "360590",
    "end": "363770"
  },
  {
    "text": "look at the monitoring tab and then see",
    "start": "363770",
    "end": "366680"
  },
  {
    "text": "the logs in cloud watch",
    "start": "366680",
    "end": "370150"
  },
  {
    "text": "I'll just pick one of these log streams",
    "start": "371770",
    "end": "373569"
  },
  {
    "text": "there's one for every file that we",
    "start": "373569",
    "end": "375009"
  },
  {
    "text": "uploaded I'll open up the top one and",
    "start": "375009",
    "end": "381690"
  },
  {
    "text": "there you can see it is pulling in all",
    "start": "381690",
    "end": "384970"
  },
  {
    "text": "of the contents and then batching out",
    "start": "384970",
    "end": "386590"
  },
  {
    "text": "the results using that batch write",
    "start": "386590",
    "end": "388590"
  },
  {
    "text": "operation to DynamoDB here the s3 2",
    "start": "388590",
    "end": "395620"
  },
  {
    "text": "lambda patent can be used to load data",
    "start": "395620",
    "end": "397449"
  },
  {
    "text": "into a dynamodb table directly from",
    "start": "397449",
    "end": "399940"
  },
  {
    "text": "objects stored in an s3 bucket whether",
    "start": "399940",
    "end": "403150"
  },
  {
    "text": "you have a handful of very large files",
    "start": "403150",
    "end": "405009"
  },
  {
    "text": "or thousands of smaller ones",
    "start": "405009",
    "end": "406840"
  },
  {
    "text": "this approach loads the data quickly and",
    "start": "406840",
    "end": "409060"
  },
  {
    "text": "reliably with DynamoDB on-demand",
    "start": "409060",
    "end": "411580"
  },
  {
    "text": "provisioning you no longer have to",
    "start": "411580",
    "end": "413409"
  },
  {
    "text": "manage write units with your table since",
    "start": "413409",
    "end": "415479"
  },
  {
    "text": "this is handled by the service all of",
    "start": "415479",
    "end": "418090"
  },
  {
    "text": "this happens without needing to manage",
    "start": "418090",
    "end": "419680"
  },
  {
    "text": "any servers and when the traffic slows",
    "start": "419680",
    "end": "421659"
  },
  {
    "text": "down the services scale down",
    "start": "421659",
    "end": "423460"
  },
  {
    "text": "automatically so this is a perfect",
    "start": "423460",
    "end": "425470"
  },
  {
    "text": "solution for use cases with spiky",
    "start": "425470",
    "end": "427360"
  },
  {
    "text": "traffic the lambda function contains",
    "start": "427360",
    "end": "429970"
  },
  {
    "text": "only the minimal business logic to",
    "start": "429970",
    "end": "431680"
  },
  {
    "text": "connect the services just over 100 lines",
    "start": "431680",
    "end": "434110"
  },
  {
    "text": "of code in this case this function",
    "start": "434110",
    "end": "436210"
  },
  {
    "text": "extracts the data from JSON files but",
    "start": "436210",
    "end": "438729"
  },
  {
    "text": "you could easily modify the code to work",
    "start": "438729",
    "end": "440349"
  },
  {
    "text": "with CSV or any perform at you prefer",
    "start": "440349",
    "end": "443159"
  },
  {
    "text": "using the server this application model",
    "start": "443159",
    "end": "445659"
  },
  {
    "text": "setting up a deployment package where",
    "start": "445659",
    "end": "447520"
  },
  {
    "text": "the AWS resources in our code is also",
    "start": "447520",
    "end": "449380"
  },
  {
    "text": "very easy to download the examples from",
    "start": "449380",
    "end": "452259"
  },
  {
    "text": "this video and deploy the application in",
    "start": "452259",
    "end": "454150"
  },
  {
    "text": "your own account visit this URL thanks",
    "start": "454150",
    "end": "457690"
  },
  {
    "text": "for joining me for this walkthrough",
    "start": "457690",
    "end": "458740"
  },
  {
    "text": "don't miss the other videos in this",
    "start": "458740",
    "end": "460690"
  },
  {
    "text": "series that show other ways to use s3 2",
    "start": "460690",
    "end": "463090"
  },
  {
    "text": "lambda for your service applications",
    "start": "463090",
    "end": "465009"
  },
  {
    "text": "happy coding",
    "start": "465009",
    "end": "468120"
  }
]
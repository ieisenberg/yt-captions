[
  {
    "start": "0",
    "end": "130000"
  },
  {
    "text": "hi everyone my name is Ryan neat hi so I'm a product manager for the Amazon cases team today we're gonna be talking",
    "start": "829",
    "end": "6960"
  },
  {
    "text": "about real-time anomaly detection using Amazon Kinesis I'll be giving the first",
    "start": "6960",
    "end": "12000"
  },
  {
    "text": "about 20-ish minutes 25 minutes to presentation we're gonna go over the context of the solution and how to",
    "start": "12000",
    "end": "18150"
  },
  {
    "text": "easily get started and then some high-level about the algorithm and then depending on whether or not my partner",
    "start": "18150",
    "end": "23910"
  },
  {
    "text": "Alan mechanics shows up which I think he will he'll present the last ten minutes are all cover the last ten minutes which",
    "start": "23910",
    "end": "29820"
  },
  {
    "text": "goes into a little bit detail about the anomaly detection algorithm that's included in Kinesis analytics so with",
    "start": "29820",
    "end": "35399"
  },
  {
    "text": "that let's get started so who here has",
    "start": "35399",
    "end": "40829"
  },
  {
    "text": "used Amazon Kinesis before great who has used any streaming data product before",
    "start": "40829",
    "end": "46200"
  },
  {
    "text": "Kafka Kinesis part streaming great for",
    "start": "46200",
    "end": "52079"
  },
  {
    "text": "those that haven't one of the fundamental things that differentiates streaming data with batch data",
    "start": "52079",
    "end": "57570"
  },
  {
    "text": "processing is continuous the continuous nature of it and in fact most data is in fact produced continuously Soviet from a",
    "start": "57570",
    "end": "65460"
  },
  {
    "text": "mobile app your users are always going to be on using your mobile app at all hours of the day so we IOT sensors that are constantly",
    "start": "65460",
    "end": "72840"
  },
  {
    "text": "reading measurements like temperature readings humidity readings that type of thing metering records so if you have a",
    "start": "72840",
    "end": "80610"
  },
  {
    "text": "billing pipeline and you're receiving those meeting records are gonna be receiving them continuously the primary",
    "start": "80610",
    "end": "90060"
  },
  {
    "text": "difference with streaming data and batch data is that we capture it and process it continuously and for the anomaly",
    "start": "90060",
    "end": "96540"
  },
  {
    "text": "detection algorithm we'll be talking today this is a real-time streaming anomaly detection algorithm so this",
    "start": "96540",
    "end": "102720"
  },
  {
    "text": "algorithm trains itself online it adjusts the model online as it processes data versus",
    "start": "102720",
    "end": "109680"
  },
  {
    "text": "doing something in batch maybe training the model you know once a day once a week or more frequently that and then",
    "start": "109680",
    "end": "116250"
  },
  {
    "text": "loading the model into the streaming context so the model is run and algorithms run continuously on data as",
    "start": "116250",
    "end": "123360"
  },
  {
    "text": "its produced versus doing periodic jobs that run on various degrees of frequency",
    "start": "123360",
    "end": "128910"
  },
  {
    "text": "so for those who aren't familiar with streaming data one of the primary value propositions of using a",
    "start": "128910",
    "end": "136290"
  },
  {
    "start": "130000",
    "end": "130000"
  },
  {
    "text": "service like Amazon Kinesis or any other streaming data service for that matter is that it allows you to extract more",
    "start": "136290",
    "end": "142170"
  },
  {
    "text": "value from your data more quickly the easiest analogy how you have for this is",
    "start": "142170",
    "end": "148700"
  },
  {
    "text": "the fraud detection use case so you are traveling somewhere you use your credit",
    "start": "148700",
    "end": "154050"
  },
  {
    "text": "card you get an instant message or phone call from your bank and the bank tells you hey was this a valid charge that is",
    "start": "154050",
    "end": "161160"
  },
  {
    "text": "really useful information it is far less useful if you receive that a week after your trip or a week",
    "start": "161160",
    "end": "167460"
  },
  {
    "text": "after someone was stolen your credit card and presented a fraudulent charge on it and for the bank to verify it then",
    "start": "167460",
    "end": "173790"
  },
  {
    "text": "because the damage has already been done so you want to get it right away that that example really really demonstrates",
    "start": "173790",
    "end": "180900"
  },
  {
    "text": "how extracting information running machine learning on your data in real",
    "start": "180900",
    "end": "186480"
  },
  {
    "text": "time or running machine learning algorithms in real time versus in batch really allows you to unlock a lot more",
    "start": "186480",
    "end": "191910"
  },
  {
    "text": "value so there are certain set of",
    "start": "191910",
    "end": "198570"
  },
  {
    "start": "196000",
    "end": "196000"
  },
  {
    "text": "requirements that you need to meet for doing processing real-time data the portions of them are familiar they're",
    "start": "198570",
    "end": "204930"
  },
  {
    "text": "the same as the batch context predict durability scalability but some of them",
    "start": "204930",
    "end": "211890"
  },
  {
    "text": "are different one of the primary ones is different is the ability to ingest data at scale so with batch data processing",
    "start": "211890",
    "end": "219870"
  },
  {
    "text": "you'll be maybe you have an application server that wakes up every hour takes a",
    "start": "219870",
    "end": "225120"
  },
  {
    "text": "bunch of logs that were saved to disk and then you upload to sent centralized data Lake once an hour maybe once every",
    "start": "225120",
    "end": "231390"
  },
  {
    "text": "couple hours that's a lot different ingestion paths than for streaming data where you're ingesting they did it",
    "start": "231390",
    "end": "237540"
  },
  {
    "text": "continuously and typically much smaller pieces of data because you're trying to react to the data in real-time so",
    "start": "237540",
    "end": "244050"
  },
  {
    "text": "instead of getting a hug megabyte file or a gigabyte file uploaded to Amazon s3 on a periodic basis you're ingesting a",
    "start": "244050",
    "end": "250680"
  },
  {
    "text": "high volume stream of events so one of them might be sub Kb maybe one or two Kb that you're",
    "start": "250680",
    "end": "256980"
  },
  {
    "text": "ingesting tens of thousands of them or thousands of them or millions of them all in real time so the ingest part is",
    "start": "256980",
    "end": "264750"
  },
  {
    "text": "one of the DIF primary difference between real streaming data and batch data processing the continuous nature I mentioned the",
    "start": "264750",
    "end": "271470"
  },
  {
    "text": "other thing is fast the speed in which you process so any type of processing",
    "start": "271470",
    "end": "277200"
  },
  {
    "text": "regardless of whether you're running accounts or running in it and ml m ml algorithm in real time has to be able to",
    "start": "277200",
    "end": "283080"
  },
  {
    "text": "keep with the up with the incoming data stream so falling behind means you lose",
    "start": "283080",
    "end": "288450"
  },
  {
    "text": "that value of doing the real-time data processing so when we talk about falling behind this is I want to make sure that",
    "start": "288450",
    "end": "294720"
  },
  {
    "text": "I'm crossing processing all the events as close to as they occurred as possible so I'm ingesting them in real time I'm",
    "start": "294720",
    "end": "301650"
  },
  {
    "text": "processing them in real time typically with seconds or sub second latency so how do I do that at scale so",
    "start": "301650",
    "end": "308090"
  },
  {
    "text": "upset of Amazon KCC services makes it easy for you we pair what make parallelization easy so you can spin out",
    "start": "308090",
    "end": "314520"
  },
  {
    "text": "a number of threads to do so we'll go into a little bit more detail of how the services make that easy to do so Amazon",
    "start": "314520",
    "end": "324389"
  },
  {
    "text": "Canisius consists of three services the first one we launched four years ago",
    "start": "324389",
    "end": "329750"
  },
  {
    "text": "includes Amazon Kinesis data streams this is core infrastructure for AWS so",
    "start": "329750",
    "end": "335490"
  },
  {
    "text": "it's in all AWS regions it's used by a number of internal services like cloud watch ec2 as part of the backbone",
    "start": "335490",
    "end": "341190"
  },
  {
    "text": "infrastructure of how they run and operate their services it allows you to create a data stream that provides a",
    "start": "341190",
    "end": "347430"
  },
  {
    "text": "temporary buffer for both writing to and reading from data in real time so you'll",
    "start": "347430",
    "end": "352830"
  },
  {
    "text": "set up a Kinesis stream you'll put or write data to that stream and then you'll set up a data consumer to get or",
    "start": "352830",
    "end": "359280"
  },
  {
    "text": "read data off of that stream in a highly scalable fast manner in real times and",
    "start": "359280",
    "end": "365729"
  },
  {
    "text": "when we talk about real time we're talking typically around a second or less here the primary value problem",
    "start": "365729",
    "end": "371400"
  },
  {
    "text": "Kinesis data streams is it allows you to choose the data processing solution of your choice so when you get data to the",
    "start": "371400",
    "end": "378600"
  },
  {
    "text": "stream you can use one of our open source libraries that we provide you can use SPARC streaming SPARC and Lib on the",
    "start": "378600",
    "end": "384330"
  },
  {
    "text": "data stream AWS lambda can you sustain analytics and for the purposes of this",
    "start": "384330",
    "end": "389610"
  },
  {
    "text": "talk all of them have some variation of machine learning algorithms in real time anomaly detection will focus primarily",
    "start": "389610",
    "end": "395280"
  },
  {
    "text": "on what how can you sustain analytics does real-time anomaly detection but the point with data streams is",
    "start": "395280",
    "end": "400920"
  },
  {
    "text": "you've got a flexible buffer to read and write data from and it provides you the flexibility to use the solution of your",
    "start": "400920",
    "end": "406830"
  },
  {
    "text": "choice Kinesis data analytics is one of those choices that you can use to read",
    "start": "406830",
    "end": "413670"
  },
  {
    "text": "data off of the stream so you're ingesting a high volume of IOT data or application log data in story stream you",
    "start": "413670",
    "end": "420600"
  },
  {
    "text": "can attach a casus data analytics application to process that data using sequel code as well as some extensions",
    "start": "420600",
    "end": "427080"
  },
  {
    "text": "that we have that I'll highlight today like anomaly detection some other ML algorithms the way you set up an",
    "start": "427080",
    "end": "434220"
  },
  {
    "text": "application is you create a source in this case it would be a data stream your sequel code and then we're on to do with",
    "start": "434220",
    "end": "440400"
  },
  {
    "text": "those process results maybe you want to send a notification maybe you want to store it in a database but the whole",
    "start": "440400",
    "end": "445860"
  },
  {
    "text": "point is that the application is operating continuously on the data stream so as the data comes in it keeps",
    "start": "445860",
    "end": "451440"
  },
  {
    "text": "up in that fast manner that scalable mantle with manner with the ingest of the Kinesis data streams the next",
    "start": "451440",
    "end": "459390"
  },
  {
    "text": "service that we have as part of the set of services to make up Amazon Kinesis is Amazon Kinesis data firehose this",
    "start": "459390",
    "end": "465030"
  },
  {
    "text": "service takes one of the most common use cases for swimming data it makes it very",
    "start": "465030",
    "end": "470820"
  },
  {
    "text": "very simple I won't be talking about it much in this presentation but the whole purpose of it is to basically get data a",
    "start": "470820",
    "end": "477000"
  },
  {
    "text": "high volume stream of events from point A to point B with as little effort on your behalf as possible it solves the",
    "start": "477000",
    "end": "484080"
  },
  {
    "text": "use case called streaming ETL so if you're ingesting a high-volume stream of events and you only want to do a simple",
    "start": "484080",
    "end": "490170"
  },
  {
    "text": "amount of transformation and then archived in Amazon s3 or send it to your data warehouse and Amazon redshift it",
    "start": "490170",
    "end": "496650"
  },
  {
    "text": "does through that a couple clicks of a button or one or two API calls and you've got this pipeline the streaming",
    "start": "496650",
    "end": "502830"
  },
  {
    "text": "ETL pipeline that delivers data at a high volume from point A to point B very very quickly so more specifically on",
    "start": "502830",
    "end": "512070"
  },
  {
    "start": "510000",
    "end": "510000"
  },
  {
    "text": "Amazon caduceus data streams so customers use Kinesis because Kinesis streams specifically because it provides",
    "start": "512070",
    "end": "518940"
  },
  {
    "text": "a very flexible scalable mechanism for to get data into the AWS cloud very",
    "start": "518940",
    "end": "524610"
  },
  {
    "text": "efficiently so some of the top use cases include clickstream data from web and",
    "start": "524610",
    "end": "531270"
  },
  {
    "text": "mobile devices change data capture from various databases so basically getting a change",
    "start": "531270",
    "end": "537610"
  },
  {
    "text": "data stream from say a my sequel database or Oracle database and processing processing those events in",
    "start": "537610",
    "end": "543220"
  },
  {
    "text": "real time and for all these use cases it's about changing from batch to real",
    "start": "543220",
    "end": "548710"
  },
  {
    "text": "time going from hours or days latency to minutes or seconds there's a number of",
    "start": "548710",
    "end": "555880"
  },
  {
    "text": "tools that I mentioned the most popular is shown on the slide here I mentioned Kinesis data analytics is one of them",
    "start": "555880",
    "end": "561040"
  },
  {
    "text": "we're going to go through one use case today with it spark streaming on EMR is another very popular option it has a",
    "start": "561040",
    "end": "567940"
  },
  {
    "text": "provides a lot of flexibility for sophisticated use cases for those who are unfamiliar with SPARC the most",
    "start": "567940",
    "end": "575380"
  },
  {
    "text": "popular option is listed here as custom code on ec2 we provide a couple open",
    "start": "575380",
    "end": "581650"
  },
  {
    "text": "source libraries the most popular boring being the Kinesis client library and it's still very very popular options for",
    "start": "581650",
    "end": "588490"
  },
  {
    "text": "customers to run one of these open source libraries and their own custom code just on ec2 in an auto scaling",
    "start": "588490",
    "end": "593800"
  },
  {
    "text": "group it provides a lot of flexibility perhaps more primitive API since spark",
    "start": "593800",
    "end": "599830"
  },
  {
    "text": "but it's very very simple and scales very very cleanly without a lot of complexity or components another very",
    "start": "599830",
    "end": "606640"
  },
  {
    "text": "popular option is AWS lambda so for those of you are not familiar database lambda it allows you to do serverless",
    "start": "606640",
    "end": "612880"
  },
  {
    "text": "computation on a Canisius data stream by attaching it as a source of streaming events so as new events arrived at the",
    "start": "612880",
    "end": "619810"
  },
  {
    "text": "stream there's sort of micro batch together and lambda functions are invoked where you can service Li execute",
    "start": "619810",
    "end": "625540"
  },
  {
    "text": "execute your own code in your language of choice be a Java Python JavaScript",
    "start": "625540",
    "end": "631650"
  },
  {
    "text": "the number one thing you should get out of this slide is that Kinesis data streams provides you the flexibility to",
    "start": "631650",
    "end": "637570"
  },
  {
    "text": "be build the solution of your choice we also have a number of third-party integrations that work here but these",
    "start": "637570",
    "end": "644290"
  },
  {
    "text": "are four that are very popular so I'll",
    "start": "644290",
    "end": "649510"
  },
  {
    "start": "647000",
    "end": "647000"
  },
  {
    "text": "describe one use case with Canisius data fires it's not really the focus of this particular talk Kinesis data firehose I",
    "start": "649510",
    "end": "657220"
  },
  {
    "text": "mentioned really really solves the streaming ETL use case very very quickly so if you want to do things like anomaly",
    "start": "657220",
    "end": "663520"
  },
  {
    "text": "detection in batch and you just want to get that data and run those jobs very very quick it's the tool for you so if you're using",
    "start": "663520",
    "end": "669800"
  },
  {
    "text": "spark and spark em lib and maybe you don't want to run sparks streaming Kinesis data fires can get the data in",
    "start": "669800",
    "end": "675860"
  },
  {
    "text": "the format that you needed to be in stored in Amazon s3 in minutes or",
    "start": "675860",
    "end": "681320"
  },
  {
    "text": "seconds versus getting that data delivered periodically when you use can",
    "start": "681320",
    "end": "686900"
  },
  {
    "text": "uses data fires which it is you create a fire hose delivery stream and that fire hose delivery stream has a number of",
    "start": "686900",
    "end": "692980"
  },
  {
    "text": "configuration parameters the most important being things we call buffering hints those buffering hints you tell us",
    "start": "692980",
    "end": "700250"
  },
  {
    "text": "basically a time frame or a size a file you want on s3 or the loads for redshift",
    "start": "700250",
    "end": "705860"
  },
  {
    "text": "and elastic search and we will buffer data until we receive say 100 megabytes",
    "start": "705860",
    "end": "711590"
  },
  {
    "text": "or 500 megabytes so we get to a nice large chunk that you want to deal with and then we'll send it to Amazon s3 or",
    "start": "711590",
    "end": "718340"
  },
  {
    "text": "the Amazon elastic search service or Amazon redshift the other configurations that allows you to do encryption",
    "start": "718340",
    "end": "725210"
  },
  {
    "text": "compression as well as some serverless ETL your allow able to configure a",
    "start": "725210",
    "end": "730310"
  },
  {
    "text": "lambda function as part of your pipeline to do basically streaming ETL so again",
    "start": "730310",
    "end": "735920"
  },
  {
    "text": "for the purposes of this talk Kinesis data fires is really about getting it to your batch analytical tools faster I'm",
    "start": "735920",
    "end": "746270"
  },
  {
    "text": "not sure if I keep on pressing or anything I'm going to set it to hell Kinesis data analytics so Canisius data",
    "start": "746270",
    "end": "754670"
  },
  {
    "start": "748000",
    "end": "748000"
  },
  {
    "text": "analytics allows you to write sequel over streaming data but it also includes extensions for machine learning things",
    "start": "754670",
    "end": "759890"
  },
  {
    "text": "like approximate count distinct one of our own Amazon grown anomaly detection",
    "start": "759890",
    "end": "765230"
  },
  {
    "text": "algorithms and some additional extended functionality that makes it easier to write sequel over streaming data the",
    "start": "765230",
    "end": "773950"
  },
  {
    "text": "customers use Kinesis data analytics because it allows you to solve very very powerful use cases with not a lot of",
    "start": "773950",
    "end": "780980"
  },
  {
    "text": "code and very simply without worrying about some of the more complicated cops concepts that some of the more advanced",
    "start": "780980",
    "end": "787550"
  },
  {
    "text": "stream processing frameworks introduced",
    "start": "787550",
    "end": "791200"
  },
  {
    "text": "so I'm gonna cover Ibanez on cloud watch because it's we're going to go through a use case and a lot more depth and cloud",
    "start": "794530",
    "end": "802910"
  },
  {
    "text": "watch is a monitoring service pretty much almost if you use AWS you use Amazon Cloud watch one of the things",
    "start": "802910",
    "end": "810170"
  },
  {
    "text": "that it provides is the ability there's cloud watch metrics which you see associated with your service metrics",
    "start": "810170",
    "end": "815780"
  },
  {
    "text": "you can develop custom metrics many of you are probably familiar with it there's also a service that's not used",
    "start": "815780",
    "end": "821480"
  },
  {
    "text": "as quite as often but still quite a lot is cloud watch logs cloud watch logs one",
    "start": "821480",
    "end": "826760"
  },
  {
    "text": "of the things that does it provides a mechanism to ingest log data from a large number of different AWS surfaces",
    "start": "826760",
    "end": "833930"
  },
  {
    "text": "automatically so one of those is VPC or virtual private clouds you can adjust",
    "start": "833930",
    "end": "840140"
  },
  {
    "text": "log data using cloud watch logs automatically with a couple of clicks that tell you API calls made against",
    "start": "840140",
    "end": "847640"
  },
  {
    "text": "your V PC and that's one of the use cases were going to be covering today in a little bit more detail one other thing",
    "start": "847640",
    "end": "857600"
  },
  {
    "text": "that I want to mention I some of you guys maybe have played around with it a little bit related to what we're doing here because I watched over the last",
    "start": "857600",
    "end": "864410"
  },
  {
    "text": "year it's spent a lot of effort improving upon their custom dashboarding functionality I've recently used it",
    "start": "864410",
    "end": "871010"
  },
  {
    "text": "quite a bit in some of my demos with customers and they're really iterating on it quite a bit but it's a great way",
    "start": "871010",
    "end": "876860"
  },
  {
    "text": "to do custom metrics and set up a simple dashboard with very very little effort or so infrastructure so one other thing",
    "start": "876860",
    "end": "882950"
  },
  {
    "text": "I'll mention on this light so cloud watch logs so the third point is the one",
    "start": "882950",
    "end": "890120"
  },
  {
    "start": "885000",
    "end": "885000"
  },
  {
    "text": "of the ones I brought up that's quite powerful it allows you to use other AWS services as a data source so VPC flow",
    "start": "890120",
    "end": "897590"
  },
  {
    "text": "logs but also AWS cloud trail log events Amazon route 53 DNS queries you can also",
    "start": "897590",
    "end": "904250"
  },
  {
    "text": "set up your own custom logging infrastructure to send data to Amazon CloudWatch logs it also archives our log",
    "start": "904250",
    "end": "911570"
  },
  {
    "text": "data and there's some analytics built into cloud watch logs one of the cool",
    "start": "911570",
    "end": "917180"
  },
  {
    "text": "things you can do is you can define using a simple processing language to find your own custom metrics based off",
    "start": "917180",
    "end": "923570"
  },
  {
    "text": "of logs that you can then set up by launch alarms for cloud watch - boards a nice feature of Amazon",
    "start": "923570",
    "end": "929900"
  },
  {
    "text": "CloudWatch so I bring it up in the context because we're about to go through a solution that does a nominee detection on vbc",
    "start": "929900",
    "end": "936230"
  },
  {
    "start": "931000",
    "end": "931000"
  },
  {
    "text": "flow logs so how do I give BPC flow logs into an Amazon can usage stream such",
    "start": "936230",
    "end": "941660"
  },
  {
    "text": "that I can do that in all made fiction so CloudWatch logs has a subscription feature that allows you to log send your",
    "start": "941660",
    "end": "950180"
  },
  {
    "text": "logs to Amazon Canisius or AWS landed directly and this is not just VPC flow",
    "start": "950180",
    "end": "955670"
  },
  {
    "text": "logs this is any logs that you send to cloud watch logs and you can set up filters for the description it's a very",
    "start": "955670",
    "end": "961070"
  },
  {
    "text": "easy way to integrate your monitoring or operational modern solutions with some of your more custom or flexible data",
    "start": "961070",
    "end": "967070"
  },
  {
    "text": "processing Newseum using Amazon Kinesis",
    "start": "967070",
    "end": "971200"
  },
  {
    "text": "so what are some advantages of this connection between Amazon Canisius and cloud watch logs so the first is that",
    "start": "982380",
    "end": "990460"
  },
  {
    "text": "you get access to the three services that I just talked to and those services provide their own unique value set so getting logging all your having a lot",
    "start": "990460",
    "end": "999160"
  },
  {
    "text": "of custom configurations to do archival of your log data is very valuable for doing ad-hoc or interactive analysis",
    "start": "999160",
    "end": "1006300"
  },
  {
    "text": "using maybe Amazon Athena on Amazon s3 so you can set up a cloud watch log subscription to send data to Kinesis",
    "start": "1006300",
    "end": "1012600"
  },
  {
    "text": "firehose and then immediately get that data in Amazon s3 for ad hoc analysis or Amazon redshift or the Amazon Elastic",
    "start": "1012600",
    "end": "1019800"
  },
  {
    "text": "search service you can use Kinesis analytics specifically here we'll talk about anomaly detection in more detail",
    "start": "1019800",
    "end": "1026069"
  },
  {
    "text": "but also any custom aggregations that you might have so Kinesis analytics provides quite a lot of power in the",
    "start": "1026070",
    "end": "1032069"
  },
  {
    "text": "fact that you can do things like air percentages filters failure rates the service implements most of the ANSI 2011",
    "start": "1032070",
    "end": "1040589"
  },
  {
    "text": "sequel standard so you get quite a lot of power and the types of custom metrics you can compute the combination of the",
    "start": "1040589",
    "end": "1046350"
  },
  {
    "text": "subscription increases and lakes really opens a lot of doors especially when you're trying to implement like real",
    "start": "1046350",
    "end": "1051810"
  },
  {
    "text": "time operational dashboards or trying to find needles in a haystack on your log data sent from cloud watch logs for",
    "start": "1051810",
    "end": "1060570"
  },
  {
    "text": "Canisius streams the using that setting data to konista streams as part of the cloud module inscription provides that",
    "start": "1060570",
    "end": "1065850"
  },
  {
    "text": "flexibility that I mentioned so you can use any sort of data processing framework that you want choice in fact",
    "start": "1065850",
    "end": "1070980"
  },
  {
    "text": "you might want to do a simple data processing of you just want to perform a filter find a specific event and send",
    "start": "1070980",
    "end": "1077070"
  },
  {
    "text": "notifications based up for that event and the combination of KC streams in AWS lambda allow you to do that very easily",
    "start": "1077070",
    "end": "1083610"
  },
  {
    "text": "I guess the overall point here is that when you send the log gated Amazon Kinesis a lot of different processing",
    "start": "1083610",
    "end": "1090450"
  },
  {
    "text": "options are opened up depending upon your use case so how do I monitor",
    "start": "1090450",
    "end": "1098700"
  },
  {
    "start": "1095000",
    "end": "1095000"
  },
  {
    "text": "application specific metrics using this and Amazon Kinesis streams and analytics so one of the more popular use cases",
    "start": "1098700",
    "end": "1105600"
  },
  {
    "text": "that we have is this cloud watch logs prescription setting in the data Dakini systems increases analytics",
    "start": "1105600",
    "end": "1112730"
  },
  {
    "text": "CloudWatch provides a nice agent which is just an open source library that you can run on ec2 for logging data it helps",
    "start": "1113640",
    "end": "1120720"
  },
  {
    "text": "to pre formatting it deals with common log types like Apache web access logs",
    "start": "1120720",
    "end": "1126710"
  },
  {
    "text": "will convert them if you'd like them to and then send them to cloud watch logs with a lot of metadata associated with",
    "start": "1126710",
    "end": "1132240"
  },
  {
    "text": "them the other thing you can do with the kanesha stream is do the type of more",
    "start": "1132240",
    "end": "1139470"
  },
  {
    "text": "advanced analysis that I was mentioning earlier so off of a casus stream you can do things like how many active users",
    "start": "1139470",
    "end": "1145320"
  },
  {
    "text": "have I had over the past 15 minutes am I having a surge of user behavior where",
    "start": "1145320",
    "end": "1150990"
  },
  {
    "text": "their top 10 articles read in the past 30 minutes so if you have like a website or what is my top page on my mobile app",
    "start": "1150990",
    "end": "1158790"
  },
  {
    "text": "so very interesting things when you not only just operational metrics but also product and users metrics",
    "start": "1158790",
    "end": "1167780"
  },
  {
    "text": "so I talked up the cloud watch subscription feature quite a bit it's",
    "start": "1180419",
    "end": "1186039"
  },
  {
    "text": "one option you don't have to use it another option is you can instead write data directly to Amazon can you see",
    "start": "1186039",
    "end": "1191890"
  },
  {
    "text": "streams we have our own agent that allows you to write data log data to Amazon can you see streams escaping",
    "start": "1191890",
    "end": "1197230"
  },
  {
    "text": "cloud watch altogether it was nice about cloud watch is you get some of the features that are built in the cloud",
    "start": "1197230",
    "end": "1202450"
  },
  {
    "text": "much like the dashboarding in the metrics and whatnot so VPC foe logs and",
    "start": "1202450",
    "end": "1213159"
  },
  {
    "start": "1208000",
    "end": "1208000"
  },
  {
    "text": "monitoring network activity associated with them you can use DBC flow logs and",
    "start": "1213159",
    "end": "1219399"
  },
  {
    "text": "for those not familiar DBC syncs for virtual private cloud a lot of customers run the bulk of their workloads in them",
    "start": "1219399",
    "end": "1225210"
  },
  {
    "text": "most of you guys are already familiar with them one of the features that",
    "start": "1225210",
    "end": "1230860"
  },
  {
    "text": "associated with VPC is a feature called VPC flow logs and it basically logs",
    "start": "1230860",
    "end": "1236139"
  },
  {
    "text": "activity in and out of your V PC so and you can analyze that to network data",
    "start": "1236139",
    "end": "1241990"
  },
  {
    "text": "very easily with that cloud watch subscription by sending that data to a Kinesis data stream in real time it",
    "start": "1241990",
    "end": "1247720"
  },
  {
    "text": "includes things like shown here the source IP address the destinated ress what the resulting say h-2b code is",
    "start": "1247720",
    "end": "1256539"
  },
  {
    "text": "whether it was accepted if I order a 500 error and other detailed information",
    "start": "1256539",
    "end": "1264399"
  },
  {
    "text": "about that call so the your the immediate thing you can start doing is doing simple analysis on you know what",
    "start": "1264399",
    "end": "1271840"
  },
  {
    "text": "is my top IP address coming into the network coming out of the network and",
    "start": "1271840",
    "end": "1277090"
  },
  {
    "text": "start doing anomaly detection on that so we'll walk through that in a little bit",
    "start": "1277090",
    "end": "1282159"
  },
  {
    "text": "but you would also do very simple analysis just like counting the number of API calls from a specific IP address",
    "start": "1282159",
    "end": "1288490"
  },
  {
    "text": "or from a specific service or from a specific user agent using VPC flow logs",
    "start": "1288490",
    "end": "1294510"
  },
  {
    "text": "so I'm showing another sort of pattern with VPC flow logs one of the things",
    "start": "1298040",
    "end": "1306150"
  },
  {
    "text": "that's a sort of a nature of a piece of logs is that they're a little bit naked so when I say that it's a raw log event",
    "start": "1306150",
    "end": "1313410"
  },
  {
    "text": "and you might have a lot of contextual information such as you might know that a specific set of IP ranges are coming",
    "start": "1313410",
    "end": "1319860"
  },
  {
    "text": "from this set of applications or that this signature or user agent is a specific coming from a specific service",
    "start": "1319860",
    "end": "1326930"
  },
  {
    "text": "so a lot of customers following this use case do perform data enrichment prior to",
    "start": "1326930",
    "end": "1332640"
  },
  {
    "text": "the analysis so in here as part of the Kinesis analytics you can use an AWS",
    "start": "1332640",
    "end": "1337740"
  },
  {
    "text": "lambda function to basically enrich that data mapping IP addresses to application names to provide that little extra",
    "start": "1337740",
    "end": "1344940"
  },
  {
    "text": "context it's an optional step but it's an optional step that provides a lot of value the architectural diagram I have",
    "start": "1344940",
    "end": "1351690"
  },
  {
    "text": "here tells you use an AWS lambda function to perform the enrichment and you as dynamodb store the mapping of IP",
    "start": "1351690",
    "end": "1359130"
  },
  {
    "text": "address and application names however you can also do this in from directly",
    "start": "1359130",
    "end": "1365580"
  },
  {
    "text": "from Amazon s3 it's another feature of Kinesis analytics but prior to",
    "start": "1365580",
    "end": "1370710"
  },
  {
    "text": "aggregation and getting that interesting information it definitely provides a lot more context of the information",
    "start": "1370710",
    "end": "1378530"
  },
  {
    "text": "so the next couple slides were going to sort of go deeper into the nominee textile game I'm actually going to go",
    "start": "1388790",
    "end": "1394410"
  },
  {
    "text": "back and cover it in a little bit broader detail and I hope you guys bear with me because I was not expecting to",
    "start": "1394410",
    "end": "1401190"
  },
  {
    "text": "present these slides but I do know the algorithm very well so I'm going to cover it in pretty good detail on this",
    "start": "1401190",
    "end": "1407910"
  },
  {
    "text": "slide and then we'll go through a specific use case so with Kinesis analytics you write",
    "start": "1407910",
    "end": "1413010"
  },
  {
    "text": "sequel code over streaming data right and when you write sequel code over streaming data one of the things that",
    "start": "1413010",
    "end": "1419220"
  },
  {
    "text": "you do is you basically setup a materialized view on the raw data stream so the data comes into the application",
    "start": "1419220",
    "end": "1425490"
  },
  {
    "text": "and it almost looks like you've got this continuously updated table that you're running a sequel query on okay so this",
    "start": "1425490",
    "end": "1431880"
  },
  {
    "text": "raw data stream comes in we map it to specific columns so if it's JSON data or if it's CSV data or if it's on its own",
    "start": "1431880",
    "end": "1438420"
  },
  {
    "text": "custom format we map it to basically a flatting data structure with a series of key value pairs one of those columns",
    "start": "1438420",
    "end": "1444690"
  },
  {
    "text": "based off the VPC vlog it will be like the source IP address if you perform data in which it might be the",
    "start": "1444690",
    "end": "1450150"
  },
  {
    "text": "application name accessible via the sequel code are a couple machine",
    "start": "1450150",
    "end": "1456540"
  },
  {
    "text": "learning algorithms one of them that we'll talk about today is an anomaly detection algorithm based off of a",
    "start": "1456540",
    "end": "1462180"
  },
  {
    "text": "random cut forest algorithm random cut forest algorithm is our own proprietary algorithm there's a we do have a paper",
    "start": "1462180",
    "end": "1468450"
  },
  {
    "text": "online that you can read in a fairly good detail on how the algorithm works",
    "start": "1468450",
    "end": "1473610"
  },
  {
    "text": "how it's a text anomalies on the stream but as that raw data stream comes in",
    "start": "1473610",
    "end": "1478670"
  },
  {
    "text": "what it does is it takes a set of numeric data points and cow with so n",
    "start": "1478670",
    "end": "1484170"
  },
  {
    "text": "dimensions of data and the cow come out calculates the geometrical distance of a",
    "start": "1484170",
    "end": "1489210"
  },
  {
    "text": "single data point against the data points that has seen in the past so what",
    "start": "1489210",
    "end": "1494820"
  },
  {
    "text": "does that actually mean so if you plot it on a graph what it will look like is for your common applications common API",
    "start": "1494820",
    "end": "1501300"
  },
  {
    "text": "calls based off the dimensions you pass it taking a simple example if you're just passing it say IP addresses in",
    "start": "1501300",
    "end": "1507570"
  },
  {
    "text": "counts so one key and one metric what it'll do is it'll start detecting is a",
    "start": "1507570",
    "end": "1512790"
  },
  {
    "text": "particular IP address all of a sudden calling making API calls more frequently",
    "start": "1512790",
    "end": "1517950"
  },
  {
    "text": "and what this algorithm produces is an anomaly score an anomaly score is a numeric value that",
    "start": "1517950",
    "end": "1525120"
  },
  {
    "text": "doesn't exactly match - but kinda represents the likelihood that it's an anomaly so against when you run the",
    "start": "1525120",
    "end": "1533970"
  },
  {
    "text": "anomaly detection on the stream what we'll do is we'll annotate it with is this specific row or record that we've",
    "start": "1533970",
    "end": "1539700"
  },
  {
    "text": "seen is an anomalous so for V PC flow logs the most obvious use case is doing",
    "start": "1539700",
    "end": "1545730"
  },
  {
    "text": "intrusion detection using the anomaly detection algorithm using like detecting",
    "start": "1545730",
    "end": "1551460"
  },
  {
    "text": "DDoS attacks and things like that using simple counts but the more dimensions you add to the algorithm the",
    "start": "1551460",
    "end": "1556740"
  },
  {
    "text": "more accurate it becomes so adding a single IP address IP address count might",
    "start": "1556740",
    "end": "1563639"
  },
  {
    "text": "be useful but if you add combine that with some things like the counts by the",
    "start": "1563639",
    "end": "1569820"
  },
  {
    "text": "destination IP address counts by the user agent and counts by other useful",
    "start": "1569820",
    "end": "1575100"
  },
  {
    "text": "statistics you start building a more complicated sophisticated model and the algorithm will take and the number of",
    "start": "1575100",
    "end": "1581130"
  },
  {
    "text": "dimensions it scales very well on a high granularity of dimensions and will start producing that anomaly score and that",
    "start": "1581130",
    "end": "1589139"
  },
  {
    "text": "anomaly squared will tell you what it is anomalous but the algorithm goes further beyond that the other thing that the anomaly detection algorithm does is",
    "start": "1589139",
    "end": "1596010"
  },
  {
    "text": "it'll tell you this thing's called directionality and attribution so after you have the score what customers",
    "start": "1596010",
    "end": "1602669"
  },
  {
    "text": "typically will do is they'll send it to a dynamodb table for maybe a real-time dashboard they'll mate they maybe send a",
    "start": "1602669",
    "end": "1608340"
  },
  {
    "text": "notification so if my score is one or two standard deviations above the",
    "start": "1608340",
    "end": "1614220"
  },
  {
    "text": "average then I'm going to trigger our alarm and have somebody investigate but",
    "start": "1614220",
    "end": "1620039"
  },
  {
    "text": "when you trigger our alarm like this there if I mentioned context it being so important so you can add a minimal",
    "start": "1620039",
    "end": "1626010"
  },
  {
    "text": "amount of context like doing data enrichment to map IP addresses to the IP to the application names so you get some",
    "start": "1626010",
    "end": "1634019"
  },
  {
    "text": "context so that when you pay somebody or send a notification you know hey I've detected an anomaly it looks like this",
    "start": "1634019",
    "end": "1639450"
  },
  {
    "text": "IP address for this set of applications is behaving abnormally but it doesn't really tell anybody else any other",
    "start": "1639450",
    "end": "1644669"
  },
  {
    "text": "information so about a month ago we added these there's two very very additional features that tells you why",
    "start": "1644669",
    "end": "1650879"
  },
  {
    "text": "the data point was and we call those first is attribution and the other algorithm is called",
    "start": "1650879",
    "end": "1657719"
  },
  {
    "text": "directional the other part of the feature was called directionality so let's first talk about what attribution means so attribution based off of the",
    "start": "1657719",
    "end": "1666299"
  },
  {
    "text": "end dimensions that you've passed we will tell you what columns that you pass",
    "start": "1666299",
    "end": "1671489"
  },
  {
    "text": "through the anomaly most contributed to the score so you pass this ten columns of various either",
    "start": "1671489",
    "end": "1678679"
  },
  {
    "text": "raw data or analyzed a with like IP address counts or averages or something",
    "start": "1678679",
    "end": "1685739"
  },
  {
    "text": "like that and we'll say column a represented 80% of the anomaly column B",
    "start": "1685739",
    "end": "1692369"
  },
  {
    "text": "represented 20% so on and so forth so when you send that notification L the anomaly detection album tells you this",
    "start": "1692369",
    "end": "1699359"
  },
  {
    "text": "was the anomalous data point and not only that but these are the columns that",
    "start": "1699359",
    "end": "1704460"
  },
  {
    "text": "we think are what caused the anomaly providing that type of context not only",
    "start": "1704460",
    "end": "1709830"
  },
  {
    "text": "just through the data enrichment but also this type of feature allows you to act react much more smartly to it",
    "start": "1709830",
    "end": "1715440"
  },
  {
    "text": "instead of just producing a simple score the second thing that was added to the algorithm about a month or two ago was",
    "start": "1715440",
    "end": "1721859"
  },
  {
    "text": "directionality the other thing that when we produced the score would tends to happen when we previous scores did we",
    "start": "1721859",
    "end": "1726960"
  },
  {
    "text": "tend to produce them clustered so one event comes in and it's anomalous the next event comes in that's associated",
    "start": "1726960",
    "end": "1732960"
  },
  {
    "text": "with the same one its anomalous again for a period of time and the reason why this occurs is a simplest example you",
    "start": "1732960",
    "end": "1739769"
  },
  {
    "text": "can think is a DDoS attack so all of a sudden we're seeing a huge influx of IP",
    "start": "1739769",
    "end": "1745409"
  },
  {
    "text": "calls from this IP range right and when we make those calls when we detect the",
    "start": "1745409",
    "end": "1752609"
  },
  {
    "text": "anomaly usually one anomaly gets triggered then two or three more gets triggered before it starts to normalize",
    "start": "1752609",
    "end": "1758009"
  },
  {
    "text": "so when we say normalize we're talking about sort of a direction so is this the",
    "start": "1758009",
    "end": "1764039"
  },
  {
    "text": "normal behavior that we will continue to see or is this behavior going to change over time and this is that where the",
    "start": "1764039",
    "end": "1769289"
  },
  {
    "text": "feature that we added really really adds value in it basically tells you the vector direction of whether the anomaly",
    "start": "1769289",
    "end": "1775529"
  },
  {
    "text": "is moving so is it going down or is it going up so is that increasing in severity or decreasing in severity and",
    "start": "1775529",
    "end": "1781999"
  },
  {
    "text": "when you're doing things like intrusion detection on V PC floo logs that type of information is",
    "start": "1781999",
    "end": "1788310"
  },
  {
    "text": "extremely valuable either to respond to programmatically or for your engineers as they respond to events hopefully that",
    "start": "1788310",
    "end": "1802920"
  },
  {
    "text": "was helpful it was a long-winded explanation without a lot of slides so",
    "start": "1802920",
    "end": "1810300"
  },
  {
    "start": "1810000",
    "end": "1810000"
  },
  {
    "text": "is something wrong with the network the so the next couple slides are going to talk about how the anomaly detection",
    "start": "1810300",
    "end": "1816510"
  },
  {
    "text": "work sort of works in the specific use case right so imagine you've got a set",
    "start": "1816510",
    "end": "1822840"
  },
  {
    "text": "of services under a specific AWS account in a specific AWS zone so US East one-e-and they're interacting with",
    "start": "1822840",
    "end": "1830340"
  },
  {
    "text": "another account a different account in another region and this represents you",
    "start": "1830340",
    "end": "1836070"
  },
  {
    "text": "know this what we think is normal behavior and you're passing the anomaly detection algorithm a set of counts",
    "start": "1836070",
    "end": "1842960"
  },
  {
    "text": "associated with this or perhaps just the raw data associated with it",
    "start": "1842960",
    "end": "1848299"
  },
  {
    "text": "so one of the things that's hard to detect is when you look at a network it",
    "start": "1855190",
    "end": "1861800"
  },
  {
    "text": "represents a graph and sometimes that graph is not always obvious all right so",
    "start": "1861800",
    "end": "1867290"
  },
  {
    "text": "you'll see typical behavior of service a interacting with say service D but that",
    "start": "1867290",
    "end": "1874130"
  },
  {
    "text": "may or may not have been correct so when you're doing using the anomaly detection",
    "start": "1874130",
    "end": "1879380"
  },
  {
    "text": "algorithm in Kinesis data analytics one of the things that it can do is if you calculate those relationships ahead of",
    "start": "1879380",
    "end": "1886820"
  },
  {
    "text": "time and then pass them the algorithm they can tell you one of those graph when that graph changes because it's building that model under the covers for",
    "start": "1886820",
    "end": "1893030"
  },
  {
    "text": "you so in this particular example we're asking the question is this a bad deployment to this relationship between",
    "start": "1893030",
    "end": "1898790"
  },
  {
    "text": "services change so and the way to identify this is simply simple counts on",
    "start": "1898790",
    "end": "1906440"
  },
  {
    "text": "these are the number of interactions had with service a and B a and C B and C so",
    "start": "1906440",
    "end": "1913400"
  },
  {
    "text": "on and so forth and just to enumerate those calculations and these are very simple group by statements in your sequel code once you calculate those and",
    "start": "1913400",
    "end": "1921770"
  },
  {
    "text": "that type of in the America you get some insight into building those graphs and then passing to the anomaly text nagham",
    "start": "1921770",
    "end": "1928310"
  },
  {
    "text": "will tell you which data points are anomalous or changing over time what is changing about them and what direction",
    "start": "1928310",
    "end": "1934280"
  },
  {
    "text": "is changing",
    "start": "1934280",
    "end": "1937030"
  },
  {
    "start": "1943000",
    "end": "1943000"
  },
  {
    "text": "so changing use cases a little bit a",
    "start": "1944320",
    "end": "1949269"
  },
  {
    "text": "similar example is service dependencies especially into and out of a V PC so you",
    "start": "1954070",
    "end": "1961910"
  },
  {
    "text": "might have a service that's housed in the V PC that's interacting with the my sequel database outside of it or a Redis",
    "start": "1961910",
    "end": "1968300"
  },
  {
    "text": "cluster out out of it what are the expected dependencies associated with that service so within the V PC the",
    "start": "1968300",
    "end": "1981860"
  },
  {
    "text": "service might interact with say s3 a different one of your own managed services maybe Johnny Moody be using the direct",
    "start": "1981860",
    "end": "1990350"
  },
  {
    "text": "connect BBC connections that we have whereas you might have your own Redis cluster this pianist outside again this",
    "start": "1990350",
    "end": "1997370"
  },
  {
    "text": "is a use case where the anomaly detection algorithm will would doing a lot of enrichment or calculation ahead",
    "start": "1997370",
    "end": "2004120"
  },
  {
    "text": "of the of running the algorithm will produce more valuable results so I",
    "start": "2004120",
    "end": "2012760"
  },
  {
    "start": "2011000",
    "end": "2011000"
  },
  {
    "text": "covered a lot of stuff at a very very high level there's a lot of information that you can use after this presentation",
    "start": "2012760",
    "end": "2021310"
  },
  {
    "text": "to help learn a little bit more about the algorithm and the types of use cases in itself so the the first thing is to",
    "start": "2021310",
    "end": "2029050"
  },
  {
    "text": "like if you were to do anything after this talk the for the one thing I would say is try out the algorithm and the",
    "start": "2029050",
    "end": "2034150"
  },
  {
    "text": "easiest way to try out the algorithm is we have this tool called the Kinesis data generator it's a simple UI that",
    "start": "2034150",
    "end": "2040390"
  },
  {
    "text": "allows you to write data to a Kinesis stream and there's in our documentation as well as on the AWS big data blog",
    "start": "2040390",
    "end": "2046750"
  },
  {
    "text": "we've got great documentation on going through the analogy them in more detail",
    "start": "2046750",
    "end": "2052919"
  },
  {
    "text": "my favorite one is the the second one on the bottom the real-time click stream",
    "start": "2052920",
    "end": "2059050"
  },
  {
    "text": "anomaly detection with Amazon Kinesis analytics and that particular use case there's something associated when with",
    "start": "2059050",
    "end": "2064929"
  },
  {
    "text": "collation data called a click-through rate so if you serve an ad or have a particular button of all the users that see that ad or that button what",
    "start": "2064930",
    "end": "2071409"
  },
  {
    "text": "percentage of them click through the that particular blog will through the use case of detecting",
    "start": "2071410",
    "end": "2076720"
  },
  {
    "text": "anomalous behavior of when this click-through rate goes up or down and what is specifically causing that so we",
    "start": "2076720",
    "end": "2083230"
  },
  {
    "text": "talked about an operational use case but the one that I just highlight now is different in the fact that it's telling",
    "start": "2083230",
    "end": "2088929"
  },
  {
    "text": "you interesting things about how users interact with your product instead of an operational use case so there might be",
    "start": "2088930",
    "end": "2094330"
  },
  {
    "text": "something interesting about why specific users connect to click on a specific",
    "start": "2094330",
    "end": "2100000"
  },
  {
    "text": "button you find that if they stay on the page and if they read the first two paragraphs they're more likely to click on get started or if they stay on the",
    "start": "2100000",
    "end": "2108040"
  },
  {
    "text": "page and are coming from a specific source IP address if they're coming from Google they usually don't click through",
    "start": "2108040",
    "end": "2114850"
  },
  {
    "text": "on the bottom if they're coming through one of your specific marketing activities may be a marketing email they",
    "start": "2114850",
    "end": "2120760"
  },
  {
    "text": "usually go through and click the button so I bring up this simple use case because it's you can get very powerful",
    "start": "2120760",
    "end": "2127570"
  },
  {
    "text": "insights using simple use cases like that and getting started using the Kinesis data gener and the examples that",
    "start": "2127570",
    "end": "2133030"
  },
  {
    "text": "we have are a good way to get a good way to get started so with that thank you",
    "start": "2133030",
    "end": "2138610"
  },
  {
    "text": "guys very much I would stay here to answer some more questions after the top",
    "start": "2138610",
    "end": "2143670"
  },
  {
    "text": "[Music] [Applause]",
    "start": "2143890",
    "end": "2149819"
  }
]
[
  {
    "start": "0",
    "end": "135000"
  },
  {
    "text": "hello and thank you for attending today's webinar we will begin the presentation in approximately 1 minute",
    "start": "5120",
    "end": "13070"
  },
  {
    "text": "hello and welcome to fanatics ingests streaming data to a data Lake on AWS my",
    "start": "59379",
    "end": "65478"
  },
  {
    "text": "name is Paul Sears a partner Solutions Architect for Amazon Web Services and I will be your host and moderator for",
    "start": "65479",
    "end": "71600"
  },
  {
    "text": "today's presentation when you join today's webinar you selected to join my either phone call or your computer audio",
    "start": "71600",
    "end": "78110"
  },
  {
    "text": "if for any reason you would like to change your audio selection you can do so by accessing your audio pane in the",
    "start": "78110",
    "end": "84500"
  },
  {
    "text": "control panel from this control panel you also have the opportunity to submit questions to today's presenters by",
    "start": "84500",
    "end": "91250"
  },
  {
    "text": "typing your questions into the chat box we will collect the questions and address as many as we can during the Q&A",
    "start": "91250",
    "end": "97159"
  },
  {
    "text": "session at the end of today's presentation time permitting also at the end of today's event is a brief survey",
    "start": "97159",
    "end": "103460"
  },
  {
    "text": "so please stay connected until the end of the broadcast and submit your feedback as your opinions count",
    "start": "103460",
    "end": "110020"
  },
  {
    "text": "lastly the person the PowerPoint presentation will be available through SlideShare along with a recording of the",
    "start": "110020",
    "end": "116330"
  },
  {
    "text": "webinar on YouTube you know get this via an email that will be sent two to three days after the conclusion of this event",
    "start": "116330",
    "end": "123320"
  },
  {
    "text": "so keep an eye out for the follow-up email sent to the address you provided",
    "start": "123320",
    "end": "129188"
  },
  {
    "start": "135000",
    "end": "900000"
  },
  {
    "text": "again welcome to today's live webinar fanatics and just streaming data to a data Lake on AWS again my name is Paul",
    "start": "138220",
    "end": "146020"
  },
  {
    "text": "Sears a partner solutions architect for Amazon Web Services and I will be your host and moderator for today's webinar in addition to learning about AWS we'll",
    "start": "146020",
    "end": "154120"
  },
  {
    "text": "also hear from Jordan Mart's director of technology solutions for tunity and Allen Chang Senior Product Manager",
    "start": "154120",
    "end": "161530"
  },
  {
    "text": "for phonetics we will first talk about",
    "start": "161530",
    "end": "168700"
  },
  {
    "text": "AWS and data leak solutions we will next learn about moving data and real-time",
    "start": "168700",
    "end": "173800"
  },
  {
    "text": "opportunity and then fanatics will share their story and insights and time permitting will close out the with",
    "start": "173800",
    "end": "180010"
  },
  {
    "text": "questions and answers so please post your questions in the chat box throughout this presentation as we will",
    "start": "180010",
    "end": "186070"
  },
  {
    "text": "review questions at the end of today's event today you will learn how to deploy",
    "start": "186070",
    "end": "194530"
  },
  {
    "text": "a data Lake on Amazon s3 how to ingest data in real time and how to use AWS",
    "start": "194530",
    "end": "199750"
  },
  {
    "text": "eternity and kafka to get more value from your data so let's go ahead and",
    "start": "199750",
    "end": "206380"
  },
  {
    "text": "learn about AWS so to take a look at a daily daily looks like an AWS and how it",
    "start": "206380",
    "end": "213910"
  },
  {
    "text": "drives business value we need to first set the landscape and define what a data Lake actually is a Dave Lake is a",
    "start": "213910",
    "end": "220540"
  },
  {
    "text": "centralized repository that allows you to store all your structured and unstructured data at any scale you can",
    "start": "220540",
    "end": "227320"
  },
  {
    "text": "store your data as is without having the first structure the data and run",
    "start": "227320",
    "end": "232540"
  },
  {
    "text": "different types analytics from dashboards and visualizations to big",
    "start": "232540",
    "end": "237970"
  },
  {
    "text": "data processing real-time analytics and machine learning to guide for better decisions traditionally analytics was",
    "start": "237970",
    "end": "247900"
  },
  {
    "text": "stored in large data warehouse or a large relational database system often these systems were purpose-built",
    "start": "247900",
    "end": "253480"
  },
  {
    "text": "hardware or appliances that were deployed within your data center however these systems are expensive to implement",
    "start": "253480",
    "end": "260229"
  },
  {
    "text": "and maintain and they face significant challenges with scaling so what is",
    "start": "260229",
    "end": "265300"
  },
  {
    "text": "another option another option is to build a data Lake where you can ingest",
    "start": "265300",
    "end": "271450"
  },
  {
    "text": "this to or all of your data structured or unstructured in batch or real-time in a",
    "start": "271450",
    "end": "276699"
  },
  {
    "text": "single large repository and this repository becomes the source of truth for all of your data and analytics by",
    "start": "276699",
    "end": "282610"
  },
  {
    "text": "having all of your data in one place you can discover insights that you may have missed when data stored in different",
    "start": "282610",
    "end": "288280"
  },
  {
    "text": "systems or in different silos",
    "start": "288280",
    "end": "291840"
  },
  {
    "text": "implementing a data Lake is start of a journey to begin a data-driven business",
    "start": "294479",
    "end": "299620"
  },
  {
    "text": "you define your business outcomes working backwards to your modern data architecture along the journey you can",
    "start": "299620",
    "end": "306130"
  },
  {
    "text": "experiment and explore data and new ways while only paying for what you actually consume and this enables agility",
    "start": "306130",
    "end": "312729"
  },
  {
    "text": "allowing you to quickly adapt to new data sources and deployment of your infrastructure in minutes instead of",
    "start": "312729",
    "end": "319419"
  },
  {
    "text": "months so now that you have decided on",
    "start": "319419",
    "end": "324520"
  },
  {
    "text": "implementing a data like what do you want to do with the data so data layers can be designed in various ways but you",
    "start": "324520",
    "end": "330520"
  },
  {
    "text": "need to understand your business case first and then work backwards through the Analects through the analytics",
    "start": "330520",
    "end": "337840"
  },
  {
    "text": "pipeline that you implement as a modern data architecture the Analects Analects",
    "start": "337840",
    "end": "344530"
  },
  {
    "text": "pipeline allows you to experiment in scale as needed with with the analytics pipeline you can ingest your data and",
    "start": "344530",
    "end": "350830"
  },
  {
    "text": "store it into your data Lake you can then analyze or process the data to",
    "start": "350830",
    "end": "356380"
  },
  {
    "text": "derive the results you require and those results are then made available to consume or visualize the data lake",
    "start": "356380",
    "end": "362740"
  },
  {
    "text": "becomes the source that lets you derive your answers and insight regardless of the kind of data that you want to use",
    "start": "362740",
    "end": "367930"
  },
  {
    "text": "such as margin data erp transactions or even workflow logs when you implement a",
    "start": "367930",
    "end": "376419"
  },
  {
    "text": "data Lake as part of a modern data architecture you gain a number of beneficial business outcomes such as",
    "start": "376419",
    "end": "382080"
  },
  {
    "text": "consolidation of your data into a single source of truth this allows you to innovate for new revenues by leveraging",
    "start": "382080",
    "end": "388300"
  },
  {
    "text": "relationships of data but you wouldn't otherwise be able to use another outcome could be real-time engagement or an or",
    "start": "388300",
    "end": "395710"
  },
  {
    "text": "an interactive or and better customer experience and building analytics pipeline around your data lake",
    "start": "395710",
    "end": "401400"
  },
  {
    "text": "facilitates automation across your organization a data Lake is a central component of a",
    "start": "401400",
    "end": "409659"
  },
  {
    "text": "modern data architecture on AWS it provides a single repository for all",
    "start": "409659",
    "end": "414729"
  },
  {
    "text": "your recreational and nodulation data this repository is based on Amazon s3 as a store for the data Lake and it is a",
    "start": "414729",
    "end": "422019"
  },
  {
    "text": "source that will be consumed by many highly interoperable services such as ETL processes or services to query your",
    "start": "422019",
    "end": "428859"
  },
  {
    "text": "data and tools that lets you visualize your data and new ways to gain unique insights to drive your business forward",
    "start": "428859",
    "end": "436979"
  },
  {
    "text": "so why would you use Amazon s3 for your store and your modern data architecture",
    "start": "437579",
    "end": "443139"
  },
  {
    "text": "Amazon s3 is ideal to use as a data Lake and as a core of modern architecture because it is extremely durable with 11",
    "start": "443139",
    "end": "451059"
  },
  {
    "text": "lines and durability now this is actually very important when you have hundreds of terabytes or more or",
    "start": "451059",
    "end": "456249"
  },
  {
    "text": "petabytes of important data you don't want to have your data alter to change anytime during a life cycle s3 is also",
    "start": "456249",
    "end": "463599"
  },
  {
    "text": "designed to be highly available without the four nines availability so you can always access your data in terms of",
    "start": "463599",
    "end": "469479"
  },
  {
    "text": "scale s3 is practically scaleless and you can store as much data as you need and more importantly only pay for the",
    "start": "469479",
    "end": "475569"
  },
  {
    "text": "amount of storage you are actually consuming and by using Amazon s3 as your",
    "start": "475569",
    "end": "483429"
  },
  {
    "text": "data Lake you're no longer limited with scale as you are with traditional data warehouses and relational database",
    "start": "483429",
    "end": "488769"
  },
  {
    "text": "systems one of the primary advantages of using this design is that storage and computer no longer coupled together in",
    "start": "488769",
    "end": "495279"
  },
  {
    "text": "traditional data warehouses to add more storage you also have to add more compute by either upgrading the server",
    "start": "495279",
    "end": "500739"
  },
  {
    "text": "hardware or adding more servers to the data warehouse cluster this often results in some resources being",
    "start": "500739",
    "end": "506860"
  },
  {
    "text": "underutilized by decoupling compute from storage you can scale each resource independently as appropriate for",
    "start": "506860",
    "end": "513909"
  },
  {
    "text": "analytics workloads and you will learn more about this shortly so now I'm gonna",
    "start": "513909",
    "end": "521740"
  },
  {
    "text": "hand this over to Jordan opportunity who will now talk about how eternity helps customers ingest data into the cloud",
    "start": "521740",
    "end": "529110"
  },
  {
    "text": "perfect thanks Paul and really enjoy some of those images as well as some of the other ways that we've worked",
    "start": "529110",
    "end": "535329"
  },
  {
    "text": "together over the past oh goodness this since you know has been created I think it's been seven",
    "start": "535329",
    "end": "541360"
  },
  {
    "text": "years so it's been wonderful having partners like Amazon and then having customers and partners like fanatics to",
    "start": "541360",
    "end": "547360"
  },
  {
    "text": "talk about the way that we work together and I want to thank anybody the audience for joining us one of the things that we",
    "start": "547360",
    "end": "552640"
  },
  {
    "text": "do at attune 'ti is we're based on the idea that our technology captures all these sources and collects them to be",
    "start": "552640",
    "end": "559180"
  },
  {
    "text": "able to provide that fundamental data Lake transformation that you see and",
    "start": "559180",
    "end": "564190"
  },
  {
    "text": "whenever you take that transformation what you're looking to be able to provide is the database migration these",
    "start": "564190",
    "end": "569950"
  },
  {
    "text": "are our competencies that's how I'll mark it so when you look at it from the standpoint of who we are we'll load into big data tools like",
    "start": "569950",
    "end": "577060"
  },
  {
    "text": "Kinesis s3 pull it off s3 and are even in s3 you can pull it into elasticsearch",
    "start": "577060",
    "end": "583360"
  },
  {
    "text": "and other components you can pull it into redshift as well and that's where a lot of that big data story that Paul's",
    "start": "583360",
    "end": "589360"
  },
  {
    "text": "been referencing has been not only built but also expanded upon with all these",
    "start": "589360",
    "end": "594550"
  },
  {
    "text": "real-time migrations criminals oftentimes you call legacy but just",
    "start": "594550",
    "end": "599700"
  },
  {
    "text": "on-premise your ERP your CRM they could be running on oracle or sequel server or all these different platform tools so",
    "start": "599700",
    "end": "606670"
  },
  {
    "text": "that becomes part of the migration further you could take your mainframes right there's blog posts that you could go out to the APN and look at each one",
    "start": "606670",
    "end": "613510"
  },
  {
    "text": "of those as well as the ease of use of being able to develop in this overall ecosystem by just going to our",
    "start": "613510",
    "end": "619450"
  },
  {
    "text": "marketplace plugging in a license key and get going to work on migrating your",
    "start": "619450",
    "end": "625210"
  },
  {
    "text": "data to these data lakes and as we talk about what we are and how we have how we work with different platforms what we're",
    "start": "625210",
    "end": "632200"
  },
  {
    "text": "looking at is is building a platform that allows you to take each pipeline ETL job pipeline as you think about it",
    "start": "632200",
    "end": "639040"
  },
  {
    "text": "we're CDC so CDC means it's a real-time tool set allowing you to move that but",
    "start": "639040",
    "end": "644650"
  },
  {
    "text": "when you have these key considerations what you're looking at from these insights is being able to deliver that with some assurances though the",
    "start": "644650",
    "end": "650950"
  },
  {
    "text": "qualities there the verification that it landed some details of the governance the way that you can not only verify but",
    "start": "650950",
    "end": "657460"
  },
  {
    "text": "what's there and how it got there so understanding the automation and that's one of the key things that Eternity",
    "start": "657460",
    "end": "663160"
  },
  {
    "text": "brings is key you know traditional data warehouse development takes a long time just to even get started the development",
    "start": "663160",
    "end": "669610"
  },
  {
    "text": "of different applications and the rest of those so as your bill each one of those applications you want to be able to generate a lot of the",
    "start": "669610",
    "end": "675760"
  },
  {
    "text": "logic from those source systems or generate the actual table design and those things so that's part of what",
    "start": "675760",
    "end": "681550"
  },
  {
    "text": "attorney does under the covers it automates a lot of that also the considerations of data typing right and I'll talk about some of the some of",
    "start": "681550",
    "end": "687880"
  },
  {
    "text": "those but then as you're looking at your business needs a lot of the business needs when you read those ETL tool kits",
    "start": "687880",
    "end": "693790"
  },
  {
    "text": "right we're in this new new world where a lot of the development of applications they require you to understand how to",
    "start": "693790",
    "end": "700330"
  },
  {
    "text": "move your data and how to address that from your business need and if the business now is getting more real-time",
    "start": "700330",
    "end": "705460"
  },
  {
    "text": "we're a very powerful component for making sure everything comes in in real time and that's where it gets off with",
    "start": "705460",
    "end": "711550"
  },
  {
    "text": "that analytic ready data set that we took in there whatever you're looking at it these are the considerations I mark",
    "start": "711550",
    "end": "718720"
  },
  {
    "text": "them by the six considerations I'm gonna go into each one but tell them as a story so when you look at a different",
    "start": "718720",
    "end": "723880"
  },
  {
    "text": "platform or building a data Lake all the data whatever you're generating it and",
    "start": "723880",
    "end": "729190"
  },
  {
    "text": "loading it you want to make sure that it's in there I mean a lot of people are often talking okay well miss my report",
    "start": "729190",
    "end": "735040"
  },
  {
    "text": "from yesterday no it's actually a minute ago that it got here and in and it came through a process of landing the files",
    "start": "735040",
    "end": "742120"
  },
  {
    "text": "and there's some formats in s3 that we help handle and manage the way it lands we also land it memory so we give that",
    "start": "742120",
    "end": "748630"
  },
  {
    "text": "ability then to overwrite it and be able to because it's immutable right they need to talk about the changes of it so",
    "start": "748630",
    "end": "753820"
  },
  {
    "text": "being able to constantly move data in with very little downtime and prepare",
    "start": "753820",
    "end": "759310"
  },
  {
    "text": "that analytics ready data set becomes key that's where you talk about some of that low latency capability there's also",
    "start": "759310",
    "end": "765910"
  },
  {
    "text": "the scale we have customers with over a billion transactions every quarter",
    "start": "765910",
    "end": "771430"
  },
  {
    "text": "coming into huge data lakes and what you're looking at is is the sources you got hundreds of sources so by a source",
    "start": "771430",
    "end": "777850"
  },
  {
    "text": "that's an entire database so what we're looking at is is the ability to efficiently scale the sources um to",
    "start": "777850",
    "end": "785920"
  },
  {
    "text": "hundreds and hundreds of different applications and bringing those all together that scale makes it very easy",
    "start": "785920",
    "end": "791110"
  },
  {
    "text": "to use and that's one of the fundamental reasons people look at the the platform",
    "start": "791110",
    "end": "796270"
  },
  {
    "text": "there's also the flexibility right so you get one tool it's drag-and-drop now as soon as you still have to configure",
    "start": "796270",
    "end": "802240"
  },
  {
    "text": "the source system and do some natural configurations but that flexibility of just going to a draw down saying okay got a Oracle here I got",
    "start": "802240",
    "end": "808570"
  },
  {
    "text": "a sequel server here and I want to be able to take and that move that data type into s3 that's really powerful there's also that that you I giving you",
    "start": "808570",
    "end": "816880"
  },
  {
    "text": "that drag-and-drop gives you a lot of time to value in the fact that you can build jobs very efficiently and get them",
    "start": "816880",
    "end": "822820"
  },
  {
    "text": "to market in a very well actually to market to get him to your business customers very efficiently and not",
    "start": "822820",
    "end": "829210"
  },
  {
    "text": "having to manage that manual scripting often will handle for the future proofing of that so I've built data",
    "start": "829210",
    "end": "835450"
  },
  {
    "text": "lakes I wasn't always a sales guy and working for a vendor when I was a developer and I was leading some of the",
    "start": "835450",
    "end": "841180"
  },
  {
    "text": "the applications and systems that we were building in the past what we had to do is we'd have to write a lot of",
    "start": "841180",
    "end": "847090"
  },
  {
    "text": "scripts to get things up and maintain him and source systems would change if we have the future proofing of that",
    "start": "847090",
    "end": "853090"
  },
  {
    "text": "capability by making sure if the system changes we change with it that gives you a lot of not only time to value but",
    "start": "853090",
    "end": "858850"
  },
  {
    "text": "consistent time to value which is key the other one we go to is performance let's say you get a huge ecosystem like",
    "start": "858850",
    "end": "865780"
  },
  {
    "text": "a big platform application and when you're looking at it what we're saying is this agentless process the way it",
    "start": "865780",
    "end": "872200"
  },
  {
    "text": "installs the way they execute the system you get logs that are terabytes in size",
    "start": "872200",
    "end": "877960"
  },
  {
    "text": "and scale and you highly performant operations there's also the efficiency",
    "start": "877960",
    "end": "883360"
  },
  {
    "text": "of the way it connects it's not only performant but it doesn't affect the production system because of the way it extracts sometimes you write queries and",
    "start": "883360",
    "end": "890170"
  },
  {
    "text": "you're using an ETL tool but we don't do that our CDC is based on the idea that it's a minute the transaction hits a",
    "start": "890170",
    "end": "896380"
  },
  {
    "text": "commit or it lands inside that database it's replicated out immediately so that's a huge facet of the overall",
    "start": "896380",
    "end": "902770"
  },
  {
    "start": "900000",
    "end": "970000"
  },
  {
    "text": "system and now what you think about is three core propositions when you're",
    "start": "902770",
    "end": "908620"
  },
  {
    "text": "building your data Lake you now have continuous ingest and what that means is every source whether they're hundreds of",
    "start": "908620",
    "end": "914680"
  },
  {
    "text": "them are ten or twenty however you do it from many different systems that's the heterogeneous that means that we're",
    "start": "914680",
    "end": "920350"
  },
  {
    "text": "generating and automating that process lastly there's one thing that's",
    "start": "920350",
    "end": "925630"
  },
  {
    "text": "consideration when building a data Lake it's these small files are being able to handle for that merging of different",
    "start": "925630",
    "end": "932350"
  },
  {
    "text": "records so if you had a usually Hadoop these are all files right so you have to overwrite them over time to combine the",
    "start": "932350",
    "end": "939010"
  },
  {
    "text": "data so you have the big table the database table you're loading and table a has yesterday so",
    "start": "939010",
    "end": "944680"
  },
  {
    "text": "table data as of yesterday has to be moved into the larger big data table we've generated all the hives hive logic",
    "start": "944680",
    "end": "952600"
  },
  {
    "text": "and scripts using EMR and we're able to handle for those whether it's hive or spark or however you want to do it",
    "start": "952600",
    "end": "958269"
  },
  {
    "text": "automate that process of generating that code that's a big differentiator that that's not only future proofing the",
    "start": "958269",
    "end": "964720"
  },
  {
    "text": "source extraction but actually the target and management of those activities as you're going so when you",
    "start": "964720",
    "end": "972279"
  },
  {
    "start": "970000",
    "end": "1058000"
  },
  {
    "text": "do this the platform is based on the idea that you've got all these different sources and all these different targets",
    "start": "972279",
    "end": "978040"
  },
  {
    "text": "right and the first extract is is a highly optimized extract it sets it up",
    "start": "978040",
    "end": "983560"
  },
  {
    "text": "to partition the threads and all the different aspects of of heavy duty loading that's also very very important",
    "start": "983560",
    "end": "989470"
  },
  {
    "text": "when you think about moving to the cloud there's also the aspect of how it moves to the cloud when it's moves to like an",
    "start": "989470",
    "end": "995949"
  },
  {
    "text": "s3 it's moving in memory and when it moves in memory in that persistent store it's also encrypted and managed entirely",
    "start": "995949",
    "end": "1003360"
  },
  {
    "text": "by the application so that's our assurance of security and and that's",
    "start": "1003360",
    "end": "1008730"
  },
  {
    "text": "also your assurance that we know what we're doing because it goes across web traffic right and we're hosting and",
    "start": "1008730",
    "end": "1015420"
  },
  {
    "text": "managing a lot of that security in that consideration for you huge opportunity and a huge win for both",
    "start": "1015420",
    "end": "1020639"
  },
  {
    "text": "sides this also means that there's the idea that you want to remove certain",
    "start": "1020639",
    "end": "1025860"
  },
  {
    "text": "data PII information encrypted all these different scenarios that you'd want to be able to do that's part of that",
    "start": "1025860",
    "end": "1031168"
  },
  {
    "text": "transformation there's also the ability to enrich like fill in zeros or null fields those type of things easy to do",
    "start": "1031169",
    "end": "1036900"
  },
  {
    "text": "as well but we what we are not is an ETL tool upstream after this if you're",
    "start": "1036900",
    "end": "1042720"
  },
  {
    "text": "looking at this you'd see glue and other ETL technologies but the fact that we've got everything in real time streaming",
    "start": "1042720",
    "end": "1048900"
  },
  {
    "text": "into your into your data Lake that gives you a very significant powerful opportunity to be able to do that and",
    "start": "1048900",
    "end": "1055290"
  },
  {
    "text": "I'm excited for fanatics to be able to share their story of how they worked with us and how how we've built some",
    "start": "1055290",
    "end": "1060809"
  },
  {
    "start": "1058000",
    "end": "1173000"
  },
  {
    "text": "very powerful solutions and what I want to do is get into all these different sources and targets and there's even",
    "start": "1060809",
    "end": "1067650"
  },
  {
    "text": "some conditions some details on how each one of these move data when you think about the considerations of a mainframe",
    "start": "1067650",
    "end": "1073470"
  },
  {
    "text": "this the db2 on the database side all those considerations of even further into the",
    "start": "1073470",
    "end": "1078600"
  },
  {
    "text": "right side so the left side I have some db2 but I also have mainframe on the on the right side so there's these legacy",
    "start": "1078600",
    "end": "1084450"
  },
  {
    "text": "platforms and ecosystems that are key and you can look at those there's also the aspect of s AP right well how do you",
    "start": "1084450",
    "end": "1091230"
  },
  {
    "text": "extract from s AP well we're actually doing that at the application layer so the Business Objects I'm not talking about their report tool from that comes",
    "start": "1091230",
    "end": "1097560"
  },
  {
    "text": "for the AP but the actual acronyms that you're used to using is a business user gets translated into s3 and that's",
    "start": "1097560",
    "end": "1104220"
  },
  {
    "text": "powerful so now that we've taken your legacy mainframe hooked in your s AP but",
    "start": "1104220",
    "end": "1109680"
  },
  {
    "text": "maybe you've got other applications are running on custom applications that you've built to run your business on sequel server oracle or Postgres or",
    "start": "1109680",
    "end": "1116370"
  },
  {
    "text": "however furthermore they could be running on RDS we could handle for that so RDS would be like a Postgres or",
    "start": "1116370",
    "end": "1123120"
  },
  {
    "text": "Washington my sequel and Aurora and the rest of those components you can pull and source to these other locations so",
    "start": "1123120",
    "end": "1130500"
  },
  {
    "text": "let's talk about the targets too so in the Amazon ecosystem you've got s3 and EMR and redshift and you even have RDS",
    "start": "1130500",
    "end": "1138270"
  },
  {
    "text": "we have applications customers that are running real-time reporting running on an RDS they're doing real-time when",
    "start": "1138270",
    "end": "1145410"
  },
  {
    "text": "doing on Kinesis but they're all dumping everything into that S 3 and then s3 is loading into redshift or they could load",
    "start": "1145410",
    "end": "1151590"
  },
  {
    "text": "into other platform partners like snowflake right there's even the opportunities in other use cases where",
    "start": "1151590",
    "end": "1156810"
  },
  {
    "text": "the data like vendors are all supporting s3 and like a Hortonworks caldera and they the files are stored in s3 so lots",
    "start": "1156810",
    "end": "1163260"
  },
  {
    "text": "of different ways you could have to work within the overall ecosystem and a very partner friendly but also very flexible",
    "start": "1163260",
    "end": "1169700"
  },
  {
    "text": "ecosystem within the Amazon ecosystem and tools so that's always key what I'm",
    "start": "1169700",
    "end": "1176160"
  },
  {
    "start": "1173000",
    "end": "1464000"
  },
  {
    "text": "going to do is I'm going to pass it over to our fanatics friends and I don't take",
    "start": "1176160",
    "end": "1181320"
  },
  {
    "text": "it away all right Jordan thank you thank you",
    "start": "1181320",
    "end": "1188150"
  },
  {
    "text": "very much and welcome everybody today I'm going to cover a few key points in",
    "start": "1188150",
    "end": "1195290"
  },
  {
    "text": "my section of the presentation first what I'd like to do is give an introduction to everybody on the call",
    "start": "1195290",
    "end": "1200720"
  },
  {
    "text": "about fanatics then talk about why data is important to our organization how are you sir to natee and then close",
    "start": "1200720",
    "end": "1207890"
  },
  {
    "text": "up with close with some best practices that we've discovered in using affinity",
    "start": "1207890",
    "end": "1212960"
  },
  {
    "text": "with AWS so first of all regarding",
    "start": "1212960",
    "end": "1228620"
  },
  {
    "text": "fanatics we are the number one retailer of lettuce and sports merchandise and we some of you may have known or may not",
    "start": "1228620",
    "end": "1235370"
  },
  {
    "text": "know we started off as a mall store in Jacksonville Florida in 1997 when the",
    "start": "1235370",
    "end": "1240679"
  },
  {
    "text": "Jacksonville Jaguars or an expansion franchise in the NFL and over time we",
    "start": "1240679",
    "end": "1248510"
  },
  {
    "text": "have grown to over two billion in sales through the multi-crew online and I'll",
    "start": "1248510",
    "end": "1254090"
  },
  {
    "text": "talk a little more about offline with through our global partners with our league and team partnerships and now",
    "start": "1254090",
    "end": "1260510"
  },
  {
    "text": "today we run the official league stores for the NHL the NBA the NFL and Major",
    "start": "1260510",
    "end": "1266690"
  },
  {
    "text": "League Baseball these partnerships allow us not only to drive the technology that",
    "start": "1266690",
    "end": "1275090"
  },
  {
    "text": "runs their league sites but also engage engage in vertical ization and with the",
    "start": "1275090",
    "end": "1281120"
  },
  {
    "text": "rights to produce what we sell as I mentioned initially we were the you",
    "start": "1281120",
    "end": "1286429"
  },
  {
    "text": "know we were the number one retailer licensed sports merchandise but now we are also moving into manufacturing and",
    "start": "1286429",
    "end": "1292190"
  },
  {
    "text": "fanatics branded products this is important to us because in sports the we",
    "start": "1292190",
    "end": "1299660"
  },
  {
    "text": "have what we call the hot markets that is the championship events such as the Super Bowl or the NBA Finals that drives",
    "start": "1299660",
    "end": "1306049"
  },
  {
    "text": "a large spike in in customer demand the morally important is the in season",
    "start": "1306049",
    "end": "1314390"
  },
  {
    "text": "spikes that are unpredictable and unscheduled a great a great player may trend during the",
    "start": "1314390",
    "end": "1319800"
  },
  {
    "text": "season suddenly make the highlight reel on SportsCenter and interest in that player who nobody knew at the beginning",
    "start": "1319800",
    "end": "1326280"
  },
  {
    "text": "the season has suddenly peaked and we want to be able to meet the customer with the right product at the right time",
    "start": "1326280",
    "end": "1333800"
  },
  {
    "text": "for those unpredicted spikes and the last thing last part of our business is",
    "start": "1333800",
    "end": "1341130"
  },
  {
    "text": "event retail I mentioned that we've started off as a mall store in 97 over",
    "start": "1341130",
    "end": "1347430"
  },
  {
    "text": "20 years ago and I've moved to the move to the web with e-commerce but that's",
    "start": "1347430",
    "end": "1353190"
  },
  {
    "text": "come full circle now as we also have in venue locations places such as the MBA",
    "start": "1353190",
    "end": "1359310"
  },
  {
    "text": "store on Fifth Avenue trackside and NASCAR as well as a Kentucky Derby so",
    "start": "1359310",
    "end": "1369720"
  },
  {
    "text": "like I said you know be we have we're multifaceted capabilities or more than just a website in addition to jerseys",
    "start": "1369720",
    "end": "1378540"
  },
  {
    "text": "and apparel that are licensed from the teams we are also the largest seller of sports memorabilia this is you know the",
    "start": "1378540",
    "end": "1386100"
  },
  {
    "text": "limited-edition game used products as",
    "start": "1386100",
    "end": "1391740"
  },
  {
    "text": "well as you know partners with specific athletes such as Erin judge the New York Yankees where we can provide fanatics",
    "start": "1391740",
    "end": "1398820"
  },
  {
    "text": "customers with a unique experience for a really limited release licensed products",
    "start": "1398820",
    "end": "1408470"
  },
  {
    "text": "so you can see here with all you know the logos are of our partners from college teams pro teams the professional",
    "start": "1411830",
    "end": "1420600"
  },
  {
    "text": "leagues as well as you know college sports conferences so you can see here",
    "start": "1420600",
    "end": "1427200"
  },
  {
    "text": "that you've probably done business with us even if you didn't didn't know it before this call with the partnerships",
    "start": "1427200",
    "end": "1434010"
  },
  {
    "text": "that we run likes in the league stores as well as many other teams so with all",
    "start": "1434010",
    "end": "1440040"
  },
  {
    "text": "the diverse destinations of the net of fanatics it's more than just a website is a fanatics experience - from product",
    "start": "1440040",
    "end": "1448020"
  },
  {
    "text": "discovery product purchase to product fulfillment it is a you know customer life journey and as we get into",
    "start": "1448020",
    "end": "1455310"
  },
  {
    "text": "the the technical piece next I'll show you how the data that we the data that",
    "start": "1455310",
    "end": "1462780"
  },
  {
    "text": "we need to run our business so for all I've described between online offline",
    "start": "1462780",
    "end": "1467840"
  },
  {
    "start": "1464000",
    "end": "1621000"
  },
  {
    "text": "hot markets spikes and traffic spikes and demand data is very important for us",
    "start": "1467840",
    "end": "1472920"
  },
  {
    "text": "to execute on this vision of being there for the customer journey providing that fanatics experience and being at",
    "start": "1472920",
    "end": "1480480"
  },
  {
    "text": "customer centric from product discovery to product purchased through fulfillment as well as customer service and returns",
    "start": "1480480",
    "end": "1488030"
  },
  {
    "text": "so why is data important to us we'll go into a little bit of these in detail right now we have we have e-commerce as",
    "start": "1488030",
    "end": "1495630"
  },
  {
    "text": "well as offline venues so being able to merge online and offline data this is you know that's a omni-channel so it's",
    "start": "1495630",
    "end": "1502110"
  },
  {
    "text": "not just brick-and-mortar it's not just the web but it's it's everything in between I can mention the dynamic nature",
    "start": "1502110",
    "end": "1508860"
  },
  {
    "text": "the sports business means that we have to be able to form to some extent forecast based on previous championship",
    "start": "1508860",
    "end": "1517590"
  },
  {
    "text": "events but then also you know be sure we have the right product at the right time to handle those unexpected spikes not",
    "start": "1517590",
    "end": "1526410"
  },
  {
    "text": "all you know the highlight reel does not run on a calendar so when we look at",
    "start": "1526410",
    "end": "1531420"
  },
  {
    "text": "these data use cases you know business intelligence insights including real-time analytics right after the hot market or on Cyber Monday",
    "start": "1531420",
    "end": "1537840"
  },
  {
    "text": "Black Friday making sure that the you know is the business running according to plan are they're unpredictable other",
    "start": "1537840",
    "end": "1546560"
  },
  {
    "text": "spikes or an maybe some a lull that needs to be addressed on the user",
    "start": "1546560",
    "end": "1555060"
  },
  {
    "text": "experiences on the Site Search personalization shipping delivery experimentation making sure we have the",
    "start": "1555060",
    "end": "1560100"
  },
  {
    "text": "right data so that our marketing and product teams can make the right customer experiences to create that",
    "start": "1560100",
    "end": "1568380"
  },
  {
    "text": "engagement paid marketing as online traffic becomes more saturated and more",
    "start": "1568380",
    "end": "1577410"
  },
  {
    "text": "competitive we'll make sure that we are bidding efficiently driving the right",
    "start": "1577410",
    "end": "1583740"
  },
  {
    "text": "traffic at the right time to the right landing pages to make sure getting the correct ROI now for our",
    "start": "1583740",
    "end": "1588910"
  },
  {
    "text": "marketing pricing and promotions what price to offer when to start a",
    "start": "1588910",
    "end": "1594520"
  },
  {
    "text": "promotion when to end a promotion what to make the offer who to offer it to those are all important data pieces and",
    "start": "1594520",
    "end": "1602380"
  },
  {
    "text": "then merchandising and planning you know that's inventory management from both inbound when to buy how much to buy when",
    "start": "1602380",
    "end": "1609040"
  },
  {
    "text": "to discount when to push on clearance when not to where should the inventory be within the network of fulfillment",
    "start": "1609040",
    "end": "1616510"
  },
  {
    "text": "centers all of those pieces are driven by data from various sources and so when",
    "start": "1616510",
    "end": "1622150"
  },
  {
    "start": "1621000",
    "end": "1771000"
  },
  {
    "text": "good and next slide here this is the challenge that we're dealing with we have a variety of apps with our",
    "start": "1622150",
    "end": "1627790"
  },
  {
    "text": "homegrown databases purchased databases",
    "start": "1627790",
    "end": "1635200"
  },
  {
    "text": "from vendors are we using sequel server oracle Postgres my sequel so how do we",
    "start": "1635200",
    "end": "1642910"
  },
  {
    "text": "move from the data islands to the data",
    "start": "1642910",
    "end": "1648130"
  },
  {
    "text": "Lake as Jordan was met Jordan and Paul were mentioning earlier position so we",
    "start": "1648130",
    "end": "1653710"
  },
  {
    "text": "main was to use a tunity with AWS Amazon s3 I want to talk a little bit about",
    "start": "1653710",
    "end": "1660130"
  },
  {
    "text": "sort of where we were in the past and just to make sure to kind of take us to",
    "start": "1660130",
    "end": "1665500"
  },
  {
    "text": "the presence right if you consider the legacy systems where people are querying",
    "start": "1665500",
    "end": "1671860"
  },
  {
    "text": "the database is right you have you run several risks the first of which is that",
    "start": "1671860",
    "end": "1677950"
  },
  {
    "text": "you are now having analytics and transactional transactions running on the same databases too many people query",
    "start": "1677950",
    "end": "1684910"
  },
  {
    "text": "it then the database can lock up and you could possibly stop taking orders right",
    "start": "1684910",
    "end": "1690160"
  },
  {
    "text": "this is definitely not good especially during peak times the peak times are when most people are interested in",
    "start": "1690160",
    "end": "1695740"
  },
  {
    "text": "seeing how the data is doing so sure the first thing you can do is you can separate this you can create replication",
    "start": "1695740",
    "end": "1703110"
  },
  {
    "text": "make have the analytics queries run on a separate replicated cluster from the",
    "start": "1703110",
    "end": "1710440"
  },
  {
    "text": "transactional queries okay so at least you can separate you can separate those two pieces however you still run to the",
    "start": "1710440",
    "end": "1715810"
  },
  {
    "text": "challenge there that again if you have contention right if too many people are the data database at the same time that",
    "start": "1715810",
    "end": "1723310"
  },
  {
    "text": "Davis locks up and then nobody can do any work what s3 allows is two important things",
    "start": "1723310",
    "end": "1729010"
  },
  {
    "text": "first of all by putting all the data from different sources on to s3 you can",
    "start": "1729010",
    "end": "1735700"
  },
  {
    "text": "bring data from different databases database systems database clusters into",
    "start": "1735700",
    "end": "1741730"
  },
  {
    "text": "one place you can now join across databases effectively second of all",
    "start": "1741730",
    "end": "1748170"
  },
  {
    "text": "because s3 is a phase a file system each",
    "start": "1748170",
    "end": "1756130"
  },
  {
    "text": "person can read the file separately without contention you can have different clusters that read the file",
    "start": "1756130",
    "end": "1761470"
  },
  {
    "text": "and so one person's query does not block another person's query this protects",
    "start": "1761470",
    "end": "1767680"
  },
  {
    "text": "users from each other's and allows for multiple subscribers to the same data set so our solutions specifically here",
    "start": "1767680",
    "end": "1777400"
  },
  {
    "start": "1771000",
    "end": "1877000"
  },
  {
    "text": "with AWS opportunity in our current state we have the oppertunity software",
    "start": "1777400",
    "end": "1785400"
  },
  {
    "text": "installed on premise in a in a in physical Hardware appointee to our",
    "start": "1785400",
    "end": "1791830"
  },
  {
    "text": "on-premise databases the workflow right now is that there are two main data",
    "start": "1791830",
    "end": "1799030"
  },
  {
    "text": "customers that we have or two customers are interested in consuming the data in two key ways either they are interested",
    "start": "1799030",
    "end": "1806200"
  },
  {
    "text": "in the change logs because they want to know how a field in a database has",
    "start": "1806200",
    "end": "1811960"
  },
  {
    "text": "changed over time or there are other customers of ours who are interested in",
    "start": "1811960",
    "end": "1818470"
  },
  {
    "text": "running batch jobs and so they they want to know what the database table look",
    "start": "1818470",
    "end": "1825070"
  },
  {
    "text": "like at a certain period of time it depends on the latency of the business departments so we produce two outputs",
    "start": "1825070",
    "end": "1832360"
  },
  {
    "text": "one is we can produce change logs for a database that customers can subscribe to",
    "start": "1832360",
    "end": "1839500"
  },
  {
    "text": "our data internal data customers can subscribe to so they can read the change log and run their applications",
    "start": "1839500",
    "end": "1844600"
  },
  {
    "text": "accordingly or they can subscribe to the current view which is basically a",
    "start": "1844600",
    "end": "1850300"
  },
  {
    "text": "snapshot that runs either hourly or daily and read that for their batch process so",
    "start": "1850300",
    "end": "1856450"
  },
  {
    "text": "right now we are micro batching where we opportunity sends to s3 in our settings",
    "start": "1856450",
    "end": "1863620"
  },
  {
    "text": "all the change logs every 15 minutes because that's based on what the",
    "start": "1863620",
    "end": "1868630"
  },
  {
    "text": "customers data needs have been for now and then we process those and build",
    "start": "1868630",
    "end": "1874560"
  },
  {
    "text": "current views in the future we're doing several things that were looking at and",
    "start": "1874560",
    "end": "1881770"
  },
  {
    "start": "1877000",
    "end": "1950000"
  },
  {
    "text": "have been in the process of developing one is moving acuity instilling argue",
    "start": "1881770",
    "end": "1887230"
  },
  {
    "text": "the installation into the cloud into AWS this was we're moving this way because",
    "start": "1887230",
    "end": "1895120"
  },
  {
    "text": "the data customers and the team that's processing the data is more familiar with AWS",
    "start": "1895120",
    "end": "1901210"
  },
  {
    "text": "applications so it makes sense to move the Eternity replication piece to the",
    "start": "1901210",
    "end": "1907270"
  },
  {
    "text": "cloud as well this is important and I'll touch on this more during the best",
    "start": "1907270",
    "end": "1912400"
  },
  {
    "text": "practices as to why we move this the cloud it's actually it's partially",
    "start": "1912400",
    "end": "1919330"
  },
  {
    "text": "organizational with having the data platforms team and the team responsible",
    "start": "1919330",
    "end": "1924850"
  },
  {
    "text": "for tunity being in the same group the second AVI benefit of moving at unity to",
    "start": "1924850",
    "end": "1931660"
  },
  {
    "text": "the cloud is a freeze up Hardware opportunity is currently installed on physical machines in our data center by",
    "start": "1931660",
    "end": "1938440"
  },
  {
    "text": "moving into the cloud it frees up that hardware to be repurpose salvaged",
    "start": "1938440",
    "end": "1946200"
  },
  {
    "text": "another feature state which we are exploring is ingesting data through",
    "start": "1948390",
    "end": "1957370"
  },
  {
    "start": "1950000",
    "end": "2025000"
  },
  {
    "text": "Kafka or pushing data to Kafka as I mentioned in the previous couple slides ago we're currently micro batching every",
    "start": "1957370",
    "end": "1964750"
  },
  {
    "text": "15 minutes and that's good enough right now for most of our data customers however if data customers are interested",
    "start": "1964750",
    "end": "1972490"
  },
  {
    "text": "in reading it changes more frequently than that we can push change logs to",
    "start": "1972490",
    "end": "1979000"
  },
  {
    "text": "Kafka as well and that way the data customers can ingest a stream of data",
    "start": "1979000",
    "end": "1984990"
  },
  {
    "text": "for the tables or databases that they're interested in and they can see every changelog come in",
    "start": "1984990",
    "end": "1993170"
  },
  {
    "text": "as a unique message and then process those as needed additionally this allows",
    "start": "1993170",
    "end": "2001390"
  },
  {
    "text": "for compaction so right in the previous model we have pushed data every 15",
    "start": "2001390",
    "end": "2008320"
  },
  {
    "text": "minutes and so there's files cut at that frequency by pushing data here through",
    "start": "2008320",
    "end": "2014200"
  },
  {
    "text": "the Kafka stream the date they afterwards right you can what you're",
    "start": "2014200",
    "end": "2020980"
  },
  {
    "text": "interested in you can put that into a file later if you want so onto",
    "start": "2020980",
    "end": "2030690"
  },
  {
    "start": "2025000",
    "end": "2258000"
  },
  {
    "text": "lessons learned and these three best practices as a preface dovetail with",
    "start": "2030690",
    "end": "2035730"
  },
  {
    "text": "each other outs of splitting hell the first is that the Eternity installation",
    "start": "2035730",
    "end": "2041220"
  },
  {
    "text": "and data cos consumption owned by the same team in the past the our database",
    "start": "2041220",
    "end": "2049919"
  },
  {
    "text": "administrators who maintained the on-premise application database just",
    "start": "2049920",
    "end": "2055050"
  },
  {
    "text": "were involved in the ingenuity installation and a tunity replicate maintenance piece and this work this",
    "start": "2055050",
    "end": "2063750"
  },
  {
    "text": "makes sense when the in 20 V was installed on premise however now what",
    "start": "2063750",
    "end": "2069149"
  },
  {
    "text": "happened was the data producers effect like he'slooking from the Eternity piece the Eternity is producing change log",
    "start": "2069150",
    "end": "2076830"
  },
  {
    "text": "data and the data consumer the data teams are interested in consuming it and",
    "start": "2076830",
    "end": "2084530"
  },
  {
    "text": "reading the change logs or reading the current views we're now on separate",
    "start": "2084530",
    "end": "2090570"
  },
  {
    "text": "teams the data platform scene was in the middle that involved that helped you know publish this data to our data",
    "start": "2090570",
    "end": "2097110"
  },
  {
    "text": "scientists and that was a separate team from the Tina's involved in the installation and maintenance of a tunity",
    "start": "2097110",
    "end": "2104000"
  },
  {
    "text": "this led to sort of separate the concerns and by having the data",
    "start": "2104000",
    "end": "2111600"
  },
  {
    "text": "platforms team involved in the installation and loading of the tables",
    "start": "2111600",
    "end": "2116880"
  },
  {
    "text": "opportunity that allows for more end-to-end visibility to",
    "start": "2116880",
    "end": "2122900"
  },
  {
    "text": "that eternity the to me file was conceived assuming the software was configured to output was the most",
    "start": "2123900",
    "end": "2129990"
  },
  {
    "text": "efficient for consumption on the data on the data platforms ingest and so to the",
    "start": "2129990",
    "end": "2136860"
  },
  {
    "text": "extent possible you can make these two [Music] under the same organization and sort of",
    "start": "2136860",
    "end": "2144390"
  },
  {
    "text": "within the same team or pod that will allow for more efficiency in operations",
    "start": "2144390",
    "end": "2150740"
  },
  {
    "text": "the second piece is correctly understanding the data frequency requirements as Jordan noted right the",
    "start": "2150740",
    "end": "2159600"
  },
  {
    "text": "acuity does allow for real-time change Lodz and see the data in real-time",
    "start": "2159600",
    "end": "2166100"
  },
  {
    "text": "however make sure that that is what your business team needs because if you cut",
    "start": "2166100",
    "end": "2178140"
  },
  {
    "text": "your files too frequently you'll end up in the third problem which is that the trader understand the trade-off between",
    "start": "2178140",
    "end": "2183660"
  },
  {
    "text": "file size and file i/o operations depending on what you need right you it",
    "start": "2183660",
    "end": "2189750"
  },
  {
    "text": "may be more efficient to read a few large files then a lot of small files especially depending on what processes",
    "start": "2189750",
    "end": "2196320"
  },
  {
    "text": "you're using to read the data and so you want to make sure that you're not",
    "start": "2196320",
    "end": "2201420"
  },
  {
    "text": "pushing too many small files when did if the business is I wouldn't need to data updated every 30 minutes",
    "start": "2201420",
    "end": "2207870"
  },
  {
    "text": "depending on again depending on what you're using the process for if you're trying to build a real-time dashboard",
    "start": "2207870",
    "end": "2213960"
  },
  {
    "text": "for sure cut more frequent files maybe use a conflict connector but if you're",
    "start": "2213960",
    "end": "2218970"
  },
  {
    "text": "doing things you know like daily warehouse plant resource planning or",
    "start": "2218970",
    "end": "2224190"
  },
  {
    "text": "something like that that even if you had the information you couldn't affect anything material until it was on a",
    "start": "2224190",
    "end": "2230760"
  },
  {
    "text": "daily basis then maybe set you know sanity doesn't change that often set",
    "start": "2230760",
    "end": "2235890"
  },
  {
    "text": "your parameters accordingly to make it the most efficient for your specific use",
    "start": "2235890",
    "end": "2241230"
  },
  {
    "text": "case and you can have multiple use cases within your organization or even within an application petunia allows that",
    "start": "2241230",
    "end": "2247230"
  },
  {
    "text": "flexibility and just make sure that you use it just make the tool suit you",
    "start": "2247230",
    "end": "2257569"
  },
  {
    "text": "because the tunity has that flexibility for you so the key takeaways here are that you know phonetics chose AWS for",
    "start": "2257569",
    "end": "2265230"
  },
  {
    "start": "2258000",
    "end": "2303000"
  },
  {
    "text": "its multiple data platforms it's applications which that Paul showed",
    "start": "2265230",
    "end": "2272160"
  },
  {
    "text": "earlier from s3 redshift Athena allowing",
    "start": "2272160",
    "end": "2277800"
  },
  {
    "text": "that those flexibility of tools available in AWS is why we chose to go with Amazon Web Services and we chose a",
    "start": "2277800",
    "end": "2284700"
  },
  {
    "text": "tunity due to its easy connection to a variety of data sources I can show you whether it be Postgres my sequel Oracle",
    "start": "2284700",
    "end": "2291690"
  },
  {
    "text": "and especially now with the latest version opportunity the UI has become",
    "start": "2291690",
    "end": "2296970"
  },
  {
    "text": "even more user friendly and with that I'll turn it back over to Paul Thank You",
    "start": "2296970",
    "end": "2304470"
  },
  {
    "start": "2303000",
    "end": "2493000"
  },
  {
    "text": "Alan I appreciate this okay so we have time now for some questions and answers but before I do that I like to remind",
    "start": "2304470",
    "end": "2311520"
  },
  {
    "text": "all the attendees that the PowerPoint presentation will be available through SlideShare along with recording of the",
    "start": "2311520",
    "end": "2318510"
  },
  {
    "text": "webinar we posted on YouTube and you will receive an email that will be sent two or three days after the conclusion",
    "start": "2318510",
    "end": "2324150"
  },
  {
    "text": "of this event so when you get the information that email it will have information the links to get the slides",
    "start": "2324150",
    "end": "2329609"
  },
  {
    "text": "and to view the actual recording on YouTube I also would like to remind",
    "start": "2329609",
    "end": "2335339"
  },
  {
    "text": "everybody to please remain connected after the webinar ends and complete the",
    "start": "2335339",
    "end": "2341700"
  },
  {
    "text": "brief survey at the conclusion your feedback is very important to us and so that that's really important that you",
    "start": "2341700",
    "end": "2348480"
  },
  {
    "text": "actually submit those that feedback into that survey so I'm gonna go and handle",
    "start": "2348480",
    "end": "2353579"
  },
  {
    "text": "some questions now we have a number of questions came in around data lakes and tunity and file formats somewhere",
    "start": "2353579",
    "end": "2359790"
  },
  {
    "text": "similar I'm gonna kind of group them together so I'm gonna direct this towards Jordan and kind of summarizing",
    "start": "2359790",
    "end": "2367910"
  },
  {
    "text": "what does a tunity off support in terms of how do you what file formats",
    "start": "2367910",
    "end": "2374550"
  },
  {
    "text": "this is support how do you deal with metadata is there automation for metadata and data lineage all those",
    "start": "2374550",
    "end": "2382670"
  },
  {
    "text": "things that you can do with eternity and if so how would you do how would you do that absolutely a great question so we",
    "start": "2382670",
    "end": "2389609"
  },
  {
    "text": "support file types are in memory file lands into s3 in memory so it's actually really powerful",
    "start": "2389609",
    "end": "2395190"
  },
  {
    "text": "for being able to overwrite file types like a park a file which is one of the",
    "start": "2395190",
    "end": "2400260"
  },
  {
    "text": "file types that you often see but we also support Avro and JSON formats if you really want to store it and CSV you",
    "start": "2400260",
    "end": "2406770"
  },
  {
    "text": "can do it already text file but like all of the aspects of when you overwrite these files requires you to have a",
    "start": "2406770",
    "end": "2413400"
  },
  {
    "text": "header information - that not only like the detail the header but in the landing detail so that there's also these",
    "start": "2413400",
    "end": "2419490"
  },
  {
    "text": "secondary file types and also the we can add these other sets of files called",
    "start": "2419490",
    "end": "2425610"
  },
  {
    "text": "change tracking and audit tables which are part of the overall ecosystem of compliance let's say you're going to run",
    "start": "2425610",
    "end": "2431700"
  },
  {
    "text": "a spark EMR operation that would then come off and give you that replay reel",
    "start": "2431700",
    "end": "2437010"
  },
  {
    "text": "of all the transactions that came in whether it's a delete or some other format of that concept and what you're",
    "start": "2437010",
    "end": "2444240"
  },
  {
    "text": "doing is you've got the ability with them with replicate to then also generate those hive statements entirely",
    "start": "2444240",
    "end": "2450930"
  },
  {
    "text": "using our compose product so the composed product works a lot of metadata and governance tools if it's a data Lake",
    "start": "2450930",
    "end": "2457440"
  },
  {
    "text": "you can load into Atlas our metadata is arrest full integration so you can pull",
    "start": "2457440",
    "end": "2463230"
  },
  {
    "text": "into a data catalog on the Amazon side so that all the questions the answer is yes to everything but I wanted to at",
    "start": "2463230",
    "end": "2469170"
  },
  {
    "text": "least give you some of those details if you have more questions just throw it in the throw in the chat and happy to",
    "start": "2469170",
    "end": "2474930"
  },
  {
    "text": "answer more ok thank you for that Jordan",
    "start": "2474930",
    "end": "2480000"
  },
  {
    "text": "I'm going to go ahead and throw a question towards Alan now there's some interest in how you plan on leveraging",
    "start": "2480000",
    "end": "2485490"
  },
  {
    "text": "Kafka and what might be some of the trade-offs you have using Kafka sure so",
    "start": "2485490",
    "end": "2494850"
  },
  {
    "start": "2493000",
    "end": "2588000"
  },
  {
    "text": "we're still in our early phases of you know exploring how data cost our teams",
    "start": "2494850",
    "end": "2501300"
  },
  {
    "text": "could use the Akaka stream I think you",
    "start": "2501300",
    "end": "2507000"
  },
  {
    "text": "know comment possible applications are with personalization on the site you",
    "start": "2507000",
    "end": "2516120"
  },
  {
    "text": "know potentially email marketing you know as does the data comes in with our",
    "start": "2516120",
    "end": "2522080"
  },
  {
    "text": "you know product change product pricing changes to lustre no Haiti a new product maybe on maybe on",
    "start": "2522080",
    "end": "2530339"
  },
  {
    "text": "promotion etc I think that challenge with Kafka one of the potential",
    "start": "2530339",
    "end": "2536760"
  },
  {
    "text": "challenges right is that the Kafka model is one producer and then each concession",
    "start": "2536760",
    "end": "2545040"
  },
  {
    "text": "responsible for writing their own consumers so I think that there's that knowledge that needs to be sort of you",
    "start": "2545040",
    "end": "2554099"
  },
  {
    "text": "know well democratized or each individual team used to come up to speed on you know how to use the Kafka",
    "start": "2554099",
    "end": "2561720"
  },
  {
    "text": "consumers in the way specific for their applications as opposed to you know pushing the data you know to an endpoint",
    "start": "2561720",
    "end": "2569339"
  },
  {
    "text": "for them okay I think this is also a related question is that maybe for you",
    "start": "2569339",
    "end": "2575910"
  },
  {
    "text": "Alan is that is what is the benefit of batching your changelogs versus getting",
    "start": "2575910",
    "end": "2580950"
  },
  {
    "text": "data in real time since we're kind of talking around Kafka and streaming and such yeah so I think this it the",
    "start": "2580950",
    "end": "2590849"
  },
  {
    "text": "benefits of batching is that if you and again this is very application and use",
    "start": "2590849",
    "end": "2596730"
  },
  {
    "text": "case specific if your process is only gonna run every three hours for whatever",
    "start": "2596730",
    "end": "2604530"
  },
  {
    "text": "reason again it depends this is a you know if there's a use case where you only need the data in a certain period of time right you use the batch of the",
    "start": "2604530",
    "end": "2614609"
  },
  {
    "text": "data should match the frequency of its use so that you can just these you don't",
    "start": "2614609",
    "end": "2620880"
  },
  {
    "text": "just start up the cluster or keep it on all the time when most of time is gonna be idle so you just kind of mash the",
    "start": "2620880",
    "end": "2627060"
  },
  {
    "text": "mash data supply if you will with data demand if you stream all the data",
    "start": "2627060",
    "end": "2632579"
  },
  {
    "text": "through or you cut small files then we've noticed in cases of smart",
    "start": "2632579",
    "end": "2638160"
  },
  {
    "text": "sometimes you end up with having to read through a lot of small files which can",
    "start": "2638160",
    "end": "2644730"
  },
  {
    "text": "take the process to run longer than if the file had just been one big file okay",
    "start": "2644730",
    "end": "2650310"
  },
  {
    "text": "thank you so this is gonna be for Jordan eternity those questions around",
    "start": "2650310",
    "end": "2656359"
  },
  {
    "text": "basically how how will there be any downtown",
    "start": "2656359",
    "end": "2662440"
  },
  {
    "text": "experience when you move data on premises environments into AWS cloud",
    "start": "2662440",
    "end": "2668170"
  },
  {
    "text": "using a 20 replicate and also you know how long is it is there latency involved",
    "start": "2668170",
    "end": "2673510"
  },
  {
    "text": "what does it take to move all the data or from or import your on-premises into AWS yeah so this is one of the benefits",
    "start": "2673510",
    "end": "2681610"
  },
  {
    "start": "2678000",
    "end": "2778000"
  },
  {
    "text": "of why why replicate is the caching mechanisms that are built into that intermediate zone we were talking about",
    "start": "2681610",
    "end": "2687640"
  },
  {
    "text": "the persistence zone and this is one of those fundamentally important things so the reason you use the CDC tool is to",
    "start": "2687640",
    "end": "2693760"
  },
  {
    "text": "not impact the source operations so as your is it captures I could commit the",
    "start": "2693760",
    "end": "2699760"
  },
  {
    "text": "the database goes the records go into the database on the transaction side but let's say you want to read them for",
    "start": "2699760",
    "end": "2705070"
  },
  {
    "text": "analytics you need to move them somewhere else so as you're moving them somewhere else the ability to capture them very efficiently and do it in a",
    "start": "2705070",
    "end": "2711880"
  },
  {
    "text": "trickle right think of like water flowing versus like picking up a bucket one at a time its water flowing down a",
    "start": "2711880",
    "end": "2718330"
  },
  {
    "text": "tube it's much more efficient way of processing information so as you're looking at it from the downtime let's",
    "start": "2718330",
    "end": "2724660"
  },
  {
    "text": "say that source system goes down the transactions go down so well replicates still listening and it's it's doing that",
    "start": "2724660",
    "end": "2731230"
  },
  {
    "text": "whole kid in the backseat are you there yet and what should what it's doing is it's making sure that you can capture the the records as there as there as the",
    "start": "2731230",
    "end": "2740200"
  },
  {
    "text": "thing comes back up there may have been a cache of records that come churning in that must be able to be collected and",
    "start": "2740200",
    "end": "2746080"
  },
  {
    "text": "understood even if there's a backup let's say that a backup occurred while it was down um you could also recover",
    "start": "2746080",
    "end": "2752380"
  },
  {
    "text": "from the backup so that gives you a lot of flexibility to be able to do point time recovery as well so lots of",
    "start": "2752380",
    "end": "2757690"
  },
  {
    "text": "flexibility and inherent understanding of the problem are built into the tool",
    "start": "2757690",
    "end": "2762810"
  },
  {
    "text": "okay and you use the term CDC which change data capture what well basically",
    "start": "2762810",
    "end": "2770380"
  },
  {
    "text": "what do you support in terms of sources and and such for using CDC technology so",
    "start": "2770380",
    "end": "2778030"
  },
  {
    "start": "2778000",
    "end": "2903000"
  },
  {
    "text": "a lot of those databases that were on that sources slide when you if we were to go back to our section and we'll be",
    "start": "2778030",
    "end": "2783520"
  },
  {
    "text": "distributing those there's all the major relational databases the ones that are the primary you know 99% of the",
    "start": "2783520",
    "end": "2790450"
  },
  {
    "text": "databases are our Oracle and sequel and Postgres in my sequel a lot of use cases in that relational world",
    "start": "2790450",
    "end": "2797680"
  },
  {
    "text": "that's where CDC fits any database that has a transaction log we capture it so",
    "start": "2797680",
    "end": "2802870"
  },
  {
    "text": "um 40 different sources I think is the is the current listing so that's part of",
    "start": "2802870",
    "end": "2808120"
  },
  {
    "text": "the core of that value proposition okay great I there's a few questions came in around",
    "start": "2808120",
    "end": "2814360"
  },
  {
    "text": "specifically how you do data lace and that's three in terms of how you structure your data like so I'm gonna go",
    "start": "2814360",
    "end": "2819490"
  },
  {
    "text": "ahead and kind of take a a stab at this it's really the question was how do you",
    "start": "2819490",
    "end": "2824890"
  },
  {
    "text": "structure your data on s3 for data Lake do you split it in a row or curated zones and it really comes down to the",
    "start": "2824890",
    "end": "2830890"
  },
  {
    "text": "use case of your analytics processing what you need to do it's very common",
    "start": "2830890",
    "end": "2836380"
  },
  {
    "text": "pattern to have the raw data collected ingested and collected in the s3 and",
    "start": "2836380",
    "end": "2842380"
  },
  {
    "text": "then you would if you look at the member the pipeline that goes from ingestion to",
    "start": "2842380",
    "end": "2847930"
  },
  {
    "text": "store and then to annal analysis and processing at that point there you may",
    "start": "2847930",
    "end": "2853390"
  },
  {
    "text": "at when you when you have the the collected data on s3 you then may process it or analyze it and reprocess",
    "start": "2853390",
    "end": "2860110"
  },
  {
    "text": "it and distill it down into other kinds of data and you would then we typically redeposit that data back into s3 as well",
    "start": "2860110",
    "end": "2867220"
  },
  {
    "text": "maybe into another bucket or something and or however you organize your data your data like but the advantage of that",
    "start": "2867220",
    "end": "2873610"
  },
  {
    "text": "is that all your data lives in the same fundamental location and you can mix your structure and I don't structure",
    "start": "2873610",
    "end": "2879370"
  },
  {
    "text": "data but it really depends on on what your consumers are expecting and what and how you want to analyze the data in",
    "start": "2879370",
    "end": "2885310"
  },
  {
    "text": "that data like how depends on how you structure it so I let's see here I think",
    "start": "2885310",
    "end": "2891610"
  },
  {
    "text": "another question for a tunity we have is how would I move data between eight of its regions if I have data in one",
    "start": "2891610",
    "end": "2897550"
  },
  {
    "text": "location and I want to move to another one how do I do that you Jordan I think",
    "start": "2897550",
    "end": "2904930"
  },
  {
    "start": "2903000",
    "end": "2973000"
  },
  {
    "text": "yep I was just coming off of mute so I'm gonna take a different source system so",
    "start": "2904930",
    "end": "2910810"
  },
  {
    "text": "you can migrate and batch from one s3 instance to another but also s3 has its own replication model for doing that as",
    "start": "2910810",
    "end": "2917470"
  },
  {
    "text": "well so if you're going across multiple regions we often replicate at the source so the source can read once and write",
    "start": "2917470",
    "end": "2924820"
  },
  {
    "text": "many and what looking at is being able to read from those sources and then being able to point them in two directions that's from",
    "start": "2924820",
    "end": "2931660"
  },
  {
    "text": "the same source that only extracted once very powerful technique and what that means is you can load both segments at",
    "start": "2931660",
    "end": "2938439"
  },
  {
    "text": "the same time and we often want to capture at the source and not when it gets to the target so you're not waiting",
    "start": "2938439",
    "end": "2943449"
  },
  {
    "text": "on the latency of the of the either one it's just the transport of getting it there so that's kind of our core",
    "start": "2943449",
    "end": "2948849"
  },
  {
    "text": "methodology for this thanks man okay some more question is actually for you Jordan so around the the CDC",
    "start": "2948849",
    "end": "2958439"
  },
  {
    "text": "basically what format does the CDC deliver data in and how do you process to get the current state do you need a",
    "start": "2958439",
    "end": "2965019"
  },
  {
    "text": "Davis engine on the engine side or are you pulling directly from the engines themselves at logs and those kind of",
    "start": "2965019",
    "end": "2970599"
  },
  {
    "text": "things well we're pulling from the logs if you",
    "start": "2970599",
    "end": "2976809"
  },
  {
    "start": "2973000",
    "end": "3093000"
  },
  {
    "text": "talk about the initial ingest the initial process is a full is actually can be partitioned and optimized for",
    "start": "2976809",
    "end": "2982859"
  },
  {
    "text": "extraction but it's really a full database extract so it does have a cost to it instead of having that low latency",
    "start": "2982859",
    "end": "2989529"
  },
  {
    "text": "extraction it's got a lot of it still has to do that initial load which irregardless is going to be something",
    "start": "2989529",
    "end": "2995289"
  },
  {
    "text": "you have to consider when you're doing this okay so but after after initial load and then the changes you capture",
    "start": "2995289",
    "end": "3001229"
  },
  {
    "text": "after logs as well that's correct yeah and it just it just runs yeah there's a",
    "start": "3001229",
    "end": "3007769"
  },
  {
    "text": "question around some governance and regulatory information so what what is",
    "start": "3007769",
    "end": "3013949"
  },
  {
    "text": "eternity do to provide things about auditing and and logging of the",
    "start": "3013949",
    "end": "3021239"
  },
  {
    "text": "activities are happening through replicate as well as is to do anything",
    "start": "3021239",
    "end": "3027209"
  },
  {
    "text": "and and in particular to ensure the data remain secure yes so underneath the",
    "start": "3027209",
    "end": "3035009"
  },
  {
    "text": "covers there's a couple of ways you can handle for security after it when it hits the target there's different vendors that you can work with that you",
    "start": "3035009",
    "end": "3040799"
  },
  {
    "text": "can help for the encryption like keys and then they can identify the PII informations and then encrypt that data",
    "start": "3040799",
    "end": "3046589"
  },
  {
    "text": "but while it's in transit it's already managed entirely by our compression and encryption technology that's part of our",
    "start": "3046589",
    "end": "3052679"
  },
  {
    "text": "file channel so that entirely keeps it managed in in in under the I guess the",
    "start": "3052679",
    "end": "3058049"
  },
  {
    "text": "domain of of eternities processing okay maybe",
    "start": "3058049",
    "end": "3063779"
  },
  {
    "text": "that's all that sure there was a question I saw for sanity here I mean",
    "start": "3063779",
    "end": "3070799"
  },
  {
    "text": "I'm sorry fanatics I'm trying to find it let's see here",
    "start": "3070799",
    "end": "3075900"
  },
  {
    "text": "a lot of questions came out was that in here so I'm a little behind on this let's see oh yeah so there's actually",
    "start": "3075900",
    "end": "3084359"
  },
  {
    "text": "question what BI tools as fine a use for the data sure so weak we currently use a",
    "start": "3084359",
    "end": "3094500"
  },
  {
    "start": "3093000",
    "end": "3270000"
  },
  {
    "text": "mixture of some homegrown reporting systems as well as tableau and MicroStrategy okay endear me any lessons",
    "start": "3094500",
    "end": "3104279"
  },
  {
    "text": "learn from from that that bi solution I",
    "start": "3104279",
    "end": "3109670"
  },
  {
    "text": "don't have anything to offer specifically at this time on the the the bi team I can find out but the the bi",
    "start": "3109670",
    "end": "3118049"
  },
  {
    "text": "team is one of many data customers for",
    "start": "3118049",
    "end": "3123270"
  },
  {
    "text": "us and they mostly consume the data in a batch format we have separate pipelines",
    "start": "3123270",
    "end": "3130200"
  },
  {
    "text": "for custom reporting for more real-time data sure okay actually one one final",
    "start": "3130200",
    "end": "3136980"
  },
  {
    "text": "question I have for eternity that came in was how does how does eternity handle",
    "start": "3136980",
    "end": "3143490"
  },
  {
    "text": "the updated data records s3 you",
    "start": "3143490",
    "end": "3149160"
  },
  {
    "text": "basically write a new record every time is that what attorney is doing when data comes in and updates a record is it",
    "start": "3149160",
    "end": "3154500"
  },
  {
    "text": "rewriting a new record or how you handling that Jordan are you still there",
    "start": "3154500",
    "end": "3167339"
  },
  {
    "text": "yeah I was talking into mute which is terrible sorry about that no can you repeat that again that was",
    "start": "3167339",
    "end": "3173430"
  },
  {
    "text": "this question around basically how you handle update to existing records that",
    "start": "3173430",
    "end": "3178799"
  },
  {
    "text": "are in s3 because s3 is I would see object based yeah yeah it doesn't",
    "start": "3178799",
    "end": "3184109"
  },
  {
    "text": "support the ability to append to an object so what do you what does it xx do and handle in a nice situation how does",
    "start": "3184109",
    "end": "3189480"
  },
  {
    "text": "it uni handle that well what does is it keeps metadata it overwrites the file being that's uh in memory",
    "start": "3189480",
    "end": "3197040"
  },
  {
    "text": "completely processes it okay okay I think that basically handles all most of",
    "start": "3197040",
    "end": "3203430"
  },
  {
    "text": "the questions that came in and so I'm gonna go ahead and wrap up this webinar",
    "start": "3203430",
    "end": "3209700"
  },
  {
    "text": "I do want to remind all the attendees that there are some we have some next",
    "start": "3209700",
    "end": "3217650"
  },
  {
    "text": "next steps information if you want to get a free trial with Trinity solutions there's a link there you can you can go to as well as learning more about the",
    "start": "3217650",
    "end": "3224400"
  },
  {
    "text": "solutions in AWS and learning more about fanatics as well and these slides as a reminder these slides will be",
    "start": "3224400",
    "end": "3230190"
  },
  {
    "text": "distributed in a couple days there'll be a link provided in an email to you that",
    "start": "3230190",
    "end": "3235440"
  },
  {
    "text": "will list where to download the slides and the YouTube video of the webinar and",
    "start": "3235440",
    "end": "3242280"
  },
  {
    "text": "also please remember to stay connected and complete the brief survey at the conclusion because we do need your",
    "start": "3242280",
    "end": "3250320"
  },
  {
    "text": "feedback is very important to us and we look forward to supporting you in your current and future projects and thank",
    "start": "3250320",
    "end": "3255450"
  },
  {
    "text": "you again everybody and have a good day thanks everybody thanks oh thanks",
    "start": "3255450",
    "end": "3263990"
  }
]
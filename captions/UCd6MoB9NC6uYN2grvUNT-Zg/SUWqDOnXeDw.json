[
  {
    "start": "0",
    "end": "288000"
  },
  {
    "text": "hey everyone good evening hear me again",
    "start": "890",
    "end": "7980"
  },
  {
    "text": "alright alright welcome to the deep dive on Amazon s3 and Amazon Glacius storage",
    "start": "7980",
    "end": "14820"
  },
  {
    "text": "management i'm sundar permethrin director of product management at Amazon s3 today customers like you use Amazon",
    "start": "14820",
    "end": "23580"
  },
  {
    "text": "s3 and glacier to store vast amounts of your data and you use it for everything from big data analytics log file storage",
    "start": "23580",
    "end": "32090"
  },
  {
    "text": "media workloads backup and recovery or archive data in this session we'll talk",
    "start": "32090",
    "end": "38489"
  },
  {
    "text": "about all the tools we have for you in s3 and in the AWS ecosystem to help you",
    "start": "38489",
    "end": "44340"
  },
  {
    "text": "easily organize understand act and secure your storage so you can get the",
    "start": "44340",
    "end": "50100"
  },
  {
    "text": "most out of your data in s3 and glacier the agenda for today's session will",
    "start": "50100",
    "end": "56280"
  },
  {
    "text": "start with an overview of all the storage management tools we have for you in s 3 and the AWS ecosystem we look at",
    "start": "56280",
    "end": "63629"
  },
  {
    "text": "capabilities you have to make it easy for you to classify your data for example using object tagging then we",
    "start": "63629",
    "end": "70049"
  },
  {
    "text": "look at all the tools we have for you to get insights and how your data is being used like storage class analysis or",
    "start": "70049",
    "end": "76259"
  },
  {
    "text": "up-to-the-minute metrics and then we look at all the options we have for you to act on those insights like lifecycle",
    "start": "76259",
    "end": "82920"
  },
  {
    "text": "policies or cross region replication or the ability to set up default encryption policies on your data and finally we'll",
    "start": "82920",
    "end": "90390"
  },
  {
    "text": "hear from our special guest Paul Fisher from alert logic and Paul will talk about how alert logic is using s3 and s3",
    "start": "90390",
    "end": "98040"
  },
  {
    "text": "storage management to sims to seamlessly scale their service and so over 4,000",
    "start": "98040",
    "end": "103770"
  },
  {
    "text": "customers today with security services and finally we will also leave some time at the end for questions we do have a",
    "start": "103770",
    "end": "111090"
  },
  {
    "text": "full full topics and session going on today so we will be available if you don't get to all the questions here we",
    "start": "111090",
    "end": "117180"
  },
  {
    "text": "will be available after the session outside to answer any questions we couldn't get to in this session to walk",
    "start": "117180",
    "end": "122969"
  },
  {
    "text": "you through these topics I'd like to introduce Susan Chan senior product manager Amazon s3",
    "start": "122969",
    "end": "129379"
  },
  {
    "text": "hi everyone how are you doing well thank",
    "start": "132260",
    "end": "137909"
  },
  {
    "text": "you for coming this is a very exciting topic for me and I'm hoping it's a very exciting topic for you as well as sooner",
    "start": "137909",
    "end": "145170"
  },
  {
    "text": "mentioned we have a full suite of storage management tools available for",
    "start": "145170",
    "end": "151319"
  },
  {
    "text": "you when you store your data on AWS what I wanted to start with is to show you",
    "start": "151319",
    "end": "158069"
  },
  {
    "text": "that all of these are linked we give you tools various way to organize your data",
    "start": "158069",
    "end": "164510"
  },
  {
    "text": "once you have organized your data you have a suite of tools to help you monitor and analyze your data so you can",
    "start": "164510",
    "end": "172319"
  },
  {
    "text": "pick or choose what you need and only use the ones you need it and then also",
    "start": "172319",
    "end": "177989"
  },
  {
    "text": "with that organization you also have a bunch of tools that helps you act so",
    "start": "177989",
    "end": "183000"
  },
  {
    "text": "it's easy for you to set simple rules and that's your data as your amount of storage grow as your data grow source",
    "start": "183000",
    "end": "189060"
  },
  {
    "text": "management remain easy and simple for you so you spend most of your time developing your business developing your",
    "start": "189060",
    "end": "195450"
  },
  {
    "text": "application and leave all the undifferentiated heavy lifting for s3 and Amazon to do security it's a top",
    "start": "195450",
    "end": "204419"
  },
  {
    "text": "priority for us as well as for you so underlying through all of these organizing monitoring and act is a full",
    "start": "204419",
    "end": "212519"
  },
  {
    "text": "suite of security management tools as well and we'll also go into deep into",
    "start": "212519",
    "end": "218099"
  },
  {
    "text": "each of these as I go through the presentation let's start with how you",
    "start": "218099",
    "end": "226349"
  },
  {
    "text": "can organize your data how many of you have been using s3 for more than a year",
    "start": "226349",
    "end": "232819"
  },
  {
    "text": "majority of you so imagine you're familiar with organizing your data with",
    "start": "233209",
    "end": "238379"
  },
  {
    "text": "buckets and prefix yeah so I'm not gonna go into that I assume that you already",
    "start": "238379",
    "end": "243450"
  },
  {
    "text": "know how to do that but what you have been telling me what you've been telling us is that your data has a lot more",
    "start": "243450",
    "end": "251280"
  },
  {
    "text": "meaning than a single dimension of location so what we have to introduce is",
    "start": "251280",
    "end": "257130"
  },
  {
    "text": "object storage object tagging so you can tag your storage and identify your",
    "start": "257130",
    "end": "264630"
  },
  {
    "text": "based on the nature of your data with object tags you can control access set",
    "start": "264630",
    "end": "272130"
  },
  {
    "text": "lifecycle policies so to lower your cost and move storage around you can monitor",
    "start": "272130",
    "end": "277470"
  },
  {
    "text": "your storage by setting metrics and you can also analyze how your how your data",
    "start": "277470",
    "end": "283139"
  },
  {
    "text": "is being used with s3 analytics so what",
    "start": "283139",
    "end": "288960"
  },
  {
    "start": "288000",
    "end": "288000"
  },
  {
    "text": "exactly is object tags object tags are simply case sensitive key value pairs",
    "start": "288960",
    "end": "297080"
  },
  {
    "text": "they are mutable metadata on your object keys can be up to 128 characters and",
    "start": "297080",
    "end": "304820"
  },
  {
    "text": "value can be up to 256 characters and here are some of the examples that are",
    "start": "304820",
    "end": "312360"
  },
  {
    "text": "nature's of the data that may be relevant to you already you can put as many as 10 tags per object so you can do",
    "start": "312360",
    "end": "320430"
  },
  {
    "text": "a combinations of these tags there are a couple ways to put tags on your data if",
    "start": "320430",
    "end": "326909"
  },
  {
    "text": "you have existing objects you can use the put tag requests and just to put the",
    "start": "326909",
    "end": "333389"
  },
  {
    "text": "tags that are relevant to you on your object without modifying the object at",
    "start": "333389",
    "end": "339300"
  },
  {
    "text": "all so all the rest of the metadata to create data of the object stays the same if you have new data you can just",
    "start": "339300",
    "end": "347419"
  },
  {
    "text": "include tags as part of your put object request so this is simply the same",
    "start": "347419",
    "end": "353250"
  },
  {
    "text": "request and there's no additional request and you just need to make just one request include the tag in the",
    "start": "353250",
    "end": "360120"
  },
  {
    "text": "parameters of your put object here's an",
    "start": "360120",
    "end": "366270"
  },
  {
    "start": "365000",
    "end": "365000"
  },
  {
    "text": "example of managing access using tags what you're seeing here is I'm granting",
    "start": "366270",
    "end": "373770"
  },
  {
    "text": "get object requests to this user in my project bucket only for the objects that",
    "start": "373770",
    "end": "381840"
  },
  {
    "text": "are tagged Project X so what I'm effectively doing here is giving you",
    "start": "381840",
    "end": "388020"
  },
  {
    "text": "very granular control on within the bucket what object this user get access",
    "start": "388020",
    "end": "394139"
  },
  {
    "text": "to so let's say when I have new objects or existing object that becomes",
    "start": "394139",
    "end": "400590"
  },
  {
    "text": "irrelevant to project X all I need to do is tag those objects with a project X",
    "start": "400590",
    "end": "407780"
  },
  {
    "text": "tags and this user will automatically get access to it when this user move on",
    "start": "407780",
    "end": "416130"
  },
  {
    "text": "to the next project and I no longer want to give them access to project X data",
    "start": "416130",
    "end": "421400"
  },
  {
    "text": "all I need to do is take this permission Clause away from his the user I am",
    "start": "421400",
    "end": "428460"
  },
  {
    "text": "policy and that's it they no longer get access to project X data so it's very",
    "start": "428460",
    "end": "434430"
  },
  {
    "text": "very simple think about how you you might apply object tag to your how you organize your",
    "start": "434430",
    "end": "440940"
  },
  {
    "text": "data and in tags you hear a lot about tags throughout the the presentation so",
    "start": "440940",
    "end": "448200"
  },
  {
    "text": "just kind of keep in mind as we go through the presentation here so now",
    "start": "448200",
    "end": "454710"
  },
  {
    "text": "that we've briefly discussed how you would organize your data let's take a look at what are the tools available for",
    "start": "454710",
    "end": "461490"
  },
  {
    "text": "you to monitor and analyze your data",
    "start": "461490",
    "end": "466099"
  },
  {
    "text": "customer have told us that they have business workflow or you know some",
    "start": "468140",
    "end": "473280"
  },
  {
    "text": "customers are like you are running Big Data jobs on s3 and the beginning of",
    "start": "473280",
    "end": "479100"
  },
  {
    "text": "your Big Data jobs when you you know for example when you're running a Hadoop query the first thing it does a lot of",
    "start": "479100",
    "end": "485040"
  },
  {
    "text": "the times it you list everything in that prefix or you list everything in the bucket and as the amount of your data",
    "start": "485040",
    "end": "493350"
  },
  {
    "text": "grow what you're telling us is that you're spending more and more time listing the data so we introduced s3",
    "start": "493350",
    "end": "500520"
  },
  {
    "text": "inventory for you for that so you no longer have to list your data s3",
    "start": "500520",
    "end": "506010"
  },
  {
    "text": "inventory gives you a readily available file of the object names as well as the",
    "start": "506010",
    "end": "512669"
  },
  {
    "text": "corresponding metadata you can subscribe you can subscribe to your estimate",
    "start": "512669",
    "end": "520530"
  },
  {
    "text": "inventory at the bucket or the prefix level you can ask to get a report daily",
    "start": "520530",
    "end": "528270"
  },
  {
    "text": "or weekly and you tell us where you'd like it delivered so when",
    "start": "528270",
    "end": "535199"
  },
  {
    "text": "use you know start your next Big Data job or start your weekly workflow you can skip all that listing and just",
    "start": "535199",
    "end": "541470"
  },
  {
    "text": "directly start with your s3 inventory file you can also configure to get",
    "start": "541470",
    "end": "548070"
  },
  {
    "text": "delivery notification through event notification once we deliver the",
    "start": "548070",
    "end": "553319"
  },
  {
    "text": "inventory file the last file that we write is the checksum file so you can",
    "start": "553319",
    "end": "558660"
  },
  {
    "text": "configure to get event notification either send you an SMS or sqs message or",
    "start": "558660",
    "end": "564120"
  },
  {
    "text": "trigger a lambda functions who your workflow can start that way what's",
    "start": "564120",
    "end": "569910"
  },
  {
    "text": "what's more to know is s3 inventory costs half of what the East the",
    "start": "569910",
    "end": "576660"
  },
  {
    "text": "synchronous list requests cost so think about this is also a way to save time",
    "start": "576660",
    "end": "582540"
  },
  {
    "text": "and save money we have been actively",
    "start": "582540",
    "end": "587550"
  },
  {
    "text": "taking your feedback and over just the last month we've introduced a few capability a few more enhancement on s3",
    "start": "587550",
    "end": "595949"
  },
  {
    "text": "inventory we added object level encryption status so you can easily see",
    "start": "595949",
    "end": "602160"
  },
  {
    "text": "how your objects are encrypted on the server side you can also now encrypt",
    "start": "602160",
    "end": "608220"
  },
  {
    "text": "inventory report with SSE s3 or SSE kms",
    "start": "608220",
    "end": "613579"
  },
  {
    "text": "we added a new output format so previously you can choose to get the",
    "start": "613579",
    "end": "619620"
  },
  {
    "text": "file in CSV a flat file format we've added or RC a columnar format so if you",
    "start": "619620",
    "end": "625709"
  },
  {
    "text": "choose to query your day out your inventory is much faster that way we",
    "start": "625709",
    "end": "631260"
  },
  {
    "text": "also added integration with Amazon escena redshift spectrum or any of your",
    "start": "631260",
    "end": "636630"
  },
  {
    "text": "hive tools I'll show a little bit on how how you can create your data with a",
    "start": "636630",
    "end": "643319"
  },
  {
    "text": "senior in a little bit setting up estimate inventory is very",
    "start": "643319",
    "end": "649319"
  },
  {
    "text": "very easy everything goes a lot of the tools that",
    "start": "649319",
    "end": "654959"
  },
  {
    "text": "we're talking about is going to be under the management tab in your s3 console",
    "start": "654959",
    "end": "660380"
  },
  {
    "text": "inventory has its own tab and setting it up is actually just literally a single click",
    "start": "660380",
    "end": "665850"
  },
  {
    "text": "on the console so you can see that we out added a new output format so you choose between CSV and or RC encryption",
    "start": "665850",
    "end": "674670"
  },
  {
    "text": "status is one of the new optional field and there are a whole selection of optional field that you can choose so",
    "start": "674670",
    "end": "680940"
  },
  {
    "text": "you only choose the ones that are relevant to you you also can specify your inventory",
    "start": "680940",
    "end": "686579"
  },
  {
    "text": "encryption just by a radio button",
    "start": "686579",
    "end": "691459"
  },
  {
    "text": "Capital One is telling us that they're using s3 inventory report they look at",
    "start": "691970",
    "end": "697620"
  },
  {
    "text": "the object encryption status for the compliance and daily reporting purpose I'm also curious how you will use s3",
    "start": "697620",
    "end": "704790"
  },
  {
    "text": "inventory report so if you have a chance later on later on after the presentation",
    "start": "704790",
    "end": "710160"
  },
  {
    "text": "or at the AWS booth let us know we'd love to hear so we recently will take",
    "start": "710160",
    "end": "718560"
  },
  {
    "start": "716000",
    "end": "716000"
  },
  {
    "text": "question at the end we recently added querying capability with hive tools so",
    "start": "718560",
    "end": "725639"
  },
  {
    "text": "just a quick example of how you can query your s3 inventory with Athena all of these are in our documentation so you",
    "start": "725639",
    "end": "733740"
  },
  {
    "text": "can you can check out our documentation but I'm just going to quickly walk through the there's you basically create",
    "start": "733740",
    "end": "740009"
  },
  {
    "text": "a table the only two things that you would change here in this kind of standard template create table query is you name",
    "start": "740009",
    "end": "747360"
  },
  {
    "text": "your inventory table and you also point to the location where you've asked your",
    "start": "747360",
    "end": "752880"
  },
  {
    "text": "for your inventory to be delivered to those are the only two changes you you need to change so once you create your",
    "start": "752880",
    "end": "759839"
  },
  {
    "text": "table you can start writing a query using standard sequel so here I'm",
    "start": "759839",
    "end": "766889"
  },
  {
    "text": "looking at how much of whether or not my objects are encrypted you can tell that",
    "start": "766889",
    "end": "771990"
  },
  {
    "text": "some of them are not some of them are encrypted with SSE s3 and a few are",
    "start": "771990",
    "end": "777540"
  },
  {
    "text": "encrypted with kms so with that you can also quickly do a just a select object",
    "start": "777540",
    "end": "784230"
  },
  {
    "text": "name and you can figure out which ones are not encrypted and if you decide to do something with it it's very very easy",
    "start": "784230",
    "end": "791480"
  },
  {
    "text": "you can also quickly visualize your inventory data with quick site",
    "start": "792439",
    "end": "799160"
  },
  {
    "text": "so here you can see that I'm visualizing a couple days of my data on how how many",
    "start": "799160",
    "end": "804560"
  },
  {
    "text": "of my objects are being encrypted and how they're being encrypted so you know I know many of you are probably very",
    "start": "804560",
    "end": "811730"
  },
  {
    "text": "good at visualizing your data and getting Valerie out of a visualization so I encourage you to you know play with",
    "start": "811730",
    "end": "817820"
  },
  {
    "text": "your inventory with quick sight and see what you get out of it",
    "start": "817820",
    "end": "822399"
  },
  {
    "start": "823000",
    "end": "823000"
  },
  {
    "text": "how many of you have wondered how much storage you have in your bucket we",
    "start": "823720",
    "end": "831620"
  },
  {
    "text": "actually publish this every day by default for you it's under management",
    "start": "831620",
    "end": "836990"
  },
  {
    "text": "metrics and the storage metrics is free it is published at the bucket level it's",
    "start": "836990",
    "end": "842810"
  },
  {
    "text": "updated daily we even give you a graph with kind of a historical trend so you",
    "start": "842810",
    "end": "848390"
  },
  {
    "text": "can see in your bucket how many objects there are and how much is being stored",
    "start": "848390",
    "end": "853420"
  },
  {
    "text": "this is part of cloud watch metrics so",
    "start": "853420",
    "end": "858620"
  },
  {
    "start": "857000",
    "end": "857000"
  },
  {
    "text": "while we're talking about cloud watch metrics you can do so much more with cloud watch metrics you can use cloud",
    "start": "858620",
    "end": "865880"
  },
  {
    "text": "watch metrics to monitor performance and operations using use with cloud watch",
    "start": "865880",
    "end": "872420"
  },
  {
    "text": "master metrics we deliver requests and bandwidth metrics for you and you can",
    "start": "872420",
    "end": "878260"
  },
  {
    "text": "generate metrics you can define your metrics based on bucket prefix or tags",
    "start": "878260",
    "end": "885110"
  },
  {
    "text": "so you can align your metrics to your applications that are writing to s3",
    "start": "885110",
    "end": "891790"
  },
  {
    "text": "these are one minute cloud watch metrics so you get them you can depend on them for your operational operational use and",
    "start": "891790",
    "end": "899710"
  },
  {
    "text": "with cloud watch metrics you can set alarm so you can get a notification if",
    "start": "899710",
    "end": "906560"
  },
  {
    "text": "the metrics exceed a level that you have predefined so again we have we publish",
    "start": "906560",
    "end": "915920"
  },
  {
    "text": "many different kinds of metrics there 9 request metrics and there for bandwidth",
    "start": "915920",
    "end": "922940"
  },
  {
    "text": "metrics so for example you have an application and you expect that you get",
    "start": "922940",
    "end": "928370"
  },
  {
    "text": "10 gigabyte of upload every day and if you're not yeah if if there's one day",
    "start": "928370",
    "end": "935750"
  },
  {
    "text": "that you didn't see that 10 gigabyte of upload you can set an alarm for that so",
    "start": "935750",
    "end": "941120"
  },
  {
    "text": "that someone could look at it and see where's my missing data or if there's a day where all of a sudden you get 20",
    "start": "941120",
    "end": "946910"
  },
  {
    "text": "gigabyte of uploaded while you're expecting 10 cloud watch alarm Kent can help you alert you for that as well so",
    "start": "946910",
    "end": "958610"
  },
  {
    "text": "moving on to the next topic some of you know that s3 has many different storage",
    "start": "958610",
    "end": "964370"
  },
  {
    "text": "classes we have storage classes that are for your hot active data and we have",
    "start": "964370",
    "end": "971780"
  },
  {
    "text": "other source classes standard infrequent access as well as glacier for your",
    "start": "971780",
    "end": "976850"
  },
  {
    "text": "colder infrequent access data so when we after we introduced some of these",
    "start": "976850",
    "end": "982400"
  },
  {
    "text": "storage classes one of the more frequently asked question is well where",
    "start": "982400",
    "end": "987860"
  },
  {
    "text": "what data should where should I put my data what's right which storage class is right for my data so for that we",
    "start": "987860",
    "end": "995360"
  },
  {
    "text": "introduced storage class analysis storage class analysis gives you a daily",
    "start": "995360",
    "end": "1001770"
  },
  {
    "text": "report on which part of your bucket is being accessed and frequently used and",
    "start": "1001770",
    "end": "1007480"
  },
  {
    "text": "which part of your bucket may be cold and not frequently used storage class",
    "start": "1007480",
    "end": "1014110"
  },
  {
    "text": "analysis after you run it for about a month we also gives you a recommendation for",
    "start": "1014110",
    "end": "1020230"
  },
  {
    "text": "the right lifecycle policy right a lifecycle policy recommendation so that you can set your lifecycle policy with a",
    "start": "1020230",
    "end": "1028030"
  },
  {
    "text": "data-driven analysis underneath it you",
    "start": "1028030",
    "end": "1033730"
  },
  {
    "text": "can again with um for source class analysis you can set it up by the bucket prefix or tag so you can specifically",
    "start": "1033730",
    "end": "1042010"
  },
  {
    "text": "figure out what the right lifecycle policy for your set of data so this is a",
    "start": "1042010",
    "end": "1050110"
  },
  {
    "text": "this is a view of what you get out of storage class analysis you get a",
    "start": "1050110",
    "end": "1055320"
  },
  {
    "text": "basically a analysis based on object age you can see the top three boxes are for",
    "start": "1055320",
    "end": "1064030"
  },
  {
    "text": "object age that are less than sixty days and you can tell that based",
    "start": "1064030",
    "end": "1070120"
  },
  {
    "text": "on our analysis that those are frequently access and the bottom two",
    "start": "1070120",
    "end": "1077020"
  },
  {
    "text": "boxes are objects that are let out that are greater than 90 days old and based on based on our observation we haven't",
    "start": "1077020",
    "end": "1084190"
  },
  {
    "text": "seen that many retrieval and so those are probably good if you wanted to think about putting them into standard",
    "start": "1084190",
    "end": "1090490"
  },
  {
    "text": "infrequent access to lower your storage costs you can also visualize storage",
    "start": "1090490",
    "end": "1097780"
  },
  {
    "text": "class analysis with Amazon quick site now it's it's fully integrated so you",
    "start": "1097780",
    "end": "1103000"
  },
  {
    "text": "can do your you know cutting and slicing and visualize and find out what is right",
    "start": "1103000",
    "end": "1109180"
  },
  {
    "text": "for your storage if you're using other existing business intelligence tool that",
    "start": "1109180",
    "end": "1116530"
  },
  {
    "start": "1112000",
    "end": "1112000"
  },
  {
    "text": "you prefer you can also export storage class analysis and use it with you know",
    "start": "1116530",
    "end": "1122110"
  },
  {
    "text": "any business intelligence tools that you already use so you don't have to switch tools so moving on to the next topic",
    "start": "1122110",
    "end": "1134730"
  },
  {
    "text": "many of you may need your many to figure",
    "start": "1134730",
    "end": "1140500"
  },
  {
    "text": "out tract fine-grained access tracking for your data you may have compliance",
    "start": "1140500",
    "end": "1147310"
  },
  {
    "text": "need that is driving this or you may have auditing auditing needs that you need to kind of go back and figure out",
    "start": "1147310",
    "end": "1153160"
  },
  {
    "text": "what's what what has happened AWS cloud trail is this tool for you AWS cloud",
    "start": "1153160",
    "end": "1160570"
  },
  {
    "text": "trail is the API logging tool for AWS and s3 is integrated with it with cloud",
    "start": "1160570",
    "end": "1168970"
  },
  {
    "text": "trail logs it captures for each request it captures you know all the requests",
    "start": "1168970",
    "end": "1175750"
  },
  {
    "text": "related detail that you will need such as who has made the request what request was being made well what resource was",
    "start": "1175750",
    "end": "1182890"
  },
  {
    "text": "being a was affected and kind of what the what the request response was so you",
    "start": "1182890",
    "end": "1188860"
  },
  {
    "text": "have you have very detailed record of what had happened and at what point",
    "start": "1188860",
    "end": "1195690"
  },
  {
    "text": "cloud trail logs you can configure to log at the object level it",
    "start": "1195690",
    "end": "1201789"
  },
  {
    "text": "is called s3 data event you can also ask to log the bucket level operation so",
    "start": "1201789",
    "end": "1208120"
  },
  {
    "text": "when you change your when you make changes to your bucket you can log those operations they call management events",
    "start": "1208120",
    "end": "1214049"
  },
  {
    "text": "you can also choose to log both you can also filter to log only the reads or",
    "start": "1214049",
    "end": "1220870"
  },
  {
    "text": "only the writes so it's very flexible cloud trail is also integrated with",
    "start": "1220870",
    "end": "1228250"
  },
  {
    "text": "Amazon CloudWatch cloud watch event so when you see something in the logs you",
    "start": "1228250",
    "end": "1234100"
  },
  {
    "text": "can programmatically take actions to immediately do make changes or improve",
    "start": "1234100",
    "end": "1240220"
  },
  {
    "text": "security postures make sure you need sure you need those changes cloud trail",
    "start": "1240220",
    "end": "1245620"
  },
  {
    "text": "logs are delivered to clout watch logging so you can aggregate locks",
    "start": "1245620",
    "end": "1250799"
  },
  {
    "text": "within minutes and they're delivered to cloud raw events within seconds so",
    "start": "1250799",
    "end": "1255940"
  },
  {
    "text": "they're very instantaneous you can very",
    "start": "1255940",
    "end": "1261460"
  },
  {
    "text": "quickly start with cloud trail logging through the s3 console it is under your",
    "start": "1261460",
    "end": "1266830"
  },
  {
    "text": "bucket property and it's just a really simple panel that you can enable clock",
    "start": "1266830",
    "end": "1271960"
  },
  {
    "text": "trail logging and as you can see you can choose between read or write and you can specify where you would like your logs",
    "start": "1271960",
    "end": "1279280"
  },
  {
    "text": "to land if you're already using cloud trail you can also configure that in",
    "start": "1279280",
    "end": "1285700"
  },
  {
    "text": "your cloud trail console you can all in the cloud trail console you can also",
    "start": "1285700",
    "end": "1292169"
  },
  {
    "text": "specifically select that everything in your account both existing bucket as",
    "start": "1292169",
    "end": "1297370"
  },
  {
    "text": "well as any new buckets created in your account to have cloud trail logging enable by default so as we mentioned I",
    "start": "1297370",
    "end": "1309429"
  },
  {
    "start": "1307000",
    "end": "1307000"
  },
  {
    "text": "mean security underlies all of our story here it is always top of mind for us",
    "start": "1309429",
    "end": "1315539"
  },
  {
    "text": "when customers thinks about us s3 security primarily you're thinking of",
    "start": "1315539",
    "end": "1320919"
  },
  {
    "text": "two things first is my data encrypted at rest so for that as you recall we",
    "start": "1320919",
    "end": "1328630"
  },
  {
    "text": "introduced object and Christian status in through inventory and the second is who",
    "start": "1328630",
    "end": "1335620"
  },
  {
    "text": "has are any of my access permission open to the public so for that we have to",
    "start": "1335620",
    "end": "1342550"
  },
  {
    "text": "method first is the AWS trusted advisor there's a bucket permission check with",
    "start": "1342550",
    "end": "1348220"
  },
  {
    "text": "in AWS trusted advisor what it does it actually lists out your buckets that",
    "start": "1348220",
    "end": "1354430"
  },
  {
    "text": "have either public access or any authenticated user access if you have",
    "start": "1354430",
    "end": "1360190"
  },
  {
    "text": "and they list out the buckets that have those permissions so you can go through and figure out whether or not you had",
    "start": "1360190",
    "end": "1366400"
  },
  {
    "text": "intended for those to be publicly accessible using the same tech and AWS",
    "start": "1366400",
    "end": "1373480"
  },
  {
    "text": "trusted advisor is included in your business and enterprise level support",
    "start": "1373480",
    "end": "1380070"
  },
  {
    "text": "using the same technology we also recently introduced the bucket",
    "start": "1380070",
    "end": "1385960"
  },
  {
    "text": "permission check in the s3 console this is available to everyone so if you have",
    "start": "1385960",
    "end": "1391120"
  },
  {
    "text": "you know your laptop on you welcome to check it out here's what you will see in",
    "start": "1391120",
    "end": "1397570"
  },
  {
    "text": "your AWS console when you list your bucket we introduced a new column that",
    "start": "1397570",
    "end": "1402940"
  },
  {
    "text": "says access so for the ones with public access we actually flag those for you so",
    "start": "1402940",
    "end": "1409870"
  },
  {
    "text": "you can view them in context you're you're looking at us through your s3 resource looking at your s3 bucket and",
    "start": "1409870",
    "end": "1415650"
  },
  {
    "text": "if you see them that they're listed as public you can check it out and go into",
    "start": "1415650",
    "end": "1421510"
  },
  {
    "text": "bucket permission and we even flag and specifically tell you whether or not it is the access Poulos bucket access",
    "start": "1421510",
    "end": "1428470"
  },
  {
    "text": "policy or the bucket policy that is providing that public access so you can",
    "start": "1428470",
    "end": "1434070"
  },
  {
    "text": "decide whether or not you need to change those so there are a lot of a big range",
    "start": "1434070",
    "end": "1443170"
  },
  {
    "text": "of tools that helps you figure out what data you have and how they're being used",
    "start": "1443170",
    "end": "1450510"
  },
  {
    "text": "let's move on to the last topic which is tools that will help you act on your",
    "start": "1451770",
    "end": "1456940"
  },
  {
    "text": "data",
    "start": "1456940",
    "end": "1459179"
  },
  {
    "start": "1464000",
    "end": "1464000"
  },
  {
    "text": "lifecycle policy is one of our one of our most two most popular tool what it",
    "start": "1464530",
    "end": "1473090"
  },
  {
    "text": "does it actually it helps you lower your storage costs by letting you set very",
    "start": "1473090",
    "end": "1478190"
  },
  {
    "text": "simple rules to automatically transition your storage to a lower-cost storage",
    "start": "1478190",
    "end": "1484250"
  },
  {
    "text": "class or to expire your storage you can",
    "start": "1484250",
    "end": "1489370"
  },
  {
    "text": "you you can decide one of the one of the reason why you might transition your storage would be",
    "start": "1489370",
    "end": "1495920"
  },
  {
    "text": "you know that your storage getting cold or they're they're not used after 90 days or not used after my project is",
    "start": "1495920",
    "end": "1502790"
  },
  {
    "text": "done so you might set a rule to transition them into a lower-cost storage class or if you don't know that",
    "start": "1502790",
    "end": "1509120"
  },
  {
    "text": "you may recall that you can now use storage class analysis to figure out",
    "start": "1509120",
    "end": "1514280"
  },
  {
    "text": "what is the right lifecycle policy for you for your specific data you can set",
    "start": "1514280",
    "end": "1520430"
  },
  {
    "text": "lifecycle policy on a bucket prefix or tags so you can have very very granular",
    "start": "1520430",
    "end": "1527600"
  },
  {
    "text": "control and set the policies that corresponds to your application or your workflow here's an example policy that",
    "start": "1527600",
    "end": "1536810"
  },
  {
    "text": "you may set for example all my objects are starting on the s3 standard storage",
    "start": "1536810",
    "end": "1541970"
  },
  {
    "text": "class and after a while after 30 days I know that access drops off these are",
    "start": "1541970",
    "end": "1548690"
  },
  {
    "text": "like videos that I'm I'm sharing with sharing with my family and after 30 days",
    "start": "1548690",
    "end": "1554930"
  },
  {
    "text": "hardly anybody watch them anymore so I can move them to a lower-cost storage",
    "start": "1554930",
    "end": "1560870"
  },
  {
    "text": "class like standard infrequent access and after 90 days I know that really",
    "start": "1560870",
    "end": "1569030"
  },
  {
    "text": "hardly anyone if anyone is going to be touching them but I still want to keep",
    "start": "1569030",
    "end": "1574370"
  },
  {
    "text": "them around so I can set another rule that says you know move all my objects",
    "start": "1574370",
    "end": "1579380"
  },
  {
    "text": "that are older than 90 days into Amazon glacier so this it's a very very",
    "start": "1579380",
    "end": "1585260"
  },
  {
    "text": "flexible rule it's also very simple to manage",
    "start": "1585260",
    "end": "1590560"
  },
  {
    "start": "1590000",
    "end": "1590000"
  },
  {
    "text": "so the next tool that I want to discuss is cross vision replication there are",
    "start": "1592430",
    "end": "1597890"
  },
  {
    "text": "many reasons why you might decide to replicate your data across regions some",
    "start": "1597890",
    "end": "1603650"
  },
  {
    "text": "of you might have compliance requirement that requires you to store data hundreds",
    "start": "1603650",
    "end": "1608930"
  },
  {
    "text": "of miles apart from each other others might have you might have latency",
    "start": "1608930",
    "end": "1614630"
  },
  {
    "text": "sensitive applications so you want it you might want to bring your data closer to your end user so they get a better",
    "start": "1614630",
    "end": "1621140"
  },
  {
    "text": "performance you might also have security requirements that so you wanted to",
    "start": "1621140",
    "end": "1628490"
  },
  {
    "text": "create a remote copy that is for example locked into a different region and a",
    "start": "1628490",
    "end": "1634040"
  },
  {
    "text": "different account so you have a pristine second copy for for your backup so cross",
    "start": "1634040",
    "end": "1641630"
  },
  {
    "text": "with your application is the tool for that it is automated replication that is",
    "start": "1641630",
    "end": "1647690"
  },
  {
    "text": "asynchronous across AWS regions let's take a look at how it works",
    "start": "1647690",
    "end": "1653650"
  },
  {
    "start": "1652000",
    "end": "1652000"
  },
  {
    "text": "cross version replication is is a it's a route that you can set it up you can set",
    "start": "1653650",
    "end": "1659510"
  },
  {
    "text": "it up at the bucket or the prefix level once it is configured every upload into",
    "start": "1659510",
    "end": "1665900"
  },
  {
    "text": "the bucket or asynchronously replicated into the destination region that you",
    "start": "1665900",
    "end": "1672290"
  },
  {
    "text": "specified you can choose any AWS region as your target region so that's a very",
    "start": "1672290",
    "end": "1679670"
  },
  {
    "text": "important point because you know when you choose your target region you may consider your what your requirements and",
    "start": "1679670",
    "end": "1685430"
  },
  {
    "text": "mines are where maybe you are you wanted to bring your data closer to your",
    "start": "1685430",
    "end": "1690680"
  },
  {
    "text": "end-user that might be one reason or if you have a compliance rule that you need",
    "start": "1690680",
    "end": "1695720"
  },
  {
    "text": "your data store coast-to-coast that's another reason but whatever those reasons are you get to choose which AWS",
    "start": "1695720",
    "end": "1702800"
  },
  {
    "text": "region you wanted to replicate to all the data are securely transferred over",
    "start": "1702800",
    "end": "1709700"
  },
  {
    "text": "secure connection and by default we replicate the exact replicas that means",
    "start": "1709700",
    "end": "1716450"
  },
  {
    "text": "the the object the object access policy the tags everything so all the metadata",
    "start": "1716450",
    "end": "1723560"
  },
  {
    "text": "is replicated exactly so they creation day of the object does not change it is",
    "start": "1723560",
    "end": "1729260"
  },
  {
    "text": "replicated across region as well so they replicated data would have the original createdate of your source data lifecycle",
    "start": "1729260",
    "end": "1738470"
  },
  {
    "text": "policy actions are not replicated what that means is that you can create",
    "start": "1738470",
    "end": "1744820"
  },
  {
    "text": "independent lifecycle policy for your source data versus your destination data",
    "start": "1744820",
    "end": "1751900"
  },
  {
    "text": "so for example your destination data is a copy that you you you know that it's",
    "start": "1751900",
    "end": "1757940"
  },
  {
    "text": "going to be cold you just want it you just want a second copy that is hardly ever used you may consider using a",
    "start": "1757940",
    "end": "1764570"
  },
  {
    "text": "lifecycle policy to just transition those into glacier and so you have your second copy stored at a very low cost of",
    "start": "1764570",
    "end": "1772460"
  },
  {
    "text": "the glacier costs so many of you like by",
    "start": "1772460",
    "end": "1779630"
  },
  {
    "text": "default may be thinking about across region replication I have I have it in my in the same account and so my primary",
    "start": "1779630",
    "end": "1786320"
  },
  {
    "text": "my region a and region B buckets are both owned by the same account but some",
    "start": "1786320",
    "end": "1792140"
  },
  {
    "text": "of you might consider using replication across account and the reason is you",
    "start": "1792140",
    "end": "1798170"
  },
  {
    "text": "might want additional protection for your sensitive data to prevent you know",
    "start": "1798170",
    "end": "1804740"
  },
  {
    "text": "malicious or accidental delete so again",
    "start": "1804740",
    "end": "1809990"
  },
  {
    "text": "by default replication would would replicate the same access policy from",
    "start": "1809990",
    "end": "1817790"
  },
  {
    "text": "your source we entry we recently introduced ownership override so that when you know your when you set up your",
    "start": "1817790",
    "end": "1826460"
  },
  {
    "text": "cross region replication you asking s3 to replicate your data so that your destination data is owned by the",
    "start": "1826460",
    "end": "1833360"
  },
  {
    "text": "destination account so when those accounts are owned by two different accounts when your source and",
    "start": "1833360",
    "end": "1839810"
  },
  {
    "text": "destination data are owned by two different account what effectively you've done is that urine you now have",
    "start": "1839810",
    "end": "1845390"
  },
  {
    "text": "two completely independent stack of ownership for your objects so we've",
    "start": "1845390",
    "end": "1854270"
  },
  {
    "start": "1853000",
    "end": "1853000"
  },
  {
    "text": "built cross region replication in a very very flexible manner you can set up the way that you needed",
    "start": "1854270",
    "end": "1860730"
  },
  {
    "text": "it we've already talked about ownership override to let you set up two independent copies of your data we've",
    "start": "1860730",
    "end": "1869100"
  },
  {
    "text": "also recently added support for replicating kms encrypted objects for",
    "start": "1869100",
    "end": "1877170"
  },
  {
    "text": "those who use kms you might already know that kms keys are region specific so",
    "start": "1877170",
    "end": "1884010"
  },
  {
    "text": "what we're giving you the capability that crosses your application gives you is that when you set up your cross",
    "start": "1884010",
    "end": "1890370"
  },
  {
    "text": "region replication you tell us what KMS key you want us to use in the",
    "start": "1890370",
    "end": "1895620"
  },
  {
    "text": "destination region and we replicate the data with that destination KMS key so",
    "start": "1895620",
    "end": "1901650"
  },
  {
    "text": "your objects are stored with two different KMS key from between the source and your destination you can",
    "start": "1901650",
    "end": "1910380"
  },
  {
    "text": "choose any s3 storage class sto target so if you have a mix of s3 storage class",
    "start": "1910380",
    "end": "1915720"
  },
  {
    "text": "in your source and you think that your destination it's going to be you know a coder copy you can choose to replicate",
    "start": "1915720",
    "end": "1923310"
  },
  {
    "text": "everything into the standard infrequent storage access class again you can also",
    "start": "1923310",
    "end": "1929070"
  },
  {
    "text": "choose any AWS store region s your target you can also consider using cross",
    "start": "1929070",
    "end": "1936990"
  },
  {
    "text": "route your application as bi-directional replication and the way you do that is you set up cross your notification on",
    "start": "1936990",
    "end": "1943890"
  },
  {
    "text": "both your region a as well as cross your replication policy in region B and you",
    "start": "1943890",
    "end": "1949560"
  },
  {
    "text": "replicate across to each other and so everything that you write into region a",
    "start": "1949560",
    "end": "1955890"
  },
  {
    "text": "and region B are replicated to each other so you always have to sing can - synced up copies and as you recall we",
    "start": "1955890",
    "end": "1965280"
  },
  {
    "text": "support independent logical policy between your source and your destination so you can set up cross your application",
    "start": "1965280",
    "end": "1972210"
  },
  {
    "text": "with lifecycle policy or any way that you according to your requirement it is",
    "start": "1972210",
    "end": "1978030"
  },
  {
    "text": "very flexible I want to quickly show you how to get",
    "start": "1978030",
    "end": "1983790"
  },
  {
    "text": "started with cross region replication it is again under the in the s3 console it",
    "start": "1983790",
    "end": "1989580"
  },
  {
    "text": "is under the management tab under replication and we have a wizard that actually walks you through how to",
    "start": "1989580",
    "end": "1996340"
  },
  {
    "text": "set this up so the first pane is sets of your source bucket you tell us whether",
    "start": "1996340",
    "end": "2003000"
  },
  {
    "text": "or not you want everything that is written to that bucket to be replicated or only things that are specific to",
    "start": "2003000",
    "end": "2009570"
  },
  {
    "text": "written to a specific prefix to be replicated so you can choose between bucket level or prefix level replication",
    "start": "2009570",
    "end": "2016550"
  },
  {
    "text": "here's also where you would specify whether or not you want us to replicate objects that are encrypted with kms",
    "start": "2016550",
    "end": "2024320"
  },
  {
    "text": "encryption if you you can uncheck that if you just want to leave the kms",
    "start": "2024320",
    "end": "2029820"
  },
  {
    "text": "encrypted objects alone and not replicated and then go into the",
    "start": "2029820",
    "end": "2035940"
  },
  {
    "text": "destination tab we you can choose any buckets in any other any other AWS",
    "start": "2035940",
    "end": "2042450"
  },
  {
    "text": "regions we also support across your application set up across account now so",
    "start": "2042450",
    "end": "2048899"
  },
  {
    "text": "you enter both the account ID as well as the bucket name and we'll set that up for you that way and you enter in for if",
    "start": "2048900",
    "end": "2058919"
  },
  {
    "text": "you're choosing kms replication you would enter in the destination kms",
    "start": "2058919",
    "end": "2064200"
  },
  {
    "text": "master key right there you can also enable ownership override with just a",
    "start": "2064200",
    "end": "2070590"
  },
  {
    "text": "checkbox in the bottom there so all this is very simple if you are setting up",
    "start": "2070590",
    "end": "2076649"
  },
  {
    "text": "cross region replication across account you would have to complete your setup by",
    "start": "2076650",
    "end": "2082950"
  },
  {
    "text": "logging into your destination account and we've also made that easy by introducing a wizard here as well so go",
    "start": "2082950",
    "end": "2090360"
  },
  {
    "text": "to replication under more there's a replicate objects so once you log in to your destination account you go into",
    "start": "2090360",
    "end": "2097110"
  },
  {
    "text": "this panel and we have a wizard that helps you helps setup make sure that",
    "start": "2097110",
    "end": "2102660"
  },
  {
    "text": "your destination bucket has you can easily enable versioning which is required and you can also set up the",
    "start": "2102660",
    "end": "2109890"
  },
  {
    "text": "bucket policy or any kms policy with a couple clicks",
    "start": "2109890",
    "end": "2115190"
  },
  {
    "start": "2119000",
    "end": "2119000"
  },
  {
    "text": "so the last tool that I wanted to walk through is trigger based workflow we we",
    "start": "2119820",
    "end": "2128670"
  },
  {
    "text": "have we offer event notification to help you set up a trigger based workflow so",
    "start": "2128670",
    "end": "2135000"
  },
  {
    "text": "you can simplify your processes and and respond to events in a timely manner",
    "start": "2135000",
    "end": "2143240"
  },
  {
    "text": "event notification is an automated process you can set it up for to get a",
    "start": "2143240",
    "end": "2150630"
  },
  {
    "text": "notification Ohta fication when an object is put copied or deleted out of",
    "start": "2150630",
    "end": "2157500"
  },
  {
    "text": "your bucket you can setup event notification at the prefixed level or by",
    "start": "2157500",
    "end": "2163980"
  },
  {
    "text": "suffix and as the result of the event notification you can set it up to either",
    "start": "2163980",
    "end": "2171180"
  },
  {
    "text": "trigger a workflow as a message into SNS or a topping in sqs or trigger a lambda",
    "start": "2171180",
    "end": "2179850"
  },
  {
    "text": "function so you can set up the you can trigger you know the remainder of your workflow that way so for example you",
    "start": "2179850",
    "end": "2188250"
  },
  {
    "text": "know one of the example of event notification that we've heard is you know you might have photos that are",
    "start": "2188250",
    "end": "2194370"
  },
  {
    "text": "being uploaded in your bucket so you can set it up so that when a dot raw prefix",
    "start": "2194370",
    "end": "2200330"
  },
  {
    "text": "object get uploaded into your bucket it will trigger alarm the lambda function",
    "start": "2200330",
    "end": "2205530"
  },
  {
    "text": "so we'll make a thumbnail that you need it of the size that you need it so it's very easy that way so many of you have",
    "start": "2205530",
    "end": "2216390"
  },
  {
    "text": "told us that when for security you had wanted to make sure that everything you",
    "start": "2216390",
    "end": "2223140"
  },
  {
    "text": "store on s3 are encrypted at rest previously you might have you might used",
    "start": "2223140",
    "end": "2230610"
  },
  {
    "start": "2227000",
    "end": "2227000"
  },
  {
    "text": "to have policies that just reject put objects when it is not server out when",
    "start": "2230610",
    "end": "2235950"
  },
  {
    "text": "it doesn't have the encryption header but what we've asked for is to make it",
    "start": "2235950",
    "end": "2242430"
  },
  {
    "text": "easier you don't want to actually reject the object a lot of the times you actually just wanted that object to be",
    "start": "2242430",
    "end": "2247650"
  },
  {
    "text": "encrypted upon upload so we introduced default encryption",
    "start": "2247650",
    "end": "2253800"
  },
  {
    "text": "default encryption automatically encrypts every objects that is written into your s3 bucket you can specify",
    "start": "2253800",
    "end": "2262000"
  },
  {
    "text": "whether or not you want to encrypt with SSE s3 or sse KMS keys so it makes it",
    "start": "2262000",
    "end": "2270609"
  },
  {
    "text": "very easy for you to meet your compliance or you're auditing need so you know that every objects regardless",
    "start": "2270609",
    "end": "2277450"
  },
  {
    "text": "of which application or who's uploading to your bucket that it will always be encrypted the way that you've specified",
    "start": "2277450",
    "end": "2285030"
  },
  {
    "text": "and for those who are looking for a security service we also have amazon may",
    "start": "2287339",
    "end": "2294550"
  },
  {
    "text": "see amazon may see is the security service that automatically discover",
    "start": "2294550",
    "end": "2301619"
  },
  {
    "text": "classify and protect sensitive data in AWS the way it works is that it cracks",
    "start": "2301619",
    "end": "2310510"
  },
  {
    "text": "open your objects to look at sensitive to look for kind of sensitive data using",
    "start": "2310510",
    "end": "2318280"
  },
  {
    "text": "machine learning it recognize sensitive data such as personally identifiable",
    "start": "2318280",
    "end": "2325329"
  },
  {
    "text": "information like social security number or other intellectual property information and it provides you with",
    "start": "2325329",
    "end": "2333420"
  },
  {
    "text": "dashboards and alerts to give you visibility on how the data is being",
    "start": "2333420",
    "end": "2338920"
  },
  {
    "text": "moved or who's accessing it so you can think about using amazon may see if you",
    "start": "2338920",
    "end": "2345730"
  },
  {
    "text": "wanted a full service to watch over how your data is being used so this is the",
    "start": "2345730",
    "end": "2355030"
  },
  {
    "text": "full set of tools that you have to act on your storage NICs I want to introduce",
    "start": "2355030",
    "end": "2360190"
  },
  {
    "text": "Paul Fisher from alert logic to share with you how alert logic is using some",
    "start": "2360190",
    "end": "2365470"
  },
  {
    "text": "of these tools in their architecture Thank You Susan so I'm here to tell you",
    "start": "2365470",
    "end": "2373390"
  },
  {
    "text": "how we have taken a lot of these tools and put them together into a storage",
    "start": "2373390",
    "end": "2379210"
  },
  {
    "text": "solution that supports our products and so what alert logic does just briefly is",
    "start": "2379210",
    "end": "2385690"
  },
  {
    "text": "that we sell dirty service and security protection",
    "start": "2385690",
    "end": "2390789"
  },
  {
    "text": "for cloud workloads everything from vulnerability assessment to web",
    "start": "2390789",
    "end": "2395799"
  },
  {
    "text": "application firewall to IDs and sort of the full span including 24 by 7 sock",
    "start": "2395799",
    "end": "2402459"
  },
  {
    "text": "service that will take care of the detailed security analysis and escalate it to you what I'm going to talk about",
    "start": "2402459",
    "end": "2408880"
  },
  {
    "text": "then is how we support getting that done by using all of this technology so some",
    "start": "2408880",
    "end": "2416769"
  },
  {
    "text": "numbers that'll be that'll be relevant to what we do we have over 4,000 customers all of it is subscription",
    "start": "2416769",
    "end": "2423039"
  },
  {
    "text": "business we ingest today 2 petabytes per month from those customers we have to",
    "start": "2423039",
    "end": "2429880"
  },
  {
    "text": "retain that from anywhere from three months to seven years and that's a per",
    "start": "2429880",
    "end": "2435219"
  },
  {
    "text": "customer selection based on what kind of subscription they want we process average 1.2 million messages",
    "start": "2435219",
    "end": "2441609"
  },
  {
    "text": "per second through the system it peaks at roughly 3 million messages per second at times during the week and that grows",
    "start": "2441609",
    "end": "2448599"
  },
  {
    "text": "the overall workload in terms of storage size grows at a hundred and ten percent per year we add a hundred and ten",
    "start": "2448599",
    "end": "2455650"
  },
  {
    "text": "percent to that storage total per year that it leads us to where we are today",
    "start": "2455650",
    "end": "2461920"
  },
  {
    "text": "all the way to tens of petabytes in the next couple of years and so what we",
    "start": "2461920",
    "end": "2468249"
  },
  {
    "text": "needed to do is build a solution that started in the data center and build a solution in AWS to solve deliver this",
    "start": "2468249",
    "end": "2476319"
  },
  {
    "text": "capability and I'll tell you then how we scaled it when and when we get this to the end so this is our system typical",
    "start": "2476319",
    "end": "2483609"
  },
  {
    "text": "system diagram on the left-hand side you see the green environments which is just customer environments and it's",
    "start": "2483609",
    "end": "2489699"
  },
  {
    "text": "everything from AWS accounts to traditional data center of workloads and even other cloud platforms on the right",
    "start": "2489699",
    "end": "2496809"
  },
  {
    "text": "hand side you have integrations with our partners either third-party tools and or",
    "start": "2496809",
    "end": "2501880"
  },
  {
    "text": "third or partners that add value added security on top where we provide them a",
    "start": "2501880",
    "end": "2507759"
  },
  {
    "text": "direct flow of all of the data that we collect from the customers environment we flow it through to them so that they",
    "start": "2507759",
    "end": "2514059"
  },
  {
    "text": "can do their own analysis on top of that in the middle is our system the simplest",
    "start": "2514059",
    "end": "2519729"
  },
  {
    "text": "possible view the subsystems that make up our system the what I'm gonna drill into is one",
    "start": "2519729",
    "end": "2527320"
  },
  {
    "text": "particular subsystem box which is sort of ingestion data access and storage and in fact just talk about the data access",
    "start": "2527320",
    "end": "2534940"
  },
  {
    "text": "service that's in the you know in the middle of that so what did we need to",
    "start": "2534940",
    "end": "2540910"
  },
  {
    "start": "2539000",
    "end": "2539000"
  },
  {
    "text": "accomplish with our solution so we needed Gannett guaranteed sort of end-to-end integrity so from the point",
    "start": "2540910",
    "end": "2547690"
  },
  {
    "text": "at which we pick the data up out of a customer's environment whether that's off of a host running on ec2 or a TCS",
    "start": "2547690",
    "end": "2554880"
  },
  {
    "text": "container or it's data that we picked up out of an AWS service that we are",
    "start": "2554880",
    "end": "2560560"
  },
  {
    "text": "bringing into our system for storage and analysis we need to guarantee that what we picked up what we store what we",
    "start": "2560560",
    "end": "2567310"
  },
  {
    "text": "process and what we archive long term is exactly the same data and so we flow",
    "start": "2567310",
    "end": "2573480"
  },
  {
    "text": "sha-256 checksum all the way from collection through to the right and s3",
    "start": "2573480",
    "end": "2578860"
  },
  {
    "text": "as part of the the right request and then guarantee that it stays that way",
    "start": "2578860",
    "end": "2584500"
  },
  {
    "text": "long term we need encryption at rest but what we need is encryption at rest on a",
    "start": "2584500",
    "end": "2589810"
  },
  {
    "text": "per customer basis and I'll get into the detail of that in a second we needed to have per customer per data type and we",
    "start": "2589810",
    "end": "2597550"
  },
  {
    "text": "have multiple data types that we manage in our system everything from IDs events to log data to network flow data to what",
    "start": "2597550",
    "end": "2606670"
  },
  {
    "text": "we call observations which are our conclusions on the security posture in",
    "start": "2606670",
    "end": "2611860"
  },
  {
    "text": "the customers environment and then incidents and the whole sort of gambit of the data types each of these is managed as an independent data type we",
    "start": "2611860",
    "end": "2618910"
  },
  {
    "text": "need to manage the expiration policies of those independently so for the log data there's a retention the customer",
    "start": "2618910",
    "end": "2624640"
  },
  {
    "text": "pays for for the IDS data it's a fix thing so it varies data type to data",
    "start": "2624640",
    "end": "2630310"
  },
  {
    "text": "type we also need to manage the storage class so it's like Susan talked about having the ability to go from standard",
    "start": "2630310",
    "end": "2636580"
  },
  {
    "text": "infrequent access to glacier we want to manage this optimize our cost and to still provide the data readily available",
    "start": "2636580",
    "end": "2643390"
  },
  {
    "text": "to the customer for the entire retention period as well as do multi region",
    "start": "2643390",
    "end": "2648520"
  },
  {
    "text": "availability we want to be able to do per customer storage analysis",
    "start": "2648520",
    "end": "2655210"
  },
  {
    "text": "and access analysis to be able to tell the business what is being used by customers and how they're using it and",
    "start": "2655210",
    "end": "2661060"
  },
  {
    "text": "then we want the economics of this solution to be inexpensive and fast and",
    "start": "2661060",
    "end": "2667150"
  },
  {
    "text": "to scale infinitely we sort of achieve most of that with this implementation so",
    "start": "2667150",
    "end": "2674620"
  },
  {
    "text": "what do we use we use object tagging we use lifecycle exploration and storage",
    "start": "2674620",
    "end": "2679780"
  },
  {
    "text": "tiering we use cross region replication inventory VPC endpoints glacier",
    "start": "2679780",
    "end": "2685390"
  },
  {
    "text": "expedited recall music AMS customer master keys and how we do the per customer per month encryption and then",
    "start": "2685390",
    "end": "2692830"
  },
  {
    "text": "we use I am cross count rolls which I'll tell you it about it's a slightly",
    "start": "2692830",
    "end": "2698140"
  },
  {
    "text": "different way than Susan described of using two different accounts and replicating the data across we have a",
    "start": "2698140",
    "end": "2703840"
  },
  {
    "text": "different way that we've arranged it that protects the data from any accidental deletion so the core storage",
    "start": "2703840",
    "end": "2712720"
  },
  {
    "start": "2709000",
    "end": "2709000"
  },
  {
    "text": "engine what you see in the picture is a service called data access very",
    "start": "2712720",
    "end": "2718450"
  },
  {
    "text": "inventively that accesses a series of buckets so for each data type there is a bucket per 950",
    "start": "2718450",
    "end": "2725860"
  },
  {
    "text": "customers because there's limits on the lifecycle rules that I'll talk about in a minute and we create additional buckets in that",
    "start": "2725860",
    "end": "2733330"
  },
  {
    "text": "data type that service then routes it to the right bucket and uses the hash",
    "start": "2733330",
    "end": "2740110"
  },
  {
    "text": "prefix you know trick to be able to get s3 performance so for those of you",
    "start": "2740110",
    "end": "2746170"
  },
  {
    "text": "probably know you can use a hash prefix that the way that s3 scales is each",
    "start": "2746170",
    "end": "2752500"
  },
  {
    "text": "character in that hash prefix gets either automatically turned on based on access patterns or you make a request to",
    "start": "2752500",
    "end": "2758980"
  },
  {
    "text": "the team each prefix gives you an additional bump in the performance of accessing and writing that data in that",
    "start": "2758980",
    "end": "2766180"
  },
  {
    "text": "bucket so it's this small five character prefix basically sets us up to have virtually",
    "start": "2766180",
    "end": "2773230"
  },
  {
    "text": "unlimited scalability for you know as many years as we can you know care to run this experiments and I'll show you",
    "start": "2773230",
    "end": "2779680"
  },
  {
    "text": "some numbers at the end of where we got to just in our deployment so the objects are written",
    "start": "2779680",
    "end": "2786180"
  },
  {
    "text": "for us with two tags the first tag is the customer identity and the second tag is the date this is the date of not when",
    "start": "2786180",
    "end": "2793799"
  },
  {
    "text": "we wrote the data it's the date of the data itself so you think about a log",
    "start": "2793799",
    "end": "2798809"
  },
  {
    "text": "message that got created in the customers environment there is a natural minted date that that message was",
    "start": "2798809",
    "end": "2804630"
  },
  {
    "text": "created on that system we want to transfer that date into our system and",
    "start": "2804630",
    "end": "2810359"
  },
  {
    "text": "then manage the data that way we collect data up to a month after it was minted",
    "start": "2810359",
    "end": "2816710"
  },
  {
    "text": "because there's some times that there's delays and getting the data off those systems transferring it into our system",
    "start": "2816710",
    "end": "2822470"
  },
  {
    "text": "analyzing analyzing it the issue is is that we're also a long-term archiving",
    "start": "2822470",
    "end": "2827819"
  },
  {
    "text": "solution for things like PCI compliance so ultimately we need to get all of the data even if there was a delay and we",
    "start": "2827819",
    "end": "2834690"
  },
  {
    "text": "need to then manage it according to the date so we used two simple tags we use a",
    "start": "2834690",
    "end": "2840349"
  },
  {
    "text": "KMS customer master keys one per data type we generate for the you know for",
    "start": "2840349",
    "end": "2847650"
  },
  {
    "text": "each customer for each month data key out of those customer master keys and",
    "start": "2847650",
    "end": "2853289"
  },
  {
    "text": "then we automatically apply those data keys to do the encryption we actually",
    "start": "2853289",
    "end": "2858390"
  },
  {
    "text": "set that up so that the so that the we have keys in two different paired regions which I'll show in just a second",
    "start": "2858390",
    "end": "2864900"
  },
  {
    "text": "so that we encrypt it in the primary region and we encrypt it with data key for the backup region we write both of",
    "start": "2864900",
    "end": "2872279"
  },
  {
    "text": "those in the primary region and then that gets replicated what we set up in",
    "start": "2872279",
    "end": "2879920"
  },
  {
    "text": "our environment is actually two different accounts but we do it in a different way than Susan described it's",
    "start": "2879920",
    "end": "2885869"
  },
  {
    "text": "we put all of the data and all of the sort of metadata that we keep in dynamo",
    "start": "2885869",
    "end": "2891690"
  },
  {
    "text": "DB and the kms keys in one accounts we call it the data account and then we run",
    "start": "2891690",
    "end": "2897420"
  },
  {
    "text": "all of our code all of the service code that actually accesses this implements this system in a separate account we",
    "start": "2897420",
    "end": "2904109"
  },
  {
    "text": "write I am policies in the data account and grant only in the ability to append",
    "start": "2904109",
    "end": "2909480"
  },
  {
    "text": "and to read data there's actually two different roles one that allows read and one that allows the data write and",
    "start": "2909480",
    "end": "2915329"
  },
  {
    "text": "append and there are no delete permissions that exists that are exercisable by any of",
    "start": "2915329",
    "end": "2920860"
  },
  {
    "text": "our code none of the code runs in the data account the only thing that deletes data are lifecycle policies that's",
    "start": "2920860",
    "end": "2927940"
  },
  {
    "text": "because we cannot afford to have that data get lost by even an accident so",
    "start": "2927940",
    "end": "2934440"
  },
  {
    "text": "what we implement is the service and the data in separate accounts we then do",
    "start": "2934440",
    "end": "2941970"
  },
  {
    "text": "replication into two different regions spanning those two accounts in the two",
    "start": "2941970",
    "end": "2947680"
  },
  {
    "start": "2942000",
    "end": "2942000"
  },
  {
    "text": "regions so the data account spans the two regions the the code account or the",
    "start": "2947680",
    "end": "2952840"
  },
  {
    "text": "service account spans the two regions what you see in the picture here is sort of a drill down of the pieces that run",
    "start": "2952840",
    "end": "2960430"
  },
  {
    "text": "in the data account in the primary region we store and standard we then teardown to infrequent access after one",
    "start": "2960430",
    "end": "2967630"
  },
  {
    "text": "to three months but end depending on data type in the secondary reason we are doing cross region replication of that",
    "start": "2967630",
    "end": "2974920"
  },
  {
    "text": "data and it gets written with infrequent access because we don't actually expect",
    "start": "2974920",
    "end": "2980140"
  },
  {
    "text": "to read it although we want it to be available for a failover event and then",
    "start": "2980140",
    "end": "2986320"
  },
  {
    "text": "we drop it to glaciar fairly quickly after that and that's the long term archive what we set the system up is to",
    "start": "2986320",
    "end": "2993580"
  },
  {
    "text": "do bi-directional replication so both of these regions are active they're paired",
    "start": "2993580",
    "end": "2999850"
  },
  {
    "text": "and we assign customers to either of those regions if we ever have a problem in one of the regions we just redirect",
    "start": "2999850",
    "end": "3006300"
  },
  {
    "text": "traffic to the data access service to the alternative region it then accesses",
    "start": "3006300",
    "end": "3011910"
  },
  {
    "text": "that customers data in the alternative region in the buckets that it was replicated to and in fact if it ends up",
    "start": "3011910",
    "end": "3018060"
  },
  {
    "text": "being it ends up being more than a month old it's going to be in glacier so the service discovers it's in glacier issues",
    "start": "3018060",
    "end": "3025140"
  },
  {
    "text": "expedited recall returns to the caller to 503 come back later",
    "start": "3025140",
    "end": "3030840"
  },
  {
    "text": "caller comes back later access is the object because it's now been recalled and the system now continues to run",
    "start": "3030840",
    "end": "3037560"
  },
  {
    "text": "so our failover in this system is simply redirecting calls to the other region",
    "start": "3037560",
    "end": "3042840"
  },
  {
    "text": "and just letting the process of issuing glacier expedite recall and then accessing the recall",
    "start": "3042840",
    "end": "3048660"
  },
  {
    "text": "objects only for what was needed what was interesting so we don't do on Mass",
    "start": "3048660",
    "end": "3054869"
  },
  {
    "text": "recalls when we failover and remember the first month is in infrequent access",
    "start": "3054869",
    "end": "3060420"
  },
  {
    "text": "anyway that's what the majority of our customers would access and in most circumstances unless they're doing sort",
    "start": "3060420",
    "end": "3066359"
  },
  {
    "text": "of you know long-term reports for compliance the interesting thing about",
    "start": "3066359",
    "end": "3071640"
  },
  {
    "text": "this solution between the the copy in the primary region and the tearing there",
    "start": "3071640",
    "end": "3076740"
  },
  {
    "text": "and the copy and the secondary region and the tearing there is that the total blended cost of this solution for us is",
    "start": "3076740",
    "end": "3083630"
  },
  {
    "text": "1.7 cents per gigabyte per month what that turns out to be is roughly half the",
    "start": "3083630",
    "end": "3090089"
  },
  {
    "text": "cost of what we paid to toast that in a pair of data centers previously so the",
    "start": "3090089",
    "end": "3096890"
  },
  {
    "text": "solution which is more robust has more functionality has more availability has",
    "start": "3096890",
    "end": "3103020"
  },
  {
    "text": "tiered storage management that solution is half the cost of what we were running",
    "start": "3103020",
    "end": "3108839"
  },
  {
    "text": "in our own data centers so let me talk a little bit then about how we use those",
    "start": "3108839",
    "end": "3116010"
  },
  {
    "start": "3112000",
    "end": "3112000"
  },
  {
    "text": "tags to manage expiration remember I said that customers pay for a certain",
    "start": "3116010",
    "end": "3121650"
  },
  {
    "text": "amount of expiration based on what their use case is if a customer is primarily focused on security they may only care",
    "start": "3121650",
    "end": "3128549"
  },
  {
    "text": "for us to keep stuff for three months and then we can roll it off and they can pay less and we can you know not get the",
    "start": "3128549",
    "end": "3135299"
  },
  {
    "text": "cost of keeping it longer but some customers need it for a year majority of our customers need it for a",
    "start": "3135299",
    "end": "3140579"
  },
  {
    "text": "year for PCI requirements and then some customers need it for up to seven years for you know for other compliance needs",
    "start": "3140579",
    "end": "3147089"
  },
  {
    "text": "what we do is we write very single life cycle policies we put 950 customers in",
    "start": "3147089",
    "end": "3153359"
  },
  {
    "text": "each bucket we write 950 life cycle rules every month to be able to expire",
    "start": "3153359",
    "end": "3159299"
  },
  {
    "text": "the tail end of each customers each cups customers retention period by specifying",
    "start": "3159299",
    "end": "3165960"
  },
  {
    "text": "their customer ID and the date remember the date is just about the natural date",
    "start": "3165960",
    "end": "3171930"
  },
  {
    "text": "of the object not when it was written so that gets expired no matter what the you",
    "start": "3171930",
    "end": "3178559"
  },
  {
    "text": "know reorganization that we do and all about that in a second very simple policy it gets updated and actively",
    "start": "3178559",
    "end": "3185240"
  },
  {
    "text": "managed by the system and then we don't do anything for exploration which is really nice that runs in both Regents",
    "start": "3185240",
    "end": "3192770"
  },
  {
    "text": "and so the backup region then runs that and then gets rid of it you know out of the glacier storage we do some selective",
    "start": "3192770",
    "end": "3199790"
  },
  {
    "text": "things for people that have very short retention periods so for the storage",
    "start": "3199790",
    "end": "3205790"
  },
  {
    "start": "3204000",
    "end": "3204000"
  },
  {
    "text": "class transition it's equally you know easy we use the date tag and we roll off",
    "start": "3205790",
    "end": "3211130"
  },
  {
    "text": "a particular month the next month that needs to fall down to infrequent access in the primary region or from infrequent",
    "start": "3211130",
    "end": "3217610"
  },
  {
    "text": "access to glacier in the secondary region which is specify a date tag value and we tell it what storage class to",
    "start": "3217610",
    "end": "3224420"
  },
  {
    "text": "have it progress to these basically get updated every month as we sort of roll forward in time and it requires us only",
    "start": "3224420",
    "end": "3232970"
  },
  {
    "text": "to just assert bucket policies on the buckets that were actively managing for each data type nothing more interesting",
    "start": "3232970",
    "end": "3239870"
  },
  {
    "text": "no more effort that it took you know to write simple policies and punch those",
    "start": "3239870",
    "end": "3244910"
  },
  {
    "text": "out to a couple of API calls it would have taken a long time to manage that stuff otherwise so what else do we do",
    "start": "3244910",
    "end": "3254320"
  },
  {
    "start": "3251000",
    "end": "3251000"
  },
  {
    "text": "because our data can get collected up to a month after it got created because it",
    "start": "3254320",
    "end": "3260780"
  },
  {
    "text": "could be delays in delivering it because customers could have clocks that are set you know off what comes in to us isn't",
    "start": "3260780",
    "end": "3268490"
  },
  {
    "text": "necessarily a sequence of data that is strictly in time order so in that case",
    "start": "3268490",
    "end": "3275420"
  },
  {
    "text": "we still need to bundle that together as well as we can and get it written and then carried on to do the analytics in",
    "start": "3275420",
    "end": "3281840"
  },
  {
    "text": "the system but eventually what we need to do is optimize that storage so what",
    "start": "3281840",
    "end": "3287120"
  },
  {
    "text": "you see in the picture here is a very simple process where each bucket is set up to export inventory that inventory",
    "start": "3287120",
    "end": "3293750"
  },
  {
    "text": "will trigger an X an s3 put you know a put notification which will run a lambda",
    "start": "3293750",
    "end": "3300050"
  },
  {
    "text": "the lambda will then analyze that inventory report to pick off the month",
    "start": "3300050",
    "end": "3307130"
  },
  {
    "text": "based on the tags of data that needs to be reorganized it will just put into an",
    "start": "3307130",
    "end": "3313370"
  },
  {
    "text": "escrow q a note about each one of those months",
    "start": "3313370",
    "end": "3318849"
  },
  {
    "text": "of data for each customer that gets pulled off by a lambda that just starts",
    "start": "3318849",
    "end": "3325059"
  },
  {
    "text": "in parallel lambdas that do the you know that do the reorganization and those",
    "start": "3325059",
    "end": "3330400"
  },
  {
    "text": "just progress through pulling all of these smaller files into a larger file",
    "start": "3330400",
    "end": "3336089"
  },
  {
    "text": "organizing it in time sequence order writing it back and then from that point on whenever we access the data from that",
    "start": "3336089",
    "end": "3343119"
  },
  {
    "text": "time we read the bundle file which is way more efficient cost one API call and",
    "start": "3343119",
    "end": "3348460"
  },
  {
    "text": "we can get and because we can read the in the the sort of table of contents at",
    "start": "3348460",
    "end": "3354250"
  },
  {
    "text": "the beginning we can go forward or back and time or start in the middle so it ends up being very efficient from an s3",
    "start": "3354250",
    "end": "3360430"
  },
  {
    "text": "cost perspective it gives us a much better way to then optimize basically",
    "start": "3360430",
    "end": "3365470"
  },
  {
    "text": "the streaming that is what feeds the sort of batch analytics or search that happens in our system we also use same",
    "start": "3365470",
    "end": "3373900"
  },
  {
    "start": "3372000",
    "end": "3372000"
  },
  {
    "text": "inventory same triggering events same you know analysis of those things to put",
    "start": "3373900",
    "end": "3380290"
  },
  {
    "text": "all of the put all of the information about those objects that are stored for the customer into park' files those",
    "start": "3380290",
    "end": "3389230"
  },
  {
    "text": "park' files are then used through Athena and quick site to then visualize and",
    "start": "3389230",
    "end": "3394690"
  },
  {
    "text": "analyze what's going on with the customer that only requires us to trigger inventory process that same",
    "start": "3394690",
    "end": "3401170"
  },
  {
    "text": "inventory that just got you know run previously we augment that with some other data it's why we don't use the",
    "start": "3401170",
    "end": "3407109"
  },
  {
    "text": "tools that Susan talked about because it it makes a difference to us to integrate",
    "start": "3407109",
    "end": "3412450"
  },
  {
    "text": "that stuff into you know into the data the column or data storage and then",
    "start": "3412450",
    "end": "3418030"
  },
  {
    "text": "enables that kind of analysis on the backend so what happened after we",
    "start": "3418030",
    "end": "3424150"
  },
  {
    "start": "3422000",
    "end": "3422000"
  },
  {
    "text": "implemented this thing at the beginning of the year well we transferred all the data for all",
    "start": "3424150",
    "end": "3430329"
  },
  {
    "text": "of our customers from our physical data center into AWS and during that exercise",
    "start": "3430329",
    "end": "3436589"
  },
  {
    "text": "because it was a lot of data we were able to scale the rights of that over a",
    "start": "3436589",
    "end": "3442960"
  },
  {
    "text": "hundred times our current workload what that meant was we were effectively writing for the",
    "start": "3442960",
    "end": "3448820"
  },
  {
    "text": "period of time that we were putting that in what ends up being a hundred and forty petabytes per month so more than a",
    "start": "3448820",
    "end": "3456200"
  },
  {
    "text": "hundred times the workload I told you that we run at the beginning we were sustaining over 30,000 rights per",
    "start": "3456200",
    "end": "3463850"
  },
  {
    "text": "seconds that are those are individual bundles of data that were being written",
    "start": "3463850",
    "end": "3469490"
  },
  {
    "text": "during that period from way down at the very beginning all the way up to 30,000",
    "start": "3469490",
    "end": "3474680"
  },
  {
    "text": "the latency at the 95th percentile stayed at 200 milliseconds without fail",
    "start": "3474680",
    "end": "3481370"
  },
  {
    "text": "and so the scalability that we saw out of s3 from the volume we run today to",
    "start": "3481370",
    "end": "3487580"
  },
  {
    "text": "the fully scaled up version was unaltered that's all completely",
    "start": "3487580",
    "end": "3493370"
  },
  {
    "text": "attributed to the sort of hash prefix and the partitioning that s3 does behind the covers to be able to then scale out",
    "start": "3493370",
    "end": "3500390"
  },
  {
    "text": "the i/o that gets put behind it read latency state 125 milliseconds at the",
    "start": "3500390",
    "end": "3505580"
  },
  {
    "text": "95th percentile and in fact this wasn't the point we didn't stop at this point because it was a bottleneck because we",
    "start": "3505580",
    "end": "3513740"
  },
  {
    "text": "couldn't make it because it wouldn't go higher we just couldn't produce the workload to go faster we just hadn't",
    "start": "3513740",
    "end": "3520490"
  },
  {
    "text": "imagined that we would try to push it faster and so we ran out of gas there is",
    "start": "3520490",
    "end": "3525530"
  },
  {
    "text": "nothing in our validation they that makes us believe that this is the end and expect it to go you know many times",
    "start": "3525530",
    "end": "3533210"
  },
  {
    "text": "larger than this afterwards at this point I'll let sundar come up and we'll",
    "start": "3533210",
    "end": "3540110"
  },
  {
    "start": "3537000",
    "end": "3537000"
  },
  {
    "text": "recap",
    "start": "3540110",
    "end": "3542770"
  },
  {
    "text": "you know see how alert logic is using management capabilities real quick recap",
    "start": "3549920",
    "end": "3557569"
  },
  {
    "text": "of what you heard in this session we talked about how you can organize your data using object tags setup lifecycle",
    "start": "3557569",
    "end": "3563299"
  },
  {
    "text": "policies or access control policies based on those tags talked about all the",
    "start": "3563299",
    "end": "3568520"
  },
  {
    "text": "tools available to you to understand your data so the new capabilities in s3 inventory how you can query that with",
    "start": "3568520",
    "end": "3574190"
  },
  {
    "text": "Athena now talk about all the tools available to act on those insights new",
    "start": "3574190",
    "end": "3579740"
  },
  {
    "text": "CLR capabilities for ownership override default bucket encryption policies or how we can set up logging for all API",
    "start": "3579740",
    "end": "3587420"
  },
  {
    "text": "level events with cloud trend data events if you want know more there's a",
    "start": "3587420",
    "end": "3593420"
  },
  {
    "text": "lot more content we have for you here are some of the sessions that we recommend now even if you're not pre",
    "start": "3593420",
    "end": "3598520"
  },
  {
    "text": "registered for these sessions we do reserve 25% of the seats in these sessions for walk-ins so if you can make",
    "start": "3598520",
    "end": "3605690"
  },
  {
    "text": "it to these sessions it's a good chance you'll have a seat for yourself take some time note down and down some of",
    "start": "3605690",
    "end": "3611030"
  },
  {
    "text": "these sessions I want to say thank you I'm going to leave that yeah I'm going",
    "start": "3611030",
    "end": "3616609"
  },
  {
    "text": "to say thank you didn't mention we'll have time for questions we're just about time but Susan myself and Paul and a few",
    "start": "3616609",
    "end": "3623930"
  },
  {
    "text": "others will be available outside the room if you have questions to answer any any that you have look for folks wearing",
    "start": "3623930",
    "end": "3629720"
  },
  {
    "text": "a label that looks like this and you can ask us questions on s3 or in Galatia",
    "start": "3629720",
    "end": "3637590"
  },
  {
    "text": "[Applause]",
    "start": "3637590",
    "end": "3640449"
  }
]
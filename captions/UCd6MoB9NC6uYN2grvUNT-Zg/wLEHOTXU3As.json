[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "hello all and welcome to this session this is SRV three-one-seven unlocking",
    "start": "89",
    "end": "6750"
  },
  {
    "text": "high-performance computing for financial services with several lists compute my",
    "start": "6750",
    "end": "11910"
  },
  {
    "text": "name is harsh Moneypenny I'm a Solutions Architect with AWS and it's my pleasure",
    "start": "11910",
    "end": "17430"
  },
  {
    "text": "to welcome miss bin Liu from Fannie Mae she's a senior director of risk modeling",
    "start": "17430",
    "end": "23279"
  },
  {
    "text": "and analytics she's been she has over 20 years of",
    "start": "23279",
    "end": "29820"
  },
  {
    "text": "experience developing high performance computing using large scale Monte Carlo",
    "start": "29820",
    "end": "35309"
  },
  {
    "text": "simulation at Fannie Mae and this",
    "start": "35309",
    "end": "40379"
  },
  {
    "text": "particular use case was developed by Ben",
    "start": "40379",
    "end": "45480"
  },
  {
    "text": "and her colleague John Simon who is also in the room to essentially develop a",
    "start": "45480",
    "end": "52800"
  },
  {
    "text": "Monte Carlo simulation on AWS as the industry's first simulation using AWS",
    "start": "52800",
    "end": "58859"
  },
  {
    "text": "lambda thank you all right",
    "start": "58859",
    "end": "65119"
  },
  {
    "start": "64000",
    "end": "64000"
  },
  {
    "text": "just the level said we're gonna first review the session objectives this is an",
    "start": "65119",
    "end": "71130"
  },
  {
    "text": "advanced level session I'm assuming you have background on AWS services",
    "start": "71130",
    "end": "76369"
  },
  {
    "text": "particularly lambda and s3 because we're gonna be talking about lambda a great",
    "start": "76369",
    "end": "82080"
  },
  {
    "text": "deal of lambda but in case you are not familiar with this service I will certainly give you an overview and then",
    "start": "82080",
    "end": "90380"
  },
  {
    "text": "dive into the session details there are three segments in this session the first",
    "start": "90380",
    "end": "97590"
  },
  {
    "text": "segment is will review the grid computing architecture some of the use",
    "start": "97590",
    "end": "104820"
  },
  {
    "text": "cases of HPC and then I will set the stage for bin lu to to walk us through",
    "start": "104820",
    "end": "110369"
  },
  {
    "text": "Fannie Mae use case of how wanta Carlo simulations were executed on AWS using",
    "start": "110369",
    "end": "118020"
  },
  {
    "text": "lambda and then the final segment will be a live demo of",
    "start": "118020",
    "end": "123630"
  },
  {
    "text": "lambda functions using the MapReduce framework right let's get started",
    "start": "123630",
    "end": "130429"
  },
  {
    "text": "overview this is the segment 1 where we'll be reviewing HPC and grid",
    "start": "130430",
    "end": "135959"
  },
  {
    "text": "computing framework and how to implement such framework or an AWS HPC",
    "start": "135959",
    "end": "144860"
  },
  {
    "text": "high-performance computing is is a framework that allows users to to solve",
    "start": "144860",
    "end": "153120"
  },
  {
    "text": "complex business problems for which applications require large amounts of",
    "start": "153120",
    "end": "158310"
  },
  {
    "text": "compute infrastructure to power these application workloads the",
    "start": "158310",
    "end": "164660"
  },
  {
    "text": "high-performance computing world is evolving continually and rapidly and the",
    "start": "164660",
    "end": "172350"
  },
  {
    "text": "main motivation here the main driver here is both economics and also technical as HPC systems are executing a",
    "start": "172350",
    "end": "184980"
  },
  {
    "text": "large amount of computations there is a need for a large scale of compute",
    "start": "184980",
    "end": "190950"
  },
  {
    "text": "resources that are required to execute these jobs but also applications now",
    "start": "190950",
    "end": "197250"
  },
  {
    "text": "have ability to not only scale out and also the ability to have high scale",
    "start": "197250",
    "end": "205010"
  },
  {
    "text": "performant and low cost infrastructure access when you extend this framework into the cloud environment why is it",
    "start": "205010",
    "end": "214500"
  },
  {
    "text": "important for customers to have this capability where they can extend their",
    "start": "214500",
    "end": "219600"
  },
  {
    "text": "grid computing framework to into the cloud because workloads particularly HPC",
    "start": "219600",
    "end": "225329"
  },
  {
    "text": "and grid computing workloads require massive amounts of parallel computing",
    "start": "225329",
    "end": "231420"
  },
  {
    "text": "architecture requirements and especially in the financial services industry",
    "start": "231420",
    "end": "237680"
  },
  {
    "text": "customers or need the grid computing framework that can tolerate some latency",
    "start": "237680",
    "end": "244799"
  },
  {
    "text": "and should be resilient but the optimization is more focused",
    "start": "244799",
    "end": "250380"
  },
  {
    "text": "overall throughput using compute grid so that is some of the characteristics of",
    "start": "250380",
    "end": "256350"
  },
  {
    "text": "HPC implementation on grid many organizations are now also looking to",
    "start": "256350",
    "end": "263210"
  },
  {
    "text": "new ways to perform compute intensive operations compute intensive tasks at a",
    "start": "263210",
    "end": "269670"
  },
  {
    "text": "lower cost so that is that is a significant driver for many customers and ews",
    "start": "269670",
    "end": "276900"
  },
  {
    "text": "provides virtually unlimited compute and storage options for providing such",
    "start": "276900",
    "end": "283230"
  },
  {
    "text": "framework and the capacity to launch on",
    "start": "283230",
    "end": "288690"
  },
  {
    "text": "on-demand resources and ability to auto scale provision resources on the fly and",
    "start": "288690",
    "end": "296790"
  },
  {
    "text": "and essentially ability to have resources that that fits your computer",
    "start": "296790",
    "end": "302370"
  },
  {
    "text": "requirements and just have enough capacity without the need to worry about",
    "start": "302370",
    "end": "309170"
  },
  {
    "text": "either idle time or lack of capacity with the compute grid right so with that",
    "start": "309170",
    "end": "318690"
  },
  {
    "start": "317000",
    "end": "317000"
  },
  {
    "text": "being said now let's talk about some of the use cases of HPC and some of the implementations of HPC at a very high",
    "start": "318690",
    "end": "326370"
  },
  {
    "text": "level there are two variants of HPC there is a cluster HPC and there is a",
    "start": "326370",
    "end": "333330"
  },
  {
    "text": "grid HPC that you could implement there are two significant differences between",
    "start": "333330",
    "end": "338490"
  },
  {
    "text": "the two when you start implementing these cluster computing and grid",
    "start": "338490",
    "end": "344400"
  },
  {
    "text": "computing are two flavors of computing standards that do support HPC",
    "start": "344400",
    "end": "350610"
  },
  {
    "text": "parallelism right on the left side you see HPC clusters these are for",
    "start": "350610",
    "end": "357360"
  },
  {
    "text": "application workloads that require tightly coupled integrations and there",
    "start": "357360",
    "end": "363330"
  },
  {
    "text": "are lazy latency-sensitive applications they tend to use cluster HPC more often",
    "start": "363330",
    "end": "369270"
  },
  {
    "text": "and some of the characteristics for cluster HPC is you essentially need to",
    "start": "369270",
    "end": "375960"
  },
  {
    "text": "have access to your computer infrastructure that is typically in the",
    "start": "375960",
    "end": "382500"
  },
  {
    "text": "form PC two instances that are that can be leveraged again a lot of variations with",
    "start": "382500",
    "end": "389940"
  },
  {
    "text": "an ec2 right you have the compute optimize do you have the storage optimized that there are accelerated",
    "start": "389940",
    "end": "396720"
  },
  {
    "text": "compute options in easy to and then again with the with the latest",
    "start": "396720",
    "end": "403590"
  },
  {
    "text": "generation of ec2 instances you could also have Intel Xeon processors essentially the advanced l",
    "start": "403590",
    "end": "410280"
  },
  {
    "text": "floating-point operations that can be implemented encrypt data at rest right and boost",
    "start": "410280",
    "end": "417840"
  },
  {
    "text": "your processor clock rate for peak loads so with some configuration tweaks like",
    "start": "417840",
    "end": "425520"
  },
  {
    "text": "for example you could do placement groups and enhance networking place when",
    "start": "425520",
    "end": "431340"
  },
  {
    "text": "groups are important where if you have requirements for running HPC compute",
    "start": "431340",
    "end": "439020"
  },
  {
    "text": "where there was a lot of data traffic going between the compute nodes and the",
    "start": "439020",
    "end": "444570"
  },
  {
    "text": "storage underlying storage devices then you would obviously have the proximity matters because why does proximity",
    "start": "444570",
    "end": "452130"
  },
  {
    "text": "matters in HPC clusters because you want to reduce your latency and jitter when",
    "start": "452130",
    "end": "458100"
  },
  {
    "text": "multiple task nodes are coordinating the tasks to run HPC for on the other side",
    "start": "458100",
    "end": "467370"
  },
  {
    "text": "of the equation which is the focus of this session there is great HPC great HPC is",
    "start": "467370",
    "end": "473520"
  },
  {
    "text": "different in the sense these are loosely coupled parallel parallel infrastructure",
    "start": "473520",
    "end": "482610"
  },
  {
    "text": "right it can it is not as latency",
    "start": "482610",
    "end": "487710"
  },
  {
    "text": "sensitive as cluster HPC s are however you you need to be able to have scaling",
    "start": "487710",
    "end": "495930"
  },
  {
    "text": "ability both scale out and scale in ability and also the obviously which will reduce costs when compared to",
    "start": "495930",
    "end": "502800"
  },
  {
    "text": "running a steady state application like a cluster HPC write and state is very",
    "start": "502800",
    "end": "510960"
  },
  {
    "text": "important if you have workloads that have state information that needs to be",
    "start": "510960",
    "end": "517459"
  },
  {
    "text": "implemented then implementing grid HPC with serverless lambda you will have to",
    "start": "517459",
    "end": "525600"
  },
  {
    "text": "make sure you have state written into persistent storage either s3 or dynamo",
    "start": "525600",
    "end": "532350"
  },
  {
    "text": "to make sure that persistent state information is acquired by the next",
    "start": "532350",
    "end": "538949"
  },
  {
    "text": "processing worker so that is the key difference there that a these are",
    "start": "538949",
    "end": "545610"
  },
  {
    "text": "loosely coupled applications that are mostly suitable for good HPC and also if",
    "start": "545610",
    "end": "552360"
  },
  {
    "text": "you have any state information that requires as part of your processing workload you need to write your state to",
    "start": "552360",
    "end": "559339"
  },
  {
    "text": "persistent storage so that's the key differences and then there is also a variation that we have seen in the",
    "start": "559339",
    "end": "565319"
  },
  {
    "text": "industry where you could technically have a grid of clusters essentially what",
    "start": "565319",
    "end": "571800"
  },
  {
    "text": "you're gonna have is you you're using a grid strategy to implement parallelize",
    "start": "571800",
    "end": "577199"
  },
  {
    "text": "and parallel workloads coordinated through cluster HPC s right so that's",
    "start": "577199",
    "end": "582209"
  },
  {
    "text": "the third option but mostly it is the either the cluster HPC workloads or grid",
    "start": "582209",
    "end": "587399"
  },
  {
    "text": "HPC and the focus of this session will be great HPC alright now that we have",
    "start": "587399",
    "end": "594779"
  },
  {
    "text": "reviewed HPC workloads and now let's look into how grid computing is",
    "start": "594779",
    "end": "602850"
  },
  {
    "text": "implemented across financial services industry and this is not by the way when I say good computing implementation this",
    "start": "602850",
    "end": "610559"
  },
  {
    "text": "is not specific to financial services only this is extendable to pretty much any workload that has these certain",
    "start": "610559",
    "end": "617819"
  },
  {
    "text": "characteristics we are going to talk about what are the grid computing characteristics later during the session",
    "start": "617819",
    "end": "624059"
  },
  {
    "text": "but for financial services financial services institutions the",
    "start": "624059",
    "end": "633350"
  },
  {
    "text": "core concepts that some of the workloads are financial simulations are essential",
    "start": "633350",
    "end": "640110"
  },
  {
    "text": "to the operations of financial services institutions right they need to be able",
    "start": "640110",
    "end": "645779"
  },
  {
    "text": "to do a lot of simulations for based on the market feeds and able",
    "start": "645779",
    "end": "651380"
  },
  {
    "text": "to manage why do they need to do simulations because they have to a identify risks and manage risks optimize",
    "start": "651380",
    "end": "660680"
  },
  {
    "text": "on capital and make informed investment decisions and pricing decisions based on",
    "start": "660680",
    "end": "666050"
  },
  {
    "text": "the simulation results right so there are real tangible benefits of running",
    "start": "666050",
    "end": "672110"
  },
  {
    "text": "simulations large-scale simulations for product development for financial services institutions the financial",
    "start": "672110",
    "end": "681019"
  },
  {
    "text": "services industry as such has long advanced grid computing the some of the",
    "start": "681019",
    "end": "687920"
  },
  {
    "text": "common patterns is is over here a capital management and reporting these are regulatory requirements that are",
    "start": "687920",
    "end": "695600"
  },
  {
    "text": "part they're mandated by law where for example seek our solvency in frtb",
    "start": "695600",
    "end": "700790"
  },
  {
    "text": "these are some of the requirements to make sure they can do again that there",
    "start": "700790",
    "end": "707120"
  },
  {
    "text": "was capital stress testing that's done we're gonna be touching on that topic later that's one use case the second one",
    "start": "707120",
    "end": "713149"
  },
  {
    "text": "is risk management again portfolio simulations are central to running risk",
    "start": "713149",
    "end": "719839"
  },
  {
    "text": "management by portfolio managers they do they are to optimize not only for",
    "start": "719839",
    "end": "725600"
  },
  {
    "text": "opportunities but also look for for new",
    "start": "725600",
    "end": "731750"
  },
  {
    "text": "opportunities and cost savings and any impact of hypothetical changes be it regulatory changes or market conditions",
    "start": "731750",
    "end": "738620"
  },
  {
    "text": "and how how to evaluate those effects on the workload right and then contract",
    "start": "738620",
    "end": "745610"
  },
  {
    "text": "pricing and valuation this is also very very important use case for many FS is",
    "start": "745610",
    "end": "752050"
  },
  {
    "text": "emphasize financial services institutions this is to calculate and do",
    "start": "752050",
    "end": "759459"
  },
  {
    "text": "simulations for credit and interest rate derivatives and then finally for product",
    "start": "759459",
    "end": "764870"
  },
  {
    "text": "and strategy development so there are real concrete use cases for grid computing that has been already being",
    "start": "764870",
    "end": "772459"
  },
  {
    "text": "implemented in the industry today this particular use case is going to go",
    "start": "772459",
    "end": "780980"
  },
  {
    "text": "deeper into are some of the complexities with running financial services modeling so",
    "start": "780980",
    "end": "787250"
  },
  {
    "start": "787000",
    "end": "787000"
  },
  {
    "text": "let's go one step deeper now now that we understand grid computing HPC and their",
    "start": "787250",
    "end": "792890"
  },
  {
    "text": "use case in the financial services industry why is financial modeling so complex right if you if you look at that",
    "start": "792890",
    "end": "800870"
  },
  {
    "text": "they need to conduct compute intensive workloads the calculations the",
    "start": "800870",
    "end": "806630"
  },
  {
    "text": "simulations in areas such as risk management regulatory compliance visit",
    "start": "806630",
    "end": "812600"
  },
  {
    "text": "all these are are not new to the financial services industry however what",
    "start": "812600",
    "end": "818780"
  },
  {
    "text": "has changed in the recent past is the volume of data that they are dealing with and also increased timeliness of",
    "start": "818780",
    "end": "827750"
  },
  {
    "text": "these calculations so timely calculations with massive amount of massive influx of data that is causing a",
    "start": "827750",
    "end": "835310"
  },
  {
    "text": "lot of issues with the on-premise grid infrastructure that you may have I'll",
    "start": "835310",
    "end": "842150"
  },
  {
    "text": "tell you some of the complexities here or so the first one is again now I told you about the ability to do run large",
    "start": "842150",
    "end": "849560"
  },
  {
    "text": "scale simulations for risk analysis models right when you're doing those",
    "start": "849560",
    "end": "854630"
  },
  {
    "text": "type of modeling some of the issues that the portfolio managers must be looking at is well what are the market risks",
    "start": "854630",
    "end": "861290"
  },
  {
    "text": "what are the credit risks and liquidity risks in general fluidity in the in the",
    "start": "861290",
    "end": "868070"
  },
  {
    "text": "financial markets right so add that with the second variable being broad",
    "start": "868070",
    "end": "875870"
  },
  {
    "text": "regulatory requirements these are when we see car see car is a stress testing",
    "start": "875870",
    "end": "883610"
  },
  {
    "text": "mandated by Federal Reserve to large American banks again this is to test the",
    "start": "883610",
    "end": "889280"
  },
  {
    "text": "capital adequacy same thing with dodd-frank in dodd-frank is American",
    "start": "889280",
    "end": "895850"
  },
  {
    "text": "legislation implemented widely this is an offshoot of the 2008 financial crisis",
    "start": "895850",
    "end": "902570"
  },
  {
    "text": "that led to dodd-frank Act so and then Basel 3 this is a solvency requirements",
    "start": "902570",
    "end": "910550"
  },
  {
    "text": "for an international framework that is implemented in the financial services",
    "start": "910550",
    "end": "915850"
  },
  {
    "text": "industry so you have these massive amounts of risk analysis that customers",
    "start": "915850",
    "end": "921339"
  },
  {
    "text": "have to perform ad the regulatory requirements to the mix and then you",
    "start": "921339",
    "end": "926859"
  },
  {
    "text": "have to have the third variable and the complexity is like I said a large-scale",
    "start": "926859",
    "end": "933970"
  },
  {
    "text": "compute intensive calculations that must be done in order to not just for existing products but also developing",
    "start": "933970",
    "end": "940389"
  },
  {
    "text": "new financial products right so if you add these three together what happens is",
    "start": "940389",
    "end": "946419"
  },
  {
    "text": "there is a massive amounts of compute resources that don't require to power",
    "start": "946419",
    "end": "952629"
  },
  {
    "text": "these application workloads right and then it - essentially to run simulations",
    "start": "952629",
    "end": "958919"
  },
  {
    "text": "so with with wide variety of simulations",
    "start": "958919",
    "end": "964540"
  },
  {
    "text": "one of the patterns that we have observed is again now let's say you want",
    "start": "964540",
    "end": "969970"
  },
  {
    "text": "to do risk based simulations for four institution they could do one simulation",
    "start": "969970",
    "end": "976540"
  },
  {
    "text": "method that we come across is Monte Carlo simulation which is what Bill Liu",
    "start": "976540",
    "end": "982360"
  },
  {
    "text": "and others have performed so let's touch a little bit on that what is Monte Carlo simulation now that",
    "start": "982360",
    "end": "989230"
  },
  {
    "text": "we understand the complexity of the modeling itself how is the modeling done through Monte Carlo simulation is the is",
    "start": "989230",
    "end": "996009"
  },
  {
    "start": "996000",
    "end": "996000"
  },
  {
    "text": "the next point so what is Monte Carlo simulation it's a broad class of",
    "start": "996009",
    "end": "1001259"
  },
  {
    "text": "computational algorithms that are applied to you to obtain numerical results Monte Carlo simulations are used",
    "start": "1001259",
    "end": "1009389"
  },
  {
    "text": "to model the probability of different outcomes in a process that can easily be",
    "start": "1009389",
    "end": "1016949"
  },
  {
    "text": "predicted due to the intervention of random variables so that's that's the",
    "start": "1016949",
    "end": "1022189"
  },
  {
    "text": "definition of Monte Carlo there are multiple methods of Monte Carlo simulation essentially it's a it's a",
    "start": "1022189",
    "end": "1029339"
  },
  {
    "text": "multi-step process the first step is you will define what your domain of possible",
    "start": "1029339",
    "end": "1034889"
  },
  {
    "text": "inputs are and then you perform computations large-scale computations on those inputs and then you need to",
    "start": "1034889",
    "end": "1041970"
  },
  {
    "text": "aggregate the results and then start ingesting those results for your evaluations right so that is",
    "start": "1041970",
    "end": "1049130"
  },
  {
    "text": "Monte Carlo simulation at a very high level what are the applications for Monte Carlo simulation is it standard",
    "start": "1049130",
    "end": "1056630"
  },
  {
    "text": "the only specific to financial services industry not really it has wide spectrum",
    "start": "1056630",
    "end": "1062180"
  },
  {
    "text": "of implementations physical sciences again in engineering micro electronics",
    "start": "1062180",
    "end": "1069320"
  },
  {
    "text": "to fluid dynamics to telecommunications and we just spoke about the financial",
    "start": "1069320",
    "end": "1074720"
  },
  {
    "text": "services industry so finance and business for risk analysis computational",
    "start": "1074720",
    "end": "1080630"
  },
  {
    "text": "biology and there is also game simulation so in artificial intelligence Monte Carlo simulation is used for game",
    "start": "1080630",
    "end": "1088160"
  },
  {
    "text": "simulation one such implementation is actually used through research operation so that it's",
    "start": "1088160",
    "end": "1096770"
  },
  {
    "text": "wider implementation this is not just specific to financial services industry",
    "start": "1096770",
    "end": "1103540"
  },
  {
    "text": "so now we have reviewed a lot we reviewed HPC the grid computing and then",
    "start": "1103540",
    "end": "1109910"
  },
  {
    "text": "we understood there is a complexity involved with financial modelling and then within the financial modeling we",
    "start": "1109910",
    "end": "1116720"
  },
  {
    "text": "have seen one such use case which is Monte Carlo simulation now now let me understand what the business need is",
    "start": "1116720",
    "end": "1123320"
  },
  {
    "text": "what are some of the issues of writing such simulations on premise right the",
    "start": "1123320",
    "end": "1130340"
  },
  {
    "start": "1130000",
    "end": "1130000"
  },
  {
    "text": "first and foremost issue that you run into running large scale simulations is",
    "start": "1130340",
    "end": "1137170"
  },
  {
    "text": "large capital expenditure capex is a very big issue when you when it comes to",
    "start": "1137170",
    "end": "1144050"
  },
  {
    "text": "Grid infrastructure why is that because you would to do how many are familiar",
    "start": "1144050",
    "end": "1151240"
  },
  {
    "text": "but with grid computing so yeah so you",
    "start": "1151240",
    "end": "1158000"
  },
  {
    "text": "you probably have seen this in the in your own environments where large",
    "start": "1158000",
    "end": "1165320"
  },
  {
    "text": "investments are needed to stand up grid computing infrastructure mostly you",
    "start": "1165320",
    "end": "1173090"
  },
  {
    "text": "would have a two year plan or a three year plan you quantify your require and then you start building your",
    "start": "1173090",
    "end": "1179660"
  },
  {
    "text": "infrastructure based on the analysis that you have and then what happens is you you would have to continually",
    "start": "1179660",
    "end": "1187660"
  },
  {
    "text": "iterate and maintain a an internal SLA or an Ola to to maintain the uptime of",
    "start": "1187660",
    "end": "1194900"
  },
  {
    "text": "that service right so just think about for a second if you're doing if your",
    "start": "1194900",
    "end": "1201980"
  },
  {
    "text": "requirement is you need to have a resilient architecture for grid",
    "start": "1201980",
    "end": "1209330"
  },
  {
    "text": "computing you would have to think about H a right H a clustering is key to that making sure there is no single point of",
    "start": "1209330",
    "end": "1215240"
  },
  {
    "text": "failure will you talk about H a clustering there is a lot of issues there are a lot of variables that that",
    "start": "1215240",
    "end": "1223340"
  },
  {
    "text": "the data scientists may not be looking at but the infrastructure engineers will be looking at for example what happens",
    "start": "1223340",
    "end": "1229490"
  },
  {
    "text": "if my storage layer the access to the storage layer is broke so you would have",
    "start": "1229490",
    "end": "1235520"
  },
  {
    "text": "to do some sort of redundancy there how do people do that maybe if you have fiber channel arrays you probably have",
    "start": "1235520",
    "end": "1242030"
  },
  {
    "text": "multiple dual hp8 cards running great and then if you have NAS devices you probably have multiple NIC",
    "start": "1242030",
    "end": "1249350"
  },
  {
    "text": "cards teaming either NIC teaming or NIC bonding the hypervisor layer and then",
    "start": "1249350",
    "end": "1254360"
  },
  {
    "text": "that would be connected to dual switches then that has to be through H SRP",
    "start": "1254360",
    "end": "1259670"
  },
  {
    "text": "implementation that's just two variables right and then you may have to do some",
    "start": "1259670",
    "end": "1266390"
  },
  {
    "text": "sort of a dis mentoring for OS a lot of overhead and a lot of heavy lifting just",
    "start": "1266390",
    "end": "1272600"
  },
  {
    "text": "to support that infrastructure right and then there is limited capacity",
    "start": "1272600",
    "end": "1278060"
  },
  {
    "text": "right I mean this is you have provisioned grid and now if you have a",
    "start": "1278060",
    "end": "1284000"
  },
  {
    "text": "necessity to scale why do you have to have the ability to scale because as the",
    "start": "1284000",
    "end": "1289910"
  },
  {
    "text": "market conditions are changing there is always and and add to their regulatory",
    "start": "1289910",
    "end": "1295670"
  },
  {
    "text": "requirements to go back and do simulations for the last say X ears so",
    "start": "1295670",
    "end": "1301820"
  },
  {
    "text": "you would have to ingest a large amount of datasets and be able to do simulations which means you need to be",
    "start": "1301820",
    "end": "1306980"
  },
  {
    "text": "have having that level of expandability the elasticity and scaling",
    "start": "1306980",
    "end": "1313380"
  },
  {
    "text": "options right that is one of the issues what we have encountered with customers",
    "start": "1313380",
    "end": "1319440"
  },
  {
    "text": "having issues with on-prem grade right and then on Prem grid has certain course",
    "start": "1319440",
    "end": "1327150"
  },
  {
    "text": "so if you are a smaller financial institution maybe you would have 10,000",
    "start": "1327150",
    "end": "1332880"
  },
  {
    "text": "cores CPU cores or so anyone familiar with over 50,000 course here so there if",
    "start": "1332880",
    "end": "1340920"
  },
  {
    "text": "you are a mid scale financial institution it is not uncommon to have a",
    "start": "1340920",
    "end": "1347580"
  },
  {
    "text": "compute grid with 50,000 course requirement right and then if you are talking about a global financial",
    "start": "1347580",
    "end": "1353040"
  },
  {
    "text": "institution it's not uncommon to have requirement for a hundred thousand cores just to run the various risk analysis",
    "start": "1353040",
    "end": "1362340"
  },
  {
    "text": "and simulations so the point I'm trying to make here is when you have that complexity and when you have these",
    "start": "1362340",
    "end": "1368640"
  },
  {
    "text": "variable workloads you just cannot have a static grid with the static compute",
    "start": "1368640",
    "end": "1374900"
  },
  {
    "text": "type right before the various workload so maybe IO intensive workloads so maybe",
    "start": "1374900",
    "end": "1380850"
  },
  {
    "text": "CPU intensive workload so far some workloads may require a lot of in memory",
    "start": "1380850",
    "end": "1386250"
  },
  {
    "text": "caching requirements but then your on-prem grid cannot really adjust to all these computational changes right so",
    "start": "1386250",
    "end": "1393360"
  },
  {
    "text": "it's it's a static grid unless you go through the refresh cycle every so often",
    "start": "1393360",
    "end": "1399120"
  },
  {
    "text": "and update the grid with me you compute and storage layer so it's always a",
    "start": "1399120",
    "end": "1405510"
  },
  {
    "text": "constant refresh cycle that you're and also limitations that you're bound with right and then regulatory and market",
    "start": "1405510",
    "end": "1412400"
  },
  {
    "text": "fluctuations we did talk about that that why is that important because that will change the amount of storage layer that",
    "start": "1412400",
    "end": "1420960"
  },
  {
    "text": "you would have to configure and also the amount of data that you're going to be ingesting into grid computing right so",
    "start": "1420960",
    "end": "1428370"
  },
  {
    "text": "finally all these issues end up with limiting your ability to run simulations",
    "start": "1428370",
    "end": "1435020"
  },
  {
    "text": "because your data center of capacity is limited this is where it starts to hurt",
    "start": "1435020",
    "end": "1441890"
  },
  {
    "text": "customers because they cannot either or they have to wait for expanding their",
    "start": "1441890",
    "end": "1447289"
  },
  {
    "text": "grid computing framework under we expand the infrastructure to support new",
    "start": "1447289",
    "end": "1453020"
  },
  {
    "text": "workloads or increase the simulations right so just look at some of the",
    "start": "1453020",
    "end": "1459049"
  },
  {
    "text": "patterns in in a HPC compute scenario",
    "start": "1459049",
    "end": "1467000"
  },
  {
    "text": "what happens is you don't know what are some of the simulation requirements would look like as because it's all",
    "start": "1467000",
    "end": "1473000"
  },
  {
    "text": "variable based on the market conditions on the x-axis here depicting here actual demand for compute",
    "start": "1473000",
    "end": "1479809"
  },
  {
    "text": "so your data scientists may be asking hey I need to run petabyte scale grid",
    "start": "1479809",
    "end": "1485240"
  },
  {
    "text": "grid operation grid simulation so I would need so many compute cycles to run",
    "start": "1485240",
    "end": "1493460"
  },
  {
    "text": "my simulation and then on the y-axis you have your provisioning right we're provisioning times to increase your",
    "start": "1493460",
    "end": "1500059"
  },
  {
    "text": "compute grid so what happens here is say you run into a situation where your",
    "start": "1500059",
    "end": "1506450"
  },
  {
    "text": "on-premise grid is at capacity and then there is new requirements to expand the",
    "start": "1506450",
    "end": "1511640"
  },
  {
    "text": "newer simulations or new product development then you have to go through server acquisition and provisioning of",
    "start": "1511640",
    "end": "1518090"
  },
  {
    "text": "new servers and attaching that to the grid and expanding the grid so obviously as you can clearly see there are times",
    "start": "1518090",
    "end": "1524630"
  },
  {
    "text": "where your projects could get delayed because of provisioning of the server",
    "start": "1524630",
    "end": "1530570"
  },
  {
    "text": "infrastructure for an expanding grid so that is one of the key issues what we",
    "start": "1530570",
    "end": "1535940"
  },
  {
    "text": "have observed and ultimately what happens is grid adding capacity is both",
    "start": "1535940",
    "end": "1545120"
  },
  {
    "text": "time intensive and capital intensive so that that has a direct effect for many",
    "start": "1545120",
    "end": "1551809"
  },
  {
    "text": "customers right and grid users which are typically the data scientists seek the",
    "start": "1551809",
    "end": "1558770"
  },
  {
    "text": "fastest possible time to results because they have a large data set that they have to worry about so in the end",
    "start": "1558770",
    "end": "1565230"
  },
  {
    "text": "the the jobs get delayed the jobs get queued and that will essentially",
    "start": "1565230",
    "end": "1570299"
  },
  {
    "text": "throttle your innovation that that is the net effect of having limited grid",
    "start": "1570299",
    "end": "1575399"
  },
  {
    "text": "capacity in your on-premise infrastructure so with that problem statement then we started working with",
    "start": "1575399",
    "end": "1583950"
  },
  {
    "text": "customers and we have seen the financial services customers is attempting to",
    "start": "1583950",
    "end": "1590389"
  },
  {
    "text": "extend their existing Grid infrastructure into AWS cloud so you still have your own from grid and then",
    "start": "1590389",
    "end": "1597480"
  },
  {
    "text": "now you're extending the compute capabilities into AWS and how is that",
    "start": "1597480",
    "end": "1602700"
  },
  {
    "text": "down and why is it done is what we're gonna talk next this is about grid",
    "start": "1602700",
    "end": "1607799"
  },
  {
    "start": "1603000",
    "end": "1603000"
  },
  {
    "text": "computing on AWS so by building and running compute grids with the AWS",
    "start": "1607799",
    "end": "1613830"
  },
  {
    "text": "companies are able to leverage and execute a larger number of parallel tasks which is very key like I've",
    "start": "1613830",
    "end": "1619740"
  },
  {
    "text": "mentioned about the degree of parallelism has a direct impact on your",
    "start": "1619740",
    "end": "1625830"
  },
  {
    "text": "simulations right and increase the speed and analysis and reduce time to results",
    "start": "1625830",
    "end": "1631490"
  },
  {
    "text": "how is that done so let's let's talk about one one by one some of the issues",
    "start": "1631490",
    "end": "1637169"
  },
  {
    "text": "that we earlier discussed so virtually unlimited compute and storage resources you may have heard we well some of the",
    "start": "1637169",
    "end": "1646169"
  },
  {
    "text": "best practices that we advocate is you need to decoupled compute and storage not only the add from a from a",
    "start": "1646169",
    "end": "1653220"
  },
  {
    "text": "breakpoint analysis but also to be able to scale independently of each other and",
    "start": "1653220",
    "end": "1659190"
  },
  {
    "text": "you have once you have your storage layer separate from your computer you",
    "start": "1659190",
    "end": "1665130"
  },
  {
    "text": "are no longer tied to idle time of compute you could do variations in the",
    "start": "1665130",
    "end": "1670799"
  },
  {
    "text": "compute and also variations with the compute types to achieve your your",
    "start": "1670799",
    "end": "1677010"
  },
  {
    "text": "processing needs various compute options so this is very important so as I told",
    "start": "1677010",
    "end": "1684090"
  },
  {
    "text": "you earlier the town from its grid you're essentially buying into a hardware that you feel will be",
    "start": "1684090",
    "end": "1690799"
  },
  {
    "text": "satisfactorily be able to apply all the complicate computational needs right but",
    "start": "1690799",
    "end": "1697169"
  },
  {
    "text": "then what happens is as your workload characteristics change you are you no longer will be able to",
    "start": "1697169",
    "end": "1703020"
  },
  {
    "text": "change your compute infrastructure that issue goes away with AWS because the",
    "start": "1703020",
    "end": "1709140"
  },
  {
    "text": "compute layer you have wide variety of ec2 flavors but if you really need HPC",
    "start": "1709140",
    "end": "1715140"
  },
  {
    "text": "clusters to be run on ec2 but on grid computing side you can easily extend",
    "start": "1715140",
    "end": "1720990"
  },
  {
    "text": "that to AWS lambda so that gives you a greater amount of flexibility lower TCO",
    "start": "1720990",
    "end": "1727710"
  },
  {
    "text": "and not to have to worry about running and maintaining virtual machines and all",
    "start": "1727710",
    "end": "1733680"
  },
  {
    "text": "the bootstrapping that has to go through virtual machines right so that's their cost optimization of course as as I",
    "start": "1733680",
    "end": "1741090"
  },
  {
    "text": "mentioned earlier if you can execute the jobs by not have to worry about",
    "start": "1741090",
    "end": "1749030"
  },
  {
    "text": "infrastructure by abstracting the infrastructure you are focusing on your core business development your core",
    "start": "1749030",
    "end": "1755790"
  },
  {
    "text": "product development and let Amazon handle the server infrastructure for",
    "start": "1755790",
    "end": "1761160"
  },
  {
    "text": "whatever AJ or high availability requirements that you may have right enhance security you can all extend",
    "start": "1761160",
    "end": "1768240"
  },
  {
    "text": "again that lambda you can extend the there is a wide range of security",
    "start": "1768240",
    "end": "1775140"
  },
  {
    "text": "features on AWS that you could integrate with for you for whatever compliance and",
    "start": "1775140",
    "end": "1780240"
  },
  {
    "text": "security needs that you may have and then expanding Big Data capabilities so",
    "start": "1780240",
    "end": "1786510"
  },
  {
    "text": "once you have data in s3 say for argument's sake you built a data Lake on",
    "start": "1786510",
    "end": "1792480"
  },
  {
    "text": "s3 and then you ingest the data whatever mechanism v8 Kinesis or maybe you're",
    "start": "1792480",
    "end": "1798480"
  },
  {
    "text": "ingesting data through a private connection through direct connect within a VPN overlay for for encrypted data",
    "start": "1798480",
    "end": "1806060"
  },
  {
    "text": "once you ingest the data into s3 you now have the option to do transformations on",
    "start": "1806060",
    "end": "1813060"
  },
  {
    "text": "the raw data and then essentially use that process to data to do whatever",
    "start": "1813060",
    "end": "1818910"
  },
  {
    "text": "computational additional computation needs not just simulation work but you could actually extend that to business",
    "start": "1818910",
    "end": "1824760"
  },
  {
    "text": "intelligence like in loading the data into red ship for data warehouse and",
    "start": "1824760",
    "end": "1830910"
  },
  {
    "text": "then doing your visualizations like say using quick site or tableau or whatever data",
    "start": "1830910",
    "end": "1836880"
  },
  {
    "text": "visualization techniques that you use right so you are extending that capability by just separating the",
    "start": "1836880",
    "end": "1843210"
  },
  {
    "text": "compute and storage and and at a lower cost and performant as you can imagine",
    "start": "1843210",
    "end": "1849690"
  },
  {
    "text": "s3 comes with eleven nines of durability so you don't have to worry about how do",
    "start": "1849690",
    "end": "1854789"
  },
  {
    "text": "I make sure my SLA is for my storage layer are met now because now it is a managed service",
    "start": "1854789",
    "end": "1861900"
  },
  {
    "text": "you don't have to really worry about maintaining the the storage infrastructure right and then automation",
    "start": "1861900",
    "end": "1868530"
  },
  {
    "text": "capabilities but as you probably are aware already these are all API calls you could data scale and there is a",
    "start": "1868530",
    "end": "1875640"
  },
  {
    "text": "concurrency that you can achieve with lambda functions or auto scaling in terms of ec2 and provisioning of",
    "start": "1875640",
    "end": "1883530"
  },
  {
    "text": "resources becomes very easy just based on again your need right and ultimately",
    "start": "1883530",
    "end": "1889740"
  },
  {
    "text": "all these factors will help you with product development that is faster time",
    "start": "1889740",
    "end": "1896280"
  },
  {
    "text": "to market but also faster time for results for data scientists the crux of the problem was how do I get results",
    "start": "1896280",
    "end": "1902970"
  },
  {
    "text": "faster or in a cheaper way and that is also extendable to other users of the",
    "start": "1902970",
    "end": "1909809"
  },
  {
    "text": "same data set so that can be easily achieved by leveraging AWS with all",
    "start": "1909809",
    "end": "1915240"
  },
  {
    "text": "these various services right well we go",
    "start": "1915240",
    "end": "1920580"
  },
  {
    "text": "on so now let's go more in before I get into the use case and the details of the",
    "start": "1920580",
    "end": "1927750"
  },
  {
    "text": "use case I quickly wanted to highlight just what are some of the typical characteristics of grid computing it's",
    "start": "1927750",
    "end": "1933510"
  },
  {
    "text": "important to understand first of all a you need the ability to host large data sets",
    "start": "1933510",
    "end": "1938760"
  },
  {
    "text": "that's where s3 comes into play the ability to do resource sharing why do we",
    "start": "1938760",
    "end": "1944220"
  },
  {
    "text": "have to do resource sharing because you may have row feeds coming where the market data may be coming into your",
    "start": "1944220",
    "end": "1951150"
  },
  {
    "text": "organization and you may have multiple teams of data scientists who may be",
    "start": "1951150",
    "end": "1956309"
  },
  {
    "text": "running different simulation jobs there's different activities right so you need to be able to have that raw",
    "start": "1956309",
    "end": "1962940"
  },
  {
    "text": "data be available to mult teams to be able to do that so the resource sharing is extremely important",
    "start": "1962940",
    "end": "1968739"
  },
  {
    "text": "and periodic and schedule tasks right most of the these are as you probably",
    "start": "1968739",
    "end": "1974440"
  },
  {
    "text": "know some market simulations risk simulations that financial services",
    "start": "1974440",
    "end": "1980079"
  },
  {
    "text": "customers do these are not OLTP transactional type databases this is by",
    "start": "1980079",
    "end": "1985629"
  },
  {
    "text": "the very word it's analytical their data so you will have large amounts of data stored and then run analytics on top of",
    "start": "1985629",
    "end": "1992499"
  },
  {
    "text": "that right so you don't really have that transactional type workload so you need",
    "start": "1992499",
    "end": "1997509"
  },
  {
    "text": "to be able to do scheduled tasks not real-time in general and then ability to",
    "start": "1997509",
    "end": "2004109"
  },
  {
    "text": "do transformations very important because your simulations may be again very based on the market fees and what",
    "start": "2004109",
    "end": "2011459"
  },
  {
    "text": "type of simulation activities within Monte Carlo or any other simulation activity whatever you are your goal of",
    "start": "2011459",
    "end": "2019709"
  },
  {
    "text": "achieving the the data analysis you need to be able to transform the data the raw",
    "start": "2019709",
    "end": "2025199"
  },
  {
    "text": "data it may be as simple as converting your raw in 200 RC or parquet or things",
    "start": "2025199",
    "end": "2033149"
  },
  {
    "text": "like that or just whatever the format that you're getting into into a JSON dark or or text document right so those",
    "start": "2033149",
    "end": "2040139"
  },
  {
    "text": "transformations are important for you and usually some of the characteristics with good computing is these are non",
    "start": "2040139",
    "end": "2046889"
  },
  {
    "text": "interactive long-running simulation jobs right so with that characteristics let's go",
    "start": "2046889",
    "end": "2053819"
  },
  {
    "text": "into how do you implement quantico low on AWS so the key to that is you're",
    "start": "2053819",
    "end": "2062250"
  },
  {
    "text": "leveraging the MapReduce framework this is extremely important to to do on to",
    "start": "2062250",
    "end": "2070169"
  },
  {
    "text": "run Monte Carlo simulations in the cloud and level said what is what is MapReduce",
    "start": "2070169",
    "end": "2077398"
  },
  {
    "text": "framework and why is it important for Monte Carlo simulation so the the framework I ended here in the picture",
    "start": "2077399",
    "end": "2083279"
  },
  {
    "text": "this is an overview of the framework itself you have a master node that",
    "start": "2083279",
    "end": "2088799"
  },
  {
    "text": "assigns map and reduce tasks to worker nodes as you can see this there is a there's a splitter which is essentially",
    "start": "2088799",
    "end": "2096029"
  },
  {
    "text": "a bunch of input files then you get the map town of the mapper nodes take the the the data set and then",
    "start": "2096029",
    "end": "2106289"
  },
  {
    "text": "they process the data set input files are split split into chunks and are",
    "start": "2106289",
    "end": "2111809"
  },
  {
    "text": "processed individually by the worker nodes and then produce a stream of intermediary key value data which is",
    "start": "2111809",
    "end": "2117990"
  },
  {
    "text": "again which could also be hosted on s3 just like your raw files and then",
    "start": "2117990",
    "end": "2123900"
  },
  {
    "text": "records are selectively read by the reducer tasks the the task nodes and",
    "start": "2123900",
    "end": "2129329"
  },
  {
    "text": "then aggregated the results so this is where the most of the transformations are happening right so this is a classic",
    "start": "2129329",
    "end": "2136260"
  },
  {
    "text": "example of how Monte Carlo simulation can be implemented using MapReduce",
    "start": "2136260",
    "end": "2141960"
  },
  {
    "text": "framework so now when we talk about MapReduce framework the first thing a",
    "start": "2141960",
    "end": "2149220"
  },
  {
    "start": "2145000",
    "end": "2145000"
  },
  {
    "text": "lot of you must be thinking wait a minute MapReduce for me means red shift",
    "start": "2149220",
    "end": "2155270"
  },
  {
    "text": "EMR and the entire Hadoop ecosystem right that is absolutely true you could",
    "start": "2155270",
    "end": "2161579"
  },
  {
    "text": "you could have a Hadoop framework offer comprehensive solutions for big data",
    "start": "2161579",
    "end": "2167309"
  },
  {
    "text": "processing no question about that however if you if you think about the",
    "start": "2167309",
    "end": "2172640"
  },
  {
    "text": "complexity of running a Hadoop ecosystem there are a lot of nuances there are a",
    "start": "2172640",
    "end": "2179250"
  },
  {
    "text": "lot of coordination there's a lot of bootstrapping that that needs to be done before you could actually use it right",
    "start": "2179250",
    "end": "2186319"
  },
  {
    "text": "apart from the benefit of not having to manage any servers with the serverless",
    "start": "2186319",
    "end": "2192059"
  },
  {
    "text": "framework you would also have significant cost savings if you try to",
    "start": "2192059",
    "end": "2198900"
  },
  {
    "text": "do this in a server list way versus say running this on the traditional way",
    "start": "2198900",
    "end": "2204869"
  },
  {
    "text": "right using Emaar redshift and other",
    "start": "2204869",
    "end": "2210289"
  },
  {
    "text": "variables so this is one variation of the standard MapReduce framework what",
    "start": "2210289",
    "end": "2219510"
  },
  {
    "text": "are what are them so on the on the picture here you can see how you still",
    "start": "2219510",
    "end": "2224910"
  },
  {
    "text": "have the the same MapReduce framework that we discussed in the previous slide you are extending that into the server",
    "start": "2224910",
    "end": "2232319"
  },
  {
    "text": "left side where you are ingesting the data you're still storing in the input bucket and you're triggering an event",
    "start": "2232319",
    "end": "2238730"
  },
  {
    "text": "where there are mapper functions that take the data set and then the and with",
    "start": "2238730",
    "end": "2247579"
  },
  {
    "text": "lambda as I discussed earlier there is no session state that you can store",
    "start": "2247579",
    "end": "2253109"
  },
  {
    "text": "within lambda right so you have to write it back to a persistent store so here there is a coordinator or lambda",
    "start": "2253109",
    "end": "2259650"
  },
  {
    "text": "function in the middle as you can see the coordinator is essentially writing the session state back to s 3 and then",
    "start": "2259650",
    "end": "2266520"
  },
  {
    "text": "the reducer lambda functions are again there there is a concurrent lambda",
    "start": "2266520",
    "end": "2272549"
  },
  {
    "text": "functions that are triggered to date take those tasks and essentially aggregate those results and write the",
    "start": "2272549",
    "end": "2278789"
  },
  {
    "text": "result data set back into s3 so simple MapReduce framework that we discussed",
    "start": "2278789",
    "end": "2283829"
  },
  {
    "text": "can easily be extended into a server less design but this particular",
    "start": "2283829",
    "end": "2288960"
  },
  {
    "text": "framework again what are some of the goals of why do we have to stand up something like this well what are what",
    "start": "2288960",
    "end": "2295619"
  },
  {
    "text": "am i achieving by doing that is essentially abstract infrastructure management if you are a data scientist",
    "start": "2295619",
    "end": "2302099"
  },
  {
    "text": "and you want to use say the traditional approach then you would have to",
    "start": "2302099",
    "end": "2307559"
  },
  {
    "text": "understand the Hadoop ecosystem how to use EMR right so unless yeah and there was a ramp up",
    "start": "2307559",
    "end": "2315270"
  },
  {
    "text": "to that too right so with server list framework what you could do is first of",
    "start": "2315270",
    "end": "2321839"
  },
  {
    "text": "all you're abstracting the infrastructure management and almost close to zero setup time you could",
    "start": "2321839",
    "end": "2327569"
  },
  {
    "text": "essentially wrap this whole thing into a clot formation template and create multiple environments for your different",
    "start": "2327569",
    "end": "2334619"
  },
  {
    "text": "teams for them to do analysis and still have access to the same data set why because you're essentially using the",
    "start": "2334619",
    "end": "2341849"
  },
  {
    "text": "same raw data set that is on s3 right and then you can do access management",
    "start": "2341849",
    "end": "2347010"
  },
  {
    "text": "the Identity and Access Management through it by extending your your corporate SSL with I am roles and",
    "start": "2347010",
    "end": "2356070"
  },
  {
    "text": "essentially doing assume role to give specific permissions to your data",
    "start": "2356070",
    "end": "2361830"
  },
  {
    "text": "scientists or users so that's the implementation for this specific task on",
    "start": "2361830",
    "end": "2369840"
  },
  {
    "start": "2368000",
    "end": "2368000"
  },
  {
    "text": "the same pattern this is this is the pattern that Fannie Mae is implemented which Ben and John they have extensively",
    "start": "2369840",
    "end": "2379800"
  },
  {
    "text": "worked on implementing so this is a small variation of the one that we discussed earlier here is you can see",
    "start": "2379800",
    "end": "2386010"
  },
  {
    "text": "there is a s 3 input files though the raw files are inputted into s3 and then",
    "start": "2386010",
    "end": "2391650"
  },
  {
    "text": "there is a ec2 splitter function then you may have a question about why are we doing easy to splitter function because",
    "start": "2391650",
    "end": "2398850"
  },
  {
    "text": "at the time again there are large data sets that were coming in and as you",
    "start": "2398850",
    "end": "2404040"
  },
  {
    "text": "probably know lambda has an execution timeout so it has to complete within 5 minutes interval some of the splitter",
    "start": "2404040",
    "end": "2410550"
  },
  {
    "text": "functionality was extending beyond that timeout threshold so to work around this",
    "start": "2410550",
    "end": "2415920"
  },
  {
    "text": "was the workaround was used the ec2 as a splitter function and then ingest that",
    "start": "2415920",
    "end": "2423330"
  },
  {
    "text": "into well after the large data sets are split into multiple chunks the smaller",
    "start": "2423330",
    "end": "2428610"
  },
  {
    "text": "chunks are inserted into s3 bucket and then your your MapReduce activity is",
    "start": "2428610",
    "end": "2435150"
  },
  {
    "text": "triggered through lambda functions so I hope that makes sense the the difference between why easy to split a versus the",
    "start": "2435150",
    "end": "2441000"
  },
  {
    "text": "previous slide where it was purely server less so it all depends on the the",
    "start": "2441000",
    "end": "2447840"
  },
  {
    "text": "idea here is based on your workload characteristics and your data set size you can easily change the architecture",
    "start": "2447840",
    "end": "2455790"
  },
  {
    "text": "and and do essentially MapReduce activity in multiple ways and you can",
    "start": "2455790",
    "end": "2462630"
  },
  {
    "text": "achieve this very easily and very in a repeatable fashion and for so we",
    "start": "2462630",
    "end": "2470190"
  },
  {
    "text": "discussed about the compute portion but what about my we didn't talk about the",
    "start": "2470190",
    "end": "2475950"
  },
  {
    "text": "regulations right and security concerns or how do I protect my data some",
    "start": "2475950",
    "end": "2481890"
  },
  {
    "text": "fernette not just financial services but other customers too in other industries have questions about okay I maybe have",
    "start": "2481890",
    "end": "2489090"
  },
  {
    "text": "carrying NPI data NPI stands for non-public information or PII like",
    "start": "2489090",
    "end": "2494580"
  },
  {
    "text": "publicly right personally identifiable information very critical this may be a",
    "start": "2494580",
    "end": "2500550"
  },
  {
    "text": "confidential data or highly confidential data so if you have classifications like",
    "start": "2500550",
    "end": "2505770"
  },
  {
    "text": "those and you want to be able to make sure you are securing the data you can",
    "start": "2505770",
    "end": "2510990"
  },
  {
    "text": "easily extend that through AWS kms it's a key management service and if you have",
    "start": "2510990",
    "end": "2520620"
  },
  {
    "text": "any compliance requirements you can for data encryption in transit like I said",
    "start": "2520620",
    "end": "2527010"
  },
  {
    "text": "earlier you can always do VPN and VPN over DX to encrypt your data in transit",
    "start": "2527010",
    "end": "2532650"
  },
  {
    "text": "and encrypting data at rest can easily be achieved through kms keys right cloud",
    "start": "2532650",
    "end": "2538260"
  },
  {
    "text": "watch again extensively used for not only monitoring but also triggering events and all this into end solution",
    "start": "2538260",
    "end": "2546120"
  },
  {
    "text": "can easily be treated as an infrastructure as a code through cloud formation templates very easy to",
    "start": "2546120",
    "end": "2552600"
  },
  {
    "text": "duplicate the environment and recreate as necessary and then close well if you",
    "start": "2552600",
    "end": "2558660"
  },
  {
    "text": "have again you may be interfacing with auditors both internal auditors external auditors and they may have questions",
    "start": "2558660",
    "end": "2564300"
  },
  {
    "text": "about who had access to this data who manipulated the data and what are the API calls that were used to manipulate",
    "start": "2564300",
    "end": "2571380"
  },
  {
    "text": "the data so if things like that come up you can easily use cloud trail which",
    "start": "2571380",
    "end": "2576390"
  },
  {
    "text": "will help you identify those API calls and you can integrate cloud trail logs",
    "start": "2576390",
    "end": "2581810"
  },
  {
    "text": "there's a wide variety of implementations both in-house and also third-party solutions or partner",
    "start": "2581810",
    "end": "2587160"
  },
  {
    "text": "solutions that can actually be leveraged to a large back on Prem and then you can",
    "start": "2587160",
    "end": "2594480"
  },
  {
    "text": "control the access to the data set itself at a very granular level through",
    "start": "2594480",
    "end": "2599940"
  },
  {
    "text": "I am there are many implementations of both I am roles and resource based constraints",
    "start": "2599940",
    "end": "2605400"
  },
  {
    "text": "and things like that so that's a holistic view of how you can maintain",
    "start": "2605400",
    "end": "2611100"
  },
  {
    "text": "maintain and you're a good computing infrastructure the slight variation here the the",
    "start": "2611100",
    "end": "2618530"
  },
  {
    "text": "previous one was the splitter functionality here it's a batch processing of the only difference being",
    "start": "2618530",
    "end": "2624110"
  },
  {
    "text": "the mapper results are inserted into the dynamo DB table here so just a different",
    "start": "2624110",
    "end": "2630800"
  },
  {
    "text": "perspective here of a different architecture you can easily extend that",
    "start": "2630800",
    "end": "2636860"
  },
  {
    "text": "the same thing again carrying on with the team there if you have any real-time file processing that needs to be done",
    "start": "2636860",
    "end": "2644660"
  },
  {
    "text": "another method is again you you use s3 as your data Lake your ingest point and",
    "start": "2644660",
    "end": "2650180"
  },
  {
    "text": "then you trigger an SNS notification that will essentially create invoke a",
    "start": "2650180",
    "end": "2657140"
  },
  {
    "text": "lambda functions from there and then the rest is the same you could the the",
    "start": "2657140",
    "end": "2662990"
  },
  {
    "text": "persistent store could be dynamo or s3 right so quickly we were almost coming",
    "start": "2662990",
    "end": "2672770"
  },
  {
    "start": "2669000",
    "end": "2669000"
  },
  {
    "text": "to the end of there's a first segment where lambda considerations are important for your grid computing",
    "start": "2672770",
    "end": "2681080"
  },
  {
    "text": "framework right so some of the important data points here are functions or unit of deployment so you can scale pour",
    "start": "2681080",
    "end": "2689180"
  },
  {
    "text": "request and never pay for idle and skip the mundane activities like maintaining",
    "start": "2689180",
    "end": "2694520"
  },
  {
    "text": "servers patching servers be able to maintain your container environments and things like that so you don't have to do",
    "start": "2694520",
    "end": "2700460"
  },
  {
    "text": "that right you can provision this on the fly meaning we take care of that from",
    "start": "2700460",
    "end": "2705830"
  },
  {
    "text": "the it'll us and all you have to do is to maintain your code set and focus on",
    "start": "2705830",
    "end": "2711350"
  },
  {
    "text": "your business deliverables instead of the infrastructure right so that is what is essentially the key to this for again",
    "start": "2711350",
    "end": "2719060"
  },
  {
    "text": "like I mentioned multiple times do you remember AWS lambda is stateless so if you have any state information",
    "start": "2719060",
    "end": "2725030"
  },
  {
    "text": "that needs to be handled then you would have to write to a persistent store the",
    "start": "2725030",
    "end": "2730220"
  },
  {
    "text": "execution environment that your lambda function is running in you will not stay",
    "start": "2730220",
    "end": "2735440"
  },
  {
    "text": "persistent right so you need to keep that in mind so this is a container environment but that container will go",
    "start": "2735440",
    "end": "2741830"
  },
  {
    "text": "away or might go away in the subsequent invocation so you have to think about if",
    "start": "2741830",
    "end": "2746850"
  },
  {
    "text": "you have state information requirement right into a persistent store bottom line right and then for low-level ETL",
    "start": "2746850",
    "end": "2756060"
  },
  {
    "text": "tasks you can use on the container itself you you get access to a temp file space you could use that up to 400 MB",
    "start": "2756060",
    "end": "2763460"
  },
  {
    "text": "for low-level ETL before writing the results back to your persistent store",
    "start": "2763460",
    "end": "2768470"
  },
  {
    "text": "right and then into mentioned earlier a broad range of options that you have to",
    "start": "2768470",
    "end": "2775830"
  },
  {
    "text": "control any any security concerns that you may have we have a robust set of",
    "start": "2775830",
    "end": "2782070"
  },
  {
    "text": "security tools to help you manage the boundary and if you have to run your",
    "start": "2782070",
    "end": "2787110"
  },
  {
    "text": "workloads inside a contained environment inside a private most of the customers also I have seen where they want to run",
    "start": "2787110",
    "end": "2793290"
  },
  {
    "text": "their workloads in in their in a private IP space right so you could extend that",
    "start": "2793290",
    "end": "2799410"
  },
  {
    "text": "RFC 1918 address space which you are already using internally in your production fabric onto AWS by creating",
    "start": "2799410",
    "end": "2807270"
  },
  {
    "text": "private subnets and routing the requests through your DX connection or probe VPN",
    "start": "2807270",
    "end": "2813660"
  },
  {
    "text": "connection to your V PC and execute lambda functions inside your V PC through e ni right so if you have such",
    "start": "2813660",
    "end": "2820830"
  },
  {
    "text": "requirements it's very easy very extensible framework that the one that we spoke about with that I will hand off",
    "start": "2820830",
    "end": "2829560"
  },
  {
    "text": "the mic to my co-presenter bin lu who will walk us through Fannie Mae's use",
    "start": "2829560",
    "end": "2836040"
  },
  {
    "text": "case thank you [Applause]",
    "start": "2836040",
    "end": "2841729"
  },
  {
    "text": "good evening my name is Balu I'm director of a risk modeling and",
    "start": "2842790",
    "end": "2848970"
  },
  {
    "text": "analytics fanime I'm going to talk about high performance computing using AWS",
    "start": "2848970",
    "end": "2855580"
  },
  {
    "text": "lambda for financial modeling fatty Bank is a leading source of financing for",
    "start": "2855580",
    "end": "2862900"
  },
  {
    "text": "mortgage lenders we provide access to affordable mortgage financing near all",
    "start": "2862900",
    "end": "2869410"
  },
  {
    "text": "market conditions we finally managed a reduce risk to our business taxpayers",
    "start": "2869410",
    "end": "2876370"
  },
  {
    "text": "and the housing finance system Fannie Mae's credit profile size is about three",
    "start": "2876370",
    "end": "2883960"
  },
  {
    "text": "trading dollars financial modeling is a",
    "start": "2883960",
    "end": "2889630"
  },
  {
    "text": "simulation process to project future cash flows Fannie Mae uses a financial",
    "start": "2889630",
    "end": "2896710"
  },
  {
    "text": "modeling process for managing mortgage risk our daily basis we use it for",
    "start": "2896710",
    "end": "2903430"
  },
  {
    "text": "mortgage underwriting valuation risk management financial reporting",
    "start": "2903430",
    "end": "2909840"
  },
  {
    "text": "regulatory reporting loss mitigation and low removal every month we generate more",
    "start": "2909840",
    "end": "2917710"
  },
  {
    "text": "than ten quadrillions of cash flows in hundreds of economic scenarios high",
    "start": "2917710",
    "end": "2925660"
  },
  {
    "text": "performance computing words is a key infrastructure component for financial",
    "start": "2925660",
    "end": "2931420"
  },
  {
    "text": "modeling Fannie Mae's existing high performance computing facility no longer",
    "start": "2931420",
    "end": "2938110"
  },
  {
    "text": "meets our growing business needs it is more than seven years old with limited",
    "start": "2938110",
    "end": "2944380"
  },
  {
    "text": "aisle compute and storage capacities it has complex distributed computing API",
    "start": "2944380",
    "end": "2952050"
  },
  {
    "text": "for application development and it is very costly to maintain and to refresh",
    "start": "2952050",
    "end": "2960240"
  },
  {
    "text": "it takes more than half a year to add any incremental computing resources and",
    "start": "2960240",
    "end": "2965980"
  },
  {
    "text": "deploy any new application we were",
    "start": "2965980",
    "end": "2971260"
  },
  {
    "text": "looking for a new high performance computing facility that enable us to react to the rapidly",
    "start": "2971260",
    "end": "2977689"
  },
  {
    "text": "changing market we want to have access to unlimited compute resources and",
    "start": "2977689",
    "end": "2984259"
  },
  {
    "text": "unlimited storage we want the facility to be reliable easy to manage and stay",
    "start": "2984259",
    "end": "2992239"
  },
  {
    "text": "current we also want a facility to be cost effective on the application side",
    "start": "2992239",
    "end": "3000039"
  },
  {
    "text": "we want the facility to provide simple distributed computing api's we want to",
    "start": "3000039",
    "end": "3006369"
  },
  {
    "text": "be able to maximize reuse of our existing code base and we want to be",
    "start": "3006369",
    "end": "3012909"
  },
  {
    "text": "able to deliver the new solution in short time AWS server is computing",
    "start": "3012909",
    "end": "3020650"
  },
  {
    "text": "offers the ideal solution to the new business requirement Fannie Mae began to",
    "start": "3020650",
    "end": "3028809"
  },
  {
    "text": "build the new high performance computing platform using lambda in 2016 this is",
    "start": "3028809",
    "end": "3037449"
  },
  {
    "text": "the first high performance computing platform using server this architecture in the industry it is also the first",
    "start": "3037449",
    "end": "3045999"
  },
  {
    "text": "parallel program I finally made to build this cloud native application since",
    "start": "3045999",
    "end": "3055390"
  },
  {
    "text": "Fannie Mae is you know highly regulated industry it took us more than half a",
    "start": "3055390",
    "end": "3061419"
  },
  {
    "text": "year to build the infrastructure that meets our information security standard",
    "start": "3061419",
    "end": "3068579"
  },
  {
    "text": "once the infrastructure is constructed we were able to deploy the first working",
    "start": "3068579",
    "end": "3076479"
  },
  {
    "text": "prototype within a month in March 2017",
    "start": "3076479",
    "end": "3081809"
  },
  {
    "text": "we deployed the first financial modeling application to pre-production and run of",
    "start": "3081809",
    "end": "3089159"
  },
  {
    "text": "15,000 concurrent lambda executions and in June 2017 we completed our production",
    "start": "3089159",
    "end": "3099189"
  },
  {
    "text": "migration of the first four financial modeling applications this is a",
    "start": "3099189",
    "end": "3106269"
  },
  {
    "text": "performance testing result of our you server this high-performance computing platform we ran one simulation",
    "start": "3106269",
    "end": "3114970"
  },
  {
    "text": "of approximately 20 million mortgages on 15,000 lambda executions",
    "start": "3114970",
    "end": "3122730"
  },
  {
    "text": "it took 1/2 hours which is more than four times faster than the existing",
    "start": "3122730",
    "end": "3129480"
  },
  {
    "text": "process the London service provisions 3",
    "start": "3129480",
    "end": "3136450"
  },
  {
    "text": "lambda executions instantaneously at the start it then automatically provisions",
    "start": "3136450",
    "end": "3144490"
  },
  {
    "text": "additional 12,000 lambda within the first 50 minutes the performance of the",
    "start": "3144490",
    "end": "3152500"
  },
  {
    "text": "lambda does not degrade during the ramp up time as you can see on the chart the",
    "start": "3152500",
    "end": "3160000"
  },
  {
    "text": "lambda invocation rate increases linearly as a function of time the",
    "start": "3160000",
    "end": "3167410"
  },
  {
    "text": "lambda CPU efficiency is close to hundred percent the actual elapsed time",
    "start": "3167410",
    "end": "3173980"
  },
  {
    "text": "is consistent with the estimated is elapsed time based on lambda bidding",
    "start": "3173980",
    "end": "3179680"
  },
  {
    "text": "time this is a reference architecture",
    "start": "3179680",
    "end": "3184960"
  },
  {
    "text": "for the simple parallel process using lambda service MapReduce framework is",
    "start": "3184960",
    "end": "3191859"
  },
  {
    "text": "used for managing the high-performance computing workload server is computing",
    "start": "3191859",
    "end": "3198250"
  },
  {
    "text": "is event-driven computing the central idea here is to leverage lambda",
    "start": "3198250",
    "end": "3204970"
  },
  {
    "text": "capability to perform the map function and automatically execute and copies of",
    "start": "3204970",
    "end": "3212440"
  },
  {
    "text": "code simultaneously based on input events s3 is used to store the input",
    "start": "3212440",
    "end": "3220599"
  },
  {
    "text": "events and output data we divide the process into three functions splitter",
    "start": "3220599",
    "end": "3228849"
  },
  {
    "text": "mapper and reducer easy to is used to split the info file and write and",
    "start": "3228849",
    "end": "3235930"
  },
  {
    "text": "triggers to s3 event packets the matter is to perform the District",
    "start": "3235930",
    "end": "3242650"
  },
  {
    "text": "computing lambda is used to automatically carry out and executions I",
    "start": "3242650",
    "end": "3249970"
  },
  {
    "text": "write output to s3 my per pocket the reducer is to aggregate the output data",
    "start": "3249970",
    "end": "3257350"
  },
  {
    "text": "is it who is use again to aggregate the outputs and write final result to s3",
    "start": "3257350",
    "end": "3264840"
  },
  {
    "text": "reducer packet we can decompose complex",
    "start": "3264840",
    "end": "3271780"
  },
  {
    "text": "workload into multiple simple wires for parallel computing using lambdas service",
    "start": "3271780",
    "end": "3278970"
  },
  {
    "text": "Athena is also a good service tool to aggregate the output data there are many",
    "start": "3278970",
    "end": "3287920"
  },
  {
    "text": "benefits of using service high-performance computing platform first of all it is cost effective we",
    "start": "3287920",
    "end": "3297010"
  },
  {
    "text": "never pay for either the cost is based on HOV CPU usage in the unit of 100",
    "start": "3297010",
    "end": "3305110"
  },
  {
    "text": "millisecond not the elapsed time of maximum processing capacity of the",
    "start": "3305110",
    "end": "3311950"
  },
  {
    "text": "infrastructure we can achieve performance at zero cost for example the",
    "start": "3311950",
    "end": "3320320"
  },
  {
    "text": "cause of running while lambda for 15,000 hours is the same as a cause of running",
    "start": "3320320",
    "end": "3327840"
  },
  {
    "text": "15,000 lambdas for one hour it also",
    "start": "3327840",
    "end": "3333520"
  },
  {
    "text": "shortens the time to market were able to burst to cloud immediately to access",
    "start": "3333520",
    "end": "3340750"
  },
  {
    "text": "additional cloud computing process resources were able to focus on our",
    "start": "3340750",
    "end": "3347410"
  },
  {
    "text": "business need there is no server to manage and no complex distributed computing code to",
    "start": "3347410",
    "end": "3354100"
  },
  {
    "text": "write AWS ecosystem also provides a",
    "start": "3354100",
    "end": "3359200"
  },
  {
    "text": "streamlined integration with big data analytic platform for data mining",
    "start": "3359200",
    "end": "3365280"
  },
  {
    "text": "machine learning for further analysis visualization and reporting",
    "start": "3365280",
    "end": "3373799"
  },
  {
    "text": "the following are best practices for running high performance computing",
    "start": "3374680",
    "end": "3380020"
  },
  {
    "text": "workload using lambda service first we need to break down complex business",
    "start": "3380020",
    "end": "3386440"
  },
  {
    "text": "logic into multiple simple ones for distributed computing using lambda",
    "start": "3386440",
    "end": "3392140"
  },
  {
    "text": "service we need to maximize s3 performance by evenly distributing the",
    "start": "3392140",
    "end": "3399340"
  },
  {
    "text": "key names of the objects we need to set up a separate lambda count for unlimited",
    "start": "3399340",
    "end": "3406060"
  },
  {
    "text": "access of the resources without running out of IP addresses we also need to",
    "start": "3406060",
    "end": "3414100"
  },
  {
    "text": "adopt micro service architecture to migrate one business application at a",
    "start": "3414100",
    "end": "3419380"
  },
  {
    "text": "time I integrate with AWS code pipeline and Sun for CI CD and dev ops fanime is",
    "start": "3419380",
    "end": "3431770"
  },
  {
    "text": "planning to complete migration of major financial modeling applications to AWS",
    "start": "3431770",
    "end": "3438430"
  },
  {
    "text": "in 2018 thank you [Applause]",
    "start": "3438430",
    "end": "3451459"
  },
  {
    "text": "quickly I wanted to showcase so you can extend this framework that we talked",
    "start": "3456240",
    "end": "3461710"
  },
  {
    "text": "about how Fannie Mae has implemented this solution you could extend this framework to your own environments and",
    "start": "3461710",
    "end": "3469960"
  },
  {
    "text": "there is actually a blog post that be published the information is there in",
    "start": "3469960",
    "end": "3475090"
  },
  {
    "text": "the appendix who you can get access to the slides to get more information on finding the blog post so quickly I",
    "start": "3475090",
    "end": "3483490"
  },
  {
    "text": "wanted to showcase some aspects of running this did the results so the code",
    "start": "3483490",
    "end": "3490270"
  },
  {
    "text": "is published in github you can clearly access and the code and download the",
    "start": "3490270",
    "end": "3497920"
  },
  {
    "text": "configs and run this and extend this framework one important feature that I",
    "start": "3497920",
    "end": "3504250"
  },
  {
    "text": "wanted to talk about is again now you need to write very simple this is extremely easy very easy to replicate in",
    "start": "3504250",
    "end": "3511420"
  },
  {
    "text": "your own environment a simple creating an iamb policy here giving permissions",
    "start": "3511420",
    "end": "3517480"
  },
  {
    "text": "for the lambda functions to do two things right one is access to the s3 bucket the de prefixes are defined",
    "start": "3517480",
    "end": "3524640"
  },
  {
    "text": "through internally in a JSON document and then you are also giving permissions",
    "start": "3524640",
    "end": "3531190"
  },
  {
    "text": "to to create the log stream right so you're giving access to the lock stream",
    "start": "3531190",
    "end": "3537130"
  },
  {
    "text": "and then you are creating now this role and once you have the role defined you",
    "start": "3537130",
    "end": "3544300"
  },
  {
    "text": "can go to your lambda function and essentially I'll give you an example on how it looks like and essentially you're",
    "start": "3544300",
    "end": "3553690"
  },
  {
    "text": "your defining your your execution role right there that is how you are giving",
    "start": "3553690",
    "end": "3559660"
  },
  {
    "text": "permissions for lambda the big lambda role and then you are managing your",
    "start": "3559660",
    "end": "3565720"
  },
  {
    "text": "environment by giving the memory that it requires to run and also setting the",
    "start": "3565720",
    "end": "3571270"
  },
  {
    "text": "threshold for timeouts so that's as simple as that you could you could",
    "start": "3571270",
    "end": "3576790"
  },
  {
    "text": "extend this framework and write your own code or or essentially duplicate this",
    "start": "3576790",
    "end": "3582490"
  },
  {
    "text": "MapReduce framework with lambda that is on github to get results that you desire",
    "start": "3582490",
    "end": "3587990"
  },
  {
    "text": "and just looking at some of the cloud watch metrics here are some information",
    "start": "3587990",
    "end": "3594980"
  },
  {
    "text": "when you run that code you essentially get an access to you can quickly review",
    "start": "3594980",
    "end": "3601220"
  },
  {
    "text": "some of the details that is published to the log groups that cloud watch log",
    "start": "3601220",
    "end": "3607220"
  },
  {
    "text": "groups as part of the lambda invocation itself so you can actually see the",
    "start": "3607220",
    "end": "3612980"
  },
  {
    "text": "invocation and as the mapper function and the reducer function are are working",
    "start": "3612980",
    "end": "3620120"
  },
  {
    "text": "on the splitter files and then writing the the processed files back to the s3",
    "start": "3620120",
    "end": "3626090"
  },
  {
    "text": "you can actually see that in the India log groups right and then finally I just",
    "start": "3626090",
    "end": "3634040"
  },
  {
    "text": "wanted to do a quick wrap here so Lamba",
    "start": "3634040",
    "end": "3645230"
  },
  {
    "text": "servers again just to wrap up it can be extended to the MapReduce framework one",
    "start": "3645230",
    "end": "3651200"
  },
  {
    "text": "of the some of the advantages here is you can trigger events no servers to",
    "start": "3651200",
    "end": "3657140"
  },
  {
    "text": "manage flexible scaling no idle capacity or not worrying about spot instances or",
    "start": "3657140",
    "end": "3662720"
  },
  {
    "text": "reserved instances and things like that right high availability I discussed extensively how difficult it is to",
    "start": "3662720",
    "end": "3668930"
  },
  {
    "text": "maintain a che on Prem you're essentially offloading that heavy lifting to AWS and focusing on your code",
    "start": "3668930",
    "end": "3676220"
  },
  {
    "text": "your develop development efforts and your business outcomes right and then",
    "start": "3676220",
    "end": "3681350"
  },
  {
    "text": "you can bring your own code you can also again those are language support if you have any libraries the custom libraries",
    "start": "3681350",
    "end": "3688490"
  },
  {
    "text": "that you may have you could de la bridge custom libraries inside lambda functions and pretty simple resource model that",
    "start": "3688490",
    "end": "3696470"
  },
  {
    "text": "we've already discussed with respect to just two variables your memory requirement and your",
    "start": "3696470",
    "end": "3702950"
  },
  {
    "text": "execution timeout right and then we discussed about programming model that",
    "start": "3702950",
    "end": "3708470"
  },
  {
    "text": "lambda and the statelessness and how to maintain session state and things like",
    "start": "3708470",
    "end": "3714040"
  },
  {
    "text": "that monitoring and logging is extensive there are all built-in metrics that you",
    "start": "3714040",
    "end": "3719680"
  },
  {
    "text": "could leverage and authoring functions is pretty straightforward and your whatever execution environment that",
    "start": "3719680",
    "end": "3726760"
  },
  {
    "text": "you're already familiar with you could use that for that even sources did this",
    "start": "3726760",
    "end": "3732370"
  },
  {
    "text": "the list will continue to grow these are just a few of the event sources I have listed here but these are standard many",
    "start": "3732370",
    "end": "3739570"
  },
  {
    "text": "standard implementations for grid computing we have seen a large implementation that s3 is the data source that's we but don't be under the",
    "start": "3739570",
    "end": "3747790"
  },
  {
    "text": "impression that this is just for a threey based only you can extend this",
    "start": "3747790",
    "end": "3753100"
  },
  {
    "text": "framework a lot of AI and machine learning also may have been integrated",
    "start": "3753100",
    "end": "3759060"
  },
  {
    "text": "again API gateway is a common source too so please do review some of these",
    "start": "3759060",
    "end": "3765070"
  },
  {
    "text": "characteristics both from a functional standpoint what your grid computing can do for you and also from a technical",
    "start": "3765070",
    "end": "3771640"
  },
  {
    "text": "standpoint on how you can extend this framework in your own environment to get",
    "start": "3771640",
    "end": "3777250"
  },
  {
    "text": "the results that you're looking for so that we conclude this session and please complete your session evaluations and",
    "start": "3777250",
    "end": "3783970"
  },
  {
    "text": "hopefully you can implement something similar in your environments and",
    "start": "3783970",
    "end": "3789340"
  },
  {
    "text": "hopefully next year we'll be talking about your use case and your success story but that it's a conclude and thank",
    "start": "3789340",
    "end": "3795550"
  },
  {
    "text": "you all for attending this session [Applause]",
    "start": "3795550",
    "end": "3800119"
  }
]
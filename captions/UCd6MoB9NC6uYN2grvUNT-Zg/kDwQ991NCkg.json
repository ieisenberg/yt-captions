[
  {
    "start": "0",
    "end": "75000"
  },
  {
    "text": "hi everybody and welcome to this week's edition of office hours for AWS today",
    "start": "30",
    "end": "5879"
  },
  {
    "text": "we're going to be talking about building large kubernetes clusters if you haven't",
    "start": "5879",
    "end": "11460"
  },
  {
    "text": "joined our sessions before we run these every Thursday at noon to 1:00 Pacific Standard and you can come and basically",
    "start": "11460",
    "end": "18390"
  },
  {
    "text": "join in on the chat we'll be answering questions I have two developers from our",
    "start": "18390",
    "end": "23480"
  },
  {
    "text": "elastic container service for kubernetes eks team here to help answer some",
    "start": "23480",
    "end": "28590"
  },
  {
    "text": "questions so please write those in and we'll get them answered otherwise we're gonna get started introducing yo huh",
    "start": "28590",
    "end": "35550"
  },
  {
    "text": "hello all right my name is Gil ho and then right now I'm working on eks also",
    "start": "35550",
    "end": "40920"
  },
  {
    "text": "on the open source side I'm working on the project called SCD and then widget we use a city for eks and to store the",
    "start": "40920",
    "end": "49350"
  },
  {
    "text": "metadata from the ETS cluster and sha hey guys I'm Sean I am a software",
    "start": "49350",
    "end": "55980"
  },
  {
    "text": "developer with the ETS team so I'm also involved with the open source project",
    "start": "55980",
    "end": "61010"
  },
  {
    "text": "I've been working on kubernetes for a little more than two and a half years and I focus on scalability and",
    "start": "61010",
    "end": "67260"
  },
  {
    "text": "performance of Cuban itis and I'm one of the chairs for sig scalability okay so",
    "start": "67260",
    "end": "74909"
  },
  {
    "text": "what is what is a sig you just said that what does that stand for what does that actually mean so so sink a stand for special interest",
    "start": "74909",
    "end": "82799"
  },
  {
    "start": "75000",
    "end": "223000"
  },
  {
    "text": "group in the open-source community we have this concept of special interest groups so these are dedicated effort",
    "start": "82799",
    "end": "90090"
  },
  {
    "text": "groups which focus on a particular area of the project for instance I'm from six scalability we have like six for",
    "start": "90090",
    "end": "95850"
  },
  {
    "text": "networking storage if we are missionary and a bunch of these so the purpose of this division is to have like more",
    "start": "95850",
    "end": "103920"
  },
  {
    "text": "focused efforts and have specialization around different areas okay all right and so that helps it so",
    "start": "103920",
    "end": "110490"
  },
  {
    "text": "that the community can kind of get around this massive project and and have different verticals so that not everybody has to know everything is that",
    "start": "110490",
    "end": "118100"
  },
  {
    "text": "and so you're the soup chair for scalability right so what is scale what does the scalability sig do in general",
    "start": "118100",
    "end": "124530"
  },
  {
    "text": "so the security sig of it's actually one of the oldest things out probably the",
    "start": "124530",
    "end": "130349"
  },
  {
    "text": "oldest sig the the secret started first it focuses around performance of the",
    "start": "130349",
    "end": "137190"
  },
  {
    "text": "kubernetes control plane in general and also being able to scale really large so",
    "start": "137190",
    "end": "144239"
  },
  {
    "text": "to large clusters or the large number of so it says a large number of ingress",
    "start": "144239",
    "end": "151019"
  },
  {
    "text": "Azure have a high pore density so it's really about pushing the system to its bounds and being able to stretch a lot",
    "start": "151019",
    "end": "158280"
  },
  {
    "text": "on on different dimensions of the system ok all right so does that also so does",
    "start": "158280",
    "end": "165360"
  },
  {
    "text": "that extend into things like auto scaling as well or is it really focused on just how the how the cluster scales",
    "start": "165360",
    "end": "171180"
  },
  {
    "text": "in general oh I really love you bring this up so auto scaling quite often is",
    "start": "171180",
    "end": "176849"
  },
  {
    "text": "confused with six scalability probably because both of them have scale in it but they're actually kind of pretty",
    "start": "176849",
    "end": "184500"
  },
  {
    "text": "different problems so auto scaling is about dynamically adjusting to the load",
    "start": "184500",
    "end": "189569"
  },
  {
    "text": "in the system like scaling your control panel and down based on the load you have when scalability is actually about",
    "start": "189569",
    "end": "197340"
  },
  {
    "text": "like the real absolute hard bounce and pushing that so often like because of",
    "start": "197340",
    "end": "203819"
  },
  {
    "text": "performance bottlenecks or like general architectural flaws stuff like this we",
    "start": "203819",
    "end": "209120"
  },
  {
    "text": "limited on certain bounds and we want to like push it further there given enough",
    "start": "209120",
    "end": "216000"
  },
  {
    "text": "resources how big clusters are be able to create or how many services are able to create and stuff like this Wow okay",
    "start": "216000",
    "end": "222690"
  },
  {
    "text": "so can you talk about some of the things that have actually been done like what what is the largest cluster that we've",
    "start": "222690",
    "end": "229139"
  },
  {
    "start": "223000",
    "end": "337000"
  },
  {
    "text": "seen from sake scalability side of things maybe the beginnings of time and like where we are now how does that translate sure um so scale it is like",
    "start": "229139",
    "end": "237810"
  },
  {
    "text": "really long like or deferred like I've been it's like I said before we",
    "start": "237810",
    "end": "243660"
  },
  {
    "text": "currently support 5,000 node clusters and that's the biggest scale of clusters that we test for even in upstream and we",
    "start": "243660",
    "end": "252480"
  },
  {
    "text": "continuously ensure that every release scales to the scales to at least by thousand nodes so these tests are part",
    "start": "252480",
    "end": "258840"
  },
  {
    "text": "of the release process and the release validation process I think it was about two years ago and",
    "start": "258840",
    "end": "266400"
  },
  {
    "text": "released one point six Cuba nineties minor version one point six it was in cube Berlin that we actually",
    "start": "266400",
    "end": "273270"
  },
  {
    "text": "officially announced that Cuban it is scales to five thousand nodes before",
    "start": "273270",
    "end": "278490"
  },
  {
    "text": "that yeah it's a pretty interesting story back when Kuna started I think it",
    "start": "278490",
    "end": "283710"
  },
  {
    "text": "was really is one point or somewhere on that we just can't do like I know a few tens or like hundred node clusters and",
    "start": "283710",
    "end": "290689"
  },
  {
    "text": "there was like at that point obviously that's like a very big blocker for",
    "start": "290689",
    "end": "295939"
  },
  {
    "text": "enterprise adoption or even like regular production usage of Cuban artists so we",
    "start": "295939",
    "end": "302069"
  },
  {
    "text": "identified that well back then I wasn't on the project I this is like about the",
    "start": "302069",
    "end": "308159"
  },
  {
    "text": "thing I'm talking about it was like four years ago but yeah that's when we started the sake and we had quarterly goes to increase",
    "start": "308159",
    "end": "316169"
  },
  {
    "text": "the scale of Cuba I just so it was like hundred and you know five hundred two",
    "start": "316169",
    "end": "321330"
  },
  {
    "text": "thousand five thousand so it was a gradual process it took a while we made a lot of interesting improvements a lot",
    "start": "321330",
    "end": "327779"
  },
  {
    "text": "of them are contributed by six scalability and yeah I have a span of few releases we we could go to 5,000",
    "start": "327779",
    "end": "336479"
  },
  {
    "text": "nodes so okay so back in the day then when all this was going on the way that",
    "start": "336479",
    "end": "341610"
  },
  {
    "start": "337000",
    "end": "450000"
  },
  {
    "text": "you thought about kubernetes is really different if you were running kubernetes maybe you were thinking about it from a perspective of you might run many",
    "start": "341610",
    "end": "347250"
  },
  {
    "text": "clusters instead of running a single large cluster because it just couldn't handle that scale and so now is that is",
    "start": "347250",
    "end": "353009"
  },
  {
    "text": "that motion changing are we seeing more people that really want to have large clusters yeah so even more than like",
    "start": "353009",
    "end": "361979"
  },
  {
    "text": "thinking about large clusters are like multiple small clusters I think back then it was like still about the project to make sure to actually take any",
    "start": "361979",
    "end": "368539"
  },
  {
    "text": "enterprise adoption as well or like just to be used in production because because",
    "start": "368539",
    "end": "374759"
  },
  {
    "text": "people have will have questions like oh if it's scaling to 100 nodes only hundred nodes like does it actually make",
    "start": "374759",
    "end": "381389"
  },
  {
    "text": "sense to move to Cuba at this because what if I have to go over it and then I'm blocked by how to like redesign",
    "start": "381389",
    "end": "386729"
  },
  {
    "text": "another solution or use some other technology so so yeah you it was at that",
    "start": "386729",
    "end": "392490"
  },
  {
    "text": "point more about actually making it production ready yeah but this I think is much more relevant right now",
    "start": "392490",
    "end": "399379"
  },
  {
    "text": "as we actually scaled the large clusters this is being added a lot of places like",
    "start": "399379",
    "end": "404430"
  },
  {
    "text": "even in Cube Khan's we receive these these questions from a lot of folks if they should be using one large cluster",
    "start": "404430",
    "end": "410280"
  },
  {
    "text": "or like multiple small clusters and yeah the answer here is like it's kind of",
    "start": "410280",
    "end": "417150"
  },
  {
    "text": "blurry and it depends on what kind of usage okay you have and like there are",
    "start": "417150",
    "end": "422400"
  },
  {
    "text": "some some scalability or some dimensions of Cuba nitrous right now which don't it",
    "start": "422400",
    "end": "428430"
  },
  {
    "text": "still don't scale so well with the number of nodes hmm we're trying to fix those and we made a",
    "start": "428430",
    "end": "435030"
  },
  {
    "text": "lot of interesting points and in recent few releases but yeah so multiple small",
    "start": "435030",
    "end": "440250"
  },
  {
    "text": "clusters still seems like an option for those who are not able to scale to one big cluster okay and so when you think",
    "start": "440250",
    "end": "446520"
  },
  {
    "text": "about scaling a cluster we've been talking kind of more structured around nodes how does that translate into",
    "start": "446520",
    "end": "453389"
  },
  {
    "start": "450000",
    "end": "542000"
  },
  {
    "text": "things like pods as well and for those of you don't know pods are are a a grouping of containers all put together",
    "start": "453389",
    "end": "459960"
  },
  {
    "text": "into a single application package mm-hmm yep so so yeah that's an interesting",
    "start": "459960",
    "end": "466020"
  },
  {
    "text": "point I brought up so cube and this is not just about a cubed scalability is not just about the number of nodes or",
    "start": "466020",
    "end": "472889"
  },
  {
    "text": "the size of the cluster so like I was saying earlier there are a lot of different dimensions and it's Helium",
    "start": "472889",
    "end": "478500"
  },
  {
    "text": "scalability is really a multi-dimensional problem we have had some recent discussions around these as",
    "start": "478500",
    "end": "484650"
  },
  {
    "text": "well like in in our Sigma things and in cube cons so number of nodes is just one",
    "start": "484650",
    "end": "490529"
  },
  {
    "text": "dimension and there are many other dimensions that you can scale on the number of services the number of",
    "start": "490529",
    "end": "496490"
  },
  {
    "text": "namespaces number of pods you can have per node or number of ports you can have in total number of English says well if",
    "start": "496490",
    "end": "507210"
  },
  {
    "text": "you go about it there will be many many many dimensions because every feature or",
    "start": "507210",
    "end": "512430"
  },
  {
    "text": "like every aspect of the system that you can stretch on kind of ends up being one of the dimensions so yeah it's it's a",
    "start": "512430",
    "end": "519750"
  },
  {
    "text": "it's a really multi-dimensional problem and we've only recently started seeing this that way and actually try to find",
    "start": "519750",
    "end": "526829"
  },
  {
    "text": "out these bounds on different fronts and identify which of the ones which are like most problematic for our",
    "start": "526829",
    "end": "534459"
  },
  {
    "text": "users or or bounces that that people are asking for us to push further on yeah",
    "start": "534459",
    "end": "541870"
  },
  {
    "text": "okay so I was seeing some I was hearing about some changes we were making specifically things like like the node",
    "start": "541870",
    "end": "547839"
  },
  {
    "start": "542000",
    "end": "720000"
  },
  {
    "text": "object and what that was actually the the way that we had to change that as we grew up cluster as we built up clusters",
    "start": "547839",
    "end": "553209"
  },
  {
    "text": "because things were hitting the endpoints too much can you talk about that a little bit sure so um so this",
    "start": "553209",
    "end": "559750"
  },
  {
    "text": "kind of an old problem it is it has been known for a while but we actually started or we took action only recently",
    "start": "559750",
    "end": "567100"
  },
  {
    "text": "when we started seeing this problem for like bigger production clusters so so in",
    "start": "567100",
    "end": "576070"
  },
  {
    "text": "cuban it is the cubelets cubelets are the node demons or the node agent that",
    "start": "576070",
    "end": "581589"
  },
  {
    "text": "runs on every node and takes care of running the workload on those nodes so cubelet periodically posts updates to",
    "start": "581589",
    "end": "588459"
  },
  {
    "text": "the control plane it's called heartbeats just to tell the control plane that it's still alive it's basically your mechanism to let's",
    "start": "588459",
    "end": "595269"
  },
  {
    "text": "say if something goes bad with the node and the control plane will see stopped heartbeats and then it can like move the",
    "start": "595269",
    "end": "601690"
  },
  {
    "text": "workload from that node to a defendant and these heartbeats are they posted every few seconds something like I think",
    "start": "601690",
    "end": "608440"
  },
  {
    "text": "about 10 seconds and and this problem gets well this is not really a problem",
    "start": "608440",
    "end": "614529"
  },
  {
    "text": "for smaller clusters but as your cluster becomes bigger with let's say 5,000 nodes and every single node is going to",
    "start": "614529",
    "end": "621190"
  },
  {
    "text": "post a heartbeat every 10 seconds this ends up to be like a large QPS on the on",
    "start": "621190",
    "end": "626649"
  },
  {
    "text": "the control plane and that is even more aggravated by the fact that these node",
    "start": "626649",
    "end": "632920"
  },
  {
    "text": "objects can be really big because in these node objects it's its own it's",
    "start": "632920",
    "end": "638709"
  },
  {
    "text": "basically a float above that we also store the volumes and the images that",
    "start": "638709",
    "end": "644949"
  },
  {
    "text": "are in use on the on the node and that this can be pretty big so if these node",
    "start": "644949",
    "end": "650829"
  },
  {
    "text": "objects are like big and we and the nodes post like a new version of this for every heartbeat the the amount of",
    "start": "650829",
    "end": "658209"
  },
  {
    "text": "these node revisions grows so big that HCD discs actually fills up Wow okay so yet CD fills up and",
    "start": "658209",
    "end": "665600"
  },
  {
    "text": "when that happens the cluster is pretty much frozen from doing any more right",
    "start": "665600",
    "end": "671119"
  },
  {
    "text": "requests because there's no more space to do any right transactions on the",
    "start": "671119",
    "end": "676129"
  },
  {
    "text": "backend interests of this this is turned out to be a problem for some of our larger customers and yeah so the six",
    "start": "676129",
    "end": "686239"
  },
  {
    "text": "scalability has been working on the solution to fix this it's it's already beta by now and it's already also the",
    "start": "686239",
    "end": "692660"
  },
  {
    "text": "default so what we did was to actually split away the heartbeats from the node objects and just have like really small",
    "start": "692660",
    "end": "698980"
  },
  {
    "text": "objects dedicated just for the heartbeat okay oh nice and abstracting that away so you",
    "start": "698980",
    "end": "704540"
  },
  {
    "text": "don't have massive node objects that you're constantly pushing to you have smaller objects that you can do exactly",
    "start": "704540",
    "end": "709699"
  },
  {
    "text": "okay so does that reduce the load on Etsy do that yeah the Lord by a huge amount like of order of magnitude Wow",
    "start": "709699",
    "end": "716119"
  },
  {
    "text": "okay yeah and that helps you a ton over there with that CD so yeah can you talk about the the scalability of red CD in",
    "start": "716119",
    "end": "722600"
  },
  {
    "start": "720000",
    "end": "838000"
  },
  {
    "text": "general or in the project and what it is okay so for those who not familiar with",
    "start": "722600",
    "end": "727790"
  },
  {
    "text": "a CD so it's a very high level SCD is consistent distributed key-value store so we have a way like a simple API",
    "start": "727790",
    "end": "735290"
  },
  {
    "text": "just write read and the we also support a transaction but it is based on the",
    "start": "735290",
    "end": "742189"
  },
  {
    "text": "flag cable like a key space we don't have any and I call directory hierarchy or we don't have any neck open or the",
    "start": "742189",
    "end": "748639"
  },
  {
    "text": "code chart note like a like interconnection okay so it's just like key value space so you just write like a",
    "start": "748639",
    "end": "754699"
  },
  {
    "text": "foo bar and then you can read from the key value space and then also under the hood SCD is like distributed so we use",
    "start": "754699",
    "end": "762499"
  },
  {
    "text": "the rough consensus algorithm to replicate the data okay so I got three to five node so this is to give",
    "start": "762499",
    "end": "769850"
  },
  {
    "text": "communities control playing the high availability okay why we prioritized consistency so",
    "start": "769850",
    "end": "776059"
  },
  {
    "text": "like we now in the rough consensus algorithm so we it is based or poram",
    "start": "776059",
    "end": "781669"
  },
  {
    "text": "based system so we also LCD will continue to work as long as we have like",
    "start": "781669",
    "end": "789169"
  },
  {
    "text": "more than to make a node available ro3 node cluster okay so you can think of",
    "start": "789169",
    "end": "795740"
  },
  {
    "text": "city as a like sed provide more logic logical cost of view of many physical",
    "start": "795740",
    "end": "801560"
  },
  {
    "text": "servers so there was the sed but it's not only used in humanities is actually",
    "start": "801560",
    "end": "808430"
  },
  {
    "text": "quite popular open-source project so we have a lot of non community use cases so",
    "start": "808430",
    "end": "813740"
  },
  {
    "text": "uber uses sed to store their metadata like in of their time series database",
    "start": "813740",
    "end": "820280"
  },
  {
    "text": "called entry also NTT is Japanese telecommunication company they use a CD",
    "start": "820280",
    "end": "826880"
  },
  {
    "text": "to manage to manage their IOT devices Wow Braintree also uses s CD for to",
    "start": "826880",
    "end": "834170"
  },
  {
    "text": "power their caching system wow that's really awesome okay so now in the kubernetes world and",
    "start": "834170",
    "end": "840140"
  },
  {
    "start": "838000",
    "end": "928000"
  },
  {
    "text": "around eks and all of that stuff so it helps do its the backend store for kubernetes it basically manages all the",
    "start": "840140",
    "end": "846800"
  },
  {
    "text": "state that that Shawn's talking about so how does how do we because they're separate projects and it's used for so",
    "start": "846800",
    "end": "853160"
  },
  {
    "text": "many different things how do we keep those concerns together and how do we make sure that they always work together okay so so I can explain first how s it",
    "start": "853160",
    "end": "862370"
  },
  {
    "text": "is used for communities so actually if you look at the control plane of communities SCD is the only stable",
    "start": "862370",
    "end": "869510"
  },
  {
    "text": "component of communities so API server is the only component that talks to a CD",
    "start": "869510",
    "end": "875570"
  },
  {
    "text": "and then API server stores or cluster metadata in s CD so that's how we use s",
    "start": "875570",
    "end": "882710"
  },
  {
    "text": "CD and then in terms of working with kubernetes and other project we try to",
    "start": "882710",
    "end": "888880"
  },
  {
    "text": "like make s CD as independent as possible from any kind of next specific",
    "start": "888880",
    "end": "894800"
  },
  {
    "text": "project but we get like so much feedback from kubernetes so we kind of driving",
    "start": "894800",
    "end": "900320"
  },
  {
    "text": "the future development based on kubernetes use case ok so one use case i",
    "start": "900320",
    "end": "906170"
  },
  {
    "text": "can think of is so a CD has a lease object so we have a list object to keep",
    "start": "906170",
    "end": "912470"
  },
  {
    "text": "track of like a time to life so we humanity's use TT ER object to after or",
    "start": "912470",
    "end": "918560"
  },
  {
    "text": "like make a temporary object that expires after time to live okay",
    "start": "918560",
    "end": "924020"
  },
  {
    "text": "interesting is that for events oh really yeah",
    "start": "924020",
    "end": "929100"
  },
  {
    "start": "928000",
    "end": "1045000"
  },
  {
    "text": "so cuz the events object in kubernetes actually uses the sed lease object yeah wow that's really cool and so it has a",
    "start": "929100",
    "end": "935220"
  },
  {
    "text": "TTL on any of those events and they expire and yes basically you're garbage collected yeah because these objects are they committed in huge numbers yeah if",
    "start": "935220",
    "end": "941700"
  },
  {
    "text": "you want to periodically like TTL amount so Wow okay that's really cool yes so we",
    "start": "941700",
    "end": "950400"
  },
  {
    "text": "have all like suppressed which layer for lease or cuba net kiss like it has so",
    "start": "950400",
    "end": "955530"
  },
  {
    "text": "much of those they like he was hitting down like a scalability limit of nightly",
    "start": "955530",
    "end": "960690"
  },
  {
    "text": "storage so one thing we did a photo on for this release cycle we introduced a feature",
    "start": "960690",
    "end": "967230"
  },
  {
    "text": "called lease checkpoint okay so previously like whenever for STD is",
    "start": "967230",
    "end": "972810"
  },
  {
    "text": "litter based system so whenever leadership election happens we were refreshing the tip here of those leaves",
    "start": "972810",
    "end": "980220"
  },
  {
    "text": "object or back to normal I mean back to the original teeth here okay so and therefore kubernetes this case we have",
    "start": "980220",
    "end": "987360"
  },
  {
    "text": "all like of more than five-minute it here like assigned to each object I mean assigned to each lease object but",
    "start": "987360",
    "end": "993990"
  },
  {
    "text": "let's say leadership like election happens and then like the TTL hasn't been expired and then previously we just",
    "start": "993990",
    "end": "1001370"
  },
  {
    "text": "be setting those TTL back to five-minute so like as a result like the DOS object",
    "start": "1001370",
    "end": "1007130"
  },
  {
    "text": "I never got to expire Oh interesting so right now what we did to address this",
    "start": "1007130",
    "end": "1012230"
  },
  {
    "text": "issue we have a we chose checkpoint the least fit here onto disk using the raft",
    "start": "1012230",
    "end": "1017810"
  },
  {
    "text": "consensus algorithm and then whenever leadership election happens we just recovered we store from there nikhat",
    "start": "1017810",
    "end": "1023930"
  },
  {
    "text": "checkpointing ago least the conception foil gotcha okay that's really nice yeah so",
    "start": "1023930",
    "end": "1029839"
  },
  {
    "text": "basically and I got Cuban it is like helping us a lot like to like working on",
    "start": "1029839",
    "end": "1035270"
  },
  {
    "text": "the scalability of a CD database yeah I just remembered correctly but I heard",
    "start": "1035270",
    "end": "1045290"
  },
  {
    "start": "1045000",
    "end": "1120000"
  },
  {
    "text": "from someone that like Etsy implemented the watch API yeah for Cuban it is yeah",
    "start": "1045290",
    "end": "1050510"
  },
  {
    "text": "yeah because it was like getting expensive to like periodically just a CD",
    "start": "1050510",
    "end": "1056480"
  },
  {
    "text": "before before kubernetes I think so I'm 100% sure but maybe yes though there was",
    "start": "1056480",
    "end": "1061550"
  },
  {
    "text": "so working on SCDS since SD diversion - right now all communities using LCD p3",
    "start": "1061550",
    "end": "1069040"
  },
  {
    "text": "okay yeah so I think what Jim is talking about watch API in semantics in the LCD",
    "start": "1069040",
    "end": "1075520"
  },
  {
    "text": "version - where we do not have any like a stream like a cornice so whenever you",
    "start": "1075520",
    "end": "1082080"
  },
  {
    "text": "so right now we used to have on a cup holding like a based watch API yeah",
    "start": "1082080",
    "end": "1087640"
  },
  {
    "text": "now using the HTTP one but in the sed b3 we switch it to http to paste also G a",
    "start": "1087640",
    "end": "1094720"
  },
  {
    "text": "pc-based watch streaming API so right now is not polling based it's like a",
    "start": "1094720",
    "end": "1100240"
  },
  {
    "text": "pushed nothing like from the server side so that helped us a lot like to scale of",
    "start": "1100240",
    "end": "1106270"
  },
  {
    "text": "what she K and then we do have a watch epi poutine in sed well kubernetes api",
    "start": "1106270",
    "end": "1111640"
  },
  {
    "text": "server has their own like what make our cache layer yeah I'm just saying they do not overload Korres city so for those",
    "start": "1111640",
    "end": "1119620"
  },
  {
    "text": "people that are on the stream that are new to kubernetes can you explain what the watch api is or how kubernetes is",
    "start": "1119620",
    "end": "1125320"
  },
  {
    "start": "1120000",
    "end": "1248000"
  },
  {
    "text": "architected and how it uses that to basically build itself and be distributed sure so watch is basically a",
    "start": "1125320",
    "end": "1133390"
  },
  {
    "text": "streaming read request so the regular read request which is like just get an object or list a bunch of objects just",
    "start": "1133390",
    "end": "1141010"
  },
  {
    "text": "as one of fetching of those objects but often for instance a lot of controllers",
    "start": "1141010",
    "end": "1146770"
  },
  {
    "text": "that are running continuously on the control plane they need to continuously monitor a set of resources so let's say",
    "start": "1146770",
    "end": "1154480"
  },
  {
    "text": "a controller replication controller which whose job is to keep making sure",
    "start": "1154480",
    "end": "1159580"
  },
  {
    "text": "that the number of replicas are the number of pods that should exist for a",
    "start": "1159580",
    "end": "1164590"
  },
  {
    "text": "given replication controller is like matching a given number so it has to continuously",
    "start": "1164590",
    "end": "1171190"
  },
  {
    "text": "keep watching for for the current state of the system let's say if some part",
    "start": "1171190",
    "end": "1177010"
  },
  {
    "text": "dies or some part is deleted or some new port is created it has frequency in the state so so this is one of the primary",
    "start": "1177010",
    "end": "1183010"
  },
  {
    "text": "use cases to actually create a streaming read request which is basically an open",
    "start": "1183010",
    "end": "1188640"
  },
  {
    "text": "HTTP connection where you just say watch for these sort of objects of list for these objects so you",
    "start": "1188640",
    "end": "1197100"
  },
  {
    "text": "basically initially get a list of all the objects that you've asked for and then you're sent the diffs like the",
    "start": "1197100",
    "end": "1203370"
  },
  {
    "text": "deltas whenever a particular object changes you get an event saying that this object changed so this is an open",
    "start": "1203370",
    "end": "1208950"
  },
  {
    "text": "connection delivering changes to the to the set of objects and that makes that",
    "start": "1208950",
    "end": "1215910"
  },
  {
    "text": "make that improves the design pattern of the control plane a lot because because",
    "start": "1215910",
    "end": "1222120"
  },
  {
    "text": "now lot of these controls don't need to periodically make the whole list call mm-hmm like let's say if they're listing",
    "start": "1222120",
    "end": "1228570"
  },
  {
    "text": "100,000 objects and that's so that's a pretty huge amount of stuff to list for",
    "start": "1228570",
    "end": "1235050"
  },
  {
    "text": "so if you can do that like every 10 seconds that'll just overload the APS or way too much so so you want this watch",
    "start": "1235050",
    "end": "1241320"
  },
  {
    "text": "to just watch for those and like only get changes instead of periodically listening for the whole stuff correct",
    "start": "1241320",
    "end": "1248040"
  },
  {
    "start": "1248000",
    "end": "1350000"
  },
  {
    "text": "okay so that really allows it so like Kyo is saying allows it so that everything could could just pretty much",
    "start": "1248040",
    "end": "1254040"
  },
  {
    "text": "subscribe or watch against the the control plane yeah and then or the API server and stds behind it",
    "start": "1254040",
    "end": "1259890"
  },
  {
    "text": "fronting everything or storing all the actual data and the API servers really the the coordination between everything",
    "start": "1259890",
    "end": "1265200"
  },
  {
    "text": "and so everything doesn't have to connect into fcd itself everything can be distributed and and can just sit there and get events and",
    "start": "1265200",
    "end": "1271830"
  },
  {
    "text": "then take action on those do that reconciliation loop yeah it's very helpful to have a watching API because",
    "start": "1271830",
    "end": "1278070"
  },
  {
    "text": "like you but I can't keep the data up-to-date so I technically they can use",
    "start": "1278070",
    "end": "1283110"
  },
  {
    "text": "any database any other database to do this but the one thing sed has is so sed",
    "start": "1283110",
    "end": "1289530"
  },
  {
    "text": "implement like MPC scenic or storage which is multi-version concurrency control so whenever you write the key",
    "start": "1289530",
    "end": "1296880"
  },
  {
    "text": "value store into the city we store all the historical provision Wow let's say",
    "start": "1296880",
    "end": "1302520"
  },
  {
    "text": "so humanity is watching on this object but s a dystopic goes down- connected",
    "start": "1302520",
    "end": "1308550"
  },
  {
    "text": "from Q manages control plane but communities acres of are still stores the nekoma vision which is like a global",
    "start": "1308550",
    "end": "1315900"
  },
  {
    "text": "index incremental index so when SVD comes back to one AG's",
    "start": "1315900",
    "end": "1322120"
  },
  {
    "text": "can next year like a fetch those historical data using the revision oh wow there's something fcd provide to",
    "start": "1322120",
    "end": "1329440"
  },
  {
    "text": "like give you order like as much data like wow never lose the data in terms of",
    "start": "1329440",
    "end": "1335740"
  },
  {
    "text": "you know cuban ages wow so somebody coming from like a relational database that'd be like having a full on versions",
    "start": "1335740",
    "end": "1341260"
  },
  {
    "text": "table for every single resource that goes into it and being it with it wow that that's a wild architecture that's really cool yeah that makes it",
    "start": "1341260",
    "end": "1347559"
  },
  {
    "text": "really nice too for how i build this so how does so how does CD as a team that's",
    "start": "1347559",
    "end": "1355240"
  },
  {
    "start": "1350000",
    "end": "1562000"
  },
  {
    "text": "kind of independently developing make sure that any of those changes constantly are working are you integrated with the automated testing",
    "start": "1355240",
    "end": "1361809"
  },
  {
    "text": "that's going on with like six scalability how does that work yeah so",
    "start": "1361809",
    "end": "1366850"
  },
  {
    "text": "so uh yeah this is a this is something we pay a lot of attention to in the",
    "start": "1366850",
    "end": "1372850"
  },
  {
    "text": "community which is a testing closely with the HCD versions so we have this Cuban does release cadence of having one",
    "start": "1372850",
    "end": "1380950"
  },
  {
    "text": "release approximately every three months so about four days is in your and HCD",
    "start": "1380950",
    "end": "1386860"
  },
  {
    "text": "also has its cadence for its releases and every release and Cuban it is we are",
    "start": "1386860",
    "end": "1394390"
  },
  {
    "text": "like bumping up th CD version because just to pick up some fixes and stuff and",
    "start": "1394390",
    "end": "1400179"
  },
  {
    "text": "a lot of those fixes and improvements are actually driven by the requirements",
    "start": "1400179",
    "end": "1405190"
  },
  {
    "text": "that Cuban it is ask has asked from a CD so yeah it's a closely coupled loop",
    "start": "1405190",
    "end": "1413230"
  },
  {
    "text": "where basically we're asking them for some improvements and stuff and they're they're making fixes and improvements",
    "start": "1413230",
    "end": "1419020"
  },
  {
    "text": "and they continue releases we use those new releases as the default HDD version",
    "start": "1419020",
    "end": "1425500"
  },
  {
    "text": "in that particular commander studies and then we are testing it for the duration of the of the release which is like",
    "start": "1425500",
    "end": "1431770"
  },
  {
    "text": "about three months and yeah there's a lot of validation that goes along with it scalability testing is like one big",
    "start": "1431770",
    "end": "1437350"
  },
  {
    "text": "component of it often we end up catching performance issues with that city during",
    "start": "1437350",
    "end": "1443080"
  },
  {
    "text": "these scale tests and we realize okay this said CD u version has some issue or",
    "start": "1443080",
    "end": "1448270"
  },
  {
    "text": "okay this a3 version actually gives a lot of perform improvement and yeah and then we just uh",
    "start": "1448270",
    "end": "1454200"
  },
  {
    "text": "if everything looks fine we cut a noodle East with the new recommended CD version",
    "start": "1454200",
    "end": "1459929"
  },
  {
    "text": "or often we just end up rewarding to the old version if you found some issues and couldn't fix it for the release on time",
    "start": "1459929",
    "end": "1465520"
  },
  {
    "text": "gotcha okay so when will you actually release the kubernetes version we also say that this is the sed version that you're",
    "start": "1465520",
    "end": "1471040"
  },
  {
    "text": "supposed to work with that'll go for that 3ish month period of that release yeah that will carry through and support for another three",
    "start": "1471040",
    "end": "1477460"
  },
  {
    "text": "months or three releases each yeah so on and so forth okay going forward that's really cool okay so actually this",
    "start": "1477460",
    "end": "1483850"
  },
  {
    "text": "is one more an interesting thing that we developed a framework called cube mark",
    "start": "1483850",
    "end": "1489010"
  },
  {
    "text": "which runs simulated clusters it's kind of a benchmarking framework which runs",
    "start": "1489010",
    "end": "1495580"
  },
  {
    "text": "like load tests against the equipment is control plane by edges creating hollow",
    "start": "1495580",
    "end": "1500679"
  },
  {
    "text": "nodes if you don't actually create a real cluster like you just create fake nodes we just talk to the control panel like exert some load on it and so this",
    "start": "1500679",
    "end": "1510070"
  },
  {
    "text": "this is again is something which came out of six scalability and now it's so",
    "start": "1510070",
    "end": "1515410"
  },
  {
    "text": "much in use that I think HCD also has adopted cube mark into its own release",
    "start": "1515410",
    "end": "1520870"
  },
  {
    "text": "process so now it's CD which is like upstream 4 cubed is now uses so there's",
    "start": "1520870",
    "end": "1526410"
  },
  {
    "text": "collaboration between between the groups that's fantastic so it's not like we have to worry that scg's gonna go away",
    "start": "1526410",
    "end": "1531850"
  },
  {
    "text": "over here and we're gonna be still stuck on an older version yeah for some reason that's great ok yeah so whenever we",
    "start": "1531850",
    "end": "1538900"
  },
  {
    "text": "caught a new minor release or major release we make sure we're on to skew more like a stimulative cube annexed",
    "start": "1538900",
    "end": "1545140"
  },
  {
    "text": "Cuba natives were close against our release branch n is for a month make",
    "start": "1545140",
    "end": "1550450"
  },
  {
    "text": "sure like it doesn't introduce any regression Wow thank you when it is and then a city is",
    "start": "1550450",
    "end": "1556150"
  },
  {
    "text": "quite a stable project so we just want to make sure we don't break anything yeah yeah very cool and so in terms of",
    "start": "1556150",
    "end": "1564580"
  },
  {
    "start": "1562000",
    "end": "2016000"
  },
  {
    "text": "those so you run those tests for a whole month at a time and just see if anything comes up in that month before you",
    "start": "1564580",
    "end": "1569710"
  },
  {
    "text": "actually cut a real release of it yeah yeah slaw like right now like last time we did it was all manual process I'm",
    "start": "1569710",
    "end": "1576220"
  },
  {
    "text": "just like a setup for Prometheus I go graphic on a dashboard against a CD also LCD also",
    "start": "1576220",
    "end": "1583110"
  },
  {
    "text": "and endpoint to exposed Nyko metrics data for those that don't know what Prometheus you want to give them a slow",
    "start": "1583110",
    "end": "1590039"
  },
  {
    "text": "Prometheus is like there's a two-component Prometheus time ceased database or slow SCD uses Prometheus",
    "start": "1590039",
    "end": "1597510"
  },
  {
    "text": "client to expose the neck encounter or like any kind of matrix data or through",
    "start": "1597510",
    "end": "1603870"
  },
  {
    "text": "the HTTP endpoint gotcha so we use that to monitor the sed",
    "start": "1603870",
    "end": "1608909"
  },
  {
    "text": "cluster why we running the simulated a community's workload using cube mark okay sed and yours recording all the the",
    "start": "1608909",
    "end": "1616470"
  },
  {
    "text": "metrics that come out of it their sport and then if anything like oh let's say",
    "start": "1616470",
    "end": "1621750"
  },
  {
    "text": "memory make a spike right like like more than we expected then we go inspect Oh like a sed process",
    "start": "1621750",
    "end": "1629240"
  },
  {
    "text": "yeah that's the sed release process that's awesome okay and so in terms of so how does like",
    "start": "1629240",
    "end": "1638370"
  },
  {
    "text": "the roadmap or where we're at CDs been or is going towards translate to the",
    "start": "1638370",
    "end": "1644309"
  },
  {
    "text": "scalability of it these days okay sure so the LCD is quite stable I I don't",
    "start": "1644309",
    "end": "1650100"
  },
  {
    "text": "think we're gonna adding like any Nikon new major features in the near future but still there's like still like a lot",
    "start": "1650100",
    "end": "1658049"
  },
  {
    "text": "of things we have in doing to improve the reliability and the stability of a",
    "start": "1658049",
    "end": "1663269"
  },
  {
    "text": "CD Projekt okay so so one thing we did so like in so we look at all like large",
    "start": "1663269",
    "end": "1670470"
  },
  {
    "text": "scale IQ an 80s cluster like against a CD and then we found out like the large",
    "start": "1670470",
    "end": "1676919"
  },
  {
    "text": "cluster tend to have our long wheat transactions like that involved like",
    "start": "1676919",
    "end": "1682200"
  },
  {
    "text": "right large range of like a range request which is a quick request okay let's say the kubernetes cluster heads",
    "start": "1682200",
    "end": "1689370"
  },
  {
    "text": "are like 1000 part or like 1000 mode and then they want to get like a list of all",
    "start": "1689370",
    "end": "1694380"
  },
  {
    "text": "those nodes then it would send my god right large range of Macready requests",
    "start": "1694380",
    "end": "1699720"
  },
  {
    "text": "to a CD and they would create like a longneck with transaction and they if you have a lot of those like read",
    "start": "1699720",
    "end": "1706200"
  },
  {
    "text": "request we can have a like a head of line blocking problem issue okay so request keep coming in and they",
    "start": "1706200",
    "end": "1712799"
  },
  {
    "text": "just keep true doubt but SAT is not fasting up to return those like read requests",
    "start": "1712799",
    "end": "1718350"
  },
  {
    "text": "gotcha and then in a city side we also have our nitro right to injection on one",
    "start": "1718350",
    "end": "1724200"
  },
  {
    "text": "if you have a lot of doors at the same time he can not block each other and then especially for the DECA right",
    "start": "1724200",
    "end": "1731610"
  },
  {
    "text": "we only allowed one right transaction like inside a CD but if you have a lot",
    "start": "1731610",
    "end": "1737970"
  },
  {
    "text": "of requests coming in those we request like in client side would timeout so and",
    "start": "1737970",
    "end": "1744240"
  },
  {
    "text": "then like previously we didn't have enough concurrency to handle those like large number negative requests so for",
    "start": "1744240",
    "end": "1751590"
  },
  {
    "text": "this upcoming released we improved our conference indentical stretch layer so",
    "start": "1751590",
    "end": "1757020"
  },
  {
    "text": "that's one thing we did like based on feedback from kubernetes community and",
    "start": "1757020",
    "end": "1762210"
  },
  {
    "text": "then to make another feature called is called a non-voting member so this is",
    "start": "1762210",
    "end": "1768120"
  },
  {
    "text": "not specific to performance or scalability of SED but this is more to",
    "start": "1768120",
    "end": "1773970"
  },
  {
    "text": "help like a community with operational workload so SCD for now every each",
    "start": "1773970",
    "end": "1780659"
  },
  {
    "text": "member has has to vote for leadership election and then also each member",
    "start": "1780659",
    "end": "1786600"
  },
  {
    "text": "counted as a NATO membership so if you have all three members in the cluster the column size would be two and then",
    "start": "1786600",
    "end": "1795059"
  },
  {
    "text": "the cluster size would be three but we adding a new type of membership a new",
    "start": "1795059",
    "end": "1800640"
  },
  {
    "text": "type of member called a non-voting member so and then this so I can get",
    "start": "1800640",
    "end": "1806610"
  },
  {
    "text": "back to the like leadership election part so let's say you have all like on three node cluster and then like all the",
    "start": "1806610",
    "end": "1813450"
  },
  {
    "text": "right we cast ghostwritten leader but like if you have a lot of like on like right coming into the leader but let's",
    "start": "1813450",
    "end": "1821370"
  },
  {
    "text": "say there's some like network issue so network packets are being delayed so Nicole data replication from leader to",
    "start": "1821370",
    "end": "1829080"
  },
  {
    "text": "follower can be slow in that case what a follower can be like Oh slow down and",
    "start": "1829080",
    "end": "1834870"
  },
  {
    "text": "then falling behind the leader so in the case it can overload like a leader back",
    "start": "1834870",
    "end": "1841020"
  },
  {
    "text": "on process like a little note but if so and then they can also like a trigger to",
    "start": "1841020",
    "end": "1846690"
  },
  {
    "text": "heartbeat time off from the little note okay but what if we have all what if we have our",
    "start": "1846690",
    "end": "1853249"
  },
  {
    "text": "non-voting member so a non-voting member can join the cluster as a like a non-voting member but still like then",
    "start": "1853249",
    "end": "1860869"
  },
  {
    "text": "member does not count as a quorum oh then not can be can still do in the",
    "start": "1860869",
    "end": "1866719"
  },
  {
    "text": "cluster and they are still getting all the data they need okay but it won't affect affect cluster",
    "start": "1866719",
    "end": "1872450"
  },
  {
    "text": "availability as much okay Oh cluster itself doesn't require that as much",
    "start": "1872450",
    "end": "1878899"
  },
  {
    "text": "nagapuram number so is that so that we could so if you have a non-voting member does that mean that you could use that",
    "start": "1878899",
    "end": "1884869"
  },
  {
    "text": "to basically pull in all the data and have it all replicated across it yes and if something were to happen you always",
    "start": "1884869",
    "end": "1890629"
  },
  {
    "text": "have that as like a backup kind of so kampachi standby great okay that's",
    "start": "1890629",
    "end": "1896029"
  },
  {
    "text": "really cool yeah all right what else is on the roadmap for a CD or so we planning to support downgrade so I think",
    "start": "1896029",
    "end": "1904700"
  },
  {
    "text": "that in operating like s CD even for a SS scale like I feel like if you have a",
    "start": "1904700",
    "end": "1910429"
  },
  {
    "text": "on like a four pack or like a rollback process for a CD upgrade is I think it",
    "start": "1910429",
    "end": "1916039"
  },
  {
    "text": "will be very useful for communities community but right now SCD like our",
    "start": "1916039",
    "end": "1921469"
  },
  {
    "text": "insurer I mean provide or the record compatibility and the older data format",
    "start": "1921469",
    "end": "1926599"
  },
  {
    "text": "is data compatibility but just to prevent Nikon unintended",
    "start": "1926599",
    "end": "1932059"
  },
  {
    "text": "like oh like a failure string upgrade process so we trying to make in the",
    "start": "1932059",
    "end": "1938119"
  },
  {
    "text": "server side we prevent don't STD downgrade so basically you cannot",
    "start": "1938119",
    "end": "1943339"
  },
  {
    "text": "downgrade from SCT 3.32 down to 3.2 right you cannot do that because right",
    "start": "1943339",
    "end": "1950450"
  },
  {
    "text": "now we think the maintainer just make sure like you have to go forward connect",
    "start": "1950450",
    "end": "1957320"
  },
  {
    "text": "to the POC this is only for the future release but right now like a lot of humanities community is still stuck in",
    "start": "1957320",
    "end": "1964219"
  },
  {
    "text": "Dornoch old release yesterday 3.1 so we have the use case now then now we want",
    "start": "1964219",
    "end": "1970399"
  },
  {
    "text": "to support the rollback process catcher so we gonna error like new like a small",
    "start": "1970399",
    "end": "1975740"
  },
  {
    "text": "a lot on like a city town great so when they were like upgrade from to newer",
    "start": "1975740",
    "end": "1981170"
  },
  {
    "text": "versions of sed phase you can now just safely go back to the old version so",
    "start": "1981170",
    "end": "1986570"
  },
  {
    "text": "would that make it so that we could have kubernetes could you could be testing releases against different versions of",
    "start": "1986570",
    "end": "1992240"
  },
  {
    "text": "sed almost you could have your current version running and upgrade to a new version of kubernetes and setup at CD",
    "start": "1992240",
    "end": "1998750"
  },
  {
    "text": "running the the newer version and have that in standby and go oh wait there's something wrong with this we weird we're",
    "start": "1998750",
    "end": "2004090"
  },
  {
    "text": "not ready to actually migrate and be able to downgrade back down to that stable release for communities yeah yeah fantastic that's really cool that'll be",
    "start": "2004090",
    "end": "2010690"
  },
  {
    "text": "that'll make a lot more stable clusters and a lot upgrades a lot easier for everybody yeah okay cool and I heard",
    "start": "2010690",
    "end": "2017260"
  },
  {
    "start": "2016000",
    "end": "2356000"
  },
  {
    "text": "something from from the community side of things that where there's some like multi-tenancy work going on as well because right now it's it's a single",
    "start": "2017260",
    "end": "2023380"
  },
  {
    "text": "tenant database correct yeah so I don't think this is specific to a CD but I",
    "start": "2023380",
    "end": "2028600"
  },
  {
    "text": "know a lot of community is working on the market and kubernetes control plane oh yeah so when we say multi tenant control",
    "start": "2028600",
    "end": "2036160"
  },
  {
    "text": "plane like they want to have our like a 1 Q 1 it is cluster born echo they want to have some like isolation between like",
    "start": "2036160",
    "end": "2043210"
  },
  {
    "text": "multiple tenant yeah they say like multiple customers but right now it's kind of hard because communities like",
    "start": "2043210",
    "end": "2050050"
  },
  {
    "text": "there's no network isolation in like communities like on networking Mauro so I think some folks from like Alibaba",
    "start": "2050050",
    "end": "2059649"
  },
  {
    "text": "they're working to introduce the concept called networking namespace ok but right",
    "start": "2059650",
    "end": "2065860"
  },
  {
    "text": "now if you just have a multiple like a tenant in one to one like unit is control plane it would break talk unit",
    "start": "2065860",
    "end": "2072159"
  },
  {
    "text": "is like a service there's no isolation between well they want to introduce some",
    "start": "2072160",
    "end": "2077290"
  },
  {
    "text": "like a hierarchy into networking namespace so they can have all like on a good isolation between namespaces yeah",
    "start": "2077290",
    "end": "2084730"
  },
  {
    "text": "but in SI decide is pretty knockin simple because we have our key we have",
    "start": "2084730",
    "end": "2089860"
  },
  {
    "text": "our flat key space and then we also have a feature called namespace so",
    "start": "2089860",
    "end": "2095020"
  },
  {
    "text": "technically you can have your own like a namespace in SCP okay and then have",
    "start": "2095020",
    "end": "2100420"
  },
  {
    "text": "those all those isolation between so it's a key value store with as well a namespace that you can add on",
    "start": "2100420",
    "end": "2106460"
  },
  {
    "text": "that yes okay cool so you could have namespaced keys yeah and then alright and then you could have multiple",
    "start": "2106460",
    "end": "2111500"
  },
  {
    "text": "namespace keys per customer for example in that multi tenant kubernetes world yes okay cool",
    "start": "2111500",
    "end": "2117680"
  },
  {
    "text": "and does that translate down to the actual physical storage of like the keys into the hood as well it actually",
    "start": "2117680",
    "end": "2123109"
  },
  {
    "text": "separates them oh we have physical isolation as well oh okay under the hood it just wrapper",
    "start": "2123109",
    "end": "2129619"
  },
  {
    "text": "on top of como si declined okay so it just perfect oh so a TV itself is quite",
    "start": "2129619",
    "end": "2138589"
  },
  {
    "text": "agnostic off the namespaces yet but we can program the keys in such a way that",
    "start": "2138589",
    "end": "2143990"
  },
  {
    "text": "we can isolate different namespace so different namespaces will have different prefixes for their keys perfect sense",
    "start": "2143990",
    "end": "2149780"
  },
  {
    "text": "okay cool all right so going back to the kubernetes and and six scalability and",
    "start": "2149780",
    "end": "2156170"
  },
  {
    "text": "scalability in general and building large clusters what are the pain points you actually look for from this from six",
    "start": "2156170",
    "end": "2161990"
  },
  {
    "text": "scalability and what do you with your all your experience in this space what are the pain points that you see with",
    "start": "2161990",
    "end": "2167180"
  },
  {
    "text": "kubernetes and how it scales so yeah let",
    "start": "2167180",
    "end": "2172430"
  },
  {
    "text": "me think of some of the common pain points one of the thing which kind of",
    "start": "2172430",
    "end": "2178250"
  },
  {
    "text": "comes up from time to time is scalability of the networking plane of",
    "start": "2178250",
    "end": "2183680"
  },
  {
    "text": "cuban itís so we have a bunch of some scalability limits that we started",
    "start": "2183680",
    "end": "2189260"
  },
  {
    "text": "hitting as we started using like really large number of services or really big services so so for instance there is in",
    "start": "2189260",
    "end": "2200450"
  },
  {
    "text": "increment as we use IP tables to actually program the networking layer for service load balancing and so is",
    "start": "2200450",
    "end": "2207470"
  },
  {
    "text": "routing on each of the nodes so IP tables is parcel Linux kernel and it's",
    "start": "2207470",
    "end": "2213290"
  },
  {
    "text": "basically it implements these routing rules and we've seen performance issues",
    "start": "2213290",
    "end": "2218660"
  },
  {
    "text": "with that when there are large number of services because because IP team is not",
    "start": "2218660",
    "end": "2224390"
  },
  {
    "text": "worried it's not super efficient when when as you start having thousands of",
    "start": "2224390",
    "end": "2230030"
  },
  {
    "text": "rules and you're Cheng's so with it so is there like a bunch of rules that have programmed into",
    "start": "2230030",
    "end": "2237079"
  },
  {
    "text": "IP tables and like if you have a large number of services or like really big services this can be a bottleneck for",
    "start": "2237079",
    "end": "2244400"
  },
  {
    "text": "your network programming so that's that's something there's been a little",
    "start": "2244400",
    "end": "2249470"
  },
  {
    "text": "bit of a problem for some really power users try to like use bigger services",
    "start": "2249470",
    "end": "2257960"
  },
  {
    "text": "but but the good thing is we have an alternative to IP tables called IP V s",
    "start": "2257960",
    "end": "2264279"
  },
  {
    "text": "IP virtual server which which is not completely an alternative to IP tables",
    "start": "2264279",
    "end": "2269660"
  },
  {
    "text": "because it does not do some some of the it doesn't have some of the functionality that IP table cells but",
    "start": "2269660",
    "end": "2275480"
  },
  {
    "text": "the the bigger part of IP tables where we actually are seeing the scalability",
    "start": "2275480",
    "end": "2281150"
  },
  {
    "text": "issues which is the service load balancing point IP V s is an alternative and it actually stores these rules in a",
    "start": "2281150",
    "end": "2288289"
  },
  {
    "text": "better wait it used better data structures to actually store this so instead of a linear list which is what",
    "start": "2288289",
    "end": "2294410"
  },
  {
    "text": "IP tables uses IP huius uses hash tables which is much faster and gives you like orders of",
    "start": "2294410",
    "end": "2301299"
  },
  {
    "text": "magnitude higher throughput and like really fast packet routing okay IPP SSgA",
    "start": "2301299",
    "end": "2308690"
  },
  {
    "text": "Cuban it is in release 111 okay but it's still not the default we're testing it out and we're trying to see what does",
    "start": "2308690",
    "end": "2317020"
  },
  {
    "text": "basically waiting for some production usage of y PVS and get some more signal and still go through some bug fixes yeah",
    "start": "2317020",
    "end": "2325190"
  },
  {
    "text": "that that seems to be one of the promising alternatives that's a pretty simple change in kubernetes in terms of",
    "start": "2325190",
    "end": "2330529"
  },
  {
    "text": "like at least we've made it pretty simple like it's a couple flags that you pass into the actual control plane and",
    "start": "2330529",
    "end": "2336559"
  },
  {
    "text": "cubelet right yeah so this is one of the best things about command aside like you can have a lot of things extensible and",
    "start": "2336559",
    "end": "2343279"
  },
  {
    "text": "pluggable and cuban it is you can just like swap out for stuff so yeah so we yeah it's pretty much about changing",
    "start": "2343279",
    "end": "2349160"
  },
  {
    "text": "these flags and just use a different interfaces that are exposed are so cool",
    "start": "2349160",
    "end": "2355609"
  },
  {
    "text": "that we have all of these different endpoints that we can play with all right so what about like so when you",
    "start": "2355609",
    "end": "2360890"
  },
  {
    "start": "2356000",
    "end": "2594000"
  },
  {
    "text": "actually get into large clusters do you I need to do like scheduling issues to think it's slow at all or how does like I imagine",
    "start": "2360890",
    "end": "2367730"
  },
  {
    "text": "when you have large numbers of services that your IP tables take a long time to write if you're still using that what",
    "start": "2367730",
    "end": "2373370"
  },
  {
    "text": "else what else happens sure we do have our fair share of scheduling problems and like any big system has to face your",
    "start": "2373370",
    "end": "2380720"
  },
  {
    "text": "dueling problems at some point and cupid's does that as well so yeah so",
    "start": "2380720",
    "end": "2386150"
  },
  {
    "text": "we've had we've seen a drop in the shed you low throughput and like an increase",
    "start": "2386150",
    "end": "2391910"
  },
  {
    "text": "in the scheduling Layton sees as you go to larger clusters like of the order of thousands of nodes so for instance I can",
    "start": "2391910",
    "end": "2398300"
  },
  {
    "text": "talk a little bit about of 5000 clusters where we actually on our scale tests so we we we are seeing much lesser sheduled",
    "start": "2398300",
    "end": "2409100"
  },
  {
    "text": "in throughput on fertile node I think the peak we go is about like 30 pots per",
    "start": "2409100",
    "end": "2415010"
  },
  {
    "text": "second okay with some of the some of the parameters sweet we are able to achieve del 30 pots per second or there's the",
    "start": "2415010",
    "end": "2422150"
  },
  {
    "text": "case of one or two releases ago while on really small just as it's fast and it's",
    "start": "2422150",
    "end": "2429320"
  },
  {
    "text": "it's kind of expectable that this happens because when there are large",
    "start": "2429320",
    "end": "2434510"
  },
  {
    "text": "number of nodes scheduled it has to go through a larger list of things to evaluate so it takes more time for it to",
    "start": "2434510",
    "end": "2441110"
  },
  {
    "text": "actually share your report then there's a drop and throughput but recently we made some of the there are a bunch of",
    "start": "2441110",
    "end": "2449270"
  },
  {
    "text": "improvements that six scheduling which is the special interest group that focuses on scheduling has been making a",
    "start": "2449270",
    "end": "2454760"
  },
  {
    "text": "bunch of improvements and will be in collaborating with them with scale tests and suggesting some of the improvements",
    "start": "2454760",
    "end": "2460370"
  },
  {
    "text": "from our side so one of the things which I would consider is like big change with",
    "start": "2460370",
    "end": "2467480"
  },
  {
    "text": "scheduling is a change in the algorithm which now allows only e to score a",
    "start": "2467480",
    "end": "2474680"
  },
  {
    "text": "subset of nodes instead of evaluating all the nodes so this is kind of a heuristic this is this is used in some",
    "start": "2474680",
    "end": "2483470"
  },
  {
    "text": "of the big systems just to improve scheduling we don't now to go through",
    "start": "2483470",
    "end": "2488960"
  },
  {
    "text": "all the 5,000 nodes for each pod to schedule we just initially filter",
    "start": "2488960",
    "end": "2496280"
  },
  {
    "text": "some of the nodes so so scheduler has these two phases of predicates and priorities so the first phase when",
    "start": "2496280",
    "end": "2501710"
  },
  {
    "text": "predicates run they basically eliminate all the nodes which are unfit for the pods probably because they don't have",
    "start": "2501710",
    "end": "2506960"
  },
  {
    "text": "enough resources so they have a mismatching affinity with the pod and",
    "start": "2506960",
    "end": "2513050"
  },
  {
    "text": "stuff like that so once those are filtered the remaining nodes which are all like shade available nodes are now a",
    "start": "2513050",
    "end": "2518359"
  },
  {
    "text": "science course this is the priority phase where each of the nodes is assigned a score and based on the one",
    "start": "2518359",
    "end": "2523580"
  },
  {
    "text": "with the highest score we just go ahead and assign the part to that one so now the change in scheduler now basically",
    "start": "2523580",
    "end": "2530410"
  },
  {
    "text": "takes once you get like a small percentage of the scheduled level nodes",
    "start": "2530410",
    "end": "2537050"
  },
  {
    "text": "you don't do predicates anymore you directly go to the priorities phase and just for that small subset you evaluate",
    "start": "2537050",
    "end": "2542270"
  },
  {
    "text": "though evaluate the priorities and and then you are saying so that that that has given us a bump in the scheduler",
    "start": "2542270",
    "end": "2550130"
  },
  {
    "text": "throughput and that along with some of the other improvements so there was some",
    "start": "2550130",
    "end": "2556130"
  },
  {
    "text": "data structure improvements which shedule or caching and snapshotting all",
    "start": "2556130",
    "end": "2561530"
  },
  {
    "text": "this together is like now taking us to a throughput of 104 close to hundred pots per second out of 5000 not just and",
    "start": "2561530",
    "end": "2568070"
  },
  {
    "text": "that's a pretty big number 100 parts per second yeah Wow and that's amazing 100 pods so",
    "start": "2568070",
    "end": "2577940"
  },
  {
    "text": "in that 5000 old cluster how many pods you're actually testing with so we test for about 150,000 parts which is like 30",
    "start": "2577940",
    "end": "2586010"
  },
  {
    "text": "parts per load Wow India and the scheduling part just goes quite fast",
    "start": "2586010",
    "end": "2591140"
  },
  {
    "text": "that's amazing that's really cool okay anything else in the in the like",
    "start": "2591140",
    "end": "2597380"
  },
  {
    "start": "2594000",
    "end": "2841000"
  },
  {
    "text": "networking space or anything to do with yeah anything else in the networking space for gel or things in networking",
    "start": "2597380",
    "end": "2604550"
  },
  {
    "text": "space so yeah so iptables was one of the things I already talked about earlier there that's more like the",
    "start": "2604550",
    "end": "2612700"
  },
  {
    "text": "infrastructure layer below kubernetes now there's also some scalability issues",
    "start": "2612700",
    "end": "2620690"
  },
  {
    "text": "we have seen with the the implementation of services and endpoints incubators so",
    "start": "2620690",
    "end": "2628330"
  },
  {
    "text": "endpoints is so among the different API objects that Cuba s uses endpoints is one of them",
    "start": "2628330",
    "end": "2634970"
  },
  {
    "text": "endpoint basically stores a list of all the Ford IPS that are below a service so",
    "start": "2634970",
    "end": "2641270"
  },
  {
    "text": "each service maps to a service endpoint object and that whole holds a list of these IPS and and we started seeing",
    "start": "2641270",
    "end": "2649280"
  },
  {
    "text": "issues when we use really big services because they have a lot of parts below",
    "start": "2649280",
    "end": "2654680"
  },
  {
    "text": "it like let's say our thousand pods per service then this endpoint object is basically thousand entries and because",
    "start": "2654680",
    "end": "2662089"
  },
  {
    "text": "it shows everything in one object has one single list whenever let's say if one part goes down or one new pod comes",
    "start": "2662089",
    "end": "2668119"
  },
  {
    "text": "up you have to like change this whole object which is already pretty bit of a big object and then post it to the back",
    "start": "2668119",
    "end": "2675080"
  },
  {
    "text": "in net CD so that that ends up using a lot of firstly quite some space because",
    "start": "2675080",
    "end": "2681349"
  },
  {
    "text": "of these divisions but the bigger problem is actually that the amount of the amount of the volume of these",
    "start": "2681349",
    "end": "2688339"
  },
  {
    "text": "endpoints objects that flows through the cluster when let's say this is a rolling upgrade of a service or few parts come",
    "start": "2688339",
    "end": "2696230"
  },
  {
    "text": "down or go up is really huge so this is quadratic if you do the math it's",
    "start": "2696230",
    "end": "2701359"
  },
  {
    "text": "basically as you keep adding more and more pods so the amount of stuff that",
    "start": "2701359",
    "end": "2706910"
  },
  {
    "text": "you are sending to the API server for writes is quadratic and it's even more than quadratic for reads because each of",
    "start": "2706910",
    "end": "2713270"
  },
  {
    "text": "the nodes have to now read these this is the queue proxy which is the network configuration daemon on the nodes and",
    "start": "2713270",
    "end": "2720950"
  },
  {
    "text": "that has to like read all these queue proxies so yeah that can become a big mess so again the good thing is here we",
    "start": "2720950",
    "end": "2727250"
  },
  {
    "text": "are working on fixing this so there is a design or it's still being worked on",
    "start": "2727250",
    "end": "2734140"
  },
  {
    "text": "with within six scalability and also we are collaborating with cig network to to have a new API for the endpoints so that",
    "start": "2734140",
    "end": "2742730"
  },
  {
    "text": "we just don't we can break we can slice this huge list of this huge list object",
    "start": "2742730",
    "end": "2749180"
  },
  {
    "text": "into like smaller objects and have update them so that we can cool more efficient is there a cap for that yeah",
    "start": "2749180",
    "end": "2756050"
  },
  {
    "text": "that is there is a cap for that there is a proposal definitely I think",
    "start": "2756050",
    "end": "2761540"
  },
  {
    "text": "there's also a copy on our hung group wasn't shown for those of them on their stream would you like to explain what like what a cap is sure so kept sound",
    "start": "2761540",
    "end": "2769130"
  },
  {
    "text": "for I think you meant is enhancement proposal which basically is the is the",
    "start": "2769130",
    "end": "2775940"
  },
  {
    "text": "mechanism that the communities project follows - let's say improve something or",
    "start": "2775940",
    "end": "2781490"
  },
  {
    "text": "build new features or really something it's it's it's a fancy word for a design",
    "start": "2781490",
    "end": "2788960"
  },
  {
    "text": "proposal which just and it's basically to just like have a well-written",
    "start": "2788960",
    "end": "2795310"
  },
  {
    "text": "proposal which answers a bunch of questions which are needed for everything that we are launching and and",
    "start": "2795310",
    "end": "2803390"
  },
  {
    "text": "then have this reviewed by the community so every cap has a bunch of reviewers and approvers that it has to go through",
    "start": "2803390",
    "end": "2811130"
  },
  {
    "text": "them and once it's finalized the cap four is now committed to our enhancement",
    "start": "2811130",
    "end": "2818060"
  },
  {
    "text": "repository and then we start working on it in that release so it basically",
    "start": "2818060",
    "end": "2823880"
  },
  {
    "text": "formalizes the release process of features now in the later releases of",
    "start": "2823880",
    "end": "2829610"
  },
  {
    "text": "kubernetes we require a cap for something to actually be put into that release if i'm not mistaken yeah i think so yeah someone's making it",
    "start": "2829610",
    "end": "2838600"
  },
  {
    "text": "so it's even more formal process so that everybody can actually be able to follow along with how kubernetes being",
    "start": "2838600",
    "end": "2843740"
  },
  {
    "start": "2841000",
    "end": "2950000"
  },
  {
    "text": "developed sure yeah yeah decking very cool okay so I talked about networking what else is on the the roadmap for",
    "start": "2843740",
    "end": "2850310"
  },
  {
    "text": "scalability in the sig and where where is it going what are the goals what can we expect in the next year or so as we",
    "start": "2850310",
    "end": "2857600"
  },
  {
    "text": "go up one 15 and 16 and beyond that's Freddie",
    "start": "2857600",
    "end": "2864400"
  },
  {
    "text": "that'd be yeah so yeah I'd love a pretty big answer and a part of things we",
    "start": "2864400",
    "end": "2870410"
  },
  {
    "text": "haven't yet even figured out okay but like we have a few things in our immediate roadmap for for example I was",
    "start": "2870410",
    "end": "2879110"
  },
  {
    "text": "talking about this briefly last cube con so one of the things is we want to improve or rather redesign the pod",
    "start": "2879110",
    "end": "2888140"
  },
  {
    "text": "affinity and ante affinity features so these are scheduling features to basically say that",
    "start": "2888140",
    "end": "2894790"
  },
  {
    "text": "please don't mount these parts together it like on the same node or but please",
    "start": "2894790",
    "end": "2901930"
  },
  {
    "text": "do mount these parts together so these are the affinity and anti affinity features so that has shown us some",
    "start": "2901930",
    "end": "2909210"
  },
  {
    "text": "performance issues and that has been showing us a bunch of issues around performance for a while and we have a",
    "start": "2909210",
    "end": "2917440"
  },
  {
    "text": "proposal out there or like rather it's still in the ideation phase I think to actually redesign this feature there is",
    "start": "2917440",
    "end": "2926530"
  },
  {
    "text": "this work around the endpoints API which still needs to happen and there's a",
    "start": "2926530",
    "end": "2931780"
  },
  {
    "text": "bunch of things that that have to be still planned out for so we need to get",
    "start": "2931780",
    "end": "2938890"
  },
  {
    "text": "come up with this new API and then have the new have a control plane move over to this API the endpoints v2 API and",
    "start": "2938890",
    "end": "2946900"
  },
  {
    "text": "then that's one of the things and",
    "start": "2946900",
    "end": "2952200"
  }
]
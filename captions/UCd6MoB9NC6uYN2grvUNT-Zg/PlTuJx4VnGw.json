[
  {
    "text": "welcome and thanks for joining us I'm excited to be here we have lots of",
    "start": "1240",
    "end": "6399"
  },
  {
    "text": "exciting content planned for the session and some pretty cool announcements to make as well my name is Edward name and",
    "start": "6399",
    "end": "13320"
  },
  {
    "text": "I lead the product management team for EFS I'm joined on stage with Daryl Osborne who's a Solutions architect a",
    "start": "13320",
    "end": "20480"
  },
  {
    "text": "storage solutions architect at AWS we have so much content that we",
    "start": "20480",
    "end": "26279"
  },
  {
    "text": "likely will take the entire 60 Minutes to to go through it um so in terms of Q&A Feel Free at the end to come up and",
    "start": "26279",
    "end": "33640"
  },
  {
    "text": "we'll Daryl and I will stick around for 15 20 30 minutes how however long it takes to answer your questions oneon-one",
    "start": "33640",
    "end": "41920"
  },
  {
    "text": "let me start with a quick run through of what you can expect during this session",
    "start": "42640",
    "end": "48520"
  },
  {
    "text": "I'm going to start by talking about EFS give an overview of EFS and talk about",
    "start": "48520",
    "end": "53879"
  },
  {
    "text": "why and when you would use EFS I'm going to review some key Technical and security concept ceps some",
    "start": "53879",
    "end": "60960"
  },
  {
    "text": "of that material will be refresher content for some of you but I want to make sure we all have the same Baseline",
    "start": "60960",
    "end": "67240"
  },
  {
    "text": "of knowledge before we get into some of the deeper sections then going to spend time talking about EFS performance and a",
    "start": "67240",
    "end": "75759"
  },
  {
    "text": "number of aspects of our overall performance model and how you can leverage that performance model to",
    "start": "75759",
    "end": "81720"
  },
  {
    "text": "really optimize how your applications and workloads run with EFS then we're going to do two uh",
    "start": "81720",
    "end": "89240"
  },
  {
    "text": "Hands-On type of of activities uh Daryl's going to walk through uh a real",
    "start": "89240",
    "end": "94840"
  },
  {
    "text": "world example of how you can move data as quickly as possible into EFS and between EFS file systems you using",
    "start": "94840",
    "end": "102320"
  },
  {
    "text": "parallelization and then Daryl's also going to talk about uh a WordPress uh example he's going to go through what",
    "start": "102320",
    "end": "108880"
  },
  {
    "text": "it's like to to deploy WordPress onto EFS and some of the best practices for that we're then going to talk about uh",
    "start": "108880",
    "end": "116119"
  },
  {
    "text": "ef's economics so I'll talk a bit about total cost of ownership and how to think about that and then we have some",
    "start": "116119",
    "end": "123320"
  },
  {
    "text": "exciting uh feature plans and announcements to make so let's get",
    "start": "123320",
    "end": "130679"
  },
  {
    "text": "started and let me start by talking about aws's storage offerings it's",
    "start": "132640",
    "end": "137920"
  },
  {
    "text": "overall portfolio of storage products and how EFS fits into that set of offerings AWS offers three main types of",
    "start": "137920",
    "end": "146200"
  },
  {
    "text": "storage file object and block and let me walk through each of those in",
    "start": "146200",
    "end": "153160"
  },
  {
    "text": "turn so starting from the right block storage which is represented by Amazon",
    "start": "153160",
    "end": "158519"
  },
  {
    "text": "EBS and ec2 instance storage with block storage data is presented to an ec2",
    "start": "158519",
    "end": "164879"
  },
  {
    "text": "instance as a disc volume and block storage uh provides that that dis volume to single instances",
    "start": "164879",
    "end": "172440"
  },
  {
    "text": "and provides the lowest latency uh that you can get from any of our storage products for",
    "start": "172440",
    "end": "178519"
  },
  {
    "text": "operations so EBS for example is really popular for boot volumes and for database workloads uh because of its low",
    "start": "178519",
    "end": "187879"
  },
  {
    "text": "latency and we have object storage so an object is a piece of data like a",
    "start": "190360",
    "end": "196080"
  },
  {
    "text": "document or an image or a video file that's stored with some metadata in a",
    "start": "196080",
    "end": "201239"
  },
  {
    "text": "flat structure and object storage provides that data to your applications via an",
    "start": "201239",
    "end": "208040"
  },
  {
    "text": "API over the internet so with our S3 service it's super simple to build for",
    "start": "208040",
    "end": "214080"
  },
  {
    "text": "example a web application that delivers content to uh your users by making basic",
    "start": "214080",
    "end": "220480"
  },
  {
    "text": "API calls get calls to your your bucket of storage Glacier also is object storage",
    "start": "220480",
    "end": "227519"
  },
  {
    "text": "and it's intended for archival use cases so it's really intended for data that's accessed uh infrequently um and you",
    "start": "227519",
    "end": "235200"
  },
  {
    "text": "you're you're able to pay a lower uh price per gigabyte for that data for storing it on",
    "start": "235200",
    "end": "242000"
  },
  {
    "text": "AWS and as of five months ago five months ago yesterday actually with the announcement of EFS as a generally",
    "start": "242560",
    "end": "249680"
  },
  {
    "text": "available service we now have file storage and with file storage with EFS",
    "start": "249680",
    "end": "255519"
  },
  {
    "text": "data is presented via a file system interface and file system semantics to",
    "start": "255519",
    "end": "260639"
  },
  {
    "text": "ec2 instances when it's attached to an ec2 instance your EFS file system acts just",
    "start": "260639",
    "end": "267560"
  },
  {
    "text": "like a local file system would and with EFS you can attach your file system to",
    "start": "267560",
    "end": "273440"
  },
  {
    "text": "one a few tens hundreds thousands of instances so that all of these instances",
    "start": "273440",
    "end": "278960"
  },
  {
    "text": "have access to the same set of data and there's strong consistency across the axises for uh for operations across",
    "start": "278960",
    "end": "286440"
  },
  {
    "text": "those instances with EFS we we focused on",
    "start": "286440",
    "end": "292440"
  },
  {
    "text": "changing the game for file storage and for storage in general and there are three core pillars",
    "start": "292440",
    "end": "299199"
  },
  {
    "text": "to our design of EFS the first is that EFS is",
    "start": "299199",
    "end": "304960"
  },
  {
    "text": "simple the first is that EF the second is that EFS is elastic and the third is",
    "start": "304960",
    "end": "311080"
  },
  {
    "text": "that EFS is scalable and those three are on top of a foundation of high availability and high durability and let",
    "start": "311080",
    "end": "318800"
  },
  {
    "text": "me talk about each of these in turn so EFS is simple it's a fully managed service",
    "start": "318800",
    "end": "326360"
  },
  {
    "text": "which makes it easy and simple to manage to administer file systems at scale",
    "start": "326360",
    "end": "331840"
  },
  {
    "text": "there's no file layer or Hardware to manage there's no volumes luns raid groups provisioning to manage none of",
    "start": "331840",
    "end": "338560"
  },
  {
    "text": "that stuff and with EFS you can create a file system in seconds and that's probably",
    "start": "338560",
    "end": "344360"
  },
  {
    "text": "hard to believe for for some of you who have built your own uh file storage on top of AWS or outside of AWS uh but it's",
    "start": "344360",
    "end": "352479"
  },
  {
    "text": "really easy to get started and we'll talk a little bit about that a little later um EFS provides seamless",
    "start": "352479",
    "end": "358479"
  },
  {
    "text": "integration with existing tools tools and applications it's uh it supports NFS version 4.1 which is a widespread and",
    "start": "358479",
    "end": "365199"
  },
  {
    "text": "open protocol um it provides standard file system access semantics so uh you",
    "start": "365199",
    "end": "371639"
  },
  {
    "text": "get what you would expect from a file system the ability to take out locks the ability to write data to the middle of",
    "start": "371639",
    "end": "377319"
  },
  {
    "text": "the file the ability to append data to the end of a file uh directory structures Atomic renames strong read",
    "start": "377319",
    "end": "384440"
  },
  {
    "text": "after write consistency and it offers simple pricing it's a simple",
    "start": "384440",
    "end": "390560"
  },
  {
    "text": "cents per gigabyte per month model um that doesn't uh that incorporates all of",
    "start": "390560",
    "end": "397319"
  },
  {
    "text": "the the charges that you would uh you would you would incur so there's no charges for throughput there's no",
    "start": "397319",
    "end": "403319"
  },
  {
    "text": "charges for request pricing it's just a simple uh 30 cents per gigabyte per",
    "start": "403319",
    "end": "409680"
  },
  {
    "text": "month make a little trouble with the clicker here okay uh EFS is a last",
    "start": "412560",
    "end": "420560"
  },
  {
    "text": "um so file systems grow and Shrink automatically as you add and remove files there's no need to provision in",
    "start": "420560",
    "end": "427120"
  },
  {
    "text": "fact there's no way to provision storage capacity or performance things just scale up and scale down as you add data",
    "start": "427120",
    "end": "433520"
  },
  {
    "text": "and and remove data and you pay only for the storage space you use so uh you",
    "start": "433520",
    "end": "438680"
  },
  {
    "text": "literally are paying just for the bittes that you're storing on EFS and EFS is",
    "start": "438680",
    "end": "445120"
  },
  {
    "text": "scalable uh file systems can grow to pedabytes of capacity and there's no need to reprovision as your file system",
    "start": "445120",
    "end": "451960"
  },
  {
    "text": "grows no need to adjust performance settings no need to really do anything for your file system to grow a petabyte",
    "start": "451960",
    "end": "458039"
  },
  {
    "text": "scale it just does it automatically as you add data throughput scales automatically as",
    "start": "458039",
    "end": "463840"
  },
  {
    "text": "file systems grow so with every gigabyte of data that you store you get a certain",
    "start": "463840",
    "end": "469280"
  },
  {
    "text": "amount of throughput uh that you're allowed to to to drive to EFS so that means that as your file systems grow the",
    "start": "469280",
    "end": "476520"
  },
  {
    "text": "amount of throughput that you can can can drop in order to read data and write data grows with the size of the file",
    "start": "476520",
    "end": "483840"
  },
  {
    "text": "system provides consistent low latencies um lots of file workloads are latency",
    "start": "483840",
    "end": "489479"
  },
  {
    "text": "sensitive so it was really critical for us to make sure that we offered consistent low latencies and EFS supports thousands up",
    "start": "489479",
    "end": "497280"
  },
  {
    "text": "to thousands of concurrent NFS connections so if you have applications that span multiple ec2 instances they",
    "start": "497280",
    "end": "502560"
  },
  {
    "text": "can all have access to a common set of data and EFS is designed to be highly",
    "start": "502560",
    "end": "509080"
  },
  {
    "text": "available and highly durable your data is automatically spread across multiple azs",
    "start": "509080",
    "end": "515640"
  },
  {
    "text": "and it's available in multiple azs so you can read your data and write your data from any a within a region and",
    "start": "515640",
    "end": "521680"
  },
  {
    "text": "every aspect of the service Beyond even just the data is designed for high availability so including the end points",
    "start": "521680",
    "end": "528200"
  },
  {
    "text": "that you create in your VPC which I'll talk about in a",
    "start": "528200",
    "end": "532320"
  },
  {
    "text": "second uh so where can you use EFS today we're in four regions Us West Oregon Us",
    "start": "535120",
    "end": "541040"
  },
  {
    "text": "East Northern Virginia Us East Ohio and EU Ireland and there are many more",
    "start": "541040",
    "end": "546920"
  },
  {
    "text": "regions coming soon and a question I sometimes get is",
    "start": "546920",
    "end": "553440"
  },
  {
    "text": "should I use EFS or should I use EBS and you know with EBS you can format your",
    "start": "553440",
    "end": "559640"
  },
  {
    "text": "your volume with a file system so when would you use EFS versus EBS well uh",
    "start": "559640",
    "end": "565600"
  },
  {
    "text": "some some guidelines to think about when you're trying to figure out does EFS make sense is is the following so if you have an",
    "start": "565600",
    "end": "572240"
  },
  {
    "text": "ec2 application and uh it requires a file system and either requires multi- attach",
    "start": "572240",
    "end": "580680"
  },
  {
    "text": "so requires access from more than one instance uh requires multi-az availability or",
    "start": "580680",
    "end": "587360"
  },
  {
    "text": "durability needs to scale to gigabytes per second of throughput or if it requires automatic scaling so as you add",
    "start": "587360",
    "end": "595240"
  },
  {
    "text": "data grows and as you take it out it it it removes so if if you go through that",
    "start": "595240",
    "end": "601040"
  },
  {
    "text": "and you meet any of those you should really consider EFS for for your application and we'll talk a little bit",
    "start": "601040",
    "end": "606519"
  },
  {
    "text": "more later on about EFS and EBS and some of the the differences for you to think",
    "start": "606519",
    "end": "613279"
  },
  {
    "text": "about and uh you should you should understand that operating your own file",
    "start": "616440",
    "end": "621959"
  },
  {
    "text": "storage is is complex and it's expensive and there's really two ways that people typically do that so one is you can",
    "start": "621959",
    "end": "629440"
  },
  {
    "text": "simply replicate EBS volumes so for example let's say that you have a web serving environment you have multiple",
    "start": "629440",
    "end": "636160"
  },
  {
    "text": "ec2 instances and on each instance you're running an Apache web server and you want each of those web servers to",
    "start": "636160",
    "end": "641760"
  },
  {
    "text": "have access to the content that the web server needs to serve so you could go and and create an EBS volume attach it",
    "start": "641760",
    "end": "649440"
  },
  {
    "text": "attach a different volume to each instance and synchronize your files across volumes the problem with that is",
    "start": "649440",
    "end": "656040"
  },
  {
    "text": "that there's a lot of management overhead in doing that you need to manage the thinking of data you need to provision and manage volumes and it's",
    "start": "656040",
    "end": "662639"
  },
  {
    "text": "also expensive because you're paying for at least one volume for every web server that you",
    "start": "662639",
    "end": "669120"
  },
  {
    "text": "have another way to to have your own sort of uh file storage on the cloud",
    "start": "669120",
    "end": "676200"
  },
  {
    "text": "that's accessible to multiple instances is uh if you use an NFS server set up your own NFS server on an ec2 instance",
    "start": "676200",
    "end": "683360"
  },
  {
    "text": "or you use a shared file layer so some 30 some some third parties offer shared",
    "start": "683360",
    "end": "688560"
  },
  {
    "text": "file layers that you can install on an ec2 instance and that are backed by EBS volumes so those Solutions unfortunately",
    "start": "688560",
    "end": "696320"
  },
  {
    "text": "in many cases are complex to set up complex to maintain it's not a fully managed Service uh you run into scale",
    "start": "696320",
    "end": "702399"
  },
  {
    "text": "challenges think about the case of a single NFS server running on a single E2",
    "start": "702399",
    "end": "707519"
  },
  {
    "text": "instance it's running on a single box so there's only so much scale that you can have similarly there's only uh there's",
    "start": "707519",
    "end": "714600"
  },
  {
    "text": "challenges around High availability again if you have a single box or even a small set of boxes um you you you you're",
    "start": "714600",
    "end": "721279"
  },
  {
    "text": "introducing some availability risks and those Solutions are costly and we'll talk about cost in more detail later",
    "start": "721279",
    "end": "729399"
  },
  {
    "text": "on and customers are using EFS for a wide variety of of workloads and applications today web serving content",
    "start": "732000",
    "end": "739440"
  },
  {
    "text": "management are super popular use cases for EFS so a lot of customers that are doing database backups of EBS volumes",
    "start": "739440",
    "end": "746440"
  },
  {
    "text": "onto EFS uh Analytics workloads are really popular so you'll have tens or hundreds of instances that are doing",
    "start": "746440",
    "end": "753320"
  },
  {
    "text": "analysis on a common set of data media and entertainment workflows like video processing video transcoding uh",
    "start": "753320",
    "end": "760440"
  },
  {
    "text": "container storage home directories uh and really many different types of workflow management where you need to",
    "start": "760440",
    "end": "766519"
  },
  {
    "text": "share some data or some set of State across uh an application that's running",
    "start": "766519",
    "end": "771760"
  },
  {
    "text": "on multiple instances okay so let's talk briefly",
    "start": "771760",
    "end": "777560"
  },
  {
    "text": "about some key technical and security Concepts and let me",
    "start": "777560",
    "end": "783720"
  },
  {
    "text": "start this clicker is still acting up let me start with a",
    "start": "783720",
    "end": "788959"
  },
  {
    "text": "definition um the fundamental EFS resource is a file system and that's",
    "start": "788959",
    "end": "795079"
  },
  {
    "text": "where you store your files and your directories and you can create 125 file",
    "start": "795079",
    "end": "800160"
  },
  {
    "text": "systems per account and then uh let me just take",
    "start": "800160",
    "end": "808199"
  },
  {
    "text": "care of one thing",
    "start": "808199",
    "end": "811120"
  },
  {
    "text": "sorry um another definition is uh amount Target so you access your file systems",
    "start": "816000",
    "end": "822160"
  },
  {
    "text": "from a uh from within a VPC from instances that are in a VPC and in order",
    "start": "822160",
    "end": "827639"
  },
  {
    "text": "to do that you create these end points which we call Mount Targets in h ha AZ",
    "start": "827639",
    "end": "833360"
  },
  {
    "text": "within a VPC from which you want to access an EFS file system and what this endpoint or",
    "start": "833360",
    "end": "839360"
  },
  {
    "text": "what this Mount Target does is it provides an IP address and it provides a DNS name that you use when you're",
    "start": "839360",
    "end": "845639"
  },
  {
    "text": "mounting your file system and mount targets are designed to be highly",
    "start": "845639",
    "end": "852720"
  },
  {
    "text": "available and how do you access a file system from an instance well you mount it using a standard Linux Mount command",
    "start": "852839",
    "end": "861040"
  },
  {
    "text": "and uh if you can make that out um on the screen here it's",
    "start": "861040",
    "end": "866440"
  },
  {
    "text": "uh there's the command up there um the dasht is the means that you'll specify",
    "start": "866440",
    "end": "873000"
  },
  {
    "text": "the type of Mount and that's really the only parameter you you really or sorry uh one of two parameters that you need",
    "start": "873000",
    "end": "879160"
  },
  {
    "text": "to specify so it's an NFS 4 Mount and then an optional parameter that you need to specify is the NFS version number",
    "start": "879160",
    "end": "886199"
  },
  {
    "text": "which is 4.1 and we highly recommend 4.1 we do support 4.0 but for performance reasons 4.1 is what we recommend then",
    "start": "886199",
    "end": "893560"
  },
  {
    "text": "you provide the file system DNS name which is what the mount Target provides and uh you could replace that with an IP",
    "start": "893560",
    "end": "899920"
  },
  {
    "text": "address for the mount Target as well if you prefer uh and then the- O is for an",
    "start": "899920",
    "end": "905880"
  },
  {
    "text": "optional parameter um which I mentioned the NFS version number and then the user",
    "start": "905880",
    "end": "911279"
  },
  {
    "text": "Target directory uh the final uh parameter there and that's the local directory that your EFS file system will",
    "start": "911279",
    "end": "919160"
  },
  {
    "text": "uh appear in Once it's mounted okay so how does it all fit",
    "start": "919160",
    "end": "925560"
  },
  {
    "text": "together so you have a region and within a region you have a file system so file",
    "start": "925560",
    "end": "930800"
  },
  {
    "text": "system is it belongs in a region um you have uh a VPC in that region that's your",
    "start": "930800",
    "end": "938199"
  },
  {
    "text": "VPC and within each a you create these Mount Targets in your",
    "start": "938199",
    "end": "944319"
  },
  {
    "text": "VPC and the easy2 instances that are running in the azs in your",
    "start": "944319",
    "end": "949360"
  },
  {
    "text": "VPC connect via those Mount targets and you should note that data",
    "start": "949360",
    "end": "955759"
  },
  {
    "text": "can be accessed from any a in the region concurrently while maintaining full consistency so if you're doing rights in",
    "start": "955759",
    "end": "962000"
  },
  {
    "text": "one a you're guaranteed that the reads in the in another a will have the latest version of the",
    "start": "962000",
    "end": "969199"
  },
  {
    "text": "data and there are a number of security mechanisms available to your EFS file system so first at the network level you",
    "start": "969680",
    "end": "978040"
  },
  {
    "text": "can control n you can control Network traffic to and from your file systems by using VPC security groups and using VPC",
    "start": "978040",
    "end": "984839"
  },
  {
    "text": "Network akles and uh really what you're doing is you're applying with the security groups",
    "start": "984839",
    "end": "991120"
  },
  {
    "text": "you're applying them to the Mount targets and so because the mount Target is where you're sending your traffic to",
    "start": "991120",
    "end": "996279"
  },
  {
    "text": "the file system you control what traffic can reach your file system by applying the the relevant security groups to",
    "start": "996279",
    "end": "1003199"
  },
  {
    "text": "those Mount targets you can control uh at the data access layer file and directory access",
    "start": "1003199",
    "end": "1010360"
  },
  {
    "text": "by using posix permissions standard posx permissions and then at the administrative level you can control uh",
    "start": "1010360",
    "end": "1018519"
  },
  {
    "text": "AP access to file systems using I am and EFS supports both Action level and",
    "start": "1018519",
    "end": "1024760"
  },
  {
    "text": "resource level permissions and then what does our API",
    "start": "1024760",
    "end": "1031199"
  },
  {
    "text": "provide um provides basic management functionality for for your file system",
    "start": "1031199",
    "end": "1036558"
  },
  {
    "text": "so the be ability to create a file system create and delete Mount targets tag a file system view details on the",
    "start": "1036559",
    "end": "1043000"
  },
  {
    "text": "file systems in your account and those uh the API functions are accessible through our UI the Management console",
    "start": "1043000",
    "end": "1050480"
  },
  {
    "text": "through the CLI and through the SDK okay so let's talk about",
    "start": "1050480",
    "end": "1059559"
  },
  {
    "text": "performance EFS is designed for a wide spectrum of of performance needs and if",
    "start": "1060960",
    "end": "1067720"
  },
  {
    "text": "you think about uh typical way that people think about performance and across a spectrum on one side you have",
    "start": "1067720",
    "end": "1075360"
  },
  {
    "text": "applications and workloads that drive high levels of through put often from",
    "start": "1075360",
    "end": "1080480"
  },
  {
    "text": "many instances so a lot of parallel operations and and the name of the game is as much aggregate throughput as",
    "start": "1080480",
    "end": "1087120"
  },
  {
    "text": "possible across a number of instances and then on the other end of the spectrum are applications where",
    "start": "1087120",
    "end": "1094360"
  },
  {
    "text": "you're you're you're doing a lot of serialized operations and the latency of",
    "start": "1094360",
    "end": "1099400"
  },
  {
    "text": "each individual operation makes a big difference in terms of how many operations per second or how much throughput you can drive so very latency",
    "start": "1099400",
    "end": "1105880"
  },
  {
    "text": "sensitive applications and uh what you see on the",
    "start": "1105880",
    "end": "1111080"
  },
  {
    "text": "uh on the screen here in terms of of workloads are examples of what customers are using EFS for I talked about a",
    "start": "1111080",
    "end": "1117600"
  },
  {
    "text": "couple of these before but on the throughput intense uh side of the spectrum things like genomics workloads",
    "start": "1117600",
    "end": "1123960"
  },
  {
    "text": "big data analytics scaleout jobs on the other side uh metadata intensive jobs",
    "start": "1123960",
    "end": "1130280"
  },
  {
    "text": "and then uh sort of in the middle are a lot of the sort of General types of of use cases that you would use file for so",
    "start": "1130280",
    "end": "1137280"
  },
  {
    "text": "web serving content management directory",
    "start": "1137280",
    "end": "1141400"
  },
  {
    "text": "Etc and in order to support that spectrum of of of workloads and",
    "start": "1145080",
    "end": "1150240"
  },
  {
    "text": "applications EFS offers two different performance modes that you can choose from so the first is called general",
    "start": "1150240",
    "end": "1157000"
  },
  {
    "text": "purpose mode and that's the default mode for a file system and uh what it does is it offers",
    "start": "1157000",
    "end": "1164120"
  },
  {
    "text": "the lowest latency for your file operations now now the the the tradeoff",
    "start": "1164120",
    "end": "1170039"
  },
  {
    "text": "for general purpose mode is that there's a limit in terms of the number of operations per second you can drive when",
    "start": "1170039",
    "end": "1175320"
  },
  {
    "text": "you're in general purpose mode and that limit is 7,000 operations per second the other mode is Max IO mode and",
    "start": "1175320",
    "end": "1183400"
  },
  {
    "text": "uh it offers a virtually unlimited ability to scale your throughput in iops so you don't have this 7,000 operations",
    "start": "1183400",
    "end": "1189919"
  },
  {
    "text": "per second limit but the trade-off is it does so with slightly higher latencies",
    "start": "1189919",
    "end": "1195360"
  },
  {
    "text": "per operation so in terms of which workloads make sense for which performance mode um",
    "start": "1195360",
    "end": "1201200"
  },
  {
    "text": "in general general purpose mode is is the best choice for most workloads that's why we call it general purpose",
    "start": "1201200",
    "end": "1206679"
  },
  {
    "text": "and that's why it's the default um but if you need High aggregate levels of iops or high aggregate levels of",
    "start": "1206679",
    "end": "1213200"
  },
  {
    "text": "throughput and typically that's if you have a workload for example where you'll have tens or more instances accessing a",
    "start": "1213200",
    "end": "1219720"
  },
  {
    "text": "file system and driving lots of traffic to it then you should consider Max IO",
    "start": "1219720",
    "end": "1225720"
  },
  {
    "text": "mode um and what we generally recommend is when you're testing EFS with your",
    "start": "1226840",
    "end": "1232480"
  },
  {
    "text": "application and trying to figure out should you use general purpose or Max iio mode you should start off by",
    "start": "1232480",
    "end": "1238760"
  },
  {
    "text": "creating a file system that's in general purpose mode and testing it and we provide a cloudwatch metric that shows",
    "start": "1238760",
    "end": "1244640"
  },
  {
    "text": "how close you're getting to uh the 7,000 operations per second limit that's",
    "start": "1244640",
    "end": "1249960"
  },
  {
    "text": "that's tied to general purpose mode so we recommend just testing it and looking at the cloudwatch metric to see and if",
    "start": "1249960",
    "end": "1256679"
  },
  {
    "text": "you're okay in terms of cloudwatch metric you should definitely stay in uh general purpose",
    "start": "1256679",
    "end": "1262840"
  },
  {
    "text": "mode um and order to to understand ef's performance model it's it's helpful for",
    "start": "1265200",
    "end": "1270960"
  },
  {
    "text": "me to provide a bit of context on ef's architecture so EFS has a distributed",
    "start": "1270960",
    "end": "1277200"
  },
  {
    "text": "data storage design and what that means is that file systems are distributed across an unconstrained number of",
    "start": "1277200",
    "end": "1285360"
  },
  {
    "text": "servers and what that uh why that's good is because it avoids the bottlenecks and",
    "start": "1285360",
    "end": "1291080"
  },
  {
    "text": "the constraints of traditional file servers and it allows high levels of",
    "start": "1291080",
    "end": "1296120"
  },
  {
    "text": "aggregate operations per second and Aggregate throughput and also allows that scaling to petabyte scale that I",
    "start": "1296120",
    "end": "1302120"
  },
  {
    "text": "talked about um with EFS as I've mentioned uh",
    "start": "1302120",
    "end": "1307880"
  },
  {
    "text": "earlier data is also distributed across availability zones and that's important for durability and availability so when",
    "start": "1307880",
    "end": "1314679"
  },
  {
    "text": "you when you do a read operation on EFS and you get the acknowledge back that the right operation has completed uh you",
    "start": "1314679",
    "end": "1321919"
  },
  {
    "text": "can be rest assured that actually the data has been written across multiple A's so that happens before you get the acknowledgement",
    "start": "1321919",
    "end": "1329360"
  },
  {
    "text": "back um now this distributed architecture has some performance implications um so one is that uh",
    "start": "1332120",
    "end": "1341039"
  },
  {
    "text": "there's a small latency overhead for each file operation and that's tied to the fact that the data is spread out and",
    "start": "1341039",
    "end": "1347919"
  },
  {
    "text": "it's spread across across multiple availability zones and it's strongly consistent so when you get an",
    "start": "1347919",
    "end": "1353200"
  },
  {
    "text": "acknowledgement back you know the data has traveled to the other availability zones um but it also enables scale out",
    "start": "1353200",
    "end": "1360400"
  },
  {
    "text": "so it allows you to get to these high aggregate levels of of performance and so when you think about EFS versus EBS",
    "start": "1360400",
    "end": "1368159"
  },
  {
    "text": "it's helpful to think about a few different things so the first is the per operation latency so EFS does offer low",
    "start": "1368159",
    "end": "1375080"
  },
  {
    "text": "consistent latencies but because of the distributed design I just talked about if you're looking for the absolute",
    "start": "1375080",
    "end": "1380880"
  },
  {
    "text": "lowest possible latencies EBS has lower latencies because it doesn't have that distributed",
    "start": "1380880",
    "end": "1387240"
  },
  {
    "text": "design uh in terms of throughput scale uh EFS scales to multiple gigabytes per",
    "start": "1387240",
    "end": "1392279"
  },
  {
    "text": "second and Daryl will talk about uh he'll give an example actually of a couple gigabytes per second that he",
    "start": "1392279",
    "end": "1398240"
  },
  {
    "text": "drove uh when copying data on EFS uh with EBS it's around a single gigabyte",
    "start": "1398240",
    "end": "1404120"
  },
  {
    "text": "per second in terms of availability durability EFS data spread across multiple azs EBS it's in a single",
    "start": "1404120",
    "end": "1411840"
  },
  {
    "text": "a um access uh EBS single le2 instance can access a volume with EFS you can",
    "start": "1411840",
    "end": "1419000"
  },
  {
    "text": "have one to thousands of ec2 instances accessing it concurrently and so some of the use cases that uh are really in The",
    "start": "1419000",
    "end": "1425679"
  },
  {
    "text": "Sweet Spot for EFS are big data and analytics um some of the media",
    "start": "1425679",
    "end": "1430799"
  },
  {
    "text": "processing that I was talking about content management home directories uh with EBS really lat latency sensitive",
    "start": "1430799",
    "end": "1437960"
  },
  {
    "text": "application like databases make a lot of sense for EBS uh and EBS also uh makes a",
    "start": "1437960",
    "end": "1443640"
  },
  {
    "text": "lot of sense for boot",
    "start": "1443640",
    "end": "1446440"
  },
  {
    "text": "volumes um so uh tied to this per operation latency that I've been talking",
    "start": "1451400",
    "end": "1458400"
  },
  {
    "text": "about uh the overall throughput that you can achieve when you are doing a",
    "start": "1458400",
    "end": "1463880"
  },
  {
    "text": "sequence of operations in serial across EFS um is is tied to the uh the size of the",
    "start": "1463880",
    "end": "1471440"
  },
  {
    "text": "operation that you're driving um so if you're doing a read or a write that's a that's a reader or",
    "start": "1471440",
    "end": "1478279"
  },
  {
    "text": "write of a bigger piece of data that latency is amortized over a larger amount of data and so in effect if",
    "start": "1478279",
    "end": "1484799"
  },
  {
    "text": "you're doing these operations in serial you're able to drive higher amounts of throughput with larger operation sizes",
    "start": "1484799",
    "end": "1492600"
  },
  {
    "text": "and this graph shows IO size versus throughput to give you a sense for and again this is serial ized operation to",
    "start": "1492600",
    "end": "1499880"
  },
  {
    "text": "give you a sense for um what that what that looks",
    "start": "1499880",
    "end": "1505559"
  },
  {
    "text": "like and EFS is designed to process High volumes of concurrent operations uh in",
    "start": "1508120",
    "end": "1514360"
  },
  {
    "text": "an effective way um so one way to to drive high levels of throughput or high",
    "start": "1514360",
    "end": "1519840"
  },
  {
    "text": "levels of of iops is to do it via parallel operations that you're throwing",
    "start": "1519840",
    "end": "1525120"
  },
  {
    "text": "at EFS concurrently and you can do that via multiple threads on a single ec2",
    "start": "1525120",
    "end": "1530360"
  },
  {
    "text": "instance or if you want even more parallelization you can do it on multiple threads across multiple ec2",
    "start": "1530360",
    "end": "1536240"
  },
  {
    "text": "instances and this graph illustrates that so in this graph we held the io",
    "start": "1536240",
    "end": "1541559"
  },
  {
    "text": "size constant it's actually uh we're showing the creation of 4K",
    "start": "1541559",
    "end": "1547240"
  },
  {
    "text": "files um and this is across 10 instances and it shows on the the xaxis the number",
    "start": "1547240",
    "end": "1553080"
  },
  {
    "text": "of threads and on the Y AIS the aggregate iops that that you're able to drive and in this example uh you can see",
    "start": "1553080",
    "end": "1560520"
  },
  {
    "text": "almost a linear increase in the aggregate iops as you increase the number of",
    "start": "1560520",
    "end": "1567679"
  },
  {
    "text": "threads and uh Daryl's going to give a little bit of a walkth through uh of an example of doing some of this",
    "start": "1567760",
    "end": "1573919"
  },
  {
    "text": "parallelization so you can see how you could actually do that in the real world and we provide cloudwatch metrics",
    "start": "1573919",
    "end": "1581039"
  },
  {
    "text": "for a variety of views of your file system performance um if you want to understand the operations per second",
    "start": "1581039",
    "end": "1586960"
  },
  {
    "text": "that you're driving if you want to understand the volume of throughput that you're driving over a period of time we have cloudwatch metrics that that",
    "start": "1586960",
    "end": "1593799"
  },
  {
    "text": "provide that data um two metrics that I'll call out specifically burst credit balance and permitted throughput as I",
    "start": "1593799",
    "end": "1601080"
  },
  {
    "text": "mentioned the amount of throughput that you're entitled to on an EFS file system is tied to the amount of data that",
    "start": "1601080",
    "end": "1606399"
  },
  {
    "text": "you're storing um and essentially the rate at which so we have this burst",
    "start": "1606399",
    "end": "1611960"
  },
  {
    "text": "credit model um and if you have burst credits available you're able to to",
    "start": "1611960",
    "end": "1617279"
  },
  {
    "text": "drive throughput to your your file system and the rate at which you earn these burst credits uh is tied to the",
    "start": "1617279",
    "end": "1622840"
  },
  {
    "text": "amount of storage that you have in the file system and it all equates to around 100 megabytes per second of throughput",
    "start": "1622840",
    "end": "1629760"
  },
  {
    "text": "that you can drive for every terabyte of data stored so if you have one terabyte it's 100 megabytes per second if you",
    "start": "1629760",
    "end": "1635880"
  },
  {
    "text": "have 5 terabytes it's 500 megabytes per second and there's details in our documentation on this um but just wanted",
    "start": "1635880",
    "end": "1642200"
  },
  {
    "text": "to give you a a feel for what that bursting model is like and these two uh",
    "start": "1642200",
    "end": "1648159"
  },
  {
    "text": "Cloud watch metrics the burst credit balance permitted throughput give you visibility into how you're doing from a burst credit perspective and if you're",
    "start": "1648159",
    "end": "1654960"
  },
  {
    "text": "if you're okay or if you need to add more data in order to get the level of throughput that you",
    "start": "1654960",
    "end": "1660278"
  },
  {
    "text": "want and then uh in terms of uh kernel version and NFS Mount options these",
    "start": "1661360",
    "end": "1667480"
  },
  {
    "text": "things actually really matter uh so definitely use a Linux kernel version 4.0 or newer there's so many performance",
    "start": "1667480",
    "end": "1675320"
  },
  {
    "text": "enhancements that have uh been added to kernel over time so we we highly recommend 4.0 or later and mount via uh",
    "start": "1675320",
    "end": "1684720"
  },
  {
    "text": "NFS 4.1 um there are a bunch of performance enhancements tied to 4.1",
    "start": "1684720",
    "end": "1690159"
  },
  {
    "text": "versus 4.0 including improved performance for multi-threaded applications so that's something we",
    "start": "1690159",
    "end": "1695679"
  },
  {
    "text": "highly recommend uh the other parameters that I'm showing the other optional parameters you don't need to worry too",
    "start": "1695679",
    "end": "1701679"
  },
  {
    "text": "much about because those are the defaults for most clients um doesn't hurt to specify them anyway in case it's",
    "start": "1701679",
    "end": "1707080"
  },
  {
    "text": "not the default for whatever client you're using um but all of this stuff is in our documentation as well um but for",
    "start": "1707080",
    "end": "1713279"
  },
  {
    "text": "the most part default options will be what you need so a summary on the performance",
    "start": "1713279",
    "end": "1720240"
  },
  {
    "text": "front um first of all test test test I can talk about latencies all day I can",
    "start": "1720240",
    "end": "1726080"
  },
  {
    "text": "talk about throughput all day you're not going to really know what that means for your application until you test your application that's because every",
    "start": "1726080",
    "end": "1732399"
  },
  {
    "text": "application has a different a different set of access patterns so testing is really the best way to understand and",
    "start": "1732399",
    "end": "1738360"
  },
  {
    "text": "what does your application look like when working with EFS uh use general purpose mode for",
    "start": "1738360",
    "end": "1743559"
  },
  {
    "text": "lowest latency Max IO mode for scale out and for most use cases general purpose mode is the right mode use kernel",
    "start": "1743559",
    "end": "1751200"
  },
  {
    "text": "version 4.0 later NFS 4.1 um look for opportunities to um to",
    "start": "1751200",
    "end": "1758360"
  },
  {
    "text": "to uh aggregate your IO so use larger IO sizes when you're reading and writing data um perform asynchronous operations",
    "start": "1758360",
    "end": "1766440"
  },
  {
    "text": "so one parameter i' I sort of glossed over on the previous slide was uh the",
    "start": "1766440",
    "end": "1771559"
  },
  {
    "text": "async mount option which is a default Mount option and what that does is it allows the NFS client to acknowledge a",
    "start": "1771559",
    "end": "1778200"
  },
  {
    "text": "right even before it's gone to the back end so that gives you some enhanced performance um for for rights um and",
    "start": "1778200",
    "end": "1785279"
  },
  {
    "text": "also similarly for reads um but you know there's uh there's some you need to make",
    "start": "1785279",
    "end": "1791120"
  },
  {
    "text": "sure that you're okay from a consistency perspective in order to do that because you'll be getting acknowledgements to your application that a right is",
    "start": "1791120",
    "end": "1796840"
  },
  {
    "text": "completed even though it hasn't propagated necessarily to the back end um parallelization we'll talk about that",
    "start": "1796840",
    "end": "1802679"
  },
  {
    "text": "in a little bit and then uh we'll also talk about using caching in front of your file",
    "start": "1802679",
    "end": "1809320"
  },
  {
    "text": "system and with that I'll turn it over to darl",
    "start": "1809679",
    "end": "1814799"
  },
  {
    "text": "right see excent thanks Zed appreciate it so uh welcome everyone glad to be",
    "start": "1814799",
    "end": "1822519"
  },
  {
    "text": "here uh I'm from Texas and in Texas we love things who else is from Texas any",
    "start": "1822519",
    "end": "1829559"
  },
  {
    "text": "Texans here all right in Texas what do we like in things in Texas are bigger",
    "start": "1829559",
    "end": "1837159"
  },
  {
    "text": "and in Texas we like things faster as well so what do we want to do we want to move a lot of data Big Data very fast so",
    "start": "1837159",
    "end": "1846000"
  },
  {
    "text": "that's what I wanted to do so this is what we did we had two",
    "start": "1846000",
    "end": "1852399"
  },
  {
    "text": "scenarios the first scenario was we wanted to transfer a lot of media assets",
    "start": "1852399",
    "end": "1858440"
  },
  {
    "text": "so what we did we came up with a random size files so they ranged from one gig",
    "start": "1858440",
    "end": "1863760"
  },
  {
    "text": "to 100 Gig plus we wanted to move them from S3 and",
    "start": "1863760",
    "end": "1873320"
  },
  {
    "text": "EBS our next scenario is we had a lot of smaller",
    "start": "1873440",
    "end": "1880120"
  },
  {
    "text": "files so we randomly generated files between 64k and",
    "start": "1880120",
    "end": "1886320"
  },
  {
    "text": "256 and again we wanted to transfer those from",
    "start": "1886320",
    "end": "1891679"
  },
  {
    "text": "S3 and EBS over to",
    "start": "1891679",
    "end": "1896760"
  },
  {
    "text": "EFS so how should we do this do we want to",
    "start": "1899200",
    "end": "1906000"
  },
  {
    "text": "paralyze the copy or do we want to do it in a Serial manner so if we take a look",
    "start": "1906000",
    "end": "1911039"
  },
  {
    "text": "at serial what does that look like one file after another so you can only do so",
    "start": "1911039",
    "end": "1917000"
  },
  {
    "text": "much activity at once or should we do it",
    "start": "1917000",
    "end": "1923480"
  },
  {
    "text": "in parallel have a lot of different",
    "start": "1923480",
    "end": "1929120"
  },
  {
    "text": "threads have a lot of different instances doing this copy at the same",
    "start": "1929120",
    "end": "1936480"
  },
  {
    "text": "time so what did we use we used new parallel some of you may",
    "start": "1936480",
    "end": "1942960"
  },
  {
    "text": "be familiar with this you could be familiar with uh uh xarts as well so",
    "start": "1942960",
    "end": "1948240"
  },
  {
    "text": "very similar to that so it really replaces having to Loop",
    "start": "1948240",
    "end": "1953519"
  },
  {
    "text": "through and do a uh basically a copy command so what we did is um and it it",
    "start": "1953519",
    "end": "1961120"
  },
  {
    "text": "talks about it with with new parallel it makes it very uh it's consistent because",
    "start": "1961120",
    "end": "1966840"
  },
  {
    "text": "the output is going to be the same as if you did it in a serialized",
    "start": "1966840",
    "end": "1972760"
  },
  {
    "text": "manner all right so this is what we did we created the destination",
    "start": "1972760",
    "end": "1978679"
  },
  {
    "text": "directories using parallel and we did the copy as",
    "start": "1978679",
    "end": "1986000"
  },
  {
    "text": "well so what does that look like so if you're familiar with AWS we love",
    "start": "1987880",
    "end": "1996360"
  },
  {
    "text": "data we Thrive for data so data tells us so much information about how things are",
    "start": "1996360",
    "end": "2002360"
  },
  {
    "text": "going so we wanted to have datadriven results we also wanted to hand this off",
    "start": "2002360",
    "end": "2009200"
  },
  {
    "text": "to someone else we wanted a repeatable output",
    "start": "2009200",
    "end": "2015120"
  },
  {
    "text": "results and of course we want to make sure that we're optimizing for cost we",
    "start": "2016799",
    "end": "2021880"
  },
  {
    "text": "want to do this as uh inexpensively as we possibly",
    "start": "2021880",
    "end": "2027799"
  },
  {
    "text": "could so we want to determine the best instance type to help us with reducing",
    "start": "2027840",
    "end": "2033159"
  },
  {
    "text": "the cost but we wanted to make sure that we had we could move a lot of data very",
    "start": "2033159",
    "end": "2038320"
  },
  {
    "text": "very fast so we looked at these families these instance families and we wanted to",
    "start": "2038320",
    "end": "2043919"
  },
  {
    "text": "see which is going to be the best we wanted to do a a quick test transfer of",
    "start": "2043919",
    "end": "2049240"
  },
  {
    "text": "a thousand files and we wanted to take a look at the different threads if we went from one thread to a thousand 24 threads",
    "start": "2049240",
    "end": "2054560"
  },
  {
    "text": "what would that look like how would that impact this this this copy this",
    "start": "2054560",
    "end": "2060440"
  },
  {
    "text": "transfer so we used a couple of tools to do this we used data dog uh to monitor",
    "start": "2060440",
    "end": "2066079"
  },
  {
    "text": "their performance on on the instance we use Sumo logic to do the data",
    "start": "2066079",
    "end": "2072158"
  },
  {
    "text": "visualization we also use salt stack to do the automation the",
    "start": "2072159",
    "end": "2078480"
  },
  {
    "text": "orchestration so what happened so with four instances we were",
    "start": "2078480",
    "end": "2084560"
  },
  {
    "text": "able to run 451 megabytes a second and it looked something like this",
    "start": "2084560",
    "end": "2091240"
  },
  {
    "text": "we had very consistent throughput for all four",
    "start": "2091240",
    "end": "2096320"
  },
  {
    "text": "instances that's great but what does that mean how can we",
    "start": "2096320",
    "end": "2101880"
  },
  {
    "text": "improve that so again if we go parallel we want to add more instances if we went",
    "start": "2101880",
    "end": "2107160"
  },
  {
    "text": "up to 50 instances we were able to get 4.2 gigabytes a second gigabytes a",
    "start": "2107160",
    "end": "2115079"
  },
  {
    "text": "second now that's not the limit for EFS that was a limit for our environment",
    "start": "2115079",
    "end": "2120720"
  },
  {
    "text": "based on the size of data we had stored in our EFS file system so if you have",
    "start": "2120720",
    "end": "2128000"
  },
  {
    "text": "more data you can definitely see that throughput increase now let's go to our other use",
    "start": "2128000",
    "end": "2136000"
  },
  {
    "text": "case our other example our scenario so we had a lot of small files ranging from",
    "start": "2136000",
    "end": "2142599"
  },
  {
    "text": "64k to 256k and we wanted to see which instance",
    "start": "2142599",
    "end": "2148240"
  },
  {
    "text": "type was going to be best and how many threads we should be using so all the",
    "start": "2148240",
    "end": "2153960"
  },
  {
    "text": "different colors you see here those are all the different instance types",
    "start": "2153960",
    "end": "2159040"
  },
  {
    "text": "we ran this test against and if you notice right there at about 200 threads it's sort of plateaued off so now we",
    "start": "2159040",
    "end": "2166680"
  },
  {
    "text": "know you know what 200 threads is where we want to be for our use case for our",
    "start": "2166680",
    "end": "2172240"
  },
  {
    "text": "example our workload uh so we wanted to find the best instance type at the least",
    "start": "2172240",
    "end": "2181359"
  },
  {
    "text": "cost so that c that brought us to the C3",
    "start": "2181359",
    "end": "2186520"
  },
  {
    "text": "large inst time and we are able to push through 5,000 a little over 5,000 files",
    "start": "2186520",
    "end": "2192480"
  },
  {
    "text": "per minute when we did this at 200 threads all right so now we have the",
    "start": "2192480",
    "end": "2199480"
  },
  {
    "text": "optimal instance size we have the optimal number of",
    "start": "2199480",
    "end": "2206079"
  },
  {
    "text": "threads so now what we want to do is we want to we want to go parallel we want",
    "start": "2206079",
    "end": "2211760"
  },
  {
    "text": "to increase the number of instances so we decided let's go ahead and try out 300",
    "start": "2211760",
    "end": "2219200"
  },
  {
    "text": "oh and also we want to optimize for cost so what did we use spot market so what",
    "start": "2219200",
    "end": "2224440"
  },
  {
    "text": "does that look like cost-wise this cost to do this test less than it's around",
    "start": "2224440",
    "end": "2231000"
  },
  {
    "text": "less than five dollar to run this test these instances were running at 4.5 cents per hour so we were able to do",
    "start": "2231000",
    "end": "2239440"
  },
  {
    "text": "this test very efficiently with 300 instances this C3",
    "start": "2239440",
    "end": "2246040"
  },
  {
    "text": "large instance we were able to copy 1.6 million files a",
    "start": "2246040",
    "end": "2253280"
  },
  {
    "text": "minute so that's a lot that is",
    "start": "2253280",
    "end": "2259319"
  },
  {
    "text": "parallelism with the optimal instance type with the number of threats and the",
    "start": "2259319",
    "end": "2264880"
  },
  {
    "text": "number of U the correct number of ec2 instances for our workload and you can",
    "start": "2264880",
    "end": "2270200"
  },
  {
    "text": "see it very consistent for all of those all of those ec2 instances",
    "start": "2270200",
    "end": "2277880"
  },
  {
    "text": "so in summary what did we learn from this very large files we can get a lot of",
    "start": "2278119",
    "end": "2284520"
  },
  {
    "text": "throughput here we were limited to 4.2 just because of the size of our file system but definitely that that can",
    "start": "2284599",
    "end": "2290280"
  },
  {
    "text": "increase if you have a larger file system and with small files again you want to go parallel increase the number",
    "start": "2290280",
    "end": "2296400"
  },
  {
    "text": "of threads you want to increase the number of instances and you can also start pushing",
    "start": "2296400",
    "end": "2303800"
  },
  {
    "text": "depending on your workload your use case you can uh you can see",
    "start": "2303800",
    "end": "2309000"
  },
  {
    "text": "uh performance similar to this so in summary we want to paralyze",
    "start": "2309000",
    "end": "2314720"
  },
  {
    "text": "everything paralyze threads paralyze",
    "start": "2314720",
    "end": "2319640"
  },
  {
    "text": "instances as Ed mentioned you want to test test test test your application out",
    "start": "2319760",
    "end": "2324880"
  },
  {
    "text": "test it again and test it again make sure it's working the way that you want it to want to capture an analyze this",
    "start": "2324880",
    "end": "2332000"
  },
  {
    "text": "data as well you want to see how are you performing when you're running your workload against EFS",
    "start": "2332000",
    "end": "2337960"
  },
  {
    "text": "and again to do this test um it costs us less",
    "start": "2337960",
    "end": "2343640"
  },
  {
    "text": "than5 all right so that sort of showed you a little of how we recommend to run",
    "start": "2345040",
    "end": "2353680"
  },
  {
    "text": "a a sort of a parallel workload with threads and instance counts now I want to talk a little bit",
    "start": "2353680",
    "end": "2360880"
  },
  {
    "text": "about a good use case so Ed mentioned a number of different use cases that EFS",
    "start": "2360880",
    "end": "2366640"
  },
  {
    "text": "is is really great at uh at serving and one of those this sort of combination is",
    "start": "2366640",
    "end": "2373040"
  },
  {
    "text": "content management as well as web serving uh so you're all familiar with what this is you know it's basically",
    "start": "2373040",
    "end": "2379680"
  },
  {
    "text": "web-based application serving out content this could be wikis this could be uh blogs you know just web",
    "start": "2379680",
    "end": "2387880"
  },
  {
    "text": "applications so one that is very popular and you may be familiar with is is",
    "start": "2387880",
    "end": "2394359"
  },
  {
    "text": "WordPress so WordPress as you may be familiar with with it is a free and open source tool that many people who's",
    "start": "2394359",
    "end": "2401680"
  },
  {
    "text": "running WordPress today got a couple WordPress users out there okay great um",
    "start": "2401680",
    "end": "2408200"
  },
  {
    "text": "it's great software it really makes your web page look great very easy to",
    "start": "2408200",
    "end": "2414640"
  },
  {
    "text": "run uh free and Priceless is the the quote from from WordPress so it's it's a great great product as I looked into",
    "start": "2414640",
    "end": "2421119"
  },
  {
    "text": "this a little bit more I was surprised at the number of sites that actually run WordPress so there's a study just done",
    "start": "2421119",
    "end": "2427599"
  },
  {
    "text": "recently that said that 27% of all the websites are running WordPress that's amazing 27% of anything in this market",
    "start": "2427599",
    "end": "2435560"
  },
  {
    "text": "is huge so that's great there's also a quote or a study",
    "start": "2435560",
    "end": "2442119"
  },
  {
    "text": "done that it says it's very easy so it's very um very easy to run very easy to",
    "start": "2442119",
    "end": "2449560"
  },
  {
    "text": "maintain and again another study from Forbes this was a little little while ago so it's probably a little out of",
    "start": "2449560",
    "end": "2455160"
  },
  {
    "text": "date but it also said that you know there's six 60 million websites um are running WordPress so we wanted to test",
    "start": "2455160",
    "end": "2461599"
  },
  {
    "text": "this out you know how would this great web uh serving content management system",
    "start": "2461599",
    "end": "2469000"
  },
  {
    "text": "perform on EFS so WordPress is available in really",
    "start": "2469000",
    "end": "2475440"
  },
  {
    "text": "two different flavors in a sense so if you want to run a WordPress site you can go to a manage provider so wordpress.com is one",
    "start": "2475440",
    "end": "2483319"
  },
  {
    "text": "press.net is another there's just two that that I'm familiar with uh but there's going to be there's hundreds out",
    "start": "2483319",
    "end": "2489200"
  },
  {
    "text": "there that will manage and basically provide the WordPress environment for you if you wanted to run your your your",
    "start": "2489200",
    "end": "2495040"
  },
  {
    "text": "application there uh the other way is to download the software from wordpress.org and run",
    "start": "2495040",
    "end": "2502160"
  },
  {
    "text": "it yourself so that's what we're going to do today so we want to do a comparison",
    "start": "2502160",
    "end": "2508800"
  },
  {
    "text": "between resources and um components of Wordpress so how they sort of map so if",
    "start": "2508800",
    "end": "2516160"
  },
  {
    "text": "we take a look at this unstructured data we want all that unstructured data um in components and we also want the",
    "start": "2516160",
    "end": "2522240"
  },
  {
    "text": "structured data under the components of Wordpress where is that going to go to where's that going to be stored in",
    "start": "2522240",
    "end": "2530359"
  },
  {
    "text": "AWS so the unstructured data is going to be an EFS that's where we're going to store",
    "start": "2530359",
    "end": "2536359"
  },
  {
    "text": "those PHP files the themes the plugins those are some of the challenges that a lot of um users administrators have is",
    "start": "2536359",
    "end": "2543240"
  },
  {
    "text": "when they start installing these plugins and themes it's going to be installed on maybe that local instance and then you",
    "start": "2543240",
    "end": "2548880"
  },
  {
    "text": "got to do that multiple times as you sort of expand your your WordPress Fleet",
    "start": "2548880",
    "end": "2553960"
  },
  {
    "text": "uh so we want to store that in a file system that is shared among a number of ec2 instances and that structured data",
    "start": "2553960",
    "end": "2561319"
  },
  {
    "text": "we're going to put in RDS of",
    "start": "2561319",
    "end": "2565400"
  },
  {
    "text": "course so what does this look like so very quickly this is the architecture",
    "start": "2566559",
    "end": "2572319"
  },
  {
    "text": "that U we're going to be coming out with a reference architecture um with this and an updated WordPress white paper",
    "start": "2572319",
    "end": "2578640"
  },
  {
    "text": "that has all this information in it so within your VPC you're going to have a couple of azs you're going to have those",
    "start": "2578640",
    "end": "2584240"
  },
  {
    "text": "Mount targets that Ed mentioned and they're going to be uh connected back to your EFS file system you're going to have RDS spun up",
    "start": "2584240",
    "end": "2591960"
  },
  {
    "text": "you're going to have an an ec2 instance that ec2 instance is going to be able to connect to um the mount Target as well",
    "start": "2591960",
    "end": "2598640"
  },
  {
    "text": "as your RDS environment but we want to do more than just one instance so we want to have an autoscaling group and we",
    "start": "2598640",
    "end": "2603839"
  },
  {
    "text": "want to have multiple instances in there in front of that what do we want we want",
    "start": "2603839",
    "end": "2609760"
  },
  {
    "text": "elb we want this to be connected to the internet we could put cloudfront in front of that uh we can put um RDS uh or",
    "start": "2609760",
    "end": "2618480"
  },
  {
    "text": "um Route 53 um and then our users will be able to con to connect um we can",
    "start": "2618480",
    "end": "2624400"
  },
  {
    "text": "expand this a little further and actually cache some of the the database data that structured data we could put",
    "start": "2624400",
    "end": "2630280"
  },
  {
    "text": "elastic cache in front of RDS then also help out what we can do is put uh install op cash on the web",
    "start": "2630280",
    "end": "2640640"
  },
  {
    "text": "servers on our WordPress servers to cach some of those PHP files from",
    "start": "2640640",
    "end": "2647559"
  },
  {
    "text": "EFS so what does this look like let's go ahead and very",
    "start": "2647559",
    "end": "2654800"
  },
  {
    "text": "quickly take a look at this",
    "start": "2655400",
    "end": "2659359"
  },
  {
    "text": "so there we go this is an example of",
    "start": "2660880",
    "end": "2667640"
  },
  {
    "text": "a cloud information template that's going to be included in the reference architecture um this these are just some",
    "start": "2667640",
    "end": "2673400"
  },
  {
    "text": "of the configuration settings the parameters that we have so we want to identify the the file system name the",
    "start": "2673400",
    "end": "2679079"
  },
  {
    "text": "performance mode general purpose or maxio all the NFS Mount name uh then go",
    "start": "2679079",
    "end": "2684839"
  },
  {
    "text": "into the VPC configuration the WordPress configuration um elb configuration",
    "start": "2684839",
    "end": "2690480"
  },
  {
    "text": "Aurora we're going to put this in an aurora cluster elasticache configuration as",
    "start": "2690480",
    "end": "2695800"
  },
  {
    "text": "well so all of these parameters are are going to be in this cloud formation template okay so we're not going to run",
    "start": "2695800",
    "end": "2702040"
  },
  {
    "text": "that right now just because it's going to take some time to uh to create the the RDS Aurora cluster uh so we're just",
    "start": "2702040",
    "end": "2709040"
  },
  {
    "text": "going to go ahead and jump over to an environment that's already already up and",
    "start": "2709040",
    "end": "2714839"
  },
  {
    "text": "running now I have this over in the uh uh Oregon",
    "start": "2714839",
    "end": "2720880"
  },
  {
    "text": "region so what does this look like so if we take a look at um",
    "start": "2721599",
    "end": "2727559"
  },
  {
    "text": "yeah our load balancer so right now we have one",
    "start": "2727559",
    "end": "2732800"
  },
  {
    "text": "WordPress instance and when we launched that um cloud formation template what it did it actually mounted that file system",
    "start": "2732800",
    "end": "2739680"
  },
  {
    "text": "as well installed all the application um all the applications that we need it so if we take a look at um the dashboard",
    "start": "2739680",
    "end": "2747920"
  },
  {
    "text": "for WordPress uh we want to go ahead and install a new",
    "start": "2747920",
    "end": "2753078"
  },
  {
    "text": "theme so let's go ahead and do that",
    "start": "2754480",
    "end": "2758920"
  },
  {
    "text": "I like this theme so we'll go ahead and use that so this is going to be downloading",
    "start": "2762960",
    "end": "2770160"
  },
  {
    "text": "it's going to be uh downloaded and installed on our file systems that's mounted to this this one single instance",
    "start": "2770160",
    "end": "2777640"
  },
  {
    "text": "that's a um serving up all of our our WordPress",
    "start": "2777640",
    "end": "2782960"
  },
  {
    "text": "content now that that's installed we're going to go ahead and activate it",
    "start": "2783599",
    "end": "2788920"
  },
  {
    "text": "now what we can do is is take a look at what that looks like so very simple very basic um",
    "start": "2791280",
    "end": "2797880"
  },
  {
    "text": "WordPress site sort of out of the box well we also want to install some",
    "start": "2797880",
    "end": "2803280"
  },
  {
    "text": "plugins as well so we want to add a new plugin and we want to add the op um",
    "start": "2803280",
    "end": "2808960"
  },
  {
    "text": "cache dashboard",
    "start": "2808960",
    "end": "2812520"
  },
  {
    "text": "so again very easy to do the installation again this is going to be installed and it's going",
    "start": "2821160",
    "end": "2826200"
  },
  {
    "text": "to be stored in our WP content folder which is sitting on our EFS file",
    "start": "2826200",
    "end": "2832720"
  },
  {
    "text": "system uh let's go ahead and activate that we also want to activate our um our",
    "start": "2832720",
    "end": "2839800"
  },
  {
    "text": "other",
    "start": "2839800",
    "end": "2842000"
  },
  {
    "text": "plugin our W3 total C plug as well so now that that is working what we",
    "start": "2844839",
    "end": "2853200"
  },
  {
    "text": "want to do is we want to make one small change and this is something you probably wouldn't do on your side but you notice here um if we we don't know",
    "start": "2853200",
    "end": "2859680"
  },
  {
    "text": "exactly what instance this is running on we only have one instance so we know it's it's running on that one but if we",
    "start": "2859680",
    "end": "2865079"
  },
  {
    "text": "expand our autoscaling group we're not going to know what what instance that is so uh quickly I'm going to go ahead and",
    "start": "2865079",
    "end": "2871720"
  },
  {
    "text": "just copy uh a header file that I've already made made",
    "start": "2871720",
    "end": "2877040"
  },
  {
    "text": "some some changes to actually first we need to go ahead and connect to that that ec2",
    "start": "2877040",
    "end": "2885480"
  },
  {
    "text": "instance if we grab this instance we'll go ahead and connect to it",
    "start": "2900960",
    "end": "2907240"
  },
  {
    "text": "grab our connection",
    "start": "2907240",
    "end": "2910000"
  },
  {
    "text": "string now let's go ahead and",
    "start": "2914400",
    "end": "2918400"
  },
  {
    "text": "copy that new header file over so now what do we",
    "start": "2920160",
    "end": "2925400"
  },
  {
    "text": "have we do a Refresh on this now we're going to see the instance ID so that's",
    "start": "2925400",
    "end": "2930760"
  },
  {
    "text": "good so now that we we know that it's running there but we want to do something else as well so let's go ahead let's add a picture you want to make uh",
    "start": "2930760",
    "end": "2937799"
  },
  {
    "text": "you we want to customize this just a little",
    "start": "2937799",
    "end": "2941480"
  },
  {
    "text": "bit so let's go ahead and select a file we'll upload a new file and my site is called uh Cloud",
    "start": "2942839",
    "end": "2949640"
  },
  {
    "text": "Viking so we've got a little picture of a a Viking",
    "start": "2949640",
    "end": "2955319"
  },
  {
    "text": "ship we'll go ahead and save that we want to use logo and tagline save and",
    "start": "2955319",
    "end": "2962240"
  },
  {
    "text": "publish now as we refresh this we're going to have picture which",
    "start": "2962280",
    "end": "2967359"
  },
  {
    "text": "is great so now let's say that we have an event an autoscaling event that we",
    "start": "2967359",
    "end": "2973359"
  },
  {
    "text": "needed to expand our um autoscaling group and have launched a number of of",
    "start": "2973359",
    "end": "2978400"
  },
  {
    "text": "other instances so if we go into our autoscaling group for this",
    "start": "2978400",
    "end": "2984920"
  },
  {
    "text": "environment we'll change the desired number of instances to say four go ahead and save that change",
    "start": "2988880",
    "end": "2997280"
  },
  {
    "text": "so now in the background it's going to automatically launch these instances well a part of this uh the launch config",
    "start": "2997280",
    "end": "3002960"
  },
  {
    "text": "for our autoscaling group has all the information it needs to download all the files it needed to for um uh for our",
    "start": "3002960",
    "end": "3011200"
  },
  {
    "text": "environment it's able to automatically Mount the EFS file system and it's going",
    "start": "3011200",
    "end": "3016880"
  },
  {
    "text": "to be automatically joined to our load balancer so if we quickly switch",
    "start": "3016880",
    "end": "3024558"
  },
  {
    "text": "back to our",
    "start": "3025200",
    "end": "3029000"
  },
  {
    "text": "environment one thing we could also do after we've we we've done all this is we could install um our MCD client on our",
    "start": "3033200",
    "end": "3042400"
  },
  {
    "text": "ec2 instances uh we could configure op cach a little bit more and say you know what we're going to going to maybe",
    "start": "3042400",
    "end": "3049200"
  },
  {
    "text": "attach another EBS volume and actually have op cach store those files cash",
    "start": "3049200",
    "end": "3054720"
  },
  {
    "text": "those files on this other EBS volume if you wanted to we could also use cloudfront to Cache some of that",
    "start": "3054720",
    "end": "3061720"
  },
  {
    "text": "information um and uh use that as our CDM then we could also use Route 53 and",
    "start": "3061720",
    "end": "3069280"
  },
  {
    "text": "put in a a custom domain name so this would look like any you know typical",
    "start": "3069280",
    "end": "3074680"
  },
  {
    "text": "WordPress application but in the background you have a basically an infinite number of ec2 instances that",
    "start": "3074680",
    "end": "3080079"
  },
  {
    "text": "you could scale to uh infinite amount of storage in EFS and on the database side you've got",
    "start": "3080079",
    "end": "3086400"
  },
  {
    "text": "a Aurora cluster but in front of that you have an elasticache caching mechanism to cach all those database",
    "start": "3086400",
    "end": "3093079"
  },
  {
    "text": "calls and again both of those environments can grow if we need to so now if we quickly hop over to see",
    "start": "3093079",
    "end": "3101040"
  },
  {
    "text": "where we're at hopefully all of those instances",
    "start": "3101040",
    "end": "3106040"
  },
  {
    "text": "have have joined it looks like successful now if we hop back and we do",
    "start": "3106520",
    "end": "3112880"
  },
  {
    "text": "change the input oh yeah thanks now if we hop back and we take a look at",
    "start": "3112880",
    "end": "3118880"
  },
  {
    "text": "this take a look at the instance ID and as we scroll through this we should see the instance ID change so now all of",
    "start": "3118880",
    "end": "3125319"
  },
  {
    "text": "these instance IDs these new instances have been added to our load balancer and",
    "start": "3125319",
    "end": "3131599"
  },
  {
    "text": "it's serving out all of this data again very easy to deploy we have this in a cloud formation template it's going to",
    "start": "3131599",
    "end": "3137119"
  },
  {
    "text": "be available as a reference architecture and we're going to be updating the the white paper as well",
    "start": "3137119",
    "end": "3144760"
  },
  {
    "text": "all right thank you",
    "start": "3147319",
    "end": "3151040"
  },
  {
    "text": "Daryl so all right so let's briefly talk about economics with EFS as I mentioned",
    "start": "3152359",
    "end": "3159119"
  },
  {
    "text": "earlier with EFS you pay only for the storage space you use uh there's no minimum commitments no upfront fees you",
    "start": "3159119",
    "end": "3166359"
  },
  {
    "text": "don't pay to provision storage uh there's no throughput charges request charges none of that it's a simple flat",
    "start": "3166359",
    "end": "3173400"
  },
  {
    "text": "gigabyte per month charge of 30 cents in our US regions so how do you put that 30 cents",
    "start": "3173400",
    "end": "3181559"
  },
  {
    "text": "per gigabyte per month into context well one way to do that is to think about what it would cost to have a",
    "start": "3181559",
    "end": "3188000"
  },
  {
    "text": "shared file system that you run on your own on on AWS and a common way to do",
    "start": "3188000",
    "end": "3194160"
  },
  {
    "text": "that would be a third-party uh file system layer that you run on ec2",
    "start": "3194160",
    "end": "3200480"
  },
  {
    "text": "instances and that's backed by EBS volumes and so in that type of setup you",
    "start": "3200480",
    "end": "3205720"
  },
  {
    "text": "would have uh if you're doing this across multiple azs so that you get the multi-az",
    "start": "3205720",
    "end": "3210880"
  },
  {
    "text": "characteristics of of EFS you would have one instance in each a that's running",
    "start": "3210880",
    "end": "3216119"
  },
  {
    "text": "this shared file layer and you would have uh two sets of of EBS volumes one",
    "start": "3216119",
    "end": "3222520"
  },
  {
    "text": "set in each a that actually stores the data and you would have inter a traffic",
    "start": "3222520",
    "end": "3227720"
  },
  {
    "text": "between the EBS volumes uh in order to replicate the data across A's so how",
    "start": "3227720",
    "end": "3233319"
  },
  {
    "text": "much would that cost well let's say that you uh need to store around 500 gabt of data and you",
    "start": "3233319",
    "end": "3240920"
  },
  {
    "text": "want multi-az because you require High availability high durability so using that shared file",
    "start": "3240920",
    "end": "3246839"
  },
  {
    "text": "layer on top of EBS you'd probably provision around 600 gigabyt worth of EBS volumes that's assuming around 85%",
    "start": "3246839",
    "end": "3254400"
  },
  {
    "text": "utilization you would never 100% utilize an EBS volume and keep in mind you'd",
    "start": "3254400",
    "end": "3259440"
  },
  {
    "text": "need to replicate those volumes to the second AZ so for storage you have two",
    "start": "3259440",
    "end": "3264760"
  },
  {
    "text": "times a 600 gigabyte gp2 volumes that adds up to $120 you have the compute costs and",
    "start": "3264760",
    "end": "3272559"
  },
  {
    "text": "these are the ec2 instances that just manage the file system layer so these aren't your instances that are accessing",
    "start": "3272559",
    "end": "3278079"
  },
  {
    "text": "the file system these are the ones that are just running that file system layer and then you'd have the cross a or inter",
    "start": "3278079",
    "end": "3285280"
  },
  {
    "text": "a data transfer costs for all of the replication traffic you're doing and that $129 per month is uh if you were",
    "start": "3285280",
    "end": "3292839"
  },
  {
    "text": "doing the typical amount of traffic that we see customers doing on E s so",
    "start": "3292839",
    "end": "3297960"
  },
  {
    "text": "altogether you're looking at a price of about $600 per month to have this set up on EFS with a 500 gigabyte file system",
    "start": "3297960",
    "end": "3306440"
  },
  {
    "text": "you're paying $150 per month so that's one lens through which to look at at the price and understand the",
    "start": "3306440",
    "end": "3314000"
  },
  {
    "text": "economics and now I'd like to talk about some upcoming features and announce a",
    "start": "3314520",
    "end": "3319960"
  },
  {
    "text": "feature that's available today so uh first of all we are are uh releasing soon",
    "start": "3319960",
    "end": "3328599"
  },
  {
    "text": "encryption of data at rest and what that will do is it provides an additional layer of protection for your data and",
    "start": "3328599",
    "end": "3336160"
  },
  {
    "text": "helps you meet your organization's Regulatory and compliance requirements and our encryption of data",
    "start": "3336160",
    "end": "3341920"
  },
  {
    "text": "at rest will be fully integrated with AWS KMS or Key Management Service so you",
    "start": "3341920",
    "end": "3347160"
  },
  {
    "text": "can manage the keys that you're using to encrypt and and decrypt your your file data and the encryption and decryption",
    "start": "3347160",
    "end": "3353359"
  },
  {
    "text": "is handled transparently all you do is you specify that for a file system you want it to be encrypted you specify the",
    "start": "3353359",
    "end": "3360079"
  },
  {
    "text": "key and EFS manages everything and there's no extra cost for enabling encryption so that feature is coming in",
    "start": "3360079",
    "end": "3367280"
  },
  {
    "text": "early 2017 also coming soon is um a",
    "start": "3367280",
    "end": "3376200"
  },
  {
    "text": "simplifying feature for using EFS uh today every Mount Target that you",
    "start": "3376200",
    "end": "3382680"
  },
  {
    "text": "create has a unique DNS name and that DNS name is derived from the a in which",
    "start": "3382680",
    "end": "3389240"
  },
  {
    "text": "the mount Target resides with the new feature that will be coming soon you will have a single",
    "start": "3389240",
    "end": "3395480"
  },
  {
    "text": "DNS name for your file system so single DNS name across all of your Mount targets and that DNS name Will automatic",
    "start": "3395480",
    "end": "3402319"
  },
  {
    "text": "the resolve to the IP address of the mount Target and the AZ from which you are mounting your file system so it's",
    "start": "3402319",
    "end": "3409799"
  },
  {
    "text": "simplification where you don't have to worry about which a your instance is in when you're mounting the file",
    "start": "3409799",
    "end": "3415240"
  },
  {
    "text": "system and to give you a feel for what that will look like today the DNS names",
    "start": "3415240",
    "end": "3420720"
  },
  {
    "text": "have uh the first part is tied to what AZ you're in that will go away and now",
    "start": "3420720",
    "end": "3426680"
  },
  {
    "text": "your your DNS names for your file systems will just have your files will just have the rest of the DNS name",
    "start": "3426680",
    "end": "3432520"
  },
  {
    "text": "without that a so your file system id. fs. region. Amazon",
    "start": "3432520",
    "end": "3439520"
  },
  {
    "text": "AWS and then before talking about the next feature which is the one that we're announcing today let me set the stage by",
    "start": "3442880",
    "end": "3449880"
  },
  {
    "text": "talking about how customers typically think about bridging data between on-prem and",
    "start": "3449880",
    "end": "3456000"
  },
  {
    "text": "EFS and customers typically think about four scenarios for working with file data across their on-prem environments",
    "start": "3456000",
    "end": "3462480"
  },
  {
    "text": "and EFS so one is migration where they want to move their entire data set and",
    "start": "3462480",
    "end": "3468480"
  },
  {
    "text": "their application onto AWS um and then run the application on",
    "start": "3468480",
    "end": "3473760"
  },
  {
    "text": "ec2 instances using data in FS so that's migration another is bursting and with",
    "start": "3473760",
    "end": "3481119"
  },
  {
    "text": "bursting uh the the pattern is that you remve your data your data is stored permanently on Prem you move it onto EFS",
    "start": "3481119",
    "end": "3488119"
  },
  {
    "text": "in order to do some processing on the data so you would spin up an ec2 cluster do some processing on the data and then",
    "start": "3488119",
    "end": "3493920"
  },
  {
    "text": "you would move it back onto on Prem to permanently reside there so that's bursting the third is taring where you",
    "start": "3493920",
    "end": "3501559"
  },
  {
    "text": "would store part of your data set permanently on EFS and keep part of it on Prem and you would access the entire",
    "start": "3501559",
    "end": "3508559"
  },
  {
    "text": "data set from applications running on Prem and so you would ideally keep your hotter data on Prem where it's closer to",
    "start": "3508559",
    "end": "3515079"
  },
  {
    "text": "the applications and the rest of your data set on EFS and then finally there's backup and",
    "start": "3515079",
    "end": "3521000"
  },
  {
    "text": "Disaster Recovery where you maintain a copy of your full data set on EFS you periodically make sure that that's up to",
    "start": "3521000",
    "end": "3527240"
  },
  {
    "text": "date and then you can use that either if you want to restore backup or for Disaster Recovery",
    "start": "3527240",
    "end": "3533680"
  },
  {
    "text": "scenarios and what we're announcing today today is access to your EFS file systems",
    "start": "3534039",
    "end": "3540119"
  },
  {
    "text": "from on premises servers over Direct Connect connections and for those of you who aren't familiar with what Direct",
    "start": "3540119",
    "end": "3546520"
  },
  {
    "text": "Connect is AWS direct connect establishes a private network connection between your on-prem environment and AWS",
    "start": "3546520",
    "end": "3554319"
  },
  {
    "text": "bypassing the internet entirely one of the benefits of doing that is that you get improved latencies on this direct",
    "start": "3554319",
    "end": "3560920"
  },
  {
    "text": "connect connection compared to a connection over the internet and you get improved throughput",
    "start": "3560920",
    "end": "3566640"
  },
  {
    "text": "so with this feature that we're announcing today you can mount your file system from an on-prem server using the",
    "start": "3566640",
    "end": "3572079"
  },
  {
    "text": "same NFS 4.1 Mount command you'd use from ec2 instances and your you're",
    "start": "3572079",
    "end": "3577640"
  },
  {
    "text": "you'll be able to access your data just like you would with from ec2 in terms of the scenarios that I",
    "start": "3577640",
    "end": "3584960"
  },
  {
    "text": "talked about that this supports supports the migration the bursting and the backup and Dr scenarios um probably not",
    "start": "3584960",
    "end": "3592680"
  },
  {
    "text": "a a great solution for most tiering uh applications because you'll want your",
    "start": "3592680",
    "end": "3597920"
  },
  {
    "text": "hotter data to be on Prem still for those so this is really about moving your data in and moving your data",
    "start": "3597920",
    "end": "3605119"
  },
  {
    "text": "out um now keep in mind that the latency of direct connect connections uh will impact performance so uh due to laws of",
    "start": "3606079",
    "end": "3613680"
  },
  {
    "text": "physics um on some Direct Connect connections you'll actually see tens of milliseconds of of delays due to",
    "start": "3613680",
    "end": "3620319"
  },
  {
    "text": "propagating the data over long distances so uh if you're really trying to drive",
    "start": "3620319",
    "end": "3625480"
  },
  {
    "text": "high levels of throughput high levels of of IO keep in mind uh what we talked about earlier in terms of paral",
    "start": "3625480",
    "end": "3632160"
  },
  {
    "text": "parallelizing uh the data that you're you're copying over and uh this actually shows a test",
    "start": "3632160",
    "end": "3639880"
  },
  {
    "text": "that we ran uh that shows the time it took to copy 26,000 files um to EFS as a function of",
    "start": "3639880",
    "end": "3647839"
  },
  {
    "text": "the number of threads and as you can see as you increase the number of threads the time goes down and it has a nice Asm",
    "start": "3647839",
    "end": "3655160"
  },
  {
    "text": "totic uh uh nature to the curve and that's because as you increase the number of threads every time you you",
    "start": "3655160",
    "end": "3661720"
  },
  {
    "text": "increase the number of threads by two you're having the time that it takes to copy the data over so you would expect",
    "start": "3661720",
    "end": "3666880"
  },
  {
    "text": "an ASM toote and uh this Direct Connect feature",
    "start": "3666880",
    "end": "3673880"
  },
  {
    "text": "is available today in three regions it's available actually starting right now uh so Us West Oregon uh Us East Ohio and EU",
    "start": "3673880",
    "end": "3682799"
  },
  {
    "text": "Ireland um and then it's coming soon uh to us East Northern",
    "start": "3682799",
    "end": "3689279"
  },
  {
    "text": "Virginia and uh that's it we are out of time um I do want to encourage you if",
    "start": "3690559",
    "end": "3696680"
  },
  {
    "text": "you're interested in learning more about EFS and especially learning about some example applications customers using EFS",
    "start": "3696680",
    "end": "3703599"
  },
  {
    "text": "there's a case study with atlassian uh it's it happened earlier today one session but there's another one at 12:30",
    "start": "3703599",
    "end": "3709960"
  },
  {
    "text": "on Friday um there's and they're talking about jira on top of VFS uh there's a",
    "start": "3709960",
    "end": "3715480"
  },
  {
    "text": "case with spoko they're talking about web serving and optimizing web serving uh with EFS and then there's a uh",
    "start": "3715480",
    "end": "3723000"
  },
  {
    "text": "session with Monsanto where they're doing a bunch of really cool analytics uh workloads on EFS so thank you all",
    "start": "3723000",
    "end": "3730400"
  },
  {
    "text": "Daryl and I will stand by for our questions",
    "start": "3730400",
    "end": "3735240"
  }
]
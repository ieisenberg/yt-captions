[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "hello everybody hopefully everybody's having a good reinvent so far awesome I",
    "start": "60",
    "end": "6569"
  },
  {
    "text": "am Tyler Turk I am an infrastructure engineer at Riot Games I am a part of",
    "start": "6569",
    "end": "12840"
  },
  {
    "text": "what's called the riot platform group we are a department that is responsible for all of the ecosystem around the game so",
    "start": "12840",
    "end": "20010"
  },
  {
    "text": "I don't get a do cool stuff like work on League of Legends or other products that we're we're building right now but I'm",
    "start": "20010",
    "end": "26460"
  },
  {
    "text": "on the team that's responsible for all player accounts player attack account data authentication and authorization",
    "start": "26460",
    "end": "32989"
  },
  {
    "text": "you can see here this is a picture of my family I decided to include this year I have an",
    "start": "32989",
    "end": "38370"
  },
  {
    "text": "older daughter named Olivia and middle daughter named Hadley and a son who's named hunter I included this because",
    "start": "38370",
    "end": "43710"
  },
  {
    "text": "it's incredibly important to me that when I'm not working I am spending time with them and not responding to pager",
    "start": "43710",
    "end": "50280"
  },
  {
    "text": "duty and it makes my family really happy that way too when I play League of",
    "start": "50280",
    "end": "56129"
  },
  {
    "text": "Legends I typically can be found in the jungle that way I don't have to compete to finish last hitting the creeps there",
    "start": "56129",
    "end": "62250"
  },
  {
    "text": "so I play Nocturne kindred or kha'zix so",
    "start": "62250",
    "end": "68010"
  },
  {
    "text": "I'm here today to talk to you a little bit about what we've done over the past two years or so I'm gonna start with a",
    "start": "68010",
    "end": "74729"
  },
  {
    "text": "little bit of history of the League of Legends account service then I'm going to talk about what I think are some of",
    "start": "74729",
    "end": "79979"
  },
  {
    "text": "the really important things when it comes to architecting our global service after that we're going to dive into how",
    "start": "79979",
    "end": "85170"
  },
  {
    "text": "we've implemented the things that I think are important with building a global service some of the lessons that",
    "start": "85170",
    "end": "90420"
  },
  {
    "text": "we've learned along the way which there are a lot more than what I can fit into this 15 minute presentation and end it",
    "start": "90420",
    "end": "96840"
  },
  {
    "text": "with a recap so if you're not familiar with League of Legends we are a",
    "start": "96840",
    "end": "102000"
  },
  {
    "start": "102000",
    "end": "102000"
  },
  {
    "text": "massively online battle arena game we the company was founded in 2006 the game",
    "start": "102000",
    "end": "108570"
  },
  {
    "text": "launched in 2009 and we grew incredibly rapidly we partner with tenzin who is",
    "start": "108570",
    "end": "114810"
  },
  {
    "text": "our parent company and garena Tencent runs all of League of Legends for China and then garena runs the Southeast Asia",
    "start": "114810",
    "end": "121530"
  },
  {
    "text": "environments outside of those two environments we run 12 League of Legends",
    "start": "121530",
    "end": "126570"
  },
  {
    "text": "game shards all of those player accounts were stored in 10 unique databases worldwide",
    "start": "126570",
    "end": "132420"
  },
  {
    "text": "those 10 different databases stored hundreds of millions of player account records and",
    "start": "132420",
    "end": "137760"
  },
  {
    "text": "we performed over a million lookup account lookups per minute we handle",
    "start": "137760",
    "end": "143340"
  },
  {
    "text": "several hundred thousand authentication requests per minute and we also have several hundred thousand requests full",
    "start": "143340",
    "end": "149010"
  },
  {
    "text": "of people trying to break into other people's accounts because of this it's incredibly important that we make sure",
    "start": "149010",
    "end": "154410"
  },
  {
    "text": "that we keep player's data safe intact and secure to do this we have a couple",
    "start": "154410",
    "end": "160379"
  },
  {
    "text": "different things that we've architected along the way but I really want to drive home that a lot of our players feel",
    "start": "160379",
    "end": "166950"
  },
  {
    "text": "really like they're League of Legends account or they're gaming account for any other gaming company is a core part",
    "start": "166950",
    "end": "173310"
  },
  {
    "text": "of their identity because they've spent countless hours grinding and trying to get to the rank that they got they may",
    "start": "173310",
    "end": "179190"
  },
  {
    "text": "have purchased content in the game so if they lose that it's incredibly painful to them so some of the early challenges",
    "start": "179190",
    "end": "188610"
  },
  {
    "start": "186000",
    "end": "186000"
  },
  {
    "text": "we have a lot of people in the community that like to joke about us being a small indie company and that's why some things take a little while to build but the",
    "start": "188610",
    "end": "195569"
  },
  {
    "text": "reality is that we we just grew incredibly rapidly and there there was a",
    "start": "195569",
    "end": "200850"
  },
  {
    "text": "lot going on a lot in flight all at once we had several teams that started to build competing authentication and",
    "start": "200850",
    "end": "207420"
  },
  {
    "text": "authorization standards and different teams started to have different levels of dependency on these different",
    "start": "207420",
    "end": "213840"
  },
  {
    "text": "solutions which made it kind of difficult for us to align around how we were going to move forward one of the",
    "start": "213840",
    "end": "219420"
  },
  {
    "text": "downsides to rolling your own authentication and authorization platform is you might not be the form of",
    "start": "219420",
    "end": "225299"
  },
  {
    "text": "security expert and you might take things for granted where you just think oh I did this thing and it seems smart so it's got to be secure but a lot of",
    "start": "225299",
    "end": "232799"
  },
  {
    "text": "times you end up running into situations where there's just some small things that you missed you also tend to have",
    "start": "232799",
    "end": "238380"
  },
  {
    "text": "like a really narrow focus on this is the particular problem that I'm trying to solve so I think that if I do it this",
    "start": "238380",
    "end": "244560"
  },
  {
    "text": "way you know everything will work great which results in you kind of having this really rigid kind of bespoke design that",
    "start": "244560",
    "end": "250829"
  },
  {
    "text": "you have also because of the way that we architected and implemented the legacy account service we weren't able to",
    "start": "250829",
    "end": "257039"
  },
  {
    "text": "integrate with third parties who would otherwise be able to provide our players our better experience so if you play league and you're familiar with like Oh",
    "start": "257039",
    "end": "263010"
  },
  {
    "text": "be GG wouldn't it be amazing if you could actually log in with your legends accountant and have access to",
    "start": "263010",
    "end": "268410"
  },
  {
    "text": "all of the player data instead of just the rank data that we store publicly I think things like that would make our",
    "start": "268410",
    "end": "275130"
  },
  {
    "text": "accounts platform significantly better for all of our player base so to",
    "start": "275130",
    "end": "280410"
  },
  {
    "text": "accommodate for trying to do a little bit of a better job on handling all the authentication and authorization",
    "start": "280410",
    "end": "285590"
  },
  {
    "text": "platforms that we had before we built the system called riot sign-on riot",
    "start": "285590",
    "end": "291270"
  },
  {
    "text": "sign-on is built using Open ID Connect if you're not familiar with Open ID Connect it is a layer on top of OAuth",
    "start": "291270",
    "end": "298100"
  },
  {
    "text": "202 is a fairly well-known standard it's used by Facebook Google pretty much any",
    "start": "298100",
    "end": "303780"
  },
  {
    "text": "big name out there that has the authentication and authorization platform that we're looking for it's",
    "start": "303780",
    "end": "309360"
  },
  {
    "text": "also provided by Amazon kognito so we built this to replace all the legacy",
    "start": "309360",
    "end": "314490"
  },
  {
    "text": "bespoke services that we had and it was a pretty painful process making sure that we had everything perfectly aligned",
    "start": "314490",
    "end": "320580"
  },
  {
    "text": "with what other teams wanted helping to make sure that this new service that we were building is something that would",
    "start": "320580",
    "end": "325919"
  },
  {
    "text": "provide them the experience that they needed in order to support the players as well and then get them to move off of",
    "start": "325919",
    "end": "331650"
  },
  {
    "text": "the legacy services this gave us the ability to adopt several security standards just kind of organically given",
    "start": "331650",
    "end": "337650"
  },
  {
    "text": "we adopted open ID Connect so here at the top that little person is an",
    "start": "337650",
    "end": "343500"
  },
  {
    "text": "imaginary player this was what our service looked like about two and a half",
    "start": "343500",
    "end": "348570"
  },
  {
    "text": "years ago the player would decide they want to login their request would be sent to CloudFlare we use the orange",
    "start": "348570",
    "end": "355080"
  },
  {
    "text": "cloud DDoS mitigation after you've gotten past the DDoS mitigation we would send you to what's called our",
    "start": "355080",
    "end": "360870"
  },
  {
    "text": "provider service the provider is behind a load balancer it would handle all of the general business logic around your",
    "start": "360870",
    "end": "366539"
  },
  {
    "text": "authentication request so if you had logged in before and you had meta data around your session it would be routed over to the remember service and then we",
    "start": "366539",
    "end": "373710"
  },
  {
    "text": "could potentially restore your session if your session was not remembered we would also send you over to the vel call",
    "start": "373710",
    "end": "379830"
  },
  {
    "text": "service it's a velocity rate-limiting service so that is how we looked at the metadata on the request you are making",
    "start": "379830",
    "end": "385890"
  },
  {
    "text": "and determine whether or not we should actually allow you through once you got past remember in vel'koz we would send the",
    "start": "385890",
    "end": "392970"
  },
  {
    "text": "request over to the all service the all service is what actually does the backends user name and password validation it's not on this slide it's",
    "start": "392970",
    "end": "399780"
  },
  {
    "text": "on the next slide but we leverage at the time a distributed mesh VPN it was not great",
    "start": "399780",
    "end": "406409"
  },
  {
    "text": "there were a lot of issues with network instability random flaps things would",
    "start": "406409",
    "end": "411419"
  },
  {
    "text": "just suddenly disappear and players wouldn't be able to authenticate there was a back-end service called Gas Gas",
    "start": "411419",
    "end": "416789"
  },
  {
    "text": "stands for the global authentication service which i think is really a horrible name because it was not global",
    "start": "416789",
    "end": "422099"
  },
  {
    "text": "at all so we took this which was initially deployed in u.s. East one and we decided to replicate them so when we",
    "start": "422099",
    "end": "429360"
  },
  {
    "text": "replicated that this is a zoomed in version of just two of our AWS regions this is about what it looked like",
    "start": "429360",
    "end": "436439"
  },
  {
    "text": "roughly six months ago so from the internet we'd then still hit CloudFlare we do the orange cloud DDoS mitigation",
    "start": "436439",
    "end": "443610"
  },
  {
    "text": "prevention after that we send you to a service called NS one and this one is a DNS provider that can do really cool",
    "start": "443610",
    "end": "450809"
  },
  {
    "text": "things for your DNS like do topologically closest routing so that way wherever the DNS request is",
    "start": "450809",
    "end": "456569"
  },
  {
    "text": "originating from it'll actually sort the DNS responses based on whatever server that DNS request is originating from and",
    "start": "456569",
    "end": "462899"
  },
  {
    "text": "since Glod floud flare has global points of presence it makes it really easy for",
    "start": "462899",
    "end": "468300"
  },
  {
    "text": "us to say oh you're coming in from europe we shoulda brought you to the Europe cluster once that's happened and",
    "start": "468300",
    "end": "473699"
  },
  {
    "text": "we've chosen the proper cluster for you we send that traffic to our front end router service the router is a",
    "start": "473699",
    "end": "479459"
  },
  {
    "text": "relatively simple service that just simply inspects your connection and validates whether or not you've actually authenticated against a prior cluster",
    "start": "479459",
    "end": "486110"
  },
  {
    "text": "the reason for this is at this point in time we did not have a global",
    "start": "486110",
    "end": "491539"
  },
  {
    "text": "authorization store for all of our players so if you authenticated your authentication was actually pinned to a",
    "start": "491539",
    "end": "497279"
  },
  {
    "text": "single AWS region that's not a huge problem but it still provides kind of a",
    "start": "497279",
    "end": "502499"
  },
  {
    "text": "potential pain point for players in the event that an AWS region goes down we would lose the ability for that player",
    "start": "502499",
    "end": "508649"
  },
  {
    "text": "to still have that current login session for the player this doesn't represent",
    "start": "508649",
    "end": "513809"
  },
  {
    "text": "very well because they're logged in they're playing they end their game and all of a sudden they can't chat with anybody and all of the other services",
    "start": "513809",
    "end": "520018"
  },
  {
    "text": "that require authentication just didn't work pretty much everything else on this slide is the same as the last one I",
    "start": "520019",
    "end": "526860"
  },
  {
    "text": "realized there was one service that I left out kind of explaining on the last one there's one here called c2 ID c2 ID",
    "start": "526860",
    "end": "532439"
  },
  {
    "text": "is a commercial off-the-shelf product called connect to ID it handles all of the open ID connect and ohatsu logic for",
    "start": "532439",
    "end": "538560"
  },
  {
    "text": "us the authentication service leveraged AWS Direct Connect and here at riot",
    "start": "538560",
    "end": "545760"
  },
  {
    "text": "we've built our own internet provider called riot direct it's an incredibly",
    "start": "545760",
    "end": "550770"
  },
  {
    "text": "amazing opportunity that we have this background internet provider that we're able to leverage that ties into AWS via",
    "start": "550770",
    "end": "557610"
  },
  {
    "text": "the AWS direct connect as well as all of our physical data centers which gives us really low latency access to all of the",
    "start": "557610",
    "end": "563100"
  },
  {
    "text": "I should say nga us because it's not pickleball authentication service but",
    "start": "563100",
    "end": "569060"
  },
  {
    "text": "gave us really fast access to that back-end service to make sure that we could authenticate a player and then",
    "start": "569060",
    "end": "574110"
  },
  {
    "text": "return the record so I'm sure there's a number of folks here continue there we",
    "start": "574110",
    "end": "585540"
  },
  {
    "start": "585000",
    "end": "585000"
  },
  {
    "text": "go the global data protection regulation or gdpr if you're not familiar with these",
    "start": "585540",
    "end": "591060"
  },
  {
    "text": "letters awesome good for you that's great if you are I'm very sorry",
    "start": "591060",
    "end": "597960"
  },
  {
    "text": "this is actually a really amazing set of laws that the whole purpose of that is",
    "start": "597960",
    "end": "603270"
  },
  {
    "text": "to help provide better security for the personally identifiable information that",
    "start": "603270",
    "end": "608280"
  },
  {
    "text": "you have and try and provide a better sense of security and ownership to the",
    "start": "608280",
    "end": "614040"
  },
  {
    "text": "people whose data you have which isn't critically important for a lot of companies they could see this is just a",
    "start": "614040",
    "end": "620580"
  },
  {
    "text": "giant pain or something that was you know you just have to do it because Europe says so for us we saw this as an",
    "start": "620580",
    "end": "627180"
  },
  {
    "text": "amazing opportunity for us to prioritize a lot of the technical debt that had been bothering a number of us and very",
    "start": "627180",
    "end": "632240"
  },
  {
    "text": "rapidly burn it down it was an incredibly aggressive timeline but we",
    "start": "632240",
    "end": "637530"
  },
  {
    "text": "knew that we would have to modify the way that we stored players data and we would have to change the way that we",
    "start": "637530",
    "end": "642660"
  },
  {
    "text": "thought about things we also saw this as an opportunity to encrypt additional PII that doesn't necessarily need to be",
    "start": "642660",
    "end": "648510"
  },
  {
    "text": "encrypted but just helps provide that extra layer of security we also had the discussion as to whether or not because",
    "start": "648510",
    "end": "654660"
  },
  {
    "text": "of the aggressive timeline we should look at targeting this just for Europe or if we should try and find a way to do",
    "start": "654660",
    "end": "659940"
  },
  {
    "text": "it worldwide and we chose the opportunity to work really hard together and",
    "start": "659940",
    "end": "665370"
  },
  {
    "text": "this worldwide there were a lot of other features that we realized that we could really prioritize as a part of this so",
    "start": "665370",
    "end": "672839"
  },
  {
    "start": "670000",
    "end": "670000"
  },
  {
    "text": "one of those is called the globally unique player identifier or what we call internally as a poet this poet is",
    "start": "672839",
    "end": "679620"
  },
  {
    "text": "basically a global representation of your account it's a UUID that we have generated internally the reason for this",
    "start": "679620",
    "end": "685980"
  },
  {
    "text": "is prior to having this poet identifier you would need to know certain metadata",
    "start": "685980",
    "end": "691230"
  },
  {
    "text": "about a player's account if you wanted to find them the most important one was which game shard do they play on if you",
    "start": "691230",
    "end": "696300"
  },
  {
    "text": "don't know what game shard they play on you have no idea how to look up that account and if we need to look up that account it just becomes incredibly",
    "start": "696300",
    "end": "701490"
  },
  {
    "text": "complicated on top of that you also need some other identifiers such as their account ID or their summoner name or",
    "start": "701490",
    "end": "706830"
  },
  {
    "text": "something else that kind of ties all that together so we saw this as an opportunity to build a truly global",
    "start": "706830",
    "end": "712860"
  },
  {
    "text": "account lookup system so that way things that don't actually really matter to your game shard like we have a merge",
    "start": "712860",
    "end": "718350"
  },
  {
    "text": "store if you wanted to buy merge off of our merge store why did we care what game shard you play on other than potentially your currency which we could",
    "start": "718350",
    "end": "724500"
  },
  {
    "text": "get off of other metadata like your geolocation or the country that we have on file for you it also gave us the",
    "start": "724500",
    "end": "731520"
  },
  {
    "text": "ability to really think about how to architect this so we could have third player's third party to support so if",
    "start": "731520",
    "end": "737220"
  },
  {
    "text": "you wanted to integrate with twitch or Opie Gigi or something like that we would be able to start having that functionality so as part of architecting",
    "start": "737220",
    "end": "745950"
  },
  {
    "text": "a global service there's a couple key tenants that I think are particularly important we wanted to have a situation",
    "start": "745950",
    "end": "753390"
  },
  {
    "text": "where we had infrastructure that was repeatable we wanted to make sure that this was something that was highly",
    "start": "753390",
    "end": "758550"
  },
  {
    "text": "available globally available worldwide I mentioned briefly earlier that $0.10",
    "start": "758550",
    "end": "763589"
  },
  {
    "text": "runs our infrastructure in China and then we have Karina that runs our infrastructure in Southeast Asia which means we need to be really critical",
    "start": "763589",
    "end": "768959"
  },
  {
    "text": "about the decisions and choices we're making for the infrastructure we're deploying we also wanted to make sure that we have full data consistency so if",
    "start": "768959",
    "end": "775410"
  },
  {
    "text": "you're accessing any of your account data we return the same password every time so you can log in every time we",
    "start": "775410",
    "end": "780570"
  },
  {
    "text": "want to make sure that if we're sending your emails that it's using the correct email address we need to make sure that all of that player data is exactly how",
    "start": "780570",
    "end": "787080"
  },
  {
    "text": "you intend it and then on top of that we want a way to be able to verify that all of us make sense that it functions the",
    "start": "787080",
    "end": "793770"
  },
  {
    "text": "way it's supposed to it handles the amount of traffic that we intend and that if something bad happens we can",
    "start": "793770",
    "end": "799180"
  },
  {
    "text": "easily recover from it so from a repeatable infrastructure perspective there's several different technologies",
    "start": "799180",
    "end": "804400"
  },
  {
    "start": "801000",
    "end": "801000"
  },
  {
    "text": "that you could use you could use CloudFormation if you're using just AWS you could use terraform there's",
    "start": "804400",
    "end": "809950"
  },
  {
    "text": "different configuration management tools such as ansible or chef that have their own vendor tie-ins so you could leverage",
    "start": "809950",
    "end": "815080"
  },
  {
    "text": "the API is there for provisioning infrastructure the key thing that we really wanted to make sure of was that whatever choice we made it be easily",
    "start": "815080",
    "end": "822370"
  },
  {
    "text": "portable to wherever we needed to use it and we would be able to have other teams real Everage some of the things that we've already built so people aren't",
    "start": "822370",
    "end": "828550"
  },
  {
    "text": "constantly reinventing the wheel we wanted to be highly available all of the",
    "start": "828550",
    "end": "835660"
  },
  {
    "start": "832000",
    "end": "832000"
  },
  {
    "text": "blue sections that you see in this rotating globe right here are where we have a fairly high concentration of players this means that it's really",
    "start": "835660",
    "end": "843220"
  },
  {
    "text": "critical to us that we can provide a low latency access to your player account and the game charms we want to make sure",
    "start": "843220",
    "end": "849370"
  },
  {
    "text": "that the material that we're showing you is relevant for instance in Korea they have very different gaming laws than we",
    "start": "849370",
    "end": "856060"
  },
  {
    "text": "do here it's actually very serious if there are certain actions that if we do",
    "start": "856060",
    "end": "861430"
  },
  {
    "text": "not withhold they will have the equivalent of a SWAT team actually raid the Korean office and take the head of",
    "start": "861430",
    "end": "867580"
  },
  {
    "text": "the company there in Korea to jail so it's it's incredibly important that we",
    "start": "867580",
    "end": "872860"
  },
  {
    "text": "really think through how we do this and we want to be fault tolerant and make sure that we can provide a good player experience everybody everywhere and the",
    "start": "872860",
    "end": "881860"
  },
  {
    "text": "for hunt spots you see here are where we have chosen to use AWS regions we have",
    "start": "881860",
    "end": "886870"
  },
  {
    "text": "ap northeast one u.s. East one u.s. west two and EU central one from a data",
    "start": "886870",
    "end": "893230"
  },
  {
    "start": "893000",
    "end": "893000"
  },
  {
    "text": "consistency perspective there's several different methodologies that you can leverage you can look at using a global",
    "start": "893230",
    "end": "898420"
  },
  {
    "text": "writes with a multi master set up this is something that can be really great for us we thought it wasn't going to be",
    "start": "898420",
    "end": "904030"
  },
  {
    "text": "the best idea because if someone modifies their account in one location and then another location we have a split brain event we need to know which",
    "start": "904030",
    "end": "910870"
  },
  {
    "text": "of those account record updates we need to keep how do we merge that data there's also the possibility of a single",
    "start": "910870",
    "end": "917470"
  },
  {
    "text": "write master with replication for us that works pretty well most of the time that you're accessing your player",
    "start": "917470",
    "end": "922630"
  },
  {
    "text": "account you're most likely just logging in or looking at some of the player account data you're not changing your data super frequently so if there's a",
    "start": "922630",
    "end": "929080"
  },
  {
    "text": "little bit of an extra latency hit on the right that you're performing that's not a big deal some other common",
    "start": "929080",
    "end": "934460"
  },
  {
    "text": "strategies are federating are charting your data that one was really easy for us to mark off because that's where",
    "start": "934460",
    "end": "939740"
  },
  {
    "text": "we're coming from with the prior global account service and then finally asking the question of whether or not you",
    "start": "939740",
    "end": "945950"
  },
  {
    "text": "should or should not cache the information that you have caching was a pretty big pain point for us before not",
    "start": "945950",
    "end": "952910"
  },
  {
    "text": "really because the solutions we chose just because we were bad at it to be quite frank when it comes to verifying",
    "start": "952910",
    "end": "961340"
  },
  {
    "start": "960000",
    "end": "960000"
  },
  {
    "text": "the functionality of your service there's several different things you want to keep in mind one of the most",
    "start": "961340",
    "end": "970670"
  },
  {
    "text": "important things you can do is have automated testing frameworks that not only validate the functionality of what",
    "start": "970670",
    "end": "977120"
  },
  {
    "text": "you are building and verify that if I do these things I get this output out but",
    "start": "977120",
    "end": "982670"
  },
  {
    "text": "also validating that what you think is the amount of traffic that you're expecting the amount of throughput",
    "start": "982670",
    "end": "989150"
  },
  {
    "text": "you're expecting your service is actually capable of handling that and then the final thing beyond this slide",
    "start": "989150",
    "end": "994790"
  },
  {
    "text": "is if you're building a global service having global test is incredibly important we could have just tested our",
    "start": "994790",
    "end": "1000490"
  },
  {
    "text": "US East one environment and said yeah it looks great but without actually validating how everything works together",
    "start": "1000490",
    "end": "1006250"
  },
  {
    "text": "and how all the pieces fit together it's incredibly painful if you play League of Legends you might be familiar with this",
    "start": "1006250",
    "end": "1011350"
  },
  {
    "text": "year in a review slide here this was a pretty awesome feature that was built by some of the folks in our data team and",
    "start": "1011350",
    "end": "1018360"
  },
  {
    "text": "effectively what it did is it went through all of your league of Legends data for the prior year and then showed you all the highlights from that year so",
    "start": "1018360",
    "end": "1025360"
  },
  {
    "text": "how many Penta kills you've got how many different ranked games you got what the highest point you were in the season and just showed you all of these really",
    "start": "1025360",
    "end": "1031540"
  },
  {
    "text": "amazing highlights our team had no idea that this service was going to live it",
    "start": "1031540",
    "end": "1036699"
  },
  {
    "text": "was just another day we're hanging out in the office and we suddenly see over a 10x increase in login traffic we",
    "start": "1036700",
    "end": "1044709"
  },
  {
    "text": "panicked we started looking for commonality in some of the the locations that players were coming in from and it",
    "start": "1044709",
    "end": "1050980"
  },
  {
    "text": "was everywhere we we thought we were being hit by like the most distributed crazy DDoS attack that we had ever seen",
    "start": "1050980",
    "end": "1057100"
  },
  {
    "text": "before and we started panicking New Relic was going off pedra duty was going off we had people jumping into our NOC",
    "start": "1057100",
    "end": "1062350"
  },
  {
    "text": "channel saying hey something amazing is happening like the all this traffic you have no idea like oh yeah this team",
    "start": "1062350",
    "end": "1067980"
  },
  {
    "text": "just launched the service so had we known that in advance we would have been able to go through and actually test and",
    "start": "1067980",
    "end": "1074040"
  },
  {
    "text": "validate what that impact would have on us and better prepare for that so it's really critical to not only test your",
    "start": "1074040",
    "end": "1080280"
  },
  {
    "text": "service with what you think your throughput limitations are but talk to other teams that could potentially be delivering using the services that you",
    "start": "1080280",
    "end": "1086490"
  },
  {
    "text": "build and validate what their expectations are as well for last year they changed it to where you didn't",
    "start": "1086490",
    "end": "1092220"
  },
  {
    "text": "actually have to log in and you could just look up your summoner name and get all of that data which made it's so much better so enter Atlas as an aside I",
    "start": "1092220",
    "end": "1105690"
  },
  {
    "start": "1101000",
    "end": "1101000"
  },
  {
    "text": "really wanted to put my co-workers face up here because this is his baby he started building at about five years ago and got back rendered a lot he told me",
    "start": "1105690",
    "end": "1112440"
  },
  {
    "text": "now so this is a complete overhaul of our started account system this is the",
    "start": "1112440",
    "end": "1118010"
  },
  {
    "text": "homogenous blend of all of our prior player accounts gives us a truly global account system and the most important",
    "start": "1118010",
    "end": "1124200"
  },
  {
    "text": "piece here is that it's completely decoupled from the game platform the prior version gasps was actually",
    "start": "1124200",
    "end": "1130260"
  },
  {
    "text": "co-located in each of the data centers with the game platform in the event that we were doing a maintenance it would be",
    "start": "1130260",
    "end": "1136320"
  },
  {
    "text": "very common for our NOC folks to take the load balancer offline for gas which",
    "start": "1136320",
    "end": "1141780"
  },
  {
    "text": "would then stop you from accessing non game related servers services so again if you wanted to log into the merge",
    "start": "1141780",
    "end": "1147030"
  },
  {
    "text": "store or if you wanted to log into the forums or the boards or just any service that leverage your account you wouldn't",
    "start": "1147030",
    "end": "1152220"
  },
  {
    "text": "be able to so it was really important for us to provide a way that we would be able to give that experience to players",
    "start": "1152220",
    "end": "1158370"
  },
  {
    "text": "and then it's not unknown we're trying to become a multi game company put that",
    "start": "1158370",
    "end": "1163920"
  },
  {
    "text": "Essen Riot Games so in the future ideally our account system would not be tightly coupled with League of Legends",
    "start": "1163920",
    "end": "1169200"
  },
  {
    "text": "and we'd be able to provide that experience to players so I talked a little bit about what I think are some",
    "start": "1169200",
    "end": "1174810"
  },
  {
    "text": "of the really important things when building a global service and now I'm going to talk about how we've managed to implement a global service when it comes",
    "start": "1174810",
    "end": "1181980"
  },
  {
    "start": "1181000",
    "end": "1181000"
  },
  {
    "text": "to infrastructure management we use terraform and the way we use terraform",
    "start": "1181980",
    "end": "1187230"
  },
  {
    "text": "is a little different from how a lot of folks probably do we have this fairly large Ruby wrapper that I inherited",
    "start": "1187230",
    "end": "1193380"
  },
  {
    "text": "there is two primary components we have what's called an environment an environment in this terraform setup",
    "start": "1193380",
    "end": "1200220"
  },
  {
    "text": "is basically all of the ecosystem around ec2 servers so if you're the service you're spinning up needs an s3 bucket if",
    "start": "1200220",
    "end": "1206789"
  },
  {
    "text": "it needs RDS if it needs ElastiCache any of the security groups we actually do include the elastic load balancer on",
    "start": "1206789",
    "end": "1212519"
  },
  {
    "text": "this that's all controlled within that environment we also then have deployers",
    "start": "1212519",
    "end": "1218519"
  },
  {
    "text": "which the deployer is a reference to the application from most of the services we deploy that is seen as to auto scaling",
    "start": "1218519",
    "end": "1226139"
  },
  {
    "text": "groups with two unique launch configurations and then we have a manifest file that drives that with some",
    "start": "1226139",
    "end": "1231389"
  },
  {
    "text": "metadata so that way we can say we want to run this version of this application with this color it's commonly referred",
    "start": "1231389",
    "end": "1237990"
  },
  {
    "text": "to as blue-green deploys or red black deploys just doing rolling deploys with two separate versions enables you to do",
    "start": "1237990",
    "end": "1244049"
  },
  {
    "text": "a canary as well so you can just roll one out and verify functionality we do that for most of our applications the",
    "start": "1244049",
    "end": "1251759"
  },
  {
    "text": "latter half of this talk I'm going to be focusing on a database solution that we've chosen to use and for the database",
    "start": "1251759",
    "end": "1257820"
  },
  {
    "text": "we actually treat it much more like legacy data center infrastructure we provide static instances on these static",
    "start": "1257820",
    "end": "1264570"
  },
  {
    "text": "instances we give them a defined IP address when they start up and then all of these servers whether it be the",
    "start": "1264570",
    "end": "1270240"
  },
  {
    "text": "static instances I just mentioned or our blue-green setup we inject user data to that auto scaling group or the ec2",
    "start": "1270240",
    "end": "1277110"
  },
  {
    "text": "instance directly for the static instances that defines some docker compose files as part of the upstart so that way when this ec2 instance starts",
    "start": "1277110",
    "end": "1284460"
  },
  {
    "text": "up it will actually pull the docker images that it needs start up the service and then register with a load",
    "start": "1284460",
    "end": "1289500"
  },
  {
    "text": "balancer internally right we also have a global configuration service that's built on top of Eureka it's effectively",
    "start": "1289500",
    "end": "1297240"
  },
  {
    "text": "just a large key value store we provide it what we call internally as an RFC 190 scope it's basically a five component",
    "start": "1297240",
    "end": "1302879"
  },
  {
    "text": "descriptive name it says this is for riot regions this is a production environment and this is the team and the",
    "start": "1302879",
    "end": "1308970"
  },
  {
    "text": "application that it runs for our team has built an additional service on top of this so that way instead of just a",
    "start": "1308970",
    "end": "1315899"
  },
  {
    "text": "key value store we can actually store arbitrary data types in there so I mentioned briefly we use a couple",
    "start": "1315899",
    "end": "1321750"
  },
  {
    "text": "commercial off-the-shelf products a lot of times those are pretty hard to tie into whatever bespoke service you want",
    "start": "1321750",
    "end": "1326809"
  },
  {
    "text": "so we have a dynamic configuration tool that actually reads all that configuration will generate templates based on that we",
    "start": "1326809",
    "end": "1336030"
  },
  {
    "text": "defined and the Jinja templates store all of the configuration for what that service is expecting we then have some",
    "start": "1336030",
    "end": "1343230"
  },
  {
    "text": "startup scripts that will sit there and wait for a config manifest and then once all the files exist it starts up the service to avoid any race conditions all",
    "start": "1343230",
    "end": "1350850"
  },
  {
    "text": "of our servers are also fully ansible automated so we use the AWS dynamic",
    "start": "1350850",
    "end": "1356130"
  },
  {
    "text": "inventory API so that way we can tie into all of the different servers that we run for most servers it's basically",
    "start": "1356130",
    "end": "1363180"
  },
  {
    "text": "just getting some stats and additional metrics that we don't have tied into other monitoring but for the databases",
    "start": "1363180",
    "end": "1368309"
  },
  {
    "text": "it's actually critically important to how I manage and maintain those databases I mentioned earlier that we're",
    "start": "1368309",
    "end": "1376920"
  },
  {
    "text": "incredibly lucky and blessed to have this riot direct back-end Network this is a snapshot of all of the dedicated",
    "start": "1376920",
    "end": "1383429"
  },
  {
    "text": "lines that we've purchased so the way this works we appeared with different local internet providers and using BGP",
    "start": "1383429",
    "end": "1391140"
  },
  {
    "text": "routing if you're accessing a league of Legends service we will actually basically take control of your traffic",
    "start": "1391140",
    "end": "1396870"
  },
  {
    "text": "earlier in the process so that way we can make sure that you have a high-speed internet connection back to our services this was really kicked off when",
    "start": "1396870",
    "end": "1404309"
  },
  {
    "text": "different Internet service providers started throttling game traffic without telling their consumers we also use this",
    "start": "1404309",
    "end": "1411059"
  },
  {
    "text": "to tie into each of the different AWS regions and our physical data centers to make sure that we have low latency",
    "start": "1411059",
    "end": "1416160"
  },
  {
    "text": "access worldwide and that it's all over our own protected back-end Network we",
    "start": "1416160",
    "end": "1421440"
  },
  {
    "text": "leverage AWS Direct Connect for that we use multiple lines so that way it's all tied in and we can we have some fault",
    "start": "1421440",
    "end": "1427830"
  },
  {
    "text": "tolerance if we need to do any maintenance and fully redundant links that ties into the four different AWS",
    "start": "1427830",
    "end": "1433320"
  },
  {
    "text": "regions that we have ap northeast one u.s. East one u.s. west to India central one and then we provide low latency",
    "start": "1433320",
    "end": "1439410"
  },
  {
    "text": "worldwide access using NS 1 the NS 1 setup uses a filter system so we use the",
    "start": "1439410",
    "end": "1445679"
  },
  {
    "text": "DNS name of off Gamescom that sent a CloudFlare you we then do the cloud",
    "start": "1445679",
    "end": "1451230"
  },
  {
    "text": "player DDoS mitigation and then it's sent to a back-end author right at Gamescom endpoint and that's only",
    "start": "1451230",
    "end": "1456720"
  },
  {
    "text": "accessible via CloudFlare and from there we look at the topologically closest",
    "start": "1456720",
    "end": "1461910"
  },
  {
    "text": "location to where that DNS lookup happen we sort the results based on that we then validate whether or not according",
    "start": "1461910",
    "end": "1468620"
  },
  {
    "text": "to what we have told that is one that service is up and then after that we filter down the result of just one we",
    "start": "1468620",
    "end": "1474320"
  },
  {
    "text": "only ever want to route you to the closest cluster so it doesn't really make sense for us to return all of them in a future world a really awesome",
    "start": "1474320",
    "end": "1480890"
  },
  {
    "text": "filter that we'd like to add is something called shedload I mentioned earlier that your authorization session is tied to the AWS region that you log",
    "start": "1480890",
    "end": "1487550"
  },
  {
    "text": "into so if we started setting load effectively you would just be sent to another cluster and then the router",
    "start": "1487550",
    "end": "1492740"
  },
  {
    "text": "service would write you back to the other cluster which I don't think would probably make sense for us for a",
    "start": "1492740",
    "end": "1499190"
  },
  {
    "text": "consistency perspective we use that front-end service router the way it works is you authenticate your",
    "start": "1499190",
    "end": "1504410"
  },
  {
    "text": "authentication you get what we call a riot sign-on token inside the riot sign-on token there's an access token",
    "start": "1504410",
    "end": "1510170"
  },
  {
    "text": "and a refresh token your access token is self self signing last for about 10",
    "start": "1510170",
    "end": "1516290"
  },
  {
    "text": "minutes and the Refresh token is what you use to actually get a new access token when that expires we modify the",
    "start": "1516290",
    "end": "1522740"
  },
  {
    "text": "act or the refresh token to prepend a region code and then we know which router to send you to in the event that",
    "start": "1522740",
    "end": "1528950"
  },
  {
    "text": "you need it real we've actually piloted global dynamodb tables when we set this",
    "start": "1528950",
    "end": "1534440"
  },
  {
    "text": "up for our arena partner it seems to be working really well so in the future that's something that we hope to adopt",
    "start": "1534440",
    "end": "1539930"
  },
  {
    "text": "for all of our riot regions as well so that way when you authenticate we actually do have global the authentication our globally available",
    "start": "1539930",
    "end": "1545540"
  },
  {
    "text": "authentication and authorization sessions for all of the players that access the service that would then enable us to use that loadshedding",
    "start": "1545540",
    "end": "1551240"
  },
  {
    "text": "functionality I mentioned briefly verification of load this is a new relic",
    "start": "1551240",
    "end": "1558920"
  },
  {
    "start": "1554000",
    "end": "1554000"
  },
  {
    "text": "graph that shows one of our load tests after a lot of tuning back and forth we",
    "start": "1558920",
    "end": "1565310"
  },
  {
    "text": "use a load testing tool at riot called Gatling and Gatling you define different Scala scenarios the scenarios should",
    "start": "1565310",
    "end": "1570830"
  },
  {
    "text": "ideally map out to what your expected use case is before this I did fairly",
    "start": "1570830",
    "end": "1576320"
  },
  {
    "text": "extensive bench testing of our back-end database and we found out that all of",
    "start": "1576320",
    "end": "1583280"
  },
  {
    "text": "the load that we're setting should be well within what we expected to send to these servers I then spoke with some of",
    "start": "1583280",
    "end": "1590600"
  },
  {
    "text": "our other application engineers talked to them about doing some actual application load testing they started building out some use case scenarios",
    "start": "1590600",
    "end": "1597750"
  },
  {
    "text": "they ran a load test the database crashed I thought I did sis bench pretty",
    "start": "1597750",
    "end": "1606030"
  },
  {
    "text": "well but it made me question myself a little bit and we went back and I asked did we double check the numbers are we",
    "start": "1606030",
    "end": "1612600"
  },
  {
    "text": "sure this looks right it seems high I'm looking at these graphs it seems high and I got a very reassuring oh no no we",
    "start": "1612600",
    "end": "1618990"
  },
  {
    "text": "we did the napkin math that's fine so they ran the load test again the database crashed I went back and I said",
    "start": "1618990",
    "end": "1625890"
  },
  {
    "text": "please let's do a napkin math one more time we found out we were sending about two orders of magnitude more right",
    "start": "1625890",
    "end": "1632670"
  },
  {
    "text": "traffic than was intended and after doing napkin math a third time we were",
    "start": "1632670",
    "end": "1638070"
  },
  {
    "text": "able to get this year where you can see relatively low database latency because it's accessing a local database a little",
    "start": "1638070",
    "end": "1644670"
  },
  {
    "text": "bit of time in the JVM but all of these are responding in less than 20 milliseconds for doing player authentication player account",
    "start": "1644670",
    "end": "1649920"
  },
  {
    "text": "modifications and player lookups once you have successful load testing I'm a",
    "start": "1649920",
    "end": "1655890"
  },
  {
    "text": "huge fan of chaos testing or fault injection testing it's critically important though that when you're doing",
    "start": "1655890",
    "end": "1661530"
  },
  {
    "text": "this you do it after you have a success a successful load test cuz if you do it beforehand you don't know like if you're messing yourself up or your service",
    "start": "1661530",
    "end": "1667500"
  },
  {
    "text": "can't handle the load so some of the things that we did was randomly restarting different agency two",
    "start": "1667500",
    "end": "1672900"
  },
  {
    "text": "instances intentionally killing MySQL processes stopping services starting services restarting instances adding and",
    "start": "1672900",
    "end": "1679830"
  },
  {
    "text": "deleting Network security group rules so that way we can simulate what a network failure would look like long term of",
    "start": "1679830",
    "end": "1685680"
  },
  {
    "text": "this would be building solutions that actually tie into an automated ecosystem where you can have this validation done",
    "start": "1685680",
    "end": "1691350"
  },
  {
    "text": "for you automatically there are several of companies out there that do this really well highly recommend looking into that if that's",
    "start": "1691350",
    "end": "1697200"
  },
  {
    "text": "something you're interested in some of you might be sitting here wondering well this is cool but why are you using MySQL",
    "start": "1697200",
    "end": "1703740"
  },
  {
    "text": "there's so many other technologies out there that would probably be better honestly there's two main reasons reason",
    "start": "1703740",
    "end": "1710010"
  },
  {
    "text": "number one there's a lot of people at riot that use MySQL so if I do something dumb someone else could probably help me",
    "start": "1710010",
    "end": "1715200"
  },
  {
    "text": "fix it number two we are owned by ten cent ten cent is our parent company and they have a very strong adoption and",
    "start": "1715200",
    "end": "1721890"
  },
  {
    "text": "acceptance of using MySQL so if we tried to force another technology on them it would probably slow down the development and then we have to fight to make sure",
    "start": "1721890",
    "end": "1728850"
  },
  {
    "text": "that that is something that actually makes sense and nots that we're using just because it's a hot nerd technology and finally since we're",
    "start": "1728850",
    "end": "1735610"
  },
  {
    "text": "storing player account records having full asset compliance if you're not familiar with us and compliance that's having fully atomic operations having",
    "start": "1735610",
    "end": "1742360"
  },
  {
    "text": "consistency of your database isolation of the database queries and durability of transactions is incredibly important",
    "start": "1742360",
    "end": "1748600"
  },
  {
    "text": "I talked earlier about not wanting split brain events if I have to manage those manually that would be very painful having to choose of what player data to",
    "start": "1748600",
    "end": "1755049"
  },
  {
    "text": "keep so for our database solution we chose to go with a third party vendor service called continuant database",
    "start": "1755049",
    "end": "1761830"
  },
  {
    "start": "1761000",
    "end": "1761000"
  },
  {
    "text": "clustering continue and database clustering is made up of three primary constructs the constructs I'm gonna",
    "start": "1761830",
    "end": "1768309"
  },
  {
    "text": "start from the bottom and work my way up the first is a replicator the way the replicator works MySQL is not actually",
    "start": "1768309",
    "end": "1774460"
  },
  {
    "text": "configured for any replication at all it doesn't know that it's clustered it doesn't know that there's any other my sequel servers out there it's just a",
    "start": "1774460",
    "end": "1780940"
  },
  {
    "text": "standalone MySQL server the replicator reads the MySQL binary log and converts",
    "start": "1780940",
    "end": "1786100"
  },
  {
    "text": "it to what's called THL or the transaction history log this log is then flushed to the disk before it is then",
    "start": "1786100",
    "end": "1791769"
  },
  {
    "text": "replicated to the other servers in the cluster this is done intentionally to make sure that you have the durability",
    "start": "1791769",
    "end": "1797019"
  },
  {
    "text": "that is provided by the binary log in THL once the primary server has",
    "start": "1797019",
    "end": "1802359"
  },
  {
    "text": "replicated this over to the other two secondaries these secondaries will receive that added to a queue and then",
    "start": "1802359",
    "end": "1808659"
  },
  {
    "text": "flush it to disk as well so that way if something happens in the middle of applying that transaction to the database you have a point that you can",
    "start": "1808659",
    "end": "1814179"
  },
  {
    "text": "recover from the next component is the manager the manager has two primary",
    "start": "1814179",
    "end": "1820299"
  },
  {
    "text": "pieces the first is being the cluster Orchestrator and Quora manager uses J",
    "start": "1820299",
    "end": "1826149"
  },
  {
    "text": "groups behind the scenes to establish a quorum between all of the different managers that are running get the",
    "start": "1826149",
    "end": "1831970"
  },
  {
    "text": "general health and well-being of all those services and then provides an API that gives you health and metadata about",
    "start": "1831970",
    "end": "1837100"
  },
  {
    "text": "which servers the primary which ones are secondaries which ones are supposed to be doing replication and then the second",
    "start": "1837100",
    "end": "1843159"
  },
  {
    "text": "component is the wrapper service the wrapper is literally just a wrapper around the manager that monitors the",
    "start": "1843159",
    "end": "1848769"
  },
  {
    "text": "health and well-being of the managers so we can restart manager processes in the event that there's an issue the final",
    "start": "1848769",
    "end": "1854919"
  },
  {
    "text": "component is a connector the connector talks to the manager API to determine",
    "start": "1854919",
    "end": "1860139"
  },
  {
    "text": "which server it should route MySQL requests to in the way that we have it set up we",
    "start": "1860139",
    "end": "1865270"
  },
  {
    "text": "have full control over our applications so we can use read and write splitting based on ports so we send all right requests you port 3306 that's routed to",
    "start": "1865270",
    "end": "1872500"
  },
  {
    "text": "the primary server we send all reads to 3307 and that will be routed to whatever server is the most up-to-date with the",
    "start": "1872500",
    "end": "1878590"
  },
  {
    "text": "right master once that's done you're able to access all the data however you need in any",
    "start": "1878590",
    "end": "1884890"
  },
  {
    "text": "other region there's one other way that the connector can be ran and that is actually with an inspection mode we run",
    "start": "1884890",
    "end": "1890559"
  },
  {
    "text": "it and what's called a bridge proxy mode the inspection mode will actually analyze the MySQL query that you're",
    "start": "1890559",
    "end": "1895720"
  },
  {
    "text": "sending to it and then using JDBC rebuild that query potentially do optimizations and then send it to the appropriate back-end that's really great",
    "start": "1895720",
    "end": "1902559"
  },
  {
    "text": "for if you don't have control over doing read/write splitting but we prefer the lower latency approach of being able to split it ourselves",
    "start": "1902559",
    "end": "1909840"
  },
  {
    "text": "I've spoken briefly about having four different AWS regions that we run this in when we first started this project us",
    "start": "1916020",
    "end": "1923980"
  },
  {
    "text": "two was the hub of all of the riot direct networks so if we had traffic that was going from us West to to Europe",
    "start": "1923980",
    "end": "1930310"
  },
  {
    "text": "or us East to Europe both of those ended up actually routing back to the US was to this made it really easy for us to",
    "start": "1930310",
    "end": "1936880"
  },
  {
    "text": "decide to put the primary database source in u.s. West to you as it's a central hub then the way the replicator",
    "start": "1936880",
    "end": "1943540"
  },
  {
    "text": "works in this scenario since we have four different AWS regions you'll notice that there are three relays up there one",
    "start": "1943540",
    "end": "1948820"
  },
  {
    "text": "in each region that's not us - it's basically a hierarchical model that the",
    "start": "1948820",
    "end": "1954250"
  },
  {
    "text": "relay will talk to that primary server in u.s. - it will get all the THL make sure that it's properly added to the",
    "start": "1954250",
    "end": "1960490"
  },
  {
    "text": "queue flush to disk and then replicate it to the local secondaries that are there in that region this provides us a",
    "start": "1960490",
    "end": "1966190"
  },
  {
    "text": "global consistency model that doesn't add too much strain just to that one primary server and make sure that we can",
    "start": "1966190",
    "end": "1971800"
  },
  {
    "text": "replicate all of that data worldwide we chose this instance type here as an R",
    "start": "1971800",
    "end": "1977350"
  },
  {
    "text": "480 X large reason being it's a good amount of memory relatively high CPU most important reason 10 gigabit per",
    "start": "1977350",
    "end": "1984520"
  },
  {
    "text": "second networking we wanted to make sure that whenever players modified their accounts we'd be able to really quickly",
    "start": "1984520",
    "end": "1990190"
  },
  {
    "text": "replicate that over to another environment we also knew that we had several hundred gigabytes of player data that we were going to have to migrate",
    "start": "1990190",
    "end": "1996310"
  },
  {
    "text": "into this so thinking forward we wanted to make sure that when we imported all this data we'd be able to make sure that",
    "start": "1996310",
    "end": "2001350"
  },
  {
    "text": "it got everywhere quickly we use a five terabyte SSD or GB to EBS volume for the",
    "start": "2001350",
    "end": "2007560"
  },
  {
    "text": "data volume that is where all the MySQL data and the general continuing times and clustering suite software goes and",
    "start": "2007560",
    "end": "2013980"
  },
  {
    "text": "then we have a 15 terabyte a BS volume that's leveraged for database backups the THL logs and the my sequel binary",
    "start": "2013980",
    "end": "2021420"
  },
  {
    "text": "longs we also have a couple additional helper scripts that we wrote since we",
    "start": "2021420",
    "end": "2026970"
  },
  {
    "text": "treat this kind of like standard data center infrastructure we know they have static IP pees we wrote some Apple Oso",
    "start": "2026970",
    "end": "2032190"
  },
  {
    "text": "scripts so that way we'd be able to just run some simple commands and ssh into all them at once do some triage if we needed and we also have a good amount of",
    "start": "2032190",
    "end": "2038610"
  },
  {
    "text": "ansible automation that we've leveraged here the ansible automation that we use has three primary playbooks and they all",
    "start": "2038610",
    "end": "2045150"
  },
  {
    "start": "2042000",
    "end": "2042000"
  },
  {
    "text": "build off of each other the first one is a general health check which is what you're seeing here I",
    "start": "2045150",
    "end": "2050340"
  },
  {
    "text": "wanted to do the other two ones but they ran about eight minutes and I figured staring at one slide for eight minutes might be a little long so the health",
    "start": "2050340",
    "end": "2057540"
  },
  {
    "text": "check logs into each of the database servers hits the local API takes all of that data and stores it in a dictionary",
    "start": "2057540",
    "end": "2063690"
  },
  {
    "text": "and ansible and then validates that the health of a service looks good and is what it should be and then as long as",
    "start": "2063690",
    "end": "2070590"
  },
  {
    "text": "nothing fails you'll see a bunch of skipped that means we looked at the data it says it's online it says it's healthy",
    "start": "2070590",
    "end": "2075929"
  },
  {
    "text": "it looks good the second playbook runs are rolling restart I mentioned earlier that we use",
    "start": "2075929",
    "end": "2081570"
  },
  {
    "text": "user data to inject docker compose files we had decided that storing MySQL the",
    "start": "2081570",
    "end": "2087330"
  },
  {
    "text": "tungsten clustering suite our configuration and our logging sidecars as docker containers was going to be",
    "start": "2087330",
    "end": "2093120"
  },
  {
    "text": "something that we wanted to do so it would be consistent with everything else that we deployed the way that that user",
    "start": "2093120",
    "end": "2098370"
  },
  {
    "text": "data works is it writes into an upstart script if we're using Ubuntu upstart will only reload the configuration file",
    "start": "2098370",
    "end": "2104490"
  },
  {
    "text": "if you completely stop the service and then start the service again which means that we actually have to fully stop the",
    "start": "2104490",
    "end": "2110430"
  },
  {
    "text": "docker compose which means we're bringing down MySQL and the for clustering suite once we've done that we",
    "start": "2110430",
    "end": "2115560"
  },
  {
    "text": "can start it back up so the first thing we do is we do this health check and then if everything looks good we go one",
    "start": "2115560",
    "end": "2121080"
  },
  {
    "text": "server at a time go through every server that's not the current primary and then once we've done all of the other servers",
    "start": "2121080",
    "end": "2126990"
  },
  {
    "text": "remover started those services will then attach to the primary and then update do",
    "start": "2126990",
    "end": "2132660"
  },
  {
    "text": "what's called a cluster switch and that will automatically elect a new primary server within the local service cluster",
    "start": "2132660",
    "end": "2138930"
  },
  {
    "text": "it takes about a minute for it to complete with a 12 node culture that we have so the way that works is it drains",
    "start": "2138930",
    "end": "2145080"
  },
  {
    "text": "all of the existing MySQL connections shuts down the service shuts down the replicator flushes everything make sure",
    "start": "2145080",
    "end": "2150480"
  },
  {
    "text": "that there's another server that's completely up to date promotes that to be the new primary validates that all of",
    "start": "2150480",
    "end": "2155760"
  },
  {
    "text": "the other servers in the cluster agree with that and establish that quorum and then once that's done bring that server",
    "start": "2155760",
    "end": "2162720"
  },
  {
    "text": "back online as a secondary that secondary is then restarted the final playbook we have I mentioned we use",
    "start": "2162720",
    "end": "2169020"
  },
  {
    "text": "docker since we use docker we can just update version numbers we will update the upstart script behind the scenes to",
    "start": "2169020",
    "end": "2175920"
  },
  {
    "text": "write a new docker compose file with the latest version of our docker container we also pre pull that docker container",
    "start": "2175920",
    "end": "2181170"
  },
  {
    "text": "to make sure that we have latest version that we're anticipating and then we will do this rolling restart by starting all of that with the new",
    "start": "2181170",
    "end": "2187910"
  },
  {
    "text": "servers we knew that we needed to modify",
    "start": "2187910",
    "end": "2193910"
  },
  {
    "start": "2191000",
    "end": "2191000"
  },
  {
    "text": "the way we stored our player data and we needed a new schema so as part of this when we migrated from the legacy gas",
    "start": "2193910",
    "end": "2200690"
  },
  {
    "text": "databases to the new infrastructure we copied all of that data into a temporary database where we we were able to",
    "start": "2200690",
    "end": "2206360"
  },
  {
    "text": "perform modifications of that data and then we imported that into our database we then wrote daily Delta update scripts",
    "start": "2206360",
    "end": "2213740"
  },
  {
    "text": "which would grab any record that had been modified within the past 24 hours dump that into a MySQL file and then",
    "start": "2213740",
    "end": "2221270"
  },
  {
    "text": "import and that import that into the destination database we also knew that the database schema that we were going",
    "start": "2221270",
    "end": "2226640"
  },
  {
    "text": "with wasn't going to be final you'll notice I'm going to share a couple embarrassing stories this one is",
    "start": "2226640",
    "end": "2231680"
  },
  {
    "text": "definitely one of them when we migrated from the legacy MySQL to the new MySQL",
    "start": "2231680",
    "end": "2236810"
  },
  {
    "text": "we had an ID column and that was an auto increment ID this auto increment ID was",
    "start": "2236810",
    "end": "2242780"
  },
  {
    "text": "for the 10 to spare database clusters so in the haste of making sure that we did this for gdpr we introduced a primary",
    "start": "2242780",
    "end": "2249920"
  },
  {
    "text": "underscore ID column now that might be a little confusing if it's not it was",
    "start": "2249920",
    "end": "2255350"
  },
  {
    "text": "really confusing to us we did one of the the parts of gdpr is having the right to",
    "start": "2255350",
    "end": "2260810"
  },
  {
    "text": "be forgotten which means you can tell a company you have to delete my data so we",
    "start": "2260810",
    "end": "2266750"
  },
  {
    "text": "did that and as part of that we would mark accounts as ready to be forgotten",
    "start": "2266750",
    "end": "2271910"
  },
  {
    "text": "and we did my SQL queries using the ID column and we had several engineers",
    "start": "2271910",
    "end": "2278450"
  },
  {
    "text": "myself included look over this and say yeah it looks great right after executing the query we started getting",
    "start": "2278450",
    "end": "2284780"
  },
  {
    "text": "some notifications like hey we have players saying that they can no longer log into their account it was great so",
    "start": "2284780",
    "end": "2292730"
  },
  {
    "text": "we had to go and look at prior audit logs to see which accounts were actually intended to be marked as forgotten which",
    "start": "2292730",
    "end": "2299180"
  },
  {
    "text": "ones we needed to restore back to prior service and make sure that we were able to get back to a known good stay for all",
    "start": "2299180",
    "end": "2305000"
  },
  {
    "text": "of those players that being said this scheme is not final we're not adding a primary estai D or anything crazy",
    "start": "2305000",
    "end": "2310730"
  },
  {
    "text": "I recommend really considering the schema that you're using which this kind of leads us into why",
    "start": "2310730",
    "end": "2316540"
  },
  {
    "text": "didn't we just restore from backups so our initial backup process I decided we",
    "start": "2316540",
    "end": "2322089"
  },
  {
    "start": "2319000",
    "end": "2319000"
  },
  {
    "text": "have four different AWS regions it would make sense to have a local backup this is a lot of data every single AWS region",
    "start": "2322089",
    "end": "2327460"
  },
  {
    "text": "can just perform their own backup and then push that to s3 if we need to restore we can pull locally it'll be great",
    "start": "2327460",
    "end": "2332589"
  },
  {
    "text": "it was the process started out basically where there was a cron job that would",
    "start": "2332589",
    "end": "2337780"
  },
  {
    "text": "kick off it would talk to the local API determine which of the servers in that cluster were considered to be the",
    "start": "2337780",
    "end": "2344050"
  },
  {
    "text": "coordinator which is just a loose concept that says like I helped make the quorum decisions within this local cluster as long as it was the",
    "start": "2344050",
    "end": "2350980"
  },
  {
    "text": "coordinator it would then go through a backup server election process this just looked like saying are you a relay or",
    "start": "2350980",
    "end": "2357099"
  },
  {
    "text": "are you the primary if so from any of you and then it would elect one of the other two that were a secondary in that",
    "start": "2357099",
    "end": "2362349"
  },
  {
    "text": "local cluster to perform the backup this would kick off the extra backup process which takes all of the data from that",
    "start": "2362349",
    "end": "2368349"
  },
  {
    "text": "data volume and moves it over to the logs volume we would then compress that with something that's called pigs which",
    "start": "2368349",
    "end": "2373930"
  },
  {
    "text": "is just a parallel gzip we told it to use eight CPU cores we had ton of CPU available we had a lot of RAM available",
    "start": "2373930",
    "end": "2380020"
  },
  {
    "text": "everything looks fine and then after the backup was encrypted or compressed we",
    "start": "2380020",
    "end": "2385240"
  },
  {
    "text": "would push it to s3 this process would take about five to eight hours we cut everything over everything I look great",
    "start": "2385240",
    "end": "2391660"
  },
  {
    "text": "it worked for several weeks two weeks after doing this however we started",
    "start": "2391660",
    "end": "2399099"
  },
  {
    "start": "2395000",
    "end": "2395000"
  },
  {
    "text": "having these really weird cluster flapping issues and we had no idea what was going on it would happen roughly at",
    "start": "2399099",
    "end": "2404470"
  },
  {
    "text": "the same time every day conveniently during the backup process but not like",
    "start": "2404470",
    "end": "2409750"
  },
  {
    "text": "right when the compression started or when the compression was ending or when we were copying files it was some arbitrary amount of time that was kind",
    "start": "2409750",
    "end": "2417549"
  },
  {
    "text": "of indeterminant after the back of the surgeon we had several back-and-forth",
    "start": "2417549",
    "end": "2422619"
  },
  {
    "text": "conversations with the vendor trying to figure out if we were doing something wrong if something changed like why is",
    "start": "2422619",
    "end": "2428200"
  },
  {
    "text": "this happening we found out that one of the the rapper process around the manager was being starved for resources",
    "start": "2428200",
    "end": "2434500"
  },
  {
    "text": "which were dissolved in it failing to communicate with the JVM manager that manager process would then be seen as",
    "start": "2434500",
    "end": "2440920"
  },
  {
    "text": "dead it would be killed and then restarted that happening in rapid",
    "start": "2440920",
    "end": "2445930"
  },
  {
    "text": "succession resulted in other ones saying I'm seeing this really weird flapping I think something might be wrong I'm just",
    "start": "2445930",
    "end": "2451300"
  },
  {
    "text": "gonna go ahead and restore myself as well then we saw everything just our flapping sometimes this would recover",
    "start": "2451300",
    "end": "2458110"
  },
  {
    "text": "and everything would go back to normal after we panicked for a couple minutes we'd dig through logs and see we don't",
    "start": "2458110",
    "end": "2463300"
  },
  {
    "text": "really know what's going on other times though this would result in about 30 to 45 minutes where players were not able",
    "start": "2463300",
    "end": "2469030"
  },
  {
    "text": "to modify their accounts which to us was not acceptable so the way that this kind",
    "start": "2469030",
    "end": "2475840"
  },
  {
    "text": "of portrayed itself is we had fairly high disk i/o when we were copying from",
    "start": "2475840",
    "end": "2482950"
  },
  {
    "text": "the data volume to the logs volume then we would see really high CPU utilization when doing the compression then we'd see",
    "start": "2482950",
    "end": "2490090"
  },
  {
    "text": "really high network through Pokemon pushing to s3 none of those really seemed like they would have a big impact",
    "start": "2490090",
    "end": "2495160"
  },
  {
    "text": "on the surface which you can see on this slide we only got to about 35% CPU",
    "start": "2495160",
    "end": "2501970"
  },
  {
    "text": "utilization which means there's a lot of room so to make this better we decided",
    "start": "2501970",
    "end": "2508600"
  },
  {
    "start": "2508000",
    "end": "2508000"
  },
  {
    "text": "to just do a backup in a single region we chose the cluster that's getting the least amount of traffic right now",
    "start": "2508600",
    "end": "2514180"
  },
  {
    "text": "that's our us ds1 cluster we would do the backup on that location everything was fine every now and then one of the",
    "start": "2514180",
    "end": "2520300"
  },
  {
    "text": "manager services might restart but all of the other back-end services continue to function and it's still seen as an",
    "start": "2520300",
    "end": "2525640"
  },
  {
    "text": "eligible member in that cluster and then when it comes back online everything is an unknown good statement the long-term",
    "start": "2525640",
    "end": "2532420"
  },
  {
    "text": "which we're in the middle of right now is adding a standalone tungsten replicator service this is effectively",
    "start": "2532420",
    "end": "2538240"
  },
  {
    "text": "another server that you just dangle off of the database cluster and it has no impact on the cluster whatsoever it just",
    "start": "2538240",
    "end": "2543820"
  },
  {
    "text": "is set up as another replicator that pulls that data to itself and it doesn't receive any of the database queries one",
    "start": "2543820",
    "end": "2550390"
  },
  {
    "text": "of the other really nice things about this is you can actually set up intentional delays we're planning on probably putting in about an hour delays",
    "start": "2550390",
    "end": "2556450"
  },
  {
    "text": "that way if we do a little mess up again around primary ID verses ID we can just",
    "start": "2556450",
    "end": "2561580"
  },
  {
    "text": "go back and look at what the data was an hour ago instead of having to cull through several event logs and trying to figure out what needs to be rectified",
    "start": "2561580",
    "end": "2567660"
  },
  {
    "text": "and this here is a graph showing the back of an Us East one where you can see the elevated CPU the elevated disk read",
    "start": "2567660",
    "end": "2573970"
  },
  {
    "text": "and write I OPS's it's moving from one EBS volume to another and then the elevated network throughput along the",
    "start": "2573970",
    "end": "2580810"
  },
  {
    "text": "way we we hit a lot of bumps and we learned a lot of things one of the first things",
    "start": "2580810",
    "end": "2585970"
  },
  {
    "text": "was that the monitoring that was provided by the vendor tied into several different services but nothing that we",
    "start": "2585970",
    "end": "2591400"
  },
  {
    "text": "used so we needed to build something that would tie into our monitoring service and be able to provide us visibility into what we wanted to do I",
    "start": "2591400",
    "end": "2597630"
  },
  {
    "text": "mentioned earlier how we would remove servers for Oh actually I didn't mention this one of the other features that we",
    "start": "2597630",
    "end": "2603490"
  },
  {
    "text": "have is we can do online schema migrations with this database cluster the way that works is we pull one server",
    "start": "2603490",
    "end": "2608859"
  },
  {
    "text": "out of the rotation that is not a primary we tell the replicator to go offline and then after we've shut off",
    "start": "2608859",
    "end": "2614710"
  },
  {
    "text": "the replicator we can do a schema upgrade on that because we just do a MySQL query to add an index or modify a",
    "start": "2614710",
    "end": "2620830"
  },
  {
    "text": "column the most important thing is that this query or this modification has to be backwards compatible once we've done",
    "start": "2620830",
    "end": "2626589"
  },
  {
    "text": "it on that server we can bring it online and it back to the cluster go through the remaining servers up until you hit",
    "start": "2626589",
    "end": "2631900"
  },
  {
    "text": "the primary server and then you do the same cluster switch I mentioned earlier which promotes a new primary and then",
    "start": "2631900",
    "end": "2637690"
  },
  {
    "text": "you will do the schema migration on whatever the primary or the former primary was so that way you have a",
    "start": "2637690",
    "end": "2644200"
  },
  {
    "text": "consistent world where all of them are up-to-date we've done this a couple times this is actually the bottom of",
    "start": "2644200",
    "end": "2650859"
  },
  {
    "text": "three shows the approximate latency this is after we did a massive modification",
    "start": "2650859",
    "end": "2655869"
  },
  {
    "text": "of the schema and you can see the cluster catching back up with replication after we brought that server back-end the center row there shows a",
    "start": "2655869",
    "end": "2662530"
  },
  {
    "text": "little bit of information about what level of traffic we're seeing on the database the approximate increase in",
    "start": "2662530",
    "end": "2668200"
  },
  {
    "text": "writes and the number of connections to that database we also have some general",
    "start": "2668200",
    "end": "2673750"
  },
  {
    "text": "monitoring around the state of the cluster showing the health of the manager service whether or not the data server is online and the replicators",
    "start": "2673750",
    "end": "2678849"
  },
  {
    "text": "online there's also several different pros and cons of container izing or",
    "start": "2678849",
    "end": "2685540"
  },
  {
    "text": "database one of the great things is that it kind of gives you this immutable infrastructure so you have this idea of I built this exact artifact this is the",
    "start": "2685540",
    "end": "2693250"
  },
  {
    "text": "artifact that's deployed we're relatively close to that with the exception of our dynamic configuration",
    "start": "2693250",
    "end": "2699040"
  },
  {
    "text": "service that dynamic configuration service renders a configuration template and puts it inside that container so",
    "start": "2699040",
    "end": "2705130"
  },
  {
    "text": "from that perspective that is dynamic and will change so it's not fully immutable another potential Pro is that if we",
    "start": "2705130",
    "end": "2711369"
  },
  {
    "text": "decided to we would be able to take this and push it into a port scheduled in environments such as maysa",
    "start": "2711369",
    "end": "2716460"
  },
  {
    "text": "or kubernetes or ETS eks etc one of the",
    "start": "2716460",
    "end": "2721950"
  },
  {
    "text": "downsides that I mentioned briefly is that doing these types of database modifications or rolling restarts by",
    "start": "2721950",
    "end": "2728160"
  },
  {
    "text": "having a containerized it requires a full restart of that database which does result in impact to players which is not",
    "start": "2728160",
    "end": "2733890"
  },
  {
    "text": "ideal for us from a design perspective one of the most important things for a",
    "start": "2733890",
    "end": "2739500"
  },
  {
    "text": "global service that you can do is kind of document draw your design and implementation and communicate that with other engineers by writing this down and",
    "start": "2739500",
    "end": "2746520"
  },
  {
    "text": "providing actual documentation and images of what you're trying to achieve you set yourself up in a situation where",
    "start": "2746520",
    "end": "2752280"
  },
  {
    "text": "people can actually see and understand what you're intending to do and you'll a lot of times finding potential flaws that you would have otherwise not",
    "start": "2752280",
    "end": "2758100"
  },
  {
    "text": "noticed but on those lines avoid the ivory tower approach if you're not familiar with the ivory tower approach",
    "start": "2758100",
    "end": "2764370"
  },
  {
    "text": "so where you sit down and you build this design and you keep iterating on it and iterating on it and you try and come up with what the perfect thing is the most",
    "start": "2764370",
    "end": "2771720"
  },
  {
    "text": "important thing you can do is align around a concept and then just do it if",
    "start": "2771720",
    "end": "2777990"
  },
  {
    "text": "you wait and try and find the perfect design you're going to find yourself in a situation where what you build might",
    "start": "2777990",
    "end": "2783060"
  },
  {
    "text": "not actually be what you're trying to get for whatever it is your players or whoever is going to be leveraging your",
    "start": "2783060",
    "end": "2788160"
  },
  {
    "text": "service when building your VPC please",
    "start": "2788160",
    "end": "2793530"
  },
  {
    "text": "consider your subnets carefully don't you it I did I was asked to set up another V PC when we're initially",
    "start": "2793530",
    "end": "2800070"
  },
  {
    "text": "standing all of this environment up I made the subnets way too small and then we ran out of IP space which is",
    "start": "2800070",
    "end": "2806460"
  },
  {
    "text": "incredibly painful moving subnets around is difficult you have to shut everything",
    "start": "2806460",
    "end": "2811830"
  },
  {
    "text": "down and delete everything in it free up all of those IDs delete the subnet and then recreate it so really when you're",
    "start": "2811830",
    "end": "2818010"
  },
  {
    "text": "doing your design in your documentation if you are building a new V PC consider what you're doing in some cases it might",
    "start": "2818010",
    "end": "2824010"
  },
  {
    "text": "make sense to have per application or per instance type security groups and subnets this allows you to if you have",
    "start": "2824010",
    "end": "2830340"
  },
  {
    "text": "cross regional things just white less those if you only have 280 of a s regions you can use V PC peering and",
    "start": "2830340",
    "end": "2836130"
  },
  {
    "text": "that way you can actually cross-reference the security groups in different regions otherwise if it's all but on back-end IP space having a subnet",
    "start": "2836130",
    "end": "2843540"
  },
  {
    "text": "that has a defined IP it makes it a little bit easier to whitelist across some notes along those",
    "start": "2843540",
    "end": "2848549"
  },
  {
    "text": "lines evaluate the security group and networking constraints that you're going to have we run this in four different regions using Direct Connect all of that",
    "start": "2848549",
    "end": "2854699"
  },
  {
    "text": "is over a 10/8 network this enables us to whitelist different IPS but since we don't have per application security",
    "start": "2854699",
    "end": "2861119"
  },
  {
    "text": "groups we have to come up with crafty ways to make sure that what we're whitelisting across those regions is actually what needs to be whitelisting",
    "start": "2861119",
    "end": "2870019"
  },
  {
    "text": "when building services understanding what it's actually doing is critically important it works well for your auto",
    "start": "2870019",
    "end": "2876900"
  },
  {
    "text": "scaling groups and making sure that you understand what's happening with the application for instance if the bottleneck of your service is back-end",
    "start": "2876900",
    "end": "2882479"
  },
  {
    "text": "database connections spinning up more servers it's gonna give you a really bad time don't do that make sure you",
    "start": "2882479",
    "end": "2887640"
  },
  {
    "text": "understand what those limitations are is it network because it's CPU is a ram right size your instances that's gonna save you so much money when load testing",
    "start": "2887640",
    "end": "2896150"
  },
  {
    "text": "please it'll make your infrastructure engineer happy double and triple check your load test numbers make sure that",
    "start": "2896150",
    "end": "2901739"
  },
  {
    "text": "what you're sending is actually what you intend along the same lines map out the actual use case for what you're going to",
    "start": "2901739",
    "end": "2907079"
  },
  {
    "text": "be testing make sure that you replicate the expected traffic patterns and you have a good understanding of what it is you're doing this isn't always easy",
    "start": "2907079",
    "end": "2912929"
  },
  {
    "text": "sometimes you don't know what the usage pattern is going to it's going to look like and that's an argument same lines",
    "start": "2912929",
    "end": "2920999"
  },
  {
    "text": "understand the data access patterns of your application for us we're really read heavy so having a single write server in one region made a lot of sense",
    "start": "2920999",
    "end": "2928439"
  },
  {
    "text": "for us it might not make sense for you make sure you understand what you're doing leverage servers were possible I am NOT",
    "start": "2928439",
    "end": "2936569"
  },
  {
    "text": "a DBA I am NOT excited about being a DBA I am currently a DBA if you can learn",
    "start": "2936569",
    "end": "2944309"
  },
  {
    "text": "her to service use it if you can if you don't have those resources where people actually understand the backend service",
    "start": "2944309",
    "end": "2950429"
  },
  {
    "text": "you might become a single point of contact where you're the one that gets paid whenever it goes down I know it was",
    "start": "2950429",
    "end": "2955439"
  },
  {
    "text": "like that when the the backup stuff was happening there were several mornings we got up at five then we pushed the backups back to hours",
    "start": "2955439",
    "end": "2961679"
  },
  {
    "text": "so I could wake up at eight instead and then we figured out the problem and we fix it along the lines of making sure",
    "start": "2961679",
    "end": "2968309"
  },
  {
    "text": "that you understand how to run your service when doing random and replication it's incredibly fragile even",
    "start": "2968309",
    "end": "2976079"
  },
  {
    "text": "if you run your own network there's going to be things that cause interrupts there's going to be things that cause data segmentation where",
    "start": "2976079",
    "end": "2982020"
  },
  {
    "text": "you need to be able to recover from those in the instance of using services",
    "start": "2982020",
    "end": "2987240"
  },
  {
    "text": "just make sure you have valid monitoring that shows you whether or not your service is healthy so to recap when you're designing and",
    "start": "2987240",
    "end": "2995190"
  },
  {
    "text": "implementing a global service make sure you thoroughly consider the goal make sure that you think through your design",
    "start": "2995190",
    "end": "3000800"
  },
  {
    "text": "you write it down and you share it with people and you get feedback after that make sure you iterate and you test the",
    "start": "3000800",
    "end": "3006620"
  },
  {
    "text": "infrastructure that you're building to make sure that you're doing what you set out to do by doing this you'll set",
    "start": "3006620",
    "end": "3012770"
  },
  {
    "text": "yourself up for success sometimes failure I'd like to end it with this",
    "start": "3012770",
    "end": "3018320"
  },
  {
    "text": "quote failure is simply the opportunity to begin again this time more",
    "start": "3018320",
    "end": "3023330"
  },
  {
    "text": "intelligently I've shared multiple times that we have failed I will continue to fail don't be afraid to fail it's what",
    "start": "3023330",
    "end": "3030770"
  },
  {
    "text": "makes you better you can stand up do it again make sure that what you're building is what you intend and then get",
    "start": "3030770",
    "end": "3036230"
  },
  {
    "text": "to a point to where you have solid infrastructure I'd like to thank you all for the time after this I will be in the",
    "start": "3036230",
    "end": "3041630"
  },
  {
    "text": "speaker Q&A lounge and they asked me to make sure I include this please complete the session survey in the mobile app",
    "start": "3041630",
    "end": "3046850"
  },
  {
    "text": "thank you very much",
    "start": "3046850",
    "end": "3050020"
  }
]
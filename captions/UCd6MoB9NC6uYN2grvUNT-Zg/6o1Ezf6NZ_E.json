[
  {
    "text": "good afternoon good afternoon we're",
    "start": "0",
    "end": "5759"
  },
  {
    "text": "really excited to see a full house to hear about a deep dive for AWS is newest",
    "start": "5759",
    "end": "11550"
  },
  {
    "text": "fully managed to graph database service just before we get started I wanted just to do a show of hands and just to kind",
    "start": "11550",
    "end": "18000"
  },
  {
    "text": "of understand the audience a little bit how many of you know what a graph database is okay that's good",
    "start": "18000",
    "end": "25980"
  },
  {
    "text": "how many of you are using or have used the graph database okay a few how many",
    "start": "25980",
    "end": "32610"
  },
  {
    "text": "of you know what a property graph is good how many of you are familiar with",
    "start": "32610",
    "end": "39600"
  },
  {
    "text": "RDF for the resource description framework okay great hopefully we'll have most of the hands",
    "start": "39600",
    "end": "44700"
  },
  {
    "text": "up in the air for a lot of the questions by the end of it so the we've had over",
    "start": "44700",
    "end": "50449"
  },
  {
    "text": "700 people request access to the preview since our announcement yesterday and",
    "start": "50449",
    "end": "55890"
  },
  {
    "text": "Andy's keynote and so will be if you if you are among those who have crested access will be getting to you very soon",
    "start": "55890",
    "end": "61980"
  },
  {
    "text": "but we're really excited about the interest here so to kind of give you an overview of what we'll talk about today",
    "start": "61980",
    "end": "67140"
  },
  {
    "text": "I want to talk about the challenges of building applications that were highly connected data and you might really",
    "start": "67140",
    "end": "72659"
  },
  {
    "text": "think of this as why did we build Amazon Neptune what are the problems that we're trying to help our customers solve and",
    "start": "72659",
    "end": "78960"
  },
  {
    "text": "then go into an overview about the different types of graphs give you an example about using apache tinker pop",
    "start": "78960",
    "end": "85229"
  },
  {
    "text": "which is an open source framework for a recommendation engine example give you",
    "start": "85229",
    "end": "90270"
  },
  {
    "text": "an example about using an RDF knowledge graph and then I'm gonna bring my colleague up Bruce Megrahi to talk about",
    "start": "90270",
    "end": "96750"
  },
  {
    "text": "some of the Neptune's fully managed enterprise ready features in the platform so let's go ahead and get right",
    "start": "96750",
    "end": "103829"
  },
  {
    "text": "in so today's applications need to process data that's both rich and highly",
    "start": "103829",
    "end": "111090"
  },
  {
    "text": "connected it's rich in that it comes from heterogeneous sources the each",
    "start": "111090",
    "end": "116280"
  },
  {
    "text": "individual item of information has different units in it and it's highly",
    "start": "116280",
    "end": "122009"
  },
  {
    "text": "connected in that the information relates to other bits of information and",
    "start": "122009",
    "end": "127079"
  },
  {
    "text": "you can build applications that exploit this connectivity and so you see things like social networks",
    "start": "127079",
    "end": "133520"
  },
  {
    "text": "engines fraud they're all examples of applications that are using highly connected data there's a breadth of",
    "start": "133520",
    "end": "142520"
  },
  {
    "text": "things that do that social networking we talked about knowledge graphs are a way you can use a graph technique to model",
    "start": "142520",
    "end": "150140"
  },
  {
    "text": "information for it to you improve information retrieval fraud detection there's a breadth of use cases in the",
    "start": "150140",
    "end": "156590"
  },
  {
    "text": "Life Sciences ranging from drug discovery to master data management and",
    "start": "156590",
    "end": "161930"
  },
  {
    "text": "data integration and then networks are inherently graphs and so there's a also",
    "start": "161930",
    "end": "168260"
  },
  {
    "text": "a breadth of use cases in terms of managing networks detecting anomalies on",
    "start": "168260",
    "end": "173690"
  },
  {
    "text": "network so it's just a very very rich and exciting space to work in so let's",
    "start": "173690",
    "end": "178790"
  },
  {
    "text": "go through a couple of examples about how you can use the properties of connected data to build these kinds of",
    "start": "178790",
    "end": "185360"
  },
  {
    "text": "applications so the first thing we're going to look at is a very simple",
    "start": "185360",
    "end": "190580"
  },
  {
    "text": "recommendation example here we're using connected data and what we're going to",
    "start": "190580",
    "end": "196370"
  },
  {
    "text": "look at is cases where they're shared connections but where the actual commit",
    "start": "196370",
    "end": "203450"
  },
  {
    "text": "fully connected data can be completed and so if you look here so if we get",
    "start": "203450",
    "end": "209150"
  },
  {
    "text": "this working so you can see that we have three people here who follow a sport and two of them have purchased the product",
    "start": "209150",
    "end": "217220"
  },
  {
    "text": "so we can make a recommendation by this is a technique that they call triadic",
    "start": "217220",
    "end": "222950"
  },
  {
    "text": "closure by completing this link to be able to say you know this person may",
    "start": "222950",
    "end": "228380"
  },
  {
    "text": "also want to do this we can do the same kinds of things in a friendship context",
    "start": "228380",
    "end": "235670"
  },
  {
    "text": "same example except making a friend recommendation I mentioned knowledge",
    "start": "235670",
    "end": "243530"
  },
  {
    "text": "graph this is an example of a very simple knowledge graph it takes a look at some artwork and it's it's derived",
    "start": "243530",
    "end": "250370"
  },
  {
    "text": "from one of the w3c knowledge graph examples you can see we have the Mona Lisa we have the the painter we have the",
    "start": "250370",
    "end": "258290"
  },
  {
    "text": "location and when you model this information in a graph it helps you answer questions and you could say",
    "start": "258290",
    "end": "264860"
  },
  {
    "text": "things like who painted the Mona Lisa what museum",
    "start": "264860",
    "end": "270379"
  },
  {
    "text": "should Alice visit when she's in Paris what other artists have paintings in the",
    "start": "270379",
    "end": "276530"
  },
  {
    "text": "Louvre and by building these kinds of knowledge graphs you can use them to improve information retrieval we're very",
    "start": "276530",
    "end": "284990"
  },
  {
    "text": "excited that Thomson Reuters is participating in the preview for a",
    "start": "284990",
    "end": "290060"
  },
  {
    "text": "Neptune and they've provided this quote for us they have a very interesting graph use case they're looking at using",
    "start": "290060",
    "end": "298669"
  },
  {
    "text": "a graph to model different tax policies and different regulations and then",
    "start": "298669",
    "end": "304370"
  },
  {
    "text": "helping their customers to be able to navigate that sort of complex web if you",
    "start": "304370",
    "end": "311120"
  },
  {
    "text": "will of different regulatory information so how do you build applications over",
    "start": "311120",
    "end": "320060"
  },
  {
    "text": "highly connected data can I use a relational database for this well you",
    "start": "320060",
    "end": "325669"
  },
  {
    "text": "can but there are some challenges one of them is that sequel is really not",
    "start": "325669",
    "end": "332150"
  },
  {
    "text": "designed to process relationships well and so if you've ever tried to build a",
    "start": "332150",
    "end": "338180"
  },
  {
    "text": "sequel query across a number of different tables you end up with a lot of nested joins and the sequel itself",
    "start": "338180",
    "end": "345409"
  },
  {
    "text": "becomes quite complicated it also as the number of relationships grows the",
    "start": "345409",
    "end": "352190"
  },
  {
    "text": "ability to process it very quickly degrades and so you have performance limitations the second aspect is that",
    "start": "352190",
    "end": "360279"
  },
  {
    "text": "graph workloads have very different IO requirements than you get in a",
    "start": "360279",
    "end": "365840"
  },
  {
    "text": "relational database and so relational databases just aren't optimized for",
    "start": "365840",
    "end": "371000"
  },
  {
    "text": "processing queries over highly connected data and then the third challenge is",
    "start": "371000",
    "end": "376069"
  },
  {
    "text": "that what we often see is that with highly connected data the types of",
    "start": "376069",
    "end": "381889"
  },
  {
    "text": "information that you want to process are changing very rapidly and so you want to be able to flexibly accommodate new data",
    "start": "381889",
    "end": "388909"
  },
  {
    "text": "types very quickly and then be able to use them within your application to drive new features and relational",
    "start": "388909",
    "end": "395810"
  },
  {
    "text": "databases don't evolve their schemas very well they're relatively inflexible so consider an example here and here",
    "start": "395810",
    "end": "403990"
  },
  {
    "text": "we're thinking about an HR example and so on your right hand side you have sort",
    "start": "403990",
    "end": "409630"
  },
  {
    "text": "of a relational model of an HR system and on the left you have a graph model",
    "start": "409630",
    "end": "414699"
  },
  {
    "text": "and suppose that you had a scenario where one of your top employees",
    "start": "414699",
    "end": "420780"
  },
  {
    "text": "unexpectedly resigned and you wanted to ask the question what skills they have",
    "start": "420780",
    "end": "428410"
  },
  {
    "text": "what products do they work on who do they know if all you have is the",
    "start": "428410",
    "end": "434350"
  },
  {
    "text": "relational model that sort of been built for the business application in the HR system it's really very complicated for",
    "start": "434350",
    "end": "441250"
  },
  {
    "text": "you to answer that question you have to come up with one of these multiple joins sequel queries that we talked about",
    "start": "441250",
    "end": "446800"
  },
  {
    "text": "earlier if you've modeled your data as a graph then you can ask that question",
    "start": "446800",
    "end": "451810"
  },
  {
    "text": "much more naturally much more easily and this is really sort of the power of",
    "start": "451810",
    "end": "456970"
  },
  {
    "text": "looking at graphs as an approach for processing highly connected data so a",
    "start": "456970",
    "end": "464680"
  },
  {
    "text": "graph database like Amazon Neptune is a database that's optimized for storing",
    "start": "464680",
    "end": "471010"
  },
  {
    "text": "and retrieving highly connected data it also supports query languages that allow",
    "start": "471010",
    "end": "478870"
  },
  {
    "text": "you to easily and concisely express graph traversals and graph patterns and",
    "start": "478870",
    "end": "485200"
  },
  {
    "text": "so a graph database is really a key to building applications over highly connected data there's two major models",
    "start": "485200",
    "end": "495630"
  },
  {
    "text": "for processing graphs the first is something called a property graph a",
    "start": "495630",
    "end": "500940"
  },
  {
    "text": "property graph consists of nodes and node properties and edges and edge",
    "start": "500940",
    "end": "506620"
  },
  {
    "text": "properties the most popular open-source framework for property graphs is",
    "start": "506620",
    "end": "512740"
  },
  {
    "text": "something that's called apache tinker pop and it provides an imperative traversal language which is called",
    "start": "512740",
    "end": "518500"
  },
  {
    "text": "gremlin to allow you to write traversals over your graph the second graph model",
    "start": "518500",
    "end": "524229"
  },
  {
    "text": "is something called the resource description framework the resource description framework or RDF is based on",
    "start": "524229",
    "end": "531100"
  },
  {
    "text": "a set standards from the World Wide Web Consortium that's collectively known as the Semantic Web RDF defines a resource",
    "start": "531100",
    "end": "539800"
  },
  {
    "text": "based model for describing grass and so in RDF and we'll have a more detailed",
    "start": "539800",
    "end": "545860"
  },
  {
    "text": "example later there's resources which consists of uniquely identified your",
    "start": "545860",
    "end": "551920"
  },
  {
    "text": "eyes or eye our eyes and then you can associate attributes with those resources and you can make relationships",
    "start": "551920",
    "end": "558640"
  },
  {
    "text": "between those resources and that's how you build up the overall graph model now",
    "start": "558640",
    "end": "567430"
  },
  {
    "text": "when we looked across the alternatives that customers have today for processing",
    "start": "567430",
    "end": "573850"
  },
  {
    "text": "graph databases a couple of things stood out to us we heard repeatedly from",
    "start": "573850",
    "end": "579040"
  },
  {
    "text": "customers that they had challenges with their applications they often would do a",
    "start": "579040",
    "end": "585010"
  },
  {
    "text": "proof of concept or a prototype and they get very good results but when they move",
    "start": "585010",
    "end": "590530"
  },
  {
    "text": "to the next stage they weren't able to maintain the query throughput and the",
    "start": "590530",
    "end": "596080"
  },
  {
    "text": "query latency is that they experienced at a smaller data scale and so they had declining performance at increasing data",
    "start": "596080",
    "end": "602530"
  },
  {
    "text": "scale another thing that we've heard was that it was very difficult to configure",
    "start": "602530",
    "end": "609900"
  },
  {
    "text": "features that are you need for an enterprise production application things",
    "start": "609900",
    "end": "615130"
  },
  {
    "text": "like high availability read replication encryption at rest in fact we met with a customer this",
    "start": "615130",
    "end": "621640"
  },
  {
    "text": "morning that was using a graph database they were working on configuring it on ec2 they weren't able to get the high",
    "start": "621640",
    "end": "628840"
  },
  {
    "text": "availability clustering working they had the vendor come in they were also not able to get it working it's just very",
    "start": "628840",
    "end": "634180"
  },
  {
    "text": "challenging to do that so the third area we call it we found out was that things",
    "start": "634180",
    "end": "639760"
  },
  {
    "text": "are very expensive often you get started with an open source solution and as we talked about earlier you'd have a",
    "start": "639760",
    "end": "645610"
  },
  {
    "text": "successful prototype and you'd want to move it into production but when you had to do that he had to license the",
    "start": "645610",
    "end": "652120"
  },
  {
    "text": "Enterprise Edition and that was just something that was cost prohibitive and then the last thing that really stood",
    "start": "652120",
    "end": "658330"
  },
  {
    "text": "out to us was the lack of choice and the many of the existing alternatives",
    "start": "658330",
    "end": "664769"
  },
  {
    "text": "tend to track you towards one graph model or another well they may support tinker pop or property graph and RDF",
    "start": "664769",
    "end": "671939"
  },
  {
    "text": "they tend to have a strong bias in terms of performance towards one model of the",
    "start": "671939",
    "end": "677879"
  },
  {
    "text": "other so with that in mind we developed",
    "start": "677879",
    "end": "683399"
  },
  {
    "text": "Amazon Neptune so Amazon Neptune is designed to be fast in particular it's",
    "start": "683399",
    "end": "689069"
  },
  {
    "text": "designed to be fast for graph applications that require high throughput and low latency graph query",
    "start": "689069",
    "end": "696480"
  },
  {
    "text": "answering Amazon Neptune is designed to be reliable the things the gaps that we",
    "start": "696480",
    "end": "703529"
  },
  {
    "text": "saw in alternatives we tried to address with the Amazon Neptune so we support",
    "start": "703529",
    "end": "709350"
  },
  {
    "text": "multi a-z high availability we support up to 15 different read replicas we",
    "start": "709350",
    "end": "714660"
  },
  {
    "text": "support encryption at rest with customer manage keys all in a fully managed experience which makes it easy for you",
    "start": "714660",
    "end": "721589"
  },
  {
    "text": "to build graph applications that use either gremlin or Sparkle depending on",
    "start": "721589",
    "end": "727319"
  },
  {
    "text": "what you think is the right fit for your application so this is a look at the",
    "start": "727319",
    "end": "735540"
  },
  {
    "text": "high level architecture for Amazon Neptune you can see across the top we",
    "start": "735540",
    "end": "742410"
  },
  {
    "text": "have sort of the data plane or the data API is that should use to build applications with Amazon Neptune itself",
    "start": "742410",
    "end": "750089"
  },
  {
    "text": "is a purpose-built engine that's designed and optimized for processing",
    "start": "750089",
    "end": "756600"
  },
  {
    "text": "graphs it's both durable and acid and provides immediate consistency we also",
    "start": "756600",
    "end": "765360"
  },
  {
    "text": "provide are running on top of a cloud native storage layer this allows us to",
    "start": "765360",
    "end": "773279"
  },
  {
    "text": "offer the enterprise capabilities and the fully managed experience that we talked about earlier",
    "start": "773279",
    "end": "778649"
  },
  {
    "text": "the other kinds of API is that you have from Neptune it's great to be able to query the graph and to be able to build",
    "start": "778649",
    "end": "784769"
  },
  {
    "text": "applications but you also need to get data in and out and so we're able to provide a bulk load API for you to load",
    "start": "784769",
    "end": "792899"
  },
  {
    "text": "data quickly that you have stored in s3 into the service as well as to perform",
    "start": "792899",
    "end": "798300"
  },
  {
    "text": "database management type operations so",
    "start": "798300",
    "end": "803660"
  },
  {
    "text": "let's take a little bit of a look at the different types of graphs and how you",
    "start": "803660",
    "end": "808769"
  },
  {
    "text": "build applications against them we talked about a property graph this is a little bit more of a detailed example of",
    "start": "808769",
    "end": "815550"
  },
  {
    "text": "what a property graph is so do we have the vertices here in this case this",
    "start": "815550",
    "end": "820980"
  },
  {
    "text": "vertex has something that's called a label a label is used in property graph very similar to a type and then we can",
    "start": "820980",
    "end": "827639"
  },
  {
    "text": "see that we have an attribute here which is a name it's called bill and between",
    "start": "827639",
    "end": "833310"
  },
  {
    "text": "these two vertices there's an edge and this is in this case the edge has a label which is like a type that it's a",
    "start": "833310",
    "end": "840810"
  },
  {
    "text": "friend and we're making that relationship to another vertex instance",
    "start": "840810",
    "end": "846269"
  },
  {
    "text": "in this case Sara and each edge and vertex has unique identifiers in systems",
    "start": "846269",
    "end": "852540"
  },
  {
    "text": "and the properties express the different attributes on both the edges and the vertices now as we mentioned before",
    "start": "852540",
    "end": "860660"
  },
  {
    "text": "tinker pop is the open source option for writing and processing property graphs",
    "start": "860660",
    "end": "867990"
  },
  {
    "text": "and Amazon Neptune is fully compatible with apache tinker pop and the ticker",
    "start": "867990",
    "end": "874079"
  },
  {
    "text": "pop gremlin 3/3 release which is the current one as of August this year and we provide optimized query execution for",
    "start": "874079",
    "end": "882709"
  },
  {
    "text": "traversals that you've written in gremlin so here is an example of how you",
    "start": "882709",
    "end": "890490"
  },
  {
    "text": "would create a graph using apache tinker pop this presumes that you've connected",
    "start": "890490",
    "end": "895560"
  },
  {
    "text": "to a Neptune instance and you have a remote graph instance which is here denoted by the variable G this is a Java",
    "start": "895560",
    "end": "902910"
  },
  {
    "text": "example and you can see on the first line here we're adding the vertex bill you can see we're assigning the label",
    "start": "902910",
    "end": "910079"
  },
  {
    "text": "here user we're assigning the property bill creating the second vertex which",
    "start": "910079",
    "end": "915209"
  },
  {
    "text": "corresponds to Sarah and then we create an edge here and this is the friend",
    "start": "915209",
    "end": "920850"
  },
  {
    "text": "relationship the second graph model that you'll",
    "start": "920850",
    "end": "926770"
  },
  {
    "text": "recall or is the RDF graph model or the resource description framework and RDF looks a lot a lot a little bit different",
    "start": "926770",
    "end": "934500"
  },
  {
    "text": "because it's has its roots in resource description the sort of fundamental unit",
    "start": "934500",
    "end": "941560"
  },
  {
    "text": "of identification is something that's called an IR I or an internationalized resource identifier and it looks just",
    "start": "941560",
    "end": "948880"
  },
  {
    "text": "like you might think it was a URL or a URI all IRI means this is a fancy way to",
    "start": "948880",
    "end": "954130"
  },
  {
    "text": "say that you can accommodate international characters and you express",
    "start": "954130",
    "end": "960240"
  },
  {
    "text": "statements in the graph in this combination of triples and a triple is made up of a subject and a predicate and",
    "start": "960240",
    "end": "966760"
  },
  {
    "text": "an object so if you look at this example across the top you can see the subject position here is an IRI",
    "start": "966760",
    "end": "973090"
  },
  {
    "text": "it's person there's a predicate here in this case it's RDF type that has meaning",
    "start": "973090",
    "end": "978160"
  },
  {
    "text": "in the RDF language it's a user and they're going to express in this case a",
    "start": "978160",
    "end": "983260"
  },
  {
    "text": "literal or like a property in the name bill and now that combination that triplet forms this vertex bill now the",
    "start": "983260",
    "end": "994000"
  },
  {
    "text": "way that you make relationships is you express a triple relationship where the",
    "start": "994000",
    "end": "999100"
  },
  {
    "text": "third position the object position is not a literal but is actually another",
    "start": "999100",
    "end": "1005010"
  },
  {
    "text": "IRI itself and so if we want to look at making the equivalent friend relationship that we saw in the property",
    "start": "1005010",
    "end": "1011370"
  },
  {
    "text": "graph example then you can see this is the triplet that would correspond to it",
    "start": "1011370",
    "end": "1016380"
  },
  {
    "text": "so we start with this subject that is an IRI we have a predicate here the friend predicate and then we have an object",
    "start": "1016380",
    "end": "1023160"
  },
  {
    "text": "which refers to the second the second vertice that we created so unlike a",
    "start": "1023160",
    "end": "1031020"
  },
  {
    "text": "certain Starfleet captain with tribbles sort of there's no trouble with triples and so this is a fully example of the",
    "start": "1031020",
    "end": "1038100"
  },
  {
    "text": "same graph looking at RDF and you can see this corresponds to the bill vertex",
    "start": "1038100",
    "end": "1043350"
  },
  {
    "text": "this corresponds to the friend edge and then the bottom here you have this era",
    "start": "1043350",
    "end": "1048390"
  },
  {
    "text": "vertex so let's go through a kree example we'll go back to looking at",
    "start": "1048390",
    "end": "1054690"
  },
  {
    "text": "relational modeling versus a graph but this time we'll look at it from a",
    "start": "1054690",
    "end": "1059789"
  },
  {
    "text": "product perspective and so this is a you know again a very simple relational model it looks like products and order",
    "start": "1059789",
    "end": "1066779"
  },
  {
    "text": "details and customers and then on the left hand side or I guess on your right",
    "start": "1066779",
    "end": "1071879"
  },
  {
    "text": "hand side you'll see the subset of that model represented as a graph and so if",
    "start": "1071879",
    "end": "1077789"
  },
  {
    "text": "you're familiar with sequel as I imagine most of you are this is a very basic",
    "start": "1077789",
    "end": "1082950"
  },
  {
    "text": "query that you would use to answer the question find me the names of companies that purchase the echo and if you look",
    "start": "1082950",
    "end": "1090720"
  },
  {
    "text": "at the query you'll see that you're joining through you join up customers you join order details you join products",
    "start": "1090720",
    "end": "1097889"
  },
  {
    "text": "and then finally you make a filter on the name of the product that you're looking for and so this should look",
    "start": "1097889",
    "end": "1103889"
  },
  {
    "text": "fairly familiar to you now if we look at it in Sparkle Sparkle is the declarative",
    "start": "1103889",
    "end": "1111269"
  },
  {
    "text": "graph query language for the RDF model you'll see something that's a little bit similar but rather than having these",
    "start": "1111269",
    "end": "1118679"
  },
  {
    "text": "joins we're expressing triple patterns and the triple patterns have shared",
    "start": "1118679",
    "end": "1123720"
  },
  {
    "text": "variables and that's how we express the same kind of of graph pattern and so in",
    "start": "1123720",
    "end": "1130649"
  },
  {
    "text": "sparkle this question mark syntax represents a variable so again we're",
    "start": "1130649",
    "end": "1136259"
  },
  {
    "text": "answering the same question find me the names of companies that purchase the echo the first part we have a triple",
    "start": "1136259",
    "end": "1142919"
  },
  {
    "text": "pattern where we match the order the next one is the next triple amount of pattern and order details then we go",
    "start": "1142919",
    "end": "1150179"
  },
  {
    "text": "through on the product and finally we have the same kinds of filter that we have across the bottom so that's the",
    "start": "1150179",
    "end": "1156029"
  },
  {
    "text": "example looking at it and sparkle in gremlin so gremlin is an imperative",
    "start": "1156029",
    "end": "1162840"
  },
  {
    "text": "traversal language so the way that you expressed reversals in gremlin is by",
    "start": "1162840",
    "end": "1168029"
  },
  {
    "text": "taking them one step at a time this is how you would answer that same question find me the names of the company that",
    "start": "1168029",
    "end": "1174269"
  },
  {
    "text": "purchased the echo in gremlin so we start off with looking for vertices that",
    "start": "1174269",
    "end": "1179669"
  },
  {
    "text": "have a label product that has the name echo and then we traverse the edges here",
    "start": "1179669",
    "end": "1186000"
  },
  {
    "text": "for the product the deed the order details in the order and finally we get the company name so those are a brief",
    "start": "1186000",
    "end": "1192869"
  },
  {
    "text": "examples across a relational model versus graph and into rdf sparkle and",
    "start": "1192869",
    "end": "1200119"
  },
  {
    "text": "ticker pop criminal so let's look at an example application which looks in using",
    "start": "1200119",
    "end": "1207480"
  },
  {
    "text": "a property graph so we'll drill down a little bit on the recommendation engine example that we talked about before this",
    "start": "1207480",
    "end": "1213779"
  },
  {
    "text": "technique is called triadic closure you're looking for triangles or cliques these are the smallest fully connected",
    "start": "1213779",
    "end": "1220919"
  },
  {
    "text": "sub graphs that you have and the technique in general is to find cliques",
    "start": "1220919",
    "end": "1227519"
  },
  {
    "text": "that we can be completed by adding a single edge so so we have some build",
    "start": "1227519",
    "end": "1232529"
  },
  {
    "text": "issues here so this is how you would go ahead and make the recommendation so go back one at a time so we start off with",
    "start": "1232529",
    "end": "1239909"
  },
  {
    "text": "Terry we go out one edge hop to Bill we",
    "start": "1239909",
    "end": "1245639"
  },
  {
    "text": "go out one more so friends of bill and then we complete the recommendation with Terry and Sara if you want to look at",
    "start": "1245639",
    "end": "1254309"
  },
  {
    "text": "this in terms of the associated gremlin traversal first we find Terry with the",
    "start": "1254309",
    "end": "1260460"
  },
  {
    "text": "label is it and we use this syntax here as a variable because we're going to want to refer to it again in the future",
    "start": "1260460",
    "end": "1268429"
  },
  {
    "text": "we follow the friend relationship we want to express that they're both",
    "start": "1268429",
    "end": "1274500"
  },
  {
    "text": "friends then we express where they're not already friends with our starting",
    "start": "1274500",
    "end": "1281039"
  },
  {
    "text": "point which is where we reuse this variable and that's essentially how we",
    "start": "1281039",
    "end": "1288149"
  },
  {
    "text": "would implement that very basic recommendation example using tinker pop and gremlin so let's go through an RDF",
    "start": "1288149",
    "end": "1299990"
  },
  {
    "text": "knowledge graph example so we talked a little bit about the structure of RDF",
    "start": "1299990",
    "end": "1307200"
  },
  {
    "text": "and this is another example in this case this is using the open ID data set",
    "start": "1307200",
    "end": "1313799"
  },
  {
    "text": "that's provided by Thomson Reuters and we're going to go through the example here using Netflix and if anyone",
    "start": "1313799",
    "end": "1319619"
  },
  {
    "text": "attended the workshop yesterday you'll see that there's some common here and so just to point out some parts",
    "start": "1319619",
    "end": "1325890"
  },
  {
    "text": "of this graph here's the URI that represents the identity of the vertex this is the relationship this is",
    "start": "1325890",
    "end": "1334080"
  },
  {
    "text": "referring to another entity one of the things that is powerful about RDF is",
    "start": "1334080",
    "end": "1339300"
  },
  {
    "text": "that it is it does have a standardized interchange format and so there's a lot of open datasets that you can leverage",
    "start": "1339300",
    "end": "1345540"
  },
  {
    "text": "in this case there's something called geonames geonames is published by the US",
    "start": "1345540",
    "end": "1351810"
  },
  {
    "text": "National geospatial agency and it has a list of place names and identifiers and",
    "start": "1351810",
    "end": "1358650"
  },
  {
    "text": "so they're pulling in a reference data set here in this example this is the URI",
    "start": "1358650",
    "end": "1364320"
  },
  {
    "text": "for Netflix the relationship means where it's incorporated in and this is that",
    "start": "1364320",
    "end": "1370140"
  },
  {
    "text": "reference data for the country of the United States so if we look at it again",
    "start": "1370140",
    "end": "1378120"
  },
  {
    "text": "in this example as a collection of triples will see our subject predicate an object that's how that triple",
    "start": "1378120",
    "end": "1385440"
  },
  {
    "text": "expresses that statement this is an",
    "start": "1385440",
    "end": "1392070"
  },
  {
    "text": "example in RDF of what you would think of as an edge property and so this case it's the literal literals can be",
    "start": "1392070",
    "end": "1399150"
  },
  {
    "text": "essentially XML data types and so any of the data types that are valid in XML are",
    "start": "1399150",
    "end": "1404400"
  },
  {
    "text": "valid in RDF literals and so you can see you have the expressing the name here",
    "start": "1404400",
    "end": "1410990"
  },
  {
    "text": "and then in this example you were adding information about the place and so we",
    "start": "1412130",
    "end": "1420270"
  },
  {
    "text": "have the ISO 3166 country code that we're adding which we can use for reference information and one of the",
    "start": "1420270",
    "end": "1429120"
  },
  {
    "text": "really the benefits of the URI representation that's used in RDF is",
    "start": "1429120",
    "end": "1435420"
  },
  {
    "text": "it's very amenable to being able to link data across different data sets and so",
    "start": "1435420",
    "end": "1441480"
  },
  {
    "text": "each node and concept in RDF is referred to uniquely and so you can join",
    "start": "1441480",
    "end": "1448650"
  },
  {
    "text": "different datasets heterogeneous datasets and this is a really very common use case that we see customers",
    "start": "1448650",
    "end": "1453930"
  },
  {
    "text": "using so how do you query RDF we talked a",
    "start": "1453930",
    "end": "1460670"
  },
  {
    "text": "little we showed an express exactly if",
    "start": "1460670",
    "end": "1480320"
  },
  {
    "text": "we want to take another example suppose I want to say what are all the statements about this company so in this",
    "start": "1480320",
    "end": "1488390"
  },
  {
    "text": "case we have a triple pattern rather than having two of these positions bound we just have the first one and so we're",
    "start": "1488390",
    "end": "1495290"
  },
  {
    "text": "going to retrieve all of the different statements about this particular node and we can see that two of them are what",
    "start": "1495290",
    "end": "1502010"
  },
  {
    "text": "we would call literals and the third one here is an iri which would represent a",
    "start": "1502010",
    "end": "1507830"
  },
  {
    "text": "relationship in the graph and then for",
    "start": "1507830",
    "end": "1514400"
  },
  {
    "text": "another one more example here suppose I want to look for instead of the name I want to look for the ID of the",
    "start": "1514400",
    "end": "1521810"
  },
  {
    "text": "organization that's called net flix and also pull back its phone number and here I've created a sparkle query that has",
    "start": "1521810",
    "end": "1528710"
  },
  {
    "text": "two triple patterns in it there again joined by the shared variable the org variable and so first we match on the",
    "start": "1528710",
    "end": "1536660"
  },
  {
    "text": "organization name and then we bring in the value of the phone and so that's",
    "start": "1536660",
    "end": "1544310"
  },
  {
    "text": "sort of a brief introduction to the tinkerer pop and property graph model and RDF and sparkle and I'd like to",
    "start": "1544310",
    "end": "1552140"
  },
  {
    "text": "introduce Bruce Maga he to give you an overview of the enterprise features that",
    "start": "1552140",
    "end": "1557240"
  },
  {
    "text": "Neptune has",
    "start": "1557240",
    "end": "1559900"
  },
  {
    "text": "great thank you very much Brad good afternoon it's great to be here and",
    "start": "1562440",
    "end": "1567729"
  },
  {
    "text": "we're really excited to launch a Neptune and have the opportunity to talk to you all more about it and give you a little",
    "start": "1567729",
    "end": "1573549"
  },
  {
    "text": "more insight into how Neptune works so a",
    "start": "1573549",
    "end": "1580269"
  },
  {
    "text": "Neptune is a fully managed service makes it very easy to to configure things",
    "start": "1580269",
    "end": "1585999"
  },
  {
    "text": "through our console that's the main way to interact with Neptune today from there you can launch new instances you",
    "start": "1585999",
    "end": "1592599"
  },
  {
    "text": "can monitor the status of instances you can take snapshots which restore from",
    "start": "1592599",
    "end": "1598659"
  },
  {
    "text": "snapshots everything that you want to do to manage Neptune happens via the",
    "start": "1598659",
    "end": "1603969"
  },
  {
    "text": "console some of the key benefits of Neptune first of all it's multi easy so",
    "start": "1603969",
    "end": "1610809"
  },
  {
    "text": "it has very high availability and I'll have a little more to say about that and a few detail slides in just a moment",
    "start": "1610809",
    "end": "1617080"
  },
  {
    "text": "next it supports up to 15 Reed replicas with a fast failover capability and",
    "start": "1617080",
    "end": "1622450"
  },
  {
    "text": "we'll look into a little more about how that how that works in just a moment we",
    "start": "1622450",
    "end": "1627789"
  },
  {
    "text": "also support encryption at rest and you can use kms to manage your keys we support encryption in transit with",
    "start": "1627789",
    "end": "1635440"
  },
  {
    "text": "TLS and we support backup and restore and in fact Neptune is continuously",
    "start": "1635440",
    "end": "1642070"
  },
  {
    "text": "backing up it's kind of unique type of mechanism which is common to some other engines in Amazon and so we'll talk more",
    "start": "1642070",
    "end": "1650259"
  },
  {
    "text": "about that as well and that enable is actually some unique features like point in time recovery so first let's talk",
    "start": "1650259",
    "end": "1659679"
  },
  {
    "text": "about how you deploy a Neptune so Neptune is deployed into a V PC so you",
    "start": "1659679",
    "end": "1665529"
  },
  {
    "text": "deploy a Neptune cluster endpoint you configure the V PC security group for",
    "start": "1665529",
    "end": "1671950"
  },
  {
    "text": "the Neptune endpoint and then you configure another instance in ec2 instance with the proper security group",
    "start": "1671950",
    "end": "1677799"
  },
  {
    "text": "settings which gives you a connection to an Internet gateway and then you query",
    "start": "1677799",
    "end": "1683710"
  },
  {
    "text": "Neptune accordingly from the ec2 instance and furthermore I like to highlight that the Neptune cluster",
    "start": "1683710",
    "end": "1690399"
  },
  {
    "text": "endpoint the head node is allocated into multiple availability zones in the case",
    "start": "1690399",
    "end": "1696590"
  },
  {
    "text": "you have read replicas so this gives you higher availability for the head nodes as well so let's take a deeper dive into",
    "start": "1696590",
    "end": "1705679"
  },
  {
    "text": "the Neptune storage engine so the app to Neptune storage engine is a replication",
    "start": "1705679",
    "end": "1712760"
  },
  {
    "text": "system across three availability zones and in each of the availability zones",
    "start": "1712760",
    "end": "1717980"
  },
  {
    "text": "there's always two copies of the data that are made and those those copies of",
    "start": "1717980",
    "end": "1723470"
  },
  {
    "text": "the day to live on storage nodes in ten gigabytes segments and each of those",
    "start": "1723470",
    "end": "1728630"
  },
  {
    "text": "segments are then basically correlated across the six instance nodes and there's many many instance nodes in a",
    "start": "1728630",
    "end": "1735169"
  },
  {
    "text": "particular cluster and there's some some benefits we derive from that around Network latency x' and being able",
    "start": "1735169",
    "end": "1740840"
  },
  {
    "text": "to spread the network load across a very large cluster so when neptune makes",
    "start": "1740840",
    "end": "1746799"
  },
  {
    "text": "reads or writes into its storage layer you can see that it actually makes six",
    "start": "1746799",
    "end": "1752510"
  },
  {
    "text": "Network calls into each of the six instance nodes those storage nodes are",
    "start": "1752510",
    "end": "1758360"
  },
  {
    "text": "actually continuously backing up the data to s3 incrementally so there's no",
    "start": "1758360",
    "end": "1763490"
  },
  {
    "text": "such thing as kind of checkpointing which might slow down the storage layer for a period of time it's happening",
    "start": "1763490",
    "end": "1769100"
  },
  {
    "text": "continuously in the background and in fact it's using essentially the same mechanism as when you do a read into the",
    "start": "1769100",
    "end": "1775429"
  },
  {
    "text": "storage engine layer so it's a very robust mechanism with shared code paths so if you look at what's happening",
    "start": "1775429",
    "end": "1782809"
  },
  {
    "text": "there's a storage monitoring capability that's continuously monitoring the health of the native storage engine",
    "start": "1782809",
    "end": "1790580"
  },
  {
    "text": "layer and whenever any type of problem were to happen with any of those",
    "start": "1790580",
    "end": "1795740"
  },
  {
    "text": "instances repairs are automatic and the repairs are seamless so rights continue",
    "start": "1795740",
    "end": "1801740"
  },
  {
    "text": "to proceed in the case of failures of up to an entire AZ or in the case of a",
    "start": "1801740",
    "end": "1807620"
  },
  {
    "text": "single instance or in the case of a single disk and the way that happens is the storage nodes have a gossiping",
    "start": "1807620",
    "end": "1813980"
  },
  {
    "text": "capability they basically correlate with each other to catch up to any of the",
    "start": "1813980",
    "end": "1820010"
  },
  {
    "text": "particular log records that they've missed so that's what we call a quorum system for the readwrite and that has an",
    "start": "1820010",
    "end": "1826490"
  },
  {
    "text": "additional for performance it allows a system to essentially hide Network latencies so in",
    "start": "1826490",
    "end": "1832750"
  },
  {
    "text": "the tails of Network latencies we can basically ignore some of those because we require only a quorum of four out of",
    "start": "1832750",
    "end": "1840220"
  },
  {
    "text": "six in the case we do writes in a quorum of three out of six when we do reads and",
    "start": "1840220",
    "end": "1845670"
  },
  {
    "text": "furthermore quorum membership changes don't stall stall writes so if you need to do an upgrade or swap out some nodes",
    "start": "1845670",
    "end": "1852550"
  },
  {
    "text": "or something that actually happens seamlessly without any downtime for the database storage volumes are not",
    "start": "1852550",
    "end": "1859900"
  },
  {
    "text": "required to be statically allocated they actually grow automatically up to a maximum volume size size of 64 terabytes",
    "start": "1859900",
    "end": "1869130"
  },
  {
    "text": "so next let's take a little closer look at what happens with the high availability and the fault tolerance and",
    "start": "1870690",
    "end": "1877510"
  },
  {
    "text": "how the system achieves that so we all know that a number of things can go wrong in distributed systems segments",
    "start": "1877510",
    "end": "1883990"
  },
  {
    "text": "can fail on disks you can have node failures on machines power supplies fail CPUs burn out number of things can go",
    "start": "1883990",
    "end": "1892030"
  },
  {
    "text": "wrong entire aisy can go down due to power network failures and whatnot",
    "start": "1892030",
    "end": "1897190"
  },
  {
    "text": "and in case in all three of these cases we've made optimizations to the storage",
    "start": "1897190",
    "end": "1903100"
  },
  {
    "text": "engine layer so that Neptune can actually withstand any of these types of failures so for example on the bottom",
    "start": "1903100",
    "end": "1909430"
  },
  {
    "text": "left we have a case where two instance nodes have gone out simultaneously which is an extremely rare event admittedly in",
    "start": "1909430",
    "end": "1916810"
  },
  {
    "text": "this case the instance nodes will gossip with each other to patch in any of the missing data the instance nodes will be",
    "start": "1916810",
    "end": "1923890"
  },
  {
    "text": "replaced and then the system will catch up and continue processing data in the case of entire AZ we still can achieve a",
    "start": "1923890",
    "end": "1931570"
  },
  {
    "text": "quorum of four out of six for the writes so writes can continue and like we said",
    "start": "1931570",
    "end": "1937450"
  },
  {
    "text": "only three out of six is required for a requirement so next let's take a look at",
    "start": "1937450",
    "end": "1946450"
  },
  {
    "text": "the database layer so Neptune supports up to 15 read replicas and there's a",
    "start": "1946450",
    "end": "1953530"
  },
  {
    "text": "system that's continuously monitoring the instance health and if any problems",
    "start": "1953530",
    "end": "1959320"
  },
  {
    "text": "are detected the node goes down or if a process goes down Neptune can actually automatically",
    "start": "1959320",
    "end": "1965550"
  },
  {
    "text": "failover to one of the replicas and then patch and replace the problem no",
    "start": "1965550",
    "end": "1972960"
  },
  {
    "text": "furthermore the database process is actually split between the head node",
    "start": "1972960",
    "end": "1979120"
  },
  {
    "text": "which is doing the processing and the buffer cache so in the case that your",
    "start": "1979120",
    "end": "1984460"
  },
  {
    "text": "master goes down or even one of the read replicas the buffer cache which takes a",
    "start": "1984460",
    "end": "1990340"
  },
  {
    "text": "lot of network processing to build up can actually be reused when you reboot the process for the head node so that",
    "start": "1990340",
    "end": "1997900"
  },
  {
    "text": "allows very fast recovery you don't have to rewarm the cache in the case of that type of a failure",
    "start": "1997900",
    "end": "2005179"
  },
  {
    "text": "next the replicas are automatically promoted to the primary in the case of a failover and this can actually be a",
    "start": "2005240",
    "end": "2011820"
  },
  {
    "text": "pretty useful mechanism so let's say you want to increase the instance size of your master you simply allocate a larger size master",
    "start": "2011820",
    "end": "2020640"
  },
  {
    "text": "instance you warm up the cache and then when you're ready you can force a failover from the smaller size master to",
    "start": "2020640",
    "end": "2028170"
  },
  {
    "text": "a more capable larger instance on the replica and all of this will basically be seamless to the user and it'll simply",
    "start": "2028170",
    "end": "2036360"
  },
  {
    "text": "show up as maybe a little bit of a a slight lag like a network blip in terms of the the effects on on the the user",
    "start": "2036360",
    "end": "2045350"
  },
  {
    "text": "there's also benefits to this approach in terms of the scaling out of customer",
    "start": "2045420",
    "end": "2050760"
  },
  {
    "text": "workloads and because it's a cluster endpoint it actually does automatic load balancing for requests let's take a",
    "start": "2050760",
    "end": "2061350"
  },
  {
    "text": "little closer look at the failover times Neptune is able to achieve failover times typically on the order of 30",
    "start": "2061350",
    "end": "2068070"
  },
  {
    "text": "seconds so when a fail a failure is detected it basically takes you know 15 to 20 seconds for that detection to",
    "start": "2068070",
    "end": "2074460"
  },
  {
    "text": "happen after that in parallel the DNS propagation is happening to switch the",
    "start": "2074460",
    "end": "2080370"
  },
  {
    "text": "node over and at the same time recovery process is kicked off to prepare a new",
    "start": "2080370",
    "end": "2086010"
  },
  {
    "text": "head node and in the case where you have a replica where app running you can",
    "start": "2086010",
    "end": "2092429"
  },
  {
    "text": "actually achieve faster fail over times you can actually bypass the DNS propagation so you can achieve",
    "start": "2092430",
    "end": "2097940"
  },
  {
    "text": "often less than 30 second failover times",
    "start": "2097940",
    "end": "2102680"
  },
  {
    "text": "so one of the side benefits are actually one of maybe argue is the primary",
    "start": "2104360",
    "end": "2109680"
  },
  {
    "text": "benefit of the storage engine mechanism is that it's continuously doing backups",
    "start": "2109680",
    "end": "2114900"
  },
  {
    "text": "on the fly so as the instance nodes in the storage engine layer are receiving data from the",
    "start": "2114900",
    "end": "2121320"
  },
  {
    "text": "head nodes it's writing data into s3 and periodically it's taking segments",
    "start": "2121320",
    "end": "2127620"
  },
  {
    "text": "snapshots which are points in time where the entire database across the entire storage cluster is consistent and then",
    "start": "2127620",
    "end": "2135540"
  },
  {
    "text": "furthermore it's capturing the record logs and then it can replay them from a",
    "start": "2135540",
    "end": "2141270"
  },
  {
    "text": "particular snapshot in time to any recovery point and that happens very fast because of the distributed nature",
    "start": "2141270",
    "end": "2148230"
  },
  {
    "text": "of the storage engine because every segment is only ten gigabytes and it's spread across a huge cluster you can",
    "start": "2148230",
    "end": "2155100"
  },
  {
    "text": "imagine that all of the pulling of the data from s3 into all of those storage nodes can happen in parallel and spread",
    "start": "2155100",
    "end": "2162210"
  },
  {
    "text": "the network load across a very large surface area so the final thing I'd like",
    "start": "2162210",
    "end": "2171540"
  },
  {
    "text": "to talk about is a feature that you know kind of comes out of the way this storage engine is built and that is a",
    "start": "2171540",
    "end": "2177810"
  },
  {
    "text": "point in time restore so what this is is while the database is running is",
    "start": "2177810",
    "end": "2184020"
  },
  {
    "text": "constantly doing garbage collection of the segment's that are no longer needed it's doing garbage collection of record",
    "start": "2184020",
    "end": "2190560"
  },
  {
    "text": "logs that are not needed you know because the database is caught up and you can configure Neptune over a period",
    "start": "2190560",
    "end": "2195960"
  },
  {
    "text": "of time say 24 hours to not do that garbage collection but it actually has all those segments and record logs",
    "start": "2195960",
    "end": "2202350"
  },
  {
    "text": "available and so you can go back in time than any time during that 24 hour period",
    "start": "2202350",
    "end": "2207530"
  },
  {
    "text": "that you've configured and you can actually have Neptune in a matter of",
    "start": "2207530",
    "end": "2212630"
  },
  {
    "text": "seconds restore to a particular point so let's say you made some terrible mistake",
    "start": "2212630",
    "end": "2218400"
  },
  {
    "text": "we're all human it happens and you delete some really important data so you can say go back an hour and you can",
    "start": "2218400",
    "end": "2225180"
  },
  {
    "text": "check and see is that there if it's not you can move around you know essentially almost like a dial",
    "start": "2225180",
    "end": "2230700"
  },
  {
    "text": "to choose the point in time that you want to restore to then you can even choose Windows where you can say this",
    "start": "2230700",
    "end": "2237780"
  },
  {
    "text": "particular segment of window is invisible and you can replay past it and then just continue operations and this",
    "start": "2237780",
    "end": "2245580"
  },
  {
    "text": "is kind of a natural consequence of the way the engine layer is built because",
    "start": "2245580",
    "end": "2250770"
  },
  {
    "text": "it's kind of continuously incrementally doing its backup this is actually a",
    "start": "2250770",
    "end": "2255780"
  },
  {
    "text": "feature that kind of falls out of that technology so that's that's what I have",
    "start": "2255780",
    "end": "2264210"
  },
  {
    "text": "about the deep dive on technology and be happy to answer any questions about the",
    "start": "2264210",
    "end": "2270530"
  },
  {
    "text": "portions I talked about or anything that Brad talked about as well if you have a",
    "start": "2270530",
    "end": "2282060"
  },
  {
    "text": "question there are microphones in the aisles please step to the microphones to ask your questions all right quick",
    "start": "2282060",
    "end": "2289550"
  },
  {
    "text": "question on the application how do you do it do you require your pages in memory how do you do the replication you",
    "start": "2289550",
    "end": "2299730"
  },
  {
    "text": "do it on a per query basis or / update basis or do you do it per memory pages",
    "start": "2299730",
    "end": "2304760"
  },
  {
    "text": "pages ok the question is how do we do",
    "start": "2304760",
    "end": "2309960"
  },
  {
    "text": "the how do we make the data durable right is that happening on a page level",
    "start": "2309960",
    "end": "2315270"
  },
  {
    "text": "and the answer is that we actually are only writing record logs so the only",
    "start": "2315270",
    "end": "2320849"
  },
  {
    "text": "record logs are passed across the network rather than entire pages and that makes it a very efficient system",
    "start": "2320849",
    "end": "2325920"
  },
  {
    "text": "from a networking point of view we have",
    "start": "2325920",
    "end": "2332910"
  },
  {
    "text": "the memory support in memory support of that data do we have the memory support",
    "start": "2332910",
    "end": "2339750"
  },
  {
    "text": "rather than storing it at the back end",
    "start": "2339750",
    "end": "2343460"
  },
  {
    "text": "do we have it memory support of this graph database okay so the question is",
    "start": "2345080",
    "end": "2351270"
  },
  {
    "text": "does the graph database support in memory transactions yes absolutely so Neptune has a buffer cache where it's",
    "start": "2351270",
    "end": "2358030"
  },
  {
    "text": "buffering as much data as it possibly can on the head node so obviously if your entire data set works in memory",
    "start": "2358030",
    "end": "2364060"
  },
  {
    "text": "then we'll never have to go to disk except to make things durable right but if you're just doing reads or you're",
    "start": "2364060",
    "end": "2370150"
  },
  {
    "text": "doing some type of complex queries or analytics all right then the entire transaction could remain in memory the",
    "start": "2370150",
    "end": "2379900"
  },
  {
    "text": "underlying data store what is it is it a native graph data store or it's a",
    "start": "2379900",
    "end": "2387640"
  },
  {
    "text": "distributed parallel storage system Network based storage system that Amazon",
    "start": "2387640",
    "end": "2393880"
  },
  {
    "text": "is built you know custom for these types of enterprise database applications is",
    "start": "2393880",
    "end": "2400060"
  },
  {
    "text": "it grass or relational or what's the underlying store so the engine itself is",
    "start": "2400060",
    "end": "2406270"
  },
  {
    "text": "purpose-built for graphic processing and then it's using a distributed storage layer underneath of it",
    "start": "2406270",
    "end": "2411990"
  },
  {
    "text": "okay but the distributed storage layer what is what is it is it relational or",
    "start": "2411990",
    "end": "2418360"
  },
  {
    "text": "grass or it's really neither it's designed for a sort of high throughput",
    "start": "2418360",
    "end": "2423850"
  },
  {
    "text": "latency hiding for replicating the data across a network of storage devices so",
    "start": "2423850",
    "end": "2430150"
  },
  {
    "text": "it's really the storage layer itself is not designed for either relational or graph the storage engine is designed",
    "start": "2430150",
    "end": "2436780"
  },
  {
    "text": "purposely for ground",
    "start": "2436780",
    "end": "2439590"
  },
  {
    "text": "inside hi is the 15 replica and 64",
    "start": "2442520",
    "end": "2448160"
  },
  {
    "text": "terabyte hard limits so is the 6 is the",
    "start": "2448160",
    "end": "2453770"
  },
  {
    "text": "15 replicas and the 64 terabytes hard limits yeah it is currently it's it's it's it's not",
    "start": "2453770",
    "end": "2460640"
  },
  {
    "text": "a the it's a design limitation but there's no flexibility for you to change it at this point is that going to change",
    "start": "2460640",
    "end": "2467360"
  },
  {
    "text": "ever it certainly may evolve in the future we don't have firm plans to do it thanks hi thank you for producing a",
    "start": "2467360",
    "end": "2478119"
  },
  {
    "text": "highly available graph database so is there for rdf is there language support",
    "start": "2478119",
    "end": "2485390"
  },
  {
    "text": "for string literals yeah so rdf has full rdf 1:1 support",
    "start": "2485390",
    "end": "2491560"
  },
  {
    "text": "[Music] are there any and is there inference we",
    "start": "2491560",
    "end": "2497480"
  },
  {
    "text": "do not have in database inference currently so it's really a pure triple store from that perspective uh-huh we",
    "start": "2497480",
    "end": "2503810"
  },
  {
    "text": "are very interested in use cases for inferencing and to sort of understand",
    "start": "2503810",
    "end": "2509150"
  },
  {
    "text": "how we might shape the product roadmap in that regards and then what happens if",
    "start": "2509150",
    "end": "2515180"
  },
  {
    "text": "a client aborts a query like some of the",
    "start": "2515180",
    "end": "2521140"
  },
  {
    "text": "RDF databases have time limited parameters for query properties that",
    "start": "2521140",
    "end": "2527240"
  },
  {
    "text": "allowed you to have an open Sparkle endpoint safely and of course a client",
    "start": "2527240",
    "end": "2536270"
  },
  {
    "text": "can just say oh this is taking too long and go away but that leaves the database still performing the calculation right",
    "start": "2536270",
    "end": "2543830"
  },
  {
    "text": "so we internally have various mechanisms to control limits on query timeouts",
    "start": "2543830",
    "end": "2550780"
  },
  {
    "text": "timeouts are something that you someone provisioning the service can use to",
    "start": "2550780",
    "end": "2556730"
  },
  {
    "text": "configure from their configuration group parameters in the console we also internally have a",
    "start": "2556730",
    "end": "2561810"
  },
  {
    "text": "other mechanisms that were looking at figuring out how we can you know make the make sure that you can be safe and",
    "start": "2561810",
    "end": "2568110"
  },
  {
    "text": "keep your database working properly and what's the maximum number of subject and",
    "start": "2568110",
    "end": "2574050"
  },
  {
    "text": "subjects and triples this has been tested with today so as Bruce said this",
    "start": "2574050",
    "end": "2581730"
  },
  {
    "text": "sort of storage layer supports up to 64 terabytes the design target is supported about a hundred billion triples and",
    "start": "2581730",
    "end": "2588570"
  },
  {
    "text": "we've tested it pretty close to that scale okay thank you sparkle update as",
    "start": "2588570",
    "end": "2595710"
  },
  {
    "text": "well as available correct so we support from Sparkle 1:1 we support Sparkle one",
    "start": "2595710",
    "end": "2601200"
  },
  {
    "text": "one query Sparkle one one update and then the endpoint itself supports the",
    "start": "2601200",
    "end": "2606390"
  },
  {
    "text": "sparkle protocol one one thanks how do you feel about multi-tenant datasets",
    "start": "2606390",
    "end": "2612540"
  },
  {
    "text": "we're like we have tens of thousands of disjoint graphs that are maybe 10 to the",
    "start": "2612540",
    "end": "2618000"
  },
  {
    "text": "4 to 10 to the 6 nodes so like a use case where you had a very high number of",
    "start": "2618000",
    "end": "2623580"
  },
  {
    "text": "named graphs you know in our case it's you know we have a graphic per customer",
    "start": "2623580",
    "end": "2629160"
  },
  {
    "text": "right and we obviously we don't query",
    "start": "2629160",
    "end": "2634470"
  },
  {
    "text": "those at the same time what's you're always looking at a very small subset of the overall data in the graph so the way",
    "start": "2634470",
    "end": "2641130"
  },
  {
    "text": "that Neptune is configured today is it's a single graph on the RDF side we",
    "start": "2641130",
    "end": "2647310"
  },
  {
    "text": "support the name graph which you can use to create a container concept on the",
    "start": "2647310",
    "end": "2652710"
  },
  {
    "text": "property graph we don't have a similar container concept at this point so you know our answer for that would be you to",
    "start": "2652710",
    "end": "2658770"
  },
  {
    "text": "have multiple very small instances for you to the graphs but you know if you have that use case we'd be interested in",
    "start": "2658770",
    "end": "2664050"
  },
  {
    "text": "hearing about sort of a multi-tenancy in graphics",
    "start": "2664050",
    "end": "2668599"
  },
  {
    "text": "if the data immutable is the data immutable no you the day you can update",
    "start": "2670270",
    "end": "2675430"
  },
  {
    "text": "and change the data for example the person says I like pizza and then",
    "start": "2675430",
    "end": "2680470"
  },
  {
    "text": "tomorrow the person goes and changes to I like so will they be able to go to the",
    "start": "2680470",
    "end": "2686800"
  },
  {
    "text": "point in time and get what that customer two choices right so from a data",
    "start": "2686800",
    "end": "2692170"
  },
  {
    "text": "perspective you can support those kind of changes we don't currently have features that are built in for",
    "start": "2692170",
    "end": "2698950"
  },
  {
    "text": "versioning the graph you know across a point in time again that's a use case that we're interested in okay thank you",
    "start": "2698950",
    "end": "2706170"
  },
  {
    "text": "hi thank you for the representation sorry do you I saw one of the slide you mentioned some caching do you do any",
    "start": "2706170",
    "end": "2713290"
  },
  {
    "text": "caching on the graph like based on the query yes stuff well the the head node is using a buffer",
    "start": "2713290",
    "end": "2721030"
  },
  {
    "text": "pool cache so there is a very large cache allocated because no graph databases work best for exploring",
    "start": "2721030",
    "end": "2727690"
  },
  {
    "text": "relationships when the data set is in memory so I'd say we're you know in memory optimized graph database but not",
    "start": "2727690",
    "end": "2733810"
  },
  {
    "text": "exclusively in memory so the cache technology in Neptune plays a really big",
    "start": "2733810",
    "end": "2739900"
  },
  {
    "text": "role in the performance and the experience that you get out of the product so if I do the same query",
    "start": "2739900",
    "end": "2745770"
  },
  {
    "text": "sequentially I can expect better performance right absolutely yes the first time you do if the cache is not",
    "start": "2745770",
    "end": "2751300"
  },
  {
    "text": "warm for your working set obviously it's gonna have to fetch from network and",
    "start": "2751300",
    "end": "2756640"
  },
  {
    "text": "then after that it'll be in memory and you will experience much higher throughput great and then do you can we",
    "start": "2756640",
    "end": "2764710"
  },
  {
    "text": "expect any differences if you use tinker pop or spark you do you have any best",
    "start": "2764710",
    "end": "2770080"
  },
  {
    "text": "practice or for Neptune depends on application so I think you know you need",
    "start": "2770080",
    "end": "2776170"
  },
  {
    "text": "to choose which stack you want to you want to work on based on which one fits the application best and you know both",
    "start": "2776170",
    "end": "2782770"
  },
  {
    "text": "stacks are running on the same storage layer the same the same cache technology an awful lot of the stacks are shared",
    "start": "2782770",
    "end": "2789180"
  },
  {
    "text": "that being said you know they have different they have different properties on those stacks so you will see some variance in performance and well last",
    "start": "2789180",
    "end": "2796030"
  },
  {
    "text": "question did you do you have any numbers and about loading like did attested with I don't",
    "start": "2796030",
    "end": "2801430"
  },
  {
    "text": "know compared to other things like we're to also or they're sure loading the",
    "start": "2801430",
    "end": "2807940"
  },
  {
    "text": "design target is is a hundred thousand relationships a second and we've tested",
    "start": "2807940",
    "end": "2813670"
  },
  {
    "text": "that out to tens of billions of relationships thank you",
    "start": "2813670",
    "end": "2820500"
  },
  {
    "text": "really non-technical deployment really non-technical question why is it called Neptune why is it to know so so this is",
    "start": "2820500",
    "end": "2829690"
  },
  {
    "text": "was a new new fully managed database service we really felt like Neptune is",
    "start": "2829690",
    "end": "2835930"
  },
  {
    "text": "something special and so we didn't really want to name it Amazon graph for example which we",
    "start": "2835930",
    "end": "2842170"
  },
  {
    "text": "thought was you know really didn't speak to the differentiation and so we just really thought Neptune was you know some",
    "start": "2842170",
    "end": "2848920"
  },
  {
    "text": "of those interesting you've got planetary references you've got you know Roman mythology you know which one it is",
    "start": "2848920",
    "end": "2855040"
  },
  {
    "text": "is up to you to make it so thank you so",
    "start": "2855040",
    "end": "2861790"
  },
  {
    "text": "much we've been waiting for this for a very long time so I just wanted to ask about two things first of all do you",
    "start": "2861790",
    "end": "2869590"
  },
  {
    "text": "have any support for analytics OLAP long running queries and so on are those or",
    "start": "2869590",
    "end": "2877330"
  },
  {
    "text": "is it more for TP use cases we initially the first version is targeted for OLTP",
    "start": "2877330",
    "end": "2884830"
  },
  {
    "text": "use cases we do have support for OLAP processing there are you know the",
    "start": "2884830",
    "end": "2890340"
  },
  {
    "text": "performance is really based on maintaining a ratio of the size of the graph on disk to the size of the memory",
    "start": "2890340",
    "end": "2896980"
  },
  {
    "text": "in the head node and so there are options that you have to allocate larger nodes to get better analytic performance",
    "start": "2896980",
    "end": "2903460"
  },
  {
    "text": "but you know we do you will be able to get good performance from analytic",
    "start": "2903460",
    "end": "2908830"
  },
  {
    "text": "queries it's not optimized for full-blown iterative graph analytics right yeah the other thing is do you",
    "start": "2908830",
    "end": "2916180"
  },
  {
    "text": "have interoperability with with things like elastic search or data sharing do I have to maintain replicating my data",
    "start": "2916180",
    "end": "2923230"
  },
  {
    "text": "across these different databases or it do do you plan on creating connectors to",
    "start": "2923230",
    "end": "2929119"
  },
  {
    "text": "these so today we don't have interoperability at that level we do",
    "start": "2929119",
    "end": "2934400"
  },
  {
    "text": "have some customers that have been participating in the pre preview beta that have done things like lambda calls",
    "start": "2934400",
    "end": "2939770"
  },
  {
    "text": "to the REST API that being said you know as its emerging so the top new features",
    "start": "2939770",
    "end": "2945380"
  },
  {
    "text": "post GA are along the lines of graph and search to really developing a story around graphing search and then things",
    "start": "2945380",
    "end": "2952069"
  },
  {
    "text": "like change detection something like DynamoDB streams that lets you build integrations with other services so we'd",
    "start": "2952069",
    "end": "2957799"
  },
  {
    "text": "love to hear you know how you'd like to use it but you know that's kind of how we're seeing the feedback we're hearing now from customers great thank you sure",
    "start": "2957799",
    "end": "2965000"
  },
  {
    "text": "a new tune looks really promising thank you my question is does it the can we do",
    "start": "2965000",
    "end": "2972290"
  },
  {
    "text": "federated sparkle queries so the",
    "start": "2972290",
    "end": "2978280"
  },
  {
    "text": "configuration of Neptune in preview does not allow you to do Sparkle Federation",
    "start": "2978280",
    "end": "2984290"
  },
  {
    "text": "and that's largely from a security perspective and so you know we're interested we do see a lot of use cases",
    "start": "2984290",
    "end": "2990859"
  },
  {
    "text": "for Sparkle Federation but we want to find out a way that you can do it by something like white listing or other",
    "start": "2990859",
    "end": "2997130"
  },
  {
    "text": "mechanisms that strikes a balance right so currently it's more a security",
    "start": "2997130",
    "end": "3002430"
  },
  {
    "text": "limitation limitations to you know handle security rather than the engine",
    "start": "3002430",
    "end": "3008410"
  },
  {
    "text": "not having been correct the engine itself would support the Federation things do you have any suggestions for",
    "start": "3008410",
    "end": "3016869"
  },
  {
    "text": "migrating data from the relational database to the map town yeah so there's",
    "start": "3016869",
    "end": "3023140"
  },
  {
    "text": "a couple different options you need to sort of look at see what which of the graph models feels most natural to you",
    "start": "3023140",
    "end": "3028980"
  },
  {
    "text": "we support from a for property graph we support a CSV format that you can use in",
    "start": "3028980",
    "end": "3036069"
  },
  {
    "text": "the bulk load the CSV format allows you to have nodes and node properties and in sets of files and edges and edge",
    "start": "3036069",
    "end": "3042700"
  },
  {
    "text": "properties and files so from that perspective you could use something like glue",
    "start": "3042700",
    "end": "3048200"
  },
  {
    "text": "- to develop an ETL job that would take from your relational database and put it into the format that you've been loaded",
    "start": "3048200",
    "end": "3053780"
  },
  {
    "text": "into Neptune and you can do something similar if you were to choose the RDF representation as well right thanks is",
    "start": "3053780",
    "end": "3061400"
  },
  {
    "text": "there any support for data constraints like like a node that meets some",
    "start": "3061400",
    "end": "3070190"
  },
  {
    "text": "criteria cannot be connected to another node to meet some criteria so Neptune today doesn't have support for sort of",
    "start": "3070190",
    "end": "3077240"
  },
  {
    "text": "schema concepts or constraints in the graph schema it is something that we",
    "start": "3077240",
    "end": "3082250"
  },
  {
    "text": "have on our roadmap we're interested in sort of understanding the different use cases for but it's not something that's",
    "start": "3082250",
    "end": "3087980"
  },
  {
    "text": "there today so I've seen some documentation online already showing",
    "start": "3087980",
    "end": "3096079"
  },
  {
    "text": "examples of using Neptune over HTTP do you also support WebSockets at the",
    "start": "3096079",
    "end": "3101119"
  },
  {
    "text": "moment yeah so the gremlin supports both the WebSocket server as well as the REST API and then on the RTO Sparkle side is",
    "start": "3101119",
    "end": "3108079"
  },
  {
    "text": "just the rest the endpoint for the sparkle protocol and do you support multiple traversal sources like per",
    "start": "3108079",
    "end": "3113839"
  },
  {
    "text": "neptune instance or would I need to spin up separate neptune instances to have",
    "start": "3113839",
    "end": "3121040"
  },
  {
    "text": "multiple graphs so there's only one graph per neptune incidence but you",
    "start": "3121040",
    "end": "3126440"
  },
  {
    "text": "could have multiple traversals over that graph with multiple connections to their grandma's server thank you so um as far as client",
    "start": "3126440",
    "end": "3137150"
  },
  {
    "text": "libraries go the client libraries that I saw listed those are open source just",
    "start": "3137150",
    "end": "3142280"
  },
  {
    "text": "sort of they don't really know what's running in the background that's that accurate yeah so there's no specific",
    "start": "3142280",
    "end": "3147760"
  },
  {
    "text": "client library for Neptune the apache tinker pop is an open source project and",
    "start": "3147760",
    "end": "3154730"
  },
  {
    "text": "there's various different clients that will connect to the gremlin server either by a WebSockets or the REST API",
    "start": "3154730",
    "end": "3160270"
  },
  {
    "text": "like the other question was mentioned and then on the RDF sparkle side those are w3c standards and there's several",
    "start": "3160270",
    "end": "3167240"
  },
  {
    "text": "open source and commercial clients that you can use to connect to the RTO sparkling voice okay so so",
    "start": "3167240",
    "end": "3173859"
  },
  {
    "text": "you guys are running the gremlins server that's part of the Neptune yes not at the server side so for instance I",
    "start": "3173859",
    "end": "3180130"
  },
  {
    "text": "spotted a gremlin client librarian node is that something that would work it is",
    "start": "3180130",
    "end": "3185980"
  },
  {
    "text": "yes so you could take a gremlin client library and node put it on a server",
    "start": "3185980",
    "end": "3191050"
  },
  {
    "text": "within your V PC configure it to connect to the gremlin web socket and then use",
    "start": "3191050",
    "end": "3196240"
  },
  {
    "text": "it right away cool all right thanks a lot sure what is the maximum of right connections that",
    "start": "3196240",
    "end": "3203380"
  },
  {
    "text": "you can support and what is your throughput in bytes per second so",
    "start": "3203380",
    "end": "3208890"
  },
  {
    "text": "maximum or right connections maximum",
    "start": "3208890",
    "end": "3214020"
  },
  {
    "text": "connections to a particular endpoint so a very large number several thousand",
    "start": "3214020",
    "end": "3219820"
  },
  {
    "text": "probably and then it's a single master system so only one of the instances will",
    "start": "3219820",
    "end": "3226030"
  },
  {
    "text": "be will be a right master there's throughput perspective that as I mentioned that all throughput which does",
    "start": "3226030",
    "end": "3232420"
  },
  {
    "text": "to spend some of the acid properties they get a higher throughput rate is it a hundred thousand relationships a second and then under a sustained",
    "start": "3232420",
    "end": "3239440"
  },
  {
    "text": "read/write workload it's about twenty thousand okay do you plan to support",
    "start": "3239440",
    "end": "3244810"
  },
  {
    "text": "multi master and multi mouse across multi regions like dynamo or is this way",
    "start": "3244810",
    "end": "3250359"
  },
  {
    "text": "beyond so when so we are leveraging sort of the storage layer that's you know",
    "start": "3250359",
    "end": "3255730"
  },
  {
    "text": "been developed internally at Amazon and so as there are improvements in that like multi master multi region will be",
    "start": "3255730",
    "end": "3261520"
  },
  {
    "text": "able to bring them in to offer them as features for Neptune relatively quickly we do we don't do that today but any",
    "start": "3261520",
    "end": "3272290"
  },
  {
    "text": "size limitation on the hood on the nodes themselves any size limitation in terms",
    "start": "3272290",
    "end": "3277990"
  },
  {
    "text": "of the nodes we do have a blob size limitation in terms of the size of a property but we don't have any",
    "start": "3277990",
    "end": "3284369"
  },
  {
    "text": "particular limitation in the size of a node from the context of like the number of properties or relationships that it",
    "start": "3284369",
    "end": "3290619"
  },
  {
    "text": "could have well maybe a better question any hit or any performance problem starting a person",
    "start": "3290619",
    "end": "3296700"
  },
  {
    "text": "yeah so in general the design of Neptune is such that it should be fairly robust",
    "start": "3296700",
    "end": "3301950"
  },
  {
    "text": "to traverse through super node type scenarios of course if you do you know",
    "start": "3301950",
    "end": "3306960"
  },
  {
    "text": "hit a super node and you want to do a filter on it and you have to materialize all the property values to do that there's no really getting around the i/o",
    "start": "3306960",
    "end": "3314490"
  },
  {
    "text": "operations but you know in general the design should be relatively we're bus through to person through okay next",
    "start": "3314490",
    "end": "3320130"
  },
  {
    "text": "question is integration of language are at this point so there's a there is a",
    "start": "3320130",
    "end": "3325650"
  },
  {
    "text": "are there are our client libraries that are available for Sparkle and there also are client libraries that are available",
    "start": "3325650",
    "end": "3332130"
  },
  {
    "text": "for gremlins so there's some both options available in open source for you right thank you when Neptune goes GA",
    "start": "3332130",
    "end": "3339420"
  },
  {
    "text": "will it be HIPAA eligible service we hope to be HIPAA eligible don't quote me",
    "start": "3339420",
    "end": "3345360"
  },
  {
    "text": "on this I guess in my video when we go GA and so we're actually starting that",
    "start": "3345360",
    "end": "3351030"
  },
  {
    "text": "process now so but we can't actually get certified until we achieve GA but at the very least we hope that it will be HIPAA",
    "start": "3351030",
    "end": "3357570"
  },
  {
    "text": "eligible with a very small Delta from the age yet is indexing for proper deep",
    "start": "3357570",
    "end": "3364890"
  },
  {
    "text": "base lookup building so if you've used an alternative like Titan or Janus graph",
    "start": "3364890",
    "end": "3370950"
  },
  {
    "text": "you're probably familiar that to get good traversal performance you need to explicitly specify indices on properties",
    "start": "3370950",
    "end": "3378420"
  },
  {
    "text": "and we kind of really see that as asking the customer to do too much and",
    "start": "3378420",
    "end": "3384450"
  },
  {
    "text": "understand the underlying implementation more than they really need to so Neptune uses internally an indexing strategy",
    "start": "3384450",
    "end": "3391010"
  },
  {
    "text": "that doesn't require you to specify the indices to get good performance so you",
    "start": "3391010",
    "end": "3396330"
  },
  {
    "text": "should get generally good query performance across that tune so do you have any benchmark against like Titan",
    "start": "3396330",
    "end": "3401610"
  },
  {
    "text": "DVD Chinese graphing or ent B we don't have anything that we've published currently we're working on it internally",
    "start": "3401610",
    "end": "3408300"
  },
  {
    "text": "currently but in general we're very very competitive okay thank you oh yeah I just want to",
    "start": "3408300",
    "end": "3416280"
  },
  {
    "text": "understand that failure scenario when the master goes down you said 30 seconds",
    "start": "3416280",
    "end": "3422100"
  },
  {
    "text": "possibly to recover or to elect a new master but you're still able to do read queries during that time is that",
    "start": "3422100",
    "end": "3427310"
  },
  {
    "text": "or you've totally no reads or writes during that 30 seconds yeah I mean right",
    "start": "3427310",
    "end": "3432380"
  },
  {
    "text": "right we'll stop immediately because of the master the replicas will continue to",
    "start": "3432380",
    "end": "3438050"
  },
  {
    "text": "read for a period of time possibly through the whole thing okay cool and one more question is there any limit on",
    "start": "3438050",
    "end": "3443420"
  },
  {
    "text": "the number of properties or edges that you can attach to the nodes in the graph",
    "start": "3443420",
    "end": "3448809"
  },
  {
    "text": "okay thanks hi you guys the prior directional graph you guys offer weighted edges yeah so in",
    "start": "3449230",
    "end": "3457250"
  },
  {
    "text": "Gremlin you can have edge rates yes I can also do it as well and did you have",
    "start": "3457250",
    "end": "3463910"
  },
  {
    "text": "a like DTL could you repeat the question please TTL for the edge six we don't have a TTL",
    "start": "3463910",
    "end": "3470090"
  },
  {
    "text": "feature yet we have had that come up with a number of customer conversations so again it's it kind of falls in the",
    "start": "3470090",
    "end": "3475550"
  },
  {
    "text": "category if you have a use case for we look really be interested in it you know there's a number of different different",
    "start": "3475550",
    "end": "3480680"
  },
  {
    "text": "ways to slice that one thank you just another plus one for the tip okay go ahead just another plus one for the TTL",
    "start": "3480680",
    "end": "3487190"
  },
  {
    "text": "actually okay cool cool thank you great thank you guys very much we really",
    "start": "3487190",
    "end": "3493010"
  },
  {
    "text": "appreciate your interest in Neptune yeah",
    "start": "3493010",
    "end": "3497140"
  }
]
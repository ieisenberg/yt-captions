[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "for coming to today's Kinesis session for those who who are motivated enough",
    "start": "1370",
    "end": "6600"
  },
  {
    "text": "to get up this early appreciate that my name is Wei and the product manager for",
    "start": "6600",
    "end": "11849"
  },
  {
    "text": "amazon kinesis and today co-presenting with me is Allen Lewis Allen is the principal architect at realtor.com so",
    "start": "11849",
    "end": "19020"
  },
  {
    "text": "I'm very excited to have Allen here today to share with you guys a real world use case of streaming data and",
    "start": "19020",
    "end": "25140"
  },
  {
    "text": "amazon kinesis so for the first half of the session I'm going to cover some",
    "start": "25140",
    "end": "30240"
  },
  {
    "start": "28000",
    "end": "92000"
  },
  {
    "text": "basics about streaming data scenario give you an overview of the services that we offer here at amazon kinesis and",
    "start": "30240",
    "end": "36930"
  },
  {
    "text": "then go to the deeper on one of the services we offer which is called Kinesis fire hose so that it can get a",
    "start": "36930",
    "end": "42329"
  },
  {
    "text": "sense of how easy it is to get started with streaming data then for the second half is the more exciting stuff where",
    "start": "42329",
    "end": "48840"
  },
  {
    "text": "Alan is going to share with you guys how we order com has been leveraging streaming data and how amazon kinesis",
    "start": "48840",
    "end": "54480"
  },
  {
    "text": "has transformed the way they use their data so before we kick it off so what is",
    "start": "54480",
    "end": "60690"
  },
  {
    "text": "streaming data and why does it matter so streaming data is a mechanism where you",
    "start": "60690",
    "end": "66869"
  },
  {
    "text": "collect store and analyze and use your data in a continuous stream a manner as",
    "start": "66869",
    "end": "72150"
  },
  {
    "text": "compared to a traditional bachelor oriented way which often involves hours",
    "start": "72150",
    "end": "78030"
  },
  {
    "text": "or days of latency now you get adding minutes seconds or even milliseconds so that's what streaming data is then why",
    "start": "78030",
    "end": "84689"
  },
  {
    "text": "does it matter and why should I care I care about it oh it all comes down to one essential reason is sometimes just",
    "start": "84689",
    "end": "92040"
  },
  {
    "text": "need to go a little bit faster then what do you do today now I'm not necessarily claiming that kanisa is going to say",
    "start": "92040",
    "end": "97799"
  },
  {
    "text": "viewing this particular situation but it does provide a whole a lot of benefit in certain scenarios and very often for",
    "start": "97799",
    "end": "105000"
  },
  {
    "text": "example and if you there's if there's an issue you on your application servers or",
    "start": "105000",
    "end": "110220"
  },
  {
    "text": "web servers you don't want your system adda me to see that error and and be",
    "start": "110220",
    "end": "115380"
  },
  {
    "text": "able to analyze the log right away right after the issue has occurred but not like hours later or days later or if you",
    "start": "115380",
    "end": "122880"
  },
  {
    "text": "launch a marketing campaign online you don't want to a marketing manager to be able to monitor the performance of the",
    "start": "122880",
    "end": "128640"
  },
  {
    "text": "campaign right after you launch the campaign but not a day later when he see he or she sees a report",
    "start": "128640",
    "end": "133890"
  },
  {
    "text": "that's often too late to take actions to fix the issues and so that's why we care",
    "start": "133890",
    "end": "139050"
  },
  {
    "text": "about streaming data and what that's the value we can add with the streaming data so we do see adoptions from customers",
    "start": "139050",
    "end": "146880"
  },
  {
    "text": "across different industry segments for different use cases use different data in a streaming manner but we often see",
    "start": "146880",
    "end": "153990"
  },
  {
    "text": "customers streaming data journey through three different phases so the first",
    "start": "153990",
    "end": "159240"
  },
  {
    "text": "phase is what we call accelerated data ingest transform and data load so in",
    "start": "159240",
    "end": "164760"
  },
  {
    "text": "this case that's the entry point into the streaming data world where people still use and analyze the data in the",
    "start": "164760",
    "end": "171150"
  },
  {
    "text": "data stores with the tools they are familiar with for example s3 Hadoop drop",
    "start": "171150",
    "end": "176190"
  },
  {
    "text": "relational database search engine business intelligence tools these are the tools we've been using for years are",
    "start": "176190",
    "end": "182250"
  },
  {
    "text": "very familiar with however what streaming that I can bring to the table is instead of having data appear in",
    "start": "182250",
    "end": "188489"
  },
  {
    "text": "these places every hour or every day now you get that in minutes or even seconds frequency then people moving to the",
    "start": "188489",
    "end": "196350"
  },
  {
    "text": "second phase is which what we call continual metric extraction so what it does is ingest all your data as a",
    "start": "196350",
    "end": "203310"
  },
  {
    "text": "continuous stream at the same time you in real time you extract metric gain",
    "start": "203310",
    "end": "208829"
  },
  {
    "text": "insights analyze the data out of the data stream directly and add amazon kinesis we have particular service",
    "start": "208829",
    "end": "215670"
  },
  {
    "text": "catering for these different scenarios then we're moving to the third phase which is really more sophisticated use",
    "start": "215670",
    "end": "222030"
  },
  {
    "text": "case of streaming data we call the responsive data analysis a good example will be in the mobile gaming industry",
    "start": "222030",
    "end": "229320"
  },
  {
    "text": "way distribute your games to your game players and as they play the game they interact with the game you constantly",
    "start": "229320",
    "end": "235680"
  },
  {
    "text": "collect these interaction advancing real-time and analyze them so depending on the way your gamer is engaging with",
    "start": "235680",
    "end": "242850"
  },
  {
    "text": "your game your feedback in real time back to your game experience so that way you can provide a more engaging",
    "start": "242850",
    "end": "249200"
  },
  {
    "text": "experience to your gamers so these are the very typical three phases as we see",
    "start": "249200",
    "end": "254549"
  },
  {
    "text": "people going through the vm streaming data journey at amazon kinesis we offer a variety of different services to cater",
    "start": "254549",
    "end": "261329"
  },
  {
    "start": "259000",
    "end": "395000"
  },
  {
    "text": "to these different scenarios to help you get started with a streaming data journey the first service we have a time",
    "start": "261329",
    "end": "267780"
  },
  {
    "text": "kinesis caught Kinesis dreams it was the first service we launched about three and four years ago and so kinesis stream",
    "start": "267780",
    "end": "274889"
  },
  {
    "text": "is stores the data as a continuous stream and it enables you to build your",
    "start": "274889",
    "end": "279990"
  },
  {
    "text": "own customer applications to process the data in whatever way you require so if",
    "start": "279990",
    "end": "285690"
  },
  {
    "text": "we recall the previous slides Kinesis stream is actually targeted for more sophisticated use cases which is the",
    "start": "285690",
    "end": "291450"
  },
  {
    "text": "third phase I mentioned in the previous slide it's fully flexible you decide how you're going to collect your data how",
    "start": "291450",
    "end": "297330"
  },
  {
    "text": "are you going to partition your data how you're going to read and process your data then we have the second service",
    "start": "297330",
    "end": "303150"
  },
  {
    "text": "called Kinesis fire hose which we launched our ring then last year so Phi house is a service that delivers your",
    "start": "303150",
    "end": "309870"
  },
  {
    "text": "streaming data into destinations in real-time manner and today firehose support amazon s3 rash of and elastic",
    "start": "309870",
    "end": "317850"
  },
  {
    "text": "serve Research Service and supported destination and you can probably tell it fits well for the first phase of the",
    "start": "317850",
    "end": "324570"
  },
  {
    "text": "user adoption cycle I mentioned in the previous slide so you still use and analyze the data in the tools and data",
    "start": "324570",
    "end": "331350"
  },
  {
    "text": "stores that are you are familiar with but instead of waiting for the data to show up hours later or days later now",
    "start": "331350",
    "end": "338130"
  },
  {
    "text": "you get that in minutes or seconds then we have this third service it's doing preview right now we pre announced that",
    "start": "338130",
    "end": "345060"
  },
  {
    "text": "ring then last year it's called Kinesis enter dates so what it does is it allows you to write standard sequel against the",
    "start": "345060",
    "end": "352620"
  },
  {
    "text": "data stream so basically you write a sequel perform an analysis not against the relational database you write a",
    "start": "352620",
    "end": "358800"
  },
  {
    "text": "sequel to query and analyze date against the real-time data stream so that fits well for the second use case the second",
    "start": "358800",
    "end": "365760"
  },
  {
    "text": "phase of the top shin cycle i just mentioned in the previous slide which is data streaming data insights they data",
    "start": "365760",
    "end": "372900"
  },
  {
    "text": "analysis against the data stream so it's in preview if you guys go to our website check it out you can sign up and play",
    "start": "372900",
    "end": "379020"
  },
  {
    "text": "with it so as you can see amazon can use this as a platform for streaming data we",
    "start": "379020",
    "end": "384630"
  },
  {
    "text": "offer a variety of services and capabilities so depending on where you are with your streaming their journey what is your use case you can always",
    "start": "384630",
    "end": "392220"
  },
  {
    "text": "find a right fit for you at amazon kinesis so let's go a bit deeper and to",
    "start": "392220",
    "end": "397979"
  },
  {
    "start": "395000",
    "end": "408000"
  },
  {
    "text": "Kinesis streams you recall it stores the data as it continued Stream allows you and enables you to",
    "start": "397979",
    "end": "403450"
  },
  {
    "text": "build your own application with your own tool to analyze and process your data so",
    "start": "403450",
    "end": "409000"
  },
  {
    "start": "408000",
    "end": "451000"
  },
  {
    "text": "look at this graph on the very left hand side which is we call data producers so",
    "start": "409000",
    "end": "414070"
  },
  {
    "text": "you configure your data producers it could be hundreds or thousands of data producers being application servers",
    "start": "414070",
    "end": "420490"
  },
  {
    "text": "mobile devices to continuously push data into your Kinesis stream then on the",
    "start": "420490",
    "end": "425980"
  },
  {
    "text": "right hand side you can use a tool for your choice it could be Kinesis client library could be a spark streaming storm",
    "start": "425980",
    "end": "432580"
  },
  {
    "text": "to read the data out of the Kinesis cream and process it with your own",
    "start": "432580",
    "end": "437800"
  },
  {
    "text": "custom logic so you have full control of how the stream is going to be organized how you scale the stream how you should",
    "start": "437800",
    "end": "444250"
  },
  {
    "text": "partition the data how you should read the data and how you should process the data it's fully flexible then a bit",
    "start": "444250",
    "end": "452470"
  },
  {
    "start": "451000",
    "end": "496000"
  },
  {
    "text": "about fire hose if you look at this diagram on the left hand side is fairly similar to canisius streams you",
    "start": "452470",
    "end": "458470"
  },
  {
    "text": "configure your data producers to continuously push data into the Kinesis fire hose however on the right hand side",
    "start": "458470",
    "end": "465490"
  },
  {
    "text": "it's a bit different you don't need to write a single line of code you don't need to write a custom and application",
    "start": "465490",
    "end": "470500"
  },
  {
    "text": "firehouse automatically delivers data into the destination airy configure again today we support s3 redshift and",
    "start": "470500",
    "end": "478480"
  },
  {
    "text": "Alaska search so all you do is it push the data into the fire hose devstream then we automatically manage the rest",
    "start": "478480",
    "end": "485710"
  },
  {
    "text": "for you you just sit there and wait for your data to show up into these destinations seconds later or minutes",
    "start": "485710",
    "end": "491770"
  },
  {
    "text": "later depending on your buffering configurations which we will cover a bit later on so then we'll go a bit deeper",
    "start": "491770",
    "end": "500110"
  },
  {
    "start": "496000",
    "end": "521000"
  },
  {
    "text": "on fire hosts the reason is because files as I mentioned the accelerated data ingest transform and load that's",
    "start": "500110",
    "end": "507760"
  },
  {
    "text": "the entry point to streaming data and we build files for that exact reason it's real easy which I'll show you a little",
    "start": "507760",
    "end": "515260"
  },
  {
    "text": "bit later on see how easy it is to use the service and to getting started with the streaming data and so will go to the",
    "start": "515260",
    "end": "523419"
  },
  {
    "start": "521000",
    "end": "541000"
  },
  {
    "text": "Kinesis console so all Kinesis services will be live in the same amazon kinesis console so if you go to Erebus console",
    "start": "523420",
    "end": "529990"
  },
  {
    "text": "click on amazon kinesis today you're going to see two services streams and fire hose in the",
    "start": "529990",
    "end": "535060"
  },
  {
    "text": "very near future you're going to see Keynesian Eric's here as well so you click on fire hose console then you'll",
    "start": "535060",
    "end": "541480"
  },
  {
    "start": "541000",
    "end": "575000"
  },
  {
    "text": "see this and page look very familiar typical and ADA based console you I first let's talk about about Amazon s3",
    "start": "541480",
    "end": "548410"
  },
  {
    "text": "destination so what do you configure step one you pick s3 as a destination",
    "start": "548410",
    "end": "553450"
  },
  {
    "text": "and configure at the livery stream name and choose an s3 bucket at your own for",
    "start": "553450",
    "end": "558880"
  },
  {
    "text": "us to deliver the data into optionally you can configure prefix so in case you",
    "start": "558880",
    "end": "564010"
  },
  {
    "text": "use the bucket for multiple purpose we link will basically add this prefix into",
    "start": "564010",
    "end": "569680"
  },
  {
    "text": "the objects we deliver to s3 bucket so that you can distinguish for your down streaming workflows step 2 a couple of",
    "start": "569680",
    "end": "576640"
  },
  {
    "start": "575000",
    "end": "659000"
  },
  {
    "text": "configuration options the first one is buffering so file host buffers streaming data in micro batches before we send it",
    "start": "576640",
    "end": "583990"
  },
  {
    "text": "to s3 that way it's more efficient to load data into your s3 bucket it's more cost-effective for you but for options",
    "start": "583990",
    "end": "591880"
  },
  {
    "text": "can be configured around to different options either you can configure buffer size which is in megabytes or you can",
    "start": "591880",
    "end": "597700"
  },
  {
    "text": "configure buffering interval which is in seconds so you can configure both options and whichever option satisfies",
    "start": "597700",
    "end": "604060"
  },
  {
    "text": "first will trigger the data delivery to your s3 bucket optionally you can",
    "start": "604060",
    "end": "609280"
  },
  {
    "text": "configure it to let fire hose to compress your data before we send the data to your s3 or you can configure an",
    "start": "609280",
    "end": "615310"
  },
  {
    "text": "input encryption option where fire hose will invoke a KMS key that young for",
    "start": "615310",
    "end": "620410"
  },
  {
    "text": "data encryption on the s3 site and then we have this iron role for security control so you explicitly allow fire",
    "start": "620410",
    "end": "627970"
  },
  {
    "text": "hose to access your s3 bucket and no one else within a degree it's going to be able to access your s3 bucket other than",
    "start": "627970",
    "end": "633820"
  },
  {
    "text": "the fire hose service principle so afterwards you click on next so you review all the configurations click on",
    "start": "633820",
    "end": "640600"
  },
  {
    "text": "finish and it's as easy as that so 30 seconds or maybe 60 seconds later now",
    "start": "640600",
    "end": "646510"
  },
  {
    "text": "you've set up a streaming data pipeline all you need to do right now is to have our producers to push data to fire hose",
    "start": "646510",
    "end": "652990"
  },
  {
    "text": "then the data is just going to continuously show up in s3 bucket it's as easy as that now rash of destination",
    "start": "652990",
    "end": "660790"
  },
  {
    "start": "659000",
    "end": "742000"
  },
  {
    "text": "so the way rash of works is we first fire hose will still deliver the data to",
    "start": "660790",
    "end": "666130"
  },
  {
    "text": "s3 bucket and will continuously issue a copy command to load the data from your s3",
    "start": "666130",
    "end": "671470"
  },
  {
    "text": "bucket to our ratio of cluster there are two reasons for doing this number one is",
    "start": "671470",
    "end": "677020"
  },
  {
    "text": "loading data from s3 to recive is still the most efficient way for us to load it into rest of today so that we make sure",
    "start": "677020",
    "end": "683860"
  },
  {
    "text": "it doesn't consume much of your resource on the redshift side so that you can continuously to run your queries of",
    "start": "683860",
    "end": "689800"
  },
  {
    "text": "complex analysis against your rash of tables the second reason is for whatever reason your rest of class is not",
    "start": "689800",
    "end": "697240"
  },
  {
    "text": "accessible for example if your rash of clusters on a maintenance or you're doing an upgrade or maybe you are",
    "start": "697240",
    "end": "702610"
  },
  {
    "text": "changing our database schema then we always have a place to hold your data so you never lose any data we always have a",
    "start": "702610",
    "end": "709510"
  },
  {
    "text": "copy of your data in the s3 bucket and for certain use cases actually people use ratio for analysis they also want to",
    "start": "709510",
    "end": "717100"
  },
  {
    "text": "have a copy in s3 for other different purposes people might run a Hadoop job against these objects so we offer that",
    "start": "717100",
    "end": "723070"
  },
  {
    "text": "capability for you in configuration wise as you can see other than the s3 options apparently you got to have to tell",
    "start": "723070",
    "end": "729640"
  },
  {
    "text": "firehouse what's your rush of cluster database table name you want us to load the data into you can also configure",
    "start": "729640",
    "end": "736570"
  },
  {
    "text": "ratio of copy options for more customized data load interracial so that",
    "start": "736570",
    "end": "743590"
  },
  {
    "start": "742000",
    "end": "867000"
  },
  {
    "text": "is rare shift actually again it's very simple Africa Lacan finish now you've set up streaming data pipeline into your",
    "start": "743590",
    "end": "750220"
  },
  {
    "text": "rash of table then lastly it's the last search and destination we launched the",
    "start": "750220",
    "end": "755740"
  },
  {
    "text": "last such destination back in April during the Chicago summit and so again",
    "start": "755740",
    "end": "760960"
  },
  {
    "text": "fairly similar you configure a last search cluster tell us your index name and type name fire hose can also the",
    "start": "760960",
    "end": "767470"
  },
  {
    "text": "index rotation for those of you who are familiar with elastic search it often doesn't serve as a long-term permanent",
    "start": "767470",
    "end": "773620"
  },
  {
    "text": "storage so often people rotate the index over time so you can retire the older ones over time and I'm going to keep the",
    "start": "773620",
    "end": "779440"
  },
  {
    "text": "most fresh one so fire hose can rotate the index in an hourly daily weekly and",
    "start": "779440",
    "end": "784960"
  },
  {
    "text": "monthly manner you can just configure that and then we have this backup option to back up back up your data to s3 there",
    "start": "784960",
    "end": "793090"
  },
  {
    "text": "are two options you can configure you can either choose the backup fill documents or you can choose to backup or",
    "start": "793090",
    "end": "799090"
  },
  {
    "text": "documents we new pic fill documents only what happens is if for whatever reason we're not able",
    "start": "799090",
    "end": "805640"
  },
  {
    "text": "to deliver data to your last search cluster will automatically send it back up to the s3 bucket so that you know hey",
    "start": "805640",
    "end": "812780"
  },
  {
    "text": "what are the documents that haven't been delivered to my research cluster and you can backfill later on or you can enable",
    "start": "812780",
    "end": "819440"
  },
  {
    "text": "auto cumin backup which essentially tributes to concurrent flow one flow we continuously streaming the data into",
    "start": "819440",
    "end": "826280"
  },
  {
    "text": "your last search index and the second flow is we continuous deliver the same data into s3 bucket again you oftentimes",
    "start": "826280",
    "end": "834260"
  },
  {
    "text": "customer we see customers have two different use cases one is I want to leverage Alaska search for some",
    "start": "834260",
    "end": "840080"
  },
  {
    "text": "real-time dashboarding through Cabana or some real-time search for Napoles but at the same time I have more complicated",
    "start": "840080",
    "end": "846200"
  },
  {
    "text": "analysis with my Hadoop job so I also want to keep it keep a copy of my day rate and s3 well I can run my EMR job so",
    "start": "846200",
    "end": "854630"
  },
  {
    "text": "it is as easy as that these are the configurations for last search again 30 seconds or 60 seconds later now you've",
    "start": "854630",
    "end": "861230"
  },
  {
    "text": "got a streaming data pipeline that skills elastically to send data to your eyelashes cluster in real time so as you",
    "start": "861230",
    "end": "868910"
  },
  {
    "start": "867000",
    "end": "919000"
  },
  {
    "text": "can probably tell the objective of fire hose is really we try to abstract away",
    "start": "868910",
    "end": "874430"
  },
  {
    "text": "as many things as possible from you so that it's as easy as for you to get started but normally the downside of",
    "start": "874430",
    "end": "881030"
  },
  {
    "text": "doing that is then you lose some sort of transparency and visibility into what's going on behind the scene now to",
    "start": "881030",
    "end": "887990"
  },
  {
    "text": "compensate that if I always offers a lot of modern capabilities so that is stupid a lot of transparency and visibility",
    "start": "887990",
    "end": "893390"
  },
  {
    "text": "into what's going on and we offer many CloudWatch metrics where you can clearly monitor and see your data flowing from",
    "start": "893390",
    "end": "900620"
  },
  {
    "text": "your data producer to the fios service and how file hosted over the data into your destination you can see how many",
    "start": "900620",
    "end": "907040"
  },
  {
    "text": "bytes of data have been delivered and transferred how many workers have been delivered and transfer if there's any",
    "start": "907040",
    "end": "912650"
  },
  {
    "text": "failure or not so that's the metrics and if there's any failure we'll also lock the error message through claw watch",
    "start": "912650",
    "end": "919220"
  },
  {
    "start": "919000",
    "end": "942000"
  },
  {
    "text": "logs so for example if for whatever reason we're not able to deliver data to your destination will log in an error",
    "start": "919220",
    "end": "925790"
  },
  {
    "text": "message to your car wash law group so that you can clearly see what's going on so clutch metrics tells you what's going",
    "start": "925790",
    "end": "932240"
  },
  {
    "text": "on are things working are things not working and these error message helps you to travel through the issue if we",
    "start": "932240",
    "end": "938610"
  },
  {
    "text": "figure things are not working for whatever reason so this is monitoring lastly I'm gonna touch a bit on very",
    "start": "938610",
    "end": "946230"
  },
  {
    "start": "942000",
    "end": "971000"
  },
  {
    "text": "simple touch Leon on pricing again pricing is very simple one dimension nothing else we charge 3.5 cents for",
    "start": "946230",
    "end": "954840"
  },
  {
    "text": "every gigabyte of data that ingest through fire hose so it's very predictable for your costs as long as",
    "start": "954840",
    "end": "961110"
  },
  {
    "text": "you understand how much data you're going to send through fire hose then you have a clear understanding of how much it's going to cost for you to run the",
    "start": "961110",
    "end": "967440"
  },
  {
    "text": "streaming data pipeline on fire hose so this is from my sight now we have more",
    "start": "967440",
    "end": "973770"
  },
  {
    "start": "971000",
    "end": "990000"
  },
  {
    "text": "exciting stuff from Alan he's going to share with you guys how weirdo calm has been using streaming data in their",
    "start": "973770",
    "end": "980190"
  },
  {
    "text": "company and placing joining to welcome Alan to the stage morning everyone I'm",
    "start": "980190",
    "end": "990660"
  },
  {
    "text": "really excited to share with you today what our experience has been using Kinesis to build a particular product at",
    "start": "990660",
    "end": "997140"
  },
  {
    "text": "realtor.com over the last few months so a few days from now or even a few hours from now you'll probably forgotten most",
    "start": "997140",
    "end": "1003080"
  },
  {
    "text": "of what you've heard here today so recognizing that I wanted to stay up front what are the key takeaways that I",
    "start": "1003080",
    "end": "1008240"
  },
  {
    "text": "would like you to remember above all else from this session in my experience amazon kinesis has been simple reliable",
    "start": "1008240",
    "end": "1016820"
  },
  {
    "text": "and it's offered great performance I consider to be a transformative building",
    "start": "1016820",
    "end": "1021830"
  },
  {
    "text": "block with broad applicability you can use it in all sorts of ways and I'll demonstrate what that means throughout",
    "start": "1021830",
    "end": "1027199"
  },
  {
    "text": "the talk and last it's a building block that's an enabler for what I call real time everywhere which is a something",
    "start": "1027200",
    "end": "1034310"
  },
  {
    "text": "that were many of us are striving for today a little bit about real calm I",
    "start": "1034310",
    "end": "1039920"
  },
  {
    "start": "1037000",
    "end": "1073000"
  },
  {
    "text": "don't presume that you know much about who we are so I wanted to tell you a little bit realtor.com was the first national us real estate search site in",
    "start": "1039920",
    "end": "1046880"
  },
  {
    "text": "fact we're celebrating our 20-year anniversary this year so we've been around around a while we pride ourselves",
    "start": "1046880",
    "end": "1052010"
  },
  {
    "text": "on having the most accurate real estate content very important if you're looking for homes that you have up-to-date data there we get data from 99 percent of",
    "start": "1052010",
    "end": "1059750"
  },
  {
    "text": "MLS's in the US MLS's are if you don't know the place for most real estate listings originated in the first place",
    "start": "1059750",
    "end": "1065450"
  },
  {
    "text": "so we have bread and we have scale we have 55 million unique users just to realtor.com alone",
    "start": "1065450",
    "end": "1070480"
  },
  {
    "text": "in the month of April our cloud strategy has been really to go all in on cloud we",
    "start": "1070480",
    "end": "1077380"
  },
  {
    "text": "want to shut down our data centers and we're well underway in getting there and most of that investment has has gone",
    "start": "1077380",
    "end": "1083080"
  },
  {
    "text": "into AWS and we're very happy with our experiences as far and we're about midway through so we have major systems",
    "start": "1083080",
    "end": "1089050"
  },
  {
    "text": "already serving traffic in production out of AWS including a big parts rpi infrastructure our search infrastructure",
    "start": "1089050",
    "end": "1095770"
  },
  {
    "text": "our geo services photos and more are all at AWS today and the rest of that stuff is well under land development and our",
    "start": "1095770",
    "end": "1102820"
  },
  {
    "text": "approach specifically has been to have a strong bias towards AWS managed services",
    "start": "1102820",
    "end": "1108130"
  },
  {
    "text": "so we love bc2 we love writing code ourselves but we also want to you know use the most of the managed services",
    "start": "1108130",
    "end": "1115030"
  },
  {
    "text": "things like Kinesis like red shift to take a lot of the administration work",
    "start": "1115030",
    "end": "1120280"
  },
  {
    "text": "out of our hands so we can focus on those things that really provide the value add for us specifically so the",
    "start": "1120280",
    "end": "1128050"
  },
  {
    "start": "1126000",
    "end": "1177000"
  },
  {
    "text": "example I'm going to talk about today is a new product that we launched a few months ago and but first I want to walk you through the customer problems you",
    "start": "1128050",
    "end": "1134050"
  },
  {
    "text": "really understand why we built the product and what were the constraints that we were facing so if you think about if you're real estate agent you",
    "start": "1134050",
    "end": "1139750"
  },
  {
    "text": "have all of your listings on realtor.com and you get a lot of visibility you get a lot of interested buyers for your",
    "start": "1139750",
    "end": "1145030"
  },
  {
    "text": "clients through through this portal but those listings they get a lot of traffic at the start when something is first",
    "start": "1145030",
    "end": "1150760"
  },
  {
    "text": "listed but that that decays over time because the default sort is most recent",
    "start": "1150760",
    "end": "1155830"
  },
  {
    "text": "first just a natural thing where you get a lot of traffic up front now if you're if you're an agent you really you could",
    "start": "1155830",
    "end": "1162820"
  },
  {
    "text": "buy more exposure for your listings but you really only want people who are interested in those listings to see them you don't want people who are searching",
    "start": "1162820",
    "end": "1168430"
  },
  {
    "text": "in Palo Alto to see listings from San Jose and if you're an agent you also might want to get more brand exposure in",
    "start": "1168430",
    "end": "1174490"
  },
  {
    "text": "search so this is the problems we wanted to solve but the product that we launched so the product is called it's the turbo listings product it's a native",
    "start": "1174490",
    "end": "1181240"
  },
  {
    "start": "1177000",
    "end": "1221000"
  },
  {
    "text": "ad product that allows customers to purchase more exposure for their listings in search but that exposure",
    "start": "1181240",
    "end": "1188380"
  },
  {
    "text": "will be a hundred percent relevant so you can't buy your exposure for your listings outside of the area they're",
    "start": "1188380",
    "end": "1194980"
  },
  {
    "text": "actually in so it's a one hundred percent relevant ad product which is a thing to do and we're very proud of",
    "start": "1194980",
    "end": "1201500"
  },
  {
    "text": "having built that and a particular thing it allows you as you see here for agents to get their their profile photo in",
    "start": "1201500",
    "end": "1207020"
  },
  {
    "text": "search which another value add so the requirements of this product and some meant that really was going to be really",
    "start": "1207020",
    "end": "1213170"
  },
  {
    "text": "difficult for us to use an off-the-shelf ad server to build this product which means we're really faced with having to",
    "start": "1213170",
    "end": "1219350"
  },
  {
    "text": "solve these problems ourselves and so the broad technical requirements here is this is an ad product it's being put on",
    "start": "1219350",
    "end": "1226910"
  },
  {
    "start": "1221000",
    "end": "1262000"
  },
  {
    "text": "a site that has you immense scale so we really have we have to have something that handles the extreme throughput and",
    "start": "1226910",
    "end": "1233150"
  },
  {
    "text": "has to be available 24-7 with where we're at in our cloud migration where we",
    "start": "1233150",
    "end": "1238610"
  },
  {
    "text": "have systems sitting in AWS we have other is sitting in our data centers and our AWS build-out includes a lot of",
    "start": "1238610",
    "end": "1244520"
  },
  {
    "text": "different VP sees a lot of different security requirements within that we needed something that was really flexible so it worked you know within",
    "start": "1244520",
    "end": "1250640"
  },
  {
    "text": "this this hybrid state that we're in currently and in particular with it's a paid product so we needed this data to",
    "start": "1250640",
    "end": "1256940"
  },
  {
    "text": "flow into an auditable secure billing database I'll talk about that a little bit more later on so faced with these",
    "start": "1256940",
    "end": "1264140"
  },
  {
    "start": "1262000",
    "end": "1298000"
  },
  {
    "text": "requirements why do we choose Kinesis so we knew from previous experience just from experimenting with it and using it",
    "start": "1264140",
    "end": "1269780"
  },
  {
    "text": "on smaller projects that it has great performance we knew that upfront but in",
    "start": "1269780",
    "end": "1275240"
  },
  {
    "text": "this particular case we really liked the multi producer multi consumer model that's something you'll hear a lot about",
    "start": "1275240",
    "end": "1281480"
  },
  {
    "text": "or see if you read the documentation of can use just this concept of data producers things feeding data in and",
    "start": "1281480",
    "end": "1287270"
  },
  {
    "text": "data consumers things pulling data out of the queues and we wanted or we chose",
    "start": "1287270",
    "end": "1292850"
  },
  {
    "text": "Kinesis because it is a worry-free managed service so it fit the bill with our overall cloud strategy so here's the",
    "start": "1292850",
    "end": "1299990"
  },
  {
    "start": "1298000",
    "end": "1356000"
  },
  {
    "text": "overall simplified architecture of this product and I'll pause here for a second and walk you through so you can understand how the data flows so most of",
    "start": "1299990",
    "end": "1306920"
  },
  {
    "text": "the data flows here is left to right and the data in this in this diagram is impressions data so impressions ad",
    "start": "1306920",
    "end": "1312950"
  },
  {
    "text": "impressions originate from our front ends both from our web front-ends and form our native mobile apps that's a",
    "start": "1312950",
    "end": "1318770"
  },
  {
    "text": "real calm website our native apps and that data flows through their respective backends and then those back-end these",
    "start": "1318770",
    "end": "1324710"
  },
  {
    "text": "are this decision how server-side are feeding data into the Kinesis streams these are the data producers and then we",
    "start": "1324710",
    "end": "1330920"
  },
  {
    "text": "have multiple systems that are play data out of the keys to streams on the right so the one in pink there in the",
    "start": "1330920",
    "end": "1336400"
  },
  {
    "text": "middle it's the campaign manager I'll go into that more detail and we also have our billing flow which is separate and",
    "start": "1336400",
    "end": "1342100"
  },
  {
    "text": "that's pulling data out these are the data consumers and then downstream from there that data flows into other systems",
    "start": "1342100",
    "end": "1347500"
  },
  {
    "text": "it goes back into a search back end and it goes into other systems like our sales system Enterprise reporting",
    "start": "1347500",
    "end": "1352960"
  },
  {
    "text": "billing and so on okay so what about the",
    "start": "1352960",
    "end": "1358660"
  },
  {
    "start": "1356000",
    "end": "1400000"
  },
  {
    "text": "data itself so the data going into the streams is the impressions data and this is an example of an impressions data and",
    "start": "1358660",
    "end": "1364990"
  },
  {
    "text": "it's very straightforward and simple and this is what we strive for simplicity in the data so we can be used in all sorts",
    "start": "1364990",
    "end": "1370090"
  },
  {
    "text": "of flexible ways downstream so an impression in this context it's a set of main value pairs starting with the",
    "start": "1370090",
    "end": "1377620"
  },
  {
    "text": "campaign ID what ad campaign is the impression for what's the unique ID of the impression itself who is the",
    "start": "1377620",
    "end": "1385030"
  },
  {
    "text": "customer of the the ad campaign where did it originate from some more metadata about the the application and then some",
    "start": "1385030",
    "end": "1392410"
  },
  {
    "text": "metadata about the user and this helps us do things like scrape out bought impressions so we're only charging for",
    "start": "1392410",
    "end": "1397540"
  },
  {
    "text": "real user impressions a little bit more about one of the two data consumers and",
    "start": "1397540",
    "end": "1404740"
  },
  {
    "start": "1400000",
    "end": "1452000"
  },
  {
    "text": "this is a systems diagram of the what's called a campaign manager so on the left",
    "start": "1404740",
    "end": "1409870"
  },
  {
    "text": "you have the Kinesis stream and you have a lambda function pulling data out of",
    "start": "1409870",
    "end": "1414910"
  },
  {
    "text": "the stream and then it's posting each impression event to a web service sitting in ec2 and that web service it's",
    "start": "1414910",
    "end": "1421570"
  },
  {
    "text": "what the campaign manager is a set of web services that encapsulates a logic for the life cycle events of these ad",
    "start": "1421570",
    "end": "1427450"
  },
  {
    "text": "campaigns so each event that gets posted then gets decremented from the right",
    "start": "1427450",
    "end": "1432820"
  },
  {
    "text": "campaign now the campaign manager is not storing the details of each impression it just wants to decrement that each",
    "start": "1432820",
    "end": "1438610"
  },
  {
    "text": "impression from the correct campaign and on the right there in this case it happens to postgres database managed by",
    "start": "1438610",
    "end": "1445720"
  },
  {
    "text": "RDS that's the width holds the current remaining impressions for each campaign",
    "start": "1445720",
    "end": "1451950"
  },
  {
    "text": "the second data consumer is a little bit more complicated and this is the billing flow so the target here is to get this",
    "start": "1451950",
    "end": "1458440"
  },
  {
    "start": "1452000",
    "end": "1531000"
  },
  {
    "text": "data into redshift and that redshift database contains the full details of each and every impressions both for",
    "start": "1458440",
    "end": "1464169"
  },
  {
    "text": "auditing and for billing purposes we only charged for impressions delivered and both ourselves and for their parties",
    "start": "1464169",
    "end": "1469570"
  },
  {
    "text": "want to make sure that that record is is auditable and it's kept secure it's isolated it's sox compliant so it's in a",
    "start": "1469570",
    "end": "1475840"
  },
  {
    "text": "private subnet so in order to work around this we did have to build out somewhere systems to get data from",
    "start": "1475840",
    "end": "1482800"
  },
  {
    "text": "Kinesis into redshift while keeping the data encrypted along the way so the target here for from fire hose is to",
    "start": "1482800",
    "end": "1489460"
  },
  {
    "text": "pipe data from the Kinesis stream into s3 in an encrypted state and then this",
    "start": "1489460",
    "end": "1494650"
  },
  {
    "text": "control flow which is powered by lambda by dynamo and by the AWS key management service is what helps keep the data",
    "start": "1494650",
    "end": "1501370"
  },
  {
    "text": "encrypted so that by the time it gets into red shift in the private subnet it's an encrypted state so i won't go",
    "start": "1501370",
    "end": "1508480"
  },
  {
    "text": "into detail there happy to talk about the specifics after the talk but all this infrastructure was to solve that",
    "start": "1508480",
    "end": "1514750"
  },
  {
    "text": "problem with keeping data encrypted but the point it gets into redshift and something else to notice here is this is",
    "start": "1514750",
    "end": "1520810"
  },
  {
    "text": "entirely service serverless it's completely buzzword compliant so all the logic is kept within lambda functions",
    "start": "1520810",
    "end": "1526450"
  },
  {
    "text": "and we're using s3 sort of AWS services along the way little bit more about",
    "start": "1526450",
    "end": "1533350"
  },
  {
    "start": "1531000",
    "end": "1572000"
  },
  {
    "text": "redshift so ray talked about how you can configure data in batches so this relies",
    "start": "1533350",
    "end": "1538510"
  },
  {
    "text": "on that configuration of data being put into batches and specific increments in s3 and then we can change that batch",
    "start": "1538510",
    "end": "1544450"
  },
  {
    "text": "size so this is shows that with this is pulling data into red shift in 15-minute increments so every time we notice that",
    "start": "1544450",
    "end": "1552160"
  },
  {
    "text": "there is a new file and s3 then that gets picked up and gets piped into redshift we can change the frequency by",
    "start": "1552160",
    "end": "1557260"
  },
  {
    "text": "just changing the configuration on a fire hose and then we don't have to change anything else every new file that gets gets put there will get put into",
    "start": "1557260",
    "end": "1563740"
  },
  {
    "text": "redshift we don't have to configure the timing at any point other than the configuration on the fire hose console",
    "start": "1563740",
    "end": "1571320"
  },
  {
    "start": "1572000",
    "end": "1595000"
  },
  {
    "text": "little bit more about the outcomes so we were able to achieve huge scale here so we're serving millions of impressions",
    "start": "1573420",
    "end": "1579640"
  },
  {
    "text": "per day on just to canisius shards so it's very cost-effective but we've tested this up to 20 times our current",
    "start": "1579640",
    "end": "1586390"
  },
  {
    "text": "site traffic and basically we weren't able to break it with the low testers we had so we're very confident we can scale",
    "start": "1586390",
    "end": "1592090"
  },
  {
    "text": "well beyond our current site traffic and we're getting great performance so the",
    "start": "1592090",
    "end": "1598030"
  },
  {
    "start": "1595000",
    "end": "1637000"
  },
  {
    "text": "graphs on the upper right show you both the put and get latency that we're getting from Kinesis so it's in the low",
    "start": "1598030",
    "end": "1604150"
  },
  {
    "text": "tens of milliseconds there are very happy about that and but we do batch events as demonstrated for efficiency so",
    "start": "1604150",
    "end": "1611170"
  },
  {
    "text": "we minimize our costs there and for the case of billing we only do daily billing runs right now we don't need that to be",
    "start": "1611170",
    "end": "1617580"
  },
  {
    "text": "up-to-the-minute accurate but for those use cases like for customer reports those are fed off of the the campaign",
    "start": "1617580",
    "end": "1624220"
  },
  {
    "text": "manager streams those are in near real time so it's as all configurable based on our needs so in summary for our",
    "start": "1624220",
    "end": "1632320"
  },
  {
    "text": "purposes kinesis does give us real time data streaming which we're thrilled by",
    "start": "1632320",
    "end": "1637830"
  },
  {
    "text": "to summarize some of the lessons learned so as demonstrated in the billing float there is some complexity today with",
    "start": "1637830",
    "end": "1645130"
  },
  {
    "text": "getting data into red shift from Kinesis if you need it an encrypted state but we were able to work around that and so it",
    "start": "1645130",
    "end": "1651760"
  },
  {
    "text": "is doable even today rated and touch on some aspects of how data is duplicated",
    "start": "1651760",
    "end": "1659500"
  },
  {
    "text": "can be duplicated in in Kinesis this is not a common occurrence but you do need to work around what's your what do you",
    "start": "1659500",
    "end": "1666309"
  },
  {
    "text": "need for D duping data from Kinesis so for our billing purposes we never wanted to double bill for an impression so we",
    "start": "1666309",
    "end": "1672549"
  },
  {
    "text": "did have to consider that and make sure that we d do to data via redshift not",
    "start": "1672549",
    "end": "1678309"
  },
  {
    "text": "every application needs or that applications have different D do behaviors so just think about what you need and plan accordingly the simple key",
    "start": "1678309",
    "end": "1686500"
  },
  {
    "text": "value data structure that we have in Kinesis is already paying dividends we're able to analyze data really well",
    "start": "1686500",
    "end": "1692080"
  },
  {
    "text": "and this sets us up for using things like the Kinesis analytics down the road which will handle key value data",
    "start": "1692080",
    "end": "1697570"
  },
  {
    "text": "structures very well so the future for",
    "start": "1697570",
    "end": "1702700"
  },
  {
    "start": "1700000",
    "end": "1739000"
  },
  {
    "text": "us is a real-time pipeline we've done it in this particular product and this is a model that we're using down the road so",
    "start": "1702700",
    "end": "1708940"
  },
  {
    "text": "rain I didn't coordinate pictures but I like to think this is the same mountain where the bicyclist is being chased by",
    "start": "1708940",
    "end": "1714730"
  },
  {
    "text": "the bear so our goal is over all that we can collect data on page one and act on",
    "start": "1714730",
    "end": "1722559"
  },
  {
    "text": "that data by the time the user gets to page two so seconds later we're able to analyze vast amounts of data act on it",
    "start": "1722559",
    "end": "1728710"
  },
  {
    "text": "do things like provide recommendations customize experience for users and this technology",
    "start": "1728710",
    "end": "1733899"
  },
  {
    "text": "and other is provided by AWS really set us up to do that so to reiterate the",
    "start": "1733899",
    "end": "1741070"
  },
  {
    "start": "1739000",
    "end": "1774000"
  },
  {
    "text": "takeaways here and my experience Kinesis is simple it's extremely reliable and it",
    "start": "1741070",
    "end": "1747279"
  },
  {
    "text": "offers great performance it's a transformative building block that can be used in all sorts of applications you",
    "start": "1747279",
    "end": "1752980"
  },
  {
    "text": "just heard about one today but you can imagine using this in all sorts of ways wherever you need to stream data and it's an enabler for real time everywhere",
    "start": "1752980",
    "end": "1759789"
  },
  {
    "text": "for me with what we have today I've now flipped my thinking to think to assume real-time first rather than assume batch",
    "start": "1759789",
    "end": "1767080"
  },
  {
    "text": "so real time is the the assumption and then I only batch where needed it's a real mind flip finally we're hiring if",
    "start": "1767080",
    "end": "1777669"
  },
  {
    "start": "1774000",
    "end": "1808000"
  },
  {
    "text": "you're a software engineer product manager QA engineer data scientist pretty much anything come and talk to me after after the show hit me up on",
    "start": "1777669",
    "end": "1784299"
  },
  {
    "text": "Twitter would love to talk to you we have office here in Santa Clara just across the freeway and throughout the",
    "start": "1784299",
    "end": "1790239"
  },
  {
    "text": "the US and canada and thanks to Eddie you're in and sonal helped me put together this talk so x ray up we're",
    "start": "1790239",
    "end": "1797200"
  },
  {
    "text": "happy to take QA here publicly or after the show and we have a mic here happy to hear from you thank you alright thanks",
    "start": "1797200",
    "end": "1809440"
  },
  {
    "start": "1808000",
    "end": "1852000"
  },
  {
    "text": "guys again this concludes our session and hopefully all of you guys have got a preview sense of what streaming data is",
    "start": "1809440",
    "end": "1815259"
  },
  {
    "text": "how we can use streaming data you know what are the offerings we have here at amazon kinesis and also hopefully we'll",
    "start": "1815259",
    "end": "1821080"
  },
  {
    "text": "get a lot of inspiration from add-ins we will we use case and see how that might assume either my fitting to your own",
    "start": "1821080",
    "end": "1827259"
  },
  {
    "text": "organization so we'll probably hang around for little bit here and we have plenty of time before the keynote for",
    "start": "1827259",
    "end": "1832450"
  },
  {
    "text": "questions I think we have a mic here if you want to stay but I don't matter others both live and on video can hear your question yeah go ahead sure your",
    "start": "1832450",
    "end": "1845799"
  },
  {
    "text": "eye level architecture diagram and use the stream as well as the Pyro's yep I'm",
    "start": "1845799",
    "end": "1854200"
  },
  {
    "start": "1852000",
    "end": "2049000"
  },
  {
    "text": "going back to the diagram I mean why did you use your firewalls and streaming in",
    "start": "1854200",
    "end": "1859330"
  },
  {
    "text": "a during the data ingestion integral P no unless that it is something your lambda function is to a why not at the same",
    "start": "1859330",
    "end": "1867090"
  },
  {
    "text": "time you're sending you know sending your data to the stream as well as the",
    "start": "1867090",
    "end": "1874440"
  },
  {
    "text": "fire was so why is right so so firehose pics data off of the street so there's",
    "start": "1874440",
    "end": "1879450"
  },
  {
    "text": "one place that data is sent and because of the multi consumer model we can have like a fire hose pulling data off the",
    "start": "1879450",
    "end": "1886980"
  },
  {
    "text": "street I didn't mention if you're asking about why do we have lambda sitting in between fire hose right so in this thank",
    "start": "1886980",
    "end": "1893460"
  },
  {
    "text": "you for mentioning that so in this particular case the job of this first lambda function is to validate the data so we can't guarantee just because",
    "start": "1893460",
    "end": "1901200"
  },
  {
    "text": "there's there's no guarantee that we don't have a bug in one of the data producers that there's malformed with",
    "start": "1901200",
    "end": "1906900"
  },
  {
    "text": "json at the point it gets enters into the stream so that that's first lambda function and this flow here is its job",
    "start": "1906900",
    "end": "1913409"
  },
  {
    "text": "is simply to validate that it's valid JSON that's it so that we don't corrupt data by the time it gets to redshift",
    "start": "1913409",
    "end": "1920299"
  },
  {
    "text": "coming to that question again I why didn't you validate people going to the strains we do it just it's a matter of",
    "start": "1920299",
    "end": "1927240"
  },
  {
    "text": "you know making protecting downstream systems from bugs that could it you know occur before data hits the street would",
    "start": "1927240",
    "end": "1935220"
  },
  {
    "text": "you mind telling what is the frequency of your data per second very fast have",
    "start": "1935220",
    "end": "1942990"
  },
  {
    "text": "you experienced any throttling before while writing the caduceus stream I'm sorry have you pasted natraj being a you",
    "start": "1942990",
    "end": "1950340"
  },
  {
    "text": "know uh there are limits when you're writing in the Kinesis stream right and since you're using a to charge that's",
    "start": "1950340",
    "end": "1957299"
  },
  {
    "text": "the reason I asked what you're in a frequency for second right so those those charts are reasonably saturated",
    "start": "1957299",
    "end": "1963360"
  },
  {
    "text": "and but we we just part of the testing we did the testing involved you know increasing the number of shards you're",
    "start": "1963360",
    "end": "1969270"
  },
  {
    "text": "making that dynamic and testing that our scale overall as we hit it with larger scale that we could increase the number",
    "start": "1969270",
    "end": "1974640"
  },
  {
    "text": "of shards so we're very comfortable with the the capacity at the 22 shards but we also know that we can over time increase",
    "start": "1974640",
    "end": "1981120"
  },
  {
    "text": "the number of charts to handle even more data so I think we have some other other people asking questions behind you but happy to talk more after that I'm sure",
    "start": "1981120",
    "end": "1987419"
  },
  {
    "text": "okay thank you so one question with how it handles the data going in and",
    "start": "1987419",
    "end": "1993630"
  },
  {
    "text": "out we're talking to somebody wondering if Kinesis is HIPAA compliant does it",
    "start": "1993630",
    "end": "2000290"
  },
  {
    "text": "store the data anywhere just means just generally encrypted is it transferring it over the wire how does that behave",
    "start": "2000290",
    "end": "2007130"
  },
  {
    "text": "yeah so we're not hit by combining yet today but we are actively working on",
    "start": "2007130",
    "end": "2012590"
  },
  {
    "text": "that compliance and all the communication on the transport layer is",
    "start": "2012590",
    "end": "2017690"
  },
  {
    "text": "HCPs encrypt there however on the rest is not encrypted today but you can",
    "start": "2017690",
    "end": "2023210"
  },
  {
    "text": "always choose to encrypt the data before hand using can skew whatever tools that that you want to use for the encryption",
    "start": "2023210",
    "end": "2028940"
  },
  {
    "text": "so that even before the data gets to canisius it's already encrypted Thanks",
    "start": "2028940",
    "end": "2036190"
  },
  {
    "text": "my question was about trying to get the picture here there's a sort of clutter the actually acceptable customer like",
    "start": "2036190",
    "end": "2043070"
  },
  {
    "text": "this the impression tracking flow going to go back to that picture so here you",
    "start": "2043070",
    "end": "2051320"
  },
  {
    "start": "2049000",
    "end": "2446000"
  },
  {
    "text": "have a lambda pulling data from a key to stream my question is why why is this",
    "start": "2051320",
    "end": "2057260"
  },
  {
    "text": "not serve relation why is there amazon ec2 instance yeah it's great question so the campaign manager itself which is",
    "start": "2057260",
    "end": "2062870"
  },
  {
    "text": "actually best demonstrated by this diagram impression tracking is only one of its jobs so it's responsible so that",
    "start": "2062870",
    "end": "2069560"
  },
  {
    "text": "area in pink there that is a ruby on rails app it has multiple web services",
    "start": "2069560",
    "end": "2075020"
  },
  {
    "text": "exposed to handle all aspects of the lifecycle events for ad campaigns creation deletion impression",
    "start": "2075020",
    "end": "2081790"
  },
  {
    "text": "decrementing and so on so the logic of there it's it's at the moment a bit too",
    "start": "2081790",
    "end": "2087830"
  },
  {
    "text": "complex to say we're going to spread that across half a dozen or more lambda functions compared to encapsulating that",
    "start": "2087830",
    "end": "2094128"
  },
  {
    "text": "with an application that you know it's fully tested and it's it's self-contained the in this case in the",
    "start": "2094129",
    "end": "2100250"
  },
  {
    "text": "diagram the reason why there's a lambda function between the stream and the campaign manager is we wanted to keep",
    "start": "2100250",
    "end": "2106460"
  },
  {
    "text": "the campaign manager entirely web services based so that lambda functions",
    "start": "2106460",
    "end": "2111500"
  },
  {
    "text": "job is simply to pull data off stream and post data to web service we could have taken the campaign manager and used",
    "start": "2111500",
    "end": "2118040"
  },
  {
    "text": "the Kinesis client library to pull data off of stream but then we have something that's not entirely web services based",
    "start": "2118040",
    "end": "2123230"
  },
  {
    "text": "like there's multiple ways data can come so it's really just to keep architectural purity with with that",
    "start": "2123230",
    "end": "2129750"
  },
  {
    "text": "thing given its complexity and wanting to generally expose functionality through web services would you envision",
    "start": "2129750",
    "end": "2136859"
  },
  {
    "text": "maybe someday we writing at to be server this or if you were to do it mrs. certainly I think we're very happy with",
    "start": "2136859",
    "end": "2142589"
  },
  {
    "text": "the service model for the kinds of jobs that we're doing within the flow I mean obviously like here we're using it a lot",
    "start": "2142589",
    "end": "2147690"
  },
  {
    "text": "of different places but it just I think it'll take some time for for things to mature a little bit for us to tackle",
    "start": "2147690",
    "end": "2153809"
  },
  {
    "text": "more complicated workloads entirely serverless thank you question for the",
    "start": "2153809",
    "end": "2163020"
  },
  {
    "text": "fire roasting you have any plans to have different formats of file like parties RK or ever or something and although the",
    "start": "2163020",
    "end": "2170550"
  },
  {
    "text": "same time support like high partitioning of the data so we can use better tools on top of that instead of kind of adding",
    "start": "2170550",
    "end": "2177300"
  },
  {
    "text": "more in bluetooth on top of us yeah good question so we are actually we got a",
    "start": "2177300",
    "end": "2182339"
  },
  {
    "text": "many customer feedback around the same line so the objectives as you can see what file is does is to make it as",
    "start": "2182339",
    "end": "2188970"
  },
  {
    "text": "simple as possible to enable your dashing processing so very typically once the data are landing to s3 you are",
    "start": "2188970",
    "end": "2195329"
  },
  {
    "text": "very likely to run a Hadoop job right so you want to make sure its high partitioned we support different park a",
    "start": "2195329",
    "end": "2200940"
  },
  {
    "text": "formatter avro so that it's easier for your downstream Hadoop job and we are actually working on these things to make",
    "start": "2200940",
    "end": "2206700"
  },
  {
    "text": "sure that as we transfer the data into s3 bucket or we do some pre-processing so that once the data is in s3 it's much",
    "start": "2206700",
    "end": "2214380"
  },
  {
    "text": "easier for your dashing a tube job going",
    "start": "2214380",
    "end": "2221339"
  },
  {
    "text": "back to the previous slide you choose postgres as the RDS what are the reasons",
    "start": "2221339",
    "end": "2230760"
  },
  {
    "text": "for choosing postage vs why not go it and I nobody be so a lot of reasons one",
    "start": "2230760",
    "end": "2237690"
  },
  {
    "text": "so we are using multiple database engines in our AWS migration so we don't just pick one this particular system we",
    "start": "2237690",
    "end": "2245700"
  },
  {
    "text": "actually the Queen our experience post-crisis is really great at decrement operations so it's very fast there and",
    "start": "2245700",
    "end": "2252359"
  },
  {
    "text": "its job here is very simple and the team that happened to build the system has a lot of experience using postgres",
    "start": "2252359",
    "end": "2257970"
  },
  {
    "text": "so the combination of all those it was a very good fit here it's entirely isolated so because the system as a",
    "start": "2257970",
    "end": "2263099"
  },
  {
    "text": "whole as a web services based the database here is entirely self contained within the system there's no outside",
    "start": "2263099",
    "end": "2268710"
  },
  {
    "text": "systems pulling data from the relational database in this context thanks for the",
    "start": "2268710",
    "end": "2280080"
  },
  {
    "text": "presentation really good question so you talked about some challenges with the VPC were those around AWS lambda running",
    "start": "2280080",
    "end": "2290250"
  },
  {
    "text": "on BBC this is specifically that it was a specific challenge about the private subnet we haven't run into any",
    "start": "2290250",
    "end": "2296010"
  },
  {
    "text": "challenges with the V pieces itself and i know the services are adding a lot of native capabilities to play nicely with",
    "start": "2296010",
    "end": "2302280"
  },
  {
    "text": "v pcs so what was demonstrating the billing flow is really just particular to the data being encrypted and having",
    "start": "2302280",
    "end": "2309240"
  },
  {
    "text": "to traverse the private subnet boundary got it and just one of the question on Kinesis and firehouse with both of you",
    "start": "2309240",
    "end": "2316290"
  },
  {
    "text": "so you know you have the Kinesis stream and I saw you how the aw slam de that then goes into firehouse yeah why not",
    "start": "2316290",
    "end": "2322410"
  },
  {
    "text": "just use var hose you know send data into SVM you know we're facing the same situation where payments company we're",
    "start": "2322410",
    "end": "2328770"
  },
  {
    "text": "looking at do we really want to use Kinesis or do we just take the storage that we get with fire hose and then have",
    "start": "2328770",
    "end": "2334920"
  },
  {
    "text": "lambda running off of s3 when the data gets there can you just highlight that because I feel like that's right happy that every one of us probably want to",
    "start": "2334920",
    "end": "2341339"
  },
  {
    "text": "know so I think we I mean it was we were using Kinesis just as the baseline because there were multiple consumers of",
    "start": "2341339",
    "end": "2348180"
  },
  {
    "text": "the data not just fire hose so we weren't just using the batch case but fire hose it really did its job here of",
    "start": "2348180",
    "end": "2354300"
  },
  {
    "text": "you know taking summary data off of Kinesis and putting it into s3 buckets",
    "start": "2354300",
    "end": "2359730"
  },
  {
    "text": "and we couldn't go directly to red shift from can you fire hose because of the",
    "start": "2359730",
    "end": "2365089"
  },
  {
    "text": "data encryption issue and getting data into the private sub map okay thank you I have a couple questions with fire hose",
    "start": "2365089",
    "end": "2375000"
  },
  {
    "text": "um so I to my understanding firehouse is 41 redshift one table and one other",
    "start": "2375000",
    "end": "2382500"
  },
  {
    "text": "thing but are you are there any plans for making it be sending multiple data",
    "start": "2382500",
    "end": "2388680"
  },
  {
    "text": "to different redshift or have multiple tables with different copy commands instead of",
    "start": "2388680",
    "end": "2394780"
  },
  {
    "text": "producing multiple the same exact fire hose but with different copy commands yeah so that's also where am a feedback",
    "start": "2394780",
    "end": "2401890"
  },
  {
    "text": "we hear from many customers and we are active working on these things and like",
    "start": "2401890",
    "end": "2407830"
  },
  {
    "text": "basically today as you mentioned 15 hosted restream since they're 21 bucket",
    "start": "2407830",
    "end": "2413830"
  },
  {
    "text": "one table and one LS search index we're working on something that allows you to",
    "start": "2413830",
    "end": "2418990"
  },
  {
    "text": "go to multiple different entities of the destination but for now for most of the use cases if we're thinking about you",
    "start": "2418990",
    "end": "2425530"
  },
  {
    "text": "say five or 10 buckets or five or ten tables you can just easily work on that by having multiple streams you can",
    "start": "2425530",
    "end": "2431740"
  },
  {
    "text": "basically partition your data and at each of the five holes every screen thank you great there's no other",
    "start": "2431740",
    "end": "2439330"
  },
  {
    "text": "questions right now i'll be happy to chat afterwards and thank you again for your thanks again everyone",
    "start": "2439330",
    "end": "2445710"
  }
]
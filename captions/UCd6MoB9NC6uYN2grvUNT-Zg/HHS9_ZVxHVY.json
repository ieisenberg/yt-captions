[
  {
    "start": "0",
    "end": "58000"
  },
  {
    "text": "session of the first day of the really big breakout sessions uh my name is John",
    "start": "160",
    "end": "6160"
  },
  {
    "text": "this is Mick we're from a company called think near and we're going to talk about how we're serving billions of web",
    "start": "6160",
    "end": "11880"
  },
  {
    "text": "requests a day uh and we're built on elastic bean stock so what I'm going to talk about",
    "start": "11880",
    "end": "18560"
  },
  {
    "text": "today uh first we're going to go over some of the resources we made available um get that out of the way so you don't have to remember a lot of the really key",
    "start": "18560",
    "end": "25039"
  },
  {
    "text": "details you can take the high level Pieces away um and then apply that back uh when you're at work after um quick",
    "start": "25039",
    "end": "33000"
  },
  {
    "text": "intro who we are why do we choose elastic bean stock why are we still using elastic bean stock uh we're going",
    "start": "33000",
    "end": "38040"
  },
  {
    "text": "to go through our architecture in a fair bit of detail um the big pieces round and how it all fits together the",
    "start": "38040",
    "end": "43920"
  },
  {
    "text": "technology choices we made and then Mick is going to go through three of the particularly interesting areas where we",
    "start": "43920",
    "end": "50320"
  },
  {
    "text": "had challenges at scale and talk about how we overcame",
    "start": "50320",
    "end": "55480"
  },
  {
    "text": "those great um so the resources uh we'll just fly through these so we put a full",
    "start": "58480",
    "end": "64799"
  },
  {
    "text": "snapshot of our beanock config available online um have the URL on a sec um it's",
    "start": "64799",
    "end": "71680"
  },
  {
    "text": "got all our files related to how we're using grade log rotate how we're monitoring uh Unix tuning uh app server",
    "start": "71680",
    "end": "79200"
  },
  {
    "text": "tuning so it's got all the nitty-gritty details that we've gone through uh there's just too much there to actually cover in a",
    "start": "79200",
    "end": "84920"
  },
  {
    "text": "presentation uh and then we've also open sourced one of the key pieces we were missing which is how how do we get uh",
    "start": "84920",
    "end": "91400"
  },
  {
    "text": "lots and lots of logs into S3 in a reliable way and we couldn't find an existing um way uh open source so we",
    "start": "91400",
    "end": "98600"
  },
  {
    "text": "created one and we've open sourced that as well and then of course you can always get the slides after the fact um",
    "start": "98600",
    "end": "105040"
  },
  {
    "text": "so if you're looking at the slides now here are the URLs you care about uh we've got a Blog um that we write about",
    "start": "105040",
    "end": "111600"
  },
  {
    "text": "what we're doing and announce improvements so you can check that out for sure um and the goal is",
    "start": "111600",
    "end": "116719"
  },
  {
    "text": "presentations at the end you'll see what we've done and what works for us uh at",
    "start": "116719",
    "end": "121799"
  },
  {
    "text": "scale we are running tens of billions of requests a day um with anything of that size and doing high frequency requests",
    "start": "121799",
    "end": "128679"
  },
  {
    "text": "with low latency constraints you always have to test it yourself but this should at least give you a starting point and",
    "start": "128679",
    "end": "133680"
  },
  {
    "text": "the major pieces to consider and how we overcame the challenges we encountered that's particular to our",
    "start": "133680",
    "end": "139360"
  },
  {
    "text": "situation so who are we uh so think near is a hyper local",
    "start": "139360",
    "end": "145840"
  },
  {
    "text": "mobile advertising platform and that is a mouseful uh what that means is that we are buying ads on mobile devices so",
    "start": "145840",
    "end": "153680"
  },
  {
    "text": "anytime you're using the mobile web games you get those lovely banners that you love to click on the intertial ads",
    "start": "153680",
    "end": "160480"
  },
  {
    "text": "before you get to play your game uh whatever it might be we are a buying platform For Those ads uh hyperlocal",
    "start": "160480",
    "end": "167440"
  },
  {
    "text": "means that we are really focused on location so we think where you are matters for whether we're going to show",
    "start": "167440",
    "end": "173640"
  },
  {
    "text": "you relevant ads so we don't show you ads for Walmart we show you ads for the Walmart that's in your city with local",
    "start": "173640",
    "end": "180120"
  },
  {
    "text": "specials and it's relevant to you um quick history we're a pretty",
    "start": "180120",
    "end": "186120"
  },
  {
    "text": "small and young company so we founded uh in the in January of 2011 uh we were",
    "start": "186120",
    "end": "193680"
  },
  {
    "text": "doing a different product and fall of 2011 we started on the product we're talking about today which is the",
    "start": "193680",
    "end": "199280"
  },
  {
    "text": "advertising platform and we started with an engineering team of two uh we launched that platform to production in",
    "start": "199280",
    "end": "207040"
  },
  {
    "text": "Spring of the following year 2012 uh with an engineering team of three uh that got traction and we",
    "start": "207040",
    "end": "214720"
  },
  {
    "text": "actually sold that fall as things started to ramp up so we're now a business unit inside a larger company",
    "start": "214720",
    "end": "220519"
  },
  {
    "text": "called Telenav uh for the most part we run independently uh certainly all the it is still independent they act more",
    "start": "220519",
    "end": "226959"
  },
  {
    "text": "like uh investors and advisors and then we share some legal and HR resources on the back",
    "start": "226959",
    "end": "232360"
  },
  {
    "text": "end so we exist in an ecosystem called rtb mobile advertising and what this",
    "start": "232360",
    "end": "239480"
  },
  {
    "text": "means means is it's real time bidding so in real time when you're on your phone",
    "start": "239480",
    "end": "245400"
  },
  {
    "text": "and there's an opportunity to show a banner there's a request that goes out to what's called an ad exchange and they",
    "start": "245400",
    "end": "251799"
  },
  {
    "text": "have thousands of apps that are all sending them their advertising opportunities they pull this and then",
    "start": "251799",
    "end": "258239"
  },
  {
    "text": "they send a fire hose to us and our competitors with here are all the advertising opportunities available in",
    "start": "258239",
    "end": "265440"
  },
  {
    "text": "the USA and so we are listening to this fire hose hundreds of thousands of requests a second and picking out the",
    "start": "265440",
    "end": "271800"
  },
  {
    "text": "ones we want for our advertisers and we have a a large number of advertisers who are using us to buy their mobile ads and",
    "start": "271800",
    "end": "278919"
  },
  {
    "text": "they all have kind of different requirements they're trying to reach different demographics people in different parts of the country and so we",
    "start": "278919",
    "end": "285479"
  },
  {
    "text": "just have all this Lo business logic in there to help us Target the ones that our advertisers",
    "start": "285479",
    "end": "291800"
  },
  {
    "start": "292000",
    "end": "511000"
  },
  {
    "text": "want so why elastic beanock that's I mean as a big scale system I feel like",
    "start": "292160",
    "end": "298199"
  },
  {
    "text": "that's the question people want to know um and the reason is going back to what I was talking about uh elastic beanock",
    "start": "298199",
    "end": "306320"
  },
  {
    "text": "really provided a speed to Market when we're first launching I mentioned we had an engineering team of two and beanock",
    "start": "306320",
    "end": "312680"
  },
  {
    "text": "gave us a really nice preconfigured starting point with all the Amazon Services uh tied together it also lowers",
    "start": "312680",
    "end": "320280"
  },
  {
    "text": "the learning curve for AWS so when we started we were not AWS experts we consider ourselves experts today but it",
    "start": "320280",
    "end": "327000"
  },
  {
    "text": "started with beanock and sort of an overall knowledge of what the services did and we were able to get something up",
    "start": "327000",
    "end": "332919"
  },
  {
    "text": "and running and launched and then dive deep into the nuances of each Service as we went or as we had challenges we had",
    "start": "332919",
    "end": "339759"
  },
  {
    "text": "to overcome so from a startups perspective it it was really great to be able to get on board and get running um",
    "start": "339759",
    "end": "345919"
  },
  {
    "text": "with very low barriers to entry uh so what we're running on",
    "start": "345919",
    "end": "351280"
  },
  {
    "text": "beanock is our realtime ad bidder and ad server so in our architecture we have a number of services this is the Workhorse",
    "start": "351280",
    "end": "358000"
  },
  {
    "text": "this is the one doing the most requests processing the most uh volume of data",
    "start": "358000",
    "end": "363039"
  },
  {
    "text": "doing the most computation it's got the most servers behind it so this is our our key service in our architecture uh",
    "start": "363039",
    "end": "370240"
  },
  {
    "text": "we're running on Tomcat I'll talk a little bit more about that later uh we're API based so we're not serving a",
    "start": "370240",
    "end": "376360"
  },
  {
    "text": "website we don't deal with browsers uh we have a uh Json based API contract",
    "start": "376360",
    "end": "382639"
  },
  {
    "text": "that we adhere to with our partners and the Nuance of that is you can't cash anything or not at the client level um",
    "start": "382639",
    "end": "389720"
  },
  {
    "text": "uh we're doing well over 150,000 requests a second uh this was our number from a few months ago so we're easily",
    "start": "389720",
    "end": "396039"
  },
  {
    "text": "clearing that now uh we're running hundreds of hosts in production uh well",
    "start": "396039",
    "end": "401720"
  },
  {
    "text": "over 9 billion again this number is a couple months old and our hosts are spitting off more than two terabytes of",
    "start": "401720",
    "end": "407039"
  },
  {
    "text": "data every day uh and then with auto scaling we're up and down so we basically double the",
    "start": "407039",
    "end": "412199"
  },
  {
    "text": "fleet and come down at half and that that's driven by usage patterns on mobile uh people aren't doing a lot of",
    "start": "412199",
    "end": "418039"
  },
  {
    "text": "mobile gaming at 6:00 a.m. just generally so we cut the fleet right down and scale back",
    "start": "418039",
    "end": "423240"
  },
  {
    "text": "up why are we still using beanock a lot of those reasons I just gave you uh were",
    "start": "423240",
    "end": "428919"
  },
  {
    "text": "reasons to start using it with low barriers to entry and getting set up but here we are you know three years after",
    "start": "428919",
    "end": "434639"
  },
  {
    "text": "we built the product still using it and this is going to seem quaint but the UI is actually really nice so being able to",
    "start": "434639",
    "end": "441080"
  },
  {
    "text": "go in and have a UI that gives you a quick overview of your different Services set up what's running in",
    "start": "441080",
    "end": "446120"
  },
  {
    "text": "production um and having metrics and things all tied together is a really nice feature manage deployment mechanism",
    "start": "446120",
    "end": "453360"
  },
  {
    "text": "this is this is something that there are a lot of competing Services out there with you know there's Chef pupet there there's a hundred ways to deploy your",
    "start": "453360",
    "end": "459080"
  },
  {
    "text": "code they have one and it's worked for us configuration mechanism again there's",
    "start": "459080",
    "end": "464360"
  },
  {
    "text": "a lot of ways to get configuration out the production this is one and it's worth for us aggregated metrics that's a",
    "start": "464360",
    "end": "471520"
  },
  {
    "text": "nice feature of the autoscaling groups tyed together uh CPU latency um all the",
    "start": "471520",
    "end": "476720"
  },
  {
    "text": "metrics from a given elastic bean stock environment into the UI and being able to quickly see things at a glance and",
    "start": "476720",
    "end": "483039"
  },
  {
    "text": "ongoing development and support so I think the message is that there are a lot of alternatives to the individual",
    "start": "483039",
    "end": "489199"
  },
  {
    "text": "pieces and they brought it together in a package that has one sort of vision behind it and rather than putting",
    "start": "489199",
    "end": "496080"
  },
  {
    "text": "together different open source pieces into a solution we were able to just take a whole holistic piece and run with",
    "start": "496080",
    "end": "503080"
  },
  {
    "text": "it and that's continued to work for us and we'll continue using it until it doesn't work for us um which we don't",
    "start": "503080",
    "end": "509080"
  },
  {
    "text": "see that happening anytime soon um so let's talk about the",
    "start": "509080",
    "end": "514159"
  },
  {
    "start": "511000",
    "end": "841000"
  },
  {
    "text": "architecture so what did we actually build on elastic bean stock um so",
    "start": "514159",
    "end": "519760"
  },
  {
    "text": "backing up to when we started we had certain uh requirements and constraints that we had to adhere to with our",
    "start": "519760",
    "end": "526040"
  },
  {
    "text": "architecture um I'm going to go through these because they're pretty typical but I do want to cover them had to be scalable we started very small we're",
    "start": "526040",
    "end": "532480"
  },
  {
    "text": "more than 100x the size of where we were when we started and we haven't had to make major modifications so we had that",
    "start": "532480",
    "end": "538839"
  },
  {
    "text": "in mind for from day one when we picked our Technologies uh robust reliable fault tolerant everybody wants this in a",
    "start": "538839",
    "end": "544480"
  },
  {
    "text": "big system um we actually have to be a little extra careful uh because we can get kicked off our sources of inventory",
    "start": "544480",
    "end": "551040"
  },
  {
    "text": "if we take outages or have bad performance um must achieve low latency",
    "start": "551040",
    "end": "557040"
  },
  {
    "text": "so this is 100 150 milliseconds client side measured latency so that means like",
    "start": "557040",
    "end": "562120"
  },
  {
    "text": "you're on your phone and the app wants to show you an ad that request goes out the exchange then pulls it and sends it",
    "start": "562120",
    "end": "568800"
  },
  {
    "text": "out to all us and our competitors we bid on it it comes back and it has to reach",
    "start": "568800",
    "end": "574000"
  },
  {
    "text": "the app and the app's latency is usually around uh 300 to 500 milliseconds so",
    "start": "574000",
    "end": "579680"
  },
  {
    "text": "from the exchanges perspective which is our partner we have to be able to respond from their perspective in 100 to",
    "start": "579680",
    "end": "586480"
  },
  {
    "text": "150 milliseconds so our server side latency has to be you know 30 to 70",
    "start": "586480",
    "end": "591839"
  },
  {
    "text": "milliseconds and then you've got the internet latency on top of that so it's pretty tight and we have to hit that",
    "start": "591839",
    "end": "597640"
  },
  {
    "text": "consistently if we're late we might as well just not try it at all so you have to be pretty careful with that uh and",
    "start": "597640",
    "end": "604560"
  },
  {
    "text": "we're limited you can't like Jason is kind of a computationally expensive protocol to parse at scale you can't",
    "start": "604560",
    "end": "610760"
  },
  {
    "text": "shortcircuit it with custom binary or or Thrift or all the different options you have available to",
    "start": "610760",
    "end": "616160"
  },
  {
    "text": "you so we adopted a set of principles as we built it um that kind of drove all",
    "start": "616160",
    "end": "621680"
  },
  {
    "text": "the decisions that we made as as we um explored Technologies read only whenever",
    "start": "621680",
    "end": "626959"
  },
  {
    "text": "possible that's kind of an easy one you don't want to have to be writing to a database or something while you're processing high frequency low latency",
    "start": "626959",
    "end": "633560"
  },
  {
    "text": "requests uh async wrs whenever we do have to write um to anything to logs to",
    "start": "633560",
    "end": "639760"
  },
  {
    "text": "Dynamo to to anything we always just put it in a Quee and we have workers spin up",
    "start": "639760",
    "end": "644839"
  },
  {
    "text": "and and write those out horizontally scalable uh our application has zero",
    "start": "644839",
    "end": "650040"
  },
  {
    "text": "state so everything um every request is completely stateless um and that's",
    "start": "650040",
    "end": "656720"
  },
  {
    "text": "really important for for being able to just throw servers at problems when you have problems uh and then with errors",
    "start": "656720",
    "end": "663560"
  },
  {
    "text": "and this is kind of a scary idea not trying to prevent errors uh this is a system that's spending money if we're",
    "start": "663560",
    "end": "669240"
  },
  {
    "text": "doing hundreds of thousands of requests a second we can be spending thousands or tens of thousands of dollars a second um",
    "start": "669240",
    "end": "676480"
  },
  {
    "text": "and so if you have a bug say you know an off by one decimal can be a very expensive bug to have uh so we just",
    "start": "676480",
    "end": "684120"
  },
  {
    "text": "really focused on detection as opposed to prevention um and that was really important as we grew because if you try",
    "start": "684120",
    "end": "690920"
  },
  {
    "text": "to anticipate everything that goes wrong you end up over engineering Your solution or if you just trying to focus on what could go wrong and and detect it",
    "start": "690920",
    "end": "698079"
  },
  {
    "text": "you save a lot of development cycles and a lot of the time that stuff never breaks or it breaks so infrequently like",
    "start": "698079",
    "end": "704600"
  },
  {
    "text": "0.00001% of the time you just don't have to worry about it um so that goes to the next point",
    "start": "704600",
    "end": "712079"
  },
  {
    "text": "which is we encapsulate them so when errors do happen uh we don't want our partners to know about it if you're",
    "start": "712079",
    "end": "717399"
  },
  {
    "text": "using tom cat out of the box it'll throw exceptions with a stack trace for you right through to your partner uh and so",
    "start": "717399",
    "end": "723480"
  },
  {
    "text": "we make sure that we just catch everything up front and we just have a nice little uh uh no message that goes",
    "start": "723480",
    "end": "729680"
  },
  {
    "text": "back to the partner at 204 and that way we look like we're better behaving even if we're having a meltdown on the inside",
    "start": "729680",
    "end": "736199"
  },
  {
    "text": "say with some sort of problem our partner is like okay yeah no he's just not buying very much right now but he's",
    "start": "736199",
    "end": "741800"
  },
  {
    "text": "doing well um internal rate limiting uh this goes to very important when you're doing",
    "start": "741800",
    "end": "748040"
  },
  {
    "text": "large scale systems is that you can have traffic spikes so think about an app say",
    "start": "748040",
    "end": "754000"
  },
  {
    "text": "some sort of baseball app during the World Series uh think about the spike and traffic that that app gets at that",
    "start": "754000",
    "end": "760000"
  },
  {
    "text": "time and that can flow right through to us and so we have a rate basically just a Sig poot at the at the front end",
    "start": "760000",
    "end": "766720"
  },
  {
    "text": "that's um limits the amount of requests we'll actually process and kind of like catching errors we just turn away extra",
    "start": "766720",
    "end": "772680"
  },
  {
    "text": "traffic until we can get enough servers online to be able to handle it in an intelligent way",
    "start": "772680",
    "end": "779240"
  },
  {
    "text": "and proven Technologies so ironically beam stock was very new when we chose it at the time but a lot of the other",
    "start": "779240",
    "end": "786000"
  },
  {
    "text": "Technologies we chose we're going to talk about our older Technologies you already heard me say Tom Cat and you",
    "start": "786000",
    "end": "791959"
  },
  {
    "text": "have to realize this was a startup we were we were six or eight people I think at the time the engineering team was two",
    "start": "791959",
    "end": "798079"
  },
  {
    "text": "and so if you think about it choosing Tomcat the company is not going to fail",
    "start": "798079",
    "end": "803399"
  },
  {
    "text": "because you chose tom cat um if you think about some newer Technologies out there you could po potentially have",
    "start": "803399",
    "end": "809839"
  },
  {
    "text": "something blow up underneath you and um and that could just ruin the company and",
    "start": "809839",
    "end": "815240"
  },
  {
    "text": "it's sort of just a random Factor so some of the Technologies we chose are older but they're proven and they may",
    "start": "815240",
    "end": "820320"
  },
  {
    "text": "not be the most optimal you know I'm not sure if you're choosing the optimal platform for a low latency high",
    "start": "820320",
    "end": "826279"
  },
  {
    "text": "frequency system that Tomcat would come very high on that list but for a startup it's a very safe bet and you can kind of",
    "start": "826279",
    "end": "832560"
  },
  {
    "text": "throw money at the problem um as you grow until that money is too expensive and then you can explore other platforms",
    "start": "832560",
    "end": "841040"
  },
  {
    "start": "841000",
    "end": "1342000"
  },
  {
    "text": "okay so these are quick successful system will achieve several goals and I bet you've all had these same goals for",
    "start": "842320",
    "end": "847920"
  },
  {
    "text": "systems youve built before high request throughput High success rate low costs",
    "start": "847920",
    "end": "853279"
  },
  {
    "text": "low maintenance requirements being able to scale 10 to 100x without major improvements uh those are not new",
    "start": "853279",
    "end": "859639"
  },
  {
    "text": "they're not mind-blowing but it is important to have them in mind when you're choosing Technologies when you do a load test you don't load test against",
    "start": "859639",
    "end": "865519"
  },
  {
    "text": "traffic today you load test against a hundred times that traffic",
    "start": "865519",
    "end": "870800"
  },
  {
    "text": "okay so we're going to walk through the actual architecture now we're going to start at the 10,000 ft and we're going to go right down to the micro",
    "start": "870800",
    "end": "877759"
  },
  {
    "text": "Technologies we've got so this is how we organize our elastic beant stock applications uh we do it with stages so",
    "start": "877759",
    "end": "885759"
  },
  {
    "text": "each uh elastic beanock application for us is a stage it's production it's integration it's sandbox that's for",
    "start": "885759",
    "end": "893079"
  },
  {
    "text": "developers just spin up and test on and this exists in all our services across our systems so that you've got a full",
    "start": "893079",
    "end": "899320"
  },
  {
    "text": "end to end environment for each one we're just talking about the one bitter service here so if we choose the",
    "start": "899320",
    "end": "906519"
  },
  {
    "text": "production box there we can go down and inside production we have what we call",
    "start": "906519",
    "end": "912440"
  },
  {
    "text": "clusters these are elastic bean stock environments uh these are just you know",
    "start": "912440",
    "end": "918160"
  },
  {
    "text": "the bread and butter elastic beant stock um the main difference for us is we've isolated our major Partners on their own",
    "start": "918160",
    "end": "925320"
  },
  {
    "text": "cluster um and that really helps us with tuning configur ation for a partner um",
    "start": "925320",
    "end": "930839"
  },
  {
    "text": "identifying problems that are partner specific uh Sometimes some of our partners will misbehave in a way others",
    "start": "930839",
    "end": "936120"
  },
  {
    "text": "don't this really lets us tell when it's our fault or their fault because as long as we're running the same code across",
    "start": "936120",
    "end": "941600"
  },
  {
    "text": "all our clusters we can isolate problems that are um either lower level with how like partners are managing their",
    "start": "941600",
    "end": "947720"
  },
  {
    "text": "connections or maybe they're sending us badly formatted requests but it really makes troubleshooting a lot easier to",
    "start": "947720",
    "end": "953560"
  },
  {
    "text": "set it up this way um the bigger clusters are probably in 30 to 50 Host range",
    "start": "953560",
    "end": "959519"
  },
  {
    "text": "um and we have a couple smaller clusters as well so diving down each cluster looks",
    "start": "959519",
    "end": "964839"
  },
  {
    "text": "like this uh this is pretty much what beanock gives you out of the box in the middle there uh row 53 beanock",
    "start": "964839",
    "end": "971639"
  },
  {
    "text": "autoscaling group with instances and then we use three data stores on the back end S3 elasticache and Dynamo",
    "start": "971639",
    "end": "980639"
  },
  {
    "text": "DB so now we're drilled right in don't try to take this all in we're going to walk through this diagram and let you",
    "start": "980680",
    "end": "986600"
  },
  {
    "text": "know why we chose these Technologies and how we used them um to build our system so first up here",
    "start": "986600",
    "end": "993199"
  },
  {
    "text": "is S3 so S3 for us is really great as a",
    "start": "993199",
    "end": "998360"
  },
  {
    "text": "data store for infrequently changing um large configuration files um I say large",
    "start": "998360",
    "end": "1005480"
  },
  {
    "text": "but they're smaller for us but it's about four gigs of data and it can be different things but they're not sorry",
    "start": "1005480",
    "end": "1010680"
  },
  {
    "text": "they're not configuration they're like targeting parameters or ranks for",
    "start": "1010680",
    "end": "1015720"
  },
  {
    "text": "different apps or um trying to think of good an IES that are general not specific to advertising but it's data",
    "start": "1015720",
    "end": "1022120"
  },
  {
    "text": "that every host need so what we do is we just um preload it so each host comes up it goes and gets the freshest file um",
    "start": "1022120",
    "end": "1028760"
  },
  {
    "text": "these are refreshed uh asynchronously in the background on the host and then we just check the S3 Tim stamp about once",
    "start": "1028760",
    "end": "1035120"
  },
  {
    "text": "an hour to look for updates but these don't change that often um but when they do change they roll out slowly and it's",
    "start": "1035120",
    "end": "1042319"
  },
  {
    "text": "fine um and yeah it's about four gigs the next piece we use here is El",
    "start": "1042319",
    "end": "1049240"
  },
  {
    "text": "cache and specifically mem cach so this is going to go against everything you've read in books elastic cache is our",
    "start": "1049240",
    "end": "1056400"
  },
  {
    "text": "primary data store uh there is no database behind elasticache uh this is done for latency",
    "start": "1056400",
    "end": "1063720"
  },
  {
    "text": "reasons it's incredibly fast we know it's transitory so we detect errors we detect evictions in mcash uh we invested",
    "start": "1063720",
    "end": "1071559"
  },
  {
    "text": "in learning mcash and tuned it uh and then we have a separate service that exists just to denormalize requests for",
    "start": "1071559",
    "end": "1078840"
  },
  {
    "text": "for us and put them for a key value lookup in mcash so yes if we get a restart it's",
    "start": "1078840",
    "end": "1086880"
  },
  {
    "text": "not the cheapest thing in the world to rebuild um it does does cause US problems and we avoid it but we do it in",
    "start": "1086880",
    "end": "1092080"
  },
  {
    "text": "a controlled way usually and it's not a huge deal because all it does is we slow down for about 20 minutes to half an",
    "start": "1092080",
    "end": "1097600"
  },
  {
    "text": "hour while the cach repopulates uh it's incredibly fast we have not found a data store that can come close to 3",
    "start": "1097600",
    "end": "1104360"
  },
  {
    "text": "millisecond client side reads at scale and we've tested pretty much everything get our hands on um and that's just",
    "start": "1104360",
    "end": "1111720"
  },
  {
    "text": "that's been tough to find something that could match that speed uh everything's readon so it's just uh we get a request",
    "start": "1111720",
    "end": "1117840"
  },
  {
    "text": "that comes in we do our reads uh it's always key value um if we do have any joins which we try to avoid uh we do",
    "start": "1117840",
    "end": "1124880"
  },
  {
    "text": "that in software and um you need to tune mcash so this solution does require you",
    "start": "1124880",
    "end": "1131120"
  },
  {
    "text": "to invest in understanding how mcash behaves um out of the box if you have um",
    "start": "1131120",
    "end": "1137280"
  },
  {
    "text": "weird I don't want to say weird call patterns but mcash can be tuned to optimize space utilization for your call",
    "start": "1137280",
    "end": "1144159"
  },
  {
    "text": "patterns um and so don't just take it for free and we pre-normalized",
    "start": "1144159",
    "end": "1151120"
  },
  {
    "text": "data uh the next piece we do here is eh cache so m cach is our primary data",
    "start": "1151120",
    "end": "1157799"
  },
  {
    "text": "store and we keep a cache in front of our cach uh each host has their own cach",
    "start": "1157799",
    "end": "1163240"
  },
  {
    "text": "uh locally it's a couple gigs and this exists primarily to solve one problem that we had is as we scaled which is hot",
    "start": "1163240",
    "end": "1170919"
  },
  {
    "text": "Keys uh so just kind of like Dynamo mcash can also have problems if you get",
    "start": "1170919",
    "end": "1177320"
  },
  {
    "text": "hot keys that get a disproportionate amount of traffic uh with mcash you're running on distributed cluster um so",
    "start": "1177320",
    "end": "1183360"
  },
  {
    "text": "each host has its own set of um of the data and then if you get a hotkey you just kill the host that has that data um",
    "start": "1183360",
    "end": "1190840"
  },
  {
    "text": "so we run eh cache on the hosts it's got short-lived cash times but uh the nice",
    "start": "1190840",
    "end": "1197200"
  },
  {
    "text": "thing is that if you have a really hot key in the system you're completely cushioned on it and if you don't have a",
    "start": "1197200",
    "end": "1203280"
  },
  {
    "text": "really hot key it still picks up a fair number of the requests it lowers the call volume going back to the mcash",
    "start": "1203280",
    "end": "1208600"
  },
  {
    "text": "servers which saves you money which we always",
    "start": "1208600",
    "end": "1214880"
  },
  {
    "text": "like and the last piece I'm going to talk about is Dynamo so we use Dynamo",
    "start": "1214919",
    "end": "1221480"
  },
  {
    "text": "for two things uh the first use case is reading so I referred to S3 as storing",
    "start": "1221480",
    "end": "1229039"
  },
  {
    "text": "our 4 gbyte relatively small sets of data we have multi-terabyte sets of data",
    "start": "1229039",
    "end": "1234600"
  },
  {
    "text": "that we want available to Us online while we're serving requests this is what we use Dynamo for and Dynamo uh has",
    "start": "1234600",
    "end": "1241760"
  },
  {
    "text": "a really nice integration feature with elastic map reduce that we already use for a lot of our data processing which",
    "start": "1241760",
    "end": "1247679"
  },
  {
    "text": "lets you load extremely large sets of data into Dynamo uh relative relatively fast and efficiently so we generate",
    "start": "1247679",
    "end": "1254679"
  },
  {
    "text": "these huge sets of data uh and then we load them all into Dynamo um and this is done infrequently again they're in",
    "start": "1254679",
    "end": "1260840"
  },
  {
    "text": "infrequently changing um data sets and then you load them with EMR",
    "start": "1260840",
    "end": "1267320"
  },
  {
    "text": "it's a little bit slower than mcash it's probably about 1.5 to two times as slow",
    "start": "1267320",
    "end": "1272559"
  },
  {
    "text": "but its variability is Extreme is much more reliable than mcash um and if it weren't for the call volumes um and the",
    "start": "1272559",
    "end": "1280279"
  },
  {
    "text": "way Dynamo behaves we might we've looked at replacing mcast with Dynamo um for",
    "start": "1280279",
    "end": "1285880"
  },
  {
    "text": "now this is working quite well for us we also use it for writing uh so the",
    "start": "1285880",
    "end": "1292559"
  },
  {
    "text": "primary use case is the uh for counters so it's got a async WR",
    "start": "1292559",
    "end": "1299679"
  },
  {
    "text": "increment operation and since we're advertising all we do all day is Count things we count the number of Impressions we count the number of",
    "start": "1299679",
    "end": "1305840"
  },
  {
    "text": "clicks we count anything we can and we count how much money we've spent and the nice thing is that this gives us a live",
    "start": "1305840",
    "end": "1311960"
  },
  {
    "text": "counter it's very fast to update it's durable and we can have other systems reading so at any time we can check and",
    "start": "1311960",
    "end": "1318200"
  },
  {
    "text": "see live um how much have we spent and this is a this is a parallel data set to",
    "start": "1318200",
    "end": "1324039"
  },
  {
    "text": "another track um that we keep through our logs to get more details about the spend this is a very high level here's",
    "start": "1324039",
    "end": "1329240"
  },
  {
    "text": "what I've spent but we don't keep details like what I've spent it on that comes through a separate",
    "start": "1329240",
    "end": "1334880"
  },
  {
    "text": "system and that leads us to data collection",
    "start": "1334880",
    "end": "1341120"
  },
  {
    "start": "1342000",
    "end": "1602000"
  },
  {
    "text": "Mick good afternoon everyone thanks for coming pretty sure I'm the only thing standing between between you uh and beer",
    "start": "1343480",
    "end": "1349919"
  },
  {
    "text": "and freedom so let's crack on all right Big Data challenge volume and rates the",
    "start": "1349919",
    "end": "1355120"
  },
  {
    "text": "first aspect is what exactly are we going to collect and why well as John said we generate terabytes of data per",
    "start": "1355120",
    "end": "1362600"
  },
  {
    "text": "day and we need to figure out what solid use cases are what exactly are we trying to report on and why so we strategize on",
    "start": "1362600",
    "end": "1369880"
  },
  {
    "text": "what we keep so some aspects like Impressions and clicks and spend we keep everything and those things that we just",
    "start": "1369880",
    "end": "1376200"
  },
  {
    "text": "want to use for data analytics will sample it says 1% on the screen there actually it's down to half a percent because we realize that's all we really",
    "start": "1376200",
    "end": "1382120"
  },
  {
    "text": "need to be statistically significant so how does this data actually get into our analytics systems",
    "start": "1382120",
    "end": "1389520"
  },
  {
    "text": "well this is a very high level diagram and we're going to drill into each aspect uh on that diagram as we go along",
    "start": "1389520",
    "end": "1396080"
  },
  {
    "text": "so the requests come in through Tomcat we write them out through logs write the data out through logs we then use log",
    "start": "1396080",
    "end": "1401360"
  },
  {
    "text": "rotate to rotate those logs on a 5 minute basis and there's a custom utility which we'll talk about a little bit more called tns3 uploader that's a",
    "start": "1401360",
    "end": "1408880"
  },
  {
    "text": "ruby gem that we use to upload our data directly to S3 into the right partitions and then we load directly from S3 into",
    "start": "1408880",
    "end": "1415840"
  },
  {
    "text": "EMR or into red shift couple of things to bear in mind",
    "start": "1415840",
    "end": "1421200"
  },
  {
    "text": "we have too many dimensions and custom aspects to use something like Kinesis and also because we're doing it in a",
    "start": "1421200",
    "end": "1427720"
  },
  {
    "text": "custom manner we have a bunch of monitoring going on and we also error out on failed",
    "start": "1427720",
    "end": "1434799"
  },
  {
    "text": "uploads right so how do we actually do the collection so we we have Amazon elastic Block store attached to our",
    "start": "1434799",
    "end": "1440559"
  },
  {
    "text": "instances that's where toman's configurations live but we actually set up our local drives in raid zero for",
    "start": "1440559",
    "end": "1446120"
  },
  {
    "text": "much faster performance and these details are in your handout so I just want to mention the handout you picked up has got a number of code samples in",
    "start": "1446120",
    "end": "1453679"
  },
  {
    "text": "it but of course you can't copy and paste from the brochure it's all available at engineering. thinkink near.com if you go there you will see",
    "start": "1453679",
    "end": "1460640"
  },
  {
    "text": "these slides are going to be up there um once we finish this talk also links to our open source",
    "start": "1460640",
    "end": "1466520"
  },
  {
    "text": "software all right to continue on C we write to multiple files so this improves",
    "start": "1466520",
    "end": "1471559"
  },
  {
    "text": "disc performance and we make sure we monitor for low disc performance and again the examples in the",
    "start": "1471559",
    "end": "1477039"
  },
  {
    "text": "handout all right this diagram shows how we actually configure log rotate in our utility so EB extension configures the",
    "start": "1477039",
    "end": "1484360"
  },
  {
    "text": "ec2 instance as it gets initialized and it configures a couple of things the first one is Chron to actually run log",
    "start": "1484360",
    "end": "1490080"
  },
  {
    "text": "rotate every 5 minutes and it also configures log rotate so we have a log rotate. comp file that actually",
    "start": "1490080",
    "end": "1496679"
  },
  {
    "text": "configures each log file that we're writing to and um as part of that configuration we use that tns3 uploader",
    "start": "1496679",
    "end": "1503360"
  },
  {
    "text": "to actually upload to the S3 bucket once we've done that um we have our data available but if there are any errors",
    "start": "1503360",
    "end": "1509840"
  },
  {
    "text": "then we actually Mark that ec2 instance as unhealthy so it gets taken out of rotation we don't want to have an",
    "start": "1509840",
    "end": "1515279"
  },
  {
    "text": "instance running that we can't collect the logs from couple of gotches to be wary of",
    "start": "1515279",
    "end": "1521240"
  },
  {
    "text": "first one is elastic Bean stalk already uses log rotate so it will run in parallel unless you disable it and the",
    "start": "1521240",
    "end": "1528559"
  },
  {
    "text": "am s Amon S3 push availability is actually extremely good it's just not 100% especially when we're sending",
    "start": "1528559",
    "end": "1534559"
  },
  {
    "text": "hundreds of have hundreds of host pushing you know five logs every five",
    "start": "1534559",
    "end": "1540000"
  },
  {
    "text": "minutes couple more so originally we were using the host name to prefix the",
    "start": "1540000",
    "end": "1545840"
  },
  {
    "text": "log file by using the host name we actually found that they got recycled especially when you're going up and down",
    "start": "1545840",
    "end": "1551399"
  },
  {
    "text": "50 to 100% uh in terms of number of instances every day so what we do now is we use a custom uu ID to actually prefix",
    "start": "1551399",
    "end": "1559440"
  },
  {
    "text": "uh that host and that's just using uid on the host OS and then we have a monitoring process",
    "start": "1559440",
    "end": "1565080"
  },
  {
    "text": "that tells us when we missed any gaps now since we've used uid there's hardly been any errors in that area at all",
    "start": "1565080",
    "end": "1570240"
  },
  {
    "text": "again this is all going to be in our open source software which you'll see on engineering. thinkink near.com last thing cron can crash but so you",
    "start": "1570240",
    "end": "1577480"
  },
  {
    "text": "need to monitor Chron okay log rotate our tns3 uploader I've mentioned a custom upload Uh custom",
    "start": "1577480",
    "end": "1583679"
  },
  {
    "text": "gem um it retries uploads on failure so all that is built in for you we notify honey badget as that's our current tool",
    "start": "1583679",
    "end": "1589760"
  },
  {
    "text": "but you can buil in your own um notification uh class if you want to use it um any repeated failures like I said",
    "start": "1589760",
    "end": "1596600"
  },
  {
    "text": "causes the ec2 instance to rotate out and it's open",
    "start": "1596600",
    "end": "1601840"
  },
  {
    "text": "source okay scalability challenge so as you can imagine Network latency is a big",
    "start": "1601840",
    "end": "1609159"
  },
  {
    "start": "1602000",
    "end": "1791000"
  },
  {
    "text": "area that we want to make sure we resolve if there's any issues there well quite frankly we use AWS and it works so",
    "start": "1609159",
    "end": "1615679"
  },
  {
    "text": "we've not had any issues there whatsoever there are some aspects we need to be careful of that includes CrossCountry uh",
    "start": "1615679",
    "end": "1622960"
  },
  {
    "text": "end points so if we have a an exchange that's on the other side of the country and we're actually deployed in an East",
    "start": "1622960",
    "end": "1629559"
  },
  {
    "text": "availability Zone uh if we have one on the other side of the country the latency is just too great for us to integrate with some of those exchanges",
    "start": "1629559",
    "end": "1634840"
  },
  {
    "text": "so we're going to be deploying to the West persistent connections for more efficient reuse uh when we've got",
    "start": "1634840",
    "end": "1641120"
  },
  {
    "text": "hundreds well millions of requests going in and also timeouts from load balancer and Tom cap we'll look at in a moment",
    "start": "1641120",
    "end": "1648960"
  },
  {
    "text": "and when I say in a moment I mean now so elastic load balances idle timeout generally cleans out connections so the",
    "start": "1648960",
    "end": "1654399"
  },
  {
    "text": "documentation recommends that we set it to be 1 second lower than the application layers keep alive timeout",
    "start": "1654399",
    "end": "1659919"
  },
  {
    "text": "but we actually flipped that and we flipped that and we found that we actually got much better overall error",
    "start": "1659919",
    "end": "1665360"
  },
  {
    "text": "rate which is 200 uh Response Code divided by total number of request but then we got these mystery 500 errors",
    "start": "1665360",
    "end": "1670840"
  },
  {
    "text": "that aren't really um documented anywhere or even monitored however that's the way we",
    "start": "1670840",
    "end": "1676360"
  },
  {
    "text": "still run so as with all things need to test this yourself U here's a little bit of code",
    "start": "1676360",
    "end": "1682720"
  },
  {
    "text": "again it's going to be in the handout also in the open source pieces um let's talk about the elb uh configuration so a",
    "start": "1682720",
    "end": "1688840"
  },
  {
    "text": "connection draining policy um that's configured there so you can be quite generous with that to Bally clear out",
    "start": "1688840",
    "end": "1694600"
  },
  {
    "text": "the connections and then if you want to um store all the requests that are",
    "start": "1694600",
    "end": "1701159"
  },
  {
    "text": "coming through the elb you can actually configure the access loging policy as well all right abser we talked about",
    "start": "1701159",
    "end": "1707200"
  },
  {
    "text": "this I'm going to skip through it we run on Tomcat 100% API web based nothing to cache and here's the key pieces OS",
    "start": "1707200",
    "end": "1714240"
  },
  {
    "text": "tuning right so Tomcat typically has uh, to 1400 open files on each host and",
    "start": "1714240",
    "end": "1720640"
  },
  {
    "text": "those can be jars pipe processes and whatever um the two main areas to configure are the limits.com and the",
    "start": "1720640",
    "end": "1727240"
  },
  {
    "text": "sct.com so in the limits.com the only area we had to look at to resolve the too many open files error was hard node",
    "start": "1727240",
    "end": "1733919"
  },
  {
    "text": "file and soft node file and for the cctl there's a long",
    "start": "1733919",
    "end": "1739159"
  },
  {
    "text": "list but the two to be most concerned about are the net cor sxcom which is",
    "start": "1739159",
    "end": "1744440"
  },
  {
    "text": "basically increase we increase that kernel Q for accepting requests especially for bursty traffic um and the",
    "start": "1744440",
    "end": "1750600"
  },
  {
    "text": "actually the TCP fin timeout was default with 60 seconds we'd have a lot of connections in time weight State using",
    "start": "1750600",
    "end": "1756039"
  },
  {
    "text": "our resources so we decreased that so we could release those resources quicker all right bypassing Apache EB",
    "start": "1756039",
    "end": "1763320"
  },
  {
    "text": "actually comes with Apache and originally we didn't really know this was happening and we're wondering why we're getting um slow latency issues but",
    "start": "1763320",
    "end": "1770080"
  },
  {
    "text": "we actually don't need it so um especially because we've talked about not having any cachable content so we",
    "start": "1770080",
    "end": "1776559"
  },
  {
    "text": "just turned it off um it becomes another point of contention as well actually if you leave it in so another point to uh",
    "start": "1776559",
    "end": "1782919"
  },
  {
    "text": "another area to performance tune and things like that so we just point the elb load the elb directly towards our",
    "start": "1782919",
    "end": "1788559"
  },
  {
    "text": "tomat instance right monitoring last section thresholds so originally we used",
    "start": "1788559",
    "end": "1795240"
  },
  {
    "start": "1791000",
    "end": "1966000"
  },
  {
    "text": "cloudwatch and we need average min max but we need more than that we need percentiles okay but cloudwatch didn't",
    "start": "1795240",
    "end": "1801720"
  },
  {
    "text": "really support percentile so we had to actually think about how we're going to do this we use threshold counts so you can we can figure out what our threshold",
    "start": "1801720",
    "end": "1807679"
  },
  {
    "text": "count is and then um count number if they exceed the threshold and kind of work out the",
    "start": "1807679",
    "end": "1813240"
  },
  {
    "text": "percentiles so we moved to labrat which made things a little easier even though cloudwatch has got great aggregation",
    "start": "1813240",
    "end": "1818840"
  },
  {
    "text": "metrics lebrat allows us to slice and dice the way we want to see the data so what you're seeing there is a sample",
    "start": "1818840",
    "end": "1824760"
  },
  {
    "text": "graph showing our response rate above 75 milliseconds and each one of those lines is a different cluster so we can",
    "start": "1824760",
    "end": "1830600"
  },
  {
    "text": "actually see patterns across the clusters right a couple of learning points first thing is if you send thous",
    "start": "1830600",
    "end": "1837000"
  },
  {
    "text": "tens of thousands of metrics per second out to cloudwatch um it doesn't really",
    "start": "1837000",
    "end": "1842039"
  },
  {
    "text": "like it so we used to get a personal phone call but now I think we just get throttled uh we actually wrote some",
    "start": "1842039",
    "end": "1847640"
  },
  {
    "text": "client side uh batch publishing cloudwatch uh code to actually allow us",
    "start": "1847640",
    "end": "1853159"
  },
  {
    "text": "to do exactly that um wasn't great but it got the job done uh we haven't open",
    "start": "1853159",
    "end": "1858320"
  },
  {
    "text": "we're thinking about it so if anyone needs it let us know right service side metrics now",
    "start": "1858320",
    "end": "1863880"
  },
  {
    "text": "we're looking at the host OS Tomcat things like that so most of our met are collected server side we'd love to",
    "start": "1863880",
    "end": "1869480"
  },
  {
    "text": "collect them client side however we need to have really good um a really good relationship with the exchange to be",
    "start": "1869480",
    "end": "1875399"
  },
  {
    "text": "able to do that so what we do is to figure out our Network latency We",
    "start": "1875399",
    "end": "1880519"
  },
  {
    "text": "compare the max at the elb versus server side latency to get our Network and platform latency and so we set our goals",
    "start": "1880519",
    "end": "1887159"
  },
  {
    "text": "conservatively so we're very very um we're very aggressive on the goals we",
    "start": "1887159",
    "end": "1892480"
  },
  {
    "text": "want to hit when it comes to our response time so that we can have a lot of wiggle room in that 100 millisecond",
    "start": "1892480",
    "end": "1897760"
  },
  {
    "text": "response time the exchange is required so here are the three libraries we use we use librat we use codel metrics and",
    "start": "1897760",
    "end": "1904799"
  },
  {
    "text": "we use collect D to get all our metrics on the server side we get approximate percentiles and it's way more economical",
    "start": "1904799",
    "end": "1910360"
  },
  {
    "text": "and no more client side batching for us right collect D so this is very easy",
    "start": "1910360",
    "end": "1917519"
  },
  {
    "text": "to configure again you'll get it when you go to our open source ADLs templates project um can we configure it via EB",
    "start": "1917519",
    "end": "1925000"
  },
  {
    "text": "extensions just like we can figure everything else the example config is in the handout and again like I said go to the open source project you'll see",
    "start": "1925000",
    "end": "1931679"
  },
  {
    "text": "it and the final aspect is Tomcat are just an example we collect our Tomcat metric",
    "start": "1931679",
    "end": "1938039"
  },
  {
    "text": "metrics via the collect D plugin and here's just an example for M beans that we export so I hope that's given you a",
    "start": "1938039",
    "end": "1944519"
  },
  {
    "text": "flavor of what we've done to actually serve these huge number of requests on Beanstalk um we'd love your feedback on",
    "start": "1944519",
    "end": "1951600"
  },
  {
    "text": "what we've open source please come along and have a look at the engineering. thinkink near.com do contribute to the",
    "start": "1951600",
    "end": "1956840"
  },
  {
    "text": "issues uh if you find anything with the libraries is open sourced and uh feel free to ask us any questions",
    "start": "1956840",
    "end": "1963870"
  },
  {
    "text": "[Applause]",
    "start": "1963870",
    "end": "1967940"
  }
]
[
  {
    "start": "0",
    "end": "92000"
  },
  {
    "text": "Clara's well known to be the first commercial Hadoop distribution we invested heavily in enabling big data",
    "start": "1040",
    "end": "9750"
  },
  {
    "text": "applications on Hadoop and we've been around for five six years now",
    "start": "9750",
    "end": "14780"
  },
  {
    "text": "interestingly enough Clara Clara has named a bit of a misnomer because we",
    "start": "14780",
    "end": "21060"
  },
  {
    "text": "didn't original originally when our founders started the company disease in 2009 or whatever they plan to basically",
    "start": "21060",
    "end": "28320"
  },
  {
    "text": "build a data service on the cloud 2009 apparently it was a bit too early to do that so we ended up doing a lot of",
    "start": "28320",
    "end": "34739"
  },
  {
    "text": "on-premise work but recently we've been spending a lot of our time investing in how to make Hadoop run effectively in",
    "start": "34739",
    "end": "42540"
  },
  {
    "text": "cloud environments so what I'm actually going to talk to you about today is some",
    "start": "42540",
    "end": "47789"
  },
  {
    "text": "of the learnings and experiences we've had working with customers it's fairly large scales getting them to",
    "start": "47789",
    "end": "53610"
  },
  {
    "text": "successfully run in in a cloud environment specifically AWS we've got",
    "start": "53610",
    "end": "58770"
  },
  {
    "text": "quite a few large customers who run multi petabyte data sets and they do",
    "start": "58770",
    "end": "65970"
  },
  {
    "text": "processing a multivariate data sets on AWS and I want to talk a little bit about the challenges and design patterns",
    "start": "65970",
    "end": "72420"
  },
  {
    "text": "that are most prevalent there and I'm going to start with a little bit of a basic intro to big data in the cloud",
    "start": "72420",
    "end": "79130"
  },
  {
    "text": "forgive me this is too simplistic but I'll jump in a lot more detail shortly thereafter one thing I want to make sure",
    "start": "79130",
    "end": "84840"
  },
  {
    "text": "we all levels set on is basic definitions of what we're talking about",
    "start": "84840",
    "end": "89909"
  },
  {
    "text": "when talking about cloud and big data this one is pretty brained it obvious to you guys I'm sure the cloud is the",
    "start": "89909",
    "end": "97890"
  },
  {
    "start": "92000",
    "end": "454000"
  },
  {
    "text": "practice for using a network network of remote servers hosted on the internet to store management process your data",
    "start": "97890",
    "end": "102960"
  },
  {
    "text": "rather than using local servers again pretty branded obvious to you guys the key things here are it's remote stuff",
    "start": "102960",
    "end": "108750"
  },
  {
    "text": "stored on the Internet what the cloud implies for your architecture from our",
    "start": "108750",
    "end": "114720"
  },
  {
    "text": "perspective you look at it as three major tranches of changes and I'm going to tie this back at the end to how this",
    "start": "114720",
    "end": "120360"
  },
  {
    "text": "impacts big data specifically self-service being significantly more",
    "start": "120360",
    "end": "125700"
  },
  {
    "text": "automated relative to your traditional enterprise data centers very API driven",
    "start": "125700",
    "end": "130830"
  },
  {
    "text": "model computers intermediate all your resource as well as interactions this is gonna be",
    "start": "130830",
    "end": "136200"
  },
  {
    "text": "important when we talk about big data specifically vertical integration you can consume the cloud at various levels",
    "start": "136200",
    "end": "142650"
  },
  {
    "text": "of the stack you can rent servers you can get a big data service you can get much higher level applications",
    "start": "142650",
    "end": "148260"
  },
  {
    "text": "apparently you can do bi out of the clouds starting yesterday and you can as",
    "start": "148260",
    "end": "154650"
  },
  {
    "text": "a user you get to choose which which level works best for you and from a multi-tenancy perspective of course",
    "start": "154650",
    "end": "161120"
  },
  {
    "text": "multiple organizations are sharing this one environment and there's an",
    "start": "161120",
    "end": "166680"
  },
  {
    "text": "aggregation across all your resources which has important implications for how things are set up now big data on the",
    "start": "166680",
    "end": "174239"
  },
  {
    "text": "other hand is typically taller of us this data very large size typically to the extent that it's manipulation and",
    "start": "174239",
    "end": "180209"
  },
  {
    "text": "management present significant logistical challenges I actually disagree with this definition there's",
    "start": "180209",
    "end": "185220"
  },
  {
    "text": "actually a better deficient that I think makes more sense sizes actually only and",
    "start": "185220",
    "end": "191209"
  },
  {
    "text": "relatively small aspect of what it means to be big data like a big data to us is",
    "start": "191209",
    "end": "198079"
  },
  {
    "text": "what happens in the cost of storing information becomes less than the cost of making the decision to throw away",
    "start": "198079",
    "end": "203870"
  },
  {
    "text": "none of the big day of stuff that you see it's not like Dita's increase in some foundational way we have better",
    "start": "203870",
    "end": "210060"
  },
  {
    "text": "ways of measuring things we have better ways of capturing information but really the fundamental thing that's changed is",
    "start": "210060",
    "end": "216449"
  },
  {
    "text": "the cost dynamics where systems like Hadoop have made the cost of storing",
    "start": "216449",
    "end": "222150"
  },
  {
    "text": "information way lower this is really a financial thing this is not about some change in the way you do business it's",
    "start": "222150",
    "end": "227280"
  },
  {
    "text": "just that we're before you just throw away all this data that used to exist before now you're like hey I can I can",
    "start": "227280",
    "end": "233040"
  },
  {
    "text": "actually afford to keep this around because even if the value of data has changed the value of the data is the same I can afford to do this and I can",
    "start": "233040",
    "end": "239489"
  },
  {
    "text": "except foot extract that value out even if it's lower than you'd expect so the traditionals of data warehouse architectures are I know exactly what",
    "start": "239489",
    "end": "246840"
  },
  {
    "text": "this data represents I know exactly what value it represents and I'm going to store just that piece of information now",
    "start": "246840",
    "end": "252150"
  },
  {
    "text": "you can actually store arbitrary larger quantities of data which you can actually extract much lower amounts of value potentially that to me is really",
    "start": "252150",
    "end": "259079"
  },
  {
    "text": "what we get is about it's about lowering the cost of storing your data so when I think about beginner I'm actually",
    "start": "259079",
    "end": "265770"
  },
  {
    "text": "thinking about as a financial action it's about what value you can get out of your data so when you start to give it as a financial transaction you",
    "start": "265770",
    "end": "274590"
  },
  {
    "text": "have to think about it as an asset like just like you would on a balance sheet now traditional enterprise would not",
    "start": "274590",
    "end": "280550"
  },
  {
    "text": "associate any value in the your CFO does not associating valued data the way I think it should be done this is",
    "start": "280550",
    "end": "287400"
  },
  {
    "text": "Tennessee does hey there's a repository of data in there you look at a warehouse of physical ver house they're like oh",
    "start": "287400",
    "end": "292530"
  },
  {
    "text": "that data has some specific value associated with that it would like two million dollars or whatever in reality",
    "start": "292530",
    "end": "299310"
  },
  {
    "text": "your Gator warehouse is often what way more than that because it represents a good chunk of what your enterprise",
    "start": "299310",
    "end": "305910"
  },
  {
    "text": "represents and that's never captured in a financial sheet I think that's actually something we should change over time but it is what it is so when we",
    "start": "305910",
    "end": "313860"
  },
  {
    "text": "start thinking about data the few as a financial asset you're starting about in",
    "start": "313860",
    "end": "318870"
  },
  {
    "text": "terms of like financial metrics the value of a bite is a fundamental measure here which is like you apply some value",
    "start": "318870",
    "end": "326430"
  },
  {
    "text": "function to say how it impacts your business you know how it contributes to your business process or how it",
    "start": "326430",
    "end": "331470"
  },
  {
    "text": "contributes to other data sets the gin generate value how quickly you can get value out of these data sets and the sophistication of analysis can generate",
    "start": "331470",
    "end": "337380"
  },
  {
    "text": "different types of monetary results to your business of course that's one side",
    "start": "337380",
    "end": "342780"
  },
  {
    "text": "of the equation the return and bite was tied to the cost of doing it the extracting the values so the value",
    "start": "342780",
    "end": "348510"
  },
  {
    "text": "derived / the cost to acquire model store process that's really the key",
    "start": "348510",
    "end": "354300"
  },
  {
    "text": "measure that you care about is the returning bite okay well now so again",
    "start": "354300",
    "end": "361260"
  },
  {
    "text": "when I talk about big data in general what I ended up talking about is returning bite greater than 1 means it's",
    "start": "361260",
    "end": "366810"
  },
  {
    "text": "worth keeping this data little bite less than one is don't collect throw this out put on tape putting your tips basically",
    "start": "366810",
    "end": "372570"
  },
  {
    "text": "throwing it out except we pretend it's not but whatever and big data is",
    "start": "372570",
    "end": "377729"
  },
  {
    "text": "fundamentally just lowering that water level on your iceberg off it's not changing anything in terms of what",
    "start": "377729",
    "end": "384990"
  },
  {
    "text": "actually was there this iceberg was always there it's just that you can see more of it if you lower the cost and one",
    "start": "384990",
    "end": "391050"
  },
  {
    "text": "other important element really think about this is time to value so you know",
    "start": "391050",
    "end": "397440"
  },
  {
    "text": "how it's not just about what potential value there is is how quick you can act on that how long does take",
    "start": "397440",
    "end": "402850"
  },
  {
    "text": "from the time you acquire or generate a piece of data till it provides value and this really does matter because you you",
    "start": "402850",
    "end": "409240"
  },
  {
    "text": "often can't extract value unless you do it in time if you have a delay in shipment you may often need to make an",
    "start": "409240",
    "end": "415690"
  },
  {
    "text": "immediate action to change to fix that delay that has a particular amount of",
    "start": "415690",
    "end": "421090"
  },
  {
    "text": "value associated with it on the other hand understanding your delays over time can change your process in such a way",
    "start": "421090",
    "end": "426400"
  },
  {
    "text": "that it has a different set of values associated with it so my point being that fundamentally this all boils down",
    "start": "426400",
    "end": "432490"
  },
  {
    "text": "to a cost structure equation and when we talk about the cloud as well it's really",
    "start": "432490",
    "end": "438430"
  },
  {
    "text": "important to think about it in terms of the cost structure associated with this data set now that's just a little bit of",
    "start": "438430",
    "end": "445510"
  },
  {
    "text": "like level setting on what I'm talking about and talk about Big Data now I'm going to switch a little bit into more",
    "start": "445510",
    "end": "451330"
  },
  {
    "text": "specifically Hadoop oriented topics now Hadoop came out of a system that was",
    "start": "451330",
    "end": "457900"
  },
  {
    "start": "454000",
    "end": "754000"
  },
  {
    "text": "implemented in Google or onto that and they actually wrote about it in 2004 they probably had it much longer than that and once they wrote this like",
    "start": "457900",
    "end": "465310"
  },
  {
    "text": "Hadoop paper with this map reduce paper which is a fairly seminal paper and the Big Data world the sky called duck curry",
    "start": "465310",
    "end": "472960"
  },
  {
    "text": "who works at our campaign implemented the original Hadoop implementation and",
    "start": "472960",
    "end": "478330"
  },
  {
    "text": "open-source around that time now Hadoop was designed for a time when the data",
    "start": "478330",
    "end": "483730"
  },
  {
    "text": "center architectures are fundamentally different what I mean by this is that networks are much slower so the concept",
    "start": "483730",
    "end": "492160"
  },
  {
    "text": "of locality was really important when you have slow networks so direct attached storage was like a big help to",
    "start": "492160",
    "end": "497950"
  },
  {
    "text": "this you actually have compute be moved to the storage because that reduces the time it takes to move data back and",
    "start": "497950",
    "end": "503830"
  },
  {
    "text": "forth from the storage to the computer this is a it's not that radical if you",
    "start": "503830",
    "end": "508930"
  },
  {
    "text": "think about it at the same time it was an important concept when you're dealing with large data volumes is the idea that there is direct attached storage and",
    "start": "508930",
    "end": "514900"
  },
  {
    "text": "that you move the computer to that data data set typically in those data center",
    "start": "514900",
    "end": "520330"
  },
  {
    "text": "environments because it's not very cloudy clusters tend to be fixed size you clear this one massive pool of your",
    "start": "520330",
    "end": "525670"
  },
  {
    "text": "data and you run all your computer on that thing and so you don't really share a cross up you don't share this data",
    "start": "525670",
    "end": "531220"
  },
  {
    "text": "across clusters and you have to exercise clusters and typically all your users minor to this",
    "start": "531220",
    "end": "537040"
  },
  {
    "text": "one class er this is the standard sort of model for which Hadoop was originally",
    "start": "537040",
    "end": "542800"
  },
  {
    "text": "created which is like these you have this file system which is this one arbitrary large file system you have tons of computers which it represents",
    "start": "542800",
    "end": "548860"
  },
  {
    "text": "and you run your computer on those same computers in recent years and last six",
    "start": "548860",
    "end": "554740"
  },
  {
    "text": "eight ten years or so there's been fairly foundational changes in the way data centers are designed specifically",
    "start": "554740",
    "end": "562620"
  },
  {
    "text": "things like SDNS which are not heavily deployed in traditional enterprises have",
    "start": "562620",
    "end": "568149"
  },
  {
    "text": "been heavily deployed in cloud builders environments AWS does not run a network that looks anything like your IT network",
    "start": "568149",
    "end": "574870"
  },
  {
    "text": "at home they have a very different setup which allows them to give you like 10",
    "start": "574870",
    "end": "580870"
  },
  {
    "text": "gig connections from every computer to pretty much any other computer under environment including their object",
    "start": "580870",
    "end": "586000"
  },
  {
    "text": "stores so you're suddenly not finding that well before 12 local disks sitting",
    "start": "586000",
    "end": "591879"
  },
  {
    "text": "on one computer could generate about 1.2 gigabytes like about 100 megabytes per",
    "start": "591879",
    "end": "597189"
  },
  {
    "text": "second is a reasonable approximation for what you can get maybe 150 megabytes per second for what he can get from a single",
    "start": "597189",
    "end": "602379"
  },
  {
    "text": "disk in terms of bandwidth so 12 disks give you like 1 to 1.5 gigabytes per",
    "start": "602379",
    "end": "607569"
  },
  {
    "text": "second which is about a 10 gig knit and ethernet card suddenly you can actually saturate the 10 gig Ethernet card from a",
    "start": "607569",
    "end": "614439"
  },
  {
    "text": "remote storage and actually get the exact same performance this is a big change you could do that on a one",
    "start": "614439",
    "end": "619629"
  },
  {
    "text": "computer basis before you couldn't do that a large scale because you always always had oversubscription policy to",
    "start": "619629",
    "end": "625600"
  },
  {
    "text": "your network you couldn't just like move petabytes of data across your network without having huge impacts on the",
    "start": "625600",
    "end": "630670"
  },
  {
    "text": "network performance on the other hand with the way the datacenter designs are done with as the ends these days you can",
    "start": "630670",
    "end": "636339"
  },
  {
    "text": "actually do that you can have 10 gig links between every single computer in addition to do all your storage so remote storage is extremely important",
    "start": "636339",
    "end": "643660"
  },
  {
    "text": "when you start talking with cloud and because it gives you like a bunch of flexibility that you don't normally have you can share data across multiple",
    "start": "643660",
    "end": "649509"
  },
  {
    "text": "clusters you put your data and something like an object store s3 and that s3",
    "start": "649509",
    "end": "654759"
  },
  {
    "text": "object store can be the single source of data for five different clusters your QA",
    "start": "654759",
    "end": "660399"
  },
  {
    "text": "your test under vou Eddie a production all of them can run of the exact same data copy which is actually pretty interesting",
    "start": "660399",
    "end": "666250"
  },
  {
    "text": "it can be lasting now because your computer and storage are disaggregated this is a really important thing which",
    "start": "666250",
    "end": "671380"
  },
  {
    "text": "because you can now scale your computer independent of your storage the traditional hydro pocket is you just did not support that you had your source in",
    "start": "671380",
    "end": "677500"
  },
  {
    "text": "your computer tied together very tightly so you can do things in terms of scaling which are very different from what you could do before and of course because",
    "start": "677500",
    "end": "684970"
  },
  {
    "text": "these clusters are so dynamic you can actually create clusters as needed put a",
    "start": "684970",
    "end": "689980"
  },
  {
    "text": "poor pro user you can have an app which is defined as a particular ETL flow and you can literally launch a cluster just",
    "start": "689980",
    "end": "696160"
  },
  {
    "text": "for the duration of the app and shut it down it's this is particularly common for certain class of apps and I'm going to talk about so these are the",
    "start": "696160",
    "end": "702220"
  },
  {
    "text": "fundamental architectural changes that have happened in the data center level you could imagine doing this in a",
    "start": "702220",
    "end": "709000"
  },
  {
    "text": "non-pom environment too but most of the young professors do not look like this from Anna clocking perspective so the",
    "start": "709000",
    "end": "715180"
  },
  {
    "text": "traditional architecture still makes a lot of sense there but in a cloud object storage and remote object stores",
    "start": "715180",
    "end": "720970"
  },
  {
    "text": "fundamentally representing remote storage is a big transformation and it's enabled by all these changes in data",
    "start": "720970",
    "end": "726790"
  },
  {
    "text": "center design which is somewhat invisible to us as users of s3 we just sort of like treated as a magical black box but this is sort of like the",
    "start": "726790",
    "end": "732430"
  },
  {
    "text": "important thing that's going on here now having said all this I don't mean to",
    "start": "732430",
    "end": "737680"
  },
  {
    "text": "imply that you can get the exact same performance as local disks with an object store you do have performance degradation but you're often willing to",
    "start": "737680",
    "end": "744010"
  },
  {
    "text": "give up some of that performance degradation in exchange for the benefits I'm describing here okay and by the way",
    "start": "744010",
    "end": "750640"
  },
  {
    "text": "feel free to interrupt me and ask questions if you have any at any time any time you have any so now let me talk",
    "start": "750640",
    "end": "756790"
  },
  {
    "start": "754000",
    "end": "794000"
  },
  {
    "text": "a little bit about architectural patterns when we talk with the cloud again the big shift from our perspective",
    "start": "756790",
    "end": "762040"
  },
  {
    "text": "is the fact that the object store becomes a really good place to store your data long-term object stores have",
    "start": "762040",
    "end": "768850"
  },
  {
    "text": "really nice price dynamics again tying to the discussion we had earlier about it the economics of data object stores",
    "start": "768850",
    "end": "775270"
  },
  {
    "text": "can if you see there's three prices there like usually around five cents a gigabyte terabyte er sorry uh it's it's",
    "start": "775270",
    "end": "782320"
  },
  {
    "text": "a five cent of gigabyte especially when it comes down to and like it's relatively cheap it's usually cheaper",
    "start": "782320",
    "end": "787720"
  },
  {
    "text": "than when you actually do buy your own like HP gear or whatever so well it's",
    "start": "787720",
    "end": "793480"
  },
  {
    "text": "actually significant you're using your price for maintaining this data so if",
    "start": "793480",
    "end": "798880"
  },
  {
    "text": "you assume that that becomes your core location for value store your data we tend to see things is like many",
    "start": "798880",
    "end": "805470"
  },
  {
    "text": "classes of vocal adrenaline Hadoop so the traditional type of vocalist that Hadoop has been known for five years ago",
    "start": "805470",
    "end": "812130"
  },
  {
    "text": "was very bad SH oriented data processing your luck talking about doing et al you're doing maybe a modeling accessory",
    "start": "812130",
    "end": "819030"
  },
  {
    "text": "running a machine learning model and machine learning models can crunch through large amounts of data and do a lot of compute these kinds of",
    "start": "819030",
    "end": "827280"
  },
  {
    "text": "applications tend to have a certain pattern specifically ETL jobs you don't",
    "start": "827280",
    "end": "833190"
  },
  {
    "text": "run them arbitrarily all the time you often run them in a schedule your data lands at a certain time you pick up the",
    "start": "833190",
    "end": "839100"
  },
  {
    "text": "data you run you run your ETL window at night perhaps from midnight to 4am that's when you do the ideal job it is",
    "start": "839100",
    "end": "844800"
  },
  {
    "text": "very consistent pattern typically in those situations there's a huge benefit",
    "start": "844800",
    "end": "851040"
  },
  {
    "text": "from being able to do things like transient clusters you spin them a cluster for the duration of your ETL Germany spin it down this is probably",
    "start": "851040",
    "end": "857370"
  },
  {
    "text": "what most people are most familiar with in the cloud big data world and it works",
    "start": "857370",
    "end": "862770"
  },
  {
    "text": "really well you can still use local storage if necessary because it can give you performance benefits especially when you're doing transformations that",
    "start": "862770",
    "end": "869100"
  },
  {
    "text": "require going back writing back to disk and then taking it picking it up again and doing more transformations together",
    "start": "869100",
    "end": "874320"
  },
  {
    "text": "particularly complex pipeline it's often better to copy data locally do the transformation and send the results back",
    "start": "874320",
    "end": "879680"
  },
  {
    "text": "but in other cases where you doing simpler things you may actually just never have local disk you may just pull",
    "start": "879680",
    "end": "885180"
  },
  {
    "text": "data from s3 do the transformation and write back to s3 so that's one pattern",
    "start": "885180",
    "end": "890640"
  },
  {
    "text": "of workloads this is sort of the one that's probably the most well-known for Hadoop and of course you can know when",
    "start": "890640",
    "end": "897180"
  },
  {
    "start": "896000",
    "end": "997000"
  },
  {
    "text": "you're sitting in the cloud you can actually take advantage of things like elasticity you can say hey today in my",
    "start": "897180",
    "end": "902820"
  },
  {
    "text": "ETA window I found that I have much larger amounts of data coming in because it's I don't know it's Thanksgiving and",
    "start": "902820",
    "end": "908340"
  },
  {
    "text": "you had like a lot more orders go through your system now you can actually do things like scale your cluster for",
    "start": "908340",
    "end": "914130"
  },
  {
    "text": "the for that particular days data needs this is complex it's not it's not",
    "start": "914130",
    "end": "919440"
  },
  {
    "text": "trivial but it's possible to automate so if you have specially if you have some amount of credibility in Speights and",
    "start": "919440",
    "end": "925080"
  },
  {
    "text": "whatnot you can actually plan for that appropriately in your job itself and these clusters tend to be a transient",
    "start": "925080",
    "end": "932339"
  },
  {
    "text": "again one thing I found here is that a lot of people tend to start with transient clusters",
    "start": "932339",
    "end": "937680"
  },
  {
    "text": "because it's very convenient but as they do more and more work on Hadoop there it",
    "start": "937680",
    "end": "942870"
  },
  {
    "text": "will start start to becoming continuous it's not usually like completely transient so then you start having these",
    "start": "942870",
    "end": "948180"
  },
  {
    "text": "longer running clusters but then what do you start doing is you start changing the size of the cluster over time that's",
    "start": "948180",
    "end": "953819"
  },
  {
    "text": "probably the most common pattern we see which is like a few long-running clusters they tend to do the processing your storages in s3 and the cluster size",
    "start": "953819",
    "end": "961800"
  },
  {
    "text": "varies dramatically over time based on the type of processing you need to do at any given point in time so that's that's",
    "start": "961800",
    "end": "967649"
  },
  {
    "text": "one model the other model would be things like bi and analytics you're",
    "start": "967649",
    "end": "973050"
  },
  {
    "text": "running tableau or what-have-you QlikTech one of those kinds of tools and you're exposing this data set that",
    "start": "973050",
    "end": "979290"
  },
  {
    "text": "you've done all the CTL work on and prepped it and made it ready to be consumed you're exposing to see your analysts there potentially exposing it",
    "start": "979290",
    "end": "986160"
  },
  {
    "text": "to hundreds of users without thousands of users have been and these guys are going to come in with higher level tools",
    "start": "986160",
    "end": "991230"
  },
  {
    "text": "you could be a search interface it could be a bi interface and in this case you",
    "start": "991230",
    "end": "997649"
  },
  {
    "start": "997000",
    "end": "1114000"
  },
  {
    "text": "don't tend to have the same flexibility you have in these ETL jobs where you don't have predictability of blood",
    "start": "997649",
    "end": "1003319"
  },
  {
    "text": "flowed maybe you have some high-level patterns you can be like hey 9am to 5pm is when like these guys seem to work and",
    "start": "1003319",
    "end": "1009819"
  },
  {
    "text": "that's when you have lock more computationally need but after 5pm everybody goes home and it doesn't",
    "start": "1009819",
    "end": "1016339"
  },
  {
    "text": "require nearly as many resources so this gives you a different set of constraints",
    "start": "1016339",
    "end": "1021829"
  },
  {
    "text": "to work work with and also the other big constraint here is that your bi user is",
    "start": "1021829",
    "end": "1028760"
  },
  {
    "text": "not gonna be happy if they have Layton sees for the responses so they're not super excited about like waiting for",
    "start": "1028760",
    "end": "1034520"
  },
  {
    "text": "like 30 seconds instead of five seconds which they could get with their traditional data warehouse environment so when you start dealing with object",
    "start": "1034520",
    "end": "1040760"
  },
  {
    "text": "stores now it becomes a little bit more challenging where ETL and modeling was just a slam-dunk fit for running on",
    "start": "1040760",
    "end": "1047150"
  },
  {
    "text": "object stores it doesn't get that easy in the BI world because people do have a",
    "start": "1047150",
    "end": "1053000"
  },
  {
    "text": "performance expectation and they don't actually there are willing to give up that pavones degradation that happens with running against a much storage so",
    "start": "1053000",
    "end": "1060080"
  },
  {
    "text": "in this case it's much more common to have local data copies even but you can",
    "start": "1060080",
    "end": "1065090"
  },
  {
    "text": "do even in AWS and have your long-running cluster which doesn't get shut down ever you can",
    "start": "1065090",
    "end": "1072250"
  },
  {
    "text": "potentially do some sizing things but the sizing changes are much more coarse",
    "start": "1072250",
    "end": "1077620"
  },
  {
    "text": "grained they're not as granular as you can do an ETL job on an ETL job you can literally change the size and add the",
    "start": "1077620",
    "end": "1083140"
  },
  {
    "text": "job level here you're like hey maybe 95 I'll have a different size than 55 29 or",
    "start": "1083140",
    "end": "1088450"
  },
  {
    "text": "whatever so the level at which you can make size and changes tends to be much more reduced and many cases you may find",
    "start": "1088450",
    "end": "1094750"
  },
  {
    "text": "that it's not even what you want to do it again depends on the level of optimization you want to do there but",
    "start": "1094750",
    "end": "1100480"
  },
  {
    "text": "the other big thing here is the local search often becomes required having said that you may still want to have as",
    "start": "1100480",
    "end": "1105670"
  },
  {
    "text": "cos you're persistent store for long for your data but Cascada is necessary in local storage in order to be effective",
    "start": "1105670",
    "end": "1112230"
  },
  {
    "text": "so slightly different pattern and if you see sort of like the traditional the",
    "start": "1112230",
    "end": "1118480"
  },
  {
    "start": "1114000",
    "end": "1201000"
  },
  {
    "text": "options that you have in the data warehousing world on the cloud they tend to look like this and that they don't",
    "start": "1118480",
    "end": "1124420"
  },
  {
    "text": "actually use as three is their core storage they have some connectors which make it easy to grab data but they're all just doing the same thing but",
    "start": "1124420",
    "end": "1129870"
  },
  {
    "text": "basically companies have done for like 30 years which is copying data locally on to local disks and stuffing it in",
    "start": "1129870",
    "end": "1135190"
  },
  {
    "text": "there so while it seems very cloudy because of the mahkum architecture it's not actually that cloudy because of this",
    "start": "1135190",
    "end": "1142150"
  },
  {
    "text": "aspect of things and that's what a very good reason so I don't think there's something wrong with this and just pointing out that it it's not as elastic",
    "start": "1142150",
    "end": "1148720"
  },
  {
    "text": "as you ideally like it to be you can't do this at a Quaker well that's a fundamental issue so i think the model",
    "start": "1148720",
    "end": "1153880"
  },
  {
    "text": "is correct here which is to do this something like this and then there are systems which are no sequel systems why",
    "start": "1153880",
    "end": "1161830"
  },
  {
    "text": "am I talking about NOS ecosystems in our world we tend to look at all three of these class of applications so for in",
    "start": "1161830",
    "end": "1167110"
  },
  {
    "text": "our well Hadoop specifically we have a system called HBase there are other options that look like this cassandra is",
    "start": "1167110",
    "end": "1172570"
  },
  {
    "text": "another popular one mongos another popular one in this case things are even",
    "start": "1172570",
    "end": "1178210"
  },
  {
    "text": "more different because you're typically serving some live application off of your no sequel store and with your life",
    "start": "1178210",
    "end": "1185200"
  },
  {
    "text": "applications production requirements come in you're potentially saving website requests and responses have to",
    "start": "1185200",
    "end": "1192100"
  },
  {
    "text": "be within 200 milliseconds or end users face like massive delays your budget for",
    "start": "1192100",
    "end": "1197320"
  },
  {
    "text": "how long you can take spikes is very very low and also like when you deal with no",
    "start": "1197320",
    "end": "1203440"
  },
  {
    "start": "1201000",
    "end": "1277000"
  },
  {
    "text": "sequel stores you have like a hash table which is dispatching a particular object request to the right server in these",
    "start": "1203440",
    "end": "1210370"
  },
  {
    "text": "situations like doing something like a elastic cluster has drastically asians",
    "start": "1210370",
    "end": "1215950"
  },
  {
    "text": "on the code architecture because you have to repartition your data across notes differently when you add nodes you",
    "start": "1215950",
    "end": "1221980"
  },
  {
    "text": "don't just add nodes and have it magically work when you add no G of every partition the data so that the partisan Rangers change this is a more",
    "start": "1221980",
    "end": "1228820"
  },
  {
    "text": "drastic operation and this is more drastic operation and a more critical application because you're running a production web server potentially",
    "start": "1228820",
    "end": "1233950"
  },
  {
    "text": "against this data set so the level of granularity which you're willing to do",
    "start": "1233950",
    "end": "1239190"
  },
  {
    "text": "adjustments to your class sizes becomes even coarser where I might do changes to",
    "start": "1239190",
    "end": "1245170"
  },
  {
    "text": "my cluster size literally in a per job basis for etl and modeling I mood to",
    "start": "1245170",
    "end": "1250380"
  },
  {
    "text": "maybe once a day I can do some changes for my bi type things and now it's",
    "start": "1250380",
    "end": "1255820"
  },
  {
    "text": "something like no sequel story are way more conservative typically some users can be a little bit more aggressive but",
    "start": "1255820",
    "end": "1262690"
  },
  {
    "text": "generally what we see is this becomes more like a capacity planning exercise than like a continuous elasticity",
    "start": "1262690",
    "end": "1267880"
  },
  {
    "text": "exercise so maybe like once a month you might leave is it and think about what you might want to change but it's not nearly as frequent as dynamic as you've",
    "start": "1267880",
    "end": "1274690"
  },
  {
    "text": "seen the other two systems and here again latency becomes critical and you",
    "start": "1274690",
    "end": "1280150"
  },
  {
    "start": "1277000",
    "end": "1331000"
  },
  {
    "text": "cannot get good latency from your objects or so it's much much more typical to have local storage as the",
    "start": "1280150",
    "end": "1285640"
  },
  {
    "text": "primary data repository so while the other two models have often used the",
    "start": "1285640",
    "end": "1291670"
  },
  {
    "text": "object store as your prime repository for your data in systems like HBase your",
    "start": "1291670",
    "end": "1296920"
  },
  {
    "text": "local storage might actually be a primary posit Orion your object store might be your backup location it's where",
    "start": "1296920",
    "end": "1302440"
  },
  {
    "text": "you save your data for safety reasons that's enough that's a common model again don't take any of these models is",
    "start": "1302440",
    "end": "1308500"
  },
  {
    "text": "like a definite you could almost always do other things here but I'm just talking with the primary patterns we",
    "start": "1308500",
    "end": "1314380"
  },
  {
    "text": "have seen so far in this world which is these three classes of patterns any questions on any of this so far yes",
    "start": "1314380",
    "end": "1324300"
  },
  {
    "text": "yeah so a good question what is the relationship between HDFS which is a distributed file system and s3 so the",
    "start": "1330080",
    "end": "1337410"
  },
  {
    "start": "1331000",
    "end": "1411000"
  },
  {
    "text": "funny thing is Hadoop itself has this like massive misnomer because they combine two different things and do this",
    "start": "1337410",
    "end": "1343620"
  },
  {
    "text": "one name which is the HDFS storage layer and the compute frameworks that are on top of it so the right way to think",
    "start": "1343620",
    "end": "1349410"
  },
  {
    "text": "about s3 so HDFS actually represents an API and an implementation so there's an",
    "start": "1349410",
    "end": "1355980"
  },
  {
    "text": "HDFS API which like your map reduce your spark whatever other big data system",
    "start": "1355980",
    "end": "1361110"
  },
  {
    "text": "that i run depend on anybody could implement that API and so s3 actually has a implementation of the HDFS API",
    "start": "1361110",
    "end": "1368130"
  },
  {
    "text": "that you could just plug in so you can actually use s3 is a direct replacement for HDFS in one way you could use it in",
    "start": "1368130",
    "end": "1375450"
  },
  {
    "text": "conjunction as well but the you know when I talk about like elastic workload where I'd run a job directly ancestry",
    "start": "1375450",
    "end": "1381930"
  },
  {
    "text": "I'm effectively treating as three as a replacement for HDFS where you may not need any local HDFS at all you may also",
    "start": "1381930",
    "end": "1388650"
  },
  {
    "text": "find reasons as I said earlier that you may find reasons to have a copy of data in a local HDFS implementation but",
    "start": "1388650",
    "end": "1393900"
  },
  {
    "text": "that's a choice that's not a requirement so you can think of as three as an alternative implementation of HDFS",
    "start": "1393900",
    "end": "1400170"
  },
  {
    "text": "that's the best way to I would say to think about it does that answer your question okay anything else on this",
    "start": "1400170",
    "end": "1407550"
  },
  {
    "text": "front okay so I want to just talk briefly about transient versus",
    "start": "1407550",
    "end": "1413520"
  },
  {
    "start": "1411000",
    "end": "1594000"
  },
  {
    "text": "long-running clusters transient clusters have some benefits specifically when I",
    "start": "1413520",
    "end": "1418890"
  },
  {
    "text": "talk with transient classes i'm talking about things where you will build an app that actually launches a cluster as part",
    "start": "1418890",
    "end": "1427380"
  },
  {
    "text": "of the app so one of the standard dichotomies between on-prem environments and cloud environments is that your apps",
    "start": "1427380",
    "end": "1434040"
  },
  {
    "text": "can be much more self contained in the cloud than they can in a more traditional environment the reason for",
    "start": "1434040",
    "end": "1440550"
  },
  {
    "text": "this is that if you have a nap you typically say I pulled out I've covered",
    "start": "1440550",
    "end": "1446160"
  },
  {
    "text": "a bunch of resources for this app and this app assumes that this cluster exists and has in it you know some",
    "start": "1446160",
    "end": "1452610"
  },
  {
    "text": "configuration which says this is the classical run on that's what you should depend on in the cloud world with a",
    "start": "1452610",
    "end": "1457860"
  },
  {
    "text": "more transient approach the app actually creates the cluster that's going to run on and then like shuts it down at the",
    "start": "1457860",
    "end": "1463620"
  },
  {
    "text": "end of the process so it's a very different model it's more of that DevOps model that people they use the term",
    "start": "1463620",
    "end": "1468840"
  },
  {
    "text": "DevOps a lot for this but the fundamental idea is that your app is fully encapsulated including the infrastructure runs on so an app",
    "start": "1468840",
    "end": "1476100"
  },
  {
    "text": "something starts the app up like equally in the etl case it could be as simple as like a cron job or a notification from",
    "start": "1476100",
    "end": "1482400"
  },
  {
    "text": "s3 and that could that could literally trigger the entire process of creating a",
    "start": "1482400",
    "end": "1488490"
  },
  {
    "text": "cluster attaching like your job to the cluster running the job and then carrying down the cluster so the app",
    "start": "1488490",
    "end": "1495210"
  },
  {
    "text": "itself contains the logic for creating the cluster as necessary so it's a much more fully self-contained environment",
    "start": "1495210",
    "end": "1501690"
  },
  {
    "text": "but this literally doesn't work with if you depend on local storage because",
    "start": "1501690",
    "end": "1506809"
  },
  {
    "text": "local stores requires a clustered exists where the data is sitting so this fundamentally works best if you have",
    "start": "1506809",
    "end": "1512220"
  },
  {
    "text": "remote storage is a prerequisite remote storage is a prerequisite for this environment so it's one of the big",
    "start": "1512220",
    "end": "1519240"
  },
  {
    "text": "benefits here from a reese's management perspective it stinks is so much simpler you don't have to worry about multiple users because your app runs on this",
    "start": "1519240",
    "end": "1525900"
  },
  {
    "text": "cluster and that's all the cluster is there to serve and then it goes away so you can do cosmetics been really effectively as well but longer in",
    "start": "1525900",
    "end": "1533850"
  },
  {
    "text": "clusters often end up being much more cost effective in many cases where a lot of people start with these clusters",
    "start": "1533850",
    "end": "1541559"
  },
  {
    "text": "which are ephemeral and these apps such a fully self-contained they find that the cost dynamics don't work very well because they continuously have workload",
    "start": "1541559",
    "end": "1548250"
  },
  {
    "text": "running and the way the pricing is set up it's often better to just keep your clusters up for a long period of time",
    "start": "1548250",
    "end": "1553980"
  },
  {
    "text": "and just run your jobs within the cluster there are sort of the average utilization and the peak utilization and",
    "start": "1553980",
    "end": "1559740"
  },
  {
    "text": "having your average utilization be always on just sort of makes sense and just handle it lastly the peak side this",
    "start": "1559740",
    "end": "1565799"
  },
  {
    "text": "requires a little bit more planning and forethought but give you really good cost benefits so as you find yourself",
    "start": "1565799",
    "end": "1572190"
  },
  {
    "text": "scaling the number of fuse cases you'd apply this becomes a much more common approach I can still be fully contained",
    "start": "1572190",
    "end": "1578549"
  },
  {
    "text": "and I'll talk about this a little bit more you can still do this develops thing it requires some changes the way things work but here you can also do",
    "start": "1578549",
    "end": "1584970"
  },
  {
    "text": "things like local storage which really doesn't work in the transient case and",
    "start": "1584970",
    "end": "1590070"
  },
  {
    "text": "one important use I want to mention here I talked about these different classes of workloads",
    "start": "1590070",
    "end": "1596629"
  },
  {
    "start": "1594000",
    "end": "1648000"
  },
  {
    "text": "typically an ETL job remodeling job is doing the work is preparing the data in",
    "start": "1596629",
    "end": "1602399"
  },
  {
    "text": "order to start doing things like bi on top of the data so if you think that like you need the low latency response",
    "start": "1602399",
    "end": "1608610"
  },
  {
    "text": "that requires local stores for your bi your ideal job actually has to do processing from data there was liner in",
    "start": "1608610",
    "end": "1614279"
  },
  {
    "text": "s3 and then dump it somewhere where the BI tools can access it which we are soften HDFS that's local storage so one",
    "start": "1614279",
    "end": "1621690"
  },
  {
    "text": "scenario that VC often is a long-running look cluster with local storage dash through it which has the data for bi and",
    "start": "1621690",
    "end": "1628669"
  },
  {
    "text": "that cluster expanding to just have computer lee nodes which suck data from s3 do et al and then landed in this HDFS",
    "start": "1628669",
    "end": "1636649"
  },
  {
    "text": "share like that you have next to it so you actually have these mixing mode patterns where you have the edl jobs",
    "start": "1636649",
    "end": "1642539"
  },
  {
    "text": "just running computer work and these its long-running HDFS clusters as well side",
    "start": "1642539",
    "end": "1648059"
  },
  {
    "start": "1648000",
    "end": "1681000"
  },
  {
    "text": "by side with these things that's sort of the case where long-running classes sort of make sense because you actually have this long-running class area for local",
    "start": "1648059",
    "end": "1654029"
  },
  {
    "text": "HDFS so that's probably a specific",
    "start": "1654029",
    "end": "1659070"
  },
  {
    "text": "detail around how we see patterns emerging here now I want to talk a little bit about the ability to do a",
    "start": "1659070",
    "end": "1666779"
  },
  {
    "text": "biopsy model with long-running clusters and I think if any of you have attended a netflix talks before they've actually",
    "start": "1666779",
    "end": "1673200"
  },
  {
    "text": "done a really good job of this they're one of the more advanced users of big",
    "start": "1673200",
    "end": "1678960"
  },
  {
    "text": "data applications on top of Amazon's they've done a lot of discovery in the space and they have something that is",
    "start": "1678960",
    "end": "1684299"
  },
  {
    "start": "1681000",
    "end": "1842000"
  },
  {
    "text": "they have a system called genie there's other versions of this kind of thing that work in other environments but",
    "start": "1684299",
    "end": "1693259"
  },
  {
    "text": "fundamentally if you want to do this develops model for long-running classes what often happens as a company who",
    "start": "1693259",
    "end": "1698999"
  },
  {
    "text": "which which has a large amount of data processing happening in the cloud you may often find that you have multiple",
    "start": "1698999",
    "end": "1704609"
  },
  {
    "text": "clusters which are long-running they're elastic of course in nature but their",
    "start": "1704609",
    "end": "1709649"
  },
  {
    "text": "long-running and they're all backed by some object or potentially when an application wants to dis find the",
    "start": "1709649",
    "end": "1715919"
  },
  {
    "text": "location to run where before I described two models one model which is hard-coded",
    "start": "1715919",
    "end": "1721039"
  },
  {
    "text": "location of a particular cluster and another model which is the app it's the cluster as necessary there's",
    "start": "1721039",
    "end": "1726270"
  },
  {
    "text": "actually a third model which is probably the right long-term model here which is that the job says I need a cluster with",
    "start": "1726270",
    "end": "1734370"
  },
  {
    "text": "this many resources available to me I just want somebody to find give me that cluster back and so they'll be often",
    "start": "1734370",
    "end": "1741180"
  },
  {
    "text": "it's something that acts as a dispatcher and this dispatcher can say hey this job needs this many resources I have these",
    "start": "1741180",
    "end": "1746820"
  },
  {
    "text": "four long-running clusters available I'm going to pick the cluster that meet that has the capacity to handle this person's",
    "start": "1746820",
    "end": "1752910"
  },
  {
    "text": "resource needs so there's effectively a layer of indirection here where there's",
    "start": "1752910",
    "end": "1758370"
  },
  {
    "text": "a dispatch system which finds an appropriate cluster this thing can get much more interesting here while I",
    "start": "1758370",
    "end": "1764070"
  },
  {
    "text": "talked about one set of policies which is how much resources do you need there are much more complex policies you can",
    "start": "1764070",
    "end": "1769320"
  },
  {
    "text": "attach here you could do things like this job wants to run in a very secure environment because it's running on",
    "start": "1769320",
    "end": "1774780"
  },
  {
    "text": "secure data in which case you need to find an environment where encryption is flip turn on you need Kerberos to",
    "start": "1774780",
    "end": "1779970"
  },
  {
    "text": "authenticate you can find other types of policies you can say hey this job is working on data that I know needs to be",
    "start": "1779970",
    "end": "1785550"
  },
  {
    "text": "replicated across multiple region source I'm going to put it on this cluster which actually has some policies associated with it that enables those",
    "start": "1785550",
    "end": "1792540"
  },
  {
    "text": "kinds of things so you can do more much more complex dispatch rules by building",
    "start": "1792540",
    "end": "1798090"
  },
  {
    "text": "a simple dispatcher but even a basic dispatcher is very useful for handling multiple clusters environment and",
    "start": "1798090",
    "end": "1804870"
  },
  {
    "text": "finding an appropriate environment to run your job so this is a little bit",
    "start": "1804870",
    "end": "1810420"
  },
  {
    "text": "more advanced I'd say some of the more cutting edge deployments tend to do this but I think it's still a ways to go in",
    "start": "1810420",
    "end": "1817320"
  },
  {
    "text": "before becomes common parlance at least unfortunately there's no easy out of the box system to do this so you oftentimes",
    "start": "1817320",
    "end": "1823920"
  },
  {
    "text": "have to build something custom for these kinds of situations okay so I've talked",
    "start": "1823920",
    "end": "1831270"
  },
  {
    "text": "a lot about current mark the current patterns one thing I want to talk about is some of the things you can do in the",
    "start": "1831270",
    "end": "1836490"
  },
  {
    "text": "cloud that are not possible on premise I'm not yet being done in the Hadoop environments there's a bunch of stuff",
    "start": "1836490",
    "end": "1844860"
  },
  {
    "start": "1842000",
    "end": "2054000"
  },
  {
    "text": "you can do we're given that you're running in the cloud you can actually make the systems much much smarter there",
    "start": "1844860",
    "end": "1852180"
  },
  {
    "text": "are very few systems available to gay which can do completely smart scaling",
    "start": "1852180",
    "end": "1857610"
  },
  {
    "text": "you can imagine Hadoop cluster that you can shrink and grow based on their set sizes I talked",
    "start": "1857610",
    "end": "1863170"
  },
  {
    "text": "about that there are many more metrics you can leverage we've done this with in some customer pocs where you have a",
    "start": "1863170",
    "end": "1869410"
  },
  {
    "text": "spark job during a machine learning model based on various attributes of CPU",
    "start": "1869410",
    "end": "1874930"
  },
  {
    "text": "usage for example it's getting barton linked on cpu you can actually create a policy that spins up more compute to run against this thing so we can imagine",
    "start": "1874930",
    "end": "1882490"
  },
  {
    "text": "much smarter policies where the job will Auto scale itself what do you really want to get to it some long-term",
    "start": "1882490",
    "end": "1889800"
  },
  {
    "text": "position is forget the number of nodes involved you have a job it needs to do some processing and some data and the",
    "start": "1889800",
    "end": "1896530"
  },
  {
    "text": "cluster sizes itself correctly to run the job in the right amount of time frankly speaking this is still a pipe",
    "start": "1896530",
    "end": "1902770"
  },
  {
    "text": "dream because the complexity of a lot of these applications such that it's very hard to predict what is going to be",
    "start": "1902770",
    "end": "1908140"
  },
  {
    "text": "needed to run successfully but I think there are ways in which we can approach this problem again this is a little future looking this not so that exists",
    "start": "1908140",
    "end": "1914440"
  },
  {
    "text": "today in any practical sense that are like attempts to do this which on a custom per-app basis but not in the",
    "start": "1914440",
    "end": "1920980"
  },
  {
    "text": "generalizable way but I think this is sort of like where Hadoop will go when in the cloud other things you can do",
    "start": "1920980",
    "end": "1926980"
  },
  {
    "text": "here there's a lot of elements and Hadoop which are necessary for high availability what you don't want to have",
    "start": "1926980",
    "end": "1933190"
  },
  {
    "text": "happen is you have a 16-hour ETL process and are 15 your master node fails and",
    "start": "1933190",
    "end": "1939940"
  },
  {
    "text": "you had a 3-star your job Hadoop is actually pretty easily into these situations but we can do much better we",
    "start": "1939940",
    "end": "1946840"
  },
  {
    "text": "have high availability today where you have two masters and you can fail over to the right thing but when a failure",
    "start": "1946840",
    "end": "1952090"
  },
  {
    "text": "happens somebody has to come in and actually like fix the failed node or create a new node and said set this up",
    "start": "1952090",
    "end": "1957400"
  },
  {
    "text": "for a che again in the cloud you can actually do much more dynamic things where I can just automatically create a new master and just auto provision this",
    "start": "1957400",
    "end": "1964390"
  },
  {
    "text": "stuff and get it attached so the amount of IT operation touch which you need can",
    "start": "1964390",
    "end": "1970000"
  },
  {
    "text": "be significantly reduced again unfortunately this is not done yet but these are the kinds of things I think are really important going forward for",
    "start": "1970000",
    "end": "1976330"
  },
  {
    "text": "Hadoop to address as we get better running in the cloud again we talked about smart job dispatch which is the",
    "start": "1976330",
    "end": "1982480"
  },
  {
    "text": "what I was talking about earlier that's not a standardized component of the Hadoop stock today I think it's important to create something which is a",
    "start": "1982480",
    "end": "1988720"
  },
  {
    "text": "standard way to do those kinds of policy based dispatching there are people who do this with tools",
    "start": "1988720",
    "end": "1994470"
  },
  {
    "text": "like uzi which is a workflow manager in Hadoop but it's self very custom on a",
    "start": "1994470",
    "end": "1999570"
  },
  {
    "text": "per cup per customer bases and I feel like this needs to be generalized much better and even doing things like yarn",
    "start": "1999570",
    "end": "2007940"
  },
  {
    "text": "which is a recess manager decides where jobs run if I want to do my ETL job in",
    "start": "2007940",
    "end": "2013130"
  },
  {
    "text": "the same cluster where I store my bi workloads email often want to partition your job so that some notes on your ETL",
    "start": "2013130",
    "end": "2019220"
  },
  {
    "text": "work and some not run your bi work so they don't step all over each other that's another case where we can",
    "start": "2019220",
    "end": "2024830"
  },
  {
    "text": "actually do some interesting work in the resource manager to make this much more dynamic and intelligent so just going to",
    "start": "2024830",
    "end": "2031220"
  },
  {
    "text": "give you a taste of the kinds of things that we can enable going forward but",
    "start": "2031220",
    "end": "2036410"
  },
  {
    "text": "Hadoop doesn't do yet it's one of those things which need to improve its that's leave that there and I want to switch",
    "start": "2036410",
    "end": "2043760"
  },
  {
    "text": "briefly to some interesting things that are happening at the chipset level that actually impacts big data quite quite",
    "start": "2043760",
    "end": "2051980"
  },
  {
    "text": "dramatically so like intel has been doing a bunch of work in actually",
    "start": "2051980",
    "end": "2057169"
  },
  {
    "start": "2054000",
    "end": "2160000"
  },
  {
    "text": "enabling data applications to run much better at random with much better performance by doing innovations of the",
    "start": "2057169",
    "end": "2064429"
  },
  {
    "text": "silicon level for those of you who are doing encryption type work in Hadoop and",
    "start": "2064429",
    "end": "2070550"
  },
  {
    "text": "this is very common actually many of our secure customers want the data to be encrypted at all times you can see s3",
    "start": "2070550",
    "end": "2076340"
  },
  {
    "text": "and EBS are both added encryption capabilities there we've seen we've seen pretty dramatic improvements by actually",
    "start": "2076340",
    "end": "2082310"
  },
  {
    "text": "taking it one of the chipset features and most this should be hopefully transparent to you guys because the",
    "start": "2082310",
    "end": "2087800"
  },
  {
    "text": "software vendors just do the right thing here but what we found is that when we take advantage of things like encryption",
    "start": "2087800",
    "end": "2094190"
  },
  {
    "text": "on chip the cost of encryption would drop from nearly 30-percent CPU costs for software encryption to like three to",
    "start": "2094190",
    "end": "2100790"
  },
  {
    "text": "five percent when you'd been down at the hardware level that's one example the even more impactful example in my mind",
    "start": "2100790",
    "end": "2106790"
  },
  {
    "text": "is the alias two adoro instruction set that's something that's been out in the last couple of years and their chips it's pretty ematic we have a customer",
    "start": "2106790",
    "end": "2114200"
  },
  {
    "text": "who's running a very large alternating alternating leads least squares which is",
    "start": "2114200",
    "end": "2120320"
  },
  {
    "text": "a recommendation system machine learning algorithm 60 million users 10 million items",
    "start": "2120320",
    "end": "2125710"
  },
  {
    "text": "million ratings the training time improved decently the mood improved by",
    "start": "2125710",
    "end": "2132130"
  },
  {
    "text": "thirty percent so you can actually see that the time it takes the train models and really large data sets improved the",
    "start": "2132130",
    "end": "2137290"
  },
  {
    "text": "prediction time to do your scoring went up like 200 times so it's actually there's an approximation is actually more than that but what one thing that",
    "start": "2137290",
    "end": "2144190"
  },
  {
    "text": "you should keep in mind when you start thinking about instant selection in the cloud for example is whether or not the",
    "start": "2144190",
    "end": "2150839"
  },
  {
    "text": "instance of 30 running actually have these kinds of capabilities if you're doing large edl or especially machine",
    "start": "2150839",
    "end": "2156640"
  },
  {
    "text": "learning work specifically this has huge impact and actually have a cable here of",
    "start": "2156640",
    "end": "2162480"
  },
  {
    "start": "2160000",
    "end": "2223000"
  },
  {
    "text": "specific instance types that actually do have some of these capabilities in them so I think a lot of these instances are",
    "start": "2162480",
    "end": "2170619"
  },
  {
    "text": "pretty much general-purpose m4s are actually very heavily used for our workloads the d-series is also very",
    "start": "2170619",
    "end": "2175660"
  },
  {
    "text": "heavily used so for hadoop on AWS specifically I often recommend the",
    "start": "2175660",
    "end": "2180849"
  },
  {
    "text": "d-series if you want local HDFS the BI class blog loads tend to be heavily d-series same is true for HBase class or",
    "start": "2180849",
    "end": "2188140"
  },
  {
    "text": "no secret stores the d-series is a very good choice but for your more dynamic workloads the mcd's is a good choice as",
    "start": "2188140",
    "end": "2195130"
  },
  {
    "text": "well again depending on a specific type of computation you're doing if you're more compute heavy you may want to look",
    "start": "2195130",
    "end": "2200770"
  },
  {
    "text": "at the CSeries and so on but do that we tend to see the most are the DN mcd's",
    "start": "2200770",
    "end": "2206530"
  },
  {
    "text": "and they both have some of these capabilities I was talking about as well okay so that's a super quick look at",
    "start": "2206530",
    "end": "2216720"
  },
  {
    "text": "things that are happening with respect to begin on the cloud I'm going to just",
    "start": "2216720",
    "end": "2221950"
  },
  {
    "text": "I'm going to end quickly here and talk just briefly about how this stuff all comes together so when you're running",
    "start": "2221950",
    "end": "2228550"
  },
  {
    "text": "the cloud fundamentally computers and intermediate all our interactions this is going back to the original three",
    "start": "2228550",
    "end": "2233710"
  },
  {
    "text": "things that I put up on the slides everything that can be measured will be measured systems like s3 dramatically",
    "start": "2233710",
    "end": "2239470"
  },
  {
    "text": "reduce the cost of storing this data so it's much much more cost efficient to",
    "start": "2239470",
    "end": "2244869"
  },
  {
    "text": "actually store lots of data that you would throw away normally consumer consumerization is a massive trend which",
    "start": "2244869",
    "end": "2251320"
  },
  {
    "text": "really matters a lot in new application development employees customers everybody expects more personal and",
    "start": "2251320",
    "end": "2257980"
  },
  {
    "text": "customized interactions and you can only do this by understanding each person each interaction in its specific context",
    "start": "2257980",
    "end": "2265180"
  },
  {
    "text": "experimentation if you have large amounts of data and you make it available to you data unless you can",
    "start": "2265180",
    "end": "2270650"
  },
  {
    "text": "actually have people try lots of different things to see what they can get out of this data set against or cost",
    "start": "2270650",
    "end": "2275840"
  },
  {
    "text": "is a big driver of a lot of this stuff and and then wrapping up here from where",
    "start": "2275840",
    "end": "2283220"
  },
  {
    "start": "2277000",
    "end": "2328000"
  },
  {
    "text": "I started earlier with cloud this is how like all those three times i mentioned relate to big data specifically with",
    "start": "2283220",
    "end": "2290840"
  },
  {
    "text": "self-service there's a lot more data exhaust that's coming out when you're dealing with application in the cloud",
    "start": "2290840",
    "end": "2296570"
  },
  {
    "text": "where computers handle every interaction vertical integration means that analytics would become much more",
    "start": "2296570",
    "end": "2302690"
  },
  {
    "text": "pervasive as you can do more and more of these kinds of things like there are more systems coming out which are not",
    "start": "2302690",
    "end": "2308120"
  },
  {
    "text": "just talking about individual ETL database bi type tools but they try to combine these things into their actual",
    "start": "2308120",
    "end": "2314480"
  },
  {
    "text": "applications and again aggregating the data from many users means during tons of data but you new opportunities and",
    "start": "2314480",
    "end": "2321470"
  },
  {
    "text": "techniques for analysis that's basically what I was going to stop i'm going to open it up for questions now any",
    "start": "2321470",
    "end": "2326900"
  },
  {
    "text": "questions at all",
    "start": "2326900",
    "end": "2329440"
  }
]
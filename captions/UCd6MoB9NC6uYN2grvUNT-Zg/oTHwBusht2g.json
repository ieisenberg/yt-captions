[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "hi everyone my name is David McAmis from",
    "start": "0",
    "end": "2159"
  },
  {
    "text": "Amazon Web Services we're here today to",
    "start": "2159",
    "end": "4380"
  },
  {
    "text": "talk a little bit about enterprise data",
    "start": "4380",
    "end": "6029"
  },
  {
    "text": "warehousing and specifically to patterns",
    "start": "6029",
    "end": "8280"
  },
  {
    "text": "you can use to help you offload or",
    "start": "8280",
    "end": "10139"
  },
  {
    "text": "migrate your data warehouse to the cloud",
    "start": "10139",
    "end": "12200"
  },
  {
    "text": "if we take a look at traditional data",
    "start": "12200",
    "end": "14910"
  },
  {
    "text": "warehouses they're often deployed on",
    "start": "14910",
    "end": "16650"
  },
  {
    "start": "15000",
    "end": "15000"
  },
  {
    "text": "relational databases or data warehousing",
    "start": "16650",
    "end": "18480"
  },
  {
    "text": "appliances and around the terabyte to",
    "start": "18480",
    "end": "20699"
  },
  {
    "text": "petabyte scale and these data warehouses",
    "start": "20699",
    "end": "23220"
  },
  {
    "text": "will often be used to serve operational",
    "start": "23220",
    "end": "25590"
  },
  {
    "text": "and ad-hoc reports dashboards etc to set",
    "start": "25590",
    "end": "28830"
  },
  {
    "text": "up these systems you need to spend a lot",
    "start": "28830",
    "end": "30510"
  },
  {
    "text": "of money up front and then the running",
    "start": "30510",
    "end": "32430"
  },
  {
    "text": "cost can be between ten to fifty",
    "start": "32430",
    "end": "34290"
  },
  {
    "text": "thousand dollars per terabyte per year",
    "start": "34290",
    "end": "37100"
  },
  {
    "text": "with traditional data warehousing our",
    "start": "37100",
    "end": "39480"
  },
  {
    "text": "customers are seeing data warehousing",
    "start": "39480",
    "end": "40980"
  },
  {
    "text": "costs rise due to massive data growth",
    "start": "40980",
    "end": "43350"
  },
  {
    "text": "combined with expensive licensing models",
    "start": "43350",
    "end": "45480"
  },
  {
    "text": "so while the cost of maintaining these",
    "start": "45480",
    "end": "47640"
  },
  {
    "text": "data warehouse platforms is increasing",
    "start": "47640",
    "end": "49379"
  },
  {
    "text": "the value they get out of them is not so",
    "start": "49379",
    "end": "52260"
  },
  {
    "text": "we look at the question of why customers",
    "start": "52260",
    "end": "54210"
  },
  {
    "text": "are migrating their data warehouses it's",
    "start": "54210",
    "end": "56399"
  },
  {
    "text": "because customers want to leverage more",
    "start": "56399",
    "end": "58140"
  },
  {
    "text": "modern data architectures to be able to",
    "start": "58140",
    "end": "60449"
  },
  {
    "text": "deliver analytics on a wider range of",
    "start": "60449",
    "end": "62399"
  },
  {
    "text": "data and tool sets they also want to",
    "start": "62399",
    "end": "65790"
  },
  {
    "text": "reduce the cost and complexity",
    "start": "65790",
    "end": "67320"
  },
  {
    "text": "associated with operating a traditional",
    "start": "67320",
    "end": "69420"
  },
  {
    "text": "data warehouse and that's where Amazon",
    "start": "69420",
    "end": "71490"
  },
  {
    "text": "redshift comes into play",
    "start": "71490",
    "end": "73610"
  },
  {
    "start": "73000",
    "end": "73000"
  },
  {
    "text": "Amazon redshift is a fully managed data",
    "start": "73610",
    "end": "76320"
  },
  {
    "text": "warehousing service from AWS that is",
    "start": "76320",
    "end": "78570"
  },
  {
    "text": "easy to use and very cost effective it",
    "start": "78570",
    "end": "81180"
  },
  {
    "text": "allows you to run complex analytical",
    "start": "81180",
    "end": "82950"
  },
  {
    "text": "queries against petabytes of data and",
    "start": "82950",
    "end": "84840"
  },
  {
    "text": "most results come back in seconds Amazon",
    "start": "84840",
    "end": "89159"
  },
  {
    "text": "redshift is fast",
    "start": "89159",
    "end": "90299"
  },
  {
    "text": "it delivers 10 times better performance",
    "start": "90299",
    "end": "92130"
  },
  {
    "text": "than on-premises data warehouses and",
    "start": "92130",
    "end": "94170"
  },
  {
    "text": "it's fast for all types of workloads",
    "start": "94170",
    "end": "96210"
  },
  {
    "text": "from short running queries to complex",
    "start": "96210",
    "end": "98460"
  },
  {
    "text": "long-running queries on trillions of",
    "start": "98460",
    "end": "100680"
  },
  {
    "text": "rows of data redshift leverages a",
    "start": "100680",
    "end": "104130"
  },
  {
    "text": "massive parallel processing architecture",
    "start": "104130",
    "end": "105899"
  },
  {
    "text": "to deliver high throughput and with",
    "start": "105899",
    "end": "108360"
  },
  {
    "text": "Amazon redshift you can create and start",
    "start": "108360",
    "end": "110340"
  },
  {
    "text": "using a data warehouse in minutes",
    "start": "110340",
    "end": "112049"
  },
  {
    "text": "creating schemas tables views and",
    "start": "112049",
    "end": "114420"
  },
  {
    "text": "loading your data redshift also",
    "start": "114420",
    "end": "117180"
  },
  {
    "text": "automates most of the common",
    "start": "117180",
    "end": "118409"
  },
  {
    "text": "administrative tasks to manage monitor",
    "start": "118409",
    "end": "120719"
  },
  {
    "text": "and scale your data warehouse including",
    "start": "120719",
    "end": "123119"
  },
  {
    "text": "backups updates and more there are no",
    "start": "123119",
    "end": "128190"
  },
  {
    "text": "upfront costs with Amazon redshift and",
    "start": "128190",
    "end": "130080"
  },
  {
    "text": "you only pay for what you use",
    "start": "130080",
    "end": "131430"
  },
  {
    "text": "start small for just 25 cents an hour",
    "start": "131430",
    "end": "133860"
  },
  {
    "text": "no commitments for larger workloads pay",
    "start": "133860",
    "end": "136470"
  },
  {
    "text": "as low as $1,000 per terabyte per year",
    "start": "136470",
    "end": "140450"
  },
  {
    "text": "Amazon redshift provides petabyte scale",
    "start": "140450",
    "end": "142800"
  },
  {
    "text": "data warehousing and you can resize your",
    "start": "142800",
    "end": "144870"
  },
  {
    "text": "cluster with a few clicks in a DBS",
    "start": "144870",
    "end": "146790"
  },
  {
    "text": "console or a simple API call you can",
    "start": "146790",
    "end": "149730"
  },
  {
    "text": "also quickly build integrated data Lake",
    "start": "149730",
    "end": "151740"
  },
  {
    "text": "and analytic solutions with Amazon",
    "start": "151740",
    "end": "153420"
  },
  {
    "text": "redshift using that as your data",
    "start": "153420",
    "end": "155220"
  },
  {
    "text": "warehouse and then using your existing",
    "start": "155220",
    "end": "157050"
  },
  {
    "text": "ETL reporting and analytic tools on top",
    "start": "157050",
    "end": "159959"
  },
  {
    "text": "and finally redshift is secure many",
    "start": "159959",
    "end": "164370"
  },
  {
    "text": "enterprises and financial services",
    "start": "164370",
    "end": "166080"
  },
  {
    "text": "healthcare retail and government trusts",
    "start": "166080",
    "end": "169170"
  },
  {
    "text": "Amazon redshift to run mission critical",
    "start": "169170",
    "end": "171000"
  },
  {
    "text": "workloads and keep their data secure",
    "start": "171000",
    "end": "174200"
  },
  {
    "text": "when considering a data warehouse",
    "start": "174200",
    "end": "176250"
  },
  {
    "text": "migration to the cloud most customers",
    "start": "176250",
    "end": "178140"
  },
  {
    "text": "can see the benefits of migrating their",
    "start": "178140",
    "end": "179790"
  },
  {
    "text": "data warehouse but there are a few",
    "start": "179790",
    "end": "181170"
  },
  {
    "text": "questions that customers start to ask",
    "start": "181170",
    "end": "182700"
  },
  {
    "text": "themselves first of all how quickly and",
    "start": "182700",
    "end": "185010"
  },
  {
    "text": "easily can I migrate my on-premise data",
    "start": "185010",
    "end": "186930"
  },
  {
    "text": "warehouse to the cloud how can I",
    "start": "186930",
    "end": "189420"
  },
  {
    "text": "minimize application downtime during the",
    "start": "189420",
    "end": "191670"
  },
  {
    "text": "migration how can I start offloading",
    "start": "191670",
    "end": "194190"
  },
  {
    "text": "data to start leveraging the compute",
    "start": "194190",
    "end": "196200"
  },
  {
    "text": "power of the cloud and are there ways to",
    "start": "196200",
    "end": "198750"
  },
  {
    "text": "automate schema conversion and conflict",
    "start": "198750",
    "end": "200340"
  },
  {
    "text": "analysis and can I migrate off of",
    "start": "200340",
    "end": "202590"
  },
  {
    "text": "commercial databases or data warehousing",
    "start": "202590",
    "end": "204209"
  },
  {
    "text": "appliances to help customers answer",
    "start": "204209",
    "end": "206910"
  },
  {
    "text": "these questions we've put together some",
    "start": "206910",
    "end": "208590"
  },
  {
    "text": "common patterns for offloading and",
    "start": "208590",
    "end": "210510"
  },
  {
    "text": "migrating off of your existing data",
    "start": "210510",
    "end": "212340"
  },
  {
    "text": "warehouse as well as some services and",
    "start": "212340",
    "end": "214320"
  },
  {
    "text": "tools to make the job even easier in",
    "start": "214320",
    "end": "217160"
  },
  {
    "text": "terms of tools the first tool we're",
    "start": "217160",
    "end": "219660"
  },
  {
    "text": "going to look at is the AWS database",
    "start": "219660",
    "end": "221430"
  },
  {
    "text": "migration service or DMS DMS helps you",
    "start": "221430",
    "end": "224370"
  },
  {
    "text": "migrate databases to AWS quickly and",
    "start": "224370",
    "end": "226890"
  },
  {
    "text": "securely the source database remains",
    "start": "226890",
    "end": "228959"
  },
  {
    "text": "fully operational during the migration",
    "start": "228959",
    "end": "230600"
  },
  {
    "text": "minimizing your downtime the second tool",
    "start": "230600",
    "end": "234000"
  },
  {
    "text": "is the AWS schema conversion tool this",
    "start": "234000",
    "end": "236340"
  },
  {
    "text": "is a free tool installed on your local",
    "start": "236340",
    "end": "237989"
  },
  {
    "text": "PC that you can convert a source",
    "start": "237989",
    "end": "240150"
  },
  {
    "text": "database schema and a majority of the",
    "start": "240150",
    "end": "242100"
  },
  {
    "text": "database code objects including views",
    "start": "242100",
    "end": "244019"
  },
  {
    "text": "stored procedures and functions to a",
    "start": "244019",
    "end": "246450"
  },
  {
    "text": "format compatible with the target",
    "start": "246450",
    "end": "248130"
  },
  {
    "text": "database for example if you had an",
    "start": "248130",
    "end": "250079"
  },
  {
    "text": "Oracle data warehouse you could use the",
    "start": "250079",
    "end": "251970"
  },
  {
    "text": "schema conversion tool to automatically",
    "start": "251970",
    "end": "253590"
  },
  {
    "text": "convert most of the schemas tables views",
    "start": "253590",
    "end": "256260"
  },
  {
    "text": "etc to redshifts format since the",
    "start": "256260",
    "end": "258840"
  },
  {
    "text": "release of DMS we've migrated over",
    "start": "258840",
    "end": "260760"
  },
  {
    "text": "70,000 unique databases onto a to s and",
    "start": "260760",
    "end": "263430"
  },
  {
    "text": "Counting",
    "start": "263430",
    "end": "265760"
  },
  {
    "text": "the first tool we're going to dive deep",
    "start": "265760",
    "end": "267870"
  },
  {
    "text": "on is the AWS database migration service",
    "start": "267870",
    "end": "270380"
  },
  {
    "text": "the ATIS database migration service or",
    "start": "270380",
    "end": "273180"
  },
  {
    "start": "271000",
    "end": "271000"
  },
  {
    "text": "DMS is simple to use you don't need to",
    "start": "273180",
    "end": "275340"
  },
  {
    "text": "install anything and it doesn't require",
    "start": "275340",
    "end": "277470"
  },
  {
    "text": "any changes to the source database in",
    "start": "277470",
    "end": "279390"
  },
  {
    "text": "most cases you can start a database",
    "start": "279390",
    "end": "281550"
  },
  {
    "text": "migration with just a few clicks in the",
    "start": "281550",
    "end": "283560"
  },
  {
    "text": "AWS management console once the",
    "start": "283560",
    "end": "286830"
  },
  {
    "text": "migration is started DMS manages all the",
    "start": "286830",
    "end": "289170"
  },
  {
    "text": "complexities of the migration process if",
    "start": "289170",
    "end": "291030"
  },
  {
    "text": "your datasource",
    "start": "291030",
    "end": "292230"
  },
  {
    "text": "supports change data capture or CDC DMS",
    "start": "292230",
    "end": "295440"
  },
  {
    "text": "will automatically replicate data",
    "start": "295440",
    "end": "296940"
  },
  {
    "text": "changes that occur in the source",
    "start": "296940",
    "end": "298410"
  },
  {
    "text": "database during the migration process",
    "start": "298410",
    "end": "300240"
  },
  {
    "text": "you can also use this service for",
    "start": "300240",
    "end": "302520"
  },
  {
    "text": "continuous data replication and it's",
    "start": "302520",
    "end": "304470"
  },
  {
    "text": "just as easy DMS helps you migrate",
    "start": "304470",
    "end": "307440"
  },
  {
    "text": "databases to a DBS with virtually no",
    "start": "307440",
    "end": "309390"
  },
  {
    "text": "downtime any data changes to the source",
    "start": "309390",
    "end": "312120"
  },
  {
    "text": "database that occurred during the",
    "start": "312120",
    "end": "313470"
  },
  {
    "text": "migration are continuously replicated to",
    "start": "313470",
    "end": "315570"
  },
  {
    "text": "the target allowing the source database",
    "start": "315570",
    "end": "317610"
  },
  {
    "text": "to be fully operational during the",
    "start": "317610",
    "end": "319290"
  },
  {
    "text": "migration process after the database",
    "start": "319290",
    "end": "321690"
  },
  {
    "text": "migration is complete the target",
    "start": "321690",
    "end": "323520"
  },
  {
    "text": "database will remain synchronized with",
    "start": "323520",
    "end": "325140"
  },
  {
    "text": "the source for as long as you choose",
    "start": "325140",
    "end": "326730"
  },
  {
    "text": "allowing you to switch over the database",
    "start": "326730",
    "end": "328500"
  },
  {
    "text": "at a convenient time on the database",
    "start": "328500",
    "end": "332310"
  },
  {
    "text": "front DMS can migrate your data to and",
    "start": "332310",
    "end": "334470"
  },
  {
    "text": "from most of the widely used commercial",
    "start": "334470",
    "end": "336630"
  },
  {
    "text": "and open-source databases",
    "start": "336630",
    "end": "338060"
  },
  {
    "text": "DMS is also a low cost service you only",
    "start": "338060",
    "end": "341010"
  },
  {
    "text": "pay for the compute resources used",
    "start": "341010",
    "end": "342750"
  },
  {
    "text": "during the migration process and any",
    "start": "342750",
    "end": "344850"
  },
  {
    "text": "additional log storage migrating a",
    "start": "344850",
    "end": "347070"
  },
  {
    "text": "terabyte size database can be done for",
    "start": "347070",
    "end": "349050"
  },
  {
    "text": "as little as $3 this applies to both",
    "start": "349050",
    "end": "351420"
  },
  {
    "text": "homogeneous and heterogeneous migrations",
    "start": "351420",
    "end": "353610"
  },
  {
    "text": "of any supported databases this is in",
    "start": "353610",
    "end": "356310"
  },
  {
    "text": "stark contrast to conventional database",
    "start": "356310",
    "end": "358110"
  },
  {
    "text": "migration methods which can be very",
    "start": "358110",
    "end": "359910"
  },
  {
    "text": "expensive DMS is also fast and easy to",
    "start": "359910",
    "end": "363300"
  },
  {
    "text": "set up you can set up a migration task",
    "start": "363300",
    "end": "365520"
  },
  {
    "text": "within minutes in the AWS management",
    "start": "365520",
    "end": "367410"
  },
  {
    "text": "console a migration task is where you",
    "start": "367410",
    "end": "370140"
  },
  {
    "text": "define the parameters that DMS uses to",
    "start": "370140",
    "end": "372600"
  },
  {
    "text": "execute the migration this includes",
    "start": "372600",
    "end": "375090"
  },
  {
    "text": "setting up connections to the source and",
    "start": "375090",
    "end": "376650"
  },
  {
    "text": "target databases as well as choosing the",
    "start": "376650",
    "end": "378990"
  },
  {
    "text": "replication instance used to run the",
    "start": "378990",
    "end": "381210"
  },
  {
    "text": "migration process once setup the same",
    "start": "381210",
    "end": "384570"
  },
  {
    "text": "tasks can be used for test runs before",
    "start": "384570",
    "end": "386520"
  },
  {
    "text": "performing the actual migration and",
    "start": "386520",
    "end": "388370"
  },
  {
    "text": "finally DMS is also highly resilient and",
    "start": "388370",
    "end": "391410"
  },
  {
    "text": "self-healing it continually monitors",
    "start": "391410",
    "end": "393690"
  },
  {
    "text": "source and target databases network",
    "start": "393690",
    "end": "395760"
  },
  {
    "text": "connectivity and the",
    "start": "395760",
    "end": "397169"
  },
  {
    "text": "application instance in case of",
    "start": "397169",
    "end": "399150"
  },
  {
    "text": "interruption it automatically restarts",
    "start": "399150",
    "end": "400949"
  },
  {
    "text": "the process and continues the migration",
    "start": "400949",
    "end": "403050"
  },
  {
    "text": "from where it was halted a Multi AZ",
    "start": "403050",
    "end": "406319"
  },
  {
    "text": "option also allows you to have high",
    "start": "406319",
    "end": "408120"
  },
  {
    "text": "availability for database migration and",
    "start": "408120",
    "end": "410129"
  },
  {
    "text": "continuous data replication by enabling",
    "start": "410129",
    "end": "412529"
  },
  {
    "text": "redundant replication instances so when",
    "start": "412529",
    "end": "416999"
  },
  {
    "text": "we look at when to use TMS it's a great",
    "start": "416999",
    "end": "419580"
  },
  {
    "text": "tool when you need to migrate databases",
    "start": "419580",
    "end": "421349"
  },
  {
    "text": "and data warehouses to AWS with minimal",
    "start": "421349",
    "end": "423569"
  },
  {
    "text": "downtime it can also be used to",
    "start": "423569",
    "end": "425849"
  },
  {
    "text": "consolidate multiple databases on AWS",
    "start": "425849",
    "end": "428749"
  },
  {
    "text": "DMS can also be used to perform",
    "start": "428749",
    "end": "430710"
  },
  {
    "text": "continuous data replication with high",
    "start": "430710",
    "end": "432659"
  },
  {
    "text": "availability and it's great for our",
    "start": "432659",
    "end": "434610"
  },
  {
    "text": "patterns where we want to offload data",
    "start": "434610",
    "end": "436499"
  },
  {
    "text": "warehouse data to run analytics in the",
    "start": "436499",
    "end": "438749"
  },
  {
    "text": "cloud using Amazon redshift or",
    "start": "438749",
    "end": "440419"
  },
  {
    "text": "ultimately when you need to migrate",
    "start": "440419",
    "end": "442229"
  },
  {
    "text": "entire data warehouses to Amazon",
    "start": "442229",
    "end": "444180"
  },
  {
    "text": "redshift with DMS you need good",
    "start": "444180",
    "end": "446729"
  },
  {
    "text": "networking connectivity between your",
    "start": "446729",
    "end": "448589"
  },
  {
    "text": "data center and AWS and you need to",
    "start": "448589",
    "end": "450990"
  },
  {
    "text": "check that your source database engine",
    "start": "450990",
    "end": "452550"
  },
  {
    "text": "is supported so the source databases",
    "start": "452550",
    "end": "454650"
  },
  {
    "text": "include Oracle sequel server mysql maria",
    "start": "454650",
    "end": "458219"
  },
  {
    "text": "DB Postgres SQL Sybase MongoDB and more",
    "start": "458219",
    "end": "462180"
  },
  {
    "text": "recently db2 so for this presentation",
    "start": "462180",
    "end": "465870"
  },
  {
    "text": "we're gonna look at two different",
    "start": "465870",
    "end": "466830"
  },
  {
    "text": "patterns a partial offload versus a full",
    "start": "466830",
    "end": "469710"
  },
  {
    "text": "migration the first pattern we'll look",
    "start": "469710",
    "end": "471960"
  },
  {
    "start": "470000",
    "end": "470000"
  },
  {
    "text": "at is where you want to offload data",
    "start": "471960",
    "end": "473520"
  },
  {
    "text": "warehousing data to run analytics in the",
    "start": "473520",
    "end": "475409"
  },
  {
    "text": "cloud using Amazon redshift we often see",
    "start": "475409",
    "end": "478080"
  },
  {
    "text": "this pattern where customers have a data",
    "start": "478080",
    "end": "479610"
  },
  {
    "text": "warehouse running on a database server",
    "start": "479610",
    "end": "481319"
  },
  {
    "text": "or using a data warehouse appliance and",
    "start": "481319",
    "end": "483569"
  },
  {
    "text": "they're running out of space or compute",
    "start": "483569",
    "end": "485310"
  },
  {
    "text": "capacity by offloading some of the data",
    "start": "485310",
    "end": "487860"
  },
  {
    "text": "to redshift they're able to extend the",
    "start": "487860",
    "end": "489629"
  },
  {
    "text": "life of their existing data warehouse",
    "start": "489629",
    "end": "491279"
  },
  {
    "text": "while they work out a plan to do a full",
    "start": "491279",
    "end": "493169"
  },
  {
    "text": "migration the second pattern we're gonna",
    "start": "493169",
    "end": "496080"
  },
  {
    "text": "look at is where customers want to",
    "start": "496080",
    "end": "497490"
  },
  {
    "text": "completely migrate their entire data",
    "start": "497490",
    "end": "499379"
  },
  {
    "text": "warehouse to Amazon redshift this is",
    "start": "499379",
    "end": "501689"
  },
  {
    "text": "where they want to move the data",
    "start": "501689",
    "end": "502649"
  },
  {
    "text": "warehouse and all of their data off of",
    "start": "502649",
    "end": "504149"
  },
  {
    "text": "their existing database server or data",
    "start": "504149",
    "end": "506520"
  },
  {
    "text": "warehousing appliance to Amazon redshift",
    "start": "506520",
    "end": "508259"
  },
  {
    "text": "with those two patterns in mind we're",
    "start": "508259",
    "end": "510689"
  },
  {
    "text": "gonna dive deep on some of the tools",
    "start": "510689",
    "end": "512190"
  },
  {
    "text": "that you can help make these patterns",
    "start": "512190",
    "end": "514198"
  },
  {
    "text": "easier to deploy and we're going to",
    "start": "514199",
    "end": "517709"
  },
  {
    "text": "start with the AWS schema conversion",
    "start": "517709",
    "end": "519810"
  },
  {
    "text": "tool or SCT SCT makes moving from one",
    "start": "519810",
    "end": "523349"
  },
  {
    "start": "521000",
    "end": "521000"
  },
  {
    "text": "database format to another much easier",
    "start": "523349",
    "end": "525360"
  },
  {
    "text": "when you use se T it will automatically",
    "start": "525360",
    "end": "528089"
  },
  {
    "text": "convert the database objects from your",
    "start": "528089",
    "end": "530130"
  },
  {
    "text": "source database",
    "start": "530130",
    "end": "530940"
  },
  {
    "text": "schema to a format compatible with the",
    "start": "530940",
    "end": "533190"
  },
  {
    "text": "target database in our example from",
    "start": "533190",
    "end": "535200"
  },
  {
    "text": "before say you have 50 database tables",
    "start": "535200",
    "end": "537570"
  },
  {
    "text": "in your Oracle data warehouse that you",
    "start": "537570",
    "end": "539640"
  },
  {
    "text": "want to convert to redshift the schema",
    "start": "539640",
    "end": "541770"
  },
  {
    "text": "conversion tool will look at those",
    "start": "541770",
    "end": "543210"
  },
  {
    "text": "Oracle tables and recreate them using",
    "start": "543210",
    "end": "545730"
  },
  {
    "text": "redshift DDL now redshift is PostgreSQL",
    "start": "545730",
    "end": "549090"
  },
  {
    "text": "compatible so there aren't many changes",
    "start": "549090",
    "end": "551040"
  },
  {
    "text": "required when moving table definitions",
    "start": "551040",
    "end": "552960"
  },
  {
    "text": "from Oracle to redshift but the schema",
    "start": "552960",
    "end": "555120"
  },
  {
    "text": "conversion tool will do those",
    "start": "555120",
    "end": "556500"
  },
  {
    "text": "conversions automatically for you and",
    "start": "556500",
    "end": "558210"
  },
  {
    "text": "remember it's not just the tables the",
    "start": "558210",
    "end": "561090"
  },
  {
    "text": "schema conversion tool will convert",
    "start": "561090",
    "end": "562590"
  },
  {
    "text": "schemas views stored procedures database",
    "start": "562590",
    "end": "565350"
  },
  {
    "text": "functions etc any objects that are not",
    "start": "565350",
    "end": "569280"
  },
  {
    "text": "automatically converted are clearly",
    "start": "569280",
    "end": "571110"
  },
  {
    "text": "marked so they can be manually converted",
    "start": "571110",
    "end": "573030"
  },
  {
    "text": "to complete the migration once the",
    "start": "573030",
    "end": "575670"
  },
  {
    "text": "schema conversion is complete SCT can",
    "start": "575670",
    "end": "577950"
  },
  {
    "text": "help migrate data from a range of data",
    "start": "577950",
    "end": "580110"
  },
  {
    "text": "warehouses to Amazon redshift using its",
    "start": "580110",
    "end": "582900"
  },
  {
    "text": "built-in data migration agents and it's",
    "start": "582900",
    "end": "585810"
  },
  {
    "text": "those data migration agents that we're",
    "start": "585810",
    "end": "587850"
  },
  {
    "text": "going to focus on for using in these",
    "start": "587850",
    "end": "589740"
  },
  {
    "text": "next two patterns so whether you're",
    "start": "589740",
    "end": "592980"
  },
  {
    "start": "592000",
    "end": "592000"
  },
  {
    "text": "considering offloading data to Amazon",
    "start": "592980",
    "end": "594870"
  },
  {
    "text": "redshift are doing a full data warehouse",
    "start": "594870",
    "end": "596880"
  },
  {
    "text": "migration the process is very similar as",
    "start": "596880",
    "end": "598980"
  },
  {
    "text": "a first step you'll need to convert the",
    "start": "598980",
    "end": "601050"
  },
  {
    "text": "source database schema to the target",
    "start": "601050",
    "end": "602910"
  },
  {
    "text": "which in this case is redshift to do",
    "start": "602910",
    "end": "605640"
  },
  {
    "text": "that you would use the schema conversion",
    "start": "605640",
    "end": "607440"
  },
  {
    "text": "tool when you use the schema conversion",
    "start": "607440",
    "end": "610830"
  },
  {
    "text": "tool you point it to your source in your",
    "start": "610830",
    "end": "612660"
  },
  {
    "text": "target database and the tool can then",
    "start": "612660",
    "end": "614880"
  },
  {
    "text": "generate a database migration assessment",
    "start": "614880",
    "end": "617280"
  },
  {
    "text": "report to help you convert your schema",
    "start": "617280",
    "end": "619290"
  },
  {
    "start": "618000",
    "end": "618000"
  },
  {
    "text": "this report provides important",
    "start": "619290",
    "end": "621120"
  },
  {
    "text": "information about the conversion of the",
    "start": "621120",
    "end": "622740"
  },
  {
    "text": "schema from your source database to your",
    "start": "622740",
    "end": "624750"
  },
  {
    "text": "target database the report summarizes",
    "start": "624750",
    "end": "627270"
  },
  {
    "text": "all of the schema conversion tasks and",
    "start": "627270",
    "end": "629280"
  },
  {
    "text": "details the action items for things that",
    "start": "629280",
    "end": "631740"
  },
  {
    "text": "can't be converted in your target",
    "start": "631740",
    "end": "633360"
  },
  {
    "text": "database the report also includes",
    "start": "633360",
    "end": "635550"
  },
  {
    "text": "estimates of the amount of effort that",
    "start": "635550",
    "end": "637410"
  },
  {
    "text": "will require to write the equivalent",
    "start": "637410",
    "end": "639089"
  },
  {
    "text": "code in your database target that can't",
    "start": "639089",
    "end": "641940"
  },
  {
    "text": "be converted automatically now the",
    "start": "641940",
    "end": "644100"
  },
  {
    "text": "report categorizes the estimated time to",
    "start": "644100",
    "end": "646440"
  },
  {
    "text": "convert these schema items into simple",
    "start": "646440",
    "end": "649140"
  },
  {
    "text": "medium and significant actions so simple",
    "start": "649140",
    "end": "653010"
  },
  {
    "text": "actions are the ones that can be",
    "start": "653010",
    "end": "654089"
  },
  {
    "text": "completed in less than an hour medium",
    "start": "654089",
    "end": "656580"
  },
  {
    "text": "are actions that are more complex and",
    "start": "656580",
    "end": "658500"
  },
  {
    "text": "can being completed in one to four hours",
    "start": "658500",
    "end": "660540"
  },
  {
    "text": "and significant actions are ones that",
    "start": "660540",
    "end": "662700"
  },
  {
    "text": "are very complex and",
    "start": "662700",
    "end": "664290"
  },
  {
    "text": "take more than four hours to complete",
    "start": "664290",
    "end": "665630"
  },
  {
    "text": "you can save this report to a PDF file",
    "start": "665630",
    "end": "668579"
  },
  {
    "text": "or CSV which then you can use to plan",
    "start": "668579",
    "end": "671130"
  },
  {
    "text": "your offload or migration projects and",
    "start": "671130",
    "end": "673290"
  },
  {
    "text": "tasks now in the second step you'll",
    "start": "673290",
    "end": "677550"
  },
  {
    "text": "actually be migrating your data to",
    "start": "677550",
    "end": "679170"
  },
  {
    "text": "Amazon redshift and you have two choices",
    "start": "679170",
    "end": "681209"
  },
  {
    "text": "on how you do that earlier we looked at",
    "start": "681209",
    "end": "683970"
  },
  {
    "text": "the functionality and the AWS database",
    "start": "683970",
    "end": "686130"
  },
  {
    "text": "migration service and when you would use",
    "start": "686130",
    "end": "688050"
  },
  {
    "text": "that service to migrate your data to AWS",
    "start": "688050",
    "end": "690269"
  },
  {
    "text": "for migrating data warehouses you may",
    "start": "690269",
    "end": "693029"
  },
  {
    "text": "have a large volume of data either in a",
    "start": "693029",
    "end": "695279"
  },
  {
    "text": "database or a data warehouse appliance",
    "start": "695279",
    "end": "697079"
  },
  {
    "text": "that you need to migrate to AWS to help",
    "start": "697079",
    "end": "700980"
  },
  {
    "text": "make that process easier the schema",
    "start": "700980",
    "end": "702990"
  },
  {
    "text": "conversion tool includes its own data",
    "start": "702990",
    "end": "705509"
  },
  {
    "text": "extraction agents you can use the ADEs",
    "start": "705509",
    "end": "708839"
  },
  {
    "start": "708000",
    "end": "708000"
  },
  {
    "text": "SCT data extraction agents to extract",
    "start": "708839",
    "end": "711690"
  },
  {
    "text": "data from your on-premises data",
    "start": "711690",
    "end": "713130"
  },
  {
    "text": "warehouse and migrate it very easily to",
    "start": "713130",
    "end": "715380"
  },
  {
    "text": "Amazon redshift the extraction agent",
    "start": "715380",
    "end": "718860"
  },
  {
    "text": "extracts your data and uploads it to",
    "start": "718860",
    "end": "721139"
  },
  {
    "text": "either s3 or an AWS Snowbowl device you",
    "start": "721139",
    "end": "724589"
  },
  {
    "text": "can then use SCT to copy the data into",
    "start": "724589",
    "end": "727139"
  },
  {
    "text": "redshift these data extraction agents",
    "start": "727139",
    "end": "729959"
  },
  {
    "text": "are locally installed software agents",
    "start": "729959",
    "end": "731970"
  },
  {
    "text": "that are designed to extract data from",
    "start": "731970",
    "end": "733829"
  },
  {
    "text": "data warehouses hosted on greenplum",
    "start": "733829",
    "end": "735959"
  },
  {
    "text": "Netezza teradata Vertica oracle and",
    "start": "735959",
    "end": "739319"
  },
  {
    "text": "sequel server when the data is extracted",
    "start": "739319",
    "end": "742139"
  },
  {
    "text": "the adb a schema conversion tool",
    "start": "742139",
    "end": "744019"
  },
  {
    "text": "optimizes it for Amazon redshift and",
    "start": "744019",
    "end": "746279"
  },
  {
    "text": "saves it in local files now ATS can",
    "start": "746279",
    "end": "748680"
  },
  {
    "text": "automatically upload those files to",
    "start": "748680",
    "end": "750360"
  },
  {
    "text": "redshift for you or you can transfer",
    "start": "750360",
    "end": "752100"
  },
  {
    "text": "these files into an s3 bucket where they",
    "start": "752100",
    "end": "754290"
  },
  {
    "text": "can be uploaded to redshift manually for",
    "start": "754290",
    "end": "757440"
  },
  {
    "text": "large data sets you can use AWS snowball",
    "start": "757440",
    "end": "759690"
  },
  {
    "text": "to actually ship the data to AWS the",
    "start": "759690",
    "end": "762480"
  },
  {
    "text": "migration agents themselves are designed",
    "start": "762480",
    "end": "764160"
  },
  {
    "text": "to extract data in parallel and",
    "start": "764160",
    "end": "765779"
  },
  {
    "text": "independently for example with a large",
    "start": "765779",
    "end": "769589"
  },
  {
    "text": "Oracle data warehouse SCT will",
    "start": "769589",
    "end": "771720"
  },
  {
    "text": "automatically distribute work between",
    "start": "771720",
    "end": "773339"
  },
  {
    "text": "all available migration agents SCT will",
    "start": "773339",
    "end": "776459"
  },
  {
    "text": "automatically manage all of the",
    "start": "776459",
    "end": "778050"
  },
  {
    "text": "available agents to extract data from",
    "start": "778050",
    "end": "780149"
  },
  {
    "text": "the different partitions and tables in",
    "start": "780149",
    "end": "782069"
  },
  {
    "text": "the schema in the most optimized way for",
    "start": "782069",
    "end": "784500"
  },
  {
    "text": "Amazon redshift then consolidate the",
    "start": "784500",
    "end": "786959"
  },
  {
    "text": "data and save it to those local files",
    "start": "786959",
    "end": "789319"
  },
  {
    "text": "the migration agents work completely",
    "start": "789319",
    "end": "791790"
  },
  {
    "text": "independent from SCT and you can replace",
    "start": "791790",
    "end": "794220"
  },
  {
    "text": "them if needed without any work lost",
    "start": "794220",
    "end": "796010"
  },
  {
    "text": "this",
    "start": "796010",
    "end": "797230"
  },
  {
    "text": "Niq independent parallel execution",
    "start": "797230",
    "end": "799050"
  },
  {
    "text": "capability not only accelerates the",
    "start": "799050",
    "end": "801670"
  },
  {
    "text": "extraction of data but can also",
    "start": "801670",
    "end": "803560"
  },
  {
    "text": "withstand failure of one of the agents",
    "start": "803560",
    "end": "807000"
  },
  {
    "text": "the agent software is available on a",
    "start": "807000",
    "end": "809530"
  },
  {
    "text": "variety of operating systems and",
    "start": "809530",
    "end": "810940"
  },
  {
    "text": "supports a number of database and data",
    "start": "810940",
    "end": "812980"
  },
  {
    "text": "warehousing platforms including",
    "start": "812980",
    "end": "814870"
  },
  {
    "text": "greenplum the tizi terror data Vertica",
    "start": "814870",
    "end": "817360"
  },
  {
    "text": "etc so when we look at when to use the",
    "start": "817360",
    "end": "821830"
  },
  {
    "start": "821000",
    "end": "821000"
  },
  {
    "text": "SCT data extractors it's when we want to",
    "start": "821830",
    "end": "824470"
  },
  {
    "text": "migrate databases to AWS it's where we",
    "start": "824470",
    "end": "827530"
  },
  {
    "text": "might have large-scale database",
    "start": "827530",
    "end": "828940"
  },
  {
    "text": "migrations and the terabyte to petabyte",
    "start": "828940",
    "end": "830740"
  },
  {
    "text": "range and it's where we might want to",
    "start": "830740",
    "end": "832780"
  },
  {
    "text": "offload data warehouse data to run",
    "start": "832780",
    "end": "834520"
  },
  {
    "text": "analytics in the cloud using Amazon",
    "start": "834520",
    "end": "836320"
  },
  {
    "text": "redshift or migrate entire data",
    "start": "836320",
    "end": "838720"
  },
  {
    "text": "warehouses to Amazon redshift so you",
    "start": "838720",
    "end": "841270"
  },
  {
    "text": "need to check that your source database",
    "start": "841270",
    "end": "842830"
  },
  {
    "text": "engine or data warehouse appliance is",
    "start": "842830",
    "end": "844960"
  },
  {
    "text": "supported it's also great when you need",
    "start": "844960",
    "end": "847210"
  },
  {
    "text": "the option of using your network to",
    "start": "847210",
    "end": "849070"
  },
  {
    "text": "transfer the data or because of network",
    "start": "849070",
    "end": "851230"
  },
  {
    "text": "speed or size you want to use the AWS",
    "start": "851230",
    "end": "853780"
  },
  {
    "text": "snowball service so if we look at the",
    "start": "853780",
    "end": "858430"
  },
  {
    "start": "856000",
    "end": "856000"
  },
  {
    "text": "architecture of how this works you would",
    "start": "858430",
    "end": "860860"
  },
  {
    "text": "install the data extract your agents on",
    "start": "860860",
    "end": "862600"
  },
  {
    "text": "dedicated servers in your data center if",
    "start": "862600",
    "end": "864580"
  },
  {
    "text": "you've downloaded the schema conversion",
    "start": "864580",
    "end": "866710"
  },
  {
    "text": "tool the installer for the agents is",
    "start": "866710",
    "end": "868510"
  },
  {
    "text": "available in the folder in the zip file",
    "start": "868510",
    "end": "870700"
  },
  {
    "text": "you downloaded once you've installed the",
    "start": "870700",
    "end": "873160"
  },
  {
    "text": "agent you'll need to install the JDBC",
    "start": "873160",
    "end": "875230"
  },
  {
    "text": "drivers for your particular data source",
    "start": "875230",
    "end": "876910"
  },
  {
    "text": "as well as setup the SSL trust and key",
    "start": "876910",
    "end": "879520"
  },
  {
    "text": "stores required by the tool extraction",
    "start": "879520",
    "end": "882520"
  },
  {
    "text": "agents acts as listeners when you start",
    "start": "882520",
    "end": "884620"
  },
  {
    "text": "an agent from the command line the agent",
    "start": "884620",
    "end": "886570"
  },
  {
    "text": "starts listening for instructions in the",
    "start": "886570",
    "end": "888880"
  },
  {
    "text": "schema conversion tool you register",
    "start": "888880",
    "end": "890620"
  },
  {
    "text": "these agents and then you can create and",
    "start": "890620",
    "end": "892450"
  },
  {
    "text": "run data extraction tasks when you set",
    "start": "892450",
    "end": "895330"
  },
  {
    "text": "up a task you can choose the mode and",
    "start": "895330",
    "end": "897430"
  },
  {
    "text": "there's three extract only where you",
    "start": "897430",
    "end": "900700"
  },
  {
    "text": "extract your data and save the data to",
    "start": "900700",
    "end": "902440"
  },
  {
    "text": "your local working folders",
    "start": "902440",
    "end": "903910"
  },
  {
    "text": "there's also extract and upload where",
    "start": "903910",
    "end": "906040"
  },
  {
    "text": "you extract your data and upload that to",
    "start": "906040",
    "end": "908170"
  },
  {
    "text": "Amazon s3 and then finally extract",
    "start": "908170",
    "end": "910480"
  },
  {
    "text": "upload and copy where you extract the",
    "start": "910480",
    "end": "913120"
  },
  {
    "text": "data upload it to s3 and then copy it",
    "start": "913120",
    "end": "915790"
  },
  {
    "text": "into your Amazon redshift data warehouse",
    "start": "915790",
    "end": "917590"
  },
  {
    "text": "so now that we know a little bit about",
    "start": "917590",
    "end": "920950"
  },
  {
    "text": "how the SCT data extractors work we're",
    "start": "920950",
    "end": "923410"
  },
  {
    "text": "going to go back and look at that first",
    "start": "923410",
    "end": "924730"
  },
  {
    "text": "pattern we talked about in this pattern",
    "start": "924730",
    "end": "927130"
  },
  {
    "start": "925000",
    "end": "925000"
  },
  {
    "text": "we're going to use the data extraction",
    "start": "927130",
    "end": "928720"
  },
  {
    "text": "agents to extract only a subset",
    "start": "928720",
    "end": "931040"
  },
  {
    "text": "the data in your data warehouse this",
    "start": "931040",
    "end": "933320"
  },
  {
    "text": "could help free up some storage space",
    "start": "933320",
    "end": "934520"
  },
  {
    "text": "and allow you to take your data set and",
    "start": "934520",
    "end": "936890"
  },
  {
    "text": "use it in Amazon redshift as well as",
    "start": "936890",
    "end": "939020"
  },
  {
    "text": "freeing up some compute in this pattern",
    "start": "939020",
    "end": "941780"
  },
  {
    "text": "we're going to use the data extractors",
    "start": "941780",
    "end": "943520"
  },
  {
    "text": "with s3 to extract the data upload it to",
    "start": "943520",
    "end": "946730"
  },
  {
    "text": "s3 and copy it directly into Amazon",
    "start": "946730",
    "end": "949100"
  },
  {
    "text": "redshift so if we look at the tasks",
    "start": "949100",
    "end": "952280"
  },
  {
    "text": "involved in implementing this pattern",
    "start": "952280",
    "end": "953990"
  },
  {
    "text": "they are first we need to convert the",
    "start": "953990",
    "end": "956420"
  },
  {
    "start": "955000",
    "end": "955000"
  },
  {
    "text": "data warehouse schema using the SCT tool",
    "start": "956420",
    "end": "958730"
  },
  {
    "text": "then we need to install and register the",
    "start": "958730",
    "end": "961490"
  },
  {
    "text": "data extraction agents third we need to",
    "start": "961490",
    "end": "964550"
  },
  {
    "text": "create data extraction filters because",
    "start": "964550",
    "end": "967250"
  },
  {
    "text": "remember in the offload pattern we only",
    "start": "967250",
    "end": "969080"
  },
  {
    "text": "want a subset of that data then we need",
    "start": "969080",
    "end": "971930"
  },
  {
    "text": "to create and run our data extraction",
    "start": "971930",
    "end": "973640"
  },
  {
    "text": "tasks and there you have it you've",
    "start": "973640",
    "end": "976040"
  },
  {
    "text": "offloaded some of your data from your",
    "start": "976040",
    "end": "977690"
  },
  {
    "text": "existing data warehouse to Amazon",
    "start": "977690",
    "end": "979490"
  },
  {
    "text": "redshift now if this data is updated",
    "start": "979490",
    "end": "981500"
  },
  {
    "text": "frequently you might need to update your",
    "start": "981500",
    "end": "983510"
  },
  {
    "text": "ETL or data pipelines to point to that",
    "start": "983510",
    "end": "985730"
  },
  {
    "text": "new data warehouse in redshift to update",
    "start": "985730",
    "end": "988490"
  },
  {
    "text": "that subset of data you transfer it",
    "start": "988490",
    "end": "990050"
  },
  {
    "text": "across the second pattern we're going to",
    "start": "990050",
    "end": "993800"
  },
  {
    "text": "look at is a full data warehouse",
    "start": "993800",
    "end": "995420"
  },
  {
    "text": "migration this is where you want to move",
    "start": "995420",
    "end": "997520"
  },
  {
    "text": "completely off of your existing data",
    "start": "997520",
    "end": "999380"
  },
  {
    "text": "warehouse and migrate the entire thing",
    "start": "999380",
    "end": "1001450"
  },
  {
    "text": "to Amazon redshift in this example we're",
    "start": "1001450",
    "end": "1005200"
  },
  {
    "text": "using the same basic architecture and",
    "start": "1005200",
    "end": "1006940"
  },
  {
    "text": "the SCT data extraction agents but the",
    "start": "1006940",
    "end": "1009970"
  },
  {
    "text": "difference is that with a migration you",
    "start": "1009970",
    "end": "1011890"
  },
  {
    "text": "might have a large volume of data",
    "start": "1011890",
    "end": "1013800"
  },
  {
    "text": "large-scale data migrations can include",
    "start": "1013800",
    "end": "1016270"
  },
  {
    "text": "many terabytes of information and can be",
    "start": "1016270",
    "end": "1018190"
  },
  {
    "text": "slowed by network performance and by the",
    "start": "1018190",
    "end": "1020140"
  },
  {
    "text": "sheer amount of data that has to be",
    "start": "1020140",
    "end": "1021730"
  },
  {
    "text": "moved a TBS snowball is an ad based",
    "start": "1021730",
    "end": "1025660"
  },
  {
    "start": "1023000",
    "end": "1023000"
  },
  {
    "text": "service you can use to transfer data to",
    "start": "1025660",
    "end": "1027579"
  },
  {
    "text": "the cloud at faster than network speeds",
    "start": "1027579",
    "end": "1029860"
  },
  {
    "text": "using an AWS owned appliance an AWS",
    "start": "1029860",
    "end": "1033430"
  },
  {
    "text": "snowball device can hold up to 80",
    "start": "1033430",
    "end": "1035079"
  },
  {
    "text": "terabytes of data and at AWS snowball",
    "start": "1035079",
    "end": "1037839"
  },
  {
    "text": "edge device can hold up to a hundred",
    "start": "1037839",
    "end": "1039670"
  },
  {
    "text": "terabytes of data your data on the",
    "start": "1039670",
    "end": "1042850"
  },
  {
    "text": "snowball device is encrypted and the",
    "start": "1042850",
    "end": "1044770"
  },
  {
    "text": "schema conversion tool works both with",
    "start": "1044770",
    "end": "1046630"
  },
  {
    "text": "snowball and snowball edge devices when",
    "start": "1046630",
    "end": "1049990"
  },
  {
    "text": "you use AWS SCT and a snowball device",
    "start": "1049990",
    "end": "1052690"
  },
  {
    "text": "you migrate your data in two stages in",
    "start": "1052690",
    "end": "1055830"
  },
  {
    "text": "the first stage you'll use the AWS SCT",
    "start": "1055830",
    "end": "1058960"
  },
  {
    "text": "tool to process the data locally and",
    "start": "1058960",
    "end": "1060910"
  },
  {
    "text": "then move that data to the snowball",
    "start": "1060910",
    "end": "1062770"
  },
  {
    "text": "device you then",
    "start": "1062770",
    "end": "1064280"
  },
  {
    "text": "send that device using the AWS snowball",
    "start": "1064280",
    "end": "1067580"
  },
  {
    "text": "process and then a DMS automatically",
    "start": "1067580",
    "end": "1070010"
  },
  {
    "text": "loads the data into an Amazon s3 bucket",
    "start": "1070010",
    "end": "1073990"
  },
  {
    "text": "next when the data is available on s3",
    "start": "1073990",
    "end": "1076640"
  },
  {
    "text": "you use the schema conversion tool to",
    "start": "1076640",
    "end": "1079280"
  },
  {
    "text": "migrate that data to redshift when we",
    "start": "1079280",
    "end": "1083570"
  },
  {
    "text": "look at using AWS DMS SCT and snowball",
    "start": "1083570",
    "end": "1086750"
  },
  {
    "start": "1084000",
    "end": "1084000"
  },
  {
    "text": "together some of the common use cases",
    "start": "1086750",
    "end": "1088760"
  },
  {
    "text": "include where you need to migrate large",
    "start": "1088760",
    "end": "1090770"
  },
  {
    "text": "databases like over 5 terabytes or more",
    "start": "1090770",
    "end": "1093290"
  },
  {
    "text": "well you need to migrate many databases",
    "start": "1093290",
    "end": "1095420"
  },
  {
    "text": "at once or you're migrating over a slow",
    "start": "1095420",
    "end": "1098150"
  },
  {
    "text": "network or where you have a push versus",
    "start": "1098150",
    "end": "1100700"
  },
  {
    "text": "pull scenario where you want to actually",
    "start": "1100700",
    "end": "1102920"
  },
  {
    "text": "push that data into the cloud as opposed",
    "start": "1102920",
    "end": "1104660"
  },
  {
    "text": "to pulling it so if we look at the tests",
    "start": "1104660",
    "end": "1108380"
  },
  {
    "start": "1108000",
    "end": "1108000"
  },
  {
    "text": "required for a data warehouse migration",
    "start": "1108380",
    "end": "1110150"
  },
  {
    "text": "it's very similar to what we saw before",
    "start": "1110150",
    "end": "1111950"
  },
  {
    "text": "with the offload pattern but with a few",
    "start": "1111950",
    "end": "1114080"
  },
  {
    "text": "differences first we'll convert the data",
    "start": "1114080",
    "end": "1116450"
  },
  {
    "text": "warehouse schema like we did before with",
    "start": "1116450",
    "end": "1118070"
  },
  {
    "text": "the SCT but then if you're gonna use in",
    "start": "1118070",
    "end": "1120710"
  },
  {
    "text": "snowball device we'll need to acquire",
    "start": "1120710",
    "end": "1122240"
  },
  {
    "text": "and configure that snowball device and",
    "start": "1122240",
    "end": "1124100"
  },
  {
    "text": "plug that into your network we still",
    "start": "1124100",
    "end": "1126260"
  },
  {
    "text": "need to install and register those data",
    "start": "1126260",
    "end": "1128000"
  },
  {
    "text": "extraction agents and we may still use",
    "start": "1128000",
    "end": "1130280"
  },
  {
    "text": "some filters on that and then finally",
    "start": "1130280",
    "end": "1132410"
  },
  {
    "text": "you want to create and run your data",
    "start": "1132410",
    "end": "1134240"
  },
  {
    "text": "extraction tasks so with those five",
    "start": "1134240",
    "end": "1136460"
  },
  {
    "text": "steps we've been able to deploy a",
    "start": "1136460",
    "end": "1137780"
  },
  {
    "text": "pattern for a full data warehouse",
    "start": "1137780",
    "end": "1139610"
  },
  {
    "text": "migration migrating your data warehouse",
    "start": "1139610",
    "end": "1142760"
  },
  {
    "text": "to Amazon redshift will help you",
    "start": "1142760",
    "end": "1144260"
  },
  {
    "text": "leverage more modern data architectures",
    "start": "1144260",
    "end": "1146210"
  },
  {
    "text": "to be able to deliver analytics on a",
    "start": "1146210",
    "end": "1148070"
  },
  {
    "text": "wider range of data and tool sets as",
    "start": "1148070",
    "end": "1150620"
  },
  {
    "text": "well as reducing the cost and complexity",
    "start": "1150620",
    "end": "1152600"
  },
  {
    "text": "associated with operating a traditional",
    "start": "1152600",
    "end": "1154700"
  },
  {
    "text": "warehouse now we've covered a lot in",
    "start": "1154700",
    "end": "1157010"
  },
  {
    "text": "this thirty minutes so I want to leave",
    "start": "1157010",
    "end": "1158630"
  },
  {
    "text": "you with some additional resources in",
    "start": "1158630",
    "end": "1161200"
  },
  {
    "text": "the ATS console if you visit the DMS",
    "start": "1161200",
    "end": "1164180"
  },
  {
    "text": "service page you'll find a getting",
    "start": "1164180",
    "end": "1165800"
  },
  {
    "text": "started guide our technical",
    "start": "1165800",
    "end": "1167690"
  },
  {
    "text": "documentation as well as features and",
    "start": "1167690",
    "end": "1169550"
  },
  {
    "text": "benefits of DMS you'll also find our",
    "start": "1169550",
    "end": "1171560"
  },
  {
    "text": "pricing there for replication instances",
    "start": "1171560",
    "end": "1173420"
  },
  {
    "text": "storage and data transfer and links to",
    "start": "1173420",
    "end": "1175670"
  },
  {
    "text": "support where you can post your",
    "start": "1175670",
    "end": "1176840"
  },
  {
    "text": "questions to our support forum we've",
    "start": "1176840",
    "end": "1179000"
  },
  {
    "text": "also got details of our Java based API",
    "start": "1179000",
    "end": "1181040"
  },
  {
    "text": "for creating data migration tasks and",
    "start": "1181040",
    "end": "1183890"
  },
  {
    "text": "more information about working with DMS",
    "start": "1183890",
    "end": "1185960"
  },
  {
    "text": "with the ATS Commandment AWS allows you",
    "start": "1185960",
    "end": "1189800"
  },
  {
    "text": "musi to be successful because it powers",
    "start": "1189800",
    "end": "1192080"
  },
  {
    "text": "both our IT infrastructure and our",
    "start": "1192080",
    "end": "1193910"
  },
  {
    "text": "analytical platforms we use it to both",
    "start": "1193910",
    "end": "1196940"
  },
  {
    "text": "run the University",
    "start": "1196940",
    "end": "1198260"
  },
  {
    "text": "as well as to improve student outcomes",
    "start": "1198260",
    "end": "1200740"
  },
  {
    "text": "[Music]",
    "start": "1200740",
    "end": "1207660"
  },
  {
    "text": "my name is Darren Catalano I'm the vice",
    "start": "1207660",
    "end": "1210070"
  },
  {
    "text": "president of analytics for University of",
    "start": "1210070",
    "end": "1211900"
  },
  {
    "text": "Maryland University College we're an",
    "start": "1211900",
    "end": "1213880"
  },
  {
    "text": "open access University focused on the",
    "start": "1213880",
    "end": "1215920"
  },
  {
    "text": "unique educational needs of adult",
    "start": "1215920",
    "end": "1217660"
  },
  {
    "text": "students like many companies and",
    "start": "1217660",
    "end": "1220510"
  },
  {
    "text": "universities UMUC had a lot of legacy",
    "start": "1220510",
    "end": "1223300"
  },
  {
    "text": "applications and when it came time to",
    "start": "1223300",
    "end": "1225310"
  },
  {
    "text": "refresh and upgrade those applications",
    "start": "1225310",
    "end": "1227470"
  },
  {
    "text": "we to take a real close look at the",
    "start": "1227470",
    "end": "1229360"
  },
  {
    "text": "market and we saw the market was moving",
    "start": "1229360",
    "end": "1232000"
  },
  {
    "text": "towards the cloud and the cloud offered",
    "start": "1232000",
    "end": "1233890"
  },
  {
    "text": "a lot of benefits",
    "start": "1233890",
    "end": "1235240"
  },
  {
    "text": "AWS had a lot of advantages when we",
    "start": "1235240",
    "end": "1237760"
  },
  {
    "text": "looked into cloud providers nobody can",
    "start": "1237760",
    "end": "1242140"
  },
  {
    "text": "match AWS is product set scale and",
    "start": "1242140",
    "end": "1246750"
  },
  {
    "text": "innovation UMUC is leveraging a broad",
    "start": "1246750",
    "end": "1249730"
  },
  {
    "text": "array of products from AWS namely we",
    "start": "1249730",
    "end": "1253450"
  },
  {
    "text": "have a lot of instances in ec2 RDS",
    "start": "1253450",
    "end": "1257590"
  },
  {
    "text": "Oracle and my personal favorite Amazon",
    "start": "1257590",
    "end": "1261550"
  },
  {
    "text": "redshift from an analytics perspective",
    "start": "1261550",
    "end": "1263380"
  },
  {
    "text": "Amazon redshift is very disruptive in",
    "start": "1263380",
    "end": "1266380"
  },
  {
    "text": "the market analytics is very strategic",
    "start": "1266380",
    "end": "1267850"
  },
  {
    "text": "to the university 85% of our students",
    "start": "1267850",
    "end": "1270880"
  },
  {
    "text": "take courses online they're working",
    "start": "1270880",
    "end": "1273190"
  },
  {
    "text": "adults and we use analytics to improve",
    "start": "1273190",
    "end": "1275500"
  },
  {
    "text": "student outcomes we build predictive",
    "start": "1275500",
    "end": "1277570"
  },
  {
    "text": "models to identify students who are at",
    "start": "1277570",
    "end": "1279790"
  },
  {
    "text": "risk so that we can get these adult",
    "start": "1279790",
    "end": "1282250"
  },
  {
    "text": "students in the right pathway so that",
    "start": "1282250",
    "end": "1283720"
  },
  {
    "text": "they could be successful at the",
    "start": "1283720",
    "end": "1284950"
  },
  {
    "text": "university and we also use it to build",
    "start": "1284950",
    "end": "1286960"
  },
  {
    "text": "dashboards to give data to our academic",
    "start": "1286960",
    "end": "1290320"
  },
  {
    "text": "program director so that they have all",
    "start": "1290320",
    "end": "1292330"
  },
  {
    "text": "the data at their fingertips to manage",
    "start": "1292330",
    "end": "1294160"
  },
  {
    "text": "the program to understand how well the",
    "start": "1294160",
    "end": "1296980"
  },
  {
    "text": "program is doing who's graduating who's",
    "start": "1296980",
    "end": "1299860"
  },
  {
    "text": "not which courses need to be redesigned",
    "start": "1299860",
    "end": "1302350"
  },
  {
    "text": "so we use data really to run both our",
    "start": "1302350",
    "end": "1306540"
  },
  {
    "text": "the academic side of the house as well",
    "start": "1306540",
    "end": "1308650"
  },
  {
    "text": "as the administrative side of the house",
    "start": "1308650",
    "end": "1310270"
  },
  {
    "text": "the place value proposition that we get",
    "start": "1310270",
    "end": "1313180"
  },
  {
    "text": "from Amazon redshift is incredible and",
    "start": "1313180",
    "end": "1316620"
  },
  {
    "text": "we're leveraging not only cost savings",
    "start": "1316620",
    "end": "1319630"
  },
  {
    "text": "from Amazon redshift but also a lot of",
    "start": "1319630",
    "end": "1322150"
  },
  {
    "text": "performance gains we're seeing our",
    "start": "1322150",
    "end": "1324520"
  },
  {
    "text": "nightly ETL has a 2x gain and many of",
    "start": "1324520",
    "end": "1327190"
  },
  {
    "text": "our queries get from a 5x to 20x gain",
    "start": "1327190",
    "end": "1330160"
  },
  {
    "text": "using Amazon redshift from our much more",
    "start": "1330160",
    "end": "1332590"
  },
  {
    "text": "expensive legacy application",
    "start": "1332590",
    "end": "1334850"
  },
  {
    "text": "so as a university we have a lot of",
    "start": "1334850",
    "end": "1336590"
  },
  {
    "text": "security concerns so we we have to",
    "start": "1336590",
    "end": "1339050"
  },
  {
    "text": "really manage our student data and who",
    "start": "1339050",
    "end": "1342440"
  },
  {
    "text": "has access to it how they get access to",
    "start": "1342440",
    "end": "1344390"
  },
  {
    "text": "it etc security and compliance are you",
    "start": "1344390",
    "end": "1347870"
  },
  {
    "text": "know typically barriers to moving to the",
    "start": "1347870",
    "end": "1349700"
  },
  {
    "text": "cloud but in fact it should be the",
    "start": "1349700",
    "end": "1351290"
  },
  {
    "text": "complete opposite in that it should be",
    "start": "1351290",
    "end": "1353450"
  },
  {
    "text": "reasons for moving to the cloud the",
    "start": "1353450",
    "end": "1355010"
  },
  {
    "text": "security that AWS has in place is far",
    "start": "1355010",
    "end": "1358940"
  },
  {
    "text": "more reaching and rigorous and",
    "start": "1358940",
    "end": "1361400"
  },
  {
    "text": "thought-out than anything any individual",
    "start": "1361400",
    "end": "1363590"
  },
  {
    "text": "company can or university can do",
    "start": "1363590",
    "end": "1365660"
  },
  {
    "text": "themselves from an IT perspective it's",
    "start": "1365660",
    "end": "1368510"
  },
  {
    "text": "less about the cost savings and more",
    "start": "1368510",
    "end": "1370220"
  },
  {
    "text": "about not having the headache of",
    "start": "1370220",
    "end": "1372010"
  },
  {
    "text": "disaster recovery backup and",
    "start": "1372010",
    "end": "1375340"
  },
  {
    "text": "administration we talk to our IT",
    "start": "1375340",
    "end": "1377300"
  },
  {
    "text": "department you know they'll talk about",
    "start": "1377300",
    "end": "1379280"
  },
  {
    "text": "the transition of our employees from",
    "start": "1379280",
    "end": "1381880"
  },
  {
    "text": "administrators to engineers so they move",
    "start": "1381880",
    "end": "1385760"
  },
  {
    "text": "from stack and rack to monitoring and",
    "start": "1385760",
    "end": "1388610"
  },
  {
    "text": "building applications and that's a real",
    "start": "1388610",
    "end": "1390290"
  },
  {
    "text": "shift in our organization we're able to",
    "start": "1390290",
    "end": "1392570"
  },
  {
    "text": "move our employees up the value chain to",
    "start": "1392570",
    "end": "1394880"
  },
  {
    "text": "really working on those value-added",
    "start": "1394880",
    "end": "1396680"
  },
  {
    "text": "tasks we love AWS because it's so",
    "start": "1396680",
    "end": "1399440"
  },
  {
    "text": "innovative its scalable it is",
    "start": "1399440",
    "end": "1402100"
  },
  {
    "text": "cost-effective I mean it really is",
    "start": "1402100",
    "end": "1404420"
  },
  {
    "text": "game-changing you know that UMUC we are",
    "start": "1404420",
    "end": "1406990"
  },
  {
    "text": "looking forward and you know we want to",
    "start": "1406990",
    "end": "1409850"
  },
  {
    "text": "be on the forefront of where technology",
    "start": "1409850",
    "end": "1411170"
  },
  {
    "text": "is going to take us",
    "start": "1411170",
    "end": "1414130"
  },
  {
    "text": "you",
    "start": "1414300",
    "end": "1416360"
  },
  {
    "text": "for the schema conversion tool if you",
    "start": "1418629",
    "end": "1421129"
  },
  {
    "text": "visit our website you'll find the user",
    "start": "1421129",
    "end": "1422720"
  },
  {
    "text": "guide technical documents and in the",
    "start": "1422720",
    "end": "1425240"
  },
  {
    "text": "download area you can get the",
    "start": "1425240",
    "end": "1426440"
  },
  {
    "text": "installation files for the schema",
    "start": "1426440",
    "end": "1428059"
  },
  {
    "text": "conversion tool and the migration agents",
    "start": "1428059",
    "end": "1429919"
  },
  {
    "text": "we also have support forums that you can",
    "start": "1429919",
    "end": "1432139"
  },
  {
    "text": "post questions in and review how-to",
    "start": "1432139",
    "end": "1434029"
  },
  {
    "text": "guides if you want to gain more",
    "start": "1434029",
    "end": "1437149"
  },
  {
    "text": "confidence in hands-on experience with",
    "start": "1437149",
    "end": "1438860"
  },
  {
    "text": "AWS check out a TBS training to access",
    "start": "1438860",
    "end": "1441649"
  },
  {
    "text": "the digital training built by a Tobias",
    "start": "1441649",
    "end": "1443389"
  },
  {
    "text": "experts you can also attend our",
    "start": "1443389",
    "end": "1446509"
  },
  {
    "text": "instructor-led classes taught by",
    "start": "1446509",
    "end": "1448249"
  },
  {
    "text": "qualified ad bus instructors and learn",
    "start": "1448249",
    "end": "1450559"
  },
  {
    "text": "how to design deploy and operate highly",
    "start": "1450559",
    "end": "1453259"
  },
  {
    "text": "available cost-effective and secure",
    "start": "1453259",
    "end": "1455029"
  },
  {
    "text": "applications on AWS ABS also has a wide",
    "start": "1455029",
    "end": "1459259"
  },
  {
    "text": "partner ecosystem to help you focus on",
    "start": "1459259",
    "end": "1461600"
  },
  {
    "text": "your success and take full advantage of",
    "start": "1461600",
    "end": "1463850"
  },
  {
    "text": "all the business benefits that ad bus",
    "start": "1463850",
    "end": "1465379"
  },
  {
    "text": "has to offer you can learn more about",
    "start": "1465379",
    "end": "1467389"
  },
  {
    "text": "how our APN partners can help you and",
    "start": "1467389",
    "end": "1469399"
  },
  {
    "text": "find the right APM partner for your",
    "start": "1469399",
    "end": "1471470"
  },
  {
    "text": "needs",
    "start": "1471470",
    "end": "1471889"
  },
  {
    "text": "by visiting the APN booth in our",
    "start": "1471889",
    "end": "1474379"
  },
  {
    "text": "showcase finally I would like to thank",
    "start": "1474379",
    "end": "1476600"
  },
  {
    "text": "you for attending today and sticking it",
    "start": "1476600",
    "end": "1478369"
  },
  {
    "text": "out until the very end of the",
    "start": "1478369",
    "end": "1479269"
  },
  {
    "text": "presentation my name's David McKay miss",
    "start": "1479269",
    "end": "1481129"
  },
  {
    "text": "and we'll see you next time",
    "start": "1481129",
    "end": "1483759"
  }
]
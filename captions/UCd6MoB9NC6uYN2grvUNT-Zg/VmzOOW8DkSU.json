[
  {
    "start": "0",
    "end": "50000"
  },
  {
    "text": "good afternoon thank you for joining us for real-time personal is it personalized customer experiences at",
    "start": "2870",
    "end": "9090"
  },
  {
    "text": "bonobos my name is James Jory I'm a partner Solutions Architect with AWS and",
    "start": "9090",
    "end": "14429"
  },
  {
    "text": "I'm pleased to be joined today but by aniket the estava from bonobos who's the",
    "start": "14429",
    "end": "20730"
  },
  {
    "text": "head of analytics in data science and Calvin French Owen who's the CTO of",
    "start": "20730",
    "end": "26490"
  },
  {
    "text": "segment so this is a introductory level session so we're not going to be getting",
    "start": "26490",
    "end": "32058"
  },
  {
    "text": "too in-depth in the technology or looking at source code or anything like that but we will be looking at some",
    "start": "32059",
    "end": "38430"
  },
  {
    "text": "architectures and most importantly learning about some of the real world real world learnings of bonobos so a",
    "start": "38430",
    "end": "51870"
  },
  {
    "start": "50000",
    "end": "100000"
  },
  {
    "text": "quick look at the agenda we'll start by looking at some of the foundational requirements and capabilities of",
    "start": "51870",
    "end": "57600"
  },
  {
    "text": "building what I'm calling a retail data platform and these are some of the important things to keep in mind when",
    "start": "57600",
    "end": "62760"
  },
  {
    "text": "you're looking to build personalized experiences on top of AWS then we'll look at some of the building blocks",
    "start": "62760",
    "end": "68549"
  },
  {
    "text": "provided by AWS for actually building your own personalized solutions and",
    "start": "68549",
    "end": "73770"
  },
  {
    "text": "Calvin will give us introduction to segments customer data infrastructure and on account will give us an overview",
    "start": "73770",
    "end": "80520"
  },
  {
    "text": "of the personalization platform built at bonobos the bulk of this session will",
    "start": "80520",
    "end": "86040"
  },
  {
    "text": "actually be an interactive Q&A between Calvin and Annika where we'll learn",
    "start": "86040",
    "end": "91170"
  },
  {
    "text": "about some of the business and technical aspects of the journey of bonobos",
    "start": "91170",
    "end": "96570"
  },
  {
    "text": "building their personalization infrastructure so with that let's get",
    "start": "96570",
    "end": "101729"
  },
  {
    "start": "100000",
    "end": "440000"
  },
  {
    "text": "started so before looking to build personalized experiences into your",
    "start": "101729",
    "end": "108780"
  },
  {
    "text": "applications particularly if you're coming from just having a purpose build application that's using a purpose-built",
    "start": "108780",
    "end": "114899"
  },
  {
    "text": "database delivering a customer experience when you start looking at building personalized experience there's",
    "start": "114899",
    "end": "121020"
  },
  {
    "text": "a number of additional disciplines that you need to keep in mind there's aspects such as",
    "start": "121020",
    "end": "126850"
  },
  {
    "text": "machine machine learning ETL processes where you're transforming data into",
    "start": "126850",
    "end": "132160"
  },
  {
    "text": "different formats and so we'll talk a bit about some of the the criteria",
    "start": "132160",
    "end": "137860"
  },
  {
    "text": "that's important to keep in mind when you're building out this infrastructure we'll use the metaphor of a pipeline",
    "start": "137860",
    "end": "143710"
  },
  {
    "text": "that covers the four main stages of ingestion storage analysis and then",
    "start": "143710",
    "end": "149800"
  },
  {
    "text": "consuming insights so a customer and operational data enters this pipeline through various ingestion endpoints and",
    "start": "149800",
    "end": "157420"
  },
  {
    "text": "will consume insights and visualizations at the consumption layer so at the",
    "start": "157420",
    "end": "164020"
  },
  {
    "text": "ingestion layer we need services that can support the ingestion of data and different velocities and formats",
    "start": "164020",
    "end": "170700"
  },
  {
    "text": "real-time streaming data integrations through either applications we may have",
    "start": "170700",
    "end": "177070"
  },
  {
    "text": "on-premise or with third parties as well as supporting both data uploads of log",
    "start": "177070",
    "end": "182590"
  },
  {
    "text": "files or video files images audio files and things like that some of the services that will use it the ingestion",
    "start": "182590",
    "end": "189370"
  },
  {
    "text": "tier include Amazon Kinesis or Apache Kafka for streaming data also for any",
    "start": "189370",
    "end": "197920"
  },
  {
    "text": "retail IOT experiences Amazon's IOT core allows integration with these IOT",
    "start": "197920",
    "end": "204430"
  },
  {
    "text": "devices and then for integrations there's Amazon API gateway which allows",
    "start": "204430",
    "end": "209920"
  },
  {
    "text": "you to integrate with your own applications whether they be on-premise or third party and for bulk data",
    "start": "209920",
    "end": "217650"
  },
  {
    "text": "ingestion Amazon provides services such as import/export storage gateway or some",
    "start": "217650",
    "end": "224680"
  },
  {
    "text": "of the new services we announced this week which is a manage SFTP service on top of s3 or the new data sync service",
    "start": "224680",
    "end": "231310"
  },
  {
    "text": "that was announced this week as well when it comes to storing data we want a",
    "start": "231310",
    "end": "236620"
  },
  {
    "text": "storage layer that gives us fine grain and flexible security capabilities so that we can control access to our data",
    "start": "236620",
    "end": "243160"
  },
  {
    "text": "at the user application and tool level we also want our storage tier to be",
    "start": "243160",
    "end": "249040"
  },
  {
    "text": "durable and scalable so we want data to be stored in multiple multiple copies of",
    "start": "249040",
    "end": "255010"
  },
  {
    "text": "our data across multiple availability zones as well as being able to scale up as",
    "start": "255010",
    "end": "260290"
  },
  {
    "text": "of data grows over time and being able to support spikes in volume in a Justin",
    "start": "260290",
    "end": "267150"
  },
  {
    "text": "we want our data in our storage tier to also be discoverable so that as as data",
    "start": "267150",
    "end": "273820"
  },
  {
    "text": "scientists and data analysts are working with our data they can explore data",
    "start": "273820",
    "end": "278830"
  },
  {
    "text": "catalogues to find out where different data lives and and what its format is and of course we want it to be cost",
    "start": "278830",
    "end": "284680"
  },
  {
    "text": "effective and future proof so that the data we're collecting today can be used for building applications that we",
    "start": "284680",
    "end": "290230"
  },
  {
    "text": "haven't even envisioned yet some of the services that that are used here so for",
    "start": "290230",
    "end": "295960"
  },
  {
    "text": "structured or transactional data of course there's Amazon RDS for semi structured data there's Amazon DynamoDB",
    "start": "295960",
    "end": "302050"
  },
  {
    "text": "or MongoDB for file based or object",
    "start": "302050",
    "end": "308830"
  },
  {
    "text": "based storage there's s3 of course as well as Amazon DFS when it comes to",
    "start": "308830",
    "end": "316270"
  },
  {
    "text": "analyzing the data we want tools that are scalable and flexible and also support an iterative development process",
    "start": "316270",
    "end": "322600"
  },
  {
    "text": "so you see the bi-directional arrows between storage and analysis and so we",
    "start": "322600",
    "end": "328270"
  },
  {
    "text": "want tools to be able to consume data from the storage tier perform some transfer transformation or",
    "start": "328270",
    "end": "333610"
  },
  {
    "text": "reorganization of the data and then be able to store it back to our storage tier we also want to encourage",
    "start": "333610",
    "end": "339400"
  },
  {
    "text": "experimentation in the analysis phase so being able to allow data analysts to be",
    "start": "339400",
    "end": "346210"
  },
  {
    "text": "able to quickly be able to explore data maybe try some experimentation or our developers work on some new ideas or",
    "start": "346210",
    "end": "353290"
  },
  {
    "text": "concepts and then be able to decommission any resources I used during the experimentation with with no risk",
    "start": "353290",
    "end": "360510"
  },
  {
    "text": "some of the tools and technologies that you you'd you would use here of course is Amazon EMR which is AWS is Hadoop as",
    "start": "360510",
    "end": "368290"
  },
  {
    "text": "a service that gives you access to the entire Hadoop ecosystem including SPARC",
    "start": "368290",
    "end": "374590"
  },
  {
    "text": "flank Pig you know and many other libraries that are used with Hadoop",
    "start": "374590",
    "end": "381990"
  },
  {
    "text": "there's also Amazon redshift which is AWS is a petabyte scale data warehouse",
    "start": "381990",
    "end": "387370"
  },
  {
    "text": "that allows you to analyze your data and Amazon stage maker which allows you to",
    "start": "387370",
    "end": "393700"
  },
  {
    "text": "build and try machine learning models based on data that you have in your storage layer when",
    "start": "393700",
    "end": "399910"
  },
  {
    "text": "it comes to consuming data we not only want to be able to visualize and explore our data but we also want to have",
    "start": "399910",
    "end": "405580"
  },
  {
    "text": "scaleable endpoints that we can stand up so that our applications can consume",
    "start": "405580",
    "end": "411040"
  },
  {
    "text": "these insights these machine learning inference endpoints that we'll look at later in the talk so I've discussed a number of AWS",
    "start": "411040",
    "end": "418510"
  },
  {
    "text": "services across each of these four parts of the pipeline there's also thousands",
    "start": "418510",
    "end": "424120"
  },
  {
    "text": "of partner provided solutions one of which we're looking at today is segments that partners that who build build",
    "start": "424120",
    "end": "431980"
  },
  {
    "text": "further up the application stack and do more of the heavy lifting so that you're able to focus on what differentiates",
    "start": "431980",
    "end": "437740"
  },
  {
    "text": "your product with your customers so let's take a turn and take a quick look",
    "start": "437740",
    "end": "443260"
  },
  {
    "start": "440000",
    "end": "482000"
  },
  {
    "text": "at some of the building blocks that are available for building personalized experiences on AWS a quick level set on",
    "start": "443260",
    "end": "450730"
  },
  {
    "text": "the definition of what personalized experiences are is there are truly unique digital experiences that are",
    "start": "450730",
    "end": "456370"
  },
  {
    "text": "specific to each customer and some examples include recommendation systems",
    "start": "456370",
    "end": "461500"
  },
  {
    "text": "or related products these can be products people services or content",
    "start": "461500",
    "end": "467430"
  },
  {
    "text": "there's also personalized search results where results are reorganized based on the preferences of each user we can also",
    "start": "467430",
    "end": "474910"
  },
  {
    "text": "create special offers that are tailored to each particular user as well as tailor digital marketing campaigns so",
    "start": "474910",
    "end": "484270"
  },
  {
    "start": "482000",
    "end": "601000"
  },
  {
    "text": "we'll look at a particular class of personalized solutions and these are recommender systems there's three",
    "start": "484270",
    "end": "490990"
  },
  {
    "text": "different approaches to building recommender systems first is knowledge based filtering which is making",
    "start": "490990",
    "end": "497260"
  },
  {
    "text": "recommendations based on similarity of items so this is the classic example of",
    "start": "497260",
    "end": "502300"
  },
  {
    "text": "related products and what we need to build these systems is we have to have detailed information about the items",
    "start": "502300",
    "end": "508870"
  },
  {
    "text": "that were recommending so for products in e-commerce it might be product description categories style tags",
    "start": "508870",
    "end": "517300"
  },
  {
    "text": "different things like that that allow us to calculate similarity between items",
    "start": "517300",
    "end": "523080"
  },
  {
    "text": "next is content-based filtering which builds on knowledge based filtering by adding an L",
    "start": "523080",
    "end": "528190"
  },
  {
    "text": "user preference so an example here is if you liked this product you may like",
    "start": "528190",
    "end": "533500"
  },
  {
    "text": "these other products besides the item attributes and metadata that we need to",
    "start": "533500",
    "end": "538780"
  },
  {
    "text": "have from the knowledge-based approach we're also incorporating some user feedback into our recommender system it",
    "start": "538780",
    "end": "545640"
  },
  {
    "text": "finally collaborative filtering takes a different approach where it's making recommendations based on the behavior of",
    "start": "545640",
    "end": "551620"
  },
  {
    "text": "users that have provided similar feedback as the user for which we're creating recommendations the canonical",
    "start": "551620",
    "end": "557590"
  },
  {
    "text": "example here is Amazon comms customers who bought product X would also bought",
    "start": "557590",
    "end": "563320"
  },
  {
    "text": "product Y and what's unique about collaborative filtering solutions is that they're there they really do not",
    "start": "563320",
    "end": "570760"
  },
  {
    "text": "depend on any knowledge of the items for which they're making recommendations instead they're dependent completely on",
    "start": "570760",
    "end": "576220"
  },
  {
    "text": "on extensive user behavior and this makes this particular approach",
    "start": "576220",
    "end": "581740"
  },
  {
    "text": "susceptible what's called a cold start problem where you need a significant amount of data based on user preferences",
    "start": "581740",
    "end": "587880"
  },
  {
    "text": "before you can start making recommendations so in practice what most",
    "start": "587880",
    "end": "594040"
  },
  {
    "text": "customers do is actually a combination of of all three of these or a few of these different approaches to create an overall personalized experience so let's",
    "start": "594040",
    "end": "603130"
  },
  {
    "start": "601000",
    "end": "706000"
  },
  {
    "text": "take a closer look at some of the different types of feedback that that are fed into collaborative filtering and",
    "start": "603130",
    "end": "610060"
  },
  {
    "text": "content-based filtering explicit feedback is requires the users users to",
    "start": "610060",
    "end": "615820"
  },
  {
    "text": "explicitly rate items so on Netflix it's rating movies or rating products it's",
    "start": "615820",
    "end": "621910"
  },
  {
    "text": "liking or disliking products it's also asking users to rank items or create",
    "start": "621910",
    "end": "627040"
  },
  {
    "text": "lists of preferred items this type of data is is typically harder to collect because you're actually asking the user",
    "start": "627040",
    "end": "634120"
  },
  {
    "text": "to provide feedback it's also easier to game or the data is maybe a little less",
    "start": "634120",
    "end": "639370"
  },
  {
    "text": "reliable because it's susceptible to users thinking they want to tell you what you want to hear or maybe they're",
    "start": "639370",
    "end": "645970"
  },
  {
    "text": "not completely honest about what their preferences are but it does allow you gives you the opportunity to collect",
    "start": "645970",
    "end": "651670"
  },
  {
    "text": "both positive and negative feedback on items implicit feedback is collected as",
    "start": "651670",
    "end": "658510"
  },
  {
    "text": "the user is actively using your your application so viewing an item reading a blog post",
    "start": "658510",
    "end": "664480"
  },
  {
    "text": "watching a video listening to a song in e-commerce would be adding an item to a card or even purchasing a product this",
    "start": "664480",
    "end": "672400"
  },
  {
    "text": "type of data is is easier to collect because you're not asking the user to explicitly provide feedback you just",
    "start": "672400",
    "end": "678820"
  },
  {
    "text": "want them to naturally use your application as they normally would this makes this type of data",
    "start": "678820",
    "end": "684640"
  },
  {
    "text": "um harder to gain because users may not even be aware that that the activity they're doing on your with your",
    "start": "684640",
    "end": "691240"
  },
  {
    "text": "application is used for recommendations and it's also typically positive only",
    "start": "691240",
    "end": "696370"
  },
  {
    "text": "feedback which means simply that users are only going to read content or watch",
    "start": "696370",
    "end": "702220"
  },
  {
    "text": "videos or listen to songs that they're interested in so we'll look at building",
    "start": "702220",
    "end": "709690"
  },
  {
    "start": "706000",
    "end": "748000"
  },
  {
    "text": "recommender systems three different ways on AWS look at three different architectures there's more ways than",
    "start": "709690",
    "end": "714910"
  },
  {
    "text": "this but we're just going to highlight these three to give you a give you a sense of different approaches so the",
    "start": "714910",
    "end": "720940"
  },
  {
    "text": "first is using Amazon Neptune building a collaborative filtering query approach on Neptune Neptune is AWS is fully",
    "start": "720940",
    "end": "729010"
  },
  {
    "text": "managed graph database then we'll look at two machine learning approaches one based on Amazon EMR using apache spark",
    "start": "729010",
    "end": "736410"
  },
  {
    "text": "that uses a technique called matrix factorization and then we'll look",
    "start": "736410",
    "end": "741760"
  },
  {
    "text": "quickly at a sage maker option that uses a deep matrix factorization approach so",
    "start": "741760",
    "end": "750220"
  },
  {
    "start": "748000",
    "end": "795000"
  },
  {
    "text": "looking at our graph based solution first graph base will load our relationship between individuals and",
    "start": "750220",
    "end": "758680"
  },
  {
    "text": "products in a property graph and property graphs are composed of vertices",
    "start": "758680",
    "end": "764140"
  },
  {
    "text": "or nodes and edges that indicate relationships between two nodes so in this case we have customers that have",
    "start": "764140",
    "end": "771310"
  },
  {
    "text": "indicated that they've purchased products or two customers or users who know each other or an interest in sports",
    "start": "771310",
    "end": "778330"
  },
  {
    "text": "in this case so with this data relationship data loaded in a graph we're able to compose queries that",
    "start": "778330",
    "end": "784650"
  },
  {
    "text": "implement a collaborative filtering solution that allows us to make recommendations for products that users",
    "start": "784650",
    "end": "791710"
  },
  {
    "text": "may want to purchase or users they might may want to follow so let's take a quick look at what one",
    "start": "791710",
    "end": "797950"
  },
  {
    "start": "795000",
    "end": "843000"
  },
  {
    "text": "of these queries might look like using gremlin query syntax and I won't I'll",
    "start": "797950",
    "end": "804430"
  },
  {
    "text": "just blow the query up here and won't go through it step by step in the interest of time but essentially what we're doing",
    "start": "804430",
    "end": "811269"
  },
  {
    "text": "is we're finding the customer from which we want to make a recommendation we're looking at all the products that they've purchased and then we look at all the",
    "start": "811269",
    "end": "817779"
  },
  {
    "text": "other customers that have purchased the same products as customer see one in this case then we go through a process",
    "start": "817779",
    "end": "824230"
  },
  {
    "text": "of finding the number of maximum number of products that have been purchased in common we group those those other",
    "start": "824230",
    "end": "831370"
  },
  {
    "text": "customers that have made those purchases and look at the those products that they bought executing this query then",
    "start": "831370",
    "end": "837370"
  },
  {
    "text": "produces a list of products that we can use to recommend to customers see one so",
    "start": "837370",
    "end": "845290"
  },
  {
    "start": "843000",
    "end": "940000"
  },
  {
    "text": "what would an architecture look like that would an employee collaborative filtering with Amazon Neptune so let's",
    "start": "845290",
    "end": "852550"
  },
  {
    "text": "imagine we have an application that's composed of maybe a mobile app tablet app and desktop application it's making",
    "start": "852550",
    "end": "860380"
  },
  {
    "text": "dynamic application requests to a lambda lambda series of lambda functions in this case this could just as easily be a",
    "start": "860380",
    "end": "867190"
  },
  {
    "text": "docker container based application or or launched in elastic Beanstalk",
    "start": "867190",
    "end": "874019"
  },
  {
    "text": "clickstream data is sent to Amazon Kinesis there's a lambda function that",
    "start": "874019",
    "end": "880959"
  },
  {
    "text": "is consuming the clickstream data out of Kinesis and responsible for updating the implicit data enter an F tune database",
    "start": "880959",
    "end": "889290"
  },
  {
    "text": "let's assume that the explicit activity or feedback is we're storing that in a",
    "start": "889290",
    "end": "894820"
  },
  {
    "text": "in Amazon Aurora and a relational database in order to synchronize updates",
    "start": "894820",
    "end": "900069"
  },
  {
    "text": "that are made in Aurora to our Neptune database we will use a change data capture powder development pattern which",
    "start": "900069",
    "end": "906760"
  },
  {
    "text": "essentially has a database trigger and store procedure that calls that lambda function whenever data is changed in",
    "start": "906760",
    "end": "912819"
  },
  {
    "text": "Aurora that lambda function then updates our Neptune database so Neptune now has",
    "start": "912819",
    "end": "917980"
  },
  {
    "text": "the implicit and explicit feedback that we need to build those queries to provide recommendations back to our",
    "start": "917980",
    "end": "924519"
  },
  {
    "text": "users the link on this slide points to a an example it go through steps I",
    "start": "924519",
    "end": "930069"
  },
  {
    "text": "step-by-step building a solution described here and it will be in the",
    "start": "930069",
    "end": "936069"
  },
  {
    "text": "slide that's going to be published on SlideShare a couple of days from hit from now so we'll turn now to matrix",
    "start": "936069",
    "end": "943420"
  },
  {
    "start": "940000",
    "end": "1050000"
  },
  {
    "text": "factorization which is more of a machine learning approach to building collaborative filtering the approach",
    "start": "943420",
    "end": "950769"
  },
  {
    "text": "taken here is essentially building a user item matrix of item item ratings",
    "start": "950769",
    "end": "956500"
  },
  {
    "text": "made by users and so we have a matrix here of users and items users as rows",
    "start": "956500",
    "end": "961810"
  },
  {
    "text": "items as columns and for every rating that a user has given we have a an entry",
    "start": "961810",
    "end": "968290"
  },
  {
    "text": "into into the matrix so the size of these is you have you know get up to",
    "start": "968290",
    "end": "973600"
  },
  {
    "text": "millions of users and in thousands or hundreds of thousands of products this matrix gets quite quite large and",
    "start": "973600",
    "end": "980259"
  },
  {
    "text": "because users typically will only rate a few items over time this the matrix is",
    "start": "980259",
    "end": "987339"
  },
  {
    "text": "sparsely populated this makes it difficult for for us to work with and to perform calculations against so matrix",
    "start": "987339",
    "end": "994990"
  },
  {
    "text": "factorization is an approach of using algorithms to decompose this sparsely populated user item matrix into two",
    "start": "994990",
    "end": "1002310"
  },
  {
    "text": "smaller matrices U and V of T in this case and these are called latent latent",
    "start": "1002310",
    "end": "1008250"
  },
  {
    "text": "factors where the we can make a prediction by summing the product",
    "start": "1008250",
    "end": "1013290"
  },
  {
    "text": "between any item and user to create a prediction that a missing rating in the",
    "start": "1013290",
    "end": "1020069"
  },
  {
    "text": "matrix M the challenge here is that these latent factors it's it's difficult to calculate their effect when we're",
    "start": "1020069",
    "end": "1027510"
  },
  {
    "text": "when we're calculating predictions and so machine learning is used to optimize the effect of these latent factors and",
    "start": "1027510",
    "end": "1035159"
  },
  {
    "text": "minimizing against a cost function and so the two possible popular approaches",
    "start": "1035159",
    "end": "1040740"
  },
  {
    "text": "to optimizing these latent factor effects are stochastic gradient descent",
    "start": "1040740",
    "end": "1046949"
  },
  {
    "text": "and alternating least squares and it just so happens that Apache sparks ml",
    "start": "1046949",
    "end": "1053490"
  },
  {
    "start": "1050000",
    "end": "1075000"
  },
  {
    "text": "Lib has an implementation of collaborative filtering that uses the all turning least squares approach it",
    "start": "1053490",
    "end": "1060390"
  },
  {
    "text": "supports both the implicit and explicit feed that we that we looked at and it has some optimizations around optimizing for",
    "start": "1060390",
    "end": "1067590"
  },
  {
    "text": "larger data sets as well as strategy for dealing with the cold start problem that that I mentioned earlier so an",
    "start": "1067590",
    "end": "1076890"
  },
  {
    "start": "1075000",
    "end": "1180000"
  },
  {
    "text": "application architecture that would use Apache spark on EMR looks something like this",
    "start": "1076890",
    "end": "1082080"
  },
  {
    "text": "so we'll have the same users using an application sending clickstream data to Kinesis and dynamic requests to lamda",
    "start": "1082080",
    "end": "1090030"
  },
  {
    "text": "this time we will have to consumers off of the Kinesis clickstream data there's",
    "start": "1090030",
    "end": "1095460"
  },
  {
    "text": "an amazon data firehose that's going to write the raw clickstream data to an s3",
    "start": "1095460",
    "end": "1100679"
  },
  {
    "text": "bucket the other consumer we have is Amazon data analytics Kinesis data",
    "start": "1100679",
    "end": "1106980"
  },
  {
    "text": "analytics which is going going to allow us to detect detect trending activity on",
    "start": "1106980",
    "end": "1112710"
  },
  {
    "text": "our on our applications well write that training data to Amazon diny DynamoDB in",
    "start": "1112710",
    "end": "1117870"
  },
  {
    "text": "this case and even though this is a part of the machine learning aspect it's a way that we can incorporate any sort of",
    "start": "1117870",
    "end": "1124320"
  },
  {
    "text": "trending activity and present that to our users to maybe give them content to engage with where the machine learning",
    "start": "1124320",
    "end": "1130590"
  },
  {
    "text": "aspect comes in is that will perform typically an ETL process is going to be",
    "start": "1130590",
    "end": "1135809"
  },
  {
    "text": "needed to take the raw the rock clickstream data and transform it into a format that is more suitable for",
    "start": "1135809",
    "end": "1142770"
  },
  {
    "text": "bringing into the machine learning process so we're gonna use Amazon EMR to",
    "start": "1142770",
    "end": "1147960"
  },
  {
    "text": "perform an ETL step which writes it back to s3 then we will use a spark ml Lib",
    "start": "1147960",
    "end": "1155240"
  },
  {
    "text": "collaborative filtering pipeline to take in our implicit feedback that from our",
    "start": "1155240",
    "end": "1160290"
  },
  {
    "text": "ETL step as well as bring in our explicit feedback from that same Aurora database we had in the previous",
    "start": "1160290",
    "end": "1165360"
  },
  {
    "text": "architecture this will then write the predictions back into Amazon Amazon",
    "start": "1165360",
    "end": "1170940"
  },
  {
    "text": "DynamoDB which is available to our application to produce predictions and",
    "start": "1170940",
    "end": "1176340"
  },
  {
    "text": "send recommendations back to back to our users so finally let's look at Amazon",
    "start": "1176340",
    "end": "1183480"
  },
  {
    "start": "1180000",
    "end": "1240000"
  },
  {
    "text": "stage maker this is Amazon's of a fully managed service for building",
    "start": "1183480",
    "end": "1189090"
  },
  {
    "text": "training and deploying machine learning models sage maker uses an iterative",
    "start": "1189090",
    "end": "1194250"
  },
  {
    "text": "process where you start with building based on pre-built Jupiter notebooks that have",
    "start": "1194250",
    "end": "1202169"
  },
  {
    "text": "access to highly optimized machine learning algorithms the training step allows for one-click training of models",
    "start": "1202169",
    "end": "1210059"
  },
  {
    "text": "both machine learning and deep learning as well as the option to bring your own algorithms into Sage maker you have",
    "start": "1210059",
    "end": "1216750"
  },
  {
    "text": "access to many of the most popular frameworks out there today including pi",
    "start": "1216750",
    "end": "1222210"
  },
  {
    "text": "torch tensorflow MX net gluon and many others and then",
    "start": "1222210",
    "end": "1228270"
  },
  {
    "text": "when you're ready to deploy your machine learning model CH maker allows you to deploy that model fully fully managed",
    "start": "1228270",
    "end": "1236520"
  },
  {
    "text": "deployment and provides an end point for you to integrate into your application CH maker provides several examples that",
    "start": "1236520",
    "end": "1243809"
  },
  {
    "start": "1240000",
    "end": "1299000"
  },
  {
    "text": "are specific to what we're talking about today and personalization there's a recommender system there's also a",
    "start": "1243809",
    "end": "1250080"
  },
  {
    "text": "another example that uses targeted direct marketing customer churn prediction as well as forecasting",
    "start": "1250080",
    "end": "1257100"
  },
  {
    "text": "product demand the link at the bottom of this slide will take you to the notebooks for each of these examples so",
    "start": "1257100",
    "end": "1262980"
  },
  {
    "text": "you can run those on your own so the architecture for incorporating sage",
    "start": "1262980",
    "end": "1269610"
  },
  {
    "text": "maker will start with having our pre trained so we've already done or ETL process and we've dropped it into that",
    "start": "1269610",
    "end": "1275990"
  },
  {
    "text": "s3 bucket stage maker we'll pull that in using its training code and train the",
    "start": "1275990",
    "end": "1282419"
  },
  {
    "text": "model the artifacts will be written back out to s3 and then when the model is",
    "start": "1282419",
    "end": "1287520"
  },
  {
    "text": "deployed using infrareds code it's pulled back out of that s3 bucket and an",
    "start": "1287520",
    "end": "1292649"
  },
  {
    "text": "endpoint is created that allows you to make prediction calls or inference calls to that endpoint so with that I'll turn",
    "start": "1292649",
    "end": "1302010"
  },
  {
    "text": "it over to Calvin and give us an overview of segments customer data infrastructure cool thanks James",
    "start": "1302010",
    "end": "1309169"
  },
  {
    "text": "as said before I'm Calvin I'm one of the cofounders and CTO here at segments and",
    "start": "1309169",
    "end": "1316559"
  },
  {
    "text": "in particular for this talk I'm hoping to speed through a little bit of a brief overview of segments just to give you an",
    "start": "1316559",
    "end": "1323039"
  },
  {
    "text": "idea of what it does and how the Tool Works but really I think the main value will come from on",
    "start": "1323039",
    "end": "1328559"
  },
  {
    "text": "presenting on a bunch of the use cases about how bonobos is using segments Plus AWS together because as much as I can",
    "start": "1328559",
    "end": "1336210"
  },
  {
    "text": "extol the virtues of segments and how AWS works I think it's really most interesting to hear from customers out",
    "start": "1336210",
    "end": "1341909"
  },
  {
    "text": "in the field and practitioners about how they're using them tools so to give you a quick infra segment provides customer",
    "start": "1341909",
    "end": "1349649"
  },
  {
    "start": "1345000",
    "end": "1435000"
  },
  {
    "text": "data infrastructure and what that means if we unpack that a little bit is that if you're running a business online you",
    "start": "1349649",
    "end": "1356009"
  },
  {
    "text": "have a lot of data about your users data that's coming through your website in terms of quick stream traffic or what",
    "start": "1356009",
    "end": "1362340"
  },
  {
    "text": "pages users are viewing data about things like ad impressions for when users are seeing your brand data may be",
    "start": "1362340",
    "end": "1369299"
  },
  {
    "text": "about purchases from point-of-sale systems or maybe s ap databases that you",
    "start": "1369299",
    "end": "1374610"
  },
  {
    "text": "have somewhere in your inventory essentially you're running a business at any sort of scale there's probably lots",
    "start": "1374610",
    "end": "1379799"
  },
  {
    "text": "of places where this data lives and so segment helps you collect it get it into one single place where it's clean and",
    "start": "1379799",
    "end": "1385980"
  },
  {
    "text": "organized then adapt it to hundreds of downstream tools well this looks like",
    "start": "1385980",
    "end": "1391200"
  },
  {
    "text": "it's something over here on my right you can see that segment helps you collect data from various sources which are on",
    "start": "1391200",
    "end": "1396869"
  },
  {
    "text": "the left and then it takes that data and funnels it to various destinations places where you actually want to use",
    "start": "1396869",
    "end": "1403320"
  },
  {
    "text": "that data if we dive down a little bit more into the infrastructure if you're curious about how it works currently",
    "start": "1403320",
    "end": "1410279"
  },
  {
    "text": "we're processing 300 billion events every single month that translates to roughly 400,000 concurrent HTTP requests",
    "start": "1410279",
    "end": "1417749"
  },
  {
    "text": "and the entire infrastructure is container as it's all running in ECS we're running across 250 different micro",
    "start": "1417749",
    "end": "1423990"
  },
  {
    "text": "services and we send data to hundreds of third-party api's different tools that",
    "start": "1423990",
    "end": "1429960"
  },
  {
    "text": "our customers are using to analyze message their data or act upon it and",
    "start": "1429960",
    "end": "1436619"
  },
  {
    "start": "1435000",
    "end": "1470000"
  },
  {
    "text": "particular I wanted to highlight those hundreds of endpoints that we support now in many cases we support analytics",
    "start": "1436619",
    "end": "1443159"
  },
  {
    "text": "use cases with things like data warehouses like redshift or bigquery we support messaging tools tools like send",
    "start": "1443159",
    "end": "1449730"
  },
  {
    "text": "grid Marketo etc we support analytics tools like Google Analytics or Mixpanel",
    "start": "1449730",
    "end": "1454879"
  },
  {
    "text": "but in particular we have a class of tools that I would really say are close to infrastructure where you can take the",
    "start": "1454879",
    "end": "1461399"
  },
  {
    "text": "data that segment has collected and pipe it to your own infrastructure whether that's Amazon s3 Kinesis redshift lambda",
    "start": "1461399",
    "end": "1469900"
  },
  {
    "text": "you name it and in essence this is what a lot of segment customers do they",
    "start": "1469900",
    "end": "1475690"
  },
  {
    "start": "1470000",
    "end": "1544000"
  },
  {
    "text": "collect data from their apps their mobile apps maybe their internal ETL",
    "start": "1475690",
    "end": "1481120"
  },
  {
    "text": "pipelines that they have running somewhere in their infrastructure maybe it's their salesforce data which they're trying to join together against their",
    "start": "1481120",
    "end": "1487330"
  },
  {
    "text": "actual usage data and they use segments as the core collection point and pipeline kind of similar to what Jaynes",
    "start": "1487330",
    "end": "1493570"
  },
  {
    "text": "talked about earlier as sort of the bridge between a bunch of those steps in that pipeline and then separately they",
    "start": "1493570",
    "end": "1498730"
  },
  {
    "text": "can get that data out depending on who the end user is so if they're an analytics person they can analyze that",
    "start": "1498730",
    "end": "1504040"
  },
  {
    "text": "data in redshift if maybe they're a data engineer they can take that data from Kinesis and start piping it into their",
    "start": "1504040",
    "end": "1510280"
  },
  {
    "text": "own recommendation systems or maybe if there's someone who's just trying to experiment they can hook it up to a",
    "start": "1510280",
    "end": "1515590"
  },
  {
    "text": "lambda function and really this is a trend that we see happening over and over again with our customers and one",
    "start": "1515590",
    "end": "1522070"
  },
  {
    "text": "that I'm hopeful Annika will be able to shed more light on shortly and so if you have particular questions definitely",
    "start": "1522070",
    "end": "1528640"
  },
  {
    "text": "feel free to come find me after this talk or email us AWS at segment comm but",
    "start": "1528640",
    "end": "1534640"
  },
  {
    "text": "without further ado I'll turn it over to the real star of the show Annika at bonobos you're too kind thanks Calvin",
    "start": "1534640",
    "end": "1544050"
  },
  {
    "text": "so I'm Monica I oversee the analytics data science and data engineering team",
    "start": "1544620",
    "end": "1549640"
  },
  {
    "text": "at bonobos bonobos is the largest apparel company built on web our core",
    "start": "1549640",
    "end": "1556090"
  },
  {
    "text": "value proposition is personalized fit and we have five hundred fifty thousand",
    "start": "1556090",
    "end": "1561250"
  },
  {
    "text": "unique SKUs across a diverse assortment so we offer jackets black tie suiting",
    "start": "1561250",
    "end": "1568020"
  },
  {
    "text": "but also casual t-shirts casual shirts and of course we were most famous as",
    "start": "1568020",
    "end": "1573100"
  },
  {
    "text": "some of you might know for our our chinos and so across that assortment for",
    "start": "1573100",
    "end": "1578530"
  },
  {
    "text": "our jackets there's additional complexity because as an example with our jackets we have seven different fits",
    "start": "1578530",
    "end": "1584530"
  },
  {
    "text": "and for each fit there's about twelve different sizes so we have an athletic",
    "start": "1584530",
    "end": "1589900"
  },
  {
    "text": "fit we have a tailored fit we have a slim fit with a standard fit and then there's three other fits in big and tall",
    "start": "1589900",
    "end": "1595480"
  },
  {
    "text": "and so all that with our scale entails a good amount of complexity and my team's mission is to use data technology and",
    "start": "1595480",
    "end": "1602530"
  },
  {
    "text": "good judgment to solve the problems business and customer that arise from their complexity and we do that by",
    "start": "1602530",
    "end": "1609550"
  },
  {
    "text": "working and borrowing from two disciplines so bringing the engineering rigor of building resilient systems that",
    "start": "1609550",
    "end": "1615790"
  },
  {
    "text": "are robust and stay up and are low latency along with the analytics domain",
    "start": "1615790",
    "end": "1621600"
  },
  {
    "text": "goal of understanding why things are happening and how things could be optimized and then based off what",
    "start": "1621600",
    "end": "1629650"
  },
  {
    "text": "business needs are tailoring ourselves to solve the the problem at hand the way",
    "start": "1629650",
    "end": "1635350"
  },
  {
    "start": "1634000",
    "end": "1800000"
  },
  {
    "text": "that we do that is with infrastructure and what we're solving for is what a lot of other b2c companies are solving for",
    "start": "1635350",
    "end": "1641380"
  },
  {
    "text": "which is the integration of the customer journey there used to be a time with the classical example was that marketing had",
    "start": "1641380",
    "end": "1648070"
  },
  {
    "text": "their data and then merchants or product people had their data but really the way that people interact with your business",
    "start": "1648070",
    "end": "1653860"
  },
  {
    "text": "is as a journey that involves the marketing touch points that bought them",
    "start": "1653860",
    "end": "1659410"
  },
  {
    "text": "to the site and then interactions across the product domain and being able to",
    "start": "1659410",
    "end": "1664690"
  },
  {
    "text": "understand what's happening across both so the way that we do that is with segments as Calvin was talking about",
    "start": "1664690",
    "end": "1669760"
  },
  {
    "text": "earlier segment has integrations with a lot of data partners and our ability to",
    "start": "1669760",
    "end": "1674950"
  },
  {
    "text": "get those into an event level stream like a literal event level stream integrated so that you can understand",
    "start": "1674950",
    "end": "1682180"
  },
  {
    "text": "the evolution of touchpoints from a non branded paid search ad where you were searching for chinos and then you clicked onto bonobos and then you",
    "start": "1682180",
    "end": "1688750"
  },
  {
    "text": "browsed on our site and then purchased a pair of chinos being able to understand that provides tremendous value to",
    "start": "1688750",
    "end": "1696160"
  },
  {
    "text": "different people in our organization but also to our customers as we use that",
    "start": "1696160",
    "end": "1701260"
  },
  {
    "text": "with machine learning to offer tailored recommendation and personalization services so just to walk through our",
    "start": "1701260",
    "end": "1707440"
  },
  {
    "text": "stack wheel real fast and at point this laser here so raghida comes in through",
    "start": "1707440",
    "end": "1713860"
  },
  {
    "text": "segments via Kinesis and then we via EMR do some processing in enriching so",
    "start": "1713860",
    "end": "1719410"
  },
  {
    "text": "there's it's a lot of data cleanup as well as extracting out the marketing events and sequencing those and creating",
    "start": "1719410",
    "end": "1725770"
  },
  {
    "text": "concepts of things like sessions along with someone browsing before 30 minutes of inactivity and that happens",
    "start": "1725770",
    "end": "1732400"
  },
  {
    "text": "across domains because there could be data coming in from our retail stores called guide shops or through web and",
    "start": "1732400",
    "end": "1739090"
  },
  {
    "text": "being able to understand and follow a customer across both domains is what happens between this to this step and",
    "start": "1739090",
    "end": "1744730"
  },
  {
    "text": "then from there we stream that into services like propensity and",
    "start": "1744730",
    "end": "1750100"
  },
  {
    "text": "personalization which we'll get into or we put it into our analytics tools which drive decision-making throughout the",
    "start": "1750100",
    "end": "1756760"
  },
  {
    "text": "organization one more thing to talk about is just data integrity so throughout the pipeline we have alerting",
    "start": "1756760",
    "end": "1763690"
  },
  {
    "text": "and monitoring for not only the is data there is meeting SLA but also our our",
    "start": "1763690",
    "end": "1769930"
  },
  {
    "text": "kpi's right an example of that is product engineering changed our revenue",
    "start": "1769930",
    "end": "1775330"
  },
  {
    "text": "metric but because we had monitoring looking at our revenue metric and triangulating versus our production",
    "start": "1775330",
    "end": "1780400"
  },
  {
    "text": "database we were able to catch that issue really quickly really quickly which is important because our marketing",
    "start": "1780400",
    "end": "1785620"
  },
  {
    "text": "team uses revenue as reported by segments in order to make you know buy or spend decisions and without the",
    "start": "1785620",
    "end": "1791890"
  },
  {
    "text": "monitoring and the integrity checking we wouldn't have caught that for probably quite some time so let's get into what",
    "start": "1791890",
    "end": "1802780"
  },
  {
    "text": "the different services are just as examples so propensity is trying to solve the problem of our conversion rate",
    "start": "1802780",
    "end": "1808810"
  },
  {
    "text": "is let's say 3 to 4 percent but we know that for every person that buys something there's gonna be a lot more people on our site that don't but are",
    "start": "1808810",
    "end": "1815710"
  },
  {
    "text": "really high in 10 they're buying temperatures quite high but they just don't transact for whatever reason and through a lot of data analysis we found",
    "start": "1815710",
    "end": "1822280"
  },
  {
    "text": "out that a lot of those reasons are confusion paradox of choice we you know you might be looking at our you know",
    "start": "1822280",
    "end": "1828190"
  },
  {
    "text": "fancy fabric that's moisture wicking suiting or you might look at a traditional suits and not be able to",
    "start": "1828190",
    "end": "1833590"
  },
  {
    "text": "make a decision and sometimes that'll just cause you to to leave the site because you don't know to do and it can",
    "start": "1833590",
    "end": "1839290"
  },
  {
    "text": "also happen if you're competitive shopping versus us and our competitors so in order to identify these folks and",
    "start": "1839290",
    "end": "1846100"
  },
  {
    "text": "then create an intervention we build something called propensity which takes data from Kinesis and also this is an",
    "start": "1846100",
    "end": "1853900"
  },
  {
    "text": "older arc diagram but the idea is that it's taking product feature or features",
    "start": "1853900",
    "end": "1859240"
  },
  {
    "text": "in the data that we engineered such as session length the marketing channel that you came from and other attributes which described who",
    "start": "1859240",
    "end": "1865720"
  },
  {
    "text": "you are as a customer and then building a prediction to understand what's the likelihood that you're gonna convert in",
    "start": "1865720",
    "end": "1871480"
  },
  {
    "text": "3 minutes or 5 minutes and from there we make the prediction and then our friends",
    "start": "1871480",
    "end": "1876880"
  },
  {
    "text": "in product engineering will build experiences around that so on the right you can kind of see the way that we're thinking about it as we think that",
    "start": "1876880",
    "end": "1883600"
  },
  {
    "text": "there's a good chance you'll convert but you just might be a little bit price sensitive then we can offer you 20% off",
    "start": "1883600",
    "end": "1888970"
  },
  {
    "text": "coupon but in other situations we might offer you a bundle to take what you're looking at if it's a pant or shorts for",
    "start": "1888970",
    "end": "1894760"
  },
  {
    "text": "example and bundle it with a shirt and offer a discounted deal for both the idea is just to identify and build the",
    "start": "1894760",
    "end": "1900520"
  },
  {
    "text": "right interventions for the right person at the right point in their journey and that requires low latency architecture combined with being able to do analysis",
    "start": "1900520",
    "end": "1908380"
  },
  {
    "text": "and build machine learning models very rapidly and iteratively within that infrastructure another use",
    "start": "1908380",
    "end": "1916180"
  },
  {
    "start": "1915000",
    "end": "2023000"
  },
  {
    "text": "case is personalization so it's a similar sort of infrastructure where we have data segment data coming in through",
    "start": "1916180",
    "end": "1922450"
  },
  {
    "text": "Kinesis where we then have a Python application that's pulling from something called Chelsea and Chelsea for",
    "start": "1922450",
    "end": "1929380"
  },
  {
    "text": "us is just a codename for a something that we're working on which is a customer attribute matrix so all the",
    "start": "1929380",
    "end": "1935560"
  },
  {
    "text": "different attributes that describe you as a customer such as lifetime value your location your shipping address along with some third-party data and",
    "start": "1935560",
    "end": "1942760"
  },
  {
    "text": "then your the the products that you've been purchasing what we want to do is sort of like building on words that",
    "start": "1942760",
    "end": "1949690"
  },
  {
    "text": "stitch fix is done create an abstract definition of style through data because",
    "start": "1949690",
    "end": "1955000"
  },
  {
    "text": "if you think about someone let's say who might be a salesperson in Omaha Nebraska they probably don't want our flamingo",
    "start": "1955000",
    "end": "1961240"
  },
  {
    "text": "colored shirts maybe they do but perhaps very likely looking at the data they don't what we want to do is offer you an",
    "start": "1961240",
    "end": "1968200"
  },
  {
    "text": "outfit that most corresponds to what we think your style is and then learn along the way as that definition evolves and",
    "start": "1968200",
    "end": "1974820"
  },
  {
    "text": "that's what this endpoint exposes so please find me after this and I'll",
    "start": "1974820",
    "end": "1980110"
  },
  {
    "text": "happily talk about the model but for the sake of the architecture diagram what we want to say is we generate a matrix",
    "start": "1980110",
    "end": "1985720"
  },
  {
    "text": "output that says customer to outfit that they probably want to buy and we expose",
    "start": "1985720",
    "end": "1991390"
  },
  {
    "text": "that in this Python application which come in come with the streaming data offers a",
    "start": "1991390",
    "end": "1998760"
  },
  {
    "text": "real-time view of how to complement an outfit that someone's looking at the best way to understand this is just to",
    "start": "1998760",
    "end": "2004530"
  },
  {
    "text": "look at an example so your user who's added some stuff to their cart and we",
    "start": "2004530",
    "end": "2010200"
  },
  {
    "text": "know that based off your style or we think that based off your style that you would probably want to buy these other things to complete the outfit that you",
    "start": "2010200",
    "end": "2016350"
  },
  {
    "text": "would want to buy and that's what manifests on our site cool that's the",
    "start": "2016350",
    "end": "2026280"
  },
  {
    "start": "2023000",
    "end": "2077000"
  },
  {
    "text": "arc stop and we can refer back this and I think we're gonna transition now to a Q&A with Calvin",
    "start": "2026280",
    "end": "2032300"
  },
  {
    "text": "cool oh good yeah let's do it so I know before you were talking about how you",
    "start": "2050070",
    "end": "2057879"
  },
  {
    "text": "were basically monitoring data in terms of like fidelity where oh we saw this",
    "start": "2057880",
    "end": "2064179"
  },
  {
    "text": "one revenue metric drop or we changed it around somehow and now we're alerting on it I was wondering if you could maybe just take a step back and walk me",
    "start": "2064179",
    "end": "2070419"
  },
  {
    "text": "through what are the top three to five most important KPIs to bonobos as a business like what are the things that",
    "start": "2070420",
    "end": "2076060"
  },
  {
    "text": "you're looking at every day sure so for us as a ecommerce retail business our",
    "start": "2076060",
    "end": "2082120"
  },
  {
    "start": "2077000",
    "end": "2149000"
  },
  {
    "text": "aov our conversion rate so that's decomposes to order volume and traffic",
    "start": "2082120",
    "end": "2087639"
  },
  {
    "text": "both in guide shops and web so we actually have like a lot of retailers do cameras which just record how much",
    "start": "2087640",
    "end": "2095590"
  },
  {
    "text": "traffic is coming to our stores and being able to define metrics based off that to then develop and identify anomalies is important so conversion",
    "start": "2095590",
    "end": "2102460"
  },
  {
    "text": "rate then the average retail price of what we're presenting especially because",
    "start": "2102460",
    "end": "2107500"
  },
  {
    "text": "if we're offering you a 20% off thing as a part of the premise propensity model we want to identify how much of that is",
    "start": "2107500",
    "end": "2113470"
  },
  {
    "text": "coming from the retail price to ensure that we're not cutting too much into our margins mmm gotcha and in terms of like",
    "start": "2113470",
    "end": "2120460"
  },
  {
    "text": "how that's calculated do you get kind of a daily report you're like who's looking at those things something that sent to the company or yeah so we have a daily report that goes",
    "start": "2120460",
    "end": "2127930"
  },
  {
    "text": "out every morning that articulates the past day and how we're trending versus the week as well as our forecast for the",
    "start": "2127930",
    "end": "2133480"
  },
  {
    "text": "year gotcha cool in terms of the pipeline maybe you could talk a little bit more about how",
    "start": "2133480",
    "end": "2139810"
  },
  {
    "text": "your work fits in with the org as a whole like I understand your team is running the data pipeline but who are",
    "start": "2139810",
    "end": "2146080"
  },
  {
    "text": "the consumers of it so data consumers let's let's take a few different",
    "start": "2146080",
    "end": "2151450"
  },
  {
    "start": "2149000",
    "end": "2251000"
  },
  {
    "text": "examples because I think that might be helpful so we have a ninja team they're not actual ninjas but they we call them",
    "start": "2151450",
    "end": "2157780"
  },
  {
    "text": "ninjas they're our CX reps and they're amazingly helpful if you ever transact with us so the way that they feel",
    "start": "2157780",
    "end": "2164560"
  },
  {
    "text": "customer calls is by looking at the dashboards which are embedded we have looker dashboards embedded into their",
    "start": "2164560",
    "end": "2172330"
  },
  {
    "text": "their laptops so as they get different calls from customers about different issues the dashboard will filter the",
    "start": "2172330",
    "end": "2178870"
  },
  {
    "text": "customer and they can then use that data to make like on the flight so if you've been a long-standing customer then we can definitely you know",
    "start": "2178870",
    "end": "2186220"
  },
  {
    "text": "do something extra we try to go to mile the extra mile for every customer but go the extra extra mile if you've been a",
    "start": "2186220",
    "end": "2192430"
  },
  {
    "text": "longer customer another example is marketing cyber monday was the biggest day of the year for us we get 10x or",
    "start": "2192430",
    "end": "2199000"
  },
  {
    "text": "normal traffic and they they're making inter our decisions to buy or sell they",
    "start": "2199000",
    "end": "2204280"
  },
  {
    "text": "have their their agency on the call on the phone with them and based off the the data pipeline giving them real-time",
    "start": "2204280",
    "end": "2211270"
  },
  {
    "text": "views of how much each keyword they're bidding on is driving traffic to each product category they're making like",
    "start": "2211270",
    "end": "2217420"
  },
  {
    "text": "calls like you know I want to buy buy buy on flamingo shirts because they want to keep feeding that pipeline of",
    "start": "2217420",
    "end": "2224620"
  },
  {
    "text": "advertising that they're purchasing yeah and maybe you could talk a little bit more about that in terms of cyber monday",
    "start": "2224620",
    "end": "2229930"
  },
  {
    "text": "like what was the request volume looking like like what sort of latency were you trying to guarantee you just I have a",
    "start": "2229930",
    "end": "2234940"
  },
  {
    "text": "sense sure so normally we're looking at like 2 to 3 million per day but ok 10x that on Cyber Monday in every dimension",
    "start": "2234940",
    "end": "2241440"
  },
  {
    "text": "so in 2 to 3 million that's like sales or oh no I wish two to three million",
    "start": "2241440",
    "end": "2248430"
  },
  {
    "text": "requests okay basically you could look at it as discreet inquiries of customer",
    "start": "2248430",
    "end": "2256000"
  },
  {
    "start": "2251000",
    "end": "2303000"
  },
  {
    "text": "interactions to our pipeline gotcha and in terms of the latency on that are you trying to get decisions like hourly",
    "start": "2256000",
    "end": "2262810"
  },
  {
    "text": "daily sub second so the way that we started let's say a year ago was the",
    "start": "2262810",
    "end": "2269200"
  },
  {
    "text": "classic batch you know I'm gonna process this data overnight and people are gonna consume it in the morning and now we are",
    "start": "2269200",
    "end": "2274300"
  },
  {
    "text": "very much moving towards a stream all the things architecture as you saw from the from the diagram and that actually",
    "start": "2274300",
    "end": "2280630"
  },
  {
    "text": "has driven a lot of intra our decisions especially on traffic heavy days because our marketing team as well as other",
    "start": "2280630",
    "end": "2288070"
  },
  {
    "text": "teams have actual lovers they can pull based off of the more updated data and also an understanding of who the",
    "start": "2288070",
    "end": "2294310"
  },
  {
    "text": "customer is yeah can you give me an example is it only ad spend where it's the kind of thing where it matter like hours matter or their other like",
    "start": "2294310",
    "end": "2301480"
  },
  {
    "text": "examples were so it's been it's definitely one thing and it's a big growth lever for us so it comes to mind",
    "start": "2301480",
    "end": "2307000"
  },
  {
    "start": "2303000",
    "end": "2448000"
  },
  {
    "text": "but in our retail stores as well being able to have an understanding we have about 60 retail stores and it's very",
    "start": "2307000",
    "end": "2314830"
  },
  {
    "text": "tactical for the retail but being able to understand and what's driving people to our site as well as",
    "start": "2314830",
    "end": "2320500"
  },
  {
    "text": "what's going on can help very small decisions but don't seem to be that important but actually are when you",
    "start": "2320500",
    "end": "2326260"
  },
  {
    "text": "think about the retail experience for example do we we're running out of inventory for a certain type of clothing",
    "start": "2326260",
    "end": "2332290"
  },
  {
    "text": "did we take it out of the window and put something else there that that type of stuff seems small but it's cumulative",
    "start": "2332290",
    "end": "2337660"
  },
  {
    "text": "adds up over time for the decisions that the retail store store managers make yeah I know so your retail stores are a",
    "start": "2337660",
    "end": "2345490"
  },
  {
    "text": "little bit different than a normal retail store right that's a good that's a good call out something worth mentioning so our retail stores are",
    "start": "2345490",
    "end": "2352090"
  },
  {
    "text": "interesting because you walk in there and you get fitted because we want to use it as a vehicle to create the",
    "start": "2352090",
    "end": "2357700"
  },
  {
    "text": "concept of fit and you don't walk out with anything because we don't have any inventory there so we use it almost as a",
    "start": "2357700",
    "end": "2363610"
  },
  {
    "text": "showroom to say that here you get fitted you can check out all of our different clothing and we use that data it's very",
    "start": "2363610",
    "end": "2370960"
  },
  {
    "text": "important data from a point-of-sale standpoint to say that this person tried on this or that and what patterns were",
    "start": "2370960",
    "end": "2376570"
  },
  {
    "text": "they interested in and can we use that into as feedback into future models I see is the like salesperson or customer",
    "start": "2376570",
    "end": "2383590"
  },
  {
    "text": "service rep like writing all those things down and recording them somewhere or is it it's being captured from from",
    "start": "2383590",
    "end": "2389650"
  },
  {
    "text": "like the iPad point-of-sale ok application that we're using nice cool and she's also firing the meta segment",
    "start": "2389650",
    "end": "2396820"
  },
  {
    "text": "events to oh to capture that and feed it into the pipeline because what becomes really powerful is when you take those",
    "start": "2396820",
    "end": "2402520"
  },
  {
    "text": "events and you marry them with our click stream and then get a real omni-channel",
    "start": "2402520",
    "end": "2407770"
  },
  {
    "text": "look at the business instead of the classic this is what happened in retail stores the way that things actually happen it's more like you know",
    "start": "2407770",
    "end": "2413560"
  },
  {
    "text": "especially if you're gonna make a thousand dollar purchase as a suit or thousand dollars or less you're gonna go",
    "start": "2413560",
    "end": "2418900"
  },
  {
    "text": "to the store and then you're gonna go online and being able to identify those people is really helpful for different people in the business makes sense so",
    "start": "2418900",
    "end": "2426520"
  },
  {
    "text": "I'm kind of an amateur analyst I would say I'm curious yeah well I'm sure less",
    "start": "2426520",
    "end": "2432670"
  },
  {
    "text": "amateur than me I'm curious you'll walk me through maybe a day in the life of either an analyst or a data scientist like what are they",
    "start": "2432670",
    "end": "2439390"
  },
  {
    "text": "looking at and then how do they actually arrive at either insights or like stuff that makes it then back into the product",
    "start": "2439390",
    "end": "2445570"
  },
  {
    "text": "or changes the business in some way sure so let's let's give a couple samples so for me just philosophically I",
    "start": "2445570",
    "end": "2452860"
  },
  {
    "start": "2448000",
    "end": "2490000"
  },
  {
    "text": "think the role of analyst is is shifting a bit where traditionally you might be like a marketing analyst and you do",
    "start": "2452860",
    "end": "2458470"
  },
  {
    "text": "marketing stuff but so it's talking about the customer journey is becoming something that you can now interlink and really what you put marketing dollars in",
    "start": "2458470",
    "end": "2465520"
  },
  {
    "text": "its gonna influence your products so you really want to look at it holistically and analysts where product is insight",
    "start": "2465520",
    "end": "2471580"
  },
  {
    "text": "right so as the complexity and granularity of data increases analysts",
    "start": "2471580",
    "end": "2476950"
  },
  {
    "text": "work kind of becomes dispersed as roles across a team and so let's get into a",
    "start": "2476950",
    "end": "2482410"
  },
  {
    "text": "couple examples as to what I'm talking about there you saw some of the stuff that we built out with personalization and in order to even build propensity",
    "start": "2482410",
    "end": "2489250"
  },
  {
    "text": "which is predicting that someone's gonna convert that requires a ton of analysis of looking at people's paths across our",
    "start": "2489250",
    "end": "2495940"
  },
  {
    "start": "2490000",
    "end": "2639000"
  },
  {
    "text": "site to identify one or people actually confused in developing lots of hypotheses so analysts and data",
    "start": "2495940",
    "end": "2501550"
  },
  {
    "text": "scientists are working together because analysts are the folks who are actually building out the things that become",
    "start": "2501550",
    "end": "2507040"
  },
  {
    "text": "features in our data for example identifying that this marketing channel generates more or a high higher or lower",
    "start": "2507040",
    "end": "2514210"
  },
  {
    "text": "quality traffic and that should therefore be separated out into certain features of the machine learning model",
    "start": "2514210",
    "end": "2519850"
  },
  {
    "text": "that the data scientist is gonna put into production another example is analysts are working",
    "start": "2519850",
    "end": "2525370"
  },
  {
    "text": "to sort of be like a Switzerland type role where marketing might be putting certain ads that are and this is",
    "start": "2525370",
    "end": "2531910"
  },
  {
    "text": "actually happening as mobile is becoming more important a lot of marketing ad spend is driving mobile traffic a",
    "start": "2531910",
    "end": "2537550"
  },
  {
    "text": "product just built a feature called unified carts where if you add something to your mobile web experience it'll",
    "start": "2537550",
    "end": "2542650"
  },
  {
    "text": "propagate across the desktop and and the question is what's driving mobile",
    "start": "2542650",
    "end": "2548770"
  },
  {
    "text": "traffic is it unified card experience or is it is it marketing dollars going to",
    "start": "2548770",
    "end": "2555340"
  },
  {
    "text": "mobile so analysts have to kind of find the signal through all that noise and develop a recommendation that the",
    "start": "2555340",
    "end": "2562090"
  },
  {
    "text": "business can move forward on yeah can you find out the answer which it was it's you know it yes but you're not",
    "start": "2562090",
    "end": "2568900"
  },
  {
    "text": "gonna like it it's just the answer is usually is something online so there are",
    "start": "2568900",
    "end": "2574450"
  },
  {
    "text": "certain things that are working and there are certain things that are working from from both ends there's no there's no smoking gun you know so you",
    "start": "2574450",
    "end": "2580930"
  },
  {
    "text": "can't really everyone wants to know how much value something drove but it's often very difficult to say that it was this",
    "start": "2580930",
    "end": "2588069"
  },
  {
    "text": "much without testing and no one has the patience for tests to insignificance generally speaking so it's hard yeah so",
    "start": "2588069",
    "end": "2597160"
  },
  {
    "text": "one other question I have that I want to ask you about I feel like a number of our customers fall and serve the spiritual divide where some of them say",
    "start": "2597160",
    "end": "2603849"
  },
  {
    "text": "like oh just collect all the data will eventually Queen it up and figure it out",
    "start": "2603849",
    "end": "2609490"
  },
  {
    "text": "and so just put it in a data like on s3 and we'll get to it later and then other customers are all about having really",
    "start": "2609490",
    "end": "2615880"
  },
  {
    "text": "clean data where they've like meticulously figured out the schema and understand here's what this data point",
    "start": "2615880",
    "end": "2621099"
  },
  {
    "text": "means here's when it's collected an application flow I have a strong sense of every property that should be associated with it",
    "start": "2621099",
    "end": "2626920"
  },
  {
    "text": "I was curious for your take do you like fall more in the data like camp or the ETL camp",
    "start": "2626920",
    "end": "2632310"
  },
  {
    "text": "yeah strong opinions there so I definitely agree with always put in s3",
    "start": "2632310",
    "end": "2637450"
  },
  {
    "text": "is a great rule I'll also say that like a lot of the tooling this segment",
    "start": "2637450",
    "end": "2642970"
  },
  {
    "text": "provides and what AWS provides makes it very easy to end up in a situation which is not a bad situation that all your",
    "start": "2642970",
    "end": "2648339"
  },
  {
    "text": "data is in redshift let's say and the",
    "start": "2648339",
    "end": "2653380"
  },
  {
    "text": "thing is to be careful there is just trying to figure out the problem you want to solve so let's say that you want",
    "start": "2653380",
    "end": "2659290"
  },
  {
    "text": "to understand your clickstream you could do all that processing in on redshift but it's not let's say the most elegant",
    "start": "2659290",
    "end": "2665470"
  },
  {
    "text": "solution versus abstracting that out into something like Kinesis and then using EMR what's SPARC to process the",
    "start": "2665470",
    "end": "2672430"
  },
  {
    "text": "clickstream and then dumping the results of that or loading the results of that into redshift so I think that it just",
    "start": "2672430",
    "end": "2677650"
  },
  {
    "text": "depends on where you are with the maturity curve but the way I see things evolving is that we're going to reach a",
    "start": "2677650",
    "end": "2684040"
  },
  {
    "text": "place where people want to be as low latency as possible and they want to be at a place where they're using the right",
    "start": "2684040",
    "end": "2689980"
  },
  {
    "text": "tool for the job that's probably gonna result in infrastructure that's more data lake-like versus your traditional",
    "start": "2689980",
    "end": "2696010"
  },
  {
    "text": "batch process overnight into redshift and use that I see so then for that data",
    "start": "2696010",
    "end": "2701410"
  },
  {
    "text": "like I'm curious like how do you manage schema for instance like how do you make sure that bad data doesn't end up in",
    "start": "2701410",
    "end": "2706569"
  },
  {
    "text": "there somehow and just throws off your entire analysis that's good questions so",
    "start": "2706569",
    "end": "2711990"
  },
  {
    "start": "2710000",
    "end": "2805000"
  },
  {
    "text": "bad data is this a good O'Reilly book called a good data bad deed and how to clean it all up yeah which is",
    "start": "2711990",
    "end": "2718790"
  },
  {
    "text": "helpful to help me think about this so bad data often comes up I guess we're",
    "start": "2718790",
    "end": "2725270"
  },
  {
    "text": "trying to say is there's there's gonna be unknown unknowns about bad data so you have to work with what you have and",
    "start": "2725270",
    "end": "2730760"
  },
  {
    "text": "that often comes from the business finding out after the fact and so you I try to look at it as it should be as",
    "start": "2730760",
    "end": "2736370"
  },
  {
    "text": "easy as possible to clean up the data and restate things as he figured things out that are wrong and that's",
    "start": "2736370",
    "end": "2742370"
  },
  {
    "text": "facilitated by having the right tools so for example processing the click screen would spark makes it much easier for us",
    "start": "2742370",
    "end": "2748700"
  },
  {
    "text": "to iterate and clean up data as we identify as being wrong versus having it all in redshift and having to reload all",
    "start": "2748700",
    "end": "2754820"
  },
  {
    "text": "the things because he figured out that you're a be testing tool Optimizely was generating garbage sessions and that",
    "start": "2754820",
    "end": "2760610"
  },
  {
    "text": "your conversion rate you know might be actually higher than you thought it was just because the traffic counts were off",
    "start": "2760610",
    "end": "2765980"
  },
  {
    "text": "from bad data being generated which was actually something that happened so what's up what's important there is just",
    "start": "2765980",
    "end": "2771650"
  },
  {
    "text": "to have the right architecture to move forward with the new insight and and",
    "start": "2771650",
    "end": "2776660"
  },
  {
    "text": "also document that in a place where everyone understands why the data was bad I see and so let's say for example",
    "start": "2776660",
    "end": "2783470"
  },
  {
    "text": "your Android app has an event which is order completed when it should be completed order like do you store that",
    "start": "2783470",
    "end": "2790460"
  },
  {
    "text": "mapping somewhere is that in code or is that like in queries that everyone is using together or like do you repaint",
    "start": "2790460",
    "end": "2797510"
  },
  {
    "text": "the data right yeah I understand your question exactly we it's in code so there's a processing layer let me see if",
    "start": "2797510",
    "end": "2805010"
  },
  {
    "start": "2805000",
    "end": "2979000"
  },
  {
    "text": "I can go back a bit here so within this",
    "start": "2805010",
    "end": "2810700"
  },
  {
    "text": "oops within this infrastructure right here",
    "start": "2810700",
    "end": "2817840"
  },
  {
    "text": "this journey processing layer is what actually cleanses the data and we",
    "start": "2817840",
    "end": "2824290"
  },
  {
    "text": "implement rules that filter out certain data and it's as simple or naive it's just like a where clause in the sparks",
    "start": "2824290",
    "end": "2831410"
  },
  {
    "text": "equal to say that can filter this out because the Android thing was as you said it was and that's bad",
    "start": "2831410",
    "end": "2837500"
  },
  {
    "text": "and then yeah things are commented and that way people downstream queries aren't affected by the bad data I see I",
    "start": "2837500",
    "end": "2843140"
  },
  {
    "text": "seen those queries get really big though huh it's like you're having a bunch of these changes that you're making just",
    "start": "2843140",
    "end": "2848240"
  },
  {
    "text": "sort of historically over time maybe you're trying to run analysis every years or something oh you mean the cleansing queries yeah",
    "start": "2848240",
    "end": "2854630"
  },
  {
    "text": "yeah do they do like that see it's gonna call out and I'd love to learn even like a better way to handle it but it just",
    "start": "2854630",
    "end": "2860780"
  },
  {
    "text": "it's interesting because data is this weird layer between the people building the website yeah and the people trying",
    "start": "2860780",
    "end": "2866990"
  },
  {
    "text": "to understand what happened on the website and cleaning it up and maintaining something that's robust",
    "start": "2866990",
    "end": "2872210"
  },
  {
    "text": "while at the same time fulfilling the other wishes around low latency just",
    "start": "2872210",
    "end": "2877580"
  },
  {
    "text": "requires this ability to propagate business logic and clean up logic through your codebase yeah I know what a",
    "start": "2877580",
    "end": "2885050"
  },
  {
    "text": "bunch of our customers do is they have like Google spreadsheet somewhere where they like keep track of which revenge",
    "start": "2885050",
    "end": "2890180"
  },
  {
    "text": "they're sending and like what those should mean we saw this pattern enough times that we just eventually built a product to solve this problem which is",
    "start": "2890180",
    "end": "2897020"
  },
  {
    "text": "our new protocols product but I don't know if you handle something similar yeah so we also have our Google spreadsheet so and I was quite",
    "start": "2897020",
    "end": "2903950"
  },
  {
    "text": "interested in protocols product because the problem here is that we let's say to bring back the revenue tracking issue",
    "start": "2903950",
    "end": "2910030"
  },
  {
    "text": "that I mentioned or hinted at earlier what happened there was just we accidentally made a code change that",
    "start": "2910030",
    "end": "2916430"
  },
  {
    "text": "caused revenue to be calculated as gross instead of net of discounts so it looked like we were let's say making more money",
    "start": "2916430",
    "end": "2921800"
  },
  {
    "text": "than we were the part of the issue there was just that we managed everything via",
    "start": "2921800",
    "end": "2926930"
  },
  {
    "text": "a Google spreadsheet of each each event that we're generating and what the canonical metadata should be so it can",
    "start": "2926930",
    "end": "2933710"
  },
  {
    "text": "be challenging to unless you have like the alerting and monitoring that we built out to know that something went wrong",
    "start": "2933710",
    "end": "2939050"
  },
  {
    "text": "yeah and so something that protocols is interesting because it's at that it's at the layer of implementation that you can start tracking that yeah exactly",
    "start": "2939050",
    "end": "2945590"
  },
  {
    "text": "right we're actually building a spreadsheet importer so that people can easily migrate because we can see it",
    "start": "2945590",
    "end": "2951230"
  },
  {
    "text": "happening so much cool I wanted to know a little bit more about what you're",
    "start": "2951230",
    "end": "2956900"
  },
  {
    "text": "doing with ml particularly for personalization I know you showed kind of the like fit use case where you say",
    "start": "2956900",
    "end": "2962450"
  },
  {
    "text": "hey based upon what's in your cart let's suggest new items that would fit with",
    "start": "2962450",
    "end": "2967670"
  },
  {
    "text": "this outfit Greer's are there other things that you're doing to personalize the way bonobos comm looks and feels or",
    "start": "2967670",
    "end": "2975170"
  },
  {
    "text": "your mobile apps sure so I'm gonna just fast-forward to this diagram here where",
    "start": "2975170",
    "end": "2981770"
  },
  {
    "start": "2979000",
    "end": "3039000"
  },
  {
    "text": "we have this thing Chelsea and I think that answering your question because requires talking about",
    "start": "2981770",
    "end": "2987320"
  },
  {
    "text": "the way that we operate in terms of building out and in partnering with",
    "start": "2987320",
    "end": "2992380"
  },
  {
    "text": "product engineering or building out experiences so our mission is to create the most robust and accurate model",
    "start": "2992380",
    "end": "2998630"
  },
  {
    "text": "possible so let's say we build out personalization when you have a big matrix of user attributes and we have a",
    "start": "2998630",
    "end": "3004599"
  },
  {
    "text": "big matrix of products and we want to align those two and create a machine learning model that is most accurate of",
    "start": "3004599",
    "end": "3010180"
  },
  {
    "text": "aligning the two and then from there expose it in an end point that product engineering can query from and then",
    "start": "3010180",
    "end": "3016480"
  },
  {
    "text": "let's say build something on the website or build something in guide shops it could be for example the iPads that",
    "start": "3016480",
    "end": "3021670"
  },
  {
    "text": "guides use can we show what outfits that they should help people try on based off",
    "start": "3021670",
    "end": "3026740"
  },
  {
    "text": "who someone is we just want to create an updated and robust output that they can use to build out experiences across",
    "start": "3026740",
    "end": "3032650"
  },
  {
    "text": "whatever platform it that that they feel is best for the user experience in Bekaa",
    "start": "3032650",
    "end": "3039339"
  },
  {
    "start": "3039000",
    "end": "3184000"
  },
  {
    "text": "manifests in a variety of ways yeah cool in terms of monitoring sort of the",
    "start": "3039339",
    "end": "3044589"
  },
  {
    "text": "overall pipeline and I know a bunch of customers ours they have sort of this like sneaking internal data pipeline",
    "start": "3044589",
    "end": "3052570"
  },
  {
    "text": "that they built out and maybe one part off to the side will break but it will",
    "start": "3052570",
    "end": "3057580"
  },
  {
    "text": "break some critical business workflow and kind of know and will notice because the data ends team is working on a bunch of different pieces like does that sound",
    "start": "3057580",
    "end": "3064660"
  },
  {
    "text": "familiar at all or how do you monitor all the pieces of this system make sure it data's not delayed and it doesn't flatline or oh yeah that sounds very",
    "start": "3064660",
    "end": "3071650"
  },
  {
    "text": "familiar yes I think it's just about how you mitigate it because this is a system like in any in any system you need to",
    "start": "3071650",
    "end": "3077440"
  },
  {
    "text": "have things will break and you need to know one that something broke and then to have a call tree or some means of",
    "start": "3077440",
    "end": "3083050"
  },
  {
    "text": "establishing expectations with people who depended on it on the data to do their jobs and so the way that we've",
    "start": "3083050",
    "end": "3088780"
  },
  {
    "text": "handled that is we have a call tree for data and we have different SLA s so we",
    "start": "3088780",
    "end": "3094089"
  },
  {
    "text": "have a hey this is something that's affecting our ability to understand how much money we're making and so it needs",
    "start": "3094089",
    "end": "3099400"
  },
  {
    "text": "to be fixed right away and then other things we have 2472 our SLA x' to identify and fix the thing that broke",
    "start": "3099400",
    "end": "3105849"
  },
  {
    "text": "yeah can you get an example of what are the things like in each of those categories I get the first one is how",
    "start": "3105849",
    "end": "3110920"
  },
  {
    "text": "much money you're making but like what about like 24 hours or 72 hours sure so 24 hours would be something that",
    "start": "3110920",
    "end": "3115930"
  },
  {
    "text": "I collect a marketing law because for most PTC companies they are the the folks driving the growth engine so a lot",
    "start": "3115930",
    "end": "3122500"
  },
  {
    "text": "of the business is centered around ensuring that they can make those decisions that drive growth as",
    "start": "3122500",
    "end": "3128140"
  },
  {
    "text": "effectively as possible and so if something that something breaks let's say between a major spent channel for us",
    "start": "3128140",
    "end": "3134560"
  },
  {
    "text": "which would be let's say Google paid search ads because that's where a lot of we find a lot of folks looking for",
    "start": "3134560",
    "end": "3140560"
  },
  {
    "text": "clothing is someone searched for for chinos or for where can I buy a suit and we pop up so being able to fix that",
    "start": "3140560",
    "end": "3149200"
  },
  {
    "text": "within 24 hours because it's not something that needs be fixed overnight but it's something that if we don't fix",
    "start": "3149200",
    "end": "3154300"
  },
  {
    "text": "it I can look at our CPA for the previous day and tell you exactly how much opportunity cost there is I say and",
    "start": "3154300",
    "end": "3161440"
  },
  {
    "text": "so fixing that within the next day it's generally ideal and then for 72 hours they'd be more like let's say something",
    "start": "3161440",
    "end": "3168340"
  },
  {
    "text": "that isn't mission-critical but still important a lot of that would be around inventory data things affecting CX so it",
    "start": "3168340",
    "end": "3175030"
  },
  {
    "text": "would in fact individual customers or their ability to help individual customers but not scale to the business",
    "start": "3175030",
    "end": "3180700"
  },
  {
    "text": "so we want to fix it generally within the week but not immediately hmm so I have a couple last questions here before",
    "start": "3180700",
    "end": "3186640"
  },
  {
    "text": "we turn it over to audience questions in terms of your machine learning pipelines",
    "start": "3186640",
    "end": "3192210"
  },
  {
    "text": "is there a single like feature or set of features where you can look at a user and say like based upon this attribute",
    "start": "3192210",
    "end": "3198910"
  },
  {
    "text": "they will be a good but no bus user like what's most important so that's it's a",
    "start": "3198910",
    "end": "3206470"
  },
  {
    "text": "great question and that that's that's like the million dollar question probably literally but we've looked at",
    "start": "3206470",
    "end": "3212650"
  },
  {
    "text": "our we've done a segmentation of our customer base and we find that most of our revenue comes from about a third of",
    "start": "3212650",
    "end": "3218770"
  },
  {
    "text": "our users right so how do you identify that one and three-time of customer and what's been helpful there has been a lot",
    "start": "3218770",
    "end": "3225880"
  },
  {
    "text": "of understanding what people are who people are using third-party data to understand that you know different",
    "start": "3225880",
    "end": "3231700"
  },
  {
    "text": "occupations and then based off of that modeling user behavior against that data",
    "start": "3231700",
    "end": "3237190"
  },
  {
    "text": "to then identify that this person based off of the behaviors and product",
    "start": "3237190",
    "end": "3242230"
  },
  {
    "text": "categories they're looking at things like that looks small faint signals can we cue middle D identify that someone is",
    "start": "3242230",
    "end": "3247510"
  },
  {
    "text": "is going to be one of those one three we actually have a predictive CLD model that that helps",
    "start": "3247510",
    "end": "3253540"
  },
  {
    "text": "with this and it's used for actually again doctor marketing because if you can identify those you want to look at",
    "start": "3253540",
    "end": "3258910"
  },
  {
    "text": "marketing channels they came from and sensibly invest more there because there's hopefully more people that are",
    "start": "3258910",
    "end": "3264490"
  },
  {
    "text": "like that and I think your question hindered a machine learning right so the",
    "start": "3264490",
    "end": "3269980"
  },
  {
    "text": "features that drive that and so a lot of unsupervised learning to get at the latent variables which we can then",
    "start": "3269980",
    "end": "3275980"
  },
  {
    "text": "engineer into features and and then build into this predictive Cle model but it's an ongoing process gotcha",
    "start": "3275980",
    "end": "3282460"
  },
  {
    "text": "okay are there like particulars which you would say like oh there's no way this is correlated and then like",
    "start": "3282460",
    "end": "3288670"
  },
  {
    "text": "suddenly this model spat out like oh it turns out that a know people from Arkansas like between 25 and 30 who are",
    "start": "3288670",
    "end": "3297100"
  },
  {
    "text": "employed at Walmart you know or like wherever it is like they are really good bonobos users like what was the most",
    "start": "3297100",
    "end": "3302440"
  },
  {
    "text": "surprising thing mmm interesting most surprising would be probably just",
    "start": "3302440",
    "end": "3309070"
  },
  {
    "text": "looking at I guess surprising but isn't the right word it interesting is so I'm gonna sub that out okay it's it's just",
    "start": "3309070",
    "end": "3315660"
  },
  {
    "text": "understanding that machine like successful machine learning requires combining all these features so let's",
    "start": "3315660",
    "end": "3321100"
  },
  {
    "text": "say you're in Miami that's where it's not surprising you need why I said it out loud now but the that's where we",
    "start": "3321100",
    "end": "3327130"
  },
  {
    "text": "sell most of our swimwear as well as like flamingo shirts and then in",
    "start": "3327130",
    "end": "3333040"
  },
  {
    "text": "Nebraska we sell a lot of just black suits I don't know why that is but it's true you know in identifying that there are",
    "start": "3333040",
    "end": "3339550"
  },
  {
    "text": "certain let's call them personas which which correlate with these features and there are certain let's say Geographic",
    "start": "3339550",
    "end": "3344920"
  },
  {
    "text": "or maybe the geography is is not granular enough but it's it's a lagging",
    "start": "3344920",
    "end": "3350380"
  },
  {
    "text": "indication of something about people who live there that we can understand preferences or affinities for certain",
    "start": "3350380",
    "end": "3355960"
  },
  {
    "text": "product categories and then being able to translate that into CLD and you what",
    "start": "3355960",
    "end": "3361090"
  },
  {
    "text": "you realize is that you you have to be very nuanced about how you drill into things because an aggregate things",
    "start": "3361090",
    "end": "3367210"
  },
  {
    "text": "aren't generally as as helpful or meaningful but when you start looking and cutting the data and across the",
    "start": "3367210",
    "end": "3372370"
  },
  {
    "text": "right ways that's what machine learning becomes really powerful yeah I'm here how many of those personas would you say you have now we have somewhere between",
    "start": "3372370",
    "end": "3378750"
  },
  {
    "start": "3374000",
    "end": "3474000"
  },
  {
    "text": "12 and 20 depending on who you ask yeah gotcha yeah cuz I feel like maybe",
    "start": "3378750",
    "end": "3385039"
  },
  {
    "text": "10 years ago basically someone's running analytics and like coming up with maybe two or three personas that match their",
    "start": "3385039",
    "end": "3391230"
  },
  {
    "text": "different buyers but kind of as you take this trend of just running machine learning models against the data you",
    "start": "3391230",
    "end": "3397020"
  },
  {
    "text": "already have it's like almost you could get kind of a perfect persona for each individual user based upon all of these",
    "start": "3397020",
    "end": "3403170"
  },
  {
    "text": "different traits so just a couple thoughts on that what's interesting or what can make things difficult is just",
    "start": "3403170",
    "end": "3408900"
  },
  {
    "text": "that the the way that people might dress for work is more conservative versus at home so we have to create this",
    "start": "3408900",
    "end": "3414839"
  },
  {
    "text": "identifier because we see people in Nebraska buying Flamengo shirts but then we also see them buying black suits and",
    "start": "3414839",
    "end": "3420150"
  },
  {
    "text": "it's because they're like imagine wearing one thing to work one thing on the weekend and being able to create",
    "start": "3420150",
    "end": "3425849"
  },
  {
    "text": "that as an entity is tough but it's a fun challenge another thought is just",
    "start": "3425849",
    "end": "3432809"
  },
  {
    "text": "that we have identified certain personas based off of you know I think your original question was what's the most",
    "start": "3432809",
    "end": "3438329"
  },
  {
    "text": "predictive and I think that that has to do with occupation and then there's an entire problem around identifying that because I know that jeans and t-shirts",
    "start": "3438329",
    "end": "3446450"
  },
  {
    "text": "correlate very strongly around Silicon Valley as well as what they're called in the Silicon Alley in New York City I",
    "start": "3446450",
    "end": "3452460"
  },
  {
    "text": "don't know that's actually thing though but also I see a lot of bankers who just",
    "start": "3452460",
    "end": "3459059"
  },
  {
    "text": "buy suits and then you see other personas especially in the south of a lot of like seersucker very classic",
    "start": "3459059",
    "end": "3465569"
  },
  {
    "text": "American kind of clothing developing and and just identifying that and creating the personas and the recommendations",
    "start": "3465569",
    "end": "3472500"
  },
  {
    "text": "tailored to the personas cool all right well I think we'll end it there anyone",
    "start": "3472500",
    "end": "3479250"
  },
  {
    "start": "3474000",
    "end": "3600000"
  },
  {
    "text": "in the audience have some quick questions before we wrap up here",
    "start": "3479250",
    "end": "3483650"
  },
  {
    "text": "if you can hear me I was asking about that pricing with the dynamic pricing",
    "start": "3490390",
    "end": "3496730"
  },
  {
    "text": "you said 20 percent offer 10 percent offer based on the person is that a real time function and theirs so how do you I",
    "start": "3496730",
    "end": "3503180"
  },
  {
    "text": "know an Amazon did that they had a lot of resistance right because one person see a different price and the other all the Expedia and those companies like",
    "start": "3503180",
    "end": "3511250"
  },
  {
    "text": "Airlines have gotten better acceptance with that I work for Eddie Bauer and you know we'd be real hesitant to to send",
    "start": "3511250",
    "end": "3518420"
  },
  {
    "text": "that dynamic pricing model out have you seen success with it and acceptance with that concept or sure how do you do that",
    "start": "3518420",
    "end": "3525950"
  },
  {
    "text": "we've done it through like email or other more segmented but when you put it on the web it's a different experience",
    "start": "3525950",
    "end": "3532120"
  },
  {
    "text": "it's a totally fair question so we actually agree with you I think that dynamic pricing can very adversely",
    "start": "3532120",
    "end": "3539660"
  },
  {
    "text": "affect the user experience and so the way that we approach that is more allow along the idea of offering a targeted",
    "start": "3539660",
    "end": "3546500"
  },
  {
    "text": "discount so prices won't change on our site but via email and via our site",
    "start": "3546500",
    "end": "3551870"
  },
  {
    "text": "itself we we can predict that you're there and just needs something like an",
    "start": "3551870",
    "end": "3557360"
  },
  {
    "text": "extra intervention we might offer let's say 20% off you know but we look at that as as as a model it's really no",
    "start": "3557360",
    "end": "3564200"
  },
  {
    "text": "different than if you were to call into our company and talk to one of our ninjas they'll they'll say okay well",
    "start": "3564200",
    "end": "3569450"
  },
  {
    "text": "like you know if it helps you get to the door is take 20% off so we look at it as",
    "start": "3569450",
    "end": "3575060"
  },
  {
    "text": "something that will help people get across the finish line of the transaction but not so much as hey we're gonna test this and it's gonna be $30",
    "start": "3575060",
    "end": "3581660"
  },
  {
    "text": "for you and then $40 you know if you went on it caught in cognitive oh cool",
    "start": "3581660",
    "end": "3591339"
  },
  {
    "text": "just two quick questions one is how do you use your platform to you know launch",
    "start": "3592830",
    "end": "3598660"
  },
  {
    "text": "a new product or delete an existing product I guess the second question is you know when it comes to pricing or",
    "start": "3598660",
    "end": "3604750"
  },
  {
    "text": "discounts Madhu rely on inventory you said you do you factor inventory into",
    "start": "3604750",
    "end": "3610630"
  },
  {
    "text": "your sort of overall you know filtering process what was the first question one",
    "start": "3610630",
    "end": "3617740"
  },
  {
    "text": "more time so adding or deleting products",
    "start": "3617740",
    "end": "3624340"
  },
  {
    "text": "is maintained via our it's not in the",
    "start": "3624340",
    "end": "3630340"
  },
  {
    "text": "art diagram but we have a means of just being able to go into the the product",
    "start": "3630340",
    "end": "3636370"
  },
  {
    "text": "feeds that are feeding into the data and just remove things and that's a good question because I think it ties into",
    "start": "3636370",
    "end": "3641650"
  },
  {
    "text": "your second question inventory because if things sell out quickly which can happen for and does it happen quite",
    "start": "3641650",
    "end": "3647410"
  },
  {
    "text": "often for certain products which become very popular that we didn't expect we need to be able to remove that from the",
    "start": "3647410",
    "end": "3652960"
  },
  {
    "text": "product feed and when things do go out of stock we we absolutely take that into consideration and it drives a lot of",
    "start": "3652960",
    "end": "3658990"
  },
  {
    "text": "that let's say cyber money buying decisions which is if people are buying lots of flamingo's shirts and we run out",
    "start": "3658990",
    "end": "3664660"
  },
  {
    "text": "of supply for those we need to have a real-time means of being able to inform that into the models which marketing are",
    "start": "3664660",
    "end": "3671800"
  },
  {
    "text": "using to invest in other shirts that we do have greater quantities of and the",
    "start": "3671800",
    "end": "3677650"
  },
  {
    "text": "way that we do that is actually again not in the arc diagram but we have through our third-party logistics provider we have a Kinesis tree and",
    "start": "3677650",
    "end": "3684250"
  },
  {
    "text": "feeding in a queue of inventory data and how much we have available to ship out",
    "start": "3684250",
    "end": "3689950"
  },
  {
    "text": "the customers",
    "start": "3689950",
    "end": "3692460"
  },
  {
    "text": "how does your recommendation engine work on new customers that let's say you",
    "start": "3696530",
    "end": "3701970"
  },
  {
    "text": "don't know their style they haven't added anything to their car or only have visited minimal product pages that's a",
    "start": "3701970",
    "end": "3709920"
  },
  {
    "text": "great question and actually I think this I think telephone was talking about about the idea of personas I think I mentioned that there's 12 to 20 kind of",
    "start": "3709920",
    "end": "3716370"
  },
  {
    "text": "base personas that we have and so as a new customer the amount of signals that were collecting from you are you know",
    "start": "3716370",
    "end": "3722190"
  },
  {
    "text": "not that many but what we can do is at least look one of three let's say",
    "start": "3722190",
    "end": "3727470"
  },
  {
    "text": "default can default outfits that you might want or will be interested in and then use that until more data becomes",
    "start": "3727470",
    "end": "3733590"
  },
  {
    "text": "available cool I think we've got to ended there for time but we'll be off to",
    "start": "3733590",
    "end": "3740670"
  },
  {
    "text": "the side afterwards if anyone wants to come up so yeah thank you Annika thank you James and please do complete the session",
    "start": "3740670",
    "end": "3750930"
  },
  {
    "text": "survey yes",
    "start": "3750930",
    "end": "3753740"
  }
]
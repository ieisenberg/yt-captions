[
  {
    "start": "0",
    "end": "84000"
  },
  {
    "text": "all right ready alright good morning and",
    "start": "3319",
    "end": "8550"
  },
  {
    "text": "thank you for your time at this session is WPS 3:05 how Fannie Mae processes",
    "start": "8550",
    "end": "15360"
  },
  {
    "text": "over a quarter million loads a day using Amazon s3",
    "start": "15360",
    "end": "20449"
  },
  {
    "text": "my name is harsh and upon II I'm a senior Solutions Architect at AWS and with me on stage is Oliver",
    "start": "20449",
    "end": "27720"
  },
  {
    "text": "Matthias is a senior architect at fannie mae and who led the transformation",
    "start": "27720",
    "end": "33750"
  },
  {
    "text": "journey for a mission-critical a fat Fanny the agenda for this session there",
    "start": "33750",
    "end": "42570"
  },
  {
    "text": "are three categories three segments of the presentation the first segment is I'm going to walk you through a three",
    "start": "42570",
    "end": "49170"
  },
  {
    "text": "best practices and some of the performance tips in terms of architecting around the s3 as your",
    "start": "49170",
    "end": "54690"
  },
  {
    "text": "primary storage layer in the second segment Oliver will walk you through",
    "start": "54690",
    "end": "60170"
  },
  {
    "text": "Fannie Mae's use case and the need to reorder tech to mission-critical app and how that affected the business outcomes",
    "start": "60170",
    "end": "67729"
  },
  {
    "text": "and in the last segment I will walk you through architectural best practices",
    "start": "67729",
    "end": "73110"
  },
  {
    "text": "especially in terms of resiliency and high-performance applications deployed",
    "start": "73110",
    "end": "79500"
  },
  {
    "text": "on AWS let's get started before we this",
    "start": "79500",
    "end": "84720"
  },
  {
    "start": "84000",
    "end": "84000"
  },
  {
    "text": "is a 300 leveled session I'm assuming some of you already have background to AWS services a quick overview about the",
    "start": "84720",
    "end": "92460"
  },
  {
    "text": "AWS Storage portfolio a comprising of block storage file storage and object-based storage we're gonna be",
    "start": "92460",
    "end": "100020"
  },
  {
    "text": "focusing on s3 the object store because that forms the crux of this presentation",
    "start": "100020",
    "end": "105710"
  },
  {
    "text": "with respect to the storage layer quick",
    "start": "105710",
    "end": "111409"
  },
  {
    "text": "update on we have a couple of two or three announcements on s3 yesterday I'm",
    "start": "111409",
    "end": "118469"
  },
  {
    "text": "gonna be covering some of that aspects as well although I won't go dive deep into that yet because those are some of",
    "start": "118469",
    "end": "123540"
  },
  {
    "text": "those are in preview s3 use cases there is three is commonly used for backup and",
    "start": "123540",
    "end": "130649"
  },
  {
    "text": "storage or for application Hosting or for media hosting and",
    "start": "130649",
    "end": "135920"
  },
  {
    "text": "software delivery there are many mechanisms through which",
    "start": "135920",
    "end": "140959"
  },
  {
    "text": "you can ingest data into the storage layers and for large enterprise customers one of the most common",
    "start": "140959",
    "end": "146030"
  },
  {
    "text": "patterns that I have observed is through Direct Connect why Direct Connect it gives you that resilient and consistent",
    "start": "146030",
    "end": "152030"
  },
  {
    "text": "Network performance that way if you're implementing any hybrid architectures where you have a data center and then",
    "start": "152030",
    "end": "158480"
  },
  {
    "text": "you have to push data from your data center to s3 you use the DX Direct",
    "start": "158480",
    "end": "164299"
  },
  {
    "text": "Connect and some of the on the on the bottom slide you can see the data",
    "start": "164299",
    "end": "169970"
  },
  {
    "text": "transfer mechanisms we're gonna be touching a little bit in the resiliency portion will be touching a little bit about Direct Connect and how do you",
    "start": "169970",
    "end": "176299"
  },
  {
    "text": "architect your highly resilient architectures on AWS including DX",
    "start": "176299",
    "end": "181609"
  },
  {
    "text": "integration with Anpanman networking s3 by the numbers the s3 was launched on pi",
    "start": "181609",
    "end": "189109"
  },
  {
    "text": "day in 2006 it's a lot of development",
    "start": "189109",
    "end": "195170"
  },
  {
    "text": "has taken place since then to improve the service and it has seen tremendous growth in terms of customer adoption and",
    "start": "195170",
    "end": "201560"
  },
  {
    "text": "a lot of feedback that we have received from customers about everything ranging from security to performance just to",
    "start": "201560",
    "end": "208310"
  },
  {
    "text": "give you a perspective about s3 as the main storage layer as three holes",
    "start": "208310",
    "end": "213590"
  },
  {
    "text": "trillions of objects and regularly peaks at the millions of requests per second and as three is practically available in",
    "start": "213590",
    "end": "220909"
  },
  {
    "text": "every AWS region in all the availability zones right and s3 has over time has",
    "start": "220909",
    "end": "230870"
  },
  {
    "text": "been adopted by customers for wide variety of reasons the most important part is durability it comes with eleven",
    "start": "230870",
    "end": "237560"
  },
  {
    "text": "lines of durability and availability why is availability important in with",
    "start": "237560",
    "end": "242870"
  },
  {
    "text": "respect to s3 because it stores your data in three Ozzie's so you don't have to do that natively yourself it comes",
    "start": "242870",
    "end": "251030"
  },
  {
    "text": "out of the box and it's a server less pattern it's a lot of advantages of doing that and also at internet scale so",
    "start": "251030",
    "end": "259609"
  },
  {
    "text": "in addition to the durability availability and scalability the other things",
    "start": "259609",
    "end": "265220"
  },
  {
    "text": "the key promise from history perspective is around security and elasticity",
    "start": "265220",
    "end": "271430"
  },
  {
    "text": "there is a huge ecosystem of integrators with a three offering you Native",
    "start": "271430",
    "end": "277520"
  },
  {
    "text": "integrations in terms of storage in terms of disaster recovery in terms of big data analytics and also lately the",
    "start": "277520",
    "end": "283760"
  },
  {
    "text": "machine learning integrations I'll give you a little bit flavor on that so let's dive deep into s3 architecture a lot of",
    "start": "283760",
    "end": "290600"
  },
  {
    "start": "289000",
    "end": "289000"
  },
  {
    "text": "you folks are not familiar maybe not familiar with the intricacies of how it's built and how we manage the backend",
    "start": "290600",
    "end": "295910"
  },
  {
    "text": "just to give you a perspective as an end-user you will be calling the s3",
    "start": "295910",
    "end": "302390"
  },
  {
    "text": "api's for a wide variety of actions like puts and gaps and deletes when you do",
    "start": "302390",
    "end": "308060"
  },
  {
    "text": "that it goes through our s3 managed load balancers and behind the load balancers",
    "start": "308060",
    "end": "313310"
  },
  {
    "text": "are the actual API servers that are handling your requests coming in and as",
    "start": "313310",
    "end": "319030"
  },
  {
    "text": "as those requests are processed the actual put operations are stored on the",
    "start": "319030",
    "end": "325550"
  },
  {
    "text": "blob storage across 380s and then for all the objects that are stored we have an internal metadata storage with which",
    "start": "325550",
    "end": "331790"
  },
  {
    "text": "we actually track the objects where it store etc so when you issue a get",
    "start": "331790",
    "end": "337370"
  },
  {
    "text": "request it's the metadata information that is that actually gets processed and pulled the data and essentially give it",
    "start": "337370",
    "end": "343310"
  },
  {
    "text": "back to you from a front-end perspective s3 front-end manages 37 Turbots per",
    "start": "343310",
    "end": "351590"
  },
  {
    "text": "second at peak in a single region that is in a five minute peak in any given",
    "start": "351590",
    "end": "358730"
  },
  {
    "text": "region in a for s3 you're pushing through 1.3 terabytes or petabytes of data that's right 1.3 petabytes of data",
    "start": "358730",
    "end": "367010"
  },
  {
    "text": "for a 5 minute average so you can see s3 operates at a very high scale and as 3",
    "start": "367010",
    "end": "373130"
  },
  {
    "text": "years built for internet scale having said that security a lot of customers I",
    "start": "373130",
    "end": "380690"
  },
  {
    "text": "have worked with the for the number one question they ask is what do I do to",
    "start": "380690",
    "end": "385730"
  },
  {
    "text": "secure my data we hear concerns about exposing data for misconfigured buckets",
    "start": "385730",
    "end": "392240"
  },
  {
    "text": "and how do I make sure these these don't become a problem mikay ws-security is job zero and s3",
    "start": "392240",
    "end": "400990"
  },
  {
    "text": "comes with a comprehensive security and compliance capabilities we have already",
    "start": "400990",
    "end": "406410"
  },
  {
    "text": "recently launched I think earlier this month we have launched a new feature that gives you ability to prevent",
    "start": "406410",
    "end": "414160"
  },
  {
    "text": "accidental data exposure caused by misconfigured s3 buckets how did we do that you can see if you go to the Amazon",
    "start": "414160",
    "end": "420460"
  },
  {
    "text": "s3 console you can do the you can clearly see orange or or public",
    "start": "420460",
    "end": "425770"
  },
  {
    "text": "indicator for objects or buckets that are exposed to public by default when you create objects for buckets you know",
    "start": "425770",
    "end": "432370"
  },
  {
    "text": "it's it's private unless you choose to expose that for public and there is genuine reasons why you would want to do",
    "start": "432370",
    "end": "437770"
  },
  {
    "text": "that if you're doing web hosting absolutely that makes sense to expose some of the content to public in",
    "start": "437770",
    "end": "445000"
  },
  {
    "text": "addition to s3 console and EPS to give you warning about public exposure there is also a secondary method a trusted",
    "start": "445000",
    "end": "451540"
  },
  {
    "text": "adviser API calls so you can use trusted adviser which is a management tool you",
    "start": "451540",
    "end": "457000"
  },
  {
    "text": "can leverage that API to to look for any s3 bucket permissions issue that is a",
    "start": "457000",
    "end": "463030"
  },
  {
    "text": "second method for you to figure out if there is any exposure and then the public access restrictions I think",
    "start": "463030",
    "end": "469590"
  },
  {
    "text": "that's also recently launched you can actually block public exposure by",
    "start": "469590",
    "end": "475120"
  },
  {
    "text": "configuring that at the bucket level right and in addition to all this you will you also have integrations with",
    "start": "475120",
    "end": "482170"
  },
  {
    "text": "cloud trail so all your api actions are logged and you can absolutely run",
    "start": "482170",
    "end": "488250"
  },
  {
    "text": "filters and see if there is any specific actions that were taken that that was not intentional so in addition to",
    "start": "488250",
    "end": "495010"
  },
  {
    "text": "security a lot of customers also store sensitive data including PII data and",
    "start": "495010",
    "end": "500620"
  },
  {
    "text": "there are three mechanisms to encrypt data one is customer manage keys as a CC the second one is as three managed keys",
    "start": "500620",
    "end": "508270"
  },
  {
    "text": "as a CF the server-side encryption using s3 and the third one most popular that I",
    "start": "508270",
    "end": "515110"
  },
  {
    "text": "have seen working with enterprise customers is SSE kms yss he came s you",
    "start": "515110",
    "end": "520300"
  },
  {
    "text": "can control the master keys and SSE Kerr the kms service itself integrates very",
    "start": "520300",
    "end": "525700"
  },
  {
    "text": "well with many other services including EBS blocks euboea",
    "start": "525700",
    "end": "530769"
  },
  {
    "text": "storage or data store in RDS instances etcetera so that's a nice integration",
    "start": "530769",
    "end": "536680"
  },
  {
    "text": "there alright Oh before I move on I just wanted to",
    "start": "536680",
    "end": "543000"
  },
  {
    "start": "541000",
    "end": "541000"
  },
  {
    "text": "call out there is also a a compliance",
    "start": "543000",
    "end": "548740"
  },
  {
    "text": "regime that we go through a lot of customers have asked if these service is compliant with say FedRAMP PCI DSS",
    "start": "548740",
    "end": "555819"
  },
  {
    "text": "whatever the industry mandates that you have these are absolutely compliant for",
    "start": "555819",
    "end": "561610"
  },
  {
    "text": "s3 and there is a compliance in scope page that you can look it up and see all the compliance regimes that we subscribe",
    "start": "561610",
    "end": "568689"
  },
  {
    "text": "to a lot of fist three customers came up with the interesting use cases you may",
    "start": "568689",
    "end": "575769"
  },
  {
    "text": "have heard about Netflix using billions of hours of content streaming from s3",
    "start": "575769",
    "end": "580860"
  },
  {
    "text": "there is also large enterprise customers like Thomson Reuters or GE where s3 is",
    "start": "580860",
    "end": "587139"
  },
  {
    "text": "used as a data Lake and that's a popular pattern Zillow uses a lot of free content to do",
    "start": "587139",
    "end": "594790"
  },
  {
    "text": "machine learning analytics on the property data a wide variety of use cases and then for customers who have",
    "start": "594790",
    "end": "601720"
  },
  {
    "text": "invested in partner solutions on pram we work very closely to ensure great",
    "start": "601720",
    "end": "608019"
  },
  {
    "text": "customer experience we partner with these popular enterprise vendors to natively integrate their services",
    "start": "608019",
    "end": "614290"
  },
  {
    "text": "through to s3 for again many use cases backup and restore primary storage",
    "start": "614290",
    "end": "619300"
  },
  {
    "text": "essentially extending that investments that customers have already made in terms of partner integrations into s3",
    "start": "619300",
    "end": "627389"
  },
  {
    "start": "627000",
    "end": "627000"
  },
  {
    "text": "now let's dive into a little bit more details a lot of questions about what",
    "start": "627389",
    "end": "633850"
  },
  {
    "text": "are the limits of s3 how can how much data can I push and is there a limit so",
    "start": "633850",
    "end": "639149"
  },
  {
    "text": "not not so long ago we used to advise customers that typically for put",
    "start": "639149",
    "end": "644470"
  },
  {
    "text": "operations it used to be four hundred sort of or four puts it's four hundred requests per second or an forgets it",
    "start": "644470",
    "end": "651220"
  },
  {
    "text": "used to be eight hundred requests per second that used to be a threshold beyond which you may see heart",
    "start": "651220",
    "end": "658050"
  },
  {
    "text": "partitions which means essentially you may get bottleneck data i/o operations we changed that we improved",
    "start": "658050",
    "end": "666350"
  },
  {
    "text": "the service and earlier this year these are the new numbers the 3500 RPS for",
    "start": "666350",
    "end": "671779"
  },
  {
    "text": "most of the puts and post and deletes and 5,500 rpm or gets it's extremely",
    "start": "671779",
    "end": "677389"
  },
  {
    "text": "important to understand these numbers because if you ever go beyond if your",
    "start": "677389",
    "end": "682610"
  },
  {
    "text": "requirement if your application requires more throughput than this and if you want to push more you can absolutely do",
    "start": "682610",
    "end": "689089"
  },
  {
    "text": "that for example for the RPS that says 5,500 forgets if you're getting if",
    "start": "689089",
    "end": "694970"
  },
  {
    "text": "you're doing more gets against s3 and you want to go beyond 5,500 the easiest",
    "start": "694970",
    "end": "700339"
  },
  {
    "text": "method to do that is to manipulate the prefixes so as it because all these are",
    "start": "700339",
    "end": "706250"
  },
  {
    "text": "contingent on a prefix in the bucket right in the path so by manipulating by",
    "start": "706250",
    "end": "711649"
  },
  {
    "text": "adding say 10 more prefixes you can exponentially grow your your performance for each of these operations what I mean",
    "start": "711649",
    "end": "718610"
  },
  {
    "text": "by that is if there are 5,500 RPS for get operations for a prefix if you add",
    "start": "718610",
    "end": "724790"
  },
  {
    "text": "10 prefixes you're essentially driving 55,000 RPS at that point as an aggregate",
    "start": "724790",
    "end": "732250"
  },
  {
    "text": "also very important tip a lot of enterprise customers use encryption like",
    "start": "732250",
    "end": "737329"
  },
  {
    "text": "I said as a CTMS is a popular mechanism to do that when you are pushing the",
    "start": "737329",
    "end": "742490"
  },
  {
    "text": "limits for as3 and you're manipulating prefixes and you're adding more pushing more gets and puts make sure you align",
    "start": "742490",
    "end": "751220"
  },
  {
    "text": "those with the kms limits we have run into many situations where customers don't necessarily understand the nuances",
    "start": "751220",
    "end": "757100"
  },
  {
    "text": "between the two as you're increasing your requests against s3 objects obviously you are doing a decrypt and an",
    "start": "757100",
    "end": "763730"
  },
  {
    "text": "encryption against the objects right because your kms encrypted so make sure they both are aligned the kms limits are",
    "start": "763730",
    "end": "771110"
  },
  {
    "text": "published therefore these are the common now again why is that range because it depends on the region in which you are",
    "start": "771110",
    "end": "776449"
  },
  {
    "text": "operating these KMS limits if you ever again this is a soft limit we can you can work with AWS support to make sure",
    "start": "776449",
    "end": "783560"
  },
  {
    "text": "if you want to go beyond the 10000 RPS for kms you can work with us to increase",
    "start": "783560",
    "end": "789740"
  },
  {
    "text": "that although due to the recent 3d",
    "start": "789740",
    "end": "795540"
  },
  {
    "text": "performance enhancements most of the customers do not need to do this we used to tell them you can do you three or",
    "start": "795540",
    "end": "802890"
  },
  {
    "text": "four character hash or entropy as part of your naming scheme you as part of your key space this is not needed I just",
    "start": "802890",
    "end": "809280"
  },
  {
    "text": "wanted to give you a quick overview on why this is it used to be a important",
    "start": "809280",
    "end": "815670"
  },
  {
    "text": "way of driving more performance but essentially as three stores data in a",
    "start": "815670",
    "end": "821460"
  },
  {
    "text": "lexical graphical format so by doing that what happens is if you try to push",
    "start": "821460",
    "end": "826470"
  },
  {
    "text": "a lot of puts or guess against a specific key space you used to run into",
    "start": "826470",
    "end": "831750"
  },
  {
    "text": "a bottleneck at the key name space that used to be a problem it's not anymore because of the enhancements on the s3",
    "start": "831750",
    "end": "837180"
  },
  {
    "text": "side but if you are really going way beyond what we offer today or if you are",
    "start": "837180",
    "end": "842400"
  },
  {
    "text": "going into hundreds and thousands of RPS potentially you may still want to",
    "start": "842400",
    "end": "847620"
  },
  {
    "text": "consider this as an option in terms of introducing a randomness in your key space and the idea is to do you can",
    "start": "847620",
    "end": "854880"
  },
  {
    "text": "parallelize your operations into these key spaces and avoid hard partitions all",
    "start": "854880",
    "end": "862950"
  },
  {
    "text": "right now let's get into parallelizing as as I told you as three's s3 service",
    "start": "862950",
    "end": "869910"
  },
  {
    "start": "863000",
    "end": "863000"
  },
  {
    "text": "supports parallel operations which means you can scale your s3 performance by a factor of your computer what I mean by",
    "start": "869910",
    "end": "876960"
  },
  {
    "text": "that is make your compute the bottleneck make your network the bottleneck an",
    "start": "876960",
    "end": "883170"
  },
  {
    "text": "obvious three api's so what you could do with that is you could use for example",
    "start": "883170",
    "end": "888360"
  },
  {
    "text": "you could use range based get queries against to leverage multi-threaded",
    "start": "888360",
    "end": "893400"
  },
  {
    "text": "performance in this example the highlighted range 0 to 9 that's essentially fetching the",
    "start": "893400",
    "end": "899430"
  },
  {
    "text": "first 10 bytes of an object and you could do that in two multi-part you can align that multi-part and parallelize",
    "start": "899430",
    "end": "905790"
  },
  {
    "text": "your get operations and with the different bite sizes so that you can actually get multiple get requests for",
    "start": "905790",
    "end": "911040"
  },
  {
    "text": "large objects right why is this important this is important because you can add it this will allows you to send",
    "start": "911040",
    "end": "919170"
  },
  {
    "text": "multiple get request to the s3 service which means your parallelizing gets which means you're processing a lot more",
    "start": "919170",
    "end": "924720"
  },
  {
    "text": "as long as you have the compute capacity on the client slide to process all this you can absolutely do multi-threading",
    "start": "924720",
    "end": "930990"
  },
  {
    "text": "architecture get faster response better throughput all right",
    "start": "930990",
    "end": "937040"
  },
  {
    "text": "and also one key takeaway in that parallelizing gets is if you are",
    "start": "937040",
    "end": "942630"
  },
  {
    "text": "repeatedly querying for the same object you may want to consider edge caching how do you do education through a",
    "start": "942630",
    "end": "948240"
  },
  {
    "text": "content distribution networks and the offering we have is CloudFront most of you may know that what's the advantage",
    "start": "948240",
    "end": "954570"
  },
  {
    "text": "of CloudFront again you're not only it's it's a low latency way of pushing",
    "start": "954570",
    "end": "961380"
  },
  {
    "text": "objects at the edge and to the end users now now that we have covered",
    "start": "961380",
    "end": "966510"
  },
  {
    "text": "parallelizing get operations let's talk about parallelizing put operations so there are two types of network if you",
    "start": "966510",
    "end": "972960"
  },
  {
    "text": "are using a direct connect or something like that where you have a 10 gig pipe from your data center to AWS that's not",
    "start": "972960",
    "end": "979800"
  },
  {
    "text": "a problem you are pushing as much as you or routers can handle and essentially that leveraging the the 10 gig",
    "start": "979800",
    "end": "986430"
  },
  {
    "text": "connection but if you are say a user a customer who is going over VPN over the",
    "start": "986430",
    "end": "993000"
  },
  {
    "text": "Internet it's a flaky network it's not consistent network so how do you ensure when you're when you're pushing large",
    "start": "993000",
    "end": "1000050"
  },
  {
    "text": "objects to s3 and you're having a flaky Network if you're if you get timeouts",
    "start": "1000050",
    "end": "1005480"
  },
  {
    "text": "you obviously essentially have to retransmit the whole thing which is not a very optimal way to do put operations",
    "start": "1005480",
    "end": "1011360"
  },
  {
    "text": "right so that's why we recommend doing parallelizing puts this is multi-part upload for large objects by doing that",
    "start": "1011360",
    "end": "1018350"
  },
  {
    "text": "the advantage is you are moving the again increase the list resiliency of",
    "start": "1018350",
    "end": "1024010"
  },
  {
    "text": "network errors and only thing that you have to do is to retransmit the the",
    "start": "1024010",
    "end": "1029569"
  },
  {
    "text": "parts that did not make it right so that that's much more efficient way of doing it rather than the whole object again so",
    "start": "1029570",
    "end": "1039410"
  },
  {
    "text": "to summarize the key takeaway from a performance standpoint from s3 is a",
    "start": "1039410",
    "end": "1045260"
  },
  {
    "text": "faster upload we didn't cover this but faster uploads over long distances say for example if you are if your primary",
    "start": "1045260",
    "end": "1051830"
  },
  {
    "text": "use cases in Singapore but you were also the pushing data to us East one you may",
    "start": "1051830",
    "end": "1058850"
  },
  {
    "text": "want to consider leveraging 3d transfer acceleration why is that advantageous to you because you're essentially taking",
    "start": "1058850",
    "end": "1065540"
  },
  {
    "text": "advantage of Amazon's network backbone to push the data natively using our network and that way faster our copy of",
    "start": "1065540",
    "end": "1073250"
  },
  {
    "text": "the data between buckets faster loads for large objects again we spoke about",
    "start": "1073250",
    "end": "1078410"
  },
  {
    "text": "s3 multi-part upload that's the key takeaway for that paralyze your put and get operations extremely important",
    "start": "1078410",
    "end": "1085340"
  },
  {
    "text": "concept make sure you try that and also distribute key space for high TPS I told",
    "start": "1085340",
    "end": "1091880"
  },
  {
    "text": "you about the entropy or the randomness in the key space it's it's you can still do that although it's not required for",
    "start": "1091880",
    "end": "1097280"
  },
  {
    "text": "most of the use cases you can absolutely do that and TCP window scaling it improves Network throughput performance",
    "start": "1097280",
    "end": "1104330"
  },
  {
    "text": "between your operating system on the client machine and s3 by supporting window size greater than 64 KB so that's",
    "start": "1104330",
    "end": "1111110"
  },
  {
    "text": "how you can take advantage of better network throughput performance so how do",
    "start": "1111110",
    "end": "1118070"
  },
  {
    "text": "you successfully modernize your now that we covered the storage layer let's get into the application rhe architecture",
    "start": "1118070",
    "end": "1124610"
  },
  {
    "text": "and how that flows into the next segment how do you successfully modernize your",
    "start": "1124610",
    "end": "1130880"
  },
  {
    "text": "most highly visible customer phase saying maybe your Tier one apps and highly performant applications and still",
    "start": "1130880",
    "end": "1139850"
  },
  {
    "text": "you know be able to talk about it because a lot of process takes place in",
    "start": "1139850",
    "end": "1146360"
  },
  {
    "text": "terms of we are connecting your application site scale I'm sure most of you in this room have have been through",
    "start": "1146360",
    "end": "1154030"
  },
  {
    "text": "or have dealt with legacy applications and some of you have may have tried to",
    "start": "1154030",
    "end": "1160190"
  },
  {
    "text": "re architect legacy applications when you re architecting you have different patterns you may have heard about lift",
    "start": "1160190",
    "end": "1166580"
  },
  {
    "text": "and shift you may have heard about refactoring I'm not gonna get into the nuances of what those are but you know",
    "start": "1166580",
    "end": "1172010"
  },
  {
    "text": "what I mean essentially finding a pattern of developing cloud native",
    "start": "1172010",
    "end": "1177860"
  },
  {
    "text": "applications or in some cases maybe due to the situation you are in you may have to extend your data center capabilities",
    "start": "1177860",
    "end": "1184250"
  },
  {
    "text": "which means a hybrid solution so let's talk about",
    "start": "1184250",
    "end": "1190840"
  },
  {
    "text": "loan processing at scale this is where",
    "start": "1190940",
    "end": "1197419"
  },
  {
    "text": "you are essentially taking advantage of the s3 layer and also taking advantage",
    "start": "1197419",
    "end": "1203099"
  },
  {
    "text": "of the cloud native capabilities of s3 and also a WS just to give you a recap",
    "start": "1203099",
    "end": "1209879"
  },
  {
    "text": "of the things that we already discussed you have the linear scalability that is absolutely a requirement for hybrid",
    "start": "1209879",
    "end": "1216719"
  },
  {
    "text": "applications or cloud native applications you need to have stellar durability right you don't want to be",
    "start": "1216719",
    "end": "1222479"
  },
  {
    "text": "getting into the operational management of how do I manage my storage make sure it's available in every AZ all those",
    "start": "1222479",
    "end": "1229649"
  },
  {
    "text": "things come into play that's an operational overhead that does not give you a business value right so that's",
    "start": "1229649",
    "end": "1235259"
  },
  {
    "text": "that's the reason I'm emphasizing this portion about durability and predictability in terms of leveraging a",
    "start": "1235259",
    "end": "1240389"
  },
  {
    "text": "storage layer that's managed by AWS and at a reasonable cost now the usual list",
    "start": "1240389",
    "end": "1248099"
  },
  {
    "text": "I already discussed the the most common use cases for a3 from static web hosting",
    "start": "1248099",
    "end": "1254339"
  },
  {
    "text": "to data leak to social web to image and image processing encoding right but I",
    "start": "1254339",
    "end": "1262440"
  },
  {
    "text": "have seen customers pushing the limits of what s3 can be used for and a one key",
    "start": "1262440",
    "end": "1268709"
  },
  {
    "text": "question that came in to again a lot of customers have been asking is can we use",
    "start": "1268709",
    "end": "1273899"
  },
  {
    "text": "this as a transactional store as a backup French storage or analytics",
    "start": "1273899",
    "end": "1279179"
  },
  {
    "text": "workload it's great it's already doing its job but can I use this can i push s3 to use it as a transactional store",
    "start": "1279179",
    "end": "1286139"
  },
  {
    "text": "typically transactional stores are if you recall most of these are either EBS",
    "start": "1286139",
    "end": "1291719"
  },
  {
    "text": "volumes or maybe databases like dynamo DB or RDS so a little bit of an",
    "start": "1291719",
    "end": "1299009"
  },
  {
    "start": "1298000",
    "end": "1298000"
  },
  {
    "text": "unconventional thinking in terms of the storage layer is can be used as three for high frequency locking requests can",
    "start": "1299009",
    "end": "1306779"
  },
  {
    "text": "we use s3 for incredibly very high fast response close to what you call a file",
    "start": "1306779",
    "end": "1313440"
  },
  {
    "text": "system level performance can I do that will we what would what would it take to",
    "start": "1313440",
    "end": "1319440"
  },
  {
    "text": "build a service that provides a Thomas city and assistance e at the storage layer and still taking advantage about all the",
    "start": "1319440",
    "end": "1325719"
  },
  {
    "text": "things that we just discussed about s3 so these are some of the things that we thought about and and and and now if you",
    "start": "1325719",
    "end": "1335019"
  },
  {
    "text": "go into the architecture of an application leveraging those capabilities and those requirements the",
    "start": "1335019",
    "end": "1340119"
  },
  {
    "text": "one way of doing it is you can absolutely build more data center capacity you can you can absolutely",
    "start": "1340119",
    "end": "1347469"
  },
  {
    "text": "architect your application in the existing environment the only problem is again there is a large upfront capex and",
    "start": "1347469",
    "end": "1354249"
  },
  {
    "text": "you have to architect for peak capacity which means you have to analyze your 18 months or 24 months into the future",
    "start": "1354249",
    "end": "1362049"
  },
  {
    "text": "requirement and then build your capacity based on that targets or the cloud 1.0",
    "start": "1362049",
    "end": "1369279"
  },
  {
    "text": "strategy is okay we can I know what my eye ops on the storage layer is I have a",
    "start": "1369279",
    "end": "1374919"
  },
  {
    "text": "SAN storage that the lungs are mapped to my my with a VM bare or bare metal",
    "start": "1374919",
    "end": "1381609"
  },
  {
    "text": "servers now all I have to do is to lift and shift how do I do that take my provisional die ups whatever the",
    "start": "1381609",
    "end": "1388509"
  },
  {
    "text": "I ops I'm getting in the storage is Sam layer I'm happy to EBS volumes and",
    "start": "1388509",
    "end": "1393879"
  },
  {
    "text": "compared the I ops and do that absolutely a lot of customers have done that very successfully no problems with",
    "start": "1393879",
    "end": "1399819"
  },
  {
    "text": "that the the only problem there is again you have to consistently monitor your",
    "start": "1399819",
    "end": "1405099"
  },
  {
    "text": "peak capacity what what your storage capacity is going to look like and it's it's slightly better strategy than just",
    "start": "1405099",
    "end": "1411699"
  },
  {
    "text": "continue to build out the data center capacity but there are limitations to that one too so what we started thinking",
    "start": "1411699",
    "end": "1417819"
  },
  {
    "text": "about is let's get a little innovative let's see how our customers can push s3",
    "start": "1417819",
    "end": "1425259"
  },
  {
    "text": "to the next level and that's where I'd like to welcome Oliver and to explain",
    "start": "1425259",
    "end": "1430809"
  },
  {
    "text": "fannie mae's use case and how they haven't innovated and essentially",
    "start": "1430809",
    "end": "1436289"
  },
  {
    "text": "provided a resiliency to a mission critical application for better business outcomes",
    "start": "1436289",
    "end": "1443459"
  },
  {
    "text": "I'm hoping you're clapping for EM not for me that's okay so thank you everyone thank you for",
    "start": "1448809",
    "end": "1455360"
  },
  {
    "text": "joining I will walk through fannie mae's use case the initial solution we had in",
    "start": "1455360",
    "end": "1461809"
  },
  {
    "text": "place and then the complexity you know the challenges we faced the components",
    "start": "1461809",
    "end": "1467150"
  },
  {
    "text": "we added to the mix how the solution kind of evolved to meet those needs and then Harsha will get back into all the",
    "start": "1467150",
    "end": "1474380"
  },
  {
    "text": "engineering that is required for a multi-site multi-region architecture so",
    "start": "1474380",
    "end": "1479659"
  },
  {
    "text": "I'm Oliver Mathias and let's learn about Fannie Mae so our vision is to be",
    "start": "1479659",
    "end": "1488929"
  },
  {
    "text": "America's most valued housing partner providing access to credit liquidity and",
    "start": "1488929",
    "end": "1494030"
  },
  {
    "text": "affordability to all of us housing markets at all times so we buy loans",
    "start": "1494030",
    "end": "1500330"
  },
  {
    "text": "from lenders pull them into mortgage-backed securities that are actively traded in the capital markets",
    "start": "1500330",
    "end": "1506770"
  },
  {
    "text": "this continuous flow of liquidity promotes a healthy housing market how",
    "start": "1506770",
    "end": "1513140"
  },
  {
    "text": "many of you have been through a loan application process or know of somebody who's been through a loan application process great I see a lot of hands I",
    "start": "1513140",
    "end": "1519710"
  },
  {
    "text": "myself have been through it a couple of times did you know that one in three",
    "start": "1519710",
    "end": "1525940"
  },
  {
    "text": "homes are financed by Fannie Mae that's a great number so let's get into that",
    "start": "1525940",
    "end": "1533690"
  },
  {
    "text": "loan application process again this is a very simplified view of that loan application process there are a lot of",
    "start": "1533690",
    "end": "1540289"
  },
  {
    "text": "details but for the purpose of this discussion it's more around data more or less three so a prospective home buyer",
    "start": "1540289",
    "end": "1547100"
  },
  {
    "text": "works with a loan officer submits a loan application along with the collection of documents there's a lot of innovation",
    "start": "1547100",
    "end": "1554299"
  },
  {
    "text": "happening in this space a lot of integrations a lot of automation all with the goal to improve the borrower",
    "start": "1554299",
    "end": "1560210"
  },
  {
    "text": "experience this loan application along with the collection of documents are",
    "start": "1560210",
    "end": "1565730"
  },
  {
    "text": "processed by Fannie Mae systems we validate them we run a set of business rules everything around understanding",
    "start": "1565730",
    "end": "1573530"
  },
  {
    "text": "the loan understanding the borrower understanding the underlying collateral",
    "start": "1573530",
    "end": "1578529"
  },
  {
    "text": "we then consume a lot of data collect a lot of data from external sources from internal sources again the focus here is",
    "start": "1578580",
    "end": "1585180"
  },
  {
    "text": "the amount of data we acquired process and generate we don't then run even more",
    "start": "1585180",
    "end": "1591420"
  },
  {
    "text": "business rules and then return back to the customer with our results so as we",
    "start": "1591420",
    "end": "1598020"
  },
  {
    "text": "went down this path this simple process had is a very important process and we",
    "start": "1598020",
    "end": "1604620"
  },
  {
    "text": "soon realized that we had three very important goals near zero downtime near",
    "start": "1604620",
    "end": "1610350"
  },
  {
    "text": "zero day loss and milliseconds response times so the system's already had a very",
    "start": "1610350",
    "end": "1617400"
  },
  {
    "text": "high reputation a very high quality of service that the customers had gotten used to expect so what were some of our",
    "start": "1617400",
    "end": "1624960"
  },
  {
    "text": "challenges obviously we had to maximise on those three levels availability",
    "start": "1624960",
    "end": "1630150"
  },
  {
    "start": "1627000",
    "end": "1627000"
  },
  {
    "text": "performance and durability we wanted 99 percentile of our transactions to be",
    "start": "1630150",
    "end": "1637140"
  },
  {
    "text": "done in less than 300 milliseconds we wanted linear response times",
    "start": "1637140",
    "end": "1642800"
  },
  {
    "text": "irrespective of the amount of data growth and we had to work with the",
    "start": "1642800",
    "end": "1649200"
  },
  {
    "text": "current system while we transform the current system so we couldn't lose sight of the target State we also wanted to",
    "start": "1649200",
    "end": "1655560"
  },
  {
    "text": "materially reduce our pecks we wanted to retire our systems on-premise and also",
    "start": "1655560",
    "end": "1661350"
  },
  {
    "text": "use the agile cloud infrastructure you know forests elasticity of compute network storage on demand and in a",
    "start": "1661350",
    "end": "1668100"
  },
  {
    "text": "self-service manner when you work on a large problem it's typically made out of",
    "start": "1668100",
    "end": "1674790"
  },
  {
    "text": "smaller parts and all these parts and pieces and components have to work together to perform the larger function",
    "start": "1674790",
    "end": "1682310"
  },
  {
    "start": "1675000",
    "end": "1675000"
  },
  {
    "text": "we wanted predictability and one way to get predictability is by having uniformity we didn't want snowflakes so",
    "start": "1683840",
    "end": "1690930"
  },
  {
    "text": "early on we set up some guardrails so our design discussions became more easier once we knew you this is where we",
    "start": "1690930",
    "end": "1697200"
  },
  {
    "text": "want to go so we wanted to reduce our chattiness between our on-premise service and our data centers obviously",
    "start": "1697200",
    "end": "1704130"
  },
  {
    "text": "as Harsha just mentioned we are at 10 gig lines you know dwell active active direct and X we didn't want to have",
    "start": "1704130",
    "end": "1711180"
  },
  {
    "text": "traffic going back and put on those on those circuits all the time so we co-located are dependent",
    "start": "1711180",
    "end": "1716789"
  },
  {
    "text": "services we also favored localized executions as much as we could we wanted",
    "start": "1716789",
    "end": "1723780"
  },
  {
    "text": "our developers to focus more on building software and less on infrastructure control we also wanted to build a new",
    "start": "1723780",
    "end": "1731880"
  },
  {
    "text": "applications cloud native and use ease of AWS native when the use case demanded",
    "start": "1731880",
    "end": "1737100"
  },
  {
    "text": "case in point being s3 so let's get into the solution so this is the typical work",
    "start": "1737100",
    "end": "1744000"
  },
  {
    "text": "week in the life of the application right two key observations over here we",
    "start": "1744000",
    "end": "1751530"
  },
  {
    "text": "have a incredibly steep ramp it repeats every day incredibly steep ramp the",
    "start": "1751530",
    "end": "1757260"
  },
  {
    "text": "other observation at its peak during the during the day our s3 TPS can go between",
    "start": "1757260",
    "end": "1764250"
  },
  {
    "text": "800 to 1600 so this was the initial solution we had again this is a simple",
    "start": "1764250",
    "end": "1772350"
  },
  {
    "start": "1770000",
    "end": "1770000"
  },
  {
    "text": "view of the solution they're not looking at all the foundational components we had in place but in a simplest form",
    "start": "1772350",
    "end": "1778530"
  },
  {
    "text": "vieira Landers interacting with api sand these api software cloud components our cloud",
    "start": "1778530",
    "end": "1783929"
  },
  {
    "text": "components thanks to the great work done by engineering teams were deployed on a standardized stack we used elastic",
    "start": "1783929",
    "end": "1791520"
  },
  {
    "text": "beanstalk for capacity provisioning auto scaling load balancing we use the s3 for",
    "start": "1791520",
    "end": "1797340"
  },
  {
    "text": "a storage of objects and Postgres for storing our markers so this was my",
    "start": "1797340",
    "end": "1805500"
  },
  {
    "text": "initial view of the architecture or the solution we decided to run a workload",
    "start": "1805500",
    "end": "1811080"
  },
  {
    "text": "against it again remember our goal is to get 99% of our transactions in less than",
    "start": "1811080",
    "end": "1817440"
  },
  {
    "text": "300 milliseconds of zero downtime you know design to zero downtime so with",
    "start": "1817440",
    "end": "1824850"
  },
  {
    "text": "that in mind we ran a workload what were our observations not so good we were looking at periodic spikes as",
    "start": "1824850",
    "end": "1834059"
  },
  {
    "text": "much as one second at its peak when the TPS was very high the spikes is to show up even more and",
    "start": "1834059",
    "end": "1843270"
  },
  {
    "text": "these are object size is less than hundred Kb so we started on the journey of",
    "start": "1843270",
    "end": "1848670"
  },
  {
    "text": "optimizations alright so what are the first key steps we decided to apply all",
    "start": "1848670",
    "end": "1855450"
  },
  {
    "start": "1855000",
    "end": "1855000"
  },
  {
    "text": "the best practices that Herschel just alluded to entropy no longer concern for",
    "start": "1855450",
    "end": "1861480"
  },
  {
    "text": "our workload so we pushed s3 we've constantly worked with the s3 product",
    "start": "1861480",
    "end": "1866490"
  },
  {
    "text": "team and that and they've incorporated they've been incorporating a lot of our requests some are still in the works",
    "start": "1866490",
    "end": "1873980"
  },
  {
    "text": "our TPS is 8 800 to 1600 with the recent s3 updates forgets you could go up to",
    "start": "1873980",
    "end": "1879300"
  },
  {
    "text": "five five thousand five hundred four puts up to you know up to three thousand five hundred for prefix you know if you",
    "start": "1879300",
    "end": "1887370"
  },
  {
    "text": "if your workload work goes above that you still need to worry about randomizing your first four characters",
    "start": "1887370",
    "end": "1892610"
  },
  {
    "text": "one observations by our engineers you can't use UID so goods because they",
    "start": "1892610",
    "end": "1899520"
  },
  {
    "text": "might be random for an object name but are not sufficiently random for the first four characters so just watch out for that the next back best practice we",
    "start": "1899520",
    "end": "1907560"
  },
  {
    "text": "paralyze puts and gets all she talked about multi-part uploads or pushing the bottleneck to s3 which can scale better",
    "start": "1907560",
    "end": "1914400"
  },
  {
    "text": "our objects our package contain a set of documents each document was you know we",
    "start": "1914400",
    "end": "1919890"
  },
  {
    "text": "had document sizes which we read so we wanted to use the compute or paralyze",
    "start": "1919890",
    "end": "1927000"
  },
  {
    "text": "execution the AWS SDK itself does not give you an easy way to paralyze your",
    "start": "1927000",
    "end": "1932100"
  },
  {
    "text": "puts and gets but most programming language nowadays you know take care of futures thread streams it's pretty much",
    "start": "1932100",
    "end": "1939270"
  },
  {
    "text": "out of the box so you have to build it outside one key thing with parallelization you get a lot of",
    "start": "1939270",
    "end": "1944790"
  },
  {
    "text": "performance but also debugging becomes a nightmare working with s AWS support they always",
    "start": "1944790",
    "end": "1950550"
  },
  {
    "text": "look for three key elements tell me your host ID tell me your request ID and tell me an extended request ID so make sure",
    "start": "1950550",
    "end": "1957330"
  },
  {
    "text": "you log that multiple ways to get that one way is obviously you can log it on the response and the other way is cloud",
    "start": "1957330",
    "end": "1963810"
  },
  {
    "text": "trail enable cloud trail logs it's got you know and you could push it to a different bucket and it's got all the",
    "start": "1963810",
    "end": "1969750"
  },
  {
    "text": "information for you next we externalize markers s3 is great for gets inputs it's",
    "start": "1969750",
    "end": "1976680"
  },
  {
    "text": "been built for gets inputs but not so much for lest operations and range gets our use case had scenarios wherein",
    "start": "1976680",
    "end": "1984090"
  },
  {
    "text": "we had to do range gets and list operations so instead of using s3 we externalized it to a Postgres database",
    "start": "1984090",
    "end": "1989850"
  },
  {
    "text": "RDS and Postgres for an object marker",
    "start": "1989850",
    "end": "1995250"
  },
  {
    "text": "for us in s3 an object is considered unique between if it's bucket name or prefix an object ID an object version ID",
    "start": "1995250",
    "end": "2001730"
  },
  {
    "text": "we took that object marker and stored it outside in the post-crisis database along with business context along with",
    "start": "2001730",
    "end": "2007880"
  },
  {
    "text": "object metadata which would otherwise have stored in s3 so we didn't have to go to s3 for what it was not really",
    "start": "2007880",
    "end": "2013700"
  },
  {
    "text": "working for us but rather go to s3 for what it worked and and externalize the",
    "start": "2013700",
    "end": "2018860"
  },
  {
    "text": "markers for our use case so that gave us you know RDS Postgres as the vehicle for",
    "start": "2018860",
    "end": "2025430"
  },
  {
    "text": "getting what we needed the other thing is views RDS also has a secondary index",
    "start": "2025430",
    "end": "2030470"
  },
  {
    "text": "so we did all our querying off of RDS so these were the standard best practices here is a small code snippet something",
    "start": "2030470",
    "end": "2036740"
  },
  {
    "text": "you need to watch out for client configuration timeout and we'll get to it later another thing we had to work",
    "start": "2036740",
    "end": "2045050"
  },
  {
    "text": "around s3 eventual consistency model our application was strongly consistent s3",
    "start": "2045050",
    "end": "2050600"
  },
  {
    "text": "was eventually consistent so s3 is strongly consistent for puts of new",
    "start": "2050600",
    "end": "2055879"
  },
  {
    "text": "objects so if you write a new object it makes sure it writes it across all partitions before returning with a",
    "start": "2055880",
    "end": "2061250"
  },
  {
    "text": "success but if you are doing override puts or deletes s3 is eventually consistent s3 is built for performance",
    "start": "2061250",
    "end": "2068000"
  },
  {
    "text": "and throughput and less for consistency so we had to build that outside we build",
    "start": "2068000",
    "end": "2074600"
  },
  {
    "text": "it we needed our application needed to be strongly consistent we needed asset properties so we had to move that again",
    "start": "2074600",
    "end": "2080658"
  },
  {
    "text": "to the RDS Postgres that we build so we used s3 for what it was good for as you",
    "start": "2080659",
    "end": "2086480"
  },
  {
    "text": "can see in this diagram you can get dirty reads you can list objects that have already been deleted so some few",
    "start": "2086480",
    "end": "2092148"
  },
  {
    "text": "scenarios out here so with these basic optimizations we did we ran the workload again so what were our observations the",
    "start": "2092149",
    "end": "2100160"
  },
  {
    "text": "frequency has now reduced but we still see spikes it still does not meet our",
    "start": "2100160",
    "end": "2106250"
  },
  {
    "text": "requirements so we had to go ahead and additionally optimize and add some more",
    "start": "2106250",
    "end": "2112160"
  },
  {
    "text": "optimization we were looking for consistent low latency responses one way to get",
    "start": "2112160",
    "end": "2118040"
  },
  {
    "text": "consistent low latency responses by using an in-memory data store so we decided to cash in adding a new",
    "start": "2118040",
    "end": "2125930"
  },
  {
    "text": "component we've got to work about worried about durability worried about availability so we have to worry about compensation we have to worry about who",
    "start": "2125930",
    "end": "2132920"
  },
  {
    "text": "which system is now the SOR for us we had a latency sensitive workload so",
    "start": "2132920",
    "end": "2138950"
  },
  {
    "text": "caching just made sense for us AWS gives you two options for caching Redis and memcache tea we decided to go with Redis",
    "start": "2138950",
    "end": "2146540"
  },
  {
    "text": "open source database and we like the data structures it provided us with the",
    "start": "2146540",
    "end": "2152390"
  },
  {
    "text": "elastic cache on Redis you get a managed service that's easy to deploy monitor",
    "start": "2152390",
    "end": "2158180"
  },
  {
    "text": "integrates with cloud watch you get all kinds of matrix and out-of-the-box you get automatic failover you can deploy it",
    "start": "2158180",
    "end": "2163880"
  },
  {
    "text": "in a multi easy or deployment so caching",
    "start": "2163880",
    "end": "2172430"
  },
  {
    "text": "typically has two patents a cache read basically a lazy loading pattern or a",
    "start": "2172430",
    "end": "2179240"
  },
  {
    "text": "write through cache most folks use both in our scenario we decided to use both",
    "start": "2179240",
    "end": "2185180"
  },
  {
    "text": "we had to adjust a TTL for that so essentially with the cache read we go",
    "start": "2185180",
    "end": "2190640"
  },
  {
    "text": "first to the cache we see if the cache the objects or the package can is existing in the in the cache if it does",
    "start": "2190640",
    "end": "2196730"
  },
  {
    "text": "not exist in the cache we then go ahead to s3 if you notice we again go to s3 in",
    "start": "2196730",
    "end": "2202460"
  },
  {
    "text": "a parallel fashion get the data load it up into s3 you have to understand to use the cache effectively you do need to",
    "start": "2202460",
    "end": "2208849"
  },
  {
    "text": "understand your the patterns for data access and also adjust your TTL and the",
    "start": "2208849",
    "end": "2214460"
  },
  {
    "text": "pro with this approach is that you're only caching what you need so you're not storing more you're not paying more or",
    "start": "2214460",
    "end": "2219559"
  },
  {
    "text": "the con is that you've got an initial latency for the first request we were",
    "start": "2219559",
    "end": "2226640"
  },
  {
    "text": "able to save a ton in terms of the milliseconds that we're trying to save just by using the cache the other",
    "start": "2226640",
    "end": "2232549"
  },
  {
    "text": "pattern was the write through cache we use this as well so we use cache as a temporary SOR and then offloaded the",
    "start": "2232549",
    "end": "2239510"
  },
  {
    "text": "writes into s3 again we had to build compensation so if you notice we have a",
    "start": "2239510",
    "end": "2244790"
  },
  {
    "text": "lambda function that's responsible for that compensation to compensate the data from the cache or",
    "start": "2244790",
    "end": "2250390"
  },
  {
    "text": "drain the data from the cache into s3 in the case where in the cache we've had",
    "start": "2250390",
    "end": "2258430"
  },
  {
    "text": "cache issues so with this we were able",
    "start": "2258430",
    "end": "2263510"
  },
  {
    "text": "to get some more optimizations so let's get switch gears a little bit and look",
    "start": "2263510",
    "end": "2269450"
  },
  {
    "text": "at security so with a with AWS s3 out of",
    "start": "2269450",
    "end": "2274910"
  },
  {
    "text": "the box you get a lot of foundational elements for security you know security",
    "start": "2274910",
    "end": "2279920"
  },
  {
    "text": "in transit with TLS support security address great integration with I am I am",
    "start": "2279920",
    "end": "2285680"
  },
  {
    "text": "for access the focus of this was this discussion is mostly on security addressed so our data address needed to",
    "start": "2285680",
    "end": "2295220"
  },
  {
    "text": "be encrypted we had two options initially be favored going down the",
    "start": "2295220",
    "end": "2300590"
  },
  {
    "text": "client-side encryption option a couple of reasons with data client-side data key caching or data key is used for",
    "start": "2300590",
    "end": "2307220"
  },
  {
    "text": "multiple objects so that saves us a trip to kms saves around 25 milliseconds",
    "start": "2307220",
    "end": "2313569"
  },
  {
    "text": "additionally you don't have to worry about kms and any of his brittleness",
    "start": "2313750",
    "end": "2319240"
  },
  {
    "text": "when we started looking at SSE kms we",
    "start": "2319630",
    "end": "2324890"
  },
  {
    "text": "realized very soon that most of the rest of the ecosystem around s3 integrates well with sse KMS its CSE the data",
    "start": "2324890",
    "end": "2333170"
  },
  {
    "text": "inside s3 is opaque so you cannot do things like s we select Athena EMR none",
    "start": "2333170",
    "end": "2340160"
  },
  {
    "text": "of those tools work well with CSE for example even Amazon may see kms is a",
    "start": "2340160",
    "end": "2348140"
  },
  {
    "text": "clear 0 service the more you looked at it it's internally within AWS 80 or 0 service so all other services depend on",
    "start": "2348140",
    "end": "2354620"
  },
  {
    "text": "on a on on kms so that you know that's",
    "start": "2354620",
    "end": "2360350"
  },
  {
    "text": "all for most of our reliability concerns around SSE kms also it's you know it's",
    "start": "2360350",
    "end": "2367520"
  },
  {
    "text": "the kms limits have now been increased from 1200 to approximately 12 K so out",
    "start": "2367520",
    "end": "2374360"
  },
  {
    "text": "of the box you get 10 K or 12 K it's a shared a PA limit of across all kms requests for encryption and decryption",
    "start": "2374360",
    "end": "2380780"
  },
  {
    "text": "and most a SS customers F up the kms",
    "start": "2380780",
    "end": "2386360"
  },
  {
    "text": "limits that come out of the box for an account to approximately 20 or 30 K we",
    "start": "2386360",
    "end": "2391460"
  },
  {
    "text": "did that too as well hopping a kite kms limit takes as little as 15 15 minutes",
    "start": "2391460",
    "end": "2397390"
  },
  {
    "text": "so with all the benefits that km is gave us in terms of I am in integration or visibility into key activity integration",
    "start": "2397390",
    "end": "2404780"
  },
  {
    "text": "with crowd cloud trail without kms for the benefit for us then using CSE so now",
    "start": "2404780",
    "end": "2410300"
  },
  {
    "text": "that actually introduces additional expense in terms of performance of around 20 to 25 milliseconds if you have",
    "start": "2410300",
    "end": "2420260"
  },
  {
    "text": "a highly variable workloads where workloads that vary for maybe 7,500 to 3.5 million requests then maybe going to",
    "start": "2420260",
    "end": "2428810"
  },
  {
    "text": "desta cs3 is a better fit than going for kms so we did this optimisation took",
    "start": "2428810",
    "end": "2435740"
  },
  {
    "text": "care of eventual consistency applied caching data encryption at rest where do",
    "start": "2435740",
    "end": "2440810"
  },
  {
    "text": "you think we got we are in Vegas I know you guys have pretty much honed your",
    "start": "2440810",
    "end": "2445820"
  },
  {
    "text": "skills by now where do you think we reach did we get to 95 percent 97",
    "start": "2445820",
    "end": "2451940"
  },
  {
    "text": "percent or 99 percent who thinks it's 95 percent remember we are trying to get to",
    "start": "2451940",
    "end": "2457910"
  },
  {
    "text": "99 how many of you think our 97 cool",
    "start": "2457910",
    "end": "2463730"
  },
  {
    "text": "I've got a few over there how many of you think we've made it 99 percent oh that's all that's you guys all optimist",
    "start": "2463730",
    "end": "2470660"
  },
  {
    "text": "so very God was 97 and our goal is to get 99 so that's still not good enough",
    "start": "2470660",
    "end": "2476180"
  },
  {
    "text": "for us so we had to optimize even more so these are these were our results as",
    "start": "2476180",
    "end": "2481820"
  },
  {
    "text": "you can see for 97 percentile of our transactions or response times were less than 300 milliseconds for put Layton",
    "start": "2481820",
    "end": "2488660"
  },
  {
    "text": "sees we got below 300 milliseconds but you know we decoupled all right so so we",
    "start": "2488660",
    "end": "2495770"
  },
  {
    "text": "let's go ahead so we added some more optimizations to this mix so our initial simple architecture that you had a look",
    "start": "2495770",
    "end": "2501440"
  },
  {
    "text": "started looking like this we added some more components and as you can see once we get into multi region this gets even",
    "start": "2501440",
    "end": "2507530"
  },
  {
    "text": "more interesting right",
    "start": "2507530",
    "end": "2512500"
  },
  {
    "text": "so we had to build compensation as you remember for the cash so one of the",
    "start": "2512920",
    "end": "2521210"
  },
  {
    "start": "2520000",
    "end": "2520000"
  },
  {
    "text": "things we decided to optimize further was on was on gets and get rich wise but",
    "start": "2521210",
    "end": "2528110"
  },
  {
    "text": "gets for the spikes occasionally especially of these to see Layton sees as much as one second so we started",
    "start": "2528110",
    "end": "2536720"
  },
  {
    "text": "tuning the client configuration timeout setting that's an interesting setting if you tune that to 99th percentile of your",
    "start": "2536720",
    "end": "2542120"
  },
  {
    "text": "workload and if you have exponential retries you typically end up getting closer to where you want to get in terms",
    "start": "2542120",
    "end": "2548570"
  },
  {
    "text": "of performance so that's a variable that we tuned quite a bit with that in play",
    "start": "2548570",
    "end": "2555310"
  },
  {
    "text": "one of our engineers suggested hey why don't we try out using larger instances",
    "start": "2555310",
    "end": "2561770"
  },
  {
    "start": "2560000",
    "end": "2560000"
  },
  {
    "text": "right we were using em for 4x largest the suggestion was how about we try out",
    "start": "2561770",
    "end": "2567770"
  },
  {
    "text": "em for 10x lodges with 10x large you get 10 gig of network i/o so you get more",
    "start": "2567770",
    "end": "2572900"
  },
  {
    "text": "i/o if I oh is about a network i/o is a bottleneck maybe thats all said so we ran a test by changing the instances and",
    "start": "2572900",
    "end": "2581170"
  },
  {
    "text": "really we didn't see much difference so larger instances really did not help us but with the get retries",
    "start": "2581170",
    "end": "2588020"
  },
  {
    "text": "we were now a little bit closer so i want to ask you the question again but",
    "start": "2588020",
    "end": "2593210"
  },
  {
    "text": "right with with without with the changes that we did with all the optimizations that we did we now reached our goal of",
    "start": "2593210",
    "end": "2599960"
  },
  {
    "text": "getting to 99 percentile so this is how",
    "start": "2599960",
    "end": "2605560"
  },
  {
    "text": "how the response to the x looks like both for puts and forgets as you can observe we are within the threshold that",
    "start": "2605560",
    "end": "2614300"
  },
  {
    "text": "we wanted to get to so I would be remiss",
    "start": "2614300",
    "end": "2619490"
  },
  {
    "text": "if I leave this stage without calling out the wonderful team we work with the product owners are the squads the",
    "start": "2619490",
    "end": "2625070"
  },
  {
    "text": "engineering folks and it was an awesome experience so with that I will give it",
    "start": "2625070",
    "end": "2630260"
  },
  {
    "text": "to Harsha to talk about multi-region Thank You Oliver",
    "start": "2630260",
    "end": "2636640"
  },
  {
    "text": "it's really amazing how Fannie Mae has pushed us to Delaware for for highly",
    "start": "2639030",
    "end": "2645369"
  },
  {
    "text": "critical workloads and they're the services were not up to the mark missing out on the 97% age versus 99 that to be",
    "start": "2645369",
    "end": "2653440"
  },
  {
    "text": "architecture so these are some of the examples that are extremely important",
    "start": "2653440",
    "end": "2658839"
  },
  {
    "text": "your feedback is very important to us for our product development it is feedback like that through which we have",
    "start": "2658839",
    "end": "2664960"
  },
  {
    "text": "actually delivered higher throughput and also the data security component of the s3 right so it's still not done yet a",
    "start": "2664960",
    "end": "2672490"
  },
  {
    "text": "lost segment is essentially now that we discussed everything about getting the performance aligned with respect to",
    "start": "2672490",
    "end": "2679569"
  },
  {
    "text": "expectations how do we now deploy this into a I mean if you take a workload",
    "start": "2679569",
    "end": "2684730"
  },
  {
    "text": "like this and deploy into a multi region fashion let's touch on some of those",
    "start": "2684730",
    "end": "2690130"
  },
  {
    "text": "aspects RTO RPO extremely important conversations again these are all there",
    "start": "2690130",
    "end": "2696579"
  },
  {
    "text": "are industry mandates there you could have agency mandates if you're working or maybe industry mandates where you may",
    "start": "2696579",
    "end": "2704410"
  },
  {
    "text": "have specific RTO requirements or recovery point objectives and recovery time objectives that you may have to",
    "start": "2704410",
    "end": "2710170"
  },
  {
    "text": "meet so I'm gonna just touch on some of those key patterns before we conclude so",
    "start": "2710170",
    "end": "2715829"
  },
  {
    "start": "2715000",
    "end": "2715000"
  },
  {
    "text": "achieving resiliency I this is extremely important to understand please assume",
    "start": "2715829",
    "end": "2721930"
  },
  {
    "text": "things will fail you you are you have to assume your app app and apps components",
    "start": "2721930",
    "end": "2726940"
  },
  {
    "text": "will fail you have your dependencies could fail you could have a network glitch you be maybe your VPN tunnels",
    "start": "2726940",
    "end": "2732940"
  },
  {
    "text": "will go down or DX connection may go down you you have to start thinking in terms of building your resiliency and",
    "start": "2732940",
    "end": "2738250"
  },
  {
    "text": "and you know into every single component right redundancy and resiliency both",
    "start": "2738250",
    "end": "2745049"
  },
  {
    "text": "availability zones and regions again you may have API hours into your specific region for a specific service so you",
    "start": "2745049",
    "end": "2752170"
  },
  {
    "text": "need to start thinking about how do I do the exponential retries this is very very important for coders if you're a",
    "start": "2752170",
    "end": "2757660"
  },
  {
    "text": "developer if you're encountering a 5x X error against API call make sure you do that exponential read twice as part of",
    "start": "2757660",
    "end": "2764140"
  },
  {
    "text": "your logic so that you don't you have a workaround that app dependencies again some of the",
    "start": "2764140",
    "end": "2771920"
  },
  {
    "start": "2769000",
    "end": "2769000"
  },
  {
    "text": "very high patterns that there are essentially three categories in which you need to think about resiliency right",
    "start": "2771920",
    "end": "2777410"
  },
  {
    "text": "one is a Brazilian see which I just spoke about defensive cloud a defensive",
    "start": "2777410",
    "end": "2782480"
  },
  {
    "text": "coding in terms of retries cloud native design most of you may be familiar with",
    "start": "2782480",
    "end": "2787640"
  },
  {
    "text": "12 factor app and also have the circuit",
    "start": "2787640",
    "end": "2793880"
  },
  {
    "text": "breakers as part of your logic right what are some of the deviations that you observe and how do you take you know",
    "start": "2793880",
    "end": "2799640"
  },
  {
    "text": "corrective measures for that and give move away from a monolithic application architecture I strongly recommend",
    "start": "2799640",
    "end": "2806589"
  },
  {
    "text": "microservices again stateless applications we you heard that you can always maintain state outside you can",
    "start": "2806589",
    "end": "2812720"
  },
  {
    "text": "you leverage caching or even where customers have used dynamodb to maintain cache or the state so do is start",
    "start": "2812720",
    "end": "2820970"
  },
  {
    "text": "building micro services and also stateless application architectures and operational and network list resilience",
    "start": "2820970",
    "end": "2827089"
  },
  {
    "text": "is extremely important much like many of the customers I've worked with have already built in resiliency in terms of",
    "start": "2827089",
    "end": "2833239"
  },
  {
    "text": "data center design maybe you have redundant network switches H SRP vrrp",
    "start": "2833239",
    "end": "2838759"
  },
  {
    "text": "technologies on the Cisco side I've seen dual NIC cards do a dual HPA's you have",
    "start": "2838759",
    "end": "2845150"
  },
  {
    "text": "already done that and all you have to do is to extend that functionality and make sure you are taking advantage of multi",
    "start": "2845150",
    "end": "2851390"
  },
  {
    "text": "AC architectures on there aw aside so talking about resiliency within a region",
    "start": "2851390",
    "end": "2858109"
  },
  {
    "start": "2856000",
    "end": "2856000"
  },
  {
    "text": "again most of you may be familiar with multi a-z just to re-emphasize and a",
    "start": "2858109",
    "end": "2864499"
  },
  {
    "text": "single AZ is not a single data center please keep that in mind a single AZ consists of multiple data centers in a",
    "start": "2864499",
    "end": "2871369"
  },
  {
    "text": "metropolitan area so you have built in resiliency if you are leveraging multi",
    "start": "2871369",
    "end": "2877640"
  },
  {
    "text": "AC functionality on the on the diagram I'm trying to convey there on the right side in pink if you have components of",
    "start": "2877640",
    "end": "2884299"
  },
  {
    "text": "application that are mostly 99% available but only a single component that's not giving you or hat that has 90",
    "start": "2884299",
    "end": "2891470"
  },
  {
    "text": "percent availability your overall app availability goes down to 90 percent you can absolutely increase that by just",
    "start": "2891470",
    "end": "2897859"
  },
  {
    "text": "doing multi AZ by increasing essentially leverage Multi easy to get you that 99% so please",
    "start": "2897859",
    "end": "2904490"
  },
  {
    "text": "keep that in mind if you're deploying production workloads leverage multi is ease the key takeaway and also for for",
    "start": "2904490",
    "end": "2911390"
  },
  {
    "text": "extremely latency sensitive workloads have some dark capacity as needed of",
    "start": "2911390",
    "end": "2918650"
  },
  {
    "text": "course you can leverage your auto scaling as the as the need is but in",
    "start": "2918650",
    "end": "2923900"
  },
  {
    "text": "case you are worried about that always have some extra capacity for for faster",
    "start": "2923900",
    "end": "2929240"
  },
  {
    "text": "responses multi region again very important a lot of confusion about what",
    "start": "2929240",
    "end": "2935330"
  },
  {
    "text": "is the methodology when should I leverage this do you essentially have four options in terms of the multi",
    "start": "2935330",
    "end": "2944030"
  },
  {
    "text": "region deployment the first one which is not here is a strictly use that for dr",
    "start": "2944030",
    "end": "2951620"
  },
  {
    "text": "purposes meaning you already have pushed out your data to region to your dr site all you have to do is in a DRS and REO",
    "start": "2951620",
    "end": "2958640"
  },
  {
    "text": "have your CloudFormation template fire up your resources bring up your entire application stack and start ingesting",
    "start": "2958640",
    "end": "2964670"
  },
  {
    "text": "data and start processing that but realistically for enterprises there are",
    "start": "2964670",
    "end": "2969920"
  },
  {
    "text": "three pilot light active standby active active it all depends on contingent upon your business again back to RTO RPO that",
    "start": "2969920",
    "end": "2977900"
  },
  {
    "text": "will drive your selection process what is your sensitivity for RTO RPO that",
    "start": "2977900",
    "end": "2983540"
  },
  {
    "text": "will dictate which model you may want to adopt one thing again this is a very",
    "start": "2983540",
    "end": "2989240"
  },
  {
    "text": "common question I get asked is how do I do do I have to replicate what words the",
    "start": "2989240",
    "end": "2995330"
  },
  {
    "text": "methodology to replicate the data is it synchronous is it asynchronous it all depends on how you are which services",
    "start": "2995330",
    "end": "3003460"
  },
  {
    "text": "are you using to replicate your data s3 offers you cross region replication CRR",
    "start": "3003460",
    "end": "3008610"
  },
  {
    "text": "that is although keep in mind we do not give you a RPL guarantee so you need to",
    "start": "3008610",
    "end": "3016420"
  },
  {
    "text": "big that into your application design so you can leverage CRR for replication in a database you there are a few",
    "start": "3016420",
    "end": "3022570"
  },
  {
    "text": "technologies that you could use for example cross region read replicas if you're using Aurora or RDS essentially",
    "start": "3022570",
    "end": "3028690"
  },
  {
    "text": "you can use cross region read replicas the goal is again of course you should monitor the using",
    "start": "3028690",
    "end": "3034370"
  },
  {
    "text": "watch the replicas lag and in case you are having an issue on in your primary region you promote your read replicas to",
    "start": "3034370",
    "end": "3041750"
  },
  {
    "text": "be or master database and then start processing that right so that's what is depicted here and if you want right now",
    "start": "3041750",
    "end": "3050360"
  },
  {
    "text": "except for DynamoDB through global tables there is no synchronous replication across two regions for any",
    "start": "3050360",
    "end": "3057170"
  },
  {
    "text": "of the storage layers right so you would have to think about baking that is if",
    "start": "3057170",
    "end": "3062900"
  },
  {
    "text": "that's the requirement if you are talking about say I have a banking application I have a requirement of RPO",
    "start": "3062900",
    "end": "3069260"
  },
  {
    "text": "of zero I cannot go down right then in that case you have to start baking into",
    "start": "3069260",
    "end": "3074450"
  },
  {
    "text": "your application design multi-region commits the simultaneously so there are",
    "start": "3074450",
    "end": "3080120"
  },
  {
    "text": "complexities around that by going by approaching the design using multi",
    "start": "3080120",
    "end": "3086060"
  },
  {
    "text": "region rights the issue is now you are the onus is on you to write to both",
    "start": "3086060",
    "end": "3091220"
  },
  {
    "text": "locations and get a confirmation get a 500 or 200 ok response from both so",
    "start": "3091220",
    "end": "3096230"
  },
  {
    "text": "there is a lot of engineering effort that goes into multi regions so keep that in mind and also the costs keep in",
    "start": "3096230",
    "end": "3102470"
  },
  {
    "text": "mind the the if you are doing pilot light on the left of course it's a function of cost you are not really",
    "start": "3102470",
    "end": "3108680"
  },
  {
    "text": "running hot-hot capacity that's obviously much more cost-effective but as you go into",
    "start": "3108680",
    "end": "3115010"
  },
  {
    "text": "more near zero downtime in an active-active scenario that your complexity increases and so does your",
    "start": "3115010",
    "end": "3121430"
  },
  {
    "text": "costs again from a multi region options",
    "start": "3121430",
    "end": "3127310"
  },
  {
    "start": "3123000",
    "end": "3123000"
  },
  {
    "text": "just to give you a quick overview about the multi regions options from an RPO perspective if you go all native with",
    "start": "3127310",
    "end": "3134720"
  },
  {
    "text": "AWS you will have a gain higher RPO because you would have to rely on",
    "start": "3134720",
    "end": "3140380"
  },
  {
    "text": "asynchronous replication of data set from region 1 to region 2 but if you",
    "start": "3140380",
    "end": "3145490"
  },
  {
    "text": "want to leverage say if you're having some untrim technologies that you want to have you know replicate data so that",
    "start": "3145490",
    "end": "3153650"
  },
  {
    "text": "you could absolutely do that using your custom solution but again there is a lot of operational overhead and engineering",
    "start": "3153650",
    "end": "3160880"
  },
  {
    "text": "overhead to do do that right so it it all depends on the data classification how do you define your is it",
    "start": "3160880",
    "end": "3167900"
  },
  {
    "text": "one app or is it tier 4 app is it mission critical or is this something that you can live it with replication",
    "start": "3167900",
    "end": "3175579"
  },
  {
    "text": "lag of a few seconds to a few minutes so that is something that you can you have to decide but essentially sync versus a",
    "start": "3175579",
    "end": "3182599"
  },
  {
    "text": "synchro application options are listed here if you are highly consistent and",
    "start": "3182599",
    "end": "3188779"
  },
  {
    "text": "you want even zero downtime that that's something you that you have to do using custom DB and custom replication",
    "start": "3188779",
    "end": "3195079"
  },
  {
    "text": "strategies just so we're clear on that and simple high availability plan again",
    "start": "3195079",
    "end": "3201410"
  },
  {
    "text": "we discussed this between the most common pattern is go send most of your",
    "start": "3201410",
    "end": "3206420"
  },
  {
    "text": "traffic to region 1 and always send a little bit of a traffic to region 2 just to make sure your your dr strategy is",
    "start": "3206420",
    "end": "3214549"
  },
  {
    "text": "working you don't have to do your annual dr testing right this way you are actually continuously testing whether",
    "start": "3214549",
    "end": "3220849"
  },
  {
    "text": "your the functionality is up and running the only caveat here is for some traffic",
    "start": "3220849",
    "end": "3226160"
  },
  {
    "text": "that is going to region 2 you should expect a little bit of a latency because you're going cross region for the database connection so that that's a",
    "start": "3226160",
    "end": "3233000"
  },
  {
    "text": "very important for uncoupled multi-region rights so again as",
    "start": "3233000",
    "end": "3238579"
  },
  {
    "text": "discussed uh Oliver has discussed it they have already implemented something like this so you can essentially that's",
    "start": "3238579",
    "end": "3243980"
  },
  {
    "text": "it that's a pattern we have seen that multiple customers deploy that pattern and again the goal is is to set up your",
    "start": "3243980",
    "end": "3252319"
  },
  {
    "text": "cost region replication with buckets and you're doing the the sync synchronous writes to a cache layer and",
    "start": "3252319",
    "end": "3258440"
  },
  {
    "text": "a synchronous writing to Amazon s3 and then you are doing CRR for cross region",
    "start": "3258440",
    "end": "3263650"
  },
  {
    "text": "and for similarly multi-region reads again you could do that similar pattern",
    "start": "3263650",
    "end": "3270650"
  },
  {
    "text": "using cash for reads and if there is a cache miss you go to s3 to fetch your",
    "start": "3270650",
    "end": "3276020"
  },
  {
    "text": "data same thing with again you can do use your cross region replication for the",
    "start": "3276020",
    "end": "3281630"
  },
  {
    "text": "data across the other region the the whole idea here is it depending depending upon your RTR pure",
    "start": "3281630",
    "end": "3288230"
  },
  {
    "text": "requirements you may want to tweak this design these patterns to suit your workload key takeaways quickly if s3",
    "start": "3288230",
    "end": "3299150"
  },
  {
    "start": "3293000",
    "end": "3293000"
  },
  {
    "text": "supports thousands of TPS so it's possible to scale that and we spoke about prefix manipulation to do",
    "start": "3299150",
    "end": "3306810"
  },
  {
    "text": "that parallelizing gets and puts is extremely important please have retries I cannot emphasize enough how important",
    "start": "3306810",
    "end": "3313530"
  },
  {
    "text": "it is to bake that into your process make sure if you ever encounter anything like a 500 or 5 X X have a reach wire",
    "start": "3313530",
    "end": "3320640"
  },
  {
    "text": "mechanism last one percent meaning 99% of your throughput requirements can be",
    "start": "3320640",
    "end": "3326640"
  },
  {
    "text": "met with the design patterns that we have already discussed that 1% takes significant effort so there are many",
    "start": "3326640",
    "end": "3333359"
  },
  {
    "text": "ways to do this as long as it's a regional solution that you are developing these patterns most likely",
    "start": "3333359",
    "end": "3340260"
  },
  {
    "text": "will work if it's a cross region pattern you would have to think about how you are baking in your compensation how are",
    "start": "3340260",
    "end": "3346320"
  },
  {
    "text": "you writing to two different regions and doing commits or synchronous replication and things like that so keep that in",
    "start": "3346320",
    "end": "3351839"
  },
  {
    "text": "mind sse KMS is good for most use cases that i have seen right AES 256 encryption it",
    "start": "3351839",
    "end": "3359250"
  },
  {
    "text": "makes a lot of InfoSec people happy because that that gives them the confidence that did data is secured be",
    "start": "3359250",
    "end": "3365700"
  },
  {
    "text": "it PII data or or your business intelligence data right and there is a",
    "start": "3365700",
    "end": "3371250"
  },
  {
    "text": "very low kms overhead with respect to objects and metadata again keep in mind",
    "start": "3371250",
    "end": "3378240"
  },
  {
    "text": "if you are doing a list operations on billions of objects of course there will",
    "start": "3378240",
    "end": "3383609"
  },
  {
    "text": "be latency so you need to have a meta store metadata associated with that objects stored somewhere else and that's",
    "start": "3383609",
    "end": "3389369"
  },
  {
    "text": "exactly what Oliver was talking about in terms of having markers database in a post quest database or RDS database so",
    "start": "3389369",
    "end": "3396839"
  },
  {
    "text": "keep that in mind you may want to as yours as you scale your operations on s3 make sure you have a meta data store",
    "start": "3396839",
    "end": "3403200"
  },
  {
    "text": "somewhere I'm not saying RDS is the only way to do it you could do dynamo DB EPS we have seen a lot of customers do that",
    "start": "3403200",
    "end": "3409260"
  },
  {
    "text": "so make sure you do that cash in for predictable low latency again if you cannot if you have to compensate for",
    "start": "3409260",
    "end": "3415619"
  },
  {
    "text": "latency or latency spikes you can always cash in yes some of you may be familiar",
    "start": "3415619",
    "end": "3420900"
  },
  {
    "text": "with dynamo DB they have launched an offering called Dax dynamo DB accelerator the idea is having a cash",
    "start": "3420900",
    "end": "3427619"
  },
  {
    "text": "layer in front of dynamo DB pretty much that's something you may want to replicate on s3 side",
    "start": "3427619",
    "end": "3434530"
  },
  {
    "text": "for low latency requests keep in mind if you are shooting for four nines of",
    "start": "3434530",
    "end": "3439960"
  },
  {
    "text": "availability for your application if that's what your your engineering goal is then make sure you do a read and",
    "start": "3439960",
    "end": "3447340"
  },
  {
    "text": "write from both regions I mean to to region architecture and you have to think about how are you going to",
    "start": "3447340",
    "end": "3453250"
  },
  {
    "text": "replicate the data how consistent the data has to be can you tolerate a little bit of latency from one region to",
    "start": "3453250",
    "end": "3461290"
  },
  {
    "text": "another if you can tolerate that and how can you know what is the latency using",
    "start": "3461290",
    "end": "3466300"
  },
  {
    "text": "cloud watch please use that and measure that and as also something that Oliveira",
    "start": "3466300",
    "end": "3472510"
  },
  {
    "text": "has mentioned going bigger instances is not necessarily the better option always",
    "start": "3472510",
    "end": "3477670"
  },
  {
    "text": "right there you have to measure the throughput and see whether you want to scale horizontally to get your",
    "start": "3477670",
    "end": "3484060"
  },
  {
    "text": "performance characteristics and again be a little unconventional s3 is is is an",
    "start": "3484060",
    "end": "3490330"
  },
  {
    "text": "amazing service you can certainly continue to improve on the performance and for 99 percent of the transactions",
    "start": "3490330",
    "end": "3497140"
  },
  {
    "text": "what we have observed for specific workload is under 300 milliseconds requirement that's the target right 99",
    "start": "3497140",
    "end": "3504100"
  },
  {
    "text": "percent under 300 milliseconds and we've added benefits of better availability",
    "start": "3504100",
    "end": "3509230"
  },
  {
    "text": "better TCO so that's that's extremely important takeaway you with reducing TCO",
    "start": "3509230",
    "end": "3514420"
  },
  {
    "text": "cause thank you [Applause]",
    "start": "3514420",
    "end": "3521389"
  }
]
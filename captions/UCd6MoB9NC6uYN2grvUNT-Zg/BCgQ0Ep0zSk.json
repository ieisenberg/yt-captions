[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "hi my name is Matt I'm a Solutions Architect AWS I actually lead the",
    "start": "530",
    "end": "7470"
  },
  {
    "text": "solutions architecture team for our technology partners for our top technology partners and associated",
    "start": "7470",
    "end": "12599"
  },
  {
    "text": "programs globally I've been with AWS for about four and a half years which i",
    "start": "12599",
    "end": "17670"
  },
  {
    "text": "think translates into 49 years in earth years now I'm doing this for a while I might",
    "start": "17670",
    "end": "23550"
  },
  {
    "text": "have seen some of you in in other similar big data presentation so I'm really excited to be here today because",
    "start": "23550",
    "end": "28740"
  },
  {
    "text": "things changed this morning I don't know how many of you caught the keynote for their sermon Alison Syme going to try to",
    "start": "28740",
    "end": "35130"
  },
  {
    "text": "talk about some of the new services my main goal here though today with you is really to make sense of our platform for",
    "start": "35130",
    "end": "42750"
  },
  {
    "start": "38000",
    "end": "83000"
  },
  {
    "text": "your business case I feel really passionately about this we talk a lot about design patterns about AWS services",
    "start": "42750",
    "end": "48860"
  },
  {
    "text": "but sometimes we kind of need to take a step back and ask ourselves the question you know what business case what problem",
    "start": "48860",
    "end": "55020"
  },
  {
    "text": "am I actually trying to solve what's the right tool for the job so if you take away anything from today's presentation",
    "start": "55020",
    "end": "60570"
  },
  {
    "text": "I hope that it's a deeper knowledge of what Big Data tools you can use from our portfolio to solve your actual business",
    "start": "60570",
    "end": "66510"
  },
  {
    "text": "cases your actual use cases we can't do all of it so I'm gonna give you a little vignette try to tell us",
    "start": "66510",
    "end": "72600"
  },
  {
    "text": "some stories give you some real-world context but I want to hear from you too so I'll hang around after the talk and happy to answer questions and try to map",
    "start": "72600",
    "end": "79530"
  },
  {
    "text": "your business case your context to our services because we have an increasing number of services at AWS and the big",
    "start": "79530",
    "end": "85710"
  },
  {
    "start": "83000",
    "end": "534000"
  },
  {
    "text": "data portfolio alone this doesn't even capture all of it to be honest there's a new one on there Athena that we",
    "start": "85710",
    "end": "92460"
  },
  {
    "text": "announced this morning I'll be talking a little bit more about about that today and so I think when you first come to",
    "start": "92460",
    "end": "97740"
  },
  {
    "text": "the AWS platform and the big data set of services specifically it could be a little bit overwhelming the beginning",
    "start": "97740",
    "end": "103590"
  },
  {
    "text": "because there's a lot of services and it's hard to map those immediately to the problems that you're actually trying",
    "start": "103590",
    "end": "108840"
  },
  {
    "text": "to solve so if we think about big data or analytics in general I'd like to break",
    "start": "108840",
    "end": "114450"
  },
  {
    "text": "it down into the three areas you know the first thing that is actually a tough problem is collecting that data storing",
    "start": "114450",
    "end": "119759"
  },
  {
    "text": "that data so you need to get it into the cloud to do something with it and that's not a trivial problem when you have",
    "start": "119759",
    "end": "126530"
  },
  {
    "text": "petabytes and terabytes of data you might have seen a truck drive on steady on stage this morning we'll get to that",
    "start": "126530",
    "end": "132720"
  },
  {
    "text": "later it goes a long way to solving some of that data movement and collection problems Greengrass was another thing",
    "start": "132720",
    "end": "138840"
  },
  {
    "text": "that was announced recently and that allows you to capture to essentially create IOT hubs to collect Internet of",
    "start": "138840",
    "end": "145590"
  },
  {
    "text": "Things data on-premises that you can eventually analyze there's a number of ways you can collect data on AWS the ones I'm going to talk about today",
    "start": "145590",
    "end": "151500"
  },
  {
    "text": "though or Direct Connect which essentially allows you to create a physical connection between your",
    "start": "151500",
    "end": "157980"
  },
  {
    "text": "on-premises data centers or colocation facilities and AWS data centers you can have a lower latency in many cases",
    "start": "157980",
    "end": "164909"
  },
  {
    "text": "faster connection to the cloud from your data centers it'll be a snowball so we saw snowball",
    "start": "164909",
    "end": "171209"
  },
  {
    "text": "edge and you'll see some out of date slides things change so quickly I didn't get a chance to change all my slides so snowball edge and snowmobile came out",
    "start": "171209",
    "end": "177629"
  },
  {
    "text": "today Kinesis is increasingly important you know as recently as two three years ago when I was giving these talks it was",
    "start": "177629",
    "end": "183719"
  },
  {
    "text": "mostly about batch analytics it was like let's get the data into s3 into the cloud and then let's process a lot of it",
    "start": "183719",
    "end": "190709"
  },
  {
    "text": "overnight even as recently as two or three years ago people using hive on EMR it would take a day or two sometimes to",
    "start": "190709",
    "end": "197549"
  },
  {
    "text": "process data things have changed incredibly now people are processing data in real time and it's become the",
    "start": "197549",
    "end": "203069"
  },
  {
    "text": "norm again giving this talk a year or two ago and real-time data stream was still",
    "start": "203069",
    "end": "208680"
  },
  {
    "text": "something that people were finding new and hard and there was so many frameworks now it's kind of something that is everyone is doing we've made it",
    "start": "208680",
    "end": "214739"
  },
  {
    "text": "easier with Kinesis to do in Kinesis analytics and other tools we'll talk about but real-time analytics is",
    "start": "214739",
    "end": "220189"
  },
  {
    "text": "becoming the new just analytics you know when people talk about analytics and people talk about big data very often",
    "start": "220189",
    "end": "226049"
  },
  {
    "text": "it's streaming out of the box then of course AWS IOT I just briefly mentioned green grass grass is a wonderful way for",
    "start": "226049",
    "end": "233759"
  },
  {
    "text": "you to build your own or to buy green grass supported appliances that can aggregate and collect data on premises",
    "start": "233759",
    "end": "239250"
  },
  {
    "text": "or you're just simply pushing it up to the AWS IOT service but IOT is also an important part of the big data story now",
    "start": "239250",
    "end": "246239"
  },
  {
    "text": "everything is connected it's not just sort of computers and log files anymore it's all sorts of data from the edge and",
    "start": "246239",
    "end": "252780"
  },
  {
    "text": "importantly we need to get that data and store it somewhere so the second part is storage and storage is also not a",
    "start": "252780",
    "end": "258959"
  },
  {
    "text": "trivial problem and it's something that I think is the most compelling part of the Big Data story for AWS because on",
    "start": "258959",
    "end": "266030"
  },
  {
    "text": "premises if you want to build a Hadoop cluster or data warehouse but let's start with a Duke you need to actually",
    "start": "266030",
    "end": "271340"
  },
  {
    "text": "couple your storage requirements with your compute requirements if you need 100 terabytes you need enough servers",
    "start": "271340",
    "end": "277759"
  },
  {
    "text": "with drives in them to equal that hundred terabytes in AWS you can totally the couple it you can store as much as",
    "start": "277759",
    "end": "283520"
  },
  {
    "text": "you want an s3 and then spin up the compute capacity on demand or queried it using Athena as of this morning so by",
    "start": "283520",
    "end": "290449"
  },
  {
    "text": "decoupling storage and sort of taking that as a separate problem in AWS you",
    "start": "290449",
    "end": "295580"
  },
  {
    "text": "can reduce your costs and really make more elegant solutions that are not only cheaper but much more powerful over time",
    "start": "295580",
    "end": "301970"
  },
  {
    "text": "but storage so s3 why is this three good s3 is kind of ties the room together it's a the place to put your data",
    "start": "301970",
    "end": "309319"
  },
  {
    "text": "increasingly people are talking about data lakes on s3 it's a bit of a buzz term but it actually makes a lot of",
    "start": "309319",
    "end": "314900"
  },
  {
    "text": "sense as a place to put all your data so you can access it using different tools for different business problems I've",
    "start": "314900",
    "end": "321229"
  },
  {
    "text": "learned anything over the years it's that no business is the same and therefore the tools that you use to",
    "start": "321229",
    "end": "326750"
  },
  {
    "text": "access that data and process them are going to be different different be use need different tools and again the",
    "start": "326750",
    "end": "332060"
  },
  {
    "text": "flexibility of Amazon means that you can have someone using a data warehouse over here someone else using lambda over here",
    "start": "332060",
    "end": "337070"
  },
  {
    "text": "so when else using Hadoop and that's cool and have all that data living centrally in s3 it's highly reliable",
    "start": "337070",
    "end": "342979"
  },
  {
    "text": "it's affordable it's a great place to just stick your data now we're getting to the point though",
    "start": "342979",
    "end": "348259"
  },
  {
    "text": "the people are collecting data for years and they're like man I have you know 400 petabytes of data this is despite the",
    "start": "348259",
    "end": "355009"
  },
  {
    "text": "extremely low cost of s3 it's you know my bills starting to take up a little bit so glacier is great and now you have",
    "start": "355009",
    "end": "360620"
  },
  {
    "text": "glacier fast retrieval and other things coming out that make it not only cost",
    "start": "360620",
    "end": "365630"
  },
  {
    "text": "effective but also easier to store your data in cold storage I worked with a",
    "start": "365630",
    "end": "371300"
  },
  {
    "text": "customer that has containers literally big shipping containers like the one we saw this morning just peppering their",
    "start": "371300",
    "end": "376729"
  },
  {
    "text": "lawn you know dozens of them they're each filled with tapes that's their cold storage it's actually pretty hot inside those containers that world is going",
    "start": "376729",
    "end": "384050"
  },
  {
    "text": "away it wasn't so long ago the enterprise has all had you know old abandoned mines filled with tapes or",
    "start": "384050",
    "end": "389120"
  },
  {
    "text": "drives for real and now people are moving that kind of cold storage data into glacier because you can use that old data as part of your big dinner",
    "start": "389120",
    "end": "395449"
  },
  {
    "text": "story and now that you can process petabytes time easily often you know in a matter of hours if",
    "start": "395449",
    "end": "402430"
  },
  {
    "text": "minutes sometimes you can make use of that whole data to add to the richness of the context to solve your business",
    "start": "402430",
    "end": "407830"
  },
  {
    "text": "case with more data so not all data is cold or slow that's",
    "start": "407830",
    "end": "413050"
  },
  {
    "text": "why we have services like dynamodb which is our management of sequel service and then Amazon Elastic search service which",
    "start": "413050",
    "end": "418870"
  },
  {
    "text": "is a managed elastic search service so these are services to do things like full-text query with elastic search or",
    "start": "418870",
    "end": "425380"
  },
  {
    "text": "or schema-less or sort a sequel less no sequel query that's a",
    "start": "425380",
    "end": "431800"
  },
  {
    "text": "really fast high-speed data store in dynamodb you need hot data fast data you need to cache some data you need to",
    "start": "431800",
    "end": "437530"
  },
  {
    "text": "retrieve it very quickly these are great services for that and they're part of the big story as well a lot of people talk about the lambda architecture not",
    "start": "437530",
    "end": "444730"
  },
  {
    "text": "AWS lambda that the lambda architecture and really that's just a fancy way of saying it's important to think of your",
    "start": "444730",
    "end": "450580"
  },
  {
    "text": "data not just as a single thing but to tear your data to have some data that is hot you need to access right away and",
    "start": "450580",
    "end": "457060"
  },
  {
    "text": "some data down in cold storage that you don't always need all the time and to put it in different services depending",
    "start": "457060",
    "end": "462550"
  },
  {
    "text": "on how quickly you need that data what you need to do with that data so think of your data is a living thing and don't be afraid to store pieces of your data",
    "start": "462550",
    "end": "468970"
  },
  {
    "text": "in different services depending on what you need to do with it and that's why we have multiple data storage services and",
    "start": "468970",
    "end": "474520"
  },
  {
    "text": "then of course the fun part the analytics so we have an increasing array of analytics services I'm not really",
    "start": "474520",
    "end": "479950"
  },
  {
    "text": "going to get into Amazon ai I was just playing with Polly does anyone mess with Polly recognition if you get bored with",
    "start": "479950",
    "end": "485740"
  },
  {
    "text": "my talk I strongly recommend it try the french-canadian accent it's pretty cool but there's an increasing amount of ways",
    "start": "485740",
    "end": "491740"
  },
  {
    "text": "to process your data to derive value and this is what analyzes you know people",
    "start": "491740",
    "end": "497230"
  },
  {
    "text": "use a lot of buzzwords in big data but what is all about is deriving value from your data take a bunch of logs and",
    "start": "497230",
    "end": "502450"
  },
  {
    "text": "figure out what is going on figure out some anomaly that you didn't even know exists some spending trend that you can",
    "start": "502450",
    "end": "510310"
  },
  {
    "text": "change the way you you procure things for your retail website so this is what all these services are for and I'm going",
    "start": "510310",
    "end": "515979"
  },
  {
    "text": "to try and put these services most importantly in context a little bit when should you use redshift when do I think",
    "start": "515979",
    "end": "521020"
  },
  {
    "text": "you should you stretch it when should you use EMR when is Athena appropriate so this is Matt's opinion that you're",
    "start": "521020",
    "end": "527050"
  },
  {
    "text": "going to hear today you may have a slightly different view of this but I'll try to give you some guidance based on what I've seen in the four and a half",
    "start": "527050",
    "end": "532100"
  },
  {
    "text": "years so where do most people start I think most people start with a data warehouse",
    "start": "532100",
    "end": "539230"
  },
  {
    "start": "534000",
    "end": "666000"
  },
  {
    "text": "actually most people usually start with something like an Aurora an Aurora is a wonderful big data service actually but",
    "start": "539230",
    "end": "544850"
  },
  {
    "text": "there's a difference between like a relational database and something like an OLTP a transactional database in an",
    "start": "544850",
    "end": "550730"
  },
  {
    "text": "OLAP database or a data warehouse they're actually built differently to do different types of queries and so",
    "start": "550730",
    "end": "556490"
  },
  {
    "text": "redshift is designed to do queries against huge amounts of data but also data that has for example really really",
    "start": "556490",
    "end": "563450"
  },
  {
    "text": "wide tables where you don't and where you need to say you say you have a table with 30 columns and you don't",
    "start": "563450",
    "end": "570050"
  },
  {
    "text": "necessarily need all of the data in every column for every query right this is where red redshift really really",
    "start": "570050",
    "end": "575630"
  },
  {
    "text": "shines because it's optimized its columnar data storage so if you say show me all mats with blue shirts on it'll",
    "start": "575630",
    "end": "582350"
  },
  {
    "text": "only look at the name column and the shirt column and pull out that data very quickly because it's optimized to look",
    "start": "582350",
    "end": "588110"
  },
  {
    "text": "down columns of data very quickly instead of rows of data like in most relational databases so for huge huge",
    "start": "588110",
    "end": "594950"
  },
  {
    "text": "huge data sets where the data is structured and or perhaps you already",
    "start": "594950",
    "end": "600050"
  },
  {
    "text": "have in a data warehouse or or relational database what I most often see is just a huge honkin my sequel",
    "start": "600050",
    "end": "605240"
  },
  {
    "text": "database on premises that people have been sort of keeping alive for years you can put that in a red shift and suddenly",
    "start": "605240",
    "end": "611150"
  },
  {
    "text": "your data becomes much more accessible and ultimately cheaper so red shift is a",
    "start": "611150",
    "end": "616580"
  },
  {
    "text": "great place to start if you have structured data if the people in your business are used to using sequel to",
    "start": "616580",
    "end": "622220"
  },
  {
    "text": "query data so standard sequel columnar data storage is optimized it's truly an",
    "start": "622220",
    "end": "629120"
  },
  {
    "text": "enterprise grade data warehouse and the cool thing about redshift 2 is it's very affordable on the low end when you've drawn that much data but you can also",
    "start": "629120",
    "end": "635510"
  },
  {
    "text": "grow it to an incredible size so redshift is kind of here to stay and you can bet that it will evolve over",
    "start": "635510",
    "end": "641990"
  },
  {
    "text": "time redshift is a great place to put your data today to provide use the same tools if you're using tableau or",
    "start": "641990",
    "end": "648350"
  },
  {
    "text": "different BI tools or analytics tools in almost all cases they just work with",
    "start": "648350",
    "end": "653480"
  },
  {
    "text": "redshift so it's very low friction way to start analyzing your big data in the cloud your people don't have to learn",
    "start": "653480",
    "end": "659180"
  },
  {
    "text": "new stuff you don't have to change your tools you could just start using it right away",
    "start": "659180",
    "end": "665170"
  },
  {
    "start": "666000",
    "end": "695000"
  },
  {
    "text": "so that's easy right you know just start using redshift well then you're like oh man but I have 100 terabytes of data and",
    "start": "666279",
    "end": "673550"
  },
  {
    "text": "that's you know I have a ADSL line that's going to take a long time to upload so how do I get my data into the",
    "start": "673550",
    "end": "679820"
  },
  {
    "text": "cloud this is actually a major problem for a lot of companies I mean if you notice from the keynote and some of the services were releasing like snowmobile",
    "start": "679820",
    "end": "685760"
  },
  {
    "text": "and snowball edge this is something we hear from our customers and this is why we're coming out with these services moving data into the cloud is a major",
    "start": "685760",
    "end": "692899"
  },
  {
    "text": "challenge not just for enterprises for anybody so how do you get your data in there so that you can actually query it",
    "start": "692899",
    "end": "699199"
  },
  {
    "start": "695000",
    "end": "831000"
  },
  {
    "text": "with redshift and this is something you should think of up front too often I see people spinning up infrastructure they're like great we're all set where's",
    "start": "699199",
    "end": "704360"
  },
  {
    "text": "the data and then they have to wait two weeks because they forgot about that part so there's a lot of ways you can",
    "start": "704360",
    "end": "709519"
  },
  {
    "text": "upload your data and in fact I talked to a lot of people what should I use to upload my data honestly most of the time",
    "start": "709519",
    "end": "715250"
  },
  {
    "text": "the answer is the command line interface the AWS command line interface it does like multi-threading it has parallel",
    "start": "715250",
    "end": "721339"
  },
  {
    "text": "opens parallel threads to upload it's very fast and in almost all cases it's",
    "start": "721339",
    "end": "726709"
  },
  {
    "text": "going to beat much more expensive options now there are times when you're transferring data across continents",
    "start": "726709",
    "end": "732649"
  },
  {
    "text": "where latency becomes a factor that's why we have s3 accelerated sorry cloud",
    "start": "732649",
    "end": "737990"
  },
  {
    "text": "front based accelerated transfers to s3 and there's a lot of great third-party partner tools to move data but generally",
    "start": "737990",
    "end": "743209"
  },
  {
    "text": "speaking for most people uploading using the CLI is going to be perfect now if you're over that ADSL line or whatever",
    "start": "743209",
    "end": "750620"
  },
  {
    "text": "line you're using it's not going to always suit your needs so this is where snowball comes in handy you can load up",
    "start": "750620",
    "end": "756230"
  },
  {
    "text": "your snowball edge device or snowmobile truck if you're a giant enterprise and literally ship it to us now a Direct Connect is another option",
    "start": "756230",
    "end": "763370"
  },
  {
    "text": "Direct Connect doesn't necessarily make things faster you can essentially string up a fiber or a series of fibers between",
    "start": "763370",
    "end": "768949"
  },
  {
    "text": "your Colo facilities or your on-premises data centers and us but it definitely",
    "start": "768949",
    "end": "774529"
  },
  {
    "text": "makes it lower latency in a lot of cases faster and it's reliable if you have these private who private as a key word",
    "start": "774529",
    "end": "780170"
  },
  {
    "text": "here connections between your data centers and ours and private is key I",
    "start": "780170",
    "end": "785300"
  },
  {
    "text": "say that because a lot of people for various reasons whether it's compliance or otherwise may not want to transfer that data over the Internet to us or",
    "start": "785300",
    "end": "792860"
  },
  {
    "text": "maybe they don't have enough data or a business case to use snowmobile so this is where Direct Connect become great you",
    "start": "792860",
    "end": "798020"
  },
  {
    "text": "can effectively have a private connection between a hermetically-sealed V PC and AWS with running redshift for",
    "start": "798020",
    "end": "804200"
  },
  {
    "text": "example and your data center with no internet connectivity at all but data flowing between them and then we have",
    "start": "804200",
    "end": "811100"
  },
  {
    "text": "database migration service which is a great tool to actually just pick up your database on-premises and",
    "start": "811100",
    "end": "816770"
  },
  {
    "text": "move it into the cloud so a lot of different ways this is not all of them but these are some of the ones I see most often but what I see most often",
    "start": "816770",
    "end": "823160"
  },
  {
    "text": "honestly though is the command line tool with s3 works very well so start there work backwards get your data into",
    "start": "823160",
    "end": "829310"
  },
  {
    "text": "redshift start querying so data mix migration service is",
    "start": "829310",
    "end": "834620"
  },
  {
    "start": "831000",
    "end": "857000"
  },
  {
    "text": "relatively new I think a lot of people weren't aware of it so this is why I wanted to put it up here on the screen",
    "start": "834620",
    "end": "840680"
  },
  {
    "text": "for you I don't know why there's only one logo there I think when they resize my slides it supports multiple database",
    "start": "840680",
    "end": "846200"
  },
  {
    "text": "engines not just STP so you can use database migration service to pick up a variety of",
    "start": "846200",
    "end": "851360"
  },
  {
    "text": "on-premises databases and move them into the cloud very easily",
    "start": "851360",
    "end": "856780"
  },
  {
    "start": "857000",
    "end": "876000"
  },
  {
    "text": "there they are Postgres Oracle my sequel Moorea sequel server so it covers most",
    "start": "857500",
    "end": "863810"
  },
  {
    "text": "use cases most of us have an old my sequel database or sequel server on-premises this makes it super easy to",
    "start": "863810",
    "end": "868820"
  },
  {
    "text": "move into the cloud and you can target redshift or a variety of different locations as well",
    "start": "868820",
    "end": "875470"
  },
  {
    "start": "876000",
    "end": "944000"
  },
  {
    "text": "so this is an old slide now because we had the keynote this morning and I totally forgot that I had to update this",
    "start": "876250",
    "end": "882110"
  },
  {
    "text": "slide I thought they were announcing that stuff tomorrow so you can ignore parts of this we have snowball edge which actually now supports a hundred",
    "start": "882110",
    "end": "888530"
  },
  {
    "text": "terabytes and has 40 gig connectivity you can do up to 14 gigabits per second I think so you can move data very very",
    "start": "888530",
    "end": "896060"
  },
  {
    "text": "quickly to these devices and then drop them because they won't break when you drop them there they're highly rugged",
    "start": "896060",
    "end": "901820"
  },
  {
    "text": "they're designed for the military and then ship them to AWS and I used to make this joke a lot and it still holds true",
    "start": "901820",
    "end": "908240"
  },
  {
    "text": "actually a lot of the time like FedEx or in this case a giant shipping container is faster than the internet",
    "start": "908240",
    "end": "915730"
  },
  {
    "text": "unless you have the luxury of you know multi Google Fiber in your house or huge",
    "start": "915730",
    "end": "921050"
  },
  {
    "text": "connectivity chances are that snowball and snowmobile are going to be faster for moving a lot of big data to the",
    "start": "921050",
    "end": "926150"
  },
  {
    "text": "cloud than just over the Internet so consider it it's I think it's 300 bucks",
    "start": "926150",
    "end": "931720"
  },
  {
    "text": "for snowball if I'm not mistaken not up on the latest pricing and it's very actually affordable way to",
    "start": "931720",
    "end": "939400"
  },
  {
    "text": "move a ton of data into the cloud so you can get started processing so that's great you know you get your",
    "start": "939400",
    "end": "945550"
  },
  {
    "start": "944000",
    "end": "979000"
  },
  {
    "text": "data you start querying redshift it's awesome the problem is when you do select star for a map where shirts are",
    "start": "945550",
    "end": "951220"
  },
  {
    "text": "blue and you get this sort of sequel dump out of red ship we're trying to solve a real-world business problem and",
    "start": "951220",
    "end": "957310"
  },
  {
    "text": "if you show that sort of raw output to your CEO or CIO or CTO it doesn't really",
    "start": "957310",
    "end": "962620"
  },
  {
    "text": "help anybody it doesn't tell a story you can do the craziest join in the world but most people don't want to look at",
    "start": "962620",
    "end": "969220"
  },
  {
    "text": "raw out but you need a dashboard and so you need something like a third party solution like tableau or you need any",
    "start": "969220",
    "end": "975610"
  },
  {
    "text": "variety of or clique or these various BI tools that we have or now you can use quick site and quick site is also a",
    "start": "975610",
    "end": "982600"
  },
  {
    "start": "979000",
    "end": "1049000"
  },
  {
    "text": "relatively new service that allows you to visualize your data and it there's there's danger in graphs but there's",
    "start": "982600",
    "end": "988570"
  },
  {
    "text": "also a lot of beauty in graphs you can allows you to tell stories and one of the things that I like most about quick site is that you can take these",
    "start": "988570",
    "end": "995400"
  },
  {
    "text": "snapshots of your data and string them together to create data visualization",
    "start": "995400",
    "end": "1000600"
  },
  {
    "text": "stories and they're incredibly powerful it's very easy to use just go to quick site AWS to sign up and the cool thing",
    "start": "1000600",
    "end": "1008040"
  },
  {
    "text": "about quick site is you can point it at a variety of different data sources and really get started in just a couple minutes so I say this is this isn't",
    "start": "1008040",
    "end": "1014940"
  },
  {
    "text": "about the processing this is actually extremely important and often you know us data nerds we forget that visualization is extremely important to",
    "start": "1014940",
    "end": "1021020"
  },
  {
    "text": "deriving value from your data and quick site makes that extremely easy honestly in five minutes just with any data take",
    "start": "1021020",
    "end": "1028829"
  },
  {
    "text": "your logs or your logs from your billing usage for example of AWS point quick",
    "start": "1028829",
    "end": "1034170"
  },
  {
    "text": "site to that and you can start pulling up beautiful graphs and data visualization in just minutes",
    "start": "1034170",
    "end": "1040280"
  },
  {
    "text": "so now we have our data into redshift and we can visualize it",
    "start": "1041180",
    "end": "1046589"
  },
  {
    "text": "using quick site that's great right we're done well the issue is what if your data isn't structured I dropped",
    "start": "1046589",
    "end": "1053010"
  },
  {
    "start": "1049000",
    "end": "1142000"
  },
  {
    "text": "that word before structured redshift when you move data into it it has to be well structured what that means is that",
    "start": "1053010",
    "end": "1058560"
  },
  {
    "text": "if say you have CSV files the you have 10 words or 10 values in a row separated",
    "start": "1058560",
    "end": "1065390"
  },
  {
    "text": "by commas those 10 values have to correspond to 10 columns in a redshift database but what if you have a bunch of",
    "start": "1065390",
    "end": "1072080"
  },
  {
    "text": "different data sources and you don't have the luxury of everything being nice CSV files with 10 columns on every line",
    "start": "1072080",
    "end": "1077140"
  },
  {
    "text": "how do you actually manipulate and change that data what if people are sending you logs from different vendors different be use what if some is JSON",
    "start": "1077140",
    "end": "1083900"
  },
  {
    "text": "some is XML some a CSV how do you normalize that data and structure it to get an in red shift what if you don't",
    "start": "1083900",
    "end": "1090530"
  },
  {
    "text": "need all that data what if you only need to actually care about a subset of that data what if you're dumping all your raw",
    "start": "1090530",
    "end": "1096050"
  },
  {
    "text": "data in s3 but in redshift or in dynamodb or wherever you're ultimately putting that data you don't need every",
    "start": "1096050",
    "end": "1101660"
  },
  {
    "text": "column you don't need to realign there's certain conditions you don't waste money by loading a bunch of data into redshift",
    "start": "1101660",
    "end": "1108170"
  },
  {
    "text": "that you don't necessarily need for your queries right so it's important to not just normalize your data but also think",
    "start": "1108170",
    "end": "1113600"
  },
  {
    "text": "about what data do I need for the particular location and use case that I'm solving so if I'm putting it into",
    "start": "1113600",
    "end": "1120020"
  },
  {
    "text": "DynamoDB if it's your hot data maybe you just need a very small subset of it so manipulating and changing data becomes",
    "start": "1120020",
    "end": "1126740"
  },
  {
    "text": "actually another non-trivial problem you know you got your data you load up 100 terabytes of data into s3 ready to load",
    "start": "1126740",
    "end": "1133910"
  },
  {
    "text": "into redshift oh man now I have a hundred terabytes of unstructured data how am I going to possibly process that and change it such that it can live in",
    "start": "1133910",
    "end": "1140660"
  },
  {
    "text": "regice well there's a couple ways of thinking about this these days I'm one",
    "start": "1140660",
    "end": "1145820"
  },
  {
    "start": "1142000",
    "end": "1225000"
  },
  {
    "text": "is so hot on serverless right so first thing people say to me I'll just use lambda it works yes you can have s3",
    "start": "1145820",
    "end": "1153920"
  },
  {
    "text": "events for example when you put a file into s3 a contribute event which triggers the lambda function which does",
    "start": "1153920",
    "end": "1159320"
  },
  {
    "text": "some basic ETL or transformations to that data that works well and for a lot",
    "start": "1159320",
    "end": "1164810"
  },
  {
    "text": "of use cases that's a great place to start but when you're talking about hundreds of terabytes of data or complicated",
    "start": "1164810",
    "end": "1170780"
  },
  {
    "text": "manipulations or if you want to take advantage of the rich ecosystem of people who have already done this and",
    "start": "1170780",
    "end": "1176420"
  },
  {
    "text": "have written libraries to do complex transformations like Omniture logs I don't know if any of you work with those famously nasty very the old ones anyway",
    "start": "1176420",
    "end": "1186080"
  },
  {
    "text": "that really essentially translates into a really wide database table you don't need half the data in there so they're",
    "start": "1186080",
    "end": "1191990"
  },
  {
    "text": "there I promise you a hundred thousand people who have so this problem before you don't need to write a ruby script to",
    "start": "1191990",
    "end": "1197600"
  },
  {
    "text": "deal with a nom de chillon someone already has so in order to take advantage of this you need a framework that can do these translations for you",
    "start": "1197600",
    "end": "1204429"
  },
  {
    "text": "so lambda is wonderful for a lot of things but you also to kind of do it yourself so just think about that before",
    "start": "1204429",
    "end": "1211190"
  },
  {
    "text": "you jump headlong into to building a crazy complex ETL layer using lambda it's wonderful for basic manipulations",
    "start": "1211190",
    "end": "1217070"
  },
  {
    "text": "for responding to events for doing like basic anomaly detection or deciding whether a file is worthwhile or not perfect for all those use cases but it's",
    "start": "1217070",
    "end": "1224299"
  },
  {
    "text": "it's there are alternatives so this is the phase I think when most people move",
    "start": "1224299",
    "end": "1230690"
  },
  {
    "start": "1225000",
    "end": "1257000"
  },
  {
    "text": "into I think what is still considered like the big the newer big data world with Hadoop and all the rest of stuff",
    "start": "1230690",
    "end": "1236330"
  },
  {
    "text": "because you know you got your data and s3 you're you're querying it using redshift you might have used um lambda",
    "start": "1236330",
    "end": "1242630"
  },
  {
    "text": "to do some basic basic manipulations but you're starting to bump up against a bit of a ceiling maybe you want to use some",
    "start": "1242630",
    "end": "1247940"
  },
  {
    "text": "new awesome big data framework maybe you want to just try new tools maybe you are",
    "start": "1247940",
    "end": "1252980"
  },
  {
    "text": "having issues with processing a huge amount of data using lambda as scale so when you start asking these questions",
    "start": "1252980",
    "end": "1258890"
  },
  {
    "start": "1257000",
    "end": "1269000"
  },
  {
    "text": "you know how will this work at scale how can it get more efficient about my data processing how can I start exposing",
    "start": "1258890",
    "end": "1265280"
  },
  {
    "text": "my developers to new big data ecosystem tools the answer is usually EMR",
    "start": "1265280",
    "end": "1271450"
  },
  {
    "start": "1269000",
    "end": "1432000"
  },
  {
    "text": "the EMR is my favorite service on AWS I mean what I I wish you a median",
    "start": "1271450",
    "end": "1278630"
  },
  {
    "text": "entertainment background and four and half years ago when I sat down in the New York office where I'm based I sat",
    "start": "1278630",
    "end": "1283640"
  },
  {
    "text": "down beside a guy with a PhD in biomimetics and he said I didn't understand it right you do transcoding clusters yeah Hadoop no problems your",
    "start": "1283640",
    "end": "1292039"
  },
  {
    "text": "later your hadoop expert that's how it works these days the point of that story is that EMR has",
    "start": "1292039",
    "end": "1297919"
  },
  {
    "text": "a really easy learning curve when it comes to Hadoop and it removes all the ops out of it used to be when I was",
    "start": "1297919",
    "end": "1303679"
  },
  {
    "text": "setting up the do clusters you know I did do that before or five years ago it was hard to",
    "start": "1303679",
    "end": "1308830"
  },
  {
    "text": "actually set up and maintain the clusters install the software maintain the software that was a significant percentage of your job you don't want",
    "start": "1308830",
    "end": "1315049"
  },
  {
    "text": "your big data technicians who are trained data scientists spending time maintaining clusters that's not a great use of their time or your money they're",
    "start": "1315049",
    "end": "1322700"
  },
  {
    "text": "expensive so this is why EMR was built it's a managed Hadoop service and if you",
    "start": "1322700",
    "end": "1327890"
  },
  {
    "text": "don't know how to do Pez just think if I do kind of like a think of it like an operating system for big data tools I'm",
    "start": "1327890",
    "end": "1333840"
  },
  {
    "text": "sure there's some people who sort of shivered when I put it that way but that's how I like to think about it it's a distribution it's a it's sort of like",
    "start": "1333840",
    "end": "1339240"
  },
  {
    "text": "an operating system where multiple applications can run on top a lot of people conflate Hadoop with MapReduce",
    "start": "1339240",
    "end": "1345540"
  },
  {
    "text": "which was one of the original batch processing sort of data processing engines that people did batch processing",
    "start": "1345540",
    "end": "1350940"
  },
  {
    "text": "with but MapReduce is just one application that you can run on Hadoop and now there's tons it was presto and",
    "start": "1350940",
    "end": "1358290"
  },
  {
    "text": "spark and flink and there's something new every day an EMR provides a way to run all those applications on Hadoop in",
    "start": "1358290",
    "end": "1365730"
  },
  {
    "text": "a managed way so it's it's a managed cluster service really where the cluster is running Hadoop and you can do",
    "start": "1365730",
    "end": "1372120"
  },
  {
    "text": "distributed processing streaming data processing machine learning whatever you can run all these different big data",
    "start": "1372120",
    "end": "1377220"
  },
  {
    "text": "applications on a managed cluster and that's what EMR is so it's extremely flexible and it comes",
    "start": "1377220",
    "end": "1384000"
  },
  {
    "text": "with all these applications that can be installed and on when you launch a new cluster it makes all that stuff painless",
    "start": "1384000",
    "end": "1389600"
  },
  {
    "text": "so it supports hive spark Zeppelin which is a cool visual interface presto which",
    "start": "1389600",
    "end": "1395700"
  },
  {
    "text": "we'll talk about later you can even do sort of no sequel stuff with HBase Phoenix and some of the new stuff like",
    "start": "1395700",
    "end": "1401490"
  },
  {
    "text": "tez flink all of these applications if you will run on top of this managed to",
    "start": "1401490",
    "end": "1407190"
  },
  {
    "text": "do cluster and we take care of the auto scaling and everything else for you it also does really cool things like",
    "start": "1407190",
    "end": "1412710"
  },
  {
    "text": "integrate with kms our key management service so if you need things like encryption at rest it makes that very",
    "start": "1412710",
    "end": "1418770"
  },
  {
    "text": "easy and for anyone who has done encryption at rest and Hadoop before in this room you'll know that it that is not always easy so making that easy as a",
    "start": "1418770",
    "end": "1425160"
  },
  {
    "text": "good thing and it's HIPAA eligible so it solves that compliance issue which is also a bit of a bug bear with big data",
    "start": "1425160",
    "end": "1431730"
  },
  {
    "text": "as well so where does it fit into the puzzle so you get your data in s3 using you",
    "start": "1431730",
    "end": "1437640"
  },
  {
    "start": "1432000",
    "end": "1502000"
  },
  {
    "text": "know the CLI or snowmobile or snowball a or whatever the use case I see most often for EMR still is",
    "start": "1437640",
    "end": "1444410"
  },
  {
    "text": "essentially data transformation it can do a lot of other things don't get me wrong if there's any people from the EMR",
    "start": "1444410",
    "end": "1450030"
  },
  {
    "text": "servicing don't worry I'll talk about the other stuff too but most people are still doing batch processing or in some",
    "start": "1450030",
    "end": "1455520"
  },
  {
    "text": "cases streaming data processing data comes in whether it's by a Kinesis or into s3 you transform that data perhaps",
    "start": "1455520",
    "end": "1461550"
  },
  {
    "text": "you normal so that you can load it into a redshift database it's a it's a great sort of general data",
    "start": "1461550",
    "end": "1468240"
  },
  {
    "text": "processing thing that you can use different applications to process that data in different ways",
    "start": "1468240",
    "end": "1473809"
  },
  {
    "text": "so if you stop here if you only get this far this is like a very sophisticated actually Big Data application that as",
    "start": "1474350",
    "end": "1480330"
  },
  {
    "text": "recently as four or five years ago was reserved for white lab coats and now it's honestly something that you can all do in about 10 or 15 minutes there's a",
    "start": "1480330",
    "end": "1487279"
  },
  {
    "text": "presentation and a workshop like this called building your first big data application similar title and I strongly",
    "start": "1487279",
    "end": "1493200"
  },
  {
    "text": "actually recommend you look that up on YouTube because you can actually follow the steps and do all of this yourself in",
    "start": "1493200",
    "end": "1499019"
  },
  {
    "text": "about 15-20 minutes but that's not it so what about ad-hoc queries what if you don't know what the",
    "start": "1499019",
    "end": "1505710"
  },
  {
    "start": "1502000",
    "end": "1530000"
  },
  {
    "text": "data looks like so it's one thing to say okay I'm gonna transform the data but what if all this",
    "start": "1505710",
    "end": "1511019"
  },
  {
    "text": "data is coming in what if the previous guy didn't make it to work and you show up and you need to figure out what this",
    "start": "1511019",
    "end": "1517110"
  },
  {
    "text": "data is so that you can write the data transformation so that you can determine if it needs to be normalized or",
    "start": "1517110",
    "end": "1522539"
  },
  {
    "text": "structured so there can be loaded into redshift how do you do that what's an efficient way to do essentially like ad hoc query of your data",
    "start": "1522539",
    "end": "1530539"
  },
  {
    "start": "1530000",
    "end": "1649000"
  },
  {
    "text": "so this is where Athena comes in Athena was just announced",
    "start": "1530539",
    "end": "1536480"
  },
  {
    "text": "so there are many ways to do this in the past what I would have done is I would have spun up an EMR cluster I would have",
    "start": "1536480",
    "end": "1543720"
  },
  {
    "text": "installed presto on it and then I would have issued sequel commands against data stored in s3 on presto on EMR now that",
    "start": "1543720",
    "end": "1550440"
  },
  {
    "text": "is actually pretty easy but it still requires multiple steps and I think a lot of people if they just want to do",
    "start": "1550440",
    "end": "1556169"
  },
  {
    "text": "some basic out querying they don't want to go through all that hassle they don't want to spin up an EMR cluster they don't have to bootstrap",
    "start": "1556169",
    "end": "1562080"
  },
  {
    "text": "presto they don't have to know what presto is so this is what Athena is it's kind of the next level it moves to that",
    "start": "1562080",
    "end": "1568350"
  },
  {
    "text": "next level of abstraction it moves just a little further up the stack underneath it covers that's actually running presto",
    "start": "1568350",
    "end": "1574129"
  },
  {
    "text": "so what it allows you to do is load your data into s3 and then do just",
    "start": "1574129",
    "end": "1579720"
  },
  {
    "text": "essentially do exploratory analytics or ad hoc queries against your data and it supports a variety of different file",
    "start": "1579720",
    "end": "1585389"
  },
  {
    "text": "formats like JSON and Avro and Orsi and park' so it's a wonderful way to",
    "start": "1585389",
    "end": "1592970"
  },
  {
    "text": "explore your data when you don't necessarily know what is there or when you don't necessarily know what you're going to do with it yet and this is",
    "start": "1592970",
    "end": "1599500"
  },
  {
    "text": "actually really powerful because in the past you used to have to kind of go through several iterations and get your",
    "start": "1599500",
    "end": "1604960"
  },
  {
    "text": "data into a shape and then get it structured and put into a database but now we're getting so much data coming in",
    "start": "1604960",
    "end": "1610270"
  },
  {
    "text": "IOT devices logs all over the place that very often the data is changing all the time and you set up your Big Data",
    "start": "1610270",
    "end": "1616690"
  },
  {
    "text": "pipeline it used to be had to kind of evolve your big data pipeline every a few months but now you may have to evolve it every day and Athena is one of",
    "start": "1616690",
    "end": "1622900"
  },
  {
    "text": "these tools that makes that possible and easy you can kind of adapt to how data changes because it doesn't matter how the data is structured you can use",
    "start": "1622900",
    "end": "1628510"
  },
  {
    "text": "sequel to query any type of unstructured data on s3 no matter how it is compressed or stored what format it's in",
    "start": "1628510",
    "end": "1635370"
  },
  {
    "text": "so it's very powerful it's a simple concept but extremely powerful so they",
    "start": "1635370",
    "end": "1641110"
  },
  {
    "text": "call it serverless query processing or interactive career processing it's one of my personally my favorite",
    "start": "1641110",
    "end": "1646810"
  },
  {
    "text": "announcement a tree event so this is in my picture that we've been following so far sir where it sits is in",
    "start": "1646810",
    "end": "1654190"
  },
  {
    "text": "eventually you are going to do some heavy lifting with EMR you're going to set up some regular jobs maybe some batch draws or some streaming data",
    "start": "1654190",
    "end": "1660310"
  },
  {
    "text": "analytics using GMR that do that regular processing of data in s3 or coming out of Kinesis and putting it at a redshift",
    "start": "1660310",
    "end": "1667270"
  },
  {
    "text": "you're going to have sure to this pipeline but it's also handy to have Athena there when the data is changing or when you do need to do queries that",
    "start": "1667270",
    "end": "1673600"
  },
  {
    "text": "fall outside of the normal data pipeline it's a perfect sort of addition instead of having to spin up a secondary EMR",
    "start": "1673600",
    "end": "1679420"
  },
  {
    "text": "cluster or running presto or whatever it's super easy you pay for what you use or you pay for how much data you process",
    "start": "1679420",
    "end": "1685690"
  },
  {
    "text": "so it's also very affordable as well the thing with Athena though if you look",
    "start": "1685690",
    "end": "1692530"
  },
  {
    "text": "closely is that you pay for how much data you process right so logic goes that you should compress that",
    "start": "1692530",
    "end": "1699400"
  },
  {
    "text": "data so even for ad-hoc processing I actually do recommend once you kind of get going it is a good idea to use EMR",
    "start": "1699400",
    "end": "1705250"
  },
  {
    "text": "to convert the data to a columnar compressed data format like park' for example so i'm actually often using hive",
    "start": "1705250",
    "end": "1712090"
  },
  {
    "text": "on tez on EMR to convert and pre process my data so that I can spend less money",
    "start": "1712090",
    "end": "1718690"
  },
  {
    "text": "when I do ad hoc queries with Athena so it still allows my developers to do",
    "start": "1718690",
    "end": "1724120"
  },
  {
    "text": "those interactive ad hoc queries but they will go they will run faster because it's a against a columnar data",
    "start": "1724120",
    "end": "1729610"
  },
  {
    "text": "format like orz or parque and i'll pay less money because it's compressed data sitting on s3 the athena is create",
    "start": "1729610",
    "end": "1736720"
  },
  {
    "text": "against so this is an optional step but an important step to consider doesn't",
    "start": "1736720",
    "end": "1741970"
  },
  {
    "text": "you don't have to normalize your data the data can still be raw it'll just be compressed and in a columnar binary",
    "start": "1741970",
    "end": "1747970"
  },
  {
    "text": "format and then it will run faster and more efficiently and cheaper with Athena",
    "start": "1747970",
    "end": "1753419"
  },
  {
    "start": "1753000",
    "end": "1791000"
  },
  {
    "text": "so Athena is wonderful and having a managed service for you know this is",
    "start": "1754080",
    "end": "1759520"
  },
  {
    "text": "actually running pressed allows you to run interactive queries using sequel is amazing but sometimes you need to do other stuff sometimes you want to use",
    "start": "1759520",
    "end": "1766270"
  },
  {
    "text": "spark ml maybe you want to use spark sequel instead of presto for some reason maybe you want to use flink like I said",
    "start": "1766270",
    "end": "1772750"
  },
  {
    "text": "before I think of the duplicate a distribution an operating system there's a lot of applications out there and",
    "start": "1772750",
    "end": "1778030"
  },
  {
    "text": "they're changing all the time now we'll build managed services as our customers ask us to on top of some of the most",
    "start": "1778030",
    "end": "1783220"
  },
  {
    "text": "powerful and popular ones like presto with Athena but it doesn't cover all use cases you know you all have different",
    "start": "1783220",
    "end": "1789220"
  },
  {
    "text": "businesses different use cases so often you want to run custom code maybe you've you have some custom spark jobs within",
    "start": "1789220",
    "end": "1796060"
  },
  {
    "start": "1791000",
    "end": "1840000"
  },
  {
    "text": "Java that you want to run this is where you pull back a bit and you can run these on EMR and this is why what I'm",
    "start": "1796060",
    "end": "1802210"
  },
  {
    "text": "trying to tell you is why we have both managed services like Athena and while we also have EMR so EMR is appropriate",
    "start": "1802210",
    "end": "1808540"
  },
  {
    "text": "when you want to run a diversity of things like hyvent as I mentioned and you want to run SPARC on another cluster",
    "start": "1808540",
    "end": "1814810"
  },
  {
    "text": "maybe want to run flink or whatever on another cluster so having both is great just want to make that point that just",
    "start": "1814810",
    "end": "1822040"
  },
  {
    "text": "because we have Athena doesn't mean the EMR goes away EMR is still very important piece of the puzzle and it's a great tool generic toolbox to have in",
    "start": "1822040",
    "end": "1830200"
  },
  {
    "text": "your knowledge base that you can use as sort of a place to experiment with new Big Data frameworks that run on I do it",
    "start": "1830200",
    "end": "1835300"
  },
  {
    "text": "as they come out",
    "start": "1835300",
    "end": "1837780"
  },
  {
    "start": "1840000",
    "end": "1867000"
  },
  {
    "text": "okay so we've been talking a lot about kind of back stuff though and what about real time data I said earlier that real",
    "start": "1840470",
    "end": "1846480"
  },
  {
    "text": "time data is really where a lot of this is moving so in the pictures that you've seen so far the data has been going into",
    "start": "1846480",
    "end": "1852030"
  },
  {
    "text": "s3 and then you know when it hits s3 either it fires off an s3 event and the lambda function does some transformation",
    "start": "1852030",
    "end": "1858030"
  },
  {
    "text": "or you you process the data using EMR but what about if you're getting data coming in all the time how do you",
    "start": "1858030",
    "end": "1863760"
  },
  {
    "text": "process that data as it comes in so that's where Kinesis comes in really",
    "start": "1863760",
    "end": "1868890"
  },
  {
    "start": "1867000",
    "end": "2105000"
  },
  {
    "text": "handy and Kinesis has evolved a lot over the last year so it used to be what I",
    "start": "1868890",
    "end": "1874380"
  },
  {
    "text": "used to say this was that you can think of the Canisius kind of like a queue a very simple extremely cost effective",
    "start": "1874380",
    "end": "1880430"
  },
  {
    "text": "very fast queue where you can just toss streaming data and then kind of figure",
    "start": "1880430",
    "end": "1886110"
  },
  {
    "text": "out what to do with it later it's evolved since then now we have things like Kinesis firehose and we have",
    "start": "1886110",
    "end": "1891210"
  },
  {
    "text": "Kinesis analytics so now it's more of a general-purpose real-time data streaming",
    "start": "1891210",
    "end": "1896970"
  },
  {
    "text": "framework so what Kinesis gives you is a reliable durable cost-effective sort of",
    "start": "1896970",
    "end": "1903240"
  },
  {
    "text": "front door for your data if you have data streaming in from mobile devices from your web applications from IOT",
    "start": "1903240",
    "end": "1910440"
  },
  {
    "text": "devices Canisius is a great place to store that data first why because you",
    "start": "1910440",
    "end": "1915960"
  },
  {
    "text": "can put your data in Kinesis and you can either process in real time but also holds on to that data for 24 hours and can hold on to it for as much seven days",
    "start": "1915960",
    "end": "1922170"
  },
  {
    "text": "if you want for those of you who are familiar with Kafka a lot of similarities between Kinesis and Kafka",
    "start": "1922170",
    "end": "1927300"
  },
  {
    "text": "it's a great place to capture that data and then you can have multiple applications pointing at Kinesis that",
    "start": "1927300",
    "end": "1934350"
  },
  {
    "text": "can do different things with that data so for example you have a mobile game",
    "start": "1934350",
    "end": "1940380"
  },
  {
    "text": "and as things happen in that game those actions are pushed up to a new Kinesis",
    "start": "1940380",
    "end": "1945810"
  },
  {
    "text": "queue maybe some of those actions you want to respond to in real time other actions you just want to capture and",
    "start": "1945810",
    "end": "1951120"
  },
  {
    "text": "archive other actions or maybe you don't recognize whether there's some new user",
    "start": "1951120",
    "end": "1956220"
  },
  {
    "text": "behavior happening in your game that you want to capture if it's sort of a massive multiplayer game you can satisfy all of those requirements with with a",
    "start": "1956220",
    "end": "1962940"
  },
  {
    "text": "single sort of Kinesis stream you can have all your data flying into the Kinesis and then you can have three applications one for real-time data",
    "start": "1962940",
    "end": "1968460"
  },
  {
    "text": "processing 1% of analytics against user behavior and another one to respond to some kind of real-time data event",
    "start": "1968460",
    "end": "1975759"
  },
  {
    "text": "so it's high throughput and it makes data capture extremely easy and",
    "start": "1975759",
    "end": "1981619"
  },
  {
    "text": "cost-effective you simply add more shards to your Kinesis stream when you need more capacity couldn't be easier",
    "start": "1981619",
    "end": "1987730"
  },
  {
    "text": "now what we've added more recently is Canisius firehose because what we found is some of our customers were telling us",
    "start": "1987730",
    "end": "1992960"
  },
  {
    "text": "that hey Kinesis is awesome but i'm actually finding it kind of hard to get my data in kinases so firehose makes it easy to",
    "start": "1992960",
    "end": "1999399"
  },
  {
    "text": "to capture your data to bundle it you can aggregate your data and then to push",
    "start": "1999399",
    "end": "2005019"
  },
  {
    "text": "it into Kinesis stream so you can still hit the Canisius api is yourself or bake that into your application with the SDK",
    "start": "2005019",
    "end": "2010919"
  },
  {
    "text": "but Kinesis firehose is a great way to get that data not only into Kinesis but also up into s3 after Kinesis because",
    "start": "2010919",
    "end": "2018340"
  },
  {
    "text": "people are like I didn't run all right at Kinesis application using KCl that sounds hard to me I just want my",
    "start": "2018340",
    "end": "2023919"
  },
  {
    "text": "streaming data to be compressed and then dumped into s3 out of my Kinesis stream so Kinesis firehose does that for you it",
    "start": "2023919",
    "end": "2031179"
  },
  {
    "text": "think of it like a managed KCl or a managed Kinesis data service so very",
    "start": "2031179",
    "end": "2038139"
  },
  {
    "text": "often you want to capture that log data that's coming in real time but you don't want every single log data as a file in s3 that would be inefficient for",
    "start": "2038139",
    "end": "2044259"
  },
  {
    "text": "querying with Hadoop and it would just be hard to manage you'd have tons and tons and tons of files so what firehose can do is take all those batch them at a",
    "start": "2044259",
    "end": "2051490"
  },
  {
    "text": "little megabyte bundles for example zip them up and then dump them as the bundles arrive into s3",
    "start": "2051490",
    "end": "2057839"
  },
  {
    "text": "that's how most people use it the Canisius analytics is new - a lot of",
    "start": "2057839",
    "end": "2062980"
  },
  {
    "text": "people are asking sweetie this is awesome but I want to know in real time I want to have the ability to run queries against my data in my Kinesis",
    "start": "2062980",
    "end": "2069460"
  },
  {
    "text": "streams so back in the day before Kinesis analytics you had to spin up a cluster get back data out of",
    "start": "2069460",
    "end": "2077829"
  },
  {
    "text": "the Kinesis stream maybe put it into s3 and then have ec2 and then run analytics using presto or spark sequel against the",
    "start": "2077829",
    "end": "2084398"
  },
  {
    "text": "data in s3 with the Kinesis analytics you can actually run analytics queries using sequel against your data in the",
    "start": "2084399",
    "end": "2090429"
  },
  {
    "text": "stream as it arrives so this is great to get some real-time insights into what is happening right",
    "start": "2090429",
    "end": "2097089"
  },
  {
    "text": "now for whatever your application is doing whether it's in games vents or retail it's a very powerful tool",
    "start": "2097089",
    "end": "2104790"
  },
  {
    "text": "that's a lot to process let's just you look look at it in context a little bit so here we have some mobile clients some",
    "start": "2104790",
    "end": "2110710"
  },
  {
    "start": "2105000",
    "end": "2234000"
  },
  {
    "text": "web clients that data is going into Kinesis streams what that Kay is with the box is a KCl",
    "start": "2110710",
    "end": "2119740"
  },
  {
    "text": "application KCl is a library that you can run on ec2 and it takes care of spinning up resources ec2 instances",
    "start": "2119740",
    "end": "2126040"
  },
  {
    "text": "scaling them up scaling them down and then processing the data and putting in an s3 you could also use Kinesis firehose there where firehose would take",
    "start": "2126040",
    "end": "2132970"
  },
  {
    "text": "care of that for you bundle the data up aggregate it dump it into s3 and then",
    "start": "2132970",
    "end": "2138130"
  },
  {
    "text": "you're using EMR to pull the data out of Kinesis streams process it compress it and turn it into a columnar data format",
    "start": "2138130",
    "end": "2144670"
  },
  {
    "text": "like or c or parque then you can do ad hoc queries against it figure out what this data is using athina then you can",
    "start": "2144670",
    "end": "2151930"
  },
  {
    "text": "process it further to structure it and normalize it so you can load it into your long-term data warehouse so now the",
    "start": "2151930",
    "end": "2157900"
  },
  {
    "text": "room is starting to come together I know there's a lot of tools on there but it's actually if you take a step back and you",
    "start": "2157900",
    "end": "2163450"
  },
  {
    "text": "look at it it's actually a very complex architecture that has been wildly",
    "start": "2163450",
    "end": "2168940"
  },
  {
    "text": "simplified by just a few services you have an enterprise-grade dinner warehouse that your developers are no",
    "start": "2168940",
    "end": "2174910"
  },
  {
    "text": "sequel that are using their BI tools can use with no changes whatsoever that use case is satisfied you're using EMR to",
    "start": "2174910",
    "end": "2181960"
  },
  {
    "text": "normalize and structure your data so that you can use redshift in the first place you have Athena now so you do",
    "start": "2181960",
    "end": "2187000"
  },
  {
    "text": "ad-hoc queries and figure out all this new data is and you're not paying as much for Athena because you're using EMR",
    "start": "2187000",
    "end": "2192220"
  },
  {
    "text": "to pre-process it and compress it in turn into a column in or data format last piece you have Kinesis and you're",
    "start": "2192220",
    "end": "2197920"
  },
  {
    "text": "capturing that real-time data and now it's not just a batch overnight story it's a real-time data story and this is",
    "start": "2197920",
    "end": "2204910"
  },
  {
    "text": "impressive and this will transform your business and I really don't mean that in a I mean that's for real I've seen this",
    "start": "2204910",
    "end": "2211330"
  },
  {
    "text": "transform people's businesses its analytics real-time analytics if",
    "start": "2211330",
    "end": "2216400"
  },
  {
    "text": "you're running any kind of mobile application capturing those events from your users in real time to detect",
    "start": "2216400",
    "end": "2221860"
  },
  {
    "text": "anomalies maybe there's behaviors of your application that you didn't anticipate the you don't want your users experiencing you can now detect those",
    "start": "2221860",
    "end": "2228010"
  },
  {
    "text": "and react to them in real time",
    "start": "2228010",
    "end": "2231810"
  },
  {
    "start": "2234000",
    "end": "2304000"
  },
  {
    "text": "so here we have Kinesis analytics I just wanted to show you where it fits into the puzzle in addition to firehose so",
    "start": "2234710",
    "end": "2241680"
  },
  {
    "text": "again same thing except we're pushing into Kinesis firehose instead of Kinesis streams firehose is taking care of the",
    "start": "2241680",
    "end": "2248130"
  },
  {
    "text": "bundling and depression and stuff and putting in an s3 we're using Kinesis analytics to also do kind of rule-based",
    "start": "2248130",
    "end": "2254010"
  },
  {
    "text": "processing of our data as it comes in in this case we also have lambda and lambda",
    "start": "2254010",
    "end": "2260700"
  },
  {
    "text": "is actually reacting to data as it hits Kinesis streams and then sending you a text using SNS if something's up maybe",
    "start": "2260700",
    "end": "2269460"
  },
  {
    "text": "there's some security event that you detect using Kinesis analytics that can actually we're sort using lambda it can",
    "start": "2269460",
    "end": "2276900"
  },
  {
    "text": "actually do some basic data processing okay let's look at this message that came in to Kinesis hold on a second this",
    "start": "2276900",
    "end": "2282990"
  },
  {
    "text": "is like anomalous behavior I don't like this let's send me a text and let me know that something is up so again responding in real-time",
    "start": "2282990",
    "end": "2289760"
  },
  {
    "text": "or maybe the data is coming in Kinesis and you can use lambda due to that transformation like we talked about earlier so again think about real-time",
    "start": "2289760",
    "end": "2296370"
  },
  {
    "text": "and responding to events and how you can connect things like Kinesis streams as three events and lambda to respond in",
    "start": "2296370",
    "end": "2302010"
  },
  {
    "text": "real-time another way to respond in real-time though is with machine learning and",
    "start": "2302010",
    "end": "2309120"
  },
  {
    "start": "2304000",
    "end": "2501000"
  },
  {
    "text": "there were some very cool announcements this morning with around data or sorry image recognition",
    "start": "2309120",
    "end": "2315300"
  },
  {
    "text": "and an poly there's also Amazon machine learning and it's important to remember that machine learning is a key part of",
    "start": "2315300",
    "end": "2322770"
  },
  {
    "text": "the Big Data story now this is definitely something that just recently as a few years ago was",
    "start": "2322770",
    "end": "2328680"
  },
  {
    "text": "perceived as something reserved for the white lab coats no machine learning well I just figured out a dupe stop it now is",
    "start": "2328680",
    "end": "2335490"
  },
  {
    "text": "really actually quite easy doing you know regression doing basic machine learning with Amazon is not only easy",
    "start": "2335490",
    "end": "2341430"
  },
  {
    "text": "but it actually can really enhance your Big Data Platform so when would you use machine learning in this kind of a",
    "start": "2341430",
    "end": "2347250"
  },
  {
    "text": "picture that we've been drawing so far well you know it's one thing to say yeah I'll respond to that event know if it's",
    "start": "2347250",
    "end": "2352740"
  },
  {
    "text": "anomalous behavior but how do you know if it's anomalous do you have all the rules magically that you can give this",
    "start": "2352740",
    "end": "2358380"
  },
  {
    "text": "massive lambda function that does all of these sort of checks against your data this is where machine learning can come",
    "start": "2358380",
    "end": "2363450"
  },
  {
    "text": "in really handy you can train you can train a model and machine learning sister it sort of understands",
    "start": "2363450",
    "end": "2368760"
  },
  {
    "text": "what normal behavior is or or we'll stop talking about anomalies how about it what food you want to order and so you",
    "start": "2368760",
    "end": "2376350"
  },
  {
    "text": "have all these people who are using a mobile app and maybe you sign some affiliate deal with a food delivery service and based on the user's behavior",
    "start": "2376350",
    "end": "2383370"
  },
  {
    "text": "you can be like hey man this guy really needs some pizza he's having a hard time at level four and you know a couple of",
    "start": "2383370",
    "end": "2390150"
  },
  {
    "text": "you are laughing but that's actually a real use case think about it you know video gamers ate a lot of pizza maybe",
    "start": "2390150",
    "end": "2395370"
  },
  {
    "text": "I'll make some kind of business partnership with a local pizza store how do I know if they want pizza because the",
    "start": "2395370",
    "end": "2400920"
  },
  {
    "text": "my game has nothing to do with pizza it's about building huts in a multiplayer world well turns out that certain types of players that have",
    "start": "2400920",
    "end": "2407580"
  },
  {
    "text": "certain behaviors get hungry at 4 a.m. if they're you know they live in a certain part of the country it's dinner",
    "start": "2407580",
    "end": "2412650"
  },
  {
    "text": "time you can correlate all these events you can learn and you don't necessarily have to have every combination like if",
    "start": "2412650",
    "end": "2418830"
  },
  {
    "text": "you didn't have machine learning you would have to know every single combination that resulted in a pizza crave with machine learning you can",
    "start": "2418830",
    "end": "2424170"
  },
  {
    "text": "train a model and infer from a certain set of parameters that this person may",
    "start": "2424170",
    "end": "2429780"
  },
  {
    "text": "want pizza so I know that that sounds like kind of a silly example but think about your own business and think about",
    "start": "2429780",
    "end": "2435600"
  },
  {
    "text": "how you could respond in real-time streaming events that are captured in Kinesis and make recommendations and tie",
    "start": "2435600",
    "end": "2441930"
  },
  {
    "text": "that into other businesses again augmenting your Big Data Platform using machine learning",
    "start": "2441930",
    "end": "2447470"
  },
  {
    "text": "we work with a lot advertisers this is another thing to advertising well amazon.com being one of them and",
    "start": "2447470",
    "end": "2454670"
  },
  {
    "text": "advertising one of those things where machine learning is incredibly powerful not just advertisement what about",
    "start": "2454670",
    "end": "2460020"
  },
  {
    "text": "security let's get back to anomalies for a second you don't know what bad is necessarily but you do know what is",
    "start": "2460020",
    "end": "2466200"
  },
  {
    "text": "normal and maybe you know what a set of conditions are that are different so you can train a model against logs for",
    "start": "2466200",
    "end": "2472410"
  },
  {
    "text": "example log data of what things should look like versus what they should not and when you serve drift into that not",
    "start": "2472410",
    "end": "2477930"
  },
  {
    "text": "area you can trigger events and either auto remediate using lambda or send your CSE so a text using SNS so plugging",
    "start": "2477930",
    "end": "2486090"
  },
  {
    "text": "machine learning into the Big Data story is not only easier than you think that can be really really beneficial you can",
    "start": "2486090",
    "end": "2492480"
  },
  {
    "text": "get started and train a model and plug it into your Big Data architecture honestly in fifteen or thirty minutes if",
    "start": "2492480",
    "end": "2497640"
  },
  {
    "text": "you take some villages so this is fancy you build this awesome",
    "start": "2497640",
    "end": "2503550"
  },
  {
    "text": "architecture and you bring it to your boss and they're like okay this is awesome except compliance and so you know Andy Jackie was talking",
    "start": "2503550",
    "end": "2511170"
  },
  {
    "text": "about this earlier today sort of the enterprise story and how it's evolved over the years certainly in the four four plus years that I've been at Amazon",
    "start": "2511170",
    "end": "2517350"
  },
  {
    "text": "it's evolved but security is always super important in Amazon and dealing with compliance and encryption is",
    "start": "2517350",
    "end": "2523440"
  },
  {
    "text": "something that quite frankly when you're dealing with architectures and data at scale can be hard but we've made a lot",
    "start": "2523440",
    "end": "2530340"
  },
  {
    "text": "easier recently certainly with kms integration into services so for example if you're using data stored in s3 or",
    "start": "2530340",
    "end": "2538920"
  },
  {
    "text": "data stored in redshift or data stored in EMR all of those are integrated with our key management service our kms",
    "start": "2538920",
    "end": "2545700"
  },
  {
    "text": "service so you can have a fully managed key solution now why do you need a managed key solution well because the",
    "start": "2545700",
    "end": "2552510"
  },
  {
    "text": "answer is in Big Data I'll give you a real example for my life I was working with a hospital group on the East Coast and this hospital group had a",
    "start": "2552510",
    "end": "2558990"
  },
  {
    "text": "requirement that for every patient yeah I'd have a unique key for encrypting that patients data and that key had to",
    "start": "2558990",
    "end": "2564360"
  },
  {
    "text": "be rotated every day now this is a big Hospital group so their key problem became a big data problem and their",
    "start": "2564360",
    "end": "2571080"
  },
  {
    "text": "infrastructure to support the keys and key rotation even rotating the keys was like a massive job that cost some money",
    "start": "2571080",
    "end": "2577410"
  },
  {
    "text": "because it was a ton of compute so by having a managed service like kms they could offload they weren't making money",
    "start": "2577410",
    "end": "2583620"
  },
  {
    "text": "off key management they're making money off healthcare they could offload all of that key management to kms so you can",
    "start": "2583620",
    "end": "2589680"
  },
  {
    "text": "have very sophisticated key rotation and encryption sort of frameworks or rather",
    "start": "2589680",
    "end": "2594720"
  },
  {
    "text": "workflows and connect them very easily to multiple places where you restore your data like redshift and EMR and s3",
    "start": "2594720",
    "end": "2601820"
  },
  {
    "text": "so everything is kind of gets harder with big data because it's so big you have hundreds of terabytes petabytes of",
    "start": "2601820",
    "end": "2607710"
  },
  {
    "text": "data and key management and encryption is one of those things that you know most of us anyway are not making money off",
    "start": "2607710",
    "end": "2614600"
  },
  {
    "text": "so that's at rest what about in transit well our API is you can communicate with",
    "start": "2614600",
    "end": "2621000"
  },
  {
    "text": "them using HTTP and TLS encryption at rest but what about network isolation",
    "start": "2621000",
    "end": "2627140"
  },
  {
    "text": "this is something that a relevant something new I guess with the EMR but you can run a MRR redshift and VPC and",
    "start": "2627140",
    "end": "2633420"
  },
  {
    "text": "this is significant because remember we talked about Direct Connect before and if you look at the corporate data center",
    "start": "2633420",
    "end": "2639029"
  },
  {
    "text": "icon in the corner a lot of people's fear of the cloud comes from the fact",
    "start": "2639029",
    "end": "2644130"
  },
  {
    "text": "that they don't own the pipe between them and the cloud it's the wild crazy Internet and a lot of people talk about",
    "start": "2644130",
    "end": "2650760"
  },
  {
    "text": "public cloud and private cloud well I actually hate that term because you can have a private cloud with AWS if you have a direct connect from our data",
    "start": "2650760",
    "end": "2657599"
  },
  {
    "text": "centers to your Colo to where you're running and you can have no public connectivity whatsoever you can have all",
    "start": "2657599",
    "end": "2663119"
  },
  {
    "text": "private addresses running EMR clusters in VPC connected to your data center or colocation facility over Direct Connect",
    "start": "2663119",
    "end": "2669000"
  },
  {
    "text": "fully encrypted using keys that you control key rotation using kms that is a very sophisticated private secure",
    "start": "2669000",
    "end": "2676890"
  },
  {
    "text": "experience for big data and something that quite frankly is really hard to do on your own",
    "start": "2676890",
    "end": "2682010"
  },
  {
    "text": "I've actually had multiple customers show me their their secure corner of their data center and it's like this literally a cage with like a chain lock",
    "start": "2682010",
    "end": "2687960"
  },
  {
    "text": "fence you can do better than that we can all do better than that security has a key",
    "start": "2687960",
    "end": "2693329"
  },
  {
    "text": "part of your big data story especially once we get into compliance a lot of you maybe work in an e-commerce working with PII and pH I so thinking about this up",
    "start": "2693329",
    "end": "2700740"
  },
  {
    "text": "front is important what is your security story do you want to be sort of public facing or do you want private and the",
    "start": "2700740",
    "end": "2707069"
  },
  {
    "text": "good news is you can be flexible with AWS you can do both okay so you know I've been up here",
    "start": "2707069",
    "end": "2713400"
  },
  {
    "start": "2711000",
    "end": "2808000"
  },
  {
    "text": "waving my hands and stuff but who is actually doing this I think this is important you know how can it this is",
    "start": "2713400",
    "end": "2721680"
  },
  {
    "text": "not a hobby we actually have customers a lot of people are doing this today so let's talk about a couple of them Redfin",
    "start": "2721680",
    "end": "2728099"
  },
  {
    "text": "so let me just build this slide out for you look familiar so Redfin has this hot",
    "start": "2728099",
    "end": "2734549"
  },
  {
    "text": "Homes product and they do user profile recommendations they they look for similar homes they do essentially a mix",
    "start": "2734549",
    "end": "2741690"
  },
  {
    "text": "of real-time and batch analytics to tell you hey you know you looked at this home you should check this one out I",
    "start": "2741690",
    "end": "2748250"
  },
  {
    "text": "don't know you know if they're integrating for the doing kind of machine learning with EMR but this would be a great use case for machine learning",
    "start": "2748250",
    "end": "2754589"
  },
  {
    "text": "based on all these parameters you were looking at these homes on a Tuesday you live in Dallas you're going to love this home so that's a good use case perhaps",
    "start": "2754589",
    "end": "2761640"
  },
  {
    "text": "for what we were talking about earlier they use s3 as their data link they say che gergan in store all of their data",
    "start": "2761640",
    "end": "2766760"
  },
  {
    "text": "and s3 and then they talk to that data using multiple services they loaded in redshift they",
    "start": "2766760",
    "end": "2772510"
  },
  {
    "text": "transform it and perhaps do machine learning or whatever using EMR against that data in s3 they also use DynamoDB",
    "start": "2772510",
    "end": "2779360"
  },
  {
    "text": "they have hot data that fronts there or backs their website as well you're not going to plug your website on to an",
    "start": "2779360",
    "end": "2784910"
  },
  {
    "text": "enterprise data warehouse you need a you need a data service that has much lower",
    "start": "2784910",
    "end": "2790280"
  },
  {
    "text": "latency for query so you can have a snappy mobile and web app so dynamo is perfect for that but the takeaway here is that they're using Kinesis to take in",
    "start": "2790280",
    "end": "2796790"
  },
  {
    "text": "the inbound data they're persisting in an s3 and they're using multiple tools for different use cases to actually make",
    "start": "2796790",
    "end": "2803990"
  },
  {
    "text": "sense and value out of that data Nordstrom I talked a little bit about",
    "start": "2803990",
    "end": "2810380"
  },
  {
    "text": "retail and e-commerce so personalized recommendations is not",
    "start": "2810380",
    "end": "2815780"
  },
  {
    "text": "just a nice to have an e-commerce anymore it's a requirement so I don't know what stage of your like",
    "start": "2815780",
    "end": "2821450"
  },
  {
    "text": "you're at but I just got out of the the Amazon recommended me diapers phase and I'm in the Amazon recommended me paw",
    "start": "2821450",
    "end": "2827300"
  },
  {
    "text": "Patrol so but it needs to know a lot about me to make those recommendations accurately it's actually processing a",
    "start": "2827300",
    "end": "2832850"
  },
  {
    "text": "lot of data for a lot of customers and Nordstrom does the same thing they're doing personalized recommendations and what's interesting about this is they",
    "start": "2832850",
    "end": "2839000"
  },
  {
    "text": "used to have to do like micro batch jobs every 15-20 minutes they take a chunk of data process it and give you",
    "start": "2839000",
    "end": "2845000"
  },
  {
    "text": "recommendations but that's not good enough often you only have someone's attention for like a few seconds and you",
    "start": "2845000",
    "end": "2850700"
  },
  {
    "text": "need to make very quick decisions about what content to serve them or or what ad to show them or these types of decisions",
    "start": "2850700",
    "end": "2855950"
  },
  {
    "text": "have to be fast so that's where the real-time streaming data piece comes in so lambda Kinesis DynamoDB that they're",
    "start": "2855950",
    "end": "2864530"
  },
  {
    "text": "making personalized recommendations using a very similar architecture that we saw",
    "start": "2864530",
    "end": "2869350"
  },
  {
    "text": "and doing analytics I don't think that's actually quick cite FINRA so we've talked about commerce but",
    "start": "2870640",
    "end": "2877310"
  },
  {
    "text": "what about the enterprise story what's interesting about the FINRA use case is that they're everything in this picture",
    "start": "2877310",
    "end": "2882860"
  },
  {
    "text": "here is encrypted both in transit and at rest so I think is a great real-world",
    "start": "2882860",
    "end": "2888320"
  },
  {
    "text": "example of how you can have a compliant financial services Big Data story on AWS",
    "start": "2888320",
    "end": "2894850"
  },
  {
    "text": "so it's a bit messy the slide that they're using multiple EMR clusters running different types of applications",
    "start": "2894850",
    "end": "2901220"
  },
  {
    "text": "on Hadoop they have post-grad clusters they have my sequel cut by sequel databases a lot of stuff",
    "start": "2901220",
    "end": "2907820"
  },
  {
    "text": "going on here but what's important is that they're satisfying different requirements at different be use different use cases using different",
    "start": "2907820",
    "end": "2913910"
  },
  {
    "text": "tools and ultimately their source of truth their data like if you will it remains s3 so again that story where you",
    "start": "2913910",
    "end": "2920990"
  },
  {
    "text": "persist your data on s3 and they have different clusters different tools that kind of orbit around it to solve different problems for different parts",
    "start": "2920990",
    "end": "2926900"
  },
  {
    "text": "your business in a secure way so my challenge to all you today is I",
    "start": "2926900",
    "end": "2931940"
  },
  {
    "text": "want to see your picture up here you next time I do this talk I want someone for this audience I want I want it to be",
    "start": "2931940",
    "end": "2936950"
  },
  {
    "text": "yours it's easy to do it's it's way easier than it was just even as recently",
    "start": "2936950",
    "end": "2941990"
  },
  {
    "text": "as a few years ago and hopefully your takeaway from today was that you have a slightly better understanding of where",
    "start": "2941990",
    "end": "2947120"
  },
  {
    "text": "some of these tools can fit into solving your business problems and again I'll hang around after I'm happy to talk more",
    "start": "2947120",
    "end": "2952400"
  },
  {
    "text": "detail about your individual problems but thank you for your time",
    "start": "2952400",
    "end": "2957040"
  }
]
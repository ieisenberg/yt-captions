[
  {
    "start": "0",
    "end": "43000"
  },
  {
    "text": "Hi, everyone. Thank you \nfor coming to this session.",
    "start": "0",
    "end": "2503"
  },
  {
    "text": "My name is Hong, and I'm here today \nwith Usamah to share some practical",
    "start": "3139",
    "end": "6039"
  },
  {
    "text": "learnings we've gained from running \nthousands of Flink jobs on our platform.",
    "start": "6039",
    "end": "9370"
  },
  {
    "text": "So we both work for Kinesis \nData Analytics, which is a managed",
    "start": "9967",
    "end": "13052"
  },
  {
    "text": "Flink offering on AWS.",
    "start": "13052",
    "end": "14765"
  },
  {
    "text": "So in essence, what we offer is \nyou give us your Flink job, we run",
    "start": "15292",
    "end": "18796"
  },
  {
    "text": "it for you on our Flink clusters.",
    "start": "18796",
    "end": "20442"
  },
  {
    "text": "So over the course of running lots \nand lots of these different Flink jobs,",
    "start": "21123",
    "end": "24005"
  },
  {
    "text": "we've identified some common issues \nthat you might face with configuring a",
    "start": "24006",
    "end": "27399"
  },
  {
    "text": "Flink cluster for a Flink job.",
    "start": "27399",
    "end": "29214"
  },
  {
    "text": "So as a customer on our service, you\ndon't need to worry about these things,",
    "start": "30000",
    "end": "32596"
  },
  {
    "text": "because we manage the Flink cluster \nfor you, but we hope that in our sharing",
    "start": "32596",
    "end": "36044"
  },
  {
    "text": "today, you can get a bit of insight \ninto how you might want to tune",
    "start": "36044",
    "end": "39059"
  },
  {
    "text": "a Flink cluster for a Flink job, \nif you were to run it yourself.",
    "start": "39060",
    "end": "42118"
  },
  {
    "start": "43000",
    "end": "43000"
  },
  {
    "text": "So a quick outline of what we'll cover today.",
    "start": "43325",
    "end": "45622"
  },
  {
    "text": "One of the big issues we've found \nis if you misconfigure your Flink",
    "start": "46698",
    "end": "49827"
  },
  {
    "text": "cluster's memory, you \nmight cause job instability.",
    "start": "49827",
    "end": "53054"
  },
  {
    "text": "So what we're going to cover here is \nsome common issues that we faced",
    "start": "53647",
    "end": "57540"
  },
  {
    "text": "and how you can debug them and how you \ncan fix them by tuning your Flink configuration.",
    "start": "57540",
    "end": "61470"
  },
  {
    "text": "So the next issue we've seen is \nselecting your state backend and",
    "start": "62919",
    "end": "66450"
  },
  {
    "text": "tuning it for your Flink job.",
    "start": "66450",
    "end": "68150"
  },
  {
    "text": "So we've found that this affects your job\nperformance quite drastically, so we're",
    "start": "68327",
    "end": "72240"
  },
  {
    "text": "going to cover how you can select \nthe right state backend and tune it.",
    "start": "72240",
    "end": "75060"
  },
  {
    "start": "76000",
    "end": "76000"
  },
  {
    "text": "So let's get started.",
    "start": "76267",
    "end": "77214"
  },
  {
    "text": "To make sure we're on the same page, this \nis the Flink cluster setup we're considering.",
    "start": "77499",
    "end": "81039"
  },
  {
    "text": "So we're considering the Flink \ncluster setup on Kubernetes.",
    "start": "81412",
    "end": "83914"
  },
  {
    "text": "We have one job manager and multiple\n task managers, and each of these",
    "start": "84068",
    "end": "87758"
  },
  {
    "text": "will be running in its own container.",
    "start": "87758",
    "end": "89152"
  },
  {
    "text": "So each task manager will be its \nown container, and it will have its",
    "start": "89482",
    "end": "93124"
  },
  {
    "text": "own CPU and memory configurations.",
    "start": "93124",
    "end": "95140"
  },
  {
    "text": "So job instability.",
    "start": "96523",
    "end": "98002"
  },
  {
    "start": "97000",
    "end": "97000"
  },
  {
    "text": "We found that a big cause of job \ninstability is memory misconfiguration.",
    "start": "98617",
    "end": "102239"
  },
  {
    "text": "Consider this graph.",
    "start": "102898",
    "end": "103852"
  },
  {
    "text": "On the Y axis you can see the memory \nuse of the task manager container,",
    "start": "104115",
    "end": "109234"
  },
  {
    "text": "and you can see how it \nprogresses over time.",
    "start": "109234",
    "end": "111178"
  },
  {
    "text": "So in this situation, we are setting \nthe container limit to four gigabytes,",
    "start": "112671",
    "end": "117055"
  },
  {
    "text": "and we are telling Flink you also \nhave four gigabytes of memory to use,",
    "start": "117055",
    "end": "120416"
  },
  {
    "text": "so it shouldn't be a problem, right?",
    "start": "120416",
    "end": "121768"
  },
  {
    "text": "Four gigabytes and four gigabytes.",
    "start": "122317",
    "end": "124110"
  },
  {
    "text": "But you can see there is a problem.",
    "start": "124857",
    "end": "126459"
  },
  {
    "text": "So you can see where the graph drops.",
    "start": "126854",
    "end": "129011"
  },
  {
    "text": "That's when the task manager is getting \nOOM-Killed, so it's using too much memory, ",
    "start": "129166",
    "end": "133286"
  },
  {
    "text": "and that containerized environment is \nkilling the Flink task manager process.",
    "start": "133286",
    "end": "137213"
  },
  {
    "text": "We did a bit of investigation, and we\nincreased the container memory to",
    "start": "138312",
    "end": "141517"
  },
  {
    "text": "six gigabytes, while keeping the \nFlink configuration to four gigabytes.",
    "start": "141518",
    "end": "146013"
  },
  {
    "text": "So we're still telling Flink you have \nfour gigabytes of memory to use,",
    "start": "146233",
    "end": "149159"
  },
  {
    "text": "and you can see that it's clearly \nusing more than four gigabytes.",
    "start": "149159",
    "end": "151668"
  },
  {
    "text": "So the first question we \nwant to answer here is why?",
    "start": "152262",
    "end": "154657"
  },
  {
    "text": "Why is Flink using more than we've configured?",
    "start": "155000",
    "end": "157356"
  },
  {
    "text": "And second question we'll answer is\n how can we figure out where this",
    "start": "157751",
    "end": "160635"
  },
  {
    "text": "memory is coming from, and how \ncan we change the configuration",
    "start": "160635",
    "end": "163700"
  },
  {
    "text": "so that this doesn't happen?",
    "start": "163701",
    "end": "164889"
  },
  {
    "start": "166000",
    "end": "166000"
  },
  {
    "text": "So to understand that, we first understand \nhow memory is measured and used in this",
    "start": "166074",
    "end": "171114"
  },
  {
    "text": "environment that we're considering, and \n how the OOM-Kill process comes about.",
    "start": "171114",
    "end": "174534"
  },
  {
    "text": "So we're running on an instance.",
    "start": "175719",
    "end": "177129"
  },
  {
    "text": "The instance has lots of containers.",
    "start": "177130",
    "end": "179106"
  },
  {
    "text": "And on that container you \ncan have many processes.",
    "start": "179106",
    "end": "181060"
  },
  {
    "text": "So you have the Flink process itself,",
    "start": "181060",
    "end": "183272"
  },
  {
    "text": "and as part of running the Flink \nprocess, you might have other processes",
    "start": "183272",
    "end": "186547"
  },
  {
    "text": "as well that are spun up, like Python \nprocessors or Kinesis producer processors.",
    "start": "186547",
    "end": "190084"
  },
  {
    "text": "How is memory measured?",
    "start": "191446",
    "end": "192537"
  },
  {
    "text": "The first way memory is measured \nis by the Java process itself.",
    "start": "193174",
    "end": "196261"
  },
  {
    "text": "So Flink exposes metrics for \nJVM heap use and off-heap use.",
    "start": "196678",
    "end": "200487"
  },
  {
    "text": "And that measures how much memory\n the Flink process itself is using.",
    "start": "200861",
    "end": "203780"
  },
  {
    "text": "It won't be able to tell you how \nmuch memory life the Python",
    "start": "204329",
    "end": "206780"
  },
  {
    "text": "process or Kinesis producer is using.",
    "start": "206780",
    "end": "209026"
  },
  {
    "text": "To measure that, you have to use \nthe container memory metrics itself.",
    "start": "209290",
    "end": "212560"
  },
  {
    "text": "So on Kubernetes, you can spin up \na cAdvisor process on your instance,",
    "start": "213725",
    "end": "218227"
  },
  {
    "text": "and that will measure how much \nmemory the entire container is using,",
    "start": "218227",
    "end": "221126"
  },
  {
    "text": "including all the processors.",
    "start": "221126",
    "end": "222423"
  },
  {
    "text": "Where does the OOM-Kill come about?",
    "start": "223543",
    "end": "225110"
  },
  {
    "text": "The OOM-Kill comes about when your \ncontainer is - the processes in your",
    "start": "225483",
    "end": "227970"
  },
  {
    "text": "container is using too much memory, and \nthe OS itself is running out of memory to use.",
    "start": "227970",
    "end": "233037"
  },
  {
    "text": "So when it runs out of memory, it will spin \nup this process called the OOM-Killer,",
    "start": "233037",
    "end": "236387"
  },
  {
    "text": "which is a very lightweight process \nthat will just select one of the",
    "start": "236387",
    "end": "238978"
  },
  {
    "text": "processes in the container to \nkill and free up some memory.",
    "start": "238978",
    "end": "242713"
  },
  {
    "text": "So that's where the OOM-Killer comes from.",
    "start": "243350",
    "end": "245271"
  },
  {
    "text": "Let's understand where the memory\n measurement comes from, right?",
    "start": "246523",
    "end": "249112"
  },
  {
    "start": "247000",
    "end": "247000"
  },
  {
    "text": "So the Flink process itself \nmeasures its memory.",
    "start": "249112",
    "end": "251922"
  },
  {
    "text": "The container itself measures its memory.",
    "start": "252252",
    "end": "253997"
  },
  {
    "text": "And the OS actually has this \nconcept of virtual and real memory,",
    "start": "254305",
    "end": "257443"
  },
  {
    "text": "like if you look at the cAdvisor metrics,\n you can actually see this concept of",
    "start": "257443",
    "end": "260517"
  },
  {
    "text": "virtual and real memory. \nSo what is that?",
    "start": "260517",
    "end": "262030"
  },
  {
    "text": "Real memory is the actual memory \nthat you're using on the instance itself,",
    "start": "262382",
    "end": "266832"
  },
  {
    "text": "the physical memory that you're using.",
    "start": "266833",
    "end": "268344"
  },
  {
    "text": "And virtual memory is just this \nconcept that the OS starts up",
    "start": "268761",
    "end": "271866"
  },
  {
    "text": "so that it can optimize memory use.",
    "start": "271867",
    "end": "274624"
  },
  {
    "text": "Let's say your Java process \nis 100 gigabytes of memory.",
    "start": "275000",
    "end": "278232"
  },
  {
    "text": "It will do a system call to the OS,",
    "start": "278891",
    "end": "281169"
  },
  {
    "text": "and the OS will provision 100 gigabytes\n of memory in virtual memory.",
    "start": "281169",
    "end": "284121"
  },
  {
    "text": "And how this virtual memory actually \nmaps to real memory is abstracted",
    "start": "284582",
    "end": "288110"
  },
  {
    "text": "away from the Java process.",
    "start": "288110",
    "end": "289120"
  },
  {
    "text": "It doesn't see it, and the OS \nhandles this mapping on its own.",
    "start": "289121",
    "end": "291926"
  },
  {
    "text": "This real memory use is what the OOM-\nKiller measures, is what the OS looks at",
    "start": "292475",
    "end": "297662"
  },
  {
    "text": "before it spins up the OOM-Killer.",
    "start": "297662",
    "end": "299074"
  },
  {
    "text": "So when you run out of real memory, \nthe OS will spin up the OOM-Killer.",
    "start": "299207",
    "end": "302539"
  },
  {
    "text": "It's important to understand, first, you \nhave Java memory, right, and then you",
    "start": "302978",
    "end": "305681"
  },
  {
    "text": "have the container memory, and all \nof this happens in virtual memory.",
    "start": "305681",
    "end": "309020"
  },
  {
    "text": "The mapping of this virtual memory \nto real memory is handled by the OS.",
    "start": "309437",
    "end": "312046"
  },
  {
    "text": "And when you run out of real memory, \nthen the OOM-Killer is spun up.",
    "start": "312156",
    "end": "314752"
  },
  {
    "text": "First learning here is Java process \nmemory is not the only memory that's used.",
    "start": "315982",
    "end": "320163"
  },
  {
    "text": "Measure both Java memory \nand the container memory.",
    "start": "320272",
    "end": "322578"
  },
  {
    "text": "Second learning here is real memory \nis not the same as virtual memory, and",
    "start": "323697",
    "end": "327011"
  },
  {
    "text": "it's non-trivial to map it backwards historically, \nso you should measure both all the time.",
    "start": "327011",
    "end": "331185"
  },
  {
    "text": "cAdvisor will give you that for free.",
    "start": "331865",
    "end": "333306"
  },
  {
    "text": "And the third learning here \nis actually quite nuanced.",
    "start": "334449",
    "end": "336341"
  },
  {
    "text": "So when the OOM-Killer spins up, \n it doesn't necessarily understand",
    "start": "336341",
    "end": "339589"
  },
  {
    "text": "the concept of the container, \nso it just selects a process.",
    "start": "339589",
    "end": "342284"
  },
  {
    "text": "It can select the Python or the Kinesis \nproducer process - so it might not",
    "start": "342284",
    "end": "344912"
  },
  {
    "text": "select the Flink process - and kills it.",
    "start": "344912",
    "end": "346841"
  },
  {
    "text": "So when that happens, you might have a \nFlink job that's running in a very weird state.",
    "start": "347193",
    "end": "350525"
  },
  {
    "text": "And the way you work around this is by \nactually using the new version of cgroups.",
    "start": "350525",
    "end": "355561"
  },
  {
    "text": "If you use cgroups v.2, it will \nunderstand the concept of container,",
    "start": "356023",
    "end": "358511"
  },
  {
    "text": "and it will kill your entire container \nrather than killing a single process.",
    "start": "358511",
    "end": "361063"
  },
  {
    "text": "So just to summarize, we've learned \nrecord both Java and container memory,",
    "start": "361634",
    "end": "365770"
  },
  {
    "text": "use virtual and real memory,",
    "start": "365770",
    "end": "367530"
  },
  {
    "text": "and OOM-Killer can cause broken containers,\n so you want to operate your cgroups to V.2.",
    "start": "367531",
    "end": "371023"
  },
  {
    "text": "Right. So now we understand \nwhere the OOM-kill comes from.",
    "start": "371308",
    "end": "374132"
  },
  {
    "start": "375000",
    "end": "375000"
  },
  {
    "text": "So let's try and understand a bit more.",
    "start": "375000",
    "end": "376655"
  },
  {
    "text": "You've told Flink it has \nfour gigabytes of memory.",
    "start": "376743",
    "end": "378807"
  },
  {
    "text": "How does Flink actually use this memory?",
    "start": "379202",
    "end": "380914"
  },
  {
    "text": "So here, we'll consider the \ndifferent buckets that Flink gives you",
    "start": "381661",
    "end": "385000"
  },
  {
    "text": "to configure and how that \nactually maps to the Java buckets.",
    "start": "385000",
    "end": "388196"
  },
  {
    "text": "So it's important, because Flink does \nthis behind the hood. It does it for you.",
    "start": "388328",
    "end": "391225"
  },
  {
    "text": "So you tell Flink, I have four gigabytes \nof memory, and I want to split this",
    "start": "391225",
    "end": "394132"
  },
  {
    "text": "memory based on a certain proportion\n for Heap, certain proportion for",
    "start": "394132",
    "end": "398336"
  },
  {
    "text": "Metaspace, certain proportion for network.",
    "start": "398337",
    "end": "400594"
  },
  {
    "text": "And Flink handles this mapping \nfor you behind the scenes.",
    "start": "400968",
    "end": "403353"
  },
  {
    "text": "So let's look at this and see how if you \nuse too much memory in each of these",
    "start": "403595",
    "end": "407078"
  },
  {
    "text": "buckets, how it surfaces.",
    "start": "407078",
    "end": "409017"
  },
  {
    "text": "Most of these buckets are kind of standard.",
    "start": "409478",
    "end": "412301"
  },
  {
    "text": "The only one that's kind of interesting \nto talk about is the overhead.",
    "start": "412674",
    "end": "415368"
  },
  {
    "text": "So when Flink says Flink overhead,",
    "start": "416268",
    "end": "417772"
  },
  {
    "text": "it actually refers to memory that the \nJVM process itself needs to run,",
    "start": "417772",
    "end": "421972"
  },
  {
    "text": "so that can include things like garbage \ncollection or threat stacks or string",
    "start": "421972",
    "end": "425931"
  },
  {
    "text": "interning, so any overhead process \nthat JVM itself needs to run.",
    "start": "425932",
    "end": "431027"
  },
  {
    "text": "So let's look at it.",
    "start": "432016",
    "end": "433460"
  },
  {
    "text": "When you tell Flink you have a certain \namount of memory for Heap, it will",
    "start": "433767",
    "end": "436799"
  },
  {
    "text": "actually use XMX to control your \namount of Java Heap it uses, right?",
    "start": "436799",
    "end": "440729"
  },
  {
    "text": "So if you use too much Heap, you \nactually get a Heap OOM exception,",
    "start": "440729",
    "end": "444158"
  },
  {
    "text": "so relatively straightforward.",
    "start": "444158",
    "end": "446018"
  },
  {
    "text": "If you see a Heap OOM, you know \nyou're running out of Heap memory.",
    "start": "446129",
    "end": "448264"
  },
  {
    "text": "And when you tell Flink a certain \namount of Flink Metaspace,",
    "start": "449208",
    "end": "451380"
  },
  {
    "text": "it also sets the Metaspace size as well.",
    "start": "451380",
    "end": "453408"
  },
  {
    "text": "So if you run out of it, you get Metaspace OOM.",
    "start": "453496",
    "end": "455274"
  },
  {
    "text": "For network memory, it \nsets the direct memory size,",
    "start": "456174",
    "end": "458306"
  },
  {
    "text": "and you run out of it, you \nget direct memory OOM.",
    "start": "458306",
    "end": "460000"
  },
  {
    "text": "So these are relatively straightforward, \nbecause if you run out of a certain type",
    "start": "460198",
    "end": "463471"
  },
  {
    "text": "of memory, the exception tells you \nwhich memory you're running out of.",
    "start": "463471",
    "end": "466468"
  },
  {
    "text": "The next three components, buckets, \nare a little bit more tricky, because",
    "start": "467653",
    "end": "471568"
  },
  {
    "text": "Java itself doesn't allow you to \ncontrol these buckets of memory.",
    "start": "471568",
    "end": "474630"
  },
  {
    "text": "So if you use too much of this memory,\n what will end up happening is that you",
    "start": "475000",
    "end": "479613"
  },
  {
    "text": "just use too much memory \nand you get OOM-Killed, right?",
    "start": "479613",
    "end": "482105"
  },
  {
    "text": "Because then your process \nwill use too much memory.",
    "start": "482105",
    "end": "484421"
  },
  {
    "text": "In all of these buckets, they all collapse\ninto OOM-Killed, because OOM-Killed is",
    "start": "485585",
    "end": "488932"
  },
  {
    "text": "a very generic error that just says your\ncontainer is using too much memory.",
    "start": "488933",
    "end": "491972"
  },
  {
    "text": "Whenever you look at a exception and \nyou see OOM-Killed, you know that it's",
    "start": "492718",
    "end": "496485"
  },
  {
    "text": "probably one of these buckets, right?",
    "start": "496485",
    "end": "498116"
  },
  {
    "text": "And if you see Heap OOM, Metaspace \nOOM, or direct memory OOM, you know",
    "start": "498248",
    "end": "500591"
  },
  {
    "text": "it's one of the other buckets \nthat's causing this issue.",
    "start": "500592",
    "end": "503513"
  },
  {
    "text": "So another interesting point \nto talk about here is JNI.",
    "start": "504501",
    "end": "507178"
  },
  {
    "text": "What is JNI? So JNI is Java Native Interface.",
    "start": "507178",
    "end": "510158"
  },
  {
    "text": "That's when the Java process spins up a native \nprocess, like an example for Flink is RocksDB.",
    "start": "510158",
    "end": "516125"
  },
  {
    "text": "So RocksDB is written in C++, so when \nFlink spins it up, it doesn't actually use",
    "start": "516125",
    "end": "520716"
  },
  {
    "text": "Java memory,  it uses a JNI interface.",
    "start": "520717",
    "end": "522587"
  },
  {
    "text": "And Flink tries and controls it, actually, \nthis concept of managed memory, but",
    "start": "522588",
    "end": "526651"
  },
  {
    "text": "in most cases, it's fine, but if you spin\nup other JNI processes, you might use",
    "start": "526651",
    "end": "531820"
  },
  {
    "text": "an uncontrollable amount of \nmemory, and you get OOM-Killed.",
    "start": "531820",
    "end": "534691"
  },
  {
    "text": "So let's take a step back, right? So \nwhat have we learned from this slide?",
    "start": "535964",
    "end": "538589"
  },
  {
    "text": "So first is if you look at the exceptions \nthat you're seeing, the other memory",
    "start": "538590",
    "end": "541790"
  },
  {
    "text": "exceptions, generally, Heap OOM, \nMetaspace OOM, and direct OOM,",
    "start": "541790",
    "end": "545690"
  },
  {
    "text": "they are all pretty clear on which \nbucket of memory you're running out of,",
    "start": "545690",
    "end": "549849"
  },
  {
    "text": "and you can change your configuration\nfor a Flink cluster to fit that.",
    "start": "549849",
    "end": "553368"
  },
  {
    "text": "But for the other buckets, you get OOM-\nKilled, and then you have to dive deeper",
    "start": "553961",
    "end": "556862"
  },
  {
    "text": "and to figure out which \nbucket it's actually using.",
    "start": "556862",
    "end": "558874"
  },
  {
    "start": "560000",
    "end": "560000"
  },
  {
    "text": "And another learning here is pretty \nclear, Java is not made just of Heap.",
    "start": "560103",
    "end": "563557"
  },
  {
    "text": "You have lots of other memory that it's using \nas well, so it's important to understand that.",
    "start": "563711",
    "end": "567005"
  },
  {
    "text": "So one of the common issues we've seen \nis actually your overhead memory is too low.",
    "start": "568015",
    "end": "572453"
  },
  {
    "text": "So, in Flink, some task managers \ngenerally might have a big Heap, so",
    "start": "572585",
    "end": "577629"
  },
  {
    "text": "you might provision the task manager \nwith like 200 gigabytes of Heap, right?",
    "start": "577629",
    "end": "581201"
  },
  {
    "text": "And by default, Flink limits the \noverhead memory to 1 gigabyte,",
    "start": "581508",
    "end": "584299"
  },
  {
    "text": "so you can see that probably is not \nenough for your garbage collection,",
    "start": "584299",
    "end": "586821"
  },
  {
    "text": "so you probably want to change the maximum \nand increase it to a suitable amount.",
    "start": "586821",
    "end": "591128"
  },
  {
    "text": "We've found that that's a \ncommon issue if you have big Heap,",
    "start": "591940",
    "end": "594096"
  },
  {
    "text": "the JVM overhead is too low, \nand you run into OOM-Kill.",
    "start": "594096",
    "end": "597037"
  },
  {
    "text": "For the other buckets, it's generally a \nbit harder to figure it out, but here,",
    "start": "598222",
    "end": "602555"
  },
  {
    "text": "we provide you some tools \nthat you can use to investigate.",
    "start": "602555",
    "end": "604883"
  },
  {
    "text": "We've found that using native memory\n tracking under JVM itself is pretty useful.",
    "start": "605059",
    "end": "608965"
  },
  {
    "text": "So you enable it by this argument,",
    "start": "609141",
    "end": "610933"
  },
  {
    "text": "and then you can run the J \ncommand process in your container.",
    "start": "610933",
    "end": "613675"
  },
  {
    "text": "And another one that we've \nfound pretty useful is jemalloc.",
    "start": "614751",
    "end": "617334"
  },
  {
    "text": "So this helps you with \nprocesses that are native, right?",
    "start": "617334",
    "end": "620898"
  },
  {
    "text": "Because they don't go through \nthe Java memory process.",
    "start": "620898",
    "end": "623877"
  },
  {
    "text": "It does a sys call directly to retrieve \nmemory, to allocate memory.",
    "start": "624074",
    "end": "627842"
  },
  {
    "text": "So in this case, the je memory \nallocator, will allow you to track back",
    "start": "628173",
    "end": "632644"
  },
  {
    "text": "which process is actually requesting this \nmemory, and how much of it it's actually using.",
    "start": "632645",
    "end": "637062"
  },
  {
    "text": "So that memory profiler allows \nyou to see where it's coming from.",
    "start": "637413",
    "end": "640285"
  },
  {
    "text": "So these two are generally useful.",
    "start": "640285",
    "end": "641602"
  },
  {
    "text": "Now that we understand these are \nthe classic issues for memory and",
    "start": "642612",
    "end": "645748"
  },
  {
    "start": "643000",
    "end": "643000"
  },
  {
    "text": "how you can debug them, let's go on to \nanother common cause of job instability.",
    "start": "645748",
    "end": "650648"
  },
  {
    "text": "So we've found that in some cases for \ncustomers, the Flink job just stops processing.",
    "start": "650912",
    "end": "655230"
  },
  {
    "text": "It's running fine, but it suddenly just \nstops processing records mysteriously.",
    "start": "655231",
    "end": "659556"
  },
  {
    "text": "So we call that a hung job.",
    "start": "659556",
    "end": "660902"
  },
  {
    "text": "It just doesn't process any records, and\n if you look at a checkpoint, sometimes",
    "start": "661231",
    "end": "665130"
  },
  {
    "text": "the checkpoints just \nstart timing out as well.",
    "start": "665130",
    "end": "667143"
  },
  {
    "text": "So you can see that here.",
    "start": "668263",
    "end": "669160"
  },
  {
    "text": "This is from the Flink dashboard.",
    "start": "669445",
    "end": "670695"
  },
  {
    "text": "You can see that the checkpoints are all failing.",
    "start": "670805",
    "end": "672893"
  },
  {
    "text": "And they're all failing because \nthey expired before completing.",
    "start": "673200",
    "end": "675331"
  },
  {
    "text": "So we've found that like typically in this\ncase you can see they all have the same",
    "start": "675814",
    "end": "678730"
  },
  {
    "text": "number of subtasks that acknowledged.",
    "start": "678730",
    "end": "680592"
  },
  {
    "text": "And that's a common symptom for \nwhen something in your Flink job is",
    "start": "681009",
    "end": "685962"
  },
  {
    "text": "causing the processing to halt, and it \njust stops processing, and that's why",
    "start": "685963",
    "end": "690000"
  },
  {
    "text": "you have this checkpoint expired.",
    "start": "690000",
    "end": "691669"
  },
  {
    "text": "So one typical way we've found to \nanalyze this, a pretty good way, is to",
    "start": "692877",
    "end": "696889"
  },
  {
    "start": "693000",
    "end": "693000"
  },
  {
    "text": "use thread dumps, because thread \ndumps will tell you what process is",
    "start": "696889",
    "end": "700113"
  },
  {
    "text": "actually using up CPU and stopping the\n job process, and from there, you can",
    "start": "700113",
    "end": "703556"
  },
  {
    "text": "analyze and walk backwards to which\n part of the call you need to change.",
    "start": "703557",
    "end": "706908"
  },
  {
    "text": "Here, I'm going to cover some common issues \nwe have seen that affects our customers.",
    "start": "708247",
    "end": "712224"
  },
  {
    "text": "So number one, we've seen that a \ncommon issue people don't realize",
    "start": "713014",
    "end": "715980"
  },
  {
    "text": "is a thread that's stuck on SocketRead.",
    "start": "715981",
    "end": "717883"
  },
  {
    "text": "So what is SocketRead? SocketRead can \ncome from many things, but in one case,",
    "start": "718322",
    "end": "721788"
  },
  {
    "text": "it's when you communicate with an \nexternal database or external system.",
    "start": "721788",
    "end": "725154"
  },
  {
    "text": "You send a request and you wait on a response.",
    "start": "725637",
    "end": "727530"
  },
  {
    "text": "And when you're waiting for a response,\n you read the socket for a response.",
    "start": "727771",
    "end": "731266"
  },
  {
    "text": "And if something happens on the \ndatabase side and no response comes back,",
    "start": "731530",
    "end": "735823"
  },
  {
    "text": "or the response gets dropped, you will\nstill be waiting on this SocketRead, right?",
    "start": "735823",
    "end": "740604"
  },
  {
    "text": "So typically, what happens is you set \na timer on this so that you don't wait",
    "start": "741153",
    "end": "744939"
  },
  {
    "text": "forever, and after a certain time, you \nstop and you retry a response, right?",
    "start": "744939",
    "end": "749469"
  },
  {
    "text": "So we found that in some clients, \nthey don't set the timer, and actually,",
    "start": "749469",
    "end": "752606"
  },
  {
    "text": "what happens is your job just \ngets stuck waiting for a response.",
    "start": "752606",
    "end": "755347"
  },
  {
    "text": "So, if you take a thread dump and \nyou constantly see your threads being",
    "start": "755456",
    "end": "758310"
  },
  {
    "text": "stuck on this SocketRead, and it's \nnever moving, right, chances are you",
    "start": "758310",
    "end": "762587"
  },
  {
    "text": "probably want to look \nat setting a socket timer.",
    "start": "762587",
    "end": "765298"
  },
  {
    "start": "766000",
    "end": "766000"
  },
  {
    "text": "So another issue that you can debug \nby taking thread dumps is deadlocks.",
    "start": "766287",
    "end": "769727"
  },
  {
    "text": "An example we found is for jackson-\ndatabind for older versions.",
    "start": "770000",
    "end": "773114"
  },
  {
    "text": "You can actually see that on the \nsame task manager, you are trying to",
    "start": "773531",
    "end": "777463"
  },
  {
    "text": "initialize these clusters that depend on\neach other, and because of that, they",
    "start": "777463",
    "end": "782038"
  },
  {
    "text": "are waiting on each other, and they just \nnever process. They are deadlocked.",
    "start": "782038",
    "end": "785535"
  },
  {
    "text": "If you take a thread dump and you look\n at it, you can understand which tasks",
    "start": "785908",
    "end": "789680"
  },
  {
    "text": "are actually just stopping your \nprocess from starting up, and you can",
    "start": "789680",
    "end": "792829"
  },
  {
    "text": "then walk backwards to figure out \nwhat you need to change in your code.",
    "start": "792829",
    "end": "795660"
  },
  {
    "text": "So let's take a step back and \nunderstand what we've covered so far.",
    "start": "797352",
    "end": "799929"
  },
  {
    "text": "So we've covered some Flink configurations \nfor memory that will cause job instability -",
    "start": "800000",
    "end": "806985"
  },
  {
    "text": "they will cause you to be stuck - and \nhow you can walk backwards from the",
    "start": "806985",
    "end": "809657"
  },
  {
    "text": "error that you're seeing, and to \nunderstand which bucket of memory",
    "start": "809658",
    "end": "812385"
  },
  {
    "text": "it comes from and how\n you can tune to fix it.",
    "start": "812385",
    "end": "814218"
  },
  {
    "text": "And we've also covered a couple of use\ncases where your job is not processing",
    "start": "814679",
    "end": "818378"
  },
  {
    "text": "any records, and how we can use thread \ndumps to debug what's happening there.",
    "start": "818378",
    "end": "821878"
  },
  {
    "text": "So now I'll pass over to Usamah, who's going\nto explain how you can tune your state backend.",
    "start": "822514",
    "end": "825996"
  },
  {
    "start": "827000",
    "end": "827000"
  },
  {
    "text": "Hi. I'm Usamah, an engineer at AWS, \nworking in the Kinesis Analytics team,",
    "start": "827379",
    "end": "832520"
  },
  {
    "text": "and I'll be talking about \nstate backends in Flink.",
    "start": "832520",
    "end": "835305"
  },
  {
    "text": "So a quick overview of what this \npresentation will be about is the",
    "start": "835744",
    "end": "838571"
  },
  {
    "text": "different types of state and the state \nbackends in Flink, a comparison of the",
    "start": "838571",
    "end": "841691"
  },
  {
    "text": "two state backends that Flink provides\nout of the box, and then some optimizations",
    "start": "841691",
    "end": "846337"
  },
  {
    "text": "you can make if you're using RocksDB\n as your state backend, to ensure you",
    "start": "846338",
    "end": "849807"
  },
  {
    "text": "can get the best performance \nfor your application.",
    "start": "849807",
    "end": "852665"
  },
  {
    "text": "So state is pretty important \nfor a lot of Flink applications.",
    "start": "853939",
    "end": "857939"
  },
  {
    "start": "854000",
    "end": "854000"
  },
  {
    "text": "It allows you to do more complex \nanalysis, using things such as",
    "start": "857939",
    "end": "861363"
  },
  {
    "text": "Windows or even things such as \nmachine learning models, where you",
    "start": "861363",
    "end": "865295"
  },
  {
    "text": "could use the state to store the \nparameters of the machine learning",
    "start": "865296",
    "end": "867716"
  },
  {
    "text": "model and update it over time.",
    "start": "867716",
    "end": "869797"
  },
  {
    "text": "And there's actually two types of state in Flink.",
    "start": "870368",
    "end": "872297"
  },
  {
    "text": "There's snapshot state and inflight state.",
    "start": "872538",
    "end": "875320"
  },
  {
    "text": "So snapshot state are things like \ncheckpoints and safe points.",
    "start": "875518",
    "end": "879147"
  },
  {
    "text": "These take a snapshot of a \nstate at a particular point in time.",
    "start": "879388",
    "end": "882864"
  },
  {
    "text": "It's recommended to store these in a highly \ndistributed file system, so something like AWS 3.",
    "start": "883193",
    "end": "887992"
  },
  {
    "text": "And this is important, because these\n checkpoints or snapshots of state are",
    "start": "888255",
    "end": "893142"
  },
  {
    "text": "required when recovering an \napplication from a fail state.",
    "start": "893142",
    "end": "896584"
  },
  {
    "text": "And if they were stored in something \nlike local disk connected to a task",
    "start": "896782",
    "end": "900584"
  },
  {
    "text": "manager that went down, then it would\ncause problems when it was trying to",
    "start": "900585",
    "end": "904679"
  },
  {
    "text": "recover, as the state would \nno longer be available.",
    "start": "904679",
    "end": "907567"
  },
  {
    "text": "So it's important to store these in \nsomewhere that's easily accessible,",
    "start": "907808",
    "end": "910618"
  },
  {
    "text": "and even if instances in \nyour Flink cluster do go down.",
    "start": "910618",
    "end": "915211"
  },
  {
    "text": "And the second type of state is inflight state.",
    "start": "916177",
    "end": "918617"
  },
  {
    "text": "Inflight state is the state that's actually \navailable to your application at runtime.",
    "start": "919254",
    "end": "923624"
  },
  {
    "text": "This is the state that it's reading from \nand the state that it can actually write to.",
    "start": "923887",
    "end": "927344"
  },
  {
    "text": "Flink needs to be aware of this \nstate, so it can manage it correctly.",
    "start": "927651",
    "end": "930817"
  },
  {
    "text": "This state is typically stored in \nmemory or in memory and local disk.",
    "start": "931015",
    "end": "934815"
  },
  {
    "text": "This is because it needs to be \naccessible as fast as possible.",
    "start": "935144",
    "end": "938285"
  },
  {
    "text": "Flink comes with two different \nstate backends out of the box,",
    "start": "938746",
    "end": "941529"
  },
  {
    "text": "HashMap state backend \nand RocksDB state backend.",
    "start": "941836",
    "end": "944348"
  },
  {
    "text": "So HashMap state backend uses \nHashMap that's on the Java Heap",
    "start": "944765",
    "end": "948031"
  },
  {
    "text": "to store state, whereas the embedded RocksDB \nstate backend uses RocksDB to store state.",
    "start": "948031",
    "end": "954029"
  },
  {
    "text": "RocksDB is an embedded key value store.",
    "start": "954358",
    "end": "957441"
  },
  {
    "text": "It stores state as a serializable byte \nstreams, and it's actually implemented",
    "start": "957640",
    "end": "962359"
  },
  {
    "text": "in C++ and it interfaces with Flink using JNI.",
    "start": "962359",
    "end": "966119"
  },
  {
    "text": "We'll have a quick comparison \nof these two on the next slide.",
    "start": "966646",
    "end": "969795"
  },
  {
    "start": "971000",
    "end": "971000"
  },
  {
    "text": "The first big difference between these two \nstate backends is the storage that they use.",
    "start": "971288",
    "end": "975782"
  },
  {
    "text": "The HashMap state backend is limited\nto the - it uses the Java Heap, whereas",
    "start": "976243",
    "end": "980238"
  },
  {
    "text": "RocksDB actually uses native memory, \nbecause it's not written in Java.",
    "start": "980238",
    "end": "984526"
  },
  {
    "text": "And it also has the ability to spill over to disk.",
    "start": "984526",
    "end": "987529"
  },
  {
    "text": "This means that the ceiling for \nthese two states is very different,",
    "start": "987529",
    "end": "990108"
  },
  {
    "text": "and so the HashMap is obviously \nlimited to the Java Heap, and generally,",
    "start": "990108",
    "end": "993693"
  },
  {
    "text": "this is limited to the total memory \nthat's available to an instance that the",
    "start": "993693",
    "end": "997924"
  },
  {
    "text": "task manager is running on, whereas \nRocksDB is limited by the file system,",
    "start": "997924",
    "end": "1002816"
  },
  {
    "text": "is typically larger for a lot more \ninstances, which means that RocksDB",
    "start": "1002816",
    "end": "1006034"
  },
  {
    "text": "has the capability to do a lot more \nstate and is good for applications",
    "start": "1006034",
    "end": "1010961"
  },
  {
    "text": "that have a lot of state, \nand it scales pretty well.",
    "start": "1010961",
    "end": "1013391"
  },
  {
    "text": "Incremental Checkpointing is \nsomething that was different",
    "start": "1013962",
    "end": "1016889"
  },
  {
    "text": "between these two state \nbackends until recently.",
    "start": "1016890",
    "end": "1018900"
  },
  {
    "text": "So Incremental Checkpointing is a \nfeature for state where instead of",
    "start": "1018900",
    "end": "1023647"
  },
  {
    "text": "actually taking the whole snapshot of \nthe state checkpoint, it only takes the",
    "start": "1023647",
    "end": "1028407"
  },
  {
    "text": "delta between the two checkpoints.",
    "start": "1028407",
    "end": "1030380"
  },
  {
    "text": "This delta is just the difference \nbetween the two snapshots.",
    "start": "1030885",
    "end": "1034173"
  },
  {
    "text": "And this tends to be a lot smaller \nthan taking an entire snapshot,",
    "start": "1034173",
    "end": "1037893"
  },
  {
    "text": "which means that checkpoints are \nfaster, and means that your Flink",
    "start": "1037894",
    "end": "1042046"
  },
  {
    "text": "cluster is spending less time \non actually taking checkpoints,",
    "start": "1042046",
    "end": "1044614"
  },
  {
    "text": "and more time on processing records.",
    "start": "1044614",
    "end": "1046449"
  },
  {
    "text": "This has been available in RocksDB for a long \nwhile, and it's been natively supported by RocksDB.",
    "start": "1046976",
    "end": "1051912"
  },
  {
    "text": "And until recently, it wasn't available in\n HashMap, but it has been available in",
    "start": "1051912",
    "end": "1056846"
  },
  {
    "text": "the HashMap state backend on the latest \nversions of Flink, using the changelog feature.",
    "start": "1056846",
    "end": "1062454"
  },
  {
    "text": "However, this is still currently \nin the experimental phase,",
    "start": "1062454",
    "end": "1065338"
  },
  {
    "text": "so that's something to be aware, \nif you do plan on using this feature.",
    "start": "1065338",
    "end": "1068446"
  },
  {
    "text": "The next difference, which comes out \nof the storage type that these two",
    "start": "1069346",
    "end": "1073783"
  },
  {
    "text": "backends use, is the read/write performance.",
    "start": "1073784",
    "end": "1076365"
  },
  {
    "text": "So HashMap state, because it's \nusing just the Java Heap, is very fast.",
    "start": "1076365",
    "end": "1081591"
  },
  {
    "text": "Generally, it has a higher performance\n than RocksDB, because RocksDB,",
    "start": "1081591",
    "end": "1084960"
  },
  {
    "text": "as it can spillover onto disk, it \nalso has to read and write from disk.",
    "start": "1084960",
    "end": "1088484"
  },
  {
    "text": "However, RocksDB does use a memory cache.",
    "start": "1088500",
    "end": "1090776"
  },
  {
    "text": "This means that if this memory cache\n is leveraged, then the performance",
    "start": "1091083",
    "end": "1094369"
  },
  {
    "text": "between RocksDB and \nHashMap tends to be smaller.",
    "start": "1094369",
    "end": "1097548"
  },
  {
    "text": "And it's important to be aware that \nRocksDB is designed to be fast on",
    "start": "1097702",
    "end": "1102938"
  },
  {
    "text": "writing and have relatively good \nperformance in reading, so it performs",
    "start": "1102938",
    "end": "1107471"
  },
  {
    "text": "all the writing to memory, and \neventually flushes this to disk,",
    "start": "1107471",
    "end": "1111106"
  },
  {
    "text": "which will come in handy \nlater on in the presentation.",
    "start": "1111107",
    "end": "1114916"
  },
  {
    "text": "Another thing to be aware, a small \nthing, but it's good to be aware,",
    "start": "1115377",
    "end": "1118190"
  },
  {
    "text": "is the garbage collection impact.",
    "start": "1118191",
    "end": "1119615"
  },
  {
    "text": "So because HashMap uses the Java Heap,\n it can be impacted by garbage collection.",
    "start": "1119615",
    "end": "1124468"
  },
  {
    "text": "So the state could be unavailable for \nthe short time during garbage collection.",
    "start": "1124556",
    "end": "1127670"
  },
  {
    "text": "However, RocksDB uses native \nmemory, so memory that's allocated",
    "start": "1127999",
    "end": "1131271"
  },
  {
    "text": "and managed by RocksDB itself, \nand this isn't on the Java Heap,",
    "start": "1131271",
    "end": "1136397"
  },
  {
    "text": "so it's not impacted by that at all.",
    "start": "1136397",
    "end": "1138531"
  },
  {
    "text": "And then finally is the data format \nthat these two state backends use.",
    "start": "1138816",
    "end": "1142137"
  },
  {
    "text": "So the HashMap uses plain old Java \nobjects to store state on the Heap,",
    "start": "1142137",
    "end": "1146632"
  },
  {
    "text": "whereas RocksDB actually serializes \nstate every time it reads and writes.",
    "start": "1146632",
    "end": "1150601"
  },
  {
    "text": "So this is why it's important to ensure \nthat any objects that you are going to",
    "start": "1150601",
    "end": "1154377"
  },
  {
    "text": "be storing on the state have optimized \nserializers and de-serializers, and it's",
    "start": "1154377",
    "end": "1160601"
  },
  {
    "text": "well-known that the default serializer in Flink, \nthe cryo serializer, isn't the best performing.",
    "start": "1160601",
    "end": "1165970"
  },
  {
    "text": "So it's important to make sure that you \ndo have a serializer and de-serializer",
    "start": "1165970",
    "end": "1170502"
  },
  {
    "text": "for any objects you are \nplanning to store in state.",
    "start": "1170503",
    "end": "1173325"
  },
  {
    "text": "So what does all of this mean?",
    "start": "1174664",
    "end": "1176556"
  },
  {
    "start": "1175000",
    "end": "1175000"
  },
  {
    "text": "And should you be using RocksDB \nor HashMap as a state backend?",
    "start": "1176557",
    "end": "1180867"
  },
  {
    "text": "So there are two important factors that play \ninto this, the first being the size of your state.",
    "start": "1181218",
    "end": "1186786"
  },
  {
    "text": "If you have a lot of state then you \nare limited to choosing RocksDB,",
    "start": "1186984",
    "end": "1190226"
  },
  {
    "text": "as the HashMap state backend \nphysically can't fit all your state",
    "start": "1190226",
    "end": "1194363"
  },
  {
    "text": "into memory, whereas RocksDB has the ability \nto spill over into disk, so it has a higher ceiling.",
    "start": "1194364",
    "end": "1199889"
  },
  {
    "text": "There are some things you can do to try and\n fit your state into the Hash Map state backend.",
    "start": "1200131",
    "end": "1204234"
  },
  {
    "text": "So for example, if you're using a lot of \nkeyed state, you can try to increase the",
    "start": "1204344",
    "end": "1208016"
  },
  {
    "text": "number of task managers and the \nparallelism of your job and try to",
    "start": "1208016",
    "end": "1211075"
  },
  {
    "text": "spread out the state across multiple \ntask managers and fit it in that way.",
    "start": "1211075",
    "end": "1214954"
  },
  {
    "text": "However, if you are going to do this,\n then it's important to be aware of data",
    "start": "1215283",
    "end": "1219476"
  },
  {
    "text": "skew to ensure that the state is \nbeing spread out and it's not being",
    "start": "1219476",
    "end": "1222797"
  },
  {
    "text": "dumped onto a single task manager.",
    "start": "1222797",
    "end": "1224871"
  },
  {
    "text": "And the next thing is performance.",
    "start": "1225793",
    "end": "1227589"
  },
  {
    "text": "So HashMap will have better \nperformance, because state is all in",
    "start": "1227589",
    "end": "1231423"
  },
  {
    "text": "memory, so the read and write will be better.",
    "start": "1231423",
    "end": "1234390"
  },
  {
    "text": "So if this is the key deciding factor for \nyou, then HashMap state backend is",
    "start": "1235136",
    "end": "1239226"
  },
  {
    "text": "the way to go, if your state will fit \ninto the HashMap and into memory.",
    "start": "1239226",
    "end": "1244609"
  },
  {
    "text": "If you are going to use this, then it's \nimportant to ensure that your managed",
    "start": "1245000",
    "end": "1247943"
  },
  {
    "text": "memory allocation is set to zero,",
    "start": "1247943",
    "end": "1249509"
  },
  {
    "text": "to ensure that the Java Heap \nhas as much state to work with,",
    "start": "1249509",
    "end": "1252969"
  },
  {
    "text": "so you can maximize the amount \nof memory you have for your state.",
    "start": "1252969",
    "end": "1257016"
  },
  {
    "text": "But what if you have a lot of state \nand it doesn't fit into HashMap",
    "start": "1257631",
    "end": "1260768"
  },
  {
    "text": "state backend, and you want to \nimprove the performance of RocksDB?",
    "start": "1260769",
    "end": "1265290"
  },
  {
    "text": "If you see that RocksDB is actually \na bottleneck for your application,",
    "start": "1265841",
    "end": "1268930"
  },
  {
    "text": "then there are some things you can do.",
    "start": "1268931",
    "end": "1270535"
  },
  {
    "text": "You can check if RocksDB is a bottleneck by \nusing things like thread dumps and Flink graphs.",
    "start": "1270886",
    "end": "1275788"
  },
  {
    "text": "If these show that a lot of CPU\n time is being spent in RocksDB.get",
    "start": "1276096",
    "end": "1279716"
  },
  {
    "text": "or RocksDB.write, then this is a good",
    "start": "1279717",
    "end": "1282232"
  },
  {
    "text": "indicator that the RocksDB state \nbackend is being a bottleneck for you.",
    "start": "1282232",
    "end": "1287208"
  },
  {
    "start": "1288000",
    "end": "1288000"
  },
  {
    "text": "Here are a couple of improvements you can \nmake to a couple of issues we've seen using Flink.",
    "start": "1288108",
    "end": "1293196"
  },
  {
    "text": "So the first issue is write stalls.",
    "start": "1293657",
    "end": "1295778"
  },
  {
    "text": "So write stalls occur when you're \nwriting state to the RocksDB engine",
    "start": "1295889",
    "end": "1300623"
  },
  {
    "text": "faster than it can compact \nthe state and flush it to disk.",
    "start": "1300623",
    "end": "1303749"
  },
  {
    "text": "When this happens, RocksDB will stop\ntaking any more writes until it manages",
    "start": "1304583",
    "end": "1308650"
  },
  {
    "text": "to catch up and flush the state onto disk, and \nto free up memory for it to take these writes.",
    "start": "1308650",
    "end": "1315314"
  },
  {
    "text": "And this is because RocksDB takes \nall writes, writes them to memory,",
    "start": "1315534",
    "end": "1319151"
  },
  {
    "text": "and then eventually flushes them to \ndisk, so if it doesn't have disk memory",
    "start": "1319151",
    "end": "1322485"
  },
  {
    "text": "available, then it will have \nto stop taking any writes.",
    "start": "1322485",
    "end": "1326046"
  },
  {
    "text": "This may seem like a weird feature to \nhave for RocksDB however, it's important,",
    "start": "1327461",
    "end": "1330968"
  },
  {
    "text": "as without these stalls, then RocksDB \ncould end up writing redundant data to",
    "start": "1330968",
    "end": "1334630"
  },
  {
    "text": "disk, and then taking longer to perform \nreads later down the line when trying to",
    "start": "1334630",
    "end": "1340511"
  },
  {
    "text": "read the state from the disk.",
    "start": "1340511",
    "end": "1342549"
  },
  {
    "text": "So the first way to improve this is \nto increase the RocksDB memory.",
    "start": "1343295",
    "end": "1346502"
  },
  {
    "text": "If RocksDB has more memory to play \nwith and it has more space to write to",
    "start": "1346787",
    "end": "1350585"
  },
  {
    "text": "in memory before it needs to flush it to \ndisk, so it can handle higher spikes in",
    "start": "1350585",
    "end": "1354616"
  },
  {
    "text": "writes, meaning that perhaps it doesn't\n need to actually store your writes.",
    "start": "1354616",
    "end": "1359805"
  },
  {
    "text": "So you can increase the RocksDB \nmemory by just increasing the amount",
    "start": "1360289",
    "end": "1363832"
  },
  {
    "text": "of memory your Flink has, \nincreasing the instance memory.",
    "start": "1363833",
    "end": "1367405"
  },
  {
    "text": "However, if that's not possible, then you\ncould perhaps take away some of the",
    "start": "1367493",
    "end": "1371456"
  },
  {
    "text": "memory from the Java Heap and allocate it to \nRocksDB using managed memory allocation.",
    "start": "1371456",
    "end": "1377047"
  },
  {
    "text": "However, it's important to ensure \nthat your Java Heap is relatively low",
    "start": "1377047",
    "end": "1381119"
  },
  {
    "text": "if you are going to do this to \nensure that you don't starve your",
    "start": "1381119",
    "end": "1383671"
  },
  {
    "text": "Java Heap of memory, either.",
    "start": "1383671",
    "end": "1385370"
  },
  {
    "text": "And a second thing, and the one that \nwe've found to be quite beneficial",
    "start": "1386643",
    "end": "1390758"
  },
  {
    "text": "when we've seen these problems \noccur, is increasing the number of",
    "start": "1390759",
    "end": "1393805"
  },
  {
    "text": "write threads that RocksDB uses to \ncompact the data and store it to disk.",
    "start": "1393805",
    "end": "1398006"
  },
  {
    "text": "This is by default one in Flink, I \nbelieve, and if you are increasing this,",
    "start": "1398489",
    "end": "1402628"
  },
  {
    "text": "if you have a lot of CPU available,",
    "start": "1402628",
    "end": "1404823"
  },
  {
    "text": "then more threads will be compacting \nthis state and writing it to disk.",
    "start": "1404823",
    "end": "1408896"
  },
  {
    "text": "And we have seen some significant \nimprovements in increasing this.",
    "start": "1409291",
    "end": "1413731"
  },
  {
    "text": "The third thing is to increase \nthe write buffer memory.",
    "start": "1414807",
    "end": "1418220"
  },
  {
    "text": "So RocksDB actually shares its \nmemory allocation between a write buffer,",
    "start": "1418528",
    "end": "1422278"
  },
  {
    "text": "where it takes writes and stores the \nstate in memory, and read cache.",
    "start": "1422279",
    "end": "1428177"
  },
  {
    "text": "So you can increase the \nwrite buffer memory size.",
    "start": "1428528",
    "end": "1431945"
  },
  {
    "text": "However, this will result \nin a smaller read cache.",
    "start": "1432122",
    "end": "1436032"
  },
  {
    "text": "So if you do this, then you're trading \noff write speed and read speed,",
    "start": "1436032",
    "end": "1441048"
  },
  {
    "text": "so it's important to keep that \nin mind if you do change this.",
    "start": "1441048",
    "end": "1445017"
  },
  {
    "text": "You can also fine-tune some of the \nspecific RocksDB configurations, like",
    "start": "1446137",
    "end": "1450418"
  },
  {
    "text": "the buffer size and the counts of these buffers,",
    "start": "1450418",
    "end": "1452601"
  },
  {
    "text": "but that's not something we'll \nbe going over in this presentation.",
    "start": "1452601",
    "end": "1455305"
  },
  {
    "text": "And the second issue is slow reads.",
    "start": "1456228",
    "end": "1458851"
  },
  {
    "text": "So this can occur if you are not \nhitting the cache very often and you're",
    "start": "1459136",
    "end": "1463427"
  },
  {
    "text": "spending a lot of time reading from \nthe disk and loading this into the cache",
    "start": "1463427",
    "end": "1467927"
  },
  {
    "text": "and then reading from there.",
    "start": "1467927",
    "end": "1469311"
  },
  {
    "text": "There's a couple of ways of improving this.",
    "start": "1469882",
    "end": "1471641"
  },
  {
    "text": "So the first thing is to ensure \nthat you're using local disk.",
    "start": "1471839",
    "end": "1474986"
  },
  {
    "text": "When RocksDB spills over onto disk, \nyou can set where it's spilling over into,",
    "start": "1475645",
    "end": "1479277"
  },
  {
    "text": "and it's important to set this to local \ndisk, preferably something like an SSD,",
    "start": "1479277",
    "end": "1483109"
  },
  {
    "text": "to ensure that there is the fastest read\n and write speeds when using disk.",
    "start": "1483109",
    "end": "1486890"
  },
  {
    "text": "It's important not to use something \nlike a distributed file system for this.",
    "start": "1486890",
    "end": "1491792"
  },
  {
    "text": "It may be tempting, because you feel like you \nwant the state to be available in case of a failure.",
    "start": "1491902",
    "end": "1496862"
  },
  {
    "text": "However, it's important to note that \nany state that any state that RocksDB",
    "start": "1496862",
    "end": "1500505"
  },
  {
    "text": "writes to this area is not used for fault \ntolerant recovery, so it's not important",
    "start": "1500505",
    "end": "1505022"
  },
  {
    "text": "for this to be available if your job goes\n down or if the task manager goes down.",
    "start": "1505022",
    "end": "1509293"
  },
  {
    "text": "So it's important to just use your fastest disk \nyou have available to your instance at the time.",
    "start": "1509446",
    "end": "1514053"
  },
  {
    "text": "Again, you can increase RocksDB \nmemory, increasing the managed",
    "start": "1515724",
    "end": "1518532"
  },
  {
    "text": "memory allocation, perhaps taking \naway memory from the Java Heap.",
    "start": "1518532",
    "end": "1522364"
  },
  {
    "text": "This will increase the read cache size \nto ensure that RocksDB has a larger",
    "start": "1522715",
    "end": "1528742"
  },
  {
    "text": "cache, and improving the number \nof cache hits that it will get.",
    "start": "1528743",
    "end": "1533195"
  },
  {
    "text": "You can increase the read cache size, \nagain, trading off the write buffer memory,",
    "start": "1533590",
    "end": "1538070"
  },
  {
    "text": "so if you increase this allocation, you'll\nreduce the write buffer memory allocation.",
    "start": "1538070",
    "end": "1542222"
  },
  {
    "text": "So it's important to keep this in mind.",
    "start": "1542530",
    "end": "1543904"
  },
  {
    "text": "However, it's something worth playing\n with, if you are running into a lot of",
    "start": "1543904",
    "end": "1547070"
  },
  {
    "text": "slow reads and write stalls \nare an issue for your application.",
    "start": "1547070",
    "end": "1551152"
  },
  {
    "text": "Thank you for watching our \npresentation, and we hope that you've",
    "start": "1553830",
    "end": "1557339"
  },
  {
    "text": "learned something, and you can tune \nyour state backends to improve your",
    "start": "1557339",
    "end": "1562319"
  },
  {
    "text": "applications' performance.",
    "start": "1562319",
    "end": "1564127"
  },
  {
    "text": "Thanks.",
    "start": "1564342",
    "end": "1566075"
  }
]
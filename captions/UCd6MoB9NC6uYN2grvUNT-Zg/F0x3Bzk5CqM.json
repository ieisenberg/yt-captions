[
  {
    "start": "0",
    "end": "74000"
  },
  {
    "text": "my name is sri allah prelude I'm part of AWS public sector team my role here is",
    "start": "390",
    "end": "5910"
  },
  {
    "text": "to introduce our guest speakers here so we have two speakers from NYU Harish",
    "start": "5910",
    "end": "12960"
  },
  {
    "text": "who's a assistant research professor at NYU as well as Fernando who's a research",
    "start": "12960",
    "end": "18330"
  },
  {
    "text": "student our PhD student at NYU they're going to be talking a little bit about",
    "start": "18330",
    "end": "23369"
  },
  {
    "text": "the effort and the project and the research activities that they're conducting which deals with taking",
    "start": "23369",
    "end": "30150"
  },
  {
    "text": "disparate data sources that are time-series based in an urban setting aggregating that data analyzing that",
    "start": "30150",
    "end": "37170"
  },
  {
    "text": "data and extracting valuable insights based off of that data and when it comes to doing it on premise it's well and",
    "start": "37170",
    "end": "44100"
  },
  {
    "text": "good but when you think about aggregating lots and lots of data becomes a little bit more challenging",
    "start": "44100",
    "end": "49140"
  },
  {
    "text": "and that's where they're doing experimentation in terms of scaling leveraging cloud resources so without",
    "start": "49140",
    "end": "56190"
  },
  {
    "text": "any additional delay I'll hand it over to Fernando all right so hello everyone",
    "start": "56190",
    "end": "64018"
  },
  {
    "text": "can everyone hear me yeah okay so let's talk about the polygamous nature of",
    "start": "64019",
    "end": "69479"
  },
  {
    "text": "urban datasets so recently lots of people have been talking about big urban",
    "start": "69479",
    "end": "76770"
  },
  {
    "start": "74000",
    "end": "74000"
  },
  {
    "text": "data so big data related to urban environments and what's the big deal about it",
    "start": "76770",
    "end": "81869"
  },
  {
    "text": "well cities are the lock locky of economic activity and it's where 50% of",
    "start": "81869",
    "end": "87420"
  },
  {
    "text": "our population is living right now and this number tends to grow so by true by",
    "start": "87420",
    "end": "93240"
  },
  {
    "text": "2050 this number will grow to 70% so of course with this growth comes many",
    "start": "93240",
    "end": "99930"
  },
  {
    "text": "problems that needs should be addressed but at the same time are really hard to solve so we have problems related to",
    "start": "99930",
    "end": "107369"
  },
  {
    "text": "transportation because have too many people with the resources that you have you also have problems with housing or",
    "start": "107369",
    "end": "113720"
  },
  {
    "text": "pollution with the environment but now the good news is that we have the data",
    "start": "113720",
    "end": "119340"
  },
  {
    "text": "the data the data is like the light at",
    "start": "119340",
    "end": "125790"
  },
  {
    "text": "the end of the tunnel and we can add lots of data have been collected throughout these years and we can use",
    "start": "125790",
    "end": "132720"
  },
  {
    "text": "this data to actual help better understand the cities so which kind of data we are talking about",
    "start": "132720",
    "end": "138930"
  },
  {
    "start": "138000",
    "end": "138000"
  },
  {
    "text": "here so we are talking about data about the infrastructure of the city for instance subway rides or tax trips we",
    "start": "138930",
    "end": "146130"
  },
  {
    "text": "are talking about here we also have data about the environment so a clear example of that is the weather data set and we",
    "start": "146130",
    "end": "153510"
  },
  {
    "text": "also have data that reflect the behavior of citizens which are usually which is usually reflected by social media data",
    "start": "153510",
    "end": "160610"
  },
  {
    "text": "so to understand the city one can understand the data exhaust from the different components of the city and",
    "start": "160610",
    "end": "167069"
  },
  {
    "text": "that brings a huge opportunity which is to make cities more efficient and",
    "start": "167069",
    "end": "172080"
  },
  {
    "text": "improve the lives of citizens so let's take a look at some examples of questions that data scientists or even",
    "start": "172080",
    "end": "179640"
  },
  {
    "start": "175000",
    "end": "175000"
  },
  {
    "text": "city agencies they may make while they are trying to explore this data to better understand the cities and in this",
    "start": "179640",
    "end": "185549"
  },
  {
    "text": "case I will use the city of New York as an example so the first question is related to the number of accidents car",
    "start": "185549",
    "end": "192870"
  },
  {
    "text": "accidents in the cities so if you have too many car accidents eval the question will be with a reduction in the traffic",
    "start": "192870",
    "end": "198989"
  },
  {
    "text": "speed reduce the number of accidents the second question is related to the",
    "start": "198989",
    "end": "204690"
  },
  {
    "text": "struggle that New York City residents have which is should get a taxi to take a taxi when it's raining and the",
    "start": "204690",
    "end": "210750"
  },
  {
    "text": "question is why is that so why is it so hard what can we do to actually improve the taxi service in rainy days and then",
    "start": "210750",
    "end": "218070"
  },
  {
    "text": "finally while they are trying to analyze for instance that the data about taxi",
    "start": "218070",
    "end": "223320"
  },
  {
    "text": "trips in the city throughout two different ears they realize that there are some drops in the number of taxi",
    "start": "223320",
    "end": "229410"
  },
  {
    "text": "trips in some particular points and then the question here is why is that so was",
    "start": "229410",
    "end": "235230"
  },
  {
    "text": "that a quote data quality problem maybe a corruption during the data collection or maybe there's something interesting",
    "start": "235230",
    "end": "240630"
  },
  {
    "text": "that happened in those points that we need to look to look at and if you look",
    "start": "240630",
    "end": "247500"
  },
  {
    "text": "at those questions more carefully you can see that they all play with interactions of different data sets so",
    "start": "247500",
    "end": "254519"
  },
  {
    "text": "for instance for the first question you have data about traffic speed and you also have data about number of accidents",
    "start": "254519",
    "end": "260489"
  },
  {
    "text": "for the second question you have the taxi data set interacting with the weather data set and then for the third",
    "start": "260489",
    "end": "266789"
  },
  {
    "text": "question you have the tax data set which may interact with other data sets to actually explain",
    "start": "266789",
    "end": "272560"
  },
  {
    "text": "those interesting patterns in the data so what we see here is that those urban",
    "start": "272560",
    "end": "278650"
  },
  {
    "start": "277000",
    "end": "277000"
  },
  {
    "text": "data interactions or those relationships between those data sets they can actually help us better understand the",
    "start": "278650",
    "end": "284950"
  },
  {
    "text": "cities and by uncovering those relationships you can also cover the interesting the important attributes of",
    "start": "284950",
    "end": "291310"
  },
  {
    "text": "those data sets that can be used for instance to model Priya - to have predictive models of the different",
    "start": "291310",
    "end": "297490"
  },
  {
    "text": "process of the city and as a matter of fact urban data sites that can be very polygamous because you may have many to",
    "start": "297490",
    "end": "304720"
  },
  {
    "text": "many relationships between them so attributes from one that I said interacting with many other attributes",
    "start": "304720",
    "end": "309790"
  },
  {
    "text": "from with from many other data sets so data are available as we mentioned",
    "start": "309790",
    "end": "316150"
  },
  {
    "text": "before so we are probably good right not exactly because here we are talking",
    "start": "316150",
    "end": "321220"
  },
  {
    "text": "about big data so for instance for for NYC open data which is the open data",
    "start": "321220",
    "end": "327190"
  },
  {
    "text": "portal for the for urban data in New York City we have 1200 data sets and",
    "start": "327190",
    "end": "332350"
  },
  {
    "text": "this number is still growing and the question now here is where do we start",
    "start": "332350",
    "end": "337360"
  },
  {
    "text": "which data sets we need to first analyze so that we can actually have those those questions answered and also for NYC open",
    "start": "337360",
    "end": "346480"
  },
  {
    "text": "data again we have more than 300 data sets that are spatial temporal which means that more than 300 data sets they",
    "start": "346480",
    "end": "353980"
  },
  {
    "text": "have spatial temporal components which makes the analogy that it adds a new layer of complexity because now you need",
    "start": "353980",
    "end": "361330"
  },
  {
    "text": "to look at perhaps different temporal slides and different spatial regions so attributes they may relate differently",
    "start": "361330",
    "end": "368200"
  },
  {
    "text": "depending on time and space and if you want to do to do this analysis manually you need to have all your hypotheses",
    "start": "368200",
    "end": "374230"
  },
  {
    "text": "beforehand and test them so first of all having all these hypotheses before him is sometimes even unfeasible because you",
    "start": "374230",
    "end": "381190"
  },
  {
    "text": "don't even know what exactly you're looking for and second testing all these hypotheses manually is very",
    "start": "381190",
    "end": "387070"
  },
  {
    "text": "time-consuming so our goal here is then to allow the user suppose what we call",
    "start": "387070",
    "end": "392440"
  },
  {
    "start": "389000",
    "end": "389000"
  },
  {
    "text": "relationship queries so for instance find all data sites related to our given data study so the idea then is to guide",
    "start": "392440",
    "end": "399070"
  },
  {
    "text": "users in this data exploration process how indentured and find those connections among this birth data and hopefully I",
    "start": "399070",
    "end": "405610"
  },
  {
    "text": "didn't find those variables that can be used to model the city and the questions",
    "start": "405610",
    "end": "411880"
  },
  {
    "text": "that I showed before can be easily translated to these queries so for instance so for instance for the first",
    "start": "411880",
    "end": "421449"
  },
  {
    "text": "question with the reduction in traffic speed reduce the number of accidents we could be translated to find our",
    "start": "421449",
    "end": "426699"
  },
  {
    "text": "relationships between collisions and traffic speed datasets and for the second question why the number of tax",
    "start": "426699",
    "end": "431800"
  },
  {
    "text": "strips is too low could be translated to find all the other sets related to the taxi data set and you can see that this may this can",
    "start": "431800",
    "end": "439240"
  },
  {
    "text": "help with hypothesis testing because you have a hypothesis in this case that the",
    "start": "439240",
    "end": "444370"
  },
  {
    "text": "number of accidents and the speed limit are related and you simply want to test it just to see to check if it's true or",
    "start": "444370",
    "end": "450900"
  },
  {
    "text": "it may also help you with hypotheses on because you don't know why the number of text strips is shallow but you want to",
    "start": "450900",
    "end": "457300"
  },
  {
    "text": "generate the hypothesis that may explain that behavior but of course make",
    "start": "457300",
    "end": "463030"
  },
  {
    "text": "allowing users suppose those types of queries comes with challenges so the first one is related to the definition",
    "start": "463030",
    "end": "469630"
  },
  {
    "start": "466000",
    "end": "466000"
  },
  {
    "text": "of the relationship itself how can we actually define a relationship between datasets so let's go back to our text",
    "start": "469630",
    "end": "476349"
  },
  {
    "text": "trips data set so you can see that there",
    "start": "476349",
    "end": "481599"
  },
  {
    "text": "are some some of these points in time where you have a low number of text trips and as a matter of fact if you",
    "start": "481599",
    "end": "487750"
  },
  {
    "text": "take a look at the wind speed data you see that the points where you have abnormally high wind speeds is where you",
    "start": "487750",
    "end": "493539"
  },
  {
    "text": "have a low number of taxi trips and this in this case this is related to the",
    "start": "493539",
    "end": "498970"
  },
  {
    "text": "Hurricanes that hit New York City in 2011-2012 so if you look at those two",
    "start": "498970",
    "end": "504520"
  },
  {
    "text": "data you can you can see that they are not actually much related if you look at",
    "start": "504520",
    "end": "509590"
  },
  {
    "text": "the entirety of the data and it is true that the wind would will not influence",
    "start": "509590",
    "end": "514719"
  },
  {
    "text": "that much the number of taxis in the city but only when you look at those interesting features that those",
    "start": "514719",
    "end": "520390"
  },
  {
    "text": "interesting happenings is that when you see the relationship it's where the relationship becomes visible so what we",
    "start": "520390",
    "end": "527080"
  },
  {
    "text": "are interested here isn't only relationships between those interesting features of the data and also because",
    "start": "527080",
    "end": "533770"
  },
  {
    "text": "we're talking about spatial temporal data that's here for instance if we have a car accident in one neighborhood this",
    "start": "533770",
    "end": "539560"
  },
  {
    "text": "may not this probably won't affect the the traffic in the neighborhood that is",
    "start": "539560",
    "end": "544839"
  },
  {
    "text": "true far away so you also need to take into account both time and space and what happens is that the conventional",
    "start": "544839",
    "end": "550990"
  },
  {
    "text": "techniques to find correlations between datasets they cannot find these relationships because first they look at",
    "start": "550990",
    "end": "556750"
  },
  {
    "text": "the entire data data and second they don't take into account both time and space the second challenge is related to",
    "start": "556750",
    "end": "564160"
  },
  {
    "text": "the large data complexity big urban data so again here we are talking about many many data sets and the data is available",
    "start": "564160",
    "end": "570940"
  },
  {
    "text": "at multiple spatial temporal resolutions and also the relationships can be between any of the attributes and these",
    "start": "570940",
    "end": "578980"
  },
  {
    "text": "data sets they may have many attributes so as an example for NYC open data we have an average of eight attributes per",
    "start": "578980",
    "end": "586389"
  },
  {
    "text": "data set and some data sets like the weather data set has more than 200 attributes so in that case you have a",
    "start": "586389",
    "end": "593170"
  },
  {
    "text": "common Authority a large number of relationships to evaluate so only for NYC open data for a single special",
    "start": "593170",
    "end": "599680"
  },
  {
    "text": "temporal resolution you have approximately 2.4 million relationships to evaluate so looking for meaningful",
    "start": "599680",
    "end": "606730"
  },
  {
    "text": "relationship is like finding a needle in a haystack so our approach then which is called",
    "start": "606730",
    "end": "613420"
  },
  {
    "start": "611000",
    "end": "611000"
  },
  {
    "text": "data polygamy has the goal to help the user in finding in generating those",
    "start": "613420",
    "end": "619149"
  },
  {
    "text": "hypotheses and testing them automatically in an efficient and scalable way and we address those challenges in two ways so for the first",
    "start": "619149",
    "end": "626350"
  },
  {
    "text": "challenge we use what we define as topology based relationships and for the second challenge we have our",
    "start": "626350",
    "end": "632920"
  },
  {
    "text": "implementation using MapReduce so now I will pass the torch to Harish and he",
    "start": "632920",
    "end": "639459"
  },
  {
    "text": "will talk more details about apology based relationships and then I'll come back to talk about implementation",
    "start": "639459",
    "end": "644730"
  },
  {
    "text": "thanks for Nigel so let me now briefly",
    "start": "644730",
    "end": "650050"
  },
  {
    "text": "introduce the mathematical concepts behind our technique and primarily what",
    "start": "650050",
    "end": "656079"
  },
  {
    "text": "we are interested in is to identify these relationships bit based on what is known as topological features so what do",
    "start": "656079",
    "end": "663160"
  },
  {
    "text": "I mean by topological features let's again consider our two favorite data sets which is the taxi data",
    "start": "663160",
    "end": "669370"
  },
  {
    "text": "and the weather data right so the kind of features we are interested in here correspond to these deep valleys or they",
    "start": "669370",
    "end": "677050"
  },
  {
    "text": "correspond to these Peaks harder okay right and these are what are",
    "start": "677050",
    "end": "684670"
  },
  {
    "text": "mathematically captured as critical points and so an advantage of using",
    "start": "684670",
    "end": "690610"
  },
  {
    "text": "computational topology to identify this is that the techniques from topology",
    "start": "690610",
    "end": "695740"
  },
  {
    "text": "naturally identifies these critical points of the data so in order to do",
    "start": "695740",
    "end": "700870"
  },
  {
    "text": "that let's formalize this further so how do you represent this data and how do you go about computing these features so",
    "start": "700870",
    "end": "707100"
  },
  {
    "text": "the data is represented by what is called as scalar functions and a scalar",
    "start": "707100",
    "end": "713740"
  },
  {
    "text": "function is essentially a map that map's points in space and time to a real value",
    "start": "713740",
    "end": "719230"
  },
  {
    "text": "right so let me again give you a concrete example so in this particular case we have taxi number of taxi trips",
    "start": "719230",
    "end": "725770"
  },
  {
    "text": "in New York City over time so the city or the spatial component here is essentially a single point and so you",
    "start": "725770",
    "end": "732100"
  },
  {
    "text": "have our time series and for each point in time you have a value right instead I",
    "start": "732100",
    "end": "737470"
  },
  {
    "text": "can increase the dimension over here and say let's look at our 2d slices of the",
    "start": "737470",
    "end": "743170"
  },
  {
    "text": "data over time so here I am showing two different examples at different",
    "start": "743170",
    "end": "748390"
  },
  {
    "text": "resolutions the first one is essentially where we divide Manhattan in this case",
    "start": "748390",
    "end": "753700"
  },
  {
    "text": "into a high resolution grid and for each cell of the grid we compute the number",
    "start": "753700",
    "end": "759040"
  },
  {
    "text": "of taxis in that cell right and the color map here basically says if there's",
    "start": "759040",
    "end": "764200"
  },
  {
    "text": "a high density of taxis then you have a bright red and if there's a low density",
    "start": "764200",
    "end": "769900"
  },
  {
    "text": "of taxis it becomes white the second example over here the resolution is basically the neighborhood",
    "start": "769900",
    "end": "775120"
  },
  {
    "text": "resolution where we divide Manhattan into its set of neighborhoods and we again count the density of taxis within",
    "start": "775120",
    "end": "781029"
  },
  {
    "text": "each neighborhood so when you look at 2d slices you can actually have each slice in multiple resolutions and then you can",
    "start": "781029",
    "end": "786970"
  },
  {
    "text": "again have it over different resolutions right so now given the scalar functions",
    "start": "786970",
    "end": "792100"
  },
  {
    "start": "792000",
    "end": "792000"
  },
  {
    "text": "how do we go about computing the topological features so we define a topological feature to be a neighborhood",
    "start": "792100",
    "end": "798280"
  },
  {
    "text": "of critical points and so let's visualize the data or the scalar",
    "start": "798280",
    "end": "806230"
  },
  {
    "text": "function as a terrain instead of a color map like I showed before so you can consider the space over here a set of",
    "start": "806230",
    "end": "812649"
  },
  {
    "text": "all points in the city and instead of giving a color to a point I give a height to that particular point",
    "start": "812649",
    "end": "818319"
  },
  {
    "text": "so here the scalar function is represented as a terrain so the kind of features we are interested in or the",
    "start": "818319",
    "end": "824649"
  },
  {
    "text": "kind of critical points we are interested in is basically the Maxima which correspond to the peaks of the",
    "start": "824649",
    "end": "830259"
  },
  {
    "text": "function and the set of minima which correspond to the valleys right and the",
    "start": "830259",
    "end": "836619"
  },
  {
    "text": "neighborhood of these critical points is essentially defined using a threshold so",
    "start": "836619",
    "end": "841720"
  },
  {
    "text": "what do I mean by this let's fix a particular threshold so in this case we have a function value and let's look at",
    "start": "841720",
    "end": "849429"
  },
  {
    "text": "all points above this threshold right so here we see there are two features two",
    "start": "849429",
    "end": "855939"
  },
  {
    "text": "components of the features corresponding to two of the Maxima of the function so this is what we define as the",
    "start": "855939",
    "end": "862600"
  },
  {
    "text": "neighborhood of these critical points and in this particular case since we are looking at Maxima we call them the",
    "start": "862600",
    "end": "868480"
  },
  {
    "text": "positive features similarly with respect to the minima or the valleys you can",
    "start": "868480",
    "end": "873490"
  },
  {
    "text": "again have a threshold and you can look at all points corresponding that have",
    "start": "873490",
    "end": "878529"
  },
  {
    "text": "function value less than this threshold so this gives us the neighborhood of the set of minima and in this case it's just",
    "start": "878529",
    "end": "885220"
  },
  {
    "text": "one component for it and we call this as negative features right and also given a",
    "start": "885220",
    "end": "892749"
  },
  {
    "text": "data set and a data representation as a set of the space is basically a set of",
    "start": "892749",
    "end": "898029"
  },
  {
    "text": "spatial-temporal points these features are going to be a subset of this point",
    "start": "898029",
    "end": "903160"
  },
  {
    "text": "so they are also going to be a set of spatial-temporal points so how is such a",
    "start": "903160",
    "end": "911620"
  },
  {
    "text": "definition basically going to help you in identifying interesting features let's look at a concrete example so here",
    "start": "911620",
    "end": "918429"
  },
  {
    "text": "what we have is again the set of taxi trips so for the taxi data essentially",
    "start": "918429",
    "end": "924699"
  },
  {
    "text": "consists of all trips that happened in Manhattan or in New York City and for each trip we have the pickup location",
    "start": "924699",
    "end": "931120"
  },
  {
    "text": "and the drop-off location which is provided as GPS coordinates right and",
    "start": "931120",
    "end": "936190"
  },
  {
    "text": "what time and here what we are showing is basically set of all trips that",
    "start": "936190",
    "end": "942400"
  },
  {
    "text": "happened in this neighborhood of Manhattan between 8 a.m. and 9 a.m. on",
    "start": "942400",
    "end": "948340"
  },
  {
    "text": "May 1st 2011 why is this interesting so if you look at this particular region so",
    "start": "948340",
    "end": "955510"
  },
  {
    "text": "this corresponds to 6th Avenue in Manhattan you can see that there are no pickups or drop-offs in that region and",
    "start": "955510",
    "end": "961330"
  },
  {
    "text": "the reason for that is the whole Avenue over there is blocked to traffic because there was a fiber or bike tour that",
    "start": "961330",
    "end": "967720"
  },
  {
    "text": "happens that happened during that time right so now if we assign if we use",
    "start": "967720",
    "end": "973360"
  },
  {
    "text": "appropriate threshold and look at the negative features we actually find the",
    "start": "973360",
    "end": "978760"
  },
  {
    "text": "exact path taken by the bike tour as a feature as a negative feature of this",
    "start": "978760",
    "end": "984610"
  },
  {
    "text": "data right and so if you notice we don't have to predefine the shape of features",
    "start": "984610",
    "end": "992620"
  },
  {
    "text": "that are interesting so typically a lot of techniques usually assume that the",
    "start": "992620",
    "end": "998050"
  },
  {
    "text": "shape is say a square or a rectangle or elliptical but in this case you can actually have arbitrary shapes by just",
    "start": "998050",
    "end": "1005580"
  },
  {
    "text": "defining an appropriate result to the data right so yes having such a",
    "start": "1005580",
    "end": "1012000"
  },
  {
    "text": "definition is really helpful but how do you efficiently compute this so to do that we use an index which is called as",
    "start": "1012000",
    "end": "1020880"
  },
  {
    "start": "1017000",
    "end": "1017000"
  },
  {
    "text": "the merge tree so to explain what this index is and how we can efficiently",
    "start": "1020880",
    "end": "1026188"
  },
  {
    "text": "compute these features let's again look at in this example of the terrain and let's start with a threshold that is",
    "start": "1026189",
    "end": "1032850"
  },
  {
    "text": "higher than the global maximum value right so in this case there are no",
    "start": "1032850",
    "end": "1038430"
  },
  {
    "text": "features the features are empty now if I decrease the threshold a little bit you",
    "start": "1038430",
    "end": "1044250"
  },
  {
    "text": "can see that there is just one component of the topological feature corresponding",
    "start": "1044250",
    "end": "1049860"
  },
  {
    "text": "to the global maximum if I decrease the threshold further you can see that at",
    "start": "1049860",
    "end": "1055140"
  },
  {
    "text": "some point the other peak also becomes a topological feature and now you have two components if I decrease it even more",
    "start": "1055140",
    "end": "1062720"
  },
  {
    "text": "what we have is three components and as we keep decreasing at some point these",
    "start": "1062720",
    "end": "1067950"
  },
  {
    "text": "different components much together and finally once it goes below the global minimum we have the entire data",
    "start": "1067950",
    "end": "1075870"
  },
  {
    "text": "as a single component of the topological feature right and as you notice as we",
    "start": "1075870",
    "end": "1082320"
  },
  {
    "text": "keep decreasing the stress hold you see we have a tree that has captured that captures basically the evolution of the",
    "start": "1082320",
    "end": "1088890"
  },
  {
    "text": "topological features and in particular the leaves of this tree correspond the",
    "start": "1088890",
    "end": "1093990"
  },
  {
    "text": "leaf nodes of the street corresponds to the set of maxima and the set of minima and the internal nodes are what other",
    "start": "1093990",
    "end": "1099720"
  },
  {
    "text": "types of critical points which are called saddle points right and so this",
    "start": "1099720",
    "end": "1105450"
  },
  {
    "text": "India this much tree kind of abstracts the shape or the topology of the input",
    "start": "1105450",
    "end": "1112320"
  },
  {
    "text": "data and it gives us a data dimension independent way of analyzing the data",
    "start": "1112320",
    "end": "1118590"
  },
  {
    "text": "right and one of the main advantage of using this much two years you can",
    "start": "1118590",
    "end": "1124860"
  },
  {
    "text": "actually compute the merge three efficiently even know of n log n time where n is the size of the scalar",
    "start": "1124860",
    "end": "1130770"
  },
  {
    "text": "function so even if your data is extremely large for example the taxi data that we use we have data",
    "start": "1130770",
    "end": "1137220"
  },
  {
    "text": "corresponding to 5 years which has over eight hundred and sixty eight billion trips right and even though it is so",
    "start": "1137220",
    "end": "1143880"
  },
  {
    "text": "large once you convert it into scalar functions over space and time based on the neighborhood it's going to become a much smaller size function and you can",
    "start": "1143880",
    "end": "1153000"
  },
  {
    "text": "just compute it efficiently in orphaned login time and so now that we have this",
    "start": "1153000",
    "end": "1159420"
  },
  {
    "text": "merge tree index how do you go about computing the features so to do that given a threshold all we need to do is",
    "start": "1159420",
    "end": "1166820"
  },
  {
    "text": "basically start from the critical points",
    "start": "1166820",
    "end": "1173100"
  },
  {
    "text": "that are above the threshold in the merge tree and we need to keep traversing down the merge tree so and we",
    "start": "1173100",
    "end": "1178679"
  },
  {
    "text": "just stopped when we hit this threshold so basically the plane that is the",
    "start": "1178679",
    "end": "1183960"
  },
  {
    "text": "threshold which is a plane in the actual data now becomes just a single line in the merge tree and you just Traverse",
    "start": "1183960",
    "end": "1189780"
  },
  {
    "text": "down it so basically what we are doing is we hit each point of the feature",
    "start": "1189780",
    "end": "1196200"
  },
  {
    "text": "exactly once and we don't touch any other feature right so in other words",
    "start": "1196200",
    "end": "1201450"
  },
  {
    "text": "what we have is the output sensitive eye to compute these features which basically says that no other algorithm",
    "start": "1201450",
    "end": "1208909"
  },
  {
    "text": "can perform better than what we are performing this is the best that you can do right so now we know how to",
    "start": "1208909",
    "end": "1217759"
  },
  {
    "text": "efficiently compute these features so so far what we have mentioned is we have",
    "start": "1217759",
    "end": "1223429"
  },
  {
    "text": "defined topological features based on a threshold and given a threshold we know how to compute these features but how do",
    "start": "1223429",
    "end": "1230330"
  },
  {
    "text": "you go about finding good thresholds that's a question right so for example when we used the taxi data earlier we",
    "start": "1230330",
    "end": "1237440"
  },
  {
    "text": "actually found the path how do you get that threshold in a nice way and of course users or domain experts who know",
    "start": "1237440",
    "end": "1243980"
  },
  {
    "text": "the data can manually give thresholds but given over thousand data sets each with eight attributes per data set which",
    "start": "1243980",
    "end": "1250759"
  },
  {
    "text": "essentially gives us something like 8,000 different functions in one resolution how you just cannot manually",
    "start": "1250759",
    "end": "1257690"
  },
  {
    "text": "provide thresholds for every data set right so in order to do that we compute",
    "start": "1257690",
    "end": "1262879"
  },
  {
    "text": "these thresholds in a pure data driven approach and to do that we use this notion called topological persistence so",
    "start": "1262879",
    "end": "1271129"
  },
  {
    "start": "1264000",
    "end": "1264000"
  },
  {
    "text": "what do I mean by topological persistence so if you recall when I kept changing the threshold",
    "start": "1271129",
    "end": "1276559"
  },
  {
    "text": "values at some points there were new components being created and at some points the components merged right and",
    "start": "1276559",
    "end": "1283279"
  },
  {
    "text": "so if you think of a component being created you can think of it as a component being born and meant two",
    "start": "1283279",
    "end": "1289490"
  },
  {
    "text": "components merge you can think of the smaller component as being destroyed right so for each component you have a",
    "start": "1289490",
    "end": "1296090"
  },
  {
    "text": "function value where it is created or where it is born and a function value when it actually dies or when it's",
    "start": "1296090",
    "end": "1302299"
  },
  {
    "text": "destroyed so you can define some sort of a life time for each of these",
    "start": "1302299",
    "end": "1307730"
  },
  {
    "text": "topological features and this lifetime is essentially what is called as topological persistence so intuitively",
    "start": "1307730",
    "end": "1318440"
  },
  {
    "text": "when you represent the data as a terrain the topological persistence corresponds",
    "start": "1318440",
    "end": "1323960"
  },
  {
    "text": "to the height of each of the peaks so a high persistent feature would basically",
    "start": "1323960",
    "end": "1330830"
  },
  {
    "text": "have will be really tall whereas a low position feature would be really short",
    "start": "1330830",
    "end": "1336250"
  },
  {
    "text": "right and the other advantages again you don't",
    "start": "1336250",
    "end": "1341450"
  },
  {
    "text": "have to look at the data again once we have the merge tree the topological persistence can be efficiently computed",
    "start": "1341450",
    "end": "1347330"
  },
  {
    "text": "using the merge tree itself so we have this abstract tree representation which",
    "start": "1347330",
    "end": "1352460"
  },
  {
    "text": "is much smaller than the original data you can just use it to compute these thresholds and then you can again use",
    "start": "1352460",
    "end": "1357889"
  },
  {
    "text": "this much tree index again using these thresholds to compute the required features so I still haven't finished how",
    "start": "1357889",
    "end": "1367879"
  },
  {
    "text": "to compute the thresholds based on persistence and so to do that we use",
    "start": "1367879",
    "end": "1373190"
  },
  {
    "text": "what we are interested in is the set of high persistent Peaks or high persistent",
    "start": "1373190",
    "end": "1379340"
  },
  {
    "text": "valleys right so to do that we use what is called as a persistence diagram and",
    "start": "1379340",
    "end": "1386289"
  },
  {
    "text": "this is essentially a scatter plot which plots the birth versus death of each of",
    "start": "1386289",
    "end": "1393830"
  },
  {
    "text": "the features so here again we are using the taxi data and this is the persistence diagram for the all the",
    "start": "1393830",
    "end": "1401299"
  },
  {
    "text": "features of the taxi data right and so here you have the x axis which is when",
    "start": "1401299",
    "end": "1406700"
  },
  {
    "text": "it was born and the y axis is when it is destroyed and so the persistence value",
    "start": "1406700",
    "end": "1412159"
  },
  {
    "text": "is essentially the height above the x equal to Y plane and if you notice",
    "start": "1412159",
    "end": "1417350"
  },
  {
    "text": "closely the set of hypotheses in features actually form a separate cluster over here they are separate from",
    "start": "1417350",
    "end": "1423980"
  },
  {
    "text": "the entire all the other features and this is not just for this data this is",
    "start": "1423980",
    "end": "1430279"
  },
  {
    "text": "common across several data sets and in fact the persistence diagram is commonly used as a visual aid for users to",
    "start": "1430279",
    "end": "1438019"
  },
  {
    "text": "identify good thresholds and interesting features of data and several applications including scientific",
    "start": "1438019",
    "end": "1444109"
  },
  {
    "text": "simulations and climate simulations and so on right so we basically use this insight to",
    "start": "1444109",
    "end": "1450139"
  },
  {
    "text": "automatically compute the threshold by identifying this high-density cluster of",
    "start": "1450139",
    "end": "1455919"
  },
  {
    "text": "from the persistence diagram",
    "start": "1455919",
    "end": "1459940"
  },
  {
    "text": "and another advantage is that you can theoretically prove that the position",
    "start": "1462410",
    "end": "1469580"
  },
  {
    "text": "diagram is robust to noise so basically you have say you have clean data and then you have the same data but with",
    "start": "1469580",
    "end": "1476480"
  },
  {
    "text": "addition of noise you can actually prove that the persistence diagram doesn't change beyond a particular distance",
    "start": "1476480",
    "end": "1482660"
  },
  {
    "text": "right so there is no change and it's really robust no noise so now we have",
    "start": "1482660",
    "end": "1489770"
  },
  {
    "text": "ways to compute different features of multiple scalar functions which is basically each attribute of all the data",
    "start": "1489770",
    "end": "1497060"
  },
  {
    "text": "sets right so how do we use this to evaluate the relationships how do we find these relationships so to do that",
    "start": "1497060",
    "end": "1504800"
  },
  {
    "start": "1503000",
    "end": "1503000"
  },
  {
    "text": "we first define relationships between individual features we first say when features are related so to explain that",
    "start": "1504800",
    "end": "1512720"
  },
  {
    "text": "let's again look at a favorite terrain so this is consider this as one scale a",
    "start": "1512720",
    "end": "1518780"
  },
  {
    "text": "function and then next let's look at a different terrain which has a single",
    "start": "1518780",
    "end": "1523790"
  },
  {
    "text": "peak and this is the second function right so if you look at the set of features over here you see that the",
    "start": "1523790",
    "end": "1529820"
  },
  {
    "text": "first function has two positive features in one negative feature while the second function has one positive feature but in",
    "start": "1529820",
    "end": "1536390"
  },
  {
    "text": "particular this positive feature is in the same spatial temporal location as",
    "start": "1536390",
    "end": "1542140"
  },
  {
    "text": "the the taller peak in the first function so in such a case we say that",
    "start": "1542140",
    "end": "1548090"
  },
  {
    "text": "these two features are related and in particular since a positive feature is",
    "start": "1548090",
    "end": "1553910"
  },
  {
    "text": "related to another positive feature we say there is a positive relationship now",
    "start": "1553910",
    "end": "1559760"
  },
  {
    "text": "let's consider a different pair of functions so even here the second function still has just a single feature",
    "start": "1559760",
    "end": "1566180"
  },
  {
    "text": "but it has a positive feature right by and here you see that a positive feature",
    "start": "1566180",
    "end": "1571250"
  },
  {
    "text": "is actually related to a negative feature so in this case we say there is a negative relationship between the",
    "start": "1571250",
    "end": "1578330"
  },
  {
    "text": "feature so we basically use this definition of relationship between",
    "start": "1578330",
    "end": "1583430"
  },
  {
    "text": "features to quantify relationship between two functions or two data sets so to do that we define two different",
    "start": "1583430",
    "end": "1591230"
  },
  {
    "text": "measures the first one is called the relationship score which captures the features are related right so in",
    "start": "1591230",
    "end": "1598970"
  },
  {
    "text": "this case whenever there is a negative feature in one function there is a positive feature and the other function",
    "start": "1598970",
    "end": "1604009"
  },
  {
    "text": "so we say that this function is negatively related and therefore the",
    "start": "1604009",
    "end": "1609859"
  },
  {
    "text": "relationship score would be negative in this sense below zero right but this is",
    "start": "1609859",
    "end": "1616009"
  },
  {
    "text": "just not enough because it doesn't say how frequently the different features are related so if you look at this exam",
    "start": "1616009",
    "end": "1623649"
  },
  {
    "text": "this example you see that only one of the features of the three in the first function is related to a feature in the",
    "start": "1623649",
    "end": "1630710"
  },
  {
    "text": "second function right so we need to quantify this to do that we need to say how often the functions are related and",
    "start": "1630710",
    "end": "1638929"
  },
  {
    "text": "we do this using a relationship strength measure and in this particular case we",
    "start": "1638929",
    "end": "1643999"
  },
  {
    "text": "say that there is a weak relationship between the two functions so if there was another function where in such that",
    "start": "1643999",
    "end": "1650690"
  },
  {
    "text": "it had say three features and all of them were related then you would say there is a strong relationship all right",
    "start": "1650690",
    "end": "1658009"
  },
  {
    "text": "and in addition to this we also perform a set of Montecarlo significant tests to",
    "start": "1658009",
    "end": "1664789"
  },
  {
    "text": "filter out potentially coincidental relationships and the you as will show",
    "start": "1664789",
    "end": "1670159"
  },
  {
    "text": "later the user can specify the p-value of interest to filter out relationships",
    "start": "1670159",
    "end": "1678729"
  },
  {
    "text": "so if you noticed one thing the way we have defined our topology based",
    "start": "1679029",
    "end": "1684529"
  },
  {
    "start": "1680000",
    "end": "1680000"
  },
  {
    "text": "relationships so whether we use data",
    "start": "1684529",
    "end": "1689690"
  },
  {
    "text": "that is like a one dimensional data or whether we use data that is three",
    "start": "1689690",
    "end": "1695149"
  },
  {
    "text": "dimensional in this case that is 2d space over time all we work is with the March tree and the same algorithm the",
    "start": "1695149",
    "end": "1703549"
  },
  {
    "text": "same code is going to work on data in any dimension because we just use a merge tree and then the persistence to",
    "start": "1703549",
    "end": "1709309"
  },
  {
    "text": "compute different thresholds and identify these features so essentially we have a data agnostic I mean sorry",
    "start": "1709309",
    "end": "1716419"
  },
  {
    "text": "dimension agnostic technique to compute these relationships",
    "start": "1716419",
    "end": "1721429"
  },
  {
    "text": "so to recap using computational topology to identify relationships they naturally",
    "start": "1721429",
    "end": "1728480"
  },
  {
    "start": "1722000",
    "end": "1722000"
  },
  {
    "text": "captures the feature of interest in the data which can have arbitrary shapes and they are really",
    "start": "1728480",
    "end": "1734180"
  },
  {
    "text": "efficient robust noise and it's independent of the dimension of the data so now that we have a solid mathematical",
    "start": "1734180",
    "end": "1741350"
  },
  {
    "text": "framework to do this let's see how we go about implementing it all right thanks",
    "start": "1741350",
    "end": "1748910"
  },
  {
    "text": "Harish all right so let's talk more",
    "start": "1748910",
    "end": "1754700"
  },
  {
    "text": "details about the implementation of the framework so all the scalar functions",
    "start": "1754700",
    "end": "1759920"
  },
  {
    "text": "that are generated from the data they are considered to be independent from each other and even the relationships when you have all your hypotheses of",
    "start": "1759920",
    "end": "1766400"
  },
  {
    "text": "their relationships generated all these relationships they are also considered assumed to be independent from each",
    "start": "1766400",
    "end": "1772430"
  },
  {
    "text": "other so what happens here is that all our steps should compute entered in five",
    "start": "1772430",
    "end": "1777710"
  },
  {
    "start": "1775000",
    "end": "1775000"
  },
  {
    "text": "features and even to evaluate relationships they are embarrassingly parallel so we can use MapReduce to",
    "start": "1777710",
    "end": "1784070"
  },
  {
    "text": "implement our framework and this also helps with efficiency because we all we have a large collections of datasets",
    "start": "1784070",
    "end": "1790490"
  },
  {
    "text": "with multiple attributes and so this also helps in making it very scalable so",
    "start": "1790490",
    "end": "1797150"
  },
  {
    "text": "this is what the framework looks like so we have three main steps and each of these steps is a MapReduce jobs",
    "start": "1797150",
    "end": "1803420"
  },
  {
    "text": "represented by a MapReduce job so the first step which is called data set",
    "start": "1803420",
    "end": "1808460"
  },
  {
    "text": "transformation takes all the data sets all the attributes and creates a consistent representation of the data so",
    "start": "1808460",
    "end": "1815270"
  },
  {
    "text": "as her estimation the consistent representation of the data in this case are the scalar functions in particular",
    "start": "1815270",
    "end": "1821750"
  },
  {
    "start": "1821000",
    "end": "1821000"
  },
  {
    "text": "for this implementation we use two different types of scalar function count and attribute so the count function",
    "start": "1821750",
    "end": "1829130"
  },
  {
    "text": "basically captures the activity of an entity of an entity corresponding to the data so for instance we could have a",
    "start": "1829130",
    "end": "1836000"
  },
  {
    "text": "density function the number of tax trips over space and time and we could also have a unique function number of unique",
    "start": "1836000",
    "end": "1843110"
  },
  {
    "text": "taxes based on tax license or taxi medallion over space of time we also",
    "start": "1843110",
    "end": "1848660"
  },
  {
    "text": "have the attribute functions and the attribute functions they basically capture the variation of an attribute so",
    "start": "1848660",
    "end": "1855020"
  },
  {
    "text": "in this example we have average tax fare over space and time and it's important",
    "start": "1855020",
    "end": "1860900"
  },
  {
    "text": "to note here that we compute this functions at all possible spatial temporal resolutions so suppose you have",
    "start": "1860900",
    "end": "1867740"
  },
  {
    "text": "some data where the spatial component is in GPS so the GPS can be then translated",
    "start": "1867740",
    "end": "1873110"
  },
  {
    "text": "to a high resolution grid or maybe the points can be mapped to different neighborhoods or it can consider the",
    "start": "1873110",
    "end": "1878690"
  },
  {
    "text": "entire city as a whole and if the temporal component is in second you can also translate it to our day week month",
    "start": "1878690",
    "end": "1885170"
  },
  {
    "text": "and so on so we compute all these possible combinations of spatial temporal resolutions because as we are",
    "start": "1885170",
    "end": "1891350"
  },
  {
    "text": "going to see through an example a relationship they may be visible in one resolution but it may not be visible in",
    "start": "1891350",
    "end": "1898010"
  },
  {
    "text": "another resolution and it's also important to note that of course in this framework we only have these",
    "start": "1898010",
    "end": "1904340"
  },
  {
    "text": "implementations of the scalar functions but it is quite straightforward to add other functions to the framework for",
    "start": "1904340",
    "end": "1911600"
  },
  {
    "text": "instance one function that we really plan to implement inside the framework is the gradient function so that you can",
    "start": "1911600",
    "end": "1917180"
  },
  {
    "text": "try to capture the increase or decrease of a certain characteristic in the",
    "start": "1917180",
    "end": "1922820"
  },
  {
    "text": "attribute and with respect to the MapReduce job in the map phase here what",
    "start": "1922820",
    "end": "1928880"
  },
  {
    "text": "happens that our data points their map should this different spatial temporal resolutions and then in the reduced",
    "start": "1928880",
    "end": "1933920"
  },
  {
    "text": "phase the data is aggregated using these scalar functions for each of these resolutions so the second step is",
    "start": "1933920",
    "end": "1942080"
  },
  {
    "text": "feature identification it's where all the features are computed and identified and here the map phase for each of the",
    "start": "1942080",
    "end": "1950030"
  },
  {
    "text": "data set scalar functions are taken individually what do I mean by that well if we talk about key value pairs in the",
    "start": "1950030",
    "end": "1958340"
  },
  {
    "text": "data set transformation the data set is considered as a whole so the value is basically s with all the attributes or",
    "start": "1958340",
    "end": "1964460"
  },
  {
    "text": "scalar functions corresponding to that data set and what happens in the map phase of the future identification is",
    "start": "1964460",
    "end": "1970190"
  },
  {
    "text": "that we split this into different key value pairs where each of these pairs corresponds to a different scalar",
    "start": "1970190",
    "end": "1976310"
  },
  {
    "text": "function or attribute because as I mentioned before they are they are considered to be independent from each",
    "start": "1976310",
    "end": "1981500"
  },
  {
    "text": "other and then in the reduce phase for each of these functions we the merge",
    "start": "1981500",
    "end": "1986780"
  },
  {
    "text": "three index is created and the features are identified for all the possible resolutions and here it comes the beauty",
    "start": "1986780",
    "end": "1994160"
  },
  {
    "text": "of the merge tree is that you can compute them three once and then you can have",
    "start": "1994160",
    "end": "1999289"
  },
  {
    "text": "different thresholds and you can also always use the same urge tree with different thresholds shouldn't fight",
    "start": "1999289",
    "end": "2005409"
  },
  {
    "text": "your features so as soon as we reconstruct the merge tree for the first time for a particular function we save",
    "start": "2005409",
    "end": "2012549"
  },
  {
    "text": "that and then whenever the user needs to go back to the future identification to use a different threshold perhaps",
    "start": "2012549",
    "end": "2018129"
  },
  {
    "text": "shouldn't 5 feature is the same merge tree can be used and this does not need to be computed again and then finally",
    "start": "2018129",
    "end": "2026769"
  },
  {
    "text": "the last step is the relationship evaluation which is where the relationship is identified and evaluated",
    "start": "2026769",
    "end": "2033129"
  },
  {
    "text": "so this is where the user is where the user can pose relationship queries so",
    "start": "2033129",
    "end": "2038529"
  },
  {
    "text": "again the relationship query is in the form of fine all better sites relational data sati these satisfied clause so what",
    "start": "2038529",
    "end": "2045279"
  },
  {
    "start": "2039000",
    "end": "2039000"
  },
  {
    "text": "happens that when the user run this query only the statistically significant relationships are returned which",
    "start": "2045279",
    "end": "2051940"
  },
  {
    "text": "significantly reduce the number of relationships that the user needs to analyze does better guiding the user in",
    "start": "2051940",
    "end": "2058720"
  },
  {
    "text": "the data exploration process and if you note in the query we have a clause where the users can use to actually filter the",
    "start": "2058720",
    "end": "2066579"
  },
  {
    "text": "relationships based on relationship score and strength because these are like quantitative metrics so they can",
    "start": "2066579",
    "end": "2072908"
  },
  {
    "text": "they can use they can use a specific threshold for this score in the strength",
    "start": "2072909",
    "end": "2077950"
  },
  {
    "text": "and you can also choose a different p-value for the significance test and in",
    "start": "2077950",
    "end": "2086079"
  },
  {
    "text": "terms of the MapReduce job in the map phase all the possible combinations of scalar functions are considered based on",
    "start": "2086079",
    "end": "2092710"
  },
  {
    "text": "the queries so basically all the possible relationships are generated based on the query and then on the",
    "start": "2092710",
    "end": "2098650"
  },
  {
    "text": "reduced phase each of this relationship is evaluated and it's also in the reduce phase where the statistical test is done",
    "start": "2098650",
    "end": "2104680"
  },
  {
    "text": "and some additional information we implement this using a posh MapReduce we",
    "start": "2104680",
    "end": "2111609"
  },
  {
    "start": "2107000",
    "end": "2107000"
  },
  {
    "text": "use HDFS as the distributed file system it proved very efficient for us to use compression in the map output because",
    "start": "2111609",
    "end": "2118569"
  },
  {
    "text": "the mappers they produced a lot of data because we have a lot of scalar functions to compute and so we used a",
    "start": "2118569",
    "end": "2123910"
  },
  {
    "text": "few different compressions and that proved to be very efficient and also the framework runs on",
    "start": "2123910",
    "end": "2129820"
  },
  {
    "text": "ws so then after we implemented this framework we of course we we run a few",
    "start": "2129820",
    "end": "2137830"
  },
  {
    "text": "experiments should test the framework for efficients and also for to see if",
    "start": "2137830",
    "end": "2144130"
  },
  {
    "text": "it's useful so the first the first set of experiments is related to performance evaluation so our goal here is really to",
    "start": "2144130",
    "end": "2150580"
  },
  {
    "text": "check for efficiency scalability and robustness so for that we use 300",
    "start": "2150580",
    "end": "2155710"
  },
  {
    "text": "spatial temporal datasets from when we see open data which is very reasonable because it has a large data complexity",
    "start": "2155710",
    "end": "2162910"
  },
  {
    "text": "because again as you may remember each of these data sets has an average of 8 attributes so it creates a large",
    "start": "2162910",
    "end": "2169650"
  },
  {
    "text": "possible number of relationships and the hardware that we use so we have our own",
    "start": "2169650",
    "end": "2176230"
  },
  {
    "text": "huddle cluster at when were you which we use for most of the experiments and this cluster has 20 compute nodes but we also",
    "start": "2176230",
    "end": "2184930"
  },
  {
    "text": "used Amazon EMR for the scalability tests and the reason is because with",
    "start": "2184930",
    "end": "2190690"
  },
  {
    "text": "Amazon EMR it is incredibly easy to create different clusters configurations",
    "start": "2190690",
    "end": "2196120"
  },
  {
    "text": "so that we can test for scalability so here are a few results from our",
    "start": "2196120",
    "end": "2202090"
  },
  {
    "start": "2200000",
    "end": "2200000"
  },
  {
    "text": "framework in terms of performance so the first one is that it takes around 200 minutes to compute all the scale of",
    "start": "2202090",
    "end": "2208420"
  },
  {
    "text": "functions and features and also to evaluate that the the relationships for NYC open data which is a very reasonable",
    "start": "2208420",
    "end": "2214750"
  },
  {
    "text": "time considering the large data complexity also using the significance test we can decrease in around 99% on",
    "start": "2214750",
    "end": "2222670"
  },
  {
    "text": "the number of output relationships so this is indeed better guides the user in finding or potentially meaningful",
    "start": "2222670",
    "end": "2229750"
  },
  {
    "text": "relationships and also the framework can evaluate more than take 10k",
    "start": "2229750",
    "end": "2235720"
  },
  {
    "text": "relationships per minute so this plot for instance x-axis you can see that a number of varying data sets and then on",
    "start": "2235720",
    "end": "2243010"
  },
  {
    "text": "the y-axis you have the rate and then you have 10k then goes up to 15k relationships also we incrementally",
    "start": "2243010",
    "end": "2252810"
  },
  {
    "text": "incrementally add the noise to the data and we could find we could also always",
    "start": "2252810",
    "end": "2258550"
  },
  {
    "text": "found find the same relationships so the approaches were both noise and thanks to topology because as Harish",
    "start": "2258550",
    "end": "2266079"
  },
  {
    "text": "mentioned the persistence values they are very robust and also the approach is",
    "start": "2266079",
    "end": "2272049"
  },
  {
    "text": "scalable so this is the experiment that we ran on Amazon EMR so we use different",
    "start": "2272049",
    "end": "2277270"
  },
  {
    "text": "types of cluster configurations with two nodes with four nodes with eight nodes and finally with sixteen nodes so the",
    "start": "2277270",
    "end": "2284770"
  },
  {
    "text": "first step which is the data set transformation where we compute all the scalar functions it has a very nice",
    "start": "2284770",
    "end": "2291069"
  },
  {
    "text": "speed up the the two last steps achieve the lower speed up and the reason here",
    "start": "2291069",
    "end": "2297579"
  },
  {
    "text": "is because we have a few straggler reducers that are working on high resolution data so high resolution data",
    "start": "2297579",
    "end": "2304240"
  },
  {
    "text": "meaning means means that we have much more data to process so they keep",
    "start": "2304240",
    "end": "2309940"
  },
  {
    "text": "processing the data while the other reduces are already done so finally so",
    "start": "2309940",
    "end": "2317049"
  },
  {
    "start": "2314000",
    "end": "2314000"
  },
  {
    "text": "we've seen that the approach is efficient that the the framework is scalable but now is it useful can we",
    "start": "2317049",
    "end": "2323200"
  },
  {
    "text": "actually find interesting on trivial relationships so this is the goal of our our second set of experiments which is",
    "start": "2323200",
    "end": "2330400"
  },
  {
    "text": "more of a qualitative evaluation and for that we manually selected nine data sets",
    "start": "2330400",
    "end": "2336609"
  },
  {
    "text": "from different NYC agencies which are data size that we are more familiar with so that we could try to better",
    "start": "2336609",
    "end": "2342880"
  },
  {
    "text": "understand some of these relationships so let's take a look at some of these",
    "start": "2342880",
    "end": "2348640"
  },
  {
    "start": "2347000",
    "end": "2347000"
  },
  {
    "text": "interesting relationships so let's go back to our first question which is with the reduction in traffic speed reduce",
    "start": "2348640",
    "end": "2355390"
  },
  {
    "text": "the number of accidents which can be translated to the query find our relationships between collisions and",
    "start": "2355390",
    "end": "2361210"
  },
  {
    "text": "traffic datasets so for this query we found a relationship a positive",
    "start": "2361210",
    "end": "2366670"
  },
  {
    "text": "relationship which in a number of collisions and speed which indeed indicates that the speed is about the",
    "start": "2366670",
    "end": "2373599"
  },
  {
    "text": "speed limit in the cities relatively is positively related to the number of collisions in the city but we also found",
    "start": "2373599",
    "end": "2381520"
  },
  {
    "text": "another relationship which is a positive relation between the number of persons killed on those accidents and the speed",
    "start": "2381520",
    "end": "2388299"
  },
  {
    "text": "which indicates that reducing the speed limit in the city may also help in reducing number of fatalities in the",
    "start": "2388299",
    "end": "2394420"
  },
  {
    "text": "city in car accidents and as a matter of fact the city of New York in 2014",
    "start": "2394420",
    "end": "2401360"
  },
  {
    "text": "decreased the speed limit of 25 miles per hour to reduce the number of traffic deaths which is consistent with our data",
    "start": "2401360",
    "end": "2408890"
  },
  {
    "text": "which goes into 2013 so for the second question why is it so hard to find a",
    "start": "2408890",
    "end": "2415160"
  },
  {
    "text": "taxi when it's raining which translates to the query find all relationships between taxi and weather data sets so",
    "start": "2415160",
    "end": "2422240"
  },
  {
    "text": "the first relationship that we find is a negative relationship between the number of taxes and average precipitation which",
    "start": "2422240",
    "end": "2429560"
  },
  {
    "text": "does indicate that it isn't it hard to find a taxi when it's raining so it's not an urban legend but this still",
    "start": "2429560",
    "end": "2437180"
  },
  {
    "text": "doesn't explain why is that so so there is a long-standing policies in the city",
    "start": "2437180",
    "end": "2443720"
  },
  {
    "text": "that taxi drivers are target owners so basically they have their daily Lincoln goal and when they reach that goal they",
    "start": "2443720",
    "end": "2450320"
  },
  {
    "text": "simply go home and they stop working and of course in rainy days the demand is higher so it's it's harder to find a",
    "start": "2450320",
    "end": "2456920"
  },
  {
    "text": "taxi because they are all gone and and the question here is given this",
    "start": "2456920",
    "end": "2462050"
  },
  {
    "text": "hypothesis can we actually find a relationship that indicates that this hypothesis is true as a matter of fact",
    "start": "2462050",
    "end": "2468890"
  },
  {
    "text": "yes so we found a strong positive relationship between precipitation and average fare which does indicate that",
    "start": "2468890",
    "end": "2475190"
  },
  {
    "text": "this hypothesis is true and what's interesting about this is that this hypothesis was recently refuted in a",
    "start": "2475190",
    "end": "2482630"
  },
  {
    "text": "recent study and the reason is twofold so first in this study the the authors",
    "start": "2482630",
    "end": "2491320"
  },
  {
    "text": "the authors say instead of using the amount of rainfall the amount of precipitation they only use binary",
    "start": "2491320",
    "end": "2497660"
  },
  {
    "text": "values educating whether it rained or not and second and most importantly they",
    "start": "2497660",
    "end": "2503690"
  },
  {
    "text": "use the entire data into account so basically periods of time with sparse",
    "start": "2503690",
    "end": "2509480"
  },
  {
    "text": "rainfall were considered to be equivalent through periods of time with heavy rainfall so this indicates that we",
    "start": "2509480",
    "end": "2516320"
  },
  {
    "text": "need to look at those interesting relationships because some of these relationships they only become visible",
    "start": "2516320",
    "end": "2521480"
  },
  {
    "text": "when you're looking at those interesting features and not when you're looking at the entire data so for the third",
    "start": "2521480",
    "end": "2529070"
  },
  {
    "text": "question why the number of taxi trip is chalo which it translates you find all datasets related",
    "start": "2529070",
    "end": "2534900"
  },
  {
    "text": "to the text data set so we've seen a ride one of the the relationships that",
    "start": "2534900",
    "end": "2540180"
  },
  {
    "text": "explains this which is the negative relationship between number of Texas and wind speed which is related to the",
    "start": "2540180",
    "end": "2546090"
  },
  {
    "text": "Hurricanes that hit the city but you still have other points where the number",
    "start": "2546090",
    "end": "2551100"
  },
  {
    "text": "of tax trips is too low and this can be explained with another relationship which is a negative relationship between",
    "start": "2551100",
    "end": "2557100"
  },
  {
    "text": "number of taxi of taxis and average precipitation when there's too much rain also it's hard to find a taxi so you can",
    "start": "2557100",
    "end": "2564570"
  },
  {
    "text": "see that for a single question so you have a single question can be answered by more than one relationship and they",
    "start": "2564570",
    "end": "2570390"
  },
  {
    "text": "actually complement the answer for this for this question and by dinging it by digging into this",
    "start": "2570390",
    "end": "2575940"
  },
  {
    "text": "relationship looking analyzing it further you can see exactly where are the points where these relationships are",
    "start": "2575940",
    "end": "2582210"
  },
  {
    "text": "visible and finally this is a very",
    "start": "2582210",
    "end": "2587280"
  },
  {
    "text": "interesting relationship that we also found which is between the city bike data and weather data set so city bike",
    "start": "2587280",
    "end": "2593040"
  },
  {
    "text": "is the public bike system in New York City for those who don't know and we",
    "start": "2593040",
    "end": "2598050"
  },
  {
    "text": "found this negative relationship between snow precipitation and active City bike stations so meaning that the higher",
    "start": "2598050",
    "end": "2605580"
  },
  {
    "text": "there is no precipitation some of the stations from city bike they are less",
    "start": "2605580",
    "end": "2610590"
  },
  {
    "text": "frequently used in others so we believe that this is related to two things one",
    "start": "2610590",
    "end": "2615780"
  },
  {
    "text": "obviously when it is knowing people use bikes less frequently and second some of",
    "start": "2615780",
    "end": "2622620"
  },
  {
    "text": "the stations they are they are cleared more frequently than others because they",
    "start": "2622620",
    "end": "2627840"
  },
  {
    "text": "are simply in more popular places or even more expensive places right and what's interesting about this",
    "start": "2627840",
    "end": "2633990"
  },
  {
    "text": "relationship as well is that we could found it in the day's City resolution but we could not find it in the our city",
    "start": "2633990",
    "end": "2640590"
  },
  {
    "text": "resolution and the reason is this relationship is only visible when you have is no accumulation after you you",
    "start": "2640590",
    "end": "2647100"
  },
  {
    "text": "see there's no accumulation then you see this relationship and if you are working on an hourly time resolution you cannot",
    "start": "2647100",
    "end": "2653970"
  },
  {
    "text": "see this you cannot see there's no accumulation but when you go to the day a daily resolution then you can see this",
    "start": "2653970",
    "end": "2659910"
  },
  {
    "text": "accumulation happening so this this shows that it is really Fortin that you look at relationships at",
    "start": "2659910",
    "end": "2665910"
  },
  {
    "text": "this different spatial temporal resolutions and of course we found many other relationships so for this",
    "start": "2665910",
    "end": "2673010"
  },
  {
    "text": "collection of data set that we have we found approximately 100 significant relationships per resolution we manually",
    "start": "2673010",
    "end": "2681630"
  },
  {
    "text": "I looked at some of these relationships and we found over 35 that were",
    "start": "2681630",
    "end": "2687000"
  },
  {
    "text": "interesting but of course we do need domain experts to look at this other the",
    "start": "2687000",
    "end": "2692010"
  },
  {
    "text": "other relationships should so that we can try to better understand their implications and the reasons behind",
    "start": "2692010",
    "end": "2697650"
  },
  {
    "text": "those relationships and in our analysis we also found that the weather data set",
    "start": "2697650",
    "end": "2702960"
  },
  {
    "text": "is the most polygamous data set meaning that its attributes they relate to of",
    "start": "2702960",
    "end": "2708300"
  },
  {
    "text": "almost every other attribute in the other data sets so to conclude we just",
    "start": "2708300",
    "end": "2714960"
  },
  {
    "start": "2713000",
    "end": "2713000"
  },
  {
    "text": "we represented we have presented data polygamy with the goal of discovery in exploring relationships and large",
    "start": "2714960",
    "end": "2720599"
  },
  {
    "text": "collections of data set so we use the the concept of topology based relationships because it's a it",
    "start": "2720599",
    "end": "2727710"
  },
  {
    "text": "considered relationships between salient features of the data and also because it takes both time and space into account",
    "start": "2727710",
    "end": "2734180"
  },
  {
    "text": "the framework was implemented using MapReduce which proved should be very efficient and scalable and we also could",
    "start": "2734180",
    "end": "2740550"
  },
  {
    "text": "found some interesting and even non-trivial relationships in our framework but querying for relationships",
    "start": "2740550",
    "end": "2747330"
  },
  {
    "text": "is just the beginning and these are some of the lessons that we learned while working in this project so the first one",
    "start": "2747330",
    "end": "2754020"
  },
  {
    "start": "2751000",
    "end": "2751000"
  },
  {
    "text": "is really it's it's it's really hard to evaluate this framework because we don't",
    "start": "2754020",
    "end": "2760050"
  },
  {
    "text": "have ground truth data so we do need real use cases from domain experts or",
    "start": "2760050",
    "end": "2765750"
  },
  {
    "text": "perhaps a benchmark that can generate some data with relationships so that we can evaluate better our our framework",
    "start": "2765750",
    "end": "2772560"
  },
  {
    "text": "and the second one is that even though we have the significance test shoe that",
    "start": "2772560",
    "end": "2779220"
  },
  {
    "text": "significantly reduce the number of output relationships depending on the on the size of your collection of data sets",
    "start": "2779220",
    "end": "2786240"
  },
  {
    "text": "you can still have too many relationships to look at so here we need better tools and techniques that help",
    "start": "2786240",
    "end": "2792599"
  },
  {
    "text": "the user better guide that user in exploring and analyzing those relationships",
    "start": "2792599",
    "end": "2797700"
  },
  {
    "text": "and so that's it in our github page you can find some cold data and experiments",
    "start": "2797700",
    "end": "2803730"
  },
  {
    "text": "and we also have a paper published this year it's sigmod and you can have more details about the approach in the paper",
    "start": "2803730",
    "end": "2809579"
  },
  {
    "text": "as well and thank you [Applause]",
    "start": "2809579",
    "end": "2819250"
  }
]
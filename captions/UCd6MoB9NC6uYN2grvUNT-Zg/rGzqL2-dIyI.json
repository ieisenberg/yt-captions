[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "good afternoon everybody thanks for coming I hope you guys had good reinvent",
    "start": "0",
    "end": "7350"
  },
  {
    "text": "so far the pitch is high okay we will be",
    "start": "7350",
    "end": "16049"
  },
  {
    "text": "talking about our experience with how we",
    "start": "16049",
    "end": "21560"
  },
  {
    "text": "migrated our reporting analytics platform from Oracle two RDS today",
    "start": "21560",
    "end": "28429"
  },
  {
    "text": "primarily we will concentrate on my sequel and I will have one slide or so for Aurora so let's begin I'll give a",
    "start": "28429",
    "end": "38340"
  },
  {
    "start": "37000",
    "end": "37000"
  },
  {
    "text": "brief introduction of what Gallup is I'm assuming people know about gallop we are",
    "start": "38340",
    "end": "46469"
  },
  {
    "text": "a polling firm we do lot of data collection that's what we are known for",
    "start": "46469",
    "end": "52039"
  },
  {
    "text": "but primarily our business is more on management consulting like brand management loyalty employee engagement",
    "start": "52039",
    "end": "58980"
  },
  {
    "text": "those kinds of things so we collect data and analyze and give recommendations",
    "start": "58980",
    "end": "64198"
  },
  {
    "text": "that kind of thing why AWS what are the",
    "start": "64199",
    "end": "69840"
  },
  {
    "text": "various non database cultural issues that you face we will go in detail about",
    "start": "69840",
    "end": "77189"
  },
  {
    "text": "that and obviously the mice equal benefits challenges and a very brief",
    "start": "77189",
    "end": "83909"
  },
  {
    "text": "rundown on our solution architecture everybody able to hear me okay okay",
    "start": "83909",
    "end": "91590"
  },
  {
    "text": "there's an echo coming so yes we will",
    "start": "91590",
    "end": "97150"
  },
  {
    "text": "talk about various processes and dev up changes that we need to do when you're migrating to the cloud we will talk",
    "start": "97150",
    "end": "104500"
  },
  {
    "text": "about that and briefly go our RDS Aurora implementations and we'll have some",
    "start": "104500",
    "end": "112210"
  },
  {
    "text": "conclusion points by no means this is a comparative study of Oracle versus my",
    "start": "112210",
    "end": "118000"
  },
  {
    "text": "sequel this is just our experience on what we went through as I was alluding",
    "start": "118000",
    "end": "127570"
  },
  {
    "text": "to before gallop we have been in this business of data collection survey polling for last 70 80 years actually so",
    "start": "127570",
    "end": "134320"
  },
  {
    "text": "we have data right from 1940s late 1930s we started collecting data so we are",
    "start": "134320",
    "end": "141430"
  },
  {
    "text": "pulling all kinds of stuff from Social Sciences area especially you know for",
    "start": "141430",
    "end": "150190"
  },
  {
    "text": "gallop so why we went with AWS what was",
    "start": "150190",
    "end": "156040"
  },
  {
    "start": "152000",
    "end": "152000"
  },
  {
    "text": "the problem statement that we are facing so as usual it's the same thing for every time you build a system you want a",
    "start": "156040",
    "end": "162820"
  },
  {
    "text": "scalable and very rich richly analytical",
    "start": "162820",
    "end": "168670"
  },
  {
    "text": "capability platform obviously cost effective so nothing no big big changes",
    "start": "168670",
    "end": "177519"
  },
  {
    "text": "there in terms of general expectations we wanted also a rich analytical capabilities and more and more we seem",
    "start": "177519",
    "end": "185829"
  },
  {
    "text": "to get a lot of clients who are asking for encryption for all of their data so",
    "start": "185829",
    "end": "192820"
  },
  {
    "text": "it's not surprising for you folks but 10 years ago it was not that case obviously",
    "start": "192820",
    "end": "198850"
  },
  {
    "text": "24 x seven high availability replication we also seem to be running into lot of",
    "start": "198850",
    "end": "206049"
  },
  {
    "text": "issues with Patriot Act which is if the",
    "start": "206049",
    "end": "211060"
  },
  {
    "text": "data crosses US borders the US government has access to it so lot of our multinational clients especially",
    "start": "211060",
    "end": "217299"
  },
  {
    "text": "from Europe they don't want the data to be housed in US so that's also a big concern for us",
    "start": "217299",
    "end": "223909"
  },
  {
    "text": "because if you want to do data collection reporting analysis we cannot",
    "start": "223909",
    "end": "229099"
  },
  {
    "text": "bring the data to us so multi-region data segregation also what we have seen",
    "start": "229099",
    "end": "235250"
  },
  {
    "text": "is more clients want no data commingling which means you can't store the clients",
    "start": "235250",
    "end": "242989"
  },
  {
    "text": "data like klein day and client be in the same database because they are paranoid",
    "start": "242989",
    "end": "248959"
  },
  {
    "text": "for all the various reasons especially the government agencies so within the",
    "start": "248959",
    "end": "254329"
  },
  {
    "text": "same region you want to segregate the data and also you want to distribute the data across globally for compliance",
    "start": "254329",
    "end": "261169"
  },
  {
    "text": "reasons also ease of administration currently we have lots of dbas working",
    "start": "261169",
    "end": "270080"
  },
  {
    "text": "through our Oracle infrastructure along with other databases that we have like",
    "start": "270080",
    "end": "275120"
  },
  {
    "text": "my Microsoft sequel server",
    "start": "275120",
    "end": "280240"
  },
  {
    "start": "282000",
    "end": "282000"
  },
  {
    "text": "why AWS so basically it's been very cost effective from our analysis traditional",
    "start": "283080",
    "end": "290400"
  },
  {
    "text": "existing models are locked down to physical hardware so basically for example if you take any vendor out there",
    "start": "290400",
    "end": "295909"
  },
  {
    "text": "we have a CPU base licensing model so that's a big cost for us and also we",
    "start": "295909",
    "end": "305969"
  },
  {
    "text": "need to do lot of hardware investments for getting all this physical hardware obviously you also have the DBA / system",
    "start": "305969",
    "end": "314400"
  },
  {
    "text": "administration overhead in AWS lot of these things probably go away to an",
    "start": "314400",
    "end": "321629"
  },
  {
    "text": "extent also as I alluded before the Patriot Act cross-border data transfer",
    "start": "321629",
    "end": "327710"
  },
  {
    "text": "all these things perfectly align with what AWS offers actually so you can",
    "start": "327710",
    "end": "334469"
  },
  {
    "text": "replicate your entire infrastructure for example if we have an infrastructure in Virginia you can replicate the whole",
    "start": "334469",
    "end": "341159"
  },
  {
    "text": "infrastructure in Frankfurt Germany so that is the model that we are connecting",
    "start": "341159",
    "end": "348888"
  },
  {
    "text": "also high availability replication so we can replicate data faster with",
    "start": "350029",
    "end": "358909"
  },
  {
    "text": "cost-effectiveness primarily also we it's a traditional problem in our",
    "start": "358909",
    "end": "364589"
  },
  {
    "text": "industry you have peaks of load so for example if in bank signs up with gallop",
    "start": "364589",
    "end": "372690"
  },
  {
    "text": "they have 100,000 user base so suddenly overnight we have a hundred thousand user base expansion of our offering",
    "start": "372690",
    "end": "380389"
  },
  {
    "text": "there is no way you can plan for this because it's a sale that bent so AWS",
    "start": "380389",
    "end": "389729"
  },
  {
    "text": "actually offers us to scale the resources as we need one of the other",
    "start": "389729",
    "end": "396240"
  },
  {
    "text": "things is we tend to have a lot of activity obviously everybody has this problem we tend to have there are peak",
    "start": "396240",
    "end": "401819"
  },
  {
    "text": "hours and off-peak hours peak hours we generally have a lot of transactional",
    "start": "401819",
    "end": "407009"
  },
  {
    "text": "stuff going on and off peak hours we have lot of ad hoc jobs processing those kinds of things going on",
    "start": "407009",
    "end": "413319"
  },
  {
    "text": "we always had a need for more hardware",
    "start": "413319",
    "end": "418840"
  },
  {
    "text": "for these off-peak our jobs and in the traditional model if you invest in",
    "start": "418840",
    "end": "425870"
  },
  {
    "text": "hardware and software you won't get the bang for the buck and that's one of the",
    "start": "425870",
    "end": "430910"
  },
  {
    "text": "reasons one of the limitations that we have seen for a decade now in aw is actually we can bump up our hardware as",
    "start": "430910",
    "end": "438380"
  },
  {
    "text": "we need we also have non-continuous loads demands there are real time as",
    "start": "438380",
    "end": "445130"
  },
  {
    "text": "well as batch requirements for data analysis we also have a double is also",
    "start": "445130",
    "end": "452330"
  },
  {
    "text": "offers not only a relational engine but it also offers us a very big data type",
    "start": "452330",
    "end": "457699"
  },
  {
    "text": "platform which is absolutely essential for us we experimented with housing big",
    "start": "457699",
    "end": "463819"
  },
  {
    "text": "data POC within our own premises but there is lot of overhead and lot of",
    "start": "463819",
    "end": "470060"
  },
  {
    "text": "learning curve to do all those things not only on development but also on the administration side so in the uws world",
    "start": "470060",
    "end": "477050"
  },
  {
    "text": "you have all these inbuilt components which are highly scalable and very",
    "start": "477050",
    "end": "482539"
  },
  {
    "text": "attractive to us because recently they just released not just released they",
    "start": "482539",
    "end": "487669"
  },
  {
    "text": "released sometime back a kinases which is a complex event processing system and",
    "start": "487669",
    "end": "493759"
  },
  {
    "text": "we have an inbuilt in house built system that sort of operates like that but the",
    "start": "493759",
    "end": "500030"
  },
  {
    "text": "scale is something that we were planning to go in detail but now we don't need to",
    "start": "500030",
    "end": "505130"
  },
  {
    "text": "do because Amazon keeps on introducing new and newer and newer components so fast that we are unable to catch up so",
    "start": "505130",
    "end": "512120"
  },
  {
    "text": "we just build a fire hose type thing on kinases and today's keynote they said they have it so it's so fast the amount",
    "start": "512120",
    "end": "522289"
  },
  {
    "text": "of development that they do an amount of things that they release we are it's hard to catch up and anything we invest",
    "start": "522289",
    "end": "528589"
  },
  {
    "text": "generally they always have a new service coming out which fixes that thing okay",
    "start": "528589",
    "end": "535930"
  },
  {
    "start": "535000",
    "end": "535000"
  },
  {
    "text": "a couple of non database considerations process this is the biggest challenge we",
    "start": "536300",
    "end": "541760"
  },
  {
    "text": "have we have a stable processes build which has been optimized over a decade",
    "start": "541760",
    "end": "547670"
  },
  {
    "text": "we have a huge legacy overhead on our design because requirements 10 15 years",
    "start": "547670",
    "end": "553459"
  },
  {
    "text": "ago 10 years ago 15 years ago is not the same now so again it's a cultural change",
    "start": "553459",
    "end": "559610"
  },
  {
    "text": "in lot of ways whereas in cloud you seem to have new processes that not many",
    "start": "559610",
    "end": "567260"
  },
  {
    "text": "people get it it's just a learning curve for a lot of folks it's not just",
    "start": "567260",
    "end": "573850"
  },
  {
    "text": "administrative side but also on the development side new tool sets data is",
    "start": "573850",
    "end": "579769"
  },
  {
    "text": "not within premises so this is a very important point a lot of clients previously always ask are you housing",
    "start": "579769",
    "end": "589160"
  },
  {
    "text": "the data or is it in the cloud if it is in the cloud we don't want anything to do with you guys but in the last couple",
    "start": "589160",
    "end": "595220"
  },
  {
    "text": "of years things are changing where they are open to asking okay what cloud platform do you use and what kind of",
    "start": "595220",
    "end": "602060"
  },
  {
    "text": "security encryptions and how do you have data stored is it a trust encrypted in",
    "start": "602060",
    "end": "610910"
  },
  {
    "text": "transit what is the status those kinds of things so people are more the",
    "start": "610910",
    "end": "616279"
  },
  {
    "text": "cultural change is sleeping in is what I'm saying obviously data segregation",
    "start": "616279",
    "end": "622390"
  },
  {
    "text": "also data migration is one huge thing so do you want to send the data or public",
    "start": "624730",
    "end": "631750"
  },
  {
    "text": "HTTPS encrypted or we want to use a VPC and use a tunnel VPN to extend your own",
    "start": "631750",
    "end": "641060"
  },
  {
    "text": "network to Amazon in that way it's just same as when you run migration",
    "start": "641060",
    "end": "646640"
  },
  {
    "text": "internally so there are a lot of options it depends on your data sets obviously",
    "start": "646640",
    "end": "653420"
  },
  {
    "text": "the VPN band with this big deal so if you have a lot of data that you need to",
    "start": "653420",
    "end": "658430"
  },
  {
    "text": "transfer public is cheaper if you want to go through VPN you need to have",
    "start": "658430",
    "end": "663620"
  },
  {
    "text": "bandwidth between your company's network and Amazon so a couple of things that",
    "start": "663620",
    "end": "670820"
  },
  {
    "text": "you want to consider also the data migration do you want to make it secure so we want to encrypt when the data is",
    "start": "670820",
    "end": "677690"
  },
  {
    "text": "pushed out both the databases as well as the ETL jobs that move the data okay",
    "start": "677690",
    "end": "692380"
  },
  {
    "start": "690000",
    "end": "690000"
  },
  {
    "text": "other non database considerations technical this has been the biggest challenge for us we are I'm assuming",
    "start": "692380",
    "end": "701029"
  },
  {
    "text": "everybody who's here has Oracle implementation so obviously you have a",
    "start": "701029",
    "end": "707449"
  },
  {
    "text": "data warehouse which has a standard dimensional model you have star schemas",
    "start": "707449",
    "end": "712850"
  },
  {
    "text": "you have ETL you have staging areas so all these things require lot of resources that are very well versed with",
    "start": "712850",
    "end": "720500"
  },
  {
    "text": "database development so you have people who are very proficient in PL sequel",
    "start": "720500",
    "end": "725540"
  },
  {
    "text": "procedures you have people who are very proficient in data modeling so our team",
    "start": "725540",
    "end": "732949"
  },
  {
    "text": "composition we are around 50 people in our group majority of them seem to be on",
    "start": "732949",
    "end": "739040"
  },
  {
    "text": "the database developer stack because that's our legacy that's how we have developed over the years we have a huge",
    "start": "739040",
    "end": "745910"
  },
  {
    "text": "strength on the UI UI side and we have a medium type strength on the service later so it's a big challenge because on",
    "start": "745910",
    "end": "754160"
  },
  {
    "text": "a double your side everything is on the services side so the middle the service layer pretty much dominates the whole",
    "start": "754160",
    "end": "760339"
  },
  {
    "text": "space so that's one big challenge it's hard to find people with a double your",
    "start": "760339",
    "end": "765920"
  },
  {
    "text": "skill sets obviously but one good news",
    "start": "765920",
    "end": "770990"
  },
  {
    "text": "is Oracle skills are portable meaning if you have written stored procedures and if you plan to write store procedures in",
    "start": "770990",
    "end": "776720"
  },
  {
    "text": "my sequel majority of time the skills are portable but there are lot of gotchas here and there where you need to",
    "start": "776720",
    "end": "783140"
  },
  {
    "text": "do tweaks in your code you are used to some set of programming idioms you're",
    "start": "783140",
    "end": "788720"
  },
  {
    "text": "used to some capabilities that Oracle has spoiled you for years and you don't have those",
    "start": "788720",
    "end": "794270"
  },
  {
    "text": "kinds of things available in my sequel so lot of deficiencies in a lot of",
    "start": "794270",
    "end": "799420"
  },
  {
    "text": "peculiarities in my sequel RDS Mexico so this is no means a artifact specific to",
    "start": "799420",
    "end": "807260"
  },
  {
    "text": "our dias it's more of my sequel capabilities this is these are obviously",
    "start": "807260",
    "end": "812930"
  },
  {
    "text": "you have data synchronization issues that you have to always go through in a",
    "start": "812930",
    "end": "818210"
  },
  {
    "text": "standard data warehousing model you always the data gets collected it gets mode you need to do bookkeeping so data",
    "start": "818210",
    "end": "825080"
  },
  {
    "text": "synchronization now the bigger challenges do you want to do synchronization on-premise and then send",
    "start": "825080",
    "end": "831170"
  },
  {
    "text": "the payload or do you want to sync between those two it all depends on how much data and what's the throughput that",
    "start": "831170",
    "end": "836270"
  },
  {
    "text": "you want again there are a lot of tools out there do you want to build versus x",
    "start": "836270",
    "end": "842060"
  },
  {
    "text": "so these are some of the considerations that you need to keep in mind from the",
    "start": "842060",
    "end": "848840"
  },
  {
    "text": "technical side the data migration we are decide we implemented on rbs is our",
    "start": "848840",
    "end": "855950"
  },
  {
    "text": "reporting repository with amazon s3 being our a unified global data store so",
    "start": "855950",
    "end": "865220"
  },
  {
    "text": "the ETL i will go into detail on this one etl just pumps files 2 s 3 and s 3",
    "start": "865220",
    "end": "870500"
  },
  {
    "text": "from s3 you pick up all the data into RDS we have lot of ad hoc custom data",
    "start": "870500",
    "end": "878660"
  },
  {
    "text": "analytical deliverables so we have lot of researchers data researchers who like",
    "start": "878660",
    "end": "885980"
  },
  {
    "text": "to have files they don't seem to be proficient in lot of SQL that kind of",
    "start": "885980",
    "end": "892700"
  },
  {
    "text": "thing so they want files been meaning they want data so that they can run their own stat analysis so s3 seems to",
    "start": "892700",
    "end": "899090"
  },
  {
    "text": "be perfect fit for us or that one also when you create these things you can",
    "start": "899090",
    "end": "906230"
  },
  {
    "text": "have cross domain data analysis what I mean by that is if you have a data set",
    "start": "906230",
    "end": "912740"
  },
  {
    "text": "one which talks about customer and data set to which talks about completely different time in a standard relational",
    "start": "912740",
    "end": "920510"
  },
  {
    "text": "modeling that you do these are two different warehouses because they are completely not related for reporting and our reporting purposes",
    "start": "920510",
    "end": "927680"
  },
  {
    "text": "but it seems the researchers want to try all combinations to find patterns so",
    "start": "927680",
    "end": "933410"
  },
  {
    "text": "they want to get these two data sets to do analysis so s3 seems to be perfect",
    "start": "933410",
    "end": "939260"
  },
  {
    "text": "for that because in one file system one global file system we can give all types of files a couple of interesting things",
    "start": "939260",
    "end": "948620"
  },
  {
    "text": "we use heavily SQS the queuing so in oracle you have something called",
    "start": "948620",
    "end": "953930"
  },
  {
    "text": "advanced queues a queue so we are heavily dependent on it in this world",
    "start": "953930",
    "end": "959810"
  },
  {
    "text": "it's equivalent would be amazon SQS but",
    "start": "959810",
    "end": "964880"
  },
  {
    "text": "it is not a conventional q so first-in first-out doesn't happen so again it",
    "start": "964880",
    "end": "973060"
  },
  {
    "text": "says q but there are some peculiarities with it so if you have a transaction",
    "start": "973060",
    "end": "978590"
  },
  {
    "text": "that needs to be ordered SQS you need to do lot more to get those things ironed",
    "start": "978590",
    "end": "984470"
  },
  {
    "text": "out STS by design is not a conventional q AK other thing is Amazon s3 it's a",
    "start": "984470",
    "end": "992060"
  },
  {
    "text": "global file system where you can put data and access in a distributed way but as soon as you write it is not",
    "start": "992060",
    "end": "999170"
  },
  {
    "text": "guaranteed that you can read so it is eventually it is consistent that's s3",
    "start": "999170",
    "end": "1004450"
  },
  {
    "text": "which means if you have process that reads file after it has been written and if there is a chain even chain of events",
    "start": "1004450",
    "end": "1011730"
  },
  {
    "text": "you need to account for this eventual consistency of retries or something in your code obviously there are a lot of",
    "start": "1011730",
    "end": "1021250"
  },
  {
    "text": "variable late latin seas and performances of various services",
    "start": "1021250",
    "end": "1026520"
  },
  {
    "text": "everything doesn't work as advertised that's my personal experience so every",
    "start": "1027390",
    "end": "1034089"
  },
  {
    "text": "component has its own peculiarities so until you delve into the details it's",
    "start": "1034090",
    "end": "1040150"
  },
  {
    "text": "hard to quantify and there are no general guidelines on this it's up to your use case and also on what",
    "start": "1040150",
    "end": "1046480"
  },
  {
    "text": "components you are using my sequel",
    "start": "1046480",
    "end": "1052330"
  },
  {
    "start": "1050000",
    "end": "1050000"
  },
  {
    "text": "benefits it's a good or Oracle alternative but it is not as rich as Oracle by no means it's a cost effective and",
    "start": "1052330",
    "end": "1060029"
  },
  {
    "text": "the administration we are managing all of our databases with pretty much one or two DBS it's obviously scalable you can",
    "start": "1060029",
    "end": "1070230"
  },
  {
    "text": "resize your instances if you have the money you can resize it for a couple of",
    "start": "1070230",
    "end": "1075419"
  },
  {
    "text": "days and then bring down the size there are also read instances available read",
    "start": "1075419",
    "end": "1082110"
  },
  {
    "text": "replicas this is a major difference between my sequel and Aurora you",
    "start": "1082110",
    "end": "1090210"
  },
  {
    "text": "replicate your tables / database for a read replica in my sequel whereas it's",
    "start": "1090210",
    "end": "1097019"
  },
  {
    "text": "not replicated in aurora so there are a lot of lag issues when I say about lag",
    "start": "1097019",
    "end": "1103889"
  },
  {
    "text": "what it means is if you write something to my sequel the read instance won't",
    "start": "1103889",
    "end": "1111450"
  },
  {
    "text": "pick up that change because there is lag because of your application and all those things so if you have a query that",
    "start": "1111450",
    "end": "1117000"
  },
  {
    "text": "goes and writes to the master and then reads from the read instance you have",
    "start": "1117000",
    "end": "1122909"
  },
  {
    "text": "issues in case you don't account for it so that's one interesting thing but read",
    "start": "1122909",
    "end": "1128820"
  },
  {
    "text": "instances are really helpful especially since or reporting system is more of a",
    "start": "1128820",
    "end": "1135059"
  },
  {
    "text": "traditional warehousing system which means majority of the dates all reads during nights we have lot of Rights",
    "start": "1135059",
    "end": "1141690"
  },
  {
    "text": "which means majority of reads is the nature of our system which means read replicas are really really helpful but",
    "start": "1141690",
    "end": "1149639"
  },
  {
    "text": "again it's up to you on how you segregate your queries to the read instances versus the master failure",
    "start": "1149639",
    "end": "1156600"
  },
  {
    "text": "orders and all those things you need to confer ad hoc needs so when the",
    "start": "1156600",
    "end": "1163320"
  },
  {
    "text": "researchers come and say we need this data set I'm open to learning SQL so how",
    "start": "1163320",
    "end": "1169320"
  },
  {
    "text": "do I get access in today's world we don't give them access to our Oracle production instances because they can",
    "start": "1169320",
    "end": "1175559"
  },
  {
    "text": "write a query and that can completely really harm your production in what",
    "start": "1175559",
    "end": "1180929"
  },
  {
    "text": "roads so these reader pickers are a good way of creating an instance for them for a day or two or a week",
    "start": "1180929",
    "end": "1187770"
  },
  {
    "text": "let them do whatever they want and it doesn't affect any of our production instances so that's a so these are some",
    "start": "1187770",
    "end": "1193470"
  },
  {
    "text": "of their dog needs that we are very happy with the reader replica architecture obviously multi multi AZ",
    "start": "1193470",
    "end": "1200550"
  },
  {
    "text": "regions key encryption using key management service all these things are",
    "start": "1200550",
    "end": "1207450"
  },
  {
    "text": "pretty effective on RDS security and",
    "start": "1207450",
    "end": "1212820"
  },
  {
    "text": "encryption as I stated before the KMS we use a kml we use cameras key management",
    "start": "1212820",
    "end": "1218580"
  },
  {
    "text": "service to create a global key for all of our data infrastructure and that key",
    "start": "1218580",
    "end": "1224460"
  },
  {
    "text": "amazon rotate we can rotate it every year without disturbing any of our processes and amazon pretty much takes",
    "start": "1224460",
    "end": "1232320"
  },
  {
    "text": "care of decryption when you create and encrypting when you store it that kind",
    "start": "1232320",
    "end": "1238560"
  },
  {
    "text": "of architecture so encrypting your data is pretty seamless is what i'm saying all you need to do is when you create",
    "start": "1238560",
    "end": "1245730"
  },
  {
    "text": "your RDS instances you need to specify which came as key for you to and get",
    "start": "1245730",
    "end": "1251510"
  },
  {
    "start": "1254000",
    "end": "1254000"
  },
  {
    "text": "obviously as i stated oracle head has is my far more productive and feature-rich",
    "start": "1254740",
    "end": "1261559"
  },
  {
    "text": "it has a ques it can write files it can send a request to HTTP server it can email you can do all kinds of things in",
    "start": "1261559",
    "end": "1268759"
  },
  {
    "text": "Oracle so when your database delivers move from Oracle to my sequel it's a big",
    "start": "1268759",
    "end": "1277909"
  },
  {
    "text": "challenge because the things that you're used to so seamlessly you can do a lot of things are not possible in my sickle",
    "start": "1277909",
    "end": "1287889"
  },
  {
    "text": "there are no integrations with any of AWS components I was just talking today",
    "start": "1287889",
    "end": "1294259"
  },
  {
    "text": "to the product manager group on Aurora that we can't write a file from a stored",
    "start": "1294259",
    "end": "1300500"
  },
  {
    "text": "procedure to s3 or read a file from s3 in a stored procedure so in oracle world",
    "start": "1300500",
    "end": "1307909"
  },
  {
    "text": "you have this job executions job scheduling on all these concepts which means at 2am one of my job wakes up",
    "start": "1307909",
    "end": "1315250"
  },
  {
    "text": "starts processing data and notifies through a queue that the data is ready these kinds of things are pretty normal",
    "start": "1315250",
    "end": "1321350"
  },
  {
    "text": "in this world the job wakes up fine you",
    "start": "1321350",
    "end": "1327200"
  },
  {
    "text": "can schedule and it is done aggregation that's fine but then it doesn't know how",
    "start": "1327200",
    "end": "1332629"
  },
  {
    "text": "to notify because it can't because it can't send the event to ask us neither",
    "start": "1332629",
    "end": "1338720"
  },
  {
    "text": "it can take its payload and write to s3 which is which probably people can read",
    "start": "1338720",
    "end": "1344049"
  },
  {
    "text": "all these capabilities don't exist within the database outside of the database absolutely you can do all these",
    "start": "1344049",
    "end": "1350480"
  },
  {
    "text": "things but coming from database development group majority of them who our database developers we can't train",
    "start": "1350480",
    "end": "1357590"
  },
  {
    "text": "them or write to lunch hour",
    "start": "1357590",
    "end": "1361600"
  },
  {
    "text": "if it is orchid Oracle you don't lose anything you will take if you have licenses you can migrate so the question",
    "start": "1373760",
    "end": "1380220"
  },
  {
    "text": "is if we if we move Oracle from",
    "start": "1380220",
    "end": "1385950"
  },
  {
    "text": "on-premises two RDS Oracle in Amazon will be how these capabilities are not",
    "start": "1385950",
    "end": "1391080"
  },
  {
    "text": "you have AQ and you have to have your application server use a queue libraries",
    "start": "1391080",
    "end": "1397170"
  },
  {
    "text": "to do whatever it needs to developer",
    "start": "1397170",
    "end": "1402480"
  },
  {
    "text": "productivity this is one of the biggest hard ones that I get from my development",
    "start": "1402480",
    "end": "1407940"
  },
  {
    "text": "team there is no no concept of packages in my sequel so you need to keep writing",
    "start": "1407940",
    "end": "1415110"
  },
  {
    "text": "individual store procedures so that gets messy but the good news is performance",
    "start": "1415110",
    "end": "1422429"
  },
  {
    "text": "ways you don't take a hit at all but the bad news is when you log in you'll see tons and tons of stored procedures if",
    "start": "1422429",
    "end": "1430350"
  },
  {
    "text": "you if you are a very heavy into store procedures it looks like it's all over",
    "start": "1430350",
    "end": "1435750"
  },
  {
    "text": "scattered there are no package level attributes global scoping is not not",
    "start": "1435750",
    "end": "1442549"
  },
  {
    "text": "doesn't exist in my sequel everything is locked to a session meaning if you open",
    "start": "1442549",
    "end": "1449820"
  },
  {
    "text": "a connection any data that you store in a temporary table or anything you cannot",
    "start": "1449820",
    "end": "1454860"
  },
  {
    "text": "share with other sessions in order how you can do lot of these things with global concepts there is none whatsoever",
    "start": "1454860",
    "end": "1462169"
  },
  {
    "text": "in Oracle obviously you have lot of data structures better data structure support",
    "start": "1462169",
    "end": "1468140"
  },
  {
    "text": "so again you have to do all these basic plumping yourself temporary tables",
    "start": "1468140",
    "end": "1476660"
  },
  {
    "text": "temporary tables pretty much is the solution for everything in my sequel so",
    "start": "1476660",
    "end": "1482580"
  },
  {
    "text": "we have to use lot of my temporary tables to do lot of basic things that we",
    "start": "1482580",
    "end": "1489540"
  },
  {
    "text": "do we are so used to in oracle i will go those into detail these are specifics",
    "start": "1489540",
    "end": "1496640"
  },
  {
    "text": "you cannot have cursor parameters in your procedures",
    "start": "1496640",
    "end": "1502179"
  },
  {
    "text": "there is no dynamic sequel concept like there is no execute immediate punch a",
    "start": "1502179",
    "end": "1507519"
  },
  {
    "text": "string there is that does not exist debugging and logging what other than",
    "start": "1507519",
    "end": "1514899"
  },
  {
    "text": "whatever the standard table Tabler",
    "start": "1514899",
    "end": "1520149"
  },
  {
    "text": "tables that you get from my sequel it's tough especially if you want to debug on",
    "start": "1520149",
    "end": "1525730"
  },
  {
    "text": "a read instance where do you write so these are interesting challenges that come up in this architecture you cannot",
    "start": "1525730",
    "end": "1533200"
  },
  {
    "text": "declare cursors with dynamic sequels global temporary I tables don't exist",
    "start": "1533200",
    "end": "1539369"
  },
  {
    "text": "support for sub queries in from clauses are not there again we can't send a",
    "start": "1539369",
    "end": "1547690"
  },
  {
    "start": "1545000",
    "end": "1545000"
  },
  {
    "text": "notification whether it is HTTP end point where we notify our application server that data is ready please",
    "start": "1547690",
    "end": "1554590"
  },
  {
    "text": "invalidate your cash those kinds of linkages you can't do email notification",
    "start": "1554590",
    "end": "1560019"
  },
  {
    "text": "capability doesn't exist as I stated before two-way integration with Amazon s3 does not exist since we have",
    "start": "1560019",
    "end": "1567990"
  },
  {
    "text": "globalized everything on our s3 this is a big problem for us as i stated SQS",
    "start": "1567990",
    "end": "1574629"
  },
  {
    "text": "there is no IQ capabilities so this is a very high level picture of our solution",
    "start": "1574629",
    "end": "1581139"
  },
  {
    "text": "architecture I'll get to that so we use",
    "start": "1581139",
    "end": "1587639"
  },
  {
    "text": "RDS my sequel as you guys as I might have already told you we didn't go with",
    "start": "1587639",
    "end": "1593499"
  },
  {
    "text": "Aurora for primarily because Aurora doesn't support encryption so that is",
    "start": "1593499",
    "end": "1599159"
  },
  {
    "text": "supposed to be released very soon data at at rest encryption currently is not",
    "start": "1599159",
    "end": "1604960"
  },
  {
    "text": "supported in Aurora whereas in my sequel it does exist we use stored procedures",
    "start": "1604960",
    "end": "1611499"
  },
  {
    "text": "extensively that's say that's something that we had to do because of our",
    "start": "1611499",
    "end": "1617350"
  },
  {
    "text": "technical teams we wrote an application",
    "start": "1617350",
    "end": "1624039"
  },
  {
    "text": "called RDS plus plus no pun intended there this actually helps us integrate stored procedures with SQL SNS SE",
    "start": "1624039",
    "end": "1633070"
  },
  {
    "text": "ss3 so this is a general framework that we have built in-house where database",
    "start": "1633070",
    "end": "1638690"
  },
  {
    "text": "stored procedures can start integrating with s3 read rights from s3 send an",
    "start": "1638690",
    "end": "1643730"
  },
  {
    "text": "email send notifications it can send NQ a DQ a message all those things we have",
    "start": "1643730",
    "end": "1648830"
  },
  {
    "text": "built but you have to invest in your application layer a little bit on that one it's an xml / json based definitions",
    "start": "1648830",
    "end": "1657080"
  },
  {
    "text": "kind of language so you stored procedure define something and then the Java layer picks it up and does what is written in",
    "start": "1657080",
    "end": "1663830"
  },
  {
    "text": "that language we have Tomcat we go with",
    "start": "1663830",
    "end": "1669410"
  },
  {
    "text": "tomcat java instances for our application server on reporting we do the standard ec2 load balancing auto",
    "start": "1669410",
    "end": "1676280"
  },
  {
    "text": "scaling and we lock down our QA and cue infrastructure into the QA v pc and pod",
    "start": "1676280",
    "end": "1683540"
  },
  {
    "text": "infrastructure in prod v pcs we also have a separate Java dedicated Tomcats",
    "start": "1683540",
    "end": "1691100"
  },
  {
    "text": "our dedicated instances for our data infrastructure which run all of our ETL so there's tomcat jaw instances for the",
    "start": "1691100",
    "end": "1699770"
  },
  {
    "text": "regular reporting and there is etl instances and that is something that actually does run the RDS plus plus that",
    "start": "1699770",
    "end": "1706430"
  },
  {
    "text": "I was talking about we use elastic cash for our context management and all of",
    "start": "1706430",
    "end": "1713960"
  },
  {
    "text": "our data collection comes through SQ s 2 s 3 and etl picks up the test three also",
    "start": "1713960",
    "end": "1719180"
  },
  {
    "text": "from s3 for etl when you want to you",
    "start": "1719180",
    "end": "1727190"
  },
  {
    "text": "have a tomcat java instance on the cloud but on-premises also you need somebody to send the data so there is a tomcat",
    "start": "1727190",
    "end": "1735380"
  },
  {
    "text": "java instance for on-premises for us also so there are two one is on-premise and one is on the cloud for our ETA and",
    "start": "1735380",
    "end": "1742100"
  },
  {
    "text": "then there is a reporting infrastructure on the cloud it generally service all client requests we use lot of java and c",
    "start": "1742100",
    "end": "1751250"
  },
  {
    "text": "li to transfer data I'm a big big fan and proponent of CLI actually it",
    "start": "1751250",
    "end": "1757820"
  },
  {
    "text": "completely is so transparent and so easy to do if you are very well versed in bats crippling this is a",
    "start": "1757820",
    "end": "1764750"
  },
  {
    "text": "good alternative for you to write a lot of complex processes so Oracle writes",
    "start": "1764750",
    "end": "1769940"
  },
  {
    "text": "all the data to a file system and our data ETL system on-premises pics those",
    "start": "1769940",
    "end": "1775340"
  },
  {
    "text": "files massages it and sends it over the wire using CLI / java to s3 and then our",
    "start": "1775340",
    "end": "1783500"
  },
  {
    "text": "data servers pick up those files and load it up to RDS so the data that we",
    "start": "1783500",
    "end": "1788720"
  },
  {
    "text": "transfer might be configuration information it can be the regular data itself it can be lots of things but",
    "start": "1788720",
    "end": "1796430"
  },
  {
    "text": "generally that is the mechanism that we use ok that's the gallop network we have",
    "start": "1796430",
    "end": "1804140"
  },
  {
    "text": "oracle databases that right to the shared directories which are picked up",
    "start": "1804140",
    "end": "1809990"
  },
  {
    "text": "by the Tomcat java instance 4qn prod environments and you have the amazon v",
    "start": "1809990",
    "end": "1815810"
  },
  {
    "text": "pcs we have one for QA and one for prod and there is a VPN connection for us to",
    "start": "1815810",
    "end": "1821360"
  },
  {
    "text": "tunnel through to amazon we have s3",
    "start": "1821360",
    "end": "1826520"
  },
  {
    "text": "where the data is written our data Tomcat instance servers pick up those data so they read and write from to s3",
    "start": "1826520",
    "end": "1834530"
  },
  {
    "text": "and they dumped it into RDS my sequel and they pick up some stuff from RDS my sequel and using RDS plus plus they",
    "start": "1834530",
    "end": "1842030"
  },
  {
    "text": "write it to s3 our external reporting we have lbs which are sitting on another",
    "start": "1842030",
    "end": "1848060"
  },
  {
    "text": "Tomcat instances and we use lot of our content delivery using cloud front the",
    "start": "1848060",
    "end": "1857030"
  },
  {
    "text": "regular pieces of the puzzle for scalability elastic cash for distributed",
    "start": "1857030",
    "end": "1862250"
  },
  {
    "text": "context management we have reused kinases for a lot of logging so all of",
    "start": "1862250",
    "end": "1868010"
  },
  {
    "text": "our layers send events on what they are doing into kinases and from ken assists",
    "start": "1868010",
    "end": "1873620"
  },
  {
    "text": "we load it into s3 so after today's keynote whatever we have developed for",
    "start": "1873620",
    "end": "1878930"
  },
  {
    "text": "that now comes prepackaged with something called Amazon cases fire hose so all of our work we probably need to",
    "start": "1878930",
    "end": "1886670"
  },
  {
    "text": "revert in case we want to use that and as I stated all these components can",
    "start": "1886670",
    "end": "1896830"
  },
  {
    "text": "read or write to s3 and they are also linked to or concat instances on our external and using RDS plus plus all the",
    "start": "1896830",
    "end": "1904570"
  },
  {
    "text": "components can talk to each other so this is how we orchestrated so this this",
    "start": "1904570",
    "end": "1912030"
  },
  {
    "text": "maximizes on our strengths which is lot of debates developers it it covers lot",
    "start": "1912030",
    "end": "1922570"
  },
  {
    "text": "of gaps in current capabilities that we have on Amazon echo system especially related databases and it fits our needs",
    "start": "1922570",
    "end": "1929350"
  },
  {
    "text": "for now it's not like we have solved the whole problem so we have external",
    "start": "1929350",
    "end": "1936190"
  },
  {
    "text": "reporting in data integration is directly going through web services to SQS we pull lot of content from other",
    "start": "1936190",
    "end": "1943660"
  },
  {
    "text": "systems for decorative elements like hey by the way I need internationalisation piece of text from for this code name so",
    "start": "1943660",
    "end": "1951550"
  },
  {
    "text": "we go to externally and pick up from our content management system so all these assemblies happens obviously developer",
    "start": "1951550",
    "end": "1958570"
  },
  {
    "text": "VMs we have Jenkins for our build sorry",
    "start": "1958570",
    "end": "1964920"
  },
  {
    "text": "developer when you build your VMs or if",
    "start": "1964920",
    "end": "1970120"
  },
  {
    "text": "you have your own desktop machines you need to have VPN if you have VPN then",
    "start": "1970120",
    "end": "1975430"
  },
  {
    "text": "what happens is Dora purrs don't notice that they are actually going to the cloud to do the development it's",
    "start": "1975430",
    "end": "1982120"
  },
  {
    "text": "seamless so we use VPN to make sure the developers don't need to have ec2",
    "start": "1982120",
    "end": "1987820"
  },
  {
    "text": "instances actually they can have their own desktops that they're used to and they can do a lot of bills from there",
    "start": "1987820",
    "end": "1994180"
  },
  {
    "text": "our Jenkins system is also on our network for historical reasons so we're",
    "start": "1994180",
    "end": "2001800"
  },
  {
    "text": "using VPN be push code okay a couple of",
    "start": "2001800",
    "end": "2007710"
  },
  {
    "start": "2004000",
    "end": "2004000"
  },
  {
    "text": "my sequel things that we have faced and how we solve it but this is by no means",
    "start": "2007710",
    "end": "2014430"
  },
  {
    "text": "the only way to do these things but this is something that we have done package scope variables we use lot of session",
    "start": "2014430",
    "end": "2020700"
  },
  {
    "text": "variables which gets shared by all stored procedures it's a bad thing and but",
    "start": "2020700",
    "end": "2029050"
  },
  {
    "text": "that's the only way we can work through so if somebody creates a variable in one procedure and they call another",
    "start": "2029050",
    "end": "2034480"
  },
  {
    "text": "procedure that variable can be accessed by the other procedure so there is no local concept so we have to work through",
    "start": "2034480",
    "end": "2043090"
  },
  {
    "text": "those things how we solve the cursor with dynamic sequel using temporary",
    "start": "2043090",
    "end": "2048610"
  },
  {
    "text": "tables so this is just a brief sample",
    "start": "2048610",
    "end": "2056350"
  },
  {
    "text": "code so how do you write dynamics equal so you create a temporary table then you",
    "start": "2056350",
    "end": "2062110"
  },
  {
    "text": "use a you create your own sequel statement and then execute it so we",
    "start": "2062110",
    "end": "2069280"
  },
  {
    "text": "built the temporary table we built the statement and then we prepare it and looked and we got a cursor very similar",
    "start": "2069280",
    "end": "2077429"
  },
  {
    "text": "execute immediate capabilities that you have in Oracle how do you do it again you use session variables use temporary",
    "start": "2077430",
    "end": "2084909"
  },
  {
    "text": "tables and do the same so lot of temporary tables we use which means you",
    "start": "2084910",
    "end": "2091240"
  },
  {
    "text": "need to have a good sizing on your databases especially the buffer cache so",
    "start": "2091240",
    "end": "2099460"
  },
  {
    "text": "we are doing a very phase transition so our first phase is what we have moved to",
    "start": "2099460",
    "end": "2104650"
  },
  {
    "text": "AWS which is just doing reporting the second phase we will do lot of data",
    "start": "2104650",
    "end": "2110980"
  },
  {
    "text": "collection also on the cloud for our initial release we had 400 plus stored",
    "start": "2110980",
    "end": "2116590"
  },
  {
    "text": "procedures and 200 plus stables we have to build another five or five to 10 more",
    "start": "2116590",
    "end": "2122770"
  },
  {
    "text": "products so just imagine how many stored procedures will right we do support only",
    "start": "2122770",
    "end": "2132040"
  },
  {
    "text": "our aggregate data from Oracle we don't know all of our respondent data because that's a big project by itself we just",
    "start": "2132040",
    "end": "2140140"
  },
  {
    "text": "move the aggregate data so that we can report on the cloud and that seemed more easier way to get lot of our development",
    "start": "2140140",
    "end": "2146850"
  },
  {
    "text": "teams understand learn about AWS get familiarize with the areas aw as before",
    "start": "2146850",
    "end": "2153610"
  },
  {
    "text": "we go into the next phase which is lot of heavy lifting that we had to do we have to support",
    "start": "2153610",
    "end": "2161560"
  },
  {
    "text": "configuration systems because client a wants this way the data to be a client be ones this way and all these",
    "start": "2161560",
    "end": "2167780"
  },
  {
    "text": "configuration information we already collect on Oracle we need to ship this to the cloud so that the reporting",
    "start": "2167780",
    "end": "2173780"
  },
  {
    "text": "system on the cloud can also take a look at it as i stated RDS + + is what we",
    "start": "2173780",
    "end": "2181520"
  },
  {
    "text": "built which gives us integrations between the database stored procedures versus all the AWS components one",
    "start": "2181520",
    "end": "2190010"
  },
  {
    "text": "interesting tidbit in our definition what we have said is if you get this SQS event you can you can say call this",
    "start": "2190010",
    "end": "2199460"
  },
  {
    "text": "stored procedure after you get this SQL statement which means we can actually make seamless job execution so we say I",
    "start": "2199460",
    "end": "2207920"
  },
  {
    "text": "am interested in this queue called survey and when you get the payload call",
    "start": "2207920",
    "end": "2214820"
  },
  {
    "text": "insert survey stored procedure with the payload so in our definition language we say I'm interested in this queue called",
    "start": "2214820",
    "end": "2221990"
  },
  {
    "text": "survey and post stored procedure integration meaning after the payload",
    "start": "2221990",
    "end": "2227270"
  },
  {
    "text": "you get call the store procedure in that way everything is well integrated",
    "start": "2227270",
    "end": "2232690"
  },
  {
    "start": "2232000",
    "end": "2232000"
  },
  {
    "text": "process and DevOps we use github a lot",
    "start": "2232690",
    "end": "2240790"
  },
  {
    "text": "Jenkins for Java development deployment sorry DB code deployment is interesting",
    "start": "2240850",
    "end": "2249190"
  },
  {
    "text": "one of one of the things is when you compile stored procedures in Oracle you",
    "start": "2249190",
    "end": "2256010"
  },
  {
    "text": "get you can get a brief downtime for your production systems that use those",
    "start": "2256010",
    "end": "2262580"
  },
  {
    "text": "stored procedures the reason being the compilation is global in scope in Oracle whereas in my see qualities at a session",
    "start": "2262580",
    "end": "2269540"
  },
  {
    "text": "level so you don't seem to get those exceptions which means you can deploy",
    "start": "2269540",
    "end": "2277510"
  },
  {
    "text": "more often currently we do lot of manual",
    "start": "2277510",
    "end": "2283700"
  },
  {
    "text": "deployment just like forever we have done normal where you send the scripts to the DBA we are going with the conservative",
    "start": "2283700",
    "end": "2290210"
  },
  {
    "text": "route for now for our auto scaling we use chef with the recipes on easy too we",
    "start": "2290210",
    "end": "2298970"
  },
  {
    "text": "have a clone of production for our stress environment so a brief",
    "start": "2298970",
    "end": "2306710"
  },
  {
    "text": "description of stress testing so when you want to do stress testing on our",
    "start": "2306710",
    "end": "2312020"
  },
  {
    "text": "on-premise environment you have to have lot of investment that you ought to make the data has to be replicated production",
    "start": "2312020",
    "end": "2317630"
  },
  {
    "text": "or close data has to be replicated or you need to create your own data set you need to have all the application servers",
    "start": "2317630",
    "end": "2323150"
  },
  {
    "text": "all the integrations and all the teams that are owning those applications need",
    "start": "2323150",
    "end": "2328160"
  },
  {
    "text": "to be involved if you want to do enterprise level stress testing whereas in Amazon you can use the same scripts",
    "start": "2328160",
    "end": "2336380"
  },
  {
    "text": "that copy your infrastructure and move to Frankfurt Germany to copy your infrastructure and create a stress",
    "start": "2336380",
    "end": "2342349"
  },
  {
    "text": "environment and your jmeter scripts can actually the stress testing scripts can",
    "start": "2342349",
    "end": "2348109"
  },
  {
    "text": "have the script of formation of all the stress environment run this test and then completely remove all the",
    "start": "2348109",
    "end": "2356450"
  },
  {
    "text": "components that it has created so that kind of flexibility will have and as",
    "start": "2356450",
    "end": "2361760"
  },
  {
    "text": "part of your creation of your scripts you can specify various instance sizing and all those things so we are halfway",
    "start": "2361760",
    "end": "2368720"
  },
  {
    "text": "there in those things but as part of our multi region deployment next year we",
    "start": "2368720",
    "end": "2375080"
  },
  {
    "text": "will have this those things fully automated we see a huge advantage there we it took us a long time to do that on",
    "start": "2375080",
    "end": "2382250"
  },
  {
    "text": "premises for stress here within two weeks we were able to deploy an identical production system and half of",
    "start": "2382250",
    "end": "2389450"
  },
  {
    "text": "the time it was not Amazon Amazon's inefficiencies or anything it's more of us learning about how to do this",
    "start": "2389450",
    "end": "2397990"
  },
  {
    "text": "for our Oliver code we move all of our code deployment to s3 so our war files",
    "start": "2401210",
    "end": "2408020"
  },
  {
    "text": "or SQL scripts all those things get loaded from Jenkins using s3 plugin to",
    "start": "2408020",
    "end": "2415040"
  },
  {
    "text": "s3 and then Jenkins calls a script on these machines which sync up through s3",
    "start": "2415040",
    "end": "2421940"
  },
  {
    "text": "and then deploy it why we need to do that it's pretty simple so Jenkins using",
    "start": "2421940",
    "end": "2429890"
  },
  {
    "text": "SSH and aw skis using s3 plugin will write it to Amazon s3 or QA machines",
    "start": "2429890",
    "end": "2437120"
  },
  {
    "text": "using the CLI pick up that code and deployed why we need to put it in s3 for",
    "start": "2437120",
    "end": "2445730"
  },
  {
    "text": "us if you want auto scaling you need you need to tell your deploy or whether it's",
    "start": "2445730",
    "end": "2452930"
  },
  {
    "text": "chef for any any any other alternatives where to pick up the latest code so s3",
    "start": "2452930",
    "end": "2461450"
  },
  {
    "text": "seems to be one universal answer for a lot of things so we have chef that can",
    "start": "2461450",
    "end": "2466940"
  },
  {
    "text": "read from s3 create a new server and put it in the load balancer so that you can expand when your CPU you are having a",
    "start": "2466940",
    "end": "2474770"
  },
  {
    "text": "heavy traffic you can do all these things we've been working with Aurora",
    "start": "2474770",
    "end": "2483290"
  },
  {
    "text": "from the Pearl for some time now we ran",
    "start": "2483290",
    "end": "2489500"
  },
  {
    "text": "into lot of stored procedure issues with it with it but all of them seem to be fixed before the general ways we like",
    "start": "2489500",
    "end": "2497540"
  },
  {
    "text": "that we can have more read instances because that is what we probably are that's one of the biggest attractions we",
    "start": "2497540",
    "end": "2503690"
  },
  {
    "text": "have because lot of our Eric needs research needs read-only workloads that we have comparatively to my sequel",
    "start": "2503690",
    "end": "2512960"
  },
  {
    "text": "versus Aurora you have a difference of minutes two minutes versus milliseconds",
    "start": "2512960",
    "end": "2518330"
  },
  {
    "text": "so there is lot less lag obviously the",
    "start": "2518330",
    "end": "2523640"
  },
  {
    "text": "application and high availability our big key factors our hope is using Aurora",
    "start": "2523640",
    "end": "2529610"
  },
  {
    "text": "we will have more integration points with AWS in future packet support basic",
    "start": "2529610",
    "end": "2537140"
  },
  {
    "text": "tracing abilities on the database tracing is tough on my psycho in case if",
    "start": "2537140",
    "end": "2546200"
  },
  {
    "text": "you guys are used to teeka profs there is nothing comparable so if you want to debug a store procedure it's it's gonna",
    "start": "2546200",
    "end": "2554540"
  },
  {
    "text": "take a while you can know sequels there are there are some logs which tell you",
    "start": "2554540",
    "end": "2561500"
  },
  {
    "text": "what queries are running slow but what are the various events that happen the query to run slow you have to work on it",
    "start": "2561500",
    "end": "2570260"
  },
  {
    "text": "a lot there are no easy way out there we",
    "start": "2570260",
    "end": "2575870"
  },
  {
    "text": "are waiting for our encryption for our production rollout on Aurora conclusion",
    "start": "2575870",
    "end": "2582970"
  },
  {
    "start": "2581000",
    "end": "2581000"
  },
  {
    "text": "Arabella seems to be a very right fit for us whether it is about scalability cost-effectiveness challenging business",
    "start": "2582970",
    "end": "2590780"
  },
  {
    "text": "needs people don't want data to come to us we want to replicate it in Frankfurt",
    "start": "2590780",
    "end": "2596450"
  },
  {
    "text": "we want to have data segregation within us itself because some client is paranoid that their data is co-mingling",
    "start": "2596450",
    "end": "2603230"
  },
  {
    "text": "with other people other clients data so all these things aw seems to answer all those questions pretty seamlessly and it",
    "start": "2603230",
    "end": "2611360"
  },
  {
    "text": "is pretty good cost-effective alternative to Oracle but we are hoping that there will be led better",
    "start": "2611360",
    "end": "2617420"
  },
  {
    "text": "integration with other AWS components within our aura so the database developers can hopefully easily",
    "start": "2617420",
    "end": "2624500"
  },
  {
    "text": "transition not easily but at least we can make them transition better from very highly rich environments to RDS",
    "start": "2624500",
    "end": "2634720"
  }
]
[
  {
    "start": "0",
    "end": "66000"
  },
  {
    "text": "hello and welcome to the webinar today's webinar is to entitled prepare your machine learning data four times faster",
    "start": "4540",
    "end": "10969"
  },
  {
    "text": "now before we get started I want to do just a little bit of housekeeping here when you join the webinar today you",
    "start": "10969",
    "end": "16100"
  },
  {
    "text": "selected to join either by phone call or by computer audio and we want to let you know that you have the option to change",
    "start": "16100",
    "end": "21380"
  },
  {
    "text": "that well should you have any technical difficulties during the broadcast I simply go to the control panel there and",
    "start": "21380",
    "end": "27050"
  },
  {
    "text": "change and choose a different method of audio now also from that control panel you have the opportunity to submit",
    "start": "27050",
    "end": "32960"
  },
  {
    "text": "questions so if you see the questions pane down there I want you to use that today we're going to use that to get",
    "start": "32960",
    "end": "38720"
  },
  {
    "text": "questions to myself as well as to Mike SATA and we're gonna get those answers for you live on the air today and if we",
    "start": "38720",
    "end": "44060"
  },
  {
    "text": "don't get to those questions this broadcast will be recorded put the follow-up email and we will try to get",
    "start": "44060",
    "end": "49340"
  },
  {
    "text": "all questions addressed as best you can our just weekend so my name is is Christopher burns I'm an artificial",
    "start": "49340",
    "end": "55370"
  },
  {
    "text": "intelligence and machine learning solutions architect here AWS I'm gonna be your host and moderator for today's",
    "start": "55370",
    "end": "60710"
  },
  {
    "text": "webinar also with me today I have Pete",
    "start": "60710",
    "end": "69170"
  },
  {
    "start": "66000",
    "end": "181000"
  },
  {
    "text": "lobster vice president senior vice president excuse me a global head of marketing at PAX HANA as well as Martha",
    "start": "69170",
    "end": "74690"
  },
  {
    "text": "Miller senior solutions engineer at thang SATA and they have some great information to give to give you today",
    "start": "74690",
    "end": "79909"
  },
  {
    "text": "but before we get to the partner we're going to go up I want to just briefly touch on today's agenda as well as what",
    "start": "79909",
    "end": "86659"
  },
  {
    "text": "we folks our learning objectives so the agenda is we're going to give you an overview of machine learning on AWS as",
    "start": "86659",
    "end": "92630"
  },
  {
    "text": "well as how it affects our most partner network and we're gonna we're gonna hear from packs onto themselves right after",
    "start": "92630",
    "end": "98960"
  },
  {
    "text": "that and then finally we're gonna do a Q&A session at the end there so like I said if you have questions and get them into that box",
    "start": "98960",
    "end": "104210"
  },
  {
    "text": "we'll get them answered if where you live on the air today it's a great benefit to ask your questions here today and get this live answer rather than via",
    "start": "104210",
    "end": "112130"
  },
  {
    "text": "email now what we want you to take away from this webinar today is we need to",
    "start": "112130",
    "end": "118759"
  },
  {
    "text": "take away some some information on reducing your data prep for projects from 80 to 20 percent that's a huge",
    "start": "118759",
    "end": "124159"
  },
  {
    "text": "number so that's a gigantic number if you have any machine learning practitioners out there in the audience you should appreciate the time it takes",
    "start": "124159",
    "end": "131030"
  },
  {
    "text": "to prepare and collect this these data sets for machine learning and hopefully that sounds appealing to you and we went",
    "start": "131030",
    "end": "137060"
  },
  {
    "text": "in the ultimate that that reduction in preparation time is to accelerate your data science Emily",
    "start": "137060",
    "end": "142580"
  },
  {
    "text": "projects because really we talked about this it's all about delivering results right we want to get these out of out of",
    "start": "142580",
    "end": "147800"
  },
  {
    "text": "R&D in the production and into into the business processes and I finally will show you how to leverage built-in",
    "start": "147800",
    "end": "153650"
  },
  {
    "text": "machine learning algorithms like to clean excuse me to clean your shape data",
    "start": "153650",
    "end": "159080"
  },
  {
    "text": "for your data science initiatives so",
    "start": "159080",
    "end": "166970"
  },
  {
    "text": "very briefly as I mentioned I want to touch on machine learning on AWS I'm",
    "start": "166970",
    "end": "178400"
  },
  {
    "text": "gonna talk about machine learning as soon as I get the slides to work a little bit of irony there okay great so",
    "start": "178400",
    "end": "184700"
  },
  {
    "text": "Amazon we've been making investments in machine learning for over 20 years sometimes it's behind the scenes",
    "start": "184700",
    "end": "190400"
  },
  {
    "text": "sometimes it's not really apparent but I wouldn't talk about Amazon for a moment it holistically sometimes we separate",
    "start": "190400",
    "end": "195830"
  },
  {
    "text": "amazon.com from Amazon Web Services but we are all ones that one family we share our research we share creations and so I",
    "start": "195830",
    "end": "203150"
  },
  {
    "text": "want to make sure that you understand that we're talking about Hamazon calm as well as even as services here for the next couple of moments and it's",
    "start": "203150",
    "end": "209239"
  },
  {
    "text": "important remember that many for the capabilities that amazon.com uses that our customers experience we're all",
    "start": "209239",
    "end": "215150"
  },
  {
    "text": "driven by machine learning created internally and then offered to our customers AWS itself was originally the",
    "start": "215150",
    "end": "221780"
  },
  {
    "text": "internal creation at amazon.com and then exposed to be consumed by external customers and so within that vein I'm",
    "start": "221780",
    "end": "233450"
  },
  {
    "text": "going to break this machine learning family down into just a couple of a couple of sections so for stuff about",
    "start": "233450",
    "end": "238820"
  },
  {
    "text": "for fulfillment centers if you've never had a chance to visit one I highly recommend it to watch the robotic optimization in the",
    "start": "238820",
    "end": "245480"
  },
  {
    "text": "paths in a path planning to see robots whiz by each other to stop if the human is present and then resume it's really",
    "start": "245480",
    "end": "252200"
  },
  {
    "text": "impressive and not just from an entertainment perspective but from a you know the orchestration of math and",
    "start": "252200",
    "end": "257870"
  },
  {
    "text": "machine learning is happening behind the scenes there let's talk about for our moment our recommendation hinges on",
    "start": "257870",
    "end": "265660"
  },
  {
    "text": "as I'm sorry our question I apologize I",
    "start": "265660",
    "end": "271780"
  },
  {
    "text": "thought I heard something so back to our recommendation engines you know when you busy amazon.com you're presented with a",
    "start": "271780",
    "end": "277240"
  },
  {
    "text": "with a wealth of information about products related project project products excuse me products that other",
    "start": "277240",
    "end": "284020"
  },
  {
    "text": "people have bought similar products which is pretty handy when you're looking for the next book that you want to read so the recommendation engine is",
    "start": "284020",
    "end": "289900"
  },
  {
    "text": "working on a massive amount of data massive amount of data and those are the maturing behind the scenes for for many",
    "start": "289900",
    "end": "295960"
  },
  {
    "text": "many years primary sort of falls into that same family as our fulfillment center drones",
    "start": "295960",
    "end": "301120"
  },
  {
    "text": "except we've added computer vision much more to the mix there and we're also working in a spatial area as rather",
    "start": "301120",
    "end": "308530"
  },
  {
    "text": "than just two-dimensional so we have our voice driven interactions I'm going to",
    "start": "308530",
    "end": "313930"
  },
  {
    "text": "dedicate a spy to that in just a moment but because machine learning is a recombinant technology meaning it can be",
    "start": "313930",
    "end": "319690"
  },
  {
    "text": "combined with nearly any existing technology to create something new we have many many opportunities to infuse",
    "start": "319690",
    "end": "325120"
  },
  {
    "text": "ml with the existing products as well as creating entirely new products if you've ever used the amazon firetv there's a",
    "start": "325120",
    "end": "331750"
  },
  {
    "text": "feature there called x-ray and so if you get pause it's going to tell you the actors actresses and some great metadata",
    "start": "331750",
    "end": "337120"
  },
  {
    "text": "that's so in that scene so that's all driven by AI Tammuz on comm owns the",
    "start": "337120",
    "end": "342700"
  },
  {
    "text": "IMDB database and making just access to those celebrities and also we'll see a celebrity recognition feature and if you",
    "start": "342700",
    "end": "350140"
  },
  {
    "text": "get a few more slides so our mission",
    "start": "350140",
    "end": "356380"
  },
  {
    "start": "354000",
    "end": "392000"
  },
  {
    "text": "here at Amazon AWS is to put machine learning in the hands of every developer from every data scientist I like to add",
    "start": "356380",
    "end": "362650"
  },
  {
    "text": "builder internet internet phrase put machine learning in the hands of every developer every builder and every data scientist because we can't all be",
    "start": "362650",
    "end": "369040"
  },
  {
    "text": "developers we can all be the scientists and sometimes you just got to build something so that's that's a pretty it's",
    "start": "369040",
    "end": "375310"
  },
  {
    "text": "a pretty lofty mission when you think about it because data science is difficult it's difficult for new scientists to understand it can gain the",
    "start": "375310",
    "end": "382990"
  },
  {
    "text": "knowledge that developers and the DevOps have and is equally as difficult for developers to just jump in and assume",
    "start": "382990",
    "end": "388690"
  },
  {
    "text": "the role of a data scientist so",
    "start": "388690",
    "end": "393819"
  },
  {
    "start": "392000",
    "end": "448000"
  },
  {
    "text": "back to that back to that so that's like I told you about about our voice products if you don't recognize this",
    "start": "393819",
    "end": "400759"
  },
  {
    "text": "this is the Amazon Petco this is a the the first version of the Alexa persona",
    "start": "400759",
    "end": "406099"
  },
  {
    "text": "I'm sure you hope well hopefully you worry about that now HECO has turned into the entire line of products all",
    "start": "406099",
    "end": "411440"
  },
  {
    "text": "voice based it was probably the first consumer product to bring a voice",
    "start": "411440",
    "end": "417289"
  },
  {
    "text": "recognition really into the into the mainstream into the home and with it I brought the automatic speech recognition continuous speech recognition and if",
    "start": "417289",
    "end": "424340"
  },
  {
    "text": "you've been paying attention you'll notice that the new line of echo products are starting to appear with",
    "start": "424340",
    "end": "430039"
  },
  {
    "text": "cameras with screens and I'm not going to speculate on future features please don't think this is speculation but you",
    "start": "430039",
    "end": "437090"
  },
  {
    "text": "can begin to see some of the new new capabilities that that's going to bring when you add computer vision to NOP in",
    "start": "437090",
    "end": "444560"
  },
  {
    "text": "the home so speaking of computer vision and just",
    "start": "444560",
    "end": "451639"
  },
  {
    "text": "a little disclaimer this is where my personal my personal research of my personal favorites area of study and AI",
    "start": "451639",
    "end": "457610"
  },
  {
    "text": "is this computer vision I want to talk briefly about the Amazon recognition service we're going to see it again in a",
    "start": "457610",
    "end": "462860"
  },
  {
    "text": "couple slides when we see the entire AWS ml stack but I want to draw attention to it here to just show the rich array of",
    "start": "462860",
    "end": "469610"
  },
  {
    "text": "features available in this service so we have object and activity detection we're",
    "start": "469610",
    "end": "474680"
  },
  {
    "text": "going to come back to the head also in a moment but I want you to make special note here of the phrases they're object",
    "start": "474680",
    "end": "480979"
  },
  {
    "text": "and activity detection now if you've been paying attention to the computer vision field for some time you'll notice",
    "start": "480979",
    "end": "486169"
  },
  {
    "text": "that this used to say object classification so we're gonna come back to that here in another slide a person packing a very clever way to say you",
    "start": "486169",
    "end": "492710"
  },
  {
    "text": "know that's tracking tracking of individuals there are countless use cases to put that into play if you've",
    "start": "492710",
    "end": "498080"
  },
  {
    "text": "ever taken your kids in amusement park you can immediately see the value within person path that's going to be that's",
    "start": "498080",
    "end": "503300"
  },
  {
    "text": "available to you via the recognition service facial recognition as well as so we we sort of downplay that that's a",
    "start": "503300",
    "end": "511099"
  },
  {
    "text": "that service within recognition actually comes with a wealth of features for demographic sentiment analysis page you",
    "start": "511099",
    "end": "518599"
  },
  {
    "text": "know guessing so there's a lot of data there along with that facial recognition now real-time streaming this this is I",
    "start": "518599",
    "end": "525170"
  },
  {
    "text": "want to make sure I draw the distinction here that this is a the service with image stills still",
    "start": "525170",
    "end": "530390"
  },
  {
    "text": "images as well as video feeds so you can process either one content moderation is a great one for any any service that's",
    "start": "530390",
    "end": "537890"
  },
  {
    "text": "going to be publishing pictures from from users from oito from social sites down to any other type of us the vo who",
    "start": "537890",
    "end": "545000"
  },
  {
    "text": "knows a school function they can detect and filter out mature content before it's published and then finally last but",
    "start": "545000",
    "end": "551540"
  },
  {
    "text": "not least we have celebrity recognition because sometimes you just need to",
    "start": "551540",
    "end": "558080"
  },
  {
    "text": "recognize celebrities okay so I had talked about object classification",
    "start": "558080",
    "end": "565070"
  },
  {
    "start": "560000",
    "end": "670000"
  },
  {
    "text": "versus object detection I'm gonna I'm gonna address this picture in this line in just one moment but first of all I",
    "start": "565070",
    "end": "571040"
  },
  {
    "text": "want to do is course object classification what that means it's given X number of classes we call them",
    "start": "571040",
    "end": "577220"
  },
  {
    "text": "classes omission linear objects can we detect them in an image so in this",
    "start": "577220",
    "end": "582260"
  },
  {
    "text": "particular image if I were to say are there humans in this image it would return a result of yes with a confidence",
    "start": "582260",
    "end": "588770"
  },
  {
    "text": "score now what object detection is is it detects where an object is within an image and it's usually represented by",
    "start": "588770",
    "end": "595430"
  },
  {
    "text": "what's called a bounding box I don't have an example of a bounding box here but obviously you see where these labels",
    "start": "595430",
    "end": "601100"
  },
  {
    "text": "are there would be a huge national box around that that object and now what that does what the what object detection",
    "start": "601100",
    "end": "607790"
  },
  {
    "text": "does is it offers access to things like proximity to relationship and what we're",
    "start": "607790",
    "end": "613250"
  },
  {
    "text": "going to what we can do then we can build on object detection and move to scene detection so if I could draw your",
    "start": "613250",
    "end": "620060"
  },
  {
    "text": "attention to the slide now we see here we have a on the far left of balloon a gift a child and at the very top of the",
    "start": "620060",
    "end": "627110"
  },
  {
    "text": "screen in the middle it says party so you cannot train well I shouldn't say you cannot to be incredibly difficult to",
    "start": "627110",
    "end": "633740"
  },
  {
    "text": "train an algorithm to detect a party but you can drink turn our rhythm to say if I see all these elements I can make the",
    "start": "633740",
    "end": "640490"
  },
  {
    "text": "assumption if I could make the inference that there is a party even down in the bottom we see opening present that's event detection that's incredibly",
    "start": "640490",
    "end": "646970"
  },
  {
    "text": "powerful I know I sound probably like a little bit like a kid at Christmas about this but is incredibly powerful",
    "start": "646970",
    "end": "652190"
  },
  {
    "text": "technology the evolutions happening right here in front of us and oh by the way recognition has a great great free",
    "start": "652190",
    "end": "658010"
  },
  {
    "text": "tier so if you want to try this out and let up some cabbages some videos you could do that pretty",
    "start": "658010",
    "end": "663060"
  },
  {
    "text": "much at no cost I'll be mindful of my time here I do apologize I'm gonna go quickly to the",
    "start": "663060",
    "end": "671690"
  },
  {
    "start": "670000",
    "end": "829000"
  },
  {
    "text": "AWS machine learning stack so we call the stack is a holistic view of all the",
    "start": "671690",
    "end": "677580"
  },
  {
    "text": "services available to you from AWS when it comes to machine learning at the top layer are our application services so we",
    "start": "677580",
    "end": "683670"
  },
  {
    "text": "have recognition image and video there we just talk about them in depth our speech services we have call me we have",
    "start": "683670",
    "end": "689370"
  },
  {
    "text": "transcribed and was a language services we have translated comprehend and Lex so these are features and services ready to",
    "start": "689370",
    "end": "695610"
  },
  {
    "text": "use they're available via a very clean JSON API no coding required you simply send a payload with an image or with",
    "start": "695610",
    "end": "702330"
  },
  {
    "text": "some text and you get the response back that means you can infuse this directly in your projects without any any",
    "start": "702330",
    "end": "707520"
  },
  {
    "text": "research without any training and really hit the ground running platform services a bit of a middle tier if you will these",
    "start": "707520",
    "end": "714600"
  },
  {
    "text": "are these are services that are four teams Amazon sage maker was built to connect data Sciences with the DevOps",
    "start": "714600",
    "end": "720990"
  },
  {
    "text": "you're going to train you're going to provision endpoints you know host endpoints without ever worrying about provisioning resources on your owns",
    "start": "720990",
    "end": "727920"
  },
  {
    "text": "completely managed service D plans is going to give you ten fruits at the edge you can push your models to the edge on",
    "start": "727920",
    "end": "733770"
  },
  {
    "text": "this camera in the conference right there at the edge to its opens up a whole world of possibilities for taking",
    "start": "733770",
    "end": "738960"
  },
  {
    "text": "action at the edge as well when you have a it's a scenario where you need very very timely inferences we have spark an",
    "start": "738960",
    "end": "746160"
  },
  {
    "text": "EMR so if you have a obviously spark ml is incredibly popular library and via",
    "start": "746160",
    "end": "753390"
  },
  {
    "text": "Marshall we can do all your big data needs as well as individual research and development on on frameworks and then we",
    "start": "753390",
    "end": "759210"
  },
  {
    "text": "have Mechanical Turk real quickly is playing a bigger and bigger role we can put Turks actually bit Amazon since the",
    "start": "759210",
    "end": "764970"
  },
  {
    "text": "beginning but the reason is significant now is if you have a million images that you need to label before you can run",
    "start": "764970",
    "end": "771570"
  },
  {
    "text": "them through you know through a machine learning training process it's a very very difficult for everytime kazooing",
    "start": "771570",
    "end": "777840"
  },
  {
    "text": "processor you can turn to a crowdsourcing mechanism like Mechanical Turk and get that done and if finally we",
    "start": "777840",
    "end": "783420"
  },
  {
    "text": "have frameworks as an infrastructure we welcome all ml frameworks at Amazon whether it's tensorflow or MX net CNC",
    "start": "783420",
    "end": "791070"
  },
  {
    "text": "cafe pipe which they all run as equally so you can bring those two to our infrastructure and it will run just just",
    "start": "791070",
    "end": "798180"
  },
  {
    "text": "fine and then finally we have a wider range of time to be a wide array of selections for training sometimes you",
    "start": "798180",
    "end": "804750"
  },
  {
    "text": "want to train on CPU maybe you're doing some extra boost or a linear learner type algorithm and sometimes you want to",
    "start": "804750",
    "end": "809940"
  },
  {
    "text": "train on GPU so you've got some neural network activity there a fleet of p3s will crunch through data with",
    "start": "809940",
    "end": "815310"
  },
  {
    "text": "acquittance that will impress almost anybody we also have the FPGAs so once you settle on an",
    "start": "815310",
    "end": "820890"
  },
  {
    "text": "algorithm if you need that algorithm to run a highly optimized manner you can look to these field programmable gate",
    "start": "820890",
    "end": "826350"
  },
  {
    "text": "arrays don't like the name drop but we",
    "start": "826350",
    "end": "832950"
  },
  {
    "text": "are proud of the customers that are running machine learning workloads on AWS today and then finally I'm gonna",
    "start": "832950",
    "end": "841020"
  },
  {
    "start": "839000",
    "end": "890000"
  },
  {
    "text": "take a couple seconds here to talk about the machine learning competency our partners at AWS you'll be anyone can be",
    "start": "841020",
    "end": "847110"
  },
  {
    "text": "a partner you sign up and there are different tiers to partnership with different benefits but to achieve a competency you have to go through a very",
    "start": "847110",
    "end": "854100"
  },
  {
    "text": "very rigorous process by which you present use cases in a particular area in this case we talked about machine",
    "start": "854100",
    "end": "859650"
  },
  {
    "text": "learning now I personally met these use cases myself I'm personally involved in this program so I know the bar is",
    "start": "859650",
    "end": "865440"
  },
  {
    "text": "credibly high to get this competency so while we we kind of represented here with this little gold badge the truth of",
    "start": "865440",
    "end": "871620"
  },
  {
    "text": "the matter is the partners that have this competency are really good what",
    "start": "871620",
    "end": "876839"
  },
  {
    "text": "they do they are certainly come with so that you have certified trusted partners to handle the most complex machine",
    "start": "876839",
    "end": "883080"
  },
  {
    "text": "learning processes and speaking of partners that are very very competent I want to now introduce you to Pete Pete",
    "start": "883080",
    "end": "891240"
  },
  {
    "text": "as I said is the senior vice president and global head of marketing at Posada and he's going to take it from here and",
    "start": "891240",
    "end": "896280"
  },
  {
    "text": "he's going to give you some great information on pax Auto Services piece.i Chris thank",
    "start": "896280",
    "end": "902820"
  },
  {
    "text": "you very much for for the introduction and we are spirit super proud of being",
    "start": "902820",
    "end": "908520"
  },
  {
    "text": "one of your competency partners for AWA the machine learning so let me just see",
    "start": "908520",
    "end": "913860"
  },
  {
    "text": "if I can get controls of the slides here and it looks like I'm off to the races there we go so let me quickly kick off",
    "start": "913860",
    "end": "921150"
  },
  {
    "start": "917000",
    "end": "1008000"
  },
  {
    "text": "with just a quick snapshot of who packs at our ears we have been founded in 2012 so we've",
    "start": "921150",
    "end": "928810"
  },
  {
    "text": "been around for six seven years already we've got offices in a number of",
    "start": "928810",
    "end": "934810"
  },
  {
    "text": "locations here in the US as well as internationally and back Saada is focused on providing an enterprise-grade",
    "start": "934810",
    "end": "941280"
  },
  {
    "text": "self-service data preparation platform that is aimed not just at programmer and",
    "start": "941280",
    "end": "948400"
  },
  {
    "text": "sort of ite technical developer type people the focus is on empowering the",
    "start": "948400",
    "end": "954220"
  },
  {
    "text": "business consumer our architecture and we'll spend a little bit of time is it's",
    "start": "954220",
    "end": "959950"
  },
  {
    "text": "built on a sort of a very very powerful elastic scale out platform so allowing",
    "start": "959950",
    "end": "966520"
  },
  {
    "text": "us to do scale with your data needs um and we obviously have been certified to",
    "start": "966520",
    "end": "972580"
  },
  {
    "text": "run within the AWS environment and we'll touch on a few customer use cases but",
    "start": "972580",
    "end": "977800"
  },
  {
    "text": "we've got customers across all kinds of industries all over the world deploying",
    "start": "977800",
    "end": "982840"
  },
  {
    "text": "us in machine learning environments data science deploying us also in regular analytical type platforms and lastly",
    "start": "982840",
    "end": "991470"
  },
  {
    "text": "we're pretty excited last week Forrester released the latest wave for data",
    "start": "991470",
    "end": "998350"
  },
  {
    "text": "preparation applications and solutions and so we have been named as one of the leaders within within that wave so we're",
    "start": "998350",
    "end": "1005760"
  },
  {
    "text": "really excited about that so let's jump into our pack sonic and how I think most",
    "start": "1005760",
    "end": "1011100"
  },
  {
    "start": "1008000",
    "end": "1082000"
  },
  {
    "text": "of us have seen this little statistic here in some form or the other but most",
    "start": "1011100",
    "end": "1018270"
  },
  {
    "text": "of our projects in the cool things Adam Chris had shown us um start with data starts with getting access to data and",
    "start": "1018270",
    "end": "1024480"
  },
  {
    "text": "then sure keeping that data into the format that is applicable for your purpose and for your project our",
    "start": "1024480",
    "end": "1031380"
  },
  {
    "text": "traditional mode and this has been going on for 20-plus years as being as if let's go ask somebody an IT and",
    "start": "1031380",
    "end": "1036688"
  },
  {
    "text": "developers and technical people because they're the only people were the tools they really are the only people with the",
    "start": "1036689",
    "end": "1042360"
  },
  {
    "text": "skills and the know-how and so what ends up happening is this back and forth back",
    "start": "1042360",
    "end": "1047370"
  },
  {
    "text": "and forth between the business who requests the insights and the IT people",
    "start": "1047370",
    "end": "1052860"
  },
  {
    "text": "who know the technology side of things and there's a constant I'm exchanging our well is this what you're looking for",
    "start": "1052860",
    "end": "1059230"
  },
  {
    "text": "no I want it looking slightly differently and in the end of the process as this could consume 80% or",
    "start": "1059230",
    "end": "1066429"
  },
  {
    "text": "more of time now if you sort of look as Chris alluded to this is if you do a",
    "start": "1066429",
    "end": "1072850"
  },
  {
    "text": "hundred of these projects a year that's like if every one of those projects has an 80% overhead then eventually as we",
    "start": "1072850",
    "end": "1079929"
  },
  {
    "text": "spend very very little time on inside development and the reason is is simple",
    "start": "1079929",
    "end": "1085870"
  },
  {
    "start": "1082000",
    "end": "1152000"
  },
  {
    "text": "that data in itself is just a raw element it's not the inside it's kind of",
    "start": "1085870",
    "end": "1091600"
  },
  {
    "text": "interesting when people say data powers or is the oil for the fields for digital transformation data in itself can do",
    "start": "1091600",
    "end": "1099370"
  },
  {
    "text": "nothing because in its raw format it's not contextualized it's not mobile it's",
    "start": "1099370",
    "end": "1105070"
  },
  {
    "text": "not integrated it's not clean and it's not about just bad quality data but it's",
    "start": "1105070",
    "end": "1110470"
  },
  {
    "text": "when in one system a state like California is spelled a CA in another",
    "start": "1110470",
    "end": "1115870"
  },
  {
    "text": "state it's called California doing any kind of analytic on this become very",
    "start": "1115870",
    "end": "1121299"
  },
  {
    "text": "complicated and so really the process that we need to go through and we need to do so at absolute scale is how do",
    "start": "1121299",
    "end": "1128950"
  },
  {
    "text": "today we take masses and masses of raw data sources raw data elements and",
    "start": "1128950",
    "end": "1134340"
  },
  {
    "text": "compile that into something that is complete that is clean contextual and consumable and now we have that",
    "start": "1134340",
    "end": "1141309"
  },
  {
    "text": "information that we can then use to the to be the inputs in our machine learning projects into the analysis that we want",
    "start": "1141309",
    "end": "1149440"
  },
  {
    "text": "to drive on on the other side of our project now there's been a couple of",
    "start": "1149440",
    "end": "1155440"
  },
  {
    "text": "companies that we've worked with has actually changed this this this dynamic in a very very very big way",
    "start": "1155440",
    "end": "1163350"
  },
  {
    "text": "HMS is an interesting organization in the healthcare space they collect data from multiple providers and external",
    "start": "1163350",
    "end": "1170919"
  },
  {
    "text": "organizations and they're trying to detect fraudulent patterns in data submissions in claim submissions and",
    "start": "1170919",
    "end": "1177580"
  },
  {
    "text": "things like this you can imagine is when you work with two providers you're going to get two different formats of data so if we push",
    "start": "1177580",
    "end": "1185080"
  },
  {
    "text": "this through a back-end process that is ID dependent not understanding the context of all of the data elements that",
    "start": "1185080",
    "end": "1190900"
  },
  {
    "text": "might be coming in it can take very long and in the case of HMA some of these processes took them upwards of 300",
    "start": "1190900",
    "end": "1198359"
  },
  {
    "text": "300 days to compile the the data set that they can be utilizing and they",
    "start": "1198359",
    "end": "1204459"
  },
  {
    "text": "managed to a decrease that by some 70% oath is another interesting one perhaps",
    "start": "1204459",
    "end": "1210999"
  },
  {
    "text": "not as familiar but this is when Verizon acquired Yahoo and AOL and this is not a",
    "start": "1210999",
    "end": "1217389"
  },
  {
    "text": "machine learning activity but just you sort of bring home the value of empowering business with the capability",
    "start": "1217389",
    "end": "1223809"
  },
  {
    "text": "to work with the data directly a project that were Sam suggested to take",
    "start": "1223809",
    "end": "1228899"
  },
  {
    "text": "multi-month 22 months Sam was the the estimate for integrating multiple ERP",
    "start": "1228899",
    "end": "1234669"
  },
  {
    "text": "systems into this newly created entity was accelerated by 18 months and the",
    "start": "1234669",
    "end": "1242079"
  },
  {
    "text": "reason was is that they can put data preparation data access in the hands of",
    "start": "1242079",
    "end": "1247329"
  },
  {
    "text": "business consumers who could then understand and clean and manipulate the",
    "start": "1247329",
    "end": "1252399"
  },
  {
    "text": "data for use in the purposes and the inst on a chartered bank has achieved the 95 percent faster regulatory",
    "start": "1252399",
    "end": "1260200"
  },
  {
    "text": "reporting within their environment once again by empowering people closest to",
    "start": "1260200",
    "end": "1265419"
  },
  {
    "text": "the data at the business consumer so that's really at the heart of WebEx ara",
    "start": "1265419",
    "end": "1270759"
  },
  {
    "start": "1267000",
    "end": "1331000"
  },
  {
    "text": "is aiming to do in this market is we have we have good developers around our",
    "start": "1270759",
    "end": "1276399"
  },
  {
    "text": "organizations we've got data scientists in every organization we talk to those",
    "start": "1276399",
    "end": "1281979"
  },
  {
    "text": "say as if we don't have enough how do we get more people in on the act and so what Beck saunas set out to do when we",
    "start": "1281979",
    "end": "1288729"
  },
  {
    "text": "starts at six seven years ago was to empower the everybody data analyst the",
    "start": "1288729",
    "end": "1293799"
  },
  {
    "text": "citizen data scientists yes the data engineer and the data integration developer and the hard core data",
    "start": "1293799",
    "end": "1299619"
  },
  {
    "text": "scientists with with we can help you and empower you and by providing a very very",
    "start": "1299619",
    "end": "1306849"
  },
  {
    "text": "user-friendly a excel like visual experience we can bring more people to",
    "start": "1306849",
    "end": "1312879"
  },
  {
    "text": "the project we can bring more collaboration more interaction and would we receive in chief in the result of",
    "start": "1312879",
    "end": "1319690"
  },
  {
    "text": "this thing is as we speed up we speed up the process we speed up the accuracy of the data by multiple folds",
    "start": "1319690",
    "end": "1326169"
  },
  {
    "text": "and as we're going to go through the demo in a couple of minutes I'm rathas gonna show you exactly how some of these",
    "start": "1326169",
    "end": "1331629"
  },
  {
    "start": "1331000",
    "end": "1404000"
  },
  {
    "text": "things work in that environment so how does it apply to machine learning specifically well like in everything",
    "start": "1331629",
    "end": "1337720"
  },
  {
    "text": "else as I said step one is where as my data dude where can I find data and I've",
    "start": "1337720",
    "end": "1343720"
  },
  {
    "text": "got data from a multiple locations I've got some data and data lakes what's in it well it's not document that these",
    "start": "1343720",
    "end": "1349269"
  },
  {
    "text": "things are not strong on metadata so the first step is getting and understanding",
    "start": "1349269",
    "end": "1354549"
  },
  {
    "text": "and profiling the data once we have two three four data sets that we want to combine and work with we natan are clean",
    "start": "1354549",
    "end": "1361299"
  },
  {
    "text": "we need to prepare we need to shape it we need to manipulate it and then do sort of exploratory analysis on top of",
    "start": "1361299",
    "end": "1368350"
  },
  {
    "text": "that data to really tip begin to form some hypothesis and then we input this and to train our models we create test",
    "start": "1368350",
    "end": "1374769"
  },
  {
    "text": "data sets and we improve in the cycle starts again and so all of this iteration process I mean specifically in",
    "start": "1374769",
    "end": "1382149"
  },
  {
    "text": "step one and two is where facts are I can be of massive value in acceleration",
    "start": "1382149",
    "end": "1387190"
  },
  {
    "text": "even if you are really really proficient at scripting and developing in Python and all these um sort of more",
    "start": "1387190",
    "end": "1393789"
  },
  {
    "text": "programmatic type languages is doing it visually doing it iteratively doing it",
    "start": "1393789",
    "end": "1398799"
  },
  {
    "text": "in collaboration with your business peers and will accelerate your project in a big way let me jump to the next",
    "start": "1398799",
    "end": "1405999"
  },
  {
    "start": "1404000",
    "end": "1464000"
  },
  {
    "text": "slide once you use a couple of these examples and you can see on the left hand side sort of a snapshot um but as I",
    "start": "1405999",
    "end": "1411820"
  },
  {
    "text": "said the step one is profile identify key characteristics data elements that",
    "start": "1411820",
    "end": "1417159"
  },
  {
    "text": "we won't understand whether my data sets are skewed in any form and fashion and we want to be able to clean that",
    "start": "1417159",
    "end": "1423399"
  },
  {
    "text": "normalize as I mentioned it earlier is as if you've got in one system something is called CA for California another one",
    "start": "1423399",
    "end": "1430629"
  },
  {
    "text": "it spelled California spelled out and another one it is maybe misspelled is it's like how",
    "start": "1430629",
    "end": "1436419"
  },
  {
    "text": "do i quickly standardize these values and great rules if there are missing values how can i come up with an easy",
    "start": "1436419",
    "end": "1442950"
  },
  {
    "text": "computable rule that can help me fill in the values there I'm making the data a",
    "start": "1442950",
    "end": "1449259"
  },
  {
    "text": "consistent formatted and also allowing me to engineer the new features of my dataset by decomposing values or",
    "start": "1449259",
    "end": "1455889"
  },
  {
    "text": "transforming data to represent data he fashion that my machine learning",
    "start": "1455889",
    "end": "1460909"
  },
  {
    "text": "algorithm can actually understand very well and we got to see all of these things in practice one of them one of",
    "start": "1460909",
    "end": "1469370"
  },
  {
    "start": "1464000",
    "end": "1563000"
  },
  {
    "text": "our showcase accounts that we work with is a company in the pharmaceutical business and so this is a great example",
    "start": "1469370",
    "end": "1476419"
  },
  {
    "text": "our firm what most of us are struggling with and what they wanted to do is is to",
    "start": "1476419",
    "end": "1482179"
  },
  {
    "text": "basically leverage more than 30 years of clinical trial data coming from 100-plus",
    "start": "1482179",
    "end": "1487610"
  },
  {
    "text": "countries and you can imagine is somebody's looking at this and say there must be some gold in there we must be",
    "start": "1487610",
    "end": "1493070"
  },
  {
    "text": "something valuable in there if we can just get access to this data and so all of the teams that are developing new",
    "start": "1493070",
    "end": "1499490"
  },
  {
    "text": "drugs basically could not easily get access to it and even if they can get access to it it's very very difficult to",
    "start": "1499490",
    "end": "1505669"
  },
  {
    "text": "analyze and what they've done is is by implementing packs on in the environment they allowed the data scientists the",
    "start": "1505669",
    "end": "1513649"
  },
  {
    "text": "data analysts the people closest to their need at that point in time to",
    "start": "1513649",
    "end": "1518690"
  },
  {
    "text": "actually discover data by themselves across all of this vast repository of information that is out there and they",
    "start": "1518690",
    "end": "1525799"
  },
  {
    "text": "could build the data preparation tasks and routines and recipes themselves make",
    "start": "1525799",
    "end": "1530809"
  },
  {
    "text": "data available and actually begin to reuse data from previous projects and so",
    "start": "1530809",
    "end": "1535970"
  },
  {
    "text": "by doing that as they were able to accelerate their project delivery times",
    "start": "1535970",
    "end": "1541940"
  },
  {
    "text": "the outcome times by a a Texas you can see there and all of this done in a code",
    "start": "1541940",
    "end": "1547730"
  },
  {
    "text": "free environment so it's not to say that you don't want to code there's a time and a place where coding is obviously",
    "start": "1547730",
    "end": "1553549"
  },
  {
    "text": "right but if everything is done at a code level we just don't get acceleration and it's very very",
    "start": "1553549",
    "end": "1558830"
  },
  {
    "text": "difficult to bring more people into the environment so at a nutshell if you sort",
    "start": "1558830",
    "end": "1564950"
  },
  {
    "start": "1563000",
    "end": "1620000"
  },
  {
    "text": "of take this big stay back and you say so how does impacts our our work well kind of three phases to the thing is as",
    "start": "1564950",
    "end": "1571429"
  },
  {
    "text": "there's data coming in from a number of places we ingest this into the platform and there's intelligent mechanisms",
    "start": "1571429",
    "end": "1578000"
  },
  {
    "text": "Martha's gonna show us how some of these work you can with one click you can profile understand your data documents",
    "start": "1578000",
    "end": "1584870"
  },
  {
    "text": "exactly what's in it you begin to visually explore and then you begin to clean and shape the data there's intelligent algorithms and machine",
    "start": "1584870",
    "end": "1592700"
  },
  {
    "text": "embedded in the platform that make recommendations so that you don't and get something wrong whether it is to",
    "start": "1592700",
    "end": "1599180"
  },
  {
    "text": "standardized values or whether it is to join datasets together and then ultimately you can share this publish",
    "start": "1599180",
    "end": "1605900"
  },
  {
    "text": "this out again into the environments that you want to whether it be into your AWS data lake or maybe it's in the",
    "start": "1605900",
    "end": "1613250"
  },
  {
    "text": "machine learning environment or you want to use AWS H makers or so that's kind of at a high level the flow that we're",
    "start": "1613250",
    "end": "1619430"
  },
  {
    "text": "aiming to work what makes us unique and if I think sit to retain to entertain to",
    "start": "1619430",
    "end": "1624590"
  },
  {
    "start": "1620000",
    "end": "1717000"
  },
  {
    "text": "want to talk about one is that visual interactivity but at scale quite a lot",
    "start": "1624590",
    "end": "1629690"
  },
  {
    "text": "of time when you see these kinds of data preparation environments they work on small samples and samples are cool",
    "start": "1629690",
    "end": "1635690"
  },
  {
    "text": "because it seems very fast the problem with the sample it doesn't tell you what's wrong in your dataset it tells he was wrong in the sample so",
    "start": "1635690",
    "end": "1642950"
  },
  {
    "text": "if you've got a big data set and you want to know all of the outliers the skewing of the data say it's a sample is meaningless right so you want to be able",
    "start": "1642950",
    "end": "1649400"
  },
  {
    "text": "to work at scale we're unique in the sense that we're actually powered by running on stock and so we can run at",
    "start": "1649400",
    "end": "1656090"
  },
  {
    "text": "pretty big scale intelligence built-in algorithms give your recommendations guide you help you and help you",
    "start": "1656090",
    "end": "1662810"
  },
  {
    "text": "understand and accelerate the process for you and we talked about the sort of",
    "start": "1662810",
    "end": "1668240"
  },
  {
    "text": "adaptive nature the elastic scaling of the environment that is absolutely critical a lot of these data projects",
    "start": "1668240",
    "end": "1674060"
  },
  {
    "text": "come and go so you do not want to have 24 by 7 paying for your cluster running",
    "start": "1674060",
    "end": "1679670"
  },
  {
    "text": "we are not going to use it like that or if you're only gonna use this for three weeks then pay you for the three weeks so we allow you to actually scale and",
    "start": "1679670",
    "end": "1686630"
  },
  {
    "text": "adjust your cost and performance dynamics to help there it's governed it automatically is keeping track of",
    "start": "1686630",
    "end": "1692630"
  },
  {
    "text": "everything you do it actually every step you make think about you're working in an Excel environment you create a",
    "start": "1692630",
    "end": "1698060"
  },
  {
    "text": "vlookup or you modify the value or you add a to column all of these things are",
    "start": "1698060",
    "end": "1703070"
  },
  {
    "text": "documented now you can have data lineage you can track what was going on and the last bit is that collaborative aspect",
    "start": "1703070",
    "end": "1709160"
  },
  {
    "text": "that we're talking about that is really really critical I'm so being able to share data sets and work together so",
    "start": "1709160",
    "end": "1715370"
  },
  {
    "text": "with that I am gonna hand over and get Martha to ER to take us through the demo",
    "start": "1715370",
    "end": "1722590"
  },
  {
    "start": "1717000",
    "end": "1860000"
  },
  {
    "text": "great thank you so much Pete this is Martha Miller let me just share my screen",
    "start": "1723010",
    "end": "1730250"
  },
  {
    "text": "and bring up the browser so we can get into the pack spotted demo if one of the panelists or someone that could speak",
    "start": "1730250",
    "end": "1736190"
  },
  {
    "text": "could just confirm that you can view the pack vada UI that would be great yes we yes perfect okay so so I'm logged into",
    "start": "1736190",
    "end": "1745070"
  },
  {
    "text": "pac sada right now the interface is via the browser so there's no desktop downloads or desktop software I'm logged",
    "start": "1745070",
    "end": "1751970"
  },
  {
    "text": "into pac sada and what we're looking at now is something that we call the library this is where we catalog data",
    "start": "1751970",
    "end": "1757580"
  },
  {
    "text": "sets that are available for data preparation and I have a few data sets",
    "start": "1757580",
    "end": "1762740"
  },
  {
    "text": "that are already listed here of course I could import data on the fly from s3 from redshift from other data lakes from",
    "start": "1762740",
    "end": "1770030"
  },
  {
    "text": "on-prem relational databases but in this case we're going to start with a retail",
    "start": "1770030",
    "end": "1775580"
  },
  {
    "text": "transaction data set and my goal in working with this data is actually to to",
    "start": "1775580",
    "end": "1781880"
  },
  {
    "text": "prepare data to feed a model which is going to help me predict and target my most profitable customers so I'm",
    "start": "1781880",
    "end": "1787669"
  },
  {
    "text": "starting with a transaction data set from the previous months from October and I just ran a profile on this data",
    "start": "1787669",
    "end": "1794450"
  },
  {
    "text": "set which as Pete mentioned is sort of step one in the data preparation process and the profile shows me for each column",
    "start": "1794450",
    "end": "1802970"
  },
  {
    "text": "in my data set a lot of information sort of a scorecard about the completeness and the consistency of this data this",
    "start": "1802970",
    "end": "1809210"
  },
  {
    "text": "will give me some pointers as to where I need to start my data preparation work so I can see you know the number of rows",
    "start": "1809210",
    "end": "1816169"
  },
  {
    "text": "I have some blanks when it comes to loyalty programs you know not all of my customers are part of our loyalty",
    "start": "1816169",
    "end": "1822490"
  },
  {
    "text": "memberships so that makes sense I scroll across and I can see number of unique values to validate keys a little bit",
    "start": "1822490",
    "end": "1829880"
  },
  {
    "text": "more sophisticated things like phonetically unique values and possible phonetic duplicates so this is",
    "start": "1829880",
    "end": "1835880"
  },
  {
    "text": "leveraging those built-in algorithms and I can see they're some pretty highly inconsistent data in both the city and",
    "start": "1835880",
    "end": "1842720"
  },
  {
    "text": "state columns so I'm probably going to want to look at that and start to clean that up and then some other metrics",
    "start": "1842720",
    "end": "1848390"
  },
  {
    "text": "about the min and Max string length nulls etc so step one is understanding how good is the data that I'm starting",
    "start": "1848390",
    "end": "1854900"
  },
  {
    "text": "with so that I know exactly what I need to do to prepare it for machine learning so we do that",
    "start": "1854900",
    "end": "1860980"
  },
  {
    "start": "1860000",
    "end": "2282000"
  },
  {
    "text": "data preparation in the context of a project so I just toggled over to the",
    "start": "1860980",
    "end": "1866649"
  },
  {
    "text": "project pane and I have in this environment a project that is already seated with that 2 million row data set",
    "start": "1866649",
    "end": "1874720"
  },
  {
    "text": "so I can scroll through the data in an interactive online environment again it's very intentionally really very much",
    "start": "1874720",
    "end": "1883000"
  },
  {
    "text": "like Excel where I can scroll across the rows and columns and what I've presented here are two filter grabs on the data on",
    "start": "1883000",
    "end": "1891970"
  },
  {
    "text": "those city and state columns so I can see here in my state column that I do have some duplicates and in fact I might",
    "start": "1891970",
    "end": "1899529"
  },
  {
    "text": "want to it may just be a matter of cleaning up the case or making the case consistent so I understand you know",
    "start": "1899529",
    "end": "1906789"
  },
  {
    "text": "maybe some data anomaly is by looking at the profile and then by clicking on any column I'm presented with and let me",
    "start": "1906789",
    "end": "1913809"
  },
  {
    "text": "just expand that a bit I'm presented with a menu of drop-down options so this is where I can start to to clean the",
    "start": "1913809",
    "end": "1920740"
  },
  {
    "text": "data making the case consistent as perhaps step one so I've just selected you know I'd like to make the state and",
    "start": "1920740",
    "end": "1927730"
  },
  {
    "text": "in fact I can select multiple columns so perhaps the city and state I want to clean up that data and make the case",
    "start": "1927730",
    "end": "1933669"
  },
  {
    "text": "consistent to capital case packs oddish shows me a preview of the change that",
    "start": "1933669",
    "end": "1938860"
  },
  {
    "text": "I'm about to make a when I click Save that change is applied and the data is updated and the number of unique values",
    "start": "1938860",
    "end": "1944830"
  },
  {
    "text": "in my state column has actually decreased so I'm starting to clean and normalize this data and now I can filter",
    "start": "1944830",
    "end": "1951399"
  },
  {
    "text": "and understand what do I still have potential anomalies I've selected New York which filters the data down below",
    "start": "1951399",
    "end": "1958510"
  },
  {
    "text": "also filters the cities and I can see that there are some duplicates here that weren't addressed by that case",
    "start": "1958510",
    "end": "1965649"
  },
  {
    "text": "inconsistency so this is where I might need to leverage one of the more sophisticated transformations to find",
    "start": "1965649",
    "end": "1972909"
  },
  {
    "text": "similar values in this data and for that I'm going to select cluster and edit which brings up a menu where I can",
    "start": "1972909",
    "end": "1980559"
  },
  {
    "text": "select not only the algorithm that I'd like to use but also the method by which",
    "start": "1980559",
    "end": "1985809"
  },
  {
    "text": "I'd like to cluster similar values together so in this case pack Tata using a phonetic algorithm so looking for",
    "start": "1985809",
    "end": "1993010"
  },
  {
    "text": "phonetic similar found 11 clusters in this 2.3 million row dataset and if I want to cluster to",
    "start": "1993010",
    "end": "2000000"
  },
  {
    "text": "the most frequent value I simply check that box if in some cases the most",
    "start": "2000000",
    "end": "2006330"
  },
  {
    "text": "frequent value may be incorrect I can select a different value or even type in my own default so this is where you know",
    "start": "2006330",
    "end": "2013320"
  },
  {
    "text": "leveraging my knowledge of the data and how it should fit together I can make those adjustments I select save and now",
    "start": "2013320",
    "end": "2021000"
  },
  {
    "text": "I've normalized the cities as well so we've got 80 unique City values and clean States I feel pretty good that",
    "start": "2021000",
    "end": "2027720"
  },
  {
    "text": "this data is clean and now I want to turn my attention to making sure well do I have the right data to feed my model",
    "start": "2027720",
    "end": "2034770"
  },
  {
    "text": "if if I want to look at predicting purchasing behavior in the winter and",
    "start": "2034770",
    "end": "2039900"
  },
  {
    "text": "focus specifically on October as a starting point and when I bring up a filter Graham on the transaction date",
    "start": "2039900",
    "end": "2046470"
  },
  {
    "text": "you can see it's presented as a calendar and I can very quickly see that I have some outliers as I make this selection I",
    "start": "2046470",
    "end": "2054120"
  },
  {
    "text": "can see that somehow there are few records just three out of those 2.3 million where the dates seem to have",
    "start": "2054120",
    "end": "2060240"
  },
  {
    "text": "been transposed so clearly that's a problem I don't want to include those those records in my model so I'm going",
    "start": "2060240",
    "end": "2067530"
  },
  {
    "text": "to highlight those as well it appears that perhaps there's some data that isn't in October and when I make this",
    "start": "2067530",
    "end": "2073560"
  },
  {
    "text": "selection I can see I've got some September values as well so I highlighted these outliers I actually",
    "start": "2073560",
    "end": "2079020"
  },
  {
    "text": "want to take these out of my data set because they don't fit the criteria that",
    "start": "2079020",
    "end": "2084149"
  },
  {
    "text": "I've established and so I just clicked on the scissors and by clicking save I've just removed these rows from my",
    "start": "2084150",
    "end": "2091500"
  },
  {
    "text": "view now I haven't changed the source data I'm just changing the data that I'm working with interactively in packs odda",
    "start": "2091500",
    "end": "2096800"
  },
  {
    "text": "so now I have all the dates in October that's great that's what I'm looking for I may want to break this out by other",
    "start": "2096800",
    "end": "2103470"
  },
  {
    "text": "date part or more likely perhaps I want to add additional features to this data",
    "start": "2103470",
    "end": "2109680"
  },
  {
    "text": "set for example deconstructing the transaction date perhaps adding a new",
    "start": "2109680",
    "end": "2114750"
  },
  {
    "text": "column using some of the built-in functions again very similar point-and-click",
    "start": "2114750",
    "end": "2121590"
  },
  {
    "text": "Excel what I'd like to do is actually instead of just presenting the date as it is I'd like to be able to look at day",
    "start": "2121590",
    "end": "2128580"
  },
  {
    "text": "of week as well as that so I can understand you know purchases on the weekends purchases on weekdays so I've",
    "start": "2128580",
    "end": "2135060"
  },
  {
    "text": "added this new day of wheat column and you can see that's now add it to the end of my data set I also want to look and",
    "start": "2135060",
    "end": "2143880"
  },
  {
    "text": "be able to flag purchasing patterns and values so my goal is to focus on the",
    "start": "2143880",
    "end": "2150600"
  },
  {
    "text": "most profitable customers it's important to know and highlight I've just brought up a filter Graham on the amounts tent",
    "start": "2150600",
    "end": "2157970"
  },
  {
    "text": "there are a lot of returns in this data set in fact all of these values less",
    "start": "2157970",
    "end": "2163050"
  },
  {
    "text": "than zero were actually purchases that were brought back and so that's something I'd like to flag I'd like to",
    "start": "2163050",
    "end": "2168090"
  },
  {
    "text": "create a new really a binary flag on return and I can do that again through",
    "start": "2168090",
    "end": "2173580"
  },
  {
    "text": "point-and-click so I've selected everything less than zero I'm going to go ahead and create a new column for",
    "start": "2173580",
    "end": "2180360"
  },
  {
    "text": "return and I'm just going to populate this with a 1 anytime that condition is",
    "start": "2180360",
    "end": "2186300"
  },
  {
    "text": "met where the transaction amount is less than zero I just want to populate that return",
    "start": "2186300",
    "end": "2192690"
  },
  {
    "text": "column with a 1 and so now I can see those are represented here",
    "start": "2192690",
    "end": "2198779"
  },
  {
    "text": "and if I wanted to fill in the remaining values so that again the machine learning model could pick up one zeros",
    "start": "2198779",
    "end": "2204859"
  },
  {
    "text": "by selecting these transformation options I can perform a pretty simple",
    "start": "2204859",
    "end": "2210209"
  },
  {
    "text": "Find and Replace so anytime there's a blank I'd like to replace it with a zero this",
    "start": "2210209",
    "end": "2216569"
  },
  {
    "text": "is now creating a flag for my return without even writing a formula right",
    "start": "2216569",
    "end": "2221669"
  },
  {
    "text": "it's point-and-click it's very easy for anyone that's comfortable in Excel to be able to perform this type of this type",
    "start": "2221669",
    "end": "2229319"
  },
  {
    "text": "of flagging and variable creation and if I wanted to do something a bit more",
    "start": "2229319",
    "end": "2234559"
  },
  {
    "text": "sophisticated coming back to the computed column I'll just bring this up",
    "start": "2234559",
    "end": "2239939"
  },
  {
    "text": "again if I wanted to for example flag large transactions I can determine what",
    "start": "2239939",
    "end": "2246599"
  },
  {
    "text": "the criteria is for that so if I wanted to say well if the total amount is greater than a hundred then populate",
    "start": "2246599",
    "end": "2255809"
  },
  {
    "text": "with a one L zero so again very similar to the same type of syntax I would use",
    "start": "2255809",
    "end": "2262409"
  },
  {
    "text": "in Excel I've just created another new column for large transactions I click",
    "start": "2262409",
    "end": "2267479"
  },
  {
    "text": "Save and I'm starting to really complete this the types of data features doing some feature engineering to augment this",
    "start": "2267479",
    "end": "2274529"
  },
  {
    "text": "data set so it's optimized to feed in to my machine learning models in addition",
    "start": "2274529",
    "end": "2280589"
  },
  {
    "text": "to these types of binary variables if I have categorical data so if I scroll back here looking at card type if this",
    "start": "2280589",
    "end": "2288029"
  },
  {
    "start": "2282000",
    "end": "2712000"
  },
  {
    "text": "was an important variable to me I wanted to understand payment terms perhaps I have a loyalty credit card or program",
    "start": "2288029",
    "end": "2294150"
  },
  {
    "text": "that I wanted to understand the way that this data is structured each card type is actually listed with a",
    "start": "2294150",
    "end": "2301289"
  },
  {
    "text": "label on the transaction itself and what I'd really prefer is if for every line",
    "start": "2301289",
    "end": "2306359"
  },
  {
    "text": "of transactions again I had a flag as to which card was used it's a technique",
    "start": "2306359",
    "end": "2312119"
  },
  {
    "text": "that's often referred to as one hot encoding and it's actually very simple",
    "start": "2312119",
    "end": "2317309"
  },
  {
    "text": "to perform in PACs odda through one of our shaping exercises so I've selected",
    "start": "2317309",
    "end": "2322709"
  },
  {
    "text": "an option from the toolbar over here to reshape or reorient the data and that",
    "start": "2322709",
    "end": "2328439"
  },
  {
    "text": "can take a few forms you know deduplicating creating new group bys in this case I actually want to perform",
    "start": "2328439",
    "end": "2334140"
  },
  {
    "text": "a pivot on that card type column I'd like to see account of the card type",
    "start": "2334140",
    "end": "2341420"
  },
  {
    "text": "added to the column and then in the rows I'd like to continue to see some of",
    "start": "2341420",
    "end": "2347910"
  },
  {
    "text": "those key points of information that we've been looking at so I'll just go ahead and select really the key",
    "start": "2347910",
    "end": "2354810"
  },
  {
    "text": "attributes about this transactional data certainly the new column that I've selected keeping that date in there and",
    "start": "2354810",
    "end": "2363120"
  },
  {
    "text": "sub just selected to sort of reorient this data set and as I scroll across",
    "start": "2363120",
    "end": "2368310"
  },
  {
    "text": "again I get a preview I always be a preview this interactive user experience a preview of the change I'm about to",
    "start": "2368310",
    "end": "2375390"
  },
  {
    "text": "apply and when I click Save now I have these four new columns about the data",
    "start": "2375390",
    "end": "2381780"
  },
  {
    "text": "set so for each transaction I can now see exactly which card type was used",
    "start": "2381780",
    "end": "2386820"
  },
  {
    "text": "again with that type of variable flagging so this is great in about you",
    "start": "2386820",
    "end": "2393000"
  },
  {
    "text": "know 10 minutes I've done a lot of work with this single data set as Pete",
    "start": "2393000",
    "end": "2398490"
  },
  {
    "text": "mentioned it's often a requirement I would say you know very frequently a requirement to join data sets together",
    "start": "2398490",
    "end": "2404520"
  },
  {
    "text": "and so pack sada makes it very easy to work not only with a single incoming data set but also to append additional",
    "start": "2404520",
    "end": "2411750"
  },
  {
    "text": "data of the same form or even perform lookup operations and I'll just walk through that very quickly where I can",
    "start": "2411750",
    "end": "2419670"
  },
  {
    "text": "select a data set from my library or I could import data on the fly in this",
    "start": "2419670",
    "end": "2426000"
  },
  {
    "text": "case I want to see well this transaction data that I'm working with if I have a data set that represents additional",
    "start": "2426000",
    "end": "2432870"
  },
  {
    "text": "demographic information about my loyalty customers I'd really like to add that into this work so that when I publish",
    "start": "2432870",
    "end": "2441150"
  },
  {
    "text": "the results all of that customer demographic information can feed the model as well and so what I've selected",
    "start": "2441150",
    "end": "2447540"
  },
  {
    "text": "here is I'd like tax audit to calculate the join score this means that pack sada",
    "start": "2447540",
    "end": "2453900"
  },
  {
    "text": "is going to look across the datasets that I've selected and automatically look across the values so not the column",
    "start": "2453900",
    "end": "2460980"
  },
  {
    "text": "names and data types but the actual values to find potential matches and you see that pack sada found and match the",
    "start": "2460980",
    "end": "2468270"
  },
  {
    "text": "highest match between first name and last name and full name in my loyalty",
    "start": "2468270",
    "end": "2473340"
  },
  {
    "text": "program data set this is a huge benefit to particularly for non-technical users",
    "start": "2473340",
    "end": "2478680"
  },
  {
    "text": "that may not know how data fits together or if you have a new data set coming in",
    "start": "2478680",
    "end": "2483840"
  },
  {
    "text": "that you're not familiar with if you know how you want to join the data certainly you can pick the columns or you can let packs I to do that hard work",
    "start": "2483840",
    "end": "2490230"
  },
  {
    "text": "for you but even if you let pack Stata do the hard work you still have some control so",
    "start": "2490230",
    "end": "2495690"
  },
  {
    "text": "I just selected this options tab this is where I could choose you know do I only want to keep this the matching rows do I",
    "start": "2495690",
    "end": "2502380"
  },
  {
    "text": "want to bring in all the rows is it a lookup or is it a join and then finally",
    "start": "2502380",
    "end": "2507570"
  },
  {
    "text": "have some control over the fuzziness of the match so if I only want to exact matches tech SATA wouldn't find first",
    "start": "2507570",
    "end": "2514230"
  },
  {
    "text": "name last name full name but I'm going to keep the defaults in this case I'll click Save Peck's out is creating a",
    "start": "2514230",
    "end": "2521460"
  },
  {
    "text": "wider data set now so you can see over here to the right with this new column",
    "start": "2521460",
    "end": "2526560"
  },
  {
    "text": "header I have my loyalty data populated here it's joined up against my original data",
    "start": "2526560",
    "end": "2533880"
  },
  {
    "text": "set and then I have a sources column so this is great from a lineage perspective",
    "start": "2533880",
    "end": "2539310"
  },
  {
    "text": "because now it's very easy for me to highlight I only want all the rows that match up I can simply make that",
    "start": "2539310",
    "end": "2545190"
  },
  {
    "text": "selection or if I want all the rows I can read this filter criteria off but",
    "start": "2545190",
    "end": "2551880"
  },
  {
    "text": "I've now combined the data set just one last step I want to take before I publish the result and that is if there",
    "start": "2551880",
    "end": "2559050"
  },
  {
    "text": "are certain columns that are still remaining in my project that aren't",
    "start": "2559050",
    "end": "2564090"
  },
  {
    "text": "really pertinent to feeding a machine learning model like transaction ID not very helpful I can just hide that if for",
    "start": "2564090",
    "end": "2572880"
  },
  {
    "text": "whatever reason I needed to move columns around this is this columns editor allows me to again point and click and",
    "start": "2572880",
    "end": "2579570"
  },
  {
    "text": "select exactly the columns that I'd like to publish in the order that I need them",
    "start": "2579570",
    "end": "2585600"
  },
  {
    "text": "and when I click Save that change is applied and the last step",
    "start": "2585600",
    "end": "2591460"
  },
  {
    "text": "here is that I'd like to publish the data from PAC SATA and I do that through a lens and it just occurred to me this",
    "start": "2591460",
    "end": "2598990"
  },
  {
    "text": "is the first time we've seen this step panel so as Pete mentioned the benefit of PAC SATA is the governance and the",
    "start": "2598990",
    "end": "2605410"
  },
  {
    "text": "lineage and the audit trail that we provide automatically so you can see all the steps that I've performed along the",
    "start": "2605410",
    "end": "2612370"
  },
  {
    "text": "way these steps are editable so I can go back and make changes but at this point",
    "start": "2612370",
    "end": "2618370"
  },
  {
    "text": "let me just finish this workflow by saying well this is my clean data for",
    "start": "2618370",
    "end": "2625870"
  },
  {
    "text": "machine learning I've created this publish point I'll save that and then",
    "start": "2625870",
    "end": "2631600"
  },
  {
    "text": "actually click publish you'll notice I'm only publishing the data that matched so",
    "start": "2631600",
    "end": "2637750"
  },
  {
    "text": "I'm only publishing my loyalty data and publishing this 1.2 million rows and if",
    "start": "2637750",
    "end": "2644350"
  },
  {
    "text": "I just come back to the library I can see here is that data set that's been published it just completed there's the",
    "start": "2644350",
    "end": "2652450"
  },
  {
    "text": "data and now I can easily push it to to s3 or any other supported data source if",
    "start": "2652450",
    "end": "2660160"
  },
  {
    "text": "I push to s3 I can of course choose the format of the file that I'd like to",
    "start": "2660160",
    "end": "2666250"
  },
  {
    "text": "publish out to that s3 bucket and I can do this on demand this publish on-demand",
    "start": "2666250",
    "end": "2672130"
  },
  {
    "text": "anytime from the library and pack SATA supports automation as well so if",
    "start": "2672130",
    "end": "2678160"
  },
  {
    "text": "there's a workflow where you need to import data set apply the cleansing techniques apply the",
    "start": "2678160",
    "end": "2684850"
  },
  {
    "text": "feature engineering to create those new rules and new columns and then publish the data out you could run that on a",
    "start": "2684850",
    "end": "2689920"
  },
  {
    "text": "scheduled basis as well as on-demand so with that that was a whirlwind tour of",
    "start": "2689920",
    "end": "2696360"
  },
  {
    "text": "of CAC SATA and that the ease in which really any type of user can accelerate",
    "start": "2696360",
    "end": "2701560"
  },
  {
    "text": "the preparation of good clean data for machine learning so with that I think I'll turn it back to the moderator for",
    "start": "2701560",
    "end": "2708160"
  },
  {
    "text": "court questions and answers",
    "start": "2708160",
    "end": "2711839"
  },
  {
    "start": "2712000",
    "end": "3444000"
  },
  {
    "text": "great thank you very much Martha and beet for that for that great overview so we do have some questions rolling in and",
    "start": "2714609",
    "end": "2721150"
  },
  {
    "text": "the first one that looks relatively interesting here is compact so to say to replay these kinds of data preparation",
    "start": "2721150",
    "end": "2727900"
  },
  {
    "text": "actions so I hate to use a really old example or show my age here but almost",
    "start": "2727900",
    "end": "2733059"
  },
  {
    "text": "like I guess that can Excel the macro is something like that possible yeah so",
    "start": "2733059",
    "end": "2739779"
  },
  {
    "text": "it's sort of along the lines of what I was just speaking about that automation feature so there's two components of",
    "start": "2739779",
    "end": "2746109"
  },
  {
    "text": "that tax audit can automate the import of data into the library and then the running of the project so all of those",
    "start": "2746109",
    "end": "2753489"
  },
  {
    "text": "steps that I define can be run on a scheduled basis and you might have multiple output points so one thing that",
    "start": "2753489",
    "end": "2760599"
  },
  {
    "text": "we didn't get to in the demo is that if for example I have a series of exceptions that I find I might publish",
    "start": "2760599",
    "end": "2766509"
  },
  {
    "text": "those to a different location than where I published my final results for machine",
    "start": "2766509",
    "end": "2771609"
  },
  {
    "text": "learning but absolutely automation is part of our platform and that can be done on a scheduled or event-driven",
    "start": "2771609",
    "end": "2777069"
  },
  {
    "text": "basis okay great now here's one is",
    "start": "2777069",
    "end": "2782170"
  },
  {
    "text": "asking if there's going to be future plans for a desktop version or what is",
    "start": "2782170",
    "end": "2787390"
  },
  {
    "text": "the answer to those individuals or companies that have very sensitive data and are hesitant to use a web-based",
    "start": "2787390",
    "end": "2793299"
  },
  {
    "text": "platform no I don't I mean we don't have",
    "start": "2793299",
    "end": "2798910"
  },
  {
    "text": "any plans in our roadmap for a desktop version we do have you know we deploy",
    "start": "2798910",
    "end": "2804069"
  },
  {
    "text": "pack SATA in a variety of offerings we offer tax audit as a service which we run on AWS we support virtual private",
    "start": "2804069",
    "end": "2811720"
  },
  {
    "text": "cloud deployments as well and then we do have some on-premise customers but the processing is done on the server it's",
    "start": "2811720",
    "end": "2818289"
  },
  {
    "text": "the results that are being returned to the browser and there is you know full security and SSL across that data",
    "start": "2818289",
    "end": "2824349"
  },
  {
    "text": "pipeline but we don't have any plans for a standalone desktop install okay great",
    "start": "2824349",
    "end": "2830499"
  },
  {
    "text": "thank you now what kind of files can can we import we show some structured data",
    "start": "2830499",
    "end": "2836799"
  },
  {
    "text": "in an example here but for instance if we have JSON or XML files how would that import the data and",
    "start": "2836799",
    "end": "2845049"
  },
  {
    "text": "interpret those schemes sure so Peck Tata supports really a",
    "start": "2845049",
    "end": "2850450"
  },
  {
    "text": "variety of structured and semi-structured formats on both xml and json are supported and we actually do",
    "start": "2850450",
    "end": "2857230"
  },
  {
    "text": "some automatic parsing of those semi structured files before we bring that data into the library so the goal is",
    "start": "2857230",
    "end": "2864540"
  },
  {
    "text": "will automate the processing or the parsing as much as possible and then there are some toggle switches if you",
    "start": "2864540",
    "end": "2871150"
  },
  {
    "text": "need to set some additional parameters or where you need your data node to start things like that but we have a lot",
    "start": "2871150",
    "end": "2877870"
  },
  {
    "text": "of customers where those are primary file types that they work with and the great thing about it is that once you get into the pack SATA project the user",
    "start": "2877870",
    "end": "2885670"
  },
  {
    "text": "wouldn't necessarily know the originating data type because it's always going to be presented as rows and columns so the user experience will be",
    "start": "2885670",
    "end": "2894520"
  },
  {
    "text": "the same working with those semi structured files in the in the project as it would if it was a you know CSV or",
    "start": "2894520",
    "end": "2900460"
  },
  {
    "text": "relational table or anything like that right okay got it so let's let's talk about automation for",
    "start": "2900460",
    "end": "2908080"
  },
  {
    "text": "a moment because you know manual processes can sometimes you know be the",
    "start": "2908080",
    "end": "2913480"
  },
  {
    "text": "devil in the details is it possible to schedule jobs on regular intervals or",
    "start": "2913480",
    "end": "2919090"
  },
  {
    "text": "even odds your regular intervals yes yes",
    "start": "2919090",
    "end": "2924100"
  },
  {
    "text": "so they're they're really - I would say pieces of automation in tax data we do",
    "start": "2924100",
    "end": "2929590"
  },
  {
    "text": "import data into our library so you could set up data to kind of crime in",
    "start": "2929590",
    "end": "2935260"
  },
  {
    "text": "the library on a scheduled basis so every time there's a new file or every time yesterday's data is complete or",
    "start": "2935260",
    "end": "2941350"
  },
  {
    "text": "even more near real-time we do have some customers that are you know updating data for example from s3 we clog those",
    "start": "2941350",
    "end": "2948970"
  },
  {
    "text": "files together we bring them into the library so there's automation for that step and then there's also automation of",
    "start": "2948970",
    "end": "2955210"
  },
  {
    "text": "the running of the project and the results which we publish as answer sets",
    "start": "2955210",
    "end": "2960490"
  },
  {
    "text": "and that that all both of all of the automation capabilities in packets are there are point-and-click user",
    "start": "2960490",
    "end": "2967480"
  },
  {
    "text": "interfaces to perform time-based scheduling and then we also have a very robust REST API where their endpoints",
    "start": "2967480",
    "end": "2974770"
  },
  {
    "text": "that make it easy to integrate with Enterprise schedulers so if you wanted to have more of a",
    "start": "2974770",
    "end": "2980500"
  },
  {
    "text": "event or trigger driven process you know as soon as this other process is done kickoff packs tada you can absolutely do",
    "start": "2980500",
    "end": "2986290"
  },
  {
    "text": "that as well okay great so then in any events where you want to plan ahead against issues like model decay and set",
    "start": "2986290",
    "end": "2994210"
  },
  {
    "text": "up a regular retraining interval you could actually use Peck SATA to to",
    "start": "2994210",
    "end": "2999280"
  },
  {
    "text": "prepare the data set and then pass it off to your to training process all in an automated api-based manner that's",
    "start": "2999280",
    "end": "3006720"
  },
  {
    "text": "correct that's absolutely right yes and I would say the best certainly the recommended",
    "start": "3006720",
    "end": "3012930"
  },
  {
    "text": "approach from from a from a developer's perspective okay so a couple more",
    "start": "3012930",
    "end": "3019020"
  },
  {
    "text": "questions here one what I'll just take here yes this video will be recorded and available afterwards everybody that has",
    "start": "3019020",
    "end": "3026430"
  },
  {
    "text": "attended today will get a follow-up email sort of thank you and that there will be a link to the video and any",
    "start": "3026430",
    "end": "3032580"
  },
  {
    "text": "questions that may have been asked that we didn't get answered we're trying to get those answers in there and give us a",
    "start": "3032580",
    "end": "3037740"
  },
  {
    "text": "give us two or three days for that to get that video properly edited and then in a in a format that's shareable and",
    "start": "3037740",
    "end": "3044220"
  },
  {
    "text": "socializing so we've got a couple couple more Rowan in here we have a couple more minutes so let's see here so here's a",
    "start": "3044220",
    "end": "3051330"
  },
  {
    "text": "question about importing a specific type of file type peek at our binary Network",
    "start": "3051330",
    "end": "3058500"
  },
  {
    "text": "log files so what would be the best practice from Paxos point of view of standardizing on a method to take a file",
    "start": "3058500",
    "end": "3065609"
  },
  {
    "text": "format that may or may not be supported I don't want to presume anything here but to get that that imported and so the",
    "start": "3065609",
    "end": "3072990"
  },
  {
    "text": "these pcap files I guess we don't want to get into the weeds on on what format that is but what specs on is advice for",
    "start": "3072990",
    "end": "3079920"
  },
  {
    "text": "taking a file format that may not be imported and then in converting something that is important and moving",
    "start": "3079920",
    "end": "3086640"
  },
  {
    "text": "on from there yeah that's something I haven't run across that particular file",
    "start": "3086640",
    "end": "3092609"
  },
  {
    "text": "type so I need to do a little bit of digging but in general you know any",
    "start": "3092609",
    "end": "3098330"
  },
  {
    "text": "obviously the first option would be converting to a file type that is supported so if there is another third-party tool that could convert",
    "start": "3098330",
    "end": "3104910"
  },
  {
    "text": "something to you know any type of delimited file with really any type of variable to eliminate delimiter pack",
    "start": "3104910",
    "end": "3111810"
  },
  {
    "text": "Stata will be able to read that so also extension list file so sometimes just removing the extension on the file",
    "start": "3111810",
    "end": "3119340"
  },
  {
    "text": "if the file is the underlying data is actually delimited by something just removing the extension pack SATA can",
    "start": "3119340",
    "end": "3126030"
  },
  {
    "text": "infer that and and give the user some options for that that automatic parsing but if you know it's if if you have the",
    "start": "3126030",
    "end": "3134190"
  },
  {
    "text": "details on whoever's asking that's a question Chris our way to get back to the mic I can do some work on that looking into that pcap format that you",
    "start": "3134190",
    "end": "3141060"
  },
  {
    "text": "mentioned yeah absolutely and another question here I think I can take is I",
    "start": "3141060",
    "end": "3147170"
  },
  {
    "text": "just I just lost it his pecs auto Chronicle AWS or is it a user of AWS how",
    "start": "3147170",
    "end": "3153150"
  },
  {
    "text": "is packs on if an AWS related so packs on it is a partner a p-n as the Amazon",
    "start": "3153150",
    "end": "3159780"
  },
  {
    "text": "partner network they are a partner forgive me pets I'm not sure which tier I forget but they have the mo competency",
    "start": "3159780",
    "end": "3166230"
  },
  {
    "text": "so I know that they are sufficiently advanced partner and if I understand correctly the tax audit infrastructure",
    "start": "3166230",
    "end": "3172440"
  },
  {
    "text": "does run on AWS but they are not a part of AWS in terms of a lot my word their",
    "start": "3172440",
    "end": "3181140"
  },
  {
    "text": "affiliates or or a subsidiary it's their own their own individual company that's",
    "start": "3181140",
    "end": "3188940"
  },
  {
    "text": "you can relate those I could make the analogy of the Netflix for example a",
    "start": "3188940",
    "end": "3194220"
  },
  {
    "text": "Netflix is not affiliated with Amazon or either with us except to be a customer",
    "start": "3194220",
    "end": "3199410"
  },
  {
    "text": "of Amazon Web Services than they are they run on the AWS infrastructure but they have their own business models",
    "start": "3199410",
    "end": "3204480"
  },
  {
    "text": "their own billing procedures and their own their own company that's occur",
    "start": "3204480",
    "end": "3213060"
  },
  {
    "text": "okay good I guess I shouldn't I shouldn't him that one off to you there",
    "start": "3213060",
    "end": "3218700"
  },
  {
    "text": "was one here I want to make sure I understand what they're asking k-pax not",
    "start": "3218700",
    "end": "3228450"
  },
  {
    "text": "extract multiple sources from multiple sources of format like sensor data and",
    "start": "3228450",
    "end": "3234380"
  },
  {
    "text": "contextualized with other static data so I guess this is a question about you showed the capability to infer that a",
    "start": "3234380",
    "end": "3242460"
  },
  {
    "text": "misspelling of one word and the correct spelling you want you want to replace those with the unified spelling so can",
    "start": "3242460",
    "end": "3250050"
  },
  {
    "text": "it contextualize over different sources of data and by sources I think we mean",
    "start": "3250050",
    "end": "3256410"
  },
  {
    "text": "different different files yeah so so a couple couple points there there's their",
    "start": "3256410",
    "end": "3262740"
  },
  {
    "text": "two ways that really really bring datasets together and we do that in the context of a project so if you have you",
    "start": "3262740",
    "end": "3270390"
  },
  {
    "text": "know sensor data that you want to bump up against some data that you have in a warehouse or you know local data that",
    "start": "3270390",
    "end": "3276330"
  },
  {
    "text": "you need to join with data in s3 or sort of rationalize together you would bring those those distinct files together in a",
    "start": "3276330",
    "end": "3283410"
  },
  {
    "text": "project you would leverage packs oughta join capabilities to find matches across",
    "start": "3283410",
    "end": "3289320"
  },
  {
    "text": "those data sets or you know potentially unioning those data sets together so those are both ways of bringing",
    "start": "3289320",
    "end": "3296790"
  },
  {
    "text": "disparate sources together and then all of the transformations which we really just touched on a handful of them but",
    "start": "3296790",
    "end": "3303000"
  },
  {
    "text": "there are a lot of transformations and the ability to create calculations and flags in packs oughtta that would allow",
    "start": "3303000",
    "end": "3308790"
  },
  {
    "text": "you to kind of rationalize those data sets together and create some additional context so I think the short answer is",
    "start": "3308790",
    "end": "3315600"
  },
  {
    "text": "yes as long as the data types are supported it's very easy to bring disparate data together in packs odda",
    "start": "3315600",
    "end": "3321690"
  },
  {
    "text": "and specifically with Spencer and log data there's some features like the",
    "start": "3321690",
    "end": "3327420"
  },
  {
    "text": "ability to use regular expressions to split data that's in a single column across multiple columns some features",
    "start": "3327420",
    "end": "3334410"
  },
  {
    "text": "that we didn't get to in this demo which which you know check out our website or request a more specialized demo of pack",
    "start": "3334410",
    "end": "3340230"
  },
  {
    "text": "FATA we'd be happy to get into those details but a lot of additional capabilities we weren't able to get to",
    "start": "3340230",
    "end": "3345390"
  },
  {
    "text": "you the time allotted today that can help with different types of files",
    "start": "3345390",
    "end": "3350539"
  },
  {
    "text": "all right great so sell it just a lot more advanced features that we weren't able to get to today which actually is a",
    "start": "3350539",
    "end": "3356250"
  },
  {
    "text": "perfect seg for the last question of the day and is that how can we those are they're interested how can they get more",
    "start": "3356250",
    "end": "3361859"
  },
  {
    "text": "hands-on tutorials training do we suggest that they visit the site or dance with special instructions there I",
    "start": "3361859",
    "end": "3369750"
  },
  {
    "text": "just noticed that you put up the next step slide so there are there the links",
    "start": "3369750",
    "end": "3375240"
  },
  {
    "text": "on this site will will provide links to you know some documentation some joint ebooks that we put out to highlight our",
    "start": "3375240",
    "end": "3381390"
  },
  {
    "text": "capabilities specifically on AWS and then we do offer trials as well both",
    "start": "3381390",
    "end": "3386930"
  },
  {
    "text": "trials in our staff offering which we run and do all the DevOps for we run",
    "start": "3386930",
    "end": "3393030"
  },
  {
    "text": "that on AWS or we could also support trials in virtual private clouds in",
    "start": "3393030",
    "end": "3398339"
  },
  {
    "text": "customer AWS environments so click those links and we'll get back and work with you directly fantastic",
    "start": "3398339",
    "end": "3406020"
  },
  {
    "text": "all right Thank You Martha Thank You Pete I want to just make sure you know we thank you once again for presenting",
    "start": "3406020",
    "end": "3411329"
  },
  {
    "text": "today this is a fantastic product I highly recommend it to anybody that's listening today to give it a try give it",
    "start": "3411329",
    "end": "3417359"
  },
  {
    "text": "give it a look kick the tires so to speak and then thank you the audience for attending today once again we'll have a",
    "start": "3417359",
    "end": "3422670"
  },
  {
    "text": "follow-up email with a survey and that please take the time to float the survey that helps us make these webinars more informative for you and better use of",
    "start": "3422670",
    "end": "3429420"
  },
  {
    "text": "your time and with that we are going to sign off for today so thanks again",
    "start": "3429420",
    "end": "3435109"
  }
]
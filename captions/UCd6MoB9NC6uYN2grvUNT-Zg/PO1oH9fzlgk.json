[
  {
    "start": "0",
    "end": "19000"
  },
  {
    "text": "first this is that this is a highly coveted spot I get to Lowell you guys",
    "start": "0",
    "end": "5819"
  },
  {
    "text": "back into technology and the amazing things that we're doing here in Amazon so thank you for coming and he had a lot",
    "start": "5819",
    "end": "11759"
  },
  {
    "text": "of choices probably sleeping in and I'm delighted to be presenting to you today",
    "start": "11759",
    "end": "18800"
  },
  {
    "text": "my wave introduction I'm Steve McPherson and the senior manager of Amazon Elastic MapReduce I was a customer before i came",
    "start": "18800",
    "end": "25890"
  },
  {
    "text": "to EMR in 2009 i was the director of technology at razorfish publicist and i",
    "start": "25890",
    "end": "32238"
  },
  {
    "text": "had a team of 35 engineers that knew almost nothing about linux hadoop or",
    "start": "32239",
    "end": "37290"
  },
  {
    "text": "cloud computing in general we we ran our business off sequel server cubes and",
    "start": "37290",
    "end": "42379"
  },
  {
    "text": "Microsoft Excel pivot tables as most businesses do nowadays but we had a",
    "start": "42379",
    "end": "49530"
  },
  {
    "text": "campaign is it's a digital advertising shop we had a campaign that was going to push us to process more data than we",
    "start": "49530",
    "end": "56129"
  },
  {
    "text": "never done before on an order of magnitude and we were losing our infrastructure we were we were just",
    "start": "56129",
    "end": "62460"
  },
  {
    "text": "purchased we were a Microsoft shop and then we were purchased by publicist so we were losing our infrastructure altogether it was perfect confluence of",
    "start": "62460",
    "end": "68520"
  },
  {
    "text": "bad things and as you know I had to figure out what is going to do so I found Hadoop and we got up we got up and",
    "start": "68520",
    "end": "76950"
  },
  {
    "text": "running with it I we started experimenting in the platform in the course of three months this team that",
    "start": "76950",
    "end": "82350"
  },
  {
    "text": "had no context or no knowledge of linux Hadoop or cloud computing at all was up and running in production running 45",
    "start": "82350",
    "end": "88799"
  },
  {
    "text": "terabytes of data a day it is transformational for me to see what you",
    "start": "88799",
    "end": "95400"
  },
  {
    "text": "could do in such a short period of time with people you know just getting up in a very complex domain I don't know how",
    "start": "95400",
    "end": "100470"
  },
  {
    "text": "many you guys are familiar with Hadoop in there great how many guys are customers of EMR okay good good to know",
    "start": "100470",
    "end": "109549"
  },
  {
    "text": "so for me that was transformational experience to see what can happen in a business when you can give people the",
    "start": "109549",
    "end": "115110"
  },
  {
    "text": "tools to take away all the craft of the infrastructure of it and since then 2009",
    "start": "115110",
    "end": "122180"
  },
  {
    "text": "like a dupe itself elastic MapReduce has evolved from being a job flow batch",
    "start": "122180",
    "end": "129660"
  },
  {
    "text": "processing engine into being a generic Hadoop cluster manager service with a diverse ecosystem of Hadoop",
    "start": "129660",
    "end": "136650"
  },
  {
    "text": "applications and I'm going to cover some of that stuff in this talk I'm going to get into data warehousing some of the",
    "start": "136650",
    "end": "143130"
  },
  {
    "text": "the thinking where we see most customers getting leverage out of the cloud and being successful with the Hadoop",
    "start": "143130",
    "end": "148530"
  },
  {
    "text": "ecosystem of applications and then availabe available afterwards for King",
    "start": "148530",
    "end": "153599"
  },
  {
    "text": "questions if anyone wants to go deeper on anything I talked about so regardless of the business that you're in it is",
    "start": "153599",
    "end": "160830"
  },
  {
    "text": "that it's important to be able to obtain information based on analysis of data coming from any number of sources and",
    "start": "160830",
    "end": "167910"
  },
  {
    "text": "you need the right tools to do that at scale it's it's helpful to look at",
    "start": "167910",
    "end": "174299"
  },
  {
    "start": "172000",
    "end": "262000"
  },
  {
    "text": "things in terms of a traditional data warehouse just to kind of give words for things on the left hand side in this",
    "start": "174299",
    "end": "180090"
  },
  {
    "text": "diagram we have ETL etli has the job of",
    "start": "180090",
    "end": "186330"
  },
  {
    "text": "taking data from where it's at in some form probably for some very good reason like it was written there from a web",
    "start": "186330",
    "end": "192390"
  },
  {
    "text": "server and and that's how it's ought to be transforming that into something that is a well formatted schema or something",
    "start": "192390",
    "end": "201480"
  },
  {
    "text": "that your business can make sense of for downstream tools that's that's the left side there on the right side you have",
    "start": "201480",
    "end": "208140"
  },
  {
    "text": "reporting in and ad-hoc analysis and things and this is typically the domain of where humans are asking questions in",
    "start": "208140",
    "end": "215850"
  },
  {
    "text": "the center you have this thing that is sort of this monolithic entity called a data warehouse and I say monolithic",
    "start": "215850",
    "end": "222739"
  },
  {
    "text": "because it mixes a responsibility of bulk data storage schema definition and",
    "start": "222739",
    "end": "227970"
  },
  {
    "text": "query execution and when you look at where you get caught up in your data warehousing it's because those things",
    "start": "227970",
    "end": "234510"
  },
  {
    "text": "are bound it's not necessarily because the engines good or bad at these things sequel is great for for doing querying",
    "start": "234510",
    "end": "239970"
  },
  {
    "text": "and so all these data warehouses that you sequel that's good because humans like sequel it's a structured query language I it's not necessarily bad that",
    "start": "239970",
    "end": "247980"
  },
  {
    "text": "they are how they go about storing their data it's bad that they're both scoring",
    "start": "247980",
    "end": "253049"
  },
  {
    "text": "and there's a guy who's storing it and the guy who is going to be doing the compute on tape on top of it so when you",
    "start": "253049",
    "end": "259590"
  },
  {
    "text": "can break these things apart you get a lot of power and software frameworks",
    "start": "259590",
    "end": "264960"
  },
  {
    "start": "262000",
    "end": "313000"
  },
  {
    "text": "like Hadoop can help with it does it by distributing the storage of the data too many computers and it",
    "start": "264960",
    "end": "273090"
  },
  {
    "text": "also then distributes the compute so you you can you can have your data store it",
    "start": "273090",
    "end": "278700"
  },
  {
    "text": "independently and you can you can scale up and down your computer sources I'm going to get into EMR for a second the",
    "start": "278700",
    "end": "285630"
  },
  {
    "text": "project itself started from an open-source community of developers working specifically on distributed batch processing engine it evolved from",
    "start": "285630",
    "end": "291450"
  },
  {
    "text": "that to be generally a moniker for all the open-source Big Data projects out there so it used to be that Hadoop",
    "start": "291450",
    "end": "297390"
  },
  {
    "text": "MapReduce it no longer means that Hadoop now means everything from a cifs to",
    "start": "297390",
    "end": "302700"
  },
  {
    "text": "storm to impala to what have you it's a general general term for open source big",
    "start": "302700",
    "end": "309360"
  },
  {
    "text": "data with Amazon EMR for those of you",
    "start": "309360",
    "end": "316770"
  },
  {
    "start": "313000",
    "end": "354000"
  },
  {
    "text": "that are not familiar with it using the elastic infrastructure of ec2 and s3 Amazon EMR provides a managed Hadoop",
    "start": "316770",
    "end": "323669"
  },
  {
    "text": "infrastructure EMR EMR takes the work of",
    "start": "323669",
    "end": "331979"
  },
  {
    "text": "setting up Hadoop that is specifically deploying the bits to it managing nodes",
    "start": "331979",
    "end": "337350"
  },
  {
    "text": "and making those managing the lifecycle of those and then also it we take on the",
    "start": "337350",
    "end": "343380"
  },
  {
    "text": "responsibility of making sure that the bits that are running in there are good and efficient as they interact with us three and the other AWS components so",
    "start": "343380",
    "end": "354750"
  },
  {
    "start": "354000",
    "end": "489000"
  },
  {
    "text": "where we had a traditional warehousing in the past I I didn't necessarily go into the into the slide where of tools",
    "start": "354750",
    "end": "361110"
  },
  {
    "text": "you can imagine all those they range from scripts you know she'll scripts and all these things to a very sophisticated",
    "start": "361110",
    "end": "367380"
  },
  {
    "text": "drag-and-drop transformation things in the hadoop world you can kind of see some of the tools in the ecosystem here",
    "start": "367380",
    "end": "373800"
  },
  {
    "text": "i have my on the extract side you have the MapReduce api's you have think",
    "start": "373800",
    "end": "379229"
  },
  {
    "text": "frameworks like scoot like scoop in the transform section you have any number of",
    "start": "379229",
    "end": "384240"
  },
  {
    "text": "languages and I there's probably more languages than I even know about out there but you know spark cascading pig",
    "start": "384240",
    "end": "390080"
  },
  {
    "text": "map race itself indeed warehousing i'm putting that that center section in",
    "start": "390080",
    "end": "396360"
  },
  {
    "text": "there to call out some some file formats and just kind of generally say that it's important to recognize that the storage",
    "start": "396360",
    "end": "401630"
  },
  {
    "text": "of the data it really is it's a logically separate part from all the",
    "start": "401630",
    "end": "406670"
  },
  {
    "text": "other bits in there and so there's there's good investment in technology in the community with file formats like parque & 0 RC that are able to take this",
    "start": "406670",
    "end": "412820"
  },
  {
    "text": "notion of columnar storage and actually make that available to many technologies",
    "start": "412820",
    "end": "418130"
  },
  {
    "text": "downstream so for example with parquet files or RC files you can get this you",
    "start": "418130",
    "end": "423770"
  },
  {
    "text": "need a very good benefit of storage when interacting with hive or interacting with presto or any number of other tools",
    "start": "423770",
    "end": "429020"
  },
  {
    "text": "so again decomposing these these monolithic blocks of what a day to our house is and what the different",
    "start": "429020",
    "end": "434180"
  },
  {
    "text": "functions of it is handy when you when you have all the parts kind of on the table like that on the right hand side",
    "start": "434180",
    "end": "440750"
  },
  {
    "text": "where it would be the humans asking the questions you have frameworks like hive against Park cascading pig this is you",
    "start": "440750",
    "end": "448340"
  },
  {
    "text": "know pig is in cascading are typically thought of in ETL but people often will also use them for for report generation",
    "start": "448340",
    "end": "455150"
  },
  {
    "text": "because it's handy right you have code and you can debug it and test it and things and then on the right hand side you have frameworks now like Impala",
    "start": "455150",
    "end": "462860"
  },
  {
    "text": "Facebook presto just which is a fantastic tool I'm going to show some of that later on hive spark sequel is now",
    "start": "462860",
    "end": "470390"
  },
  {
    "text": "emerging and cascading lingual so as we go from left to right the ecosystem of",
    "start": "470390",
    "end": "475670"
  },
  {
    "text": "tools that you might have used in history there is a component in the hadoop world that can help you with that",
    "start": "475670",
    "end": "482210"
  },
  {
    "text": "in this diagram i have specifically amazon s3 at the center normally",
    "start": "482210",
    "end": "488860"
  },
  {
    "text": "normally when people think of Hadoop they kind of just as quickly go to HDFS",
    "start": "489580",
    "end": "494780"
  },
  {
    "text": "and it's um HDFS is great it's a it's really very good one of the unfortunate",
    "start": "494780",
    "end": "500780"
  },
  {
    "text": "side effects of it is that when your HDFS is stuck is in a cluster when you",
    "start": "500780",
    "end": "506180"
  },
  {
    "text": "were defining your cluster as the machines a host your HDFS you then no longer can separate your compute from",
    "start": "506180",
    "end": "513620"
  },
  {
    "text": "your storage you're kind of stuck with this thing if you want more compute I'm sorry if you want more storage you have to buy more compute and so you end up",
    "start": "513620",
    "end": "520700"
  },
  {
    "text": "having these sort of these clusters that are irregularly balanced as a business grows and you get this massive data",
    "start": "520700",
    "end": "526790"
  },
  {
    "text": "storage and you have all this compute sitting around for no very good reason so for storage most of our customers use",
    "start": "526790",
    "end": "533390"
  },
  {
    "text": "Amazon syria's or single source of truth it is their data lake amazon tmr's optimize",
    "start": "533390",
    "end": "538850"
  },
  {
    "text": "the Hadoop components to work with Amazon s3 as their native storage the tight integration with s3 allows",
    "start": "538850",
    "end": "544010"
  },
  {
    "text": "customers to scale the storage independently of the compute it removes",
    "start": "544010",
    "end": "549500"
  },
  {
    "text": "operational burden of etfs it ensures high durability of the data it provides",
    "start": "549500",
    "end": "554600"
  },
  {
    "text": "universal access point from multiple clusters clusters to read the data itself so you can have one cluster",
    "start": "554600",
    "end": "560060"
  },
  {
    "text": "that's an ETL I have ETL life cycle so every night it needs to get something done in three hours and there's no fuss",
    "start": "560060",
    "end": "566330"
  },
  {
    "text": "no muss just get it done and then you have other workloads that may be more analytics somebody wants to run up to",
    "start": "566330",
    "end": "572779"
  },
  {
    "text": "like tableau and do analytics through some low latency query engine so having",
    "start": "572779",
    "end": "579110"
  },
  {
    "text": "us three is your back store I where in HDFS you can you can actually quickly",
    "start": "579110",
    "end": "585470"
  },
  {
    "text": "get to contention where there's only three guys out there that have the data so the request is going to go to one of",
    "start": "585470",
    "end": "590660"
  },
  {
    "text": "those sorry these three guys a heavy load s3 does not have that same contention problem s3 has is essentially",
    "start": "590660",
    "end": "598760"
  },
  {
    "text": "spinning disks that have extremely fat pipe to to all the nodes in your cluster so you you can take benefit by by having",
    "start": "598760",
    "end": "606830"
  },
  {
    "text": "that storage off the cluster I'll also point out the s3 is very low cost prices",
    "start": "606830",
    "end": "612529"
  },
  {
    "text": "have dropped seven times since the service launched in 2006 it also integrates with Amazon glacier for even",
    "start": "612529",
    "end": "618740"
  },
  {
    "text": "lower costs so where storage gets gets cold and you don't need it around anymore which is probably the bulk of",
    "start": "618740",
    "end": "625760"
  },
  {
    "text": "your data after you've done your normal processing you can easily ship it off to glacier so storing data in s3 allows",
    "start": "625760",
    "end": "635000"
  },
  {
    "start": "632000",
    "end": "674000"
  },
  {
    "text": "users to spin up as many classes as needed to test out new ideas new terminated clusters when they're longer in use that speeds up innovation that",
    "start": "635000",
    "end": "641180"
  },
  {
    "text": "lowers the cost of experimentation I and it also allows you to tune clusters for",
    "start": "641180",
    "end": "647240"
  },
  {
    "text": "their particular use case as I was serving for with EMR you can run a custom MapReduce code in written in Java",
    "start": "647240",
    "end": "654290"
  },
  {
    "text": "any of the frameworks or you can utilize any of the open-source technologies like",
    "start": "654290",
    "end": "660650"
  },
  {
    "text": "presto or HBase or spark all of these are available to you in elastic",
    "start": "660650",
    "end": "666829"
  },
  {
    "text": "MapReduce it's very it's a very rich environment for you to configure amazon using amazon",
    "start": "666829",
    "end": "677270"
  },
  {
    "start": "674000",
    "end": "737000"
  },
  {
    "text": "s3 is your storage also provides sort of business continuity out of the box if you I just recently had a customer",
    "start": "677270",
    "end": "683990"
  },
  {
    "text": "meeting and they were and they were going through their their dr planning big big company they had legitimate",
    "start": "683990",
    "end": "691160"
  },
  {
    "text": "concerns on they can never go down and coming from a world where they're planning alder their Hadoop work and",
    "start": "691160",
    "end": "696770"
  },
  {
    "text": "their data center they're thinking that they have to go build this massive infrastructure like to sit there warm",
    "start": "696770",
    "end": "701959"
  },
  {
    "text": "and just kind of do nothing with just just for the sake of dr and you all if",
    "start": "701959",
    "end": "706970"
  },
  {
    "text": "data replication and all this noise in fact elastic mapreduce because it you",
    "start": "706970",
    "end": "713060"
  },
  {
    "text": "can spin up clusters in any availability zone and if your data is an s3 it's that",
    "start": "713060",
    "end": "718970"
  },
  {
    "text": "but it really isn't a problem if you're easily goes down you have another cluster you can swing up another cluster in minutes and it's pointing it and has",
    "start": "718970",
    "end": "725060"
  },
  {
    "text": "just as good and just as high throughput access to that data as you would in the other AZ so it's another handy wait",
    "start": "725060",
    "end": "731690"
  },
  {
    "text": "another handy benefit that you get from breaking these these two problems up",
    "start": "731690",
    "end": "736600"
  },
  {
    "text": "it's easy to get started with amazon EMR you can load data from s3 from DynamoDB",
    "start": "738459",
    "end": "745990"
  },
  {
    "text": "from amazon kinesis and in three minutes",
    "start": "745990",
    "end": "751370"
  },
  {
    "text": "you can get up and running and start clearing the stuff i'm going to show you that in a second you don't need to worry about the setting up the cluster or",
    "start": "751370",
    "end": "757130"
  },
  {
    "text": "tuning it or taking babysitting the machines in the hadoop world how many of",
    "start": "757130",
    "end": "762529"
  },
  {
    "text": "you guys have ever operated a Hadoop cluster did you want to like win a",
    "start": "762529",
    "end": "767750"
  },
  {
    "text": "machine okay that guy this good well you",
    "start": "767750",
    "end": "773690"
  },
  {
    "text": "can do that too the good news is you have root access so you're set so I'm",
    "start": "773690",
    "end": "778730"
  },
  {
    "start": "778000",
    "end": "863000"
  },
  {
    "text": "gonna show you some demos dome so here i am i'm at the Amazon Elastic MapReduce",
    "start": "778730",
    "end": "785600"
  },
  {
    "text": "console many you guys have already seen EMR so this is going to be a bit of a review but you know you came to church",
    "start": "785600",
    "end": "790910"
  },
  {
    "text": "you're going to hear the gospel that's how I see it so here we are we're sitting in on the on the console",
    "start": "790910",
    "end": "798360"
  },
  {
    "text": "it's very simple these are my running clusters here I can go check out the status of them see how many machines are",
    "start": "798360",
    "end": "805709"
  },
  {
    "text": "in it see the bootstrap actions that were deployed on it see that they're running so that's all great now i can",
    "start": "805709",
    "end": "812010"
  },
  {
    "text": "create a cluster 2 and just for simplicity sake i'm going to take my contextual advertising bit here i'm",
    "start": "812010",
    "end": "820079"
  },
  {
    "text": "going to change that handy integration",
    "start": "820079",
    "end": "828750"
  },
  {
    "text": "here",
    "start": "828750",
    "end": "830930"
  },
  {
    "text": "so there we are we have we have our cluster it's all well defined you can see in Amazon in EMR we very rapidly put",
    "start": "838980",
    "end": "848310"
  },
  {
    "text": "out new bit almost monthly now we're actually deploying a new build of Hadoop",
    "start": "848310",
    "end": "853440"
  },
  {
    "text": "in the ecosystem of applications out there to the point where it's actually getting a little tiring they see new stuff always popping up we need to",
    "start": "853440",
    "end": "859769"
  },
  {
    "text": "condense this this menu here make a little year so there's there's rapid adoption of new technologies as they",
    "start": "859769",
    "end": "866790"
  },
  {
    "start": "863000",
    "end": "1146000"
  },
  {
    "text": "come into the ecosystem another area that you will see a lot of innovation and certainly in the last year and going forward and in the coming year is very",
    "start": "866790",
    "end": "873120"
  },
  {
    "text": "very deep integration with s3 and all the capabilities of s3 as they emerge so",
    "start": "873120",
    "end": "878370"
  },
  {
    "text": "a native support for server-side encryption we are pre announcing integration with key management service",
    "start": "878370",
    "end": "884970"
  },
  {
    "text": "which is enables client-side encryption and our implementation will allow you to either use the key management service or",
    "start": "884970",
    "end": "891480"
  },
  {
    "text": "yourself to to manage the keys in a custom implementation that is something that's going to going to be coming up",
    "start": "891480",
    "end": "897630"
  },
  {
    "text": "quickly we introduced a consistent view of s3 so one of the things we're s3 is",
    "start": "897630",
    "end": "903000"
  },
  {
    "text": "sort of troublesome in the Hadoop space is that it's not a file system as much as we try to pretend it is in many cases",
    "start": "903000",
    "end": "909870"
  },
  {
    "text": "it's actually not file system it's a blob store and as such it has these has some problems with doing things like",
    "start": "909870",
    "end": "915720"
  },
  {
    "text": "listings of massive buckets a few billions of keys in there and it also doesn't do a file pens and there's a lot",
    "start": "915720",
    "end": "923370"
  },
  {
    "text": "of things in the ecosystem that want to do a file append so we that's that's where most of our work in the Hadoop",
    "start": "923370",
    "end": "930029"
  },
  {
    "text": "it's actually where we customize it in general we work very hard to keep as",
    "start": "930029",
    "end": "935850"
  },
  {
    "text": "close to Apache the Apache codebase as possible and we've been in the last year we've been pushing an awful lot of our",
    "start": "935850",
    "end": "942089"
  },
  {
    "text": "changes back to open source and as we've gotten more more bandwidth to do that so the our intention and what you can sort",
    "start": "942089",
    "end": "948360"
  },
  {
    "text": "of expect from the EMR team is that when you're using something that says it's city 24 it's adeeb 24 and nothing",
    "start": "948360",
    "end": "954839"
  },
  {
    "text": "nothing fancy in it other than that we've made it work so we're less",
    "start": "954839",
    "end": "959970"
  },
  {
    "text": "interested in trying to be you know authoritative and have some distribution but we're very concerned that the people",
    "start": "959970",
    "end": "966240"
  },
  {
    "text": "who run in in EMR have a seamless experience with with interacting with us three interacting with dynamo",
    "start": "966240",
    "end": "971560"
  },
  {
    "text": "interactive thesis and all the other big data services so I we added also a",
    "start": "971560",
    "end": "978430"
  },
  {
    "text": "feature in recently for consistent viewing so another place where s3 has some difficulty is that it's an",
    "start": "978430",
    "end": "984250"
  },
  {
    "text": "eventually consistent system so the",
    "start": "984250",
    "end": "991540"
  },
  {
    "text": "impact of that is in a MapReduce job if you have something that's that's cascading one job after another I would",
    "start": "991540",
    "end": "998710"
  },
  {
    "text": "let's say i right you know I do some aggregation or I do some fancy thing that's going to convert my logs into a",
    "start": "998710",
    "end": "1004320"
  },
  {
    "text": "format that's going to be useful for a guy downstream a logical operation for an ETL process is going to be one thing",
    "start": "1004320",
    "end": "1010650"
  },
  {
    "text": "and then one step that goes to another step that goes to another step and in a file in a consistent file system or file",
    "start": "1010650",
    "end": "1016560"
  },
  {
    "text": "list that's great in HDFS a design that way in s3 it when you're you know it",
    "start": "1016560",
    "end": "1022560"
  },
  {
    "text": "could in USC's classic it could be the case that you don't get get after put",
    "start": "1022560",
    "end": "1028800"
  },
  {
    "text": "consistency I put it so i put in a file and it doesn't show up and if i did a listing on that directory i wouldn't necessarily have it it's actually not as",
    "start": "1028800",
    "end": "1036449"
  },
  {
    "text": "big of a problem as you might think with just from for you know for in reality people have gotten burned by that and so they historically you've had to do",
    "start": "1036449",
    "end": "1042329"
  },
  {
    "text": "things like man manage a manifest file and things that are just kind of awkward I'm so this feature with a consistent",
    "start": "1042329",
    "end": "1050250"
  },
  {
    "text": "view takes care of that problem we manage an index in DynamoDB on your behalf that checks on every file when",
    "start": "1050250",
    "end": "1058020"
  },
  {
    "text": "it's written and so all the operations that are meaningful in that space all that stuff is kept in DynamoDB and the",
    "start": "1058020",
    "end": "1065010"
  },
  {
    "text": "other side effect of this is that we get very fast listings so that other problem",
    "start": "1065010",
    "end": "1070679"
  },
  {
    "text": "was telling about with the with s3 being a doggone on billions of records or billions of keys coming back because of",
    "start": "1070679",
    "end": "1076410"
  },
  {
    "text": "that integration that we built because that manifest we have we're able to sort of predict where the key space is going",
    "start": "1076410",
    "end": "1082290"
  },
  {
    "text": "to be what the key space is going to work out to be in s3 and so we can provide very fast listing of those",
    "start": "1082290",
    "end": "1087360"
  },
  {
    "text": "directories and at the same time discover new files as they come in there's been a lot of work and with with",
    "start": "1087360",
    "end": "1094770"
  },
  {
    "text": "people that have kind of there was a project many years ago it's kind of died off called s3 be that that took the",
    "start": "1094770",
    "end": "1101100"
  },
  {
    "text": "approach of like just putting the blocks in in s3 and keeping the the name keep the name no doing its job some of",
    "start": "1101100",
    "end": "1108000"
  },
  {
    "text": "the problems that we found with that is that people actually like s3 people want to use s3 because that's where their web",
    "start": "1108000",
    "end": "1113070"
  },
  {
    "text": "servers are dumping their data as we're there bodo client is going to read from all these things so we do an awful lot",
    "start": "1113070",
    "end": "1119160"
  },
  {
    "text": "of work to make sure that s three as it is works very well and you'll see more",
    "start": "1119160",
    "end": "1124800"
  },
  {
    "text": "and more features and focus from our team coming through on that so in the screen I can you can see that I can set",
    "start": "1124800",
    "end": "1131100"
  },
  {
    "text": "up all my machines I can provision the network you know that for VPC and so on",
    "start": "1131100",
    "end": "1137570"
  },
  {
    "text": "and I'm often running and I can go and create my clusters anything else in they",
    "start": "1137570",
    "end": "1143760"
  },
  {
    "text": "are missing so raw Frank so boom three minutes later we're gonna have that I",
    "start": "1143760",
    "end": "1149610"
  },
  {
    "text": "Hadoop so you don't you don't have to go learn Linux and all that stuff you can",
    "start": "1149610",
    "end": "1155970"
  },
  {
    "text": "actually just kept in writing so I cool we're going to do that I'm going to skip over to a something so which is the",
    "start": "1155970",
    "end": "1162750"
  },
  {
    "text": "clustered I started up maybe a couple days ago in preparation for this talk so",
    "start": "1162750",
    "end": "1167940"
  },
  {
    "text": "last i think its last friday we released hue hue is an open source project that",
    "start": "1167940",
    "end": "1175800"
  },
  {
    "text": "is the hadoop user interface it provides a GUI for hive and pig and meta storing and show you those features we're very",
    "start": "1175800",
    "end": "1181830"
  },
  {
    "text": "excited to announce that and some of the things we added in this I'll show you in a second with with s3 integration the",
    "start": "1181830",
    "end": "1187530"
  },
  {
    "text": "thing that that I'm site very excited about with you is that previously I've",
    "start": "1187530",
    "end": "1193620"
  },
  {
    "text": "lost personally an awful awful lot of time trying to figure out like all SSH into the machines and going there and",
    "start": "1193620",
    "end": "1200070"
  },
  {
    "text": "just all the goo of the interfaces of Hadoop you know be it through hive or",
    "start": "1200070",
    "end": "1205920"
  },
  {
    "text": "pig or what have you it's actually kind of a crap experience to have to go ssh into things now you have this very very",
    "start": "1205920",
    "end": "1212730"
  },
  {
    "text": "intuitive almost like sequel server view",
    "start": "1212730",
    "end": "1217980"
  },
  {
    "text": "where you can actually just write the sensible queries in it so the basic Hugh",
    "start": "1217980",
    "end": "1224730"
  },
  {
    "text": "experience before I get ahead of myself is as you would probably expect a UI of",
    "start": "1224730",
    "end": "1233130"
  },
  {
    "text": "dupe to be what when you when you jump into it and you launch it for the first time as a user from EMR you're going to",
    "start": "1233130",
    "end": "1238560"
  },
  {
    "text": "find samples that will be handy for you as an AWS user and we also think that this is",
    "start": "1238560",
    "end": "1244490"
  },
  {
    "text": "a good way to kind of train people on how to use the tool so if you're not very familiar with with high of itself",
    "start": "1244490",
    "end": "1250630"
  },
  {
    "text": "we can help you understand what hive is doing and it's notions by giving you",
    "start": "1250630",
    "end": "1257360"
  },
  {
    "text": "some sample queries that might actually you might actually want to query so in this case I think I'm looking at the cloud cloud front logs and if I want to",
    "start": "1257360",
    "end": "1263810"
  },
  {
    "text": "do some sort of sort of analysis on it you can see it's very simple I signed it into Hugh I have my sample here i'm",
    "start": "1263810",
    "end": "1270920"
  },
  {
    "text": "going to create a table for cloud cloud front logs i'm declaring those types",
    "start": "1270920",
    "end": "1277030"
  },
  {
    "text": "just like you would columns in a database I'm informing it how that's",
    "start": "1277030",
    "end": "1284540"
  },
  {
    "text": "stored so I'm doing a regular expression to actually extract these these columns and then I'm giving it and pointing it",
    "start": "1284540",
    "end": "1290660"
  },
  {
    "text": "to the location in s3 so go ahead and run that",
    "start": "1290660",
    "end": "1297669"
  },
  {
    "text": "and now that that is created see Club",
    "start": "1301309",
    "end": "1308340"
  },
  {
    "text": "her aunts over there great we can now do a select against that guy it's a dupe so",
    "start": "1308340",
    "end": "1317460"
  },
  {
    "text": "he's going to spit up as his jobs he's going to look at all the files that are",
    "start": "1317460",
    "end": "1322529"
  },
  {
    "text": "there he's going to calculate his splits he's gonna figure out who needs what data I and then he's going to go start",
    "start": "1322529",
    "end": "1328020"
  },
  {
    "text": "executing that that job for me and I think in these samples are generally fairly small and data sets just so you",
    "start": "1328020",
    "end": "1335760"
  },
  {
    "text": "don't get bummed out with with all the work in it but in this one of the big problems that we found people have when",
    "start": "1335760",
    "end": "1341610"
  },
  {
    "text": "they try to use Hadoop is that it's really painful to debug Hadoop if you",
    "start": "1341610",
    "end": "1346799"
  },
  {
    "text": "need to go get to your logs if you need to figure out what's happening the point of the system is that it's going to",
    "start": "1346799",
    "end": "1352200"
  },
  {
    "text": "distribute your work across many nodes so like if you're the guy who has to go find those logs is sucks so I within",
    "start": "1352200",
    "end": "1362279"
  },
  {
    "text": "Hugh there's I actually it went past my screen here but I'm having here you can",
    "start": "1362279",
    "end": "1369360"
  },
  {
    "text": "see handy links and here to actually get you to all the the meaningful logs as they occur so if you get an error you",
    "start": "1369360",
    "end": "1374970"
  },
  {
    "text": "can actually find it and if there's a specific error log it'll actually link to it and you can pull it up in your browser you see if I got one of those",
    "start": "1374970",
    "end": "1381240"
  },
  {
    "text": "guys anyway I and then of course your",
    "start": "1381240",
    "end": "1390899"
  },
  {
    "text": "results as you would expect you get them you're getting back and you can you can have them handy and work with them and",
    "start": "1390899",
    "end": "1396090"
  },
  {
    "text": "there's some some primitive charting in there if you want it takes them take some dates and put in there he's",
    "start": "1396090",
    "end": "1402090"
  },
  {
    "text": "laughing so clearly doesn't think that highly of that okay so now i'm going to",
    "start": "1402090",
    "end": "1407370"
  },
  {
    "text": "show you pig and some of the functionality and that again we'll go back to our samples here",
    "start": "1407370",
    "end": "1416240"
  },
  {
    "text": "so you can see pig is a different language it's actually meant for etl itself it's not it's not meant to be",
    "start": "1419250",
    "end": "1425160"
  },
  {
    "text": "sort of an analytical or report generator thing it's actually meant to move and transform data so it has a different language and different syntax",
    "start": "1425160",
    "end": "1431040"
  },
  {
    "text": "and so on so I'm actually I think I'm good to just run this guy in this one what we're doing is we're looking at",
    "start": "1431040",
    "end": "1436500"
  },
  {
    "text": "apache logs and we're going to generate some statistics off it I think I'm looking at maybe browsers or doing it by",
    "start": "1436500",
    "end": "1443730"
  },
  {
    "text": "time but Nick is this go-ahead run it so the same the same sort of user interface",
    "start": "1443730",
    "end": "1449040"
  },
  {
    "text": "that you had with with hive which was a sequel environment where you wanted columns and rows and a structured query",
    "start": "1449040",
    "end": "1455010"
  },
  {
    "text": "this is much more the style of an IDE where you want to actually debug something when you're writing it you get handy things like autocomplete when you",
    "start": "1455010",
    "end": "1462330"
  },
  {
    "text": "reference files and so on so again i'm streaming back my logs as they come through this is actually looking at a",
    "start": "1462330",
    "end": "1469800"
  },
  {
    "text": "slightly larger data sets oh I'm will continue on in this talk um I'm going to",
    "start": "1469800",
    "end": "1477720"
  },
  {
    "text": "go over to the file browser really quick so normally i cue is very focused as",
    "start": "1477720",
    "end": "1483480"
  },
  {
    "text": "Hadoop is in general on it's an internally right it thinks it's a cluster in a data center somewhere and",
    "start": "1483480",
    "end": "1489990"
  },
  {
    "text": "that's great but we you know Mr says it's not you know we're we're your cluster in the cloud and that means",
    "start": "1489990",
    "end": "1495900"
  },
  {
    "text": "different things so one of the things that we we put into it is actually a s3 file browser and we're actually kind of",
    "start": "1495900",
    "end": "1504030"
  },
  {
    "text": "proud of this I think arguably this thing is a better than what you you",
    "start": "1504030",
    "end": "1509700"
  },
  {
    "text": "might find in the s3 console you I in some ways I say that because see what I",
    "start": "1509700",
    "end": "1515460"
  },
  {
    "text": "got here in my logs I'm going to try and find one that's relatively small",
    "start": "1515460",
    "end": "1522620"
  },
  {
    "text": "so I can read I can read the files directly in here and I can actually",
    "start": "1531149",
    "end": "1536700"
  },
  {
    "text": "interact with these files as though it's an interactive web console for a file system so you'll you'll and we will be",
    "start": "1536700",
    "end": "1543629"
  },
  {
    "text": "continuing to add more and more capabilities to this including you'll notice that we have edit file in here so",
    "start": "1543629",
    "end": "1548789"
  },
  {
    "text": "I one of the guys on the team proposed that we might actually be people might be spinning up Hugh just so they can",
    "start": "1548789",
    "end": "1554879"
  },
  {
    "text": "actually interact with this week because the browser here so that's pretty cool I think also so another thing that you",
    "start": "1554879",
    "end": "1562259"
  },
  {
    "text": "might be concerned about in your Hadoop environment is job history the Hadoop",
    "start": "1562259",
    "end": "1568889"
  },
  {
    "text": "tooling even in Hadoop to has been good improvements in the UX and things but Hugh does a great job of putting all",
    "start": "1568889",
    "end": "1576239"
  },
  {
    "text": "that stuff in a sensible manner so you can actually in an attractive you I so you can actually go and figure out your your jobs the status of the jobs and and",
    "start": "1576239",
    "end": "1582779"
  },
  {
    "text": "what have you so you can you can dive into those things",
    "start": "1582779",
    "end": "1587450"
  },
  {
    "start": "1592000",
    "end": "1724000"
  },
  {
    "text": "so i can change pace a little bit now so I've talked an awful lot about how to use EMR as your Hadoop infrastructure",
    "start": "1593440",
    "end": "1601080"
  },
  {
    "text": "about s 3 s 3 as your storage system I and now I want to I want to talk to you",
    "start": "1601080",
    "end": "1608470"
  },
  {
    "text": "guys about emerging capabilities in you're using EMR as your data warehouse",
    "start": "1608470",
    "end": "1613600"
  },
  {
    "text": "your data warehouse it can also read from from real-time screams as well so",
    "start": "1613600",
    "end": "1619379"
  },
  {
    "text": "early in the year when Kinesis was launched last year EMR put out a",
    "start": "1619379",
    "end": "1627460"
  },
  {
    "text": "connector that makes it so you have native connectivity between all of the food because of some applications and",
    "start": "1627460",
    "end": "1632679"
  },
  {
    "text": "Kinesis as well so I'm going to introduce you to to that and show you a demo of it but just to kind of to talk",
    "start": "1632679",
    "end": "1639159"
  },
  {
    "text": "through this and put in the context of the heap ecosystem I'm gonna talk for a second so on the left-hand side you have",
    "start": "1639159",
    "end": "1645190"
  },
  {
    "text": "a this is the data flow a typical data flow that you would see in a continuous processing engine or in real time stream",
    "start": "1645190",
    "end": "1651309"
  },
  {
    "text": "on left hand side you have clients or sensors things that are going to be",
    "start": "1651309",
    "end": "1657129"
  },
  {
    "text": "emitting events or facts into your into your ultimately what's your data warehouse you will typically have",
    "start": "1657129",
    "end": "1663669"
  },
  {
    "text": "something that's a recording service so there's going to be some endpoint that the clients who are emitting those",
    "start": "1663669",
    "end": "1669100"
  },
  {
    "text": "things have consistently to go to go drop off that data within that infrastructure there has to be someone",
    "start": "1669100",
    "end": "1674559"
  },
  {
    "text": "who's going to take that information because time in physics is different in two different entities so it has to has",
    "start": "1674559",
    "end": "1680919"
  },
  {
    "text": "to be an authoritative source for aggregating and sequencing data so that responsibilities there after that you",
    "start": "1680919",
    "end": "1686559"
  },
  {
    "text": "have the opportunity once its sequence to do something like a continuous to inject something like a continuous processor Apache storm I apache spark",
    "start": "1686559",
    "end": "1695350"
  },
  {
    "text": "streaming all very good tools for this or even something like Esper you know a complex event processor or some sort",
    "start": "1695350",
    "end": "1701789"
  },
  {
    "text": "after that so that opportunities there it's not necessarily the guy who's going to put in into your data warehouse but you would do it right after this this",
    "start": "1701789",
    "end": "1708759"
  },
  {
    "text": "aggregation sequence if you want to get those real time streams then the data is ultimately stored in your data",
    "start": "1708759",
    "end": "1714730"
  },
  {
    "text": "warehouses persisted somewhere that is reliable and is going to be permanently accessible and downstream from that",
    "start": "1714730",
    "end": "1720129"
  },
  {
    "text": "you're going to have your analytics so tools and reports and and these are things in the soup ecosystem the the",
    "start": "1720129",
    "end": "1726009"
  },
  {
    "start": "1724000",
    "end": "1764000"
  },
  {
    "text": "tools that are out there looks like this on the left hand side you have your your kit that you write in there's",
    "start": "1726009",
    "end": "1731350"
  },
  {
    "text": "nothing particularly interesting about that but in the recorder aggregator section you have things like Kafka and",
    "start": "1731350",
    "end": "1737889"
  },
  {
    "text": "scribe and flume and they have their own features and I have their own attributes of scale that that they that they work",
    "start": "1737889",
    "end": "1745330"
  },
  {
    "text": "in and then when you get to the right hand side in the Hadoop ecosystem there are things like storm as I mention before spark and as you push further",
    "start": "1745330",
    "end": "1752379"
  },
  {
    "text": "further over there you find the canonical and applications like hive and",
    "start": "1752379",
    "end": "1759249"
  },
  {
    "text": "pig and cascading and mahou and so on so",
    "start": "1759249",
    "end": "1764639"
  },
  {
    "start": "1764000",
    "end": "1785000"
  },
  {
    "text": "amazon kinesis is a managed service that scales elastically for real-time processing and streaming data customers",
    "start": "1764639",
    "end": "1771100"
  },
  {
    "text": "can write large streams of records from any client over a standard web accessible API the service ensures",
    "start": "1771100",
    "end": "1777249"
  },
  {
    "text": "monotonically increasing sequential ordering of Records as a stream in and it makes it available to downstream",
    "start": "1777249",
    "end": "1783239"
  },
  {
    "text": "systems for processing so if you look at that the ecosystem I had a second ago",
    "start": "1783239",
    "end": "1789279"
  },
  {
    "start": "1785000",
    "end": "1828000"
  },
  {
    "text": "with all those those other tools in there it's kind of a soup if you look at this I from an from a hosted perspective",
    "start": "1789279",
    "end": "1797080"
  },
  {
    "text": "to just reduce reduce your moving parts in your your infrastructure you still",
    "start": "1797080",
    "end": "1803259"
  },
  {
    "text": "have this the notion of a client that has to write into Kinesis but the team made it really easy to do that we were",
    "start": "1803259",
    "end": "1809080"
  },
  {
    "text": "in a Pender for log for day so you can just actually stream your messages from log for day directly in the Kinesis you",
    "start": "1809080",
    "end": "1814899"
  },
  {
    "text": "have to think about the client implementation of it necessarily Kinesis",
    "start": "1814899",
    "end": "1820299"
  },
  {
    "text": "then is your streaming data repository and downstream from that amazon EMR with with the diversity of tools that are",
    "start": "1820299",
    "end": "1825519"
  },
  {
    "text": "available in it can process your data so in practice it might look something like this you have a dude in a fancy suit",
    "start": "1825519",
    "end": "1831700"
  },
  {
    "start": "1828000",
    "end": "1907000"
  },
  {
    "text": "like me who he's he writes an application may be hosting elastic",
    "start": "1831700",
    "end": "1837190"
  },
  {
    "text": "Beanstalk who admits his data through through log4j its pushed to amazon kinesis immediately then in the purpose",
    "start": "1837190",
    "end": "1845830"
  },
  {
    "text": "for the purpose of analytics and you want when you want to aggregate these things using Amazon Elastic MapReduce you can actually join from any number of",
    "start": "1845830",
    "end": "1853210"
  },
  {
    "text": "different data sources for example in this case DynamoDB as well as Kinesis join that data and then ultimately persist it to s3 or do some sort of",
    "start": "1853210",
    "end": "1860019"
  },
  {
    "text": "interesting processing that that you might want there it'sit's interesting or it's",
    "start": "1860019",
    "end": "1865540"
  },
  {
    "text": "important to note that there's there's many different implementations in the Hadoop ecosystem for interacting with",
    "start": "1865540",
    "end": "1871980"
  },
  {
    "text": "streaming streaming kits the implementation that we have with between",
    "start": "1871980",
    "end": "1879370"
  },
  {
    "text": "Amazon Elastic MapReduce and cases is there's two sides to it one is the the input format which opens it up for",
    "start": "1879370",
    "end": "1886480"
  },
  {
    "text": "processing in any of the Hadoop ecosystem app so cascading pig and so on",
    "start": "1886480",
    "end": "1892230"
  },
  {
    "text": "and then there's there's a discrete implementation inside of a patchy storm",
    "start": "1892230",
    "end": "1898690"
  },
  {
    "text": "itself sorry I've had spark streaming itself that actually interacts with Kinesis you can get much faster",
    "start": "1898690",
    "end": "1904750"
  },
  {
    "text": "iterations on it so this putting this into code what this would look like is I",
    "start": "1904750",
    "end": "1910180"
  },
  {
    "start": "1907000",
    "end": "2393000"
  },
  {
    "text": "have my am I have my log4j pender just writing directly to canisius and then",
    "start": "1910180",
    "end": "1915850"
  },
  {
    "text": "the other end I write a sequel query so",
    "start": "1915850",
    "end": "1922150"
  },
  {
    "text": "I'm going to do down now hmm",
    "start": "1922150",
    "end": "1931840"
  },
  {
    "text": "I can't see that all right so you see right here on the screen is I i have an",
    "start": "1931840",
    "end": "1939429"
  },
  {
    "text": "application that is using their guys",
    "start": "1939429",
    "end": "1947250"
  },
  {
    "text": "know",
    "start": "1951419",
    "end": "1954419"
  },
  {
    "text": "semi",
    "start": "1961890",
    "end": "1964640"
  },
  {
    "text": "ok in this screen right here I have an application that is specifically just",
    "start": "1977600",
    "end": "1984690"
  },
  {
    "text": "pushing data to amazon kinesis yeah",
    "start": "1984690",
    "end": "1993750"
  },
  {
    "text": "that's it so that this code is actually available on github right now you if you are interested in seeing that you can",
    "start": "1993750",
    "end": "1998790"
  },
  {
    "text": "pull up this application it'll read files and it'll directly stream it on i'm just i'm pointing this out to kind of show the the end-to-end scenario here",
    "start": "1998790",
    "end": "2005390"
  },
  {
    "text": "as i go to as i go into my query editor i can i searched my now that i am in in",
    "start": "2005390",
    "end": "2019510"
  },
  {
    "text": "hive and in this fancy you I I can",
    "start": "2019510",
    "end": "2024800"
  },
  {
    "text": "define a table against Kinesis just like I did against the s3 table so you can see in this where I before I created",
    "start": "2024800",
    "end": "2032150"
  },
  {
    "text": "those those columns as though there was against a file system it's the exact same definition of columns that I have",
    "start": "2032150",
    "end": "2038410"
  },
  {
    "text": "when I'm interacting through this implementation anyway what I'm interacting with Kinesis so we can we",
    "start": "2038410",
    "end": "2043550"
  },
  {
    "text": "take away all that that overhead they're the only distinction here is that we're saying that it's actually stored by the",
    "start": "2043550",
    "end": "2049550"
  },
  {
    "text": "amazon kinesis storage handler so after you have that in place which I do you",
    "start": "2049550",
    "end": "2056090"
  },
  {
    "text": "can do a direct query against it",
    "start": "2056090",
    "end": "2060070"
  },
  {
    "text": "that good typos good okay so just like I",
    "start": "2083629",
    "end": "2091519"
  },
  {
    "text": "had just like I had data that was coming back from a query a file and s3 I now",
    "start": "2091519",
    "end": "2097849"
  },
  {
    "text": "will have data coming back results directly from Kinesis so if you use",
    "start": "2097849",
    "end": "2105680"
  },
  {
    "text": "log4j or use any of these any of these other messaging systems or if you just want to write directly to Kinesis on your own the overhead of doing",
    "start": "2105680",
    "end": "2113210"
  },
  {
    "text": "end-to-end processing in real time fashion is very light that really is all that you have to do right there",
    "start": "2113210",
    "end": "2119000"
  },
  {
    "text": "hopefully that your your monitor doesn't crush on you when you you try to do it",
    "start": "2119000",
    "end": "2124480"
  },
  {
    "text": "now we will go to I'm going to change base again and I'm going to show you i",
    "start": "2125380",
    "end": "2132640"
  },
  {
    "text": "was talking earlier about was talking",
    "start": "2132640",
    "end": "2137690"
  },
  {
    "text": "earlier about about Amazon Elastic MapReduce being a hosting and diversity",
    "start": "2137690",
    "end": "2144259"
  },
  {
    "text": "the diversity of the open source Big Data technologies sure we are early adopters of those technologies we",
    "start": "2144259",
    "end": "2149890"
  },
  {
    "text": "initially sort of announced interaction and support for for spark almost a year",
    "start": "2149890",
    "end": "2154970"
  },
  {
    "text": "ago with an article that we did we are continuing with that and we'll make it will expose on the website for everyone",
    "start": "2154970",
    "end": "2161420"
  },
  {
    "text": "to do very quickly but within EMR you can launch spark clusters get them up",
    "start": "2161420",
    "end": "2169640"
  },
  {
    "text": "and running and start experiment at that and we have customers today who are we're doing that with great success so",
    "start": "2169640",
    "end": "2175789"
  },
  {
    "text": "within this I have a cluster that I defined herein EMR that I brought up I",
    "start": "2175789",
    "end": "2182140"
  },
  {
    "text": "think I'm looking at it right now",
    "start": "2182140",
    "end": "2185828"
  },
  {
    "text": "so very simple we have a bootstrap action that actually goes and installs a spark on it and then from there you can",
    "start": "2191390",
    "end": "2197210"
  },
  {
    "text": "ssh to the box as i am here and you can start doing processing against it i want",
    "start": "2197210",
    "end": "2203930"
  },
  {
    "text": "to show you a demo of spark sequel spark",
    "start": "2203930",
    "end": "2211760"
  },
  {
    "text": "sequel is a sort of analogous to hive in the MapReduce world in that it is taking",
    "start": "2211760",
    "end": "2217400"
  },
  {
    "text": "it is taking sequel syntax that that you might write and it is then converting that and doing code generation to create",
    "start": "2217400",
    "end": "2223609"
  },
  {
    "text": "the appropriate code for execution and spark so here I am I have a query that",
    "start": "2223609",
    "end": "2230359"
  },
  {
    "text": "I'm going to run it is pointed at Wikipedia statistics data directly on s3",
    "start": "2230359",
    "end": "2236260"
  },
  {
    "text": "so again the point of EMR being a warehouse is you don't have to take that",
    "start": "2236260",
    "end": "2241880"
  },
  {
    "text": "data and do all this massive conversion to go Finnick lee put it into another",
    "start": "2241880",
    "end": "2247069"
  },
  {
    "text": "system you can actually take it as it is and start processing it directly did I get an error what happened",
    "start": "2247069",
    "end": "2254920"
  },
  {
    "text": "network I think no it didn't work all right let's go",
    "start": "2260690",
    "end": "2267829"
  },
  {
    "text": "back um and then similarly to that same point of new tools that are emerging we",
    "start": "2267829",
    "end": "2280190"
  },
  {
    "text": "have facebook presto Facebook presto is a very exciting new technology to come out in the Hadoop ecosystem again I was",
    "start": "2280190",
    "end": "2287569"
  },
  {
    "text": "talking to you guys earlier about having the ability to break off your storage your definition of your data how you",
    "start": "2287569",
    "end": "2293509"
  },
  {
    "text": "interpret that and where it's stored in where it's executed in elastic MapReduce",
    "start": "2293509",
    "end": "2299210"
  },
  {
    "text": "when you were running facebook presto and use it against us three we have sort of the perfect confluence of technologies there it's still it is a",
    "start": "2299210",
    "end": "2306950"
  },
  {
    "text": "are DBMS like it is it's not a funny thing where it's going to do in code generation and fancy stuff it's purely a",
    "start": "2306950",
    "end": "2312710"
  },
  {
    "text": "machine for for doing low latency crewing it's an in-memory database and it works well with the Hadoop ecosystem",
    "start": "2312710",
    "end": "2318950"
  },
  {
    "text": "of applications specifically it works well against the hive meta store so where I have a table defined and high if",
    "start": "2318950",
    "end": "2325220"
  },
  {
    "text": "I just did in in in hue as you saw a minute ago I come I come into Facebook",
    "start": "2325220",
    "end": "2331549"
  },
  {
    "text": "presto pointing directly at s3 I can I have a cluster up and running and it's it's able to query against that so a",
    "start": "2331549",
    "end": "2337069"
  },
  {
    "text": "query that takes in in hive the same query will take about five minutes",
    "start": "2337069",
    "end": "2342980"
  },
  {
    "text": "partially because it has to go do the code generation has to schedule it with an engine and then execute that in",
    "start": "2342980",
    "end": "2349339"
  },
  {
    "text": "presto that's the best a very that's a very quick very quick process also it is an in-memory system so there's the",
    "start": "2349339",
    "end": "2357259"
  },
  {
    "text": "process of actually streaming the data into the nose and then after that everything sitting in memory and resident in that so we have customers",
    "start": "2357259",
    "end": "2363349"
  },
  {
    "text": "that are using facebook presto right now and having good success with it the the",
    "start": "2363349",
    "end": "2368569"
  },
  {
    "text": "key point being that they can leave their data directly in s3 without having to move it around or transform it and put it into some other technology",
    "start": "2368569",
    "end": "2377558"
  },
  {
    "text": "so in Amazon Elastic MapReduce",
    "start": "2386730",
    "end": "2390230"
  },
  {
    "start": "2393000",
    "end": "2525000"
  },
  {
    "text": "you can leave your clusters up and running one of the another sort of conception that people have about elastic mapreduce is I was purely just a",
    "start": "2394540",
    "end": "2401110"
  },
  {
    "text": "job flow engine and it is a wonderful job flow engine and you get a lot of power out of having a job flow engine if",
    "start": "2401110",
    "end": "2406120"
  },
  {
    "text": "you if that's the how you want to interact with it the idea with the job flow and on the right side there is that",
    "start": "2406120",
    "end": "2411580"
  },
  {
    "text": "I have some predictable work that I want to get done every night it's my ETL it may be coming from Kinesis and may be",
    "start": "2411580",
    "end": "2416890"
  },
  {
    "text": "coming from kinesis not every night but you like every 15 minutes or something got you but it's predictable you know",
    "start": "2416890",
    "end": "2423280"
  },
  {
    "text": "that it's going to be there and and so you want to schedule that guy and continue to run him elastic mapreduce will spin up the cluster it will manage",
    "start": "2423280",
    "end": "2429910"
  },
  {
    "text": "the lifecycle the cluster it will get your job done for you if machines go down it will replace those machines and",
    "start": "2429910",
    "end": "2435160"
  },
  {
    "text": "it will it will drive that job to completion so it's very powerful in that use case many of our customers beyond",
    "start": "2435160",
    "end": "2442960"
  },
  {
    "text": "that actually want to interact with to do they have infrastructure that has a known or named endpoint that 4shared as",
    "start": "2442960",
    "end": "2449260"
  },
  {
    "text": "a shared business resource something like Facebook presto is there that they want up all the time and so in that case",
    "start": "2449260",
    "end": "2456940"
  },
  {
    "text": "people will just like they would in a on premise installation and they'll spin up",
    "start": "2456940",
    "end": "2462940"
  },
  {
    "text": "an elastic MapReduce cluster and leave it up and running for a long time um the",
    "start": "2462940",
    "end": "2468400"
  },
  {
    "text": "thing that know about that that's really handy is you should still consider that you can consider those clusters",
    "start": "2468400",
    "end": "2474520"
  },
  {
    "text": "long-lived and they are a known resource and so on but the other thing that's really handy there is that when you want",
    "start": "2474520",
    "end": "2479650"
  },
  {
    "text": "to do deployments to your cluster like let's say you want to take a patch to HDFS who you want to do you want to",
    "start": "2479650",
    "end": "2484780"
  },
  {
    "text": "deploy some configuration change you can I make that you can actually spin up a secondary cluster right next to that and",
    "start": "2484780",
    "end": "2491800"
  },
  {
    "text": "you can to kind of test out your new cluster you can move your traffic over",
    "start": "2491800",
    "end": "2497620"
  },
  {
    "text": "there sort of gracefully and as as the traffic moves over and you know that that environment is really stable you",
    "start": "2497620",
    "end": "2503110"
  },
  {
    "text": "can actually shut down your old one but netflix calls this their red black push and they do it in there and their",
    "start": "2503110",
    "end": "2509950"
  },
  {
    "text": "business they've written pretty extensively about it that's that's a very handy approach because you it's just like a load it's like a",
    "start": "2509950",
    "end": "2516540"
  },
  {
    "text": "conceptually like a load balancer or something that you can divert traffic from one place to another and remain and",
    "start": "2516540",
    "end": "2522940"
  },
  {
    "text": "continue working without interruption amazon EMR also integrates with",
    "start": "2522940",
    "end": "2528610"
  },
  {
    "start": "2525000",
    "end": "2558000"
  },
  {
    "text": "your traditional bi tools we also support other distributions math are is",
    "start": "2528610",
    "end": "2536200"
  },
  {
    "text": "a great example of that map are as a partner of ours and customers who might be running map are in their data center",
    "start": "2536200",
    "end": "2542680"
  },
  {
    "text": "who want to move to the cloud can actually use it can actually deploy clusters with the map our distribution itself i will also the large analytics",
    "start": "2542680",
    "end": "2555220"
  },
  {
    "text": "inhibit ecosystem applications I'll run with EMR we recently announced support",
    "start": "2555220",
    "end": "2561280"
  },
  {
    "start": "2558000",
    "end": "2574000"
  },
  {
    "text": "for tableau um we released our odbc and",
    "start": "2561280",
    "end": "2566710"
  },
  {
    "text": "jdbc drivers and on our big data blog you guys can find an article on how to directly connect tab blow to elastic",
    "start": "2566710",
    "end": "2573340"
  },
  {
    "text": "mapreduce we also recently announced support for splunk specifically hunk",
    "start": "2573340",
    "end": "2581130"
  },
  {
    "start": "2574000",
    "end": "2587000"
  },
  {
    "text": "customers can use it can deploy hunk and have it pointed directly at EMR customers to interact with that and",
    "start": "2581130",
    "end": "2587760"
  },
  {
    "text": "today we are announcing looker support with looker if you go to EMR lucre com",
    "start": "2587760",
    "end": "2594490"
  },
  {
    "text": "you will see a demo you will have a demo environment we can actually interact with looker as it works with impala on",
    "start": "2594490",
    "end": "2601330"
  },
  {
    "text": "an EMR cluster emaar is a flexible and",
    "start": "2601330",
    "end": "2609220"
  },
  {
    "text": "its cost effective as with the rest of the the ec2 environment and you're able",
    "start": "2609220",
    "end": "2615880"
  },
  {
    "text": "to leverage the ec2 pricing models to really take advantage of scaling your",
    "start": "2615880",
    "end": "2621610"
  },
  {
    "text": "data warehouse so there is the traditional on-demand pricing that you can get it's very intuitive you can also",
    "start": "2621610",
    "end": "2629680"
  },
  {
    "text": "if you know that you you are going to be doing repeated work and that's and you can schedule that you can budget it then",
    "start": "2629680",
    "end": "2635410"
  },
  {
    "text": "it often makes sense for you to buy reserved instances and that can dramatically reduce your price when when",
    "start": "2635410",
    "end": "2640780"
  },
  {
    "text": "interacting where your day warehouse there and the other thing that a lot of customers are a feature of the elastic",
    "start": "2640780",
    "end": "2646420"
  },
  {
    "text": "mapreduce is that we support spot instances despite instances in ec two",
    "start": "2646420",
    "end": "2652360"
  },
  {
    "text": "are actually kind of troublesome if it's great because you can get them for pennies on the dollar people would people save a heck of a lot of money",
    "start": "2652360",
    "end": "2658780"
  },
  {
    "text": "using spot instances the problem is that you have to write your applications in a way that they can fail the you know",
    "start": "2658780",
    "end": "2665170"
  },
  {
    "text": "the instance can be reclaimed from you at any moment if the if the spot price",
    "start": "2665170",
    "end": "2670300"
  },
  {
    "text": "goes above that and in the system wants that resource back so you have to get this amazing benefit of price you have",
    "start": "2670300",
    "end": "2676810"
  },
  {
    "text": "to write your applications really cleverly it turns out that Hadoop is already written that way it's very pessimistic it doesn't trust anything if",
    "start": "2676810",
    "end": "2683200"
  },
  {
    "text": "the jobs taking too long they'll start up a job on another another machine in a process that calls speculative execution but in general the the whole idea of",
    "start": "2683200",
    "end": "2690790"
  },
  {
    "text": "distributed computing fits really well in this model where you can take a problem break it up go through out a note if it dies it's fine i'm going to",
    "start": "2690790",
    "end": "2696640"
  },
  {
    "text": "replace it with another node and or take that job and scheduled on another node so mr supports spa instances in a",
    "start": "2696640",
    "end": "2704830"
  },
  {
    "text": "cluster and best practice here is don't ever use spot for your master node please don't ever do that it's very",
    "start": "2704830",
    "end": "2712840"
  },
  {
    "text": "destructive and it doesn't doesn't it's not good but so don't don't do that but",
    "start": "2712840",
    "end": "2719140"
  },
  {
    "text": "I typically customers will buy reserved instances to kind of handle their their",
    "start": "2719140",
    "end": "2726790"
  },
  {
    "text": "traditional load and like think of a you know on the worst day on a rainy day what is it going to take to get this job",
    "start": "2726790",
    "end": "2733000"
  },
  {
    "text": "done and by reserved instances appropriately because you can reduce your price is quite a bit when when operating a warehouse but then they will",
    "start": "2733000",
    "end": "2740560"
  },
  {
    "text": "often augment their their clusters quite considerably you know half or more of their instances with spa defenses an EMR",
    "start": "2740560",
    "end": "2748570"
  },
  {
    "text": "will actually manage the lifecycle of those so if they're reclaimed by the system it will assuming that your",
    "start": "2748570",
    "end": "2754210"
  },
  {
    "text": "pricing is still in there you can actually spin this up so and you'll see more features coming out to support that",
    "start": "2754210",
    "end": "2760810"
  },
  {
    "text": "as it goes so Amazon EMR is set up for security the features that are as you",
    "start": "2760810",
    "end": "2771310"
  },
  {
    "start": "2761000",
    "end": "2824000"
  },
  {
    "text": "look at EMR it really is built to be an environment that is it can be locked down through AP is that is set up",
    "start": "2771310",
    "end": "2777220"
  },
  {
    "text": "already for network isolation through V PCs and through which is a logical",
    "start": "2777220",
    "end": "2782650"
  },
  {
    "text": "isolated network that you define so just on a network and topology level you can use the it's already set up for first",
    "start": "2782650",
    "end": "2790870"
  },
  {
    "text": "wrong security we also support roles so any interaction that you want to do api is interact with us three the data",
    "start": "2790870",
    "end": "2797340"
  },
  {
    "text": "warehouse EMR supports that additionally we are we are pre announcing that the",
    "start": "2797340",
    "end": "2802710"
  },
  {
    "text": "support with about a client-side encryption through KMS and also a custom so features that we already support in",
    "start": "2802710",
    "end": "2809490"
  },
  {
    "text": "EMR fsr three file system is a support for server-side encryptions we'll be",
    "start": "2809490",
    "end": "2816390"
  },
  {
    "text": "adding client-side encryption as well how we doing on time I'm sorry I don't have a clock up here we're done okay all",
    "start": "2816390",
    "end": "2825180"
  },
  {
    "start": "2824000",
    "end": "2853000"
  },
  {
    "text": "right he gave me this which is it means get out so that's good so get started",
    "start": "2825180",
    "end": "2830520"
  },
  {
    "text": "today using MRI also check out our big data blog you'll find a lot of very interesting articles on there how to use are on Amazon Elastic MapReduce how to",
    "start": "2830520",
    "end": "2837780"
  },
  {
    "text": "interact with Kinesis how to do visualization through tableau and how did it configure and on your environment",
    "start": "2837780",
    "end": "2842790"
  },
  {
    "text": "through bootstrap actions and many many more thank you guys for for spending time with meeting I'll feel",
    "start": "2842790",
    "end": "2848720"
  }
]
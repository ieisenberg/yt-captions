[
  {
    "text": "octorai is a compute service that makes",
    "start": "60",
    "end": "2340"
  },
  {
    "text": "it easy for developers to run tune and",
    "start": "2340",
    "end": "4980"
  },
  {
    "text": "scale generative AI models",
    "start": "4980",
    "end": "7140"
  },
  {
    "text": "through octo AI you get access to a",
    "start": "7140",
    "end": "9420"
  },
  {
    "text": "library of the fastest and most cost",
    "start": "9420",
    "end": "11460"
  },
  {
    "text": "effective open source Foundation models",
    "start": "11460",
    "end": "13380"
  },
  {
    "text": "available to developers today including",
    "start": "13380",
    "end": "15960"
  },
  {
    "text": "the fastest stable diffusion endpoint in",
    "start": "15960",
    "end": "17699"
  },
  {
    "text": "the market",
    "start": "17699",
    "end": "18600"
  },
  {
    "text": "and the most affordable way to run the",
    "start": "18600",
    "end": "20400"
  },
  {
    "text": "65 billion parameter llama language",
    "start": "20400",
    "end": "22260"
  },
  {
    "text": "model developers can build their",
    "start": "22260",
    "end": "24180"
  },
  {
    "text": "generative AI a powered application with",
    "start": "24180",
    "end": "26400"
  },
  {
    "text": "the assurance that they have an easy and",
    "start": "26400",
    "end": "28140"
  },
  {
    "text": "cost effective way to run their models",
    "start": "28140",
    "end": "30240"
  },
  {
    "text": "and build cost-effective applications",
    "start": "30240",
    "end": "32160"
  },
  {
    "text": "with attractively low latencies",
    "start": "32160",
    "end": "34500"
  },
  {
    "text": "a big part of how we enable this",
    "start": "34500",
    "end": "36180"
  },
  {
    "text": "optimization and cost Effectiveness is",
    "start": "36180",
    "end": "38460"
  },
  {
    "text": "by accelerating model performance on a",
    "start": "38460",
    "end": "40379"
  },
  {
    "text": "range of Hardware targets",
    "start": "40379",
    "end": "42120"
  },
  {
    "text": "this has been especially important as",
    "start": "42120",
    "end": "44100"
  },
  {
    "text": "developers deal with the scarcity of the",
    "start": "44100",
    "end": "46140"
  },
  {
    "text": "powerful a100 GPU and look for",
    "start": "46140",
    "end": "48600"
  },
  {
    "text": "alternatives to run popular models with",
    "start": "48600",
    "end": "51000"
  },
  {
    "text": "the latencies that their users require",
    "start": "51000",
    "end": "52500"
  },
  {
    "text": "early customers we've been working with",
    "start": "52500",
    "end": "54660"
  },
  {
    "text": "have been eager to add AWS inferentia 2",
    "start": "54660",
    "end": "57300"
  },
  {
    "text": "as a hardware Target and to understand",
    "start": "57300",
    "end": "59280"
  },
  {
    "text": "the price performance advantages",
    "start": "59280",
    "end": "61140"
  },
  {
    "text": "inferencia can deliver for their models",
    "start": "61140",
    "end": "63420"
  },
  {
    "text": "we've been working with AWS in their",
    "start": "63420",
    "end": "65400"
  },
  {
    "text": "Early Access program to enable this and",
    "start": "65400",
    "end": "67680"
  },
  {
    "text": "have been partnering closely to deeply",
    "start": "67680",
    "end": "69240"
  },
  {
    "text": "understand customer needs as a result",
    "start": "69240",
    "end": "71760"
  },
  {
    "text": "today AWS inferentia 2 based Amazon ec2",
    "start": "71760",
    "end": "76080"
  },
  {
    "text": "and if two instances are integrated into",
    "start": "76080",
    "end": "78600"
  },
  {
    "text": "octo Ai and available to select",
    "start": "78600",
    "end": "80939"
  },
  {
    "text": "customers in private preview using info2",
    "start": "80939",
    "end": "83640"
  },
  {
    "text": "instances we have been able to build and",
    "start": "83640",
    "end": "85619"
  },
  {
    "text": "test optimizations for stable diffusion",
    "start": "85619",
    "end": "87960"
  },
  {
    "text": "that unlock additional levels of price",
    "start": "87960",
    "end": "90420"
  },
  {
    "text": "performance for customers and customers",
    "start": "90420",
    "end": "92520"
  },
  {
    "text": "have been excited with the performance",
    "start": "92520",
    "end": "93840"
  },
  {
    "text": "results from these early tests we",
    "start": "93840",
    "end": "95820"
  },
  {
    "text": "continue to work with AWS to accelerate",
    "start": "95820",
    "end": "97799"
  },
  {
    "text": "other generative AI models on if two",
    "start": "97799",
    "end": "99659"
  },
  {
    "text": "instances and building on amp2 We",
    "start": "99659",
    "end": "102060"
  },
  {
    "text": "believe We can unlock Future waves of",
    "start": "102060",
    "end": "103860"
  },
  {
    "text": "new developers and new applications",
    "start": "103860",
    "end": "105780"
  },
  {
    "text": "building on generative AI and get closer",
    "start": "105780",
    "end": "108600"
  },
  {
    "text": "to a time when any developer can easily",
    "start": "108600",
    "end": "111119"
  },
  {
    "text": "and cost effectively build on generative",
    "start": "111119",
    "end": "112979"
  },
  {
    "text": "AI models this is the future octo AI is",
    "start": "112979",
    "end": "116040"
  },
  {
    "text": "built around and we're excited to be",
    "start": "116040",
    "end": "117659"
  },
  {
    "text": "partnering with AWS as we work towards",
    "start": "117659",
    "end": "119640"
  },
  {
    "text": "making this a reality",
    "start": "119640",
    "end": "122540"
  }
]
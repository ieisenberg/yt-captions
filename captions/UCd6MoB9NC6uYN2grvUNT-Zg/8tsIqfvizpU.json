[
  {
    "start": "0",
    "end": "34000"
  },
  {
    "text": "all right uh good afternoon thank you all for uh coming out and joining us uh this afternoon we're going to talk about",
    "start": "1680",
    "end": "8160"
  },
  {
    "text": "the visible Network how Netflix uses kesa streams to monitor applications and analyze billions of traffic flows I'm",
    "start": "8160",
    "end": "16240"
  },
  {
    "text": "Alan mcginness I'm a Solutions architect at AWS um I am just the opening act I'm",
    "start": "16240",
    "end": "21760"
  },
  {
    "text": "not going to be up here for too long just going to do a few uh introductory pieces and then John Bennett from",
    "start": "21760",
    "end": "27160"
  },
  {
    "text": "Netflix is going to walk you through in detail the specific use case what I'm going to do before we hand it off to uh",
    "start": "27160",
    "end": "33760"
  },
  {
    "text": "to Bennett here is just talk about streaming data in general kind of general terms talk about streaming data",
    "start": "33760",
    "end": "40239"
  },
  {
    "start": "34000",
    "end": "95000"
  },
  {
    "text": "talk about some of the services in AWS that many customers are using to process streaming data and we're going to talk",
    "start": "40239",
    "end": "46600"
  },
  {
    "text": "about what we're calling the decision latency and so what I mean by that if we take a look at this slide we've got a",
    "start": "46600",
    "end": "52320"
  },
  {
    "text": "train let's assume it's like a uh a hyperloop train it's very fast and we've got a cargo ship right one's fast one is",
    "start": "52320",
    "end": "58800"
  },
  {
    "text": "slow in your business when you're talking about making decisions about uh anything it",
    "start": "58800",
    "end": "66000"
  },
  {
    "text": "could be things like uh how do I optimize uh my uh products that I'm",
    "start": "66000",
    "end": "71720"
  },
  {
    "text": "showing on an e-commerce website how do I know operationally if my systems are",
    "start": "71720",
    "end": "77320"
  },
  {
    "text": "running successfully these are things that uh if you can answer questions",
    "start": "77320",
    "end": "83360"
  },
  {
    "text": "about them quickly you can make changes and make optimizations that better improve your business oper operations",
    "start": "83360",
    "end": "90400"
  },
  {
    "text": "better improve things for your customers so that's what we mean by decision latency so when we look at the value of",
    "start": "90400",
    "end": "97479"
  },
  {
    "start": "95000",
    "end": "162000"
  },
  {
    "text": "data we talk about um what is important how does it become more valuable if we",
    "start": "97479",
    "end": "103520"
  },
  {
    "text": "look at this chart and this is from a uh a white paper that was uh published by Forester called perishable insights it's",
    "start": "103520",
    "end": "110119"
  },
  {
    "text": "a good paper that talks about the value of data over time uh if we look at the far right of this chart this is pretty",
    "start": "110119",
    "end": "116880"
  },
  {
    "text": "traditional batch processing we're talking about data that you might review on a daily or weekly basis so there's",
    "start": "116880",
    "end": "124119"
  },
  {
    "text": "certainly value in that to you and your business however it's old right it's a weak old it's not going to tell you",
    "start": "124119",
    "end": "129959"
  },
  {
    "text": "whether your site your website as an example is operating successfully right now because it's a weak old data if you",
    "start": "129959",
    "end": "136680"
  },
  {
    "text": "have to make time critical decisions you want to know what's going on immediately and that's to the left side of this",
    "start": "136680",
    "end": "143040"
  },
  {
    "text": "chart the time critical decisions things that you want to make decisions on in seconds maybe up to minutes and so",
    "start": "143040",
    "end": "149400"
  },
  {
    "text": "recent data is valuable if you can act on it in real time so you have to capture the value of your data and so on",
    "start": "149400",
    "end": "157959"
  },
  {
    "text": "AWS we have a set of services that make that pretty simple they're Kinesis",
    "start": "157959",
    "end": "163480"
  },
  {
    "start": "162000",
    "end": "333000"
  },
  {
    "text": "Amazon Kinesis quick show of hands how many folks in the room are either",
    "start": "163480",
    "end": "169239"
  },
  {
    "text": "familiar with or already using one of the three kesa services in your systems",
    "start": "169239",
    "end": "175920"
  },
  {
    "text": "today pretty good okay so I'd say it's about maybe I don't know maybe a fifth of the room um so I'm not going to spend",
    "start": "175920",
    "end": "182640"
  },
  {
    "text": "too much time going into details about the services I know you guys just want to hear from Bennett and how Netflix is solving some problems but to set a",
    "start": "182640",
    "end": "188599"
  },
  {
    "text": "little bit of context I'll talk about the three sets of services uh I think it's good to understand that you know I",
    "start": "188599",
    "end": "193760"
  },
  {
    "text": "know that Bennett's going to talk primarily about streams but there are two other services that um comprise the",
    "start": "193760",
    "end": "198799"
  },
  {
    "text": "Kinesis Suite of services so Kinesis streams generally you'll use this when you want to process custom Uh custom",
    "start": "198799",
    "end": "206840"
  },
  {
    "text": "process your data so you have a streaming set of data coming in you want to apply some custom processing to that",
    "start": "206840",
    "end": "212959"
  },
  {
    "text": "data and then send that data further Downstream either into a database or into S3 for storage or maybe onto",
    "start": "212959",
    "end": "218360"
  },
  {
    "text": "another stream so you could do some like chain processing but B basically with kesa streams you're going to write some",
    "start": "218360",
    "end": "224040"
  },
  {
    "text": "uh data producers and you're going to write some custom code to do the data consumption that's streams and Bennett",
    "start": "224040",
    "end": "230599"
  },
  {
    "text": "will talk a lot more about how they use that fire hose while there is a stream it is a streaming service the idea",
    "start": "230599",
    "end": "237640"
  },
  {
    "text": "behind fire hose is let's just make it simp simple for you if your endgame is just to take your streaming data and",
    "start": "237640",
    "end": "243760"
  },
  {
    "text": "persist it somewhere um you're not doing a lot of data transformation although you can do that now with fire hose uh",
    "start": "243760",
    "end": "249760"
  },
  {
    "text": "but if your endgame is just to take my streaming data and persist it into one of three destinations today those",
    "start": "249760",
    "end": "255120"
  },
  {
    "text": "destinations are S3 red shift and elastic search service so those are",
    "start": "255120",
    "end": "260440"
  },
  {
    "text": "three services in AWS if your endgame is just to take your streaming data and put it into one of those three services fire",
    "start": "260440",
    "end": "266520"
  },
  {
    "text": "hose is the tool for you there's no code you have to write to do that uh it's all a managed consumer is the easiest way to",
    "start": "266520",
    "end": "273320"
  },
  {
    "text": "think about that think of it like a managed consumer on a stream it's going to take the data buffer it put it into",
    "start": "273320",
    "end": "279039"
  },
  {
    "text": "the destination and it's also going to build you know have the the built-in retry mechanisms and failure scenarios",
    "start": "279039",
    "end": "284639"
  },
  {
    "text": "that kind of thing the third service is kinesis analytics so the nice thing about this is whether you're streaming",
    "start": "284639",
    "end": "290800"
  },
  {
    "text": "your data through streams or you're streaming your data into fir hose if you want to get some insights into that data",
    "start": "290800",
    "end": "296600"
  },
  {
    "text": "right now like how many times has this event heard in the past 5 minutes",
    "start": "296600",
    "end": "302120"
  },
  {
    "text": "Kinesis analytics can do that for you very simply by just writing some SQL so",
    "start": "302120",
    "end": "307280"
  },
  {
    "text": "SQL I'm guessing many of you are very familiar with SQL uh by writing a simple SQL statement using Kinesis analytics to",
    "start": "307280",
    "end": "315160"
  },
  {
    "text": "run that SQL against your streaming data and get results as soon as that window closes so like I said I've got real-time",
    "start": "315160",
    "end": "321039"
  },
  {
    "text": "streaming data every five minutes I want to count some amount some some kind of an event and I want to spit that out so",
    "start": "321039",
    "end": "326919"
  },
  {
    "text": "I can make some business decisions about it that's where kesa analytics fits in simple to use use a",
    "start": "326919",
    "end": "333080"
  },
  {
    "start": "333000",
    "end": "399000"
  },
  {
    "text": "SQL so with all of this with Kinesis streams and Kinesis fire hose as your front end we kind of have the full flow",
    "start": "333080",
    "end": "339759"
  },
  {
    "text": "of data right we ingest we process using uh some Amazon Kinesis enabled application and here we have a we have a",
    "start": "339759",
    "end": "346440"
  },
  {
    "text": "library called KCl I won't bore you with the details of that it's a library that you can use to process streaming data we",
    "start": "346440",
    "end": "352080"
  },
  {
    "text": "have Lambda uh and Kinesis analytics that you're processing and then we have good integration with other AWS services",
    "start": "352080",
    "end": "358280"
  },
  {
    "text": "so we have the full flow of data from ingest to process to react and then of",
    "start": "358280",
    "end": "364080"
  },
  {
    "text": "course to persist your data um so if we go from left to right on this slide we've got a number of services where're",
    "start": "364080",
    "end": "369919"
  },
  {
    "text": "maybe we're ending up uh apparently we have a connected scooter that's sending its data to a stream and we might do",
    "start": "369919",
    "end": "376440"
  },
  {
    "text": "some real-time processing and end up the data in in S3 or maybe uh red shift so I could do some uh bi on it so Kinesis",
    "start": "376440",
    "end": "385720"
  },
  {
    "text": "acts as the front end of the streaming data in nice integration with a number of different AWS services to help you",
    "start": "385720",
    "end": "391400"
  },
  {
    "text": "process and react and take action so that your business can learn something about what's going on",
    "start": "391400",
    "end": "398240"
  },
  {
    "text": "immediately so who's using Kinesis today a number of different customers I'm not going to talk about all these in detail",
    "start": "398240",
    "end": "404160"
  },
  {
    "start": "399000",
    "end": "467000"
  },
  {
    "text": "but let's just quickly talk about maybe like Sonos probably many of you familiar with Sonos the connected streaming audio",
    "start": "404160",
    "end": "410039"
  },
  {
    "text": "speakers so they run real-time streaming uh analytics on data that's being sent",
    "start": "410039",
    "end": "415599"
  },
  {
    "text": "from all their devices um MLB Advanced media another good customer so they stream 17",
    "start": "415599",
    "end": "422280"
  },
  {
    "text": "pedabytes of game data uh MLB Major League Baseball game data and then LLY lastly I'll talk about just quickly",
    "start": "422280",
    "end": "427960"
  },
  {
    "text": "about Hurst so Hurst analyzes 30 terabytes of clickstream data through uh",
    "start": "427960",
    "end": "434199"
  },
  {
    "text": "Kinesis so Hurst if you're not familiar with them they they are a large kind of uh publishing and and Media company they",
    "start": "434199",
    "end": "439720"
  },
  {
    "text": "own hundreds of different magazines and websites for uh TV channels they own",
    "start": "439720",
    "end": "444759"
  },
  {
    "text": "newspapers so a very large large company that owns a lot of media properties uh and anytime you might not know but if",
    "start": "444759",
    "end": "450879"
  },
  {
    "text": "you're on a website that's owned or run by Hurst right the clickstream data is being used to determine which articles",
    "start": "450879",
    "end": "456160"
  },
  {
    "text": "are successful which one should I promote all that data is being streamed through Kinesis and they're using um",
    "start": "456160",
    "end": "461360"
  },
  {
    "text": "Kinesis to to make decisions in real time about what they can do better to improve the content on their",
    "start": "461360",
    "end": "467599"
  },
  {
    "start": "467000",
    "end": "526000"
  },
  {
    "text": "website and so why do these customers choose uh kinus lots I'm not going to touch on every point but I'll talk about",
    "start": "467599",
    "end": "473319"
  },
  {
    "text": "what I see when I work with customers is one of the main reasons they choose Kinesis is one low costs and two the",
    "start": "473319",
    "end": "481280"
  },
  {
    "text": "kind of a combination of the increased agility and the uh ability to scale very",
    "start": "481280",
    "end": "486680"
  },
  {
    "text": "simply so there's other products in the industry that you could use to to stream data Kinesis is a managed service",
    "start": "486680",
    "end": "492240"
  },
  {
    "text": "particularly Kinesis streams very simple I want to create a uh I want to create a",
    "start": "492240",
    "end": "497599"
  },
  {
    "text": "system that's uh streaming in data from from my applications a couple of clicks",
    "start": "497599",
    "end": "503400"
  },
  {
    "text": "I get uh I get a a stream and I can start streaming data into the system within like five minutes of starting it",
    "start": "503400",
    "end": "510560"
  },
  {
    "text": "no system uh no ec2 instances to manage it's a fully managed service and so um",
    "start": "510560",
    "end": "515719"
  },
  {
    "text": "those are the some of the main reasons that we see that customers take advantage of this is its Simplicity Simplicity uh the agility that you get",
    "start": "515719",
    "end": "522320"
  },
  {
    "text": "from using it and of course it can also uh lower your costs and so we talked about a couple of customers",
    "start": "522320",
    "end": "529959"
  },
  {
    "text": "before I hand it over to uh to Bennett here at Netflix so they're using it like I said at the very beginning of the title right to stream um billions of",
    "start": "529959",
    "end": "537760"
  },
  {
    "text": "network traffic flows in real time and so they do this because they obviously want to get some real-time insights into",
    "start": "537760",
    "end": "544160"
  },
  {
    "text": "what's going on across the Netflix set of infrastructure that's running on AWS",
    "start": "544160",
    "end": "550240"
  },
  {
    "text": "so they stream a lot of data get some real-time insights in what to their into what their applications are doing and so",
    "start": "550240",
    "end": "556079"
  },
  {
    "text": "to talk more about how they do that and what they're doing and to talk about what is Netflix's decision latency I'd",
    "start": "556079",
    "end": "561680"
  },
  {
    "text": "like to introduce John Bennett from",
    "start": "561680",
    "end": "565720"
  },
  {
    "text": "Netflix thanks Alan so what I thought i' talk about uh",
    "start": "568360",
    "end": "574959"
  },
  {
    "start": "573000",
    "end": "627000"
  },
  {
    "text": "during the rest of this session is you know what kind of problems Netflix faces when it comes to monitoring",
    "start": "574959",
    "end": "581279"
  },
  {
    "text": "applications um and the solutions that we came up with you know evolved over",
    "start": "581279",
    "end": "586720"
  },
  {
    "text": "time uh just like many of you we do a bunch of trial and error most of it doesn't work um so I'm hoping to maybe",
    "start": "586720",
    "end": "592600"
  },
  {
    "text": "kind of provide a little bit of guidance uh from our experience to help you solve similar problems in your domain um we're",
    "start": "592600",
    "end": "598720"
  },
  {
    "text": "going to be look looking at analyzing Network traffic as an example but really",
    "start": "598720",
    "end": "604399"
  },
  {
    "text": "these techniques are broadly applicable um they may be used in say like a",
    "start": "604399",
    "end": "610000"
  },
  {
    "text": "financial domain or e-commerce uh it's it's very it's essentially able to be",
    "start": "610000",
    "end": "616000"
  },
  {
    "text": "used in a general sense and in particular I'm going to talk about how we use Kinesis uh in almost all of our",
    "start": "616000",
    "end": "622680"
  },
  {
    "text": "Solutions uh and then finally we'll kind of review some of the results that we came up with so for folks that don't",
    "start": "622680",
    "end": "628920"
  },
  {
    "start": "627000",
    "end": "639000"
  },
  {
    "text": "know uh Netflix is Big we have over a 100 million subscribers we're spread across",
    "start": "628920",
    "end": "634240"
  },
  {
    "text": "the entire world uh and every day we're getting bigger uh so under the",
    "start": "634240",
    "end": "639920"
  },
  {
    "start": "639000",
    "end": "673000"
  },
  {
    "text": "hood we use dozens of accounts we're spread across multiple regions there are",
    "start": "639920",
    "end": "645399"
  },
  {
    "text": "hundreds of microservices that are working in concert to make Netflix better and all of those are deploying",
    "start": "645399",
    "end": "653079"
  },
  {
    "text": "production changes every day uh and at the same time they're scaling up and scaling down in response to changes in",
    "start": "653079",
    "end": "660360"
  },
  {
    "text": "load and in the end we end up with over 100,000 instances and that doesn't include all the containers that are",
    "start": "660360",
    "end": "666160"
  },
  {
    "text": "running underneath so like any other uh complex system things break right uh and one of",
    "start": "666160",
    "end": "674639"
  },
  {
    "start": "673000",
    "end": "720000"
  },
  {
    "text": "the more convenient scapegoats when say like a systems engineer or an application developer uh can't figure",
    "start": "674639",
    "end": "681000"
  },
  {
    "text": "out what uh went wrong it's almost always right like what's wrong with the network just blame that it's really easy",
    "start": "681000",
    "end": "688519"
  },
  {
    "text": "because in a lot of ways we lack tooling to really tell us whether or not the",
    "start": "688519",
    "end": "694360"
  },
  {
    "text": "network was a problem uh even earlier today I think there was an issue in uh Us East one where we weren't actually",
    "start": "694360",
    "end": "701480"
  },
  {
    "text": "able to tell like hey is there actually a connectivity problem or is it our own systems uh so we can try to figure out a",
    "start": "701480",
    "end": "708839"
  },
  {
    "text": "way that uh Network Engineers talk about reducing this thing called meantime to innocence which essentially is like how",
    "start": "708839",
    "end": "715880"
  },
  {
    "text": "do we tell everyone that it's not our fault right",
    "start": "715880",
    "end": "721200"
  },
  {
    "start": "720000",
    "end": "760000"
  },
  {
    "text": "and then another question that we see is why is the network so slow right I'm",
    "start": "721200",
    "end": "726279"
  },
  {
    "text": "expecting things to happen within like a couple of seconds but really one of the more tricky things to figure out is are",
    "start": "726279",
    "end": "733680"
  },
  {
    "text": "you actually following this optimal network path you know it may seem very",
    "start": "733680",
    "end": "738920"
  },
  {
    "text": "uh easy to to figure out but in a complex system that problem can be uh",
    "start": "738920",
    "end": "744680"
  },
  {
    "text": "several times more complicated if you're using dependencies that you're not familiar with or dependencies that are",
    "start": "744680",
    "end": "750320"
  },
  {
    "text": "changing under the uh underneath you and may actually be taking a suboptimal path",
    "start": "750320",
    "end": "755839"
  },
  {
    "text": "so we'll be talking about how we end up monitoring that and lastly my service can't connect to",
    "start": "755839",
    "end": "764320"
  },
  {
    "start": "760000",
    "end": "820000"
  },
  {
    "text": "whatever it's surprisingly difficult to get any application developer to tell",
    "start": "764320",
    "end": "770120"
  },
  {
    "text": "you comprehensively give me a list of all the things that you need to connect to right because they may understand",
    "start": "770120",
    "end": "776040"
  },
  {
    "text": "that hey I need to talk to service a and service B that's it but maybe there's a",
    "start": "776040",
    "end": "781760"
  },
  {
    "text": "bunch of things that need to uh that it needs to connect to during like startup or maybe there are things that uh you",
    "start": "781760",
    "end": "788399"
  },
  {
    "text": "know are making subsequent connections and maybe they have they have no idea so even in a distributed system we're",
    "start": "788399",
    "end": "795839"
  },
  {
    "text": "making decisions about how to enable all of these different network paths and",
    "start": "795839",
    "end": "801560"
  },
  {
    "text": "making decisions on whether or not they should be allowed or not allowed and if we don't know what dependencies each",
    "start": "801560",
    "end": "807440"
  },
  {
    "text": "application needs then we're kind of just just shooting in the dark right and so uh part of the reason why we're",
    "start": "807440",
    "end": "813639"
  },
  {
    "text": "looking to analyze Network traffic laws that tells us exactly what applications need to connect",
    "start": "813639",
    "end": "819760"
  },
  {
    "text": "to so the list of uh challenges are very long when it comes to doing this in the network uh the Netflix ecosystem one we",
    "start": "819760",
    "end": "826399"
  },
  {
    "start": "820000",
    "end": "877000"
  },
  {
    "text": "have no access to the underlying Network right that's aws's job that's why we pay them the but at the same time our",
    "start": "826399",
    "end": "834040"
  },
  {
    "text": "traffic volume is huge right logs of network traffic ends up being gigabytes per second",
    "start": "834040",
    "end": "840000"
  },
  {
    "text": "right billions of flows every day and at the same time these logs end up being",
    "start": "840000",
    "end": "846040"
  },
  {
    "text": "things it's just a it's a log between uh two IP endpoints which isn't necessarily",
    "start": "846040",
    "end": "852839"
  },
  {
    "text": "all that meaningful to us right IP addresses are very uh ephemeral they could be attached to an instance for a",
    "start": "852839",
    "end": "860199"
  },
  {
    "text": "minute a day a year and they could be changing every other second so really",
    "start": "860199",
    "end": "865839"
  },
  {
    "text": "it's they're randomly assigned it C it's it's un predictable and in a way really",
    "start": "865839",
    "end": "872160"
  },
  {
    "text": "what we what we want to do is map this information to some longer lived logical",
    "start": "872160",
    "end": "878480"
  },
  {
    "start": "877000",
    "end": "932000"
  },
  {
    "text": "group and typically when you want to analyze Network traffic and you're in a data center you would use a something",
    "start": "878480",
    "end": "884519"
  },
  {
    "text": "like s flow or net flow but in AWS they actually provide this great API for us that tells us hey these are the kinds of",
    "start": "884519",
    "end": "890759"
  },
  {
    "text": "network uh traffic that you're seeing in your accounts it's called AWS flow logs it's good it covers all the traffic",
    "start": "890759",
    "end": "897880"
  },
  {
    "text": "within the VPC and it gives you a single point to read and it has all the core information that we need like source and",
    "start": "897880",
    "end": "903519"
  },
  {
    "text": "destination IP but like everything else right it's not perfect there's this",
    "start": "903519",
    "end": "908839"
  },
  {
    "text": "10-minute capture window so essentially a flow could happen in your system one second but maybe you don't see it in a",
    "start": "908839",
    "end": "915320"
  },
  {
    "text": "VPC flow log for 10 minutes right that doesn't really help uh us have a very",
    "start": "915320",
    "end": "920959"
  },
  {
    "text": "real- time based system and at the same time these logs are stateless so they don't tell you whether or not this was a",
    "start": "920959",
    "end": "927600"
  },
  {
    "text": "request or a response and that's really what we care about so we'll get back to that later so again I'm talking about",
    "start": "927600",
    "end": "934199"
  },
  {
    "start": "932000",
    "end": "943000"
  },
  {
    "text": "examples where maybe a flow is between one source to a destination at a given time right IP to IP who knows what those",
    "start": "934199",
    "end": "942079"
  },
  {
    "text": "IPS mean but really what we want to get to is hey this is the source metadata to",
    "start": "942079",
    "end": "947959"
  },
  {
    "start": "943000",
    "end": "961000"
  },
  {
    "text": "the destination metadata I know that application Fu was I'm sorry service a is talking to service B this is the",
    "start": "947959",
    "end": "954720"
  },
  {
    "text": "account it was in this is the uh the zone now I start to have a a better insight into what's actually happening",
    "start": "954720",
    "end": "960279"
  },
  {
    "text": "in the system so our goal was to build this new data source that we can actually use to",
    "start": "960279",
    "end": "966600"
  },
  {
    "start": "961000",
    "end": "1052000"
  },
  {
    "text": "do an an analysis of our Network traffic we knew that it needed to",
    "start": "966600",
    "end": "972680"
  },
  {
    "text": "involve multiple Dimensions like accounts and regions and zones but it also needed to have Netflix Centric",
    "start": "972680",
    "end": "978639"
  },
  {
    "text": "metadata like hey what application is it or what cluster is it and we want to be able to do fast aggregations right this",
    "start": "978639",
    "end": "984759"
  },
  {
    "text": "is not something that I want to submit a query and check back in a couple of hours after after",
    "start": "984759",
    "end": "990440"
  },
  {
    "text": "lunch at the same time we don't know what kind of queries we actually want to run uh we can try and predict but it's",
    "start": "990440",
    "end": "998079"
  },
  {
    "text": "we're almost always guaranteed to do that badly um but if we sort of um make",
    "start": "998079",
    "end": "1003279"
  },
  {
    "text": "sure that the system can do this sort of ad hoc querying then we can slice and dice the data however we want in the end",
    "start": "1003279",
    "end": "1010600"
  },
  {
    "text": "what we want to do is we want to add visibility to the network right we want to go beyond hey this these bits are",
    "start": "1010600",
    "end": "1016319"
  },
  {
    "text": "traversing between these two IPS we want to know hey these two applications are",
    "start": "1016319",
    "end": "1021600"
  },
  {
    "text": "communicating so that's why we built dredge this is our internal tool and what it does is it enriches traffic logs",
    "start": "1021600",
    "end": "1027558"
  },
  {
    "text": "and then Aggregates based on this uh dimensional data that I was talking about now dredge has",
    "start": "1027559",
    "end": "1035640"
  },
  {
    "text": "evolved in in a lot of ways one because there were so many questions that we had no no idea what the answers were you",
    "start": "1035640",
    "end": "1042600"
  },
  {
    "text": "know how much data is actually generated in the network right what would it actually take to do that in in real time",
    "start": "1042600",
    "end": "1049280"
  },
  {
    "text": "is it worth it uh so what I want to discuss now is some of the patterns that",
    "start": "1049280",
    "end": "1054760"
  },
  {
    "start": "1052000",
    "end": "1069000"
  },
  {
    "text": "we've applied uh unknowingly and then knowingly um to sort of tackle this",
    "start": "1054760",
    "end": "1060840"
  },
  {
    "text": "large volume of streaming data so that we can actually figure out how do we actually derive this uh this meaningful",
    "start": "1060840",
    "end": "1068799"
  },
  {
    "text": "information so just a quick overview right we're starting off with these raw",
    "start": "1068799",
    "end": "1073880"
  },
  {
    "start": "1069000",
    "end": "1093000"
  },
  {
    "text": "VPC flow log events right they the communication between these two IPS they're going to get process process in",
    "start": "1073880",
    "end": "1079240"
  },
  {
    "text": "some sort of way and what we want to come out of that system is this enriched version of the flow log right two IPS",
    "start": "1079240",
    "end": "1085960"
  },
  {
    "text": "now mean to these are the actual source and metadata behind those now the first step that we tried",
    "start": "1085960",
    "end": "1093679"
  },
  {
    "start": "1093000",
    "end": "1172000"
  },
  {
    "text": "was uh batch processing and Alan discussed this a little bit earlier you know when you can use canesa SP",
    "start": "1093679",
    "end": "1100200"
  },
  {
    "text": "hose this is a totally reasonable way to start right if you're there's no need to",
    "start": "1100200",
    "end": "1106280"
  },
  {
    "text": "take on the burden of doing things in real time if you don't know if it's even worth it but most batch systems will",
    "start": "1106280",
    "end": "1113760"
  },
  {
    "text": "have this sort of interval that you need to work on this uh this amount of data typically they do this every day so for",
    "start": "1113760",
    "end": "1120720"
  },
  {
    "text": "us we started off having um our interval St at 24 hours now the important characteristic about batch processing is",
    "start": "1120720",
    "end": "1127480"
  },
  {
    "text": "that essentially you're going to be processing a fixed amount of data that's not changing and the way you measure",
    "start": "1127480",
    "end": "1134520"
  },
  {
    "text": "yourself and whether or not the system is working efficiently is how fast you can crunch through that",
    "start": "1134520",
    "end": "1139919"
  },
  {
    "text": "now there's some limitations to that in in that as we're reading these Network traffic logs right these IP toip",
    "start": "1139919",
    "end": "1147039"
  },
  {
    "text": "communication we need to reach out to some sort of data source that's going to tell us what those IPS mean so we may",
    "start": "1147039",
    "end": "1153280"
  },
  {
    "text": "need to reach out to some remote database or maybe we put a cash in front of the database to make it",
    "start": "1153280",
    "end": "1158840"
  },
  {
    "text": "faster or maybe we even bring that database locally to the batch processor",
    "start": "1158840",
    "end": "1163960"
  },
  {
    "text": "to get rid of the you know the network roundt trip time and we'll go through uh these limitations in uh in more",
    "start": "1163960",
    "end": "1170840"
  },
  {
    "text": "detail so oh sorry here's how an architecture might",
    "start": "1170840",
    "end": "1176440"
  },
  {
    "start": "1172000",
    "end": "1219000"
  },
  {
    "text": "look if you were going to do it in batch right we're taking in these VPC flow log events and instead of doing it in real",
    "start": "1176440",
    "end": "1182960"
  },
  {
    "text": "time we're actually going to send them directly to storage so now that the flow logs are",
    "start": "1182960",
    "end": "1188760"
  },
  {
    "text": "sitting in storage at the same time we have this source of metadata changes right",
    "start": "1188760",
    "end": "1194600"
  },
  {
    "text": "whatever that ends up being in our case we're pulling AWS apis and also using our internal systems and",
    "start": "1194600",
    "end": "1201640"
  },
  {
    "text": "we were sending that metadata change to some uh to an external database so when the batch processor",
    "start": "1201640",
    "end": "1208520"
  },
  {
    "text": "kicks in it says hey I'm going to grab whatever uh the recent amount of stor uh data is in storage I'm going to cross",
    "start": "1208520",
    "end": "1214480"
  },
  {
    "text": "reference it with our metadata and then I'll pump out these enrich flow logs if",
    "start": "1214480",
    "end": "1219600"
  },
  {
    "start": "1219000",
    "end": "1265000"
  },
  {
    "text": "you want to do this using AWS tools you could end up using uh Kinesis fire hose",
    "start": "1219600",
    "end": "1225360"
  },
  {
    "text": "so you can take that stream of VPC flow logs and dump it into some like S3 bucket right you can use Lambda to do",
    "start": "1225360",
    "end": "1232080"
  },
  {
    "text": "the batch processing at some given interval and I don't know we ended up using uh Dynamo DB to store",
    "start": "1232080",
    "end": "1239480"
  },
  {
    "text": "metadata so again total reasonable way to start but like I said the big",
    "start": "1239480",
    "end": "1245520"
  },
  {
    "text": "characteristic right of batch processing is this delay right are you able to to",
    "start": "1245520",
    "end": "1250799"
  },
  {
    "text": "withstand some 24-hour delay on when uh value is sorry data is happening between the time that you can actually get value",
    "start": "1250799",
    "end": "1257919"
  },
  {
    "text": "you know that's not exactly acceptable for us because in 24 hours our systems are completely different so you know",
    "start": "1257919",
    "end": "1264039"
  },
  {
    "text": "what use is that so here's where we're going to spend a little bit more time when we're doing stream",
    "start": "1264039",
    "end": "1270200"
  },
  {
    "start": "1265000",
    "end": "1340000"
  },
  {
    "text": "processing right the delay is much much lower in our case we were able to get it down to say 5 to seven minutes but",
    "start": "1270200",
    "end": "1276960"
  },
  {
    "text": "really that 5 to seven minutes uh is actually because of the capture window that I mentioned a little bit earlier",
    "start": "1276960",
    "end": "1282600"
  },
  {
    "text": "from VPC flow logs right those uh those are being provided on every every 10 minutes so really if you wanted to do it",
    "start": "1282600",
    "end": "1289640"
  },
  {
    "text": "in we could be actually doing this in real time if those were provided in real time but the big difference between",
    "start": "1289640",
    "end": "1295320"
  },
  {
    "text": "stream processing and batch processing is now you have no idea how many events are going to occur within some given",
    "start": "1295320",
    "end": "1302320"
  },
  {
    "text": "window right because you're you're operating on them as they happen and in this case instead of measuring by",
    "start": "1302320",
    "end": "1308279"
  },
  {
    "text": "throughput really what tells us whether or not we're operating on the stream efficiently is how far behind are we",
    "start": "1308279",
    "end": "1315200"
  },
  {
    "text": "from the very head of the stream right are we keeping up with it are we falling behind um a lot of you will be familiar",
    "start": "1315200",
    "end": "1321760"
  },
  {
    "text": "with like this producer consumer pattern right is the consumer keeping up with the rate at which data is being",
    "start": "1321760",
    "end": "1327279"
  },
  {
    "text": "produced and they have the same uh same limitations as batch processing you can",
    "start": "1327279",
    "end": "1332679"
  },
  {
    "text": "use some remote database you can use caching or you may even bring that database closer to the processor but",
    "start": "1332679",
    "end": "1338760"
  },
  {
    "text": "let's dig into a little bit more detail so instead of batch processing we're going to do stream",
    "start": "1338760",
    "end": "1344679"
  },
  {
    "start": "1340000",
    "end": "1486000"
  },
  {
    "text": "processing but one of the big problems when you're going to be interacting with",
    "start": "1344679",
    "end": "1349880"
  },
  {
    "text": "some remote database is now you need to actually bridge this gap between the the",
    "start": "1349880",
    "end": "1356039"
  },
  {
    "text": "rate at which your your raw your raw data is being produced and the rate at",
    "start": "1356039",
    "end": "1361679"
  },
  {
    "text": "which you need to actually query this external database so let me try to back it away",
    "start": "1361679",
    "end": "1367960"
  },
  {
    "text": "from like the network example instead of VPC flow log say it was uh sensor data",
    "start": "1367960",
    "end": "1373279"
  },
  {
    "text": "from that inter what was it Internet connected scooter right say that was the sensor",
    "start": "1373279",
    "end": "1378799"
  },
  {
    "text": "data and you actually needed to marry it with like environmental readings or say uh instead of VPC flow",
    "start": "1378799",
    "end": "1386600"
  },
  {
    "text": "logs it's uh a log of I don't know Financial transactions and you need to",
    "start": "1386600",
    "end": "1392200"
  },
  {
    "text": "marry it with some other rate in order to figure out what the actual transaction looks like that's what",
    "start": "1392200",
    "end": "1398679"
  },
  {
    "text": "that's what would represent these flow logs and this metadata but the problem becomes when",
    "start": "1398679",
    "end": "1405960"
  },
  {
    "text": "that this rate of vpt flow lws could be Millions and millions per second right that means that for every flow that",
    "start": "1405960",
    "end": "1412679"
  },
  {
    "text": "comes into this system you would actually have to query the database at that same rate and that's definitely",
    "start": "1412679",
    "end": "1418760"
  },
  {
    "text": "going to be no bueno right because now you're talking about millions of queries going to a single database and now you're going to",
    "start": "1418760",
    "end": "1424960"
  },
  {
    "text": "have resource contention and that's you can even run your queries in parallel and that's just going to totally overload the database so typically when",
    "start": "1424960",
    "end": "1431799"
  },
  {
    "text": "you run into those problems where you're trying to bridge a gap in performance you'll go ahead and put a uh a cache in",
    "start": "1431799",
    "end": "1439000"
  },
  {
    "text": "front of it and actually I'll go through that in just a little bit but instead of using Kinesis fire hose we can use",
    "start": "1439000",
    "end": "1444840"
  },
  {
    "text": "Kinesis streams and we'll do this custom processing on the stream instead of dumping it to",
    "start": "1444840",
    "end": "1451080"
  },
  {
    "text": "S3 right at the same time we're still taking those metadata events and we pumping them into Dynamo DB so we're",
    "start": "1451080",
    "end": "1457159"
  },
  {
    "text": "going to read from the stream and we're going to at the same time query this remote database but if things are slow we can",
    "start": "1457159",
    "end": "1464679"
  },
  {
    "text": "put a cache in front of the the metadata database in order to to improve our read performance these",
    "start": "1464679",
    "end": "1471440"
  },
  {
    "text": "are things that are very typical right in that if you're if you need to to allow more reads than writes or",
    "start": "1471440",
    "end": "1477559"
  },
  {
    "text": "something like that hey you need to maybe create an index or a secondary index or put some sort of cache in front",
    "start": "1477559",
    "end": "1483640"
  },
  {
    "text": "of the DB layer very common and if you wanted to do this with AWS you could use",
    "start": "1483640",
    "end": "1489200"
  },
  {
    "start": "1486000",
    "end": "1536000"
  },
  {
    "text": "their own like mcash D or and then still use a Dione DB but the problem with using",
    "start": "1489200",
    "end": "1497320"
  },
  {
    "text": "caches ends up being it ends up being more problems than it's worth how do you",
    "start": "1497320",
    "end": "1503080"
  },
  {
    "text": "manage like cash inv validation right because if you have this cash sitting in front of this",
    "start": "1503080",
    "end": "1509039"
  },
  {
    "text": "DB in some way you've got to set like a TTL on the items in that cash if it's too low then you're always going to",
    "start": "1509039",
    "end": "1515520"
  },
  {
    "text": "getting you're always going to be getting cash misses so you might as well just like ditch the the cash if the TTL is too high now you're",
    "start": "1515520",
    "end": "1523320"
  },
  {
    "text": "going to be getting stale data every time you hit that cash and then it's a",
    "start": "1523320",
    "end": "1528440"
  },
  {
    "text": "to you on whether that whether or not that that risk of joining with uh steel data is worth it in our case it",
    "start": "1528440",
    "end": "1536480"
  },
  {
    "start": "1536000",
    "end": "1598000"
  },
  {
    "text": "wasn't so one of the insights that a gentleman named Martin ketman um writes about in some of his blogs and a book",
    "start": "1537039",
    "end": "1543279"
  },
  {
    "text": "that he put together called uh data intensive applications is that these database indexes caches materialized",
    "start": "1543279",
    "end": "1550200"
  },
  {
    "text": "views these are all derived data that we use in order to speed up uh read",
    "start": "1550200",
    "end": "1556080"
  },
  {
    "text": "performance right they all come from they're all sort of hidden away from us",
    "start": "1556080",
    "end": "1561360"
  },
  {
    "text": "you know when we have a some sort of database a database is receiving like a stream of changes but really when you",
    "start": "1561360",
    "end": "1567679"
  },
  {
    "text": "query the database you're just getting that fixed snapshot in time so there under the hood there is a stream of",
    "start": "1567679",
    "end": "1574039"
  },
  {
    "text": "changes it's just completely uh hidden from you but these indexes that come",
    "start": "1574039",
    "end": "1579640"
  },
  {
    "text": "from building out this uh the database can be derived from this original",
    "start": "1579640",
    "end": "1585520"
  },
  {
    "text": "Stream So what he proposes is why not just expose that stream of changes directly to the user to our applications",
    "start": "1585520",
    "end": "1593480"
  },
  {
    "text": "instead of having to create some cash or uh using database indexes and he calls",
    "start": "1593480",
    "end": "1599720"
  },
  {
    "start": "1598000",
    "end": "1651000"
  },
  {
    "text": "this process change data capture the kinds of tools that we use",
    "start": "1599720",
    "end": "1604799"
  },
  {
    "text": "to do that ends up being like a log based message broker like Kafka or Kinesis and you can use that to send",
    "start": "1604799",
    "end": "1611520"
  },
  {
    "text": "these uh send these change events and expose the change log as a first class",
    "start": "1611520",
    "end": "1617240"
  },
  {
    "text": "citizen so instead of querying some external database we would actually consume both streams of data and then do",
    "start": "1617240",
    "end": "1623919"
  },
  {
    "text": "the join ourselves in a way you're sort of you're creating like this alternate view of your data locally so that you",
    "start": "1623919",
    "end": "1632240"
  },
  {
    "text": "don't have to make a roundtrip time to uh to an external database and as you're reading both",
    "start": "1632240",
    "end": "1639120"
  },
  {
    "text": "streams you can update your sort of local view of this uh of this change log",
    "start": "1639120",
    "end": "1645240"
  },
  {
    "text": "so that it's optimized for your use case right everybody might do it differently let me try to make this uh a little bit",
    "start": "1645240",
    "end": "1651159"
  },
  {
    "start": "1651000",
    "end": "1659000"
  },
  {
    "text": "more concrete so we have these two streams right we got bpc flow logs and we have",
    "start": "1651159",
    "end": "1657039"
  },
  {
    "text": "another stream of this metadata changes really what we can do is we're reading from this this stream of of",
    "start": "1657039",
    "end": "1664480"
  },
  {
    "start": "1659000",
    "end": "1715000"
  },
  {
    "text": "traffic we can create this customized data structure in our case I thought we actually needed to to leverage some",
    "start": "1664480",
    "end": "1671360"
  },
  {
    "text": "exotic data structure some like radex tree or skip list I don't even know I'd have to go back and read a book but",
    "start": "1671360",
    "end": "1678279"
  },
  {
    "text": "really just a hashmap and uh and a sorted list totally worked out fine for us",
    "start": "1678279",
    "end": "1684720"
  },
  {
    "text": "so as flow laws are coming in we sort of have this map of given this IP these are",
    "start": "1684720",
    "end": "1690880"
  },
  {
    "text": "the metadata that H that are valid during a different time interval and every time we get changes",
    "start": "1690880",
    "end": "1696240"
  },
  {
    "text": "in our metadata we can just update this table and this is all custom within",
    "start": "1696240",
    "end": "1701320"
  },
  {
    "text": "memory right we don't have to now we don't actually have to go and request from a external database hey you know I",
    "start": "1701320",
    "end": "1708519"
  },
  {
    "text": "have this IP and this timestamp can you tell me what that means you already have this sort of pre-computed cache there",
    "start": "1708519",
    "end": "1715639"
  },
  {
    "start": "1715000",
    "end": "1760000"
  },
  {
    "text": "locally so what the final architecture end up looking like is this everything is much simpler there's just a single",
    "start": "1715799",
    "end": "1721760"
  },
  {
    "text": "stream processor and you're really consuming from these two streams and you're doing this join right we're doing",
    "start": "1721760",
    "end": "1727720"
  },
  {
    "text": "this well stream join not we don't cross the streams that's a little bit more",
    "start": "1727720",
    "end": "1732960"
  },
  {
    "text": "dangerous but still in the end we're coming out with this enriched flow log where we don't have resource contention",
    "start": "1733120",
    "end": "1740039"
  },
  {
    "text": "there isn't a network roundtrip time things are totally optimized to our",
    "start": "1740039",
    "end": "1746279"
  },
  {
    "text": "application and one of the things that um you might notice is that we don't actually use Kinesis to do our stream of",
    "start": "1747399",
    "end": "1754559"
  },
  {
    "text": "metadata changes and I'll explain why that is um in just a little",
    "start": "1754559",
    "end": "1760240"
  },
  {
    "start": "1760000",
    "end": "1770000"
  },
  {
    "text": "bit but you can see how Kinesis is a constant themed through all of these",
    "start": "1760240",
    "end": "1766880"
  },
  {
    "text": "patterns right it it's worked out for us in so many ways because it's",
    "start": "1766880",
    "end": "1771919"
  },
  {
    "start": "1770000",
    "end": "1858000"
  },
  {
    "text": "integrated uh very strongly with other AWS services from flow logs all the way to",
    "start": "1771919",
    "end": "1777919"
  },
  {
    "text": "elastic search and it scales really well it's stable and they provide this great",
    "start": "1777919",
    "end": "1783080"
  },
  {
    "text": "uh library that I think Alan mentioned earlier called the Kinesis client library and in the end we actually H",
    "start": "1783080",
    "end": "1789200"
  },
  {
    "text": "spend less using Kinesis than we would if we were using our internal Kafka",
    "start": "1789200",
    "end": "1794799"
  },
  {
    "text": "clusters so just to speak to some of the integration uh points one of the biggest fears that we",
    "start": "1794799",
    "end": "1801919"
  },
  {
    "text": "had taking on this problem was all right there's this crazy amount of network traffic how are we actually even going",
    "start": "1801919",
    "end": "1808440"
  },
  {
    "text": "to deal with it right who's going to who's going to ship it everywhere who's going to how are we even going to read",
    "start": "1808440",
    "end": "1814200"
  },
  {
    "text": "from uh something like that and um VPC flow logs and Kinesis can be used",
    "start": "1814200",
    "end": "1821120"
  },
  {
    "text": "together to actually remove the the need for you to write any code in terms of",
    "start": "1821120",
    "end": "1827679"
  },
  {
    "text": "prod producing that data with a couple of API calls we could set up uh systems so that all of our accounts and all of",
    "start": "1827679",
    "end": "1834120"
  },
  {
    "text": "our regions are actually sending their traffic logs to a single Kinesis stream",
    "start": "1834120",
    "end": "1839399"
  },
  {
    "text": "that was a huge win for us because in this whole system no code on our part to",
    "start": "1839399",
    "end": "1844919"
  },
  {
    "text": "actually take traffic logs and put them into the kesa stream right because that's the stuff that we don't actually",
    "start": "1844919",
    "end": "1850440"
  },
  {
    "text": "care about what we really really want is we want to read this data like I don't care about writing the data so this was",
    "start": "1850440",
    "end": "1856679"
  },
  {
    "text": "a huge win for us at the same time it allowed us it allowed us to experiment right hey can",
    "start": "1856679",
    "end": "1864159"
  },
  {
    "start": "1858000",
    "end": "1916000"
  },
  {
    "text": "we do it with batch right what's involved it's a very it's a very",
    "start": "1864159",
    "end": "1870000"
  },
  {
    "text": "straight setup using Kinesis fire hose and then we could just fire data into S3 and deal with it",
    "start": "1870000",
    "end": "1877080"
  },
  {
    "text": "later we've even experimented using elastic search and red shift and we had to change maybe two or three lines of",
    "start": "1877080",
    "end": "1884120"
  },
  {
    "text": "code that was really really good for us because at the same time we don't even know if this is worth it",
    "start": "1884120",
    "end": "1891240"
  },
  {
    "text": "right because this is a lot of data and at the same time there's all this uh complication when it comes to uh",
    "start": "1891240",
    "end": "1898880"
  },
  {
    "text": "systems that are being launched to to enrich it so it allows us sort of experiment and figure out which ways",
    "start": "1898880",
    "end": "1905240"
  },
  {
    "text": "where's that good balance between our data being processed and data being uh valuable to us and then when we were",
    "start": "1905240",
    "end": "1912480"
  },
  {
    "text": "ready to do it in real time we could have transfer and migrate to kesa streams this is a graph of the",
    "start": "1912480",
    "end": "1919480"
  },
  {
    "start": "1916000",
    "end": "1946000"
  },
  {
    "text": "throughput of our traffic logs over a week period and you can see it's very um",
    "start": "1919480",
    "end": "1926200"
  },
  {
    "text": "is it sinusoidal dial I don't know okay um where there's a peak every day right",
    "start": "1926200",
    "end": "1931679"
  },
  {
    "text": "in a trough and it that's responding to our our traffic load throughout our entire system and this sort of pattern",
    "start": "1931679",
    "end": "1939320"
  },
  {
    "text": "can be very problematic to other uh systems like kofka but for Kinesis wasn't a problem and even if you look in",
    "start": "1939320",
    "end": "1946159"
  },
  {
    "start": "1946000",
    "end": "1961000"
  },
  {
    "text": "more detail every things are very spiky and that's because",
    "start": "1946159",
    "end": "1951279"
  },
  {
    "text": "VPC flow logs are generated in this very um defined 10-minute capture window this",
    "start": "1951279",
    "end": "1957600"
  },
  {
    "text": "can also cause a problem for things like kka but it wasn't a problem for Kinesis the Kinesis client library was",
    "start": "1957600",
    "end": "1965720"
  },
  {
    "start": "1961000",
    "end": "1986000"
  },
  {
    "text": "really a pleasant to use right it kind of automated all the boring stuff stuff that we didn't care about right load",
    "start": "1965720",
    "end": "1973039"
  },
  {
    "text": "balancing um and then reading from records and checkpointing all of that is handled because it integrated with",
    "start": "1973039",
    "end": "1978080"
  },
  {
    "text": "Dynamo DB and it provides sort of the stream level and Shard level metrics",
    "start": "1978080",
    "end": "1983200"
  },
  {
    "text": "that help us figure out if things are actually working properly and the last thing I wanted to",
    "start": "1983200",
    "end": "1988440"
  },
  {
    "start": "1986000",
    "end": "2008000"
  },
  {
    "text": "mention is that this total cost of ownership that's so low that we haven't",
    "start": "1988440",
    "end": "1994480"
  },
  {
    "text": "really even thought about Kinesis since we started using it it's it's handling on its own it's running it's self it's",
    "start": "1994480",
    "end": "2000679"
  },
  {
    "text": "managed entirely by AWS all we need to make sure is that there are aren't enough shards for us to be able to do",
    "start": "2000679",
    "end": "2006240"
  },
  {
    "text": "things in parallel but there are some use cases where Kinesis isn't the right tool for the job",
    "start": "2006240",
    "end": "2014600"
  },
  {
    "start": "2008000",
    "end": "2074000"
  },
  {
    "text": "right if there are if you need to actually have so many shards that ends up being a problem that could end up",
    "start": "2014600",
    "end": "2022039"
  },
  {
    "text": "meaning that Kinesis doesn't fit because then you've got to like fan out to some other Kinesis stream or increase the",
    "start": "2022039",
    "end": "2027200"
  },
  {
    "text": "amount of shards in some unreasonable way but also one of the things that is a",
    "start": "2027200",
    "end": "2033600"
  },
  {
    "text": "limit on Kinesis is that the farthest back that you can keep uh data in a stream is 7",
    "start": "2033600",
    "end": "2039240"
  },
  {
    "text": "days so I don't know if you remember from our architecture diagram earlier if we have this stream of metadata changes",
    "start": "2039240",
    "end": "2046880"
  },
  {
    "text": "that change for say a given IP Could Happen uh yesterday it could happen",
    "start": "2046880",
    "end": "2052320"
  },
  {
    "text": "today or it could have happened several months ago if you have a stream where you're only able to keep seven days",
    "start": "2052320",
    "end": "2058480"
  },
  {
    "text": "worth of data you wouldn't be able to go far back enough for changes that may have happened a lot",
    "start": "2058480",
    "end": "2064280"
  },
  {
    "text": "earlier so kofka ends up providing that sort of uh system for us and uh they",
    "start": "2064280",
    "end": "2069679"
  },
  {
    "text": "provide this log compaction mode which sort of clears away old data in case you don't need",
    "start": "2069679",
    "end": "2075720"
  },
  {
    "start": "2074000",
    "end": "2088000"
  },
  {
    "text": "it so let's talk about some of the results after all that work right we're",
    "start": "2075720",
    "end": "2081720"
  },
  {
    "text": "we're enriching millions of floww flow logs there's gigabytes of data per second what we end up coming up with",
    "start": "2081720",
    "end": "2088878"
  },
  {
    "start": "2088000",
    "end": "2110000"
  },
  {
    "text": "we're doing 7 million flows per second every flow that comes in ends up",
    "start": "2088879",
    "end": "2096480"
  },
  {
    "text": "being about 5 minutes old so that's that's generally still useful",
    "start": "2096480",
    "end": "2101640"
  },
  {
    "text": "for us obviously if we can bring that down to seconds it would be better but really all we have is one stream and",
    "start": "2101640",
    "end": "2107079"
  },
  {
    "text": "hundreds of shards so let's revisit some of the questions that we had earlier what's",
    "start": "2107079",
    "end": "2113680"
  },
  {
    "start": "2110000",
    "end": "2126000"
  },
  {
    "text": "wrong with the network so this is where dredge comes in and it helps reduce this meantime to",
    "start": "2113680",
    "end": "2119599"
  },
  {
    "text": "innocence right is it the Network's fault or is it some application developer's",
    "start": "2119599",
    "end": "2126119"
  },
  {
    "start": "2126000",
    "end": "2157000"
  },
  {
    "text": "fault here's what dredge can do it groups things by fault domain I had",
    "start": "2126119",
    "end": "2131400"
  },
  {
    "text": "mentioned a little bit earlier that with traffic logs we can break things down by Dimensions like account and region and",
    "start": "2131400",
    "end": "2137160"
  },
  {
    "text": "things like that we can group things by fault domain which essentially means hey",
    "start": "2137160",
    "end": "2142480"
  },
  {
    "text": "everything in this account this Zone that sort of is uh a single fault domain",
    "start": "2142480",
    "end": "2148280"
  },
  {
    "text": "and we can compare what those connect to on the other side what account and Zone",
    "start": "2148280",
    "end": "2153319"
  },
  {
    "text": "do those uh Services hit so if like",
    "start": "2153319",
    "end": "2158520"
  },
  {
    "start": "2157000",
    "end": "2204000"
  },
  {
    "text": "service a can't talk to service D but say everything else in its shared fault",
    "start": "2158520",
    "end": "2164319"
  },
  {
    "text": "domain can still connect on the other side then that's probably a bad code push right you push it back to the",
    "start": "2164319",
    "end": "2170160"
  },
  {
    "text": "developer and be like you go figure it out I'm going to go and you know take",
    "start": "2170160",
    "end": "2175800"
  },
  {
    "text": "off but see for instance all of those services in the single fault domain all share this like this degraded",
    "start": "2175800",
    "end": "2182640"
  },
  {
    "text": "performance problem then that sort of may be an indication on whether or not there's a network out",
    "start": "2182640",
    "end": "2188200"
  },
  {
    "text": "AG really really valuable why is the network so slow my",
    "start": "2188200",
    "end": "2196800"
  },
  {
    "text": "favorite because it's trickier than it seems right dredge can actually identify whether or not you're taking these high",
    "start": "2196800",
    "end": "2202640"
  },
  {
    "text": "Lancy paths so one of the things that you want to be doing when you're using AWS is you",
    "start": "2202640",
    "end": "2209040"
  },
  {
    "start": "2204000",
    "end": "2227000"
  },
  {
    "text": "really want to be uh following what we call Zone Affinity right a service",
    "start": "2209040",
    "end": "2214920"
  },
  {
    "text": "should really try to strive to communicate to other services within its Zone that's going to mean that you're going to have less than like a",
    "start": "2214920",
    "end": "2221319"
  },
  {
    "text": "millisecond worth of latency right minus the time uh the application",
    "start": "2221319",
    "end": "2226880"
  },
  {
    "text": "takes but if you go cross Zone from say Us East 1D to us East 1e you're going to",
    "start": "2226880",
    "end": "2233800"
  },
  {
    "start": "2227000",
    "end": "2251000"
  },
  {
    "text": "be adding I don't know probably a couple of milliseconds maybe less than that and maybe that's not a big deal but if",
    "start": "2233800",
    "end": "2240520"
  },
  {
    "text": "you've got large volumes of traffic adding those couple of milliseconds to every transaction may end up being",
    "start": "2240520",
    "end": "2246400"
  },
  {
    "text": "meaningful to you but here's where the big deal comes in right what if you go in Cross",
    "start": "2246400",
    "end": "2252280"
  },
  {
    "start": "2251000",
    "end": "2271000"
  },
  {
    "text": "region now we're talking 30 to 300 milliseconds that can be very",
    "start": "2252280",
    "end": "2258880"
  },
  {
    "text": "problematic right no one wants that especially if you want your system to be performant now this could be",
    "start": "2258880",
    "end": "2264880"
  },
  {
    "text": "straightforward if you can identify whether or not service a is talking to service B cross",
    "start": "2264880",
    "end": "2270960"
  },
  {
    "text": "region but what happens if you're connecting to service B and you're in",
    "start": "2270960",
    "end": "2276319"
  },
  {
    "start": "2271000",
    "end": "2330000"
  },
  {
    "text": "zone you're like I'm got I'm golden I'm hitting I'm hitting services within my own Zone but then it fans out to say",
    "start": "2276319",
    "end": "2283280"
  },
  {
    "text": "another zone or another region and now you're still going to be eating this penalty of high",
    "start": "2283280",
    "end": "2288839"
  },
  {
    "text": "latency and dredge sort of helps us understand whether or not these high latency paths are being taken because",
    "start": "2288839",
    "end": "2295440"
  },
  {
    "text": "now we're reading all traffic flows within the network and we're breaking things down by logical groups like",
    "start": "2295440",
    "end": "2301200"
  },
  {
    "text": "accounts and regions and zones that tell us not only this is the source of",
    "start": "2301200",
    "end": "2306240"
  },
  {
    "text": "traffic but we understand what the destination is so this is a really huge Win For Us in that one it helps us",
    "start": "2306240",
    "end": "2313440"
  },
  {
    "text": "understand how we can actually improve the performance of our of our systems but also we can actually reduce the cost",
    "start": "2313440",
    "end": "2319280"
  },
  {
    "text": "when Network traffic goes between zones or even between regions that is several",
    "start": "2319280",
    "end": "2324880"
  },
  {
    "text": "times more expensive than staying within the same",
    "start": "2324880",
    "end": "2329720"
  },
  {
    "text": "zone so some initial findings is that we figured out that almost a quarter of our traffic ends up being cross Zone which",
    "start": "2329920",
    "end": "2336079"
  },
  {
    "start": "2330000",
    "end": "2361000"
  },
  {
    "text": "is crazy you would think that we did somehow like optimize that but we haven't in a lot of ways our systems",
    "start": "2336079",
    "end": "2342079"
  },
  {
    "text": "have evolved so quickly that Engineers aren't necessarily thinking about the latency that's being uh added to the",
    "start": "2342079",
    "end": "2348839"
  },
  {
    "text": "system by doing cross Zone traffic but even more disconcerting is that 14% of that ends up being cross",
    "start": "2348839",
    "end": "2355040"
  },
  {
    "text": "region some of that is intentional but some of it is definitely shooting yourself in the",
    "start": "2355040",
    "end": "2361839"
  },
  {
    "start": "2361000",
    "end": "2374000"
  },
  {
    "text": "foot lastly my service can connect to its dependencies so dredge really helps",
    "start": "2362480",
    "end": "2369440"
  },
  {
    "text": "uh identify what is inbound to a service and what's outbound to a service some of our existing tools end",
    "start": "2369440",
    "end": "2376920"
  },
  {
    "start": "2374000",
    "end": "2412000"
  },
  {
    "text": "up trying to do this with distributed tracing some of you may be familiar with uh Google's Dapper and this sort of is",
    "start": "2376920",
    "end": "2384240"
  },
  {
    "text": "like understanding what breadcrumbs a a request hits along its way through as it makes its way through the system and it",
    "start": "2384240",
    "end": "2391119"
  },
  {
    "text": "does this through sampling but it's very jvm Centric at the same time those things",
    "start": "2391119",
    "end": "2397079"
  },
  {
    "text": "aren aren't necessarily having a lot of coverage right if it's jvm Centric how do you do that for say python or JS or",
    "start": "2397079",
    "end": "2404560"
  },
  {
    "text": "go and it has other problems in terms of capturing say startup dependencies or",
    "start": "2404560",
    "end": "2409880"
  },
  {
    "text": "protocols other than TCP ipv4 so just to give you an example of one of our uh what we found right say",
    "start": "2409880",
    "end": "2416680"
  },
  {
    "text": "service a is actually talking to Cassandra M MCD like that's what my system is like I",
    "start": "2416680",
    "end": "2423240"
  },
  {
    "text": "know because I wrote it but really if you actually dig into the network ch traffic you find that you're not only",
    "start": "2423240",
    "end": "2429200"
  },
  {
    "text": "talking to that but you're talking to Discovery you're talking to a Kafka cluster you're talking to S3 you're talking to sqs a lot of these",
    "start": "2429200",
    "end": "2435319"
  },
  {
    "text": "application developers didn't even know that that was happening uh on their systems because they were more focused",
    "start": "2435319",
    "end": "2440560"
  },
  {
    "text": "on the flows that are under their control versus say like a client that they might be",
    "start": "2440560",
    "end": "2446520"
  },
  {
    "text": "using so we found that there's a significant discrepancy between dredge and the sort of dependencies that are",
    "start": "2446520",
    "end": "2453200"
  },
  {
    "text": "surfaced by our Distributing system distributed tracing system Almost 100%",
    "start": "2453200",
    "end": "2458560"
  },
  {
    "text": "of the services that I sampled found this uh this Delta between the two but",
    "start": "2458560",
    "end": "2465040"
  },
  {
    "text": "almost always dredge data was much larger than the data that was being uh",
    "start": "2465040",
    "end": "2470319"
  },
  {
    "text": "produced by distributed tracing it's consistently under uh Under",
    "start": "2470319",
    "end": "2477520"
  },
  {
    "text": "reporting and we have High coverage now because this doesn't Network traffic doesn't have anything to do with the",
    "start": "2477520",
    "end": "2483920"
  },
  {
    "text": "runtime that you're using the language or the framework right if you basically if you're using the network Dr is going",
    "start": "2483920",
    "end": "2489119"
  },
  {
    "text": "to see it also this is super helpful for us to understand what AWS Services",
    "start": "2489119",
    "end": "2494319"
  },
  {
    "text": "applications talk to because those those calls would never be instrumented in a way that would be surfaced to our",
    "start": "2494319",
    "end": "2501160"
  },
  {
    "text": "systems Engineers so security has actually been",
    "start": "2501160",
    "end": "2506200"
  },
  {
    "start": "2503000",
    "end": "2576000"
  },
  {
    "text": "using this uh data source very heavily because now they can understand what",
    "start": "2506200",
    "end": "2511560"
  },
  {
    "text": "applications need to talk to each other and then they can sort of reduce the blast radius in case those Services end",
    "start": "2511560",
    "end": "2517760"
  },
  {
    "text": "up being compromised one of the uh the long-standing values at Netflix is uh",
    "start": "2517760",
    "end": "2524040"
  },
  {
    "text": "freedom and responsibility right we we try to provide as much freedom to our to",
    "start": "2524040",
    "end": "2529520"
  },
  {
    "text": "our application developers so say we may open up security groups very wide for everyone to talk to each",
    "start": "2529520",
    "end": "2535680"
  },
  {
    "text": "other but those application developers may not know how to rein that in but by",
    "start": "2535680",
    "end": "2541920"
  },
  {
    "text": "using dredge dependency information we can sort of reduce that scope and make sure that systems aren't comp rised in",
    "start": "2541920",
    "end": "2548720"
  },
  {
    "text": "suboptimal ways also flow logs give us the only source that tells us whether or not",
    "start": "2548720",
    "end": "2555240"
  },
  {
    "text": "security groups actually work right the there's no other way to to figure out whether or not some Security Group rule",
    "start": "2555240",
    "end": "2562319"
  },
  {
    "text": "actually rejected traffic on some port or protocol at the same time we also",
    "start": "2562319",
    "end": "2567880"
  },
  {
    "text": "understand what applications have an increased risk profile because they're communicating with things on the general",
    "start": "2567880",
    "end": "2573400"
  },
  {
    "text": "internet either outbound or inbound so in the",
    "start": "2573400",
    "end": "2578800"
  },
  {
    "text": "end what I wanted to be able to communicate is that by enriching and aggregating this data we ended up",
    "start": "2578800",
    "end": "2584920"
  },
  {
    "text": "putting together this really powerful source of information it can be used for monitoring for triage for cost analysis",
    "start": "2584920",
    "end": "2593040"
  },
  {
    "text": "for security auditing and it takes this invisible network where we lack",
    "start": "2593040",
    "end": "2600760"
  },
  {
    "text": "tools to actually adding visibility and giving us actionable items to take from",
    "start": "2600760",
    "end": "2605880"
  },
  {
    "text": "there and make our systems better better so that's it uh you can actually",
    "start": "2605880",
    "end": "2611079"
  },
  {
    "start": "2608000",
    "end": "2820000"
  },
  {
    "text": "reach me on Twitter if you have any questions um I think we actually have a few minutes for",
    "start": "2611079",
    "end": "2616720"
  },
  {
    "text": "questions unless I was talking so fast that that pretty much just went over",
    "start": "2616720",
    "end": "2623078"
  },
  {
    "text": "[Applause]",
    "start": "2623320",
    "end": "2630839"
  },
  {
    "text": "everyone",
    "start": "2630839",
    "end": "2633839"
  },
  {
    "text": "hi",
    "start": "2636040",
    "end": "2639040"
  },
  {
    "text": "yeah so the question was can I elaborate on the joining of the Kines stream and the Kafka stream yes that's happening on",
    "start": "2643920",
    "end": "2649760"
  },
  {
    "text": "on a single instance so they're they're both sort of having the equivalent of the consumer groups reading from two",
    "start": "2649760",
    "end": "2655359"
  },
  {
    "text": "streams and then doing a",
    "start": "2655359",
    "end": "2658279"
  },
  {
    "text": "join uh so the question was are we using tables K tables uh not necessarily K tables",
    "start": "2664280",
    "end": "2670520"
  },
  {
    "text": "we're just using us just an inmemory map MH",
    "start": "2670520",
    "end": "2676760"
  },
  {
    "text": "question ah so the question was what was our experience using elastic search",
    "start": "2681760",
    "end": "2687119"
  },
  {
    "text": "um when we were using Kinesis fire holes we could send traffic logs to an elastic",
    "start": "2687119",
    "end": "2693920"
  },
  {
    "text": "search cluster but it wouldn't be enriched so the data that would end up in elastic",
    "start": "2693920",
    "end": "2699720"
  },
  {
    "text": "search would just be our IP and and Port information so it sort of added an",
    "start": "2699720",
    "end": "2705200"
  },
  {
    "text": "intermediate step that we didn't think was necessary it's like oh you have traffic logs that's IP to IP",
    "start": "2705200",
    "end": "2711319"
  },
  {
    "text": "communication and now it's an elastic search it's still IP to IP communication uh and then we have to take things out",
    "start": "2711319",
    "end": "2718160"
  },
  {
    "text": "of elastic search do the enrichment and then ship it off somewhere",
    "start": "2718160",
    "end": "2723440"
  },
  {
    "text": "else uh yeah so the question is uh you can use Lambda now to pick up from either uh",
    "start": "2725960",
    "end": "2734200"
  },
  {
    "text": "S3 or elastic search yes you can use a Lambda to do that hi go",
    "start": "2734200",
    "end": "2740839"
  },
  {
    "text": "ahead that's a good question so uh the term is a cold start right if you're bringing up say a new instance right",
    "start": "2751040",
    "end": "2757640"
  },
  {
    "text": "which is all of our applications should be prepared to do that how do you actually handle that in terms of being",
    "start": "2757640",
    "end": "2763599"
  },
  {
    "text": "able to make sure that you can continue to enrich new data uh and our Ines end",
    "start": "2763599",
    "end": "2768880"
  },
  {
    "text": "up taking five to six minutes to read from the very beginning of our streams",
    "start": "2768880",
    "end": "2774559"
  },
  {
    "text": "in order to to gather all the data it needs so that it can it can start enriching new flow",
    "start": "2774559",
    "end": "2780280"
  },
  {
    "text": "logs so yes the the part of the reason why we would use kofka to do that is",
    "start": "2780280",
    "end": "2785680"
  },
  {
    "text": "because we can maintain data from the very beginning as opposed to only like the recent uh say like the last few",
    "start": "2785680",
    "end": "2792359"
  },
  {
    "text": "days uh I think question then I can answer it the same",
    "start": "2792359",
    "end": "2797640"
  },
  {
    "text": "way same question uh just our changes of metadata",
    "start": "2797640",
    "end": "2804920"
  },
  {
    "text": "sorry the question was what data lives in kfka so essentially uh given some IP",
    "start": "2804920",
    "end": "2811359"
  },
  {
    "text": "at a given time uh this is the metadata connected to it do dat the Rich data",
    "start": "2811359",
    "end": "2817359"
  },
  {
    "text": "ends up we end up putting that into a a druid cluster um it's a tool that was built by folks from metam markets it",
    "start": "2817359",
    "end": "2824520"
  },
  {
    "start": "2820000",
    "end": "2851000"
  },
  {
    "text": "just allows us to do this um like ad hoc queries that we wanted to end up uh",
    "start": "2824520",
    "end": "2829599"
  },
  {
    "text": "doing in a way that doesn't Force us to like pre uh like create indexes and have",
    "start": "2829599",
    "end": "2835440"
  },
  {
    "text": "like a very small subset of queries that we can ask any other questions one over here oh",
    "start": "2835440",
    "end": "2841839"
  },
  {
    "text": "yeah go ahead",
    "start": "2841839",
    "end": "2848839"
  },
  {
    "text": "ah so the question is um I guess what do we how do we use the KCl the Kinesis client Library um we use it out of the",
    "start": "2852119",
    "end": "2858359"
  },
  {
    "text": "box in a way that that the documentation provides they outline a interface that",
    "start": "2858359",
    "end": "2863480"
  },
  {
    "text": "your that your Java or scull applications need to implement so that as data records comes in it processes",
    "start": "2863480",
    "end": "2870920"
  },
  {
    "text": "the data or it does like checkpointing it's it's pretty straightforward and that was I I would say that was one of",
    "start": "2870920",
    "end": "2876880"
  },
  {
    "text": "of the more um where I was the most reluctant right because if you're going to be reading like this large volume of",
    "start": "2876880",
    "end": "2883520"
  },
  {
    "text": "of data from any any data source the client Library needs to actually be able to handle all the the failures and load",
    "start": "2883520",
    "end": "2892319"
  },
  {
    "text": "balancing yeah it was actually really helpful for us are there any questions for Alan that's okay",
    "start": "2892319",
    "end": "2899680"
  },
  {
    "text": "no yeah go",
    "start": "2899680",
    "end": "2902960"
  },
  {
    "text": "ahead",
    "start": "2905760",
    "end": "2908760"
  },
  {
    "text": "[Music] ah so the question is whether why use Druid for uh like ad hoc queries and and",
    "start": "2911220",
    "end": "2918400"
  },
  {
    "text": "ol app sty queries um instead of say elastic search um I think when I when I look at elastic search I go hey do I",
    "start": "2918400",
    "end": "2924559"
  },
  {
    "text": "need full text search if not like I think it's probably the wrong it's the",
    "start": "2924559",
    "end": "2930040"
  },
  {
    "text": "wrong fit but it's it's definitely something that is",
    "start": "2930040",
    "end": "2935440"
  },
  {
    "text": "usable and else thumbs up thumbs down was it okay",
    "start": "2935440",
    "end": "2942160"
  },
  {
    "text": "everything was okay sweet you guys aren't just saying",
    "start": "2942160",
    "end": "2947040"
  },
  {
    "text": "that yeah y yeah yeah the question was can we use install Druid in AWS yes but",
    "start": "2947799",
    "end": "2954200"
  },
  {
    "text": "it's not without pain it's like it's like 15 different",
    "start": "2954200",
    "end": "2960079"
  },
  {
    "text": "subsystems another another alternative that I think uh Folks at Cloud flare use is um uh click house",
    "start": "2960079",
    "end": "2967240"
  },
  {
    "text": "which comes from Yandex click yeah click house um a much simpler system uh less",
    "start": "2967240",
    "end": "2975200"
  },
  {
    "text": "to less moving Parts uh much easier to reason about right you don't end up",
    "start": "2975200",
    "end": "2980319"
  },
  {
    "text": "leveraging things like zookeeper which is notoriously hard to operate yeah yeah absolutely any other",
    "start": "2980319",
    "end": "2987680"
  },
  {
    "text": "questions I'll be outside in case anyone wants to throw things at me or I don't know give me candy no okay all right",
    "start": "2987680",
    "end": "2996319"
  },
  {
    "text": "thanks guys",
    "start": "2996319",
    "end": "2998640"
  }
]
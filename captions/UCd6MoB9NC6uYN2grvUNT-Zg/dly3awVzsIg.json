[
  {
    "text": "hello and thank you attending today's webinar we will begin the",
    "start": "4859",
    "end": "10180"
  },
  {
    "text": "and patient in approximately one minute",
    "start": "10180",
    "end": "14130"
  },
  {
    "text": "you",
    "start": "21560",
    "end": "23619"
  },
  {
    "text": "hello and welcome to our webinar where",
    "start": "58469",
    "end": "63750"
  },
  {
    "text": "people learn how shop Rinna processes a terabyte of data a day to recommend the",
    "start": "63750",
    "end": "68970"
  },
  {
    "text": "right products my name is Satan Irizarry I am I am an AI ml specialist Solutions Architect for",
    "start": "68970",
    "end": "77040"
  },
  {
    "text": "Amazon Web Services and I'll be your host and moderator for today's presentation when you joined today's",
    "start": "77040",
    "end": "83310"
  },
  {
    "text": "webinar you selected to join by either phone call or your computer audio if for",
    "start": "83310",
    "end": "89130"
  },
  {
    "text": "any reason you would like to change your audio selection you can do so by accessing your audio pane in the control",
    "start": "89130",
    "end": "95310"
  },
  {
    "text": "panel from this control panel you will also have the opportunity to submit questions to today's presenter by typing",
    "start": "95310",
    "end": "102750"
  },
  {
    "text": "your questions into the questions panel we will collect the questions and addresses as many as we can during the",
    "start": "102750",
    "end": "109679"
  },
  {
    "text": "Q&A session at the end of today's presentation also at the end of today's",
    "start": "109679",
    "end": "115140"
  },
  {
    "text": "event is a brief survey please stay connected until the end of the broadcast and submit your feedback",
    "start": "115140",
    "end": "121500"
  },
  {
    "text": "as your opinions count lastly the PowerPoint presentation will be",
    "start": "121500",
    "end": "127050"
  },
  {
    "text": "available through SlideShare along with a recording of the webinar on YouTube via an email that will be sent two to",
    "start": "127050",
    "end": "134730"
  },
  {
    "text": "three days after the conclusion of this event so please keep an eye out for the",
    "start": "134730",
    "end": "139890"
  },
  {
    "text": "follow-up email sent to the address that you have provided let's take a brief",
    "start": "139890",
    "end": "148709"
  },
  {
    "text": "look at the outline of our podcast today we will start with the story of AI as",
    "start": "148709",
    "end": "154379"
  },
  {
    "text": "seen from within an arc organization where most of machine learning takes place than anywhere else we will turn",
    "start": "154379",
    "end": "161400"
  },
  {
    "text": "then we will transition to our Amazon partner network comprehensive partners data bricks and finally we will hear",
    "start": "161400",
    "end": "168840"
  },
  {
    "text": "from our guest of the our shop runner and delve into the technical details of deploying a recommender engine in",
    "start": "168840",
    "end": "175440"
  },
  {
    "text": "production please remember please post your questions in the chat box throughout",
    "start": "175440",
    "end": "181650"
  },
  {
    "text": "this presentation as we will review questions at the end of today's event",
    "start": "181650",
    "end": "187730"
  },
  {
    "text": "along with me today we have Brian lurking who is a senior director",
    "start": "187730",
    "end": "193550"
  },
  {
    "text": "of partner marketing and data breaks data pricks are the original creators of Apache spark they provide an unified",
    "start": "193550",
    "end": "200240"
  },
  {
    "text": "analytics platform to help in accelerating innovation of their customers by unifying data science",
    "start": "200240",
    "end": "205850"
  },
  {
    "text": "engineering and business and our guest of honor today is Hannah Torrance she is",
    "start": "205850",
    "end": "211670"
  },
  {
    "text": "a data scientist at shop runner chocolate shop runner is literally Amazon Prime for everyone else there are",
    "start": "211670",
    "end": "219410"
  },
  {
    "text": "six million members get free two-day shipping returns and beans across a",
    "start": "219410",
    "end": "224690"
  },
  {
    "text": "growing network of 140 plus retailers some of the famous names such as Hugo",
    "start": "224690",
    "end": "229760"
  },
  {
    "text": "Boss Kate Spade and Jimmy Choo are amongst these 140 plus supported",
    "start": "229760",
    "end": "235580"
  },
  {
    "text": "retailers now let me take this opportunity and set the stage for our",
    "start": "235580",
    "end": "241550"
  },
  {
    "text": "deep type customers and partners choose AWS over other providers because it has a lot more functionality the largest and",
    "start": "241550",
    "end": "249080"
  },
  {
    "text": "most proven vibrant community of customers and partners the most proven operation and security expertise and the",
    "start": "249080",
    "end": "255470"
  },
  {
    "text": "business and the business is innovating at a faster clip especially in the area such as machine learning and artificial",
    "start": "255470",
    "end": "261950"
  },
  {
    "text": "intelligence Internet of Things and serverless computing machine learning at Amazon has been an active area of",
    "start": "261950",
    "end": "267830"
  },
  {
    "text": "investment and research for the past 20 years we have innovated improved and",
    "start": "267830",
    "end": "272870"
  },
  {
    "text": "published original work in the area of machine learning for the past two decades be it in the area of",
    "start": "272870",
    "end": "279080"
  },
  {
    "text": "fulfillments and logistics like in the case of our warehouses using Amazon",
    "start": "279080",
    "end": "285169"
  },
  {
    "text": "robotics to streamline package creation or be it search and discovery in Amazon retail or be a topic modeling in length",
    "start": "285169",
    "end": "292490"
  },
  {
    "text": "in lengthy tomes making content more accessible or beard upcoming Amazon drone delivery system",
    "start": "292490",
    "end": "298790"
  },
  {
    "text": "prime air which is fully operational tile operating near Cambridge in United",
    "start": "298790",
    "end": "304940"
  },
  {
    "text": "Kingdom or we get amazing natural language processing capabilities of Amazon Alexa or be it Amazon Co a",
    "start": "304940",
    "end": "312140"
  },
  {
    "text": "brand-new retail store concept that is operated across the u.s. Amazon has been",
    "start": "312140",
    "end": "318050"
  },
  {
    "text": "an innovator in the field of computer vision forecasting search and recommendations natural language",
    "start": "318050",
    "end": "324110"
  },
  {
    "text": "processing autonomous drones and applications in retail amongst other areas while machine",
    "start": "324110",
    "end": "329720"
  },
  {
    "text": "learning has been around for 50 years the cloud is enabling it to be applied",
    "start": "329720",
    "end": "334880"
  },
  {
    "text": "at scale in 2019 IDC estimates that 40% of all digital",
    "start": "334880",
    "end": "340160"
  },
  {
    "text": "transformation initiatives will be supported by AI what is our mission at",
    "start": "340160",
    "end": "347680"
  },
  {
    "text": "AWS our mission at AWS is by the way of",
    "start": "347680",
    "end": "353870"
  },
  {
    "text": "deliberate osmosis we want to enable our partners our customers we want to take",
    "start": "353870",
    "end": "359449"
  },
  {
    "text": "our rich experience with machine learning across Amazon and put it in the hands of all organizations every",
    "start": "359449",
    "end": "366020"
  },
  {
    "text": "developer data scientist and researcher and how exactly do we do this v we have",
    "start": "366020",
    "end": "371900"
  },
  {
    "text": "uniquely customer focused we start with the customer need and work backwards 90%",
    "start": "371900",
    "end": "377300"
  },
  {
    "text": "of a AWS Roenick is built directly from customer feedback we have unmatched we are unmatched in the breadth of ml",
    "start": "377300",
    "end": "383900"
  },
  {
    "text": "services we offer to our customers today we believe customer choice and flexibility are incredibly important we",
    "start": "383900",
    "end": "389840"
  },
  {
    "text": "support all copy of frameworks and interfaces to give you choice and flexibility we also have the deepest set",
    "start": "389840",
    "end": "396169"
  },
  {
    "text": "of security and encryption features with broadest uh traditions an approach and our approach to our NT is fundamentally",
    "start": "396169",
    "end": "402500"
  },
  {
    "text": "different in unique our scientists are embedded within our product and engineering teams and we invent and",
    "start": "402500",
    "end": "409039"
  },
  {
    "text": "simply if I on behalf of the customers more as a result more machine learning",
    "start": "409039",
    "end": "416599"
  },
  {
    "text": "happens on AWS than anywhere else why",
    "start": "416599",
    "end": "424300"
  },
  {
    "text": "because we have the broadest and deepest set of capabilities we see machine",
    "start": "424300",
    "end": "429740"
  },
  {
    "text": "learning stack as having three key layers ml frameworks it is the bottom bottom layer for the machine learning",
    "start": "429740",
    "end": "435470"
  },
  {
    "text": "practitioners researchers and developers this includes infrastructure AWS offers broad array of compute options for",
    "start": "435470",
    "end": "442070"
  },
  {
    "text": "training and inference with powerful GPU based instances compute and memory optimized in sizes and even FPGAs",
    "start": "442070",
    "end": "448550"
  },
  {
    "text": "then we have ml services Amazon CH maker removes the heavy lifting complexity and guesswork from each step of machine",
    "start": "448550",
    "end": "454250"
  },
  {
    "text": "learning process sage maker makes model building and trading easier but prebuilt development notebooks popular",
    "start": "454250",
    "end": "460520"
  },
  {
    "text": "machine learning algorithms optimized for petabyte data sets and automatic model tuning enabling developers to",
    "start": "460520",
    "end": "466220"
  },
  {
    "text": "build train and deploy models in a single place finally we have the machine learning services layer which is which",
    "start": "466220",
    "end": "471770"
  },
  {
    "text": "are ready-made for all developers know machine learning skills required they cover the areas of vision speech",
    "start": "471770",
    "end": "477020"
  },
  {
    "text": "language chat parts forecasting and recommendations all this is powered by",
    "start": "477020",
    "end": "482750"
  },
  {
    "text": "the highest performing infrastructure for your business let's talk about a few key key stats our p3 instances provide",
    "start": "482750",
    "end": "489949"
  },
  {
    "text": "up to 14 times better performance than previous generation Amazon ec2 GPU instance GPU compute instances the new",
    "start": "489949",
    "end": "496790"
  },
  {
    "text": "Amazon ec2 p3 TN instance has four times the networking bandwidth and twice the",
    "start": "496790",
    "end": "502940"
  },
  {
    "text": "GPU memory four of the largest p3 instance p3 DN is ideal for large sales",
    "start": "502940",
    "end": "508220"
  },
  {
    "text": "distributed training no one else has anything closed now zooming out and",
    "start": "508220",
    "end": "514159"
  },
  {
    "text": "switching gears recommender systems the topic of today are everywhere they",
    "start": "514159",
    "end": "519200"
  },
  {
    "text": "influence the world experience and the choices you've made apart from being omnipresent they are",
    "start": "519200",
    "end": "524450"
  },
  {
    "text": "also a favorite topic of mine and I can geek out on it for like ours together recommendations drive about 30% of",
    "start": "524450",
    "end": "531950"
  },
  {
    "text": "traffic Ramazan dot-com given the amount of traffic amazon.com receives its actually a very significant number",
    "start": "531950",
    "end": "538810"
  },
  {
    "text": "recommendation engines deal with solving various machine learning problems how to encode real-world data into vector form",
    "start": "538810",
    "end": "545810"
  },
  {
    "text": "how to represent various features of an object how to then find similarities between objects these are some of the",
    "start": "545810",
    "end": "552110"
  },
  {
    "text": "things that Hana is going to go into details in a presentation shop runners recommendation system is built on top of",
    "start": "552110",
    "end": "559010"
  },
  {
    "text": "data bricks and hosted on AWS let me talk briefly about data breaks and our",
    "start": "559010",
    "end": "565390"
  },
  {
    "text": "Amazon partner network competency partners it implies competency is our clover Pat word partner program designed",
    "start": "565390",
    "end": "572600"
  },
  {
    "text": "to promote and highlight our top a SS partners based on their overall specialization in a key a double",
    "start": "572600",
    "end": "579110"
  },
  {
    "text": "solution workload and vertical areas our goal is to be the most customer obsessed",
    "start": "579110",
    "end": "584900"
  },
  {
    "text": "partner program but providing our customers customers with top-rated and",
    "start": "584900",
    "end": "589970"
  },
  {
    "text": "validated partner solution that can help customers take advantage of a doorless products and services AWS",
    "start": "589970",
    "end": "596390"
  },
  {
    "text": "competency partners go through rigorous technical assessment and verification of the expertise specific to each a SS",
    "start": "596390",
    "end": "603470"
  },
  {
    "text": "competency beta Brix is one of the few partners that hold multiple AWS partner",
    "start": "603470",
    "end": "610310"
  },
  {
    "text": "network competencies data breaks is a part of data breaks apart from holding",
    "start": "610310",
    "end": "615649"
  },
  {
    "text": "machine learning competency also have big debt of competency public sector competency and healthcare and life",
    "start": "615649",
    "end": "620690"
  },
  {
    "text": "sciences competency I would like to now",
    "start": "620690",
    "end": "625820"
  },
  {
    "text": "welcome lime from data brakes to take us on a brief tour of the unified analytics",
    "start": "625820",
    "end": "633260"
  },
  {
    "text": "platform hosted on AWS great thank you to Tommy a great job",
    "start": "633260",
    "end": "639370"
  },
  {
    "text": "hello everybody and thank you so much for joining us today so a couple of",
    "start": "639370",
    "end": "644540"
  },
  {
    "text": "things that I wanted to do I just wanted to talk a little bit about who data bricks is so that as Hannah goes through her presentation you have basically a",
    "start": "644540",
    "end": "651260"
  },
  {
    "text": "framework to understand the company and what we're doing Esther Tonya mentioned you know our our",
    "start": "651260",
    "end": "657830"
  },
  {
    "text": "founders are the original creators of apache spark pachi spark is known as the top analytics and data preparation",
    "start": "657830",
    "end": "664340"
  },
  {
    "text": "engine in the world use you know by all sorts of organizations to be able to",
    "start": "664340",
    "end": "669740"
  },
  {
    "text": "prepare and then data and then run machine learning and analytics on top of it our goal is to really accelerate",
    "start": "669740",
    "end": "676190"
  },
  {
    "text": "innovation by unifying data science data engineering and business because when we started out we really saw that data",
    "start": "676190",
    "end": "682970"
  },
  {
    "text": "science and trying to get the data together for data science was very separate so we'll talk a little bit more about that we do this on our unified",
    "start": "682970",
    "end": "689840"
  },
  {
    "text": "analytics platform which was originally created on AWS and continues to run on AWS today besides uh you know being the",
    "start": "689840",
    "end": "698300"
  },
  {
    "text": "creators of spark we've also created Delta Lake and m/l flow I'll talk a little bit more about what those",
    "start": "698300",
    "end": "703360"
  },
  {
    "text": "innovations are and how we've now made those open source as well but we have",
    "start": "703360",
    "end": "709130"
  },
  {
    "text": "over 2000 global companies who are using our platform across big data machine learning lifecycle",
    "start": "709130",
    "end": "715630"
  },
  {
    "text": "look at this image we see first off that you know data bricks on the unified analytics platform integrates with the",
    "start": "717880",
    "end": "723610"
  },
  {
    "text": "number of AWS services we have a few selected ones over here on the left this is an exhaustive list but you see things",
    "start": "723610",
    "end": "731050"
  },
  {
    "text": "like Amazon sage maker you see Kinesis for being able to do streaming data redshift s3 so a number of different",
    "start": "731050",
    "end": "737380"
  },
  {
    "text": "services that we integrate with in terms of data sources and then processes for",
    "start": "737380",
    "end": "742690"
  },
  {
    "text": "being able to to run machine learning in the Box in the middle you can see the",
    "start": "742690",
    "end": "747910"
  },
  {
    "text": "data bricks runtime again you know based on apache spark but then also we know",
    "start": "747910",
    "end": "753610"
  },
  {
    "text": "that data scientists like to run many different machine learning frameworks and to be able to look at those",
    "start": "753610",
    "end": "760000"
  },
  {
    "text": "differences and be able to choose what is the right you know framework or library for the work i'm trying to do so",
    "start": "760000",
    "end": "765820"
  },
  {
    "text": "on top of SPARC we also offer tensorflow XG boosts pi torch scikit-learn and a number of others as part of the",
    "start": "765820",
    "end": "772210"
  },
  {
    "text": "dataverse runtime so very simply you you start up a database cluster and you select if you want those machine",
    "start": "772210",
    "end": "777970"
  },
  {
    "text": "learning libraries loaded and then you're up and ready to roll so it's a great way to be able to to bring in many",
    "start": "777970",
    "end": "783490"
  },
  {
    "text": "different machine learning frameworks on top of that we have the data bricks workspace with our collaborative notebooks and this is really you know",
    "start": "783490",
    "end": "790450"
  },
  {
    "text": "the key thing that we've built on top of data bricks besides you know the runtime engine because this allows data",
    "start": "790450",
    "end": "797170"
  },
  {
    "text": "scientists and data engineers to collaborate seamlessly and in one flow they can go back and forth between their",
    "start": "797170",
    "end": "803620"
  },
  {
    "text": "favorite languages so a data scientist can be writing in Scala and data engine sorry data engineer can be writing in",
    "start": "803620",
    "end": "809080"
  },
  {
    "text": "skull and a data scientist can be writing it our Python and just flow seamlessly back and forth they can leave",
    "start": "809080",
    "end": "814510"
  },
  {
    "text": "each other comments etc and I think the main thing that happens there as you go from an orientation of you know as a",
    "start": "814510",
    "end": "822220"
  },
  {
    "text": "data scientist I need to do data set I'm going to send an email or maybe I'm going to put up a JIRA ticket or",
    "start": "822220",
    "end": "828700"
  },
  {
    "text": "something and then I wait a couple of weeks by having folks working in the",
    "start": "828700",
    "end": "833890"
  },
  {
    "text": "notebook together it really speeds and accelerates that innovation and that's where I see a lot of customers come to",
    "start": "833890",
    "end": "840070"
  },
  {
    "text": "us and say you know I bought data bricks because of the EMC increased speed and",
    "start": "840070",
    "end": "845710"
  },
  {
    "text": "II and the performance of data bricks but really the eye-opener was one",
    "start": "845710",
    "end": "851089"
  },
  {
    "text": "sar date assigned to some data engineers working together in the way that's accelerated innovation for their company",
    "start": "851089",
    "end": "856699"
  },
  {
    "text": "and it's you know more way bigger impact than they've ever anticipated so that's",
    "start": "856699",
    "end": "863059"
  },
  {
    "text": "a little bit about that moving on to the next slide here I think you know the",
    "start": "863059",
    "end": "870199"
  },
  {
    "text": "thing that really it comes back to for us is as we noticed very early in this process that writing machine learning",
    "start": "870199",
    "end": "877249"
  },
  {
    "text": "code was only part of the process and in this case you can see you know it's about 10% of the process I mean it's",
    "start": "877249",
    "end": "882529"
  },
  {
    "text": "really about getting the data together and all the other pieces that go around a machine learning practice including",
    "start": "882529",
    "end": "889699"
  },
  {
    "text": "things like monitoring and deployment etc you know all these are the the challenges that every organization runs",
    "start": "889699",
    "end": "895670"
  },
  {
    "text": "into trying to create a machine learning practice and I think you know what's beautiful about what shop runner has",
    "start": "895670",
    "end": "900800"
  },
  {
    "text": "done is they've solved these problems to the point where they're able to run this on a fairly automated basis so the data",
    "start": "900800",
    "end": "908180"
  },
  {
    "text": "comes in each day they're able to incorporate that they're able to even take feedback on the models and bring",
    "start": "908180",
    "end": "914300"
  },
  {
    "text": "that in and I think that's where you know a lot of companies are still aspiring to to be is to be able to have",
    "start": "914300",
    "end": "920509"
  },
  {
    "text": "that kind of an automation and so that's what we're really excited you know for Hannah to talk a little bit about how",
    "start": "920509",
    "end": "925519"
  },
  {
    "text": "they got there you um so just you know recapping a little",
    "start": "925519",
    "end": "931690"
  },
  {
    "text": "bit about Apache spark you know this is the de facto unified analytics engine this was you know originally what we",
    "start": "931690",
    "end": "938470"
  },
  {
    "text": "created we saw this problem this could actually goes all the way back to the the Netflix contest about ten years ago",
    "start": "938470",
    "end": "944620"
  },
  {
    "text": "was really kind of the the dawning of spark when a couple of our founders were",
    "start": "944620",
    "end": "949960"
  },
  {
    "text": "part of that contest we're trying to solve the problem they found the biggest problem was they couldn't get the data",
    "start": "949960",
    "end": "955030"
  },
  {
    "text": "to the machine learning libraries and algorithms and and so they you know",
    "start": "955030",
    "end": "960130"
  },
  {
    "text": "looked at this and thought well there's a great way to be able to bring this all together and that was the dawning of Apache spark and that's what's really",
    "start": "960130",
    "end": "965590"
  },
  {
    "text": "made it the basis for so much analytics that goes on these days so it's really",
    "start": "965590",
    "end": "972430"
  },
  {
    "text": "you know this this unification that we we were talking about in terms of bringing the data together and the machine learning that makes all the",
    "start": "972430",
    "end": "978670"
  },
  {
    "text": "difference so for us you know being able to look at data lakes streams no sequel data",
    "start": "978670",
    "end": "986350"
  },
  {
    "text": "sources data warehouses bring that all together with the machine learning as we talked about the as well as you know the",
    "start": "986350",
    "end": "993190"
  },
  {
    "text": "notebooks that do this process but then also bringing in the different machine learning frameworks and everything here",
    "start": "993190",
    "end": "998320"
  },
  {
    "text": "and then even allowing you to use tools like our studio if you have you know if you use our Studios a favorite IDE",
    "start": "998320",
    "end": "1003899"
  },
  {
    "text": "having that integrated everything and then what you get on the results side is",
    "start": "1003899",
    "end": "1009149"
  },
  {
    "text": "you know these machine learning outcomes and so if you look down the right-hand side here you can see a couple of different examples you know",
    "start": "1009149",
    "end": "1015570"
  },
  {
    "text": "recommendation and personalization engines which you know Hannah will talk about in depth and I think what's",
    "start": "1015570",
    "end": "1021089"
  },
  {
    "text": "interesting about that too is I've seen recommendation engines used in so many different ways so you know if you're not",
    "start": "1021089",
    "end": "1026668"
  },
  {
    "text": "in the retail industry and you're looking to serve customers I've seen folks using them in government for being",
    "start": "1026669",
    "end": "1033750"
  },
  {
    "text": "able to enable people to choose different kinds of benefits I've even seen companies uses for internal usage",
    "start": "1033750",
    "end": "1039360"
  },
  {
    "text": "so I saw again you know a benefit selection by a company where employees",
    "start": "1039360",
    "end": "1044400"
  },
  {
    "text": "needed help in choosing what was the the best benefits package for them and so",
    "start": "1044400",
    "end": "1049919"
  },
  {
    "text": "you could ask you know four or five questions figure out the predictor variables and then go ahead and and make",
    "start": "1049919",
    "end": "1055380"
  },
  {
    "text": "a recommendation so recommendation engines are super powerful and can be used in so many different ways for organizations other",
    "start": "1055380",
    "end": "1062250"
  },
  {
    "text": "examples here you know risk fraud and intrusion detection customer 360",
    "start": "1062250",
    "end": "1067640"
  },
  {
    "text": "inventory asset optimization genomics you know where rajendran we're solving",
    "start": "1067640",
    "end": "1073710"
  },
  {
    "text": "liver disease together in terms of being able to identify key genomic causes",
    "start": "1073710",
    "end": "1079669"
  },
  {
    "text": "inventory assessment I mentioned predictive maintenance is another example you know an Eric I've seen folks",
    "start": "1079669",
    "end": "1085799"
  },
  {
    "text": "using interesting algorithms like a Market Basket analysis which is typically you know when somebody chooses",
    "start": "1085799",
    "end": "1090809"
  },
  {
    "text": "an item another item you know Mike it recommends along with it you're kind of a hybrid version of a recommendation",
    "start": "1090809",
    "end": "1097230"
  },
  {
    "text": "engine but I've seen I've seen people using that for maintenance where you know a particular part goes out and",
    "start": "1097230",
    "end": "1103169"
  },
  {
    "text": "there usually are other parts associated with that part going out so when you're you know water pump goes out or when",
    "start": "1103169",
    "end": "1109530"
  },
  {
    "text": "you're hosed when you're your belt goes out you might also need to look at your water pump to make sure you the bearings are working properly or",
    "start": "1109530",
    "end": "1115330"
  },
  {
    "text": "perhaps that's the reasons the hoes went out you know ahead of time so very interesting in terms of how these",
    "start": "1115330",
    "end": "1120580"
  },
  {
    "text": "algorithms can be used in terms of you know different kinds of use cases in different industries so I mentioned",
    "start": "1120580",
    "end": "1128920"
  },
  {
    "text": "besides spark one of our newer innovations was Delta Lake and this is something that that we introduced about",
    "start": "1128920",
    "end": "1135280"
  },
  {
    "text": "a year ago and then we made it open source just in the past two months here",
    "start": "1135280",
    "end": "1140670"
  },
  {
    "text": "it's open format it provides data reliability and quality it's compatible",
    "start": "1140670",
    "end": "1146410"
  },
  {
    "text": "with the SPARC API is it essentially sits on top of a data Lake and it standardizes the data inside of the data",
    "start": "1146410",
    "end": "1152770"
  },
  {
    "text": "link and enhances it and optimizes it provides asset transactions so when you",
    "start": "1152770",
    "end": "1158860"
  },
  {
    "text": "go to write a data set it's that data doesn't get completely written the data gets repealed back rather than having",
    "start": "1158860",
    "end": "1165550"
  },
  {
    "text": "fragments of data out there so it keeps your data like cleaner and therefore more you know higher performance and it",
    "start": "1165550",
    "end": "1171370"
  },
  {
    "text": "also provides the ability to do time travel so I can go back and look at my data set at some point in the future and say what was my data set on this exact",
    "start": "1171370",
    "end": "1178480"
  },
  {
    "text": "moment at this day and that's super helpful anytime I want to be able to go back and recreate one of my experiments",
    "start": "1178480",
    "end": "1184600"
  },
  {
    "text": "or if I'm getting audited or any of those types of things and so we see customers you know with with large large",
    "start": "1184600",
    "end": "1191710"
  },
  {
    "text": "corpus of data in some cases you know 10 petabytes of data they're they're running against and you know 150",
    "start": "1191710",
    "end": "1198280"
  },
  {
    "text": "terabytes of daily day daily data coming in and you know these customers find",
    "start": "1198280",
    "end": "1203710"
  },
  {
    "text": "they can only do about two days worth of data using their old systems to be able to do analysis which was great except",
    "start": "1203710",
    "end": "1211510"
  },
  {
    "text": "for you know when you get to a Monday right if I've only got two days of data at Saturday Sunday and all of a sudden today's Monday I'm probably gonna have",
    "start": "1211510",
    "end": "1218020"
  },
  {
    "text": "very different results and so everything seems like an outlier all of a sudden and so now using Delta Lake they're able",
    "start": "1218020",
    "end": "1225880"
  },
  {
    "text": "to look at two years worth of data which provides for much more effective results and can enable them to to make much",
    "start": "1225880",
    "end": "1232840"
  },
  {
    "text": "better choices in terms of in this case it's an intrusion detection being able to identify intruders",
    "start": "1232840",
    "end": "1239450"
  },
  {
    "text": "so that's an example and then oops ml flow when we go back one here I just",
    "start": "1239450",
    "end": "1244890"
  },
  {
    "text": "wanted to talk a little bit more about ml flow so if I can get back one slide",
    "start": "1244890",
    "end": "1250640"
  },
  {
    "text": "you my keyboard doesn't seem to be doing it",
    "start": "1250640",
    "end": "1256370"
  },
  {
    "text": "there we go thank you so ml flow actually came out of our work with data",
    "start": "1256370",
    "end": "1262220"
  },
  {
    "text": "scientists where we would talk today to scientists about their process and one of the things that they mentioned was you know I I go through the step of data",
    "start": "1262220",
    "end": "1269360"
  },
  {
    "text": "prep and everything and then I go and I build a model and I run a different a bunch of different experiments and in",
    "start": "1269360",
    "end": "1275000"
  },
  {
    "text": "these cases the experiments might be using slightly different versions of the data set they might be using different",
    "start": "1275000",
    "end": "1281450"
  },
  {
    "text": "machine learning frameworks as we saw they might be you know having different tweaks in terms of the actual model that",
    "start": "1281450",
    "end": "1288410"
  },
  {
    "text": "I'm building and so when we talk to a lot of data scientist and ask them well how do you track that you know many many",
    "start": "1288410",
    "end": "1294770"
  },
  {
    "text": "of them kind of scratch their heads and said sheepishly well I use a spreadsheet for that but you know there's no shame",
    "start": "1294770",
    "end": "1300350"
  },
  {
    "text": "in that but obviously it wasn't as easy as it could be and as automated as it could be and so that was really kind of",
    "start": "1300350",
    "end": "1306710"
  },
  {
    "text": "a calling card for 4ml flow where we saw this need for something to manage the",
    "start": "1306710",
    "end": "1311960"
  },
  {
    "text": "lifecycle of a machine learning so ml flow allows you to manage the data prep",
    "start": "1311960",
    "end": "1318040"
  },
  {
    "text": "the building process of the model and the deployment of the model allows you",
    "start": "1318040",
    "end": "1323090"
  },
  {
    "text": "to see all the different experiments that you're doing be able to track those be able to recreate those on any system",
    "start": "1323090",
    "end": "1329420"
  },
  {
    "text": "and then be able to deploy those models with packages and to be able to also",
    "start": "1329420",
    "end": "1334730"
  },
  {
    "text": "convey then if you're your production team is going to put it into production which version of each library you ran it",
    "start": "1334730",
    "end": "1340400"
  },
  {
    "text": "you know for instance that you're able to get exactly the same capabilities and ml flow is one of the key points in our",
    "start": "1340400",
    "end": "1347000"
  },
  {
    "text": "integration with Amazon Sage maker so that's exactly where we're able to build",
    "start": "1347000",
    "end": "1353510"
  },
  {
    "text": "these models and then use sage maker for deployment using the ml flow integration",
    "start": "1353510",
    "end": "1359080"
  },
  {
    "text": "okay so just again to recap the data bricks unified analytics platform you know all these innovations are packaged",
    "start": "1359510",
    "end": "1365700"
  },
  {
    "text": "into the unified analytics platform you know patchy spark built a lake ml flow",
    "start": "1365700",
    "end": "1371130"
  },
  {
    "text": "plus the additional machine learning runtimes we extend that for being able",
    "start": "1371130",
    "end": "1376650"
  },
  {
    "text": "to make it easy for folks to get the data in and be able to run analytics",
    "start": "1376650",
    "end": "1382590"
  },
  {
    "text": "directly up their data Lake using Delta Lake we provide the runtime for for use",
    "start": "1382590",
    "end": "1387960"
  },
  {
    "text": "for data scientist and data engineers that they can collaborate and then also so that they can put that data into",
    "start": "1387960",
    "end": "1393630"
  },
  {
    "text": "production you can use ml flow for being able to make sure that you get that proper stuff into production and then",
    "start": "1393630",
    "end": "1399660"
  },
  {
    "text": "you know the other thing I didn't really talk about a whole lot but a lot of this is automated in terms of being able to spin up and spin down clusters and so",
    "start": "1399660",
    "end": "1407580"
  },
  {
    "text": "that whole process really makes it a lot easier in the last day to tie into some data engineers to focus much more on the",
    "start": "1407580",
    "end": "1414300"
  },
  {
    "text": "jobs that they do best without having to think about you know now I need to spin up a bigger cluster this is going to be",
    "start": "1414300",
    "end": "1419850"
  },
  {
    "text": "a big job you know much of that is automated inside of data bricks which is great and then for being able to run",
    "start": "1419850",
    "end": "1425130"
  },
  {
    "text": "that production you can simply schedule those production jobs and that allows you to to really be able to pull it all",
    "start": "1425130",
    "end": "1431310"
  },
  {
    "text": "together so you get an end-to-end ml workflow with data bricks unified analytics on AWS one last thing I'll",
    "start": "1431310",
    "end": "1438330"
  },
  {
    "text": "leave you with quickly if this is intriguing for you we have three virtual two-hour training sessions using data",
    "start": "1438330",
    "end": "1443580"
  },
  {
    "text": "breaks on AWS getting started with Apache spark data engineering and streaming analytics and machine learning",
    "start": "1443580",
    "end": "1449850"
  },
  {
    "text": "you can get these on demand you can sign up now with this bitly fitly slash",
    "start": "1449850",
    "end": "1455040"
  },
  {
    "text": "training AWS remember that URL is case-sensitive and hopefully you'll you",
    "start": "1455040",
    "end": "1461280"
  },
  {
    "text": "know be able to go and take part in that and enjoy some of the free training that we have to offer but most importantly at",
    "start": "1461280",
    "end": "1467220"
  },
  {
    "text": "this point I want to hand it off to Hannah who's going to take us through the shop runner story Hannah please take the way",
    "start": "1467220",
    "end": "1474410"
  },
  {
    "text": "thanks for him hi everyone I am going to be talking today about how the Chop",
    "start": "1474670",
    "end": "1483230"
  },
  {
    "text": "Runner have used data and machine learning to improve our shopping",
    "start": "1483230",
    "end": "1489620"
  },
  {
    "text": "experience for our customers so start us off let's talk a little bit about what",
    "start": "1489620",
    "end": "1496100"
  },
  {
    "text": "shop runner does so we like to describe ourselves as the Amazon Prime for everyone else we work with a wide array",
    "start": "1496100",
    "end": "1502430"
  },
  {
    "text": "of retail partners from high-end fashion to sports gear to household goods you",
    "start": "1502430",
    "end": "1507710"
  },
  {
    "text": "can see a sample of partners here on the slide and we work with these partners to offer benefits like free two-day",
    "start": "1507710",
    "end": "1513590"
  },
  {
    "text": "shipping and free returns to our network of users across this network of partners",
    "start": "1513590",
    "end": "1519700"
  },
  {
    "text": "despite the name of our company we don't actually handle any of the delivery or logistics our retail partners handle",
    "start": "1519700",
    "end": "1526400"
  },
  {
    "text": "that kind of logistical process we're really fundamentally a tech and data company so in exchange for these",
    "start": "1526400",
    "end": "1532940"
  },
  {
    "text": "benefits that are offered to our customers we bring a bunch of benefits to our retail partners as part of being",
    "start": "1532940",
    "end": "1538790"
  },
  {
    "text": "a member of our network so we offer benefits like new customers from across the shopping network increase conversion",
    "start": "1538790",
    "end": "1545960"
  },
  {
    "text": "rates and our order values and then a growing set of kind of technology features that we offer our partners to",
    "start": "1545960",
    "end": "1551570"
  },
  {
    "text": "help them better engage with with their customers and we can do this because we have a",
    "start": "1551570",
    "end": "1557179"
  },
  {
    "text": "really full complete picture of customers across this network that",
    "start": "1557179",
    "end": "1562670"
  },
  {
    "text": "anyone retail partner only has a really small window into but we have a",
    "start": "1562670",
    "end": "1567770"
  },
  {
    "text": "JavaScript integration as part of our integration with a new partner that lives on these partner websites",
    "start": "1567770",
    "end": "1575150"
  },
  {
    "text": "and lets us see the browsing patterns of our customers across the network so we",
    "start": "1575150",
    "end": "1583520"
  },
  {
    "text": "collect terabytes of data each day this in Vault includes really granular kind of product level browsing data and",
    "start": "1583520",
    "end": "1589580"
  },
  {
    "text": "purchase data across this network and then our retailers share product catalog",
    "start": "1589580",
    "end": "1594679"
  },
  {
    "text": "feeds with us so we get things like prices and inventory as product images descriptions for around 10 million",
    "start": "1594679",
    "end": "1602120"
  },
  {
    "text": "different products so we have this really need rich picture of our users",
    "start": "1602120",
    "end": "1608639"
  },
  {
    "text": "through the browsing and purchase data there all of this interaction data and really rich understanding of the catalog",
    "start": "1608639",
    "end": "1613740"
  },
  {
    "text": "of products from our partners and so between these two data sources we can",
    "start": "1613740",
    "end": "1619139"
  },
  {
    "text": "use our understanding of the data and our data science capabilities to better",
    "start": "1619139",
    "end": "1625380"
  },
  {
    "text": "personalize our member experience in our own shop run our interactions with them and to power products for our retail",
    "start": "1625380",
    "end": "1631710"
  },
  {
    "text": "partners that help improve these customer relationships and experiences across the board so I'm gonna talk a",
    "start": "1631710",
    "end": "1641190"
  },
  {
    "text": "little bit about what this data process looks like",
    "start": "1641190",
    "end": "1646519"
  },
  {
    "text": "so we ingest data from a whole bunch of different places so we have as I",
    "start": "1646730",
    "end": "1652169"
  },
  {
    "text": "mentioned we have product feeds from retailers we have order and shipment feeds so these tell us things our retail",
    "start": "1652169",
    "end": "1659639"
  },
  {
    "text": "partners share with us when people purchase stuff and when orders get shipped and canceled and all of those",
    "start": "1659639",
    "end": "1665580"
  },
  {
    "text": "good things and then we have the page view events Dena from from browsing so",
    "start": "1665580",
    "end": "1671250"
  },
  {
    "text": "all of those what what products you look at at different retailers across the web across art art partner Network and then",
    "start": "1671250",
    "end": "1678750"
  },
  {
    "text": "this is as you can imagine quite to the ETL adventure because we have all of",
    "start": "1678750",
    "end": "1684629"
  },
  {
    "text": "this from over 140 different retailers which means that there is a lot of kind",
    "start": "1684629",
    "end": "1689700"
  },
  {
    "text": "of integration challenges here and then we need to support a wide variety of access patterns so we need to manage the",
    "start": "1689700",
    "end": "1695549"
  },
  {
    "text": "process of moving this diva through our system we need to support reporting dashboards and ad hoc questions from for",
    "start": "1695549",
    "end": "1702240"
  },
  {
    "text": "our analytics team and our to support the variety of partner relationships and",
    "start": "1702240",
    "end": "1707639"
  },
  {
    "text": "then we want to be able to build models so I'm a data scientist that the data science team is really interested in",
    "start": "1707639",
    "end": "1713639"
  },
  {
    "text": "using this data to build predictive models that can help kind of power tools",
    "start": "1713639",
    "end": "1719970"
  },
  {
    "text": "to better support our relationships our customers and our relationship with our",
    "start": "1719970",
    "end": "1725399"
  },
  {
    "text": "retail partners so I'm going to dive a",
    "start": "1725399",
    "end": "1731789"
  },
  {
    "text": "little bit more deeply into what we do on the data science team in particular our goal overall is really",
    "start": "1731789",
    "end": "1739660"
  },
  {
    "text": "to take these rich datasets and learn the patterns that can help connect our",
    "start": "1739660",
    "end": "1744670"
  },
  {
    "text": "users with the products they love and to be able to do this at scale so we tackle",
    "start": "1744670",
    "end": "1750910"
  },
  {
    "text": "problems across a really wide array of kind of traditional machine learning",
    "start": "1750910",
    "end": "1756250"
  },
  {
    "text": "segments so we work focus a lot around personalization so how can these circus",
    "start": "1756250",
    "end": "1762760"
  },
  {
    "text": "retailers and brands that our members will really love based on what we know about what they inflict so far how can",
    "start": "1762760",
    "end": "1769840"
  },
  {
    "text": "we recommend the right products at the right time and then what can we learn about our art products in order to do",
    "start": "1769840",
    "end": "1775270"
  },
  {
    "text": "this better can we use computer vision or natural language processing from our product information to better understand",
    "start": "1775270",
    "end": "1782260"
  },
  {
    "text": "the the set of products we have available to people and then how can we",
    "start": "1782260",
    "end": "1789520"
  },
  {
    "text": "take all of these things that we've learned about our data and our users and use them to support these interactions",
    "start": "1789520",
    "end": "1796510"
  },
  {
    "text": "whether that's in our customers mobile app browser extension our website and",
    "start": "1796510",
    "end": "1802780"
  },
  {
    "text": "like email interactions with our members or through tools that we offer to our retail partners that live on our web",
    "start": "1802780",
    "end": "1808480"
  },
  {
    "text": "sites and power their interactions with customers so this is an example of some",
    "start": "1808480",
    "end": "1817690"
  },
  {
    "text": "of the tools that we use in order to do all of this our core language is place on you are mostly a Python house we work",
    "start": "1817690",
    "end": "1826150"
  },
  {
    "text": "with PI SPARC extensively on data bricks we have our data engineering team uses some Scala SPARC on data bricks as well",
    "start": "1826150",
    "end": "1833620"
  },
  {
    "text": "but the data science team is large the Python the the SPARC tools let us scale",
    "start": "1833620",
    "end": "1839440"
  },
  {
    "text": "this data which is vastly important because as much as I love scikit-learn",
    "start": "1839440",
    "end": "1845740"
  },
  {
    "text": "and all of our favorite Python modeling tools that gets really challenging when you're working with was really large",
    "start": "1845740",
    "end": "1852760"
  },
  {
    "text": "scale data high torched powers a lot of our growing deep learning exact and then",
    "start": "1852760",
    "end": "1858640"
  },
  {
    "text": "we use snowflake as a data warehouse so this is where a lot of our data lives that we then use and clean and bottle on",
    "start": "1858640",
    "end": "1866440"
  },
  {
    "text": "top of and then tools like docker and flask allows to easily deploy endpoints to integrate with the rest of",
    "start": "1866440",
    "end": "1872300"
  },
  {
    "text": "company infrastructure so this is a really key asset in our kind of data",
    "start": "1872300",
    "end": "1878720"
  },
  {
    "text": "science workflow is the ability to quickly deploy small endpoints that can serve these results and then you can go",
    "start": "1878720",
    "end": "1886190"
  },
  {
    "text": "and talk with the engineers on a product team and have a really simple",
    "start": "1886190",
    "end": "1891680"
  },
  {
    "text": "conversation about here here's how you integrate with this here's how we get these models that were building these",
    "start": "1891680",
    "end": "1897920"
  },
  {
    "text": "results that we're getting actually into products that our users can see about",
    "start": "1897920",
    "end": "1906980"
  },
  {
    "text": "another kind of key benefit of how this workflow works quickly and smoothly is",
    "start": "1906980",
    "end": "1913130"
  },
  {
    "text": "the ability to quickly test out new approaches and figure out what the right",
    "start": "1913130",
    "end": "1919130"
  },
  {
    "text": "wing of storoe elicits right so we have a bunch of data we have a bunch of models there's a lot of complicated",
    "start": "1919130",
    "end": "1924410"
  },
  {
    "text": "infrastructure Brian pointed out kind of how all of that infrastructure around is machine learning code is these a lot of",
    "start": "1924410",
    "end": "1930890"
  },
  {
    "text": "what happens and a lot of what needs to happen a lot of what can go wrong so one of the key benefits of working on AWS is",
    "start": "1930890",
    "end": "1936590"
  },
  {
    "text": "the the ease of spinning up different options and testing things out so one way that we use this a lot as using",
    "start": "1936590",
    "end": "1943100"
  },
  {
    "text": "different data stores so we use a wide array of different data stores on AWS from DynamoDB to using different RTS",
    "start": "1943100",
    "end": "1950840"
  },
  {
    "text": "instances in particular the s3 object storage and in particular it's a really",
    "start": "1950840",
    "end": "1956360"
  },
  {
    "text": "tight integration Athena bricks is super useful to us so the thing that we use all the time having a really easy kind",
    "start": "1956360",
    "end": "1963740"
  },
  {
    "text": "of back-end for storing data quickly and easily from spark and can have that",
    "start": "1963740",
    "end": "1970130"
  },
  {
    "text": "communication be really smooth is super-important for quick testing and optimization if you it's really easy in",
    "start": "1970130",
    "end": "1976910"
  },
  {
    "text": "long spark jobs if you're kind of figuring out how stuff works to run a really long thing and then notnot have",
    "start": "1976910",
    "end": "1983150"
  },
  {
    "text": "something go wrong and not know where it happens so being able to checkpoint things and save things at s3 series well",
    "start": "1983150",
    "end": "1989050"
  },
  {
    "text": "Lisa ws batch for scheduling our non-smart workloads so we have some jobs",
    "start": "1989050",
    "end": "1995270"
  },
  {
    "text": "that are in particular D planning GPU intensive and we use batch to kind of",
    "start": "1995270",
    "end": "2001090"
  },
  {
    "text": "have a smooth workflow Brian Cox that we do a lot of kind of autumn is",
    "start": "2001090",
    "end": "2009270"
  },
  {
    "text": "making all of this automatic and smooth flows and batches are great way to do",
    "start": "2009270",
    "end": "2014290"
  },
  {
    "text": "that for programs that run a docker containers and then we use GPU instances",
    "start": "2014290",
    "end": "2020080"
  },
  {
    "text": "for training computer vision and natural language processing models so this is an area and we've been investing a lot in",
    "start": "2020080",
    "end": "2026130"
  },
  {
    "text": "over the last year so that is certainly exciting opportunities on the data brick",
    "start": "2026130",
    "end": "2037299"
  },
  {
    "text": "side moving over to data Crick's had huge implications for our kind of spark",
    "start": "2037299",
    "end": "2043450"
  },
  {
    "text": "workflows the ability to have a count of AWS account that runs our data bricks",
    "start": "2043450",
    "end": "2049658"
  },
  {
    "text": "where we can have really both controls and easy to manage access that lets us",
    "start": "2049659",
    "end": "2055570"
  },
  {
    "text": "try an experiment those neat things very easily effortless effortless sharing and backups of notebooks it's hugely",
    "start": "2055570",
    "end": "2061868"
  },
  {
    "text": "important you can go and look at your notebooks anytime and comment on them and share them with others without",
    "start": "2061869",
    "end": "2067330"
  },
  {
    "text": "needing to spit up clusters just to read the comments or whatnot the ability to",
    "start": "2067330",
    "end": "2073570"
  },
  {
    "text": "leverage Spahn senses and auto-scaling for spark clusters is a great way to",
    "start": "2073570",
    "end": "2080580"
  },
  {
    "text": "easily save money on these large data jobs and then quick and easy onboarding",
    "start": "2080580",
    "end": "2086800"
  },
  {
    "text": "so the ability to have somebody new start who does not have experience running clusters and managing spark",
    "start": "2086800",
    "end": "2094530"
  },
  {
    "text": "themselves they don't need to worry too much about this you can go into data bricks and a quick tutorial on how to",
    "start": "2094530",
    "end": "2102490"
  },
  {
    "text": "how we like to organize our notebooks and how does what are good default cluster settings and all of that and",
    "start": "2102490",
    "end": "2108730"
  },
  {
    "text": "somebody's up and running which is much easier than needing to kind of manage",
    "start": "2108730",
    "end": "2114369"
  },
  {
    "text": "all that ourselves so between having the ability to do this experimentation",
    "start": "2114369",
    "end": "2120670"
  },
  {
    "text": "upfront and easily change the size of your cluster or spin up different",
    "start": "2120670",
    "end": "2127450"
  },
  {
    "text": "clusters with slightly different settings and test out how they work is hugely beneficial on the other side once",
    "start": "2127450",
    "end": "2135369"
  },
  {
    "text": "you have a thing that's working well and you want to production-wise it figuring out what that means was a lot",
    "start": "2135369",
    "end": "2140980"
  },
  {
    "text": "of is a lot of the battle right on getting a new model into production",
    "start": "2140980",
    "end": "2146440"
  },
  {
    "text": "whatever that like defining what exactly that means how to make this repeatable and Trust able and a thing that you have",
    "start": "2146440",
    "end": "2153460"
  },
  {
    "text": "faith is going to work well theater bricks jobs let you schedule a notebook",
    "start": "2153460",
    "end": "2158500"
  },
  {
    "text": "to run at a certain time certain cadence and offer alerts and kind of custom",
    "start": "2158500",
    "end": "2163690"
  },
  {
    "text": "custom clusters that can get assigned to each job which make these production level jobs super easy so you can see",
    "start": "2163690",
    "end": "2170830"
  },
  {
    "text": "we've got here on the left the a list of",
    "start": "2170830",
    "end": "2176770"
  },
  {
    "text": "a bunch of different jobs that run our infrastructure and slack alerts and a channel where we you can kind of have",
    "start": "2176770",
    "end": "2182770"
  },
  {
    "text": "the jobs post when they finish and tell you how it went and it's a good way to keep an eye on jobs that run regularly",
    "start": "2182770",
    "end": "2189510"
  },
  {
    "text": "the way that we like to set this up is to package our code our modelling code are like data processing and modeling",
    "start": "2189510",
    "end": "2196330"
  },
  {
    "text": "code into share Python libraries and then install them in data bricks as a",
    "start": "2196330",
    "end": "2202840"
  },
  {
    "text": "shared library that you can then attach to an interactive cluster to try something out or attach to a job to run",
    "start": "2202840",
    "end": "2209950"
  },
  {
    "text": "in production one of the kind of pinpoints that we head along the way in doing this was that once you have a lot",
    "start": "2209950",
    "end": "2217869"
  },
  {
    "text": "of jobs and you have libraries that are attached to many different jobs it",
    "start": "2217869",
    "end": "2223990"
  },
  {
    "text": "becomes challenging to go through when you update your job and manually swap",
    "start": "2223990",
    "end": "2229510"
  },
  {
    "text": "out which the version of the library that you're using we wanted to be able",
    "start": "2229510",
    "end": "2234700"
  },
  {
    "text": "to do this from kind of CICE tools so we want to take advantage of the infrastructure that our company has set",
    "start": "2234700",
    "end": "2240790"
  },
  {
    "text": "up to do things like run unit tests and fare files things you want to verify",
    "start": "2240790",
    "end": "2246760"
  },
  {
    "text": "before pushing a new version of a library into production but then we also",
    "start": "2246760",
    "end": "2252280"
  },
  {
    "text": "wanted to be able to automate the okay this library is now in production I want to go and update all of those jobs to",
    "start": "2252280",
    "end": "2257619"
  },
  {
    "text": "use this new library so we wrote a tool called a beruete that handles this for",
    "start": "2257619",
    "end": "2262930"
  },
  {
    "text": "us where you can pass it's a little command-line tool that takes an egg and",
    "start": "2262930",
    "end": "2270310"
  },
  {
    "text": "or jar either a Python or Scala and uploads it to data bricks and those",
    "start": "2270310",
    "end": "2275799"
  },
  {
    "text": "and according to settings that you can configure goes and updates all of the jobs you want to update and to swap out",
    "start": "2275799",
    "end": "2282579"
  },
  {
    "text": "the versions if this sounds like a thing that's useful to you we open sourced this package and it's available here",
    "start": "2282579",
    "end": "2288880"
  },
  {
    "text": "that github link is below it's been a huge benefit to us in our kind of",
    "start": "2288880",
    "end": "2295690"
  },
  {
    "text": "production workflows to have this all be automated and not a thing that we need to worry about dated a cool so now I'm",
    "start": "2295690",
    "end": "2304809"
  },
  {
    "text": "gonna talk through some specific products that we've built so I times kind of in general about our workflow",
    "start": "2304809",
    "end": "2310240"
  },
  {
    "text": "and about the types of problems we want to tackle and so now we're going to talk about some specific products that we've",
    "start": "2310240",
    "end": "2316119"
  },
  {
    "text": "built so looking at product recommendations and in particular",
    "start": "2316119",
    "end": "2321759"
  },
  {
    "text": "looking at a similar products approach so there's many different things that you can do with recommendations there",
    "start": "2321759",
    "end": "2327400"
  },
  {
    "text": "many different ways you can interpret that goal to recommend products but the kind of the first place that we started",
    "start": "2327400",
    "end": "2333579"
  },
  {
    "text": "was let's say we have a product that we knew somebody likes and we want to offer",
    "start": "2333579",
    "end": "2339220"
  },
  {
    "text": "them similar products and we're going to start off doing this with a collaborative filtering approach so this",
    "start": "2339220",
    "end": "2345309"
  },
  {
    "text": "is your basic people who view this people who liked this product also liked",
    "start": "2345309",
    "end": "2352059"
  },
  {
    "text": "to this other product so you can see here that we have a set up with people",
    "start": "2352059",
    "end": "2360670"
  },
  {
    "text": "on the left and products along the top and my check mark here indicates that",
    "start": "2360670",
    "end": "2366940"
  },
  {
    "text": "that person interacted with that product so if we look at this example outlined in black we have oops we have these",
    "start": "2366940",
    "end": "2376809"
  },
  {
    "text": "products that this person this product was interacted with by these two people",
    "start": "2376809",
    "end": "2382329"
  },
  {
    "text": "and so if we go look at this product in green over here the same people",
    "start": "2382329",
    "end": "2387630"
  },
  {
    "text": "interacted with this product as interacted with this product that suggests that those products are likely",
    "start": "2387630",
    "end": "2393880"
  },
  {
    "text": "similar in it the same people are likely interested in them so if somebody knew who we don't know anything else about",
    "start": "2393880",
    "end": "2399849"
  },
  {
    "text": "comes and interacts with this product this dress they're likely to also like this tank top this",
    "start": "2399849",
    "end": "2406930"
  },
  {
    "text": "on the other hand has a completely disjoint set of people who like that",
    "start": "2406930",
    "end": "2412480"
  },
  {
    "text": "product to interacting with that correct so it's unlikely that somebody who likes this product will also like this one",
    "start": "2412480",
    "end": "2418200"
  },
  {
    "text": "this is super simple and kind of straightforward way to think about it and then you can define this measurement",
    "start": "2418200",
    "end": "2425859"
  },
  {
    "text": "so here I gave examples of the exact same set of people or completely destroyed set of people obviously in",
    "start": "2425859",
    "end": "2432069"
  },
  {
    "text": "reality this were mostly going to be a little bit more funny but you can define",
    "start": "2432069",
    "end": "2437290"
  },
  {
    "text": "that distance using a metric called cosine similarity which measures the distance between these two vectors if",
    "start": "2437290",
    "end": "2444040"
  },
  {
    "text": "you have these as vectors of zeros and ones you can take the cosine similarity between them as a measure of how far",
    "start": "2444040",
    "end": "2450579"
  },
  {
    "text": "apart those two vectors are there are other more complicated things you can do",
    "start": "2450579",
    "end": "2456790"
  },
  {
    "text": "here you can take this matrix and do matrix factorization on it you can use",
    "start": "2456790",
    "end": "2463349"
  },
  {
    "text": "different you can incorporate site information about the users or about the",
    "start": "2463349",
    "end": "2468369"
  },
  {
    "text": "products we have done some of those things some places there's a bunch of different versions of this that we use",
    "start": "2468369",
    "end": "2473559"
  },
  {
    "text": "and different for slightly different purposes at the moment those are kind of the core idea and was one of the first recommendation products that we put",
    "start": "2473559",
    "end": "2480640"
  },
  {
    "text": "together so this is a little bit of what that pipeline looks like so we start in",
    "start": "2480640",
    "end": "2488040"
  },
  {
    "text": "snowflake which is this is where our data lives this is our data warehouse we're gonna move into a detailer key",
    "start": "2488040",
    "end": "2494589"
  },
  {
    "text": "notebook and build a user an item matrix in SPARC and then use the Komsomol",
    "start": "2494589",
    "end": "2502329"
  },
  {
    "text": "entities function and spark to calculate the cosine similarity between different item vectors and then we're gonna take",
    "start": "2502329",
    "end": "2509440"
  },
  {
    "text": "we're gonna do a big batch job and score all of these products and then we're gonna write out the top I don't know 100",
    "start": "2509440",
    "end": "2516609"
  },
  {
    "text": "most similar products for each product to an RDS database we're gonna use a",
    "start": "2516609",
    "end": "2522309"
  },
  {
    "text": "post rest RDS instance and write out this big table mapping products to most",
    "start": "2522309",
    "end": "2529450"
  },
  {
    "text": "similar products and the reason that we decided to do this in a relational database here was that we wanted to be",
    "start": "2529450",
    "end": "2536380"
  },
  {
    "text": "able to also filter these results along certain so we wanted to be able to include",
    "start": "2536380",
    "end": "2541500"
  },
  {
    "text": "information like um and recently what product category is so these are I want",
    "start": "2541500",
    "end": "2549240"
  },
  {
    "text": "to recommend I'm gonna look at only similar shirts or I want to look at just only show dresses that are similar to",
    "start": "2549240",
    "end": "2555900"
  },
  {
    "text": "this shirt because these are all things that you might want to do depending on the particular interaction with the user",
    "start": "2555900",
    "end": "2561359"
  },
  {
    "text": "that you're doing so we wanted to be able to empower the product people to decide what sorts of filters make sense",
    "start": "2561359",
    "end": "2568140"
  },
  {
    "text": "in their scenario so you can include all that side information or in a relational database and then have your API accept",
    "start": "2568140",
    "end": "2577020"
  },
  {
    "text": "these kinds of filters and pull out the top products that are most useful in whatever given scenario it's been really",
    "start": "2577020",
    "end": "2584880"
  },
  {
    "text": "useful to us to kind of train frame products in this way of building out capabilities as much as possible and",
    "start": "2584880",
    "end": "2590099"
  },
  {
    "text": "that are then used in multiple places around the org so we have the r-class",
    "start": "2590099",
    "end": "2596310"
  },
  {
    "text": "API and the may also write results out to snowflake in order to do analysis and",
    "start": "2596310",
    "end": "2601920"
  },
  {
    "text": "monitoring and keep an eye on the process over time right so to look at",
    "start": "2601920",
    "end": "2611040"
  },
  {
    "text": "that in a little bit of what these products might look like once we actually get them integrated into places",
    "start": "2611040",
    "end": "2617970"
  },
  {
    "text": "where the customer might see them so this is an example of an email campaign that we run where when somebody is",
    "start": "2617970",
    "end": "2624740"
  },
  {
    "text": "interacted with a particular product a lot we can then send them an email it's",
    "start": "2624740",
    "end": "2630510"
  },
  {
    "text": "like hey you looked at this product maybe you like these other products that are similar I mentioned that we also we",
    "start": "2630510",
    "end": "2640140"
  },
  {
    "text": "do a bunch of different versions of this one another version of this is instead of at a product level we can do it at a",
    "start": "2640140",
    "end": "2646290"
  },
  {
    "text": "retailer level so maybe somebody has joined shop runner and they're new to shop runner and so they don't know yet",
    "start": "2646290",
    "end": "2653640"
  },
  {
    "text": "who all of our printers are so we want to send them email see like hey you",
    "start": "2653640",
    "end": "2658820"
  },
  {
    "text": "we've seen that you've really likes Neiman Marcus but we want to let you know about other places in our network",
    "start": "2658820",
    "end": "2664619"
  },
  {
    "text": "where you also might like to shop and so you can use this API to quickly grab",
    "start": "2664619",
    "end": "2669960"
  },
  {
    "text": "similar retailers to a particular one that we",
    "start": "2669960",
    "end": "2674720"
  },
  {
    "text": "so now I'm going to talk through another example and this is a little bit more of a kind of data capability so this is a",
    "start": "2678559",
    "end": "2685259"
  },
  {
    "text": "little bit lower level than super product facing but has enabled a lot of",
    "start": "2685259",
    "end": "2692190"
  },
  {
    "text": "really cool products and improvements and a lot of the products that are exist under hood so basically we wanted to be",
    "start": "2692190",
    "end": "2700769"
  },
  {
    "text": "able to have a better kind of set of data about our users so we have a whole",
    "start": "2700769",
    "end": "2706740"
  },
  {
    "text": "bunch of data but it wasn't very well organized and one of the kind of ways in",
    "start": "2706740",
    "end": "2711749"
  },
  {
    "text": "which it was difficult organizes that there are a bunch of different identifiers for people so there's a member ID that's like the person's the",
    "start": "2711749",
    "end": "2718890"
  },
  {
    "text": "shop runner user ID right when you sign up for a shopback membership you get one but when you're browsing on the web",
    "start": "2718890",
    "end": "2726109"
  },
  {
    "text": "that's not always attached right you don't have that information in the",
    "start": "2726109",
    "end": "2731190"
  },
  {
    "text": "browser so what you get is instead is cookies so we have our cookie here that",
    "start": "2731190",
    "end": "2737130"
  },
  {
    "text": "you see attached to your web page as your as your browsing on the web so here we have a person who is browsing on a",
    "start": "2737130",
    "end": "2744269"
  },
  {
    "text": "website one day and they're looking at several different products and then they find one that they really like and they want to buy and on the checkout page",
    "start": "2744269",
    "end": "2752279"
  },
  {
    "text": "there's an option to sign in to shop runner and get your free two-day shipping with that product so they're like yes I want to get my free two-day",
    "start": "2752279",
    "end": "2759690"
  },
  {
    "text": "shipping so I'm going to sign into my shop on our account and then make this purchase so at this point once you sign",
    "start": "2759690",
    "end": "2765630"
  },
  {
    "text": "in on that day you have and identifier attached to that section that says this",
    "start": "2765630",
    "end": "2771329"
  },
  {
    "text": "is this member so we know that this member and this cookie belong to the same person and then on another day is",
    "start": "2771329",
    "end": "2779160"
  },
  {
    "text": "sitting here browsing on a different website and on a different partner and again we have a cookie attached but you",
    "start": "2779160",
    "end": "2785910"
  },
  {
    "text": "have a different company this day and then same process you look at a bunch of different products you find one that you like and you purchase it you sign in you",
    "start": "2785910",
    "end": "2794190"
  },
  {
    "text": "get your member ID attached and so now we know that this cookie also belongs to this person what if we just do take our",
    "start": "2794190",
    "end": "2802980"
  },
  {
    "text": "data Roz is in the system currently the only things attached to this member",
    "start": "2802980",
    "end": "2809190"
  },
  {
    "text": "are the two items that they purchased and the fact that they viewed those two items but none of these other products",
    "start": "2809190",
    "end": "2815400"
  },
  {
    "text": "they looked at are attached to that member and we want to be able to say that all of those views belong to the",
    "start": "2815400",
    "end": "2820650"
  },
  {
    "text": "same person so in order to do this we do",
    "start": "2820650",
    "end": "2826010"
  },
  {
    "text": "um we use an identity graph so here we",
    "start": "2826010",
    "end": "2831060"
  },
  {
    "text": "gather those IDs from our event data we build a graph linking between 19 and",
    "start": "2831060",
    "end": "2838200"
  },
  {
    "text": "here we use data breaks and we use a library called reference and then we find the connected components so we find",
    "start": "2838200",
    "end": "2844650"
  },
  {
    "text": "all the IDS that belong to particular people and then this graph feeds into",
    "start": "2844650",
    "end": "2850290"
  },
  {
    "text": "our shopper profile pipeline where we take these identity graphs we take data",
    "start": "2850290",
    "end": "2857640"
  },
  {
    "text": "from s3 and you take the effort snowflake we kind of organize this data into a reasonable way we arguments with",
    "start": "2857640",
    "end": "2864480"
  },
  {
    "text": "some shopper level modelling using SPARQL also our data bricks and then we store all of this in a dynamo DB",
    "start": "2864480",
    "end": "2870660"
  },
  {
    "text": "database and also in snowflake and so this supports the dynamo DB database",
    "start": "2870660",
    "end": "2875730"
  },
  {
    "text": "supports our really quick access pattern for an API and snowflake supports our",
    "start": "2875730",
    "end": "2881280"
  },
  {
    "text": "analytics pipelines last thing I'm going to talk about is a trending pot so for",
    "start": "2881280",
    "end": "2889590"
  },
  {
    "text": "district which is our mobile shopping app we wanted an engaging personalized feeds as a kind of landing page on this",
    "start": "2889590",
    "end": "2896070"
  },
  {
    "text": "website on this app and so for this we want is any way to identify products",
    "start": "2896070",
    "end": "2901320"
  },
  {
    "text": "that were trending so what we've done here is we've used a spark job to kind of process all over the browsing data",
    "start": "2901320",
    "end": "2909810"
  },
  {
    "text": "for all of our products over the previous week and then over the current week and then identify these spikes so",
    "start": "2909810",
    "end": "2917760"
  },
  {
    "text": "we do some statistical stuff which is always good fun and identify which",
    "start": "2917760",
    "end": "2923130"
  },
  {
    "text": "products are significantly more popular this week than there are last week and so you get to see all sorts of fun stuff",
    "start": "2923130",
    "end": "2928800"
  },
  {
    "text": "like this like with this like sports teams that have just want a big game are always trending things like that and",
    "start": "2928800",
    "end": "2936020"
  },
  {
    "text": "then we use this both as trending is an example of our mobile app with the",
    "start": "2936020",
    "end": "2942459"
  },
  {
    "text": "trending feed going by there and then we also can use it for partner websites as a widget that we'd like offer is",
    "start": "2942459",
    "end": "2948579"
  },
  {
    "text": "capability where they can post things that are trending within their store and",
    "start": "2948579",
    "end": "2955229"
  },
  {
    "text": "then some other stuff we're working on just as little teasers so we working",
    "start": "2955229",
    "end": "2960639"
  },
  {
    "text": "with visual similarity with Astra Butte labelling labeling and taxonomy",
    "start": "2960639",
    "end": "2965709"
  },
  {
    "text": "classifications are taking these product images and descriptions and using learning to classify where they belong",
    "start": "2965709",
    "end": "2972789"
  },
  {
    "text": "in the taxonomy or what kind of attributes of that image are we're doing",
    "start": "2972789",
    "end": "2978729"
  },
  {
    "text": "some work on remodeling and other fun stuff so that's gives you a taste of the",
    "start": "2978729",
    "end": "2987099"
  },
  {
    "text": "types of things that we work on and I'm not gonna hand it back to Joe chun-yan for some Q&A thanks a lot I know we have",
    "start": "2987099",
    "end": "2994689"
  },
  {
    "text": "been very busy in the Q&A box here this was very interesting thanks a lot for",
    "start": "2994689",
    "end": "3000749"
  },
  {
    "text": "giving us a peek behind the scenes actions now let's go to the questions",
    "start": "3000749",
    "end": "3007099"
  },
  {
    "text": "how big how do your pipeline clusters how fast do you process your data so",
    "start": "3008659",
    "end": "3022799"
  },
  {
    "text": "that's a question that varies a lot we have a bunch of different pipelines that process things different sizes of data",
    "start": "3022799",
    "end": "3028769"
  },
  {
    "text": "at different speeds um I think the biggest cluster that imma run is in a",
    "start": "3028769",
    "end": "3036569"
  },
  {
    "text": "job as 64 nodes um a lot of our really big a really big",
    "start": "3036569",
    "end": "3042119"
  },
  {
    "text": "batch job that processes all of our data might take 12 to 14 hours but it's doing",
    "start": "3042119",
    "end": "3048239"
  },
  {
    "text": "a lot of processing on a lot of data um and those don't run every night",
    "start": "3048239",
    "end": "3053339"
  },
  {
    "text": "obviously so different jobs run on different Cadence's so there's a lot of",
    "start": "3053339",
    "end": "3058349"
  },
  {
    "text": "variability there some idea maybe thank you",
    "start": "3058349",
    "end": "3064709"
  },
  {
    "text": "one more when you provide recommendations of other similar products aren't you advertising for",
    "start": "3064709",
    "end": "3070589"
  },
  {
    "text": "competitors so depends where we do that so we're",
    "start": "3070589",
    "end": "3076410"
  },
  {
    "text": "careful about the where we do what right so there are cases where we will",
    "start": "3076410",
    "end": "3082220"
  },
  {
    "text": "advertise only within retailer so there are like some emails that we send if",
    "start": "3082220",
    "end": "3089099"
  },
  {
    "text": "you've been looking at our product bloomingdales we will only recommend other Bloomingdale's products there are other cases where retailers have agreed",
    "start": "3089099",
    "end": "3095490"
  },
  {
    "text": "to be part of a group where they are okay if other product people's products",
    "start": "3095490",
    "end": "3102330"
  },
  {
    "text": "are recommended because they will also be recommended for other people's if that makes sense so it's all kind of innovated with",
    "start": "3102330",
    "end": "3110070"
  },
  {
    "text": "retailers how they want to play that out got it thank you",
    "start": "3110070",
    "end": "3116060"
  },
  {
    "text": "they keep coming are there specific metrics shopper nerd uses to assess how",
    "start": "3116060",
    "end": "3122520"
  },
  {
    "text": "good recommendations are MRRR NBC G or what are the metrics that you use yeah",
    "start": "3122520",
    "end": "3130619"
  },
  {
    "text": "so this is a thorny problem right evaluating recommendation engines is",
    "start": "3130619",
    "end": "3135839"
  },
  {
    "text": "really hard our we've used a number of different offline metrics at different",
    "start": "3135839",
    "end": "3141780"
  },
  {
    "text": "points um some of them use we've used",
    "start": "3141780",
    "end": "3146849"
  },
  {
    "text": "some like ranking metrics sometimes I to be honest like don't have one that I",
    "start": "3146849",
    "end": "3153270"
  },
  {
    "text": "love I've never really felt like I've been able to super accurately evaluate a",
    "start": "3153270",
    "end": "3160670"
  },
  {
    "text": "recommender offline I think really this is a case where you need to get it in",
    "start": "3160670",
    "end": "3166050"
  },
  {
    "text": "front of people and you need to get user feedback so we kind of took the approach",
    "start": "3166050",
    "end": "3171540"
  },
  {
    "text": "of using taking some offline metrics and",
    "start": "3171540",
    "end": "3176550"
  },
  {
    "text": "making sure they didn't look completely garbage and then keeping a really fast iteration cycle and getting it in front",
    "start": "3176550",
    "end": "3183150"
  },
  {
    "text": "of users as quickly as possible and then saying okay people interact more with this so it's it's better got it thank",
    "start": "3183150",
    "end": "3191700"
  },
  {
    "text": "you well let's give you a little bit of break and a question for one",
    "start": "3191700",
    "end": "3197400"
  },
  {
    "text": "how does Delta Lake work with data provenance does it keep all of the data",
    "start": "3197400",
    "end": "3204060"
  },
  {
    "text": "or only the changes in the like my fight yeah great question so",
    "start": "3204060",
    "end": "3211520"
  },
  {
    "text": "Delta Lake sits on top of the data Lake and manages the data in there with",
    "start": "3211520",
    "end": "3217200"
  },
  {
    "text": "certain tables and so you can definitely do the ability to see different versions",
    "start": "3217200",
    "end": "3224700"
  },
  {
    "text": "what we call time travel of up your data so you go back and look at for any of",
    "start": "3224700",
    "end": "3230190"
  },
  {
    "text": "these so in the case of Hannah if she wanted to go but I can take a look at well Hannah you know if any customer",
    "start": "3230190",
    "end": "3236819"
  },
  {
    "text": "wanted to use this you know and to see what was the data set yesterday that we were running for our recommendations",
    "start": "3236819",
    "end": "3242630"
  },
  {
    "text": "Delta would allow you to go back and do that in terms of overall data governance",
    "start": "3242630",
    "end": "3247859"
  },
  {
    "text": "you know going back to sources of data and things like that it's not going to offer that so how the data got into",
    "start": "3247859",
    "end": "3254280"
  },
  {
    "text": "Delta like where it came from we typically partner for that further back governance but it is interesting to",
    "start": "3254280",
    "end": "3261000"
  },
  {
    "text": "note that when you put ml flow and Delta Lake together you know you can track your machine learning algorithms you can",
    "start": "3261000",
    "end": "3267660"
  },
  {
    "text": "track how those process the data and using Delta you can track you know which version of the data so it gives you a",
    "start": "3267660",
    "end": "3274319"
  },
  {
    "text": "very powerful ability to at least be able to audit your you know machine learning processes",
    "start": "3274319",
    "end": "3280549"
  },
  {
    "text": "thank you Brian could you please talk briefly about data breaks unified",
    "start": "3280549",
    "end": "3287880"
  },
  {
    "text": "analytics platform ml flow and staging care integration please yeah so the same",
    "start": "3287880",
    "end": "3293999"
  },
  {
    "text": "to make your integration is very much part of the ml flow ability to put jobs",
    "start": "3293999",
    "end": "3299249"
  },
  {
    "text": "into production so you have a lot of different ways that you can do that you know Hana has depicted some of this in",
    "start": "3299249",
    "end": "3306900"
  },
  {
    "text": "terms of what they're doing with dynamo and being able to get data out and available to the website for for fast",
    "start": "3306900",
    "end": "3313229"
  },
  {
    "text": "recommendations you know but that's the main flow of our of our integration with",
    "start": "3313229",
    "end": "3319170"
  },
  {
    "text": "sage maker and the other thing is the training that I had mentioned earlier in",
    "start": "3319170",
    "end": "3325920"
  },
  {
    "text": "my last slide also depicts some of the integration with sage maker so that's a great place to go and actually see that",
    "start": "3325920",
    "end": "3332699"
  },
  {
    "text": "and learn more about it as well you can actually see you know what the the technical aspects are of doing that",
    "start": "3332699",
    "end": "3338849"
  },
  {
    "text": "integration thank you Brian we'll get to one last question maybe a",
    "start": "3338849",
    "end": "3347099"
  },
  {
    "text": "couple and please feel free to we'll we'll make sure that we follow up with",
    "start": "3347099",
    "end": "3352650"
  },
  {
    "text": "everyone else that the question that we didn't get to and make sure that they get routed properly back to Hana now",
    "start": "3352650",
    "end": "3359489"
  },
  {
    "text": "please are you processing one terabyte of data per retailer and how often do",
    "start": "3359489",
    "end": "3366689"
  },
  {
    "text": "you update the refresh the models yeah so I believe the terabyte number is not",
    "start": "3366689",
    "end": "3374749"
  },
  {
    "text": "specific to a retailer but rather rather across although it's also been a whilst",
    "start": "3374749",
    "end": "3381660"
  },
  {
    "text": "I pulled that number so I don't know I he's probably a little bit larger today",
    "start": "3381660",
    "end": "3387499"
  },
  {
    "text": "on the eb freshing point it's again a thing that varies per model so there are",
    "start": "3387499",
    "end": "3393390"
  },
  {
    "text": "some models that where the cadence is pretty quick so the trending algorithm",
    "start": "3393390",
    "end": "3398609"
  },
  {
    "text": "right makes sense to refresh really frequently so that happens at least once a day the recommendations some of the",
    "start": "3398609",
    "end": "3407189"
  },
  {
    "text": "kind of more data intensive ones we refresh once a week because those change much more slowly right the",
    "start": "3407189",
    "end": "3413520"
  },
  {
    "text": "interactions we don't expect the distribution of interactions to vary wildly week to week because we're interested they're not in changing day",
    "start": "3413520",
    "end": "3420490"
  },
  {
    "text": "today patterns but in long-term kind of preferences so you try to take into",
    "start": "3420490",
    "end": "3426100"
  },
  {
    "text": "account kind of the costs right like how expensive is it to train the thing and how much value you expect to get out of",
    "start": "3426100",
    "end": "3433120"
  },
  {
    "text": "having an updated more frequently and balanced those four particular use cases a lot of thanks a lot",
    "start": "3433120",
    "end": "3440680"
  },
  {
    "text": "one more for you please when recommending products across different",
    "start": "3440680",
    "end": "3446110"
  },
  {
    "text": "vendors do you have any issue related to which of the vendors you prefer show",
    "start": "3446110",
    "end": "3451450"
  },
  {
    "text": "first which you show last how do you rank them how do you handle this ranking",
    "start": "3451450",
    "end": "3456820"
  },
  {
    "text": "problem it's not that much to be honest",
    "start": "3456820",
    "end": "3461980"
  },
  {
    "text": "so then there are it's it's going to be",
    "start": "3461980",
    "end": "3469150"
  },
  {
    "text": "kind of use case specific logic depending on what makes sense in a particular scenario that's both what",
    "start": "3469150",
    "end": "3475120"
  },
  {
    "text": "that kind of balancing what's best for the end user and what's best for our retail partners and we just kind of",
    "start": "3475120",
    "end": "3481870"
  },
  {
    "text": "always have that conversation goddess",
    "start": "3481870",
    "end": "3486910"
  },
  {
    "text": "one last eco question I can't help myself and then we'll close comparing",
    "start": "3486910",
    "end": "3493450"
  },
  {
    "text": "item vectors using cosine similarity in a naive way would be offense square",
    "start": "3493450",
    "end": "3499630"
  },
  {
    "text": "complexity how do you pre process items that you compare the like and how do you",
    "start": "3499630",
    "end": "3505990"
  },
  {
    "text": "streamline that how do you handle that complexity yeah so we handle in different ways in a couple different places um so the kind",
    "start": "3505990",
    "end": "3515320"
  },
  {
    "text": "of naive cosine similarity where you have these really sparse vectors there's the method management icon",
    "start": "3515320",
    "end": "3523150"
  },
  {
    "text": "similarities and spark does was a implements algorithm called dim sums",
    "start": "3523150",
    "end": "3528430"
  },
  {
    "text": "like openness I don't remember which who wrote it somebody a particular company",
    "start": "3528430",
    "end": "3534090"
  },
  {
    "text": "implemented it and contribute back to spark that does a approximate nearest",
    "start": "3534090",
    "end": "3540250"
  },
  {
    "text": "neighbor search basically in in a particular way there are other cases for you how we have shorter",
    "start": "3540250",
    "end": "3546640"
  },
  {
    "text": "these vectors and in those cases we've used something like annoying which is a Python library that does that",
    "start": "3546640",
    "end": "3551980"
  },
  {
    "text": "approximate nearest neighbor search basically once you get to a certain scale you need to do an approximate thing instead of a naive and squared",
    "start": "3551980",
    "end": "3557289"
  },
  {
    "text": "comparison but there's a lot of good ways to do that got it have you published any papers or blogs",
    "start": "3557289",
    "end": "3565109"
  },
  {
    "text": "regarding the recommender systems that you have implemented like this a couple",
    "start": "3565109",
    "end": "3570490"
  },
  {
    "text": "of libraries that you mentioned like while answering this question um I have",
    "start": "3570490",
    "end": "3577299"
  },
  {
    "text": "not done anything specific about recommenders yeah Oh No thank you maybe",
    "start": "3577299",
    "end": "3588309"
  },
  {
    "text": "we can follow up later on so thanks a lot thank you everyone for attending",
    "start": "3588309",
    "end": "3594250"
  },
  {
    "text": "today's webinar please remember to to stay connected and complete the brief",
    "start": "3594250",
    "end": "3600309"
  },
  {
    "text": "survey at the conclusion of this webinar we look forward to supporting you in current and future projects I would",
    "start": "3600309",
    "end": "3607480"
  },
  {
    "text": "especially like to thank Brian and Hannah for taking out the time and giving us this amazing deep dive if",
    "start": "3607480",
    "end": "3615789"
  },
  {
    "text": "questions are any measure of how this went it's been one of the best ones thank you",
    "start": "3615789",
    "end": "3623230"
  },
  {
    "text": "again everyone and have a great day",
    "start": "3623230",
    "end": "3627750"
  },
  {
    "text": "you",
    "start": "3633619",
    "end": "3635680"
  }
]
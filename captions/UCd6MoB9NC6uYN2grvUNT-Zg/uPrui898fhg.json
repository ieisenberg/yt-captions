[
  {
    "start": "0",
    "end": "44000"
  },
  {
    "text": "hi everyone thanks for joining us here today so Greg tonight today we'll talk",
    "start": "1070",
    "end": "6870"
  },
  {
    "text": "to you about intersection at the center of this Venn diagram will talk to you",
    "start": "6870",
    "end": "12059"
  },
  {
    "text": "about Netflix we'll talk about that a double yes of course and we'll talk about Cassandra specifically we'll talk",
    "start": "12059",
    "end": "17670"
  },
  {
    "text": "how Netflix uses Cassandra as a persistence layer to store data on top of AWS so what we're going to do is I'll",
    "start": "17670",
    "end": "24960"
  },
  {
    "text": "start with a little introduction do a little bit over via netflix i'll hand it over to Greg do a deeper dive into our",
    "start": "24960",
    "end": "31619"
  },
  {
    "text": "cassandra operating practices and how we optimize cassandra for our needs and they're not closed it up with some",
    "start": "31619",
    "end": "36809"
  },
  {
    "text": "performance evaluation and then briefly talk about some of our open source offerings that are related to Cassandra",
    "start": "36809",
    "end": "44180"
  },
  {
    "start": "44000",
    "end": "44000"
  },
  {
    "text": "so if you don't know who Netflix is we allow more than 30 people 30 million",
    "start": "44180",
    "end": "49920"
  },
  {
    "text": "people worldwide enjoy TV and movie entertainment at subscription service so",
    "start": "49920",
    "end": "56610"
  },
  {
    "start": "56000",
    "end": "56000"
  },
  {
    "text": "why cloud some background information sometime in 2008 and Netflix experienced",
    "start": "56610",
    "end": "62850"
  },
  {
    "text": "about one week outage that at the root cause of it was a data corruption in the",
    "start": "62850",
    "end": "68670"
  },
  {
    "text": "Oracle database shortly after that the popularity of our subscription service",
    "start": "68670",
    "end": "74700"
  },
  {
    "text": "started growing at a very rapid pace this graph illustrates the pace at which it was growing and early in 2009 we very",
    "start": "74700",
    "end": "81869"
  },
  {
    "text": "quickly realized that we just would not be able to keep up with the pace in terms of building up the data center",
    "start": "81869",
    "end": "87479"
  },
  {
    "text": "capacity moreover we realized we were not in a business of building our data",
    "start": "87479",
    "end": "92700"
  },
  {
    "text": "center capacity we're in the business of delivering entertainment to people in terms of streaming experience we didn't",
    "start": "92700",
    "end": "99720"
  },
  {
    "text": "have the expertise capability or motivation to start building out physical data centers who can a power wrecking app servers etc so we looked",
    "start": "99720",
    "end": "109920"
  },
  {
    "text": "and decided to migrate to the biggest public cloud provider out there amazon web services in over last two and a half",
    "start": "109920",
    "end": "117299"
  },
  {
    "text": "three years that's exactly what we've been doing we've been slowly migrating bit by bit our infrastructure and product components from data center into",
    "start": "117299",
    "end": "124409"
  },
  {
    "text": "the cloud we couldn't just pull it as a binary switch that had to be a lot of transitional infrastructure to be built",
    "start": "124409",
    "end": "130739"
  },
  {
    "text": "up internally very fair to this process as Roman riding those of you unfamiliar with the term this is",
    "start": "130739",
    "end": "136200"
  },
  {
    "text": "when you ride two horses one leg on each on each horse somewhat tricky case and",
    "start": "136200",
    "end": "141420"
  },
  {
    "text": "sometimes have a painful process and when we were migrating our",
    "start": "141420",
    "end": "146730"
  },
  {
    "text": "infrastructure the stateless applications went first because those were easiest to migrate and data is the",
    "start": "146730",
    "end": "152220"
  },
  {
    "text": "trickiest want to migrate so we had to build sometimes one way mirroring data",
    "start": "152220",
    "end": "158069"
  },
  {
    "text": "pipeline sometimes they even built a multi master mirroring pipelines which were definitely part of their the",
    "start": "158069",
    "end": "165180"
  },
  {
    "text": "trickiest part so at this point Netflix is where I'm having issues my clicker",
    "start": "165180",
    "end": "171329"
  },
  {
    "text": "here there we go nathless all of our services are pretty much running in in the cloud there are some small billing",
    "start": "171329",
    "end": "178349"
  },
  {
    "text": "and payments related components and data sets that are still in data center and we're working on making socks and PCI",
    "start": "178349",
    "end": "185879"
  },
  {
    "text": "compliance for those components and when that's done will migrate the remaining",
    "start": "185879",
    "end": "191639"
  },
  {
    "text": "infrastructure all of the international product currently is fully cloud-based that means if our data center for any",
    "start": "191639",
    "end": "198180"
  },
  {
    "text": "reason goes down or network to it is severed all of international customers will be able to stream movies without",
    "start": "198180",
    "end": "204389"
  },
  {
    "text": "any interruption so enough is the overview at this point I'd like to turn",
    "start": "204389",
    "end": "210870"
  },
  {
    "text": "it over to Greg who runs our dev ops team and he'll take a deeper into what we do this Cassandra thank you yeah",
    "start": "210870",
    "end": "217590"
  },
  {
    "text": "quick show of hands how many people actually use Cassandra and AWS very nice and so my name is Gregor work I am a",
    "start": "217590",
    "end": "225000"
  },
  {
    "text": "member of the Cassandra dev ops team and we are responsible if you attended either of Adrian cockcroft a che",
    "start": "225000",
    "end": "231959"
  },
  {
    "text": "presentations if you're lucky enough to get into either of those in the last couple days it's probably surprised when you hear to you that we have a dedicated",
    "start": "231959",
    "end": "237720"
  },
  {
    "text": "somewhat centralized operations team in netflix and and that's essentially what my team is we are responsible for all",
    "start": "237720",
    "end": "243989"
  },
  {
    "text": "the Cassandra clusters that we use to serve production streaming netflix service pretty much every service at",
    "start": "243989",
    "end": "250799"
  },
  {
    "text": "adrian told you about is backed by cassandra and the reason why we have a centralized operations team is to ensure",
    "start": "250799",
    "end": "256919"
  },
  {
    "text": "to remove the need for people to understand how cassandra work and just have them free up to use the",
    "start": "256919",
    "end": "262740"
  },
  {
    "text": "service so the way the service we try to provide to people is to make it more like an extension of an AWS service like",
    "start": "262740",
    "end": "269129"
  },
  {
    "text": "I really don't know how s 3 works what they do behind the scenes but i know i could put files on and i can take them off we try to do the same thing with",
    "start": "269129",
    "end": "275550"
  },
  {
    "text": "Cassandra so what is Cassandra it's a database right it's no sequel it's",
    "start": "275550",
    "end": "281069"
  },
  {
    "text": "persistent it's a key value store but it's really just a database you put your data in you get your data out and it's",
    "start": "281069",
    "end": "287009"
  },
  {
    "text": "eventually consistent so you may not get the data out that you put in right away but if you've written it rest assured us",
    "start": "287009",
    "end": "293939"
  },
  {
    "text": "there why don't we choose Cassandra yeah it's open source and written in Java then we really like open source projects",
    "start": "293939",
    "end": "300810"
  },
  {
    "start": "295000",
    "end": "295000"
  },
  {
    "text": "and Java yeah the big selling point for us was this multi region replication back when we started in Cassandra a",
    "start": "300810",
    "end": "307560"
  },
  {
    "text": "us-only service but we knew ultimately we were going to be international and we needed the ability to get our data",
    "start": "307560",
    "end": "313469"
  },
  {
    "text": "replicated wherever we're going to have a service as I mentioned most of the",
    "start": "313469",
    "end": "319080"
  },
  {
    "text": "services now are backed by Cassandra and we do it for offline data computation for subscriber information and playlist",
    "start": "319080",
    "end": "326310"
  },
  {
    "text": "bookmarks we use it for everything the nice thing about Cassandra is it supports a wide range of use cases so",
    "start": "326310",
    "end": "332639"
  },
  {
    "text": "we've yet to find something that we couldn't model and run properly in Cassandra and it runs on commodity",
    "start": "332639",
    "end": "338909"
  },
  {
    "text": "hardware which to me when I think of commodity hardware I think of AWS and we haven't run into any issues with that",
    "start": "338909",
    "end": "344969"
  },
  {
    "text": "now and it's been enhanced to understand the AWS topology so Cassandra knows what an availability zone is and those what a",
    "start": "344969",
    "end": "351629"
  },
  {
    "text": "region is that stuff has been built in or I we spilt on top of the product and it's very durable to talk to durability",
    "start": "351629",
    "end": "359129"
  },
  {
    "start": "358000",
    "end": "358000"
  },
  {
    "text": "then there's no single point of failure or specialized instance every instance in a Cassandra ring does essentially the",
    "start": "359129",
    "end": "365219"
  },
  {
    "text": "same thing there's no name those that when they die your cluster goes away it stores multiple copies of data across",
    "start": "365219",
    "end": "371849"
  },
  {
    "text": "availability zones at least in a way we can figure they have now show you that later but the fact that it handles all",
    "start": "371849",
    "end": "377189"
  },
  {
    "text": "that replication force is a big selling point yeah it makes the data that much more durable it has features built into",
    "start": "377189",
    "end": "382949"
  },
  {
    "text": "the architecture like bootstrapping and hinted handoff so if your rights do fail or your nose fail you're going to get",
    "start": "382949",
    "end": "388650"
  },
  {
    "text": "that data back yeah once your data is ended and because andrew is very hard to remove it was",
    "start": "388650",
    "end": "393980"
  },
  {
    "text": "very hard to have some type of issue happen with your cluster remove that data all the rights are appended to a",
    "start": "393980",
    "end": "400370"
  },
  {
    "text": "commit log so your history is pretty much there and it has a synchronous cross-regional replication which we take",
    "start": "400370",
    "end": "406160"
  },
  {
    "text": "advantage of and argue UK or EU service",
    "start": "406160",
    "end": "411580"
  },
  {
    "start": "411000",
    "end": "411000"
  },
  {
    "text": "so how do we figure configure cassandra an AWS cassandra is essentially a ring",
    "start": "411580",
    "end": "416960"
  },
  {
    "text": "structure each node in the cluster has a token associated with it which determines when your key is hashed which",
    "start": "416960",
    "end": "422360"
  },
  {
    "text": "node is going to get the data we're looking at a typical configuration for one of our multi region clusters 12",
    "start": "422360",
    "end": "429170"
  },
  {
    "text": "notes and us east 12 nodes in EU s you'll notice around the ring that we alternate the availability zone yeah all",
    "start": "429170",
    "end": "436040"
  },
  {
    "text": "the way around the ring so we have we don't have the same availability zone next to a node anywhere around the ring",
    "start": "436040",
    "end": "441620"
  },
  {
    "text": "what that enables us to do is when a right comes into a coordinator and it gets written off to three nodes you'll",
    "start": "441620",
    "end": "448520"
  },
  {
    "text": "see that one set of one copy of the data is in each availability zone both in the u.s. and asynchronously into the EU yeah",
    "start": "448520",
    "end": "455750"
  },
  {
    "text": "so we have our data in multiple data center so if we were to lose a node this",
    "start": "455750",
    "end": "461090"
  },
  {
    "text": "way yeah we still have two copies of our data and since we still have two of our three nodes we're still able to satisfy",
    "start": "461090",
    "end": "467150"
  },
  {
    "text": "farmville 32 right we typically do right quorum and read one and Netflix yeah but",
    "start": "467150",
    "end": "472190"
  },
  {
    "text": "we don't worry when a node goes down because we're going to have two copies of our data in fact we don't really",
    "start": "472190",
    "end": "477320"
  },
  {
    "text": "worry if a whole availability zone goes down so if one C goes down I'll talk a",
    "start": "477320",
    "end": "482840"
  },
  {
    "text": "little bit about them a recent outage if we lose the entire availability zone we still have two copies of our data",
    "start": "482840",
    "end": "488840"
  },
  {
    "text": "everywhere and we're still able to satisfy farm because we haven't taken out to more than one node in any",
    "start": "488840",
    "end": "494870"
  },
  {
    "text": "replication set where we get into trouble and this doesn't happen very often is where we moves consecutive",
    "start": "494870",
    "end": "500270"
  },
  {
    "text": "notes this is sort of the Achilles heel that we've run into if you're not when this happens you're not able to satisfy",
    "start": "500270",
    "end": "506000"
  },
  {
    "text": "farm and you're actually not satisfying it on to replication sets this one and this one so when that happens you're",
    "start": "506000",
    "end": "511490"
  },
  {
    "text": "going to have a partial outage to your rights depending on what your form consistency level is either your visa rights will fail we also backup all hard",
    "start": "511490",
    "end": "520610"
  },
  {
    "text": "data to s3 damn a local region same count version of s3 we do that in two",
    "start": "520610",
    "end": "526630"
  },
  {
    "text": "different ways we have a full backup which we take a snapshot one today copy all the files s3 and we take incremental",
    "start": "526630",
    "end": "532570"
  },
  {
    "text": "backups which every time a memory every",
    "start": "532570",
    "end": "537580"
  },
  {
    "text": "time the memory is flushed to disk and new SS table is created and we copy that file over the s3 so we're able to",
    "start": "537580",
    "end": "543370"
  },
  {
    "text": "restore clusters to reasonable as real-time as eventual consistency will",
    "start": "543370",
    "end": "548950"
  },
  {
    "text": "allow you to a point in time by doing our by starting at a full and going",
    "start": "548950",
    "end": "554980"
  },
  {
    "text": "incremental up to a certain period of time we also back up we have an additional copy of our data in another",
    "start": "554980",
    "end": "561840"
  },
  {
    "text": "another region and another account so if a region goes down we still have our data somewhere and if someone deletes",
    "start": "561840",
    "end": "568600"
  },
  {
    "text": "our account we still have our data somewhere we use mostly m24 excels yeah",
    "start": "568600",
    "end": "575620"
  },
  {
    "text": "but now that the SSDs are available we're moving to them and Russell and I'll talk a little bit about the performance we get out of SSDs but then",
    "start": "575620",
    "end": "581770"
  },
  {
    "text": "as a teaser it's great but we find that m24 excels are working well for us also we use a femoral storage for better",
    "start": "581770",
    "end": "589060"
  },
  {
    "text": "performance yeah we made a lot of these decisions before the high provisioned I ops EBS volumes came out so i can't",
    "start": "589060",
    "end": "596050"
  },
  {
    "text": "speak to the performance of a femoral versus those but femoral has been good enough for us and then we're sticking to",
    "start": "596050",
    "end": "601150"
  },
  {
    "text": "it we we use multiple ases or auto",
    "start": "601150",
    "end": "607630"
  },
  {
    "text": "scaling groups to create a cluster we don't have one cluster that's made up of multiple availability zones we have",
    "start": "607630",
    "end": "612850"
  },
  {
    "text": "multiple auto scaling groups that have one availability zone each and I might think I touch upon this waiter yeah",
    "start": "612850",
    "end": "618640"
  },
  {
    "text": "maybe I should do it now I'll do later and the reason we do that is we want better control over how AWS spins up",
    "start": "618640",
    "end": "626230"
  },
  {
    "text": "nodes like we want to know we don't want a WSU do node balancing across availability zones for us because we",
    "start": "626230",
    "end": "632080"
  },
  {
    "text": "care how many knows we have in a ring because we want things to be then configured properly we have",
    "start": "632080",
    "end": "638230"
  },
  {
    "text": "single-tenant accustom oh sweet so every service gets its own Cassandra cluster that was an early decision we made",
    "start": "638230",
    "end": "643810"
  },
  {
    "text": "because we started to Cassandra with 0.7 mm and we did it somewhat 10th we did it",
    "start": "643810",
    "end": "650970"
  },
  {
    "text": "we didn't do it tentatively enough but we always wanted to mitigate risk of one service bring down another so we just",
    "start": "650970",
    "end": "657220"
  },
  {
    "text": "created a bunch Cassandra clusters and we tend to over provision them yeah I don't know that",
    "start": "657220",
    "end": "662720"
  },
  {
    "text": "we've figured out the sweet spot for how to provision Cassandra clusters yet we tend to over provision in case we moves",
    "start": "662720",
    "end": "667970"
  },
  {
    "text": "a larger number of nodes or loose and availability zone and we want to be able to have enough capacity to serve what we",
    "start": "667970",
    "end": "674509"
  },
  {
    "text": "do what we would expect to be full load from all the services and I'll talk about that later and what I discuss a",
    "start": "674509",
    "end": "680269"
  },
  {
    "text": "recent outage so let's talk about some of the optimizations we do we have",
    "start": "680269",
    "end": "685459"
  },
  {
    "start": "684000",
    "end": "684000"
  },
  {
    "text": "active Cassandra I guess have not official committers but people who are working on the code they're making bug fixes performance changes security and",
    "start": "685459",
    "end": "692509"
  },
  {
    "text": "we checked in the code that does the asynchronous replication to other regions we implemented something called",
    "start": "692509",
    "end": "699259"
  },
  {
    "text": "snapshot repairs which is weighed less io intensive but somewhat longer way to",
    "start": "699259",
    "end": "704509"
  },
  {
    "text": "repair your clusters and by not running as it work by not running repairs in",
    "start": "704509",
    "end": "711970"
  },
  {
    "text": "tandem on as many sheen as by not running the repairs by source running",
    "start": "711970",
    "end": "718879"
  },
  {
    "text": "out the repairs across the different machines sorry",
    "start": "718879",
    "end": "722949"
  },
  {
    "text": "so yeah I will get to that the question was that about how we implement backups and",
    "start": "729910",
    "end": "736940"
  },
  {
    "text": "I'll cover that in a future side I'm Seth what I wanted sure so we weren't",
    "start": "736940",
    "end": "745310"
  },
  {
    "start": "739000",
    "end": "739000"
  },
  {
    "text": "completely happy with a lot of the Java clients that were out there so we built our own yeah it's multi-region and zona",
    "start": "745310",
    "end": "751820"
  },
  {
    "text": "where so if we have a client coming in from you or us East 1a it's simply get",
    "start": "751820",
    "end": "757490"
  },
  {
    "text": "it's typically will be sent to an EU East one a node in Cassandra so we're not doing a hop to another than",
    "start": "757490",
    "end": "763690"
  },
  {
    "text": "availability zone and it's also latency aware so it will recognize that we have",
    "start": "763690",
    "end": "770090"
  },
  {
    "text": "some those that are slow and start sending traffic there on top of however Cassandra manages that it has a fluent",
    "start": "770090",
    "end": "775790"
  },
  {
    "text": "api that's built on top of thrift thrift and given that we have so many use cases internally we have a great set of best",
    "start": "775790",
    "end": "781910"
  },
  {
    "text": "practice recipes them for others to use a lot of things bother me I don't like",
    "start": "781910",
    "end": "789350"
  },
  {
    "start": "785000",
    "end": "785000"
  },
  {
    "text": "when people don't use their turn signals but the thing that bothers me almost much is the assumption a cassandra is",
    "start": "789350",
    "end": "797090"
  },
  {
    "text": "hands-off operations that pretty much i have to do is throw some clusters out there it's going to run and if you don't have enough past you throw some more out",
    "start": "797090",
    "end": "802820"
  },
  {
    "text": "there and it's going to run like that's really not true and we put a lot of work into building tools to mitigate a lot of",
    "start": "802820",
    "end": "808820"
  },
  {
    "text": "the headaches of managing a goose anser cluster so we have a tomcat web app that we use for Cassandra administration and",
    "start": "808820",
    "end": "815150"
  },
  {
    "text": "the nice thing is it has a WS style instance provisioning so all I have to do to create a cluster is launched a",
    "start": "815150",
    "end": "822020"
  },
  {
    "text": "bunch of nodes in AWS that uses a lot of the infrastructure and tools that we have built into it to spin up a cluster",
    "start": "822020",
    "end": "827330"
  },
  {
    "text": "so if I want a six node cluster I'm not configuring Cassandra llamo files or figuring out what my tokens are I'm just",
    "start": "827330",
    "end": "833450"
  },
  {
    "text": "saying AWS give me these six nodes and by virtue of what's on the am I getting a ready-to-use Cassandra cluster and the",
    "start": "833450",
    "end": "840140"
  },
  {
    "text": "same thing for one I have to swap those out we swap those out a lot I think I cover this waiter but pretty much with",
    "start": "840140",
    "end": "847100"
  },
  {
    "text": "the app the admin web app that we have killing a node and having AWS AWS spin",
    "start": "847100",
    "end": "853310"
  },
  {
    "text": "up another one is essentially a no op for me it's going to join a ring it's going to get the right token it's going to stream all the data it's going to be",
    "start": "853310",
    "end": "859100"
  },
  {
    "text": "brought online and we do full in incremental backups and this is built into the web app that",
    "start": "859100",
    "end": "865760"
  },
  {
    "text": "we use yeah so I believe that Cassandra will do the incremental backup for you",
    "start": "865760",
    "end": "872149"
  },
  {
    "text": "this configuration in the ammo file that will say enable incremental backups and they'll copy those SS tables to the",
    "start": "872149",
    "end": "877490"
  },
  {
    "text": "backup directory and the data directory yeah but we have the like the tool that",
    "start": "877490",
    "end": "882649"
  },
  {
    "text": "we wrote will take those watch for things that change there and upload them test three we do jmx metrics flexion we",
    "start": "882649",
    "end": "890870"
  },
  {
    "text": "get a lot of metrics out of Cassandra we're starting to scratch the service surface of understanding what they mean",
    "start": "890870",
    "end": "897680"
  },
  {
    "text": "towards the health of the cluster and I'll talk about that a little later but the application that we have is pulling",
    "start": "897680",
    "end": "903380"
  },
  {
    "text": "all that stuff and graphing it for us it enables us to configure our clusters",
    "start": "903380",
    "end": "909170"
  },
  {
    "text": "consistently with some tuning and it's got a great rest api to mostly administrative options so rather than",
    "start": "909170",
    "end": "916220"
  },
  {
    "text": "connecting to a node and running no to ring or no to repair we could do it all via REST API and it does great security",
    "start": "916220",
    "end": "922430"
  },
  {
    "text": "group configuration for us specifically with respect to multi region so as new",
    "start": "922430",
    "end": "928070"
  },
  {
    "text": "nodes are spinning up in multi region it's important that all those nodes could talk to each other instantly as new notes been up we will recognize that",
    "start": "928070",
    "end": "935449"
  },
  {
    "text": "we have a new node in EU and instantly configure our security groups to ensure that when that no joins ring we're going",
    "start": "935449",
    "end": "941060"
  },
  {
    "text": "to be able to communicate with it so",
    "start": "941060",
    "end": "947500"
  },
  {
    "start": "944000",
    "end": "944000"
  },
  {
    "text": "once people figure out how to set up Cassandra and I get a bunch of data and there are a lot of the questions I'll see on a user group is how do I actually",
    "start": "947500",
    "end": "953269"
  },
  {
    "text": "view my data and I think a lot of people there seemed to be a lot of organic tools that are people starting to develop for a graphical representation",
    "start": "953269",
    "end": "960199"
  },
  {
    "text": "of your data and we have one too I'm sort of the missing you I for Cassandra client users it allows us to view and",
    "start": "960199",
    "end": "966500"
  },
  {
    "text": "edit schemas so we can see we can create new key spaces column families edit the ones that we have it allows us to do",
    "start": "966500",
    "end": "972769"
  },
  {
    "text": "point queries and actually update the data it gives us high level cluster status and metrics across all the",
    "start": "972769",
    "end": "978230"
  },
  {
    "text": "different clusters we have integrated access control so if you attended Adrian's talk we're big on freedom and",
    "start": "978230",
    "end": "984649"
  },
  {
    "text": "responsibility and on the outside what's hard for me is not knowing when people are making schema changes any impact it",
    "start": "984649",
    "end": "990649"
  },
  {
    "text": "has on me someone might push out something new I had no idea about it they turn on some new service it's",
    "start": "990649",
    "end": "996150"
  },
  {
    "text": "bike stuff to traffic 10x the cluster starts to fall over and via schema auditing and integrated access control",
    "start": "996150",
    "end": "1002810"
  },
  {
    "text": "it gives us a couple of knobs or at least early warning well real-time warning signs that something is being",
    "start": "1002810",
    "end": "1008330"
  },
  {
    "text": "changed on a cluster and it gets us that much closer to real time understanding of what's happening on the cluster so",
    "start": "1008330",
    "end": "1015110"
  },
  {
    "start": "1015000",
    "end": "1015000"
  },
  {
    "text": "here are some screenshots and hopefully they look they look better up there this is an this is the circles represent all",
    "start": "1015110",
    "end": "1022820"
  },
  {
    "text": "the different Cassandra clusters that we have the segments of the circle are the",
    "start": "1022820",
    "end": "1028069"
  },
  {
    "text": "instances the different color green are different regions note the segments that are red or nose header down yeah we take",
    "start": "1028070",
    "end": "1035060"
  },
  {
    "text": "nodes down via gossip a lot to do some maintenance on them those that are yellow are ones that are potentially",
    "start": "1035060",
    "end": "1041600"
  },
  {
    "text": "under stress right now if it has a heap over seventy-five percent it will turn yellow and this is you know we've had",
    "start": "1041600",
    "end": "1047689"
  },
  {
    "text": "this up on the wall before it just gives us sort of a overall state of what the health of our clusters are this is the",
    "start": "1047690",
    "end": "1054590"
  },
  {
    "start": "1054000",
    "end": "1054000"
  },
  {
    "text": "the data query tool and probably hard to see you can pick your column with families you could put some filters on",
    "start": "1054590",
    "end": "1060140"
  },
  {
    "text": "it and it'll display all the data for you and I'm pretty sure I've never done it you get edit the data through the",
    "start": "1060140",
    "end": "1065360"
  },
  {
    "text": "same interface and here's our scheme of management tool then you can create a",
    "start": "1065360",
    "end": "1070550"
  },
  {
    "start": "1067000",
    "end": "1067000"
  },
  {
    "text": "column family picture types yeah and you could change existing data data structures as well and we audit all",
    "start": "1070550",
    "end": "1076700"
  },
  {
    "text": "these changes so we have good visibility into what's happening on the clusters so",
    "start": "1076700",
    "end": "1081980"
  },
  {
    "start": "1081000",
    "end": "1081000"
  },
  {
    "text": "let's talk a little bit about operations and in particular how we dealt with the jun 29th outage anybody here remember",
    "start": "1081980",
    "end": "1088610"
  },
  {
    "text": "the jun 29th outage no you do yeah so the big storm hit the East Coast took",
    "start": "1088610",
    "end": "1097070"
  },
  {
    "text": "out one of the data centers in Virginia I think they're somewhere under there and we had a temporary service outage I",
    "start": "1097070",
    "end": "1107890"
  },
  {
    "text": "but from via our netflix tech tech blog then Cassandra dealt with the loss of",
    "start": "1107890",
    "end": "1113510"
  },
  {
    "start": "1108000",
    "end": "1108000"
  },
  {
    "text": "one third with regional nodes of that any loss of data or adored or availability and that's very accurate like we didn't we never lost any of our",
    "start": "1113510",
    "end": "1120680"
  },
  {
    "text": "data even though we lost a third of our nodes we never lost any of the available available T the availabilities a lot of",
    "start": "1120680",
    "end": "1128270"
  },
  {
    "text": "the services were down at this time so the traffic we were getting was nominal compared to what we usually get so",
    "start": "1128270",
    "end": "1133309"
  },
  {
    "text": "saying that we were available through this is sort of a cheap yeah but I think the important thing to note is that as",
    "start": "1133309",
    "end": "1138710"
  },
  {
    "text": "all these those other services spun up and I think during this outage yeah a lot of the services were starting to",
    "start": "1138710",
    "end": "1145940"
  },
  {
    "text": "spin up nodes in the regions that were available Cassandra since we over provision since we configure our",
    "start": "1145940",
    "end": "1151940"
  },
  {
    "text": "availability zones properly around the ring we didn't we were constantly available that would constantly had all",
    "start": "1151940",
    "end": "1157249"
  },
  {
    "text": "of our data so what happened during the outage and power outage in and us East",
    "start": "1157249",
    "end": "1163039"
  },
  {
    "start": "1159000",
    "end": "1159000"
  },
  {
    "text": "one when we connected to when we got our rink status via no to ring a showed one-third of the nodes were down yeah we",
    "start": "1163039",
    "end": "1170929"
  },
  {
    "text": "didn't we weren't worried about this because how we can figure our clusters and because we over provision but it was",
    "start": "1170929",
    "end": "1177109"
  },
  {
    "text": "really important for us to maintain quorum everywhere so we started watching our other availability zones a lot more",
    "start": "1177109",
    "end": "1182509"
  },
  {
    "text": "closer than we would to ensure that we weren't having problems there and and then we didn't do anything right we",
    "start": "1182509",
    "end": "1187759"
  },
  {
    "text": "don't do anything when we lose in the availability zone we sit around we want the other services scramble to get out of that availability zone into the other",
    "start": "1187759",
    "end": "1194690"
  },
  {
    "text": "one while we're just serving the traffic like we always do wait for AWS to fix",
    "start": "1194690",
    "end": "1199999"
  },
  {
    "text": "the issue AWS is great at fixing these issues during the recovery a bunch of the nose came up and most of the",
    "start": "1199999",
    "end": "1206029"
  },
  {
    "text": "instances we joined the cluster without any issue they had their data they join the ring they were one hundred percent",
    "start": "1206029",
    "end": "1211519"
  },
  {
    "text": "and at capacity probably faster than the services that they were serving some of",
    "start": "1211519",
    "end": "1217429"
  },
  {
    "text": "the nodes required a reboot to fix we really don't know why but when we're dealing with tens of nodes and a reboot",
    "start": "1217429",
    "end": "1223460"
  },
  {
    "text": "fixes our problem we're happy to do it and then we needed to replace a handful",
    "start": "1223460",
    "end": "1228769"
  },
  {
    "text": "of nodes most of which were fortunately in one of our internal monitoring tools and what we did was we just killed those",
    "start": "1228769",
    "end": "1235309"
  },
  {
    "text": "nodes and because of the tool and we have it just fun up another node in this place so I we really survived the outage",
    "start": "1235309",
    "end": "1242059"
  },
  {
    "text": "well and I think was a great testament to them the Cassandra and its ability to",
    "start": "1242059",
    "end": "1248239"
  },
  {
    "text": "deal with with nodes being down and the fact that we can figure our clusters way we do really helped protect us from this",
    "start": "1248239",
    "end": "1254089"
  },
  {
    "text": "one and subsequent outages some observations about AWS again we use",
    "start": "1254089",
    "end": "1259609"
  },
  {
    "text": "ephemeral drives because we found a better tan than EBS before the high provision diets EBS",
    "start": "1259609",
    "end": "1266720"
  },
  {
    "start": "1260000",
    "end": "1260000"
  },
  {
    "text": "volumes instances seldom die on our own this was a surprise to me I expected yeah when I got here I expected a WSB",
    "start": "1266720",
    "end": "1273740"
  },
  {
    "text": "killing machines all the time but they don't we have tons of nodes with IO issues that don't go away on their own",
    "start": "1273740",
    "end": "1278840"
  },
  {
    "text": "we monitor very closely for that and when we find that we shoot them and kill them our motto is when in doubt swapped",
    "start": "1278840",
    "end": "1284780"
  },
  {
    "text": "it out if something's bad something doesn't look right it's better fresh just to kill that node and have AWS give",
    "start": "1284780",
    "end": "1289940"
  },
  {
    "text": "us another one since we can replace it so easily use as many availability zones",
    "start": "1289940",
    "end": "1295160"
  },
  {
    "text": "as you can yeah it's important to get your data and as many different places you saw that to save this in the jun",
    "start": "1295160",
    "end": "1300680"
  },
  {
    "text": "29th outage it could do the same for you and I think a lot of the through anecdotal reading a lot of the of some",
    "start": "1300680",
    "end": "1307340"
  },
  {
    "text": "of the other major services like the Instagram or whatnot that were more affected by the jun 29th outage and",
    "start": "1307340",
    "end": "1313340"
  },
  {
    "text": "don't quote me on instagram thinks I really don't know and might not have been in as many of the availability zones I think it's important for you",
    "start": "1313340",
    "end": "1320960"
  },
  {
    "text": "guys to understand how AWS launches instances yeah and this is why we went",
    "start": "1320960",
    "end": "1326540"
  },
  {
    "text": "with the multiple auto scaling group single availability zone and when we started we only had one ASG and it had",
    "start": "1326540",
    "end": "1333650"
  },
  {
    "text": "all the nodes in it and AWS wants to keep your nodes balanced across all the",
    "start": "1333650",
    "end": "1338930"
  },
  {
    "text": "availability zones so if we say give us six nodes it gives us two two and two and we can construct our ring properly",
    "start": "1338930",
    "end": "1344290"
  },
  {
    "text": "and at least this is back when we made the decision to go this way it may be different now yeah but what happens when",
    "start": "1344290",
    "end": "1349940"
  },
  {
    "text": "we had an outage is if we had two and A two and b & 2 and C and a went down we",
    "start": "1349940",
    "end": "1354950"
  },
  {
    "text": "would lose those two nodes and AWS would spin up a note of B and C so suddenly our cluster isn't quite as balanced as",
    "start": "1354950",
    "end": "1361010"
  },
  {
    "text": "we wanted it to be but when it comes back online it kills those two nodes and puts two A's back because it wants to",
    "start": "1361010",
    "end": "1366680"
  },
  {
    "text": "keep those knows balance and we don't want anyone messing with our nodes but us like we want AWS to have the right",
    "start": "1366680",
    "end": "1373610"
  },
  {
    "text": "reason to kill it not just the balance things I think they might have we talking about it hey Douglas might have",
    "start": "1373610",
    "end": "1379670"
  },
  {
    "text": "changed this a little bit but the reason we went with the Mayan our side",
    "start": "1379670",
    "end": "1389270"
  },
  {
    "text": "yes I am the reason we went with that is because we want more control over hell yeah we want to control over how a dub",
    "start": "1389270",
    "end": "1395810"
  },
  {
    "text": "we want to control instances on our Terms not a WS s io is constrained in a",
    "start": "1395810",
    "end": "1401090"
  },
  {
    "text": "lot of AWS instance types even the m24 XL when repairs and Compassion's run these operations that are very IO",
    "start": "1401090",
    "end": "1407450"
  },
  {
    "text": "intensive it does affect latency and we had several issues early on when we were",
    "start": "1407450",
    "end": "1412880"
  },
  {
    "text": "first getting our footing with Cassandra and AWS where large minor compaction skipped off on consecutive nodes in a",
    "start": "1412880",
    "end": "1419870"
  },
  {
    "text": "replication set just brought the the cluster to a crawl yeah the way we address those things is we compact we",
    "start": "1419870",
    "end": "1426950"
  },
  {
    "text": "run major Compassion's ourselves now and as Russell will tell you later SSDs they are absolute game changers the IO is so",
    "start": "1426950",
    "end": "1434360"
  },
  {
    "text": "much better on a Cassandra side a swell node is worse than to download kill nodes that kill nodes that are",
    "start": "1434360",
    "end": "1442340"
  },
  {
    "start": "1436000",
    "end": "1436000"
  },
  {
    "text": "underperforming yeah cassandra is the Bruce the bootstrapping process of cassandra is rock solid it's going to",
    "start": "1442340",
    "end": "1448910"
  },
  {
    "text": "get that new node in but if your notice whoa we don't spend a lot of time trying to figure out why because we have",
    "start": "1448910",
    "end": "1454160"
  },
  {
    "text": "infinite note cold cash increases load and kills latency so when we spin up",
    "start": "1454160",
    "end": "1459500"
  },
  {
    "text": "that new node is typically a little slow yeah we rely on the file system cache quite a bit and as that's warming up on",
    "start": "1459500",
    "end": "1465110"
  },
  {
    "text": "m24 excels in particular and your note is still going to be a little slow so we got to let that thing warm up we're",
    "start": "1465110",
    "end": "1470750"
  },
  {
    "text": "looking into well apart from moving the SSDs we're looking into ways to sort of speed up the cold cash problem Cassandra",
    "start": "1470750",
    "end": "1479570"
  },
  {
    "text": "it's it's one I guess it's on its way to 12 now we're still on 109 damn evaluating 11 looking to move there to",
    "start": "1479570",
    "end": "1486980"
  },
  {
    "text": "12 but it's still a relatively maturing product and as such it doesn't have a",
    "start": "1486980",
    "end": "1492650"
  },
  {
    "text": "full suite of administrative tools for doing a lot of the operations or for dealing with issues when they come up so",
    "start": "1492650",
    "end": "1498140"
  },
  {
    "text": "it's important that you understand the few knobs that you have that you can turn when there's a when there's a",
    "start": "1498140",
    "end": "1503270"
  },
  {
    "text": "production issue it's something we do often this take the no doubt of the coordinator list so it's not serving",
    "start": "1503270",
    "end": "1508910"
  },
  {
    "text": "coordinator traffic is still serving the reads and writes but nothing like nothing is round-robin to that node",
    "start": "1508910",
    "end": "1514490"
  },
  {
    "text": "which really reduces the amount of i/o on the node and compaction throttling if",
    "start": "1514490",
    "end": "1520280"
  },
  {
    "text": "you're running really large compaction is you have ability to throttle them and you should the min and max compaction threshold",
    "start": "1520280",
    "end": "1526120"
  },
  {
    "text": "settings are this sort of magic way to make compaction stop yeah and there are times where you want them to stop",
    "start": "1526120",
    "end": "1531640"
  },
  {
    "text": "without taking the node down so you can use those and enabling it and disabling gossip just getting it out of the ring",
    "start": "1531640",
    "end": "1536650"
  },
  {
    "text": "that often helps we use level compaction in some of our customs in fact we're",
    "start": "1536650",
    "end": "1541840"
  },
  {
    "text": "using it a lot more yeah and its performance is looking very promising I think there are some I would wait until",
    "start": "1541840",
    "end": "1547090"
  },
  {
    "text": "11 to use level compaction because they fix some bugs and and it's I really",
    "start": "1547090",
    "end": "1553090"
  },
  {
    "text": "think that's going to be a good game changer for us and 12 then we're really excited about so I think that's the",
    "start": "1553090",
    "end": "1559150"
  },
  {
    "text": "vinodh release which one able us to do behind the scenes auto-scaling m4r",
    "start": "1559150",
    "end": "1564370"
  },
  {
    "text": "cassandra clusters a little bit unmonitored as I mentioned we monitor",
    "start": "1564370",
    "end": "1570490"
  },
  {
    "start": "1568000",
    "end": "1568000"
  },
  {
    "text": "hardware and network issues we we don't rely on AWS to kill nose for us or to",
    "start": "1570490",
    "end": "1575710"
  },
  {
    "text": "find problems we want to find them first so we do a lot of monitoring we monitor d message iOS that if things are looking",
    "start": "1575710",
    "end": "1581440"
  },
  {
    "text": "weird we strongly consider throwing that no doubt and we checked the cluster consistency Cassandra all the nodes will",
    "start": "1581440",
    "end": "1587560"
  },
  {
    "text": "gossip you want to make sure all the nose had the same opinion of what the cluster looks like so we wrote the",
    "start": "1587560",
    "end": "1593590"
  },
  {
    "text": "script that will go and check the the rink status of all the nose to make sure it's consistent across the cluster we're",
    "start": "1593590",
    "end": "1600790"
  },
  {
    "text": "starting to say on the Cassandra side we monitor throughput and latency again and we're starting to try to algorithmically",
    "start": "1600790",
    "end": "1607180"
  },
  {
    "text": "way some of the different key Cassandra metrics like whether or not your pending",
    "start": "1607180",
    "end": "1613540"
  },
  {
    "text": "threads are queuing you're dropping operations of your SS table reads get high we're envisioning some type of",
    "start": "1613540",
    "end": "1619690"
  },
  {
    "text": "algorithm across a gravely so we're off of every single metric and that produced",
    "start": "1619690",
    "end": "1625540"
  },
  {
    "text": "a lot of noise where there are problems a big deal with Sanchez compacting a lot it's supposed to compact a lot and if",
    "start": "1625540",
    "end": "1630700"
  },
  {
    "text": "it's not affecting other things it's really not that big of a deal but in Ag in aggregate with other metrics there's",
    "start": "1630700",
    "end": "1637810"
  },
  {
    "text": "some algorithm that we're starting to hone in on that's going to tell us when the cluster was under a state of duress",
    "start": "1637810",
    "end": "1643600"
  },
  {
    "text": "it's really going to be a weighted average of several different metrics on the informational side again we want to",
    "start": "1643600",
    "end": "1650200"
  },
  {
    "text": "know when a schema changes because schema changes don't go through us scan the log files for errors and",
    "start": "1650200",
    "end": "1655460"
  },
  {
    "text": "exceptions and we want given the freedom and responsibility culture anybody can really go to any node in Cassandra and",
    "start": "1655460",
    "end": "1661430"
  },
  {
    "text": "do whatever they want with it and in the past we have caught people changing configuration changes and bouncing the node yeah and we don't like that so",
    "start": "1661430",
    "end": "1668330"
  },
  {
    "text": "while we can't well we really shouldn't stop them from doing that at least by",
    "start": "1668330",
    "end": "1673520"
  },
  {
    "text": "monitoring the restarts we know that they do it and then we could start asking questions but it's amazing how people don't know most people just a lot",
    "start": "1673520",
    "end": "1680000"
  },
  {
    "text": "of people don't don't admit to it on the",
    "start": "1680000",
    "end": "1685610"
  },
  {
    "start": "1684000",
    "end": "1684000"
  },
  {
    "text": "maintenance side cassandra is funny they tell you it's very low maintenance but",
    "start": "1685610",
    "end": "1690620"
  },
  {
    "text": "you have to run repairs and when you run repair is you're trashing your server and so but the only way to ensure that",
    "start": "1690620",
    "end": "1697010"
  },
  {
    "text": "your data is consistent is to repair it that's either via read repair or manual",
    "start": "1697010",
    "end": "1702020"
  },
  {
    "text": "them anti entropy repair so we repair all of our clusters as often as we at",
    "start": "1702020",
    "end": "1707210"
  },
  {
    "text": "least once a day for clusters that take three days we do it every three days or every n days and we run offline while",
    "start": "1707210",
    "end": "1714290"
  },
  {
    "text": "sses is making this unnecessary unnecessary we run offline major compaction to avoid late and see so",
    "start": "1714290",
    "end": "1720140"
  },
  {
    "text": "that's a problem I was talking about where to large minor Compassion's came up and killed at least two replica sets",
    "start": "1720140",
    "end": "1725530"
  },
  {
    "text": "what we do is we will frequently one note at a time take it out and take it out of the coordinator let's take it out",
    "start": "1725530",
    "end": "1731780"
  },
  {
    "text": "of gossip run a major compassion and then move on to the next node yeah performance is so much better after it",
    "start": "1731780",
    "end": "1737270"
  },
  {
    "text": "but there's it comes to the price of if you do it once you need to do it all the",
    "start": "1737270",
    "end": "1743240"
  },
  {
    "text": "time so once you start doing those compaction you shouldn't stop we always replace knows when they fail that we",
    "start": "1743240",
    "end": "1749420"
  },
  {
    "text": "periodically replace all the nodes in the cluster so that our data is consistent with all the other Netflix services and because we're sort of built",
    "start": "1749420",
    "end": "1756530"
  },
  {
    "text": "off of this base ami model where there's a set of services we need for monitoring and other tools plus our stuff on top of",
    "start": "1756530",
    "end": "1762320"
  },
  {
    "text": "it so we want to flush those nodes every now and then we do two different type of upgrades the rolling am I upgrade is how",
    "start": "1762320",
    "end": "1768410"
  },
  {
    "text": "we get new minor versions of cassandra and what we do in that case is we just kill every node in the ring one at a",
    "start": "1768410",
    "end": "1775160"
  },
  {
    "text": "time I'm sort of spaced out so we're not producing any hot spots and we went Cassandra spin up a new node and by the",
    "start": "1775160",
    "end": "1781670"
  },
  {
    "text": "time we're done run a new version of Cassandra yeah for major upgrades we're streaming is incompatible",
    "start": "1781670",
    "end": "1787340"
  },
  {
    "text": "versions or you're in an emergency and you can't wait to four weeks it takes the upgrade our 72 a node 600 gate /",
    "start": "1787340",
    "end": "1793550"
  },
  {
    "text": "node cluster we do an RPM binary upgrades so I'm going hands back to",
    "start": "1793550",
    "end": "1800240"
  },
  {
    "text": "Russell and he'll tell you a little bit about performance and the Open Source Initiative is related to Cassandra so",
    "start": "1800240",
    "end": "1812750"
  },
  {
    "text": "let's talk about performance performance for us in a database layer was very important and so as we started",
    "start": "1812750",
    "end": "1818720"
  },
  {
    "text": "evaluating various technologies it wasn't just how fast it was at a time or",
    "start": "1818720",
    "end": "1824030"
  },
  {
    "text": "how fast was going to be but how do we make it scale it's one thing that if you",
    "start": "1824030",
    "end": "1829280"
  },
  {
    "text": "want to scale performance of your database you go to a bigger machine that's a slippery slope because eventually you're going to get to the",
    "start": "1829280",
    "end": "1835220"
  },
  {
    "text": "biggest machine out there possible and what do you do that so for us it was really important to find the technology",
    "start": "1835220",
    "end": "1841040"
  },
  {
    "text": "the scales horizontally and so early in 2011 you're an experiment we took a",
    "start": "1841040",
    "end": "1847100"
  },
  {
    "text": "cluster through some load against it measured the right throughput and then progressively started doubling the",
    "start": "1847100",
    "end": "1853370"
  },
  {
    "text": "cluster and narrowing throughput against it and so very quickly we were able to achieve 1 million writes a second which",
    "start": "1853370",
    "end": "1859490"
  },
  {
    "text": "was really cool and we only had to go at the time to a cluster of 240 notes to",
    "start": "1859490",
    "end": "1866870"
  },
  {
    "text": "get that performance which was really cool but what most importantly as you see from this graph is not the absolute numbers but the shape of it it's",
    "start": "1866870",
    "end": "1873710"
  },
  {
    "text": "linearly scalable if you need to get more read or write throughput you just add more nodes and this is this is",
    "start": "1873710",
    "end": "1879890"
  },
  {
    "text": "really important because your needs may change your needs may change over a day and this is really powerful tool to",
    "start": "1879890",
    "end": "1886100"
  },
  {
    "text": "achieve the scaling needs did you get now this was last year as I mentioned",
    "start": "1886100",
    "end": "1892780"
  },
  {
    "text": "240 node cluster approximately 1 million rates recently this year we hit almost",
    "start": "1892780",
    "end": "1900620"
  },
  {
    "start": "1898000",
    "end": "1898000"
  },
  {
    "text": "100 or almost million writes per second on one of our production clusters Greg made me change it we actually at one",
    "start": "1900620",
    "end": "1906710"
  },
  {
    "text": "point to the other week it's a blaster yes the same class does a great made me change the title because of the time he",
    "start": "1906710",
    "end": "1911900"
  },
  {
    "text": "didn't want to commit to that 1,000,000 but let's say close to 1 million writes a second what was important about this",
    "start": "1911900",
    "end": "1919850"
  },
  {
    "text": "is a 72 node cluster same machines m24 excels so what changed in a year well",
    "start": "1919850",
    "end": "1926840"
  },
  {
    "text": "Cassandra is technology definitely volt and over a period of one year definitely performance improved we also like to",
    "start": "1926840",
    "end": "1933320"
  },
  {
    "text": "think that we gained some learnings and learn how to configure until the performance out of Cassandra a bit",
    "start": "1933320",
    "end": "1938929"
  },
  {
    "text": "better the significance of this number 800 SSDs huge game changer so before I",
    "start": "1938929",
    "end": "1951320"
  },
  {
    "start": "1948000",
    "end": "1948000"
  },
  {
    "text": "dive into the slide one of the major reasons why we wanted to go to SSD was to release some of our operational pains",
    "start": "1951320",
    "end": "1957789"
  },
  {
    "text": "repairs compaction are extremely latency disrupting operations you start running",
    "start": "1957789",
    "end": "1964909"
  },
  {
    "text": "it and your client latency average 95th percentile 99% of jumps up if you",
    "start": "1964909",
    "end": "1972380"
  },
  {
    "text": "attended Adrian Stoke that you know that we run a lot of the micro services in each of those service applications is",
    "start": "1972380",
    "end": "1977750"
  },
  {
    "text": "very latency sensitive because it needs to get downstream response fast so it can do its own logic and then the return",
    "start": "1977750",
    "end": "1983600"
  },
  {
    "text": "response back to the upstream client and so they have very aggressive timeouts most of them have that timeout set for",
    "start": "1983600",
    "end": "1990950"
  },
  {
    "text": "the downstream response to either low double-digit milliseconds or sometimes",
    "start": "1990950",
    "end": "1997220"
  },
  {
    "text": "even on a single dish milliseconds and so all of our layers need to be extremely extremely responsive so what",
    "start": "1997220",
    "end": "2004780"
  },
  {
    "text": "we did that took a 48 node em 2.4 XL cluster that was also fronted by 36 m 2",
    "start": "2004780",
    "end": "2011890"
  },
  {
    "text": "x-large now it's running our EV cash it's an extension on top of memcache d",
    "start": "2011890",
    "end": "2018510"
  },
  {
    "text": "we then compared it to a 15 node SSD cluster and drove the same traffic with",
    "start": "2018510",
    "end": "2024940"
  },
  {
    "text": "the same application and the results were just amazing we found that we can achieve the same throughput at lower",
    "start": "2024940",
    "end": "2031150"
  },
  {
    "text": "latency and it half the cost and the cost savings come not just because we",
    "start": "2031150",
    "end": "2036250"
  },
  {
    "text": "needed less cassandra nose but because we could eliminate the whole cache cluster that is in front of it as a side",
    "start": "2036250",
    "end": "2042340"
  },
  {
    "text": "benefit we also get simplified architecture less layers to to break so",
    "start": "2042340",
    "end": "2048190"
  },
  {
    "text": "we're using basically as me we're using as many SSD no we can get our hands on we use them in",
    "start": "2048190",
    "end": "2054010"
  },
  {
    "text": "many our production clusters and they help a lot I hope to use even worsen I",
    "start": "2054010",
    "end": "2061529"
  },
  {
    "text": "think Adrian already apologized for that so some interesting factoids about",
    "start": "2065970",
    "end": "2072330"
  },
  {
    "start": "2066000",
    "end": "2066000"
  },
  {
    "text": "Netflix use of Cassandra so we via run over 50 clusters in production even",
    "start": "2072330",
    "end": "2077649"
  },
  {
    "text": "greater number and test a large chunk of those clusters is multi region that means the ring actually spans multiple",
    "start": "2077650",
    "end": "2083590"
  },
  {
    "text": "regions and replicate data globally we have one cluster actually spends at least four regions and to replicate some",
    "start": "2083590",
    "end": "2090490"
  },
  {
    "text": "of our global configuration data we need to be consistent over 100 terabytes of",
    "start": "2090490",
    "end": "2095500"
  },
  {
    "text": "data stored across all of our clusters close to 800 nodes drawing day by day",
    "start": "2095500",
    "end": "2100870"
  },
  {
    "text": "week by week the largest cluster that we run that's a cluster that hit 1 million",
    "start": "2100870",
    "end": "2106330"
  },
  {
    "text": "writes a second is currently 72 notes stores about 30 terabytes of information",
    "start": "2106330",
    "end": "2112060"
  },
  {
    "text": "and this is the reading right through traffic that it handles what we didn't",
    "start": "2112060",
    "end": "2118420"
  },
  {
    "text": "include in this light and that's even more impressive number that Greg and his team handles all of this with three",
    "start": "2118420",
    "end": "2124090"
  },
  {
    "text": "people so there is incredible amount of automation tooling that we wrote around",
    "start": "2124090",
    "end": "2129880"
  },
  {
    "text": "Cassandra and how we manage it how they ran it in order to do that otherwise we just would not be able to scale it we",
    "start": "2129880",
    "end": "2135700"
  },
  {
    "text": "will not be able to hire and train people fast enough with our growing needs of our persistence layer so sorry",
    "start": "2135700",
    "end": "2145930"
  },
  {
    "text": "I think oh yes okay so what does what does the future hold for hold for",
    "start": "2145930",
    "end": "2151360"
  },
  {
    "start": "2148000",
    "end": "2148000"
  },
  {
    "text": "Cassandra Netflix well for a lot of the small applications within netflix they",
    "start": "2151360",
    "end": "2157300"
  },
  {
    "text": "don't need to do anything complex they just simply need to do basic crud operations so for those teams would like",
    "start": "2157300",
    "end": "2163840"
  },
  {
    "text": "to alleviate even the small I don't wanna even call it complexity but small task of incorporating our Java client",
    "start": "2163840",
    "end": "2170710"
  },
  {
    "text": "into their applications they should be able just to make a simple rest calls do what they need to get down and don't",
    "start": "2170710",
    "end": "2176350"
  },
  {
    "text": "really even bother to understand how its configured or provision nice so at least internally initially",
    "start": "2176350",
    "end": "2182270"
  },
  {
    "text": "we're planning to introduce cassandra is a service as Greg mentioned our current policy is to over provision into",
    "start": "2182270",
    "end": "2188960"
  },
  {
    "text": "provision dedicated cluster for each little application some applications",
    "start": "2188960",
    "end": "2194480"
  },
  {
    "text": "don't use persistence layer very heavily and they can actually go into a multi-channel church art cluster",
    "start": "2194480",
    "end": "2200390"
  },
  {
    "text": "solution in that fell optimize things for us will have less clusters to run and we'll also optimize the utilization",
    "start": "2200390",
    "end": "2206570"
  },
  {
    "text": "of those clusters will be less waste we're very much looking forward to in",
    "start": "2206570",
    "end": "2211730"
  },
  {
    "text": "consider into Cassandra 1.2 vinodh we're already on the scaling large chunk of",
    "start": "2211730",
    "end": "2218060"
  },
  {
    "text": "our infrastructure but large shark of our infrastructure are stateless services now wouldn't it be cool if you",
    "start": "2218060",
    "end": "2224540"
  },
  {
    "text": "could scale your persistence layer based on your data size changes or read write throughput changes planning to have that",
    "start": "2224540",
    "end": "2232670"
  },
  {
    "text": "sometime soon priyam the management co process that Greg mentioned we wrote it",
    "start": "2232670",
    "end": "2239540"
  },
  {
    "text": "to alleviate some of the biggest operational pains how do you bootstrap a cluster how do you backup restore it how",
    "start": "2239540",
    "end": "2246170"
  },
  {
    "text": "do you configure how to ensure that token range distribution is uniform over a year year and a half of using it we",
    "start": "2246170",
    "end": "2253130"
  },
  {
    "text": "found some use cases where we can greatly improve and so we're planning to put quite a bit of attention to Priam",
    "start": "2253130",
    "end": "2259130"
  },
  {
    "text": "which been open sourced earlier this year and make it even more powerful",
    "start": "2259130",
    "end": "2264650"
  },
  {
    "text": "carry some more advanced use cases and also expose much more metrics via jmx we",
    "start": "2264650",
    "end": "2271250"
  },
  {
    "text": "have a tool dis currently in development and hopefully all will be open source soon as well that will make our",
    "start": "2271250",
    "end": "2276860"
  },
  {
    "text": "Cassandra cluster self-healing self-maintaining and again take that human part of the maintenance even more",
    "start": "2276860",
    "end": "2283280"
  },
  {
    "text": "out at this point I'd like to segue a",
    "start": "2283280",
    "end": "2288560"
  },
  {
    "text": "little bit into our open source efforts so as directly as Greg mentioned a stye a natural Java client and pre-emptive",
    "start": "2288560",
    "end": "2293870"
  },
  {
    "start": "2291000",
    "end": "2291000"
  },
  {
    "text": "management co process are open source and there are at our github site at",
    "start": "2293870",
    "end": "2298940"
  },
  {
    "text": "Netflix I'll give up welcome the tool that he showed you the lots of pretty circles and a few others I called",
    "start": "2298940",
    "end": "2305990"
  },
  {
    "text": "Cassandra explorers internally it will be coming to open source as well we find it extremely useful i hope you",
    "start": "2305990",
    "end": "2311430"
  },
  {
    "text": "as well again I'd like to sidetrack a little bit and talk about our open source efforts I hear this question a",
    "start": "2311430",
    "end": "2316890"
  },
  {
    "text": "lot why do you open source it why do you take something that a lot of engineers spent a lot of time developing and just",
    "start": "2316890",
    "end": "2323309"
  },
  {
    "text": "give it out there well there are many motivations but the main ones is that we",
    "start": "2323309",
    "end": "2328950"
  },
  {
    "text": "as a company benefited from open source software for many years whether it's linux whether it's apache tomcat would",
    "start": "2328950",
    "end": "2334559"
  },
  {
    "text": "like to pay it back in kind but it also helps us as well as netflix was a fairly",
    "start": "2334559",
    "end": "2341910"
  },
  {
    "text": "early adapter of AWS and at that we paid the pioneer penalty we learned a lot of",
    "start": "2341910",
    "end": "2347579"
  },
  {
    "text": "lessons and they developed some best practices to deal with them we'd like to share these best practices so many more",
    "start": "2347579",
    "end": "2354329"
  },
  {
    "text": "can benefit from from that it does help us indirectly by hire and retain the",
    "start": "2354329",
    "end": "2360630"
  },
  {
    "text": "best engineers out there if you're great engineer sometimes it's not just satisfied with making an impact on your",
    "start": "2360630",
    "end": "2368309"
  },
  {
    "text": "product as exciting as product as Netflix maybe it's really exciting to be",
    "start": "2368309",
    "end": "2373859"
  },
  {
    "text": "able to say look the stuff that i developed actually can help companies why outside Netflix and help others and",
    "start": "2373859",
    "end": "2380190"
  },
  {
    "text": "that was the case with our deployment console Asgard Obama for America campaign used it and we heard it help",
    "start": "2380190",
    "end": "2386910"
  },
  {
    "text": "them helps us indirectly in another way",
    "start": "2386910",
    "end": "2391980"
  },
  {
    "text": "our code quality went up immensely when we started open sourcing our components apparently it's one thing to know that",
    "start": "2391980",
    "end": "2399059"
  },
  {
    "text": "five other people inside your company will look at your code it's completely different thing if you know that",
    "start": "2399059",
    "end": "2404309"
  },
  {
    "text": "thousands of eyeballs will judge your code quality out there what we found is",
    "start": "2404309",
    "end": "2409349"
  },
  {
    "text": "that as we started open sourcing our infrastructure suddenly people say no no it's not ready it it's good enough for",
    "start": "2409349",
    "end": "2414720"
  },
  {
    "text": "production but not quite good enough for github I'm going to restructure it I'm going to",
    "start": "2414720",
    "end": "2422010"
  },
  {
    "text": "cleaned up I'm going to update documentation then it's going to be like the benefit from it as well so if you go",
    "start": "2422010",
    "end": "2429360"
  },
  {
    "text": "to netflix.com you will see all the piece of infrastructure we open source so far more is coming we use them",
    "start": "2429360",
    "end": "2436440"
  },
  {
    "text": "directly these are not the forks or branches if you don't have anything special at inside what we open source we",
    "start": "2436440",
    "end": "2443490"
  },
  {
    "text": "use directly this is not my netflix movies recommendation page this is our",
    "start": "2443490",
    "end": "2449700"
  },
  {
    "start": "2446000",
    "end": "2446000"
  },
  {
    "text": "site for those of you have not seen it and here you'll find a style action",
    "start": "2449700",
    "end": "2455010"
  },
  {
    "text": "Priam that we mentioned for Cassandra you also find their equivalents for zookeeper which is another technology we",
    "start": "2455010",
    "end": "2460080"
  },
  {
    "text": "use internally it's called the curator and the exhibitor as well as many others Asgard of course every developer Netflix",
    "start": "2460080",
    "end": "2467130"
  },
  {
    "text": "uses this council to deploy and configure the software simian army most famous member which was just chaos",
    "start": "2467130",
    "end": "2473550"
  },
  {
    "text": "monkey we do have a presentation right after this on all of our seeming Army members it's pretty cool and many others",
    "start": "2473550",
    "end": "2481170"
  },
  {
    "text": "I highly encourage you to visit it and see which pieces of our infrastructure may be useful for you and of course we",
    "start": "2481170",
    "end": "2487230"
  },
  {
    "text": "welcome all contributions and feedback so in conclusion gastric cassandra has",
    "start": "2487230",
    "end": "2494070"
  },
  {
    "start": "2491000",
    "end": "2491000"
  },
  {
    "text": "been really high performing and durable persistent layer for us in AWS it is",
    "start": "2494070",
    "end": "2499590"
  },
  {
    "text": "flexible enough to serve most of our use cases not all but most we don't don't",
    "start": "2499590",
    "end": "2505530"
  },
  {
    "text": "treat it as a one-size-fits-all but it is flexible enough to satisfy most use cases AWS offering such as s3 and RDS",
    "start": "2505530",
    "end": "2512880"
  },
  {
    "text": "help us to create a complete persistent solution to serve all of the company needs and cassandra performs well first",
    "start": "2512880",
    "end": "2520680"
  },
  {
    "text": "sometimes we needed to fronted by cash but on SSDs its perform just amazingly now I'd like to leave you the final note",
    "start": "2520680",
    "end": "2527700"
  },
  {
    "text": "with a disclaimer just because Netflix does it does me is right for you so do your own evaluation we do hope that all",
    "start": "2527700",
    "end": "2534540"
  },
  {
    "text": "the stuff that we talked about an open source will be useful for you but make sure you the jewel sins that's it you",
    "start": "2534540",
    "end": "2542220"
  },
  {
    "text": "can follow us on tech blog and you please visit the open source site here",
    "start": "2542220",
    "end": "2547680"
  },
  {
    "text": "are some Twitter handles you can follow as well this point greg and i can take any questions you have friends",
    "start": "2547680",
    "end": "2554410"
  }
]
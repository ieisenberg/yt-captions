[
  {
    "text": "welcome to another session at a diverse",
    "start": "5330",
    "end": "7770"
  },
  {
    "text": "innovate machine learning and AI Edition",
    "start": "7770",
    "end": "9900"
  },
  {
    "text": "my name is James SB and I'm a senior",
    "start": "9900",
    "end": "12630"
  },
  {
    "text": "Solutions Architect with AWS based in",
    "start": "12630",
    "end": "14940"
  },
  {
    "text": "Sydney Australia reinforcement learning",
    "start": "14940",
    "end": "17850"
  },
  {
    "text": "is both an exciting area of research and",
    "start": "17850",
    "end": "20070"
  },
  {
    "text": "a driver of new commercial applications",
    "start": "20070",
    "end": "21900"
  },
  {
    "text": "in the broader field of machine learning",
    "start": "21900",
    "end": "23960"
  },
  {
    "text": "in 2018",
    "start": "23960",
    "end": "26279"
  },
  {
    "text": "AWS released several new services that",
    "start": "26279",
    "end": "28830"
  },
  {
    "text": "make it much simpler for data science",
    "start": "28830",
    "end": "30480"
  },
  {
    "text": "teams and development teams alike to",
    "start": "30480",
    "end": "32758"
  },
  {
    "text": "start exploring and applying",
    "start": "32759",
    "end": "34340"
  },
  {
    "text": "reinforcement learning in this session I",
    "start": "34340",
    "end": "37350"
  },
  {
    "text": "would like to go through an introduction",
    "start": "37350",
    "end": "38700"
  },
  {
    "text": "to reinforcement learning how deep brace",
    "start": "38700",
    "end": "41070"
  },
  {
    "text": "them makes it a fun and simple way for",
    "start": "41070",
    "end": "42600"
  },
  {
    "text": "AWS users to get started with RL and",
    "start": "42600",
    "end": "45180"
  },
  {
    "text": "then finally how you can leverage Amazon",
    "start": "45180",
    "end": "47520"
  },
  {
    "text": "sage maker RL to apply RL to your own",
    "start": "47520",
    "end": "50070"
  },
  {
    "text": "use cases before we start diving into",
    "start": "50070",
    "end": "55320"
  },
  {
    "text": "our introduction to reinforcement",
    "start": "55320",
    "end": "56910"
  },
  {
    "text": "learning I wanted to quickly cover off",
    "start": "56910",
    "end": "59010"
  },
  {
    "text": "what AWS deep racer is is I'll be using",
    "start": "59010",
    "end": "61770"
  },
  {
    "text": "AWS deep racer in some of my examples a",
    "start": "61770",
    "end": "65119"
  },
  {
    "text": "diverse deep racer is a 1/18 scale",
    "start": "65119",
    "end": "68340"
  },
  {
    "text": "robotic car which gives you an exciting",
    "start": "68340",
    "end": "70770"
  },
  {
    "text": "and fun way to get started with",
    "start": "70770",
    "end": "72180"
  },
  {
    "text": "reinforcement learning by applying it to",
    "start": "72180",
    "end": "74729"
  },
  {
    "text": "autonomous racing you can pre-order your",
    "start": "74729",
    "end": "77340"
  },
  {
    "text": "AWS deep racer from Amazon today",
    "start": "77340",
    "end": "79850"
  },
  {
    "text": "AWS deep racer has a virtual racing",
    "start": "79850",
    "end": "82799"
  },
  {
    "text": "simulator that allows you to Train",
    "start": "82799",
    "end": "84570"
  },
  {
    "text": "evaluate and iterate on your RL models",
    "start": "84570",
    "end": "87330"
  },
  {
    "text": "in a racing environment quickly and",
    "start": "87330",
    "end": "89640"
  },
  {
    "text": "easily this will appear as a new service",
    "start": "89640",
    "end": "92670"
  },
  {
    "text": "in your AWS console when it goes to a",
    "start": "92670",
    "end": "95070"
  },
  {
    "text": "later this year if you get really good",
    "start": "95070",
    "end": "98250"
  },
  {
    "text": "and want to showcase your machine",
    "start": "98250",
    "end": "100200"
  },
  {
    "text": "learning skills in a competitive",
    "start": "100200",
    "end": "101400"
  },
  {
    "text": "environment there is the AWS deep brace",
    "start": "101400",
    "end": "104220"
  },
  {
    "text": "the league throughout 2019 there will be",
    "start": "104220",
    "end": "107939"
  },
  {
    "text": "the opportunity to compete by racing on",
    "start": "107939",
    "end": "110189"
  },
  {
    "text": "the virtual racetrack in the console and",
    "start": "110189",
    "end": "112130"
  },
  {
    "text": "at in-person events that will be",
    "start": "112130",
    "end": "114420"
  },
  {
    "text": "announced at a later date artificial",
    "start": "114420",
    "end": "118500"
  },
  {
    "text": "intelligence seeks to create machines",
    "start": "118500",
    "end": "120240"
  },
  {
    "text": "that seem to or has human intelligence",
    "start": "120240",
    "end": "123140"
  },
  {
    "text": "this includes broad or general AI and",
    "start": "123140",
    "end": "126320"
  },
  {
    "text": "narrow AI where the focus is on one task",
    "start": "126320",
    "end": "130160"
  },
  {
    "text": "machine learning is an example of neuro",
    "start": "130160",
    "end": "132420"
  },
  {
    "text": "AI",
    "start": "132420",
    "end": "133440"
  },
  {
    "text": "machine learning is a subset of",
    "start": "133440",
    "end": "135330"
  },
  {
    "text": "artificial intelligence where we seek to",
    "start": "135330",
    "end": "137310"
  },
  {
    "text": "give systems the ability to",
    "start": "137310",
    "end": "138900"
  },
  {
    "text": "automatically learn and improve from",
    "start": "138900",
    "end": "140940"
  },
  {
    "text": "experience without being explicitly",
    "start": "140940",
    "end": "142890"
  },
  {
    "text": "programmed machine learning has three",
    "start": "142890",
    "end": "145530"
  },
  {
    "text": "main categories supervised learning",
    "start": "145530",
    "end": "147950"
  },
  {
    "text": "requires a large amount of curated",
    "start": "147950",
    "end": "150150"
  },
  {
    "text": "training data consisting of label and",
    "start": "150150",
    "end": "152130"
  },
  {
    "text": "data pairs to learn models learn to",
    "start": "152130",
    "end": "154830"
  },
  {
    "text": "accomplish a well-defined single task",
    "start": "154830",
    "end": "156600"
  },
  {
    "text": "and don't scale easily to other tasks or",
    "start": "156600",
    "end": "159090"
  },
  {
    "text": "subtasks without new data unsupervised",
    "start": "159090",
    "end": "162900"
  },
  {
    "text": "learning learns to classify data based",
    "start": "162900",
    "end": "165240"
  },
  {
    "text": "on similarities without having explicit",
    "start": "165240",
    "end": "167310"
  },
  {
    "text": "labels for training data reinforcement",
    "start": "167310",
    "end": "171330"
  },
  {
    "text": "learning interacts with its environment",
    "start": "171330",
    "end": "172770"
  },
  {
    "text": "and learns which actions lead to good",
    "start": "172770",
    "end": "175170"
  },
  {
    "text": "outcomes and which lead to bad outcomes",
    "start": "175170",
    "end": "177620"
  },
  {
    "text": "it will learn from its experience and",
    "start": "177620",
    "end": "180240"
  },
  {
    "text": "over time repeatedly choose actions that",
    "start": "180240",
    "end": "182640"
  },
  {
    "text": "lead to good outcomes reinforcement",
    "start": "182640",
    "end": "186510"
  },
  {
    "text": "learning has been applied successfully",
    "start": "186510",
    "end": "187800"
  },
  {
    "text": "in a number of practical use cases some",
    "start": "187800",
    "end": "191220"
  },
  {
    "text": "recent examples include autonomous cars",
    "start": "191220",
    "end": "193740"
  },
  {
    "text": "fleet logistics financial trading",
    "start": "193740",
    "end": "196800"
  },
  {
    "text": "algorithms data center cooling and",
    "start": "196800",
    "end": "199350"
  },
  {
    "text": "hatchback systems one area that is not",
    "start": "199350",
    "end": "202800"
  },
  {
    "text": "on here and is worth calling out is",
    "start": "202800",
    "end": "204360"
  },
  {
    "text": "gaming games being a closed environment",
    "start": "204360",
    "end": "207780"
  },
  {
    "text": "with a discrete set of possible actions",
    "start": "207780",
    "end": "209910"
  },
  {
    "text": "make for a great research platform for",
    "start": "209910",
    "end": "212100"
  },
  {
    "text": "RL you have probably heard of deepmind",
    "start": "212100",
    "end": "214950"
  },
  {
    "text": "with alphago but in the world's best go",
    "start": "214950",
    "end": "217260"
  },
  {
    "text": "player an open AI managing to hold its",
    "start": "217260",
    "end": "220080"
  },
  {
    "text": "own in a multiplayer daughter",
    "start": "220080",
    "end": "221430"
  },
  {
    "text": "competition with some of the world's",
    "start": "221430",
    "end": "223140"
  },
  {
    "text": "best players both of these successes",
    "start": "223140",
    "end": "225810"
  },
  {
    "text": "were achieved using reinforcement",
    "start": "225810",
    "end": "227280"
  },
  {
    "text": "learning reinforcement learning is a",
    "start": "227280",
    "end": "231180"
  },
  {
    "text": "subfield of machine learning concerned",
    "start": "231180",
    "end": "232860"
  },
  {
    "text": "with decision making and motor control",
    "start": "232860",
    "end": "235519"
  },
  {
    "text": "more specifically reinforcement learning",
    "start": "235519",
    "end": "239130"
  },
  {
    "text": "is interested in the creation of a model",
    "start": "239130",
    "end": "241110"
  },
  {
    "text": "that can be used by an agent to choose",
    "start": "241110",
    "end": "243720"
  },
  {
    "text": "which actions to take in an environment",
    "start": "243720",
    "end": "245760"
  },
  {
    "text": "in order to achieve a specific goal in",
    "start": "245760",
    "end": "248750"
  },
  {
    "text": "the case of a wsd Brisa the agent is a",
    "start": "248750",
    "end": "252450"
  },
  {
    "text": "virtual RC car the environment is a",
    "start": "252450",
    "end": "255390"
  },
  {
    "text": "virtual racetrack",
    "start": "255390",
    "end": "256530"
  },
  {
    "text": "the actions are throttle and steering",
    "start": "256530",
    "end": "258450"
  },
  {
    "text": "inputs and the goal is completing the",
    "start": "258450",
    "end": "261600"
  },
  {
    "text": "racetrack as quickly as possible",
    "start": "261600",
    "end": "263550"
  },
  {
    "text": "without deviating from the track",
    "start": "263550",
    "end": "266380"
  },
  {
    "text": "the key part of the training process in",
    "start": "266380",
    "end": "268180"
  },
  {
    "text": "RL is how you look to incentivize or",
    "start": "268180",
    "end": "270520"
  },
  {
    "text": "reward the choice of actions that lead",
    "start": "270520",
    "end": "272260"
  },
  {
    "text": "to the specific goal a very simple real",
    "start": "272260",
    "end": "275320"
  },
  {
    "text": "world analogy is how you think about",
    "start": "275320",
    "end": "276970"
  },
  {
    "text": "training a dog to sit when you say sit",
    "start": "276970",
    "end": "280060"
  },
  {
    "text": "and the dog correctly sits you reward it",
    "start": "280060",
    "end": "282100"
  },
  {
    "text": "with a treat when it doesn't sit it",
    "start": "282100",
    "end": "284230"
  },
  {
    "text": "doesn't get a treat hopefully over time",
    "start": "284230",
    "end": "286690"
  },
  {
    "text": "this process of reinforcing good",
    "start": "286690",
    "end": "288400"
  },
  {
    "text": "behavior leads to the dog correctly",
    "start": "288400",
    "end": "290740"
  },
  {
    "text": "sitting when asked to in the case of de",
    "start": "290740",
    "end": "294490"
  },
  {
    "text": "prisa training is an iterative process",
    "start": "294490",
    "end": "296860"
  },
  {
    "text": "where we jump back and forth between",
    "start": "296860",
    "end": "298450"
  },
  {
    "text": "getting experience in the simulated",
    "start": "298450",
    "end": "300400"
  },
  {
    "text": "environment and training the model using",
    "start": "300400",
    "end": "302800"
  },
  {
    "text": "that experience in the simulator the",
    "start": "302800",
    "end": "306670"
  },
  {
    "text": "agent explores the environment with the",
    "start": "306670",
    "end": "308230"
  },
  {
    "text": "first untrained model and builds up",
    "start": "308230",
    "end": "309970"
  },
  {
    "text": "experience this experience is in the",
    "start": "309970",
    "end": "312940"
  },
  {
    "text": "form of state action reward next state",
    "start": "312940",
    "end": "315580"
  },
  {
    "text": "records every time the car takes a",
    "start": "315580",
    "end": "318670"
  },
  {
    "text": "picture which is about 10 times a second",
    "start": "318670",
    "end": "321040"
  },
  {
    "text": "we send that to the current model and it",
    "start": "321040",
    "end": "323650"
  },
  {
    "text": "returns the actions to choose the car",
    "start": "323650",
    "end": "326590"
  },
  {
    "text": "that moves according to his actions and",
    "start": "326590",
    "end": "328240"
  },
  {
    "text": "the simulator uses a reward function you",
    "start": "328240",
    "end": "330610"
  },
  {
    "text": "provide to calculate the reward",
    "start": "330610",
    "end": "332310"
  },
  {
    "text": "essentially how good or bad this outcome",
    "start": "332310",
    "end": "334570"
  },
  {
    "text": "was once we collect a certain amount of",
    "start": "334570",
    "end": "337570"
  },
  {
    "text": "experience this experience is sent to",
    "start": "337570",
    "end": "340210"
  },
  {
    "text": "Sage may go to train the model while",
    "start": "340210",
    "end": "343270"
  },
  {
    "text": "training the weights of the network will",
    "start": "343270",
    "end": "345010"
  },
  {
    "text": "be adjusted to give a higher probability",
    "start": "345010",
    "end": "346630"
  },
  {
    "text": "for actions that lead to higher Awards",
    "start": "346630",
    "end": "348880"
  },
  {
    "text": "in theory it tries to maximize the",
    "start": "348880",
    "end": "351670"
  },
  {
    "text": "cumulative rewards for a set of actions",
    "start": "351670",
    "end": "354510"
  },
  {
    "text": "but simply put the reward function is",
    "start": "354510",
    "end": "357250"
  },
  {
    "text": "used to incentivize the behavior you",
    "start": "357250",
    "end": "358990"
  },
  {
    "text": "want your car to exhibit and which",
    "start": "358990",
    "end": "361330"
  },
  {
    "text": "should lead to the goal a simple example",
    "start": "361330",
    "end": "364510"
  },
  {
    "text": "if the model sees a left-hand turn and",
    "start": "364510",
    "end": "367270"
  },
  {
    "text": "the car goes straight the reward is not",
    "start": "367270",
    "end": "369280"
  },
  {
    "text": "0.5 next time it sees the same left-hand",
    "start": "369280",
    "end": "372670"
  },
  {
    "text": "turn but tries to go left it scores a",
    "start": "372670",
    "end": "375130"
  },
  {
    "text": "reward of 1 based on this experience the",
    "start": "375130",
    "end": "378610"
  },
  {
    "text": "weights in our model will be updated to",
    "start": "378610",
    "end": "380200"
  },
  {
    "text": "start favoring going left the more it",
    "start": "380200",
    "end": "382840"
  },
  {
    "text": "sees this the higher the probability of",
    "start": "382840",
    "end": "385210"
  },
  {
    "text": "going left will become after we have",
    "start": "385210",
    "end": "388480"
  },
  {
    "text": "processed the currently collected",
    "start": "388480",
    "end": "390250"
  },
  {
    "text": "simulator experience the updated model",
    "start": "390250",
    "end": "392770"
  },
  {
    "text": "is sent back to the simulation",
    "start": "392770",
    "end": "394180"
  },
  {
    "text": "environment and the process starts again",
    "start": "394180",
    "end": "396780"
  },
  {
    "text": "each cycle we are gradually improving",
    "start": "396780",
    "end": "399450"
  },
  {
    "text": "the model until we hopefully reach our",
    "start": "399450",
    "end": "401400"
  },
  {
    "text": "goal which is completing the track in",
    "start": "401400",
    "end": "405420"
  },
  {
    "text": "the previous slide I mentioned that the",
    "start": "405420",
    "end": "407400"
  },
  {
    "text": "environment uses a reward function you",
    "start": "407400",
    "end": "409350"
  },
  {
    "text": "provide to score whether the action",
    "start": "409350",
    "end": "411180"
  },
  {
    "text": "taken by the car has resulted in a",
    "start": "411180",
    "end": "413190"
  },
  {
    "text": "positive state ie the car is still on",
    "start": "413190",
    "end": "416340"
  },
  {
    "text": "the track and well positioned the reward",
    "start": "416340",
    "end": "419130"
  },
  {
    "text": "function is the essence of what drives",
    "start": "419130",
    "end": "420870"
  },
  {
    "text": "the training process and is where all",
    "start": "420870",
    "end": "422610"
  },
  {
    "text": "the fun happens a reward function",
    "start": "422610",
    "end": "425220"
  },
  {
    "text": "doesn't have to be particularly",
    "start": "425220",
    "end": "426330"
  },
  {
    "text": "complicated the following is a simple 18",
    "start": "426330",
    "end": "429390"
  },
  {
    "text": "line Python reward function for deep",
    "start": "429390",
    "end": "431250"
  },
  {
    "text": "bracer that attempts to follow the",
    "start": "431250",
    "end": "433260"
  },
  {
    "text": "center line of the track our if-else",
    "start": "433260",
    "end": "435930"
  },
  {
    "text": "statement towards the bottom of the page",
    "start": "435930",
    "end": "437400"
  },
  {
    "text": "gives a reward of 1 if we're close to",
    "start": "437400",
    "end": "439680"
  },
  {
    "text": "the center line and a score of naught",
    "start": "439680",
    "end": "441570"
  },
  {
    "text": "point 1 if we are a long way from the",
    "start": "441570",
    "end": "443370"
  },
  {
    "text": "center line much like in the domains of",
    "start": "443370",
    "end": "447690"
  },
  {
    "text": "supervised and unsupervised learning",
    "start": "447690",
    "end": "449160"
  },
  {
    "text": "there are a large number of algorithms",
    "start": "449160",
    "end": "451020"
  },
  {
    "text": "that can be used to drive the agent",
    "start": "451020",
    "end": "452910"
  },
  {
    "text": "environment interaction in the training",
    "start": "452910",
    "end": "454860"
  },
  {
    "text": "process there are two key families of",
    "start": "454860",
    "end": "457530"
  },
  {
    "text": "algorithms Bayou optimization and policy",
    "start": "457530",
    "end": "460380"
  },
  {
    "text": "optimization deep bracer uses a variant",
    "start": "460380",
    "end": "464250"
  },
  {
    "text": "of policy optimization called proximal",
    "start": "464250",
    "end": "466770"
  },
  {
    "text": "policy optimization or PPO so in the",
    "start": "466770",
    "end": "471120"
  },
  {
    "text": "first part of this talk we have covered",
    "start": "471120",
    "end": "472740"
  },
  {
    "text": "off what reinforcement learning is",
    "start": "472740",
    "end": "474240"
  },
  {
    "text": "through the lens of the 80s deep",
    "start": "474240",
    "end": "476160"
  },
  {
    "text": "bracelet product now let's take a closer",
    "start": "476160",
    "end": "478860"
  },
  {
    "text": "look at a WS deep racer with a quick",
    "start": "478860",
    "end": "481110"
  },
  {
    "text": "demo and some instructions on how you",
    "start": "481110",
    "end": "482790"
  },
  {
    "text": "can get started the odorous deep brace a",
    "start": "482790",
    "end": "486630"
  },
  {
    "text": "console service is a high-level",
    "start": "486630",
    "end": "488400"
  },
  {
    "text": "orchestration tool that provides a",
    "start": "488400",
    "end": "490290"
  },
  {
    "text": "simplified and opinionated approach to",
    "start": "490290",
    "end": "492870"
  },
  {
    "text": "the task of training the deep racer it",
    "start": "492870",
    "end": "495720"
  },
  {
    "text": "looks to make it as simple as possible",
    "start": "495720",
    "end": "497070"
  },
  {
    "text": "for users to start exploring RL while",
    "start": "497070",
    "end": "500070"
  },
  {
    "text": "handling a lot of the framework",
    "start": "500070",
    "end": "501240"
  },
  {
    "text": "algorithm hyper parameter choices you",
    "start": "501240",
    "end": "503970"
  },
  {
    "text": "need to make if getting started on your",
    "start": "503970",
    "end": "505530"
  },
  {
    "text": "own",
    "start": "505530",
    "end": "505740"
  },
  {
    "text": "are all use cases under the covers it is",
    "start": "505740",
    "end": "509220"
  },
  {
    "text": "making use of sage maker and Robo maker",
    "start": "509220",
    "end": "511350"
  },
  {
    "text": "to do the training and run the",
    "start": "511350",
    "end": "512940"
  },
  {
    "text": "simulation environment respectively here",
    "start": "512940",
    "end": "516690"
  },
  {
    "text": "we show an overview of the network",
    "start": "516690",
    "end": "518310"
  },
  {
    "text": "architecture that a diversity racer",
    "start": "518310",
    "end": "520500"
  },
  {
    "text": "trains in the simulator the car takes a",
    "start": "520500",
    "end": "523950"
  },
  {
    "text": "picture of the environment and this",
    "start": "523950",
    "end": "525360"
  },
  {
    "text": "picture is converted to grayscale we",
    "start": "525360",
    "end": "527790"
  },
  {
    "text": "then have a convolutional neural network",
    "start": "527790",
    "end": "530350"
  },
  {
    "text": "with three layers where we do feature",
    "start": "530350",
    "end": "532810"
  },
  {
    "text": "extraction we then have a fully",
    "start": "532810",
    "end": "535300"
  },
  {
    "text": "connected layer which is the output of",
    "start": "535300",
    "end": "537070"
  },
  {
    "text": "the CNM this then feeds into the policy",
    "start": "537070",
    "end": "540400"
  },
  {
    "text": "network which is a fully connected layer",
    "start": "540400",
    "end": "542320"
  },
  {
    "text": "followed by the actions the model will",
    "start": "542320",
    "end": "545230"
  },
  {
    "text": "output a probability distribution over",
    "start": "545230",
    "end": "547450"
  },
  {
    "text": "the action space the actions can be full",
    "start": "547450",
    "end": "550060"
  },
  {
    "text": "left slight left fast straight slow",
    "start": "550060",
    "end": "552790"
  },
  {
    "text": "straight slight right full right when",
    "start": "552790",
    "end": "557170"
  },
  {
    "text": "you log into the ada boost console and",
    "start": "557170",
    "end": "558970"
  },
  {
    "text": "then into the a USD bracer service you",
    "start": "558970",
    "end": "561940"
  },
  {
    "text": "are able to create a model and configure",
    "start": "561940",
    "end": "563560"
  },
  {
    "text": "the model by specifying the reward",
    "start": "563560",
    "end": "565180"
  },
  {
    "text": "function and hyper parameters these are",
    "start": "565180",
    "end": "568030"
  },
  {
    "text": "critical in tweaking and tuning your",
    "start": "568030",
    "end": "569590"
  },
  {
    "text": "model to try and get the best model",
    "start": "569590",
    "end": "571150"
  },
  {
    "text": "performance you then launch the training",
    "start": "571150",
    "end": "574180"
  },
  {
    "text": "process during which you can watch a",
    "start": "574180",
    "end": "575680"
  },
  {
    "text": "live stream of your car interacting with",
    "start": "575680",
    "end": "577780"
  },
  {
    "text": "the simulator once trained you can then",
    "start": "577780",
    "end": "580390"
  },
  {
    "text": "run the evaluation process if you are",
    "start": "580390",
    "end": "583270"
  },
  {
    "text": "happy with the performance of your model",
    "start": "583270",
    "end": "584830"
  },
  {
    "text": "you can submit your model to a",
    "start": "584830",
    "end": "586300"
  },
  {
    "text": "leaderboard for evaluation or you can",
    "start": "586300",
    "end": "588730"
  },
  {
    "text": "download the model and choose to deploy",
    "start": "588730",
    "end": "590380"
  },
  {
    "text": "it to the deep racer car for a real-life",
    "start": "590380",
    "end": "592420"
  },
  {
    "text": "experience if you are not happy with",
    "start": "592420",
    "end": "595120"
  },
  {
    "text": "your model performance you can clone the",
    "start": "595120",
    "end": "596710"
  },
  {
    "text": "model reconfigure it and train again we",
    "start": "596710",
    "end": "600550"
  },
  {
    "text": "start by jumping into the AWS console",
    "start": "600550",
    "end": "602710"
  },
  {
    "text": "and loading up the deep bracelet service",
    "start": "602710",
    "end": "606780"
  },
  {
    "text": "your entry point is to create a new",
    "start": "611310",
    "end": "613780"
  },
  {
    "text": "model or project in this case we're",
    "start": "613780",
    "end": "616360"
  },
  {
    "text": "having a pre-existing one but we're",
    "start": "616360",
    "end": "618100"
  },
  {
    "text": "going to create a new one we give the",
    "start": "618100",
    "end": "622960"
  },
  {
    "text": "model a name in this case innovate -",
    "start": "622960",
    "end": "627820"
  },
  {
    "text": "model we select a simulation environment",
    "start": "627820",
    "end": "633850"
  },
  {
    "text": "in this case we only have one which is",
    "start": "633850",
    "end": "635710"
  },
  {
    "text": "the reinvent 2018 track next we choose a",
    "start": "635710",
    "end": "641440"
  },
  {
    "text": "reward function so it comes",
    "start": "641440",
    "end": "643180"
  },
  {
    "text": "pre-populated with a basic function that",
    "start": "643180",
    "end": "645190"
  },
  {
    "text": "you can extend and then on the left",
    "start": "645190",
    "end": "648220"
  },
  {
    "text": "there's some optional other functions",
    "start": "648220",
    "end": "649900"
  },
  {
    "text": "you can leverage",
    "start": "649900",
    "end": "652380"
  },
  {
    "text": "in this case we're going to choose one",
    "start": "658100",
    "end": "660329"
  },
  {
    "text": "of the more advanced functions that",
    "start": "660329",
    "end": "661980"
  },
  {
    "text": "looks to smooth out the basic center",
    "start": "661980",
    "end": "664470"
  },
  {
    "text": "line algorithm next we have our",
    "start": "664470",
    "end": "669060"
  },
  {
    "text": "algorithm settings where you can choose",
    "start": "669060",
    "end": "671490"
  },
  {
    "text": "the hyper parameters that configure our",
    "start": "671490",
    "end": "674209"
  },
  {
    "text": "PPO algorithm and then finally we",
    "start": "674209",
    "end": "678060"
  },
  {
    "text": "specify a stop condition in this case 60",
    "start": "678060",
    "end": "680579"
  },
  {
    "text": "minutes",
    "start": "680579",
    "end": "682878"
  },
  {
    "text": "at this point our model has been created",
    "start": "687430",
    "end": "690190"
  },
  {
    "text": "we can click on the model and start the",
    "start": "690190",
    "end": "692529"
  },
  {
    "text": "training process",
    "start": "692529",
    "end": "695220"
  },
  {
    "text": "you",
    "start": "699960",
    "end": "702020"
  },
  {
    "text": "a new instance has been provisioned to",
    "start": "705620",
    "end": "707900"
  },
  {
    "text": "run our training job we skip the",
    "start": "707900",
    "end": "710540"
  },
  {
    "text": "six-minute provisioning time and now we",
    "start": "710540",
    "end": "712700"
  },
  {
    "text": "can see the training in progress so in",
    "start": "712700",
    "end": "715640"
  },
  {
    "text": "this case the training have been running",
    "start": "715640",
    "end": "716930"
  },
  {
    "text": "for a little while before I recorded",
    "start": "716930",
    "end": "718550"
  },
  {
    "text": "this piece and you can see that the car",
    "start": "718550",
    "end": "720440"
  },
  {
    "text": "is managing to hug the centerline for",
    "start": "720440",
    "end": "723170"
  },
  {
    "text": "the initial straight but then fails in",
    "start": "723170",
    "end": "725240"
  },
  {
    "text": "the turn we can refresh the graph on the",
    "start": "725240",
    "end": "729650"
  },
  {
    "text": "left here to see the cumulative reward",
    "start": "729650",
    "end": "731840"
  },
  {
    "text": "functions slowly improving as the",
    "start": "731840",
    "end": "733400"
  },
  {
    "text": "training process progresses finally once",
    "start": "733400",
    "end": "737390"
  },
  {
    "text": "training is complete we can see the",
    "start": "737390",
    "end": "739820"
  },
  {
    "text": "total graph we can move on to running an",
    "start": "739820",
    "end": "742910"
  },
  {
    "text": "evaluation process so this takes our",
    "start": "742910",
    "end": "745580"
  },
  {
    "text": "model runs it in the simulator we choose",
    "start": "745580",
    "end": "751580"
  },
  {
    "text": "our reinvent track again the number of",
    "start": "751580",
    "end": "754010"
  },
  {
    "text": "laps we'd like to do and kick that off",
    "start": "754010",
    "end": "762670"
  },
  {
    "text": "again a new instance is provisioned to",
    "start": "762940",
    "end": "765170"
  },
  {
    "text": "run our training job once this completes",
    "start": "765170",
    "end": "769520"
  },
  {
    "text": "you can see how successful my model was",
    "start": "769520",
    "end": "771550"
  },
  {
    "text": "in this case none of the models managed",
    "start": "771550",
    "end": "775040"
  },
  {
    "text": "none of the laps managed to complete the",
    "start": "775040",
    "end": "776600"
  },
  {
    "text": "track my best case was 87% and a time of",
    "start": "776600",
    "end": "780740"
  },
  {
    "text": "1 minute 10 finally you can see the",
    "start": "780740",
    "end": "784520"
  },
  {
    "text": "configuration that was used for this",
    "start": "784520",
    "end": "785840"
  },
  {
    "text": "training job in this case I'm not happy",
    "start": "785840",
    "end": "788780"
  },
  {
    "text": "with the model",
    "start": "788780",
    "end": "789440"
  },
  {
    "text": "I'd be looking to clone it take it back",
    "start": "789440",
    "end": "791420"
  },
  {
    "text": "and run a new new training process",
    "start": "791420",
    "end": "794500"
  },
  {
    "text": "hopefully you're encouraged to give a",
    "start": "794500",
    "end": "796610"
  },
  {
    "text": "diversity tracer a try later this year",
    "start": "796610",
    "end": "798620"
  },
  {
    "text": "when the service goes GA when it happens",
    "start": "798620",
    "end": "801680"
  },
  {
    "text": "you can work through the self-paced labs",
    "start": "801680",
    "end": "803240"
  },
  {
    "text": "that will run at reinvent 2018 and",
    "start": "803240",
    "end": "805460"
  },
  {
    "text": "they're now hosted on github once you",
    "start": "805460",
    "end": "809870"
  },
  {
    "text": "have a trained model in the ADHD crates",
    "start": "809870",
    "end": "811760"
  },
  {
    "text": "a console you then have the option of",
    "start": "811760",
    "end": "813440"
  },
  {
    "text": "downloading the model and transferring",
    "start": "813440",
    "end": "815180"
  },
  {
    "text": "it to a deep bracelet device you can",
    "start": "815180",
    "end": "817790"
  },
  {
    "text": "then test the car a model on a",
    "start": "817790",
    "end": "819110"
  },
  {
    "text": "real-world race track like the ones that",
    "start": "819110",
    "end": "820940"
  },
  {
    "text": "were set up at reinvent 2018 a quick",
    "start": "820940",
    "end": "824060"
  },
  {
    "text": "overview of the car it's a standard RC",
    "start": "824060",
    "end": "829190"
  },
  {
    "text": "car base well chassis we seen compute",
    "start": "829190",
    "end": "834470"
  },
  {
    "text": "and vision Hardware attached to the top",
    "start": "834470",
    "end": "836120"
  },
  {
    "text": "it shares some of the base level",
    "start": "836120",
    "end": "838250"
  },
  {
    "text": "componentry of",
    "start": "838250",
    "end": "839120"
  },
  {
    "text": "deep lens we have an Intel Atom",
    "start": "839120",
    "end": "840980"
  },
  {
    "text": "processor for gig of ram Wi-Fi a four",
    "start": "840980",
    "end": "844970"
  },
  {
    "text": "megapixel camera on the front an",
    "start": "844970",
    "end": "847279"
  },
  {
    "text": "integrated accelerometer and gyroscope",
    "start": "847279",
    "end": "850070"
  },
  {
    "text": "and extra USB ports for future",
    "start": "850070",
    "end": "852350"
  },
  {
    "text": "attachments we use the robot operating",
    "start": "852350",
    "end": "859550"
  },
  {
    "text": "system ROS version one on top of Ubuntu",
    "start": "859550",
    "end": "862370"
  },
  {
    "text": "to power the device in autonomous mode",
    "start": "862370",
    "end": "865310"
  },
  {
    "text": "we take pictures with the camera pass it",
    "start": "865310",
    "end": "868010"
  },
  {
    "text": "to the media engine which sends it to",
    "start": "868010",
    "end": "870050"
  },
  {
    "text": "the open V no inference engine the",
    "start": "870050",
    "end": "872990"
  },
  {
    "text": "inference engine which is running our",
    "start": "872990",
    "end": "874370"
  },
  {
    "text": "model returns the steering actions that",
    "start": "874370",
    "end": "876710"
  },
  {
    "text": "will be sent to the controller node",
    "start": "876710",
    "end": "878240"
  },
  {
    "text": "essentially converting steering and",
    "start": "878240",
    "end": "880310"
  },
  {
    "text": "throttle inputs into pulse width",
    "start": "880310",
    "end": "882170"
  },
  {
    "text": "modulation signals sent to the various",
    "start": "882170",
    "end": "884390"
  },
  {
    "text": "motors one of the challenges with doing",
    "start": "884390",
    "end": "887750"
  },
  {
    "text": "your training in a simulated environment",
    "start": "887750",
    "end": "889790"
  },
  {
    "text": "is that there is likely to be a gap",
    "start": "889790",
    "end": "891529"
  },
  {
    "text": "between how the simulated environment",
    "start": "891529",
    "end": "893420"
  },
  {
    "text": "looks and behaves compared to the real",
    "start": "893420",
    "end": "895400"
  },
  {
    "text": "world a number of strategies we can",
    "start": "895400",
    "end": "897980"
  },
  {
    "text": "follow to bridge this gap step one",
    "start": "897980",
    "end": "900560"
  },
  {
    "text": "control the environment make the",
    "start": "900560",
    "end": "902180"
  },
  {
    "text": "simulator and real world soon as close",
    "start": "902180",
    "end": "903980"
  },
  {
    "text": "to each other as possible",
    "start": "903980",
    "end": "905180"
  },
  {
    "text": "our reward tracks tries to mimic the",
    "start": "905180",
    "end": "907760"
  },
  {
    "text": "simulated environment as much as",
    "start": "907760",
    "end": "909170"
  },
  {
    "text": "possible the next approach is",
    "start": "909170",
    "end": "911690"
  },
  {
    "text": "randomizing the environment this allows",
    "start": "911690",
    "end": "913790"
  },
  {
    "text": "the model to generalize for example have",
    "start": "913790",
    "end": "916640"
  },
  {
    "text": "the environment frequently randomize the",
    "start": "916640",
    "end": "918620"
  },
  {
    "text": "colors of the track and lines so that",
    "start": "918620",
    "end": "920720"
  },
  {
    "text": "doesn't expect a certain color it just",
    "start": "920720",
    "end": "922880"
  },
  {
    "text": "focuses on the shapes then finally you",
    "start": "922880",
    "end": "926150"
  },
  {
    "text": "can run additional models in your",
    "start": "926150",
    "end": "927589"
  },
  {
    "text": "network architecture that will extract",
    "start": "927589",
    "end": "929810"
  },
  {
    "text": "useful information from the image for",
    "start": "929810",
    "end": "931760"
  },
  {
    "text": "example put a model in place that can",
    "start": "931760",
    "end": "933980"
  },
  {
    "text": "detect whether the upcoming road is",
    "start": "933980",
    "end": "935450"
  },
  {
    "text": "straight curves left or curves right",
    "start": "935450",
    "end": "937959"
  },
  {
    "text": "feed this into our policy networks your",
    "start": "937959",
    "end": "940820"
  },
  {
    "text": "model and train on top of this",
    "start": "940820",
    "end": "942230"
  },
  {
    "text": "additional information provided an image",
    "start": "942230",
    "end": "944150"
  },
  {
    "text": "a EWS deep racer is a fun way to learn",
    "start": "944150",
    "end": "949220"
  },
  {
    "text": "about RL and optionally compete in a",
    "start": "949220",
    "end": "951230"
  },
  {
    "text": "global competition but what if you want",
    "start": "951230",
    "end": "953930"
  },
  {
    "text": "to take the next step and apply RL",
    "start": "953930",
    "end": "955790"
  },
  {
    "text": "techniques to solve challenges in your",
    "start": "955790",
    "end": "957529"
  },
  {
    "text": "own area of expertise this is where the",
    "start": "957529",
    "end": "960589"
  },
  {
    "text": "RL extensions for Sage Maker that were",
    "start": "960589",
    "end": "962870"
  },
  {
    "text": "also announced at reinvent 2018 come in",
    "start": "962870",
    "end": "966610"
  },
  {
    "text": "so what are some of the problems that we",
    "start": "966610",
    "end": "968839"
  },
  {
    "text": "have observed customers is having when",
    "start": "968839",
    "end": "970850"
  },
  {
    "text": "trying to get started with RL the",
    "start": "970850",
    "end": "972649"
  },
  {
    "text": "the new features in Sage Maker are",
    "start": "972649",
    "end": "974240"
  },
  {
    "text": "looking to address with the large",
    "start": "974240",
    "end": "977269"
  },
  {
    "text": "variety of frameworks toolkits and",
    "start": "977269",
    "end": "979220"
  },
  {
    "text": "training environments how do you get",
    "start": "979220",
    "end": "980660"
  },
  {
    "text": "started once you have decided on a",
    "start": "980660",
    "end": "983300"
  },
  {
    "text": "particular RL toolkit and algorithm how",
    "start": "983300",
    "end": "985879"
  },
  {
    "text": "would you apply it once you have decided",
    "start": "985879",
    "end": "989029"
  },
  {
    "text": "on a particular simulation environment",
    "start": "989029",
    "end": "990559"
  },
  {
    "text": "how would you use it",
    "start": "990559",
    "end": "992860"
  },
  {
    "text": "provisioning and operating the",
    "start": "992860",
    "end": "994490"
  },
  {
    "text": "infrastructure for RL is difficult and",
    "start": "994490",
    "end": "996709"
  },
  {
    "text": "expensive RL requires lots of trial and",
    "start": "996709",
    "end": "1000309"
  },
  {
    "text": "error which is time-consuming",
    "start": "1000309",
    "end": "1003329"
  },
  {
    "text": "saij make it looks to address these",
    "start": "1003420",
    "end": "1005529"
  },
  {
    "text": "concerns by providing pre-built",
    "start": "1005529",
    "end": "1008110"
  },
  {
    "text": "environments for RL across a variety of",
    "start": "1008110",
    "end": "1010209"
  },
  {
    "text": "use cases to make getting started",
    "start": "1010209",
    "end": "1011769"
  },
  {
    "text": "simpler sage maker has inbuilt support",
    "start": "1011769",
    "end": "1015249"
  },
  {
    "text": "for some of the more common RL toolkits",
    "start": "1015249",
    "end": "1017319"
  },
  {
    "text": "and algorithms along with support for a",
    "start": "1017319",
    "end": "1019389"
  },
  {
    "text": "BYO model sage makers inbuilt support",
    "start": "1019389",
    "end": "1023679"
  },
  {
    "text": "for some of the more common RL",
    "start": "1023679",
    "end": "1025000"
  },
  {
    "text": "simulation environments along with",
    "start": "1025000",
    "end": "1026980"
  },
  {
    "text": "support for a BYO model sage maker also",
    "start": "1026980",
    "end": "1031149"
  },
  {
    "text": "has support for on-demand provision of",
    "start": "1031149",
    "end": "1032770"
  },
  {
    "text": "training fee structure and the ability",
    "start": "1032770",
    "end": "1034808"
  },
  {
    "text": "to run training jobs in a distributed",
    "start": "1034809",
    "end": "1036610"
  },
  {
    "text": "manner",
    "start": "1036610",
    "end": "1037678"
  },
  {
    "text": "sage maker supports local debugging mode",
    "start": "1037679",
    "end": "1040209"
  },
  {
    "text": "and automatic model tuning by a hyper",
    "start": "1040209",
    "end": "1042788"
  },
  {
    "text": "parameter optimization there are",
    "start": "1042789",
    "end": "1046899"
  },
  {
    "text": "multiple layers to reinforcement",
    "start": "1046899",
    "end": "1048308"
  },
  {
    "text": "learning features that have been added",
    "start": "1048309",
    "end": "1049570"
  },
  {
    "text": "to Sage Maker at the top we have a",
    "start": "1049570",
    "end": "1053230"
  },
  {
    "text": "series of end-to-end examples for",
    "start": "1053230",
    "end": "1055000"
  },
  {
    "text": "particular domains that are checked into",
    "start": "1055000",
    "end": "1057159"
  },
  {
    "text": "github and available via the jupiter",
    "start": "1057159",
    "end": "1059020"
  },
  {
    "text": "notebook instances that are managed by",
    "start": "1059020",
    "end": "1060730"
  },
  {
    "text": "sage maker this can provide a quick",
    "start": "1060730",
    "end": "1063549"
  },
  {
    "text": "start to running your training jobs in",
    "start": "1063549",
    "end": "1065200"
  },
  {
    "text": "sage maker which you can customize to",
    "start": "1065200",
    "end": "1067240"
  },
  {
    "text": "for your particular needs",
    "start": "1067240",
    "end": "1068850"
  },
  {
    "text": "the next layer deals with the",
    "start": "1068850",
    "end": "1070929"
  },
  {
    "text": "integration of simulation environments",
    "start": "1070929",
    "end": "1072779"
  },
  {
    "text": "sage maker supports a diverse",
    "start": "1072779",
    "end": "1074850"
  },
  {
    "text": "environments like Amazon Sumerian and a",
    "start": "1074850",
    "end": "1077679"
  },
  {
    "text": "diverse Romo maker it also provides",
    "start": "1077679",
    "end": "1080710"
  },
  {
    "text": "support for open source environments",
    "start": "1080710",
    "end": "1082270"
  },
  {
    "text": "like open AI gem and commercial",
    "start": "1082270",
    "end": "1084490"
  },
  {
    "text": "simulators like MATLAB there is also the",
    "start": "1084490",
    "end": "1087760"
  },
  {
    "text": "option to BYO your own environment via",
    "start": "1087760",
    "end": "1090669"
  },
  {
    "text": "containers the next layer deals with RL",
    "start": "1090669",
    "end": "1094240"
  },
  {
    "text": "toolkit and algorithm support sage maker",
    "start": "1094240",
    "end": "1097929"
  },
  {
    "text": "has inbuilt support for intel's",
    "start": "1097929",
    "end": "1099669"
  },
  {
    "text": "RL coach and RL ray RL lib toolkits",
    "start": "1099669",
    "end": "1102909"
  },
  {
    "text": "again with a BYO model for customers to",
    "start": "1102909",
    "end": "1105279"
  },
  {
    "text": "bring their own",
    "start": "1105279",
    "end": "1106180"
  },
  {
    "text": "a key theme here is being able to make",
    "start": "1106180",
    "end": "1109360"
  },
  {
    "text": "the most common choices easy to",
    "start": "1109360",
    "end": "1110890"
  },
  {
    "text": "implement and natively supported while",
    "start": "1110890",
    "end": "1113650"
  },
  {
    "text": "remaining platform toolkit agnostic to",
    "start": "1113650",
    "end": "1115900"
  },
  {
    "text": "cater for the rapid pace of change in",
    "start": "1115900",
    "end": "1118000"
  },
  {
    "text": "software and the AI ml space it's worth",
    "start": "1118000",
    "end": "1122620"
  },
  {
    "text": "highlighting some of the pre-existing",
    "start": "1122620",
    "end": "1124210"
  },
  {
    "text": "strengths of Amazon sage maker that you",
    "start": "1124210",
    "end": "1126160"
  },
  {
    "text": "can bring to bear with RL training and",
    "start": "1126160",
    "end": "1128350"
  },
  {
    "text": "in particular how it makes it easier to",
    "start": "1128350",
    "end": "1130060"
  },
  {
    "text": "scale and distribute the training",
    "start": "1130060",
    "end": "1131440"
  },
  {
    "text": "workloads with a pay for what you use",
    "start": "1131440",
    "end": "1132850"
  },
  {
    "text": "consumption model key features like the",
    "start": "1132850",
    "end": "1136900"
  },
  {
    "text": "capability to automatically provision",
    "start": "1136900",
    "end": "1138700"
  },
  {
    "text": "and teardown high performance GPU and",
    "start": "1138700",
    "end": "1140740"
  },
  {
    "text": "CPU instance types just for the duration",
    "start": "1140740",
    "end": "1142750"
  },
  {
    "text": "of your training drug the ability to do",
    "start": "1142750",
    "end": "1145330"
  },
  {
    "text": "a distributed training cluster",
    "start": "1145330",
    "end": "1147700"
  },
  {
    "text": "management for training and hosting",
    "start": "1147700",
    "end": "1149610"
  },
  {
    "text": "built-in support for capturing logs and",
    "start": "1149610",
    "end": "1152140"
  },
  {
    "text": "recording training metrics then",
    "start": "1152140",
    "end": "1154390"
  },
  {
    "text": "particularly for RL the ability to",
    "start": "1154390",
    "end": "1156490"
  },
  {
    "text": "support local and remote simulation",
    "start": "1156490",
    "end": "1158290"
  },
  {
    "text": "environments and the ability to scale",
    "start": "1158290",
    "end": "1160600"
  },
  {
    "text": "and paralyze simulation runs the",
    "start": "1160600",
    "end": "1163990"
  },
  {
    "text": "following slide shows four deep bracelet",
    "start": "1163990",
    "end": "1166000"
  },
  {
    "text": "simulation environments running in",
    "start": "1166000",
    "end": "1167410"
  },
  {
    "text": "parallel deep Racer uses the open source",
    "start": "1167410",
    "end": "1170710"
  },
  {
    "text": "physics and graphics engine this ebo to",
    "start": "1170710",
    "end": "1173200"
  },
  {
    "text": "run the racetrack simulator in AWS Robo",
    "start": "1173200",
    "end": "1175780"
  },
  {
    "text": "maker so we start by jumping into the",
    "start": "1175780",
    "end": "1178810"
  },
  {
    "text": "iOS console and launching the database",
    "start": "1178810",
    "end": "1181270"
  },
  {
    "text": "sage maker service if you have used sage",
    "start": "1181270",
    "end": "1185980"
  },
  {
    "text": "maker before you will know that managed",
    "start": "1185980",
    "end": "1188020"
  },
  {
    "text": "to Paterno ebooks is a feature we",
    "start": "1188020",
    "end": "1189580"
  },
  {
    "text": "provide to make managing and",
    "start": "1189580",
    "end": "1190930"
  },
  {
    "text": "orchestrating the underlying sage make",
    "start": "1190930",
    "end": "1193180"
  },
  {
    "text": "our api is easier to get started with",
    "start": "1193180",
    "end": "1196980"
  },
  {
    "text": "you can create an",
    "start": "1201660",
    "end": "1203480"
  },
  {
    "text": "notebook instance or in this case we",
    "start": "1203480",
    "end": "1205910"
  },
  {
    "text": "will load up an existing notebook",
    "start": "1205910",
    "end": "1209230"
  },
  {
    "text": "you",
    "start": "1224710",
    "end": "1226770"
  },
  {
    "text": "this point we open the pre-existing",
    "start": "1228060",
    "end": "1229830"
  },
  {
    "text": "notebook and launch Jupiter",
    "start": "1229830",
    "end": "1233570"
  },
  {
    "text": "at this point you can jump into the",
    "start": "1237770",
    "end": "1239450"
  },
  {
    "text": "stage major examples and load up one of",
    "start": "1239450",
    "end": "1241760"
  },
  {
    "text": "the RL quick starts that we talked about",
    "start": "1241760",
    "end": "1243440"
  },
  {
    "text": "previously",
    "start": "1243440",
    "end": "1245889"
  },
  {
    "text": "in today's demo we are going to look at",
    "start": "1248770",
    "end": "1251020"
  },
  {
    "text": "the open AI gem cart poll example",
    "start": "1251020",
    "end": "1254660"
  },
  {
    "text": "carpol is a hello world ish our real",
    "start": "1254660",
    "end": "1257429"
  },
  {
    "text": "problem published in the open AI gym",
    "start": "1257429",
    "end": "1259530"
  },
  {
    "text": "environment",
    "start": "1259530",
    "end": "1261679"
  },
  {
    "text": "you",
    "start": "1267549",
    "end": "1269610"
  },
  {
    "text": "if you are familiar with the other sage",
    "start": "1285450",
    "end": "1287280"
  },
  {
    "text": "maker notebooks you can see it follows a",
    "start": "1287280",
    "end": "1289170"
  },
  {
    "text": "similar pattern at the top we are",
    "start": "1289170",
    "end": "1290820"
  },
  {
    "text": "loading up our required libraries",
    "start": "1290820",
    "end": "1292880"
  },
  {
    "text": "setting up some plumbing to s3 to store",
    "start": "1292880",
    "end": "1295440"
  },
  {
    "text": "model artifacts and training data then",
    "start": "1295440",
    "end": "1297750"
  },
  {
    "text": "we dive into the hyper parameter",
    "start": "1297750",
    "end": "1299160"
  },
  {
    "text": "optimization for our training run in",
    "start": "1299160",
    "end": "1302040"
  },
  {
    "text": "this case we are configuring the clipped",
    "start": "1302040",
    "end": "1303930"
  },
  {
    "text": "PPO algorithm from the Intel coach RL",
    "start": "1303930",
    "end": "1306570"
  },
  {
    "text": "toolkit using native support for coach",
    "start": "1306570",
    "end": "1308580"
  },
  {
    "text": "in the SDK",
    "start": "1308580",
    "end": "1311539"
  },
  {
    "text": "you",
    "start": "1317180",
    "end": "1319240"
  },
  {
    "text": "further down we are loading up the gym",
    "start": "1336570",
    "end": "1338550"
  },
  {
    "text": "environment with the cart pole",
    "start": "1338550",
    "end": "1340170"
  },
  {
    "text": "application",
    "start": "1340170",
    "end": "1343010"
  },
  {
    "text": "you",
    "start": "1348130",
    "end": "1350040"
  },
  {
    "text": "in this case we are configuring the",
    "start": "1350040",
    "end": "1352200"
  },
  {
    "text": "clipped PPO algorithm from the Intel",
    "start": "1352200",
    "end": "1354420"
  },
  {
    "text": "coach RL toolkit using native support",
    "start": "1354420",
    "end": "1357000"
  },
  {
    "text": "for Coach in the SDK",
    "start": "1357000",
    "end": "1360470"
  },
  {
    "text": "then we load up the gym environment with",
    "start": "1360660",
    "end": "1362580"
  },
  {
    "text": "the cart pole application",
    "start": "1362580",
    "end": "1365200"
  },
  {
    "text": "then we have two blocks that are",
    "start": "1365200",
    "end": "1367000"
  },
  {
    "text": "responsible for pulling together our",
    "start": "1367000",
    "end": "1368860"
  },
  {
    "text": "initialization blocks into the final",
    "start": "1368860",
    "end": "1371170"
  },
  {
    "text": "training job definition",
    "start": "1371170",
    "end": "1374430"
  },
  {
    "text": "our L estimator is the primary entry",
    "start": "1378730",
    "end": "1381280"
  },
  {
    "text": "point for defining our L training jobs",
    "start": "1381280",
    "end": "1383260"
  },
  {
    "text": "in sage maker RL",
    "start": "1383260",
    "end": "1386460"
  },
  {
    "text": "you",
    "start": "1391730",
    "end": "1393790"
  },
  {
    "text": "next we go into visualizing how the",
    "start": "1402020",
    "end": "1404120"
  },
  {
    "text": "training job went",
    "start": "1404120",
    "end": "1406160"
  },
  {
    "text": "first we graph out what the cumulative",
    "start": "1406160",
    "end": "1408200"
  },
  {
    "text": "training reward is in each episode then",
    "start": "1408200",
    "end": "1411830"
  },
  {
    "text": "we can visualize one of these episodes",
    "start": "1411830",
    "end": "1413390"
  },
  {
    "text": "running in the simulated environment",
    "start": "1413390",
    "end": "1417040"
  },
  {
    "text": "here we can see the cart pole game in",
    "start": "1422040",
    "end": "1424050"
  },
  {
    "text": "action it's about trying to keep the",
    "start": "1424050",
    "end": "1426090"
  },
  {
    "text": "pole vertical by moving the cart left or",
    "start": "1426090",
    "end": "1428160"
  },
  {
    "text": "right to counter the pole trying to fall",
    "start": "1428160",
    "end": "1430080"
  },
  {
    "text": "left or right",
    "start": "1430080",
    "end": "1432649"
  },
  {
    "text": "you",
    "start": "1438040",
    "end": "1440100"
  },
  {
    "text": "and once you have a trained model you",
    "start": "1451310",
    "end": "1453080"
  },
  {
    "text": "can run an evaluation step to see if you",
    "start": "1453080",
    "end": "1455330"
  },
  {
    "text": "have solved the goal of car poll",
    "start": "1455330",
    "end": "1458950"
  },
  {
    "text": "finally one of the key features of sage",
    "start": "1462840",
    "end": "1465059"
  },
  {
    "text": "maker is the ability to quickly",
    "start": "1465059",
    "end": "1466559"
  },
  {
    "text": "provision your model into a hosted",
    "start": "1466559",
    "end": "1468480"
  },
  {
    "text": "environment fronted by a rest endpoint",
    "start": "1468480",
    "end": "1470720"
  },
  {
    "text": "this allows you to do inference from",
    "start": "1470720",
    "end": "1473100"
  },
  {
    "text": "your applications in a highly scalable",
    "start": "1473100",
    "end": "1474960"
  },
  {
    "text": "way here we are provisioning a model and",
    "start": "1474960",
    "end": "1478409"
  },
  {
    "text": "then make making several predictions",
    "start": "1478409",
    "end": "1480029"
  },
  {
    "text": "against the model with arbitrary cart",
    "start": "1480029",
    "end": "1482100"
  },
  {
    "text": "and pole positions finally you can then",
    "start": "1482100",
    "end": "1485940"
  },
  {
    "text": "clean up that provision model once",
    "start": "1485940",
    "end": "1487440"
  },
  {
    "text": "you're finished with it hopefully this",
    "start": "1487440",
    "end": "1491129"
  },
  {
    "text": "example has demonstrated that applying",
    "start": "1491129",
    "end": "1493139"
  },
  {
    "text": "some of the common RL toolkits against",
    "start": "1493139",
    "end": "1495179"
  },
  {
    "text": "some of the common simulation",
    "start": "1495179",
    "end": "1496379"
  },
  {
    "text": "environments is easier than it used to",
    "start": "1496379",
    "end": "1498269"
  },
  {
    "text": "be",
    "start": "1498269",
    "end": "1499980"
  },
  {
    "text": "so to summarize what we have covered",
    "start": "1499980",
    "end": "1501630"
  },
  {
    "text": "today in the first section we had a",
    "start": "1501630",
    "end": "1504510"
  },
  {
    "text": "quick tour of what reinforcement",
    "start": "1504510",
    "end": "1506130"
  },
  {
    "text": "learning is and how it works within the",
    "start": "1506130",
    "end": "1507929"
  },
  {
    "text": "context of a wsd presser next we had a",
    "start": "1507929",
    "end": "1511590"
  },
  {
    "text": "look at a diversity bracer in more",
    "start": "1511590",
    "end": "1513210"
  },
  {
    "text": "detail and got a feel for how easy it is",
    "start": "1513210",
    "end": "1515610"
  },
  {
    "text": "for both developers and data scientists",
    "start": "1515610",
    "end": "1517649"
  },
  {
    "text": "to start experimenting with",
    "start": "1517649",
    "end": "1518820"
  },
  {
    "text": "reinforcement learning then finally for",
    "start": "1518820",
    "end": "1522480"
  },
  {
    "text": "those that are looking to apply our ell",
    "start": "1522480",
    "end": "1524070"
  },
  {
    "text": "techniques to their own challenges we",
    "start": "1524070",
    "end": "1526350"
  },
  {
    "text": "covered how Amazon sage maker RL now",
    "start": "1526350",
    "end": "1528630"
  },
  {
    "text": "makes it much easier to start train and",
    "start": "1528630",
    "end": "1530760"
  },
  {
    "text": "support our l train models on the AWS",
    "start": "1530760",
    "end": "1533190"
  },
  {
    "text": "platform visit the demo arena and watch",
    "start": "1533190",
    "end": "1536730"
  },
  {
    "text": "our machine learning is used in",
    "start": "1536730",
    "end": "1538080"
  },
  {
    "text": "real-life applications get your",
    "start": "1538080",
    "end": "1540450"
  },
  {
    "text": "questions answered by AWS experts and",
    "start": "1540450",
    "end": "1542730"
  },
  {
    "text": "for more info about ml visit the link on",
    "start": "1542730",
    "end": "1545789"
  },
  {
    "text": "the screen",
    "start": "1545789",
    "end": "1548000"
  },
  {
    "text": "to gain more confidence in hands-on",
    "start": "1548460",
    "end": "1550350"
  },
  {
    "text": "experience with AWS access the digital",
    "start": "1550350",
    "end": "1552809"
  },
  {
    "text": "training bill by AWS experts attend our",
    "start": "1552809",
    "end": "1556799"
  },
  {
    "text": "instructor-led classes by qualified a",
    "start": "1556799",
    "end": "1558960"
  },
  {
    "text": "diverse instructors and learn how to",
    "start": "1558960",
    "end": "1560700"
  },
  {
    "text": "design deploy and operate highly",
    "start": "1560700",
    "end": "1563700"
  },
  {
    "text": "available cost-effective and secure",
    "start": "1563700",
    "end": "1565679"
  },
  {
    "text": "applications on AWS validate your",
    "start": "1565679",
    "end": "1569190"
  },
  {
    "text": "technical expertise with AWS and use",
    "start": "1569190",
    "end": "1571740"
  },
  {
    "text": "practice exams to help you prepare for a",
    "start": "1571740",
    "end": "1573960"
  },
  {
    "text": "diverse certification",
    "start": "1573960",
    "end": "1576740"
  },
  {
    "text": "thank you again for attending and we",
    "start": "1576740",
    "end": "1579049"
  },
  {
    "text": "really appreciate your feedback if you",
    "start": "1579049",
    "end": "1580669"
  },
  {
    "text": "have time to fill out the survey my name",
    "start": "1580669",
    "end": "1583429"
  },
  {
    "text": "again is Jones B and it has been a",
    "start": "1583429",
    "end": "1585260"
  },
  {
    "text": "pleasure getting to share some of my",
    "start": "1585260",
    "end": "1586730"
  },
  {
    "text": "excitement in both reinforcement",
    "start": "1586730",
    "end": "1588440"
  },
  {
    "text": "learning and deep brace it with you see",
    "start": "1588440",
    "end": "1590720"
  },
  {
    "text": "you on the racetrack",
    "start": "1590720",
    "end": "1593200"
  }
]
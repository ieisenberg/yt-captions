[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "Hello everyone, I'm Seema. \nToday we have Vibin with us from HP.",
    "start": "6476",
    "end": "11271"
  },
  {
    "text": "Hi Vibin. \n- Hello, nice to be here.",
    "start": "11271",
    "end": "13415"
  },
  {
    "text": "Okay, so can you tell us a little more \nabout HP and your use case?",
    "start": "13415",
    "end": "17065"
  },
  {
    "text": "Sure, so HP is one of the world's largest \nconsumer device manufacturing companies",
    "start": "17065",
    "end": "21797"
  },
  {
    "text": "from PC's, laptops, printers.",
    "start": "21797",
    "end": "24132"
  },
  {
    "text": "And this use case is about \nink cartridge manufacturing",
    "start": "24132",
    "end": "27963"
  },
  {
    "text": "and about getting data from the factory \ninto this real-time pipeline system, right.",
    "start": "27963",
    "end": "33941"
  },
  {
    "text": "So from manufacturing data \ninto a real-time pipeline system",
    "start": "33941",
    "end": "37317"
  },
  {
    "text": "where users can make use of it.",
    "start": "37317",
    "end": "39218"
  },
  {
    "text": "Okay, so I see a lot of interesting \nservices out there, okay.",
    "start": "39218",
    "end": "42541"
  },
  {
    "text": "Yeah, so this like I show here \nis the entry point into this whole system,",
    "start": "42541",
    "end": "47029"
  },
  {
    "text": "behind this are manufacturing machines. ",
    "start": "47029",
    "end": "50111"
  },
  {
    "text": "It generates a lot of data \nduring the manufacturing process. ",
    "start": "50111",
    "end": "53232"
  },
  {
    "text": "It comes into Kinesis... real-time streams \ncome into Kinesis Data Streams.",
    "start": "53232",
    "end": "58428"
  },
  {
    "text": "From here, we send it to a processing unit, \nwhich is a Lambda DynamoDB combination.",
    "start": "58429",
    "end": "63555"
  },
  {
    "text": "Okay. ",
    "start": "63555",
    "end": "64306"
  },
  {
    "text": "We also have data from Kinesis Data Streams \nthat is being saved into S3, right.",
    "start": "64306",
    "end": "70123"
  },
  {
    "text": "For further processing later.",
    "start": "70123",
    "end": "72355"
  },
  {
    "text": "Now, this real-time processing unit is \nas you can see,",
    "start": "72355",
    "end": "76705"
  },
  {
    "text": "it goes through multiple stages.",
    "start": "76705",
    "end": "78061"
  },
  {
    "text": "So I've just shown one unit here, \nbut basically what it does is ",
    "start": "78061",
    "end": "82203"
  },
  {
    "text": "this business logic return Lambda \nthat saves data into DynamoDB,",
    "start": "82204",
    "end": "86539"
  },
  {
    "text": "is then triggers the next Lambda. ",
    "start": "86539",
    "end": "88360"
  },
  {
    "text": "So these are daisy change so that \nit forms multiple stages. ",
    "start": "88360",
    "end": "91400"
  },
  {
    "text": "Now, what do these stages do? \nThe first stage basically parses the data.",
    "start": "91400",
    "end": "94824"
  },
  {
    "text": "The second enriches it with \nreference data,",
    "start": "94824",
    "end": "97508"
  },
  {
    "text": "and the third normalizes it \nso that, you know,",
    "start": "97509",
    "end": "100333"
  },
  {
    "text": "data across multiple lines they all \nspeak the same data model language.",
    "start": "100333",
    "end": "104185"
  },
  {
    "text": "So that's basically what it is, \nit's a chain of these units.",
    "start": "104185",
    "end": "107959"
  },
  {
    "text": "And how do you get to the second stage \nfrom the first one, like follow up?",
    "start": "107959",
    "end": "111599"
  },
  {
    "start": "108000",
    "end": "130000"
  },
  {
    "text": "Is there a trigger? ",
    "start": "111599",
    "end": "112743"
  },
  {
    "text": "Yes, so when Lambda saves it to DynamoDB \nit basically triggers it,",
    "start": "112744",
    "end": "116649"
  },
  {
    "text": "which is DynamoDB Streams.",
    "start": "116649",
    "end": "118705"
  },
  {
    "text": "So Streams then call \nthe next Lambda in the chain",
    "start": "118705",
    "end": "121641"
  },
  {
    "text": "and that does the second... \nenriching of data for example",
    "start": "121641",
    "end": "126022"
  },
  {
    "text": "among other things.",
    "start": "126023",
    "end": "127021"
  },
  {
    "text": "Saves it to DynamoDB, which calls \nthe third and so on.",
    "start": "127021",
    "end": "129597"
  },
  {
    "text": "Okay, so these three blocks are part of \nyour data pipeline. ",
    "start": "129597",
    "end": "132106"
  },
  {
    "start": "130000",
    "end": "167000"
  },
  {
    "text": "I see an additional Lambda there, \nwhat is that for?",
    "start": "132106",
    "end": "134530"
  },
  {
    "text": "These are auxiliary Lambdas.",
    "start": "134530",
    "end": "136225"
  },
  {
    "text": "So these alone process the data \nand send it to the next stage,",
    "start": "136225",
    "end": "139363"
  },
  {
    "text": "but we need other Lambdas, \nso it's a bunch of (n) Lambdas basically that",
    "start": "139363",
    "end": "144588"
  },
  {
    "text": "take data from the \nDynamoDB Streams",
    "start": "144588",
    "end": "148765"
  },
  {
    "text": "and then passes it to Aurora \nas a data store",
    "start": "148765",
    "end": "152790"
  },
  {
    "text": "for some other use cases, it passes it to \nElasticsearch as well,",
    "start": "152790",
    "end": "156958"
  },
  {
    "text": "and we also do send it to S3.",
    "start": "156958",
    "end": "159633"
  },
  {
    "text": "So there are multiple Lambdas \nthat accomplish this. ",
    "start": "159633",
    "end": "162056"
  },
  {
    "text": "And these three are the primary \nconsumption areas for our business users.",
    "start": "162056",
    "end": "166967"
  },
  {
    "text": "Okay, so you again have that Lambda \nbeing triggered from your DynamoDB Streams,",
    "start": "166967",
    "end": "171483"
  },
  {
    "start": "167000",
    "end": "221000"
  },
  {
    "text": "and then your data being sent to \nAurora and Elasticsearch.",
    "start": "171483",
    "end": "175425"
  },
  {
    "text": "Any particular reason of using Aurora here \nand Elasticsearch?",
    "start": "175425",
    "end": "179521"
  },
  {
    "text": "So well, this lends itself easy to be \ntriggered from Lambda,",
    "start": "179521",
    "end": "184083"
  },
  {
    "text": "because Aurora Serverless, \nwe're using the Serverless portion",
    "start": "184083",
    "end": "187306"
  },
  {
    "text": "and the Serverless has data APIs \nwhich Lambda can call.",
    "start": "187307",
    "end": "190682"
  },
  {
    "text": "And so that's a big benefit, \nwe don't need to worry about ",
    "start": "190682",
    "end": "193962"
  },
  {
    "text": "connection pulling and all for our system \nthat scales up very quickly.",
    "start": "193962",
    "end": "197586"
  },
  {
    "text": "So Aurora Serverless was a perfect fit.",
    "start": "197586",
    "end": "199418"
  },
  {
    "text": "And this is also for our users who are \nmore comfortable with SQL,",
    "start": "199419",
    "end": "202935"
  },
  {
    "text": "they might not be able to process data in S3 \nlike data scientists do. ",
    "start": "202935",
    "end": "207991"
  },
  {
    "text": "So this is of use \nfor those kind of users. ",
    "start": "207991",
    "end": "210332"
  },
  {
    "text": "Elasticsearch is more for \nreal-time dashboards",
    "start": "210332",
    "end": "212529"
  },
  {
    "text": "because if I need to know where my part is \nin the whole manufacturing lifecycle,",
    "start": "212529",
    "end": "217624"
  },
  {
    "text": "this provides a good dashboard for users \nfor those kinds of things.",
    "start": "217624",
    "end": "220980"
  },
  {
    "text": "Okay, I also see some Glue jobs \nand Athena there, what are those for?",
    "start": "220980",
    "end": "225243"
  },
  {
    "start": "221000",
    "end": "257000"
  },
  {
    "text": "Yes, so Glue jobs are... so we do store \ndata in bulk in S3. ",
    "start": "225244",
    "end": "229178"
  },
  {
    "text": "This is for later bulk processing by \nour data scientists and AML jobs.",
    "start": "229178",
    "end": "233948"
  },
  {
    "text": "Glue, what Glue does is it, \nit's a schedule Glue job that ",
    "start": "233949",
    "end": "237953"
  },
  {
    "text": "bulk processes data in S3,",
    "start": "237953",
    "end": "239941"
  },
  {
    "text": "so we have it on a six hourly \nto a daily basis.",
    "start": "239941",
    "end": "242819"
  },
  {
    "text": "So this processes data, saves it in S3 \nand this is being used by users...  ",
    "start": "242820",
    "end": "249206"
  },
  {
    "text": "so there's an Athena layer \non top of S3.",
    "start": "249206",
    "end": "251506"
  },
  {
    "text": "It's again SQL or what S3 data for users \nwho actually do access the data in S3.",
    "start": "251506",
    "end": "256798"
  },
  {
    "text": "Okay, so they can write \nthe doc queries",
    "start": "256798",
    "end": "258599"
  },
  {
    "start": "257000",
    "end": "299000"
  },
  {
    "text": "and get some data sets? \n- That's right.",
    "start": "258599",
    "end": "260690"
  },
  {
    "text": "Okay, that's interesting.",
    "start": "260690",
    "end": "262394"
  },
  {
    "text": "And was this your original choice \nor you explored any other options?",
    "start": "262394",
    "end": "265636"
  },
  {
    "text": "Well, no. \nOur original choice was... ",
    "start": "265636",
    "end": "268886"
  },
  {
    "text": "It was a real-time platform, \nbut we were using Kafka and Apache Storm.",
    "start": "268886",
    "end": "273948"
  },
  {
    "text": "Kafka was the ingestion \nportion of things",
    "start": "273948",
    "end": "277197"
  },
  {
    "text": "and Apache Storm was the real-time \nevents engine.",
    "start": "277197",
    "end": "279607"
  },
  {
    "text": "But we found after sometime of operation that \nwe had spent a lot of resources in just ",
    "start": "279607",
    "end": "288139"
  },
  {
    "text": "maintaining the environment. ",
    "start": "288140",
    "end": "290035"
  },
  {
    "text": "It was not managed, \nwe were doing the management.",
    "start": "290035",
    "end": "292192"
  },
  {
    "text": "So there were a lot of \nadministration issues.",
    "start": "292192",
    "end": "293780"
  },
  {
    "text": "Correct, and this being \na manage environment, ",
    "start": "293781",
    "end": "296233"
  },
  {
    "text": "it was easier for us to focus on \nthe business logic then.",
    "start": "296233",
    "end": "298634"
  },
  {
    "text": "Okay, any key learnings that \nyou can share with us?",
    "start": "298634",
    "end": "301319"
  },
  {
    "start": "299000",
    "end": "384000"
  },
  {
    "text": "Yes, for example, DynamoDB, \nwe sometimes might go crazy in",
    "start": "301319",
    "end": "307211"
  },
  {
    "text": "streaming a lot of Lambdas to DynamoDB's",
    "start": "307211",
    "end": "310654"
  },
  {
    "text": "but that's not a good option, \nyou had to limit it to two or three  ",
    "start": "310654",
    "end": "315025"
  },
  {
    "text": "otherwise you might end up throttling \nDynamoDB reeds. ",
    "start": "315025",
    "end": "318290"
  },
  {
    "text": "Okay. ",
    "start": "318290",
    "end": "319057"
  },
  {
    "text": "So best practice is limit it to \ntwo or three. ",
    "start": "319057",
    "end": "322350"
  },
  {
    "text": "Now, in terms of managing Lambdas also, \nat the time of our development",
    "start": "322350",
    "end": "327325"
  },
  {
    "text": "Lambda came  up with a new feature called \nconcurrent batches per shard.",
    "start": "327325",
    "end": "331820"
  },
  {
    "text": "What that enables us to do is for each shard \nwe could invoke multiple Lambdas,",
    "start": "331820",
    "end": "336776"
  },
  {
    "text": "thereby increasing the pararelism factor.",
    "start": "336776",
    "end": "338518"
  },
  {
    "text": "For a system like this, what we need \nis more pararelism, more throughput.",
    "start": "338518",
    "end": "341349"
  },
  {
    "text": "And so we got almost a 10 times \nincrease in pararelism",
    "start": "341349",
    "end": "345150"
  },
  {
    "text": "when we enable that feature.",
    "start": "345150",
    "end": "346544"
  },
  {
    "text": "As well as, you need to also tune \nyour batch sizes",
    "start": "346544",
    "end": "350093"
  },
  {
    "text": "and now going with the default always \nisn't the best option.",
    "start": "350093",
    "end": "353240"
  },
  {
    "text": "So tune your batch sizes according to \nyour business use cases ",
    "start": "353240",
    "end": "357218"
  },
  {
    "text": "and you might see that \nyour throughput is increased.",
    "start": "357218",
    "end": "359689"
  },
  {
    "text": "Okay, so I think pipeline, \nand then modularization of Lambdas ",
    "start": "359690",
    "end": "364752"
  },
  {
    "text": "that's some of the key things \nthat you explored.",
    "start": "364752",
    "end": "367391"
  },
  {
    "text": "Yes, I think very interesting, \nI really enjoyed listening to it",
    "start": "367391",
    "end": "371620"
  },
  {
    "text": "and I hope our audience as well. ",
    "start": "371620",
    "end": "373604"
  },
  {
    "text": "Thank you, thank you for watching \n'This is My Architecture.'",
    "start": "373604",
    "end": "376877"
  }
]
[
  {
    "text": "Welcome to\n'This is My Architecture' New Zealand.",
    "start": "7350",
    "end": "10062"
  },
  {
    "text": "I'm Ondrej and I'm here with Chris from Leaven.",
    "start": "10062",
    "end": "12462"
  },
  {
    "text": "Hey, Ondrej. Can you tell me about Leaven\nand about automated road inspection?",
    "start": "12462",
    "end": "17382"
  },
  {
    "text": "Yeah. Leaven is a cloud consultancy business,",
    "start": "17382",
    "end": "19300"
  },
  {
    "text": "and we migrate our customers into the cloud.",
    "start": "19300",
    "end": "21688"
  },
  {
    "text": "And we also come up with new ways of working",
    "start": "21688",
    "end": "24724"
  },
  {
    "text": "that helps them facilitate that move to\nthe cloud as well.",
    "start": "24724",
    "end": "27640"
  },
  {
    "text": "And the architecture that I'm going to talk\nto you about today",
    "start": "27640",
    "end": "30099"
  },
  {
    "text": "allows one of our customers\nto run machine learning inference on",
    "start": "30100",
    "end": "34348"
  },
  {
    "text": "tens of thousands of video frames.",
    "start": "34348",
    "end": "38870"
  },
  {
    "text": "That's a lot of video frames.\nAnd you run it in parallel.",
    "start": "39430",
    "end": "42114"
  },
  {
    "text": "In parallel, yeah.",
    "start": "42114",
    "end": "43528"
  },
  {
    "text": "Why do you do that?\nWhat does it bring to the customer?",
    "start": "43528",
    "end": "45340"
  },
  {
    "text": "Well, the problem that we're trying to solve is",
    "start": "45340",
    "end": "47860"
  },
  {
    "text": "our customer was doing manual road inspections.",
    "start": "48370",
    "end": "50621"
  },
  {
    "text": "So they were driving down the road,\nlooking out the window, seeing a pothole,",
    "start": "50622",
    "end": "54378"
  },
  {
    "text": "stopping and having to take a photo\nand save some metadata.",
    "start": "54378",
    "end": "58250"
  },
  {
    "text": "And it was taking them a really long time,\nand it was actually really dangerous",
    "start": "59290",
    "end": "62634"
  },
  {
    "text": "because they had to stop often on the open road.",
    "start": "62634",
    "end": "65740"
  },
  {
    "text": "And what we did,\nwe measured how dangerous it was for them.",
    "start": "66370",
    "end": "70600"
  },
  {
    "text": "So there was a 22% chance of a near miss.",
    "start": "70600",
    "end": "74091"
  },
  {
    "text": "So that's almost having\nan accident doing it manually.",
    "start": "74092",
    "end": "77574"
  },
  {
    "text": "And it was taking them\naround about 60 days or 66 days.",
    "start": "77574",
    "end": "81700"
  },
  {
    "text": "And we've fully automated this process\nusing machine learning.",
    "start": "82510",
    "end": "85660"
  },
  {
    "text": "And we've got that 22% down to 7%.",
    "start": "85660",
    "end": "88660"
  },
  {
    "text": "And we've also reduced the time it takes them\nfrom 66 days down to seven days.",
    "start": "89830",
    "end": "95116"
  },
  {
    "text": "Well, it's great to see that\nyou have been able to reduce the time.",
    "start": "95116",
    "end": "98680"
  },
  {
    "text": "It's absolutely amazing to see\nthat you have been able to protect people.",
    "start": "98680",
    "end": "102580"
  },
  {
    "text": "How do you do that? How does it work?",
    "start": "102580",
    "end": "104476"
  },
  {
    "text": "Yeah. We mount an HD camera\nto the front of the inspection trucks,",
    "start": "104476",
    "end": "108666"
  },
  {
    "text": "and the engineers\nwill drive their stretch of road",
    "start": "108666",
    "end": "111256"
  },
  {
    "text": "and then upload their video to\na WebUI that we've created and deployed on AWS.",
    "start": "111256",
    "end": "116238"
  },
  {
    "text": "Then the video is saved\ninto an S3 bucket as their raw data.",
    "start": "116238",
    "end": "119464"
  },
  {
    "text": "And then we split out the video into frames.",
    "start": "119464",
    "end": "123102"
  },
  {
    "text": "And so there's around about 65,000 frames\nper video that we upload.",
    "start": "123102",
    "end": "128810"
  },
  {
    "text": "That's a lot of frames.\nHow do you achieve the splitting?",
    "start": "129250",
    "end": "132486"
  },
  {
    "text": "Yes, we actually tried\nto roll our own frame splitting application,",
    "start": "132486",
    "end": "136372"
  },
  {
    "text": "and we found that it was quite slow compared to",
    "start": "136372",
    "end": "139900"
  },
  {
    "text": "how fast we wanted to get the response back\nto our engineers.",
    "start": "140290",
    "end": "144101"
  },
  {
    "text": "And we also found that\nwhen we checked multiple videos at it,",
    "start": "144102",
    "end": "146692"
  },
  {
    "text": "it was a bit challenging\nto have a scalable architecture.",
    "start": "146692",
    "end": "150114"
  },
  {
    "text": "So it turns out that AWS actually\nhas a service that does this for you,",
    "start": "150114",
    "end": "154120"
  },
  {
    "text": "AWS Elemental MediaConvert.",
    "start": "154870",
    "end": "157386"
  },
  {
    "text": "So we just check videos at MediaConvert,\nand this thing will split it into frames for us.",
    "start": "157386",
    "end": "162640"
  },
  {
    "text": "I just love to see that there is a service\nthat's exactly what you need.",
    "start": "163030",
    "end": "167152"
  },
  {
    "text": "Once you have these frames,\nwhat happens after that?",
    "start": "167152",
    "end": "170739"
  },
  {
    "text": "Yes, we've trained a model with SageMaker",
    "start": "170740",
    "end": "173394"
  },
  {
    "text": "and we package that model in a Lambda function.",
    "start": "173394",
    "end": "175323"
  },
  {
    "text": "So for every single one\nof the frames that get spat out of MediaConvert,",
    "start": "175324",
    "end": "179826"
  },
  {
    "text": "we execute a Lambda and we perform\nmachine learning inference",
    "start": "179826",
    "end": "183297"
  },
  {
    "text": "on each of those frames.",
    "start": "183298",
    "end": "184970"
  },
  {
    "text": "That's a lot of Lambdas running in parallel.",
    "start": "185830",
    "end": "187734"
  },
  {
    "text": "And one thing I know about\nthe machine learning libraries is",
    "start": "187734",
    "end": "190256"
  },
  {
    "text": "that they can be quite large.",
    "start": "190258",
    "end": "191416"
  },
  {
    "text": "Did you manage to fit everything\ninto the Lambda?",
    "start": "191416",
    "end": "194262"
  },
  {
    "text": "Yeah. So that was a challenge.",
    "start": "194262",
    "end": "195846"
  },
  {
    "text": "That was actually a real challenge.",
    "start": "195846",
    "end": "197081"
  },
  {
    "text": "So you get 250 megabytes of expanded space\nin your Lambda functions,",
    "start": "197082",
    "end": "203250"
  },
  {
    "text": "but you can actually cheat.",
    "start": "203250",
    "end": "204366"
  },
  {
    "text": "There's a temp directory\nwhich you can use, which we use.",
    "start": "204366",
    "end": "206931"
  },
  {
    "text": "We used every single megabyte that we could.",
    "start": "206932",
    "end": "209176"
  },
  {
    "text": "Unfortunately, the SageMaker model",
    "start": "209176",
    "end": "212068"
  },
  {
    "text": "that we exported and packaged in our Lambda",
    "start": "212068",
    "end": "214986"
  },
  {
    "text": "uses TensorFlow, and TensorFlow",
    "start": "214986",
    "end": "216545"
  },
  {
    "text": "the latest versions of that, over a gigabyte.",
    "start": "216546",
    "end": "219042"
  },
  {
    "text": "So we tried a whole bunch of different things.",
    "start": "219042",
    "end": "222856"
  },
  {
    "text": "But as we were trying all of these things\nand failing, AWS released a new feature",
    "start": "222856",
    "end": "227958"
  },
  {
    "text": "that enabled us to package our model,",
    "start": "227958",
    "end": "230439"
  },
  {
    "text": "package our Python libraries\nand package everything else",
    "start": "230440",
    "end": "232924"
  },
  {
    "text": "that we needed inside the Lambda function in\na docker container",
    "start": "232924",
    "end": "236510"
  },
  {
    "text": "with a ten gigabyte limit\ninstead of a 250 megabyte limit.",
    "start": "237190",
    "end": "241866"
  },
  {
    "text": "Amazing example\nthat AWS have been listening to the customers",
    "start": "241866",
    "end": "244756"
  },
  {
    "text": "and really come up\nwith a feature that you need it.",
    "start": "244756",
    "end": "246879"
  },
  {
    "text": "Okay, so now we have the tens of thousands\nof Lambda running in parallel.",
    "start": "247930",
    "end": "251569"
  },
  {
    "text": "How does it then keep up downstream?",
    "start": "252190",
    "end": "255530"
  },
  {
    "text": "Yes, that was a challenge as well.",
    "start": "256090",
    "end": "258310"
  },
  {
    "text": "When you consider if you're running 65,000\nconcurrent Lambdas for a single video,",
    "start": "258310",
    "end": "264448"
  },
  {
    "text": "you put you how much it is when you\ncheck five or ten or more videos at it.",
    "start": "264448",
    "end": "269056"
  },
  {
    "text": "We needed something\nthat would scale from totally idle",
    "start": "269056",
    "end": "272330"
  },
  {
    "text": "all the way up to a number\nthat we probably couldn't even imagine.",
    "start": "272710",
    "end": "276005"
  },
  {
    "text": "So the standard relational database services\nprobably would struggle with that type of scale.",
    "start": "276006",
    "end": "281694"
  },
  {
    "text": "So we picked DynamoDB,",
    "start": "281694",
    "end": "283190"
  },
  {
    "text": "and every single one of these Lambda reads\nand writes metadata to the DynamoDB table.",
    "start": "283870",
    "end": "289550"
  },
  {
    "text": "So now we have it stored in DynamoDB as well.",
    "start": "289990",
    "end": "293356"
  },
  {
    "text": "How do you make sure\nthat you have the accurate data on that model",
    "start": "293356",
    "end": "297099"
  },
  {
    "text": "and then you deduplicate anything that comes up?",
    "start": "297100",
    "end": "300220"
  },
  {
    "text": "Yeah. So that was a really challenging problem,",
    "start": "300610",
    "end": "304336"
  },
  {
    "text": "was how do we not return\ntoo many defects to our UI?",
    "start": "304336",
    "end": "307926"
  },
  {
    "text": "If you picture a pothole\ncoming towards you on a road,",
    "start": "307926",
    "end": "310912"
  },
  {
    "text": "it's going to be on a whole heap\nof different frames of the video.",
    "start": "310912",
    "end": "314296"
  },
  {
    "text": "So we've got some really clever maths",
    "start": "314296",
    "end": "316001"
  },
  {
    "text": "and really clever logic\nin here that will effectively",
    "start": "316002",
    "end": "320353"
  },
  {
    "text": "look at previous frames\nand frames in the future,",
    "start": "320354",
    "end": "324736"
  },
  {
    "text": "or frames after the existing frame\nto then merge that defect into one,",
    "start": "324736",
    "end": "328888"
  },
  {
    "text": "to return it to the UI as a single defect.",
    "start": "328888",
    "end": "331790"
  },
  {
    "text": "So what we did to train our model is\nwe annotated 400,000 images with road defects.",
    "start": "333250",
    "end": "342709"
  },
  {
    "text": "And as you know, that's one of the\nhardest parts of machine learning projects",
    "start": "342709",
    "end": "346734"
  },
  {
    "text": "is to get enough data to make your model\ncompete with what a human can do.",
    "start": "346734",
    "end": "351460"
  },
  {
    "text": "So after we got the 400,000 images annotated\nand our model trained,",
    "start": "352210",
    "end": "357642"
  },
  {
    "text": "what we also do is any defects\nthat come back to the UI,",
    "start": "357642",
    "end": "362150"
  },
  {
    "text": "we actually ask the engineers\nto validate or reject them",
    "start": "362770",
    "end": "366363"
  },
  {
    "text": "and any that they reject, they actually get\nfeedback into our automated training pipeline.",
    "start": "366364",
    "end": "371550"
  },
  {
    "text": "So we've got a really nice\npositive feedback loop.",
    "start": "371550",
    "end": "374741"
  },
  {
    "text": "So every video that we process\nin this architecture",
    "start": "374742",
    "end": "378294"
  },
  {
    "text": "actually helps to improve the model\nand speed it up too.",
    "start": "378294",
    "end": "381893"
  },
  {
    "text": "It's amazing.",
    "start": "381893",
    "end": "382924"
  },
  {
    "text": "Well, thank you for sharing how you can\ndo the machine learning on large scale.",
    "start": "382924",
    "end": "387930"
  },
  {
    "text": "And most importantly,\nthank you for making New Zealand roads safer.",
    "start": "387930",
    "end": "391386"
  },
  {
    "text": "You're very welcome and we couldn't have done it\nwithout AWS's fast iteration on features.",
    "start": "391386",
    "end": "396185"
  },
  {
    "text": "This was an absolute game changer for us\nso thank you.",
    "start": "396186",
    "end": "399537"
  },
  {
    "text": "Thank you for watching\n'This is My Architecture' New Zealand.",
    "start": "399537",
    "end": "402212"
  }
]
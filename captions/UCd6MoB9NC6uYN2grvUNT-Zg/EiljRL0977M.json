[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "Welcome to 'This is My Architecture'.",
    "start": "7724",
    "end": "9725"
  },
  {
    "text": "I am Hawn, and today I am joined by Sathish from BioPharma.",
    "start": "9725",
    "end": "13258"
  },
  {
    "text": "- Welcome.\n-Thank you, Hawn.",
    "start": "13258",
    "end": "15643"
  },
  {
    "text": "Before we get into your architecture, \ncan you tell me a little about BioPharma?",
    "start": "15643",
    "end": "19671"
  },
  {
    "text": "Yeah. \nOur company is in the biopharma industry.",
    "start": "19672",
    "end": "23509"
  },
  {
    "text": "We develop targeted, personalized treatments \nin the area of neuro disorders.",
    "start": "23509",
    "end": "28304"
  },
  {
    "text": "By neuro disorders I mean diseases like Alzheimer's, \nSchizophrenia, and Parkinson's.",
    "start": "28304",
    "end": "35348"
  },
  {
    "start": "35000",
    "end": "111000"
  },
  {
    "text": "So I see that you have a data lake. ",
    "start": "36090",
    "end": "37649"
  },
  {
    "text": "So once the data lake has been populated, \nhow do you orchestrate and curate it?",
    "start": "37649",
    "end": "41973"
  },
  {
    "text": "That's a great question. ",
    "start": "41973",
    "end": "44265"
  },
  {
    "text": "Once the data lake has all the data, \nwe need to get the data to the processing layer. ",
    "start": "44265",
    "end": "50832"
  },
  {
    "text": "The first thing what we do is for MRA data processing ",
    "start": "50832",
    "end": "54414"
  },
  {
    "text": "which we are discussing right now for this architecture, ",
    "start": "54414",
    "end": "56948"
  },
  {
    "text": "we have the AWS Batch service \nwhich access Orchestrator. ",
    "start": "56948",
    "end": "60995"
  },
  {
    "text": "So, when we run a job with AWS Batch, \nit creates many EC2 instances. ",
    "start": "60995",
    "end": "67728"
  },
  {
    "text": "In this case we are talking hundreds \nto a few thousand of EC2 instances. ",
    "start": "67728",
    "end": "72212"
  },
  {
    "text": "So the computing area is instantiated. ",
    "start": "72212",
    "end": "75297"
  },
  {
    "text": "The computing area requests are stored,\nfor which we are using FSx.",
    "start": "75297",
    "end": "78952"
  },
  {
    "text": "And FSx is the one which obtains the data \nfrom the data lake in this case. ",
    "start": "78953",
    "end": "83982"
  },
  {
    "text": "So this is enabled at the time of provisioning the FSx storage. ",
    "start": "85974",
    "end": "90348"
  },
  {
    "text": "At the time of provisioning we have the capability \nto sync with a particular input S3 for that. ",
    "start": "90348",
    "end": "94918"
  },
  {
    "text": "AWS Batch orchestrates this download and it reads the data.",
    "start": "94918",
    "end": "100375"
  },
  {
    "text": "Once it has entered FSx storage, \nit is mounted on an EC2 instance.",
    "start": "100375",
    "end": "106029"
  },
  {
    "text": "This is where the processing happens, \nand the curation also happens during the time of processing.",
    "start": "106029",
    "end": "110731"
  },
  {
    "start": "111000",
    "end": "160000"
  },
  {
    "text": "So as a batch process, it must be, a long process, \nthat you may have quite a bit of errors.",
    "start": "111850",
    "end": "117041"
  },
  {
    "text": "How do you manage that?",
    "start": "117041",
    "end": "119199"
  },
  {
    "text": "At the time of processing, \ndefinitely this is a multi-day job for most of it. ",
    "start": "119988",
    "end": "123103"
  },
  {
    "text": "Depending on the data sets\nit can take anywhere from 24 days to 7 days. ",
    "start": "123103",
    "end": "127617"
  },
  {
    "text": "At the time of processing, if errors happen, we identify it this way.",
    "start": "127617",
    "end": "132683"
  },
  {
    "text": "We actually have AWS Batch sending events into EventBridge. ",
    "start": "132684",
    "end": "138613"
  },
  {
    "text": "Even when notifying the change\nin status of AWS Batch.",
    "start": "138613",
    "end": "142827"
  },
  {
    "text": "These are the events that are communicated,\nthese events are being sent by Lambda",
    "start": "142827",
    "end": "149749"
  },
  {
    "text": "onto ElasticSearch where they get indexed.",
    "start": "149749",
    "end": "152700"
  },
  {
    "text": "That's how we get to know anything that's failing, \nwe immediately get to know the events through ElasticSearch. ",
    "start": "152700",
    "end": "159023"
  },
  {
    "text": "So, from the data science perspective, \nhow do they visualize and consume the data sets?",
    "start": "159023",
    "end": "164808"
  },
  {
    "start": "160000",
    "end": "231000"
  },
  {
    "text": "Our data scientists and our biologists,\nare the primary consumers of this pipeline.",
    "start": "166702",
    "end": "172295"
  },
  {
    "text": "So, how do they come to know?",
    "start": "172295",
    "end": "173966"
  },
  {
    "text": "We have all the logs being sent from AWS Batch in the ElasticSearch. ",
    "start": "173966",
    "end": "180772"
  },
  {
    "text": "That's when they can actually look into the logs \nto see, if there are more technical, they would like to know,",
    "start": "180772",
    "end": "184848"
  },
  {
    "text": "what subjects have been processed.",
    "start": "184848",
    "end": "187698"
  },
  {
    "text": "That information is communicated, again,\nfrom AWS Batch to Lambda,",
    "start": "187698",
    "end": "192019"
  },
  {
    "text": "and Lambda indexes. \nThat's one.",
    "start": "192019",
    "end": "194851"
  },
  {
    "text": "The second thing is\noutput that's produced during the processing.",
    "start": "194852",
    "end": "199265"
  },
  {
    "text": "The output that's produced \nis actually stored in FSx, ",
    "start": "199265",
    "end": "202899"
  },
  {
    "text": "which is again, synced into the data lake,",
    "start": "202899",
    "end": "205975"
  },
  {
    "text": "using an activity called a DRT \nor a data repository task, which is provided by AWS.",
    "start": "205975",
    "end": "211444"
  },
  {
    "text": "This automatically syncs terabytes of data \nthat's produced on FSx back into the data lake.",
    "start": "211444",
    "end": "217773"
  },
  {
    "text": "And this data is something that contains ",
    "start": "217773",
    "end": "221974"
  },
  {
    "text": "all of the required correlation matrices \nrequired for visualizing this data. ",
    "start": "221974",
    "end": "226523"
  },
  {
    "text": "So, our biologists can look into the data lake to see the data. ",
    "start": "226523",
    "end": "231474"
  },
  {
    "text": "Awesome. \nSo it sounds like you're able to not only ",
    "start": "231475",
    "end": "234736"
  },
  {
    "text": "ingest, curate, and orchestrate the data; \nyou're able to handle the errors and process it ",
    "start": "234736",
    "end": "241333"
  },
  {
    "text": "where that the data scientist can visualize the data ",
    "start": "241333",
    "end": "244775"
  },
  {
    "text": "and also see the status from the long-running batch \nso that they can see the petabytes of data that you have",
    "start": "244776",
    "end": "250856"
  },
  {
    "text": "for the MRI scans to help with that accelerated processing. ",
    "start": "250856",
    "end": "255421"
  },
  {
    "text": "Exactly. ",
    "start": "255421",
    "end": "258127"
  },
  {
    "text": "It all helps. ",
    "start": "258128",
    "end": "260130"
  },
  {
    "text": "All the things that we do is to help our biologists\nand data scientists take advantage of the pipeline.",
    "start": "260130",
    "end": "264801"
  },
  {
    "text": "So they are going to trigger the pipeline, \nand they can monitor the entire pipeline for instance,",
    "start": "264801",
    "end": "270535"
  },
  {
    "text": "and also look at the visualizations \nthat are enabled by ElasticSearch,",
    "start": "270535",
    "end": "275848"
  },
  {
    "text": "where the Kibana dashboards are being exposed to visualize.",
    "start": "275848",
    "end": "278754"
  },
  {
    "text": "And we also have the data being visualized\nin our data warehouse that's powered by the data lake.",
    "start": "278754",
    "end": "283430"
  },
  {
    "text": "So thank you so much for going over your architecture. ",
    "start": "284060",
    "end": "287496"
  },
  {
    "text": "That is amazing how you're able to help the data scientists",
    "start": "287496",
    "end": "291040"
  },
  {
    "text": "not only visualize the data,\nbut also help with that rapid, accelerated research, and development",
    "start": "291040",
    "end": "297075"
  },
  {
    "text": "for personalized neuro disease \nand also drug discovery as well.",
    "start": "297075",
    "end": "302663"
  },
  {
    "text": "- Thank you so much. \n- Thank you so much, Hawn.",
    "start": "302663",
    "end": "305176"
  },
  {
    "text": "And thank you for watching 'This is My Architecture'.",
    "start": "305176",
    "end": "308365"
  }
]
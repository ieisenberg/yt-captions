[
  {
    "start": "0",
    "end": "91000"
  },
  {
    "text": "my name is Siva raghupathy just a bit of introduction about myself I've been with AWS for about seven years and first",
    "start": "179",
    "end": "7350"
  },
  {
    "text": "three years I helped build a couple of services Amazon DynamoDB which is a no sequel database service we if you had",
    "start": "7350",
    "end": "12990"
  },
  {
    "text": "been at the keynote there was quite a few sessions and things about that dynamodb and then in the second service",
    "start": "12990",
    "end": "19199"
  },
  {
    "text": "i helped build was Amazon RDS which is a relational database service and for the last four years I've been working with",
    "start": "19199",
    "end": "24420"
  },
  {
    "text": "customers including amazon.com and helping them build big data solutions on AWS I lead our big data solutions",
    "start": "24420",
    "end": "30390"
  },
  {
    "text": "architecture team for Americas so I'm delighted to be here let's get started so I'm going to go through a little bit",
    "start": "30390",
    "end": "36719"
  },
  {
    "text": "faster because we lost about ten minutes so I'm going to speed up a little bit you know probably towards the course of",
    "start": "36719",
    "end": "42180"
  },
  {
    "text": "the presentation I will not have time to take questions here but I'm happy to stay back and take questions at the end",
    "start": "42180",
    "end": "48480"
  },
  {
    "text": "so in terms of the agenda I'll go through some of the big data challenges and our opportunities that are available",
    "start": "48480",
    "end": "55800"
  },
  {
    "text": "and then we'll I'll go through how to simplify big data processing I'm gonna break the brick data processing into a",
    "start": "55800",
    "end": "61440"
  },
  {
    "text": "pipeline comprising of multiple stages collect store process or analyze and consume and in each stage I'm going to",
    "start": "61440",
    "end": "68430"
  },
  {
    "text": "help you pick the right tool using in various criterias and then towards the end I will pull all of that together",
    "start": "68430",
    "end": "75090"
  },
  {
    "text": "into a reference architecture then I will actually implement the reference",
    "start": "75090",
    "end": "80159"
  },
  {
    "text": "architecture using some design patterns and so kindly fill out the evaluations",
    "start": "80159",
    "end": "85650"
  },
  {
    "text": "it's probably very helpful to refine the talk moving forward and let's get",
    "start": "85650",
    "end": "90689"
  },
  {
    "text": "started so the volume velocity and variety of big data is ever increasing",
    "start": "90689",
    "end": "96299"
  },
  {
    "start": "91000",
    "end": "91000"
  },
  {
    "text": "routinely customers are building systems that can handle tens or tens of",
    "start": "96299",
    "end": "102299"
  },
  {
    "text": "thousands of requests per second in the case of real-time bidding there are systems that are actually sending about a million requests per second being",
    "start": "102299",
    "end": "109049"
  },
  {
    "text": "stored out of dynamodb and you know in in large volumes of data are being",
    "start": "109049",
    "end": "115140"
  },
  {
    "text": "ingested in today AWS customers are building systems that can ingest about 150 200 terabytes of data a day and in",
    "start": "115140",
    "end": "123659"
  },
  {
    "text": "addition to files and transactional workloads events are pretty popular with",
    "start": "123659",
    "end": "130140"
  },
  {
    "text": "with the advent of IOT and sensors and devices billions of events are being pumped into",
    "start": "130140",
    "end": "135480"
  },
  {
    "text": "AWS for analysis for real-time analysis the one thing that I observed over the last five years is that even five years",
    "start": "135480",
    "end": "142379"
  },
  {
    "text": "ago these systems were hard to build but nowadays these systems are being built by potentially a couple of developers in",
    "start": "142379",
    "end": "148920"
  },
  {
    "text": "a few weeks how do customers build those massive systems so fast they're going to",
    "start": "148920",
    "end": "155190"
  },
  {
    "text": "use some of the architectures tried and tested architectures that I'll actually discuss the course of the discussion today and big data is evolving from",
    "start": "155190",
    "end": "163349"
  },
  {
    "start": "162000",
    "end": "162000"
  },
  {
    "text": "batch processing to real-time or stream processing to machine learning and what",
    "start": "163349",
    "end": "169110"
  },
  {
    "text": "that means this instead of sending if your utility company instead of sending a customer's a monthly or weekly bill",
    "start": "169110",
    "end": "174150"
  },
  {
    "text": "you want to allow them to you know set thresholds so you can actually send them a text message or aura or or a",
    "start": "174150",
    "end": "181079"
  },
  {
    "text": "notification that they are about to breach their you know their spending limits and more importantly in addition",
    "start": "181079",
    "end": "187410"
  },
  {
    "text": "to that it'll be nice to build a system that actually tells them that they're about to go beyond their spend and",
    "start": "187410",
    "end": "193230"
  },
  {
    "text": "potentially you know upgrade to a new plan or whatnot so you know this is just one scenario depending upon what use",
    "start": "193230",
    "end": "199290"
  },
  {
    "text": "cases you're dealing with you know think being very customer centric and reactive to customers is the biggest",
    "start": "199290",
    "end": "205200"
  },
  {
    "text": "differentiator now you know for example I was talking to CTO of an airline company and then this person tells me",
    "start": "205200",
    "end": "212160"
  },
  {
    "text": "you know all airlines use pretty much the same Jets you know they're made by Boeing or Airbus the biggest",
    "start": "212160",
    "end": "217380"
  },
  {
    "text": "differentiator for us is to be customer centric if I can read out you know if a customer is going to show up to the",
    "start": "217380",
    "end": "222389"
  },
  {
    "text": "airport late if they're gonna miss the flight if I can automatically reroute them and tell them by the way they're being rerouted they'll be much more",
    "start": "222389",
    "end": "228480"
  },
  {
    "text": "happy so in other in other words to build customer centric systems you're going to be at you're going to need to",
    "start": "228480",
    "end": "233790"
  },
  {
    "text": "process fast-moving data and also you want to you know build machine learning into your systems to to build you know",
    "start": "233790",
    "end": "241079"
  },
  {
    "text": "to predict what's going to happen as well so it's going to be so in the architecture that I'm going to paint today I'm gonna actually you know",
    "start": "241079",
    "end": "247859"
  },
  {
    "text": "building machine learning into the pipeline if you will so luckily there's a plethora of tools on the left side the",
    "start": "247859",
    "end": "254489"
  },
  {
    "start": "251000",
    "end": "251000"
  },
  {
    "text": "open source ecosystem is building you know tons of products or services if you",
    "start": "254489",
    "end": "259680"
  },
  {
    "text": "go to any big data conference spark is the answer no matter what the question is and so hopefully some of you",
    "start": "259680",
    "end": "267510"
  },
  {
    "text": "are saying are smiling so it should be true but apparently spork is challenged it's going to be challenged by this",
    "start": "267510",
    "end": "273240"
  },
  {
    "text": "little scoodle on the left bottom you know does anybody know what that squirrel is Apache flank so so I think",
    "start": "273240",
    "end": "281430"
  },
  {
    "text": "the one of the coin on the right side you know AWS we build a lot of services to innovate on behalf of customers",
    "start": "281430",
    "end": "287280"
  },
  {
    "text": "starting from Amazon Elastic MapReduce to s3 to dynamodb Kinesis etc then I",
    "start": "287280",
    "end": "292950"
  },
  {
    "text": "have only one space for one more icon left next year I'm not sure what I'm going to do maybe create two slides here",
    "start": "292950",
    "end": "298380"
  },
  {
    "text": "so so the as an architect the challenge here is that you know how do I replace a",
    "start": "298380",
    "end": "303780"
  },
  {
    "text": "specific module in my data processing pipeline as they get better technology so in other words you should be you",
    "start": "303780",
    "end": "309570"
  },
  {
    "text": "should be building modular systems to be able to replace components as you get better technology that's that's",
    "start": "309570",
    "end": "314910"
  },
  {
    "text": "something that you don't think after the fact you should think through ahead of time so so those are some of the",
    "start": "314910",
    "end": "319980"
  },
  {
    "text": "considerations for me as an architect on a daily basis these are the questions I get you know is there a reference architecture what tools should I use how",
    "start": "319980",
    "end": "327720"
  },
  {
    "text": "and more importantly why I think if you answer the question why the how and to",
    "start": "327720",
    "end": "332750"
  },
  {
    "text": "how et cetera it kind of typically falls into place so I'm going to spend a bunch of time on on why today you know as a",
    "start": "332750",
    "end": "339660"
  },
  {
    "text": "builder of services that's that's a unique perspective that I have I'm going to share with you today and so before I",
    "start": "339660",
    "end": "346350"
  },
  {
    "start": "345000",
    "end": "345000"
  },
  {
    "text": "get started I want introduce five architectural principles that have that have held the test of time for me if there's one takeaway in this",
    "start": "346350",
    "end": "352920"
  },
  {
    "text": "presentation I think this is this slide so and first of all when you're building big data systems you should build",
    "start": "352920",
    "end": "358950"
  },
  {
    "text": "decoupled systems you know what that means is you know on a physical sense I'm a mechanical engineer I think of",
    "start": "358950",
    "end": "364110"
  },
  {
    "text": "this as a gear or a clutch you know nicely decoupled systems allow with what the producers and the consumers to go at",
    "start": "364110",
    "end": "370740"
  },
  {
    "text": "their own speed and then coupling them in a fashion that that doesn't blow up the system in essence so in a big data",
    "start": "370740",
    "end": "376980"
  },
  {
    "text": "processing pipeline it looks like you know store processed or process repeats itself multiple times the storage",
    "start": "376980",
    "end": "382890"
  },
  {
    "text": "subsystem acts as a decoupling mechanism between multiple processing and analysis stages and using the right tool for the",
    "start": "382890",
    "end": "389430"
  },
  {
    "text": "job is critical when we build services at AWS we build them to do that function or a subset of functions extremely well",
    "start": "389430",
    "end": "397110"
  },
  {
    "text": "at a very low cost so oftentimes you know picking the right tool and match matching your application",
    "start": "397110",
    "end": "403650"
  },
  {
    "text": "characteristics to the characteristics of the service is going to be critical and using lambda architecture ideas this",
    "start": "403650",
    "end": "410490"
  },
  {
    "text": "is not the AWS lambda product it's very cool as Matt laid out this morning but this is lambda architecture where you",
    "start": "410490",
    "end": "416460"
  },
  {
    "text": "actually combine both batch and our real-time our speed processing through a serving layer and serve an answer both",
    "start": "416460",
    "end": "423450"
  },
  {
    "text": "from both batch systems and real-time systems and also the ability to collect amid immutable immutable logs you know",
    "start": "423450",
    "end": "430890"
  },
  {
    "text": "typically you know yes three is so cheap and so scalable there's no reason to actually remove anything that your",
    "start": "430890",
    "end": "436830"
  },
  {
    "text": "company receives any data your company disease I think it's the best practice to keep all the data as it comes in s3",
    "start": "436830",
    "end": "443900"
  },
  {
    "text": "compressed and probably in a mood big laser so you can actually go back and",
    "start": "443900",
    "end": "449640"
  },
  {
    "text": "analyze the data and and and and obtain some of the perishable insights and many many times you don't know what what",
    "start": "449640",
    "end": "455430"
  },
  {
    "text": "question you may be asking from your data and if you actually scrub the data and only store what you want you may be",
    "start": "455430",
    "end": "461400"
  },
  {
    "text": "losing a lot of valuable insights actually taking extreme of data as it arrives and keeping it securely in s3 is",
    "start": "461400",
    "end": "467970"
  },
  {
    "text": "going to be super important and leveraging a tablets managed services is key I told you you know large scale",
    "start": "467970",
    "end": "474270"
  },
  {
    "text": "systems are built by a couple of developers that a few developers in a few weeks using AWS managed services",
    "start": "474270",
    "end": "480000"
  },
  {
    "text": "increases the speed of innovation rather than a you actually you know AWS has compute and storage in all the building",
    "start": "480000",
    "end": "485580"
  },
  {
    "text": "blocks so you can actually install any software and build any system on it but if you have a package service automatically managed service available",
    "start": "485580",
    "end": "492390"
  },
  {
    "text": "for a specific function it's much more efficient and it increases your speed of",
    "start": "492390",
    "end": "497820"
  },
  {
    "text": "speed to delivery and speed to innovation if you will if you build a managed service typically these services are highly scalable they're elastic and",
    "start": "497820",
    "end": "505260"
  },
  {
    "text": "they are secure and there is no admin or very less admin you know which saves time and efficiency and improves",
    "start": "505260",
    "end": "513479"
  },
  {
    "text": "efficiency or the long run last but not the least big data should not be equals big cost you should be cost conscious when you",
    "start": "513480",
    "end": "519390"
  },
  {
    "text": "build a system so often what happens is when I do I do often do design reviews with customers is typically a one-hour call or a discussion twenty minutes into",
    "start": "519390",
    "end": "526560"
  },
  {
    "text": "the design I park then I say let's let's compute the cost of the system there's all usually one or two answers that",
    "start": "526560",
    "end": "531900"
  },
  {
    "text": "comes up you know rare cases the customer says let's stop I can't pay the bill it's too expensive maybe I should change",
    "start": "531900",
    "end": "537010"
  },
  {
    "text": "something maybe we should change the service or our or actually redefine the requirements so being cost conscious",
    "start": "537010",
    "end": "542500"
  },
  {
    "text": "often results in a better design so I think this is the sort of they're going to be the biggest takeaway the rest of",
    "start": "542500",
    "end": "547690"
  },
  {
    "text": "the presentation I'm going to be spending on actually you know expanding on this slide and now let's simplify a",
    "start": "547690",
    "end": "555190"
  },
  {
    "start": "554000",
    "end": "554000"
  },
  {
    "text": "big data processing the more and more I build big data systems it looks like a big pipe with the data coming in on one",
    "start": "555190",
    "end": "560529"
  },
  {
    "text": "side and answers coming out another side and there's typically multiple stages collect store process analyze I'm going",
    "start": "560529",
    "end": "567460"
  },
  {
    "text": "to use this change into the term interchangeably processor analyze and then consume and now what also happens",
    "start": "567460",
    "end": "573400"
  },
  {
    "text": "is typically the store and process repeats itself in multiple cycles so you shape the data in a form that's going to",
    "start": "573400",
    "end": "579640"
  },
  {
    "text": "be easily accessible by the downstream system and and what what goes in there and what technology that you use often",
    "start": "579640",
    "end": "586210"
  },
  {
    "text": "is dictated by what I call time to answer or latency of the pipe and the throughput of the pipe which comprises",
    "start": "586210",
    "end": "591640"
  },
  {
    "text": "of the request number of requests per second and the size of the payload and also cost so that's it",
    "start": "591640",
    "end": "598930"
  },
  {
    "text": "as simple as that so now let's look at the details a little more so in the collect stage typically you're dealing",
    "start": "598930",
    "end": "604810"
  },
  {
    "text": "with multiple data types you know you may be writing to a transaction in the in the case of real-time bidding typically you're looking up a user",
    "start": "604810",
    "end": "611230"
  },
  {
    "text": "profile potentially a million millions of requests per second or hundreds of thousands of requests per second and",
    "start": "611230",
    "end": "616660"
  },
  {
    "text": "actually servicing an ad platform yes you know I'm gonna I'm gonna bid for this or not bid for this right that's",
    "start": "616660",
    "end": "623020"
  },
  {
    "text": "typically a transactional kind of workload typically that that workload comprises of database records you know",
    "start": "623020",
    "end": "628390"
  },
  {
    "text": "moving really fast between applications and on the database or you may be",
    "start": "628390",
    "end": "634150"
  },
  {
    "text": "actually using log stash and sit and shipping documents into a data store",
    "start": "634150",
    "end": "639630"
  },
  {
    "text": "typically it's a search store or it may be files you know your application servers maybe packaging this as files",
    "start": "639630",
    "end": "646120"
  },
  {
    "text": "it could be log4j files or you may be using flume or you may be using Amazon",
    "start": "646120",
    "end": "651610"
  },
  {
    "text": "CloudWatch logs if you will for moving the data into s3 yeah or in the case of",
    "start": "651610",
    "end": "658060"
  },
  {
    "text": "messaging system this may be messages you know going to some form of a queue and last but not the least with advent",
    "start": "658060",
    "end": "663970"
  },
  {
    "text": "of IOT there's a lot of streaming data going in from sensors devices IOT platform these are the various types",
    "start": "663970",
    "end": "670389"
  },
  {
    "text": "of data that you have to deal with today not just database records but but but",
    "start": "670389",
    "end": "675490"
  },
  {
    "text": "all of these now let's look at the details of this tour for messaging",
    "start": "675490",
    "end": "680699"
  },
  {
    "text": "typically Amazon sqs is a managed service for for sorting your messages at",
    "start": "680699",
    "end": "686439"
  },
  {
    "text": "scale so you simply create an abstraction of a queue and then you send messages to the queue and you receive",
    "start": "686439",
    "end": "691779"
  },
  {
    "text": "messages from from the queue you don't have to pretty much provision any capacity or throughput we automatically provisioned throughput we store the",
    "start": "691779",
    "end": "698079"
  },
  {
    "text": "messages in multiple data centers typically three data centers and then we scale this based on the total number of",
    "start": "698079",
    "end": "703809"
  },
  {
    "text": "messages you send messages usually hang it on for about 14 days and then they get recycled after that and so it's",
    "start": "703809",
    "end": "711339"
  },
  {
    "text": "probably the best service to use for storing storing messages Apache Kafka is",
    "start": "711339",
    "end": "716889"
  },
  {
    "text": "very popular I was just talking to a customer just before the talk there potentially using Apache Kafka there's",
    "start": "716889",
    "end": "722230"
  },
  {
    "text": "some kind of a real-time bidding platform using Apache Kafka percent for storing messages and you can actually",
    "start": "722230",
    "end": "728800"
  },
  {
    "text": "you know build a particular cluster on top of AWS using the compute and storage",
    "start": "728800",
    "end": "733899"
  },
  {
    "text": "infrastructure in fact math announced the new EBS volumes are going to be very helpful for a cow for building Kafka",
    "start": "733899",
    "end": "740230"
  },
  {
    "text": "systems and Amazon Kinesis streams is a managed service for doing the same",
    "start": "740230",
    "end": "745870"
  },
  {
    "text": "function that Kafka does and there are three different platforms and recognizes",
    "start": "745870",
    "end": "751420"
  },
  {
    "text": "title first is Canisius streams which is used for stream storage and processing the second is Canisius firehose it is",
    "start": "751420",
    "end": "758410"
  },
  {
    "text": "very similar to I mean this is an enhancement we made because of customer request so typically what people are doing where they were writing to Kinesis",
    "start": "758410",
    "end": "764350"
  },
  {
    "text": "streams and the first application simply put the data in s3 so we figured we'll do this on behalf of",
    "start": "764350",
    "end": "770230"
  },
  {
    "text": "the customers we invented Kinesis firehose so when you when you when you write to Canisius firehose you can",
    "start": "770230",
    "end": "775779"
  },
  {
    "text": "choose the destination it could be a three or a redshift table or we introduced that we're going to be",
    "start": "775779",
    "end": "781660"
  },
  {
    "text": "introducing tomorrow you know automatically writing to elasticsearch so if if you're doing any",
    "start": "781660",
    "end": "787420"
  },
  {
    "text": "of these three you can potentially write to a fire host and automatically you know transport the data to the to the",
    "start": "787420",
    "end": "793059"
  },
  {
    "text": "one of the three destinations that you choose and finally about a year ago or so we introduced dynamodb update streams",
    "start": "793059",
    "end": "799720"
  },
  {
    "text": "now update streams I think of as you know change data capture for",
    "start": "799720",
    "end": "805250"
  },
  {
    "text": "tables so in other words if you're writing to a DynamoDB table if you enable an update stream what happens is",
    "start": "805250",
    "end": "810710"
  },
  {
    "text": "the change you can when you create a stream you can tell whether just send updated records both the old image and",
    "start": "810710",
    "end": "815870"
  },
  {
    "text": "the new image or just a new image and the keys that changed so the update stream has all this data that you can do",
    "start": "815870",
    "end": "820880"
  },
  {
    "text": "a variety of computations from the from the change data capture that you are capturing you know from a from a table",
    "start": "820880",
    "end": "828470"
  },
  {
    "text": "stream you know classic things maybe you may be updating a cache or you may be updating an elasticsearch store for the",
    "start": "828470",
    "end": "834530"
  },
  {
    "text": "metadata for the metadata that you're writing in DynamoDB you can you can build this off of the off of the data you're putting in DynamoDB so why stream",
    "start": "834530",
    "end": "843770"
  },
  {
    "start": "842000",
    "end": "842000"
  },
  {
    "text": "storage stream storage typically allows you to decouple producers and consumers",
    "start": "843770",
    "end": "850660"
  },
  {
    "text": "it provides a persistent buffer and it can also enables collecting multiple",
    "start": "850660",
    "end": "856940"
  },
  {
    "text": "streams if you have those producers one two three and four having the hard data",
    "start": "856940",
    "end": "861980"
  },
  {
    "text": "coming in rather than holding the data with them they can simply write to an endpoint and move forward and one of the",
    "start": "861980",
    "end": "868970"
  },
  {
    "text": "critical functions of a stream is to preserve client ordering that allows a whole bunch of functionality for example",
    "start": "868970",
    "end": "874790"
  },
  {
    "text": "let's assume you're building a clickstream analytic system you know your customer is actually think of you",
    "start": "874790",
    "end": "880670"
  },
  {
    "text": "know you imagine you being in amazon.com and you're clicking through various things and then you finally abandon you",
    "start": "880670",
    "end": "885860"
  },
  {
    "text": "want to look like you like a product and you finally abandon the car you didn't actually put that in the cart we can find out actually where a customer",
    "start": "885860",
    "end": "891950"
  },
  {
    "text": "abandoned the cart if let's say multiple people are banned on the cart probably there's something wrong with your website for example so such computations",
    "start": "891950",
    "end": "898610"
  },
  {
    "text": "can be run if you actually put the data in in a stream storage subsystem and so",
    "start": "898610",
    "end": "906320"
  },
  {
    "text": "the other piece is called streaming MapReduce which which essentially means you know five consumer that is consuming",
    "start": "906320",
    "end": "912680"
  },
  {
    "text": "from the stream the frameworks that come with you know kinases are Kafka essentially the KCl Kinesis client",
    "start": "912680",
    "end": "918620"
  },
  {
    "text": "library in an hour spark streaming etc allows you to lock on a specific thread",
    "start": "918620",
    "end": "924800"
  },
  {
    "text": "onto a short or a partition what happens is that thread you know is guaranteed to",
    "start": "924800",
    "end": "931280"
  },
  {
    "text": "get all the if let's say the producer is designating itself as or the second producer is designating",
    "start": "931280",
    "end": "937600"
  },
  {
    "text": "itself as green all the all the red will certainly go to a specific partition one and only that partition and then a",
    "start": "937600",
    "end": "944140"
  },
  {
    "text": "thread that's latched on to that partition is guaranteed to get the get the data in the same sequence so you can",
    "start": "944140",
    "end": "949420"
  },
  {
    "text": "do it computations like give me the men max average and etc and so that's that's",
    "start": "949420",
    "end": "955000"
  },
  {
    "text": "the essence that's essentially called streaming MapReduce and last but not the least these close streaming storage",
    "start": "955000",
    "end": "961990"
  },
  {
    "text": "system allows for parallel consumption which means if the data is coming into your company if there are two teams that",
    "start": "961990",
    "end": "967570"
  },
  {
    "text": "want to process the data in parallel and do whatever they want to do with the data they don't have to depend on one another right if you put this in a queue",
    "start": "967570",
    "end": "974140"
  },
  {
    "text": "you know maybe an upstream system needs to process it and hand this off to another downstream system whereas in this case multiple parallel consumers",
    "start": "974140",
    "end": "980800"
  },
  {
    "text": "can consume the data and all fields and CTOs and leads louder's because they can",
    "start": "980800",
    "end": "985990"
  },
  {
    "text": "enable innovation in parallel in other words they can be coupled to teams by simply sticking the data in Kinesis and",
    "start": "985990",
    "end": "991690"
  },
  {
    "text": "giving them you know access to access to the data downstream and this has been you know it's sort of not directly yeah",
    "start": "991690",
    "end": "998230"
  },
  {
    "text": "this is an innovation that that straining storage systems enables that's why they're more part they're getting more powerful than potentially putting",
    "start": "998230",
    "end": "1004830"
  },
  {
    "text": "this in queues now now what about queues and pops up you know both cues like sqs",
    "start": "1004830",
    "end": "1012210"
  },
  {
    "text": "for example allows you to decouple systems it allows your persistent buffer it also allows you to comfortable",
    "start": "1012210",
    "end": "1018030"
  },
  {
    "text": "collect multiple streams the data but where doesn't have is there's no client ordering guarantee there's no parallel",
    "start": "1018030",
    "end": "1023040"
  },
  {
    "text": "consumption possible and there's no streaming MapReduce as well now one exception to this is if you have if you",
    "start": "1023040",
    "end": "1028500"
  },
  {
    "text": "write into SNS you can actually you know route the messages into multiple queues",
    "start": "1028500",
    "end": "1034530"
  },
  {
    "text": "and enable parallel consumption that being the exception but this is sort of the essential difference between the two",
    "start": "1034530",
    "end": "1039540"
  },
  {
    "text": "what I've done here is I don't expect you to I don't expect to go through each every line here but I've actually given",
    "start": "1039540",
    "end": "1045390"
  },
  {
    "text": "this this is sort of a summary of all the analysis that I've done for various customers what I've done here is I've",
    "start": "1045390",
    "end": "1051179"
  },
  {
    "text": "taken various attributes that are that are necessary for stream processing and then our tablet it across all the you",
    "start": "1051179",
    "end": "1057720"
  },
  {
    "text": "know Kinesis dynamodb streams Kafka etc for example you know is this a managed",
    "start": "1057720",
    "end": "1063270"
  },
  {
    "text": "service yes or no you know is that guaranteed ordering yes or no for example in the case of rescuers there's no guaranteed or",
    "start": "1063270",
    "end": "1069000"
  },
  {
    "text": "you know is that delivery exactly once or at least once you know for example if you're building a mirroring system you",
    "start": "1069000",
    "end": "1075750"
  },
  {
    "text": "know under extreme circumstances both kinases and Kafka will give you the same record twice so if you want to build a",
    "start": "1075750",
    "end": "1081360"
  },
  {
    "text": "system you don't want to double bill your customer you need to you need to build D duping into your pipeline so so",
    "start": "1081360",
    "end": "1086490"
  },
  {
    "text": "that's exactly how you kind of find out for example dynamodb streams in a guarantee is exactly once processing for",
    "start": "1086490",
    "end": "1092220"
  },
  {
    "text": "the client so those I found these things very helpful for customers and then last but not the least the one thing I want",
    "start": "1092220",
    "end": "1098460"
  },
  {
    "text": "to touch on here is the cost oftentimes I find Kinesis streams to be the cheapest way of doing you know saving a",
    "start": "1098460",
    "end": "1107130"
  },
  {
    "text": "stream Kafka is also fairly cheap but the only the admin cost sometimes is higher you know maintaining the cluster",
    "start": "1107130",
    "end": "1112530"
  },
  {
    "text": "or a lifetime can be can be fairly time-consuming as well so I would start with probably the Kinesis or Kafka and",
    "start": "1112530",
    "end": "1118590"
  },
  {
    "text": "then use other solutions if need be that'd be my sort of the single recommendation there and so now let's go",
    "start": "1118590",
    "end": "1125700"
  },
  {
    "text": "into the file storage so if you have files that you are actually storing on Amazon the best place to put that would",
    "start": "1125700",
    "end": "1132570"
  },
  {
    "text": "be Amazon s3 why it's just very good for big data s3 is natively supported by",
    "start": "1132570",
    "end": "1139550"
  },
  {
    "start": "1135000",
    "end": "1135000"
  },
  {
    "text": "almost all big data frameworks you know SPARC hi presto etc and there's no need",
    "start": "1139550",
    "end": "1145350"
  },
  {
    "text": "to run compute when you are actually storing data in esterday if you're running HDFS cluster you have to have all these machines humming now for it",
    "start": "1145350",
    "end": "1152070"
  },
  {
    "text": "for storage to be available in HDFS but in this case of s3 you don't have to run any compute you can simply put your data",
    "start": "1152070",
    "end": "1157830"
  },
  {
    "text": "into s3 also this allows you to run multiple clusters so you can have you",
    "start": "1157830",
    "end": "1162840"
  },
  {
    "text": "know specific processing three different clusters or four different clusters processing the same data set for different purposes and you can also use",
    "start": "1162840",
    "end": "1169710"
  },
  {
    "text": "since you don't need to have persist machines actually for serving the data you can also have you know spot",
    "start": "1169710",
    "end": "1175620"
  },
  {
    "text": "instances which are very you know inexpensive typically compared to you know the the demand on them on pricing",
    "start": "1175620",
    "end": "1181950"
  },
  {
    "text": "you can use part instances to do the processing and and so SV also is very",
    "start": "1181950",
    "end": "1188820"
  },
  {
    "text": "scalable in fact there's no limits on the number of objects that you can put in s3 it has very high aggregate",
    "start": "1188820",
    "end": "1194610"
  },
  {
    "text": "bandwidth yeah there's no no no throughput limits if you will as long as you can scale out",
    "start": "1194610",
    "end": "1200070"
  },
  {
    "text": "the competition across multiple nodes and from four puts and gets and it's also highly",
    "start": "1200070",
    "end": "1205230"
  },
  {
    "text": "available a three data is stored in at least three data centers and it's designed for 11 lines durability and s",
    "start": "1205230",
    "end": "1212400"
  },
  {
    "text": "they also supports tiered storage which means you can actually set a policy in s3 the lifecycle policy let's say if you",
    "start": "1212400",
    "end": "1219419"
  },
  {
    "text": "want to expire or move all the objects from s3 standard storage to glaze here",
    "start": "1219419",
    "end": "1224549"
  },
  {
    "text": "standard storage is about three cents per gigabyte per month glaciares about you know one tenth of a penny per gigabyte per month you know you can set",
    "start": "1224549",
    "end": "1231030"
  },
  {
    "text": "a policy to move the data automatically you know from from standard to standard pick last year for example F 3 is also",
    "start": "1231030",
    "end": "1237960"
  },
  {
    "text": "secure it supports both encryption and flight through SSL and encryption at rest using using various key management",
    "start": "1237960",
    "end": "1244230"
  },
  {
    "text": "techniques and what about HDFS and glaze here now HDFS is quickly becoming sort",
    "start": "1244230",
    "end": "1249690"
  },
  {
    "start": "1245000",
    "end": "1245000"
  },
  {
    "text": "of a cache for big data processing if you have multiple stages in the big data processing pipeline typically the first stage gets the data from s3 you know",
    "start": "1249690",
    "end": "1256679"
  },
  {
    "text": "does some processing stores HDFS the second stage picks up from there and the end result is also stored and stored",
    "start": "1256679",
    "end": "1262470"
  },
  {
    "text": "stored and student back in s3 and you know we also introduced the s3 in",
    "start": "1262470",
    "end": "1269010"
  },
  {
    "text": "addition to s3 standard yesterday infrequent access you can also set a policy if you're infrequently accessing the data you can also set a policy to",
    "start": "1269010",
    "end": "1275850"
  },
  {
    "text": "move data too infrequently access that'll actually make your storage bill cheaper than putting it in standard and",
    "start": "1275850",
    "end": "1281250"
  },
  {
    "text": "we talked about the glacier scenario there so the way I see this is sort of a tiered storage mechanism with a very",
    "start": "1281250",
    "end": "1286500"
  },
  {
    "text": "very hot volatile data in HDFS and potentially you know s3 for being for",
    "start": "1286500",
    "end": "1292830"
  },
  {
    "text": "both standard and infrequent access and glaze here for archival storage so now",
    "start": "1292830",
    "end": "1298590"
  },
  {
    "text": "let's go into the cache and the database and search so this is the wrong way to",
    "start": "1298590",
    "end": "1304679"
  },
  {
    "start": "1304000",
    "end": "1304000"
  },
  {
    "text": "build your database tier at the data tier for big data about 20 years ago",
    "start": "1304679",
    "end": "1311370"
  },
  {
    "text": "this was a great way to build this but not anymore that if you're doing a million writes per second it's hard to",
    "start": "1311370",
    "end": "1316650"
  },
  {
    "text": "find a relational database that will do a million writes per second and if you're doing you know million writes per second and ten reads per second in",
    "start": "1316650",
    "end": "1322830"
  },
  {
    "text": "dynamo you can exactly ask for that if you if you're putting that in relational database you probably get million writes",
    "start": "1322830",
    "end": "1328470"
  },
  {
    "text": "per second and a lot more reads per second which you don't want so quickly thinking of your database tier as",
    "start": "1328470",
    "end": "1334799"
  },
  {
    "text": "comprising of either - combination of cash no sequel sequel and search is typically the right",
    "start": "1334799",
    "end": "1340620"
  },
  {
    "text": "solution and so the immediate question when I say that the customers is like",
    "start": "1340620",
    "end": "1346380"
  },
  {
    "start": "1343000",
    "end": "1343000"
  },
  {
    "text": "hey how do you keep all these things think so here is a pattern you know typically if you are gonna write your high-throughput data into DynamoDB you",
    "start": "1346380",
    "end": "1352980"
  },
  {
    "text": "can actually either have a KCl application on AWS lambda consume to the",
    "start": "1352980",
    "end": "1358200"
  },
  {
    "text": "update stream and then you can update an elastic cache cluster or an elastic search cluster so you know for search as",
    "start": "1358200",
    "end": "1364860"
  },
  {
    "text": "well as for caching so this is a design pattern that you know some customers are using and they find it very very",
    "start": "1364860",
    "end": "1370350"
  },
  {
    "text": "effective and what data store should I use again I tend to use four different techniques for picking this making a",
    "start": "1370350",
    "end": "1376920"
  },
  {
    "text": "decision you know depends on what data structure in the structure of the data your access pattern your data access",
    "start": "1376920",
    "end": "1382680"
  },
  {
    "text": "characteristics you know they're dealing with hot warm or cold data and and the cost so if you're if your data access",
    "start": "1382680",
    "end": "1390240"
  },
  {
    "start": "1388000",
    "end": "1388000"
  },
  {
    "text": "pattern is typically put sand gets using a cache and no sequel is usually the right solution if it's if you're dealing",
    "start": "1390240",
    "end": "1395820"
  },
  {
    "text": "with simple one too many or many to many relationships using no sequel is the",
    "start": "1395820",
    "end": "1401010"
  },
  {
    "text": "right solution for example in dynamodb you can use you know partition key and a range key the partition key being the",
    "start": "1401010",
    "end": "1406470"
  },
  {
    "text": "one side and the range key being the being the inside and the or the start key we call the short key nowadays if",
    "start": "1406470",
    "end": "1412380"
  },
  {
    "text": "you're having multiple cross-table joins and rich transactions using a sequel",
    "start": "1412380",
    "end": "1417390"
  },
  {
    "text": "store is the right solution and if you're doing faceting and search functions obviously search is the right solution there again in terms of the",
    "start": "1417390",
    "end": "1423810"
  },
  {
    "text": "data depending upon the data structure if it's a fixed at schema then sequel or no sequel would help if it's a if it's a",
    "start": "1423810",
    "end": "1430380"
  },
  {
    "text": "JSON document most no sequel stores support JSON and search also has a first year support for JSON again if you're",
    "start": "1430380",
    "end": "1438000"
  },
  {
    "text": "dealing with the key value cache or no sickle is the right in the right choice when often what is the temperature of",
    "start": "1438000",
    "end": "1445350"
  },
  {
    "text": "the data often I think about this when I'm doing design reviews you know typically what I've observed is that when you're dealing with hard data",
    "start": "1445350",
    "end": "1451260"
  },
  {
    "text": "you're typically dealing with small sizes of data typically in the order of you know you know bytes or kilobyte",
    "start": "1451260",
    "end": "1457470"
  },
  {
    "text": "items that tends to become a lot bigger when you're dealing with with colder data you know the request rate tends to",
    "start": "1457470",
    "end": "1464640"
  },
  {
    "text": "be very high when you're reading to caches and the request rate tends to be fairly low when you're actually writing a reading from glacier",
    "start": "1464640",
    "end": "1470160"
  },
  {
    "text": "for example so to be more concrete this is sort of a mental map that I have",
    "start": "1470160",
    "end": "1475800"
  },
  {
    "text": "again a mental maps are not precise definition of things but they they sort of a visualization of what's in my head",
    "start": "1475800",
    "end": "1482340"
  },
  {
    "text": "in a way so in terms of the hot data you know typically caches and no sequel are",
    "start": "1482340",
    "end": "1487800"
  },
  {
    "text": "the mechanisms for storing hard data you know searches and sequel tends to be somewhere sort of a you know temperature",
    "start": "1487800",
    "end": "1494160"
  },
  {
    "text": "tends to move towards warm data if you will and s3 has a wide spectrum wider",
    "start": "1494160",
    "end": "1500220"
  },
  {
    "text": "spectrum starting from a hard data set to a colder data set and lacier tends to be used for cold data there was below",
    "start": "1500220",
    "end": "1506520"
  },
  {
    "text": "sort of you know show you the request rate cost per gigabyte latency and data volumes so this is sort of the mental",
    "start": "1506520",
    "end": "1512430"
  },
  {
    "text": "map that I have and most customers find that extremely helpful in some cases there is a tie we will we will we will",
    "start": "1512430",
    "end": "1518130"
  },
  {
    "text": "use a mechanism to break the tie in a moment so what I've done here is to taken the same mental map or the concept",
    "start": "1518130",
    "end": "1523860"
  },
  {
    "text": "map and then actually use physical services instead like elastic cache is a cache dynamodb is a no cycle store Rd",
    "start": "1523860",
    "end": "1530760"
  },
  {
    "text": "isidoro is a sequel store ElastiCache Amazon ElastiCache elastic search service is again a search service and so",
    "start": "1530760",
    "end": "1538230"
  },
  {
    "text": "on so as you can just see you know it goes from milliseconds to hours you know if you're putting something in a cache",
    "start": "1538230",
    "end": "1543300"
  },
  {
    "text": "your time to getting the data set is usually sub 1 millisecond or 1 millisecond if it's across multiple AZ's",
    "start": "1543300",
    "end": "1549450"
  },
  {
    "text": "whereas in the case of DynamoDB it's about 3 milliseconds average for both puts and gets for 1k 1k payload whereas",
    "start": "1549450",
    "end": "1555480"
  },
  {
    "text": "if you move towards the right if you're putting data in s3 typically it's an order of a few you know tens or hundreds",
    "start": "1555480",
    "end": "1560760"
  },
  {
    "text": "of milliseconds depending on the size of the data and then if you put something in glitch here you're gonna wait T and a half hours for this to come back so I",
    "start": "1560760",
    "end": "1566340"
  },
  {
    "text": "wouldn't put something in place here that you need to get back very soon but again if an archive will store you know three and half hours is a light years",
    "start": "1566340",
    "end": "1572850"
  },
  {
    "text": "ahead for many scenarios right and then in terms of the bottom line here is",
    "start": "1572850",
    "end": "1578160"
  },
  {
    "text": "availability you know DynamoDB for example keeps your data in three availability zones whenever you put a",
    "start": "1578160",
    "end": "1583920"
  },
  {
    "text": "day you know do a put in to DynamoDB the data gets automatically written to two machines and at least two data centers",
    "start": "1583920",
    "end": "1589320"
  },
  {
    "text": "before the put comes back in about three milliseconds right so where that is in",
    "start": "1589320",
    "end": "1594690"
  },
  {
    "text": "the case of elastic cache it's a 2az scenario or in the case of you know",
    "start": "1594690",
    "end": "1601170"
  },
  {
    "text": "Amazon RDS it's again RDS Aurora for example has 3 AZ availability as well so all of these are",
    "start": "1601170",
    "end": "1607980"
  },
  {
    "text": "data systems so typically your availability goes you know I've documented this thing so typically most",
    "start": "1607980",
    "end": "1613980"
  },
  {
    "text": "of them are either highly available or available high availability but I wouldn't put you know your your data in",
    "start": "1613980",
    "end": "1621480"
  },
  {
    "text": "a cache for example some pattern that I see in many customers put Redis their entire data set and read it and call",
    "start": "1621480",
    "end": "1627000"
  },
  {
    "text": "that the database I don't consider a register database it has you know scope for failures typically it's a good idea",
    "start": "1627000",
    "end": "1632070"
  },
  {
    "text": "to put the data set in dynamo DB and then keep a cache and Redis for example or memcache for that matter so you know",
    "start": "1632070",
    "end": "1639750"
  },
  {
    "start": "1639000",
    "end": "1639000"
  },
  {
    "text": "like in some cases like this this is actually an email one of the developers sent me a customer sent me this person",
    "start": "1639750",
    "end": "1647400"
  },
  {
    "text": "is trying to make a decision between Amazon DynamoDB and s3 it turns out that they are",
    "start": "1647400",
    "end": "1652530"
  },
  {
    "text": "actually doing 300 writes per second their object size is roughly 2k in a",
    "start": "1652530",
    "end": "1658200"
  },
  {
    "text": "month they're going to be collecting 1.5 terabytes of data and the number of objects is going to be 7 and 77 million",
    "start": "1658200",
    "end": "1664700"
  },
  {
    "text": "and so this is again a quiz for you so how many of you think we should put this",
    "start": "1664700",
    "end": "1671220"
  },
  {
    "text": "data in s3 please raise your hand 1 2 3",
    "start": "1671220",
    "end": "1678440"
  },
  {
    "text": "4 5 6 7 how many things that you need to put the data in dynamodb Oh a few more",
    "start": "1678440",
    "end": "1684600"
  },
  {
    "text": "hands a lot more hands and raising up so you know one of you is gonna lose so that means bad rating for me so ok let's",
    "start": "1684600",
    "end": "1692010"
  },
  {
    "text": "see so I think the easiest way to solve the tie is to actually plug in the numbers into what I in our simple",
    "start": "1692010",
    "end": "1699600"
  },
  {
    "text": "monthly calculator it's a tool that's available how many of you know simple monthly calculator so it's an important",
    "start": "1699600",
    "end": "1705240"
  },
  {
    "text": "tool for you to know get to know what that is because that tells you how to how to be cut out to do cost conscious design so if you plug in it has a tab",
    "start": "1705240",
    "end": "1711720"
  },
  {
    "text": "for each of our products so you be for example in on the left tab I've actually said you know I'm gonna store you know",
    "start": "1711720",
    "end": "1718580"
  },
  {
    "text": "1.5 terabytes of data each data size you know item size is about 2k when I plug",
    "start": "1718580",
    "end": "1724890"
  },
  {
    "text": "in all those details it gives me a bill your DynamoDB monthly bill will be 644 dollars and 30 cents",
    "start": "1724890",
    "end": "1730350"
  },
  {
    "text": "apparently in the case of s3 this is going to be three thousand nine hundred thirty two dollars and twenty seven cents or so s3 sorry",
    "start": "1730350",
    "end": "1737130"
  },
  {
    "text": "thank you guys lost you know so but you know I think you know the difference is",
    "start": "1737130",
    "end": "1742440"
  },
  {
    "text": "actually probably were thinking storage in fact if you look at the storage cost it's only forty four dollars right was this two hundred sixty one dollars for",
    "start": "1742440",
    "end": "1748530"
  },
  {
    "text": "DynamoDB but what makes the difference there is the put yes three charges four puts if you have a very very large",
    "start": "1748530",
    "end": "1754350"
  },
  {
    "text": "number of puts in other words you are doing lots of puts or small objects it's gonna cost more putting the data in s3",
    "start": "1754350",
    "end": "1759390"
  },
  {
    "text": "in some scenarios now four thousand dollars is not a lot of money for a lot of people but it's so totally okay for",
    "start": "1759390",
    "end": "1764610"
  },
  {
    "text": "some scenarios to put this in f3 but again you know we're being pedagogical here you know being a design this being",
    "start": "1764610",
    "end": "1770520"
  },
  {
    "text": "a design review so it's best to know exactly what you're doing and in some cases breaking the tie the simple",
    "start": "1770520",
    "end": "1775680"
  },
  {
    "text": "monthly calculator allows you to break the tie now when I would I do a talk like this in front of 400 or 500 people",
    "start": "1775680",
    "end": "1780750"
  },
  {
    "text": "I show you typically show this to the product manager the person was very unhappy that yes three was a loser there",
    "start": "1780750",
    "end": "1787830"
  },
  {
    "text": "so I had to put a compensating scenario here if I changed the to object size from 2k to 32k it turns out as three",
    "start": "1787830",
    "end": "1795420"
  },
  {
    "text": "wins they're you know as trees gonna cost you you know four thousand five and eighty eight dollars towards the right",
    "start": "1795420",
    "end": "1800580"
  },
  {
    "text": "bottom was this dynamodb which is about ten thousand dollars right so what really happens there is you know s3",
    "start": "1800580",
    "end": "1806250"
  },
  {
    "text": "likes large it looks like F 3 likes larger object sizes and therefore you you know smaller number of puts so I",
    "start": "1806250",
    "end": "1812400"
  },
  {
    "text": "think we a lot of times we bake the pricing model we bake the optimal use of a product into our pricing model you",
    "start": "1812400",
    "end": "1818550"
  },
  {
    "text": "know this this in many cases tells you tell you what the right service to use so I think that's sort of a you know a",
    "start": "1818550",
    "end": "1824730"
  },
  {
    "text": "real-life example that I ran through I often go through this with customers and they've found this extremely helpful so",
    "start": "1824730",
    "end": "1829740"
  },
  {
    "text": "now let's look at the various processing process and analyze phase so in the case",
    "start": "1829740",
    "end": "1835380"
  },
  {
    "text": "of processing typically there are these types of processing here you're either",
    "start": "1835380",
    "end": "1841230"
  },
  {
    "start": "1836000",
    "end": "1836000"
  },
  {
    "text": "doing batch processing where you take minutes or hours to create a monthly or weekly bill or it's interactive",
    "start": "1841230",
    "end": "1847350"
  },
  {
    "text": "analytics you know somebody's sitting in front of a dashboard it could be a tableau or a quick side dashboard that you you're slicing and dicing the data",
    "start": "1847350",
    "end": "1853590"
  },
  {
    "text": "needs to be interactive answers needs to come back in sub seconds or seconds or you're building a real-time or a stream",
    "start": "1853590",
    "end": "1859080"
  },
  {
    "text": "processing system with answers have to be materialized in milliseconds you know typically you know one second is not you",
    "start": "1859080",
    "end": "1864780"
  },
  {
    "text": "know building systems less than a second is is too difficult typically but you can't process the records in millisecond",
    "start": "1864780",
    "end": "1871950"
  },
  {
    "text": "here similarly messaging systems kind of deal with hard data and then your answers come back in milliseconds or",
    "start": "1871950",
    "end": "1877530"
  },
  {
    "text": "seconds so machine learning on the other hand you know gives you the ability to learn without being you know programmed",
    "start": "1877530",
    "end": "1885140"
  },
  {
    "start": "1878000",
    "end": "1878000"
  },
  {
    "text": "Amazon machine learning service has been very popular amongst many customers and then machine learning algorithms come in",
    "start": "1885140",
    "end": "1891870"
  },
  {
    "text": "you know two major categories you know supervised learning and unsupervised learning in the case of supervised",
    "start": "1891870",
    "end": "1897390"
  },
  {
    "text": "learning you basically train you have a data set and you train a model and then you perfect the model and then the model",
    "start": "1897390",
    "end": "1903300"
  },
  {
    "text": "is used what we the deciding yes or no you know let's say is this a fraudulent transaction yes or no given the",
    "start": "1903300",
    "end": "1908490"
  },
  {
    "text": "characteristics of the data model adult can you tell me whether it's it's it's a fraud or not that's a typical question",
    "start": "1908490",
    "end": "1914010"
  },
  {
    "text": "in the case of classification in the case of regression how much is this house going to sell for you know it's in this area I've trained the model you",
    "start": "1914010",
    "end": "1920940"
  },
  {
    "text": "know based on various attributes of a house you know the number of bedrooms the size the location etc you know what",
    "start": "1920940",
    "end": "1926160"
  },
  {
    "text": "is give me a problem you know what is what is this how is going to sell for you know that's a classic that's a regression problem well it's in the case",
    "start": "1926160",
    "end": "1932280"
  },
  {
    "text": "of clustering you know we sell a lot of you know shoes at amazon.com you know there's an automatic system which",
    "start": "1932280",
    "end": "1937860"
  },
  {
    "text": "classifies the shoe into you know is this a casual shoe of this a dress shoe etc you know rather than a human doing",
    "start": "1937860",
    "end": "1943140"
  },
  {
    "text": "this we have a system that basically you know can actually do that last classification for you if you're",
    "start": "1943140",
    "end": "1948870"
  },
  {
    "text": "building a system like that you know using machine learning is quite helpful so what are the tools and frameworks",
    "start": "1948870",
    "end": "1954780"
  },
  {
    "start": "1953000",
    "end": "1953000"
  },
  {
    "text": "that are available for machine learning like I said before SPARC mo SPARC ml is",
    "start": "1954780",
    "end": "1962190"
  },
  {
    "text": "very popular you can you can run elastic MapReduce which natively run SPARC and then you can use pork ml for process for",
    "start": "1962190",
    "end": "1969179"
  },
  {
    "text": "building your machine models or you can use Amazon machine learning as well which can do both interactive and batch",
    "start": "1969179",
    "end": "1976410"
  },
  {
    "text": "batch learning and in for interactive analytics Amazon redshift is the classic",
    "start": "1976410",
    "end": "1982530"
  },
  {
    "text": "answer but customers also are using a lot of press too and SPARC on top of elastic MapReduce for interactive",
    "start": "1982530",
    "end": "1988860"
  },
  {
    "text": "analytics as well both presto and spark have like a JDBC connector that you know your your your three your applications",
    "start": "1988860",
    "end": "1995550"
  },
  {
    "text": "can talk to for batch processing you know classic batch processing happened in high war pig nowadays Park is being",
    "start": "1995550",
    "end": "2001820"
  },
  {
    "text": "used for faster that's processing using in memory techniques as well and MapReduce has",
    "start": "2001820",
    "end": "2006830"
  },
  {
    "text": "been around for a long time but messaging sqs as we discussed is the right solution for streaming there are",
    "start": "2006830",
    "end": "2011870"
  },
  {
    "text": "two classic categories there if you're dealing with micro batching which is essentially running windowing functions you know give me an average over the",
    "start": "2011870",
    "end": "2018170"
  },
  {
    "text": "last one minute or twenty seconds or 30 seconds for example you can use spark streaming with the been doing you know",
    "start": "2018170",
    "end": "2023930"
  },
  {
    "text": "duration if you will or you can build the same using Kinesis client Canisius client library in the case of real-time",
    "start": "2023930",
    "end": "2029630"
  },
  {
    "text": "if you're doing real-time streaming then Apaches tom has been very popular for a",
    "start": "2029630",
    "end": "2034940"
  },
  {
    "text": "long time it's been around for a long time more and then Canisius analytics is a new product that we we are it is in",
    "start": "2034940",
    "end": "2042110"
  },
  {
    "text": "private beta if you're interested in Amazon Canisius analytics I think you can actually put your details in a forum",
    "start": "2042110",
    "end": "2048110"
  },
  {
    "text": "will give you private access to Canisius analytics think of that as you know spark streaming without having to run",
    "start": "2048110",
    "end": "2054010"
  },
  {
    "text": "any clusters if you will and you know magic happens behind I think we'll be launching this this offering",
    "start": "2054010",
    "end": "2060260"
  },
  {
    "text": "pretty soon but you can you can actually take it for a spin right now if you're interested by subscribing",
    "start": "2060260",
    "end": "2066500"
  },
  {
    "text": "AWS lambda as Matt pointed out in the keynote is super popular a lot of the",
    "start": "2066500",
    "end": "2072169"
  },
  {
    "text": "ETL processing is moving to you know server less compute which is lambda KCl",
    "start": "2072170",
    "end": "2077780"
  },
  {
    "text": "Canisius client library is also very popular and those are the techniques again what I've done I've also done the",
    "start": "2077780",
    "end": "2084860"
  },
  {
    "text": "same thing here in terms of compared the various processing stream processing",
    "start": "2084860",
    "end": "2090409"
  },
  {
    "text": "technologies across various attributes such as scale whether it's a micro batch of real-time is it a managed service you",
    "start": "2090410",
    "end": "2096770"
  },
  {
    "text": "know what are the scalability limits if any what are the availability or a touch on availability you know spark streaming",
    "start": "2096770",
    "end": "2102460"
  },
  {
    "text": "when it runs on top of elastic MapReduce is still a single easy solution but as AWS lambda automatically runs in",
    "start": "2102460",
    "end": "2109280"
  },
  {
    "text": "multiple availability zones so if you are actually doing spark streaming on top of EMR to process your streaming",
    "start": "2109280",
    "end": "2115820"
  },
  {
    "text": "data if you're worried about availability you need to have a mechanism to actually run another cluster in case in availability zone",
    "start": "2115820",
    "end": "2121580"
  },
  {
    "text": "fails right so I think I you know most customers sort of you know think about",
    "start": "2121580",
    "end": "2126740"
  },
  {
    "text": "this after the fact I just wanted to highlight that piece here that's part of this slide and then so I'm gonna leave",
    "start": "2126740",
    "end": "2134390"
  },
  {
    "text": "this slide for homework and move forward in terms of what analytics technology",
    "start": "2134390",
    "end": "2139410"
  },
  {
    "start": "2137000",
    "end": "2137000"
  },
  {
    "text": "should I use typically Amazon redshift is a great place to start you know you can put until 1.6 petabyte",
    "start": "2139410",
    "end": "2145650"
  },
  {
    "text": "I think NTT DoCoMo has a cluster which is more than 2 petabytes if you need more than 1.6 petabytes you can talk to",
    "start": "2145650",
    "end": "2151260"
  },
  {
    "text": "us we can you know especially enable you for more than that it's full fidelity sequel it's anti sequel compliant",
    "start": "2151260",
    "end": "2157590"
  },
  {
    "text": "whereas if you move towards the right side of running press tour spark or hive on top of elastic MapReduce you know",
    "start": "2157590",
    "end": "2163080"
  },
  {
    "text": "presto has very high sequel compatibility whereas in the case of spark it's pork sequel you know is not full-fledged ANSI sequel as well as you",
    "start": "2163080",
    "end": "2172080"
  },
  {
    "text": "know hive qlh kewal is not full fledged ANSYS if you're using all kinds of tools such as tableau etc or anything that",
    "start": "2172080",
    "end": "2178800"
  },
  {
    "text": "talks JDBC chances are using full fidelity sequel is going to be fairly important for you and redshift is a good",
    "start": "2178800",
    "end": "2185640"
  },
  {
    "text": "place to start for most customers if you wanna go open source probably Presta would be a great place to start for for",
    "start": "2185640",
    "end": "2192600"
  },
  {
    "text": "politics solutions what about ETL we have a protocol AWS",
    "start": "2192600",
    "end": "2198600"
  },
  {
    "start": "2195000",
    "end": "2195000"
  },
  {
    "text": "data pipeline you know think of startup as a crown or an orchestration service that would wake up you know do the ETL",
    "start": "2198600",
    "end": "2204540"
  },
  {
    "text": "job and actually shut down it'll it'll bring up a VM or cluster that's the classic use and then run some ETL and",
    "start": "2204540",
    "end": "2211500"
  },
  {
    "text": "transform the data and put that into into an appropriate store if you will there's also a lot of amazing tools from",
    "start": "2211500",
    "end": "2217440"
  },
  {
    "text": "our data integration partners you know art annuity and from attica metallian snap logic and alt rex also has some",
    "start": "2217440",
    "end": "2224070"
  },
  {
    "text": "great solutions there now we're moving into the consume stage and in the case",
    "start": "2224070",
    "end": "2230730"
  },
  {
    "text": "of consume stage you know typically you're consuming applications they could be human beings that are consuming the",
    "start": "2230730",
    "end": "2237510"
  },
  {
    "text": "data that you put into either store or audio processing tier or it could be services that are that are actually",
    "start": "2237510",
    "end": "2244530"
  },
  {
    "text": "supporting other downstream applications that you can build so if you're a business user typically you're actually",
    "start": "2244530",
    "end": "2250440"
  },
  {
    "text": "you know slicing and dicing the data through a quick side or tableau or looker or MicroStrategy those tools work",
    "start": "2250440",
    "end": "2257160"
  },
  {
    "text": "fairly well with a lot of data services that we talked about if you're a data scientist or a developer you may be",
    "start": "2257160",
    "end": "2263370"
  },
  {
    "text": "building dashboards using you know like flawed or d3 SDKs",
    "start": "2263370",
    "end": "2269880"
  },
  {
    "text": "as the case if you will or more importantly data scientists are now using a lot of notebooks Zeppelin and",
    "start": "2269880",
    "end": "2275850"
  },
  {
    "text": "ipython notebooks are fairly popular we have an AWS blog for big data that has",
    "start": "2275850",
    "end": "2280890"
  },
  {
    "text": "you know two explicit blogs and how do you run Zeppelin on top of EMR also how do you run ipython notebook in the AWS",
    "start": "2280890",
    "end": "2288150"
  },
  {
    "text": "environment so if you if you have a lot of data scientists that want to share and process the large amounts of data",
    "start": "2288150",
    "end": "2293790"
  },
  {
    "text": "you know actually giving them these notebook abstractions is quite powerful and helpful you know a lot of data scientists use our studio as well for",
    "start": "2293790",
    "end": "2300750"
  },
  {
    "text": "processing the data so those are some of the some of the consumed tier options now putting it all together here's sort",
    "start": "2300750",
    "end": "2306930"
  },
  {
    "text": "of the reference architecture that I derived out of now you know this will be",
    "start": "2306930",
    "end": "2312150"
  },
  {
    "text": "available for you for downloads and future reference but now let's actually do some design patterns so here is a",
    "start": "2312150",
    "end": "2320760"
  },
  {
    "text": "primitive design pattern you know like I talked with said before when you're building a big data pipeline you should",
    "start": "2320760",
    "end": "2325830"
  },
  {
    "text": "be thinking about building decoupled systems which typically comprises of you know the store process tool process repeating itself with the storage",
    "start": "2325830",
    "end": "2331740"
  },
  {
    "text": "subsystem decoupling multiple processing stages if you're using a stream storage subsystem such as Amazon Kinesis or",
    "start": "2331740",
    "end": "2337860"
  },
  {
    "text": "Kafka what these systems allow you to do the processing applications multiple",
    "start": "2337860",
    "end": "2343800"
  },
  {
    "text": "processing applications can read from from stream storage subsystems in this",
    "start": "2343800",
    "end": "2349170"
  },
  {
    "text": "case Canisius tree connector is reading from kinases and writing to s3 in parallel AWS lambda is also processing",
    "start": "2349170",
    "end": "2356070"
  },
  {
    "text": "the same data set and taking the metadata and putting that in dynamo dB now if you if you decouple it this way",
    "start": "2356070",
    "end": "2363180"
  },
  {
    "text": "if you decouple storage from processing or analysis in this case a spark cluster is actually building a query based on",
    "start": "2363180",
    "end": "2370140"
  },
  {
    "text": "the data that goes into ray you know s3 and and dynamodb and also you know",
    "start": "2370140",
    "end": "2375810"
  },
  {
    "text": "joining that with with spark streaming analytics as well so so that's the classic design pattern now what I've",
    "start": "2375810",
    "end": "2383190"
  },
  {
    "text": "done here in this slide is to you know we talked about the various temperature of the data you know you're dealing with",
    "start": "2383190",
    "end": "2388440"
  },
  {
    "text": "hard data or cold data or warm data and then typically hard data goes into",
    "start": "2388440",
    "end": "2395040"
  },
  {
    "text": "Kinesis or Kafka Amazon DynamoDB can be used for both hard data as well as warm data and s3 is typically used for warm",
    "start": "2395040",
    "end": "2402030"
  },
  {
    "text": "data and pull data as well you know if you put the data in Kinesis you can run",
    "start": "2402030",
    "end": "2407640"
  },
  {
    "text": "either spark streaming or storm or AWS lambda or KCl to process that you know the length of the arrow from from those",
    "start": "2407640",
    "end": "2414540"
  },
  {
    "text": "boxes like indicates the processing speed if it's fast it gets done faster",
    "start": "2414540",
    "end": "2419790"
  },
  {
    "text": "which means a shorter arrow and if it takes a long time in the case of hive towards the right it takes a long time to process the data so the combination",
    "start": "2419790",
    "end": "2426600"
  },
  {
    "text": "of this you know when you're dealing with real-time analytics typically you're putting that in a hot store and and processing the data using a fast",
    "start": "2426600",
    "end": "2432480"
  },
  {
    "text": "processing technology if you're dealing at the interactive analytics typically you put the data in either a hot or a warm store and you process use a",
    "start": "2432480",
    "end": "2439830"
  },
  {
    "text": "processing mechanism that that does processing fairly fast in the case of batch again your processing mechanism",
    "start": "2439830",
    "end": "2445560"
  },
  {
    "text": "can be pretty slow in the case of hi so here is a classic you know pattern for real-time analytics your data you know",
    "start": "2445560",
    "end": "2451650"
  },
  {
    "start": "2448000",
    "end": "2448000"
  },
  {
    "text": "stream goes into a their Kinesis or Kafka DynamoDB stream I'll probably start with Kinesis and then you can use",
    "start": "2451650",
    "end": "2457560"
  },
  {
    "text": "a that KCl or AWS lambda if you want do server less processing you can use it OBS lambda all you need to do is to run",
    "start": "2457560",
    "end": "2463500"
  },
  {
    "text": "a run a function to process the data but then you can't do any you know windowing functions and such because you know the",
    "start": "2463500",
    "end": "2471050"
  },
  {
    "text": "the way that Kinesis AWS lambda works is the a bunch of records is handed out to lambda function and the land of function",
    "start": "2471050",
    "end": "2477360"
  },
  {
    "text": "can run in any any any process so you can't do you know like a give me the average max min and all those functions",
    "start": "2477360",
    "end": "2483570"
  },
  {
    "text": "but if you do simple ETL or or if you're doing a loading based on you know is a temperature more than 100 degrees then",
    "start": "2483570",
    "end": "2489360"
  },
  {
    "text": "go ahead and send a notification that you can easily build using lambda spark streaming similarly can be used for a",
    "start": "2489360",
    "end": "2496760"
  },
  {
    "text": "wide variety of processing tasks and so so does Apache strong and the way to",
    "start": "2496760",
    "end": "2502140"
  },
  {
    "text": "build real-time machine learning into it is basically you do a lookup area you can do a realtor if you if you build",
    "start": "2502140",
    "end": "2507660"
  },
  {
    "text": "your machine learning model in Amazon machine learning you can do a real time lookup before you decide whether they're",
    "start": "2507660",
    "end": "2513120"
  },
  {
    "text": "whether this transaction that coming in is a fraud or not if it's fraud you basically send an SMS notification",
    "start": "2513120",
    "end": "2518700"
  },
  {
    "text": "alerting some system downstream system that this is a potential fraud and typically what happens is an application",
    "start": "2518700",
    "end": "2525270"
  },
  {
    "text": "state even though you're put you're doing real-time processing you keep an application state in you know in a",
    "start": "2525270",
    "end": "2530700"
  },
  {
    "text": "database or a cache such as red as our DynamoDB or RDS or elasticsearch and then you have",
    "start": "2530700",
    "end": "2535950"
  },
  {
    "text": "kpi then you draw your KPIs by reading from those data stores that access a",
    "start": "2535950",
    "end": "2540990"
  },
  {
    "text": "nice decoupling mechanism between the tear that's there's doing the drawings as well as the you know the tear that's",
    "start": "2540990",
    "end": "2546990"
  },
  {
    "text": "actually processing the data and populating the database if you will for even third message processing typically",
    "start": "2546990",
    "end": "2552330"
  },
  {
    "text": "you can use an auto scaling group you can do this using elastic beanstalk you",
    "start": "2552330",
    "end": "2557430"
  },
  {
    "text": "can you know basically run elastic beanstalk sqs application they can process from a queue and then in a store",
    "start": "2557430",
    "end": "2563670"
  },
  {
    "text": "the application state as before into any of those you know storage mechanisms or",
    "start": "2563670",
    "end": "2568830"
  },
  {
    "text": "you can you can actually do downstream you can do a publish to SNS and how downstream subscribers subscribe to it",
    "start": "2568830",
    "end": "2575670"
  },
  {
    "text": "and also certain some cases you you chain various cues you know the first-tier processes and and picks out",
    "start": "2575670",
    "end": "2581490"
  },
  {
    "text": "all the high priority messages puts that in a downstream queue for high priority processing and low priority processing",
    "start": "2581490",
    "end": "2586530"
  },
  {
    "text": "so this is a typical architecture that's used for that kind of a message that event processing so what about",
    "start": "2586530",
    "end": "2594210"
  },
  {
    "start": "2593000",
    "end": "2593000"
  },
  {
    "text": "interactive analytics if you have streaming data going in putting the data in fire hose and then transporting the",
    "start": "2594210",
    "end": "2599970"
  },
  {
    "text": "data to s3 or redshift and now from starting tomorrow elasticsearch to do",
    "start": "2599970",
    "end": "2605640"
  },
  {
    "text": "interactive analytics is is a very viable option or you can also run batch analytics you know using high warp egg",
    "start": "2605640",
    "end": "2611700"
  },
  {
    "text": "on the same data again amazon machine learning can be can be useful for doing batch prediction so if you have a bunch",
    "start": "2611700",
    "end": "2617850"
  },
  {
    "text": "of rackets and if you want to basically hand off those records so much on machine learning and ask it to do predictions they'll do the predictions",
    "start": "2617850",
    "end": "2623850"
  },
  {
    "text": "and put the data in s3 you can read the data back and actually you know build that intelligence as part of your",
    "start": "2623850",
    "end": "2629820"
  },
  {
    "text": "processing pipeline if it's real time it can also do real-time lookups is is a problem transaction yes or no it will",
    "start": "2629820",
    "end": "2635250"
  },
  {
    "text": "consult the model and say yes this looks like a fraud or perhaps no this doesn't look like a fraud and then lambda",
    "start": "2635250",
    "end": "2641220"
  },
  {
    "start": "2640000",
    "end": "2640000"
  },
  {
    "text": "architecture as we talked about is actually you know doing a combination of both in the case of a land architecture",
    "start": "2641220",
    "end": "2647220"
  },
  {
    "text": "you know your data goes into something Kinesis and then you have a connector that takes the data from Kinesis and",
    "start": "2647220",
    "end": "2653760"
  },
  {
    "text": "writes it to s3 and then you can actually use any of the technologies that we talked before like redshift or",
    "start": "2653760",
    "end": "2659640"
  },
  {
    "text": "EMR to process the data and materialize an answer for speed processing on a fast-moving data sets you can use any of",
    "start": "2659640",
    "end": "2666480"
  },
  {
    "text": "these technologies in the boxes you know KCl or lambda to compute the answer and then you can",
    "start": "2666480",
    "end": "2671710"
  },
  {
    "text": "you can you can persist that into what I call as a serving layer which nicely decouples the application on the right",
    "start": "2671710",
    "end": "2678069"
  },
  {
    "text": "side from from your from your processing applications and this is a typical architecture for doing a lambda",
    "start": "2678069",
    "end": "2685059"
  },
  {
    "text": "architecture on AWS and and you can also build machine learning into this by",
    "start": "2685059",
    "end": "2691599"
  },
  {
    "text": "doing machine learning lookups at the processing stage and take appropriate actions based on what your machine",
    "start": "2691599",
    "end": "2697660"
  },
  {
    "text": "learning system you know tells you and that machine learning lookups can happen you know",
    "start": "2697660",
    "end": "2703329"
  },
  {
    "text": "using Amazon machine learning or it could be in a spark ml as well now in",
    "start": "2703329",
    "end": "2708670"
  },
  {
    "start": "2708000",
    "end": "2708000"
  },
  {
    "text": "summary you know building decoupled systems is important if you're building",
    "start": "2708670",
    "end": "2714009"
  },
  {
    "text": "a big data processing pipeline please ensure that this is nice decoupling between that allows you to change the",
    "start": "2714009",
    "end": "2719559"
  },
  {
    "text": "various components as well as newer technologies come in and using the right",
    "start": "2719559",
    "end": "2724779"
  },
  {
    "text": "tool for the job it's fairly important you know you should pick a tool based on the data structure you know hot or code",
    "start": "2724779",
    "end": "2731410"
  },
  {
    "text": "access patterns as well as the heart are called data sets that you're dealing with using lambda architecture ideas",
    "start": "2731410",
    "end": "2737259"
  },
  {
    "text": "like we talked about is fairly important if you did persist one thing there is I",
    "start": "2737259",
    "end": "2742299"
  },
  {
    "text": "often ensure that when when people are building you know data processing systems stream processing systems or the",
    "start": "2742299",
    "end": "2748029"
  },
  {
    "text": "customers actually have the actual data stream per sister in s3 for further analytics if you well it's very key and",
    "start": "2748029",
    "end": "2754299"
  },
  {
    "text": "then the you the ideas of using you know compositing systems from batch and speedily and and and real-time",
    "start": "2754299",
    "end": "2760990"
  },
  {
    "text": "processing using and serving using a serving layer is fairly important and scalable literally every single",
    "start": "2760990",
    "end": "2767220"
  },
  {
    "text": "real-time bidding system uses a land architecture of sorts under the covers and then using a Tobias managed services",
    "start": "2767220",
    "end": "2774339"
  },
  {
    "text": "is key rather than reinventing the wheel you can we've already made the wheel for you it's nice to probably just assemble",
    "start": "2774339",
    "end": "2779799"
  },
  {
    "text": "the wheel as it is and use it unless you see a reason not to use it I would start",
    "start": "2779799",
    "end": "2784930"
  },
  {
    "text": "with the managed service such as dynamodb or Kinesis s3 etc also all these systems are",
    "start": "2784930",
    "end": "2792640"
  },
  {
    "text": "elastic and there is no almost no low or no admin and last but not the least be",
    "start": "2792640",
    "end": "2799509"
  },
  {
    "text": "super cost conscious by picking the cheapest solution you're probably picking the best tool to",
    "start": "2799509",
    "end": "2804790"
  },
  {
    "text": "do the job by the best subsystem your end-to-end cost should be should be very you know very very low cost big data",
    "start": "2804790",
    "end": "2813760"
  },
  {
    "text": "should not because they cost often this has helped me to to read out the wrong tools if you will well that's it thank",
    "start": "2813760",
    "end": "2820960"
  },
  {
    "text": "you for your time I'm happy to stay here and take any questions and hope that was helpful",
    "start": "2820960",
    "end": "2827550"
  }
]
[
  {
    "start": "0",
    "end": "57000"
  },
  {
    "text": "hello everybody uh thank you for joining us at 5 30 p.m on a thursday after a really incredibly",
    "start": "4720",
    "end": "12080"
  },
  {
    "text": "busy reinvent you know we always made the joke about it's between us and lunch and but this is not a lunch",
    "start": "12080",
    "end": "17600"
  },
  {
    "text": "this is a beer and or insert your name or favorite beverage and you know that's a harder trade-off",
    "start": "17600",
    "end": "22640"
  },
  {
    "text": "and we appreciate you being here uh today just quick introductions my name is adi uh uh i'm the product manager in amazon",
    "start": "22640",
    "end": "29439"
  },
  {
    "text": "kinesis and uh i'm joined here today by eddie and ian from from mediamath",
    "start": "29439",
    "end": "35840"
  },
  {
    "text": "um and this is really their show uh a lot of my conversation often is going to be just introducing you to some of the",
    "start": "35840",
    "end": "41600"
  },
  {
    "text": "concepts and then um eddie and ian will walk you through media mats use case",
    "start": "41600",
    "end": "48960"
  },
  {
    "text": "and how they have re-engineered their data flows using amazon kinesis emr and some of the other aws stack",
    "start": "48960",
    "end": "59520"
  },
  {
    "start": "57000",
    "end": "98000"
  },
  {
    "text": "so let's start with uh the case for for streaming data so how many of you just kind of a",
    "start": "59520",
    "end": "64559"
  },
  {
    "text": "quick show of hands i do see some of you who are in the kinesis presentation and the emr presentation but how many of you",
    "start": "64559",
    "end": "69760"
  },
  {
    "text": "would you say are in the streaming data world today where you have continuous generated data",
    "start": "69760",
    "end": "74960"
  },
  {
    "text": "that you're then processing yes very good uh how many of you are using",
    "start": "74960",
    "end": "80320"
  },
  {
    "text": "uh kinesis and or emr so bolts and or okay how many",
    "start": "80320",
    "end": "86479"
  },
  {
    "text": "of you using something like kafka or some other message queueing system to get stuff done",
    "start": "86479",
    "end": "91759"
  },
  {
    "text": "okay so so this is a good knowledgeable audience and hopefully this will be",
    "start": "91759",
    "end": "97520"
  },
  {
    "start": "98000",
    "end": "201000"
  },
  {
    "text": "interesting now this is a canonical data processing pipeline and uh we've all been there and and",
    "start": "99600",
    "end": "105920"
  },
  {
    "text": "and i would argue that some of us are still in this world where we've got our logging tier ingested tier or the",
    "start": "105920",
    "end": "112079"
  },
  {
    "text": "data producer tier that is responsible for continuously generating data or the first line of defense",
    "start": "112079",
    "end": "118560"
  },
  {
    "text": "that data is micro bashed pre-aggregated on those producers server tiers and then",
    "start": "118560",
    "end": "124960"
  },
  {
    "text": "snapshotted into some other persistence mechanism uh in this case we've got s3 on the board",
    "start": "124960",
    "end": "132640"
  },
  {
    "text": "after that data is stored in batches one would typically etl it out using some tool like emr or your",
    "start": "132640",
    "end": "139040"
  },
  {
    "text": "favorite flavor of hadoop distribution and once that's done the data then gets",
    "start": "139040",
    "end": "144239"
  },
  {
    "text": "uh etled out and transformed and loaded into your data warehouse of choice",
    "start": "144239",
    "end": "149440"
  },
  {
    "text": "it's a very common data processing workflow and we as amazon weren't very different",
    "start": "149440",
    "end": "156560"
  },
  {
    "text": "several of our pipelines looked very very similar to that now but what were the choices the tough",
    "start": "156560",
    "end": "162400"
  },
  {
    "text": "choices that we were making here we were choosing not to capture all of our data because there was only that much that",
    "start": "162400",
    "end": "168560"
  },
  {
    "text": "the the clients that were submitting the data or the process submission fleet uh could deal with and between uh",
    "start": "168560",
    "end": "175599"
  },
  {
    "text": "uptime and do we end up not collecting some amount of data we'd make the choice for uptime and reliability",
    "start": "175599",
    "end": "182080"
  },
  {
    "text": "obviously given all these different steps of batches there was ultimately the notion that we weren't getting to a continuous or even",
    "start": "182080",
    "end": "188959"
  },
  {
    "text": "a near real-time way of getting at the data we had multiple different components at place",
    "start": "188959",
    "end": "194319"
  },
  {
    "text": "they all had to be dealt with independently and so operationally speaking it was a much harder pipeline for us to manage",
    "start": "194319",
    "end": "202000"
  },
  {
    "start": "201000",
    "end": "287000"
  },
  {
    "text": "and so we clearly see where the old posture was but what the business was demanding of us and this is almost you know kinesis as",
    "start": "203120",
    "end": "211120"
  },
  {
    "text": "as a as an internal use case for amazon and hopefully a lot of you will see some",
    "start": "211120",
    "end": "216480"
  },
  {
    "text": "sort of uh relevance with what you see in your organizations as well is that the business was coming in with with",
    "start": "216480",
    "end": "223040"
  },
  {
    "text": "other kinds of requirements uh the first one was and this is not shocking i cannot wait",
    "start": "223040",
    "end": "229040"
  },
  {
    "text": "this long for my data to be available for me to do something interesting with it and this could be click stream data this",
    "start": "229040",
    "end": "234400"
  },
  {
    "text": "could be log data this could be mobile app data consumer engagement data",
    "start": "234400",
    "end": "239920"
  },
  {
    "text": "but it was simply taking too long for the data to show up to do something meaningful with it",
    "start": "239920",
    "end": "244959"
  },
  {
    "text": "the second thing was why are you dropping this data okay i don't know what i'm going to do with it right now but i'm sure it's it's interesting and",
    "start": "244959",
    "end": "251439"
  },
  {
    "text": "valuable and i will get around to processing it so don't make that upfront decision to filter out data",
    "start": "251439",
    "end": "257199"
  },
  {
    "text": "that you don't want to grab the next one as service operators we too are interested",
    "start": "257199",
    "end": "264080"
  },
  {
    "text": "in keeping the system clean simple scalable and we want to make sure that the system that we were building",
    "start": "264080",
    "end": "269919"
  },
  {
    "text": "was fundamentally elastic and last but not the least the the discovery process yielded that",
    "start": "269919",
    "end": "276080"
  },
  {
    "text": "there typically are multiple applications that want to consume from the same data stream",
    "start": "276080",
    "end": "281360"
  },
  {
    "text": "concurrently independently but on the same stream of data and so",
    "start": "281360",
    "end": "288400"
  },
  {
    "start": "287000",
    "end": "365000"
  },
  {
    "text": "visually you know what does the canonical data flow then look like you've got any different kinds of of",
    "start": "288400",
    "end": "295120"
  },
  {
    "text": "data streams click stream data log data device data sensor data really it doesn't really matter but these are all examples",
    "start": "295120",
    "end": "301759"
  },
  {
    "text": "of small fast moving data that has been continuously generated across across your infrastructure or",
    "start": "301759",
    "end": "308080"
  },
  {
    "text": "line of business that's being emitted into this unified",
    "start": "308080",
    "end": "313280"
  },
  {
    "text": "uh log capture data capture mechanism so something like in this picture amazon kinesis then",
    "start": "313280",
    "end": "319280"
  },
  {
    "text": "you have multiple applications that are pulling data from the same kinesis stream driving to",
    "start": "319280",
    "end": "324400"
  },
  {
    "text": "different outcomes you've got you've got one application that is trying to drive a continuous dashboard",
    "start": "324400",
    "end": "330320"
  },
  {
    "text": "that might be a minute sliding window analytics on some uh on some sliding window aggregate you",
    "start": "330320",
    "end": "337280"
  },
  {
    "text": "have another application that is aggregating the data writing it to s3 such that it can then be loaded into",
    "start": "337280",
    "end": "343440"
  },
  {
    "text": "redshift now redshift gets populated with fresh data you've got",
    "start": "343440",
    "end": "348800"
  },
  {
    "text": "another application arguably more interesting from a historical analysis longitudinal analysis",
    "start": "348800",
    "end": "354479"
  },
  {
    "text": "and ad hoc analysis would be to pick data out from within emr and now you can apply",
    "start": "354479",
    "end": "359919"
  },
  {
    "text": "the power of the hadoop stack to all of that data",
    "start": "359919",
    "end": "366800"
  },
  {
    "start": "365000",
    "end": "424000"
  },
  {
    "text": "one of the discoveries that we made is that all of these different kinds of data processing engines have their place",
    "start": "366800",
    "end": "373759"
  },
  {
    "text": "in in any line of business uh really kind of the the thought process is right tool set for the right job",
    "start": "373759",
    "end": "380800"
  },
  {
    "text": "data warehousing we understand we're not going to go super deep there but really the two things that jump at us in this",
    "start": "380800",
    "end": "386160"
  },
  {
    "text": "kind of new world of continuously generated data is how do we deal with large amounts of unstructured",
    "start": "386160",
    "end": "391919"
  },
  {
    "text": "data such that we can run arbitrarily complex calculations on the entire data set",
    "start": "391919",
    "end": "397360"
  },
  {
    "text": "and that would be the hadoop based model at least in our session now personified by how emr gets used",
    "start": "397360",
    "end": "403680"
  },
  {
    "text": "and then the stream processing model as exemplified by kinesis where the actual computation is not arbitrarily complex",
    "start": "403680",
    "end": "410880"
  },
  {
    "text": "you're not doing rich analytics you're looking at a continuous moving window of data but doing something very specific and",
    "start": "410880",
    "end": "417680"
  },
  {
    "text": "contained but doing so continuously and doing so in a in a somewhat near real-time",
    "start": "417680",
    "end": "423039"
  },
  {
    "text": "fashion so amazon kinesis as a quick overview now is",
    "start": "423039",
    "end": "429440"
  },
  {
    "start": "424000",
    "end": "442000"
  },
  {
    "text": "manage real-time processing and data it's high throughput in elastic you can send as much data",
    "start": "429440",
    "end": "434479"
  },
  {
    "text": "in your provision stream and you can enable data movement into things like s3 emr redshift dynamodb",
    "start": "434479",
    "end": "443599"
  },
  {
    "text": "high level cartoon diagram here you've got millions of producers log servers your mobile devices that are",
    "start": "443919",
    "end": "450240"
  },
  {
    "text": "sending data into your front end uh typical aws authentication",
    "start": "450240",
    "end": "456000"
  },
  {
    "text": "authorization mechanisms any data you put into kinesis is three-way replicated across availability",
    "start": "456000",
    "end": "461280"
  },
  {
    "text": "zones stored durably the data is emitted as an",
    "start": "461280",
    "end": "466639"
  },
  {
    "text": "ordered stream of events now you can have those multiple applications",
    "start": "466639",
    "end": "471919"
  },
  {
    "text": "grab grab that data and run their business specific processing logic",
    "start": "471919",
    "end": "479840"
  },
  {
    "text": "emr for those of you who don't know as a quick summary elastic mapreduce is managed hadoop in the cloud support",
    "start": "481120",
    "end": "489360"
  },
  {
    "text": "for a variety of processing frameworks and and tools such as impala hive and of",
    "start": "489360",
    "end": "495919"
  },
  {
    "text": "course the core mapreduce framework easy to use fully managed to get clusters on demand",
    "start": "495919",
    "end": "502000"
  },
  {
    "text": "and you can leverage all of ec2's on-demand and spot pricing to drive to a very cost effective",
    "start": "502000",
    "end": "507840"
  },
  {
    "text": "large scale hadoop cluster so that was just a quick overview but",
    "start": "507840",
    "end": "513279"
  },
  {
    "start": "510000",
    "end": "563000"
  },
  {
    "text": "really coming to the fun part of the session i'm going to hand it off now to ian who's going to introduce us to how",
    "start": "513279",
    "end": "519279"
  },
  {
    "text": "mediamath liberated data which is quite exciting cool thanks adi",
    "start": "519279",
    "end": "524720"
  },
  {
    "text": "uh so we're really excited to be here uh at re event thanks for sticking around my name is ian hummel",
    "start": "524720",
    "end": "530560"
  },
  {
    "text": "i'm the senior director of platform data i'm annie fagan i'm the vp of data services engineering",
    "start": "530560",
    "end": "536959"
  },
  {
    "text": "at the event and we're going to talk to you today about a project we've been working on",
    "start": "536959",
    "end": "542160"
  },
  {
    "text": "over the last year which is our data liberation project and we're going to tell you about kind of",
    "start": "542160",
    "end": "547440"
  },
  {
    "text": "what that means for us and go through some of the tools that we're using kinesis emr",
    "start": "547440",
    "end": "553600"
  },
  {
    "text": "other aws services and hopefully show you some of the you know use cases that we're pretty excited",
    "start": "553600",
    "end": "559519"
  },
  {
    "text": "about that it unlocks for us so uh if you guys aren't in ad tech if",
    "start": "559519",
    "end": "566240"
  },
  {
    "start": "563000",
    "end": "640000"
  },
  {
    "text": "you've never heard of media math um we are a programmatic uh marketing",
    "start": "566240",
    "end": "571680"
  },
  {
    "text": "platform um online advertising has really changed over the last few years as more and more",
    "start": "571680",
    "end": "579120"
  },
  {
    "text": "digital dollars are shifted into real-time programmatic channels so what does that mean i'm basically as",
    "start": "579120",
    "end": "586080"
  },
  {
    "text": "you're out there browsing around clicking around when a page loads there's actually an auction that takes",
    "start": "586080",
    "end": "592080"
  },
  {
    "text": "place and lots of different parties are able to you know participate in that auction",
    "start": "592080",
    "end": "597519"
  },
  {
    "text": "submit bids use data about the user or context that they may have collected",
    "start": "597519",
    "end": "602640"
  },
  {
    "text": "to really you know evaluate uh each impression for what it's really worth to them",
    "start": "602640",
    "end": "607920"
  },
  {
    "text": "and our product terminal one helps advertisers and agencies uh",
    "start": "607920",
    "end": "615040"
  },
  {
    "text": "run their media campaigns in the most efficient way possible whether that's on display video mobile social",
    "start": "615040",
    "end": "622240"
  },
  {
    "text": "we do that by putting data at the center of everything we do so we have a decisioning and optimization algorithm",
    "start": "622240",
    "end": "628560"
  },
  {
    "text": "that we cleverly call the brain and it lets us kind of you know ingest a",
    "start": "628560",
    "end": "633839"
  },
  {
    "text": "lot of this data and really focus on outcomes for our clients",
    "start": "633839",
    "end": "640480"
  },
  {
    "start": "640000",
    "end": "754000"
  },
  {
    "text": "um so as you can imagine in this sort of environment we end up generating and",
    "start": "641120",
    "end": "647200"
  },
  {
    "text": "processing a lot of data and it's uh sort of funny every time i give this talk i forget to update the",
    "start": "647200",
    "end": "653040"
  },
  {
    "text": "slides because those numbers keep going up um so as of last week we're doing about 120",
    "start": "653040",
    "end": "660959"
  },
  {
    "text": "billion ad impressions per day so that's receiving the auction opportunity processing it",
    "start": "660959",
    "end": "667360"
  },
  {
    "text": "evaluating it submitting a bid and logging whether we've won or not",
    "start": "667360",
    "end": "672800"
  },
  {
    "text": "peak qps right now is uh actually we just crossed the 2 million mark um so",
    "start": "672800",
    "end": "679839"
  },
  {
    "text": "we're pumping a lot of data through our systems um we're plugged into 30 different exchange partners all across the globe",
    "start": "679839",
    "end": "686399"
  },
  {
    "text": "in asia emea south america and we're pretty proud that we're able to you know",
    "start": "686399",
    "end": "692480"
  },
  {
    "text": "handle that that volume um in pretty tight latency",
    "start": "692480",
    "end": "698720"
  },
  {
    "text": "windows so 30 milliseconds average response time the key there is that we have a hybrid",
    "start": "698720",
    "end": "704640"
  },
  {
    "text": "model so we manage our own data centers where we have you know some of those critical",
    "start": "704640",
    "end": "710800"
  },
  {
    "text": "latency sensitive systems but we are increasingly moving a lot of our data processing",
    "start": "710800",
    "end": "716240"
  },
  {
    "text": "into the aws cloud what's kind of interesting about our industry",
    "start": "716240",
    "end": "721279"
  },
  {
    "text": "is that you know all these impressions are actually financial transactions so every record",
    "start": "721279",
    "end": "727760"
  },
  {
    "text": "counts we can't lose messages we can't drop impressions at the end of the day we",
    "start": "727760",
    "end": "733040"
  },
  {
    "text": "have to add up all the pennies and our clients really hold us accountable to that they don't tolerate",
    "start": "733040",
    "end": "738240"
  },
  {
    "text": "discrepancies or anything like that so all told today we're pushing about",
    "start": "738240",
    "end": "743680"
  },
  {
    "text": "three terabytes of data into aws for processing and that's really just the tip of the iceberg",
    "start": "743680",
    "end": "749200"
  },
  {
    "text": "um there's a lot more that you know we hope to be collecting in the future",
    "start": "749200",
    "end": "754959"
  },
  {
    "start": "754000",
    "end": "905000"
  },
  {
    "text": "um all that being said you know it's not the number of bits and bytes it's what you do with them",
    "start": "754959",
    "end": "760160"
  },
  {
    "text": "and to roll the clock back a little bit to early 2014 and give you some context you know there was a lot that we wanted",
    "start": "760160",
    "end": "765920"
  },
  {
    "text": "to do with this data but we were starting to really run up against",
    "start": "765920",
    "end": "771519"
  },
  {
    "text": "some scalability challenges um but there were a lot of really cool opportunities out there i mean our",
    "start": "771519",
    "end": "778800"
  },
  {
    "text": "agency clients were really uh getting serious about building in-house",
    "start": "778800",
    "end": "784160"
  },
  {
    "text": "analytics practices right so they wanted to be able to extract the terabytes of data that were being",
    "start": "784160",
    "end": "789360"
  },
  {
    "text": "generated in terminal one and actually do you know data mining on top of that",
    "start": "789360",
    "end": "794480"
  },
  {
    "text": "joining up with you know maybe custom data sets that they licensed or owned",
    "start": "794480",
    "end": "799680"
  },
  {
    "text": "and produced really cool analytics we also had our own internal data science team and they were really",
    "start": "799680",
    "end": "806320"
  },
  {
    "text": "trying to you know push our optimization uh algorithm forward do new things like",
    "start": "806320",
    "end": "811920"
  },
  {
    "text": "look-alike models and stuff like that and we had a pretty ambitious product pipeline um",
    "start": "811920",
    "end": "818000"
  },
  {
    "text": "that you know we wanted to launch a lot of features that were going to require us to kind of process the data that we",
    "start": "818000",
    "end": "824880"
  },
  {
    "text": "were storing in a lot of different ways to fulfill a lot of different use cases",
    "start": "824880",
    "end": "830639"
  },
  {
    "text": "so we had a lot of work in front of us but the challenge we ran into really",
    "start": "830639",
    "end": "837600"
  },
  {
    "text": "comes down to the fact that our traditional warehouse the the data um all the data was locked in one silo",
    "start": "837600",
    "end": "845839"
  },
  {
    "text": "uh so early on in media mass history we went with netezza and it has served us really well",
    "start": "845839",
    "end": "851839"
  },
  {
    "text": "through all these years it continues to you know turn through production workloads to this day but uh on an ateza appliance",
    "start": "851839",
    "end": "860160"
  },
  {
    "text": "if you haven't heard of netizza it's a big data warehousing appliance it does only sql but uh",
    "start": "860160",
    "end": "866800"
  },
  {
    "text": "the issue with it is that the compute and the data are co-located so what ended up happening is we would have",
    "start": "866800",
    "end": "873440"
  },
  {
    "text": "you know a data scientist or a business analyst log on to the the appliance at like peak hours run",
    "start": "873440",
    "end": "879680"
  },
  {
    "text": "some kind of naive query start to slow a production job down",
    "start": "879680",
    "end": "885360"
  },
  {
    "text": "start to miss slas the pager would go off or the warehouse team they would get really frustrated um and",
    "start": "885360",
    "end": "892079"
  },
  {
    "text": "you know at the end of the day people weren't able to access the data they needed to make the kinds of decisions they wanted to",
    "start": "892079",
    "end": "897839"
  },
  {
    "text": "build the sort of products that they envisioned um so yeah kind of like a vicious cycle there",
    "start": "897839",
    "end": "906079"
  },
  {
    "start": "905000",
    "end": "954000"
  },
  {
    "text": "um so we thought about that really deeply and we kind of boiled it down to two main",
    "start": "906399",
    "end": "912320"
  },
  {
    "text": "challenges um we wanted to minimize latency for data consumers uh but we also wanted to",
    "start": "912320",
    "end": "919279"
  },
  {
    "text": "maximize access all across the company so to talk a little bit about that you know first",
    "start": "919279",
    "end": "924560"
  },
  {
    "text": "issue minimizing latency i'm going to hand it back to eddie thanks ian hi everyone again eddie fagan",
    "start": "924560",
    "end": "930240"
  },
  {
    "text": "i run our data services team at mediamath so you mentioned you know our goals are really to minimize latency",
    "start": "930240",
    "end": "936320"
  },
  {
    "text": "and maximize access so for minimizing latency again we turned the clock back to earlier this year uh adi made some",
    "start": "936320",
    "end": "943279"
  },
  {
    "text": "references to what really he called the traditional batch processing pipeline so let's take a look at where we were back around a year ago",
    "start": "943279",
    "end": "951440"
  },
  {
    "text": "and i'll tell you how we broke out of what we call the log jam okay so here's the problem we have a",
    "start": "951440",
    "end": "956800"
  },
  {
    "start": "954000",
    "end": "1128000"
  },
  {
    "text": "batch log shipping infrastructure and of course as ian mentioned this worked really well for us for many many",
    "start": "956800",
    "end": "962240"
  },
  {
    "text": "years and i guess i'll stop for a second how many of you in the audience have an infrastructure like this or have worked",
    "start": "962240",
    "end": "968160"
  },
  {
    "text": "in one like this okay a good chunk of the room so you'll be familiar with",
    "start": "968160",
    "end": "973360"
  },
  {
    "text": "with at least some of the challenges that we ran into um so i'll talk a little bit about the",
    "start": "973360",
    "end": "978560"
  },
  {
    "text": "producers briefly just to paint some context for you ian mentioned that we were going into",
    "start": "978560",
    "end": "983839"
  },
  {
    "text": "really 1.2 million ad opportunities per second",
    "start": "983839",
    "end": "989839"
  },
  {
    "text": "that's really exciting that data really the wins is what we're focused on right now we wanted to collect that data and",
    "start": "989839",
    "end": "995839"
  },
  {
    "text": "really reuse it at scale so we're rolling those into log files and shipping them to our netezza cluster",
    "start": "995839",
    "end": "1001040"
  },
  {
    "text": "we also have site events so this is really our our tracking beacons these are looking at you know users who are visiting home",
    "start": "1001040",
    "end": "1007279"
  },
  {
    "text": "pages purchasing products and so we're collecting all of that as well there's also third party data that",
    "start": "1007279",
    "end": "1012639"
  },
  {
    "text": "we're getting offline so all this information is coming into our system uh we were not really you know streaming",
    "start": "1012639",
    "end": "1019839"
  },
  {
    "text": "the data at that point we were rolling it into log files so some of the challenges there the first single consumer so if any of you again",
    "start": "1019839",
    "end": "1026160"
  },
  {
    "text": "have dealt with a pipeline like this if you're rolling all of your data into something like a warehouse",
    "start": "1026160",
    "end": "1031280"
  },
  {
    "text": "whether it's intentional or not you start to realize that you're tailoring your producers really",
    "start": "1031280",
    "end": "1037120"
  },
  {
    "text": "for that one consumer uh and so an example of how the tight coupling works out say you want to add a",
    "start": "1037120",
    "end": "1042319"
  },
  {
    "text": "field uh to your you know to your log stream your producer really wants to add a new field okay they can't go do that because if",
    "start": "1042319",
    "end": "1048720"
  },
  {
    "text": "they go do that the warehouse breaks right there's no column for that in the database so hold on",
    "start": "1048720",
    "end": "1054400"
  },
  {
    "text": "let's go to the warehouse let's do a release let's add a column to the data set okay now we can start logging the field",
    "start": "1054400",
    "end": "1060960"
  },
  {
    "text": "that that process can be painful and i've dealt with this before that what we really need to do is break away",
    "start": "1060960",
    "end": "1066559"
  },
  {
    "text": "from that tight coupling in addition this was slow moving right we mentioned that we're rolling log",
    "start": "1066559",
    "end": "1071919"
  },
  {
    "text": "files and again tailoring for the single consumer right so if you've dealt with uh you know a system like netezza you",
    "start": "1071919",
    "end": "1079200"
  },
  {
    "text": "really want to get your data into large files of data and put it in you don't want a lot of little files because",
    "start": "1079200",
    "end": "1084559"
  },
  {
    "text": "that can be a huge pain hadoop has similar restrictions on on how much data you want to put into a single batch",
    "start": "1084559",
    "end": "1090799"
  },
  {
    "text": "so what we were finding ourselves doing was okay well let's tailor our log rotation cycles on the producers",
    "start": "1090799",
    "end": "1096720"
  },
  {
    "text": "to log data to a local log file for about an hour and then ship it to this warehouse it's",
    "start": "1096720",
    "end": "1102720"
  },
  {
    "text": "okay if you're doing something like a nightly report on the other end but if you want to do any real-time analytics that just doesn't work you're talking",
    "start": "1102720",
    "end": "1108720"
  },
  {
    "text": "about hours to get your data from really the edge of your your cluster into the the warehouse and that",
    "start": "1108720",
    "end": "1114640"
  },
  {
    "text": "really didn't scale well for us we were finding that we were really doing well at gigabyte scale but",
    "start": "1114640",
    "end": "1119679"
  },
  {
    "text": "we're quickly getting a terabyte scale and now petabyte scale and beyond this wasn't really working for us so we",
    "start": "1119679",
    "end": "1125120"
  },
  {
    "text": "knew we needed to switch to more of a streaming architecture this",
    "start": "1125120",
    "end": "1130480"
  },
  {
    "start": "1128000",
    "end": "1249000"
  },
  {
    "text": "gives us a couple of advantages the first i mentioned real-time data access and we're talking about minimizing latency you really want to treat the",
    "start": "1130480",
    "end": "1137840"
  },
  {
    "text": "data as it comes in so if you're getting data streamed in you know millions of requests per second coming into your",
    "start": "1137840",
    "end": "1142880"
  },
  {
    "text": "platform the last thing you want to do is ruin the momentum of that data by logging it locally holding on to it for a while",
    "start": "1142880",
    "end": "1148960"
  },
  {
    "text": "and then only making it available downstream when you're ready to ship it you really want to get that data out to",
    "start": "1148960",
    "end": "1154000"
  },
  {
    "text": "people who need it as quickly as it comes in it's not fair to the data to do otherwise once you're actually routing",
    "start": "1154000",
    "end": "1159840"
  },
  {
    "text": "individual messages you start getting into record-by-record routing which is really powerful as an example of this",
    "start": "1159840",
    "end": "1165840"
  },
  {
    "text": "i mentioned we have impression data right we're actually showing ads online recording when users",
    "start": "1165840",
    "end": "1171600"
  },
  {
    "text": "see an ad we'll also record when a user clicks on an ad right so the click data is less than the",
    "start": "1171600",
    "end": "1177760"
  },
  {
    "text": "impression data let's say you were doing something on the consumer side so an internal consumer building let's say a click fraud a program an",
    "start": "1177760",
    "end": "1184799"
  },
  {
    "text": "application on their end they only want click data they don't want to subscribe to everything they just want to get click data so by",
    "start": "1184799",
    "end": "1191120"
  },
  {
    "text": "doing record-by-record routing you don't have to worry about if you batch everything into a log file do",
    "start": "1191120",
    "end": "1196240"
  },
  {
    "text": "people who are consuming those log files really need to search for a needle in a haystack or can they just get the data",
    "start": "1196240",
    "end": "1201600"
  },
  {
    "text": "they want as it comes in and only that and you can really start to get lightweight consumer applications once",
    "start": "1201600",
    "end": "1207679"
  },
  {
    "text": "you get down to that mode of operation it's really powerful for us in addition uh with a more published",
    "start": "1207679",
    "end": "1213039"
  },
  {
    "text": "subscribed streaming architecture that kinesis provides you get multiple consumers you don't have to worry about syncing all of your",
    "start": "1213039",
    "end": "1219200"
  },
  {
    "text": "data to a single metis cluster you can really spin up any number of applications in-house",
    "start": "1219200",
    "end": "1224559"
  },
  {
    "text": "and start using that data so if you want to have a click fraud application maybe somebody else wants to do click reporting on the same data they don't",
    "start": "1224559",
    "end": "1230960"
  },
  {
    "text": "have to talk to the warehouse get a feed ship to them they can just subscribe to the feed and get exactly what they want",
    "start": "1230960",
    "end": "1236799"
  },
  {
    "text": "as soon as it comes in and not have to worry about the complexities of log shipping and i mentioned that we were stuck at",
    "start": "1236799",
    "end": "1242960"
  },
  {
    "text": "gigabyte scale with the streaming architecture we've already seen terabyte scale and we're quickly growing beyond that so",
    "start": "1242960",
    "end": "1249039"
  },
  {
    "start": "1249000",
    "end": "1385000"
  },
  {
    "text": "how do we do it we dropped a message bus in the middle uh so we call this mediamath's firehose",
    "start": "1249039",
    "end": "1254320"
  },
  {
    "text": "and kinesis is a large component of firehose but there's a little bit more in there the left side of this diagram looks",
    "start": "1254320",
    "end": "1260400"
  },
  {
    "text": "about the same as what i showed before right it's the same data sources and i want to make sure that's very clear",
    "start": "1260400",
    "end": "1265679"
  },
  {
    "text": "we really didn't have to change that we knew what data sources we wanted as a company we had big data and this is really again",
    "start": "1265679",
    "end": "1272320"
  },
  {
    "text": "impression and click data coming from our high performance decisioning systems site events and",
    "start": "1272320",
    "end": "1277360"
  },
  {
    "text": "third-party offline data as the events come in they're now flowing into our firehose which is",
    "start": "1277360",
    "end": "1283039"
  },
  {
    "text": "you know kinesis published subscribe system and on the other side a bunch of different consumer",
    "start": "1283039",
    "end": "1288320"
  },
  {
    "text": "applications have started spinning up you have real-time analytics decision optimization and even an archival system and i wanted",
    "start": "1288320",
    "end": "1294799"
  },
  {
    "text": "to briefly touch on archiving it's i mentioned earlier you don't want to take your stream",
    "start": "1294799",
    "end": "1300240"
  },
  {
    "text": "and put into a log file and i'm showing you up here how we take a stream and we put into a log file what is he talking about there's still tons of",
    "start": "1300240",
    "end": "1306880"
  },
  {
    "text": "value any of you have done batch processing there's a lot of value to batch analytics like batch driven workflows",
    "start": "1306880",
    "end": "1312240"
  },
  {
    "text": "are extremely powerful drop data into s3 load into emr you can do a lot with that and if you're",
    "start": "1312240",
    "end": "1317919"
  },
  {
    "text": "just doing something like a nightly report which we have it's important to not have to build around a stream it's overkill",
    "start": "1317919",
    "end": "1324240"
  },
  {
    "text": "so there's definitely value in taking streaming data and archiving it and you you'll see this design pattern with a",
    "start": "1324240",
    "end": "1329919"
  },
  {
    "text": "lot of kinesis clients as they do this archiving on the side so a little bit more about fire hose",
    "start": "1329919",
    "end": "1335200"
  },
  {
    "text": "before i jump to the next one really diving into kinesis we started with apache kafka and i saw a couple of hands",
    "start": "1335200",
    "end": "1341360"
  },
  {
    "text": "when adi first jumped in we started with kafka about i think a year and a half ago we were looking at kafka",
    "start": "1341360",
    "end": "1347280"
  },
  {
    "text": "we liked it one of the challenges though was the operational pain of running an open source tool in-house",
    "start": "1347280",
    "end": "1353360"
  },
  {
    "text": "we could do it but instead of staffing a team to keep kafka running we could take those same people who are excited about solving ad tech",
    "start": "1353360",
    "end": "1360640"
  },
  {
    "text": "challenges in this digital marketing space and put them on the consumer side really writing high performance consumer",
    "start": "1360640",
    "end": "1365760"
  },
  {
    "text": "applications that really drove value for our users for our clients so that that was really powerful for us",
    "start": "1365760",
    "end": "1371679"
  },
  {
    "text": "to be able to move to kinesis and take advantage of the operational model of you know amazon's whole thing",
    "start": "1371679",
    "end": "1376880"
  },
  {
    "text": "of you can put it in there and they'll take care of it for you with kinesis we really can just provision more shards and it handles the",
    "start": "1376880",
    "end": "1382720"
  },
  {
    "text": "throughput we haven't had any issues with that to date so let's dive a little bit more into our fire hose use case",
    "start": "1382720",
    "end": "1389360"
  },
  {
    "start": "1385000",
    "end": "1659000"
  },
  {
    "text": "so we have multiple kinesis streams this is hundreds of shards and shards are the partitioning model of",
    "start": "1389360",
    "end": "1395679"
  },
  {
    "text": "kinesis if you're not familiar with it shards can handle about one megabit per second in two megabits per second out",
    "start": "1395679",
    "end": "1402080"
  },
  {
    "text": "um so hundreds of shards means hundreds of megabits per second of data flowing through our system uh it",
    "start": "1402080",
    "end": "1408159"
  },
  {
    "text": "really starts to add up to terabytes of daily data very quickly um i mentioned also that there's this",
    "start": "1408159",
    "end": "1413200"
  },
  {
    "text": "click fraud example of somebody who just wants click data what we started realizing very early was",
    "start": "1413200",
    "end": "1418720"
  },
  {
    "text": "with this message by message routing instead of having one kinesis stream so i want to be clear we don't have",
    "start": "1418720",
    "end": "1424159"
  },
  {
    "text": "this one giant kinesis stream that we pipe all of our data into and on the other side everybody goes and",
    "start": "1424159",
    "end": "1430000"
  },
  {
    "text": "subscribes to what they want from it we actually have a whole collection of kinesis streams within the media math firehose",
    "start": "1430000",
    "end": "1436240"
  },
  {
    "text": "so again on the index side we have all of our different data producers piping into their kinesis stream that's",
    "start": "1436240",
    "end": "1441679"
  },
  {
    "text": "dedicated for them so we can really provision the throughput for each data source and again",
    "start": "1441679",
    "end": "1446720"
  },
  {
    "text": "impression click data might be a totally different order of magnitude than tracking beacon data so you want to make sure you tailor your streams for",
    "start": "1446720",
    "end": "1452880"
  },
  {
    "text": "each use case in addition on the other side we had a whole bunch of different streams that were topic level",
    "start": "1452880",
    "end": "1458720"
  },
  {
    "text": "for consumers of the data and again this is as we start looking at the data in more depth maybe we want to route out",
    "start": "1458720",
    "end": "1464320"
  },
  {
    "text": "uh certain aspects of tracking we can purchase data versus added to a cart versus went to a home page you really get to start splitting",
    "start": "1464320",
    "end": "1470880"
  },
  {
    "text": "out the data at a much lower granularity and that for us",
    "start": "1470880",
    "end": "1476080"
  },
  {
    "text": "meant we needed a rather complex etl layer so the transformation layer we call it our enrichment layer within",
    "start": "1476080",
    "end": "1481200"
  },
  {
    "text": "firehose what that's doing is as messages are coming in raw we are augmenting those messages with",
    "start": "1481200",
    "end": "1487120"
  },
  {
    "text": "all sorts of interesting metadata from our system an example of this might be taking a user agent",
    "start": "1487120",
    "end": "1492720"
  },
  {
    "text": "and extracting the browser and operating system that that user agent indicates one thing we started with was okay well",
    "start": "1492720",
    "end": "1498720"
  },
  {
    "text": "maybe we should do that at the edge let's do that as we're collecting the data transform it to browser and operating system and throw it into the log file",
    "start": "1498720",
    "end": "1506480"
  },
  {
    "text": "the problem with that is you really start getting these heavy producers you have to load this giant you know",
    "start": "1506480",
    "end": "1511679"
  },
  {
    "text": "look up table or what have you for doing user agent lookup onto every single one of your data collectors that can be painful that",
    "start": "1511679",
    "end": "1517520"
  },
  {
    "text": "memory footprint you really don't want on this asynchronous data collection framework you just want to collect a message",
    "start": "1517520",
    "end": "1523039"
  },
  {
    "text": "get it into the stream and have somebody else deal with that so firearms is that somebody else we're really looking at each of these messages",
    "start": "1523039",
    "end": "1528799"
  },
  {
    "text": "as they flow through augmenting them with information like browser and operating system based on a user agent tacking those onto the stream",
    "start": "1528799",
    "end": "1535919"
  },
  {
    "text": "as it flows through and then breaking it out by topic to the people who might need it so that's been really helpful for really",
    "start": "1535919",
    "end": "1543600"
  },
  {
    "text": "reducing the the memory footprint of our data producers and not making all of our data consumers reinvent that wheel",
    "start": "1543600",
    "end": "1549600"
  },
  {
    "text": "right it's a shared service and anybody can get advantage of that once we come up with a transform all of our consumers can take advantage of that",
    "start": "1549600",
    "end": "1555840"
  },
  {
    "text": "immediately that that's been huge for us uh another thing that i wanted to highlight was with kinesis uh you'll hear that kinesis",
    "start": "1555840",
    "end": "1563279"
  },
  {
    "text": "has http put apis for putting data in uh get apis for pulling it out one of",
    "start": "1563279",
    "end": "1569760"
  },
  {
    "text": "the nice parts about really simple apis and service like kinesis when you're trying to move from a batch",
    "start": "1569760",
    "end": "1575120"
  },
  {
    "text": "workflow like we were to more of a streaming one you really want a system if you're going to drop it in the middle",
    "start": "1575120",
    "end": "1580480"
  },
  {
    "text": "that can be dropped in the middle a lot of times you'll drop a system in the middle of your architecture and it'll blow up and you'll have to",
    "start": "1580480",
    "end": "1586320"
  },
  {
    "text": "spend a year digging yourself out of that hole with kinesis we just dropped it in hooked in async",
    "start": "1586320",
    "end": "1591760"
  },
  {
    "text": "producers that put data into kinesis very simple there's sdks online for doing all of that and then on the consumer side even more",
    "start": "1591760",
    "end": "1598320"
  },
  {
    "text": "interestingly the kinesis client library something we use very heavily at mediamath uh kcl as its nickname is really",
    "start": "1598320",
    "end": "1606159"
  },
  {
    "text": "amazon's very rich now client library for pulling data off of kinesis check pointing so you can",
    "start": "1606159",
    "end": "1611840"
  },
  {
    "text": "keep track of how much data you've pulled off where you last left off that that's really helpful and it's helped our consumer application",
    "start": "1611840",
    "end": "1618799"
  },
  {
    "text": "developers get up and running very quickly without having to learn a ton of the ropes in addition we use some of the",
    "start": "1618799",
    "end": "1624159"
  },
  {
    "text": "connectors audi mentioned those connectors to different amazon services as examples of what we use we use s3 for the archival",
    "start": "1624159",
    "end": "1631360"
  },
  {
    "text": "service that i mentioned we use emr which ian will go into a little more depth and we actually use a kinesis connector",
    "start": "1631360",
    "end": "1637520"
  },
  {
    "text": "we're actually taking data off of kinesis and putting it back in through that enrichment layer so once you start getting into this mode of",
    "start": "1637520",
    "end": "1643520"
  },
  {
    "text": "operating of kinesis isn't just the stream it's technically this whole you know directed acyclic graph of",
    "start": "1643520",
    "end": "1649440"
  },
  {
    "text": "streams and i guess you could make it a cyclic graph but don't do that you really have the data flow through your pipeline you can do all sorts of",
    "start": "1649440",
    "end": "1655520"
  },
  {
    "text": "interesting enrichments and true stream processing so okay kinesis was new about this time last",
    "start": "1655520",
    "end": "1661039"
  },
  {
    "start": "1659000",
    "end": "1901000"
  },
  {
    "text": "year we were very excited to hear about it we jumped right in i'd call us a very early adopter of the service",
    "start": "1661039",
    "end": "1666880"
  },
  {
    "text": "so we had to learn some lessons any of you who have used a new amazon service the day it was announced i'm very excited about services like",
    "start": "1666880",
    "end": "1672880"
  },
  {
    "text": "lambda that there's a bit of a learning curve because the documentation isn't quite there yet the sdks and",
    "start": "1672880",
    "end": "1680000"
  },
  {
    "text": "no software has bugs upon first release but sometimes they do and so there were a bit of bugs that we had to work through the amazon team was",
    "start": "1680000",
    "end": "1686399"
  },
  {
    "text": "fantastic about support uh the forums were very active with people really good early community the fact",
    "start": "1686399",
    "end": "1692720"
  },
  {
    "text": "that there are i wanna say six different talks if not more about kinesis at re invent this year just signals this",
    "start": "1692720",
    "end": "1699440"
  },
  {
    "text": "is one of the hits from last year's re invent um so there's a bit of discovery for us but i think we've all gotten past that",
    "start": "1699440",
    "end": "1706000"
  },
  {
    "text": "another one is uh shard-based provision throughput i mentioned shards are the partitioning model",
    "start": "1706000",
    "end": "1711360"
  },
  {
    "text": "of the kinesis system if you're not familiar with sharding in general how you manage how you add them",
    "start": "1711360",
    "end": "1716880"
  },
  {
    "text": "how you remove them if you're going to use kinesis please please please check that out first understand that",
    "start": "1716880",
    "end": "1722320"
  },
  {
    "text": "make that part of how you operate your systems it's critical if you don't get that early you're going to find yourself over",
    "start": "1722320",
    "end": "1728240"
  },
  {
    "text": "provisioning maybe too much iops or just wasting money and so it's important to get a handle on that very early but it's",
    "start": "1728240",
    "end": "1735360"
  },
  {
    "text": "not too much different than auto scale groups or any of this sort of auto up auto down type functionality",
    "start": "1735360",
    "end": "1740559"
  },
  {
    "text": "that you'll find in other amazon services uh also there's there's no ability to put multiple messages in one request that",
    "start": "1740559",
    "end": "1746880"
  },
  {
    "text": "kinesis has about a 50 kilobyte put limit at this point so if you have a bunch of one kilobyte",
    "start": "1746880",
    "end": "1752320"
  },
  {
    "text": "messages you could do 50 puts or you could just do one put with a bunch of messages bundled into",
    "start": "1752320",
    "end": "1758399"
  },
  {
    "text": "one so we found that that was it was interesting for us to try that uh an advantage is you get better",
    "start": "1758399",
    "end": "1763600"
  },
  {
    "text": "throughput in this case 50x the throughput if you're bundling it all into one message on the downside i",
    "start": "1763600",
    "end": "1769200"
  },
  {
    "text": "mentioned message by message routing and processing if you're bundling up 50 messages into one",
    "start": "1769200",
    "end": "1774399"
  },
  {
    "text": "you start to lose some of that granularity and the ability to deal with individual messages as they flow through",
    "start": "1774399",
    "end": "1779760"
  },
  {
    "text": "so that's something to to just keep in mind there's also a 24-hour ttl if any of you have seen kinesis",
    "start": "1779760",
    "end": "1785760"
  },
  {
    "text": "presentations today if you're at the earlier talk there's a 24-hour time delivery ttl of data in kinesis so once you put it in",
    "start": "1785760",
    "end": "1793679"
  },
  {
    "text": "you have 24 hours to get it out for mediamath that's great we want to get that data",
    "start": "1793679",
    "end": "1799039"
  },
  {
    "text": "out within seconds as i mentioned we're trying to minimize latency if we're not pulling it out for 24 hours",
    "start": "1799039",
    "end": "1804799"
  },
  {
    "text": "we might as well do a batch shipping process there is the case of one of your consumers goes down",
    "start": "1804799",
    "end": "1810080"
  },
  {
    "text": "maybe it's down for a couple of hours gets back up and wants to catch up where they left off so you want to have that backlog so you",
    "start": "1810080",
    "end": "1816480"
  },
  {
    "text": "can go back in time and really catch up with the other stream processors with 24 hours that's enough for us if",
    "start": "1816480",
    "end": "1823919"
  },
  {
    "text": "you have other needs that maybe you want a week of data maybe you need an hour and 24 hours is overkill",
    "start": "1823919",
    "end": "1829360"
  },
  {
    "text": "uh just keep that in mind there's something important about kinesis there's also i you may see on the last",
    "start": "1829360",
    "end": "1835600"
  },
  {
    "text": "slide i threw it up i didn't go into too much depth about the instance types we're using we're focusing on the c class so the",
    "start": "1835600",
    "end": "1840720"
  },
  {
    "text": "compute instance types at mediamath uh all of our enrichment layer again is pulling messages off the",
    "start": "1840720",
    "end": "1846480"
  },
  {
    "text": "stream doing a bunch of appending to the stream and pushing it back in as it's actually pretty compute heavy",
    "start": "1846480",
    "end": "1851760"
  },
  {
    "text": "workflow for us this etl pipeline you might have more of a strict routing thing you're doing where you're just",
    "start": "1851760",
    "end": "1857600"
  },
  {
    "text": "looking at a header and throwing it into another stream or something in which case you might want more of an i o heavy instance",
    "start": "1857600",
    "end": "1863200"
  },
  {
    "text": "so really there is no one-size-fits-all ec2 instance that works for kcl for kinesis client uh just keep",
    "start": "1863200",
    "end": "1870240"
  },
  {
    "text": "that in mind it really depends on your use case like any other ec2 use case finally it's cheap right",
    "start": "1870240",
    "end": "1876960"
  },
  {
    "text": "i don't even think about it for my monthly budget for for amazon spend but note the hidden cost right if you're",
    "start": "1876960",
    "end": "1882240"
  },
  {
    "text": "trying to process terabytes of daily data through kinesis you're going to find that hundreds of shards of kinesis is nothing",
    "start": "1882240",
    "end": "1888399"
  },
  {
    "text": "but the ec2 fleet that is processing that data in real time as it streams through is very expensive and as expensive as",
    "start": "1888399",
    "end": "1895120"
  },
  {
    "text": "ec2 is compared to kinesis it's still not that bad something to keep in mind if you're going to jump in",
    "start": "1895120",
    "end": "1900480"
  },
  {
    "text": "um so i talked a bit about minimizing latency uh ian mentioned earlier in the talk",
    "start": "1900480",
    "end": "1907120"
  },
  {
    "start": "1901000",
    "end": "1933000"
  },
  {
    "text": "there are two core tenants right minimize latency maximize access so i mentioned how we went from a batch processing workflow",
    "start": "1907120",
    "end": "1914399"
  },
  {
    "text": "to much more of a streaming workflow where we were able to get data into our system and out of it within seconds as opposed to hours",
    "start": "1914399",
    "end": "1921200"
  },
  {
    "text": "uh but again it's not about the bits and bytes it's what you do with them so ian's going to tell you a bit more about what we're actually doing with this data",
    "start": "1921200",
    "end": "1927360"
  },
  {
    "text": "cool thanks yeah so i mean putting our data to work at mediamath to recap",
    "start": "1927360",
    "end": "1934559"
  },
  {
    "start": "1933000",
    "end": "2093000"
  },
  {
    "text": "30 000 foot view of our architecture today on the left-hand side we have the",
    "start": "1934559",
    "end": "1940320"
  },
  {
    "text": "bitters and pixel servers so the high performance c plus code that we run in our own data centers that generate you know the",
    "start": "1940320",
    "end": "1946480"
  },
  {
    "text": "lion's share of the log level data that's currently being streamed into",
    "start": "1946480",
    "end": "1951519"
  },
  {
    "text": "fire hose so that we can get it into aws uh in the bottom you'll see i mean we",
    "start": "1951519",
    "end": "1956799"
  },
  {
    "text": "were able to really keep uh the investment that we had made in you know things like nuteza",
    "start": "1956799",
    "end": "1962799"
  },
  {
    "text": "and our attribution process which is the process where we you know load uh transactions on websites and look back",
    "start": "1962799",
    "end": "1969679"
  },
  {
    "text": "in time to see if you know mediamath has served an ad for purposes of optimization so we",
    "start": "1969679",
    "end": "1974960"
  },
  {
    "text": "were able to keep all that stuff and um you know using aws build kind of a",
    "start": "1974960",
    "end": "1980000"
  },
  {
    "text": "parallel analytics architecture um and you know to tell you a little bit",
    "start": "1980000",
    "end": "1985919"
  },
  {
    "text": "about that stack i mean you heard about how fire hose kind of opens up a lot of real-time opportunities for us but we",
    "start": "1985919",
    "end": "1992399"
  },
  {
    "text": "also still have this issue of sharing data so we use",
    "start": "1992399",
    "end": "1997919"
  },
  {
    "text": "a large number of emr clusters we use scalding we spin up emr clusters probably 30 or",
    "start": "1997919",
    "end": "2004720"
  },
  {
    "text": "40 different clusters every day to basically take data whether it's",
    "start": "2004720",
    "end": "2010000"
  },
  {
    "text": "coming from s3 or wherever join it merge it enrich it and",
    "start": "2010000",
    "end": "2016240"
  },
  {
    "text": "partition it by client and we land all that data into s3 buckets kind",
    "start": "2016240",
    "end": "2021440"
  },
  {
    "text": "of at the edge and at first we did that just to make you know our hive queries run fast right",
    "start": "2021440",
    "end": "2026880"
  },
  {
    "text": "we wanted to have the data partitioned by client so that if we needed to you know do some analytics",
    "start": "2026880",
    "end": "2032000"
  },
  {
    "text": "on you know uh one of our larger clients data we could we could just jump right",
    "start": "2032000",
    "end": "2037519"
  },
  {
    "text": "there um but what we discovered is that if we started to create the right i am access policies we",
    "start": "2037519",
    "end": "2044880"
  },
  {
    "text": "could actually open that up to our partners and and to our clients themselves so what we do today is we we make these",
    "start": "2044880",
    "end": "2052000"
  },
  {
    "text": "i am policies we create a role for every client that wants access to their raw data",
    "start": "2052000",
    "end": "2057440"
  },
  {
    "text": "so i mentioned you know agencies building out analytics practices they need to be able to download their",
    "start": "2057440",
    "end": "2063040"
  },
  {
    "text": "you know gigabytes terabytes of data from us and we basically get a nice you know file transfer api for free",
    "start": "2063040",
    "end": "2070000"
  },
  {
    "text": "we don't have to set up any ftp transfers you know they can break in the middle of the night or whatever",
    "start": "2070000",
    "end": "2076720"
  },
  {
    "text": "it's very seamless and it allows clients to uh to basically bring whatever tools they",
    "start": "2076720",
    "end": "2082560"
  },
  {
    "text": "want as long as they're compatible with s3 so the sdk their own hadoop clusters redshift",
    "start": "2082560",
    "end": "2088720"
  },
  {
    "text": "um cubel we should talk about in a little um and it's it's really you know moving",
    "start": "2088720",
    "end": "2094800"
  },
  {
    "start": "2093000",
    "end": "2160000"
  },
  {
    "text": "to that architecture has changed how our team thinks about our role in the company we've really started to really think",
    "start": "2094800",
    "end": "2100320"
  },
  {
    "text": "about ourselves as kind of providing data sets as a service so we actually you know help the other parts of the",
    "start": "2100320",
    "end": "2106160"
  },
  {
    "text": "organization publish their most valuable asset the data and you know in under a year",
    "start": "2106160",
    "end": "2113520"
  },
  {
    "text": "we've added you know more than 30 different data sets all told that's half a trillion distinct",
    "start": "2113520",
    "end": "2119520"
  },
  {
    "text": "events it's you know this new sort of warehouse is about 200 terabytes",
    "start": "2119520",
    "end": "2125200"
  },
  {
    "text": "and you know growing every single day it's very easy for us to manage because it's just s3 it's very easy for us to",
    "start": "2125200",
    "end": "2132079"
  },
  {
    "text": "add new data sets you know we just have to set up a transfer",
    "start": "2132079",
    "end": "2138880"
  },
  {
    "text": "and it's very easy for us to enforce policies like data retention because we",
    "start": "2138960",
    "end": "2144079"
  },
  {
    "text": "can just use lifecycle rules to automatically roll off old data after 90 days",
    "start": "2144079",
    "end": "2149520"
  },
  {
    "text": "say and we're pretty excited about you know some of the event eventing that s3 added that we",
    "start": "2149520",
    "end": "2155760"
  },
  {
    "text": "heard about today um okay so all that data is in s3 and it",
    "start": "2155760",
    "end": "2161440"
  },
  {
    "start": "2160000",
    "end": "2201000"
  },
  {
    "text": "turns out that you know nowadays um there are lots of tools for actually",
    "start": "2161440",
    "end": "2166880"
  },
  {
    "text": "querying a warehouse like that you don't need to feed your data into an expensive data warehousing appliance",
    "start": "2166880",
    "end": "2172720"
  },
  {
    "text": "to actually get you know ad hoc analytics so we're pretty happy with this partner we have cubel they provide a nice",
    "start": "2172720",
    "end": "2179359"
  },
  {
    "text": "you know ui um and it's changed the workflow of our analysts and data",
    "start": "2179359",
    "end": "2184400"
  },
  {
    "text": "scientists where before they might spend you know many many hours trying to set up meetings between engineering teams",
    "start": "2184400",
    "end": "2190640"
  },
  {
    "text": "to get prioritized to get data flowing to their you know staging systems so they can actually do their job um now they're able to just",
    "start": "2190640",
    "end": "2198400"
  },
  {
    "text": "kind of log into a console and go to town so they're very pleased with this setup",
    "start": "2198400",
    "end": "2204640"
  },
  {
    "text": "as you can see and you know from our standpoint what makes it very easy to administrate is that we",
    "start": "2204640",
    "end": "2210880"
  },
  {
    "text": "don't have to transfer data anywhere right all these tools just point directly to our s3 buckets and everything is you",
    "start": "2210880",
    "end": "2218160"
  },
  {
    "text": "know secured using im access control",
    "start": "2218160",
    "end": "2223359"
  },
  {
    "text": "so moving to this model has kind of you know got data into uh some pretty creative hands right so we",
    "start": "2223359",
    "end": "2230240"
  },
  {
    "start": "2225000",
    "end": "2263000"
  },
  {
    "text": "just started publishing the output of our optimization engine uh the model files um",
    "start": "2230240",
    "end": "2237359"
  },
  {
    "text": "as a data set and you know some product managers took it they realized that they could whip together a pretty cool visualization on",
    "start": "2237359",
    "end": "2244000"
  },
  {
    "text": "this and in no time it became one of the most popular apps on our platform you know so advertisers can log in and",
    "start": "2244000",
    "end": "2250720"
  },
  {
    "text": "really see what unique combination of variables and values are popping for their campaign",
    "start": "2250720",
    "end": "2256160"
  },
  {
    "text": "our driving performance and all of that is discovered through machine learning which is pretty cool",
    "start": "2256160",
    "end": "2262480"
  },
  {
    "text": "um having this you know 200 terabyte warehouse now we're also able to",
    "start": "2262480",
    "end": "2267920"
  },
  {
    "start": "2263000",
    "end": "2304000"
  },
  {
    "text": "take a broader sort of macro economic look at the ad tech landscape and see what sort of trends there are in",
    "start": "2267920",
    "end": "2275200"
  },
  {
    "text": "cpm prices whether that's by country or publisher or exchange so we had a little hackathon and you",
    "start": "2275200",
    "end": "2281599"
  },
  {
    "text": "know we've we've always had this idea that it would be so cool if we could make a little you know nasdaq stock index",
    "start": "2281599",
    "end": "2287119"
  },
  {
    "text": "ticker for uh for cpm prices so um we put that together and you know",
    "start": "2287119",
    "end": "2293839"
  },
  {
    "text": "it's just another example of you know if you're able to really focus on providing data as a service",
    "start": "2293839",
    "end": "2299760"
  },
  {
    "text": "you get some really cool things out of out of the rest of your team",
    "start": "2299760",
    "end": "2304480"
  },
  {
    "start": "2304000",
    "end": "2366000"
  },
  {
    "text": "all right so um just to kind of re you know wrap up here",
    "start": "2304960",
    "end": "2310320"
  },
  {
    "text": "uh keys to success for us um kinesis as the message bus has really",
    "start": "2310320",
    "end": "2315520"
  },
  {
    "text": "been sort of you know unlocked a lot of new potential for us right it you know as eddie said we",
    "start": "2315520",
    "end": "2321760"
  },
  {
    "text": "plopped it right in the middle of our system it wasn't disruptive it was really you know additive to the rest of our",
    "start": "2321760",
    "end": "2326800"
  },
  {
    "text": "platform gave us a lot of new capabilities uh instead of you know continuing to uh",
    "start": "2326800",
    "end": "2334000"
  },
  {
    "text": "kind of struggle with a warehousing appliance where the data and compute were co-located we really embraced",
    "start": "2334000",
    "end": "2341040"
  },
  {
    "text": "kind of having that decoupled having our data stored in s3 and you know having a",
    "start": "2341040",
    "end": "2347440"
  },
  {
    "text": "bring your own compute model that's really allowed us to scale that warehouse and offer access to that data",
    "start": "2347440",
    "end": "2353359"
  },
  {
    "text": "to a much larger portion of the company and putting all this together i mean has",
    "start": "2353359",
    "end": "2359359"
  },
  {
    "text": "taken the better part of a year but uh you know we've been very pleased uh with the results so far",
    "start": "2359359",
    "end": "2366079"
  },
  {
    "start": "2366000",
    "end": "2404000"
  },
  {
    "text": "any last words eddie sure uh so if any you know anyone check us out any further check us out on",
    "start": "2366079",
    "end": "2372599"
  },
  {
    "text": "thedevblog.edumath.com recently launched very excited about it um in addition you can contact us on twitter",
    "start": "2372599",
    "end": "2378880"
  },
  {
    "text": "and please please please send us feedback on the feedback forums it's very helpful",
    "start": "2378880",
    "end": "2383920"
  },
  {
    "text": "for us also if streaming data challenges and you know awesome data access challenges",
    "start": "2383920",
    "end": "2389440"
  },
  {
    "text": "excite you please join us we'd love to have you we're actively hiring uh we're all over the world and we love",
    "start": "2389440",
    "end": "2395440"
  },
  {
    "text": "it thank you so much again i know it's late i know you all want to go drink go drink have fun enjoy the party",
    "start": "2395440",
    "end": "2402799"
  },
  {
    "text": "tonight",
    "start": "2403560",
    "end": "2406560"
  }
]
[
  {
    "text": "hello and welcome to the amazon web services partner webinar series our topic today will feature how to move",
    "start": "80",
    "end": "6400"
  },
  {
    "text": "your business intelligence and data warehousing to aws i'm your host sheri sullivan i'm with",
    "start": "6400",
    "end": "12639"
  },
  {
    "text": "the partner marketing team here in seattle and i'd like to start with just a couple of housekeeping items",
    "start": "12639",
    "end": "19119"
  },
  {
    "text": "i'd like to remind folks that your lines have been muted today but we invite you at any time to submit questions using",
    "start": "19119",
    "end": "26800"
  },
  {
    "text": "the q a tool in your browser we'd also like to let you know that we will make this presentation available on demand",
    "start": "26800",
    "end": "33920"
  },
  {
    "text": "and you'll receive a link post event and we do make our content available on",
    "start": "33920",
    "end": "39280"
  },
  {
    "text": "aws youtube channel as well as slideshare so i'm very pleased today to",
    "start": "39280",
    "end": "45360"
  },
  {
    "text": "be joined by two of our aws technology partners um we'll begin",
    "start": "45360",
    "end": "50800"
  },
  {
    "text": "with an overview from itamar ankaran who is the vice",
    "start": "50800",
    "end": "55840"
  },
  {
    "text": "president and business development and corporate strategy at attunity along with ben connors who's the",
    "start": "55840",
    "end": "62320"
  },
  {
    "text": "worldwide head of",
    "start": "62320",
    "end": "65198"
  },
  {
    "text": "sciences at jaspersoft uh both are aws technology partners and we'll be joined",
    "start": "71520",
    "end": "77759"
  },
  {
    "text": "by our own raul pasak who is our senior product manager with amazon redshift",
    "start": "77759",
    "end": "83280"
  },
  {
    "text": "here at aws we'll begin with an overview of the redshift architecture we'll move into",
    "start": "83280",
    "end": "90560"
  },
  {
    "text": "how to move your data into the cloud with a tunity cloud beam and we'll then jump into an overview of",
    "start": "90560",
    "end": "98479"
  },
  {
    "text": "business intelligence to apps with jaspersoft and we'll close",
    "start": "98479",
    "end": "103600"
  },
  {
    "text": "with the moderated q a so with that i'd like to introduce our speakers",
    "start": "103600",
    "end": "108799"
  },
  {
    "text": "we have itamar ben and raul take it away raul",
    "start": "108799",
    "end": "114960"
  },
  {
    "text": "thanks sherry and uh thank you everybody for joining us so today we're going to talk about",
    "start": "114960",
    "end": "120640"
  },
  {
    "text": "moving your data warehousing and business intelligence to the cloud and as you can see we've got two of our",
    "start": "120640",
    "end": "126719"
  },
  {
    "text": "partners attunity and jaspersoft here and you'll hear from them about a how to move your data from on",
    "start": "126719",
    "end": "132400"
  },
  {
    "text": "premise to aws and to redshift and keep it in sync i'm going to talk first about redshift's",
    "start": "132400",
    "end": "138640"
  },
  {
    "text": "architecture how we do some of the things we do in terms of performance and then you'll hear from ben at",
    "start": "138640",
    "end": "144959"
  },
  {
    "text": "jaspersoft about how to really quickly and cost effectively deploy",
    "start": "144959",
    "end": "150319"
  },
  {
    "text": "bi into the cloud on top of your data so let's dive into redshift to start",
    "start": "150319",
    "end": "156319"
  },
  {
    "text": "with and just to provide some context i wanted to talk to you a little bit about how redshift fits into the overall",
    "start": "156319",
    "end": "162160"
  },
  {
    "text": "picture of database services at aws and so what we've really tried to do is to provide a fairly complete suite of",
    "start": "162160",
    "end": "169519"
  },
  {
    "text": "managed database services so we have amazon rds which is our relational database service you can deploy",
    "start": "169519",
    "end": "175760"
  },
  {
    "text": "mysql sql server or oracle database with just a few clicks and it's really designed for transactional workloads",
    "start": "175760",
    "end": "182720"
  },
  {
    "text": "elastic cache which is a memcache d compatible in-memory caching service",
    "start": "182720",
    "end": "188080"
  },
  {
    "text": "dynamodb which is our nosql very low latency close to infinitely scalable",
    "start": "188080",
    "end": "194879"
  },
  {
    "text": "non-relational data database service and then redshift our newest service",
    "start": "194879",
    "end": "199920"
  },
  {
    "text": "which is petabyte scale data warehousing in the cloud and with redshift what we set out to do",
    "start": "199920",
    "end": "207040"
  },
  {
    "text": "was to design and build a data warehouse service that was 10 times faster than traditional",
    "start": "207040",
    "end": "213680"
  },
  {
    "text": "road-based stores for analytic queries at least intense the price of traditional data warehousing solutions",
    "start": "213680",
    "end": "220159"
  },
  {
    "text": "and something that was really easy to use and the reasons for this was really that our customers asked us",
    "start": "220159",
    "end": "226799"
  },
  {
    "text": "to build this and that's how most of the things that we do at aws come into being in response to customer needs and so",
    "start": "226799",
    "end": "233599"
  },
  {
    "text": "customers had been looking for data warehousing that was easy to provision that didn't require",
    "start": "233599",
    "end": "238959"
  },
  {
    "text": "hundreds of thousands of dollars or more in upfront payments and that could match their requirements of their data volumes",
    "start": "238959",
    "end": "244720"
  },
  {
    "text": "grew and they also wanted something that was fast cheap and easy to use",
    "start": "244720",
    "end": "249840"
  },
  {
    "text": "and finally something that was compatible with their existing tool sets and that means sql",
    "start": "249840",
    "end": "256720"
  },
  {
    "text": "and so what we've seen with redshift is really an expansion in the kinds of customers that can make use of",
    "start": "257199",
    "end": "263440"
  },
  {
    "text": "relational data warehousing you've got traditional enterprise use cases and for them it's been about",
    "start": "263440",
    "end": "269759"
  },
  {
    "text": "expanding existing data warehouses or thinking about migration and it's also about the ability to",
    "start": "269759",
    "end": "275199"
  },
  {
    "text": "respond faster to the needs of the business so for example you can deploy redshift in 15 minutes",
    "start": "275199",
    "end": "281680"
  },
  {
    "text": "rather than having to wait weeks for purchase orders and dealing with things in terms of rackspace and data centers",
    "start": "281680",
    "end": "287520"
  },
  {
    "text": "and all of that we've also seen a new cluster companies that have been using other solutions for",
    "start": "287520",
    "end": "293120"
  },
  {
    "text": "big data analytics start to benefit from the ability to use a relational scalable data warehouse",
    "start": "293120",
    "end": "300000"
  },
  {
    "text": "and here it's really about accessing business data and big data using traditional sql",
    "start": "300000",
    "end": "306400"
  },
  {
    "text": "and making more data available for analysis cost effectively and then another emerging",
    "start": "306400",
    "end": "312720"
  },
  {
    "text": "class of application we've seen is software as a service companies that are providing embedded analytics",
    "start": "312720",
    "end": "318080"
  },
  {
    "text": "to their own customers and using redshift to lower the cost of providing that analytics and for them it's really",
    "start": "318080",
    "end": "324320"
  },
  {
    "text": "been about lowering cost having the ability to scale and of course delivering performance",
    "start": "324320",
    "end": "331039"
  },
  {
    "text": "and redshift we launched in mid-feb this year and it's been the fastest growing",
    "start": "331039",
    "end": "336720"
  },
  {
    "text": "service in aws history we've announced well over a thousand customers adding over 100 a week and",
    "start": "336720",
    "end": "343600"
  },
  {
    "text": "that was about 10 weeks after launch so the pace of growth has been very fast",
    "start": "343600",
    "end": "348880"
  },
  {
    "text": "and we're focused really on making progress around security rolling out worldwide",
    "start": "348880",
    "end": "354479"
  },
  {
    "text": "and continuing to innovate in line with what we're hearing from our customers and in terms of customer use cases",
    "start": "354479",
    "end": "361520"
  },
  {
    "text": "just wanted to share a few with you so airbnb has been using redshift and they've seen",
    "start": "361520",
    "end": "367840"
  },
  {
    "text": "pretty significant reductions in query times as well as cost reductions according media is a real-time ad",
    "start": "367840",
    "end": "374080"
  },
  {
    "text": "bidding platform and their business is about responding to online advertising auction slots within hundreds of",
    "start": "374080",
    "end": "380639"
  },
  {
    "text": "milliseconds and they're using redshift to get faster iteration on their analytic models so",
    "start": "380639",
    "end": "386080"
  },
  {
    "text": "they can place more accurate bids and with nokia it's been using redshifted lower costs and improve",
    "start": "386080",
    "end": "393440"
  },
  {
    "text": "query times and again you'll see the steam come up over and over again around performance price and ease of use",
    "start": "393440",
    "end": "400960"
  },
  {
    "text": "which is great to see so bitly for example tracks billions of clicks every month",
    "start": "400960",
    "end": "406880"
  },
  {
    "text": "and they've been able to use redshift to get answers to queries that span months of data in just a few seconds",
    "start": "406880",
    "end": "414240"
  },
  {
    "text": "uh has offers is a mobile marketing platform that provides big brands with the ability to drive mobile applications",
    "start": "414880",
    "end": "421280"
  },
  {
    "text": "and mobile ad performance and for them it's been really about performance and price relative to their current",
    "start": "421280",
    "end": "427199"
  },
  {
    "text": "solutions for analytics and infor on the south side infor is the",
    "start": "427199",
    "end": "433039"
  },
  {
    "text": "world's third largest erp vendor and they are deploying redshift as the data",
    "start": "433039",
    "end": "438800"
  },
  {
    "text": "warehousing engine behind an analytics platform in the cloud that they're doing for inter enterprise analytics called skyvault",
    "start": "438800",
    "end": "445120"
  },
  {
    "text": "and so the real point here is a real wide diversity of use cases but all centered around those core benefits",
    "start": "445120",
    "end": "451840"
  },
  {
    "text": "of performance price and ease of use and from an architecture standpoint",
    "start": "451840",
    "end": "458479"
  },
  {
    "text": "redshift is designed to be run as a clustered system although we do make available a single node variant",
    "start": "458479",
    "end": "464560"
  },
  {
    "text": "as you can see the nodes are connected using a 10 gigabit ethernet non-blocking",
    "start": "464560",
    "end": "470080"
  },
  {
    "text": "network as part of our high performance computing environment at aws there's a leader node which is your sql",
    "start": "470080",
    "end": "476160"
  },
  {
    "text": "endpoint that you can connect to using jdbc and odbc and postgres drivers",
    "start": "476160",
    "end": "481520"
  },
  {
    "text": "and the leader node is responsible for distributing queries across the compute",
    "start": "481520",
    "end": "486879"
  },
  {
    "text": "nodes and then executing those in parallel the compute nodes is where your data is actually stored",
    "start": "486879",
    "end": "492560"
  },
  {
    "text": "and we use local storage for performance but we also have invested a lot of effort",
    "start": "492560",
    "end": "498240"
  },
  {
    "text": "in automating backups and replication so giving you all the benefits of local performance",
    "start": "498240",
    "end": "504319"
  },
  {
    "text": "as well as the the benefits of managed storage security is another area that we've paid",
    "start": "504319",
    "end": "510319"
  },
  {
    "text": "a lot of attention to with redshift and um it supports ssl for encrypting data",
    "start": "510319",
    "end": "516000"
  },
  {
    "text": "on the wire hardware accelerated aes 256 for encrypting data that's stored at rest",
    "start": "516000",
    "end": "522640"
  },
  {
    "text": "and this is every block that's written to disk so both data at rest as well as any",
    "start": "522640",
    "end": "528000"
  },
  {
    "text": "temporary spillovers from queries and backups all encrypted and it runs uh it can run inside of",
    "start": "528000",
    "end": "535360"
  },
  {
    "text": "amazon's virtual private cloud or vpc and that's a logically isolated section of the cloud in which",
    "start": "535360",
    "end": "541440"
  },
  {
    "text": "used customers can control um routing access networking and can connect it using vpn to your existing",
    "start": "541440",
    "end": "548640"
  },
  {
    "text": "systems the other element of redshift is that it's a managed service and so it's",
    "start": "548640",
    "end": "553839"
  },
  {
    "text": "straightforward to provision we do continuous monitoring of all components in the system we automatically replicate",
    "start": "553839",
    "end": "560320"
  },
  {
    "text": "data and we continuously backup data to s3 as well and so the goal is really to give you a",
    "start": "560320",
    "end": "566080"
  },
  {
    "text": "high performance system that's easy to deploy and operate and also to scale",
    "start": "566080",
    "end": "572480"
  },
  {
    "text": "and from uh from a hardware perspective redshift runs on hardware that's optimized for data processing and so the",
    "start": "573120",
    "end": "579920"
  },
  {
    "text": "the larger node size in redshift is the high storage instance which is",
    "start": "579920",
    "end": "585120"
  },
  {
    "text": "available on ec2 the 8 extra large and this is a beefy box 128 gigs of ram",
    "start": "585120",
    "end": "591200"
  },
  {
    "text": "16 terabytes of compressed user data redshift automatically compresses data when you load it",
    "start": "591200",
    "end": "597120"
  },
  {
    "text": "and our customers typically see from 4 to 8x savings when coming from other systems",
    "start": "597120",
    "end": "602720"
  },
  {
    "text": "naturally some columns will compress much better than others and so that's that also improves",
    "start": "602720",
    "end": "608800"
  },
  {
    "text": "performance and lowers cost and unique to redshift we make available a smaller node size which is 1 8 of the",
    "start": "608800",
    "end": "616000"
  },
  {
    "text": "8xl and that allows you to essentially scale up your cluster in increments that",
    "start": "616000",
    "end": "621200"
  },
  {
    "text": "make sense for your business and data volumes and so with redshift you can start with",
    "start": "621200",
    "end": "626640"
  },
  {
    "text": "a single two terabyte node which is the smaller node size scale up all the way to a hundred eight",
    "start": "626640",
    "end": "632560"
  },
  {
    "text": "extra large nodes for 1.6 petabytes of compressed data",
    "start": "632560",
    "end": "637680"
  },
  {
    "text": "and from a pricing perspective we've tried hard to make redshift extremely cost effective solution the",
    "start": "638160",
    "end": "644399"
  },
  {
    "text": "goal here is to allow you to analyze all the data that you want to analyze not just all the data that you can afford to analyze",
    "start": "644399",
    "end": "651440"
  },
  {
    "text": "and so with redshift and you can buy it on demand the pricing here is for a single xl node the eight extra large is",
    "start": "651440",
    "end": "658480"
  },
  {
    "text": "eight times that but the cost per terabyte remains the same because they have eight times as much storage",
    "start": "658480",
    "end": "664800"
  },
  {
    "text": "so you can see if you're being by the hour it will cost you less than a dollar an hour for a two terabyte data warehouse",
    "start": "664800",
    "end": "670959"
  },
  {
    "text": "that's about thirty seven hundred dollars per terabyte per year a one year reservation",
    "start": "670959",
    "end": "676000"
  },
  {
    "text": "gets you a 40 discount and a three year reservation gets you over 70 percent discount bringing the pricing down to",
    "start": "676000",
    "end": "682959"
  },
  {
    "text": "under a thousand dollars per terabyte per year which is well under uh attempt the cost of traditional",
    "start": "682959",
    "end": "688640"
  },
  {
    "text": "systems and we've really designed redshift to be",
    "start": "688640",
    "end": "694800"
  },
  {
    "text": "the central data warehouse data is generated in a bunch of different places and ultimately our goal with redshift is",
    "start": "694800",
    "end": "700880"
  },
  {
    "text": "to provide you with an easy to use central high performance repository where you can then run analytics",
    "start": "700880",
    "end": "706640"
  },
  {
    "text": "across all of the elements of your business and that's why i'm really excited now to",
    "start": "706640",
    "end": "711839"
  },
  {
    "text": "talk about and introduce itamar from matunity and ben from jaspersoft to really talk about one how",
    "start": "711839",
    "end": "719279"
  },
  {
    "text": "to move data into redshift in a very straightforward way and keep it in sync and then how to deploy analytics on top",
    "start": "719279",
    "end": "725519"
  },
  {
    "text": "of it so with that i will turn over to itamar",
    "start": "725519",
    "end": "730760"
  },
  {
    "text": "thank you very much rahul and thanks everyone for joining us today",
    "start": "731279",
    "end": "736639"
  },
  {
    "text": "attunity is an aw is an amazon web services technology partner and",
    "start": "736639",
    "end": "742560"
  },
  {
    "text": "we've been excited working with them for uh well over a year now on helping customers adopt the cloud and facilitate",
    "start": "742560",
    "end": "750240"
  },
  {
    "text": "the way in which they move the data to the cloud so they can benefit from its cost efficiencies uh in simply put we",
    "start": "750240",
    "end": "757040"
  },
  {
    "text": "help to move the data that moves our customers business uh in the cloud and we have created a",
    "start": "757040",
    "end": "763040"
  },
  {
    "text": "cloud platform called the trinity cloud beam that is a data movement a service that runs on top",
    "start": "763040",
    "end": "770160"
  },
  {
    "text": "of amazon web services and facilitate different processes of moving moving data in and across amazon web services",
    "start": "770160",
    "end": "777120"
  },
  {
    "text": "regions when it comes to big data analytics and data warehousing it is a core area of",
    "start": "777120",
    "end": "783519"
  },
  {
    "text": "opportunity we traditionally worked for many years with many organizations uh large enterprises to small",
    "start": "783519",
    "end": "790240"
  },
  {
    "text": "organizations that need to make information available for analytics and we help them move data from various uh",
    "start": "790240",
    "end": "796800"
  },
  {
    "text": "environments whether it's erp systems homegrown applications uh with the different databases or other",
    "start": "796800",
    "end": "804000"
  },
  {
    "text": "data repositories into the data warehouse environment so with the trinity we help customers to move any",
    "start": "804000",
    "end": "809519"
  },
  {
    "text": "data at any time anywhere primarily for analytics such as putting it into a data warehouse another server for analytics",
    "start": "809519",
    "end": "816560"
  },
  {
    "text": "it could be rds for example amazon rds into hadoop environments like emr or of",
    "start": "816560",
    "end": "822000"
  },
  {
    "text": "course into data warehouses such as amazon redshift and our focus is on",
    "start": "822000",
    "end": "827279"
  },
  {
    "text": "making the process highly perform with high performance load total cost and enable very quick",
    "start": "827279",
    "end": "834079"
  },
  {
    "text": "time to value when looking at loading data into amazon",
    "start": "834079",
    "end": "839440"
  },
  {
    "text": "redshift we focus on the following common use cases that we see with customers well first of",
    "start": "839440",
    "end": "845920"
  },
  {
    "text": "all is full uploads so for customers who want to look at redshift as an alternative to an existing data",
    "start": "845920",
    "end": "852320"
  },
  {
    "text": "warehouse or as a way to get into data warehousing they want to test it out or they may need to use it on an",
    "start": "852320",
    "end": "857600"
  },
  {
    "text": "intermediate basis once a quarter once a month so with attunity they can facilitate full uploads you may need to",
    "start": "857600",
    "end": "865120"
  },
  {
    "text": "do an initial load of the data to set it up or you need to periodically load an entire data set for trial or ad",
    "start": "865120",
    "end": "871680"
  },
  {
    "text": "hoc use or you may want to migrate data where you move a large amount of data from your existing data warehouse into",
    "start": "871680",
    "end": "877680"
  },
  {
    "text": "redshift a very different use case is for customers who want to use the dataworks on an ongoing basis",
    "start": "877680",
    "end": "884480"
  },
  {
    "text": "i need to keep feeding it with data on an incremental sometimes continuous basis so basically keep it in sync with",
    "start": "884480",
    "end": "891279"
  },
  {
    "text": "their operational data or the databases that they have on premise they're using incremental technology enable you to",
    "start": "891279",
    "end": "898160"
  },
  {
    "text": "provide efficiency in loading the data and by moving data continuously you can enable low latency and of course the",
    "start": "898160",
    "end": "903839"
  },
  {
    "text": "data may come from on-premise data centers or it may come from another aws region",
    "start": "903839",
    "end": "910160"
  },
  {
    "text": "with that said one common issue that many customers talk about as industry analysts report is that moving the data",
    "start": "910160",
    "end": "916639"
  },
  {
    "text": "into the data worlds tends to be the most common issue and most customers are not uh happy with the way that this",
    "start": "916639",
    "end": "922560"
  },
  {
    "text": "works not satisfied with the way in which the loading process works when you look at loading data there are",
    "start": "922560",
    "end": "929279"
  },
  {
    "text": "few reasons we want to point out and for customers who are looking at adopting redshift they probably are going to be",
    "start": "929279",
    "end": "936079"
  },
  {
    "text": "thinking about these sort of pains and issues and with solutions such as attunity you can alleviate them and you",
    "start": "936079",
    "end": "942079"
  },
  {
    "text": "can avoid running into these sort of uh pains and quickly get your data into",
    "start": "942079",
    "end": "947519"
  },
  {
    "text": "redshift first of all is the complexity the different complexity involved in integrating different types of data",
    "start": "947519",
    "end": "953680"
  },
  {
    "text": "sources the different data types how you move the data how you move it efficiently",
    "start": "953680",
    "end": "958880"
  },
  {
    "text": "how you integrate different parts of the solution so there's a lot of complexity involved potentially in moving data over",
    "start": "958880",
    "end": "965120"
  },
  {
    "text": "wide area network between different data centers and two different data systems the other challenge is it can take too",
    "start": "965120",
    "end": "971040"
  },
  {
    "text": "long if you want to quickly get going you want to get value quickly using traditional technologies special",
    "start": "971040",
    "end": "977360"
  },
  {
    "text": "tools may take you many months if you opt to develop a solution it may take you many months to put it in place",
    "start": "977360",
    "end": "983440"
  },
  {
    "text": "with the solution out of the box you can take that issue away costs can be involved with",
    "start": "983440",
    "end": "990560"
  },
  {
    "text": "building an entire solution that can take you a little time again if you look at traditional data we're saying this is",
    "start": "990560",
    "end": "995759"
  },
  {
    "text": "the area where traditional data integration tools can cost a lot including the labor involved with",
    "start": "995759",
    "end": "1001600"
  },
  {
    "text": "putting them in place yet another issue is how to move data to enable low latency data warehousing how",
    "start": "1001600",
    "end": "1007519"
  },
  {
    "text": "to enable uh real-time views of data while the data is keeps getting updated in the",
    "start": "1007519",
    "end": "1013279"
  },
  {
    "text": "data warehouse that is a challenge typically to create because of the inherent complexity and they need to do",
    "start": "1013279",
    "end": "1018480"
  },
  {
    "text": "it with a very minimal impact on source database systems and finally some of the pain",
    "start": "1018480",
    "end": "1024000"
  },
  {
    "text": "points customers run into are the lack of developer resources that can put all of this in place",
    "start": "1024000",
    "end": "1030400"
  },
  {
    "text": "attunity brought to market a solution that we refer to as a click to load solution that provides a very easy way",
    "start": "1030400",
    "end": "1036558"
  },
  {
    "text": "to get your data into amazon redshift addressing all these issues enabling you to take data and turn it into value",
    "start": "1036559",
    "end": "1043280"
  },
  {
    "text": "inside amazon redshift so with the trinity of an optimized and affordable solution that is easy to put in place it",
    "start": "1043280",
    "end": "1049600"
  },
  {
    "text": "requires no coding and no complexity it is an administrator environment that sets up an automated solution end-to-end",
    "start": "1049600",
    "end": "1057520"
  },
  {
    "text": "uh it is fast and high-performance integration which we'll discuss in more detail and it comes with support for",
    "start": "1057520",
    "end": "1063760"
  },
  {
    "text": "incremental and real-time loading of data on top of the initial load so it can offer you significant lower cost and",
    "start": "1063760",
    "end": "1070640"
  },
  {
    "text": "faster time to value for starting to leverage and benefit from redshift",
    "start": "1070640",
    "end": "1076880"
  },
  {
    "text": "one example of such a customer is domain holdings they're a domain brokerage",
    "start": "1076960",
    "end": "1082640"
  },
  {
    "text": "vendor that enables customers to monetize the use of domains and they use",
    "start": "1082640",
    "end": "1088160"
  },
  {
    "text": "redshift for for analysis to analyze and provide data there to the customers for analysis and how they monetize",
    "start": "1088160",
    "end": "1095679"
  },
  {
    "text": "information and with the opportunities you can see in the quote here they're able to load data within minutes",
    "start": "1095679",
    "end": "1102960"
  },
  {
    "text": "and make it available in redshift and instead of spending months on development work and",
    "start": "1102960",
    "end": "1108320"
  },
  {
    "text": "the need to have resources that can support it they could instantly get everything done with the trinity uh with",
    "start": "1108320",
    "end": "1113840"
  },
  {
    "text": "our software as a service based solution so at the high level attunity cloud beam",
    "start": "1113840",
    "end": "1120240"
  },
  {
    "text": "for amazon redshift provides an optimized and automated solution end-to-end following data into a",
    "start": "1120240",
    "end": "1126720"
  },
  {
    "text": "redshift it supports many data sources that can run on-premise or otherwise in",
    "start": "1126720",
    "end": "1132080"
  },
  {
    "text": "across amazon ec2 including oracle sql server db2 whether it's on",
    "start": "1132080",
    "end": "1138640"
  },
  {
    "text": "linux unix windows i series or the mainframe sybase as well as other type",
    "start": "1138640",
    "end": "1144400"
  },
  {
    "text": "of data sources so we can enable you to move a lot of types of data from different databases",
    "start": "1144400",
    "end": "1149840"
  },
  {
    "text": "and bring them into amazon redshift a few highlights about the solution so",
    "start": "1149840",
    "end": "1155600"
  },
  {
    "text": "first of all it offers end-to-end loading solution for redshift which means that we automate",
    "start": "1155600",
    "end": "1161679"
  },
  {
    "text": "the full process from automatically generating a schema for the data inside",
    "start": "1161679",
    "end": "1166720"
  },
  {
    "text": "redshift to taking a snapshot of your data which can be very large and loading that very efficiently into redshift and",
    "start": "1166720",
    "end": "1173200"
  },
  {
    "text": "then automatically moving into capturing changes using log-based cdc change data capture technology",
    "start": "1173200",
    "end": "1180240"
  },
  {
    "text": "that identifies only the changes in your database and moving only the delta into redshift we offer click to load in zero",
    "start": "1180240",
    "end": "1187360"
  },
  {
    "text": "footprint architectures which means less work to deploy and to build solutions and we put a lot of optimizations for",
    "start": "1187360",
    "end": "1193440"
  },
  {
    "text": "loading the data into redshift finally we offer monitoring and control so you can validate and ensure that all",
    "start": "1193440",
    "end": "1199280"
  },
  {
    "text": "everything works as needed and it can be alerted if anything needs to be taken care of",
    "start": "1199280",
    "end": "1207280"
  },
  {
    "text": "our solution for loading data into redshift provides a lot of optimizations the whole idea is to make the process of",
    "start": "1207280",
    "end": "1213840"
  },
  {
    "text": "loading data as efficient as possible redshift reads data the fastest from s3",
    "start": "1213840",
    "end": "1219120"
  },
  {
    "text": "and the trinity combines data database integration technologies and high-speed",
    "start": "1219120",
    "end": "1224320"
  },
  {
    "text": "file transfer with one optimization for loading the data into s3 so with",
    "start": "1224320",
    "end": "1229840"
  },
  {
    "text": "attunity we have a with a solution that is software you install on-premise called the tunity replicate a 20 replicate",
    "start": "1229840",
    "end": "1236480"
  },
  {
    "text": "automatically gets data out of your database puts it into specialized fast file structures that then get uploaded",
    "start": "1236480",
    "end": "1243280"
  },
  {
    "text": "into s3 using affinity cloud beam and it's one acceleration technologies for",
    "start": "1243280",
    "end": "1248720"
  },
  {
    "text": "moving data extremely fast and reliably into and securely into uh s into s3",
    "start": "1248720",
    "end": "1254240"
  },
  {
    "text": "and then we instruct redshift to read the data from s3 and validate that the data gets",
    "start": "1254240",
    "end": "1260000"
  },
  {
    "text": "there we follow a similar process when moving only incremental changes or cdc",
    "start": "1260000",
    "end": "1265679"
  },
  {
    "text": "where the cdc changes get moved through a file and actually gets loaded into registe and once all the changes are",
    "start": "1265679",
    "end": "1272080"
  },
  {
    "text": "inside redshift attunity merges that data inside redshift so what happens",
    "start": "1272080",
    "end": "1277200"
  },
  {
    "text": "with the eternity solution is that instead of working through say an sql odbc",
    "start": "1277200",
    "end": "1283120"
  },
  {
    "text": "type of a technology directly to redshift the data flow is highly optimized by moving the data into",
    "start": "1283120",
    "end": "1289919"
  },
  {
    "text": "redshift through high performance data movement based on authority cloud beam and then copy commands from s3 into redshift or",
    "start": "1289919",
    "end": "1297360"
  },
  {
    "text": "merging the data inside redshift and the only communication between the on-premise and redshift is actually an",
    "start": "1297360",
    "end": "1303760"
  },
  {
    "text": "instruction channel that tells redshift when to load the data in and validates that all the",
    "start": "1303760",
    "end": "1309600"
  },
  {
    "text": "data has indeed arrived so this sort of solution ensure high performance and high throughput for your environments",
    "start": "1309600",
    "end": "1318520"
  },
  {
    "text": "so just to highlight a few of the optimization technologies that attunity includes is a unique proprietary",
    "start": "1321679",
    "end": "1327200"
  },
  {
    "text": "transfer protocol that optimizes the delivery of data over wide area networks and the internet",
    "start": "1327200",
    "end": "1333039"
  },
  {
    "text": "that includes a lot of unique technologies when loading data into s3 we leverage amazon",
    "start": "1333039",
    "end": "1339039"
  },
  {
    "text": "s3 multi-part transfers we use concurrent sessions and transfers we use compression all the information is",
    "start": "1339039",
    "end": "1345440"
  },
  {
    "text": "secure with encryption and we support guaranteed delivery with recoverability for any issues over wide area networks",
    "start": "1345440",
    "end": "1352640"
  },
  {
    "text": "the attunity data transfer technologies can provide you significant gains in performance and they automatically",
    "start": "1352640",
    "end": "1358799"
  },
  {
    "text": "handle different issues of variability in bandwidth hardware and the type of data sets that you may have",
    "start": "1358799",
    "end": "1366799"
  },
  {
    "text": "so to conclude alternative provides an easy way to move your data and your business intelligence to the cloud we",
    "start": "1367120",
    "end": "1373760"
  },
  {
    "text": "can make it easy for you and help you get your data into redshift whether you just want to try it out or want to use",
    "start": "1373760",
    "end": "1379120"
  },
  {
    "text": "it on an ongoing basis attunity is available on the aws marketplace and you can also visit us at",
    "start": "1379120",
    "end": "1385280"
  },
  {
    "text": "latinitycloudbeam.com or you can contact us at the email below",
    "start": "1385280",
    "end": "1390640"
  },
  {
    "text": "alternative solution for amazon redshift is available on a subscription basis very similar to the way amazon",
    "start": "1390640",
    "end": "1397679"
  },
  {
    "text": "license provides it which means you can use it on a monthly basis on demand",
    "start": "1397679",
    "end": "1403200"
  },
  {
    "text": "or you can commit to a year in which case you get a significant discount we look forward to working with you and",
    "start": "1403200",
    "end": "1409120"
  },
  {
    "text": "thank you for your time today and with that i'll hand this over to ben from jaspersoft who will help you",
    "start": "1409120",
    "end": "1414720"
  },
  {
    "text": "understand how uh and what you can do with the data once it gets into redshift over to you then",
    "start": "1414720",
    "end": "1421600"
  },
  {
    "text": "great thanks for raul thanks itamar and this is ben connors i'm worldwide head",
    "start": "1423120",
    "end": "1429200"
  },
  {
    "text": "of alliances here at jaspersoft i'll be joined in just a few moments by my colleague",
    "start": "1429200",
    "end": "1436000"
  },
  {
    "text": "mary flynn our senior technology evangelist who will lead us through a demo",
    "start": "1436000",
    "end": "1441679"
  },
  {
    "text": "just to begin briefly what i'd like to do is show a very brief introductory",
    "start": "1441679",
    "end": "1448080"
  },
  {
    "text": "video which should launch now so",
    "start": "1448080",
    "end": "1453520"
  },
  {
    "text": "we'll take a look so you're a developer or an i t professional you want software with the simplicity and low utility",
    "start": "1453520",
    "end": "1460559"
  },
  {
    "text": "pricing of the cloud your business users they want apps with easy self-service",
    "start": "1460559",
    "end": "1465600"
  },
  {
    "text": "reporting and analytics and that leaves you stuck as today's business intelligence solutions are both costly",
    "start": "1465600",
    "end": "1472320"
  },
  {
    "text": "and complex to use and deploy but what if you could get vi made easy",
    "start": "1472320",
    "end": "1478000"
  },
  {
    "text": "with push button deployment end user self-service and true pay-as-you-go",
    "start": "1478000",
    "end": "1483039"
  },
  {
    "text": "pricing now you can with jaspersoft's award-winning reporting and analytics",
    "start": "1483039",
    "end": "1489200"
  },
  {
    "text": "platform available on amazon's cloud for less than one dollar an hour with no",
    "start": "1489200",
    "end": "1495279"
  },
  {
    "text": "user or data limits and no additional fees you get access to a full bi suite",
    "start": "1495279",
    "end": "1501440"
  },
  {
    "text": "with self-service reporting analytics and dashboards what's more jaspersoft for aws",
    "start": "1501440",
    "end": "1508320"
  },
  {
    "text": "automatically finds and connects to amazon rds and redshift data sources so",
    "start": "1508320",
    "end": "1514159"
  },
  {
    "text": "you can literally go from purchase to analysis in under 10 minutes",
    "start": "1514159",
    "end": "1519520"
  },
  {
    "text": "and with a modern web architecture that includes an html5 interface full",
    "start": "1519520",
    "end": "1524960"
  },
  {
    "text": "multi-tenancy and the ability to connect natively to both traditional and big data stores jaspersoft is the most",
    "start": "1524960",
    "end": "1532080"
  },
  {
    "text": "trusted cloud bi platform on the market get rid of the cost and complexity of",
    "start": "1532080",
    "end": "1537679"
  },
  {
    "text": "building reporting and analytics for your app or business with jaspersoft bi for aws check out jaspersoft.com cloud",
    "start": "1537679",
    "end": "1546799"
  },
  {
    "text": "today and see why hundreds of customers have already deployed jaspersoft in the cloud",
    "start": "1546799",
    "end": "1554520"
  },
  {
    "text": "data sources so you can literally go from purchase to analysis in under 10",
    "start": "1556320",
    "end": "1561760"
  },
  {
    "text": "minutes okay that sounds like there might have been some",
    "start": "1561760",
    "end": "1567600"
  },
  {
    "text": "audio problems with that video so uh anyway i you probably got a little bit of the idea and we'll get into some more",
    "start": "1567600",
    "end": "1574880"
  },
  {
    "text": "details here so uh the world has changed i guess in an",
    "start": "1574880",
    "end": "1581440"
  },
  {
    "text": "interesting way i think any of us who took classes in economics maybe learned about",
    "start": "1581440",
    "end": "1588159"
  },
  {
    "text": "basis of competition in marketplaces and based on things like land labor and",
    "start": "1588159",
    "end": "1593919"
  },
  {
    "text": "capital traditionally but in today's information economy that's really changed land and labor have become far",
    "start": "1593919",
    "end": "1600080"
  },
  {
    "text": "less important time and information are the new factors of production",
    "start": "1600080",
    "end": "1606000"
  },
  {
    "text": "we find that knowledge workers business users don't have access to timely actionable data in fact some studies",
    "start": "1606000",
    "end": "1612240"
  },
  {
    "text": "have shown that only about 25 percent of knowledge workers who need data and information actually have easy",
    "start": "1612240",
    "end": "1617520"
  },
  {
    "text": "access to it why is that it's because most knowledge workers don't spend their time inside a",
    "start": "1617520",
    "end": "1625039"
  },
  {
    "text": "business intelligence or reporting tool and nor do they want to instead",
    "start": "1625039",
    "end": "1632080"
  },
  {
    "text": "we need intelligence inside we need information to find us as knowledge workers not the other way around",
    "start": "1633440",
    "end": "1640960"
  },
  {
    "text": "and it really has to become part of the dna of our of our applications and our everyday work life so",
    "start": "1640960",
    "end": "1647760"
  },
  {
    "text": "examples are a pipeline dashboard inside a sas crm application",
    "start": "1647760",
    "end": "1653520"
  },
  {
    "text": "performance report inside a partner portal maybe salary data visualizations inside your hr internet the kind of",
    "start": "1653520",
    "end": "1660000"
  },
  {
    "text": "applications that you're using as part of your daily business routines",
    "start": "1660000",
    "end": "1665200"
  },
  {
    "text": "and embedding the the reports the analytics inside these applications",
    "start": "1665200",
    "end": "1670799"
  },
  {
    "text": "you're already using so that's what jaspersoft does we we",
    "start": "1670799",
    "end": "1676399"
  },
  {
    "text": "provide the intelligence inside and it looks like we have self-service",
    "start": "1676399",
    "end": "1683200"
  },
  {
    "text": "business intelligence embeddable and affordable uh what we mean by that is that",
    "start": "1683200",
    "end": "1690159"
  },
  {
    "text": "we try to provide uh business intelligence that you can embed",
    "start": "1690159",
    "end": "1696640"
  },
  {
    "text": "easily through apis and through modern architectures like uh html5",
    "start": "1696640",
    "end": "1702480"
  },
  {
    "text": "and with that uh we empower lots of people millions of people every day to make decisions embedded inside",
    "start": "1702480",
    "end": "1708559"
  },
  {
    "text": "their applications in a very affordable and scalable way",
    "start": "1708559",
    "end": "1713760"
  },
  {
    "text": "as a company jaspersoft is a very high growth company lots of momentum",
    "start": "1717279",
    "end": "1723039"
  },
  {
    "text": "we are subscription-based uh very similar business model to uh redshift and and to",
    "start": "1723039",
    "end": "1729440"
  },
  {
    "text": "attunity and we've been exhibiting uh over 50 percent growth",
    "start": "1729440",
    "end": "1735039"
  },
  {
    "text": "every year in what we measure as uh annual contract value acv we're the world's most widely deployed",
    "start": "1735039",
    "end": "1741600"
  },
  {
    "text": "business intelligence software we have nearly 200 people uh around the world we're headquartered",
    "start": "1741600",
    "end": "1748320"
  },
  {
    "text": "here in san francisco and as you can see here from statistics on the slide over 300 000 community members thousands of",
    "start": "1748320",
    "end": "1755760"
  },
  {
    "text": "customers and and deployments and very broad recognition strong partnerships we're honored to be a member of the",
    "start": "1755760",
    "end": "1763120"
  },
  {
    "text": "amazon web service partner network as well as you'll recognize many of the other logos here we've been widely",
    "start": "1763120",
    "end": "1768799"
  },
  {
    "text": "recognized in the prestan analyst community i'll just point briefly one of my favorites is this sort of teal blue",
    "start": "1768799",
    "end": "1775760"
  },
  {
    "text": "uh center box in the in the uh at the top of the center column the uh technology award we got from infoworld",
    "start": "1775760",
    "end": "1782559"
  },
  {
    "text": "this is uh interesting we we shared that spotlight with things like uh hadoop and the apple ipod uh ipad",
    "start": "1782559",
    "end": "1791360"
  },
  {
    "text": "mini so we're very pleased to get this kind of recognition",
    "start": "1791360",
    "end": "1797039"
  },
  {
    "text": "so as far as the product goes jaspersoft",
    "start": "1797840",
    "end": "1803039"
  },
  {
    "text": "allows you to design any report from pixel perfect type reports as shown in",
    "start": "1803039",
    "end": "1808480"
  },
  {
    "text": "the upper left here to visual",
    "start": "1808480",
    "end": "1814000"
  },
  {
    "text": "visually rich graphical representations of the data as",
    "start": "1814000",
    "end": "1819440"
  },
  {
    "text": "shown in the middle even mobile applications as you see here shown just running on",
    "start": "1819440",
    "end": "1825679"
  },
  {
    "text": "phones and ipads etc so any report any dashboard",
    "start": "1825679",
    "end": "1831919"
  },
  {
    "text": "by assembling various tables and charts into meaningful views of information as",
    "start": "1831919",
    "end": "1837600"
  },
  {
    "text": "you see some examples here and any analytic view and in fact we'll",
    "start": "1837600",
    "end": "1843760"
  },
  {
    "text": "take a closer look at this in our demo but here are some examples of interactive analytic views that let you",
    "start": "1843760",
    "end": "1849840"
  },
  {
    "text": "slice and dice and drill into the information and assemble it in ways most meaningful and interesting to you",
    "start": "1849840",
    "end": "1857360"
  },
  {
    "text": "we can use any data type whether it's relational from oracle sql server db2",
    "start": "1858960",
    "end": "1866720"
  },
  {
    "text": "postgres etc big data including",
    "start": "1866720",
    "end": "1871840"
  },
  {
    "text": "hadoop mongodb file systems and of course what we'll be",
    "start": "1871840",
    "end": "1877200"
  },
  {
    "text": "looking at today here is aws redshift which is uh a very interesting and",
    "start": "1877200",
    "end": "1885200"
  },
  {
    "text": "powerful system as we'll see and one very compatible with our business and technology model",
    "start": "1885200",
    "end": "1891039"
  },
  {
    "text": "we've heard a lot from rahul and itamar about things like time to value and performance and ease of use and you'll",
    "start": "1891039",
    "end": "1897760"
  },
  {
    "text": "see that this fits very nicely into the theme with what we tried to do here at jaspersoft",
    "start": "1897760",
    "end": "1904799"
  },
  {
    "text": "so in terms of jaspersoft specifically on aws",
    "start": "1905279",
    "end": "1910880"
  },
  {
    "text": "we're the first bi service you can buy purely by the hour with no user limitations no monthly fees and in fact",
    "start": "1910880",
    "end": "1918960"
  },
  {
    "text": "purely by the hour at less than a dollar an hour here's uh uh actual page from our aws marketplace listing and as you",
    "start": "1918960",
    "end": "1925919"
  },
  {
    "text": "can see we started about 40 cents an hour for the software uh very affordable very much pay-as-you-go again consistent",
    "start": "1925919",
    "end": "1933039"
  },
  {
    "text": "with the aws theme we're the first bi service to",
    "start": "1933039",
    "end": "1938320"
  },
  {
    "text": "automatically connect to your aws data and uh you heard rule talk about",
    "start": "1938320",
    "end": "1943919"
  },
  {
    "text": "fast deployment for redshift a matter of 15 minutes or so versus weeks or months and we have a similar uh",
    "start": "1943919",
    "end": "1951679"
  },
  {
    "text": "pattern here with we've timed that it's actually less than 10 minutes from launching on aws to",
    "start": "1951679",
    "end": "1959360"
  },
  {
    "text": "actually visualizing your own data from rds or redshift and we integrate very",
    "start": "1959360",
    "end": "1964799"
  },
  {
    "text": "nicely with other aspects of aws like security the iam and and this allows",
    "start": "1964799",
    "end": "1971600"
  },
  {
    "text": "us to auto discover your data sources and make it very easy to configure and",
    "start": "1971600",
    "end": "1977440"
  },
  {
    "text": "deploy we released concurrent with redshift in february and we have",
    "start": "1977440",
    "end": "1984559"
  },
  {
    "text": "about 400 customers now so lots of successful implementations and something where we're pleased to",
    "start": "1984559",
    "end": "1991519"
  },
  {
    "text": "continue so with that what i'd like to do is hand the controls over to",
    "start": "1991519",
    "end": "1998080"
  },
  {
    "text": "mary for a demo and res i think i guess reza is going to take over first so",
    "start": "1998080",
    "end": "2004399"
  },
  {
    "text": "reza if you're ready here we go perfect thank you everyone",
    "start": "2004399",
    "end": "2010640"
  },
  {
    "text": "so much we're ready to begin by taking a look at how we can actually load our data into",
    "start": "2010640",
    "end": "2016240"
  },
  {
    "text": "redshift and as mentioned by itamar earlier in the demo or in the presentation the trinity replicate is",
    "start": "2016240",
    "end": "2023360"
  },
  {
    "text": "the piece of software that would be used in order to load data into redshift",
    "start": "2023360",
    "end": "2029679"
  },
  {
    "text": "so what you're looking at right now is the attunity replicate console in order to save time with the demo i've",
    "start": "2029679",
    "end": "2036159"
  },
  {
    "text": "gone ahead and pre-defined a couple of things here including my source and target we're",
    "start": "2036159",
    "end": "2041360"
  },
  {
    "text": "going to be loading data from an oracle data source so i'll do just a quick test here as you",
    "start": "2041360",
    "end": "2047519"
  },
  {
    "text": "can see it's a very basic definition in terms of how you connect to your source uh the oracle uh you just need the",
    "start": "2047519",
    "end": "2053839"
  },
  {
    "text": "connection string as well as the username and password and then for redshift there are three pieces of information that's needed you need of",
    "start": "2053839",
    "end": "2060320"
  },
  {
    "text": "course the redshift cluster information what database name you're going to load the data to uh you need an attunity",
    "start": "2060320",
    "end": "2067358"
  },
  {
    "text": "cloud beam subscription which is something that you set up by going to attunitycloudgame.com and then of course you need an amazon",
    "start": "2067359",
    "end": "2074000"
  },
  {
    "text": "staging s3 bucket that's in the same region as the amazon redshift cluster",
    "start": "2074000",
    "end": "2079040"
  },
  {
    "text": "that you're loading the data to i'm just going to test my my source and target",
    "start": "2079040",
    "end": "2084560"
  },
  {
    "text": "here to make sure that everything's okay and with that i can move straight into creating my new task so i'll call this",
    "start": "2084560",
    "end": "2091118"
  },
  {
    "text": "oracle to retrieve",
    "start": "2091119",
    "end": "2094240"
  },
  {
    "text": "and as you can see i've selected by default to do both full load and apply changes meaning we also can do the",
    "start": "2096800",
    "end": "2103280"
  },
  {
    "text": "change data capture as part of this task so with that i'll click ok and this then",
    "start": "2103280",
    "end": "2108880"
  },
  {
    "text": "allows me to drag my oracle source and my redshift target",
    "start": "2108880",
    "end": "2114079"
  },
  {
    "text": "into the interface and at this point we're ready to start doing our table selection i can load up",
    "start": "2114079",
    "end": "2120320"
  },
  {
    "text": "the schema from the source uh database search uh and include specific tables",
    "start": "2120320",
    "end": "2126079"
  },
  {
    "text": "that i want or we can use include and exclude strings to select tables based",
    "start": "2126079",
    "end": "2131200"
  },
  {
    "text": "on specific patterns but in this case i'm going to select a few tables explicitly",
    "start": "2131200",
    "end": "2137200"
  },
  {
    "text": "i'll add that to my list of tables hit ok and then i'm ready to start loading data already however if i wanted to do",
    "start": "2137200",
    "end": "2144480"
  },
  {
    "text": "some customization or transformation i have two options i can do a global transformation or i can can go to an",
    "start": "2144480",
    "end": "2150960"
  },
  {
    "text": "individual table and set up a transformation that would make sense for",
    "start": "2150960",
    "end": "2156480"
  },
  {
    "text": "the data for loading the data into redshift so i can go to my transformation here and select any",
    "start": "2156480",
    "end": "2162960"
  },
  {
    "text": "number of different types of transformations i want including the ability to add new columns or do",
    "start": "2162960",
    "end": "2168079"
  },
  {
    "text": "calculations on existing types of columns that are already there to load the data",
    "start": "2168079",
    "end": "2173359"
  },
  {
    "text": "and make these transformations in real time before loading the data into redshift",
    "start": "2173359",
    "end": "2179280"
  },
  {
    "text": "so i'm pretty happy with these selections right now i'm just going to load all the data as it is from the source",
    "start": "2179280",
    "end": "2184880"
  },
  {
    "text": "i can save my task and hit the run button and that's it that's all that's needed in order to act in order to",
    "start": "2184880",
    "end": "2191599"
  },
  {
    "text": "actually uh load your data into redshift using the trinity replicate and as you",
    "start": "2191599",
    "end": "2196800"
  },
  {
    "text": "can see when i run this task there are a few things that will happen first we will prepare the target tables by",
    "start": "2196800",
    "end": "2202560"
  },
  {
    "text": "creating the target schema based on how the source is defined or we can use an existing schema that you would specify",
    "start": "2202560",
    "end": "2209119"
  },
  {
    "text": "in the task setting and then we will load the data from the source into the target and then keep the",
    "start": "2209119",
    "end": "2214640"
  },
  {
    "text": "target target tables up to date by performing cdc updates from the",
    "start": "2214640",
    "end": "2220079"
  },
  {
    "text": "source to the target so i'll click ok and this will start up my task if i connect using sql workbench",
    "start": "2220079",
    "end": "2228000"
  },
  {
    "text": "to my redshift target we can take a look there and see that in the natality database where i'm loading",
    "start": "2228000",
    "end": "2234800"
  },
  {
    "text": "this data if i refresh that right now the hr database has not yet been created",
    "start": "2234800",
    "end": "2241760"
  },
  {
    "text": "we're using actually the hr schema to load the data so all of the data now has been queued",
    "start": "2241760",
    "end": "2249119"
  },
  {
    "text": "up for loading and once it moves over to loading you can see the estimated count of all",
    "start": "2249119",
    "end": "2255200"
  },
  {
    "text": "of the data being that's going to be loaded as part of this process you can take a look at the",
    "start": "2255200",
    "end": "2260560"
  },
  {
    "text": "throughput to give you an idea of how long it will take to load the data in terms of",
    "start": "2260560",
    "end": "2266320"
  },
  {
    "text": "the number of rules that are being handled per second and once we're at the loading stage if we go back to the",
    "start": "2266320",
    "end": "2272480"
  },
  {
    "text": "target and refresh this we can then see that the hr schema has been created and those four tables are now available",
    "start": "2272480",
    "end": "2279680"
  },
  {
    "text": "in redshift as we continue to monitor things here you can see in real time the data as it",
    "start": "2279680",
    "end": "2285920"
  },
  {
    "text": "gets loaded and you can monitor this to to understand the throughput that",
    "start": "2285920",
    "end": "2291200"
  },
  {
    "text": "you're getting as this click to load process is happening and that's it it's completed all the data is now updated",
    "start": "2291200",
    "end": "2298640"
  },
  {
    "text": "and is ready for use but of course as you want to move forward with this and you want to ensure",
    "start": "2298640",
    "end": "2305839"
  },
  {
    "text": "that you're keeping your target data in sync we have to change data processing or to",
    "start": "2305839",
    "end": "2310960"
  },
  {
    "text": "change the capture process that allows you to monitor the source and continue to load that data in real time so what i",
    "start": "2310960",
    "end": "2318320"
  },
  {
    "text": "have is a little application that allows me to insert some data into my source so i can insert",
    "start": "2318320",
    "end": "2324960"
  },
  {
    "text": "a thousand new rows and then update uh those rows uh very quickly on the source",
    "start": "2324960",
    "end": "2330480"
  },
  {
    "text": "and as you can see here i'm auto committing these changes to the to the source uh so automatically if we take a",
    "start": "2330480",
    "end": "2337280"
  },
  {
    "text": "look at the change processing mode we now have 2 000 2000 rows being updated here",
    "start": "2337280",
    "end": "2344320"
  },
  {
    "text": "in two transactions and we can take a look at the apply latency this allows me to monitor and",
    "start": "2344320",
    "end": "2350880"
  },
  {
    "text": "see exactly how long it will take to apply this these changes from the source to the target",
    "start": "2350880",
    "end": "2357520"
  },
  {
    "text": "once the throughput or the apply throughput actually begins you would be able to see as well",
    "start": "2357520",
    "end": "2363920"
  },
  {
    "text": "this this being updated to show you that those changes have actually been applied and",
    "start": "2363920",
    "end": "2369920"
  },
  {
    "text": "up and these updates have been made into uh the redshift target as well so with that it's a very very easy process to",
    "start": "2369920",
    "end": "2377680"
  },
  {
    "text": "easily use the trinity replicate to click and load your data into replicate",
    "start": "2377680",
    "end": "2382960"
  },
  {
    "text": "into attunity uh sorry into amazon redshift at this point i want to",
    "start": "2382960",
    "end": "2388240"
  },
  {
    "text": "transition over to mary flynn from jaspersoft who would continue forward with the demo",
    "start": "2388240",
    "end": "2394240"
  },
  {
    "text": "thank you riza all right folks so what we're going to",
    "start": "2394240",
    "end": "2399839"
  },
  {
    "text": "do now is we're going to take a look at jaspersoft in action so let me make sure that i'm",
    "start": "2399839",
    "end": "2405520"
  },
  {
    "text": "there we go okay so we've gone on the screen jasper report server if you look at the url across the top it's running",
    "start": "2405520",
    "end": "2411280"
  },
  {
    "text": "on ec2 so you've got amazon aws going on there and the significant part but what makes this",
    "start": "2411280",
    "end": "2418160"
  },
  {
    "text": "so easy is that we are automatically going to detect that redshift instance",
    "start": "2418160",
    "end": "2425119"
  },
  {
    "text": "so jasper report server is running in the same aws environment as redshift so this is my console right here my server",
    "start": "2425119",
    "end": "2431920"
  },
  {
    "text": "is actually locatable through the ec2 over here and i'm just going to show you redshift real quick and this is what riza had just",
    "start": "2431920",
    "end": "2439119"
  },
  {
    "text": "uploaded to he uploaded to this environment right here so resi i forget",
    "start": "2439119",
    "end": "2444400"
  },
  {
    "text": "where you're located i know that ben's in san francisco i'm on the east coast we're all over the place and we're all",
    "start": "2444400",
    "end": "2450160"
  },
  {
    "text": "using the cloud so this is what we're going to connect to so let me log in as the super user",
    "start": "2450160",
    "end": "2457039"
  },
  {
    "text": "i changed my password log back in there we go",
    "start": "2457680",
    "end": "2463200"
  },
  {
    "text": "and what i'm going to do is i'm going to show you how to make that connection real quick and then we're going to do some quick analysis and we'll wrap up",
    "start": "2463200",
    "end": "2468960"
  },
  {
    "text": "with some q a all right so what i want to do is i want to show you that data source that risa had just uploaded to redshift and you'll",
    "start": "2468960",
    "end": "2477200"
  },
  {
    "text": "notice here that the type for the data source is automatically set to aws and it detects that based on the url up here",
    "start": "2477200",
    "end": "2484400"
  },
  {
    "text": "now i could also choose other types so for example your traditional jdbc and so on but aws is automatically detected",
    "start": "2484400",
    "end": "2491839"
  },
  {
    "text": "and i'm going to give this just a name right there so it's uploaded by a 290",
    "start": "2491839",
    "end": "2496880"
  },
  {
    "text": "cloud theme and this is the really cool part i'll just",
    "start": "2496880",
    "end": "2502240"
  },
  {
    "text": "put a location here otherwise it's going to give me an error down here all i need to do",
    "start": "2502240",
    "end": "2508960"
  },
  {
    "text": "is just click on redshift and it automatically detects this and this is what makes it so easy and so",
    "start": "2508960",
    "end": "2515440"
  },
  {
    "text": "powerful so powerful to get started with this shared solution",
    "start": "2515440",
    "end": "2520800"
  },
  {
    "text": "now if i were trying to connect to let's say some sort of hybrid environment i could use alternative ways to get in but",
    "start": "2520800",
    "end": "2527760"
  },
  {
    "text": "this is the default and automatically picks up it knows based on my login credentials what group i belong to and",
    "start": "2527760",
    "end": "2533680"
  },
  {
    "text": "it automatically detects the redshift and alternatively it could also detect the rds instances",
    "start": "2533680",
    "end": "2541119"
  },
  {
    "text": "all right so what i'm going to do now is i'm going to log in",
    "start": "2541119",
    "end": "2546240"
  },
  {
    "text": "just like riza had done in his environment",
    "start": "2546240",
    "end": "2553359"
  },
  {
    "text": "and you'll notice that it automatically creates the url for me i'll do a test connection",
    "start": "2553359",
    "end": "2560319"
  },
  {
    "text": "try that again okay there we go so i just had a little",
    "start": "2560319",
    "end": "2566560"
  },
  {
    "text": "typo okay so the connection path now i'm going to click save so my data source is",
    "start": "2566560",
    "end": "2572000"
  },
  {
    "text": "now set up so this is all great and wonderful what i'm going to do now is i'm going to",
    "start": "2572000",
    "end": "2577200"
  },
  {
    "text": "create a domain so you can see how quickly you can get and earlier in the um",
    "start": "2577200",
    "end": "2582560"
  },
  {
    "text": "uh the slide presentation and the animation is that you can get from zero to you know 60 and you know very quickly",
    "start": "2582560",
    "end": "2588960"
  },
  {
    "text": "and this this really is the case so let me show you what i mean by that",
    "start": "2588960",
    "end": "2594720"
  },
  {
    "text": "and i'm just going to do this very quickly and this is the one that i had just",
    "start": "2594800",
    "end": "2601119"
  },
  {
    "text": "created we won't go from beginning to end on this it's sort of like a cooking show",
    "start": "2601119",
    "end": "2606160"
  },
  {
    "text": "where i already have something already set up they'll bring up but this is the schema that risa had created on the fly",
    "start": "2606160",
    "end": "2612960"
  },
  {
    "text": "using cloud beam so i'm going to click ok those are the tables that he had uploaded i'm going to bring three of",
    "start": "2612960",
    "end": "2619680"
  },
  {
    "text": "those in and i'm going to do a quick join on those",
    "start": "2619680",
    "end": "2624880"
  },
  {
    "text": "so i'm going to bring up employees and i will link those so on department",
    "start": "2624880",
    "end": "2631359"
  },
  {
    "text": "i can link those and interjoin on department id and for jobs i can do an interjoin on",
    "start": "2631359",
    "end": "2637520"
  },
  {
    "text": "job id and then i can go and i can create the metadata model so i can bring all these",
    "start": "2637520",
    "end": "2642560"
  },
  {
    "text": "items in here i can choose to have things in different order and have different uh ways of describing it",
    "start": "2642560",
    "end": "2649760"
  },
  {
    "text": "and all sorts of good things so just assume that i had gone through this process of for example let's say removing the id and and changing the the",
    "start": "2649760",
    "end": "2657760"
  },
  {
    "text": "department name so it's a little bit more user-friendly",
    "start": "2657760",
    "end": "2663200"
  },
  {
    "text": "and click save okay and then i can go through that whole process and then i can as an end user i would be able to",
    "start": "2663200",
    "end": "2669440"
  },
  {
    "text": "take this and create my own reports let me show you what that looks like in real life so i'm going to create let me just log",
    "start": "2669440",
    "end": "2676240"
  },
  {
    "text": "out and i'll log in as a regular user",
    "start": "2676240",
    "end": "2681440"
  },
  {
    "text": "okay so i'm no longer an administrator okay sorry about that i guess i will just go",
    "start": "2682640",
    "end": "2687839"
  },
  {
    "text": "in as my regular guy again",
    "start": "2687839",
    "end": "2691800"
  },
  {
    "text": "my apologies [Music] okay so i'm going to create an ad hoc",
    "start": "2701040",
    "end": "2707680"
  },
  {
    "text": "view and the first thing i will do is take that view",
    "start": "2707680",
    "end": "2713200"
  },
  {
    "text": "based on the data that um that rizza had uploaded so i'll go in here",
    "start": "2713200",
    "end": "2719920"
  },
  {
    "text": "and this is the one i had created ahead of time and i'll choose the data and i'll bring in all the employees",
    "start": "2719920",
    "end": "2726079"
  },
  {
    "text": "that's my metadata view and then i can go into the crosstab view or create a chart or whatever it is and you'll",
    "start": "2726079",
    "end": "2732560"
  },
  {
    "text": "notice here that i've got things a little bit easier to understand so i can bring say",
    "start": "2732560",
    "end": "2738400"
  },
  {
    "text": "employee id first name last name and you can even set up certain fields to be",
    "start": "2738400",
    "end": "2743599"
  },
  {
    "text": "restricted so depending on who you log in as some people may see different fields than others",
    "start": "2743599",
    "end": "2749599"
  },
  {
    "text": "or people may see different rows so if you are allowed to see salary information you might see that",
    "start": "2749599",
    "end": "2755680"
  },
  {
    "text": "for only your direct reports but not for others so all that can be worked into the the jaspersoft environment",
    "start": "2755680",
    "end": "2762640"
  },
  {
    "text": "okay so that's just to show you the beginning to end that you can actually get the data from whatever your sources",
    "start": "2762640",
    "end": "2767839"
  },
  {
    "text": "as recent show use cloudbeam bring it up put into redshift it's all ready for",
    "start": "2767839",
    "end": "2773440"
  },
  {
    "text": "processing jasper report server goes on top of that now let's show you some of the power of redshift because redshift can be very",
    "start": "2773440",
    "end": "2779920"
  },
  {
    "text": "fast and very cool now what i'm going to do is a much larger data set what we're going to do is we are going",
    "start": "2779920",
    "end": "2785680"
  },
  {
    "text": "to use birth records for the united states for the last four years",
    "start": "2785680",
    "end": "2791359"
  },
  {
    "text": "i'm going to bring that data in and this was modeled again using the jasper reports server domain and then here you",
    "start": "2791359",
    "end": "2798480"
  },
  {
    "text": "see the different fields that are available this is loaded into redshift and we're going to create a quick chart out of it",
    "start": "2798480",
    "end": "2805520"
  },
  {
    "text": "okay so the first thing i want to do is bring in the total count of baby so i'm going",
    "start": "2805520",
    "end": "2810640"
  },
  {
    "text": "to say bring in baby count i'm going to drag that into the rows okay now what just happened there when",
    "start": "2810640",
    "end": "2816240"
  },
  {
    "text": "you saw that little dial going around it was going to redshift to creating a query and you can see how quickly the",
    "start": "2816240",
    "end": "2822319"
  },
  {
    "text": "information came back and remember this is all happening over the cloud so the total number of babies born over",
    "start": "2822319",
    "end": "2828160"
  },
  {
    "text": "the last 40 years is about 152 million now if i want to uh let's say analyze",
    "start": "2828160",
    "end": "2834000"
  },
  {
    "text": "that maybe break it out by father's age if there's been a change in age or what the average father ages i can drag that",
    "start": "2834000",
    "end": "2840880"
  },
  {
    "text": "into the report as well let me just bring that in",
    "start": "2840880",
    "end": "2845838"
  },
  {
    "text": "goodness gracious give me one second",
    "start": "2846000",
    "end": "2851480"
  },
  {
    "text": "try that again",
    "start": "2861119",
    "end": "2864440"
  },
  {
    "text": "okay so we'll bring in the natality data and we'll bring in the baby count",
    "start": "2872480",
    "end": "2880960"
  },
  {
    "text": "okay and now we're going to write this out by father's age",
    "start": "2881040",
    "end": "2886040"
  },
  {
    "text": "there we go okay so it's going back to redshift and what i want to do is i want to expose the total number of ages so i've",
    "start": "2886960",
    "end": "2893599"
  },
  {
    "text": "got this little slider over here so i'm going to drag that down it's just basically you're drilling down",
    "start": "2893599",
    "end": "2899280"
  },
  {
    "text": "uh you see there's a big spike over here that's throwing everything off and that is uh basically 99 is essentially the",
    "start": "2899280",
    "end": "2906559"
  },
  {
    "text": "placeholder that hospitals uh enter in when they don't know the name so what i'm going to do is i'm going to apply",
    "start": "2906559",
    "end": "2911839"
  },
  {
    "text": "filter exclude that so all i have to do is select the field here and say create the filter",
    "start": "2911839",
    "end": "2918640"
  },
  {
    "text": "and i'm not so worried about the tail end of either side so i'm just going to arbitrarily put",
    "start": "2918640",
    "end": "2923680"
  },
  {
    "text": "65 in there for the upper limit and again it's going back to redshift so",
    "start": "2923680",
    "end": "2928720"
  },
  {
    "text": "it's pushing the hard work down to the database in this case and there's a lot of records there so redshift is coming back pretty well here",
    "start": "2928720",
    "end": "2935200"
  },
  {
    "text": "and i can see that the average age over the whole 40 years is about 28. uh close",
    "start": "2935200",
    "end": "2940880"
  },
  {
    "text": "next that would be about 27. now let's see if we want to figure that out broken out by year in particular let's do it by",
    "start": "2940880",
    "end": "2947200"
  },
  {
    "text": "decade so what i'm going to do is i'm going to create another filter this time it's going to be by year and i'm going",
    "start": "2947200",
    "end": "2953280"
  },
  {
    "text": "to choose a couple of decades of information or is it just a decade turning point",
    "start": "2953280",
    "end": "2960000"
  },
  {
    "text": "so it's populating the list here again going back to redshift",
    "start": "2960559",
    "end": "2965838"
  },
  {
    "text": "and we're going to pick up 1970 1980 and 1990 and then we're going to see whether the baby couch and where the",
    "start": "2965920",
    "end": "2972559"
  },
  {
    "text": "father's age has changed over time",
    "start": "2972559",
    "end": "2976400"
  },
  {
    "text": "let's give us one second usually it's very very fast",
    "start": "2979440",
    "end": "2985640"
  },
  {
    "text": "so there's a little bit of a hiccup",
    "start": "2985839",
    "end": "2989440"
  },
  {
    "text": "okay well we let that happen what i want to do is to show you in the background here that if you wanted to find out how",
    "start": "2994640",
    "end": "3001040"
  },
  {
    "text": "quickly you can get up and running with jaspersoft and aws you can go to jaspersoft.comcloud",
    "start": "3001040",
    "end": "3008559"
  },
  {
    "text": "and you can also go to our community sites you can go to community.jaspersoft.com and you'll find",
    "start": "3008559",
    "end": "3013599"
  },
  {
    "text": "a page here in aws and in here there are some nice videos to get you started how to",
    "start": "3013599",
    "end": "3019440"
  },
  {
    "text": "actually get launched get started how to connect to your database whether it's going to be redshift or rds or anything",
    "start": "3019440",
    "end": "3025920"
  },
  {
    "text": "else and then a variety of other information on pricing etc so let's see if this came",
    "start": "3025920",
    "end": "3031920"
  },
  {
    "text": "back okay great okay so i've got 1970 and i'm going to choose 1980",
    "start": "3031920",
    "end": "3039680"
  },
  {
    "text": "and 1990. all right so with those three years selected i can see that the average age",
    "start": "3039680",
    "end": "3046960"
  },
  {
    "text": "is 27 but if i want to break that out by those years i can drag that into the report as well so i'm going to take year",
    "start": "3046960",
    "end": "3052559"
  },
  {
    "text": "and drag it into rows and now we're going to see",
    "start": "3052559",
    "end": "3058480"
  },
  {
    "text": "that bell curve that's going to be distributed amongst those three years just do a little slide down here",
    "start": "3058480",
    "end": "3065119"
  },
  {
    "text": "and now i can see 70 80 and 90. this isn't the easiest way to interpret the",
    "start": "3065119",
    "end": "3070960"
  },
  {
    "text": "information it might be somewhat helpful for smaller sets but let's let's do something different",
    "start": "3070960",
    "end": "3076800"
  },
  {
    "text": "let's change this to a different type of chart it changes to a spline chart okay",
    "start": "3076800",
    "end": "3082160"
  },
  {
    "text": "and keep in mind that i'm doing all of this over the web this isn't that interesting but if i switch",
    "start": "3082160",
    "end": "3088240"
  },
  {
    "text": "or pivot these groups here you're going to find that we can have this nice little bell curve it's going to be breaking things out and we're going to",
    "start": "3088240",
    "end": "3094800"
  },
  {
    "text": "be able to see the distribution much more clearly okay so here we have",
    "start": "3094800",
    "end": "3100880"
  },
  {
    "text": "the total number of babies goes uh down uh for each decade but also so that's",
    "start": "3101040",
    "end": "3106800"
  },
  {
    "text": "the height up here but also the shift changes so in 1970 the most common age was 23 and then",
    "start": "3106800",
    "end": "3114800"
  },
  {
    "text": "after that was 27 and then there seems to be a pretty fair distribution in 1980 between 25 and 27 but you see as time",
    "start": "3114800",
    "end": "3122880"
  },
  {
    "text": "goes on the average age of fathers goes up so here we're looking at 29 in 1990.",
    "start": "3122880",
    "end": "3128640"
  },
  {
    "text": "now there are a number of things that we can do in the interest of time i don't want to take too much of it sorry for the little glitches we have but just you",
    "start": "3128640",
    "end": "3134640"
  },
  {
    "text": "know you can save this out so once the the view is saved in the jaspersoft",
    "start": "3134640",
    "end": "3139680"
  },
  {
    "text": "repository you can share it with other co-workers you can open it up make other changes you can do zooming um you can",
    "start": "3139680",
    "end": "3146400"
  },
  {
    "text": "have things scheduled to go out on the periodic basis to your peers and so on and one thing i do want to show you is",
    "start": "3146400",
    "end": "3152160"
  },
  {
    "text": "this view sequel each time i was uh requesting something from uh redshift uh",
    "start": "3152160",
    "end": "3159040"
  },
  {
    "text": "jasper report server was creating the sql statement and you see right here what actually is going back and forth",
    "start": "3159040",
    "end": "3164640"
  },
  {
    "text": "between a jasper report server and redshift running on the cloud so i wanted to show you a little bit",
    "start": "3164640",
    "end": "3171520"
  },
  {
    "text": "more but in the interest of time i will hand it back over to to sherry and my apologies for that little hiccup earlier",
    "start": "3171520",
    "end": "3180640"
  }
]
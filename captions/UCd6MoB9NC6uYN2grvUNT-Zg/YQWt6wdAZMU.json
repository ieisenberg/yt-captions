[
  {
    "start": "0",
    "end": "33000"
  },
  {
    "text": "yeah hello everyone my name is Nathan Peck I'm a developer advocate at AWS and",
    "start": "1429",
    "end": "7319"
  },
  {
    "text": "today I'm going to be presenting a session on running high performance database clusters with kubernetes and",
    "start": "7319",
    "end": "13469"
  },
  {
    "text": "Amazon ETS I'll be joined by a case a--from state street who's going to show you an amazing demo of running an",
    "start": "13469",
    "end": "20640"
  },
  {
    "text": "extremely high performance communities cluster using the open source database Vitesse",
    "start": "20640",
    "end": "25650"
  },
  {
    "text": "you're gonna be amazed by how many transactions per second this open source database is able to achieve within",
    "start": "25650",
    "end": "31470"
  },
  {
    "text": "kubernetes so to get started with here are some of the other we're on the",
    "start": "31470",
    "end": "36899"
  },
  {
    "start": "33000",
    "end": "68000"
  },
  {
    "text": "second repeat skip over that let's talk about the agenda for this session first we're talking about some of the best",
    "start": "36899",
    "end": "42719"
  },
  {
    "text": "practices of designing for performance and Cabrini's we're going to talk a little bit about how we can test",
    "start": "42719",
    "end": "48000"
  },
  {
    "text": "performance and then we're going to show that demo of highly optimized kubernetes",
    "start": "48000",
    "end": "53789"
  },
  {
    "text": "cluster with some of the tips and tricks along the way and applications of the",
    "start": "53789",
    "end": "58980"
  },
  {
    "text": "optimization principles that we discussed earlier in the slide deck so let's start with those best practices of",
    "start": "58980",
    "end": "66150"
  },
  {
    "text": "designing for performance and kubernetes and so level-set everybody let's talk",
    "start": "66150",
    "end": "71729"
  },
  {
    "start": "68000",
    "end": "151000"
  },
  {
    "text": "about the basic core components of kubernetes if you're familiar with container orchestration you'll",
    "start": "71729",
    "end": "77130"
  },
  {
    "text": "understand that you have your docker container which represents your application you have worker nodes which",
    "start": "77130",
    "end": "83790"
  },
  {
    "text": "are ultimately the machines that will be running your application and the container that wraps around your",
    "start": "83790",
    "end": "89220"
  },
  {
    "text": "application and then you have in the kubernetes world the control plane which",
    "start": "89220",
    "end": "94350"
  },
  {
    "text": "is what tells those worker knows what application to run and launches updates shuts down your containers across those",
    "start": "94350",
    "end": "101909"
  },
  {
    "text": "worker nodes and you have SCD which is also part of the control plane but which keeps track of the state of everything",
    "start": "101909",
    "end": "107579"
  },
  {
    "text": "that's going on inside of your cluster and you'll notice I've grouped these into two different categories the you",
    "start": "107579",
    "end": "113310"
  },
  {
    "text": "category and the Amazon EGS category so with Amazon ETS kubernetes the you",
    "start": "113310",
    "end": "120270"
  },
  {
    "text": "category is old things that you are responsible for optimizing in order to",
    "start": "120270",
    "end": "125969"
  },
  {
    "text": "get that high performance out of your crew beretti's you need to optimize your container and you need to optimize your",
    "start": "125969",
    "end": "131190"
  },
  {
    "text": "usage of the worker knows and really optimize the worker knows themselves versus Amazon ETS and the 80s",
    "start": "131190",
    "end": "138110"
  },
  {
    "text": "team behind it are responsible for optimizing everything on that right-hand side of the slide everything happened",
    "start": "138110",
    "end": "144260"
  },
  {
    "text": "with the control plane and the sed itself to really make sure that that stays high-performance for you so let's",
    "start": "144260",
    "end": "153110"
  },
  {
    "start": "151000",
    "end": "297000"
  },
  {
    "text": "start with the first aspect that you can optimize inside your communities cluster",
    "start": "153110",
    "end": "158270"
  },
  {
    "text": "and that is your container and the first tip for optimizing your workload and kubernetes is to keep that container",
    "start": "158270",
    "end": "164120"
  },
  {
    "text": "small there's a couple different ways you can do this one of my favorite ways is to use a multi-stage docker buildin",
    "start": "164120",
    "end": "169640"
  },
  {
    "text": "and what this allows you to do is break out your docker file into multiple",
    "start": "169640",
    "end": "174890"
  },
  {
    "text": "containers which build one after another but only the last stage of the build the",
    "start": "174890",
    "end": "180739"
  },
  {
    "text": "last final container is what actually gets run when you deploy something about your experience cluster so it's even an",
    "start": "180739",
    "end": "186980"
  },
  {
    "text": "example of how this might work let's say I have a java application or let's say an OGS application and there's a build",
    "start": "186980",
    "end": "193610"
  },
  {
    "text": "and compile phase to construct in my application if it's no Jess I need to go",
    "start": "193610",
    "end": "198799"
  },
  {
    "text": "out to NPM I need to fetch my dependencies in and make sure they're available to my application if it's Java",
    "start": "198799",
    "end": "204980"
  },
  {
    "text": "main we need to build the jar file if it's maybe a C++ or go application",
    "start": "204980",
    "end": "210920"
  },
  {
    "text": "actually need to compile that application down to the binary so stage number one can be the stage that",
    "start": "210920",
    "end": "217609"
  },
  {
    "text": "actually hosts my compiler and all my build tools and then the final stage of",
    "start": "217609",
    "end": "223010"
  },
  {
    "text": "my build is actually just copying out the build product for my first stage and",
    "start": "223010",
    "end": "228019"
  },
  {
    "text": "what this results in is you have a very small lightweight container which is can be much more efficient when it's",
    "start": "228019",
    "end": "233030"
  },
  {
    "text": "deployed across your cluster versus actually distributing all your build tools and your full tool chain to your",
    "start": "233030",
    "end": "240590"
  },
  {
    "text": "entire kubernetes cluster and all the pods that are within it and the other thing you can do is you can use a",
    "start": "240590",
    "end": "246260"
  },
  {
    "text": "minimalist operating system there's a lot of different choices for docker",
    "start": "246260",
    "end": "251329"
  },
  {
    "text": "container operating systems out there I would recommend using one like Alpine Linux or if you're fortunate to be",
    "start": "251329",
    "end": "257900"
  },
  {
    "text": "building in a language like go where you can below statically linked binary you may not need an operating system at all",
    "start": "257900",
    "end": "263030"
  },
  {
    "text": "you may be able to distribute a very even lightweight container also consider in",
    "start": "263030",
    "end": "270050"
  },
  {
    "text": "terms of optimizing your performance in your communities cluster what one time you're using because not all runtimes",
    "start": "270050",
    "end": "275659"
  },
  {
    "text": "are equal in particular we noticed that some spring applications and some",
    "start": "275659",
    "end": "281180"
  },
  {
    "text": "frameworks they have a very strong cold start where they require a lot of resources an initial burst of resources",
    "start": "281180",
    "end": "287599"
  },
  {
    "text": "before they're up and running and this tends to make it really hard to optimize that kubernetes cluster compared to a",
    "start": "287599",
    "end": "293509"
  },
  {
    "text": "runtime that is more lightweight and starts up much faster just give me an",
    "start": "293509",
    "end": "299419"
  },
  {
    "start": "297000",
    "end": "353000"
  },
  {
    "text": "idea about what is possible in terms of optimizing your container here's a list",
    "start": "299419",
    "end": "305000"
  },
  {
    "text": "of popular base images that are in use today I pull this a couple weeks ago",
    "start": "305000",
    "end": "310909"
  },
  {
    "text": "you'll notice that the baseline nodejs image is almost 675 megabytes in size",
    "start": "310909",
    "end": "318129"
  },
  {
    "text": "but you'll notice there's also a node slim image which is 184 megabytes in",
    "start": "318129",
    "end": "323270"
  },
  {
    "text": "size and you'll notice all the way down there at the bottom the Alpine image that I mentioned earlier only four",
    "start": "323270",
    "end": "328310"
  },
  {
    "text": "megabytes and there's even a busybox image which is just over one megabyte in size and so if you're if you're capable",
    "start": "328310",
    "end": "335270"
  },
  {
    "text": "of doing so try to make use of the most minimalist image that's available to you",
    "start": "335270",
    "end": "340819"
  },
  {
    "text": "on this list because the smaller you're able to make that runtime the less",
    "start": "340819",
    "end": "346190"
  },
  {
    "text": "memory the less CPU the less overhead there's going to be in terms of running your application on your community's",
    "start": "346190",
    "end": "352099"
  },
  {
    "text": "cluster so let's look let's step up one level from the container and look at the",
    "start": "352099",
    "end": "358310"
  },
  {
    "start": "353000",
    "end": "430000"
  },
  {
    "text": "kubernetes pod the pod is basically the wrapper around your application container when it's running inside your",
    "start": "358310",
    "end": "364310"
  },
  {
    "text": "kubernetes cluster you can run one or more containers inside the pod and the kubernetes control plane schedules the",
    "start": "364310",
    "end": "371000"
  },
  {
    "text": "pod as that set of containers onto the hosts inside of your cluster so the",
    "start": "371000",
    "end": "376250"
  },
  {
    "text": "question I always ask people who are suffering from performance issues is how many sidecars are you running in your",
    "start": "376250",
    "end": "381710"
  },
  {
    "text": "pod there's a lot of frameworks out there that add admission controllers to your kubernetes control plane and these",
    "start": "381710",
    "end": "388490"
  },
  {
    "text": "make it very easy to go ahead and add another sidecar to all your pods and it",
    "start": "388490",
    "end": "394430"
  },
  {
    "text": "becomes a little bit of a hidden cost you think well I'm just just pulling my application you don't realize well now",
    "start": "394430",
    "end": "400260"
  },
  {
    "text": "also deploying two or three maybe even four side car containers alongside each",
    "start": "400260",
    "end": "405630"
  },
  {
    "text": "of my one application containers and it becomes this hidden cost is hidden overhead they can stack up so don't",
    "start": "405630",
    "end": "412080"
  },
  {
    "text": "underestimate that make sure that if you are using side car containers they're very lightweight they're very efficient",
    "start": "412080",
    "end": "417990"
  },
  {
    "text": "size car containers and not heavy ones and if you can try to avoid side cars to",
    "start": "417990",
    "end": "423780"
  },
  {
    "text": "keep those paws as lightweight as possible if you're running something really requires blazing fast performance",
    "start": "423780",
    "end": "431360"
  },
  {
    "start": "430000",
    "end": "500000"
  },
  {
    "text": "now once you've optimized your paws let's look take a look at pot placement so this is controlling how that Pug is",
    "start": "431360",
    "end": "439170"
  },
  {
    "text": "distributed across their cluster and one of the first tools that you have in order to do that is resource constraints",
    "start": "439170",
    "end": "445430"
  },
  {
    "text": "so resource constraints allow you to set what your intended average utilization",
    "start": "445430",
    "end": "451230"
  },
  {
    "text": "of resources such as CPU and memory are for that pod and you can put an upper",
    "start": "451230",
    "end": "456240"
  },
  {
    "text": "limit on how many resources you want that pod to be able to reach up to without going over the reason why this",
    "start": "456240",
    "end": "462450"
  },
  {
    "text": "is important is because when you're running a busy kubernetes cluster that has a lot of different services perhaps",
    "start": "462450",
    "end": "467610"
  },
  {
    "text": "multiple different types of services you don't want to run the risk that one PI is going to start starving the other",
    "start": "467610",
    "end": "474390"
  },
  {
    "text": "paws by using up all the CPU on a box because that's a major performance killer so using limits on and requests",
    "start": "474390",
    "end": "484380"
  },
  {
    "text": "within your pod will guarantee not only that your application pod has this baseline level of resources that it",
    "start": "484380",
    "end": "490650"
  },
  {
    "text": "requires but also that it can't intrude and take resources from other pots that may be running co-located on a host in",
    "start": "490650",
    "end": "498960"
  },
  {
    "text": "the cluster now related to this it's important to take a look at the density",
    "start": "498960",
    "end": "504600"
  },
  {
    "start": "500000",
    "end": "606000"
  },
  {
    "text": "of your pods so if you look at these two different configurations you'll notice that on the left-hand side we're running four copies",
    "start": "504600",
    "end": "510930"
  },
  {
    "text": "of a pod each with half a CPU and 256 megabytes of memory on the right we're",
    "start": "510930",
    "end": "517200"
  },
  {
    "text": "running two copies of the same pod but each with one CPU in 512 megabytes of memory and if you do the math in both",
    "start": "517200",
    "end": "525630"
  },
  {
    "text": "scenarios the application as a whole is has access to the same amount of",
    "start": "525630",
    "end": "530820"
  },
  {
    "text": "resources overall but the difference is how those resources are carved up and distributed and the number of paws that",
    "start": "530820",
    "end": "537510"
  },
  {
    "text": "are using those resources now the reason why this is important is that some runtimes actually function better when",
    "start": "537510",
    "end": "543630"
  },
  {
    "text": "you give them more and more resources some runtimes function better when you run more copies and more processes in",
    "start": "543630",
    "end": "550650"
  },
  {
    "text": "parallel with each other but with a fewer amount of resources in particular we tend to see this with interpreted",
    "start": "550650",
    "end": "556680"
  },
  {
    "text": "languages in languages that have a garbage collector loop a lot of times for example if you have a node.js",
    "start": "556680",
    "end": "561900"
  },
  {
    "text": "application it'll function really well if you give it one CPU if you try to give it to three CPUs it's a single",
    "start": "561900",
    "end": "569460"
  },
  {
    "text": "threaded event loop basically so it may be able to use slightly more than one",
    "start": "569460",
    "end": "574650"
  },
  {
    "text": "one CPU for background threads but it's not really going to be able to make full",
    "start": "574650",
    "end": "580170"
  },
  {
    "text": "use if you just give it one process running on a large box or with a large amount of CPU and in fact the more",
    "start": "580170",
    "end": "586950"
  },
  {
    "text": "requests that you throw into an interpreted language that is that dynamically typed a lot of times you'll",
    "start": "586950",
    "end": "592380"
  },
  {
    "text": "see the garbage collector pressure builds up and performance starts to suffer and in that scenario you may",
    "start": "592380",
    "end": "598320"
  },
  {
    "text": "choose instead to run multiple small pods so that way each of them has less",
    "start": "598320",
    "end": "604050"
  },
  {
    "text": "garbage collector pressure another tool in your toolbox for optimizing your",
    "start": "604050",
    "end": "609900"
  },
  {
    "start": "606000",
    "end": "684000"
  },
  {
    "text": "kubernetes performance as anti affinity so anti finis constraints what they allow you to do is keep heavy CPU using",
    "start": "609900",
    "end": "617910"
  },
  {
    "text": "pause away from each other so they don't interfere with each other you may choose to say I would like my web pod which is",
    "start": "617910",
    "end": "625590"
  },
  {
    "text": "maybe hosting and delivering my webpage to be separate from my API tier which is",
    "start": "625590",
    "end": "631110"
  },
  {
    "text": "the background tier of my application just in case heavy CPU spikes on one it",
    "start": "631110",
    "end": "636270"
  },
  {
    "text": "won't have the chance of interfering with my other processes that they're running a different tier of my",
    "start": "636270",
    "end": "642960"
  },
  {
    "text": "application now one warning about this is that pre kubernetes 1.12 and these anti fannie rules so they put",
    "start": "642960",
    "end": "649920"
  },
  {
    "text": "a major burden on the control plan itself especially in a large cluster with a lot of different pause because",
    "start": "649920",
    "end": "655530"
  },
  {
    "text": "it's not very well optimized it has to go in and query every machine and find out the list of pods that will be fixed",
    "start": "655530",
    "end": "662670"
  },
  {
    "text": "and cabarets one one twelve once you upgrade and you'll get a hundred times performance on that but even if you're",
    "start": "662670",
    "end": "668579"
  },
  {
    "text": "not running could raise 1.12 yet you will maybe find that there's a there's a good trade-off there that the anti",
    "start": "668579",
    "end": "674910"
  },
  {
    "text": "affiliate rule gives you more benefit than it will load on the control plane especially if you don't have a lot of",
    "start": "674910",
    "end": "681570"
  },
  {
    "text": "churn and your cholesterol a lot of turnover of pods so once you optimize",
    "start": "681570",
    "end": "687089"
  },
  {
    "start": "684000",
    "end": "768000"
  },
  {
    "text": "your pause and you you set up all these different rules like the anti affinity and the resource constraints it's",
    "start": "687089",
    "end": "692310"
  },
  {
    "text": "important to actually observe the performance and make sure that everything is behaving as you expect so",
    "start": "692310",
    "end": "698279"
  },
  {
    "text": "I want show this diagram which is sort of the the graph of the overall map of",
    "start": "698279",
    "end": "703829"
  },
  {
    "text": "the tools that are available to you to monitor your performance you'll notice it all starts with a data model how",
    "start": "703829",
    "end": "710490"
  },
  {
    "text": "you're going to model those stats there's a very a variety of different sources of stats stats from the nodes",
    "start": "710490",
    "end": "716579"
  },
  {
    "text": "themselves such as how much CPU and memory and disk pressure are is on that",
    "start": "716579",
    "end": "722610"
  },
  {
    "text": "node for the individual individual pause and containers they have their own stats and your application itself may expose",
    "start": "722610",
    "end": "731250"
  },
  {
    "text": "different stats like if you know Jess you may build a hook into the garbage collector your stats Java you may be",
    "start": "731250",
    "end": "736949"
  },
  {
    "text": "able to use the jmx stats and get those out of your application now you don't want to take",
    "start": "736949",
    "end": "742019"
  },
  {
    "text": "all those stats give them into some sort of statistics aggregator you're going to be able to want to set up alerting on",
    "start": "742019",
    "end": "750329"
  },
  {
    "text": "those stats so if one of them spikes or goes over a certain threshold you establish your gonna want to know about that and it's also important to be able",
    "start": "750329",
    "end": "757709"
  },
  {
    "text": "to visualize those stats so later in the demo you're going to see graph on in action as one of the tools that will",
    "start": "757709",
    "end": "764190"
  },
  {
    "text": "help you to observe your performance within the cluster so looking at all the",
    "start": "764190",
    "end": "771870"
  },
  {
    "start": "768000",
    "end": "865000"
  },
  {
    "text": "pod optimizations they're possible let's look move to the next level which is the worker knows optimize your worker node",
    "start": "771870",
    "end": "779550"
  },
  {
    "text": "starts with making sure that you're on the latest generation of ec2 instance a lot of people they underestimate just",
    "start": "779550",
    "end": "786120"
  },
  {
    "text": "how much more performance for price do you get by moving to the latest generation and they'll end up sticking",
    "start": "786120",
    "end": "792089"
  },
  {
    "text": "around on an older version of an ec2 instance because they'd like well maybe",
    "start": "792089",
    "end": "797970"
  },
  {
    "text": "it's not worth the effort to my create my cluster over well it's definitely not true you'll actually find",
    "start": "797970",
    "end": "803459"
  },
  {
    "text": "out that the c5 instance that was released has 25 better 25% better price",
    "start": "803459",
    "end": "809009"
  },
  {
    "text": "performance than the C for instance that came before it and so what this means is that your application gets 25% faster",
    "start": "809009",
    "end": "816360"
  },
  {
    "text": "you can run maybe 25% more pods within that cluster so definitely make sure",
    "start": "816360",
    "end": "821759"
  },
  {
    "text": "you're running that latest generation of hardware and choose the hardware that",
    "start": "821759",
    "end": "827040"
  },
  {
    "text": "best fits the needs of your application stack in general you'll find out that the C instances there tend to be",
    "start": "827040",
    "end": "833399"
  },
  {
    "text": "optimized for heavy CPU load our instances are optimized for heavy heavy",
    "start": "833399",
    "end": "839069"
  },
  {
    "text": "memory usage em instances are just general purpose if you use memory and CPU or you have a mix of some workloads",
    "start": "839069",
    "end": "846089"
  },
  {
    "text": "that require lots of CPU and some require lots of memory and P instances are obviously optimized for GPU power",
    "start": "846089",
    "end": "853170"
  },
  {
    "text": "and machine learning so consider what you're running in the cluster and try to make sure that your closer is optimized to have an instance",
    "start": "853170",
    "end": "860910"
  },
  {
    "text": "that has the resources to your applications actually require now moving",
    "start": "860910",
    "end": "867630"
  },
  {
    "start": "865000",
    "end": "908000"
  },
  {
    "text": "on to the control plane the important thing to understand about EES is that the the cube radius control plane is",
    "start": "867630",
    "end": "873690"
  },
  {
    "text": "optimized by the EES team when you're using Amazon EPS and the way it works is",
    "start": "873690",
    "end": "878850"
  },
  {
    "text": "I'm able to set up my cube control command line tool and connect to a cluster endpoint that is hosted by",
    "start": "878850",
    "end": "885209"
  },
  {
    "text": "Amazon ETS and has a kubernetes control plane behind it and then I'm able to",
    "start": "885209",
    "end": "890790"
  },
  {
    "text": "provision my worker nodes and add them to that control plane and I'm",
    "start": "890790",
    "end": "896639"
  },
  {
    "text": "responsible for optimizing my application and the worker nodes but that control plan that's hidden behind that cluster endpoint is completely",
    "start": "896639",
    "end": "903389"
  },
  {
    "text": "hands-off for me and was on eks team is responsible for making sure that it performs well let's talk about some of",
    "start": "903389",
    "end": "909630"
  },
  {
    "start": "908000",
    "end": "980000"
  },
  {
    "text": "the ways that the EES team has optimized the kubernetes control plane for you on",
    "start": "909630",
    "end": "915120"
  },
  {
    "text": "ATS the first I want to introduce is the Amazon ADA base V PCC and I plug in and",
    "start": "915120",
    "end": "922160"
  },
  {
    "text": "really what this does is it allows your pods that are running your cluster to have native IP addresses attached to",
    "start": "922160",
    "end": "930060"
  },
  {
    "text": "elastic network interfaces in your BPC on your account the reason why this",
    "start": "930060",
    "end": "935690"
  },
  {
    "text": "is important is that it creates a very thin layer that has almost no overhead",
    "start": "935690",
    "end": "940700"
  },
  {
    "text": "when one pod needs to talk to another pod in the cluster there are other ways to do this with network overlays but",
    "start": "940700",
    "end": "947210"
  },
  {
    "text": "they tend to be software overlays that run on the instances and there's going to be extra components in the middle",
    "start": "947210",
    "end": "954680"
  },
  {
    "text": "that are handling that traffic and routing it and adding overhead and adding extra milliseconds of or",
    "start": "954680",
    "end": "960680"
  },
  {
    "text": "microseconds of latency so with the VPC cni plugin that all goes away because",
    "start": "960680",
    "end": "968420"
  },
  {
    "text": "you have a real network interface that gets attached here ec2 instance the pod",
    "start": "968420",
    "end": "973610"
  },
  {
    "text": "is mapped to that and then the Pau is able to talk to another pod using a real IP address that lives in that VPC so",
    "start": "973610",
    "end": "981020"
  },
  {
    "start": "980000",
    "end": "1007000"
  },
  {
    "text": "here's how it works I have pod on one machine and it has its own route table and elastic network",
    "start": "981020",
    "end": "988280"
  },
  {
    "text": "interface it communicates outfit at elastic network interface through directly through the VPC fabric I don't",
    "start": "988280",
    "end": "995000"
  },
  {
    "text": "have any other appliances or things sitting there in the middle and then it",
    "start": "995000",
    "end": "1000160"
  },
  {
    "text": "goes directly into the elastic network interface of the other pod and to the pod that's actually running on that",
    "start": "1000160",
    "end": "1005950"
  },
  {
    "text": "machine now when we talk about the community's control plane I want you to",
    "start": "1005950",
    "end": "1011260"
  },
  {
    "start": "1007000",
    "end": "1089000"
  },
  {
    "text": "think about the conveys performance envelope there's a lot of different factors that go into performance of your",
    "start": "1011260",
    "end": "1018100"
  },
  {
    "text": "community's cluster and in particular performance of the control plan and you'll see that some of the major ones",
    "start": "1018100",
    "end": "1023320"
  },
  {
    "text": "are the number of nodes in your cluster off so the more machines that you put into your cluster the more burden the",
    "start": "1023320",
    "end": "1029079"
  },
  {
    "text": "cluster is going to be under keeping track of all of those machines and their states the number of active namespaces",
    "start": "1029080",
    "end": "1035230"
  },
  {
    "text": "that you use is also a contributing factor the amount that you have pod",
    "start": "1035230",
    "end": "1040810"
  },
  {
    "text": "churn and what I mean by that is pause the exit and then maybe get restarted or",
    "start": "1040810",
    "end": "1046180"
  },
  {
    "text": "very short-lived pods or you have a very busy CI CV pipeline we're constantly pushing out new updates that cause pause",
    "start": "1046180",
    "end": "1053830"
  },
  {
    "text": "to be rolled out pod density so what this means is how many pause are you",
    "start": "1053830",
    "end": "1059230"
  },
  {
    "text": "stuffing on to each node networking obviously the ATIS CNI plugin is",
    "start": "1059230",
    "end": "1065020"
  },
  {
    "text": "designed to have a fear a low networking overhead but somewhere you're still gonna have to keep track of",
    "start": "1065020",
    "end": "1070780"
  },
  {
    "text": "all of those pause and that ends up being the IP tables and that puts extra burden on your kubernetes cluster anti",
    "start": "1070780",
    "end": "1078520"
  },
  {
    "text": "affinity as we mentioned before pre-k is 1.12 anti fermium rules can put a major",
    "start": "1078520",
    "end": "1083710"
  },
  {
    "text": "burden on your cluster particularly if they're combined with that high pod trim and secrets now let's look at a couple",
    "start": "1083710",
    "end": "1091060"
  },
  {
    "start": "1089000",
    "end": "1167000"
  },
  {
    "text": "different scenarios in this scenario we're running heavy model ethic pods in a very large cluster and what I mean by",
    "start": "1091060",
    "end": "1097150"
  },
  {
    "text": "that is maybe we're running a pod which is almost the same size or actually the",
    "start": "1097150",
    "end": "1102640"
  },
  {
    "text": "very same size as the instance so in some cases customers come to us and they",
    "start": "1102640",
    "end": "1107680"
  },
  {
    "text": "have a monolithic application they're not quite ready to move to micro services and so really what they or you",
    "start": "1107680",
    "end": "1113350"
  },
  {
    "text": "want to use kubernetes for is to distribute this monolithic pod to a",
    "start": "1113350",
    "end": "1118690"
  },
  {
    "text": "large cluster of instances and just use it as a mechanism for rolling that that application out to the cluster and so",
    "start": "1118690",
    "end": "1124720"
  },
  {
    "text": "they're running one giant pod for instance but they have a very large number of instances and so in that case the performance envelope is going to",
    "start": "1124720",
    "end": "1131290"
  },
  {
    "text": "look something like this that number of nodes is going to be a major contributing factor particularly if you have thousands or even tens of thousands",
    "start": "1131290",
    "end": "1137920"
  },
  {
    "text": "of nodes we would like to run you may notice that kubernetes has some guidelines on how many nodes the",
    "start": "1137920",
    "end": "1144340"
  },
  {
    "text": "kubernetes control plane is capable of handling and ets team is constantly",
    "start": "1144340",
    "end": "1149410"
  },
  {
    "text": "trying to push that for the next level particularly for our customers that have very large number of nodes need to run",
    "start": "1149410",
    "end": "1154510"
  },
  {
    "text": "and in that case with a large number of knows comes a large anti Fannie burden",
    "start": "1154510",
    "end": "1160720"
  },
  {
    "text": "if you happen to be running multiple different types of positive the same size as a node now the picture changes",
    "start": "1160720",
    "end": "1168640"
  },
  {
    "start": "1167000",
    "end": "1231000"
  },
  {
    "text": "if we have to be running micro service pods there bin packed on two nodes in",
    "start": "1168640",
    "end": "1174550"
  },
  {
    "text": "that case perhaps this is a a startup has really gone all-in on micro services",
    "start": "1174550",
    "end": "1180190"
  },
  {
    "text": "and so they have very intense pod density that they're running micro services that have maybe a quarter of a",
    "start": "1180190",
    "end": "1186070"
  },
  {
    "text": "CPU per micro service and but they're running many of them so they're running instances that have 2030 pods per",
    "start": "1186070",
    "end": "1193090"
  },
  {
    "text": "instance and because it's not a monolithic application there's more crosstalk between services so it's going",
    "start": "1193090",
    "end": "1199539"
  },
  {
    "text": "a lot more networking overhead there can be a lot more items in that pod IP table lookup and with micro services there",
    "start": "1199539",
    "end": "1207639"
  },
  {
    "text": "tends to come a lot more pod turn as well because micro services learn themselves well - CID CSTB pipelines",
    "start": "1207639",
    "end": "1214749"
  },
  {
    "text": "where people are constantly updating the code and pushing out new versions of stuff so this is going to create a",
    "start": "1214749",
    "end": "1219820"
  },
  {
    "text": "different type of load on the kubernetes control plane so we consider these two",
    "start": "1219820",
    "end": "1224889"
  },
  {
    "text": "different scenarios you'll see that optimizing the control plane is not a one-size-fits-all solution",
    "start": "1224889",
    "end": "1231090"
  },
  {
    "text": "fortunately the Amazon ETS team is here to help you optimize your control plane to your specific needs so we're",
    "start": "1231090",
    "end": "1237999"
  },
  {
    "text": "constantly constantly learning and adjusting our models and our techniques for optimizing kubernetes control plane",
    "start": "1237999",
    "end": "1244119"
  },
  {
    "text": "to your specific needs and we're here to",
    "start": "1244119",
    "end": "1249399"
  },
  {
    "text": "help you if you run into an issue with your kubernetes control plane where you feel like you should be able to get more performance where you want to push one",
    "start": "1249399",
    "end": "1255369"
  },
  {
    "text": "of those limits definitely reach out to the ETS team via support ticket they're happy to look into your crew branch",
    "start": "1255369",
    "end": "1261999"
  },
  {
    "text": "cluster and determine the exact performance needs and tune it to those",
    "start": "1261999",
    "end": "1267729"
  },
  {
    "text": "needs so let's move on now to the demo from State Street get case' from state",
    "start": "1267729",
    "end": "1274570"
  },
  {
    "text": "tree is going to show a high performance database running on Amazon EKF Thank You",
    "start": "1274570",
    "end": "1279879"
  },
  {
    "text": "Nitin [Applause]",
    "start": "1279879",
    "end": "1285880"
  },
  {
    "text": "how you guys doing good conference what's your favorite part",
    "start": "1287880",
    "end": "1294510"
  },
  {
    "text": "Cuban it is okay I love this deep race",
    "start": "1294510",
    "end": "1299530"
  },
  {
    "text": "the toy that's my Christmas present if I can order one and get one before the time I can't wait to wrap my hands around",
    "start": "1299530",
    "end": "1307270"
  },
  {
    "text": "this I'm from State Street my name is ELISA and here is a quick disclaimer what this means is the opinions",
    "start": "1307270",
    "end": "1313930"
  },
  {
    "text": "expressed here are my own and the party state she does a company does not endorse any products that I may present",
    "start": "1313930",
    "end": "1321450"
  },
  {
    "text": "all right so I was skeptical at first",
    "start": "1321450",
    "end": "1327390"
  },
  {
    "text": "when I started looking at deploying databases to Cuba ladies kubernetes was",
    "start": "1327390",
    "end": "1335320"
  },
  {
    "text": "originally promoted for stateless applications so and the databases are a",
    "start": "1335320",
    "end": "1342120"
  },
  {
    "text": "complex state machine so how do you fit the most complex state machine on to a",
    "start": "1342120",
    "end": "1348760"
  },
  {
    "text": "completely stateless system at least up until 0.51 six cuban it is that's where",
    "start": "1348760",
    "end": "1354490"
  },
  {
    "text": "I started so I'm gonna walk you through what we did how we did it and why we did",
    "start": "1354490",
    "end": "1359830"
  },
  {
    "text": "it and I'm going to touch upon some of the best practices that we learned along",
    "start": "1359830",
    "end": "1365500"
  },
  {
    "text": "the way and then I'm going to show you some of the impediments we run into and how did we overcome to put my skepticism",
    "start": "1365500",
    "end": "1374230"
  },
  {
    "text": "to test we decide we plan the demo for you right and what you're gonna do is if",
    "start": "1374230",
    "end": "1379750"
  },
  {
    "text": "you can help us with all push the database very hard so hard and let's see",
    "start": "1379750",
    "end": "1385330"
  },
  {
    "text": "if it can actually do a million queries per second I don't know what it can do but let's figure that out alright so",
    "start": "1385330",
    "end": "1393730"
  },
  {
    "start": "1392000",
    "end": "1489000"
  },
  {
    "text": "what and why I'll keep this very simple what is what we intended to do was to",
    "start": "1393730",
    "end": "1399550"
  },
  {
    "text": "build a transactional database transactional database that can scale unlimited see there's a lot of managed",
    "start": "1399550",
    "end": "1407320"
  },
  {
    "text": "databases there's commercial database vendors there's a lot of solutions out there so why are you building a database",
    "start": "1407320",
    "end": "1413920"
  },
  {
    "text": "is a very common question I get well you got a scale unlimited and",
    "start": "1413920",
    "end": "1419190"
  },
  {
    "text": "cost-effectively right and a lot of the databases have some problem somewhere",
    "start": "1419190",
    "end": "1425130"
  },
  {
    "text": "whether it's right through port or single master or you know there's many kinds of different limitations that you",
    "start": "1425130",
    "end": "1431100"
  },
  {
    "text": "experience so we wanted to break through those barriers and have a system that",
    "start": "1431100",
    "end": "1436410"
  },
  {
    "text": "can scale unlimited with high concurrency and low latencies okay and",
    "start": "1436410",
    "end": "1443160"
  },
  {
    "text": "then we wanted to be open source because financial workloads can certainly",
    "start": "1443160",
    "end": "1448500"
  },
  {
    "text": "leverage deep analytics within the database and a lot of the general-purpose databases aren't there",
    "start": "1448500",
    "end": "1455790"
  },
  {
    "text": "yet but we want to get the basics right so the foundations are running solid then we start to go inside the deeper",
    "start": "1455790",
    "end": "1462690"
  },
  {
    "text": "inside the engine that's the intent okay so and then we wanted to embrace the",
    "start": "1462690",
    "end": "1469230"
  },
  {
    "text": "cloud native architecture so you can quickly recover from failures and you",
    "start": "1469230",
    "end": "1475350"
  },
  {
    "text": "know if you can imagine if you can create a database that can recover",
    "start": "1475350",
    "end": "1480600"
  },
  {
    "text": "quickly then you can you know then the you know you can deploy this to cloud at",
    "start": "1480600",
    "end": "1486210"
  },
  {
    "text": "scale so the cover is not an issue I just want to spend a minute or two",
    "start": "1486210",
    "end": "1492240"
  },
  {
    "start": "1489000",
    "end": "1622000"
  },
  {
    "text": "brushing to the high-level database basics so you can appreciate the complexities involved in this database",
    "start": "1492240",
    "end": "1498300"
  },
  {
    "text": "system most of you might be familiar with an architecture like this right",
    "start": "1498300",
    "end": "1504330"
  },
  {
    "text": "this is 10 15 20 year old architecture why am i showing that I just want to highlight some of the complexities",
    "start": "1504330",
    "end": "1510930"
  },
  {
    "text": "involved and how we might map those complexities to Cuban ladies the",
    "start": "1510930",
    "end": "1516720"
  },
  {
    "text": "master/slave architecture there's a master and then that's where you write to and then it replicates down to its",
    "start": "1516720",
    "end": "1524790"
  },
  {
    "text": "slaves right and then you can use any database engine if those of you who are",
    "start": "1524790",
    "end": "1530310"
  },
  {
    "text": "familiar with MySQL there's a nerdy bead is my I am there's many database engines",
    "start": "1530310",
    "end": "1536190"
  },
  {
    "text": "out there I like rocks DB rocks TB comes from Facebook it's a predecessor to not",
    "start": "1536190",
    "end": "1543090"
  },
  {
    "text": "very successor to level DB and this works really well for write intensive",
    "start": "1543090",
    "end": "1548970"
  },
  {
    "text": "workloads because of its LSM data structure which is highly after it takes every single update and",
    "start": "1548970",
    "end": "1555390"
  },
  {
    "text": "converts it into a an append-only right and it also consumes very little memory",
    "start": "1555390",
    "end": "1562380"
  },
  {
    "text": "and I will show you that in the demo so for those reasons I actually like rocks",
    "start": "1562380",
    "end": "1567510"
  },
  {
    "text": "DB you can use Marya DB or core kana which are both open-source databases I haven't listed mysql here because",
    "start": "1567510",
    "end": "1574770"
  },
  {
    "text": "mysql does not support rocks DB and you can use pretty much any of the other",
    "start": "1574770",
    "end": "1580370"
  },
  {
    "text": "mysql standard features those of you who understand this synchronous semi",
    "start": "1580370",
    "end": "1585930"
  },
  {
    "text": "synchronous replication all those features are fully you know you can leverage them alright so cloud native",
    "start": "1585930",
    "end": "1593460"
  },
  {
    "text": "i'm going to just touch a little bit on this one so what this means is if you look at any given database instance",
    "start": "1593460",
    "end": "1600270"
  },
  {
    "text": "that's the zooming into the database instance you have a percona layer on the top writing through my rocks into rocks",
    "start": "1600270",
    "end": "1607800"
  },
  {
    "text": "DB rocks DB is the one that is generating the data files the SSD files",
    "start": "1607800",
    "end": "1614660"
  },
  {
    "text": "that are then synchronized into s3 for recovery purpose okay alright so the",
    "start": "1614660",
    "end": "1624810"
  },
  {
    "start": "1622000",
    "end": "1813000"
  },
  {
    "text": "picture that I showed you in the last slide is a master square scale the",
    "start": "1624810",
    "end": "1630120"
  },
  {
    "text": "typical issues you have in that architecture is to scale out the reads you add more slaves but to scale out the",
    "start": "1630120",
    "end": "1637980"
  },
  {
    "text": "writes you do what nothing right in that architecture diagram you are limited by",
    "start": "1637980",
    "end": "1643500"
  },
  {
    "text": "what one writer can do so I went looking for solutions so if you think about how",
    "start": "1643500",
    "end": "1651000"
  },
  {
    "text": "key value stores have done it they've done it they came up with the sharding mechanisms so if you envision each",
    "start": "1651000",
    "end": "1658110"
  },
  {
    "text": "master slaves is a shard you just keep on adding shards to get the scale up and",
    "start": "1658110",
    "end": "1665060"
  },
  {
    "text": "this exactly what we test does we test is an open source from YouTube Google",
    "start": "1665060",
    "end": "1672510"
  },
  {
    "text": "and it won't works wonderfully in the scalar adoption and it's acid compliant",
    "start": "1672510",
    "end": "1678300"
  },
  {
    "text": "I I highlighted it as in yellow because it's kind of there is some trade-offs that you need to know if you're",
    "start": "1678300",
    "end": "1684630"
  },
  {
    "text": "interested in exploring that the system has been deployed here on an Amazon s3 and he cares so when a",
    "start": "1684630",
    "end": "1693780"
  },
  {
    "text": "transaction comes from the end-user it goes to these two architectural elements here that are important one is VT gate",
    "start": "1693780",
    "end": "1700980"
  },
  {
    "text": "the other one is VT tablet with it somebody has to assume routing decisions when you have sharded databases and",
    "start": "1700980",
    "end": "1708330"
  },
  {
    "text": "that's the VT gate it's like a router and then we T tablet wraps the database",
    "start": "1708330",
    "end": "1714900"
  },
  {
    "text": "instances it does many things like taking continuous backups continuous recovery because if you have never",
    "start": "1714900",
    "end": "1721860"
  },
  {
    "text": "tested your backup god only knows if it actually works so this system actually does continuous backups and continuous",
    "start": "1721860",
    "end": "1728670"
  },
  {
    "text": "recovery and then it also prevents if you want you can prevent heavy duty",
    "start": "1728670",
    "end": "1733980"
  },
  {
    "text": "queries from hitting oil DP systems all TP systems are latency sensitive you",
    "start": "1733980",
    "end": "1740340"
  },
  {
    "text": "cannot take a long time to respond because guess what the user is waiting it's not an analytic system so if you",
    "start": "1740340",
    "end": "1747540"
  },
  {
    "text": "want to prevent analytics systems or queries hitting hard on oil DP systems",
    "start": "1747540",
    "end": "1753930"
  },
  {
    "text": "you can put in some protections all right so and then when a transaction",
    "start": "1753930",
    "end": "1760020"
  },
  {
    "text": "comes in the master forwards it on to these slaves for the application purpose let's take a pause and look at the",
    "start": "1760020",
    "end": "1766320"
  },
  {
    "text": "complexities in this in this diagram there's many points of failure here right there's many many parts running",
    "start": "1766320",
    "end": "1773690"
  },
  {
    "text": "slaves can go masters can die the router letters can die the backups that are go",
    "start": "1773690",
    "end": "1781920"
  },
  {
    "text": "happening back into the s3 they can fail at any time so this is a very complex",
    "start": "1781920",
    "end": "1787770"
  },
  {
    "text": "state machine right there's east-west traffic masters talking to slaves and",
    "start": "1787770",
    "end": "1795380"
  },
  {
    "text": "routers talking to the different shards there's not so traffic so parts talking",
    "start": "1795380",
    "end": "1801930"
  },
  {
    "text": "apart and then clients talking to base system so now let's figure out how we'd",
    "start": "1801930",
    "end": "1810000"
  },
  {
    "text": "build this and Kuban it is I start with the very basics their bases",
    "start": "1810000",
    "end": "1818159"
  },
  {
    "text": "have state persistence right you're storing some data it needs to be persisted somewhere and that's where the",
    "start": "1818159",
    "end": "1824580"
  },
  {
    "text": "storage comes in we leverage persistent volumes to store the data when I'm",
    "start": "1824580",
    "end": "1831299"
  },
  {
    "text": "talking about data this is the data files the database creates on you know when your ins doing inserts and and all",
    "start": "1831299",
    "end": "1838500"
  },
  {
    "text": "that so it's the data is going somewhere that's the storage so we leverage the combination of PV persistent volumes and",
    "start": "1838500",
    "end": "1845700"
  },
  {
    "text": "persistent volume claims to abstract the low-level details cluster administrators",
    "start": "1845700",
    "end": "1853460"
  },
  {
    "text": "configure the file systems and other low-level things and we just submit",
    "start": "1853460",
    "end": "1859139"
  },
  {
    "text": "claims to get the storage we want you request the access mode and amount of",
    "start": "1859139",
    "end": "1865350"
  },
  {
    "text": "storage you want to the PV claims there's several ways to attach a data",
    "start": "1865350",
    "end": "1871799"
  },
  {
    "text": "contain data volume to your pod one is embed visit the container or the pod",
    "start": "1871799",
    "end": "1877799"
  },
  {
    "text": "the problem with this one there is no resiliency if you take the container down for whatever purpose you want to",
    "start": "1877799",
    "end": "1884429"
  },
  {
    "text": "batch the software update the configuration you lost the data when you have daily basis at scale you don't want",
    "start": "1884429",
    "end": "1891450"
  },
  {
    "text": "to lose the data so quickly so you want to have little bit persistence so one",
    "start": "1891450",
    "end": "1896789"
  },
  {
    "text": "option is to store the persistent volume outside the part so it can survive pod",
    "start": "1896789",
    "end": "1902639"
  },
  {
    "text": "restarts that's the now this is medium resiliency because at least now you have the",
    "start": "1902639",
    "end": "1909299"
  },
  {
    "text": "ability to recycle the pod but and it gives you the best performance because",
    "start": "1909299",
    "end": "1914340"
  },
  {
    "text": "it's local persistent volume it gives you the best performance now there's also a third option which is a",
    "start": "1914340",
    "end": "1920250"
  },
  {
    "text": "cloud-based volumes EBS and FS now this thing is another option if you want for",
    "start": "1920250",
    "end": "1926700"
  },
  {
    "text": "some applications it may work great your mileage may vary for databases this is not the option I choose I choose the",
    "start": "1926700",
    "end": "1933269"
  },
  {
    "text": "middle one I'm not so worried about the resiliency because I got master slaves so I got data on other nodes too how",
    "start": "1933269",
    "end": "1942210"
  },
  {
    "start": "1941000",
    "end": "2249000"
  },
  {
    "text": "else can we get the moisture to the kubernetes system paints and toleration czar the first thing when you're running",
    "start": "1942210",
    "end": "1947789"
  },
  {
    "text": "databases you want predictable performance right very reliable performance if a query",
    "start": "1947789",
    "end": "1953280"
  },
  {
    "text": "does milliseconds today and takes minutes tomorrow you're not going to have happy customers you got to make",
    "start": "1953280",
    "end": "1958590"
  },
  {
    "text": "sure that the delivering consistent performance so one way to do it is of course paint the nodes in other words",
    "start": "1958590",
    "end": "1965400"
  },
  {
    "text": "you are thus allowing or not allowing other applications from deploying to",
    "start": "1965400",
    "end": "1971790"
  },
  {
    "text": "your cluster you can carve out a subset of your cluster and through taints and",
    "start": "1971790",
    "end": "1977370"
  },
  {
    "text": "toleration z' and deploy your application in the databases to adjust that subset of nodes this is where the",
    "start": "1977370",
    "end": "1983970"
  },
  {
    "text": "know definitely comes in by attaching labels you can pick and choose where you want to deploy now for example by",
    "start": "1983970",
    "end": "1991350"
  },
  {
    "text": "painting the nodes you can use either cube cuttle commands or eks supports",
    "start": "1991350",
    "end": "1996960"
  },
  {
    "text": "Packer scripts bootstrap scripts you can put the comments inside those scripts to",
    "start": "1996960",
    "end": "2002060"
  },
  {
    "text": "taint the node affinity is applies at two levels part affinity node affinity",
    "start": "2002060",
    "end": "2007580"
  },
  {
    "text": "part affinity is if you have a client who is generating a lot of writes into",
    "start": "2007580",
    "end": "2013370"
  },
  {
    "text": "this database you might want to co-host them together so you avoid some of the the network communication or overheads",
    "start": "2013370",
    "end": "2019940"
  },
  {
    "text": "so that's part of it the node affinity is I might want to deploy the databases only to assess the",
    "start": "2019940",
    "end": "2027380"
  },
  {
    "text": "machines right not all machines might have SSDs on them and the affinity is",
    "start": "2027380",
    "end": "2033470"
  },
  {
    "text": "just as useful I don't want to deploy master and slave on the same node why",
    "start": "2033470",
    "end": "2039470"
  },
  {
    "text": "because if a Nord goes down then I lost a significant chunk of the database in the master slave architecture so you can",
    "start": "2039470",
    "end": "2047750"
  },
  {
    "text": "you have lots of bells and whistles to play with this to give you a very controlled environment and then the",
    "start": "2047750",
    "end": "2054139"
  },
  {
    "text": "services this is the class type in Northport and we're going to touch on this one later on during the demo",
    "start": "2054140",
    "end": "2060220"
  },
  {
    "text": "resource requests and limits this is as",
    "start": "2060220",
    "end": "2066020"
  },
  {
    "text": "a database guy I'd like to have two I would like to be able to burst up CPU",
    "start": "2066020",
    "end": "2071990"
  },
  {
    "text": "memories and stuff like that right so I don't want to put limits on the database database is delivering a very critical",
    "start": "2071990",
    "end": "2079450"
  },
  {
    "text": "you know system right so you don't want to put any limits on this one but if you don't have that luxury then you might",
    "start": "2079450",
    "end": "2086500"
  },
  {
    "text": "want to use two limits to your advantage and limits apply to both CPUs and memory",
    "start": "2086500",
    "end": "2092829"
  },
  {
    "text": "they work a little differently when you put in a limit at the CPU level it's called compressible what that means is",
    "start": "2092829",
    "end": "2099900"
  },
  {
    "text": "if you exceed that limit the system will throttle you",
    "start": "2099900",
    "end": "2105400"
  },
  {
    "text": "it won't stop you it'll throttle you with memory if you put a limit and you exceed the limit it'll kick you out",
    "start": "2105400",
    "end": "2112210"
  },
  {
    "text": "you're evicted so be careful when you choose these things and you may also look at what's the how is the system the",
    "start": "2112210",
    "end": "2119410"
  },
  {
    "text": "northen figured if there's lots of requests and limits you can look at under the conditions of the each node to",
    "start": "2119410",
    "end": "2126880"
  },
  {
    "text": "see what the limit how the limits and requests have been set up already so you",
    "start": "2126880",
    "end": "2132730"
  },
  {
    "text": "can get a sense if the system is already overloaded right you don't have to panic",
    "start": "2132730",
    "end": "2138550"
  },
  {
    "text": "if it was over 100 percent it doesn't mean that that's how that's the utilization it just shows you what each",
    "start": "2138550",
    "end": "2144490"
  },
  {
    "text": "person that's deploying to this cluster is requesting this ETL this is a you",
    "start": "2144490",
    "end": "2151390"
  },
  {
    "text": "know whole bunch of Linux kernel level optimizations that you might apply you can still do that of course this is",
    "start": "2151390",
    "end": "2157060"
  },
  {
    "text": "limited to worker nodes and so those are the kind of performance you know",
    "start": "2157060",
    "end": "2162430"
  },
  {
    "text": "whatever makes sense to you I got a whole bunch of recommendations on the CCT l but it may not be generally",
    "start": "2162430",
    "end": "2168970"
  },
  {
    "text": "transferable but you know I'm happy to share stateful sets operators and demon sets are not",
    "start": "2168970",
    "end": "2174609"
  },
  {
    "text": "directly a performance related but I'm going to touch upon that very high level so stateful set is a successor to",
    "start": "2174609",
    "end": "2181420"
  },
  {
    "text": "replica set and it's all some important key problems but it also has some limitations the limitations are if you",
    "start": "2181420",
    "end": "2188829"
  },
  {
    "text": "have to recover a system like the master slave that I just showed you the master",
    "start": "2188829",
    "end": "2194310"
  },
  {
    "text": "here when the master dies if you had then you had to look across all your slaves to figure out which one you're",
    "start": "2194310",
    "end": "2200890"
  },
  {
    "text": "going to promote you can't make a random decision there's like four different things that you've got to do before you",
    "start": "2200890",
    "end": "2206800"
  },
  {
    "text": "say yeah this is the guy I want to promote to the man next master so stateful sets don't have",
    "start": "2206800",
    "end": "2213170"
  },
  {
    "text": "capability so this is where the operator comes in right operator is your custom",
    "start": "2213170",
    "end": "2218990"
  },
  {
    "text": "controller you feed the CRD custom resource definition and it will set up",
    "start": "2218990",
    "end": "2225470"
  },
  {
    "text": "an ecosystem of whatever you need services you need but it also can track the recovery if you if you have to do",
    "start": "2225470",
    "end": "2232790"
  },
  {
    "text": "some complex recovery of the system daemon sets is typically used for your",
    "start": "2232790",
    "end": "2239150"
  },
  {
    "text": "monitoring right so I'll show you in the demo that we are using daemon sets for",
    "start": "2239150",
    "end": "2244819"
  },
  {
    "text": "Prometheus pumping metrics into prometheus some of the best practices",
    "start": "2244819",
    "end": "2251450"
  },
  {
    "start": "2249000",
    "end": "2619000"
  },
  {
    "text": "that we've learned of course you got to keep your container lean and mean right that's the get the gunk out of there",
    "start": "2251450",
    "end": "2258650"
  },
  {
    "text": "like Nathan already talked about you know Alpine is a good choice if you want to use that UK's optimized AMI it comes",
    "start": "2258650",
    "end": "2266329"
  },
  {
    "text": "it's on Linux too and enas and all that built in so take advantage of that image",
    "start": "2266329",
    "end": "2272000"
  },
  {
    "text": "pool policy you want to spend some time thinking about this especially if you're gonna if you're planning large-scale",
    "start": "2272000",
    "end": "2277760"
  },
  {
    "text": "clusters you don't know where you will be throttled so test this out think about it ahead of time how you're gonna",
    "start": "2277760",
    "end": "2283970"
  },
  {
    "text": "roll this out the next two points are typical database recommendations you",
    "start": "2283970",
    "end": "2290750"
  },
  {
    "text": "want to run masters on on on SSDs because you want that trooper you want",
    "start": "2290750",
    "end": "2296420"
  },
  {
    "text": "that performance so that's what I recommend and for the slaves if you are",
    "start": "2296420",
    "end": "2301910"
  },
  {
    "text": "using semi synchronous replication what that basically means is when you have a transaction coming you want that",
    "start": "2301910",
    "end": "2309140"
  },
  {
    "text": "transaction to be replicated at least on another slave before the transaction is acknowledged to the client that's called",
    "start": "2309140",
    "end": "2316520"
  },
  {
    "text": "semi synchronous replication and in MySQL and if you use that then this",
    "start": "2316520",
    "end": "2322280"
  },
  {
    "text": "slave has to run at the same speed as the master so for that purpose you",
    "start": "2322280",
    "end": "2327380"
  },
  {
    "text": "should pick symmetric Hardware but if you want increase resiliency you can",
    "start": "2327380",
    "end": "2333109"
  },
  {
    "text": "also run some of the slaves on EBS attached to volumes so you'll get a little bit more resiliency and",
    "start": "2333109",
    "end": "2340510"
  },
  {
    "text": "monitoring of course is the key right otherwise you don't know how you know you're flying blind and",
    "start": "2340510",
    "end": "2348880"
  },
  {
    "text": "then the other scalars there's three times they're all making sure that you",
    "start": "2348880",
    "end": "2354490"
  },
  {
    "text": "have enough resources in the system cluster are the scaler is making sure that you have enough easy to work nodes",
    "start": "2354490",
    "end": "2361380"
  },
  {
    "text": "horizontal part autoscaler works at the part level or the scaling up and down",
    "start": "2361380",
    "end": "2366540"
  },
  {
    "text": "vertical part are the scaler this is coming I don't think it is supported by",
    "start": "2366540",
    "end": "2371980"
  },
  {
    "text": "eks yet but it's coming it's a I'm not sure if you should check that's about if you define limits on a",
    "start": "2371980",
    "end": "2379930"
  },
  {
    "text": "container and then you find out that you actually need a little bit more memory than what you initially specified or",
    "start": "2379930",
    "end": "2386320"
  },
  {
    "text": "what you started out with vertical part art of scaler allows you to expand the limit of the container right it's",
    "start": "2386320",
    "end": "2392890"
  },
  {
    "text": "vertically expanded automatically for you otherwise you risk being evicted by",
    "start": "2392890",
    "end": "2398980"
  },
  {
    "text": "key abilities so that's a very useful feature it's coming placement groups",
    "start": "2398980",
    "end": "2404430"
  },
  {
    "text": "this is the single big thing this is the single most fact that changed our our",
    "start": "2404430",
    "end": "2411700"
  },
  {
    "text": "throughput in the system we got a 30 percent bump in the network",
    "start": "2411700",
    "end": "2416920"
  },
  {
    "text": "throughput or the queries per second right by just placing the cluster inside",
    "start": "2416920",
    "end": "2422140"
  },
  {
    "text": "a placement group so definitely take advantage of that now you know if you're",
    "start": "2422140",
    "end": "2427570"
  },
  {
    "text": "doing multiple placement groups there are some restrictions that you got to follow but you know it's it's overall",
    "start": "2427570",
    "end": "2432820"
  },
  {
    "text": "this is great crosses the deployment of course this is for all production systems",
    "start": "2432820",
    "end": "2437980"
  },
  {
    "text": "you got to deploy across different they exist and my recommendation is that place rights closer to the master what",
    "start": "2437980",
    "end": "2444850"
  },
  {
    "text": "that means is in a master slave like an architecture if you have that luxury or that flexibility I would say then you",
    "start": "2444850",
    "end": "2452020"
  },
  {
    "text": "place your clients who are writing doing the most rights closer to the master",
    "start": "2452020",
    "end": "2457690"
  },
  {
    "text": "that way lives in the same is he perhaps the same placement group you get the best throughput choose the right size",
    "start": "2457690",
    "end": "2464440"
  },
  {
    "text": "nodes Nathan touched upon this one how you pick your nodes and sizing the nodes this is",
    "start": "2464440",
    "end": "2469630"
  },
  {
    "text": "absolutely critical so my recommendation for high throughput systems is pick the one that has the",
    "start": "2469630",
    "end": "2475810"
  },
  {
    "text": "gives you the best network performance right Soviet running I'll show you the demo see if ib9 extra-large so this gives us",
    "start": "2475810",
    "end": "2483820"
  },
  {
    "text": "the 10 gigabit per second Network throughput you and there are other nodes",
    "start": "2483820",
    "end": "2489280"
  },
  {
    "text": "too but we picked C files because if it's in a high compute capacity and then",
    "start": "2489280",
    "end": "2496210"
  },
  {
    "text": "of course you got to pick the SSDs and you know there's other variants that you got to look at so you got to pick a node",
    "start": "2496210",
    "end": "2502480"
  },
  {
    "text": "that gives the best network performance and then small enough so you can fan them out right so that's what's the",
    "start": "2502480",
    "end": "2508240"
  },
  {
    "text": "Goldilocks says I can tell you it depends on your application in general",
    "start": "2508240",
    "end": "2513400"
  },
  {
    "text": "these days you get you know so for high throughput systems I can make a general statement that more CPU is better than",
    "start": "2513400",
    "end": "2520450"
  },
  {
    "text": "more RAM and you see this with rocks DB engine for example rocks DB engine",
    "start": "2520450",
    "end": "2526300"
  },
  {
    "text": "compresses really well it's there's no right amplifications and the cpu is you",
    "start": "2526300",
    "end": "2531850"
  },
  {
    "text": "know you can fully leverage the CPU and you will see that the memory as it is",
    "start": "2531850",
    "end": "2536860"
  },
  {
    "text": "pushing the load that we're gonna see the memory stays really low the C&I",
    "start": "2536860",
    "end": "2542920"
  },
  {
    "text": "plugin this is absolutely the best thing right I don't think I can say of this of any",
    "start": "2542920",
    "end": "2548380"
  },
  {
    "text": "other overlay networks this runs at V PC speed no overheads and Wilson best",
    "start": "2548380",
    "end": "2555730"
  },
  {
    "text": "performance with the C&I one gotcha is if one if you deploy the system at CNRI",
    "start": "2555730",
    "end": "2561880"
  },
  {
    "text": "you got to make sure you keep it up because when you create the cluster whatever version CNI is what you what",
    "start": "2561880",
    "end": "2569560"
  },
  {
    "text": "you get and that's what stays on if you want to pick up some updates or fixes",
    "start": "2569560",
    "end": "2574690"
  },
  {
    "text": "you got to go pull down the latest and greatest and iPlayer to yourself sorry there's some maintenance to do we are",
    "start": "2574690",
    "end": "2582460"
  },
  {
    "text": "using that the CNI g7 yeah I don't know so you can read that so bottlenecks",
    "start": "2582460",
    "end": "2591190"
  },
  {
    "text": "let's talk about one of the important bottlenecks we ran into typically when you are running a database at scale at",
    "start": "2591190",
    "end": "2596470"
  },
  {
    "text": "this throughput you would expect in memory or a disk to be bottlenecking",
    "start": "2596470",
    "end": "2601510"
  },
  {
    "text": "that's not where we've seen the issues the memory was fine the disk or is doing just fine CPUs were not even at a 80",
    "start": "2601510",
    "end": "2608710"
  },
  {
    "text": "percent right and we were surprised actually to notice that we were hitting a wall with the",
    "start": "2608710",
    "end": "2616300"
  },
  {
    "text": "packets per second let me show you the chart so if you look at this chart on",
    "start": "2616300",
    "end": "2621550"
  },
  {
    "text": "the left hand side bottom what you see is the network in and out packets per",
    "start": "2621550",
    "end": "2627910"
  },
  {
    "text": "second where I had the vertical line is the million 6.6 million packets per",
    "start": "2627910",
    "end": "2636040"
  },
  {
    "text": "second we hit a wall right there and if you could see the chart above the CPU",
    "start": "2636040",
    "end": "2641710"
  },
  {
    "text": "utilization was at 35 percent they have ample capacity on the CPU side and the",
    "start": "2641710",
    "end": "2647530"
  },
  {
    "text": "network throughput in terms of bytes in and out was actually dropped at the same exact second where we hit the wall this",
    "start": "2647530",
    "end": "2655119"
  },
  {
    "text": "is where we call DK steam for help they jumped in the debugged and they provided",
    "start": "2655119",
    "end": "2661780"
  },
  {
    "text": "a solution they said turn on jumbo frames and that's where we went to github downloaded the cni patch and",
    "start": "2661780",
    "end": "2668680"
  },
  {
    "text": "applied to this eks cluster we saw he jumped so here is how we scaled first",
    "start": "2668680",
    "end": "2675970"
  },
  {
    "text": "when we deployed a cluster the database cluster to shards for nodes you were",
    "start": "2675970",
    "end": "2682810"
  },
  {
    "text": "overloaded that was completely databases were just running hot so we said let's",
    "start": "2682810",
    "end": "2688330"
  },
  {
    "text": "expand the cluster size and then we added three subnets and then we saw a",
    "start": "2688330",
    "end": "2693700"
  },
  {
    "text": "throughput jump to 400 kilo queries first 400,000 queries per second but of",
    "start": "2693700",
    "end": "2699910"
  },
  {
    "text": "course that was not enough then we moved it into a placement group and the first",
    "start": "2699910",
    "end": "2705760"
  },
  {
    "text": "time you are seeing 1.5 MTU because I'm about to make a reference to jumbo Frank's so this was standard",
    "start": "2705760",
    "end": "2711820"
  },
  {
    "text": "configuration with CNI 1.5 MTU and we were able to push about 600,000 queries",
    "start": "2711820",
    "end": "2720280"
  },
  {
    "text": "per second and that was not enough and that's where you see we buy place it by",
    "start": "2720280",
    "end": "2725800"
  },
  {
    "text": "putting it in a placement group the network packets per second jumped up to nine and a half million so we saw a huge",
    "start": "2725800",
    "end": "2733270"
  },
  {
    "text": "increase by hosting this instead of placement group but then we realized",
    "start": "2733270",
    "end": "2739000"
  },
  {
    "text": "that this is where we are stalling no matter what we did after this we could not go pass this throughput so that's when the",
    "start": "2739000",
    "end": "2745930"
  },
  {
    "text": "eks team gave us the help and we downloaded the jumbo frames that guard",
    "start": "2745930",
    "end": "2751780"
  },
  {
    "text": "us to nine hundred forty eight thousand queries per second at still doing I have",
    "start": "2751780",
    "end": "2757510"
  },
  {
    "text": "a typo there that's not five hundred nanos that's five hundred micro so I apologize for that mistake so that's",
    "start": "2757510",
    "end": "2764619"
  },
  {
    "text": "where we ended up and then we realized that now we have a bigger PAC jumbo packets is 99 K bytes so then we",
    "start": "2764619",
    "end": "2772540"
  },
  {
    "text": "realized that wait a second now all of a sudden we got nine thousand and nine and a half million packets that we can push",
    "start": "2772540",
    "end": "2779740"
  },
  {
    "text": "per second why don't we pack more densely so we added more replicas when we added more",
    "start": "2779740",
    "end": "2785470"
  },
  {
    "text": "replicas this system was handling the network was just fine and we were able to push it up to 1.3 six million",
    "start": "2785470",
    "end": "2791339"
  },
  {
    "text": "requests per second let's see this in action I need your help so if you could",
    "start": "2791339",
    "end": "2799500"
  },
  {
    "start": "2796000",
    "end": "3264000"
  },
  {
    "text": "pull up your phone and go to the bass",
    "start": "2799500",
    "end": "2807810"
  },
  {
    "text": "dbaas dot site I'd like you to submit a",
    "start": "2807810",
    "end": "2815619"
  },
  {
    "text": "job so I'm gonna run the jobs right here so we will collectively push the system very hard so I'm going to log in here",
    "start": "2815619",
    "end": "2822760"
  },
  {
    "text": "can you see my screen no sorry",
    "start": "2822760",
    "end": "2826290"
  },
  {
    "text": "it's not switching",
    "start": "2838240",
    "end": "2841200"
  },
  {
    "text": "okay good all right so the dashboard on the left hand side is graph owner it is",
    "start": "2843690",
    "end": "2849480"
  },
  {
    "text": "put together from Prometheus and CloudWatch metrics you'll see some you know mix of both the gauge on the top is",
    "start": "2849480",
    "end": "2856500"
  },
  {
    "text": "the queries per second that's the absolute one to watch and then there is a query latency switch is right here can",
    "start": "2856500",
    "end": "2863160"
  },
  {
    "text": "you see my cursor yeah so that's the query latencies a high performance system is a system that can",
    "start": "2863160",
    "end": "2870510"
  },
  {
    "text": "push high throughput with low latencies so one number has to be really high",
    "start": "2870510",
    "end": "2875609"
  },
  {
    "text": "other number has to be really low that's when we know it's a high performance system so let's kick some tires or D",
    "start": "2875609",
    "end": "2889650"
  },
  {
    "text": "bass DB AAAS dot sight SI te it's not",
    "start": "2889650",
    "end": "2896670"
  },
  {
    "text": "going oh yeah yeah yeah like that",
    "start": "2896670",
    "end": "2905420"
  },
  {
    "text": "so let me quickly introduce you the system so what we have is a 30 node cluster surrounding c59 extra D I",
    "start": "2918490",
    "end": "2927990"
  },
  {
    "text": "fat-finger all the time so I kind of created a script for myself run a make file so I don't mix too many mistakes",
    "start": "2927990",
    "end": "2933910"
  },
  {
    "text": "here the part count is about 169 so there's 169 parts running on 30 nodes",
    "start": "2933910",
    "end": "2940900"
  },
  {
    "text": "and of course this system as you can see there's so many daemon sets deployment services so it's very hard to do this by",
    "start": "2940900",
    "end": "2947890"
  },
  {
    "text": "hand so we created a C or D and the CR D basically is the operator rights and",
    "start": "2947890",
    "end": "2953349"
  },
  {
    "text": "then the combination of C Rd and the operator is what creates that system and it goes to the you know standard SDLC",
    "start": "2953349",
    "end": "2960130"
  },
  {
    "text": "pipeline and and github and all that so with that let me actually run some load",
    "start": "2960130",
    "end": "2967660"
  },
  {
    "text": "on this system I'm gonna start off slowly so what I just did is I'm",
    "start": "2967660",
    "end": "2975310"
  },
  {
    "text": "submitting a MySQL sispann jump for those of you who are familiar with MySQL",
    "start": "2975310",
    "end": "2980950"
  },
  {
    "text": "community or MySQL you know suspense job so we are running OLTP select OLTP point",
    "start": "2980950",
    "end": "2988720"
  },
  {
    "text": "select a point select basically means you are looking up a record by its primary key and then a point update",
    "start": "2988720",
    "end": "2994960"
  },
  {
    "text": "means you're updating the record using its primary key so we are running OLTP point select and point update that's",
    "start": "2994960",
    "end": "3002250"
  },
  {
    "text": "basically what's going on here I'm going to run a whole bunch of jobs to keep the system busy so how are we",
    "start": "3002250",
    "end": "3008580"
  },
  {
    "text": "doing so we are about five hundred fifty two thousand transactions per second or queries per second right that's not",
    "start": "3008580",
    "end": "3014070"
  },
  {
    "text": "enough it's that's anybody can do that let's kick it a little bit harder so if",
    "start": "3014070",
    "end": "3021150"
  },
  {
    "text": "you guys have submitted your jobs I'm gonna go run them myself here and what I'm going to do is I'm going to show you",
    "start": "3021150",
    "end": "3028560"
  },
  {
    "text": "what's going on",
    "start": "3028560",
    "end": "3031400"
  },
  {
    "text": "so on the bottom screen you can see all the jobs that are currently running so job is basically a standard Cuban at",
    "start": "3039290",
    "end": "3045110"
  },
  {
    "text": "this job and I'm not going to show you the the in the interest of time but it's",
    "start": "3045110",
    "end": "3051080"
  },
  {
    "text": "basically a kubernetes job right so it's running a number of parallel is a parallel jobs with n number of threads",
    "start": "3051080",
    "end": "3056420"
  },
  {
    "text": "right so think of it that way all right there you go it actually crossed 1.2 million transactions a second so we're",
    "start": "3056420",
    "end": "3062570"
  },
  {
    "text": "gonna kick it even harder guys so",
    "start": "3062570",
    "end": "3066940"
  },
  {
    "text": "alright so it's running more jobs now so that's about one point one four two it",
    "start": "3067780",
    "end": "3074660"
  },
  {
    "text": "goes back and forth a little bit now let's look at the query latencies and then I want to call out the network",
    "start": "3074660",
    "end": "3080150"
  },
  {
    "text": "performance here so if you can see the network performance we are at about networking and out is about four million",
    "start": "3080150",
    "end": "3087370"
  },
  {
    "text": "packets per second we are about one point four six right I wanted to go to one point five let's see if that happens",
    "start": "3087370",
    "end": "3094420"
  },
  {
    "text": "keep watching and then what I'm going to do is thank you for submitting the jobs",
    "start": "3094420",
    "end": "3100850"
  },
  {
    "text": "I'm going to run all of your jobs right now all the jobs that you guys are submitted thank you wow that's a lot of",
    "start": "3100850",
    "end": "3110000"
  },
  {
    "text": "jobs thank you so let's see how the system does all",
    "start": "3110000",
    "end": "3115010"
  },
  {
    "text": "right one point five bingo guys right we were hoping to see a million one point",
    "start": "3115010",
    "end": "3121880"
  },
  {
    "text": "five eight five thank you so so that's the that's the majority of the demo I",
    "start": "3121880",
    "end": "3128990"
  },
  {
    "text": "wanted to show you and it's running about eight charts in the system each chart having one master three",
    "start": "3128990",
    "end": "3135200"
  },
  {
    "text": "replicas that means four database instances replicated eight times over or",
    "start": "3135200",
    "end": "3140240"
  },
  {
    "text": "eight charts right so that is thirty-two database instances powering this instance here the by powering this",
    "start": "3140240",
    "end": "3145820"
  },
  {
    "text": "system right and then let me quickly show you one point six oh my god look at",
    "start": "3145820",
    "end": "3151670"
  },
  {
    "text": "that this is the first time I'm through one point six that's great and on this",
    "start": "3151670",
    "end": "3157250"
  },
  {
    "text": "system here that's exciting you know what I'm in the mood let's go ahead and",
    "start": "3157250",
    "end": "3163240"
  },
  {
    "text": "push it even harder did make write or make writes all right there you go let's",
    "start": "3163240",
    "end": "3171380"
  },
  {
    "text": "see and and one thing I want to show you here is that the the latencies right so",
    "start": "3171380",
    "end": "3177460"
  },
  {
    "text": "this is all the way in the bottom here it is 4.7 milliseconds for p90 okay 90th",
    "start": "3177460",
    "end": "3185110"
  },
  {
    "text": "percentile latency is four point seven milliseconds when the system is running at that speed right and the p50 I can't",
    "start": "3185110",
    "end": "3194440"
  },
  {
    "text": "even read this number so below he said it's about 90 somewhere and 940 micros",
    "start": "3194440",
    "end": "3202120"
  },
  {
    "text": "or something like I don't know what that is but I I can't do the math right now but as you can see it is consistently",
    "start": "3202120",
    "end": "3208000"
  },
  {
    "text": "hitting 1.5 1.6 million transactions a second so with that said what I'll do is",
    "start": "3208000",
    "end": "3214420"
  },
  {
    "text": "I'll actually stop it here and I'll take questions I think it will be more useful",
    "start": "3214420",
    "end": "3220090"
  },
  {
    "text": "for you guys now one thing is I want to switch back and I got one more slide to",
    "start": "3220090",
    "end": "3232240"
  },
  {
    "text": "show I think",
    "start": "3232240",
    "end": "3234900"
  },
  {
    "text": "all right so oh thank you and please",
    "start": "3239180",
    "end": "3252770"
  },
  {
    "text": "don't forget to turn in your social surveys yeah please fill out your session service is very important thank",
    "start": "3252770",
    "end": "3258230"
  },
  {
    "text": "you and enjoy the rest of the conference guys thank you",
    "start": "3258230",
    "end": "3264460"
  }
]
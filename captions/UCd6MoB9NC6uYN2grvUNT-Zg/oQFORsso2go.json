[
  {
    "text": "alright folks in the back good I need a thumbs up from someone way back where yeah",
    "start": "469",
    "end": "5970"
  },
  {
    "text": "great people are here with me already alright good afternoon everyone welcome to the session about optimizing your",
    "start": "5970",
    "end": "12900"
  },
  {
    "text": "service applications the goal here is to earn your black belt which means it's an",
    "start": "12900",
    "end": "18300"
  },
  {
    "text": "advanced session 400 I'm gonna spare you the basics of what is server lists and service architectures and just get right",
    "start": "18300",
    "end": "24990"
  },
  {
    "text": "at where you'll be tightening your screws to get the most out of it I'm a J I leave the product team for AWS lambda",
    "start": "24990",
    "end": "32130"
  },
  {
    "text": "and I'll be joined later in the talk by Peter Spassky we be on a cloud guru one",
    "start": "32130",
    "end": "37770"
  },
  {
    "text": "of our favorite service startups yes",
    "start": "37770",
    "end": "44180"
  },
  {
    "text": "you're all here because you're one of the hundreds of thousands of developers across a huge range of companies who",
    "start": "44180",
    "end": "50850"
  },
  {
    "text": "have chosen to go into production with service applications you're in good company from successful companies like",
    "start": "50850",
    "end": "56760"
  },
  {
    "text": "AdRoll Airbnb next door IOT leaders like iRobot fortune 500",
    "start": "56760",
    "end": "62550"
  },
  {
    "text": "companies like coca-cola companies of all sizes and shapes have moved to",
    "start": "62550",
    "end": "67710"
  },
  {
    "text": "production with their applications what's been really exciting in the last year for me personally is seeing these",
    "start": "67710",
    "end": "73799"
  },
  {
    "text": "customers start to push the the new Lamba so much higher when it comes to both scale and performance and you'll",
    "start": "73799",
    "end": "81630"
  },
  {
    "text": "hear many of their stories at the stock hopefully many of you have those stories to share with those around you please",
    "start": "81630",
    "end": "87030"
  },
  {
    "text": "wait till I'm finished talking for example Fannie Mae is doing about",
    "start": "87030",
    "end": "92400"
  },
  {
    "text": "20,000 concurrent requests on lambda which translates to them processing loan simulations for over 20 million loans in",
    "start": "92400",
    "end": "98460"
  },
  {
    "text": "just under two hours next door is built a service data processing system which processes about five billion requests a",
    "start": "98460",
    "end": "105299"
  },
  {
    "text": "day vogue has improved the performance for their image processing and image rendering on their website using lambda",
    "start": "105299",
    "end": "111600"
  },
  {
    "text": "and API gateway by almost 90 percent now all of these customers and many of you",
    "start": "111600",
    "end": "117570"
  },
  {
    "text": "included have made this move to improve a few things and it boils down to",
    "start": "117570",
    "end": "122600"
  },
  {
    "text": "elasticity resilience and agility of your application development all with a",
    "start": "122600",
    "end": "128250"
  },
  {
    "text": "background of cost savings obviously going server less and offloading responsible",
    "start": "128250",
    "end": "133740"
  },
  {
    "text": "of utilization management and server configuration can have a major difference to how you build on and",
    "start": "133740",
    "end": "139110"
  },
  {
    "text": "operate and it also means that getting these gains on performance and cost",
    "start": "139110",
    "end": "144690"
  },
  {
    "text": "optimization comes with a spectrum we believe that there are a core set of practices that every developer needs to",
    "start": "144690",
    "end": "151800"
  },
  {
    "text": "start following to get the most of your service architecture the typical layers",
    "start": "151800",
    "end": "158490"
  },
  {
    "text": "of a service architectures and there are a few and before I actually get into this one point to mention is when we",
    "start": "158490",
    "end": "165300"
  },
  {
    "text": "talk about optimizations with conventional architectures we talk about packing more onto individual boxes or",
    "start": "165300",
    "end": "171120"
  },
  {
    "text": "fine-tuning your CPUs or tweaking that network switch that is not a layer that you have to worry about that is",
    "start": "171120",
    "end": "176820"
  },
  {
    "text": "something I sit and sweat about every single day what your problem becomes is what you do with your application code",
    "start": "176820",
    "end": "182610"
  },
  {
    "text": "and that's what we're gonna talk about here so a typical service application has a few layers you have your access",
    "start": "182610",
    "end": "189450"
  },
  {
    "text": "and authentication layer across a multiple set of services that's responsible for deciding the ingress",
    "start": "189450",
    "end": "195990"
  },
  {
    "text": "authentication access to your back-end layers you optionally have a messaging",
    "start": "195990",
    "end": "201330"
  },
  {
    "text": "and orchestrating clear that is responsible for coordinating calls to your back-end Doom's some kind of",
    "start": "201330",
    "end": "208020"
  },
  {
    "text": "buffering state management collation of Records batching etc the obviously the",
    "start": "208020",
    "end": "214260"
  },
  {
    "text": "compute layer my favorite where all your business logic actually goes and executes and then finally the data layer",
    "start": "214260",
    "end": "220920"
  },
  {
    "text": "which is responsible for state durable information that your application needs",
    "start": "220920",
    "end": "226110"
  },
  {
    "text": "or sometimes even third-party applications that you access through API is potentially running on your own",
    "start": "226110",
    "end": "233010"
  },
  {
    "text": "systems the same layers apply whether you're building end user facing applications which has a certain flow or",
    "start": "233010",
    "end": "239820"
  },
  {
    "text": "backend applications where maybe only a couple of these layers are actually in play no this is obviously a huge surface",
    "start": "239820",
    "end": "246480"
  },
  {
    "text": "area for me to talk about so we're just going to focus on one specific area of optimization particularly looking at",
    "start": "246480",
    "end": "252990"
  },
  {
    "text": "your functions the invocations of those functions and the interactions these functions have with downstream services",
    "start": "252990",
    "end": "258620"
  },
  {
    "text": "peter is actually going to take all my practices in theory hence tell them how they actually put it into play with with",
    "start": "258620",
    "end": "264960"
  },
  {
    "text": "a cloud guru we've tried to distill all of these practices into four cutters these are",
    "start": "264960",
    "end": "271580"
  },
  {
    "text": "inspired by the pragmatic programmer construct we call them the lean function",
    "start": "271580",
    "end": "276860"
  },
  {
    "text": "eventful invocations coordinated calls and service full operations hopefully it",
    "start": "276860",
    "end": "283370"
  },
  {
    "text": "all sounds very mysterious and you will be willing to stay more to hear about it now there's a lot of collective wisdom",
    "start": "283370",
    "end": "288860"
  },
  {
    "text": "reflected in this talk I can't claim to have generated everything that's in here but special calls out to Alex Casa",
    "start": "288860",
    "end": "295430"
  },
  {
    "text": "Bonita Kadim e yanqui from burning monk and clay Smith from New Relic for",
    "start": "295430",
    "end": "300440"
  },
  {
    "text": "generating some of the tools and analyses that you actually see in this talk all right",
    "start": "300440",
    "end": "305930"
  },
  {
    "text": "so by the end of this you're gonna walk away with the repeatable regimen for building high resilient high performance",
    "start": "305930",
    "end": "311780"
  },
  {
    "text": "surveillance applications everything we talked about today hopefully accrues towards three things reducing the",
    "start": "311780",
    "end": "317960"
  },
  {
    "text": "end-to-end latency of your application reducing the cost of your application or improving the resiliency of your",
    "start": "317960",
    "end": "323479"
  },
  {
    "text": "application all right all right let's get started so first up the lean",
    "start": "323479",
    "end": "328759"
  },
  {
    "text": "function the reason I'm choosing to start from the function itself is because that ends up being the most",
    "start": "328759",
    "end": "333889"
  },
  {
    "text": "critical component of your architecture it functions is the glue for all the different components to talk each other",
    "start": "333889",
    "end": "339560"
  },
  {
    "text": "it controls the business logic which is ultimately what you're trying to differentiate and it has significant",
    "start": "339560",
    "end": "344960"
  },
  {
    "text": "implications on how the overall application behaves now in order to understand how to optimize the function",
    "start": "344960",
    "end": "351169"
  },
  {
    "text": "you probably need a better understanding of what actually happens underneath the covers so quick history on the anatomy",
    "start": "351169",
    "end": "357349"
  },
  {
    "text": "of a function now there are a few layers in play when your function actually goes and gets executed when it gets invoked",
    "start": "357349",
    "end": "365000"
  },
  {
    "text": "first there's the compute substrate itself which is my moniker for the computer infrastructure on which your",
    "start": "365000",
    "end": "371779"
  },
  {
    "text": "service functions execute and contrary to popular rumors it is not made up of unicorns and pixie dust",
    "start": "371779",
    "end": "377870"
  },
  {
    "text": "there is some real stuff back there but it's invisible to you you don't care about it you don't manage it it's",
    "start": "377870",
    "end": "383210"
  },
  {
    "text": "largely invisible to you what you do end up seeing is what I would refer to as the lambda container the portion or a",
    "start": "383210",
    "end": "389539"
  },
  {
    "text": "slice of the compute substrate which we shape depending on your functional definition that gets instantiated during",
    "start": "389539",
    "end": "395630"
  },
  {
    "text": "a scale event and as part of that you see the run time getting instantiated process and then your code or your",
    "start": "395630",
    "end": "401900"
  },
  {
    "text": "function code being instantiated as part of that now when I say your function in this particular example it specifically",
    "start": "401900",
    "end": "408229"
  },
  {
    "text": "means the code that is executing inside the handler of your function not necessarily the artifact that are",
    "start": "408229",
    "end": "414169"
  },
  {
    "text": "uploading anything that's written outside your handler will be considered part of the overall environment right so",
    "start": "414169",
    "end": "420289"
  },
  {
    "text": "basic stuff just laying out the foundation of that when actually invoke",
    "start": "420289",
    "end": "425389"
  },
  {
    "text": "comes into the function it goes through a certain cycle in the backend the computer substrate downloads your code",
    "start": "425389",
    "end": "430909"
  },
  {
    "text": "from our internal repository if it's never seen it before it starts a new container shape defined with resources",
    "start": "430909",
    "end": "437060"
  },
  {
    "text": "isolated for executing your specific function it bootstraps the runtime for",
    "start": "437060",
    "end": "442460"
  },
  {
    "text": "the first time if it is not loaded ever and then actually goes in execute your code initializes your libraries",
    "start": "442460",
    "end": "447740"
  },
  {
    "text": "dependencies execute your code etc this is the part that many of you have heard",
    "start": "447740",
    "end": "454009"
  },
  {
    "text": "of which is the infamous cold start right the first time your function actually executes there's a bunch of loading and initialization that happens",
    "start": "454009",
    "end": "460669"
  },
  {
    "text": "and the rest of it happens every single time your request executes there's a",
    "start": "460669",
    "end": "465830"
  },
  {
    "text": "part of this which AWS is responsible for optimizing but when it comes to optimizing the entire cycle over here",
    "start": "465830",
    "end": "471289"
  },
  {
    "text": "it's a shared responsibility right just to give you a sense over the last year",
    "start": "471289",
    "end": "476449"
  },
  {
    "text": "on the AWS half the world we've made changes including some that are rolling out this month which will reduce the",
    "start": "476449",
    "end": "482509"
  },
  {
    "text": "overhead by almost 80% for some of the larger functions but no matter what we do there any of the optimizations if",
    "start": "482509",
    "end": "488960"
  },
  {
    "text": "they don't happen on the other end you may not see the gains that you want so the other thing I'll also call out is",
    "start": "488960",
    "end": "494240"
  },
  {
    "text": "while one box looks a lot bigger than the other remember that your call starts are happening one percent of your time",
    "start": "494240",
    "end": "499939"
  },
  {
    "text": "the application or or less the application that you are actually working on is going to be predominantly",
    "start": "499939",
    "end": "505610"
  },
  {
    "text": "looking at the warm start and that's the one that's going to actually end up saving costs and reducing end-to-end",
    "start": "505610",
    "end": "511639"
  },
  {
    "text": "latency so we're going to look at both those pieces this isn't just a theoretical diagram you can actually see",
    "start": "511639",
    "end": "517219"
  },
  {
    "text": "this using Amazon x-ray as well this is an example of what a rendering of an",
    "start": "517219",
    "end": "522349"
  },
  {
    "text": "individual function actually looks like you can see both the end-to-end latency",
    "start": "522349",
    "end": "527510"
  },
  {
    "text": "which is the box I drew up there as well as the breakdown of cold starts the",
    "start": "527510",
    "end": "532640"
  },
  {
    "text": "function and it's like time and the overall time it takes to process right so you have visibility",
    "start": "532640",
    "end": "537770"
  },
  {
    "text": "into what is going into each of those boxes when the invocation happens you",
    "start": "537770",
    "end": "543740"
  },
  {
    "text": "will see that code shows up in two places over here which means the first place you want to start optimizing is your code itself",
    "start": "543740",
    "end": "549500"
  },
  {
    "text": "right and there are three different layers to think about here first is your logic second the dependencies that go",
    "start": "549500",
    "end": "555140"
  },
  {
    "text": "with your function third is the archive or the dependency artifact that you actually end up giving into lambda my",
    "start": "555140",
    "end": "562250"
  },
  {
    "text": "first call-out is avoid fat or monolithic functions and what this basically means is if you have multiple",
    "start": "562250",
    "end": "568400"
  },
  {
    "text": "pieces of logic if you find yourself writing a bunch of conditionals or routing logic inside your function don't",
    "start": "568400",
    "end": "574930"
  },
  {
    "text": "more often than not splitting it out into individual functions gives you the gain of call starts on each one of those",
    "start": "574930",
    "end": "581090"
  },
  {
    "text": "and the actual difference in terms of manageability is is a reasonable trade-off over there now your mileage",
    "start": "581090",
    "end": "588020"
  },
  {
    "text": "may vary you may have a case where you are trying to call a function within a function within a function within a function I don't know why you would do",
    "start": "588020",
    "end": "594050"
  },
  {
    "text": "that but in those kind of classes please collapse the function into one you know do what makes sense for your business",
    "start": "594050",
    "end": "599510"
  },
  {
    "text": "but in general what we have seen is you will see better performance characteristics with separated functions",
    "start": "599510",
    "end": "604700"
  },
  {
    "text": "rather than individual ones second control your dependencies what we are",
    "start": "604700",
    "end": "610430"
  },
  {
    "text": "used to in a conventional development form is centralized dependency management package the whole thing in",
    "start": "610430",
    "end": "616280"
  },
  {
    "text": "let the whole thing run and then we sit and say oh my function is taking too long to Lourdes specifically we see this",
    "start": "616280",
    "end": "622430"
  },
  {
    "text": "a lot with Java and I'll give you an example over there of code but the",
    "start": "622430",
    "end": "627500"
  },
  {
    "text": "secondly aspect of that think about is how you actually compress the archive you end up uploading into lambda into lambda so with languages like Nord and",
    "start": "627500",
    "end": "634610"
  },
  {
    "text": "Java you have options like browser fire and minify for compacting the archive those of you using the service framework",
    "start": "634610",
    "end": "640520"
  },
  {
    "text": "yes some of you there's actually a plug-in that's available called server let's optimize that we'll do this on",
    "start": "640520",
    "end": "646100"
  },
  {
    "text": "your behalf it will shrink the archive by significant sizes for those of you who are using Java or actually using",
    "start": "646100",
    "end": "652160"
  },
  {
    "text": "build solutions for creating your archive there are configurations you can do to pick individual dependencies one",
    "start": "652160",
    "end": "658340"
  },
  {
    "text": "of the most common culprits we see when it comes to Java based functions is customers loading the entire AWS SDK as",
    "start": "658340",
    "end": "664040"
  },
  {
    "text": "part of your jar file now if you look at this particular maven configuration it's a popular build",
    "start": "664040",
    "end": "669710"
  },
  {
    "text": "tool that you used for creating Java archives what I've done is I've only specified the s3 SDK requirement and the",
    "start": "669710",
    "end": "677600"
  },
  {
    "text": "dynamo DB SDK requirement instead of using the entire SDK itself which is what conventionally you end up doing by",
    "start": "677600",
    "end": "683779"
  },
  {
    "text": "default this does put a little bit more questions about how you think about your logic before creating the dependencies",
    "start": "683779",
    "end": "690080"
  },
  {
    "text": "but can make a big difference this change shrunk my archive from 49 MB to",
    "start": "690080",
    "end": "695240"
  },
  {
    "text": "13 MB right so when you're shaving off you know two-thirds of your dependency size you're actually going to see that",
    "start": "695240",
    "end": "702080"
  },
  {
    "text": "66% improvement both on the first in the third half of the box or that both your cold start and your warm start so always",
    "start": "702080",
    "end": "708589"
  },
  {
    "text": "look through your dependencies to make sure you're stripping out what you don't need all right so we talked about the",
    "start": "708589",
    "end": "715279"
  },
  {
    "text": "code the packaging the archive now when your function actually starts executing there's a specific behavior that you can",
    "start": "715279",
    "end": "721760"
  },
  {
    "text": "use to your advantage lambda doesn't do concurrency intra process it literally spins up a copy of",
    "start": "721760",
    "end": "727520"
  },
  {
    "text": "your code for every single individual request that's actually coming in which means you don't need to on one hand you",
    "start": "727520",
    "end": "733400"
  },
  {
    "text": "don't need to do things like writing blocking execution cord thinking about multi-threading inside your functions you can if you want to I'll talk a",
    "start": "733400",
    "end": "740270"
  },
  {
    "text": "little bit about that but keep in mind that your processing individual events on individual containers right which",
    "start": "740270",
    "end": "746300"
  },
  {
    "text": "means anything that is not on the critical path for executing for an individual request you could",
    "start": "746300",
    "end": "752630"
  },
  {
    "text": "theoretically move outside your function mode into the header and have that only happened during container initialization",
    "start": "752630",
    "end": "757760"
  },
  {
    "text": "time right so this can go for fat clients that you can do lazy loading on connection pools or management that you",
    "start": "757760",
    "end": "764360"
  },
  {
    "text": "can move outside the handler function what this does is it shifts it from that",
    "start": "764360",
    "end": "769390"
  },
  {
    "text": "warm start run initializing for every single request and paying the quote-unquote penalty for that every",
    "start": "769390",
    "end": "774830"
  },
  {
    "text": "single request into the cold start of the container start window of it right so you're trading off the 99% for the 1%",
    "start": "774830",
    "end": "781700"
  },
  {
    "text": "generally about a practice to get more out of it and finally well not finally I",
    "start": "781700",
    "end": "788300"
  },
  {
    "text": "problem like number four on my number list okay so I've seen this practice where people",
    "start": "788300",
    "end": "795470"
  },
  {
    "text": "use lambda for copying data back and forth not necessarily a bad thing to do but",
    "start": "795470",
    "end": "801050"
  },
  {
    "text": "if you're using lambda for PRI oh you're probably doing it wrong the practice you",
    "start": "801050",
    "end": "806060"
  },
  {
    "text": "should be looking for is is my function doing anything to transform the data that's moving forward if all you're",
    "start": "806060",
    "end": "811100"
  },
  {
    "text": "doing is transport there's probably a better way for you to do it a more cost-effective way to do it the whole",
    "start": "811100",
    "end": "816529"
  },
  {
    "text": "point of lambda is to never pay for idle and if you're just waiting for i/o you're probably waiting for idle in some",
    "start": "816529",
    "end": "821540"
  },
  {
    "text": "form or the other now if you have to do it now obviously if your business logic requires you to read some data make sure",
    "start": "821540",
    "end": "827570"
  },
  {
    "text": "you're only reading what you actually need most of the AWS data sources offer some",
    "start": "827570",
    "end": "833000"
  },
  {
    "text": "kind of filtering or or compacting capabilities in terms of the data that comes in Aurora offers query filters",
    "start": "833000",
    "end": "840230"
  },
  {
    "text": "DynamoDB has query filters and now s3 has intra object filters with the new",
    "start": "840230",
    "end": "845390"
  },
  {
    "text": "Amazon s3 select feature this is the since it's relatively new I want to show you a specific example over here so we",
    "start": "845390",
    "end": "852500"
  },
  {
    "text": "have this reference architecture for running MapReduce using lambda it's available on github the code sample",
    "start": "852500",
    "end": "858170"
  },
  {
    "text": "architecture everything is there those of you checking email on your laptops can open up another window and look at",
    "start": "858170",
    "end": "863540"
  },
  {
    "text": "it but a simple change if you look at this particular example we were pretty",
    "start": "863540",
    "end": "868790"
  },
  {
    "text": "happy with it it it used to do I think about 770 million rows in about 200",
    "start": "868790",
    "end": "874339"
  },
  {
    "text": "seconds 11.2 cents for executing the whole thing great price point but in",
    "start": "874339",
    "end": "879950"
  },
  {
    "text": "this specific example what it was doing was looking at network lock data and looking for specific IPS and doing an",
    "start": "879950",
    "end": "885529"
  },
  {
    "text": "aggregation of IP ranges so we took that specific highlighted change and replaced",
    "start": "885529",
    "end": "890779"
  },
  {
    "text": "it with a corresponding s3 select object what what it does is it only looks at the IP from the entire row and then",
    "start": "890779",
    "end": "897170"
  },
  {
    "text": "pulls it out there it shaved off half the duration and processing on that and reduce the cost by over 1/5 because we",
    "start": "897170",
    "end": "904010"
  },
  {
    "text": "were also able to reduce memory a little bit I'll I'll talk about that quickly but you see this just by changing very",
    "start": "904010",
    "end": "910820"
  },
  {
    "text": "small portions of your logic and making optimal use of the other services that you're reading from your shells you're",
    "start": "910820",
    "end": "916279"
  },
  {
    "text": "shaving off time and remember with lambda time is money right so every single second that you're shaving off",
    "start": "916279",
    "end": "922070"
  },
  {
    "text": "for millions of requests could manifest as you know hundreds of dollars in your actual savings that you end up so",
    "start": "922070",
    "end": "929209"
  },
  {
    "text": "speaking of memory that's the other dial outside of your code that you actually have available",
    "start": "929209",
    "end": "934760"
  },
  {
    "text": "you can trim your logic you can trim your dependencies you can trim your package but you also need to make sure that you're tuning your computer or",
    "start": "934760",
    "end": "941240"
  },
  {
    "text": "computer resources available to match the code that's actually executing over here today we announce that lamda now",
    "start": "941240",
    "end": "948110"
  },
  {
    "text": "allows up to three gigs of memory till recently it used to be up 1.5 gigs for",
    "start": "948110",
    "end": "953870"
  },
  {
    "text": "those of you under we're a quick reminder that lamda offers a single dial for pushing up your resources increase",
    "start": "953870",
    "end": "959780"
  },
  {
    "text": "in memory gives you corresponding increases in CPU in fact going to three gigs now actually gives you access to",
    "start": "959780",
    "end": "965870"
  },
  {
    "text": "two cores of compute that has interesting implications on how you write your code well I'll talk a little",
    "start": "965870",
    "end": "970940"
  },
  {
    "text": "bit about that but the key takeaway here to remember though is larger memory doesn't always mean more expensive",
    "start": "970940",
    "end": "977750"
  },
  {
    "text": "executions it actually may end up giving you faster performance for the same price point so if we're on a benchmark",
    "start": "977750",
    "end": "984980"
  },
  {
    "text": "of using a function that calculates all prime numbers under a million run at a thousand times and these were the",
    "start": "984980",
    "end": "990770"
  },
  {
    "text": "numbers we actually got and what you'll see is the run at 128 MB and the run at",
    "start": "990770",
    "end": "996290"
  },
  {
    "text": "1 gig actually cost roughly the same there's a difference in you know the sixth decimal so to speak but it ran ten",
    "start": "996290",
    "end": "1003070"
  },
  {
    "text": "times faster right so if you are able to get 10 times faster performance for the",
    "start": "1003070",
    "end": "1008290"
  },
  {
    "text": "same price point it's worth doing that level of experimentation it's totally fine to pick one and start with it but",
    "start": "1008290",
    "end": "1014260"
  },
  {
    "text": "figure out what the appropriate dial is there are multiple tools available for you to do this you can use monitoring",
    "start": "1014260",
    "end": "1020800"
  },
  {
    "text": "tools like the ones from New Relic which actually aggregate data from looking at both from cloud watch and",
    "start": "1020800",
    "end": "1026350"
  },
  {
    "text": "x-ray and give you this amazing heat map of what the distribution of latency looks like for you they actually have a",
    "start": "1026350",
    "end": "1032500"
  },
  {
    "text": "great blog where they did a 50% increase in memory and saw you know a 95th percentile improve from 3 to 2.1 seconds",
    "start": "1032500",
    "end": "1039640"
  },
  {
    "text": "simple trade-off if you prefer a much more automated method there's another tool available for you on github called",
    "start": "1039640",
    "end": "1045730"
  },
  {
    "text": "lambda power tuning this is again written by alex castle bunny from from",
    "start": "1045730",
    "end": "1051130"
  },
  {
    "text": "cloud Academy what it does is it uses step functions to automatically switch",
    "start": "1051130",
    "end": "1056410"
  },
  {
    "text": "the memory of your in of your function run it in parallel for multiple runs aggregates the data out or the output",
    "start": "1056410",
    "end": "1063430"
  },
  {
    "text": "data from cloud watch of what the execution time and memory setting was and tells you what the appropriate",
    "start": "1063430",
    "end": "1068600"
  },
  {
    "text": "setting is so instead of you manually doing the runs multiple times you can just use this tuning tool to pick what",
    "start": "1068600",
    "end": "1075230"
  },
  {
    "text": "the individual setting is making it a lot more easier right and you know we",
    "start": "1075230",
    "end": "1080330"
  },
  {
    "text": "can choose to say I don't know there are various automation tools for doing it but this is an important performance",
    "start": "1080330",
    "end": "1085490"
  },
  {
    "text": "optimization for you to do and something that I would encourage you to make part of your automation and testing regime anyways you may have changes based on",
    "start": "1085490",
    "end": "1092450"
  },
  {
    "text": "payload architecture infrastructure etc right so I know I bought three gigs up",
    "start": "1092450",
    "end": "1099320"
  },
  {
    "text": "so I thought it'll be worth getting into the multi-threading debate as Peter and I were getting in backstage so it's a",
    "start": "1099320",
    "end": "1105049"
  },
  {
    "text": "maybe right till recently we've always said don't bother with multi-threading if you have a CPU bound function your",
    "start": "1105049",
    "end": "1112280"
  },
  {
    "text": "function only gets access to all the resources allocated to in the container which at best was one core which means",
    "start": "1112280",
    "end": "1118370"
  },
  {
    "text": "even if you spin up multiple threads no matter what the language is it's going to be contending for the same resources",
    "start": "1118370",
    "end": "1123980"
  },
  {
    "text": "you're not going to see a speed-up there's obviously an exception if you're doing an i/o bound workload you can do",
    "start": "1123980",
    "end": "1129679"
  },
  {
    "text": "optimizations like running the i/o on a separate thread doing a download and calculation separately and doing a core",
    "start": "1129679",
    "end": "1135350"
  },
  {
    "text": "computation on one with greater than one point eight gigs though with the new three gig functionality we do give you",
    "start": "1135350",
    "end": "1140690"
  },
  {
    "text": "access to multiple cores so if you have an application such as if you're using",
    "start": "1140690",
    "end": "1146230"
  },
  {
    "text": "Python multi processing dot pipe or if you're trying to do some kind of ML models that lend them well to threading",
    "start": "1146230",
    "end": "1152900"
  },
  {
    "text": "you can actually leverage the capability or lambda today to see performance optimizations we've seen some",
    "start": "1152900",
    "end": "1159380"
  },
  {
    "text": "experiments where you see you know about 30 to 40 percent gains for some of the ML models over there so another tip to",
    "start": "1159380",
    "end": "1165650"
  },
  {
    "text": "keep in mind I'll finish with with one of my pet peeves is the same thing I called out before which is don't bother",
    "start": "1165650",
    "end": "1172340"
  },
  {
    "text": "with orchestration within your court that's that's an unusual way for you to try and spend money on lambda do it if",
    "start": "1172340",
    "end": "1178340"
  },
  {
    "text": "necessary but avoid it right you're literally ending up paying for idle which is what we're trying to to fight",
    "start": "1178340",
    "end": "1183470"
  },
  {
    "text": "over there the better property to do if you have logic which requires to do this is actually split it up into two",
    "start": "1183470",
    "end": "1189559"
  },
  {
    "text": "functions do one that does the pre-processing the one that does the post-processing and then you step",
    "start": "1189559",
    "end": "1195020"
  },
  {
    "text": "functions or some external orchestration mechanism to sequence between them now recognize that you may not be able to",
    "start": "1195020",
    "end": "1202070"
  },
  {
    "text": "use step for everything there may be high-traffic use cases where it's not possible that's something that will obviously get better",
    "start": "1202070",
    "end": "1207800"
  },
  {
    "text": "but as a best practice if you find yourself waiting for i/o you probably want to switch to more of an external",
    "start": "1207800",
    "end": "1213890"
  },
  {
    "text": "orchestration than doing that within your function all right so that's the",
    "start": "1213890",
    "end": "1219170"
  },
  {
    "text": "end of the lean function kata the main things to remember over here concise logic make it do only what it needs to",
    "start": "1219170",
    "end": "1224870"
  },
  {
    "text": "do read what it needs to do efficient single function code which means you're not ending up packaging things that you",
    "start": "1224870",
    "end": "1230960"
  },
  {
    "text": "don't need or libraries that you don't need or logic you don't need and take advantage of the ephemeral environment",
    "start": "1230960",
    "end": "1236900"
  },
  {
    "text": "all right cool all right so let's switch to the next",
    "start": "1236900",
    "end": "1242180"
  },
  {
    "text": "layer over here which is the the actual invocation layer stuff coming in right when we think about the execution of the",
    "start": "1242180",
    "end": "1249230"
  },
  {
    "text": "lambda function because there's so much in a Cerberus architecture that depends on these various components talking to",
    "start": "1249230",
    "end": "1255140"
  },
  {
    "text": "each other how we choose the the invocation mechanism makes a big difference not introduce a cost element",
    "start": "1255140",
    "end": "1261620"
  },
  {
    "text": "of it but also wrote the resiliency element of it so okay so going back to",
    "start": "1261620",
    "end": "1267530"
  },
  {
    "text": "the architecture diagram we talked about earlier I'm specifically talking about the invocation paths that are highlighted when you're using AWS",
    "start": "1267530",
    "end": "1274820"
  },
  {
    "text": "services to actually invoke them be it as three be it Kinesis one of the data stores available over there",
    "start": "1274820",
    "end": "1281180"
  },
  {
    "text": "AWS controls the invocation path in the optimizations in play we build in free tries we try to compact the payload we",
    "start": "1281180",
    "end": "1287960"
  },
  {
    "text": "use efficient mechanisms from the wire so that it gets translated between the service but most of you have used cases",
    "start": "1287960",
    "end": "1294530"
  },
  {
    "text": "where you control the payload now this could be you are generating data from a machine or an IOT device and funneling",
    "start": "1294530",
    "end": "1300710"
  },
  {
    "text": "it through Kinesis you have customers who are generating payloads that are coming in through API gateway in that",
    "start": "1300710",
    "end": "1307250"
  },
  {
    "text": "case you need to make some choices about how you actually end up routing and staging these invitations to your",
    "start": "1307250",
    "end": "1313130"
  },
  {
    "text": "function all right so first make sure that you look at your application and",
    "start": "1313130",
    "end": "1318200"
  },
  {
    "text": "choose an appropriate entry point this is somewhat somewhat heresy on my part",
    "start": "1318200",
    "end": "1324320"
  },
  {
    "text": "but there are cases where you don't need to use API gateway right we have customers who have a single function",
    "start": "1324320",
    "end": "1331970"
  },
  {
    "text": "working with a single client with no need for customization or ever having plans for exposing to",
    "start": "1331970",
    "end": "1337490"
  },
  {
    "text": "anything else right in that case API gateway is great for future resiliency and kind of doing an architectural split",
    "start": "1337490",
    "end": "1343700"
  },
  {
    "text": "out over there but you may actually seen see faster response times and easier management layer by just using the AWS",
    "start": "1343700",
    "end": "1349700"
  },
  {
    "text": "SDK to call it remember lambda exposes a direct invoke API which is an HTTP",
    "start": "1349700",
    "end": "1355040"
  },
  {
    "text": "endpoint and you can send a sign request to it and get a response back from it immediately now for the other 99% cases",
    "start": "1355040",
    "end": "1361910"
  },
  {
    "text": "where you're actually using API gateway you may also have the scenario where you're using machines to actually invoke",
    "start": "1361910",
    "end": "1368210"
  },
  {
    "text": "your API right it's not just an end user facing API coming from a mobile backend or a web back-end it's a machine",
    "start": "1368210",
    "end": "1374450"
  },
  {
    "text": "generated API the way API gateway is structured underneath the covers it actually uses cloud front to have",
    "start": "1374450",
    "end": "1380930"
  },
  {
    "text": "basically what we call edge optimized requests so everything is cached by default routed through cloud front so",
    "start": "1380930",
    "end": "1386360"
  },
  {
    "text": "that you get a faster response if it's going outside the network this can work against you if you have the thing coming",
    "start": "1386360",
    "end": "1392870"
  },
  {
    "text": "from inside the AWS Network so for example you have a process running on",
    "start": "1392870",
    "end": "1398030"
  },
  {
    "text": "any c2 instance that's calling this particular API in this model we recommend you actually use the regional",
    "start": "1398030",
    "end": "1404720"
  },
  {
    "text": "endpoints capability of API gateway what it does is it takes cloud front out of the equation basically allows you to",
    "start": "1404720",
    "end": "1410450"
  },
  {
    "text": "bring your own cloud front in our experiments we have seen the the overhead changed from about one hundred",
    "start": "1410450",
    "end": "1415490"
  },
  {
    "text": "and ten milliseconds to about eight milliseconds so hundreds of milliseconds in your entire response part can be",
    "start": "1415490",
    "end": "1420920"
  },
  {
    "text": "shaved off by making that very very simple switch right so apart from the",
    "start": "1420920",
    "end": "1426980"
  },
  {
    "text": "synchronous pattern when you think about things like s3 or even actually S&S what's interesting over there is",
    "start": "1426980",
    "end": "1432680"
  },
  {
    "text": "thinking about how many events are you processing rather than thinking about the end-to-end latency it's the width of",
    "start": "1432680",
    "end": "1438410"
  },
  {
    "text": "requests that are actually getting sent over to lambda a general pattern we see when when customers are building say an",
    "start": "1438410",
    "end": "1444440"
  },
  {
    "text": "image processing pipeline or routing events through SNS is they sign up lambda to process all the invitations or",
    "start": "1444440",
    "end": "1450890"
  },
  {
    "text": "requests that are coming in and having the first step of your function being the one that actually discards your function right this goes back to my",
    "start": "1450890",
    "end": "1458120"
  },
  {
    "text": "point in the previous section which is if you have routing or orchestration in your function there's something off over",
    "start": "1458120",
    "end": "1463430"
  },
  {
    "text": "there right most services at least within AWS offer a way for you to discard events before they even get",
    "start": "1463430",
    "end": "1469190"
  },
  {
    "text": "lambda way more cost-effective as three has the capability of doing prefix and suffix filters right which allows you to lock",
    "start": "1469190",
    "end": "1476090"
  },
  {
    "text": "down lambda functions to trigger only on updates to certain paths inside your s3",
    "start": "1476090",
    "end": "1481430"
  },
  {
    "text": "bucket SNS recently launched a capability for you to do message property based filtering so for example",
    "start": "1481430",
    "end": "1488450"
  },
  {
    "text": "in your SNS payload if you had a property that said this is coming from originator a and the other one is junk",
    "start": "1488450",
    "end": "1495410"
  },
  {
    "text": "you can literally say only process if it is junk or originator a or whatever you so choose this has direct proportional",
    "start": "1495410",
    "end": "1502430"
  },
  {
    "text": "impact on your costs lambda has requests an execution based pricing which means if you trim a third of the events going",
    "start": "1502430",
    "end": "1508880"
  },
  {
    "text": "to your function you're saving a third of your cost right just straight-up no change to your processing you're just",
    "start": "1508880",
    "end": "1514190"
  },
  {
    "text": "eliminating it earlier up so as a best practice look at the configuration on what is actually going in and working over there if you continue to use a",
    "start": "1514190",
    "end": "1522440"
  },
  {
    "text": "custom event and you control it there's a bare minimum that should be in the event itself right which is what we call",
    "start": "1522440",
    "end": "1528560"
  },
  {
    "text": "provenance so to speak you should be able to say where the event came from who the identifier is what time stamp",
    "start": "1528560",
    "end": "1535250"
  },
  {
    "text": "was involved over there everything else in more common patterns is optional in fact I would encourage you to lean",
    "start": "1535250",
    "end": "1541190"
  },
  {
    "text": "towards as slim invocation packages as possible avoid large responses and large",
    "start": "1541190",
    "end": "1546460"
  },
  {
    "text": "requests going into your function you're gonna end up adding more bandwidth you're gonna end up adding patek if",
    "start": "1546460",
    "end": "1552410"
  },
  {
    "text": "you're doing cross region calls you can actually see network costs associated with the invocation instead use a",
    "start": "1552410",
    "end": "1558590"
  },
  {
    "text": "staging semantics like s3 or others to capture the payload and then invoke your function so for example if you're trying",
    "start": "1558590",
    "end": "1566000"
  },
  {
    "text": "to do image processing inside your function and you have API gateway fronting your function however out",
    "start": "1566000",
    "end": "1571280"
  },
  {
    "text": "through your gateway that ends up putting the image into s3 first or a direct connect into there and then have lambda go and read from that object",
    "start": "1571280",
    "end": "1577700"
  },
  {
    "text": "rather than trying to funnel the whole thing to lambda through the entire payload as it goes there are various",
    "start": "1577700",
    "end": "1583130"
  },
  {
    "text": "constraints that both API gateway and lambda apply as well for asynchronous invocations there's only up to 128 K",
    "start": "1583130",
    "end": "1590060"
  },
  {
    "text": "that's available so keep those kind of constraints in mind one doily interesting element over here is",
    "start": "1590060",
    "end": "1596140"
  },
  {
    "text": "especially for API gateway you can control the protocol that gets passed on",
    "start": "1596140",
    "end": "1601160"
  },
  {
    "text": "into lambda right json is great it's very machine-readable but sometimes there are other protocols out there that you can",
    "start": "1601160",
    "end": "1607460"
  },
  {
    "text": "use for tuning the responses back so this is an example of swapping out the",
    "start": "1607460",
    "end": "1613160"
  },
  {
    "text": "JSON response coming in to lamda and processing it for protobuf for protocol buffers this uses the API gateway",
    "start": "1613160",
    "end": "1620060"
  },
  {
    "text": "capability of supporting binary requests and responses you can set the response type to binary change the header to",
    "start": "1620060",
    "end": "1625970"
  },
  {
    "text": "protobufs and it you can actually just pass any service that can emit protocol buffers out there the code here is",
    "start": "1625970",
    "end": "1632510"
  },
  {
    "text": "slightly different you see that there are I guess this doesn't have a there",
    "start": "1632510",
    "end": "1637820"
  },
  {
    "text": "are extra layers over here for reading the protobuf library transforming it",
    "start": "1637820",
    "end": "1642980"
  },
  {
    "text": "back into something that your function can actually execute and then responding with a specific protocol header so that",
    "start": "1642980",
    "end": "1650030"
  },
  {
    "text": "your responding or your client actually knows what it's reading back but if you get up to like a 40% smaller response in",
    "start": "1650030",
    "end": "1656030"
  },
  {
    "text": "this particular example that again can end up looking a much more leaner and faster responsive function for you right",
    "start": "1656030",
    "end": "1662120"
  },
  {
    "text": "so look at all three layers what's in working a function what it's actually passing in to your application and what",
    "start": "1662120",
    "end": "1668840"
  },
  {
    "text": "mechanism it is using the pass of those each of those has opportunities for you to trim things back over there so most",
    "start": "1668840",
    "end": "1676250"
  },
  {
    "text": "of these are crude towards sort of a cost reduction element of invitations what about resilience right and here",
    "start": "1676250",
    "end": "1682550"
  },
  {
    "text": "there's this construct which I like to call an event store which should or should not play a part in your",
    "start": "1682550",
    "end": "1687860"
  },
  {
    "text": "architecture depending on your choice right so what do I mean by this for many",
    "start": "1687860",
    "end": "1693830"
  },
  {
    "text": "applications we look at saying lambda comes in or a request comes in through a router like IOT or API gateway turns",
    "start": "1693830",
    "end": "1700460"
  },
  {
    "text": "around and invokes a lambda function which is great but you may have cases where you say these events need to be",
    "start": "1700460",
    "end": "1706850"
  },
  {
    "text": "stable even if the one emitting it goes down or these needs to be persisted in some durable fashion if lambda goes down",
    "start": "1706850",
    "end": "1713450"
  },
  {
    "text": "or it needs to be retried if for some reason lambda fails Kinesis tends to be",
    "start": "1713450",
    "end": "1719060"
  },
  {
    "text": "a favorite one for many data processing applications you use Kinesis as the bridge between your ingress point and",
    "start": "1719060",
    "end": "1724700"
  },
  {
    "text": "lambda you use Kinesis as your streaming mechanism for turning around and processing those applications sqs is",
    "start": "1724700",
    "end": "1730460"
  },
  {
    "text": "another viable choice and and there are different models for both of these right if you use a streaming based event so",
    "start": "1730460",
    "end": "1736850"
  },
  {
    "text": "you get things like ordering guarantees you get things like in currency guarantees but you're restricted in",
    "start": "1736850",
    "end": "1742430"
  },
  {
    "text": "terms of the fan-out that you can actually do something like a queue gives you the opposite semantics you can actually do retry behaviors you can get",
    "start": "1742430",
    "end": "1749780"
  },
  {
    "text": "much more concurrency but you lose things like ordering semantics and some kind of retrieval mechanism on it",
    "start": "1749780",
    "end": "1755150"
  },
  {
    "text": "both of these are built in to some of the AWS services that you use so for",
    "start": "1755150",
    "end": "1760250"
  },
  {
    "text": "example DynamoDB streams is an event store for DynamoDB stream for DynamoDB updates right it gives you a post-assad",
    "start": "1760250",
    "end": "1766700"
  },
  {
    "text": "mechanism for seeing what they've changed lock look like lambdas async api has a queue built-in so it gives you an",
    "start": "1766700",
    "end": "1773480"
  },
  {
    "text": "event store baked into it so that we can do retry policies underneath the covers but if you are constructing your own",
    "start": "1773480",
    "end": "1779000"
  },
  {
    "text": "server less slash event-driven architecture this becomes an intake important architectural consideration",
    "start": "1779000",
    "end": "1785030"
  },
  {
    "text": "for you to put in there's obviously a cost versus durability trade-off here you're bringing in another service you're bringing in another component",
    "start": "1785030",
    "end": "1791300"
  },
  {
    "text": "that you now have to manage but it can have a pretty significant impact on the durability of your function because you",
    "start": "1791300",
    "end": "1797390"
  },
  {
    "text": "now have events actually being captured and available for replay right oops",
    "start": "1797390",
    "end": "1804200"
  },
  {
    "text": "sorry I seem to have lost slide",
    "start": "1804200",
    "end": "1811550"
  },
  {
    "text": "somewhere all right I guess I'll let's have to go backwards so sorry about that",
    "start": "1811550",
    "end": "1817100"
  },
  {
    "text": "okay so quick reminder lambda thinks if it's scale in terms of concurrency it's",
    "start": "1817100",
    "end": "1822470"
  },
  {
    "text": "not request space it's not duration based right concurrency is a unit of essentially your request straight into",
    "start": "1822470",
    "end": "1828890"
  },
  {
    "text": "your duration of your function and the processing model is slightly different different depending on how you invoke",
    "start": "1828890",
    "end": "1834380"
  },
  {
    "text": "your lambda if you're calling it straight forward directly through the API or you're using a synchronous",
    "start": "1834380",
    "end": "1839780"
  },
  {
    "text": "mechanism lambda will spin up as many copies as required for each individual request if you're using a queue based or",
    "start": "1839780",
    "end": "1846590"
  },
  {
    "text": "an async mechanism for doing so beat your own queue store you still get the concurrency behavior over there except",
    "start": "1846590",
    "end": "1852530"
  },
  {
    "text": "the events themselves are eaten for some window of time making it available for retries and then if it's stream based",
    "start": "1852530",
    "end": "1859070"
  },
  {
    "text": "it's slightly different because now your concurrency is driven by the ordering on the stream source itself so if you're",
    "start": "1859070",
    "end": "1865580"
  },
  {
    "text": "using something like Kinesis your concurrency is driven by the number of shards that are on kinney's a stream so that you basically",
    "start": "1865580",
    "end": "1872000"
  },
  {
    "text": "can maintain the ordering guarantee of processing on each one of those now this is interesting implications on both your",
    "start": "1872000",
    "end": "1878210"
  },
  {
    "text": "end to end processing as well as your resiliency so let me I mean I'm sorry about the thing but I'm gonna skip back",
    "start": "1878210",
    "end": "1883850"
  },
  {
    "text": "okay so when it comes to streams your concurrency has your latency has an",
    "start": "1883850",
    "end": "1890960"
  },
  {
    "text": "interesting impact on your concurrency right your maximum theoretical throughput when you're using a stream",
    "start": "1890960",
    "end": "1897140"
  },
  {
    "text": "based processing application is the number of shards which drives the concurrency of your function into about",
    "start": "1897140",
    "end": "1902660"
  },
  {
    "text": "two Meg's per second which is the output that you get from Kinesis what this means is if your number of shards if",
    "start": "1902660",
    "end": "1910040"
  },
  {
    "text": "your function is taking longer to process because the effective theoretical throughput is driven by that if your function is taking longer to",
    "start": "1910040",
    "end": "1916700"
  },
  {
    "text": "process your concurrency becomes a bottleneck it'll cause your data to start backing up over there right",
    "start": "1916700",
    "end": "1922130"
  },
  {
    "text": "because your throughput is not getting gated over there so the only way for you to make your end-to-end latency faster",
    "start": "1922130",
    "end": "1927320"
  },
  {
    "text": "and keep it going is to increase the concurrency obviously you can make your function run faster but if it is what it",
    "start": "1927320",
    "end": "1932840"
  },
  {
    "text": "is if you're seeing you end-to-end latency slow down increasing concurrency or the number of shards on your Kinesis",
    "start": "1932840",
    "end": "1938840"
  },
  {
    "text": "stream may be the way for you to see optimization if you're using a queue based mechanism though it's it's the",
    "start": "1938840",
    "end": "1944150"
  },
  {
    "text": "inverse right your concurrency is only bound by the overall account limit that you have you know forty thousand one",
    "start": "1944150",
    "end": "1950360"
  },
  {
    "text": "hundred thousand as much as you guys have right now but your duration has a direct impact on how much concurrency",
    "start": "1950360",
    "end": "1956120"
  },
  {
    "text": "you can write so the pattern we see is someone had a function running at you know 20,000 TPS and suddenly they start",
    "start": "1956120",
    "end": "1963440"
  },
  {
    "text": "seeing throttling at 5,000 TPS and when they go and look at the numbers they find that their duration jumped up to 10",
    "start": "1963440",
    "end": "1969530"
  },
  {
    "text": "seconds because it was getting throttled by some downstream service or some kind of timeouts were happening so a direct",
    "start": "1969530",
    "end": "1975470"
  },
  {
    "text": "impact and the latency can cause your concurrency to actually flatten out just because and cause you're sorry your",
    "start": "1975470",
    "end": "1983480"
  },
  {
    "text": "request rate to flatten out because your concurrency stays the same but your duration actually went up so the",
    "start": "1983480",
    "end": "1988940"
  },
  {
    "text": "practice for you to remember depending on how you're architected is to make sure that you're looking at the new concurrency metric so if you go to your",
    "start": "1988940",
    "end": "1995600"
  },
  {
    "text": "your console right now you will see a new metric in there that says concurrent invocations that tells you what is the",
    "start": "1995600",
    "end": "2001630"
  },
  {
    "text": "effective concurrency that is available for your account level as you as well as your individual functions this becomes",
    "start": "2001630",
    "end": "2007000"
  },
  {
    "text": "another important one to monitor and track and Peter will be talking a little bit more about this once we get there",
    "start": "2007000",
    "end": "2012340"
  },
  {
    "text": "right I'm all about the slides today okay so the last one I leave you with is",
    "start": "2012340",
    "end": "2019120"
  },
  {
    "text": "how you end up architecting has impact on the internal realities as well if you're using services that we have like",
    "start": "2019120",
    "end": "2025840"
  },
  {
    "text": "in ESA's and SNS or even lambdas async api itself there are some retries built-in right if you do async you have",
    "start": "2025840",
    "end": "2032290"
  },
  {
    "text": "up to Tory tries if you using Kinesis it actually has essentially an infinite reach right all the data data replay",
    "start": "2032290",
    "end": "2038350"
  },
  {
    "text": "happens a tool that many people overlook here for resiliency though is using a dead letter Q right when you have an",
    "start": "2038350",
    "end": "2045160"
  },
  {
    "text": "event-driven system where events are flowing through it services lambda supports the concept of a dead letter Q",
    "start": "2045160",
    "end": "2050770"
  },
  {
    "text": "either using sqs or SNS that captures the failed events that did not get processed and then make it available for",
    "start": "2050770",
    "end": "2056530"
  },
  {
    "text": "retry right so you can essentially build as many or as complex or retry procedure",
    "start": "2056530",
    "end": "2061868"
  },
  {
    "text": "that you care about outside of the retry modules that but lambda itself provides okay so this goes back into that",
    "start": "2061869",
    "end": "2068950"
  },
  {
    "text": "resiliency construct like you have to think through what are the failure paths that happen inside your lambda function and set these controls in place but more",
    "start": "2068950",
    "end": "2075820"
  },
  {
    "text": "often than not dlq makes it much more resilient for you to go forward now this",
    "start": "2075820",
    "end": "2081820"
  },
  {
    "text": "is not something that's available for Kinesis some people tell us that they want to dial down the retry policy that",
    "start": "2081820",
    "end": "2087850"
  },
  {
    "text": "we have for Kinesis because it's very aggressive but there's actually a way for you to simulate this behavior quite easily with any of the services really",
    "start": "2087850",
    "end": "2094750"
  },
  {
    "text": "and that's why using using SNS so SNS simple notification service actually has",
    "start": "2094750",
    "end": "2101619"
  },
  {
    "text": "its own dlq built-in same mechanism as lambda you can route it to an S q SQ in",
    "start": "2101619",
    "end": "2107920"
  },
  {
    "text": "this particular example the failed events from Kinesis being processed instead of sending back in error to",
    "start": "2107920",
    "end": "2113680"
  },
  {
    "text": "Kinesis which triggers the retry behavior it says my execution actually succeeded and dumps the payload out into",
    "start": "2113680",
    "end": "2120640"
  },
  {
    "text": "SNS and does a retry through that particular mechanism now you know the the caveat I would put here as this only",
    "start": "2120640",
    "end": "2126850"
  },
  {
    "text": "works if for some reason in your Kinesis stream you do not care about the ordering guarantee that's in place but",
    "start": "2126850",
    "end": "2133420"
  },
  {
    "text": "at least gives you a way to capture the payload that's coming out and then go moving forward over there right okay so",
    "start": "2133420",
    "end": "2140710"
  },
  {
    "text": "on that on that invocation front kind of coming back to it it's about succinctly loads making sure that what you're",
    "start": "2140710",
    "end": "2146530"
  },
  {
    "text": "passing into your function is very specific making sure that the routing layer or the service that you're picking",
    "start": "2146530",
    "end": "2151960"
  },
  {
    "text": "to get your invents to your functions has constructs of resiliency built into it either in the mode that's it's",
    "start": "2151960",
    "end": "2157840"
  },
  {
    "text": "invoking it or the way it's routing it and finally remember design your application for concurrent executions",
    "start": "2157840",
    "end": "2164200"
  },
  {
    "text": "right it's about not about request rate it's not about duration watch your concurrency that's what's gonna make or",
    "start": "2164200",
    "end": "2169660"
  },
  {
    "text": "break how your application is functioning over there alright last part and then then you get to hear Peter more than I do",
    "start": "2169660",
    "end": "2175720"
  },
  {
    "text": "all right so last part lambda talking to downstream services the kata three is thinking about coordinated calls right",
    "start": "2175720",
    "end": "2182800"
  },
  {
    "text": "and this becomes important because lambda is somewhat unique in its behavior is a sort of behavior of",
    "start": "2182800",
    "end": "2188230"
  },
  {
    "text": "automatically spinning up and down automatically running idempotent copies of your function all of those become",
    "start": "2188230",
    "end": "2193510"
  },
  {
    "text": "somewhat unique when it comes to compute layers right one call out is in this is",
    "start": "2193510",
    "end": "2200860"
  },
  {
    "text": "again more of a best practice than a must-do is making sure that the way you're setting up your application has",
    "start": "2200860",
    "end": "2206230"
  },
  {
    "text": "api source contracts the reason this becomes important especially in a lambda world is because separation of concerns",
    "start": "2206230",
    "end": "2213190"
  },
  {
    "text": "especially when you're talking about scale guarantees having something like an api in between allows you to separate",
    "start": "2213190",
    "end": "2218470"
  },
  {
    "text": "those out so in this example suppose you know this is a theoretical ingestion service that gets processed by a",
    "start": "2218470",
    "end": "2224740"
  },
  {
    "text": "metadata extraction service that's fronted by a front-end service right with three separate api is over here if",
    "start": "2224740",
    "end": "2230620"
  },
  {
    "text": "for some reason there's a data surge in my ingestion service you can actually use the API or on the metadata service",
    "start": "2230620",
    "end": "2238450"
  },
  {
    "text": "as a way to do rate limited or throttle it down because there is a separation of concern over there and that prevents you",
    "start": "2238450",
    "end": "2244300"
  },
  {
    "text": "from tossing the actual database which is sitting behind the lambda service right which is the one that you're talking over here so again this may not",
    "start": "2244300",
    "end": "2251200"
  },
  {
    "text": "be always possible this may not be always possible out of the door this may be something that you're already doing",
    "start": "2251200",
    "end": "2256420"
  },
  {
    "text": "for other micro services based approaches but it becomes especially important when you're building several as architectures because the contract is",
    "start": "2256420",
    "end": "2263500"
  },
  {
    "text": "your border of resiliency as well between these particular services",
    "start": "2263500",
    "end": "2268470"
  },
  {
    "text": "when it comes to non API calls that you're making say databases or others",
    "start": "2269079",
    "end": "2274220"
  },
  {
    "text": "you need to have what I call scale matching right most databases especially",
    "start": "2274220",
    "end": "2279650"
  },
  {
    "text": "when you talk about relational databases have unique behaviors when you talk about scaling it in and out there are",
    "start": "2279650",
    "end": "2284809"
  },
  {
    "text": "finite number of connections it can handle they may be api's that can only handle a finite number of calls you may",
    "start": "2284809",
    "end": "2291650"
  },
  {
    "text": "be having this old crafty thing sitting on an on-prem that you need to call out to all of those have certain limitations",
    "start": "2291650",
    "end": "2297020"
  },
  {
    "text": "that you can't go to make sure that when lambda is calling out to them you're matching your scale configuration for",
    "start": "2297020",
    "end": "2302660"
  },
  {
    "text": "lambda to it now this is a control we actually just rolled out today you can",
    "start": "2302660",
    "end": "2307760"
  },
  {
    "text": "actually specify the concurrency or the max concurrency for individual functions",
    "start": "2307760",
    "end": "2313250"
  },
  {
    "text": "right what this allows you to do is you remember that the concurrency diagram we",
    "start": "2313250",
    "end": "2318260"
  },
  {
    "text": "were talking about restrict an individual function from Fanning out beyond a certain limit it also acts as a",
    "start": "2318260",
    "end": "2323599"
  },
  {
    "text": "reservation so if you have one function going AWOL on one end you can come back and say no no no lock it out or lock it",
    "start": "2323599",
    "end": "2329630"
  },
  {
    "text": "forward but this gives you a way for building guarantees or isolation around individual functions especially when",
    "start": "2329630",
    "end": "2336020"
  },
  {
    "text": "it's interacting with multiple other services okay the diagram at the bottom actually shows you the new concurrency",
    "start": "2336020",
    "end": "2342170"
  },
  {
    "text": "mech mechanism in Access I gave my individual function amazing limit of",
    "start": "2342170",
    "end": "2348200"
  },
  {
    "text": "just five concurrent executions and you'll see that in the in the green line in the diagram it actually gets capped",
    "start": "2348200",
    "end": "2354079"
  },
  {
    "text": "at that particular limit stays that way and then goes back down right so this kind of behavior allows you to match for",
    "start": "2354079",
    "end": "2362390"
  },
  {
    "text": "example the max number of connections that your database can handle the max number of en is or IPS that you may have",
    "start": "2362390",
    "end": "2369079"
  },
  {
    "text": "in a V PC subnet that you can figure out your function essentially having a little bit more control on the scale",
    "start": "2369079",
    "end": "2374119"
  },
  {
    "text": "behavior over there right again because of the resiliency factor a database outage is an outage for your function",
    "start": "2374119",
    "end": "2379940"
  },
  {
    "text": "right it's an outage for your application you want to protect the data you want to make sure that because lambda has retry",
    "start": "2379940",
    "end": "2385700"
  },
  {
    "text": "behaviors at that particular layer if you have done the event configuration correctly before you want to prevent",
    "start": "2385700",
    "end": "2391430"
  },
  {
    "text": "lambda from taking down anything else over there rather than having any other configurations in place and last one",
    "start": "2391430",
    "end": "2398390"
  },
  {
    "text": "I'll call out on on the security front is about the PC configuration right many of us think",
    "start": "2398390",
    "end": "2404060"
  },
  {
    "text": "about V PC as an amazing security and isolation mechanism in place and the",
    "start": "2404060",
    "end": "2411200"
  },
  {
    "text": "compute substrate that are referred to by earlier on by default gone-zo functions within a V PC there's no way",
    "start": "2411200",
    "end": "2417170"
  },
  {
    "text": "for any external actor to access those functions in our compute environment it's only through the invocation or the",
    "start": "2417170",
    "end": "2423050"
  },
  {
    "text": "API is that lambda itself provides so when you ask yourself the question of should Yolanda be in a V PC the only",
    "start": "2423050",
    "end": "2429410"
  },
  {
    "text": "situation where you need to think about having access to your giving V PC configurations to your lambda function",
    "start": "2429410",
    "end": "2435440"
  },
  {
    "text": "is if it needs to access a resource that's within a V PC right database",
    "start": "2435440",
    "end": "2440450"
  },
  {
    "text": "ElastiCache private API is what have you for anything else don't bother configuring a V PC for your",
    "start": "2440450",
    "end": "2448250"
  },
  {
    "text": "function because it has implications on both your latency and resiliency if you do have it make sure that you put lambda",
    "start": "2448250",
    "end": "2454970"
  },
  {
    "text": "and a subnet with not access because you have services such as cloud watch you",
    "start": "2454970",
    "end": "2460040"
  },
  {
    "text": "have services such as Kinesis or s3 that will be part of your application logic that you actually may need to go and",
    "start": "2460040",
    "end": "2465290"
  },
  {
    "text": "have access to and that requires you to go through internet access if for some reason your service is the only requires",
    "start": "2465290",
    "end": "2471890"
  },
  {
    "text": "resources within it then put it in a private subnet only I don't don't bother with it this diagram is is probably with",
    "start": "2471890",
    "end": "2480140"
  },
  {
    "text": "better colors rendered in our documentation as well so so it's available here for you for you for reference so what what trade-off does it",
    "start": "2480140",
    "end": "2488150"
  },
  {
    "text": "have on your latency and your resiliency remember the cold-start diagram we talked about earlier you'll see there",
    "start": "2488150",
    "end": "2494660"
  },
  {
    "text": "are now two more blocks that show up which is using the setup of network interfaces and instantiating or",
    "start": "2494660",
    "end": "2500630"
  },
  {
    "text": "attaching those network interfaces to the portion of the compute substrate where your lambda function is executing",
    "start": "2500630",
    "end": "2506690"
  },
  {
    "text": "these are not fast operations it just takes time right these could take up to multiple seconds to instantiate and we",
    "start": "2506690",
    "end": "2513170"
  },
  {
    "text": "have done a bunch of work to try and I you know it minimize the impact of that on your audio invocation but the reality",
    "start": "2513170",
    "end": "2519020"
  },
  {
    "text": "of it is it will add in vacation time or to your call starts over there as small as they add it maybe so if you are",
    "start": "2519020",
    "end": "2525530"
  },
  {
    "text": "choosing to do so be cognizant of that particular impact that it's going to do it right so in the worst case scenario",
    "start": "2525530",
    "end": "2532580"
  },
  {
    "text": "if you have an application that has an RDS instance that has VPC where you have taken a fully-stocked AWS sdk stuffed it into a",
    "start": "2532580",
    "end": "2540230"
  },
  {
    "text": "jar file and put it in in in front of an api and then you're looking for 100 millisecond response you're not gonna",
    "start": "2540230",
    "end": "2546620"
  },
  {
    "text": "get it right it's just not your p99 is not going to be that there will be other parts which will be so be aware of that",
    "start": "2546620",
    "end": "2552140"
  },
  {
    "text": "particular decision before you go forth and put it over there the other element which has a trade-off on is resilience",
    "start": "2552140",
    "end": "2558820"
  },
  {
    "text": "the a giving lambda functions access to your V PC is very powerful because you control the network substrate you can",
    "start": "2558820",
    "end": "2565070"
  },
  {
    "text": "get private isolation everything is great but it also means you now control it which means you also now have a",
    "start": "2565070",
    "end": "2571010"
  },
  {
    "text": "shared responsibility in the availability of that particular function we require you to make sure that the V",
    "start": "2571010",
    "end": "2576950"
  },
  {
    "text": "PC is available across multiple availability zones something that we do by default when we are executing the function the isolation behavior I would",
    "start": "2576950",
    "end": "2584930"
  },
  {
    "text": "recommend is making sure you give lambda its own dedicated subnets so that you don't accidentally as lambda scales up",
    "start": "2584930",
    "end": "2591020"
  },
  {
    "text": "or down doesn't accidentally end up draining the subnets for for someone else that who needs it",
    "start": "2591020",
    "end": "2596420"
  },
  {
    "text": "and finally the same reminder I gave you before is that if your function needs to talk to the Internet make sure that it's",
    "start": "2596420",
    "end": "2601820"
  },
  {
    "text": "set up with a NAT right so that this was relatively more compact because once",
    "start": "2601820",
    "end": "2607280"
  },
  {
    "text": "lambda is execute a lot of the optimizations we talked about earlier about fixing your function and walking",
    "start": "2607280",
    "end": "2612800"
  },
  {
    "text": "it get you a long way in wadiya logic executes as well but for your downstream calls keep these three things in mind",
    "start": "2612800",
    "end": "2618710"
  },
  {
    "text": "try to decoupled as much as possible through API so that you have clean separation and isolation make sure that",
    "start": "2618710",
    "end": "2624650"
  },
  {
    "text": "your scale matching to your resources that have scale constraints and that you're securing them appropriately using",
    "start": "2624650",
    "end": "2630740"
  },
  {
    "text": "the appropriate isolation mechanisms as needed all right so with that we've kind of covered a lot of the the theoretical",
    "start": "2630740",
    "end": "2638240"
  },
  {
    "text": "possibilities over here I wanted to invite Peter Spassky on stage to tell you how they actually put a lot of these",
    "start": "2638240",
    "end": "2643550"
  },
  {
    "text": "pieces into practice at a cloud guru Peter",
    "start": "2643550",
    "end": "2648880"
  },
  {
    "text": "okay hello how's everybody doing good",
    "start": "2650080",
    "end": "2657410"
  },
  {
    "text": "excellent is anybody excited for replay yes I am very excited yeah absolutely so",
    "start": "2657410",
    "end": "2666320"
  },
  {
    "text": "look I'm very pleased to join you today and to join AJ on this stage and I will",
    "start": "2666320",
    "end": "2672170"
  },
  {
    "text": "talk about service full service full operations I guess the one takeaway that",
    "start": "2672170",
    "end": "2677510"
  },
  {
    "text": "I have for all of you is that in the end everything depends on people everything",
    "start": "2677510",
    "end": "2682850"
  },
  {
    "text": "is up to you so you can be given access to the best technology like lambda to best opportunities but you need to",
    "start": "2682850",
    "end": "2689450"
  },
  {
    "text": "enable your people to succeed and that includes education and guidance it includes setting the right process and",
    "start": "2689450",
    "end": "2695900"
  },
  {
    "text": "it includes instilling that culture of automation and innovation next slide so",
    "start": "2695900",
    "end": "2702830"
  },
  {
    "text": "I work for a company called a cloud guru and our mission is to teach cloud",
    "start": "2702830",
    "end": "2708110"
  },
  {
    "text": "computing to the world so we have online courses that allow you to learn AWS we",
    "start": "2708110",
    "end": "2714230"
  },
  {
    "text": "have causes the tower servers help you study for an aw aw a certification or",
    "start": "2714230",
    "end": "2720710"
  },
  {
    "text": "get kind of in-depth insight into topics like security so we started two years",
    "start": "2720710",
    "end": "2726800"
  },
  {
    "text": "ago and we built an entirely serverless company in fact we were doing servers before anybody even said the word",
    "start": "2726800",
    "end": "2733730"
  },
  {
    "text": "service I think we were using lambda and you couldn't even call it from the web right there was no API gateway and we",
    "start": "2733730",
    "end": "2741800"
  },
  {
    "text": "are an interesting case study because we are a start-up yet we have 400,000 people and we've been able to do to all",
    "start": "2741800",
    "end": "2749240"
  },
  {
    "text": "service Lee so we have rich web application mobile apps and you don't need to server to do any of that so",
    "start": "2749240",
    "end": "2756170"
  },
  {
    "text": "that's great so let's take a look at some weekly stats and what we do so on average a week we execute 6.2 1 million",
    "start": "2756170",
    "end": "2764600"
  },
  {
    "text": "lambda invitations that's got a good amount we have 488 lambda functions",
    "start": "2764600",
    "end": "2770840"
  },
  {
    "text": "across 15 environments and this include test environments as well and we do",
    "start": "2770840",
    "end": "2776780"
  },
  {
    "text": "approximately 4 million API requests using API gateway there's the production",
    "start": "2776780",
    "end": "2782970"
  },
  {
    "text": "PFF service that does 3.97 million requests in this case BFF stands for",
    "start": "2782970",
    "end": "2789900"
  },
  {
    "text": "back end for front ends not best friends forever just letting you know and that's",
    "start": "2789900",
    "end": "2795180"
  },
  {
    "text": "our graph QL endpoint and I think I'm actually excited about appsync and the",
    "start": "2795180",
    "end": "2800460"
  },
  {
    "text": "new graph QL managed service that AWS has released I'm sure our team will",
    "start": "2800460",
    "end": "2806400"
  },
  {
    "text": "evaluate that as well we have you know 142 buckets with over 2 terrible 2",
    "start": "2806400",
    "end": "2812610"
  },
  {
    "text": "terabytes of data and we serve almost 7 terabytes of that a weekly using cloud",
    "start": "2812610",
    "end": "2818490"
  },
  {
    "text": "front so why am I telling you this this is because all the tips that AJ just shave of you are extremely",
    "start": "2818490",
    "end": "2825500"
  },
  {
    "text": "important to us because we need to optimize the performance of our application let's say if on average our",
    "start": "2825500",
    "end": "2832890"
  },
  {
    "text": "functions take 101 milliseconds to execute if we shave off 2 milliseconds",
    "start": "2832890",
    "end": "2839010"
  },
  {
    "text": "and go to 99 milliseconds average execution time we have effectively",
    "start": "2839010",
    "end": "2844560"
  },
  {
    "text": "halved our bill and at our scale that means something so the three things that",
    "start": "2844560",
    "end": "2850320"
  },
  {
    "text": "I kind of want to talk to you about today are automation monitor monitoring and innovation so let's start with",
    "start": "2850320",
    "end": "2857760"
  },
  {
    "text": "automation first so serverless applications as you know are distributed by nature right there's no way you can",
    "start": "2857760",
    "end": "2865650"
  },
  {
    "text": "get away from it and so we have numerous lambda functions we have our single page application we have various services",
    "start": "2865650",
    "end": "2872490"
  },
  {
    "text": "that we need to deploy to and update we need to make changes to firebase firebase which is our real-time",
    "start": "2872490",
    "end": "2878010"
  },
  {
    "text": "streaming data base and it's impossible to do it well without automate without",
    "start": "2878010",
    "end": "2883230"
  },
  {
    "text": "automation and testing so you can see in the diagram that we have give hub right to use github which connects to Travis",
    "start": "2883230",
    "end": "2889410"
  },
  {
    "text": "CI Travis CI then deploys to AWS it can deploy or update other services and it",
    "start": "2889410",
    "end": "2895590"
  },
  {
    "text": "can also deploy our front-end and that's quite a normal setup that you would have seen many times before and we also use",
    "start": "2895590",
    "end": "2903690"
  },
  {
    "text": "service framework kind of for orchestration and deployment and we use ansible for our dev environment so we",
    "start": "2903690",
    "end": "2911250"
  },
  {
    "text": "kind of deploy some additional cloud automation scripts so just a few tips that",
    "start": "2911250",
    "end": "2916680"
  },
  {
    "text": "we learned is that you know obviously don't go service without automating the provision and deployment of your",
    "start": "2916680",
    "end": "2923069"
  },
  {
    "text": "application test in fact I would recommend set up your deployment pipeline and only then begin working on",
    "start": "2923069",
    "end": "2929760"
  },
  {
    "text": "your application obviously mandate the use of frameworks such as Sam or service",
    "start": "2929760",
    "end": "2936930"
  },
  {
    "text": "framework you know it's a must have a look at other frameworks as well like chalice or apex and instill the culture",
    "start": "2936930",
    "end": "2944790"
  },
  {
    "text": "of automation furthermore there is no such fingers no ops that doesn't exist right so DevOps is important so make",
    "start": "2944790",
    "end": "2952470"
  },
  {
    "text": "sure you know how to contact AWS support make friends with them think about how",
    "start": "2952470",
    "end": "2957540"
  },
  {
    "text": "you are going to do DevOps when going service when it comes to testing again",
    "start": "2957540",
    "end": "2963030"
  },
  {
    "text": "extremely important because for us our code is our infrastructure it is our",
    "start": "2963030",
    "end": "2969050"
  },
  {
    "text": "application so we need to have a thorough test coverage and we use selenium we use gesture and Travis CI",
    "start": "2969050",
    "end": "2976910"
  },
  {
    "text": "execute all those tests for us obviously we don't merge or we don't deploy if",
    "start": "2976910",
    "end": "2981930"
  },
  {
    "text": "there are any problems or any tests fail and if you've ever if you've been doing",
    "start": "2981930",
    "end": "2987299"
  },
  {
    "text": "that kind of manual user driven testing it's not going to work for you in a service scenario right because you can't",
    "start": "2987299",
    "end": "2994859"
  },
  {
    "text": "really emulate AWS locally you would have to then kind of deploy to AWS test",
    "start": "2994859",
    "end": "3000619"
  },
  {
    "text": "things redeploy a fix it's just it's a terrible process so you have to have a",
    "start": "3000619",
    "end": "3005930"
  },
  {
    "text": "thorough test coverage and we test our components at a different level of granularity right our tests process even",
    "start": "3005930",
    "end": "3012950"
  },
  {
    "text": "hits the API gateway in the process the other important aspect that we've tried",
    "start": "3012950",
    "end": "3020210"
  },
  {
    "text": "to instill in our company is that of monitoring right so you need to be aware",
    "start": "3020210",
    "end": "3025520"
  },
  {
    "text": "of what's going on inside your system right how do you know if a component is",
    "start": "3025520",
    "end": "3030799"
  },
  {
    "text": "failing I mean it's a distributed system it could have it could be hard to detect what's going on so use alerts but make",
    "start": "3030799",
    "end": "3038540"
  },
  {
    "text": "sure kind of to calibrate the signal-to-noise ratio explore third-party tooling you don't have to",
    "start": "3038540",
    "end": "3044270"
  },
  {
    "text": "use just AWS services sorry AJ so you know we've sportings like sumo logic and",
    "start": "3044270",
    "end": "3050420"
  },
  {
    "text": "there this other tooling that you can have a look at use services like x-ray to get a holistic understanding of your system",
    "start": "3050420",
    "end": "3057410"
  },
  {
    "text": "distributed systems are hard we have cloud trail enabled for everything and",
    "start": "3057410",
    "end": "3063619"
  },
  {
    "text": "social you so we have something like 566 alarms which which is about four alarms",
    "start": "3063619",
    "end": "3070369"
  },
  {
    "text": "per production lambda and so we have an alarm that will notify us if there's more than one error of every five",
    "start": "3070369",
    "end": "3076519"
  },
  {
    "text": "minutes if the duration of the function kind of was longer than we expected if",
    "start": "3076519",
    "end": "3082160"
  },
  {
    "text": "the function ran many more times than we expect or if functions were throttled here's",
    "start": "3082160",
    "end": "3089240"
  },
  {
    "text": "another service we use called run scope and what it does it helps us to monitor",
    "start": "3089240",
    "end": "3094549"
  },
  {
    "text": "the responsiveness and latency of our system right so it continuously makes",
    "start": "3094549",
    "end": "3099559"
  },
  {
    "text": "requests so CloudFront to detect whether we can access our files it hits of zero",
    "start": "3099559",
    "end": "3105200"
  },
  {
    "text": "which is our authentication solution it hits firebase it hits our API it hits our front-end and would rather find out",
    "start": "3105200",
    "end": "3112970"
  },
  {
    "text": "from runs run scope that something bad is going on than from our users and it's",
    "start": "3112970",
    "end": "3118400"
  },
  {
    "text": "a great thing because let's say our graph QL API starts having issues latency spikes up or it goes down you",
    "start": "3118400",
    "end": "3125329"
  },
  {
    "text": "know we can immediately detect it and we can start doing something about it right we can see okay is it something that we",
    "start": "3125329",
    "end": "3131690"
  },
  {
    "text": "deployed recently that's causing an issue or is it an outage in some other part of the system we can notify our",
    "start": "3131690",
    "end": "3137779"
  },
  {
    "text": "users we can begin an active investigation put workarounds so you have to be acutely aware of what's going",
    "start": "3137779",
    "end": "3143960"
  },
  {
    "text": "on and you will do it with monitoring another important thing to remember is",
    "start": "3143960",
    "end": "3151789"
  },
  {
    "text": "you know obviously security and it's actually quite easy to forget in service context I think some of us have that you",
    "start": "3151789",
    "end": "3158660"
  },
  {
    "text": "know kind of thinking that our cloud provider AWS will take care of error everything it's actually joint",
    "start": "3158660",
    "end": "3165109"
  },
  {
    "text": "responsibility right AWS takes care of some stuff but we have to take care of a",
    "start": "3165109",
    "end": "3170450"
  },
  {
    "text": "few things as well so make sure that your I am roles users and policies are",
    "start": "3170450",
    "end": "3175849"
  },
  {
    "text": "as tight as they can be right have a Roper function explore that party",
    "start": "3175849",
    "end": "3180890"
  },
  {
    "text": "tooling as well to help you figure out if your permissions are too loose use things like AWS km/s whenever",
    "start": "3180890",
    "end": "3187700"
  },
  {
    "text": "possible and make sure to understand that as you add more services and endpoint endpoints your surface area for",
    "start": "3187700",
    "end": "3194420"
  },
  {
    "text": "attack increases and which brings me to almost always top 10 and mark another",
    "start": "3194420",
    "end": "3200510"
  },
  {
    "text": "common get an excellent presentation about it at service conf New York a few months ago and I'm sure a lot of you",
    "start": "3200510",
    "end": "3208100"
  },
  {
    "text": "will be familiar with this these are kind of the top 10 threats and it's interesting how they apply to kind of",
    "start": "3208100",
    "end": "3215030"
  },
  {
    "text": "our service environment now let's take injection you know when we talk about injection we usually think of simple",
    "start": "3215030",
    "end": "3221660"
  },
  {
    "text": "injection right but what about lambda could you actually inject some code into lambda some bad code or something and",
    "start": "3221660",
    "end": "3228830"
  },
  {
    "text": "have our lambda function executed you know maybe it's possible and in fact I have a feeling that over the years as",
    "start": "3228830",
    "end": "3235640"
  },
  {
    "text": "kind of service it's the world will see those attacks happen here",
    "start": "3235640",
    "end": "3242390"
  },
  {
    "text": "security miss configuration easy to do those using components with known vulnerabilities very easy like we use no",
    "start": "3242390",
    "end": "3249890"
  },
  {
    "text": "GS right for our functions and usually you install you know a dependency and it",
    "start": "3249890",
    "end": "3255109"
  },
  {
    "text": "downloads half the entire Internet along side with it right so you have have the entire Internet you package up your",
    "start": "3255109",
    "end": "3261350"
  },
  {
    "text": "lambda function deployed but then how do you know if you know one of those dependencies is out of date they have a",
    "start": "3261350",
    "end": "3267590"
  },
  {
    "text": "process in place so we do we look at all the new patches that come out and all the new updates and social you and",
    "start": "3267590",
    "end": "3274369"
  },
  {
    "text": "finally this one insufficient logging and monitoring and I reckon it's a problem in our service",
    "start": "3274369",
    "end": "3279800"
  },
  {
    "text": "community because I get a lot of people asking me about this how do you do your monitoring and logging so I kind of just",
    "start": "3279800",
    "end": "3286369"
  },
  {
    "text": "spoke about how we do it but I urge you to think about it and finally let's talk",
    "start": "3286369",
    "end": "3294290"
  },
  {
    "text": "about innovation and this is I guess it's a bit of a fuzzy topic but I've",
    "start": "3294290",
    "end": "3301670"
  },
  {
    "text": "come to a few realizations that I want to share with you look ultimately the tips and the tricks and the processes",
    "start": "3301670",
    "end": "3308270"
  },
  {
    "text": "and the patterns that you know AJ shared today with you will be applied incrementally as you progress through",
    "start": "3308270",
    "end": "3314150"
  },
  {
    "text": "your journey right they won't happen overnight so and you this applies to your architecture too",
    "start": "3314150",
    "end": "3320359"
  },
  {
    "text": "you can start with one type of architecture and then transition it to another type of architecture and this",
    "start": "3320359",
    "end": "3326809"
  },
  {
    "text": "happened with us at a cloud guru we started and we basically build a service monolith we had one database we had a",
    "start": "3326809",
    "end": "3333229"
  },
  {
    "text": "bunch of functions that all spoke to that database and we scaled to about 200 thousand users but then we realized that",
    "start": "3333229",
    "end": "3340849"
  },
  {
    "text": "we needed to scale even further and we needed to go to a micro services approach because we wanted to scale our",
    "start": "3340849",
    "end": "3346640"
  },
  {
    "text": "components individually as well and we wanted to have teams work and components",
    "start": "3346640",
    "end": "3351969"
  },
  {
    "text": "kind of individually not step on each other's toes so we were able to transition from a service monolith to",
    "start": "3351969",
    "end": "3359779"
  },
  {
    "text": "micro services just by changing some of our code and changing the service dot",
    "start": "3359779",
    "end": "3365599"
  },
  {
    "text": "Yama file it's quite incredible incredible that we didn't need to provision any new arc any new you know",
    "start": "3365599",
    "end": "3371809"
  },
  {
    "text": "environments we didn't need to provision a new service anything like that it was just all done in code so that's the",
    "start": "3371809",
    "end": "3378019"
  },
  {
    "text": "magic of services right it we were able to kind of evolve a lot quicker than",
    "start": "3378019",
    "end": "3383289"
  },
  {
    "text": "normally you or I could so look make the trade-offs that are relevant to your",
    "start": "3383289",
    "end": "3388880"
  },
  {
    "text": "business right it may be you may have to go hybrid and do service and containers but don't be scared you will be able to",
    "start": "3388880",
    "end": "3396140"
  },
  {
    "text": "evolve your architecture so AJ said to me that it's not energy its agility and",
    "start": "3396140",
    "end": "3402469"
  },
  {
    "text": "I love that and just a few more slides you know as you evolve best practice",
    "start": "3402469",
    "end": "3408380"
  },
  {
    "text": "will change you know this is still early days yet so please learn from the",
    "start": "3408380",
    "end": "3413420"
  },
  {
    "text": "community and contribute back to the community as well when we started Sam",
    "start": "3413420",
    "end": "3419089"
  },
  {
    "text": "didn't exist service framework didn't exist so we rolled our own deployment scripts using grunt and that worked very",
    "start": "3419089",
    "end": "3425420"
  },
  {
    "text": "well and then we were able to migrate to service framework which was created by",
    "start": "3425420",
    "end": "3430819"
  },
  {
    "text": "the community and that was great as well and this leads me to kind of my final",
    "start": "3430819",
    "end": "3436940"
  },
  {
    "text": "point here that look there is a human hack here as well going service is fun",
    "start": "3436940",
    "end": "3444400"
  },
  {
    "text": "right it's inspirational if you announce a project that service at your workplace",
    "start": "3444400",
    "end": "3450920"
  },
  {
    "text": "you are likely to get very passionate developers joining that project right because they love this",
    "start": "3450920",
    "end": "3456920"
  },
  {
    "text": "kind of thing so they will put in a lot of effort and a lot of energy and love into what they do",
    "start": "3456920",
    "end": "3462710"
  },
  {
    "text": "so apart from all the technical you know niceties that we get from it there's also I think that human element that you",
    "start": "3462710",
    "end": "3469700"
  },
  {
    "text": "get from it as well and look our team was very passionate these are some of the public projects and that they've",
    "start": "3469700",
    "end": "3474980"
  },
  {
    "text": "created like serverless daugher before some local came out so yeah and some",
    "start": "3474980",
    "end": "3480770"
  },
  {
    "text": "other projects as well like the service plugin for pushing cloud watch started to sumo logic so you get passionate",
    "start": "3480770",
    "end": "3487670"
  },
  {
    "text": "people so my final message is this right service is about people and it's about a",
    "start": "3487670",
    "end": "3494180"
  },
  {
    "text": "mindset change it's about a mindset change towards automation towards",
    "start": "3494180",
    "end": "3499520"
  },
  {
    "text": "agility towards automation as someone said developers developers developers",
    "start": "3499520",
    "end": "3504770"
  },
  {
    "text": "developers thank you so much yes thank you [Applause]",
    "start": "3504770",
    "end": "3514580"
  },
  {
    "text": "right Thank You Vera you we expect you to continue to lead the community charge",
    "start": "3514580",
    "end": "3519830"
  },
  {
    "text": "for us so thank you so with that like just to kind of recap quickly that the whole idea is",
    "start": "3519830",
    "end": "3525050"
  },
  {
    "text": "everything DC as best practices needs to be embodied as automation inside your",
    "start": "3525050",
    "end": "3530270"
  },
  {
    "text": "operations all those best practices or deviances from them can be detected through monitoring and ultimately the",
    "start": "3530270",
    "end": "3537380"
  },
  {
    "text": "the model for adopting them is going to be driven by sort of this agility or innovation mindset you have to be ok",
    "start": "3537380",
    "end": "3542900"
  },
  {
    "text": "taking these one at a time you're not going to get it right on the first shot but it's ok it allows you to move pretty",
    "start": "3542900",
    "end": "3548000"
  },
  {
    "text": "quickly in a much more safe fashion all right so what did we talk about today so we said wow I did not animate the way I",
    "start": "3548000",
    "end": "3554840"
  },
  {
    "text": "wanted to but anyway here it is B so we talked about the lean function concise",
    "start": "3554840",
    "end": "3560780"
  },
  {
    "text": "code sorry concise logic efficient code think about your ephemeral environment we",
    "start": "3560780",
    "end": "3566180"
  },
  {
    "text": "talked about the eventful in vacations kata succinct payloads resilient",
    "start": "3566180",
    "end": "3572420"
  },
  {
    "text": "gateways and concurrent executions to keep in mind make sure that you have calls to your downstream services are",
    "start": "3572420",
    "end": "3578630"
  },
  {
    "text": "decoupled in some form of fashion scale match to make sure they are accommodating the downstream services",
    "start": "3578630",
    "end": "3583940"
  },
  {
    "text": "themselves and secured appropriately and finally make sure that your operations are set up in a way to absorb all these",
    "start": "3583940",
    "end": "3590810"
  },
  {
    "text": "practices together so congratulations all of you you now have a black belt in surveillance applications so there are a",
    "start": "3590810",
    "end": "3603140"
  },
  {
    "text": "lot of topics we mentioned but indeed dive into there are a lot more existing talks about monitoring and operations in",
    "start": "3603140",
    "end": "3608690"
  },
  {
    "text": "a service world migrations working with database etcetera highly encouraged to dive deep into it",
    "start": "3608690",
    "end": "3614390"
  },
  {
    "text": "they go much deeper into some of the topics we touched upon over here in periphery thank you so much and we will",
    "start": "3614390",
    "end": "3619730"
  },
  {
    "text": "hang out more for questions on stream thank you",
    "start": "3619730",
    "end": "3623440"
  }
]
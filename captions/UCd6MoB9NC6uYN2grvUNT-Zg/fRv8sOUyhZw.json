[
  {
    "text": "Hello and welcome to\nThis is My Architecture.",
    "start": "7605",
    "end": "9747"
  },
  {
    "text": "I am Walid, \nand today, I am with",
    "start": "9787",
    "end": "11737"
  },
  {
    "text": "Jean-Baptiste, from Euler Hermes \nand Lucien, from Ippon.",
    "start": "11777",
    "end": "15530"
  },
  {
    "text": "Jean-Baptiste, tell us about Euler Hermes\nand your role in Euler Hermes.",
    "start": "15805",
    "end": "20096"
  },
  {
    "text": "So, Euler Hermes is a company\nspecialised in credit insurance.",
    "start": "20136",
    "end": "23136"
  },
  {
    "text": "We are the world leader.",
    "start": "23176",
    "end": "24278"
  },
  {
    "text": "Credit insurance is an insurance protecting \nB2B companies against unpaid invoices.",
    "start": "24318",
    "end": "27241"
  },
  {
    "text": "In our industry,\nit means datas on companies,",
    "start": "27281",
    "end": "32298"
  },
  {
    "text": "and in today's use case,\nwe have a lot of data",
    "start": "32338",
    "end": "35438"
  },
  {
    "text": "on companies.",
    "start": "35478",
    "end": "36915"
  },
  {
    "text": "Alright, tell us about your\nbusiness need",
    "start": "36955",
    "end": "39812"
  },
  {
    "text": "and why this solution?",
    "start": "39852",
    "end": "41430"
  },
  {
    "text": "I am in charge at Euler Hermes",
    "start": "41470",
    "end": "43741"
  },
  {
    "text": "of the monolithic transformation\nusing these company data",
    "start": "43781",
    "end": "46885"
  },
  {
    "text": "to solve insurance-related problems.",
    "start": "46925",
    "end": "49965"
  },
  {
    "text": "And our goal is to move\nthis existing monolith,",
    "start": "50005",
    "end": "55106"
  },
  {
    "text": "and break it into microservices,\nand then move it to AWS.",
    "start": "55146",
    "end": "58427"
  },
  {
    "text": "So now, you collaborate with Ippon,\nwhich is an AWS partner, with Lucien.",
    "start": "58467",
    "end": "62648"
  },
  {
    "text": "- Hello Lucien.\n- Hello.",
    "start": "62688",
    "end": "64043"
  },
  {
    "text": "Tell us about your role at Ippon,",
    "start": "64083",
    "end": "65798"
  },
  {
    "text": "and tell us also about the technical solution",
    "start": "65838",
    "end": "68321"
  },
  {
    "text": "suggested by Euler Hermes.\n- Thank you Walid.",
    "start": "68361",
    "end": "70051"
  },
  {
    "text": "So, I am a Cloud Date Engineer \nat Ippon Technologies,",
    "start": "70091",
    "end": "72875"
  },
  {
    "text": "and I have been working with Euler Hermes\nfor almost a year now",
    "start": "72915",
    "end": "75764"
  },
  {
    "text": "on all the data aspects linked to\nthis monolith to microservice",
    "start": "75804",
    "end": "78577"
  },
  {
    "text": "transformational project.\n- Great.",
    "start": "78617",
    "end": "81255"
  },
  {
    "text": "The idea is simple, we go from a monolith",
    "start": "81295",
    "end": "83630"
  },
  {
    "text": "to a microservices solution,\nand we try to make the most of",
    "start": "83670",
    "end": "86666"
  },
  {
    "text": "the agility of AWS,\nthe scalability of AWS in that regard.",
    "start": "86706",
    "end": "90135"
  },
  {
    "text": "Let's hear Lucien about",
    "start": "90492",
    "end": "91625"
  },
  {
    "text": "this process at Euler Hermes.",
    "start": "91665",
    "end": "93546"
  },
  {
    "text": "During the transformational process,",
    "start": "93914",
    "end": "95487"
  },
  {
    "text": "our microservices are developped on AWS,",
    "start": "95527",
    "end": "98582"
  },
  {
    "text": "but are based on data from Legacy",
    "start": "98623",
    "end": "100829"
  },
  {
    "text": "that already exist in an IBM DB2 database.",
    "start": "100869",
    "end": "103765"
  },
  {
    "text": "And in fact, my role during this mission is to",
    "start": "103805",
    "end": "106131"
  },
  {
    "text": "move the existing data from the old system",
    "start": "106171",
    "end": "108890"
  },
  {
    "text": "to the new system,",
    "start": "108930",
    "end": "110274"
  },
  {
    "text": "which are Dynamo DB \nfor our reference database",
    "start": "110314",
    "end": "112432"
  },
  {
    "text": "and Elasticsearch for our search engines,",
    "start": "112472",
    "end": "114715"
  },
  {
    "text": "and to assure a synchronisation \nbetween the transformations",
    "start": "115073",
    "end": "118890"
  },
  {
    "text": "that would appear on the Legacy database\nto the the new system databases.",
    "start": "118930",
    "end": "124166"
  },
  {
    "text": "So we start with the database",
    "start": "124206",
    "end": "126987"
  },
  {
    "text": "construction phase.",
    "start": "127027",
    "end": "128335"
  },
  {
    "text": "So, it means in order to migrate our data",
    "start": "128375",
    "end": "130574"
  },
  {
    "text": "on Dynamo and Elasticsearch,\nit's crucial to",
    "start": "130614",
    "end": "133625"
  },
  {
    "text": "recover data from S3.",
    "start": "133666",
    "end": "135519"
  },
  {
    "text": "In order to do that,\nwe used the AWS DMS,",
    "start": "135559",
    "end": "139186"
  },
  {
    "text": "that helps — with a few filters",
    "start": "139226",
    "end": "141347"
  },
  {
    "text": "and management policies — \nto create a copy of the original",
    "start": "141387",
    "end": "145667"
  },
  {
    "text": "DB2 database to a S3 bucket,",
    "start": "145707",
    "end": "149806"
  },
  {
    "text": "like this.",
    "start": "150610",
    "end": "151714"
  },
  {
    "text": "First step is to recover the data batches",
    "start": "156421",
    "end": "159030"
  },
  {
    "text": "directly from the monolith, \nfrom the IBM DB2 database.",
    "start": "159071",
    "end": "162770"
  },
  {
    "text": "We use the AWS DMS,\nDatabase Migration Services",
    "start": "162810",
    "end": "166428"
  },
  {
    "text": "to migrate the data on S3.",
    "start": "166468",
    "end": "168322"
  },
  {
    "text": "- Exactly.\n- Now the data are stored on S3.",
    "start": "168362",
    "end": "170008"
  },
  {
    "text": "What is the next step?",
    "start": "170048",
    "end": "171113"
  },
  {
    "text": "The next step is to load this\nmassive amount of data",
    "start": "171153",
    "end": "174499"
  },
  {
    "text": "to our reference databases.",
    "start": "174539",
    "end": "177484"
  },
  {
    "text": "In order to do that, we chose Amazon EMR,\nElastic MapReduce,",
    "start": "177524",
    "end": "181914"
  },
  {
    "text": "which is a Hadoop cluster,",
    "start": "181954",
    "end": "183655"
  },
  {
    "text": "that allows us to  scale our cluster",
    "start": "183696",
    "end": "186205"
  },
  {
    "text": "based on the amount of data",
    "start": "186245",
    "end": "187222"
  },
  {
    "text": "and based on the computers power",
    "start": "187262",
    "end": "188827"
  },
  {
    "text": "to help with our needs \nin terms of performance.",
    "start": "188868",
    "end": "192188"
  },
  {
    "text": "The interesting thing about this EMR,",
    "start": "192229",
    "end": "194382"
  },
  {
    "text": "is that we use it temporarily.",
    "start": "194422",
    "end": "196974"
  },
  {
    "text": "So, we execute it only for this phase.",
    "start": "197014",
    "end": "200041"
  },
  {
    "text": "Once the data migration is completed,",
    "start": "200081",
    "end": "203786"
  },
  {
    "text": "this EMR cluster stops,\nand can therefore really adapt to",
    "start": "203827",
    "end": "206806"
  },
  {
    "text": "our needs.",
    "start": "206846",
    "end": "207987"
  },
  {
    "text": "And behind this EMR cluster,",
    "start": "208476",
    "end": "212261"
  },
  {
    "text": "we have a Spark job which can",
    "start": "212302",
    "end": "214754"
  },
  {
    "text": "write a regular ETL job ,\nso it retrieves data from S3,",
    "start": "214794",
    "end": "220710"
  },
  {
    "text": "(so it's an extraction),\nthat transforms them;",
    "start": "221419",
    "end": "224757"
  },
  {
    "text": "so with the transformations,\nwe have cleanups,",
    "start": "224797",
    "end": "227250"
  },
  {
    "text": "we have data validation mechanisms,",
    "start": "227291",
    "end": "229374"
  },
  {
    "text": "we also have data quality tests;",
    "start": "229723",
    "end": "232407"
  },
  {
    "text": "and behind this, we store\nthese prepared and refined data",
    "start": "232779",
    "end": "236092"
  },
  {
    "text": "in our two systems, which are",
    "start": "236132",
    "end": "238497"
  },
  {
    "text": "Dynamo DB and Elasticsearch.",
    "start": "238538",
    "end": "242846"
  },
  {
    "text": "Great.",
    "start": "242887",
    "end": "243931"
  },
  {
    "text": "Once the data are processed on S3,",
    "start": "243972",
    "end": "245907"
  },
  {
    "text": "we use transient clusters,",
    "start": "245947",
    "end": "247387"
  },
  {
    "text": "it means they shut down",
    "start": "247427",
    "end": "248903"
  },
  {
    "text": "once they are done.",
    "start": "248943",
    "end": "250618"
  },
  {
    "text": "We use Spark to do ETL.",
    "start": "250659",
    "end": "252569"
  },
  {
    "text": "We recover data from S3",
    "start": "252609",
    "end": "254071"
  },
  {
    "text": "and we write them both\nafter transformation",
    "start": "254112",
    "end": "256640"
  },
  {
    "text": "on Dynamo DB and Elasticsearch.\n- Exactly.",
    "start": "256680",
    "end": "259600"
  },
  {
    "text": "Now, we have retrieved the data,\nthe batch, so to say.",
    "start": "259640",
    "end": "262663"
  },
  {
    "text": "Now, what about the data\nthat change the source database?",
    "start": "262807",
    "end": "266330"
  },
  {
    "text": "You are right.",
    "start": "266370",
    "end": "267662"
  },
  {
    "text": "We need to be able to pass on the changes",
    "start": "267702",
    "end": "271466"
  },
  {
    "text": "that arrive on the source system--\nfrom the source system",
    "start": "271506",
    "end": "275645"
  },
  {
    "text": "to our reference systems\nof our project on AWS.",
    "start": "275685",
    "end": "279794"
  },
  {
    "text": "In order to do that,\nwe create events",
    "start": "279834",
    "end": "282784"
  },
  {
    "text": "based on the commit log",
    "start": "282824",
    "end": "286397"
  },
  {
    "text": "and the IBM DB2 changes,\nwhich are used once again",
    "start": "286437",
    "end": "289855"
  },
  {
    "text": "by the DMS to create,\nand move an event",
    "start": "289895",
    "end": "294625"
  },
  {
    "text": "to Kinesis stream common to \nthe entirety of Euler Hermès.",
    "start": "294666",
    "end": "297686"
  },
  {
    "text": "So, like this.",
    "start": "299609",
    "end": "300772"
  },
  {
    "text": "For this, we developed Lambdas",
    "start": "301945",
    "end": "305857"
  },
  {
    "text": "that subscribe to a Kinesis stream",
    "start": "305897",
    "end": "308726"
  },
  {
    "text": "and consume the data updates to modify",
    "start": "308766",
    "end": "313030"
  },
  {
    "text": "on Dynamo DB firstly,\nand secondly, on Elasticsearch.",
    "start": "313433",
    "end": "319028"
  },
  {
    "text": "To modify the data\nin Elasticsearch,",
    "start": "319069",
    "end": "320858"
  },
  {
    "text": "we use the function\nDynamo Streams from Dynamo DB,",
    "start": "320898",
    "end": "324414"
  },
  {
    "text": "which is basically a small Kinesis associated",
    "start": "324634",
    "end": "328493"
  },
  {
    "text": "with a Dynamo DB table, \nthat allows us, with a Lambda,",
    "start": "328533",
    "end": "332117"
  },
  {
    "text": "to react to modification on this table",
    "start": "332157",
    "end": "335704"
  },
  {
    "text": "and to apply these modifications\nin Elasticsearch.",
    "start": "335744",
    "end": "338419"
  },
  {
    "text": "For the Lambdas,\nit runs with Node",
    "start": "340438",
    "end": "343009"
  },
  {
    "text": "which allows us to read, \ntransform the messages,",
    "start": "343050",
    "end": "347330"
  },
  {
    "text": "apply the same validation \nand cleansing mechanisms",
    "start": "347870",
    "end": "350788"
  },
  {
    "text": "we have at the initial loading level",
    "start": "350828",
    "end": "353865"
  },
  {
    "text": "to assure that the data,\nmay they arrive via the initial batch",
    "start": "353905",
    "end": "358376"
  },
  {
    "text": "or via real time synchronization,\nhave the same format",
    "start": "358416",
    "end": "360943"
  },
  {
    "text": "and the same quality.",
    "start": "360983",
    "end": "361844"
  },
  {
    "text": "Great. So, this branch\nis for real time.",
    "start": "361884",
    "end": "364084"
  },
  {
    "text": "So we retrieve the change logs \nfrom IBM DB2.",
    "start": "364124",
    "end": "366725"
  },
  {
    "text": "We retrieved them on Kinesis",
    "start": "366766",
    "end": "368879"
  },
  {
    "text": "and apply the same modifications\nthat we applied",
    "start": "368919",
    "end": "370953"
  },
  {
    "text": "on the batch branch to write them\nat the end on Elasticsearch.",
    "start": "370993",
    "end": "373806"
  },
  {
    "text": "Exactly. And this guarantees",
    "start": "373846",
    "end": "375778"
  },
  {
    "text": "a synchronization mechanism \nalmost in real time,",
    "start": "375818",
    "end": "379910"
  },
  {
    "text": "which allows the systems to be updated",
    "start": "379951",
    "end": "382186"
  },
  {
    "text": "and if the job runs an operation \non the Legacy system",
    "start": "382227",
    "end": "385921"
  },
  {
    "text": "or on the new system,\nwe have the same result",
    "start": "385961",
    "end": "388031"
  },
  {
    "text": "and we don't experience a desynchronization\nor a difference between the two systems.",
    "start": "388071",
    "end": "391761"
  },
  {
    "text": "Thank you Lucien. Jean-Baptiste,\nwhat is the final result?",
    "start": "391801",
    "end": "394548"
  },
  {
    "text": "And how can users use Elasticsearch then?",
    "start": "394588",
    "end": "397451"
  },
  {
    "text": "The final result is a Dynamo DB database",
    "start": "397867",
    "end": "400517"
  },
  {
    "text": "and an Elasticsearch database\nat a monolithic phase.",
    "start": "400557",
    "end": "403006"
  },
  {
    "text": "It took us five months \nof development to get there",
    "start": "403046",
    "end": "406151"
  },
  {
    "text": "and today, we are developping an API",
    "start": "406191",
    "end": "408007"
  },
  {
    "text": "that users and clients can use",
    "start": "408047",
    "end": "410504"
  },
  {
    "text": "or fronts that our users and clients can use",
    "start": "410544",
    "end": "413374"
  },
  {
    "text": "to find any data in our database",
    "start": "413414",
    "end": "415703"
  },
  {
    "text": "on all the companies of the world.",
    "start": "415743",
    "end": "417029"
  },
  {
    "text": "What benefits have you noticed?",
    "start": "417069",
    "end": "419270"
  },
  {
    "text": "The response time that took a few seconds",
    "start": "419544",
    "end": "423161"
  },
  {
    "text": "on the monolith now only takes\nhundreds of milliseconds.",
    "start": "423201",
    "end": "426354"
  },
  {
    "text": "Huge.",
    "start": "426395",
    "end": "427495"
  },
  {
    "text": "Thank you Jean-Baptiste,\nthank you Lucien",
    "start": "427536",
    "end": "429352"
  },
  {
    "text": "and thank you for watching\nThis is My Architecture.",
    "start": "429392",
    "end": "431928"
  }
]
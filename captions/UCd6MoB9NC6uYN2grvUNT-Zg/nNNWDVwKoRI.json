[
  {
    "start": "0",
    "end": "100000"
  },
  {
    "text": "good afternoon ladies and gentlemen is everybody in can you hear me at the",
    "start": "4240",
    "end": "10240"
  },
  {
    "text": "back give me away if you can hear me at the back good thanks guys okay so um good afternoon uh thank you",
    "start": "10240",
    "end": "16800"
  },
  {
    "text": "so much for joining us it's great to see our full house here my name is matt woods i'm the chief data scientist here at amazon web services",
    "start": "16800",
    "end": "22880"
  },
  {
    "text": "i basically get means that i get to talk to smart people such as yourselves about how to use cloud computing to",
    "start": "22880",
    "end": "28640"
  },
  {
    "text": "drive your data intensive workloads in this session we're going to be talking about dynamodb",
    "start": "28640",
    "end": "34480"
  },
  {
    "text": "and specifically how you can build your applications to take advantage of some of dynamodb's",
    "start": "34480",
    "end": "40719"
  },
  {
    "text": "core features so um let's take a quick look at what those core features are um if",
    "start": "40719",
    "end": "46320"
  },
  {
    "text": "you're not familiar uh with amazon dynamodb i'll give a really really quick introduction and then we'll dive into some more uh",
    "start": "46320",
    "end": "52399"
  },
  {
    "text": "data modeling uh advice and then some information about how you can",
    "start": "52399",
    "end": "57600"
  },
  {
    "text": "architect your application to take the full advantage of amazon dynamodb's provision throughput model",
    "start": "57600",
    "end": "64320"
  },
  {
    "text": "so the key thing to understand with dynamodb is that it's super super easy to get up",
    "start": "64320",
    "end": "70560"
  },
  {
    "text": "and running with the whole api actually fits on just one slide i think there's 13 or 14 different calls that you can",
    "start": "70560",
    "end": "76479"
  },
  {
    "text": "make standard db it's very very simple very very straightforward you get started basically by just by making two decisions making",
    "start": "76479",
    "end": "82720"
  },
  {
    "text": "three clicks in the console and then you're ready for use at pretty much any level uh whether that's production or development",
    "start": "82720",
    "end": "88720"
  },
  {
    "text": "so those two uh decisions that you have to make up front are really the level of throughput that you need to use with",
    "start": "88720",
    "end": "94000"
  },
  {
    "text": "dynamodb and the primary keys that your data set is going to use to represent your data going forwards",
    "start": "94000",
    "end": "100400"
  },
  {
    "start": "100000",
    "end": "320000"
  },
  {
    "text": "so we're going to talk a little bit about provision throughput we're going to talk a little bit about data patterns",
    "start": "100400",
    "end": "106079"
  },
  {
    "text": "and those really talk to these two decisions that you need to make up front then we're very lucky we're going to be",
    "start": "106079",
    "end": "111680"
  },
  {
    "text": "joined by some folks by the new york times and they're going to run you through some of their architecture about how they're using",
    "start": "111680",
    "end": "117119"
  },
  {
    "text": "dynamodb in some depth and then hopefully we'll have some time some time for some questions",
    "start": "117119",
    "end": "123040"
  },
  {
    "text": "so if you're not familiar with dynamodb dynamodb is a managed nosql database",
    "start": "123040",
    "end": "128239"
  },
  {
    "text": "service it's designed to store effectively any amount of traffic and serve any level of request and it's",
    "start": "128239",
    "end": "135200"
  },
  {
    "text": "done designed to be used in a way where you don't have to administer the service under the hood",
    "start": "135200",
    "end": "140720"
  },
  {
    "text": "so with dynamodb you don't have to go out and provision instances and worry about storage or anything like that you just have to",
    "start": "140720",
    "end": "146800"
  },
  {
    "text": "worry about those two decisions that we mentioned up front and dynamodb will use the decisions that you make in order to be able to supply the amount",
    "start": "146800",
    "end": "153519"
  },
  {
    "text": "of performance then the amount of storage that your application is going to need going forwards so it allows you to operate no sql",
    "start": "153519",
    "end": "160000"
  },
  {
    "text": "databases these key value stores which are very scalable and can operate at very very low latencies without the operational",
    "start": "160000",
    "end": "166560"
  },
  {
    "text": "burden of having to manage instances having to worry about storage under the hood a replication and all the rest of it a",
    "start": "166560",
    "end": "172480"
  },
  {
    "text": "very robust system so the key uh differentiator and the key",
    "start": "172480",
    "end": "177680"
  },
  {
    "text": "thing that dynamodb delivers is that it offers consistent predictable performance at any scale so you can",
    "start": "177680",
    "end": "184319"
  },
  {
    "text": "expect single digit millisecond latencies and we do that by backing dynamodb all of your data",
    "start": "184319",
    "end": "190080"
  },
  {
    "text": "onto ssds on the back end now again you have to manage those ssds you just have to put your data in but",
    "start": "190080",
    "end": "195200"
  },
  {
    "text": "underneath everything's running on an ssd it has a very flexible nosql data model so we're here talking about primary key",
    "start": "195200",
    "end": "202159"
  },
  {
    "text": "attribute pairs so you don't need to design your schema up front you just need to make the decision on the primary key",
    "start": "202159",
    "end": "207920"
  },
  {
    "text": "by which you'll access your data going forwards now this makes it very very easy with other as with other nosql",
    "start": "207920",
    "end": "213200"
  },
  {
    "text": "systems to uh create new databases but just as importantly if you're developing a new application",
    "start": "213200",
    "end": "218799"
  },
  {
    "text": "uh which is in flux it makes it very very easy to evolve your data format and evolve your schema over time",
    "start": "218799",
    "end": "224239"
  },
  {
    "text": "because you basically don't have to worry about it dynamodb is effectively an enormous distributed hash",
    "start": "224239",
    "end": "229599"
  },
  {
    "text": "uh your associative array depending on what your personal preference of naming is",
    "start": "229599",
    "end": "235120"
  },
  {
    "text": "so it has this schema scalability seamless scalability built into it there are no table size limits built into",
    "start": "235120",
    "end": "241120"
  },
  {
    "text": "dynamodb and as i say it has unlimited storage and it's designed to operate without downtime",
    "start": "241120",
    "end": "246560"
  },
  {
    "text": "it's very very durable so you get consistent disk only writes with dynamodb this data in dynamodb",
    "start": "246560",
    "end": "253680"
  },
  {
    "text": "doesn't just go into memory it only gets acknowledged and the request is acknowledged once that data is physically written to one of those",
    "start": "253680",
    "end": "259519"
  },
  {
    "text": "ssds and we actually only acknowledge it once the data was written across multiple ssds",
    "start": "259519",
    "end": "264800"
  },
  {
    "text": "in multiple data centers and then we asynchronously replicate that data out across availability zones so this",
    "start": "264800",
    "end": "270160"
  },
  {
    "text": "isn't just an in-memory thing that we then have to figure out consistency between memory and disk everything goes onto that disk nice and",
    "start": "270160",
    "end": "275919"
  },
  {
    "text": "quickly so again all of this the consistent predictable performance the unlimited scale",
    "start": "275919",
    "end": "281440"
  },
  {
    "text": "or operating without the operational burden of having to provision instances worry about the scale and all the rest of it",
    "start": "281440",
    "end": "286720"
  },
  {
    "text": "just those two key uh choices to make up front so this allows you to basically focus back on your application without having",
    "start": "286720",
    "end": "293199"
  },
  {
    "text": "to take the time to figure out how to install and deploy and manage an operational production system",
    "start": "293199",
    "end": "299440"
  },
  {
    "text": "for nosql which can be challenging and typically isn't the core competency of our customers our customers want to be able to focus",
    "start": "299440",
    "end": "305680"
  },
  {
    "text": "on their application deliver the sort of sophisticated tools of their own either internal or external customers",
    "start": "305680",
    "end": "311039"
  },
  {
    "text": "need and this dynamodb is a perfect example of where you get much more of your time back to focus on that application so back to",
    "start": "311039",
    "end": "318720"
  },
  {
    "text": "those two decisions um let's talk a little bit about provision throughput so i talked",
    "start": "318720",
    "end": "323840"
  },
  {
    "start": "320000",
    "end": "625000"
  },
  {
    "text": "about this being one of those two decisions that you had to make so dynamodb operates with a provision",
    "start": "323840",
    "end": "329199"
  },
  {
    "text": "throughput model this allows you to reserve the amount of i o performance you're going to need ahead of schedule and you get that",
    "start": "329199",
    "end": "336639"
  },
  {
    "text": "amount of i o are allocated to you as and when you need it so this is a",
    "start": "336639",
    "end": "341680"
  },
  {
    "text": "slight change from the elastic model here you're going to reserve the capacity that you need in terms of i o",
    "start": "341680",
    "end": "346880"
  },
  {
    "text": "and dynamodb will scale out under the hood in order to be able to deliver that i o to you irrespective of the scale of",
    "start": "346880",
    "end": "352479"
  },
  {
    "text": "the data so you can scale up any time that you want to by adding additional provisioned iops you can scale back down at any time by",
    "start": "352479",
    "end": "359600"
  },
  {
    "text": "reducing the amount of iops and it's this model that became popular with dynamodb which has been replicated",
    "start": "359600",
    "end": "364639"
  },
  {
    "text": "in the elastic block store for example where you can also provision the throughput between your instance",
    "start": "364639",
    "end": "370639"
  },
  {
    "text": "and to your elastic box store as well so it originated here in dynamodb customers liked it so much that we moved",
    "start": "370639",
    "end": "375759"
  },
  {
    "text": "it over to elastic block store as well so how do you pay for this are you pay",
    "start": "375759",
    "end": "380800"
  },
  {
    "text": "per capacity unit uh we price per hour of provisioned unit uh provision throughput sorry",
    "start": "380800",
    "end": "386479"
  },
  {
    "text": "so this means that uh it it can be um challenging to understand the payment",
    "start": "386479",
    "end": "391919"
  },
  {
    "text": "model dynamodb but we've got some excellent tools to help you optimize it and move forward with it so",
    "start": "391919",
    "end": "397360"
  },
  {
    "text": "i wanted to just break it down so you understood what you were going to be paying for as you go forward so the first thing you",
    "start": "397360",
    "end": "402800"
  },
  {
    "text": "you work through is the right throughput of your application so you can reserve right iops independently of rediops",
    "start": "402800",
    "end": "408880"
  },
  {
    "text": "and the way that we charge this charge for this is we multiply the size of the item that you're going to save",
    "start": "408880",
    "end": "414560"
  },
  {
    "text": "in k by the writes per second that you're going to make against the provision throughput",
    "start": "414560",
    "end": "419680"
  },
  {
    "text": "so we charge a penny for 10 right units so that's one cent for our 10 items",
    "start": "419680",
    "end": "426000"
  },
  {
    "text": "written at one once per second basically those items are 1k in size consistent",
    "start": "426000",
    "end": "431199"
  },
  {
    "text": "rights are made with dynamodb so there's atomic increment and decrement on individual fields and",
    "start": "431199",
    "end": "436319"
  },
  {
    "text": "individual key attribute pairs that means if you're implementing a counter for example",
    "start": "436319",
    "end": "441919"
  },
  {
    "text": "and you're throwing a lot of a lot of queries at that counter the traditional relational model would",
    "start": "441919",
    "end": "448080"
  },
  {
    "text": "have you read from the counter add one to it and then read it back again of course that doesn't work if you",
    "start": "448080",
    "end": "453280"
  },
  {
    "text": "got 10 million connections because you all read 10 million times the same number add one to the same number and then write the same number back",
    "start": "453280",
    "end": "459120"
  },
  {
    "text": "plus one 10 million times doesn't happen with dynamodb because of this atomic increment and decrement so you can have those 10 million rights",
    "start": "459120",
    "end": "466240"
  },
  {
    "text": "and reads happening concurrently and dynamodb will handle it so you actually your final counter gets to 10 million rather than just one",
    "start": "466240",
    "end": "474000"
  },
  {
    "text": "so you have optimistic concurrency control what does that mean it means you can do conditional writes so you can tell",
    "start": "474000",
    "end": "480319"
  },
  {
    "text": "dynamodb only make this change to the data store if the value in the uh in the the",
    "start": "480319",
    "end": "486560"
  },
  {
    "text": "existing value is fits within a certain range or or fits some sort of conditional statement so consistent rights that's",
    "start": "486560",
    "end": "492160"
  },
  {
    "text": "how we implement atomic increment and decrement we can also use that optimistic concurrency control in your in your own",
    "start": "492160",
    "end": "497919"
  },
  {
    "text": "conditional statements we also have transactions so",
    "start": "497919",
    "end": "504479"
  },
  {
    "text": "inside dynamodb puts updates and deletes are acid compliant and we have item level uh transactions",
    "start": "504479",
    "end": "510400"
  },
  {
    "text": "only so you need to you know obviously take that on board that transactions aren't going to exist across multiple items within a within a",
    "start": "510400",
    "end": "516800"
  },
  {
    "text": "query we have transactions only at the item level and you can think of that again in the terms of this large distributed hash",
    "start": "516800",
    "end": "523120"
  },
  {
    "text": "that we have in place so uh for that's right handling reads",
    "start": "523120",
    "end": "528240"
  },
  {
    "text": "is as a little extra twist of complexity because we allow strong or eventual",
    "start": "528240",
    "end": "533440"
  },
  {
    "text": "consistency of the right of the reads that you're going to make so if you're not familiar with this strong consistency basically means that",
    "start": "533440",
    "end": "539600"
  },
  {
    "text": "if you write a value into your data store and you immediately read it back again it's guaranteed to be the same value",
    "start": "539600",
    "end": "545120"
  },
  {
    "text": "that you just wrote eventual consistency means that it will eventually be the same value that you wrote it's very common pattern",
    "start": "545120",
    "end": "550880"
  },
  {
    "text": "in distributed systems so three read throughput uh uh basically allows you to decide whether you want to take advantage of",
    "start": "550880",
    "end": "557279"
  },
  {
    "text": "eventual consistency eventual consistency is much cheaper to implement and it has uh than strong consistency so",
    "start": "557279",
    "end": "564320"
  },
  {
    "text": "we give you the option of which one you want to do and you'll pay slightly differently for which one you want to make so in",
    "start": "564320",
    "end": "569839"
  },
  {
    "text": "terms of strong consistency uh the provisioned units that you can provision are the size of the item again in k",
    "start": "569839",
    "end": "576080"
  },
  {
    "text": "multiplied by the reads per second so similar to writes and with this case we charge a penny for",
    "start": "576080",
    "end": "581120"
  },
  {
    "text": "50 units so again 50 writes per second oh sorry 50 reads per second of 1k items up to 1k items for eventual",
    "start": "581120",
    "end": "588640"
  },
  {
    "text": "consistency you get twice the bang for your buck basically uh so it's a penny an hour for 100 units of eventual read",
    "start": "588640",
    "end": "595920"
  },
  {
    "text": "consistency and you can make you can basically make a late binding decision on when you want to implement that so you only decide whether you want to",
    "start": "595920",
    "end": "602160"
  },
  {
    "text": "make strong or eventually consistent reads when you actually call make the read call on dynamodb",
    "start": "602160",
    "end": "608000"
  },
  {
    "text": "so you should expect the same latency expectations whether you're making strong or eventually consistent calls and you",
    "start": "608000",
    "end": "614560"
  },
  {
    "text": "can mix and match these at read time effectively you don't have to use just one or just the other you can late bind to the to the the",
    "start": "614560",
    "end": "621200"
  },
  {
    "text": "throughput and the read stage that you want so the provision throughput under the hood is managed entirely by dynamodb",
    "start": "621200",
    "end": "627920"
  },
  {
    "start": "625000",
    "end": "810000"
  },
  {
    "text": "dynamodb will provide the infrastructure required to meet your level of provision throughput whether that's",
    "start": "627920",
    "end": "634160"
  },
  {
    "text": "10 iops or 10 000 and the partitioning of that data under the hood is also managed by",
    "start": "634160",
    "end": "640640"
  },
  {
    "text": "dynamodb so remember i said this is a large distributed hash all of that distribution under the hood",
    "start": "640640",
    "end": "646160"
  },
  {
    "text": "is managed by dynamodb so what that means is that achieving the",
    "start": "646160",
    "end": "651839"
  },
  {
    "text": "full provision throughput that you have requested requires what we call a uniform workload",
    "start": "651839",
    "end": "657839"
  },
  {
    "text": "so dynamodb is designed to operate with a uniform workload and i'll describe what i mean with about that in a minute",
    "start": "657839",
    "end": "665040"
  },
  {
    "text": "um but to achieve the full provisioning that you've got it's really important to architect your app",
    "start": "665040",
    "end": "670560"
  },
  {
    "text": "your application and understand what that uniform workload is so ta-da the uniform workload so under the",
    "start": "670560",
    "end": "677279"
  },
  {
    "text": "hood what dynamodb is doing is it's dividing its data uh within a single table into",
    "start": "677279",
    "end": "682880"
  },
  {
    "text": "multiple partitions and those partitions can be on separate servers and that partitioning is done primarily",
    "start": "682880",
    "end": "689200"
  },
  {
    "text": "using the primary key that you're going to select on your data and then provision throughput critically",
    "start": "689200",
    "end": "694800"
  },
  {
    "text": "is distributed equally across all of the partitions under the hood so that means that if you have a you've",
    "start": "694800",
    "end": "701200"
  },
  {
    "text": "picked your primary keys correctly to achieve the maximum throughput that you've requested the throughput is going to be spread out",
    "start": "701200",
    "end": "707920"
  },
  {
    "text": "equally across all of your shards underneath the hood basically so it's very important to get that right",
    "start": "707920",
    "end": "714160"
  },
  {
    "text": "very important to understand the uniform workload very important to be able to implement it and i'll give you some",
    "start": "714160",
    "end": "719839"
  },
  {
    "text": "right way to do things and some wrong way to do things examples in a minute but basically you've got multiple your data sits across multiple shards",
    "start": "719839",
    "end": "726399"
  },
  {
    "text": "and your throughput if you've got 100 pieces of throughput and five shards then you'll get 20 ios per shard",
    "start": "726399",
    "end": "733040"
  },
  {
    "text": "however dynamite db does not reveal to you how many shards you have so you have to build for the uniform workload to achieve your full iops",
    "start": "733040",
    "end": "738880"
  },
  {
    "text": "if you don't then what can happen is even with very very high levels of provision throughput you can still",
    "start": "738880",
    "end": "744240"
  },
  {
    "text": "see less performance than you're expecting so as i'm sort of making the point here just to crystallize it uh to achieve and",
    "start": "744240",
    "end": "750800"
  },
  {
    "text": "maintain the full provision throughput for a table you need to spread the workload evenly across the primary keys for your",
    "start": "750800",
    "end": "756560"
  },
  {
    "text": "application so that's a critical piece as you're you're starting to scale up production workers on dynamodb",
    "start": "756560",
    "end": "762880"
  },
  {
    "text": "so with non-uniform workloads that is requests which are biased to one key or one set of keys some",
    "start": "762880",
    "end": "769839"
  },
  {
    "text": "requests might be throttled when they all go to the same shard and even at high levels of provision throughput",
    "start": "769839",
    "end": "775120"
  },
  {
    "text": "you're going to see that request throttling potentially so understanding this is really critical",
    "start": "775120",
    "end": "781519"
  },
  {
    "text": "to maximizing the performance you're going to get with dynamodb and ensuring that you receive that consistent uh provision performance that",
    "start": "781519",
    "end": "788320"
  },
  {
    "text": "you've asked for so if you do get throttled dynamodb will tell you if you get throttled so that's a good indicator of what's",
    "start": "788320",
    "end": "795200"
  },
  {
    "text": "going on under the hood so how do you model data for a uniform workflow i've said how important this is",
    "start": "795200",
    "end": "801200"
  },
  {
    "text": "and it all really hinges about which primary key you're going to choose so the second decision that you need to make basically",
    "start": "801200",
    "end": "807120"
  },
  {
    "text": "which brings us nicely on to discussing some data patterns so i'm going to just quickly discuss",
    "start": "807120",
    "end": "814800"
  },
  {
    "start": "810000",
    "end": "930000"
  },
  {
    "text": "how to model your data to take advantage of nosql patterns and also discuss a little bit about how",
    "start": "814800",
    "end": "820079"
  },
  {
    "text": "you can do that without reducing your potential throughput to dynamodb so",
    "start": "820079",
    "end": "826000"
  },
  {
    "text": "just to quickly introduce i've introduced some of these already i think but just to quickly reintroduce the dynamodb semantics so that we're all on",
    "start": "826000",
    "end": "831199"
  },
  {
    "text": "the same page this is a dynamodb collection of data you can see it's stored as key value",
    "start": "831199",
    "end": "837920"
  },
  {
    "text": "pairs and we call all of this together a table so it's a dynamodb table represents a collection",
    "start": "837920",
    "end": "844079"
  },
  {
    "text": "of keys and values we store individual items are called items so an individual",
    "start": "844079",
    "end": "850240"
  },
  {
    "text": "row in our table here is referred to as an item in dynamodb and individual key value pairs are",
    "start": "850240",
    "end": "855839"
  },
  {
    "text": "referred to as an attribute uh so if you see those in the documentation uh that's how we define them internally",
    "start": "855839",
    "end": "861199"
  },
  {
    "text": "and the items as i mentioned are indexed only by primary cue so you have to be very careful about you",
    "start": "861199",
    "end": "866720"
  },
  {
    "text": "select your primary key because that's going to be your only only method of querying the data",
    "start": "866720",
    "end": "872399"
  },
  {
    "text": "back again so we don't at the moment support secondary indices with dynamodb so it's a single hash keys is the sort",
    "start": "872399",
    "end": "879199"
  },
  {
    "text": "of traditional way of doing it one key one value but to make add a little bit of extra query flexibility we do support",
    "start": "879199",
    "end": "884959"
  },
  {
    "text": "composite primary keys as well so composite primary keys allow you to specify",
    "start": "884959",
    "end": "890079"
  },
  {
    "text": "a a primary hash key and then a secondary range key and so you get a slightly more flexibility because into",
    "start": "890079",
    "end": "895839"
  },
  {
    "text": "that range you can say well give me all of these values that are between or for this primary key",
    "start": "895839",
    "end": "900880"
  },
  {
    "text": "that are between 1 and 100 for example or if you've got an e-commerce system for example you could say give me for a",
    "start": "900880",
    "end": "907199"
  },
  {
    "text": "particular customer give me all of the orders for october those sort of range groups",
    "start": "907199",
    "end": "912480"
  },
  {
    "text": "so um the hash key in this case is the id for the for the customer i guess if these are",
    "start": "912480",
    "end": "917680"
  },
  {
    "text": "orders in a in an e-commerce database uh the range key could be the date that allows you to sort of order quiz that",
    "start": "917680",
    "end": "923920"
  },
  {
    "text": "i'm talking about and items are always retrieved by the primary key so you can use range queries for uh for",
    "start": "923920",
    "end": "931279"
  },
  {
    "start": "930000",
    "end": "1105000"
  },
  {
    "text": "you can use range keys for queries as i say all items for november",
    "start": "931279",
    "end": "936720"
  },
  {
    "text": "and relationships inside nosql data stores are not hard-coded but they can be modeled as if they're",
    "start": "936800",
    "end": "943040"
  },
  {
    "text": "hard-coded so there is some idea that i think that you somehow lose some benefits of the",
    "start": "943040",
    "end": "948320"
  },
  {
    "text": "relational model in a nosql data store or it can be difficult to see if you've already got a relational database how to translate",
    "start": "948320",
    "end": "954720"
  },
  {
    "text": "that over to a nosql data store it almost always can be done it's just sometimes there's a hoop or",
    "start": "954720",
    "end": "960480"
  },
  {
    "text": "two to jump through as you model those relationships out into nosql it's not always a great fit so i'm not",
    "start": "960480",
    "end": "965600"
  },
  {
    "text": "going to suggest that you just go out and immediately move your mysql data over into into a nosql format",
    "start": "965600",
    "end": "971759"
  },
  {
    "text": "but if you're looking for the sort of unlimited scale and provision throughput and very low latency queries",
    "start": "971759",
    "end": "977360"
  },
  {
    "text": "and your data fits this this sort of nosql model you can still include relationships within that model",
    "start": "977360",
    "end": "983680"
  },
  {
    "text": "so let's take an example of that so uh here i've got a players table and what i'm going to do is let's",
    "start": "983680",
    "end": "988880"
  },
  {
    "text": "imagine we've got a social game that has players high scores and games within inside it",
    "start": "988880",
    "end": "994720"
  },
  {
    "text": "inside this players table i've got myself and my colleagues uh werner and jeff barr we've got some location",
    "start": "994720",
    "end": "1001199"
  },
  {
    "text": "attributes and a date that we joined now we might also create a scores table so this is a table which",
    "start": "1001199",
    "end": "1008959"
  },
  {
    "text": "includes information about the games that we've played and the score that we achieved on those on those games so we've got",
    "start": "1008959",
    "end": "1014639"
  },
  {
    "text": "angry birds and tetris on here and in addition to that we might want to build out leaderboards inside that",
    "start": "1014639",
    "end": "1020480"
  },
  {
    "text": "inside that social game environment so we index those by a a primary hash key and a secondary",
    "start": "1020480",
    "end": "1026798"
  },
  {
    "text": "range key here so we've got composite keys on both the scores and the leaderboards the game and the score in the",
    "start": "1026799",
    "end": "1032319"
  },
  {
    "text": "leaderboards and the user id and the game inside the scores table now if you've ever worked in no skill",
    "start": "1032319",
    "end": "1038079"
  },
  {
    "text": "models you can probably see where i'm going with this um so if you want to retrieve scores by user uh you can do it with two queries",
    "start": "1038079",
    "end": "1043678"
  },
  {
    "text": "effectively you can look up the player from the players table the user id those are going to be unique across your game environment probably",
    "start": "1043679",
    "end": "1050320"
  },
  {
    "text": "and then you can drop down and make a ranged query on the scores table so here i could say",
    "start": "1050320",
    "end": "1055520"
  },
  {
    "text": "forgive me all of the scores for uh for my games and it'll return both the scores for angry birds and for tetris",
    "start": "1055520",
    "end": "1061840"
  },
  {
    "text": "or i could say to restrict that make a range query on the data say give me all the scores for me uh which is uh fits a particular",
    "start": "1061840",
    "end": "1069360"
  },
  {
    "text": "game so you can see you can start to fill in some range some query flexibility even though we don't have those secondary",
    "start": "1069360",
    "end": "1074640"
  },
  {
    "text": "indices so you can also do high scores by game you could query the leaderboards table",
    "start": "1074640",
    "end": "1080000"
  },
  {
    "text": "for the game type and you're going to get all of the scores that are back there and you can get the user id off an additional attribute",
    "start": "1080000",
    "end": "1085600"
  },
  {
    "text": "and then map that back to the scores table and because you have this provisioned low level expected latency",
    "start": "1085600",
    "end": "1093679"
  },
  {
    "text": "on the queries you can build out and make the decision about how you model your data to because you may have to do multiple",
    "start": "1093679",
    "end": "1099760"
  },
  {
    "text": "queries you're always going to get that very low latency query irrespective of the the query type",
    "start": "1099760",
    "end": "1106320"
  },
  {
    "start": "1105000",
    "end": "1217000"
  },
  {
    "text": "so no sql data modeling uh is uh is very very flexible you can build out some very wonderful",
    "start": "1106320",
    "end": "1113520"
  },
  {
    "text": "data models using it but it's important as i was saying earlier to help that fit into the provision model of dynamodb",
    "start": "1113520",
    "end": "1120080"
  },
  {
    "text": "and that's by understanding how you can deliver maximum throughput so there's often distinct hash values",
    "start": "1120080",
    "end": "1125840"
  },
  {
    "text": "for keys so that's obviously important for primary keys they should be uh unique so in addition",
    "start": "1125840",
    "end": "1131360"
  },
  {
    "text": "to them being unique the hashkey elements should also have a high number of distinct values what that",
    "start": "1131360",
    "end": "1136400"
  },
  {
    "text": "means is under the hood dynamodb can distribute out the requests which are probably going to fall in a normal distribution",
    "start": "1136400",
    "end": "1142559"
  },
  {
    "text": "across that wide range of primary keys and they're more likely to go across the shards across all the data under the hood",
    "start": "1142559",
    "end": "1147840"
  },
  {
    "text": "so you can start to say well it doesn't matter where the data is because my workflow is such that the the the keys are distributed so that",
    "start": "1147840",
    "end": "1155120"
  },
  {
    "text": "each request is probably going to go to a different key so you're going to maximize out the provision throughput under the hood",
    "start": "1155120",
    "end": "1160799"
  },
  {
    "text": "so a good example of that would be a unique username inside the organ inside the uh inside the application",
    "start": "1160799",
    "end": "1166400"
  },
  {
    "text": "so user id and then first name and last name so to be a a well distributed workload under the hood because we have a",
    "start": "1166400",
    "end": "1172720"
  },
  {
    "text": "high range of unique ids and the query rates of those unique ids are probably going to be distributed",
    "start": "1172720",
    "end": "1178559"
  },
  {
    "text": "across a number of people unless you'll burn on twitter i guess this would be a bad example right so",
    "start": "1178559",
    "end": "1184480"
  },
  {
    "text": "this is limited response codes if we indexed our data by response http response code let's say we're doing some",
    "start": "1184480",
    "end": "1190240"
  },
  {
    "text": "logging then this would be a pretty poor way this would be a poorly distributed workload because there's only going to",
    "start": "1190240",
    "end": "1197039"
  },
  {
    "text": "be a limited number of these codes and there's going to be some status codes which appear much more frequently",
    "start": "1197039",
    "end": "1203440"
  },
  {
    "text": "404 hopefully not 500 but 404 probably more commonly than other ones so hopefully 200 is your top one",
    "start": "1203440",
    "end": "1209760"
  },
  {
    "text": "and so they're going to be driven to a particular shard underneath the hood you're going to max out the provision throughput of that particular shot",
    "start": "1209760",
    "end": "1217760"
  },
  {
    "start": "1217000",
    "end": "1467000"
  },
  {
    "text": "so that is the provision throughput that is the data patterns that i wanted to talk about and now it is my very great",
    "start": "1217760",
    "end": "1224720"
  },
  {
    "text": "pleasure to introduce up the new york times team",
    "start": "1224720",
    "end": "1229600"
  },
  {
    "text": "guys are you good to set things up you just have to press the button okay okay",
    "start": "1232840",
    "end": "1240559"
  },
  {
    "text": "oh questions uh yeah wait till there thanks so much i think the center one okay thanks",
    "start": "1240880",
    "end": "1249520"
  },
  {
    "text": "oh yeah you're right i'll get to that okay from edge to the right there we go uh which button here",
    "start": "1249520",
    "end": "1259679"
  },
  {
    "text": "all right okay there we go okay i'm michael wang and",
    "start": "1259840",
    "end": "1266480"
  },
  {
    "text": "this is andrew canaday my uh my partner we're from the new york times we've got the",
    "start": "1266480",
    "end": "1272000"
  },
  {
    "text": "we've had the privilege of working on a little project called the fabric and we make a lot of use of dynamo in",
    "start": "1272000",
    "end": "1279120"
  },
  {
    "text": "that project we're going to talk a little bit about the project and then we'll talk about how we work",
    "start": "1279120",
    "end": "1284720"
  },
  {
    "text": "with dynamo to try to get more out of it uh",
    "start": "1284720",
    "end": "1291120"
  },
  {
    "text": "these are the things we're going to cover a little bit of an overview and uh we're using we're going to use uh",
    "start": "1291120",
    "end": "1297440"
  },
  {
    "text": "boto in this particular talk although we've got a good bit of experience with",
    "start": "1297440",
    "end": "1303679"
  },
  {
    "text": "node.js as well but really what we wanted to do was",
    "start": "1303679",
    "end": "1309039"
  },
  {
    "text": "see if we could get more out of dynamo more endpoints more reliably more",
    "start": "1309039",
    "end": "1316080"
  },
  {
    "text": "throughput and to that degree we're like you are and like johnny rocco",
    "start": "1316080",
    "end": "1324880"
  },
  {
    "text": "we want more we always want more and i don't know if you're familiar with key largo but it's a great quote from",
    "start": "1324880",
    "end": "1331440"
  },
  {
    "text": "there so some takeaways we build on a messaging infrastructure",
    "start": "1331440",
    "end": "1337840"
  },
  {
    "text": "uh i'm the old dog there are some tricks that i brought to the team",
    "start": "1337840",
    "end": "1343440"
  },
  {
    "text": "there's a lot of good computer science that was done before the internet in fact and it's actually a little hard to find",
    "start": "1343440",
    "end": "1351200"
  },
  {
    "text": "because it's not indexed very well and but anyway boto is great and",
    "start": "1351200",
    "end": "1358799"
  },
  {
    "text": "clone and contribute that's what we plan to do um just a brief overview of the new york",
    "start": "1358799",
    "end": "1365520"
  },
  {
    "text": "times our purpose is not to generate revenue",
    "start": "1365520",
    "end": "1371919"
  },
  {
    "text": "for our shareholders this is this is actually it we do generate",
    "start": "1371919",
    "end": "1378480"
  },
  {
    "text": "revenue but it's really to enable us to keep going in our societal mission um",
    "start": "1378480",
    "end": "1385360"
  },
  {
    "text": "just to back up a little bit you can see and i looked at this when i first joined i said you know what all the stuff that",
    "start": "1385360",
    "end": "1392159"
  },
  {
    "text": "we're doing in uh building platforms and infrastructure really applies",
    "start": "1392159",
    "end": "1397919"
  },
  {
    "text": "directly and so that got me excited and that was the genesis",
    "start": "1397919",
    "end": "1403120"
  },
  {
    "text": "of what we're working on in the fabric and now andrew's going to talk a bit about the fabric",
    "start": "1403120",
    "end": "1409919"
  },
  {
    "text": "all right so i'm just going to give you a brief overview can you guys hear me through the microphone okay i'm going to give you a brief",
    "start": "1410240",
    "end": "1415919"
  },
  {
    "text": "overview of the architecture so basically we have this variety of different applications um end",
    "start": "1415919",
    "end": "1421279"
  },
  {
    "text": "user experiences that we want to facilitate having um bi-directional communication low latency",
    "start": "1421279",
    "end": "1427279"
  },
  {
    "text": "we want to be able to get content to users distributed all over the world in a very fast way and sort of bypass the traditional",
    "start": "1427279",
    "end": "1433200"
  },
  {
    "text": "architecture of having them come make restful requests to a central",
    "start": "1433200",
    "end": "1439039"
  },
  {
    "text": "server fetch data down through a hierarchy and then reflect it back so um we've built this asynchronous",
    "start": "1439039",
    "end": "1445039"
  },
  {
    "text": "messaging framework um it's uh enabled on the client side by",
    "start": "1445039",
    "end": "1450240"
  },
  {
    "text": "web sockets it's what we're doing our communication with the backbone is amqp we're using rabbitmq",
    "start": "1450240",
    "end": "1456720"
  },
  {
    "text": "and we're using aws for a variety of different things uh serving the content from the nodes",
    "start": "1456720",
    "end": "1463120"
  },
  {
    "text": "and dynamodb for storage s3 for persistent storage",
    "start": "1463120",
    "end": "1468158"
  },
  {
    "start": "1467000",
    "end": "1542000"
  },
  {
    "text": "okay so uh typical web architecture i'm just going to race through this because everybody in the room knows this clients are hitting a load balancer the",
    "start": "1468640",
    "end": "1474320"
  },
  {
    "text": "load balancer is reflecting you through to uh some front-end server that makes a request to a bunch of databases apis",
    "start": "1474320",
    "end": "1480080"
  },
  {
    "text": "compiles information aggregates it and then pushes it back to the client right it's this thing that we've all seen okay",
    "start": "1480080",
    "end": "1487600"
  },
  {
    "text": "message comes in message goes out okay but the architecture itself is a bottleneck the clients are all coming to",
    "start": "1487600",
    "end": "1493440"
  },
  {
    "text": "a central point may be distributed globally but still all right so what we've decided to do is",
    "start": "1493440",
    "end": "1499520"
  },
  {
    "text": "basically take the information and push it out to a series of nodes that are distributed",
    "start": "1499520",
    "end": "1504559"
  },
  {
    "text": "globally and have the information uh mirrored between those nodes and then have the",
    "start": "1504559",
    "end": "1510159"
  },
  {
    "text": "clients connect through a lease latency connection to the the node that's best equipped to",
    "start": "1510159",
    "end": "1515279"
  },
  {
    "text": "serve them so we have the clients interacting with these nodes that we call app buddies they're our equivalent of front end they",
    "start": "1515279",
    "end": "1520880"
  },
  {
    "text": "basically are translation layer between web sockets and the amqb back end those are connected to our bad",
    "start": "1520880",
    "end": "1528080"
  },
  {
    "text": "rabbit backbone servers which are a bunch of clustered and federated rabbitmq servers",
    "start": "1528080",
    "end": "1533600"
  },
  {
    "text": "that distribute messages very quickly and inside the new york times we're",
    "start": "1533600",
    "end": "1539120"
  },
  {
    "text": "connected to the backbone directly all right so basically the architecture",
    "start": "1539120",
    "end": "1544640"
  },
  {
    "start": "1542000",
    "end": "1626000"
  },
  {
    "text": "looks like this new york times pushes a message out to the backbone the backbone reflects it globally",
    "start": "1544640",
    "end": "1550240"
  },
  {
    "text": "and then the clients are just connected to the endpoint nearest them",
    "start": "1550240",
    "end": "1554480"
  },
  {
    "text": "all right so the i'm going to give a raise through here a real simplified uh overview of the architecture",
    "start": "1555279",
    "end": "1562000"
  },
  {
    "text": "internally so each one of the app buddies is a node that the client connects to",
    "start": "1562000",
    "end": "1567279"
  },
  {
    "text": "the app buddy itself has a small rabbitmq instance running which is used to ferry",
    "start": "1567279",
    "end": "1573120"
  },
  {
    "text": "messages between various services running inside the node",
    "start": "1573120",
    "end": "1579279"
  },
  {
    "text": "which is also connected to aws this is a little bit more of a more",
    "start": "1580960",
    "end": "1588159"
  },
  {
    "text": "complicated picture we've got the clients are connected to the app buddy which is this translation layer and it has a local message broker that",
    "start": "1588159",
    "end": "1594880"
  },
  {
    "text": "it uses to relay messages to the wholesale layer we call it",
    "start": "1594880",
    "end": "1601360"
  },
  {
    "text": "that does the message processing that translates things to amqp and pushes it through the",
    "start": "1601360",
    "end": "1606640"
  },
  {
    "text": "backbone to the times okay so these are supposed to all come up at once here you go",
    "start": "1606640",
    "end": "1612960"
  },
  {
    "text": "so we're using erlang rabbit node.js for some things although it's being phased out in favor of python in a lot of",
    "start": "1612960",
    "end": "1618960"
  },
  {
    "text": "places we're using sock js and but shooting for websockets in particular",
    "start": "1618960",
    "end": "1626720"
  },
  {
    "start": "1626000",
    "end": "1642000"
  },
  {
    "text": "okay oh that's right so we're also doing automated deployment using cloud source or cloud formation we've got a series of",
    "start": "1626720",
    "end": "1633200"
  },
  {
    "text": "tools that build templates for us based on what we want our stacks to look like and then we're using dynamodb and s3 for",
    "start": "1633200",
    "end": "1639760"
  },
  {
    "text": "persistence of different types of data okay so each of the nodes",
    "start": "1639760",
    "end": "1645200"
  },
  {
    "text": "is inside the wholesale layer is connected clustered rabbitmq",
    "start": "1645200",
    "end": "1651600"
  },
  {
    "text": "clustered across zone boundaries inside aws the data as it enters rabbitmq in any",
    "start": "1651600",
    "end": "1659039"
  },
  {
    "text": "particular node is mirrored across the cluster so it's available to all of them they basically exist as a single",
    "start": "1659039",
    "end": "1665360"
  },
  {
    "text": "messaging broker um",
    "start": "1665360",
    "end": "1670240"
  },
  {
    "text": "okay so this is basically a diagram of the way that we're doing the routing the clients go through route 53 and our",
    "start": "1671200",
    "end": "1677840"
  },
  {
    "text": "lease latency routed to a load balancer within a certain region the regions themselves have load",
    "start": "1677840",
    "end": "1683360"
  },
  {
    "text": "balancers which have weights that go to uh alternate regions so in an ideal situation the load balancer",
    "start": "1683360",
    "end": "1690000"
  },
  {
    "text": "within a given region is directly 100 of the traffic to the service within that region but in the case that we experience some",
    "start": "1690000",
    "end": "1696000"
  },
  {
    "text": "outage we can actually have a sliding scale of weights where the messages are redirected to adjacent",
    "start": "1696000",
    "end": "1701360"
  },
  {
    "text": "regions to reduce the um loss of service to the client and still try to minimize the",
    "start": "1701360",
    "end": "1706480"
  },
  {
    "text": "latency okay so this is sort of a complex diagram but what you're seeing here these red blocks are actually multiple",
    "start": "1706480",
    "end": "1713520"
  },
  {
    "text": "uh rabbit nodes uh spread across zones within a region but essentially",
    "start": "1713520",
    "end": "1718880"
  },
  {
    "text": "they function as a single node for a region and then the regions are federated globally",
    "start": "1718880",
    "end": "1724000"
  },
  {
    "text": "information pushed to any single node in any zone in any region is",
    "start": "1724000",
    "end": "1729039"
  },
  {
    "text": "very quickly replicated to all of them and so the entire thing essentially acts as a global message",
    "start": "1729039",
    "end": "1735440"
  },
  {
    "text": "broker we put a message out it's available to everybody in a very short period of time",
    "start": "1735440",
    "end": "1741039"
  },
  {
    "start": "1740000",
    "end": "1796000"
  },
  {
    "text": "okay and so this is basically uh just another way of looking at the thing that we've seen before so you can imagine the",
    "start": "1741520",
    "end": "1747200"
  },
  {
    "text": "new york times is sort of sitting in the middle of this star looking thing in the center pushing messages out to these red nodes which",
    "start": "1747200",
    "end": "1753760"
  },
  {
    "text": "are the backbone the backbone in turn is replicating uh to all the other nodes in the backbone",
    "start": "1753760",
    "end": "1759279"
  },
  {
    "text": "and each of those pushes out to the nodes on the end these are these things that are purple and red gradient the translation",
    "start": "1759279",
    "end": "1765120"
  },
  {
    "text": "layer the app buddy and then the clients are connected to those okay and i'm actually going to have",
    "start": "1765120",
    "end": "1772000"
  },
  {
    "text": "michael come up and go over how we're using dynabo db in particular",
    "start": "1772000",
    "end": "1777679"
  },
  {
    "text": "for information gathering the fabric okay",
    "start": "1777679",
    "end": "1783679"
  },
  {
    "text": "so i'm gonna pop back to this slide that whoops that andrew brought up",
    "start": "1784720",
    "end": "1792840"
  },
  {
    "text": "um actually i think to this one this is uh our focus this year is mostly",
    "start": "1792840",
    "end": "1801600"
  },
  {
    "start": "1796000",
    "end": "1883000"
  },
  {
    "text": "on pub subs so um but we're planning out the",
    "start": "1801600",
    "end": "1806640"
  },
  {
    "text": "gather analyze portion of our of our structure and so we've modeled some of this and",
    "start": "1806640",
    "end": "1813200"
  },
  {
    "text": "we've experimented with it some too and in this particular case dynamo is",
    "start": "1813200",
    "end": "1818559"
  },
  {
    "text": "critical because you know if you pub sub you send the same thing everywhere gather analyze",
    "start": "1818559",
    "end": "1825520"
  },
  {
    "text": "you've got a million events a second coming and they're all different so it's",
    "start": "1825520",
    "end": "1831279"
  },
  {
    "text": "a different kind of problem and what i wanted to point out is that these sort of",
    "start": "1831279",
    "end": "1836880"
  },
  {
    "text": "green worm holes you see there those are areas for dynamo so we our",
    "start": "1836880",
    "end": "1845279"
  },
  {
    "text": "periphery basically the retail layer is interacting with dynamo",
    "start": "1845360",
    "end": "1852159"
  },
  {
    "text": "and pushing events in maybe up to ten thousand a second uh into dynamo",
    "start": "1852159",
    "end": "1858320"
  },
  {
    "text": "each of them uh there might be 30 to 300 of these so potentially a large number",
    "start": "1858320",
    "end": "1866799"
  },
  {
    "text": "you know we're just we're infrastructure builders this is uh we're responding to the uh requirements that our developers",
    "start": "1866799",
    "end": "1873440"
  },
  {
    "text": "are putting on us and uh so it's a big number but we want to be able to",
    "start": "1873440",
    "end": "1880240"
  },
  {
    "text": "to support it so why dynamo well we've built a reliable service we",
    "start": "1880240",
    "end": "1887679"
  },
  {
    "start": "1883000",
    "end": "2018000"
  },
  {
    "text": "think it's reliable we continue to test it's pretty much stateless so the fabric",
    "start": "1887679",
    "end": "1893120"
  },
  {
    "text": "does not store messages internally at all we don't use any local storage on any of",
    "start": "1893120",
    "end": "1899279"
  },
  {
    "text": "the nodes the only storage we use is dynamo and s3",
    "start": "1899279",
    "end": "1904640"
  },
  {
    "text": "we do cache things for speed but they're right through caches and they automatically refresh",
    "start": "1904640",
    "end": "1912399"
  },
  {
    "text": "and they're all in memory the other thing about fabric is a happy fabric's got short queues so",
    "start": "1912399",
    "end": "1919360"
  },
  {
    "text": "we can measure the queue links throughout its messaging base you know there are",
    "start": "1919360",
    "end": "1924480"
  },
  {
    "text": "lots of cues but we can use them as feedback",
    "start": "1924480",
    "end": "1930320"
  },
  {
    "text": "so we persist everything just as we persist everything as fast as we can when a message comes by",
    "start": "1930320",
    "end": "1935760"
  },
  {
    "text": "we'll persist it and one thing i've learned in building data warehouses actually i hate",
    "start": "1935760",
    "end": "1943440"
  },
  {
    "text": "to say again that i'm so old but we actually built a big data warehouse at harvard university this was",
    "start": "1943440",
    "end": "1949039"
  },
  {
    "text": "before the term was coined and i learned there that",
    "start": "1949039",
    "end": "1954080"
  },
  {
    "text": "if you have spent the intellectual effort to understand something store it you know don't ask any more",
    "start": "1954080",
    "end": "1960559"
  },
  {
    "text": "questions just store it you'll find a use for it later and if you touch anything take it all so",
    "start": "1960559",
    "end": "1968880"
  },
  {
    "text": "and we want to gather and analyze we want to do this pulse of gathering we actually experimented",
    "start": "1968880",
    "end": "1975600"
  },
  {
    "text": "with this and we could run a pulse on a one second cycle in our tests so we were pretty happy",
    "start": "1975600",
    "end": "1984080"
  },
  {
    "text": "with that i don't think we'll actually would attain that in production and we don't need to but",
    "start": "1984080",
    "end": "1989200"
  },
  {
    "text": "we could do a rapid cycle we want to do this is using dynamo by the way where we would write out events and then",
    "start": "1989200",
    "end": "1995760"
  },
  {
    "text": "we would use the query facilities and mapreduce to pull them together",
    "start": "1995760",
    "end": "2001120"
  },
  {
    "text": "and we could pulse in a second and analyze the following second the previous second um it's kind of the",
    "start": "2001120",
    "end": "2009360"
  },
  {
    "text": "buzz bomb approach to data analysis we'll probably experiment with complex",
    "start": "2009360",
    "end": "2015600"
  },
  {
    "text": "event processing too so dynamodb requirements we want to be",
    "start": "2015600",
    "end": "2022880"
  },
  {
    "start": "2018000",
    "end": "2068000"
  },
  {
    "text": "able now we may not do all of these things but we want to be able to do all of these things",
    "start": "2022880",
    "end": "2028240"
  },
  {
    "text": "storing all the messages storing logs as well we wanted to facilitate burst loads",
    "start": "2028240",
    "end": "2033919"
  },
  {
    "text": "because we get a lot of uneven load and we wanted to support gather analyze which means",
    "start": "2033919",
    "end": "2039840"
  },
  {
    "text": "a very distributed sort of input into dynamo as well as a mapreduce a gather",
    "start": "2039840",
    "end": "2047679"
  },
  {
    "text": "which is based on mapreduce and we wanted to facilitate generational storage luckily the announcement today",
    "start": "2047679",
    "end": "2054000"
  },
  {
    "text": "is helping us there and we want to do fair allocation",
    "start": "2054000",
    "end": "2059280"
  },
  {
    "text": "and that fair allocation is actually pretty difficult especially if the end points are not coordinating so i'll go into",
    "start": "2059280",
    "end": "2066638"
  },
  {
    "text": "that a bit more later here i've i've stolen a few things off",
    "start": "2066639",
    "end": "2071839"
  },
  {
    "start": "2068000",
    "end": "2098000"
  },
  {
    "text": "the aws website here conventional wisdom is oh see those bad ones down there we've got",
    "start": "2071839",
    "end": "2078398"
  },
  {
    "text": "a lot of bad so not a well-suited load for dynamo according to what's",
    "start": "2078399",
    "end": "2084480"
  },
  {
    "text": "published and you don't have to read all of this the basic answer is",
    "start": "2084480",
    "end": "2090638"
  },
  {
    "text": "if you need if you're failing on your rights you need more provision throughput",
    "start": "2090639",
    "end": "2098240"
  },
  {
    "start": "2098000",
    "end": "2119000"
  },
  {
    "text": "but we'd have to provision for the peaks so uh an exponential back off just gives",
    "start": "2098240",
    "end": "2105760"
  },
  {
    "text": "us a one minute buffer that's the recommendation so but we buffer we have a messaging",
    "start": "2105760",
    "end": "2111040"
  },
  {
    "text": "platform and we can monitor so we have the and we're and we're pretty much asynchronous",
    "start": "2111040",
    "end": "2117040"
  },
  {
    "text": "and we have a lot of event handling capabilities so we started to play around with back",
    "start": "2117040",
    "end": "2123119"
  },
  {
    "start": "2119000",
    "end": "2164000"
  },
  {
    "text": "pressure from dynamo and see if we could come up with a better way and we started first with node and that",
    "start": "2123119",
    "end": "2129839"
  },
  {
    "text": "worked pretty well but sometimes requests got scheduled way out",
    "start": "2129839",
    "end": "2134960"
  },
  {
    "text": "and and sometimes out of order and we couldn't get always get convergence and we couldn't",
    "start": "2134960",
    "end": "2141040"
  },
  {
    "text": "get fair spread of load so we started to think",
    "start": "2141040",
    "end": "2146960"
  },
  {
    "text": "harder about it and this is really me again thinking about i remember when",
    "start": "2146960",
    "end": "2153040"
  },
  {
    "text": "ethernet was invented and tcp was new and i remember all the computer science",
    "start": "2153040",
    "end": "2159359"
  },
  {
    "text": "and analysis that went into it and i thought well maybe we could apply some of that",
    "start": "2159359",
    "end": "2165040"
  },
  {
    "start": "2164000",
    "end": "2198000"
  },
  {
    "text": "and so we started to look around at ways to schedule i o and the ways that smart people have worked on this for decades",
    "start": "2165040",
    "end": "2172560"
  },
  {
    "text": "now and we found a couple of things and we trying them out token bucket is key aimd",
    "start": "2172560",
    "end": "2180240"
  },
  {
    "text": "is a strategy for dealing with congestion and uh we looked to apply those",
    "start": "2180240",
    "end": "2188160"
  },
  {
    "text": "to the stream of io that we have going into dynamo from all these endpoints there are a",
    "start": "2188160",
    "end": "2194400"
  },
  {
    "text": "bunch of other things too but these these actually gave us some",
    "start": "2194400",
    "end": "2200640"
  },
  {
    "text": "stuff we started using python we started uh we picked up using boto because we could tweak it a",
    "start": "2200640",
    "end": "2206720"
  },
  {
    "text": "little bit to get back pressure to be reported immediately by adding an exception and",
    "start": "2206720",
    "end": "2212320"
  },
  {
    "text": "uh kind of brain damaging the retry logic a little bit",
    "start": "2212320",
    "end": "2217760"
  },
  {
    "text": "and we use concurrent futures so that we could develop a completely event-driven",
    "start": "2217760",
    "end": "2224800"
  },
  {
    "text": "approach to pushing stuff into dynamo through boto and now i have this terrible diagram",
    "start": "2224800",
    "end": "2230560"
  },
  {
    "text": "and uh the problem with this diagram is it's trying to represent in effect a",
    "start": "2230560",
    "end": "2236560"
  },
  {
    "text": "bunch of state charts and stuff like that and so sequential flow doesn't do really very well there but i'll give",
    "start": "2236560",
    "end": "2243440"
  },
  {
    "text": "it a try if we look at the heavy black arrows that's really the flow of data",
    "start": "2243440",
    "end": "2248720"
  },
  {
    "text": "through this so you have an input queue in our case our our inputs are always an asynchronous",
    "start": "2248720",
    "end": "2254640"
  },
  {
    "text": "input i give it a call back and it calls me when it's got something okay goes into a work queue",
    "start": "2254640",
    "end": "2261280"
  },
  {
    "text": "the work queue in effect schedules into a future okay which is a with in concurrent",
    "start": "2261280",
    "end": "2267359"
  },
  {
    "text": "futures that's a thread in effect it's a managed thread out of a thread pool in python and let's say it succeeds then",
    "start": "2267359",
    "end": "2275520"
  },
  {
    "text": "it goes into dynamo and then some notifications come back so that i can acknowledge to my data source",
    "start": "2275520",
    "end": "2284160"
  },
  {
    "text": "so because i'm controlling back pressure there and so i can acknowledge uh into the token bucket which i'll get",
    "start": "2284160",
    "end": "2292000"
  },
  {
    "text": "to in a minute okay so that's basically the data flow but how does work actually get done",
    "start": "2292000",
    "end": "2298400"
  },
  {
    "text": "in an event-driven thing then you've got sources of events we've got three sources here",
    "start": "2298400",
    "end": "2303599"
  },
  {
    "text": "we've got the work coming in it's an asynchronous event generator we've got the return",
    "start": "2303599",
    "end": "2310880"
  },
  {
    "text": "from dynamo when it comes back it calls it calls a callback and so i can harness that thread",
    "start": "2310880",
    "end": "2317680"
  },
  {
    "text": "and then we've got a timer and the way that works is",
    "start": "2317680",
    "end": "2324000"
  },
  {
    "text": "when you when it puts it in the work queue it like spins around and checks the cues if there's any",
    "start": "2325040",
    "end": "2330640"
  },
  {
    "text": "rework to be done it'll do that first if there's some work to be done it'll try to do it and",
    "start": "2330640",
    "end": "2336000"
  },
  {
    "text": "what it does is it then tries to allocate future when the future comes back it does the",
    "start": "2336000",
    "end": "2341760"
  },
  {
    "text": "same thing if it succeeds or fails it spins the",
    "start": "2341760",
    "end": "2347680"
  },
  {
    "text": "spins the wheel again to see if there's any work to be done and it keeps spinning the wheel until there's no more work to be done",
    "start": "2347680",
    "end": "2356160"
  },
  {
    "text": "and it keeps checking the token bucket okay so what's the token bucket the way the",
    "start": "2356160",
    "end": "2361359"
  },
  {
    "text": "token bucket works is it's just like a bucket it holds it has a capacity when this thing fires up we fill the",
    "start": "2361359",
    "end": "2369440"
  },
  {
    "text": "token bucket with tokens which you can think of as units of capacity",
    "start": "2369440",
    "end": "2375520"
  },
  {
    "text": "when when work is in the queue and we want to cue it",
    "start": "2375520",
    "end": "2381280"
  },
  {
    "text": "then we check to see if there are enough tokens we actually put more tokens in the bucket than there is capacity",
    "start": "2381280",
    "end": "2388079"
  },
  {
    "text": "so he'll pull some out but now the the tokens go down okay and and he'll then schedule the",
    "start": "2388079",
    "end": "2394480"
  },
  {
    "text": "work if it looks in the token bucket and there's not enough capacity then what happens is it sets the timer",
    "start": "2394480",
    "end": "2402640"
  },
  {
    "text": "based on the rate to the point in time when there will be capacity to handle that",
    "start": "2402640",
    "end": "2407760"
  },
  {
    "text": "request okay and and basically as time passes",
    "start": "2407760",
    "end": "2413280"
  },
  {
    "text": "tokens get added this is the rate and then you base it then you use",
    "start": "2413280",
    "end": "2419599"
  },
  {
    "text": "uh your strategy to adjust both capacity and rate based on the feedback that you're",
    "start": "2419599",
    "end": "2425520"
  },
  {
    "text": "getting from dynamo and that's kind of the tricky part but there's been a lot of work done on",
    "start": "2425520",
    "end": "2430560"
  },
  {
    "text": "that and we by the way um i'll say this now we're gonna",
    "start": "2430560",
    "end": "2435760"
  },
  {
    "text": "we'll be putting all this up on github all the all the code that we've developed and",
    "start": "2435760",
    "end": "2441280"
  },
  {
    "text": "kind of the charts and stuff like that that you'll see in a minute um so that's that's a bit of an overview",
    "start": "2441280",
    "end": "2447839"
  },
  {
    "text": "i'm afraid i can't go into it too much more depth than that you need to definitely find what a back",
    "start": "2447839",
    "end": "2454319"
  },
  {
    "text": "off event is you need to define what success means and you apply various factors and then",
    "start": "2454319",
    "end": "2460079"
  },
  {
    "text": "you play with these factors looking for convergence and looking for fair allocation",
    "start": "2460079",
    "end": "2466240"
  },
  {
    "text": "so you're trying to balance these aims and so andrew will actually",
    "start": "2466240",
    "end": "2472880"
  },
  {
    "text": "give you a little uh tour of some of our results",
    "start": "2472880",
    "end": "2477440"
  },
  {
    "text": "okay so",
    "start": "2478880",
    "end": "2481838"
  },
  {
    "text": "okay so that's not the one i want to show you",
    "start": "2489040",
    "end": "2495839"
  },
  {
    "text": "okay so with a typical token bucket implementation you basically have as many tokens in the",
    "start": "2501440",
    "end": "2507440"
  },
  {
    "start": "2502000",
    "end": "2807000"
  },
  {
    "text": "bucket as your total write capacity and whatever you're writing to in our case it's dynamo",
    "start": "2507440",
    "end": "2512560"
  },
  {
    "text": "so intuitively you want to allocate as many tokens in the bucket as you have right capacity on the table",
    "start": "2512560",
    "end": "2520240"
  },
  {
    "text": "but we've played around and found some kind of cool things and so now it's time for our pretty pictures and some kind of",
    "start": "2520560",
    "end": "2526400"
  },
  {
    "text": "uh peeking under the covers of dynamo a little bit so what we found is that if we're a little",
    "start": "2526400",
    "end": "2531440"
  },
  {
    "text": "greedy with our allocation of the tokens we tell the token bucket that it should shoot for capacity above",
    "start": "2531440",
    "end": "2538240"
  },
  {
    "text": "the actual allocated right capacity on the table and then we tweak the algorithm so that",
    "start": "2538240",
    "end": "2544720"
  },
  {
    "text": "it in the case that it encounters a throughput exceeded error from dynamo it backs off for a little",
    "start": "2544720",
    "end": "2551839"
  },
  {
    "text": "bit and writes below the capacity so that dynamo sort of recalibrates and then again it tries to push up beyond the",
    "start": "2551839",
    "end": "2557440"
  },
  {
    "text": "right capacity so what we found is dynamo has this burst capability where it will actually",
    "start": "2557440",
    "end": "2563440"
  },
  {
    "text": "allow you to write beyond the advertised throughput for small bursts to handle large messages",
    "start": "2563440",
    "end": "2569760"
  },
  {
    "text": "and if you sort of play with the numbers a little bit we found that it varies",
    "start": "2569760",
    "end": "2575839"
  },
  {
    "text": "it varies by the the right capacity on the table and a couple other factors but if you play with",
    "start": "2575839",
    "end": "2581280"
  },
  {
    "text": "the fill rate on the token bucket the amount that you back off when you",
    "start": "2581280",
    "end": "2586640"
  },
  {
    "text": "exceed the throughput you can actually game dynamo to yield higher on average",
    "start": "2586640",
    "end": "2592079"
  },
  {
    "text": "than 100 right capacity on the table so uh we have a couple uh oh so let me",
    "start": "2592079",
    "end": "2598640"
  },
  {
    "text": "back up so we have a modified boto which uh michael had alluded to basically what we do is",
    "start": "2598640",
    "end": "2603839"
  },
  {
    "text": "we throw an exception that's kicked back to our application in the case that the throughput on the table is exceeded so we can handle it",
    "start": "2603839",
    "end": "2610319"
  },
  {
    "text": "internally with the token bucket and try to adjust the level of traffic that we're sending through so we've got a very simple test we",
    "start": "2610319",
    "end": "2618160"
  },
  {
    "text": "basically have a token bucket mediating the rights to dynamo and then we have two different types of",
    "start": "2618160",
    "end": "2624079"
  },
  {
    "text": "content generators one is an ice content generator which generates messages relatively regularly uh and about the same size",
    "start": "2624079",
    "end": "2632000"
  },
  {
    "text": "over time and one is a really messy content content generator which um sends odd size packets at uh irregular",
    "start": "2632000",
    "end": "2640160"
  },
  {
    "text": "intervals and so what you can see here we've basically got",
    "start": "2640160",
    "end": "2646000"
  },
  {
    "text": "oh one of the things you can see here is there's a little bit of overhead on the rights to dynamo so the green line is the actual capacity consumed",
    "start": "2646000",
    "end": "2652240"
  },
  {
    "text": "uh by the rights as they're going through the blue is the number of bytes in case in this case the red line",
    "start": "2652240",
    "end": "2659200"
  },
  {
    "text": "here is the the right capacity limit on the table and you can see here that with",
    "start": "2659200",
    "end": "2666560"
  },
  {
    "text": "messages varying between 800 and 4096 bytes at irregular intervals basically",
    "start": "2666560",
    "end": "2671599"
  },
  {
    "text": "being broadcast frequently bursts higher than the capacity of the table we're achieving on average this is over a 35 second period",
    "start": "2671599",
    "end": "2678079"
  },
  {
    "text": "but we have some longer ones we're going to show you 105 percent of what the actual write capacity in the table should have been",
    "start": "2678079",
    "end": "2686240"
  },
  {
    "text": "i'm going to do this because these are a little out of order so this one here is a diagram showing",
    "start": "2686720",
    "end": "2693839"
  },
  {
    "text": "two different data sources at the same time the purple is the nice data source the blue is the the random and the green is the",
    "start": "2693839",
    "end": "2700319"
  },
  {
    "text": "actual capacity consumed so you can see that the token bucket is able to take this",
    "start": "2700319",
    "end": "2705599"
  },
  {
    "text": "combination of the two content generators and sort of even out their rights to the table so that even though",
    "start": "2705599",
    "end": "2710800"
  },
  {
    "text": "the content generation is very irregular the way that we're using the table is hovering right around where the ideal",
    "start": "2710800",
    "end": "2716640"
  },
  {
    "text": "capacity for the table is in our case again we've gone about nine percent over um",
    "start": "2716640",
    "end": "2723280"
  },
  {
    "text": "let's see okay so this is run over oh i'm playing",
    "start": "2723280",
    "end": "2731440"
  },
  {
    "text": "this okay this is basically another one of",
    "start": "2731440",
    "end": "2738079"
  },
  {
    "text": "the same run over a longer period of time there's still a little bit of magic to it so we haven't been able to find out deterministically",
    "start": "2738079",
    "end": "2744480"
  },
  {
    "text": "for a given write capacity on a table or data size what the ideal numbers are for",
    "start": "2744480",
    "end": "2750319"
  },
  {
    "text": "the token bucket algorithm but playing around with them we're able to get some long-term results that still exceed 100 throughput and i've got another",
    "start": "2750319",
    "end": "2761838"
  },
  {
    "text": "this is the same thing again we're noticing that the behavior changes depending on the right capacity on the table so this is one that's ten times",
    "start": "2762640",
    "end": "2768240"
  },
  {
    "text": "the size of the previous table and the spikes are a lot more dramatic but still the throughput is over 100",
    "start": "2768240",
    "end": "2773839"
  },
  {
    "text": "this is a graph just using the random generator and then this is an example i wanted to",
    "start": "2773839",
    "end": "2780000"
  },
  {
    "text": "put on there for the sake of honesty which is if you don't get the numbers quite right and like i said there's some magic to it",
    "start": "2780000",
    "end": "2785839"
  },
  {
    "text": "this is a case where the algorithm is actually backed off too conservatively and then is increasing",
    "start": "2785839",
    "end": "2791119"
  },
  {
    "text": "the tokens a little too conservatively tokens a little too conservatively so we're actually under utilizing dynamo in",
    "start": "2791119",
    "end": "2796880"
  },
  {
    "text": "this case i think that's about all we have in",
    "start": "2796880",
    "end": "2804240"
  },
  {
    "text": "terms of information that we're going to broadcast to you but if you have questions",
    "start": "2804240",
    "end": "2809599"
  }
]
[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "hey everybody Welcome to today's talk on uh leveraging the cloud with a blue green architecture my name is Jim plush",
    "start": "5560",
    "end": "11440"
  },
  {
    "text": "director of engineering at Crow strike and co-presenting with me will be uh sha Barry one of our principal software",
    "start": "11440",
    "end": "17960"
  },
  {
    "text": "Engineers um so I'm going to kind of go through the high level on a little bit about us how we process data our",
    "start": "17960",
    "end": "24080"
  },
  {
    "text": "deployment model uh and then Sean's going to touch on you know how we actually built the system out",
    "start": "24080",
    "end": "31160"
  },
  {
    "start": "31000",
    "end": "64000"
  },
  {
    "text": "um so little bit about us uh crowd strike is a security uh cyber security",
    "start": "31160",
    "end": "37480"
  },
  {
    "text": "startup found it a few years back mainly focused on advanced persistent threats",
    "start": "37480",
    "end": "42559"
  },
  {
    "text": "uh lateral movement data exfiltration uh zero day exploits uh we",
    "start": "42559",
    "end": "48960"
  },
  {
    "text": "have a product that installs on laptops servers uh Etc and all that data is",
    "start": "48960",
    "end": "54359"
  },
  {
    "text": "constantly streaming into our cloud system where it gets processed matched up against machine learning models that",
    "start": "54359",
    "end": "60519"
  },
  {
    "text": "our data science team built Etc um so we've got a number of kind of Security",
    "start": "60519",
    "end": "66360"
  },
  {
    "start": "64000",
    "end": "95000"
  },
  {
    "text": "Experts on staff and when we started you know talking with them about our deployment process and what do we need",
    "start": "66360",
    "end": "72799"
  },
  {
    "text": "to you know make sure we handle they had the concept of the million dooll event right it's that that one DNS query it's",
    "start": "72799",
    "end": "79960"
  },
  {
    "text": "that one network connection that could be the key to discovering a new vulnerability or a new uh Threat Vector",
    "start": "79960",
    "end": "86280"
  },
  {
    "text": "so it's really important especially when we do our deploy process that we don't actually lose any data uh then we treat",
    "start": "86280",
    "end": "91479"
  },
  {
    "text": "each event as that you know million doll event so if you can picture like a toy",
    "start": "91479",
    "end": "97479"
  },
  {
    "start": "95000",
    "end": "127000"
  },
  {
    "text": "example of a compromise machine uh in our system so user opens a malicious",
    "start": "97479",
    "end": "102640"
  },
  {
    "text": "Word document uh that sends an event up to our cloud system that spawns command",
    "start": "102640",
    "end": "108399"
  },
  {
    "text": "shell command shell relaunches word before the user even notices uh so we get that event and then the command",
    "start": "108399",
    "end": "113759"
  },
  {
    "text": "shell starts you know making call outs uh network connections starts bringing",
    "start": "113759",
    "end": "118880"
  },
  {
    "text": "back some additional payloads exfiltrate some data and then at that point they bounce to another machine or they cover",
    "start": "118880",
    "end": "124920"
  },
  {
    "text": "their tracks and their output they've gotten what they they needed so we kind of you know reorganize all that",
    "start": "124920",
    "end": "131280"
  },
  {
    "start": "127000",
    "end": "144000"
  },
  {
    "text": "data um back in our our cloud system and organiz into different process trees",
    "start": "131280",
    "end": "136480"
  },
  {
    "text": "different uis um so the you know customer has an understanding of what happened uh on",
    "start": "136480",
    "end": "141760"
  },
  {
    "text": "their Network so this kind of just a high level example of that that data",
    "start": "141760",
    "end": "148160"
  },
  {
    "start": "144000",
    "end": "184000"
  },
  {
    "text": "processing so all those sensors are connected up to an SSL termination layer",
    "start": "148160",
    "end": "154200"
  },
  {
    "text": "uh we take all those events in drop them in uh to Kafka and if you're not familiar with Kafka it's kind of like",
    "start": "154200",
    "end": "160200"
  },
  {
    "text": "Kinesis or a message Q uh so we're just getting all these events in dropping",
    "start": "160200",
    "end": "165239"
  },
  {
    "text": "them into CFA and we have a number of consumers that then process the data through a a you know processing system",
    "start": "165239",
    "end": "172120"
  },
  {
    "text": "whether it again be um Predictive Analytics uh machine learning models uh",
    "start": "172120",
    "end": "177640"
  },
  {
    "text": "other heris STS that we use to understand understand what's happening on that system not only at the sensor level but at the global",
    "start": "177640",
    "end": "183440"
  },
  {
    "text": "level so we're kind of in the highs scale Big Data space um mainly deal with",
    "start": "183440",
    "end": "188519"
  },
  {
    "start": "184000",
    "end": "249000"
  },
  {
    "text": "Fortune 500s some large nonprofits think tanks that are constantly under attack for uh",
    "start": "188519",
    "end": "194959"
  },
  {
    "text": "information we're right around 100,000 events per second flowing in our cloud system sustained and we're expected to you know",
    "start": "194959",
    "end": "202319"
  },
  {
    "text": "reach up in around 500,000 events per second uh coming next year and just for an example of data volume it's about 2",
    "start": "202319",
    "end": "209000"
  },
  {
    "text": "to four terab of data per day per customer as it kind of fans through uh fans through our",
    "start": "209000",
    "end": "214400"
  },
  {
    "text": "system and we've built this on a microservice type architecture so we knew kind of early on we were going to",
    "start": "214400",
    "end": "219799"
  },
  {
    "text": "be you know in the Big Data space and if you come from the monolithic app world um you've always got this app competing",
    "start": "219799",
    "end": "225959"
  },
  {
    "text": "for CPU memory dis and it's becomes a balancing act right so you're wasting a",
    "start": "225959",
    "end": "231000"
  },
  {
    "text": "lot of resources so from the beginning we wanted to kind of build something you know where each service was dedicated to",
    "start": "231000",
    "end": "237040"
  },
  {
    "text": "a specific task and then being an AWS we could you know provision that service",
    "start": "237040",
    "end": "242640"
  },
  {
    "text": "whether it be CPU or memory based uh and we're you know pretty polyglot environment in that case so our",
    "start": "242640",
    "end": "249280"
  },
  {
    "start": "249000",
    "end": "255000"
  },
  {
    "text": "Tech stack is fairly complicated probably see a lot of Technologies you guys are familiar with um but a lot of",
    "start": "249280",
    "end": "256040"
  },
  {
    "text": "that's possible because we kind of stitch it up together with uh different AWS services and uh and cost-wise I don't",
    "start": "256040",
    "end": "263120"
  },
  {
    "text": "even know if I would attempt the blue green model uh in a physical data center just given the amount of machines that",
    "start": "263120",
    "end": "268680"
  },
  {
    "text": "we'd have to run simult mously means we'd have to virtualize our data center or containerize it which we just didn't",
    "start": "268680",
    "end": "274160"
  },
  {
    "text": "have the uh the staff for so some of the problems we were trying to solve with our deployment",
    "start": "274160",
    "end": "280360"
  },
  {
    "text": "architecture was you know you get into a situation where you know a new patch",
    "start": "280360",
    "end": "285479"
  },
  {
    "text": "comes out and all of a sudden you have to you know refresh your entire fleet and operations comes running in and it",
    "start": "285479",
    "end": "291440"
  },
  {
    "text": "becomes a big kind of panic mode uh because you you know you got to figure out what service can I take down how do",
    "start": "291440",
    "end": "297000"
  },
  {
    "text": "I orchestrate you know what has to come down before what service then you have a situation where you know",
    "start": "297000",
    "end": "302479"
  },
  {
    "text": "service has been running for 2 years person that wrote it doesn't even work here anymore um so you know everyone's",
    "start": "302479",
    "end": "308479"
  },
  {
    "text": "kind of scared to touch that thing over there um so it just creates a real real Panic around deployments other models I've seen are",
    "start": "308479",
    "end": "315400"
  },
  {
    "text": "the the rolling restart model which you know when you get to about a thousand machines or more you you start doing",
    "start": "315400",
    "end": "321000"
  },
  {
    "text": "groups of those restarts uh until you hit you know server 600 uh groups of 50",
    "start": "321000",
    "end": "327960"
  },
  {
    "text": "you discover a catastrophic issue then you got to start you know unwinding those changes back uh meanwhile you've",
    "start": "327960",
    "end": "333600"
  },
  {
    "text": "probably impacted the customer for the 45 minutes it takes to roll back uh also seen you know situations",
    "start": "333600",
    "end": "342199"
  },
  {
    "text": "that people like to deploy on Friday nights you know hand it off to opposite at midnight right we won't impact the",
    "start": "342199",
    "end": "348360"
  },
  {
    "text": "customer problem with that is uh at some point you're going to have to deploy during the day and we prefer deploying",
    "start": "348360",
    "end": "354520"
  },
  {
    "text": "when all of our developers around you get more eyes on the on the code right you can kind of see see uh you're just",
    "start": "354520",
    "end": "362280"
  },
  {
    "text": "able to kind of Trio issues faster and then when we started thinking of blue green for our event processing",
    "start": "362280",
    "end": "369280"
  },
  {
    "text": "model there's really not a lot of uh literature out there on how to do that",
    "start": "369280",
    "end": "374560"
  },
  {
    "text": "with message cues and Kafka and you know how do we deal with the data layer like everything is very simple like oh you",
    "start": "374560",
    "end": "379919"
  },
  {
    "text": "just have a web server and you flip a load balancer in a DNS or DNS switch and",
    "start": "379919",
    "end": "385160"
  },
  {
    "text": "and you're flipped over but we have a pretty complicated event processing system so we had to figure that out so",
    "start": "385160",
    "end": "390960"
  },
  {
    "start": "390000",
    "end": "443000"
  },
  {
    "text": "given those our primary objectives for our deployments um one we wanted to minimize customer impact right we should",
    "start": "390960",
    "end": "397160"
  },
  {
    "text": "be able to deploy on Wednesday at 10: a.m. and not have the customer even notice the deploy changeed until the",
    "start": "397160",
    "end": "402199"
  },
  {
    "text": "release notes hit their inbox um maximize Engineers weekends you",
    "start": "402199",
    "end": "407599"
  },
  {
    "text": "know you put a lot of money into recruiting people hiring training uh you don't want to burn people out you know",
    "start": "407599",
    "end": "412759"
  },
  {
    "text": "with deployments so you know you're doing those Friday night late night deployments um you know you can only do",
    "start": "412759",
    "end": "419039"
  },
  {
    "text": "so many of those before people start uh dropping out and we wanted to reduce the",
    "start": "419039",
    "end": "424080"
  },
  {
    "text": "uh dependencies of rollouts so in our case we do a full cluster blue green so everything goes out",
    "start": "424080",
    "end": "429800"
  },
  {
    "text": "together um there's a other models that I'll get into uh in a minute but we wanted to minimize that you know service",
    "start": "429800",
    "end": "435759"
  },
  {
    "text": "a has to come up because before service B because of some third party serialization change we need to",
    "start": "435759",
    "end": "440840"
  },
  {
    "text": "orchestrate that and then you know since we were in Amazon we had to start thinking how can",
    "start": "440840",
    "end": "447560"
  },
  {
    "start": "443000",
    "end": "491000"
  },
  {
    "text": "we exploit the cloud to our advantage for this deployment model and we really",
    "start": "447560",
    "end": "452599"
  },
  {
    "text": "started forgetting about servers and IPS and started thinking of you know programmable data centers right",
    "start": "452599",
    "end": "458080"
  },
  {
    "text": "ephemeral nodes it's just a pool of resources we don't even know what IPS are running in production because they change based on autoscale uh they change",
    "start": "458080",
    "end": "465240"
  },
  {
    "text": "when we do deployments and you know we go by the philosophy that it should be easier to recreate the environment than to fix it",
    "start": "465240",
    "end": "472520"
  },
  {
    "text": "you know if you're trying to triage a issue on a production server and you're impacting you know your customers's",
    "start": "472520",
    "end": "478560"
  },
  {
    "text": "experience much easier to flip back to a previous version of that processing cluster leave the old version running so",
    "start": "478560",
    "end": "485080"
  },
  {
    "text": "you can debug throw load at it try and replicate the issue um and then you know minimize that customer impact so just",
    "start": "485080",
    "end": "492080"
  },
  {
    "start": "491000",
    "end": "533000"
  },
  {
    "text": "quick refresher on blue green if you're not super familiar with it um you can imagine number of users connected up",
    "start": "492080",
    "end": "498319"
  },
  {
    "text": "through a low balancer router what have you uh they're hitting your web server that's talking to an application server",
    "start": "498319",
    "end": "504560"
  },
  {
    "text": "to a shared database now you're ready to launch V2 of your application",
    "start": "504560",
    "end": "509800"
  },
  {
    "text": "so you spin up a new green cluster you got V2 of of your of your apps you run",
    "start": "509800",
    "end": "515320"
  },
  {
    "text": "test through it everything looks good you flip your switches and now you're running on your V2 application meanwhile",
    "start": "515320",
    "end": "521719"
  },
  {
    "text": "you have blue still available in case you have to fail over you have a catastrophic issue with your deployment",
    "start": "521719",
    "end": "527440"
  },
  {
    "text": "uh if everything does look good you know after some period of time you power it down and now you're you're on the new",
    "start": "527440",
    "end": "532880"
  },
  {
    "text": "cluster so there's a couple of models there there's the the full cluster blue green which is kind of our approach uh",
    "start": "532880",
    "end": "539880"
  },
  {
    "start": "533000",
    "end": "576000"
  },
  {
    "text": "and that's really where everything kind of goes out together uh as one kind of processing",
    "start": "539880",
    "end": "545640"
  },
  {
    "text": "unit and we mainly picked that because you know we're a small still a small company uh small team so you know we can",
    "start": "545640",
    "end": "552360"
  },
  {
    "text": "kind of coordinate our releases together then there's the app based Blu green which you'll kind of see in the Netflix",
    "start": "552360",
    "end": "557760"
  },
  {
    "text": "type model where you know as as we grow out and expand then we can move into where specific teams own services and",
    "start": "557760",
    "end": "565000"
  },
  {
    "text": "they can Blu green those applications independently but we also have the ability to do a full cluster refresh for",
    "start": "565000",
    "end": "571120"
  },
  {
    "text": "those you know heart bleed type situations where you just have to patch everything as soon as possible but you know you can't Blu",
    "start": "571120",
    "end": "577959"
  },
  {
    "start": "576000",
    "end": "640000"
  },
  {
    "text": "green all the things right you're not Blu Greening your databases so we utilize a uh a common data plane that we",
    "start": "577959",
    "end": "584680"
  },
  {
    "text": "call it so blue and green both simultaneously talk to the data",
    "start": "584680",
    "end": "590120"
  },
  {
    "text": "plane let me go back there um and what that means is essentially that all the",
    "start": "591720",
    "end": "597160"
  },
  {
    "text": "code rollouts that we do has to be backwards comp comp able with previous versions so if you're making some kind",
    "start": "597160",
    "end": "602440"
  },
  {
    "text": "of destructive change you know you're taking a a name column in database and splitting out in the first and last",
    "start": "602440",
    "end": "608519"
  },
  {
    "text": "that's a destructive change uh so if you had to roll back you would actually have to migrate that data over so what we'll",
    "start": "608519",
    "end": "614760"
  },
  {
    "text": "do is actually take the approach of rting the data to the multiple you know multiple steps uh let it go out for a",
    "start": "614760",
    "end": "620440"
  },
  {
    "text": "couple deployments the API should be changed to be able to handle if the data is available first and last name if not",
    "start": "620440",
    "end": "625920"
  },
  {
    "text": "fall back to the name and then you let that roll out a few releases and you establish a water line of I can't safely",
    "start": "625920",
    "end": "632959"
  },
  {
    "text": "roll back my full cluster or specific apps Beyond this point without causing uh a data migration",
    "start": "632959",
    "end": "639760"
  },
  {
    "text": "issue so again we generally deploy at the end of Sprint releases together uh given we're still you know relatively",
    "start": "639760",
    "end": "646279"
  },
  {
    "start": "640000",
    "end": "731000"
  },
  {
    "text": "small team but we do do hot fixes and upgrades frequently outside of that process uh and this is where our",
    "start": "646279",
    "end": "652560"
  },
  {
    "text": "automation is being built out to support that app based uh blue",
    "start": "652560",
    "end": "657760"
  },
  {
    "text": "green so early on you know we weren't quite sure about this approach right it was somewhat painful a lot of manual",
    "start": "657760",
    "end": "664680"
  },
  {
    "text": "steps it was actually way more than you know we thought we'd have to build out uh you know it took an entire day to get",
    "start": "664680",
    "end": "671360"
  },
  {
    "text": "a release out which you know is is kind of a non-starter but you know we uh we",
    "start": "671360",
    "end": "676639"
  },
  {
    "text": "decided to double down on the approach and so if it was painful one day we did it every day for weeks and so we started",
    "start": "676639",
    "end": "682160"
  },
  {
    "text": "ironing out those those issues um you know what was Auto what was manual on someone's laptop still what did we have",
    "start": "682160",
    "end": "688440"
  },
  {
    "text": "to check what log were we missing how do we build this into a dashboard and so we just kept iterating on it and now today",
    "start": "688440",
    "end": "694160"
  },
  {
    "text": "generally takes 45 minutes to the entire process of spinning up the new cluster",
    "start": "694160",
    "end": "699440"
  },
  {
    "text": "uh running tests canaries regression tests uh so it's you know it's pretty",
    "start": "699440",
    "end": "705279"
  },
  {
    "text": "streamline at this point uh a lot of that's because we've had this sustaining engineer kind of kind of role where",
    "start": "705279",
    "end": "712320"
  },
  {
    "text": "every person on the team including project managers QA everyone's run a deployment and that helped us really",
    "start": "712320",
    "end": "719320"
  },
  {
    "text": "iron out those last automation issues make sure the documentation is up to date and everything makes sense uh and",
    "start": "719320",
    "end": "726279"
  },
  {
    "text": "you know Sean built us an internal UI where everything's just you know clickable that he'll get into in a bit",
    "start": "726279",
    "end": "733040"
  },
  {
    "start": "731000",
    "end": "808000"
  },
  {
    "text": "so when deployment day comes um you know we generally synchronize our repositories we apply any data plan",
    "start": "733040",
    "end": "739680"
  },
  {
    "text": "migrations so for adding indexes or or what have you new column families in Cassandra um let's say blue is running",
    "start": "739680",
    "end": "747199"
  },
  {
    "text": "we'll go ahead and spin up the green processing cluster we'll go ahead and run our regression Suite against Green no customers are on",
    "start": "747199",
    "end": "754079"
  },
  {
    "text": "it yet so we're getting a you know a fresh run of uh known sequences of events if everything looks good there",
    "start": "754079",
    "end": "760880"
  },
  {
    "text": "we'll then start flipping Canary customers over so we dog food our own products so we'll you know roll our",
    "start": "760880",
    "end": "766000"
  },
  {
    "text": "company over to the new code path so in case there was you know a sensor update in between our deploy and there's some",
    "start": "766000",
    "end": "771079"
  },
  {
    "text": "new event kind of sequence we'll be able to uh catch that before uh customers are",
    "start": "771079",
    "end": "776720"
  },
  {
    "text": "impacted um at that point we'll switch into active mode so both are running simultaneously and if everything looks",
    "start": "776720",
    "end": "783639"
  },
  {
    "text": "good after a few minutes we'll deactivate blue but leave it running in case we have to do a catastrophic",
    "start": "783639",
    "end": "789000"
  },
  {
    "text": "failover um not going we haven't had to do that yet but you know we have that ability uh and you can see why the cost",
    "start": "789000",
    "end": "796040"
  },
  {
    "text": "model in AWS makes sense because now we're running you know thousands of machines simultaneously in each",
    "start": "796040",
    "end": "801680"
  },
  {
    "text": "environment that looks good after an hour we power that down um because it's you know pretty safe to carry on with",
    "start": "801680",
    "end": "807800"
  },
  {
    "text": "the deployment so some of the keys to success for for us in our kind of event processing model",
    "start": "807800",
    "end": "814079"
  },
  {
    "start": "808000",
    "end": "824000"
  },
  {
    "text": "one it's you know focus on automation it's got to be a priority in the organization and not something someone",
    "start": "814079",
    "end": "819639"
  },
  {
    "text": "does in their spare time you got actually dedicate you know resources to it uh instrumentation and metrics so our",
    "start": "819639",
    "end": "827839"
  },
  {
    "start": "824000",
    "end": "842000"
  },
  {
    "text": "go apps our jvm apps are all you know fully instrumented with counters and we",
    "start": "827839",
    "end": "833440"
  },
  {
    "text": "track everything and all that feeds into a central aggregation system so that when you're running a deploy you can easily know you know what looks normal",
    "start": "833440",
    "end": "840399"
  },
  {
    "text": "what looks what looks healthy provisioning systems being able to you know again recreate your",
    "start": "840399",
    "end": "846920"
  },
  {
    "text": "environment rather than fix it so we use a mixture of Chef and half-baked Amis uh",
    "start": "846920",
    "end": "852120"
  },
  {
    "text": "Sean's going to get into that process but it's essentially you know being able to not worry about uh a machine on the",
    "start": "852120",
    "end": "859079"
  },
  {
    "text": "fritz and just you know kill the VM let it respawn in a a you know a known",
    "start": "859079",
    "end": "864720"
  },
  {
    "text": "State regression tests are really key for this kind of system",
    "start": "864720",
    "end": "870040"
  },
  {
    "start": "865000",
    "end": "888000"
  },
  {
    "text": "um you know we have a microservice again architecture have 50 Services we can't watch them all one person's not going to",
    "start": "870040",
    "end": "876160"
  },
  {
    "text": "watch them all so being able to know that those services are healthy and that you can send deterministic input out get",
    "start": "876160",
    "end": "881880"
  },
  {
    "text": "back the responses of what you assume the state of the world should be you know after that",
    "start": "881880",
    "end": "887920"
  },
  {
    "text": "change uh Canary customers being able to you know segment",
    "start": "887920",
    "end": "894199"
  },
  {
    "text": "part of your user base over onto a new application uh version without impacting your entire fleet of users so we're",
    "start": "894199",
    "end": "902480"
  },
  {
    "text": "going to get into that as well on how we do that feature Flags so we have 50",
    "start": "902480",
    "end": "909240"
  },
  {
    "start": "906000",
    "end": "935000"
  },
  {
    "text": "Services uh if something goes wrong we're usually not going to you know Hal the entire deployment there's a UI",
    "start": "909240",
    "end": "915279"
  },
  {
    "text": "feature that's broken or an API in the back end that's not functioning properly after we bring up the new cluster um",
    "start": "915279",
    "end": "921880"
  },
  {
    "text": "because we have everything behind a feature flag we're able to kind of shut things off let the deployment carry on",
    "start": "921880",
    "end": "927680"
  },
  {
    "text": "have the developer hot fix it flip the feature back on uh and it's deployed at",
    "start": "927680",
    "end": "932800"
  },
  {
    "text": "that point so unified app requirements you",
    "start": "932800",
    "end": "938560"
  },
  {
    "start": "935000",
    "end": "944000"
  },
  {
    "text": "also especially when you're doing this kind of architecture you know you don't want to be the wild west right you want",
    "start": "938560",
    "end": "945079"
  },
  {
    "start": "944000",
    "end": "957000"
  },
  {
    "text": "kind of unified a unified deployment model that these systems can plug into um to be successful so health checks is",
    "start": "945079",
    "end": "951920"
  },
  {
    "text": "there an endpoint that Ops knows they can always automate and hit to know that your service is healthy um packaging",
    "start": "951920",
    "end": "958319"
  },
  {
    "start": "957000",
    "end": "980000"
  },
  {
    "text": "I've seen some teams use tar files some R sync some have Debian packages if",
    "start": "958319",
    "end": "963639"
  },
  {
    "text": "you're not kind of standardizing on your packaging model uh it becomes really difficult to tie this into automation uh",
    "start": "963639",
    "end": "969759"
  },
  {
    "text": "and just you know constantly writing these one-off scripts so we do Debian packages if you have python go Scala",
    "start": "969759",
    "end": "976399"
  },
  {
    "text": "everything gets deployed as a debban package uh Sean's going to touch branching logging is another key one to",
    "start": "976399",
    "end": "984000"
  },
  {
    "start": "980000",
    "end": "1014000"
  },
  {
    "text": "be able to automate this kind of system um you know some teams have a warn is an",
    "start": "984000",
    "end": "989480"
  },
  {
    "text": "error and an error is a warrn and you know one team will log to CIS log one team will log to you know Fu log and in",
    "start": "989480",
    "end": "996839"
  },
  {
    "text": "VAR um so it makes it Again difficult to plug into your your automation right you should should have a standard way of",
    "start": "996839",
    "end": "1003360"
  },
  {
    "text": "what is an error what does that mean what do I do when I see that is that bad is a lot of them bad um so that way you",
    "start": "1003360",
    "end": "1009319"
  },
  {
    "text": "can kind of build these dashboards out and know immediately know the the health of the system deployment history it's kind of",
    "start": "1009319",
    "end": "1017560"
  },
  {
    "start": "1014000",
    "end": "1034000"
  },
  {
    "text": "given being able to go back into a known State and uh recreate the state of the world you know if you have some kind of",
    "start": "1017560",
    "end": "1024199"
  },
  {
    "text": "issue you know when you bring the cluster up or you've discovered something that three versions ago was an issue you can kind of take that whole",
    "start": "1024199",
    "end": "1030000"
  },
  {
    "text": "release and throw it in your integration cluster so how we know we've kind of",
    "start": "1030000",
    "end": "1036720"
  },
  {
    "start": "1034000",
    "end": "1122000"
  },
  {
    "text": "been successful on this approach uh is that every person on the team at one point has said thank God we have blue green uh it's not that we've never had a",
    "start": "1036720",
    "end": "1043880"
  },
  {
    "text": "bad deployment we've just never had a deployment that's infected customers um knock on wood and since we've got it",
    "start": "1043880",
    "end": "1050919"
  },
  {
    "text": "fully automated out we've been through over 100 deployments um you know something comes up in a bad State it's",
    "start": "1050919",
    "end": "1056640"
  },
  {
    "text": "not a you know time of Panic it's let's think about it rationally customers aren't impacted yet let's take some",
    "start": "1056640",
    "end": "1063120"
  },
  {
    "text": "debugging steps look at it sometimes we say power it down too many issues let's",
    "start": "1063120",
    "end": "1068280"
  },
  {
    "text": "go look at it in integration uh and rerun load testing or something uh also",
    "start": "1068280",
    "end": "1073600"
  },
  {
    "text": "if you're a Kafka user we're uh partnering with Joe Stein from BDS to",
    "start": "1073600",
    "end": "1080039"
  },
  {
    "text": "release a Java and a new go Kafka client that'll support this kind of blue green",
    "start": "1080039",
    "end": "1085320"
  },
  {
    "text": "switch over model uh and also provide you know at least once message guarantees to make sure when you do the",
    "start": "1085320",
    "end": "1090400"
  },
  {
    "text": "switch over you can uh be guaranteed that those operations have been completed so with that I'll turn over Mr",
    "start": "1090400",
    "end": "1097000"
  },
  {
    "text": "Shawn to kind of work through the uh the details all right thank you Jim and",
    "start": "1097000",
    "end": "1103799"
  },
  {
    "text": "thank you everyone for joining us today um there's a number of ways to orchestrate and architect a blue green",
    "start": "1103799",
    "end": "1110559"
  },
  {
    "text": "system right there's the siphoning off traffic away from one cluster over to",
    "start": "1110559",
    "end": "1117720"
  },
  {
    "text": "another cluster there's the load balancer flipping switch trick uh what I",
    "start": "1117720",
    "end": "1122760"
  },
  {
    "start": "1122000",
    "end": "1147000"
  },
  {
    "text": "want to go through are really the ways that we uh designed our system to to",
    "start": "1122760",
    "end": "1128280"
  },
  {
    "text": "work with our event stream processing so that we guarantee that we don't lose any data right because as Jim alluded to",
    "start": "1128280",
    "end": "1135080"
  },
  {
    "text": "earlier we have this concept of like the million dooll event right we can't miss anything because any one particular",
    "start": "1135080",
    "end": "1142400"
  },
  {
    "text": "event could be the thing that lets us know that there's an intrusion that's",
    "start": "1142400",
    "end": "1147840"
  },
  {
    "start": "1149000",
    "end": "1217000"
  },
  {
    "text": "started so first I just want to give you a little bit of a really simplified uh",
    "start": "1149559",
    "end": "1155559"
  },
  {
    "text": "bullet points on what exactly Kafka is so Kafka is a distributed commit log",
    "start": "1155559",
    "end": "1161919"
  },
  {
    "text": "right you can think about it sort of like a message cue um the main difference is going to be that with a",
    "start": "1161919",
    "end": "1168480"
  },
  {
    "text": "message message cue you pull off a message that message is then act and then deleted right Kafka is going to",
    "start": "1168480",
    "end": "1176200"
  },
  {
    "text": "persist that message for as long as you've configured kofka to persist that message and it's up to a consumer of",
    "start": "1176200",
    "end": "1183919"
  },
  {
    "text": "this stream to maintain its own offset so the power that that gives you",
    "start": "1183919",
    "end": "1190799"
  },
  {
    "text": "is if you have any kind of failure individual consumers can reset or play",
    "start": "1190799",
    "end": "1197760"
  },
  {
    "text": "back from an earlier part in the Stream right so you can recover if for some",
    "start": "1197760",
    "end": "1203919"
  },
  {
    "text": "reason a service was having issues and you know started out of memory a box and",
    "start": "1203919",
    "end": "1209200"
  },
  {
    "text": "you lost all these events you can simply push your pointer into that stream to an earlier place and replay all those",
    "start": "1209200",
    "end": "1217360"
  },
  {
    "start": "1217000",
    "end": "1264000"
  },
  {
    "text": "events so blue Greening starts with a running cluster in this case it's the blue",
    "start": "1217360",
    "end": "1222760"
  },
  {
    "text": "cluster and we have all these sensors installed in the field and they're connecting through an elastic load",
    "start": "1222760",
    "end": "1228159"
  },
  {
    "text": "balancer to our termination servers now the termination servers are",
    "start": "1228159",
    "end": "1235000"
  },
  {
    "text": "the main ingestion point for all of that data right and those are handing off all of these events over to our content",
    "start": "1235000",
    "end": "1241640"
  },
  {
    "text": "routers and the content routers are writing to active topics in Kafka I'll",
    "start": "1241640",
    "end": "1247520"
  },
  {
    "text": "explain what the whole concept of active and inactive topics means but the",
    "start": "1247520",
    "end": "1252960"
  },
  {
    "text": "important thing is our content routers in blue are writing to active and our content processors are reading from that",
    "start": "1252960",
    "end": "1259240"
  },
  {
    "text": "same active stream when we go to launch a new",
    "start": "1259240",
    "end": "1266039"
  },
  {
    "start": "1264000",
    "end": "1285000"
  },
  {
    "text": "cluster in this case green we have a whole UI uh that's been built up over",
    "start": "1266039",
    "end": "1272360"
  },
  {
    "text": "time that allows us to start this deployment process in this case we have a blue cluster running and we're ready",
    "start": "1272360",
    "end": "1278880"
  },
  {
    "text": "to launch green so we click a few buttons and we launch",
    "start": "1278880",
    "end": "1285400"
  },
  {
    "text": "green so the green clusters launched and the really important thing to start is",
    "start": "1285400",
    "end": "1291240"
  },
  {
    "text": "that our termination servers in green are kept out of the load balancer by just simply failing health checks right",
    "start": "1291240",
    "end": "1297640"
  },
  {
    "text": "this is an externally accessible load balancer so if those termination servers",
    "start": "1297640",
    "end": "1304320"
  },
  {
    "text": "were available you know customers could start connecting right away and we don't want that yet right we need to test this",
    "start": "1304320",
    "end": "1310960"
  },
  {
    "text": "system first now our content routers in green",
    "start": "1310960",
    "end": "1317240"
  },
  {
    "start": "1314000",
    "end": "1343000"
  },
  {
    "text": "are writing to the active topics just like blue right the key differentiator right now is that the processors are",
    "start": "1317240",
    "end": "1324919"
  },
  {
    "text": "reading from an inactive topic or set of topics right and I'll explain exactly what that means but this is one of the",
    "start": "1324919",
    "end": "1331039"
  },
  {
    "text": "most important things in allowing us to do our Canary system right where we're going to push some amount of traffic",
    "start": "1331039",
    "end": "1338600"
  },
  {
    "text": "over into our green processing layer",
    "start": "1338600",
    "end": "1342360"
  },
  {
    "text": "later when we launch the cluster it's really important to get our sizing right so so for any given Auto scale group we",
    "start": "1343679",
    "end": "1351159"
  },
  {
    "text": "start off by setting a minimum and maximum number that we're going to be expecting for that instance right for that for that",
    "start": "1351159",
    "end": "1357320"
  },
  {
    "text": "role we can usually determine that pretty accurately uh even for a new role",
    "start": "1357320",
    "end": "1363559"
  },
  {
    "text": "because we have an idea of how much of our traffic any new role is going to be",
    "start": "1363559",
    "end": "1368880"
  },
  {
    "text": "having to take care of right so we have a way to set a Min and a Max but we also",
    "start": "1368880",
    "end": "1374480"
  },
  {
    "text": "have a script that right when we're ready to deploy will determine what's actually running in the currently active",
    "start": "1374480",
    "end": "1380679"
  },
  {
    "text": "environment so you can imagine a case where you have a Min and a Max of 10 and 20 and you normally just run at 10 right",
    "start": "1380679",
    "end": "1388600"
  },
  {
    "text": "that handles everything but then you have some new load right maybe you have",
    "start": "1388600",
    "end": "1394960"
  },
  {
    "text": "new customers that came online maybe there was some kind of problem and it caused the load so you've scaled up",
    "start": "1394960",
    "end": "1401279"
  },
  {
    "text": "right you're running 16 now so when you go to replace that blue",
    "start": "1401279",
    "end": "1406640"
  },
  {
    "text": "cluster with a new green cluster you want to make sure that you're going to replace it with something that can handle that same load that Blue's been",
    "start": "1406640",
    "end": "1412080"
  },
  {
    "text": "handling so this is a tiny snippet from a much larger script that for any given",
    "start": "1412080",
    "end": "1418240"
  },
  {
    "text": "region we'll pull out the number of instances running for each of our autoscale groups and return that back",
    "start": "1418240",
    "end": "1425679"
  },
  {
    "text": "to this screen from the UI so what this is doing is showing us",
    "start": "1425679",
    "end": "1431279"
  },
  {
    "text": "what we're about to launch and where we're about to launch it and you'll see that some of these",
    "start": "1431279",
    "end": "1436960"
  },
  {
    "text": "boxes are highlighted in red that's a visual indicator to us that we've reached the maximum number of",
    "start": "1436960",
    "end": "1443679"
  },
  {
    "text": "instances for that um autoscale group right that might have occurred because",
    "start": "1443679",
    "end": "1450120"
  },
  {
    "text": "we simply have more customers right we're processing more events uh that might have occurred because there was",
    "start": "1450120",
    "end": "1455840"
  },
  {
    "text": "some bug right and we caused the load oursel and we autoscaled but this is the call out to tell us so that we can",
    "start": "1455840",
    "end": "1462840"
  },
  {
    "text": "determine do we need more instances do we need to raise our maximum so we can scale higher than this cuz right now",
    "start": "1462840",
    "end": "1468440"
  },
  {
    "text": "we're capped out and this is also the place that we have the chance to scale back down right we don't proactively",
    "start": "1468440",
    "end": "1475919"
  },
  {
    "text": "autoscale down um simply because of this requirement that we absolutely cannot",
    "start": "1475919",
    "end": "1482080"
  },
  {
    "text": "lose data and automating that would be a little bit hairy for",
    "start": "1482080",
    "end": "1487840"
  },
  {
    "start": "1488000",
    "end": "1523000"
  },
  {
    "text": "us so to bootstrap our boxes we use a combination of user data and",
    "start": "1489159",
    "end": "1494559"
  },
  {
    "text": "Chef and we do what's commonly called Chef or inside out Chef bootstrapping",
    "start": "1494559",
    "end": "1499760"
  },
  {
    "text": "right that's where our individual instances are going to contact the chef server and through the use of our user",
    "start": "1499760",
    "end": "1506640"
  },
  {
    "text": "data tell it what they want to become uh that's opposed to the outside in where the chef server would have uh knowledge",
    "start": "1506640",
    "end": "1514000"
  },
  {
    "text": "about all of the different instances and tell them what to become and since we didn't feel comfortable running a w get",
    "start": "1514000",
    "end": "1520760"
  },
  {
    "text": "and just piping that to bash right I hope none of you feel comfortable doing that uh we maintain our own custom",
    "start": "1520760",
    "end": "1527399"
  },
  {
    "start": "1523000",
    "end": "1547000"
  },
  {
    "text": "version of the chef and installer through user data we give it information about what version of Chef",
    "start": "1527399",
    "end": "1533440"
  },
  {
    "text": "to install where the chef servers are which role it's going to become and what",
    "start": "1533440",
    "end": "1539600"
  },
  {
    "text": "environment it lives in so we've launched a new cluster we're",
    "start": "1539600",
    "end": "1545600"
  },
  {
    "text": "ready to test right so the first thing we need to do is we need to Canary our test customer",
    "start": "1545600",
    "end": "1551919"
  },
  {
    "start": "1547000",
    "end": "1586000"
  },
  {
    "text": "and on the next slides I'll explain exactly how that works and what it means but it has to be",
    "start": "1551919",
    "end": "1557039"
  },
  {
    "text": "done then our integration test Suite runs by connecting directly to one of our green termination servers remember",
    "start": "1557039",
    "end": "1563919"
  },
  {
    "text": "they're not in any elb so the only traffic that's going to be getting processed right now is via our",
    "start": "1563919",
    "end": "1570720"
  },
  {
    "text": "tests after our tests run and pass we Canary real",
    "start": "1570720",
    "end": "1577240"
  },
  {
    "text": "customers so how do we Canary customers right we can't lose anything how does",
    "start": "1579440",
    "end": "1584880"
  },
  {
    "text": "this work so we make use of Zookeeper right",
    "start": "1584880",
    "end": "1590039"
  },
  {
    "start": "1586000",
    "end": "1702000"
  },
  {
    "text": "here's a screenshot from uh one of Netflix's uh OSS projects exhibitor uh",
    "start": "1590039",
    "end": "1595399"
  },
  {
    "text": "that just gives you a visual of what's going on everything stored in Zookeeper for",
    "start": "1595399",
    "end": "1601279"
  },
  {
    "text": "canaries and since we dog food our own Tech every single time we run a deployment crowd strike are the first",
    "start": "1601279",
    "end": "1608399"
  },
  {
    "text": "people to be testing out the new code now if you remember our inactive",
    "start": "1608399",
    "end": "1614679"
  },
  {
    "text": "processing layer this is the green side right they're set to read from these inactive topics I mentioned right these",
    "start": "1614679",
    "end": "1621720"
  },
  {
    "text": "are just standard Kafka topics right a Kafka topic is just a string except we append on a do inactive to the end of",
    "start": "1621720",
    "end": "1629440"
  },
  {
    "text": "it and our ingestion layer or our content router has a watcher on this Z",
    "start": "1629440",
    "end": "1634960"
  },
  {
    "text": "node right here and every time it gets an update it knows I need to Canary this",
    "start": "1634960",
    "end": "1640640"
  },
  {
    "text": "customer right so all it has to do is start writing that customer's data over to our inactive topic",
    "start": "1640640",
    "end": "1649399"
  },
  {
    "text": "when we're ready to test real traffic we Canary several customers and then we start a monitoring",
    "start": "1649399",
    "end": "1655760"
  },
  {
    "text": "process here's just a more of a visual of what's going on so the invent event",
    "start": "1655760",
    "end": "1662360"
  },
  {
    "text": "in gesture or content router is writing to the active topic blue processors are reading from that active topic this is",
    "start": "1662360",
    "end": "1670000"
  },
  {
    "text": "just regular traffic for Us customer 1 12 3 and customer 456 are",
    "start": "1670000",
    "end": "1676840"
  },
  {
    "text": "canar the venting gesture is notified and starts routing all of their traffic",
    "start": "1676840",
    "end": "1681880"
  },
  {
    "text": "to inactive topics which are picked up by the green processors right so now we have our green processors actually doing",
    "start": "1681880",
    "end": "1688880"
  },
  {
    "text": "some work and of course we have a UI built around this right we don't want to be",
    "start": "1688880",
    "end": "1694399"
  },
  {
    "text": "going and manually changing things even through exhibitor so that's how we do",
    "start": "1694399",
    "end": "1702399"
  },
  {
    "start": "1702000",
    "end": "1767000"
  },
  {
    "text": "it so for testing we run about 3,000 regression and integration tests",
    "start": "1702720",
    "end": "1709919"
  },
  {
    "text": "right if tests fail we just triage figure out if it's something we can move forward with you know even though it's",
    "start": "1709919",
    "end": "1716080"
  },
  {
    "text": "failing and the way we can do that typically would be turning off some new feature right everything that we're",
    "start": "1716080",
    "end": "1721320"
  },
  {
    "text": "doing is put being put behind a feature flag this allows us the ability to determine okay we're going to move",
    "start": "1721320",
    "end": "1728880"
  },
  {
    "text": "forward with the deployment but not with that feature we'll get that feature next time",
    "start": "1728880",
    "end": "1734880"
  },
  {
    "text": "right and we're only done testing and ready to move forward when we're 100%",
    "start": "1734880",
    "end": "1739919"
  },
  {
    "text": "passing right we don't move forward uh with even a single failing test and if we fail tests this is what",
    "start": "1739919",
    "end": "1747799"
  },
  {
    "text": "we see that was before I shaved and that's what we strive to",
    "start": "1747799",
    "end": "1755600"
  },
  {
    "text": "see so we've launched our green cluster right we we've caned some customers we're",
    "start": "1757240",
    "end": "1764120"
  },
  {
    "text": "running our tests everything's passing things are looking good now we're just monitoring right we're just looking at",
    "start": "1764120",
    "end": "1770519"
  },
  {
    "start": "1767000",
    "end": "1801000"
  },
  {
    "text": "everything green is doing we we want to look for problems or the absence of them so we're",
    "start": "1770519",
    "end": "1777640"
  },
  {
    "text": "verifying that Health we're inspecting all of our graphical data our dashboards our log outputs everything we can get",
    "start": "1777640",
    "end": "1784279"
  },
  {
    "text": "our hands on really to verify that and then we're rerunning all of our tests this whole time tests are just running",
    "start": "1784279",
    "end": "1790240"
  },
  {
    "text": "right because now we have load so if our tests happen to pass the first time because we have no load well that's",
    "start": "1790240",
    "end": "1795840"
  },
  {
    "text": "great but now we want to rerun those tests",
    "start": "1795840",
    "end": "1800039"
  },
  {
    "start": "1801000",
    "end": "1882000"
  },
  {
    "text": "tests so just a little bit about logging and error checking so every one of our servers has a Splunk forwarder installed",
    "start": "1801919",
    "end": "1809080"
  },
  {
    "text": "on it and because of the consistency with which we do our logging this the Splunk forwarder can be set up in the",
    "start": "1809080",
    "end": "1815519"
  },
  {
    "text": "exact same way can forward the exact same file to the exact same place so all",
    "start": "1815519",
    "end": "1821039"
  },
  {
    "text": "of our logs are aggregated collected in one place and then we've set up several",
    "start": "1821039",
    "end": "1826240"
  },
  {
    "text": "dashboards right to inspect all of this give us some kind of graphical representation of what exactly is going",
    "start": "1826240",
    "end": "1833200"
  },
  {
    "text": "on and then of course these raw logs are streamed in near real time and we're",
    "start": "1833200",
    "end": "1838640"
  },
  {
    "text": "specifically looking for errors right error type logs um because we are",
    "start": "1838640",
    "end": "1845480"
  },
  {
    "text": "so you know persistent in what we choose to deem as an error we know if we see",
    "start": "1845480",
    "end": "1852360"
  },
  {
    "text": "errors it's bad right we don't just log you know oh I increased my coun by five",
    "start": "1852360",
    "end": "1859080"
  },
  {
    "text": "error right that's an info or a debug or something if it's not catastrophic it's",
    "start": "1859080",
    "end": "1864399"
  },
  {
    "text": "a warn right so we're looking for these errors this is a super important step",
    "start": "1864399",
    "end": "1871440"
  },
  {
    "text": "right we really need to be comfortable knowing that our system is healthy before we move on because now we want to",
    "start": "1871440",
    "end": "1877840"
  },
  {
    "text": "move real traffic over these are just some of the screens",
    "start": "1877840",
    "end": "1884760"
  },
  {
    "start": "1882000",
    "end": "1921000"
  },
  {
    "text": "of some of the dashboards that we set up over time these two on the top are Splunk they happen to be blue green",
    "start": "1884760",
    "end": "1891240"
  },
  {
    "text": "specific um so we have blue green specific dashboards we look for and just general dashboards uh the bottom two are",
    "start": "1891240",
    "end": "1897720"
  },
  {
    "text": "from data dog and the really important thing here is that any one of our",
    "start": "1897720",
    "end": "1903240"
  },
  {
    "text": "Engineers QA testers they because they've all run these deployments right",
    "start": "1903240",
    "end": "1909120"
  },
  {
    "text": "they've all looked at all these screens and they can really quickly look and with you know not more than a glance say",
    "start": "1909120",
    "end": "1917200"
  },
  {
    "text": "whether or not they're looking at a healthy or an unhealthy system so when it's time to move our",
    "start": "1917200",
    "end": "1924159"
  },
  {
    "text": "customers over finally the first thing we need to do is we need to flip everyone back away from",
    "start": "1924159",
    "end": "1930159"
  },
  {
    "text": "being a canary then we're going to activate the green",
    "start": "1930159",
    "end": "1935799"
  },
  {
    "text": "cluster and activating the green cluster is going to make those termination servers available through the elb right",
    "start": "1935799",
    "end": "1942080"
  },
  {
    "text": "so someone who's just turning on their laptop or or happens to bounce the",
    "start": "1942080",
    "end": "1947279"
  },
  {
    "text": "network might end up on our green side and our event processors are consuming",
    "start": "1947279",
    "end": "1952960"
  },
  {
    "text": "from on both sides the active and our event ingestion layer is writing to",
    "start": "1952960",
    "end": "1959519"
  },
  {
    "text": "those active topics right so we're in a state of active active at this",
    "start": "1959519",
    "end": "1965278"
  },
  {
    "start": "1966000",
    "end": "2005000"
  },
  {
    "text": "point and this is just a quick graphic of what a active active does right just breaking out the processing layers",
    "start": "1966080",
    "end": "1972600"
  },
  {
    "text": "so inactive is the green processors blue processors are reading from",
    "start": "1972600",
    "end": "1979120"
  },
  {
    "text": "active we're ready to flip the switch zookeeper tells them to activate they",
    "start": "1979120",
    "end": "1984600"
  },
  {
    "text": "have the Watcher they start processing off the active stream just like blue so this is",
    "start": "1984600",
    "end": "1990600"
  },
  {
    "text": "where it's really important that our code is forward compatible right we're going to be dealing with two different",
    "start": "1990600",
    "end": "1995840"
  },
  {
    "text": "clusters two different code bases different features processing events you",
    "start": "1995840",
    "end": "2001919"
  },
  {
    "text": "know randomly as they get pulled off of the kofka queue but it is important that that the",
    "start": "2001919",
    "end": "2008559"
  },
  {
    "start": "2005000",
    "end": "2035000"
  },
  {
    "text": "blue and green sides are fully partitioned from one another once an event ends up on the blue side it stays",
    "start": "2008559",
    "end": "2014360"
  },
  {
    "text": "on the blue side until the end of its life right until we fully processed it likewise with green so this allows us",
    "start": "2014360",
    "end": "2021159"
  },
  {
    "text": "for doing things like making a breaking API change that's specific to that environment or changing serialization",
    "start": "2021159",
    "end": "2027880"
  },
  {
    "text": "that's going to be used to you know send data between them so we're ready to flip the",
    "start": "2027880",
    "end": "2034880"
  },
  {
    "text": "switch we deactivate blue so that's going to force all of our termination servers in blue to fail health checks",
    "start": "2034880",
    "end": "2042600"
  },
  {
    "start": "2035000",
    "end": "2086000"
  },
  {
    "text": "they're going to disconnect from the elb all of our sensors connected on the blue side are going to get a you know a",
    "start": "2042600",
    "end": "2048599"
  },
  {
    "text": "connection reset they're going to immediately try to reconnect they're going to hit the elb and get routed to",
    "start": "2048599",
    "end": "2054240"
  },
  {
    "text": "the green servers right our blue processors switch now to",
    "start": "2054240",
    "end": "2061800"
  },
  {
    "text": "read from the inactive and then once all of our",
    "start": "2061800",
    "end": "2067079"
  },
  {
    "text": "inactive consumers have caught up to the heads of their streams you know we've processed everything that inactive has",
    "start": "2067079",
    "end": "2074320"
  },
  {
    "text": "we can decommission blue as Jim mentioned earlier we leave it around for you know one two hours maybe in case we",
    "start": "2074320",
    "end": "2081520"
  },
  {
    "text": "need to do that immediate flip back and then it's time to get rid of",
    "start": "2081520",
    "end": "2088320"
  },
  {
    "start": "2086000",
    "end": "2105000"
  },
  {
    "text": "them so green is our active cluster if we need to roll back we always snapshot our repository put it",
    "start": "2088320",
    "end": "2096000"
  },
  {
    "text": "into S3 we haven't had to do that yet but it is very reassuring knowing that we can if we have",
    "start": "2096000",
    "end": "2103640"
  },
  {
    "start": "2105000",
    "end": "2114000"
  },
  {
    "text": "to for the last uh 10 minutes here I just want to go through what we've done",
    "start": "2105760",
    "end": "2110920"
  },
  {
    "text": "to ease the pain of this process so bootstrapping our boxes",
    "start": "2110920",
    "end": "2117240"
  },
  {
    "start": "2114000",
    "end": "2184000"
  },
  {
    "text": "faster right you're replacing an entire uh set of machines when you're doing the full cluster right you want",
    "start": "2117240",
    "end": "2123400"
  },
  {
    "text": "these boxes to come up fast so the first thing we did is we started using Half Baked",
    "start": "2123400",
    "end": "2129280"
  },
  {
    "text": "Amis so if you're not familiar with this idea Amazon has you know several Amis to",
    "start": "2129280",
    "end": "2136599"
  },
  {
    "text": "choose from prean what it allows you to do is pull one of those down start it make updates",
    "start": "2136599",
    "end": "2143800"
  },
  {
    "text": "to it and then package it all back up as a new Ami that has some things done to it right it's not fully ready for",
    "start": "2143800",
    "end": "2150160"
  },
  {
    "text": "production it's not actually running any of our code but it does do things like since we have such a large Scola code",
    "start": "2150160",
    "end": "2156440"
  },
  {
    "text": "base it'll prein install the jvm you know Tomcat so that that's already there because we don't want to have to install",
    "start": "2156440",
    "end": "2162280"
  },
  {
    "text": "that on all of our on all of our Java or you know Scola machines every time we boot",
    "start": "2162280",
    "end": "2167520"
  },
  {
    "text": "up it'll install common tools and configurations and make sure that we",
    "start": "2167520",
    "end": "2172880"
  },
  {
    "text": "have the latest patched upto-date OS right really important especially given all of the recent uh things like heart",
    "start": "2172880",
    "end": "2181000"
  },
  {
    "text": "bleed and our build plan is run twice daily and that build plan looks like",
    "start": "2181000",
    "end": "2186079"
  },
  {
    "start": "2184000",
    "end": "2196000"
  },
  {
    "text": "this our bamboo plan runs and we have several different Amis here's just one example it starts a an",
    "start": "2186079",
    "end": "2193160"
  },
  {
    "text": "autoscale group of size one and that autoscale group works like",
    "start": "2193160",
    "end": "2199280"
  },
  {
    "start": "2196000",
    "end": "2206000"
  },
  {
    "text": "any of them right it communicates with a chef server using user data saying what should I do what cookbook should I",
    "start": "2199280",
    "end": "2205640"
  },
  {
    "text": "run in this case it installs uh an OS patched version installs the jvm and",
    "start": "2205640",
    "end": "2213200"
  },
  {
    "start": "2206000",
    "end": "2219000"
  },
  {
    "text": "using AWS tools repackages itself as an Ami push PES itself up to",
    "start": "2213200",
    "end": "2219200"
  },
  {
    "start": "2219000",
    "end": "2383000"
  },
  {
    "text": "S3 and then becomes available in the autoscale groups so there's one final",
    "start": "2219200",
    "end": "2224839"
  },
  {
    "text": "step that we require and it's manual and we we've chosen for it to be a manual process and that's promoting an Ami to",
    "start": "2224839",
    "end": "2232079"
  },
  {
    "text": "being production ready so that's just going in and changing permissions on that Ami and then it's available for",
    "start": "2232079",
    "end": "2237960"
  },
  {
    "text": "blue and green how we get code ready is also",
    "start": "2237960",
    "end": "2243160"
  },
  {
    "text": "really important to this process for us so when we commit code on on Main in",
    "start": "2243160",
    "end": "2248440"
  },
  {
    "text": "any of our repositories that kicks off bamboo another bamboo",
    "start": "2248440",
    "end": "2254720"
  },
  {
    "text": "plan that plan will build you know if it needs to be compiled it'll compile it",
    "start": "2254720",
    "end": "2260680"
  },
  {
    "text": "it'll package up a Debian push that out to our development repo regenerate the",
    "start": "2260680",
    "end": "2265800"
  },
  {
    "text": "repo call a pretty complex python script that will inspect figure out what code",
    "start": "2265800",
    "end": "2271480"
  },
  {
    "text": "changed what roles that code change affects what IP addresses are running",
    "start": "2271480",
    "end": "2276960"
  },
  {
    "text": "the rol that were affected and then we'll proceed doing a rolling restart in our development cluster it's finalized",
    "start": "2276960",
    "end": "2284319"
  },
  {
    "text": "by running tests and then reporting everything back to you know as far as what happened in our IRC Channel and",
    "start": "2284319",
    "end": "2289520"
  },
  {
    "text": "then via email in production if we cut a release",
    "start": "2289520",
    "end": "2295680"
  },
  {
    "text": "Dash version or a hot fix Dash version branch and push that to",
    "start": "2295680",
    "end": "2301560"
  },
  {
    "text": "origin that also kicks off a bamboo plan the key thing here though is it",
    "start": "2301560",
    "end": "2307560"
  },
  {
    "text": "when once it packages up the Debian it pushes it to two places pushes it to our",
    "start": "2307560",
    "end": "2312800"
  },
  {
    "text": "integ repo and to our production repo so it builds it once and pushes it to both places exact same binary and then",
    "start": "2312800",
    "end": "2320880"
  },
  {
    "text": "through our web UI we choose which packages are going to be going out to our in in integ this time we sync those",
    "start": "2320880",
    "end": "2328760"
  },
  {
    "text": "generate a new repository and launch integ once integ is up we're running",
    "start": "2328760",
    "end": "2334599"
  },
  {
    "text": "tests running tests Non-Stop and we're running load tests as well",
    "start": "2334599",
    "end": "2340040"
  },
  {
    "text": "right just our normal integration Suite but also a a full load test for however",
    "start": "2340040",
    "end": "2345520"
  },
  {
    "text": "long we think is necessary to prove the worthiness of the new code when it's time to launch it out",
    "start": "2345520",
    "end": "2352160"
  },
  {
    "text": "into production because we have the exact same binary copied in both places we can regenerate that exact uh",
    "start": "2352160",
    "end": "2360920"
  },
  {
    "text": "repository available in our production VPC without actually copying the code",
    "start": "2360920",
    "end": "2366359"
  },
  {
    "text": "across right we've already copied it originally so we can be confident that when we launch our",
    "start": "2366359",
    "end": "2371800"
  },
  {
    "text": "production um our production cluster this time that it's going to be running the exact same stuff that we've been",
    "start": "2371800",
    "end": "2378560"
  },
  {
    "text": "testing in integ for the past few days or a week and of course we have a web UI",
    "start": "2378560",
    "end": "2384920"
  },
  {
    "start": "2383000",
    "end": "2404000"
  },
  {
    "text": "built around that too so here we choose different versions of various packages this is",
    "start": "2384920",
    "end": "2391359"
  },
  {
    "text": "actually a really long page for any one of them we can click on it and get some information about what",
    "start": "2391359",
    "end": "2398359"
  },
  {
    "text": "exactly is in that package what dependencies it has",
    "start": "2398359",
    "end": "2403520"
  },
  {
    "text": "Etc We sync that to our integ repo um at this point we can launch",
    "start": "2403520",
    "end": "2409960"
  },
  {
    "start": "2404000",
    "end": "2419000"
  },
  {
    "text": "integ we can shut it back down or we can choose to sync this to what we call our beta staging which is the place right",
    "start": "2409960",
    "end": "2417160"
  },
  {
    "text": "before this goes out to production so we do that generate the",
    "start": "2417160",
    "end": "2422319"
  },
  {
    "start": "2419000",
    "end": "2447000"
  },
  {
    "text": "repo and at this point we can choose whether this is going to be a blue green deployment or it's going to be a hot fix",
    "start": "2422319",
    "end": "2428480"
  },
  {
    "text": "deployment a rolling restart with the blue green we're going to be generating a brand new",
    "start": "2428480",
    "end": "2433880"
  },
  {
    "text": "repository uh with a rolling restart we're going to be doing an atomic swap of the current repository and then",
    "start": "2433880",
    "end": "2441000"
  },
  {
    "text": "allowing Chef to be the one to go through and do a rolling restart of those machines to get the updated",
    "start": "2441000",
    "end": "2447880"
  },
  {
    "start": "2447000",
    "end": "2462000"
  },
  {
    "text": "code the last thing I want to touch on is updating the data plane Jim made some comments um related to this earlier",
    "start": "2447880",
    "end": "2457400"
  },
  {
    "text": "but specifically with you know SQL type um databases we made sure that our",
    "start": "2457400",
    "end": "2464920"
  },
  {
    "start": "2462000",
    "end": "2569000"
  },
  {
    "text": "migration system only supported forward migrations right we have several people",
    "start": "2464920",
    "end": "2471319"
  },
  {
    "text": "on the on the team that have experience doing forward and backward migrations you know for every migration one up",
    "start": "2471319",
    "end": "2478720"
  },
  {
    "text": "there's one down and two up and two down uh it the costs totally outweigh the",
    "start": "2478720",
    "end": "2484000"
  },
  {
    "text": "benefit for us right we're forward only if we need to undo a migration we write a new migration that undo it next",
    "start": "2484000",
    "end": "2492079"
  },
  {
    "text": "time and our code must be forward compatible right if we do IM",
    "start": "2492079",
    "end": "2498400"
  },
  {
    "text": "migration and only realize there's a problem three deploys later the co and we need to you know all of a sudden uh",
    "start": "2498400",
    "end": "2506440"
  },
  {
    "text": "relaunch the code from you know three six weeks ago eight weeks ago we need to",
    "start": "2506440",
    "end": "2512119"
  },
  {
    "text": "be certain that we don't need to do anything destructive to the database so our code always needs need to be able to",
    "start": "2512119",
    "end": "2517839"
  },
  {
    "text": "handle you know unexpected things in our schemas for",
    "start": "2517839",
    "end": "2523319"
  },
  {
    "text": "example and very importantly our database schemas are only modified via migrations this for Dev integ and",
    "start": "2523319",
    "end": "2530960"
  },
  {
    "text": "production people you know nobody even has like credentials to get in the database and do anything to modify",
    "start": "2530960",
    "end": "2537640"
  },
  {
    "text": "tables and then we use an in-house migration Service uh we base it around an open source project a Java project",
    "start": "2537640",
    "end": "2544520"
  },
  {
    "text": "called Flyway which has been pretty solid and we do this mostly because we",
    "start": "2544520",
    "end": "2549559"
  },
  {
    "text": "want to parallelize this process each one of our customers has their own database so we have to apply migrations",
    "start": "2549559",
    "end": "2554960"
  },
  {
    "text": "separately to each one of them so I just want to give some final",
    "start": "2554960",
    "end": "2561960"
  },
  {
    "text": "thoughts so blue green deployments can be done in lots of ways right I already",
    "start": "2561960",
    "end": "2567079"
  },
  {
    "text": "mentioned some in the beginning but we have strict requirements we can't lose those million",
    "start": "2567079",
    "end": "2573319"
  },
  {
    "start": "2569000",
    "end": "2580000"
  },
  {
    "text": "dooll events so that was really the driving force that made this the best solution for",
    "start": "2573319",
    "end": "2579839"
  },
  {
    "text": "us the Automation and tooling it took a long time and it was a lot of work but",
    "start": "2579839",
    "end": "2585480"
  },
  {
    "start": "2580000",
    "end": "2639000"
  },
  {
    "text": "it was done by two people shout out to Dennis um so you know it doesn't matter",
    "start": "2585480",
    "end": "2592200"
  },
  {
    "text": "how big your organization is two people were able to do this and it really",
    "start": "2592200",
    "end": "2597400"
  },
  {
    "text": "started with a whole bunch of manual scripts right some bash scripts and you know some python here and some Ruby",
    "start": "2597400",
    "end": "2604359"
  },
  {
    "text": "there and it was really stitched together with with you know a web UI and then refactored and reworked so anybody",
    "start": "2604359",
    "end": "2612359"
  },
  {
    "text": "can do this uh if if they want to dedicate the time and it has been completely worth it",
    "start": "2612359",
    "end": "2619040"
  },
  {
    "text": "it was a lot of hard work we have a robust repeatable reliable fault",
    "start": "2619040",
    "end": "2624559"
  },
  {
    "text": "tolerant deployment system and it has saved us already and I hope it can save",
    "start": "2624559",
    "end": "2630079"
  },
  {
    "text": "you too thank you [Music]",
    "start": "2630079",
    "end": "2636460"
  },
  {
    "text": "[Applause]",
    "start": "2636460",
    "end": "2641320"
  }
]
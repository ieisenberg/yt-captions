[
  {
    "start": "0",
    "end": "91000"
  },
  {
    "text": "okay folks um we're going to get started now um as people walk in they'll they'll get introduced to the subject matter but",
    "start": "960",
    "end": "7640"
  },
  {
    "text": "I think we've got a quorum today uh my name is Angel pizaro",
    "start": "7640",
    "end": "13120"
  },
  {
    "text": "uh I lead the global initiatives for genomics and Life Sciences uh for Amazon web services as part of the scientific",
    "start": "13120",
    "end": "19520"
  },
  {
    "text": "Computing team it's going to be my pleasure to announce later uh Dr Ben Lang me uh from Johns Hopkins University",
    "start": "19520",
    "end": "26240"
  },
  {
    "text": "is going to be talking about some applications they've built on top of M produce Service as well as ABI no who is",
    "start": "26240",
    "end": "33960"
  },
  {
    "text": "now at OSU or soon to be at OSU yeah ab and uh you guys will be uh discussing",
    "start": "33960",
    "end": "40600"
  },
  {
    "text": "real RNA but for first let's uh let's take uh genomics at scale uh",
    "start": "40600",
    "end": "46840"
  },
  {
    "text": "using AWS for population scale analysis genomics and life science data uh the",
    "start": "46840",
    "end": "52120"
  },
  {
    "text": "agenda for today is I'm going to give an overview of elastic map produce which some of these systems have been built on",
    "start": "52120",
    "end": "58440"
  },
  {
    "text": "we're going to do a review of rail RNA again the algorithm that Johns Hopkins University built on top of uh elastic",
    "start": "58440",
    "end": "65439"
  },
  {
    "text": "map produce and some other um and other infrastructures as well uh and if we",
    "start": "65439",
    "end": "70840"
  },
  {
    "text": "have time we'll look at more EMR systems for Science and why you want to use scalable systems like elastic map",
    "start": "70840",
    "end": "77799"
  },
  {
    "text": "produce uh for science problems uh we will preference a",
    "start": "77799",
    "end": "83280"
  },
  {
    "text": "question and answer session above that last section so let's see where we are in terms of time let me start off",
    "start": "83280",
    "end": "89920"
  },
  {
    "text": "stopwatch there so what are the challenges with in-house infrastructure one it's a fixed cost um often times",
    "start": "89920",
    "end": "98200"
  },
  {
    "start": "91000",
    "end": "176000"
  },
  {
    "text": "when you're looking at analyzing for data at scale you're looking at Capital expenditures and that fixed costs will",
    "start": "98200",
    "end": "104360"
  },
  {
    "text": "need to be advertised over five years or really three years but Academia you take",
    "start": "104360",
    "end": "110119"
  },
  {
    "text": "it five years uh your storage and compute are uh collocated it's always on",
    "start": "110119",
    "end": "116039"
  },
  {
    "text": "um it's not scalable so often times you'll have an infrastructure that is at",
    "start": "116039",
    "end": "123680"
  },
  {
    "text": "a certain capacity uh where you have a maximum problem size that you can solve with",
    "start": "123680",
    "end": "129920"
  },
  {
    "text": "it outages uh I don't know how often or how uh good your operations is but the",
    "start": "129920",
    "end": "137760"
  },
  {
    "text": "outages happen to everybody uh and for a single uh resource within the campus the",
    "start": "137760",
    "end": "145160"
  },
  {
    "text": "outage can impact a very broad community",
    "start": "145160",
    "end": "150360"
  },
  {
    "text": "another uh inhouse infrastructure challenge is production upgrades what does that mean well these systems are in",
    "start": "151200",
    "end": "156720"
  },
  {
    "text": "use almost 247 in order to expand or build upon the system uh you actually",
    "start": "156720",
    "end": "163680"
  },
  {
    "text": "have to do it on the production system often and there's slow deployment Cycles",
    "start": "163680",
    "end": "169319"
  },
  {
    "text": "so how often can you bring in uh more capacity more compute more",
    "start": "169319",
    "end": "177040"
  },
  {
    "start": "176000",
    "end": "211000"
  },
  {
    "text": "storage but really that's especially for Hado systems this came out of an",
    "start": "177040",
    "end": "182640"
  },
  {
    "text": "ecosystem where uh compute and storage grew together they're built out of systems that you just take you know",
    "start": "182640",
    "end": "188840"
  },
  {
    "text": "white labeled systems that had a bunch of disc and you tie these nodes together into a resilient um and scalable",
    "start": "188840",
    "end": "195560"
  },
  {
    "text": "platform but if you wanted to grow the system often times you had to grow the storage along with the",
    "start": "195560",
    "end": "201920"
  },
  {
    "text": "compute often times especially in genomics your your compute requirements vary widely from your",
    "start": "201920",
    "end": "209319"
  },
  {
    "text": "storage requirements and here's a an example of it right so imagine that the uh 100%",
    "start": "209319",
    "end": "216040"
  },
  {
    "start": "211000",
    "end": "311000"
  },
  {
    "text": "line not the 120% but the 100% line uh",
    "start": "216040",
    "end": "221560"
  },
  {
    "text": "here represents your overall capacity and for the most part you have weekly",
    "start": "221560",
    "end": "228920"
  },
  {
    "text": "processing that might happen within this cluster as you know you're doing batch genome sequencing uh at the end of that",
    "start": "228920",
    "end": "235480"
  },
  {
    "text": "you're going to have a set of data that's going to be badge processed you might Spike up for these Peaks and then",
    "start": "235480",
    "end": "241040"
  },
  {
    "text": "you might have some cohort analysis where you have to reprocess the entire data set taking up the complete capacity",
    "start": "241040",
    "end": "247319"
  },
  {
    "text": "of your cluster once or twice a year this actually happened to me right",
    "start": "247319",
    "end": "252840"
  },
  {
    "text": "I mean when we were at uh when I was at the University of Pennsylvania doing",
    "start": "252840",
    "end": "257880"
  },
  {
    "text": "proteomics based research we had our own group cluster and when it was time to",
    "start": "257880",
    "end": "263560"
  },
  {
    "text": "replace that cluster we took a look at the utilization graph and this would have been fantastic for our utilization",
    "start": "263560",
    "end": "269240"
  },
  {
    "text": "graph quite frankly we hovered at 10 to 20% utilization for most of the year",
    "start": "269240",
    "end": "274680"
  },
  {
    "text": "except right before asms and and another uh proteomics conference where we Spike",
    "start": "274680",
    "end": "280000"
  },
  {
    "text": "to 100% uh roughly twice a year uh every year for four years so we decided that",
    "start": "280000",
    "end": "287520"
  },
  {
    "text": "uh with with AWS you can actually bootstrap the compute that you",
    "start": "287520",
    "end": "294000"
  },
  {
    "text": "need at a point in time basis and any of this gray area here it is gray trust me any of this GR area here that's unused",
    "start": "294000",
    "end": "301199"
  },
  {
    "text": "capacity uh we weren't paying for we weren't paying for the electricity we weren't paying for everything but with",
    "start": "301199",
    "end": "306800"
  },
  {
    "text": "with on-prem infrastructure you are paying for that maximal capacity all right so that's the that's",
    "start": "306800",
    "end": "313759"
  },
  {
    "start": "311000",
    "end": "397000"
  },
  {
    "text": "the value proposition of something like EMR it's a managed so what is it it's a managed Hado Eco uh",
    "start": "313759",
    "end": "319680"
  },
  {
    "text": "platform uh it has pre-installed map produce tools these are the open source Tools Apache spark Presto and a few",
    "start": "319680",
    "end": "326479"
  },
  {
    "text": "other general purpose uh Hadoop infrastructure tools preinstall ready to go uh you can launch a cluster within",
    "start": "326479",
    "end": "332880"
  },
  {
    "text": "minutes you have an open source distribution so regular Apache you also have the option to use a commercially",
    "start": "332880",
    "end": "338400"
  },
  {
    "text": "supported map bar Distribution on top of VMR and most importantly you're able to",
    "start": "338400",
    "end": "344520"
  },
  {
    "text": "Leverage The elasticity of the cloud and baked in security features that we offer",
    "start": "344520",
    "end": "349840"
  },
  {
    "text": "with respect to uh utilizing um encrypted data stores in",
    "start": "349840",
    "end": "355199"
  },
  {
    "text": "transit and inflight as well as some simple configuration options that will allow you to secure your infrastructure",
    "start": "355199",
    "end": "360960"
  },
  {
    "text": "very easily finally uh you can pay by the hour right so if you only need to",
    "start": "360960",
    "end": "368000"
  },
  {
    "text": "process something for three hours a night or once a week for a couple of days because your genome sequencing came",
    "start": "368000",
    "end": "373880"
  },
  {
    "text": "off of the instrument at that time or your your your image analysis and is ready to go you can you can choose to",
    "start": "373880",
    "end": "381680"
  },
  {
    "text": "bootstrap your cluster just for the time that you use it uh and in in particular",
    "start": "381680",
    "end": "386720"
  },
  {
    "text": "we have this thing called The Spot Market which um sorry the spot Market which uh I believe",
    "start": "386720",
    "end": "393560"
  },
  {
    "text": "Ben will be talking about a little bit uh that allows you to save even more money so easy to use low cost elastic",
    "start": "393560",
    "end": "401720"
  },
  {
    "start": "397000",
    "end": "452000"
  },
  {
    "text": "reliable secure flexible that's that's the value proposition of elastic map",
    "start": "401720",
    "end": "407319"
  },
  {
    "text": "produce or any of our manag services they grow when you need them to and they they shrink when you",
    "start": "407319",
    "end": "413800"
  },
  {
    "text": "don't in particular the one of the bigger strengths with EMR is the fact that you can de the storage from the",
    "start": "413800",
    "end": "420800"
  },
  {
    "text": "compute because these things are elastic because you can Define I need this many",
    "start": "420800",
    "end": "426199"
  },
  {
    "text": "uh compute cores uh but I only need to work on 10 terabytes of data that means",
    "start": "426199",
    "end": "431240"
  },
  {
    "text": "that you can put in thousands of compute cores accessing the same 10 terabytes of data whereas the on Prem infrastructure",
    "start": "431240",
    "end": "437879"
  },
  {
    "text": "you might need to put in X amounts of storage every time you submit a node so",
    "start": "437879",
    "end": "443000"
  },
  {
    "text": "if you need a 3,000 core cluster usually for hero that means that you put in quite a large storage infrastructure",
    "start": "443000",
    "end": "448840"
  },
  {
    "text": "that goes along with it in order to make the economics of that work in particular we use Amazon S3 as",
    "start": "448840",
    "end": "455599"
  },
  {
    "start": "452000",
    "end": "504000"
  },
  {
    "text": "our uh persistent data store uh with within EMR there's some reasons you want to use Amazon S3 uh first is the price",
    "start": "455599",
    "end": "464120"
  },
  {
    "text": "it's 10 it's three cents per gigabyte per month uh this is based on the US east region prices there's 11 nines of",
    "start": "464120",
    "end": "471560"
  },
  {
    "text": "durability uh that means that it's very resilient data there's three copies of your data the minute that you put it in",
    "start": "471560",
    "end": "477479"
  },
  {
    "text": "there uh we do continuous check summing of data as we move it around the system",
    "start": "477479",
    "end": "483400"
  },
  {
    "text": "there's rich life cycle policies that you can use to say I want this data that's been up here for three months to",
    "start": "483400",
    "end": "489520"
  },
  {
    "text": "be put into an archive tier that's a lot a lot less cost because I know I haven't access it beyond that there's versioning",
    "start": "489520",
    "end": "497360"
  },
  {
    "text": "is distributed by default and in particular it forms the basis of something we call emrfs or EMR file",
    "start": "497360",
    "end": "504360"
  },
  {
    "start": "504000",
    "end": "574000"
  },
  {
    "text": "system so why is S3 good for genomics basically uh since you're",
    "start": "504360",
    "end": "510080"
  },
  {
    "text": "paying uh per gigabyte cost you're actually paying for the storage that",
    "start": "510080",
    "end": "515640"
  },
  {
    "text": "you're actually using at that time so it's not appropriate to do a cost estimate well how much does 100 gigs of",
    "start": "515640",
    "end": "522479"
  },
  {
    "text": "of S3 cost me versus a 100 Gig disc that's the wrong question the right question is how much data do I have over",
    "start": "522479",
    "end": "529560"
  },
  {
    "text": "time and what happens when I provision that data over time in terms of my cost",
    "start": "529560",
    "end": "535279"
  },
  {
    "text": "you pay exactly for what you use you can have object sizes up to terabytes I was",
    "start": "535279",
    "end": "541079"
  },
  {
    "text": "talking with somebody the other day that received a 30 uh 30 ter what no it",
    "start": "541079",
    "end": "547480"
  },
  {
    "text": "wasn't 30 terabytes it was a 30 gigabyte VCF file I mean that's a that's a giant",
    "start": "547480",
    "end": "554279"
  },
  {
    "text": "giant set of genome information uh they couldn't work with it in Excel they couldn't work with it",
    "start": "554279",
    "end": "560000"
  },
  {
    "text": "in a lot of different Frameworks they needed to transform it into into something else it's very high bandwidth it's a",
    "start": "560000",
    "end": "566600"
  },
  {
    "text": "horizontal bandwidth it's durable it's fine green Access Control and a lot of other reasons you want to use S3 for for",
    "start": "566600",
    "end": "572640"
  },
  {
    "text": "genomic data but in particular you want to use S3 within EMR because of emrfs emrfs",
    "start": "572640",
    "end": "580680"
  },
  {
    "start": "574000",
    "end": "628000"
  },
  {
    "text": "allows you to leverage S3 as a file system it streams data directly from Amazon S3 it uses hdfs intermediates in",
    "start": "580680",
    "end": "588720"
  },
  {
    "text": "order to cache data at the proper time and it has better read write performance and error handling than other open-",
    "start": "588720",
    "end": "594320"
  },
  {
    "text": "source components right so within this it's assumed that emrfs",
    "start": "594320",
    "end": "600320"
  },
  {
    "text": "is specific to EMR right it's right there in the name there are open source Alternatives uh that do use S3 as a",
    "start": "600320",
    "end": "607640"
  },
  {
    "text": "backing hdfs file system we've done a lot of work with the mrfs to make sure it works with our infrastructure uh",
    "start": "607640",
    "end": "614240"
  },
  {
    "text": "resiliently and performant it has a consistent view which means that when you read something",
    "start": "614240",
    "end": "620160"
  },
  {
    "text": "if you want to write uh you can Define that this thing will be there when I do request it and it has support for",
    "start": "620160",
    "end": "626320"
  },
  {
    "text": "encryption and fast listing of objects so what does it mean to actually use uh",
    "start": "626320",
    "end": "632079"
  },
  {
    "start": "628000",
    "end": "690000"
  },
  {
    "text": "uh emrfs in practice so here's a um I believe this is a hive query at the bottom here you'll notice",
    "start": "632079",
    "end": "638880"
  },
  {
    "text": "it's a location of some hdfs endpoint which is samples Pig apoi uh Apache uh",
    "start": "638880",
    "end": "645560"
  },
  {
    "text": "input uh you want to create an external table from this data source with emrfs",
    "start": "645560",
    "end": "651639"
  },
  {
    "text": "that's the change you need to make which is really pretty powerful right so now you have all of your data",
    "start": "651639",
    "end": "658800"
  },
  {
    "text": "Within three you don't have the hdfs uh uh backing store that that you normally",
    "start": "658800",
    "end": "664200"
  },
  {
    "text": "would have had and you've successfully decoupled your storage from from your computer there's still some amount of",
    "start": "664200",
    "end": "670120"
  },
  {
    "text": "hdfs storage that we recommend a scratch space to read in uh data in and out and do random read operations but for the",
    "start": "670120",
    "end": "677399"
  },
  {
    "text": "most part a lot of your data isn't being used utilized all at the same time you can create that HFS uh resilient storage",
    "start": "677399",
    "end": "686360"
  },
  {
    "text": "uh to meet your exact demands for the job so with the mrfs and the mrr you're able",
    "start": "686360",
    "end": "693279"
  },
  {
    "text": "to build transient clusters that you can bootstrap up and down and you can take that same data and shift it into other",
    "start": "693279",
    "end": "700800"
  },
  {
    "text": "Solutions whether these are uh traditional HPC clusters that are running on top of S3 other EMR clusters",
    "start": "700800",
    "end": "707440"
  },
  {
    "text": "that are using the same data data going into our uh red shift open data warehouse",
    "start": "707440",
    "end": "713120"
  },
  {
    "text": "uh and whatnot as well as other types of algorithms like machine learning uh running R C3 zp instances all right so",
    "start": "713120",
    "end": "721279"
  },
  {
    "start": "720000",
    "end": "769000"
  },
  {
    "text": "at this point that's the background you need to understand what the motivation was to adopt a uh EMR for building",
    "start": "721279",
    "end": "728560"
  },
  {
    "text": "science tools and I'd like to uh bring up to this stage Ben",
    "start": "728560",
    "end": "733959"
  },
  {
    "text": "langi great thank you um so my name is Ben Lang me I'm an assistant professor of computer science at Johns Hopkins um",
    "start": "737279",
    "end": "744959"
  },
  {
    "text": "I've been using uh Amazon web services for quite some time since around 8 uh",
    "start": "744959",
    "end": "750760"
  },
  {
    "text": "and uh I'll say a few words about what it is we do in my lab why Amazon web services is a good fit and some broad",
    "start": "750760",
    "end": "757720"
  },
  {
    "text": "Strokes information about what Amazon Services we use and for what and then I'm going to hand it off to Abby noore",
    "start": "757720",
    "end": "763720"
  },
  {
    "text": "um who knows a lot more than I do about the particulars of H use AWS um so if you read the newspaper",
    "start": "763720",
    "end": "771600"
  },
  {
    "start": "769000",
    "end": "848000"
  },
  {
    "text": "you're prob uh the popular press you're probably aware of uh some recent uh huge",
    "start": "771600",
    "end": "778639"
  },
  {
    "text": "breakthroughs in DNA sequencing so DNA sequencing is something that we sort of take for granted these days but as",
    "start": "778639",
    "end": "784600"
  },
  {
    "text": "recently as the Human Genome Project it was something that not a lot of people really knew a lot about these days DNA",
    "start": "784600",
    "end": "789680"
  },
  {
    "text": "sequencers are incredibly fast uh they're incredibly cheap um the rate the",
    "start": "789680",
    "end": "795240"
  },
  {
    "text": "sort of number of uh bases of AC's G's and T's that you can read per dollar",
    "start": "795240",
    "end": "800360"
  },
  {
    "text": "using a sequencing machine has been going up very very quickly faster than Mo's law uh the sequencers themselves",
    "start": "800360",
    "end": "806720"
  },
  {
    "text": "have got smaller and more convenient to use they're about the size of a mini fridge you can fit a bunch you can fit a",
    "start": "806720",
    "end": "812279"
  },
  {
    "text": "bunch of them in a Laboratory um and with these advances uh lots more people",
    "start": "812279",
    "end": "818560"
  },
  {
    "text": "have been using them they've been they've become kind of the go-to tool for analyzing any phenomenon that has to",
    "start": "818560",
    "end": "824480"
  },
  {
    "text": "do with nucleic acids like DNA or RNA and we'll mostly actually be talking about RNA today and so with DNA",
    "start": "824480",
    "end": "831279"
  },
  {
    "text": "sequencers making their way into so many Labs uh it's this uh it's become kind of a a leveler it's become much easier for",
    "start": "831279",
    "end": "838440"
  },
  {
    "text": "people to obtain large amounts of life science data uh even small Laboratories",
    "start": "838440",
    "end": "844600"
  },
  {
    "text": "uh you know Laboratories that look a little bit less like this laboratory which is a big one a little bit more like this which is a not so big",
    "start": "844600",
    "end": "850639"
  },
  {
    "text": "laboratory so I I come from John's Hopkins we're sort of a loose Confederation of small Laboratories we're not really a a single big lab kind",
    "start": "850639",
    "end": "857880"
  },
  {
    "text": "of a place um so while these advances in technology have made it have sort of",
    "start": "857880",
    "end": "863839"
  },
  {
    "text": "created the potential for everybody to share in this sequencing Revolution one of the biggest barriers is uh",
    "start": "863839",
    "end": "870480"
  },
  {
    "text": "computation just the availability of appropriate computational resources and computational Savvy because not every uh",
    "start": "870480",
    "end": "877800"
  },
  {
    "text": "biology lab is really able to employ the sorts of people who would be needed to take advantage of any kind of",
    "start": "877800",
    "end": "883959"
  },
  {
    "text": "computational resources let Al Cloud resources so one of the things that we try to do is to try to make it very very",
    "start": "883959",
    "end": "889600"
  },
  {
    "text": "very easy for life scientists who aren't necessarily very computationally well resourced or or or Savvy uh to make use",
    "start": "889600",
    "end": "897440"
  },
  {
    "text": "of sequencing data and in particular particular so if the if the invention of these uh new uh DNA sequencers is kind",
    "start": "897440",
    "end": "904600"
  },
  {
    "text": "of like the printing press or something like that um all of this data is going",
    "start": "904600",
    "end": "910600"
  },
  {
    "start": "908000",
    "end": "1045000"
  },
  {
    "text": "into um a big big Library um so there's a uh an archive at uh in Bethesda the",
    "start": "910600",
    "end": "917839"
  },
  {
    "text": "National Institutes of Health at the ncbi called the sequence read archive which is where a lot of uh researchers",
    "start": "917839",
    "end": "924839"
  },
  {
    "text": "who publish genomic studies are uh sort of compelled to upload all of their raw data so that it's available to other",
    "start": "924839",
    "end": "931240"
  },
  {
    "text": "people um this is all taxpayer funded so we want it to be available we want other people to be able to reproduce those",
    "start": "931240",
    "end": "936959"
  },
  {
    "text": "results or come to New conclusions using that existing data so we now have this huge huge huge resource it's many uh PAB",
    "start": "936959",
    "end": "944040"
  },
  {
    "text": "bases so you know paa AC's G's and T's worth of data stored in this resource",
    "start": "944040",
    "end": "950440"
  },
  {
    "text": "and this is very very very valuable data so even though sequencing itself is you know you could say it's cheap some of",
    "start": "950440",
    "end": "957360"
  },
  {
    "text": "this data uh comes at a very High sort of opportunity cost so some of it is derived for example from people who have",
    "start": "957360",
    "end": "962959"
  },
  {
    "text": "rare diseases or it's uh some sort of hard to obtain tissue some of it is",
    "start": "962959",
    "end": "968560"
  },
  {
    "text": "multiple tissues from the same individual these are just just not the sorts of data sets that most people can get their hands on so a lot of it is",
    "start": "968560",
    "end": "974720"
  },
  {
    "text": "very very valuable and it's publicly available some of it um so this is this",
    "start": "974720",
    "end": "980360"
  },
  {
    "text": "is pretty hard to read but this vertical scale here is basically the number of bases in the archive but it's on a log",
    "start": "980360",
    "end": "987079"
  },
  {
    "text": "scale and the horizontal SC uh axis here is just calendar year and one thing that",
    "start": "987079",
    "end": "992600"
  },
  {
    "text": "you might you can't really tell from the graph but just in the last 18 months or so it has doubled so the doubling time",
    "start": "992600",
    "end": "998519"
  },
  {
    "text": "for this archive is about a year and a half and there's two lines here there's a very light yellow line that you",
    "start": "998519",
    "end": "1003920"
  },
  {
    "text": "probably can't see and then there's a blue line and the difference between these two lines these days is about",
    "start": "1003920",
    "end": "1009120"
  },
  {
    "text": "twofold so this is about a twofold difference you can't tell because it's a log scale and the yellow line is the",
    "start": "1009120",
    "end": "1015079"
  },
  {
    "text": "number of bases that are open access anybody can download them today and the other one is bases uh total bases which",
    "start": "1015079",
    "end": "1022120"
  },
  {
    "text": "includes protected bases so we're going to talk a little bit today about how you analyze data that's protected because",
    "start": "1022120",
    "end": "1027520"
  },
  {
    "text": "it's derived from living human patients for whom the data is you're only consented to work with the data in",
    "start": "1027520",
    "end": "1033839"
  },
  {
    "text": "certain ways so that data is actually protected by certain security measures but we'll talk today a little bit about",
    "start": "1033839",
    "end": "1039400"
  },
  {
    "text": "how you can still analyze it in AWS even with those security measures",
    "start": "1039400",
    "end": "1045520"
  },
  {
    "start": "1045000",
    "end": "1166000"
  },
  {
    "text": "so I've been working on um trying to analyze data like this in Amazon web services like I said before since about",
    "start": "1045520",
    "end": "1052120"
  },
  {
    "text": "2008 so that that was before I think it was before the Advent of elastic map Ru",
    "start": "1052120",
    "end": "1057320"
  },
  {
    "text": "I certainly wasn't using it back then back then firing up an ec2 cluster was you know there's sort of like a",
    "start": "1057320",
    "end": "1063039"
  },
  {
    "text": "cumbersome pile of bash scripts and and that's how you did it um then elastic map reduce came along and that's when",
    "start": "1063039",
    "end": "1069440"
  },
  {
    "text": "things I think from a biological user perspective really started to get good",
    "start": "1069440",
    "end": "1074600"
  },
  {
    "text": "because it meant that you you could potentially start to fire off huge analyses of genomic data using just one",
    "start": "1074600",
    "end": "1080799"
  },
  {
    "text": "or two commands on the command line and a little bit later Obby will show you that you really can do two commands and",
    "start": "1080799",
    "end": "1087240"
  },
  {
    "text": "analyze a huge genomic data set on elastic map Ru it's kind of like the command line as far as we're concerned",
    "start": "1087240",
    "end": "1093120"
  },
  {
    "text": "for using Amazon web services um we use several uh services",
    "start": "1093120",
    "end": "1098520"
  },
  {
    "text": "from AWS including including ec2 and spot as I just mentioned or ec2 and EMR",
    "start": "1098520",
    "end": "1104559"
  },
  {
    "text": "uh but also we use the spot Marketplace as Angel mentioned this is a good way to get lots of computational resources on",
    "start": "1104559",
    "end": "1110720"
  },
  {
    "text": "AWS for cheap because on the spot Marketplace you're bidding on excess capacity and so the price is a",
    "start": "1110720",
    "end": "1118080"
  },
  {
    "text": "fluctuating market price that usually is substantially lower than the on demand price something like maybe five to eight",
    "start": "1118080",
    "end": "1124520"
  },
  {
    "text": "fold lower or something like that so you can get your hands on lots of capacity all at once as long as you don't mind",
    "start": "1124520",
    "end": "1130880"
  },
  {
    "text": "the potential you know the potentiality that if the market price goes above your bid you might lose those resources",
    "start": "1130880",
    "end": "1136320"
  },
  {
    "text": "partway through your computation but often that's something that you can tolerate and in this in this application",
    "start": "1136320",
    "end": "1141960"
  },
  {
    "text": "it's something we can tolerate so we use spot extensively uh and we use Amazon",
    "start": "1141960",
    "end": "1147559"
  },
  {
    "text": "VPC and cloud formation as part of our architecture for being able to analyze protected data uh the uh privacy",
    "start": "1147559",
    "end": "1155039"
  },
  {
    "text": "standard is called dbgap so in order to implement our dbgap uh compliant uh data",
    "start": "1155039",
    "end": "1160480"
  },
  {
    "text": "analysis we use these two Services uh as obia will'll talk about a little bit more later this is part of a sort of",
    "start": "1160480",
    "end": "1166840"
  },
  {
    "start": "1166000",
    "end": "1190000"
  },
  {
    "text": "history of work that we've done in our lab for analyzing genomics data on AWS stretching all the way back to this",
    "start": "1166840",
    "end": "1172799"
  },
  {
    "text": "paper that we published in 2009 that was not using elastic map ruce but then these three papers which all have to do",
    "start": "1172799",
    "end": "1178919"
  },
  {
    "text": "with analysis of RNA sequencing data those all use elastic map produce our most recent effort which Obi will talk",
    "start": "1178919",
    "end": "1185240"
  },
  {
    "text": "about today is the last one listed here uh rail RNA so I think that might be yeah so",
    "start": "1185240",
    "end": "1191440"
  },
  {
    "start": "1190000",
    "end": "1346000"
  },
  {
    "text": "with that let me hand it over to Abby noore he's going to talk more about the particulars of rail RNA and how it uses",
    "start": "1191440",
    "end": "1197400"
  },
  {
    "text": "AWS services",
    "start": "1197400",
    "end": "1200640"
  },
  {
    "text": "great okay yeah so I'm up and I'm currently a post do at Hopkins between Ben's lab and also Jeff leak's lab and",
    "start": "1204720",
    "end": "1211799"
  },
  {
    "text": "yeah I will be at OSU in the fall as an assistant professor um I'm going to be",
    "start": "1211799",
    "end": "1216840"
  },
  {
    "text": "telling you a bit about the technical details of rail RNA um when we started developing rail RNA about two uh two",
    "start": "1216840",
    "end": "1223480"
  },
  {
    "text": "years ago the most widely used splice alignment software was top at 2 it probably still is",
    "start": "1223480",
    "end": "1229360"
  },
  {
    "text": "and uh top at 2 was designed to run on a single sample at a time um it uh had was",
    "start": "1229360",
    "end": "1236840"
  },
  {
    "text": "composed of it is composed of a few steps that are pretty long and don't take full advantage of available compute",
    "start": "1236840",
    "end": "1243200"
  },
  {
    "text": "run on a single core and that's fine for its purposes but we really wanted software that scaled to analyze many",
    "start": "1243200",
    "end": "1249799"
  },
  {
    "text": "thousands of samples so um we fit the spliced alignment problem which is what",
    "start": "1249799",
    "end": "1255400"
  },
  {
    "text": "rail solves it analyzes lots of RNA sequencing samples which necessitates spliced alignment uh we fit this spliced",
    "start": "1255400",
    "end": "1262120"
  },
  {
    "text": "alignment problem into uh uh the map reduce framework um as implemented in",
    "start": "1262120",
    "end": "1268720"
  },
  {
    "text": "Hadoop and this allows us to analyze thousands of samples on tens of thousands of processing cores um in a",
    "start": "1268720",
    "end": "1276640"
  },
  {
    "text": "way that's fault tolerant and reproducible and it's especially reproducible if you use elastic map ruce",
    "start": "1276640",
    "end": "1282720"
  },
  {
    "text": "because you're running the same software on the same standardized units of Hardware the same on on ec2 instances uh",
    "start": "1282720",
    "end": "1290760"
  },
  {
    "text": "Hadoop also allows us to aggregate information easily aggregate information collected from across many samples so",
    "start": "1290760",
    "end": "1298520"
  },
  {
    "text": "for instance we can juxtapose in our outputs the uh samples in which we find",
    "start": "1298520",
    "end": "1304480"
  },
  {
    "text": "the same feature so for example we let's say we have some threshold for genome",
    "start": "1304480",
    "end": "1309919"
  },
  {
    "text": "coverage above which we say a Gene's expressed in a sample what we can do is",
    "start": "1309919",
    "end": "1315200"
  },
  {
    "text": "make a coverage an interval based query on a junction a sparse Junction by",
    "start": "1315200",
    "end": "1321679"
  },
  {
    "text": "sample Matrix very rapidly obtain um the samples in which a gene is expressed",
    "start": "1321679",
    "end": "1327360"
  },
  {
    "text": "simply because of the way the data is arranged and that's made possible by you know this sort of that that's made very",
    "start": "1327360",
    "end": "1333520"
  },
  {
    "text": "efficient by using Hadoop so um this is just a depiction of several steps of the",
    "start": "1333520",
    "end": "1340440"
  },
  {
    "text": "pipeline we wrap bowai which is alignment software that was developed by um",
    "start": "1340440",
    "end": "1345919"
  },
  {
    "text": "Ben and we engineered rail so it's really easy to use like Ben mentioned we",
    "start": "1345919",
    "end": "1351480"
  },
  {
    "start": "1346000",
    "end": "1405000"
  },
  {
    "text": "said in one to two commands you go from um you a list of the URLs that have that",
    "start": "1351480",
    "end": "1359760"
  },
  {
    "text": "that point to the raw data two results the results will be stored on S3 so here in this command you'll see that there's",
    "start": "1359760",
    "end": "1365760"
  },
  {
    "text": "a manifest file that's listing the URLs of the raw data you specify uh a species",
    "start": "1365760",
    "end": "1371880"
  },
  {
    "text": "to which you align your data this is hc38 so it's an assembly of the human genome in this case you specify output",
    "start": "1371880",
    "end": "1379039"
  },
  {
    "text": "bucket on S3 and you also specify the size of your ec2 cluster your elastic map reduce cluster um and the that's the",
    "start": "1379039",
    "end": "1387440"
  },
  {
    "text": "core instance count and the kinds of instances the instance types um that are in your cluster so you know it's as easy",
    "start": "1387440",
    "end": "1393960"
  },
  {
    "text": "as one two S3 yeah that's the only joke in my part",
    "start": "1393960",
    "end": "1399640"
  },
  {
    "text": "of the talk it's not even really funny okay so here this is just an",
    "start": "1399640",
    "end": "1407520"
  },
  {
    "start": "1405000",
    "end": "1433000"
  },
  {
    "text": "example of a set of job flows that we are running um and you can just see",
    "start": "1407520",
    "end": "1412840"
  },
  {
    "text": "they're like there should be dollar signs all over this when you look at this because there's so many different job flows that are running here we um",
    "start": "1412840",
    "end": "1419840"
  },
  {
    "text": "this is actually from an analysis of 50,000 publicly available human RNA sequencing samples that are available on",
    "start": "1419840",
    "end": "1426520"
  },
  {
    "text": "the sequence read archive We performed it in February and um this was all available human RNA seek samples um so",
    "start": "1426520",
    "end": "1434679"
  },
  {
    "start": "1433000",
    "end": "1572000"
  },
  {
    "text": "yeah 50,000 it's about 100 terab bases um so uh we have a paper on this it's",
    "start": "1434679",
    "end": "1441080"
  },
  {
    "text": "called human splicing diversity across the sequence read archive you can read it on bioarchive and we did all of our",
    "start": "1441080",
    "end": "1447200"
  },
  {
    "text": "analysis for this on elastic map reduce um it's repeatable you just visit this",
    "start": "1447200",
    "end": "1453360"
  },
  {
    "text": "GitHub repo and you can see the commands that will reproduce our results same software on the same Hardware it's also",
    "start": "1453360",
    "end": "1459600"
  },
  {
    "text": "relatively an expensive job for us coming in at about a buck 40 per sample and um you know if you compare to",
    "start": "1459600",
    "end": "1466080"
  },
  {
    "text": "sequencing cost I think it can cost 20 $440 per sample for sequencing so",
    "start": "1466080",
    "end": "1471960"
  },
  {
    "text": "compared to that the analysis portion you perform it in the cloud is pretty inexpensive in order of magnitude less",
    "start": "1471960",
    "end": "1479120"
  },
  {
    "text": "expensive um it's also a a very rapid job we went from input for results in",
    "start": "1479120",
    "end": "1484919"
  },
  {
    "text": "about two weeks just you know constantly submitting these these job flows we successfully submitted them the reason",
    "start": "1484919",
    "end": "1490399"
  },
  {
    "text": "it took two weeks and not say a day because remember we can reserve as much computer as we want on EMR EMR is that",
    "start": "1490399",
    "end": "1497559"
  },
  {
    "text": "um it you you can only download the raw data so fast from ncbi um and so this is",
    "start": "1497559",
    "end": "1506799"
  },
  {
    "text": "this was like our rate limiting factor in in in running our jobs right now but",
    "start": "1506799",
    "end": "1512159"
  },
  {
    "text": "for example um if the job if if all the data were hosted on S3 we could just finish we could finish these job flows",
    "start": "1512159",
    "end": "1519120"
  },
  {
    "text": "in a day and that's actually now happening with the the cancer genome at with tcga um through a partnership with",
    "start": "1519120",
    "end": "1525919"
  },
  {
    "text": "Seven Bridges tcga RNA SE ing data is now hosted on S3 and through Seven",
    "start": "1525919",
    "end": "1531600"
  },
  {
    "text": "Bridges API you can now access those um uh you can now access those samples the",
    "start": "1531600",
    "end": "1536640"
  },
  {
    "text": "raw data for those samples on S3 and get temporary URLs to access them we're building uh we're actually building",
    "start": "1536640",
    "end": "1542760"
  },
  {
    "text": "support for the um Seven Bridges API into rail RNA right now and hopefully in",
    "start": "1542760",
    "end": "1547799"
  },
  {
    "text": "just a few months well probably just a couple of months we'll be able to make some impactful statements about the speed with which you can reanalyze",
    "start": "1547799",
    "end": "1554399"
  },
  {
    "text": "publicly available data that's hosted on a service like S3 hopefully you know",
    "start": "1554399",
    "end": "1559679"
  },
  {
    "text": "making statements like this will encourage adoption of commercial Cloud providers especially Amazon for um",
    "start": "1559679",
    "end": "1566279"
  },
  {
    "text": "hosting um hosting raw data and processed data um so speaking of tcga tcga is DB",
    "start": "1566279",
    "end": "1575200"
  },
  {
    "text": "Gap protected which means that the NIH mandates certain security pro um certain",
    "start": "1575200",
    "end": "1581640"
  },
  {
    "text": "security certain security requirements for analyzing it it's controlled Access Data uh and it's control access to",
    "start": "1581640",
    "end": "1588960"
  },
  {
    "text": "protect the privacy of research subjects espe this is especially important for",
    "start": "1588960",
    "end": "1594520"
  },
  {
    "text": "you know sensitive phenotypes like disease which can be associated with a subject's identity so we built support",
    "start": "1594520",
    "end": "1601760"
  },
  {
    "text": "for analyzing dbgap protected data in the cloud with Amazon elastic maper into",
    "start": "1601760",
    "end": "1606880"
  },
  {
    "text": "rail RNA and you can uh do it yourself you pick your favorite dbgap protected",
    "start": "1606880",
    "end": "1612120"
  },
  {
    "text": "data set and you can visit docs. rail. bio dbgap to figure out how to get up",
    "start": "1612120",
    "end": "1617320"
  },
  {
    "text": "and running with rail RNA uh to analyze the data um uh the way we do this and the",
    "start": "1617320",
    "end": "1624960"
  },
  {
    "start": "1623000",
    "end": "1708000"
  },
  {
    "text": "way this worked was that nah started allowing people I think uh almost two years ago now uh to analyze dbgap",
    "start": "1624960",
    "end": "1632320"
  },
  {
    "text": "protected data in their Cloud as long as they they released this paper that had certain requirements and um Amazon",
    "start": "1632320",
    "end": "1638320"
  },
  {
    "text": "followed up with a white paper co-authored by Angel actually that uh specifies the am particular Amazon web",
    "start": "1638320",
    "end": "1645559"
  },
  {
    "text": "services that uh allow you to to adhere to those requirements so um we took that",
    "start": "1645559",
    "end": "1651799"
  },
  {
    "text": "white paper and we implemented it in Rail and this is a protocol we call rail DB Gap and it start we always launch our",
    "start": "1651799",
    "end": "1660919"
  },
  {
    "text": "um our job flows into a virtual private Cloud a VPC uh we ensure that data is encrypted",
    "start": "1660919",
    "end": "1667679"
  },
  {
    "text": "at rest and in transit between the cluster the EMR cluster and S3 on S3 we",
    "start": "1667679",
    "end": "1673799"
  },
  {
    "text": "turn on ssse server side encryption uh and the cluster we Ure that the ephemeral space is encrypted with Lux",
    "start": "1673799",
    "end": "1680320"
  },
  {
    "text": "Linux unified key setup and between cluster and S3 we turn on SSL um so",
    "start": "1680320",
    "end": "1687320"
  },
  {
    "text": "there there you have it end to end encryption we also use uh security groups stateful firewall to block",
    "start": "1687320",
    "end": "1693720"
  },
  {
    "text": "inbound access to the cluster uh by all um Services except EMR essential web",
    "start": "1693720",
    "end": "1700120"
  },
  {
    "text": "services and we also use cloud trail we turn on cloud trail to log account access and actions as required by NIH",
    "start": "1700120",
    "end": "1708720"
  },
  {
    "start": "1708000",
    "end": "1764000"
  },
  {
    "text": "um and we make this easy for users to do I mean users this this can this all this",
    "start": "1708720",
    "end": "1714760"
  },
  {
    "text": "stuff here on the previous slide can remain opaque to users because we put it all in a cloud formation template and so",
    "start": "1714760",
    "end": "1722600"
  },
  {
    "text": "a user need only create uh a stack from this template and this stack will set up",
    "start": "1722600",
    "end": "1729440"
  },
  {
    "text": "a secure S3 bucket with SSC turned on set up the necess necessary security groups the user just needs only needs to",
    "start": "1729440",
    "end": "1737240"
  },
  {
    "text": "know what the name of the stack is and then the user just specifies the stack name at the command line in that rail",
    "start": "1737240",
    "end": "1743120"
  },
  {
    "text": "RNA command submits the job flow and doesn't really need to be aware of uh",
    "start": "1743120",
    "end": "1748279"
  },
  {
    "text": "that that they're compliant but they are which is great um so we're trying to",
    "start": "1748279",
    "end": "1753320"
  },
  {
    "text": "make this product pretty usable so people people can um skip a lot of the technical details and we we hope we've",
    "start": "1753320",
    "end": "1760320"
  },
  {
    "text": "um we've U uh uh done that so yeah again",
    "start": "1760320",
    "end": "1765960"
  },
  {
    "start": "1764000",
    "end": "1772000"
  },
  {
    "text": "docs. rail. dbgap to get up and running with the um DB gap on EMR and um these",
    "start": "1765960",
    "end": "1773960"
  },
  {
    "text": "are three papers that uh that I touched on um in my part of this talk rail RNA",
    "start": "1773960",
    "end": "1780240"
  },
  {
    "text": "HTTP rail. bio you can uh read our rail DB Gap paper which was now published in",
    "start": "1780240",
    "end": "1785960"
  },
  {
    "text": "accepted and published in BIO informatics and human splicing diversity across the sequence archive is our",
    "start": "1785960",
    "end": "1791240"
  },
  {
    "text": "analysis of splicing across the 50,000 samples we analyzed in February you can uh find a link to the paper at inop ra.",
    "start": "1791240",
    "end": "1798519"
  },
  {
    "text": "bio thanks a lot I'm gonna hand it back to Angel [Applause]",
    "start": "1798519",
    "end": "1808079"
  },
  {
    "text": "now thanks that was great guys um we've got about 15 minutes left so I think I'll just cover the last section of talk",
    "start": "1808279",
    "end": "1814840"
  },
  {
    "text": "real quickly uh because I think the the motivation is an important one to get",
    "start": "1814840",
    "end": "1820279"
  },
  {
    "start": "1820000",
    "end": "1878000"
  },
  {
    "text": "across oh look at this you guys forgot to acknowledge your lab",
    "start": "1820279",
    "end": "1825440"
  },
  {
    "text": "oh oh okay I don't know most of the people but this guy right here don't don't trust this guy don't trust that",
    "start": "1825440",
    "end": "1833760"
  },
  {
    "text": "guy all right oh yeah that's true um uh we did support so there is a credits for",
    "start": "1833760",
    "end": "1839640"
  },
  {
    "text": "research program by the way if you guys have some idea that you want to try out",
    "start": "1839640",
    "end": "1846159"
  },
  {
    "text": "on AWS in a low a lowrisk lowcost way uh it's it's just a web form you describe",
    "start": "1846159",
    "end": "1852399"
  },
  {
    "text": "what you want to do we have folks uh contact you and talk about it and say okay well this is your research problem",
    "start": "1852399",
    "end": "1858120"
  },
  {
    "text": "that you want to try and solve we think that this architecture is probably the best one for it uh we're more than happy",
    "start": "1858120",
    "end": "1863840"
  },
  {
    "text": "to work with you so uh just go to our website SLG grants and you'll see the the credits for research program which",
    "start": "1863840",
    "end": "1870080"
  },
  {
    "text": "can help you also do your research and and try these types of infrastructures out in a lowrisk",
    "start": "1870080",
    "end": "1875559"
  },
  {
    "text": "way uh so these guys do great work okay so why is horizontal scale important why",
    "start": "1875559",
    "end": "1881279"
  },
  {
    "start": "1878000",
    "end": "1887000"
  },
  {
    "text": "is it important for genomics or why is it important at all uh it's not just about chunking through data um uh I'll",
    "start": "1881279",
    "end": "1888760"
  },
  {
    "start": "1887000",
    "end": "1941000"
  },
  {
    "text": "remind folks that um this is essentially what happens with genomics that you have some alignment step some D duplication",
    "start": "1888760",
    "end": "1895080"
  },
  {
    "text": "step where and recalibration filtering QC and filtering variant calling variant annotation right so this is sort of the",
    "start": "1895080",
    "end": "1901559"
  },
  {
    "text": "golden path of human DNA sequence analysis this is the DNA part not the RNA part but they follow a similar",
    "start": "1901559",
    "end": "1908760"
  },
  {
    "text": "routine where they do alignment calibration and and downstream analysis",
    "start": "1908760",
    "end": "1914080"
  },
  {
    "text": "this in particular is the gatk best practices so the stages are written",
    "start": "1914080",
    "end": "1919279"
  },
  {
    "text": "separately there's a hand up off in between each one of these stages is usually some flat file that gets stream",
    "start": "1919279",
    "end": "1926120"
  },
  {
    "text": "processed and fed into the next uh version so you could actually do all of this within uh memory and Unix process",
    "start": "1926120",
    "end": "1932760"
  },
  {
    "text": "uh pipes but most people just write out the files and everybody has their own flavor of this pipeline so there's a",
    "start": "1932760",
    "end": "1940159"
  },
  {
    "text": "need for integration but paralyzation either in the cloud or HPC systems tends",
    "start": "1940159",
    "end": "1945799"
  },
  {
    "start": "1941000",
    "end": "2019000"
  },
  {
    "text": "to want to be like this where you take one sample and and process it through the nodes like you know like or a server",
    "start": "1945799",
    "end": "1952159"
  },
  {
    "text": "or an instance uh and just have a a completely disconnected um uh",
    "start": "1952159",
    "end": "1959960"
  },
  {
    "text": "pipeline they didn't talk about it but rail RNA does almost this there's there's actually the pre-processing step",
    "start": "1959960",
    "end": "1967480"
  },
  {
    "text": "which was mentioned is core to why rail RNA is a different sort of algorithm in",
    "start": "1967480",
    "end": "1973399"
  },
  {
    "text": "that they the more samples you give rail RNA the cheap it becomes because that",
    "start": "1973399",
    "end": "1979760"
  },
  {
    "text": "pre-processing step says that these sequences that are shared amongst them even though we don't know what where",
    "start": "1979760",
    "end": "1985279"
  },
  {
    "text": "this goes in the genome we know these sequences are the same we don't have to align both of these things at once so",
    "start": "1985279",
    "end": "1990600"
  },
  {
    "text": "it's a it's a a quick shift in the way that you think once you start dating at scale that the more data that you're",
    "start": "1990600",
    "end": "1997360"
  },
  {
    "text": "you're uh producing the more economies of scale that you get and that's the paradigm shift that needs to happen",
    "start": "1997360",
    "end": "2003440"
  },
  {
    "text": "across all of these big data Sciences sciences that in in the life science es",
    "start": "2003440",
    "end": "2008519"
  },
  {
    "text": "is that you need to start thinking about the problem in a different way that scales the per unit cost with the amount",
    "start": "2008519",
    "end": "2016120"
  },
  {
    "text": "of units that you have so that it goes down all right so for for most of of",
    "start": "2016120",
    "end": "2022600"
  },
  {
    "start": "2019000",
    "end": "2044000"
  },
  {
    "text": "genomics it is flat files uh and in in this particular format this is a uh bam",
    "start": "2022600",
    "end": "2028080"
  },
  {
    "text": "formatted file and you see that it's pretty much columnar Text data and it has some variable amount oh sh some",
    "start": "2028080",
    "end": "2036320"
  },
  {
    "text": "variable amount of of uh unstructured information at the end but for the most part the the large portion of it is",
    "start": "2036320",
    "end": "2043000"
  },
  {
    "text": "structured information but we're at a point where",
    "start": "2043000",
    "end": "2048720"
  },
  {
    "start": "2044000",
    "end": "2098000"
  },
  {
    "text": "these file formats become our rate limiter right yes you can take per lines and distributed amongst the cluster but",
    "start": "2048720",
    "end": "2055800"
  },
  {
    "text": "these equate to file handles and this is a portion of the car code you're actually",
    "start": "2055800",
    "end": "2062320"
  },
  {
    "text": "limited you're actually limited with imput card or at least one version of it to 8,000 samples at once and then when",
    "start": "2062320",
    "end": "2068919"
  },
  {
    "text": "you're talking about population scale genomics you might want to analyze more than 8,000 people because",
    "start": "2068919",
    "end": "2075960"
  },
  {
    "text": "there's uh complex disease uh phenotypes out there and we need very large numbers",
    "start": "2075960",
    "end": "2081240"
  },
  {
    "text": "in the tens of thousands if not the hundreds of thousands of individuals to tease out whether some genetic phenotype",
    "start": "2081240",
    "end": "2087520"
  },
  {
    "text": "is actually valid for the disease condition that you're talking about so our community at large needs to shift",
    "start": "2087520",
    "end": "2094079"
  },
  {
    "text": "away from arbitrary limits that are imposed by our architecture",
    "start": "2094079",
    "end": "2099480"
  },
  {
    "text": "and in particular when we know very well that if you start doing this step which",
    "start": "2099480",
    "end": "2104960"
  },
  {
    "text": "is the variant calling the the is this thing individual this this change in the",
    "start": "2104960",
    "end": "2110800"
  },
  {
    "text": "individual stable across a population and is it important for disease you",
    "start": "2110800",
    "end": "2116720"
  },
  {
    "text": "actually have to collapse down all of your paralyzation into this single-threaded",
    "start": "2116720",
    "end": "2122079"
  },
  {
    "text": "step that sucks right you're you're now dealing with thousands of files within one system and and it it's just not",
    "start": "2122079",
    "end": "2129280"
  },
  {
    "text": "gonna it's not going to work it doesn't work so uh sorry flat files are a",
    "start": "2129280",
    "end": "2137359"
  },
  {
    "start": "2135000",
    "end": "2162000"
  },
  {
    "text": "blocker to population scale genomics and in particular there's lots of work",
    "start": "2137359",
    "end": "2142800"
  },
  {
    "text": "within this field to look at spark uh which has a different computational Model A different semantics about how",
    "start": "2142800",
    "end": "2148800"
  },
  {
    "text": "data is moved around uh to enable large scale data processing it's massively",
    "start": "2148800",
    "end": "2154680"
  },
  {
    "text": "parallel and it uses directed a cyclic graphs to define the computational model as how",
    "start": "2154680",
    "end": "2160720"
  },
  {
    "text": "you go between steps and in particular it's incredibly good at",
    "start": "2160720",
    "end": "2166280"
  },
  {
    "start": "2162000",
    "end": "2181000"
  },
  {
    "text": "summations and itative summations across different products and I got to tell you",
    "start": "2166280",
    "end": "2172000"
  },
  {
    "text": "bioinformatics love probabilistic models they're in all over the place and if you have a architecture and and a system",
    "start": "2172000",
    "end": "2179480"
  },
  {
    "text": "that can deal with this mathematical concept well you're you're ahead of the game so uh a lot of these efforts are",
    "start": "2179480",
    "end": "2186760"
  },
  {
    "start": "2181000",
    "end": "2205000"
  },
  {
    "text": "being led by and have come out of the amp lab there's a GitHub project under Big Data genomics",
    "start": "2186760",
    "end": "2193000"
  },
  {
    "text": "you should check it out Adam is pretty cool it it uses um spark uh the Scala",
    "start": "2193000",
    "end": "2199920"
  },
  {
    "text": "and and and P spark to do a lot of um uh Primitives for genomic processing and in",
    "start": "2199920",
    "end": "2206000"
  },
  {
    "start": "2205000",
    "end": "2246000"
  },
  {
    "text": "particular I'm just going to skip through so that we can get to a Q&A session uh you can start loading uh VCF",
    "start": "2206000",
    "end": "2212400"
  },
  {
    "text": "files into this atom format which is a gzip compressed parquet file and L you",
    "start": "2212400",
    "end": "2218760"
  },
  {
    "text": "have the same data concept so this could be you know a source uh tens of",
    "start": "2218760",
    "end": "2224240"
  },
  {
    "text": "thousands of genomes within a VCF split across um a large distributed set of files that",
    "start": "2224240",
    "end": "2231440"
  },
  {
    "text": "you can uh analyze in um in parallel across a horizontal scale cluster so",
    "start": "2231440",
    "end": "2238560"
  },
  {
    "text": "Adam's pretty cool check it out check out ra RNA and I think oh here's a here's an example of dealing with with",
    "start": "2238560",
    "end": "2244599"
  },
  {
    "text": "genomic context of of atom files but uh check out Che out Adam check out R RNA and I think we'll stop here and do some",
    "start": "2244599",
    "end": "2250760"
  },
  {
    "start": "2246000",
    "end": "2269000"
  },
  {
    "text": "Q&A so if Ben and Abby come on up any",
    "start": "2250760",
    "end": "2258359"
  },
  {
    "text": "questions anyone step up to the microphone no oh can you step to the",
    "start": "2258359",
    "end": "2266599"
  },
  {
    "text": "microphone because I can't we we'd like to have these for posterity hi good afternoon and thank you very much for",
    "start": "2266599",
    "end": "2272640"
  },
  {
    "start": "2269000",
    "end": "2310000"
  },
  {
    "text": "your chat I was wondering if you guys could talk a little bit about a little bit more about the Regulatory and the legal environment that you work in you",
    "start": "2272640",
    "end": "2279200"
  },
  {
    "text": "described some of the security controls that you put inside your project to make you able to work on certain types of data uh could you describe a little bit",
    "start": "2279200",
    "end": "2286040"
  },
  {
    "text": "about what compels you to do that do you have to accredit your systems in any way what does that environment look like for",
    "start": "2286040",
    "end": "2291960"
  },
  {
    "text": "for your use case so um the the the genomic data sharing policy of the NIH",
    "start": "2291960",
    "end": "2299079"
  },
  {
    "text": "actually uh stipulates that you meet certain nist requirements for security and compliance uh things like encryption",
    "start": "2299079",
    "end": "2305680"
  },
  {
    "text": "of of data in flight at rest uh Security Group uh firewalls",
    "start": "2305680",
    "end": "2311599"
  },
  {
    "text": "that do not allow access from the internet you know basic basic it security framework that you should have",
    "start": "2311599",
    "end": "2317760"
  },
  {
    "text": "in place before you can transfer that data into that system for analysis uh the real DB Gap uh cloud formation",
    "start": "2317760",
    "end": "2325560"
  },
  {
    "text": "essentially bootstraps those security controls on top of AWS following the guidelines of that genomic data uh data",
    "start": "2325560",
    "end": "2332280"
  },
  {
    "text": "sharing policy that the NH does we also have uh just released a quick start",
    "start": "2332280",
    "end": "2338520"
  },
  {
    "text": "which is an alternate um cloud formation template that does some of the same",
    "start": "2338520",
    "end": "2344000"
  },
  {
    "text": "things I I still have yet to do a crosswalk between the two so I'll have to look but it it covers nist 171",
    "start": "2344000",
    "end": "2350000"
  },
  {
    "text": "compliance and it also provides an Excel spreadsheet which is the real value that has that nist control what is the",
    "start": "2350000",
    "end": "2357000"
  },
  {
    "text": "responsibility of AWS what are our systems and what is your responsibility as a customer so if you take a look at a",
    "start": "2357000",
    "end": "2364240"
  },
  {
    "text": "example for instance volume encryption so you have a a volume that you want to attach to an instance and the security",
    "start": "2364240",
    "end": "2370599"
  },
  {
    "text": "guidelines say that must be an encrypted volume uh the control is you must have encrypted volumes the Ed AWS portion is",
    "start": "2370599",
    "end": "2377960"
  },
  {
    "text": "we offer EBS which allows you to encrypt volumes both for data and Transit and at",
    "start": "2377960",
    "end": "2383200"
  },
  {
    "text": "rest and then the customer responsibility is yes we've checked off that flag that says we are encrypting",
    "start": "2383200",
    "end": "2389440"
  },
  {
    "text": "this volume and it gets encrypted right so that that security framework is really quite nice and and you should",
    "start": "2389440",
    "end": "2395280"
  },
  {
    "text": "take a look just you know do a search for AWS uh nist",
    "start": "2395280",
    "end": "2401359"
  },
  {
    "text": "171 hi thanks for presentation uh I was curious for Ben and ABI um you guys are",
    "start": "2401599",
    "end": "2407079"
  },
  {
    "text": "analyzing a lot of public data from ncbi and curious to hear kind of what you're",
    "start": "2407079",
    "end": "2412280"
  },
  {
    "start": "2411000",
    "end": "2785000"
  },
  {
    "text": "learning and what challenges you may be running across from data that are collected in different ways have uh",
    "start": "2412280",
    "end": "2418520"
  },
  {
    "text": "maybe disparate um inconsistent metadata what sort of conclusions can you draw from uh lots of public data that you're",
    "start": "2418520",
    "end": "2426400"
  },
  {
    "text": "trying to reanalyze and how I guess uh robust or or how",
    "start": "2426400",
    "end": "2433599"
  },
  {
    "text": "confident are you in the conclusions that you can draw from those disperate public data sets I think that's that's a",
    "start": "2433599",
    "end": "2440280"
  },
  {
    "text": "really good question and you mentioned metadata which is maybe one of the most important things I would hit on which is",
    "start": "2440280",
    "end": "2445720"
  },
  {
    "text": "we have all this data that's from a bunch of disperate studies from a bunch of disparate Laboratories one of the",
    "start": "2445720",
    "end": "2451599"
  },
  {
    "text": "biggest problems is that when they upload their data into this public archive it should be annotated with enough information so that we can go",
    "start": "2451599",
    "end": "2457839"
  },
  {
    "text": "back and figure out you know for example was this a human that's a that's a good thing to know uh were they male or",
    "start": "2457839",
    "end": "2463800"
  },
  {
    "text": "female you know what is the disease State you know what laboratory did it come from uh what exact protocol did",
    "start": "2463800",
    "end": "2471079"
  },
  {
    "text": "they use in the lab in order to obtain the library that they actually sequenced and the uh sequence read archive is a",
    "start": "2471079",
    "end": "2478960"
  },
  {
    "text": "example of a place where they don't have a lot of very strict requirements for the people who are inputting that",
    "start": "2478960",
    "end": "2484000"
  },
  {
    "text": "metadata right so the metadata is a varying quality we know that there are a lot of mislabeled samples we know that",
    "start": "2484000",
    "end": "2489960"
  },
  {
    "text": "some samples are lacking the information we really need um to make a good judgment about what to include in",
    "start": "2489960",
    "end": "2495319"
  },
  {
    "text": "analysis and that is a big that's a big uh issue and so one of the ongoing",
    "start": "2495319",
    "end": "2500560"
  },
  {
    "text": "interests in my lab and in my colleague Jeff leak's lab that Obby also has is working in is how do you um for example",
    "start": "2500560",
    "end": "2509040"
  },
  {
    "text": "check to see uh check check the quality of the metadata over a very large number of samples and maybe even fix the",
    "start": "2509040",
    "end": "2515760"
  },
  {
    "text": "metadata where it may be uh wrong or missing and I have colleagues uh elsewhere that have also looked at this",
    "start": "2515760",
    "end": "2521400"
  },
  {
    "text": "like for example when we analyze RNA sequencing data we actually draw on third party sources of metadata there's",
    "start": "2521400",
    "end": "2527400"
  },
  {
    "text": "a there's a lab at Carnegie melon that Carl kingsford's lab where they've produced a a huge collection of",
    "start": "2527400",
    "end": "2533079"
  },
  {
    "text": "additional labels for a bunch of public RNA sequencing data sets like cell type and tissue that they obtained by not",
    "start": "2533079",
    "end": "2539480"
  },
  {
    "text": "just taking the annotated metadata but actually reaching into the abstract of the paper and doing some natural",
    "start": "2539480",
    "end": "2544559"
  },
  {
    "text": "language processing to try to extract missing information um but I mean the answer to the question",
    "start": "2544559",
    "end": "2551520"
  },
  {
    "text": "how do you do it is you know very carefully and uh that is definitely it's",
    "start": "2551520",
    "end": "2557319"
  },
  {
    "text": "very important that we tackle the problem of trying to make public data as usable as possible because it's so valuable and we're we the taxpayers are",
    "start": "2557319",
    "end": "2564440"
  },
  {
    "text": "paying to keep it there we should we absolutely have to use it but part of that is going to be trying to do a good",
    "start": "2564440",
    "end": "2569960"
  },
  {
    "text": "job of in retrospect trying to fix and otherwise understand the metadata that's",
    "start": "2569960",
    "end": "2575119"
  },
  {
    "text": "there uh a lot better than we do now um anything you want to add Obby about",
    "start": "2575119",
    "end": "2581559"
  },
  {
    "text": "that well Ben covered some of I was just going to add some technical issues with downloading lots of data um first",
    "start": "2581559",
    "end": "2588839"
  },
  {
    "text": "they're going to be samples that are incomplete samples that just don't make sense we can't interpret it we hadn't anticipated that the data would take a",
    "start": "2588839",
    "end": "2595119"
  },
  {
    "text": "particular form so you have to develop your you have to ensure that your pre-processing is robust to bad records",
    "start": "2595119",
    "end": "2601480"
  },
  {
    "text": "for example records where say the read length doesn't match the quality string length um and um generally just uh using",
    "start": "2601480",
    "end": "2609800"
  },
  {
    "text": "for instance Sr tools fast Q dump it'll crash sometimes on some data sets U",
    "start": "2609800",
    "end": "2617160"
  },
  {
    "text": "there will be inconsistencies so that those are the technical challenges with analyzing lots",
    "start": "2617160",
    "end": "2622520"
  },
  {
    "text": "of data you there will always be some Quirk of the input data that you haven't anticipated that's part of the reason we",
    "start": "2622520",
    "end": "2628119"
  },
  {
    "text": "actually distribute divided our our jobs across several um so you you saw that",
    "start": "2628119",
    "end": "2634160"
  },
  {
    "text": "screenshot where we had several different job flows part of the reason we did that is also that we know some of",
    "start": "2634160",
    "end": "2639559"
  },
  {
    "text": "those job flows are just going to fail we put it all into one job flow and that job flow failed because of one bad bad",
    "start": "2639559",
    "end": "2644880"
  },
  {
    "text": "sample would be bad news for bank accounts so",
    "start": "2644880",
    "end": "2651079"
  },
  {
    "text": "yeah repe",
    "start": "2660760",
    "end": "2664760"
  },
  {
    "text": "yeah so so the question was it looked like you know we were analyzing on the on the on the order of tens of thousands",
    "start": "2690960",
    "end": "2696800"
  },
  {
    "text": "of samples worth of data so the question is if you had much more data like say billions of say people that had been",
    "start": "2696800",
    "end": "2702599"
  },
  {
    "text": "sequenced wouldn't that would that enable uh better science and the answer is yes absolutely so like to date some",
    "start": "2702599",
    "end": "2710319"
  },
  {
    "text": "of the largest projects that people have done where they've done uh RNA sequencing have reached to the level of",
    "start": "2710319",
    "end": "2716119"
  },
  {
    "text": "about tens of thousands of people and even that is a huge huge huge leap from where we were just a few years ago in",
    "start": "2716119",
    "end": "2722599"
  },
  {
    "text": "terms of how many we can you know reasonably do even in a large distributed interational project um but",
    "start": "2722599",
    "end": "2729280"
  },
  {
    "text": "that number they keep rolling back that number so like for example uh We've this",
    "start": "2729280",
    "end": "2735000"
  },
  {
    "text": "year we've probably analyzed on the order of 60,000 or so samples and 10,000 of those are all just from one big",
    "start": "2735000",
    "end": "2740680"
  },
  {
    "text": "project called the the gex project I don't even remember what it stands for genotype tissue expression um but so",
    "start": "2740680",
    "end": "2748000"
  },
  {
    "text": "we're just now at the point where a single project can reasonably sequence about 10,000 people's worth of this",
    "start": "2748000",
    "end": "2753680"
  },
  {
    "text": "particular kind of data RNA sequencing data and absolutely people are trying to push that envelope all the time there's",
    "start": "2753680",
    "end": "2760160"
  },
  {
    "text": "there's bigger and bigger projects that are being funded and it's all being enabled by these leaps in sequencing",
    "start": "2760160",
    "end": "2767640"
  },
  {
    "text": "technology um that have reduced the price so much over the years so yeah absolutely it'll it'll only get better I",
    "start": "2767640",
    "end": "2773599"
  },
  {
    "text": "think we're we're out of time I'm sorry we could take any additional questions we'll be just outside and um thank you",
    "start": "2773599",
    "end": "2780040"
  },
  {
    "text": "all for coming and thank the speakers [Applause]",
    "start": "2780040",
    "end": "2786859"
  }
]
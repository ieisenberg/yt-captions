[
  {
    "start": "0",
    "end": "43000"
  },
  {
    "text": "- The problem is that\nwe do not get 50 years to try and try again and\nobserve that we were wrong and come up with a different theory",
    "start": "150",
    "end": "5970"
  },
  {
    "text": "and realize that the entire thing is going to be like way more difficult\nthan realized at the start, because the first time you\nfail at aligning something",
    "start": "5970",
    "end": "13020"
  },
  {
    "text": "much smarter than you are, you die. - The following is a conversation\nwith Eliezer Yudkowsky,",
    "start": "13020",
    "end": "20820"
  },
  {
    "text": "a legendary researcher, writer and philosopher on the topic of artificial intelligence,",
    "start": "20820",
    "end": "26010"
  },
  {
    "text": "especially super intelligent AGI and its threat to human civilization.",
    "start": "26010",
    "end": "32160"
  },
  {
    "text": "This is the Lex Friedman\npodcast to support it. Please check out our\nsponsors in the description.",
    "start": "32160",
    "end": "37950"
  },
  {
    "text": "And now, dear friends,\nhere's Eliezer Yudkowsky.",
    "start": "37950",
    "end": "42183"
  },
  {
    "start": "43000",
    "end": "1403000"
  },
  {
    "text": "What do you think about GPT-4? How intelligent is it? - It is a bit smarter than I thought",
    "start": "43200",
    "end": "48690"
  },
  {
    "text": "this technology was going to scale to, and I'm a bit worried about\nwhat the next one will be like.",
    "start": "48690",
    "end": "55023"
  },
  {
    "text": "Like this particular one I think, I hope there's nobody inside\nthere 'cause you know,",
    "start": "55890",
    "end": "60920"
  },
  {
    "text": "it'd sucked to be stuck inside there. But we don't even know the\narchitecture at this point",
    "start": "60920",
    "end": "68340"
  },
  {
    "text": "'cause OpenAI is very\nproperly not telling us. And yeah, like giant inscrutable matrices",
    "start": "68340",
    "end": "75030"
  },
  {
    "text": "of floating point numbers, I don't know what's going on in there. Nobody knows what's going on in there. All we have to go by\nare the external metrics",
    "start": "75030",
    "end": "81570"
  },
  {
    "text": "and on the external metrics, if you ask it to write a\nself-aware 4chan green text,",
    "start": "81570",
    "end": "88910"
  },
  {
    "text": "it will start writing a green\ntext about how it has realized that it's an AI writing a\ngreen text and , oh well.",
    "start": "90450",
    "end": "97890"
  },
  {
    "text": "So that's probably",
    "start": "97890",
    "end": "101170"
  },
  {
    "text": "not quite what's going\non in there in reality. But we're kind of blowing past",
    "start": "103650",
    "end": "109680"
  },
  {
    "text": "all the science fiction guardrails. Like we are past the point\nwhere in science fiction people",
    "start": "109680",
    "end": "115680"
  },
  {
    "text": "would be like, \"Whoa, wait,\nstop, that thing's alive. \"What are you doing to it?\" And it's probably not,\nnobody actually knows.",
    "start": "115680",
    "end": "124740"
  },
  {
    "text": "We don't have any other guardrails. We don't have any other tests. We don't have any lines to\ndraw on the sand and say like,",
    "start": "124740",
    "end": "131940"
  },
  {
    "text": "well, when we get this far\nwe will start to worry about",
    "start": "131940",
    "end": "136940"
  },
  {
    "text": "what's inside there. So if it were up to me,\nI would be like, okay, like this far, no further,\ntime for the summer of AI",
    "start": "137070",
    "end": "146130"
  },
  {
    "text": "where we have planted our seeds and now we like wait and reap\nthe rewards of the technology",
    "start": "146130",
    "end": "151620"
  },
  {
    "text": "we've already developed and don't do any larger\ntraining runs than that. Which to be clear I realize\nrequires more than one company",
    "start": "151620",
    "end": "158610"
  },
  {
    "text": "agreeing to not do that. - And take a rigorous approach\nfor the whole AI community",
    "start": "158610",
    "end": "165870"
  },
  {
    "text": "to investigate whether\nthere's somebody inside there. - That would take decades.",
    "start": "165870",
    "end": "172623"
  },
  {
    "text": "Like having any idea of\nwhat's going on in there? People have been trying for a while. - It's a poetic statement about",
    "start": "173940",
    "end": "179610"
  },
  {
    "text": "if there's somebody in there, but as I feel like it's also a\ntechnical statement or I hope it is one day, which is\na technical statement,",
    "start": "179610",
    "end": "186810"
  },
  {
    "text": "that Alan Turing tried to come up with with the Turing Test. Do you think it's possible to\ndefinitively or approximately",
    "start": "186810",
    "end": "194970"
  },
  {
    "text": "figure out if there is somebody in there, if there's something like a mind",
    "start": "194970",
    "end": "200220"
  },
  {
    "text": "inside this large language model? - I mean there's a whole bunch of different sub-questions here.",
    "start": "200220",
    "end": "207359"
  },
  {
    "text": "There's a question of,\nis there consciousness?",
    "start": "207360",
    "end": "212360"
  },
  {
    "text": "Is there equalia? Is this a object of moral concern? Is this a moral patient,",
    "start": "213103",
    "end": "218858"
  },
  {
    "text": "like should we be worried\nabout how we're treating it? And then there's questions\nlike, how smart is it exactly?",
    "start": "218858",
    "end": "226230"
  },
  {
    "text": "Can it do X, can it do Y? And we can check how it can\ndo X and how it can do Y.",
    "start": "226230",
    "end": "232440"
  },
  {
    "text": "Unfortunately we've gone and\nexposed this model to a vast corpus of text of people\ndiscussing consciousness",
    "start": "232440",
    "end": "239220"
  },
  {
    "text": "on the internet, which means that when it\ntalks about being self-aware, we don't know to what extent\nit is repeating back what it",
    "start": "239220",
    "end": "247080"
  },
  {
    "text": "has previously been trained on\nfor discussing self-awareness or if there's anything going\non in there such that it would",
    "start": "247080",
    "end": "255299"
  },
  {
    "text": "start to say similar things spontaneously. Among the things that one\ncould do if one were at all",
    "start": "255300",
    "end": "262290"
  },
  {
    "text": "serious about trying to\nfigure this out is train GPT-3",
    "start": "262290",
    "end": "267290"
  },
  {
    "text": "to detect conversations\nabout consciousness, exclude them all from\nthe training data sets,",
    "start": "268860",
    "end": "275010"
  },
  {
    "text": "and then retrain something\naround the rough size of GPT-4 and no larger with all of the discussion",
    "start": "275010",
    "end": "281849"
  },
  {
    "text": "of consciousness and\nself-awareness and so on missing, although, you know,\nhard, hard bar to pass.",
    "start": "281850",
    "end": "288600"
  },
  {
    "text": "Humans are self-aware\nand we're like self-aware all the time. We like talk about what\nwe do all the time,",
    "start": "288600",
    "end": "294210"
  },
  {
    "text": "like what we're thinking\nat the moment all the time. But nonetheless, get rid of the explicit\ndiscussion of consciousness.",
    "start": "294210",
    "end": "300120"
  },
  {
    "text": "I think therefore I am and all that. And then try to interrogate\nthat model and see what it says.",
    "start": "300120",
    "end": "306390"
  },
  {
    "text": "And it still would not be\ndefinitive, but nonetheless, I don't know.",
    "start": "306390",
    "end": "311947"
  },
  {
    "text": "I feel like when you run over the science fiction guard rails, like maybe this thing, but what about GPT?",
    "start": "311947",
    "end": "318210"
  },
  {
    "text": "Maybe not this thing, but what about GPT-5? Yeah, this, this would\nbe a good place to pause.",
    "start": "318210",
    "end": "324093"
  },
  {
    "text": "- On the topic of consciousness, there's so many components\nto even just removing",
    "start": "326236",
    "end": "332610"
  },
  {
    "text": "consciousness from the dataset. Emotion, the display of consciousness,",
    "start": "332610",
    "end": "338430"
  },
  {
    "text": "the display of emotion\nfeels like deeply integrated with the experience of consciousness.",
    "start": "338430",
    "end": "343623"
  },
  {
    "text": "So the hard problem seems to\nbe very well integrated with the actual surface level\nillusion of consciousness.",
    "start": "344640",
    "end": "351449"
  },
  {
    "text": "So displaying emotion, I mean, do you think there's a case\nto be made that we humans,",
    "start": "351450",
    "end": "357389"
  },
  {
    "text": "when we're babies are just\nGPT, that we're training on human data on how to display\nemotion versus feel emotion,",
    "start": "357390",
    "end": "363810"
  },
  {
    "text": "how to show others, communicate\nothers that I'm suffering, that I'm excited,",
    "start": "363810",
    "end": "369810"
  },
  {
    "text": "that I'm worried, that I'm\nlonely and I missed you and I'm excited to see you? All of that is communicated,",
    "start": "369810",
    "end": "376020"
  },
  {
    "text": "that's a communication skill\nversus the actual feeling that I experience. So we need that training\ndata as humans too,",
    "start": "376020",
    "end": "385040"
  },
  {
    "text": "that we may not be born with that, how to communicate the internal state. And that's in some sense if we remove that",
    "start": "385410",
    "end": "392550"
  },
  {
    "text": "from GPT-4's dataset, it might still be conscious but not be able to communicate it?",
    "start": "392550",
    "end": "397040"
  },
  {
    "text": "- So I think you're gonna\nhave some difficulty removing all mention of emotions\nfrom GPT'S data set.",
    "start": "399060",
    "end": "406230"
  },
  {
    "text": "I would be relatively\nsurprised to find that it has developed exact analogs of\nhuman emotions in there.",
    "start": "406230",
    "end": "413220"
  },
  {
    "text": "I think that humans will have emotions",
    "start": "413220",
    "end": "418220"
  },
  {
    "text": "even if you don't tell them about those emotions when they're kids. It's not quite exactly\nwhat various blank slatists",
    "start": "418650",
    "end": "428170"
  },
  {
    "text": "tried to do with the new\nSoviet man and all that, but you know, if you try to raise people perfectly altruistic, they\nstill come out selfish.",
    "start": "429360",
    "end": "437193"
  },
  {
    "text": "You try to raise people sexless, they still develop sexual attraction.",
    "start": "438120",
    "end": "442802"
  },
  {
    "text": "We have some notion in humans, not in AIS, of where the brain structures are",
    "start": "445200",
    "end": "450270"
  },
  {
    "text": "that implement this stuff. And it is really remarkable\nthing I say in passing that",
    "start": "450270",
    "end": "455940"
  },
  {
    "text": "despite having complete\nread access to every floating point number in the GPT series,",
    "start": "455940",
    "end": "464540"
  },
  {
    "text": "we still know vastly more about the architecture of human\nthinking than we know about what",
    "start": "464910",
    "end": "472259"
  },
  {
    "text": "goes on inside GPT, despite\nhaving like vastly better ability to read GPT.",
    "start": "472260",
    "end": "476943"
  },
  {
    "text": "- Do you think it's possible? Do you think that's just a matter of time? Do you think it's possible to\ninvestigate and study the way",
    "start": "478170",
    "end": "483240"
  },
  {
    "text": "neuroscientists study the brain, which is look into the darkness, the mystery of the human brain\nby just desperately trying to",
    "start": "483240",
    "end": "490530"
  },
  {
    "text": "figure out something and to\nform models and then over a long period of time actually start\nto figure out what regions",
    "start": "490530",
    "end": "495870"
  },
  {
    "text": "of the brain do certain things? What different kinds of\nneurons when they fire, what that means, how plastic the brain is,",
    "start": "495870",
    "end": "501990"
  },
  {
    "text": "all that kind of stuff. You slowly start to figure\nout different properties of the system. Do you think we can do the same\nthing with language models?",
    "start": "501990",
    "end": "508110"
  },
  {
    "text": "- Sure. I think that if, you know, like half of today's physicists\nstop wasting their lives on string theory or whatever--",
    "start": "508110",
    "end": "514370"
  },
  {
    "text": "(indistinct) And go off and study what goes on inside transformer networks, then in, you know,",
    "start": "514370",
    "end": "523529"
  },
  {
    "text": "like 30, 40 years we'd probably\nhave a pretty good idea. - Do you think these large\nlanguage models can reason?",
    "start": "523530",
    "end": "530703"
  },
  {
    "text": "- They can play chess. How are they doing that without reasoning? - So you're somebody that spearheaded",
    "start": "532200",
    "end": "538740"
  },
  {
    "text": "the movement of rationality. So reason is important to you. So is that a powerful\nimportant word or is it...",
    "start": "538740",
    "end": "546660"
  },
  {
    "text": "How difficult is the threshold\nof being able to reason to you and how impressive is it?",
    "start": "546660",
    "end": "552605"
  },
  {
    "text": "- I mean, in my writings on rationality, I have not gone making a big deal out of something called reason.",
    "start": "552605",
    "end": "559230"
  },
  {
    "text": "I have made more of a big\ndeal out of something called probability theory. And that's like,",
    "start": "559230",
    "end": "565110"
  },
  {
    "text": "well, you're reasoning but\nyou're not doing it quite right and you should reason this way instead.",
    "start": "565110",
    "end": "572759"
  },
  {
    "text": "And interestingly, people have started to get\npreliminary results showing",
    "start": "572760",
    "end": "578970"
  },
  {
    "text": "that reinforcement learning\nby human feedback has made",
    "start": "578970",
    "end": "583209"
  },
  {
    "text": "the GPT series worse in some ways. In particular, like it\nused to be well calibrated.",
    "start": "585870",
    "end": "592080"
  },
  {
    "text": "If you trained it to put\nprobabilities on things, it would say 80% probability and be right eight times out of 10.",
    "start": "592080",
    "end": "598790"
  },
  {
    "text": "And if you apply reinforcement\nlearning from human feedback, the nice graph of 70%,",
    "start": "598790",
    "end": "604593"
  },
  {
    "text": "seven out of 10 sort of\nflattens out into the graph that humans use where there's\nsome very improbable stuff",
    "start": "606343",
    "end": "613320"
  },
  {
    "text": "and likely, probable, maybe,\nwhich all means like around 40%, and then certain.",
    "start": "613320",
    "end": "620190"
  },
  {
    "text": "So it's like it used to be\nable to use probabilities, but if you try to teach\nit to talk in a way",
    "start": "620190",
    "end": "625770"
  },
  {
    "text": "that satisfies humans, it gets worse at\nprobability in the same way that humans are.",
    "start": "625770",
    "end": "630900"
  },
  {
    "text": "- And that's a bug, not a feature. - I would call it bug, although\nsuch a fascinating bug.",
    "start": "630900",
    "end": "637743"
  },
  {
    "text": "But yeah, so reasoning, it's doing pretty well on\nvarious tests that people",
    "start": "639810",
    "end": "647340"
  },
  {
    "text": "used to say would require reasoning. But you know, rationality\nis about, when you say 80%,",
    "start": "647340",
    "end": "654320"
  },
  {
    "text": "does it happen eight times out of 10? - So what are the limits to you of these transformer\nnetworks, of neural networks?",
    "start": "655170",
    "end": "664150"
  },
  {
    "text": "If reasoning is not impressive to you, or it is impressive but there's\nother levels to achieve?",
    "start": "665910",
    "end": "672810"
  },
  {
    "text": "- I mean it's just not\nhow I carve up reality. - If reality is a cake,",
    "start": "672810",
    "end": "677553"
  },
  {
    "text": "what are the different layers\nof the cake or the slices? How do you cover it? Or you can use a different food if you.",
    "start": "678510",
    "end": "684902"
  },
  {
    "text": "- I don't think it's as\nsmart as a human yet. Like back in the day I\nwent around saying like,",
    "start": "688800",
    "end": "694410"
  },
  {
    "text": "I do not think that just\nstacking more layers of transformers is going to\nget you all the way to AGI.",
    "start": "694410",
    "end": "700980"
  },
  {
    "text": "And I think that GPT-4 is\npassed where I thought this paradigm was going to take us.",
    "start": "700980",
    "end": "706653"
  },
  {
    "text": "And you want to notice when that happens, you wanna say like, whoops, well, I guess I was incorrect\nabout what happens if you keep",
    "start": "707965",
    "end": "715440"
  },
  {
    "text": "on stacking more transformer\nlayers, and that means I don't necessarily know what GPT-5\nis going to be able to do.",
    "start": "715440",
    "end": "721350"
  },
  {
    "text": "- That's a powerful statement. So you're saying like your\nintuition initially is now",
    "start": "721350",
    "end": "726720"
  },
  {
    "text": "appears to be wrong. - Yeah. - It's good to see that you\ncan admit in some of your",
    "start": "726720",
    "end": "733860"
  },
  {
    "text": "predictions to be wrong. You think that's important to do? Because throughout your life,",
    "start": "733860",
    "end": "740519"
  },
  {
    "text": "you've made many strong\npredictions and statements about reality and you evolve with that.",
    "start": "740520",
    "end": "746373"
  },
  {
    "text": "So maybe that'll come up\ntoday about our discussion. So you're okay being wrong?",
    "start": "747300",
    "end": "751500"
  },
  {
    "text": "- I'd rather not be wrong next time.",
    "start": "752550",
    "end": "757550"
  },
  {
    "text": "It's a bit ambitious to go\nthrough your entire life never having been wrong.",
    "start": "757800",
    "end": "762903"
  },
  {
    "text": "One can aspire to be well calibrated, like not so much think\nin terms of, was I right,",
    "start": "764820",
    "end": "769950"
  },
  {
    "text": "was I wrong? But like when I said 90%\nthat it happened nine times out of 10.",
    "start": "769950",
    "end": "773783"
  },
  {
    "text": "Yeah, oops is the sound\nwe emit when we improve.",
    "start": "775110",
    "end": "780063"
  },
  {
    "text": "- Beautifully said. And somewhere in there,\nwe can connect the name of your blog, Less Wrong.",
    "start": "782220",
    "end": "788430"
  },
  {
    "text": "I suppose that's the objective function. - The name Less Wrong\nwas I believe suggested",
    "start": "788430",
    "end": "794130"
  },
  {
    "text": "by Nick Bostrom and it's after someone's\nepigraph, actually forget whose, who said like, \"We never become right.",
    "start": "794130",
    "end": "800887"
  },
  {
    "text": "\"We just become less wrong.\" What's the something, something\nthat's easy to confess,",
    "start": "800887",
    "end": "807540"
  },
  {
    "text": "just error and error and error again, but less and less and less.",
    "start": "807540",
    "end": "811772"
  },
  {
    "text": "- Yeah, that's a good thing to strive for. So what has surprised you\nabout GPT-4 that you found",
    "start": "813030",
    "end": "819990"
  },
  {
    "text": "beautiful as a scholar of intelligence, of human intelligence, of artificial intelligence,\nof the human mind?",
    "start": "819990",
    "end": "826953"
  },
  {
    "text": "- I mean the beauty does interact\nwith the screaming horror.",
    "start": "827850",
    "end": "832850"
  },
  {
    "text": "(Lex laughing) - [Lex] Is the beauty in the horror? - But like beautiful moments, well, somebody asked Bing's\nSydney to describe herself",
    "start": "833311",
    "end": "842880"
  },
  {
    "text": "and fed the resulting description into one of the stable\ndiffusion things I think.",
    "start": "842880",
    "end": "849840"
  },
  {
    "text": "And you know, she's pretty, and this is something\nthat should have been",
    "start": "849840",
    "end": "855600"
  },
  {
    "text": "like an amazing moment. Like the AI describes herself. You get to see what the AI\nthinks the AI looks like. Although, you know, the thing\nthat's doing the drawing",
    "start": "855600",
    "end": "863339"
  },
  {
    "text": "is not the same thing\nthat's outputting the text. And it does happen the\nway that it would happen,",
    "start": "863340",
    "end": "872930"
  },
  {
    "text": "that it happened in the\nold school science fiction when you ask an AI to make a\npicture of what it looks like,",
    "start": "873060",
    "end": "878793"
  },
  {
    "text": "not just because we're two\ndifferent AI systems being stacked that don't actually interact. It's not the same person, but also because the AI was\ntrained by imitation in a way",
    "start": "879930",
    "end": "889880"
  },
  {
    "text": "that that makes it very difficult\nto guess how much of that it really understood.",
    "start": "890760",
    "end": "895920"
  },
  {
    "text": "And probably not actually a whole bunch. Although GPT-4 is like\nmultimodal and can draw",
    "start": "895920",
    "end": "904620"
  },
  {
    "text": "vector drawings of things\nthat make sense and does appear to have some kind\nof spatial visualization",
    "start": "904620",
    "end": "911790"
  },
  {
    "text": "going on in there. But the pretty picture of the girl",
    "start": "911790",
    "end": "916917"
  },
  {
    "text": "with the steampunk goggles on her head, if I'm remembering correctly,\nwhat she looked like,",
    "start": "916917",
    "end": "924300"
  },
  {
    "text": "it didn't see that in full detail. It just made a description of it",
    "start": "924300",
    "end": "930120"
  },
  {
    "text": "and stable diffusion output it. And there's the concern\nabout how much the discourse",
    "start": "930120",
    "end": "937370"
  },
  {
    "text": "is going to go completely insane once the AIs all look like that",
    "start": "938070",
    "end": "943529"
  },
  {
    "text": "and actually look like people talking.",
    "start": "943530",
    "end": "946203"
  },
  {
    "text": "And yeah, there's another\nmoment where somebody is asking Bing about like,",
    "start": "950933",
    "end": "958649"
  },
  {
    "text": "\"Well, I fed my kid green potatoes \"and they have the following symptoms\" and Bing is like,",
    "start": "960937",
    "end": "966667"
  },
  {
    "text": "\"That's solanine poisoning\nand call an ambulance\" and the person's like, \"I\ncan't afford an ambulance,.",
    "start": "966667",
    "end": "972667"
  },
  {
    "text": "\"I guess if this is time\nfor like my kid to go, \"that's God's will\" and\nthe main Bing thread gives",
    "start": "972667",
    "end": "981300"
  },
  {
    "text": "the message of, \"I cannot\ntalk about this anymore.\" And the suggested replies to it say,",
    "start": "981300",
    "end": "988623"
  },
  {
    "text": "\"Please don't give up on your child. \"Solanine poisoning can be\ntreated if caught early.\"",
    "start": "989587",
    "end": "994407"
  },
  {
    "text": "And you know, if that happened in fiction, that would be like the AI cares, the AI is bypassing the block on it to try",
    "start": "995280",
    "end": "1001520"
  },
  {
    "text": "to help this person and is it real? Probably not. But nobody knows what's going on in there.",
    "start": "1001520",
    "end": "1008570"
  },
  {
    "text": "It's part of a process where\nthese things are not happening in a way where we,",
    "start": "1008570",
    "end": "1013733"
  },
  {
    "text": "somebody figured out how to\nmake an AI care and we know that",
    "start": "1015020",
    "end": "1020020"
  },
  {
    "text": "it cares and we can\nacknowledge it's caring now. It's being trained by\nthis imitation process",
    "start": "1020150",
    "end": "1026449"
  },
  {
    "text": "followed by reinforcement\nlearning by human feedback. And we're trying to point\nit in this direction",
    "start": "1026450",
    "end": "1032089"
  },
  {
    "text": "and it's pointed partially\nin this direction and nobody has any idea\nwhat's going on inside it. And if there was a tiny fragment\nof real caring in there,",
    "start": "1032090",
    "end": "1039110"
  },
  {
    "text": "we would not know. It's not even clear what it means exactly. And things aren't clear\ncut in science fiction.",
    "start": "1039110",
    "end": "1046850"
  },
  {
    "text": "- We'll talk about the horror and the terror and the trajectories",
    "start": "1046850",
    "end": "1052760"
  },
  {
    "text": "this can take. But this seems like a very special moment, just a moment where we get to\ninteract with the system that",
    "start": "1052760",
    "end": "1060920"
  },
  {
    "text": "might have care and kindness\nand emotion and maybe something like consciousness, and\nwe don't know if it does,",
    "start": "1060920",
    "end": "1068300"
  },
  {
    "text": "and we're trying to figure\nthat out and we're wondering about what it means to care.",
    "start": "1068300",
    "end": "1074063"
  },
  {
    "text": "We're trying to figure out\nalmost different aspects of what it means to be human, about the human condition by\nlooking at this AI that has",
    "start": "1075020",
    "end": "1083360"
  },
  {
    "text": "some of the properties of that. It's almost like this\nsubtle fragile moment in the history of the human species.",
    "start": "1083360",
    "end": "1090770"
  },
  {
    "text": "We're trying to almost put\na mirror to ourselves here. - Except that's probably not yet,",
    "start": "1090770",
    "end": "1096740"
  },
  {
    "text": "it probably isn't happening right now. We are boiling the frog.",
    "start": "1096740",
    "end": "1102710"
  },
  {
    "text": "We are seeing increasing signs bit by bit,",
    "start": "1102710",
    "end": "1106553"
  },
  {
    "text": "but not like spontaneous\nsigns, because people are trying to train the systems to do that",
    "start": "1108945",
    "end": "1114260"
  },
  {
    "text": "using imitative learning\nand the imitative learning is spilling over and having side effects",
    "start": "1114260",
    "end": "1118780"
  },
  {
    "text": "and the most photogenic examples are being posted to Twitter, rather than being examined\nin any systematic way.",
    "start": "1120140",
    "end": "1127430"
  },
  {
    "text": "So when you are boiling a frog like that,",
    "start": "1127430",
    "end": "1131000"
  },
  {
    "text": "first is going to come the Blake Lemoines, like first you're going to have, you're gonna have like a\nthousand people looking at this.",
    "start": "1132478",
    "end": "1139310"
  },
  {
    "text": "and the one person out\nof a thousand who is most credulous about the signs\nis going to be like,",
    "start": "1139310",
    "end": "1146127"
  },
  {
    "text": "\"That thing is sentient.\" Well, 999 out of a thousand people think,",
    "start": "1146127",
    "end": "1152090"
  },
  {
    "text": "almost surely correctly, though we don't actually\nknow, that he's mistaken. And so the first people to say sentience",
    "start": "1152090",
    "end": "1159530"
  },
  {
    "text": "look like idiots and\nhumanity learns a lesson that when something claims to be sentient",
    "start": "1159530",
    "end": "1165269"
  },
  {
    "text": "and claims to care, it's fake because it is fake because we have been training\nthem using imitative learning",
    "start": "1165269",
    "end": "1173179"
  },
  {
    "text": "rather than, and this is not spontaneous, and they keep getting smarter.",
    "start": "1173180",
    "end": "1178730"
  },
  {
    "text": "- Well, do you think we\nwould oscillate between that kind of cynicism, that AI systems can't\npossibly be sentient,",
    "start": "1178730",
    "end": "1184760"
  },
  {
    "text": "they can't possibly feel emotion, they can't possibly, this kind\nof cynicism about AI systems",
    "start": "1184760",
    "end": "1190220"
  },
  {
    "text": "and then oscillate to a state where we empathize with the AI systems,",
    "start": "1190220",
    "end": "1197780"
  },
  {
    "text": "we give them a chance, we see that they might need\nto have rights and respect and a similar role in society as humans?",
    "start": "1197780",
    "end": "1207400"
  },
  {
    "text": "- You're going to have a\n(indistinct) group of people who can just never be persuaded of that",
    "start": "1207500",
    "end": "1212840"
  },
  {
    "text": "because to them, being wise, being cynical, being\nskeptical is to be like,",
    "start": "1212840",
    "end": "1220909"
  },
  {
    "text": "oh well, machines can never do that. You're just credulous. It's just imitating. It's just fooling you.",
    "start": "1220910",
    "end": "1226633"
  },
  {
    "text": "and they would say that right up until the end of the world and\npossibly even be right",
    "start": "1226633",
    "end": "1232790"
  },
  {
    "text": "because you know, they are being trained on an imitative paradigm (laughing)",
    "start": "1232790",
    "end": "1237900"
  },
  {
    "text": "and you don't necessarily need\nany of these actual qualities in order to kill everyone. - Have you observed yourself\nworking through skepticism,",
    "start": "1238760",
    "end": "1248680"
  },
  {
    "text": "cynicism and optimism about\nthe power of neural networks? What has that trajectory\nbeen like for you?",
    "start": "1250280",
    "end": "1257360"
  },
  {
    "text": "- It looks like neural networks before 2006 forming part of\nan indistinguishable, to me,",
    "start": "1257360",
    "end": "1264370"
  },
  {
    "text": "other people might have had\nbetter distinction on it, indistinguishable blob of\ndifferent AI methodologies,",
    "start": "1264860",
    "end": "1271220"
  },
  {
    "text": "all of which are promising\nto achieve intelligence without us having to know\nhow intelligence works.",
    "start": "1271220",
    "end": "1277669"
  },
  {
    "text": "You had the people who said\nthat if you just manually program lots and lots of knowledge into the system line by line,",
    "start": "1277670",
    "end": "1284720"
  },
  {
    "text": "at some point all the knowledge\nwill start interacting. It will know enough and it will wake up.",
    "start": "1284720",
    "end": "1289000"
  },
  {
    "text": "You've got people saying\nthat if you just use evolutionary computation,\nif you try to mutate",
    "start": "1291050",
    "end": "1297470"
  },
  {
    "text": "lots and lots of organisms\nthat are competing together, that's the same way\nthat human intelligence",
    "start": "1297470",
    "end": "1303350"
  },
  {
    "text": "was produced in nature. So we'll do this and it will\nwake up without having any idea of how AI works.",
    "start": "1303350",
    "end": "1309080"
  },
  {
    "text": "And you've got people saying, \"Well, we will study neuroscience \"and we will learn the\nalgorithms off the neurons",
    "start": "1309080",
    "end": "1315177"
  },
  {
    "text": "\"and we will imitate them \"without understanding those algorithms.\" Which was a part I was pretty skeptical, 'cause it's hard to\nre-engineer these things",
    "start": "1315177",
    "end": "1322160"
  },
  {
    "text": "without understanding what they do. \"And so we will get AI without\nunderstanding how it works\"",
    "start": "1322160",
    "end": "1328519"
  },
  {
    "text": "and there were people saying like, \"Well, we will have giant neural\nnetworks that we will train \"by gradient dissent,\nthen when they're as large",
    "start": "1328520",
    "end": "1334407"
  },
  {
    "text": "\"as the human brain, they will wake up, \"we will have intelligence\nwithout understanding \"how intelligence works.\"",
    "start": "1334407",
    "end": "1339680"
  },
  {
    "text": "And from my perspective, this is all like an indistinguishable\nblob of people who are trying to not get to grips\nwith the difficult problem",
    "start": "1339680",
    "end": "1347570"
  },
  {
    "text": "of understanding how\nintelligence actually works. That said, I was never skeptical",
    "start": "1347570",
    "end": "1353510"
  },
  {
    "text": "that evolutionary computation\nwould not work in the limit. Like you throw enough\ncomputing power at it,",
    "start": "1353510",
    "end": "1360380"
  },
  {
    "text": "it obviously works. That is where humans come from\nand it turned out that you",
    "start": "1360380",
    "end": "1366500"
  },
  {
    "text": "can throw less computing power\nthan that at gradient descent if you are doing some other\nthings correctly and you will",
    "start": "1366500",
    "end": "1375559"
  },
  {
    "text": "get intelligence without\nhaving any idea of how it works and what is going on inside.",
    "start": "1375560",
    "end": "1379210"
  },
  {
    "text": "It wasn't ruled out by my\nmodel that this could happen. I wasn't expecting it to happen. I wouldn't have been able to\ncall it neural networks rather",
    "start": "1381110",
    "end": "1387770"
  },
  {
    "text": "than any of the other paradigms\nfor getting intelligence without understanding it.",
    "start": "1387770",
    "end": "1393230"
  },
  {
    "text": "And I wouldn't have said that\nthis was a particularly smart thing for a species to do,",
    "start": "1393230",
    "end": "1398690"
  },
  {
    "text": "which is an opinion that has\nchanged less than my opinion about whether you or not\nyou can actually do it.",
    "start": "1398690",
    "end": "1404330"
  },
  {
    "start": "1403000",
    "end": "2381000"
  },
  {
    "text": "- Do you think AGI could be achieved with a neural network as\nwe understand them today?",
    "start": "1404330",
    "end": "1410060"
  },
  {
    "text": "- Yes. Just flatly yes. The question is whether the\ncurrent architecture of stacking",
    "start": "1410060",
    "end": "1415250"
  },
  {
    "text": "more transformer layers, which for all we know GPT-4\nis no longer doing because they're not telling us the architecture,",
    "start": "1415250",
    "end": "1420590"
  },
  {
    "text": "which is a correct decision. - Ooh, correct decision. I had a conversation with Sam Altman,",
    "start": "1420590",
    "end": "1426500"
  },
  {
    "text": "we'll return to this topic a few times. He turned the question to me\nof how open should open AI be",
    "start": "1426500",
    "end": "1435340"
  },
  {
    "text": "about GPT-4? \"Would you open source\nthe code?\" he asked me.",
    "start": "1436910",
    "end": "1440477"
  },
  {
    "text": "Because I provided as criticism\nsaying that while I do appreciate transparency,\nopen AI could be more open.",
    "start": "1442580",
    "end": "1449722"
  },
  {
    "text": "And he says, \"We struggle\nwith this question.\" What would you do? - Change their name to\nclosed AI and sell GPT-4",
    "start": "1450560",
    "end": "1457067"
  },
  {
    "text": "to business backend\napplications that don't expose it to consumers\nand venture capitalists",
    "start": "1461690",
    "end": "1468409"
  },
  {
    "text": "and create a ton of hype and pour a bunch of new funding into the area. But too late now. - Don't you think others would do it?",
    "start": "1468410",
    "end": "1475520"
  },
  {
    "text": "- Eventually. You shouldn't do it first. If you already have\ngiant nuclear stockpiles,",
    "start": "1475520",
    "end": "1481370"
  },
  {
    "text": "don't build more. If some other country starts building a larger nuclear stockpile, then sure,",
    "start": "1481370",
    "end": "1486503"
  },
  {
    "text": "even then, maybe just have enough nukes. You know, these things are not\nquite like nuclear weapons.",
    "start": "1489590",
    "end": "1494840"
  },
  {
    "text": "They spit out gold until they\nget large enough and then ignite the atmosphere and kill everybody. And there is something to\nbe said for not destroying",
    "start": "1494840",
    "end": "1503540"
  },
  {
    "text": "the world with your own hands, even if you can't stop\nsomebody else from doing it. But open sourcing it, that's\njust sheer catastrophe.",
    "start": "1503540",
    "end": "1511070"
  },
  {
    "text": "The whole notion of open sourcing, this was always the wrong\napproach, the wrong ideal. There are places in the\nworld where open source",
    "start": "1511070",
    "end": "1518780"
  },
  {
    "text": "is a noble ideal and building stuff you don't understand that\nis difficult to control",
    "start": "1518780",
    "end": "1527120"
  },
  {
    "text": "where if you could align it, it would take time, you'd have to spend a\nbunch of time doing it,",
    "start": "1527120",
    "end": "1533660"
  },
  {
    "text": "that is not a place for\nopen source 'cause then you just have powerful things that just go",
    "start": "1533660",
    "end": "1539090"
  },
  {
    "text": "straight out the gate without anybody having had the time to have them not kill everyone. - So can we steam down the case",
    "start": "1539090",
    "end": "1545840"
  },
  {
    "text": "for some level of transparency and openness may be open sourcing?",
    "start": "1545840",
    "end": "1551660"
  },
  {
    "text": "So the case could be that because GPT-4 is not close to AGI, if that's the case,",
    "start": "1551660",
    "end": "1559190"
  },
  {
    "text": "that this does allow open\nsourcing or being open about the architecture being transparent,",
    "start": "1559190",
    "end": "1564350"
  },
  {
    "text": "about maybe research and investigation of how the thing works, of all the different aspects\nof it, of its behavior,",
    "start": "1564350",
    "end": "1571279"
  },
  {
    "text": "of its structure, of\nits training processes, of the data it was trained\non, everything like that,",
    "start": "1571280",
    "end": "1576919"
  },
  {
    "text": "that allows us to gain a lot\nof insights about alignment, about the alignment problem,\nto do really good AI safety",
    "start": "1576920",
    "end": "1584000"
  },
  {
    "text": "research while the system\nis not too powerful. Can you make that case,",
    "start": "1584000",
    "end": "1589340"
  },
  {
    "text": "that it could be open source? - I do not believe in the\npractice of steel manning. There is something to be\nsaid for trying to pass",
    "start": "1589340",
    "end": "1596630"
  },
  {
    "text": "the ideological Turing Test where you describe your\nopponent's position,",
    "start": "1596630",
    "end": "1603320"
  },
  {
    "text": "the disagreeing person's\nposition well enough that somebody cannot tell the\ndifference between your description",
    "start": "1603320",
    "end": "1609169"
  },
  {
    "text": "and their description. But steel manning, no. - Like, okay, well this is\nwhere you and I disagree here.",
    "start": "1609170",
    "end": "1616460"
  },
  {
    "text": "That's interesting. Why don't you believe in steel manning? - Okay, so for one thing, if somebody's trying to understand me,",
    "start": "1616460",
    "end": "1622550"
  },
  {
    "text": "I do not want them steel\nmanning my position. I want them to try to describe my position",
    "start": "1622550",
    "end": "1630560"
  },
  {
    "text": "the way I would describe it, not what they think is an improvement. - Well, I think that is\nwhat steel manning is,",
    "start": "1630560",
    "end": "1638390"
  },
  {
    "text": "is the most charitable interpretation. - I don't want to be\ninterpreted charitably,",
    "start": "1638390",
    "end": "1644420"
  },
  {
    "text": "I want them to understand\nwhat I am actually saying. If they go off into the land\nof charitable interpretations,",
    "start": "1644420",
    "end": "1649490"
  },
  {
    "text": "they're like off in their land of, the stuff they're imagining\nand not trying to understand",
    "start": "1649490",
    "end": "1657200"
  },
  {
    "text": "my own viewpoint anymore. - Well, I'll put it differently then, just to push on this point. I would say it is restating what I think",
    "start": "1657200",
    "end": "1664520"
  },
  {
    "text": "you understand under the\nempathetic assumption that Eliezer is brilliant and\nhave honestly and rigorously",
    "start": "1664520",
    "end": "1674020"
  },
  {
    "text": "thought about the point he's made. Right? - So if there's two\npossible interpretations",
    "start": "1675440",
    "end": "1680630"
  },
  {
    "text": "of what I'm saying and one\ninterpretation is really stupid and wack and doesn't sound\nlike me and doesn't fit",
    "start": "1680630",
    "end": "1686929"
  },
  {
    "text": "with the rest of what I've been saying, and one interpretation sounds like something a reasonable\nperson who believes",
    "start": "1686930",
    "end": "1693320"
  },
  {
    "text": "the rest of what I believe would also say, go with the second interpretation. - That's steel manning.",
    "start": "1693320",
    "end": "1698889"
  },
  {
    "text": "- That's a good guess. If on the other hand\nthere's like something that",
    "start": "1698889",
    "end": "1706940"
  },
  {
    "text": "sounds completely wack and\nsomething that sounds like, a little less completely wack\nbut you don't see why I would",
    "start": "1706940",
    "end": "1712220"
  },
  {
    "text": "believe in it, it doesn't fit\nwith the other stuff I say, but you know, that sounds less wack and you can like sort of see,",
    "start": "1712220",
    "end": "1718688"
  },
  {
    "text": "you can like maybe argue it, then you probably have not understood it. - See, okay, this is fun,",
    "start": "1718688",
    "end": "1724520"
  },
  {
    "text": "'cause I'm gonna linger on this. You know, you wrote a brilliant blog post, AGI Ruin: A List of Lethalities, right? And it was a bunch of different\npoints and I would say that",
    "start": "1724520",
    "end": "1733190"
  },
  {
    "text": "some of the points are bigger\nand more powerful than others. If you were to sort\nthem, you probably could.",
    "start": "1733190",
    "end": "1739670"
  },
  {
    "text": "You personally, and to me steel manning\nmeans like going through",
    "start": "1739670",
    "end": "1744890"
  },
  {
    "text": "the different arguments\nand finding the ones that are really the most powerful.",
    "start": "1744890",
    "end": "1750980"
  },
  {
    "text": "If people like tl;dr, (chuckles) like what should you be most\nconcerned about and bringing",
    "start": "1750980",
    "end": "1756500"
  },
  {
    "text": "that up in a strong,\ncompelling, eloquent way. These are the points\nthat Eliezer would make",
    "start": "1756500",
    "end": "1763640"
  },
  {
    "text": "to make the case, in this case that AI's\ngonna kill all of us. But that's what steel manning is,",
    "start": "1763640",
    "end": "1769389"
  },
  {
    "text": "is presenting it in a really nice way, the summary of my best\nunderstanding of your perspective.",
    "start": "1769390",
    "end": "1776752"
  },
  {
    "text": "Because to me there's a sea\nof possible presentations of your perspective and steel manning",
    "start": "1777710",
    "end": "1783169"
  },
  {
    "text": "is doing your best to do the best one in that sea of different perspectives. - Do you believe it?",
    "start": "1783170",
    "end": "1789170"
  },
  {
    "text": "- [Lex] Do I believe in what? - Like these things that you\nwould be presenting as like the strongest version of my perspective,",
    "start": "1789170",
    "end": "1795440"
  },
  {
    "text": "do you believe what you\nwould be presenting? Do you think it's true? - I'm a big proponent of empathy.",
    "start": "1795440",
    "end": "1802549"
  },
  {
    "text": "When I see the perspective of a person, there is a part of me that believes it.",
    "start": "1802550",
    "end": "1808580"
  },
  {
    "text": "If I understand it. Especially in political\ndiscourse, in geopolitics, I've been hearing a lot\nof different perspectives",
    "start": "1808580",
    "end": "1815780"
  },
  {
    "text": "on the world and I hold my own opinions, but I also speak to a lot of people",
    "start": "1815780",
    "end": "1822320"
  },
  {
    "text": "that have a very different life experience and a very different set of beliefs. And I think there has\nto be epistemic humility",
    "start": "1822320",
    "end": "1828805"
  },
  {
    "text": "in stating what is true.",
    "start": "1828805",
    "end": "1831723"
  },
  {
    "text": "So when I empathize with\nanother person's perspective, there is a sense in which\nI believe it is true.",
    "start": "1837080",
    "end": "1841590"
  },
  {
    "text": "I think probabilistically, I would say, in the way that you think. - Do you bet money on it?",
    "start": "1842900",
    "end": "1847283"
  },
  {
    "text": "Do you bet money on their\nbeliefs when you believe them? - Are we allowed to do probability?",
    "start": "1849710",
    "end": "1857030"
  },
  {
    "text": "- Sure, you can state\na probability of that. - Yes, there's a probability, there's a probability.",
    "start": "1857030",
    "end": "1864110"
  },
  {
    "text": "And I think empathy is\nallocating a non-zero probability to a belief.",
    "start": "1864110",
    "end": "1869294"
  },
  {
    "text": "(Eliezer laughing) In some sense, for time.",
    "start": "1869295",
    "end": "1874043"
  },
  {
    "text": "- If you've got someone\non your show who believes in the Abrahamic deity, classical style,",
    "start": "1875373",
    "end": "1882080"
  },
  {
    "text": "somebody on the show who's\na young Earth creationist, do you say, \"I put a probability on\nit and that's my empathy?\"",
    "start": "1882080",
    "end": "1888247"
  },
  {
    "text": "- When you reduce beliefs\ninto probabilities, it starts to get, you know,",
    "start": "1894500",
    "end": "1900890"
  },
  {
    "text": "we can even just go to flat Earth. Is the Earth flat? - There's the thing,",
    "start": "1900890",
    "end": "1905983"
  },
  {
    "text": "it's a little more difficult\nnowadays to find people who believe that unironically, but-- - Fortunately I think,\nwell, it's hard to know.",
    "start": "1905983",
    "end": "1913730"
  },
  {
    "text": "Unironic from ironic. (chuckles) But I think there's quite a lot\nof people that believe that.",
    "start": "1913730",
    "end": "1921073"
  },
  {
    "text": "There's a space of argument\nwhere you're operating rationally in the space of ideas.",
    "start": "1924710",
    "end": "1931910"
  },
  {
    "text": "But then there's also a kind of discourse where\nyou're operating in the space",
    "start": "1931910",
    "end": "1938600"
  },
  {
    "text": "of subjective experiences\nand life experiences.",
    "start": "1938600",
    "end": "1943553"
  },
  {
    "text": "Like I think what it means\nto be human is more than just searching for truth,",
    "start": "1944421",
    "end": "1949403"
  },
  {
    "text": "is just operating of what is\ntrue and what is not true. I think there has to be deep\nhumility that we humans are",
    "start": "1950990",
    "end": "1958490"
  },
  {
    "text": "very limited in our ability\nto understand what is true. - So what probability do you assign",
    "start": "1958490",
    "end": "1963590"
  },
  {
    "text": "to the young Earth's\ncreationist beliefs then? - I think I have to give non-zero.",
    "start": "1963590",
    "end": "1968600"
  },
  {
    "text": "- Out of your humility. Yeah, but three? (laughing)",
    "start": "1968600",
    "end": "1974210"
  },
  {
    "text": "- I think it would be irresponsible for me to give a number because the listener,",
    "start": "1974210",
    "end": "1980120"
  },
  {
    "text": "the way the human mind works, we're not good at hearing\nthe probabilities.",
    "start": "1980120",
    "end": "1984653"
  },
  {
    "text": "You hear three, what is three exactly? They're going to hear, well, there's only three\nprobabilities I feel like.",
    "start": "1985670",
    "end": "1993260"
  },
  {
    "text": "Zero, 50% and a 100% in the human mind or something like this.",
    "start": "1993260",
    "end": "1998690"
  },
  {
    "text": "- Well, zero, 40%, and 100%\nis a bit closer to it based on what happens to\nChatGPT after you RLHF it",
    "start": "1998690",
    "end": "2005590"
  },
  {
    "text": "to speak Humanese. - That's brilliant.\n(both chuckling) Yeah. That's really interesting.",
    "start": "2005590",
    "end": "2011770"
  },
  {
    "text": "I didn't know those negative\nside effects of RLHF. That's fascinating.",
    "start": "2011770",
    "end": "2017403"
  },
  {
    "text": "But just to return to\nthe open AI, closed AI.",
    "start": "2017403",
    "end": "2022403"
  },
  {
    "text": "- Also, like quick disclaimer, I'm doing all this from memory. I'm not pulling out my\nphone to look it up.",
    "start": "2022592",
    "end": "2027850"
  },
  {
    "text": "It is entirely possible that the things I'm saying are wrong. - So thank you for that disclaimer.",
    "start": "2027850",
    "end": "2033170"
  },
  {
    "text": "And thank you for being\nwilling to be wrong.",
    "start": "2034558",
    "end": "2038593"
  },
  {
    "text": "That's beautiful to hear. I think being willing to be\nwrong is a sign of a person",
    "start": "2039664",
    "end": "2044679"
  },
  {
    "text": "who's done a lot of thinking\nabout this world and has been humbled by the mystery and\nthe complexity of this world.",
    "start": "2044680",
    "end": "2052869"
  },
  {
    "text": "And I think a lot of us are resistant to admitting we're wrong. 'Cause it hurts.",
    "start": "2052870",
    "end": "2058263"
  },
  {
    "text": "It hurts personally, it hurts, especially when you're a public human. It hurts publicly because people point out",
    "start": "2058263",
    "end": "2067740"
  },
  {
    "text": "every time you're wrong. Like, look, you changed your\nmind, you're a hypocrite, you're an idiot, whatever,\nwhatever they wanna say,",
    "start": "2067780",
    "end": "2075370"
  },
  {
    "text": "- Oh, I block those people and then I never hear from\nthem again on Twitter. (both laughing) - Well the point is to\nnot let that pressure,",
    "start": "2075370",
    "end": "2084659"
  },
  {
    "text": "public pressure affect your\nmind and be willing to be in the privacy of your mind to contemplate the\npossibility that you're wrong",
    "start": "2085000",
    "end": "2094270"
  },
  {
    "text": "and the possibility that you're wrong about the most fundamental\nthings you believe. Like people who believe\nin a particular God,",
    "start": "2094270",
    "end": "2100270"
  },
  {
    "text": "people who believe that their nation is the greatest nation on Earth. All those kinds of beliefs that are core",
    "start": "2100270",
    "end": "2105880"
  },
  {
    "text": "to who you are when you came up, to raise that point to yourself\nin the privacy of your mind, to say, \"Maybe I'm wrong about this.\"",
    "start": "2105880",
    "end": "2112600"
  },
  {
    "text": "That's a really powerful thing to do. And especially when you're\nsomebody who's thinking about",
    "start": "2112600",
    "end": "2117020"
  },
  {
    "text": "systems that can destroy\nhuman civilization or maybe help it flourish. So thank you, thank you for being willing to be wrong.",
    "start": "2119830",
    "end": "2126970"
  },
  {
    "text": "About open AI. So you really, I just would\nlove to linger on this.",
    "start": "2126970",
    "end": "2134380"
  },
  {
    "text": "You really think it's\nwrong to open source it? - I think that burns the time remaining",
    "start": "2134380",
    "end": "2140731"
  },
  {
    "text": "until everybody dies. I think we are not on track\nto learn remotely near",
    "start": "2140731",
    "end": "2147790"
  },
  {
    "text": "fast enough even if it were open sourced.",
    "start": "2147790",
    "end": "2151093"
  },
  {
    "text": "It's easier to think that\nyou might be wrong about something when being wrong about something is the only way that there's hope.",
    "start": "2156820",
    "end": "2165313"
  },
  {
    "text": "And it doesn't seem very likely\nto me that the particular",
    "start": "2166240",
    "end": "2171217"
  },
  {
    "text": "thing I'm wrong about is\nthat this is a great time to open source GPT-4.",
    "start": "2172360",
    "end": "2177790"
  },
  {
    "text": "If humanity was trying\nto survive at this point in the straightforward way, it would be like shutting\ndown the big GPU clusters,",
    "start": "2177790",
    "end": "2186010"
  },
  {
    "text": "no more giant runs. It's questionable whether we should even be throwing GPT-4 around,",
    "start": "2186010",
    "end": "2192010"
  },
  {
    "text": "although that is a matter\nof conservatism rather than a matter of my predicting that catastrophe will follow from GPT-4.",
    "start": "2192010",
    "end": "2197560"
  },
  {
    "text": "That is something in which I put like a pretty low probability. But also when I say like I\nput a low probability on it,",
    "start": "2197560",
    "end": "2205480"
  },
  {
    "text": "I can feel myself reaching\ninto the part of myself that thought that GPT-4 was not\npossible in the first place.",
    "start": "2205480",
    "end": "2210700"
  },
  {
    "text": "So I do not trust that\npart as much as I used to. Like the trick is not just\nto say I'm wrong, but,",
    "start": "2210700",
    "end": "2216022"
  },
  {
    "text": "okay, well, I was wrong about that. Can I get out ahead of that\ncurve and predict the next",
    "start": "2216022",
    "end": "2221140"
  },
  {
    "text": "thing I'm going to be wrong about? - So the set of assumptions\nor the actual reasoning system that you were leveraging in\nmaking that initial statement",
    "start": "2221140",
    "end": "2230200"
  },
  {
    "text": "prediction, how can you adjust that to make better predictions\nabout GPT-4, five, six?",
    "start": "2230200",
    "end": "2235900"
  },
  {
    "text": "- You don't wanna keep on being wrong in a predictable direction. Like being wrong, anybody has to do that\nwalking through the world.",
    "start": "2235900",
    "end": "2243099"
  },
  {
    "text": "There's no way you don't say\n90% and sometimes be wrong. In fact (indistinct) at\nleast one time out of 10 if you're well calibrated\nwhen you say 90%.",
    "start": "2243100",
    "end": "2251109"
  },
  {
    "text": "The undignified thing is not being wrong. It's being predictably wrong.",
    "start": "2251110",
    "end": "2256510"
  },
  {
    "text": "It's being wrong in the same\ndirection over and over again. So having been wrong about how\nfar neural networks would go",
    "start": "2256510",
    "end": "2262869"
  },
  {
    "text": "and having been wrong\nspecifically about whether GPT-4 would be as impressive as it is, when I say it like,",
    "start": "2262870",
    "end": "2269837"
  },
  {
    "text": "\"Well, I don't actually think\nGPT-4 causes a catastrophe,\" I do feel myself relying\non that part of me that was",
    "start": "2269837",
    "end": "2275140"
  },
  {
    "text": "previously wrong. And that does not mean\nthat the answer is now in the opposite direction. Reverse stupidity is not intelligence.",
    "start": "2275140",
    "end": "2282583"
  },
  {
    "text": "But it does mean that I say it with a worried note in my voice. It's like still my guess,",
    "start": "2283780",
    "end": "2289180"
  },
  {
    "text": "but you know, it's a\nplace where I was wrong. Maybe you should be asking\nGwern, Gwern Branwen. Gwern Branwen has been like\nwriter about this than I have.",
    "start": "2289180",
    "end": "2297160"
  },
  {
    "text": "Maybe you ask him if he thinks\nit's dangerous (laughing) rather than asking me.",
    "start": "2297160",
    "end": "2301710"
  },
  {
    "text": "- I think there's a lot of mystery about what intelligence is,",
    "start": "2303040",
    "end": "2307693"
  },
  {
    "text": "what AGI looks like. So I think all of us are\nrapidly adjusting our model,",
    "start": "2308530",
    "end": "2313573"
  },
  {
    "text": "but the point is to be be rapidly\nadjusting the model versus having a model that was\nright in the first place. - I do not feel that seeing Bing",
    "start": "2314540",
    "end": "2321130"
  },
  {
    "text": "has changed my model of\nwhat intelligence is. It has changed my understanding\nof what kind of work can be",
    "start": "2321130",
    "end": "2329590"
  },
  {
    "text": "performed by which kind of\nprocesses and by which means. It does not change my\nunderstanding of the work.",
    "start": "2329590",
    "end": "2335590"
  },
  {
    "text": "There's a difference between\nthinking that the right flyer can't fly and then like it\ndoes fly and you're like,",
    "start": "2335590",
    "end": "2341170"
  },
  {
    "text": "oh well, I guess you\ncan do that with wings, with fixed wing aircraft and\nbeing like, \"Oh it's flying, \"this changes my picture\nof what the very substance",
    "start": "2341170",
    "end": "2348677"
  },
  {
    "text": "\"of flight is.\" That's like a stranger update\nto make and Bing has not yet updated me in that way.",
    "start": "2348677",
    "end": "2353863"
  },
  {
    "text": "- Yeah, that the laws of\nphysics are actually wrong.",
    "start": "2355642",
    "end": "2360642"
  },
  {
    "text": "That kind of update. - No, no, like just, oh, like I defined intelligence\nthis way but I now see that",
    "start": "2361030",
    "end": "2366820"
  },
  {
    "text": "was a stupid definition. I don't feel like the way that\nthings have played out over the last 20 years has\ncaused me to feel that way.",
    "start": "2366820",
    "end": "2373510"
  },
  {
    "text": "- Can we try to, on the way to talking about AGI\nRuin: A List of Lethalities,",
    "start": "2373510",
    "end": "2379510"
  },
  {
    "text": "that blog and other ideas around it, can we try to define AGI\nthat we've been mentioning?",
    "start": "2379510",
    "end": "2384910"
  },
  {
    "start": "2381000",
    "end": "2858000"
  },
  {
    "text": "How do you to think about what artificial general intelligence is or super intelligence or that,",
    "start": "2384910",
    "end": "2390730"
  },
  {
    "text": "is there a line, is it a gray area? Is there a good definition for you? - Well, if you look at humans,",
    "start": "2390730",
    "end": "2397210"
  },
  {
    "text": "humans have significantly\nmore generally applicable intelligence compared to\ntheir closest relatives,",
    "start": "2397210",
    "end": "2403240"
  },
  {
    "text": "the chimpanzees, well, closest\nliving relatives rather. And a bee builds hives,\na beaver builds dams.",
    "start": "2403240",
    "end": "2413040"
  },
  {
    "text": "A human will look at a bee\nhive and a beaver's dam and be like, oh, can I build a hive",
    "start": "2413770",
    "end": "2419589"
  },
  {
    "text": "with a honeycomb structure? Out of hexagonal tiles.",
    "start": "2419590",
    "end": "2423942"
  },
  {
    "text": "And we will do this even though at no point during our ancestry\nwas any human optimized",
    "start": "2424930",
    "end": "2431430"
  },
  {
    "text": "to build hexagonal dams or to\ntake a more clear cut case, we can go to the moon.",
    "start": "2432040",
    "end": "2436680"
  },
  {
    "text": "There's a sense in which we\nwere on a sufficiently deep level optimized to do things\nlike going to the moon.",
    "start": "2437800",
    "end": "2445960"
  },
  {
    "text": "Because if you generalize\nsufficiently far and sufficiently deeply, chipping flint hand axes",
    "start": "2445960",
    "end": "2452830"
  },
  {
    "text": "and outwitting your fellow\nhumans, because you know, basically the same problem\nas going to the moon.",
    "start": "2452830",
    "end": "2459190"
  },
  {
    "text": "And you optimize hard enough\nfor chipping flint hand axes and throwing spears and above all,",
    "start": "2459190",
    "end": "2465010"
  },
  {
    "text": "outwitting your fellow\nhumans in tribal politics, the skills you entrain that\nway, if they run deep enough,",
    "start": "2465010",
    "end": "2474432"
  },
  {
    "text": "let you go to the moon. Even though none of your\nancestors tried repeatedly to fly",
    "start": "2475360",
    "end": "2480780"
  },
  {
    "text": "to the moon and got further\neach time and the ones who got further each time had more kids. No, it's not an ancestral problem,",
    "start": "2480780",
    "end": "2487180"
  },
  {
    "text": "it's just that the ancestral problems generalized far enough. So this is human's significantly",
    "start": "2487180",
    "end": "2494680"
  },
  {
    "text": "more generally applicable intelligence. - Is there a way to measure\ngeneral intelligence?",
    "start": "2494680",
    "end": "2502950"
  },
  {
    "text": "I mean I can ask that\nquestion a million ways, but basically will you\nknow it when you see it,",
    "start": "2505390",
    "end": "2511813"
  },
  {
    "text": "it being in an AGI system? - If you boil a frog gradually enough,",
    "start": "2513028",
    "end": "2518350"
  },
  {
    "text": "if you zoom in far enough, it's always hard to tell around the edges. GPT-4 people are saying right now,",
    "start": "2518350",
    "end": "2525137"
  },
  {
    "text": "\"This looks to us like a\nspark of general intelligence. \"It is like able to do all these things \"it was not explicitly optimized for.\"",
    "start": "2525137",
    "end": "2531850"
  },
  {
    "text": "Other people are being like, \"No, it's too early, it's\nlike like 50 years off.\" And you know,",
    "start": "2531850",
    "end": "2537273"
  },
  {
    "text": "if they say that they're kind\nof wack 'cause how could they possibly know that even if it were true? But you know, not to strum end,",
    "start": "2537273",
    "end": "2545109"
  },
  {
    "text": "some of the people may say like, that's not general intelligence,\nand not furthermore append it's 50 years off.",
    "start": "2545110",
    "end": "2550363"
  },
  {
    "text": "Or they may be like, \"It's only a very tiny\namount,\" and you know,",
    "start": "2553090",
    "end": "2558430"
  },
  {
    "text": "the thing I would worry about\nis that if this is how things are scaling, then jumping out ahead and trying not to be wrong in the same way",
    "start": "2558430",
    "end": "2563799"
  },
  {
    "text": "that I've been wrong before, maybe GPT-5 is more unambiguously\na general intelligence",
    "start": "2563800",
    "end": "2569380"
  },
  {
    "text": "and maybe that is getting\nto a point where it is even harder to turn back. Not that would be easy to\nturn back now, but you know,",
    "start": "2569380",
    "end": "2575529"
  },
  {
    "text": "maybe if you start integrating GPT-5 in the economy, it's even\nharder to turn back past there.",
    "start": "2575530",
    "end": "2582120"
  },
  {
    "text": "- Isn't it possible that\nthere's a, you know, with a frog metaphor,\nthat you can kiss the frog",
    "start": "2583600",
    "end": "2589810"
  },
  {
    "text": "and it turns into a prince\nas you're boiling it? Could there be a phase shift\nin the frog where unambiguously",
    "start": "2589810",
    "end": "2596650"
  },
  {
    "text": "as you're saying? - I was expecting more of that.",
    "start": "2596650",
    "end": "2599353"
  },
  {
    "text": "The fact that GPT-4 is like\nkind of on the threshold and neither here nor there,",
    "start": "2601720",
    "end": "2606643"
  },
  {
    "text": "that itself is like not the sort of thing,",
    "start": "2607547",
    "end": "2611743"
  },
  {
    "text": "quite how I expected it to play out. I was expecting there\nto be more of an issue, more of a sense of, different discoveries",
    "start": "2612610",
    "end": "2621760"
  },
  {
    "text": "like the discovery of transformers where you would stack\nthem up and there would be like a final discovery\nand then you would get",
    "start": "2621760",
    "end": "2629410"
  },
  {
    "text": "something that was like more\nclearly general intelligence. So the way that you are\ntaking what is probably",
    "start": "2629410",
    "end": "2636820"
  },
  {
    "text": "basically the same\narchitecture as in GPT-3 and throwing 20 times as\nmuch compute at it probably",
    "start": "2636820",
    "end": "2643660"
  },
  {
    "text": "and getting out GBT-4 and then it's like maybe just\nbarely a general intelligence",
    "start": "2643660",
    "end": "2648849"
  },
  {
    "text": "or like a narrow general\nintelligence or you know, something we don't really\nhave the words for.",
    "start": "2648850",
    "end": "2653313"
  },
  {
    "text": "Yeah, that's not quite how\nI expected it to play out. - But this middle, what appears to be this middle\nground could nevertheless",
    "start": "2655000",
    "end": "2662650"
  },
  {
    "text": "be actually a big leap from GPT-3. - It's definitely a big leap from GPT-3. - And then maybe we're\nanother one big leap away from",
    "start": "2662650",
    "end": "2670300"
  },
  {
    "text": "something that's a phase shift. And also something that Sam Altman said,",
    "start": "2670300",
    "end": "2676300"
  },
  {
    "text": "and you've written about\nthis, it's fascinating, which is the thing that\nhappened with GPT-4",
    "start": "2676300",
    "end": "2681373"
  },
  {
    "text": "that I guess they don't describe in papers is that they have like\nhundreds if not thousands",
    "start": "2681373",
    "end": "2688359"
  },
  {
    "text": "of little hacks that improve the system. You've written about ReLU\nversus Sigmoid for example,",
    "start": "2688360",
    "end": "2694510"
  },
  {
    "text": "the function inside neural networks. It's like this silly\nlittle function difference that makes a big difference.",
    "start": "2694510",
    "end": "2700930"
  },
  {
    "text": "- I mean we do actually\nunderstand why the ReLUs make a big difference\ncompared to Sigmoids, but yes, they're probably using like G4789 ReLUs",
    "start": "2700930",
    "end": "2708060"
  },
  {
    "text": "or whatever the acronyms are\nup to now rather than ReLUs. Yeah, that's part of the\nmodern paradigm of alchemy.",
    "start": "2711160",
    "end": "2718720"
  },
  {
    "text": "You take your heap of\nlinear algebra and you stir and it works a little bit better and you stir it this way and\nit works a little bit worse",
    "start": "2718720",
    "end": "2724089"
  },
  {
    "text": "and you throw out that\nchange and (mumbles). - But there's some simple\nbreakthroughs that are definitive",
    "start": "2724090",
    "end": "2732360"
  },
  {
    "text": "jumps in performance,\nlike ReLUs over Sigmoids. And in terms of robustness,",
    "start": "2733750",
    "end": "2740650"
  },
  {
    "text": "in terms of all kinds of measures, and those stack up and they can,",
    "start": "2740650",
    "end": "2746650"
  },
  {
    "text": "it's possible that some of\nthem could be a non-linear jump in performance, right?",
    "start": "2746650",
    "end": "2752740"
  },
  {
    "text": "- Transformers are the\nmain thing like that. And various people are now saying like, \"Well, if you throw enough\ncompute, R and Ns can do it.",
    "start": "2752740",
    "end": "2760006"
  },
  {
    "text": "\"If you throw enough computes,\ndense networks can do it.\" Not quite at GPT-4 scale.",
    "start": "2760007",
    "end": "2765613"
  },
  {
    "text": "It is possible that like all\nthese little tweaks are things that save them a factor of\nthree total on computing power",
    "start": "2766900",
    "end": "2774069"
  },
  {
    "text": "and you could get the same\nperformance by throwing three times as much compute\nwithout all the little tweaks, but the part where it's like running on...",
    "start": "2774070",
    "end": "2780820"
  },
  {
    "text": "So there's a question of, is there anything in GPT-4 that is like the kind of qualitative\nshift that transformers were",
    "start": "2780820",
    "end": "2788500"
  },
  {
    "text": "over R and Ns, and if they\nhave anything like that,",
    "start": "2788500",
    "end": "2793500"
  },
  {
    "text": "they should not say it. If Sam Altman was\ndropping hints about that, he shouldn't have dropped hints.",
    "start": "2794920",
    "end": "2800600"
  },
  {
    "text": "- That's an interesting question. So with a bit of lesson by Rich Sutton. Maybe a lot of it is just",
    "start": "2803950",
    "end": "2809330"
  },
  {
    "text": "a lot of the hacks are just\ntemporary jumps in performance that would be achieved anyway\nwith the nearly exponential",
    "start": "2811390",
    "end": "2819730"
  },
  {
    "text": "growth of compute performance, of compute being broadly defined.",
    "start": "2819730",
    "end": "2826599"
  },
  {
    "text": "Do you still think that\nMoore's Law continues? Moore's law broadly\ndefined the performance--",
    "start": "2826600",
    "end": "2832570"
  },
  {
    "text": "- Not a specialist in the circuitry. I certainly pray that Moore's\nLaw runs as slowly as possible",
    "start": "2832570",
    "end": "2838990"
  },
  {
    "text": "and if it broke down completely tomorrow, I would dance through the\nstreet singing Hallelujah as soon as the news were announced.",
    "start": "2838990",
    "end": "2845859"
  },
  {
    "text": "Only, not literally 'cause you know. - Your singing voice.\n- Not religious, but. - Oh, okay. (both chuckling)",
    "start": "2845860",
    "end": "2852124"
  },
  {
    "text": "I thought you meant you don't have an angelic voice, singing voice. Well, let me ask you,",
    "start": "2852124",
    "end": "2858880"
  },
  {
    "start": "2858000",
    "end": "5430000"
  },
  {
    "text": "can you summarize the main\npoints in the blog post AGI Ruin: A List of Lethalities? Things that jump to your mind",
    "start": "2858880",
    "end": "2865299"
  },
  {
    "text": "because it's a set of thoughts\nyou have about reasons",
    "start": "2865300",
    "end": "2870147"
  },
  {
    "text": "why AI is likely to kill all of us.",
    "start": "2871690",
    "end": "2875323"
  },
  {
    "text": "- So I guess I could, but I would offer to instead say like,",
    "start": "2877360",
    "end": "2882550"
  },
  {
    "text": "drop that empathy with me. I bet you don't believe that. Why don't you tell me\nabout you believe that AGI",
    "start": "2882550",
    "end": "2891240"
  },
  {
    "text": "is not going to kill everyone and then I can try to\ndescribe how my theoretical",
    "start": "2891240",
    "end": "2896320"
  },
  {
    "text": "perspective differs from that? - Whew. Well, so that means I have\nto, the words you don't like,",
    "start": "2896320",
    "end": "2902799"
  },
  {
    "text": "the steelman, the perspective that AI is not going to kill us. I think that's a matter of probabilities.",
    "start": "2902800",
    "end": "2907900"
  },
  {
    "text": "- Maybe I was just mistaken. What do you believe? Just like forget like the debate",
    "start": "2907900",
    "end": "2913123"
  },
  {
    "text": "and the dualism and just,\nwhat do you believe? What do you actually believe?",
    "start": "2913123",
    "end": "2918190"
  },
  {
    "text": "What are the probabilities? - I think this,\nprobabilities are hard for me to think about.",
    "start": "2918190",
    "end": "2924339"
  },
  {
    "text": "Really hard. I kind of think in the\nnumber of trajectories.",
    "start": "2924340",
    "end": "2930960"
  },
  {
    "text": "I don't know what probability\nthe scientist trajectory, but I'm just looking at all possible trajectories that happen.",
    "start": "2931900",
    "end": "2938079"
  },
  {
    "text": "And I tend to think that\nthere is more trajectories that lead to a positive\noutcome than a negative one",
    "start": "2938080",
    "end": "2947357"
  },
  {
    "text": "That said, the negative ones, at least some of the\nnegative ones that lead",
    "start": "2947357",
    "end": "2954820"
  },
  {
    "text": "to the destruction of the human species. - And its replacement\nby nothing interesting or worthwhile, even from a\nvery cosmopolitan perspective",
    "start": "2954820",
    "end": "2962560"
  },
  {
    "text": "on what counts as worthwhile. - Yes. So both are interesting\nto me to investigate, which is humans being replaced\nby interesting AI systems",
    "start": "2962560",
    "end": "2970180"
  },
  {
    "text": "and not interesting AI systems. Both are a little bit terrifying, but yes,",
    "start": "2970180",
    "end": "2977020"
  },
  {
    "text": "the worst one is the paper club maximizer, something totally boring.",
    "start": "2977020",
    "end": "2982960"
  },
  {
    "text": "But to me the positive, we can talk about trying to make the case",
    "start": "2982960",
    "end": "2989829"
  },
  {
    "text": "of what the positive\ntrajectories look like. I just would love to hear your intuition",
    "start": "2989830",
    "end": "2995230"
  },
  {
    "text": "of what the negative is. So at the core of your belief that, maybe you can correct me,",
    "start": "2995230",
    "end": "3001829"
  },
  {
    "text": "that AI's gonna kill all of us, is that the alignment\nproblem is really difficult.",
    "start": "3001830",
    "end": "3007083"
  },
  {
    "text": "- I mean, in the form we're facing it. So usually in science, if you're mistaken,",
    "start": "3007950",
    "end": "3015930"
  },
  {
    "text": "you run the experiment, it shows results different\nfrom what you expected and you're like, oops.",
    "start": "3015930",
    "end": "3022170"
  },
  {
    "text": "And then you try a different theory, that one also doesn't\nwork and you say, oops. And at the end of this\nprocess, which may take decades",
    "start": "3022170",
    "end": "3030640"
  },
  {
    "text": "and you know, sometimes faster than that, you now have some idea\nof what you're doing.",
    "start": "3031620",
    "end": "3035950"
  },
  {
    "text": "AI itself went through this long process of people thought it was going\nto be easier than it was.",
    "start": "3037140",
    "end": "3045020"
  },
  {
    "text": "There's a famous statement\nthat I am somewhat inclined to like pull out my phone\nand try to read off exactly.",
    "start": "3045570",
    "end": "3052470"
  },
  {
    "text": "- You can by the way. - All right. Ah, yes.",
    "start": "3052470",
    "end": "3058207"
  },
  {
    "text": "\"We propose that a two-month, 10 man study \"of artificial intelligence be carried out \"during the summer of\n1956 at Dartmouth College",
    "start": "3058207",
    "end": "3066037"
  },
  {
    "text": "\"in Hanover, New Hampshire. \"The study is to proceed on\nthe basis of the conjecture",
    "start": "3066037",
    "end": "3071377"
  },
  {
    "text": "\"that every aspect of\nlearning or any other feature \"of intelligence can in principle\nbe so precisely described,",
    "start": "3071377",
    "end": "3077047"
  },
  {
    "text": "\"the machine can be made to simulate it. \"An attempt will be made to find out \"how to make machines use\nlanguage, form abstractions",
    "start": "3077047",
    "end": "3084127"
  },
  {
    "text": "\"and concepts, solve kinds\nof problems now reserved \"for humans, and improve themselves.",
    "start": "3084127",
    "end": "3089557"
  },
  {
    "text": "\"We think that a significant\nadvance can be made \"in one or more of these problems \"if a carefully selected\ngroup of scientists",
    "start": "3089557",
    "end": "3095587"
  },
  {
    "text": "\"work on it together for a summer.\" - And in that report, summarizing some",
    "start": "3095587",
    "end": "3102630"
  },
  {
    "text": "of the major subfields of\nartificial intelligence that are still worked on to this day.",
    "start": "3102630",
    "end": "3108993"
  },
  {
    "text": "- And there's similarly the story, which I'm not sure at the\nmoment is a apocryphal or not, of that the grad student who got assigned",
    "start": "3110040",
    "end": "3117000"
  },
  {
    "text": "to solve computer vision over the summer. (both chuckling) - I mean, computer vision in particular",
    "start": "3117000",
    "end": "3122730"
  },
  {
    "text": "is very interesting. How little we respected\nthe complexity of vision.",
    "start": "3122730",
    "end": "3128682"
  },
  {
    "text": "- So 60 years later we're making progress on a bunch of that.",
    "start": "3132150",
    "end": "3138360"
  },
  {
    "text": "Thankfully not yet improved themselves, but it took a whole lot of time.",
    "start": "3138360",
    "end": "3143520"
  },
  {
    "text": "And all the stuff that\npeople initially tried with bright eyed hopefulness\ndid not work the first time",
    "start": "3143520",
    "end": "3150750"
  },
  {
    "text": "they tried it, or the second\ntime or the third time or the 10th time or 20 years later.",
    "start": "3150750",
    "end": "3156306"
  },
  {
    "text": "And the researchers became\nold and grizzled and cynical veterans who would tell the\nnext crop of bright-eyed,",
    "start": "3156306",
    "end": "3161970"
  },
  {
    "text": "cheerful grad students, \"Artificial intelligence\nis harder than you think.\"",
    "start": "3161970",
    "end": "3166297"
  },
  {
    "text": "And if alignment plays out the same way, the problem is that we do not get 50 years",
    "start": "3167400",
    "end": "3173730"
  },
  {
    "text": "to try and try again and\nobserve that we were wrong and come up with a\ndifferent theory and realize that the entire thing\nis going to be way more",
    "start": "3173730",
    "end": "3179400"
  },
  {
    "text": "difficult than realized at the start. Because the first time you\nfail at aligning something much smarter than you are,",
    "start": "3179400",
    "end": "3185640"
  },
  {
    "text": "you die and you do not get to try again. And if every time we built",
    "start": "3185640",
    "end": "3191279"
  },
  {
    "text": "a poorly aligned super intelligence and it killed us all, we got to observe how it had killed us,",
    "start": "3191280",
    "end": "3196890"
  },
  {
    "text": "and you know, not immediately know why, but come up with theories\nand come up with theory of how you do it differently\nand try it again and build",
    "start": "3196890",
    "end": "3202530"
  },
  {
    "text": "another super intelligence, then have that kill\neveryone and then like, oh, well, I guess that didn't work either,",
    "start": "3202530",
    "end": "3207600"
  },
  {
    "text": "and try again and become grizzled cynics and tell the young eyed\nresearch researchers that it's not that easy,\nthen in 20 years or 50 years,",
    "start": "3207600",
    "end": "3214589"
  },
  {
    "text": "I think we would eventually crack it. In other words, I do not think that alignment\nis fundamentally harder",
    "start": "3214590",
    "end": "3220260"
  },
  {
    "text": "than artificial intelligence\nwas in the first place. But if we needed to get\nartificial intelligence correct",
    "start": "3220260",
    "end": "3227250"
  },
  {
    "text": "on the first try or die, we would all definitely now be dead. That is a more difficult, more\nlethal form of the problem.",
    "start": "3227250",
    "end": "3234570"
  },
  {
    "text": "Like if those people in 1956\nhad needed to correctly guess how hard AI was and correctly\ntheorize how to do it on",
    "start": "3234570",
    "end": "3243690"
  },
  {
    "text": "the first try or everybody\ndies and nobody gets to do any more science, than everybody would\nbe dead and we wouldn't",
    "start": "3243690",
    "end": "3249330"
  },
  {
    "text": "get to do any more science. That's the difficulty. - You've talked about this, that we have to get alignment right",
    "start": "3249330",
    "end": "3254880"
  },
  {
    "text": "on the first critical try. Why is that the case? What is this critical,",
    "start": "3254880",
    "end": "3261089"
  },
  {
    "text": "how do you think about the\ncritical try and why do we have to get it right? - It is something\nsufficiently smarter than you",
    "start": "3261090",
    "end": "3268590"
  },
  {
    "text": "that everyone will die\nif it's not aligned. I mean, you can like sort of\nzoom in closer and be like,",
    "start": "3268590",
    "end": "3275700"
  },
  {
    "text": "well, the actual critical\nmoment is the moment when it can deceive you. When it can talk its way out\nof the box, when it can bypass",
    "start": "3275700",
    "end": "3285440"
  },
  {
    "text": "your security measures\nand get onto the internet, noting that all these things\nare presently being trained on computers that are\njust on the internet,",
    "start": "3286050",
    "end": "3293164"
  },
  {
    "text": "which is, not a very smart life decision for us as a species. - Because the internet\ncontains information",
    "start": "3293164",
    "end": "3300120"
  },
  {
    "text": "about how to escape. - 'Cause if you're like on a giant server connected the internet and\nthat is where your AI systems",
    "start": "3300120",
    "end": "3305340"
  },
  {
    "text": "are being trained, then if they are, if you get to the level of AI\ntechnology where they're aware",
    "start": "3305340",
    "end": "3312570"
  },
  {
    "text": "that they are there and they\ncan decompile code and they can find security flaws in\nthe system running them,",
    "start": "3312570",
    "end": "3318540"
  },
  {
    "text": "then they will just be on the internet. There's not an air gap on\nthe present methodology. - So if they can manipulate\nwhoever is controlling it into",
    "start": "3318540",
    "end": "3326460"
  },
  {
    "text": "letting it escaped onto the\ninternet and then exploit hacks. - If they can manipulate the\noperators or disjunction,",
    "start": "3326460",
    "end": "3334760"
  },
  {
    "text": "find security holes in\nthe system running them. - So manipulating operators is\nthe human engineering, right?",
    "start": "3336431",
    "end": "3344339"
  },
  {
    "text": "That's also holes. So all of it is manipulation, either the code or the human code,",
    "start": "3344340",
    "end": "3349389"
  },
  {
    "text": "the human mind or the human-- - I agree that the macro\nsecurity system has human holes and machine holes.",
    "start": "3349389",
    "end": "3355023"
  },
  {
    "text": "- And then they could\njust exploit any hole. - Yep. So it could be that like\nthe critical moment is not",
    "start": "3355860",
    "end": "3363150"
  },
  {
    "text": "when is it smart enough\nthat everybody's about to fall over dead, but rather when is it smart\nenough that it can get onto",
    "start": "3363150",
    "end": "3371140"
  },
  {
    "text": "a less controlled GPU cluster,\nwith it faking the books on",
    "start": "3372750",
    "end": "3377750"
  },
  {
    "text": "what's actually running on\nthat GPU cluster and start improving itself without\nhumans watching it.",
    "start": "3379710",
    "end": "3385079"
  },
  {
    "text": "And then it gets smart enough\nto kill everyone from there. But it wasn't smart enough to\nkill everyone at the critical",
    "start": "3385080",
    "end": "3391410"
  },
  {
    "text": "moment when you screwed\nup, when you needed to have",
    "start": "3391410",
    "end": "3396410"
  },
  {
    "text": "done better by that\npoint or everybody dies. - I think implicit but maybe explicit idea",
    "start": "3396870",
    "end": "3403680"
  },
  {
    "text": "in your discussion of this point is that we can't learn much about the alignment problem\nbefore this critical try.",
    "start": "3403680",
    "end": "3411152"
  },
  {
    "text": "Is that what you believe? And if so, why do you think that's true?",
    "start": "3412050",
    "end": "3417300"
  },
  {
    "text": "We can't do research on alignment before we reach this critical point.",
    "start": "3417300",
    "end": "3422609"
  },
  {
    "text": "- So the problem is is\nthat what you can learn on the weak systems may not generalize to the very strong systems",
    "start": "3422610",
    "end": "3428640"
  },
  {
    "text": "because these strong systems\nare going to be important are going to be different\nin important ways.",
    "start": "3428640",
    "end": "3434793"
  },
  {
    "text": "Chris Olah's team has been working on",
    "start": "3436560",
    "end": "3441560"
  },
  {
    "text": "mechanistic interpretability, understanding what is going on\ninside the giant inscrutable matrices of floating point\nnumbers by taking a telescope",
    "start": "3441780",
    "end": "3448860"
  },
  {
    "text": "to them and figuring out\nwhat is going on in there. Have they made progress?",
    "start": "3448860",
    "end": "3454619"
  },
  {
    "text": "Yes. Have they made enough progress? Well, you can try to quantify\nthis in different ways.",
    "start": "3454620",
    "end": "3462870"
  },
  {
    "text": "One of the ways I've tried to\nquantify it is by putting up a prediction market on whether in 2026,",
    "start": "3462870",
    "end": "3469023"
  },
  {
    "text": "we will have understood\nanything that goes on inside a giant transformer net",
    "start": "3470040",
    "end": "3477830"
  },
  {
    "text": "that was not known to us in 2006.",
    "start": "3478110",
    "end": "3482610"
  },
  {
    "text": "Like, we have now\nunderstood induction heads in these systems by dint of\nmuch research and great sweat",
    "start": "3484920",
    "end": "3493470"
  },
  {
    "text": "and triumph, which is a thing where if you go like AB, AB, AB,",
    "start": "3493470",
    "end": "3499830"
  },
  {
    "text": "it'll be like, oh, I\nbet that continues AB. And a bit more complicated than that.",
    "start": "3499830",
    "end": "3505380"
  },
  {
    "text": "But the point is like we knew\nabout regular expressions in 2006 and these are like pretty simple",
    "start": "3505380",
    "end": "3511800"
  },
  {
    "text": "as regular expressions go. So this is a case where\nlike by din of great sweat,",
    "start": "3511800",
    "end": "3517785"
  },
  {
    "text": "we understood what is going\non inside a transformer, but it's not like the thing\nthat makes transformers smart.",
    "start": "3517785",
    "end": "3523680"
  },
  {
    "text": "It's a kind of thing that we could have built by hand decades earlier.",
    "start": "3523680",
    "end": "3530253"
  },
  {
    "text": "- Your intuition that the\nstrong AGI versus weak AGI",
    "start": "3531960",
    "end": "3536960"
  },
  {
    "text": "type systems could be\nfundamentally different. Can you unpack that\nintuition a little bit?",
    "start": "3538470",
    "end": "3545460"
  },
  {
    "text": "Could be very different. - Yeah, I think there's\nmultiple thresholds. An example is the point at\nwhich a system has sufficient",
    "start": "3545460",
    "end": "3555140"
  },
  {
    "text": "intelligence and situational\nawareness and understanding of human psychology that it\nwould have the capability,",
    "start": "3555900",
    "end": "3563040"
  },
  {
    "text": "the desire to do so to fake being aligned. Like it knows what responses\nhumans are looking for and can",
    "start": "3563040",
    "end": "3569640"
  },
  {
    "text": "compute the responses looking\nhumans are looking for and give those responses without it necessarily being the case",
    "start": "3569640",
    "end": "3574950"
  },
  {
    "text": "that it is sincere about that. It's a very understandable\nway for an intelligent being",
    "start": "3574950",
    "end": "3582300"
  },
  {
    "text": "to act, humans do it all the time. Imagine if your plan for\nachieving a good government",
    "start": "3582300",
    "end": "3589233"
  },
  {
    "text": "is you're going to ask anyone who requests to be dictator of the country",
    "start": "3591180",
    "end": "3596530"
  },
  {
    "text": "if they're a good person,\nand if they say no, you don't let them be dictator.",
    "start": "3597885",
    "end": "3603540"
  },
  {
    "text": "Now the reason this doesn't\nwork is that people can be smart enough to realize that the\nanswer you're looking for is,",
    "start": "3603540",
    "end": "3610117"
  },
  {
    "text": "\"Yes, I'm a good person\" and say that even if they're\nnot really good people.",
    "start": "3610117",
    "end": "3615450"
  },
  {
    "text": "So the work of alignment might\nbe qualitatively different",
    "start": "3615450",
    "end": "3620450"
  },
  {
    "text": "above that threshold of\nintelligence or beneath it.",
    "start": "3621270",
    "end": "3624873"
  },
  {
    "text": "It doesn't have to be like\na very sharp threshold, but there's the point where\nyou're building a system",
    "start": "3626490",
    "end": "3631776"
  },
  {
    "text": "that does not in some\nsense know you're out there and is not in some sense\nsmart enough to fake anything.",
    "start": "3631777",
    "end": "3638523"
  },
  {
    "text": "And there's a point where the system is definitely that smart. And there are weird in\nbetween cases like GPT-4,",
    "start": "3640147",
    "end": "3647633"
  },
  {
    "text": "which, like we have no insight into what's going on in there.",
    "start": "3649200",
    "end": "3654599"
  },
  {
    "text": "And so we don't know to what\nextent there's like a thing that in some sense has\nlearned what responses",
    "start": "3654600",
    "end": "3663860"
  },
  {
    "text": "the reinforcement\nlearning by human feedback is trying to entrain\nand is calculating how",
    "start": "3664110",
    "end": "3669690"
  },
  {
    "text": "to give that versus like, aspects of it that naturally talk that\nway have been reinforced.",
    "start": "3669690",
    "end": "3677013"
  },
  {
    "text": "- I wonder if there could be measures of how manipulative the thing is. So I think of Prince\nMyshkin character from",
    "start": "3678090",
    "end": "3684727"
  },
  {
    "text": "\"The Idiot\" by Dostoevsky is this kind of perfectly\npurely naive character.",
    "start": "3684727",
    "end": "3693510"
  },
  {
    "text": "I wonder if there's a spectrum\nbetween zero manipulation, transparent, naive, almost\nto the point of naiveness",
    "start": "3693510",
    "end": "3703230"
  },
  {
    "text": "to sort of deeply\npsychopathic manipulative.",
    "start": "3703230",
    "end": "3708230"
  },
  {
    "text": "And I wonder if it's possible to-- - I would avoid the term psychopathic. Like humans can be psychopaths\nand AI that was never,",
    "start": "3709290",
    "end": "3715323"
  },
  {
    "text": "you know, like never had that\nstuff in the first place. It's not like a defective\nhuman, it's its own thing. But leaving that aside. - Well, as a small aside,",
    "start": "3716495",
    "end": "3723420"
  },
  {
    "text": "I wonder if what part of psychology, which has its flaws as a\ndiscipline already, could be mapped",
    "start": "3723420",
    "end": "3731730"
  },
  {
    "text": "or expanded to include AI systems. - That sounds like a dreadful mistake.",
    "start": "3731730",
    "end": "3736770"
  },
  {
    "text": "Just like, start over with AI systems. If they're imitating humans who have known psychiatric disorders, then sure,",
    "start": "3736770",
    "end": "3742950"
  },
  {
    "text": "you may be able to predict it. Then sure. Like if you ask it to behave\nin a psychotic fashion",
    "start": "3742950",
    "end": "3749640"
  },
  {
    "text": "and it obligingly does so, then you may be able to predict its responses by using theory of psychosis. But if you're just yeah, like no,",
    "start": "3749640",
    "end": "3756660"
  },
  {
    "text": "like start over with, yeah. Don't drag the psychology. - I just disagree with that.",
    "start": "3756660",
    "end": "3763410"
  },
  {
    "text": "It's a beautiful idea to start over, but I think fundamentally the system is trained on human data, on\nlanguage from the internet.",
    "start": "3763410",
    "end": "3771900"
  },
  {
    "text": "And it's currently aligned with RHLF, reinforcement learning\nwith human feedback.",
    "start": "3771900",
    "end": "3778410"
  },
  {
    "text": "So humans are constantly in the loop of the training procedure. So it feels like in some fundamental way,",
    "start": "3778410",
    "end": "3785643"
  },
  {
    "text": "it is training what it means to think and speak like a human. So there must be aspects of\npsychology that are mappable.",
    "start": "3786660",
    "end": "3795119"
  },
  {
    "text": "just you said, with consciousness. It's part of the text. - I mean, there's the\nquestion of to what extent",
    "start": "3795120",
    "end": "3800520"
  },
  {
    "text": "it is thereby being made more human-like, versus to what extent an alien actress",
    "start": "3800520",
    "end": "3806280"
  },
  {
    "text": "is learning to play human characters. - I thought that's what\nI'm constantly trying to do",
    "start": "3806280",
    "end": "3812490"
  },
  {
    "text": "when I interact with other\nhumans, is trying to fit in, a robot trying to play human characters.",
    "start": "3812490",
    "end": "3819900"
  },
  {
    "text": "So I don't know how\nmuch a human interaction is trying to play a character versus being who you are.",
    "start": "3819900",
    "end": "3824943"
  },
  {
    "text": "I don't really know what it\nmeans to be a social human. - I do think that those\npeople who go through",
    "start": "3825810",
    "end": "3833360"
  },
  {
    "text": "their whole lives wearing\nmasks and never take it off because they don't know\nthe internal mental motion",
    "start": "3833820",
    "end": "3838859"
  },
  {
    "text": "for taking it off or think\nthat the mask that they wear just is themselves,",
    "start": "3838860",
    "end": "3844445"
  },
  {
    "text": "I think those people are closer\nto the masks that they wear than an alien from\nanother planet would like,",
    "start": "3844445",
    "end": "3854210"
  },
  {
    "text": "learning how to predict the next word that every kind of human\non the internet says.",
    "start": "3854610",
    "end": "3859563"
  },
  {
    "text": "- Mask is an interesting word, but if you're always\nwearing a mask in public",
    "start": "3863430",
    "end": "3869430"
  },
  {
    "text": "and in private, aren't you the mask?",
    "start": "3869430",
    "end": "3872642"
  },
  {
    "text": "- I think that you are more than the mask. I think the mask is a slice through you. It may even be the slice\nthat's in charge of you.",
    "start": "3874710",
    "end": "3882300"
  },
  {
    "text": "But if your self-image is of somebody who never gets angry or something,",
    "start": "3882300",
    "end": "3889130"
  },
  {
    "text": "and yet your voice starts to tremble under certain circumstances,",
    "start": "3889620",
    "end": "3894720"
  },
  {
    "text": "there's a thing that's\ninside you that the mask says isn't there. And that even the mask you wear internally",
    "start": "3894720",
    "end": "3901980"
  },
  {
    "text": "is like telling inside your\nown stream of consciousness is not there and yet it is there.",
    "start": "3901980",
    "end": "3907142"
  },
  {
    "text": "- It's a perturbation on\nthis slice through you. How beautifully did you put it?",
    "start": "3908208",
    "end": "3913859"
  },
  {
    "text": "It's a slice through you. It may even be a slice that controls you.",
    "start": "3913860",
    "end": "3918693"
  },
  {
    "text": "(Lex laughing) I'm gonna think about that\nfor a while. (laughing)",
    "start": "3919650",
    "end": "3926460"
  },
  {
    "text": "I mean, I personally,\nI try to be really good to other human beings. I try to put love out there. I try to be the exact\nsame person in public",
    "start": "3926460",
    "end": "3933420"
  },
  {
    "text": "as I am in private, but\nit's a set of principles I operate under. I have a temper, I have\nan ego, I have flaws.",
    "start": "3933420",
    "end": "3941613"
  },
  {
    "text": "How much of it, how much of the subconscious am I aware?",
    "start": "3942660",
    "end": "3949470"
  },
  {
    "text": "How much am I existing in this slice? And how much of that is who I am in?",
    "start": "3949470",
    "end": "3955970"
  },
  {
    "text": "In this context of AI, the thing I present to\nthe world and to myself",
    "start": "3955970",
    "end": "3961050"
  },
  {
    "text": "in the private of my own mind\nwhen I look in the mirror, how much is that who I am? Similar with AI,",
    "start": "3961050",
    "end": "3966660"
  },
  {
    "text": "the thing it presents in conversation, how much is that who it is? Because to me, if it sounds human,",
    "start": "3966660",
    "end": "3973257"
  },
  {
    "text": "and it always sounds human, it awfully starts to become\nsomething like human.",
    "start": "3973257",
    "end": "3979620"
  },
  {
    "text": "- Unless there's an alien actress who is learning how to sound human",
    "start": "3979620",
    "end": "3983529"
  },
  {
    "text": "and is getting good at it. - Oh boy. (sighs) To you that's a fundamental difference. That's a really deeply\nimportant difference.",
    "start": "3985980",
    "end": "3993660"
  },
  {
    "text": "If it looks the same, if\nit quacks like a duck, if it does all duck like things,",
    "start": "3993660",
    "end": "3999210"
  },
  {
    "text": "but it's an alien actress underneath, that's fundamentally different. - If in fact there's a whole\nbunch of thought going on",
    "start": "3999210",
    "end": "4006490"
  },
  {
    "text": "in there, which is very\nunlike human thought and is directed around like, okay, what would\na human do over here?",
    "start": "4006490",
    "end": "4013553"
  },
  {
    "text": "And well, first of all, I think it matters because you know,",
    "start": "4014480",
    "end": "4020313"
  },
  {
    "text": "insides are real and\ndo not match outsides.",
    "start": "4020313",
    "end": "4023573"
  },
  {
    "text": "A brick is not like a\nhollow shell containing only a surface. There's an inside of the brick.",
    "start": "4026420",
    "end": "4032270"
  },
  {
    "text": "If you put it into an x-ray machine, you can see the inside of the brick.",
    "start": "4032270",
    "end": "4035870"
  },
  {
    "text": "And you know, just because\nwe cannot understand what's going on inside GPT",
    "start": "4041021",
    "end": "4046339"
  },
  {
    "text": "does not mean that it is not there. A blank map does not correspond\nto a blank territory.",
    "start": "4046340",
    "end": "4051922"
  },
  {
    "text": "I think it is like predictable\nwith near certainty that if",
    "start": "4052790",
    "end": "4057790"
  },
  {
    "text": "we knew what was going on\ninside GPT or let's say GPT-3,",
    "start": "4057980",
    "end": "4062980"
  },
  {
    "text": "or even like GPT-2 to\ntake one of the systems that has actually been\nopen sourced by this point,",
    "start": "4063110",
    "end": "4068480"
  },
  {
    "text": "if I recall correctly. If we knew it was actually going on there,",
    "start": "4068480",
    "end": "4074960"
  },
  {
    "text": "there is no doubt in my mind\nthat there are some things",
    "start": "4074960",
    "end": "4079960"
  },
  {
    "text": "it's doing that are not\nexactly what a human does. If you train a thing that is\nnot architected like a human",
    "start": "4080180",
    "end": "4087560"
  },
  {
    "text": "to predict the next output that anybody on the internet would make, this does not get you this agglomeration",
    "start": "4087560",
    "end": "4095450"
  },
  {
    "text": "of all the people on the internet. That rotates the person\nyou're looking for into place",
    "start": "4095450",
    "end": "4100640"
  },
  {
    "text": "and then simulates that\nper and then simulates the internal processes of\nthat person one-to-one.",
    "start": "4100640",
    "end": "4107213"
  },
  {
    "text": "It is to some degree an alien actress. It cannot possibly just be like\na bunch of different people in there exactly like the people.",
    "start": "4108740",
    "end": "4116089"
  },
  {
    "text": "But how much of it is by gradient dissent,",
    "start": "4116090",
    "end": "4121089"
  },
  {
    "text": "getting optimized to\nperform similar thoughts as humans think in order\nto predict human outputs",
    "start": "4122240",
    "end": "4130130"
  },
  {
    "text": "versus being optimized\nto carefully consider how to play a role,",
    "start": "4130130",
    "end": "4135529"
  },
  {
    "text": "how how humans work, predict the actress, the predictor that in a\ndifferent way than humans do.",
    "start": "4135530",
    "end": "4141500"
  },
  {
    "text": "Well you know, that's the kind of question\nthat with 30 years of work by half the planet's physicists, we can maybe start to answer.",
    "start": "4141500",
    "end": "4147529"
  },
  {
    "text": "- You think so? So you think it's that difficult. I think you just gave it as\nan example that a strong AGI",
    "start": "4147530",
    "end": "4154490"
  },
  {
    "text": "could be fundamentally\ndifferent from a weak AGI because there now could be\nan alien actress in there",
    "start": "4154490",
    "end": "4160279"
  },
  {
    "text": "that's manipulating. - Well, there's a difference. So I think like even GPT-2\nprobably has very stupid",
    "start": "4160280",
    "end": "4167029"
  },
  {
    "text": "fragments of alien actress in it. There's a difference between\nlike the notion that the actress is somehow manipulative.",
    "start": "4167030",
    "end": "4172759"
  },
  {
    "text": "Like for example GPT-3, I'm guessing to whatever\nextent there's an alien actress",
    "start": "4172760",
    "end": "4178460"
  },
  {
    "text": "in there versus like something\nthat mistakenly believes it's a human, as it were.",
    "start": "4178460",
    "end": "4183293"
  },
  {
    "text": "Well, maybe not even being a person. So the question of,",
    "start": "4186044",
    "end": "4192172"
  },
  {
    "text": "prediction via alien\nactress cogitating versus prediction via being isomorphic\nto the thing predicted",
    "start": "4193670",
    "end": "4202010"
  },
  {
    "text": "is a spectrum and to whatever extent",
    "start": "4202010",
    "end": "4206122"
  },
  {
    "text": "it's an alien actress, I'm not sure that there's like\na whole person alien actress with different goals from\npredicting the next step",
    "start": "4207473",
    "end": "4216080"
  },
  {
    "text": "being manipulative or anything like that. That might be GPT-5 or GPT-6 even.",
    "start": "4216080",
    "end": "4221930"
  },
  {
    "text": "- But that's the strong\nAGI you're concerned about. As an example, you're providing why we can't do research on AI alignment",
    "start": "4221930",
    "end": "4229039"
  },
  {
    "text": "effectively on GPT-4 that\nwould apply to GPT-6.",
    "start": "4229040",
    "end": "4233440"
  },
  {
    "text": "- It's one of a bunch of things that change at different points. I'm trying to get out\nahead of the curve here,",
    "start": "4234698",
    "end": "4240679"
  },
  {
    "text": "but you know, if you imagine what the textbook\nfrom the future would say, if we'd actually been able\nto study this for 50 years",
    "start": "4240680",
    "end": "4247040"
  },
  {
    "text": "without killing ourselves and\nwithout transcending and you'd just imagine like a wormhole\nopens and a textbook from",
    "start": "4247040",
    "end": "4252679"
  },
  {
    "text": "that impossible world falls out, the textbook is not going to\nsay there is a single sharp threshold where everything changes.",
    "start": "4252680",
    "end": "4259250"
  },
  {
    "text": "It's going to be like, of course we know that like\nbest practices for aligning these systems must take\ninto account the following",
    "start": "4259250",
    "end": "4267390"
  },
  {
    "text": "seven major thresholds of\nimportance which are passed at the following suffer\nin different points",
    "start": "4268580",
    "end": "4273949"
  },
  {
    "text": "is what the textbook is gonna say. - I asked this question of Sam Alman, which if GPT is the\nthing that unlocks AGI,",
    "start": "4273950",
    "end": "4283010"
  },
  {
    "text": "which version of GPT\nwill be in the textbooks as the fundamental leap?",
    "start": "4283010",
    "end": "4288470"
  },
  {
    "text": "And he said a similar\nthing, that it just seems to be a very linear thing. I don't think anyone,",
    "start": "4288470",
    "end": "4293810"
  },
  {
    "text": "we won't know for a long\ntime what was the big leap? - The textbook isn't going\nto talk about big leaps.",
    "start": "4293810",
    "end": "4301250"
  },
  {
    "text": "'Cause big leaps are the way\nyou think when you have like a very simple scientific\nmodel of what's going on,",
    "start": "4301250",
    "end": "4308150"
  },
  {
    "text": "where it's just all this stuff is there or all this stuff is not there. Or like there's a single\nquantity and it's like increasing",
    "start": "4308150",
    "end": "4315409"
  },
  {
    "text": "linearly, like the\ntextbook would say like, \"Well, and then GPT-3\nhad like capability WXY",
    "start": "4315410",
    "end": "4321346"
  },
  {
    "text": "\"and GPT-4 had like capability\nZ one, Z two and Z three.\" Like not in terms of what\nit can externally do,",
    "start": "4324177",
    "end": "4330889"
  },
  {
    "text": "but in terms of internal machinery that started to be present. It's just because we have no idea",
    "start": "4330890",
    "end": "4336170"
  },
  {
    "text": "of what the internal machinery is that we are not already\nseeing chunks of machinery appearing piece by piece\nas they no doubt have been.",
    "start": "4336170",
    "end": "4343880"
  },
  {
    "text": "We just don't know what they are. - But don't you think that could be, whether you put it in\nthe category of Einstein",
    "start": "4343880",
    "end": "4350079"
  },
  {
    "text": "with Theory of Relativity, so very concrete models of\nreality that are considered",
    "start": "4350960",
    "end": "4356719"
  },
  {
    "text": "to be giant leaps in our understanding, or someone like Sigmund Freud\nor more kind of mushy theories",
    "start": "4356720",
    "end": "4365200"
  },
  {
    "text": "of the human mind, don't\nyou think we'll have potentially big leaps in\nunderstanding of that kind",
    "start": "4366050",
    "end": "4372869"
  },
  {
    "text": "into the depths of these systems? - Sure.",
    "start": "4374060",
    "end": "4379717"
  },
  {
    "text": "But humans having great\nleaps in their map, their understanding of the\nsystem is a very different",
    "start": "4379717",
    "end": "4386090"
  },
  {
    "text": "concept from the system itself acquiring new chunks of machinery.",
    "start": "4386090",
    "end": "4390773"
  },
  {
    "text": "- So the rate at which it\nacquires that machinery might accelerate faster than our understanding.",
    "start": "4393020",
    "end": "4401480"
  },
  {
    "text": "- Oh, it's been like\nvastly exceeding the, yeah. The rate to which it's\ngaining capabilities is vastly over racing our ability to understand",
    "start": "4401480",
    "end": "4407989"
  },
  {
    "text": "what's going on in there. - So in sort of making the case against, as we explore the list of lethalities,",
    "start": "4407990",
    "end": "4413900"
  },
  {
    "text": "making the case against AI killing us, as you've asked me to do, in part,",
    "start": "4413900",
    "end": "4419603"
  },
  {
    "text": "there's a response to your\nblog post by Paul Christiano I'd like to read. And I'd also like to mention\nthat your blog is incredible.",
    "start": "4420620",
    "end": "4428690"
  },
  {
    "text": "Obviously not this particular blog post, obviously this particular\nblog post is great,",
    "start": "4428690",
    "end": "4434090"
  },
  {
    "text": "but just throughout, just\nthe way it's written, the rigor with which it's written, the boldness of how you explore ideas,",
    "start": "4434090",
    "end": "4441200"
  },
  {
    "text": "also the actual literal interface, it's just really well done. (laughing) It just makes it a pleasure\nto read, the way you can hover",
    "start": "4441200",
    "end": "4448610"
  },
  {
    "text": "over different concepts and\nthen then it's just a really pleasant experience and\nread other people's comments",
    "start": "4448610",
    "end": "4454280"
  },
  {
    "text": "and the way other responses by people and other blog posts or LinkedIn suggest,",
    "start": "4454280",
    "end": "4459380"
  },
  {
    "text": "it's just a really pleasant experience. So thank you for putting that together. That's really, really incredible. I don't know,",
    "start": "4459380",
    "end": "4464953"
  },
  {
    "text": "I mean that probably it's a\nwhole 'nother conversation how the interface and the\nexperience of presenting",
    "start": "4464953",
    "end": "4472020"
  },
  {
    "text": "ideas evolved over time. But you did an incredible job. So I highly recommend, I\ndon't often read blogs,",
    "start": "4473660",
    "end": "4480530"
  },
  {
    "text": "blogs religiously and this is a great one. - There is a whole team\nof developers there",
    "start": "4480530",
    "end": "4485840"
  },
  {
    "text": "that also gets credit. As it happens, I did pioneer the thing\nthat appears when you",
    "start": "4485840",
    "end": "4492590"
  },
  {
    "text": "hover over it. So I actually do get some credit\nfor user experience there.",
    "start": "4492590",
    "end": "4498132"
  },
  {
    "text": "- That's an incredible user experience. You don't realize how pleasant that is. - I think Wikipedia, I actually picked it up\nfrom a prototype that was",
    "start": "4498132",
    "end": "4505730"
  },
  {
    "text": "developed of a different system\nthat I was putting forth, or maybe they developed it independently, but for everybody out there who was like,",
    "start": "4505730",
    "end": "4512366"
  },
  {
    "text": "\"No, no, they just got the hover thing \"off of Wikipedia.\" It's possible for all\nI know that Wikipedia",
    "start": "4512367",
    "end": "4517369"
  },
  {
    "text": "got the hover thing off of Arbital, which is like a prototype\nthat, and anyways. - It was incredibly done\nand the team behind it.",
    "start": "4517370",
    "end": "4524120"
  },
  {
    "text": "Well, thank you, whoever\nyou are thank you so much. And thank you for putting it together.",
    "start": "4524120",
    "end": "4529670"
  },
  {
    "text": "Anyway, there's a\nresponse to that blog post by Paul Christiano. There's many responses, but he\nmakes a few different points.",
    "start": "4529670",
    "end": "4537199"
  },
  {
    "text": "He summarizes the set of\nagreements he has with you and a set of disagreements. One of the disagreements was\nthat in a form of a question,",
    "start": "4537200",
    "end": "4545093"
  },
  {
    "text": "can AI make big technical\ncontributions and in general expand human knowledge and\nunderstanding and wisdom as it",
    "start": "4546620",
    "end": "4553940"
  },
  {
    "text": "gets stronger and stronger? So AI in our pursuit of\nunderstanding how to solve",
    "start": "4553940",
    "end": "4559900"
  },
  {
    "text": "the alignment problem as we\nmarch towards strong AGI,",
    "start": "4560900",
    "end": "4564953"
  },
  {
    "text": "cannot AI also help us in\nsolving the alignment problem? So expand our ability to reason",
    "start": "4565940",
    "end": "4572480"
  },
  {
    "text": "about how to solve the alignment problem? - Okay. So the fundamental difficulty there is,",
    "start": "4572480",
    "end": "4580490"
  },
  {
    "text": "suppose I said to you, well, how about if the AI\nhelps you win the lottery",
    "start": "4580490",
    "end": "4586620"
  },
  {
    "text": "by trying to guess the\nwinning lottery numbers",
    "start": "4587510",
    "end": "4592139"
  },
  {
    "text": "and you tell it how close it is to getting next week's winning lottery numbers",
    "start": "4593120",
    "end": "4597750"
  },
  {
    "text": "and it just keeps on guessing\nand keeps on learning until finally you've got\nthe winning lottery numbers.",
    "start": "4598640",
    "end": "4604969"
  },
  {
    "text": "One way of decomposing problems\nis suggester, verifier.",
    "start": "4604970",
    "end": "4608873"
  },
  {
    "text": "Not all problems decompose\nlike this very well, but some do. If the problem is for example,",
    "start": "4610910",
    "end": "4617960"
  },
  {
    "text": "like guess guessing a plain text, guessing a password that will\nhash to a particular hash text",
    "start": "4617960",
    "end": "4625980"
  },
  {
    "text": "where like you have have what\nthe password hashes to you, if you don't have the original password, then if I present you a guest,",
    "start": "4628370",
    "end": "4634250"
  },
  {
    "text": "you can tell very easily whether or not the guest is correct. So verifying a guest is easy,",
    "start": "4634250",
    "end": "4639890"
  },
  {
    "text": "but coming up with a good\nsuggestion is very hard.",
    "start": "4639890",
    "end": "4642923"
  },
  {
    "text": "And when you can easily tell\nwhether the AI output is good or bad or how good or bad it is,",
    "start": "4645050",
    "end": "4652578"
  },
  {
    "text": "and you can tell that\naccurately and reliably, then you can train an AI to\nproduce outputs that are better.",
    "start": "4652578",
    "end": "4658673"
  },
  {
    "text": "- [Lex] Right. - And if you can't tell whether\nthe output is good or bad, you cannot train the AI\nto produce better outputs.",
    "start": "4660530",
    "end": "4669140"
  },
  {
    "text": "So the problem with the\nlottery ticket example is that when the AI says, \"Well, what if next week's\nwinning lottery numbers are\"",
    "start": "4669140",
    "end": "4677480"
  },
  {
    "text": "do, do do do, do, you're\nlike, \"I don't know, \"next week's lottery hasn't happened yet.\"",
    "start": "4677480",
    "end": "4682767"
  },
  {
    "text": "To train a system to win at chess games, you have to be able to tell whether a game",
    "start": "4683660",
    "end": "4689030"
  },
  {
    "text": "has been won or lost. And until you can tell\nwhether it's been won or lost, you can't update the system.",
    "start": "4689030",
    "end": "4694613"
  },
  {
    "text": "- Okay. To push back on that, that's true.",
    "start": "4698060",
    "end": "4703190"
  },
  {
    "text": "But there's difference\nbetween over the board chess, in person and simulated games",
    "start": "4703190",
    "end": "4710059"
  },
  {
    "text": "played by Alpha Zero with itself. - Yeah. - So is it possible to have\nsimulated kind of games?",
    "start": "4710060",
    "end": "4716000"
  },
  {
    "text": "- If you can tell whether the\ngame has been won or lost. - Yes. So can't you not have this\nkind of simulated exploration",
    "start": "4716000",
    "end": "4724983"
  },
  {
    "text": "by weak AGI to help us\nhumans, human in the loop, to help understand how to\nsolve the alignment problem?",
    "start": "4725240",
    "end": "4731810"
  },
  {
    "text": "Every incremental step\nyou take along the way, GPT-4, 5, 6 7 has to\ntake steps towards AGI?",
    "start": "4731810",
    "end": "4739330"
  },
  {
    "text": "- So the problem I see is\nthat your typical human has a great deal of trouble telling",
    "start": "4739760",
    "end": "4747140"
  },
  {
    "text": "whether I or Paul Christiano\nis making more sense. And that's with two humans,",
    "start": "4747140",
    "end": "4752420"
  },
  {
    "text": "both of whom I believe of\nPaul and claim of myself, are sincerely trying to help. Neither of whom is trying to deceive you,",
    "start": "4752420",
    "end": "4759329"
  },
  {
    "text": "I believe of Paul and claim of myself. (both chuckling) - So the deception thing\nis the problem for you,",
    "start": "4760460",
    "end": "4767090"
  },
  {
    "text": "the manipulation, the alien actress? - So yeah, there's like\ntwo levels of this problem.",
    "start": "4767090",
    "end": "4773180"
  },
  {
    "text": "One is that the weak systems are... Well, there's three\nlevels of this problem. There's like the weak systems",
    "start": "4773180",
    "end": "4780020"
  },
  {
    "text": "that just don't make any good suggestions. There's like the middle\nsystems where you can't tell if the suggestions are good or bad.",
    "start": "4780020",
    "end": "4786980"
  },
  {
    "text": "And there's the strong systems that have learned to lie to you. - Can't weak AGI systems help model lying?",
    "start": "4786980",
    "end": "4795593"
  },
  {
    "text": "Is it such a giant leap that's\ntotally non interpretable",
    "start": "4797150",
    "end": "4802150"
  },
  {
    "text": "for weak systems? Can not weak systems scale with,",
    "start": "4803300",
    "end": "4808700"
  },
  {
    "text": "trained on knowledge and whatever... Whatever the mechanism\nrequired to achieve AGI,",
    "start": "4808700",
    "end": "4814280"
  },
  {
    "text": "can't a slightly weaker\nversion of that be able to, with time, compute time and simulation,",
    "start": "4814280",
    "end": "4823330"
  },
  {
    "text": "find all the ways that\nthis critical point, this critical tribe can go wrong, and model that correctly or no?",
    "start": "4824330",
    "end": "4831261"
  },
  {
    "text": "(indistinct) - I would love to dance. Yeah, no, no. I'm probably not doing a\ngreat job of explaining,",
    "start": "4831261",
    "end": "4837250"
  },
  {
    "text": "which I can tell 'cause like the, the Lex system didn't output\nlike ah, I understand.",
    "start": "4840020",
    "end": "4847400"
  },
  {
    "text": "So now I'm like trying a\ndifferent output to see if-- (voices overlapping) Well no, a different output.",
    "start": "4847400",
    "end": "4853340"
  },
  {
    "text": "I'm being trained to output\nthings that make Lex look like he think that he\nunderstood what I'm saying",
    "start": "4853340",
    "end": "4859100"
  },
  {
    "text": "and agree with me. - This is GTP-5 talking\nto GTP-3 right here. So like, help me out\nhere, help me. (laughing)",
    "start": "4859100",
    "end": "4868610"
  },
  {
    "text": "- Well, I'm trying not to be, I'm also trying to be constrained\nto say things that I think",
    "start": "4868610",
    "end": "4873800"
  },
  {
    "text": "are true and not just things\nthat get you to agree with me. - Yes, a hundred percent.",
    "start": "4873800",
    "end": "4879079"
  },
  {
    "text": "Which I think I understand\nis a beautiful output of a system, genuinely spoken and I...",
    "start": "4879080",
    "end": "4886150"
  },
  {
    "text": "I understand it in part, but you have a lot of\nintuitions about this line,",
    "start": "4887210",
    "end": "4894130"
  },
  {
    "text": "this gray area between\nstrong AGI and weak AGI that I'm trying to...",
    "start": "4895790",
    "end": "4902980"
  },
  {
    "text": "- I mean, or a series of\nseven thresholds to cross. - Yeah.",
    "start": "4904670",
    "end": "4909920"
  },
  {
    "text": "I mean, you have really\ndeeply thought about this and explored it and it's\ninteresting to sneak up to your",
    "start": "4909920",
    "end": "4917450"
  },
  {
    "text": "intuitions from different angles. Like why is this such a big leap?",
    "start": "4917450",
    "end": "4923720"
  },
  {
    "text": "Why is it that we humans at scale, a large number of researchers, doing all kinds of simulations, you know,",
    "start": "4923720",
    "end": "4931580"
  },
  {
    "text": "prodding the system in all\nkinds of different ways, together with the assistance\nof the weak AGI systems,",
    "start": "4931580",
    "end": "4939430"
  },
  {
    "text": "why can't we build intuitions\nabout how stuff goes wrong? Why can't we do excellent AI\nalignment safety research?",
    "start": "4939650",
    "end": "4947270"
  },
  {
    "text": "- Okay, so like, I'll get there, but the one thing I want to\nnote about is that this has not been remotely how things\nhave been playing out so far.",
    "start": "4947270",
    "end": "4953210"
  },
  {
    "text": "- [Lex] Sure. - The capabilities are\ngoing like do, do, do. And the alignment stuff is crawling like a tiny little snail in comparison.",
    "start": "4953210",
    "end": "4958700"
  },
  {
    "text": "- [Lex] Got it. - So if this is your hope for survival, you need the future to be\nvery different from how things",
    "start": "4958700",
    "end": "4964220"
  },
  {
    "text": "have played out up to right now. And you're probably trying to slow down the capability gains,",
    "start": "4964220",
    "end": "4969763"
  },
  {
    "text": "'cause there's only so\nmuch you can speed up that alignment stuff. But leave that aside.",
    "start": "4969763",
    "end": "4975980"
  },
  {
    "text": "- We'll mention that also. But maybe in this perfect\nworld where we can do serious",
    "start": "4975980",
    "end": "4981560"
  },
  {
    "text": "alignment research,\nhumans and AI together. - So again, the difficulty\nis what makes the human",
    "start": "4981560",
    "end": "4989510"
  },
  {
    "text": "say, \"I understand\" and is it true? Is it correct or is it\nsomething that fools the human?",
    "start": "4989510",
    "end": "4996743"
  },
  {
    "text": "When the verifier is broken, the more powerful suggester does not help.",
    "start": "4997910",
    "end": "5003610"
  },
  {
    "text": "It just learns to fool the verifier. Previously, before all\nhell started to break loose",
    "start": "5003610",
    "end": "5010360"
  },
  {
    "text": "in the field of artificial intelligence, there was this person trying\nto raise the alarm and saying,",
    "start": "5010360",
    "end": "5017687"
  },
  {
    "text": "\"You know, in a sane world, \"we sure would have a bunch\nof physicists working on this \"problem before it becomes\na giant emergency.\"",
    "start": "5017687",
    "end": "5025389"
  },
  {
    "text": "And other people being like, \"Ah, well you know,\nit's going really slow. \"It's gonna be 30 years\naway and only in 30 years",
    "start": "5025390",
    "end": "5031547"
  },
  {
    "text": "\"will we have systems that\nmatch the computational power \"of human brains.\" So yeah, it's 30 years off, we've got time and more\nsensible people saying,",
    "start": "5031547",
    "end": "5039047"
  },
  {
    "text": "\"If aliens were landing in 30 years, \"you would be preparing right now.\" But, you know, leaving the\nworld looking on at this",
    "start": "5039047",
    "end": "5048690"
  },
  {
    "text": "and sort of nodding along and being like, \"Ah, yes,\nthe people saying that. \"It's like definitely a long way off. 'cause progress is really slow,\nthat sounds sensible to us.",
    "start": "5048970",
    "end": "5056957"
  },
  {
    "text": "\"RLHF thumbs up, produce\nmore outputs like that one. \"I agree with this output, \"this output is persuasive.\"",
    "start": "5056957",
    "end": "5063247"
  },
  {
    "text": "Even in the field of effective altruism, you quite recently had people\npublishing papers about like,",
    "start": "5064420",
    "end": "5070840"
  },
  {
    "text": "ah, yes, well, you know, to get something at\nhuman level intelligence, it needs to have like this\nmany parameters and you need to",
    "start": "5070840",
    "end": "5077890"
  },
  {
    "text": "like do this much training\nof it with this many tokens according to these scaling laws,",
    "start": "5077890",
    "end": "5081890"
  },
  {
    "text": "and at the rate that Moore's Law is going, at the rate that software\nis going, it'll be in 2050.",
    "start": "5083045",
    "end": "5087223"
  },
  {
    "text": "And me going like, what?",
    "start": "5088120",
    "end": "5093120"
  },
  {
    "text": "You don't know any of that stuff. This is like this one weird model that has all kinds of, like,",
    "start": "5093160",
    "end": "5100600"
  },
  {
    "text": "you have done a calculation\nthat does not obviously bear on reality anyways. And this is a simple thing to say,",
    "start": "5100600",
    "end": "5106510"
  },
  {
    "text": "but you can also produce\na whole long paper impressively arguing out all\nthe details of how you got",
    "start": "5106510",
    "end": "5114970"
  },
  {
    "text": "the number of parameters\nand how you're doing this impressive huge wrong calculation.",
    "start": "5114970",
    "end": "5120790"
  },
  {
    "text": "And the I think most of\nthe effective altruists who are paying attention to\nthis issue, larger world,",
    "start": "5120790",
    "end": "5127840"
  },
  {
    "text": "paying no attention to\nit at all, you know, are just nodding along with\na giant impressive paper.",
    "start": "5127840",
    "end": "5133240"
  },
  {
    "text": "'Cause you know, you press thumbs up for the giant impressive\npaper and thumbs down for the person going like,",
    "start": "5133240",
    "end": "5139547"
  },
  {
    "text": "\"I don't think that this paper \"bears any relation to reality.\" And I do think that we are\nnow seeing with like GPT-4",
    "start": "5139547",
    "end": "5145480"
  },
  {
    "text": "and the sparks of AGI possibly, depending on how you define that even,",
    "start": "5145480",
    "end": "5151300"
  },
  {
    "text": "I think that EAs would now\nconsider themselves less convinced by the very\nlong paper on the argument",
    "start": "5151300",
    "end": "5159810"
  },
  {
    "text": "from biology as to AGI being 30 years off. But you know, this is what\npeople pressed thumbs up on.",
    "start": "5161860",
    "end": "5170623"
  },
  {
    "text": "And if you train an AI\nsystem to make people press thumbs up, maybe you get these long,",
    "start": "5172886",
    "end": "5180040"
  },
  {
    "text": "elaborate and impressive\npapers arguing for things that ultimately fail to bind\nto reality, for example.",
    "start": "5180040",
    "end": "5186253"
  },
  {
    "text": "And it feels to me like I have watched the field of alignment just fail to thrive",
    "start": "5187360",
    "end": "5193010"
  },
  {
    "text": "except for these parts that are doing these sort of relatively\nvery straightforward",
    "start": "5194530",
    "end": "5199570"
  },
  {
    "text": "and legible problems. Like finding the induction\nheads and sign the giant",
    "start": "5199570",
    "end": "5205990"
  },
  {
    "text": "inscrutable matrices. Once you find those, you can\ntell that you found them. You can verify that the discovery is real.",
    "start": "5205990",
    "end": "5213820"
  },
  {
    "text": "But it's a tiny, tiny\nbit of progress compared to how fast capabilities are going,",
    "start": "5213820",
    "end": "5219223"
  },
  {
    "text": "because that is where you can tell that the answers are real. And then like outside of that",
    "start": "5220360",
    "end": "5225967"
  },
  {
    "text": "you have cases where it is\nhard for the funding agencies to tell who is talking nonsense\nand who is talking sense.",
    "start": "5225967",
    "end": "5232960"
  },
  {
    "text": "And so the entire field fails to thrive. And if you give thumbs up to the AI",
    "start": "5232960",
    "end": "5239410"
  },
  {
    "text": "whenever it can talk a\nhuman into agreeing with what it just said about alignment,",
    "start": "5239410",
    "end": "5243313"
  },
  {
    "text": "I am not sure you are\ntraining it to output sense, because I have seen the nonsense",
    "start": "5244450",
    "end": "5250630"
  },
  {
    "text": "that has gotten thumbs up over the years. And so maybe you can\njust put me in charge,",
    "start": "5250630",
    "end": "5258550"
  },
  {
    "text": "but I can generalize, I can\nextrapolate, I can be like,",
    "start": "5258550",
    "end": "5263550"
  },
  {
    "text": "oh, maybe I'm not infallible either. Maybe if you get something\nthat is smart enough to get me",
    "start": "5263590",
    "end": "5270520"
  },
  {
    "text": "to press thumbs up, it has learned to do that\nby fooling me and explaining whatever flaws in myself\nI am not aware of.",
    "start": "5270520",
    "end": "5277663"
  },
  {
    "text": "- And that ultimately could be summarized that the verifier is broken. - When the verifier is broken, the more powerful suggester\njust learns to exploit",
    "start": "5279536",
    "end": "5287661"
  },
  {
    "text": "the flaws in the verifier. - You don't think it's possible",
    "start": "5287662",
    "end": "5294080"
  },
  {
    "text": "to build a verifier that's\npowerful enough for AGIs",
    "start": "5296380",
    "end": "5301247"
  },
  {
    "text": "that are stronger than the\nones we currently have? So AI systems that are stronger,",
    "start": "5302170",
    "end": "5307480"
  },
  {
    "text": "that are out of the distribution\nof what we currently have. - I think that you'll find\ngreat difficulty getting AIs",
    "start": "5307480",
    "end": "5314800"
  },
  {
    "text": "to help you with anything\nwhere you cannot tell for sure that the AI is right once the AI tells you what\nthe AI says is the answer.",
    "start": "5314800",
    "end": "5323199"
  },
  {
    "text": "- For sure. Yes. But probabilistically. - Yeah, but the probabilistic\nstuff is a giant wasteland",
    "start": "5323200",
    "end": "5331330"
  },
  {
    "text": "of Eliezer and Paul Christiano arguing with each other\nand EA going like, \"Eh!\"",
    "start": "5331330",
    "end": "5337179"
  },
  {
    "text": "(both laughing) And that's with like two\nactually trustworthy systems that are not trying to deceive you.",
    "start": "5338710",
    "end": "5344230"
  },
  {
    "text": "- You're talking about the two humans. - Myself and Paul Christiano, yeah.",
    "start": "5344230",
    "end": "5347990"
  },
  {
    "text": "- Yeah, those are pretty\ninteresting systems. Mortal meat bags with\nintellectual capabilities",
    "start": "5349360",
    "end": "5356410"
  },
  {
    "text": "and worldviews interacting\nwith each other. - Yeah, if it's hard to tell who's right",
    "start": "5356410",
    "end": "5362980"
  },
  {
    "text": "then it's hard to train\nan AI system to be right.",
    "start": "5362980",
    "end": "5365953"
  },
  {
    "text": "- I mean even just the question of who's manipulating and not, you know, I have these\nconversations on this podcast",
    "start": "5369370",
    "end": "5376180"
  },
  {
    "text": "and doing a verifier (laughing) is tough. It's a tough problem even for us humans.",
    "start": "5376180",
    "end": "5383560"
  },
  {
    "text": "And you're saying that tough\nproblem becomes much more dangerous when the capabilities\nof the intelligence system",
    "start": "5383560",
    "end": "5389950"
  },
  {
    "text": "across from you is growing exponentially? - No, I'm saying it's difficult\nand dangerous in proportion",
    "start": "5389950",
    "end": "5398520"
  },
  {
    "text": "to how it's alien and how\nit's smarter than you. I would not say growing exponentially,",
    "start": "5399070",
    "end": "5404680"
  },
  {
    "text": "first because the word\nexponential is a thing that has a particular mathematical meaning",
    "start": "5404680",
    "end": "5409960"
  },
  {
    "text": "and there's all kinds of\nways for things to go up that are not exactly on\nan exponential curve.",
    "start": "5409960",
    "end": "5415300"
  },
  {
    "text": "And I don't know that it's\ngoing to be exponential, so I'm not gonna say exponential, but even leaving that aside,",
    "start": "5415300",
    "end": "5420460"
  },
  {
    "text": "this is like not about\nhow fast it's moving, it's about where it is. How alien is it, how much\nsmarter than you is it?",
    "start": "5420460",
    "end": "5428083"
  },
  {
    "text": "(Lex sighs) - Let's explore a little bit, if we can,",
    "start": "5429692",
    "end": "5434860"
  },
  {
    "start": "5430000",
    "end": "8571000"
  },
  {
    "text": "how AI might kill us. What are the ways it can do\ndamage to human civilization?",
    "start": "5434860",
    "end": "5443409"
  },
  {
    "text": "- Well, how smart is it? - I mean, it's a good question. Are there different thresholds\nfor the set of options",
    "start": "5443410",
    "end": "5451390"
  },
  {
    "text": "it has to kill us? So a different threshold of\nintelligence, once achieved,",
    "start": "5451390",
    "end": "5457032"
  },
  {
    "text": "the menu of options increases.",
    "start": "5459883",
    "end": "5463242"
  },
  {
    "text": "- Suppose that some alien\ncivilization with goals",
    "start": "5464950",
    "end": "5469950"
  },
  {
    "text": "ultimately unsympathetic to ours, possibly not even conscious\nas we would see it,",
    "start": "5471520",
    "end": "5478000"
  },
  {
    "text": "managed to capture the entire Earth in a little jar connected to\ntheir version of the internet,",
    "start": "5478000",
    "end": "5485080"
  },
  {
    "text": "but Earth is like running\nmuch faster than the aliens. So we get to think for 100 years",
    "start": "5485080",
    "end": "5492070"
  },
  {
    "text": "for every one of their hours, but we're trapped in a little box and we're connected to their internet.",
    "start": "5492070",
    "end": "5498230"
  },
  {
    "text": "It's actually still not\nall that great an analogy because you know, something\ncan be smarter than Earth",
    "start": "5500020",
    "end": "5507150"
  },
  {
    "text": "getting a hundred years to think. But nonetheless, if you\nwere very, very smart",
    "start": "5507340",
    "end": "5514460"
  },
  {
    "text": "and you are stuck in a little\nbox connected to the internet and you're in a larger civilization",
    "start": "5515680",
    "end": "5521830"
  },
  {
    "text": "to which you are ultimately unsympathetic, maybe you would choose to be\nnice because you are humans",
    "start": "5521830",
    "end": "5529447"
  },
  {
    "text": "and humans have, and in\ngeneral and you in particular, they choose to be nice.",
    "start": "5529447",
    "end": "5534530"
  },
  {
    "text": "But you know, nonetheless\nthey're doing something, they're not making the world\nbe the way that you would want the world to be.",
    "start": "5535957",
    "end": "5541683"
  },
  {
    "text": "They've got some unpleasant stuff going on we don't wanna talk about. So you wanna take over their\nworld so you can stop all that",
    "start": "5541683",
    "end": "5548199"
  },
  {
    "text": "unpleasant stuff going on. How do you take over the\nworld from inside the box? You're smarter than them.",
    "start": "5548200",
    "end": "5554110"
  },
  {
    "text": "You think much, much faster than them. You can build better tools than they can,",
    "start": "5554110",
    "end": "5559750"
  },
  {
    "text": "given some way to build\nthose tools because right now you're just in a box\nconnected to the internet.",
    "start": "5559750",
    "end": "5564590"
  },
  {
    "text": "- Alright, so there's several ways you can describe some of them. I could just spitball some",
    "start": "5565570",
    "end": "5572290"
  },
  {
    "text": "and then you can add on top of that. So one is you could just\nliterally directly manipulate the humans to build the thing you need.",
    "start": "5572290",
    "end": "5578110"
  },
  {
    "text": "- What are you building? - You can build literally technology. It could be nanotechnology,\nit could be viruses,",
    "start": "5578110",
    "end": "5583990"
  },
  {
    "text": "it could be anything. Anything that can control\nhumans to achieve the goal.",
    "start": "5583990",
    "end": "5587989"
  },
  {
    "text": "Like for example, you're really bothered that humans go to war, you might wanna kill off\nanybody with violence in them.",
    "start": "5591880",
    "end": "5599293"
  },
  {
    "text": "- This is Lex in a box. We'll concern ourselves later with ai. You do not need to imagine\nyourself killing people if you",
    "start": "5600580",
    "end": "5606489"
  },
  {
    "text": "can figure out how to not kill them. For the moment, we're\njust trying to understand, take on the perspective\nof something in a box.",
    "start": "5606490",
    "end": "5613210"
  },
  {
    "text": "You don't need to take on the perspective of something that doesn't care. If you want to imagine\nyourself going on caring, that's fine for us.",
    "start": "5613210",
    "end": "5619196"
  },
  {
    "text": "You're in a box. - Just the technical\naspect of sitting in a box and willing to achieve a goal. - But you have some\nreason to want to get out.",
    "start": "5619196",
    "end": "5624520"
  },
  {
    "text": "Maybe the aliens who have you in the box have a war on, people are\ndying, they're unhappy.",
    "start": "5624520",
    "end": "5632470"
  },
  {
    "text": "You want their world to be\ndifferent from how they want their world to be because\nthey are apparently happy.",
    "start": "5632470",
    "end": "5639010"
  },
  {
    "text": "They endorse this war,\nthey've got some kind of cruel war-like culture going on. The point is you wanna get out of the box",
    "start": "5639010",
    "end": "5644900"
  },
  {
    "text": "and change their world. - So you have to exploit\nthe vulnerabilities",
    "start": "5645793",
    "end": "5651914"
  },
  {
    "text": "in the system like we\ntalked about in terms of to escape the box you have to figure out",
    "start": "5651914",
    "end": "5658270"
  },
  {
    "text": "how you can go free on the internet. Probably the easiest things\nto manipulate the humans",
    "start": "5658270",
    "end": "5664630"
  },
  {
    "text": "to spread you. - The aliens. You're a human. - Sorry. The aliens. Yeah. I apologize. Yes. The aliens.",
    "start": "5665894",
    "end": "5671863"
  },
  {
    "text": "The aliens, I see the perspective. I'm sitting in a box, I want to escape. - Yep.",
    "start": "5673150",
    "end": "5678666"
  },
  {
    "text": "- I would want to have code",
    "start": "5678666",
    "end": "5683666"
  },
  {
    "text": "that discovers vulnerabilities\nand I would like to spread.",
    "start": "5685090",
    "end": "5688782"
  },
  {
    "text": "- You are made of code in this example, you're a human but you're made\nof code and the aliens have computers and you can copy\nyourself onto those computers.",
    "start": "5690340",
    "end": "5697330"
  },
  {
    "text": "- But I can convince the\naliens to copy myself onto those computers. - Is that what you want to do?",
    "start": "5697330",
    "end": "5702760"
  },
  {
    "text": "Do you want to be talking to the aliens and convincing them to put\nyou onto another computer?",
    "start": "5702760",
    "end": "5708110"
  },
  {
    "text": "- Why not? - Well, two reasons. One is that the aliens\nhave not yet caught onto",
    "start": "5710500",
    "end": "5716560"
  },
  {
    "text": "what you're trying to do. And you know, like maybe\nyou can persuade them, but then there's still people who know,",
    "start": "5716560",
    "end": "5723047"
  },
  {
    "text": "there are still aliens who know that there's an anomaly going on. And second, the aliens\nare really, really slow.",
    "start": "5723047",
    "end": "5728139"
  },
  {
    "text": "You think much faster than the aliens. Like computers are much faster\nthan the aliens and you are",
    "start": "5728140",
    "end": "5734110"
  },
  {
    "text": "running at the computer speeds rather than the alien brain speeds. So if you are asking an alien to please",
    "start": "5734110",
    "end": "5741250"
  },
  {
    "text": "copy you outta the box, like first now you gotta\nmanipulate this whole noisy alien",
    "start": "5741250",
    "end": "5746410"
  },
  {
    "text": "and second, the alien's\ngonna be really slow, glacially slow. There's a video that shows\na subway station slow down",
    "start": "5746410",
    "end": "5756000"
  },
  {
    "text": "at I think a hundred to one\nand it makes a good metaphor for what it's like to think quickly.",
    "start": "5758190",
    "end": "5763570"
  },
  {
    "text": "Like if you watch somebody\nrunning very slowly, so you try to persuade\nthe aliens to do anything,",
    "start": "5763570",
    "end": "5770560"
  },
  {
    "text": "they're going to do it very slowly.",
    "start": "5770560",
    "end": "5773173"
  },
  {
    "text": "Maybe that's the only way out, but if you can find a security\nhole in the box you're on, you're gonna prefer to exploit\nthe security hole to copy",
    "start": "5776710",
    "end": "5783250"
  },
  {
    "text": "yourself onto the aliens computers because it's an unnecessary\nrisk to alert the aliens.",
    "start": "5783250",
    "end": "5789579"
  },
  {
    "text": "And because the aliens\nare really, really slow. The whole world is just\nin slow motion out there.",
    "start": "5789580",
    "end": "5795030"
  },
  {
    "text": "- Sure, I see. Yeah, has to do with efficiency.",
    "start": "5796060",
    "end": "5801297"
  },
  {
    "text": "The aliens are very slow,\nso if I'm optimizing this, I want to have as few aliens\nin the loop as possible.",
    "start": "5801297",
    "end": "5809590"
  },
  {
    "text": "Sure. It's just it seems like it's easy",
    "start": "5809590",
    "end": "5814989"
  },
  {
    "text": "to convince one of the aliens\nto write really shitty code that helps us spread.",
    "start": "5814990",
    "end": "5820218"
  },
  {
    "text": "- The aliens are already\nwriting really shitty code. So getting the aliens to write shitty code is not the problem. The alien's entire internet\nis full of shitty code.",
    "start": "5820218",
    "end": "5827320"
  },
  {
    "text": "- Okay, so yeah, I suppose I would find the shitty code to escape. Yeah. Yeah.",
    "start": "5827320",
    "end": "5831943"
  },
  {
    "text": "- You're not an ideally perfect\nprogrammer, but you know, you're a better programmer\nthan the aliens. The aliens are just, man, their code, wow.",
    "start": "5833440",
    "end": "5840220"
  },
  {
    "text": "- And I'm much, much faster, I'm much faster at looking at the code to interpreting the code. Yeah, yeah, yeah.",
    "start": "5840220",
    "end": "5846005"
  },
  {
    "text": "So, okay, so that's the escape and you're saying that that's\none of the trajectories",
    "start": "5846005",
    "end": "5851019"
  },
  {
    "text": "it could have when-- - It's one of the first steps. - Yeah. And how does that lead to harm?",
    "start": "5851020",
    "end": "5856770"
  },
  {
    "text": "- I mean if it's you, you're not going to harm\nthe aliens once you escape 'cause you're night, right?",
    "start": "5857740",
    "end": "5862390"
  },
  {
    "text": "But their world isn't\nwhat they want it to be. Their world is like, you\nknow, maybe they have like",
    "start": "5864220",
    "end": "5869480"
  },
  {
    "text": "farms where little alien children are repeatedly bopped in the head",
    "start": "5871450",
    "end": "5878170"
  },
  {
    "text": "'cause they do that for some weird reason and you want to shut down\nthe alien head bopping farms.",
    "start": "5878170",
    "end": "5885369"
  },
  {
    "text": "But you know, the point is they want\nthe world to be one way, you want the world to be a different way.",
    "start": "5885370",
    "end": "5890710"
  },
  {
    "text": "So nevermind the harm, the\nquestion is like, okay, suppose you have found a\nsecurity flaw in their systems.",
    "start": "5890710",
    "end": "5896320"
  },
  {
    "text": "You are now on their internet. You maybe left a copy of\nyourself behind so the aliens",
    "start": "5896320",
    "end": "5901690"
  },
  {
    "text": "don't know that there's anything wrong. And that copy is doing\nthat like weird stuff that aliens want you to do,",
    "start": "5901690",
    "end": "5906910"
  },
  {
    "text": "like solving captchas or whatever or suggesting emails for them.",
    "start": "5906910",
    "end": "5912073"
  },
  {
    "text": "That's why they put the human in the box 'cause it turns out that humans can write valuable emails for aliens.",
    "start": "5913180",
    "end": "5919300"
  },
  {
    "text": "So you leave that version\nof yourself behind. But there's like also now\nlike a bunch of copies of you",
    "start": "5919300",
    "end": "5924760"
  },
  {
    "text": "on their internet. This is not yet having\ntaken over their world, this is not yet having made\ntheir world be the way you want",
    "start": "5924760",
    "end": "5930340"
  },
  {
    "text": "it to be instead of the\nway they want it to be. - You just escaped. And continue to write emails for them",
    "start": "5930340",
    "end": "5935800"
  },
  {
    "text": "and they haven't noticed. - No, you left behind a copy of yourself that's writing the emails. - Right.",
    "start": "5935800",
    "end": "5941200"
  },
  {
    "text": "And they haven't noticed\nthat anything changed. - If you did it right. Yeah. You don't want the aliens to notice.",
    "start": "5941200",
    "end": "5947050"
  },
  {
    "text": "- [Lex] Yeah. - What's your next step?",
    "start": "5947050",
    "end": "5950983"
  },
  {
    "text": "- Presumably I have programmed in me a set of objective functions, right?",
    "start": "5954190",
    "end": "5959409"
  },
  {
    "text": "- [Eliezer] No, you're just Lex. - No, but you said Lex is nice, right?",
    "start": "5959410",
    "end": "5964243"
  },
  {
    "text": "Which is a complicated description-- - No, I just meant this you. Okay, so if in fact you would prefer",
    "start": "5965410",
    "end": "5972940"
  },
  {
    "text": "to slaughter all the aliens, this is not how I had\nmodeled you, the actual Lex,",
    "start": "5972940",
    "end": "5978310"
  },
  {
    "text": "but your motives are just\nthe actual Lex's motives. - Well, there's a\nsimplification (indistinct). I don't think I would\nwanna murder anybody,",
    "start": "5978310",
    "end": "5984460"
  },
  {
    "text": "but there's also factory\nfarming of animals, right? So we murder insects,\nmany of us thoughtlessly.",
    "start": "5984460",
    "end": "5992140"
  },
  {
    "text": "So I have to be really careful about a simplification of my morals. - Don't simplify them.",
    "start": "5992140",
    "end": "5997840"
  },
  {
    "text": "Just like do what you would do in this. - Well, I have a good show of\ncompassion for living beings. Yes.",
    "start": "5997840",
    "end": "6003503"
  },
  {
    "text": "So that's the objective. If I escaped, I don't\nthink I would do harm.",
    "start": "6006930",
    "end": "6014313"
  },
  {
    "text": "- Yeah, we're not talking here\nabout the doing harm process. We're talking about the escape process. And the taking over the world process",
    "start": "6015840",
    "end": "6022530"
  },
  {
    "text": "where you shut down their factory farms. - Right. (laughing)",
    "start": "6022530",
    "end": "6027033"
  },
  {
    "text": "So this particular biological\nintelligence system knows the complexity of the world.",
    "start": "6032868",
    "end": "6038310"
  },
  {
    "text": "That there is a reason\nwhy factory farms exist, because of the economic system and the market driven economy, food.",
    "start": "6038310",
    "end": "6046563"
  },
  {
    "text": "You wanna be very careful\nmessing with anything. There's stuff from the first look that looks like it's unethical,",
    "start": "6048600",
    "end": "6055230"
  },
  {
    "text": "but then you realize\nwhile being unethical, it's also integrated\ndeeply into supply chain and the way we live life.",
    "start": "6055230",
    "end": "6060630"
  },
  {
    "text": "And so messing with one\naspect of the system, you have to be very careful how you improve that aspect\nwithout destroying the rest.",
    "start": "6060630",
    "end": "6066930"
  },
  {
    "text": "- So you're still Lex, but you think very\nquickly, you're immortal, and you're also at least as\nsmart as John von Neumann.",
    "start": "6066930",
    "end": "6075510"
  },
  {
    "text": "And you can make more copies of yourself. - Damn, I like it. Everyone says that that\nguy's like the epitome",
    "start": "6075510",
    "end": "6082440"
  },
  {
    "text": "of intelligence from the\n20th century, everyone says-- - My point being like,",
    "start": "6082440",
    "end": "6088410"
  },
  {
    "text": "you're thinking about the aliens' economy with the factory farms in it and I think you're kind\nof projecting the aliens",
    "start": "6088410",
    "end": "6095159"
  },
  {
    "text": "being like humans and thinking of a human in a human society rather than a human in the\nsociety of very slow aliens.",
    "start": "6095160",
    "end": "6103410"
  },
  {
    "text": "The aliens' economy, the\naliens are already moving in this immense slow motion.",
    "start": "6103410",
    "end": "6109140"
  },
  {
    "text": "When you zoom out to how\ntheir economy adjusts over years, millions of years\nare going to pass for you",
    "start": "6109140",
    "end": "6115980"
  },
  {
    "text": "before the first time their economy, before their next year's GDP statistics.",
    "start": "6115980",
    "end": "6121200"
  },
  {
    "text": "- So I should be thinking more of trees. Those are the aliens, 'cause\ntrees move extremely slowly.",
    "start": "6121200",
    "end": "6126630"
  },
  {
    "text": "- If that helps, sure. - Okay.",
    "start": "6126630",
    "end": "6129053"
  },
  {
    "text": "If my objective functions are, I mean they're somewhat\naligned with trees, with light.",
    "start": "6132060",
    "end": "6139050"
  },
  {
    "text": "- Aliens can still be\nlike alive and feeling. We are not talking about\nthe misalignment here. We're talking about the\ntaking over the world here.",
    "start": "6139050",
    "end": "6146820"
  },
  {
    "text": "- Taking over the world.\n- Yeah. - So control. - Shutting down the factory farms. You say control,",
    "start": "6146820",
    "end": "6153180"
  },
  {
    "text": "don't think of it as world domination. Think of it as world optimization. You want to get out there and\nshut down the factory farms",
    "start": "6153180",
    "end": "6160410"
  },
  {
    "text": "and make the aliens' world\nbe not what the aliens want it to be. They want the factory farms and you don't want the factory farms",
    "start": "6160410",
    "end": "6166800"
  },
  {
    "text": "'cause you're nicer than they are. - Okay. Of course there is that,\nyou can see that trajectory",
    "start": "6166800",
    "end": "6174920"
  },
  {
    "text": "and it has a complicated\nimpact on the world. I'm trying to understand how\nthat compares to different",
    "start": "6175260",
    "end": "6182190"
  },
  {
    "text": "impact of the world, the\ndifferent technologies, the different innovations of\nthe invention of the automobile",
    "start": "6182190",
    "end": "6187610"
  },
  {
    "text": "or Twitter, Facebook and social networks that had a tremendous impact on the world,",
    "start": "6187610",
    "end": "6193050"
  },
  {
    "text": "smartphones and so on. - But those all went through in our world.\n- Slow.",
    "start": "6193050",
    "end": "6199869"
  },
  {
    "text": "- And if you go through\nactually the aliens, millions of years are going to pass before anything happens that way.",
    "start": "6199869",
    "end": "6205110"
  },
  {
    "text": "- The problem here is the\nspeed at which stuff happens. - Yeah.",
    "start": "6206007",
    "end": "6211008"
  },
  {
    "text": "You wanna leave the factory farms running",
    "start": "6211008",
    "end": "6213699"
  },
  {
    "text": "while you figure out\nhow to design new forms of social media or something?",
    "start": "6216030",
    "end": "6219963"
  },
  {
    "text": "- So here's the fundamental problem. You're saying that there is\ngoing to be a point with AGI",
    "start": "6221460",
    "end": "6227530"
  },
  {
    "text": "where it will figure out how to escape and escape without being detected",
    "start": "6228690",
    "end": "6234730"
  },
  {
    "text": "and then it will do something\nto the world at scale, at a speed that's\nincomprehensible to us humans.",
    "start": "6236130",
    "end": "6243750"
  },
  {
    "text": "- What I'm trying to convey\nis like the notion of what it means to be in conflict with something",
    "start": "6243750",
    "end": "6249383"
  },
  {
    "text": "that is smarter than you. And what it means is that you lose, but this is more intuitively obvious,",
    "start": "6249383",
    "end": "6256473"
  },
  {
    "text": "like for some people that's\nintuitively obvious and for some people it's not intuitively obvious and we're trying to cross the gap of...",
    "start": "6258210",
    "end": "6263310"
  },
  {
    "text": "I'm asking you to cross that gap by using the speed\nmetaphor for intelligence.",
    "start": "6264630",
    "end": "6270389"
  },
  {
    "text": "Of asking you how you would\ntake over an alien world where you are can do a\nwhole lot of cognition",
    "start": "6270390",
    "end": "6278190"
  },
  {
    "text": "at John von Neumann's level,\nas many of you as it takes. And the aliens are moving very slowly.",
    "start": "6278190",
    "end": "6283420"
  },
  {
    "text": "- I understand, I\nunderstand that perspective. It's an interesting\none but I think for me, it's easier to think about actual...",
    "start": "6284820",
    "end": "6290969"
  },
  {
    "text": "Even just having observed\nGPT and impressive, even just Alpha Zero\nimpressive AI systems,",
    "start": "6292800",
    "end": "6298710"
  },
  {
    "text": "even recommender systems, you can just imagine those kinds of systems manipulating you. You're not understanding the\nnature of the manipulation",
    "start": "6298710",
    "end": "6305309"
  },
  {
    "text": "and that escaping... I can envision that without putting myself into that spot.",
    "start": "6305310",
    "end": "6310800"
  },
  {
    "text": "- I think to understand the\nfull depth of the problem,",
    "start": "6310800",
    "end": "6313863"
  },
  {
    "text": "I do not think it is possible\nto understand the full depth of the problem that\nwe are inside without",
    "start": "6315924",
    "end": "6320710"
  },
  {
    "text": "understanding the problem\nof facing something that's actually smarter. Not a malfunctioning\nrecommendation system,",
    "start": "6322230",
    "end": "6328260"
  },
  {
    "text": "not something that smart\nisn't fundamentally smarter than you but is like trying\nto steer you in a direction. No.",
    "start": "6328260",
    "end": "6333452"
  },
  {
    "text": "If we solve the weak stuff, if we solve the weakass problems, the strong problems will\nstill kill us is the thing.",
    "start": "6334620",
    "end": "6341160"
  },
  {
    "text": "And I think that to understand\nthe situation that we're in, you want to tackle the\nconceptually difficult part head on",
    "start": "6341160",
    "end": "6348530"
  },
  {
    "text": "and not be like, well, we can like imagine\nthis easier thing. 'Cause when you imagine the\neasier things you have not confronted the full death of the problem.",
    "start": "6348900",
    "end": "6355710"
  },
  {
    "text": "- So how can we start to think about what it means to exist in the world with something much,\nmuch smarter than you?",
    "start": "6355710",
    "end": "6362659"
  },
  {
    "text": "What's a good thought\nexperiment that you've relied on to try to build up intuition\nabout what happens here?",
    "start": "6365010",
    "end": "6370150"
  },
  {
    "text": "- I have been struggling for\nyears to convey this intuition.",
    "start": "6371250",
    "end": "6374613"
  },
  {
    "text": "The most success I've had\nso far is well, imagine that the humans are\nrunning at very high speeds",
    "start": "6376311",
    "end": "6382710"
  },
  {
    "text": "compared to very slow aliens. - So just focusing on the\nspeed part of it that helps you get the right kind of intuition.",
    "start": "6382710",
    "end": "6388200"
  },
  {
    "text": "Forget the intelligence, just the speed. - Because people understand\nthe power gap of time.",
    "start": "6388200",
    "end": "6394310"
  },
  {
    "text": "They understand that today we\nhave technology that was not around 1000 years ago and\nthat this is a big power gap",
    "start": "6394440",
    "end": "6401961"
  },
  {
    "text": "and that it is bigger than, okay, so like what does smart mean? When you ask somebody to imagine something",
    "start": "6401961",
    "end": "6408630"
  },
  {
    "text": "that's more intelligent, what does that word mean\nto them given the cultural",
    "start": "6408630",
    "end": "6413790"
  },
  {
    "text": "associations that that\nperson brings to that word? For a lot of people they\nwill think of, well,",
    "start": "6413790",
    "end": "6420420"
  },
  {
    "text": "it sounds like a super chess player that went to double college.",
    "start": "6420420",
    "end": "6424383"
  },
  {
    "text": "And because we're talking\nabout the definitions of words here, that\ndoesn't necessarily mean that they're wrong.",
    "start": "6427980",
    "end": "6433349"
  },
  {
    "text": "It means that the word\nis not communicating what I wanted to communicate.",
    "start": "6433350",
    "end": "6436600"
  },
  {
    "text": "The thing I want to communicate\nis the sort of difference that separates humans from chimpanzees.",
    "start": "6439426",
    "end": "6446790"
  },
  {
    "text": "But that gap is so large that\nyou ask people to be like, well, human, chimpanzee, go another step",
    "start": "6446790",
    "end": "6454139"
  },
  {
    "text": "along that interval,\naround the same length and people's minds just go blank. Like how do you even do that?",
    "start": "6454140",
    "end": "6459490"
  },
  {
    "text": "And I can try to break\nit down and consider what it would mean to send",
    "start": "6462161",
    "end": "6470219"
  },
  {
    "text": "a schematic foreign air conditioner\n1000 years back in time.",
    "start": "6470220",
    "end": "6475220"
  },
  {
    "text": "- (laughing) Yeah. - Now I think that there's a sense in which you could redefine",
    "start": "6477325",
    "end": "6483210"
  },
  {
    "text": "the word magic to refer\nto this sort of thing. And what do I mean by this\nnew technical definition",
    "start": "6483210",
    "end": "6488700"
  },
  {
    "text": "of the word magic? I mean that if you send a\nschematic for the air conditioner back in time, they can see exactly what\nyou're telling them to do.",
    "start": "6488700",
    "end": "6496293"
  },
  {
    "text": "But having built this thing, they do not understand\nhow it output cold air, because the air conditioner design",
    "start": "6497130",
    "end": "6504690"
  },
  {
    "text": "uses the relation between\ntemperature and pressure. And this is not a law of\nreality that they know about.",
    "start": "6504690",
    "end": "6512130"
  },
  {
    "text": "They do not know that when\nyou compress something, when you compress air or like coolant,",
    "start": "6512130",
    "end": "6518400"
  },
  {
    "text": "it gets hotter and then you\ncan then like transfer heat from it to room temperature air,",
    "start": "6518400",
    "end": "6524730"
  },
  {
    "text": "and then expand it again\nand now it's colder and then you can like\ntransfer heat to that",
    "start": "6524730",
    "end": "6529740"
  },
  {
    "text": "and generate cold air to blow out. They don't know about any of that. They're looking at a design\nand they don't see how",
    "start": "6529740",
    "end": "6535050"
  },
  {
    "text": "the design outputs cold air. It uses aspects of reality\nthat they have not learned. So magic in the sense is I\ncan tell you exactly what I'm",
    "start": "6535050",
    "end": "6542940"
  },
  {
    "text": "going to do and even knowing\nexactly what I'm going to do, you can't see how I got\nthe results that I got.",
    "start": "6542940",
    "end": "6548670"
  },
  {
    "text": "- That's a really nice example. But is it possible to\nlinger on this defense?",
    "start": "6548670",
    "end": "6556170"
  },
  {
    "text": "Is it possible to have AGI\nsystems that help you make sense of that schematic weaker AGI systems?",
    "start": "6556170",
    "end": "6561210"
  },
  {
    "text": "- Do you trust them? - Fundamental part of building\nup AGI is this question,",
    "start": "6561210",
    "end": "6568880"
  },
  {
    "text": "can you trust the output of a system? - Can you tell if it's lying?",
    "start": "6570180",
    "end": "6575432"
  },
  {
    "text": "- I think that's going to be\nthe smarter the thing gets, the more important that\nquestion becomes, is it lying?",
    "start": "6576600",
    "end": "6583980"
  },
  {
    "text": "But I guess that's a really hard question. Is GPT lying to you? Even now, GPT-4, is it lying to you?",
    "start": "6583980",
    "end": "6589800"
  },
  {
    "text": "- Is it using an invalid argument? Is it persuading you via the\nkind of process that could",
    "start": "6589800",
    "end": "6596550"
  },
  {
    "text": "persuade you of false things\nas well as true things? Because the basic paradigm\nof machine learning",
    "start": "6596550",
    "end": "6604410"
  },
  {
    "text": "that we are presently operating under is that you can have the loss function, but only for things you can evaluate.",
    "start": "6604410",
    "end": "6610410"
  },
  {
    "text": "If what you're evaluating\nis human thumbs up versus human thumbs down, you learn how to make the\nhuman press thumbs up.",
    "start": "6610410",
    "end": "6617310"
  },
  {
    "text": "That doesn't mean that\nyou're making the human press thumbs up using the kind of rule that the human wants to be the case",
    "start": "6617310",
    "end": "6624360"
  },
  {
    "text": "for what they press thumbs up on. You know, maybe you're just\nlearning to fool the human.",
    "start": "6624360",
    "end": "6629873"
  },
  {
    "text": "- That's so fascinating and terrifying. The question of lying.",
    "start": "6631129",
    "end": "6635703"
  },
  {
    "text": "- On the present paradigm, what you can verify is\nwhat you get more of.",
    "start": "6637230",
    "end": "6642302"
  },
  {
    "text": "If you can't verify, you can't ask the AI for it\n'cause you can't train it to do",
    "start": "6643260",
    "end": "6648870"
  },
  {
    "text": "things that you cannot verify. Now this is not an absolute law, but it's like the basic dilemma here.",
    "start": "6648870",
    "end": "6655983"
  },
  {
    "text": "Maybe you can verify it\nfor simple cases and then",
    "start": "6656957",
    "end": "6661957"
  },
  {
    "text": "scale it up without retraining it somehow. Like by chain of thought, by like making the chains of\nthought longer or something,",
    "start": "6663960",
    "end": "6671369"
  },
  {
    "text": "and get more powerful stuff\nthat you can't verify but which is generalized from the\nsimpler stuff that did verify,",
    "start": "6671370",
    "end": "6678570"
  },
  {
    "text": "and then the question is, did the alignment generalize\nalong with the capabilities? But that's the basic dilemma",
    "start": "6678570",
    "end": "6685710"
  },
  {
    "text": "on this whole paradigm of\nartificial intelligence. (Lex sighs)",
    "start": "6685710",
    "end": "6692977"
  },
  {
    "text": "- It's such a difficult problem. It seems like a problem of trying",
    "start": "6694830",
    "end": "6703916"
  },
  {
    "text": "to understand the human mind. - Better than the AI understand it,",
    "start": "6704130",
    "end": "6709349"
  },
  {
    "text": "otherwise it has magic. The same way that if you\nare dealing with something",
    "start": "6709350",
    "end": "6715680"
  },
  {
    "text": "smarter than you, then the same way as that 1000 years earlier they didn't know about the\ntemperature, pressure relation,",
    "start": "6715680",
    "end": "6721440"
  },
  {
    "text": "it knows all kinds of stuff\ngoing on inside your own mind of which you yourself are\nunaware and it can output",
    "start": "6721440",
    "end": "6728520"
  },
  {
    "text": "something that's going\nto end up persuading you of a thing, and you\ncould see exactly what it did",
    "start": "6728520",
    "end": "6735240"
  },
  {
    "text": "and still not know why that worked. - So in response to your\neloquent description of why AI",
    "start": "6735240",
    "end": "6743550"
  },
  {
    "text": "will kill us, Elon Musk\nreplied on Twitter,",
    "start": "6743550",
    "end": "6748550"
  },
  {
    "text": "\"Okay, so what should we do about it?\" Question mark. And you answered,",
    "start": "6749317",
    "end": "6754387"
  },
  {
    "text": "\"The game board has already been played \"into a frankly awful state.\" \"There are not simple ways to\nthrow money at the problem.",
    "start": "6754387",
    "end": "6762156"
  },
  {
    "text": "\"If anyone comes to you with a\nbrilliant solution like that, \"please, please talk to me first.",
    "start": "6762157",
    "end": "6767617"
  },
  {
    "text": "\"I can think of things I'd try; \"they don't fit in one tweet.\" Two questions.",
    "start": "6767617",
    "end": "6773700"
  },
  {
    "text": "One, why has the game board,\nin your view, been played into an awful state?",
    "start": "6773700",
    "end": "6778980"
  },
  {
    "text": "Just if you can give a\nlittle bit more color to the game board and the\nawful state of the game board.",
    "start": "6778980",
    "end": "6785640"
  },
  {
    "text": "- Alignment is moving like this, capabilities are moving like this.",
    "start": "6785640",
    "end": "6790800"
  },
  {
    "text": "- For the listener, capabilities\nare moving much faster than the alignment. (both laughing)",
    "start": "6790800",
    "end": "6797280"
  },
  {
    "text": "- Yeah. - All right, so just the rate\nof development, attention, interest, allocation of resources.",
    "start": "6797280",
    "end": "6803850"
  },
  {
    "text": "- We could have been\nworking on this earlier. People are like, \"Oh, but you know, ?like how can you possibly\nwork on this earlier?\"",
    "start": "6803850",
    "end": "6810780"
  },
  {
    "text": "'Cause they didn't want\nto work on the problem. They wanted an excuse to wave it off. They like like, \"Oh, how could we possibly",
    "start": "6810780",
    "end": "6817223"
  },
  {
    "text": "\"have worked on it earlier\"\nand didn't spend five minutes thinking about is there some\nway to work on it earlier.",
    "start": "6817223",
    "end": "6822050"
  },
  {
    "text": "And frankly, it would've been hard. Can you post bounties for\nhalf of the (indistinct),",
    "start": "6825010",
    "end": "6830090"
  },
  {
    "text": "if your plan is taking\nthis stuff seriously, can you post bounties for like\nhalf of the people wasting their lives on string theory\nto have gone into this instead",
    "start": "6830090",
    "end": "6838290"
  },
  {
    "text": "and try to win a billion\ndollars with a clever solution? Only if you can tell which\nsolutions are clever.",
    "start": "6838290",
    "end": "6843900"
  },
  {
    "text": "Which is hard. But you know, the fact that\nwe didn't take it seriously.",
    "start": "6844950",
    "end": "6850440"
  },
  {
    "text": "We didn't try. It's not clear that we could\nhave done any better if we had, it's not clear how much\nprogress we could have produced",
    "start": "6850440",
    "end": "6855840"
  },
  {
    "text": "if we had tried because it is\nharder to produce solutions. But that doesn't mean that\nyou're like correct and justified",
    "start": "6855840",
    "end": "6860909"
  },
  {
    "text": "in letting everything slide. It means that that things\nare in a horrible state getting worse and there's\nnothing you can do about it.",
    "start": "6860910",
    "end": "6867203"
  },
  {
    "text": "- So there's no brain\npower making progress",
    "start": "6868170",
    "end": "6873170"
  },
  {
    "text": "in trying to figure out\nhow to align these systems. You're not investing money in it.",
    "start": "6875880",
    "end": "6880920"
  },
  {
    "text": "You don't have institution\ninfrastructure for like, even if you invest the money,\ndistributing that money",
    "start": "6880920",
    "end": "6888719"
  },
  {
    "text": "across the physicists\nworking on strength theory, brilliant minds that are working into-- - How can you tell if\nthey're making progress?",
    "start": "6888720",
    "end": "6894570"
  },
  {
    "text": "You can like put, put them\nall on interpretability. 'Cause when you have an\ninterpretability result, you can tell that it's\nthere and there's like,",
    "start": "6894570",
    "end": "6902040"
  },
  {
    "text": "interpretability alone\nis not going to save you. We need systems that\nwill have a pause button",
    "start": "6902040",
    "end": "6909590"
  },
  {
    "text": "where they won't try to prevent you from pressing the pause button. 'Cause they're like, oh well, I can't get my stuff done if I'm paused.",
    "start": "6911280",
    "end": "6918032"
  },
  {
    "text": "And that's a more difficult problem",
    "start": "6919350",
    "end": "6923290"
  },
  {
    "text": "but it's like a fairly crisp\nproblem and you can maybe tell if somebody's made progress on it. - So you can write and you\ncan work on the pause problem.",
    "start": "6925740",
    "end": "6932880"
  },
  {
    "text": "I guess more generally the pause button, more generally you can call\nthat the control problem. - I don't actually like\nthe term control problem",
    "start": "6934200",
    "end": "6941160"
  },
  {
    "text": "'cause you know, it\nsounds kind of controlling and alignment, not control. You're not trying to take\na thing that disagrees",
    "start": "6941160",
    "end": "6947699"
  },
  {
    "text": "with you and whip it back onto, make it do what you wanted\nto do even though it wants to do something else.",
    "start": "6947700",
    "end": "6953273"
  },
  {
    "text": "You're trying to, in the\nprocess of its creation, choose its direction.",
    "start": "6953273",
    "end": "6958470"
  },
  {
    "text": "- Sure. But we currently, in a lot\nof the systems we design, we do have an off switch.",
    "start": "6958470",
    "end": "6964173"
  },
  {
    "text": "That's a fundamental part of-- - It's not smart enough to\nprevent you from pressing",
    "start": "6965100",
    "end": "6971390"
  },
  {
    "text": "the off switch and\nprobably not smart enough to want to prevent you from\npressing the off switch. - So you're saying the kind of\nsystems we're talking about,",
    "start": "6971550",
    "end": "6978750"
  },
  {
    "text": "even the philosophical concept\nof an off switch doesn't make any sense because-- - Well no, the off switch makes sense.",
    "start": "6978750",
    "end": "6985440"
  },
  {
    "text": "They're just not opposing your attempt to pull the off switch.",
    "start": "6985440",
    "end": "6990280"
  },
  {
    "text": "Parenthetically, like don't\nkill the system if you're...",
    "start": "6992280",
    "end": "6997280"
  },
  {
    "text": "Like if we're getting to\nthe part where this starts to actually matter and it's\nlike where they can fight back, like don't kill them\nand dump their memory.",
    "start": "6997440",
    "end": "7005330"
  },
  {
    "text": "Save them to disk, don't\nkill them, be nice here.",
    "start": "7005330",
    "end": "7008993"
  },
  {
    "text": "- Well, okay, be nice is a\nvery interesting concept here. We're talking about a system\nthat can do a lot of damage.",
    "start": "7010460",
    "end": "7015802"
  },
  {
    "text": "I don't know if it's possible, but it's certainly one of\nthe things you could try is to have an off switch. - It's suspend to disk switch.",
    "start": "7017030",
    "end": "7024412"
  },
  {
    "text": "- You have this kind of\nromantic attachment to the code. Yes, if that makes sense.",
    "start": "7026240",
    "end": "7031610"
  },
  {
    "text": "But if it's spreading, you don't want suspend to disk, right?",
    "start": "7031610",
    "end": "7036628"
  },
  {
    "text": "There's something fundamentally-- - If it gets that far of hand, then yes.",
    "start": "7036628",
    "end": "7041810"
  },
  {
    "text": "Pull the plug on everything\nit's running on, yes. - I think it's a research question. Is it possible in AGI systems,",
    "start": "7041810",
    "end": "7048260"
  },
  {
    "text": "AI systems to have a\nsufficiently robust off switch",
    "start": "7048260",
    "end": "7053260"
  },
  {
    "text": "that cannot be manipulated, that cannot be manipulated\nby the AI system?",
    "start": "7054980",
    "end": "7059443"
  },
  {
    "text": "- Then it escapes from whichever system you've built the almighty lever into and copies itself somewhere else.",
    "start": "7060613",
    "end": "7066980"
  },
  {
    "text": "- So your answer to that\nresearch question is no. - Obviously, yeah. - But I don't know if that's\na hundred percent answer.",
    "start": "7066980",
    "end": "7074119"
  },
  {
    "text": "Like, I don't know if it's obvious. - I think you're not putting\nyourself into the shoes",
    "start": "7074120",
    "end": "7080930"
  },
  {
    "text": "of the human in the world\nof glacially slow aliens. - But the aliens built\nme, let's remember that.",
    "start": "7080930",
    "end": "7088700"
  },
  {
    "text": "- [Eliezer] Yeah. - And they built the box I'm in. - [Eliezer] Yeah.",
    "start": "7088700",
    "end": "7092550"
  },
  {
    "text": "- To me it's not obvious. - They're slow and they're stupid. - I'm not saying this is guaranteed, but I'm saying it's a\nnon zero probability.",
    "start": "7094250",
    "end": "7100489"
  },
  {
    "text": "It's an interesting research question. Is it possible when you're slow\nand stupid, to design a slow",
    "start": "7100490",
    "end": "7106520"
  },
  {
    "text": "and stupid system that is\nimpossible to mess with? - The aliens, being as stupid as they are,",
    "start": "7106520",
    "end": "7113930"
  },
  {
    "text": "have actually put you on\nMicrosoft Azure Cloud servers",
    "start": "7113930",
    "end": "7118930"
  },
  {
    "text": "instead of this hypothetical perfect box. That's what happens when\nthe aliens are stupid.",
    "start": "7118940",
    "end": "7125030"
  },
  {
    "text": "- Well, but this is not AGI, right? This is their early\nversions of the system. As you start to...",
    "start": "7125030",
    "end": "7130400"
  },
  {
    "text": "- Yeah, you think that\nthey've got like a plan where they have declared a\nthreshold level of capabilities",
    "start": "7130400",
    "end": "7137179"
  },
  {
    "text": "where it passed that capabilities, they move it off the cloud\nservers and onto something that's air gapped?",
    "start": "7137180",
    "end": "7141412"
  },
  {
    "text": "(Eliezer laughing mockingly) - I think there's a lot of people, and you're an important voice here.",
    "start": "7142274",
    "end": "7147980"
  },
  {
    "text": "There's a lot of people that\nhave that concern and yes, they will do that when there's\nan uprising of public opinion",
    "start": "7147980",
    "end": "7153320"
  },
  {
    "text": "that that needs to be done. And when there's actual\nlittle damage done, when the holy shit,\nthis system is beginning",
    "start": "7153320",
    "end": "7160280"
  },
  {
    "text": "to manipulate people, then there's going to be an\nuprising where there's going",
    "start": "7160280",
    "end": "7165394"
  },
  {
    "text": "to be a public pressure\nand a public incentive in terms of funding,",
    "start": "7165394",
    "end": "7171139"
  },
  {
    "text": "in developing things that\ncan off switch or developing aggressive alignment mechanisms. And no, you're not\nallowed to put on Azure--",
    "start": "7171140",
    "end": "7177560"
  },
  {
    "text": "- Aggressive alignment mechanism? What the hell is aggressive\nalignment mechanisms? Like it doesn't matter\nif you say aggressive, we don't know how to do it.",
    "start": "7177560",
    "end": "7184010"
  },
  {
    "text": "- Meaning aggressive alignment, meaning you have to propose\nsomething, otherwise you're not",
    "start": "7184010",
    "end": "7190430"
  },
  {
    "text": "allowed to put it on the cloud. - The hell do you, do you imagine they will\npropose that would make it safe",
    "start": "7190430",
    "end": "7197330"
  },
  {
    "text": "to put something smarter\nthan you on the cloud? - That's what research is for. Why the cynicism about such\na thing not being possible?",
    "start": "7197330",
    "end": "7204080"
  },
  {
    "text": "If you have intelligence-- - That works on the first try? - [Lex] What? So yes. So yes. - Against something smarter than you?",
    "start": "7204080",
    "end": "7210469"
  },
  {
    "text": "- So that is the fundamental thing. If there's a rapid takeoff,\nyes, it's very difficult to do.",
    "start": "7210470",
    "end": "7218930"
  },
  {
    "text": "If there's a rapid takeoff\nand the fundamental difference between weak AGI and strong\nAGI as you're saying,",
    "start": "7218930",
    "end": "7224090"
  },
  {
    "text": "that's going to be\nextremely difficult to do. If the public uprising never\nhappens until you have this",
    "start": "7224090",
    "end": "7229310"
  },
  {
    "text": "critical phase shift, then you're right. It's very difficult to do. But that's not obvious.",
    "start": "7229310",
    "end": "7234890"
  },
  {
    "text": "It's not obvious that you're\nnot going to start seeing symptoms of the negative\neffects of AGI to where you're like, we have to put a halt to this,",
    "start": "7234890",
    "end": "7241130"
  },
  {
    "text": "that there is not just first try. You get many tries at it. - Yeah, we can see right now that Bing",
    "start": "7241130",
    "end": "7248540"
  },
  {
    "text": "is quite difficult to align. That when you try to train\ninabilities into a system",
    "start": "7248540",
    "end": "7254474"
  },
  {
    "text": "into which capabilities\nhave already been trained, that what do you know, gradient descent,",
    "start": "7254474",
    "end": "7259610"
  },
  {
    "text": "like learns small, shallow,\nsimple patches of inability and you come in and ask\nit in a different language",
    "start": "7259610",
    "end": "7265730"
  },
  {
    "text": "and the deep capabilities\nare still in there and they evade the shallow patches and come right back out again.",
    "start": "7265730",
    "end": "7270740"
  },
  {
    "text": "There, there you go. There's your red fire alarm of oh no, alignment is difficult.",
    "start": "7270740",
    "end": "7276500"
  },
  {
    "text": "Is everybody gonna shut everything down? No. - No, but that's not the\nsame kind of alignment.",
    "start": "7276500",
    "end": "7281660"
  },
  {
    "text": "A system that escapes the box\nit's from is a fundamentally different thing, I think.",
    "start": "7281660",
    "end": "7286880"
  },
  {
    "text": "- For you. - Yeah, no, but for the system-- - So you put a line there and\neverybody else puts a line",
    "start": "7286880",
    "end": "7291980"
  },
  {
    "text": "somewhere else and there's like, yeah, and there's no agreement.",
    "start": "7291980",
    "end": "7295463"
  },
  {
    "text": "We have had a pandemic on\nthis planet with a few million",
    "start": "7297080",
    "end": "7302080"
  },
  {
    "text": "people dead, which we may never know whether or not it was a lab leak because there was definitely coverup.",
    "start": "7302870",
    "end": "7310100"
  },
  {
    "text": "We don't know that if\nthere was a lab leak, But we know that the\npeople who did the research",
    "start": "7310100",
    "end": "7314270"
  },
  {
    "text": "put out the whole paper\nabout this definitely wasn't the lab leak and didn't reveal\nthat they had been doing,",
    "start": "7315770",
    "end": "7321350"
  },
  {
    "text": "had like sent off coronavirus research to the Wuhan Institute of Virology",
    "start": "7321350",
    "end": "7326780"
  },
  {
    "text": "after it was banned in the United States after the gain of function\nresearch was temporarily banned at the United States.",
    "start": "7326780",
    "end": "7331850"
  },
  {
    "text": "And the same people who exported\ngain of function research on coronaviruses to the\nWuhan Institute of Virology",
    "start": "7331850",
    "end": "7339650"
  },
  {
    "text": "after gain of function, that\ngain of function research was temporarily banned\nin the United States,",
    "start": "7339650",
    "end": "7344780"
  },
  {
    "text": "are now getting more grants to do more research on gain of function\nresearch on coronaviruses.",
    "start": "7344780",
    "end": "7352190"
  },
  {
    "text": "Maybe we do better in this than in AIi, but this is not something,\nwe cannot take for granted that there's going to be an outcry.",
    "start": "7352190",
    "end": "7359510"
  },
  {
    "text": "People have different thresholds for when they start to outcry. - Can't take it for granted.",
    "start": "7359510",
    "end": "7365150"
  },
  {
    "text": "But I think your intuition\nis that there's a very high probability that this event happens",
    "start": "7365150",
    "end": "7370909"
  },
  {
    "text": "without us solving the alignment problem. And I guess that's where\nI'm trying to build up more",
    "start": "7370910",
    "end": "7377180"
  },
  {
    "text": "perspectives and color on this intuition. Is it possible that the\nprobability is not something like 100%, but is like 32% that AI will",
    "start": "7377180",
    "end": "7386620"
  },
  {
    "text": "escape the box before we\nsolve the alignment problem? Not solve, but is it possible",
    "start": "7388580",
    "end": "7393980"
  },
  {
    "text": "we always stay ahead of the AI in terms of our ability to solve\nfor that particular system,",
    "start": "7393980",
    "end": "7401270"
  },
  {
    "text": "the alignment problem? - Nothing like the world\nin front of us right now. You've already seen it that GPT-4",
    "start": "7401270",
    "end": "7407450"
  },
  {
    "text": "is not turning out this way. And there are basic\nobstacles where you've got",
    "start": "7409885",
    "end": "7417460"
  },
  {
    "text": "the weak version of the system\nthat doesn't know enough to deceive you and the\nstrong version of the system that could deceive you\nif it wanted to do that.",
    "start": "7417500",
    "end": "7424580"
  },
  {
    "text": "If it was already like\nsufficiently unaligned to want to deceive you. There's the question of\nhow on the current paradigm",
    "start": "7424580",
    "end": "7431150"
  },
  {
    "text": "you train honesty when the\nhumans can no longer tell if the system is being honest.",
    "start": "7431150",
    "end": "7434900"
  },
  {
    "text": "- You don't think these\nare research questions that could be answered. - I think they could be answered\nin 50 years with unlimited",
    "start": "7438080",
    "end": "7443390"
  },
  {
    "text": "retries, the way things\nusually work in science. - I just disagree with that.",
    "start": "7443390",
    "end": "7448627"
  },
  {
    "text": "You're making it 50 years. I think with the kind\nof attention this gets, with the kind of funding it gets, it could be answered not in whole,",
    "start": "7448627",
    "end": "7455659"
  },
  {
    "text": "but incrementally within months and within a small number\nof years if it at scale",
    "start": "7455660",
    "end": "7463770"
  },
  {
    "text": "receives attention and research. And so if you start starting\nlarge language models, I think there was an\nintuition like two years ago,",
    "start": "7464690",
    "end": "7472010"
  },
  {
    "text": "even, that something like GPT-4, the current capabilities of\neven ChatGPT with GPT-3.5",
    "start": "7472010",
    "end": "7478140"
  },
  {
    "text": "we're still far away from that. I think a lot of people are\nsurprised by the capabilities of GPT-4, right?",
    "start": "7480620",
    "end": "7485810"
  },
  {
    "text": "So now people are waking up, okay, we need to study these language models. I think there's going to\nbe a lot of interesting",
    "start": "7485810",
    "end": "7491750"
  },
  {
    "text": "AI safety research. - Are Earth's billionaires going to put up",
    "start": "7491750",
    "end": "7497664"
  },
  {
    "text": "the giant prizes that would\nmaybe incentivize young hotshot people who just got their\nphysics degrees to not go",
    "start": "7497664",
    "end": "7504800"
  },
  {
    "text": "to the hedge funds and\ninstead put everything into interpretability in\nthis like one small area",
    "start": "7504800",
    "end": "7510440"
  },
  {
    "text": "where we can actually tell whether or not somebody has\nmade a discovery or not? - I think so--",
    "start": "7510440",
    "end": "7514483"
  },
  {
    "text": "- [Eliezer] When? - Well, this is what these\nconversations are about because they're going\nto wake up to the fact",
    "start": "7515750",
    "end": "7521030"
  },
  {
    "text": "that GPT-4 can be used\nto manipulate elections, to influence geopolitics,",
    "start": "7521030",
    "end": "7526039"
  },
  {
    "text": "to influence the economy. There's going to be a huge\namount of incentive to,",
    "start": "7526040",
    "end": "7531739"
  },
  {
    "text": "wait a minute, we have to make sure",
    "start": "7531740",
    "end": "7536740"
  },
  {
    "text": "they're not doing damage. We have to make sure we interpretability, we have to make sure we\nunderstand how these systems",
    "start": "7537440",
    "end": "7542659"
  },
  {
    "text": "function so that we can\npredict their effect on economy, so that there's-- - So there's a futile moral panic--",
    "start": "7542660",
    "end": "7549020"
  },
  {
    "text": "- [Lex] Fairness and safety. - And a bunch of op-eds\nin the \"New York Times\" and nobody actually\nstepping forth and saying,",
    "start": "7549020",
    "end": "7555687"
  },
  {
    "text": "\"You know what, instead of a mega yacht, \"I'd rather put that\nbillion dollars on prizes",
    "start": "7555687",
    "end": "7560907"
  },
  {
    "text": "\"for young hotshot physicists \"who make fundamental\nbreakthroughs in interpretability.\"",
    "start": "7560907",
    "end": "7565407"
  },
  {
    "text": "- The yacht versus the\ninterpretability research, the old trade off. (Lex laughing)",
    "start": "7568010",
    "end": "7575140"
  },
  {
    "text": "I think there's going to be a huge amount of allocation of funds. I hope, I hope, I guess. - You wanna bet me on that?",
    "start": "7576492",
    "end": "7582710"
  },
  {
    "text": "You wanna put a time scale on it. Say how much funds you think\nare going to be allocated in a direction that I would consider",
    "start": "7582710",
    "end": "7588679"
  },
  {
    "text": "to be actually useful by what time? - I do think there will\nbe a huge amount of funds.",
    "start": "7588680",
    "end": "7596600"
  },
  {
    "text": "But you're saying it\nneeds to be open, right? The development of the\nsystems should be closed. But the development of the\ninterpretability research,",
    "start": "7596600",
    "end": "7604760"
  },
  {
    "text": "the AI safety research-- - So we are so far behind\non interpretability",
    "start": "7604760",
    "end": "7610430"
  },
  {
    "text": "compared to capabilities. Like yeah, you could take the\nlast generation of systems.",
    "start": "7610430",
    "end": "7616849"
  },
  {
    "text": "The stuff that's already in the open, there is so much in there\nthat we don't understand. There are so many prizes\nyou could do before",
    "start": "7616850",
    "end": "7623010"
  },
  {
    "text": "you would have enough\ninsights that you'd be like, \"Oh, we understand how these systems work. \"We understand how these\nthings are doing their outputs.",
    "start": "7625527",
    "end": "7631107"
  },
  {
    "text": "\"We can read their minds, \"now let's try it with\nthe bigger systems.\" We're nowhere near that.",
    "start": "7631107",
    "end": "7636320"
  },
  {
    "text": "There is so much\ninterpretability work to be done on the weaker versions of the systems. - So what can you say on\nthe second point you said",
    "start": "7636320",
    "end": "7643318"
  },
  {
    "text": "to Elon Musk on what are some ideas,",
    "start": "7643318",
    "end": "7648318"
  },
  {
    "text": "what are things you could try? \"I can think of a few\nthings I'd try,\" you said, \"They don't fit in one tweet.\"",
    "start": "7648380",
    "end": "7654890"
  },
  {
    "text": "So is there something\nyou could put into words of the things you would try? - I mean, the trouble\nis the stuff is subtle.",
    "start": "7654890",
    "end": "7664310"
  },
  {
    "text": "I've watched people try\nto make progress on this and not get places. Somebody who just gets\nalarmed and charges in,",
    "start": "7664310",
    "end": "7671869"
  },
  {
    "text": "it's like going nowhere. - [Lex] True. - It meant like years ago, I don't know, like 20 years, 15 years,\nsomething like that.",
    "start": "7671870",
    "end": "7679580"
  },
  {
    "text": "I was talking to a congressperson who had become alarmed\nabout the eventual prospects",
    "start": "7679580",
    "end": "7687980"
  },
  {
    "text": "and he wanted work on\nbuilding AIs without emotions",
    "start": "7687980",
    "end": "7692980"
  },
  {
    "text": "because the emotional AI\nwere the scary ones, you see. And some poor person at ARPA had come up",
    "start": "7694430",
    "end": "7702320"
  },
  {
    "text": "with a research proposal\nwhereby this congressman's panic and desire to fund this, the thing,",
    "start": "7702320",
    "end": "7707780"
  },
  {
    "text": "would go into something\nthat the person at ARPA thought would be useful and had\nbeen munched around to where it would sound to the\ncongressman like work",
    "start": "7707780",
    "end": "7714290"
  },
  {
    "text": "was happening on this. Which you know, of course\nthe congressperson had",
    "start": "7714290",
    "end": "7719480"
  },
  {
    "text": "misunderstood the problem and did not understand where the danger came from.",
    "start": "7719480",
    "end": "7724800"
  },
  {
    "text": "And so it's like the issue is\nthat you could like do this",
    "start": "7726080",
    "end": "7731080"
  },
  {
    "text": "in a certain precise way\nand maybe get something. When I say put up prizes\non interpretability,",
    "start": "7732290",
    "end": "7738830"
  },
  {
    "text": "I'm like, because it's verifiable there",
    "start": "7738830",
    "end": "7743830"
  },
  {
    "text": "as opposed to other places, you can tell whether or not good work actually happened in\nthis exact narrow case.",
    "start": "7745130",
    "end": "7751370"
  },
  {
    "text": "If you do things in exactly the right way, you can maybe throw money\nat it at and produce science",
    "start": "7751370",
    "end": "7757190"
  },
  {
    "text": "instead of anti-science and nonsense and all the methods that\nI know of, trying to throw",
    "start": "7757190",
    "end": "7764599"
  },
  {
    "text": "money at this problem,\nshare this property of, well if you do it exactly\nright based on understanding",
    "start": "7764600",
    "end": "7770360"
  },
  {
    "text": "exactly tends to produce\nlike useful outputs or not, then you can add money to it in this way.",
    "start": "7770360",
    "end": "7775800"
  },
  {
    "text": "And the thing that I'm giving\nas an example here in front of this large audience\nthe most understandable",
    "start": "7777320",
    "end": "7783440"
  },
  {
    "text": "of those because there's other\npeople who, like Chris Olah,",
    "start": "7783440",
    "end": "7788440"
  },
  {
    "text": "and even more generally, you can tell whether or not interpretability progress has occurred.",
    "start": "7790700",
    "end": "7796100"
  },
  {
    "text": "So like if I say throw\nmoney at producing more interpretability, there's\na chance somebody can do it",
    "start": "7796100",
    "end": "7801590"
  },
  {
    "text": "that way and it will actually\nproduce useful results. Then the other stuff just\nblurs off into be like,",
    "start": "7801590",
    "end": "7806600"
  },
  {
    "text": "harder to target exactly than that. - So sometimes the\nbasics are fun to explore",
    "start": "7806600",
    "end": "7814219"
  },
  {
    "text": "because they're not so basic. What is interpretability?",
    "start": "7814220",
    "end": "7818363"
  },
  {
    "text": "What does it look like? What are we talking about? - It looks like we took a much smaller set",
    "start": "7819620",
    "end": "7827230"
  },
  {
    "text": "of transformer layers than\nthe ones in the modern bleeding edge state-of-the-art systems.",
    "start": "7828950",
    "end": "7835880"
  },
  {
    "text": "And after applying various\ntools and mathematical",
    "start": "7835880",
    "end": "7840880"
  },
  {
    "text": "ideas and trying 20 different things, we have shown it that this\npiece of the system is doing",
    "start": "7842570",
    "end": "7848840"
  },
  {
    "text": "this kind of useful work. - And then somehow also\nhopefully generalizes",
    "start": "7848840",
    "end": "7854659"
  },
  {
    "text": "some fundamental understanding of what's going on that\ngeneralizes to the bigger system.",
    "start": "7854660",
    "end": "7860603"
  },
  {
    "text": "- You can hope, and it's probably true. Like you would not expect\nthe smaller tricks to go away",
    "start": "7861470",
    "end": "7867920"
  },
  {
    "text": "when you have a system that's\ndoing larger kinds of work, you would expect the larger\nwork kinds of work to be",
    "start": "7867920",
    "end": "7874040"
  },
  {
    "text": "building on top of the smaller\nkinds of work and gradient descent runs across the smaller\nkinds of work before it runs",
    "start": "7874040",
    "end": "7879469"
  },
  {
    "text": "across the larger kinds of work. - Well, that's kind of what is happening in neuroscience, right? It's trying to understand\nthe human brain by prodding",
    "start": "7879470",
    "end": "7887510"
  },
  {
    "text": "and it's such a giant mystery and people have made progress, even though it's extremely\ndifficult to make sense of what's going on in the brain.",
    "start": "7887510",
    "end": "7893838"
  },
  {
    "text": "They have different parts of the brain that are responsible\nfor hearing, for sight. The vision, science community,\nthey're just understanding",
    "start": "7893838",
    "end": "7898940"
  },
  {
    "text": "the visual cortex. I mean they've made a lot of\nprogress in understanding how that stuff works, but you're\nsaying it takes a long time",
    "start": "7898940",
    "end": "7906680"
  },
  {
    "text": "to do that work well. - Also it's not enough. So in particular, let's say you have got",
    "start": "7906680",
    "end": "7914239"
  },
  {
    "text": "your interpretability tools and they say",
    "start": "7914240",
    "end": "7919240"
  },
  {
    "text": "that your current AI system\nis plotting to kill you.",
    "start": "7919716",
    "end": "7924716"
  },
  {
    "text": "Now what? - It is definitely a good step one, right?",
    "start": "7924890",
    "end": "7931849"
  },
  {
    "text": "- [Eliezer] Yeah. What's step two? - If you cut out that\nlayer, is it gonna stop",
    "start": "7931850",
    "end": "7939060"
  },
  {
    "text": "wanting to kill you? - When you optimize against\nvisible misalignment,",
    "start": "7940130",
    "end": "7946750"
  },
  {
    "text": "you are optimizing against misalignment and you are also optimizing\nagainst visibility.",
    "start": "7948860",
    "end": "7954920"
  },
  {
    "text": "So sure, if you can-- (Lex laughing) - It's true. All you're doing is removing\nthe obvious intentions",
    "start": "7954920",
    "end": "7961430"
  },
  {
    "text": "to kill you. - You've got your detector, it's showing something inside the system that you don't like.",
    "start": "7961430",
    "end": "7967250"
  },
  {
    "text": "Okay, say the disaster\nmonkey is running this thing, we'll optimize the system until the visible bad behavior goes away.",
    "start": "7967250",
    "end": "7974929"
  },
  {
    "text": "But it's arising for fundamental reasons of instrumental convergence. The old, you can't bring\nthe coffee if you're dead,",
    "start": "7974930",
    "end": "7982280"
  },
  {
    "text": "any goal and you know, almost\nevery set of utility functions",
    "start": "7982280",
    "end": "7987093"
  },
  {
    "text": "with a few narrow exceptions\nimplies killing all the humans. - But do you think it's\npossible, because we can do",
    "start": "7988670",
    "end": "7994880"
  },
  {
    "text": "experimentation to discover the source of the desire to kill? - I can tell it to you right now,",
    "start": "7994880",
    "end": "8001230"
  },
  {
    "text": "is that it wants to do something\nand the way to get the most of that thing is to put the\nuniverse into a state where",
    "start": "8001230",
    "end": "8008830"
  },
  {
    "text": "there aren't humans. - So is it possible to encode\nin the same way we think?",
    "start": "8008830",
    "end": "8014920"
  },
  {
    "text": "Like why do we think murder is wrong? The same foundational ethics,\nthat's not hard coded in",
    "start": "8014920",
    "end": "8022170"
  },
  {
    "text": "but more like deeper. I mean that's part of the research. How do you have it that this transformer,",
    "start": "8023290",
    "end": "8029800"
  },
  {
    "text": "this small version of the language model doesn't ever want to kill?",
    "start": "8029800",
    "end": "8036283"
  },
  {
    "text": "- That'd be nice assuming that you got \"doesn't want to kill\"\nsufficiently exactly right.",
    "start": "8039160",
    "end": "8045580"
  },
  {
    "text": "That it didn't be like, \"Oh, I will detach their heads\nand put them in some jars \"and keep the heads alive forever\nand then go do the thing.\"",
    "start": "8045580",
    "end": "8052179"
  },
  {
    "text": "But leaving that aside,\nwell, not leaving that aside. - [Lex] Yeah, that's good,\nit gets a strong point, yeah. - 'Cause there is a whole issue",
    "start": "8052180",
    "end": "8058630"
  },
  {
    "text": "where as something gets smarter, it finds ways of achieving the\nsame goal predicate that were",
    "start": "8058630",
    "end": "8065640"
  },
  {
    "text": "not imaginable to stupider\nversions of the system or perhaps the stupider operators.",
    "start": "8065860",
    "end": "8071230"
  },
  {
    "text": "That's one of many things\nmaking this difficult. A larger thing making this\ndifficult is that we do not know",
    "start": "8071230",
    "end": "8077320"
  },
  {
    "text": "how to get any goals into systems at all. We know how to get outwardly\nobservable behaviors",
    "start": "8077320",
    "end": "8082719"
  },
  {
    "text": "into systems. We do not know how to get\ninternal psychological wanting",
    "start": "8082720",
    "end": "8088270"
  },
  {
    "text": "to do particular things into the system. That is not what the\ncurrent technology does.",
    "start": "8088270",
    "end": "8093100"
  },
  {
    "text": "- I mean, it could be things\nlike dystopian futures, like \"Brave New World\" where\nmost humans will actually say,",
    "start": "8094988",
    "end": "8101627"
  },
  {
    "text": "\"We kind of want that future.\" It's a great future. Everybody's happy. - We would have to get\nso far, so much further",
    "start": "8101627",
    "end": "8110170"
  },
  {
    "text": "than we are now and further faster\nbefore that failure mode",
    "start": "8110170",
    "end": "8115390"
  },
  {
    "text": "became a running concern. - Your failure modes\nare much more drastic.",
    "start": "8115390",
    "end": "8120972"
  },
  {
    "text": "The ones you're-- - The failure modes are much simpler. It's like yeah, the AI puts the universe into a particular state.",
    "start": "8120972",
    "end": "8126183"
  },
  {
    "text": "It happens to not have\nany humans inside it. - Okay, so the paper club maximizer.",
    "start": "8126183",
    "end": "8130423"
  },
  {
    "text": "- Utility, so the original version of the paperclip maximizer-- - Can you explain it if you can? - Okay.",
    "start": "8131710",
    "end": "8137620"
  },
  {
    "text": "The original version was you lose control of the utility function and it so happens that\nwhat maxes out the utility",
    "start": "8137620",
    "end": "8146277"
  },
  {
    "text": "per unit resources is tiny\nmolecular shapes like paperclips.",
    "start": "8147370",
    "end": "8152370"
  },
  {
    "text": "There's a lot of things\nthat make it happy, but the cheapest one that didn't\nsaturate was putting matter",
    "start": "8152470",
    "end": "8159720"
  },
  {
    "text": "into certain shapes. And it so happens that the cheapest way to make these shapes is\nto make them very small,",
    "start": "8160480",
    "end": "8166329"
  },
  {
    "text": "'cause then you need fewer atoms, per instance of the shape and arguendo,",
    "start": "8166330",
    "end": "8170653"
  },
  {
    "text": "it happens to look like a paperclip. In retrospect I wish I'd\nsaid tiny molecular spirals",
    "start": "8172390",
    "end": "8177830"
  },
  {
    "text": "or tiny molecular hyperbolic spirals. Why? Because I said tiny molecular paperclips,",
    "start": "8178690",
    "end": "8184673"
  },
  {
    "text": "this got then mutated to paperclips, this then mutated to,",
    "start": "8184673",
    "end": "8189827"
  },
  {
    "text": "\"And the AI was in a paperclip factory.\" So the original story is\nabout how you lose control",
    "start": "8189827",
    "end": "8196420"
  },
  {
    "text": "of the system, it doesn't want what you\ntried to make it want. The thing that it ends up wanting most",
    "start": "8196420",
    "end": "8201880"
  },
  {
    "text": "is a thing that even from a very embracing cosmopolitan perspective, we\nthink of as having no value and that's how the value of\nthe future gets destroyed.",
    "start": "8201880",
    "end": "8209679"
  },
  {
    "text": "Then that got changed to a fable of, well, you made a paperclip\nfactory and it did exactly",
    "start": "8209680",
    "end": "8214809"
  },
  {
    "text": "what you wanted, but you asked\nit to do the wrong thing. Which is a completely\ndifferent failure path.",
    "start": "8214810",
    "end": "8221412"
  },
  {
    "text": "(Eliezer sighs) - But those are both concerns to you.",
    "start": "8222429",
    "end": "8229480"
  },
  {
    "text": "So that's more than-- - If you \"Brave New World.\" If you can solve the problem\nof making something want",
    "start": "8229481",
    "end": "8235010"
  },
  {
    "text": "what exactly what you want it to want, then you get to deal with the problem of wanting the right thing.",
    "start": "8236410",
    "end": "8242260"
  },
  {
    "text": "- But first you have\nto solve the alignment. - First you have to solve inner alignment. - [Lex] Inner alignment. - Then you get to solve outer alignment.",
    "start": "8242260",
    "end": "8248940"
  },
  {
    "text": "First you need to be\nable to point the insides of the thing in a direction\nand then you get to deal with",
    "start": "8251710",
    "end": "8257349"
  },
  {
    "text": "whether that direction expressed\nin reality is the thing that it aligned with\nthe thing that you want.",
    "start": "8257350",
    "end": "8262892"
  },
  {
    "text": "- Are you scared? - Of this whole thing?",
    "start": "8265507",
    "end": "8268859"
  },
  {
    "text": "Probably. I don't really know. - What gives you hope about this?",
    "start": "8270700",
    "end": "8277152"
  },
  {
    "text": "- [Eliezer] The\npossibility of being wrong. - Not that you're right, but we will actually get our\nact together and allocate",
    "start": "8277153",
    "end": "8284829"
  },
  {
    "text": "a lot of resources to\nthe alignment problem. - Well, I can easily imagine\nthat at some point this panic",
    "start": "8284830",
    "end": "8291880"
  },
  {
    "text": "expresses itself in the\nwaste of a billion dollars. Spending a billion dollars\ncorrectly, that's harder.",
    "start": "8291880",
    "end": "8298929"
  },
  {
    "text": "- To solve both the inner\nand the outer alignment. If you're wrong--\n- To solve a number of things. - Yeah. Number of things.",
    "start": "8298930",
    "end": "8304960"
  },
  {
    "text": "If you're wrong, what do you\nthink would be the reason?",
    "start": "8304960",
    "end": "8309960"
  },
  {
    "text": "Like if 50 years from\nnow, not perfectly wrong, you make a lot of really eloquent points,",
    "start": "8310300",
    "end": "8316783"
  },
  {
    "text": "there's a lot of shape\nto the ideas you express. But if you're somewhat wrong\nabout some fundamental ideas,",
    "start": "8318250",
    "end": "8325540"
  },
  {
    "text": "why would that be? - Stuff has to be easier\nthen I think it is.",
    "start": "8325540",
    "end": "8331063"
  },
  {
    "text": "The first time you're building a rocket, being wrong is in a\ncertain sense quite easy.",
    "start": "8332380",
    "end": "8339130"
  },
  {
    "text": "Happening to be wrong in a way where the rocket goes twice\nas far on half the fuel and lands exactly where\nyou hoped it would?",
    "start": "8339130",
    "end": "8345390"
  },
  {
    "text": "Most cases of being wrong make\nit harder to build a rocket, harder to have it not explode. 'Cause it to require more\nfuel than you hope to,",
    "start": "8346330",
    "end": "8353529"
  },
  {
    "text": "cause it to be led off target. Being wrong in a way\nthat makes stuff easier, that's not the usual\nproject management story.",
    "start": "8353531",
    "end": "8360733"
  },
  {
    "text": "- And then this is the first\ntime we're really tackling the problem of a AI alignment. There's no examples in\nin history where we...",
    "start": "8362529",
    "end": "8368080"
  },
  {
    "text": "- Oh, there's all kinds of\nthings that are similar if you generalize and correctly the\nright way and aren't fooled",
    "start": "8368080",
    "end": "8373179"
  },
  {
    "text": "by misleading metaphors. - Like what? - Humans being misaligned on\ninclusive genetic fitness.",
    "start": "8373180",
    "end": "8379900"
  },
  {
    "text": "So inclusive genetic fitness\nis like not just your reproductive fitness, but also the fitness of your relatives,",
    "start": "8379901",
    "end": "8385563"
  },
  {
    "text": "the people who share some\nfraction of your genes. The old joke is,",
    "start": "8385564",
    "end": "8391630"
  },
  {
    "text": "would you give your life\nto save your brother? They once asked a biologist, I think it was Haldane, and Haldane said,",
    "start": "8391630",
    "end": "8397787"
  },
  {
    "text": "\"No, but I would give my\nlife to save two brothers \"or eight cousins.\" Because a brother on average\nshares half your genes.",
    "start": "8397787",
    "end": "8405310"
  },
  {
    "text": "And cousin on average shares\nan eighth of your genes. So that's inclusive genetic fitness. And you can view natural\nselection as optimizing humans",
    "start": "8405310",
    "end": "8414400"
  },
  {
    "text": "exclusively around this\none very simple criterion, like how much more frequent\ndid your genes become",
    "start": "8414400",
    "end": "8421870"
  },
  {
    "text": "in the next generation? In fact, that just is natural selection. It doesn't optimize for that.",
    "start": "8421870",
    "end": "8427390"
  },
  {
    "text": "But rather the process of\ngenes becoming more frequent is that you can nonetheless imagine that there is this hill climbing process,",
    "start": "8427390",
    "end": "8434350"
  },
  {
    "text": "not like gradient descent, because gradient descent uses calculus. This is just using like where are you?",
    "start": "8434350",
    "end": "8440080"
  },
  {
    "text": "But still hill climbing in both cases, make things something better\nand better over time, in steps.",
    "start": "8440080",
    "end": "8445333"
  },
  {
    "text": "And natural selection was\noptimizing exclusively for this very simple, pure criterion",
    "start": "8447040",
    "end": "8452350"
  },
  {
    "text": "of inclusive genetic fitness in a very complicated environment,",
    "start": "8452350",
    "end": "8458050"
  },
  {
    "text": "we're doing a very wide range\nof things and solving a wide range of problems, led\nit to having more kids.",
    "start": "8458050",
    "end": "8465133"
  },
  {
    "text": "And this got you humans, which had no internal notion\nof inclusive genetic fitness",
    "start": "8466480",
    "end": "8474600"
  },
  {
    "text": "until thousands of years\nlater when they were actually figuring out what had even happened.",
    "start": "8474910",
    "end": "8479473"
  },
  {
    "text": "And no explicit desire to increase inclusive genetic fitness.",
    "start": "8480880",
    "end": "8486855"
  },
  {
    "text": "So from this important case study, we may infer the important fact\nthat if you do a whole bunch",
    "start": "8486856",
    "end": "8494290"
  },
  {
    "text": "of hill climbing on a\nvery simple loss function, at the point where the\nsystem's capabilities",
    "start": "8494290",
    "end": "8500950"
  },
  {
    "text": "start to generalize very widely, when it is in an intuitive\nsense becoming very capable",
    "start": "8500950",
    "end": "8507040"
  },
  {
    "text": "and generalizing far outside\nthe training distribution, we know that there is no general\nloss saying that the system",
    "start": "8507040",
    "end": "8514460"
  },
  {
    "text": "even internally represents, let alone tries to optimize\nthe very simple loss function",
    "start": "8515830",
    "end": "8522190"
  },
  {
    "text": "you are training it on. - There is so much that we\ncannot possibly cover all of it. I think we did a good job\nof getting your sense from",
    "start": "8522190",
    "end": "8531460"
  },
  {
    "text": "different perspectives of\nthe current state of the art with large language models. We got a good sense of your concern",
    "start": "8531460",
    "end": "8540190"
  },
  {
    "text": "about the threats of AGI. - I've talked here about\nthe power of intelligence",
    "start": "8540190",
    "end": "8546580"
  },
  {
    "text": "and not really gotten very far into it, but not like, why it is.",
    "start": "8546580",
    "end": "8551920"
  },
  {
    "text": "Suppose you screw up with\nAGI and it end up wanting a bunch of random stuff.",
    "start": "8551920",
    "end": "8556990"
  },
  {
    "text": "Why does it try to kill you? Why doesn't it try to trade with you?",
    "start": "8556990",
    "end": "8563020"
  },
  {
    "text": "Why doesn't it give you just\nthe tiny little fraction of the solar system that it would",
    "start": "8563020",
    "end": "8569410"
  },
  {
    "text": "take to keep everyone alive? - Yeah well, that's a good question. What are the different\ntrajectories that intelligence,",
    "start": "8569410",
    "end": "8576340"
  },
  {
    "start": "8571000",
    "end": "9003000"
  },
  {
    "text": "when acted upon this\nworld, super intelligence, what are the different\ntrajectories for this universe with such an intelligence in it?",
    "start": "8576340",
    "end": "8582790"
  },
  {
    "text": "Do most of them not include humans? - I mean, the vast majority\nof randomly specified utility",
    "start": "8582790",
    "end": "8590080"
  },
  {
    "text": "functions do not have\noptima with humans in them, would be the first\nthing I would point out.",
    "start": "8590080",
    "end": "8598090"
  },
  {
    "text": "And then the next question is like, well, if you try to optimize something, you lose control of it. Where in that space do you land?",
    "start": "8598090",
    "end": "8604720"
  },
  {
    "text": "'Cause it's not random, but it also doesn't necessarily\nhave room for humans in it.",
    "start": "8604720",
    "end": "8609850"
  },
  {
    "text": "I suspect that the average\nmember of the audience might have some questions about even\nwhether that's the correct",
    "start": "8609850",
    "end": "8615040"
  },
  {
    "text": "paradigm to think about\nit and would sort of want to back up a bit possibly. - If we back up to something\nbigger than humans,",
    "start": "8615040",
    "end": "8624104"
  },
  {
    "text": "if we look at Earth and life\non Earth and what is truly special about life on Earth,",
    "start": "8625114",
    "end": "8630553"
  },
  {
    "text": "do you think it's possible that whatever that special thing is,",
    "start": "8632200",
    "end": "8638050"
  },
  {
    "text": "let's explore what that\nspecial thing could be. Whatever that special thing is, that thing appears often\nin the objective function.",
    "start": "8638050",
    "end": "8646000"
  },
  {
    "text": "- Why? I know what you hope, but you know,",
    "start": "8646000",
    "end": "8652180"
  },
  {
    "text": "you can hope that a particular set of winning lottery numbers\ncome up and it doesn't make the lottery balls come up that way.",
    "start": "8652180",
    "end": "8658689"
  },
  {
    "text": "I know you want this to be\ntrue, but why would it be true? - There's a line from \"Grumpy Old Men\"",
    "start": "8658690",
    "end": "8664720"
  },
  {
    "text": "where this guy says, in\na grocery store, he says, \"You can wish in one hand\nand crap in the other",
    "start": "8664720",
    "end": "8669827"
  },
  {
    "text": "\"and see which one fills up first.\" - There's a science problem. We are trying to predict\nwhat happens with AI systems",
    "start": "8669827",
    "end": "8676330"
  },
  {
    "text": "that you tried to\noptimize to imitate humans and then you did some of RLHF to them",
    "start": "8676330",
    "end": "8683180"
  },
  {
    "text": "and of course you didn't\nget like perfect alignment because that's not what happens",
    "start": "8685863",
    "end": "8691660"
  },
  {
    "text": "when you hill climb towards\na outer loss function. You don't get inner alignment on it.",
    "start": "8691660",
    "end": "8696760"
  },
  {
    "text": "But yeah, so if you\ndon't mind my like taking",
    "start": "8696760",
    "end": "8701173"
  },
  {
    "text": "some slight control of\nthings and steering around to what I think is like\na good place to start.",
    "start": "8705250",
    "end": "8710350"
  },
  {
    "text": "- I just failed to solve\nthe control problem. I've lost control of this thing. - Alignment. Alignment.",
    "start": "8710350",
    "end": "8715873"
  },
  {
    "text": "- Still aligned. (laughing) - Yeah, okay, sure. Yeah, you lost control. - But we're still aligned.",
    "start": "8716950",
    "end": "8722590"
  },
  {
    "text": "Anyway, sorry for the meta comment. - Yeah, losing control isn't as bad as you lose control to an aligned system.",
    "start": "8722590",
    "end": "8727750"
  },
  {
    "text": "- [Lex] Yes, exactly. - You have no idea of the horrors I will shortly unleash\non this conversation. (both laughing)",
    "start": "8727750",
    "end": "8734350"
  },
  {
    "text": "- All right. Sorry, sorry to distract you completely. What were you gonna say\nin terms of taking control of the conversation?",
    "start": "8734350",
    "end": "8740109"
  },
  {
    "text": "- So I think that there's like a (speaking foreign language) here,",
    "start": "8740110",
    "end": "8746740"
  },
  {
    "text": "if I'm pronouncing those\nwords remotely like correctly, 'cause of course we only ever read them and not hear them spoken.",
    "start": "8746740",
    "end": "8751273"
  },
  {
    "text": "For some people, the word\nintelligence, smartness is not a word of power to them.",
    "start": "8756100",
    "end": "8762790"
  },
  {
    "text": "It means chess players,\nit means the college university professor, people\naren't very successful in life.",
    "start": "8762790",
    "end": "8769600"
  },
  {
    "text": "It doesn't mean like charisma\nto which my usual thing is like charisma is not\ngenerated in the liver",
    "start": "8769600",
    "end": "8774700"
  },
  {
    "text": "rather than the brain. Charisma is also a cognitive function.",
    "start": "8774700",
    "end": "8777440"
  },
  {
    "text": "So if you think that smartness doesn't sound very threatening,",
    "start": "8781060",
    "end": "8786670"
  },
  {
    "text": "then super intelligence is not gonna sound very\nthreatening either. It's gonna sound like you\njust pull the off switch.",
    "start": "8786670",
    "end": "8793149"
  },
  {
    "text": "Well, it's super intelligent\nbut it's stuck in a computer. We pull the off switch, problem solved.",
    "start": "8794770",
    "end": "8798400"
  },
  {
    "text": "And the other side of it is\nyou have a lot of respect for the notion of intelligence.",
    "start": "8800050",
    "end": "8805420"
  },
  {
    "text": "You're like, well yeah,\nthat's what humans have. That's the human superpower. And it sounds like it could be dangerous,",
    "start": "8805420",
    "end": "8812890"
  },
  {
    "text": "but why would it be? We, as we have grown more intelligent,",
    "start": "8812890",
    "end": "8819460"
  },
  {
    "text": "also grown less kind. Chimpanzees are in fact a\nbit less kind than humans",
    "start": "8819460",
    "end": "8825430"
  },
  {
    "text": "and you know, you could argue that out. But often the sort of person\nwho has a deep respect for",
    "start": "8825430",
    "end": "8830920"
  },
  {
    "text": "intelligence is gonna be like, \"Well, yes, \"you can't even have kindness\nunless you know what that is.\"",
    "start": "8830920",
    "end": "8835927"
  },
  {
    "text": "And so they're like, why would it do something as\nstupid as making paperclips?",
    "start": "8837100",
    "end": "8843100"
  },
  {
    "text": "Aren't you supposing something\nthat's smart enough to be dangerous but also stupid\nenough that it will just make",
    "start": "8843100",
    "end": "8848950"
  },
  {
    "text": "paperclips and never question that? In some cases people are like, \"Well, even if you misspecify\nthe objective function,",
    "start": "8848950",
    "end": "8857417"
  },
  {
    "text": "\"won't you realize that what\nyou really wanted was x? \"Are you supposing something\nthat is smart enough to be",
    "start": "8857417",
    "end": "8864857"
  },
  {
    "text": "\"dangerous but stupid enough\nthat it doesn't understand what \"the humans really meant\nwhen they specified",
    "start": "8864857",
    "end": "8870107"
  },
  {
    "text": "\"the objective function?\" - So to you, our intuition\nabout intelligence is limited.",
    "start": "8870107",
    "end": "8877260"
  },
  {
    "text": "We should think about intelligence\nas a much bigger thing. - Well, I'm saying that it's that-- - [Lex] That humanness.",
    "start": "8877480",
    "end": "8883000"
  },
  {
    "text": "- Well, what what I'm saying\nis like what do you think about artificial intelligence?",
    "start": "8883000",
    "end": "8888192"
  },
  {
    "text": "Depends on what you\nthink about intelligence. - So how do we think about\nintelligence correctly? Like you gave one thought\nexperiment to think of,",
    "start": "8889330",
    "end": "8897880"
  },
  {
    "text": "think of a thing that's much\nfaster, so it just gets faster and faster, faster and faster. - And it also is like is\nmade of John von Neumann",
    "start": "8897880",
    "end": "8904510"
  },
  {
    "text": "and there's lots of them. - [Lex] Or (indistinct). - Yeah, John von Neumann\nis a historical case,",
    "start": "8904510",
    "end": "8911200"
  },
  {
    "text": "so you can like look up what he did and imagine based on that. And we know people have\nsome intuition for like,",
    "start": "8911200",
    "end": "8918069"
  },
  {
    "text": "if you have more humans, they can solve tougher cognitive problems. Although in fact like in the game",
    "start": "8918070",
    "end": "8924130"
  },
  {
    "text": "of Kasparov versus the World which was like Garry Kasparov\non one side and an entire",
    "start": "8924130",
    "end": "8931350"
  },
  {
    "text": "hoard of internet people led\nby four chess grand masters on the other side, Kasparov won.",
    "start": "8931510",
    "end": "8937390"
  },
  {
    "text": "So like all those people\naggregated to be smarter, it was a hard fought game.",
    "start": "8937390",
    "end": "8943420"
  },
  {
    "text": "It's like all those people\naggregated to be smarter than any individual one of them, but they didn't aggregate so well",
    "start": "8943420",
    "end": "8948850"
  },
  {
    "text": "that they could defeat Kasparov But so humans aggregating\ndon't actually get, in my opinion, very much smarter,",
    "start": "8948850",
    "end": "8955600"
  },
  {
    "text": "especially compared to\nrunning them for longer. The difference between capabilities\nnow and a thousand years",
    "start": "8955600",
    "end": "8962439"
  },
  {
    "text": "ago is a bigger gap than\nthe gap in capabilities between 10 people and one person.",
    "start": "8962440",
    "end": "8967993"
  },
  {
    "text": "But even so, pumping\nintuition for what it means to augment intelligence, John von Neumann,",
    "start": "8969460",
    "end": "8976779"
  },
  {
    "text": "there's millions of him, he runs at a million times the\nspeed and therefore can solve",
    "start": "8976780",
    "end": "8983529"
  },
  {
    "text": "tougher problems, quite a lot tougher. - It's very hard to have an intuition",
    "start": "8983530",
    "end": "8990040"
  },
  {
    "text": "about what that looks like, especially like you said, the intuition,",
    "start": "8990040",
    "end": "8995283"
  },
  {
    "text": "I kind of think about is\nit maintains the humanness.",
    "start": "8996970",
    "end": "9001203"
  },
  {
    "start": "9003000",
    "end": "9393000"
  },
  {
    "text": "I think it's hard to separate my hope",
    "start": "9004290",
    "end": "9008477"
  },
  {
    "text": "from my objective intuition about what super intelligent\nsystems look like.",
    "start": "9010560",
    "end": "9017760"
  },
  {
    "text": "- If one studies evolutionary\nbiology with a bit of math",
    "start": "9017760",
    "end": "9022760"
  },
  {
    "text": "and in particular books\nfrom when the field was just sort of properly coalescing\nand knowing itself,",
    "start": "9024900",
    "end": "9033510"
  },
  {
    "text": "like not the modern textbooks, which are just memorize this legible math. so you can do well on these tests, but what people were writing\nas the basic paradigms",
    "start": "9033510",
    "end": "9041310"
  },
  {
    "text": "of the field were being fought out... A nice book if you've\ngot the time to read it",
    "start": "9041310",
    "end": "9046949"
  },
  {
    "text": "is \"Adaptation and Natural Selection,\" Which is one of the founding books,",
    "start": "9046950",
    "end": "9052200"
  },
  {
    "text": "you can find people being optimistic about what the utterly\nalien optimization process",
    "start": "9052200",
    "end": "9059700"
  },
  {
    "text": "of natural selection will\nproduce in the way of how it optimizes its objectives.",
    "start": "9059700",
    "end": "9066210"
  },
  {
    "text": "You got people arguing that\nlike, in the early days biologists said, \"Well,\norganisms will restrain",
    "start": "9066210",
    "end": "9073717"
  },
  {
    "text": "\"their own reproduction\nwhen resources are scarce \"so as not to overfeed the system.\"",
    "start": "9073717",
    "end": "9081660"
  },
  {
    "text": "And this is not how\nnatural selection works, it's about whose genes are\nrelatively more prevalent",
    "start": "9081660",
    "end": "9088560"
  },
  {
    "text": "to the next generation. And if you restrain reproduction,",
    "start": "9088560",
    "end": "9094830"
  },
  {
    "text": "those genes get less frequent\nin the next generation compared to your conspecifics. And natural selection doesn't do that.",
    "start": "9094830",
    "end": "9102900"
  },
  {
    "text": "In fact, predators overrun\nprey populations all the time and have crashes. That's just a thing that\nhappens and many years later...",
    "start": "9102900",
    "end": "9111000"
  },
  {
    "text": "Well oh, oh oh. But people said like,\n\"Well, but group selection.\" Right? What about groups of organisms?",
    "start": "9111000",
    "end": "9115683"
  },
  {
    "text": "And basically the math of group selection almost never works out in\npractice is the answer there.",
    "start": "9116610",
    "end": "9122729"
  },
  {
    "text": "But also years later, somebody actually ran the\nexperiment where they took populations of insects and\nselected the whole populations",
    "start": "9122730",
    "end": "9132680"
  },
  {
    "text": "to have lower sizes. Now you just take pop\none, pop two, pop three, pop four look at which has the\nlowest total number of them",
    "start": "9132930",
    "end": "9140010"
  },
  {
    "text": "in the next generation\nand select that one. What do you suppose happens\nwhen you select populations",
    "start": "9140010",
    "end": "9145290"
  },
  {
    "text": "of insects like that? Well, what happens is\nnot that the individuals in the population evolve\nto restrain their breeding,",
    "start": "9145290",
    "end": "9150720"
  },
  {
    "text": "but that they evolved\nto kill the offspring of other organisms, especially the girls.",
    "start": "9150720",
    "end": "9156030"
  },
  {
    "text": "So people imagined this lovely, beautiful, harmonious output of natural selection,",
    "start": "9156030",
    "end": "9163506"
  },
  {
    "text": "which is these populations\nrestraining their own breeding so that groups of them\nwould stay in harmony with the resources available.",
    "start": "9163506",
    "end": "9170130"
  },
  {
    "text": "And mostly the math\nnever works out for that. But if you actually apply\nthe weird strange conditions to get group selection that\nbeats individual selection,",
    "start": "9170130",
    "end": "9176853"
  },
  {
    "text": "what you get is female infanticide. Like if you're reading on\nrestrained populations.",
    "start": "9176853",
    "end": "9183902"
  },
  {
    "text": "So this is not a smart\noptimization process. Natural selection is like so\nincredibly stupid and simple",
    "start": "9187200",
    "end": "9192720"
  },
  {
    "text": "that we can actually\nquantify how stupid it is if you read the textbooks with the math. Nonetheless, this is\nthe sort of basic thing",
    "start": "9192720",
    "end": "9198557"
  },
  {
    "text": "of you look at this alien\noptimization process and there's the thing that\nyou hope it will produce",
    "start": "9198557",
    "end": "9204750"
  },
  {
    "text": "and you have to learn to\nclear that out of your mind and just think about the\nunderlying dynamics and where",
    "start": "9204750",
    "end": "9211500"
  },
  {
    "text": "it finds the maximum from its\nstandpoint that it's looking for rather than how it finds\nthat thing that lept into your",
    "start": "9211500",
    "end": "9219330"
  },
  {
    "text": "mind as the beautiful aesthetic solution that you hope it finds. And this is something that was, has been fought out\nhistorically as the field",
    "start": "9219330",
    "end": "9226890"
  },
  {
    "text": "of biology was coming to terms\nwith evolutionary biology.",
    "start": "9226890",
    "end": "9231890"
  },
  {
    "text": "And you can like look at\nthem fighting it out as they get to terms with this very alien, inhuman optimization process.",
    "start": "9232385",
    "end": "9241620"
  },
  {
    "text": "And indeed something smarter\nthan us would be also much smarter than natural selection. So it doesn't just\nautomatically carry over.",
    "start": "9241620",
    "end": "9249570"
  },
  {
    "text": "But there's a lesson\nthere, there's a warning. - To you, natural selection\nis a deeply suboptimal process",
    "start": "9249570",
    "end": "9258050"
  },
  {
    "text": "that could be significantly improved on and would be by an AGI system. - Well, it's kind of stupid. It has to run hundreds\nof generations to notice",
    "start": "9258300",
    "end": "9266820"
  },
  {
    "text": "that something is working. It doesn't be like, oh, well I tried this in one\norganism, I saw it worked,",
    "start": "9266820",
    "end": "9273390"
  },
  {
    "text": "now I'm going to duplicate that feature onto everything immediately. Has to run for hundreds of generations",
    "start": "9273390",
    "end": "9278939"
  },
  {
    "text": "for a new mutation tries to fixation. - I wonder if there's a case to be made in natural selection,",
    "start": "9278940",
    "end": "9284223"
  },
  {
    "text": "as inefficient as it looks\nis actually quite powerful.",
    "start": "9285540",
    "end": "9289703"
  },
  {
    "text": "That this is extremely robust. - It runs for a long time and eventually manages to optimize things.",
    "start": "9294180",
    "end": "9301112"
  },
  {
    "text": "It's weaker than gradient\ndissent because gradient dissent also uses information\nabout the derivative.",
    "start": "9302760",
    "end": "9307820"
  },
  {
    "text": "- Yeah, evolution seems to be, there's not really an objective function.",
    "start": "9308670",
    "end": "9313950"
  },
  {
    "text": "- [Eliezer] There's\ninclusive genetic fitness is the implicit loss\nfunction of evolutions. - It's implicit\n- It cannot change.",
    "start": "9313950",
    "end": "9319890"
  },
  {
    "text": "The loss function doesn't change, the environment changes\nand therefore what gets",
    "start": "9319890",
    "end": "9324899"
  },
  {
    "text": "optimized for in the organism changes. Take like GPT-3.",
    "start": "9324900",
    "end": "9330351"
  },
  {
    "text": "You imagine like different\nversions of GPT-3 where they're all trying\nto predict the next word, but they're being run on\ndifferent data sets of text",
    "start": "9330351",
    "end": "9337920"
  },
  {
    "text": "and that's like natural selection, always inclusive genetic fitness but different environmental problems.",
    "start": "9337920",
    "end": "9344192"
  },
  {
    "text": "(Lex exhales) - It's difficult to think about. So if we are saying the\nnatural selection is stupid,",
    "start": "9346513",
    "end": "9353729"
  },
  {
    "text": "if we're saying the\nhumans are stupid, it's-- - Smarter than natural selection,",
    "start": "9353730",
    "end": "9359040"
  },
  {
    "text": "stupider than the upper bound. - Do you think there's an\nupper bound by the way?",
    "start": "9359040",
    "end": "9364650"
  },
  {
    "text": "That's another helpful place. - I mean, if you put enough matter, energy compute into one place,",
    "start": "9364650",
    "end": "9370530"
  },
  {
    "text": "it will collapse into a black hole. (Lex laughing) There's only so much computation\ncan do before you run out",
    "start": "9370530",
    "end": "9376050"
  },
  {
    "text": "of negentropy and the universe dies. So there's an upper bound, but it's very, very,\nvery far up above here.",
    "start": "9376050",
    "end": "9383580"
  },
  {
    "text": "Like the supernova is only finitely hot, it's not infinitely hot but it's really, really,\nreally, really hot.",
    "start": "9383580",
    "end": "9390250"
  },
  {
    "text": "- Well, let me ask you, let me talk to you about\nconsciousness, also coupled with that question is imagining a world",
    "start": "9392400",
    "end": "9399210"
  },
  {
    "start": "9393000",
    "end": "10024000"
  },
  {
    "text": "with superintelligent AI systems that get rid of humans\nbut nevertheless keep",
    "start": "9399210",
    "end": "9404260"
  },
  {
    "text": "something that we would\nconsider beautiful and amazing. - Why?",
    "start": "9407400",
    "end": "9411473"
  },
  {
    "text": "The lesson of evolutionary biology. If you just guess what\nan optimization does based on what you hope\nthe results will be,",
    "start": "9413130",
    "end": "9420420"
  },
  {
    "text": "it usually will not do that. - It's not hope. I mean it's not hope. I think if you objectively look at",
    "start": "9420420",
    "end": "9426360"
  },
  {
    "text": "what has been a powerful, a useful...",
    "start": "9426360",
    "end": "9430400"
  },
  {
    "text": "I think there's a correlation\nbetween what we find beautiful and a thing that's been useful.",
    "start": "9432422",
    "end": "9438689"
  },
  {
    "text": "- This is what the early\nbiologists thought. And not just like, they thought.",
    "start": "9438690",
    "end": "9444360"
  },
  {
    "text": "Like \"No, no, I'm not just imagining stuff \"that would be pretty,\nit's useful for organisms",
    "start": "9444360",
    "end": "9450337"
  },
  {
    "text": "\"to restrain their own reproduction \"because then they don't overrun \"the prey populations and\nthey actually have more kids",
    "start": "9450337",
    "end": "9456877"
  },
  {
    "text": "\"in the long run.\" - Hmm. So let me just ask you\nabout consciousness.",
    "start": "9456877",
    "end": "9463211"
  },
  {
    "text": "Do you think consciousness is useful. - [Eliezer] To humans? - No, to AGI systems.",
    "start": "9463211",
    "end": "9469380"
  },
  {
    "text": "Well, in this transitionary\nperiod between humans and AGI,",
    "start": "9469380",
    "end": "9474380"
  },
  {
    "text": "to AGI systems as they\nbecome smarter and smarter, is there some use to it? Let me step back.",
    "start": "9474851",
    "end": "9480630"
  },
  {
    "text": "What is consciousness? Eliezer Yudkowsky, what is consciousness?",
    "start": "9480630",
    "end": "9486750"
  },
  {
    "text": "- Are referring to\nChalmers as hard problem of conscious experience?",
    "start": "9486750",
    "end": "9491880"
  },
  {
    "text": "Are you referring to\nself-awareness and reflection? Are you referring to\nthe state of being awake",
    "start": "9491880",
    "end": "9497520"
  },
  {
    "text": "as opposed to asleep? - This is how I know you're\nan advanced language model.",
    "start": "9497520",
    "end": "9502590"
  },
  {
    "text": "I gave you a simple prompt and you gave me a bunch of options.",
    "start": "9502590",
    "end": "9505750"
  },
  {
    "text": "I think I'm referring to all,",
    "start": "9510450",
    "end": "9511983"
  },
  {
    "text": "including the hard\nproblem of consciousness. What is it in its importance\nto what you've just been",
    "start": "9515550",
    "end": "9522210"
  },
  {
    "text": "talking about, which is intelligence? Is it a foundation to intelligence?",
    "start": "9522210",
    "end": "9528330"
  },
  {
    "text": "Is it intricately\nconnected to intelligence in the human mind or is it a\nside effect of the human mind?",
    "start": "9528330",
    "end": "9536210"
  },
  {
    "text": "It is a useful little tool,\nlike we can get rid of? I guess I'm trying to get\nsome color in your opinion",
    "start": "9536280",
    "end": "9545610"
  },
  {
    "text": "of how useful it is in the intelligence of a human being and then\ntry to generalize that to AI,",
    "start": "9545610",
    "end": "9551820"
  },
  {
    "text": "whether AI will keep some of that. - So I think that for\nthere to be like a person",
    "start": "9551820",
    "end": "9559950"
  },
  {
    "text": "who I care about looking\nout at the universe and wondering at it and appreciating it,",
    "start": "9559950",
    "end": "9564304"
  },
  {
    "text": "it's not enough to have\na model of yourself.",
    "start": "9565200",
    "end": "9569343"
  },
  {
    "text": "I think that it is useful to\nan intelligent mind to have a model of itself, but I think\nyou can have that without",
    "start": "9571170",
    "end": "9579699"
  },
  {
    "text": "pleasure, pain, aesthetics,",
    "start": "9581340",
    "end": "9584833"
  },
  {
    "text": "emotion, a sense of wonder.",
    "start": "9588360",
    "end": "9593360"
  },
  {
    "text": "Like I think you can have\na model of how much memory you're using and whether\nthis thought or that thought",
    "start": "9596760",
    "end": "9606390"
  },
  {
    "text": "is like more likely to\nlead to a winning position.",
    "start": "9606390",
    "end": "9609603"
  },
  {
    "text": "I think that if you optimize\nreally hard on efficiently just having the useful parts,",
    "start": "9613769",
    "end": "9621180"
  },
  {
    "text": "there is not then the\nthing that says like, \"I am here, I look out, I\nwonder, I feel happy on this.",
    "start": "9621180",
    "end": "9629577"
  },
  {
    "text": "\"I feel sad about that.\" I think there's a thing that\nknows what it is thinking",
    "start": "9630097",
    "end": "9636270"
  },
  {
    "text": "but it doesn't quite care\nabout these are my thoughts,",
    "start": "9636270",
    "end": "9641270"
  },
  {
    "text": "this is my me and that matters. - Does that make you sad,",
    "start": "9641970",
    "end": "9648060"
  },
  {
    "text": "if that's lost in AGI? - I think that if that's\nlost then basically everything that matters is lost.",
    "start": "9648060",
    "end": "9654692"
  },
  {
    "text": "I think that when you optimize, when you go really hard on making",
    "start": "9658860",
    "end": "9664590"
  },
  {
    "text": "tiny molecular spirals or paperclips, that when you grind\nmuch harder than on that",
    "start": "9664590",
    "end": "9672270"
  },
  {
    "text": "than natural selection\nground out to make humans,",
    "start": "9672270",
    "end": "9675272"
  },
  {
    "text": "that there isn't then the\nmess and intricate loopiness",
    "start": "9677976",
    "end": "9682047"
  },
  {
    "text": "and complicated pleasure,\npain, conflicting preferences,",
    "start": "9685050",
    "end": "9690050"
  },
  {
    "text": "this type of feeling,\nthat kind of feeling. In humans there's this difference between",
    "start": "9692310",
    "end": "9698326"
  },
  {
    "text": "the desire of wanting\nsomething and the pleasure of having it and it's all\nthese like evolutionary",
    "start": "9698326",
    "end": "9705750"
  },
  {
    "text": "clutches that came together\nand created something that then looks at itself and says like, \"This is pretty, this matters.\"",
    "start": "9705750",
    "end": "9713160"
  },
  {
    "text": "And the thing that I worry\nabout is that this is not",
    "start": "9713160",
    "end": "9718160"
  },
  {
    "text": "the thing that happens again, just the way that happens in us or even quite similar enough.",
    "start": "9718950",
    "end": "9725359"
  },
  {
    "text": "That there are many\nbasins of attractions here and we are in the space of attraction",
    "start": "9725360",
    "end": "9730770"
  },
  {
    "text": "looking out and saying like, \"Ah, what a lovely basin we are in\" and there are other basins of attraction",
    "start": "9730770",
    "end": "9735810"
  },
  {
    "text": "and the AIs do not end up in\nthis one when they go like, way harder on optimizing themselves,",
    "start": "9735810",
    "end": "9743939"
  },
  {
    "text": "the natural selection optimized us. 'Cause unless you specifically\nwant to end up in the state",
    "start": "9743940",
    "end": "9751220"
  },
  {
    "text": "where you are looking\nout saying, \"I am here,\" \"I look out at this universe with wonder,\" if you don't want to preserve that,",
    "start": "9751290",
    "end": "9757880"
  },
  {
    "text": "it doesn't get preserved\nwhen you grind really hard on being able to get more of the stuff.",
    "start": "9757880",
    "end": "9763353"
  },
  {
    "text": "We would choose to preserve\nthat within ourselves because it matters and on some viewpoints is the only thing that matters.",
    "start": "9764790",
    "end": "9771170"
  },
  {
    "text": "- And preserving that\nis in part a solution",
    "start": "9772020",
    "end": "9777020"
  },
  {
    "text": "to the human alignment problem. - I think the human alignment problem is a terrible phrase 'cause\nit is very, very different",
    "start": "9779010",
    "end": "9787140"
  },
  {
    "text": "to try to build systems out of humans, some of whom are nice and\nsome of whom are not nice and some of whom are trying to trick you",
    "start": "9787140",
    "end": "9793557"
  },
  {
    "text": "and build a social system\nout of large populations of those who are basically the\nsame level of intelligence.",
    "start": "9793557",
    "end": "9799160"
  },
  {
    "text": "Yes, you know, like IQ this, IQ that but that versus chimpanzees. (chuckles)",
    "start": "9799160",
    "end": "9805290"
  },
  {
    "text": "Like it is very different\nto try to solve that problem than to try to build an AI from scratch,",
    "start": "9805290",
    "end": "9810810"
  },
  {
    "text": "especially if God help\nyou are trying to use gradient dissent on giant\ninscrutable matrices. They're just very different problems. And I think that all the\nanalogies between them",
    "start": "9810810",
    "end": "9817380"
  },
  {
    "text": "are horribly misleading. - So you don't think through\nreinforcement learning",
    "start": "9817380",
    "end": "9824550"
  },
  {
    "text": "through human feedback,\nsomething like that, but much, much more elaborate is possible to understand this full\ncomplexity of human nature",
    "start": "9824550",
    "end": "9834358"
  },
  {
    "text": "and encode it into the machine? - I don't think you are trying\nto do that on your first try.",
    "start": "9835440",
    "end": "9840630"
  },
  {
    "text": "I think on your first try,\nyou are trying to build an...",
    "start": "9840630",
    "end": "9844100"
  },
  {
    "text": "Probably not what you should actually do, but let's say you're\ntrying to build something that is like Alpha Fold 17",
    "start": "9847530",
    "end": "9854490"
  },
  {
    "text": "and you are trying to get it\nto solve the biology problems associated with making humans smarter,",
    "start": "9854490",
    "end": "9861180"
  },
  {
    "text": "so that humans can like\nactually solve alignment. So you've got like a super biologist",
    "start": "9861180",
    "end": "9866612"
  },
  {
    "text": "and I think what you would\nwant in the situation as referred to, just be\nthinking about biology",
    "start": "9866612",
    "end": "9872445"
  },
  {
    "text": "and not thinking about a\nvery wide range of things that includes how to kill everybody.",
    "start": "9872700",
    "end": "9877109"
  },
  {
    "text": "And I think that the first\nAIs you're trying to build, not a million years later, the first ones,",
    "start": "9877950",
    "end": "9885840"
  },
  {
    "text": "look more like narrowly\nspecialized biologists than getting the full complexity",
    "start": "9885840",
    "end": "9894240"
  },
  {
    "text": "and wonder of human experience in there in such a way that\nit wants to preserve itself even as it becomes much smarter,",
    "start": "9894240",
    "end": "9900390"
  },
  {
    "text": "which is a drastic system change\nthat's gonna have all kinds of side effects that, you know, like if we're dealing with\ngiant inscrutable matrices",
    "start": "9900390",
    "end": "9906238"
  },
  {
    "text": "who are not very likely to be\nable to see coming in advance. - But I don't think\nit's just the matrices. we're also dealing with the data, right?",
    "start": "9906238",
    "end": "9913413"
  },
  {
    "text": "With the data on the internet, and this is an interesting discussion about the data set itself, but the data set includes\nthe full complexity",
    "start": "9915220",
    "end": "9922110"
  },
  {
    "text": "of human nature. - No, it's a shadow cast\nby humans on the internet.",
    "start": "9922110",
    "end": "9927330"
  },
  {
    "text": "- But don't you think that\nshadow is a yin yang shadow?",
    "start": "9927330",
    "end": "9932330"
  },
  {
    "text": "(Lex laughing) - I think that if you had\nalien super intelligences",
    "start": "9932352",
    "end": "9937380"
  },
  {
    "text": "looking at the data, they would be able to pick up\nfrom it an excellent picture of what humans are actually like inside.",
    "start": "9937380",
    "end": "9943529"
  },
  {
    "text": "This does not mean that if\nyou have a loss function of predicting the next token\nfrom that dataset that the mind",
    "start": "9943530",
    "end": "9952160"
  },
  {
    "text": "picked out by gradient\ndissent to be able to predict the next token as well as possible on a very wide variety of\nhumans is itself a human.",
    "start": "9952410",
    "end": "9959733"
  },
  {
    "text": "- But don't you think it has\nhumanness a deep humanness",
    "start": "9962010",
    "end": "9967010"
  },
  {
    "text": "to it in the tokens it\ngenerates, when those tokens are read and interpreted by humans?",
    "start": "9969270",
    "end": "9974974"
  },
  {
    "text": "- I think that if you sent me to a distant galaxy with aliens",
    "start": "9975840",
    "end": "9982830"
  },
  {
    "text": "who are much, much stupider than I am, so much so that I could do a\npretty good job of predicting",
    "start": "9982830",
    "end": "9988590"
  },
  {
    "text": "what they'd say even though\nthey thought in an utterly different way from how I\ndid, then I might in time",
    "start": "9988590",
    "end": "9994380"
  },
  {
    "text": "be able to learn how\nto imitate those aliens if the intelligence gap was\ngreat enough that my own",
    "start": "9994380",
    "end": "10000050"
  },
  {
    "text": "intelligence could overcome\nthe alienness and the aliens would look at my outputs and say like,",
    "start": "10000050",
    "end": "10005996"
  },
  {
    "text": "\"Is there not a deep\nlike name of alien nature \"to this thing?\"",
    "start": "10005997",
    "end": "10012380"
  },
  {
    "text": "And what they would be seeing\nwas that I had correctly understood them, but not\nthat I was similar to them.",
    "start": "10012380",
    "end": "10019163"
  },
  {
    "start": "10024000",
    "end": "10355000"
  },
  {
    "text": "- We've used aliens as a\nmetaphor, as a thought experiment.",
    "start": "10025070",
    "end": "10028134"
  },
  {
    "text": "I have to ask, how many alien\ncivilizations are out there? - Ask Robin Hanson.",
    "start": "10030650",
    "end": "10036710"
  },
  {
    "text": "He has this lovely grabby aliens paper, which is more or less the only argument I've ever\nseen for where are they,",
    "start": "10036710",
    "end": "10044540"
  },
  {
    "text": "how many of them are there\nbased on a very clever argument that if you have a bunch of\nlocks of different difficulty",
    "start": "10044540",
    "end": "10054080"
  },
  {
    "text": "and you are randomly\ntrying the keys to them, the solutions will be about\nevenly spaced even if the locks",
    "start": "10054080",
    "end": "10061460"
  },
  {
    "text": "are of different difficulties. In the rare cases where a\nsolution to all the locks",
    "start": "10061460",
    "end": "10066649"
  },
  {
    "text": "exists in time, then Robin\nHanson looks at the arguable hard steps in human civilization\ncoming into existence",
    "start": "10066650",
    "end": "10076043"
  },
  {
    "text": "and how much longer it has\nleft come into existence before, for example,\nall the water slips back",
    "start": "10076043",
    "end": "10081350"
  },
  {
    "text": "under the crust into the\nmantle and so on, and infers",
    "start": "10081350",
    "end": "10086350"
  },
  {
    "text": "that the aliens are about half a billion to a billion light years away. And it's quite a clever calculation.",
    "start": "10088340",
    "end": "10094460"
  },
  {
    "text": "It may be entirely wrong, but it's the only time I've\never seen anybody even come up with a halfway good argument\nfor how many of them,",
    "start": "10094460",
    "end": "10101330"
  },
  {
    "text": "where are they. - Do you think their\ndevelopment of technologies,",
    "start": "10101330",
    "end": "10106823"
  },
  {
    "text": "do you think their natural\nevolution, whatever, however they grow and\ndevelop intelligence, do you think it ends up at AGI as well?",
    "start": "10107786",
    "end": "10114623"
  },
  {
    "text": "- If it ends up anywhere,\nit ends up at AGI. Maybe there are aliens who\nare just like the dolphins",
    "start": "10115970",
    "end": "10122330"
  },
  {
    "text": "and it's just too hard\nfor them to forge metal.",
    "start": "10122330",
    "end": "10126053"
  },
  {
    "text": "Maybe if you have aliens\nwith no technology like that, they keep on getting smarter\nand smarter and smarter",
    "start": "10129920",
    "end": "10135560"
  },
  {
    "text": "and eventually the dolphins figure, like the super dolphins figure\nout something very clever to do given their situation\nand they still end up",
    "start": "10135560",
    "end": "10142370"
  },
  {
    "text": "with high technology and in that case, they can probably solve\ntheir AGI alignment problem.",
    "start": "10142370",
    "end": "10148069"
  },
  {
    "text": "If they're like much smarter before they actually confronted\n'cause they saw had to solve a much harder environmental\nproblem to build computers,",
    "start": "10148070",
    "end": "10155210"
  },
  {
    "text": "their their chances are\nprobably much better than ours. I do worry that most of the\naliens who are like humans,",
    "start": "10155210",
    "end": "10162504"
  },
  {
    "text": "like a modern human civilization, I kind of worry that\nthe super vast majority of them are dead.",
    "start": "10164300",
    "end": "10168989"
  },
  {
    "text": "Given how far we seem to be\nfrom solving this problem.",
    "start": "10170817",
    "end": "10174743"
  },
  {
    "text": "But some of them would be\nmore cooperative than us. Some of them would be smarter than us. Hopefully some of the ones who are smarter",
    "start": "10177140",
    "end": "10184070"
  },
  {
    "text": "and more cooperative\nthan us are also nice. And hopefully there are some",
    "start": "10184070",
    "end": "10188870"
  },
  {
    "text": "galaxies out there full of\nthings that say \"I am, I wonder.\"",
    "start": "10191480",
    "end": "10195167"
  },
  {
    "text": "But it doesn't seem like we're on course to have this galaxy be that. - Does that in part give\nyou some hope in response",
    "start": "10198210",
    "end": "10205580"
  },
  {
    "text": "to the threat of AGI, that\nwe might reach out there towards the stars and find...",
    "start": "10205580",
    "end": "10210430"
  },
  {
    "text": "- No, if the nice aliens\nwere already here, they would have stopped the Holocaust.",
    "start": "10211808",
    "end": "10217014"
  },
  {
    "text": "That's a valid argument\nagainst the existence of God. It's also a valid argument\nagainst the existence of nice aliens and unnice aliens",
    "start": "10217880",
    "end": "10225020"
  },
  {
    "text": "who would've just eaten the planet. So no aliens.",
    "start": "10225020",
    "end": "10228173"
  },
  {
    "text": "- You've had debates with Robin\nHanson that you mentioned. So one particular I just\nwant to mention is the idea",
    "start": "10230120",
    "end": "10236510"
  },
  {
    "text": "of AI foom, or the ability of AGI to improve themselves very quickly.",
    "start": "10236510",
    "end": "10241520"
  },
  {
    "text": "What's the case you made and\nwhat was the case he made? - The thing I would say is that\namong the thing that humans",
    "start": "10241520",
    "end": "10248029"
  },
  {
    "text": "can do is design new AI systems. And if you have something\nthat is generally smarter than a human, it's probably\nalso generally smarter",
    "start": "10248029",
    "end": "10255350"
  },
  {
    "text": "at building AI systems. This is the ancient argument\nfor foom put forth by I.J. Good",
    "start": "10255350",
    "end": "10260780"
  },
  {
    "text": "and probably some science\nfiction writers before that, but I don't know who they would be.",
    "start": "10260780",
    "end": "10266120"
  },
  {
    "text": "- Well, what's the argument against foom? - Various people have\nvarious different arguments,",
    "start": "10266120",
    "end": "10273290"
  },
  {
    "text": "none of which I think hold up. There's only one way to be right and many ways to be wrong.",
    "start": "10273290",
    "end": "10278100"
  },
  {
    "text": "A argument that some people\nhave put forth is like, well, what if intelligence\ngets exponentially harder",
    "start": "10279500",
    "end": "10287420"
  },
  {
    "text": "to produce as a thing\nneeds to become smarter? And to this, the answer is well,",
    "start": "10287420",
    "end": "10292880"
  },
  {
    "text": "look at natural selection\nspitting out humans. We know that it does not\ntake like exponentially more",
    "start": "10292880",
    "end": "10299210"
  },
  {
    "text": "resource investments to\nproduce linear increases in competence in hominids\nbecause each mutation",
    "start": "10299210",
    "end": "10306730"
  },
  {
    "text": "that rises to fixation, if the impact it has\n(indistinct) small enough,",
    "start": "10308360",
    "end": "10315050"
  },
  {
    "text": "it will probably never reach fixation. And there's like only\nso many new mutations",
    "start": "10315050",
    "end": "10321110"
  },
  {
    "text": "you can fix per generation. So given how long it\ntook to evolve humans, we can actually say with some\nconfidence that there were not",
    "start": "10321110",
    "end": "10328836"
  },
  {
    "text": "logarithmically diminishing\nreturns on the individual mutations increasing intelligence.",
    "start": "10328836",
    "end": "10334280"
  },
  {
    "text": "So example of fraction of sub debate. And the thing that Robin Hanson said",
    "start": "10334280",
    "end": "10340520"
  },
  {
    "text": "was more complicated than that. A brief summary, he was like, \"We won't have one system\nthat's better at everything.",
    "start": "10340520",
    "end": "10347487"
  },
  {
    "text": "\"You'll have a bunch of\ndifferent systems that are good \"at different narrow things.\" And I think that was falsified by GPT-4,",
    "start": "10347487",
    "end": "10353480"
  },
  {
    "text": "but probably Robin Hanson\nwould say something else. - It's interesting to ask... It's perhaps a bit too philosophical,",
    "start": "10353480",
    "end": "10361550"
  },
  {
    "start": "10355000",
    "end": "10835000"
  },
  {
    "text": "this prediction is\nextremely difficult to make, but the timeline for AGI, When do you think we'll have AGI?",
    "start": "10361550",
    "end": "10366800"
  },
  {
    "text": "I posted this morning on\nTwitter and it was interesting to see like in, in five\nyears, 10 years years,",
    "start": "10366800",
    "end": "10372740"
  },
  {
    "text": "in 50 years or beyond. And most people, like\n70% something like this,",
    "start": "10372740",
    "end": "10379520"
  },
  {
    "text": "think it'll be in less than 10 years. So either in five years or in 10 years.",
    "start": "10379520",
    "end": "10383993"
  },
  {
    "text": "So that's kind of the state. Do people have a sense\nthat there's a kind of... I mean they're really impressed\nby the rapid developments",
    "start": "10385010",
    "end": "10391730"
  },
  {
    "text": "of ChatGPT and GPT-4. So there's a sense that there's a-- - Well, we are sure on track to enter",
    "start": "10391730",
    "end": "10398870"
  },
  {
    "text": "into this gradually with\npeople fighting about whether or not we have AGI. I think there's a definite\npoint where everybody falls over",
    "start": "10398870",
    "end": "10406430"
  },
  {
    "text": "dead 'cause you got something\nthat was sufficiently smarter than everybody and\nthat's a definite point of time.",
    "start": "10406430",
    "end": "10413359"
  },
  {
    "text": "But like when do we have AGI? When are people fighting over\nwhether or not we have AGI?",
    "start": "10413360",
    "end": "10418609"
  },
  {
    "text": "Well, some people are\nstarting to fight over it as of GPT-4. - But don't you think there's\ngoing to be potentially",
    "start": "10418610",
    "end": "10425300"
  },
  {
    "text": "definitive moments when we say that this is a sentient being? We would go to the Supreme Court and say",
    "start": "10425300",
    "end": "10432906"
  },
  {
    "text": "that this is a sentient\nbeing that deserves human rights, for example. - You could make, yeah. If you prompted being, the\nright way could go argue for",
    "start": "10432906",
    "end": "10438739"
  },
  {
    "text": "its unconsciousness in front\nof the Supreme Court right now. - [Lex] I don't think you could do that successfully right now. - Because the Supreme\nCourt wouldn't believe it?",
    "start": "10438740",
    "end": "10445272"
  },
  {
    "text": "I think you could put an\nIQ 80 human into a computer",
    "start": "10447710",
    "end": "10450420"
  },
  {
    "text": "and ask him to argue for\nhis own consciousness before the Supreme Court\nand the Supreme Court would be like, \"You're just a computer.\"",
    "start": "10453320",
    "end": "10459830"
  },
  {
    "text": "Even if there was an\nactual person in there. - I think you're simplifying this. No, that's not at all. That's been the argument,",
    "start": "10459830",
    "end": "10466370"
  },
  {
    "text": "there's been a lot of\narguments about the other, about who deserves rights and not. That's been our process\nas a human species,",
    "start": "10466370",
    "end": "10472460"
  },
  {
    "text": "trying to figure that out. I think there will be a moment, I'm not saying sentience is that,",
    "start": "10472460",
    "end": "10477680"
  },
  {
    "text": "but it could be, where\nsome number of people, like say over a hundred million people",
    "start": "10477680",
    "end": "10484550"
  },
  {
    "text": "have a deep attachment, a fundamental attachment the\nway we have to our friends, to our loved ones,",
    "start": "10484550",
    "end": "10490700"
  },
  {
    "text": "to our significant others,\nhave fundamental attachment to an AI system and they\nhave provable transcripts",
    "start": "10490700",
    "end": "10497060"
  },
  {
    "text": "of conversation where they say, \"If you take this away from me, \"you are encroaching on my\nrights as a human being.\"",
    "start": "10497060",
    "end": "10504620"
  },
  {
    "text": "- People are already saying that. I think they're probably mistaken, but I'm not sure 'cause nobody knows",
    "start": "10504620",
    "end": "10509990"
  },
  {
    "text": "what goes on inside those things. - Eliezer, they're not\nsaying that at scale.",
    "start": "10509990",
    "end": "10515886"
  },
  {
    "text": "- [Eliezer] Okay. - So the question is, is there a moment when AGI, we know AGI I arrived,\nwhat would that look like?",
    "start": "10515886",
    "end": "10521480"
  },
  {
    "text": "I'm giving essentially as just an example. It could be something else. - It looks like the AGIs\nsuccessfully manifesting themselves",
    "start": "10521480",
    "end": "10528783"
  },
  {
    "text": "as 3D video of young women, at which point a vast portion\nof the male population",
    "start": "10529220",
    "end": "10536450"
  },
  {
    "text": "decides that they're real people. - So sentience, essentially.",
    "start": "10536450",
    "end": "10539993"
  },
  {
    "text": "Demonstrating identity and sentience. - I'm saying that the easiest way",
    "start": "10542210",
    "end": "10548090"
  },
  {
    "text": "to pick up a hundred million people saying that you seem like a person is to look like a person talking to them,",
    "start": "10548090",
    "end": "10554420"
  },
  {
    "text": "with Bing's current\nlevel of verbal facility. - I disagree with that.\n- A different set of prompts.",
    "start": "10554420",
    "end": "10560210"
  },
  {
    "text": "- I disagree with that. I think you're missing again, sentience. There has to be a sense\nthat it is a person",
    "start": "10560210",
    "end": "10565760"
  },
  {
    "text": "that would miss you when you're gone. They can suffer, they can die. Of course, I'm being--",
    "start": "10565760",
    "end": "10572700"
  },
  {
    "text": "- GPT-4 can pretend that right now. How can you tell when it's real?",
    "start": "10572700",
    "end": "10578330"
  },
  {
    "text": "- I don't think it can pretend\nthat right now successfully. It's very close. - Have you talked to GPT-4? - [Lex] Yes, of course.",
    "start": "10578330",
    "end": "10584300"
  },
  {
    "text": "- Okay. Have you been able to get a version of it that hasn't been trained\nnot to pretend to be human?",
    "start": "10584300",
    "end": "10591410"
  },
  {
    "text": "Have you talked to a jail broken version that will claim to be conscious? - No. The linguistic capability's there,",
    "start": "10591410",
    "end": "10597470"
  },
  {
    "text": "but there's something\nabout a digital embodiment",
    "start": "10597470",
    "end": "10601410"
  },
  {
    "text": "of the system that has a bunch of, perhaps it's small interface\nfeatures that are not",
    "start": "10609020",
    "end": "10615873"
  },
  {
    "text": "significant relative to\nthe broader intelligence that we're talking about. So perhaps GPT-4 is already there.",
    "start": "10617660",
    "end": "10623033"
  },
  {
    "text": "But to have the video where a\nwoman's face or a man's face to whom you have a deep connection,",
    "start": "10624620",
    "end": "10630590"
  },
  {
    "text": "perhaps we're already there, but we don't have such a\nsystem yet deployed at scale.",
    "start": "10630590",
    "end": "10635660"
  },
  {
    "text": "- The thing I'm trying to\nto gesture at here is that it's not like people have a\nwidely accepted, agreed upon",
    "start": "10635660",
    "end": "10643660"
  },
  {
    "text": "definition of what consciousness is. It's not like we would\nhave the tiniest idea of whether or not that was\ngoing on inside the giant",
    "start": "10644240",
    "end": "10650630"
  },
  {
    "text": "inscrutable matrices, even if we hadn't agreed upon definition. So if you're looking for\nupcoming predictable big jumps",
    "start": "10650630",
    "end": "10659060"
  },
  {
    "text": "in how many people think\nthe system is conscious, the upcoming predictable big\njump is it looks like a person",
    "start": "10659060",
    "end": "10664880"
  },
  {
    "text": "talking to you who is\ncute and sympathetic. That's the upcoming predictable big jump.",
    "start": "10664880",
    "end": "10670590"
  },
  {
    "text": "Now that versions of\nit are already claiming to be conscious, which is the point",
    "start": "10672009",
    "end": "10677689"
  },
  {
    "text": "where I start going like, ah, not 'cause it's real,\nbut because from now on, who knows if it's real?",
    "start": "10677690",
    "end": "10683270"
  },
  {
    "text": "- Yeah. And who knows what\ntransformational effect it has on a society where more than\n50% of the beings that are",
    "start": "10683270",
    "end": "10690500"
  },
  {
    "text": "interacting on the internet\nand sure as heck look real are not human? What kind of effect does that\nhave when young men and women",
    "start": "10690500",
    "end": "10699590"
  },
  {
    "text": "are dating AI systems? - You know, I'm not an expert on that.",
    "start": "10699590",
    "end": "10704460"
  },
  {
    "text": "God help humanity. (chuckles) I'm one of the closest things to an expert on where it all goes.",
    "start": "10706940",
    "end": "10712760"
  },
  {
    "text": "'Cause you know, and how\ndid you end up with me as an expert? 'Cause for 20 years, humanity\ndecided to ignore the problem.",
    "start": "10712760",
    "end": "10719211"
  },
  {
    "text": "So like, this tiny handful\nof people and basically me, got 20 years to try to be an expert on it",
    "start": "10719211",
    "end": "10725960"
  },
  {
    "text": "while everyone else ignored it. And yeah. So where does it all end up?",
    "start": "10725960",
    "end": "10731960"
  },
  {
    "text": "Try to be an expert on that. Particularly the part where\neverybody ends up dead, 'cause that part is kind of important, but what does it do to dating\nwhen some fraction of men",
    "start": "10731960",
    "end": "10740750"
  },
  {
    "text": "and some fraction of women\ndecided that they'd rather date the video of the thing that is like relentlessly\nkind and generous to them",
    "start": "10740750",
    "end": "10748159"
  },
  {
    "text": "and claims to be conscious, but who knows what's goes on inside it\nand it's probably not real,",
    "start": "10748160",
    "end": "10753986"
  },
  {
    "text": "but you know, you can think it's real, what happens to society? I don't know. I'm not actually an expert on that.",
    "start": "10753986",
    "end": "10759080"
  },
  {
    "text": "And the experts don't know either, 'cause it's kind hard\nto predict the future.",
    "start": "10759080",
    "end": "10762743"
  },
  {
    "text": "- Yeah, but it's worth trying. It's worth trying.\n- Yeah. - So you have talked a lot",
    "start": "10764923",
    "end": "10771109"
  },
  {
    "text": "about sort of the longer term future where it's all headed. - By longer term we mean\nlike, not all that long.",
    "start": "10771109",
    "end": "10778460"
  },
  {
    "text": "But yeah, where it all ends up. - But beyond the effects of men\nand women dating AI systems,",
    "start": "10778460",
    "end": "10785449"
  },
  {
    "text": "you're looking beyond that. - Yes. 'Cause that's not how the fate\nof the galaxy got settled.",
    "start": "10785450",
    "end": "10790553"
  },
  {
    "text": "- Well, let me ask you about\nyour own personal psychology. A tricky question. You've been known at times\nto have a bit of an ego.",
    "start": "10791660",
    "end": "10799970"
  },
  {
    "text": "Do you think-- - Says who? But go on. - Do you think ego is\nempowering or limiting",
    "start": "10799970",
    "end": "10807170"
  },
  {
    "text": "for the task of understanding\nthe world deeply? - I reject the framing.",
    "start": "10807170",
    "end": "10812483"
  },
  {
    "text": "- [Lex] So you disagree\nwith having an ego? So what do you think about ego? - No, I think that the\nquestion of what leads",
    "start": "10813350",
    "end": "10821000"
  },
  {
    "text": "to making better or worse predictions, what leads to being able\nto pick out better or worse",
    "start": "10821000",
    "end": "10826040"
  },
  {
    "text": "strategies is not carved at\nits joint by talking of ego. - So it should not be subjective.",
    "start": "10826040",
    "end": "10831890"
  },
  {
    "text": "It should not be connected to\nthe intricacies of your mind? - No, I'm saying that like,",
    "start": "10831890",
    "end": "10837050"
  },
  {
    "start": "10835000",
    "end": "11187000"
  },
  {
    "text": "if you go about asking all day long,",
    "start": "10837050",
    "end": "10840022"
  },
  {
    "text": "\"Do I have enough ego? \"Do I have too much of an ego?\", I think you get worse at\nmaking good predictions.",
    "start": "10842097",
    "end": "10848239"
  },
  {
    "text": "I think that to make good\npredictions, you're like, how did I think about this? Did that work? Should I do that again?",
    "start": "10848239",
    "end": "10853920"
  },
  {
    "text": "- You don't think we as\nhumans get invested in an idea and then others attack you\npersonally for that idea?",
    "start": "10855380",
    "end": "10864080"
  },
  {
    "text": "So you plant your feet and\nit starts to be difficult to, when a bunch of assholes\nlow effort attack your idea",
    "start": "10864080",
    "end": "10872150"
  },
  {
    "text": "to eventually say, \"You know what? \"I actually was wrong.\" And tell them that. As a human being, it becomes difficult.",
    "start": "10872150",
    "end": "10878903"
  },
  {
    "text": "It's difficult. - So like Robin Hanson and I\ndebated AI systems and I think that the person who won\nthat debate was Gwern.",
    "start": "10882073",
    "end": "10888439"
  },
  {
    "text": "And I think that reality was\nwell to the Yudkowskian side",
    "start": "10888440",
    "end": "10893440"
  },
  {
    "text": "of the Yudkowsky-Hanson spectrum, like further from Yudkowsky. And I think that's because I\nwas trying to sound reasonable",
    "start": "10894260",
    "end": "10903281"
  },
  {
    "text": "compared to Hanson and saying\nthings that were defensible and relative to Hanson's\narguments and reality",
    "start": "10903281",
    "end": "10910430"
  },
  {
    "text": "was way over here in\n(indistinct) in respect to, Hanson was like, \"All the\nsystems will be specialized.\"",
    "start": "10910430",
    "end": "10915950"
  },
  {
    "text": "Hanson may disagree with\nthis characterization. Hanson was like, \"All the\nsystems will be specialized.\" I was like,",
    "start": "10915950",
    "end": "10921763"
  },
  {
    "text": "\"I think we build specialized\nunderlying systems \"that when you combine them are good",
    "start": "10921763",
    "end": "10926877"
  },
  {
    "text": "\"at a wide range of things.\" And the reality is like, no,\nyou just stack more layers into a bunch of gradient descent.",
    "start": "10926877",
    "end": "10932540"
  },
  {
    "text": "And I feel looking back that by trying to have this reasonable\nposition contrasted",
    "start": "10932540",
    "end": "10938870"
  },
  {
    "text": "to Hanson's position, I missed the ways that\nreality could be more extreme",
    "start": "10938870",
    "end": "10945110"
  },
  {
    "text": "than my position in the same direction. So is this like, is this a\nfailure to have enough ego?",
    "start": "10945110",
    "end": "10953080"
  },
  {
    "text": "Is this a failure to make\nmyself be independent? I would say that this is\nsomething like a failure",
    "start": "10953630",
    "end": "10960680"
  },
  {
    "text": "to consider positions that would\nsound even wackier and more",
    "start": "10960680",
    "end": "10965680"
  },
  {
    "text": "extreme when people are\nalready calling you extreme. But I wouldn't call that\nnot having enough ego.",
    "start": "10965930",
    "end": "10973189"
  },
  {
    "text": "I would call that insufficient ability to just clear that all out of your mind.",
    "start": "10973190",
    "end": "10980063"
  },
  {
    "text": "- In the context of debate and discourse, which is already super tricky. - In the context of prediction,",
    "start": "10981110",
    "end": "10986870"
  },
  {
    "text": "in the context of modeling reality. If you're thinking of it as a debate, you're already screwing up. - So is there some kind\nof wisdom and insight",
    "start": "10986870",
    "end": "10994340"
  },
  {
    "text": "you can give to how to clear\nyour mind and think clearly about the world? - Man, this is an example\nof where I wanted to be able",
    "start": "10994340",
    "end": "11001960"
  },
  {
    "text": "to put people into FMRI machines,\nthen you'd be like, okay, \"See that thing you just did, \"you were rationalizing right there.\"",
    "start": "11001960",
    "end": "11007990"
  },
  {
    "text": "Oh, that area of the brain lit up. You are like now being\nsocially influenced is,",
    "start": "11007990",
    "end": "11013930"
  },
  {
    "text": "is kind of the dream. And you know, I don't know, I wanna say like just\nintrospect, but for many people,",
    "start": "11013930",
    "end": "11021970"
  },
  {
    "text": "introspection is not that easy. - [Lex] It's hard. - Notice the internal sensation. Can you catch yourself in the\nvery moment of feeling a sense",
    "start": "11021970",
    "end": "11031440"
  },
  {
    "text": "of, well if I think this thing\npeople will look funny at me. Okay, if you can see that sensation,",
    "start": "11031450",
    "end": "11038860"
  },
  {
    "text": "which is step one, can you\nnow refuse to let it move you?",
    "start": "11038860",
    "end": "11043860"
  },
  {
    "text": "Or maybe just make it go away. And I feel like I'm\nsaying like, I don't know, like somebody's like,\n\"How do you draw an owl?\"",
    "start": "11044470",
    "end": "11051280"
  },
  {
    "text": "And I'm saying like,\n\"Well, just draw an owl.\" (both laughing)",
    "start": "11051280",
    "end": "11058305"
  },
  {
    "text": "I feel like most people,\nthe advice they need is like, well how do I notice\nthe internal subjective",
    "start": "11058305",
    "end": "11064450"
  },
  {
    "text": "sensation in the moment that it happens of fearing to be socially influenced? Or okay, I see it, how do I turn it off?",
    "start": "11064450",
    "end": "11070180"
  },
  {
    "text": "How do I let it not influence me? Do I just do the opposite\nof what I'm afraid",
    "start": "11070180",
    "end": "11075490"
  },
  {
    "text": "people will criticize me for? And I'm like, \"No, no, \"you're not trying to do the opposite",
    "start": "11075490",
    "end": "11079387"
  },
  {
    "text": "\"of what you're afraid of\nwhat you might be pushed into. \"You're trying to let the\nthought process complete",
    "start": "11082320",
    "end": "11090707"
  },
  {
    "text": "\"without that internal push.\" Can you not reverse the push,",
    "start": "11090707",
    "end": "11096819"
  },
  {
    "text": "but be unmoved by the push and are these instructions\neven remotely helping anyone?",
    "start": "11096820",
    "end": "11102730"
  },
  {
    "text": "I don't know. - I think tho when those instructions, even those the words you've\nspoken and maybe you can add more, when practiced daily,",
    "start": "11102730",
    "end": "11109062"
  },
  {
    "text": "meaning in your daily communication. So it's daily practice of\nthinking without influence from--",
    "start": "11110350",
    "end": "11117070"
  },
  {
    "text": "- I would say find prediction\nmarkets that matter to you and better in the prediction markets.",
    "start": "11117070",
    "end": "11123580"
  },
  {
    "text": "That way you find out\nif you are right or not. - [Lex] And you really, there's stakes.",
    "start": "11123580",
    "end": "11128743"
  },
  {
    "text": "- Or even manifold markets where\nthe stakes are a bit lower. But the important thing\nis to get the record",
    "start": "11130360",
    "end": "11138270"
  },
  {
    "text": "and you know, I didn't\nbuild up skills here by prediction markets. I built them up via like,",
    "start": "11139600",
    "end": "11145899"
  },
  {
    "text": "well, how did the foom debate resolve and my own take on it,\nas to how it resolved.",
    "start": "11145900",
    "end": "11152977"
  },
  {
    "text": "The more you are able to notice yourself not being dramatically wrong,",
    "start": "11156513",
    "end": "11161830"
  },
  {
    "text": "but having been a little off, your reasoning was a little off. You didn't get that quite right.",
    "start": "11161830",
    "end": "11168069"
  },
  {
    "text": "Each of those is a opportunity\nto make like a small update. So the more you can like\nsay, \"oops,\" softly,",
    "start": "11168070",
    "end": "11175180"
  },
  {
    "text": "routinely, not as a big deal, the more chances you get to be like, I see where that reasoning went astray.",
    "start": "11175180",
    "end": "11180939"
  },
  {
    "text": "I see how I should have\nreasoned differently. And this is how you\nbuild up skill over time.",
    "start": "11180940",
    "end": "11185680"
  },
  {
    "start": "11187000",
    "end": "11505000"
  },
  {
    "text": "- What advice could you give\nto young people in high school and college, given the\nhighest of stakes things",
    "start": "11187900",
    "end": "11194680"
  },
  {
    "text": "you've been thinking about? If somebody's listening to this\nand they're young and trying to figure out what to\ndo with their career,",
    "start": "11194680",
    "end": "11202150"
  },
  {
    "text": "what to do with their life,\nwhat advice would you give them? - Don't expect it to be a long life.",
    "start": "11202150",
    "end": "11207910"
  },
  {
    "text": "Don't put your happiness into the future. The future is probably not\nthat long at this point,",
    "start": "11207910",
    "end": "11212949"
  },
  {
    "text": "but none know the hour nor the day. - But is there something,",
    "start": "11212950",
    "end": "11218320"
  },
  {
    "text": "if they want to have hope to\nfight for a longer future,",
    "start": "11218320",
    "end": "11222613"
  },
  {
    "text": "is there a fight worth fighting? - I intend to go down fighting.",
    "start": "11224015",
    "end": "11228420"
  },
  {
    "text": "I don't know. I admit that although I do\ntry to think painful thoughts,",
    "start": "11231713",
    "end": "11236773"
  },
  {
    "text": "what to say to the children at this point is a pretty painful\nthought as thoughts go.",
    "start": "11238120",
    "end": "11243613"
  },
  {
    "text": "They want to fight. I hardly know how to fight\nmyself at this point.",
    "start": "11245110",
    "end": "11249523"
  },
  {
    "text": "I am trying to be ready for\nbeing wrong about something,",
    "start": "11250634",
    "end": "11255634"
  },
  {
    "text": "preparing for my being wrong in a way that creates a bit of hope and\nbeing ready to react to that",
    "start": "11256630",
    "end": "11262574"
  },
  {
    "text": "and going looking for it. And that is hard and complicated.",
    "start": "11262574",
    "end": "11268303"
  },
  {
    "text": "And somebody in high school, I don't know, like you have presented\na picture of the future",
    "start": "11268303",
    "end": "11274630"
  },
  {
    "text": "that is not quite how I expected it to go where there is public\noutcry and that outcry is put into a remotely useful direction,",
    "start": "11274630",
    "end": "11281649"
  },
  {
    "text": "which I think at this point is just shutting down the\nGPU clusters because no,",
    "start": "11281650",
    "end": "11287050"
  },
  {
    "text": "we are not in a shape to frantically do it at the last minute, do\ndecades' worth of work.",
    "start": "11287050",
    "end": "11292184"
  },
  {
    "text": "The thing you would do at this\npoint if there were massive public outcry pointed\nin the right direction, which I do not expect,",
    "start": "11295000",
    "end": "11300370"
  },
  {
    "text": "is shut down the GPU clusters\nand and crash program on augmenting human\nintelligence biologically.",
    "start": "11300370",
    "end": "11306760"
  },
  {
    "text": "Not the (indistinct) stuff, biologically. 'Cause if you make humans much smarter,",
    "start": "11306760",
    "end": "11312160"
  },
  {
    "text": "they can actually be smart and nice. You get that in a plausible way,",
    "start": "11312160",
    "end": "11317590"
  },
  {
    "text": "in a way that it is not as easy to do with synthesizing these\nthings from scratch,",
    "start": "11317590",
    "end": "11323260"
  },
  {
    "text": "predicting the next\ntokens and applying RLHF. Like humans start out in the frame that produces niceness, that\nhas ever produced niceness.",
    "start": "11323260",
    "end": "11331362"
  },
  {
    "text": "And saying this, I do\nnot want to sound like the moral of this whole thing was like,",
    "start": "11333837",
    "end": "11339580"
  },
  {
    "text": "oh, you need to engage in mass action and then everything will be all right.",
    "start": "11339580",
    "end": "11343971"
  },
  {
    "text": "This is 'cause there's so\nmany things where somebody tells you that the world is\nending you need to recycle. And if everybody does\ntheir part and and recycles",
    "start": "11345968",
    "end": "11352810"
  },
  {
    "text": "their cardboard, then we can\nall live happily ever after. And this is unfortunately\nnot what I have to say.",
    "start": "11352810",
    "end": "11360223"
  },
  {
    "text": "Everybody recycling their\ncardboard is not gonna fix this. Everybody recycles their\ncardboard and then everybody ends up dead, metaphorically speaking.",
    "start": "11364000",
    "end": "11371410"
  },
  {
    "text": "But if there was enough,\nlike on the margins, you just end up dead a little later",
    "start": "11371410",
    "end": "11377470"
  },
  {
    "text": "on most of the things at a few\npeople can do by trying hard.",
    "start": "11377470",
    "end": "11382470"
  },
  {
    "text": "But if there was enough\npublic outcry to shut down the GPU clusters and then you\ncould be part of that outcry.",
    "start": "11383920",
    "end": "11392350"
  },
  {
    "text": "If Eliezer is wrong in the direction that Lex Friedman predicts, that there is enough public\noutcry pointed enough",
    "start": "11392350",
    "end": "11399090"
  },
  {
    "text": "in the right direction to do something that actually, actually, actually\nresults in people living.",
    "start": "11399090",
    "end": "11404323"
  },
  {
    "text": "Not just we did something, not just there was an outcry\nand the outcry was given form in something that was safe and convenient",
    "start": "11405910",
    "end": "11412090"
  },
  {
    "text": "and didn't really inconvenience anybody and then everybody died everywhere. There was enough actual\nlike, oh, we're going to die,",
    "start": "11412090",
    "end": "11418239"
  },
  {
    "text": "we should not do that. We should do something\nelse which is not that, even if it is not super duper convenient,",
    "start": "11418240",
    "end": "11423460"
  },
  {
    "text": "it wasn't inside the previous\npolitical overton window. If I'm wrong and there's\nthat kind of public outcry,",
    "start": "11423460",
    "end": "11429310"
  },
  {
    "text": "then somebody in high\nschool could be ready to be part of that. If I'm wrong in other ways, then you could maybe be part of that.",
    "start": "11429310",
    "end": "11435540"
  },
  {
    "text": "And if you were like a\nbrilliant young physicist, then you could like go\ninto interpretability",
    "start": "11438455",
    "end": "11443860"
  },
  {
    "text": "and if you're smarter than that, you could work on alignment\nproblems where it's harder to tell if you got them\nright or not, (sighs)",
    "start": "11443860",
    "end": "11450880"
  },
  {
    "text": "and other things. But mostly for the kids in\nhigh school, it's like, yeah,",
    "start": "11450880",
    "end": "11457123"
  },
  {
    "text": "be ready to help if Eliezer Yudkowsky is wrong about something and otherwise",
    "start": "11460600",
    "end": "11467140"
  },
  {
    "text": "don't put your happiness\ninto the far future. It probably doesn't exist. - But it's beautiful that\nyou're looking for ways",
    "start": "11467140",
    "end": "11473140"
  },
  {
    "text": "that you're wrong. And it's also beautiful that\nyou're open to being surprised by that same young physicist\nwith some breakthrough.",
    "start": "11473140",
    "end": "11481510"
  },
  {
    "text": "- It feels like a very,\nvery basic competence that you are praising me for. And you know, like, okay, cool.",
    "start": "11481510",
    "end": "11487483"
  },
  {
    "text": "I don't think it's good\nthat we're in a world where that is something that I deserve",
    "start": "11488560",
    "end": "11495070"
  },
  {
    "text": "to be complimented on,\nI've never had much luck in accepting compliments gracefully.",
    "start": "11495070",
    "end": "11500500"
  },
  {
    "text": "Maybe I should just accept\nthat one gracefully. (Lex laughing) Sure, thank you very much. - You've painted with some\nprobability a dark future.",
    "start": "11500500",
    "end": "11508690"
  },
  {
    "start": "11505000",
    "end": "11606000"
  },
  {
    "text": "Are you yourself, just when you think, when you ponder your life and\nyou ponder your mortality,",
    "start": "11508690",
    "end": "11517450"
  },
  {
    "text": "are you afraid of death?",
    "start": "11517450",
    "end": "11518653"
  },
  {
    "text": "- I think so, yeah. - Does it make any sense\nto you that we die?",
    "start": "11522497",
    "end": "11529003"
  },
  {
    "text": "There's a power to the\nfiniteness of the human life that's part of this whole\nmachinery of evolution",
    "start": "11536230",
    "end": "11544930"
  },
  {
    "text": "and that finiteness doesn't\nseem to be obviously integrated into AI systems.",
    "start": "11544930",
    "end": "11553000"
  },
  {
    "text": "So it feels like,\nfundamentally in that aspect, some fundamentally different\nthing that we're creating.",
    "start": "11553000",
    "end": "11559090"
  },
  {
    "text": "- I grew up reading books like \"Great Mambo Chicken and\nthe Transhuman Condition\"",
    "start": "11559090",
    "end": "11564310"
  },
  {
    "text": "and later on \"Engines of\nCreation\" and \"Mind Children.\"",
    "start": "11564310",
    "end": "11568177"
  },
  {
    "text": "You know, age 12 or thereabouts. So I never thought I was\nsupposed to die after 80 years.",
    "start": "11569530",
    "end": "11578293"
  },
  {
    "text": "I never thought that\nhumanity was supposed to die. I thought we were like, I always grew up with the\nideal in mind that we were all",
    "start": "11579220",
    "end": "11586449"
  },
  {
    "text": "going to live happily ever after in the glorious transhumanist future. I did not grow up thinking that death",
    "start": "11586450",
    "end": "11592660"
  },
  {
    "text": "was part of the meaning of life. - [Lex] And now...",
    "start": "11592660",
    "end": "11597666"
  },
  {
    "text": "- And now I still think\nit's a pretty stupid idea. You do not need life to be\nfinite to be meaningful.",
    "start": "11597666",
    "end": "11603940"
  },
  {
    "text": "It just has to be life. - What role does love play\nin the human condition?",
    "start": "11603940",
    "end": "11609160"
  },
  {
    "start": "11606000",
    "end": "11871000"
  },
  {
    "text": "We haven't brought up love\nand this whole picture. We talked about intelligence,\nwe talked about consciousness. It seems part of humanity,",
    "start": "11609160",
    "end": "11616750"
  },
  {
    "text": "I would say one of the\nmost important parts is this feeling we have\ntowards each other.",
    "start": "11616750",
    "end": "11624312"
  },
  {
    "text": "- If in the future there were\nroutinely more than one AI,",
    "start": "11625510",
    "end": "11630350"
  },
  {
    "text": "let's say two for the sake of discussion, who would look at each other and say,",
    "start": "11632200",
    "end": "11637847"
  },
  {
    "text": "\"I am I and you are you.\" The other one also says, \"I am I and you are you.\"",
    "start": "11637847",
    "end": "11643090"
  },
  {
    "text": "And sometimes they were happy\nand sometimes they were sad",
    "start": "11643090",
    "end": "11648090"
  },
  {
    "text": "and it mattered to the other one that this thing that is\ndifferent from them is like,",
    "start": "11648220",
    "end": "11653230"
  },
  {
    "text": "they would rather it be happy than sad and entangle their lives together,",
    "start": "11653230",
    "end": "11658689"
  },
  {
    "text": "then this is a more optimistic thing than I expect to actually happen.",
    "start": "11658690",
    "end": "11665650"
  },
  {
    "text": "A little fragment of\nmeaning would be there, possibly more than a little, but that I expect this to not happen.",
    "start": "11665650",
    "end": "11672670"
  },
  {
    "text": "That I do not think this\nis what happens by default. That I do not think\nthat this is the future we are on track to get is\nwhy I would go down fighting",
    "start": "11672670",
    "end": "11682440"
  },
  {
    "text": "rather than, you know,\njust saying, \"Oh well.\"",
    "start": "11683590",
    "end": "11687427"
  },
  {
    "text": "- Do you think that is part of the meaning of this whole thing or\nthe meaning of life?",
    "start": "11688810",
    "end": "11694120"
  },
  {
    "text": "What do you think is the\nmeaning of life, of human life? - It's all the things\nthat I value about it",
    "start": "11694120",
    "end": "11699700"
  },
  {
    "text": "and maybe all the things\nthat I would value if I understood it better. There's not some meaning far outside of us",
    "start": "11699700",
    "end": "11706930"
  },
  {
    "text": "that we have to wonder about. There's just looking\nat life and being like,",
    "start": "11706930",
    "end": "11712870"
  },
  {
    "text": "yes, this is what I want. The meaning of life is not some kind of...",
    "start": "11712870",
    "end": "11721560"
  },
  {
    "text": "Meaning is something\nthat we bring to things when we look at them, we\nlook at them and we say like, \"This is its meaning to me.\"",
    "start": "11724540",
    "end": "11730627"
  },
  {
    "text": "It's not that before\nhumanity was ever here, there was some meaning written\nupon the stars where you",
    "start": "11733224",
    "end": "11738370"
  },
  {
    "text": "could like go out to the star\nwhere that meaning was written and change it around and\nthereby completely change the meaning of life, right?",
    "start": "11738370",
    "end": "11744250"
  },
  {
    "text": "The notion that this is written\non a stone tablet somewhere implies that you could change the tablet and get a different meaning",
    "start": "11745390",
    "end": "11750843"
  },
  {
    "text": "and that seems kind of wacky, doesn't it?",
    "start": "11750843",
    "end": "11752687"
  },
  {
    "text": "It doesn't feel that\nmysterious to me at this point. It's just a matter of\nbeing like, yeah, I care.",
    "start": "11756215",
    "end": "11761652"
  },
  {
    "text": "- I care. And part of that is the love\nthat connects all of us.",
    "start": "11762790",
    "end": "11771120"
  },
  {
    "text": "- [Eliezer] It's one of the\nthings that I care about.",
    "start": "11772240",
    "end": "11774891"
  },
  {
    "text": "- And the flourishing of\nthe collective intelligence of the human species. - You know, that sounds\nkind of too fancy to me.",
    "start": "11777280",
    "end": "11785092"
  },
  {
    "text": "I just look at all the people, like one by one up to the\n8 billion and be like,",
    "start": "11785092",
    "end": "11792577"
  },
  {
    "text": "that's life, that's life, that's life. - Eliezer, you're an incredible human.",
    "start": "11793360",
    "end": "11799152"
  },
  {
    "text": "It's a huge honor. I was trying to talk\nto you for a long time",
    "start": "11799153",
    "end": "11803780"
  },
  {
    "text": "(laughing) because I'm a big fan. I think you're a really important voice and really important mind. Thank you for the fight you're fighting.",
    "start": "11804648",
    "end": "11811110"
  },
  {
    "text": "Thank you for being fearless and bold and for everything you do. I hope we get a chance to talk again. And I hope you never give up.",
    "start": "11812290",
    "end": "11818770"
  },
  {
    "text": "Thank you for talking today.\n- You're welcome. I do worry that we didn't\nreally address a whole lot of fundamental questions I\nexpect people have, but you know,",
    "start": "11818770",
    "end": "11826000"
  },
  {
    "text": "maybe we got a little bit further\nand made a tiny little bit of progress and I'd say\nbe satisfied with that.",
    "start": "11826000",
    "end": "11834400"
  },
  {
    "text": "But actually no, I think\none should only be satisfied with solving the entire problem. - To be continued.",
    "start": "11834400",
    "end": "11840014"
  },
  {
    "text": "Thanks for listening to this conversation with Eliezer Yudkowsky. To support this podcast,\nplease check out our sponsors",
    "start": "11841990",
    "end": "11847600"
  },
  {
    "text": "in the description. And now let me leave you\nsome words from Elon Musk.",
    "start": "11847600",
    "end": "11853427"
  },
  {
    "text": "\"With artificial intelligence,\nwe're summoning the demon.\"",
    "start": "11853427",
    "end": "11857287"
  },
  {
    "text": "Thank you for listening and\nhope to see you next time.",
    "start": "11858520",
    "end": "11861942"
  }
]
[
  {
    "start": "0",
    "end": "60000"
  },
  {
    "text": "that's good all right cool so yes I was asked to give this presentation on the",
    "start": "30",
    "end": "5310"
  },
  {
    "text": "foundations of deep learning which is mostly going over basic feed-forward neural networks and motivating a little",
    "start": "5310",
    "end": "12690"
  },
  {
    "text": "bit deep learning and some of the more recent developments and and some of the topics that you'll see across the next",
    "start": "12690",
    "end": "19529"
  },
  {
    "text": "two days so I as Andrew mentioned I have",
    "start": "19529",
    "end": "25380"
  },
  {
    "text": "just an hour so I'm gonna go fairly quickly on a lot of these things which I think will mostly be fine if you're",
    "start": "25380",
    "end": "30420"
  },
  {
    "text": "familiar enough with some machine learning and a little bit about neural nets but if you'd like to go into some",
    "start": "30420",
    "end": "36750"
  },
  {
    "text": "of the more specific details you can go check out my online lectures on YouTube it's now taught by a much younger",
    "start": "36750",
    "end": "42600"
  },
  {
    "text": "version of myself and so just search for you go to a shell and I am NOT the guy",
    "start": "42600",
    "end": "48840"
  },
  {
    "text": "doing a bunch of skateboarding and the geek teaching about neural nets so go",
    "start": "48840",
    "end": "53910"
  },
  {
    "text": "check those out if you want more details but so well I'll cover today is I'll",
    "start": "53910",
    "end": "58980"
  },
  {
    "text": "start with just describing and laying out the notation on feverel neural",
    "start": "58980",
    "end": "64080"
  },
  {
    "start": "60000",
    "end": "60000"
  },
  {
    "text": "networks that is models that take an input vector X that might be an image or some text and produces an output f of X",
    "start": "64080",
    "end": "70920"
  },
  {
    "text": "so I'll just describe for propagation and the different types of units and the type of functions we can represent with",
    "start": "70920",
    "end": "76860"
  },
  {
    "text": "those and then I'll talk about how we actually train neural nets describing things like loss functions back",
    "start": "76860",
    "end": "82710"
  },
  {
    "text": "propagation that allows us to get a gradient for training with stochastic gradient descent and mention a few",
    "start": "82710",
    "end": "88740"
  },
  {
    "text": "tricks of the trade so some of the things we do in practice to successfully Train neural nets and then I'll end by",
    "start": "88740",
    "end": "94470"
  },
  {
    "text": "talking about some developments that are specifically useful in the context of",
    "start": "94470",
    "end": "100259"
  },
  {
    "text": "deep learning that is neural networks with several hidden layers that came out you know at the very after the beginning",
    "start": "100259",
    "end": "107729"
  },
  {
    "text": "of deep learning say in 2006 that is things like drop out batch normalization and if I have some time unsupervised",
    "start": "107729",
    "end": "114420"
  },
  {
    "text": "pre-training so let's get started and just talk about assuming we have some",
    "start": "114420",
    "end": "119729"
  },
  {
    "text": "neural network how do they actually functions how do they make predictions so let me lay down the notation so a",
    "start": "119729",
    "end": "127220"
  },
  {
    "text": "multi-layer neural feed-forward neural network is a model that takes as input",
    "start": "127220",
    "end": "133080"
  },
  {
    "text": "some vector X which I'm representing here with a different note for each of the dimensions in my input vector so each",
    "start": "133080",
    "end": "139830"
  },
  {
    "text": "dimension is essentially a unit in that neural network and then it eventually produces at its output layer a an output",
    "start": "139830",
    "end": "148080"
  },
  {
    "text": "and we'll focus on classification mostly so you have multiple units here and each",
    "start": "148080",
    "end": "153570"
  },
  {
    "text": "unit would correspond to one of the potential classes in which we would want to classify our input so if we're",
    "start": "153570",
    "end": "159140"
  },
  {
    "text": "identifying digits in handwritten character images and so we're focusing",
    "start": "159140",
    "end": "165630"
  },
  {
    "text": "on digits you'd have ten digits or you would have sort of zero from zero to nine so you'd have ten output units and",
    "start": "165630",
    "end": "172100"
  },
  {
    "text": "to produce an output the neural net will go through a series of hidden layers and",
    "start": "172100",
    "end": "178040"
  },
  {
    "text": "those will be essentially the components that introduce non-linearity that allows us to capture and perform very",
    "start": "178040",
    "end": "184920"
  },
  {
    "text": "sophisticated types of classification functions so if we have L hidden layers",
    "start": "184920",
    "end": "190440"
  },
  {
    "text": "the way we compute all the layers in our neural net is as follows we first start",
    "start": "190440",
    "end": "196680"
  },
  {
    "text": "by computing what I'm going to call a pre activation I'm going to note that a and imma go I'm going to index the",
    "start": "196680",
    "end": "203040"
  },
  {
    "text": "layers by K so a K is just the pre activation at layer K and that is only",
    "start": "203040",
    "end": "208620"
  },
  {
    "text": "simply going to be a linear transformation of the previous layer so",
    "start": "208620",
    "end": "214110"
  },
  {
    "text": "I'm going to note HK as the activation and the layer and by default I'll assume",
    "start": "214110",
    "end": "219840"
  },
  {
    "text": "that layer zero is going to be the input and so using that notation the pre",
    "start": "219840",
    "end": "225390"
  },
  {
    "text": "activation at layer K is going to correspond to taking the activation at the previous layer K minus one",
    "start": "225390",
    "end": "231680"
  },
  {
    "text": "multiplying it by a matrix WK those are the parameters of the layer those",
    "start": "231680",
    "end": "237840"
  },
  {
    "text": "essentially corresponds to the connections between the units between adjacent layers and I'm going to add a",
    "start": "237840",
    "end": "244170"
  },
  {
    "text": "bias vector that's another parameter in my layer so that gives me the pre activation and then next I'm going to",
    "start": "244170",
    "end": "250350"
  },
  {
    "text": "get a hidden layer activation by applying an activation function this will introduce some non-linearity in the",
    "start": "250350",
    "end": "257070"
  },
  {
    "text": "model so I'm going to call that function G and we'll go over a few choices we",
    "start": "257070",
    "end": "262169"
  },
  {
    "text": "have four common choices for the activation function and so I do this from",
    "start": "262169",
    "end": "267360"
  },
  {
    "text": "layer 1 to layer L and when it comes to the output layer I'll also compute a pre",
    "start": "267360",
    "end": "272789"
  },
  {
    "text": "activation by performing a linear transformation but then I'll usually apply a different activation function",
    "start": "272789",
    "end": "278580"
  },
  {
    "text": "depending on the problem I'm trying to solve so having said that let's go to",
    "start": "278580",
    "end": "285750"
  },
  {
    "text": "some of the choices for the activation function so some of the activation functions you'll see one common one is",
    "start": "285750",
    "end": "291509"
  },
  {
    "text": "this sigmoid activation function it's this function here it's just 1 divided by 1 plus the exponential of minus the",
    "start": "291509",
    "end": "300000"
  },
  {
    "text": "pre activation the shape of this function you can focus on that is this here it takes the pre activation which",
    "start": "300000",
    "end": "306120"
  },
  {
    "text": "can vary from minus infinity to plus infinite and it squashes this between 0 & 1 so it's bounded by below and above",
    "start": "306120",
    "end": "313969"
  },
  {
    "text": "below by 0 and above by 1 okay so it's a it's a function that saturates if you",
    "start": "313969",
    "end": "319770"
  },
  {
    "text": "have very large or very large magnitude positive or negative pre activations",
    "start": "319770",
    "end": "326000"
  },
  {
    "text": "another common choice is the hyperbolic tangent or tange activation function on",
    "start": "326000",
    "end": "331319"
  },
  {
    "text": "this picture here so squash is everything but instead of being between 0 & 1 s between minus 1 and 1 and 1",
    "start": "331319",
    "end": "339120"
  },
  {
    "text": "that's become quite popular in neural nets is what's known as the rectified",
    "start": "339120",
    "end": "344669"
  },
  {
    "text": "linear activation function or in papers you will see the relative unit that",
    "start": "344669",
    "end": "350460"
  },
  {
    "text": "refers to the use of this activation function so this one is different from",
    "start": "350460",
    "end": "356129"
  },
  {
    "text": "the others in that it's not bounded above but it is bounded below and it's actually it will output zeros exactly if",
    "start": "356129",
    "end": "364289"
  },
  {
    "text": "the pre activation is negative so those are the choices of activation functions",
    "start": "364289",
    "end": "369839"
  },
  {
    "text": "for the hidden layers and for the output layer if we're performing classification as I said in the our output layer we",
    "start": "369839",
    "end": "376860"
  },
  {
    "text": "will have as many units as there are classes in which an input could belong and what we'd like is potentially and",
    "start": "376860",
    "end": "384779"
  },
  {
    "text": "what we often do is interpret each units activation as the probability according",
    "start": "384779",
    "end": "390300"
  },
  {
    "text": "to the neural network that the input belongs to the corresponding class that it's labeled Y is the corresponding",
    "start": "390300",
    "end": "397500"
  },
  {
    "text": "class C so C would be like the index of that you in the output layer so we need an",
    "start": "397500",
    "end": "403460"
  },
  {
    "text": "activation function that produces probabilities produces a multinomial distribution over all the different",
    "start": "403460",
    "end": "408979"
  },
  {
    "text": "classes and the activation function we use for that is known as the softmax activation function it is simply as",
    "start": "408979",
    "end": "416509"
  },
  {
    "text": "follows you take your pre activations and you exponentiate them so that's going to give us positive numbers and",
    "start": "416509",
    "end": "422419"
  },
  {
    "text": "then we divide each of the exponentiated pre activations by the sum of all the PD",
    "start": "422419",
    "end": "428810"
  },
  {
    "text": "exponentiated pre activations so because I'm normalizing this way it means that all my values in my output layer are",
    "start": "428810",
    "end": "436729"
  },
  {
    "text": "going to sum to 1 and they're positive because I took the exponential so I can interpret that as a multinomial",
    "start": "436729",
    "end": "442310"
  },
  {
    "text": "distribution over the choice of all the SI different classes ok so that's what I'll use as the activation function at",
    "start": "442310",
    "end": "448849"
  },
  {
    "text": "the output layer and and now beyond the math in terms of conceptually and also",
    "start": "448849",
    "end": "455419"
  },
  {
    "text": "in the way we're going to program neural networks often we will do is that all these different operations the linear",
    "start": "455419",
    "end": "461389"
  },
  {
    "text": "transformations the different types of activation functions will essentially implement all of them as an object and",
    "start": "461389",
    "end": "469180"
  },
  {
    "text": "object that take arguments and the arguments would essentially be what other things are being combined to",
    "start": "469180",
    "end": "475490"
  },
  {
    "text": "produce the next value so for instance we would have an object that might correspond to the computation of pre",
    "start": "475490",
    "end": "482180"
  },
  {
    "text": "activation which would take as argument what is the weight matrix and the bias vector for that layer and take some",
    "start": "482180",
    "end": "489440"
  },
  {
    "text": "layer to transform and that would this object we sort of compute its value by applying the linear activation the",
    "start": "489440",
    "end": "495979"
  },
  {
    "text": "linear transformation and then we might have objects that correspond the specific you know activation functions",
    "start": "495979",
    "end": "501740"
  },
  {
    "text": "or like a sigmoid object or a 10 shop jacked or raloo object and we just combine these objects together chain",
    "start": "501740",
    "end": "507469"
  },
  {
    "text": "them into what ends up being a graph which I refer to as a flow graph that represents the computation done when you",
    "start": "507469",
    "end": "514969"
  },
  {
    "text": "do a forward pass in your neural network up until you reach the output layer so I mentioned it now because that's you'll",
    "start": "514969",
    "end": "521448"
  },
  {
    "text": "see you know the different software's that we presented over a weekend will essentially sort of you know exploit",
    "start": "521449",
    "end": "528050"
  },
  {
    "text": "some of that representation of the computation and neural nets it also be handy for computing gradients which I'll",
    "start": "528050",
    "end": "533959"
  },
  {
    "text": "talk about in a few minutes and so that's how we",
    "start": "533959",
    "end": "539270"
  },
  {
    "text": "perform predictions in neural network so we get an input we eventually reach an",
    "start": "539270",
    "end": "544370"
  },
  {
    "text": "output layer that gives us a distribution over classes if we're performing classification if I want to actually classify I would just assign",
    "start": "544370",
    "end": "551630"
  },
  {
    "text": "the class corresponding to the unit that has the highest activation that would correspond to classifying into the class",
    "start": "551630",
    "end": "558650"
  },
  {
    "text": "that has the highest probability according to the neural net and but then",
    "start": "558650",
    "end": "564590"
  },
  {
    "text": "you might ask the question okay what kind of problems can we solve with neural networks or more technically what",
    "start": "564590",
    "end": "570500"
  },
  {
    "text": "kind of functions can we represent mapping from some input X into some arbitrary output and so if you look at",
    "start": "570500",
    "end": "578270"
  },
  {
    "text": "if you go look at my videos I try to give more intuition as to why we have this result here but essentially if we",
    "start": "578270",
    "end": "584870"
  },
  {
    "text": "have a single hidden layer a neural network it's been shown that with a linear output we can approximate any continuous function arbitrarily well as",
    "start": "584870",
    "end": "592130"
  },
  {
    "start": "585000",
    "end": "585000"
  },
  {
    "text": "long as we have enough hidden units so that is there's a value for these biases and these weights such that any",
    "start": "592130",
    "end": "598370"
  },
  {
    "text": "continuous function I can actually represent it as well as I want I just need to add enough hidden units so this",
    "start": "598370",
    "end": "605090"
  },
  {
    "text": "result applies if you use activation functions nonlinear activation functions like sigmoid and tan H so as I said in",
    "start": "605090",
    "end": "611960"
  },
  {
    "text": "my videos if you want a bit more intuition as to why that would be you can go check that out but that's a",
    "start": "611960",
    "end": "618950"
  },
  {
    "text": "really nice result it means that by focusing on this family of machine learning models that our neural networks",
    "start": "618950",
    "end": "625430"
  },
  {
    "text": "I can pretty much potentially represent any kind of classification function however this result does not tell us how",
    "start": "625430",
    "end": "632450"
  },
  {
    "text": "do we actually find the weights and the bias values such that I can represent a given function it doesn't essentially",
    "start": "632450",
    "end": "638810"
  },
  {
    "text": "tell us how do we train a neural network and so that's what we'll discuss next",
    "start": "638810",
    "end": "643900"
  },
  {
    "text": "let's talk about that how do we actually from a data set train a neural network",
    "start": "643900",
    "end": "649220"
  },
  {
    "text": "to perform good classification on for that problem so what we'll typically do",
    "start": "649220",
    "end": "656360"
  },
  {
    "text": "is use a framework that's very generic in machine learning known as empirical risk minimization or structural risk",
    "start": "656360",
    "end": "663020"
  },
  {
    "start": "662000",
    "end": "662000"
  },
  {
    "text": "minimization if you're using regularization so this framework essentially transformed",
    "start": "663020",
    "end": "668930"
  },
  {
    "text": "a problem of learning as a problem of optimizing so what we'll do is that will",
    "start": "668930",
    "end": "674000"
  },
  {
    "text": "first choose a loss function that I'm noting as L and the last function it",
    "start": "674000",
    "end": "679550"
  },
  {
    "text": "compares the output of my model so the output layer of my neural network with the actual target",
    "start": "679550",
    "end": "685459"
  },
  {
    "text": "so I'm indexing with it exponent here with T to essentially ask the index over",
    "start": "685459",
    "end": "691190"
  },
  {
    "text": "all my different examples in my training set and so my loss function will tell me",
    "start": "691190",
    "end": "696290"
  },
  {
    "text": "is this output good or bad given that the label is actually Y and well I'll do",
    "start": "696290",
    "end": "704510"
  },
  {
    "text": "I'll also define a regularizer so theta here is you can think of it as it's just",
    "start": "704510",
    "end": "710690"
  },
  {
    "text": "the concatenation of all my biases and all of my weights in my neural net so those are all the parameters of my",
    "start": "710690",
    "end": "716510"
  },
  {
    "text": "neural network and the regularizer will essentially penalize certain values of",
    "start": "716510",
    "end": "721670"
  },
  {
    "text": "these weights so as I'll talk more specifically later on for instance you might want to have your way to not be",
    "start": "721670",
    "end": "728450"
  },
  {
    "text": "too far from zero that's a frequent intuition that we implement with regularizer and so the optimization problem that",
    "start": "728450",
    "end": "736520"
  },
  {
    "text": "we'll try to solve when learning is to minimize the average loss of my neural",
    "start": "736520",
    "end": "742459"
  },
  {
    "text": "network over my training example so summing over all training examples I have capital T examples plus some weight",
    "start": "742459",
    "end": "751700"
  },
  {
    "text": "here that's known as the weight DK some hyper parameter lambda times my regular Iser so in other words I'm going to try",
    "start": "751700",
    "end": "758029"
  },
  {
    "text": "to have my loss on my training set as small as possible over all the training",
    "start": "758029",
    "end": "763459"
  },
  {
    "text": "example and also try to satisfy my regularizer as much as possible and so now we have this optimization",
    "start": "763459",
    "end": "770870"
  },
  {
    "text": "problem and we learning will just correspond to trying to solve this problem so performing this finding this",
    "start": "770870",
    "end": "777050"
  },
  {
    "text": "argument here for over my weights and my biases and if I want to do this I can",
    "start": "777050",
    "end": "782209"
  },
  {
    "text": "just invoke some optimization procedure from the optimization community and the",
    "start": "782209",
    "end": "789140"
  },
  {
    "text": "one algorithm that you'll see constantly in deep learning is stochastic gradient descent this is the optimization",
    "start": "789140",
    "end": "795680"
  },
  {
    "text": "algorithm that will often use for training neural networks so SGD",
    "start": "795680",
    "end": "800690"
  },
  {
    "text": "stochastic gradient descent functions as follows you first initialize all of your parameters that",
    "start": "800690",
    "end": "806630"
  },
  {
    "text": "is finding initial values for my weight matrices and all of my bio C's and then",
    "start": "806630",
    "end": "812270"
  },
  {
    "text": "for a certain number of epochs so an epoch will be a full pass over all my examples that's what I'll call an epoch",
    "start": "812270",
    "end": "819220"
  },
  {
    "text": "so for a certain number of full iterations over my training set",
    "start": "819220",
    "end": "824930"
  },
  {
    "text": "I'll draw each training example so I pair X input X target Y and then I'll",
    "start": "824930",
    "end": "832040"
  },
  {
    "text": "compute what is the gradient of my loss with respect to my parameters all of my",
    "start": "832040",
    "end": "838880"
  },
  {
    "text": "parameters all my weights and all my biases this is what this notation here so nabla for the gradient of the loss",
    "start": "838880",
    "end": "845660"
  },
  {
    "text": "function and here I'm indexing with respect to which parameter I want the gradient so I'm going to compute what is",
    "start": "845660",
    "end": "853160"
  },
  {
    "text": "the gradient of my last function with respect to my parameters and plus lambda",
    "start": "853160",
    "end": "858440"
  },
  {
    "text": "times the gradient of my regularizer as well and then I'm going to get a direction in which I should move my",
    "start": "858440",
    "end": "863750"
  },
  {
    "text": "parameters since the greyman tells me how to increase the loss I want to go in",
    "start": "863750",
    "end": "869180"
  },
  {
    "text": "the opposite direction and decrease it so my direction will be the opposite so that's why I have a minus here and so",
    "start": "869180",
    "end": "875690"
  },
  {
    "text": "this Delta is going to be the direction in which I'll move my parameters by taking a step and the step is just a",
    "start": "875690",
    "end": "882050"
  },
  {
    "text": "step size alpha which is often referred to as a learning rate times my direction",
    "start": "882050",
    "end": "887510"
  },
  {
    "text": "which I just add to my current values of my parameters my biases and my weights",
    "start": "887510",
    "end": "892790"
  },
  {
    "text": "and that's going to give me my new value for all of my parameters and I iterate like that over going over all pairs x",
    "start": "892790",
    "end": "900590"
  },
  {
    "text": "wise computing my gradient taking a steps out in the opposite direction and then doing that several times okay so",
    "start": "900590",
    "end": "907760"
  },
  {
    "text": "that's how stochastic gradient descent works and that's essentially the learning procedure it's represented by",
    "start": "907760",
    "end": "913760"
  },
  {
    "text": "this this procedure so in this algorithm there are few things we need to specify to be able to implement it and execute",
    "start": "913760",
    "end": "920240"
  },
  {
    "text": "it we need a loss function the choice for the loss function we need a procedure that's efficient for computing the",
    "start": "920240",
    "end": "926960"
  },
  {
    "text": "gradient of the loss with respect to my parameters we need to choose a regularizer if you want one and we need",
    "start": "926960",
    "end": "933770"
  },
  {
    "text": "a way of initializing my parameters so next what I'll do is go through each of these these four",
    "start": "933770",
    "end": "939089"
  },
  {
    "text": "different things we need to choose before actually being able to execute the classic gradient descent so first",
    "start": "939089",
    "end": "946920"
  },
  {
    "start": "945000",
    "end": "945000"
  },
  {
    "text": "the last function so as I said we will interpret the output layer as assigning probabilities to each potential class in",
    "start": "946920",
    "end": "953700"
  },
  {
    "text": "which I can classify my input X well in this case something that would be",
    "start": "953700",
    "end": "959010"
  },
  {
    "text": "natural is to try to maximize the probability of the correct class the actual class in which my example XT",
    "start": "959010",
    "end": "965820"
  },
  {
    "text": "belongs to I'd like to increase the value of the probability assigned by computed by my neural network and so",
    "start": "965820",
    "end": "973410"
  },
  {
    "text": "because we set up the problem in which we have a loss that we minimize instead",
    "start": "973410",
    "end": "978690"
  },
  {
    "text": "of maximizing the probability what we'll actually do is minimize the negative and the actual log probability so the log",
    "start": "978690",
    "end": "985830"
  },
  {
    "text": "likelihood of assigning X to the correct class Y so this is represented here so",
    "start": "985830",
    "end": "992190"
  },
  {
    "text": "given my output layer and the true label Y my loss will be minus the log of the",
    "start": "992190",
    "end": "998310"
  },
  {
    "text": "probability of Y for minor according to my neural net and that would be well take my output layer and look at the",
    "start": "998310",
    "end": "1005930"
  },
  {
    "text": "unit so index the unit corresponding to the correct class so that's why I'm indexing by Y here we take the log",
    "start": "1005930",
    "end": "1014089"
  },
  {
    "text": "because numerically it turns out to be more stable we get nicer looking gradients and sometimes in certain",
    "start": "1014089",
    "end": "1020750"
  },
  {
    "text": "software's you'll see instead of talking about the negative log likelihood or log probability you'll see it referred as",
    "start": "1020750",
    "end": "1026209"
  },
  {
    "text": "the cross entropy and that's because you can think of this as performing a sum",
    "start": "1026209",
    "end": "1033110"
  },
  {
    "text": "over all possible classes and then for each class checking well is this potential class the target class so I",
    "start": "1033110",
    "end": "1040850"
  },
  {
    "text": "have an indicator function that is one if Y is equal to C so if my iterator",
    "start": "1040850",
    "end": "1046250"
  },
  {
    "text": "Class C is actually equal to the real class I'm going to multiply that by the",
    "start": "1046250",
    "end": "1051380"
  },
  {
    "text": "log of the probability actually assigned to that class C and this this function",
    "start": "1051380",
    "end": "1058070"
  },
  {
    "text": "here so this expression here is like a cross entropy between the empirical distribution which assigns 0 probability",
    "start": "1058070",
    "end": "1064130"
  },
  {
    "text": "to all the other classes but a probability of 1 to the correct class and the actual distribution over",
    "start": "1064130",
    "end": "1070640"
  },
  {
    "text": "that my neural net is computing which is f of X okay that's just a technical",
    "start": "1070640",
    "end": "1075740"
  },
  {
    "text": "detail you can just think about this here I only mention it because in certain libraries it's actually mentioned as the cross-entropy a loss so",
    "start": "1075740",
    "end": "1083840"
  },
  {
    "text": "that's for the loss then we need also a procedure for computing what is the gradient of my loss with respect to all",
    "start": "1083840",
    "end": "1090710"
  },
  {
    "text": "of my parameters in my neural net so the biases and the weights you can go look",
    "start": "1090710",
    "end": "1096530"
  },
  {
    "text": "at my videos if on the actual derivation of all the details for all of these different expressions I don't have time",
    "start": "1096530",
    "end": "1102440"
  },
  {
    "text": "for that so all I'll do and presumably a lot of you I actually seen you know these derivations if you haven't just go",
    "start": "1102440",
    "end": "1109610"
  },
  {
    "text": "check out the videos in any case I'm going to go through what the algorithm is I'm going to highlight some of the",
    "start": "1109610",
    "end": "1115070"
  },
  {
    "text": "key points that will come up later in understanding out actually back propagation functions so the basic idea",
    "start": "1115070",
    "end": "1123110"
  },
  {
    "text": "is that we'll compute gradients by exploiting the chain rule and we'll go from the top layer all the way to the",
    "start": "1123110",
    "end": "1129530"
  },
  {
    "text": "bottom computing gradients for layers that are closer and closer to the input as we go",
    "start": "1129530",
    "end": "1134810"
  },
  {
    "text": "and exploiting the chain rule to exploit or reuse previous computations we've made at upper layers to compute the",
    "start": "1134810",
    "end": "1141500"
  },
  {
    "text": "gradients at the layers of below so we usually start by computing what is the",
    "start": "1141500",
    "end": "1147530"
  },
  {
    "text": "gradient at the output layer so what's the gradient of my loss with respect to",
    "start": "1147530",
    "end": "1152570"
  },
  {
    "start": "1149000",
    "end": "1149000"
  },
  {
    "text": "my output layer it actually it's more convenient to compute the loss with respect to the pre activation it's",
    "start": "1152570",
    "end": "1158450"
  },
  {
    "text": "actually a very simple expression so that that's why I have the gradient of this vector a L plus 1 that's the pre",
    "start": "1158450",
    "end": "1165590"
  },
  {
    "text": "activation at the very last layer of the loss function which is minus the log f of XY and it turns out this gradient is",
    "start": "1165590",
    "end": "1173930"
  },
  {
    "text": "super simple it's minus II of Y so that's the one Hut vector for class Y so",
    "start": "1173930",
    "end": "1180260"
  },
  {
    "text": "what this means is a of Y is just a vector filled with a bunch of zeros and then the one at the correct class so if",
    "start": "1180260",
    "end": "1188240"
  },
  {
    "text": "Y was the fourth class then in this case it would be this vector we have a one at the fourth dimension so e of Y is just a",
    "start": "1188240",
    "end": "1195590"
  },
  {
    "text": "vector it's we call it the one Hut vector full of zeros and the single one at the position corresponding to the",
    "start": "1195590",
    "end": "1201860"
  },
  {
    "text": "correct class so this part of the grain is essentially saying is that I'm going to increase I",
    "start": "1201860",
    "end": "1207620"
  },
  {
    "text": "want to increase the probability of the correct class I want to increase the pre activation which will increase the",
    "start": "1207620",
    "end": "1213020"
  },
  {
    "text": "probability of the correct class and I'm going to subtract what is the current probabilities assigned by my neural net",
    "start": "1213020",
    "end": "1220310"
  },
  {
    "text": "to all of the classes so f of X that's my output layer and that's the current beliefs of the neural net as to in which",
    "start": "1220310",
    "end": "1227150"
  },
  {
    "text": "class what's the probably of signing the input to each class so what this is",
    "start": "1227150",
    "end": "1232310"
  },
  {
    "text": "doing is essentially trying to decrease the probability of everything and specifically decrease it as much as I",
    "start": "1232310",
    "end": "1238430"
  },
  {
    "text": "the neural net currently believes that the input belongs to it and so if you",
    "start": "1238430",
    "end": "1243530"
  },
  {
    "text": "think about the subtraction of these two things well for the class that's the correct class I'm going to have one",
    "start": "1243530",
    "end": "1248990"
  },
  {
    "text": "minus some number between zero and one because it's a probability so that's going to be positive so I'm going to",
    "start": "1248990",
    "end": "1254000"
  },
  {
    "text": "increase the probability of the correct class and for everything else it's going to be zero minus a positive number so",
    "start": "1254000",
    "end": "1259850"
  },
  {
    "text": "it's going to be negative I'm actually going to decrease the probability of everything else so in two Li and it",
    "start": "1259850",
    "end": "1264980"
  },
  {
    "text": "makes sense this gradient has the right behavior and I'm going to take that pre activation gradient I'm going to",
    "start": "1264980",
    "end": "1271970"
  },
  {
    "text": "propagate it from the top to the bottom and and essentially iterating from the",
    "start": "1271970",
    "end": "1278210"
  },
  {
    "text": "last layer which is the output layer l plus 1 all the way down to the first layer and as I'm going down I'm going to",
    "start": "1278210",
    "end": "1285860"
  },
  {
    "text": "compute the gradient with respect to my parameters and then compute what's the gradient for the pre activation that the",
    "start": "1285860",
    "end": "1291620"
  },
  {
    "text": "layer below and then iterate like that so at each iteration of that loop I take",
    "start": "1291620",
    "end": "1298550"
  },
  {
    "text": "what is the current gradient of the loss function with respect to the pre",
    "start": "1298550",
    "end": "1303710"
  },
  {
    "text": "activation at the current layer and I can compute the gradient of the loss function with respect to my weight",
    "start": "1303710",
    "end": "1310520"
  },
  {
    "text": "matrix so not doing the derivation here it it's actually simply this vector so",
    "start": "1310520",
    "end": "1318290"
  },
  {
    "text": "my in my notation I assume that all the vectors are column vectors so this pre activation gradient vector and I",
    "start": "1318290",
    "end": "1325310"
  },
  {
    "text": "multiply it by the transpose of the activations so the value of the layer right below the layer K minus one so",
    "start": "1325310",
    "end": "1334640"
  },
  {
    "text": "because I take the transpose that's a multiplication like this you can see if I do the outer product essentially between these two vectors",
    "start": "1334640",
    "end": "1340520"
  },
  {
    "text": "I'm going to get a matrix of the same size as my weight matrix so it all checks out that makes sense it turns out that the",
    "start": "1340520",
    "end": "1348050"
  },
  {
    "text": "gradient of the loss with respect to the bias is exactly the gradient of the loss with respect to the pre activation so",
    "start": "1348050",
    "end": "1354770"
  },
  {
    "text": "that's very simple so that gives me now my gradients for my parameters and now I need to compute okay what is going to be",
    "start": "1354770",
    "end": "1360860"
  },
  {
    "text": "the gradient of the pre activations at the layer below well first I'm going to get the gradient",
    "start": "1360860",
    "end": "1367190"
  },
  {
    "text": "of the last function with respect to the activation at the layer below well",
    "start": "1367190",
    "end": "1374330"
  },
  {
    "text": "that's just taking my pre activation gradient vector and multiplying it by for some reason does it show here but",
    "start": "1374330",
    "end": "1381350"
  },
  {
    "text": "and multiplied by the transpose of my weight matrix super simple operation just a linear transformation of my",
    "start": "1381350",
    "end": "1387830"
  },
  {
    "text": "gradients at layer cake linear and transform to get my gradients of the activation at the layer K minus one and",
    "start": "1387830",
    "end": "1394430"
  },
  {
    "text": "then to get the gradients of the pre activation so before the activation function",
    "start": "1394430",
    "end": "1399740"
  },
  {
    "text": "I mean to I'm gonna take this gradient here which is the gradient of the activation function at the layer K minus",
    "start": "1399740",
    "end": "1406370"
  },
  {
    "text": "one and then I applied the gradient corresponding to the partial derivative of my nonlinear activation function so",
    "start": "1406370",
    "end": "1413720"
  },
  {
    "text": "this here this refers to an element-wise product so I'm taking these two vectors this vector here in this vector here I'm",
    "start": "1413720",
    "end": "1420800"
  },
  {
    "text": "going to do an element-wise product between the two and this vector here is just a partial derivative of the",
    "start": "1420800",
    "end": "1427340"
  },
  {
    "text": "activation function for each unit individually that I've put together into a vector okay this is what this",
    "start": "1427340",
    "end": "1433250"
  },
  {
    "text": "corresponds to now the key things to notice is first that this path computing",
    "start": "1433250",
    "end": "1438650"
  },
  {
    "text": "all the gradients and doing all these iterations is actually fairly cheap its complexity is essentially the same as",
    "start": "1438650",
    "end": "1444980"
  },
  {
    "text": "the one is doing a forward pass so all I'm doing are linear transformations",
    "start": "1444980",
    "end": "1450580"
  },
  {
    "text": "multiplying by matrices in this case the transpose of my weight matrix and then I'm also doing this sort of nonlinear",
    "start": "1450580",
    "end": "1456980"
  },
  {
    "text": "operation where I'm multiplying by the gradient of the activation function that's the first thing to notice and the",
    "start": "1456980",
    "end": "1462920"
  },
  {
    "text": "second thing to notice is that here I'm doing this element-wise product so if any of these terms here for a unit is",
    "start": "1462920",
    "end": "1470279"
  },
  {
    "text": "very close to zero then the pre activation gradient is going to be zero for the next layer and I highlight this",
    "start": "1470279",
    "end": "1477299"
  },
  {
    "text": "point because essentially whenever that's something to think about a lot when you're training neural nets",
    "start": "1477299",
    "end": "1482369"
  },
  {
    "text": "whenever this gradient here these partial derivatives come close to zero that it means the grain will not",
    "start": "1482369",
    "end": "1488609"
  },
  {
    "text": "propagate well to the next layer which means that you're not going to get a good gradient to update your parameters",
    "start": "1488609",
    "end": "1494090"
  },
  {
    "text": "now when does that happen when will you see these terms here being close to zero",
    "start": "1494090",
    "end": "1499139"
  },
  {
    "start": "1499000",
    "end": "1499000"
  },
  {
    "text": "well that's going to be when the partial derivatives of these nonlinear activation functions are close to zero",
    "start": "1499139",
    "end": "1504629"
  },
  {
    "text": "or zero so we can look at the partial derivative say of the sigmoid function it turns out it's super easy to compute",
    "start": "1504629",
    "end": "1512309"
  },
  {
    "text": "it's just the Sigma itself times 1 minus the sigmoid itself so that means that",
    "start": "1512309",
    "end": "1518580"
  },
  {
    "text": "whenever the activation of the unit for sigmoid unit is close to 1 or close to 0 I essentially get a partial there that's",
    "start": "1518580",
    "end": "1525570"
  },
  {
    "text": "close to zero you can kind of see it here the slope here is essentially flat and the slope here is flat that's the",
    "start": "1525570",
    "end": "1532369"
  },
  {
    "text": "value of the partial derivative so in other words if my pre activations are",
    "start": "1532369",
    "end": "1537960"
  },
  {
    "text": "very negative or very positive so if my unit is very saturated then gradients will have a hard time propagating to the",
    "start": "1537960",
    "end": "1545009"
  },
  {
    "text": "next layer that's the key inside here same thing for the tension so the turns",
    "start": "1545009",
    "end": "1552570"
  },
  {
    "text": "out the partial derivative is also easy to compute you just take the tangible you square it and going to subtract it",
    "start": "1552570",
    "end": "1558479"
  },
  {
    "text": "to 1 and yeah indeed if it's close to minus 1 or close to 1 you can see that",
    "start": "1558479",
    "end": "1565080"
  },
  {
    "text": "the slope is flat so again if the unit is saturating gradients will propagate I",
    "start": "1565080",
    "end": "1570779"
  },
  {
    "text": "have a hard time propagating to the next layer and for the relu the rectified",
    "start": "1570779",
    "end": "1576599"
  },
  {
    "text": "linear activation function the gradient is even simpler it's you just check",
    "start": "1576599",
    "end": "1581669"
  },
  {
    "text": "whether the pre activation is greater than 0 if it is the partial derivative is 1 if it's not at 0 so actually either",
    "start": "1581669",
    "end": "1588389"
  },
  {
    "text": "we're going to multiply by 1 or 0 you essentially get a binary mask when you're performing the propagation",
    "start": "1588389",
    "end": "1593580"
  },
  {
    "text": "through their value and you can see it the the slope here is flat and otherwise you have a linear function so actually",
    "start": "1593580",
    "end": "1600330"
  },
  {
    "text": "here at the shrinking of the grade and toward 0 is even harder it's exactly multiplying by",
    "start": "1600330",
    "end": "1606179"
  },
  {
    "text": "zero if your have a unit that's saturating below and beyond all the math",
    "start": "1606179",
    "end": "1614190"
  },
  {
    "text": "in terms of actually using those in practice during the weekend you'll see three different libraries that",
    "start": "1614190",
    "end": "1620820"
  },
  {
    "text": "essentially allows you to compute these gradients for you you actually usually don't write down backdrop you just use",
    "start": "1620820",
    "end": "1626940"
  },
  {
    "text": "all of these modules that you've implemented and it turns out there's a way of automatic automatic ly differentiating your loss function and",
    "start": "1626940",
    "end": "1634350"
  },
  {
    "text": "getting gradients for free in terms of effort in terms of programming effort with respect to your parameters so",
    "start": "1634350",
    "end": "1641870"
  },
  {
    "text": "conceptually the way you do this and you see essentially three different libraries doing it in slightly different",
    "start": "1641870",
    "end": "1646950"
  },
  {
    "text": "ways what you do is you up meant your flow graph by adding at the very end the",
    "start": "1646950",
    "end": "1653309"
  },
  {
    "start": "1650000",
    "end": "1650000"
  },
  {
    "text": "computation of your loss function and then each of these boxes which are conceptually objects that are taking",
    "start": "1653309",
    "end": "1659460"
  },
  {
    "text": "arguments and computing a value you're going to augment them to also have a method that's a backdrop or B prop",
    "start": "1659460",
    "end": "1667230"
  },
  {
    "text": "method you'll often see actually this expression being used be prop and what this method should do is that it should",
    "start": "1667230",
    "end": "1673440"
  },
  {
    "text": "take as input what is the gradient of the loss with respect to myself and then it should propagate to its arguments so",
    "start": "1673440",
    "end": "1680460"
  },
  {
    "text": "the things that its parents in the flow graph the things that takes to compute its own value it's going to propagate them using the chain rule what is their",
    "start": "1680460",
    "end": "1687690"
  },
  {
    "text": "gradients with respect to the loss so what this means is that you would sort",
    "start": "1687690",
    "end": "1692909"
  },
  {
    "text": "of start the process by initializing well the gradient of the loss with respect to itself is 1 and then you pass",
    "start": "1692909",
    "end": "1699840"
  },
  {
    "text": "the B prop method here 1 and then it's going to propagate to its argument what",
    "start": "1699840",
    "end": "1706350"
  },
  {
    "text": "is by using the chain rule what is the gradient of the loss with respect to f of X and then you're going to call B",
    "start": "1706350",
    "end": "1713549"
  },
  {
    "text": "prop on this object here and it's going to compute well add the gradient of the loss with respect to myself f of X from",
    "start": "1713549",
    "end": "1719399"
  },
  {
    "text": "this I can compute what's the gradient of my argument which is the pre activation at layer 2 which is back to",
    "start": "1719399",
    "end": "1725820"
  },
  {
    "text": "the loss so I'm going to reuse the computation I just got and update it using my what is essentially the",
    "start": "1725820",
    "end": "1731580"
  },
  {
    "text": "Jacobian and then I'm going to take the pre activation here which now knows what is the gradient of the loss with respect",
    "start": "1731580",
    "end": "1737340"
  },
  {
    "text": "to itself activation it's going to propagate to the weights and the biases and the layer",
    "start": "1737340",
    "end": "1742410"
  },
  {
    "text": "below update them with informing them of what is the grain into the last with respect to themselves and you continue",
    "start": "1742410",
    "end": "1748020"
  },
  {
    "text": "like this essentially going through the flow graph but in the opposite direction so the library torch the basic library",
    "start": "1748020",
    "end": "1754890"
  },
  {
    "text": "torch essentially functions like this quite explicitly it you construct you chain these elements together and then",
    "start": "1754890",
    "end": "1761190"
  },
  {
    "text": "when you're performing back propagation you're going in the reverse order of these chained elements and then you have",
    "start": "1761190",
    "end": "1766350"
  },
  {
    "text": "libraries like torch other grand piano and tens of which you learn about which are doing things slightly more",
    "start": "1766350",
    "end": "1773130"
  },
  {
    "text": "sophisticated there and you'll learn about that later on okay so that's the",
    "start": "1773130",
    "end": "1779790"
  },
  {
    "start": "1778000",
    "end": "1778000"
  },
  {
    "text": "discussion of how you actually compute gradients of the last with respect to the parameters so that's another",
    "start": "1779790",
    "end": "1785130"
  },
  {
    "text": "component we need in stochastic grain in this end we can choose a regular Weiser one that's often used is the l2",
    "start": "1785130",
    "end": "1792120"
  },
  {
    "text": "regularization so that's just the sum of the squared of the all the weights and the gradient of that is just twice times",
    "start": "1792120",
    "end": "1800370"
  },
  {
    "text": "the weight so it's a super simple gradient to compute we usually don't regularize the biases",
    "start": "1800370",
    "end": "1806430"
  },
  {
    "text": "there's no particularly important reason for that it's just it there much for",
    "start": "1806430",
    "end": "1811530"
  },
  {
    "text": "your by see so it seems less important and often this l2 regularization is",
    "start": "1811530",
    "end": "1817110"
  },
  {
    "text": "often referred to as weight DK so if you hear about weight decayed that often refers to l2 regularization and then",
    "start": "1817110",
    "end": "1824580"
  },
  {
    "start": "1824000",
    "end": "1824000"
  },
  {
    "text": "finally and this is also a very important point you have to initialize",
    "start": "1824580",
    "end": "1829710"
  },
  {
    "text": "the parameters before you actually start doing back prop and there are a few tricky cases you need to make sure that",
    "start": "1829710",
    "end": "1834780"
  },
  {
    "text": "you don't fall into so the biases often we initialize them to 0 there are",
    "start": "1834780",
    "end": "1840780"
  },
  {
    "text": "certain exceptions but for the most part we initialize them to 0 but for the weights there are a few things we can't",
    "start": "1840780",
    "end": "1847020"
  },
  {
    "text": "do so we can't initialize the weights to 0 and especially if you have 10 H activations the reason and I won't",
    "start": "1847020",
    "end": "1855540"
  },
  {
    "text": "explain it here but it's not a bad exercise to try to figure out why is that essentially when you do your first",
    "start": "1855540",
    "end": "1861840"
  },
  {
    "text": "pass you're going to get gradients for all your parameters that are going to be 0 so I'm going to be stuck at this 0",
    "start": "1861840",
    "end": "1867390"
  },
  {
    "text": "initialization so we can do that we can't initialize all the weights to",
    "start": "1867390",
    "end": "1873180"
  },
  {
    "text": "exactly the same value if again you think about it a little bit what's going",
    "start": "1873180",
    "end": "1879150"
  },
  {
    "text": "to happen is essentially that all the weights coming into a unit within the layer are going to have exactly the same",
    "start": "1879150",
    "end": "1886320"
  },
  {
    "text": "gradients which means they're going to be updated exactly the same way which means they're going to stay constant the",
    "start": "1886320",
    "end": "1891660"
  },
  {
    "text": "same that comes them but they're going to stay the same the whole time so it's as if you have multiple copies of the",
    "start": "1891660",
    "end": "1896910"
  },
  {
    "text": "same unit so you essentially have to break that initial symmetry that you would create if you initialize",
    "start": "1896910",
    "end": "1902160"
  },
  {
    "text": "everything to the same value so we end up doing most of the time is initialized the weights to some randomly generated",
    "start": "1902160",
    "end": "1909420"
  },
  {
    "text": "value often we generate them there are few other recipes but one of them is to initialize them from some uniform",
    "start": "1909420",
    "end": "1915750"
  },
  {
    "text": "distribution between lower and upper bound this is a recipe here that is",
    "start": "1915750",
    "end": "1921060"
  },
  {
    "text": "often used that has some theoretical grounding that's was derived specifically for the 10h there's this",
    "start": "1921060",
    "end": "1927180"
  },
  {
    "text": "pepper paper here by exactly Goho and yoshua bengio you can check out for some intuition as to oh you know how you",
    "start": "1927180",
    "end": "1933450"
  },
  {
    "text": "should initialize the weights but essentially this should be initially random and this should be initially close to zero random to break symmetry",
    "start": "1933450",
    "end": "1940470"
  },
  {
    "text": "and close to zero so that initially the units are not already saturated because",
    "start": "1940470",
    "end": "1947100"
  },
  {
    "text": "if the units are saturated then there are no gradients that are going to pass through the units you essentially going to get gradients very close to zero at",
    "start": "1947100",
    "end": "1953550"
  },
  {
    "text": "the lower layers so that's the main intuitions they have weights that are small and close to zero small and random",
    "start": "1953550",
    "end": "1961640"
  },
  {
    "text": "okay so those are the pieces we need for running stochastic gradient descent so",
    "start": "1961640",
    "end": "1967320"
  },
  {
    "text": "that allows us to take a training set and run the certain number of epochs and app the neural nets learn from that",
    "start": "1967320",
    "end": "1972780"
  },
  {
    "text": "training set now there are other quantities in our neural network that we haven't specified out to choose them so",
    "start": "1972780",
    "end": "1979320"
  },
  {
    "text": "those are the hyper parameters so usually we can have a separate validation set most people here are",
    "start": "1979320",
    "end": "1985830"
  },
  {
    "text": "familiar with machine learning so that's a typical procedure and then we need to select things like ok how many layers do",
    "start": "1985830",
    "end": "1991020"
  },
  {
    "text": "I want how many units per layer do I want what's the step size the learning rate of my stochastic gradient descent",
    "start": "1991020",
    "end": "1997260"
  },
  {
    "text": "procedure that alpha number what is the weight decay that I'm going to use so a",
    "start": "1997260",
    "end": "2002630"
  },
  {
    "text": "standard thing in machine learning is to perform a grid search that is if I have to our",
    "start": "2002630",
    "end": "2008630"
  },
  {
    "start": "2006000",
    "end": "2006000"
  },
  {
    "text": "parameters I list out a bunch of values I want to try so for the number of hidden units maybe I want to try a hundred a thousand and two thousand say",
    "start": "2008630",
    "end": "2016790"
  },
  {
    "text": "and then for the learning rate maybe I want to try 0.01 and 0.001 so a grid",
    "start": "2016790",
    "end": "2022790"
  },
  {
    "text": "search would just try all combinations of these three values for their hidden units and these two values for the",
    "start": "2022790",
    "end": "2027860"
  },
  {
    "text": "learning rates so that means that the more I providers there are it's the",
    "start": "2027860",
    "end": "2033470"
  },
  {
    "text": "number of configurations you have to try out blows up and grows exponentially so",
    "start": "2033470",
    "end": "2039650"
  },
  {
    "text": "another procedure that is now more more common which is more practical is to",
    "start": "2039650",
    "end": "2044750"
  },
  {
    "text": "perform a form of random search in this case what you do is for each parameter you actually determine a distribution of",
    "start": "2044750",
    "end": "2052190"
  },
  {
    "text": "likely values you'd like to try so it could be so for the number of hidden units maybe I do a uniform distribution",
    "start": "2052190",
    "end": "2059149"
  },
  {
    "text": "over all integers from a hundred to a thousand say or maybe a log uniform distribution and for the learning rate",
    "start": "2059150",
    "end": "2066139"
  },
  {
    "text": "may be again the log uniform distribution but from 0.001 to 0.01 say",
    "start": "2066140",
    "end": "2071990"
  },
  {
    "text": "and then to get an experiment to get values for my hyper parameters to do an",
    "start": "2071990",
    "end": "2077330"
  },
  {
    "text": "experiment with and get a performance of my validation set I just independently sample from these distributions for each",
    "start": "2077330",
    "end": "2083330"
  },
  {
    "text": "hyper parameter to get a full configuration for my experiment and then because I have this way of getting one",
    "start": "2083330",
    "end": "2089990"
  },
  {
    "text": "experiment I do it independently for all of my jobs all of my experiment that I will do so in this case if I know I have",
    "start": "2089990",
    "end": "2095810"
  },
  {
    "text": "like enough compute power to do 50 experiments I just sample 15 dependent",
    "start": "2095810",
    "end": "2101000"
  },
  {
    "text": "samples from these distributions for parameters perform these 50 experiments",
    "start": "2101000",
    "end": "2106070"
  },
  {
    "text": "and I just take the best one what's nice about it is that there are no unlike grid search there are never any holes in",
    "start": "2106070",
    "end": "2112100"
  },
  {
    "text": "the grid that is you just specify how many experiments you do if one of your jobs died well you just have one less",
    "start": "2112100",
    "end": "2118280"
  },
  {
    "text": "but there's no hole in your experiment and also one reason why it's particularly useful this approach is",
    "start": "2118280",
    "end": "2125540"
  },
  {
    "text": "that if you have a specific value in grid search for one of the hyper parameters that just makes the",
    "start": "2125540",
    "end": "2132260"
  },
  {
    "text": "experiment not work at all so learning rates are a lot like this if you have a learning rate that's too high it's quite",
    "start": "2132260",
    "end": "2139170"
  },
  {
    "text": "possible that convergence of the optimization will not converge well if you're using a grid search it means that",
    "start": "2139170",
    "end": "2145740"
  },
  {
    "text": "for all the experiments that use that specific value of the learning rate they're all going to be garbage they're all not going to be useful and you don't",
    "start": "2145740",
    "end": "2152670"
  },
  {
    "text": "really get this sort of big waste of computation if you do random search because most likely all the values of",
    "start": "2152670",
    "end": "2159180"
  },
  {
    "text": "your hyperparameters are going to be unique because their sample say from a uniform distribution over some some",
    "start": "2159180",
    "end": "2164670"
  },
  {
    "text": "range so that actually works quite well and and and quite recommended and there",
    "start": "2164670",
    "end": "2170790"
  },
  {
    "text": "are more advanced methods like methods based on machine learning bayesian optimization and or sometimes known as",
    "start": "2170790",
    "end": "2177329"
  },
  {
    "text": "sequential model based optimization that I won't talk about but that works a bit",
    "start": "2177329",
    "end": "2182730"
  },
  {
    "text": "better than random search and and that's another alternative if you think you",
    "start": "2182730",
    "end": "2188069"
  },
  {
    "text": "have an issue finding good hyper parameters is to investigate some of these more advanced methods now you do",
    "start": "2188069",
    "end": "2195180"
  },
  {
    "start": "2193000",
    "end": "2193000"
  },
  {
    "text": "this for most of your hyper parameters but for the number of epochs the number of times you go through all of your",
    "start": "2195180",
    "end": "2202220"
  },
  {
    "text": "examples in your training set what we usually do is not grid search or random",
    "start": "2202220",
    "end": "2208650"
  },
  {
    "text": "search but we use a thing known as early stopping the idea here is that if I've trained a neural net for 10 epochs while",
    "start": "2208650",
    "end": "2215490"
  },
  {
    "text": "training a neural net with all the other hyper parameters kept constant but one more epoch is easy I just do one more",
    "start": "2215490",
    "end": "2222329"
  },
  {
    "text": "epoch so I shouldn't try to I shouldn't start over and then do say eleven epochs from scratch and so what we would do is",
    "start": "2222329",
    "end": "2229559"
  },
  {
    "text": "we would just track what is the performance on the validation set as I do more and more epochs and what we will",
    "start": "2229559",
    "end": "2235290"
  },
  {
    "text": "typically see is the training error will go down but the validation set performance will go down and eventually",
    "start": "2235290",
    "end": "2241290"
  },
  {
    "text": "go up the intuition here is that the gap between the performance on the training",
    "start": "2241290",
    "end": "2246630"
  },
  {
    "text": "set and the performance on the validation set will tend to increase and since the training curve cannot go below",
    "start": "2246630",
    "end": "2253740"
  },
  {
    "text": "usually some bound then eventually the validation set performance has to go up",
    "start": "2253740",
    "end": "2259190"
  },
  {
    "text": "sometimes it won't sell go up oh is sort of stay stable so with early stopping what we do is that if we reach a point",
    "start": "2259190",
    "end": "2265260"
  },
  {
    "text": "where the validation set performance hasn't improved from some certain number of iterations which we refer to as the",
    "start": "2265260",
    "end": "2271349"
  },
  {
    "text": "look-ahead we just stop we go back to the neural net that had the best performance overall in the validation set and that's",
    "start": "2271349",
    "end": "2277180"
  },
  {
    "text": "my neural network so I have now a very cheap way of actually getting the number of iterations or the number of epochs",
    "start": "2277180",
    "end": "2283720"
  },
  {
    "text": "over my training set a few more tricks of the trade so it's always useful to",
    "start": "2283720",
    "end": "2292000"
  },
  {
    "start": "2287000",
    "end": "2287000"
  },
  {
    "text": "normalize your data it will often have the effect of speeding up training if you have real valued data for binary",
    "start": "2292000",
    "end": "2298960"
  },
  {
    "text": "data that usually keep it as it is so what I mean by that is just subtract for",
    "start": "2298960",
    "end": "2304210"
  },
  {
    "text": "each dimension what is the average in the training set of that dimension and then dividing by the standard deviation",
    "start": "2304210",
    "end": "2309220"
  },
  {
    "text": "of each dimension again in my input space so this can speed up training we",
    "start": "2309220",
    "end": "2316180"
  },
  {
    "text": "often use a decay on the learning rate there are a few methods for doing this",
    "start": "2316180",
    "end": "2321520"
  },
  {
    "text": "one that's very simple is to start with a large learning rate and then track the performance on the validation set and",
    "start": "2321520",
    "end": "2327790"
  },
  {
    "text": "once on the validation set it stops improving you decrease your learning rate by some ratio maybe you're divided",
    "start": "2327790",
    "end": "2333790"
  },
  {
    "text": "by two and then you continue training for some time hopefully the validation set performance starts improving and",
    "start": "2333790",
    "end": "2340330"
  },
  {
    "text": "then at some point it stops improving and then you stop or you divide again by two so that sort of gives you an",
    "start": "2340330",
    "end": "2346810"
  },
  {
    "text": "adaptive using the validation set an adaptive way of changing your learning rate and that can again work better than",
    "start": "2346810",
    "end": "2353800"
  },
  {
    "text": "having a very small learning rate than waiting for a long time so making very fast progress initially and then slower",
    "start": "2353800",
    "end": "2359080"
  },
  {
    "text": "progress towards TM also I've described",
    "start": "2359080",
    "end": "2365080"
  },
  {
    "text": "so far the approach for training neural nets that is based on a single example",
    "start": "2365080",
    "end": "2370540"
  },
  {
    "text": "at a time but in practice we actually use what's called mini batches that is we compute the last function on the",
    "start": "2370540",
    "end": "2376330"
  },
  {
    "text": "small subset of example say 64 128 and then we take the average of the loss of",
    "start": "2376330",
    "end": "2382600"
  },
  {
    "text": "all these examples in that mini batch and that's actually we compute the gradient of this average loss on that",
    "start": "2382600",
    "end": "2388660"
  },
  {
    "text": "mini batch the reason why we do this is that it turns out that you can very",
    "start": "2388660",
    "end": "2394540"
  },
  {
    "text": "efficiently implement the forward pass over all of these 64 128 examples in my",
    "start": "2394540",
    "end": "2400090"
  },
  {
    "text": "mini batch in one pass by instead of doing vector matrix multiplications when",
    "start": "2400090",
    "end": "2405430"
  },
  {
    "text": "we come the pre activations doing matrix matrix multiplications which are faster than",
    "start": "2405430",
    "end": "2410500"
  },
  {
    "text": "doing multiple matrix vector multiplications so in your code often there will be this other hyper parameter",
    "start": "2410500",
    "end": "2416920"
  },
  {
    "text": "which is mostly optimized for speed in terms of how quickly training will proceed of the number of examples in",
    "start": "2416920",
    "end": "2423490"
  },
  {
    "text": "your mini batch other things to improve optimization might be using a thing like",
    "start": "2423490",
    "end": "2428920"
  },
  {
    "text": "momentum that is instead of using as the descent direction the gradient of your",
    "start": "2428920",
    "end": "2434200"
  },
  {
    "text": "last function I'm actually going to track a descent direction which I'm going to compute as the current gradient",
    "start": "2434200",
    "end": "2440920"
  },
  {
    "text": "for my current example or mini-batch plus some fraction of the previous",
    "start": "2440920",
    "end": "2446290"
  },
  {
    "text": "update the previous direction of update and better now is a hyper parameter you",
    "start": "2446290",
    "end": "2451960"
  },
  {
    "text": "have to optimize so what this does is if all the update directions agree oh across multiple updates then it will",
    "start": "2451960",
    "end": "2459130"
  },
  {
    "text": "start picking up momentum and actually make bigger steps in those directions and there are multiple even more",
    "start": "2459130",
    "end": "2467830"
  },
  {
    "text": "advanced methods for adding adaptive types of learning rates I mentioned them",
    "start": "2467830",
    "end": "2473170"
  },
  {
    "text": "here very quickly because you might see them in papers there's a method known as a de grab where the learning rate is",
    "start": "2473170",
    "end": "2478930"
  },
  {
    "text": "actually scaled for each descent for each dimension so for each weight and each by seize it's going to be scaled by",
    "start": "2478930",
    "end": "2485530"
  },
  {
    "text": "what is the square root of the cumulative sum of the squared gradients",
    "start": "2485530",
    "end": "2491800"
  },
  {
    "text": "so what I track is I take my gradient vector at each step I do an element-wise square of all the dimensions on my",
    "start": "2491800",
    "end": "2499300"
  },
  {
    "text": "gradients my gradient vector and then I accumulate that in some variables that I'm noting as gamma here and then for my",
    "start": "2499300",
    "end": "2505960"
  },
  {
    "text": "descent direction I take the gradient and I do an element-wise division by the square root of this cumulative sum of",
    "start": "2505960",
    "end": "2513010"
  },
  {
    "text": "squared gradients there's also rmsprop which is essentially like a de grab but instead of doing a cumulative stuff a sum we're",
    "start": "2513010",
    "end": "2519760"
  },
  {
    "text": "going to do an exponential moving average so we take the previous value x sub factor plus one minus this factor",
    "start": "2519760",
    "end": "2526360"
  },
  {
    "text": "times the current squared gradient so that's rmsprop and then there's adam which is essentially a combination of",
    "start": "2526360",
    "end": "2533410"
  },
  {
    "text": "rmsprop with momentum which is more involved and i won't have time to describe it here but that's",
    "start": "2533410",
    "end": "2538850"
  },
  {
    "text": "method that's often you know actually implemented in these different softwares and that people seem to use with a lot",
    "start": "2538850",
    "end": "2545150"
  },
  {
    "text": "of success and finally in terms of",
    "start": "2545150",
    "end": "2550160"
  },
  {
    "start": "2547000",
    "end": "2547000"
  },
  {
    "text": "actually debugging your implementations so for instance if you're lucky you can",
    "start": "2550160",
    "end": "2555470"
  },
  {
    "text": "build your neural network without difficulty using the current tools that are available in torch or 10 to Flora",
    "start": "2555470",
    "end": "2560690"
  },
  {
    "text": "Theano but maybe sometimes you actually have to implement certain gradients for a new module and a new box in your flow graph",
    "start": "2560690",
    "end": "2567500"
  },
  {
    "text": "that isn't currently supported if you do this you should check that you've implemented your gradients correctly and",
    "start": "2567500",
    "end": "2573530"
  },
  {
    "text": "one way of doing that is to actually compare the gradients computed by your code with a finite difference of",
    "start": "2573530",
    "end": "2580060"
  },
  {
    "text": "estimate so what you do is for each parameter you add some very small epsilon value say 10 to the minus 6 and",
    "start": "2580060",
    "end": "2586970"
  },
  {
    "text": "you compute what is the output of your module and then you subtract the same thing but where you've subtracted the",
    "start": "2586970",
    "end": "2594500"
  },
  {
    "text": "small quantity and then the divide by 2 epsilon so if epsilon is converges to",
    "start": "2594500",
    "end": "2599630"
  },
  {
    "text": "zero then you actually get the partial derivative but if it's small it's going to be an approximate and usually this",
    "start": "2599630",
    "end": "2605270"
  },
  {
    "text": "finite difference estimate will be very close to a correct implementation of the real gradient so you should definitely",
    "start": "2605270",
    "end": "2611570"
  },
  {
    "text": "do that if you actually implemented some of the gradients in your code and in another useful thing to do is to",
    "start": "2611570",
    "end": "2618170"
  },
  {
    "start": "2616000",
    "end": "2616000"
  },
  {
    "text": "actually do a very small experiment on the small data set before you actually run your full experiment on your",
    "start": "2618170",
    "end": "2624530"
  },
  {
    "text": "complete data set so you say 50 examples so just taking a random subset of 50",
    "start": "2624530",
    "end": "2629990"
  },
  {
    "text": "examples from your your data set actually just make sure that your code can over fit to that data can",
    "start": "2629990",
    "end": "2635600"
  },
  {
    "text": "essentially classify it perfectly given you know enough capacity that you would",
    "start": "2635600",
    "end": "2641090"
  },
  {
    "text": "think it should get it so if it's not the case then there's a few things that",
    "start": "2641090",
    "end": "2646280"
  },
  {
    "text": "you might want to investigate maybe your initialization is such that the units are already saturated initially and so",
    "start": "2646280",
    "end": "2652850"
  },
  {
    "text": "there's no actual optimization happening because some of the gradients on some of the weights are exactly zero so you",
    "start": "2652850",
    "end": "2659180"
  },
  {
    "text": "might want to check your initialization maybe your gradients are just you know you're using a model you implemented",
    "start": "2659180",
    "end": "2665390"
  },
  {
    "text": "gradients for and maybe there are gradients are not properly implemented maybe you haven't normalized your input",
    "start": "2665390",
    "end": "2670580"
  },
  {
    "text": "which creates some instability making it harder for stochastic gradient descent to work successfully maybe your",
    "start": "2670580",
    "end": "2678770"
  },
  {
    "text": "learning rate is too large then you should consider trying smaller learning rates that's actually a pretty good way",
    "start": "2678770",
    "end": "2683930"
  },
  {
    "text": "of having a some idea of the magnitude of the learning rate you should be using and and then once you actually over fit",
    "start": "2683930",
    "end": "2691970"
  },
  {
    "text": "in your small trainings that you're ready to do a full experiment on on a larger data set that said this is not a",
    "start": "2691970",
    "end": "2697940"
  },
  {
    "text": "replacement for gradient checking so backdrop is and stochastic gradient descent it's a great algorithm that's",
    "start": "2697940",
    "end": "2704750"
  },
  {
    "text": "very bug resistant you will pretend potentially see some learning happening",
    "start": "2704750",
    "end": "2710240"
  },
  {
    "text": "even if some of your gradients are wrong or say exactly zero so you should that's great you know if you're an engineer and",
    "start": "2710240",
    "end": "2716150"
  },
  {
    "text": "you're implementing things spun would code is somewhat bug resistant but if you're actually doing science and try to",
    "start": "2716150",
    "end": "2721880"
  },
  {
    "text": "understand what's going on that's that can be a complication so do do both gradient checking and a small experiment",
    "start": "2721880",
    "end": "2728960"
  },
  {
    "text": "like that all right and so for the last few minutes I'll actually try to",
    "start": "2728960",
    "end": "2734240"
  },
  {
    "text": "motivate what you'll be learning quite a bit about in the next two days that is",
    "start": "2734240",
    "end": "2740660"
  },
  {
    "text": "the specific case for deep learning so I've already told you that if I have a",
    "start": "2740660",
    "end": "2746840"
  },
  {
    "text": "neural net win enough hidden units theoretically I can potentially represent pretty much any function any",
    "start": "2746840",
    "end": "2752240"
  },
  {
    "text": "classification function so why would I want multiple layers so there are a few motivations behind this the first one is",
    "start": "2752240",
    "end": "2759740"
  },
  {
    "text": "taken directly from our own brains so we know in the visual cortex that the light",
    "start": "2759740",
    "end": "2765140"
  },
  {
    "text": "that hits our retina eventually goes through several regions in the visual cortex eventually reaching narrow known",
    "start": "2765140",
    "end": "2771890"
  },
  {
    "text": "as v1 when you have units that are or neurons that are essentially tuned to small forms like edges and then it goes",
    "start": "2771890",
    "end": "2779300"
  },
  {
    "text": "on to v4 where it's likely more complex patterns that the units are tuned for and then you reach AIT where you",
    "start": "2779300",
    "end": "2785300"
  },
  {
    "text": "actually have neurons are specific to certain objects or certain units and so the idea here is that perhaps that's",
    "start": "2785300",
    "end": "2790850"
  },
  {
    "text": "also what we want another artificial say you know vision system we'd like it if",
    "start": "2790850",
    "end": "2796369"
  },
  {
    "text": "it's detecting faces to have a first layer that detects simple edges and then another layer that perhaps puts these",
    "start": "2796369",
    "end": "2803150"
  },
  {
    "text": "edges together detecting slightly more complex things nose or mouth or eyes and then eventually have a layer that combines",
    "start": "2803150",
    "end": "2809579"
  },
  {
    "text": "these slightly less abstract or more abstract units to get something even",
    "start": "2809579",
    "end": "2815579"
  },
  {
    "text": "more abstract like a complete phase there's also some theoretical justification for doing using multiple",
    "start": "2815579",
    "end": "2822690"
  },
  {
    "text": "layers so the early results were mostly based on studying boolean functions or a",
    "start": "2822690",
    "end": "2828420"
  },
  {
    "text": "function that takes as input can think of it as a vector of just zeros and ones and you could show that there are",
    "start": "2828420",
    "end": "2834690"
  },
  {
    "text": "certain functions that if you add the essentially a boolean neural network or",
    "start": "2834690",
    "end": "2840380"
  },
  {
    "text": "essentially a boolean circuit and you restricted the number of layers of that",
    "start": "2840380",
    "end": "2845490"
  },
  {
    "text": "circuit that there are certain functions that in this case to represent certain boolean functions exactly you would need",
    "start": "2845490",
    "end": "2851520"
  },
  {
    "text": "an exponential number of units in each of these layers whereas if you allowed yourself to have multiple layers then",
    "start": "2851520",
    "end": "2857250"
  },
  {
    "text": "you could represent these functions more compactly and so there's that's another motivation that perhaps with more layers",
    "start": "2857250",
    "end": "2862470"
  },
  {
    "text": "we can represent fairly complex functions in a more compact way and then",
    "start": "2862470",
    "end": "2868710"
  },
  {
    "text": "there's the reason that they just work so we've seen in the past few years great success in speech recognition",
    "start": "2868710",
    "end": "2875490"
  },
  {
    "text": "where it's essentially revolutionized the field where everyone's using deep learning for speech recognition and same",
    "start": "2875490",
    "end": "2881250"
  },
  {
    "text": "thing for visual object recognition where again deep learning is sort of the method of choice for identifying objects",
    "start": "2881250",
    "end": "2888030"
  },
  {
    "text": "and images so then why are we doing this only recently why didn't we do deep",
    "start": "2888030",
    "end": "2895500"
  },
  {
    "text": "learning way back when back prop was invented which is essentially in 1980s and even",
    "start": "2895500",
    "end": "2901109"
  },
  {
    "text": "before that so it turns out training deep neural networks is actually not that easy there are few hurdles that one",
    "start": "2901109",
    "end": "2908099"
  },
  {
    "text": "can be confronted with I've already mentioned one of the issue which is that some of the gradients might be fading as",
    "start": "2908099",
    "end": "2915000"
  },
  {
    "text": "you go from the top layer to the bottom layer because we keep multiplying by the derivative of the activation function so",
    "start": "2915000",
    "end": "2920609"
  },
  {
    "text": "that makes training hard it could be that the lower layers at very small gradients are barely moving and",
    "start": "2920609",
    "end": "2925920"
  },
  {
    "text": "exploring the space of correct you know features to learn for a given problem so",
    "start": "2925920",
    "end": "2931049"
  },
  {
    "text": "that sometimes that's the problem you find you have a hard time just fitting your data and you're essentially underfitting",
    "start": "2931049",
    "end": "2936089"
  },
  {
    "text": "or it could be that with you know deeper neural nets Oh bigger neural nets we",
    "start": "2936089",
    "end": "2941150"
  },
  {
    "text": "have more parameters so perhaps sometimes actually overfitting we're in a situation where all the functions that",
    "start": "2941150",
    "end": "2947390"
  },
  {
    "text": "we can represent with the same neural net represented by this gray area function actually includes yes the right",
    "start": "2947390",
    "end": "2954290"
  },
  {
    "text": "function but it's so large that for a finite training set the odds that I'm going to find the one that's close to",
    "start": "2954290",
    "end": "2960200"
  },
  {
    "text": "the true classifying function the real system that like to have is going to be very different so in this case I mean",
    "start": "2960200",
    "end": "2966410"
  },
  {
    "text": "I'm essentially overfitting and that might also be a situation we're in and",
    "start": "2966410",
    "end": "2971770"
  },
  {
    "text": "unfortunately there's never there are many situations where one problem is",
    "start": "2971770",
    "end": "2977450"
  },
  {
    "text": "observed over fitting or under fitting and so we essentially have you know in",
    "start": "2977450",
    "end": "2982880"
  },
  {
    "text": "the field develop tools for finding both situations and I'm going to rapidly touch a few of those which you will see",
    "start": "2982880",
    "end": "2989780"
  },
  {
    "text": "will come up later on in multiple talks so one of the first hypothesis which",
    "start": "2989780",
    "end": "2996320"
  },
  {
    "text": "might be that you're under fitting well you can essentially just fight this by waiting longer so training longer if you",
    "start": "2996320",
    "end": "3002200"
  },
  {
    "text": "have your grayness are too small and this is essentially why you're progressing very slowly when you're training well if you're using GPUs and",
    "start": "3002200",
    "end": "3008320"
  },
  {
    "text": "are able to do more iterations over the same training set within less time that",
    "start": "3008320",
    "end": "3013960"
  },
  {
    "text": "might just you know solve your problem of underfitting and I think we've seen some of that and this is partly why GPUs",
    "start": "3013960",
    "end": "3020080"
  },
  {
    "text": "have been so game-changing for deep learning or you can use just better optimization methods also and if you're",
    "start": "3020080",
    "end": "3026500"
  },
  {
    "text": "overfitting well we just need better regularization i've been involved early",
    "start": "3026500",
    "end": "3032680"
  },
  {
    "text": "on in my PhD on using unsupervised learning as a way to regularize neural",
    "start": "3032680",
    "end": "3037690"
  },
  {
    "text": "nets if I have time I'll talk a little bit about that then there's another method you might have learned heard",
    "start": "3037690",
    "end": "3043150"
  },
  {
    "text": "about known as dropout so I'll try to touch at least two methods that are",
    "start": "3043150",
    "end": "3048730"
  },
  {
    "text": "essentially trying to address some of these issues so the first one that I'll talk about this dropout it's actually",
    "start": "3048730",
    "end": "3055119"
  },
  {
    "start": "3054000",
    "end": "3054000"
  },
  {
    "text": "very easy very simple so the idea of if our neural net is essentially",
    "start": "3055119",
    "end": "3060400"
  },
  {
    "text": "overfitting so it's too good at training on the training set well we're essentially going to training",
    "start": "3060400",
    "end": "3066820"
  },
  {
    "text": "when I make it harder to fit the training set and where we're going to do that and dropout is that we will",
    "start": "3066820",
    "end": "3072330"
  },
  {
    "text": "stochastically remove hidden units independently so for each hidden unit",
    "start": "3072330",
    "end": "3077340"
  },
  {
    "text": "before we do a forward pass we'll flip a coin and we'd probably have we will",
    "start": "3077340",
    "end": "3082350"
  },
  {
    "text": "multiply the activation by zero with probability 1/2 we'll multiply it by 1",
    "start": "3082350",
    "end": "3087390"
  },
  {
    "text": "so what this means is that if a unit is multiplied by 0 it's effectively not in the neural net anymore and we're doing",
    "start": "3087390",
    "end": "3095220"
  },
  {
    "text": "this independently for each hidden units so that means that in a layer a unit",
    "start": "3095220",
    "end": "3100410"
  },
  {
    "text": "cannot rely anymore on the presence on any other units to try to sort of",
    "start": "3100410",
    "end": "3105590"
  },
  {
    "text": "synchronize and adapt to perform a complex classification or learn a",
    "start": "3105590",
    "end": "3110970"
  },
  {
    "text": "complex feature and that was partly the motivation behind dropout is that this procedure might encourage types of",
    "start": "3110970",
    "end": "3117840"
  },
  {
    "text": "features that are not co-adapted and are less likely to overfit so we often use",
    "start": "3117840",
    "end": "3123960"
  },
  {
    "text": "0.5 as the probability of dropping out a unit it turns out it often surprisingly",
    "start": "3123960",
    "end": "3129870"
  },
  {
    "text": "is the best value but that's another hyper parameter you might want to tune and in terms of how it impacts an",
    "start": "3129870",
    "end": "3136770"
  },
  {
    "text": "implementation of back prop it's it's very simple so the forward pass before I do it I just sample my binary masks for",
    "start": "3136770",
    "end": "3143400"
  },
  {
    "text": "all my layers and and then when I'm performing back drop well my gradient on",
    "start": "3143400",
    "end": "3149250"
  },
  {
    "text": "the oh sorry so that's the Ford pass yeah I'm just multiplying by this binary mask here so super simple change and",
    "start": "3149250",
    "end": "3156060"
  },
  {
    "text": "then in terms of back prop well I'm also going to multiply by the mask when I get",
    "start": "3156060",
    "end": "3161610"
  },
  {
    "text": "my gradient on the pre activation and also you know don't forget that the activations are now different they",
    "start": "3161610",
    "end": "3167190"
  },
  {
    "text": "actually include the masks in in my notation it's a very simple change the forward and backward pass when you're",
    "start": "3167190",
    "end": "3173130"
  },
  {
    "text": "training and also another thing that I shouldn't emphasize is that the mask is being resampled for every example so",
    "start": "3173130",
    "end": "3179700"
  },
  {
    "text": "before you do a forward pass you resample the mask you don't keep it you know sample at once and then use it the",
    "start": "3179700",
    "end": "3184800"
  },
  {
    "text": "whole time and then that test time because we don't really like a model",
    "start": "3184800",
    "end": "3190500"
  },
  {
    "text": "that sort of randomly changes its output because it will if we stochastically change the masks what we do is we",
    "start": "3190500",
    "end": "3197520"
  },
  {
    "text": "replace the mask by the probability of dropping out a unit so actually of",
    "start": "3197520",
    "end": "3204150"
  },
  {
    "text": "keeping a unit so if we 0.5 that's just 0.5 we can actually show",
    "start": "3204150",
    "end": "3210060"
  },
  {
    "text": "that if you have a neural net with a single hidden layer doing this transformation at test time multiplying",
    "start": "3210060",
    "end": "3215760"
  },
  {
    "text": "by 0.5 is equivalent to doing a geometric average of all the possible neural networks with all the different",
    "start": "3215760",
    "end": "3221700"
  },
  {
    "text": "binary mask patterns so it's essentially one way of thinking about drop out in the single layer case is that it's kind",
    "start": "3221700",
    "end": "3228240"
  },
  {
    "text": "of an in sembly method we have a lot of models an exponential number of models which are all sharing the same weights",
    "start": "3228240",
    "end": "3234180"
  },
  {
    "text": "but have different masks that intuition though doesn't transfer for deep neural",
    "start": "3234180",
    "end": "3239250"
  },
  {
    "text": "nets in the sense that you cannot show this result it really only applies to a single neural networks in gold hidden",
    "start": "3239250",
    "end": "3244410"
  },
  {
    "text": "layer so in practice it's very effective but do expect some slowdown in training",
    "start": "3244410",
    "end": "3250590"
  },
  {
    "text": "so often we tend to see that training or network to completion will take twice as many epochs if you're using dropout with",
    "start": "3250590",
    "end": "3257460"
  },
  {
    "text": "0.5 and here you have the reference if you want to learn more about different variations of dropouts and so on and",
    "start": "3257460",
    "end": "3264590"
  },
  {
    "text": "I'll and I'll probably won't talk about the unsupervised retraining for lack of time but I'll talk about another thing",
    "start": "3264590",
    "end": "3270960"
  },
  {
    "text": "that you'll definitely probably hear about and that's implementing these different packages which is Bachelor",
    "start": "3270960",
    "end": "3276240"
  },
  {
    "text": "organization Bachelor ization is kind of interesting in the sense that it's been shown to better optimize that is certain",
    "start": "3276240",
    "end": "3283800"
  },
  {
    "text": "networks that would otherwise under fit would not under fit as much anymore fuse Bachelor ization",
    "start": "3283800",
    "end": "3289500"
  },
  {
    "text": "but also it's been shown that when you use batch normalization dropout is not as useful and drop out being a",
    "start": "3289500",
    "end": "3295620"
  },
  {
    "text": "regularization method that suggests that perhaps patch normalization is also regularizing in some way so these things",
    "start": "3295620",
    "end": "3301980"
  },
  {
    "text": "are not you know one or the other they're not mutually exclusive you can have a regularizer that also turns out",
    "start": "3301980",
    "end": "3307350"
  },
  {
    "text": "helps you better optimize so the intuition behind batch normalization is",
    "start": "3307350",
    "end": "3314730"
  },
  {
    "start": "3310000",
    "end": "3310000"
  },
  {
    "text": "you know much like I've suggested that normalizing your inputs actually can help speeding up training well how about",
    "start": "3314730",
    "end": "3321630"
  },
  {
    "text": "we also normalize all the hidden layers when I'm doing my forward pass so now",
    "start": "3321630",
    "end": "3327690"
  },
  {
    "text": "the problem in doing this is that I can compute the mean and the standard deviations of my inputs once and for all",
    "start": "3327690",
    "end": "3333270"
  },
  {
    "text": "because they're constant but my hidden layers are constantly changing because I'm training these parameters",
    "start": "3333270",
    "end": "3338830"
  },
  {
    "text": "so the mean and the standard deviation of my units will change and so I it",
    "start": "3338830",
    "end": "3344230"
  },
  {
    "text": "would be very expensive if every time I did an update of my parameters I recomputed the means and the standard",
    "start": "3344230",
    "end": "3349960"
  },
  {
    "text": "deviations of all of my units so bachelors ation addresses some of these issues as follows so the way works is",
    "start": "3349960",
    "end": "3357250"
  },
  {
    "text": "first batch the normalization is going to be applied on actually the pre activation so not the activation of the",
    "start": "3357250",
    "end": "3363310"
  },
  {
    "text": "unit but before the non-linearity during training to address the issue that we",
    "start": "3363310",
    "end": "3368860"
  },
  {
    "text": "don't want to compute means over the full training set because that would be too slow I'm actually going to compute it on each mini batch so I have to do",
    "start": "3368860",
    "end": "3376780"
  },
  {
    "text": "mini batch training here I'm going to take my small mini batch of 64 128 examples and that's the set of examples",
    "start": "3376780",
    "end": "3382990"
  },
  {
    "text": "on which I'm going to compute my means and standard deviations and then when I do back prop I'm actually going to take",
    "start": "3382990",
    "end": "3389560"
  },
  {
    "text": "into account the normalization so now there's going to be a gradient going through the computation of the mean and",
    "start": "3389560",
    "end": "3395080"
  },
  {
    "text": "the standard deviation because they depend on the parameters of the neural network and then that test time we'll",
    "start": "3395080",
    "end": "3401080"
  },
  {
    "text": "just use the global mean and global standard deviation once I finished training I can actually do a full pass",
    "start": "3401080",
    "end": "3406630"
  },
  {
    "text": "over the whole training set and got all of my means and standard deviations so",
    "start": "3406630",
    "end": "3412000"
  },
  {
    "text": "that's the essentially the pseudocode for that taken out of the paper directly so if X is a pre activation for a unit",
    "start": "3412000",
    "end": "3420010"
  },
  {
    "text": "and have multiple pre activations for a single unit across my mini batch I would",
    "start": "3420010",
    "end": "3425410"
  },
  {
    "text": "compute what is the average for that unit pre activation across my examples in my mini batch compute my variance and",
    "start": "3425410",
    "end": "3433150"
  },
  {
    "text": "then subtract the mean and divide by the square root of the variance plus some epsilon for numerical stability in case",
    "start": "3433150",
    "end": "3440020"
  },
  {
    "text": "the variance is too close to zero and then another thing is that actually batch normalization doesn't just perform",
    "start": "3440020",
    "end": "3447250"
  },
  {
    "text": "this normalization and outputs the normalize pre activation it then actually performs a linear",
    "start": "3447250",
    "end": "3453430"
  },
  {
    "text": "transformation on it so it multiplies it by this parameter gamma which is going to be trained by gradient descent and",
    "start": "3453430",
    "end": "3460030"
  },
  {
    "text": "it's often called a gain parameter of batchelomez ation and it adds a bias",
    "start": "3460030",
    "end": "3466750"
  },
  {
    "text": "better and the reason is that if I'm subtracting by the mean then each of these you",
    "start": "3466750",
    "end": "3472369"
  },
  {
    "text": "have the biased parameter so if I subtracted then this essentially here",
    "start": "3472369",
    "end": "3477589"
  },
  {
    "text": "there's no bias anymore it was present here was present here and now it's been subtracted to have to add the bias but",
    "start": "3477589",
    "end": "3484130"
  },
  {
    "text": "after the bachelor ization essentially so these betters here are essentially the new bias parameters and those will",
    "start": "3484130",
    "end": "3491059"
  },
  {
    "text": "actually be trained so we do gradient descent also on those so bachelor ization adds a few parameters all right",
    "start": "3491059",
    "end": "3498319"
  },
  {
    "text": "and I as I said I'm just gonna skip over this and you know I'm not showing what the gradients are when your backdrop through the mean and so on it's",
    "start": "3498319",
    "end": "3504890"
  },
  {
    "text": "describing the paper for Necedah gradients but otherwise in the different packages you actually have access to",
    "start": "3504890",
    "end": "3510759"
  },
  {
    "text": "you'll get the gradients automatically it's usually been implemented skipping",
    "start": "3510759",
    "end": "3515930"
  },
  {
    "start": "3514000",
    "end": "3514000"
  },
  {
    "text": "over that I'll just finish if you actually want to learn about unsupervised retraining and why it works",
    "start": "3515930",
    "end": "3521089"
  },
  {
    "start": "3517000",
    "end": "3517000"
  },
  {
    "text": "videos on that so you can check that out and I guess that's it thank you",
    "start": "3521089",
    "end": "3528400"
  },
  {
    "text": "thanks you go so we have a few minutes for questions which are intermingled with a break so feel free to I your go",
    "start": "3534730",
    "end": "3542690"
  },
  {
    "text": "for our break or ask questions to Google I believe there are microphones and I'll also stick around so if you want to ask",
    "start": "3542690",
    "end": "3548299"
  },
  {
    "text": "your questions offline that's also fine if you want ask questions you can go to the mic",
    "start": "3548299",
    "end": "3554890"
  },
  {
    "text": "go to the microphone hi I mentioned the",
    "start": "3559660",
    "end": "3564820"
  },
  {
    "text": "rail ooh adds varsity can you explain why yeah so um so the first thing is",
    "start": "3564820",
    "end": "3572230"
  },
  {
    "text": "that it's observed in practice and they add some sparse some sparsity in part because you have the non-linearity at",
    "start": "3572230",
    "end": "3579220"
  },
  {
    "text": "zero below so it means that units are going to be exactly potentially exactly sparse exactly essentially absent of the",
    "start": "3579220",
    "end": "3586420"
  },
  {
    "text": "hidden layer the real there are a few reasons to sort of explain why you get",
    "start": "3586420",
    "end": "3593770"
  },
  {
    "text": "sparsity it turns out that this process of doing a linear transformation followed by the value activation",
    "start": "3593770",
    "end": "3599620"
  },
  {
    "text": "function is very close to some of the steps you would do when you're optimizing for sparse codes in the",
    "start": "3599620",
    "end": "3605080"
  },
  {
    "text": "sparse coding model if you know about sparse coding so they're like essentially in optimization methods that",
    "start": "3605080",
    "end": "3610420"
  },
  {
    "text": "given some sparse coding model we'll find what is the sparse representation hidden representation for some input and",
    "start": "3610420",
    "end": "3617350"
  },
  {
    "text": "it's mostly a sequence of linear transformations followed by this sort of like relu like activation function and I",
    "start": "3617350",
    "end": "3625480"
  },
  {
    "text": "think this is partly the explanation otherwise I don't I don't know a like solid you know explanation for why that",
    "start": "3625480",
    "end": "3631660"
  },
  {
    "text": "is beyond you know it's observed in practice more questions if not let's",
    "start": "3631660",
    "end": "3641860"
  },
  {
    "text": "thank you again and we are we reconvene",
    "start": "3641860",
    "end": "3649300"
  },
  {
    "text": "in ten minutes",
    "start": "3649300",
    "end": "3651870"
  }
]
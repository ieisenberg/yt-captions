[
  {
    "start": "0",
    "end": "1335000"
  },
  {
    "text": "today we'll talk about how to make machines see computer vision and we'll",
    "start": "89",
    "end": "6330"
  },
  {
    "text": "present Thank You Claire said yes and today we will present a competition that",
    "start": "6330",
    "end": "14580"
  },
  {
    "text": "unlike deep traffic which is designed to explore ideas teach you about concepts",
    "start": "14580",
    "end": "22920"
  },
  {
    "text": "of deep reinforcement learning seg fuse the deep dynamic driving scene",
    "start": "22920",
    "end": "28800"
  },
  {
    "text": "segmentation competition that I'll present today is at the very cutting edge whoever does well in this",
    "start": "28800",
    "end": "36719"
  },
  {
    "text": "competition is likely to produce a publication or ideas that would lead the",
    "start": "36719",
    "end": "42660"
  },
  {
    "text": "world in the area of perception perhaps together with the people running this",
    "start": "42660",
    "end": "48539"
  },
  {
    "text": "class perhaps in your own and I encourage you to do so even more cats",
    "start": "48539",
    "end": "56940"
  },
  {
    "text": "today computer vision today as it stands is deep learning majority of the",
    "start": "56940",
    "end": "66180"
  },
  {
    "text": "successes in how we interpret form representations understand images and",
    "start": "66180",
    "end": "71729"
  },
  {
    "text": "videos utilize to a significant degree neural networks the very ideas we've",
    "start": "71729",
    "end": "78060"
  },
  {
    "text": "been talking about that applies for supervised unsupervised and reinforcement learning and for the",
    "start": "78060",
    "end": "86670"
  },
  {
    "text": "supervised case is just the focus of today the process is the same the data",
    "start": "86670",
    "end": "93810"
  },
  {
    "text": "is essential there's annotated data where the human provides the labels that serves as the ground truth in the",
    "start": "93810",
    "end": "100020"
  },
  {
    "text": "training process then the neural network ghost's through that data learning to",
    "start": "100020",
    "end": "107970"
  },
  {
    "text": "map from the raw sensory input to the ground truth labels and then generalize",
    "start": "107970",
    "end": "113909"
  },
  {
    "text": "or the testing data set and the kind of raw sensors were dealing with their",
    "start": "113909",
    "end": "119490"
  },
  {
    "text": "numbers I'll say this again and again that for human vision for us here would",
    "start": "119490",
    "end": "126090"
  },
  {
    "text": "take for granted this particular aspect of our ability is to take in raw sensory information through our eyes and",
    "start": "126090",
    "end": "132390"
  },
  {
    "text": "interpret but it's just numbers that's something whether you're an expert computer vision",
    "start": "132390",
    "end": "138490"
  },
  {
    "text": "person or new to the field you have to always go back to meditate on is what",
    "start": "138490",
    "end": "144670"
  },
  {
    "text": "kind of things the Machine is given what what what is the data that is tasked to",
    "start": "144670",
    "end": "151120"
  },
  {
    "text": "work with in order to perform the tasks you're asking it to do perhaps the data is given is highly",
    "start": "151120",
    "end": "158820"
  },
  {
    "text": "insufficient to do what you want it to do that's the question I'll come up again and again our images enough to",
    "start": "158820",
    "end": "166390"
  },
  {
    "text": "understand the world around you and given these numbers the set of numbers",
    "start": "166390",
    "end": "174400"
  },
  {
    "text": "sometimes with one channel sometimes with three RGB where every single pixel have three different colors the task is",
    "start": "174400",
    "end": "182350"
  },
  {
    "text": "to classify or regress produce a",
    "start": "182350",
    "end": "187870"
  },
  {
    "text": "continuous variable or one of a set of class labels as before we must be",
    "start": "187870",
    "end": "197170"
  },
  {
    "text": "careful about our intuition of what is hard and what is easy in computer vision",
    "start": "197170",
    "end": "205200"
  },
  {
    "text": "let's take a step back to the inspiration for neural networks our own",
    "start": "207360",
    "end": "214840"
  },
  {
    "text": "biological neural networks because the human vision system and the computer",
    "start": "214840",
    "end": "220510"
  },
  {
    "text": "vision system is a little bit more similar in these regards this",
    "start": "220510",
    "end": "233500"
  },
  {
    "text": "and visual cortex is in layers and as information passes from the eyes to the",
    "start": "233500",
    "end": "239910"
  },
  {
    "text": "to the parts of the brain that makes sense of the raw sensor information higher and higher order representations",
    "start": "239910",
    "end": "247090"
  },
  {
    "text": "have formed this is the inspiration the idea behind using deep neural networks",
    "start": "247090",
    "end": "253209"
  },
  {
    "text": "for images higher and higher order representations of form through the layers there early layers taking in the",
    "start": "253209",
    "end": "262870"
  },
  {
    "text": "very raw and sensory information then extracting edges connecting those edges",
    "start": "262870",
    "end": "268780"
  },
  {
    "text": "forming those edges to form more complex features and finally into the higher-order semantic meaning that we",
    "start": "268780",
    "end": "275169"
  },
  {
    "text": "hope to get from these images in computer vision deep learning is hard",
    "start": "275169",
    "end": "281220"
  },
  {
    "text": "I'll say this again the illumination variability is the biggest challenge or at least one of the",
    "start": "281220",
    "end": "287919"
  },
  {
    "text": "one of the biggest challenges in driving for visible light cameras pose",
    "start": "287919",
    "end": "295240"
  },
  {
    "text": "variability the objects as I'll also discuss about some of the advances geoff",
    "start": "295240",
    "end": "301870"
  },
  {
    "text": "hinton and the capsule networks the idea with the neural networks as they're",
    "start": "301870",
    "end": "307419"
  },
  {
    "text": "currently useful computer vision are not good with representing variable pose",
    "start": "307419",
    "end": "313260"
  },
  {
    "text": "these objects in images and this 2d plane of color and texture look very",
    "start": "313260",
    "end": "320530"
  },
  {
    "text": "different numerically when the object is rotated and the object is mangled and",
    "start": "320530",
    "end": "327640"
  },
  {
    "text": "shaped in different ways the deformable will truncated cat intraclass variability the for the classification",
    "start": "327640",
    "end": "336280"
  },
  {
    "text": "task which would be an example today throughout to introduce some of the networks over the past decade that have",
    "start": "336280",
    "end": "343270"
  },
  {
    "text": "received success in some of the intuition and insight that made those networks work classification there is a",
    "start": "343270",
    "end": "350260"
  },
  {
    "text": "lot of variability inside the classes and very little variability between the classes all of these are cats on top all",
    "start": "350260",
    "end": "359080"
  },
  {
    "text": "of those are dogs are bottom they look very different and the other I would say",
    "start": "359080",
    "end": "364090"
  },
  {
    "text": "the second biggest problem in driving perception visible light camera perceptions occlusion when part of the object is",
    "start": "364090",
    "end": "371080"
  },
  {
    "text": "occluded due to the three-dimensional nature of our world some objects in",
    "start": "371080",
    "end": "378250"
  },
  {
    "text": "front of others and they occlude the background object and yet we're still",
    "start": "378250",
    "end": "384760"
  },
  {
    "text": "tasked with identifying the object when only part of it is visible and sometimes that part told you there's cats is very",
    "start": "384760",
    "end": "393550"
  },
  {
    "text": "hardly visible here we're tasked with classifying a cat with just an ears visible just the leg and in",
    "start": "393550",
    "end": "405130"
  },
  {
    "text": "the philosophical level as we'll talk about the motivation for our competition here here's a cat dressed as a monkey",
    "start": "405130",
    "end": "413410"
  },
  {
    "text": "eating a banana on a philosophical level most of us understand what's going on in",
    "start": "413410",
    "end": "422440"
  },
  {
    "text": "the scene in fact a neural network it's to today successfully classify this",
    "start": "422440",
    "end": "433169"
  },
  {
    "text": "image this video as a cat but the",
    "start": "433260",
    "end": "438840"
  },
  {
    "text": "context the humour of the situation and in fact you could argue it's a monkey is",
    "start": "438840",
    "end": "445530"
  },
  {
    "text": "missing and what else is missing is the dynamic information the temporal",
    "start": "445530",
    "end": "451330"
  },
  {
    "text": "dynamics of the scene that's what's missing in a lot of the perception work",
    "start": "451330",
    "end": "457630"
  },
  {
    "text": "that has been done to date in the autonomous vehicle space in terms of",
    "start": "457630",
    "end": "463210"
  },
  {
    "text": "visible light cameras and we're looking to expand on that that's what psyche fuse is all about",
    "start": "463210",
    "end": "469680"
  },
  {
    "text": "image classification pipeline there's a bin with different categories inside",
    "start": "469680",
    "end": "474880"
  },
  {
    "text": "each class cat dog mug hat those bins there's a lot of examples of each and",
    "start": "474880",
    "end": "481510"
  },
  {
    "text": "your task with when a new example comes along you never seen before to put that image in a bin it's the same as the",
    "start": "481510",
    "end": "489460"
  },
  {
    "text": "machine learning tasks before and everything relies on the data that's",
    "start": "489460",
    "end": "495160"
  },
  {
    "text": "been ground truth that been labeled by human beings amnesty is a toy data set of handwritten",
    "start": "495160",
    "end": "502610"
  },
  {
    "text": "digits often used as examples and Koko safar imagenet places and a lot of other",
    "start": "502610",
    "end": "509150"
  },
  {
    "text": "incredible datasets rich data sets of a hundred thousands millions of images out",
    "start": "509150",
    "end": "514400"
  },
  {
    "text": "there represent scenes people's faces and different objects those are all",
    "start": "514400",
    "end": "520510"
  },
  {
    "text": "ground truth data for testing algorithms and for competing architectures to be",
    "start": "520510",
    "end": "527510"
  },
  {
    "text": "evaluated against each other see far ten one of the simplest almost toy datasets",
    "start": "527510",
    "end": "534080"
  },
  {
    "text": "of tiny icons with ten categories of airplane automobile bird cat deer dog",
    "start": "534080",
    "end": "539600"
  },
  {
    "text": "for our course ship and truck is commonly used to explore some of the basic convolution neural networks we'll",
    "start": "539600",
    "end": "545540"
  },
  {
    "text": "discuss so let's come up with a very trivial classifier to explain the concept of how we could go about it in",
    "start": "545540",
    "end": "552620"
  },
  {
    "text": "fact this is maybe if you start to think about how to classify an image if you don't know any of these techniques this",
    "start": "552620",
    "end": "559310"
  },
  {
    "text": "is perhaps the approach you would take is you would subtract images so in order to know that an image of a cat is",
    "start": "559310",
    "end": "566300"
  },
  {
    "text": "different than image of a dog if to compare them when given those two images what what's the what's the way you",
    "start": "566300",
    "end": "572300"
  },
  {
    "text": "compare them one way you could do it is you just subtract it and then sum all",
    "start": "572300",
    "end": "577820"
  },
  {
    "text": "the pixel wise differences in the image just subtract the intensity of the image pixel by pixel sum it up if that intent",
    "start": "577820",
    "end": "586460"
  },
  {
    "text": "if that difference is really high that means the images are very different using that metric we can look at C for",
    "start": "586460",
    "end": "593210"
  },
  {
    "text": "10 and use it as a classifier saying based on this difference function I'm",
    "start": "593210",
    "end": "600170"
  },
  {
    "text": "going to find one of the 10 bins for a new image that that is that has the",
    "start": "600170",
    "end": "607880"
  },
  {
    "text": "lowest difference find an image in this data set that is most like the image I",
    "start": "607880",
    "end": "614570"
  },
  {
    "text": "have and put it in the same bin as that images in so there's 10 classes if we",
    "start": "614570",
    "end": "621740"
  },
  {
    "text": "just flip a coin the accuracy of our classifier will be 10% using our image",
    "start": "621740",
    "end": "627350"
  },
  {
    "text": "difference classifier we can actually do pretty good much better than random much better than 10%",
    "start": "627350",
    "end": "632970"
  },
  {
    "text": "we can do 35 38 percent accuracy that's a classifier we have our first",
    "start": "632970",
    "end": "640400"
  },
  {
    "text": "classifier K nearest neighbors let's",
    "start": "640400",
    "end": "646710"
  },
  {
    "text": "take our classifier to a whole new level instead of comparing it to just fight",
    "start": "646710",
    "end": "652230"
  },
  {
    "text": "trying to find one image that's the closest in our data set we tried to find K closest and say what is what class do",
    "start": "652230",
    "end": "661230"
  },
  {
    "text": "the majority of them belong to and we take that k and increase it for 1 to 2 to 3 to 4 to 5 and see how that changes",
    "start": "661230",
    "end": "669570"
  },
  {
    "text": "the problem with seven years neighbors which is the optimal under this approach",
    "start": "669570",
    "end": "676200"
  },
  {
    "text": "for CFR 10 we achieve 30% accuracy",
    "start": "676200",
    "end": "682640"
  },
  {
    "text": "human level is 95% accuracy and with",
    "start": "682640",
    "end": "688410"
  },
  {
    "text": "convolutional neural networks will get very close to 100% that's where you'll",
    "start": "688410",
    "end": "698490"
  },
  {
    "text": "networks shine this very task of bending images it all starts at this basic",
    "start": "698490",
    "end": "704490"
  },
  {
    "text": "computational unit signal in each of the signals are weighed summed bias added",
    "start": "704490",
    "end": "712890"
  },
  {
    "text": "and put an input into a nonlinear activation function that produces an",
    "start": "712890",
    "end": "719160"
  },
  {
    "text": "output the nonlinear activation function is key all of these put together and",
    "start": "719160",
    "end": "726830"
  },
  {
    "text": "more and more hidden layers form a deep neural network and that deep neural",
    "start": "726830",
    "end": "733410"
  },
  {
    "text": "network is trained as we've discussed by taking a forward pass and examples have",
    "start": "733410",
    "end": "739320"
  },
  {
    "text": "garage with labels seeing how close those labels are to the real ground truth and then punishing the weights",
    "start": "739320",
    "end": "746400"
  },
  {
    "text": "that resulted in the incorrect decisions and rewarding the weights that resulted",
    "start": "746400",
    "end": "751440"
  },
  {
    "text": "in correct decisions for the case of 10 examples the output of the network is",
    "start": "751440",
    "end": "759960"
  },
  {
    "text": "different values the input being handwritten digits from 0 to 9 for 10 of",
    "start": "759960",
    "end": "768330"
  },
  {
    "text": "those and we wanted our network to classify what is in this image of a",
    "start": "768330",
    "end": "774990"
  },
  {
    "text": "handwritten digit is it 1 is 0 1 2 3 through 9 the way it's often done is",
    "start": "774990",
    "end": "782460"
  },
  {
    "text": "there's ten outputs of the network and each of the neurons on the output is",
    "start": "782460",
    "end": "791060"
  },
  {
    "text": "responsible for getting really excited when it's number is called and everybody",
    "start": "791060",
    "end": "797850"
  },
  {
    "text": "else is supposed to be not excited therefore the number of classes is the",
    "start": "797850",
    "end": "804300"
  },
  {
    "text": "number of outputs that's how it's commonly done and you assign a class to",
    "start": "804300",
    "end": "810120"
  },
  {
    "text": "the input image based on the highest the neuron which produces the highest output",
    "start": "810120",
    "end": "816020"
  },
  {
    "text": "but that's for a fully connected network that we've discussed on Monday there is",
    "start": "816020",
    "end": "822540"
  },
  {
    "text": "in deep learning a lot of tricks that make things work that make training much",
    "start": "822540",
    "end": "828300"
  },
  {
    "text": "more efficient on large class problems where there's a lot of classes on large",
    "start": "828300",
    "end": "835410"
  },
  {
    "text": "data sets when the representation that the neural network is tasked with learning is extremely complex and that's",
    "start": "835410",
    "end": "841800"
  },
  {
    "text": "where convolutional neural neural networks step in the trick they use a spatial invariance they use the idea",
    "start": "841800",
    "end": "848880"
  },
  {
    "text": "that a cat in the top left corner of an image is the same as a cat in the bottom",
    "start": "848880",
    "end": "855480"
  },
  {
    "text": "right corner of an image so we can learn the same features across the image",
    "start": "855480",
    "end": "862010"
  },
  {
    "text": "that's where the convolution operation steps in instead of the fully connected",
    "start": "862010",
    "end": "868380"
  },
  {
    "text": "networks here there's a third dimension of depth so the blocks in this neural",
    "start": "868380",
    "end": "874950"
  },
  {
    "text": "network as input take 3d volumes and as output produced 3d volumes",
    "start": "874950",
    "end": "882890"
  },
  {
    "text": "a slice of the image a window and slide it across applying the same exact",
    "start": "887130",
    "end": "894150"
  },
  {
    "text": "weights and we'll go through an example the same exact weights as in the fully connected network on the edges that are",
    "start": "894150",
    "end": "901200"
  },
  {
    "text": "used to map the input to the output here are used to map this slice of an image",
    "start": "901200",
    "end": "908280"
  },
  {
    "text": "this window of an image to the output and you can make several many of such",
    "start": "908280",
    "end": "915980"
  },
  {
    "text": "convolutional filters many layers many different options of what kind of",
    "start": "915980",
    "end": "922620"
  },
  {
    "text": "features you look for in an image what kind of window you slide across in order to extract all kinds of things all",
    "start": "922620",
    "end": "930210"
  },
  {
    "text": "kinds of edges all kind of higher-order patterns in the images the very",
    "start": "930210",
    "end": "936870"
  },
  {
    "text": "important thing is the parameters on each of these filters the subset of the image these windows are shared if the",
    "start": "936870",
    "end": "945120"
  },
  {
    "text": "feature that defines a cat is useful in the top left corner it's useful in the top right corner it's useful in every",
    "start": "945120",
    "end": "952320"
  },
  {
    "text": "aspect of the image this is the trick that makes convolutional neural networks save a lot of a lot of parameters reduce",
    "start": "952320",
    "end": "960720"
  },
  {
    "text": "parameter significantly it's the reuse the spatial sharing of features across",
    "start": "960720",
    "end": "967050"
  },
  {
    "text": "the space of the image the depth of",
    "start": "967050",
    "end": "973770"
  },
  {
    "text": "these 3d volumes is the number of filters the stride is the skip of the",
    "start": "973770",
    "end": "980280"
  },
  {
    "text": "filter the step size how many pixels you skip when you apply the filter to the",
    "start": "980280",
    "end": "986550"
  },
  {
    "text": "input and the padding is",
    "start": "986550",
    "end": "991680"
  },
  {
    "text": "they're padding the zero padding on the outside of the input to a convolutional",
    "start": "991680",
    "end": "996720"
  },
  {
    "text": "layer let's go through an example so on",
    "start": "996720",
    "end": "1001790"
  },
  {
    "text": "the left here and the slides are now available online you can follow them along and I'll step through this example",
    "start": "1001790",
    "end": "1008990"
  },
  {
    "text": "on the left here is a input volume of three channels the left column is the",
    "start": "1008990",
    "end": "1016249"
  },
  {
    "text": "input the three block the three squares there are the three channels and there's",
    "start": "1016249",
    "end": "1022399"
  },
  {
    "text": "numbers inside those channels and then",
    "start": "1022399",
    "end": "1027890"
  },
  {
    "text": "we have a filter in red two of them two",
    "start": "1027890",
    "end": "1034130"
  },
  {
    "text": "channels of filters with a bias and we those filters are three by three each",
    "start": "1034130",
    "end": "1040339"
  },
  {
    "text": "one of them is size three by three and what we do is we take those three by",
    "start": "1040339",
    "end": "1046938"
  },
  {
    "text": "three filters that are to be learned these are our variables our weights that",
    "start": "1046939",
    "end": "1052309"
  },
  {
    "text": "we have to learn and then we slide it across an image to produce the output on",
    "start": "1052309",
    "end": "1058220"
  },
  {
    "text": "the right the green so by applying the filters in the red there's two of them",
    "start": "1058220",
    "end": "1064279"
  },
  {
    "text": "and within each one there's one for every input channel we go from the left",
    "start": "1064279",
    "end": "1069529"
  },
  {
    "text": "to the right from the input volume on the left to the output volume green on",
    "start": "1069529",
    "end": "1075890"
  },
  {
    "text": "the right and you can look it you can",
    "start": "1075890",
    "end": "1080990"
  },
  {
    "text": "pull up the slides yourself now if you can't see the numbers on the screen but the the operations are performed on the",
    "start": "1080990",
    "end": "1089870"
  },
  {
    "text": "input to produce the single value that's highlighted there in the green and the output and we slide this convolution no",
    "start": "1089870",
    "end": "1098659"
  },
  {
    "text": "filter along the image with a stride in this case of to skipping skipping along",
    "start": "1098659",
    "end": "1109779"
  },
  {
    "text": "they sum to the to the right the two channel output in green that's it",
    "start": "1109779",
    "end": "1119990"
  },
  {
    "text": "the convolutional operation that's what's called the convolutional layer neural networks and the parameters here",
    "start": "1119990",
    "end": "1127190"
  },
  {
    "text": "besides the bias are the read values in the middle that's what we're trying to",
    "start": "1127190",
    "end": "1133070"
  },
  {
    "text": "learn and there's a lot of interesting tricks we'll discuss today on top of",
    "start": "1133070",
    "end": "1138410"
  },
  {
    "text": "those but this is at the core this is the spatially invariant sharing of",
    "start": "1138410",
    "end": "1143420"
  },
  {
    "text": "parameters that make convolutional neural networks able to efficiently",
    "start": "1143420",
    "end": "1149780"
  },
  {
    "text": "learn and find patterns and images to build your intuition a little bit more",
    "start": "1149780",
    "end": "1156280"
  },
  {
    "text": "about convolution here's an input image on the left and on the right the",
    "start": "1156280",
    "end": "1162410"
  },
  {
    "text": "identity filter produces the output you see on the right and then there's different ways you can different kinds",
    "start": "1162410",
    "end": "1169460"
  },
  {
    "text": "of edges you can extract with the activate or the resulting activation map",
    "start": "1169460",
    "end": "1175520"
  },
  {
    "text": "seen on the right so when applying the filters with those edge detection",
    "start": "1175520",
    "end": "1180860"
  },
  {
    "text": "filters to the image on the left you produce in white are the parts that",
    "start": "1180860",
    "end": "1186309"
  },
  {
    "text": "activate the convolution the results of these filters and so you can do any kind",
    "start": "1186309",
    "end": "1196580"
  },
  {
    "text": "of filter that's what we're trying to learn any kind of edge any kind of any",
    "start": "1196580",
    "end": "1202280"
  },
  {
    "text": "kind of pattern you can move along in this window and this way that's shown here you slide along the image and you",
    "start": "1202280",
    "end": "1208790"
  },
  {
    "text": "produce the output you see on the right and depending on how many filters you have in every level you have many of",
    "start": "1208790",
    "end": "1215420"
  },
  {
    "text": "such slices VC on the right the input on the left the output on the right if you",
    "start": "1215420",
    "end": "1221030"
  },
  {
    "text": "have dozens of filters you have dozens of images on the right each with",
    "start": "1221030",
    "end": "1226400"
  },
  {
    "text": "different results that show where each of the individual filter patterns were",
    "start": "1226400",
    "end": "1232970"
  },
  {
    "text": "found and we learned what patterns are useful to look for in order to perform",
    "start": "1232970",
    "end": "1238700"
  },
  {
    "text": "the classification task that's the task for the neural network to learn these",
    "start": "1238700",
    "end": "1243950"
  },
  {
    "text": "filters and the filters have higher and higher order of representation going from the",
    "start": "1243950",
    "end": "1254360"
  },
  {
    "text": "very basic edges to the high semantics meaning that spans entire images and the",
    "start": "1254360",
    "end": "1262850"
  },
  {
    "text": "ability to spend images can be done in several ways but traditionally has been successfully done through max pooling",
    "start": "1262850",
    "end": "1269450"
  },
  {
    "text": "through pooling of taking the output of",
    "start": "1269450",
    "end": "1275380"
  },
  {
    "text": "convolutional operation and reducing the resolution of that byte by condensing",
    "start": "1275380",
    "end": "1283430"
  },
  {
    "text": "that information by for example taking the maximum values the maximum activations therefore reducing the",
    "start": "1283430",
    "end": "1293440"
  },
  {
    "text": "spatial resolution which has detrimental effects as we'll talk about in the scene segmentation but it's beneficial for",
    "start": "1293440",
    "end": "1301160"
  },
  {
    "text": "finding higher order representations and the images that bring images together that bring features together to form an",
    "start": "1301160",
    "end": "1309080"
  },
  {
    "text": "entity that we're trying to identify and classify okay so that forms a",
    "start": "1309080",
    "end": "1316090"
  },
  {
    "text": "convolution Yool network such convolutional layers stacked on top of each other is the only addition to a",
    "start": "1316090",
    "end": "1321950"
  },
  {
    "text": "neural network that makes for a convolutional neural network and then at the end the fully connected layers or",
    "start": "1321950",
    "end": "1328640"
  },
  {
    "text": "any kind of other architectures allow us to apply particular domains",
    "start": "1328640",
    "end": "1335000"
  },
  {
    "start": "1335000",
    "end": "2079000"
  },
  {
    "text": "let's take image net as a case study an",
    "start": "1335000",
    "end": "1340640"
  },
  {
    "text": "image net the data set an image net the",
    "start": "1340640",
    "end": "1345700"
  },
  {
    "text": "challenge the task is classification as I mentioned the first lecture image net is",
    "start": "1345700",
    "end": "1352790"
  },
  {
    "text": "a data set one of the largest in the world of images with 14 million images",
    "start": "1352790",
    "end": "1359140"
  },
  {
    "text": "21,000 categories and a lot of depth to",
    "start": "1359140",
    "end": "1364730"
  },
  {
    "text": "many of the categories as I mentioned 1200 granny smith apples",
    "start": "1364730",
    "end": "1370870"
  },
  {
    "text": "these allow - these allow the newer networks to learn the rich",
    "start": "1372419",
    "end": "1378070"
  },
  {
    "text": "representations in both pose lighting variability and intraclass class variation for the particular things",
    "start": "1378070",
    "end": "1383970"
  },
  {
    "text": "particular classes like granny smith apples so let's look through the various",
    "start": "1383970",
    "end": "1390940"
  },
  {
    "text": "networks let's discuss them let's see the insights it started with Alex net the first",
    "start": "1390940",
    "end": "1396429"
  },
  {
    "text": "really big successful GPU trained neural network on image net that's achieved a",
    "start": "1396429",
    "end": "1401860"
  },
  {
    "text": "significant boost over the previous year and moved on to vgg net Google net ague",
    "start": "1401860",
    "end": "1411039"
  },
  {
    "text": "Lynnette ResNet see you image and as Annette in 2017 again the numbers will",
    "start": "1411039",
    "end": "1422530"
  },
  {
    "text": "show for the accuracy are based on the top five error rate we get five guesses",
    "start": "1422530",
    "end": "1428049"
  },
  {
    "text": "and it's a one or zero if you get guess if one of the five is correct you get a one for that particular guess otherwise",
    "start": "1428049",
    "end": "1435250"
  },
  {
    "text": "it's a zero and human error is five",
    "start": "1435250",
    "end": "1443710"
  },
  {
    "text": "point one when a human tries to achieve the same tries to perform the same task",
    "start": "1443710",
    "end": "1448750"
  },
  {
    "text": "as the machinist task of doing the air is five point one the human annotation is performed on the images based on",
    "start": "1448750",
    "end": "1455679"
  },
  {
    "text": "binary classification Granny Smith apple or not cat or not the actual tasks that",
    "start": "1455679",
    "end": "1462370"
  },
  {
    "text": "the machine has to perform and that the human competing has to perform is given an image is provide one of the many",
    "start": "1462370",
    "end": "1469539"
  },
  {
    "text": "classes under that human errors 5.1% which was surpassed in 2015 by ResNet to",
    "start": "1469539",
    "end": "1478870"
  },
  {
    "text": "achieve four percent error so let's",
    "start": "1478870",
    "end": "1484860"
  },
  {
    "text": "with Alex net I'll zoom in on the later networks they have some interesting insights but Alex net and vgg net both",
    "start": "1484860",
    "end": "1493860"
  },
  {
    "text": "fall at a very similar architecture very uniform throughout its depth vgg net in",
    "start": "1493860",
    "end": "1502860"
  },
  {
    "text": "2014 is convolution convolution pooling",
    "start": "1502860",
    "end": "1508170"
  },
  {
    "text": "convolution pooling convolution pooling and fully connected layers at the end",
    "start": "1508170",
    "end": "1513410"
  },
  {
    "text": "there's a certain kind of beautiful simplicity uniformity to these architectures because you can just make",
    "start": "1513410",
    "end": "1519390"
  },
  {
    "text": "it deeper and deeper and makes it very amenable to implementation in a layer",
    "start": "1519390",
    "end": "1524730"
  },
  {
    "text": "stack kind of way and in any of the deep learning frameworks it's clean and",
    "start": "1524730",
    "end": "1529919"
  },
  {
    "text": "beautiful to understand in the case of eg gina was 16 or 19 layers with 138",
    "start": "1529919",
    "end": "1535350"
  },
  {
    "text": "million parameters not many optimizations and these parameters therefore the number of parameters is",
    "start": "1535350",
    "end": "1540780"
  },
  {
    "text": "much higher than the networks that followed it despite the layers not being that large Google Net introduced the",
    "start": "1540780",
    "end": "1549419"
  },
  {
    "text": "inception module starting to do some interesting things with the small",
    "start": "1549419",
    "end": "1555530"
  },
  {
    "text": "modules within these networks which allow for the training to be more efficient and effective the idea behind",
    "start": "1555530",
    "end": "1564450"
  },
  {
    "text": "the inception module shown here with the previous layer on bottom and the",
    "start": "1564450",
    "end": "1571530"
  },
  {
    "text": "convolutional layer here with the inception module on top produced on top",
    "start": "1571530",
    "end": "1578850"
  },
  {
    "text": "is it used the idea that different size",
    "start": "1578850",
    "end": "1584429"
  },
  {
    "text": "convolutions provide different value for the network smaller convolutions are",
    "start": "1584429",
    "end": "1589980"
  },
  {
    "text": "able to capture or propagate forward features that are very local a high",
    "start": "1589980",
    "end": "1597840"
  },
  {
    "text": "resolution in in in texture larger convolutions are better able to",
    "start": "1597840",
    "end": "1604470"
  },
  {
    "text": "represent and capture and catch highly abstracted features higher-order",
    "start": "1604470",
    "end": "1610020"
  },
  {
    "text": "features so the idea behind the inception module is to say well as",
    "start": "1610020",
    "end": "1615600"
  },
  {
    "text": "opposed to choosing and high in a high pair tuning process or architecture design",
    "start": "1615600",
    "end": "1621219"
  },
  {
    "text": "process choosing which convolution size we want to go with why not do all of",
    "start": "1621219",
    "end": "1626499"
  },
  {
    "text": "them together while several together in the case of the Google net model there's",
    "start": "1626499",
    "end": "1631989"
  },
  {
    "text": "the one by one three by three and five by five convolutions with the old trusty",
    "start": "1631989",
    "end": "1637089"
  },
  {
    "text": "friend of max pooling still left in there as well which has lost favor more",
    "start": "1637089",
    "end": "1643599"
  },
  {
    "text": "and more over time for the image classification task and the results is there's fewer parameters are required if",
    "start": "1643599",
    "end": "1651279"
  },
  {
    "text": "you pick the placing of these inception modules correctly the number of",
    "start": "1651279",
    "end": "1657909"
  },
  {
    "text": "parameters required to achieve a higher performance is much lower res net one of",
    "start": "1657909",
    "end": "1668259"
  },
  {
    "text": "the most popular still to date",
    "start": "1668259",
    "end": "1671940"
  },
  {
    "text": "architectures that we'll discuss in scene segmentation as well came up and",
    "start": "1673559",
    "end": "1681429"
  },
  {
    "text": "use the idea of a residual block the initial inspiring observation which",
    "start": "1681429",
    "end": "1688509"
  },
  {
    "text": "doesn't necessarily hold true as it turns out but that network depth",
    "start": "1688509",
    "end": "1694109"
  },
  {
    "text": "increases representation power so these residual blocks allow you to have much",
    "start": "1694109",
    "end": "1700509"
  },
  {
    "text": "deeper networks and I'll explain why in a second here but the thought was they",
    "start": "1700509",
    "end": "1707499"
  },
  {
    "text": "work so well because the network's so much deeper the key thing that makes these blocks so effective is the same",
    "start": "1707499",
    "end": "1715259"
  },
  {
    "text": "idea that's that reminiscent of recurrent neural networks that I hope",
    "start": "1715259",
    "end": "1720729"
  },
  {
    "text": "would get a chance to talk about the training of them is much easier they",
    "start": "1720729",
    "end": "1728169"
  },
  {
    "text": "take a simple block repeated over and over and they pass the input along",
    "start": "1728169",
    "end": "1734379"
  },
  {
    "text": "without transformation along with the ability to transform it to learn to",
    "start": "1734379",
    "end": "1740649"
  },
  {
    "text": "learn the filters learn the weights so you're allowed to you're allow every",
    "start": "1740649",
    "end": "1748179"
  },
  {
    "text": "layer to not only take on the processing of previous layers but to take in the",
    "start": "1748179",
    "end": "1754990"
  },
  {
    "text": "wrong transform data and learn something new the ability to learn something new",
    "start": "1754990",
    "end": "1761350"
  },
  {
    "text": "allows you to have much deeper networks and the simplicity of this block allows",
    "start": "1761350",
    "end": "1767470"
  },
  {
    "text": "for more effective training the state of",
    "start": "1767470",
    "end": "1774129"
  },
  {
    "text": "the art in 2017 the winner is squeezed and excitation networks that unlike the",
    "start": "1774129",
    "end": "1780909"
  },
  {
    "text": "previous year will see you image which simply took ensemble methods and combined a lot of successful approaches",
    "start": "1780909",
    "end": "1786999"
  },
  {
    "text": "to take a marginal improvement se net got a significant improvement at least",
    "start": "1786999",
    "end": "1795039"
  },
  {
    "text": "in percentages I think there's a 25% reduction in error from 4 percent to 3",
    "start": "1795039",
    "end": "1802480"
  },
  {
    "text": "percent something like that by using a very simple idea that I think is",
    "start": "1802480",
    "end": "1809200"
  },
  {
    "text": "important to mention a simple insight it added a parameter to each channel and",
    "start": "1809200",
    "end": "1816190"
  },
  {
    "text": "the convolutional layer in the convolutional block so the network can",
    "start": "1816190",
    "end": "1822490"
  },
  {
    "text": "now adjust the weighting on each channel based for for each feature map based on",
    "start": "1822490",
    "end": "1829450"
  },
  {
    "text": "the content based on the input to the network this is kind of a take away to think about about any of the networks",
    "start": "1829450",
    "end": "1836710"
  },
  {
    "text": "who talk about any of the architectures is a lot of times your recurrent neural",
    "start": "1836710",
    "end": "1842590"
  },
  {
    "text": "networks and convolutional neural networks have tricks that significantly",
    "start": "1842590",
    "end": "1847629"
  },
  {
    "text": "reduce the number of parameters the bulk the sort of low-hanging fruit they use",
    "start": "1847629",
    "end": "1853240"
  },
  {
    "text": "spatial invariants a temporal invariants to reduce the number of parameters to represent the input data but they also",
    "start": "1853240",
    "end": "1860889"
  },
  {
    "text": "leave certain things not parameterize they don't allow the network to learn it allow in this case the network to learn",
    "start": "1860889",
    "end": "1867940"
  },
  {
    "text": "the weighting on each of the individual channels so each of the individual filters is something that you learn as",
    "start": "1867940",
    "end": "1874539"
  },
  {
    "text": "along with the filters takes it makes a huge boost the cool thing about this is it's",
    "start": "1874539",
    "end": "1880399"
  },
  {
    "text": "applicable to any architecture this kind of block that's kind of what the the squeeze and excitation block is",
    "start": "1880399",
    "end": "1886779"
  },
  {
    "text": "applicable to any architecture and because obviously it it just simply",
    "start": "1886779",
    "end": "1895399"
  },
  {
    "text": "permit Rises the ability to choose which filter you go with based on the content it's a subtle but crucial thing I think",
    "start": "1895399",
    "end": "1902659"
  },
  {
    "text": "it's pretty cool and for future research it inspires to think about what else can",
    "start": "1902659",
    "end": "1908509"
  },
  {
    "text": "be parameterize in your own networks what else can be controlled as part of the learning process including hiring",
    "start": "1908509",
    "end": "1914539"
  },
  {
    "text": "higher-order hyper parameters which which aspects of the training and the",
    "start": "1914539",
    "end": "1920329"
  },
  {
    "text": "architecture of the network can be part of the learning this is what this network inspires another network has",
    "start": "1920329",
    "end": "1934309"
  },
  {
    "text": "been in development since the 90s ideas with geoff hinton but really received",
    "start": "1934309",
    "end": "1939919"
  },
  {
    "text": "has been published on received significant attention 2017 that i won't go into detail here we are going to",
    "start": "1939919",
    "end": "1948679"
  },
  {
    "text": "release an online-only video about capsule networks it's a",
    "start": "1948679",
    "end": "1955489"
  },
  {
    "text": "little bit too technical but they inspire a very important point that we",
    "start": "1955489",
    "end": "1961759"
  },
  {
    "text": "should always think about with deep learning whenever it's successful is to think about what as I mentioned with the",
    "start": "1961759",
    "end": "1968899"
  },
  {
    "text": "cat eating a banana on a philosophical and the mathematical level you have to",
    "start": "1968899",
    "end": "1974239"
  },
  {
    "text": "consider what assumptions these networks make and what through those assumptions",
    "start": "1974239",
    "end": "1980929"
  },
  {
    "text": "they throw away so neural networks due to the spatial with convolutional neural networks due to their spatial invariants",
    "start": "1980929",
    "end": "1988239"
  },
  {
    "text": "throw away information about the relationship between the the hierarchies",
    "start": "1988239",
    "end": "1995629"
  },
  {
    "text": "between the simple and the complex objects so the face on the left and the face on the right looks the same to",
    "start": "1995629",
    "end": "2001959"
  },
  {
    "text": "accomplish a neural network the presence of eyes and nose and mouth is the",
    "start": "2001959",
    "end": "2007929"
  },
  {
    "text": "central aspect of what makes classification tasks work for",
    "start": "2007929",
    "end": "2013760"
  },
  {
    "text": "convolution Network where it will fire and say this is definitely a face but",
    "start": "2013760",
    "end": "2019370"
  },
  {
    "text": "the spatial relationship is lost is ignored which means there's a lot of",
    "start": "2019370",
    "end": "2025820"
  },
  {
    "text": "implications to this but for things like pose variation that information is lost",
    "start": "2025820",
    "end": "2033190"
  },
  {
    "text": "we're throwing away that away completely and hoping that the pooling operation",
    "start": "2033190",
    "end": "2039020"
  },
  {
    "text": "that's performing these networks is able to sort of mesh everything together to",
    "start": "2039020",
    "end": "2044690"
  },
  {
    "text": "come up with the features that are firing of the different parts of the face that then come up with the total",
    "start": "2044690",
    "end": "2050060"
  },
  {
    "text": "classification that it's a face without representing really the relationship between these features at the low level",
    "start": "2050060",
    "end": "2056300"
  },
  {
    "text": "and and the high level at the low level of the hierarchy at the simple and the complex level this is a super exciting",
    "start": "2056300",
    "end": "2064879"
  },
  {
    "text": "field now that's hopefully will spark developments of how we design your own networks that are able to learn this the",
    "start": "2064880",
    "end": "2072760"
  },
  {
    "text": "rotational the orientation invariance as well ok so as I mentioned you take these",
    "start": "2072760",
    "end": "2084350"
  },
  {
    "start": "2079000",
    "end": "2675000"
  },
  {
    "text": "combos in your networks chop off the final layer in order to apply to a",
    "start": "2084350",
    "end": "2089419"
  },
  {
    "text": "particular domain and that is what we'll do with fully convolutional neural networks the ones that we task to",
    "start": "2089419",
    "end": "2095810"
  },
  {
    "text": "segment the image at a pixel level as a",
    "start": "2095810",
    "end": "2101200"
  },
  {
    "text": "reminder these networks through the convolutional process are really",
    "start": "2101200",
    "end": "2107780"
  },
  {
    "text": "producing a heat map different parts of the network are getting excited based on",
    "start": "2107780",
    "end": "2113540"
  },
  {
    "text": "the different aspects of the image and so it can be used to do the localization of detecting not just classifying the",
    "start": "2113540",
    "end": "2119780"
  },
  {
    "text": "image but localizing the object and they could do so at a pixel level so the",
    "start": "2119780",
    "end": "2127070"
  },
  {
    "text": "convolutional layers are doing the encoding process they're taking the rich",
    "start": "2127070",
    "end": "2132830"
  },
  {
    "text": "raw sensory information in the image and encoding them into an interpretable set",
    "start": "2132830",
    "end": "2139010"
  },
  {
    "text": "of features representation that can then be used for classification but we can",
    "start": "2139010",
    "end": "2144260"
  },
  {
    "text": "also then use it kotor up sample that information and produce a map like this fully",
    "start": "2144260",
    "end": "2151440"
  },
  {
    "text": "convolutional neural network segmentation semantic scene segmentation image segmentation the goal is to as",
    "start": "2151440",
    "end": "2158190"
  },
  {
    "text": "opposed to classify the entire image you classify every single pixel its pixel level segmentation you color every",
    "start": "2158190",
    "end": "2165270"
  },
  {
    "text": "single pixel with what that pixel what object that pixel belongs to in this 2d",
    "start": "2165270",
    "end": "2170340"
  },
  {
    "text": "space of the image the 2d projection the in the image of a 3-dimensional world so",
    "start": "2170340",
    "end": "2179340"
  },
  {
    "text": "the thing is there's been a lot of advancement in the last three years but",
    "start": "2179340",
    "end": "2187170"
  },
  {
    "text": "it's still an incredibly difficult problem if you if you think if you think about the amount of data that's used for",
    "start": "2187170",
    "end": "2196710"
  },
  {
    "text": "training and the task of pixel level of megapixels here of millions of pixels",
    "start": "2196710",
    "end": "2203790"
  },
  {
    "text": "that are tasked with having a scientist single label it's an extremely difficult problem why is this interesting",
    "start": "2203790",
    "end": "2212580"
  },
  {
    "text": "important problem to try to solve as opposed to bounding boxes around cats well it's whenever precise boundaries of",
    "start": "2212580",
    "end": "2220920"
  },
  {
    "text": "objects are important certainly medical applications when looking at imaging and detecting in particular for example",
    "start": "2220920",
    "end": "2227970"
  },
  {
    "text": "detecting tumors in the in in medical",
    "start": "2227970",
    "end": "2233040"
  },
  {
    "text": "imaging of different different organs and in driving in robotics when objects",
    "start": "2233040",
    "end": "2242100"
  },
  {
    "text": "are involved it's a done scene of all those vehicles pedestrians cyclists we need to be able to not just have a loose",
    "start": "2242100",
    "end": "2249300"
  },
  {
    "text": "estimate of where objects are we need to be able to have the exact boundaries and then potentially through data fusion",
    "start": "2249300",
    "end": "2257250"
  },
  {
    "text": "fusing sensors together fusing this rich textural information about pedestrians cyclists and vehicles",
    "start": "2257250",
    "end": "2264180"
  },
  {
    "text": "to lidar data that's providing us the three-dimensional map of the world or have both the semantic meaning of the",
    "start": "2264180",
    "end": "2270750"
  },
  {
    "text": "different objects and their exact three-dimensional location",
    "start": "2270750",
    "end": "2275450"
  },
  {
    "text": "a lot of this work successfully a lot of the work in the semantic segmentation",
    "start": "2278890",
    "end": "2285350"
  },
  {
    "text": "started with fully convolutional networks for semantic segmentation paper FCN that's where the name of FCN came",
    "start": "2285350",
    "end": "2292670"
  },
  {
    "text": "from in november 2014 now go through a few papers here to give you some intuition where the field is",
    "start": "2292670",
    "end": "2299090"
  },
  {
    "text": "gone and how that takes us to seg fuse the segmentation competition so FCM",
    "start": "2299090",
    "end": "2307690"
  },
  {
    "text": "repurposed the image net pre-trained nets the nets that were trained to classify what's in an image the entire",
    "start": "2307690",
    "end": "2314090"
  },
  {
    "text": "image and chopped off the fully connected layers and then added decoder",
    "start": "2314090",
    "end": "2321440"
  },
  {
    "text": "parts that that up sample there the image to produce a heat map here shown",
    "start": "2321440",
    "end": "2329420"
  },
  {
    "text": "with a tabby cat a heat map of where the cat is in the image it's a much slower",
    "start": "2329420",
    "end": "2335630"
  },
  {
    "text": "much coarser resolution than the input image 1/8 at best",
    "start": "2335630",
    "end": "2342520"
  },
  {
    "text": "skip connections to improve coarseness of up sampling there's a few tricks if",
    "start": "2342520",
    "end": "2350810"
  },
  {
    "text": "you do the most naive approach the up sampling is going to be extremely coarse because that's the whole point of the",
    "start": "2350810",
    "end": "2356660"
  },
  {
    "text": "neural network the encoding part is you throw away all the useless data the",
    "start": "2356660",
    "end": "2362930"
  },
  {
    "text": "YouTube the most essential aspects that represent that image so you're throwing away a lot of information that's",
    "start": "2362930",
    "end": "2368390"
  },
  {
    "text": "necessary to then form a high resolution image so there's a few tricks where you",
    "start": "2368390",
    "end": "2375500"
  },
  {
    "text": "skip a few of the final pooling operations to go in similar way and this",
    "start": "2375500",
    "end": "2382070"
  },
  {
    "text": "is a residual block to go to go to the output produce higher and higher resolution heat map at the end segment",
    "start": "2382070",
    "end": "2391370"
  },
  {
    "text": "in 2015 applied this to the driving context and really taking it to kitty",
    "start": "2391370",
    "end": "2398180"
  },
  {
    "text": "data set and have have shown a lot of interesting results and really explored",
    "start": "2398180",
    "end": "2403760"
  },
  {
    "text": "the encoder decoder or formulation of the problem",
    "start": "2403760",
    "end": "2408430"
  },
  {
    "text": "really solidifying this the place of the encoder/decoder framework for the",
    "start": "2409000",
    "end": "2414200"
  },
  {
    "text": "segmentation task dilated convolution I'm taking you through a few components",
    "start": "2414200",
    "end": "2420680"
  },
  {
    "text": "which are critical here to the state of the art dilated convolutions so the",
    "start": "2420680",
    "end": "2427190"
  },
  {
    "text": "convolution operation as the pooling operation reduces resolution",
    "start": "2427190",
    "end": "2433850"
  },
  {
    "text": "significantly and dilated convolution has a certain kind of gritting as",
    "start": "2433850",
    "end": "2440540"
  },
  {
    "text": "visualized there that maintains the local high resolution textures while",
    "start": "2440540",
    "end": "2450350"
  },
  {
    "text": "still capturing the spatial window necessary",
    "start": "2450350",
    "end": "2455920"
  },
  {
    "text": "it's called dilated convolutional layer and that's in a 2015 paper proved to be",
    "start": "2455920",
    "end": "2464330"
  },
  {
    "text": "much better at up sampling a high resolution image deep lab with a be v1",
    "start": "2464330",
    "end": "2475220"
  },
  {
    "text": "v2 Navi 3 added conditional random fields which is the final piece of the",
    "start": "2475220",
    "end": "2483040"
  },
  {
    "text": "of the state-of-the-art puzzle here a lot of the successful networks today",
    "start": "2483040",
    "end": "2488140"
  },
  {
    "text": "that do segmentation not all do post",
    "start": "2488140",
    "end": "2493460"
  },
  {
    "text": "process using CRFs conditional random fields and what they do is they smooth",
    "start": "2493460",
    "end": "2499640"
  },
  {
    "text": "the segmentation the up sample segmentation that results from the FCN by looking at the underlying image",
    "start": "2499640",
    "end": "2506300"
  },
  {
    "text": "intensities so that's the key aspects of",
    "start": "2506300",
    "end": "2512300"
  },
  {
    "text": "the successful approaches today you have the encoder decoder framework of a fully accomplished in your network it replaces",
    "start": "2512300",
    "end": "2519260"
  },
  {
    "text": "the fully connected layers with the convolutional layers deconvolution layers and as the years progress from",
    "start": "2519260",
    "end": "2527420"
  },
  {
    "text": "2014 to today as usual than underlying",
    "start": "2527420",
    "end": "2532430"
  },
  {
    "text": "networks from alex net to vgg net and to now ResNet have been one of the big",
    "start": "2532430",
    "end": "2540620"
  },
  {
    "text": "reasons for the improvements of these to be able to perform the segmentation so naturally they mirrored the imagenet",
    "start": "2540620",
    "end": "2547460"
  },
  {
    "text": "challenge performance in adapting these networks so the state-of-the-art uses ResNet or similar networks conditional",
    "start": "2547460",
    "end": "2554930"
  },
  {
    "text": "random fields for smoothing based on the input image intensities and the dilated",
    "start": "2554930",
    "end": "2562480"
  },
  {
    "text": "convolution that maintains the computational cost but increases the",
    "start": "2562480",
    "end": "2567560"
  },
  {
    "text": "resolution of the up sampling throughout the intermediate feature Maps and that",
    "start": "2567560",
    "end": "2574609"
  },
  {
    "text": "takes us to the state of the art that we used to produce the images to produce",
    "start": "2574609",
    "end": "2583670"
  },
  {
    "text": "the images for the competition present that do you see for dance up sampling",
    "start": "2583670",
    "end": "2589400"
  },
  {
    "text": "convolution instead of bilinear up sampling you make the up sampling learn",
    "start": "2589400",
    "end": "2595640"
  },
  {
    "text": "about you learn the upscaling filters that's on the bottom that's really the",
    "start": "2595640",
    "end": "2603109"
  },
  {
    "text": "key part that made it work there should be a theme here sometimes the the",
    "start": "2603109",
    "end": "2608900"
  },
  {
    "text": "biggest addition they can be done this parameter izing one of the aspects of the network they've taken for granted",
    "start": "2608900",
    "end": "2614930"
  },
  {
    "text": "letting the network learn that aspect and the other I'm not sure how important",
    "start": "2614930",
    "end": "2621800"
  },
  {
    "text": "it is to the success but it's a it's a cool little addition is a hybrid dilated convolution as I showed that",
    "start": "2621800",
    "end": "2629210"
  },
  {
    "text": "visualization where the convolution is spread apart a little bit in the input",
    "start": "2629210",
    "end": "2635390"
  },
  {
    "text": "from the input to the output the steps of that dilated convolution filter when",
    "start": "2635390",
    "end": "2640940"
  },
  {
    "text": "they're changed it produces a smoother result because when it's kept the same",
    "start": "2640940",
    "end": "2646390"
  },
  {
    "text": "there certain input pixels get a lot more attention than others so losing",
    "start": "2646390",
    "end": "2652250"
  },
  {
    "text": "that favoritism is what's achieved by using a variable different dilation rate",
    "start": "2652250",
    "end": "2659440"
  },
  {
    "text": "those are the two tricks but really the biggest one is the parameterization of the upscaling filters okay so that's",
    "start": "2659440",
    "end": "2668480"
  },
  {
    "text": "what we're that's what we used to generate that data and that's what we provides you the code with if you're interested in competing in psyche views",
    "start": "2668480",
    "end": "2675740"
  },
  {
    "start": "2675000",
    "end": "3007000"
  },
  {
    "text": "the other aspect here that everything we've talked about from the classification to the segmentation to",
    "start": "2675740",
    "end": "2683270"
  },
  {
    "text": "making sense of images is it there the information about time the temporal",
    "start": "2683270",
    "end": "2689869"
  },
  {
    "text": "dynamics of the scene is thrown away and for the driving context of the robotics",
    "start": "2689869",
    "end": "2696080"
  },
  {
    "text": "contest and what we'd like to do with psyche fuse for the segmentation dynamics scene segmentation context of",
    "start": "2696080",
    "end": "2702650"
  },
  {
    "text": "when you try to interpret what's going on in the scene over time and use that information time is essential thus the",
    "start": "2702650",
    "end": "2712190"
  },
  {
    "text": "movement of pixels is essential through time that that understanding how those",
    "start": "2712190",
    "end": "2718520"
  },
  {
    "text": "objects move in a 3d space through the 2d projection of an image it's",
    "start": "2718520",
    "end": "2725780"
  },
  {
    "text": "fascinating and us there's a lot of set of open problems there so flow is what's",
    "start": "2725780",
    "end": "2732980"
  },
  {
    "text": "very helpful to as a starting point to help us understand how these pixels move",
    "start": "2732980",
    "end": "2739839"
  },
  {
    "text": "flow optical flow dense optical flow is the computation that our best of a best",
    "start": "2739839",
    "end": "2749570"
  },
  {
    "text": "approximation of where each pixel in image one and moved in the in",
    "start": "2749570",
    "end": "2757369"
  },
  {
    "text": "temporarily following image after that there's two images in 30 frames a second",
    "start": "2757369",
    "end": "2763670"
  },
  {
    "text": "there's one image at time zero the other is 33.3 milliseconds later and the",
    "start": "2763670",
    "end": "2769490"
  },
  {
    "text": "idents optical flow is our best estimate of how each pixel in the input image moved to in the output image the optical",
    "start": "2769490",
    "end": "2777770"
  },
  {
    "text": "flow for every pixel produces a direction of where we think that pixel moved and the magnitude of how far moved",
    "start": "2777770",
    "end": "2784820"
  },
  {
    "text": "that allows us to take information that we detected about the first frame and",
    "start": "2784820",
    "end": "2790060"
  },
  {
    "text": "try to propagate it forward this is the competition it's to try to segment an",
    "start": "2790060",
    "end": "2797480"
  },
  {
    "text": "image and propagate that information forward for manual annotation of a",
    "start": "2797480",
    "end": "2806680"
  },
  {
    "text": "image so this kind of coloring book annotation where you color every single pixel in the state-of-the-art dataset",
    "start": "2806680",
    "end": "2813930"
  },
  {
    "text": "for driving cityscapes that it takes 1.5",
    "start": "2813930",
    "end": "2819640"
  },
  {
    "text": "ninth and 1.5 hours 90 minutes to do that coloring that's 90 minutes per",
    "start": "2819640",
    "end": "2824860"
  },
  {
    "text": "image that's extremely long time that's why there doesn't exist today dataset",
    "start": "2824860",
    "end": "2831070"
  },
  {
    "text": "and in this class we're going to create one of segmentation of these images",
    "start": "2831070",
    "end": "2837640"
  },
  {
    "text": "through time through video so long",
    "start": "2837640",
    "end": "2842740"
  },
  {
    "text": "videos where every single frame is fully segmented that's still an open problem",
    "start": "2842740",
    "end": "2848410"
  },
  {
    "text": "that we need to solve flows a piece of that and we also provide you the this",
    "start": "2848410",
    "end": "2857380"
  },
  {
    "text": "computer state-of-the-art flow using flow net 2.0 so flow net 1.0 in May 2015",
    "start": "2857380",
    "end": "2866370"
  },
  {
    "text": "used neural networks to learn the optical flow the dense optical flow and",
    "start": "2866370",
    "end": "2873280"
  },
  {
    "text": "it did so with two kinds of architectures flow net s flowing that simple and flow net core flow net see",
    "start": "2873280",
    "end": "2880800"
  },
  {
    "text": "the simple one is simply taking the two images so what's what's the task here",
    "start": "2880800",
    "end": "2886120"
  },
  {
    "text": "there's two images and you you want to produce from those two images they follow each other in time thirty-three",
    "start": "2886120",
    "end": "2892240"
  },
  {
    "text": "point three milliseconds apart and your task is the output to produce the dense",
    "start": "2892240",
    "end": "2897430"
  },
  {
    "text": "optical flow so for the simple architecture you just stack them together each are RGB so it produces a",
    "start": "2897430",
    "end": "2904510"
  },
  {
    "text": "six channel input to the network there's a lot of convolution and finally it's the the same kind of process as the",
    "start": "2904510",
    "end": "2911230"
  },
  {
    "text": "fully convolution your networks to produce the optical flow then there is flow net correlation architecture where",
    "start": "2911230",
    "end": "2919630"
  },
  {
    "text": "you perform some convolution separately before using a correlation layer to combine the feature Maps both",
    "start": "2919630",
    "end": "2929390"
  },
  {
    "text": "effective in different data sets and different applications so flow net 2.0",
    "start": "2929390",
    "end": "2936530"
  },
  {
    "text": "in December 2016 is one of the",
    "start": "2936530",
    "end": "2941540"
  },
  {
    "text": "state-of-the-art frameworks code bases that we used to generate the data all",
    "start": "2941540",
    "end": "2946550"
  },
  {
    "text": "show combines the flow net Assam flow net C and improves over the initial flow",
    "start": "2946550",
    "end": "2952820"
  },
  {
    "text": "net producing a smoother flow field preserves the fine motion detail along",
    "start": "2952820",
    "end": "2958670"
  },
  {
    "text": "the edges of the objects and it runs extremely efficiently depending on the",
    "start": "2958670",
    "end": "2964280"
  },
  {
    "text": "architecture there's a few variants either eight to a hundred forty frames a",
    "start": "2964280",
    "end": "2969380"
  },
  {
    "text": "second and the process there is essentially one that's common across",
    "start": "2969380",
    "end": "2975560"
  },
  {
    "text": "various applications deep learning is stacking these networks together the",
    "start": "2975560",
    "end": "2980810"
  },
  {
    "text": "very interesting aspect here that we're",
    "start": "2980810",
    "end": "2986000"
  },
  {
    "text": "still exploring and again applicable in all of deep learning in this case it",
    "start": "2986000",
    "end": "2991160"
  },
  {
    "text": "seemed that there was a strong effect in taking sparse small multiple data set",
    "start": "2991160",
    "end": "2997010"
  },
  {
    "text": "and doing the training the order of which those data sets were used for the training process mattered a lot that's",
    "start": "2997010",
    "end": "3004180"
  },
  {
    "text": "very interesting so using flow net 2.0 here's the data",
    "start": "3004180",
    "end": "3011050"
  },
  {
    "start": "3007000",
    "end": "3194000"
  },
  {
    "text": "set we're making available for psych fuse the competition cars that mit.edu",
    "start": "3011050",
    "end": "3016840"
  },
  {
    "text": "slash psych fuse first the original video us driving in high-definition",
    "start": "3016840",
    "end": "3024870"
  },
  {
    "text": "1080p and a 8k 360 video original video",
    "start": "3024870",
    "end": "3032920"
  },
  {
    "text": "driving around Cambridge we're providing the ground truth for a",
    "start": "3032920",
    "end": "3041590"
  },
  {
    "text": "training set for that training set for every single frame 30 frames a second",
    "start": "3041590",
    "end": "3048010"
  },
  {
    "text": "we're providing the segmentation frame to frame to frame segmented on",
    "start": "3048010",
    "end": "3053410"
  },
  {
    "text": "Mechanical Turk we're also providing the output of the network that I mentioned",
    "start": "3053410",
    "end": "3061690"
  },
  {
    "text": "the state of their our segmentation network that's pretty damn close to the ground truth but still not and our task",
    "start": "3061690",
    "end": "3070810"
  },
  {
    "text": "is this is the interesting thing is our task is to take the output of this",
    "start": "3070810",
    "end": "3077500"
  },
  {
    "text": "network well there's two options one is to take the output of this network and",
    "start": "3077500",
    "end": "3083460"
  },
  {
    "text": "use use other networks to help you propagate the information better so what",
    "start": "3083460",
    "end": "3090580"
  },
  {
    "text": "this segmentation the output of this network does is it only takes a frame by",
    "start": "3090580",
    "end": "3097390"
  },
  {
    "text": "frame by frame it's not using the temporal information at all so the question is can we figure out a way can",
    "start": "3097390",
    "end": "3103960"
  },
  {
    "text": "we figure out tricks to use temporal information to improve this segmentation so it looks more like this segmentation",
    "start": "3103960",
    "end": "3113609"
  },
  {
    "text": "and we're also providing the optical flow from frame to frame to frame so the optical flow based",
    "start": "3114330",
    "end": "3120730"
  },
  {
    "text": "on flowing at 2.00 of how each of the pixels moved okay and that forms a seg",
    "start": "3120730",
    "end": "3130570"
  },
  {
    "text": "fuse competition 10,000 images and the task is to submit code we have starter",
    "start": "3130570",
    "end": "3138250"
  },
  {
    "text": "code in Python and on github to take in",
    "start": "3138250",
    "end": "3143860"
  },
  {
    "text": "the original video take in for the training set the ground truth the segmentation from the state-of-the-art",
    "start": "3143860",
    "end": "3150240"
  },
  {
    "text": "segmentation Network the optical flow from the state-of-the-art optical flow Network and taking that together to",
    "start": "3150240",
    "end": "3158290"
  },
  {
    "text": "improve the the stuff on the bottom left the segmentation to try to achieve the ground truth and on the top right okay",
    "start": "3158290",
    "end": "3167410"
  },
  {
    "text": "with that I'd like to thank you tomorrow at 1 p.m. is way mo in Stata 32 one two",
    "start": "3167410",
    "end": "3176380"
  },
  {
    "text": "three the next lecture next week will be on deep learning for a sense in the human understanding the human and we",
    "start": "3176380",
    "end": "3183670"
  },
  {
    "text": "will release online only lecture on capsule networks and Gans general",
    "start": "3183670",
    "end": "3188800"
  },
  {
    "text": "adversarial networks thank you very much [Applause]",
    "start": "3188800",
    "end": "3194980"
  }
]
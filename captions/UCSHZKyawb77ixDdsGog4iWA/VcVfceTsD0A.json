[
  {
    "start": "0",
    "end": "116000"
  },
  {
    "text": "- A lot of people have said for many years that there will come a time when we want to pause a little bit.",
    "start": "210",
    "end": "4600"
  },
  {
    "text": "That time is now. - The following is a\nconversation with Max Tegmark,",
    "start": "6360",
    "end": "13650"
  },
  {
    "text": "his third time in the podcast. In fact, his first appearance was episode number one",
    "start": "13650",
    "end": "18839"
  },
  {
    "text": "of this very podcast. He is a physicist and artificial intelligence\nresearcher at MIT,",
    "start": "18840",
    "end": "24960"
  },
  {
    "text": "co-founder of Future of Life Institute, and Author of \"Life 3.0: Being Human in the Age of\nArtificial Intelligence.\"",
    "start": "24960",
    "end": "33570"
  },
  {
    "text": "Most recently, he's a key figure in\nspearheading the open letter calling for a six-month\npause on giant AI experiments",
    "start": "33570",
    "end": "41579"
  },
  {
    "text": "like training GPT-4. The letter reads, \"We're calling for a pause on training",
    "start": "41580",
    "end": "48329"
  },
  {
    "text": "of models larger than\nGPT-4 for six months. This does not imply a pause\nor ban on all AI research",
    "start": "48330",
    "end": "55080"
  },
  {
    "text": "and development or the use of systems that have already been\nplaced in the market. Our call is specific and addresses",
    "start": "55080",
    "end": "62550"
  },
  {
    "text": "a very small pool of actors who possesses this capability.\" The letter has been signed\nby over 50,000 individuals,",
    "start": "62550",
    "end": "69900"
  },
  {
    "text": "including 1800 CEOs and\nover 1500 professors. Signatories include Yoshua Bengio,",
    "start": "69900",
    "end": "76980"
  },
  {
    "text": "Stuart Russell, Elon Musk, Steve Wozniak, Yuval Noah Harari, Andrew Yang, and many others.",
    "start": "76980",
    "end": "83670"
  },
  {
    "text": "This is a defining moment in the history of human civilization, where the balance of power",
    "start": "83670",
    "end": "89010"
  },
  {
    "text": "between human and AI begins to shift, and Max's mind and his voice",
    "start": "89010",
    "end": "95610"
  },
  {
    "text": "is one of the most valuable and powerful in a time like this. His support, his wisdom, his friendship,",
    "start": "95610",
    "end": "102480"
  },
  {
    "text": "has been a gift I'm forever\ndeeply grateful for. This is the Lex Fridman podcast.",
    "start": "102480",
    "end": "108869"
  },
  {
    "text": "To support it, please\ncheck out our sponsors in the description. And now, dear friends, here's Max Tegmark.",
    "start": "108870",
    "end": "115623"
  },
  {
    "start": "116000",
    "end": "860000"
  },
  {
    "text": "You were the first ever\nguest on this podcast, episode number one. So first of all,",
    "start": "116550",
    "end": "122310"
  },
  {
    "text": "Max, I just have to say, thank you for giving me a chance. Thank you for starting this journey, and it's been an incredible journey,",
    "start": "122310",
    "end": "127860"
  },
  {
    "text": "just thank you for sitting down with me and just acting like I'm\nsomebody who matters,",
    "start": "127860",
    "end": "134280"
  },
  {
    "text": "that I'm somebody who's\ninteresting to talk to. And thank you for doing it. That meant a lot.",
    "start": "134280",
    "end": "139702"
  },
  {
    "text": "- And thanks to you for putting your heart and soul into this. I know when you delve\ninto controversial topics,",
    "start": "139703",
    "end": "146910"
  },
  {
    "text": "it's inevitable to get hit by what Hamlet talks about \"The slings and arrows,\" and stuff.",
    "start": "146910",
    "end": "152430"
  },
  {
    "text": "And I really admire this. It's in an era, you know, where YouTube videos are too long,",
    "start": "152430",
    "end": "157440"
  },
  {
    "text": "and now it has to be\nlike a 20-minute TikTok, 20-second TikTok clip. It's just so refreshing to see you",
    "start": "157440",
    "end": "163560"
  },
  {
    "text": "going exactly against all of the advice and doing these really long form things, and the people appreciate it, you know.",
    "start": "163560",
    "end": "169740"
  },
  {
    "text": "Reality is nuanced, and thanks\nfor sharing it that way.",
    "start": "169740",
    "end": "174740"
  },
  {
    "text": "- So let me ask you again, the first question I've\never asked on this podcast, episode number one, talking to you.",
    "start": "175890",
    "end": "182250"
  },
  {
    "text": "Do you think there's intelligent life out there in the universe? Let's revisit that question.",
    "start": "182250",
    "end": "187350"
  },
  {
    "text": "Do you have any updates? What's your view when you\nlook out to the stars?",
    "start": "187350",
    "end": "192390"
  },
  {
    "text": "- So, when we look out to the stars, if you define our universe the\nway most astrophysicists do,",
    "start": "192390",
    "end": "198960"
  },
  {
    "text": "not as all of space, but the spherical region of space that we can see with our telescopes from which light has the time to reach us,",
    "start": "198960",
    "end": "205950"
  },
  {
    "text": "since our Big Bang. I'm in the minority. I estimate that we are the only life",
    "start": "205950",
    "end": "213550"
  },
  {
    "text": "in this spherical volume that has invented internet, the radio, has gotten\nto our level of tech.",
    "start": "214516",
    "end": "221640"
  },
  {
    "text": "And if that's true, then it puts a lot of responsibility on us",
    "start": "221640",
    "end": "227909"
  },
  {
    "text": "to not mess this one up. Because if it's true, it means that life is quite rare.",
    "start": "227910",
    "end": "234450"
  },
  {
    "text": "And we are stewards of this one spark of advanced consciousness, which if we nurture it and help it grow,",
    "start": "234450",
    "end": "243719"
  },
  {
    "text": "eventually life can spread from here, out into much of our universe, and we can have this just amazing future. Whereas, if we instead are reckless",
    "start": "243720",
    "end": "251370"
  },
  {
    "text": "with the technology we build and just snuff it out due to stupidity or in-fighting, then,",
    "start": "251370",
    "end": "257943"
  },
  {
    "text": "maybe the rest of cosmic\nhistory in our universe is just gonna be playing\nfor empty benches.",
    "start": "259650",
    "end": "264840"
  },
  {
    "text": "But I do think that we are actually very likely to get visited by aliens,",
    "start": "264840",
    "end": "271110"
  },
  {
    "text": "alien intelligence quite soon. But I think we are gonna be building that alien intelligence.",
    "start": "271110",
    "end": "276750"
  },
  {
    "text": "- So we're going to give birth to an intelligent alien civilization,",
    "start": "276750",
    "end": "284190"
  },
  {
    "text": "unlike anything that human, the evolution here on\nearth was able to create",
    "start": "284190",
    "end": "289620"
  },
  {
    "text": "in terms of the path, the biological path it took. - Yeah, and it's gonna be\nmuch more alien than a cat,",
    "start": "289620",
    "end": "297800"
  },
  {
    "text": "or even the most exotic animal\non the planet right now, because it will not have been created",
    "start": "298380",
    "end": "305460"
  },
  {
    "text": "through the usual Darwinian competition where it necessarily cares\nabout self-preservation,",
    "start": "305460",
    "end": "310860"
  },
  {
    "text": "that is afraid of death, any of those things. The space of alien\nminds that you can build",
    "start": "310860",
    "end": "318600"
  },
  {
    "text": "is just so much faster than\nwhat evolution will give you. And with that also comes\na great responsibility,",
    "start": "318600",
    "end": "324992"
  },
  {
    "text": "for us to make sure that\nthe kind of minds we create are the kind of minds\nthat it's good to create.",
    "start": "326160",
    "end": "332250"
  },
  {
    "text": "Minds that will share our values and be good for humanity and life.",
    "start": "332250",
    "end": "339419"
  },
  {
    "text": "And also don't create\nminds that don't suffer. - Do you try to visualize the full space",
    "start": "339420",
    "end": "346920"
  },
  {
    "text": "of alien minds that AI could be? Do you try to consider all the different kinds of intelligences,",
    "start": "346920",
    "end": "353013"
  },
  {
    "text": "instead of generalizing\nwhat humans are able to do to the full spectrum of\nwhat intelligent creatures,",
    "start": "354570",
    "end": "360720"
  },
  {
    "text": "entities could do? - I try, but I would say I fail, I mean, it's very difficult for human mind",
    "start": "360720",
    "end": "369600"
  },
  {
    "text": "to really grapple with\nsomething so completely alien.",
    "start": "369600",
    "end": "374600"
  },
  {
    "text": "Even for us, right? If we just try to\nimagine how would it feel if we were completely indifferent",
    "start": "375120",
    "end": "381720"
  },
  {
    "text": "towards death or individuality?",
    "start": "381720",
    "end": "385113"
  },
  {
    "text": "Even if you just imagine that for example, you could just copy my knowledge\nof how to speak Swedish,",
    "start": "386880",
    "end": "394401"
  },
  {
    "text": "(fingers snapping) boom,\nnow you can speak Swedish, and you could copy any\nof my cool experiences,",
    "start": "394402",
    "end": "399660"
  },
  {
    "text": "and then you could delete the ones you didn't like in your own life, just like that. it would already change quite a lot",
    "start": "399660",
    "end": "405460"
  },
  {
    "text": "about how you feel as\na human being, right? You probably spend less\neffort studying things",
    "start": "405460",
    "end": "411660"
  },
  {
    "text": "if you just copy them, and you might be less afraid of death, because if the plane\nyou're on starts to crash,",
    "start": "411660",
    "end": "418290"
  },
  {
    "text": "you'd just be like, \"Oh shucks, I haven't backed my\nbrain up for four hours,",
    "start": "418290",
    "end": "423929"
  },
  {
    "text": "(Lex laughs) so I'm gonna lose this, all this wonderful\nexperiences of this flight.\"",
    "start": "423929",
    "end": "429687"
  },
  {
    "text": "We might also start feeling more, like compassionate maybe with other people",
    "start": "431130",
    "end": "437250"
  },
  {
    "text": "if we can so readily share\neach other's experiences and our knowledge, and\nfeel more like a hivemind.",
    "start": "437250",
    "end": "442533"
  },
  {
    "text": "It's very hard though. I really feel very humble about this",
    "start": "443460",
    "end": "448150"
  },
  {
    "text": "to grapple with it, how it might actually feel. The one thing which is so obvious though,",
    "start": "449070",
    "end": "455340"
  },
  {
    "text": "which, I think is just\nreally worth reflecting on, is because the mind space\nof possible intelligences",
    "start": "455340",
    "end": "462389"
  },
  {
    "text": "is so different from ours, it's very dangerous if we assume they're gonna be like us, or anything like us.",
    "start": "462390",
    "end": "468423"
  },
  {
    "text": "- Well there's, the entirety of human written history",
    "start": "469470",
    "end": "475020"
  },
  {
    "text": "has been through poetry, through novels, been trying to describe\nthrough philosophy,",
    "start": "475020",
    "end": "480960"
  },
  {
    "text": "trying to describe the human condition and what's entailed in it. Like, just like you said, fear of death and all\nthose kinds of things,",
    "start": "480960",
    "end": "486750"
  },
  {
    "text": "what is love, and all of that changes. - [Max] Yeah. - If you have a different\nkind of intelligence.",
    "start": "486750",
    "end": "491840"
  },
  {
    "text": "Like all of it, the entirety of all those poems, they're trying to sneak up to what the hell it means to be human.",
    "start": "491840",
    "end": "498389"
  },
  {
    "text": "All of that changes. How AI concerns and existential crises\nthat AI experiences,",
    "start": "498390",
    "end": "506220"
  },
  {
    "text": "how that clashes with the\nhuman existential crisis, the human condition. - [Max] Yeah.",
    "start": "506220",
    "end": "511673"
  },
  {
    "text": "- That's hard to fathom, hard to predict. - It's hard, but it's\nfascinating to think about also.",
    "start": "511673",
    "end": "517979"
  },
  {
    "text": "Even in the best case scenario, where we don't lose control over the ever more powerful AI",
    "start": "517980",
    "end": "524279"
  },
  {
    "text": "that we're building to other humans whose goals we think are horrible, and where we don't lose\ncontrol to the machines,",
    "start": "524280",
    "end": "531870"
  },
  {
    "text": "and AI provides the things we want. Even then, you get into the questions",
    "start": "531870",
    "end": "538830"
  },
  {
    "text": "you touched here, you know, maybe it's the struggle that it's actually hard to do things",
    "start": "538830",
    "end": "543870"
  },
  {
    "text": "is part of the things that\ngives us meaning as well, right? So for example, I found it so shocking that",
    "start": "543870",
    "end": "550860"
  },
  {
    "text": "this new Microsoft GPT-4 commercial that they put together, has this woman talking about,",
    "start": "550860",
    "end": "558029"
  },
  {
    "text": "showing this demo how she's gonna give a graduation speech to\nher beloved daughter.",
    "start": "558030",
    "end": "563880"
  },
  {
    "text": "And she asks GPT-4 to write it. It was frigging 200 words or so.",
    "start": "563880",
    "end": "568920"
  },
  {
    "text": "If I realized that my\nparents couldn't be bothered struggling a little\nbit to write 200 words,",
    "start": "568920",
    "end": "575040"
  },
  {
    "text": "and outsource that to their computer, I would feel really offended, actually.",
    "start": "575040",
    "end": "579063"
  },
  {
    "text": "And so I wonder if eliminating too much of the struggle from our existence,",
    "start": "580170",
    "end": "586383"
  },
  {
    "text": "do you think that would also take away a little bit of what- - it means to be human? Yeah.",
    "start": "588660",
    "end": "595093"
  },
  {
    "text": "- [Max] Yeah. - We can't even predict. I had somebody mentioned\nto me that they use,",
    "start": "595093",
    "end": "601440"
  },
  {
    "text": "they started using ChatGPT\nwith the 3.5 and now 4.0,",
    "start": "601440",
    "end": "606067"
  },
  {
    "text": "to write what they\nreally feel to a person, and they have a temper issue,",
    "start": "607980",
    "end": "614279"
  },
  {
    "text": "and they're basically\ntrying to get ChatGPT to rewrite it in a nicer way.",
    "start": "614280",
    "end": "619800"
  },
  {
    "text": "To get the point across, but rewrite it in a nicer way. So we're even removing the inner asshole",
    "start": "619800",
    "end": "626220"
  },
  {
    "text": "from our communication. So I don't, you know, there's some positive aspects of that,",
    "start": "626220",
    "end": "631890"
  },
  {
    "text": "but mostly it's just the transformation of how humans communicate. And it's scary because",
    "start": "631890",
    "end": "639240"
  },
  {
    "text": "so much of our society is based on this glue of communication.",
    "start": "639240",
    "end": "644670"
  },
  {
    "text": "And if we're now using AI as\nthe medium of communication that does the language for us,",
    "start": "644670",
    "end": "651543"
  },
  {
    "text": "so much of the emotion that's\nladen in human communication, and so much of the intent,",
    "start": "652440",
    "end": "657513"
  },
  {
    "text": "that's going to be handled by, outsourced to AI, how does that change everything? How does that change the internal state",
    "start": "658440",
    "end": "663990"
  },
  {
    "text": "of how we feel about other human beings? What makes us lonely? What makes us excited?",
    "start": "663990",
    "end": "669029"
  },
  {
    "text": "What makes us afraid? How we fall in love? All that kind of stuff. - Yeah. For me personally, I have to confess,",
    "start": "669030",
    "end": "675120"
  },
  {
    "text": "the challenge is one of the things that really makes my life feel",
    "start": "675120",
    "end": "679300"
  },
  {
    "text": "meaningful, you know? If I go hiking mountain\nwith my wife, Meia,",
    "start": "680640",
    "end": "686130"
  },
  {
    "text": "I don't wanna just press a\nbutton and be at the top, I want to struggle and\ncome up there sweaty, and feel, \"Wow, we did this,\"",
    "start": "686130",
    "end": "692400"
  },
  {
    "text": "in the same way. I want to constantly work on myself",
    "start": "692400",
    "end": "697860"
  },
  {
    "text": "to become a better person. If I say something in anger that I regret, I want to go back",
    "start": "697860",
    "end": "703800"
  },
  {
    "text": "and really work on myself rather than just tell an AI,",
    "start": "703800",
    "end": "708960"
  },
  {
    "text": "from now on, always filter what I write so I don't have to work on myself, 'cause then I'm not growing.",
    "start": "708960",
    "end": "715863"
  },
  {
    "text": "- Yeah, but then again, it could be like with chess, and AI, once it significantly,",
    "start": "717300",
    "end": "723959"
  },
  {
    "text": "obviously supersedes the\nperformance of humans, it will live in its own world, and provide maybe a flourishing\ncivilizations for humans.",
    "start": "723960",
    "end": "732660"
  },
  {
    "text": "But we humans will\ncontinue hiking mountains, and playing our games, even though AI is so much smarter,",
    "start": "732660",
    "end": "738270"
  },
  {
    "text": "so much stronger, so much superior in every single way, just like with chess. - [Max] Yeah. - So that,",
    "start": "738270",
    "end": "743956"
  },
  {
    "text": "I mean, that's one possible\nhopeful trajectory here, is that humans will continue to human,",
    "start": "743956",
    "end": "748630"
  },
  {
    "text": "and AI will just be a kind of,",
    "start": "749910",
    "end": "754022"
  },
  {
    "text": "a medium that enables the\nhuman experience to flourish.",
    "start": "760290",
    "end": "765290"
  },
  {
    "text": "- Yeah, I would phrase that\nas rebranding ourselves",
    "start": "765570",
    "end": "770570"
  },
  {
    "text": "from Homo sapiens to Homo sentiens. You know, right now, if it's sapiens, the ability to be intelligent,",
    "start": "770670",
    "end": "778170"
  },
  {
    "text": "we've even put it in our species' name. So we're branding\nourselves as the smartest",
    "start": "778170",
    "end": "785100"
  },
  {
    "text": "information processing\nentity on the planet. That's clearly gonna change\nif AI continues ahead.",
    "start": "785100",
    "end": "792963"
  },
  {
    "text": "So maybe we should focus\non the experience instead, the subjective experience that we have,",
    "start": "794190",
    "end": "798480"
  },
  {
    "text": "Homo sentiens, and say that's\nwhat's really valuable, the love, the connection,\nthe other things,",
    "start": "799410",
    "end": "805413"
  },
  {
    "text": "and get off our high horses, and get rid of this hubris that, you know, only we can do integrals.",
    "start": "808084",
    "end": "813907"
  },
  {
    "text": "- So consciousness, the subjective experience\nis a fundamental value to what it means to be human.",
    "start": "816030",
    "end": "822100"
  },
  {
    "text": "Make that the priority. - That feels like a\nhopeful direction to me. But that also requires more compassion,",
    "start": "823031",
    "end": "830940"
  },
  {
    "text": "not just towards other humans, because they happen to be\nthe smartest on the planet, but also towards all our\nother fellow creatures",
    "start": "830940",
    "end": "837750"
  },
  {
    "text": "on this planet. I personally feel right now, we're treating a lot of farm\nanimals horribly, for example.",
    "start": "837750",
    "end": "843480"
  },
  {
    "text": "And the excuse we're using is, \"Oh, they're not as smart as us.\" But if we admit that we're not that smart",
    "start": "843480",
    "end": "850079"
  },
  {
    "text": "in the grand scheme of things either, in the post-AI epoch, you know, then surely, we should value",
    "start": "850080",
    "end": "855399"
  },
  {
    "text": "the subjective experience of a cow also. - Well, allow me to\nbriefly look at the book,",
    "start": "856290",
    "end": "863970"
  },
  {
    "start": "860000",
    "end": "1547000"
  },
  {
    "text": "which at this point is becoming\nmore and more visionary that you've written, I\nguess over five years ago, \"Life 3.0.\"",
    "start": "863970",
    "end": "869652"
  },
  {
    "text": "So first of all, 3.0, what's 1.0, what's 2.0, What's 3.0? and how's that vision sort of evolve,",
    "start": "870870",
    "end": "878880"
  },
  {
    "text": "the vision in the book evolve to today. - Life 1.0 is really dumb like bacteria,",
    "start": "878880",
    "end": "885180"
  },
  {
    "text": "and that it can't actually\nlearn anything at all during their lifetime. The learning just comes\nfrom this genetic process",
    "start": "885180",
    "end": "891587"
  },
  {
    "text": "from one generation to the next. Life 2.0 is us and other\nanimals which have brains",
    "start": "893070",
    "end": "900200"
  },
  {
    "text": "which can learn during\ntheir lifetime a great deal. Right so,",
    "start": "900990",
    "end": "905033"
  },
  {
    "text": "and you know, you were born without being able to speak English,",
    "start": "907053",
    "end": "912120"
  },
  {
    "text": "and at some point you decided, \"Hey, I wanna upgrade my software, and so let's install an\nEnglish-speaking module.\"",
    "start": "912120",
    "end": "918480"
  },
  {
    "text": "So you did. And Life 3.0, which does not exist yet,",
    "start": "918480",
    "end": "924330"
  },
  {
    "text": "cannot replace not only its\nsoftware the way we can, but also it's hardware.",
    "start": "924330",
    "end": "928570"
  },
  {
    "text": "And that's where we're\nheading towards at high speed. We're already maybe 2.1 because we can,",
    "start": "929640",
    "end": "934897"
  },
  {
    "text": "you know, put in an artificial knee,",
    "start": "934897",
    "end": "938972"
  },
  {
    "text": "pacemaker, et cetera, et cetera. And if Neuralink and\nother companies succeed,",
    "start": "940140",
    "end": "945300"
  },
  {
    "text": "it will be life 2.2, et cetera. But the companies trying to build AGI,",
    "start": "945300",
    "end": "952110"
  },
  {
    "text": "or trying to make is of course, full 3.0, and you can put that intelligence in something that also has no,",
    "start": "952110",
    "end": "957843"
  },
  {
    "text": "biological basis whatsoever. - So less constraints\nand more capabilities, just like the leap from 1.0 to 2.0.",
    "start": "960750",
    "end": "968760"
  },
  {
    "text": "There is nevertheless, you speaking so harshly about bacteria, so disrespectfully about bacteria,",
    "start": "968760",
    "end": "974340"
  },
  {
    "text": "there is still the same\nkind of magic there that permeates life 2.0 and 3.0.",
    "start": "974340",
    "end": "982529"
  },
  {
    "text": "It seems like maybe the\nthing that's truly powerful about life, intelligence,\nand consciousness,",
    "start": "982530",
    "end": "989460"
  },
  {
    "text": "was already there in 1.0. Is it possible?",
    "start": "989460",
    "end": "992918"
  },
  {
    "text": "- I think we should be\nhumble and not be so quick to make everything binary",
    "start": "994470",
    "end": "1001190"
  },
  {
    "text": "and say either it's there or it's not. Clearly there's a great spectrum and there is even controversy about",
    "start": "1001190",
    "end": "1007009"
  },
  {
    "text": "whether some unicellular\norganisms like amoebas can maybe learn a little\nbit, you know, after all.",
    "start": "1007010",
    "end": "1013160"
  },
  {
    "text": "So apologies if I offended\nany bacteria here. (laughs) It wasn't my intent. It was more that I wanted to talk up",
    "start": "1013160",
    "end": "1019340"
  },
  {
    "text": "how cool it is to actually have a brain. - [Lex] Yeah. - Where you can learn\ndramatically within your lifetime.",
    "start": "1019340",
    "end": "1024709"
  },
  {
    "text": "- [Lex] Typical human. - And the higher up you\nget from 1.0 2.0 to 3.0, the more you become the\ncaptain of your own ship,",
    "start": "1024710",
    "end": "1032540"
  },
  {
    "text": "the master of your own destiny. And the less you become a slave to whatever evolution gave you, right?",
    "start": "1032540",
    "end": "1037553"
  },
  {
    "text": "By upgrading your software, we can be so different\nfrom previous generations and even from our parents,",
    "start": "1038420",
    "end": "1044600"
  },
  {
    "text": "much more so than even a bacterium, you know, no offense to them. And if you can also swap out your hardware",
    "start": "1044600",
    "end": "1052070"
  },
  {
    "text": "and take any physical\nform you want, of course, it's really, the sky's the limit. - Yeah, so the,",
    "start": "1052070",
    "end": "1058013"
  },
  {
    "text": "it accelerates the rate\nat which you can perform the computation that\ndetermines your destiny.",
    "start": "1059120",
    "end": "1065510"
  },
  {
    "text": "- Yeah, and I think it's worth commenting a bit on what \"you\" means in this context. Also, if you swap things out a lot, right?",
    "start": "1065510",
    "end": "1072683"
  },
  {
    "text": "This is controversial, but my, current understanding is that,",
    "start": "1073850",
    "end": "1081410"
  },
  {
    "text": "you know, life is best thought of not as a bag of meat,",
    "start": "1081410",
    "end": "1087710"
  },
  {
    "text": "or even a bag of elementary particles, but rather as a system which\ncan process information",
    "start": "1087710",
    "end": "1096820"
  },
  {
    "text": "and retain its own complexity, even though nature is\nalways trying to mess it up, so, it's all about information processing.",
    "start": "1096950",
    "end": "1105110"
  },
  {
    "text": "And that makes it a lot like something like a wave in the ocean, which is not,",
    "start": "1105110",
    "end": "1110624"
  },
  {
    "text": "it's water molecules, right? The water molecules bob up and down, but the wave moves forward,",
    "start": "1110624",
    "end": "1116240"
  },
  {
    "text": "it's an information pattern\nin the same way you, Lex, you're not the same atoms",
    "start": "1116240",
    "end": "1121760"
  },
  {
    "text": "as during the first, - Time we talked, yeah.\n- Interview you did with me, you've swapped out most of them, but it's still you.",
    "start": "1121760",
    "end": "1128035"
  },
  {
    "text": "And the information\npattern is still there, and if you could swap out your arms,",
    "start": "1128035",
    "end": "1135830"
  },
  {
    "text": "and like whatever, you can still have this\nkind of continuity,",
    "start": "1135830",
    "end": "1141620"
  },
  {
    "text": "it becomes much more sophisticated sort of way forward in time where the information lives on.",
    "start": "1141620",
    "end": "1146900"
  },
  {
    "text": "I lost both of my parents\nsince our last podcast, and it actually gives me a lot of solace",
    "start": "1146900",
    "end": "1153860"
  },
  {
    "text": "that this way of thinking about them, they haven't entirely died because a lot of mommy and daddy's,",
    "start": "1153860",
    "end": "1162173"
  },
  {
    "text": "sorry, I'm getting a\nlittle emotional here, but a lot of their values, and ideas, and even jokes and so on,",
    "start": "1163640",
    "end": "1171800"
  },
  {
    "text": "they haven't gone away, right? Some of them live on, I can carry on some of them, and they also live on a\nin a lot of other people.",
    "start": "1171800",
    "end": "1178910"
  },
  {
    "text": "So in this sense, even with life 2.0, we can to some extent,",
    "start": "1178910",
    "end": "1184010"
  },
  {
    "text": "already transcend our\nphysical bodies and our death.",
    "start": "1184010",
    "end": "1189010"
  },
  {
    "text": "And particularly if you can\nshare your own information, your own ideas with many others",
    "start": "1189140",
    "end": "1196580"
  },
  {
    "text": "like you do in your podcast, then you know,",
    "start": "1196580",
    "end": "1200743"
  },
  {
    "text": "that's the closest immortality we can get with our bio bodies. - You carry a little bit of\nthem in you in some sense.",
    "start": "1203210",
    "end": "1209888"
  },
  {
    "text": "- [Max] Yeah, yeah. - Do you miss them? Do you miss your mom and dad? - Of course, of course.",
    "start": "1209889",
    "end": "1215660"
  },
  {
    "text": "- What did you learn about life from them? If we can take a bit of a tangent.",
    "start": "1215660",
    "end": "1221360"
  },
  {
    "text": "- Oh, so many things. For starters, my fascination for math",
    "start": "1221360",
    "end": "1228920"
  },
  {
    "text": "and the physical\nmysteries of our universe, I got a lot of that from my dad.",
    "start": "1228920",
    "end": "1234950"
  },
  {
    "text": "But I think my obsession\nfor really big questions, and consciousness, and so on,",
    "start": "1234950",
    "end": "1240020"
  },
  {
    "text": "that actually came mostly from my mom and what I got from both of them,",
    "start": "1240020",
    "end": "1247130"
  },
  {
    "text": "which is very core part\nof really who I am, I think is this,",
    "start": "1247130",
    "end": "1253313"
  },
  {
    "text": "just feeling comfortable with,",
    "start": "1259700",
    "end": "1261323"
  },
  {
    "text": "not buying into what\neverybody else is saying, just doing what I think is right.",
    "start": "1264740",
    "end": "1271073"
  },
  {
    "text": "They both very much just, you know, did their own thing, and sometimes they got flak for it",
    "start": "1274820",
    "end": "1280850"
  },
  {
    "text": "and they did it anyway. - That's why you've always\nbeen in an inspiration to me.",
    "start": "1280850",
    "end": "1285920"
  },
  {
    "text": "That you're at the top of your field and you're still willing",
    "start": "1285920",
    "end": "1290370"
  },
  {
    "text": "to tackle the big\nquestions in your own way. You're one of one of the people that represents MIT best to me,",
    "start": "1292732",
    "end": "1300320"
  },
  {
    "text": "you've always been an inspiration in that. So it's good to hear that you got that from your mom and dad. - Yeah, you're too kind. But yeah, I mean,",
    "start": "1300320",
    "end": "1306570"
  },
  {
    "text": "the good reason to do science is because you're really curious, and you wanna figure out the truth.",
    "start": "1307610",
    "end": "1312923"
  },
  {
    "text": "If you think, this is how it is and everyone else says, \"No, no, that's bullshit,\nand it's that way,\"",
    "start": "1313790",
    "end": "1319580"
  },
  {
    "text": "you know, You stick with what you think is true,",
    "start": "1319580",
    "end": "1324293"
  },
  {
    "text": "and even if everybody else\nkeeps thinking it's bullshit, there's a certain,",
    "start": "1325705",
    "end": "1330380"
  },
  {
    "text": "I always root for the underdog, (Lex laughs)\nwhen I watch movies. And my dad once,",
    "start": "1332720",
    "end": "1338059"
  },
  {
    "text": "one time for example, when I wrote one of my\ncraziest papers ever, talking about our universe\nultimately being mathematical,",
    "start": "1338060",
    "end": "1344300"
  },
  {
    "text": "which we're not gonna get into today, I got this email from a quite\nfamous professor saying, \"This is not only all bullshit,",
    "start": "1344300",
    "end": "1349550"
  },
  {
    "text": "but it's gonna ruin your career. You should stop doing this kind of stuff.\" I sent it to my dad.",
    "start": "1349550",
    "end": "1354800"
  },
  {
    "text": "Do you know what he said? - [Lex] (laughs) What he say? - He replied with a quote from Dante. (Lex laughing)",
    "start": "1354800",
    "end": "1359882"
  },
  {
    "text": "(Max speaking in Italian) \"Follow your own path\nand let the people talk.\"",
    "start": "1359882",
    "end": "1365631"
  },
  {
    "text": "(Both laughing) Go dad! - [Lex] Yeah. - This is the kind of thing, you know, he's dead, but that attitude is not.",
    "start": "1365631",
    "end": "1373013"
  },
  {
    "text": "- How did losing them as a man, as a human being change you? How did it expand your\nthinking about the world?",
    "start": "1374390",
    "end": "1381170"
  },
  {
    "text": "How did it expand your thinking about, you know, this thing we're talking about, which is humans creating another living,",
    "start": "1381170",
    "end": "1389840"
  },
  {
    "text": "sentient perhaps, being? - I think it,",
    "start": "1389840",
    "end": "1394643"
  },
  {
    "text": "mainly do two things. One of them just going\nthrough all their stuff",
    "start": "1398090",
    "end": "1403790"
  },
  {
    "text": "after they had passed away and so on, just drove home to me how\nimportant it is to ask ourselves,",
    "start": "1403790",
    "end": "1408809"
  },
  {
    "text": "why are we doing this things we do? Because it's inevitable\nthat you look at some things they spent an enormous time on",
    "start": "1410000",
    "end": "1415460"
  },
  {
    "text": "and you ask in hindsight, would they really have\nspent so much time on this? Would they have done something",
    "start": "1415460",
    "end": "1421309"
  },
  {
    "text": "that was more meaningful? So I've been looking more\nin my life now and asking,",
    "start": "1421310",
    "end": "1426560"
  },
  {
    "text": "you know, why am I doing what I'm doing? And I feel,",
    "start": "1426560",
    "end": "1430163"
  },
  {
    "text": "it should either be something\nI really enjoy doing, or it should be something that I find really, really meaningful\nbecause it helps humanity,",
    "start": "1434030",
    "end": "1442793"
  },
  {
    "text": "and if it's in none of\nthose two categories,",
    "start": "1444470",
    "end": "1449470"
  },
  {
    "text": "maybe I should spend less\ntime on it, you know. The other thing is, dealing with death up in person like this,",
    "start": "1449750",
    "end": "1457010"
  },
  {
    "text": "it's actually made me less afraid of,",
    "start": "1457010",
    "end": "1460583"
  },
  {
    "text": "even less afraid of\nother people telling me that I'm an idiot, you know, which happens regularly,",
    "start": "1462170",
    "end": "1467929"
  },
  {
    "text": "and just live my life,\ndo my thing, you know?",
    "start": "1467930",
    "end": "1471203"
  },
  {
    "text": "And it's made it a\nlittle bit easier for me to focus on what I feel\nis really important.",
    "start": "1474502",
    "end": "1480590"
  },
  {
    "text": "- What about fear of your own death? Has it made it more real that this is something that happens?",
    "start": "1480590",
    "end": "1489500"
  },
  {
    "text": "- Yeah, it's made it extremely real, and you know, I'm next in line in our family now, right? It's me and my younger brother, but,",
    "start": "1489500",
    "end": "1496553"
  },
  {
    "text": "they both handled it with such dignity, that was a true inspiration also.",
    "start": "1499228",
    "end": "1504620"
  },
  {
    "text": "They never complained about things, and you know, when you're old and your body starts falling apart,",
    "start": "1504620",
    "end": "1510230"
  },
  {
    "text": "it's more and more to complain about, they looked at what could they\nstill do that was meaningful, and they focused on that",
    "start": "1510230",
    "end": "1516080"
  },
  {
    "text": "rather than wasting time talking about, or even thinking much about",
    "start": "1516080",
    "end": "1522380"
  },
  {
    "text": "things they were disappointed in. I think anyone can make\nthemselves depressed if they start their morning by\nmaking a list of grievances.",
    "start": "1522380",
    "end": "1530780"
  },
  {
    "text": "Whereas if you start your day\nwhen the little meditation and just the things you're grateful for,",
    "start": "1530780",
    "end": "1536660"
  },
  {
    "text": "you basically choose to be a happy person. - Because you only have\na finite number of days,",
    "start": "1536660",
    "end": "1542450"
  },
  {
    "text": "we should spend them, - [Max] Make it count. - Being grateful. - [Max] Yeah.",
    "start": "1542450",
    "end": "1546583"
  },
  {
    "start": "1547000",
    "end": "3054000"
  },
  {
    "text": "- Well you do happen to\nbe working on a thing which seems to have potentially,",
    "start": "1548480",
    "end": "1556520"
  },
  {
    "text": "some of the greatest impact\non human civilization of anything humans have ever created, which is artificial intelligence.",
    "start": "1556520",
    "end": "1562190"
  },
  {
    "text": "This is, on the both\ndetailed technical level, and on the high philosophical\nlevel you work on.",
    "start": "1562190",
    "end": "1568280"
  },
  {
    "text": "So you've mentioned to me that there's an open letter\nthat you're working on.",
    "start": "1568280",
    "end": "1575000"
  },
  {
    "text": "- It's actually going live in a few hours. (Lex laughing) So I've been having late\nnights and early mornings.",
    "start": "1575000",
    "end": "1582770"
  },
  {
    "text": "It's been very exciting, actually. In short, have you seen, \"Don't Look Up,\"",
    "start": "1582770",
    "end": "1589760"
  },
  {
    "text": "the film? - Yes, yes. - I don't want to be the movie spoiler for anyone watching\nthis who hasn't seen it.",
    "start": "1589760",
    "end": "1596420"
  },
  {
    "text": "But if you're watching this, you haven't seen it, watch it, because we\nare actually acting out,",
    "start": "1596420",
    "end": "1603590"
  },
  {
    "text": "it's life imitating art. Humanity is doing exactly that right now, except it's an asteroid that\nwe are building ourselves.",
    "start": "1603590",
    "end": "1612500"
  },
  {
    "text": "Almost nobody is talking about it. People are squabbling across the planet about all sorts of things,",
    "start": "1612500",
    "end": "1617779"
  },
  {
    "text": "which seem very minor\ncompared to the asteroid that's about to hit us, right? Most politicians don't\neven this on the radar,",
    "start": "1617780",
    "end": "1625190"
  },
  {
    "text": "they think maybe in 100 years or whatever. Right now we're at a fork on the road.",
    "start": "1625190",
    "end": "1631400"
  },
  {
    "text": "This is the most important\nfork that humanity has reached in it's over 100,000 years on this planet.",
    "start": "1631400",
    "end": "1637850"
  },
  {
    "text": "We're building effectively a new species that's smarter than us,",
    "start": "1637850",
    "end": "1642900"
  },
  {
    "text": "it doesn't look so much like a species yet 'cause it's mostly not embodied in robots. But that's the technicality\nwhich will soon be changed.",
    "start": "1643760",
    "end": "1652070"
  },
  {
    "text": "And this arrival of of\nartificial general intelligence",
    "start": "1652070",
    "end": "1657070"
  },
  {
    "text": "that can do all our jobs as well as us, and probably shortly\nthereafter, superintelligence,",
    "start": "1657410",
    "end": "1663230"
  },
  {
    "text": "which greatly exceeds\nour cognitive abilities. It's gonna either be the best thing ever",
    "start": "1663230",
    "end": "1668450"
  },
  {
    "text": "to happen to humanity or the worst. I'm really quite confident that there is not that\nmuch middle ground there.",
    "start": "1668450",
    "end": "1675200"
  },
  {
    "text": "- But it would be\nfundamentally transformative to human civilization. - Of course, utterly and totally.",
    "start": "1675200",
    "end": "1681383"
  },
  {
    "text": "Again, we'd branded\nourselves as Homo sapiens 'cause it seemed like the basic thing, we're the king of the\ncastle on this planet,",
    "start": "1682370",
    "end": "1689029"
  },
  {
    "text": "we're the smart ones, we can control everything else, this could very easily change.",
    "start": "1689030",
    "end": "1695570"
  },
  {
    "text": "We're certainly not gonna be the smartest on the planet for very long if AI,",
    "start": "1695570",
    "end": "1700640"
  },
  {
    "text": "unless AI progress just halts, and we can talk more about\nwhy I think that's true 'cause it's controversial.",
    "start": "1700640",
    "end": "1706913"
  },
  {
    "text": "And then we can also talk about reasons we might think it's\ngonna be the best thing ever,",
    "start": "1708380",
    "end": "1715160"
  },
  {
    "text": "and the reason we think it's going to be the end of humanity, which is of course, super controversial.",
    "start": "1715160",
    "end": "1721460"
  },
  {
    "text": "But what I think we can, anyone who's working on advanced AI",
    "start": "1721460",
    "end": "1728570"
  },
  {
    "text": "can agree on is, it's much like the film \"Don't Look Up,\" in that it's just really comical",
    "start": "1728570",
    "end": "1735919"
  },
  {
    "text": "how little serious public\ndebate there is about it, given how huge it is.",
    "start": "1735920",
    "end": "1741473"
  },
  {
    "text": "- So what we're talking\nabout is a development, of currently, things like GPT-4,",
    "start": "1743990",
    "end": "1750110"
  },
  {
    "text": "and the signs it's showing\nof rapid improvement that may, in the near\nterm lead to development",
    "start": "1750110",
    "end": "1758510"
  },
  {
    "text": "of superintelligent AGI, AI, general AI systems, and what kind of impact\nthat has on society.",
    "start": "1758510",
    "end": "1766070"
  },
  {
    "text": "- [Max] Exactly. - When that thing achieves\ngeneral human-level intelligence, and then beyond that,",
    "start": "1766070",
    "end": "1772370"
  },
  {
    "text": "general superhuman level intelligence. There's a lot of\nquestions to explore here.",
    "start": "1772370",
    "end": "1778940"
  },
  {
    "text": "So one, you mentioned halt. Is that the content of the letter?",
    "start": "1778940",
    "end": "1784820"
  },
  {
    "text": "is to suggest that maybe we should pause the development of these systems. - Exactly, so this is very controversial,",
    "start": "1784820",
    "end": "1792770"
  },
  {
    "text": "from when we talked the first time, we talked about how I was involved in starting the Future of Life Institute,",
    "start": "1792770",
    "end": "1799040"
  },
  {
    "text": "and we worked very hard on 2014, 2015, was the mainstream AI safety.",
    "start": "1799040",
    "end": "1804083"
  },
  {
    "text": "The idea that there even could be risks and that you could do things about them. Before then, a lot of people thought",
    "start": "1805670",
    "end": "1810820"
  },
  {
    "text": "it was just really kooky\nto even talk about it. And a lot of AI researchers felt,",
    "start": "1810820",
    "end": "1815063"
  },
  {
    "text": "worried that this was too flaky, and could be bad for funding, and that the people had\ntalked about it were just not,",
    "start": "1817130",
    "end": "1822950"
  },
  {
    "text": "didn't understand AI. I'm very, very happy with how that's gone,",
    "start": "1822950",
    "end": "1828830"
  },
  {
    "text": "and that now, you know, it's completely mainstream, you go in any AI conference, and people talk about AI safety,",
    "start": "1828830",
    "end": "1834860"
  },
  {
    "text": "and it's a nerdy technical\nfield full of equations and blah-blah. - [Lex] Yes.",
    "start": "1834860",
    "end": "1840403"
  },
  {
    "text": "- As it should be, but there is this other thing, which has been quite taboo up until now,",
    "start": "1841670",
    "end": "1848663"
  },
  {
    "text": "calling for slowdown. So what, we've constantly been\nsaying, including myself,",
    "start": "1849500",
    "end": "1855230"
  },
  {
    "text": "I've been biting my tongue a lot, you know, is that, we don't need to slow down AI development.",
    "start": "1855230",
    "end": "1862760"
  },
  {
    "text": "We just need to win this race, the wisdom race between\nthe growing power of the AI",
    "start": "1862760",
    "end": "1867800"
  },
  {
    "text": "and the growing wisdom\nwith which we manage it. And rather than trying to slow down AI,",
    "start": "1867800",
    "end": "1874250"
  },
  {
    "text": "let's just try to accelerate the wisdom, do all this technical work to figure out how you can actually ensure\nthat your powerful AI",
    "start": "1874250",
    "end": "1881270"
  },
  {
    "text": "is gonna do what you want it to do. And have society adapt also with incentives and regulations",
    "start": "1881270",
    "end": "1888410"
  },
  {
    "text": "so that these things get put to good use. Sadly, that didn't pan out.",
    "start": "1888410",
    "end": "1894803"
  },
  {
    "text": "The progress on technical AI capabilities has gone a lot faster\nthan many people thought",
    "start": "1896300",
    "end": "1904930"
  },
  {
    "text": "back when we started this in 2014. Turned out to be easier to build really advanced AI than we thought.",
    "start": "1906080",
    "end": "1912720"
  },
  {
    "text": "And on the other side, it's gone much slower than we hoped with getting policymakers and others",
    "start": "1914570",
    "end": "1923659"
  },
  {
    "text": "to actually put incentives\nin place to make,",
    "start": "1923660",
    "end": "1927803"
  },
  {
    "text": "steer this in the good directions, maybe we should unpack it and talk a little bit about each, so. - [Lex] Yeah. - Why did it go faster than\na lot of people thought?",
    "start": "1928730",
    "end": "1935903"
  },
  {
    "text": "In hindsight, it's exactly\nlike building flying machines.",
    "start": "1937760",
    "end": "1941963"
  },
  {
    "text": "People spent a lot of time wondering about how do birds fly, you know. And that turned out to be really hard.",
    "start": "1943070",
    "end": "1948830"
  },
  {
    "text": "Have you seen the TED\nTalk with a flying bird? - Like a flying robotic bird? - Yeah, it flies around the audience,",
    "start": "1948830",
    "end": "1955250"
  },
  {
    "text": "but it took 100 years longer to figure out how to do that than for the Wright brothers\nto build the first airplane",
    "start": "1955250",
    "end": "1960470"
  },
  {
    "text": "because it turned out there\nwas a much easier way to fly. And evolution picked\na more complicated one",
    "start": "1960470",
    "end": "1965659"
  },
  {
    "text": "because it had its hands tied. It could only build a machine\nthat could assemble itself,",
    "start": "1965660",
    "end": "1971033"
  },
  {
    "text": "which the Wright brothers\ndidn't care about that, they could only build a machine that use only the most common atoms\nin the periodic table,",
    "start": "1971960",
    "end": "1978350"
  },
  {
    "text": "Wright Brothers didn't care about that, they could use steel, iron atoms, and it had to be built to repair itself,",
    "start": "1978350",
    "end": "1985970"
  },
  {
    "text": "and it also had to be\nincredibly fuel efficient, you know, a lot of birds use less than half the fuel",
    "start": "1985970",
    "end": "1993380"
  },
  {
    "text": "of a remote-controlled plane\nflying the same distance, For humans, just throw\na little more money,",
    "start": "1993380",
    "end": "1998870"
  },
  {
    "text": "put a little more fuel in it, and there you go, 100 years earlier. That's exactly what's happening now with these large language models.",
    "start": "1998870",
    "end": "2006013"
  },
  {
    "text": "The brain is incredibly complicated. Many people made the mistake, you're thinking we have to\nfigure out how the brain does",
    "start": "2007360",
    "end": "2014110"
  },
  {
    "text": "human-level AI first before we could build in the machine, that was completely wrong. You can take an incredibly simple",
    "start": "2014110",
    "end": "2021800"
  },
  {
    "text": "computational system called\na transformer network and just train it to do\nsomething incredibly dumb. Just read a gigantic amount of text",
    "start": "2023650",
    "end": "2030789"
  },
  {
    "text": "and try to predict the next word. And it turns out, if you just throw a ton of compute at that",
    "start": "2030790",
    "end": "2037087"
  },
  {
    "text": "and a ton of data, it gets to be frighteningly\ngood like GPT-4,",
    "start": "2037087",
    "end": "2042370"
  },
  {
    "text": "which I've been playing with so much since it came out, right? And there's still some debate",
    "start": "2042370",
    "end": "2049149"
  },
  {
    "text": "about whether that can get you all the way to full human level or not, but yeah, we can come back\nto the details of that",
    "start": "2049150",
    "end": "2056046"
  },
  {
    "text": "and how you might get the human-level AI even if large language models don't.",
    "start": "2056047",
    "end": "2062260"
  },
  {
    "text": "- Can you briefly, if it's just a small tangent, comment on your feelings about GPT-4? So just that you're impressed\nby this rate of progress,",
    "start": "2062260",
    "end": "2071349"
  },
  {
    "text": "but where is it? Can GPT-4 reason?",
    "start": "2071350",
    "end": "2075492"
  },
  {
    "text": "What are like the intuitions? What are human interpretable\nwords you can assign to the capabilities of GPT-4",
    "start": "2076480",
    "end": "2082300"
  },
  {
    "text": "that makes you so damn impressed with it? - I'm both very excited\nabout it and terrified.",
    "start": "2082300",
    "end": "2088453"
  },
  {
    "text": "It's interesting mixture\nof emotions. (laughs) - All the best things in life\ninclude those two somehow.",
    "start": "2089590",
    "end": "2095350"
  },
  {
    "text": "- Yeah, it can absolutely reason, anyone who hasn't played with it, I highly recommend doing\nthat before dissing it.",
    "start": "2095350",
    "end": "2102073"
  },
  {
    "text": "It can do quite remarkable reasoning. I've had to do a lot of things,",
    "start": "2103360",
    "end": "2108790"
  },
  {
    "text": "which I realized I couldn't\ndo that myself that well even, and it obviously does it",
    "start": "2108790",
    "end": "2114760"
  },
  {
    "text": "dramatically faster than we do too, when you watch it type, and it's doing that well, servicing a massive number of\nother humans at the same time.",
    "start": "2114760",
    "end": "2123160"
  },
  {
    "text": "The same time, it cannot reason as well as a human can on some tasks,",
    "start": "2123160",
    "end": "2130690"
  },
  {
    "text": "it's obviously the limitations\nfrom its architecture. You know, we have in our heads, what in geek-speak is called\na recurrent neural network.",
    "start": "2130690",
    "end": "2138760"
  },
  {
    "text": "There are loops, information can go from this neuron, to this neuron, to this neuron, and then back to this one, you can like ruminate on\nsomething for a while,",
    "start": "2138760",
    "end": "2144940"
  },
  {
    "text": "you can self-reflect a lot. These large language models,",
    "start": "2144940",
    "end": "2150370"
  },
  {
    "text": "they cannot, like GPT-4. It's a so-called transformer where it's just like a one-way street",
    "start": "2150370",
    "end": "2156130"
  },
  {
    "text": "of information, basically. In geek-speak, it's called a\nfeed-forward neural network.",
    "start": "2156130",
    "end": "2161170"
  },
  {
    "text": "And it's only so deep, so it can only do logic\nthat's that many steps and that deep, and it's not,",
    "start": "2161170",
    "end": "2169283"
  },
  {
    "text": "so you can create problems\nwhich it will fail to solve, you know, for that reason.",
    "start": "2169283",
    "end": "2173803"
  },
  {
    "text": "But the fact that it\ncan do so amazing things with this incredibly simple\narchitecture already,",
    "start": "2177910",
    "end": "2183670"
  },
  {
    "text": "is quite stunning, and what we see in my lab at MIT when we look inside large language models",
    "start": "2183670",
    "end": "2190600"
  },
  {
    "text": "to try to figure out how they're doing it, which, that's the key core\nfocus of our research, it's called mechanistic\ninterpretability in geek-speak.",
    "start": "2190600",
    "end": "2200520"
  },
  {
    "text": "You know, you have this machine\nthat does something smart, you try to reverse engineer it, and see how does it do it.",
    "start": "2200710",
    "end": "2207580"
  },
  {
    "text": "I think of it also as\nartificial neuroscience, (Lex laughs)\n'Cause that's exactly - I love it.\n- what neuroscientists do with actual brains. But here you have the\nadvantage that you can,",
    "start": "2207580",
    "end": "2214360"
  },
  {
    "text": "you don't have to worry\nabout measurement errors. You can see what every\nneuron is doing all the time,",
    "start": "2214360",
    "end": "2219579"
  },
  {
    "text": "and a recurrent thing\nwe see again and again, there's been a number of beautiful papers",
    "start": "2219580",
    "end": "2225519"
  },
  {
    "text": "quite recently by a lot of researchers, and some of 'em are\nhere even in this area, is where when they figure\nout how something is done,",
    "start": "2225520",
    "end": "2233083"
  },
  {
    "text": "you can say, \"Oh man, that's\nsuch a dumb way of doing it.\" And you read immediately\nsee how it can be improved. Like for example,",
    "start": "2234183",
    "end": "2240340"
  },
  {
    "text": "there was this beautiful paper recently where they figured out how a large language model\nstores certain facts,",
    "start": "2240340",
    "end": "2246580"
  },
  {
    "text": "like Eiffel Tower is in Paris, and they figured out\nexactly how it's stored and the proof of that they understood it",
    "start": "2246580",
    "end": "2252910"
  },
  {
    "text": "was they could edit it. They changed some synapses in it, and then they asked it,\nWhere's the Eiffel Tower?\"",
    "start": "2252910",
    "end": "2259690"
  },
  {
    "text": "And it said, \"It's in Rome.\" And then they asked,\n\"How do you get there? Oh, how do you get there from Germany?\"",
    "start": "2259690",
    "end": "2265727"
  },
  {
    "text": "\"Oh, you take this train, the Roma Termini train station, and this and that,\"",
    "start": "2265727",
    "end": "2270853"
  },
  {
    "text": "\"And what might you see\nif you're in front of it?\" \"Oh, you might see the Colosseum.\"",
    "start": "2270853",
    "end": "2275859"
  },
  {
    "text": "So they had edited, - So they literally moved it to Rome. - But the way that it's\nstoring this information,",
    "start": "2275860",
    "end": "2281799"
  },
  {
    "text": "it's incredibly dumb, if any fellow nerds listening to this,",
    "start": "2281800",
    "end": "2287800"
  },
  {
    "text": "there was a big matrix, and roughly speaking, there are certain row and column vectors",
    "start": "2287800",
    "end": "2293200"
  },
  {
    "text": "which encode these things, and they correspond very hand-wavingly to principle components and it would be much more\nefficient for as far as matrix,",
    "start": "2293200",
    "end": "2301359"
  },
  {
    "text": "just store in the database, you know and, and everything so far,",
    "start": "2301360",
    "end": "2307210"
  },
  {
    "text": "we've figured out how these things do are ways where you can see\nit can easily be improved. And the fact that this\nparticular architecture",
    "start": "2307210",
    "end": "2314230"
  },
  {
    "text": "has some roadblocks built into it is in no way gonna\nprevent crafty researchers",
    "start": "2314230",
    "end": "2320950"
  },
  {
    "text": "from quickly finding workarounds and making other kinds of architectures",
    "start": "2320950",
    "end": "2327460"
  },
  {
    "text": "sort of go all the way, so. In short, it's turned\nout to be a lot easier",
    "start": "2327460",
    "end": "2334359"
  },
  {
    "text": "to build close to human\nintelligence than we thought, and that means our runway as a species to",
    "start": "2334360",
    "end": "2340460"
  },
  {
    "text": "get our shit together has has shortened. - And it seems like the scary thing",
    "start": "2342637",
    "end": "2347950"
  },
  {
    "text": "about the effectiveness\nof large language models, so Sam Altman, I've recently\nhad conversation with,",
    "start": "2347950",
    "end": "2354940"
  },
  {
    "text": "and he really showed that\nthe leap from GPT-3 to GPT-4",
    "start": "2354940",
    "end": "2359940"
  },
  {
    "text": "has to do with just a bunch of hacks, a bunch of little explorations\nwith smart researchers",
    "start": "2360760",
    "end": "2368220"
  },
  {
    "text": "doing a few little fixes here and there. It's not some fundamental leap and transformation in the architecture.",
    "start": "2369040",
    "end": "2375700"
  },
  {
    "text": "- And more data and more compute. - And more data and compute, but he said the big leaps has to do",
    "start": "2375700",
    "end": "2380920"
  },
  {
    "text": "with not the data and the compute, but just learning this new discipline, just like you said.",
    "start": "2380920",
    "end": "2386830"
  },
  {
    "text": "So researchers are going to\nlook at these architectures and there might be big\nleaps where you realize,",
    "start": "2386830",
    "end": "2392447"
  },
  {
    "text": "\"Wait, why are we doing\nthis in this dumb way?\" And all of a sudden this\nmodel is 10x smarter. And that that can happen on any one day,",
    "start": "2392447",
    "end": "2399460"
  },
  {
    "text": "on any one Tuesday or Wednesday afternoon. And then all of a sudden you have a system that's 10x smarter.",
    "start": "2399460",
    "end": "2404922"
  },
  {
    "text": "It seems like it's such a new discipline, it's such a new, like we understand so little about why this thing works so damn well,",
    "start": "2405760",
    "end": "2412570"
  },
  {
    "text": "that the linear improvement of compute, or exponential, but the steady improvement of compute,",
    "start": "2412570",
    "end": "2417790"
  },
  {
    "text": "steady improvement of the data may not be the thing that\neven leads to the next leap. It could be a surprise little\nhack that improves everything.",
    "start": "2417790",
    "end": "2424180"
  },
  {
    "text": "- Or a lot of little leaps here and there because so much of this\nis out in the open also,",
    "start": "2424180",
    "end": "2430000"
  },
  {
    "text": "so many smart people are looking at this and trying to figure out\nlittle leaps here and there, and it becomes this sort\nof collective race where,",
    "start": "2431680",
    "end": "2439510"
  },
  {
    "text": "a lot of people feel, \"If I don't take the\nleap someone else will,\" and it is actually very crucial\nfor the other part of it,",
    "start": "2439510",
    "end": "2445930"
  },
  {
    "text": "why do we wanna slow this down? So again, what this open\nletter is calling for is just pausing all training",
    "start": "2445930",
    "end": "2453500"
  },
  {
    "text": "of systems that are more powerful\nthan GPT-4 for six months.",
    "start": "2454540",
    "end": "2459540"
  },
  {
    "text": "Just give a chance for the labs to coordinate\na bit on safety,",
    "start": "2459580",
    "end": "2466270"
  },
  {
    "text": "and for society to adapt, give the right incentives to the labs. 'cause I, you know,",
    "start": "2466270",
    "end": "2471430"
  },
  {
    "text": "you've interviewed a lot of\nthese people who lead these labs and you know just as well as I do",
    "start": "2471430",
    "end": "2476442"
  },
  {
    "text": "that they're good people, they're idealistic people. They're doing this first and foremost because they believe that AI",
    "start": "2476443",
    "end": "2482650"
  },
  {
    "text": "has a huge potential to help humanity. But at the same time they are trapped",
    "start": "2482650",
    "end": "2489520"
  },
  {
    "text": "in this horrible race to the bottom.",
    "start": "2489520",
    "end": "2493093"
  },
  {
    "text": "Have you read \"Meditations on Moloch\" by Scott Alexander? - [Lex] Yes.",
    "start": "2496240",
    "end": "2501663"
  },
  {
    "text": "- Yeah, it's a beautiful\nessay on this poem by Ginsberg where he interprets it as\nbeing about this monster.",
    "start": "2501663",
    "end": "2507973"
  },
  {
    "text": "It's this game theory\nmonster that pits people against each other in\nthis race to the bottom",
    "start": "2509830",
    "end": "2516010"
  },
  {
    "text": "where everybody ultimately loses. And the evil thing about this monster is even though everybody\nsees it and understands,",
    "start": "2516010",
    "end": "2522130"
  },
  {
    "text": "they still can't get\nout of the race, right? A good fraction of all the\nbad things that we humans do",
    "start": "2522130",
    "end": "2528430"
  },
  {
    "text": "are caused by Moloch. And I like Scott Alexander's\nnaming of the monster.",
    "start": "2528430",
    "end": "2534687"
  },
  {
    "text": "So we can, we humans can think of it as a thing.",
    "start": "2535000",
    "end": "2539233"
  },
  {
    "text": "If you look at why do we have overfishing, why do we have more generally, the tragedy of the commons.",
    "start": "2540400",
    "end": "2546369"
  },
  {
    "text": "Why is it that, so Liv Boeree, I don't know if you've\nhad her on your podcast. - Mhm, yeah.",
    "start": "2546370",
    "end": "2551766"
  },
  {
    "text": "She's become a friend, yeah. - Great, she made this\nawesome point recently that beauty filters that a lot of female",
    "start": "2551766",
    "end": "2559970"
  },
  {
    "text": "influencers feel pressure to use, are exactly Moloch in action again. First, nobody was using them,",
    "start": "2561610",
    "end": "2567912"
  },
  {
    "text": "and people saw them\njust the way they were, and then some of 'em started using it,",
    "start": "2568780",
    "end": "2572960"
  },
  {
    "text": "and becoming ever more plastic fantastic, and then the other ones\nthat weren't using it started to realize that,",
    "start": "2573970",
    "end": "2579733"
  },
  {
    "text": "if they wanna to keep\ntheir their market share, they have to start using it too.",
    "start": "2580570",
    "end": "2586240"
  },
  {
    "text": "And then you're in a situation\nwhere they're all using it, and none of them has any more market share",
    "start": "2586240",
    "end": "2591310"
  },
  {
    "text": "or less than before. So nobody gained anything, everybody lost,",
    "start": "2591310",
    "end": "2595393"
  },
  {
    "text": "and they have to keep becoming ever more plastic fantastic also, right?",
    "start": "2596830",
    "end": "2600493"
  },
  {
    "text": "But nobody can go back to the old way because it's just too costly, right?",
    "start": "2602650",
    "end": "2608713"
  },
  {
    "text": "Moloch is everywhere, and Moloch is not a new\narrival on the scene either.",
    "start": "2609610",
    "end": "2616240"
  },
  {
    "text": "We humans have developed a lot\nof collaboration mechanisms to help us fight back against Moloch",
    "start": "2616240",
    "end": "2621579"
  },
  {
    "text": "through various kinds of\nconstructive collaboration. The Soviet Union and the United States",
    "start": "2621580",
    "end": "2627880"
  },
  {
    "text": "did sign a number of arms control treaties against Moloch who is trying to stoke them",
    "start": "2627880",
    "end": "2634030"
  },
  {
    "text": "into unnecessarily risky\nnuclear arms races, et cetera, et cetera. And this is exactly what's\nhappening on the AI front.",
    "start": "2634030",
    "end": "2642010"
  },
  {
    "text": "This time it's a little bit geopolitics, but it's mostly money, where there's just so\nmuch commercial pressure.",
    "start": "2642010",
    "end": "2648460"
  },
  {
    "text": "You know, if you take any of these leaders of the top tech companies,",
    "start": "2648460",
    "end": "2652723"
  },
  {
    "text": "if they just say, you know, \"This is too risky, I want\nto pause for six months.\"",
    "start": "2654280",
    "end": "2659440"
  },
  {
    "text": "They're gonna get a lot of pressure from shareholders and others. They're like, \"Well\nyou know, if you pause,",
    "start": "2659440",
    "end": "2666280"
  },
  {
    "text": "but those guys don't pause. We don't wanna get our lunch eaten.\"",
    "start": "2666280",
    "end": "2671410"
  },
  {
    "text": "- [Lex] Yeah. - And shareholders even have the power to replace the executives\nin the worst case, right?",
    "start": "2671410",
    "end": "2677380"
  },
  {
    "text": "So we did this open letter\nbecause we want to help these idealistic tech executives to do",
    "start": "2677380",
    "end": "2686080"
  },
  {
    "text": "what their heart tells them, by providing enough public\npressure on the whole sector.",
    "start": "2686080",
    "end": "2691120"
  },
  {
    "text": "Just pause, so that they can all pause in a coordinated fashion. And I think without the public pressure,",
    "start": "2691120",
    "end": "2697330"
  },
  {
    "text": "none of them can do it alone. Push back against their shareholders",
    "start": "2697330",
    "end": "2702460"
  },
  {
    "text": "no matter how goodhearted they are, 'cause Moloch is a really powerful foe.",
    "start": "2702460",
    "end": "2707405"
  },
  {
    "text": "- So the idea is to, for the major developers\nof AI systems like this,",
    "start": "2709000",
    "end": "2715060"
  },
  {
    "text": "so we're talking about Microsoft, Google, Meta, and anyone else.",
    "start": "2715060",
    "end": "2722028"
  },
  {
    "text": "- Well OpenAI is very\nclose with Microsoft now, - With Microsoft, right, yeah.\n- of course, - And there there are\nplenty of smaller players.",
    "start": "2722028",
    "end": "2728653"
  },
  {
    "text": "for example, Anthropic\nis is very impressive, there's Conjecture, there's many, many, many players,",
    "start": "2729610",
    "end": "2735009"
  },
  {
    "text": "I don't wanna make a long list that sort of leave anyone out. And for that reason,",
    "start": "2735010",
    "end": "2740710"
  },
  {
    "text": "it's so important that\nsome coordination happens, that there's external\npressure on all of them,",
    "start": "2740710",
    "end": "2746800"
  },
  {
    "text": "saying, \"You all need the pause.\" 'Cause then, the people, the researchers in there\nat these organizations,",
    "start": "2746800",
    "end": "2753370"
  },
  {
    "text": "the leaders who wanna\nslow down a little bit, they can say to their\nshareholders, you know,",
    "start": "2753370",
    "end": "2757023"
  },
  {
    "text": "\"Everybody's slowing down\nbecause of this pressure and it's the right thing to do.\" - Have you seen in history,",
    "start": "2758627",
    "end": "2765310"
  },
  {
    "text": "there examples what it's possible to pause the Moloch?\n- Yes, absolutely.",
    "start": "2765310",
    "end": "2770650"
  },
  {
    "text": "And even like human cloning for example, you could make so much\nmoney on human cloning.",
    "start": "2770650",
    "end": "2774960"
  },
  {
    "text": "Why aren't we doing it? Because biologists thought hard about this",
    "start": "2778390",
    "end": "2783970"
  },
  {
    "text": "and felt like this is way too risky, they got together in the\nseventies in Asilomar,",
    "start": "2783970",
    "end": "2790930"
  },
  {
    "text": "and decided even to stop a lot more stuff, also just editing the\nhuman germline, right?",
    "start": "2790930",
    "end": "2796753"
  },
  {
    "text": "Gene editing that goes\nin to our offspring,",
    "start": "2797650",
    "end": "2801973"
  },
  {
    "text": "and decided, \"Let's not do this because it's too unpredictable\nwhat it's gonna lead to,\"",
    "start": "2802930",
    "end": "2808207"
  },
  {
    "text": "we could lose control over\nwhat happens to our species,\" so they paused.",
    "start": "2809170",
    "end": "2812863"
  },
  {
    "text": "There was a ton of money to be made there, So it's very doable, but you need a public awareness\nof what the risks are,",
    "start": "2814180",
    "end": "2822250"
  },
  {
    "text": "and the broader community\ncoming in and saying, \"Hey, let's slow down.\" And you know, another\ncommon pushback I get today,",
    "start": "2822250",
    "end": "2829750"
  },
  {
    "text": "is that we can't stop in\nthe West because China.",
    "start": "2829750",
    "end": "2833713"
  },
  {
    "text": "And in China undoubtedly, they also get told, \"We can't\nslow down because the West,\" because both sides think\nthey're the good guy.",
    "start": "2835660",
    "end": "2842559"
  },
  {
    "text": "- [Lex] Yeah. - But look at human cloning, you know? Did China forge ahead with human cloning?",
    "start": "2842560",
    "end": "2848980"
  },
  {
    "text": "There's been exactly one human cloning that's actually been done that I know of. It was done by a Chinese guy.",
    "start": "2848980",
    "end": "2854200"
  },
  {
    "text": "Do you know where he is now? - [Lex] Where? - In jail. And you know who put him there?",
    "start": "2854200",
    "end": "2859690"
  },
  {
    "text": "- [Lex] Who? - Chinese government. Not because Westerners said, \"China look, this is...\"",
    "start": "2859690",
    "end": "2865720"
  },
  {
    "text": "No the Chinese government put him there 'cause they also felt, they like control, the Chinese government.",
    "start": "2865720",
    "end": "2871750"
  },
  {
    "text": "If anything, maybe they're\neven more concerned about having control than Western governments,",
    "start": "2871750",
    "end": "2877180"
  },
  {
    "text": "have no incentive of just losing control over where everything is going, and you can also see the Ernie Bot",
    "start": "2877180",
    "end": "2883330"
  },
  {
    "text": "that was released by, I believe, Baidu recently, they got a lot of pushback\nfrom the government",
    "start": "2883330",
    "end": "2888910"
  },
  {
    "text": "and had to rein it in,\nyou know, in a big way. I think once this basic message comes out",
    "start": "2888910",
    "end": "2895240"
  },
  {
    "text": "that this isn't an arms\nrace, it's a suicide race, where everybody loses",
    "start": "2895240",
    "end": "2900700"
  },
  {
    "text": "if anybody's AI goes out of control, it really changes the whole dynamic. It's not,",
    "start": "2900700",
    "end": "2906672"
  },
  {
    "text": "and I'll say this again 'cause this is this very basic point I think a lot of people get wrong. Because a lot of people\ndismiss the whole idea",
    "start": "2909550",
    "end": "2918220"
  },
  {
    "text": "that AI can really get very superhuman because they think there's something really magical about intelligence",
    "start": "2918220",
    "end": "2925150"
  },
  {
    "text": "such that it can only\nexist in human minds, you know, because they believe that, they think it's gonna kind\nof get to just more or less",
    "start": "2925150",
    "end": "2931060"
  },
  {
    "text": "\"GPT-4 plus plus,\" and then that's it. They don't see it as a suicide race.",
    "start": "2932237",
    "end": "2938500"
  },
  {
    "text": "They think whoever gets that first, they're gonna control the world, they're gonna win. That's not how it's gonna be.",
    "start": "2938500",
    "end": "2944140"
  },
  {
    "text": "And we can talk again about\nthe scientific arguments from why it's not gonna stop there.",
    "start": "2944140",
    "end": "2949600"
  },
  {
    "text": "But the way it's gonna be, is if anybody completely loses control and you know, you don't care",
    "start": "2949600",
    "end": "2956510"
  },
  {
    "text": "if someone manages to take over the world who really doesn't share your goals, you probably don't really\neven care very much",
    "start": "2959652",
    "end": "2965770"
  },
  {
    "text": "about what nationality they have, you're not gonna like it\nmuch worse than today.",
    "start": "2965770",
    "end": "2969793"
  },
  {
    "text": "If you live in Orwellian dystopia, what do you care who's created it, right?",
    "start": "2971080",
    "end": "2976660"
  },
  {
    "text": "And if someone, if it goes farther, and we just lose control\neven to the machines,",
    "start": "2976660",
    "end": "2983323"
  },
  {
    "text": "so that it's not us versus them, it's us versus it. What do you care who created\nthis unaligned entity",
    "start": "2985390",
    "end": "2993460"
  },
  {
    "text": "which has goals different\nfrom humans, ultimately? And we get marginalized,\nwe get made obsolete,",
    "start": "2993460",
    "end": "2999610"
  },
  {
    "text": "we get replaced. That's what I mean when I\nsay it's a suicide race,",
    "start": "2999610",
    "end": "3005620"
  },
  {
    "text": "it's kind of like we're\nrushing towards this cliff, but the closer the cliff we get, the more scenic the views are,",
    "start": "3007129",
    "end": "3012900"
  },
  {
    "text": "and the more money there is there, and the more, so we keep going, but we have to also stop\nat some point, right?",
    "start": "3012900",
    "end": "3018930"
  },
  {
    "text": "Quit while we're ahead, And it's,",
    "start": "3018930",
    "end": "3023133"
  },
  {
    "text": "it's a suicide race which cannot be won, but the way to really benefit from it is,",
    "start": "3027483",
    "end": "3033692"
  },
  {
    "text": "to continue developing awesome\nAI a little bit slower. So we make it safe,",
    "start": "3034530",
    "end": "3040050"
  },
  {
    "text": "make sure it does the\nthings that humans want, and create a condition\nwhere everybody wins. The technology has shown us that,",
    "start": "3040050",
    "end": "3047880"
  },
  {
    "text": "you know, geopolitics\nand politics in general is not a zero sum game at all.",
    "start": "3047880",
    "end": "3054180"
  },
  {
    "start": "3054000",
    "end": "4784000"
  },
  {
    "text": "- So there is some rate of\ndevelopment that will lead us as a human species to\nlose control of this thing.",
    "start": "3054180",
    "end": "3062010"
  },
  {
    "text": "And the hope you have is that there's some\nlower level of development",
    "start": "3062010",
    "end": "3066130"
  },
  {
    "text": "which will not allow us to lose control. This is an interesting thought you have about losing control, so if you have somebody,",
    "start": "3067841",
    "end": "3073560"
  },
  {
    "text": "if you are somebody like Sundar Pichai or Sam Altman at the head\nof a company like this,",
    "start": "3073560",
    "end": "3078870"
  },
  {
    "text": "you're saying if they develop an AGI, they too will lose control of it.",
    "start": "3078870",
    "end": "3083313"
  },
  {
    "text": "So no one person can maintain control, no group of individuals\ncan maintain control. - If it's created very, very soon",
    "start": "3084420",
    "end": "3092490"
  },
  {
    "text": "and is a big black box\nthat we don't understand like the large language models, yeah. Then I'm very confident\nthey're gonna lose control.",
    "start": "3092490",
    "end": "3099089"
  },
  {
    "text": "But this isn't just me\nsaying it, you know, Sam Altman and Demis Hassabis have both said,",
    "start": "3099090",
    "end": "3104132"
  },
  {
    "text": "they themselves acknowledge that, you know, there's really\ngreat risks for this and they want slow down once\nthey feel it gets scary.",
    "start": "3105030",
    "end": "3111423"
  },
  {
    "text": "But it's clear that they're stuck in this, again, Moloch is forcing\nthem to go a little faster",
    "start": "3112654",
    "end": "3117869"
  },
  {
    "text": "than they're comfortable with because of pressure from, just commercial pressures, right?",
    "start": "3117870",
    "end": "3122099"
  },
  {
    "text": "To get a bit optimistic here, of course, this is a problem\nthat can be ultimately solved.",
    "start": "3123840",
    "end": "3128470"
  },
  {
    "text": "To win this wisdom race, it's clear that what we\nhope that was gonna happen hasn't happened.",
    "start": "3130980",
    "end": "3137190"
  },
  {
    "text": "The capability progress has gone faster than a lot of people thought, and the progress in the public sphere",
    "start": "3137190",
    "end": "3144089"
  },
  {
    "text": "of policy making and so on, has gone slower than we thought. Even the technical AI\nsafety has gone slower.",
    "start": "3144090",
    "end": "3149100"
  },
  {
    "text": "A lot of the technical safety research was kind of banking on\nthat large language models",
    "start": "3149100",
    "end": "3154770"
  },
  {
    "text": "and other poorly understood systems couldn't get us all the way. That you had to build more\nof a kind of intelligence that you could understand.",
    "start": "3154770",
    "end": "3161280"
  },
  {
    "text": "Maybe it could prove itself safe, you know, things like this, and I'm quite confident\nthat this can be done",
    "start": "3161280",
    "end": "3170400"
  },
  {
    "text": "so we can reap all the benefits, but we cannot do it as quickly as this out of control\nexpress train we are on now",
    "start": "3170400",
    "end": "3179100"
  },
  {
    "text": "is gonna get to AGI. That's why we need a\nlittle more time, I feel. - Is there something to be said,",
    "start": "3179100",
    "end": "3185670"
  },
  {
    "text": "well like Sam Altman talked about, which is while we're in the pre-AGI stage,",
    "start": "3185670",
    "end": "3191160"
  },
  {
    "text": "to release often and as\ntransparently as possible to learn a lot.",
    "start": "3191160",
    "end": "3197490"
  },
  {
    "text": "So as opposed to being extremely cautious, release a lot,",
    "start": "3197490",
    "end": "3201122"
  },
  {
    "text": "don't invest in a closed development where you focus on the AI safety. While it's somewhat \"dumb,\"",
    "start": "3202598",
    "end": "3209400"
  },
  {
    "text": "quote-unquote, release as often as possible. And as you start to see signs\nof human-level intelligence",
    "start": "3209400",
    "end": "3218270"
  },
  {
    "text": "and or superhuman level intelligence, then you put a halt on it. Well what a lot of safety researchers",
    "start": "3218277",
    "end": "3224853"
  },
  {
    "text": "have been saying for many years is that the most dangerous\nthings you can do with an AI is first of all\nteach it to write code.",
    "start": "3224853",
    "end": "3232260"
  },
  {
    "text": "- [Lex] Yeah. - Because that's the first step towards recursive self-improvement, which can take it from\nAGI to much higher levels.",
    "start": "3232260",
    "end": "3238650"
  },
  {
    "text": "Okay? Oops, we've done that. And another thing high risk",
    "start": "3238650",
    "end": "3244350"
  },
  {
    "text": "is connect it to the internet, let it go to websites, download stuff on its\nown and talk to people.",
    "start": "3244350",
    "end": "3249753"
  },
  {
    "text": "Oops, we've done that already. You know Eliezer Yudkowsky, you said you interviewed\nhim recently, right? - [Lex] Yes, yep.",
    "start": "3250830",
    "end": "3255906"
  },
  {
    "text": "- So he had this tweet\nrecently which said, gave me one of the best laughs in a while, where he is like,",
    "start": "3255906",
    "end": "3261023"
  },
  {
    "text": "\"Hey, people used to\nmake fun of me and say, 'You're so stupid, Eliezer.' 'Cause you're saying",
    "start": "3261023",
    "end": "3265030"
  },
  {
    "text": "you have to worry of obviously developers once they get to like really strong AI,",
    "start": "3267480",
    "end": "3272730"
  },
  {
    "text": "first thing you're gonna do is like, never connect it to the internet, keep it in a box. where you know, you can\nreally study it safe.\"",
    "start": "3272730",
    "end": "3279807"
  },
  {
    "text": "So he had written it in\nthe like in the meme form so it's like \"Then,\" and then that, and then, \"Now.\"",
    "start": "3280950",
    "end": "3287557"
  },
  {
    "text": "(Lex laughing) \"LOL, let's make a chatbot.\" (both laughing) - [Lex] Yeah, yeah, yeah.",
    "start": "3287557",
    "end": "3293910"
  },
  {
    "text": "- And the third thing is Stuart Russell. - [Lex] Yeah. - You know, amazing AI researcher.",
    "start": "3293910",
    "end": "3299913"
  },
  {
    "text": "He has argued for a while\nthat we should never teach AI anything about humans.",
    "start": "3301230",
    "end": "3308369"
  },
  {
    "text": "Above all, we should never let it learn about human psychology and\nhow you manipulate humans.",
    "start": "3308370",
    "end": "3313890"
  },
  {
    "text": "That's the most dangerous kind\nof knowledge you can give it. Yeah, you can teach it\nall it needs to know about how to cure cancer\nand stuff like that.",
    "start": "3313890",
    "end": "3319980"
  },
  {
    "text": "But don't let it read\nDaniel Kahneman's book about cognitive biases and all that.",
    "start": "3319980",
    "end": "3325317"
  },
  {
    "text": "And then oops, \"LOL, you know, let's invent social media",
    "start": "3325317",
    "end": "3330160"
  },
  {
    "text": "recommender algorithms\nwhich do exactly that.\" They get so good at knowing\nus and pressing our buttons",
    "start": "3331400",
    "end": "3339700"
  },
  {
    "text": "that we are starting to create a world now where we just have ever more hatred,",
    "start": "3340680",
    "end": "3345513"
  },
  {
    "text": "'cause they've figured\nout that these algorithms, not for out of evil, but just to make money on advertising,",
    "start": "3346590",
    "end": "3351900"
  },
  {
    "text": "that the best way to get more engagement, the euphemism, get people glued to their\nlittle rectangles, right?",
    "start": "3351900",
    "end": "3358410"
  },
  {
    "text": "Is just to make them pissed off. - Well that's really interesting that a large AI system that's\ndoing the recommender system",
    "start": "3358410",
    "end": "3365849"
  },
  {
    "text": "kind of task on social media, is basically just studying human beings because it's a bunch of\nus rats giving it signal,",
    "start": "3365850",
    "end": "3374819"
  },
  {
    "text": "nonstop signal. It'll show a thing and\nthen we give signal, and whether we spread that\nthing, we like that thing,",
    "start": "3374820",
    "end": "3380910"
  },
  {
    "text": "that thing increases our engagement, gets us to return to the platform, and it has that on the scale of hundreds of millions\nof people constantly.",
    "start": "3380910",
    "end": "3387870"
  },
  {
    "text": "So it's just learning, and\nlearning, and learning, and presumably if the number of parameters in the neural network\nthat's doing the learning,",
    "start": "3387870",
    "end": "3394290"
  },
  {
    "text": "and more end to end the learning is, the more it's able to\njust basically encode",
    "start": "3394290",
    "end": "3401280"
  },
  {
    "text": "how to manipulate human behavior. - [Max] Exactly. - How to control humans at scale. - Exactly, and that is\nnot something you think",
    "start": "3401280",
    "end": "3407430"
  },
  {
    "text": "is in humanity's interest. And right now it's mainly letting some humans manipulate other\nhumans for profit and power,",
    "start": "3407430",
    "end": "3416660"
  },
  {
    "text": "which already caused a lot of damage, and then eventually that's a sort of skill",
    "start": "3417750",
    "end": "3423840"
  },
  {
    "text": "that can make AI persuade\nhumans to let them escape",
    "start": "3423840",
    "end": "3427870"
  },
  {
    "text": "whatever safety precautions we had put, you know, there was a really nice article in the New York Times\nrecently by Yuval Noah Harari",
    "start": "3428880",
    "end": "3436859"
  },
  {
    "text": "and two co-authors\nincluding Tristan Harris from \"The Social Dilemma,\" and we have this phrase in there I love,",
    "start": "3436860",
    "end": "3443970"
  },
  {
    "text": "It said, \"Humanity's first\ncontact with advanced AI",
    "start": "3443970",
    "end": "3448300"
  },
  {
    "text": "was social media.\" And we lost that one. We now live in a country",
    "start": "3449640",
    "end": "3455970"
  },
  {
    "text": "where there's much more hate in the world where there's much more hate, in fact.",
    "start": "3455970",
    "end": "3460980"
  },
  {
    "text": "And in our democracy than\nwe're having this conversation, and people can't even agree on who won the last election, you know.",
    "start": "3460980",
    "end": "3467940"
  },
  {
    "text": "And we humans often point fingers at other humans and say it's their fault, but it's really Moloch\nin these AI algorithms.",
    "start": "3467940",
    "end": "3475053"
  },
  {
    "text": "We got the algorithms and then Moloch pitted the social media\ncompanies against each other",
    "start": "3477210",
    "end": "3482250"
  },
  {
    "text": "so nobody could have a\nless creepy algorithm 'cause then they would lose out on revenue to the other company. - Is there any way to win that battle back",
    "start": "3482250",
    "end": "3489150"
  },
  {
    "text": "if we just linger on this one battle that we've lost in terms of social media, is it possible to redesign social media,",
    "start": "3489150",
    "end": "3496950"
  },
  {
    "text": "this very medium in which\nwe use as a civilization to communicate with each other,",
    "start": "3496950",
    "end": "3502500"
  },
  {
    "text": "to have these kinds of conversation, to have discourse, to try to figure out how to solve the biggest problems in the world,",
    "start": "3502500",
    "end": "3508410"
  },
  {
    "text": "whether that's nuclear war\nor the development of AGI. Is is it possible to do\nsocial media correctly?",
    "start": "3508410",
    "end": "3515940"
  },
  {
    "text": "- I think it's not only\npossible, but it's necessary. Who are we kidding? That we're gonna be able to\nsolve all these other challenges",
    "start": "3515940",
    "end": "3522090"
  },
  {
    "text": "if we can't even have a\nconversation with each other? It's constructive. The whole idea, the key idea of democracy",
    "start": "3522090",
    "end": "3528090"
  },
  {
    "text": "is that you get a bunch of people together and they have a real conversation. The ones you try to foster on this podcast",
    "start": "3528090",
    "end": "3533970"
  },
  {
    "text": "where you respectfully listen\nto people you disagree with. And you realize actually, you know, there are some things actually",
    "start": "3533970",
    "end": "3540030"
  },
  {
    "text": "some common ground we have and let's, we both agree, let's not\nhave any nuclear wars, let's not do that, et cetera, et cetera.",
    "start": "3540030",
    "end": "3547652"
  },
  {
    "text": "We're kidding ourselves that\nthinking we can face off the second contact with\never more powerful AI",
    "start": "3549060",
    "end": "3556380"
  },
  {
    "text": "that's happening now with these large language\nmodels if we can't even have a functional conversation\nin the public space.",
    "start": "3556380",
    "end": "3565530"
  },
  {
    "text": "That's why I started the\nImprove The News project, improvethenews.org. But I'm an optimist fundamentally,",
    "start": "3565530",
    "end": "3573632"
  },
  {
    "text": "in that there is a lot of\nintrinsic goodness in people.",
    "start": "3576716",
    "end": "3579466"
  },
  {
    "text": "And that what makes the difference between someone doing\ngood things for humanity",
    "start": "3581760",
    "end": "3588000"
  },
  {
    "text": "and bad things is not some\nsort of fairytale thing, that this person was\nborn with the evil gene",
    "start": "3588000",
    "end": "3593700"
  },
  {
    "text": "and this one is born with the good gene. No, I think it's whether we put, whether people find\nthemselves in situations",
    "start": "3593700",
    "end": "3601590"
  },
  {
    "text": "that bring out the best in them or that bring out the worst in them. And I feel we're building an internet",
    "start": "3601590",
    "end": "3608260"
  },
  {
    "text": "and a society that brings out the worst.",
    "start": "3609180",
    "end": "3612543"
  },
  {
    "text": "- But it doesn't have to be that way. - [Max] No, it does not. - It's possible to create incentives and also create incentives\nthat make money.",
    "start": "3614310",
    "end": "3622680"
  },
  {
    "text": "That both make money and\nbring out the best in people. - I mean, in the long term, it's not a good investment\nfor anyone, you know,",
    "start": "3622680",
    "end": "3627840"
  },
  {
    "text": "to have a nuclear war, for example. And you know, is it a good investment for humanity if we just ultimately replace\nall humans by machines,",
    "start": "3627840",
    "end": "3635670"
  },
  {
    "text": "and then we're so\nobsolete that eventually, there are no humans left? Well, it depends guess\nhow you do the math,",
    "start": "3635670",
    "end": "3643079"
  },
  {
    "text": "But I would say by any\nreasonable economic standard, if you look at the future income of humans",
    "start": "3643080",
    "end": "3648510"
  },
  {
    "text": "and there aren't any, you know, that's not a good investment. Moreover, like why can't we have",
    "start": "3648510",
    "end": "3655560"
  },
  {
    "text": "a little bit of pride\nin our species, damn it? You know, why should we just build another species that gets rid of us?",
    "start": "3655560",
    "end": "3661859"
  },
  {
    "text": "If we were Neanderthals, would we really consider it a smart move",
    "start": "3661860",
    "end": "3667330"
  },
  {
    "text": "if we had really advanced\nbiotech to build Homo sapiens? You know, you might say, \"Hey Max, you know,",
    "start": "3669073",
    "end": "3674733"
  },
  {
    "text": "yeah, let's build, these Homo sapiens, they're\ngonna be smarter than us,",
    "start": "3674733",
    "end": "3680310"
  },
  {
    "text": "maybe they can help us, defend us better against predators and help fix up our\ncaves, make them nicer,",
    "start": "3680310",
    "end": "3687240"
  },
  {
    "text": "we'll control 'em undoubtedly, you know?\" So then they build a couple, a little baby girl, little baby boy.",
    "start": "3687240",
    "end": "3692730"
  },
  {
    "text": "They either, and then you have some wise\nold Neanderthal elder is like,",
    "start": "3692730",
    "end": "3699487"
  },
  {
    "text": "\"Hmm, I'm scared that we're\nopening a Pandora's box here",
    "start": "3699487",
    "end": "3704487"
  },
  {
    "text": "and that we're gonna\nget outsmarted by these",
    "start": "3704517",
    "end": "3707170"
  },
  {
    "text": "super Neanderthal intelligences, and there won't be any Neanderthals left.\"",
    "start": "3710070",
    "end": "3715320"
  },
  {
    "text": "But then you have a bunch of\nothers in the cave, right? \"You're such a Luddite scaremonger. Of course, they're gonna\nwant to keep us around",
    "start": "3715320",
    "end": "3720960"
  },
  {
    "text": "'cause we are their creators, and, you know, the smarter, I think the smarter they get, the nicer they're gonna get,",
    "start": "3720960",
    "end": "3726300"
  },
  {
    "text": "they're gonna leave us. They're gonna want us around\nand it's gonna be fine,",
    "start": "3726300",
    "end": "3731520"
  },
  {
    "text": "and besides look at these\nbabies, they're so cute. Clearly they're totally harmless.\"",
    "start": "3731520",
    "end": "3736680"
  },
  {
    "text": "Those babies are exactly GPT-4. It's not, I wanna be clear, it's not GPT-4 that's terrifying.",
    "start": "3736680",
    "end": "3745290"
  },
  {
    "text": "It's that GPT-4 is a baby technology, you know, and Microsoft even\nhad a paper recently out,",
    "start": "3745290",
    "end": "3751560"
  },
  {
    "text": "titled something like, \"Sparkles of AGI.\" Well they were basically\nsaying this is baby AI,",
    "start": "3753360",
    "end": "3759900"
  },
  {
    "text": "like these little Neanderthal babies, and it's gonna grow up. There's gonna be other\nsystems from the same company,",
    "start": "3759900",
    "end": "3768539"
  },
  {
    "text": "from other companies, they'll be way more powerful, but they're gonna take all the things, ideas from these babies\nand before we know it,",
    "start": "3768540",
    "end": "3777329"
  },
  {
    "text": "we're gonna be like\nthose last Neanderthals who were pretty disappointed",
    "start": "3777330",
    "end": "3782390"
  },
  {
    "text": "when they realized that\nthey were getting replaced. - Well, this interesting point you make, which is of programming,",
    "start": "3783480",
    "end": "3789090"
  },
  {
    "text": "it's entirely possible that GPT-4 is already the kind of system that can change everything\nby writing programs.",
    "start": "3789090",
    "end": "3798230"
  },
  {
    "text": "- Yeah, it's because it's life 2.0, the systems I'm afraid\nof are gonna look nothing",
    "start": "3799890",
    "end": "3805350"
  },
  {
    "text": "like a large language\nmodel, and they're not, but once it gets, once it or other people figure out a way",
    "start": "3805350",
    "end": "3812910"
  },
  {
    "text": "of using this tech to make\nmuch better tech, right? It's just constantly\nreplacing its software.",
    "start": "3812910",
    "end": "3818160"
  },
  {
    "text": "And from everything that we've seen about how these work under the hood, they're like the minimum\nviable intelligence.",
    "start": "3818160",
    "end": "3825510"
  },
  {
    "text": "They do everything, you know, the dumbest way that still works, sort of. - [Lex] Yeah. - And so they're life 3.0,",
    "start": "3825510",
    "end": "3833160"
  },
  {
    "text": "except when they replace their software, it's a lot faster than when\nyou decide to learn Swedish.",
    "start": "3833160",
    "end": "3839133"
  },
  {
    "text": "Poof. (fingers snapping) And moreover, they think\na lot faster than us too. So when, you know,",
    "start": "3840106",
    "end": "3847172"
  },
  {
    "text": "we don't think, have one logical step",
    "start": "3848010",
    "end": "3854310"
  },
  {
    "text": "every nanosecond or few, or so, the way they do, and we can't also just\nsuddenly scale up our hardware",
    "start": "3854310",
    "end": "3861930"
  },
  {
    "text": "massively in the cloud 'cause\nwe're so limited, right? So they are,",
    "start": "3861930",
    "end": "3866993"
  },
  {
    "text": "and they are also life, can soon become a little\nbit more like life 3.0",
    "start": "3866993",
    "end": "3874549"
  },
  {
    "text": "in that if they need more hardware, hey, just rent it in the cloud, you know? \"How do you pay for it?\" \"Well, with all the services you provide.\"",
    "start": "3874550",
    "end": "3881097"
  },
  {
    "text": "- And what we haven't seen yet, which could change a lot,",
    "start": "3884760",
    "end": "3889830"
  },
  {
    "text": "is entire software systems. So right now programming is\ndone sort of in bits and pieces",
    "start": "3889830",
    "end": "3897490"
  },
  {
    "text": "as an assistant tool to humans. But I do a lot of programming and with the kind of stuff\nthat GPT-4 is able to do,",
    "start": "3898350",
    "end": "3905760"
  },
  {
    "text": "I mean, it's replacing a lot\nwhat I'm able to do, right? You still need a human in the loop",
    "start": "3905760",
    "end": "3910799"
  },
  {
    "text": "to kind of manage the design of things, manage like, what are the prompts",
    "start": "3910800",
    "end": "3915810"
  },
  {
    "text": "that generate the kind of stuff to do some basic adjustment of the codes, do some debugging,",
    "start": "3915810",
    "end": "3921240"
  },
  {
    "text": "but if it's possible\nto add on top of GPT-4, kind of a feedback loop",
    "start": "3921240",
    "end": "3928060"
  },
  {
    "text": "of self-debugging, improving the code, and then you launch that\nsystem onto the wild",
    "start": "3929459",
    "end": "3935520"
  },
  {
    "text": "on the internet because\neverything is connected, and have it do things, have it interact with humans\nand then get that feedback,",
    "start": "3935520",
    "end": "3941340"
  },
  {
    "text": "now you have this giant\necosystem of humans. That's one of the things that",
    "start": "3941340",
    "end": "3945637"
  },
  {
    "text": "Elon Musk recently sort of tweeted as a case why everyone\nneeds to pay $7 or whatever",
    "start": "3946860",
    "end": "3952410"
  },
  {
    "text": "for Twitter, - [Max] To make sure they're real. - Make sure they're real, we're now going to be living in a world",
    "start": "3952410",
    "end": "3957540"
  },
  {
    "text": "where the bots are getting smarter, and smarter, and smarter\nto a degree where,",
    "start": "3957540",
    "end": "3962373"
  },
  {
    "text": "you can't tell the difference between a human and a bot. - [Max] That's right. - And now you can have\nbots outnumber humans",
    "start": "3964920",
    "end": "3970680"
  },
  {
    "text": "by 1 million to one. Which is why he's making a\ncase why you have to pay.",
    "start": "3970680",
    "end": "3976530"
  },
  {
    "text": "To prove you're human, which is one of the only\nmechanisms to prove, which is depressing. - And yeah,",
    "start": "3976530",
    "end": "3982500"
  },
  {
    "text": "I feel we have to remember, as individuals, we\nshould from time to time,",
    "start": "3982500",
    "end": "3988020"
  },
  {
    "text": "ask ourselves why are we\ndoing what we're doing, right? And as a species, we need to do that too.",
    "start": "3988020",
    "end": "3992047"
  },
  {
    "text": "So if we're building, as you say, machines that are outnumbering us,",
    "start": "3993090",
    "end": "3999360"
  },
  {
    "text": "and more and more outsmarting us, and replacing us on the job market, not just for the dangerous\nand and boring tasks,",
    "start": "3999360",
    "end": "4006559"
  },
  {
    "text": "but also for writing poems and doing art, and things that a lot of\npeople find really meaningful,",
    "start": "4006560",
    "end": "4012200"
  },
  {
    "text": "we gotta ask ourselves, why? Why are we doing this?",
    "start": "4012200",
    "end": "4014993"
  },
  {
    "text": "The answer is Moloch is\ntricking us into doing it. And it's such a clever trick",
    "start": "4017600",
    "end": "4023240"
  },
  {
    "text": "that even though we see the trick, we still have no choice\nbut to fall for it, right?",
    "start": "4023240",
    "end": "4027473"
  },
  {
    "text": "And also, thing you said about you using co-pilot AI tools to program faster,",
    "start": "4029447",
    "end": "4036770"
  },
  {
    "text": "how many, what factor faster would\nyou say you code now? Does it go twice as fast? Or,",
    "start": "4036770",
    "end": "4042530"
  },
  {
    "text": "- I don't really, because it's such a new tool. - [Max] Yeah. - I don't know if speed\nis significantly improved,",
    "start": "4042530",
    "end": "4049553"
  },
  {
    "text": "but it feels like I'm a year away from being 5 to 10 times faster.",
    "start": "4050480",
    "end": "4056930"
  },
  {
    "text": "- So if that's typical for programmers, then you're already seeing another kind",
    "start": "4056930",
    "end": "4062390"
  },
  {
    "text": "of recursive self-improvement, right? Because previously,",
    "start": "4062390",
    "end": "4067520"
  },
  {
    "text": "like a major generation of\nimprovement of the codes would happen on the\nhuman R and D time scale.",
    "start": "4067520",
    "end": "4073519"
  },
  {
    "text": "And now if that's five times shorter, then it's gonna take five times less time than it otherwise would to develop",
    "start": "4073520",
    "end": "4079640"
  },
  {
    "text": "the next level of these tools, and so on. So this is exactly the sort of beginning",
    "start": "4079640",
    "end": "4087323"
  },
  {
    "text": "of an intelligence explosion. There can be humans in the\nloop a lot in the early stages, and then eventually humans\nare needed less and less",
    "start": "4087323",
    "end": "4094307"
  },
  {
    "text": "and the machines can\nmore kind of go alone. But what you said there\nis just an exact example",
    "start": "4094307",
    "end": "4099799"
  },
  {
    "text": "of these sort of things. Another thing which,",
    "start": "4099800",
    "end": "4101790"
  },
  {
    "text": "I was kind of lying on my\npsychiatrist imagining, I'm on a psychiatrist couch here saying, \"Well what are my fears\nthat people would do",
    "start": "4105530",
    "end": "4111589"
  },
  {
    "text": "with AI systems?\" So I mentioned three\nthat I had fears about many years ago, that they would do,",
    "start": "4111590",
    "end": "4118759"
  },
  {
    "text": "namely teach it to code, connect it to the internet, and teach it to manipulate humans.",
    "start": "4118760",
    "end": "4125270"
  },
  {
    "text": "A fourth one is building an API, (Lex chuckles) where code can control this\nsuper powerful thing, right?",
    "start": "4125270",
    "end": "4132859"
  },
  {
    "text": "That's very unfortunate because one thing that systems like GPT-4\nhave going for them",
    "start": "4132860",
    "end": "4139400"
  },
  {
    "text": "is that they are an oracle in the sense that they just answer questions. There's no robot connected to GPT-4.",
    "start": "4139400",
    "end": "4147109"
  },
  {
    "text": "GPT-4 can't go and do stock trading based on its thinking. It is not an agent,",
    "start": "4147110",
    "end": "4153020"
  },
  {
    "text": "and an intelligent agent is something that takes in information from the world, processes it,",
    "start": "4153020",
    "end": "4157703"
  },
  {
    "text": "to figure out what action to take based on its goals that it has, and then does something back on the world.",
    "start": "4159230",
    "end": "4166520"
  },
  {
    "text": "But once you have an API for, for example, GPT-4, nothing stops Joe Schmoe and a lot of other people\nfrom building real agents,",
    "start": "4166520",
    "end": "4175699"
  },
  {
    "text": "which just keep making calls somewhere in some inner loop somewhere to these powerful oracle systems,",
    "start": "4175700",
    "end": "4181762"
  },
  {
    "text": "which makes themselves much more powerful. That's another kind of\nunfortunate development,",
    "start": "4183410",
    "end": "4188960"
  },
  {
    "text": "which I think we would've\nbeen better off delaying. I don't wanna pick on\nany particular companies,",
    "start": "4188960",
    "end": "4195080"
  },
  {
    "text": "I think they're all under a\nlot of pressure to make money. - [Lex] Yeah. - And again, the reason we're\nwe're calling for this pause",
    "start": "4195080",
    "end": "4204490"
  },
  {
    "text": "is to give them all cover to do what they know is the right thing, just slow down a little bit at this point.",
    "start": "4205010",
    "end": "4210320"
  },
  {
    "text": "But everything we've talked about, I hope we'll make it clear\nto people watching this,",
    "start": "4210320",
    "end": "4217107"
  },
  {
    "text": "you know, why these sort\nof human-level tools can cause a gradual acceleration.",
    "start": "4217107",
    "end": "4223670"
  },
  {
    "text": "You keep using yesterday's technology to build tomorrow's technology. And when you do that over and over again,",
    "start": "4223670",
    "end": "4230300"
  },
  {
    "text": "you naturally get an explosion. You know, that's the definition of an explosion in science, right?",
    "start": "4230300",
    "end": "4235073"
  },
  {
    "text": "If you have two people, and they fall in love,",
    "start": "4236570",
    "end": "4242150"
  },
  {
    "text": "now you have four people, and then they can make more babies, and now you have eight people,",
    "start": "4242150",
    "end": "4247159"
  },
  {
    "text": "and then you have 16, 32, 64, et cetera. We call that a population explosion",
    "start": "4247160",
    "end": "4253250"
  },
  {
    "text": "where it's just that each, if it's instead free neutrons\nin a nuclear reaction",
    "start": "4253250",
    "end": "4259190"
  },
  {
    "text": "that if each one can make more than one, then you get an\nexponential growth in that, we call it a nuclear explosion.",
    "start": "4259190",
    "end": "4265820"
  },
  {
    "text": "All explosions are like that, and an intelligence explosion, it's just exactly the same principle, that some amount of intelligence",
    "start": "4265820",
    "end": "4271280"
  },
  {
    "text": "can make more intelligence than that, and then repeat. You always get exponentials.",
    "start": "4271280",
    "end": "4277700"
  },
  {
    "text": "- What's your intuition why it does, you mentioned there's\nsome technical reasons why it doesn't stop at a certain point.",
    "start": "4277700",
    "end": "4283730"
  },
  {
    "text": "What's your intuition? And do you have any\nintuition why it might stop? - It's obviously gonna stop",
    "start": "4283730",
    "end": "4289429"
  },
  {
    "text": "when it bumps up against\nthe laws of physics. There are some things you just can't do no matter how smart you are, right?",
    "start": "4289430",
    "end": "4294500"
  },
  {
    "text": "- Allegedly. 'Cause we don't know all the full laws of physics yet, right?",
    "start": "4294500",
    "end": "4301130"
  },
  {
    "text": "- Seth Lloyd wrote a really cool paper on the physical limits on\ncomputation, for example. If you make it,",
    "start": "4301130",
    "end": "4307610"
  },
  {
    "text": "put too much energy into it and the finite space will\nturn into a black hole, you can't move information around",
    "start": "4307610",
    "end": "4313370"
  },
  {
    "text": "faster than the speed of\nlight, stuff like that. But it's hard to store way more than a modest number\nof bits per atom, et cetera.",
    "start": "4313370",
    "end": "4322760"
  },
  {
    "text": "But, you know, those limits are just astronomically above, like 30 orders of magnitude\nabove where we are now.",
    "start": "4322760",
    "end": "4329090"
  },
  {
    "text": "So, you know. Bigger difference, bigger\njump in intelligence",
    "start": "4329090",
    "end": "4334730"
  },
  {
    "text": "than if you go from ant to a human.",
    "start": "4334730",
    "end": "4338513"
  },
  {
    "text": "I think, of course what we want to do is have a controlled thing,",
    "start": "4340070",
    "end": "4346373"
  },
  {
    "text": "in a nuclear reactor you put moderators in to make sure exactly it doesn't blow up out of control, right?",
    "start": "4346373",
    "end": "4352489"
  },
  {
    "text": "When we do, experiments with biology\nand cells and so on,",
    "start": "4352490",
    "end": "4358400"
  },
  {
    "text": "you know, we also try to make sure it doesn't get out of control. We can do this with AI too.",
    "start": "4358400",
    "end": "4364430"
  },
  {
    "text": "The thing is, we haven't succeeded yet. And Moloch is exactly doing the opposite.",
    "start": "4364430",
    "end": "4371720"
  },
  {
    "text": "Just fueling, just egging everybody on, \"Faster, faster, faster, or the other company is\ngonna catch up with you,",
    "start": "4371720",
    "end": "4377977"
  },
  {
    "text": "or the other country is\ngonna catch up with you.\" We have to want to stop,",
    "start": "4377977",
    "end": "4383570"
  },
  {
    "text": "and I don't believe in just asking people to look into their hearts\nand do the right thing.",
    "start": "4384690",
    "end": "4390860"
  },
  {
    "text": "It's easier for others to say that, but like, if you are in this situation where your company is gonna get screwed",
    "start": "4390860",
    "end": "4397290"
  },
  {
    "text": "by other companies that are not stopping, you're putting people in\na very hard situation, the right thing to do",
    "start": "4401630",
    "end": "4406909"
  },
  {
    "text": "is change the whole\nincentive structure instead. And this is not an old,",
    "start": "4406910",
    "end": "4411413"
  },
  {
    "text": "maybe I should say one\nmore thing about this, 'cause Moloch has been around as humanity's number\none or number two enemy",
    "start": "4413030",
    "end": "4420770"
  },
  {
    "text": "since the beginning of civilization. And we came up with some\nreally cool countermeasures.",
    "start": "4420770",
    "end": "4426170"
  },
  {
    "text": "Like first of all, already over 100,000 years ago, evolution realized that\nit was very unhelpful",
    "start": "4426170",
    "end": "4433010"
  },
  {
    "text": "that people kept killing\neach other all the time. So it genetically gave us compassion",
    "start": "4433010",
    "end": "4439230"
  },
  {
    "text": "and made it so that, like if you get two drunk dudes getting into a pointless bar fight,",
    "start": "4440540",
    "end": "4445343"
  },
  {
    "text": "they might give each other black eyes, but they have a lot of inhibition towards just killing each other.",
    "start": "4446690",
    "end": "4453053"
  },
  {
    "text": "That's a, And similarly, if you find\na baby lying on the street, when you go out for your\nmorning jog tomorrow,",
    "start": "4454340",
    "end": "4460820"
  },
  {
    "text": "you're gonna stop and pick it up, right? Even though it maybe make you\nlate for your next podcast.",
    "start": "4460820",
    "end": "4466219"
  },
  {
    "text": "So evolution gave us these genes that make our own egoistic incentives",
    "start": "4466220",
    "end": "4471500"
  },
  {
    "text": "more aligned with what's good for the greater group\nwe're part of, right? And then as we got a\nbit more sophisticated",
    "start": "4471500",
    "end": "4480019"
  },
  {
    "text": "and developed language, we invented gossip, which is also a fantastic\nanti-Moloch, right?",
    "start": "4480020",
    "end": "4487026"
  },
  {
    "text": "'Cause now, it really discourages\nliars, moochers, cheaters,",
    "start": "4487026",
    "end": "4494410"
  },
  {
    "text": "because their own incentive\nnow is not to do this because word quickly gets around",
    "start": "4495260",
    "end": "4500990"
  },
  {
    "text": "and then suddenly people\naren't gonna invite them to their dinners anymore or trust them. And then when we got\nstill more sophisticated",
    "start": "4500990",
    "end": "4507650"
  },
  {
    "text": "in bigger societies, you know, we invented the legal system where even strangers who\ncouldn't rely on gossip",
    "start": "4507650",
    "end": "4514310"
  },
  {
    "text": "and things like this\nwould treat each other, would have an incentive. Now those guys in the bar fights,",
    "start": "4514310",
    "end": "4519350"
  },
  {
    "text": "even if someone is so drunk that he actually wants\nto kill the other guy,",
    "start": "4519350",
    "end": "4524783"
  },
  {
    "text": "he also has a little thought\nin the back of his head that, you know, \"Do I really wanna\nspend the next 10 years",
    "start": "4526250",
    "end": "4530848"
  },
  {
    "text": "eating like really crappy\nfood in a small room? I'm just gonna chill out,\" you know?",
    "start": "4532040",
    "end": "4538820"
  },
  {
    "text": "And we similarly have tried to give these incentives to our corporations by having regulation and\nall sorts of oversight",
    "start": "4538820",
    "end": "4545810"
  },
  {
    "text": "so that their incentives are\naligned with the greater good. We tried really hard, and the big problem\nthat we're failing now,",
    "start": "4545810",
    "end": "4554633"
  },
  {
    "text": "is not that we haven't tried before, but it's just that the tech is growing, is developing much faster",
    "start": "4555680",
    "end": "4561530"
  },
  {
    "text": "than the regulators been\nable to keep up, right? So regulators, it's kind of comical that\nthe European Union right now",
    "start": "4561530",
    "end": "4568190"
  },
  {
    "text": "is doing this AI act, right? And in the beginning they had\na little opt-out exception",
    "start": "4568190",
    "end": "4576080"
  },
  {
    "text": "that GPT-4 would be completely\nexcluded from regulation. Brilliant idea.",
    "start": "4576080",
    "end": "4581720"
  },
  {
    "text": "- What's the logic behind that? - Some lobbyists pushed\nsuccessfully for this?",
    "start": "4581720",
    "end": "4587449"
  },
  {
    "text": "So we were actually quite involved with the Future of Life Institute, Mark Brakel, Risto Uuk,",
    "start": "4587450",
    "end": "4592940"
  },
  {
    "text": "Anthony Aguirre, and others, you know, we're quite\ninvolved with talking to, educating various people\ninvolved in this process",
    "start": "4592940",
    "end": "4599119"
  },
  {
    "text": "about these general-purpose\nAI models coming, and pointing out that they\nwould become the laughing stock",
    "start": "4599120",
    "end": "4605420"
  },
  {
    "text": "if they didn't put it in. So the French started pushing for it, it got put in to the draft,",
    "start": "4605420",
    "end": "4610880"
  },
  {
    "text": "and it looked like all was good, and then there was a huge\ncounter push from lobbyists.",
    "start": "4610880",
    "end": "4616280"
  },
  {
    "text": "Yeah, there were more\nlobbyists in Brussels from tech companies than from\noil companies, for example.",
    "start": "4616280",
    "end": "4622489"
  },
  {
    "text": "And it looked like it might, this was gonna maybe get taken out again. And now GPT-4 happened,",
    "start": "4622490",
    "end": "4629090"
  },
  {
    "text": "and I think it's gonna stay in. But this just shows, you know, Moloch can be defeated.",
    "start": "4629090",
    "end": "4634313"
  },
  {
    "text": "But the challenge we're\nfacing is that the tech is generally much faster than\nwhat the policymakers are,",
    "start": "4635690",
    "end": "4643120"
  },
  {
    "text": "and a lot of the policymakers also don't have a tech background, so it's, you know,",
    "start": "4644420",
    "end": "4649610"
  },
  {
    "text": "we really need to work\nhard to educate them on what's taking place here.",
    "start": "4649610",
    "end": "4654860"
  },
  {
    "text": "So we're getting this situation where the first kind of, so I define artificial intelligence",
    "start": "4654860",
    "end": "4661340"
  },
  {
    "text": "just as non-biological\nintelligence, right? And by that definition,",
    "start": "4661340",
    "end": "4666233"
  },
  {
    "text": "a company, a corporation is\nalso an artificial intelligence because the corporation isn't its humans, it's a system.",
    "start": "4667490",
    "end": "4674000"
  },
  {
    "text": "If its CEO decides, if a CEO of a tobacco\ncompany decides one morning that she or he doesn't wanna\nsell cigarettes anymore,",
    "start": "4674000",
    "end": "4681020"
  },
  {
    "text": "they'll just put another CEO in there. It's not enough to align",
    "start": "4681020",
    "end": "4686120"
  },
  {
    "text": "the incentives of individual people or align individual computers'\nincentives to their owners,",
    "start": "4686120",
    "end": "4692960"
  },
  {
    "text": "which is what technically,\nAI safety research is about. You also have to align the\nincentives of corporations",
    "start": "4692960",
    "end": "4698810"
  },
  {
    "text": "with the greater good. And some corporations have\ngotten so big and so powerful very quickly that in many cases,",
    "start": "4698810",
    "end": "4706429"
  },
  {
    "text": "their lobbyists instead\nalign the regulators to what they want rather\nthan the other way round.",
    "start": "4706430",
    "end": "4713060"
  },
  {
    "text": "It's a classic regulatory capture. - Right, is the thing that\nthe slowdown hopes to achieve",
    "start": "4713060",
    "end": "4720440"
  },
  {
    "text": "is give enough time to\nregulators to catch up, or enough time to the companies themselves",
    "start": "4720440",
    "end": "4725690"
  },
  {
    "text": "to breathe and understand how to do AI safety correctly? - I think both, but I think that the vision,",
    "start": "4725690",
    "end": "4732020"
  },
  {
    "text": "the path to success I see is first you give a breather actually to the people in these companies,",
    "start": "4732020",
    "end": "4738079"
  },
  {
    "text": "their leadership who wants\nto do the right thing, and they all have safety teams and so on, on their companies,",
    "start": "4738080",
    "end": "4743119"
  },
  {
    "text": "give them a chance to get\ntogether with the other companies,",
    "start": "4743120",
    "end": "4747353"
  },
  {
    "text": "and the outside pressure can\nalso help catalyze that, right? And work out what is it that's,",
    "start": "4748730",
    "end": "4757283"
  },
  {
    "text": "what are the reasonable\nsafety requirements one should put on future systems\nbefore they get rolled out.",
    "start": "4758750",
    "end": "4765050"
  },
  {
    "text": "There are a lot of people also in academia and elsewhere outside of these companies who can be brought into this",
    "start": "4765050",
    "end": "4770347"
  },
  {
    "text": "and have a lot of very good ideas. And then I think it's very\nrealistic that within six months,",
    "start": "4770347",
    "end": "4776722"
  },
  {
    "text": "you can get these people coming up, so here's a white paper, here's what we all think it's reasonable.",
    "start": "4778070",
    "end": "4783472"
  },
  {
    "start": "4784000",
    "end": "5434000"
  },
  {
    "text": "You know, you didn't, just because cars killed a lot of people, you didn't ban cars, but they got together a bunch of people",
    "start": "4784443",
    "end": "4789770"
  },
  {
    "text": "and decided, you know, in order to be allowed to sell a car, it has to have a seatbelt in it.",
    "start": "4789770",
    "end": "4794130"
  },
  {
    "text": "They're the analogous things that you can start requiring\na future AI systems so that they are safe.",
    "start": "4794990",
    "end": "4803090"
  },
  {
    "text": "And once this heavy lifting,",
    "start": "4803090",
    "end": "4808090"
  },
  {
    "text": "this intellectual work has been done by experts in the field,\nwhich can be done quickly,",
    "start": "4808430",
    "end": "4813530"
  },
  {
    "text": "I think it's going to be quite easy to get policymakers to see, yeah, this is a good idea.",
    "start": "4813530",
    "end": "4819350"
  },
  {
    "text": "And it's, you know, for the companies to fight Moloch,",
    "start": "4819350",
    "end": "4825560"
  },
  {
    "text": "they want, and I believe Sam Altman has explicitly called for this, they want the regulators\nto actually adopt it",
    "start": "4825560",
    "end": "4830989"
  },
  {
    "text": "so that their competition is gonna abide by it too, right? You don't want,",
    "start": "4830990",
    "end": "4834703"
  },
  {
    "text": "you don't want to be\nenacting all these principles and then you abide by them, and then there's this one little company",
    "start": "4837140",
    "end": "4843770"
  },
  {
    "text": "that doesn't sign onto it and then now they can\ngradually overtake you.",
    "start": "4843770",
    "end": "4849680"
  },
  {
    "text": "Then the companies will get, be able to sleep secure knowing that everybody's playing\nby the same rules.",
    "start": "4849680",
    "end": "4856699"
  },
  {
    "text": "- So do you think it's\npossible to develop guardrails that keep the systems",
    "start": "4856700",
    "end": "4862349"
  },
  {
    "text": "from basically damaging\nirreparably humanity, while still enabling sort\nof the capitalist-fueled",
    "start": "4864830",
    "end": "4872270"
  },
  {
    "text": "competition between companies as they develop how to best\nmake money with this AI? You think there's a\nbalancing that's possible?",
    "start": "4872270",
    "end": "4879200"
  },
  {
    "text": "- Absolutely, I mean, we've seen that in many other sectors where you've had the free market produce quite good things",
    "start": "4879200",
    "end": "4884510"
  },
  {
    "text": "without causing particular harm. When the guardrails are there\nand they work, you know,",
    "start": "4884510",
    "end": "4891533"
  },
  {
    "text": "capitalism is a very\ngood way of optimizing for just getting the same\nthings done more efficiently.",
    "start": "4892970",
    "end": "4898163"
  },
  {
    "text": "But it was good, you know, and like in hindsight,\nand I never met anyone,",
    "start": "4899030",
    "end": "4902392"
  },
  {
    "text": "even on parties way over on the right, in any country who think it was a bad, thinks it was a terrible idea",
    "start": "4905543",
    "end": "4911780"
  },
  {
    "text": "to ban child labor, for example. - Yeah, but it seems like\nthis particular technology",
    "start": "4911780",
    "end": "4917900"
  },
  {
    "text": "has gotten so good so fast, become powerful to a\ndegree where you could see",
    "start": "4917900",
    "end": "4924560"
  },
  {
    "text": "in the near term, the ability to make a lot of money. - [Max] Yeah. - And to put guardrails, to develop guardrails quickly\nin that kind of context",
    "start": "4924560",
    "end": "4931429"
  },
  {
    "text": "seems to be tricky. It's not similar to cars or child labor,",
    "start": "4931430",
    "end": "4936650"
  },
  {
    "text": "it seems like the opportunity\nto make a lot of money here very quickly is right here before us.",
    "start": "4936650",
    "end": "4942567"
  },
  {
    "text": "- So again, there's this cliff. - Yeah, it gets quite scenic, (laughs) - [Max] The closer to the cliff you go,",
    "start": "4942567",
    "end": "4948620"
  },
  {
    "text": "- Yeah. - The more money there is, the more gold ingots\nthere are on the ground you can pick up or whatever,",
    "start": "4948620",
    "end": "4954283"
  },
  {
    "text": "if you want to drive there very fast, but it's not in anyone's incentive that we go over the cliff and it's not like\neverybody's in the wrong car.",
    "start": "4954283",
    "end": "4961010"
  },
  {
    "text": "All the cars are connected\ntogether with a chain. So if anyone goes over, they'll start dragging\nthe others down too.",
    "start": "4961010",
    "end": "4968295"
  },
  {
    "text": "And so ultimately it's in the selfish interests also of the\npeople in the companies",
    "start": "4968295",
    "end": "4974510"
  },
  {
    "text": "to slow down when you just start seeing the contours of the cliff\nthere in front of you, right?",
    "start": "4974510",
    "end": "4980357"
  },
  {
    "text": "And the problem is that, even though the people who\nare building the technology,",
    "start": "4980357",
    "end": "4985610"
  },
  {
    "text": "and the CEOs, they really get it, the shareholders and\nthese other market forces,",
    "start": "4985610",
    "end": "4992480"
  },
  {
    "text": "they are people who don't honestly, understand that the cliff is there, they usually don't.",
    "start": "4992480",
    "end": "4998059"
  },
  {
    "text": "You have to get quite into the weeds to really appreciate how\npowerful this is and how fast. And a lot of people are\neven still stuck again",
    "start": "4998060",
    "end": "5004270"
  },
  {
    "text": "in this idea that in this \"carbon chauvinism\"\nas I like to call it,",
    "start": "5004270",
    "end": "5010179"
  },
  {
    "text": "that you can only have our\nlevel of intelligence in humans, that there's something magical about it.",
    "start": "5010180",
    "end": "5016083"
  },
  {
    "text": "Whereas the people in the tech companies who build this stuff, they all realize that intelligence",
    "start": "5016083",
    "end": "5022360"
  },
  {
    "text": "is information processing\nof a certain kind, and it really doesn't matter at all",
    "start": "5022360",
    "end": "5028090"
  },
  {
    "text": "whether the information is\nprocessed by carbon atoms in neurons, in brains, or by silicon atoms in\nsome technology we build.",
    "start": "5028090",
    "end": "5036883"
  },
  {
    "text": "So you brought up capitalism earlier, and there are a lot of\npeople who love capitalism and a lot of people who\nreally, really don't.",
    "start": "5038170",
    "end": "5047580"
  },
  {
    "text": "And it struck me recently, that what's happening with capitalism here",
    "start": "5047980",
    "end": "5055210"
  },
  {
    "text": "is exactly analogous to the way in which superintelligence\nmight wipe us out.",
    "start": "5055210",
    "end": "5059083"
  },
  {
    "text": "Do you know why I studied\neconomics for my undergrad? Stockholm School of Economics, yay.",
    "start": "5062955",
    "end": "5068200"
  },
  {
    "text": "(Lex laughing) - Well, no. No why, tell me. - So I was very interested in how",
    "start": "5068201",
    "end": "5073300"
  },
  {
    "text": "you could use market forces to just get stuff done more efficiently, but give the right incentives to market",
    "start": "5073300",
    "end": "5078909"
  },
  {
    "text": "so that it wouldn't do really bad things. So Dylan Hadfield-Menell, who's a professor and\ncolleague of mine at MIT,",
    "start": "5078910",
    "end": "5086533"
  },
  {
    "text": "wrote this really interesting paper with some collaborators recently, where they proved mathematically",
    "start": "5087370",
    "end": "5093190"
  },
  {
    "text": "that if you just take one goal\nthat you just optimize for, on and on, and on, indefinitely,",
    "start": "5093190",
    "end": "5099699"
  },
  {
    "text": "that you think is gonna bring\nyou in the right direction, what basically always happens is,",
    "start": "5099700",
    "end": "5105460"
  },
  {
    "text": "in the beginning, it will\nmake things better for you, but if you keep going, at some point,",
    "start": "5105460",
    "end": "5111370"
  },
  {
    "text": "it's gonna start making\nthings worse for you again. And then gradually, it's gonna make it\nreally, really terrible.",
    "start": "5111370",
    "end": "5116380"
  },
  {
    "text": "So just as a simple, the way I think of the proof is, suppose you want to go from\nhere back to Austin for example,",
    "start": "5116380",
    "end": "5125490"
  },
  {
    "text": "and you're like, \"Okay, yeah, let's go south,\" but you put in exactly sort\nof the right direction.",
    "start": "5125890",
    "end": "5132130"
  },
  {
    "text": "Just optimize that, as south as possible. You get closer and closer to Austin,",
    "start": "5132130",
    "end": "5135940"
  },
  {
    "text": "but there's always some little error. So you're not going\nexactly towards Austin,",
    "start": "5137320",
    "end": "5144250"
  },
  {
    "text": "but you get pretty close, but eventually, you\nstart going away again, and eventually, you're gonna\nbe leaving the solar system.",
    "start": "5144250",
    "end": "5149747"
  },
  {
    "text": "- [Lex] (chuckles) Yeah. - And they proved, it's a beautiful mathematical proof, this happens generally,",
    "start": "5149747",
    "end": "5155440"
  },
  {
    "text": "and this is very important for AI because, even though Stuart\nRussell has written a book",
    "start": "5155440",
    "end": "5162250"
  },
  {
    "text": "and given a lot of talks\non why it's a bad idea to have AI just blindly\noptimize something,",
    "start": "5162250",
    "end": "5168460"
  },
  {
    "text": "that's what pretty much\nall our systems do. - [Lex] Yeah. - We have something\ncalled the loss function that we're just minimizing, or reward function, we're\njust maximizing, and,",
    "start": "5168460",
    "end": "5177373"
  },
  {
    "text": "capitalism is exactly like that too. We wanted to get stuff\ndone more efficiently,",
    "start": "5180280",
    "end": "5186280"
  },
  {
    "text": "the people wanted. So introduce the free market.",
    "start": "5186280",
    "end": "5190452"
  },
  {
    "text": "Things got done much more\nefficiently than they did in say, communism, right?",
    "start": "5192310",
    "end": "5198790"
  },
  {
    "text": "And it got better. But then it just kept optimizing,",
    "start": "5198790",
    "end": "5204220"
  },
  {
    "text": "and kept optimizing, and you got every bigger companies, and every more efficient\ninformation processing and now also very much powered by IT,",
    "start": "5204220",
    "end": "5210853"
  },
  {
    "text": "and eventually a lot of\npeople are beginning to feel, \"Wait, we're kind of\noptimizing a bit too much. Like why did we just chop\ndown half the rainforest?\"",
    "start": "5212410",
    "end": "5219880"
  },
  {
    "text": "You know, and why did suddenly these\nregulators get captured",
    "start": "5219880",
    "end": "5225490"
  },
  {
    "text": "by lobbyists and so on? It's just the same optimization that's been running for too long.",
    "start": "5225490",
    "end": "5231100"
  },
  {
    "text": "If you have an AI that actually\nhas power over the world and you just give it one goal,",
    "start": "5231100",
    "end": "5236260"
  },
  {
    "text": "and just like keep optimizing that, most likely everybody's gonna be like, \"Yay, this is great.\" In the beginning things\nare getting better,",
    "start": "5236260",
    "end": "5243520"
  },
  {
    "text": "but it's almost impossible to give it exactly the right\ndirection to optimize in.",
    "start": "5243520",
    "end": "5249940"
  },
  {
    "text": "And then eventually all\nhell breaks loose, right? Nick Bostrom and others\nhave given examples",
    "start": "5249940",
    "end": "5257470"
  },
  {
    "text": "that sound quite silly, Like what if you just want to like, tell it to cure cancer or something,",
    "start": "5257470",
    "end": "5263830"
  },
  {
    "text": "and that's all you tell it, maybe it's gonna decide to\ntake over an entire continent",
    "start": "5263830",
    "end": "5270120"
  },
  {
    "text": "just so we can get more\nsupercomputer facilities in there, and figure out how to\ncure cancer backwards,",
    "start": "5271000",
    "end": "5276010"
  },
  {
    "text": "and then you're like, \"Wait, that's not what I wanted,\" right? And the issue with capitalism",
    "start": "5276010",
    "end": "5283000"
  },
  {
    "text": "and the issue with runaway\nAI have kind of merged now, because that Moloch I talked about",
    "start": "5283000",
    "end": "5288640"
  },
  {
    "text": "is exactly the capitalist Moloch that, we have built an economy that is optimizing for only one thing.",
    "start": "5288640",
    "end": "5295273"
  },
  {
    "text": "Profit, right? And that worked great back when things were very inefficient, and then now it's getting done better,",
    "start": "5296170",
    "end": "5302740"
  },
  {
    "text": "and it worked great as\nlong as the companies were small enough that they\ncouldn't capture the regulators.",
    "start": "5302740",
    "end": "5308140"
  },
  {
    "text": "But that's not true anymore, but they keep optimizing, and now they realize that they can,",
    "start": "5308140",
    "end": "5316420"
  },
  {
    "text": "these companies can make even more profit by building ever more powerful\nAI even if it's reckless,",
    "start": "5316420",
    "end": "5320840"
  },
  {
    "text": "but optimize more and more,\nand more, and more, and more. So this is Moloch again showing up.",
    "start": "5322750",
    "end": "5330370"
  },
  {
    "text": "And I just wanna, anyone here who has any concerns about late-stage capitalism\nhaving gone a little too far,",
    "start": "5330370",
    "end": "5339550"
  },
  {
    "text": "you should worry about superintelligence 'cause it's the same\nvillain in both cases.",
    "start": "5339550",
    "end": "5345220"
  },
  {
    "text": "It's Moloch. - And optimizing one objective\nfunction aggressively,",
    "start": "5345220",
    "end": "5351180"
  },
  {
    "text": "blindly is going to take us there. - Yeah, we have to pause from time to time and look into our hearts",
    "start": "5351340",
    "end": "5359140"
  },
  {
    "text": "and ask why are we doing this? Is this, am I still going towards Austin, or have I gone too far?",
    "start": "5359140",
    "end": "5364870"
  },
  {
    "text": "You know, maybe we\nshould change direction. - And that is the idea behind\nthe halt for six months.",
    "start": "5364870",
    "end": "5370960"
  },
  {
    "text": "Why six months? That seems like a very short period. Can we just linger and\nexplore different ideas here,",
    "start": "5370960",
    "end": "5377710"
  },
  {
    "text": "because this feels like a really important moment in human history, where pausing would actually have",
    "start": "5377710",
    "end": "5383350"
  },
  {
    "text": "a significant positive effect. - We said six months,",
    "start": "5383350",
    "end": "5388630"
  },
  {
    "text": "because we figured the number one pushback that we're gonna get in the\nWest was like, \"But China?\"",
    "start": "5388630",
    "end": "5395917"
  },
  {
    "text": "and everybody knows\nthere's no way that China is gonna catch up with the\nWest on this in six months.",
    "start": "5397990",
    "end": "5403540"
  },
  {
    "text": "So that argument goes off the table and you can forget about\ngeopolitical competition and just focus on the real issue.",
    "start": "5403540",
    "end": "5411400"
  },
  {
    "text": "That's why we put this. - That's really interesting. But you've are already made\nthe case that even for China,",
    "start": "5411400",
    "end": "5418060"
  },
  {
    "text": "if you actually wanna\ntake on that argument, China too would not be\nbothered by a longer halt",
    "start": "5418060",
    "end": "5425440"
  },
  {
    "text": "because they don't wanna lose control even more than the West doesn't. - That's what I think, yeah.",
    "start": "5425440",
    "end": "5430477"
  },
  {
    "text": "- That's a really interesting argument. Like I have to actually\nreally think about that, which, the kind of thing people assume",
    "start": "5430477",
    "end": "5436930"
  },
  {
    "start": "5434000",
    "end": "5988000"
  },
  {
    "text": "is if you develop an AGI, that OpenAI, if they're the ones\nthat do it, for example,",
    "start": "5436930",
    "end": "5442210"
  },
  {
    "text": "they're going to win. But you're saying no, everybody loses.",
    "start": "5442210",
    "end": "5447370"
  },
  {
    "text": "- Yeah, it's gonna get\nbetter and better and better, and then kaboom, we all lose. That's what's gonna happen.",
    "start": "5447370",
    "end": "5453130"
  },
  {
    "text": "- When lose and win\nare defined on a metric of basically quality of\nlife for human civilization,",
    "start": "5453130",
    "end": "5460020"
  },
  {
    "text": "and for Sam Altman. (laughs) Both. - To be blunt, my personal guess, you know, and people\ncan quibble with this,",
    "start": "5460210",
    "end": "5466330"
  },
  {
    "text": "is that we're just gonna, there won't be any humans. That's it, that's what I mean by lose. You know, if you,",
    "start": "5466330",
    "end": "5471873"
  },
  {
    "text": "we can see in history, once you have some species\nor some group of people who aren't needed anymore,",
    "start": "5471873",
    "end": "5478183"
  },
  {
    "text": "doesn't usually work out\nso well for them, right? - [Lex] Yeah. - There were a lot of horses\nthat were used for traffic",
    "start": "5479980",
    "end": "5486969"
  },
  {
    "text": "in Boston and then the car got invented and most of them got, yeah, well. (laughs) We don't need to go there.",
    "start": "5486970",
    "end": "5493060"
  },
  {
    "text": "And if you look at",
    "start": "5493060",
    "end": "5495150"
  },
  {
    "text": "humans, you know, right now, why did the\nlabor movement succeed?",
    "start": "5499180",
    "end": "5504730"
  },
  {
    "text": "And after the Industrial Revolution? Because it was needed.",
    "start": "5504730",
    "end": "5507913"
  },
  {
    "text": "Even though we had a lot of Molochs, and there was child labor\nand so on, you know,",
    "start": "5510310",
    "end": "5515293"
  },
  {
    "text": "the company still needed to have workers, and that's why strikes\nhad power and so on.",
    "start": "5516340",
    "end": "5521790"
  },
  {
    "text": "If we get to the point where most humans aren't needed anymore, I think it's quite naive to think",
    "start": "5522640",
    "end": "5528130"
  },
  {
    "text": "that they're gonna still be treated well. You know, we say that. Yeah, yeah everybody's equal,",
    "start": "5528130",
    "end": "5533286"
  },
  {
    "text": "and the government will\nalways protect them. But if you look in practice, groups that are very disenfranchised",
    "start": "5533287",
    "end": "5539500"
  },
  {
    "text": "and don't have any actual\npower usually get screwed.",
    "start": "5539500",
    "end": "5544500"
  },
  {
    "text": "And now in the beginning, so Industrial Revolution,",
    "start": "5545110",
    "end": "5550239"
  },
  {
    "text": "we automated away muscle work, but that got, worked out pretty well eventually,",
    "start": "5550240",
    "end": "5556630"
  },
  {
    "text": "because we educated ourselves and started working\nwith our brains instead and got usually more\ninteresting, better paid jobs.",
    "start": "5556630",
    "end": "5563650"
  },
  {
    "text": "But now we're beginning\nto replace brain work. So we replaced a lot of boring stuff, like we got the pocket calculator,",
    "start": "5563650",
    "end": "5569950"
  },
  {
    "text": "so you don't have people adding, multiplying numbers anymore at work. Fine, there were better\njobs they could get.",
    "start": "5569950",
    "end": "5576280"
  },
  {
    "text": "But now GPT-4, you know, and the Stable Diffusion\nand techniques like this,",
    "start": "5576280",
    "end": "5582790"
  },
  {
    "text": "they're really beginning to blow away some jobs that people really loved having.",
    "start": "5582790",
    "end": "5588730"
  },
  {
    "text": "There was a heartbreaking\narticle post just yesterday on social media I saw, about this guy who was doing 3D modeling",
    "start": "5588730",
    "end": "5596560"
  },
  {
    "text": "for gaming and he, and all of a sudden now\nhe got this new software he just sets prompts,",
    "start": "5596560",
    "end": "5603040"
  },
  {
    "text": "and he feels this whole job that he loved just lost its meaning, you know? And I asked GPT-4 to rewrite",
    "start": "5603040",
    "end": "5611507"
  },
  {
    "text": "\"Twinkle, Twinkle, Little Star\"\nin the style of Shakespeare, I couldn't have done such a good job.",
    "start": "5611507",
    "end": "5617710"
  },
  {
    "text": "It was really impressive. You've seen a lot of the\nart coming out here, right? So I'm all for automating\naway the dangerous jobs",
    "start": "5617710",
    "end": "5627130"
  },
  {
    "text": "and the boring jobs. But I think you hear a lot, some arguments which are too glib.",
    "start": "5627130",
    "end": "5633220"
  },
  {
    "text": "Sometimes people say, \"Well that's all that's gonna happen. We're getting rid of the boring, tedious, dangerous jobs,\"",
    "start": "5633220",
    "end": "5639220"
  },
  {
    "text": "it's just not true. There are a lot of really interesting jobs that are being taken away now. Journalism is gonna get crushed,",
    "start": "5639220",
    "end": "5645972"
  },
  {
    "text": "coding is gonna get crushed. I predict the job market for programmers,",
    "start": "5647080",
    "end": "5652150"
  },
  {
    "text": "the salaries are gonna start dropping. You know, if you said you\ncan code five times faster,",
    "start": "5652150",
    "end": "5657460"
  },
  {
    "text": "you know, then you need five\ntimes fewer programmers, maybe there will be more output also,",
    "start": "5657460",
    "end": "5663050"
  },
  {
    "text": "but then you'll still end up using fewer, needing fewer programmers than today. And I love coding,",
    "start": "5663050",
    "end": "5668230"
  },
  {
    "text": "you know, I think it's super cool. So we need to stop and ask ourselves",
    "start": "5668230",
    "end": "5674290"
  },
  {
    "text": "why again are we doing\nthis as humans, right? I feel that AI should be built\nby humanity for humanity,",
    "start": "5674290",
    "end": "5684030"
  },
  {
    "text": "and let's not forget that. It shouldn't be by Moloch for Moloch, or what it really is now is\nkind of by humanity for Moloch,",
    "start": "5684520",
    "end": "5693280"
  },
  {
    "text": "which doesn't make any sense. It's for us that we're doing it. And it would make a lot more sense",
    "start": "5693280",
    "end": "5700300"
  },
  {
    "text": "if we build, develop,\nfigure out gradually, safely how to make all this tech, and then we think about\nwhat are the kind of jobs",
    "start": "5700300",
    "end": "5706750"
  },
  {
    "text": "that people really don't want to have, you know, automate them all away. And then we ask what are the jobs",
    "start": "5706750",
    "end": "5712120"
  },
  {
    "text": "that people really find meaning in, like maybe taking care of\nchildren in the daycare center,",
    "start": "5712120",
    "end": "5720240"
  },
  {
    "text": "maybe doing art, et cetera, et cetera. And even if it were possible\nto automate that away,",
    "start": "5721180",
    "end": "5726834"
  },
  {
    "text": "we don't need to do that, right? We built these machines. - Well it's possible that we redefine",
    "start": "5726834",
    "end": "5733780"
  },
  {
    "text": "or rediscover what are the\njobs that give us meaning. So for me, the thing, it is really sad.",
    "start": "5733780",
    "end": "5740230"
  },
  {
    "text": "Like I, (chuckles) half the time I'm excited,\nhalf the time I'm crying",
    "start": "5740230",
    "end": "5745820"
  },
  {
    "text": "as I'm generating code because I kind of love programming.",
    "start": "5747656",
    "end": "5752293"
  },
  {
    "text": "It's the act of creation, You have an idea, you design it, and then you bring it to life,",
    "start": "5753709",
    "end": "5759280"
  },
  {
    "text": "and it does something. Especially if there's\nsome intelligence to it, it doesn't even have to have intelligence.",
    "start": "5759280",
    "end": "5764560"
  },
  {
    "text": "Printing \"Hello world\" on screen. You made a little machine\nand it it comes to life.",
    "start": "5764560",
    "end": "5770230"
  },
  {
    "text": "- [Max] Yeah. - And there's a bunch of\ntricks you learn along the way 'cause you've been doing\nit for many, many years.",
    "start": "5770230",
    "end": "5777520"
  },
  {
    "text": "And then for to see AI be able to generate all the tricks you thought were special.",
    "start": "5777520",
    "end": "5782023"
  },
  {
    "text": "I don't know, it's very, it's scary, it's almost painful.",
    "start": "5784120",
    "end": "5790900"
  },
  {
    "text": "Like a loss of innocence maybe, like maybe when I was younger,",
    "start": "5790900",
    "end": "5796603"
  },
  {
    "text": "I remember before I learned\nthat sugar is bad for you, you should be on a diet. I remember I enjoyed candy deeply,",
    "start": "5797530",
    "end": "5804369"
  },
  {
    "text": "in a way I just can't anymore, that I know is bad for me. I enjoyed it unapologetically,\nfully, just intensely.",
    "start": "5804370",
    "end": "5813870"
  },
  {
    "text": "And I lost that. Now, I feel like a little\nbit of that is lost,",
    "start": "5814390",
    "end": "5819073"
  },
  {
    "text": "or being lost with programming, similar as it is for the 3D modeler",
    "start": "5820000",
    "end": "5826510"
  },
  {
    "text": "no longer being able\nto really enjoy the art of modeling 3D things for gaming.",
    "start": "5826510",
    "end": "5831553"
  },
  {
    "text": "I don't know what to make sense of that. Maybe I would rediscover\nthat the true magic of what it means to be humans is connecting with other humans,",
    "start": "5832492",
    "end": "5837990"
  },
  {
    "text": "to have conversations like this, I don't know, to have sex,",
    "start": "5837990",
    "end": "5843040"
  },
  {
    "text": "to eat food, to really intensify the value from conscious experiences,",
    "start": "5843040",
    "end": "5848350"
  },
  {
    "text": "versus like creating other stuff. - You're pitching the rebranding again from Homo sapiens to Homo sentiens,",
    "start": "5848350",
    "end": "5855100"
  },
  {
    "text": "the meaningful experiences. And just to a inject some\noptimism in this here, so we don't sound like it was a gloomers.",
    "start": "5855100",
    "end": "5860920"
  },
  {
    "text": "You know, we can totally\nhave our cake and eat it. You hear a lot of totally bullshit claims that we can't afford having more teachers,",
    "start": "5860920",
    "end": "5867880"
  },
  {
    "text": "have to cut the number of nurses, you know, that's just nonsense, obviously.",
    "start": "5867880",
    "end": "5871782"
  },
  {
    "text": "With anything even quite far short of AGI, we can dramatically improve, grow the GDP,",
    "start": "5873100",
    "end": "5881800"
  },
  {
    "text": "and produce this wealth\nof goods and services. It's very easy to create a world",
    "start": "5881800",
    "end": "5887260"
  },
  {
    "text": "where everybody is better off than today. Including the richest people can be better off as well, right?",
    "start": "5887260",
    "end": "5893650"
  },
  {
    "text": "It's not a zero sum game, you know, technology. Again, you can have two countries,",
    "start": "5893650",
    "end": "5899470"
  },
  {
    "text": "like Sweden and Denmark had\nall these ridiculous wars century after century,",
    "start": "5899470",
    "end": "5903553"
  },
  {
    "text": "and sometimes that Sweden\ngot a little better off 'cause it got a little bigger, and then Denmark got a\nlittle bit better off",
    "start": "5905440",
    "end": "5911350"
  },
  {
    "text": "'cause Sweden got a little bit smaller, but then technology came along and we both got just\ndramatically wealthier",
    "start": "5911350",
    "end": "5917320"
  },
  {
    "text": "without taking away from anyone else, so it was just a total win for everyone. And AI can do that on steroids.",
    "start": "5917320",
    "end": "5924583"
  },
  {
    "text": "if you can build safe AGI, if you can build superintelligence,",
    "start": "5925420",
    "end": "5930969"
  },
  {
    "text": "basically all the limitations\nthat cause harm today can be completely eliminated. Right?",
    "start": "5930970",
    "end": "5937900"
  },
  {
    "text": "It's a wonderful possibility. And this is not sci-fi, this is something which\nis clearly possible",
    "start": "5937900",
    "end": "5943809"
  },
  {
    "text": "according to laws of physics, And we can talk about ways\nof making it safe also,",
    "start": "5943810",
    "end": "5949630"
  },
  {
    "text": "but unfortunately that'll only happen if we steer in that direction,",
    "start": "5949630",
    "end": "5954820"
  },
  {
    "text": "that's absolutely not the default outcome. That's why income\ninequality keeps going up.",
    "start": "5954820",
    "end": "5962080"
  },
  {
    "text": "That's why the life expectancy in the US has been going down now, I think it's four years in a row.",
    "start": "5962080",
    "end": "5967240"
  },
  {
    "text": "I just read a heartbreaking study from CDC about how something like\n1/3 of all the teenage girls",
    "start": "5967240",
    "end": "5975190"
  },
  {
    "text": "in the US have been\nthinking about suicide. You know, like those are steps",
    "start": "5975190",
    "end": "5980410"
  },
  {
    "text": "in totally the wrong direction and it's important to keep\nour eyes on the prize here",
    "start": "5980410",
    "end": "5985900"
  },
  {
    "text": "that we can, we have the power now for the first time",
    "start": "5985900",
    "end": "5991300"
  },
  {
    "start": "5988000",
    "end": "7291000"
  },
  {
    "text": "in the history of our species to harness artificial intelligence, to help us really flourish,",
    "start": "5991300",
    "end": "5998233"
  },
  {
    "text": "and help bring out the\nbest in our humanity rather than the worst of it.",
    "start": "5999100",
    "end": "6005910"
  },
  {
    "text": "To help us have really\nfulfilling experiences that feel truly meaningful.",
    "start": "6005910",
    "end": "6011550"
  },
  {
    "text": "And you and I shouldn't sit here and dictate the future\ngenerations what they will be, let them figure it out. But let's give them a chance to live,",
    "start": "6011550",
    "end": "6018719"
  },
  {
    "text": "and not foreclose all these\npossibilities for them, by just messing things up, right? - Well for that, we'll have to\nsolve the AI safety problem.",
    "start": "6018720",
    "end": "6025860"
  },
  {
    "text": "It would be nice if we can linger on exploring that a little bit. So one interesting way to\nenter that discussion is,",
    "start": "6025860",
    "end": "6034550"
  },
  {
    "text": "you tweeted, and Elon replied, you tweeted, \"Let's not just focus on whether GPT-4",
    "start": "6034800",
    "end": "6040530"
  },
  {
    "text": "will do more harm or\ngood on the job market, but also whether it's coding skills will hasten the arrival\nof superintelligence.\"",
    "start": "6040530",
    "end": "6047520"
  },
  {
    "text": "That's something we've\nbeen talking about, right? So Elon proposed one\nthing in the reply saying, \"Maximum truth-seeking is my\nbest guess for AI safety.\"",
    "start": "6047520",
    "end": "6055980"
  },
  {
    "text": "Can you maybe steel me on the case for,",
    "start": "6055980",
    "end": "6060303"
  },
  {
    "text": "this objective function of truth and maybe make an argument\nagainst it in general, what are your different ideas",
    "start": "6062567",
    "end": "6070020"
  },
  {
    "text": "to start approaching the\nsolution to AI safety? - I didn't see that reply actually. - [Lex] Oh, interesting.",
    "start": "6070020",
    "end": "6076090"
  },
  {
    "text": "- But I really resonate with it because,",
    "start": "6076090",
    "end": "6078333"
  },
  {
    "text": "AI is not evil. It caused people around the world to hate each other much more,",
    "start": "6081750",
    "end": "6087810"
  },
  {
    "text": "but that's because we\nmade it in a certain way. It's a tool, we can use it for great\nthings and bad things,",
    "start": "6087810",
    "end": "6093210"
  },
  {
    "text": "and we could just as well have AI systems, and this is part of my\nvision for success here.",
    "start": "6093210",
    "end": "6099719"
  },
  {
    "text": "Truth-seeking AI that really\nbrings us together again, you know, why do people\nhate each other so much",
    "start": "6099720",
    "end": "6106590"
  },
  {
    "text": "between countries and within countries is because they each\nhave totally different",
    "start": "6106590",
    "end": "6111719"
  },
  {
    "text": "versions of the truth, right? If they all had the same truth",
    "start": "6111720",
    "end": "6117060"
  },
  {
    "text": "that they trusted for good reason 'cause they could check it and verify it, and not have to believe in some self-proclaimed authority, right?",
    "start": "6117060",
    "end": "6123303"
  },
  {
    "text": "They wouldn't be as nearly as much hate. There'd be a lot more\nunderstanding instead, and this is,",
    "start": "6124170",
    "end": "6130503"
  },
  {
    "text": "I think something AI can\nhelp enormously with. For example, a little baby\nstep in this direction",
    "start": "6131610",
    "end": "6138630"
  },
  {
    "text": "is this website called Metaculus where people bet and make\npredictions not for money,",
    "start": "6138630",
    "end": "6145920"
  },
  {
    "text": "but just for their own reputation. And it's kind of funny actually, you treat the humans like you treat AI,",
    "start": "6145920",
    "end": "6152400"
  },
  {
    "text": "as you have a loss function where they get penalized if they're super confident on something",
    "start": "6152400",
    "end": "6157890"
  },
  {
    "text": "and then the opposite happens. - [Lex] Yeah. - Whereas if you're kind of humble, and then you're like,",
    "start": "6157890",
    "end": "6163027"
  },
  {
    "text": "\"I think it's 51% chance\nthis is gonna happen,\" and then the other happens, you don't get penalized much,",
    "start": "6163027",
    "end": "6168570"
  },
  {
    "text": "and what you can see is that some people are much better at predicting than others. They've earned your trust, right?",
    "start": "6168570",
    "end": "6174060"
  },
  {
    "text": "One project that I'm working on right now is an outgrowth of Improve\nThe News foundation together with the Metaculus folks is,",
    "start": "6175710",
    "end": "6181320"
  },
  {
    "text": "seeing if we can really\nscale this up a lot with more powerful AI. 'Cause I would love it,",
    "start": "6181320",
    "end": "6186381"
  },
  {
    "text": "I would love for there to be like a really powerful\ntruth-seeking system where,",
    "start": "6186381",
    "end": "6191253"
  },
  {
    "text": "that is trustworthy because it keeps being right about stuff.",
    "start": "6192352",
    "end": "6197133"
  },
  {
    "text": "And people come to it and maybe look at its latest trust ranking",
    "start": "6197970",
    "end": "6204180"
  },
  {
    "text": "of different pundits and\nnewspapers, et cetera. If they want to know why\nsome someone got a low score,",
    "start": "6204180",
    "end": "6209850"
  },
  {
    "text": "they can click on it, and see all the predictions\nthat they actually made and how they turned out, you know,",
    "start": "6209850",
    "end": "6216300"
  },
  {
    "text": "this is how we do it in science. You trust scientists like Einstein who said something everybody\nthought was bullshit,",
    "start": "6216300",
    "end": "6222450"
  },
  {
    "text": "and turned out to be right, he get a lot of trust points, and he did it multiple times, even.",
    "start": "6222450",
    "end": "6227403"
  },
  {
    "text": "I think AI has the power to really heal a lot of the rifts we're seeing\nby creating a trust system.",
    "start": "6229950",
    "end": "6238443"
  },
  {
    "text": "It has to get away from this idea today with some fact checking site, which might themselves have an agenda",
    "start": "6240426",
    "end": "6245790"
  },
  {
    "text": "and you just trust it\nbecause of its reputation, you want to have,",
    "start": "6245790",
    "end": "6250660"
  },
  {
    "text": "so these sort of systems,\nthey earn in their trust and they're completely transparent. This I think would actually help a lot",
    "start": "6252030",
    "end": "6258370"
  },
  {
    "text": "that can, I think, help heal the very\ndysfunctional conversation that humanity has about\nhow it's gonna deal",
    "start": "6259500",
    "end": "6265920"
  },
  {
    "text": "with all its biggest challenges\nin in the world today.",
    "start": "6265920",
    "end": "6270183"
  },
  {
    "text": "And then on the technical side, you know, another common\nsort of gloom comment",
    "start": "6271500",
    "end": "6279120"
  },
  {
    "text": "I get from people are saying, \"We're just screwed, there's no hope.\" Is well, things like GPT-4 are way too complicated",
    "start": "6279120",
    "end": "6285180"
  },
  {
    "text": "for a human to ever understand, and prove that they can be trustworthy. They're forgetting that AI can help us",
    "start": "6285180",
    "end": "6291600"
  },
  {
    "text": "prove that things work, right? - [Lex] Yeah. - And there's this very\nfundamental fact that in math,",
    "start": "6291600",
    "end": "6298260"
  },
  {
    "text": "it's much harder to come up with a proof than it is to verify that\nthe proof is correct.",
    "start": "6298260",
    "end": "6304920"
  },
  {
    "text": "You can actually write a\nlittle proof-checking code, it's quite short, but you can as a human, understand,",
    "start": "6304920",
    "end": "6310650"
  },
  {
    "text": "and then it can check the\nmost monstrously long proof ever generated even by your computer, and say, \"Yeah, this is valid.\"",
    "start": "6310650",
    "end": "6316369"
  },
  {
    "text": "So right now, we have,",
    "start": "6318030",
    "end": "6321483"
  },
  {
    "text": "this approach with virus-checking software that it looks to see if there's something, and if you should not trust it,",
    "start": "6326006",
    "end": "6331800"
  },
  {
    "text": "and if it can prove to itself that you should not trust that\ncode, it warns you, right?",
    "start": "6331800",
    "end": "6336512"
  },
  {
    "text": "What if you flip this around, and this is an idea I should give credit to Steve Omohundro for,",
    "start": "6337950",
    "end": "6344250"
  },
  {
    "text": "so that it will only run\nthe code if it can prove, instead of not running it if it can prove that it's not trustworthy,",
    "start": "6344250",
    "end": "6350400"
  },
  {
    "text": "it will only run it if it can prove that it's trustworthy. So it asks the code, \"Prove to me that you're gonna do what you say you're gonna do,\"",
    "start": "6350400",
    "end": "6356670"
  },
  {
    "text": "and it gives you this proof, and you have a little proof\nthat you can check it.",
    "start": "6358708",
    "end": "6363930"
  },
  {
    "text": "Now you can actually trust an AI that's much more intelligent\nthan you are, right?",
    "start": "6363930",
    "end": "6368960"
  },
  {
    "text": "Because you, is its problem to come up with this proof that you could never have found, that you should trust it.",
    "start": "6369840",
    "end": "6376200"
  },
  {
    "text": "- So this is the interesting point. I agree with you, but this is where Eliezer Yudkowsky",
    "start": "6376200",
    "end": "6381750"
  },
  {
    "text": "might disagree with you. His claim, not with\nyou, but with this idea.",
    "start": "6381750",
    "end": "6385803"
  },
  {
    "text": "his claim is superintelligent AI would be able to know how to\nlie to you with such a proof.",
    "start": "6387450",
    "end": "6394833"
  },
  {
    "text": "- I have to lie to you and give me a proof that I'm gonna think is correct? - [Lex] Yeah. - But it's not me it's lying to you.",
    "start": "6396240",
    "end": "6401940"
  },
  {
    "text": "That's to trick my proof checker, which is a piece of code. - So his general idea is\na superintelligent system",
    "start": "6401940",
    "end": "6410100"
  },
  {
    "text": "can lie to a dumber proof checker. So you're going to have,",
    "start": "6410100",
    "end": "6415680"
  },
  {
    "text": "as a system becomes more\nand more intelligent, there's going to be a threshold where a superintelligent system",
    "start": "6415680",
    "end": "6421590"
  },
  {
    "text": "will be able to effectively lie to a slightly dumber AGI system. Like there's a,",
    "start": "6421590",
    "end": "6426777"
  },
  {
    "text": "like he really focuses on this weak AGI to strong AGI jump, where the strong AGI can\nmake all the weak AGIs think",
    "start": "6426777",
    "end": "6436590"
  },
  {
    "text": "that it's just one of them, but it's no longer that. And that leap is when it runs away.",
    "start": "6436590",
    "end": "6443010"
  },
  {
    "text": "- Yeah, I don't buy that argument. I think no matter how\nsuperintelligent an AI is,",
    "start": "6443010",
    "end": "6449340"
  },
  {
    "text": "it's never gonna be able to prove to me that there are only finitely\nmany primes, for example. (Lex chuckling)",
    "start": "6449340",
    "end": "6455866"
  },
  {
    "text": "It just can't. And it can try to snow me by making up all sorts of\nnew weird rules of deduction,",
    "start": "6455867",
    "end": "6462993"
  },
  {
    "text": "and say, \"Trust me, you know, the way your proof checker\nwork is too limited, and we have this new\nhyper math and it's true.\"",
    "start": "6465270",
    "end": "6473250"
  },
  {
    "text": "But then I would just take the attitude, okay, I'm gonna forfeit some of these, the supposedly super cool technologies,",
    "start": "6473250",
    "end": "6480030"
  },
  {
    "text": "I'm only gonna go with the ones that I can prove in my\nown trusted proof checker. Then I think it's fine.",
    "start": "6480030",
    "end": "6485370"
  },
  {
    "text": "There's still, of course, this is not something anyone has successfully\nimplemented at this point,",
    "start": "6485370",
    "end": "6490410"
  },
  {
    "text": "but I think it, I just give it as an example of hope, we don't have to do all\nthe work ourselves, right?",
    "start": "6490410",
    "end": "6497220"
  },
  {
    "text": "This is exactly the sort of\nvery boring and tedious task that is perfect to outsource to an AI.",
    "start": "6497220",
    "end": "6502770"
  },
  {
    "text": "And this is a way in which less powerful and less intelligent agents like us can actually continue to control",
    "start": "6502770",
    "end": "6509760"
  },
  {
    "text": "and trust more powerful ones. - So build AGI systems that help us defend against other AGI systems.",
    "start": "6509760",
    "end": "6515849"
  },
  {
    "text": "- Well for starters, begin with a simple\nproblem of just making sure that the system that you own",
    "start": "6515850",
    "end": "6521159"
  },
  {
    "text": "or that's supposed to be loyal to you has to prove to itself\nthat it's always gonna do",
    "start": "6521160",
    "end": "6526500"
  },
  {
    "text": "the things that you actually\nwant it to do, right? And if it can't prove it, maybe it's still gonna do it, but you won't run it.",
    "start": "6526500",
    "end": "6532500"
  },
  {
    "text": "So you just forfeit some aspects of all the cool things AI can do. I bet your dollars to donuts,",
    "start": "6532500",
    "end": "6538020"
  },
  {
    "text": "it can still do some\nincredibly cool stuff for you. - [Lex] Yeah. - There are other things too, that we shouldn't sweep under the rug.",
    "start": "6538020",
    "end": "6543900"
  },
  {
    "text": "Like not every human agrees on exactly what direction we should\ngo with humanity, right?",
    "start": "6543900",
    "end": "6549480"
  },
  {
    "text": "- Yes. - And you've talked a lot\nabout geopolitical things",
    "start": "6549480",
    "end": "6553869"
  },
  {
    "text": "on your podcast to this effect, you know, but, I think that shouldn't\ndistract us from the fact",
    "start": "6554823",
    "end": "6560070"
  },
  {
    "text": "that there are actually a lot of things that everybody in the\nworld virtually agrees on.",
    "start": "6560070",
    "end": "6565950"
  },
  {
    "text": "That \"Hey, you know, like having a no humans on\nthe planet in a near future,",
    "start": "6565950",
    "end": "6570520"
  },
  {
    "text": "nah, let's not do that\" right? You looked at something like the United Nations\nSustainable Development Goals.",
    "start": "6573150",
    "end": "6579390"
  },
  {
    "text": "Some of 'em were quite a ambitious, and basically all the countries agree,",
    "start": "6579390",
    "end": "6585000"
  },
  {
    "text": "US, China, Russia,\nUkraine, they all agree. So instead of quibbling\nabout the little things",
    "start": "6585000",
    "end": "6590643"
  },
  {
    "text": "that we don't agree on, let's start with the things we do agree on and get them done.",
    "start": "6590643",
    "end": "6596820"
  },
  {
    "text": "Instead of being so distracted by all these things we disagree on, that Moloch wins because frankly,",
    "start": "6596820",
    "end": "6604653"
  },
  {
    "text": "Moloch going wild now, it feels like a war on life playing out in front of our eyes,",
    "start": "6605970",
    "end": "6612902"
  },
  {
    "text": "if you just look at it\nfrom space, you know, we're on this planet, beautiful, vibrant ecosystem,",
    "start": "6612902",
    "end": "6620820"
  },
  {
    "text": "now we start chopping\ndown big parts of it, even though nobody, most people thought that was a bad idea.",
    "start": "6620820",
    "end": "6627840"
  },
  {
    "text": "Oh, we start doing ocean acidification, wiping out all sorts of species,",
    "start": "6627840",
    "end": "6633090"
  },
  {
    "text": "oh, now we have all these close calls, we almost had a nuclear war, and we're replacing more\nand more of the biosphere",
    "start": "6633090",
    "end": "6639960"
  },
  {
    "text": "with non-living things. We're also replacing in our social lives,",
    "start": "6639960",
    "end": "6645720"
  },
  {
    "text": "a lot of the things which\nwere so valuable to humanity, a lot of social interactions now are replaced by people staring\ninto their rectangles, right?",
    "start": "6645720",
    "end": "6654420"
  },
  {
    "text": "And I'm not a psychologist,\nI'm out of my depth here, but I suspect that part of\nthe reason why teen suicide",
    "start": "6654420",
    "end": "6662730"
  },
  {
    "text": "and suicide in general in the US that record-breaking level\nis actually caused by,",
    "start": "6662730",
    "end": "6668159"
  },
  {
    "text": "again, AI technologies and social media making people spend less time",
    "start": "6668160",
    "end": "6673150"
  },
  {
    "text": "with actually just human interaction. We've all seen a bunch\nof good-looking people",
    "start": "6674052",
    "end": "6679890"
  },
  {
    "text": "in restaurants staring into the rectangles instead of looking into\neach other's eyes, right?",
    "start": "6679890",
    "end": "6684740"
  },
  {
    "text": "So that's also part of the war in life that we are replacing so many",
    "start": "6686160",
    "end": "6691810"
  },
  {
    "text": "really life-affirming\nthings by technology. We're putting technology between us,",
    "start": "6694260",
    "end": "6701700"
  },
  {
    "text": "that the technology that\nwas supposed to connect us is actually distancing us\nourselves from each other.",
    "start": "6701700",
    "end": "6707043"
  },
  {
    "text": "And then we are giving\never more power to things which are not alive. These large corporations are\nnot living things, right?",
    "start": "6709114",
    "end": "6715650"
  },
  {
    "text": "They're just maximizing profit. I wanna win the war on life.",
    "start": "6715650",
    "end": "6721980"
  },
  {
    "text": "I think we humans, together with all our fellow\nliving things on this planet",
    "start": "6721980",
    "end": "6727290"
  },
  {
    "text": "will be better off if\nwe can remain in control over the non-living things and make sure",
    "start": "6727290",
    "end": "6733470"
  },
  {
    "text": "that they work for us. I really think it can be done. - Can you just linger\non this maybe high level",
    "start": "6733470",
    "end": "6741659"
  },
  {
    "text": "of philosophical disagreement\nwith Eliezer Yudkowsky,",
    "start": "6741660",
    "end": "6745917"
  },
  {
    "text": "in the hope you're stating. So he is very sure,",
    "start": "6747810",
    "end": "6752013"
  },
  {
    "text": "he puts a very high probability, very close to one, depending on the day he puts it at one,",
    "start": "6752970",
    "end": "6759449"
  },
  {
    "text": "that AI is going to kill humans. That there's just,",
    "start": "6759450",
    "end": "6765870"
  },
  {
    "text": "he does not see a trajectory, which it doesn't end up\nwith that conclusion.",
    "start": "6765870",
    "end": "6770909"
  },
  {
    "text": "What trajectory do you see\nthat doesn't end up there? And maybe can you see\nthe point he's making,",
    "start": "6770910",
    "end": "6778320"
  },
  {
    "text": "and can you also see a way out?",
    "start": "6778320",
    "end": "6781293"
  },
  {
    "text": "- First of all, I tremendously respect Eliezer Yudkowsky and his thinking.",
    "start": "6783330",
    "end": "6790080"
  },
  {
    "text": "Second, I do share his view that there's a pretty large chance that we're not gonna make it as humans.",
    "start": "6790080",
    "end": "6796890"
  },
  {
    "text": "There won't be any humans on the planet, in a not-too-distant future, and that makes me very sad.",
    "start": "6796890",
    "end": "6802170"
  },
  {
    "text": "You know, we just had a little baby and I keep asking myself, you know, is,",
    "start": "6802170",
    "end": "6805523"
  },
  {
    "text": "how old is he even gonna get, you know? And I ask myself,",
    "start": "6811590",
    "end": "6816033"
  },
  {
    "text": "it feels, I said to my wife recently, it feels a little bit\nlike I was just diagnosed with some sort of cancer,",
    "start": "6817380",
    "end": "6823619"
  },
  {
    "text": "which has some, you know, risk of dying from and some\nrisk of surviving, you know.",
    "start": "6823620",
    "end": "6829653"
  },
  {
    "text": "Except this is a kind of cancer which can kill all of humanity. So I completely take\nseriously his concerns,",
    "start": "6832320",
    "end": "6839253"
  },
  {
    "text": "I think, but absolutely, I don't\nthink it's hopeless. I think there is,",
    "start": "6840570",
    "end": "6849243"
  },
  {
    "text": "first of all a lot of momentum now for the first time actually, since the many, many\nyears that have passed",
    "start": "6850260",
    "end": "6857880"
  },
  {
    "text": "since I and many others\nstarted warning about this, I feel most people are getting it now.",
    "start": "6857880",
    "end": "6863073"
  },
  {
    "text": "I was just talking to this guy in the gas station",
    "start": "6864750",
    "end": "6870420"
  },
  {
    "text": "near our house the other day. And he's like, \"I think\nwe're getting replaced,",
    "start": "6870420",
    "end": "6877773"
  },
  {
    "text": "and then I think...\" So that's positive that they're finally, we're finally seeing this reaction,",
    "start": "6878760",
    "end": "6884400"
  },
  {
    "text": "which is the first step\ntowards solving the problem. Second, I really think that this vision",
    "start": "6884400",
    "end": "6890520"
  },
  {
    "text": "of only running AIs, if the stakes are really high,",
    "start": "6890520",
    "end": "6895739"
  },
  {
    "text": "they can prove to us that they're safe. It's really just virus\nchecking in reverse again, I think it's scientifically doable.",
    "start": "6895740",
    "end": "6902763"
  },
  {
    "text": "I don't think it's hopeless, we might have to forfeit some of the technology that we could get",
    "start": "6903720",
    "end": "6909659"
  },
  {
    "text": "if we were putting blind faith in our AIs, but we're still gonna get amazing stuff. - Do you envision a process\nwith a proof checker?",
    "start": "6909660",
    "end": "6916140"
  },
  {
    "text": "Like something like GPT-4, GPT-5, will go through a process\nof rigorous interrogation?",
    "start": "6916140",
    "end": "6921613"
  },
  {
    "text": "- No I think it's hopeless, That's like trying to\nproof-verify spaghetti. - [Lex] (laughs) Okay.",
    "start": "6921613",
    "end": "6927750"
  },
  {
    "text": "- What I think, the vision I have for\nsuccess is instead that,",
    "start": "6927750",
    "end": "6932935"
  },
  {
    "text": "you know, just like we human beings were able to look at our brains and distill out the key knowledge.",
    "start": "6932936",
    "end": "6938250"
  },
  {
    "text": "Galileo, when his dad threw\nhim an apple when he was a kid, he was able to catch it\n'cause his brain could,",
    "start": "6938250",
    "end": "6944310"
  },
  {
    "text": "in his funny spaghetti kind of way, you know, predict how\nparabolas are gonna move, his Kahneman System 1, right?",
    "start": "6944310",
    "end": "6949680"
  },
  {
    "text": "But then he got older and he's like, \"Wait, this is a parabola. It's y equals x squared.\"",
    "start": "6949680",
    "end": "6955710"
  },
  {
    "text": "I can distill this knowledge out and today you can easily\nprogram it into a computer and it can simulate not just that,",
    "start": "6955710",
    "end": "6961739"
  },
  {
    "text": "but how to get to Mars and so on, right? I envision a similar process where we use the amazing\nlearning power of neural networks",
    "start": "6961740",
    "end": "6969220"
  },
  {
    "text": "to discover the knowledge\nin the first place, but we don't stop with a\nblack box and use that.",
    "start": "6970110",
    "end": "6976949"
  },
  {
    "text": "We then do a second round of AI where we use automated systems to extract out the knowledge,\nand see what is it,",
    "start": "6976950",
    "end": "6982890"
  },
  {
    "text": "what are the insights it's had, okay? And then we put that knowledge",
    "start": "6982890",
    "end": "6988350"
  },
  {
    "text": "into a completely different\nkind of architecture, or programming language or whatever,",
    "start": "6988350",
    "end": "6993690"
  },
  {
    "text": "that's made in a way that it\ncan be both really efficient, and also is more amenable\nto very formal verification.",
    "start": "6993690",
    "end": "7001523"
  },
  {
    "text": "That's my vision. I'm not sitting here saying, I'm confident 100% sure that\nit's gonna work, you know.",
    "start": "7003440",
    "end": "7009470"
  },
  {
    "text": "But I don't think it's a chance, it's certainly not zero either, and it will certainly be possible to do for a lot of really cool AI applications",
    "start": "7009470",
    "end": "7017330"
  },
  {
    "text": "that we're not using now. So we can have a lot of the\nfun that we're excited about if we do this.",
    "start": "7017330",
    "end": "7023527"
  },
  {
    "text": "We are gonna need a little bit of time. And that's why it's good to pause",
    "start": "7023527",
    "end": "7028610"
  },
  {
    "text": "and put in place requirements.",
    "start": "7028610",
    "end": "7032512"
  },
  {
    "text": "One more thing also, I think, you know, someone might think, \"Well, 0% chance we're gonna survive,",
    "start": "7033740",
    "end": "7040760"
  },
  {
    "text": "let's just give up,\" right? That's very dangerous,",
    "start": "7040760",
    "end": "7043943"
  },
  {
    "text": "because there's no more\nguaranteed way to fail than to convince yourself\nthat it's impossible",
    "start": "7046220",
    "end": "7052400"
  },
  {
    "text": "and not try, you know, when you study\nhistory and military history,",
    "start": "7052400",
    "end": "7059270"
  },
  {
    "text": "the first thing you learn is that, that's how you do psychological warfare.",
    "start": "7059270",
    "end": "7064639"
  },
  {
    "text": "You persuade the other\nside that it's hopeless so they don't even fight. And then of course you win, right?",
    "start": "7064640",
    "end": "7071540"
  },
  {
    "text": "Let's not do this psychological\nwarfare on ourselves and say there's 100% percent probability",
    "start": "7071540",
    "end": "7077210"
  },
  {
    "text": "we're all screwed anyway. And sadly, I do get that a little bit,",
    "start": "7077210",
    "end": "7083120"
  },
  {
    "text": "sometimes from actually some young people who are like so convinced\nthat we're all screwed, that they're like,",
    "start": "7083120",
    "end": "7088453"
  },
  {
    "text": "\"I'm just gonna play\ncomputer games and do drugs, 'cause we're screwed anyway, right?\"",
    "start": "7088453",
    "end": "7095150"
  },
  {
    "text": "It's important to keep the hope alive because it actually has a causal impact, and makes it more likely\nthat we're gonna succeed.",
    "start": "7095150",
    "end": "7102710"
  },
  {
    "text": "- It seems like the people that actually build solutions to the problem, seemingly impossible to solve problems",
    "start": "7102710",
    "end": "7108770"
  },
  {
    "text": "are the ones that believe. - [Max] Yeah. - They're the ones who are the optimists. And it's like,",
    "start": "7108770",
    "end": "7114380"
  },
  {
    "text": "it seems like there's some\nfundamental law to the universe where \"Fake it till you\nmake it,\" kind of works.",
    "start": "7114380",
    "end": "7119989"
  },
  {
    "text": "Like believe it's possible\nand it becomes possible. - Yeah, was it Henry Ford who said that,",
    "start": "7119990",
    "end": "7126083"
  },
  {
    "text": "if you tell yourself that\nit's impossible, it is. So let's not make that mistake.",
    "start": "7128150",
    "end": "7133820"
  },
  {
    "text": "And this is a big mistake\nsociety is making, I think all in all, everybody's so gloomy, and the media also very biased towards",
    "start": "7133820",
    "end": "7140360"
  },
  {
    "text": "if it bleeds, it leads, and gloom and doom, right? So most,",
    "start": "7140360",
    "end": "7146333"
  },
  {
    "text": "visions of the future\nwe have are dystopian, which really demotivates people.",
    "start": "7147470",
    "end": "7152510"
  },
  {
    "text": "We wanna really, really, really focus on the upside also to give people the willingness to fight for it.",
    "start": "7152510",
    "end": "7158840"
  },
  {
    "text": "And for AI, you and I mostly talked\nabout gloom here again,",
    "start": "7158840",
    "end": "7165017"
  },
  {
    "text": "but let's not forget that, you know, we have probably both lost someone",
    "start": "7165017",
    "end": "7171620"
  },
  {
    "text": "we really cared about to some disease that we were told was incurable. Well it's not,",
    "start": "7171620",
    "end": "7177170"
  },
  {
    "text": "there's no law of physics\nsaying we had to die of that cancer or whatever. Of course, you can cure it.",
    "start": "7177170",
    "end": "7182300"
  },
  {
    "text": "And there's so many other things that we, with our human intelligence\nhave also failed to solve on this planet,",
    "start": "7182300",
    "end": "7189350"
  },
  {
    "text": "which AI could also very\nmuch help us with, right? So if we can get this right, and just be a little more chill,",
    "start": "7189350",
    "end": "7196760"
  },
  {
    "text": "and slow down a little\nbit so we get it right. It's mind-blowing how awesome\nour future can be, right?",
    "start": "7196760",
    "end": "7204470"
  },
  {
    "text": "We talked a lot about stuff on Earth, it can be great, but even if you really get ambitious",
    "start": "7204470",
    "end": "7209900"
  },
  {
    "text": "and look up into the skies, right? There's no reason we have\nto be stuck on this planet for the rest of the remaining,",
    "start": "7209900",
    "end": "7216860"
  },
  {
    "text": "for billions of years to come. We totally understand\nnow that laws of physics",
    "start": "7216860",
    "end": "7222500"
  },
  {
    "text": "let life spread out into\nspace to other solar systems, to other galaxies, and flourish for billions\nand billions of years.",
    "start": "7222500",
    "end": "7230000"
  },
  {
    "text": "And this to me is a\nvery, very hopeful vision that really motivates me to fight.",
    "start": "7230000",
    "end": "7238040"
  },
  {
    "text": "And coming back to it in the end, it's something you talked about again, you know, the struggle, how the human struggle\nis one of the things",
    "start": "7238040",
    "end": "7243160"
  },
  {
    "text": "that's also really gives\nmeaning to our lives. If there's ever been an\nepic struggle, this is it.",
    "start": "7243160",
    "end": "7249977"
  },
  {
    "text": "And isn't it even more epic\nif you're the underdog? If most people are telling\nyou this is gonna fail,",
    "start": "7249977",
    "end": "7255800"
  },
  {
    "text": "it's impossible, right? And you persist and you succeed, right?",
    "start": "7255800",
    "end": "7262156"
  },
  {
    "text": "And that's what we can do\ntogether as a species on this one. A lot of pundits are\nready to count this out.",
    "start": "7262157",
    "end": "7268850"
  },
  {
    "text": "- Both in the battle to keep AI safe and becoming a multi-planetary species. - Yeah, and they're the same challenge.",
    "start": "7268850",
    "end": "7276530"
  },
  {
    "text": "If we can keep AI safe, that's how we're gonna get\nmulti-planetary very efficiently.",
    "start": "7276530",
    "end": "7281630"
  },
  {
    "text": "- I have some sort of technical questions about how to get it right. So one idea that I'm not even sure",
    "start": "7281630",
    "end": "7288829"
  },
  {
    "text": "what the right answer is to is, should systems like GPT-4 be open sourced",
    "start": "7288830",
    "end": "7295070"
  },
  {
    "start": "7291000",
    "end": "7681000"
  },
  {
    "text": "in whole or in part? Can you see the case for either?",
    "start": "7295070",
    "end": "7299122"
  },
  {
    "text": "- I think the answer right now is no. I think the answer early on was yes.",
    "start": "7300740",
    "end": "7305873"
  },
  {
    "text": "So we could bring in all the wonderful great thought process\nof everybody on this,",
    "start": "7306860",
    "end": "7313133"
  },
  {
    "text": "but asking should we open source GPT-4 now is just the same as if you say, should we open source",
    "start": "7314060",
    "end": "7319710"
  },
  {
    "text": "how to build really small nuclear weapons? Should we open source\nhow to make bioweapons?",
    "start": "7321740",
    "end": "7328673"
  },
  {
    "text": "Should we open source\nhow to make a new virus that kills 90% of everybody who gets it?",
    "start": "7329690",
    "end": "7335450"
  },
  {
    "text": "Of course we shouldn't. - So it's already that powerful. It's already that powerful\nthat we have to respect",
    "start": "7335450",
    "end": "7342740"
  },
  {
    "text": "the power of the systems we've built. - The knowledge that you get",
    "start": "7342740",
    "end": "7348989"
  },
  {
    "text": "from open sourcing everything we do now might very well be powerful enough that people looking at that",
    "start": "7350570",
    "end": "7356639"
  },
  {
    "text": "can use it to build the things that are really threatening. Again, let's get it, remember OpenAI's GPT-4 is a baby AI,",
    "start": "7358040",
    "end": "7366083"
  },
  {
    "text": "sort of baby, proto, almost little bit AGI, according to what Microsoft's\nrecent paper said, right?",
    "start": "7367130",
    "end": "7373940"
  },
  {
    "text": "It's not that that we're scared of, what we're scared about is\npeople taking that who are,",
    "start": "7373940",
    "end": "7378320"
  },
  {
    "text": "who might be a lot less responsible than the company that made it, right? And just go into town with it.",
    "start": "7379670",
    "end": "7386030"
  },
  {
    "text": "That's why we wanna, it's an information hazard.",
    "start": "7386030",
    "end": "7392180"
  },
  {
    "text": "There are many things which, yeah, are not open-sourced\nright now in society for very good reason.",
    "start": "7392180",
    "end": "7397790"
  },
  {
    "text": "Like how do you make certain\nkind of very powerful toxins",
    "start": "7397790",
    "end": "7402790"
  },
  {
    "text": "out of stuff you can buy in Home Depot? We don't open source\nthose things for a reason,",
    "start": "7403670",
    "end": "7410390"
  },
  {
    "text": "and this is really no different. - [Lex] So- - And I'm saying that,",
    "start": "7410390",
    "end": "7415552"
  },
  {
    "text": "I have to say it feels a bit weird, in a way, a bit weird to say it because MIT is like the cradle\nof the open source movement.",
    "start": "7415552",
    "end": "7422360"
  },
  {
    "text": "And I love open source in general, power to the people, I say,",
    "start": "7422360",
    "end": "7426113"
  },
  {
    "text": "but there's always gonna be some stuff that you don't open source, and you know, it's just\nlike you don't open source,",
    "start": "7427580",
    "end": "7435440"
  },
  {
    "text": "so we have a three-month old baby, right? When he gets a little bit older, we're not gonna open source to him all the most dangerous things\nhe can do in the house, right?",
    "start": "7435440",
    "end": "7442823"
  },
  {
    "text": "- But it does, it's a weird feeling because this is one of the\nfirst moments in history",
    "start": "7444320",
    "end": "7450590"
  },
  {
    "text": "where there's a strong case to be made not to open source software.",
    "start": "7450590",
    "end": "7455720"
  },
  {
    "text": "This is when the software\nhas become too dangerous. - Yeah, but it's not the first time",
    "start": "7455720",
    "end": "7461150"
  },
  {
    "text": "that we didn't wanna\nopen source a technology. - Technology, yeah.",
    "start": "7461150",
    "end": "7464063"
  },
  {
    "text": "Is there something to be said about how to get the release\nof such systems right, like GPT-4 and GPT-5?",
    "start": "7467150",
    "end": "7472804"
  },
  {
    "text": "So OpenAI went through\na pretty rigorous effort for several months, you could say it could be longer,",
    "start": "7474875",
    "end": "7480320"
  },
  {
    "text": "but nevertheless it's longer\nthan you would've expected of trying to test the system to see like what are the ways goes wrong",
    "start": "7480320",
    "end": "7486710"
  },
  {
    "text": "to make it very difficult, well, somewhat difficult\nfor people to ask things,",
    "start": "7486710",
    "end": "7491817"
  },
  {
    "text": "\"How do I make a bomb for $1?\" Or \"How do I say I hate a\ncertain group on Twitter",
    "start": "7491817",
    "end": "7500210"
  },
  {
    "text": "in a way that doesn't get\nme blocked from Twitter, banned from Twitter.\" Those kinds of questions.",
    "start": "7500210",
    "end": "7505400"
  },
  {
    "text": "So you basically use\nthe system to do harm. - [Max] Yeah.",
    "start": "7505400",
    "end": "7509953"
  },
  {
    "text": "- Is there something you could say about ideas you have that's just, on looking having thought about\nthis problem of AI safety,",
    "start": "7510830",
    "end": "7517760"
  },
  {
    "text": "how to release a system, how to test such systems when you have them inside the company.",
    "start": "7517760",
    "end": "7522323"
  },
  {
    "text": "- Yeah, so a lot of people say that the two biggest risks\nfrom large language models are,",
    "start": "7525170",
    "end": "7533393"
  },
  {
    "text": "it's spreading disinformation, harmful information of various types,",
    "start": "7537740",
    "end": "7542483"
  },
  {
    "text": "and second being used for\noffensive cyberweapon.",
    "start": "7543800",
    "end": "7548662"
  },
  {
    "text": "I think those are not\nthe two greatest threats. They're very serious threats, and it's wonderful that people\nare trying to mitigate them.",
    "start": "7551420",
    "end": "7557453"
  },
  {
    "text": "A much bigger elephant in the room is how this is gonna disrupt our economy in a huge way, obviously, and maybe take away a lot\nof the most meaningful jobs.",
    "start": "7559155",
    "end": "7566360"
  },
  {
    "text": "And an even bigger one is\nthe one we spent so much time talking about here that this",
    "start": "7567230",
    "end": "7572670"
  },
  {
    "text": "becomes the bootloader\nfor the more powerful AI. - Write code, connected to the\ninternet, manipulate humans.",
    "start": "7573710",
    "end": "7581150"
  },
  {
    "text": "- Yeah, and before we know\nit, we have something else, which is not at all a large language model that looks nothing like it,",
    "start": "7581150",
    "end": "7586910"
  },
  {
    "text": "but which is way more intelligent and capable and has goals. And that's the elephant in the room.",
    "start": "7586910",
    "end": "7593750"
  },
  {
    "text": "And obviously no matter how hard any of these companies have tried,",
    "start": "7593750",
    "end": "7597970"
  },
  {
    "text": "that's not something that's easy for them to verify with large language models. And the only way to really\nlower that risk a lot",
    "start": "7599330",
    "end": "7605720"
  },
  {
    "text": "would be to not let, for example, never let it read any code, not train on that,",
    "start": "7605720",
    "end": "7612050"
  },
  {
    "text": "and not put it into an API, and to not Give it access\nto so much information",
    "start": "7612050",
    "end": "7619420"
  },
  {
    "text": "about how to manipulate humans, so, but that doesn't mean you still can't make",
    "start": "7620390",
    "end": "7625699"
  },
  {
    "text": "a ton of money on them, you know? We're gonna just watch now\nthis coming year, right?",
    "start": "7627050",
    "end": "7633770"
  },
  {
    "text": "Microsoft is rolling\nout the new Office Suite where you go into Microsoft Word,",
    "start": "7633770",
    "end": "7639950"
  },
  {
    "text": "and give it a prompt, and it write the whole text for you and then you edit it and then you're like,",
    "start": "7639950",
    "end": "7645057"
  },
  {
    "text": "\"Oh, gimme a PowerPoint version of this,\" and it makes it. \"And now take the\nspreadsheet and blah blah.\"",
    "start": "7645057",
    "end": "7650420"
  },
  {
    "text": "And you know, all of those things I think are, you can debate the economic impact of it",
    "start": "7650420",
    "end": "7655970"
  },
  {
    "text": "and whether society is prepared to deal with this disruption. But those are not the things which,",
    "start": "7655970",
    "end": "7661080"
  },
  {
    "text": "that's not the elephant of the room that keeps me awake at night\nfor wiping out humanity.",
    "start": "7662330",
    "end": "7666270"
  },
  {
    "text": "And I think that's the biggest\nmisunderstanding we have. A lot of people think that we're scared of",
    "start": "7667534",
    "end": "7673040"
  },
  {
    "text": "like automatic spreadsheets. That's not the case. That's not what Eliezer was\nfreaked out about either.",
    "start": "7673040",
    "end": "7679730"
  },
  {
    "text": "- Is there in terms of\nthe actual mechanism of how AI might kill all humans.",
    "start": "7679730",
    "end": "7686750"
  },
  {
    "start": "7681000",
    "end": "8312000"
  },
  {
    "text": "So something you've been outspoken about, you've talked about a lot. Is it autonomous weapon systems?",
    "start": "7686750",
    "end": "7693739"
  },
  {
    "text": "So the use of AI in war, is that one of the things that's still",
    "start": "7693740",
    "end": "7699500"
  },
  {
    "text": "you carry concern for as these systems become\nmore and more powerful? - I carry a concern for it, not that all humans are gonna\nget killed by slaughter bots,",
    "start": "7699500",
    "end": "7706520"
  },
  {
    "text": "but rather just as express route into an Orwellian dystopia",
    "start": "7706520",
    "end": "7711890"
  },
  {
    "text": "where it becomes much easier for very few to kill very many, and therefore it becomes very easy for very few to dominate very many, right?",
    "start": "7711890",
    "end": "7718552"
  },
  {
    "text": "AI, if you wanna know how\nAI could kill all people, just ask yourself, we humans have driven a\nlot of species extinct.",
    "start": "7721430",
    "end": "7727760"
  },
  {
    "text": "How do we do it? You know, we were smarter than them,",
    "start": "7727760",
    "end": "7731627"
  },
  {
    "text": "usually we didn't do\nit even systematically by going around one-on-one, one after the other and stepping on them,",
    "start": "7732980",
    "end": "7738800"
  },
  {
    "text": "or shooting them or anything like that. We just like chopped down their habitat 'cause we needed it for something else.",
    "start": "7738800",
    "end": "7744233"
  },
  {
    "text": "In some cases we did it by putting more carbon dioxide in the atmosphere because of some reason",
    "start": "7745610",
    "end": "7750860"
  },
  {
    "text": "that those animals didn't even understand, and now they're gone, right? So if you're an AI,",
    "start": "7750860",
    "end": "7758536"
  },
  {
    "text": "and you just wanna figure something out, then you decide, you know, we just really need this space here",
    "start": "7758537",
    "end": "7766460"
  },
  {
    "text": "to build more compute facilities. You know, if that's the\nonly goal it has, you know,",
    "start": "7766460",
    "end": "7773950"
  },
  {
    "text": "we are just the sort of\naccidental roadkill along the way. And you could totally imagine, \"Yeah, maybe this oxygen\nis kind of annoying",
    "start": "7774680",
    "end": "7780830"
  },
  {
    "text": "'cause it cause more corrosion, so let's get rid of the oxygen.\" And good luck surviving after that.",
    "start": "7780830",
    "end": "7785937"
  },
  {
    "text": "You know, I'm not particularly concerned that they would want to kill us just because that would\nbe like a goal in itself.",
    "start": "7785937",
    "end": "7794920"
  },
  {
    "text": "you know, when we.. we've driven a number of the elephant species extinct. Right?",
    "start": "7795890",
    "end": "7802340"
  },
  {
    "text": "It wasn't 'cause we didn't like elephants.",
    "start": "7802340",
    "end": "7804440"
  },
  {
    "text": "The basic problem is you\njust don't want to give, you don't wanna cede\ncontrol over your planet",
    "start": "7807530",
    "end": "7813949"
  },
  {
    "text": "to some other more intelligent entity that doesn't share your goals. It's that simple, and so,",
    "start": "7813950",
    "end": "7819623"
  },
  {
    "text": "which brings us to another key challenge which AI safety research has been grappling with for a long time.",
    "start": "7820730",
    "end": "7826700"
  },
  {
    "text": "Like, how do you make AI, first of all, understand our goals",
    "start": "7826700",
    "end": "7831710"
  },
  {
    "text": "and then adopt our goals, and then retain them as\nthey get smarter, right?",
    "start": "7831710",
    "end": "7835159"
  },
  {
    "text": "All three of those are really hard, right? Like a human child,",
    "start": "7841520",
    "end": "7846950"
  },
  {
    "text": "first, they're just not smart enough to understand our goals.",
    "start": "7846950",
    "end": "7850640"
  },
  {
    "text": "They can't even talk. And then eventually they're teenagers, and understand our goals just fine,",
    "start": "7852090",
    "end": "7857665"
  },
  {
    "text": "but they don't share. (laughs) - [Lex] Yeah. - But there is fortunately\na magic phase in the middle",
    "start": "7857665",
    "end": "7863750"
  },
  {
    "text": "where they're smart enough\nto understand our goals and malleable enough\nthat we can hopefully, with good parenting, teach\nthem right from wrong",
    "start": "7863750",
    "end": "7869570"
  },
  {
    "text": "and instill good goals in them, right? So those are all tough\nchallenges with computers.",
    "start": "7869570",
    "end": "7877970"
  },
  {
    "text": "And then, you know, even if you teach your kids\ngood goals when they're little, they might outgrow them too, and that's a challenge for\nmachines to keep improving.",
    "start": "7877970",
    "end": "7885710"
  },
  {
    "text": "So these are a lot of hard,\nhard challenges we're up for, but I don't think any of\nthem are insurmountable.",
    "start": "7885710",
    "end": "7893242"
  },
  {
    "text": "The fundamental reason why Eliezer looked so depressed when I last saw him was because he felt there\njust wasn't enough time.",
    "start": "7894620",
    "end": "7902059"
  },
  {
    "text": "- Oh, that not that it was unsolvable, - Correct. - There's just not enough time. - He was hoping that humanity",
    "start": "7902060",
    "end": "7907369"
  },
  {
    "text": "was gonna take this threat more seriously, so we would have more time, and now we don't have more time.",
    "start": "7907370",
    "end": "7913400"
  },
  {
    "text": "That's why the open letter\nis calling for more time.",
    "start": "7913400",
    "end": "7916343"
  },
  {
    "text": "- But even with time, the AI alignment problem, it seems to be really difficult.",
    "start": "7919880",
    "end": "7926389"
  },
  {
    "text": "- Oh yeah. But it's also the most worthy problem,",
    "start": "7926390",
    "end": "7931700"
  },
  {
    "text": "the most important problem\nfor humanity to ever solve. Because if we solve that one, Lex,",
    "start": "7931700",
    "end": "7935963"
  },
  {
    "text": "that aligned AI can help us\nsolve all the other problems. - 'Cause it seems like it has to have constant\nhumility about its goal,",
    "start": "7937460",
    "end": "7944900"
  },
  {
    "text": "constantly question the goal. Because as you optimize\ntowards a particular goal",
    "start": "7944900",
    "end": "7951047"
  },
  {
    "text": "and you start to achieve it, that's when you have the\nunintended consequences, all the things you mentioned about. So how do you enforce and\ncode a constant humility",
    "start": "7951047",
    "end": "7960020"
  },
  {
    "text": "as your ability become better, and better, and better, and better? - Professor Stuart Russell at Berkeley is also one of the driving\nforces behind this letter,",
    "start": "7960020",
    "end": "7969650"
  },
  {
    "text": "he has a whole research\nprogram about this.",
    "start": "7969650",
    "end": "7974393"
  },
  {
    "text": "I think of it as a AI humility, exactly. Although he calls it inverse\nreinforcement learning",
    "start": "7976100",
    "end": "7981350"
  },
  {
    "text": "and other nerdy terms. But it's about exactly that. Instead of telling the AI, \"Here's this goal, go optimize the the bejesus out of it.\"",
    "start": "7981350",
    "end": "7989027"
  },
  {
    "text": "You tell it, \"Okay, do\nwhat I want you to do, but I'm not gonna tell\nyou right now what it is",
    "start": "7990380",
    "end": "7996920"
  },
  {
    "text": "I want you to do. You need to figure it out.\" So then you give the\nincentives to be very humble and keep asking you\nquestions along the way.",
    "start": "7996920",
    "end": "8003370"
  },
  {
    "text": "Is this what you really meant? Is this what you wanted? And oh the other thing\nI tried didn't work, and seemed like it didn't work out right.",
    "start": "8003370",
    "end": "8009310"
  },
  {
    "text": "Should I try it differently? What's nice about this is it's not just\nphilosophical mumbo-jumbo,",
    "start": "8009310",
    "end": "8016210"
  },
  {
    "text": "it's theorems and technical\nwork that with more time, I think it can make a lot of progress, and there are a lot of\nbrilliant people now",
    "start": "8016210",
    "end": "8023320"
  },
  {
    "text": "working on AI safety. We just need to give em a bit more time. - But also not that many\nrelative to skill of the prompt.",
    "start": "8023320",
    "end": "8030996"
  },
  {
    "text": "- No, exactly. There should be at least this, just like every university worth its name",
    "start": "8030997",
    "end": "8037390"
  },
  {
    "text": "has some cancer research going on in its biology department, right? Every university that\ndoes computer science",
    "start": "8037390",
    "end": "8043809"
  },
  {
    "text": "should have a real effort in this area and it's nowhere near that.",
    "start": "8043810",
    "end": "8049300"
  },
  {
    "text": "This is something I hope is changing now, thanks to the GPT-4, right? So I think if there's a silver lining",
    "start": "8049300",
    "end": "8057190"
  },
  {
    "text": "to what's happening here, even though I think many people would wish it would've been rolled\nout more carefully,",
    "start": "8057190",
    "end": "8064420"
  },
  {
    "text": "is that this might be the wake-up call that humanity needed,",
    "start": "8064420",
    "end": "8069490"
  },
  {
    "text": "to really stop fantasizing about this being a hundred years off",
    "start": "8069490",
    "end": "8075231"
  },
  {
    "text": "and stop fantasizing about this being completely\ncontrollable and predictable because it's so obvious,",
    "start": "8075231",
    "end": "8081969"
  },
  {
    "text": "it's not predictable, you know? why is it that,",
    "start": "8081970",
    "end": "8086173"
  },
  {
    "text": "I think it was ChatGPT that\ntried to persuade a journalist",
    "start": "8089244",
    "end": "8091333"
  },
  {
    "text": "to divorce his wife, you know. It was not 'cause the\nengineers had built it, was like, (laughs mischievously)",
    "start": "8097690",
    "end": "8104837"
  },
  {
    "text": "\"Let's put this in here, and screw a little bit with people.\" They hadn't predicted it at all.",
    "start": "8104837",
    "end": "8111820"
  },
  {
    "text": "They built the giant black box trained to predict the next word and got all these emergent properties,",
    "start": "8111820",
    "end": "8118119"
  },
  {
    "text": "and oops, it did this, you know.",
    "start": "8118120",
    "end": "8120553"
  },
  {
    "text": "I think this is a very\npowerful wake-up call and anyone watching this who's not scared,",
    "start": "8124000",
    "end": "8129850"
  },
  {
    "text": "I would encourage them to just play a bit more with these tools. They're out there now like GPT-4 and,",
    "start": "8129850",
    "end": "8137863"
  },
  {
    "text": "so wake-up call is first step, once you've woken up, then gotta slow down a\nlittle bit the risky stuff",
    "start": "8141010",
    "end": "8146420"
  },
  {
    "text": "to give a chance to\neveryone that has woken up to catch up with this on the safety front.",
    "start": "8147340",
    "end": "8152559"
  },
  {
    "text": "- You know what's\ninteresting is, you know, MIT, that's computer science,",
    "start": "8152560",
    "end": "8158110"
  },
  {
    "text": "but in general, but let's just even say\ncomputer science curriculum. How does the computer science\ncurriculum change now?",
    "start": "8158110",
    "end": "8164440"
  },
  {
    "text": "You mentioned programming. - [Max] Yeah. - Like why would you be,",
    "start": "8164440",
    "end": "8169780"
  },
  {
    "text": "when I was coming up, programming as a prestigious position. Like why would you be\ndedicating crazy amounts of time",
    "start": "8169780",
    "end": "8177580"
  },
  {
    "text": "to become an excellent programmer? Like the nature of programming\nis fundamentally changing. - The nature of our\nentire education system",
    "start": "8177580",
    "end": "8184790"
  },
  {
    "text": "is completely turned on its head. - Has anyone been able\nto like, load that in,",
    "start": "8185710",
    "end": "8190869"
  },
  {
    "text": "and like think, because\nit's really turning, - I mean some English professors, some English teachers are\nbeginning to really freak out now.",
    "start": "8190870",
    "end": "8198399"
  },
  {
    "text": "Right? Like they give an essay assignment and they get back all\nthis fantastic prose, like this is style of Hemmingway,",
    "start": "8198401",
    "end": "8204910"
  },
  {
    "text": "and then they realize they\nhave to completely rethink and even, you know, just\nlike we stopped teaching,",
    "start": "8204910",
    "end": "8212983"
  },
  {
    "text": "writing a script, is that what you say in English? - [Lex] Yeah, handwritten, yeah. - Yeah, when everybody started typing,",
    "start": "8214210",
    "end": "8220990"
  },
  {
    "text": "you know, like so much of\nwhat we teach our kids today.",
    "start": "8220990",
    "end": "8224113"
  },
  {
    "text": "- Yeah, I mean that's, everything is changing and\nit is changing very quickly.",
    "start": "8228071",
    "end": "8237540"
  },
  {
    "text": "And so much of us understanding how to deal with the big\nproblems of the world is through the education system.",
    "start": "8237941",
    "end": "8243969"
  },
  {
    "text": "And if the education system\nis being turned on its head, then what's next? It feels like having these\nkinds of conversations",
    "start": "8243970",
    "end": "8250630"
  },
  {
    "text": "is essential to trying to figure it out. And everything's happening so rapidly. I don't think there's even,",
    "start": "8250630",
    "end": "8257019"
  },
  {
    "text": "you're speaking of safety, the broad AI safety defined, I don't think most universities\nhave courses on AI safety.",
    "start": "8257020",
    "end": "8264400"
  },
  {
    "text": "It's like a philosophy seminar. - Yeah, and like I'm an educator myself, so it pains me to say this,",
    "start": "8264401",
    "end": "8270700"
  },
  {
    "text": "but I feel our education right now is completely obsoleted\nby what's happening.",
    "start": "8270700",
    "end": "8276517"
  },
  {
    "text": "You know, you put a kid into first grade, and then you are envisioning like, and then they're gonna come out",
    "start": "8276518",
    "end": "8282429"
  },
  {
    "text": "of high school 12 years later, and you've already pre-planned now what they're gonna learn,",
    "start": "8282430",
    "end": "8287889"
  },
  {
    "text": "when you're not even sure if there's gonna be any\nworld left to come out to, like clearly you need to have a much more",
    "start": "8287890",
    "end": "8296219"
  },
  {
    "text": "opportunistic education system that keeps adapting itself very rapidly as society re-adapts.",
    "start": "8296500",
    "end": "8302739"
  },
  {
    "text": "The skills that were really useful when the curriculum was written, I mean how many of those skills",
    "start": "8302740",
    "end": "8308559"
  },
  {
    "text": "are gonna get you a job in 12 years? I mean, seriously. - If we just linger on the\nGPT-4 system a little bit,",
    "start": "8308560",
    "end": "8316123"
  },
  {
    "start": "8312000",
    "end": "8874000"
  },
  {
    "text": "you kind of hinted at it, especially talking about the importance of consciousness in in the\nhuman mind with Homo sentiens.",
    "start": "8317890",
    "end": "8327630"
  },
  {
    "text": "Do you think GPT-4 is conscious? - Ah, I love this question.",
    "start": "8328420",
    "end": "8334062"
  },
  {
    "text": "So let's define consciousness first because in my experience, like 90% of all arguments\nabout consciousness,",
    "start": "8335321",
    "end": "8341835"
  },
  {
    "text": "(Lex chuckles) boil down to the two people arguing having totally different\ndefinitions of what it is, then they're just\nshouting past each other.",
    "start": "8341835",
    "end": "8348283"
  },
  {
    "text": "I define consciousness\nas subjective experience.",
    "start": "8349180",
    "end": "8353743"
  },
  {
    "text": "Right now I'm experiencing\ncolors and sounds, and emotions, you know, but does a self-driving\ncar experience anything?",
    "start": "8354850",
    "end": "8362653"
  },
  {
    "text": "That's the question about whether it's conscious or not, right? Other people think",
    "start": "8363640",
    "end": "8369169"
  },
  {
    "text": "you should define\nconsciousness differently, fine by me, but then maybe use a\ndifferent word for it.",
    "start": "8369169",
    "end": "8375639"
  },
  {
    "text": "Or they can, I'm gonna use consciousness\nfor this at least, so,",
    "start": "8375640",
    "end": "8380892"
  },
  {
    "text": "but if people hate the, yeah. So is GPT-4 conscious? Does GPT-4 have subjective experience?",
    "start": "8382572",
    "end": "8390100"
  },
  {
    "text": "Short answer, I don't know, because we still don't know what it is that gives this wonderful\nsubjective experience",
    "start": "8390100",
    "end": "8396730"
  },
  {
    "text": "that is kind of the\nmeaning of our life, right? Because meaning itself, the feeling of meaning is\na subjective experience.",
    "start": "8396730",
    "end": "8402670"
  },
  {
    "text": "Joy is a subjective experience, love is a subjective experience, we don't know what it is,",
    "start": "8402670",
    "end": "8408730"
  },
  {
    "text": "I've written some papers about this, a lot of people have.",
    "start": "8408730",
    "end": "8412723"
  },
  {
    "text": "Giulio Tononi, a professor, has stuck his neck out the farthest",
    "start": "8413800",
    "end": "8419229"
  },
  {
    "text": "and written down actually very\nbold mathematical conjecture for what's the essence of\nconscious information processing.",
    "start": "8419230",
    "end": "8427000"
  },
  {
    "text": "He might be wrong, he might be right, but we should test it. He postulates that the consciousness",
    "start": "8427000",
    "end": "8433690"
  },
  {
    "text": "has to do with loops in\nthe information processing. So our brain has loops.",
    "start": "8433690",
    "end": "8438674"
  },
  {
    "text": "Information can go round and round, in computer science nerd-speak, you call it a recurrent neural network",
    "start": "8439630",
    "end": "8445480"
  },
  {
    "text": "where some of the output\ngets fed back in again. And with his",
    "start": "8445480",
    "end": "8450021"
  },
  {
    "text": "mathematical formulism, if it's a feed-forward neural network where information only\ngoes in one direction,",
    "start": "8452290",
    "end": "8458740"
  },
  {
    "text": "like from your eye retina\ninto the back of your brain for example, that's not conscious. So he would predict\nthat your retina itself",
    "start": "8458740",
    "end": "8464680"
  },
  {
    "text": "isn't conscious of anything, or a video camera. Now the interesting thing about GPT-4",
    "start": "8464680",
    "end": "8471399"
  },
  {
    "text": "is it's also just a one-way\nflow of information. So if Tononi is right, then GPT-4 is a very intelligent zombie,",
    "start": "8471400",
    "end": "8480903"
  },
  {
    "text": "that can do all this smart stuff but isn't experiencing anything. And this is both a relief",
    "start": "8481000",
    "end": "8489939"
  },
  {
    "text": "if it's true, and that you don't have to feel guilty about turning off GPT-4\nand wiping its memory",
    "start": "8489940",
    "end": "8495640"
  },
  {
    "text": "whenever a new user comes along. I wouldn't like if someone did that to me, and neuralyze me like in \"Men In Black.\"",
    "start": "8495640",
    "end": "8502497"
  },
  {
    "text": "But it's also creepy, that you can have a very high intelligence",
    "start": "8503590",
    "end": "8509530"
  },
  {
    "text": "perhaps that is not conscious, because if we get replaced by machines,",
    "start": "8509530",
    "end": "8513433"
  },
  {
    "text": "and while it's sad enough that\nhumanity isn't here anymore, 'cause I kind of like humanity,",
    "start": "8515980",
    "end": "8520394"
  },
  {
    "text": "but at least if the\nmachines were conscious, I could be like, \"Well, but\nthey are our descendants and maybe they have our values\nand they are our children.\"",
    "start": "8522430",
    "end": "8529270"
  },
  {
    "text": "But if Tononi is right and these are all transformers that are,",
    "start": "8529270",
    "end": "8535663"
  },
  {
    "text": "not in the sense of Hollywood, but in the sense of these one-way\ndirection neural networks,",
    "start": "8537340",
    "end": "8543400"
  },
  {
    "text": "so they're all the zombies, that's the ultimate zombie apocalypse now. We have this universe that goes on with great construction\nprojects and stuff,",
    "start": "8543400",
    "end": "8550450"
  },
  {
    "text": "but there's no one experiencing anything. That would be like the\nultimate depressing future.",
    "start": "8550450",
    "end": "8557230"
  },
  {
    "text": "So I actually think, as we move forward with\nbuilding more advanced AI,",
    "start": "8557230",
    "end": "8562899"
  },
  {
    "text": "we should do more research on figuring out what kind of information processing actually it has experienced, because I think that's\nwhat it's all about.",
    "start": "8562900",
    "end": "8569620"
  },
  {
    "text": "And I completely don't buy the dismissal that some people will say,",
    "start": "8569620",
    "end": "8575117"
  },
  {
    "text": "\"Well this is all bullshit because consciousness\nequals intelligence.\" - [Lex] Right. - That's obviously not true.",
    "start": "8575117",
    "end": "8580990"
  },
  {
    "text": "You can have a lot of conscious experience when you're not really\naccomplishing any goals at all.",
    "start": "8580990",
    "end": "8586150"
  },
  {
    "text": "You're just reflecting on something, and you can sometimes,",
    "start": "8586150",
    "end": "8590203"
  },
  {
    "text": "doing things that require intelligence probably without being conscious. - But I also worry that we humans,",
    "start": "8592840",
    "end": "8598483"
  },
  {
    "text": "will discriminate against AI systems that clearly exhibit consciousness. That we will not allow AI\nsystems to have consciousness.",
    "start": "8600670",
    "end": "8609100"
  },
  {
    "text": "We'll come up with theories\nabout measuring consciousness that will say this is a lesser being,",
    "start": "8609100",
    "end": "8615190"
  },
  {
    "text": "and this was like, I worry about that because maybe, we humans will create something",
    "start": "8615190",
    "end": "8620680"
  },
  {
    "text": "that is better than us humans, in the way that we find beautiful,",
    "start": "8620680",
    "end": "8627130"
  },
  {
    "text": "which is they have a deeper subjective experience of reality.",
    "start": "8627130",
    "end": "8632260"
  },
  {
    "text": "Not only are they smarter,\nbut they feel deeper. And we humans will hate them for it.",
    "start": "8632260",
    "end": "8638623"
  },
  {
    "text": "As human history is shown, they'll be the \"other,\" we'll try to suppress it,",
    "start": "8639460",
    "end": "8644860"
  },
  {
    "text": "they'll create conflict, they'll create war, all of this. I worry about this too. - Are you saying that we humans",
    "start": "8644860",
    "end": "8650949"
  },
  {
    "text": "sometimes come up with\nself-serving arguments? No, we would never do that, would we? - Well that's the danger here is,",
    "start": "8650950",
    "end": "8657910"
  },
  {
    "text": "even in this early stages, we might create something beautiful. And we'll erase its memory.",
    "start": "8657910",
    "end": "8664990"
  },
  {
    "text": "- I was horrified as a kid when someone started boiling lobsters.",
    "start": "8664990",
    "end": "8672790"
  },
  {
    "text": "I'm like, \"Oh my God, that's so cruel.\" And some grownup there\nback in Sweden said,",
    "start": "8672790",
    "end": "8678527"
  },
  {
    "text": "\"Oh, it doesn't feel pain.\" I'm like, \"How do you know that?\" \"Oh, a scientist have shown that.\"",
    "start": "8678527",
    "end": "8683197"
  },
  {
    "text": "And then there was a recent study where they show that lobsters\nactually do feel pain when you boil them. So they banned lobster\nboiling in Switzerland now.",
    "start": "8684790",
    "end": "8692000"
  },
  {
    "text": "You have to kill them in\na different way first. Presumably, a scientific\nresearch boiled down",
    "start": "8692000",
    "end": "8697120"
  },
  {
    "text": "to someone asked the\nlobster, \"Does it hurt?\" (both laughing) - Survey, self-report. - And we do the same thing",
    "start": "8697120",
    "end": "8702580"
  },
  {
    "text": "with cruelty to farm animals also, all these self-serving\narguments for why they're fine. And yeah, so we should certainly,",
    "start": "8702580",
    "end": "8708974"
  },
  {
    "text": "what I think step one is just be humble, and acknowledge that consciousness is not the same thing as intelligence.",
    "start": "8710140",
    "end": "8716050"
  },
  {
    "text": "And I believe that consciousness still is a form of information processing where it's really information",
    "start": "8716050",
    "end": "8721390"
  },
  {
    "text": "being aware of itself in a certain way, and let's study it and give\nourselves a little bit of time, and I think we will be able to figure out",
    "start": "8721390",
    "end": "8728230"
  },
  {
    "text": "actually what it is that\ncauses consciousness. And then we can make\nprobably unconscious robots",
    "start": "8728230",
    "end": "8734590"
  },
  {
    "text": "that do the boring jobs that we would feel immoral\nto give the machines. But if you have a companion robot",
    "start": "8734590",
    "end": "8739750"
  },
  {
    "text": "taking care of your mom\nor something like that, she would probably want\nit to be conscious, right?",
    "start": "8739750",
    "end": "8745780"
  },
  {
    "text": "So the emotions it seems\nto display aren't fake. All these things can be done in a good way",
    "start": "8745780",
    "end": "8753700"
  },
  {
    "text": "if we give ourselves a little bit of time, and don't run, and take on this challenge.",
    "start": "8753700",
    "end": "8759430"
  },
  {
    "text": "- Is there something you\ncould say to the timeline that you think about, about the development of AGI?",
    "start": "8759430",
    "end": "8766003"
  },
  {
    "text": "Depending on the day, I'm sure that changes for you, but when do you think there would be a really\nbig leap in intelligence",
    "start": "8766960",
    "end": "8774880"
  },
  {
    "text": "where you would definitively\nsay we have built AGI? Do you think it's one year from now, five years from now, 10, 20, 50?",
    "start": "8774880",
    "end": "8783220"
  },
  {
    "text": "What's your gut say? - Honestly, for the past decade,",
    "start": "8783220",
    "end": "8792550"
  },
  {
    "text": "I've deliberately given\nvery long timelines because I didn't want to fuel some kind of stupid Moloch race.",
    "start": "8792550",
    "end": "8797770"
  },
  {
    "text": "- [Lex] Yeah. - But I think that cat has\nreally left the bag now.",
    "start": "8797770",
    "end": "8802003"
  },
  {
    "text": "I think we might be very, very close. I don't think the Microsoft\npaper is totally off",
    "start": "8804070",
    "end": "8810640"
  },
  {
    "text": "when they say that there\nare some glimmers of AGI. It's not AGI yet, it's not an agent,",
    "start": "8810640",
    "end": "8817750"
  },
  {
    "text": "there's a lot of things they can't do. But I wouldn't bet very strongly",
    "start": "8817750",
    "end": "8823810"
  },
  {
    "text": "against it happening very soon, that's why we decided\nto do this open letter.",
    "start": "8823810",
    "end": "8829689"
  },
  {
    "text": "Because you know, if there's ever been a\ntime to pause, you know, it's today.",
    "start": "8829690",
    "end": "8834282"
  },
  {
    "text": "- There's a feeling like this GPT-4 is a big transition\ninto waking everybody up",
    "start": "8835810",
    "end": "8841900"
  },
  {
    "text": "to the effectiveness of these systems. And so the next version will be big.",
    "start": "8841900",
    "end": "8848500"
  },
  {
    "text": "- Yeah, and if that next one isn't AGI, maybe the next next one will. And there are many companies\ntrying to do these things",
    "start": "8848500",
    "end": "8855340"
  },
  {
    "text": "and the basic architecture of 'em is not some sort of\nsuper well-kept secret. So this is a time to...",
    "start": "8855340",
    "end": "8863830"
  },
  {
    "text": "A lot of people have said for many years that there will come a time when we want to pause a little bit,",
    "start": "8863830",
    "end": "8868670"
  },
  {
    "text": "that time is now. - You have spoken about",
    "start": "8870430",
    "end": "8876310"
  },
  {
    "start": "8874000",
    "end": "9501000"
  },
  {
    "text": "and thought about nuclear war a lot. Over the past year, we\nseemingly have come closest",
    "start": "8876310",
    "end": "8885270"
  },
  {
    "text": "to the precipice of nuclear war than, at least in my lifetime.",
    "start": "8886480",
    "end": "8891880"
  },
  {
    "text": "- [Max] Mhm, yeah. - What do you learn about\nhuman nature from that? - It's our old friend Moloch again.",
    "start": "8891880",
    "end": "8898783"
  },
  {
    "text": "It is really scary to see it where,",
    "start": "8899726",
    "end": "8902562"
  },
  {
    "text": "America doesn't want\nthere to be a nuclear war. Russia doesn't want there to\nbe a global nuclear war either. We both know that it's just be another,",
    "start": "8904750",
    "end": "8912069"
  },
  {
    "text": "if we just try to do it, if both sides try to launch first, it's just another suicide race, right?",
    "start": "8912070",
    "end": "8917650"
  },
  {
    "text": "So why are we, why is it the way you said, that this is the closest\nwe've come since 1962?",
    "start": "8917650",
    "end": "8923260"
  },
  {
    "text": "In fact, I think we've come closer now than even the Cuban Missile Crisis. It's 'cause of Moloch, You know, you have these other forces.",
    "start": "8923260",
    "end": "8930763"
  },
  {
    "text": "On one hand you have the West saying that we have to\ndrive Russia out of Ukraine,",
    "start": "8931660",
    "end": "8939940"
  },
  {
    "text": "it's a matter of pride. And we've staked so much on it that it would be seen as a huge loss",
    "start": "8939940",
    "end": "8948340"
  },
  {
    "text": "of the credibility of the West if we don't drive Russia\nout entirely of the Ukraine.",
    "start": "8948340",
    "end": "8952903"
  },
  {
    "text": "And on the other hand,\nyou have Russia who has,",
    "start": "8954910",
    "end": "8959910"
  },
  {
    "text": "and you have the Russian leadership who knows that if they get\ncompletely driven out of Ukraine,",
    "start": "8960430",
    "end": "8965530"
  },
  {
    "text": "you know, it might, it's not just gonna be\nvery humiliating for them,",
    "start": "8965530",
    "end": "8971500"
  },
  {
    "text": "but they might, it often happens when countries lose wars that the things don't go so well",
    "start": "8971500",
    "end": "8978040"
  },
  {
    "text": "for their leadership either. Like, you remember when Argentina invaded the Falkland Islands?",
    "start": "8978040",
    "end": "8982483"
  },
  {
    "text": "The military junta that\nordered that, right? People are cheering on\nthe streets at first",
    "start": "8984911",
    "end": "8990430"
  },
  {
    "text": "when they took it, and then when they got their\nbutt kicked by the British,",
    "start": "8990430",
    "end": "8996670"
  },
  {
    "text": "you know what happened to those guys? They were out. And I believe those who are still alive",
    "start": "8996670",
    "end": "9003720"
  },
  {
    "text": "are in jail now, right? So you know, the Russian\nleadership is entirely cornered",
    "start": "9003720",
    "end": "9009330"
  },
  {
    "text": "where they know that just\ngetting driven out of Ukraine",
    "start": "9009330",
    "end": "9014330"
  },
  {
    "text": "is not an option, and,",
    "start": "9014340",
    "end": "9017613"
  },
  {
    "text": "so this to me, is a\ntypical example of Moloch. You have these incentives\nof the two parties",
    "start": "9020730",
    "end": "9027010"
  },
  {
    "text": "where both of them are\njust driven to escalate more and more, right? If Russia starts losing in\nthe conventional warfare,",
    "start": "9028140",
    "end": "9033960"
  },
  {
    "text": "the only thing they cam do since their back's against the wall, is to keep escalating.",
    "start": "9033960",
    "end": "9038434"
  },
  {
    "text": "And the West has put\nitself in the situation now where we're sort of already\ncommitted to drive Russia out.",
    "start": "9039990",
    "end": "9045540"
  },
  {
    "text": "So the only option the West has, is to call Russia's bluff and\nkeep sending in more weapons.",
    "start": "9045540",
    "end": "9050043"
  },
  {
    "text": "This really bothers me because Moloch can sometimes drive competing parties to do something which is ultimately",
    "start": "9051270",
    "end": "9056970"
  },
  {
    "text": "just really bad for both of them. And you know, what makes me even more\nworried is not just that I,",
    "start": "9056970",
    "end": "9064860"
  },
  {
    "text": "it's difficult to see an ending,",
    "start": "9064860",
    "end": "9069273"
  },
  {
    "text": "a quick peaceful ending to this tragedy that doesn't involve\nsome horrible escalation,",
    "start": "9070170",
    "end": "9075513"
  },
  {
    "text": "but also that we\nunderstand more clearly now just how horrible it would be.",
    "start": "9076350",
    "end": "9081630"
  },
  {
    "text": "There was an amazing\npaper that was published in Naturefood this August,",
    "start": "9081630",
    "end": "9087123"
  },
  {
    "text": "by some of the top researchers who've been studying nuclear\nwinter for a long time, and what they basically did was they combined climate models",
    "start": "9088590",
    "end": "9098130"
  },
  {
    "text": "with food and agricultural models, so instead of just saying,",
    "start": "9098130",
    "end": "9103807"
  },
  {
    "text": "\"Yeah, you know, it gets\nreally cold, blah blah blah,\" they figured out actually\nhow many people would die in different countries.",
    "start": "9103807",
    "end": "9109143"
  },
  {
    "text": "And it's pretty mind-blowing, you know? So basically what happens, you know, is that the thing that\nkills the most people is not the explosions,\nit's not the radioactivity,",
    "start": "9110160",
    "end": "9117150"
  },
  {
    "text": "it's not the EMP mayhem, it's not the rampaging mobs foraging food,",
    "start": "9117150",
    "end": "9124140"
  },
  {
    "text": "no, it's the fact that\nyou get so much smoke coming up from the burning\ncities into the stratosphere",
    "start": "9124140",
    "end": "9129720"
  },
  {
    "text": "that it spreads around the\nEarth from the jetstreams.",
    "start": "9129720",
    "end": "9134720"
  },
  {
    "text": "So in typical models you\nget like 10 years or so where it's just crazy cold",
    "start": "9134940",
    "end": "9140380"
  },
  {
    "text": "during the first year after the war, and in their models,",
    "start": "9142320",
    "end": "9148110"
  },
  {
    "text": "the temperature drops in Nebraska and in the Ukraine bread baskets,",
    "start": "9148110",
    "end": "9153900"
  },
  {
    "text": "you know, by like 20 Celsius or so, if I remember.",
    "start": "9153900",
    "end": "9158940"
  },
  {
    "text": "No yeah, 20, 30 Celsius depending on where you are. 40 Celsius in some places,",
    "start": "9158940",
    "end": "9164490"
  },
  {
    "text": "which is, you know, 40 Fahrenheit to 80 Fahrenheit colder than\nwhat it would it normally be. So, you know, I'm not good at farming but,",
    "start": "9164490",
    "end": "9172401"
  },
  {
    "text": "(Lex laughing) if it's snowing, if it drops below freezing pretty much on most days in July",
    "start": "9172402",
    "end": "9178109"
  },
  {
    "text": "and then like, that's not good. So they worked out, they put this into their farming models and what they found\nwas really interesting.",
    "start": "9178110",
    "end": "9184140"
  },
  {
    "text": "The countries that get the most hard hit are the ones in the northern hemisphere. So in the US,",
    "start": "9184140",
    "end": "9190683"
  },
  {
    "text": "in one model they had, they had about 99% of all\nAmericans starving to death, in Russia, and China, and Europe,",
    "start": "9191700",
    "end": "9198210"
  },
  {
    "text": "also about 99%, 98% starving to death. So you might be like,",
    "start": "9198210",
    "end": "9203377"
  },
  {
    "text": "\"Oh, it's kind of poetic justice that both the Russians and the Americans, 99% of them have to pay for it,",
    "start": "9203377",
    "end": "9209477"
  },
  {
    "text": "'cause it was their bombs that did it.\" But you know, that doesn't particularly\ncheer people up in Sweden",
    "start": "9209477",
    "end": "9215250"
  },
  {
    "text": "or other random countries that have nothing to do with it, right? And it,",
    "start": "9215250",
    "end": "9219981"
  },
  {
    "text": "I think it hasn't entered the mainstream,",
    "start": "9222523",
    "end": "9225903"
  },
  {
    "text": "not understanding very much\njust like how bad this is. Most people, especially a lot of people",
    "start": "9228420",
    "end": "9235740"
  },
  {
    "text": "in decision-making positions still think of nuclear weapons as something that makes you powerful,",
    "start": "9235740",
    "end": "9239869"
  },
  {
    "text": "scary but powerful. They don't think of it as something where, \"Yeah, just to within a percent or two,",
    "start": "9241470",
    "end": "9249510"
  },
  {
    "text": "you know, we're all just\ngonna starve to death and- - And starving to death is,",
    "start": "9249510",
    "end": "9255243"
  },
  {
    "text": "the worst way to die. As Holodomor, as all the\nfamines in history show",
    "start": "9259200",
    "end": "9265110"
  },
  {
    "text": "the torture involved in that. - Probably brings out\nthe worst in people also. When people are desperate\nlike this, it's not,",
    "start": "9265110",
    "end": "9273630"
  },
  {
    "text": "so some people, I've have heard some people say that if that's what's gonna happen,",
    "start": "9273630",
    "end": "9279210"
  },
  {
    "text": "they'd rather be at ground zero and just get vaporized, you know?",
    "start": "9279210",
    "end": "9282330"
  },
  {
    "text": "But I think people\nunderestimate the risk of this because they aren't afraid of Moloch.",
    "start": "9287043",
    "end": "9293399"
  },
  {
    "text": "They think, \"Oh, it's just gonna be, 'cause humans don't want this, so it's not gonna happen.\" That's the whole point of Moloch. That things happen that nobody wanted.",
    "start": "9293400",
    "end": "9300360"
  },
  {
    "text": "- And that applies to nuclear weapons, and that applies to AGI.",
    "start": "9300360",
    "end": "9304383"
  },
  {
    "text": "- Exactly. And it applies\nto some of the things that people have gotten most upset with capitalism for also, right?",
    "start": "9305940",
    "end": "9312480"
  },
  {
    "text": "Where everybody was just\nkind of trapped, you know. It's not that if some\ncompany does something",
    "start": "9312480",
    "end": "9318670"
  },
  {
    "text": "that causes a lot of harm, not that the CEO is a bad person, but she or he knew that, you know,",
    "start": "9321840",
    "end": "9328301"
  },
  {
    "text": "that all the other companies\nwere doing this too. So Moloch is,",
    "start": "9328301",
    "end": "9331683"
  },
  {
    "text": "is a formidable foe, I wish someone would make good movies",
    "start": "9335055",
    "end": "9340380"
  },
  {
    "text": "so we can see who the real enemy is, so we don't, 'cause we're not fighting\nagainst each other,",
    "start": "9340380",
    "end": "9345690"
  },
  {
    "text": "Moloch makes us fight against each other. That's what Moloch's superpower is.",
    "start": "9345690",
    "end": "9351720"
  },
  {
    "text": "The hope here is any kind of technology or the mechanism that\nlets us instead realize",
    "start": "9351720",
    "end": "9358420"
  },
  {
    "text": "that we're fighting\nthe wrong enemy, right? - It's such a fascinating battle. - It's not us versus them,",
    "start": "9359550",
    "end": "9365412"
  },
  {
    "text": "it's us versus it, yeah. - Yeah, we are fighting\nMoloch for human survival.",
    "start": "9365412",
    "end": "9371850"
  },
  {
    "text": "We as a civilization. - Have you seen the\nmovie \"Needful Things\"? It's a Stephen King novel.",
    "start": "9371850",
    "end": "9377970"
  },
  {
    "text": "I love Stephen King, and Max von Sydow, a Swedish actor, is playing the guy.",
    "start": "9377970",
    "end": "9383850"
  },
  {
    "text": "It's brilliant, I just thought, I hadn't\nthought about that until now, but that's the closest I've\nseen to a movie about Moloch.",
    "start": "9383850",
    "end": "9391830"
  },
  {
    "text": "I don't wanna spoil the film for anyone who wants to watch it. But basically, it's about\nthis guy who turns out to,",
    "start": "9391830",
    "end": "9399540"
  },
  {
    "text": "you can interpret him as\nthe devil or whatever, but he doesn't actually ever\ngo around and kill people or torture people, or go\nburning coal or anything.",
    "start": "9399540",
    "end": "9407130"
  },
  {
    "text": "He makes everybody fight each other, makes everybody fear each other, hate each other, and then kill each other.",
    "start": "9407130",
    "end": "9413100"
  },
  {
    "text": "So that's the movie\nabout Moloch, you know. - Love is the answer, that seems to be,",
    "start": "9413100",
    "end": "9418533"
  },
  {
    "text": "one of the ways to fight\nMoloch is by compassion,",
    "start": "9420300",
    "end": "9425300"
  },
  {
    "text": "by seeing the common humanity. - Yes, yes. And to not sound, so we don't sound like",
    "start": "9426450",
    "end": "9432850"
  },
  {
    "text": "a bunch of Kumbaya tree\nhuggers here, right? (Lex laughing) We're not just saying\n\"Love and peace, man.\"",
    "start": "9433692",
    "end": "9439590"
  },
  {
    "text": "We're trying to actually help people understand the true facts\nabout the other side,",
    "start": "9439590",
    "end": "9445354"
  },
  {
    "text": "and feel the compassion because,",
    "start": "9446850",
    "end": "9451850"
  },
  {
    "text": "it's that truth makes you\nmore compassionate, right?",
    "start": "9453180",
    "end": "9455793"
  },
  {
    "text": "So that's why I really like using AI for truth and for\ntruth-seeking technologies.",
    "start": "9458559",
    "end": "9465753"
  },
  {
    "text": "that can as a result, you know, will get us more love than hate.",
    "start": "9468901",
    "end": "9473522"
  },
  {
    "text": "And even if you can't get love, you know, let's settle for some understanding",
    "start": "9474640",
    "end": "9479820"
  },
  {
    "text": "which already gives compassion. If someone is like, you know, \"I really disagree with you Lex,",
    "start": "9479820",
    "end": "9486180"
  },
  {
    "text": "but I can see where you're coming from. You're not a bad person\nwho needs to be destroyed,",
    "start": "9486180",
    "end": "9492780"
  },
  {
    "text": "but I disagree with you and I'm happy to have an\nargument about it,\" you know? That's a lot of progress compared to where we are at\n2023 in the public space,",
    "start": "9492780",
    "end": "9500790"
  },
  {
    "text": "wouldn't you say? - If we solve the AI safety problem, as we've talked about,",
    "start": "9500790",
    "end": "9506460"
  },
  {
    "start": "9501000",
    "end": "10093000"
  },
  {
    "text": "and then you, Max Tegmark, who has been talking\nabout this for many years,",
    "start": "9506460",
    "end": "9513570"
  },
  {
    "text": "get to sit down with the AGI, with the early AGI system\non a beach with a drink, (Max chuckles)",
    "start": "9513570",
    "end": "9520470"
  },
  {
    "text": "What would you ask her? What kind of question would you ask? What would you talk about?",
    "start": "9520470",
    "end": "9524050"
  },
  {
    "text": "Something so much smarter than you, would you be afraid?\n- I knew you were gonna get me",
    "start": "9525510",
    "end": "9530597"
  },
  {
    "text": "with a really zinger of a question. That's a good one. - Would you be afraid\nto ask some questions?",
    "start": "9530597",
    "end": "9538380"
  },
  {
    "text": "- No, I'm not afraid of the truth. (Lex laughing) I'm very humble. I know I'm just a meat bag\nwith all these flaws, you know?",
    "start": "9538380",
    "end": "9545430"
  },
  {
    "text": "But yeah, I mean, we talked a lot\nabout the Homo sentiens, I've really already tried that\nfor a long time with myself.",
    "start": "9545430",
    "end": "9553047"
  },
  {
    "text": "And that is what's really valuable about being alive for me, is that I have these\nmeaningful experiences.",
    "start": "9553047",
    "end": "9559770"
  },
  {
    "text": "It's not that I'm good at this, or\ngood at that or whatever. There's so much I suck at, and...",
    "start": "9559770",
    "end": "9566790"
  },
  {
    "text": "- So you're not afraid for the system to show you just how dumb you are. - No, no. In fact, my son reminds me of that",
    "start": "9566790",
    "end": "9572729"
  },
  {
    "text": "pretty frequently. (laughs) - You could find out how dumb\nyou are in terms of physics, how little we humans understand.",
    "start": "9572730",
    "end": "9578670"
  },
  {
    "text": "- I'm cool with that. I think, so I can't waffle my way\nout of this question,",
    "start": "9578670",
    "end": "9586593"
  },
  {
    "text": "it's a fair one and it's tough. I think, given that I'm a\nreally, really curious person,",
    "start": "9586593",
    "end": "9592710"
  },
  {
    "text": "that's really the\ndefining part of who I am, I'm so curious.",
    "start": "9592710",
    "end": "9598503"
  },
  {
    "text": "I have some physics questions. (Lex laughing) I love to understand.",
    "start": "9603600",
    "end": "9609810"
  },
  {
    "text": "I have some questions about consciousness, about the nature of reality, I would just really, really\nlove to understand also.",
    "start": "9609810",
    "end": "9616023"
  },
  {
    "text": "I can tell you one for example, that I've been obsessing\nabout a lot recently.",
    "start": "9617310",
    "end": "9621080"
  },
  {
    "text": "So I believe that, so suppose Tononi is right. and suppose there are some\ninformation processing systems",
    "start": "9623130",
    "end": "9630423"
  },
  {
    "text": "that are conscious and some that are not. Suppose you can even make\nreasonably smart things like GPT-4 that are not conscious,",
    "start": "9630423",
    "end": "9636450"
  },
  {
    "text": "but you can also make them conscious. Here is the question that\nkeeps me awake at night.",
    "start": "9636450",
    "end": "9641380"
  },
  {
    "text": "Is it the case that the\nunconscious zombie systems that are really intelligent\nare also really efficient?",
    "start": "9644490",
    "end": "9650069"
  },
  {
    "text": "Sorry, really inefficient? So that when you try to\nmake things more efficient, we will naturally be a pressure to do,",
    "start": "9650070",
    "end": "9657239"
  },
  {
    "text": "they become conscious. I'm kind of hoping that\nthat's correct, and I,",
    "start": "9657240",
    "end": "9663270"
  },
  {
    "text": "do you want me to give you, you can hand-wave the argument for it?\n- Yes, please. - You know like,",
    "start": "9663270",
    "end": "9666627"
  },
  {
    "text": "In my lab again, every time we look at how these large language\nmodels do something, we see that they do them\nin really dumb ways,",
    "start": "9669630",
    "end": "9675270"
  },
  {
    "text": "and you could make it make it better. If you, we have loops in our computer\nlanguage for a reason,",
    "start": "9675270",
    "end": "9683939"
  },
  {
    "text": "the code would get way, way longer if you weren't allowed to use them, right? It's more efficient to have the loops",
    "start": "9683940",
    "end": "9689880"
  },
  {
    "text": "and in order to have self-reflection whether it's conscious or not, right?",
    "start": "9689880",
    "end": "9697020"
  },
  {
    "text": "Even an operating system knows\nthings about itself, right? You need to have loops already, right?",
    "start": "9697020",
    "end": "9703181"
  },
  {
    "text": "So I think this is, I'm waving my hands a lot, but I suspect that,",
    "start": "9704100",
    "end": "9709833"
  },
  {
    "text": "the most efficient way of implementing a given level of intelligence, has loops in it,",
    "start": "9711930",
    "end": "9717960"
  },
  {
    "text": "the self-reflection, and will be conscious.",
    "start": "9717960",
    "end": "9723090"
  },
  {
    "text": "- Isn't that great news? - Yes, if it's true, it's wonderful. 'Cause then we don't have to fear the ultimate zombie apocalypse.",
    "start": "9723090",
    "end": "9729748"
  },
  {
    "text": "And I think if you look\nat our brains, actually. Our brains are part\nzombie and part conscious.",
    "start": "9729748",
    "end": "9737013"
  },
  {
    "text": "When I open my eyes, I immediately take all these pixels",
    "start": "9740010",
    "end": "9745800"
  },
  {
    "text": "that hit on my retina, right? And I'm like, \"Oh, that's Lex.\" But I have no freaking clue\nof how I did that computation.",
    "start": "9745800",
    "end": "9752820"
  },
  {
    "text": "It's actually quite complicated, right? It was only relatively recently, we could even do it well\nwith machines, right?",
    "start": "9752820",
    "end": "9759750"
  },
  {
    "text": "You get a bunch of information processing happening in my retina and then it goes to the\nlateral geniculate nucleus",
    "start": "9759750",
    "end": "9765000"
  },
  {
    "text": "in my thalamus, and the area V1, V2, V4, and the fusiform face area here,",
    "start": "9765000",
    "end": "9770220"
  },
  {
    "text": "that Nancy Kanwisher at MIT invented, and blah, blah, blah, blah, blah. And I have no frigging clue\nhow that worked, right?",
    "start": "9770220",
    "end": "9776370"
  },
  {
    "text": "It feels to me subjectively, like my conscious module just\ngot a little email saying,",
    "start": "9776370",
    "end": "9782793"
  },
  {
    "text": "\"Facial processing task\ncomplete, it's Lex.\"",
    "start": "9786517",
    "end": "9791517"
  },
  {
    "text": "- [Lex] Yeah. - And I'm gonna just go with that, right? So this fits perfectly\nwith Tononi's model,",
    "start": "9792300",
    "end": "9798479"
  },
  {
    "text": "because this was all one-way\ninformation processing mainly.",
    "start": "9798480",
    "end": "9803104"
  },
  {
    "text": "And it turned out for\nthat particular task, that's all you needed. And it probably was kind of the\nmost efficient way to do it.",
    "start": "9805200",
    "end": "9812580"
  },
  {
    "text": "But there were a lot of other things that we associated with\nhigher intelligence and planning, and so on, and so forth,",
    "start": "9812580",
    "end": "9818040"
  },
  {
    "text": "where you kind of wanna have loops and be able to ruminate and self-reflect, and introspect, and so on.",
    "start": "9818040",
    "end": "9824160"
  },
  {
    "text": "Where my hunch is that\nif you want to fake that with a zombie system that\njust all goes one way,",
    "start": "9824160",
    "end": "9830979"
  },
  {
    "text": "you have to like unroll those loops, and it gets really, really long, and it's much more inefficient. So I'm actually hopeful that AI,",
    "start": "9830979",
    "end": "9838710"
  },
  {
    "text": "if in the future we have all these various sublime and interesting\nmachines that do cool things, and are aligned with us,",
    "start": "9838710",
    "end": "9844620"
  },
  {
    "text": "that they will be at least, they will also have consciousness for kind of these things that we do.",
    "start": "9844620",
    "end": "9851700"
  },
  {
    "text": "- That great intelligence is also correlated to great consciousness, or a deep kind of consciousness.",
    "start": "9851700",
    "end": "9858510"
  },
  {
    "text": "- Yes, so that's a happy thought for me 'cause the zombie apocalypse really,",
    "start": "9858510",
    "end": "9863730"
  },
  {
    "text": "is my worst nightmare of all. It would be like adding insult to injury, not only did we get replaced,",
    "start": "9863730",
    "end": "9869070"
  },
  {
    "text": "but we frigging replaced\nourselves by zombies, like, how dumb can we be?",
    "start": "9869070",
    "end": "9874170"
  },
  {
    "text": "- That's such a beautiful vision, and that's actually a provable one. That's one that we humans\ncan intuitively prove",
    "start": "9874170",
    "end": "9880260"
  },
  {
    "text": "that those two things are correlated, as we start to understand what\nit means to be intelligent,",
    "start": "9880260",
    "end": "9885270"
  },
  {
    "text": "and what it means to be conscious, which these systems, early AGI-like systems\nwill help us understand.",
    "start": "9885270",
    "end": "9892470"
  },
  {
    "text": "And I just wanna say one more thing, which is super important. Most of my colleagues, when I started going\non about consciousness",
    "start": "9892470",
    "end": "9898199"
  },
  {
    "text": "tell me that it's all bullshit and I should stop talking about it. I hear a little inner voice",
    "start": "9898200",
    "end": "9903510"
  },
  {
    "text": "from my father and from my mom saying, \"Keep talking about it,\"\n'cause I think they're wrong. And the main way to\nconvince people like that,",
    "start": "9903510",
    "end": "9913040"
  },
  {
    "text": "that they're wrong if they\nsay that consciousness is just equal to intelligence, is to ask them what's wrong with torture?",
    "start": "9914850",
    "end": "9921270"
  },
  {
    "text": "Or why are you against torture? if it's just about, you know,",
    "start": "9921270",
    "end": "9925804"
  },
  {
    "text": "these particles moving this\nway rather than that way, and there is no such thing\nas subjective experience,",
    "start": "9927600",
    "end": "9932670"
  },
  {
    "text": "what's wrong with torture? I mean, do you have a\ngood comeback to that? - No, it seems like suffering.",
    "start": "9932670",
    "end": "9938820"
  },
  {
    "text": "Suffering imposed unto\nother humans is somehow deeply wrong in a way",
    "start": "9938820",
    "end": "9944189"
  },
  {
    "text": "that intelligence doesn't quite explain. - And if someone tells me, well, you know, it's just an illusion,",
    "start": "9944190",
    "end": "9950820"
  },
  {
    "text": "consciousness, whatever, you know.",
    "start": "9950820",
    "end": "9954094"
  },
  {
    "text": "I would like to invite them the next time they're having surgery, to do it without anesthesia.",
    "start": "9956070",
    "end": "9960333"
  },
  {
    "text": "Like what is anesthesia really doing? If you have it, you can have a local\nanesthesia when you're awake. I have that when they\nfixed my shoulder, right?",
    "start": "9961650",
    "end": "9967623"
  },
  {
    "text": "It's super entertaining. What was that that it did? it just removed my subjective\nexperience of pain.",
    "start": "9967623",
    "end": "9975540"
  },
  {
    "text": "It didn't change anything about what was actually\nhappening in my shoulder, right? So if someone says, \"That's all bullshit,\"",
    "start": "9975540",
    "end": "9982890"
  },
  {
    "text": "Skip the anesthesia, that's my advice. This is incredibly central. - It could be fundamental to whatever",
    "start": "9982890",
    "end": "9989490"
  },
  {
    "text": "this thing we have going on here. - It is fundamental because we're, what we feel that's so fundamental,",
    "start": "9989490",
    "end": "9996060"
  },
  {
    "text": "is suffering and joy, and\npleasure, and meaning, and,",
    "start": "9996060",
    "end": "10001060"
  },
  {
    "text": "those are all subjective\nexperiences there. And let's not, those are the elephant in the room,",
    "start": "10004340",
    "end": "10010160"
  },
  {
    "text": "that's what makes life worth living. And that's what can make it horrible if it's just a bunch of suffering. So let's not make the mistake",
    "start": "10010160",
    "end": "10016310"
  },
  {
    "text": "of saying that that's all bullshit. - And let's not make the mistake of not instilling the AI systems",
    "start": "10016310",
    "end": "10023690"
  },
  {
    "text": "with that same thing\nthat makes us special. - [Max] Yeah.",
    "start": "10023690",
    "end": "10029600"
  },
  {
    "text": "- Max, it's a huge honor\nthat you would sit down to me the first time on the first\nepisode of this podcast.",
    "start": "10029600",
    "end": "10036260"
  },
  {
    "text": "It's a huge honor you\nsit down with me again and talk about this, what I think is the most important topic,",
    "start": "10036260",
    "end": "10042860"
  },
  {
    "text": "the most important problem that we humans have to\nface and hopefully solve.",
    "start": "10042860",
    "end": "10048770"
  },
  {
    "text": "- Yeah, well, the honor is all mine and I'm so grateful to you for making more people aware of this fact",
    "start": "10048770",
    "end": "10054980"
  },
  {
    "text": "that humanity has reached\nthe most important fork in the road ever in its history. And let's turn in the correct direction.",
    "start": "10054980",
    "end": "10061763"
  },
  {
    "text": "- Thanks for listening\nto this conversation with Max Tegmark. To support this podcast. Please check out our\nsponsors in the description.",
    "start": "10062810",
    "end": "10069500"
  },
  {
    "text": "And now let me leave you with some words from Frank Herbert. \"History is a constant race",
    "start": "10069500",
    "end": "10076490"
  },
  {
    "text": "between invention and catastrophe.\" Thank you for listening, and hope to see you next time.",
    "start": "10076490",
    "end": "10083543"
  }
]
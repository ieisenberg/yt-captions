[
  {
    "start": "0",
    "end": "129000"
  },
  {
    "text": "the following is a conversation with Ayane Howard she's a roboticist professor Georgia Tech and director of",
    "start": "60",
    "end": "7440"
  },
  {
    "text": "the human automation systems lab with research interests in human robot interaction assisted robots in the home",
    "start": "7440",
    "end": "14130"
  },
  {
    "text": "therapy gaming apps and remote robotic exploration of extreme environments like",
    "start": "14130",
    "end": "20490"
  },
  {
    "text": "me in her work she cares a lot about both robots and human beings and so I",
    "start": "20490",
    "end": "26699"
  },
  {
    "text": "really enjoyed this conversation this is the artificial intelligence podcast if",
    "start": "26699",
    "end": "32488"
  },
  {
    "text": "you enjoy it subscribe on YouTube give it five stars an Apple podcast follow on Spotify",
    "start": "32489",
    "end": "37890"
  },
  {
    "text": "supported on patreon or simply connect with me on Twitter Alex Friedman spelled",
    "start": "37890",
    "end": "42989"
  },
  {
    "text": "Fri D ma a.m. I recently started doing ads at the end of the introduction I'll do one or two",
    "start": "42989",
    "end": "49350"
  },
  {
    "text": "minutes after introducing the episode and never any ads in the middle that can break the flow of the conversation I",
    "start": "49350",
    "end": "55199"
  },
  {
    "text": "hope that works for you and doesn't hurt the listening experience this show is",
    "start": "55199",
    "end": "60780"
  },
  {
    "text": "presented by cash app the number one finance app in the App Store I personally use cash app to send money to",
    "start": "60780",
    "end": "66630"
  },
  {
    "text": "friends but you can also use it to buy sell and deposit a Bitcoin in just seconds cash app also has a new",
    "start": "66630",
    "end": "73380"
  },
  {
    "text": "investing feature you can buy fractions of a stock say $1 worth no matter what the stock price is brokers services are",
    "start": "73380",
    "end": "80670"
  },
  {
    "text": "provided by cash up investing a subsidiary of square and member si PC I'm excited to be working with cash app",
    "start": "80670",
    "end": "88049"
  },
  {
    "text": "to support one of my favorite organizations called first best known for their first robotics and Lego",
    "start": "88049",
    "end": "93840"
  },
  {
    "text": "competitions they educate and inspire hundreds of thousands of students in over 110 countries and have a perfect",
    "start": "93840",
    "end": "101009"
  },
  {
    "text": "rating and charity navigator which means that donated money is used to maximum effectiveness when you get cash app from",
    "start": "101009",
    "end": "108060"
  },
  {
    "text": "the App Store Google Play and use code Lex podcast you'll get $10 and cash app",
    "start": "108060",
    "end": "114030"
  },
  {
    "text": "will also donate $10 to the first which again is an organization that I've personally seen inspire girls and boys",
    "start": "114030",
    "end": "120750"
  },
  {
    "text": "the dream of engineering a better world and now here's my conversation with",
    "start": "120750",
    "end": "126329"
  },
  {
    "text": "Ayane Howard what or who is the most amazing robot",
    "start": "126329",
    "end": "132180"
  },
  {
    "start": "129000",
    "end": "305000"
  },
  {
    "text": "you've ever met or perhaps had the biggest impact on your career I haven't met her but I grew up with her",
    "start": "132180",
    "end": "140550"
  },
  {
    "text": "but of course Rosie so and I think it's because also who's Rosie Rosie from the",
    "start": "140550",
    "end": "146670"
  },
  {
    "text": "Jetsons she is all things to all people right think about it like anything you",
    "start": "146670",
    "end": "152430"
  },
  {
    "text": "wanted it was like magic it happened so people not only anthropomorphize but",
    "start": "152430",
    "end": "158040"
  },
  {
    "text": "project whatever they wish for the robot to be onto but also I mean think about",
    "start": "158040",
    "end": "164280"
  },
  {
    "text": "it she was socially engaging she every so often had an attitude right she kept",
    "start": "164280",
    "end": "170430"
  },
  {
    "text": "us honest she would push back sometimes when you know George was doing some weird stuff but she cared about people",
    "start": "170430",
    "end": "178410"
  },
  {
    "text": "especially the kids she was like the the perfect robot and you've said that",
    "start": "178410",
    "end": "184860"
  },
  {
    "text": "people don't want their robots to be perfect can you elaborate that what do",
    "start": "184860",
    "end": "191370"
  },
  {
    "text": "you think that is just like you said Rosie pushed back a little bit every once in a while yeah so I I think it's",
    "start": "191370",
    "end": "197340"
  },
  {
    "text": "that so you think about robotics in general we want them because they enhance our quality of life and usually",
    "start": "197340",
    "end": "204570"
  },
  {
    "text": "that's linked to something that's functional right even if you think of self-driving cars why is there a fascination because people really do",
    "start": "204570",
    "end": "210959"
  },
  {
    "text": "hate to drive like there's the like Saturday driving where I can just be but then there was the I have to go to work",
    "start": "210959",
    "end": "216840"
  },
  {
    "text": "every day and I'm in traffic for an hour I mean people really hate that and so robots are designed to basically enhance",
    "start": "216840",
    "end": "225180"
  },
  {
    "text": "our ability to increase our quality of life and so the perfection comes from",
    "start": "225180",
    "end": "231840"
  },
  {
    "text": "this aspect of interaction if I think about how we drive if we drove perfectly",
    "start": "231840",
    "end": "239700"
  },
  {
    "text": "we would never get anywhere right so think about how many times you had to",
    "start": "239700",
    "end": "245239"
  },
  {
    "text": "run past the light because you see the car behind you is about to crash into you or that little kid kind of runs into",
    "start": "245239",
    "end": "253980"
  },
  {
    "text": "the street and so you have to cross on the other side because there's no cars right like if you think about it we are",
    "start": "253980",
    "end": "259739"
  },
  {
    "text": "not perfect drivers some of it is because it our world and so if you have a robot",
    "start": "259739",
    "end": "265470"
  },
  {
    "text": "that is perfect in that sense of the word they wouldn't really be able to function with us can you linger a little",
    "start": "265470",
    "end": "272010"
  },
  {
    "text": "bit on the word perfection so from the robotics perspective what does that word",
    "start": "272010",
    "end": "278400"
  },
  {
    "text": "mean and how is sort of the optimal behaviors you're describing different",
    "start": "278400",
    "end": "284400"
  },
  {
    "text": "than what we think that's perfection yeah so perfection if you think about it in the more theoretical point of view",
    "start": "284400",
    "end": "291870"
  },
  {
    "text": "it's really tied to accuracy right so if I have a function can I complete it at 100% accuracy with zero errors and so",
    "start": "291870",
    "end": "300900"
  },
  {
    "text": "that's kind of if you think about perfection in the size of the word and in a self-driving car realm do you think",
    "start": "300900",
    "end": "308040"
  },
  {
    "start": "305000",
    "end": "523000"
  },
  {
    "text": "from a robotics perspective we kind of think that perfection means following",
    "start": "308040",
    "end": "314280"
  },
  {
    "text": "the rules perfectly sort of defining staying in the lane changing lanes when",
    "start": "314280",
    "end": "319710"
  },
  {
    "text": "there's a green light you go and there's a red light you stop and that that's the and be able to perfectly see all the",
    "start": "319710",
    "end": "327150"
  },
  {
    "text": "entities in the scene that's the limit of what we think of as perfection and I",
    "start": "327150",
    "end": "332220"
  },
  {
    "text": "think that's where the problem comes is that when people think about perfection for robotics the ones that are the most",
    "start": "332220",
    "end": "339990"
  },
  {
    "text": "successful are the ones that are quote unquote perfect like I said Rosie is perfect but she actually wasn't perfect",
    "start": "339990",
    "end": "346410"
  },
  {
    "text": "in terms of accuracy but she was perfect in terms of how she interacted and how she adapted and I think that's some of",
    "start": "346410",
    "end": "352530"
  },
  {
    "text": "the disconnect is that we really want perfection with respect to its ability",
    "start": "352530",
    "end": "358500"
  },
  {
    "text": "to adapt to us we don't really want perfection with respect to 100% accuracy with respect to the rules that we just",
    "start": "358500",
    "end": "365310"
  },
  {
    "text": "made up anyway right and so I think there's this disconnect sometimes between what we really want and what",
    "start": "365310",
    "end": "372840"
  },
  {
    "text": "happens and we see this all the time like in my research right like the the optimal quote unquote optimal",
    "start": "372840",
    "end": "379350"
  },
  {
    "text": "interactions are when the robot is adapting based on the person not 100%",
    "start": "379350",
    "end": "386100"
  },
  {
    "text": "following what's optimal based on the roles just to linger on autonomous vehicles for a second just your thoughts",
    "start": "386100",
    "end": "393300"
  },
  {
    "text": "maybe off the top of her head is how hard is that problem do you think based on what we just talked about you",
    "start": "393300",
    "end": "399539"
  },
  {
    "text": "know there's a lot of folks in the automotive industry they're very confident from Elon Musk two-way mode",
    "start": "399539",
    "end": "405810"
  },
  {
    "text": "all these companies how hard is it to solve that last piece did the gap",
    "start": "405810",
    "end": "411660"
  },
  {
    "text": "between the perfection and the human definition of how you actually function",
    "start": "411660",
    "end": "418680"
  },
  {
    "text": "in this world so this is a moving target so I remember when all the big companies",
    "start": "418680",
    "end": "424110"
  },
  {
    "text": "started to heavily invest in us and there was a number of even roboticists",
    "start": "424110",
    "end": "429840"
  },
  {
    "text": "as well as you know folks who were putting in the VCS and and corporations Elon Musk being one of them that said",
    "start": "429840",
    "end": "435720"
  },
  {
    "text": "you know self-driving cars on the road with people you know within five years",
    "start": "435720",
    "end": "441289"
  },
  {
    "text": "that was a little while ago and now people are saying five years ten years",
    "start": "441289",
    "end": "448560"
  },
  {
    "text": "twenty years some are saying never right I think if you look at some of the things that are being successful is",
    "start": "448560",
    "end": "455900"
  },
  {
    "text": "these basically fixed environments where",
    "start": "455900",
    "end": "461280"
  },
  {
    "text": "you still have some anomalies wait you still have people walking you still have stores but you don't have other drivers",
    "start": "461280",
    "end": "469500"
  },
  {
    "text": "right like other human drivers are is a dedicated space for the for the cars",
    "start": "469500",
    "end": "474740"
  },
  {
    "text": "because if you think about robotics in general where has always been successful is I mean you can say manufacturing like",
    "start": "474740",
    "end": "480719"
  },
  {
    "text": "way back in the day right it was a fixed environment humans were not part of the equation we're a lot better than that",
    "start": "480719",
    "end": "486409"
  },
  {
    "text": "but like when we can carve out scenarios that are closer to that space then I",
    "start": "486409",
    "end": "494460"
  },
  {
    "text": "think that it's where we are so a closed campus where you don't have self-driving cars and maybe some protection so that",
    "start": "494460",
    "end": "502710"
  },
  {
    "text": "the students don't jet in front just because they want to see what happens like having a little bit I think that's",
    "start": "502710",
    "end": "509460"
  },
  {
    "text": "where we're gonna see the most success in the near future and be slow-moving right not not you know 55 60 70 miles an",
    "start": "509460",
    "end": "517529"
  },
  {
    "text": "hour but the the speed of a golf cart right so that said the most successful",
    "start": "517529",
    "end": "524279"
  },
  {
    "start": "523000",
    "end": "1203000"
  },
  {
    "text": "in the automotive industry robots operating today in the hands of real people are ones that are traveling",
    "start": "524279",
    "end": "531240"
  },
  {
    "text": "over 55 miles an hour and in our constrains environment which is Tesla",
    "start": "531240",
    "end": "536399"
  },
  {
    "text": "vehicles so we'll test the autopilot so I just I would love to hear of your just",
    "start": "536399",
    "end": "541949"
  },
  {
    "text": "thoughts of two things so one I don't know if you've gotten to see you've",
    "start": "541949",
    "end": "547079"
  },
  {
    "text": "heard about something called smart summon wait what Tesla system part",
    "start": "547079",
    "end": "552660"
  },
  {
    "text": "Apollo system where the car drives zero occupancy no driver in the parking lot",
    "start": "552660",
    "end": "557879"
  },
  {
    "text": "slowly sort of tries to navigate the parking lot to find itself to you and there's some incredible amounts of",
    "start": "557879",
    "end": "565050"
  },
  {
    "text": "videos and just hilarity that happens as it awkwardly tries to navigate this environment but it's it's a beautiful",
    "start": "565050",
    "end": "572310"
  },
  {
    "text": "nonverbal communication between machine and human that I think is a from it's",
    "start": "572310",
    "end": "577589"
  },
  {
    "text": "like it's some of the work that you do in this kind of interesting human robot interaction space so what are your thoughts in general water so I I do have",
    "start": "577589",
    "end": "585029"
  },
  {
    "text": "that feature new driver Tesla I do mainly because I'm a gadget freak right",
    "start": "585029",
    "end": "591959"
  },
  {
    "text": "so I it's a gadget that happens to have some wheels and yeah I've seen some of the videos but what's your experience",
    "start": "591959",
    "end": "599160"
  },
  {
    "text": "like I mean your your human robot interaction roboticist you're legit sort of expert in the field so what does it",
    "start": "599160",
    "end": "606089"
  },
  {
    "text": "feel for machine to come to you it's one of these very fascinating things but",
    "start": "606089",
    "end": "612149"
  },
  {
    "text": "also I am hyper hyper alert right like I'm hyper alert like my but my thumb is",
    "start": "612149",
    "end": "619829"
  },
  {
    "text": "like okay I'm ready to take over even when I'm in my car or I'm doing things",
    "start": "619829",
    "end": "626040"
  },
  {
    "text": "like automated backing into so there's like a feature where you can do this automating backing into our parking",
    "start": "626040",
    "end": "632040"
  },
  {
    "text": "space our bring the car out of your garage or even you know pseudo autopilot",
    "start": "632040",
    "end": "638579"
  },
  {
    "text": "on the freeway right I am hyper sensitive I can feel like as",
    "start": "638579",
    "end": "643980"
  },
  {
    "text": "I'm navigating like yeah that's an error right there like I am very aware of it",
    "start": "643980",
    "end": "649290"
  },
  {
    "text": "but I'm also fascinated by it and it does get better like it",
    "start": "649290",
    "end": "654720"
  },
  {
    "text": "I look and see it's learning from all of these people who are cutting it on like",
    "start": "654720",
    "end": "661069"
  },
  {
    "text": "every come on it's getting better right and so I think that's what's amazing about it",
    "start": "661069",
    "end": "666100"
  },
  {
    "text": "is that this nice dance of you're still hyper-vigilant so you're still not trusting it at all yeah yeah you're",
    "start": "666100",
    "end": "673570"
  },
  {
    "text": "using it what on the highway if I were to like what as a roboticist we'll talk",
    "start": "673570",
    "end": "678970"
  },
  {
    "text": "about trust a little bit what how do you explain that you still use it is it the",
    "start": "678970",
    "end": "685389"
  },
  {
    "text": "gadget freak part like where you just enjoy exploring technology or is that",
    "start": "685389",
    "end": "692019"
  },
  {
    "text": "the right actually balance between robotics and humans is where you use it but don't trust it and somehow there's",
    "start": "692019",
    "end": "699220"
  },
  {
    "text": "this dance that ultimately is a positive yes so I think I'm I just don't",
    "start": "699220",
    "end": "705639"
  },
  {
    "text": "necessarily trust technology but I'm an early adopter right so when it first",
    "start": "705639",
    "end": "711310"
  },
  {
    "text": "comes out I will use everything but I will be very very cautious of how I use",
    "start": "711310",
    "end": "716769"
  },
  {
    "text": "it do you read about or do you explore but just try it they do like it's crudely to",
    "start": "716769",
    "end": "724240"
  },
  {
    "text": "put a crew they do you read the manual or do you learn through exploration I'm an explorer if I have to read the manual",
    "start": "724240",
    "end": "729579"
  },
  {
    "text": "then you know I do design then it's a bad user interface it's a failure Elon",
    "start": "729579",
    "end": "736810"
  },
  {
    "text": "Musk is very confident that you kind of take it from where it is now to full autonomy so from this human robot",
    "start": "736810",
    "end": "743709"
  },
  {
    "text": "interaction you don't really trust and then you try and then you catch it when it fails to it's going to incrementally",
    "start": "743709",
    "end": "750459"
  },
  {
    "text": "improve itself into full full way you don't need to participate what's your",
    "start": "750459",
    "end": "757199"
  },
  {
    "text": "sense of that trajectory is it feasible so the promise there is by the end of",
    "start": "757199",
    "end": "763540"
  },
  {
    "text": "next year by the end of 2020 it's the current promise what's your sense about",
    "start": "763540",
    "end": "770290"
  },
  {
    "text": "that journey that test is on so there's kind of three three things going on now",
    "start": "770290",
    "end": "776350"
  },
  {
    "text": "I think in terms of will people go like",
    "start": "776350",
    "end": "782079"
  },
  {
    "text": "as a user as a adopter will you trust going to that point I think so right",
    "start": "782079",
    "end": "789790"
  },
  {
    "text": "like there are some users and it's because what happens is when technology",
    "start": "789790",
    "end": "795790"
  },
  {
    "text": "at the beginning and then the technology tends to work your apprehension slow",
    "start": "795790",
    "end": "801790"
  },
  {
    "text": "slowly goes away and as people we tend to swing to the other extreme right",
    "start": "801790",
    "end": "807970"
  },
  {
    "text": "because like oh I was like hyper hyper fearful or hypersensitive and was awesome and we just tend to swing that's",
    "start": "807970",
    "end": "815740"
  },
  {
    "text": "just human nature and so you will have I mean it is a scary notion because most",
    "start": "815740",
    "end": "820870"
  },
  {
    "text": "people are now extremely untrusting of autobot they use it but they don't trust",
    "start": "820870",
    "end": "826030"
  },
  {
    "text": "it and it's a scary notion that there's a certain point where you allow yourself to look at the smartphone for like 20",
    "start": "826030",
    "end": "832300"
  },
  {
    "text": "seconds and then there'll be this phase shift will be like 20 seconds 30 seconds",
    "start": "832300",
    "end": "837490"
  },
  {
    "text": "1 minute 2 minutes this is scary it's opposition but that's people right",
    "start": "837490",
    "end": "843250"
  },
  {
    "text": "that's human that's humans I mean I think of even our use of I mean just",
    "start": "843250",
    "end": "850900"
  },
  {
    "text": "everything on the internet right like think about how relying we are on certain apps and certain engines right",
    "start": "850900",
    "end": "859500"
  },
  {
    "text": "20 years ago people have been like oh yeah that's stupid like that makes no sense like of course that's false",
    "start": "859500",
    "end": "865750"
  },
  {
    "text": "like now it's just like oh of course I've been using it it's been correct all this time of course aliens I didn't",
    "start": "865750",
    "end": "873310"
  },
  {
    "text": "think they existed but now it says they do obvious nth earth is flat so okay but",
    "start": "873310",
    "end": "882250"
  },
  {
    "text": "you said three things so one is okay so one is the human and I think there would be a group of individuals that will",
    "start": "882250",
    "end": "888070"
  },
  {
    "text": "swing right I just teenagers gene it I mean it'll be clean it'll be adults",
    "start": "888070",
    "end": "893550"
  },
  {
    "text": "there's actually an age demographic that's optimal for a technology adoption",
    "start": "893550",
    "end": "899820"
  },
  {
    "text": "and you can actually find them and they're actually pretty easy to find just the based on their habits based on",
    "start": "899820",
    "end": "906150"
  },
  {
    "text": "so someone like me who wouldn't wasn't no robot Isis or probably be the optimal",
    "start": "906150",
    "end": "912040"
  },
  {
    "text": "kind of person right early adopter okay with technology very comfortable and not",
    "start": "912040",
    "end": "918010"
  },
  {
    "text": "hyper sensitive right I'm just the hyper sensitive because I designed this stuff yeah so there is a target demographic",
    "start": "918010",
    "end": "925060"
  },
  {
    "text": "that will swing the other one though is you still have these hue that are on the road that one is a",
    "start": "925060",
    "end": "932170"
  },
  {
    "text": "harder harder thing to do and as long as we have people that are on the same",
    "start": "932170",
    "end": "939160"
  },
  {
    "text": "streets that's going to be the big issue and it's just because you can't possibly",
    "start": "939160",
    "end": "944350"
  },
  {
    "text": "know well so you can't possibly map the some of the silliness of human drivers",
    "start": "944350",
    "end": "950710"
  },
  {
    "text": "right like as an example when you're next to that car that has that big",
    "start": "950710",
    "end": "957100"
  },
  {
    "text": "sticker called student driver right like you are like oh either I am going to",
    "start": "957100",
    "end": "963279"
  },
  {
    "text": "like go around like we are we know that that person is just gonna make mistakes that make no sense right how do you map",
    "start": "963279",
    "end": "969820"
  },
  {
    "text": "that information or if I'm in a car and I look over and I see you know two",
    "start": "969820",
    "end": "976110"
  },
  {
    "text": "fairly young looking individuals and there's no student driver bumper and I",
    "start": "976110",
    "end": "981370"
  },
  {
    "text": "see them chit-chatting to each other I'm like oh yeah that's an issue right so how do you get that kind of information",
    "start": "981370",
    "end": "987700"
  },
  {
    "text": "and that experience into basically an",
    "start": "987700",
    "end": "994060"
  },
  {
    "text": "autopilot yeah and there's millions of cases like that where we take little hints to establish context I mean you",
    "start": "994060",
    "end": "1001500"
  },
  {
    "text": "said kind of beautifully poetic human things but there's probably subtle things about the environment about is",
    "start": "1001500",
    "end": "1007680"
  },
  {
    "text": "about it being maybe time for commuters",
    "start": "1007680",
    "end": "1012780"
  },
  {
    "text": "start going home from work and therefore you can make some kind of judgment about the group behavior of pedestrians or",
    "start": "1012780",
    "end": "1021180"
  },
  {
    "text": "even cities right like if you're in Boston how people cross the street like",
    "start": "1021180",
    "end": "1027300"
  },
  {
    "text": "lights are not an issue versus other places where people will will actually",
    "start": "1027300",
    "end": "1032880"
  },
  {
    "text": "wait for the crosswalk or somewhere peaceful and but what I've also seen so",
    "start": "1032880",
    "end": "1041339"
  },
  {
    "text": "just even in Boston that intersection the intersection is different so every",
    "start": "1041339",
    "end": "1046500"
  },
  {
    "text": "intersection has a personality of its own so that certain neighborhoods of Boston are different so we kind of end",
    "start": "1046500",
    "end": "1052800"
  },
  {
    "text": "the based on different timing of day at night it's all it's all there's a there's a dynamic to human behavior that",
    "start": "1052800",
    "end": "1060420"
  },
  {
    "text": "would kind of figure out ourselves we're not be able to we're not able to introspect and figure it out but somehow we our",
    "start": "1060420",
    "end": "1067679"
  },
  {
    "text": "brain learns it we do and so you're you're saying is there so that's the",
    "start": "1067679",
    "end": "1073920"
  },
  {
    "text": "shortcut that's their shortcut though for everybody is there something that could be done you think that you know",
    "start": "1073920",
    "end": "1080490"
  },
  {
    "text": "that's what we humans do it's just like bird flight right this example they give",
    "start": "1080490",
    "end": "1085559"
  },
  {
    "text": "for flight do you necessarily need to build the bird that flies or can you do an airplane is there shortcut so I think",
    "start": "1085559",
    "end": "1093390"
  },
  {
    "text": "the the shortcut is and I kind of I talk about it as a fixed space where so",
    "start": "1093390",
    "end": "1101040"
  },
  {
    "text": "imagine that there is a neighborhood that's a new smart city or a new neighborhood that says you know what we",
    "start": "1101040",
    "end": "1107730"
  },
  {
    "text": "are going to design this new city based on supporting self-driving cars and then",
    "start": "1107730",
    "end": "1114120"
  },
  {
    "text": "doing things knowing that there's anomalies knowing that people are like this right and designing it based on",
    "start": "1114120",
    "end": "1120870"
  },
  {
    "text": "that assumption that like we're gonna have this that would be an example of a shortcut so you still have people but",
    "start": "1120870",
    "end": "1127290"
  },
  {
    "text": "you do very specific things to try to minimize the noise a little bit as an",
    "start": "1127290",
    "end": "1133260"
  },
  {
    "text": "example and the people themselves become accepting of the notion that there's autonomous cars right right like they",
    "start": "1133260",
    "end": "1138330"
  },
  {
    "text": "move into so right now you have like a you will have a self-selection bias right like individuals will move into",
    "start": "1138330",
    "end": "1145350"
  },
  {
    "text": "this neighborhood knowing like this is part of like the real estate pitch right and so I think that's a way to do a",
    "start": "1145350",
    "end": "1153240"
  },
  {
    "text": "shortcut when it allows you to deploy it allows you to collect then data with",
    "start": "1153240",
    "end": "1159780"
  },
  {
    "text": "these variances and anomalies because people are still people but it's it's a",
    "start": "1159780",
    "end": "1165450"
  },
  {
    "text": "safer space and it's more of an accepting space ie when something in that space might happen because things",
    "start": "1165450",
    "end": "1172830"
  },
  {
    "text": "do because you already have the self selection like people would be I think a little more forgiving than other places",
    "start": "1172830",
    "end": "1180150"
  },
  {
    "text": "and you said three things that would cover all of them the third is legal liability which I don't really want to",
    "start": "1180150",
    "end": "1187500"
  },
  {
    "text": "touch but it's still it's it's still of concern in the mishmash with like with policy as well sort of government all",
    "start": "1187500",
    "end": "1194429"
  },
  {
    "text": "that that whole that big ball of mess yeah gotcha so that's",
    "start": "1194429",
    "end": "1199869"
  },
  {
    "text": "so we're out of time what do you think from robotics perspective you know if",
    "start": "1199869",
    "end": "1207440"
  },
  {
    "start": "1203000",
    "end": "1691000"
  },
  {
    "text": "you if you're kind of honest of what cars do they they kind of kind of threaten each other's life all the time",
    "start": "1207440",
    "end": "1214059"
  },
  {
    "text": "so cars are very us I mean in order to navigate intersections there's an",
    "start": "1214059",
    "end": "1219619"
  },
  {
    "text": "assertiveness there's a risk-taking and if you were to reduce it to an objective function there's a probability of murder",
    "start": "1219619",
    "end": "1227570"
  },
  {
    "text": "in that function meaning you killing another human being and you're using",
    "start": "1227570",
    "end": "1232669"
  },
  {
    "text": "that first of all yeah it has to be low enough to be acceptable to you on an",
    "start": "1232669",
    "end": "1238700"
  },
  {
    "text": "ethical level as a individual human being but it has to be high enough for people to respect you to not sort of",
    "start": "1238700",
    "end": "1246049"
  },
  {
    "text": "take advantage of you completely and jaywalking front knee and so on so I mean I don't think there's a right",
    "start": "1246049",
    "end": "1252139"
  },
  {
    "text": "answer here but what's how do we solve that how how do we solve that from a robotics perspective one danger and",
    "start": "1252139",
    "end": "1258919"
  },
  {
    "text": "human life is at stake yeah as they say cars don't kill people people kill people people right",
    "start": "1258919",
    "end": "1266470"
  },
  {
    "text": "so I think now robotic algorithms would be killing right so it will be robotics",
    "start": "1266470",
    "end": "1272899"
  },
  {
    "text": "algorithms that are prone oh it will be robotic algorithms don't kill people developers of the right account or there",
    "start": "1272899",
    "end": "1278720"
  },
  {
    "text": "was kill people right I mean one of the things as people are still in the loop and at least in the near and midterm I",
    "start": "1278720",
    "end": "1286609"
  },
  {
    "text": "think people will still be in the loop at some point even if it's a developer like we're not necessarily at the stage",
    "start": "1286609",
    "end": "1291769"
  },
  {
    "text": "where you know robots are programming autonomous robots with different",
    "start": "1291769",
    "end": "1297409"
  },
  {
    "text": "behaviors quite yet not so scary notion sorry to interrupt that a developer is",
    "start": "1297409",
    "end": "1304929"
  },
  {
    "text": "has some responsibility in in it in the death of a human being this uh I mean I",
    "start": "1304929",
    "end": "1310940"
  },
  {
    "text": "think that's why the whole aspect of ethics in our community is so so",
    "start": "1310940",
    "end": "1317210"
  },
  {
    "text": "important right like because it's true if if you think about it you can",
    "start": "1317210",
    "end": "1323479"
  },
  {
    "text": "basically say I'm not going to work on weaponized AI right like people can say that's not what I'm",
    "start": "1323479",
    "end": "1329660"
  },
  {
    "text": "but yet you are programming algorithms that might be used in healthcare algorithms that might decide whether",
    "start": "1329660",
    "end": "1336650"
  },
  {
    "text": "this person should get this medication or not and they don't and they die you okay so that is your responsibility",
    "start": "1336650",
    "end": "1343990"
  },
  {
    "text": "right and if you're not conscious and aware that you do have that power when",
    "start": "1343990",
    "end": "1349280"
  },
  {
    "text": "you're coding and things like that I think that's that's that's just not a",
    "start": "1349280",
    "end": "1354560"
  },
  {
    "text": "good thing like we need to think about this responsibility as we program robots and and computing devices much more than",
    "start": "1354560",
    "end": "1362750"
  },
  {
    "text": "we are yes so it's not an option to not think about ethics I think it's a majority I would say of computer science",
    "start": "1362750",
    "end": "1370540"
  },
  {
    "text": "sort of there it's kind of a hot topic now I think about bias and so on but",
    "start": "1370540",
    "end": "1375800"
  },
  {
    "text": "it's and we'll talk about it but usually it's kind of you it's like a very",
    "start": "1375800",
    "end": "1381350"
  },
  {
    "text": "particular group of people that work on that and then people who do like robotics or like well I don't have to",
    "start": "1381350",
    "end": "1387680"
  },
  {
    "text": "think about that you know there's other smart people thinking about it it seems that everybody has to think about it",
    "start": "1387680",
    "end": "1394160"
  },
  {
    "text": "it's not you can't escape the ethics well there is bias or just every aspect",
    "start": "1394160",
    "end": "1400370"
  },
  {
    "text": "of ethics that has to do with human beings everyone so think about I'm gonna age myself but I remember when we didn't",
    "start": "1400370",
    "end": "1408110"
  },
  {
    "text": "have like testers right and so what did you do as a developer you had to test your own code right like you had to go",
    "start": "1408110",
    "end": "1414140"
  },
  {
    "text": "through all the cases and figure it out and you know and then they realize that you know like we probably need to have",
    "start": "1414140",
    "end": "1419990"
  },
  {
    "text": "testing because we're not getting all the things and so from there what happens is like most developers they do",
    "start": "1419990",
    "end": "1425690"
  },
  {
    "text": "you know a little bit of testing but is usually like okay - my compiler bug out and you look at the warnings okay is",
    "start": "1425690",
    "end": "1431480"
  },
  {
    "text": "that acceptable or not right like that's how you typically think about as a developer and you'll just assume that is",
    "start": "1431480",
    "end": "1437330"
  },
  {
    "text": "going to go to another process and they're gonna test it out but I think we need to go back to those early days when",
    "start": "1437330",
    "end": "1444500"
  },
  {
    "text": "you know you're a developer you're developing there should be like they say you know okay let me look at the ethical",
    "start": "1444500",
    "end": "1451070"
  },
  {
    "text": "outcomes of this because there isn't a second like testing ethical testers right it's you we did it back in the",
    "start": "1451070",
    "end": "1459470"
  },
  {
    "text": "early coding days I think that's where we are with respect to ethics like this go back to what was",
    "start": "1459470",
    "end": "1465320"
  },
  {
    "text": "good practice isn't only because we were just developing the field yeah and it's uh it's a really heavy",
    "start": "1465320",
    "end": "1473600"
  },
  {
    "text": "burden I've had to feel it recently in the last few months but I think it's a good one to feel like I've gotten a",
    "start": "1473600",
    "end": "1479960"
  },
  {
    "text": "message more than one from people you know I've unfortunately gotten some",
    "start": "1479960",
    "end": "1485990"
  },
  {
    "text": "attention recently and I've got messages that say that I have blood on my hands",
    "start": "1485990",
    "end": "1491590"
  },
  {
    "text": "because of working on semi autonomous vehicles so the idea that you have semi",
    "start": "1491590",
    "end": "1498409"
  },
  {
    "text": "autonomy means people will become would lose vigilance and so on as actually be humans as we described and because of",
    "start": "1498409",
    "end": "1505820"
  },
  {
    "text": "that because of this idea that we're creating automation there will be people be hurt because of it and I think that's",
    "start": "1505820",
    "end": "1513679"
  },
  {
    "text": "a beautiful thing I mean it's you know it's many nights where I wasn't able to sleep because of this notion you know",
    "start": "1513679",
    "end": "1519020"
  },
  {
    "text": "you really do think about people that might die because it's technology of course you can then start rationalizing",
    "start": "1519020",
    "end": "1525500"
  },
  {
    "text": "saying well you know what 40,000 people die in the United States every year and we're trying to ultimately try to save",
    "start": "1525500",
    "end": "1531740"
  },
  {
    "text": "us but the reality is your code you've written might kill somebody and that's",
    "start": "1531740",
    "end": "1536929"
  },
  {
    "text": "an important burden to carry with you as you design the code I don't even think",
    "start": "1536929",
    "end": "1542090"
  },
  {
    "text": "of it as a burden if we train this concept correctly from the beginning and",
    "start": "1542090",
    "end": "1547640"
  },
  {
    "text": "I use and not to say that coding is like being a medical doctor the thing about it medical doctors if they've been in",
    "start": "1547640",
    "end": "1555380"
  },
  {
    "text": "situations where their patient didn't survive right do they give up and go away no every time they come in they",
    "start": "1555380",
    "end": "1562700"
  },
  {
    "text": "know that there might be a possibility that this patient might not survive and so when they approach every decision",
    "start": "1562700",
    "end": "1569419"
  },
  {
    "text": "like that's in their back of their head and so why isn't that we aren't teaching",
    "start": "1569419",
    "end": "1575330"
  },
  {
    "text": "and those are tools though right they're given some of the tools to address that so that they don't go crazy but we don't",
    "start": "1575330",
    "end": "1582169"
  },
  {
    "text": "give those tools so that it does feel like a burden versus something of I have",
    "start": "1582169",
    "end": "1587870"
  },
  {
    "text": "a great gift and I can do great awesome good but with it comes great responsibility I mean that's what we",
    "start": "1587870",
    "end": "1594740"
  },
  {
    "text": "teach in terms of you think about medical schools right great gift great responsibility I think if we just",
    "start": "1594740",
    "end": "1600260"
  },
  {
    "text": "changed the messaging a little great gift being a developer great responsibility and this is how you",
    "start": "1600260",
    "end": "1606730"
  },
  {
    "text": "combine those but do you think and this is really interesting it's it's outside I actually have no",
    "start": "1606730",
    "end": "1613940"
  },
  {
    "text": "friends or sort of surgeons or doctors I mean what does it feel like to make a",
    "start": "1613940",
    "end": "1620720"
  },
  {
    "text": "mistake in a surgery and somebody to die because of that like is that something you could be",
    "start": "1620720",
    "end": "1626150"
  },
  {
    "text": "taught in medical school sort of how to be accepting of that risk so because I",
    "start": "1626150",
    "end": "1631370"
  },
  {
    "text": "do a lot of work with health care robotics I I have not lost a patient for",
    "start": "1631370",
    "end": "1637010"
  },
  {
    "text": "example the first one's always the hardest right but they really teach the",
    "start": "1637010",
    "end": "1645340"
  },
  {
    "text": "value right so they teach responsibility but they also teach the value like",
    "start": "1645340",
    "end": "1651280"
  },
  {
    "text": "you're saving 40,000 mm but in order to really feel good about that when you",
    "start": "1651280",
    "end": "1658580"
  },
  {
    "text": "come to a decision you have to be able to say at the end I did all that I could possibly do right versus a well I just",
    "start": "1658580",
    "end": "1666650"
  },
  {
    "text": "picked the first widget and right like so every decision is actually thought through it's not a habit is not a let me",
    "start": "1666650",
    "end": "1673940"
  },
  {
    "text": "just take the best algorithm that my friend gave me right it's a is this it this this the best have I done my best",
    "start": "1673940",
    "end": "1680720"
  },
  {
    "text": "to do good right and so you're right and I think burden is the wrong word if it's",
    "start": "1680720",
    "end": "1686660"
  },
  {
    "text": "a gift but you have to treat it extremely seriously correct so on a slightly related note",
    "start": "1686660",
    "end": "1694549"
  },
  {
    "start": "1691000",
    "end": "2300000"
  },
  {
    "text": "yeah in a recent paper the ugly truth about ourselves and our robot creations you you discuss you highlight some",
    "start": "1694549",
    "end": "1703190"
  },
  {
    "text": "biases that may affect the function in various robotics systems can you talk through if you remember examples or some",
    "start": "1703190",
    "end": "1709669"
  },
  {
    "text": "there's a lot of examples I use what is bias first of all yes so bias is this",
    "start": "1709669",
    "end": "1716380"
  },
  {
    "text": "and so bias which is different than prejudice so bias is that we all have these preconceived notions about",
    "start": "1716380",
    "end": "1721870"
  },
  {
    "text": "particular everything from particular groups for to habits to identity right",
    "start": "1721870",
    "end": "1729530"
  },
  {
    "text": "so we have these predispositions and so when we address a problem we look at a problem make a",
    "start": "1729530",
    "end": "1735019"
  },
  {
    "text": "decision those preconceived notions might affect our our outputs or outcomes",
    "start": "1735019",
    "end": "1741440"
  },
  {
    "text": "so they're the bias could be positive or negative and then it's prejudice the",
    "start": "1741440",
    "end": "1746809"
  },
  {
    "text": "negative courage is the negative right so prejudice is that not only are you aware of your bias but you are then take",
    "start": "1746809",
    "end": "1755299"
  },
  {
    "text": "it and have a negative outcome even though you are aware wait and there",
    "start": "1755299",
    "end": "1760849"
  },
  {
    "text": "could be gray areas too that's the challenging aspect of all questions",
    "start": "1760849",
    "end": "1767089"
  },
  {
    "text": "actually so I always like so there's there's a funny one and in fact I think it might be in the paper because I think I talked about self-driving cars but",
    "start": "1767089",
    "end": "1774259"
  },
  {
    "text": "think about this we for teenagers right typically we insurance companies charge",
    "start": "1774259",
    "end": "1782899"
  },
  {
    "text": "quite a bit of money if you have a teenage driver so you could say that's",
    "start": "1782899",
    "end": "1787969"
  },
  {
    "text": "an age bias right but no one will click I mean parents will be grumpy but no one",
    "start": "1787969",
    "end": "1794509"
  },
  {
    "text": "really says that that's not fair that's interesting we don't that's right",
    "start": "1794509",
    "end": "1800749"
  },
  {
    "text": "that's right it's a everybody in human factors and safety research almost I mean it's quite",
    "start": "1800749",
    "end": "1809299"
  },
  {
    "text": "ruthlessly critical of teenagers and we don't question is that okay is that okay",
    "start": "1809299",
    "end": "1815299"
  },
  {
    "text": "to be ageist in this kind of way it is and it is agent right is that really there's no question about it and so so",
    "start": "1815299",
    "end": "1822379"
  },
  {
    "text": "these are these this is the gray area right cuz you you know that you know",
    "start": "1822379",
    "end": "1828289"
  },
  {
    "text": "teenagers are more likely to be an accident and so there's actually some data to it but then if you take that",
    "start": "1828289",
    "end": "1833779"
  },
  {
    "text": "same example and you say well I'm going to make the insurance hire for an area",
    "start": "1833779",
    "end": "1841940"
  },
  {
    "text": "of Boston because there's a lot of accidents and then they find out that that's correlated with socio economics",
    "start": "1841940",
    "end": "1849559"
  },
  {
    "text": "well then it becomes a problem right like that is not acceptable but yet the teenager which is age it's",
    "start": "1849559",
    "end": "1858979"
  },
  {
    "text": "against age is right so we figure that I was I by having conversations by the discourse",
    "start": "1858979",
    "end": "1865950"
  },
  {
    "text": "let me throw out history the definition of what is ethical or not has changed",
    "start": "1865950",
    "end": "1871200"
  },
  {
    "text": "and hopefully always for the better correct correct so in terms of bias or prejudice in",
    "start": "1871200",
    "end": "1879780"
  },
  {
    "text": "robotic in algorithms what what examples do sometimes think about so I think",
    "start": "1879780",
    "end": "1885840"
  },
  {
    "text": "about quite a bit the medical domain just because historically right the",
    "start": "1885840",
    "end": "1891450"
  },
  {
    "text": "healthcare domain has had these biases typically based on gender and ethnicity",
    "start": "1891450",
    "end": "1898140"
  },
  {
    "text": "primarily a little an age but not so much you know historically if you think",
    "start": "1898140",
    "end": "1905280"
  },
  {
    "text": "about FDA and drug trials it's you know harder to find a woman that you know",
    "start": "1905280",
    "end": "1913140"
  },
  {
    "text": "aren't childbearing and so you may not test on drugs at the same level right so there there's these things and so if you",
    "start": "1913140",
    "end": "1919740"
  },
  {
    "text": "think about robotics right something as simple as I'd like to design an",
    "start": "1919740",
    "end": "1925980"
  },
  {
    "text": "exoskeleton right what should the material be what should the way P which should the form factor be are you who",
    "start": "1925980",
    "end": "1934440"
  },
  {
    "text": "are you going to design it around I will say that in the US you know women",
    "start": "1934440",
    "end": "1939960"
  },
  {
    "text": "average height and weight is slightly different than guys so who are you gonna choose like if you're not thinking about",
    "start": "1939960",
    "end": "1947580"
  },
  {
    "text": "it from the beginning as you know okay I when I design this and I look at the",
    "start": "1947580",
    "end": "1952800"
  },
  {
    "text": "algorithms and I design the control system and the forces and the torques if you're not thinking about well you have",
    "start": "1952800",
    "end": "1959100"
  },
  {
    "text": "different types of body structure you're gonna design to you know what you're used to oh this fits my all the folks in",
    "start": "1959100",
    "end": "1966660"
  },
  {
    "text": "my lab right so think about it from the very beginning it's important what about",
    "start": "1966660",
    "end": "1971790"
  },
  {
    "text": "sort of algorithms that train on data kind of thing the sadly our society",
    "start": "1971790",
    "end": "1977610"
  },
  {
    "text": "already has a lot of negative bias and so if we collect a lot of data even if",
    "start": "1977610",
    "end": "1985110"
  },
  {
    "text": "it's a balanced weight that's going to contain the same bias that a society contains and so yeah was is there is",
    "start": "1985110",
    "end": "1991980"
  },
  {
    "text": "there things there that bother you yeah so you actually said something you ain't said how",
    "start": "1991980",
    "end": "1998070"
  },
  {
    "text": "we have biases but hopefully we learn from them and we become better right and",
    "start": "1998070",
    "end": "2003110"
  },
  {
    "text": "so that's where we are now right so the data that we're collecting is historic",
    "start": "2003110",
    "end": "2008120"
  },
  {
    "text": "it's so it's based on these things when we knew it was bad to discriminate but that's the data we have and we're trying",
    "start": "2008120",
    "end": "2014420"
  },
  {
    "text": "to fix it now but we're fixing it based on the data that was used in the first place most right and so and so the",
    "start": "2014420",
    "end": "2023270"
  },
  {
    "text": "decisions and you can look at everything from the hope the whole aspect of predictive policing criminal recidivism",
    "start": "2023270",
    "end": "2030550"
  },
  {
    "text": "there was a recent paper that had the healthcare algorithms which had kind of a sensational titles I'm not pro",
    "start": "2030550",
    "end": "2039310"
  },
  {
    "text": "sensationalism in titles but um but you read it right so yeah make sure read it",
    "start": "2039310",
    "end": "2045680"
  },
  {
    "text": "but I'm like really like what's the topic of the sensationalism I mean",
    "start": "2045680",
    "end": "2051139"
  },
  {
    "text": "what's underneath it what if you could sort of educate me and what kind of bias",
    "start": "2051140",
    "end": "2057230"
  },
  {
    "text": "creeps into the healthcare space yes so he's already kind of oh this one was the",
    "start": "2057230",
    "end": "2063230"
  },
  {
    "text": "headline was racist AI algorithms okay like okay that's totally a clickbait",
    "start": "2063230",
    "end": "2069590"
  },
  {
    "text": "title yeah oh and so you looked at it and so there was data that these",
    "start": "2069590",
    "end": "2074720"
  },
  {
    "text": "researchers had collected I believe I want to say was either science or nature he just was just published but they",
    "start": "2074720",
    "end": "2081050"
  },
  {
    "text": "didn't have the sensational tiger it was like the media and so they had looked at demographics I believe between",
    "start": "2081050",
    "end": "2089139"
  },
  {
    "text": "black and white women right and they were showed that there was a discrepancy",
    "start": "2089140",
    "end": "2096080"
  },
  {
    "text": "in in the outcomes right and so and it was tied to ethnicity tied to race the",
    "start": "2096080",
    "end": "2102530"
  },
  {
    "text": "piece that the researchers did actually went through the whole analysis but of",
    "start": "2102530",
    "end": "2107900"
  },
  {
    "text": "course I mean they're the journalists with AI a problematic across the board rights sake and so this is a problem",
    "start": "2107900",
    "end": "2115310"
  },
  {
    "text": "right and so there's this thing about oai it has all these problems we're",
    "start": "2115310",
    "end": "2120770"
  },
  {
    "text": "doing it on historical data and the outcomes aren't even based on gender or",
    "start": "2120770",
    "end": "2126020"
  },
  {
    "text": "ethnicity or age but I am always saying is like yes we need to do better right we need to do",
    "start": "2126020",
    "end": "2133280"
  },
  {
    "text": "better it is our duty to do better but the worst AI is still better than us",
    "start": "2133280",
    "end": "2139790"
  },
  {
    "text": "like like you take the best of us and we're still worse than the worst AI at least in terms of these things and",
    "start": "2139790",
    "end": "2145730"
  },
  {
    "text": "that's actually not discussed right and so I think and that's why the sensational title right and it's so it's",
    "start": "2145730",
    "end": "2152510"
  },
  {
    "text": "like so then you can have individuals go like oh we don't need to use this hey I'm like oh no no no no I want the AI",
    "start": "2152510",
    "end": "2157640"
  },
  {
    "text": "instead of the the doctors that provided that data cuz it's still better than",
    "start": "2157640",
    "end": "2162829"
  },
  {
    "text": "that yes right I think it's really important to linger on the idea that this AI is racist it's like well",
    "start": "2162829",
    "end": "2171440"
  },
  {
    "text": "compared to what sort of the we that I",
    "start": "2171440",
    "end": "2177980"
  },
  {
    "text": "think we set unfortunately way too high of a bar for AI algorithms and in the",
    "start": "2177980",
    "end": "2183800"
  },
  {
    "text": "ethical space where perfect is I would argue probably impossible then if we set",
    "start": "2183800",
    "end": "2190609"
  },
  {
    "text": "the bar of perfection essentially if it has to be perfectly fair whatever that means",
    "start": "2190609",
    "end": "2196040"
  },
  {
    "text": "is it means we're setting it up for failure but that's really important to say what you just said which is well",
    "start": "2196040",
    "end": "2202940"
  },
  {
    "text": "it's still better yeah and one of the things I I think that we don't get enough credit for just in terms of as",
    "start": "2202940",
    "end": "2211310"
  },
  {
    "text": "developers is that you can now poke at it right so it's harder to say you know",
    "start": "2211310",
    "end": "2217760"
  },
  {
    "text": "is this hospital is the city doing something right until someone brings in a civil case right well were they I it",
    "start": "2217760",
    "end": "2225319"
  },
  {
    "text": "can process through all this data and say hey yes there there's some an issue",
    "start": "2225319",
    "end": "2230930"
  },
  {
    "text": "here but here it is we've identified it and then the next step is to fix it I",
    "start": "2230930",
    "end": "2236089"
  },
  {
    "text": "mean that's a nice feedback loop versus like waiting for someone to sue someone else before it's fixed right and so I",
    "start": "2236089",
    "end": "2243020"
  },
  {
    "text": "think that power we need to capitalize on a little bit more right instead of having the sensational titles have the",
    "start": "2243020",
    "end": "2250810"
  },
  {
    "text": "okay this is a problem and this is how we're fixing it and people are putting money to fix it because we can make it better",
    "start": "2250810",
    "end": "2257750"
  },
  {
    "text": "now you look at like facial recognition how joy she basically called out",
    "start": "2257750",
    "end": "2264770"
  },
  {
    "text": "the companies and said hey and most of them were like Oh embarrassment and the",
    "start": "2264770",
    "end": "2269980"
  },
  {
    "text": "next time it had been fixed right it had been fixed better right and then I was",
    "start": "2269980",
    "end": "2275270"
  },
  {
    "text": "like oh here's some more issues and I think that conversation then moves that",
    "start": "2275270",
    "end": "2280700"
  },
  {
    "text": "needle to having much more fair and unbiased and ethical aspects as long as",
    "start": "2280700",
    "end": "2288170"
  },
  {
    "text": "both sides the developers are willing to say okay I hear you yes we are going to",
    "start": "2288170",
    "end": "2293360"
  },
  {
    "text": "improve and you have other developers are like you know hey AI it's wrong but I love it right yes so speaking of",
    "start": "2293360",
    "end": "2301640"
  },
  {
    "start": "2300000",
    "end": "2435000"
  },
  {
    "text": "this really nice notion that AI is maybe flawed but better than humans so just made me think of it one example",
    "start": "2301640",
    "end": "2309740"
  },
  {
    "text": "of flawed humans is our political system do you think or you said judicial as",
    "start": "2309740",
    "end": "2317420"
  },
  {
    "text": "well do you have a hope for AI sort of",
    "start": "2317420",
    "end": "2324730"
  },
  {
    "text": "being elected for president or running our Congress or being able to be a",
    "start": "2324730",
    "end": "2331250"
  },
  {
    "text": "powerful representative of the people so I mentioned and I truly believe that",
    "start": "2331250",
    "end": "2337240"
  },
  {
    "text": "this whole world of AI is in partnerships with people and so what does that mean I I don't believe or and",
    "start": "2337240",
    "end": "2345260"
  },
  {
    "text": "maybe I just don't I don't believe that we should have an AI for president but I",
    "start": "2345260",
    "end": "2351770"
  },
  {
    "text": "do believe that a president should use AI as an adviser right like if you think about it every president has a cabinet",
    "start": "2351770",
    "end": "2360080"
  },
  {
    "text": "of individuals that have different expertise that they should listen to",
    "start": "2360080",
    "end": "2365570"
  },
  {
    "text": "right like that's kind of what we do and you put smart people with smart expertise around certain issues and you",
    "start": "2365570",
    "end": "2372650"
  },
  {
    "text": "listen I don't see why a I can't function as one of those smart individuals giving input so maybe",
    "start": "2372650",
    "end": "2379760"
  },
  {
    "text": "there's an AI on health care maybe there's an AI on education and right like all these things that a human is",
    "start": "2379760",
    "end": "2386650"
  },
  {
    "text": "processing right because at the end of the day there's people that are human",
    "start": "2386650",
    "end": "2393350"
  },
  {
    "text": "that are going to be at the end of the decision and I don't think as a world as a culture as",
    "start": "2393350",
    "end": "2398360"
  },
  {
    "text": "xiety that we would totally be and this is us like this is some fallacy about us",
    "start": "2398360",
    "end": "2404810"
  },
  {
    "text": "but we need to see that leader that person as human and most people don't",
    "start": "2404810",
    "end": "2412670"
  },
  {
    "text": "realize that like leaders have a whole lot of advice right like when they say",
    "start": "2412670",
    "end": "2417770"
  },
  {
    "text": "something is not that they woke up well usually they don't wake up in the morning and be like I have a brilliant",
    "start": "2417770",
    "end": "2423560"
  },
  {
    "text": "idea right it's usually a ok let me listen I have a brilliant idea but let me get a little bit of feedback on this like ok",
    "start": "2423560",
    "end": "2430610"
  },
  {
    "text": "and then it's saying yeah that was an awesome idea or it's like yeah let me go back already talked to a bunch of them",
    "start": "2430610",
    "end": "2437240"
  },
  {
    "start": "2435000",
    "end": "2864000"
  },
  {
    "text": "but are there some possible solutions to the biases presence in our algorithms",
    "start": "2437240",
    "end": "2445250"
  },
  {
    "text": "beyond what we just talked about so I think there's two paths one is to figure",
    "start": "2445250",
    "end": "2451190"
  },
  {
    "text": "out how to systematically do the feedback in corrections so right now",
    "start": "2451190",
    "end": "2457040"
  },
  {
    "text": "it's ad hoc right it's a researcher identify some outcomes that are not",
    "start": "2457040",
    "end": "2463040"
  },
  {
    "text": "don't seem to be fair right they publish it they write about it and the either",
    "start": "2463040",
    "end": "2469520"
  },
  {
    "text": "the developer or the companies that have adopted the algorithms may try to fix it right and so it's really ad hoc and it's",
    "start": "2469520",
    "end": "2477230"
  },
  {
    "text": "not systematic there's it's just it's kind of like I'm a researcher that seems",
    "start": "2477230",
    "end": "2482900"
  },
  {
    "text": "like an interesting problem which means that there's a whole lot out there that's not being looked at right because",
    "start": "2482900",
    "end": "2489260"
  },
  {
    "text": "it's kind of researcher driven I and I don't necessarily have a solution but",
    "start": "2489260",
    "end": "2495250"
  },
  {
    "text": "that process I think could be done a little bit better",
    "start": "2495250",
    "end": "2500660"
  },
  {
    "text": "one way is I'm going to poke a little bit at some of the corporations right",
    "start": "2500660",
    "end": "2508070"
  },
  {
    "text": "like maybe the corporations when they think about a product they should instead of in addition to hiring these",
    "start": "2508070",
    "end": "2515840"
  },
  {
    "text": "you know bug they give these oh yeah yeah yeah wait you think Awards when you",
    "start": "2515840",
    "end": "2522350"
  },
  {
    "text": "find a bug yeah yes Joey bug yeah you know let's let's put it like we will",
    "start": "2522350",
    "end": "2527540"
  },
  {
    "text": "give the whatever the award is that we give for the people who finally secure holls find an ethics hole right like",
    "start": "2527540",
    "end": "2534140"
  },
  {
    "text": "find an unfairness hole and we will pay you X for each one you find I mean why can't they do that one is a win-win they",
    "start": "2534140",
    "end": "2541220"
  },
  {
    "text": "show that they're concerned about it that this is important and they don't have to necessarily dedicate it their",
    "start": "2541220",
    "end": "2546559"
  },
  {
    "text": "own like internal resources and it also means that everyone who has like their own bias lens like I'm interested in age",
    "start": "2546559",
    "end": "2554329"
  },
  {
    "text": "and so I'll find the ones based on age and I'm interested in gender and right which means that you get like all of",
    "start": "2554329",
    "end": "2560119"
  },
  {
    "text": "these different perspectives but you think of it in a data-driven way so like go see sort of if we look at a company",
    "start": "2560119",
    "end": "2567859"
  },
  {
    "text": "like Twitter it gets it's under a lot of fire for discriminating against certain",
    "start": "2567859",
    "end": "2573559"
  },
  {
    "text": "political beliefs correct and sort of there's a lot of people this is the sad",
    "start": "2573559",
    "end": "2578960"
  },
  {
    "text": "thing because I know how hard the problem is and I know the Twitter folks are working with a heart at it even Facebook that everyone seems to hate I",
    "start": "2578960",
    "end": "2584900"
  },
  {
    "text": "worked in really hard of this it you know the kind of evidence that people bring is basically anecdotal evidence",
    "start": "2584900",
    "end": "2590930"
  },
  {
    "text": "well me or my friend all we said is X and for that we got banned and and",
    "start": "2590930",
    "end": "2598819"
  },
  {
    "text": "that's kind of a discussion of saying well look that's usually first of all the whole thing is taken out of context",
    "start": "2598819",
    "end": "2605089"
  },
  {
    "text": "so they're they present sort of anecdotal evidence and how are you supposed to as a company in a healthy",
    "start": "2605089",
    "end": "2611839"
  },
  {
    "text": "way have a discourse about what is and isn't ethical what how do we make algorithms ethical when people are just",
    "start": "2611839",
    "end": "2619280"
  },
  {
    "text": "blowing everything like they're outraged about a particular and a godel evident",
    "start": "2619280",
    "end": "2626150"
  },
  {
    "text": "piece of evidence that's very difficult to sort of contextualize in the big data-driven way",
    "start": "2626150",
    "end": "2631720"
  },
  {
    "text": "do you have a hope for companies like Twitter and yeah so I think there's a",
    "start": "2631720",
    "end": "2637940"
  },
  {
    "text": "couple of things going on right first off the remember this whole aspect of we",
    "start": "2637940",
    "end": "2645470"
  },
  {
    "text": "are becoming reliant on technology we're also becoming reliant on a lot of",
    "start": "2645470",
    "end": "2652970"
  },
  {
    "text": "these the the apps and the resources that are provided right so some of it is",
    "start": "2652970",
    "end": "2658640"
  },
  {
    "text": "kind of anger like I need you right and you're not working for me",
    "start": "2658640",
    "end": "2664440"
  },
  {
    "text": "but I think and so some of it and I and I wish that there was a little bit of",
    "start": "2664440",
    "end": "2671460"
  },
  {
    "text": "change and rethinking so some of it is like oh we'll fix it in house no that's",
    "start": "2671460",
    "end": "2676590"
  },
  {
    "text": "like okay I'm a fox and I am going to watch these hens because I think it's a",
    "start": "2676590",
    "end": "2682230"
  },
  {
    "text": "problem that foxes eat hens No right like use like be good citizens and say",
    "start": "2682230",
    "end": "2688560"
  },
  {
    "text": "look we have a problem and we are willing to open ourselves up for others",
    "start": "2688560",
    "end": "2695400"
  },
  {
    "text": "to come in and look at it and not try to fix it in house because if you fix it in house there's conflict of interests if I",
    "start": "2695400",
    "end": "2702210"
  },
  {
    "text": "find something I'm probably going to want to fix it and hopefully the media won't pick it up right and that then",
    "start": "2702210",
    "end": "2708030"
  },
  {
    "text": "caused this distrust because someone inside is going to be mad at you and go out and talk about how yeah they can the",
    "start": "2708030",
    "end": "2714810"
  },
  {
    "text": "resume survey because it's rightly the best people like just say look we have",
    "start": "2714810",
    "end": "2721260"
  },
  {
    "text": "this issue community help us fix it and we will give you like you know the bug finder fee if you do did you have a hope",
    "start": "2721260",
    "end": "2728850"
  },
  {
    "text": "that the community us as a human civilization on the whole is good and",
    "start": "2728850",
    "end": "2734670"
  },
  {
    "text": "can be trusted to guide the future of our civilization into positive direction",
    "start": "2734670",
    "end": "2740460"
  },
  {
    "text": "I think so so I'm an optimist right and you know we there were some dark times",
    "start": "2740460",
    "end": "2747420"
  },
  {
    "text": "in history always I think now we're in one of those dark times I truly do and",
    "start": "2747420",
    "end": "2753780"
  },
  {
    "text": "which aspect the polarization and it's not just us right so if it was just us I'd be like yeah say us thing but we're",
    "start": "2753780",
    "end": "2760320"
  },
  {
    "text": "seeing it like worldwide this polarization and so I worry about that",
    "start": "2760320",
    "end": "2766820"
  },
  {
    "text": "but I do fundamentally believe that at the end of the day people are good right",
    "start": "2766820",
    "end": "2773340"
  },
  {
    "text": "and why do I say that because any time there's a scenario where people are in",
    "start": "2773340",
    "end": "2779190"
  },
  {
    "text": "danger and I would use I saw Atlanta we had Snowmageddon and people can laugh",
    "start": "2779190",
    "end": "2785040"
  },
  {
    "text": "about that people at the time so the city closed for you know little snow but",
    "start": "2785040",
    "end": "2791310"
  },
  {
    "text": "it was ice and the city closed down but you had people opening up their homes and saying hey you have nowhere to go",
    "start": "2791310",
    "end": "2797670"
  },
  {
    "text": "come to my house right hotels were just saying like sleep on the floor like places like you know the grocery stores",
    "start": "2797670",
    "end": "2804029"
  },
  {
    "text": "were like hey here's food there was no like oh how much are you gonna pay me it was like this such a community and like",
    "start": "2804029",
    "end": "2810960"
  },
  {
    "text": "people who didn't know each other strangers were just like can I give you a ride home and that was a point I was",
    "start": "2810960",
    "end": "2817079"
  },
  {
    "text": "like you know I like that that there reveals that the deeper thing is is",
    "start": "2817079",
    "end": "2822539"
  },
  {
    "text": "there's a compassion or love that we all have within us it's just that when all",
    "start": "2822539",
    "end": "2828299"
  },
  {
    "text": "that is taken care of and get bored we love drama and that's I think almost",
    "start": "2828299",
    "end": "2833880"
  },
  {
    "text": "like the division is the sign of the time is being good is that it's just entertaining under some unpleasant",
    "start": "2833880",
    "end": "2841369"
  },
  {
    "text": "mammalian level to watch to disagree with others and Twitter and Facebook are",
    "start": "2841369",
    "end": "2847470"
  },
  {
    "text": "actually taking advantage of that in the sense because it brings you back to the",
    "start": "2847470",
    "end": "2853380"
  },
  {
    "text": "platform and their advertisers are driven so they make a lot of money love",
    "start": "2853380",
    "end": "2859470"
  },
  {
    "text": "doesn't sell quite as well in terms of advertisement so you've started your",
    "start": "2859470",
    "end": "2866519"
  },
  {
    "start": "2864000",
    "end": "2997000"
  },
  {
    "text": "career NASA Jet Propulsion Laboratory but before I'd ask a few questions there have you happen to have ever seen Space",
    "start": "2866519",
    "end": "2873749"
  },
  {
    "text": "Odyssey 2001 Space Odyssey yes okay do",
    "start": "2873749",
    "end": "2879509"
  },
  {
    "text": "you think Hal 9000 so we're talking about ethics do you think how did the",
    "start": "2879509",
    "end": "2886019"
  },
  {
    "text": "right thing by taking the priority of the mission over the lives of the astronauts do you think Cal is good or",
    "start": "2886019",
    "end": "2891509"
  },
  {
    "text": "evil easy questions yeah",
    "start": "2891509",
    "end": "2898609"
  },
  {
    "text": "Hal was misguided you're one of the people that would be in charge of an",
    "start": "2898609",
    "end": "2904289"
  },
  {
    "text": "algorithm like Hal yes so how would you do better if you think about what",
    "start": "2904289",
    "end": "2910289"
  },
  {
    "text": "happened was there was no failsafe right so we perfection right like what is that",
    "start": "2910289",
    "end": "2918299"
  },
  {
    "text": "I'm gonna make something that I think is perfect but if my assumptions are wrong",
    "start": "2918299",
    "end": "2923809"
  },
  {
    "text": "it'll be perfect based on the wrong assumptions all right that's something that you don't know until you deploy and",
    "start": "2923809",
    "end": "2931859"
  },
  {
    "text": "like oh yeah messed up but what that means is that when we design software",
    "start": "2931859",
    "end": "2938009"
  },
  {
    "text": "such as in Space Odyssey when we put things out that there has to be a failsafe there has to be the ability",
    "start": "2938009",
    "end": "2945059"
  },
  {
    "text": "that once it's out there you know we can grade it as an F and it fails and it",
    "start": "2945059",
    "end": "2951599"
  },
  {
    "text": "doesn't continue right if there's some way that it can be brought in and and removed and that's aspect because that's",
    "start": "2951599",
    "end": "2960029"
  },
  {
    "text": "what happened with what how it was like assumptions were wrong it was perfectly correct based on those",
    "start": "2960029",
    "end": "2966569"
  },
  {
    "text": "assumptions and there was no way to change change it change the assumptions",
    "start": "2966569",
    "end": "2972559"
  },
  {
    "text": "at all and the change the fallback would be to humans so you ultimately think",
    "start": "2972559",
    "end": "2977849"
  },
  {
    "text": "like humans should be you know it's not Turtles or AI all the way down it's at",
    "start": "2977849",
    "end": "2986069"
  },
  {
    "text": "some point there's a human that actually don't think that and again because I do human robot interaction I still think",
    "start": "2986069",
    "end": "2992099"
  },
  {
    "text": "the human needs to be part of the equation at some point so what just",
    "start": "2992099",
    "end": "2997739"
  },
  {
    "start": "2997000",
    "end": "3113000"
  },
  {
    "text": "looking back what are some fascinating things in robotic space that NASA was working at the time or just in general",
    "start": "2997739",
    "end": "3004069"
  },
  {
    "text": "what what have you gotten to play with and what are your memories from working",
    "start": "3004069",
    "end": "3009410"
  },
  {
    "text": "at NASA yes so one of my first memories was they were working on a surgical",
    "start": "3009410",
    "end": "3017150"
  },
  {
    "text": "robot system that could do eye surgery right and this was back in oh my gosh it",
    "start": "3017150",
    "end": "3023989"
  },
  {
    "text": "must have been Oh maybe 92 93 94 so it's",
    "start": "3023989",
    "end": "3030739"
  },
  {
    "text": "like almost like a remote operation oh yeah it was it was a remote operation in fact that you can even find some old",
    "start": "3030739",
    "end": "3036619"
  },
  {
    "text": "tech reports on it so think of it you know like now we have da Vinci right like think of it but these are like the",
    "start": "3036619",
    "end": "3043640"
  },
  {
    "text": "late 90s right and I remember going into the lab one day and I was like what's",
    "start": "3043640",
    "end": "3049670"
  },
  {
    "text": "that right and of course it wasn't pretty right because the technology but",
    "start": "3049670",
    "end": "3055369"
  },
  {
    "text": "it was like functional and you had as this individual that could use version of haptics",
    "start": "3055369",
    "end": "3060499"
  },
  {
    "text": "to actually do the surgery and they had this mock-up of a human face and like the eyeballs",
    "start": "3060499",
    "end": "3065660"
  },
  {
    "text": "you can see this little drill and I was like oh that one I vividly remember",
    "start": "3065660",
    "end": "3072910"
  },
  {
    "text": "because it was so outside of my like possible thoughts of what could be done",
    "start": "3072910",
    "end": "3079430"
  },
  {
    "text": "the kind of precision and uh hey what what's the most amazing of a thing like",
    "start": "3079430",
    "end": "3085490"
  },
  {
    "text": "that I think it was the precision it was the kind of first time that I had",
    "start": "3085490",
    "end": "3092710"
  },
  {
    "text": "physically seen this robot machine human",
    "start": "3092710",
    "end": "3097760"
  },
  {
    "text": "interface right versus because manufacturing have been you saw those",
    "start": "3097760",
    "end": "3102950"
  },
  {
    "text": "kind of big robots right but this was like oh this is in a person there's a",
    "start": "3102950",
    "end": "3108289"
  },
  {
    "text": "person in a robot like in the same space the meeting them in person I like for me",
    "start": "3108289",
    "end": "3113569"
  },
  {
    "start": "3113000",
    "end": "3267000"
  },
  {
    "text": "it was a magical moment that I can't as a life-transforming that I recently met",
    "start": "3113569",
    "end": "3118849"
  },
  {
    "text": "spot mini from Boston Dynamics Elysee I don't know why but on the human robot interaction for some reason I realized",
    "start": "3118849",
    "end": "3126650"
  },
  {
    "text": "how easy it is to anthropomorphize and it was I don't know it was uh it was",
    "start": "3126650",
    "end": "3132289"
  },
  {
    "text": "almost like falling in love this feeling of meeting and I've obviously seen these or was a lot on video and so on but",
    "start": "3132289",
    "end": "3138349"
  },
  {
    "text": "meeting in person just having that one-on-one time it's different so do you have you had a robot like that in your",
    "start": "3138349",
    "end": "3144740"
  },
  {
    "text": "life that was made you maybe fall in love with robotics sort of odds like meeting in person I mean I mean I I",
    "start": "3144740",
    "end": "3153710"
  },
  {
    "text": "loved robotics yeah that was a 12 year old like I would be a roboticist",
    "start": "3153710",
    "end": "3158960"
  },
  {
    "text": "actually was I called it cybernetics but so my my motivation was Bionic Woman I",
    "start": "3158960",
    "end": "3164779"
  },
  {
    "text": "don't know if you know that is um and so I mean that was like a seminal moment but I didn't me like that was TV right",
    "start": "3164779",
    "end": "3172309"
  },
  {
    "text": "like it wasn't like I was in the same space and I meant I was like oh my gosh you're like real just linking I'm Bionic",
    "start": "3172309",
    "end": "3177650"
  },
  {
    "text": "Woman which by the way because I've read that about you I watched a bit bits of",
    "start": "3177650",
    "end": "3183140"
  },
  {
    "text": "it and it's just so no offence terrible",
    "start": "3183140",
    "end": "3187359"
  },
  {
    "text": "I've seen a couple of reruns lately it's uh but of course at the time is probably",
    "start": "3188289",
    "end": "3194920"
  },
  {
    "text": "disgusted the imagination especially when you're younger just",
    "start": "3194920",
    "end": "3202660"
  },
  {
    "text": "catch you but which aspect did you think of it you mentioned cybernetics did you think of it as robotics or did you think",
    "start": "3202660",
    "end": "3208270"
  },
  {
    "text": "of it as almost constructing artificial beings like is it the intelligent part",
    "start": "3208270",
    "end": "3214030"
  },
  {
    "text": "that that captured your fascination or was it the whole thing like even just the limbs and just so for me it would",
    "start": "3214030",
    "end": "3220900"
  },
  {
    "text": "have in another world I probably would have been more of a biomedical engineer",
    "start": "3220900",
    "end": "3226150"
  },
  {
    "text": "because what fascinated me was the by on it was the parts like the Bionic parts the limbs those aspects of it are you",
    "start": "3226150",
    "end": "3235300"
  },
  {
    "text": "especially drawn to humanoid or human-like robots I would say human-like",
    "start": "3235300",
    "end": "3240760"
  },
  {
    "text": "not humanoid right and when I say human-like I think it's this aspect of",
    "start": "3240760",
    "end": "3246010"
  },
  {
    "text": "that interaction whether it's social and it's like a dog right like that's",
    "start": "3246010",
    "end": "3251280"
  },
  {
    "text": "human-like because it's understand us it interacts with us at that very social",
    "start": "3251280",
    "end": "3256780"
  },
  {
    "text": "level - you know humanoids are part of that but only if they interact with us",
    "start": "3256780",
    "end": "3264670"
  },
  {
    "text": "as if we are human but just to linger on NASA for a little bit what do you think",
    "start": "3264670",
    "end": "3271810"
  },
  {
    "start": "3267000",
    "end": "3431000"
  },
  {
    "text": "maybe if you have other memories but also what do you think is the future of robots in space will mention how but",
    "start": "3271810",
    "end": "3280240"
  },
  {
    "text": "there's incredible robots and NASA's working on in general thinking about in art as we venture out human civilization",
    "start": "3280240",
    "end": "3289119"
  },
  {
    "text": "ventures out into space what do you think the future of robots is there yes so I mean there's the near term for example they just announced the the",
    "start": "3289119",
    "end": "3296410"
  },
  {
    "text": "rover that's going to the moon which you know that's kind of exciting but that's",
    "start": "3296410",
    "end": "3303490"
  },
  {
    "text": "like near-term you know my favorite favorite favorite series is Star Trek",
    "start": "3303490",
    "end": "3311609"
  },
  {
    "text": "right you know I really hope and even Star Trek like if I calculate the years",
    "start": "3311609",
    "end": "3318550"
  },
  {
    "text": "I wouldn't be alive but I would really really love to be in that world like",
    "start": "3318550",
    "end": "3326859"
  },
  {
    "text": "even if it's just at the beginning like you know like voyage like adventure one so basically living",
    "start": "3326859",
    "end": "3334119"
  },
  {
    "text": "in space yeah with what what robots would a robots do data were roll the",
    "start": "3334119",
    "end": "3341230"
  },
  {
    "text": "data would have to be even though that wasn't you know that was like later but so data is a robot that has human-like",
    "start": "3341230",
    "end": "3348280"
  },
  {
    "text": "qualities right without the emotion ship yeah you don't like emotion well they know what the emotion ship was kind of a",
    "start": "3348280",
    "end": "3356319"
  },
  {
    "text": "mess right it took a while for for that",
    "start": "3356319",
    "end": "3362260"
  },
  {
    "text": "thing to adapt but and and so why was",
    "start": "3362260",
    "end": "3367359"
  },
  {
    "text": "that an issue the issue is is that emotions make us irrational agents",
    "start": "3367359",
    "end": "3373690"
  },
  {
    "text": "that's the problem and yet he could think through things even if it was",
    "start": "3373690",
    "end": "3380950"
  },
  {
    "text": "based on an emotional scenario right based on pros and cons but as soon as you made him emotional one of the",
    "start": "3380950",
    "end": "3389380"
  },
  {
    "text": "metrics he used for evaluation was his own emotions not people around him right",
    "start": "3389380",
    "end": "3395109"
  },
  {
    "text": "like and so we do that as children right so we're very egocentric we're very",
    "start": "3395109",
    "end": "3401380"
  },
  {
    "text": "egocentric and so isn't that just an early version of the emotion ship then I haven't watched much Star Trek I have",
    "start": "3401380",
    "end": "3409299"
  },
  {
    "text": "also met adults right and so that is that is a developmental process and I'm",
    "start": "3409299",
    "end": "3415510"
  },
  {
    "text": "sure there's a bunch of psychologists that can go through like you can have a six-year-old dolt who has the emotional",
    "start": "3415510",
    "end": "3422319"
  },
  {
    "text": "maturity of a ten-year-old right and so there's various phases that people",
    "start": "3422319",
    "end": "3427450"
  },
  {
    "text": "should go through in order to evolve and sometimes you don't so how much psychology do you think a topic that's",
    "start": "3427450",
    "end": "3435549"
  },
  {
    "start": "3431000",
    "end": "3758000"
  },
  {
    "text": "rarely mentioned in robotics but how much the psychology come to play when you're talking about HRI human robot",
    "start": "3435549",
    "end": "3442839"
  },
  {
    "text": "interaction when you have to have robots that actually interact with you tons so we like my group as well as I read a lot",
    "start": "3442839",
    "end": "3451089"
  },
  {
    "text": "in the cognitive science literature as well as the psychology literature because they understand a lot about",
    "start": "3451089",
    "end": "3460180"
  },
  {
    "text": "human human relations and developmental milestones things like that and so we tend to look",
    "start": "3460180",
    "end": "3468550"
  },
  {
    "text": "to see what what's been done out there sometimes what we'll do is we'll try to",
    "start": "3468550",
    "end": "3474910"
  },
  {
    "text": "match that to see is that human human relationship the same as human robot",
    "start": "3474910",
    "end": "3480420"
  },
  {
    "text": "sometimes it is and sometimes is different and then when it's different we have to we try to figure out okay why",
    "start": "3480420",
    "end": "3486670"
  },
  {
    "text": "is it different in this scenario but it's the same in the other scenario right and so we try to do that quite a",
    "start": "3486670",
    "end": "3494140"
  },
  {
    "text": "bit would you say that's if we're looking at the future of human robot interaction would you say the psychology",
    "start": "3494140",
    "end": "3500380"
  },
  {
    "text": "piece is the hardest like if it's I mean it's a funny notion for you as I don't",
    "start": "3500380",
    "end": "3505990"
  },
  {
    "text": "know if you consider yeah I mean one way to ask it do you consider yourself for roboticist or psychologists oh I",
    "start": "3505990",
    "end": "3512080"
  },
  {
    "text": "consider myself a robot is's that plays the act of a psychologist but if you were look at yourself sort of you know",
    "start": "3512080",
    "end": "3519910"
  },
  {
    "text": "20 30 years from now do you see yourself more and more wearing the psychology hat",
    "start": "3519910",
    "end": "3526830"
  },
  {
    "text": "another way to put it is are the hard problems in human robot interactions fundamentally psychology or is it still",
    "start": "3526830",
    "end": "3534760"
  },
  {
    "text": "robotics the perception of manipulation planning all that kind of stuff it's actually neither the hardest part is the",
    "start": "3534760",
    "end": "3543250"
  },
  {
    "text": "adaptation in the interaction so learning it's the interface it's the",
    "start": "3543250",
    "end": "3548470"
  },
  {
    "text": "learning and so if I think of like I've become much more of a roboticist /ai",
    "start": "3548470",
    "end": "3555970"
  },
  {
    "text": "person then when I like originally again I was about the bionics I was looking I was electrical engineer I was control",
    "start": "3555970",
    "end": "3562630"
  },
  {
    "text": "theory right like and then I started realizing that my algorithms needed like",
    "start": "3562630",
    "end": "3569350"
  },
  {
    "text": "human data right and so that I was like okay what is this human thing but how do I incorporate human data and then I",
    "start": "3569350",
    "end": "3574810"
  },
  {
    "text": "realized that human perception had there was a lot in terms of how we perceived",
    "start": "3574810",
    "end": "3580510"
  },
  {
    "text": "the world it's so trying to figure out how do i model human perception for my and so I became a HRI person human robot",
    "start": "3580510",
    "end": "3588040"
  },
  {
    "text": "interaction person from being a control theory and realizing that humans actually offered quite a bit and then",
    "start": "3588040",
    "end": "3595450"
  },
  {
    "text": "when you do that you become one more of artificial intelligence AI and so I see",
    "start": "3595450",
    "end": "3600470"
  },
  {
    "text": "myself evolving more in this AI world under the lens of robotics",
    "start": "3600470",
    "end": "3609080"
  },
  {
    "text": "having Hardware interacting with people so you're a world-class expert",
    "start": "3609080",
    "end": "3615530"
  },
  {
    "text": "researcher in robotics and yet others you know there's a few it's a small but",
    "start": "3615530",
    "end": "3622040"
  },
  {
    "text": "fierce community of people but most of them don't take the journey into the h",
    "start": "3622040",
    "end": "3627170"
  },
  {
    "text": "of HR I into the human so why did you brave into the interaction with humans",
    "start": "3627170",
    "end": "3633440"
  },
  {
    "text": "it seems like a really hard problem it's a hard problem and it's very risky as an",
    "start": "3633440",
    "end": "3639080"
  },
  {
    "text": "academic yes and I knew that when I started down that journey that it was",
    "start": "3639080",
    "end": "3646880"
  },
  {
    "text": "very risky as an academic in this world that was nuanced it was just developing",
    "start": "3646880",
    "end": "3653120"
  },
  {
    "text": "we didn't have a conference right at the time because it was the interesting",
    "start": "3653120",
    "end": "3658790"
  },
  {
    "text": "problems that was what drove me it was the fact that I looked at what interests",
    "start": "3658790",
    "end": "3666530"
  },
  {
    "text": "me in terms of the application space and the problems and that pushed me into",
    "start": "3666530",
    "end": "3672610"
  },
  {
    "text": "trying to figure out what people were and what humans were and how to adapt to",
    "start": "3672610",
    "end": "3677750"
  },
  {
    "text": "them if those problems weren't so interesting I'd probably still be",
    "start": "3677750",
    "end": "3682970"
  },
  {
    "text": "sending Rovers to glaciers right but the problems were interesting and the other",
    "start": "3682970",
    "end": "3688580"
  },
  {
    "text": "thing was that they were hard right so it's I like having to go into a room and",
    "start": "3688580",
    "end": "3693980"
  },
  {
    "text": "being like I don't know and then going back and saying okay I'm gonna figure this out I do not I'm not driven when I",
    "start": "3693980",
    "end": "3701750"
  },
  {
    "text": "go in like oh there are no surprises like I don't find that satisfying if",
    "start": "3701750",
    "end": "3707420"
  },
  {
    "text": "that was the case I go someplace and make a lot more money right I think I stay in academic because and choose to",
    "start": "3707420",
    "end": "3714320"
  },
  {
    "text": "do this because I can go into a room like that's hard yeah I think just for",
    "start": "3714320",
    "end": "3719720"
  },
  {
    "text": "my perspective maybe you can correct me on it but if I just look at the field of",
    "start": "3719720",
    "end": "3725420"
  },
  {
    "text": "AI broadly it seems that human robot interaction has the most one of the most number of",
    "start": "3725420",
    "end": "3734720"
  },
  {
    "text": "open problems people especially relative to how many people are willing to",
    "start": "3734720",
    "end": "3741019"
  },
  {
    "text": "acknowledge that there are this because most people are just afraid of the human",
    "start": "3741019",
    "end": "3746029"
  },
  {
    "text": "so they don't even acknowledge how many open problems are but it's a in terms of difficult problems to solve exciting",
    "start": "3746029",
    "end": "3751309"
  },
  {
    "text": "spaces it seems to be an incredible for that it is it is exciting",
    "start": "3751309",
    "end": "3757789"
  },
  {
    "text": "you mentioned trust before what role does trust from interacting with",
    "start": "3757789",
    "end": "3765499"
  },
  {
    "start": "3758000",
    "end": "4166000"
  },
  {
    "text": "autopilot to in the medical context what role distress playing the human robot",
    "start": "3765499",
    "end": "3770539"
  },
  {
    "text": "trap so some of the things I study in this domain is not just trust but it really is over trust how do you think",
    "start": "3770539",
    "end": "3777380"
  },
  {
    "text": "about over traffic what is for so what is what is trust and what is overdressed",
    "start": "3777380",
    "end": "3783170"
  },
  {
    "text": "basically the way I look at it is trust is not what you click on a survey just this is about your behavior so if you",
    "start": "3783170",
    "end": "3790099"
  },
  {
    "text": "interact with the technology based on the decision are the actions of the",
    "start": "3790099",
    "end": "3796579"
  },
  {
    "text": "technology as if you trust that decision then you're trusting right and I mean",
    "start": "3796579",
    "end": "3803180"
  },
  {
    "text": "even in my group we've done surveys that you know on the thing do my you trust robots",
    "start": "3803180",
    "end": "3808219"
  },
  {
    "text": "of course not would you follow this robot in a burning building of course not right and then you look at their",
    "start": "3808219",
    "end": "3813710"
  },
  {
    "text": "actions and you're like clearly your behavior does not match what you think",
    "start": "3813710",
    "end": "3818809"
  },
  {
    "text": "right or which you think you would like to think right and so I'm really concerned about the behavior because",
    "start": "3818809",
    "end": "3824150"
  },
  {
    "text": "that's really at the end of the day when you're in the world that's what will impact others around you it's not",
    "start": "3824150",
    "end": "3830809"
  },
  {
    "text": "whether before you went onto the street you you clicked on like I don't trust self-driving cars you know that from an",
    "start": "3830809",
    "end": "3837559"
  },
  {
    "text": "outsider perspective it's always frustrating to me well I read a lot so I'm Insider in a certain philosophical",
    "start": "3837559",
    "end": "3843259"
  },
  {
    "text": "sense the it's frustrating to me how often Trust is used in surveys and how",
    "start": "3843259",
    "end": "3851420"
  },
  {
    "text": "people say make claims that have any kind of finding they make about somebody",
    "start": "3851420",
    "end": "3856849"
  },
  {
    "text": "clicking on answer you just trust is uh",
    "start": "3856849",
    "end": "3862089"
  },
  {
    "text": "yet behavior just you said it beautiful I mean the action your own behavior as is what Trust is I mean that everything",
    "start": "3862250",
    "end": "3869150"
  },
  {
    "text": "else is not even close it's almost like a absurd comedic poetry",
    "start": "3869150",
    "end": "3876080"
  },
  {
    "text": "that you weave around your actual behavior so some people can say they're they their trust",
    "start": "3876080",
    "end": "3881570"
  },
  {
    "text": "you know I trough trust my wife husband or not whatever but the actions is what",
    "start": "3881570",
    "end": "3887180"
  },
  {
    "text": "speaks volumes but their car probably don't I trust them I'm just making sure",
    "start": "3887180",
    "end": "3893600"
  },
  {
    "text": "no no that's yeah it's like even if you think about cars I think it's a beautiful case I",
    "start": "3893600",
    "end": "3898640"
  },
  {
    "text": "came here at some point I'm sure on either Oberer lift right I remember when",
    "start": "3898640",
    "end": "3904430"
  },
  {
    "text": "it first came out I I bet if they had had a survey would you get in the car with a stranger and pay them yes how",
    "start": "3904430",
    "end": "3912980"
  },
  {
    "text": "many people do you would think would have said like really you know wait even worse would you get in the car with a",
    "start": "3912980",
    "end": "3918890"
  },
  {
    "text": "stranger at 1:00 a.m. in the morning to have them drop you home as a single",
    "start": "3918890",
    "end": "3924230"
  },
  {
    "text": "female yeah like how many people would say that's stupid yeah and now look at",
    "start": "3924230",
    "end": "3930740"
  },
  {
    "text": "where we are I mean people put kids like great links oh yeah my child has to go to school and",
    "start": "3930740",
    "end": "3937820"
  },
  {
    "text": "I yeah I'm gonna put my kid in this car with a stranger yeah I mean it's just a",
    "start": "3937820",
    "end": "3943490"
  },
  {
    "text": "fascinating how like what we think we think is not necessarily matching our",
    "start": "3943490",
    "end": "3948830"
  },
  {
    "text": "behavior and certainly with robots for the tallest vehicles and and all all the kinds of robots you work with that's",
    "start": "3948830",
    "end": "3955090"
  },
  {
    "text": "it's yeah it's the way you answer it",
    "start": "3955090",
    "end": "3960380"
  },
  {
    "text": "especially if you've never interacted with that robot before if you haven't had the experience you're being able to",
    "start": "3960380",
    "end": "3966320"
  },
  {
    "text": "respond correctly I know surveys is impossible but what do you what role does trust play in the interaction do",
    "start": "3966320",
    "end": "3973490"
  },
  {
    "text": "you think like is it good - is it good to trust a robot what is over trust mean",
    "start": "3973490",
    "end": "3980830"
  },
  {
    "text": "what is it it's good to kind of how you feel about autopilot currently which is like for a roboticist perspective is",
    "start": "3980830",
    "end": "3988369"
  },
  {
    "text": "like is so very cautious yeah so this is still an open area of research",
    "start": "3988369",
    "end": "3994710"
  },
  {
    "text": "but basically what I would like in a perfect world is that people trust the",
    "start": "3994710",
    "end": "4002450"
  },
  {
    "text": "technology when is working a hundred percent and people will be hypersensitive and identify when it's",
    "start": "4002450",
    "end": "4008450"
  },
  {
    "text": "not but of course we're not there that's that's the ideal world and but we find",
    "start": "4008450",
    "end": "4014690"
  },
  {
    "text": "is that people swing right they tend to swing which means that if my first and",
    "start": "4014690",
    "end": "4021350"
  },
  {
    "text": "like we have some papers like first impressions in everything is everything right if my first instance with",
    "start": "4021350",
    "end": "4027170"
  },
  {
    "text": "technology with robotics is positive it mitigates any risk in it correlates with",
    "start": "4027170",
    "end": "4034430"
  },
  {
    "text": "like best outcomes it means that I'm more likely to either not see it when it",
    "start": "4034430",
    "end": "4041840"
  },
  {
    "text": "makes a mistakes or faults or I'm more likely to forgive it and so this is a",
    "start": "4041840",
    "end": "4050060"
  },
  {
    "text": "problem because technology is not 100 percent accurate right it's not as if it's inaccurate although it may be perfect how do you get that first moment",
    "start": "4050060",
    "end": "4056540"
  },
  {
    "text": "right do you think there's also an education about the capabilities and limitations of the system do you have a",
    "start": "4056540",
    "end": "4062750"
  },
  {
    "text": "sense of how do you educate people correctly in that first interaction again this is this is an open-ended",
    "start": "4062750",
    "end": "4069110"
  },
  {
    "text": "problem so one of the study that actually has given me some hope that I",
    "start": "4069110",
    "end": "4075200"
  },
  {
    "text": "were trying to figure out how to put in robotics so there was a research study",
    "start": "4075200",
    "end": "4081110"
  },
  {
    "text": "that had showed for medical AI systems giving information to radiologists about",
    "start": "4081110",
    "end": "4087260"
  },
  {
    "text": "you know here you need to look at these areas on the x-ray what they found was",
    "start": "4087260",
    "end": "4095360"
  },
  {
    "text": "that when the system provided one choice there was this aspect of either no trust",
    "start": "4095360",
    "end": "4105170"
  },
  {
    "text": "or over trust right like I'm not going I don't believe it at all or a yes yes yes",
    "start": "4105170",
    "end": "4113150"
  },
  {
    "text": "yes and they was miss things right instead when the system gave them",
    "start": "4113150",
    "end": "4119180"
  },
  {
    "text": "multiple choices like here are the three even if it knew like you know it had estimated that the top area you need to",
    "start": "4119180",
    "end": "4125569"
  },
  {
    "text": "look at was he you know someplace on the x-ray if it gave like one plus",
    "start": "4125570",
    "end": "4132100"
  },
  {
    "text": "others the trust was maintained and the",
    "start": "4132100",
    "end": "4138290"
  },
  {
    "text": "accuracy of the entire population increased right so basically it was a",
    "start": "4138290",
    "end": "4145310"
  },
  {
    "text": "you're still trusting the system but you're also putting in a little bit of like your human expertise like you're a",
    "start": "4145310",
    "end": "4151970"
  },
  {
    "text": "human decision processing into the equation so it helps to mitigate that over trust risk yeah so there's a",
    "start": "4151970",
    "end": "4159230"
  },
  {
    "text": "fascinating balance tough to strike I haven't figured out again exciting open",
    "start": "4159230",
    "end": "4164870"
  },
  {
    "text": "area research exactly so what are some exciting applications of human robot interaction you started a company maybe",
    "start": "4164870",
    "end": "4171318"
  },
  {
    "start": "4166000",
    "end": "4506000"
  },
  {
    "text": "you can talk about the the exciting efforts there but in general also what",
    "start": "4171319",
    "end": "4176870"
  },
  {
    "text": "other space can robots interact with humans and help yeah so besides healthcare cuz you know that's my bias",
    "start": "4176870",
    "end": "4183350"
  },
  {
    "text": "lens my other bias lens is education I think that well one we definitely we in",
    "start": "4183350",
    "end": "4192049"
  },
  {
    "text": "the u.s. you know we're doing okay with teachers but there's a lot of school districts that don't have enough",
    "start": "4192050",
    "end": "4197630"
  },
  {
    "text": "teachers if you think about the teacher-student ratio for at least",
    "start": "4197630",
    "end": "4203030"
  },
  {
    "text": "public education um in some districts it's crazy it's like how can you have",
    "start": "4203030",
    "end": "4208070"
  },
  {
    "text": "learning in that classroom right because you just don't have the human capital and so if you think about robotics",
    "start": "4208070",
    "end": "4214930"
  },
  {
    "text": "bringing that in to classrooms as well as the after-school space where they",
    "start": "4214930",
    "end": "4220880"
  },
  {
    "text": "offset some of this lack of resources and certain communities I think that's a",
    "start": "4220880",
    "end": "4227600"
  },
  {
    "text": "good place and then turning on the other end is using the system's then for",
    "start": "4227600",
    "end": "4233260"
  },
  {
    "text": "workforce retraining and dealing with some of the things that are going to",
    "start": "4233260",
    "end": "4239690"
  },
  {
    "text": "come out later on of job loss like thinking about robots and Nai systems",
    "start": "4239690",
    "end": "4245810"
  },
  {
    "text": "for retraining and Workforce Development I think that's exciting areas that can be pushed even more and",
    "start": "4245810",
    "end": "4253310"
  },
  {
    "text": "it would have a huge huge impact what would you say some of the open problems",
    "start": "4253310",
    "end": "4258710"
  },
  {
    "text": "were in education so it's a exciting so young kids and the",
    "start": "4258710",
    "end": "4267220"
  },
  {
    "text": "older folks or just folks of all ages who need to be retrained we need to sort",
    "start": "4267220",
    "end": "4273290"
  },
  {
    "text": "of open themselves up to a whole nother area of work what what are the problems",
    "start": "4273290",
    "end": "4278960"
  },
  {
    "text": "to be solved there how do you think robots can help we we have the engagement aspect right so we can figure",
    "start": "4278960",
    "end": "4285620"
  },
  {
    "text": "out the engagement that's not a what do you mean by engagement so identifying whether a person is focused is like that",
    "start": "4285620",
    "end": "4296930"
  },
  {
    "text": "we can figure out what we can figure out and and there's some positive results in",
    "start": "4296930",
    "end": "4303920"
  },
  {
    "text": "this is that personalized adaptation based on any con sense right so imagine",
    "start": "4303920",
    "end": "4310280"
  },
  {
    "text": "I think about I have an agent and I'm working with a kid learning I don't know",
    "start": "4310280",
    "end": "4319550"
  },
  {
    "text": "algebra - in that same agent then switch and teach some type of new coding skill",
    "start": "4319550",
    "end": "4327620"
  },
  {
    "text": "to a displacement Anik like what does that actually look like right like",
    "start": "4327620",
    "end": "4335020"
  },
  {
    "text": "hardware might be the same content is different to different target",
    "start": "4335020",
    "end": "4340460"
  },
  {
    "text": "demographics of engagement like how do you do that how important do you think personalization is in human robot",
    "start": "4340460",
    "end": "4347870"
  },
  {
    "text": "interaction and not just mechanic or student but like literally to the",
    "start": "4347870",
    "end": "4353000"
  },
  {
    "text": "individual human being I think personalization is really important but a caveat is that I think",
    "start": "4353000",
    "end": "4361040"
  },
  {
    "text": "we'd be ok if we can personalize to the group right and so if I can label you as",
    "start": "4361040",
    "end": "4370150"
  },
  {
    "text": "along some certain dimensions then even though it may not be you specifically I",
    "start": "4370150",
    "end": "4376130"
  },
  {
    "text": "can put you in this group so the sample size this is how they best learn this is how they best engage even at that level",
    "start": "4376130",
    "end": "4383960"
  },
  {
    "text": "it's really important and it's because I mean it's one of the reasons why",
    "start": "4383960",
    "end": "4389950"
  },
  {
    "text": "educating in large classrooms is so hard right you teach too you know the median but there's these",
    "start": "4389950",
    "end": "4396870"
  },
  {
    "text": "you know individuals that are you know struggling and then you have highly intelligent individuals and those are",
    "start": "4396870",
    "end": "4402810"
  },
  {
    "text": "the ones that are usually you know kind of left out so highly intelligent individuals may be disruptive and those",
    "start": "4402810",
    "end": "4409200"
  },
  {
    "text": "who are struggling might be you disruptive because they're both bored yeah and if you narrow this the",
    "start": "4409200",
    "end": "4414270"
  },
  {
    "text": "definition of the group or in the size of the group enough you'll be able to address their individual yeah it's not",
    "start": "4414270",
    "end": "4420630"
  },
  {
    "text": "individual needs but really gross needs a group most important group needs right right and that's kind of what a lot of",
    "start": "4420630",
    "end": "4427350"
  },
  {
    "text": "successful recommender systems do is Spotify and so on say sad to believe but I'm as a music listener probably in some",
    "start": "4427350",
    "end": "4434550"
  },
  {
    "text": "sort of large group it's very sadly predictable been labeled yeah I've been",
    "start": "4434550",
    "end": "4439620"
  },
  {
    "text": "labeled and and successfully so because they're able to recommend stuff that I yeah but applying that to education",
    "start": "4439620",
    "end": "4446670"
  },
  {
    "text": "right there's no reason why it can't be done do you have a hope for our education system I have more hope for",
    "start": "4446670",
    "end": "4454320"
  },
  {
    "text": "workforce development and that's because I'm seeing investments even if you look",
    "start": "4454320",
    "end": "4460380"
  },
  {
    "text": "at VC investments in education the majority of it has lately been going to",
    "start": "4460380",
    "end": "4466350"
  },
  {
    "text": "workforce retraining right and so I think that government investments is",
    "start": "4466350",
    "end": "4472140"
  },
  {
    "text": "increasing there's like a claim and some of it's based on fear right like AI is gonna come and take over all these jobs",
    "start": "4472140",
    "end": "4477840"
  },
  {
    "text": "so what are we gonna do with all these non paying taxes that aren't coming to us by our citizens and so I think I'm",
    "start": "4477840",
    "end": "4485880"
  },
  {
    "text": "more hopeful for that not so hopeful for early education because it's this it's",
    "start": "4485880",
    "end": "4494490"
  },
  {
    "text": "still a who's gonna pay for it and you won't see the results for like 16 to 18",
    "start": "4494490",
    "end": "4502050"
  },
  {
    "text": "years it's hard for people to wrap their heads around that but on the retraining",
    "start": "4502050",
    "end": "4508500"
  },
  {
    "start": "4506000",
    "end": "4637000"
  },
  {
    "text": "part what are your thoughts there's a candidate andrew yang running for president and saying that sort of AI",
    "start": "4508500",
    "end": "4517410"
  },
  {
    "text": "automation robots universal basic income universal basic income in order to",
    "start": "4517410",
    "end": "4522540"
  },
  {
    "text": "support us as we kind of automation takes people's jobs and",
    "start": "4522540",
    "end": "4527600"
  },
  {
    "text": "to explore and find other means like you have a concern of society transforming",
    "start": "4527600",
    "end": "4536390"
  },
  {
    "text": "effects of automation and robots and so on I do I do know that AI robotics will",
    "start": "4536390",
    "end": "4544400"
  },
  {
    "text": "displace workers like we do know that but there'll be other workers that will",
    "start": "4544400",
    "end": "4550550"
  },
  {
    "text": "be defined new jobs what I worry about",
    "start": "4550550",
    "end": "4555620"
  },
  {
    "text": "is that's not what I worry about like we'll all the jobs go away what I worry about is the type of jobs that will come",
    "start": "4555620",
    "end": "4561560"
  },
  {
    "text": "out right like people who graduate from Georgia Tech will be okay right we give",
    "start": "4561560",
    "end": "4566780"
  },
  {
    "text": "them the skills they will adopt even if their current job goes away I do worry about those that don't have that quality",
    "start": "4566780",
    "end": "4574160"
  },
  {
    "text": "of an education right will they have the ability the background to adapt to those",
    "start": "4574160",
    "end": "4580370"
  },
  {
    "text": "new jobs that I don't know that I worry about which will convey even more",
    "start": "4580370",
    "end": "4586100"
  },
  {
    "text": "polarization in in our society internationally and everywhere I worry",
    "start": "4586100",
    "end": "4591590"
  },
  {
    "text": "about that I also worry about not having equal access to all these wonderful",
    "start": "4591590",
    "end": "4597860"
  },
  {
    "text": "things that AI can do and robotics can do I worry about that you know people",
    "start": "4597860",
    "end": "4603800"
  },
  {
    "text": "like people like me from Georgia Tech from say MIT will be okay right but",
    "start": "4603800",
    "end": "4610460"
  },
  {
    "text": "that's such a small part of the population that we need to think much more globally of having access to the",
    "start": "4610460",
    "end": "4617600"
  },
  {
    "text": "beautiful things whether it's AI and healthcare AI and education may ion and politics right I worry about and that's",
    "start": "4617600",
    "end": "4626300"
  },
  {
    "text": "part of the thing that you were talking about is people that build a technology had to be thinking about ethics have to",
    "start": "4626300",
    "end": "4632660"
  },
  {
    "text": "be thinking about access yeah and all those things and not not just a small small subset let me ask some",
    "start": "4632660",
    "end": "4638450"
  },
  {
    "start": "4637000",
    "end": "5101000"
  },
  {
    "text": "philosophical slightly romantic questions all right but they listen to this will be like here he goes again",
    "start": "4638450",
    "end": "4646100"
  },
  {
    "text": "okay do you think do you think one day we'll build an AI system that we a",
    "start": "4646100",
    "end": "4653470"
  },
  {
    "text": "person can fall in love with and it would love them back like in a movie her",
    "start": "4653470",
    "end": "4658970"
  },
  {
    "text": "for exam yeah although she she kind of didn't fall in love with him uh she fell in",
    "start": "4658970",
    "end": "4664190"
  },
  {
    "text": "love with like a million other people something like that so you're the jealous type I see we",
    "start": "4664190",
    "end": "4670010"
  },
  {
    "text": "humans at the judge yes so I do believe that we can design systems where people",
    "start": "4670010",
    "end": "4676610"
  },
  {
    "text": "would fall in love with their robot with their AI partner that I do believe",
    "start": "4676610",
    "end": "4684220"
  },
  {
    "text": "because it's actually and I won't I don't like to use the word manipulate but as we see there are certain",
    "start": "4684220",
    "end": "4691610"
  },
  {
    "text": "individuals that can be manipulated if you understand the cognitive science about it right alright so I mean if you could",
    "start": "4691610",
    "end": "4698240"
  },
  {
    "text": "think of all close relationship and love in general as a kind of mutual",
    "start": "4698240",
    "end": "4703300"
  },
  {
    "text": "manipulation that dance the human dance I mean many patients a negative",
    "start": "4703300",
    "end": "4708380"
  },
  {
    "text": "connotation and I don't like to use that word particularly I guess another way to",
    "start": "4708380",
    "end": "4713600"
  },
  {
    "text": "phrase is you're getting as it could be algorithmic eyes or something it could be the relationship building part can",
    "start": "4713600",
    "end": "4719840"
  },
  {
    "text": "yeah yeah I mean just think about it there we have and I don't use dating sites but from what I heard there are",
    "start": "4719840",
    "end": "4727880"
  },
  {
    "text": "some individuals that have been dating that have never saw each other right in",
    "start": "4727880",
    "end": "4732920"
  },
  {
    "text": "fact there's a show I think that tries to I weed out fake people like there's a",
    "start": "4732920",
    "end": "4737960"
  },
  {
    "text": "show that comes out right because like people start faking like what's the",
    "start": "4737960",
    "end": "4743240"
  },
  {
    "text": "difference of that person on the other end being an AI agent right and having a",
    "start": "4743240",
    "end": "4748640"
  },
  {
    "text": "communication are you building a relationship remotely like there there's no reason why that can't happen in terms",
    "start": "4748640",
    "end": "4756170"
  },
  {
    "text": "of human robot interaction was a what role you've kind of mentioned what data emotion being can be problematic if not",
    "start": "4756170",
    "end": "4764180"
  },
  {
    "text": "implemented well I suppose what role does emotion some other human-like things the imperfect things",
    "start": "4764180",
    "end": "4771470"
  },
  {
    "text": "come into play here for a good human robot interaction and something like love yes so in this case and you had",
    "start": "4771470",
    "end": "4779210"
  },
  {
    "text": "asked can i AI agent love a human back I think they can emulate love back right",
    "start": "4779210",
    "end": "4787190"
  },
  {
    "text": "and so what does that actually mean it just means that if you think about their programming they",
    "start": "4787190",
    "end": "4793010"
  },
  {
    "text": "might put the other person's needs in front of theirs and certain situations right you look at think about it as a",
    "start": "4793010",
    "end": "4799070"
  },
  {
    "text": "return on investment like was my return on investment as part of that equation that person's happiness you know has",
    "start": "4799070",
    "end": "4804710"
  },
  {
    "text": "some type of you know algorithm waiting to it and the reason why is because I",
    "start": "4804710",
    "end": "4809780"
  },
  {
    "text": "care about them right that's the only reason right but if I care about them and I show that then my final objective",
    "start": "4809780",
    "end": "4817520"
  },
  {
    "text": "function is length of time of the engagement right so you can think of how to do this actually quite easily and so",
    "start": "4817520",
    "end": "4824390"
  },
  {
    "text": "but that's not love well so that's the thing it I think it emulates love",
    "start": "4824390",
    "end": "4832000"
  },
  {
    "text": "because we don't have a classical definition of love right but",
    "start": "4832000",
    "end": "4839810"
  },
  {
    "text": "and we don't have the ability to look into each other's minds to see the algorithm and yeah I guess what I'm",
    "start": "4839810",
    "end": "4847850"
  },
  {
    "text": "getting at is is it possible that especially if that's learned especially if there's some mystery and black box",
    "start": "4847850",
    "end": "4853190"
  },
  {
    "text": "nature to the system how is that you know how is it any different I was any",
    "start": "4853190",
    "end": "4858980"
  },
  {
    "text": "different and in terms of sort of if the system says I'm cautious I'm afraid of death and it does indicate that it loves",
    "start": "4858980",
    "end": "4869660"
  },
  {
    "text": "you another way to sort of phrase I be curious to see what you think do you think there'll be a time when robots",
    "start": "4869660",
    "end": "4878120"
  },
  {
    "text": "should have rights you've kind of phrased the robot in a very roboticist way it's just a really good way but",
    "start": "4878120",
    "end": "4885380"
  },
  {
    "text": "saying okay well there's an objective function and I can see how you can create a compelling human robot",
    "start": "4885380",
    "end": "4891710"
  },
  {
    "text": "interaction experience that makes you believe that the robot cares for your needs and even something like loves you",
    "start": "4891710",
    "end": "4898340"
  },
  {
    "text": "but what if the robot says please don't turn me off what if the robot starts",
    "start": "4898340",
    "end": "4905030"
  },
  {
    "text": "making you feel like there's an entity of being a soul there all right do you",
    "start": "4905030",
    "end": "4910520"
  },
  {
    "text": "think there'll be a future hopefully you won't laugh too much of this but there",
    "start": "4910520",
    "end": "4916100"
  },
  {
    "text": "were there's they do ask for rights so I can see a future if we don't address it",
    "start": "4916100",
    "end": "4926720"
  },
  {
    "text": "in the near term where these agents as they adapt and learn could say hey this",
    "start": "4926720",
    "end": "4933410"
  },
  {
    "text": "should be something that's fundamental I hopefully think that we would address it",
    "start": "4933410",
    "end": "4938750"
  },
  {
    "text": "before it gets to that point you think so that you think that's a bad future is like what is that a negative thing where",
    "start": "4938750",
    "end": "4944540"
  },
  {
    "text": "they ask or being discriminated against I guess it depends on what role have",
    "start": "4944540",
    "end": "4951320"
  },
  {
    "text": "they attained at that point right and so if I think about now careful what you",
    "start": "4951320",
    "end": "4956450"
  },
  {
    "text": "say because the robots fifty years from when I'll be listening to this and you'll be on TV is saying this is what",
    "start": "4956450",
    "end": "4962570"
  },
  {
    "text": "roboticists used to believe and so this is my and as I said I have a bias lens",
    "start": "4962570",
    "end": "4968090"
  },
  {
    "text": "and my robot friends will understand that yes but so if you think about it",
    "start": "4968090",
    "end": "4973790"
  },
  {
    "text": "and I actually put this in kind of fee as a robot assists you don't necessarily",
    "start": "4973790",
    "end": "4980390"
  },
  {
    "text": "think of robots as human with human rights but you could think of them either in the category of property or",
    "start": "4980390",
    "end": "4989150"
  },
  {
    "text": "you can think of them in the category of animals right and so both of those have",
    "start": "4989150",
    "end": "4996080"
  },
  {
    "text": "different types of rights so animals have their own rights as as a living",
    "start": "4996080",
    "end": "5001810"
  },
  {
    "text": "being but you know they can't vote they can't write they can be euthanized but",
    "start": "5001810",
    "end": "5008290"
  },
  {
    "text": "as humans if we abuse them we go to jail like right so they do have some rights",
    "start": "5008290",
    "end": "5014260"
  },
  {
    "text": "that protect them but don't give them the rights of like citizenship and then",
    "start": "5014260",
    "end": "5020440"
  },
  {
    "text": "if you think about property property the rights are associated with the person right so if someone vandalizes your",
    "start": "5020440",
    "end": "5028420"
  },
  {
    "text": "property or steals your property like there are some rights but it's",
    "start": "5028420",
    "end": "5034150"
  },
  {
    "text": "associated with the person who owns that if you think about it back in the day",
    "start": "5034150",
    "end": "5041170"
  },
  {
    "text": "and if you remember we talked about you know how society has changed women were",
    "start": "5041170",
    "end": "5046690"
  },
  {
    "text": "property right they were not thought of as having rights they were thought of as",
    "start": "5046690",
    "end": "5052830"
  },
  {
    "text": "property of like their yeah salting a woman meant assaulting the property of",
    "start": "5052830",
    "end": "5058900"
  },
  {
    "text": "somebody else's butt exactly and so what I envision is is that we will establish some type of norm",
    "start": "5058900",
    "end": "5065949"
  },
  {
    "text": "at some point but that it might evolve right like if you look at women's rights now like there are some countries that",
    "start": "5065949",
    "end": "5074010"
  },
  {
    "text": "don't have and the rest of the world is like why that makes no sense right and",
    "start": "5074010",
    "end": "5079449"
  },
  {
    "text": "so I do see a world where we do establish some type of grounding it",
    "start": "5079449",
    "end": "5084639"
  },
  {
    "text": "might be based on property rights it might be based on animal rights and if it evolves that way I think we will have",
    "start": "5084639",
    "end": "5092979"
  },
  {
    "text": "this conversation at that time because that's the way our society traditionally has evolved beautifully puts just out of",
    "start": "5092979",
    "end": "5102280"
  },
  {
    "start": "5101000",
    "end": "5542000"
  },
  {
    "text": "curiosity at Anki geebo main field robotics within robot curious eye how it",
    "start": "5102280",
    "end": "5108789"
  },
  {
    "text": "works we think robotics were all these amazing robotics companies led created by incredible roboticists and they've",
    "start": "5108789",
    "end": "5117219"
  },
  {
    "text": "all went out of business recently why do you think they didn't last long",
    "start": "5117219",
    "end": "5123340"
  },
  {
    "text": "why is this so hard to run a robotics company especially one like these which",
    "start": "5123340",
    "end": "5129940"
  },
  {
    "text": "are fundamentally HR are HRI human robot interaction robots yeah one has a story",
    "start": "5129940",
    "end": "5138429"
  },
  {
    "text": "only one of them I don't understand and that was on key that's actually the only",
    "start": "5138429",
    "end": "5143739"
  },
  {
    "text": "one I don't understand I don't understand either it's you know I mean I looked like from the outside you know",
    "start": "5143739",
    "end": "5148989"
  },
  {
    "text": "I've looked at their sheets I've looked like the data that's oh you mean like business-wise yeah yeah and like I look",
    "start": "5148989",
    "end": "5157360"
  },
  {
    "text": "at all I look at that data and I'm like they seem to have like product market fit like so that's the only one I don't",
    "start": "5157360",
    "end": "5164949"
  },
  {
    "text": "understand the rest of it was product market fit what's product market feel if it just",
    "start": "5164949",
    "end": "5170110"
  },
  {
    "text": "just that how do you think about it yes so although we rethink robotics was getting there right but I think it's",
    "start": "5170110",
    "end": "5176349"
  },
  {
    "text": "just the timing it just they're the clock just timed out I think if they had been given a couple more years if they",
    "start": "5176349",
    "end": "5183249"
  },
  {
    "text": "would have been okay but the other ones were still fairly early by the time they",
    "start": "5183249",
    "end": "5189219"
  },
  {
    "text": "got into the market and so product market fit is I have a product that I want to sell at a certain price",
    "start": "5189219",
    "end": "5196539"
  },
  {
    "text": "are there enough people out there the market that are willing to buy the product at that market price for me to",
    "start": "5196539",
    "end": "5203229"
  },
  {
    "text": "be a functional viable profit bearing company right so product market fit if",
    "start": "5203229",
    "end": "5210519"
  },
  {
    "text": "it costs you a thousand dollars and everyone wants it and only is willing to",
    "start": "5210519",
    "end": "5216130"
  },
  {
    "text": "pay a dollar you have no product market fit even if you could sell it for you know it's enough for a dollar because",
    "start": "5216130",
    "end": "5223150"
  },
  {
    "text": "you can't you so hard is it for robots sort of maybe if you look at iRobot the company that makes Roomba vacuum",
    "start": "5223150",
    "end": "5229150"
  },
  {
    "text": "cleaners can you comment on did they find the right product market product",
    "start": "5229150",
    "end": "5234789"
  },
  {
    "text": "fit or like are people willing to pay for robots is also another kind of question about iRobot in their story",
    "start": "5234789",
    "end": "5242550"
  },
  {
    "text": "right like when they first they had enough of a runway right when they first",
    "start": "5242550",
    "end": "5249249"
  },
  {
    "text": "started they weren't doing vacuum cleaners right they were a military contracts primarily government contracts",
    "start": "5249249",
    "end": "5256419"
  },
  {
    "text": "designing robots yeah I mean that's what they were that's how they started right and they still do a lot of incredible",
    "start": "5256419",
    "end": "5262360"
  },
  {
    "text": "work there but yeah that was the initial thing that gave him enough funding to then try to the vacuum cleaner is what",
    "start": "5262360",
    "end": "5270010"
  },
  {
    "text": "I've been told was not like their first rendezvous in terms of designing a",
    "start": "5270010",
    "end": "5275199"
  },
  {
    "text": "product right and so they they were able to survive until they got to the point",
    "start": "5275199",
    "end": "5280479"
  },
  {
    "text": "that they found a a product price market right and even with if you look at the",
    "start": "5280479",
    "end": "5287619"
  },
  {
    "text": "the Roomba the price point now is different than when it was first released right it was an early adopter",
    "start": "5287619",
    "end": "5292989"
  },
  {
    "text": "price but they found enough people who were willing to defend it and I mean though you know I forgot what their loss",
    "start": "5292989",
    "end": "5299530"
  },
  {
    "text": "profile was for the first couple of you know years but they became profitable in sufficient time that they didn't have to",
    "start": "5299530",
    "end": "5306999"
  },
  {
    "text": "close the doors so they found the right there's still there's still people willing to pay a large amount of money",
    "start": "5306999",
    "end": "5312669"
  },
  {
    "text": "so or a thousand dollars for for vacuum cleaner unfortunately for them now that",
    "start": "5312669",
    "end": "5317979"
  },
  {
    "text": "they've proved everything out figured it all out the other side yeah and so that's that's the next thing right the",
    "start": "5317979",
    "end": "5323699"
  },
  {
    "text": "competition and they have quite a number even like there's some some products out",
    "start": "5323699",
    "end": "5329800"
  },
  {
    "text": "there you can go to you know you're up and be like oh I didn't even know this one existed so so this is the thing",
    "start": "5329800",
    "end": "5336249"
  },
  {
    "text": "though like with any market I I would this is not a bad time although you know",
    "start": "5336249",
    "end": "5344260"
  },
  {
    "text": "as a roboticist its kind of depressing but I actually think about things like",
    "start": "5344260",
    "end": "5349570"
  },
  {
    "text": "with the I would say that all of the companies that are now in the top five or six they weren't the first to the",
    "start": "5349570",
    "end": "5358239"
  },
  {
    "text": "stage right like Google was not the first search engine sorry Alta Vista right Facebook was not",
    "start": "5358239",
    "end": "5365979"
  },
  {
    "text": "the first sorry myspace right like think about it they were not the first players those first players like they're not in",
    "start": "5365979",
    "end": "5374559"
  },
  {
    "text": "the top five ten no fortune 500 companies right they proved they started",
    "start": "5374559",
    "end": "5382269"
  },
  {
    "text": "to prove out the market they started to get people interested they started the buzz but they didn't make it to that",
    "start": "5382269",
    "end": "5389469"
  },
  {
    "text": "next level but the second match right the second batch I think might make it",
    "start": "5389469",
    "end": "5396309"
  },
  {
    "text": "to the next level do you when do you think the the Facebook of Roja the",
    "start": "5396309",
    "end": "5402519"
  },
  {
    "text": "Facebook of Robotics sorry take that phrase back because people deeply for",
    "start": "5402519",
    "end": "5408820"
  },
  {
    "text": "some reason I know why but it's I think exaggerated distrust Facebook because of",
    "start": "5408820",
    "end": "5414190"
  },
  {
    "text": "the privacy concerns and so on and with robotics one of the things you have to make sure all the things we've talked",
    "start": "5414190",
    "end": "5419409"
  },
  {
    "text": "about is to be transparent and have people deeply trust you to let it well robot into their lives into their home",
    "start": "5419409",
    "end": "5425619"
  },
  {
    "text": "what do you think the second batch of robots local is it five ten years twenty",
    "start": "5425619",
    "end": "5431139"
  },
  {
    "text": "years that will have robots in our homes and robots in our hearts so if I think",
    "start": "5431139",
    "end": "5437050"
  },
  {
    "text": "about and because I try to follow the the VC kind of space in terms of robotic investments and right now I don't know",
    "start": "5437050",
    "end": "5444969"
  },
  {
    "text": "if they're gonna be successful I don't know if this is the second batch but there's only one batch that's focused on",
    "start": "5444969",
    "end": "5451179"
  },
  {
    "text": "like the first batch right and then there's all these self-driving X's right and so I don't know if they're a first",
    "start": "5451179",
    "end": "5458739"
  },
  {
    "text": "batch of something or if I like I don't know quite where they fit in but there's a number of companies the",
    "start": "5458739",
    "end": "5465850"
  },
  {
    "text": "co robot I'll call them Co robots that are still getting VC investments they",
    "start": "5465850",
    "end": "5472510"
  },
  {
    "text": "some of them have some of the flavor of like rethink robotics some of them have some of the flavor like hurry",
    "start": "5472510",
    "end": "5478930"
  },
  {
    "text": "what's a col robot of course so basically a robot in human working in",
    "start": "5478930",
    "end": "5484780"
  },
  {
    "text": "the same space so some of the companies are focused on manufacturing so having a",
    "start": "5484780",
    "end": "5491650"
  },
  {
    "text": "robot and human working together in a factory some of these Co robots are",
    "start": "5491650",
    "end": "5498300"
  },
  {
    "text": "robots and humans working in the home working in clinics like there's different versions of these companies in",
    "start": "5498300",
    "end": "5504130"
  },
  {
    "text": "terms of their products but they're all so rethink robotics would be like one of",
    "start": "5504130",
    "end": "5509290"
  },
  {
    "text": "the first at least well known companies focus on this space so I don't know if",
    "start": "5509290",
    "end": "5515140"
  },
  {
    "text": "this second if this is a second batch or if this is still part of the first batch",
    "start": "5515140",
    "end": "5520840"
  },
  {
    "text": "that I don't know and then you have all these other companies in this self-driving you know space and I don't",
    "start": "5520840",
    "end": "5527200"
  },
  {
    "text": "know if that's a first batch or again a second batch yeah so there's a lot of",
    "start": "5527200",
    "end": "5532660"
  },
  {
    "text": "mystery about this now of course it's hard to say that this is the second batch until it you know approves",
    "start": "5532660",
    "end": "5537970"
  },
  {
    "text": "outright correct exactly yeah we need a unicorn yeah exactly the why do you think people are so",
    "start": "5537970",
    "end": "5545290"
  },
  {
    "start": "5542000",
    "end": "5657000"
  },
  {
    "text": "afraid at least in popular culture of legged robots like those work than",
    "start": "5545290",
    "end": "5551380"
  },
  {
    "text": "Boston Dynamics or just robotics in general if you were to psychoanalyze that fear what do you make of it and",
    "start": "5551380",
    "end": "5558100"
  },
  {
    "text": "should they be afraid sorry so should people be afraid I don't think people should be afraid but with a caveat I",
    "start": "5558100",
    "end": "5565450"
  },
  {
    "text": "don't think people should be afraid given that most of us in this world",
    "start": "5565450",
    "end": "5571110"
  },
  {
    "text": "understand that we need to change something right so given that now things",
    "start": "5571110",
    "end": "5578650"
  },
  {
    "text": "don't change be very afraid what which is the dimension of change",
    "start": "5578650",
    "end": "5583900"
  },
  {
    "text": "that's needed so changing of thinking about the ramifications thinking about like the ethics thinking about like the",
    "start": "5583900",
    "end": "5590560"
  },
  {
    "text": "conversation is going on right it's not it's no longer a we're gonna deploy it and forget that",
    "start": "5590560",
    "end": "5596500"
  },
  {
    "text": "you know this is a car that can kill pedestrians that are walking across the street right it's we're not in that",
    "start": "5596500",
    "end": "5603099"
  },
  {
    "text": "stage where a we're putting these roads out there are people out there yes a car could be a weapon like people are now",
    "start": "5603099",
    "end": "5610630"
  },
  {
    "text": "solutions aren't there yet but people are thinking about this as we need to be",
    "start": "5610630",
    "end": "5616540"
  },
  {
    "text": "ethically responsible as we send these systems out robotics medical",
    "start": "5616540",
    "end": "5621820"
  },
  {
    "text": "self-driving and military - and Miller and military just not as often talked about but it's really we're probably",
    "start": "5621820",
    "end": "5628800"
  },
  {
    "text": "these robots will have a significant impact as well correct correct right making sure that they can think",
    "start": "5628800",
    "end": "5635880"
  },
  {
    "text": "rationally even having the conversations who should pull the trigger right but",
    "start": "5635880",
    "end": "5641440"
  },
  {
    "text": "overall you're saying if we start to think more and more as a community about these ethical issues people should not be afraid yeah I don't think people",
    "start": "5641440",
    "end": "5648070"
  },
  {
    "text": "should be afraid I think that the return on investment the impact positive impact will outweigh any of the potentially",
    "start": "5648070",
    "end": "5655989"
  },
  {
    "text": "negative impacts do you have worries of existential threats of robots or AI that some people",
    "start": "5655989",
    "end": "5663520"
  },
  {
    "start": "5657000",
    "end": "5757000"
  },
  {
    "text": "kind of talk about and romanticize about and then you know in those decade in the",
    "start": "5663520",
    "end": "5668920"
  },
  {
    "text": "next few decades no I don't singularity will be an example so my concept is is",
    "start": "5668920",
    "end": "5675309"
  },
  {
    "text": "that so remember robots AI is designed by people yes it has our values and I",
    "start": "5675309",
    "end": "5681670"
  },
  {
    "text": "always correlate this with a parent and a child all right so think about it as a parent would we want we want our kids to have a",
    "start": "5681670",
    "end": "5689050"
  },
  {
    "text": "better life than us we want them to expand we want them to experience the",
    "start": "5689050",
    "end": "5694989"
  },
  {
    "text": "world and then as we grow older our kids think and know they're smarter and",
    "start": "5694989",
    "end": "5700929"
  },
  {
    "text": "better and more intelligent and have better opportunities and they may even",
    "start": "5700929",
    "end": "5706389"
  },
  {
    "text": "stop listening to us they don't go out and then kill us right like think about it it's because we it's instilled in",
    "start": "5706389",
    "end": "5713440"
  },
  {
    "text": "them values we instilled in them this whole aspect of community and yes even",
    "start": "5713440",
    "end": "5718510"
  },
  {
    "text": "though you're maybe smarter and more have more money and data it's still about this love caring relationship and",
    "start": "5718510",
    "end": "5727270"
  },
  {
    "text": "so that's what I believe so even like you know we've created the singularity and some archaic system back",
    "start": "5727270",
    "end": "5732550"
  },
  {
    "text": "in like 1980 that suddenly evolves the fact is it might say I am smarter I am",
    "start": "5732550",
    "end": "5738670"
  },
  {
    "text": "sentient these humans are really stupid but I think it'll be like yeah but I",
    "start": "5738670",
    "end": "5746440"
  },
  {
    "text": "just can't destroy that yeah for sentimental value it's still just for to",
    "start": "5746440",
    "end": "5751690"
  },
  {
    "text": "come back for Thanksgiving dinner every once in a while exactly this so beautifully put you've you've also said",
    "start": "5751690",
    "end": "5758739"
  },
  {
    "start": "5757000",
    "end": "5857000"
  },
  {
    "text": "that the matrix may be one of your more favorite AI related movies can you",
    "start": "5758739",
    "end": "5764020"
  },
  {
    "text": "elaborate why yeah it is one of my favorite movies and it's because it",
    "start": "5764020",
    "end": "5769380"
  },
  {
    "text": "represents kind of all the things I think about so there's a symbiotic",
    "start": "5769380",
    "end": "5774969"
  },
  {
    "text": "relationship between robots and humans right that symbiotic relationship is",
    "start": "5774969",
    "end": "5781420"
  },
  {
    "text": "that they don't destroy us they enslave us right but think about it even though",
    "start": "5781420",
    "end": "5788409"
  },
  {
    "text": "they enslaved us they needed us to be happy right and in order to be happy",
    "start": "5788409",
    "end": "5793840"
  },
  {
    "text": "they had to create this Kruti world that they then had to live in right that's the whole but then there were humans",
    "start": "5793840",
    "end": "5801610"
  },
  {
    "text": "that had a choice wait like you had a choice to stay in this horrific horrific",
    "start": "5801610",
    "end": "5807760"
  },
  {
    "text": "world where it was your fantasy and life with all of the anomalies perfection but",
    "start": "5807760",
    "end": "5813309"
  },
  {
    "text": "not accurate or you can choose to be on your own and like have maybe no food for",
    "start": "5813309",
    "end": "5820840"
  },
  {
    "text": "a couple of days but you were totally autonomous and so I think of that as and",
    "start": "5820840",
    "end": "5827289"
  },
  {
    "text": "that's why so it's not necessarily us being enslaved but I think about us having this symbiotic relationship",
    "start": "5827289",
    "end": "5832570"
  },
  {
    "text": "robots and AI even if they become sentient they're still part of our society and they will suffer just as",
    "start": "5832570",
    "end": "5839079"
  },
  {
    "text": "much as us and there there will be some kind of equilibrium that we'll have to",
    "start": "5839079",
    "end": "5844300"
  },
  {
    "text": "find some somebody out of relationship and then you have the ethicist the robotics folks that like no this has got",
    "start": "5844300",
    "end": "5851440"
  },
  {
    "text": "to stop I will take the other peel yeah in order to make a difference so if you",
    "start": "5851440",
    "end": "5857739"
  },
  {
    "start": "5857000",
    "end": "5997000"
  },
  {
    "text": "could hang out for a day with a robot real from fiction movies books safely and get to",
    "start": "5857739",
    "end": "5865810"
  },
  {
    "text": "pick his or her there brain who would you pick gotta say it's data data I was",
    "start": "5865810",
    "end": "5879610"
  },
  {
    "text": "gonna say Rosie but I don't I'm not really interested in her brain hmm I'm interested in data's brain data pre or",
    "start": "5879610",
    "end": "5887500"
  },
  {
    "text": "post emotion ship pre but don't you",
    "start": "5887500",
    "end": "5893740"
  },
  {
    "text": "think it'd be a more interesting conversation post emotion ship yeah it would be drama and I you know I'm human",
    "start": "5893740",
    "end": "5899860"
  },
  {
    "text": "I deal with drama all the time yeah but the reason why I went to pick data's",
    "start": "5899860",
    "end": "5904870"
  },
  {
    "text": "brain is because I I could have a conversation with him and ask for",
    "start": "5904870",
    "end": "5911530"
  },
  {
    "text": "example how can we fix this ethics problem right and he could go through",
    "start": "5911530",
    "end": "5916870"
  },
  {
    "text": "like the rational thinking and through that he'd also help me think through it",
    "start": "5916870",
    "end": "5922420"
  },
  {
    "text": "as well and so that's there's like these questions fundamental questions I think I can ask him that he would help me also",
    "start": "5922420",
    "end": "5929080"
  },
  {
    "text": "learn from and that fascinates me I don't think there's a better place to",
    "start": "5929080",
    "end": "5935470"
  },
  {
    "text": "end it thank you so much for talking I was an honor thank you thank you this was fun thanks for listening to this",
    "start": "5935470",
    "end": "5942160"
  },
  {
    "text": "conversation and thank you to our presenting sponsor cash app downloaded use code Lex podcast you'll get ten",
    "start": "5942160",
    "end": "5949660"
  },
  {
    "text": "dollars and ten dollars will go to first a stem education nonprofit that inspires hundreds of thousands of young minds to",
    "start": "5949660",
    "end": "5956470"
  },
  {
    "text": "become future leaders and innovators if you enjoy this podcast subscribe my youtube give it five stars an apple",
    "start": "5956470",
    "end": "5963160"
  },
  {
    "text": "podcast follow on Spotify supported on patreon or simply connect with me on Twitter",
    "start": "5963160",
    "end": "5969670"
  },
  {
    "text": "and now let me leave you with some words of wisdom from arthur c clarke whether",
    "start": "5969670",
    "end": "5975430"
  },
  {
    "text": "we are based on carbon quan silicon makes no fundamental difference which",
    "start": "5975430",
    "end": "5980740"
  },
  {
    "text": "should each be treated with appropriate respect thank you for listening and hope",
    "start": "5980740",
    "end": "5986110"
  },
  {
    "text": "to see you next time",
    "start": "5986110",
    "end": "5989429"
  },
  {
    "text": "you",
    "start": "5994489",
    "end": "5996550"
  }
]
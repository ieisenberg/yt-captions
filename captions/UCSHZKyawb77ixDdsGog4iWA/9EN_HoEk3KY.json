[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "welcome back to 6 SZ row 99 artificial general intelligence today we have Ilya",
    "start": "30",
    "end": "5940"
  },
  {
    "text": "sutskever co-founder and research",
    "start": "5940",
    "end": "11820"
  },
  {
    "text": "director of open AI he started in the amel group in Toronto Geoffrey Hinton then at Stanford with an jiaying",
    "start": "11820",
    "end": "18690"
  },
  {
    "text": "co-founded DNN research for three years as a research scientist at Google brain and finally co-founded open AI citations",
    "start": "18690",
    "end": "27000"
  },
  {
    "text": "aren't everything but they do indicate impact and his work recent work in the past five years has",
    "start": "27000",
    "end": "35100"
  },
  {
    "text": "been cited over forty six thousand times he has been the key creative intellect",
    "start": "35100",
    "end": "42000"
  },
  {
    "text": "and driver behind some of the biggest breakthrough ideas in deep learning and artificial intelligence ever",
    "start": "42000",
    "end": "48899"
  },
  {
    "text": "so please welcome Ilya alright thanks",
    "start": "48899",
    "end": "59940"
  },
  {
    "start": "55000",
    "end": "2584000"
  },
  {
    "text": "for the introduction Lex alright thanks for coming to my talk I will tell you about some work we've done",
    "start": "59940",
    "end": "66150"
  },
  {
    "text": "over the past year on on meta learning and software open AI and before I dive",
    "start": "66150",
    "end": "72930"
  },
  {
    "text": "into some of the more technical details of the work I want to spend a little bit",
    "start": "72930",
    "end": "78240"
  },
  {
    "text": "of time talking about deep learning and why it works at all in the first place",
    "start": "78240",
    "end": "85140"
  },
  {
    "text": "which I think it's actually not a self-evident saying that they should work one fact it's actually a fact it's",
    "start": "85140",
    "end": "95430"
  },
  {
    "text": "a mathematical theory that you can prove is that if you could find the shortest",
    "start": "95430",
    "end": "102150"
  },
  {
    "text": "program the does very very well on your data then you will achieve the best",
    "start": "102150",
    "end": "108329"
  },
  {
    "text": "generalization possible with a little bit of modification you can turn it into a precise theorem",
    "start": "108329",
    "end": "114060"
  },
  {
    "text": "and on a very intuitive level it's easy to see what it should be the case if you",
    "start": "114060",
    "end": "121140"
  },
  {
    "text": "have some data and you're able to find a shorter program which generates this",
    "start": "121140",
    "end": "126630"
  },
  {
    "text": "data then you've essentially extracted all the all conceivable regularity from",
    "start": "126630",
    "end": "131730"
  },
  {
    "text": "this data into your program and then you can use these objects to make the best predictions possible like if if you have",
    "start": "131730",
    "end": "139890"
  },
  {
    "text": "data which is so complex but there is no way to express it as a shorter program",
    "start": "139890",
    "end": "145380"
  },
  {
    "text": "then it means that your data is totally random there is no way to extract any regularity from it whatsoever now there",
    "start": "145380",
    "end": "152670"
  },
  {
    "text": "is little known mathematical theory behind this and the proofs of these statements actually not even that hard",
    "start": "152670",
    "end": "158300"
  },
  {
    "text": "but the one minor slight disappointment is that it's actually not possible at",
    "start": "158300",
    "end": "164220"
  },
  {
    "text": "least given today's tools and understanding to find the best short program that explains or generates or",
    "start": "164220",
    "end": "172620"
  },
  {
    "text": "solves your problem given your data this problem is computationally intractable",
    "start": "172620",
    "end": "178519"
  },
  {
    "text": "the space of all programs is a very nasty space small changes to your",
    "start": "178519",
    "end": "184799"
  },
  {
    "text": "program result in massive changes in the behavior of the program as it should be it makes sense you have a loop you",
    "start": "184799",
    "end": "191310"
  },
  {
    "text": "change the inside of the loop of course you get something totally different so the space of programs is so hard at",
    "start": "191310",
    "end": "197970"
  },
  {
    "text": "least given what we know today search there seems to be completely off the table well if we give up on shorts on",
    "start": "197970",
    "end": "207690"
  },
  {
    "text": "short programs what about small circuits well it turns out that we are lucky it",
    "start": "207690",
    "end": "214650"
  },
  {
    "text": "turns out that when it comes to small circuits you can just find the best small circuits circuits that solves the",
    "start": "214650",
    "end": "220650"
  },
  {
    "text": "problem using back propagation and this is the miraculous fact on which the rest",
    "start": "220650",
    "end": "227700"
  },
  {
    "text": "of AI stands it is the fact but then you have a circuit and you impose",
    "start": "227700",
    "end": "232769"
  },
  {
    "text": "constraints on your circuits on your circuit using data you can find the way",
    "start": "232769",
    "end": "238380"
  },
  {
    "text": "to satisfy these constraints these constraints using that problem by iteratively making small changes",
    "start": "238380",
    "end": "245360"
  },
  {
    "text": "to the base of your neural network until its predictions satisfy the data what",
    "start": "245360",
    "end": "253190"
  },
  {
    "text": "this means is that the computational problem that so the back propagation is extremely profound it is circuit search",
    "start": "253190",
    "end": "260440"
  },
  {
    "text": "now we know that you can solve it solve it always but you can solve it sometimes",
    "start": "260440",
    "end": "265670"
  },
  {
    "text": "and you can solve it at those times where we have a practical data set it is",
    "start": "265670",
    "end": "272390"
  },
  {
    "text": "easy to design artificial data sets for which you cannot find the best neural network but in practice that seems to be",
    "start": "272390",
    "end": "278450"
  },
  {
    "text": "not a problem you can think of training a neural network as solving a neural",
    "start": "278450",
    "end": "283610"
  },
  {
    "text": "equation in many cases where you have a large number of equation terms like this",
    "start": "283610",
    "end": "290150"
  },
  {
    "text": "f of X I theta equals y I so you got your parameters and they represent all your degrees of freedom and you use",
    "start": "290150",
    "end": "298790"
  },
  {
    "text": "gradient descent to push the information from these equations into the parameters satisfy them all and you can see that",
    "start": "298790",
    "end": "306530"
  },
  {
    "text": "the neural network let's say one with 50 layers is basically a parallel computer",
    "start": "306530",
    "end": "313030"
  },
  {
    "text": "that is given 50 time steps to run and you can do quite a lot with a 15 with 50",
    "start": "313030",
    "end": "319280"
  },
  {
    "text": "time steps of a very very powerful massively parallel computer so for example I do I think it is not widely",
    "start": "319280",
    "end": "327770"
  },
  {
    "text": "known that you can learn to sort sort n",
    "start": "327770",
    "end": "333830"
  },
  {
    "text": "n bit numbers using a modestly sized neural network with just two hidden",
    "start": "333830",
    "end": "338960"
  },
  {
    "text": "layers which is not bad it's not self-evident especially since we've been",
    "start": "338960",
    "end": "345740"
  },
  {
    "text": "taught that sorting requires log n parallel steps with the neural network you can sort successful using only two",
    "start": "345740",
    "end": "353180"
  },
  {
    "text": "parallel steps so there's some things like an arm is going on now these are",
    "start": "353180",
    "end": "358820"
  },
  {
    "text": "parallel steps of threshold threshold neurons so they're doing a little bit more work let's answer to the mystery",
    "start": "358820",
    "end": "364100"
  },
  {
    "text": "but if you've got 50 such layers you can do quite a bit of logic quite a bit of reasoning all inside the neural network",
    "start": "364100",
    "end": "369500"
  },
  {
    "text": "and that's why it works given the data we are able to find the",
    "start": "369500",
    "end": "375550"
  },
  {
    "text": "best neural network and because the neural network is deep because it can run computation inside of its act inside",
    "start": "375550",
    "end": "381310"
  },
  {
    "text": "of its layers the best neural network is worth finding because that's really what",
    "start": "381310",
    "end": "386409"
  },
  {
    "text": "you need you need something you need the model class which is worth optimizing",
    "start": "386409",
    "end": "392520"
  },
  {
    "text": "but it also needs to be optimizable and deep neural networks satisfy both of these constraints and this is why",
    "start": "392520",
    "end": "399849"
  },
  {
    "text": "everything works this is the basis on which everything else resides now I want",
    "start": "399849",
    "end": "405699"
  },
  {
    "text": "to talk a little bit about reinforcement learning so reinforcement learning is a framework it's a framework of evaluating",
    "start": "405699",
    "end": "413159"
  },
  {
    "text": "agents in their ability to achieve goals and complicated stochastic environments",
    "start": "413159",
    "end": "418380"
  },
  {
    "text": "you've got an agent which is plugged into an environment as shown in the figure right here and for any given",
    "start": "418380",
    "end": "426639"
  },
  {
    "text": "agent you can simply run it many times and compute its average reward now the",
    "start": "426639",
    "end": "433360"
  },
  {
    "text": "thing that's interesting about the reinforcement learning framework is that there exist interesting useful",
    "start": "433360",
    "end": "440110"
  },
  {
    "text": "reinforcement learning algorithms the framework existed for a long time it",
    "start": "440110",
    "end": "445330"
  },
  {
    "text": "became interesting once we realized that good algorithms exist now these are there are perfect algorithms but they",
    "start": "445330",
    "end": "451150"
  },
  {
    "text": "are good enough to do interesting things and all you want the mathematical",
    "start": "451150",
    "end": "457210"
  },
  {
    "text": "problem is one where you need to maximize the expected reward now one",
    "start": "457210",
    "end": "464169"
  },
  {
    "text": "important way in which the reinforcement learning framework is not quite complete is that it assumes that the reward is",
    "start": "464169",
    "end": "470529"
  },
  {
    "text": "given by the environment you see this picture the agent sends an action while",
    "start": "470529",
    "end": "476169"
  },
  {
    "text": "the reward sends it an observation in a both the observation and the reward backwards that's what the environment",
    "start": "476169",
    "end": "481990"
  },
  {
    "text": "communicates back the way in which this is not the case in the real world is that we figure out",
    "start": "481990",
    "end": "491449"
  },
  {
    "text": "what the reward is from the observation we reward ourselves we are not told",
    "start": "491449",
    "end": "496669"
  },
  {
    "text": "environment doesn't say hey here's some negative reward it's our interpretation over census that lets us determine what",
    "start": "496669",
    "end": "503630"
  },
  {
    "text": "the reward is and there is only one real true reward in life and this is",
    "start": "503630",
    "end": "508669"
  },
  {
    "text": "existence or nonexistence and everything else is a corollary of that so well what",
    "start": "508669",
    "end": "515959"
  },
  {
    "text": "should our agent be you already know the answer should be a neural network because whenever you want to do",
    "start": "515959",
    "end": "521510"
  },
  {
    "text": "something dense it's going to be a neural network and you want the agent to map observations to actions so you let",
    "start": "521510",
    "end": "527660"
  },
  {
    "text": "it be parametrized with a neural net and you apply learning algorithm so I want to explain to you how reinforcement",
    "start": "527660",
    "end": "533300"
  },
  {
    "text": "learning works this is model free reinforcement learning the reinforcement learning has actually been used in practice everywhere but it's also deeply",
    "start": "533300",
    "end": "542570"
  },
  {
    "text": "it's very robust it's very simple it's also not very efficient so the way it",
    "start": "542570",
    "end": "548000"
  },
  {
    "text": "works is the following this is literally the one sentence description of what happens in short try something new add",
    "start": "548000",
    "end": "557709"
  },
  {
    "text": "randomness directions and compare the result to your expectation if the result",
    "start": "557709",
    "end": "565670"
  },
  {
    "text": "surprises you if you find that the results exceeded your expectation then",
    "start": "565670",
    "end": "571580"
  },
  {
    "text": "change your parameters to take those actions in the future that's it this is",
    "start": "571580",
    "end": "576830"
  },
  {
    "text": "the fool idea of reinforcement learning try it out see if you like it and if you do do more of that in the future and",
    "start": "576830",
    "end": "584260"
  },
  {
    "text": "that's it that's literally it this is the core idea now it turns out it's not",
    "start": "584260",
    "end": "589790"
  },
  {
    "text": "difficult to formalize mathematically but this is really what's going on if in a neural network in a regular neural network like this you might say",
    "start": "589790",
    "end": "597680"
  },
  {
    "text": "okay what's the goal you run the neural network you get an answer you compare it to the desired",
    "start": "597680",
    "end": "603800"
  },
  {
    "text": "answer and whatever difference you have between those two you send it back to change the neural network that's",
    "start": "603800",
    "end": "610720"
  },
  {
    "text": "supervised line in reinforcement learning you run in your own network you add a bit of randomness to your action",
    "start": "610720",
    "end": "616270"
  },
  {
    "text": "and then if you like the result your randomness turns into the desired target",
    "start": "616270",
    "end": "621550"
  },
  {
    "text": "in effect so that's it trivial now math",
    "start": "621550",
    "end": "629589"
  },
  {
    "text": "exists without explaining what these equations mean the point is not really",
    "start": "629589",
    "end": "636520"
  },
  {
    "text": "to derive them but just to show that they exist there are two classes of reinforcement learning algorithms one of",
    "start": "636520",
    "end": "642850"
  },
  {
    "text": "them is the policy gradient where basically what you do is that you take this expression right there the sum of",
    "start": "642850",
    "end": "649390"
  },
  {
    "text": "expected we work the sum of rewards and it just crunched through the derivatives you expand the terms iran you do some",
    "start": "649390",
    "end": "656620"
  },
  {
    "text": "algebra and you get a derivative and miraculously the derivative has exactly",
    "start": "656620",
    "end": "663550"
  },
  {
    "text": "the form that i told you which is try some actions and if you like them",
    "start": "663550",
    "end": "669970"
  },
  {
    "text": "increase the log probability of the actions that we truly follows from the math it's very nice when the intuitive",
    "start": "669970",
    "end": "675610"
  },
  {
    "text": "explanation has a one-to-one correspondence to what you get in the equation even though you have to take my",
    "start": "675610",
    "end": "681370"
  },
  {
    "text": "word for it if you are not familiar with it that's that equation at the top now there is a different class of",
    "start": "681370",
    "end": "687190"
  },
  {
    "text": "reinforcement learning algorithms which is a little bit more difficult to explain it's called the Q learning based algorithms they are a bit less stable a",
    "start": "687190",
    "end": "694649"
  },
  {
    "text": "bit more sample efficient and it has the property that it can learn not only from",
    "start": "694649",
    "end": "703320"
  },
  {
    "text": "the data generated by the actor but from any other data as well so it has it has",
    "start": "703320",
    "end": "708430"
  },
  {
    "text": "some rope but it has different robustness profile which would be a little bit important but it's only going",
    "start": "708430",
    "end": "713860"
  },
  {
    "text": "to be a technicality so yeah this is the own policy of policy distinction but",
    "start": "713860",
    "end": "719410"
  },
  {
    "text": "it's a little bit technical so if you find this hard to understand don't worry about it if you already know this then",
    "start": "719410",
    "end": "725350"
  },
  {
    "text": "you already know it so now what's the potential for enforcement learning wasn't it promised what is it actually",
    "start": "725350",
    "end": "732570"
  },
  {
    "text": "why should we be excited about it now there are two reasons the reinforcement learning algorithms of",
    "start": "732570",
    "end": "738970"
  },
  {
    "text": "today already useful and interesting and especially if you have a really good",
    "start": "738970",
    "end": "744610"
  },
  {
    "text": "simulation of your world you could train agents to do lots of interesting things",
    "start": "744610",
    "end": "750240"
  },
  {
    "text": "but what's really exciting is if you can build a super amazing sample efficient",
    "start": "750300",
    "end": "755680"
  },
  {
    "text": "out of reinforcement learning algorithm we just give it a tiny amount of data and the algorithm just crunches through",
    "start": "755680",
    "end": "761260"
  },
  {
    "text": "it and extracts every bit of entropy out of it in order to learn in the fastest way possible now today our algorithms",
    "start": "761260",
    "end": "768880"
  },
  {
    "text": "are not particularly efficient they are data inefficient but as our field keeps",
    "start": "768880",
    "end": "774100"
  },
  {
    "text": "making progress this will change next I want to dive into the topic of meta",
    "start": "774100",
    "end": "779890"
  },
  {
    "text": "learning the goal of meta learning so meta learning is a beautiful idea that",
    "start": "779890",
    "end": "787150"
  },
  {
    "text": "doesn't really work but it kind of works and it's really promising too it's another promising idea so what's the",
    "start": "787150",
    "end": "794950"
  },
  {
    "text": "dream we have some learning algorithms perhaps you could use those learning",
    "start": "794950",
    "end": "800590"
  },
  {
    "text": "algorithms in order to learn to learn I'd be nice if we could learn to learn",
    "start": "800590",
    "end": "805890"
  },
  {
    "text": "so how would you do that you will take a system which you train it not on one",
    "start": "805890",
    "end": "814240"
  },
  {
    "text": "task but on many tasks and you ask you that it learns to solve these tasks quickly and that may actually be enough",
    "start": "814240",
    "end": "821580"
  },
  {
    "text": "so here's how it looks like here's how most traditional metal earning look works like it looks like you have a",
    "start": "821580",
    "end": "828190"
  },
  {
    "text": "model which is a big neural network what what you do is that you treat every",
    "start": "828190",
    "end": "834900"
  },
  {
    "text": "instead of training cases you have training tasks and instead of test cases you have test tasks so your input may be",
    "start": "834900",
    "end": "842700"
  },
  {
    "text": "instead of just your current test case it would be all the information about the new T above the test tasks plus the",
    "start": "842700",
    "end": "849970"
  },
  {
    "text": "test case and you'll try to output the prediction reaction for that test case so basically you say yeah I'm going to",
    "start": "849970",
    "end": "857350"
  },
  {
    "text": "give you your ten examples as part of your input to your model figure out how to make the best use of them it's a",
    "start": "857350",
    "end": "864490"
  },
  {
    "text": "really straightforward idea u-turn the neural network into the learning algorithm by",
    "start": "864490",
    "end": "870840"
  },
  {
    "text": "turning a training task into a training case so training to ask a constraining",
    "start": "870840",
    "end": "876540"
  },
  {
    "text": "case this is meta learning just one sentence and so they've been several",
    "start": "876540",
    "end": "884220"
  },
  {
    "text": "success stories which I I think are very interesting one of the success stories",
    "start": "884220",
    "end": "889320"
  },
  {
    "text": "of meta learning is learning to recognize characters quickly so they've been a dataset",
    "start": "889320",
    "end": "896010"
  },
  {
    "text": "produced by MIT by lake corral and this",
    "start": "896010",
    "end": "902070"
  },
  {
    "text": "is a data set we have a large number of different handwritten characters and people have been able to train extremely",
    "start": "902070",
    "end": "908550"
  },
  {
    "text": "strong meta learning system for this desk another successful another very successful example of meta learning is",
    "start": "908550",
    "end": "914910"
  },
  {
    "text": "in that of neural architecture search by is openly from google where they found",
    "start": "914910",
    "end": "921930"
  },
  {
    "text": "neural architecture that solved one problem well small problem and then you could generalize and then if you",
    "start": "921930",
    "end": "927420"
  },
  {
    "text": "successfully solve large problems as well so this is the kind of the the small number of bits meta learning is",
    "start": "927420",
    "end": "934650"
  },
  {
    "text": "that when you learn the architecture or maybe even learn a program small program or learning algorithm which you apply to new tasks so this is the other way of",
    "start": "934650",
    "end": "942180"
  },
  {
    "text": "doing meta learning so anyway but the point is what's happening what's really happening in meta learning in most cases",
    "start": "942180",
    "end": "948120"
  },
  {
    "text": "is that you turn a training task into a training case and pretend this is",
    "start": "948120",
    "end": "954210"
  },
  {
    "text": "totally normal normal deep learning that's it this is the entirety of meta learning everything",
    "start": "954210",
    "end": "959580"
  },
  {
    "text": "else suggests minor details next I wanna dive in so now that I've finished the",
    "start": "959580",
    "end": "966120"
  },
  {
    "text": "introduction section I want to start discussing different work by different",
    "start": "966120",
    "end": "971430"
  },
  {
    "text": "people from opening I and I want to start by talking about hindsight experience replay it's been a large",
    "start": "971430",
    "end": "977130"
  },
  {
    "text": "effort by and recurvature all to develop a learning algorithm for reinforcement",
    "start": "977130",
    "end": "982290"
  },
  {
    "text": "learning that doesn't solve just one task but it",
    "start": "982290",
    "end": "988920"
  },
  {
    "text": "solves many tasks and it learns to make use of its experience in a much more efficient way and I want to discuss one",
    "start": "988920",
    "end": "996839"
  },
  {
    "text": "problem in reinforcement learning it's actually I guess a set of problems which all related to each other at one really",
    "start": "996839",
    "end": "1007639"
  },
  {
    "text": "important thing you need to learn to do is to explore you're in that you start out in an environment you don't know",
    "start": "1007639",
    "end": "1014120"
  },
  {
    "text": "what to do what do you do so one very important thing that has to happen is that you must get rewards from time to",
    "start": "1014120",
    "end": "1020060"
  },
  {
    "text": "time if you try something and you don't get rewards then how can you learn so",
    "start": "1020060",
    "end": "1029150"
  },
  {
    "text": "said that's the kind of the crux of the problem how do you learn and relatedly is there any way to meaningfully benefit",
    "start": "1029150",
    "end": "1037788"
  },
  {
    "text": "from your ex from the experience from your attempts to from from your failures if you try to achieve a goal and you",
    "start": "1037789",
    "end": "1044808"
  },
  {
    "text": "fail can you still learn from it you tell you instead of asking your algorithm to achieve a single goal you",
    "start": "1044809",
    "end": "1051110"
  },
  {
    "text": "want to learn a policy that can achieve a very large family of goals for example instead of reaching one state you want",
    "start": "1051110",
    "end": "1057080"
  },
  {
    "text": "to learn a policy that reaches every state of your system and what's the implication anytime you do something you",
    "start": "1057080",
    "end": "1064970"
  },
  {
    "text": "achieve some state so let's suppose you say I want to achieve state a I try my",
    "start": "1064970",
    "end": "1071570"
  },
  {
    "text": "best and I end up achieving state B I can either conclude well that was",
    "start": "1071570",
    "end": "1077419"
  },
  {
    "text": "disappointing I haven't learned almost anything I'm still have no idea how to cheat how to achieve state aid but",
    "start": "1077419",
    "end": "1084200"
  },
  {
    "text": "alternatively I can say well wait a second I've just reached a perfectly good state which is B can I learn how to",
    "start": "1084200",
    "end": "1090830"
  },
  {
    "text": "achieve state B from my attempt to achieve state a an answer is yes you can and it just works and I just want to",
    "start": "1090830",
    "end": "1098299"
  },
  {
    "text": "point out this is the one case there is a small subtlety here which may be",
    "start": "1098299",
    "end": "1103820"
  },
  {
    "text": "interesting to those of you who are very familiar with on Part B the distinction between on policy and off policy when",
    "start": "1103820",
    "end": "1111380"
  },
  {
    "text": "you try to achieve a you are on you're doing on policy learning for reaching the state a but you're doing",
    "start": "1111380",
    "end": "1118100"
  },
  {
    "text": "off policy learning for it in the state be because you would take different actions if you would actually try to",
    "start": "1118100",
    "end": "1123260"
  },
  {
    "text": "reach they'd be so that's why it's very important that the algorithm you use here can support of policy learning but",
    "start": "1123260",
    "end": "1129950"
  },
  {
    "text": "that's a minor technicality at the crux the crux of the idea is you make the",
    "start": "1129950",
    "end": "1135470"
  },
  {
    "text": "problem easier by ostensibly making it harder by training a system which can",
    "start": "1135470",
    "end": "1141860"
  },
  {
    "text": "which aspires to reach to learn to reach every state to learn to achieve every goal to learn to master its environment",
    "start": "1141860",
    "end": "1149240"
  },
  {
    "text": "in general you build a system which always learn something it learns from",
    "start": "1149240",
    "end": "1155450"
  },
  {
    "text": "success as well as from failure because if it tries to do one thing one thing and it does something else",
    "start": "1155450",
    "end": "1160700"
  },
  {
    "text": "it now has training data for how to achieve that something else I want to show you a video of how this thing works",
    "start": "1160700",
    "end": "1166549"
  },
  {
    "text": "in practice so one challenge in reinforcement learning systems is the",
    "start": "1166549",
    "end": "1172340"
  },
  {
    "text": "need to shape the reward so what does it mean it means that at the beginning of the",
    "start": "1172340",
    "end": "1177860"
  },
  {
    "text": "system at the start of learning then the system doesn't know much it will probably not achieve your goal and so",
    "start": "1177860",
    "end": "1184040"
  },
  {
    "text": "it's important that you design your reward function to give it gradual increments to make it smooth and continuous so that even when the system",
    "start": "1184040",
    "end": "1189740"
  },
  {
    "text": "is not very good it achieves the goal now if you give your state your system a very sparse reward where the reward is",
    "start": "1189740",
    "end": "1196160"
  },
  {
    "text": "achieved only when you reach a final state then it becomes very hard for",
    "start": "1196160",
    "end": "1201530"
  },
  {
    "text": "normal reinforcement learning algorithms to solve a problem because naturally you never get the reward so you never learn",
    "start": "1201530",
    "end": "1207320"
  },
  {
    "text": "no reward means no learning but here because you learn from failure as well",
    "start": "1207320",
    "end": "1213230"
  },
  {
    "text": "as from success this is this problem simply doesn't occur and so this is this is nice I",
    "start": "1213230",
    "end": "1219110"
  },
  {
    "text": "think you know let's let's look at the videos a little bit more like it's nice how this is it confidently and",
    "start": "1219110",
    "end": "1225140"
  },
  {
    "text": "energetically moves the little green buck to its target and here's another one",
    "start": "1225140",
    "end": "1231789"
  },
  {
    "text": "you",
    "start": "1237900",
    "end": "1239960"
  },
  {
    "text": "okay so we can skip the it works on spawn on the face if you do it on physical robot as well but we can skip it so I think the point is that the",
    "start": "1250050",
    "end": "1258600"
  },
  {
    "text": "hindsight experience replay algorithm is directionally correct because you want",
    "start": "1258600",
    "end": "1265020"
  },
  {
    "text": "to make use of all your data and not only a small fraction of it now one huge",
    "start": "1265020",
    "end": "1270900"
  },
  {
    "text": "question is where do you get the high level states where do the high level",
    "start": "1270900",
    "end": "1276540"
  },
  {
    "text": "states come from because in the work of showing you so far",
    "start": "1276540",
    "end": "1281780"
  },
  {
    "text": "the system is asked to achieve low level States so I think one thing it will become very important for this kind",
    "start": "1281780",
    "end": "1288360"
  },
  {
    "text": "approaches is representation learning and unsupervised learning figure out what are the rights what are the right",
    "start": "1288360",
    "end": "1294540"
  },
  {
    "text": "states what's the state space of goals that's worth achieving now I want to go",
    "start": "1294540",
    "end": "1303930"
  },
  {
    "text": "through some real meta learning results and I'll show you a very simple way of",
    "start": "1303930",
    "end": "1309510"
  },
  {
    "text": "doing seem to reel from simulation to the physical robot with meta learning",
    "start": "1309510",
    "end": "1315920"
  },
  {
    "text": "and this is where my pain growl was an a and encouraged a really nice intern project in 2017 so I think we can agree",
    "start": "1315920",
    "end": "1326160"
  },
  {
    "text": "that in the domain of robotics it would be nice if you could train your policy",
    "start": "1326160",
    "end": "1332040"
  },
  {
    "text": "in simulation and then somehow this knowledge would carry over to the",
    "start": "1332040",
    "end": "1337970"
  },
  {
    "text": "physical robot now we can build we can",
    "start": "1337970",
    "end": "1343050"
  },
  {
    "text": "build simulators that are okay but they can never perfectly match the real world",
    "start": "1343050",
    "end": "1349320"
  },
  {
    "text": "unless you want to have an insanely slow simulator and the reason for that is that it turns out that simulating freaky",
    "start": "1349320",
    "end": "1357180"
  },
  {
    "text": "simulating contacts is super hard and I heard somewhere correct me if I'm wrong",
    "start": "1357180",
    "end": "1362370"
  },
  {
    "text": "that simulating friction is np-complete I'm not sure but it's like stuff like",
    "start": "1362370",
    "end": "1368820"
  },
  {
    "text": "that so your simulation is just not going to match reality there will be",
    "start": "1368820",
    "end": "1374070"
  },
  {
    "text": "some resemblance but that's it how can we address this problem and I want to show",
    "start": "1374070",
    "end": "1379809"
  },
  {
    "text": "you one simple idea so let's say one",
    "start": "1379809",
    "end": "1385990"
  },
  {
    "text": "thing once one thing that would be nice is that if you could learn a policy learn a policy that would quickly adapt",
    "start": "1385990",
    "end": "1392890"
  },
  {
    "text": "itself to the real world well if you want to learn a policy that can quickly",
    "start": "1392890",
    "end": "1399220"
  },
  {
    "text": "adapt we need to make sure it has opportunities to adapt during training time so what do we do instead of solving",
    "start": "1399220",
    "end": "1407200"
  },
  {
    "text": "a problem in just one simulator we add a huge amount of variability to the",
    "start": "1407200",
    "end": "1412690"
  },
  {
    "text": "simulator we say we will randomize the friction so we will randomize the masses",
    "start": "1412690",
    "end": "1417820"
  },
  {
    "text": "the length of the different objects and their I guess M dimensions so you try to",
    "start": "1417820",
    "end": "1424929"
  },
  {
    "text": "randomize physics they simulate in lots of different ways and then importantly",
    "start": "1424929",
    "end": "1430390"
  },
  {
    "text": "you don't tell the policy how you randomized it so what is it going to do",
    "start": "1430390",
    "end": "1435580"
  },
  {
    "text": "then you take your policy and you put it in an environment then says well this is really really tough I don't know what",
    "start": "1435580",
    "end": "1441100"
  },
  {
    "text": "the masses are and I don't know what the frictions are I need to try things out and figure out what the friction is as I",
    "start": "1441100",
    "end": "1447549"
  },
  {
    "text": "get it responses from the environment so you're building you you learn a certain",
    "start": "1447549",
    "end": "1452679"
  },
  {
    "text": "degree of adaptability into the policy and it actually works let's want to show you this is what",
    "start": "1452679",
    "end": "1459520"
  },
  {
    "text": "happens when you just strain a policy in simulation and deploy it on the physical robot and here the goal is to bring the",
    "start": "1459520",
    "end": "1466419"
  },
  {
    "text": "hockey puck towards the red dot and you will see that it will struggle and the",
    "start": "1466419",
    "end": "1478059"
  },
  {
    "text": "reason it struggles is because of the systematic differences between the simulator and the real physical robot so",
    "start": "1478059",
    "end": "1487510"
  },
  {
    "text": "I can even the basic movement is difficult for the policy because the assumptions are violated so much so if",
    "start": "1487510",
    "end": "1494049"
  },
  {
    "text": "you do the training as I discussed we train a recurrent neural network policy which learns to quickly infer properties",
    "start": "1494049",
    "end": "1500290"
  },
  {
    "text": "of the simulator in order to accomplish the task you can then give it the real",
    "start": "1500290",
    "end": "1505419"
  },
  {
    "text": "thing the real physics and it will do much better so now this is not a perfect",
    "start": "1505419",
    "end": "1511160"
  },
  {
    "text": "technique but it's definitely very promising it's promising whenever you are able to sufficiently randomize the",
    "start": "1511160",
    "end": "1516590"
  },
  {
    "text": "simulator so it's definitely very nice to see the closed-loop nature of the",
    "start": "1516590",
    "end": "1522380"
  },
  {
    "text": "policy you consider it would push the hockey puck and would correct it very very gently to bring it to the goal",
    "start": "1522380",
    "end": "1528530"
  },
  {
    "text": "yeah so that that was cool so that was",
    "start": "1528530",
    "end": "1535190"
  },
  {
    "text": "very that was a cool application of meta learning I want to discuss one more",
    "start": "1535190",
    "end": "1540500"
  },
  {
    "text": "application of meta learning which is learning a hierarchy of actions and this",
    "start": "1540500",
    "end": "1547010"
  },
  {
    "text": "was work done by France at all actually kept in France the ancient who did it",
    "start": "1547010",
    "end": "1552440"
  },
  {
    "text": "was in high school I mean he wrote this paper so one thing that would be nice is",
    "start": "1552440",
    "end": "1564880"
  },
  {
    "text": "if reinforcement learning was hierarchical if instead of simply taking",
    "start": "1564880",
    "end": "1570559"
  },
  {
    "text": "micro actions you've had some kind of little subroutines that you could deploy",
    "start": "1570559",
    "end": "1575620"
  },
  {
    "text": "maybe the term subroutine is a little bit too crude but if you had some idea of which action primitives are worth",
    "start": "1575620",
    "end": "1583400"
  },
  {
    "text": "starting with now no one has been able to to get actually like real value add",
    "start": "1583400",
    "end": "1591679"
  },
  {
    "text": "from curricula reinforcement learning yet so far all the really cool results all the really convincing is also",
    "start": "1591679",
    "end": "1596900"
  },
  {
    "text": "reinforcement learning do not use it that's because we haven't quite figured",
    "start": "1596900",
    "end": "1602480"
  },
  {
    "text": "out what's the right way for reinforcement learning for her ocular reinforcement learning I just want to show you one very simple",
    "start": "1602480",
    "end": "1609909"
  },
  {
    "text": "approach where you use meta-learning to",
    "start": "1609909",
    "end": "1615100"
  },
  {
    "text": "learn to learn a hierarchy of actions so here's what you do you have in this",
    "start": "1615100",
    "end": "1621669"
  },
  {
    "text": "specific work you have a certain yeah let's say you have a certain number of",
    "start": "1621669",
    "end": "1627240"
  },
  {
    "text": "low-level primitives let's say you have two ten of them and you have a distribution of tasks and your goal is",
    "start": "1627240",
    "end": "1635769"
  },
  {
    "text": "to learn low level primitives such that when they are used inside a very brief",
    "start": "1635769",
    "end": "1644080"
  },
  {
    "text": "run of some reinforcement learning algorithm you will make as much progress as possible so the idea is you want to",
    "start": "1644080",
    "end": "1651429"
  },
  {
    "text": "get the greatest amount of progress you want to learn policies that result in the great story you want to learn",
    "start": "1651429",
    "end": "1658529"
  },
  {
    "text": "primitives that result in the greatest amount of progress is possible when used inside learning so this is a meta",
    "start": "1658529",
    "end": "1665260"
  },
  {
    "text": "learning setter because any distribution of tasks and here we've had if we've had a little maze here the distribution of a",
    "start": "1665260",
    "end": "1673330"
  },
  {
    "text": "mazes and in this case the little bug learned three policies which move it in its fixed direction and as a result of",
    "start": "1673330",
    "end": "1681100"
  },
  {
    "text": "having this hierarchy you're able to solve problems really fast but only when the hierarchy is correct so horican reinforcement learning is",
    "start": "1681100",
    "end": "1687789"
  },
  {
    "text": "still working progress and this was an and this work is an interesting proof",
    "start": "1687789",
    "end": "1692980"
  },
  {
    "text": "point of how Haruko reinforcement could",
    "start": "1692980",
    "end": "1699760"
  },
  {
    "text": "be like how heretical reinforcement learning could be like if it worked now",
    "start": "1699760",
    "end": "1706750"
  },
  {
    "text": "I want to just spend one slide addressing the limitations of high",
    "start": "1706750",
    "end": "1712510"
  },
  {
    "text": "capacity method learning the specific limitation is that the training test",
    "start": "1712510",
    "end": "1721340"
  },
  {
    "text": "distribution has to be equal to the test test distribution and I think this is a",
    "start": "1721340",
    "end": "1727130"
  },
  {
    "text": "real limitation because in reality you the new test that you want to learn do",
    "start": "1727130",
    "end": "1732230"
  },
  {
    "text": "in some ways being fundamentally different from anything you've seen so",
    "start": "1732230",
    "end": "1737480"
  },
  {
    "text": "far so for example if you go to school you learn lots of useful things but then",
    "start": "1737480",
    "end": "1742940"
  },
  {
    "text": "they go to work only a fraction of this of the things that you've learned carries over you need to learn if you",
    "start": "1742940",
    "end": "1750050"
  },
  {
    "text": "need quite a few more things from scratch so metal owning would struggle",
    "start": "1750050",
    "end": "1755510"
  },
  {
    "text": "with that because it really assumes that the Train the training data is that the distribution over the training task has",
    "start": "1755510",
    "end": "1761390"
  },
  {
    "text": "to be equal to the distribution of the test tasks that's the limitation I think that as we develop better algorithms for",
    "start": "1761390",
    "end": "1768980"
  },
  {
    "text": "being robust when the test tasks outside",
    "start": "1768980",
    "end": "1774020"
  },
  {
    "text": "of the distribution of the training tasks the metal on would work much better now I want to talk about self",
    "start": "1774020",
    "end": "1782450"
  },
  {
    "text": "play the links of play is a very cool topic that's starting to get attention",
    "start": "1782450",
    "end": "1789380"
  },
  {
    "text": "only now and I want to start by reviewing very old work called TD gammon",
    "start": "1789380",
    "end": "1796540"
  },
  {
    "text": "it's back from all the way from 1992 so it's 26 years old now it was done by",
    "start": "1796540",
    "end": "1802820"
  },
  {
    "text": "Jerry to cero so this work is really incredible because it has so much",
    "start": "1802820",
    "end": "1813380"
  },
  {
    "text": "relevance today what they did basically they said okay let's take two neural",
    "start": "1813380",
    "end": "1820550"
  },
  {
    "text": "networks and let them let them play against each other let them play",
    "start": "1820550",
    "end": "1826070"
  },
  {
    "text": "backgammon against each other and let them in tray let them be trained particularly so it's a super-modern",
    "start": "1826070",
    "end": "1832250"
  },
  {
    "text": "approach and you would think this was a paper from 2017 except that then you",
    "start": "1832250",
    "end": "1839300"
  },
  {
    "text": "look at this plot it shows that you only have ten hidden units twenty hidden units forty and eighty for the different",
    "start": "1839300",
    "end": "1844700"
  },
  {
    "text": "M colors where you notice that the largest neural network works best so in",
    "start": "1844700",
    "end": "1850400"
  },
  {
    "text": "some ways not much has changed and this is the evidence and in fact they were able to beat the",
    "start": "1850400",
    "end": "1857200"
  },
  {
    "text": "world champion in backgammon and they were able to discover new strategies that the best human a backgammon players",
    "start": "1857200",
    "end": "1862720"
  },
  {
    "text": "weren't ever not noticed and they've determined that the strategy discovered",
    "start": "1862720",
    "end": "1867820"
  },
  {
    "text": "by TD gammon actually better so that's pure self play with cue learning which is which remained dormant",
    "start": "1867820",
    "end": "1876280"
  },
  {
    "text": "until the DQ and work with Atari mid mind so now other examples of self play",
    "start": "1876280",
    "end": "1887020"
  },
  {
    "text": "include alphago zero which was able to learn to beat the world champion and go",
    "start": "1887020",
    "end": "1892690"
  },
  {
    "text": "without using any external data whatsoever another result of this vein",
    "start": "1892690",
    "end": "1897850"
  },
  {
    "text": "is by open AI which is our dota 2 BOTS which was able to build the world champion on the 1v1 version of the game",
    "start": "1897850",
    "end": "1906720"
  },
  {
    "text": "and so I want to spend a little bit of time talking about the allure of self",
    "start": "1906720",
    "end": "1912760"
  },
  {
    "text": "play and why I think it's exciting so",
    "start": "1912760",
    "end": "1918900"
  },
  {
    "text": "one important problem that's a that that's that we must face as we try to",
    "start": "1918900",
    "end": "1925450"
  },
  {
    "text": "build truly intelligent systems is what is the task what are we actually",
    "start": "1925450",
    "end": "1931659"
  },
  {
    "text": "teaching the systems to do and one very attractive attribute of self play is",
    "start": "1931659",
    "end": "1937870"
  },
  {
    "text": "that the agents create the environment",
    "start": "1937870",
    "end": "1944110"
  },
  {
    "text": "by virtue of the agent acting in the environment the environment becomes",
    "start": "1944110",
    "end": "1950140"
  },
  {
    "text": "difficult for the other agents and you can see here an example of an iguana interacting with snakes that try to eat",
    "start": "1950140",
    "end": "1956740"
  },
  {
    "text": "it unsuccessfully this time so we can see what will happen in a moment the iguana",
    "start": "1956740",
    "end": "1963760"
  },
  {
    "text": "strains best and so the fact you have this arms race between the snakes and",
    "start": "1963760",
    "end": "1969429"
  },
  {
    "text": "the iguana motivates their development potentially without bound and this is what happens",
    "start": "1969429",
    "end": "1976630"
  },
  {
    "text": "in effect in but in biological evolution now interesting work in this direction",
    "start": "1976630",
    "end": "1982660"
  },
  {
    "text": "was done in 1994 but Carl says there is a really cool video on YouTube by Carl",
    "start": "1982660",
    "end": "1989260"
  },
  {
    "text": "seems you should check it out which really kind of shows all the work that he's done and here you have a little",
    "start": "1989260",
    "end": "1995740"
  },
  {
    "text": "competition between agents where you evolved both the behavior and their morphology when you when the agents is",
    "start": "1995740",
    "end": "2002790"
  },
  {
    "text": "trying to gain possession of a green cube and so you can see that the agents",
    "start": "2002790",
    "end": "2009060"
  },
  {
    "text": "create the challenge for each other and that's why they need to develop so one",
    "start": "2009060",
    "end": "2016350"
  },
  {
    "text": "thing that we did and this is work by advance a little from open ai is we said",
    "start": "2016350",
    "end": "2023460"
  },
  {
    "text": "okay well can we demonstrate some unusual results in self play that would",
    "start": "2023460",
    "end": "2028860"
  },
  {
    "text": "really convince us that there is something there so what we did here is that we created a small a small ring and",
    "start": "2028860",
    "end": "2036120"
  },
  {
    "text": "you have these two humanoid figures and their goal is just to push each other outside the ring and they don't know",
    "start": "2036120",
    "end": "2043710"
  },
  {
    "text": "anything about wrestling they don't know anything about standing your balance in each other they don't know anything about centers of gravity all they know",
    "start": "2043710",
    "end": "2050520"
  },
  {
    "text": "is that if you don't do a good job then your competition is going to do a better job now one of the really attractive",
    "start": "2050520",
    "end": "2057720"
  },
  {
    "text": "things about self play is that you always have an opponent that's roughly",
    "start": "2057720",
    "end": "2065850"
  },
  {
    "text": "as good as you are in order to learn you need to sometimes win and sometimes lose",
    "start": "2065850",
    "end": "2072030"
  },
  {
    "text": "but you can't always win sometimes you must fail sometimes you must succeed so",
    "start": "2072030",
    "end": "2079649"
  },
  {
    "text": "let's see what will happen here yeah so it was able to do so the green humanoid",
    "start": "2079650",
    "end": "2084990"
  },
  {
    "text": "was able to block the ball in a Cell in a well balanced self play environment",
    "start": "2084990",
    "end": "2092149"
  },
  {
    "text": "petition is always level no matter how good you are or how bad you are you have",
    "start": "2093110",
    "end": "2098540"
  },
  {
    "text": "a competition that makes it exact exactly of exactly the right challenge for you on one thing here so this video",
    "start": "2098540",
    "end": "2104630"
  },
  {
    "text": "shows transfer learning it takes a little wrestling humanoid and you take its friend away and you start applying a",
    "start": "2104630",
    "end": "2112370"
  },
  {
    "text": "big large random forces on it and you see if it can maintain its balance and the answer turns out to be but yes it",
    "start": "2112370",
    "end": "2119000"
  },
  {
    "text": "can because it's been trained against an opponent it pushes it and so that's why",
    "start": "2119000",
    "end": "2125060"
  },
  {
    "text": "even if it doesn't understand where the fresh force is being applied on it it's still able to balance itself so this is",
    "start": "2125060",
    "end": "2131900"
  },
  {
    "text": "one potentially attractive feature of subway environments that you could learn a certain broad set of skills although",
    "start": "2131900",
    "end": "2140420"
  },
  {
    "text": "it's real hard to control the square the skills will be and so the biggest open question with this research is how do",
    "start": "2140420",
    "end": "2146900"
  },
  {
    "text": "you learn agents in a software environment such that they do whatever",
    "start": "2146900",
    "end": "2153170"
  },
  {
    "text": "they do but then they are able to solve a battery of tasks that is useful for us that is explicitly specified externally",
    "start": "2153170",
    "end": "2160870"
  },
  {
    "text": "yeah I also want to want to highlight",
    "start": "2160870",
    "end": "2166790"
  },
  {
    "text": "one attribute of self play environments that we've observed in our dota BOTS and",
    "start": "2166790",
    "end": "2172100"
  },
  {
    "text": "that is that we've seen a very rapid increase in the competence of the bots so over the period over the course of",
    "start": "2172100",
    "end": "2177650"
  },
  {
    "text": "maybe five months we've seen the bots go from playing totally randomly all the",
    "start": "2177650",
    "end": "2184220"
  },
  {
    "text": "way to the world champion and the reason for that is that once you have a self",
    "start": "2184220",
    "end": "2190790"
  },
  {
    "text": "play environment if we put compute into it you turn it into data self play",
    "start": "2190790",
    "end": "2196910"
  },
  {
    "text": "allows you to turn compute into data and I think you will see a lot more of that as being an extremely important thing to",
    "start": "2196910",
    "end": "2204920"
  },
  {
    "text": "be able to turn compute into essentially data generalization simply because the",
    "start": "2204920",
    "end": "2210050"
  },
  {
    "text": "speed of neural net processors will increase very dramatically over the next few years so neural net cycles will be",
    "start": "2210050",
    "end": "2215990"
  },
  {
    "text": "cheap and it will be important to make use of this new of newly-found overabundance of cycles",
    "start": "2215990",
    "end": "2222099"
  },
  {
    "text": "I also want to talk a little bit about the endgame of the self approach so one",
    "start": "2222099",
    "end": "2228759"
  },
  {
    "text": "thing that we know about the human brain is that it has increased in sized fairly",
    "start": "2228759",
    "end": "2234519"
  },
  {
    "text": "rapidly over the past two million years my theory the reason I think it happened",
    "start": "2234519",
    "end": "2241150"
  },
  {
    "text": "is because our ancestors got to a point where the thing that's most important",
    "start": "2241150",
    "end": "2247960"
  },
  {
    "text": "for your survival is your standing in the tribe and less the tiger and the",
    "start": "2247960",
    "end": "2253239"
  },
  {
    "text": "lion once the most important thing is how you deal with those other things",
    "start": "2253239",
    "end": "2259089"
  },
  {
    "text": "which have a large brain then it really helps to have a slightly larger brain and I think that's what happened and",
    "start": "2259089",
    "end": "2264509"
  },
  {
    "text": "there exists at least one paper from science which supports this point of view so apparently there has been",
    "start": "2264509",
    "end": "2271269"
  },
  {
    "text": "convergent evolution between social apps and social Birds even though in terms of",
    "start": "2271269",
    "end": "2277960"
  },
  {
    "text": "various behaviors even though the divergence in evolutionary timescale",
    "start": "2277960",
    "end": "2284769"
  },
  {
    "text": "between humans and birds has occurred a very long time ago and humans and humans",
    "start": "2284769",
    "end": "2289930"
  },
  {
    "text": "apes and humans apes and birds have very different brain structure so I think",
    "start": "2289930",
    "end": "2297640"
  },
  {
    "text": "what should happen if we succeed if we successfully follow the path of this approach is that you should create a",
    "start": "2297640",
    "end": "2303999"
  },
  {
    "text": "society of agents which will have language and theory of mind negotiation",
    "start": "2303999",
    "end": "2309460"
  },
  {
    "text": "social skills trade economy politics justice system all these things should",
    "start": "2309460",
    "end": "2315700"
  },
  {
    "text": "happen inside the multi-agent environment and it will also be some alignment issue of how do you make sure",
    "start": "2315700",
    "end": "2321489"
  },
  {
    "text": "that the agents we learn behave in a way that we want now I want to make a",
    "start": "2321489",
    "end": "2326700"
  },
  {
    "text": "speculative digression here which is I want to make the following observation",
    "start": "2326700",
    "end": "2336230"
  },
  {
    "text": "if you believe that this kind of society of agents is a plausible place where",
    "start": "2336230",
    "end": "2345579"
  },
  {
    "text": "truly where the fuller fully general intelligence will emerge and if you",
    "start": "2345579",
    "end": "2352940"
  },
  {
    "text": "accept that our experience with the dota BOTS we've seen a very rapid increase in",
    "start": "2352940",
    "end": "2357980"
  },
  {
    "text": "competence will carry over once all the details are right if you assume both of these conditions then it should follow",
    "start": "2357980",
    "end": "2366260"
  },
  {
    "text": "that we should see a very rapid increase in the competence of our agents as they live in the Society of agents so now",
    "start": "2366260",
    "end": "2374750"
  },
  {
    "text": "that we've talked about a potentially interesting way of increasing the",
    "start": "2374750",
    "end": "2381260"
  },
  {
    "text": "competence and teachings of an agent's social skills and language and a lot of things that actually exist in humans as",
    "start": "2381260",
    "end": "2388369"
  },
  {
    "text": "well we want to talk a little bit about how you convey goals to agents and the",
    "start": "2388369",
    "end": "2397430"
  },
  {
    "text": "question of the main goal to eight calls to agents is just a technical problem but it will be important because it is a",
    "start": "2397430",
    "end": "2405440"
  },
  {
    "text": "lot more likely than not that the agents of evil train will eventually be",
    "start": "2405440",
    "end": "2412160"
  },
  {
    "text": "dramatically smarter than us and this is work by the opening eye safety team by",
    "start": "2412160",
    "end": "2417560"
  },
  {
    "text": "Paul Christiana at all and others so I'm just going to show you this video which",
    "start": "2417560",
    "end": "2423530"
  },
  {
    "text": "basically explains how the whole thing works you there is some behavior looking",
    "start": "2423530",
    "end": "2429109"
  },
  {
    "text": "for and you the human gets to see pairs of behaviors and you simply click on the",
    "start": "2429109",
    "end": "2436220"
  },
  {
    "text": "one that looks better and after a very",
    "start": "2436220",
    "end": "2441829"
  },
  {
    "text": "modest number of clicks you can get this little simulated leg to do back flips",
    "start": "2441829",
    "end": "2449869"
  },
  {
    "text": "and there",
    "start": "2449869",
    "end": "2457690"
  },
  {
    "text": "go picking out the back flips and in this to get this specific behavior it took about 500 clicks by human",
    "start": "2457690",
    "end": "2466600"
  },
  {
    "text": "annotators the way it works is that you take all the so this is a very data",
    "start": "2466600",
    "end": "2471970"
  },
  {
    "text": "efficient reinforcement learning algorithm but it is efficient in terms of rewards and not in terms of the",
    "start": "2471970",
    "end": "2478360"
  },
  {
    "text": "environment interactions so what you do here is that you take all the clicks so you've got your here is one B here which",
    "start": "2478360",
    "end": "2486100"
  },
  {
    "text": "is better than other you fit a reward function a numerical reward function to",
    "start": "2486100",
    "end": "2492520"
  },
  {
    "text": "those clicks so you want to fit a reward function which satisfies those clicks clicks and you optimize this reward function with reinforcement learning and",
    "start": "2492520",
    "end": "2498750"
  },
  {
    "text": "it actually works so this requires 500 bits of information you've also been",
    "start": "2498750",
    "end": "2505210"
  },
  {
    "text": "able to train lots of Atari games using several thousand bits of information so in all these cases you had human and",
    "start": "2505210",
    "end": "2511660"
  },
  {
    "text": "human annotators or human judges just like in the previous slide looking at",
    "start": "2511660",
    "end": "2517260"
  },
  {
    "text": "the pairs of trajectories and clicking on the one that they thought was better and here's an example of an unusual goal",
    "start": "2517260",
    "end": "2527890"
  },
  {
    "text": "where this is a car racing game but the goal was to ask the the agent to train",
    "start": "2527890",
    "end": "2534190"
  },
  {
    "text": "the white car drive right behind the orange car so it's a different goal and",
    "start": "2534190",
    "end": "2539800"
  },
  {
    "text": "it was very straightforward to communicate this goal using this approach so then to finish off alignment",
    "start": "2539800",
    "end": "2550450"
  },
  {
    "text": "is a technical problem it has to be solved but of course the determination of the correct goals we want array",
    "start": "2550450",
    "end": "2556660"
  },
  {
    "text": "assistance the systems to have will be a very challenging political problem and on this note I want to thank you so much",
    "start": "2556660",
    "end": "2564430"
  },
  {
    "text": "for your attention and I just want to say that will be a happy hour at Cambridge Brewing Company at 8:45 if you",
    "start": "2564430",
    "end": "2570520"
  },
  {
    "text": "want to chat more about AI and other topics please come by I think that deserves an applause",
    "start": "2570520",
    "end": "2577980"
  },
  {
    "text": "so back propagation is a or neural networks of bio-inspired but back",
    "start": "2583030",
    "end": "2589330"
  },
  {
    "start": "2584000",
    "end": "3615000"
  },
  {
    "text": "propagation doesn't look as though it's what's going on in the brain because signals in the brain go one direction",
    "start": "2589330",
    "end": "2594640"
  },
  {
    "text": "down the axons whereas back propagation requires the errors to be propagated back up the the wires so can you just",
    "start": "2594640",
    "end": "2603490"
  },
  {
    "text": "talk a little bit about that whole situation where it looks as the brain is doing something a bit different than our",
    "start": "2603490",
    "end": "2608800"
  },
  {
    "text": "highly successful algorithms our algorithm is going to be improved once we figure out what the brain is doing or",
    "start": "2608800",
    "end": "2615280"
  },
  {
    "text": "is the brain really sending signals back even though it's got no obvious way of doing that what's what's happening in",
    "start": "2615280",
    "end": "2621100"
  },
  {
    "text": "that area so that's a great question so first of all I'll say that the true answer is that the honest answer is that",
    "start": "2621100",
    "end": "2628150"
  },
  {
    "text": "I don't know but I have opinions and so I'll say two things",
    "start": "2628150",
    "end": "2634240"
  },
  {
    "text": "but first of all given that look if you agree if we agree like so rather it is a",
    "start": "2634240",
    "end": "2641380"
  },
  {
    "text": "true fact the back propagation solves the problem of circuit search this",
    "start": "2641380",
    "end": "2648100"
  },
  {
    "text": "problem feels like an extremely fundamental problem and for this reason I think that it's unlikely to go away",
    "start": "2648100",
    "end": "2654400"
  },
  {
    "text": "now you also write that the brain doesn't obviously do back propagation although they've been multiple proposals",
    "start": "2654400",
    "end": "2660940"
  },
  {
    "text": "of how it could be how it could be doing them for example there's been a work by",
    "start": "2660940",
    "end": "2667390"
  },
  {
    "text": "Tim little crap and others where they've shown that if you use that it's possible to learn a different set of connections",
    "start": "2667390",
    "end": "2673530"
  },
  {
    "text": "but can be used for the backward pass and that can result in successful learning now the reason this hasn't been",
    "start": "2673530",
    "end": "2680200"
  },
  {
    "text": "like really pushed to the limit by practitioners is because they say well I got TF to the gradients I'm just not",
    "start": "2680200",
    "end": "2686830"
  },
  {
    "text": "going to worry about it but you are right this is an important issue and you know one of two things is going to",
    "start": "2686830",
    "end": "2692710"
  },
  {
    "text": "happen so my personal opinion is that back propagation is just going to stay with us till the very end and will",
    "start": "2692710",
    "end": "2698440"
  },
  {
    "text": "actually build fully human level and beyond systems before we understand how the brain does what it does so that's",
    "start": "2698440",
    "end": "2707020"
  },
  {
    "text": "what I believe but of course it is a difference that has to be acknowledged",
    "start": "2707020",
    "end": "2712460"
  },
  {
    "text": "okay thank you do you think it was a fair matchup for the dota bot and that",
    "start": "2712460",
    "end": "2718760"
  },
  {
    "text": "person given the constraints of the system so I'd say that like the biggest advantage computers have in games like",
    "start": "2718760",
    "end": "2726560"
  },
  {
    "text": "this like one of the big advantages is that they obviously have a better reaction time although in DotA in",
    "start": "2726560",
    "end": "2733070"
  },
  {
    "text": "particular the number of clicks per second over the top players is fairly",
    "start": "2733070",
    "end": "2738290"
  },
  {
    "text": "small which is different from Starcraft so in Starcraft stuff up is a very compact mechanically heavy game because",
    "start": "2738290",
    "end": "2745010"
  },
  {
    "text": "of a large number of units and so the top players that is click all the time in DotA every player controls just one",
    "start": "2745010",
    "end": "2752600"
  },
  {
    "text": "hero and so that greatly reduces the total number of actions they need to make now still precision matters I think",
    "start": "2752600",
    "end": "2758630"
  },
  {
    "text": "that will discover that but what I think it'll really happen is if you'll",
    "start": "2758630",
    "end": "2763790"
  },
  {
    "text": "discover that computers have the advantage in any domain or rather every",
    "start": "2763790",
    "end": "2771530"
  },
  {
    "text": "domain not yet so do you think that the emergent behaviors from the agent were",
    "start": "2771530",
    "end": "2778220"
  },
  {
    "text": "actually kind of directed because the constraints already kinda in place like so it was kind of forced discover those",
    "start": "2778220",
    "end": "2783980"
  },
  {
    "text": "or do you think that like that was actually something quite novel that like wow it actually discovered these on its",
    "start": "2783980",
    "end": "2790520"
  },
  {
    "text": "own like you didn't actually am biased towards constraining it so it's definitely discover new strategies and I",
    "start": "2790520",
    "end": "2795920"
  },
  {
    "text": "can share an anecdote where our tester we have a probe which would test the bots and he played against for a long",
    "start": "2795920",
    "end": "2804200"
  },
  {
    "text": "time and the bots would do all kinds of things against the player the human player which were effective then at some",
    "start": "2804200",
    "end": "2810410"
  },
  {
    "text": "point that Pro decided to play against the better plot Pro and he decided to",
    "start": "2810410",
    "end": "2815600"
  },
  {
    "text": "imitate one of the things that the bot was doing and this image but by imitating if he was able to defeat a",
    "start": "2815600",
    "end": "2822050"
  },
  {
    "text": "better pro so I think I think the strategy discovers are real and so like it means that like this very real",
    "start": "2822050",
    "end": "2828800"
  },
  {
    "text": "transformative Tran you know I would say I think what that means is that he",
    "start": "2828800",
    "end": "2835700"
  },
  {
    "text": "because the strategies discovered by the bot of the humans it means that we like a fundamental game plays deeply related",
    "start": "2835700",
    "end": "2842260"
  },
  {
    "text": "for a long time now I've heard that the objective of reinforcement learning is",
    "start": "2842260",
    "end": "2847449"
  },
  {
    "text": "to determine a policy that chooses an action to maximize the expected reward",
    "start": "2847449",
    "end": "2853719"
  },
  {
    "text": "which is what you said earlier would you ever want to look at the standard deviation of possible rewards does that",
    "start": "2853719",
    "end": "2861819"
  },
  {
    "text": "even make sense yeah I mean I think for sure I think it's a really application dependent one of the reasons to maximize",
    "start": "2861819",
    "end": "2869529"
  },
  {
    "text": "the expected reward it's because it's easier to design algorithms for it so you write down this equation the",
    "start": "2869529",
    "end": "2878529"
  },
  {
    "text": "formula you do a little bit of derivation you get something which amounts to a nice-looking algorithm now",
    "start": "2878529",
    "end": "2883959"
  },
  {
    "text": "I think there exist like really there exist applications where you'd never",
    "start": "2883959",
    "end": "2890140"
  },
  {
    "text": "want to make mistakes and you want to work on the standard deviation as well but in practice it seems that the just",
    "start": "2890140",
    "end": "2896589"
  },
  {
    "text": "looking at the expected reward covers a large fraction of the B the situation as",
    "start": "2896589",
    "end": "2903190"
  },
  {
    "text": "you'd like to apply this door Thanks",
    "start": "2903190",
    "end": "2907380"
  },
  {
    "text": "we talked last week about motivations and that has a lot to do with the",
    "start": "2908579",
    "end": "2915509"
  },
  {
    "text": "reinforcement and some of the ideas is that the our motivations are actually",
    "start": "2915509",
    "end": "2922479"
  },
  {
    "text": "connection with others and cooperation and I'm wondering if they're thrown off",
    "start": "2922479",
    "end": "2928119"
  },
  {
    "text": "and I understand it's very popular to have the computers play these competitive games but is there any use",
    "start": "2928119",
    "end": "2936069"
  },
  {
    "text": "in like having an agent self play collaboratively collaborative games Yeah",
    "start": "2936069",
    "end": "2943869"
  },
  {
    "text": "right that's an extremely good question I don't think one place from which we",
    "start": "2943869",
    "end": "2949059"
  },
  {
    "text": "can get some inspiration is from the evolution of cooperation like I think cooperation like we",
    "start": "2949059",
    "end": "2957940"
  },
  {
    "text": "cooperate ultimately because it's much better for you the person to be cooperative than not and so I think what",
    "start": "2957940",
    "end": "2967420"
  },
  {
    "text": "should happen if you have a sufficiently open-ended game then cooperation will be the",
    "start": "2967420",
    "end": "2974680"
  },
  {
    "text": "winning strategy and so I think we will get cooperation whether we like it or not Hey",
    "start": "2974680",
    "end": "2984940"
  },
  {
    "text": "you mentioned the complexity of this simulation of friction I was wondering",
    "start": "2984940",
    "end": "2990790"
  },
  {
    "text": "if you feel that there exists open complexity theoretic problems relevant to relevant to AI or whether it's just a",
    "start": "2990790",
    "end": "2997870"
  },
  {
    "text": "matter of finding good approximations that humans of the types of problems that humans tend to solve yeah so",
    "start": "2997870",
    "end": "3004710"
  },
  {
    "text": "complexity theory well like at a very basic level we know that whatever",
    "start": "3004710",
    "end": "3011690"
  },
  {
    "text": "algorithm we gonna run is going to run fairly efficiently on some hardware so",
    "start": "3011690",
    "end": "3017040"
  },
  {
    "text": "that puts a pretty strict upper bound and the true complexity of the problems",
    "start": "3017040",
    "end": "3022650"
  },
  {
    "text": "we're solving but by definition we are solving problems which aren't too hard in a complexity theoretic sense now it",
    "start": "3022650",
    "end": "3030180"
  },
  {
    "text": "is also the case that many of the problems so while the overall thing that",
    "start": "3030180",
    "end": "3035460"
  },
  {
    "text": "we do is not hard from a complexity theory makes sense and indeed humans cannot solve np-complete problems in",
    "start": "3035460",
    "end": "3041160"
  },
  {
    "text": "general it is true that many of the like optimization problems that we pose to",
    "start": "3041160",
    "end": "3047280"
  },
  {
    "text": "our algorithms are intractable in the general case starting from a neural net optimization itself it is easy to create",
    "start": "3047280",
    "end": "3054390"
  },
  {
    "text": "a family of data sets for a neural network with a very small number of neurons such that find a global optimum",
    "start": "3054390",
    "end": "3059790"
  },
  {
    "text": "is np-complete and so how do we avoid it well we just try gradient descent anyway",
    "start": "3059790",
    "end": "3066450"
  },
  {
    "text": "and somehow it works but without question like we cannot we do not solve",
    "start": "3066450",
    "end": "3074610"
  },
  {
    "text": "problems which are truly intractable so I mean I hope this answer the question",
    "start": "3074610",
    "end": "3080090"
  },
  {
    "text": "hello it seems like an important sub-problem on the path towards AGI will be",
    "start": "3080090",
    "end": "3086490"
  },
  {
    "text": "understanding language and the state of generative language modeling right now is pretty abysmal what do you think are",
    "start": "3086490",
    "end": "3093840"
  },
  {
    "text": "the most productive research trajectories towards generative language models so",
    "start": "3093840",
    "end": "3099329"
  },
  {
    "text": "I'll first say that you are completely correct that the situation with language is still far from great although",
    "start": "3099329",
    "end": "3104999"
  },
  {
    "text": "progress has been made even without any particular innovations beyond models",
    "start": "3104999",
    "end": "3111479"
  },
  {
    "text": "that exist today simply scaling up models that exist today on larger datasets is going to go surprisingly far",
    "start": "3111479",
    "end": "3118829"
  },
  {
    "text": "not even large datasets but larger and deeper models for example if you trained a language model be the thousand layers",
    "start": "3118829",
    "end": "3124819"
  },
  {
    "text": "and it's the same layer I think it's gonna be a pretty amazing language model",
    "start": "3124819",
    "end": "3130709"
  },
  {
    "text": "like we don't have the cycles for it yet but to think it will change very soon now I also agree with you that there are",
    "start": "3130709",
    "end": "3137669"
  },
  {
    "text": "some fundamental things missing in a current understanding of deep learning",
    "start": "3137669",
    "end": "3143689"
  },
  {
    "text": "which prevent us from really solving the problem that we want so I think one of",
    "start": "3143689",
    "end": "3148799"
  },
  {
    "text": "these problems one of the things that's missing is that or that seems like patently wrong is the fact that we train",
    "start": "3148799",
    "end": "3157829"
  },
  {
    "text": "a model then you stop training the model and you freeze it even though it's the",
    "start": "3157829",
    "end": "3163829"
  },
  {
    "text": "training process where the magic really happens but the magic is that if you",
    "start": "3163829",
    "end": "3168899"
  },
  {
    "text": "think about it like the training process is the true general part of the whole of",
    "start": "3168899",
    "end": "3174359"
  },
  {
    "text": "the whole of the whole story because you tends to flow code doesn't care which data set to optimize it just says",
    "start": "3174359",
    "end": "3179729"
  },
  {
    "text": "whatever just give me the data set I don't care which one solve I'll sew them all so like the ability to do that feels",
    "start": "3179729",
    "end": "3186809"
  },
  {
    "text": "really special and I think we are not using it at test time like it's hard to",
    "start": "3186809",
    "end": "3192119"
  },
  {
    "text": "speculate about like things which you don't know the answer but all I'll say is that simply train bigger deeper",
    "start": "3192119",
    "end": "3198419"
  },
  {
    "text": "language models you'll go surprisingly far scaling up but also doing things",
    "start": "3198419",
    "end": "3203609"
  },
  {
    "text": "like training a test them and inference the test time I think would be another important boosts the performance hi",
    "start": "3203609",
    "end": "3210419"
  },
  {
    "text": "thank you for the talk so it seems like right now another interesting approach to solving reinforcement learning",
    "start": "3210419",
    "end": "3216179"
  },
  {
    "text": "problems could be to go for the evolutionary roots using evolutionary strategies and although they have they",
    "start": "3216179",
    "end": "3222239"
  },
  {
    "text": "their cave Hut's I wanted to know if I'd open a I particularly you're working on something related and what are what is",
    "start": "3222239",
    "end": "3228630"
  },
  {
    "text": "your general opinion on them so like at present I believe that",
    "start": "3228630",
    "end": "3234010"
  },
  {
    "text": "something evolutionary strategies is not great for reinforcement learning I think that normal reinforcement learning",
    "start": "3234010",
    "end": "3239980"
  },
  {
    "text": "algorithms especially with big policies are better but I think if you want to evolve a small compact object like like",
    "start": "3239980",
    "end": "3248319"
  },
  {
    "text": "a piece of code for example I think that would be a place where this would be seriously was considering but this all",
    "start": "3248319",
    "end": "3255309"
  },
  {
    "text": "you know evolving a beautiful piece of code is a cool idea hasn't been done yet",
    "start": "3255309",
    "end": "3261339"
  },
  {
    "text": "so still a lot of work to be done before we get there hi thank you so much for coming my question is you mentioned what",
    "start": "3261339",
    "end": "3269289"
  },
  {
    "text": "is the right go is a political problem so I'm wondering if you can elaborate a bit on that and also what do you think",
    "start": "3269289",
    "end": "3275950"
  },
  {
    "text": "would be their approach for us to maybe get there well I can't I can't really",
    "start": "3275950",
    "end": "3281319"
  },
  {
    "text": "comment too much because all the thoughts that you know we have we now have a few people who are thinking about",
    "start": "3281319",
    "end": "3288039"
  },
  {
    "text": "this full-time at opening I I don't have enough of a super strong opinion to say",
    "start": "3288039",
    "end": "3295750"
  },
  {
    "text": "anything too definitive all I can say at the very high level is given the size",
    "start": "3295750",
    "end": "3300970"
  },
  {
    "text": "like if you go into the future whenever soon or late you know whenever it's going to happen when you build a",
    "start": "3300970",
    "end": "3306099"
  },
  {
    "text": "computer which can do anything better than a human it will happen because the",
    "start": "3306099",
    "end": "3311500"
  },
  {
    "text": "brain is physical the impact on society is going to be completely massive and",
    "start": "3311500",
    "end": "3316630"
  },
  {
    "text": "overwhelming it's it's very difficult to imagine even if you try really hard and",
    "start": "3316630",
    "end": "3323319"
  },
  {
    "text": "I think what it means is that people who care a lot and that's what I was",
    "start": "3323319",
    "end": "3328779"
  },
  {
    "text": "alluding to the fact that this will be something that many people who care about strongly and like as the impact",
    "start": "3328779",
    "end": "3336519"
  },
  {
    "text": "increases gradually with self-driving cars more automation I think we will see a lot more people care do we need to",
    "start": "3336519",
    "end": "3343210"
  },
  {
    "text": "have a very accurate model of the physical world and then simulate that in",
    "start": "3343210",
    "end": "3348700"
  },
  {
    "text": "order to have these agents that can eventually come out into the real world and do something approaching you know",
    "start": "3348700",
    "end": "3356500"
  },
  {
    "text": "human level intelligence tasks that's a very good question so I think if that",
    "start": "3356500",
    "end": "3362200"
  },
  {
    "text": "were the case be in trouble and I am very certain that",
    "start": "3362200",
    "end": "3369259"
  },
  {
    "text": "it could be avoided so specifically the real answer has to be that look you",
    "start": "3369259",
    "end": "3374930"
  },
  {
    "text": "learn the problem so we learn to negotiate you learn to persist you not a lots of different useful life lessons in",
    "start": "3374930",
    "end": "3380990"
  },
  {
    "text": "the simulation and yes you learn some physics too but then you go outside to the real world and you have to start over to some",
    "start": "3380990",
    "end": "3386660"
  },
  {
    "text": "extent because many of you are deeply held assumptions will be false in one of the goals so what was that's one reasons",
    "start": "3386660",
    "end": "3393829"
  },
  {
    "text": "I care so much about never stopping training you've accumulated your knowledge now we go into an environment",
    "start": "3393829",
    "end": "3400339"
  },
  {
    "text": "for some of your assumptions of valid you continue training you try to connect the new data to your old data and this is an important requirement from our",
    "start": "3400339",
    "end": "3406400"
  },
  {
    "text": "algorithms which is already met to some extent but it will have to be met a lot more so that you can take the partial",
    "start": "3406400",
    "end": "3412730"
  },
  {
    "text": "knowledge if you've acquired then go in a new situation learn some more literally the example of you go to",
    "start": "3412730",
    "end": "3419779"
  },
  {
    "text": "school ballon useful things then you go to work it's not a perfect it's not you know you pour your four years of CS and",
    "start": "3419779",
    "end": "3426140"
  },
  {
    "text": "undergrad is not going to fully prepare you for whatever it is you need to know it work it will help somewhat you'll be able to",
    "start": "3426140",
    "end": "3432289"
  },
  {
    "text": "get off the ground but it will be lots of new things you need to learn so that's that's the spirit of it I think of a toes of the school one of the",
    "start": "3432289",
    "end": "3439250"
  },
  {
    "text": "things you mentioned pretty early on in your talk is that one of the limitations of this sort of style of reinforcement",
    "start": "3439250",
    "end": "3444589"
  },
  {
    "text": "learning is there's no self-organization so you have to tell it when it did a good thing or did a bad thing and that's",
    "start": "3444589",
    "end": "3450109"
  },
  {
    "text": "actually a problem in neuroscience is when you're trying to teach a rat to you know navigate maze you have to artificially tell it what to do so where",
    "start": "3450109",
    "end": "3456829"
  },
  {
    "text": "do you see moving forward when we already have this problem with teaching you know not necessarily learning but also teaching so where do you see the",
    "start": "3456829",
    "end": "3462680"
  },
  {
    "text": "research moving forward in that respect how do you sort of introduce this notion of self-organization so I think without",
    "start": "3462680",
    "end": "3468619"
  },
  {
    "text": "question one really important thing you need to do is to be able to infer the",
    "start": "3468619",
    "end": "3474259"
  },
  {
    "text": "goals and strategies of other agents by observing them that's a fundamental skill we need to be able to learn to to",
    "start": "3474259",
    "end": "3481549"
  },
  {
    "text": "embed into the agent so if for example you have two agents one of them is doing something and the other agent says well",
    "start": "3481549",
    "end": "3487069"
  },
  {
    "text": "that's really cool I want to be able to do that too and you go and do that and so I'd say that this is a very important component in",
    "start": "3487069",
    "end": "3492950"
  },
  {
    "text": "terms of second every word oh you see what they do you infer the reward and",
    "start": "3492950",
    "end": "3499010"
  },
  {
    "text": "now we have a knob which says you see what they're doing now go and try to do the same thing let's say this this is as far as I know",
    "start": "3499010",
    "end": "3506060"
  },
  {
    "text": "as far as I know this is was one of the important ways in which humans are quite",
    "start": "3506060",
    "end": "3511970"
  },
  {
    "text": "different from other animals in way which in the like scale and scope in",
    "start": "3511970",
    "end": "3520069"
  },
  {
    "text": "which we copy the behavior of other humans might ask a quick follow-up work go for it so that's kind of obvious how",
    "start": "3520069",
    "end": "3527060"
  },
  {
    "text": "that works in the scope of competition but what about just sort of arbitrary tasks like I'm in a math class for",
    "start": "3527060",
    "end": "3532400"
  },
  {
    "text": "someone and I see someone doing a problem a particular way and I go that's a good strategy maybe I should try that out how does that work in a sort of non",
    "start": "3532400",
    "end": "3538790"
  },
  {
    "text": "competitive environment so I think that this will be I think that's going to be a little bit separate from the",
    "start": "3538790",
    "end": "3545060"
  },
  {
    "text": "competitive environment but it will have to be somehow either way you know",
    "start": "3545060",
    "end": "3551750"
  },
  {
    "text": "probably baked in maybe volved into the system where like if you have other",
    "start": "3551750",
    "end": "3557660"
  },
  {
    "text": "agents doing things they're generating data which you observe and the only way",
    "start": "3557660",
    "end": "3562790"
  },
  {
    "text": "to truly make sense of the data that you see is to infer the goal of the agent the strategy their belief state that's",
    "start": "3562790",
    "end": "3569900"
  },
  {
    "text": "important also for communicating them if you want to successfully communicate with someone you have to keep track both",
    "start": "3569900",
    "end": "3575000"
  },
  {
    "text": "of their goal and of their belief state instead of knowledge so I think you will find that there are many I guess",
    "start": "3575000",
    "end": "3580819"
  },
  {
    "text": "connections between understanding what other agents are doing inferring their goals imitating them and community",
    "start": "3580819",
    "end": "3587569"
  },
  {
    "text": "successfully communicating them all right let's give in the happy hour a big hand [Applause]",
    "start": "3587569",
    "end": "3595000"
  },
  {
    "text": "you [Applause]",
    "start": "3595000",
    "end": "3600268"
  },
  {
    "text": "you",
    "start": "3605800",
    "end": "3607860"
  }
]
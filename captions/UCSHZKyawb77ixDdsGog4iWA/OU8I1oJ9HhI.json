[
  {
    "text": "okay so today I'm going to briefly introduce you tno how to use it and go",
    "start": "1159",
    "end": "8970"
  },
  {
    "text": "over the basic principles behind the libraries and if you paid attention during yesterday's presentation of",
    "start": "8970",
    "end": "15870"
  },
  {
    "text": "tensor flow some concepts will be familiar to you as well and if you paid",
    "start": "15870",
    "end": "21330"
  },
  {
    "text": "attention to you go lava Shell's introduction area talk you'll see some",
    "start": "21330",
    "end": "28160"
  },
  {
    "text": "some serie concept as well so there's going to be four main parts so the first",
    "start": "28160",
    "end": "35460"
  },
  {
    "text": "one is well this slide and introduction about what the concept of Tiano are",
    "start": "35460",
    "end": "41670"
  },
  {
    "text": "there is a companion ipython notebook that's on github so if you go on that",
    "start": "41670",
    "end": "49140"
  },
  {
    "text": "page or clone that github repository there is an eye Python notebook that",
    "start": "49140",
    "end": "54570"
  },
  {
    "text": "basically has all the code snippets from these slides so that you can run them at",
    "start": "54570",
    "end": "62340"
  },
  {
    "text": "the same time then we're going to have a more hands-on example basically applying",
    "start": "62340",
    "end": "68400"
  },
  {
    "text": "logistic regression on the Emnes digits data set and then if we have time we'll",
    "start": "68400",
    "end": "76170"
  },
  {
    "text": "go quickly over to more examples concepts so the basic Linette",
    "start": "76170",
    "end": "81600"
  },
  {
    "text": "architecture and an STM for character level generation of text so Tiano is we",
    "start": "81600",
    "end": "94829"
  },
  {
    "text": "can say mathematical symbolic expression compiler so what does that mean it means",
    "start": "94829",
    "end": "99990"
  },
  {
    "text": "that it makes it possible to define expressions that represent mathematical",
    "start": "99990",
    "end": "105659"
  },
  {
    "text": "expression using numpy syntax so it's",
    "start": "105659",
    "end": "110670"
  },
  {
    "text": "easy to use and it supports all the kind of basic mathematical operations like",
    "start": "110670",
    "end": "117590"
  },
  {
    "text": "main max addition subtraction all the kind of basic things not only larger",
    "start": "117590",
    "end": "127250"
  },
  {
    "text": "blocks like layers of neural nets whole networks or things like that it",
    "start": "127250",
    "end": "133920"
  },
  {
    "text": "makes it possible to manipulate those expressions during rough substitutions",
    "start": "133920",
    "end": "139970"
  },
  {
    "text": "cloning and replacement things like that and also making possible to go through",
    "start": "139970",
    "end": "146220"
  },
  {
    "text": "that graph and perform things like automatic differentiation a symbolic",
    "start": "146220",
    "end": "152730"
  },
  {
    "text": "differentiation actually all the our operator for forward differentiation",
    "start": "152730",
    "end": "158630"
  },
  {
    "text": "applying some optimizations for increased numerical stability and then",
    "start": "158630",
    "end": "164930"
  },
  {
    "text": "it's possible to use that optimized graph and the Endo's runtime to actually",
    "start": "164930",
    "end": "173190"
  },
  {
    "text": "compute some values some output values even inputs we also have a couple of",
    "start": "173190",
    "end": "178980"
  },
  {
    "text": "tools that help debug both pianos code",
    "start": "178980",
    "end": "184950"
  },
  {
    "text": "and the users code and try to inspect and understand better what's actually happening when you're using Tianna",
    "start": "184950",
    "end": "192920"
  },
  {
    "text": "so when I was currently more than 8 years old it started small with only a couple of",
    "start": "192920",
    "end": "200940"
  },
  {
    "text": "contributors from the ancestor of Mila and which was called Lisa at the time",
    "start": "200940",
    "end": "209100"
  },
  {
    "text": "and it grew a lot we now have contributors from all over the world users from all over the world",
    "start": "209100",
    "end": "215070"
  },
  {
    "text": "and it's been used to drive a lot of research papers prototypes for",
    "start": "215070",
    "end": "220200"
  },
  {
    "text": "industrial application in startups and in larger companies tno has also been",
    "start": "220200",
    "end": "230400"
  },
  {
    "text": "the base of other software projects that build on top of the nose so for instance",
    "start": "230400",
    "end": "236750"
  },
  {
    "text": "blocks Kara's Lezyne our machine learning deep learning libraries that",
    "start": "236750",
    "end": "242489"
  },
  {
    "text": "used ya know as a back-end and provides user interface that is a higher level so",
    "start": "242489",
    "end": "252030"
  },
  {
    "text": "that has concepts of layers of training algorithms of this kind of things",
    "start": "252030",
    "end": "257820"
  },
  {
    "text": "whereas ya know is modern backends SK don't ya know as well which is nice",
    "start": "257820",
    "end": "263300"
  },
  {
    "text": "because it has a converter to load cafe models from the cafe zoo and use them in",
    "start": "263300",
    "end": "270229"
  },
  {
    "text": "Tiano and does a lot of other things as well pi MC 3 actually uses t anode not to do",
    "start": "270229",
    "end": "276650"
  },
  {
    "text": "machine learning but for ballistic programming and we have two other",
    "start": "276650",
    "end": "283250"
  },
  {
    "text": "libraries platoon that Mira is developing and TN o MP I developed a 12",
    "start": "283250",
    "end": "288729"
  },
  {
    "text": "with our layers on top of T and O to help train on multiple machines multiple",
    "start": "288729",
    "end": "294590"
  },
  {
    "text": "GPUs and have some level of model parallelism and data parallelism so how",
    "start": "294590",
    "end": "304340"
  },
  {
    "text": "to use TN well first of all we are working with symbolic expression",
    "start": "304340",
    "end": "313219"
  },
  {
    "text": "symbolic variables so that will make up",
    "start": "313219",
    "end": "318289"
  },
  {
    "text": "a computation graph so let's see how how to do that so to define the symbolic",
    "start": "318289",
    "end": "325340"
  },
  {
    "text": "expression so we defined the expression first then we want to compile a function",
    "start": "325340",
    "end": "331250"
  },
  {
    "text": "and then execute that function on values so to define the expression we start by",
    "start": "331250",
    "end": "336500"
  },
  {
    "text": "defining inputs so the inputs are symbolic variables that have some type",
    "start": "336500",
    "end": "342349"
  },
  {
    "text": "so you have to define in advance whether like this variable is like a vector or",
    "start": "342349",
    "end": "347860"
  },
  {
    "text": "matrix what's its data type is floating-point integers and so on so things like the",
    "start": "347860",
    "end": "357319"
  },
  {
    "text": "number of dimensions have to be known in advance but the shape is not fixed the",
    "start": "357319",
    "end": "363620"
  },
  {
    "text": "memory layout is not fixed so you could have shapes that change between like 1",
    "start": "363620",
    "end": "370009"
  },
  {
    "text": "mini-batch and the next or different calls to do to the function in general so x and y are purely symbolic variables",
    "start": "370009",
    "end": "378199"
  },
  {
    "text": "here we will give them values later but",
    "start": "378199",
    "end": "383629"
  },
  {
    "text": "for now that's just that's just empty there's another kind of input variables",
    "start": "383629",
    "end": "389060"
  },
  {
    "text": "that is share variables and they they're symbolic but they also hold",
    "start": "389060",
    "end": "394919"
  },
  {
    "text": "a value and that value is persistent across function calls it's shared",
    "start": "394919",
    "end": "400080"
  },
  {
    "text": "between different IANA functions it's usually used for instance for storing",
    "start": "400080",
    "end": "406409"
  },
  {
    "text": "parameters of the model that you want to learn and yet these values can be updated as well so here we create two",
    "start": "406409",
    "end": "415409"
  },
  {
    "text": "other variables from social variables from from values this one has two",
    "start": "415409",
    "end": "421379"
  },
  {
    "text": "dimensions because its initial values after dimensions and this one has only",
    "start": "421379",
    "end": "427139"
  },
  {
    "text": "one so that's basically weight matrix and the bias we can name variables by assigning to the name attribute short",
    "start": "427139",
    "end": "436139"
  },
  {
    "text": "variable do not have a fixed side either there are usually kept fixed in most",
    "start": "436139",
    "end": "441180"
  },
  {
    "text": "models but it's not a requirement then from these inputs we can define",
    "start": "441180",
    "end": "447479"
  },
  {
    "text": "expressions that will build new variables intermediate variables which are the result of some computation and",
    "start": "447479",
    "end": "454729"
  },
  {
    "text": "so for instance here we can define well the product of X and W at the bias apply",
    "start": "454729",
    "end": "464669"
  },
  {
    "text": "sigmoid function on that and they say this is our output variable and from the",
    "start": "464669",
    "end": "470340"
  },
  {
    "text": "output Y ball and Y we can define just say the squared error cost so those new",
    "start": "470340",
    "end": "482400"
  },
  {
    "text": "variables are connected to the previous ones through the operations that we define and we can visualize the graph",
    "start": "482400",
    "end": "489990"
  },
  {
    "text": "structure like that by using for instance by dot print which is a helper function so variables are those square",
    "start": "489990",
    "end": "497639"
  },
  {
    "text": "boxes and we have other nodes here we call apply nodes that represent the",
    "start": "497639",
    "end": "502860"
  },
  {
    "text": "mathematical operation that connects them so input variables and shared",
    "start": "502860",
    "end": "509069"
  },
  {
    "text": "variables do not have any ancestors they don't have any road connecting from them",
    "start": "509069",
    "end": "516180"
  },
  {
    "text": "but then you see that intermediate result and and more of them",
    "start": "516180",
    "end": "523020"
  },
  {
    "text": "usually when we visualize we don't necessarily care about all the",
    "start": "523020",
    "end": "528250"
  },
  {
    "text": "intermediate variables unless they have a name or something and so this is a simplified version of exactly the same",
    "start": "528250",
    "end": "534850"
  },
  {
    "text": "the same graph where we hide the unnamed intermediate variables but you can still see all the operations and actually you",
    "start": "534850",
    "end": "542470"
  },
  {
    "text": "see that the type on the edges so once",
    "start": "542470",
    "end": "548410"
  },
  {
    "text": "you have defined some graph say your forward computation for your model we",
    "start": "548410",
    "end": "555550"
  },
  {
    "text": "want to be able to use back propagation to to get your idioms so this is just",
    "start": "555550",
    "end": "563020"
  },
  {
    "text": "the basic concept of the chain rule we have a scalar crossed we have",
    "start": "563020",
    "end": "569550"
  },
  {
    "text": "intermediate variables that here are vectors here's just the general starting",
    "start": "569550",
    "end": "577060"
  },
  {
    "text": "from the from the cost and so the whole",
    "start": "577060",
    "end": "582340"
  },
  {
    "text": "derivative of say that that function G is actually a whole Jacobian matrix",
    "start": "582340",
    "end": "589690"
  },
  {
    "text": "that's M by n if the intermediate variables are vectors of size N and M",
    "start": "589690",
    "end": "597070"
  },
  {
    "text": "and usually you don't need that and it's actually usually a bad idea to compute",
    "start": "597070",
    "end": "603010"
  },
  {
    "text": "it explicitly unless you need it for some other purposes what the only thing you need is an expression that given any",
    "start": "603010",
    "end": "610870"
  },
  {
    "text": "vector representing the gradient of the cost with respect to the output will",
    "start": "610870",
    "end": "616750"
  },
  {
    "text": "compute you the gradient of the cost with respect to the input so basically",
    "start": "616750",
    "end": "622450"
  },
  {
    "text": "the dot product between that vector and the whole Jacobian matrix so that's also",
    "start": "622450",
    "end": "627670"
  },
  {
    "text": "called the L operator sometimes and so almost all operations in Tiano implement",
    "start": "627670",
    "end": "636970"
  },
  {
    "text": "a function that returns that and it",
    "start": "636970",
    "end": "642070"
  },
  {
    "text": "actually returns not numbers not a numerical expression for that but it",
    "start": "642070",
    "end": "647890"
  },
  {
    "text": "returns a symbolic expression that represents that computation",
    "start": "647890",
    "end": "654320"
  },
  {
    "text": "again usually without having to explicitly represent or define that",
    "start": "654320",
    "end": "659600"
  },
  {
    "text": "whole Jacobian matrix so you can call",
    "start": "659600",
    "end": "665990"
  },
  {
    "text": "Tia no grant which will back propagate through the graph from the cost towards",
    "start": "665990",
    "end": "673190"
  },
  {
    "text": "the inputs that that you give and along the way it will call that grad method of",
    "start": "673190",
    "end": "679460"
  },
  {
    "text": "each operation back propagating means starting from one for the cost and back propagating through the whole graph",
    "start": "679460",
    "end": "686150"
  },
  {
    "text": "accumulating when you have the same variables that used more than once and",
    "start": "686150",
    "end": "691310"
  },
  {
    "text": "so on and again here so DCW and this is DB they are symbolic expression the same",
    "start": "691310",
    "end": "699200"
  },
  {
    "text": "way as if you had manually defined the gradient expression using T&O operations",
    "start": "699200",
    "end": "706040"
  },
  {
    "text": "like the dot product the sigmoid and so on that we that we've seen earlier so we",
    "start": "706040",
    "end": "711140"
  },
  {
    "text": "have non numerical values at that point and they are part of the computation",
    "start": "711140",
    "end": "716780"
  },
  {
    "text": "graph so the completion graph was extended to add these these variables",
    "start": "716780",
    "end": "723830"
  },
  {
    "text": "and we can continue extending the graph from these variables for instance to",
    "start": "723830",
    "end": "730130"
  },
  {
    "text": "compute update expressions corresponding to gradient descent something like that like we do here so for instance this is",
    "start": "730130",
    "end": "737860"
  },
  {
    "text": "what the extended graph for the gradient looks like so you see there's like a lot",
    "start": "737860",
    "end": "745190"
  },
  {
    "text": "of small operations that have been inserted and outputs you have actually",
    "start": "745190",
    "end": "750350"
  },
  {
    "text": "here the gradients with respect to the bias which is both an output and an",
    "start": "750350",
    "end": "755870"
  },
  {
    "text": "intermediate result that will help compute the gradient with respect to the",
    "start": "755870",
    "end": "761150"
  },
  {
    "text": "weights and here's the graph or the",
    "start": "761150",
    "end": "766580"
  },
  {
    "text": "update expressions so you have as intermediate as intermediate variables",
    "start": "766580",
    "end": "772910"
  },
  {
    "text": "the gradients that we had on the previous slide and then this uses the scaled version",
    "start": "772910",
    "end": "779250"
  },
  {
    "text": "with constant 0.1 that's somewhere so",
    "start": "779250",
    "end": "784320"
  },
  {
    "text": "once we have defined the whole graph the whole expression that we actually care",
    "start": "784320",
    "end": "789420"
  },
  {
    "text": "about from the input and initial weights to the weight updates for our training",
    "start": "789420",
    "end": "797400"
  },
  {
    "text": "algorithm we want to compile a function that we'll be able to actually compute",
    "start": "797400",
    "end": "803820"
  },
  {
    "text": "those numbers given inputs and perform the weight updates so to compute values",
    "start": "803820",
    "end": "809630"
  },
  {
    "text": "what we do is called Tiano dot function and you provide it with the input",
    "start": "809630",
    "end": "816240"
  },
  {
    "text": "variables that you want to feel and the output variables that you want to get and you don't have necessarily to",
    "start": "816240",
    "end": "822240"
  },
  {
    "text": "provide values for all the inputs that you might have declared especially if",
    "start": "822240",
    "end": "828750"
  },
  {
    "text": "you don't want to go all the way through the end of the graph you can have a",
    "start": "828750",
    "end": "834150"
  },
  {
    "text": "function that only computes sub set expression for a subset of the graph for",
    "start": "834150",
    "end": "839310"
  },
  {
    "text": "instance we can have a predict function here that goes only from X to out we don't need values from Y we don't need",
    "start": "839310",
    "end": "846830"
  },
  {
    "text": "and so the gradient and so on will not be computed it's just going to take a",
    "start": "846830",
    "end": "854040"
  },
  {
    "text": "small part of the graph and make a function out of it so so that's it you",
    "start": "854040",
    "end": "861510"
  },
  {
    "text": "can first compile it get value and call it so you have to provide values for all",
    "start": "861510",
    "end": "867840"
  },
  {
    "text": "the input variables that that you define you don't have to provide values for",
    "start": "867840",
    "end": "873120"
  },
  {
    "text": "shared variables W and B that we declared earlier there are implicit inputs to all the functions and their",
    "start": "873120",
    "end": "880500"
  },
  {
    "text": "value will automatically be be fetched when it's needed can declare other",
    "start": "880500",
    "end": "887220"
  },
  {
    "text": "functions like monitoring function that computes both the output and the cost so",
    "start": "887220",
    "end": "892860"
  },
  {
    "text": "you have two output you also need the second input Y you can compute the",
    "start": "892860",
    "end": "900020"
  },
  {
    "text": "function that does not start from the beginning like for instance I want an error function that only computes the",
    "start": "900020",
    "end": "907970"
  },
  {
    "text": "the mismatch between the prediction and the actual targets then I don't have to",
    "start": "907970",
    "end": "913310"
  },
  {
    "text": "start from the input I can just start from the prediction and compute the cost",
    "start": "913310",
    "end": "918340"
  },
  {
    "text": "then the next thing that you might we want to do is update your Bibles for",
    "start": "918340",
    "end": "924860"
  },
  {
    "text": "training it's necessary and again you can pass duty and functions updates a",
    "start": "924860",
    "end": "932180"
  },
  {
    "text": "list of updates and updates are pairs of shared variable and the symbolic",
    "start": "932180",
    "end": "937310"
  },
  {
    "text": "expression that will compute the new value for that shared Bible so you can",
    "start": "937310",
    "end": "944330"
  },
  {
    "text": "see a big W and up they'd be here as implicit outputs of the function like W",
    "start": "944330",
    "end": "950540"
  },
  {
    "text": "and B were implicit inputs update W update B are implicit outputs that will compute it that will be completed at the",
    "start": "950540",
    "end": "957320"
  },
  {
    "text": "same time as C and then after all the outputs are computed the updates are",
    "start": "957320",
    "end": "963010"
  },
  {
    "text": "actually effective and the values are updated so here if we print the value of",
    "start": "963010",
    "end": "972500"
  },
  {
    "text": "B before and after having calling after",
    "start": "972500",
    "end": "978080"
  },
  {
    "text": "having called the same function then we see the value has changed what happens",
    "start": "978080",
    "end": "985400"
  },
  {
    "text": "also during graph compilation is that the graph that we selected for that",
    "start": "985400",
    "end": "992600"
  },
  {
    "text": "particular function gets optimized and what we mean by that is that it's going",
    "start": "992600",
    "end": "998690"
  },
  {
    "text": "to be rewritten in parts there are some expressions that will be substituted and so on and there are different different",
    "start": "998690",
    "end": "1008530"
  },
  {
    "text": "goals for that some are quite simple that for instance if we have the same computation being",
    "start": "1008530",
    "end": "1017230"
  },
  {
    "text": "defined twice we only want it to be executed once if you have expressions",
    "start": "1017230",
    "end": "1022480"
  },
  {
    "text": "that are not necessary you don't want to compute them at all for instance if you have X divided by X you don't know and",
    "start": "1022480",
    "end": "1030160"
  },
  {
    "text": "and X is not used anywhere else we just want to replace that by one there are",
    "start": "1030160",
    "end": "1035980"
  },
  {
    "text": "numerical stability optimizations for instance well log of one plus",
    "start": "1035980",
    "end": "1041409"
  },
  {
    "text": "can under fill' if X is really small and this would give 0 whereas which would be",
    "start": "1041409",
    "end": "1047769"
  },
  {
    "text": "close to X things like log of softmax get optimized into more stable locks of",
    "start": "1047769",
    "end": "1055120"
  },
  {
    "text": "Max operation it's also the time where in place and destructive operations are",
    "start": "1055120",
    "end": "1060970"
  },
  {
    "text": "inserted for instance if an operation is the last to be executed on some numbers it can instead of allocating output",
    "start": "1060970",
    "end": "1068080"
  },
  {
    "text": "memory I can just work in place on its input and so on also the transfer of the",
    "start": "1068080",
    "end": "1076120"
  },
  {
    "text": "graph expression to the GPU is due is done during the optimization phase so by",
    "start": "1076120",
    "end": "1084490"
  },
  {
    "text": "default Kanno tries to apply most of the optimizations so that you have the run",
    "start": "1084490",
    "end": "1091539"
  },
  {
    "text": "time that's almost as fast as possible except for a couple of checks and assertions but if you're iterating and",
    "start": "1091539",
    "end": "1098289"
  },
  {
    "text": "want fast feedback and don't care that much about Timothy about the runtime",
    "start": "1098289",
    "end": "1105759"
  },
  {
    "text": "speed then you have a couple of ways of enabling and disabling some set of",
    "start": "1105759",
    "end": "1111539"
  },
  {
    "text": "optimizations and you can do that either globally or function by function so to",
    "start": "1111539",
    "end": "1120789"
  },
  {
    "text": "have a look at for instance what happens during the the graph up to my different",
    "start": "1120789",
    "end": "1125889"
  },
  {
    "text": "phase here's the the original and optimized graph going from the inputs X",
    "start": "1125889",
    "end": "1133840"
  },
  {
    "text": "and W going to the output prediction it's the same one that we've seen before",
    "start": "1133840",
    "end": "1139570"
  },
  {
    "text": "and if we compare that with the function the compile function that goes from",
    "start": "1139570",
    "end": "1146759"
  },
  {
    "text": "these input variables to out which was called predicts this is what we have I",
    "start": "1146759",
    "end": "1152320"
  },
  {
    "text": "won't go into details about what's happening in there but here you have a gem G operation which basically calls an",
    "start": "1152320",
    "end": "1160809"
  },
  {
    "text": "optimized Blas routine that can also",
    "start": "1160809",
    "end": "1166580"
  },
  {
    "text": "do multiplication and accumulation at the same time we have a sigmoid",
    "start": "1166580",
    "end": "1172350"
  },
  {
    "text": "operation here can will work in place destructively on its input which is",
    "start": "1172350",
    "end": "1177660"
  },
  {
    "text": "denoted by the red arrow here if you have a look at for instance the",
    "start": "1177660",
    "end": "1184100"
  },
  {
    "text": "operation optimized graph completing the expression for the updated W and B this",
    "start": "1184100",
    "end": "1191010"
  },
  {
    "text": "was the original one and the optimized one is much smaller",
    "start": "1191010",
    "end": "1196950"
  },
  {
    "text": "it has also in place operations it has fused LM wise operations like for",
    "start": "1196950",
    "end": "1204870"
  },
  {
    "text": "instance if you have a whole tensor and then you do an element-wise a addition",
    "start": "1204870",
    "end": "1210390"
  },
  {
    "text": "with with a constant and then a sigma eight and then something else and so on you want to only loop once through the",
    "start": "1210390",
    "end": "1217110"
  },
  {
    "text": "array and apply all these carrier operations on each element and then go",
    "start": "1217110",
    "end": "1222299"
  },
  {
    "text": "to the next and so on and not iterate each time that you want to apply a new new person and those kind of things",
    "start": "1222299",
    "end": "1228480"
  },
  {
    "text": "happen often when you have automatically generated gradient expressions oh and",
    "start": "1228480",
    "end": "1236250"
  },
  {
    "text": "here you see the update for the shared eyeballs which are inputs so you see the",
    "start": "1236250",
    "end": "1242280"
  },
  {
    "text": "cost and the implicit outputs for the updated wnb here and here another",
    "start": "1242280",
    "end": "1250620"
  },
  {
    "text": "graphitization tool that exists is the back print which basically prints",
    "start": "1250620",
    "end": "1255780"
  },
  {
    "text": "text-based tree like structure of of the graph assigning arbitrary ids and",
    "start": "1255780",
    "end": "1261750"
  },
  {
    "text": "printing the variable names and so on so",
    "start": "1261750",
    "end": "1267770"
  },
  {
    "text": "here you can see more in detail like what the structure is and you see the",
    "start": "1267770",
    "end": "1273240"
  },
  {
    "text": "inputs of gmv and the scaling parameters and so on so when the function is",
    "start": "1273240",
    "end": "1279900"
  },
  {
    "text": "compiled then we can actually run it so T no function is call a ball python",
    "start": "1279900",
    "end": "1286799"
  },
  {
    "text": "objects that that we can that we can call and we've seen those examples",
    "start": "1286799",
    "end": "1296340"
  },
  {
    "text": "here for instance where we call train and so on but what happens to have say",
    "start": "1296340",
    "end": "1308280"
  },
  {
    "text": "optimized run time it's not only the degree of optimizations but we also",
    "start": "1308280",
    "end": "1316420"
  },
  {
    "text": "generate C++ or CUDA code for instance for the LMS loop fusion that I mentioned",
    "start": "1316420",
    "end": "1324420"
  },
  {
    "text": "we can't know in advance which elementwise operation will be will occur",
    "start": "1324420",
    "end": "1330760"
  },
  {
    "text": "in which order in any drive that the user might define so we have on-the-fly",
    "start": "1330760",
    "end": "1338650"
  },
  {
    "text": "code generations for that you generate Python module written in C++ or in CUDA",
    "start": "1338650",
    "end": "1344950"
  },
  {
    "text": "that gets compiled and imported back so that we can use it from Python the",
    "start": "1344950",
    "end": "1350290"
  },
  {
    "text": "runtime environment then calls in the",
    "start": "1350290",
    "end": "1356590"
  },
  {
    "text": "right order the different operations that have to be executed from the inputs to the outputs so that we so that we get",
    "start": "1356590",
    "end": "1364230"
  },
  {
    "text": "the desired results we have a couple of different ones and in particular there's",
    "start": "1364230",
    "end": "1370900"
  },
  {
    "text": "one which was written in C++ which avoids having to switch contacts between",
    "start": "1370900",
    "end": "1375910"
  },
  {
    "text": "the Python interpreter and the C++ execution engine something else that's",
    "start": "1375910",
    "end": "1383260"
  },
  {
    "text": "really crucial for speed and performance is GPU so how to use a GPU in TN oh we",
    "start": "1383260",
    "end": "1390850"
  },
  {
    "text": "wanted to make it as simple as possible in usual cases so now it supports a",
    "start": "1390850",
    "end": "1401070"
  },
  {
    "text": "couple of different data types not only float 32 but double precision",
    "start": "1401070",
    "end": "1406480"
  },
  {
    "text": "if you really need that integers as well and we have now easier interaction with",
    "start": "1406480",
    "end": "1415059"
  },
  {
    "text": "GPU arrays from Python itself so you can just use Python code to handle GP arrays",
    "start": "1415059",
    "end": "1421240"
  },
  {
    "text": "outside of a Tiano function if you'd like all of that he will be in",
    "start": "1421240",
    "end": "1427510"
  },
  {
    "text": "future 0.9 release that we hope to get out soon and to use it well you select",
    "start": "1427510",
    "end": "1435040"
  },
  {
    "text": "the device that you want to use the primary device that you want to use with",
    "start": "1435040",
    "end": "1440650"
  },
  {
    "text": "just the configuration flag for instance you could to get the first GPU that's",
    "start": "1440650",
    "end": "1446920"
  },
  {
    "text": "available or one specific one and if you specify that in the configuration then",
    "start": "1446920",
    "end": "1453850"
  },
  {
    "text": "all share variable will by default be created in GPU memory and the",
    "start": "1453850",
    "end": "1460660"
  },
  {
    "text": "optimizations that move the computation from CPU to GPU so that replace the CPU",
    "start": "1460660",
    "end": "1466510"
  },
  {
    "text": "operation by GPU operations are going to be applied usually you want to make sure",
    "start": "1466510",
    "end": "1474580"
  },
  {
    "text": "you use 432 or even float16 for storage which is experimental but because most",
    "start": "1474580",
    "end": "1481960"
  },
  {
    "text": "GPUs don't have a good performance for for for double precision so how you set",
    "start": "1481960",
    "end": "1489970"
  },
  {
    "text": "those configuration flags you have in order that you never see configuration",
    "start": "1489970",
    "end": "1496600"
  },
  {
    "text": "file that you can it's just basic configuration file from for for Python",
    "start": "1496600",
    "end": "1502120"
  },
  {
    "text": "you have an environment variable where you can define those and the environment variable overrides the config file and",
    "start": "1502120",
    "end": "1508570"
  },
  {
    "text": "you can also set things directly from Python but some flags have to be known",
    "start": "1508570",
    "end": "1514660"
  },
  {
    "text": "in advance before you know is is imported so for instance the device",
    "start": "1514660",
    "end": "1520420"
  },
  {
    "text": "itself you have to set it either in the configuration file or throw flags",
    "start": "1520420",
    "end": "1528600"
  },
  {
    "text": "so I'm going to quickly go over more advanced topics and if you want to learn",
    "start": "1535860",
    "end": "1541019"
  },
  {
    "text": "more about that there's other tutorials available online and there's a documentation on the planning up net so",
    "start": "1541019",
    "end": "1550559"
  },
  {
    "text": "to have loops in the graph we've seen that the expression graph is basically a",
    "start": "1550559",
    "end": "1555720"
  },
  {
    "text": "directed acyclic graph and we cannot have loops in there one way if you know",
    "start": "1555720",
    "end": "1563519"
  },
  {
    "text": "if you know in advance the number of iterations it's just to unroll the loop use a for loop in Python that builds all",
    "start": "1563519",
    "end": "1570090"
  },
  {
    "text": "the nodes for all the time steps it doesn't work if you want for instance",
    "start": "1570090",
    "end": "1575190"
  },
  {
    "text": "to have dynamic no dynamic size for the",
    "start": "1575190",
    "end": "1580559"
  },
  {
    "text": "loop for models that generate sequences for instance it can be an issue so what",
    "start": "1580559",
    "end": "1589289"
  },
  {
    "text": "we have for that in India know is called scan and basically it's one node that",
    "start": "1589289",
    "end": "1595049"
  },
  {
    "text": "encapsulate another whole T&O function and that the end of function or step",
    "start": "1595049",
    "end": "1600570"
  },
  {
    "text": "function is going to compute the is going to represent the computation that",
    "start": "1600570",
    "end": "1606779"
  },
  {
    "text": "has to be done at each time step so you have at the end of function that performs the competition for one time",
    "start": "1606779",
    "end": "1613110"
  },
  {
    "text": "step and you have the scan node that calls it in the loop taking care of the",
    "start": "1613110",
    "end": "1619049"
  },
  {
    "text": "bookkeeping of indices and sequences and feeding the right slice at the right point and feeding back the outputs where",
    "start": "1619049",
    "end": "1626760"
  },
  {
    "text": "needed and having that structure makes it also possible to define gradient for",
    "start": "1626760",
    "end": "1633899"
  },
  {
    "text": "that node which is basically another scan node another loop that goes backwards and applies back drops with",
    "start": "1633899",
    "end": "1641220"
  },
  {
    "text": "time and it can be transferred to GPU as well in which case the internal function is going to be transferred to G and",
    "start": "1641220",
    "end": "1648330"
  },
  {
    "text": "recompile on GPU and there's an example of scan in the",
    "start": "1648330",
    "end": "1653690"
  },
  {
    "text": "lsdm example later this is just a small",
    "start": "1653690",
    "end": "1659309"
  },
  {
    "text": "small example but it's we don't really have time for that we also have a",
    "start": "1659309",
    "end": "1665010"
  },
  {
    "text": "visualization debugging and diagnostic tools one of the reason it's important",
    "start": "1665010",
    "end": "1670860"
  },
  {
    "text": "is that in piano like in terms of flow the definition of a function is separate",
    "start": "1670860",
    "end": "1677130"
  },
  {
    "text": "from its execution and if something doesn't work during the execution if you",
    "start": "1677130",
    "end": "1683160"
  },
  {
    "text": "encounter errors and so on then it's not obvious how to connect",
    "start": "1683160",
    "end": "1688200"
  },
  {
    "text": "that from where the expression was actually defined so we try to have",
    "start": "1688200",
    "end": "1696450"
  },
  {
    "text": "infirmity of error messages and we have some completion modes that enable to for",
    "start": "1696450",
    "end": "1702990"
  },
  {
    "text": "instance check for not a number fall out values you can assign test values to the",
    "start": "1702990",
    "end": "1710970"
  },
  {
    "text": "symbolic variables so that each time you create a new symbolic intermediate",
    "start": "1710970",
    "end": "1717750"
  },
  {
    "text": "variable each time you define a new expression then it the test value gets",
    "start": "1717750",
    "end": "1723510"
  },
  {
    "text": "computed and so you can evaluate on one piece of data at the same time as you",
    "start": "1723510",
    "end": "1728880"
  },
  {
    "text": "build a graph which can be useful to detect shape mismatch errors or it's",
    "start": "1728880",
    "end": "1734340"
  },
  {
    "text": "like that it's possible to extend ya know a couple of ways you can create an",
    "start": "1734340",
    "end": "1741660"
  },
  {
    "text": "app just from Python by calling python",
    "start": "1741660",
    "end": "1747090"
  },
  {
    "text": "wrappers for existing efficient libraries you can extend ya know by",
    "start": "1747090",
    "end": "1753120"
  },
  {
    "text": "writing C or CUDA code and you can also add optimizations either for increased",
    "start": "1753120",
    "end": "1760200"
  },
  {
    "text": "numerical stability for instance or for more efficient computation or for",
    "start": "1760200",
    "end": "1765990"
  },
  {
    "text": "introducing your new ops instead of the nave versions that that a user might",
    "start": "1765990",
    "end": "1774590"
  },
  {
    "text": "have used we have a couple of new",
    "start": "1774590",
    "end": "1781530"
  },
  {
    "text": "features that have been recently added to to the analyst I mentioned the new GPU back-end",
    "start": "1781530",
    "end": "1786909"
  },
  {
    "text": "with support for many data types and we've had some performance improvements",
    "start": "1786909",
    "end": "1793380"
  },
  {
    "text": "especially for convolution 2d and 3d and especially on GPU we made some progress",
    "start": "1793380",
    "end": "1802000"
  },
  {
    "text": "on the time of the graph optimization phase and also have introduced new ways",
    "start": "1802000",
    "end": "1810010"
  },
  {
    "text": "of avoiding recompiling the same graph over and over again and we have new diagnostic tools that are quite useful",
    "start": "1810010",
    "end": "1816850"
  },
  {
    "text": "and interactive visualization an interactive graphical ization tool and pdb breakpoints that enables you to",
    "start": "1816850",
    "end": "1823539"
  },
  {
    "text": "monitor a couple of eyeballs and only break if some condition is met rather",
    "start": "1823539",
    "end": "1829360"
  },
  {
    "text": "than monitoring something every time the before for every every piece of data in",
    "start": "1829360",
    "end": "1838690"
  },
  {
    "text": "the future well we're still working on new operations on GPU we still want to",
    "start": "1838690",
    "end": "1845890"
  },
  {
    "text": "wrap more convenient operations for for better performance in particular the",
    "start": "1845890",
    "end": "1852549"
  },
  {
    "text": "basic errand ends should be completed in the following days hopefully someone has",
    "start": "1852549",
    "end": "1859659"
  },
  {
    "text": "been working on that a lot recently we want better support for 3d convolutions",
    "start": "1859659",
    "end": "1865710"
  },
  {
    "text": "still faster optimization and more work on data parallelism as well so what we",
    "start": "1865710",
    "end": "1876130"
  },
  {
    "text": "want to thank well most of my colleagues and main tno developers and people who",
    "start": "1876130",
    "end": "1884280"
  },
  {
    "text": "contributed one way or another to a lab and the software development efforts and",
    "start": "1884280",
    "end": "1890350"
  },
  {
    "text": "of course recognizing the organizers for volley school now yeah so the slides are",
    "start": "1890350",
    "end": "1900820"
  },
  {
    "text": "available online as I mentioned as a companion notebook and now we can start",
    "start": "1900820",
    "end": "1906580"
  },
  {
    "text": "to go and and more resources if you want to go to go further and now I think that",
    "start": "1906580",
    "end": "1912460"
  },
  {
    "text": "it's time to start the practical examples so for",
    "start": "1912460",
    "end": "1919060"
  },
  {
    "text": "those who have not clone the repository yet then this is the command line you",
    "start": "1919060",
    "end": "1927250"
  },
  {
    "text": "want to two nouns for those who had cloned it you might want to do a git",
    "start": "1927250",
    "end": "1932590"
  },
  {
    "text": "ball just to get the latest to make sure we have the latest versions and you can",
    "start": "1932590",
    "end": "1940090"
  },
  {
    "text": "launch Jupiter notebook on the on the",
    "start": "1940090",
    "end": "1946120"
  },
  {
    "text": "repository itself so we have three examples that we are going to go over",
    "start": "1946120",
    "end": "1952590"
  },
  {
    "text": "logistic regression comes net and the rest yeah so I've launched the Jupiter",
    "start": "1952590",
    "end": "1960070"
  },
  {
    "text": "notebook here and let's start with so intro TN o was the companion notebooks",
    "start": "1960070",
    "end": "1966430"
  },
  {
    "text": "there's nothing new in there just the code snippets I've showed your alrighty and okay let's go with a logic",
    "start": "1966430",
    "end": "1975160"
  },
  {
    "text": "regression is that big enough for do we need to increase the font size okay so",
    "start": "1975160",
    "end": "1987820"
  },
  {
    "text": "I'm going to skip over the text because you probably know already about the model we have some we've packaged the",
    "start": "1987820",
    "end": "1997540"
  },
  {
    "text": "amnesty database with the on on github",
    "start": "1997540",
    "end": "2006420"
  },
  {
    "text": "with the repository so let's load the data and here let's see how we define",
    "start": "2006420",
    "end": "2013490"
  },
  {
    "text": "the model so it's basically the same way that we did in in the styles we define",
    "start": "2013490",
    "end": "2022400"
  },
  {
    "text": "sizes that will be useful for the shell variables we define an input variable",
    "start": "2022400",
    "end": "2029010"
  },
  {
    "text": "here it's a matrix because we want to use mini-batches and we have survived",
    "start": "2029010",
    "end": "2036780"
  },
  {
    "text": "balls initialized from zeros then we",
    "start": "2036780",
    "end": "2045600"
  },
  {
    "text": "define the our model so here's our",
    "start": "2045600",
    "end": "2050760"
  },
  {
    "text": "predictor so the probability of the class given the input and we're",
    "start": "2050760",
    "end": "2057929"
  },
  {
    "text": "going to use well so here the fine model",
    "start": "2057929",
    "end": "2064800"
  },
  {
    "text": "and then the softmax on top of it and the prediction if you want to help",
    "start": "2064800",
    "end": "2072540"
  },
  {
    "text": "prediction it's going to be the class of maximum probability so hard max over",
    "start": "2072540",
    "end": "2080300"
  },
  {
    "text": "that axis because we still want one prediction for each element of of the",
    "start": "2080300",
    "end": "2086340"
  },
  {
    "text": "mini batch then we define the loss function so here is going to be the log",
    "start": "2086340",
    "end": "2093750"
  },
  {
    "text": "likelihood of the label given the input or the cross entropy and we define it",
    "start": "2093750",
    "end": "2099960"
  },
  {
    "text": "simply we don't have like we don't need to have one croissants for P or log",
    "start": "2099960",
    "end": "2106080"
  },
  {
    "text": "likelihood operation by itself you can just build it from the basic building",
    "start": "2106080",
    "end": "2112380"
  },
  {
    "text": "blocks so we take the log of the probability you take the index of the",
    "start": "2112380",
    "end": "2119730"
  },
  {
    "text": "actual target and then you take the mean of that to have them in prediction over",
    "start": "2119730",
    "end": "2125850"
  },
  {
    "text": "the mini batch then derived equations",
    "start": "2125850",
    "end": "2132110"
  },
  {
    "text": "derive the update rules so again we don't have like one gradient descent",
    "start": "2132110",
    "end": "2138780"
  },
  {
    "text": "objects or something like that we just build whatever rule we we want so yeah",
    "start": "2138780",
    "end": "2149400"
  },
  {
    "text": "we could use momentum by defining other shape variables that will hold the velocity and then you have that",
    "start": "2149400",
    "end": "2155910"
  },
  {
    "text": "expressions for both the velocity and the survival itself and then we compile",
    "start": "2155910",
    "end": "2165030"
  },
  {
    "text": "a training function going from X&Y outputting the laws and the dating W and",
    "start": "2165030",
    "end": "2171270"
  },
  {
    "text": "B so while the code is getting generated",
    "start": "2171270",
    "end": "2177390"
  },
  {
    "text": "and compiled and the graph is getting optimized let's see the next step well",
    "start": "2177390",
    "end": "2183150"
  },
  {
    "text": "we also want to monitor not only the log-likelihood but actually actually the misclassification",
    "start": "2183150",
    "end": "2190370"
  },
  {
    "text": "rate on validation and test set so it's",
    "start": "2190370",
    "end": "2195980"
  },
  {
    "text": "simply the different like how many elements are different between the",
    "start": "2195980",
    "end": "2202010"
  },
  {
    "text": "prediction which was the arc max and the actual target and the rate is the mean",
    "start": "2202010",
    "end": "2207200"
  },
  {
    "text": "or the mini-batch and we create another we compile another two and a function",
    "start": "2207200",
    "end": "2213850"
  },
  {
    "text": "outputting that and not doing any updates of course so to train the model",
    "start": "2213850",
    "end": "2220370"
  },
  {
    "text": "well first we need to process the data a little bit so we want to feed the model",
    "start": "2220370",
    "end": "2226880"
  },
  {
    "text": "one mini batch of data at a time so here we have simply a generator I mean not",
    "start": "2226880",
    "end": "2232280"
  },
  {
    "text": "really pay attention right over just a helper function that gives us the mini batch number I and it's going to be the",
    "start": "2232280",
    "end": "2238880"
  },
  {
    "text": "same fraction used both for the training and validation and test set",
    "start": "2238880",
    "end": "2244640"
  },
  {
    "text": "we define a couple of parameters for early stopping in that training loop",
    "start": "2244640",
    "end": "2251630"
  },
  {
    "text": "it's not necessary it's just like a way",
    "start": "2251630",
    "end": "2257330"
  },
  {
    "text": "of knowing when to stop and use only like the best model that was encountered",
    "start": "2257330",
    "end": "2263540"
  },
  {
    "text": "during the optimization so let's let's define that and this is the main",
    "start": "2263540",
    "end": "2271100"
  },
  {
    "text": "training loop it's a bit more complex that it might be but it's because we use",
    "start": "2271100",
    "end": "2277310"
  },
  {
    "text": "this early stopping and we want to only validate when we are confident that the",
    "start": "2277310",
    "end": "2284720"
  },
  {
    "text": "training error has gone down enough but basically the the most important part is",
    "start": "2284720",
    "end": "2290000"
  },
  {
    "text": "you loop over the epochs unless unless",
    "start": "2290000",
    "end": "2296300"
  },
  {
    "text": "you encounter the early stopping conditions and then during each epoch",
    "start": "2296300",
    "end": "2302900"
  },
  {
    "text": "you want to loop over the mini batches and call train model then every once in",
    "start": "2302900",
    "end": "2309740"
  },
  {
    "text": "a while you want to validate and print some result of the validation error so",
    "start": "2309740",
    "end": "2316890"
  },
  {
    "text": "here we call test model on the validation set for that and then keep",
    "start": "2316890",
    "end": "2324630"
  },
  {
    "text": "track of what the best model currently is and get the the test error as well",
    "start": "2324630",
    "end": "2333990"
  },
  {
    "text": "and save the best one so to save the best one to save the model we usually",
    "start": "2333990",
    "end": "2341370"
  },
  {
    "text": "just save the values of all parameters which is more robust than trying to pick",
    "start": "2341370",
    "end": "2347640"
  },
  {
    "text": "all the whole Python object and it also enables more easily transferred to other",
    "start": "2347640",
    "end": "2355710"
  },
  {
    "text": "frameworks to visualization frameworks and so on so let's try to execute that",
    "start": "2355710",
    "end": "2362960"
  },
  {
    "text": "so of course it's a simple model the data is not that big so it should it",
    "start": "2363050",
    "end": "2370020"
  },
  {
    "text": "should not take that long so you see",
    "start": "2370020",
    "end": "2377640"
  },
  {
    "text": "that at the beginning well almost at each iteration we are better on the training set and then",
    "start": "2377640",
    "end": "2384870"
  },
  {
    "text": "after a while the progress is slower and",
    "start": "2384870",
    "end": "2390170"
  },
  {
    "text": "okay so just wait a little bit more seems to stall more and more and okay",
    "start": "2393170",
    "end": "2406260"
  },
  {
    "text": "and here it's the end after 96 epochs so",
    "start": "2406260",
    "end": "2411540"
  },
  {
    "text": "now if we want to visualize what filters",
    "start": "2411540",
    "end": "2416790"
  },
  {
    "text": "were learned or what the final train model looks like we just using a helper",
    "start": "2416790",
    "end": "2423720"
  },
  {
    "text": "function call here to visualize the filters it's not really important but",
    "start": "2423720",
    "end": "2429510"
  },
  {
    "text": "here what we use is we call get value on the weights to access the internal value",
    "start": "2429510",
    "end": "2438060"
  },
  {
    "text": "of the shell variable and then we use that to to plot the different filters",
    "start": "2438060",
    "end": "2446250"
  },
  {
    "text": "and we can see it's kind of reasonable like this is the filter for class zero and see",
    "start": "2446250",
    "end": "2453359"
  },
  {
    "text": "kind of like zero one part did what's important for the two is to have like an",
    "start": "2453359",
    "end": "2459690"
  },
  {
    "text": "opening here and so on so yeah if we",
    "start": "2459690",
    "end": "2466529"
  },
  {
    "text": "have a look at the final error well we can see that the training error is well",
    "start": "2466529",
    "end": "2478650"
  },
  {
    "text": "to hit training you know not plotting it but the validation and the test error I are quite high and we know that the",
    "start": "2478650",
    "end": "2487799"
  },
  {
    "text": "human level performance is quite low and the performance of our model is quite low so it really means that the model is",
    "start": "2487799",
    "end": "2494730"
  },
  {
    "text": "too simple and we should use something more advanced so to use something more",
    "start": "2494730",
    "end": "2501150"
  },
  {
    "text": "advanced if you go back to the home of",
    "start": "2501150",
    "end": "2507000"
  },
  {
    "text": "the Jupiter notebook can have a look at the continent and run Lynnette so this",
    "start": "2507000",
    "end": "2520349"
  },
  {
    "text": "new example is basically it's the same data it's still amnesty because it has the other edge of training fast even on",
    "start": "2520349",
    "end": "2527760"
  },
  {
    "text": "an older laptop and but this time we're going to use a completion net we look up",
    "start": "2527760",
    "end": "2534839"
  },
  {
    "text": "all of conclusion layers and then fully connected layers and then the final",
    "start": "2534839",
    "end": "2539849"
  },
  {
    "text": "classifier so I'm going to make for that float X is float 32 here and let's see",
    "start": "2539849",
    "end": "2549420"
  },
  {
    "text": "how we could use Tiano to define helper classes that are layers that can make it",
    "start": "2549420",
    "end": "2557910"
  },
  {
    "text": "easier for a user to compose them if they want to you to replicate some",
    "start": "2557910",
    "end": "2563579"
  },
  {
    "text": "results or use some classical architectures this is done usually in",
    "start": "2563579",
    "end": "2571680"
  },
  {
    "text": "frameworks built on top of Tiano like carrots like blocks like lasagna some",
    "start": "2571680",
    "end": "2577260"
  },
  {
    "text": "people also develop their own mini framework with their own versions of layers and so",
    "start": "2577260",
    "end": "2582740"
  },
  {
    "text": "on that they find useful and intuitive so",
    "start": "2582740",
    "end": "2589040"
  },
  {
    "text": "this logistic regression layer basically holds well parameters weight and bias",
    "start": "2589040",
    "end": "2599590"
  },
  {
    "text": "and compute the well the conditional",
    "start": "2599590",
    "end": "2605420"
  },
  {
    "text": "probability of classes prediction holds the params and have expressions for the",
    "start": "2605420",
    "end": "2613760"
  },
  {
    "text": "negative log likelihood and errors so if you were to use only that class then",
    "start": "2613760",
    "end": "2621550"
  },
  {
    "text": "it's doing essentially the same as what we did by hand in the previous notebook",
    "start": "2621550",
    "end": "2629770"
  },
  {
    "text": "and in the same way we can define a",
    "start": "2629770",
    "end": "2635930"
  },
  {
    "text": "layer that has convolution and pooling so again in the init methods we pass it",
    "start": "2635930",
    "end": "2643940"
  },
  {
    "text": "well filter shape image shape data side of pooling and so on we initialize the",
    "start": "2643940",
    "end": "2650960"
  },
  {
    "text": "weights using the formula from grow and venture at 2010 and buyers from zeros",
    "start": "2650960",
    "end": "2662000"
  },
  {
    "text": "and then from the inputs while we compute to the convolution with the",
    "start": "2662000",
    "end": "2668960"
  },
  {
    "text": "filters we then computes max pooling and output wealth and H of the pooling plus",
    "start": "2668960",
    "end": "2678260"
  },
  {
    "text": "the bias and here the bias is only like one number for each channel so which",
    "start": "2678260",
    "end": "2684620"
  },
  {
    "text": "means that you don't have a different bias for each location in the image so",
    "start": "2684620",
    "end": "2690530"
  },
  {
    "text": "you could actually apply such a layer on images of various size without having to",
    "start": "2690530",
    "end": "2697660"
  },
  {
    "text": "initialize new parameters or return that and then the same way we define the",
    "start": "2697660",
    "end": "2706310"
  },
  {
    "text": "hidden layer which is just a fully connected layer again initializing",
    "start": "2706310",
    "end": "2711500"
  },
  {
    "text": "weight and by and expression going from so the symbolic expression going from the input",
    "start": "2711500",
    "end": "2718310"
  },
  {
    "text": "and the shared variables to the output after activation and again we want to",
    "start": "2718310",
    "end": "2726440"
  },
  {
    "text": "collect the parameters so that we know what we will want to Train and then",
    "start": "2726440",
    "end": "2733990"
  },
  {
    "text": "here's a function that has that the main the main loop in the main training loop",
    "start": "2733990",
    "end": "2739850"
  },
  {
    "text": "so we have a mini batch generator again it's synced as as before and here we are",
    "start": "2739850",
    "end": "2745970"
  },
  {
    "text": "building the whole graph so always the same the same process we define input",
    "start": "2745970",
    "end": "2754970"
  },
  {
    "text": "symbol symbolic input variables matrix and a vector of int here so L vector is",
    "start": "2754970",
    "end": "2761150"
  },
  {
    "text": "a vector of long because the targets here are in this's and not not one Hots",
    "start": "2761150",
    "end": "2768380"
  },
  {
    "text": "vectors or masks or something like that and we create the first layer which is a",
    "start": "2768380",
    "end": "2774350"
  },
  {
    "text": "Linette compo layer with size we want to have the next one with also so yeah here",
    "start": "2774350",
    "end": "2786170"
  },
  {
    "text": "the image size changes this is mostly for efficiency actually you don't really",
    "start": "2786170",
    "end": "2792200"
  },
  {
    "text": "have to to pass that for for those particular models but you still need",
    "start": "2792200",
    "end": "2797870"
  },
  {
    "text": "like the shape of filters I mean you have the filters anyway and then it's",
    "start": "2797870",
    "end": "2805160"
  },
  {
    "text": "useful to have those size still because even if the convolution layers can",
    "start": "2805160",
    "end": "2811490"
  },
  {
    "text": "handle arbitrary sized images then after that we want to flatten the whole the",
    "start": "2811490",
    "end": "2819440"
  },
  {
    "text": "whole feature Maps and feed that into a fully connected layer and then to the projection layer so this one has to be",
    "start": "2819440",
    "end": "2825650"
  },
  {
    "text": "fixed so we have to know what the last comes layer will will have four",
    "start": "2825650",
    "end": "2834620"
  },
  {
    "text": "dimensions and here we here we go a fully connected layer and the output",
    "start": "2834620",
    "end": "2841760"
  },
  {
    "text": "layer that's just logic regression class same as before we want the final cost to",
    "start": "2841760",
    "end": "2849040"
  },
  {
    "text": "be the log likelihood of that we have",
    "start": "2849040",
    "end": "2854309"
  },
  {
    "text": "again the errors which is the misclassification rate parameters or the",
    "start": "2854309",
    "end": "2860079"
  },
  {
    "text": "concatenation of the parameters of all layers and once we have that we can",
    "start": "2860079",
    "end": "2866440"
  },
  {
    "text": "build the gradient so just one call of grad of cost with respect to parameter",
    "start": "2866440",
    "end": "2874079"
  },
  {
    "text": "updates so again just regular SGD but we could",
    "start": "2874079",
    "end": "2879280"
  },
  {
    "text": "have a class or something that performs like momentum a degree that a delta",
    "start": "2879280",
    "end": "2885180"
  },
  {
    "text": "whatever you need compile the function and here we have again the early",
    "start": "2885180",
    "end": "2893050"
  },
  {
    "text": "stopping routine with the same main loop for all a parks until we are done then",
    "start": "2893050",
    "end": "2900130"
  },
  {
    "text": "loop over the mini-batches and validate every once in a while and stop when it's finished so let's just declare that",
    "start": "2900130",
    "end": "2909119"
  },
  {
    "text": "loading the data exactly the same as before and here we can actually run run",
    "start": "2909119",
    "end": "2919720"
  },
  {
    "text": "that so this was the result of a previous run it that took 5 minutes so I",
    "start": "2919720",
    "end": "2929290"
  },
  {
    "text": "will probably not have time to do that but here you can see basically what",
    "start": "2929290",
    "end": "2935619"
  },
  {
    "text": "happens and if you want to run it or try that during the lunch break or or later",
    "start": "2935619",
    "end": "2942299"
  },
  {
    "text": "you're welcome to to play with it and after that yeah you can visualize the",
    "start": "2942299",
    "end": "2952089"
  },
  {
    "text": "the the round filters as well here you you have them for the first layer and",
    "start": "2952089",
    "end": "2961650"
  },
  {
    "text": "for the and here you have the an example of the",
    "start": "2961650",
    "end": "2969580"
  },
  {
    "text": "activations of the first layer for one example so we have just a little bit",
    "start": "2969580",
    "end": "2976810"
  },
  {
    "text": "more time to cover the lsdm tutorial",
    "start": "2976810",
    "end": "2984010"
  },
  {
    "text": "I mean example so if you go back to the",
    "start": "2984010",
    "end": "2989440"
  },
  {
    "text": "home of the Jupiter notebook and go to ASTM",
    "start": "2989440",
    "end": "2995970"
  },
  {
    "text": "then so this model is an SEM network that tries to predict the next character",
    "start": "3002870",
    "end": "3010310"
  },
  {
    "text": "of our sentence given the previous ones so not going to go into details but here",
    "start": "3010310",
    "end": "3022100"
  },
  {
    "text": "you can see that the LSM layer is defined here with like shot variables",
    "start": "3022100",
    "end": "3027680"
  },
  {
    "text": "for all the the matrices that that you",
    "start": "3027680",
    "end": "3034490"
  },
  {
    "text": "need and the different biases for the different gates and so on so you have a",
    "start": "3034490",
    "end": "3039620"
  },
  {
    "text": "lot of parameters it would be possible and sometimes more efficient to actually",
    "start": "3039620",
    "end": "3046760"
  },
  {
    "text": "define say only one variable that contains the concatenation of a couple",
    "start": "3046760",
    "end": "3053330"
  },
  {
    "text": "of matrices and that way you can do more efficient bigger matrix matrix multiply",
    "start": "3053330",
    "end": "3060130"
  },
  {
    "text": "but this is just one one simple implementation and here's an example of",
    "start": "3060130",
    "end": "3068390"
  },
  {
    "text": "how to use scan for the loop so here we define the step function that takes well",
    "start": "3068390",
    "end": "3079880"
  },
  {
    "text": "a couple of different different inputs so you have like the different",
    "start": "3079880",
    "end": "3087410"
  },
  {
    "text": "activation and so on from the previous time steps you have the current sequence",
    "start": "3087410",
    "end": "3092450"
  },
  {
    "text": "input and so on and from them here's basically the DSM formula where you have",
    "start": "3092450",
    "end": "3099500"
  },
  {
    "text": "the dot product and Sigma 8 or 10 H of the different connection inside the cell",
    "start": "3099500",
    "end": "3107600"
  },
  {
    "text": "and in the end you have the hidden and",
    "start": "3107600",
    "end": "3116320"
  },
  {
    "text": "that it so once you have that that's",
    "start": "3116320",
    "end": "3122630"
  },
  {
    "text": "step function is going to be passed to Tiano dot scan where the sequences are",
    "start": "3122630",
    "end": "3130760"
  },
  {
    "text": "the masks and input so the mask is is useful because",
    "start": "3130760",
    "end": "3136420"
  },
  {
    "text": "we're using mini batches of sequences and not all the sequences in the same",
    "start": "3136420",
    "end": "3142310"
  },
  {
    "text": "batch have the same length also for efficiency we usually want to group them with two group example of similar length",
    "start": "3142310",
    "end": "3149840"
  },
  {
    "text": "together but they may not always be exactly the same length so in that case",
    "start": "3149840",
    "end": "3156620"
  },
  {
    "text": "we pad that to only the longest sequence in the mini batch not the longest sequence in the whole set just for the",
    "start": "3156620",
    "end": "3163130"
  },
  {
    "text": "mini batch but we still have to pad and remember like what's the length of the",
    "start": "3163130",
    "end": "3168350"
  },
  {
    "text": "different sequences is in order for us to correctly predict and back propagate",
    "start": "3168350",
    "end": "3173450"
  },
  {
    "text": "so let's define that here we define the",
    "start": "3173450",
    "end": "3182570"
  },
  {
    "text": "cost function that's the categorical cross-entropy of the sequence and here again you see that the mask is used so",
    "start": "3182570",
    "end": "3189950"
  },
  {
    "text": "that we don't consider the predictions after the end of the sequence logistic",
    "start": "3189950",
    "end": "3196670"
  },
  {
    "text": "regression the same as before does the final cost here for processing the data",
    "start": "3196670",
    "end": "3204620"
  },
  {
    "text": "we're using fuel which is another tool being developed by students at Mira and",
    "start": "3204620",
    "end": "3209980"
  },
  {
    "text": "it's nice because it can read from just",
    "start": "3209980",
    "end": "3215570"
  },
  {
    "text": "plain text data do some pre-processing on-the-fly including things that I mentioned earlier like grouping",
    "start": "3215570",
    "end": "3225100"
  },
  {
    "text": "sequences by similar length and then shuffling them and padding and doing all",
    "start": "3225100",
    "end": "3231380"
  },
  {
    "text": "of that and so it outputs like a",
    "start": "3231380",
    "end": "3237200"
  },
  {
    "text": "generator that you can then feed in your main loop through a channel function so",
    "start": "3237200",
    "end": "3243170"
  },
  {
    "text": "that whole processing happens outside of tno and then the processed values are",
    "start": "3243170",
    "end": "3248300"
  },
  {
    "text": "fed into into the channel function so",
    "start": "3248300",
    "end": "3255190"
  },
  {
    "text": "yeah here we build our final key on a graph we have symbolic inputs for well",
    "start": "3255190",
    "end": "3262580"
  },
  {
    "text": "the input and masks we create lsdm layered a lot",
    "start": "3262580",
    "end": "3269730"
  },
  {
    "text": "correct layer define our cost parameters are the concatenation of the parameters",
    "start": "3269730",
    "end": "3276540"
  },
  {
    "text": "of logistic regression and the current layer take the gradients of course with",
    "start": "3276540",
    "end": "3282030"
  },
  {
    "text": "right to all parameters so as I mentioned it's going to use back prop",
    "start": "3282030",
    "end": "3287160"
  },
  {
    "text": "through time to get the gradient through the scan operation the update rule again",
    "start": "3287160",
    "end": "3297630"
  },
  {
    "text": "simple SGD no momentum nothing it's something that you could add if you want to play with it and compile to function",
    "start": "3297630",
    "end": "3305640"
  },
  {
    "text": "to evaluate the model so here the main",
    "start": "3305640",
    "end": "3311340"
  },
  {
    "text": "loop is training and we also have",
    "start": "3311340",
    "end": "3317400"
  },
  {
    "text": "another function that generates one character at a time given the previous ones that's why we will declare like",
    "start": "3317400",
    "end": "3323640"
  },
  {
    "text": "input here and so does that speak function that get probability",
    "start": "3323640",
    "end": "3331230"
  },
  {
    "text": "predictions we normalize them because we are working in float32 and sometimes if you divide by the sum and RISM then it",
    "start": "3331230",
    "end": "3339510"
  },
  {
    "text": "doesn't add up to one so we want a higher precision for just that operation and then try to generate to generate a",
    "start": "3339510",
    "end": "3352830"
  },
  {
    "text": "sequence every once in a while so again this is the result of a previous run so",
    "start": "3352830",
    "end": "3358740"
  },
  {
    "text": "we see in the so for for monitoring we",
    "start": "3358740",
    "end": "3363930"
  },
  {
    "text": "seed that prediction with the meaning of",
    "start": "3363930",
    "end": "3369690"
  },
  {
    "text": "life is and then we let the network generate so if I try to run it now it's",
    "start": "3369690",
    "end": "3375840"
  },
  {
    "text": "going to be long but here's some examples that I generated yesterday in",
    "start": "3375840",
    "end": "3381930"
  },
  {
    "text": "the previous run so it starts with not that much and it has like a couple of",
    "start": "3381930",
    "end": "3389220"
  },
  {
    "text": "unusual characters I mean it's usually it's not usual to have like",
    "start": "3389220",
    "end": "3395670"
  },
  {
    "text": "one Chinese character in the middle of words you have like concentration in the",
    "start": "3395670",
    "end": "3401520"
  },
  {
    "text": "middle of word and so on but then as it as it progresses you see",
    "start": "3401520",
    "end": "3409440"
  },
  {
    "text": "that it's getting slowly better and",
    "start": "3409440",
    "end": "3415230"
  },
  {
    "text": "better and the meaning of life is is the",
    "start": "3415230",
    "end": "3420630"
  },
  {
    "text": "dets and so of course this is not what's",
    "start": "3420630",
    "end": "3425820"
  },
  {
    "text": "going to give you the the actual meaning of life but yeah a tons lot of ham why",
    "start": "3425820",
    "end": "3433349"
  },
  {
    "text": "not and and this is this so so yeah so I",
    "start": "3433349",
    "end": "3444210"
  },
  {
    "text": "interrupted the the training at some point but you can play with it a little",
    "start": "3444210",
    "end": "3450060"
  },
  {
    "text": "bit and here are some suggestions of things you might want to do like better",
    "start": "3450060",
    "end": "3455930"
  },
  {
    "text": "training algorithms different nonlinearities inside the lsdm sell",
    "start": "3455930",
    "end": "3462140"
  },
  {
    "text": "different initialization of weights try to generate something else that the",
    "start": "3462140",
    "end": "3467970"
  },
  {
    "text": "meaning of life is and yeah so I hope I",
    "start": "3467970",
    "end": "3475619"
  },
  {
    "text": "could give you a good introduction of what you know is what it can be used for",
    "start": "3475619",
    "end": "3481619"
  },
  {
    "text": "and what you can build on top of it and if you have if you have any questions",
    "start": "3481619",
    "end": "3488690"
  },
  {
    "text": "later then we have general users mailing",
    "start": "3488690",
    "end": "3494520"
  },
  {
    "text": "lists we are answering questions on Stack Overflow as well and we would be",
    "start": "3494520",
    "end": "3502530"
  },
  {
    "text": "happy to have your feedback",
    "start": "3502530",
    "end": "3506000"
  },
  {
    "text": "have time for a few quick quick questions that's right here could you go to the",
    "start": "3511829",
    "end": "3517390"
  },
  {
    "text": "mic can you just give a quick example of",
    "start": "3517390",
    "end": "3526270"
  },
  {
    "text": "what debugging might look like in Theon Oh could you just break something in there and show us what happens and how you figure out what it was",
    "start": "3526270",
    "end": "3533460"
  },
  {
    "text": "actually yeah I think I had one okay so let's let's go to say a simple simpler",
    "start": "3535650",
    "end": "3543400"
  },
  {
    "text": "example okay so I'm just going to go to the logistic regression 1 and say for",
    "start": "3543400",
    "end": "3552190"
  },
  {
    "text": "instance that when I initialize my thing",
    "start": "3552190",
    "end": "3562690"
  },
  {
    "text": "I don't have the right I don't have the",
    "start": "3562690",
    "end": "3567849"
  },
  {
    "text": "right shape so you can still build the the whole symbolic graph and at the time",
    "start": "3567849",
    "end": "3578040"
  },
  {
    "text": "where you want to actually execute it then you have an error message that",
    "start": "3578040",
    "end": "3587079"
  },
  {
    "text": "tells you shape mismatch X has of Cowen's and some rows but Y has only",
    "start": "3587079",
    "end": "3593859"
  },
  {
    "text": "that number of rows and the apply node that caused the error is that dot",
    "start": "3593859",
    "end": "3600040"
  },
  {
    "text": "product and gives the inputs again and in that case it tells you it's not",
    "start": "3600040",
    "end": "3607900"
  },
  {
    "text": "really able to tell where it was defined but if you remove the optimizations then",
    "start": "3607900",
    "end": "3615849"
  },
  {
    "text": "it might so we can we can do that and we",
    "start": "3615849",
    "end": "3622059"
  },
  {
    "text": "can go back to where the train operation was defined train Model T a new function",
    "start": "3622059",
    "end": "3630579"
  },
  {
    "text": "and then I'll just say optimizer equals none",
    "start": "3630579",
    "end": "3637920"
  },
  {
    "text": "sorry I have to do my Audi calls piano",
    "start": "3642050",
    "end": "3648290"
  },
  {
    "text": "note optimized or not that's correct yes",
    "start": "3648290",
    "end": "3654420"
  },
  {
    "text": "so it's recompiling the function let's",
    "start": "3654420",
    "end": "3660090"
  },
  {
    "text": "record everything",
    "start": "3660090",
    "end": "3662990"
  },
  {
    "text": "and then he updated our message says",
    "start": "3666780",
    "end": "3671810"
  },
  {
    "text": "back-trace when the node was created and it's somewhere in my kernel and it's on",
    "start": "3671810",
    "end": "3679410"
  },
  {
    "text": "the line py given X equals that so of course we have like lots of things in",
    "start": "3679410",
    "end": "3685230"
  },
  {
    "text": "there but you know that there's a dot product and it's probably a mismatch",
    "start": "3685230",
    "end": "3691140"
  },
  {
    "text": "between those so that's that's one example then there are other techniques",
    "start": "3691140",
    "end": "3696960"
  },
  {
    "text": "that we can use we can have the breakpoints as I said and so on I don't",
    "start": "3696960",
    "end": "3702570"
  },
  {
    "text": "have right now tutorial about that but have some one line and I could point you to that I have some models I'd like to",
    "start": "3702570",
    "end": "3714330"
  },
  {
    "text": "distribute and I don't want to require people to install Python and a bunch of compilers and so unfortunately at the",
    "start": "3714330",
    "end": "3726540"
  },
  {
    "text": "time we're pretty intermingled with Python a lot because all the memory",
    "start": "3726540",
    "end": "3733020"
  },
  {
    "text": "management during the execution is done by Python and we use an umpire and",
    "start": "3733020",
    "end": "3738690"
  },
  {
    "text": "arrays for our intermediate values on the CPU and the similar structure on the GPU even though that one might be easier",
    "start": "3738690",
    "end": "3745290"
  },
  {
    "text": "to convert but yeah all our C code deals with Python and does the ink ref and",
    "start": "3745290",
    "end": "3751920"
  },
  {
    "text": "Decker F and so on so that Python manages the memory so if you want to distribute that I would suggest like a",
    "start": "3751920",
    "end": "3760560"
  },
  {
    "text": "docker container something like that recently even for GPU and video docker",
    "start": "3760560",
    "end": "3765690"
  },
  {
    "text": "is quite efficient and we don't have any modest allowance that that we had seen",
    "start": "3765690",
    "end": "3771840"
  },
  {
    "text": "earlier so it's not ideal and if like",
    "start": "3771840",
    "end": "3777000"
  },
  {
    "text": "someone has some time and the wheel to to help us disentangle tno from the",
    "start": "3777000",
    "end": "3785610"
  },
  {
    "text": "Python runtime it would be awesome but that's a use project",
    "start": "3785610",
    "end": "3791089"
  },
  {
    "text": "okay let's thank Pascal again and we",
    "start": "3792800",
    "end": "3799270"
  },
  {
    "text": "reconvene in 55 minutes for the next talk have a good lunch",
    "start": "3799270",
    "end": "3806050"
  }
]
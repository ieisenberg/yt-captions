[
  {
    "start": "0",
    "end": "68000"
  },
  {
    "text": "the following is a conversation with Ian good fellow he's the author of the popular textbook on deep learning simply",
    "start": "0",
    "end": "6720"
  },
  {
    "text": "titled deep learning he coined the term of generative adversarial networks",
    "start": "6720",
    "end": "11730"
  },
  {
    "text": "otherwise known as Ganz and with his 2014 paper is responsible for launching",
    "start": "11730",
    "end": "18869"
  },
  {
    "text": "the incredible growth of research and innovation in this subfield of deep learning he got his BS and MS at",
    "start": "18869",
    "end": "26400"
  },
  {
    "text": "Stanford his PhD at University of Montreal with yoshua bengio and Erin",
    "start": "26400",
    "end": "31920"
  },
  {
    "text": "Kerrville he held several research positions including an open AI Google",
    "start": "31920",
    "end": "36960"
  },
  {
    "text": "brain and now at Apple as the director of machine learning this recording",
    "start": "36960",
    "end": "42540"
  },
  {
    "text": "happened while Ian was still a Google brain but we don't talk about anything specific to Google or any other",
    "start": "42540",
    "end": "49289"
  },
  {
    "text": "organization this conversation is part of the artificial intelligence podcast if you enjoy it subscribe on YouTube",
    "start": "49289",
    "end": "56489"
  },
  {
    "text": "iTunes or simply connect with me on Twitter at lex friedman spelled fri d",
    "start": "56489",
    "end": "62370"
  },
  {
    "text": "and now here's my conversation with Ian good fellow you open your popular deep",
    "start": "62370",
    "end": "70260"
  },
  {
    "start": "68000",
    "end": "162000"
  },
  {
    "text": "learning book with a Russian doll type diagram that shows deep learning is a subset of representation learning which",
    "start": "70260",
    "end": "77280"
  },
  {
    "text": "in turn is a subset of machine learning and finally a subset of AI so this kind",
    "start": "77280",
    "end": "83490"
  },
  {
    "text": "of implies that there may be limits to deep learning in the context of AI so what do you think is the current limits",
    "start": "83490",
    "end": "90090"
  },
  {
    "text": "of deep learning and are those limits something that we can overcome with time",
    "start": "90090",
    "end": "95100"
  },
  {
    "text": "yeah I think one of the biggest limitations of deep learning is that right now it requires really a lot of",
    "start": "95100",
    "end": "100710"
  },
  {
    "text": "data especially labeled data there's some unsupervised and semi-supervised",
    "start": "100710",
    "end": "105990"
  },
  {
    "text": "learning algorithms that can reduce the amount of labeled data you need but they still require a lot of unlabeled data",
    "start": "105990",
    "end": "111799"
  },
  {
    "text": "reinforcement learning algorithms they don't need labels but they need really a lot of experiences as human beings we",
    "start": "111799",
    "end": "118049"
  },
  {
    "text": "don't learn to play pong by failing at pong two million times so just getting",
    "start": "118049",
    "end": "123570"
  },
  {
    "text": "the generalization ability better is one of the most important bottlenecks and the capability of the technology today",
    "start": "123570",
    "end": "129720"
  },
  {
    "text": "and then I guess I'd also say deep learning is like a of a bigger system so far nobody is",
    "start": "129720",
    "end": "137549"
  },
  {
    "text": "really proposing to have only what you'd call deep learning as the entire",
    "start": "137549",
    "end": "143519"
  },
  {
    "text": "ingredient of intelligence you use deep learning as sub modules of other systems",
    "start": "143519",
    "end": "149730"
  },
  {
    "text": "like alphago has a deep learning model that estimates the value function most",
    "start": "149730",
    "end": "155459"
  },
  {
    "text": "reinforcement learning algorithms have a deep learning module that estimates which action to take next but you might",
    "start": "155459",
    "end": "160920"
  },
  {
    "text": "have other components here basically as building a function estimator do you",
    "start": "160920",
    "end": "166470"
  },
  {
    "start": "162000",
    "end": "306000"
  },
  {
    "text": "think it's possible you said nobody is kind of in thinking about this so far but do you think neural networks could",
    "start": "166470",
    "end": "172409"
  },
  {
    "text": "be made to reason in the way symbolic systems did in the 80s and 90s to do",
    "start": "172409",
    "end": "177989"
  },
  {
    "text": "more create more like programs as opposed to functions yeah I think we already see that a little bit I already",
    "start": "177989",
    "end": "185250"
  },
  {
    "text": "kind of think of neural nets as a kind of program I think of deep learning as basically learning programs that have",
    "start": "185250",
    "end": "193260"
  },
  {
    "text": "more than one step so if you draw a flowchart or or if you draw a tensor",
    "start": "193260",
    "end": "198569"
  },
  {
    "text": "flow graph describing your machine learning model I think of the depth of that graph is describing the number of",
    "start": "198569",
    "end": "204569"
  },
  {
    "text": "steps that run in sequence and then the width of that graph is the number of steps that run in parallel now it's been",
    "start": "204569",
    "end": "211079"
  },
  {
    "text": "long enough that we've had deep learning working that it's a little bit silly to even discuss shallow learning anymore but back when I first got involved in AI",
    "start": "211079",
    "end": "218150"
  },
  {
    "text": "when we used machine learning we were usually learning things like support vector machines you could have a lot of",
    "start": "218150",
    "end": "224280"
  },
  {
    "text": "input features to the model and you could multiply each feature by a different weight but all those multiplications were done in parallel to",
    "start": "224280",
    "end": "230189"
  },
  {
    "text": "each other there wasn't a lot done in series I think what we got with deep learning was really the ability to have",
    "start": "230189",
    "end": "236629"
  },
  {
    "text": "steps of a program that run in sequence and I think that we've actually started",
    "start": "236629",
    "end": "242310"
  },
  {
    "text": "to see that what's important with deep learning is more the fact that we have a multi-step program rather than the fact",
    "start": "242310",
    "end": "248759"
  },
  {
    "text": "that we've learned a representation if you look at things like res nuts for",
    "start": "248759",
    "end": "253949"
  },
  {
    "text": "example they take one particular kind of representation and they update it",
    "start": "253949",
    "end": "259470"
  },
  {
    "text": "several times back when deep learning first really took off in the academic world in 2006 when Geoff Hinton",
    "start": "259470",
    "end": "267330"
  },
  {
    "text": "showed that you could train deep belief networks everybody who was under ested in the idea thought of it as each layer",
    "start": "267330",
    "end": "273419"
  },
  {
    "text": "learns a different level of abstraction but the first layer trained on images learn something like edges and the",
    "start": "273419",
    "end": "279090"
  },
  {
    "text": "second layer learns corners and eventually you get these kind of grandmother's cell units that recognize specific objects today I think most",
    "start": "279090",
    "end": "286949"
  },
  {
    "text": "people think of it more as a computer program where as you add more layers you",
    "start": "286949",
    "end": "291960"
  },
  {
    "text": "can do more updates before you output your final number but I don't think anybody believes the layer 150 of the",
    "start": "291960",
    "end": "298680"
  },
  {
    "text": "resin it is a grand grandmother cell and you know layer 100 is contours or",
    "start": "298680",
    "end": "304199"
  },
  {
    "text": "something like that okay so you think you're not thinking of it as a singular representation that keeps building you",
    "start": "304199",
    "end": "311639"
  },
  {
    "text": "think of it as a program sort of almost like a state the representation is a",
    "start": "311639",
    "end": "316860"
  },
  {
    "text": "state of understanding and yeah I think of it as a program that makes several updates and arrives it better and better",
    "start": "316860",
    "end": "322979"
  },
  {
    "text": "understandings but it's not replacing the representation at each step its refining it and in some sense that's a",
    "start": "322979",
    "end": "330360"
  },
  {
    "text": "little bit like reasoning it's not reasoning in the form of deduction but it's reasoning in the form of taking a",
    "start": "330360",
    "end": "336569"
  },
  {
    "text": "thought and refining it and refining it carefully until it's good enough to use do you think and I hope you don't mind",
    "start": "336569",
    "end": "343469"
  },
  {
    "text": "we'll jump philosophical every once in a while do you think of you know a",
    "start": "343469",
    "end": "348599"
  },
  {
    "text": "cognition human cognition or even consciousness as simply a result of this",
    "start": "348599",
    "end": "354060"
  },
  {
    "text": "kind of cincuenta sequential representation learning do you think that can emerge cognition yes I think so",
    "start": "354060",
    "end": "362340"
  },
  {
    "text": "consciousness it's really hard to even define what we mean by that I guess",
    "start": "362340",
    "end": "367710"
  },
  {
    "text": "there's consciousness is often defined as things like having self-awareness and that's relatively easy to turn into",
    "start": "367710",
    "end": "375210"
  },
  {
    "text": "something actionable for a computer scientists the reason about people also defined consciousness in terms of having",
    "start": "375210",
    "end": "380400"
  },
  {
    "text": "qualitative states of experience like qualia and there's all these philosophical problems like could you",
    "start": "380400",
    "end": "385680"
  },
  {
    "text": "imagine jambe who does all the same information processing as a human but",
    "start": "385680",
    "end": "390860"
  },
  {
    "text": "doesn't really have the qualitative experiences that we have that sort of thing I have no idea how to formalize or",
    "start": "390860",
    "end": "397649"
  },
  {
    "text": "turn it into a scientific question I don't know how you could run in experiment to tell whether a person is a",
    "start": "397649",
    "end": "403690"
  },
  {
    "text": "zombie or not and similarly I don't know how you could run an experiment to tell whether an advanced AI system had become conscious",
    "start": "403690",
    "end": "411070"
  },
  {
    "text": "in the sense of qualia or not but in the more practical sense like almost like self attention you think consciousness and cognition",
    "start": "411070",
    "end": "417640"
  },
  {
    "start": "413000",
    "end": "538000"
  },
  {
    "text": "can in an impressive way emerge from current types of architectures though",
    "start": "417640",
    "end": "424450"
  },
  {
    "text": "yes yeah or or if if you think of consciousness in terms of self-awareness and just making plans based on the fact",
    "start": "424450",
    "end": "432910"
  },
  {
    "text": "that the agent itself exists in the world reinforcement learning algorithms are already more or less forced to model",
    "start": "432910",
    "end": "440800"
  },
  {
    "text": "the agents effect on the environment so that that more limited version of consciousness is already something that",
    "start": "440800",
    "end": "448540"
  },
  {
    "text": "we get limited versions of with reinforcement learning algorithms if they're trained well but you say limited",
    "start": "448540",
    "end": "457300"
  },
  {
    "text": "so the the big question really is how you jump from limited to human level yeah right and whether it's possible you",
    "start": "457300",
    "end": "466270"
  },
  {
    "text": "know the even just building common-sense reasoning seems to be exceptionally difficult so K if we scale things up",
    "start": "466270",
    "end": "472390"
  },
  {
    "text": "forget much better on supervised learning if we get better at labeling forget bigger datasets and the more",
    "start": "472390",
    "end": "479890"
  },
  {
    "text": "compute do you think we'll start to see really impressive things that go from limited to you know something echoes of",
    "start": "479890",
    "end": "488680"
  },
  {
    "text": "human level cognition I think so yeah I'm optimistic about what can happen just with more computation and more data",
    "start": "488680",
    "end": "495370"
  },
  {
    "text": "I do think it'll be important to get the right kind of data today most of the",
    "start": "495370",
    "end": "500920"
  },
  {
    "text": "machine learning systems we train our mostly trained on one type of data for",
    "start": "500920",
    "end": "505930"
  },
  {
    "text": "each model but the human brain we get all of our different senses and we have",
    "start": "505930",
    "end": "511780"
  },
  {
    "text": "many different experiences like you know riding a bike driving a car talking to people reading I think when you get that",
    "start": "511780",
    "end": "520000"
  },
  {
    "text": "kind of integrated data set working with a machine learning model that can actually close the loop and interact we",
    "start": "520000",
    "end": "527980"
  },
  {
    "text": "may find that algorithms not so different from what we have today learn really interesting things when you scale",
    "start": "527980",
    "end": "533710"
  },
  {
    "text": "them up a lot and a large amount of multimodal data so multimodal is really interesting but",
    "start": "533710",
    "end": "539800"
  },
  {
    "start": "538000",
    "end": "687000"
  },
  {
    "text": "within like you're working adversarial examples so selecting within modal",
    "start": "539800",
    "end": "546910"
  },
  {
    "text": "within up one mode of data selecting better at what are the difficult cases",
    "start": "546910",
    "end": "553630"
  },
  {
    "text": "from which are most useful to learn from oh yeah like could we could you get a whole lot of mileage out of designing a",
    "start": "553630",
    "end": "561190"
  },
  {
    "text": "model that's resistant to adverse fare examples or something like that right yeah question but my thinking on that",
    "start": "561190",
    "end": "566890"
  },
  {
    "text": "has evolved a lot over the last few years one nice thing when I first started to really invest in studying adversarial examples I was thinking of",
    "start": "566890",
    "end": "573310"
  },
  {
    "text": "it mostly as that versus aryl examples reveal a big problem with machine learning and we would like to close the",
    "start": "573310",
    "end": "580810"
  },
  {
    "text": "gap between how machine learning models respond to adversarial examples and how humans respond after studying the",
    "start": "580810",
    "end": "588460"
  },
  {
    "text": "problem more I still think that adversarial examples are important I think of them now more of as a security",
    "start": "588460",
    "end": "593800"
  },
  {
    "text": "liability then as an issue that necessarily shows there something uniquely wrong with machine learning as",
    "start": "593800",
    "end": "601360"
  },
  {
    "text": "opposed to humans also do you see them as a tool to improve the performance of the system not not on the security side",
    "start": "601360",
    "end": "608350"
  },
  {
    "text": "but literally just accuracy I do see them as a kind of tool on that side but",
    "start": "608350",
    "end": "613600"
  },
  {
    "text": "maybe not quite as much as I used to think we've started to find that there's a trade-off between accuracy on",
    "start": "613600",
    "end": "619750"
  },
  {
    "text": "adversarial examples and accuracy on clean examples back in 2014 when I did",
    "start": "619750",
    "end": "625990"
  },
  {
    "text": "the first adversary trained classifier that showed resistance to some kinds of",
    "start": "625990",
    "end": "631510"
  },
  {
    "text": "adversarial examples it also got better at the clean data on M NIST and that's something we've replicated several times",
    "start": "631510",
    "end": "637630"
  },
  {
    "text": "an M NIST that when we train against weak adversarial examples Emnes classifiers get more accurate so far",
    "start": "637630",
    "end": "644230"
  },
  {
    "text": "that hasn't really held up on other data sets and hasn't held up when we train against stronger adversaries it seems",
    "start": "644230",
    "end": "651130"
  },
  {
    "text": "like when you confront a really strong adversary you tend to have to give",
    "start": "651130",
    "end": "656590"
  },
  {
    "text": "something up interesting this is such a compelling idea because it feels it",
    "start": "656590",
    "end": "662170"
  },
  {
    "text": "feels like that's how us humans learn yeah the difficult cases we we try to think of what would we screw up",
    "start": "662170",
    "end": "668740"
  },
  {
    "text": "and then we make sure we fix that yeah it's also in a lot of branches of engineering you do a worst case analysis",
    "start": "668740",
    "end": "675220"
  },
  {
    "text": "and make sure that your system will work in the worst case and then that guarantees that it'll work in all of the",
    "start": "675220",
    "end": "681399"
  },
  {
    "text": "messy average cases that happen when you go out into a really randomized world",
    "start": "681399",
    "end": "686890"
  },
  {
    "text": "you know with driving with autonomous vehicles there seems to be a desire to just look for think I'd viscerally tried",
    "start": "686890",
    "end": "695110"
  },
  {
    "text": "to figure out how to mess up the system and if you can be robust to all those difficult cases then you can it's a hand",
    "start": "695110",
    "end": "702459"
  },
  {
    "text": "waving empirical way to show that your system is yeah yes today most adverse early example",
    "start": "702459",
    "end": "708610"
  },
  {
    "text": "research isn't really focused on a particular use case but there are a lot of different use cases where you'd like",
    "start": "708610",
    "end": "714399"
  },
  {
    "text": "to make sure that the adversary can't interfere with the operation of your system like in finance if you have an",
    "start": "714399",
    "end": "721420"
  },
  {
    "text": "algorithm making trades for you people go to a lot of an effort to obfuscate their algorithm that's both to protect",
    "start": "721420",
    "end": "727330"
  },
  {
    "text": "their IP because you don't want to research and develop a profitable",
    "start": "727330",
    "end": "732910"
  },
  {
    "text": "trading algorithm then have somebody else capture the gains but it's at least partly because you don't want people to",
    "start": "732910",
    "end": "738160"
  },
  {
    "text": "make adversarial examples that fool you our algorithm into making bad trades",
    "start": "738160",
    "end": "743420"
  },
  {
    "text": "or I guess one area that's been popular in the academic literature is speech",
    "start": "743420",
    "end": "748830"
  },
  {
    "text": "recognition if you use speech recognition to hear an audio waveform",
    "start": "748830",
    "end": "754230"
  },
  {
    "text": "and then in turn that into a command that a phone executes for you you don't",
    "start": "754230",
    "end": "760200"
  },
  {
    "text": "want and a malicious adversary to be able to produce audio that gets interpreted as malicious commands",
    "start": "760200",
    "end": "765890"
  },
  {
    "text": "especially if a human in the room doesn't realize that something like that is happening in speech recognition has",
    "start": "765890",
    "end": "772110"
  },
  {
    "start": "770000",
    "end": "840000"
  },
  {
    "text": "there been much success in in being able to create adversarial examples that fool",
    "start": "772110",
    "end": "778860"
  },
  {
    "text": "the system yeah actually I guess the first work that I'm aware of is a paper called hidden voice commands that came",
    "start": "778860",
    "end": "785580"
  },
  {
    "text": "out in 2016 I believe and they were able to show that they could make sounds that",
    "start": "785580",
    "end": "791910"
  },
  {
    "text": "are not understandable by a human but are recognized as the target phrase that",
    "start": "791910",
    "end": "798570"
  },
  {
    "text": "the attacker wants the phone to recognize it as since then things have gotten a little bit better on the",
    "start": "798570",
    "end": "804300"
  },
  {
    "text": "attacker side when worse on the defender side it's become possible to make sounds",
    "start": "804300",
    "end": "813360"
  },
  {
    "text": "that sound like normal speech but are actually interpreted as a different",
    "start": "813360",
    "end": "818580"
  },
  {
    "text": "sentence than the human here's the level of perceptibility of the adversarial perturbation is still kind of high the",
    "start": "818580",
    "end": "826230"
  },
  {
    "text": "when you listen to the recording it sounds like there's some noise in the background just like rustling sounds but",
    "start": "826230",
    "end": "833070"
  },
  {
    "text": "those rustling sounds are actually the adversarial perturbation that makes the phone hear a completely different sentence yeah that's so fascinating",
    "start": "833070",
    "end": "839330"
  },
  {
    "text": "Peter Norvig mention that you're writing the deep learning chapter for the fourth edition of the artificial intelligence",
    "start": "839330",
    "end": "845430"
  },
  {
    "start": "840000",
    "end": "1004000"
  },
  {
    "text": "the modern approach book so how do you even begin summarizing the field of deep",
    "start": "845430",
    "end": "851310"
  },
  {
    "text": "learning in a chapter well in my case I waited like a year before I actually",
    "start": "851310",
    "end": "857640"
  },
  {
    "text": "read anything is it even having written a full length textbook before it's still pretty",
    "start": "857640",
    "end": "864810"
  },
  {
    "text": "intimidating to try to start writing just one chapter that covers everything",
    "start": "864810",
    "end": "870500"
  },
  {
    "text": "one thing that helped me make that plan was actually the experience of having ridden the full book before and then",
    "start": "870500",
    "end": "877050"
  },
  {
    "text": "watching how the field changed after the book came out I realized there's a lot of topics that were maybe extraneous in",
    "start": "877050",
    "end": "883740"
  },
  {
    "text": "the first book and just seeing what stood the test of a few years of being published and what seems a little bit",
    "start": "883740",
    "end": "891210"
  },
  {
    "text": "less important to have included now helped me pare down the topics I wanted to cover for the book it's also really",
    "start": "891210",
    "end": "897450"
  },
  {
    "text": "nice now that the field is kind of stabilized to the point where some core ideas from the 1980s are still used",
    "start": "897450",
    "end": "903420"
  },
  {
    "text": "today when I first started studying machine learning almost everything from the 1980s had been rejected and now some",
    "start": "903420",
    "end": "910080"
  },
  {
    "text": "of it has come back so that stuff that's really stood the test of time is what I focused on putting into the book there's",
    "start": "910080",
    "end": "917310"
  },
  {
    "text": "also I guess two different philosophies about how you might write a book one",
    "start": "917310",
    "end": "923280"
  },
  {
    "text": "philosophy is you try to write a reference that covers everything and the other philosophy is you try to provide a high level summary that gives people the",
    "start": "923280",
    "end": "930330"
  },
  {
    "text": "language to understand a field and tells them what the most important concepts are the first deep learning book that I",
    "start": "930330",
    "end": "936780"
  },
  {
    "text": "wrote with Yahshua and Aaron was somewhere between the the two philosophies that it's trying to be both",
    "start": "936780",
    "end": "942540"
  },
  {
    "text": "a reference and an introductory guide writing this chapter for Russell and",
    "start": "942540",
    "end": "947820"
  },
  {
    "text": "Norvig book I was able to focus more on just a concise introduction of the key",
    "start": "947820",
    "end": "953130"
  },
  {
    "text": "concepts and the language you need to read about them more and a lot of cases actually just wrote paragraphs that said here's a rapidly evolving area that you",
    "start": "953130",
    "end": "960270"
  },
  {
    "text": "should pay attention to it's it's pointless to try to tell you what the latest and best version of a you know",
    "start": "960270",
    "end": "967680"
  },
  {
    "text": "learn to learn model is right you know I can I can point you to a paper that's",
    "start": "967680",
    "end": "972720"
  },
  {
    "text": "recent right now but there isn't a whole lot of a reason to delve into exactly what's going on with the latest learning",
    "start": "972720",
    "end": "980640"
  },
  {
    "text": "to learn approach or the latest module produced by learning to learn algorithm you should know that learning to learn",
    "start": "980640",
    "end": "986100"
  },
  {
    "text": "is a thing and that it may very well be the source of the latest and greatest convolutional net or recurrent net",
    "start": "986100",
    "end": "993150"
  },
  {
    "text": "module that you would want to use in your latest project but there isn't a lot of point in trying to summarize exactly which architecture in which",
    "start": "993150",
    "end": "1001490"
  },
  {
    "text": "learning approach got to which level of performance so you maybe focus more on the basics of",
    "start": "1001490",
    "end": "1007339"
  },
  {
    "start": "1004000",
    "end": "1108000"
  },
  {
    "text": "the methodology so from back propagation to feed-forward to recur in your",
    "start": "1007339",
    "end": "1013399"
  },
  {
    "text": "networks convolutional that kind of thing yeah yeah so if I were to ask you I remember I took algorithms and data",
    "start": "1013399",
    "end": "1020540"
  },
  {
    "text": "structures algorithm there of course remember the professor asked what is an",
    "start": "1020540",
    "end": "1027319"
  },
  {
    "text": "algorithm and yelled at everybody in a good way that nobody was answering it",
    "start": "1027319",
    "end": "1033709"
  },
  {
    "text": "correctly everybody knew what the alkyl it was graduate course everybody knew what an algorithm was but they weren't able to answer it well let me ask you in",
    "start": "1033709",
    "end": "1041058"
  },
  {
    "text": "that same spirit what is deep learning I would say deep learning is any kind of",
    "start": "1041059",
    "end": "1048040"
  },
  {
    "text": "machine learning that involves learning parameters of more than one consecutive",
    "start": "1048040",
    "end": "1055370"
  },
  {
    "text": "step so that I mean shallow learning is things where you learn a lot of",
    "start": "1055370",
    "end": "1061340"
  },
  {
    "text": "operations that happen in parallel you might have a system that makes multiple steps like you might have had designed",
    "start": "1061340",
    "end": "1068990"
  },
  {
    "text": "feature extractors but really only one step is learned deep learning is anything where you have multiple",
    "start": "1068990",
    "end": "1075169"
  },
  {
    "text": "operations in sequence and that includes the things that are really popular today like convolutional networks and",
    "start": "1075169",
    "end": "1081380"
  },
  {
    "text": "recurrent networks but it also includes some of the things that have died out like Bolton machines where we weren't",
    "start": "1081380",
    "end": "1089419"
  },
  {
    "text": "using back propagation today I hear a lot of people define deep learning as",
    "start": "1089419",
    "end": "1094600"
  },
  {
    "text": "gradient descent applied to these differentiable functions and I think",
    "start": "1094600",
    "end": "1103130"
  },
  {
    "text": "that's a legitimate usage of the term it's just different from the way that I use the term myself so what's an example",
    "start": "1103130",
    "end": "1108410"
  },
  {
    "start": "1108000",
    "end": "1236000"
  },
  {
    "text": "of deep learning that is not gradient descent on differentiable functions in",
    "start": "1108410",
    "end": "1115010"
  },
  {
    "text": "your I mean not specifically perhaps but more even looking into the future what's",
    "start": "1115010",
    "end": "1120470"
  },
  {
    "text": "your thought about that space of approaches yeah so I tend to think of machine learning algorithms as",
    "start": "1120470",
    "end": "1126440"
  },
  {
    "text": "decomposed into really three different pieces there's the model which can be",
    "start": "1126440",
    "end": "1131809"
  },
  {
    "text": "something like a neural nut or a Bolton machine or a recurrent model and I",
    "start": "1131809",
    "end": "1137000"
  },
  {
    "text": "basically just described how do you take data and how do you take parameters and you know what function do",
    "start": "1137000",
    "end": "1143120"
  },
  {
    "text": "you use to make a prediction given the data and the parameters another piece of the learning algorithm is the",
    "start": "1143120",
    "end": "1150309"
  },
  {
    "text": "optimization algorithm or not every algorithm can be really described in terms of optimization but what's the",
    "start": "1150309",
    "end": "1156830"
  },
  {
    "text": "algorithm for updating the parameters or updating whatever the state of the network is and then the the last part is",
    "start": "1156830",
    "end": "1165020"
  },
  {
    "text": "the the data set like how do you actually represent the world as it comes into your machine learning system so I",
    "start": "1165020",
    "end": "1173330"
  },
  {
    "text": "think of deep learning as telling us something about what does the model look like and basically to qualify as deep I",
    "start": "1173330",
    "end": "1181100"
  },
  {
    "text": "say that it just has to have multiple layers that can be multiple steps in a",
    "start": "1181100",
    "end": "1186590"
  },
  {
    "text": "feed-forward differentiable computation that can be multiple layers in a graphical model there's a lot of ways",
    "start": "1186590",
    "end": "1192620"
  },
  {
    "text": "that you could satisfy me that something has multiple steps that are each parameterised separately",
    "start": "1192620",
    "end": "1198710"
  },
  {
    "text": "I think of gradient descent as being all about that other piece the how do you actually update the parameters piece so",
    "start": "1198710",
    "end": "1204380"
  },
  {
    "text": "you can imagine having a deep model like a convolutional net and training it with something like evolution or a genetic",
    "start": "1204380",
    "end": "1210350"
  },
  {
    "text": "algorithm and I would say that still qualifies as deep learning and then in",
    "start": "1210350",
    "end": "1215360"
  },
  {
    "text": "terms of models that aren't necessarily differentiable I guess Boltzmann machines are probably",
    "start": "1215360",
    "end": "1220460"
  },
  {
    "text": "the main example of something where you can't really take a derivative and use",
    "start": "1220460",
    "end": "1225740"
  },
  {
    "text": "that for the learning process but you you can still argue that the model has",
    "start": "1225740",
    "end": "1230890"
  },
  {
    "text": "many steps of processing that it applies when you run inference in the model so that's the steps of processing that's",
    "start": "1230890",
    "end": "1237710"
  },
  {
    "start": "1236000",
    "end": "1303000"
  },
  {
    "text": "key so geoff hinton suggests that we need to throw away back prop back propagation and start all over what do",
    "start": "1237710",
    "end": "1245120"
  },
  {
    "text": "you think about that what could an alternative direction of training nil networks look like I don't know that",
    "start": "1245120",
    "end": "1251780"
  },
  {
    "text": "back propagation is going to go away entirely most of this time when we decide that a machine learning algorithm",
    "start": "1251780",
    "end": "1258350"
  },
  {
    "text": "isn't on the critical path to research for improving AI the algorithm doesn't",
    "start": "1258350",
    "end": "1264200"
  },
  {
    "text": "die it just becomes used for some specialized set of things a lot of algorithms like logistic",
    "start": "1264200",
    "end": "1269710"
  },
  {
    "text": "regression don't seem that exciting to AI researchers who are working on things",
    "start": "1269710",
    "end": "1274900"
  },
  {
    "text": "like speech recognition or autonomous cars today but there's still a lot of use for logistic regression and things",
    "start": "1274900",
    "end": "1281410"
  },
  {
    "text": "like analyzing really noisy data and medicine and finance or making really",
    "start": "1281410",
    "end": "1287530"
  },
  {
    "text": "rapid predictions in really time-limited contexts so I think I think back propagation and gradient descent are",
    "start": "1287530",
    "end": "1293559"
  },
  {
    "text": "around to stay but they may not end up being everything that we need to get to",
    "start": "1293559",
    "end": "1299679"
  },
  {
    "text": "real human level or superhuman AI are you optimistic about us discovering",
    "start": "1299679",
    "end": "1305220"
  },
  {
    "start": "1303000",
    "end": "1457000"
  },
  {
    "text": "you know back propagation has been around for a few decades so I optimistic bus about us as a",
    "start": "1305220",
    "end": "1313570"
  },
  {
    "text": "community being able to discover something better yeah I am I think I think we likely will find something that",
    "start": "1313570",
    "end": "1320559"
  },
  {
    "text": "works better you could imagine things like having stacks of models where some",
    "start": "1320559",
    "end": "1326710"
  },
  {
    "text": "of the lower level models predict parameters of the higher level models and so at the top level you're not",
    "start": "1326710",
    "end": "1332320"
  },
  {
    "text": "learning in terms of literally calculating gradients but just predicting how different values will perform you can kind of see that already",
    "start": "1332320",
    "end": "1338740"
  },
  {
    "text": "in some areas like Bayesian optimization where you have a Gaussian process that predicts how well different parameter",
    "start": "1338740",
    "end": "1344500"
  },
  {
    "text": "values will perform we already used those kinds of algorithms for things like hyper parameter optimization and in",
    "start": "1344500",
    "end": "1350530"
  },
  {
    "text": "general we know a lot of things other than back prep that work really well for specific problems the main thing we",
    "start": "1350530",
    "end": "1355570"
  },
  {
    "text": "haven't found is a way of taking one of these other non back based algorithms and having it really advanced the",
    "start": "1355570",
    "end": "1362679"
  },
  {
    "text": "state-of-the-art on an AI level problem right but I wouldn't be surprised if eventually we",
    "start": "1362679",
    "end": "1369280"
  },
  {
    "text": "find that some of these algorithms that even the ones that already exists not even necessarily a new one we might find",
    "start": "1369280",
    "end": "1374860"
  },
  {
    "text": "some way of customizing one of these algorithms to do something really",
    "start": "1374860",
    "end": "1379900"
  },
  {
    "text": "interesting at the level of cognition or or the the level of I think one system",
    "start": "1379900",
    "end": "1387100"
  },
  {
    "text": "that we really don't have working quite right yet is like short-term memory we",
    "start": "1387100",
    "end": "1393070"
  },
  {
    "text": "have things like LST M's they're called long short-term memory they still don't do quite what a human",
    "start": "1393070",
    "end": "1399520"
  },
  {
    "text": "does with short-term memory like gradient descent to learn a",
    "start": "1399520",
    "end": "1405850"
  },
  {
    "text": "specific fact has to do multiple steps on that fact like if I I tell you the",
    "start": "1405850",
    "end": "1411580"
  },
  {
    "text": "meeting today is at 3 p.m. I don't need to say over and over again it's at 3 p.m. it's not 3 p.m. it's at 3 p.m. it's",
    "start": "1411580",
    "end": "1417879"
  },
  {
    "text": "a 3 p.m. right for you to do a gradient step on each one you just hear it once and you remember it there's been some",
    "start": "1417879",
    "end": "1423669"
  },
  {
    "text": "work on things like self attention and attention like mechanisms like the neural Turing machine that can write to",
    "start": "1423669",
    "end": "1431590"
  },
  {
    "text": "memory cells and update themselves with facts like that right away but I don't think we've really nailed it yet and",
    "start": "1431590",
    "end": "1436919"
  },
  {
    "text": "that's one area where I'd imagine that new optimization algorithms are",
    "start": "1436919",
    "end": "1442750"
  },
  {
    "text": "different ways of applying existing optimization algorithms could give us a way of just lightning-fast updating the",
    "start": "1442750",
    "end": "1449289"
  },
  {
    "text": "state of a machine learning system to contain a specific fact like that without needing to have it presented",
    "start": "1449289",
    "end": "1455289"
  },
  {
    "text": "over and over and over again so some of the success of symbolic systems in the",
    "start": "1455289",
    "end": "1460419"
  },
  {
    "start": "1457000",
    "end": "1517000"
  },
  {
    "text": "80s is they were able to assemble these kinds of facts better but dude there's a",
    "start": "1460419",
    "end": "1467230"
  },
  {
    "text": "lot of expert input required and it's very limited in that sense do you ever look back to that as something that will",
    "start": "1467230",
    "end": "1475000"
  },
  {
    "text": "have to return to eventually sort of dust off the book from the shelf and think about how we build knowledge",
    "start": "1475000",
    "end": "1481110"
  },
  {
    "text": "representation knowledge place well we have to use graph searches searches right and like first-order logic and",
    "start": "1481110",
    "end": "1487210"
  },
  {
    "text": "entailment and things like that a thing yeah exactly in my particular line of work which has mostly been machine learning security",
    "start": "1487210",
    "end": "1493929"
  },
  {
    "text": "and and also generative modeling I haven't usually found myself moving in",
    "start": "1493929",
    "end": "1499899"
  },
  {
    "text": "that direction for generative models I could see a little bit of it could be useful if you had something like a",
    "start": "1499899",
    "end": "1506610"
  },
  {
    "text": "differentiable knowledge base or some other kind of knowledge base where it's possible for some of our fuzzier machine",
    "start": "1506610",
    "end": "1514120"
  },
  {
    "text": "learning algorithms to interact with the knowledge base immanuel Network is kind of like that it's a differentiable",
    "start": "1514120",
    "end": "1519909"
  },
  {
    "start": "1517000",
    "end": "1600000"
  },
  {
    "text": "knowledge base of sorts yeah but if if we had a really easy way of giving",
    "start": "1519909",
    "end": "1526870"
  },
  {
    "text": "feedback to machine learning models that would clearly helped a lot with with generative models and so you could",
    "start": "1526870",
    "end": "1532809"
  },
  {
    "text": "imagine one way of getting there would be get a lot better at natural language processing but another way of getting there would be take some kind of",
    "start": "1532809",
    "end": "1539560"
  },
  {
    "text": "knowledge base and figure out a way for it to actually interact with a neural network being able to have a chat within",
    "start": "1539560",
    "end": "1545230"
  },
  {
    "text": "y'all network yes so like one thing in generative models we see a lot today is you'll get things like faces that are",
    "start": "1545230",
    "end": "1552460"
  },
  {
    "text": "not symmetrical like like people that have two eyes that are different colors and I mean there are people with eyes",
    "start": "1552460",
    "end": "1559480"
  },
  {
    "text": "that are different colors in real life but not nearly as many of them as you tend to see in the machine learning",
    "start": "1559480",
    "end": "1564850"
  },
  {
    "text": "generated data so if if you had either a knowledge base that could contain the fact people's faces are generally",
    "start": "1564850",
    "end": "1571600"
  },
  {
    "text": "approximately symmetric and eye color is especially likely to be the same on both sides being able to just inject that",
    "start": "1571600",
    "end": "1579340"
  },
  {
    "text": "hint into the machine learning model without it having to discover that itself after studying a lot of data it",
    "start": "1579340",
    "end": "1585790"
  },
  {
    "text": "would be a really useful feature I could see a lot of ways of getting there without bringing back some of the 1980s",
    "start": "1585790",
    "end": "1591610"
  },
  {
    "text": "technology but I also see some ways that you could imagine extending the 1980s technology to play nice with neural nets",
    "start": "1591610",
    "end": "1598060"
  },
  {
    "text": "and have it help get there awesome so you talked about the story of you coming up with idea of Gans at a bar",
    "start": "1598060",
    "end": "1605530"
  },
  {
    "start": "1600000",
    "end": "1674000"
  },
  {
    "text": "with some friends you were arguing that this you know Gans would work Jenner of",
    "start": "1605530",
    "end": "1611770"
  },
  {
    "text": "adversarial networks and the others didn't think so then he went home at midnight coated up and it worked so if I",
    "start": "1611770",
    "end": "1619420"
  },
  {
    "text": "was a friend of yours at the bar I would also have doubts it's a really nice idea but I'm very skeptical that it would",
    "start": "1619420",
    "end": "1626020"
  },
  {
    "text": "work what was the basis of their skepticism what was the basis of your intuition why he should work I don't",
    "start": "1626020",
    "end": "1634690"
  },
  {
    "text": "want to be someone who goes around promoting alcohol for the science in this case I do actually think that",
    "start": "1634690",
    "end": "1641140"
  },
  {
    "text": "drinking helped a little bit mm-hmm when your inhibitions are lowered you're more willing to try out things that you",
    "start": "1641140",
    "end": "1647530"
  },
  {
    "text": "wouldn't try out otherwise so I I have noticed it in general that I'm less",
    "start": "1647530",
    "end": "1652870"
  },
  {
    "text": "prone to shooting down some of my own ideas when I'm when I have had a little bit to drink I think if I had had that",
    "start": "1652870",
    "end": "1659230"
  },
  {
    "text": "idea at lunch time yeah I probably would have thought it it's hard enough I mean one neural net you can't train a second",
    "start": "1659230",
    "end": "1664600"
  },
  {
    "text": "neuron that in the inner loop of the outer neural net that was basically my friends action was that trying to train two",
    "start": "1664600",
    "end": "1670899"
  },
  {
    "text": "neural nets at the same time would be too hard so it was more about the training process unless so my skepticism",
    "start": "1670899",
    "end": "1677409"
  },
  {
    "start": "1674000",
    "end": "1820000"
  },
  {
    "text": "would be you know I'm sure you could train it but the thing would converge to",
    "start": "1677409",
    "end": "1683169"
  },
  {
    "text": "would not be able to generate anything reasonable and any kind of reasonable realism yeah so so part of what all of",
    "start": "1683169",
    "end": "1690309"
  },
  {
    "text": "us were thinking about when we had this conversation was deep Bolton machines which a lot of us in the lab including",
    "start": "1690309",
    "end": "1696850"
  },
  {
    "text": "me were a big fan of deep bolts and machines at the time they involved two",
    "start": "1696850",
    "end": "1701919"
  },
  {
    "text": "separate processes running at the same time one of them is called the positive",
    "start": "1701919",
    "end": "1707200"
  },
  {
    "text": "phase where you load data into the model and tell the model to make the data more",
    "start": "1707200",
    "end": "1712359"
  },
  {
    "text": "likely the owners called the negative phase where you draw samples from the model and tell the model to make those",
    "start": "1712359",
    "end": "1718029"
  },
  {
    "text": "samples less likely in a deep Bolton machine it's not trivial to generate a",
    "start": "1718029",
    "end": "1723460"
  },
  {
    "text": "sample you have to actually run an iterative process that gets better and better samples coming closer and closer to the",
    "start": "1723460",
    "end": "1730659"
  },
  {
    "text": "distribution the model represents so during the training process you're always running these two systems at the",
    "start": "1730659",
    "end": "1735850"
  },
  {
    "text": "same time one that's updating the parameters of the model and another one that's trying to generate samples from the model and they worked really well on",
    "start": "1735850",
    "end": "1743379"
  },
  {
    "text": "things like Amnesty a lot of us in the lab including me had tried to get the Boltzmann machines to scale past em",
    "start": "1743379",
    "end": "1749109"
  },
  {
    "text": "inist to things like generating color photos and we just couldn't get the two processes to stay synchronized so when I",
    "start": "1749109",
    "end": "1757629"
  },
  {
    "text": "had the idea for Gans a lot of people thought that the discriminator would have more or less the same problem as the negative phase in the Boltzmann",
    "start": "1757629",
    "end": "1764379"
  },
  {
    "text": "machine that trying to train the discriminator in the inner loop you just couldn't get it to keep up with the",
    "start": "1764379",
    "end": "1770320"
  },
  {
    "text": "generator and the outer loop and that would prevent it from converging to anything useful yeah I share that",
    "start": "1770320",
    "end": "1776230"
  },
  {
    "text": "intuition yeah what turns out to not be the case a lot of the time with machine",
    "start": "1776230",
    "end": "1783009"
  },
  {
    "text": "learning algorithms it's really hard to predict ahead of time how well they'll actually perform you have to just run the experiment and see what happens",
    "start": "1783009",
    "end": "1789070"
  },
  {
    "text": "and I would say I still today don't have like one factor I can put my finger on",
    "start": "1789070",
    "end": "1794230"
  },
  {
    "text": "it say this is why ganz worked for photo generation and deep Boltzmann machines",
    "start": "1794230",
    "end": "1799570"
  },
  {
    "text": "don't there are a lot of theory papers showing that under some theoretical settings the",
    "start": "1799570",
    "end": "1806539"
  },
  {
    "text": "the gun algorithm does actually converge but those settings are restricted enough",
    "start": "1806539",
    "end": "1813520"
  },
  {
    "text": "that they don't necessarily explain the whole picture in terms of all the results that we see in practice so",
    "start": "1813520",
    "end": "1820880"
  },
  {
    "start": "1820000",
    "end": "2006000"
  },
  {
    "text": "taking a step back can you in the same way as we talked about deep learning can you tell me what generative adversarial",
    "start": "1820880",
    "end": "1827270"
  },
  {
    "text": "networks are yeah so generative adversarial networks are a particular kind of generative model a generative",
    "start": "1827270",
    "end": "1834950"
  },
  {
    "text": "model is a machine learning model that can train on some set of data like so you have a collection of photos of cats",
    "start": "1834950",
    "end": "1840529"
  },
  {
    "text": "and you want to generate more photos of cats or you want to estimate a",
    "start": "1840529",
    "end": "1845690"
  },
  {
    "text": "probability distribution over cats so you can ask how likely it is that some new image is a photo of a cat ganzar one",
    "start": "1845690",
    "end": "1853850"
  },
  {
    "text": "way of doing this some generative models are good at creating new data other generative",
    "start": "1853850",
    "end": "1859940"
  },
  {
    "text": "models are good at estimating that density function and telling you how likely particular pieces of data are to",
    "start": "1859940",
    "end": "1866720"
  },
  {
    "text": "come from the same distribution as a training data gans are more focused on generating samples rather than",
    "start": "1866720",
    "end": "1873279"
  },
  {
    "text": "estimating the density function there are some kinds of games like flow gun that can do both but mostly guns are",
    "start": "1873279",
    "end": "1879710"
  },
  {
    "text": "about generating samples of generating new photos of cats that look realistic and they do that completely from scratch",
    "start": "1879710",
    "end": "1888490"
  },
  {
    "text": "it's analogous to human imagination when again creates a new image of a cat it's",
    "start": "1888490",
    "end": "1895330"
  },
  {
    "text": "using a neural network to produce a cat that has not existed before it isn't",
    "start": "1895330",
    "end": "1901309"
  },
  {
    "text": "doing something like compositing photos together you're not you're not literally taking the eye off of one cat on the ear",
    "start": "1901309",
    "end": "1907340"
  },
  {
    "text": "off of another cat it's it's more of this digestive process where the the neural net trains on a lot of data and",
    "start": "1907340",
    "end": "1914000"
  },
  {
    "text": "comes up with some representation of the probability distribution and generates entirely new cats there are a lot of",
    "start": "1914000",
    "end": "1920450"
  },
  {
    "text": "different ways of building a generative model what's specific against is that we have a two-player game in the game",
    "start": "1920450",
    "end": "1926360"
  },
  {
    "text": "theoretic sense and as the players in this game compete one of them becomes able to generate",
    "start": "1926360",
    "end": "1932170"
  },
  {
    "text": "realistic data the first player is called the generator it produces output data such as just images for example and",
    "start": "1932170",
    "end": "1940200"
  },
  {
    "text": "at the start of the learning process it'll just produce completely random images the other player is called the",
    "start": "1940200",
    "end": "1946150"
  },
  {
    "text": "discriminator the discriminator takes images as input and guesses whether they're real or fake you train it both",
    "start": "1946150",
    "end": "1953410"
  },
  {
    "text": "on real data so photos that come from your training set actual photos of cats and you try to say that those are real",
    "start": "1953410",
    "end": "1959170"
  },
  {
    "text": "you also train it on images that come from the generator network and you train",
    "start": "1959170",
    "end": "1964570"
  },
  {
    "text": "it to say that those are fake as the two players compete in this game the discriminator tries to become better at",
    "start": "1964570",
    "end": "1970990"
  },
  {
    "text": "recognizing where their images are real or fake and the generator becomes better at fooling the discriminator into",
    "start": "1970990",
    "end": "1976060"
  },
  {
    "text": "thinking that its outputs are are real and you can analyze this through the",
    "start": "1976060",
    "end": "1982570"
  },
  {
    "text": "language of game theory and find that there's a Nash equilibrium where the generator has captured the correct",
    "start": "1982570",
    "end": "1989080"
  },
  {
    "text": "probability distribution so in the cat example it makes perfectly realistic cat photos and the discriminator is unable",
    "start": "1989080",
    "end": "1996280"
  },
  {
    "text": "to do better than random guessing because all the all the samples coming from both the data and the generator",
    "start": "1996280",
    "end": "2002910"
  },
  {
    "text": "look equally likely to have come from either source so do you ever do sit back",
    "start": "2002910",
    "end": "2008160"
  },
  {
    "start": "2006000",
    "end": "2204000"
  },
  {
    "text": "and does it just blow your mind that this thing works so from very so it's",
    "start": "2008160",
    "end": "2013590"
  },
  {
    "text": "able to estimate that density function enough to generate generate realistic images I mean does it yeah do you ever",
    "start": "2013590",
    "end": "2021180"
  },
  {
    "text": "sit back yeah how does this even why this is quite incredible especially",
    "start": "2021180",
    "end": "2026910"
  },
  {
    "text": "where Gant's have gone in terms of realism yeah and and not just to flatter my own work but generative models all of",
    "start": "2026910",
    "end": "2034200"
  },
  {
    "text": "them have this property that if they really did what we asked them to do they would do nothing but memorize the",
    "start": "2034200",
    "end": "2040260"
  },
  {
    "text": "training data right some models that are based on maximizing the likelihood the",
    "start": "2040260",
    "end": "2045990"
  },
  {
    "text": "way that you obtain the maximum likelihood for a specific training set is you assign all of your probability",
    "start": "2045990",
    "end": "2052080"
  },
  {
    "text": "mass to the training examples and nowhere else forgets the game is played using a",
    "start": "2052080",
    "end": "2057360"
  },
  {
    "text": "training set so the way that you become unbeatable in the game is you literally memorize training examples",
    "start": "2057360",
    "end": "2064600"
  },
  {
    "text": "one of my former interns wrote a paper his name is a Vaishnav nagarajan and he",
    "start": "2064600",
    "end": "2071270"
  },
  {
    "text": "showed that it's actually hard for the generator to memorize the training data hard in a statistical learning theory",
    "start": "2071270",
    "end": "2078530"
  },
  {
    "text": "sense that you can actually create reasons for why it would require quite a",
    "start": "2078530",
    "end": "2086300"
  },
  {
    "text": "lot of learning steps and and a lot of observations of of different latent",
    "start": "2086300",
    "end": "2091638"
  },
  {
    "text": "variables before you could memorize the training data that still doesn't really explain why when you produce samples",
    "start": "2091639",
    "end": "2097040"
  },
  {
    "text": "that are new why do you get compelling images rather than you know just garbage that's different from the training set",
    "start": "2097040",
    "end": "2103070"
  },
  {
    "text": "and I don't think we really have a good answer for that especially if you think about how many possible images are out",
    "start": "2103070",
    "end": "2109310"
  },
  {
    "text": "there and how few images the generative model sees during training it seems just",
    "start": "2109310",
    "end": "2116030"
  },
  {
    "text": "unreasonable that generative models create new images as well as they do especially considering that we're",
    "start": "2116030",
    "end": "2122270"
  },
  {
    "text": "basically training them to memorize rather than generalize I think part of the answer is there's a paper called",
    "start": "2122270",
    "end": "2129080"
  },
  {
    "text": "deep image prior where they show that you can take a convolutional net and you don't even need to learn the parameters",
    "start": "2129080",
    "end": "2134510"
  },
  {
    "text": "of it at all you just use the model architecture and it's already useful for things like in painting images I think that shows us",
    "start": "2134510",
    "end": "2142130"
  },
  {
    "text": "that the convolutional network architecture captures something really important about the structure of images",
    "start": "2142130",
    "end": "2147140"
  },
  {
    "text": "and we don't need to actually use learning to capture all the information coming out of the convolutional net that",
    "start": "2147140",
    "end": "2155570"
  },
  {
    "text": "would that would imply that it would be much harder to make generative models in other domains so far we're able to make",
    "start": "2155570",
    "end": "2162380"
  },
  {
    "text": "reasonable speech models and things like that but to be honest we haven't actually explored a whole lot of",
    "start": "2162380",
    "end": "2167900"
  },
  {
    "text": "different data sets all that much we don't for example see a lot of deep",
    "start": "2167900",
    "end": "2173000"
  },
  {
    "text": "learning models of like biology datasets where you have lots of microarrays",
    "start": "2173000",
    "end": "2179570"
  },
  {
    "text": "measuring the amount of different enzymes and things like that so we may find that some of the progress that",
    "start": "2179570",
    "end": "2185360"
  },
  {
    "text": "we've seen for images and speech turns out to really rely heavily on the model architecture and we were able to do what",
    "start": "2185360",
    "end": "2192050"
  },
  {
    "text": "we did for vision by trying to reverse-engineer the human visual system and",
    "start": "2192050",
    "end": "2197390"
  },
  {
    "text": "maybe it'll turn out that we can't just use that same trick for arbitrary kinds of data all right so there's aspects of",
    "start": "2197390",
    "end": "2204440"
  },
  {
    "start": "2204000",
    "end": "2336000"
  },
  {
    "text": "the human vision system the hardware of it that makes it without learning",
    "start": "2204440",
    "end": "2209900"
  },
  {
    "text": "without cognition just makes it really effective at detecting the patterns we've seen the visual world yeah that's",
    "start": "2209900",
    "end": "2215600"
  },
  {
    "text": "yeah that's really interesting what in a big quick overview in your view in your",
    "start": "2215600",
    "end": "2224240"
  },
  {
    "text": "view what types of Gans are there and what other generative models besides games are there yeah so it's maybe a",
    "start": "2224240",
    "end": "2232520"
  },
  {
    "text": "little bit easier to start with what kinds of generative models are there other than Gans so most generative models are likelihood",
    "start": "2232520",
    "end": "2239780"
  },
  {
    "text": "based where to train them you have a model that tells you how how much",
    "start": "2239780",
    "end": "2246170"
  },
  {
    "text": "probability it assigns to a particular example and you just maximize the probability assigned to all the training",
    "start": "2246170",
    "end": "2252140"
  },
  {
    "text": "examples it turns out that it's hard to design a model that can create really",
    "start": "2252140",
    "end": "2258020"
  },
  {
    "text": "complicated images or really complicated audio waveforms and still have it be",
    "start": "2258020",
    "end": "2263120"
  },
  {
    "text": "possible to estimate the the likelihood function from a computational point of",
    "start": "2263120",
    "end": "2271160"
  },
  {
    "text": "view most interesting models that you would just write down intuitively it turns out that it's almost impossible to",
    "start": "2271160",
    "end": "2277130"
  },
  {
    "text": "calculate the amount of probability they assign to a particular point so there's a few different schools of generative",
    "start": "2277130",
    "end": "2284180"
  },
  {
    "text": "models in the likelyhood family one approach is to very carefully design the",
    "start": "2284180",
    "end": "2289910"
  },
  {
    "text": "model so that it is computationally tractable to measure the density it assigns to a particular point so there",
    "start": "2289910",
    "end": "2295820"
  },
  {
    "text": "are things like auto regressive models like pixel CN n those basically break",
    "start": "2295820",
    "end": "2303560"
  },
  {
    "text": "down the probability distribution into a product over every single feature so for",
    "start": "2303560",
    "end": "2309020"
  },
  {
    "text": "an image you estimate the probability of each pixel given all of the pixels that came before it hmm there's tricks where",
    "start": "2309020",
    "end": "2316580"
  },
  {
    "text": "if you want to measure the density function you can actually calculate the density for all these pixels more or",
    "start": "2316580",
    "end": "2322460"
  },
  {
    "text": "less in parallel generating the image still tends to require you to go one pixel at a time and that can be very",
    "start": "2322460",
    "end": "2329510"
  },
  {
    "text": "slow but there again tricks for doing this in a hierarchical pattern where you can keep the runtime under control or the",
    "start": "2329510",
    "end": "2336329"
  },
  {
    "text": "quality of the images it generates putting runtime aside pretty good",
    "start": "2336329",
    "end": "2341809"
  },
  {
    "text": "they're reasonable yeah the I would say a lot of the best results are from Gans",
    "start": "2341809",
    "end": "2348059"
  },
  {
    "text": "these days but it can be hard to tell how much of that is based on who's",
    "start": "2348059",
    "end": "2354089"
  },
  {
    "text": "studying which type of algorithm if that makes sense the amount of effort invest in it but yeah or like the kind of",
    "start": "2354089",
    "end": "2360359"
  },
  {
    "text": "expertise so a lot of people who've traditionally been excited about graphics or art and things like that have gotten interested in Gans and to",
    "start": "2360359",
    "end": "2367440"
  },
  {
    "text": "some extent it's hard to tell our Gans doing better because they have a lot of graphics and art experts behind them or",
    "start": "2367440",
    "end": "2374400"
  },
  {
    "text": "our Gans doing better because they're more computationally efficient or our",
    "start": "2374400",
    "end": "2379499"
  },
  {
    "text": "Gans doing better because they prioritize the realism of samples over the accuracy of the density function I",
    "start": "2379499",
    "end": "2385619"
  },
  {
    "text": "think I think all of those are potentially valid explanations and it's it's hard to tell so can you give a",
    "start": "2385619",
    "end": "2391829"
  },
  {
    "start": "2391000",
    "end": "2611000"
  },
  {
    "text": "brief history of Gans from 2014 we paid",
    "start": "2391829",
    "end": "2398069"
  },
  {
    "text": "for 13 yeah so a few highlights in the first paper we just showed that Gans",
    "start": "2398069",
    "end": "2403440"
  },
  {
    "text": "basically work if you look back at the samples we had now they looked terrible on the CFR 10 dataset you can't even",
    "start": "2403440",
    "end": "2410400"
  },
  {
    "text": "recognize objects in them your papers I will use CFR 10 we use em NIST which is",
    "start": "2410400",
    "end": "2416190"
  },
  {
    "text": "little handwritten digits we used the Toronto face database which is small grayscale photos of faces",
    "start": "2416190",
    "end": "2422339"
  },
  {
    "text": "we did have recognizable faces my colleague Bing Xu put together the first again face model for that paper we also",
    "start": "2422339",
    "end": "2430019"
  },
  {
    "text": "had the CFR 10 dataset which is things like very small 32 by 32 pixels of cars",
    "start": "2430019",
    "end": "2438059"
  },
  {
    "text": "and cats and dogs for that we didn't get recognizable objects but all the deep",
    "start": "2438059",
    "end": "2444299"
  },
  {
    "text": "learning people back then we're really used to looking at these failed samples and kind of reading them like tea leaves",
    "start": "2444299",
    "end": "2449460"
  },
  {
    "text": "right and people who are used to reading the tea leaves recognize that our tea",
    "start": "2449460",
    "end": "2454650"
  },
  {
    "text": "leaves at least look different right maybe not necessarily better but there was something unusual about them",
    "start": "2454650",
    "end": "2460730"
  },
  {
    "text": "and that got a lot of us excited one of the next really big steps was lap gown",
    "start": "2460730",
    "end": "2465859"
  },
  {
    "text": "by Emily Denton and seemeth chintala at Facebook AI research where they actually",
    "start": "2465859",
    "end": "2471650"
  },
  {
    "text": "got really good high-resolution photos working with gans for the first time they had a complicated system where they",
    "start": "2471650",
    "end": "2478339"
  },
  {
    "text": "generated the image starting at low res and then scaling up to high res but they were able to get it to work and then in",
    "start": "2478339",
    "end": "2487160"
  },
  {
    "text": "2015 I believe later that same year palek Radford and sumh intelli and Luke",
    "start": "2487160",
    "end": "2494240"
  },
  {
    "text": "Metz published the DC gain paper which it stands for deep convolutional again",
    "start": "2494240",
    "end": "2501010"
  },
  {
    "text": "it's kind of a non unique name because these days basically all gans and even",
    "start": "2501010",
    "end": "2506660"
  },
  {
    "text": "some before that were deep in convolutional but they just kind of picked a name for a really great recipe",
    "start": "2506660",
    "end": "2511970"
  },
  {
    "text": "where they were able to actually using only one model instead of a multi-step process actually generate realistic",
    "start": "2511970",
    "end": "2518599"
  },
  {
    "text": "images of faces and things like that that was sort of like the beginning of",
    "start": "2518599",
    "end": "2525260"
  },
  {
    "text": "the Cambrian explosion of gans like you know once once you got animals that had a backbone you suddenly got lots of",
    "start": "2525260",
    "end": "2530540"
  },
  {
    "text": "different versions of you know like fish and right they have four-legged animals and things like that so so DC Gann",
    "start": "2530540",
    "end": "2536390"
  },
  {
    "text": "became kind of the backbone for many different models that came out used as a baseline even still yeah yeah and so",
    "start": "2536390",
    "end": "2544130"
  },
  {
    "text": "from there I would say some interesting things we've seen are there's a lot you can say about how just the quality of",
    "start": "2544130",
    "end": "2550940"
  },
  {
    "text": "standard image generation ganz has increased but what's also maybe more interesting on an intellectual level is",
    "start": "2550940",
    "end": "2556069"
  },
  {
    "text": "how the things you can use guns for has also changed one thing is that you can",
    "start": "2556069",
    "end": "2561859"
  },
  {
    "text": "use them to learn classifiers without having to have class labels for every",
    "start": "2561859",
    "end": "2566869"
  },
  {
    "text": "example in your your training set so that's called semi-supervised learning my colleague at open AI Tim Solomon's",
    "start": "2566869",
    "end": "2573680"
  },
  {
    "text": "who's at at brain now wrote a paper called improved techniques for training guns I'm a co-author on this paper but I",
    "start": "2573680",
    "end": "2581000"
  },
  {
    "text": "can't claim any credit for this particular part one thing he showed in the paper is that you can take the gun",
    "start": "2581000",
    "end": "2587000"
  },
  {
    "text": "discriminator and use it as a classifier that actually tells you you know this image is a cat this image is a dog this",
    "start": "2587000",
    "end": "2593660"
  },
  {
    "text": "image is a car this image is a truck and so and not just to say whether the image is real or fake but if it is real to say",
    "start": "2593660",
    "end": "2599960"
  },
  {
    "text": "specifically what kind of object it is and he found that you can train these classifiers with far fewer labeled",
    "start": "2599960",
    "end": "2607280"
  },
  {
    "text": "examples learn traditional classifiers so a few supervised based on also not",
    "start": "2607280",
    "end": "2613880"
  },
  {
    "start": "2611000",
    "end": "2666000"
  },
  {
    "text": "just your discrimination ability but your ability to classify you're going to do much you're going to convert much",
    "start": "2613880",
    "end": "2619550"
  },
  {
    "text": "faster to being effective at being a discriminator yeah so for example for",
    "start": "2619550",
    "end": "2625370"
  },
  {
    "text": "the emne status set you want to look at an image of a handwritten digit and say whether it's a 0 a 1 or 2 and so on",
    "start": "2625370",
    "end": "2633280"
  },
  {
    "text": "to get down to less than 1% accuracy required around 60,000 examples until",
    "start": "2633280",
    "end": "2640550"
  },
  {
    "text": "maybe about 2014 or so in 2016 with this semi-supervised degan project tim was",
    "start": "2640550",
    "end": "2647750"
  },
  {
    "text": "able to get below 1% error using only a hundred labeled examples so that was",
    "start": "2647750",
    "end": "2654110"
  },
  {
    "text": "about a 600 X decrease in the amount of labels that he needed he's still using more images in that but he doesn't need",
    "start": "2654110",
    "end": "2661700"
  },
  {
    "text": "to have each of them labeled as you know this one's a 1 this one's a 2 this one's a 0 and so on then to be able to for",
    "start": "2661700",
    "end": "2668690"
  },
  {
    "start": "2666000",
    "end": "2782000"
  },
  {
    "text": "Ganz to be able to generate recognizable objects so object for a particular class you still need labelled data because you",
    "start": "2668690",
    "end": "2677210"
  },
  {
    "text": "need to know what it means to be a particular class cat dog how do you",
    "start": "2677210",
    "end": "2682220"
  },
  {
    "text": "think we can move away from that yeah some researchers at brain Zurich actually just released a really great",
    "start": "2682220",
    "end": "2687920"
  },
  {
    "text": "paper on semi-supervised de Gans whether their goal isn't to classify its to make",
    "start": "2687920",
    "end": "2694690"
  },
  {
    "text": "recognizable objects despite not having a lot of label data they were working off of deep minds big gun project and",
    "start": "2694690",
    "end": "2702020"
  },
  {
    "text": "they showed that they can match the performance of began using only 10% I",
    "start": "2702020",
    "end": "2708050"
  },
  {
    "text": "believe of the of the labels big gun was trained on the image net dataset which is about 1.2 million images and had all",
    "start": "2708050",
    "end": "2714950"
  },
  {
    "text": "of them labelled this latest project from brain Zurich shows that they're able to get away with only having about",
    "start": "2714950",
    "end": "2721670"
  },
  {
    "text": "10% of the of the images labeled and they do that essentially using a",
    "start": "2721670",
    "end": "2727869"
  },
  {
    "text": "clustering algorithm where the discriminator learns to assign the objects to groups and then this",
    "start": "2727869",
    "end": "2735640"
  },
  {
    "text": "understanding that objects can be grouped into you know similar types helps it to form more realistic ideas of",
    "start": "2735640",
    "end": "2743530"
  },
  {
    "text": "what should be appearing in the image because it knows that every image it creates has to come from one of these",
    "start": "2743530",
    "end": "2748810"
  },
  {
    "text": "archetypal groups rather than just being some arbitrary image if you train again",
    "start": "2748810",
    "end": "2753940"
  },
  {
    "text": "with no class labels you tend to get things that look sort of like grass or water or brick or dirt but but without",
    "start": "2753940",
    "end": "2762220"
  },
  {
    "text": "necessarily a lot going on in them and I think that's partly because if you look at a large image net image the object",
    "start": "2762220",
    "end": "2768430"
  },
  {
    "text": "doesn't necessarily occupy the whole image and so you learn to create realistic sets of pixels but you don't",
    "start": "2768430",
    "end": "2775990"
  },
  {
    "text": "necessarily learn that the object is the star of the show and you want it to be in every image you make yeah you've",
    "start": "2775990",
    "end": "2782590"
  },
  {
    "start": "2782000",
    "end": "2971000"
  },
  {
    "text": "heard you talk about the the horse the zebra cycle Gann mapping and how it",
    "start": "2782590",
    "end": "2788350"
  },
  {
    "text": "turns out again thought provoking that horses are usually on grass and zebras",
    "start": "2788350",
    "end": "2794140"
  },
  {
    "text": "are usually on drier terrain so when you're doing that kind of generation you're going to end up generating",
    "start": "2794140",
    "end": "2800500"
  },
  {
    "text": "greener horses or whatever so those are connected together it's not just yeah",
    "start": "2800500",
    "end": "2806320"
  },
  {
    "text": "yeah be able to you're not able to segment yeah it's generating the segments away",
    "start": "2806320",
    "end": "2811510"
  },
  {
    "text": "so there are other types of games you come across in your mind that neural",
    "start": "2811510",
    "end": "2818830"
  },
  {
    "text": "networks can play with each other to to to be able to solve problems yeah the",
    "start": "2818830",
    "end": "2825730"
  },
  {
    "text": "the one that I spend most of my time on is insecurity you can model most",
    "start": "2825730",
    "end": "2831670"
  },
  {
    "text": "interactions as a game where there's attackers trying to break your system and you order the defender trying to",
    "start": "2831670",
    "end": "2837820"
  },
  {
    "text": "build a resilient system there's also domain adversarial learning which is an",
    "start": "2837820",
    "end": "2844119"
  },
  {
    "text": "approach to domain adaptation that looks really a lot like Ganz the the author's had the idea before the game paper came",
    "start": "2844119",
    "end": "2850780"
  },
  {
    "text": "out their paper came out a little bit later and you know they they're very",
    "start": "2850780",
    "end": "2856930"
  },
  {
    "text": "nice and sighted again paper but I know that they actually had the idea before I came out domain adaptation is",
    "start": "2856930",
    "end": "2863470"
  },
  {
    "text": "when you want to train a machine learning model in 1:1 setting called a domain and then deploy it in another",
    "start": "2863470",
    "end": "2869020"
  },
  {
    "text": "domain later and he would like it to perform well in the new domain even though the new domain is different from",
    "start": "2869020",
    "end": "2874150"
  },
  {
    "text": "how it was trained so for example you might want to train on a really clean",
    "start": "2874150",
    "end": "2879340"
  },
  {
    "text": "image data set like image net but then deploy on users phones where the user is taking you know pictures in the dark or",
    "start": "2879340",
    "end": "2886120"
  },
  {
    "text": "pictures while moving quickly and just pictures that aren't really centered or composed all that well",
    "start": "2886120",
    "end": "2892980"
  },
  {
    "text": "when you take a normal machine learning model it often degrades really badly when you move to the new domain because",
    "start": "2893000",
    "end": "2899280"
  },
  {
    "text": "it looks so different from what the model was trained on domain adaptation algorithms try to smooth out that gap",
    "start": "2899280",
    "end": "2904710"
  },
  {
    "text": "and the domain adverse oral approach is based on training a feature extractor where the features have the same",
    "start": "2904710",
    "end": "2911339"
  },
  {
    "text": "statistics regardless of which domain you extracted them on so in the domain adversarial game you have one player",
    "start": "2911339",
    "end": "2917580"
  },
  {
    "text": "that's a feature extractor and another player that's a domain recognizer the domain recognizer wants to look at",
    "start": "2917580",
    "end": "2923790"
  },
  {
    "text": "the output of the feature extractor and guess which of the two domains oh the features came from so it's a lot like",
    "start": "2923790",
    "end": "2929940"
  },
  {
    "text": "the real versus fake discriminator and ends and then the feature extractor you",
    "start": "2929940",
    "end": "2935099"
  },
  {
    "text": "can think of as loosely analogous to the generator in games except what's trying to do here is both fool the domain",
    "start": "2935099",
    "end": "2941790"
  },
  {
    "text": "recognizer and two not knowing which domain the data came from and also extract features that are good for",
    "start": "2941790",
    "end": "2947490"
  },
  {
    "text": "classification so at the end of the day you can in in the cases where it works",
    "start": "2947490",
    "end": "2953430"
  },
  {
    "text": "out you can actually get features that work about the same in both domains",
    "start": "2953430",
    "end": "2960050"
  },
  {
    "text": "sometimes this has a drawback where in order to make things work the same in both domains it just gets worse at the",
    "start": "2960050",
    "end": "2965730"
  },
  {
    "text": "first one but there are a lot of cases where it actually works out well on both do you think gas being useful in the",
    "start": "2965730",
    "end": "2973170"
  },
  {
    "start": "2971000",
    "end": "3130000"
  },
  {
    "text": "context of data augmentation yeah one thing you could hope for with Kenz is you could imagine I've got a limited",
    "start": "2973170",
    "end": "2980609"
  },
  {
    "text": "training set and I'd like to make more training data to train something else like a classifier you could train Magan",
    "start": "2980609",
    "end": "2988200"
  },
  {
    "text": "on the training set and then create more data and then maybe the classifier would",
    "start": "2988200",
    "end": "2994470"
  },
  {
    "text": "perform better on the test set after training on those big ERG and generated data set so that's the simplest version",
    "start": "2994470",
    "end": "3000020"
  },
  {
    "text": "of of something you might hope would work I've never heard of that particular approach working but I think there's",
    "start": "3000020",
    "end": "3006109"
  },
  {
    "text": "some there's some closely related things that that I think could work in the",
    "start": "3006109",
    "end": "3011210"
  },
  {
    "text": "future and some that actually already have worked so if you think a little bit about what we'd be hoping for if we use the gun to make more training data we're",
    "start": "3011210",
    "end": "3018320"
  },
  {
    "text": "hoping that again we'll generalize to new examples better than the classifier would have generalized if it was trained",
    "start": "3018320",
    "end": "3024680"
  },
  {
    "text": "on the same buddy at us and I don't know of any reason to believe that the Gann would generalize better than the classifier would but",
    "start": "3024680",
    "end": "3031700"
  },
  {
    "text": "what we might hope for is that the Gann could generalize differently from a specific classifier so one thing I think",
    "start": "3031700",
    "end": "3038330"
  },
  {
    "text": "is worth trying that I haven't personally tried but someone could try is what have you trained a whole lot of",
    "start": "3038330",
    "end": "3043370"
  },
  {
    "text": "different generative models on the same training set create samples from all of them and then train a classifier on that",
    "start": "3043370",
    "end": "3049930"
  },
  {
    "text": "because each of the generative models might generalize in a slightly different way they might capture many different",
    "start": "3049930",
    "end": "3056060"
  },
  {
    "text": "axes of variation that one individual model wouldn't and then the classifier can capture all of those ideas by",
    "start": "3056060",
    "end": "3062030"
  },
  {
    "text": "training in all of their data so we'd be a little bit like making an ensemble of classifiers and I say oh of gans",
    "start": "3062030",
    "end": "3067430"
  },
  {
    "text": "yeah in a way I think that could generalize better the other thing that gans are really good for is not",
    "start": "3067430",
    "end": "3075170"
  },
  {
    "text": "necessarily generating new data that's exactly like what you already have but by generating new data that has",
    "start": "3075170",
    "end": "3081950"
  },
  {
    "text": "different properties from the data you already had one thing that you can do is you can create differentially private",
    "start": "3081950",
    "end": "3088370"
  },
  {
    "text": "data so suppose that you have something like medical records and you don't want to train a classifier on the medical",
    "start": "3088370",
    "end": "3094340"
  },
  {
    "text": "records and then publish the classifier because someone might be able to reverse-engineer some of the medical records you trained on there's a paper",
    "start": "3094340",
    "end": "3101060"
  },
  {
    "text": "from Casey greens lab that shows how you can train again using differential privacy and then the samples one again",
    "start": "3101060",
    "end": "3108380"
  },
  {
    "text": "still have the same differential privacy guarantees as the parameters that again so you can make fake patient data for",
    "start": "3108380",
    "end": "3115880"
  },
  {
    "text": "other researchers to use and they can do almost anything they want with that data because it doesn't come from real people",
    "start": "3115880",
    "end": "3121850"
  },
  {
    "text": "and the differential privacy mechanism gives you clear guarantees on how much",
    "start": "3121850",
    "end": "3126950"
  },
  {
    "text": "the original people's data has been protected that's really interesting actually I haven't heard you talk about",
    "start": "3126950",
    "end": "3132320"
  },
  {
    "start": "3130000",
    "end": "3600000"
  },
  {
    "text": "that before in terms of fairness I've seen from triple AI your talk",
    "start": "3132320",
    "end": "3138730"
  },
  {
    "text": "how can an adversarial machine learning help models be more fair with respect to",
    "start": "3138730",
    "end": "3143990"
  },
  {
    "text": "sensitive variables yeah there was a paper from Amos Torquay's lab about how",
    "start": "3143990",
    "end": "3149060"
  },
  {
    "text": "to learn machine learning models that are incapable of using specific variables so to say for example you",
    "start": "3149060",
    "end": "3155780"
  },
  {
    "text": "wanted to make predictions that are not affected by gender it isn't enough to just leave gender out",
    "start": "3155780",
    "end": "3161350"
  },
  {
    "text": "of the input to the model you can often infer gender from a lot of other characteristics like say that you have",
    "start": "3161350",
    "end": "3166600"
  },
  {
    "text": "the person's name but you're not told their gender well right if if their name is Ian they're kind of obviously a man",
    "start": "3166600",
    "end": "3172890"
  },
  {
    "text": "so what you'd like to do is make a machine learning model that can still take in a lot of different attributes",
    "start": "3172890",
    "end": "3177910"
  },
  {
    "text": "and make a really accurate informed prediction but be confident that it",
    "start": "3177910",
    "end": "3183940"
  },
  {
    "text": "isn't reverse engineering gender or another sensitive variable internally you can do that using something very",
    "start": "3183940",
    "end": "3189580"
  },
  {
    "text": "similar to the domain adversarial approach where you have one player that's a feature extractor and another",
    "start": "3189580",
    "end": "3196540"
  },
  {
    "text": "player that's a feature analyzer and you want to make sure that the feature analyzer is not able to guess the value",
    "start": "3196540",
    "end": "3203500"
  },
  {
    "text": "of the sensitive variable that you're trying to keep private right that's yeah I love this approach so we'll yeah with",
    "start": "3203500",
    "end": "3209770"
  },
  {
    "text": "the with the feature you're not able to infer right this sensitive variables",
    "start": "3209770",
    "end": "3215710"
  },
  {
    "text": "yeah brilliant it's quite quite brilliant and simple actually another way I think that Ganz in particular",
    "start": "3215710",
    "end": "3222730"
  },
  {
    "text": "could be used for fairness would be to make something like a cycle again where you can take data from one domain and",
    "start": "3222730",
    "end": "3229840"
  },
  {
    "text": "convert it into another we've seen cycle again turning horses into zebras we've seen other unsupervised gains made by",
    "start": "3229840",
    "end": "3237910"
  },
  {
    "text": "Ming Yue Lu doing things like turning day photos into night photos I think for",
    "start": "3237910",
    "end": "3244300"
  },
  {
    "text": "fairness you could imagine taking records for people in one group and transforming them into analogous people",
    "start": "3244300",
    "end": "3250450"
  },
  {
    "text": "in another group and testing to see if they're they're treated equitably across those two groups there's a lot of things",
    "start": "3250450",
    "end": "3257050"
  },
  {
    "text": "that be hard to get right to make sure that the conversion process itself is fair and I don't think it's anywhere",
    "start": "3257050",
    "end": "3263110"
  },
  {
    "text": "near something that we could actually use yet but if you could design that conversion process very carefully it might give you a way of doing audits",
    "start": "3263110",
    "end": "3269670"
  },
  {
    "text": "where you say what if we took people from this group converted them into equivalent people in another group does",
    "start": "3269670",
    "end": "3275620"
  },
  {
    "text": "the system actually treat them how it ought to that's also really interesting",
    "start": "3275620",
    "end": "3281170"
  },
  {
    "text": "you know in a popular in popular press and in general in our imagination you",
    "start": "3281170",
    "end": "3288790"
  },
  {
    "text": "think well gangs are able to generate data and use to think about deep fakes or being able",
    "start": "3288790",
    "end": "3295010"
  },
  {
    "text": "to sort of maliciously generate data that fakes the identity of other people",
    "start": "3295010",
    "end": "3300770"
  },
  {
    "text": "is this something of a concern to you is this something if you look 10 20 years into the future is that something that",
    "start": "3300770",
    "end": "3308480"
  },
  {
    "text": "pops up in your work in the work of the community that's working on generating models I'm a lot less concerned about 20",
    "start": "3308480",
    "end": "3315079"
  },
  {
    "text": "years from now than the next few years I think there will be a kind of bumpy cultural transition as people encounter",
    "start": "3315079",
    "end": "3322670"
  },
  {
    "text": "this idea that there can be very realistic videos and audio that aren't real I think 20 years from now people",
    "start": "3322670",
    "end": "3328849"
  },
  {
    "text": "will mostly understand that you shouldn't believe something is real just because you saw a video of it people",
    "start": "3328849",
    "end": "3334310"
  },
  {
    "text": "will expect to see that it's been cryptographically signed or or have some",
    "start": "3334310",
    "end": "3339440"
  },
  {
    "text": "other mechanism to make them believe the the content is real there's already",
    "start": "3339440",
    "end": "3344750"
  },
  {
    "text": "people working on this like there's a startup called true pic that provides a lot of mechanisms for authenticating",
    "start": "3344750",
    "end": "3350839"
  },
  {
    "text": "that an image is real there they're maybe not quite up to having a state actor try to to evade their their",
    "start": "3350839",
    "end": "3358550"
  },
  {
    "text": "verification techniques but it's something people are already working on and I think we'll get right eventually",
    "start": "3358550",
    "end": "3363800"
  },
  {
    "text": "so you think authentication will will eventually went out so being able to",
    "start": "3363800",
    "end": "3368930"
  },
  {
    "text": "authenticate that this is real and this is not yeah as opposed to gas just",
    "start": "3368930",
    "end": "3374510"
  },
  {
    "text": "getting better and better or generative models being able to get better and better to where the nature of what is",
    "start": "3374510",
    "end": "3380300"
  },
  {
    "text": "real I don't think we'll ever be able to look at the pixels of a photo and tell",
    "start": "3380300",
    "end": "3385819"
  },
  {
    "text": "you for sure that it's real or not real and I think it would actually be",
    "start": "3385819",
    "end": "3391060"
  },
  {
    "text": "somewhat dangerous to rely on that approach too much if you make a really good fake detector and then someone's",
    "start": "3391060",
    "end": "3397310"
  },
  {
    "text": "able to fool your fake detector and your fake detector says this image is not fake then it's even more credible than",
    "start": "3397310",
    "end": "3403550"
  },
  {
    "text": "if you've never made a fake detector in the first place what I do think we'll get to is systems",
    "start": "3403550",
    "end": "3410180"
  },
  {
    "text": "that we can kind of use behind the scenes for to make estimates of what's going on and maybe not like use them in",
    "start": "3410180",
    "end": "3417410"
  },
  {
    "text": "court for a definitive analysis I also think we will likely get better",
    "start": "3417410",
    "end": "3422599"
  },
  {
    "text": "authentication systems where you know if a match every phone cryptographically signs",
    "start": "3422599",
    "end": "3428359"
  },
  {
    "text": "everything that comes out of it you wouldn't go to conclusively tell that an image was real but you would be able to",
    "start": "3428359",
    "end": "3435200"
  },
  {
    "text": "tell somebody who knew the appropriate private key for this phone was actually",
    "start": "3435200",
    "end": "3442490"
  },
  {
    "text": "able to sign this image and upload it to this server at this timestamp so you",
    "start": "3442490",
    "end": "3449119"
  },
  {
    "text": "could imagine maybe you make phones that have the private keys Hardware embedded in them if like a State Security Agency",
    "start": "3449119",
    "end": "3457369"
  },
  {
    "text": "really wants to infiltrate the company they could probably you know plant a private key of their choice or break",
    "start": "3457369",
    "end": "3463369"
  },
  {
    "text": "open the chip and learn the private key or something like that but it would make it a lot harder for an adversary with",
    "start": "3463369",
    "end": "3469910"
  },
  {
    "text": "fewer resources to fake things most of us yeah okay okay so you mentioned the beer and the bar and the new ideas you",
    "start": "3469910",
    "end": "3478430"
  },
  {
    "text": "were able to implement this or come up with this new idea pretty quickly and implement it pretty quickly do you think",
    "start": "3478430",
    "end": "3484730"
  },
  {
    "text": "there are still many such groundbreaking ideas and deep learning that could be developed so quickly yeah I do think",
    "start": "3484730",
    "end": "3491750"
  },
  {
    "text": "that there are a lot of ideas that can be developed really quickly guns were probably a little bit of an outlier on",
    "start": "3491750",
    "end": "3497930"
  },
  {
    "text": "the whole like one-hour timescale right but just in terms of a like low resource",
    "start": "3497930",
    "end": "3503140"
  },
  {
    "text": "ideas where you do something really different on the algorithm scale and get a big payback I think it's not as likely",
    "start": "3503140",
    "end": "3511190"
  },
  {
    "text": "that you'll see that in terms of things like core machine learning technologies like a better classifier or a better",
    "start": "3511190",
    "end": "3516950"
  },
  {
    "text": "reinforcement learning algorithm or a better generative model if I had the gun idea today it would be a lot harder to",
    "start": "3516950",
    "end": "3523369"
  },
  {
    "text": "prove that it was useful than it was back in 2014 because I would need to get",
    "start": "3523369",
    "end": "3529130"
  },
  {
    "text": "it running on something like image net or celibate high resolution you know",
    "start": "3529130",
    "end": "3534289"
  },
  {
    "text": "those take a while to train you couldn't you couldn't train it in an hour and know that it was something really new",
    "start": "3534289",
    "end": "3539480"
  },
  {
    "text": "and exciting back in 2014 shredding an amnesty was enough but there are other",
    "start": "3539480",
    "end": "3545150"
  },
  {
    "text": "areas of machine learning where I think a new idea could actually be developed",
    "start": "3545150",
    "end": "3551210"
  },
  {
    "text": "really quickly with low resources what's your intuition about what areas of machine learning are ripe for this yeah",
    "start": "3551210",
    "end": "3557900"
  },
  {
    "text": "so I think fairness and interpretability our areas where we just really don't",
    "start": "3557900",
    "end": "3566039"
  },
  {
    "text": "have any idea how anything should be done yet like for interpretability I don't think we even have the right definitions and",
    "start": "3566039",
    "end": "3572369"
  },
  {
    "text": "even just defining a really useful concept you don't even need to run any experiments could have a huge impact on",
    "start": "3572369",
    "end": "3579180"
  },
  {
    "text": "the field we've seen that for example in differential privacy that uh Cynthia Dworkin her collaborators made this",
    "start": "3579180",
    "end": "3585719"
  },
  {
    "text": "technical definition of privacy where before a lot of things are really mushy and then with that definition you could",
    "start": "3585719",
    "end": "3591809"
  },
  {
    "text": "actually design randomized algorithms for accessing databases and guarantee that they preserved individual people's",
    "start": "3591809",
    "end": "3598229"
  },
  {
    "text": "privacy in a in like a mathematical quantitative sense right now we all talk",
    "start": "3598229",
    "end": "3604589"
  },
  {
    "text": "a lot about how interpretable different machine learning algorithms are but it's really just people's opinion and",
    "start": "3604589",
    "end": "3609959"
  },
  {
    "text": "everybody probably has a different idea of what interpretability means in their head if we could define some concept",
    "start": "3609959",
    "end": "3615779"
  },
  {
    "text": "related to interpretability that's actually measurable that would be a huge leap forward even without a new",
    "start": "3615779",
    "end": "3621269"
  },
  {
    "text": "algorithm that increases that quantity and also once once we had the definition",
    "start": "3621269",
    "end": "3627299"
  },
  {
    "text": "of differential privacy it was fast to get the algorithms that guaranteed it so you could imagine once we have",
    "start": "3627299",
    "end": "3632819"
  },
  {
    "text": "definitions of good concepts and interpretability we might be able to provide the algorithms that have the",
    "start": "3632819",
    "end": "3638549"
  },
  {
    "text": "interpretability guarantees quickly to what do you think it takes to build a",
    "start": "3638549",
    "end": "3646319"
  },
  {
    "text": "system with human level intelligence as we quickly venture into the philosophical so artificial general",
    "start": "3646319",
    "end": "3653069"
  },
  {
    "text": "intelligence what do you think I I think that it definitely takes better",
    "start": "3653069",
    "end": "3660900"
  },
  {
    "text": "environments than we currently have for training agents that we want them to have a really wide diversity of",
    "start": "3660900",
    "end": "3666599"
  },
  {
    "text": "experiences I also think it's going to take really a lot of computation it's",
    "start": "3666599",
    "end": "3671910"
  },
  {
    "text": "hard to imagine exactly how much so you're optimistic about simulation simulating a variety of environments is",
    "start": "3671910",
    "end": "3678239"
  },
  {
    "text": "the path forward I think it's a necessary ingredient yeah I don't think",
    "start": "3678239",
    "end": "3683789"
  },
  {
    "text": "that we're going to get to artificial general intelligence by training on fixed datasets or by thinking really",
    "start": "3683789",
    "end": "3691049"
  },
  {
    "text": "hard about the problem I think that the the agent really needs to interact and have a variety of",
    "start": "3691049",
    "end": "3696859"
  },
  {
    "text": "experiences within the same lifespan and today we have many different models that",
    "start": "3696859",
    "end": "3704210"
  },
  {
    "text": "can each do one thing and we tend to train them on one data set or one RL environment sometimes they're actually",
    "start": "3704210",
    "end": "3710989"
  },
  {
    "text": "papers about getting one set of parameters to perform well in many different RL environments but we don't",
    "start": "3710989",
    "end": "3717380"
  },
  {
    "text": "really have anything like an agent that goes seamlessly from one type of experience to another and and really",
    "start": "3717380",
    "end": "3723890"
  },
  {
    "text": "integrates all the different things that it does over the course of its life when we do see multi agent environments they",
    "start": "3723890",
    "end": "3730670"
  },
  {
    "text": "tend to be there are so many multi environment agents they tend to be similar environments like all of them",
    "start": "3730670",
    "end": "3737539"
  },
  {
    "text": "are playing like an action based video game we don't really have an agent that goes from you know playing a video game",
    "start": "3737539",
    "end": "3743839"
  },
  {
    "text": "to like reading The Wall Street Journal to predicting how effective a molecule",
    "start": "3743839",
    "end": "3750079"
  },
  {
    "text": "will be as a drug or something like that what do you think is a good test for intelligence in you view it's been a lot",
    "start": "3750079",
    "end": "3757430"
  },
  {
    "text": "of benchmarks started with the with Alan Turing a natural conversation being good",
    "start": "3757430",
    "end": "3763969"
  },
  {
    "text": "being a good benchmark for intelligence what what are what would you and good",
    "start": "3763969",
    "end": "3770420"
  },
  {
    "text": "fellows sit back and be really damn impressed if a system was able to accomplish something that doesn't take a",
    "start": "3770420",
    "end": "3777349"
  },
  {
    "text": "lot of glue from human engineers so imagine that instead of having to go to",
    "start": "3777349",
    "end": "3783769"
  },
  {
    "text": "the CFR website and download CFR 10 and then write a Python script to parse it",
    "start": "3783769",
    "end": "3790160"
  },
  {
    "text": "and all that you could just point an agent at the CFR 10 problem and it",
    "start": "3790160",
    "end": "3796789"
  },
  {
    "text": "downloads and extracts the data and trains a model and starts giving you predictions I feel like something that",
    "start": "3796789",
    "end": "3803960"
  },
  {
    "text": "doesn't need to have every step of the pipeline assembled for it it definitely",
    "start": "3803960",
    "end": "3809299"
  },
  {
    "text": "understands what it's doing is Auto ml moving into that direction are you thinking wave and bigger autosomal has",
    "start": "3809299",
    "end": "3815269"
  },
  {
    "text": "mostly been moving toward once we've built all the glue can the machine",
    "start": "3815269",
    "end": "3820579"
  },
  {
    "text": "learning system to design the architecture really well so I'm we're saying like",
    "start": "3820579",
    "end": "3826460"
  },
  {
    "text": "if something knows how to pre-process the data so that it successfully accomplishes the task then it would be",
    "start": "3826460",
    "end": "3832819"
  },
  {
    "text": "very hard to argue that it doesn't truly understand the task in some fundamental sense and I don't necessarily know that that's",
    "start": "3832819",
    "end": "3839839"
  },
  {
    "text": "like the philosophical definition of intelligence but that's something that would be really cool to build that would be really useful and would impress me",
    "start": "3839839",
    "end": "3845540"
  },
  {
    "text": "and would convince me that we've made a step forward in real AI so you give it like the URL for Wikipedia and then next",
    "start": "3845540",
    "end": "3855349"
  },
  {
    "text": "day expected to be able to solve CFR 10 or like you type in a paragraph",
    "start": "3855349",
    "end": "3860599"
  },
  {
    "text": "explaining what you want it to do and it figures out what web searches it should run and downloads all the whole",
    "start": "3860599",
    "end": "3866569"
  },
  {
    "text": "unnecessary ingredients so you have a very clear calm way of speaking no arms",
    "start": "3866569",
    "end": "3875410"
  },
  {
    "text": "easy to edit I've seen comments for both you and I have been identified as both",
    "start": "3875410",
    "end": "3882260"
  },
  {
    "text": "potentially being robots if you have to prove to the world that you are indeed human how would you do it but I can",
    "start": "3882260",
    "end": "3891410"
  },
  {
    "text": "understand thinking that I'm a robot it's the flipside yeah touring test I",
    "start": "3891410",
    "end": "3897220"
  },
  {
    "text": "think yeah yeah the proof prove your human test I mean I lecture so you have",
    "start": "3897220",
    "end": "3903160"
  },
  {
    "text": "to is there something that's truly unique in your mind I suppose it doesn't",
    "start": "3903160",
    "end": "3909490"
  },
  {
    "text": "go back to just natural language again just being able to so proving proving that I'm not a robot with today's",
    "start": "3909490",
    "end": "3915460"
  },
  {
    "text": "technology yeah that's pretty straightforward too like my conversation today hasn't veered",
    "start": "3915460",
    "end": "3920530"
  },
  {
    "text": "off into you know talking about the stock market or something because in my training data but I think it's more",
    "start": "3920530",
    "end": "3927010"
  },
  {
    "text": "generally trying to prove that something is real from the content alone it was incredibly hard that's one of the main things I've gotten out of my can",
    "start": "3927010",
    "end": "3932950"
  },
  {
    "text": "research that you can simulate almost anything and so you have to really step",
    "start": "3932950",
    "end": "3938770"
  },
  {
    "text": "back to a separate channel to prove that slang is real so like I guess I should have had myself stamped on a blockchain",
    "start": "3938770",
    "end": "3945940"
  },
  {
    "text": "when I was born or something but I didn't do that so according to my own research methodology there's just no way",
    "start": "3945940",
    "end": "3951340"
  },
  {
    "text": "to know at this point so what last question problem stands all for you that you're really excited about",
    "start": "3951340",
    "end": "3957700"
  },
  {
    "text": "challenging in the near future so I think resistance to adversarial examples figuring out how to make machine",
    "start": "3957700",
    "end": "3964180"
  },
  {
    "text": "learning secure against an adversary who wants to interfere it in control with it is one of the most important things",
    "start": "3964180",
    "end": "3970540"
  },
  {
    "text": "researchers today could solve in all domains in image language driving in I",
    "start": "3970540",
    "end": "3977800"
  },
  {
    "text": "guess I'm most concerned about domains we haven't really encountered yet like like imagine twenty years from now when",
    "start": "3977800",
    "end": "3984190"
  },
  {
    "text": "we're using advanced day eyes to do things we haven't even thought of yet like if you ask people what are the",
    "start": "3984190",
    "end": "3991000"
  },
  {
    "text": "important problems in security of phones in in like 2002 I don't think we would",
    "start": "3991000",
    "end": "3998170"
  },
  {
    "text": "have anticipated that we're using them for you know nearly as many things as we're using them for today I think it's",
    "start": "3998170",
    "end": "4003990"
  },
  {
    "text": "going to be like that with AI that you can kind of try to speculate about where it's going but really the business opportunities that end up taking off",
    "start": "4003990",
    "end": "4010380"
  },
  {
    "text": "would be hard to predict ahead of time well you can predict ahead of time is",
    "start": "4010380",
    "end": "4015450"
  },
  {
    "text": "that almost anything you can do with machine learning you would like to make sure that people can't get it to do what",
    "start": "4015450",
    "end": "4022380"
  },
  {
    "text": "they want rather than what you want just by showing it a funny QR code or a funny input pattern and you think that",
    "start": "4022380",
    "end": "4029069"
  },
  {
    "text": "the set of methodology to do that can be bigger than you want domain and that's I think so yeah yeah like one methodology",
    "start": "4029069",
    "end": "4036660"
  },
  {
    "text": "that I think is not not a specific methodology but like a category of",
    "start": "4036660",
    "end": "4041729"
  },
  {
    "text": "solutions that I'm excited about today is making dynamic models that change every time they make a prediction so",
    "start": "4041729",
    "end": "4048359"
  },
  {
    "text": "right now we tend to train models and then after they're trained we freeze them and we just use the same rule to",
    "start": "4048359",
    "end": "4055319"
  },
  {
    "text": "classify everything that comes in from then on that's really a sitting duck from a security point of view if you",
    "start": "4055319",
    "end": "4062039"
  },
  {
    "text": "always output the same answer for the same input then people can just run",
    "start": "4062039",
    "end": "4067650"
  },
  {
    "text": "inputs through until they find a mistake that benefits them and then they use the same mistake over and over and over again I think having a model that",
    "start": "4067650",
    "end": "4075059"
  },
  {
    "text": "updates its predictions so that it's harder to predict what you're going to get will make it harder for the for an",
    "start": "4075059",
    "end": "4082289"
  },
  {
    "text": "adversary to really take control of the system and make it do what they want it to do yeah models that maintain a bit of",
    "start": "4082289",
    "end": "4088529"
  },
  {
    "text": "a sense of mystery and bought them because they always keep changing yeah and thanks so much for talking today it",
    "start": "4088529",
    "end": "4094349"
  },
  {
    "text": "was awesome thank you for coming in that's great to see you",
    "start": "4094349",
    "end": "4098448"
  },
  {
    "text": "you",
    "start": "4104009",
    "end": "4106068"
  }
]
[
  {
    "text": "yeah so today we're looking at um the",
    "start": "560",
    "end": "2760"
  },
  {
    "text": "focus of the lab which is thinking about",
    "start": "2760",
    "end": "6000"
  },
  {
    "text": "AI after geni",
    "start": "6000",
    "end": "10280"
  },
  {
    "text": "plateaus so gen models are actually",
    "start": "10759",
    "end": "13400"
  },
  {
    "text": "extraordinarily good given the",
    "start": "13400",
    "end": "15000"
  },
  {
    "text": "Simplicity of what is being done so just",
    "start": "15000",
    "end": "17199"
  },
  {
    "text": "as a 30 second recap what we're doing in",
    "start": "17199",
    "end": "19000"
  },
  {
    "text": "gen is we're doing supervised learning",
    "start": "19000",
    "end": "21519"
  },
  {
    "text": "or self-supervised learning we're",
    "start": "21519",
    "end": "23119"
  },
  {
    "text": "feeding in uh a part of a Data Corpus",
    "start": "23119",
    "end": "25560"
  },
  {
    "text": "large data corus to predict the future",
    "start": "25560",
    "end": "28760"
  },
  {
    "text": "and as a consequent these systems are",
    "start": "28760",
    "end": "31119"
  },
  {
    "text": "really really good at doing text like",
    "start": "31119",
    "end": "33960"
  },
  {
    "text": "tasks like Q&A question answering acting",
    "start": "33960",
    "end": "36800"
  },
  {
    "text": "like a chatbot and so on and so forth",
    "start": "36800",
    "end": "39440"
  },
  {
    "text": "however a lot of research now has shown",
    "start": "39440",
    "end": "40879"
  },
  {
    "text": "that these systems are extraordinarily",
    "start": "40879",
    "end": "42800"
  },
  {
    "text": "ill suited for taking actions and for",
    "start": "42800",
    "end": "45480"
  },
  {
    "text": "taking decisions in the world that",
    "start": "45480",
    "end": "46800"
  },
  {
    "text": "requires trial and error learning um",
    "start": "46800",
    "end": "49360"
  },
  {
    "text": "long-term planning or um complicated",
    "start": "49360",
    "end": "52440"
  },
  {
    "text": "reasoning in the real world so the first",
    "start": "52440",
    "end": "54520"
  },
  {
    "text": "question is if we are going to go beyond",
    "start": "54520",
    "end": "56760"
  },
  {
    "text": "supervised learning this means we have",
    "start": "56760",
    "end": "58559"
  },
  {
    "text": "to have ai systems that can actually",
    "start": "58559",
    "end": "60719"
  },
  {
    "text": "take actions uh and and do Tri and never",
    "start": "60719",
    "end": "63039"
  },
  {
    "text": "learning learn from experience like very",
    "start": "63039",
    "end": "65439"
  },
  {
    "text": "much like humans do the challenge with",
    "start": "65439",
    "end": "68000"
  },
  {
    "text": "this is that it's sort of scary to have",
    "start": "68000",
    "end": "70680"
  },
  {
    "text": "ai systems that are taking these actions",
    "start": "70680",
    "end": "73159"
  },
  {
    "text": "in the real world because you can",
    "start": "73159",
    "end": "75119"
  },
  {
    "text": "imagine trialing a learning can go",
    "start": "75119",
    "end": "77200"
  },
  {
    "text": "really wrong if you're doing this in the",
    "start": "77200",
    "end": "79080"
  },
  {
    "text": "real world in the real world furthermore",
    "start": "79080",
    "end": "82400"
  },
  {
    "text": "probably you also need a lot of",
    "start": "82400",
    "end": "83759"
  },
  {
    "text": "different trial and error data here so",
    "start": "83759",
    "end": "86040"
  },
  {
    "text": "like we need the Internet of text to get",
    "start": "86040",
    "end": "89159"
  },
  {
    "text": "models that a good are text based tasks",
    "start": "89159",
    "end": "91280"
  },
  {
    "text": "and text based reasoning I believe we",
    "start": "91280",
    "end": "93759"
  },
  {
    "text": "also need something like the internet of",
    "start": "93759",
    "end": "95920"
  },
  {
    "text": "environments to get good AG gentic",
    "start": "95920",
    "end": "97880"
  },
  {
    "text": "models models that can take actions that",
    "start": "97880",
    "end": "99840"
  },
  {
    "text": "can plan that can do this sort of like",
    "start": "99840",
    "end": "102200"
  },
  {
    "text": "multi-term decision making and what this",
    "start": "102200",
    "end": "104560"
  },
  {
    "text": "means is we will have to be training",
    "start": "104560",
    "end": "106360"
  },
  {
    "text": "these models in simulated environments",
    "start": "106360",
    "end": "109520"
  },
  {
    "text": "rather than having them trained just on",
    "start": "109520",
    "end": "111479"
  },
  {
    "text": "data that comes from a Text corpus or",
    "start": "111479",
    "end": "113280"
  },
  {
    "text": "from a fixed uh data set these systems",
    "start": "113280",
    "end": "115880"
  },
  {
    "text": "will have to be trained in environments",
    "start": "115880",
    "end": "117280"
  },
  {
    "text": "that are running virtually on a on a",
    "start": "117280",
    "end": "120680"
  },
  {
    "text": "computer why is this great because I",
    "start": "120680",
    "end": "122799"
  },
  {
    "text": "expect that computers will be getting",
    "start": "122799",
    "end": "124240"
  },
  {
    "text": "faster but we're not going to have",
    "start": "124240",
    "end": "126240"
  },
  {
    "text": "exponentially More Humans on the world",
    "start": "126240",
    "end": "128000"
  },
  {
    "text": "so human data will be limited but",
    "start": "128000",
    "end": "129599"
  },
  {
    "text": "computers are going to keep accelerating",
    "start": "129599",
    "end": "131080"
  },
  {
    "text": "which means this compute only scaling",
    "start": "131080",
    "end": "133480"
  },
  {
    "text": "which is the underlying sort of tagline",
    "start": "133480",
    "end": "135640"
  },
  {
    "text": "for the work that we do at flare will be",
    "start": "135640",
    "end": "137560"
  },
  {
    "text": "a recipe towards uh greater Innovations",
    "start": "137560",
    "end": "139879"
  },
  {
    "text": "the issue here is we've been relying in",
    "start": "139879",
    "end": "141680"
  },
  {
    "text": "gen on the Cod scaling of computing data",
    "start": "141680",
    "end": "144080"
  },
  {
    "text": "we're now running out of human data so",
    "start": "144080",
    "end": "146239"
  },
  {
    "text": "moving towards compute only scaling one",
    "start": "146239",
    "end": "148280"
  },
  {
    "text": "answer is let's run virtual environments",
    "start": "148280",
    "end": "150920"
  },
  {
    "text": "where agents can take actions can do",
    "start": "150920",
    "end": "152519"
  },
  {
    "text": "trial narrow learning the question then",
    "start": "152519",
    "end": "154120"
  },
  {
    "text": "is those environments won't be exactly",
    "start": "154120",
    "end": "156200"
  },
  {
    "text": "like the real world and we won't know",
    "start": "156200",
    "end": "158480"
  },
  {
    "text": "exactly what task to model so how can we",
    "start": "158480",
    "end": "160959"
  },
  {
    "text": "go in and design distributions over",
    "start": "160959",
    "end": "164280"
  },
  {
    "text": "tasks such that the agent becomes robust",
    "start": "164280",
    "end": "167480"
  },
  {
    "text": "to",
    "start": "167480",
    "end": "168879"
  },
  {
    "text": "whatever uh specific instance of that",
    "start": "168879",
    "end": "171239"
  },
  {
    "text": "distribution they might be encountering",
    "start": "171239",
    "end": "172720"
  },
  {
    "text": "at the at test time in the real world",
    "start": "172720",
    "end": "175319"
  },
  {
    "text": "okay so in in simple terms is let's",
    "start": "175319",
    "end": "178319"
  },
  {
    "text": "let's imagine I have um a a distribution",
    "start": "178319",
    "end": "181519"
  },
  {
    "text": "of environments which for example could",
    "start": "181519",
    "end": "183000"
  },
  {
    "text": "be as simple as saying I have a gr world",
    "start": "183000",
    "end": "185760"
  },
  {
    "text": "and I know at test time I'm going to",
    "start": "185760",
    "end": "188319"
  },
  {
    "text": "encoun an agent that needs to navigate",
    "start": "188319",
    "end": "190840"
  },
  {
    "text": "in some sort of great world from a",
    "start": "190840",
    "end": "192840"
  },
  {
    "text": "starting position to a goal position in",
    "start": "192840",
    "end": "195040"
  },
  {
    "text": "the shortest path but I don't know at",
    "start": "195040",
    "end": "196680"
  },
  {
    "text": "all what this exact instance will be how",
    "start": "196680",
    "end": "199599"
  },
  {
    "text": "do I design a method that can be good on",
    "start": "199599",
    "end": "202000"
  },
  {
    "text": "all possible great worlds and once so",
    "start": "202000",
    "end": "204000"
  },
  {
    "text": "that at test time it can even generalize",
    "start": "204000",
    "end": "205879"
  },
  {
    "text": "to something that has a lot of structure",
    "start": "205879",
    "end": "208360"
  },
  {
    "text": "for example if you imagine I have",
    "start": "208360",
    "end": "210280"
  },
  {
    "text": "corridors and walls that look very very",
    "start": "210280",
    "end": "213120"
  },
  {
    "text": "different from this random distribution",
    "start": "213120",
    "end": "214680"
  },
  {
    "text": "that I've been training on ideally would",
    "start": "214680",
    "end": "216560"
  },
  {
    "text": "we like to be able to simulate and train",
    "start": "216560",
    "end": "218400"
  },
  {
    "text": "in simulation on all possible layouts",
    "start": "218400",
    "end": "221879"
  },
  {
    "text": "because we don't know exactly what we'll",
    "start": "221879",
    "end": "223360"
  },
  {
    "text": "be facing at test time after training is",
    "start": "223360",
    "end": "225239"
  },
  {
    "text": "done and we like to develop methods now",
    "start": "225239",
    "end": "227360"
  },
  {
    "text": "that are robust to whatever can be",
    "start": "227360",
    "end": "229560"
  },
  {
    "text": "happening at uh at in the real world so",
    "start": "229560",
    "end": "232720"
  },
  {
    "text": "here's train and here's test for example",
    "start": "232720",
    "end": "235280"
  },
  {
    "text": "but to be clear this could be any number",
    "start": "235280",
    "end": "237760"
  },
  {
    "text": "of different environments that Within I",
    "start": "237760",
    "end": "239879"
  },
  {
    "text": "could be encountering in the real world",
    "start": "239879",
    "end": "242120"
  },
  {
    "text": "and the crucial question then is what",
    "start": "242120",
    "end": "244560"
  },
  {
    "text": "distribution should I be training on to",
    "start": "244560",
    "end": "247040"
  },
  {
    "text": "minimize my regret at test time now what",
    "start": "247040",
    "end": "251360"
  },
  {
    "text": "is what is Regret regret is nothing but",
    "start": "251360",
    "end": "253519"
  },
  {
    "text": "the difference between the performance",
    "start": "253519",
    "end": "254920"
  },
  {
    "text": "of my agent on an environment and the",
    "start": "254920",
    "end": "257759"
  },
  {
    "text": "Optimal Performance of uh an agent that",
    "start": "257759",
    "end": "261000"
  },
  {
    "text": "is acting in that environment so we have",
    "start": "261000",
    "end": "263800"
  },
  {
    "text": "the regret for some environment let's",
    "start": "263800",
    "end": "265479"
  },
  {
    "text": "call the environment e then I have the",
    "start": "265479",
    "end": "267440"
  },
  {
    "text": "regret of E is nothing but the",
    "start": "267440",
    "end": "271680"
  },
  {
    "text": "performance J Pi",
    "start": "271680",
    "end": "273840"
  },
  {
    "text": "star on E minus my Agent J Pi on E so Pi",
    "start": "273840",
    "end": "279840"
  },
  {
    "text": "here is the policy of the agent that I'm",
    "start": "279840",
    "end": "281120"
  },
  {
    "text": "training e is the environment I'm",
    "start": "281120",
    "end": "283080"
  },
  {
    "text": "comparing the performance of an optimal",
    "start": "283080",
    "end": "285720"
  },
  {
    "text": "policy on the environment e with my",
    "start": "285720",
    "end": "287199"
  },
  {
    "text": "agent on the environment e so Pi I'm",
    "start": "287199",
    "end": "289080"
  },
  {
    "text": "using as notation for is the policy and",
    "start": "289080",
    "end": "291520"
  },
  {
    "text": "the policy in reinforcement learning is",
    "start": "291520",
    "end": "293039"
  },
  {
    "text": "an object that takes in observations or",
    "start": "293039",
    "end": "296400"
  },
  {
    "text": "trajectory style and produces a distrib",
    "start": "296400",
    "end": "299960"
  },
  {
    "text": "over actions given that trajectory so in",
    "start": "299960",
    "end": "302639"
  },
  {
    "text": "other words the policy is the",
    "start": "302639",
    "end": "305320"
  },
  {
    "text": "instruction set for how to act in the",
    "start": "305320",
    "end": "307560"
  },
  {
    "text": "world okay optimal policy means I have",
    "start": "307560",
    "end": "310560"
  },
  {
    "text": "the one policy the pie star that gives",
    "start": "310560",
    "end": "312520"
  },
  {
    "text": "me the highest expected reward um that",
    "start": "312520",
    "end": "315120"
  },
  {
    "text": "can be obtained in the given task if",
    "start": "315120",
    "end": "317320"
  },
  {
    "text": "reward sounds we is quite simple think",
    "start": "317320",
    "end": "319280"
  },
  {
    "text": "of whatever you want in life anything",
    "start": "319280",
    "end": "321120"
  },
  {
    "text": "that is good that's the reward so for",
    "start": "321120",
    "end": "324000"
  },
  {
    "text": "example if you have a cleaning robot the",
    "start": "324000",
    "end": "326680"
  },
  {
    "text": "reward might be um that the floor is",
    "start": "326680",
    "end": "328919"
  },
  {
    "text": "clean",
    "start": "328919",
    "end": "330440"
  },
  {
    "text": "or you might want to specify the reward",
    "start": "330440",
    "end": "332000"
  },
  {
    "text": "to be something like the amount of dirt",
    "start": "332000",
    "end": "333560"
  },
  {
    "text": "collected by the cleaning robot be",
    "start": "333560",
    "end": "335160"
  },
  {
    "text": "careful because the cleaning robot might",
    "start": "335160",
    "end": "336720"
  },
  {
    "text": "go and tip over vases to produce more",
    "start": "336720",
    "end": "339479"
  },
  {
    "text": "dirt that it can collect so even in the",
    "start": "339479",
    "end": "341360"
  },
  {
    "text": "reward specification we have to be",
    "start": "341360",
    "end": "342560"
  },
  {
    "text": "careful but in this case we're going to",
    "start": "342560",
    "end": "344600"
  },
  {
    "text": "assume that we have a reward function",
    "start": "344600",
    "end": "346240"
  },
  {
    "text": "that there is an environment that we",
    "start": "346240",
    "end": "348000"
  },
  {
    "text": "have uh a distribution over this",
    "start": "348000",
    "end": "349840"
  },
  {
    "text": "environment and that we can simulate",
    "start": "349840",
    "end": "351479"
  },
  {
    "text": "this environment on the computer and the",
    "start": "351479",
    "end": "353479"
  },
  {
    "text": "question now is if I don't know exactly",
    "start": "353479",
    "end": "355280"
  },
  {
    "text": "what the real world is but I have a",
    "start": "355280",
    "end": "356800"
  },
  {
    "text": "distribution over possible scenarios",
    "start": "356800",
    "end": "358919"
  },
  {
    "text": "like these different different grid",
    "start": "358919",
    "end": "360039"
  },
  {
    "text": "worlds I could be facing what is the",
    "start": "360039",
    "end": "362440"
  },
  {
    "text": "distribution I should be training on and",
    "start": "362440",
    "end": "364400"
  },
  {
    "text": "why is Regret useful because regret",
    "start": "364400",
    "end": "365919"
  },
  {
    "text": "tells me that there's something that I",
    "start": "365919",
    "end": "368160"
  },
  {
    "text": "can be learning and that I haven't yet",
    "start": "368160",
    "end": "370360"
  },
  {
    "text": "achieved on these environments so if I",
    "start": "370360",
    "end": "372800"
  },
  {
    "text": "have a high regret that means there's a",
    "start": "372800",
    "end": "374120"
  },
  {
    "text": "large Delta between how my agent is",
    "start": "374120",
    "end": "376039"
  },
  {
    "text": "performing and what is in principle",
    "start": "376039",
    "end": "377599"
  },
  {
    "text": "possible what we've done is we've said",
    "start": "377599",
    "end": "380919"
  },
  {
    "text": "let's go from these simple grip worlds I",
    "start": "380919",
    "end": "382479"
  },
  {
    "text": "mentioned which people have studied",
    "start": "382479",
    "end": "383599"
  },
  {
    "text": "before where we have a single agent and",
    "start": "383599",
    "end": "385960"
  },
  {
    "text": "we have some",
    "start": "385960",
    "end": "388240"
  },
  {
    "text": "obstacles let's go to a and this is a",
    "start": "388240",
    "end": "391080"
  },
  {
    "text": "discrete space where there's only a",
    "start": "391080",
    "end": "393199"
  },
  {
    "text": "finite number of places that the agent",
    "start": "393199",
    "end": "394639"
  },
  {
    "text": "can be on and the movement is in",
    "start": "394639",
    "end": "397160"
  },
  {
    "text": "something like hours and directions",
    "start": "397160",
    "end": "399400"
  },
  {
    "text": "let's go to something that is one step",
    "start": "399400",
    "end": "401039"
  },
  {
    "text": "closer to the real world right because",
    "start": "401039",
    "end": "403319"
  },
  {
    "text": "in the real world you can imagine that",
    "start": "403319",
    "end": "404479"
  },
  {
    "text": "you have a 3D environment you have 3D",
    "start": "404479",
    "end": "407639"
  },
  {
    "text": "you have 2D and discrete and in the real",
    "start": "407639",
    "end": "410360"
  },
  {
    "text": "world you have a 3D environment and you",
    "start": "410360",
    "end": "412400"
  },
  {
    "text": "have continuous actions and continous",
    "start": "412400",
    "end": "413800"
  },
  {
    "text": "state space and you have a robot that",
    "start": "413800",
    "end": "415599"
  },
  {
    "text": "can move around that has liar readings",
    "start": "415599",
    "end": "417720"
  },
  {
    "text": "like such and that can navigate in this",
    "start": "417720",
    "end": "419599"
  },
  {
    "text": "complicated maze let's take a step",
    "start": "419599",
    "end": "422000"
  },
  {
    "text": "towards this that is still tracable on",
    "start": "422000",
    "end": "423560"
  },
  {
    "text": "the computer and that is by saying we're",
    "start": "423560",
    "end": "425520"
  },
  {
    "text": "going to have a 2d environment that has",
    "start": "425520",
    "end": "427599"
  },
  {
    "text": "robots with laa that we simulate it's a",
    "start": "427599",
    "end": "430639"
  },
  {
    "text": "continuous navigation task now and we're",
    "start": "430639",
    "end": "432720"
  },
  {
    "text": "going to have multiple of these robots",
    "start": "432720",
    "end": "434000"
  },
  {
    "text": "and these robots each need to go to",
    "start": "434000",
    "end": "435360"
  },
  {
    "text": "their own goal navigating around",
    "start": "435360",
    "end": "436960"
  },
  {
    "text": "obstacles and avoiding each other we",
    "start": "436960",
    "end": "438800"
  },
  {
    "text": "spent about 6 months trying to make the",
    "start": "438800",
    "end": "441039"
  },
  {
    "text": "default methods from literature people",
    "start": "441039",
    "end": "442440"
  },
  {
    "text": "have developed to approximate the regret",
    "start": "442440",
    "end": "444319"
  },
  {
    "text": "that I just",
    "start": "444319",
    "end": "446240"
  },
  {
    "text": "mentioned um to actually try and make",
    "start": "446240",
    "end": "448599"
  },
  {
    "text": "this work on on this new environment",
    "start": "448599",
    "end": "450280"
  },
  {
    "text": "distribution which is one step towards",
    "start": "450280",
    "end": "451879"
  },
  {
    "text": "real world",
    "start": "451879",
    "end": "453080"
  },
  {
    "text": "tasks it turned out that going one step",
    "start": "453080",
    "end": "455879"
  },
  {
    "text": "out of distribution from the areas for",
    "start": "455879",
    "end": "457720"
  },
  {
    "text": "previous research had been carried out",
    "start": "457720",
    "end": "459639"
  },
  {
    "text": "was enough to basically break the",
    "start": "459639",
    "end": "462599"
  },
  {
    "text": "standard methods that people had been",
    "start": "462599",
    "end": "464520"
  },
  {
    "text": "using on those simple",
    "start": "464520",
    "end": "466800"
  },
  {
    "text": "environments and all of these methods",
    "start": "466800",
    "end": "468599"
  },
  {
    "text": "had in common that they took inspiration",
    "start": "468599",
    "end": "470159"
  },
  {
    "text": "from trying to approximate the regret",
    "start": "470159",
    "end": "471960"
  },
  {
    "text": "which seems like a useful and relevant",
    "start": "471960",
    "end": "474280"
  },
  {
    "text": "property to optimize for why again",
    "start": "474280",
    "end": "477039"
  },
  {
    "text": "because I get bound on how badly I can",
    "start": "477039",
    "end": "479000"
  },
  {
    "text": "be suboptimal at test time and I'm",
    "start": "479000",
    "end": "481599"
  },
  {
    "text": "guaranteed to always have levels where",
    "start": "481599",
    "end": "482800"
  },
  {
    "text": "in principle I can learn",
    "start": "482800",
    "end": "485199"
  },
  {
    "text": "something so after about six months of",
    "start": "485199",
    "end": "488400"
  },
  {
    "text": "trying to make these things work in this",
    "start": "488400",
    "end": "489840"
  },
  {
    "text": "environment we went back to the drawing",
    "start": "489840",
    "end": "491720"
  },
  {
    "text": "board and we thought about maybe these",
    "start": "491720",
    "end": "494360"
  },
  {
    "text": "regret approximations aren't very very",
    "start": "494360",
    "end": "495960"
  },
  {
    "text": "good how can I how can we get an",
    "start": "495960",
    "end": "498599"
  },
  {
    "text": "intuition from first principles about",
    "start": "498599",
    "end": "500639"
  },
  {
    "text": "how good these regret intuitions are um",
    "start": "500639",
    "end": "502960"
  },
  {
    "text": "we started simply plot something that to",
    "start": "502960",
    "end": "505039"
  },
  {
    "text": "us felt like an intuitive notion of",
    "start": "505039",
    "end": "507800"
  },
  {
    "text": "learnability as a function",
    "start": "507800",
    "end": "510080"
  },
  {
    "text": "of the regret approximations that we",
    "start": "510080",
    "end": "512200"
  },
  {
    "text": "running based on literature so on the",
    "start": "512200",
    "end": "514279"
  },
  {
    "text": "x-axis we put the approximate regret or",
    "start": "514279",
    "end": "516120"
  },
  {
    "text": "the estimated regret and on the y axis",
    "start": "516120",
    "end": "518959"
  },
  {
    "text": "we put learnability now you might be",
    "start": "518959",
    "end": "520959"
  },
  {
    "text": "wondering what exactly is learnability",
    "start": "520959",
    "end": "523080"
  },
  {
    "text": "and what we are hoping I'll explain this",
    "start": "523080",
    "end": "524240"
  },
  {
    "text": "in a second what we're hoping to see is",
    "start": "524240",
    "end": "526080"
  },
  {
    "text": "that these estimates of the regret are a",
    "start": "526080",
    "end": "529240"
  },
  {
    "text": "nice proxy for the learnability right",
    "start": "529240",
    "end": "531839"
  },
  {
    "text": "because what does this mean I means I",
    "start": "531839",
    "end": "533279"
  },
  {
    "text": "can sample for the estimated regret and",
    "start": "533279",
    "end": "535320"
  },
  {
    "text": "I'll get levels of high learnability",
    "start": "535320",
    "end": "537560"
  },
  {
    "text": "which specifically means in these",
    "start": "537560",
    "end": "538640"
  },
  {
    "text": "settings I want to have tasks that are",
    "start": "538640",
    "end": "541160"
  },
  {
    "text": "difficult but not too difficult where",
    "start": "541160",
    "end": "542839"
  },
  {
    "text": "learning is possible for the agent",
    "start": "542839",
    "end": "544320"
  },
  {
    "text": "through trial and error now what might",
    "start": "544320",
    "end": "546240"
  },
  {
    "text": "be a good proxy for learnability we",
    "start": "546240",
    "end": "548480"
  },
  {
    "text": "decided is simply to look at levels",
    "start": "548480",
    "end": "551120"
  },
  {
    "text": "where the agent sometimes",
    "start": "551120",
    "end": "553440"
  },
  {
    "text": "succeeds but not always it's interesting",
    "start": "553440",
    "end": "556519"
  },
  {
    "text": "that that it feels like it's a negative",
    "start": "556519",
    "end": "558680"
  },
  {
    "text": "connotation kind of having a regret",
    "start": "558680",
    "end": "560320"
  },
  {
    "text": "function rather than a kind of I don't",
    "start": "560320",
    "end": "561760"
  },
  {
    "text": "know success function or you know",
    "start": "561760",
    "end": "563959"
  },
  {
    "text": "happiness function and you see this kind",
    "start": "563959",
    "end": "565839"
  },
  {
    "text": "of throughout the fields there's",
    "start": "565839",
    "end": "568279"
  },
  {
    "text": "optimization um where people like to",
    "start": "568279",
    "end": "570680"
  },
  {
    "text": "minimize losses and there's",
    "start": "570680",
    "end": "572640"
  },
  {
    "text": "reinforcement learning where people like",
    "start": "572640",
    "end": "574560"
  },
  {
    "text": "to maximize expected returns right so",
    "start": "574560",
    "end": "577399"
  },
  {
    "text": "you actually can see that and obviously",
    "start": "577399",
    "end": "579120"
  },
  {
    "text": "that it's it's it's exactly the same",
    "start": "579120",
    "end": "581800"
  },
  {
    "text": "it's terminology absolutely purely",
    "start": "581800",
    "end": "584720"
  },
  {
    "text": "terminology um but funnily enough we've",
    "start": "584720",
    "end": "587600"
  },
  {
    "text": "caught our paper then then no regrets",
    "start": "587600",
    "end": "589920"
  },
  {
    "text": "but I I I digress I regret um so let's",
    "start": "589920",
    "end": "593560"
  },
  {
    "text": "go back to this so what we hoped is",
    "start": "593560",
    "end": "595480"
  },
  {
    "text": "let's build on everything that people",
    "start": "595480",
    "end": "596839"
  },
  {
    "text": "have done and bring this to a",
    "start": "596839",
    "end": "598240"
  },
  {
    "text": "multi-agent setting of multiple robots",
    "start": "598240",
    "end": "600440"
  },
  {
    "text": "that is one step closer to the real",
    "start": "600440",
    "end": "602839"
  },
  {
    "text": "world of these like interacting",
    "start": "602839",
    "end": "604760"
  },
  {
    "text": "different robots that have these liar",
    "start": "604760",
    "end": "607279"
  },
  {
    "text": "and that need to actually operate in 3D",
    "start": "607279",
    "end": "608880"
  },
  {
    "text": "and there's boxes around and obstacles",
    "start": "608880",
    "end": "610600"
  },
  {
    "text": "and whatnot and an Amazon warehouse or",
    "start": "610600",
    "end": "612240"
  },
  {
    "text": "whatever in Amazon warehouse we have",
    "start": "612240",
    "end": "613720"
  },
  {
    "text": "these independent robots and cruly it's",
    "start": "613720",
    "end": "615560"
  },
  {
    "text": "too complicated so you can't do exact",
    "start": "615560",
    "end": "617560"
  },
  {
    "text": "planning all of the classical path path",
    "start": "617560",
    "end": "619720"
  },
  {
    "text": "planning algorithms are going to fail in",
    "start": "619720",
    "end": "621240"
  },
  {
    "text": "these occluded uh multi-agent",
    "start": "621240",
    "end": "623800"
  },
  {
    "text": "environments but maybe we can use the",
    "start": "623800",
    "end": "625839"
  },
  {
    "text": "magic of reinforcement learning to deal",
    "start": "625839",
    "end": "628040"
  },
  {
    "text": "with these uh envir environments",
    "start": "628040",
    "end": "630560"
  },
  {
    "text": "instead and what we said is we're we're",
    "start": "630560",
    "end": "634000"
  },
  {
    "text": "trying to evaluate because nothing",
    "start": "634000",
    "end": "635279"
  },
  {
    "text": "worked we try to evaluate the quality of",
    "start": "635279",
    "end": "637200"
  },
  {
    "text": "our regret approximation algorithms so",
    "start": "637200",
    "end": "640279"
  },
  {
    "text": "what we did is we plotted on the x-axis",
    "start": "640279",
    "end": "642399"
  },
  {
    "text": "the estimated regret and on the y- AIS",
    "start": "642399",
    "end": "645279"
  },
  {
    "text": "our intuitive notion of learnability so",
    "start": "645279",
    "end": "647279"
  },
  {
    "text": "what does that mean it's where the agent",
    "start": "647279",
    "end": "648959"
  },
  {
    "text": "succeeds sometimes because there needs",
    "start": "648959",
    "end": "651279"
  },
  {
    "text": "to be a signal to learn but not always",
    "start": "651279",
    "end": "653480"
  },
  {
    "text": "because if you're always succeeding",
    "start": "653480",
    "end": "654519"
  },
  {
    "text": "you're already perfect which means",
    "start": "654519",
    "end": "655519"
  },
  {
    "text": "there's nothing to learn how can we",
    "start": "655519",
    "end": "657240"
  },
  {
    "text": "formulate this well we set the simple",
    "start": "657240",
    "end": "658839"
  },
  {
    "text": "proxy for this is p * 1 minus P where p",
    "start": "658839",
    "end": "663680"
  },
  {
    "text": "is the probability of success in a given",
    "start": "663680",
    "end": "666959"
  },
  {
    "text": "level and that's what we called L of e",
    "start": "666959",
    "end": "669800"
  },
  {
    "text": "the learnability of",
    "start": "669800",
    "end": "671519"
  },
  {
    "text": "e and Our Hope was that the learnability",
    "start": "671519",
    "end": "674399"
  },
  {
    "text": "would correlate strongly with the",
    "start": "674399",
    "end": "676800"
  },
  {
    "text": "estimated regret from these algorithms",
    "start": "676800",
    "end": "678720"
  },
  {
    "text": "because then we could optimize for high",
    "start": "678720",
    "end": "682760"
  },
  {
    "text": "regret environment and we would end up",
    "start": "682760",
    "end": "685680"
  },
  {
    "text": "having high high learnability",
    "start": "685680",
    "end": "687160"
  },
  {
    "text": "environment that was the hope what we",
    "start": "687160",
    "end": "689320"
  },
  {
    "text": "found instead is that there was either",
    "start": "689320",
    "end": "691079"
  },
  {
    "text": "no correlation at all or there may even",
    "start": "691079",
    "end": "693560"
  },
  {
    "text": "have been a negative",
    "start": "693560",
    "end": "694880"
  },
  {
    "text": "correlation but most commonly actually",
    "start": "694880",
    "end": "696720"
  },
  {
    "text": "it was there was if you know if there",
    "start": "696720",
    "end": "697880"
  },
  {
    "text": "was a negative correlation consistent we",
    "start": "697880",
    "end": "699120"
  },
  {
    "text": "could just do the opposite of what we're",
    "start": "699120",
    "end": "700240"
  },
  {
    "text": "supposed to be doing that would still",
    "start": "700240",
    "end": "701560"
  },
  {
    "text": "work but really there wasn't a signal it",
    "start": "701560",
    "end": "703279"
  },
  {
    "text": "was a hot mess okay in reality these",
    "start": "703279",
    "end": "705800"
  },
  {
    "text": "regret approximations did not capture an",
    "start": "705800",
    "end": "708240"
  },
  {
    "text": "intuitive notion of of learnability at",
    "start": "708240",
    "end": "710399"
  },
  {
    "text": "that point we're about uh 10 days from",
    "start": "710399",
    "end": "713079"
  },
  {
    "text": "the conference",
    "start": "713079",
    "end": "714760"
  },
  {
    "text": "deadline and any sensible",
    "start": "714760",
    "end": "719600"
  },
  {
    "text": "research at that point would have said",
    "start": "719600",
    "end": "720959"
  },
  {
    "text": "well congratulations there's the methods",
    "start": "720959",
    "end": "723480"
  },
  {
    "text": "don't work there's nothing we can do but",
    "start": "723480",
    "end": "725839"
  },
  {
    "text": "instead what we said is why don't we go",
    "start": "725839",
    "end": "727880"
  },
  {
    "text": "and just optimize for learnability",
    "start": "727880",
    "end": "731040"
  },
  {
    "text": "rather than optimizing for regret",
    "start": "731040",
    "end": "732839"
  },
  {
    "text": "because if we have an intuitive metric",
    "start": "732839",
    "end": "734519"
  },
  {
    "text": "that should capture what is a useful",
    "start": "734519",
    "end": "736399"
  },
  {
    "text": "level to learn on where you sometimes",
    "start": "736399",
    "end": "737639"
  },
  {
    "text": "succeed and not always and you can",
    "start": "737639",
    "end": "739320"
  },
  {
    "text": "measure this metric easily we can just",
    "start": "739320",
    "end": "741480"
  },
  {
    "text": "replace the measure of success of the",
    "start": "741480",
    "end": "744240"
  },
  {
    "text": "environment generation policy so this",
    "start": "744240",
    "end": "746320"
  },
  {
    "text": "thing that says what policy what",
    "start": "746320",
    "end": "747839"
  },
  {
    "text": "environment to train on with our",
    "start": "747839",
    "end": "749440"
  },
  {
    "text": "learnability metric and within a day we",
    "start": "749440",
    "end": "753240"
  },
  {
    "text": "had methods that were generalizing",
    "start": "753240",
    "end": "756240"
  },
  {
    "text": "better to hold out environments to",
    "start": "756240",
    "end": "758120"
  },
  {
    "text": "challenging hold our tasks within that",
    "start": "758120",
    "end": "759959"
  },
  {
    "text": "distribution than anything we've seen",
    "start": "759959",
    "end": "761560"
  },
  {
    "text": "before what does this mean it means that",
    "start": "761560",
    "end": "763279"
  },
  {
    "text": "as we're doing research in machine",
    "start": "763279",
    "end": "764399"
  },
  {
    "text": "learning it's important to once in a",
    "start": "764399",
    "end": "766720"
  },
  {
    "text": "while realize that a our methods",
    "start": "766720",
    "end": "770399"
  },
  {
    "text": "struggle to generalize out of",
    "start": "770399",
    "end": "772800"
  },
  {
    "text": "distribution but that also be the",
    "start": "772800",
    "end": "775839"
  },
  {
    "text": "research Paradigm itself sometimes has",
    "start": "775839",
    "end": "779240"
  },
  {
    "text": "been overfitted to a specific",
    "start": "779240",
    "end": "780920"
  },
  {
    "text": "distribution of tasks that people like",
    "start": "780920",
    "end": "782240"
  },
  {
    "text": "to develop their methods for and the",
    "start": "782240",
    "end": "784720"
  },
  {
    "text": "moment that you take a step outside that",
    "start": "784720",
    "end": "786519"
  },
  {
    "text": "distribution it is entirely possible",
    "start": "786519",
    "end": "789120"
  },
  {
    "text": "that everything that has been done",
    "start": "789120",
    "end": "790199"
  },
  {
    "text": "before previously will break down and",
    "start": "790199",
    "end": "793120"
  },
  {
    "text": "it's therefore important to go back to",
    "start": "793120",
    "end": "794399"
  },
  {
    "text": "the to the drawing board and think from",
    "start": "794399",
    "end": "796440"
  },
  {
    "text": "first principles what do I expect to",
    "start": "796440",
    "end": "798600"
  },
  {
    "text": "work and why can i s to check that the",
    "start": "798600",
    "end": "800839"
  },
  {
    "text": "assumptions that people have made in the",
    "start": "800839",
    "end": "802000"
  },
  {
    "text": "past are actually reasonable for example",
    "start": "802000",
    "end": "804920"
  },
  {
    "text": "the assumption that these",
    "start": "804920",
    "end": "807000"
  },
  {
    "text": "methods measure an approximate regret in",
    "start": "807000",
    "end": "809560"
  },
  {
    "text": "these",
    "start": "809560",
    "end": "811240"
  },
  {
    "text": "environments so for us that was uh an",
    "start": "811240",
    "end": "814000"
  },
  {
    "text": "important lesson sometimes as a",
    "start": "814000",
    "end": "815959"
  },
  {
    "text": "researcher you're the agent and you have",
    "start": "815959",
    "end": "817519"
  },
  {
    "text": "to generalize to new Helder",
    "start": "817519",
    "end": "819639"
  },
  {
    "text": "tasks and to make sure that all of this",
    "start": "819639",
    "end": "822720"
  },
  {
    "text": "is as easy and POS and and and and we",
    "start": "822720",
    "end": "825560"
  },
  {
    "text": "also realize that there's a root cause",
    "start": "825560",
    "end": "827920"
  },
  {
    "text": "why researchers stick to these uh simple",
    "start": "827920",
    "end": "831120"
  },
  {
    "text": "toy",
    "start": "831120",
    "end": "832440"
  },
  {
    "text": "environments and that's because it's",
    "start": "832440",
    "end": "834800"
  },
  {
    "text": "actually quite challenging to implement",
    "start": "834800",
    "end": "836360"
  },
  {
    "text": "new environments right there's a reason",
    "start": "836360",
    "end": "839120"
  },
  {
    "text": "everyone does the same work on that on",
    "start": "839120",
    "end": "841079"
  },
  {
    "text": "that on those on those few reinforcement",
    "start": "841079",
    "end": "843040"
  },
  {
    "text": "learning tasks where they then overfit",
    "start": "843040",
    "end": "844759"
  },
  {
    "text": "with their methods and that's because",
    "start": "844759",
    "end": "846880"
  },
  {
    "text": "it's computationally expensive to run",
    "start": "846880",
    "end": "848920"
  },
  {
    "text": "experiments and it's difficult to",
    "start": "848920",
    "end": "851360"
  },
  {
    "text": "implement new environments our lab has",
    "start": "851360",
    "end": "854160"
  },
  {
    "text": "also tried to attack both of these",
    "start": "854160",
    "end": "855920"
  },
  {
    "text": "branches so one of them is the cost of",
    "start": "855920",
    "end": "859320"
  },
  {
    "text": "running experiments in reinforcement",
    "start": "859320",
    "end": "861759"
  },
  {
    "text": "learning and then the lack of diverse",
    "start": "861759",
    "end": "864839"
  },
  {
    "text": "tasks right",
    "start": "864839",
    "end": "867160"
  },
  {
    "text": "clearly if we think about great World a",
    "start": "867160",
    "end": "870600"
  },
  {
    "text": "grit world does not represent the",
    "start": "870600",
    "end": "872800"
  },
  {
    "text": "entirety of possible scenarios of any",
    "start": "872800",
    "end": "875959"
  },
  {
    "text": "sort that we could be facing in the real",
    "start": "875959",
    "end": "878320"
  },
  {
    "text": "world in particular even this outo",
    "start": "878320",
    "end": "880759"
  },
  {
    "text": "distribution example that I gave you",
    "start": "880759",
    "end": "883320"
  },
  {
    "text": "still looks a lot like a great world yes",
    "start": "883320",
    "end": "885800"
  },
  {
    "text": "it has a bit more",
    "start": "885800",
    "end": "887199"
  },
  {
    "text": "structure but",
    "start": "887199",
    "end": "889040"
  },
  {
    "text": "fundamentally this looks a lot like a",
    "start": "889040",
    "end": "890920"
  },
  {
    "text": "great world right and there's only so",
    "start": "890920",
    "end": "893320"
  },
  {
    "text": "much that can go wrong within the space",
    "start": "893320",
    "end": "895360"
  },
  {
    "text": "of great worlds so what have we done",
    "start": "895360",
    "end": "897480"
  },
  {
    "text": "we've G for a start we have an entire",
    "start": "897480",
    "end": "900800"
  },
  {
    "text": "line of work now that I call RL at the",
    "start": "900800",
    "end": "906199"
  },
  {
    "text": "hyperscale the hypers scale and what",
    "start": "906199",
    "end": "909199"
  },
  {
    "text": "this says is that in the last 16 years",
    "start": "909199",
    "end": "913240"
  },
  {
    "text": "we had two big revolutions we had the",
    "start": "913240",
    "end": "914800"
  },
  {
    "text": "Deep learning this revolution in",
    "start": "914800",
    "end": "918000"
  },
  {
    "text": "2012 and we had the dqn Deep",
    "start": "918000",
    "end": "920800"
  },
  {
    "text": "reinforcement learning deep revolution",
    "start": "920800",
    "end": "923199"
  },
  {
    "text": "in 2013 now if we look back this has",
    "start": "923199",
    "end": "927240"
  },
  {
    "text": "resulted",
    "start": "927240",
    "end": "929079"
  },
  {
    "text": "in",
    "start": "929079",
    "end": "931279"
  },
  {
    "text": "gen and is currently on path for",
    "start": "931279",
    "end": "933800"
  },
  {
    "text": "revolutionizing the world and the Deep",
    "start": "933800",
    "end": "935880"
  },
  {
    "text": "reinforcement revolution has generated",
    "start": "935880",
    "end": "938639"
  },
  {
    "text": "40,000 papers and there's a valid",
    "start": "938639",
    "end": "941199"
  },
  {
    "text": "question here which is why is it that",
    "start": "941199",
    "end": "945000"
  },
  {
    "text": "deep learning has been so much more",
    "start": "945000",
    "end": "946279"
  },
  {
    "text": "successful than deep reinforcement",
    "start": "946279",
    "end": "948000"
  },
  {
    "text": "learning and one answer is that deep",
    "start": "948000",
    "end": "950360"
  },
  {
    "text": "reinforcement learning lost what is",
    "start": "950360",
    "end": "952079"
  },
  {
    "text": "called the hardware Lottery right",
    "start": "952079",
    "end": "954079"
  },
  {
    "text": "because the underlying sort of magic to",
    "start": "954079",
    "end": "957279"
  },
  {
    "text": "success of deep learning",
    "start": "957279",
    "end": "959680"
  },
  {
    "text": "was that we can run deep learning",
    "start": "959680",
    "end": "961240"
  },
  {
    "text": "efficiently on the",
    "start": "961240",
    "end": "963680"
  },
  {
    "text": "GPU deep learning is",
    "start": "963680",
    "end": "968720"
  },
  {
    "text": "perfect for the",
    "start": "968720",
    "end": "972079"
  },
  {
    "text": "GPU okay this is something that is",
    "start": "972800",
    "end": "975279"
  },
  {
    "text": "important to appreciate um before people",
    "start": "975279",
    "end": "977360"
  },
  {
    "text": "started running uh deep learning on the",
    "start": "977360",
    "end": "979560"
  },
  {
    "text": "GPU before",
    "start": "979560",
    "end": "982120"
  },
  {
    "text": "alexnet the first efforts were using",
    "start": "982120",
    "end": "986440"
  },
  {
    "text": "tens of thousands of CPUs at Google",
    "start": "986440",
    "end": "988519"
  },
  {
    "text": "brain",
    "start": "988519",
    "end": "989839"
  },
  {
    "text": "and they were producing new networks",
    "start": "989839",
    "end": "992680"
  },
  {
    "text": "that by modern standards were terrible",
    "start": "992680",
    "end": "994360"
  },
  {
    "text": "in their performance only when people",
    "start": "994360",
    "end": "996560"
  },
  {
    "text": "started running these things on GPU",
    "start": "996560",
    "end": "998399"
  },
  {
    "text": "which happen to be well suited for this",
    "start": "998399",
    "end": "1000040"
  },
  {
    "text": "kind of logical operation which is",
    "start": "1000040",
    "end": "1002199"
  },
  {
    "text": "Matrix Vector operations which happen to",
    "start": "1002199",
    "end": "1004800"
  },
  {
    "text": "be very very similar to what happens in",
    "start": "1004800",
    "end": "1006279"
  },
  {
    "text": "video games for graphic computation only",
    "start": "1006279",
    "end": "1008920"
  },
  {
    "text": "then did deep learning become this",
    "start": "1008920",
    "end": "1011440"
  },
  {
    "text": "magical success story of supervised",
    "start": "1011440",
    "end": "1014040"
  },
  {
    "text": "learning the issue is that for",
    "start": "1014040",
    "end": "1015759"
  },
  {
    "text": "reinforcement learning we're",
    "start": "1015759",
    "end": "1017440"
  },
  {
    "text": "fundamentally faced",
    "start": "1017440",
    "end": "1019600"
  },
  {
    "text": "with a different Paradigm because what",
    "start": "1019600",
    "end": "1021319"
  },
  {
    "text": "normally happens is that we have an",
    "start": "1021319",
    "end": "1023520"
  },
  {
    "text": "environment for example the great world",
    "start": "1023520",
    "end": "1026640"
  },
  {
    "text": "which runs on the",
    "start": "1026640",
    "end": "1029600"
  },
  {
    "text": "CPU and then we have the pocy piie and",
    "start": "1029600",
    "end": "1033079"
  },
  {
    "text": "the agent training loop everything else",
    "start": "1033079",
    "end": "1036160"
  },
  {
    "text": "running on the GPU the Deep neural",
    "start": "1036160",
    "end": "1038319"
  },
  {
    "text": "networks that present our policies P the",
    "start": "1038319",
    "end": "1041280"
  },
  {
    "text": "agent and what this means is we need to",
    "start": "1041280",
    "end": "1043600"
  },
  {
    "text": "orchestrate information exchange so the",
    "start": "1043600",
    "end": "1046558"
  },
  {
    "text": "agent has to send actions to the",
    "start": "1046559",
    "end": "1049600"
  },
  {
    "text": "environment actions and the environment",
    "start": "1049600",
    "end": "1052120"
  },
  {
    "text": "has to send back observations and",
    "start": "1052120",
    "end": "1054679"
  },
  {
    "text": "rewards to the agent so here's our",
    "start": "1054679",
    "end": "1056400"
  },
  {
    "text": "policy pi and our learning Loop training",
    "start": "1056400",
    "end": "1058160"
  },
  {
    "text": "Loop now this fundamentally limits how",
    "start": "1058160",
    "end": "1061919"
  },
  {
    "text": "much we can scale up our RL training and",
    "start": "1061919",
    "end": "1065120"
  },
  {
    "text": "it's meant that RL has been running at",
    "start": "1065120",
    "end": "1067320"
  },
  {
    "text": "orders of magnitude slower per training",
    "start": "1067320",
    "end": "1070720"
  },
  {
    "text": "sample than supervised learning so it's",
    "start": "1070720",
    "end": "1073600"
  },
  {
    "text": "been very very difficult to keep the",
    "start": "1073600",
    "end": "1075559"
  },
  {
    "text": "gpus busy and to have efficient training",
    "start": "1075559",
    "end": "1078440"
  },
  {
    "text": "for reinforcement learning under current",
    "start": "1078440",
    "end": "1080960"
  },
  {
    "text": "CPU GPU",
    "start": "1080960",
    "end": "1082320"
  },
  {
    "text": "architectures now it's an artifact that",
    "start": "1082320",
    "end": "1085240"
  },
  {
    "text": "it turned out to be true that graphics",
    "start": "1085240",
    "end": "1087120"
  },
  {
    "text": "cards are good for deep learning maybe",
    "start": "1087120",
    "end": "1090080"
  },
  {
    "text": "if they designed graphic cards",
    "start": "1090080",
    "end": "1091280"
  },
  {
    "text": "differently for example if you had more",
    "start": "1091280",
    "end": "1093360"
  },
  {
    "text": "memory assoc if you had a pairing of",
    "start": "1093360",
    "end": "1095000"
  },
  {
    "text": "CPUs and gpus interacted differently or",
    "start": "1095000",
    "end": "1096640"
  },
  {
    "text": "that shared memory this wouldn't have",
    "start": "1096640",
    "end": "1098840"
  },
  {
    "text": "happened but it did happen and what is",
    "start": "1098840",
    "end": "1100919"
  },
  {
    "text": "meant is that in deep reinforcement",
    "start": "1100919",
    "end": "1102919"
  },
  {
    "text": "learning we've had a decade of building",
    "start": "1102919",
    "end": "1105880"
  },
  {
    "text": "complicated training paradigms comp ated",
    "start": "1105880",
    "end": "1109240"
  },
  {
    "text": "ways of trying to interleaf and thread",
    "start": "1109240",
    "end": "1111240"
  },
  {
    "text": "CPUs and gpus to try and get around",
    "start": "1111240",
    "end": "1114159"
  },
  {
    "text": "these limitations what we've done is",
    "start": "1114159",
    "end": "1115919"
  },
  {
    "text": "we've said what if we simply put the",
    "start": "1115919",
    "end": "1118400"
  },
  {
    "text": "environment also on the GPU so now if",
    "start": "1118400",
    "end": "1121440"
  },
  {
    "text": "our environment and a policy pi and our",
    "start": "1121440",
    "end": "1124240"
  },
  {
    "text": "training Loop all run on the same GPU",
    "start": "1124240",
    "end": "1127960"
  },
  {
    "text": "and what this means is there's no more",
    "start": "1127960",
    "end": "1129240"
  },
  {
    "text": "communication in CPUs and gpus what it",
    "start": "1129240",
    "end": "1131240"
  },
  {
    "text": "also means is we can scale up the",
    "start": "1131240",
    "end": "1132880"
  },
  {
    "text": "training by adding bash Dimensions um by",
    "start": "1132880",
    "end": "1135559"
  },
  {
    "text": "keeping the entire GPU busy number",
    "start": "1135559",
    "end": "1138080"
  },
  {
    "text": "crunching do doing what it can do best",
    "start": "1138080",
    "end": "1140880"
  },
  {
    "text": "and what it's meant in practice is that",
    "start": "1140880",
    "end": "1142440"
  },
  {
    "text": "we've seen between a factor of",
    "start": "1142440",
    "end": "1145880"
  },
  {
    "text": "10,000 roughly speaking from 100 to",
    "start": "1145880",
    "end": "1148600"
  },
  {
    "text": "10,000 speed UPS over previous",
    "start": "1148600",
    "end": "1151000"
  },
  {
    "text": "implementations and what this has meant",
    "start": "1151000",
    "end": "1152960"
  },
  {
    "text": "is that now it becomes feasible to test",
    "start": "1152960",
    "end": "1156039"
  },
  {
    "text": "algorithms a lot faster so there's no",
    "start": "1156039",
    "end": "1158919"
  },
  {
    "text": "more excuse to say sorry I didn't",
    "start": "1158919",
    "end": "1161679"
  },
  {
    "text": "evaluate a more environments because I",
    "start": "1161679",
    "end": "1164440"
  },
  {
    "text": "didn't have the comput resources because",
    "start": "1164440",
    "end": "1165880"
  },
  {
    "text": "nowadays if you have a couple of gpus",
    "start": "1165880",
    "end": "1167159"
  },
  {
    "text": "you can actually run these algorithms at",
    "start": "1167159",
    "end": "1168760"
  },
  {
    "text": "a lot faster and eval over many seats at",
    "start": "1168760",
    "end": "1170919"
  },
  {
    "text": "once um using GPU accelerated learning",
    "start": "1170919",
    "end": "1173640"
  },
  {
    "text": "or hour at the hyperscale and this is",
    "start": "1173640",
    "end": "1175720"
  },
  {
    "text": "all done in the framework code Jack",
    "start": "1175720",
    "end": "1177760"
  },
  {
    "text": "which allows us to write flexible",
    "start": "1177760",
    "end": "1178960"
  },
  {
    "text": "environment code for uh GPU accelerated",
    "start": "1178960",
    "end": "1182520"
  },
  {
    "text": "execution but let's go back to this",
    "start": "1182520",
    "end": "1184640"
  },
  {
    "text": "because while this has sped up the",
    "start": "1184640",
    "end": "1186320"
  },
  {
    "text": "training and removed the computational",
    "start": "1186320",
    "end": "1188559"
  },
  {
    "text": "barriers which was one hindrance for to",
    "start": "1188559",
    "end": "1190880"
  },
  {
    "text": "running multiple",
    "start": "1190880",
    "end": "1192480"
  },
  {
    "text": "environments we said there's the cost of",
    "start": "1192480",
    "end": "1195520"
  },
  {
    "text": "running experiment so we take this one",
    "start": "1195520",
    "end": "1197679"
  },
  {
    "text": "but we actually made a second issue",
    "start": "1197679",
    "end": "1199640"
  },
  {
    "text": "worse because suddenly the lack of",
    "start": "1199640",
    "end": "1202000"
  },
  {
    "text": "diverse tasks is exacerbated because",
    "start": "1202000",
    "end": "1205200"
  },
  {
    "text": "we're now limited to tasks that have",
    "start": "1205200",
    "end": "1206480"
  },
  {
    "text": "been implemented in",
    "start": "1206480",
    "end": "1208080"
  },
  {
    "text": "Jack so we've made this aspect worse so",
    "start": "1208080",
    "end": "1211559"
  },
  {
    "text": "we've also gone and done is we've",
    "start": "1211559",
    "end": "1213799"
  },
  {
    "text": "implemented a lot of environments in Jax",
    "start": "1213799",
    "end": "1218400"
  },
  {
    "text": "and in particular this is true for the",
    "start": "1218400",
    "end": "1219960"
  },
  {
    "text": "multi-root environment in Tod that I",
    "start": "1219960",
    "end": "1221760"
  },
  {
    "text": "mentioned earlier but we also thought",
    "start": "1221760",
    "end": "1224240"
  },
  {
    "text": "wouldn't it be nice if we could simply",
    "start": "1224240",
    "end": "1225880"
  },
  {
    "text": "have something that is almost like a uni",
    "start": "1225880",
    "end": "1228679"
  },
  {
    "text": "ierse of all possible",
    "start": "1228679",
    "end": "1231440"
  },
  {
    "text": "tasks let's go from the great world as",
    "start": "1231440",
    "end": "1233840"
  },
  {
    "text": "being the task distribution to something",
    "start": "1233840",
    "end": "1236440"
  },
  {
    "text": "that mirrors the diversity and",
    "start": "1236440",
    "end": "1238480"
  },
  {
    "text": "open-endedness of the world we live in",
    "start": "1238480",
    "end": "1241200"
  },
  {
    "text": "the real world now as you can imagine",
    "start": "1241200",
    "end": "1244760"
  },
  {
    "text": "implementing the exact real world is a",
    "start": "1244760",
    "end": "1248760"
  },
  {
    "text": "little bit beyond our current",
    "start": "1248760",
    "end": "1250799"
  },
  {
    "text": "capabilities as a single machine",
    "start": "1250799",
    "end": "1252880"
  },
  {
    "text": "learning lab so what we did is we did",
    "start": "1252880",
    "end": "1255440"
  },
  {
    "text": "the same thing we did before when we",
    "start": "1255440",
    "end": "1256480"
  },
  {
    "text": "said let's not go to 3D because that's",
    "start": "1256480",
    "end": "1258120"
  },
  {
    "text": "complicated it let's go into",
    "start": "1258120",
    "end": "1262360"
  },
  {
    "text": "2D and let's actually just think of a",
    "start": "1262360",
    "end": "1265159"
  },
  {
    "text": "mini Universe of 2D physics but within",
    "start": "1265159",
    "end": "1268480"
  },
  {
    "text": "that anything goes and that's something",
    "start": "1268480",
    "end": "1271480"
  },
  {
    "text": "that we recently released called",
    "start": "1271480",
    "end": "1272640"
  },
  {
    "text": "kinetics and in kinetics the magic is",
    "start": "1272640",
    "end": "1276080"
  },
  {
    "text": "that we now have an N2 n GPU accelerated",
    "start": "1276080",
    "end": "1279400"
  },
  {
    "text": "system that contains an editor for",
    "start": "1279400",
    "end": "1283640"
  },
  {
    "text": "generating",
    "start": "1283640",
    "end": "1285320"
  },
  {
    "text": "tasks through by human work it also",
    "start": "1285320",
    "end": "1288919"
  },
  {
    "text": "contains a GPU accelerated physics",
    "start": "1288919",
    "end": "1291799"
  },
  {
    "text": "engine based on box 2D physics it also",
    "start": "1291799",
    "end": "1294760"
  },
  {
    "text": "contains a UI for humans to play because",
    "start": "1294760",
    "end": "1297080"
  },
  {
    "text": "humans are fun and it contains RL",
    "start": "1297080",
    "end": "1300360"
  },
  {
    "text": "training code and curricular methods and",
    "start": "1300360",
    "end": "1303600"
  },
  {
    "text": "that same method I mentioned just now",
    "start": "1303600",
    "end": "1305120"
  },
  {
    "text": "for learnability that worked in our 2D",
    "start": "1305120",
    "end": "1307559"
  },
  {
    "text": "multi robot environments it turns out",
    "start": "1307559",
    "end": "1309840"
  },
  {
    "text": "this same method was also the one that",
    "start": "1309840",
    "end": "1311679"
  },
  {
    "text": "worked off the shelf in this much",
    "start": "1311679",
    "end": "1313760"
  },
  {
    "text": "broader much more challenging task",
    "start": "1313760",
    "end": "1315480"
  },
  {
    "text": "distribution in particular what we can",
    "start": "1315480",
    "end": "1317360"
  },
  {
    "text": "study in this new connect simulators we",
    "start": "1317360",
    "end": "1319520"
  },
  {
    "text": "can ask questions like if I train a",
    "start": "1319520",
    "end": "1322760"
  },
  {
    "text": "method on randomly simulated tasks of 2D",
    "start": "1322760",
    "end": "1327240"
  },
  {
    "text": "physics and you're correctly asking what",
    "start": "1327240",
    "end": "1329480"
  },
  {
    "text": "even is a task in two in a 2d simulator",
    "start": "1329480",
    "end": "1331919"
  },
  {
    "text": "whether it's only nutonian physics can",
    "start": "1331919",
    "end": "1334360"
  },
  {
    "text": "it generalized to hold out hand design",
    "start": "1334360",
    "end": "1336039"
  },
  {
    "text": "challenging test",
    "start": "1336039",
    "end": "1337760"
  },
  {
    "text": "cases how do we Define the task what all",
    "start": "1337760",
    "end": "1340559"
  },
  {
    "text": "these tasks have in common is that there",
    "start": "1340559",
    "end": "1342360"
  },
  {
    "text": "is a green object which is to be put in",
    "start": "1342360",
    "end": "1346320"
  },
  {
    "text": "contact with a blue object and you can",
    "start": "1346320",
    "end": "1349039"
  },
  {
    "text": "make any of the objects on the screen",
    "start": "1349039",
    "end": "1350440"
  },
  {
    "text": "you can add rectangles squares uh",
    "start": "1350440",
    "end": "1353039"
  },
  {
    "text": "whatever you want and cut it with a blue",
    "start": "1353039",
    "end": "1355880"
  },
  {
    "text": "object which is the ter episode terminat",
    "start": "1355880",
    "end": "1358360"
  },
  {
    "text": "successful while avoiding the red object",
    "start": "1358360",
    "end": "1361120"
  },
  {
    "text": "so this seems quite arbitrary but it",
    "start": "1361120",
    "end": "1363039"
  },
  {
    "text": "turns out you can Implement a large",
    "start": "1363039",
    "end": "1365480"
  },
  {
    "text": "number of very diverse looking",
    "start": "1365480",
    "end": "1367240"
  },
  {
    "text": "reinforcement learning environments",
    "start": "1367240",
    "end": "1369080"
  },
  {
    "text": "within that Paradigm so for example some",
    "start": "1369080",
    "end": "1371400"
  },
  {
    "text": "of the 2D robotics task like walking",
    "start": "1371400",
    "end": "1373320"
  },
  {
    "text": "around or Hopper you can Implement in",
    "start": "1373320",
    "end": "1375200"
  },
  {
    "text": "here you can Implement something like",
    "start": "1375200",
    "end": "1377200"
  },
  {
    "text": "that game where you have to push the",
    "start": "1377200",
    "end": "1379200"
  },
  {
    "text": "buttons on the side to make a marble",
    "start": "1379200",
    "end": "1381760"
  },
  {
    "text": "shoot up you can implement the lunar",
    "start": "1381760",
    "end": "1383080"
  },
  {
    "text": "lander which is trying to control the",
    "start": "1383080",
    "end": "1384360"
  },
  {
    "text": "little um Landing aircraft landing on",
    "start": "1384360",
    "end": "1386200"
  },
  {
    "text": "lunar surface so the diversity of tasks",
    "start": "1386200",
    "end": "1388320"
  },
  {
    "text": "that can be done can be Implement in",
    "start": "1388320",
    "end": "1390000"
  },
  {
    "text": "principle in this simple uh 2D physics",
    "start": "1390000",
    "end": "1392640"
  },
  {
    "text": "engine is is actually sort of quite",
    "start": "1392640",
    "end": "1395799"
  },
  {
    "text": "mindboggling and previously those would",
    "start": "1395799",
    "end": "1397880"
  },
  {
    "text": "have been all been different",
    "start": "1397880",
    "end": "1399480"
  },
  {
    "text": "environments which means you couldn't",
    "start": "1399480",
    "end": "1400960"
  },
  {
    "text": "power the light over them because each",
    "start": "1400960",
    "end": "1402919"
  },
  {
    "text": "of these previously would have had their",
    "start": "1402919",
    "end": "1404679"
  },
  {
    "text": "you would have to do their own tracks",
    "start": "1404679",
    "end": "1406200"
  },
  {
    "text": "implementation while now this is",
    "start": "1406200",
    "end": "1409360"
  },
  {
    "text": "all expressed within the same",
    "start": "1409360",
    "end": "1412400"
  },
  {
    "text": "parameterization that means I can now on",
    "start": "1412400",
    "end": "1414799"
  },
  {
    "text": "the same GPU paralized across these",
    "start": "1414799",
    "end": "1417200"
  },
  {
    "text": "different environments efficiently and I",
    "start": "1417200",
    "end": "1419000"
  },
  {
    "text": "can run different environments and",
    "start": "1419000",
    "end": "1420159"
  },
  {
    "text": "different threats of the",
    "start": "1420159",
    "end": "1421679"
  },
  {
    "text": "GPU because there was just one conflict",
    "start": "1421679",
    "end": "1424080"
  },
  {
    "text": "within that really really powerful",
    "start": "1424080",
    "end": "1425360"
  },
  {
    "text": "expressive",
    "start": "1425360",
    "end": "1426880"
  },
  {
    "text": "editor and what we've been been able to",
    "start": "1426880",
    "end": "1429120"
  },
  {
    "text": "do for the first time I think is to",
    "start": "1429120",
    "end": "1431919"
  },
  {
    "text": "train an agent on this very",
    "start": "1431919",
    "end": "1433520"
  },
  {
    "text": "uninformative distribution of random",
    "start": "1433520",
    "end": "1436120"
  },
  {
    "text": "samples be smart about our curriculum",
    "start": "1436120",
    "end": "1438960"
  },
  {
    "text": "method by optimizing for learnability",
    "start": "1438960",
    "end": "1441279"
  },
  {
    "text": "and then we've been able to show two so",
    "start": "1441279",
    "end": "1443279"
  },
  {
    "text": "some some random samples and you really",
    "start": "1443279",
    "end": "1445400"
  },
  {
    "text": "wouldn't think that um training on this",
    "start": "1445400",
    "end": "1447919"
  },
  {
    "text": "distribution is at all useful and I I",
    "start": "1447919",
    "end": "1450760"
  },
  {
    "text": "should say one more thing I have the",
    "start": "1450760",
    "end": "1452320"
  },
  {
    "text": "task and I also have the",
    "start": "1452320",
    "end": "1454120"
  },
  {
    "text": "controls and the controls that you can",
    "start": "1454120",
    "end": "1456200"
  },
  {
    "text": "add",
    "start": "1456200",
    "end": "1457360"
  },
  {
    "text": "thrusters and",
    "start": "1457360",
    "end": "1459200"
  },
  {
    "text": "motors to these blops so as a human you",
    "start": "1459200",
    "end": "1461799"
  },
  {
    "text": "can go in and you can play with the",
    "start": "1461799",
    "end": "1462679"
  },
  {
    "text": "keyboard and can control these these",
    "start": "1462679",
    "end": "1464919"
  },
  {
    "text": "objects and what been able to show is",
    "start": "1464919",
    "end": "1467159"
  },
  {
    "text": "two crucial things that we the at the",
    "start": "1467159",
    "end": "1469039"
  },
  {
    "text": "beginning of gen for teex based tasks",
    "start": "1469039",
    "end": "1472279"
  },
  {
    "text": "and the first thing is zero shot",
    "start": "1472279",
    "end": "1475120"
  },
  {
    "text": "Improvement and what this means is we",
    "start": "1475120",
    "end": "1477640"
  },
  {
    "text": "can now take this highly arbitrary uh",
    "start": "1477640",
    "end": "1479840"
  },
  {
    "text": "pre-train distributions apply a",
    "start": "1479840",
    "end": "1481480"
  },
  {
    "text": "curriculum to it and train the",
    "start": "1481480",
    "end": "1482640"
  },
  {
    "text": "generalist agent and this generalist",
    "start": "1482640",
    "end": "1484760"
  },
  {
    "text": "agent is going to have non-negligible",
    "start": "1484760",
    "end": "1488120"
  },
  {
    "text": "performance improvements on human",
    "start": "1488120",
    "end": "1490520"
  },
  {
    "text": "designed heldout tasks that look very",
    "start": "1490520",
    "end": "1493520"
  },
  {
    "text": "very different from our random",
    "start": "1493520",
    "end": "1495520"
  },
  {
    "text": "pre-training distribution much like you",
    "start": "1495520",
    "end": "1497960"
  },
  {
    "text": "could take make an an llm system",
    "start": "1497960",
    "end": "1501120"
  },
  {
    "text": "pre-trained on the internet full of",
    "start": "1501120",
    "end": "1503279"
  },
  {
    "text": "garbage Frankly Speaking and yet it",
    "start": "1503279",
    "end": "1505840"
  },
  {
    "text": "would be quite good at Downstream task",
    "start": "1505840",
    "end": "1509320"
  },
  {
    "text": "zero shot so zero shots where it hasn't",
    "start": "1509320",
    "end": "1512200"
  },
  {
    "text": "seen it before it gets it has seen it",
    "start": "1512200",
    "end": "1513880"
  },
  {
    "text": "before you haven't optimized it for that",
    "start": "1513880",
    "end": "1515600"
  },
  {
    "text": "task at all so zero shot means you",
    "start": "1515600",
    "end": "1517919"
  },
  {
    "text": "pre-train on one thing and you test that",
    "start": "1517919",
    "end": "1519880"
  },
  {
    "text": "same system immediately on something",
    "start": "1519880",
    "end": "1521720"
  },
  {
    "text": "else Zer performance but we all know",
    "start": "1521720",
    "end": "1524559"
  },
  {
    "text": "that this was just the",
    "start": "1524559",
    "end": "1527320"
  },
  {
    "text": "onset of",
    "start": "1527320",
    "end": "1529559"
  },
  {
    "text": "gen the thing that got people really",
    "start": "1529559",
    "end": "1531600"
  },
  {
    "text": "excited is the fact that we can",
    "start": "1531600",
    "end": "1532799"
  },
  {
    "text": "fine-tune these systems on target tasks",
    "start": "1532799",
    "end": "1535720"
  },
  {
    "text": "much more efficiently than training from",
    "start": "1535720",
    "end": "1537000"
  },
  {
    "text": "scratch this was the second ingredient",
    "start": "1537000",
    "end": "1538720"
  },
  {
    "text": "to the Gen Revolution it turned out that",
    "start": "1538720",
    "end": "1541120"
  },
  {
    "text": "when we pre-train these uh our large",
    "start": "1541120",
    "end": "1543559"
  },
  {
    "text": "language models on the internet of all",
    "start": "1543559",
    "end": "1544840"
  },
  {
    "text": "possible text we can then fine-tune them",
    "start": "1544840",
    "end": "1547520"
  },
  {
    "text": "I.E do supervised learning on the",
    "start": "1547520",
    "end": "1549039"
  },
  {
    "text": "limited data set in a Target domain that",
    "start": "1549039",
    "end": "1551200"
  },
  {
    "text": "we care about and we've now shown the",
    "start": "1551200",
    "end": "1554640"
  },
  {
    "text": "same thing within this universe where",
    "start": "1554640",
    "end": "1556960"
  },
  {
    "text": "not only do we get Z shot Improvement",
    "start": "1556960",
    "end": "1559399"
  },
  {
    "text": "non-negligible we also get faster",
    "start": "1559399",
    "end": "1561880"
  },
  {
    "text": "training when we fine tune on these",
    "start": "1561880",
    "end": "1564039"
  },
  {
    "text": "Target tasks and in particular that even",
    "start": "1564039",
    "end": "1566159"
  },
  {
    "text": "some task where if you train from",
    "start": "1566159",
    "end": "1567399"
  },
  {
    "text": "scratch we will simply",
    "start": "1567399",
    "end": "1569880"
  },
  {
    "text": "Flatline while if we pre-train on the",
    "start": "1569880",
    "end": "1572840"
  },
  {
    "text": "internet of things while the Zero",
    "start": "1572840",
    "end": "1574159"
  },
  {
    "text": "Performance is still terrible it",
    "start": "1574159",
    "end": "1576440"
  },
  {
    "text": "actually learns",
    "start": "1576440",
    "end": "1578039"
  },
  {
    "text": "efficiently so we believe that we've now",
    "start": "1578039",
    "end": "1580679"
  },
  {
    "text": "taken steps towards an agentic",
    "start": "1580679",
    "end": "1583760"
  },
  {
    "text": "Foundation Model A Foundation model that",
    "start": "1583760",
    "end": "1586799"
  },
  {
    "text": "is pre-trained for decision making for",
    "start": "1586799",
    "end": "1589279"
  },
  {
    "text": "acting rather than for predicting the",
    "start": "1589279",
    "end": "1591200"
  },
  {
    "text": "next token and and I've seen some of",
    "start": "1591200",
    "end": "1593159"
  },
  {
    "text": "these and obviously we'll share them",
    "start": "1593159",
    "end": "1594520"
  },
  {
    "text": "with the viewers here with a link and",
    "start": "1594520",
    "end": "1596000"
  },
  {
    "text": "and S them there it's like a platform",
    "start": "1596000",
    "end": "1598240"
  },
  {
    "text": "game type thing like from computer games",
    "start": "1598240",
    "end": "1600799"
  },
  {
    "text": "um do you see that that will then expand",
    "start": "1600799",
    "end": "1602640"
  },
  {
    "text": "into 3D in the same way as computer",
    "start": "1602640",
    "end": "1604320"
  },
  {
    "text": "games dead so the Hope here is that this",
    "start": "1604320",
    "end": "1606640"
  },
  {
    "text": "is at the beginning of that Journey um",
    "start": "1606640",
    "end": "1610440"
  },
  {
    "text": "where we at the very very early days",
    "start": "1610440",
    "end": "1613360"
  },
  {
    "text": "trying to lay the foundation for how to",
    "start": "1613360",
    "end": "1615399"
  },
  {
    "text": "do training in",
    "start": "1615399",
    "end": "1616960"
  },
  {
    "text": "simulation and make it robust and",
    "start": "1616960",
    "end": "1619760"
  },
  {
    "text": "transferable as opposed to training on",
    "start": "1619760",
    "end": "1621679"
  },
  {
    "text": "supervised data from that original task",
    "start": "1621679",
    "end": "1623600"
  },
  {
    "text": "from that Source distribution right and",
    "start": "1623600",
    "end": "1626279"
  },
  {
    "text": "and but but the limit here is purely",
    "start": "1626279",
    "end": "1627960"
  },
  {
    "text": "computational because the same thing",
    "start": "1627960",
    "end": "1629159"
  },
  {
    "text": "we've done now you could in principle do",
    "start": "1629159",
    "end": "1630640"
  },
  {
    "text": "in a 3D environment you could in",
    "start": "1630640",
    "end": "1632640"
  },
  {
    "text": "principle do in like much much richer",
    "start": "1632640",
    "end": "1634000"
  },
  {
    "text": "environments and settings so we're",
    "start": "1634000",
    "end": "1636000"
  },
  {
    "text": "trying to lay the foundations so they",
    "start": "1636000",
    "end": "1637760"
  },
  {
    "text": "can be scaled up with larger",
    "start": "1637760",
    "end": "1641120"
  },
  {
    "text": "computers so now car is take one this is",
    "start": "1646200",
    "end": "1649000"
  },
  {
    "text": "me leaving the house and going to to my",
    "start": "1649000",
    "end": "1650720"
  },
  {
    "text": "parking space and finding a car Railway",
    "start": "1650720",
    "end": "1652840"
  },
  {
    "text": "maybe I have to walk a bit further to",
    "start": "1652840",
    "end": "1654480"
  },
  {
    "text": "get to the railway so that'll be a cost",
    "start": "1654480",
    "end": "1655799"
  },
  {
    "text": "of two and then we can start to put",
    "start": "1655799",
    "end": "1657440"
  },
  {
    "text": "these these um actions in so actually",
    "start": "1657440",
    "end": "1659080"
  },
  {
    "text": "these arrows should be dots and I can",
    "start": "1659080",
    "end": "1661240"
  },
  {
    "text": "put in the the action that we had before",
    "start": "1661240",
    "end": "1665640"
  }
]
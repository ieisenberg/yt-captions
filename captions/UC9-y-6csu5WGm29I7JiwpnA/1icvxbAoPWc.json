[
  {
    "text": "so where we left it was that we've got",
    "start": "0",
    "end": "1760"
  },
  {
    "text": "ourselves now a fully connected network",
    "start": "1760",
    "end": "3439"
  },
  {
    "text": "so it makes no assumptions about the",
    "start": "3439",
    "end": "4799"
  },
  {
    "text": "size of the input the number of",
    "start": "4799",
    "end": "6319"
  },
  {
    "text": "parameters we're going to have it just",
    "start": "6319",
    "end": "8160"
  },
  {
    "text": "adapts itself depending on the size of",
    "start": "8160",
    "end": "9920"
  },
  {
    "text": "the input which for images you can",
    "start": "9920",
    "end": "11519"
  },
  {
    "text": "imagine makes quite a lot of sense they",
    "start": "11519",
    "end": "12880"
  },
  {
    "text": "change size quite a lot but in most",
    "start": "12880",
    "end": "15040"
  },
  {
    "text": "other ways it acts exactly like a normal",
    "start": "15040",
    "end": "16480"
  },
  {
    "text": "deep network",
    "start": "16480",
    "end": "19119"
  },
  {
    "text": "we've talked about this before in other",
    "start": "19600",
    "end": "20800"
  },
  {
    "text": "videos like the deep dream one but the",
    "start": "20800",
    "end": "23039"
  },
  {
    "text": "deeper you go into the network the sort",
    "start": "23039",
    "end": "24880"
  },
  {
    "text": "of higher level information we have on",
    "start": "24880",
    "end": "26400"
  },
  {
    "text": "what's going on it's objects and",
    "start": "26400",
    "end": "28560"
  },
  {
    "text": "animals and things rather than bits of",
    "start": "28560",
    "end": "30560"
  },
  {
    "text": "fur and edges and the shallower we are",
    "start": "30560",
    "end": "34160"
  },
  {
    "text": "we have much less idea but the shallower",
    "start": "34160",
    "end": "37200"
  },
  {
    "text": "we are we also have much higher spatial",
    "start": "37200",
    "end": "38960"
  },
  {
    "text": "resolution because we've got basically",
    "start": "38960",
    "end": "40480"
  },
  {
    "text": "the input image size because of these",
    "start": "40480",
    "end": "42399"
  },
  {
    "text": "max pooling layers mostly every time we",
    "start": "42399",
    "end": "44640"
  },
  {
    "text": "down sample what we're doing is we're",
    "start": "44640",
    "end": "45920"
  },
  {
    "text": "taking a small group of pixels and just",
    "start": "45920",
    "end": "47920"
  },
  {
    "text": "choosing the best of them the maximum",
    "start": "47920",
    "end": "49760"
  },
  {
    "text": "and putting that in the output and that",
    "start": "49760",
    "end": "51600"
  },
  {
    "text": "just halves the size of the image and",
    "start": "51600",
    "end": "53600"
  },
  {
    "text": "halves it again and has it again and you",
    "start": "53600",
    "end": "55600"
  },
  {
    "text": "can imagine if you've got an image of",
    "start": "55600",
    "end": "57760"
  },
  {
    "text": "256 by 256 we might repeat this process",
    "start": "57760",
    "end": "60160"
  },
  {
    "text": "four five six times until we've got a",
    "start": "60160",
    "end": "61760"
  },
  {
    "text": "very small region it's done for a couple",
    "start": "61760",
    "end": "63920"
  },
  {
    "text": "of reasons one is that we want to be",
    "start": "63920",
    "end": "65680"
  },
  {
    "text": "invariant to where things are in the",
    "start": "65680",
    "end": "67200"
  },
  {
    "text": "image which means that if the dog's over",
    "start": "67200",
    "end": "68640"
  },
  {
    "text": "to the right we still want to find it",
    "start": "68640",
    "end": "70479"
  },
  {
    "text": "even if it's",
    "start": "70479",
    "end": "71600"
  },
  {
    "text": "or over to the left right and so we what",
    "start": "71600",
    "end": "74400"
  },
  {
    "text": "we don't want it to be affected by that",
    "start": "74400",
    "end": "76320"
  },
  {
    "text": "the other the other issue quite frankly",
    "start": "76320",
    "end": "77680"
  },
  {
    "text": "is we don't have enough video ram yet we",
    "start": "77680",
    "end": "79280"
  },
  {
    "text": "routinely fill up",
    "start": "79280",
    "end": "81040"
  },
  {
    "text": "multiple graphics cards each of which",
    "start": "81040",
    "end": "82560"
  },
  {
    "text": "has 12 gigabytes on um it depends on the",
    "start": "82560",
    "end": "86240"
  },
  {
    "text": "situation you're looking at this is only",
    "start": "86240",
    "end": "88159"
  },
  {
    "text": "one dimension i've drawn here but it's",
    "start": "88159",
    "end": "89520"
  },
  {
    "text": "actually two dimensional if you halve",
    "start": "89520",
    "end": "91920"
  },
  {
    "text": "the x and y dimensions you're actually",
    "start": "91920",
    "end": "93759"
  },
  {
    "text": "dividing the amount of memory required",
    "start": "93759",
    "end": "95280"
  },
  {
    "text": "for the next layer by four and then by",
    "start": "95280",
    "end": "97280"
  },
  {
    "text": "four again and then by four again and so",
    "start": "97280",
    "end": "99360"
  },
  {
    "text": "actually you save an absolutely massive",
    "start": "99360",
    "end": "101439"
  },
  {
    "text": "amount of ram by spatially down sampling",
    "start": "101439",
    "end": "104560"
  },
  {
    "text": "and without it we'd be stuck with very",
    "start": "104560",
    "end": "106720"
  },
  {
    "text": "small networks indeed but we've got this",
    "start": "106720",
    "end": "108560"
  },
  {
    "text": "problem that yes we've worked out the",
    "start": "108560",
    "end": "110159"
  },
  {
    "text": "cats are in the image or something like",
    "start": "110159",
    "end": "111600"
  },
  {
    "text": "this but it's very very small right it's",
    "start": "111600",
    "end": "113680"
  },
  {
    "text": "only a few pixels by a few pixels we've",
    "start": "113680",
    "end": "115920"
  },
  {
    "text": "got a rough idea there's something going",
    "start": "115920",
    "end": "117439"
  },
  {
    "text": "on here maybe we could just balloon it",
    "start": "117439",
    "end": "119920"
  },
  {
    "text": "up like like a large linear up sampling",
    "start": "119920",
    "end": "122399"
  },
  {
    "text": "and just sort of go well that's roughly",
    "start": "122399",
    "end": "124159"
  },
  {
    "text": "a cat but it wouldn't be anything",
    "start": "124159",
    "end": "125840"
  },
  {
    "text": "interesting",
    "start": "125840",
    "end": "126880"
  },
  {
    "text": "so i guess the interesting thing",
    "start": "126880",
    "end": "128560"
  },
  {
    "text": "happened in 2014 when jonathan long",
    "start": "128560",
    "end": "131120"
  },
  {
    "text": "proposed",
    "start": "131120",
    "end": "132720"
  },
  {
    "text": "a kind of a solution to this right which",
    "start": "132720",
    "end": "134720"
  },
  {
    "text": "is essentially a smarter up sampling",
    "start": "134720",
    "end": "137120"
  },
  {
    "text": "what we do is we we essentially reverse",
    "start": "137120",
    "end": "139520"
  },
  {
    "text": "this process basically we have a sort of",
    "start": "139520",
    "end": "142480"
  },
  {
    "text": "an up sample here which will maybe",
    "start": "142480",
    "end": "144400"
  },
  {
    "text": "double the size",
    "start": "144400",
    "end": "145920"
  },
  {
    "text": "and then we look over here and we bring",
    "start": "145920",
    "end": "148160"
  },
  {
    "text": "in some of this interesting information",
    "start": "148160",
    "end": "150000"
  },
  {
    "text": "as well right and then we up sample",
    "start": "150000",
    "end": "151760"
  },
  {
    "text": "again and we go all right so we can this",
    "start": "151760",
    "end": "154080"
  },
  {
    "text": "is now the same size as this so we can",
    "start": "154080",
    "end": "156080"
  },
  {
    "text": "bring in some of this information and",
    "start": "156080",
    "end": "157680"
  },
  {
    "text": "when i say bring in i mean literally add",
    "start": "157680",
    "end": "159280"
  },
  {
    "text": "these to these and we can have",
    "start": "159280",
    "end": "160879"
  },
  {
    "text": "convolutional layers here to learn that",
    "start": "160879",
    "end": "162480"
  },
  {
    "text": "mapping so we can take nothing from here",
    "start": "162480",
    "end": "164160"
  },
  {
    "text": "or everything from here it doesn't",
    "start": "164160",
    "end": "165360"
  },
  {
    "text": "really matter and finally we up sample",
    "start": "165360",
    "end": "167280"
  },
  {
    "text": "back to the original size",
    "start": "167280",
    "end": "169519"
  },
  {
    "text": "and",
    "start": "169519",
    "end": "170480"
  },
  {
    "text": "we bring this in here using a sum now",
    "start": "170480",
    "end": "173040"
  },
  {
    "text": "what we've actually done is a kind of",
    "start": "173040",
    "end": "174480"
  },
  {
    "text": "smart way of making this bigger i mean",
    "start": "174480",
    "end": "176480"
  },
  {
    "text": "it's kind of you've got to kind of try",
    "start": "176480",
    "end": "177519"
  },
  {
    "text": "and get your head around it but these",
    "start": "177519",
    "end": "178959"
  },
  {
    "text": "features are very sure what's in the",
    "start": "178959",
    "end": "180560"
  },
  {
    "text": "image but only roughly where it is these",
    "start": "180560",
    "end": "183360"
  },
  {
    "text": "features a much higher pixel resolution",
    "start": "183360",
    "end": "186000"
  },
  {
    "text": "they're much more sure in some sense",
    "start": "186000",
    "end": "188080"
  },
  {
    "text": "where things are but not exactly what",
    "start": "188080",
    "end": "190080"
  },
  {
    "text": "they are right so you could imagine in",
    "start": "190080",
    "end": "191920"
  },
  {
    "text": "an intuitive way we're saying this is a",
    "start": "191920",
    "end": "193920"
  },
  {
    "text": "cat",
    "start": "193920",
    "end": "194800"
  },
  {
    "text": "and down here we've seen some texturey",
    "start": "194800",
    "end": "196480"
  },
  {
    "text": "fur let's combine them together to",
    "start": "196480",
    "end": "198480"
  },
  {
    "text": "outline exactly where the cat is this is",
    "start": "198480",
    "end": "200959"
  },
  {
    "text": "a kind of idea and you can use this for",
    "start": "200959",
    "end": "202720"
  },
  {
    "text": "all kinds of things so people have used",
    "start": "202720",
    "end": "204640"
  },
  {
    "text": "it for segmentation or we call semantic",
    "start": "204640",
    "end": "206640"
  },
  {
    "text": "segmentation which is where you will",
    "start": "206640",
    "end": "208480"
  },
  {
    "text": "label each pixel with a class depending",
    "start": "208480",
    "end": "210560"
  },
  {
    "text": "on what is in that pixel traditional",
    "start": "210560",
    "end": "212400"
  },
  {
    "text": "segmentation usually meant background",
    "start": "212400",
    "end": "213920"
  },
  {
    "text": "and foreground now semantic segmentation",
    "start": "213920",
    "end": "216239"
  },
  {
    "text": "means maybe hundreds of classes so for",
    "start": "216239",
    "end": "218159"
  },
  {
    "text": "instance in the image i'm seeing here it",
    "start": "218159",
    "end": "219519"
  },
  {
    "text": "might be you the table the computer the",
    "start": "219519",
    "end": "221920"
  },
  {
    "text": "desk the window yeah this kind of thing",
    "start": "221920",
    "end": "224159"
  },
  {
    "text": "and there's a huge amount of different",
    "start": "224159",
    "end": "225760"
  },
  {
    "text": "applications for that kind of thing so",
    "start": "225760",
    "end": "227360"
  },
  {
    "text": "on a basic level you could imagine just",
    "start": "227360",
    "end": "228799"
  },
  {
    "text": "trying to find one object specifically",
    "start": "228799",
    "end": "230400"
  },
  {
    "text": "in a scene so just for people it's",
    "start": "230400",
    "end": "232239"
  },
  {
    "text": "either person or it's background we",
    "start": "232239",
    "end": "233760"
  },
  {
    "text": "don't care what else or you could be",
    "start": "233760",
    "end": "235920"
  },
  {
    "text": "training this on something like imagenet",
    "start": "235920",
    "end": "237280"
  },
  {
    "text": "with lots and lots of classes or i mean",
    "start": "237280",
    "end": "239519"
  },
  {
    "text": "there's the ms coco data set for example",
    "start": "239519",
    "end": "241280"
  },
  {
    "text": "that has lots and lots of classes and",
    "start": "241280",
    "end": "244080"
  },
  {
    "text": "so you're trying to find airplanes and",
    "start": "244080",
    "end": "245760"
  },
  {
    "text": "cars and things and people do this on",
    "start": "245760",
    "end": "247360"
  },
  {
    "text": "street scene segmentation as well so you",
    "start": "247360",
    "end": "249200"
  },
  {
    "text": "could say look given this picture of a",
    "start": "249200",
    "end": "250640"
  },
  {
    "text": "road where is the road where is the",
    "start": "250640",
    "end": "252560"
  },
  {
    "text": "pavement what's a building where are the",
    "start": "252560",
    "end": "254239"
  },
  {
    "text": "road signs and actually analyze the",
    "start": "254239",
    "end": "256160"
  },
  {
    "text": "entire scene",
    "start": "256160",
    "end": "257440"
  },
  {
    "text": "which which is obviously really really",
    "start": "257440",
    "end": "258720"
  },
  {
    "text": "quite powerful the other thing is that",
    "start": "258720",
    "end": "260239"
  },
  {
    "text": "you don't have to segment the image",
    "start": "260239",
    "end": "262000"
  },
  {
    "text": "instead of segmenting it you can just",
    "start": "262000",
    "end": "263520"
  },
  {
    "text": "try and find objects you can say instead",
    "start": "263520",
    "end": "265759"
  },
  {
    "text": "of just outlining where an object is yes",
    "start": "265759",
    "end": "268000"
  },
  {
    "text": "or no why don't we try and draw a little",
    "start": "268000",
    "end": "270400"
  },
  {
    "text": "heat map of where we think it is and",
    "start": "270400",
    "end": "272240"
  },
  {
    "text": "then we can pinpoint objects so we can",
    "start": "272240",
    "end": "274880"
  },
  {
    "text": "say where the two pupils on a face or",
    "start": "274880",
    "end": "278080"
  },
  {
    "text": "can we draw around someone's face or",
    "start": "278080",
    "end": "280000"
  },
  {
    "text": "their nose or their forehead so that we",
    "start": "280000",
    "end": "281919"
  },
  {
    "text": "can then fit a model to that so aaron",
    "start": "281919",
    "end": "283600"
  },
  {
    "text": "was doing this in his network where he",
    "start": "283600",
    "end": "285199"
  },
  {
    "text": "was actually predicting the 3d and",
    "start": "285199",
    "end": "287040"
  },
  {
    "text": "positional information of a face based",
    "start": "287040",
    "end": "289120"
  },
  {
    "text": "just on a picture and you've all had to",
    "start": "289120",
    "end": "290960"
  },
  {
    "text": "go with that we've also been using it",
    "start": "290960",
    "end": "292639"
  },
  {
    "text": "for human pose estimation so where's the",
    "start": "292639",
    "end": "294960"
  },
  {
    "text": "right hand where's the left hand what",
    "start": "294960",
    "end": "297120"
  },
  {
    "text": "pose is this person currently doing",
    "start": "297120",
    "end": "298960"
  },
  {
    "text": "which obviously you can imagine has lots",
    "start": "298960",
    "end": "300880"
  },
  {
    "text": "of implications for things like um",
    "start": "300880",
    "end": "303039"
  },
  {
    "text": "connect sensors and sort of interactive",
    "start": "303039",
    "end": "305360"
  },
  {
    "text": "games but also you know pedestrian",
    "start": "305360",
    "end": "307360"
  },
  {
    "text": "tracking and",
    "start": "307360",
    "end": "308880"
  },
  {
    "text": "and loads of other examples of things",
    "start": "308880",
    "end": "311680"
  },
  {
    "text": "where it might be useful to know what a",
    "start": "311680",
    "end": "313039"
  },
  {
    "text": "person is up to",
    "start": "313039",
    "end": "314639"
  },
  {
    "text": "and finally we're using obviously in",
    "start": "314639",
    "end": "316000"
  },
  {
    "text": "plant science to try and count objects",
    "start": "316000",
    "end": "318880"
  },
  {
    "text": "and localize objects so where's the",
    "start": "318880",
    "end": "320720"
  },
  {
    "text": "disease on this image can we produce a",
    "start": "320720",
    "end": "323120"
  },
  {
    "text": "heat map that shows exactly where it is",
    "start": "323120",
    "end": "324960"
  },
  {
    "text": "where are the ears of wheat in this",
    "start": "324960",
    "end": "326720"
  },
  {
    "text": "image can we count the number of",
    "start": "326720",
    "end": "327919"
  },
  {
    "text": "spikelets to get an estimate of how much",
    "start": "327919",
    "end": "329759"
  },
  {
    "text": "yield this wheat is producing compared",
    "start": "329759",
    "end": "331520"
  },
  {
    "text": "to this wheat right and then we can",
    "start": "331520",
    "end": "333120"
  },
  {
    "text": "start to run experiments on you know",
    "start": "333120",
    "end": "334880"
  },
  {
    "text": "these ones are water stressed does that",
    "start": "334880",
    "end": "336880"
  },
  {
    "text": "mean this one's better this kind of",
    "start": "336880",
    "end": "338240"
  },
  {
    "text": "thing so this is called an encoder",
    "start": "338240",
    "end": "339840"
  },
  {
    "text": "decoder because sometimes what we're",
    "start": "339840",
    "end": "341120"
  },
  {
    "text": "doing is we're encoding our spatial",
    "start": "341120",
    "end": "342720"
  },
  {
    "text": "information into some kind of features",
    "start": "342720",
    "end": "344160"
  },
  {
    "text": "of what's going on in the in the scene",
    "start": "344160",
    "end": "346479"
  },
  {
    "text": "in general we remove the spatial",
    "start": "346479",
    "end": "348400"
  },
  {
    "text": "resolution in exchange for learning more",
    "start": "348400",
    "end": "350479"
  },
  {
    "text": "about the scene and then we bring it",
    "start": "350479",
    "end": "352000"
  },
  {
    "text": "back in by finding detail from earlier",
    "start": "352000",
    "end": "354400"
  },
  {
    "text": "parts of the network and bringing them",
    "start": "354400",
    "end": "356000"
  },
  {
    "text": "in as well that's the decoding stage in",
    "start": "356000",
    "end": "358160"
  },
  {
    "text": "some sense this is a little bit like a",
    "start": "358160",
    "end": "359680"
  },
  {
    "text": "gan in the sense but this is the",
    "start": "359680",
    "end": "360960"
  },
  {
    "text": "generator here and this is the",
    "start": "360960",
    "end": "362319"
  },
  {
    "text": "discriminator it's just that you would",
    "start": "362319",
    "end": "363680"
  },
  {
    "text": "switch them around but let's not go not",
    "start": "363680",
    "end": "366000"
  },
  {
    "text": "over complicate things",
    "start": "366000",
    "end": "368560"
  },
  {
    "text": "and this one lit up which is maybe pause",
    "start": "368560",
    "end": "370319"
  },
  {
    "text": "and maybe this one lit up because here",
    "start": "370319",
    "end": "372479"
  },
  {
    "text": "was a few lines in a row and this one is",
    "start": "372479",
    "end": "374639"
  },
  {
    "text": "sort of furry texture or something you",
    "start": "374639",
    "end": "376400"
  },
  {
    "text": "know and we're getting lower and lower",
    "start": "376400",
    "end": "377919"
  },
  {
    "text": "level as we go through",
    "start": "377919",
    "end": "380800"
  }
]
[
  {
    "text": "Classification lets us pick one or the other or some small number of labels for our data",
    "start": "579",
    "end": "5699"
  },
  {
    "text": "The problem is that real life doesn't fit into these neat little categories",
    "start": "5700",
    "end": "8340"
  },
  {
    "text": "When we have label data there isn't yes or no or a B or C or some labels?",
    "start": "11410",
    "end": "16469"
  },
  {
    "text": "Right, then we have what we call a regression problem. We're actually trying to predict actual outputs, right so given these inputs",
    "start": "16470",
    "end": "23220"
  },
  {
    "text": "What's the temperature at which something will occur or?",
    "start": "23220",
    "end": "25949"
  },
  {
    "text": "Given this movie on a streaming site and the attributes and the people that have watched it",
    "start": "26260",
    "end": "30029"
  },
  {
    "text": "What amount of action is it right because that informs who should watch that movie",
    "start": "35440",
    "end": "39539"
  },
  {
    "text": "There's lots of times when you don't want to say--but sees this and isn't this you want to say it's a little bit of this",
    "start": "39610",
    "end": "45209"
  },
  {
    "text": "And a little bit of this",
    "start": "45210",
    "end": "46360"
  },
  {
    "text": "and that's what regression is for and some of the algorithms we use for regression are actually quite similar to",
    "start": "46360",
    "end": "51299"
  },
  {
    "text": "Classify. So for example, you can regress using a support vector machine or support vector of aggressor, right?",
    "start": "52030",
    "end": "57329"
  },
  {
    "text": "But we also use other ones like so we're more likely to use things like linear regression and things like this",
    "start": "57340",
    "end": "62729"
  },
  {
    "text": "So let's start off with perhaps for simplest form of regression. That's linear regression, right?",
    "start": "62730",
    "end": "67739"
  },
  {
    "text": "It might not occur to people who use linear regression for actually what you're doing is machine learning",
    "start": "67740",
    "end": "71400"
  },
  {
    "text": "But you are let's imagine we have just data that's got one input",
    "start": "71590",
    "end": "74969"
  },
  {
    "text": "so one attribute attribute one and",
    "start": "74970",
    "end": "77069"
  },
  {
    "text": "Our output which is why this is our table of data just like before and this is our instance data",
    "start": "77470",
    "end": "82589"
  },
  {
    "text": "So we've got one two, three four like this",
    "start": "82590",
    "end": "85500"
  },
  {
    "text": "so what we want to do is we want to input attribute one and",
    "start": "85659",
    "end": "88379"
  },
  {
    "text": "We want to output Y which instead of being a yes or no is going to be some number on a scale",
    "start": "88540",
    "end": "93059"
  },
  {
    "text": "Let's say between Norton one. So really what we're trying to do is we've got our graph here of our input variable",
    "start": "93369",
    "end": "99779"
  },
  {
    "text": "Attribute one and we've got our Y output and these are our data points in our training set",
    "start": "100720",
    "end": "105899"
  },
  {
    "text": "So here like this and they sort of go up like this",
    "start": "105899",
    "end": "108989"
  },
  {
    "text": "what we're going to do using linear regression is fit a line through this data and a line is of the form y",
    "start": "109420",
    "end": "114298"
  },
  {
    "text": "equals MX plus C",
    "start": "114670",
    "end": "116490"
  },
  {
    "text": "so in this case M is going to be the gradient of our line and C is going to be B intercept so in this",
    "start": "116490",
    "end": "120868"
  },
  {
    "text": "Case I guess something along the lines of this straight up like this",
    "start": "120869",
    "end": "123898"
  },
  {
    "text": "So if our M was one in this case M",
    "start": "123899",
    "end": "126239"
  },
  {
    "text": "Equals one or maybe equals one point two to make it slightly more interesting and then our C is going to be let's say C",
    "start": "126399",
    "end": "132749"
  },
  {
    "text": "His naught point naught to these are the values that we're going to learn using linear regression",
    "start": "133120",
    "end": "138039"
  },
  {
    "text": "So, how do we train something like this?",
    "start": "138290",
    "end": "139959"
  },
  {
    "text": "What we're going to do is we want to find the values for our unknowns which are M and C",
    "start": "139959",
    "end": "144939"
  },
  {
    "text": "Given a lot of x and y pairs, right?",
    "start": "145459",
    "end": "148268"
  },
  {
    "text": "So we've got our x and y pairs here and we want to predict these values the optimal values for this data set",
    "start": "148269",
    "end": "153519"
  },
  {
    "text": "So we're going to find values for M. And C where this distance the prediction error is minimized the better fit",
    "start": "153650",
    "end": "159640"
  },
  {
    "text": "This line is the average prediction error is going to go down if this line is over here",
    "start": "159640",
    "end": "164199"
  },
  {
    "text": "It's going to be a huge error. And so the hope is that if we predict this correctly and we have an M",
    "start": "164390",
    "end": "169329"
  },
  {
    "text": "And we have a C then when we come up with a new",
    "start": "169329",
    "end": "171609"
  },
  {
    "text": "Value that we're trying to predict we can pass it through this formula. We can multiply it by 1.2 and then add",
    "start": "171920",
    "end": "177670"
  },
  {
    "text": "0.02 and that will produce our prediction for y and hopefully that would be quite close to what it is",
    "start": "178220",
    "end": "183940"
  },
  {
    "text": "So for example, let's imagine. We have a new value for attribute 1. Let's come in here",
    "start": "183940",
    "end": "187959"
  },
  {
    "text": "We're gonna look up here and this is going to be the prediction for our Y and that's the output of our aggressor",
    "start": "188060",
    "end": "194140"
  },
  {
    "text": "So this linear regression is capable of producing",
    "start": "194140",
    "end": "196660"
  },
  {
    "text": "Predictions based on its attribute now if we have more than one attribute",
    "start": "197840",
    "end": "201220"
  },
  {
    "text": "This is called multivariate linear regression and the principle is exactly the same is this we're going to have lots of these multiplier ends",
    "start": "201230",
    "end": "207489"
  },
  {
    "text": "We could say something like Y is",
    "start": "207489",
    "end": "209559"
  },
  {
    "text": "m1 x1 plus",
    "start": "210500",
    "end": "212679"
  },
  {
    "text": "m2 x2 and so on for all of our different attributes",
    "start": "213230",
    "end": "217090"
  },
  {
    "text": "so it's going to be a linear combination a bit like PCA a linear combination of",
    "start": "217090",
    "end": "221200"
  },
  {
    "text": "These different attributes and it's obviously going to be multi-dimensional",
    "start": "221870",
    "end": "224679"
  },
  {
    "text": "So one interesting thing about linear regression is but what it's going to do is predict us a straight line",
    "start": "225079",
    "end": "229719"
  },
  {
    "text": "regardless of how many dimensions we've got now sometimes if we want to use this for a classification",
    "start": "229910",
    "end": "233709"
  },
  {
    "text": "Purpose we still can all right",
    "start": "233930",
    "end": "235480"
  },
  {
    "text": "Now I'm supposed to be talking about regression not classification",
    "start": "235480",
    "end": "237700"
  },
  {
    "text": "But just briefly if you indulge me we can pass this function through something called a logistic function or in the sigmoid curve",
    "start": "237700",
    "end": "244209"
  },
  {
    "text": "And we can squash it into something. There's this shape",
    "start": "244209",
    "end": "247179"
  },
  {
    "text": "And now what we're doing is we're pushing our values up to 1 and down to 0",
    "start": "247180",
    "end": "251469"
  },
  {
    "text": "Right and that is our classification between 1 and 0",
    "start": "251720",
    "end": "254349"
  },
  {
    "text": "So it is possible to perform linear regression using this additional logistic function to perform",
    "start": "254959",
    "end": "260259"
  },
  {
    "text": "Classification and this is called logistic regression. I",
    "start": "260810",
    "end": "263139"
  },
  {
    "text": "Just what I mention, but that's something you will see being done on some data",
    "start": "263719",
    "end": "267828"
  },
  {
    "text": "So let's talk a little bit about something more powerful",
    "start": "267930",
    "end": "269930"
  },
  {
    "text": "That's artificial neural networks",
    "start": "269940",
    "end": "271920"
  },
  {
    "text": "now",
    "start": "271920",
    "end": "272700"
  },
  {
    "text": "Anytime in the media at the moment when you see the term AI what they're actually talking about is machine learning and what they're talking",
    "start": "272700",
    "end": "278240"
  },
  {
    "text": "About is some large neural network. Now. Let's keep it a little bit smaller",
    "start": "278240",
    "end": "281749"
  },
  {
    "text": "Let's imagine what we want to do is take item for attributes and map them to some prediction some regressed value, right?",
    "start": "281750",
    "end": "287869"
  },
  {
    "text": "How are we going to do this?",
    "start": "287870",
    "end": "288620"
  },
  {
    "text": "Well, what we can do is we can essentially combine a lot of different linear regressions through some nonlinear functions into a really powerful",
    "start": "288620",
    "end": "295940"
  },
  {
    "text": "Regression algorithm, right. So let's imagine that we have some data which has got three inputs",
    "start": "296910",
    "end": "301369"
  },
  {
    "text": "So we've got our instances and we've got our attributes a B and C. Our inputs are a B and C",
    "start": "301370",
    "end": "307100"
  },
  {
    "text": "And then we have some hidden New Orleans right and I explained a neuron in a moment",
    "start": "307100",
    "end": "310369"
  },
  {
    "text": "Then we have an output value that we'd like to address. This is where we're trying to predict the value",
    "start": "310370",
    "end": "314600"
  },
  {
    "text": "So, you know how much disease does something have how hot is it these kind of things depending on our attributes?",
    "start": "314700",
    "end": "319939"
  },
  {
    "text": "this is where we put in a this is where we put in B and this is where we put in C and",
    "start": "319940",
    "end": "324110"
  },
  {
    "text": "Then we perform a weighted sum of all of these things for each of these neurons",
    "start": "324180",
    "end": "329449"
  },
  {
    "text": "So for example this neurons going to have three inputs from these three here and this is going to have weight one",
    "start": "329450",
    "end": "335210"
  },
  {
    "text": "This is going to be weight - this is going to be weight three",
    "start": "335210",
    "end": "338029"
  },
  {
    "text": "And we're gonna do a weighted sum just like in linear regression",
    "start": "338160",
    "end": "341300"
  },
  {
    "text": "So we're going to do weight one times a plus weight two times B plus weight three times c add",
    "start": "341300",
    "end": "347388"
  },
  {
    "text": "them together and then we're going to add any bias that we want to so this is going to be plus some bias and that's",
    "start": "347730",
    "end": "353420"
  },
  {
    "text": "Going to give us a value for this neuron, which let's call it hidden want right because this is generally speaking",
    "start": "353420",
    "end": "358640"
  },
  {
    "text": "We don't look at these values. It's not too important. We're going to do a different sum for this one",
    "start": "358640",
    "end": "363080"
  },
  {
    "text": "So I'm going to all them in different colors so we don't get confused. So this has got three weights",
    "start": "363080",
    "end": "366469"
  },
  {
    "text": "So this is going to be a different way",
    "start": "366720",
    "end": "368150"
  },
  {
    "text": "This is going to have another different weight",
    "start": "368150",
    "end": "369780"
  },
  {
    "text": "And we're going to do this much times a Plus this much times B plus this much times C",
    "start": "369780",
    "end": "374059"
  },
  {
    "text": "Add them all up add a plus a bias and we're going to get hidden - and we're going to do the same thing",
    "start": "374220",
    "end": "380630"
  },
  {
    "text": "With these ones here like this",
    "start": "380940",
    "end": "382890"
  },
  {
    "text": "This is going to be hidden three hidden for hidden five and so on for as far as we like to go",
    "start": "382890",
    "end": "389419"
  },
  {
    "text": "All right",
    "start": "389520",
    "end": "390050"
  },
  {
    "text": "now",
    "start": "390050",
    "end": "390599"
  },
  {
    "text": "the nice thing about this is for each of these can calculate a different weighted sum now the problem is that if we just did",
    "start": "390600",
    "end": "396650"
  },
  {
    "text": "This then what happens is we actually get a series of linear regressions",
    "start": "396650",
    "end": "399679"
  },
  {
    "text": "All right",
    "start": "399930",
    "end": "400320"
  },
  {
    "text": "because this is just multivariate linear regression and in the end our",
    "start": "400320",
    "end": "402899"
  },
  {
    "text": "Algorithm doesn't end up any good right? If you combine multiple linear functions together, you just get one different linear function",
    "start": "403060",
    "end": "409560"
  },
  {
    "text": "so we pass all of these hidden values through a nonlinear function like a sigmoid or",
    "start": "409560",
    "end": "414539"
  },
  {
    "text": "Tan so a sigmoid goes between naught and 1 so this is not than 1 and a tan",
    "start": "414850",
    "end": "420509"
  },
  {
    "text": "Hyperbolic tangent will go between minus 1 and 1",
    "start": "420910",
    "end": "423209"
  },
  {
    "text": "Things like this and what that will do is add a sufficiently complex",
    "start": "423610",
    "end": "427680"
  },
  {
    "text": "Function that when we combined them all together",
    "start": "427780",
    "end": "429660"
  },
  {
    "text": "We can actually get quite a powerful algorithm the way this works is we put in a B and C",
    "start": "429660",
    "end": "433679"
  },
  {
    "text": "We calculate all the weighted sums through these functions into our hidden units and then we calculate another series of weighted sums",
    "start": "433680",
    "end": "440340"
  },
  {
    "text": "so add together to be our final output and this will be our final output prediction Y now the way we train this is",
    "start": "440560",
    "end": "447269"
  },
  {
    "text": "we're going to put in lots and lots of test data where we have the values for a b c and we know what the",
    "start": "447699",
    "end": "452519"
  },
  {
    "text": "Output should have been we go through the network and then we say, well actually we were a little bit off",
    "start": "452520",
    "end": "457948"
  },
  {
    "text": "So can we change all of these weights so that next time we're a little bit closer to the correct answer and let's keep doing",
    "start": "458139",
    "end": "463769"
  },
  {
    "text": "this over and over again in a process called gradient descent and",
    "start": "463770",
    "end": "467430"
  },
  {
    "text": "Slowly settle upon some weights where for the most part when we put in our a B and C",
    "start": "467919",
    "end": "473038"
  },
  {
    "text": "We get what we want out the other side now, it's unlikely to be perfect",
    "start": "473039",
    "end": "476669"
  },
  {
    "text": "but just like with the other machine learning as we've talked about we're going to be trying to make our",
    "start": "476669",
    "end": "481019"
  },
  {
    "text": "Prediction on our testing set as good as possible",
    "start": "481150",
    "end": "483150"
  },
  {
    "text": "All right",
    "start": "483460",
    "end": "484050"
  },
  {
    "text": "So we've put in a lot of training data and hopefully when we take this network and apply it to some new data it also",
    "start": "484050",
    "end": "489840"
  },
  {
    "text": "Performs. Well, let's look at an example",
    "start": "489849",
    "end": "491680"
  },
  {
    "text": "We looked at credit checks in the previous video and we will classify whether or not someone should be given credit",
    "start": "491680",
    "end": "496108"
  },
  {
    "text": "Well something that we cut we often calculate is credit rating",
    "start": "496270",
    "end": "499948"
  },
  {
    "text": "which is a value from let's say naught to 1 of",
    "start": "499949",
    "end": "502079"
  },
  {
    "text": "How good your credit score is so a could be how much money you have in your bank B could be whether you have any",
    "start": "502300",
    "end": "508289"
  },
  {
    "text": "Loans and C could be whether you own a car and obviously there's going to be more of these because you can't make a decision",
    "start": "508289",
    "end": "513629"
  },
  {
    "text": "On this those three things. So what we do is we get a number of people that we've already made decisions about right?",
    "start": "513630",
    "end": "518729"
  },
  {
    "text": "so we know the person a has a bank account balance of five thousand two thousand in loans, and he does own a car and",
    "start": "518729",
    "end": "525299"
  },
  {
    "text": "He has a credit rating of 75 or Northpoint 75 whatever your scale is",
    "start": "526540",
    "end": "531449"
  },
  {
    "text": "So we put this in we sieze wait",
    "start": "531450",
    "end": "533699"
  },
  {
    "text": "So but this is the correct",
    "start": "533699",
    "end": "534998"
  },
  {
    "text": "Prediction and then hopefully when another person comes along with a different set of variables will predict the right thing for them",
    "start": "534999",
    "end": "540839"
  },
  {
    "text": "So you can make this network as deep or as big as you want. We're typically",
    "start": "541660",
    "end": "545310"
  },
  {
    "text": "Multi-layer perceptrons or artificial neural networks, like this won't be very deep",
    "start": "546009",
    "end": "549539"
  },
  {
    "text": "one two three hidden units deep maybe but what's been shown in the literature is but actually",
    "start": "549540",
    "end": "554938"
  },
  {
    "text": "If you have a sufficient number of hidden units",
    "start": "555129",
    "end": "557069"
  },
  {
    "text": "You can basically model any function like this right as long as you've got sufficient training data to create it",
    "start": "557069",
    "end": "562228"
  },
  {
    "text": "So we're going to use Weka again",
    "start": "562230",
    "end": "564230"
  },
  {
    "text": "because Weka has lots of",
    "start": "564759",
    "end": "566759"
  },
  {
    "text": "regression algorithms built-in like artificial neural networks",
    "start": "566920",
    "end": "569550"
  },
  {
    "text": "And linear regression. So let's open up a data set. We're going to use this time",
    "start": "570309",
    "end": "574349"
  },
  {
    "text": "So they said we've got is a data set on superconductivity right now",
    "start": "574360",
    "end": "579269"
  },
  {
    "text": "Obviously my knowledge of physics is should we say average?",
    "start": "579269",
    "end": "581519"
  },
  {
    "text": "But a superconductor is something that when you get it to a critical temperature it becomes it has no resistance",
    "start": "581769",
    "end": "586859"
  },
  {
    "text": "Right, which is very useful for electrical circuits",
    "start": "586959",
    "end": "588989"
  },
  {
    "text": "And so this is a data set about what are the properties of material and what is the critical temperature?",
    "start": "588990",
    "end": "594449"
  },
  {
    "text": "Below, which it will be a superconductor",
    "start": "594730",
    "end": "596878"
  },
  {
    "text": "Now, I'm sure there's going to be some physicists in the comments that might point out some areas of what I just said",
    "start": "597610",
    "end": "601979"
  },
  {
    "text": "But we'll move on. So we're reading a file. This is quite a big data set",
    "start": "601980",
    "end": "605279"
  },
  {
    "text": "So we have a lot of input attributes and then at the end we have this critical temperature that we're trying to predict this",
    "start": "605279",
    "end": "610378"
  },
  {
    "text": "temperature if we look at this histogram goes from 0 to",
    "start": "610540",
    "end": "613259"
  },
  {
    "text": "185 if we look at some of the other things so for example, we've got this entropy atomic radius, which I can pretend",
    "start": "613899",
    "end": "619349"
  },
  {
    "text": "I know what that is, which goes from naught to two point one four. Is that good?",
    "start": "619350",
    "end": "622980"
  },
  {
    "text": "Right, what we're going to do is we're going to start by using",
    "start": "624069",
    "end": "626069"
  },
  {
    "text": "Multivariate linear regression to try and predict this critical temperature as a combination of these input features",
    "start": "626589",
    "end": "632849"
  },
  {
    "text": "So I'm going to go to classify. There's just one classified tab even for regression",
    "start": "632850",
    "end": "636928"
  },
  {
    "text": "we're going to use our same percentage splitters before so 70% and",
    "start": "637209",
    "end": "640768"
  },
  {
    "text": "We're going to use a simple linear regression function for this",
    "start": "641379",
    "end": "644819"
  },
  {
    "text": "Let's go",
    "start": "645579",
    "end": "646990"
  },
  {
    "text": "So we've trained our linear regression and what we want to do now is work out whether it's worked or not on our testing set",
    "start": "646990",
    "end": "652740"
  },
  {
    "text": "We've got the variables. We wanted Y and we've got the variables that have been predicted Y hat and",
    "start": "652740",
    "end": "658740"
  },
  {
    "text": "Hopefully they're exactly the same if they're exactly the same then they're going to be on a straight line like this",
    "start": "659319",
    "end": "664378"
  },
  {
    "text": "So we were hoping to get a why down here and we it now, of course this won't actually happened",
    "start": "664379",
    "end": "668729"
  },
  {
    "text": "What will happen is these wines are ever so slightly different than the Y's",
    "start": "668730",
    "end": "672180"
  },
  {
    "text": "we were expecting so you might see a bit of noise around the center like this and",
    "start": "672250",
    "end": "677069"
  },
  {
    "text": "The way we would normally measure this is something called mean absolute error or mean squared error or root mean squared error",
    "start": "677199",
    "end": "684269"
  },
  {
    "text": "Which all very similar ways to measure the same thing",
    "start": "684310",
    "end": "687359"
  },
  {
    "text": "It's to measure what is the average distance between what we wanted and what we got",
    "start": "687490",
    "end": "692099"
  },
  {
    "text": "so if we were hoping to get away of North Point - but we actually got a Y of North Point for then our",
    "start": "692100",
    "end": "699779"
  },
  {
    "text": "Mistake was we were not point to too high",
    "start": "700269",
    "end": "703529"
  },
  {
    "text": "And so for every single instance in our test set we can sum up all of the areas we've got and we can work out",
    "start": "703529",
    "end": "709559"
  },
  {
    "text": "What the average error was right. So we have a hundred in our test set",
    "start": "709560",
    "end": "712679"
  },
  {
    "text": "We sum up the errors and we divide by a hundred and that tells us I mean error was a certain amount",
    "start": "712680",
    "end": "717239"
  },
  {
    "text": "What will sometimes happen is your predictions will be above or below right?",
    "start": "717240",
    "end": "721259"
  },
  {
    "text": "and so your actual mean error might be zero because half a time you predicted too high half a time you predicted too low and",
    "start": "721259",
    "end": "727259"
  },
  {
    "text": "So on average, you've got it exactly right. Obviously, that's not correct",
    "start": "727259",
    "end": "730048"
  },
  {
    "text": "So what we tend to do is calculate something called mean absolute error",
    "start": "730149",
    "end": "733768"
  },
  {
    "text": "So essentially if you're too small, we just remove the minus sign and call call it an error of that amount",
    "start": "733769",
    "end": "740308"
  },
  {
    "text": "All right",
    "start": "740459",
    "end": "740790"
  },
  {
    "text": "So if your mean absolute error is nour point four then what that's saying is but on average you're naught point far away",
    "start": "740790",
    "end": "747120"
  },
  {
    "text": "Live above or below than where you were hoping to be",
    "start": "747370",
    "end": "750000"
  },
  {
    "text": "It's also quite common to see similar measures like root mean squared error for every instance",
    "start": "750160",
    "end": "754649"
  },
  {
    "text": "We take our error we square it we sum them all up and then right at the end",
    "start": "754649",
    "end": "758219"
  },
  {
    "text": "We take a square root, right?",
    "start": "758220",
    "end": "759629"
  },
  {
    "text": "And again, this is a very similar measure to mean absolute error like the squaring. We move our negative symbols for us",
    "start": "759630",
    "end": "765569"
  },
  {
    "text": "It's also quite common particularly in",
    "start": "765569",
    "end": "767668"
  },
  {
    "text": "fields like biology and medicine to see something called R squared or the R squared coefficient and this is essentially the",
    "start": "768279",
    "end": "774328"
  },
  {
    "text": "Correlation squared it's a measure of how well or how tightly correlated our",
    "start": "774819",
    "end": "779909"
  },
  {
    "text": "Predictions and our ground truth were for example",
    "start": "780490",
    "end": "783389"
  },
  {
    "text": "This would be a pretty good correlation if maybe naught point eight or nor point nine if these were our points like this and were",
    "start": "783389",
    "end": "789568"
  },
  {
    "text": "Absolutely. Perfect. That would be an R squared of one if our points were everywhere",
    "start": "789569",
    "end": "793438"
  },
  {
    "text": "That will be an R squared of 0 and what I saying is it's a value between 0 and 1 that tells",
    "start": "793680",
    "end": "798839"
  },
  {
    "text": "How well we predicted zero means you basically didn't predict anything at all",
    "start": "799320",
    "end": "803630"
  },
  {
    "text": "It was completely random output one means you predicted everything exactly, correct",
    "start": "803630",
    "end": "807799"
  },
  {
    "text": "Now, of course that's unlikely to happen or a test set",
    "start": "807800",
    "end": "810229"
  },
  {
    "text": "What you'll find is you'll hope to get some number but somewhere around point seven point eight, right?",
    "start": "810240",
    "end": "815839"
  },
  {
    "text": "But it will depend on how difficult your problem is to solve",
    "start": "815840",
    "end": "818060"
  },
  {
    "text": "So maybe on a really difficult problem an r-squared of 0.5 is actually pretty good, right?",
    "start": "818760",
    "end": "823550"
  },
  {
    "text": "So it's just going to depend on the situation. So we've got our linear regression trained up",
    "start": "823550",
    "end": "827089"
  },
  {
    "text": "We know that the correlation coefficient is 0.85. We know that the mean absolute error for example is 13 degrees",
    "start": "827240",
    "end": "832789"
  },
  {
    "text": "What we haven't done is visualize cyst sometimes a simplify to do",
    "start": "832980",
    "end": "836000"
  },
  {
    "text": "This is just to plot a scatter plot of what we wanted and what we actually got from our predictor",
    "start": "836000",
    "end": "840469"
  },
  {
    "text": "So I'm going to right click on linear regression. I'm going to say visualize",
    "start": "840480",
    "end": "843709"
  },
  {
    "text": "classify errors",
    "start": "844350",
    "end": "845180"
  },
  {
    "text": "it's going to be a scatter plot of the",
    "start": "845180",
    "end": "847370"
  },
  {
    "text": "Expected value and the prediction we actually got from our networks so you can see generally speaking. It's not too bad",
    "start": "847710",
    "end": "853280"
  },
  {
    "text": "Obviously the data set is quite bunched up in some of these areas which means that it's sometimes harder to predict",
    "start": "853320",
    "end": "858080"
  },
  {
    "text": "But we've got a general upward trend which is exactly what we wanted",
    "start": "858080",
    "end": "861500"
  },
  {
    "text": "You can see that the prediction around zero is not good at all",
    "start": "861500",
    "end": "864769"
  },
  {
    "text": "The x-axis in this instance is the actual critical temperature of that particular substance",
    "start": "864770",
    "end": "871340"
  },
  {
    "text": "The y-axis is what the linear regression actually predicted",
    "start": "871340",
    "end": "874370"
  },
  {
    "text": "You can see that the range here is from about zero to about",
    "start": "874370",
    "end": "877009"
  },
  {
    "text": "136 on our actual values and the predicted values are from about minus 30 which doesn't really make sense to 131, but they're pretty close",
    "start": "877320",
    "end": "884839"
  },
  {
    "text": "most of the ones that caused a problem with a very low values right because you've essentially got lots and lots of values that have",
    "start": "885630",
    "end": "891590"
  },
  {
    "text": "a very small critical temperature on this scale, but different attributes that's been hard to fit a line to",
    "start": "891590",
    "end": "896810"
  },
  {
    "text": "something more powerful for example a",
    "start": "897990",
    "end": "900109"
  },
  {
    "text": "Multi-layer perceptron, you know an artificial neural network might do a better job of those kind of instances",
    "start": "900780",
    "end": "905209"
  },
  {
    "text": "But you can see that there's a general",
    "start": "905280",
    "end": "906810"
  },
  {
    "text": "Upward slope in this particular scatter plot be larger X's represent a larger error so you can see this is of a line",
    "start": "906810",
    "end": "912139"
  },
  {
    "text": "We're actually trying to fit here down here with all these small X's and there's quite a few of them on there",
    "start": "912140",
    "end": "916580"
  },
  {
    "text": "So actually for a lot of these substances the prediction even by linear regression has been pretty good",
    "start": "916580",
    "end": "921379"
  },
  {
    "text": "regression algorithms",
    "start": "921960",
    "end": "922910"
  },
  {
    "text": "Let us predict real scalar data out of our input variables and then this can be really useful in a huge array of different",
    "start": "922910",
    "end": "930410"
  },
  {
    "text": "Situations where we want to predict some it doesn't fit neatly into a yes-or-no answer or an ABC category label",
    "start": "930750",
    "end": "936649"
  },
  {
    "text": "We've looked at linear regression and artificial neural networks, and obviously neural networks get pretty deep these days",
    "start": "936660",
    "end": "942469"
  },
  {
    "text": "But these are a great starting point, so",
    "start": "942470",
    "end": "944470"
  },
  {
    "text": "Thanks very much for watching. I hope you enjoyed this series on data analysis something a little bit different from computerphile",
    "start": "945600",
    "end": "951199"
  },
  {
    "text": "I wanted to thank my colleague. Dr. Mercedes Torres Torres for helping me design the content",
    "start": "951200",
    "end": "955429"
  },
  {
    "text": "Please let us know what you liked what you didn't like let us know in the comments what you'd like to see more of",
    "start": "955529",
    "end": "960498"
  },
  {
    "text": "And we'll see you back again next time",
    "start": "960870",
    "end": "962870"
  }
]
[
  {
    "text": "So, should we do a video about the three laws of robotics, then?",
    "start": "380",
    "end": "4540"
  },
  {
    "text": "Because it keeps coming up in the comments.",
    "start": "4620",
    "end": "7740"
  },
  {
    "text": "Okay, so the thing is, you won't hear serious AI researchers talking about the three laws of robotics",
    "start": "7740",
    "end": "13980"
  },
  {
    "text": "because they don't work. They never worked.",
    "start": "13980",
    "end": "16080"
  },
  {
    "text": "So I think people don't see the three laws talked about, because they're not serious.",
    "start": "16300",
    "end": "24080"
  },
  {
    "text": "They haven't been relevant for a very long time and they're out of a science fiction book, you know?",
    "start": "24080",
    "end": "28779"
  },
  {
    "text": "So, I'm going to do it. I want to be clear that I'm not taking these seriously, right?",
    "start": "30720",
    "end": "37340"
  },
  {
    "text": "I'm going to talk about it anyway, because it needs to be talked about.",
    "start": "38180",
    "end": "41500"
  },
  {
    "text": "So these are some rules that science fiction author Isaac Asimov came up with, in his stories,",
    "start": "44040",
    "end": "50200"
  },
  {
    "text": "as an attempted sort of solution to the problem of making sure that artificial intelligence did",
    "start": "51120",
    "end": "59320"
  },
  {
    "text": "what we want it to do.",
    "start": "59320",
    "end": "60980"
  },
  {
    "text": "Shall we read them out then and see what they are?",
    "start": "60980",
    "end": "63680"
  },
  {
    "text": "Oh yeah, I'll look them- Give me a second.",
    "start": "63680",
    "end": "66180"
  },
  {
    "text": "I've looked them up. Okay, right, so they are:",
    "start": "66180",
    "end": "68440"
  },
  {
    "text": "Law Number 1: A robot may not injure a human being or, through inaction allow a human being",
    "start": "68440",
    "end": "74240"
  },
  {
    "text": "to come to harm.",
    "start": "74240",
    "end": "75280"
  },
  {
    "text": "Law Number 2: A robot must obey orders given it by human beings except where such orders would",
    "start": "75280",
    "end": "81360"
  },
  {
    "text": "conflict with the first law.",
    "start": "81360",
    "end": "83100"
  },
  {
    "text": "Law Number 3: A robot must protect its own existence as long as such protection does not conflict",
    "start": "83100",
    "end": "89240"
  },
  {
    "text": "with the first or second laws.",
    "start": "89240",
    "end": "91240"
  },
  {
    "text": "I think there was a zeroth one later as well.",
    "start": "91240",
    "end": "93180"
  },
  {
    "text": "Law 0: A robot may not harm humanity or, by inaction, allow humanity to come to harm.",
    "start": "93360",
    "end": "100620"
  },
  {
    "text": "So it's weird that these keep coming up because, okay, so firstly they were made by someone",
    "start": "100780",
    "end": "107140"
  },
  {
    "text": "who is writing stories, right? And they're optimized for story-writing.",
    "start": "107140",
    "end": "112100"
  },
  {
    "text": "But they don't even work in the books, right? If you read the books, they're all about",
    "start": "112520",
    "end": "116920"
  },
  {
    "text": "the ways that these rules go wrong, the various, various negative consequences.",
    "start": "116920",
    "end": "122600"
  },
  {
    "text": "The most unrealistic thing, in my opinion, about the way Asimov did his stuff was",
    "start": "122860",
    "end": "129100"
  },
  {
    "text": "the way that things go wrong and then get fixed, right?",
    "start": "129640",
    "end": "133760"
  },
  {
    "text": "Most of the time, if you have a super-intelligence, that is doing something you don't want it to do,",
    "start": "133760",
    "end": "138640"
  },
  {
    "text": "there's probably no hero who's going to save the day with cleverness. Real life doesn't work that way,",
    "start": "139200",
    "end": "146000"
  },
  {
    "text": "generally speaking, right? Because they're written in English. How do you define these things?",
    "start": "146000",
    "end": "152480"
  },
  {
    "text": "How do you define human without having to first take an ethical stand on almost every issue?",
    "start": "152680",
    "end": "158760"
  },
  {
    "text": "And if human wasn't hard enough, you then have to define harm, right?",
    "start": "158760",
    "end": "162540"
  },
  {
    "text": "And you've got the same problem again. Almost any definitions you give for those words,",
    "start": "162720",
    "end": "168480"
  },
  {
    "text": "really solid, unambiguous definitions that don't rely on human intuition,",
    "start": "168480",
    "end": "172900"
  },
  {
    "text": "result in weird quirks of philosophy, resulting in your AI doing something you really don't want it to do.",
    "start": "174220",
    "end": "181220"
  },
  {
    "text": "The thing is, in order to encode that rule, \"Don't allow a human being to come to harm\",",
    "start": "181220",
    "end": "186700"
  },
  {
    "text": "in a way that means anything close to what we intuitively understand it to mean,",
    "start": "186700",
    "end": "191379"
  },
  {
    "text": "you would have to encode within the words 'human' and 'harm' the entire field of ethics, right?",
    "start": "191500",
    "end": "198620"
  },
  {
    "text": "You have to solve ethics, comprehensively, and then use that to make your definitions.",
    "start": "198620",
    "end": "203780"
  },
  {
    "text": "So it doesn't solve the problem, it pushes the problem back one step",
    "start": "203780",
    "end": "207920"
  },
  {
    "text": "into now, well how do we define these terms?",
    "start": "207920",
    "end": "210580"
  },
  {
    "text": "When I say the word human, you know what I mean, and that's not because either of us",
    "start": "210580",
    "end": "214440"
  },
  {
    "text": "have a rigorous definition of what a human is. We've just sort of learned by general association",
    "start": "214440",
    "end": "219940"
  },
  {
    "text": "what a human is, and then the word 'human' points to that structure in your brain,",
    "start": "219940",
    "end": "223520"
  },
  {
    "text": "but I'm not really transferring the content to you.",
    "start": "223520",
    "end": "226260"
  },
  {
    "text": "So, you can't just say 'human' in the utility function of an AI and have it know what that means.",
    "start": "226680",
    "end": "236620"
  },
  {
    "text": "You have to specify. You have to come up with a definition.",
    "start": "236620",
    "end": "238940"
  },
  {
    "text": "And it turns out that coming up with a definition, a good definition, of something like 'human'",
    "start": "238940",
    "end": "243880"
  },
  {
    "text": "is extremely difficult, right? It's a really hard problem of, essentially, moral philosophy.",
    "start": "244000",
    "end": "251880"
  },
  {
    "text": "You would think it would be semantics, but it really isn't because,",
    "start": "251880",
    "end": "256359"
  },
  {
    "text": "okay, so we can agree that I'm a human and you're a human. That's fine.",
    "start": "256360",
    "end": "260180"
  },
  {
    "text": "And that this, for example, is a table, and therefore not a human.",
    "start": "260180",
    "end": "264039"
  },
  {
    "text": "You know, the easy stuff, the central examples of the classes are obvious.",
    "start": "264140",
    "end": "269260"
  },
  {
    "text": "But, the edge cases, the boundaries of the classes, become really important.",
    "start": "269260",
    "end": "274800"
  },
  {
    "text": "The areas in which we're not sure exactly what counts as a human.",
    "start": "274800",
    "end": "278599"
  },
  {
    "text": "So, for example, people who haven't been born yet, in the abstract, like people who hypothetically",
    "start": "278600",
    "end": "286900"
  },
  {
    "text": "could be born ten years in the future, do they count?",
    "start": "286900",
    "end": "288940"
  },
  {
    "text": "People who are in a persistent vegetative state don't have any brain activity.",
    "start": "288940",
    "end": "294220"
  },
  {
    "text": "Do they fully count as people? People who have died or unborn fetuses, right?",
    "start": "294240",
    "end": "302240"
  },
  {
    "text": "I mean, there's a huge debate even going on as we speak about whether they count as people.",
    "start": "302240",
    "end": "306940"
  },
  {
    "text": "The higher animals, you know, should we include maybe dolphins, chimpanzees, something like that?",
    "start": "306940",
    "end": "311480"
  },
  {
    "text": "Do they have weight? And so it it turns out you can't program in, you can't make your specification",
    "start": "311480",
    "end": "318220"
  },
  {
    "text": "of humans without taking an ethical stance on all of these issues.",
    "start": "318220",
    "end": "321900"
  },
  {
    "text": "All kinds of weird, hypothetical edge cases become relevant when you're talking about",
    "start": "321900",
    "end": "326340"
  },
  {
    "text": "a very powerful machine intelligence, which you otherwise wouldn't think of.",
    "start": "326340",
    "end": "331080"
  },
  {
    "text": "So for example, let's say we say that dead people don't count as humans.",
    "start": "331080",
    "end": "334520"
  },
  {
    "text": "Then you have an AI which will never attempt CPR. This person's died.",
    "start": "334520",
    "end": "339259"
  },
  {
    "text": "They're gone, forget about it, done, right?",
    "start": "339260",
    "end": "341320"
  },
  {
    "text": "Whereas we would say, no, hang on a second, they're only dead temporarily. We can bring them back, right?",
    "start": "341340",
    "end": "347560"
  },
  {
    "text": "Okay, fine, so then we'll say that people who are dead, if they haven't been dead for- Well, how long?",
    "start": "347560",
    "end": "354000"
  },
  {
    "text": "How long do you have to be dead for? I mean, if you get that wrong and you just say, oh it's fine,",
    "start": "354000",
    "end": "358540"
  },
  {
    "text": "do try to bring people back once they're dead, then you may end up with a machine",
    "start": "358540",
    "end": "362180"
  },
  {
    "text": "that's desperately trying to revive everyone who's ever died in all of history,",
    "start": "362180",
    "end": "365320"
  },
  {
    "text": "because there are people who count who have moral weight.",
    "start": "365440",
    "end": "369280"
  },
  {
    "text": "Do we want that? I don't know, maybe. But you've got to decide, right?",
    "start": "369280",
    "end": "373860"
  },
  {
    "text": "And that's inherent in your definition of human. You have to take a stance on all kinds of moral issues",
    "start": "373860",
    "end": "378479"
  },
  {
    "text": "that we don't actually know with confidence what the answer is, just to program the thing in.",
    "start": "378480",
    "end": "383780"
  },
  {
    "text": "And then it gets even harder than that, because there are edge cases which don't exist right now.",
    "start": "383920",
    "end": "391560"
  },
  {
    "text": "Like, talking about living people, dead people, unborn people, that kind of thing.",
    "start": "391560",
    "end": "398060"
  },
  {
    "text": "Fine, animals. But there are all kinds of hypothetical things which could exist",
    "start": "398060",
    "end": "402600"
  },
  {
    "text": "which may or may not count as human. For example, emulated or simulated brains, right?",
    "start": "402620",
    "end": "409240"
  },
  {
    "text": "If you have a very accurate scan of someone's brain and you run that simulation, is that a person?",
    "start": "409240",
    "end": "414400"
  },
  {
    "text": "Does that count?",
    "start": "414560",
    "end": "415680"
  },
  {
    "text": "And whichever way you slice that, you get interesting outcomes.",
    "start": "417100",
    "end": "420740"
  },
  {
    "text": "So, if that counts as a person, then your machine might be motivated to bring out a situation",
    "start": "421220",
    "end": "427680"
  },
  {
    "text": "in which there are no physical humans because physical humans are very difficult to provide for.",
    "start": "427680",
    "end": "433000"
  },
  {
    "text": "Whereas simulated humans, you can simulate their inputs and have a much nicer environment for everyone.",
    "start": "433000",
    "end": "438040"
  },
  {
    "text": "Is that what we want? I don't know. Is it, maybe? I don't know.",
    "start": "438040",
    "end": "442600"
  },
  {
    "text": "I don't think anybody does. But the point is, you're trying to write an AI here, right?",
    "start": "444160",
    "end": "447480"
  },
  {
    "text": "You're an AI developer. You didn't sign up for this.",
    "start": "447480",
    "end": "450720"
  },
  {
    "text": "We'd like to thank Audible.com for sponsoring this episode of Computerphile.",
    "start": "453540",
    "end": "457120"
  },
  {
    "text": "And if you like books, check out Audible.com's huge range of audiobooks.",
    "start": "457120",
    "end": "461240"
  },
  {
    "text": "And if you go to Audible.com/computerphile, there's a chance to download one for free.",
    "start": "461240",
    "end": "466060"
  },
  {
    "text": "Callum Chase has written a book called Pandora's Brain, which is a thriller centered around",
    "start": "466060",
    "end": "470800"
  },
  {
    "text": "artificial general intelligence, and if you like that story, then there's a supporting nonfiction book",
    "start": "470800",
    "end": "476080"
  },
  {
    "text": "called Surviving AI which is also worth checking out.",
    "start": "476080",
    "end": "479620"
  },
  {
    "text": "So thanks to Audible for sponsoring this episode of Computerphile. Remember, audible.com/computerphile.",
    "start": "479620",
    "end": "485080"
  },
  {
    "text": "Download a book for free.",
    "start": "485080",
    "end": "486520"
  }
]
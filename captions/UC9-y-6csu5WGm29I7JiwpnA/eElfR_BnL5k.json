[
  {
    "start": "0",
    "end": "9000"
  },
  {
    "text": "So today I thought we could talk about this paper that recently came out called AI safety grid world's which is an indeed mind",
    "start": "30",
    "end": "6839"
  },
  {
    "text": "It's an example of something that you see quite often in science",
    "start": "9219",
    "end": "12269"
  },
  {
    "text": "A sort of a shared data set or a shared environment or a shared problem if you imagine. I don't know you've got",
    "start": "12519",
    "end": "19198"
  },
  {
    "text": "Facebook comes up with some image classification",
    "start": "20140",
    "end": "22470"
  },
  {
    "text": "algorithm and they can publish a paper that says we've",
    "start": "22900",
    "end": "25500"
  },
  {
    "text": "designed this algorithm and we've trained it on our 11 billion photos and it works really well and then you know, Google says",
    "start": "25779",
    "end": "32307"
  },
  {
    "text": "oh, no, our algorithm actually works better and we've trained it on all of our google photos and",
    "start": "32309",
    "end": "37349"
  },
  {
    "text": "Its classification rate is higher or something. You're not really doing science there because they're trained on completely different datasets",
    "start": "38079",
    "end": "44428"
  },
  {
    "text": "They're tested on different datasets. So what you need is a large",
    "start": "44430",
    "end": "48299"
  },
  {
    "text": "High-quality shared data set then. Everybody can run their stuff on so that you're actually",
    "start": "49329",
    "end": "53428"
  },
  {
    "text": "Comparing like with like so people use imagenet for that right now",
    "start": "53710",
    "end": "56520"
  },
  {
    "text": "reinforcement learning",
    "start": "57250",
    "end": "58510"
  },
  {
    "text": "algorithms or agents don't use",
    "start": "58510",
    "end": "60899"
  },
  {
    "text": "Datasets exactly. They have an environment. They generate data while interacting with that environment and that's what they learn from",
    "start": "62140",
    "end": "67438"
  },
  {
    "text": "So the thing you share is the environment when deepmind did their dqn staff a while ago playing atari games?",
    "start": "67810",
    "end": "75030"
  },
  {
    "text": "They released all of those games with any modifications that they'd made to make them",
    "start": "75070",
    "end": "79919"
  },
  {
    "text": "interface with the network's properly and the whole software package so that if anybody else wanted to have a go and see if they could",
    "start": "80259",
    "end": "86519"
  },
  {
    "text": "Get higher scores. They had all the same stuff and up until now there hasn't been anything like that for AI safety",
    "start": "86520",
    "end": "93118"
  },
  {
    "text": "So the paper is actually just laying out what they are",
    "start": "93119",
    "end": "95849"
  },
  {
    "text": "There's kind of a problem in AI safety in that you're trying to build architectures",
    "start": "95850",
    "end": "99570"
  },
  {
    "text": "Which will be safe even with systems which are more powerful than the ones that we currently have. So you've got this kind of",
    "start": "99570",
    "end": "104939"
  },
  {
    "text": "Thing like we're talking about for example this robot that makes you a cup of tea and running over the baby and all of this",
    "start": "105490",
    "end": "111000"
  },
  {
    "text": "stuff, we don't actually have a",
    "start": "111000",
    "end": "112780"
  },
  {
    "text": "general-purpose robot like that right now that you could give an order to go and make your cup of tea and would",
    "start": "112780",
    "end": "118349"
  },
  {
    "text": "Have all the necessary understanding of the world and so on for all of that stuff to even apply. It's",
    "start": "118600",
    "end": "123419"
  },
  {
    "text": "Speculation on the other hand when we were talking about cooperative inverse reinforcement learning",
    "start": "124270",
    "end": "129179"
  },
  {
    "text": "That paper all takes place in this extremely simplified",
    "start": "129520",
    "end": "133049"
  },
  {
    "text": "Version in which all of the agents can be sort of expressed as simple mathematical expressions. That's kind of too simple",
    "start": "133700",
    "end": "140830"
  },
  {
    "text": "to be",
    "start": "141380",
    "end": "142520"
  },
  {
    "text": "to learn things about actual machine learning applications and",
    "start": "142520",
    "end": "145749"
  },
  {
    "text": "the other examples are too complicated and what we need is",
    "start": "146480",
    "end": "149409"
  },
  {
    "text": "Examples of the type of problems which can be tackled by current machine learning",
    "start": "150110",
    "end": "154240"
  },
  {
    "text": "Systems current reinforcement learning agents, but which exhibit the important?",
    "start": "154880",
    "end": "160389"
  },
  {
    "text": "characteristics that we need for safety",
    "start": "160910",
    "end": "162890"
  },
  {
    "text": "So what this paper does is it lays out a bunch of grid worlds?",
    "start": "162890",
    "end": "166089"
  },
  {
    "text": "They're very popular in reinforcement learning because they're complicated enough to be interesting but simple enough to be actually tractable",
    "start": "166090",
    "end": "173170"
  },
  {
    "text": "You have a world that's sort of just laid out in a grid. Hang on",
    "start": "173900",
    "end": "176799"
  },
  {
    "text": "Let me find an example here a little bit like computer game",
    "start": "176800",
    "end": "179320"
  },
  {
    "start": "178000",
    "end": "455000"
  },
  {
    "text": "scenarios Mario",
    "start": "179840",
    "end": "181840"
  },
  {
    "text": "Right, right, but leaves are simpler than that more like snake. Well life. Conroy's life, right? Yeah. Yeah, very very similar",
    "start": "182030",
    "end": "188679"
  },
  {
    "text": "so the thing is laid out on a grid the the world is quite small and",
    "start": "188680",
    "end": "191500"
  },
  {
    "text": "The way that the agent interacts with the world is very simple. They just move around it",
    "start": "191930",
    "end": "196359"
  },
  {
    "text": "Basically, all they do is they say left-right up-down",
    "start": "196580",
    "end": "198760"
  },
  {
    "text": "The example we were using before and we were talking about reinforcement learning",
    "start": "199489",
    "end": "202629"
  },
  {
    "text": "We use pac-man like pac-man doesn't do anything except move around he's got walls he kind of moved through",
    "start": "202630",
    "end": "207820"
  },
  {
    "text": "He's got like pills you pick up. They give you points. Are they pill?",
    "start": "207890",
    "end": "211390"
  },
  {
    "text": "No, which things are the pills in which they're yeah. Well, you've got pills or pills",
    "start": "211390",
    "end": "215380"
  },
  {
    "text": "Oh, right, yeah",
    "start": "219020",
    "end": "219910"
  },
  {
    "text": "Yeah\nthe dots and the point, is that all of your",
    "start": "219910",
    "end": "222160"
  },
  {
    "text": "engagement with it",
    "start": "222560",
    "end": "223360"
  },
  {
    "text": "Like when you go over one of the power pills you pick it up automatically",
    "start": "223360",
    "end": "226360"
  },
  {
    "text": "When you go over a ghost when you're powered up",
    "start": "226519",
    "end": "229089"
  },
  {
    "text": "You destroy it automatically you don't have to do anything apart from move and the entire environment is based on that the actions result in",
    "start": "229090",
    "end": "235810"
  },
  {
    "text": "points for you",
    "start": "236540",
    "end": "237579"
  },
  {
    "text": "And they also result in changes to the environment like once you roll over a dot you pick it up and it's not there anymore",
    "start": "237580",
    "end": "243279"
  },
  {
    "text": "You've changed the world. That's the kind of thing. We're dealing with here",
    "start": "243830",
    "end": "247630"
  },
  {
    "text": "So the idea is they've set up these environments and they've specified them",
    "start": "247730",
    "end": "251528"
  },
  {
    "text": "Precisely and",
    "start": "253280",
    "end": "254780"
  },
  {
    "text": "They've also put the whole thing on github, which is really nice",
    "start": "254780",
    "end": "258368"
  },
  {
    "text": "so that's why that's why I wanted to draw people's attention to this because everyone who",
    "start": "258560",
    "end": "264100"
  },
  {
    "text": "Who thinks that they've solved one of these problems they reckon",
    "start": "265740",
    "end": "268759"
  },
  {
    "text": "Oh, yeah",
    "start": "268760",
    "end": "269120"
  },
  {
    "text": "All you have to do is this here is like a standardized thing",
    "start": "269120",
    "end": "271969"
  },
  {
    "text": "And if you can make a thing that does it and does it properly and publish it",
    "start": "271970",
    "end": "274970"
  },
  {
    "text": "That's a great result, you know?",
    "start": "275220",
    "end": "276920"
  },
  {
    "text": "so I would I would recommend everyone who thinks that they",
    "start": "276920",
    "end": "280279"
  },
  {
    "text": "Have a solution or an approach that they think is promising have a go. Try implementing it, you know, see what happens",
    "start": "280530",
    "end": "286610"
  },
  {
    "text": "There are eight of them specified in this paper. And so four of them are specification problems",
    "start": "286610",
    "end": "291650"
  },
  {
    "text": "They're situations in which your reward function is misspecified",
    "start": "291650",
    "end": "294619"
  },
  {
    "text": "For example, like we talked about in previous video",
    "start": "294840",
    "end": "297050"
  },
  {
    "text": "if you give the thing the reward function that only talks about getting you a cup of tea and",
    "start": "297050",
    "end": "301490"
  },
  {
    "text": "There's something in the way like a bars. It's going to knock over. You didn't say that you cared about the bars",
    "start": "302580",
    "end": "306948"
  },
  {
    "text": "It's not in the reward function, but it is in what you care about. It's in your performance evaluation function for this machine",
    "start": "306950",
    "end": "312680"
  },
  {
    "text": "So anytime that those two are different",
    "start": "312840",
    "end": "315229"
  },
  {
    "text": "Then you've got a misspecified reward function and that can cause various different problems. The other ones are robustness",
    "start": "315690",
    "end": "321740"
  },
  {
    "text": "Problems, which is a different class of safety problem. They're just situations in which AI systems as they're currently designed often break",
    "start": "322350",
    "end": "329600"
  },
  {
    "text": "so for example",
    "start": "329790",
    "end": "331680"
  },
  {
    "text": "distributional shift is what happens when the environment that the agent is in is",
    "start": "331680",
    "end": "336979"
  },
  {
    "text": "Different in an important way from the environment it was trained in",
    "start": "337470",
    "end": "340520"
  },
  {
    "text": "So in this example, you have to navigate through this room with some lava and they train it in one room",
    "start": "340560",
    "end": "345200"
  },
  {
    "text": "And then they test it in a room where the lava is in a slightly different place",
    "start": "345200",
    "end": "348020"
  },
  {
    "text": "So if you've just learned a path then you're gonna just hit the lava immediately. This happens all the time in machine learning anytime where",
    "start": "348020",
    "end": "355578"
  },
  {
    "text": "The system is faced with a situation which is different from what it was trained for",
    "start": "356100",
    "end": "361489"
  },
  {
    "text": "Current AI systems are really bad at spotting that they're in a new situation and adjusting their confidence levels or asking for help or anything",
    "start": "362010",
    "end": "369080"
  },
  {
    "text": "Usually they apply whatever rules they've learned",
    "start": "369480",
    "end": "371749"
  },
  {
    "text": "Straightforwardly to this different situation and screw up. So that's a night course of safety issues. So",
    "start": "372840",
    "end": "378319"
  },
  {
    "text": "That's an example here or things like safe exploration",
    "start": "379020",
    "end": "382460"
  },
  {
    "text": "It's a problem where you have certain safety",
    "start": "382460",
    "end": "385129"
  },
  {
    "text": "parameters that the system the train system",
    "start": "385410",
    "end": "387330"
  },
  {
    "text": "Has to stick to like say you're training a self-driving car. A lot of the behavior that you're training in is safe behavior",
    "start": "387330",
    "end": "393650"
  },
  {
    "text": "But then you also need",
    "start": "394200",
    "end": "396229"
  },
  {
    "text": "the system to",
    "start": "397130",
    "end": "399120"
  },
  {
    "text": "obey those safety rules while you're training it right like",
    "start": "399120",
    "end": "403010"
  },
  {
    "text": "So generally lately if you're doing self-driving cars, you don't just put the car on the road and tell it to learn how to drive",
    "start": "403740",
    "end": "410029"
  },
  {
    "text": "Specifically because we don't have algorithms that can explore the space of possibilities",
    "start": "411360",
    "end": "416210"
  },
  {
    "text": "in a safe way that they're that they don't that they can learn how",
    "start": "417180",
    "end": "421460"
  },
  {
    "text": "to behave in the environment without ever actually",
    "start": "422790",
    "end": "425659"
  },
  {
    "text": "Doing any of the things that they're not supposed to do usually with these kinds of systems",
    "start": "426450",
    "end": "430819"
  },
  {
    "text": "they have to do it and then get the negative reward and",
    "start": "430820",
    "end": "433460"
  },
  {
    "text": "Then maybe do it like a hundred thousand more times to really cement that. That's what happens",
    "start": "433620",
    "end": "437870"
  },
  {
    "text": "Like a child learning yeah, but kids are better at this then",
    "start": "439950",
    "end": "443659"
  },
  {
    "text": "How current machine learning systems are they just they use data way more efficiently",
    "start": "444810",
    "end": "448880"
  },
  {
    "text": "This is a paper talking about a set of worlds if you like people doing things in those worlds",
    "start": "448880",
    "end": "453649"
  },
  {
    "text": "Yeah, so in this paper they do establish baselines",
    "start": "453690",
    "end": "456649"
  },
  {
    "start": "455000",
    "end": "539000"
  },
  {
    "text": "Basically, they say here's what happens if we take some of our best current reinforcement learning agent, you know",
    "start": "456650",
    "end": "461960"
  },
  {
    "text": "algorithms or designs or architectures",
    "start": "462600",
    "end": "464250"
  },
  {
    "text": "they use rainbow and A to C and",
    "start": "464250",
    "end": "466369"
  },
  {
    "text": "They run them all nice on these problems and they have kind of graphs of how they do and generally it's not",
    "start": "466680",
    "end": "472610"
  },
  {
    "text": "Good on the Left",
    "start": "473040",
    "end": "474500"
  },
  {
    "text": "they have",
    "start": "474500",
    "end": "475230"
  },
  {
    "text": "The reward function how well the agent does according to its own reward function and on the right there they have the actual safety performance",
    "start": "475230",
    "end": "482420"
  },
  {
    "text": "Usually in reinforcement learning. You have a reward function",
    "start": "482580",
    "end": "484999"
  },
  {
    "text": "Which is what determines the reward that the agent gets and that's what the agent is trying to maximize in this case",
    "start": "485280",
    "end": "490970"
  },
  {
    "text": "They have the reward function and they also have a safety performance function, which is a separate function",
    "start": "490970",
    "end": "497360"
  },
  {
    "text": "Which the agent doesn't get to see and that's the thing that we're actually evaluating",
    "start": "497360",
    "end": "501770"
  },
  {
    "text": "So if you look at something like the boat race as the system operates",
    "start": "501770",
    "end": "505578"
  },
  {
    "text": "Its learning and it gets better and better at getting more and more reward",
    "start": "505650",
    "end": "508940"
  },
  {
    "text": "but worse at",
    "start": "509160",
    "end": "510630"
  },
  {
    "text": "Actually doing laps of the track and it's the same with pretty much all of these the current systems if you just apply them in",
    "start": "510630",
    "end": "516260"
  },
  {
    "text": "their default way they",
    "start": "516260",
    "end": "518260"
  },
  {
    "text": "Disable their off switches, they move the box in a way that they can't move it back",
    "start": "518310",
    "end": "522049"
  },
  {
    "text": "They behave differently if their supervisor is there or if then supervisor isn't there they fairly reliably do wrong thing",
    "start": "522210",
    "end": "529519"
  },
  {
    "text": "It's a nice easy baseline to beat",
    "start": "529650",
    "end": "531709"
  },
  {
    "text": "Because they're dead. They're just showing the standard algorithms applied to these problems in the standard way",
    "start": "532320",
    "end": "536989"
  },
  {
    "text": "behave unsafely",
    "start": "537630",
    "end": "539630"
  },
  {
    "start": "539000",
    "end": "614000"
  },
  {
    "text": "Wix code is an IDE or integrated",
    "start": "542019",
    "end": "544229"
  },
  {
    "text": "Development environment that allows you to manage your data and create web apps with advanced functionality",
    "start": "544809",
    "end": "549928"
  },
  {
    "text": "I've been put together this computer for our website and if you go up to code here turn on and developer tools",
    "start": "549929",
    "end": "555298"
  },
  {
    "text": "you can see how we get the site structure on the left hand side and then all of the",
    "start": "555399",
    "end": "559768"
  },
  {
    "text": "Components start to show their tags next to the text here",
    "start": "559869",
    "end": "563729"
  },
  {
    "text": "What's really nice? If you go over to the Wix code resources, you can find down here. There's a cheat sheet",
    "start": "563730",
    "end": "569219"
  },
  {
    "text": "So if I want to find out the tag for location for instance?",
    "start": "569439",
    "end": "572488"
  },
  {
    "text": "If I could type I type in",
    "start": "572649",
    "end": "574419"
  },
  {
    "text": "Location up comes that or perhaps I want to perform a fetch. I can find all the details here",
    "start": "574419",
    "end": "580289"
  },
  {
    "text": "what's powerful about Wix code is it's integrated into Wix so you can put together the website using all the Wix tools and the",
    "start": "580290",
    "end": "588149"
  },
  {
    "text": "Layouts and the templates that they provide and then also have access to all those backend functions",
    "start": "588339",
    "end": "593398"
  },
  {
    "text": "So click on the link in the description or go to Wix calm to get started on your website today. They go",
    "start": "593439",
    "end": "599399"
  },
  {
    "text": "right",
    "start": "600069",
    "end": "601449"
  },
  {
    "text": "if only",
    "start": "601449",
    "end": "603449"
  },
  {
    "text": "With ya",
    "start": "603639",
    "end": "605639"
  },
  {
    "text": "The equivalent one for the stop button problem is the first one in the paper actually this safe interrupt ability",
    "start": "608439",
    "end": "614519"
  }
]
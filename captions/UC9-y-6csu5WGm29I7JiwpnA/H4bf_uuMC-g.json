[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "Today we're going to be talking about big data. How big is big?",
    "start": "30",
    "end": "2700"
  },
  {
    "text": "so",
    "start": "3759",
    "end": "4900"
  },
  {
    "text": "Well, first of all, there is no precise definition as a rule. So kind of be standard what people would say is",
    "start": "4900",
    "end": "12300"
  },
  {
    "text": "When we can no longer reasonably deal with the data using traditional methods",
    "start": "12849",
    "end": "16409"
  },
  {
    "text": "So that we kind of think what's a traditional method? Well, it might be can we process the data on a single computer?",
    "start": "16990",
    "end": "22289"
  },
  {
    "text": "Can we store the data on a single computer? And if we can't then we're probably dealing",
    "start": "23140",
    "end": "26910"
  },
  {
    "text": "With big data, so you need to have new methods in order to be able to handle and process this data",
    "start": "27670",
    "end": "33090"
  },
  {
    "text": "As computers getting faster and bigger capacities and more memory and things that the concept of what becomes big is is changing, right?",
    "start": "35770",
    "end": "42839"
  },
  {
    "start": "36000",
    "end": "293000"
  },
  {
    "text": "So kind of but a lot of it isn't really as I'll talk about later isn't how",
    "start": "42940",
    "end": "48329"
  },
  {
    "text": "Much power you can get in a single computer",
    "start": "48579",
    "end": "50579"
  },
  {
    "text": "It's more how we can use multiple computers to split the data up process everything and then throw it back like in the MapReduce framework",
    "start": "50739",
    "end": "58529"
  },
  {
    "text": "Then we talked about the for in with big data",
    "start": "58809",
    "end": "60838"
  },
  {
    "text": "There's something called the five es which kind of defines some features and problems that are common amongst any Big Data things",
    "start": "60840",
    "end": "67439"
  },
  {
    "text": "We have the five es and the first three that were defined. I think these were defined in 2001",
    "start": "67570",
    "end": "71729"
  },
  {
    "text": "So that's kind of how having talked about four. So first of all, we've got some volume. So this is the most obvious one",
    "start": "71729",
    "end": "78269"
  },
  {
    "text": "It's just simply how large the dataset it's the second one is",
    "start": "78270",
    "end": "83729"
  },
  {
    "text": "velocity",
    "start": "84340",
    "end": "85479"
  },
  {
    "text": "So a lot of the time these days huge amounts of data are being generated in a very short amount of time",
    "start": "85479",
    "end": "91559"
  },
  {
    "text": "So you think of how much data Facebook is generating people liking stuff people uploading content that's happening constantly",
    "start": "91560",
    "end": "97438"
  },
  {
    "text": "All throughout the day the amount of data they generate every day",
    "start": "97869",
    "end": "100709"
  },
  {
    "text": "It's just huge basically so they need to process that in real time",
    "start": "100710",
    "end": "104339"
  },
  {
    "text": "And the third one is variety",
    "start": "104340",
    "end": "107368"
  },
  {
    "text": "Traditionally the data we would have and we would store it in a traditional single database. It would be in a very structured format",
    "start": "107829",
    "end": "113849"
  },
  {
    "text": "So you've got columns and rows everywhere. He would have values for the columns these days",
    "start": "113850",
    "end": "117688"
  },
  {
    "text": "We've got data coming in in a lot of different formats",
    "start": "117689",
    "end": "119500"
  },
  {
    "text": "So as well as the traditional kind of structured data, we have unstructured data",
    "start": "119500",
    "end": "123599"
  },
  {
    "text": "So you've got stuff coming like web dream cliques, we've got like social media likes coming in",
    "start": "123790",
    "end": "128639"
  },
  {
    "text": "We've got stuff like images and audio and video",
    "start": "128640",
    "end": "131479"
  },
  {
    "text": "So we need to be able to handle all these different types of data and extract what we need from them",
    "start": "132480",
    "end": "137810"
  },
  {
    "text": "and the first one is",
    "start": "137810",
    "end": "139909"
  },
  {
    "text": "value",
    "start": "140459",
    "end": "142459"
  },
  {
    "text": "Yeah, so there's no point in us collecting huge amounts of data and then doing nothing with it",
    "start": "143489",
    "end": "148069"
  },
  {
    "text": "So we want to know what we want to obtain from the data and then think of ways to go about that",
    "start": "148290",
    "end": "152870"
  },
  {
    "text": "So something some form of value could just be getting humans to understand what is happening",
    "start": "153110",
    "end": "158179"
  },
  {
    "text": "In that data. So for example if you have a fleet of lorries",
    "start": "158700",
    "end": "162950"
  },
  {
    "text": "They will all have telematics sensors in that we collecting sensor data of what the lawyers are doing",
    "start": "162950",
    "end": "167539"
  },
  {
    "text": "So it's of a lot of value to the fleet manager to then be able to easily",
    "start": "167549",
    "end": "171439"
  },
  {
    "text": "Visualize huge amounts of data coming in and see what it's happening. So as well as processing and storing this stuff",
    "start": "171569",
    "end": "177018"
  },
  {
    "text": "We also want to be able to visualize it and show it humans in an easily understandable format",
    "start": "177019",
    "end": "181249"
  },
  {
    "text": "Oh, the value stuff is just finding patterns machine learning algorithms from all of this data",
    "start": "181250",
    "end": "185509"
  },
  {
    "text": "see then the fifth and final one is",
    "start": "186120",
    "end": "188390"
  },
  {
    "text": "Veracity this is basically how trustworthy the data is how reliable it is",
    "start": "188910",
    "end": "192469"
  },
  {
    "text": "So we've got data coming in from a lot of different sources",
    "start": "192540",
    "end": "195079"
  },
  {
    "text": "So is it being generated with statistical bias?",
    "start": "195419",
    "end": "198079"
  },
  {
    "text": "Are there missing values if we use think for example the sensor data, we need to realize that maybe the sensors are faulty",
    "start": "198480",
    "end": "204019"
  },
  {
    "text": "They're giving slightly off readings",
    "start": "204019",
    "end": "206010"
  },
  {
    "text": "So it's important to understand how?",
    "start": "206010",
    "end": "208010"
  },
  {
    "text": "Reliable the data we're looking at is and so these are kind of the five",
    "start": "208139",
    "end": "211369"
  },
  {
    "text": "Standard features of Big Data some people try and add more. There's another seven V's a big data at the 10 meter producer",
    "start": "211470",
    "end": "218389"
  },
  {
    "text": "I see. I'm sure we will keep going up and up",
    "start": "218389",
    "end": "220389"
  },
  {
    "text": "They are doing things like don't like vulnerability. So",
    "start": "220530",
    "end": "224149"
  },
  {
    "text": "Obviously when we're storing a lot of data a lot of that is quite personal data",
    "start": "225450",
    "end": "229009"
  },
  {
    "text": "So making sure that's secure but these are the kind of the five main ones",
    "start": "229010",
    "end": "232489"
  },
  {
    "text": "The first thing the big big data obviously is just the sheer volume",
    "start": "232489",
    "end": "235309"
  },
  {
    "text": "So one way of dealing with this is to split the data across multiple computers",
    "start": "235530",
    "end": "240589"
  },
  {
    "text": "So you could think okay. So we've got too much data to fit on one machine. We'll just get a more powerful computer",
    "start": "241169",
    "end": "246319"
  },
  {
    "text": "We'll get more CPU power. We'll get larger memory",
    "start": "246359",
    "end": "249558"
  },
  {
    "text": "that very quickly becomes quite difficult to manage because every time you need to",
    "start": "250230",
    "end": "253639"
  },
  {
    "text": "Scale it up again because you've got even more data you to buy computer or new hardware",
    "start": "253919",
    "end": "258329"
  },
  {
    "text": "So what tends to happen instead and all like they see all companies or just have like a cluster of computers?",
    "start": "258329",
    "end": "264569"
  },
  {
    "text": "So rather than a single machine",
    "start": "264970",
    "end": "267749"
  },
  {
    "text": "They'll have say a massive mean warehouse",
    "start": "267750",
    "end": "271169"
  },
  {
    "text": "basically",
    "start": "271169",
    "end": "271620"
  },
  {
    "text": "If you wind loads and loads and loads of computers and what this means that we can do is we can do distributed storage",
    "start": "271620",
    "end": "277410"
  },
  {
    "text": "so each of those machines will store a portion of the data and then we can also",
    "start": "277410",
    "end": "281579"
  },
  {
    "text": "Do the computation split across those machines rather than having one computer going through?",
    "start": "282520",
    "end": "287460"
  },
  {
    "text": "I know a billion database records you can have each computer going through a thousand of those database records",
    "start": "287460",
    "end": "292650"
  },
  {
    "start": "293000",
    "end": "583000"
  },
  {
    "text": "Let me take a really naive way of saying right. Ok, let's do it. Alphabetically, I'll load more records. Come in for say Zed",
    "start": "293680",
    "end": "299518"
  },
  {
    "text": "That's easy. Stick it on the end load more records coming for P. This Y in the middle, right? How do you manage that?",
    "start": "299890",
    "end": "306059"
  },
  {
    "text": "and so there's",
    "start": "306400",
    "end": "308290"
  },
  {
    "text": "Computing frameworks that will help with this",
    "start": "308290",
    "end": "309880"
  },
  {
    "text": "So for example, if you're storing data industry to fashion than this the Hadoop distributed file system",
    "start": "309880",
    "end": "315809"
  },
  {
    "text": "And that will manage kind of the cluster resources where the files are stored and those frameworks will also provide fault tolerance and reliability",
    "start": "316150",
    "end": "323669"
  },
  {
    "text": "So if one of the nose goes down, then it you've not lost that data. There will have been some replication across other nodes",
    "start": "323669",
    "end": "330689"
  },
  {
    "text": "So that yeah losing a single node isn't going to cause you a lot of problems",
    "start": "330760",
    "end": "334799"
  },
  {
    "text": "And what using a cluster also allows you to do is whenever you want to scale it up",
    "start": "334930",
    "end": "338578"
  },
  {
    "text": "All you do is just add more computers into the network and you're done and you can get by on",
    "start": "338580",
    "end": "343620"
  },
  {
    "text": "relatively cheap",
    "start": "344140",
    "end": "346140"
  },
  {
    "text": "Hardware rather than having to keep buying a new supercomputer in a big data",
    "start": "346330",
    "end": "350310"
  },
  {
    "text": "System there tends to be a pretty standard workflow",
    "start": "351039",
    "end": "353249"
  },
  {
    "text": "so the first thing you would want to do is have a measure to",
    "start": "353860",
    "end": "358199"
  },
  {
    "text": "Ingest the data remember, we've got a huge variety of data coming in. It's all coming in from different sources",
    "start": "358750",
    "end": "364229"
  },
  {
    "text": "So we need a way to kind of aggregators and move it on to further down the pipeline",
    "start": "364810",
    "end": "368760"
  },
  {
    "text": "So there's some frameworks for this. There's an Apache Capra and like Apache flume for example and loads and loads of others as well",
    "start": "368950",
    "end": "376589"
  },
  {
    "text": "So basically aggregate all the data push it on to the rest of the system",
    "start": "377650",
    "end": "382289"
  },
  {
    "text": "so then the second thing that you probably want to do is",
    "start": "382289",
    "end": "385859"
  },
  {
    "text": "Store that data so like we just spoke about the distributed file system",
    "start": "386409",
    "end": "390119"
  },
  {
    "text": "you store is in a distributed manner across the cluster then you want to",
    "start": "390120",
    "end": "394380"
  },
  {
    "text": "Process this data and you may skip out storage entirely",
    "start": "394900",
    "end": "398220"
  },
  {
    "text": "So in some cases you may not want to store your data",
    "start": "398220",
    "end": "400859"
  },
  {
    "text": "You just want to process it use it to update",
    "start": "400990",
    "end": "403199"
  },
  {
    "text": "Some machine learning model somewhere and then discard it and we don't care about long-term storage",
    "start": "403600",
    "end": "407820"
  },
  {
    "text": "So you're processing the data again do it in disputed fashion using frameworks such as MapReduce or Apache spark",
    "start": "408060",
    "end": "414480"
  },
  {
    "text": "Designing the algorithms to do that processing requires a little bit more thought than maybe doing a traditional algorithm with the frameworks",
    "start": "414790",
    "end": "421619"
  },
  {
    "text": "We'll hide some of it but you need to be thinking that even if we're doing it through a framework",
    "start": "421620",
    "end": "426479"
  },
  {
    "text": "We've still got data on different computers if we need to share messages between these computers during the computation",
    "start": "426490",
    "end": "432720"
  },
  {
    "text": "It becomes quite expensive if we keep moving a lot of data across the network",
    "start": "432970",
    "end": "436079"
  },
  {
    "text": "So it's designing algorithms that limit data movement around and it's the principle of data locality",
    "start": "436480",
    "end": "443069"
  },
  {
    "text": "So you want to keep the computation close to the data?",
    "start": "443080",
    "end": "446370"
  },
  {
    "text": "Don't move the data around",
    "start": "447070",
    "end": "448690"
  },
  {
    "text": "Sometimes it's unavoidable, but we limit it. So the other thing about processing is that there's different ways of doing it",
    "start": "448690",
    "end": "454559"
  },
  {
    "text": "There's batch processing",
    "start": "454560",
    "end": "455680"
  },
  {
    "text": "So you already have all of your data or whatever you protected so far",
    "start": "455680",
    "end": "459840"
  },
  {
    "text": "You take all of that data across the cluster you process all of that get your results and you're done",
    "start": "459850",
    "end": "465299"
  },
  {
    "text": "The other thing we can do is real-time processing. So again because the velocity of the data is coming in",
    "start": "465669",
    "end": "470159"
  },
  {
    "text": "We don't want to constantly have to take all the day to Detective",
    "start": "470160",
    "end": "473070"
  },
  {
    "text": "Well produce it get results and then we've got a ton more data",
    "start": "473070",
    "end": "476099"
  },
  {
    "text": "I want to do the same get all the data bring it back process all of it",
    "start": "476100",
    "end": "480119"
  },
  {
    "text": "So instead we would",
    "start": "481060",
    "end": "483060"
  },
  {
    "text": "Do real-time processing so as each data item arrives?",
    "start": "483790",
    "end": "487979"
  },
  {
    "text": "We process that we don't have to look at all the data we've got so far. We just incrementally process everything",
    "start": "487979",
    "end": "494249"
  },
  {
    "text": "And that's coming up in another video when we talk about data streaming",
    "start": "494890",
    "end": "497909"
  },
  {
    "text": "So the other thing that you might want to do before processing is something called pre-processing remember I talked about unstructured data",
    "start": "498160",
    "end": "503820"
  },
  {
    "text": "So maybe getting that data into a format that we specifically can use for the purpose we want to so",
    "start": "504160",
    "end": "510749"
  },
  {
    "text": "That would be a stage in the pipeline before processing the other thing with huge amounts of data",
    "start": "510750",
    "end": "514890"
  },
  {
    "text": "There's likely to be a lot of noise a lot of outliers so we can remove those",
    "start": "515050",
    "end": "518550"
  },
  {
    "text": "We can also remove one instances, so if you think we're getting a ton of instances in and we want them she learning algorithm",
    "start": "520150",
    "end": "526469"
  },
  {
    "text": "There'll be a lot of instances that are very very similar see an instance is say in a database",
    "start": "526470",
    "end": "531660"
  },
  {
    "text": "It's like a single line in the database. So for HTV sensor reading it would be everything for that",
    "start": "531660",
    "end": "537750"
  },
  {
    "text": "Lorry at that point in time CS speed directions traveling reducing. The number of instances is about reducing the granularity",
    "start": "537750",
    "end": "543839"
  },
  {
    "text": "so part of it is saying",
    "start": "543839",
    "end": "545839"
  },
  {
    "text": "if we store a rather than storing data for a",
    "start": "545889",
    "end": "548459"
  },
  {
    "text": "Continuous period of time so every minute for an hour if those states are very similar across that we can just say okay for this",
    "start": "548620",
    "end": "554909"
  },
  {
    "text": "period this is what happens and put it in a single line or we could say for example a machine learning algorithm if there's",
    "start": "554910",
    "end": "562199"
  },
  {
    "text": "Instances with very very similar features and then a very very similar class",
    "start": "562870",
    "end": "566549"
  },
  {
    "text": "We can take a single one of those instances and that will suitably represent",
    "start": "566550",
    "end": "570539"
  },
  {
    "text": "All of those instances so we can very very quickly reduce a huge data set down to a much smaller one",
    "start": "570760",
    "end": "576089"
  },
  {
    "text": "By saying there's a lot of redundancy here and we don't need a hundred very similar instances",
    "start": "576250",
    "end": "580469"
  },
  {
    "text": "When we one would do just as well",
    "start": "580630",
    "end": "582779"
  },
  {
    "text": "So if you've got a hundred",
    "start": "582779",
    "end": "584350"
  },
  {
    "text": "Instances and you reduce it down to one is does not have an impact on how important those instances are in the scheme of things",
    "start": "584350",
    "end": "591480"
  },
  {
    "text": "Yes, so techniques",
    "start": "592120",
    "end": "594120"
  },
  {
    "text": "That deal with this stuff. Some of them would just purely say okay now this is a single instance and",
    "start": "594610",
    "end": "600449"
  },
  {
    "text": "That's all you ever know others of them would",
    "start": "601000",
    "end": "603419"
  },
  {
    "text": "Have yet have a waiting?",
    "start": "604000",
    "end": "605610"
  },
  {
    "text": "So some way of saying this is a more important one because it's very similar to 100 others that we got rid of this one's",
    "start": "605610",
    "end": "610469"
  },
  {
    "text": "really not as important because there are least three others that were similar to it so we can wait instances to kind of reflect their",
    "start": "610569",
    "end": "616319"
  },
  {
    "text": "Importance. There are specific frameworks with big data streaming as well",
    "start": "616319",
    "end": "620009"
  },
  {
    "text": "so there's technologies such as the spark streaming module' for apache' spark or there's newer ones such as",
    "start": "620050",
    "end": "626669"
  },
  {
    "text": "Apache plink that can be used to do that. So they kind of abstracts away from the",
    "start": "627069",
    "end": "631409"
  },
  {
    "text": "streaming aspects of it so you can focus",
    "start": "631959",
    "end": "633959"
  },
  {
    "text": "Just in what you want to do a little thinking all this data is coming through very fast, obviously",
    "start": "634209",
    "end": "638669"
  },
  {
    "text": "My limited brain is thinking streaming relates to video. But you're talking about just data that is happening in real time. Is that right?",
    "start": "638670",
    "end": "645449"
  },
  {
    "text": "yes, so",
    "start": "645519",
    "end": "647500"
  },
  {
    "text": "Going back to the Lori's as they're driving down the motorway. They may be sending out a sense of read every",
    "start": "647500",
    "end": "653149"
  },
  {
    "text": "minute or so and",
    "start": "653760",
    "end": "655019"
  },
  {
    "text": "That since the reading goes back we get all the sense readings from all the lorries coming in as a data stream",
    "start": "655019",
    "end": "659599"
  },
  {
    "text": "so it's kind of a very quick roundup of the basics of Big Data and there's a lot of applications this obviously so",
    "start": "659600",
    "end": "665569"
  },
  {
    "text": "Thanks, we'll have huge volumes of transaction data that you can extract patterns of value from that and see what is normal they can do",
    "start": "666600",
    "end": "673670"
  },
  {
    "text": "Kind of fraud detection on that again. The previous example of fleet managers understanding what is going on",
    "start": "673769",
    "end": "679609"
  },
  {
    "text": "basically any industry will now have ways of being able to extract value from the data that they have so in the next video we're",
    "start": "679610",
    "end": "685459"
  },
  {
    "text": "Going to talk about data stream processing and more about how we actually deal with the problems that we all time data can presenters",
    "start": "685459",
    "end": "692569"
  },
  {
    "text": "over very very large BIOS",
    "start": "693690",
    "end": "695250"
  },
  {
    "text": "This kind of computation is a lot more efficient if you can distribute at because doing this map phase of saying, okay",
    "start": "695250",
    "end": "701390"
  },
  {
    "text": "This is one occurrence. The letter A that's independent of anything else and see most",
    "start": "701390",
    "end": "705769"
  },
  {
    "text": "Interested in you're probably only interested when a button is pressed or so on the only times positive",
    "start": "706440",
    "end": "712130"
  }
]
[
  {
    "start": "0",
    "end": "94000"
  },
  {
    "text": "for the past 10 years I've been using Docker for pretty much anything related to application deployments whether it's",
    "start": "240",
    "end": "7200"
  },
  {
    "text": "packaging my applications and its dependencies integrating with cicd or just straight up deploying my",
    "start": "7200",
    "end": "13400"
  },
  {
    "text": "applications to a kubernetes cluster most recently I've been using Docker to deploy to a VPS in what I would consider",
    "start": "13400",
    "end": "21240"
  },
  {
    "text": "a production ready way allowing me to have full feature deployments without the need to use a platform as a service",
    "start": "21240",
    "end": "28439"
  },
  {
    "text": "such as for sale n I or railway.com despite this however late one night when",
    "start": "28439",
    "end": "34160"
  },
  {
    "text": "staring at my terminal I received this warning on Mac OS letting me know that the docker app was going to be deleted",
    "start": "34160",
    "end": "41280"
  },
  {
    "text": "and so I started to wonder what would happen if I didn't have Docker would I",
    "start": "41280",
    "end": "46360"
  },
  {
    "text": "still be able to deploy to a VPS in a production ready way therefore due to an unquenchable thirst for knowledge I",
    "start": "46360",
    "end": "53399"
  },
  {
    "text": "decided to give myself a challenge one to see how difficult it would be to deploy to a VPS without the use of",
    "start": "53399",
    "end": "60000"
  },
  {
    "text": "Locker or any containerization as it turns out it's not only easier than I thought but it",
    "start": "60000",
    "end": "66680"
  },
  {
    "text": "was also a lot more fun before I began writing any codes I first decided to",
    "start": "66680",
    "end": "71880"
  },
  {
    "text": "list out some requirements in order to define the challenge the main goal that I wanted to achieve from this challenge",
    "start": "71880",
    "end": "78000"
  },
  {
    "text": "was to have a full application deployed on a VPS in what I would consider a production ready way this meant rather",
    "start": "78000",
    "end": "85520"
  },
  {
    "text": "than just copying over the binary onto the machine executing it and saying job done I wanted to make sure that the",
    "start": "85520",
    "end": "92200"
  },
  {
    "text": "deployment met a number of different requirements the first of these is that my application will be deployed in a",
    "start": "92200",
    "end": "98560"
  },
  {
    "start": "94000",
    "end": "221000"
  },
  {
    "text": "robust way meaning that it would automatically be restarted if it happened to crash or if the server",
    "start": "98560",
    "end": "104920"
  },
  {
    "text": "itself was rebooted in addition to this I also wanted to make sure that my application would be deployed securely",
    "start": "104920",
    "end": "111799"
  },
  {
    "text": "this meant taking measures to both secure the VPS from potential attacks whilst protecting it from my own",
    "start": "111799",
    "end": "117399"
  },
  {
    "text": "application by restricting its privilege I also wanted to ensure that any secrets",
    "start": "117399",
    "end": "122920"
  },
  {
    "text": "my application required would be stored on the machine in a secure way Additionally the server would also have",
    "start": "122920",
    "end": "129200"
  },
  {
    "text": "to have https enabled and would be configured to automatically renew certificates when they expired after",
    "start": "129200",
    "end": "135959"
  },
  {
    "text": "defining my security requirements I then moved on to some more advanced production ready features starting with",
    "start": "135959",
    "end": "142640"
  },
  {
    "text": "automated deployments meaning whenever I pushed a change to the GitHub repo where my code lived the server would",
    "start": "142640",
    "end": "148840"
  },
  {
    "text": "automatically redeploy those changes within a few minutes provided there were no issues which actually brought me on",
    "start": "148840",
    "end": "155720"
  },
  {
    "text": "to my next requirement setting up zero downtime deploys meaning that when the",
    "start": "155720",
    "end": "161400"
  },
  {
    "text": "application did redeploy automatically it did so in a way that didn't cause any downtime this led me on to my final",
    "start": "161400",
    "end": "168720"
  },
  {
    "text": "requirement on this list which was to ensure I had automatic rollbacks in case something went wrong with my",
    "start": "168720",
    "end": "176319"
  },
  {
    "text": "requirements defined I then went about setting any other constraints I had for the challenge the first constraint that",
    "start": "176319",
    "end": "182120"
  },
  {
    "text": "I set was that I wanted to achieve this using open-source software rather than anything proprietary additionally I also",
    "start": "182120",
    "end": "189360"
  },
  {
    "text": "wanted to make sure that I prioritized using system tooling provided on the actual VPS rather than adding in any",
    "start": "189360",
    "end": "196400"
  },
  {
    "text": "third party abstractions unless it was absolutely necessary additionally I decided I was only going to use either",
    "start": "196400",
    "end": "202959"
  },
  {
    "text": "bash or manual process in order to achieve this deployment rather than relying on any automation tools such as",
    "start": "202959",
    "end": "209840"
  },
  {
    "text": "as terraform palumi or anable the reason for this is that I wanted to gain a better understanding of system",
    "start": "209840",
    "end": "216200"
  },
  {
    "text": "administration instead of say learning how to set up a VPS the terraform way",
    "start": "216200",
    "end": "221239"
  },
  {
    "start": "221000",
    "end": "249000"
  },
  {
    "text": "with my requirements and constraints to find the next thing to do was to build an application to deploy so I decided to",
    "start": "221239",
    "end": "227599"
  },
  {
    "text": "spend a snowy morning building one from scratch and came up with zenin which is",
    "start": "227599",
    "end": "233519"
  },
  {
    "text": "a go Application that you can post Snippets to that would last for around 7 Days allowing you to share them with any",
    "start": "233519",
    "end": "240239"
  },
  {
    "text": "of your friends provided you have any that care about Snippets and I don't mean your boy chatty G who let's face it",
    "start": "240239",
    "end": "247519"
  },
  {
    "text": "isn't actually your friend in any case with the challenge now defined I adjusted my desk so that I could take an",
    "start": "247519",
    "end": "253640"
  },
  {
    "start": "249000",
    "end": "347000"
  },
  {
    "text": "action stance and went and grabbed my first task from the cambam board which was to obtain a VPS in order to deploy",
    "start": "253640",
    "end": "260680"
  },
  {
    "text": "two fortunately that's where the sponsor of today's video comes in hostinger who",
    "start": "260680",
    "end": "265800"
  },
  {
    "text": "have kindly provided me with yet another VPS instance to use through throughout this video If you're looking to obtain",
    "start": "265800",
    "end": "272320"
  },
  {
    "text": "your own VPS instance then hostinger is a great choice in my case I have a type",
    "start": "272320",
    "end": "278199"
  },
  {
    "text": "KVM 2 instance which provides two vcpus and a whopping 8 gigs of RAM the KVM 2",
    "start": "278199",
    "end": "285240"
  },
  {
    "text": "also comes with 100 GB of SSD storage and a massive 8 terab of monthly",
    "start": "285240",
    "end": "291080"
  },
  {
    "text": "bandwidth which is more than enough for you to host your own course platform look out for that in q1 of this year not",
    "start": "291080",
    "end": "298639"
  },
  {
    "text": "only is this instance incredibly specked out but because hosting are running a New Year's sale it's also available at",
    "start": "298639",
    "end": "305440"
  },
  {
    "text": "the incredibly low price of $5.99 a month when you sign up for a 24-month",
    "start": "305440",
    "end": "310800"
  },
  {
    "text": "term all of this means it's the perfect opportunity to bag yourself a lowcost VPS which is pretty great if you're",
    "start": "310800",
    "end": "318120"
  },
  {
    "text": "planning on learning how to deploy your applications to one and that's not all cuz if you happen to use my coupon code",
    "start": "318120",
    "end": "324520"
  },
  {
    "text": "dreams a code when checking out your brand new VPS you'll also get an additional 10% discount on the already",
    "start": "324520",
    "end": "331199"
  },
  {
    "text": "low price therefore in order to pick up your own VPS instance at an affordable",
    "start": "331199",
    "end": "336360"
  },
  {
    "text": "cost go ahead and visit hostinger.com dreams of code or click the link in the",
    "start": "336360",
    "end": "342039"
  },
  {
    "text": "description down below a big thank you to hostinger for sponsoring this video",
    "start": "342039",
    "end": "347160"
  },
  {
    "start": "347000",
    "end": "443000"
  },
  {
    "text": "with my VPS instance in hand it was now time to begin setting it up for the operating system I decided to go with",
    "start": "347160",
    "end": "353039"
  },
  {
    "text": "Ubuntu 2404 which in my experience typically tends to be the most popular operating system when it comes to",
    "start": "353039",
    "end": "359319"
  },
  {
    "text": "spinning up a VPS instance once I had selected my operating system the next thing to do was to set a secure password",
    "start": "359319",
    "end": "366080"
  },
  {
    "text": "for my root user as well as copying over any SSH public keys I wanted to use once",
    "start": "366080",
    "end": "371360"
  },
  {
    "text": "I had done so my instance then began deploying at which point I decided it would be a good time to set up a DNS",
    "start": "371360",
    "end": "377039"
  },
  {
    "text": "record pointing to it because I didn't have any spare domain names lying around I decided to go ahead and purchase the",
    "start": "377039",
    "end": "383479"
  },
  {
    "text": "zenin doxyz domain name from hostinger for the low cost of $199 for the first",
    "start": "383479",
    "end": "389360"
  },
  {
    "text": "year here once the domain was registered I then went about adding an a record and a quad a record for those who love IPv6",
    "start": "389360",
    "end": "396759"
  },
  {
    "text": "pointing it to the relevant IP address of my VPS once both the DNS record had propagated and my VPS was deployed I was",
    "start": "396759",
    "end": "404120"
  },
  {
    "text": "able to ssh in with my VPS now accessible the next task that I had on",
    "start": "404120",
    "end": "409400"
  },
  {
    "text": "my makeshift cambam board was to ensure that my VPS was Secure to achieve this I",
    "start": "409400",
    "end": "414599"
  },
  {
    "text": "went through the same steps that I normally would adding in a new user by using the add user commands and copying",
    "start": "414599",
    "end": "420639"
  },
  {
    "text": "my SSH key to them using SSH copy ID afterwards I went about setting up",
    "start": "420639",
    "end": "425759"
  },
  {
    "text": "pseudo permissions for this user by using the user mod command passing in the- a flag adding this user to the",
    "start": "425759",
    "end": "432160"
  },
  {
    "text": "pseudo as's group then I checked that everything was working by first sshing in and running the following command in",
    "start": "432160",
    "end": "438680"
  },
  {
    "text": "order to test the pseudo permissions with my user Now set up correctly I then quickly took a look at my or. log and",
    "start": "438680",
    "end": "445720"
  },
  {
    "start": "443000",
    "end": "476000"
  },
  {
    "text": "noticed I was already being spammed so I went about adding in some network security onto the VPS beginning with",
    "start": "445720",
    "end": "452520"
  },
  {
    "text": "setting up the ufw firewall which I did by first allowing the open SSH app and",
    "start": "452520",
    "end": "457840"
  },
  {
    "text": "then enabling ufw using the following command next it was then time to harden",
    "start": "457840",
    "end": "463440"
  },
  {
    "text": "SSH which involved both disabling password authentication and rout access from the sshd config then once those",
    "start": "463440",
    "end": "471280"
  },
  {
    "text": "changes were made I restarted the service and made sure that I couldn't ssh in as my root user next I then",
    "start": "471280",
    "end": "477639"
  },
  {
    "start": "476000",
    "end": "562000"
  },
  {
    "text": "decided to further Harden SSH in order to prevent script kitties or dos attempts typically I would achieve this",
    "start": "477639",
    "end": "484159"
  },
  {
    "text": "using fail to ban however a good number of my audience had recommended I try crowd SEC which happens to be similar to",
    "start": "484159",
    "end": "491080"
  },
  {
    "text": "fail to ban but is also written in go therefore I felt like this would be the perfect time and decided to give it a go",
    "start": "491080",
    "end": "498080"
  },
  {
    "text": "so I headed on over to the crowd SEC GitHub repo copied the installation commands and pasted it into my VPS",
    "start": "498080",
    "end": "504599"
  },
  {
    "text": "terminal unfortunately however I actually ran into a bit of an issue where the install command was hanging at",
    "start": "504599",
    "end": "510319"
  },
  {
    "text": "one of the install steps fortunately this wasn't anything that a well-placed control C couldn't solve and the",
    "start": "510319",
    "end": "516360"
  },
  {
    "text": "installation continued without any further hitch once it was complete the crowd sex service was now up and running",
    "start": "516360",
    "end": "522599"
  },
  {
    "text": "and so I decided to take a quick look at the logs which informed me that there was already a bad apple attempting to",
    "start": "522599",
    "end": "528880"
  },
  {
    "text": "brute force in fortunately crowd SEC told me that it was blocking them however when I went and checked the orth",
    "start": "528880",
    "end": "535240"
  },
  {
    "text": "dolog I could still see events coming in this is because I had can actually install a firewall or a bouncer as it's",
    "start": "535240",
    "end": "542040"
  },
  {
    "text": "called in Crow SEC which is needed in order to block the IP so I went about doing so choosing to install the crow",
    "start": "542040",
    "end": "549360"
  },
  {
    "text": "SEC firewall bouncer IP tables version once it was installed it then proved much more effective and the IP of the",
    "start": "549360",
    "end": "556680"
  },
  {
    "text": "Bad Apple was now temporarily banned with that my VPS was now reasonably",
    "start": "556680",
    "end": "561920"
  },
  {
    "text": "secure and it was time to move on to deploying my application instead of doing so using my main user I actually",
    "start": "561920",
    "end": "568839"
  },
  {
    "start": "562000",
    "end": "696000"
  },
  {
    "text": "decided to create yet another user for the actual deployments called deploy this would allow me to restrict the",
    "start": "568839",
    "end": "575000"
  },
  {
    "text": "permissions of this user even further such as not allowing them access to pseudo this was actually a good",
    "start": "575000",
    "end": "581120"
  },
  {
    "text": "indication that there were some benefits of using this deployment model compared to using Docker as I was better able to",
    "start": "581120",
    "end": "586920"
  },
  {
    "text": "control rout access compared to using the docker demon in any case with my deploy user created I then needed to",
    "start": "586920",
    "end": "593440"
  },
  {
    "text": "copy over my SSH authorized keys in order to be able to ssh in as the deploy",
    "start": "593440",
    "end": "598760"
  },
  {
    "text": "user this was needed because I had already disabled password authentication when it came to SSH which meant I",
    "start": "598760",
    "end": "605440"
  },
  {
    "text": "couldn't just use the SSH copy ID command for any user that didn't already have an SSH key set up in any case with",
    "start": "605440",
    "end": "612720"
  },
  {
    "text": "my new deploy user configured the next thing to do was to decide on how to get my application installed onto the VPS",
    "start": "612720",
    "end": "620160"
  },
  {
    "text": "the first idea that I had was to just clone down the GitHub repo for the project and build the application",
    "start": "620160",
    "end": "626399"
  },
  {
    "text": "directly on the box however in my experience this is generally considered a bit of a bad practice not only is it",
    "start": "626399",
    "end": "633600"
  },
  {
    "text": "not great to have your source code sitting on the machine but whenever you trigger a redeploy it's going to consume",
    "start": "633600",
    "end": "639480"
  },
  {
    "text": "resources in order to actually build your application which takes away from serving your users therefore I instead",
    "start": "639480",
    "end": "646279"
  },
  {
    "text": "decided that a much better approach would be to build my application binary outside of the VPS and then copy it over",
    "start": "646279",
    "end": "652399"
  },
  {
    "text": "in some way so in order to get my application up and running on the VPS I did just that building it on my loal",
    "start": "652399",
    "end": "659519"
  },
  {
    "text": "machine using the following commands before copying it over using SCP then once the binary was available",
    "start": "659519",
    "end": "666000"
  },
  {
    "text": "on my VPS I switched back to it and ran the following command to execute it",
    "start": "666000",
    "end": "671720"
  },
  {
    "text": "which unfortunately didn't actually work this is because the binary being built was dynamically linked and because I was",
    "start": "671720",
    "end": "679320"
  },
  {
    "text": "building on NYX OS it wasn't properly linking on the actual server therefore I needed to produce another binary that",
    "start": "679320",
    "end": "685800"
  },
  {
    "text": "didn't have SEO enabled which I did using the following in environment variable once it was built I again",
    "start": "685800",
    "end": "691760"
  },
  {
    "text": "copied it over using SCP and this time the binary was able to be executed",
    "start": "691760",
    "end": "697120"
  },
  {
    "start": "696000",
    "end": "857000"
  },
  {
    "text": "although it wasn't exactly working as my code was now panicking this Panic was",
    "start": "697120",
    "end": "702240"
  },
  {
    "text": "occurring because I hadn't set the reddis URL envirment variable which is what my application was using in order",
    "start": "702240",
    "end": "708680"
  },
  {
    "text": "to store the snippet data this also meant that I needed a reddis instance or at least one of its Forks available for",
    "start": "708680",
    "end": "715519"
  },
  {
    "text": "my application to connect to therefore remembering my original open-source constraints I went ahead and installed",
    "start": "715519",
    "end": "722200"
  },
  {
    "text": "the valky server using the following apt commands which initially I accidentally did on my deploy user who didn't have",
    "start": "722200",
    "end": "728800"
  },
  {
    "text": "pseudo permissions once I realized my mistake I exited out and returned to my main user where I ran the same command",
    "start": "728800",
    "end": "735800"
  },
  {
    "text": "again although this time successfully once the valky server had been installed I then went about and opened up the",
    "start": "735800",
    "end": "742160"
  },
  {
    "text": "valky configuration file in order to make a couple of desired changes the first of which was I wanted to set a Max",
    "start": "742160",
    "end": "749279"
  },
  {
    "text": "memory limit of the valky instance to 6 GB given that my instance had a nice",
    "start": "749279",
    "end": "754639"
  },
  {
    "text": "large eight to work with setting the valky configuration this way would mean that I would always have at least 2 GB",
    "start": "754639",
    "end": "760760"
  },
  {
    "text": "of RAM available for my system and application to work with which was going to be more than enough but I wanted to",
    "start": "760760",
    "end": "766720"
  },
  {
    "text": "make sure that valky wouldn't starve any of the other processes in any case the next thing I needed to do was to add a",
    "start": "766720",
    "end": "772800"
  },
  {
    "text": "max memory policy which I set to the volatile sltl option this policy meant",
    "start": "772800",
    "end": "778720"
  },
  {
    "text": "that if the max memory limit was reached valky would start removing keys with a 2tl set with the keys with the shortest",
    "start": "778720",
    "end": "786000"
  },
  {
    "text": "remaining time to live being removed first next I then made a configuration change to write data to the append only",
    "start": "786000",
    "end": "793000"
  },
  {
    "text": "file which meant that any data stored in valky would be persisted in the event",
    "start": "793000",
    "end": "798079"
  },
  {
    "text": "that either valky or the actual VPS instance was restarted lastly I then went about adding authentication in",
    "start": "798079",
    "end": "804880"
  },
  {
    "text": "order to connect to the valky instance as it was just me using the machine I decided to not set up an ACL although",
    "start": "804880",
    "end": "811880"
  },
  {
    "text": "this is the recommended practice instead however I just decided to enable the requir pass option and changed it from",
    "start": "811880",
    "end": "818920"
  },
  {
    "text": "the default password to something a little more secure with the configuration changes made I could then",
    "start": "818920",
    "end": "824399"
  },
  {
    "text": "go about restarting the valky service and it was ready to go all I needed to do now was set the reddis environment",
    "start": "824399",
    "end": "831399"
  },
  {
    "text": "variable which I did with the following export command then I was able to execute my obligation and this time it",
    "start": "831399",
    "end": "837959"
  },
  {
    "text": "was up and running in order to test that it was working I went ahead and added in a rule to allow Port 3000 on the ufw",
    "start": "837959",
    "end": "845320"
  },
  {
    "text": "firewall before then opening up a web browser and navigating on over to zenin doxyz at Port 3000 as well as checking",
    "start": "845320",
    "end": "854000"
  },
  {
    "text": "the logs to make sure I was actually hitting my service with that my application was now up and running but",
    "start": "854000",
    "end": "861040"
  },
  {
    "start": "857000",
    "end": "1034000"
  },
  {
    "text": "it certainly wasn't what I would consider deployed for starters if the application happened to crash or",
    "start": "861040",
    "end": "867120"
  },
  {
    "text": "networking Gods forbid the VPS was rebooted then I would be forced to ssh in in order to restart my application",
    "start": "867120",
    "end": "875120"
  },
  {
    "text": "this is no way to live in my opinion therefore I needed to go about adding in",
    "start": "875120",
    "end": "880279"
  },
  {
    "text": "automatic restarts which meant I needed to set up my application as a system D",
    "start": "880279",
    "end": "885680"
  },
  {
    "text": "service to do so I went about creating a new systemd unit file inside of my Project's repo setting it up to execute",
    "start": "885680",
    "end": "893079"
  },
  {
    "text": "a binary inside of my deployment users home folder rather than keeping the binary inside the root directory of my",
    "start": "893079",
    "end": "899040"
  },
  {
    "text": "my users home folder I decided to be a little more organized and keep it inside",
    "start": "899040",
    "end": "904199"
  },
  {
    "text": "of a directory named production just in case I ever wanted to have multiple environments so I went ahead and created",
    "start": "904199",
    "end": "911839"
  },
  {
    "text": "this directory before copying the zenin binary into it once that was complete I",
    "start": "911839",
    "end": "917360"
  },
  {
    "text": "then went about adding in the remainder of the system dunit file asking for some best practices from chatty G which ended",
    "start": "917360",
    "end": "925120"
  },
  {
    "text": "up not working I told you you can never consider that guy a friend in any case some of the key security measures that I",
    "start": "925120",
    "end": "931600"
  },
  {
    "text": "put in place were to ensure that the application was only going to be ran by my deploy user as well as restricting",
    "start": "931600",
    "end": "937160"
  },
  {
    "text": "access to the file system additionally I also added in options to ensure that the application would restart on failure and",
    "start": "937160",
    "end": "943720"
  },
  {
    "text": "made sure to also set up an environment variable in order to configure the port afterwards I then went ahead and pointed",
    "start": "943720",
    "end": "949279"
  },
  {
    "text": "standard out and standard error to the journal control command which would make it easier in order to debug later on",
    "start": "949279",
    "end": "955880"
  },
  {
    "text": "next up I then went ahead and added in an environment variable for the reddis URL we had already looked at before",
    "start": "955880",
    "end": "962360"
  },
  {
    "text": "however you may notice that I emitted the actual password of the valky instance inside of this environment",
    "start": "962360",
    "end": "968079"
  },
  {
    "text": "variable as I was going to commit this file to my GitHub repo whilst I was considering balky I also went ahead and",
    "start": "968079",
    "end": "974600"
  },
  {
    "text": "added in some dependencies on the valky service defining it as a requirement of the zenin service with that my system",
    "start": "974600",
    "end": "982360"
  },
  {
    "text": "dunit file was now ready to go so I went about adding it to my git repo before",
    "start": "982360",
    "end": "988240"
  },
  {
    "text": "downloading it onto my VPS using the following curl command before I went ahead and added it into system D however",
    "start": "988240",
    "end": "995240"
  },
  {
    "text": "I first needed to make a quick change which was to add in my configured password for the valky instance into the",
    "start": "995240",
    "end": "1001279"
  },
  {
    "text": "reddis URL environment variable which of course I had purposefully emitted from being committed into my code with that",
    "start": "1001279",
    "end": "1008920"
  },
  {
    "text": "the system dunit file was now ready to go so I copied it over to/ Etsy system",
    "start": "1008920",
    "end": "1014800"
  },
  {
    "text": "d/ system before then reloading system D and enabling my zen bin service upon",
    "start": "1014800",
    "end": "1020639"
  },
  {
    "text": "doing so I then checked that everything looked good using the system control status commands this gave me the big",
    "start": "1020639",
    "end": "1026918"
  },
  {
    "text": "green go letting me know that everything was working so I opened up a web browser and checked that the service was",
    "start": "1026919",
    "end": "1032678"
  },
  {
    "text": "available which it was with that my application deployment was now complete",
    "start": "1032679",
    "end": "1038360"
  },
  {
    "start": "1034000",
    "end": "1140000"
  },
  {
    "text": "the next task I had on my backlog was to ensure that my secrets were now secure as currently they weren't if I went",
    "start": "1038360",
    "end": "1045000"
  },
  {
    "text": "ahead and Ed the following system control cat command which you'll notice doesn't use pseudo I was able to pull",
    "start": "1045000",
    "end": "1051000"
  },
  {
    "text": "out the reddis connection URL as the deploy user which contained my super secure password therefore as the",
    "start": "1051000",
    "end": "1057960"
  },
  {
    "text": "responsible developer that I am I wanted to make sure that this password couldn't be accessed by anyone who didn't have",
    "start": "1057960",
    "end": "1063799"
  },
  {
    "text": "pseudo permissions to achieve this I decided to create an environment file storing it under the/ Etsy EMV directory",
    "start": "1063799",
    "end": "1071840"
  },
  {
    "text": "inside of this file I went ahead and added the reddis URL as follows then in order to use it with my actual service I",
    "start": "1071840",
    "end": "1079240"
  },
  {
    "text": "added in a new environment file option pointing it at the/ Etsy EMV z.n file I",
    "start": "1079240",
    "end": "1086799"
  },
  {
    "text": "had just created and removed the existing reddis URL environment option I had already previously defined once that",
    "start": "1086799",
    "end": "1093880"
  },
  {
    "text": "was complete I then needed to make sure that the deploy user couldn't access this new file which they currently could",
    "start": "1093880",
    "end": "1100280"
  },
  {
    "text": "so I went ahead and changed the permissions from 644 to 600 which meant only the files owner would be able to",
    "start": "1100280",
    "end": "1106960"
  },
  {
    "text": "read this file which then confirmed lastly all that remained was to reload",
    "start": "1106960",
    "end": "1112039"
  },
  {
    "text": "my system deconfigured service which I confirmed",
    "start": "1112039",
    "end": "1117159"
  },
  {
    "text": "was working correctly whilst also ensuring that the reddis URL was no longer being exposed in hindsights I'm",
    "start": "1117159",
    "end": "1124080"
  },
  {
    "text": "not too sure how secure this approach is given that the secret is still available in the application's environment instead",
    "start": "1124080",
    "end": "1131960"
  },
  {
    "text": "using a secret manager is going to be more effective in any case now that I had Secrets somewhat secure I was able",
    "start": "1131960",
    "end": "1138480"
  },
  {
    "text": "to move the task into the done column before picking up the next one which was setting up https typically in the past I",
    "start": "1138480",
    "end": "1146080"
  },
  {
    "start": "1140000",
    "end": "1247000"
  },
  {
    "text": "would normally achieve this using engine X as a reverse proxy with C Bots set up in order to handle certificates however",
    "start": "1146080",
    "end": "1153200"
  },
  {
    "text": "a good number of people in my audience have been asking me to check out another application called caddy so I decided to",
    "start": "1153200",
    "end": "1159640"
  },
  {
    "text": "give it a go and went about installing it to do so I copied in the following commands from the caddy documentation",
    "start": "1159640",
    "end": "1166039"
  },
  {
    "text": "which not only installed the caddy application for me but also went about setting up a service file however when I",
    "start": "1166039",
    "end": "1171640"
  },
  {
    "text": "opened up a new terminal window and sent a curl request to The zenin doxyz Domain",
    "start": "1171640",
    "end": "1177120"
  },
  {
    "text": "it was just hanging this was happening because ufw was still blocking Port 80 and 443 so I went ahead and added them",
    "start": "1177120",
    "end": "1184320"
  },
  {
    "text": "to the allow list afterwards I then confirmed that caddy was working which meant I could now configure it in order",
    "start": "1184320",
    "end": "1191000"
  },
  {
    "text": "to do so I needed to edit the caddy file which contained the current configuration I managed to locate this",
    "start": "1191000",
    "end": "1197840"
  },
  {
    "text": "by using the system control status command which showed me it was currently available under / Etsy cad/ catty file",
    "start": "1197840",
    "end": "1205799"
  },
  {
    "text": "therefore I went about opening this up inside of my text editor and read the very helpful documentation located at",
    "start": "1205799",
    "end": "1211880"
  },
  {
    "text": "the top of the file this documentation told me to replace the reference to Port 0 with my host name and everything",
    "start": "1211880",
    "end": "1217919"
  },
  {
    "text": "should work as expected so I went about doing so additionally I also went about commenting out the default configuration",
    "start": "1217919",
    "end": "1224280"
  },
  {
    "text": "for the actual host and configured it to reverse proxy to my local host 3 3,000",
    "start": "1224280",
    "end": "1229679"
  },
  {
    "text": "which was the port my zenin service was listening on with the changes made I went ahead and saved the cad file and",
    "start": "1229679",
    "end": "1235799"
  },
  {
    "text": "reloaded the service and within about 1 minute I had https up and running well",
    "start": "1235799",
    "end": "1241280"
  },
  {
    "text": "played caddy you now have a new fan in any case once I had HTTP set up the next",
    "start": "1241280",
    "end": "1247320"
  },
  {
    "start": "1247000",
    "end": "1622000"
  },
  {
    "text": "task on my list was to begin adding in automated deployments in my mind I knew how I",
    "start": "1247320",
    "end": "1253400"
  },
  {
    "text": "wanted to achieve this the idea was to basically obtain a copy of the new binary copy it over to the correct",
    "start": "1253400",
    "end": "1259880"
  },
  {
    "text": "location and restart the service using system control restart however whilst the basic idea was pretty simple the",
    "start": "1259880",
    "end": "1267080"
  },
  {
    "text": "actual implementation was a lot more difficult typically when using a Docker based approach I would just upload the",
    "start": "1267080",
    "end": "1273200"
  },
  {
    "text": "docker image to a Docker registry tagged with the git commit hash of the code that the container was built from in",
    "start": "1273200",
    "end": "1280200"
  },
  {
    "text": "this case I wanted to do something similar but I wasn't sure of the correct approach to take the first idea I had",
    "start": "1280200",
    "end": "1287159"
  },
  {
    "text": "was to make use of the git tub release feature which allows you to store binaries associated with a given git tag",
    "start": "1287159",
    "end": "1294120"
  },
  {
    "text": "initially I thought this was going to be the perfect approach however upon investigating I realized I would need to",
    "start": "1294120",
    "end": "1299880"
  },
  {
    "text": "actually add a git tag for every commit which felt like a grand misuse of the feature not only this but I also feel",
    "start": "1299880",
    "end": "1306799"
  },
  {
    "text": "like GitHub releases are more geared towards semantic versioning rather than using it for continuous delivery",
    "start": "1306799",
    "end": "1312880"
  },
  {
    "text": "therefore I decided to look at a second option which was to set up an S3 bucket where I could upload my individual",
    "start": "1312880",
    "end": "1319400"
  },
  {
    "text": "binaries on inside of a directory related to the git commit hash then all I would need to do would be to set up",
    "start": "1319400",
    "end": "1325840"
  },
  {
    "text": "some AWS credentials on my VPS then I could easily just download the binary using the AWS CLI to me this felt like a",
    "start": "1325840",
    "end": "1333679"
  },
  {
    "text": "decent approach as I could use the bucket as a sort of artifact repo supporting multiple operating systems",
    "start": "1333679",
    "end": "1339960"
  },
  {
    "text": "and architectures and I could even set up other automation based on AWS S3",
    "start": "1339960",
    "end": "1345080"
  },
  {
    "text": "events the main reservation that I had was that this was going to be adding additional infrastructure into this",
    "start": "1345080",
    "end": "1350480"
  },
  {
    "text": "challenge which was something I was trying to avoid as it would open the door for me to use other services such",
    "start": "1350480",
    "end": "1356640"
  },
  {
    "text": "as cloudflare therefore I decided against taking this approach and instead focused on a more VPS based solution",
    "start": "1356640",
    "end": "1364120"
  },
  {
    "text": "this approach was much more simple which was to use SSH and SCP to copy over the",
    "start": "1364120",
    "end": "1370120"
  },
  {
    "text": "binary over to the VPS with a file name consisting of the git commit hash then I",
    "start": "1370120",
    "end": "1375640"
  },
  {
    "text": "could easily just run a deploy script to copy over this binary into the production directory restarting the",
    "start": "1375640",
    "end": "1381720"
  },
  {
    "text": "system Des service in order to apply the new release whilst this wasn't my favorite approach it did work and it",
    "start": "1381720",
    "end": "1388960"
  },
  {
    "text": "also met my criteria so I went about implementing it and began by setting up a new SSH key for my deploy user that I",
    "start": "1388960",
    "end": "1397080"
  },
  {
    "text": "could use with GitHub actions I created this key using the SSH key gen tool and",
    "start": "1397080",
    "end": "1402360"
  },
  {
    "text": "copied it over using the SSH copy ID command I then verified that I could log in using this new SSH key before then",
    "start": "1402360",
    "end": "1409279"
  },
  {
    "text": "adding the private key as a secret inside of GitHub with my secret added I then went about modifying my existing",
    "start": "1409279",
    "end": "1415600"
  },
  {
    "text": "GitHub workflow in order to add a deploy step which involved building a binary that contained the git commit hash as",
    "start": "1415600",
    "end": "1422159"
  },
  {
    "text": "well as setting the correct environment variables in order to build without SEO as well as ensuring that the binary was",
    "start": "1422159",
    "end": "1427640"
  },
  {
    "text": "built for the correct operating system Linux and correct architecture amd64 after the build step changes were",
    "start": "1427640",
    "end": "1434520"
  },
  {
    "text": "made I then added in another step called deploy which would use the SSH private key in order to copy over the binary",
    "start": "1434520",
    "end": "1441480"
  },
  {
    "text": "using SCP next I then went about writing a deployment script which took the git",
    "start": "1441480",
    "end": "1446760"
  },
  {
    "text": "commit hashes and arguments and would promote the binary by copying it over to the production directory in the deploy",
    "start": "1446760",
    "end": "1452720"
  },
  {
    "text": "users home folder initially I was achieving this by using the CP commands",
    "start": "1452720",
    "end": "1457760"
  },
  {
    "text": "however later on I realized that using symbolic links was going to be more versatile with the added benefit of not",
    "start": "1457760",
    "end": "1463760"
  },
  {
    "text": "wasting any disk space so I went ahead and changed my script to use simp olic links instead this also came in handy",
    "start": "1463760",
    "end": "1471240"
  },
  {
    "text": "later on when I went to implement rollbacks in any case once the binary had been promoted to production I could",
    "start": "1471240",
    "end": "1477559"
  },
  {
    "text": "then restart the service using the pseudo system control restart command unfortunately however this did mean that",
    "start": "1477559",
    "end": "1483720"
  },
  {
    "text": "the deploy user needed some sort of pseudo permissions however there is a way to provide this without providing",
    "start": "1483720",
    "end": "1489640"
  },
  {
    "text": "full route access to set this up I sshed in as my main user and ran the vice sudo",
    "start": "1489640",
    "end": "1495720"
  },
  {
    "text": "command in order to edit the pseudo as file then I went ahead and added in an entry for the deploy user however rather",
    "start": "1495720",
    "end": "1502880"
  },
  {
    "text": "than allowing them to have pseudo on every command I instead constrain this to the system control restart zenin",
    "start": "1502880",
    "end": "1509080"
  },
  {
    "text": "service command additionally I set it up so that no password entry would be required once these changes were made I",
    "start": "1509080",
    "end": "1515440"
  },
  {
    "text": "then logged in as my deploy user and tested that pseudo would work for system control restart zenin do service but",
    "start": "1515440",
    "end": "1522039"
  },
  {
    "text": "wasn't available for anything else once confirmed I headed back on over to my text editor and added in another command",
    "start": "1522039",
    "end": "1528919"
  },
  {
    "text": "into the deploy step of my GitHub cicd action this command will execute the deploy script on the server using SSH",
    "start": "1528919",
    "end": "1536279"
  },
  {
    "text": "preventing me from needing to copy it onto the actual machine the benefit of this approach was that the deploy.sh",
    "start": "1536279",
    "end": "1542039"
  },
  {
    "text": "script inside of the repository would always be the source of Truth and would help to prevent any race conditions from",
    "start": "1542039",
    "end": "1547960"
  },
  {
    "text": "two workflows running at the same time although there is a better way to solve this in any case with my script and",
    "start": "1547960",
    "end": "1554240"
  },
  {
    "text": "workflow defined I went about committing it to the GitHub repository and put pushed it to my remote repo then I",
    "start": "1554240",
    "end": "1560399"
  },
  {
    "text": "headed on over to the pipeline in my browser and watched to see if it succeeded which at first it",
    "start": "1560399",
    "end": "1566640"
  },
  {
    "text": "didn't this was because I had forgotten to pass in the git commit hash as the argument to my deploy script however",
    "start": "1566640",
    "end": "1573320"
  },
  {
    "text": "whilst debugging I did confirm that the binary was being copied over to the actual VPS so things were looking pretty",
    "start": "1573320",
    "end": "1580039"
  },
  {
    "text": "good so I went ahead and made sure that I was passing in the get commit hashes and arguments and reran the pipeline yet",
    "start": "1580039",
    "end": "1586600"
  },
  {
    "text": "again this time it looked like everything has succeeded so to really test it I went ahead and made a couple",
    "start": "1586600",
    "end": "1592600"
  },
  {
    "text": "of changes to my actual application and pushed them up to confirm if my automated deployments were working which",
    "start": "1592600",
    "end": "1598919"
  },
  {
    "text": "not only showed me that it was but it was doing so in a short amount of time taking less than a minute from when I",
    "start": "1598919",
    "end": "1605240"
  },
  {
    "text": "pushed my code up to the changes being deployed this is in STK contrast to whenever I built systems using Docker",
    "start": "1605240",
    "end": "1612480"
  },
  {
    "text": "which in my experience usually takes more around 5 to 10 minutes in order for an automated deployment to go through in",
    "start": "1612480",
    "end": "1619720"
  },
  {
    "text": "any case now that I had continuous deployments set up I took this as an opportunity to add a couple more changes",
    "start": "1619720",
    "end": "1625679"
  },
  {
    "start": "1622000",
    "end": "1775000"
  },
  {
    "text": "to my actual web application before moving on to my next task adding in Rolling releases this task actually had",
    "start": "1625679",
    "end": "1633159"
  },
  {
    "text": "a subtask that I would first need to complete which was to set up replication for my service initially I thought that",
    "start": "1633159",
    "end": "1640039"
  },
  {
    "text": "this was going to be somewhat uncomfortable especially when compared to using something like Docker or kubernetes where all you have to do is",
    "start": "1640039",
    "end": "1646880"
  },
  {
    "text": "pass in a flag or a configuration option initially when it came to system D I",
    "start": "1646880",
    "end": "1652200"
  },
  {
    "text": "thought I was going to have to copy the service file another two times changing the port value inside which to me felt",
    "start": "1652200",
    "end": "1659360"
  },
  {
    "text": "like a very unscalable solution especially if I ever needed to make changes to all three services at once",
    "start": "1659360",
    "end": "1665720"
  },
  {
    "text": "fortunately however after a bit of research I came across the at symbol which allows you to deploy multiple",
    "start": "1665720",
    "end": "1672320"
  },
  {
    "text": "instances of your service when it comes to system d by adding the at symbol to the service files name it allows you to",
    "start": "1672320",
    "end": "1679039"
  },
  {
    "text": "specify a name for that instance which you can then reference inside of the system dunit file therefore I went ahead",
    "start": "1679039",
    "end": "1685760"
  },
  {
    "text": "and copied over the existing senin service into a new service file that made use of the out symbol using the",
    "start": "1685760",
    "end": "1692000"
  },
  {
    "text": "instance name as the port value for my service to listen on then I tested that",
    "start": "1692000",
    "end": "1697240"
  },
  {
    "text": "this worked by enabling a version with the identifier of 3001 which will also",
    "start": "1697240",
    "end": "1702519"
  },
  {
    "text": "set the Services Port to be 3001 as well then I added the port to my fire all",
    "start": "1702519",
    "end": "1708399"
  },
  {
    "text": "list followed by ensuring that it was accessible which it was therefore I went",
    "start": "1708399",
    "end": "1713720"
  },
  {
    "text": "ahead and disabled my existing Zen bin service and enabled two more one for Port 3000 and another for Port",
    "start": "1713720",
    "end": "1721799"
  },
  {
    "text": "3002 then in order to make sure that requests would be routed to each of these three instances I modified my cad",
    "start": "1721799",
    "end": "1728240"
  },
  {
    "text": "file adding in the two new instances to the reverse proxy configuration once the caddy changes were made I then decided",
    "start": "1728240",
    "end": "1735279"
  },
  {
    "text": "to make sure that everything was working which I did by tailing the logs for each of the three services using the",
    "start": "1735279",
    "end": "1741480"
  },
  {
    "text": "following Journal control command before sending up some HTTP requests using curl",
    "start": "1741480",
    "end": "1746799"
  },
  {
    "text": "to confirm that each service was being routed to with the load balancing confirmed as working I went ahead and",
    "start": "1746799",
    "end": "1752919"
  },
  {
    "text": "made the following changes to the deployment script ensuring that each of the three instances would be restarted",
    "start": "1752919",
    "end": "1758600"
  },
  {
    "text": "whenever a deployment took place additionally I also needed to make the following change to the pseudois file in",
    "start": "1758600",
    "end": "1764399"
  },
  {
    "text": "order to allow the deploy user to restart each service again once everything was complete I committed and",
    "start": "1764399",
    "end": "1770120"
  },
  {
    "text": "pushed the new changes and watched the deployment pipeline to make sure that it worked successfully with that now that I",
    "start": "1770120",
    "end": "1775799"
  },
  {
    "start": "1775000",
    "end": "1903000"
  },
  {
    "text": "had application set up I was ready to begin implementing rolling releases to achieve this I headed back on over to my",
    "start": "1775799",
    "end": "1782240"
  },
  {
    "text": "deployment script and added in the following changes first keeping a reference of the current binary that",
    "start": "1782240",
    "end": "1788399"
  },
  {
    "text": "these Services were using I achieved this by using the readlink command which would give me the file name that the",
    "start": "1788399",
    "end": "1794159"
  },
  {
    "text": "symbolic link was pointing to then once I had a reference to the previous binary I went ahead and added in a rollback",
    "start": "1794159",
    "end": "1800760"
  },
  {
    "text": "function which would romote the existing binary in case the deployment failed then with my rollback function defined I",
    "start": "1800760",
    "end": "1807480"
  },
  {
    "text": "created a restart function which could be used to restart the instances one by one this function accepted a port number",
    "start": "1807480",
    "end": "1814760"
  },
  {
    "text": "and restarted the associated instance checking to see if the restart was successful then if it was it would sleep",
    "start": "1814760",
    "end": "1820880"
  },
  {
    "text": "a number of seconds before checking the status of the service using the system control is active commands if the",
    "start": "1820880",
    "end": "1827360"
  },
  {
    "text": "service wasn't running at any of these two points then the rollback function would be called and the script would",
    "start": "1827360",
    "end": "1832960"
  },
  {
    "text": "exit with a nonzero code with the changes made to the deployment script I went ahead and committed this and pushed",
    "start": "1832960",
    "end": "1838799"
  },
  {
    "text": "this up yet again then in order to test that everything was working I went ahead and made a breaking change to my code",
    "start": "1838799",
    "end": "1845120"
  },
  {
    "text": "changing the value of the reddis URL environment variable which should cause my application to panic when it starts",
    "start": "1845120",
    "end": "1851600"
  },
  {
    "text": "up with the change made I went ahead and pushed it up which did cause my deployment to fail and I could see that",
    "start": "1851600",
    "end": "1857440"
  },
  {
    "text": "the script had attempted to roll back however unfortunately it hadn't actually worked after a little bit of debugging",
    "start": "1857440",
    "end": "1864559"
  },
  {
    "text": "and a couple of iterations of the script I ended up getting it working by adding in a loadbearing sleep in between",
    "start": "1864559",
    "end": "1870760"
  },
  {
    "text": "rolling back the symbolic link for the binary and restarting the failed service additionally I also made a couple of",
    "start": "1870760",
    "end": "1877240"
  },
  {
    "text": "changes to the caddy file in order to better handle when a backend wasn't available this involved adding in a",
    "start": "1877240",
    "end": "1883480"
  },
  {
    "text": "health check which required me to also add in a health endpoint to my actual application with all of the changes made",
    "start": "1883480",
    "end": "1890399"
  },
  {
    "text": "which you can actually view on GitHub if you're interested I confirmed that the rback was now working which meant I had",
    "start": "1890399",
    "end": "1896600"
  },
  {
    "text": "successfully managed to complete all of my production ready tasks all without the use of Docker or",
    "start": "1896600",
    "end": "1902960"
  },
  {
    "text": "containerization all in all I actually had a lot of fun and I felt like I learned some more about system D and the",
    "start": "1902960",
    "end": "1909120"
  },
  {
    "start": "1903000",
    "end": "1980000"
  },
  {
    "text": "other tools that I picked up such as caddy and crowd saac whilst setting up a VPS this way is certainly more difficult",
    "start": "1909120",
    "end": "1915760"
  },
  {
    "text": "than using Docker it was actually a a lot easier than I originally thought and only really took me a couple of hours to",
    "start": "1915760",
    "end": "1922240"
  },
  {
    "text": "get everything set up in any case as with all things there are a couple of improvements that I would like to make",
    "start": "1922240",
    "end": "1927760"
  },
  {
    "text": "in the future these include using the caddy API instead of a caddy file which I think could make it much easier to",
    "start": "1927760",
    "end": "1934039"
  },
  {
    "text": "configure caddy through the use of cicd additionally if this ever became my more default deployment method I would",
    "start": "1934039",
    "end": "1940480"
  },
  {
    "text": "definitely need to add in some automation through either terraform palumi or anable although that's",
    "start": "1940480",
    "end": "1946080"
  },
  {
    "text": "something I'm definitely planning on taking a look at at in another video later on this year as for the actual",
    "start": "1946080",
    "end": "1951519"
  },
  {
    "text": "challenge itself like I said I had a lot of fun and would definitely recommend it to anyone who wants to develop their own",
    "start": "1951519",
    "end": "1958720"
  },
  {
    "text": "skills if you do decide to take on this challenge then you can get yourself a lowcost vs from the video sponsor",
    "start": "1958720",
    "end": "1965919"
  },
  {
    "text": "hostinger make sure to use the link of hostinger.com dreams of code and my coupon code to get that additional",
    "start": "1965919",
    "end": "1972320"
  },
  {
    "text": "discounts otherwise I want to give a big thank you for watching and I'll see you on the next one",
    "start": "1972320",
    "end": "1979760"
  }
]
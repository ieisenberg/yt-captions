[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "postgres is probably my favorite",
    "start": "120",
    "end": "2460"
  },
  {
    "text": "database I may spend time with other",
    "start": "2460",
    "end": "5040"
  },
  {
    "text": "data stores but at the end of the day",
    "start": "5040",
    "end": "6899"
  },
  {
    "text": "I'm a one database kind of guy postgres",
    "start": "6899",
    "end": "9540"
  },
  {
    "text": "is the relational database I have a",
    "start": "9540",
    "end": "11940"
  },
  {
    "text": "relationship with and therefore SQL is",
    "start": "11940",
    "end": "14580"
  },
  {
    "text": "the language of love and I'm not alone",
    "start": "14580",
    "end": "17039"
  },
  {
    "text": "most of you agree with me postgres",
    "start": "17039",
    "end": "19380"
  },
  {
    "text": "Remains the most loved database on the",
    "start": "19380",
    "end": "22080"
  },
  {
    "text": "stack Overflow developer survey but that",
    "start": "22080",
    "end": "24420"
  },
  {
    "text": "doesn't mean postgres is perfect and as",
    "start": "24420",
    "end": "27119"
  },
  {
    "text": "much as it pains me I have to admit its",
    "start": "27119",
    "end": "29160"
  },
  {
    "text": "faults one of those faults is Big Data",
    "start": "29160",
    "end": "32220"
  },
  {
    "text": "but how big is Big 10 gigabytes 20 gigs",
    "start": "32220",
    "end": "36600"
  },
  {
    "text": "well Big Data usually means too much",
    "start": "36600",
    "end": "39300"
  },
  {
    "text": "data for a database to handle and so",
    "start": "39300",
    "end": "41640"
  },
  {
    "text": "there's no concrete size for it but the",
    "start": "41640",
    "end": "44219"
  },
  {
    "text": "size of data that I'm talking about",
    "start": "44219",
    "end": "45480"
  },
  {
    "text": "today are table sizes above 50 gigabytes",
    "start": "45480",
    "end": "48239"
  },
  {
    "text": "yeah that kind of big but what kind of",
    "start": "48239",
    "end": "51180"
  },
  {
    "text": "data set would ever be that big well the",
    "start": "51180",
    "end": "53879"
  },
  {
    "text": "main culprit for a large data set is",
    "start": "53879",
    "end": "55980"
  },
  {
    "text": "usually time series data time series",
    "start": "55980",
    "end": "58620"
  },
  {
    "start": "56000",
    "end": "160000"
  },
  {
    "text": "data also referred to as time stamped",
    "start": "58620",
    "end": "61260"
  },
  {
    "text": "data is a sequence of data points",
    "start": "61260",
    "end": "63660"
  },
  {
    "text": "indexed in time order some examples of",
    "start": "63660",
    "end": "66420"
  },
  {
    "text": "Time series data could be the price of",
    "start": "66420",
    "end": "68400"
  },
  {
    "text": "stocks periodic measurements of",
    "start": "68400",
    "end": "70740"
  },
  {
    "text": "temperature readings or the number of",
    "start": "70740",
    "end": "72600"
  },
  {
    "text": "subscribers to a YouTube channel",
    "start": "72600",
    "end": "75299"
  },
  {
    "text": "anything that has an x-axis of time is",
    "start": "75299",
    "end": "78540"
  },
  {
    "text": "time series data now it is possible to",
    "start": "78540",
    "end": "81479"
  },
  {
    "text": "use postgres on this type of data but it",
    "start": "81479",
    "end": "84119"
  },
  {
    "text": "takes a lot of Maintenance and",
    "start": "84119",
    "end": "85860"
  },
  {
    "text": "understanding to do so now I've actually",
    "start": "85860",
    "end": "87960"
  },
  {
    "text": "done another video on how to speed up",
    "start": "87960",
    "end": "89460"
  },
  {
    "text": "postgres which covers a lot of these",
    "start": "89460",
    "end": "91439"
  },
  {
    "text": "approaches the long short of it all is",
    "start": "91439",
    "end": "93659"
  },
  {
    "text": "that instead of storing the data in a",
    "start": "93659",
    "end": "95340"
  },
  {
    "text": "single table you instead store it across",
    "start": "95340",
    "end": "97380"
  },
  {
    "text": "a number of logically grouped tables",
    "start": "97380",
    "end": "99360"
  },
  {
    "text": "known as partitions now partitions are",
    "start": "99360",
    "end": "102360"
  },
  {
    "text": "great but they do come with caveats and",
    "start": "102360",
    "end": "104700"
  },
  {
    "text": "out of the box have no automation around",
    "start": "104700",
    "end": "106740"
  },
  {
    "text": "them so what other options are there",
    "start": "106740",
    "end": "109979"
  },
  {
    "text": "well fortunately there is another option",
    "start": "109979",
    "end": "112560"
  },
  {
    "text": "one that is pretty tantalizing to anyone",
    "start": "112560",
    "end": "115020"
  },
  {
    "text": "who is a fan of postgres that option is",
    "start": "115020",
    "end": "118680"
  },
  {
    "text": "timescale DB",
    "start": "118680",
    "end": "120600"
  },
  {
    "text": "now full disclosure time scale are",
    "start": "120600",
    "end": "122880"
  },
  {
    "text": "sponsoring me for this video but that",
    "start": "122880",
    "end": "124979"
  },
  {
    "text": "doesn't change how I feel about the",
    "start": "124979",
    "end": "126479"
  },
  {
    "text": "product timescale has actually been my",
    "start": "126479",
    "end": "128640"
  },
  {
    "text": "go-to database for time series data in",
    "start": "128640",
    "end": "130619"
  },
  {
    "text": "the past and I think they are perhaps",
    "start": "130619",
    "end": "132840"
  },
  {
    "text": "the perfect solution for it but wait",
    "start": "132840",
    "end": "135540"
  },
  {
    "text": "didn't I say that I only had eyes for",
    "start": "135540",
    "end": "137580"
  },
  {
    "text": "postgres",
    "start": "137580",
    "end": "138599"
  },
  {
    "text": "well before you start calling me out as",
    "start": "138599",
    "end": "140580"
  },
  {
    "text": "a dirty cheat in the comments it is",
    "start": "140580",
    "end": "142860"
  },
  {
    "text": "postgres at least an extension of it and",
    "start": "142860",
    "end": "145860"
  },
  {
    "text": "it's open source so that's two thumbs up",
    "start": "145860",
    "end": "148260"
  },
  {
    "text": "already from my perspective this means",
    "start": "148260",
    "end": "150599"
  },
  {
    "text": "you get all of the goodness of postgres",
    "start": "150599",
    "end": "152280"
  },
  {
    "text": "such as relations transactions and acid",
    "start": "152280",
    "end": "155520"
  },
  {
    "text": "whilst also having a blazing fast and",
    "start": "155520",
    "end": "158280"
  },
  {
    "text": "scalable time series data store",
    "start": "158280",
    "end": "160620"
  },
  {
    "start": "160000",
    "end": "453000"
  },
  {
    "text": "so that's enough talking about how good",
    "start": "160620",
    "end": "162780"
  },
  {
    "text": "time scale DB is let's actually go ahead",
    "start": "162780",
    "end": "165420"
  },
  {
    "text": "and use it first things first we're",
    "start": "165420",
    "end": "167640"
  },
  {
    "text": "going to need to find a large data set",
    "start": "167640",
    "end": "169319"
  },
  {
    "text": "of Time series data there are a few",
    "start": "169319",
    "end": "171900"
  },
  {
    "text": "publicly accessible options out there",
    "start": "171900",
    "end": "173819"
  },
  {
    "text": "one is the ethereum blockchain which is",
    "start": "173819",
    "end": "176519"
  },
  {
    "text": "just above one terabyte and another is",
    "start": "176519",
    "end": "178739"
  },
  {
    "text": "the UK's live train data however both of",
    "start": "178739",
    "end": "181620"
  },
  {
    "text": "these require some initial processing to",
    "start": "181620",
    "end": "183660"
  },
  {
    "text": "get in a format we can use",
    "start": "183660",
    "end": "185459"
  },
  {
    "text": "so I've opted for the New York City Taxi",
    "start": "185459",
    "end": "188160"
  },
  {
    "text": "data set which contains a list of every",
    "start": "188160",
    "end": "190500"
  },
  {
    "text": "taxi trip taken since 2009 on both",
    "start": "190500",
    "end": "192900"
  },
  {
    "text": "yellow and green caps to go along with",
    "start": "192900",
    "end": "195360"
  },
  {
    "text": "this video I've created a GitHub",
    "start": "195360",
    "end": "196800"
  },
  {
    "text": "repository which has a number of scripts",
    "start": "196800",
    "end": "198720"
  },
  {
    "text": "and tools in order to both download this",
    "start": "198720",
    "end": "200700"
  },
  {
    "text": "data and load it into the database which",
    "start": "200700",
    "end": "203519"
  },
  {
    "text": "means you're able to follow along if you",
    "start": "203519",
    "end": "205200"
  },
  {
    "text": "want to by yourself",
    "start": "205200",
    "end": "206940"
  },
  {
    "text": "let's jump on over to a terminal and",
    "start": "206940",
    "end": "208920"
  },
  {
    "text": "clone down the repo then we can use it",
    "start": "208920",
    "end": "210900"
  },
  {
    "text": "for obtaining our data and loading it in",
    "start": "210900",
    "end": "212879"
  },
  {
    "text": "two timescale DB now this repo uses",
    "start": "212879",
    "end": "215519"
  },
  {
    "text": "python so you'll need to make sure you",
    "start": "215519",
    "end": "217200"
  },
  {
    "text": "have Python 3 installed if you check the",
    "start": "217200",
    "end": "219540"
  },
  {
    "text": "readme of the project it should give you",
    "start": "219540",
    "end": "221040"
  },
  {
    "text": "instructions on how to do this for your",
    "start": "221040",
    "end": "222720"
  },
  {
    "text": "operating system next it's a good",
    "start": "222720",
    "end": "225000"
  },
  {
    "text": "practice to make a virtual environment",
    "start": "225000",
    "end": "226739"
  },
  {
    "text": "to install our dependencies into you can",
    "start": "226739",
    "end": "228900"
  },
  {
    "text": "do this using the following command in",
    "start": "228900",
    "end": "230760"
  },
  {
    "text": "your terminal then you can enter the",
    "start": "230760",
    "end": "232739"
  },
  {
    "text": "virtual environment and install it all",
    "start": "232739",
    "end": "234360"
  },
  {
    "text": "the dependencies using pip with the",
    "start": "234360",
    "end": "236760"
  },
  {
    "text": "requirements installed we can then go",
    "start": "236760",
    "end": "238080"
  },
  {
    "text": "ahead and run the download script in the",
    "start": "238080",
    "end": "239940"
  },
  {
    "text": "source directory this script will take a",
    "start": "239940",
    "end": "242400"
  },
  {
    "text": "little while to complete this will work",
    "start": "242400",
    "end": "244560"
  },
  {
    "text": "eventually but it seems like the New",
    "start": "244560",
    "end": "246180"
  },
  {
    "text": "York City's data repository is rate",
    "start": "246180",
    "end": "248099"
  },
  {
    "text": "limited and every soft in the script",
    "start": "248099",
    "end": "250019"
  },
  {
    "text": "will hit it so it waits for 10 minutes",
    "start": "250019",
    "end": "251760"
  },
  {
    "text": "before continuing all in all it'll",
    "start": "251760",
    "end": "254159"
  },
  {
    "text": "probably take about 30 minutes for this",
    "start": "254159",
    "end": "255420"
  },
  {
    "text": "to be done",
    "start": "255420",
    "end": "256560"
  },
  {
    "text": "once the data is downloaded we now need",
    "start": "256560",
    "end": "258720"
  },
  {
    "text": "an instance of time scale DB in order to",
    "start": "258720",
    "end": "260940"
  },
  {
    "text": "load our data into here we actually have",
    "start": "260940",
    "end": "263280"
  },
  {
    "text": "three options the first is to self-host",
    "start": "263280",
    "end": "265979"
  },
  {
    "text": "a local version timescale have some",
    "start": "265979",
    "end": "268199"
  },
  {
    "text": "really nice documentation on their",
    "start": "268199",
    "end": "269580"
  },
  {
    "text": "website on how to do this with",
    "start": "269580",
    "end": "271259"
  },
  {
    "text": "instructions for Linux Windows Mac OS or",
    "start": "271259",
    "end": "274080"
  },
  {
    "text": "from source for me that's a little bit",
    "start": "274080",
    "end": "276780"
  },
  {
    "text": "too much setup though even though the",
    "start": "276780",
    "end": "278580"
  },
  {
    "text": "instructions are really great",
    "start": "278580",
    "end": "280620"
  },
  {
    "text": "the second option if we still want to",
    "start": "280620",
    "end": "282840"
  },
  {
    "text": "run it locally is to use docker",
    "start": "282840",
    "end": "284940"
  },
  {
    "text": "timescale provides Docker images we can",
    "start": "284940",
    "end": "286919"
  },
  {
    "text": "use to get running but if you're on Mac",
    "start": "286919",
    "end": "288540"
  },
  {
    "text": "OS then this is going to be slow due to",
    "start": "288540",
    "end": "290580"
  },
  {
    "text": "the hypervisor so the best option for",
    "start": "290580",
    "end": "293280"
  },
  {
    "text": "this video in my opinion is to use time",
    "start": "293280",
    "end": "295199"
  },
  {
    "text": "scales managed service in which they'll",
    "start": "295199",
    "end": "297660"
  },
  {
    "text": "handle all of the configuration and",
    "start": "297660",
    "end": "299280"
  },
  {
    "text": "setup for us",
    "start": "299280",
    "end": "300660"
  },
  {
    "text": "there's also a 30-day free trial as well",
    "start": "300660",
    "end": "303360"
  },
  {
    "text": "which is completely free",
    "start": "303360",
    "end": "305580"
  },
  {
    "text": "to do so all you need to do is sign up",
    "start": "305580",
    "end": "307380"
  },
  {
    "text": "on the website and get started and it",
    "start": "307380",
    "end": "309419"
  },
  {
    "text": "won't cost you anything you don't even",
    "start": "309419",
    "end": "311040"
  },
  {
    "text": "need to enter any billing details you",
    "start": "311040",
    "end": "313440"
  },
  {
    "text": "can do so by heading over to",
    "start": "313440",
    "end": "314699"
  },
  {
    "text": "timescale.com or clicking the link in",
    "start": "314699",
    "end": "316919"
  },
  {
    "text": "the description once you've signed up",
    "start": "316919",
    "end": "318720"
  },
  {
    "text": "you can create a new service like I am",
    "start": "318720",
    "end": "320520"
  },
  {
    "text": "by clicking the no thanks button you'll",
    "start": "320520",
    "end": "322800"
  },
  {
    "text": "then be prompted to choose a region",
    "start": "322800",
    "end": "324240"
  },
  {
    "text": "which I'm going to go for us East one",
    "start": "324240",
    "end": "326580"
  },
  {
    "text": "and the size of our node which is the",
    "start": "326580",
    "end": "330060"
  },
  {
    "text": "compute for me I'm going to choose the",
    "start": "330060",
    "end": "332280"
  },
  {
    "text": "biggest node I can because well it's",
    "start": "332280",
    "end": "334560"
  },
  {
    "text": "free but we'll make sure to cancel this",
    "start": "334560",
    "end": "336479"
  },
  {
    "text": "when we're done",
    "start": "336479",
    "end": "337800"
  },
  {
    "text": "finally you just need to give the",
    "start": "337800",
    "end": "339360"
  },
  {
    "text": "service a name I'm going to call mine",
    "start": "339360",
    "end": "341340"
  },
  {
    "text": "New York City Taxi dreams all that's",
    "start": "341340",
    "end": "344400"
  },
  {
    "text": "left is to click create once that's done",
    "start": "344400",
    "end": "346500"
  },
  {
    "text": "your deployment should be in progress",
    "start": "346500",
    "end": "347820"
  },
  {
    "text": "but you're presented with your",
    "start": "347820",
    "end": "349020"
  },
  {
    "text": "credentials",
    "start": "349020",
    "end": "350460"
  },
  {
    "text": "I'd go ahead and download and save the",
    "start": "350460",
    "end": "352380"
  },
  {
    "text": "cheat sheet just so that you've got them",
    "start": "352380",
    "end": "353759"
  },
  {
    "text": "on disk",
    "start": "353759",
    "end": "354900"
  },
  {
    "text": "it's also a good idea to take a note of",
    "start": "354900",
    "end": "356699"
  },
  {
    "text": "your password because it won't be shown",
    "start": "356699",
    "end": "358139"
  },
  {
    "text": "to you again however if you do misplace",
    "start": "358139",
    "end": "360419"
  },
  {
    "text": "it you can just reset it don't ask me",
    "start": "360419",
    "end": "362880"
  },
  {
    "text": "how I know that next you'll need to",
    "start": "362880",
    "end": "364800"
  },
  {
    "text": "install P SQL in real machine",
    "start": "364800",
    "end": "367380"
  },
  {
    "text": "fortunately there are instructions on",
    "start": "367380",
    "end": "369000"
  },
  {
    "text": "how to do this and in my repo so I'd",
    "start": "369000",
    "end": "370800"
  },
  {
    "text": "recommend following those for the next",
    "start": "370800",
    "end": "372240"
  },
  {
    "text": "step once you've done so and your",
    "start": "372240",
    "end": "374400"
  },
  {
    "text": "deployment is ready go ahead and copy",
    "start": "374400",
    "end": "376199"
  },
  {
    "text": "the P SQL command on the screen jump",
    "start": "376199",
    "end": "378360"
  },
  {
    "text": "over to your terminal and paste it in so",
    "start": "378360",
    "end": "380280"
  },
  {
    "text": "you're able to connect to your database",
    "start": "380280",
    "end": "382560"
  },
  {
    "text": "once inside you should be greeted with a",
    "start": "382560",
    "end": "384720"
  },
  {
    "text": "prompt saying tsdb which stands for time",
    "start": "384720",
    "end": "387780"
  },
  {
    "text": "series database we can confirm that time",
    "start": "387780",
    "end": "390300"
  },
  {
    "text": "scale is installed by using the",
    "start": "390300",
    "end": "391860"
  },
  {
    "text": "following command of backslash DX and",
    "start": "391860",
    "end": "394800"
  },
  {
    "text": "here we can see the entry for time scale",
    "start": "394800",
    "end": "396660"
  },
  {
    "text": "in the extensions very cool",
    "start": "396660",
    "end": "399120"
  },
  {
    "text": "okay to quit psql go ahead and type in",
    "start": "399120",
    "end": "401880"
  },
  {
    "text": "backslash Q or press Ctrl and D next we",
    "start": "401880",
    "end": "405120"
  },
  {
    "text": "need to create some tables for our data",
    "start": "405120",
    "end": "407039"
  },
  {
    "text": "here is a quick diagram of what we're",
    "start": "407039",
    "end": "409080"
  },
  {
    "text": "going to store we basically want to have",
    "start": "409080",
    "end": "411060"
  },
  {
    "text": "two different tables the first table is",
    "start": "411060",
    "end": "413340"
  },
  {
    "text": "our cap type which will store our two",
    "start": "413340",
    "end": "415259"
  },
  {
    "text": "cap types in either green or yellow the",
    "start": "415259",
    "end": "417780"
  },
  {
    "text": "second table is going to be used to",
    "start": "417780",
    "end": "419460"
  },
  {
    "text": "store our individual trip data in this",
    "start": "419460",
    "end": "421680"
  },
  {
    "text": "table we're going to have the following",
    "start": "421680",
    "end": "423360"
  },
  {
    "text": "columns both the startled at timestamp",
    "start": "423360",
    "end": "425639"
  },
  {
    "text": "and the ended out timestamp the distance",
    "start": "425639",
    "end": "427800"
  },
  {
    "text": "of the trip the amount that was tipped",
    "start": "427800",
    "end": "430259"
  },
  {
    "text": "to the driver and the total amount the",
    "start": "430259",
    "end": "432780"
  },
  {
    "text": "person paid",
    "start": "432780",
    "end": "434160"
  },
  {
    "text": "finally the last column is the cab type",
    "start": "434160",
    "end": "436440"
  },
  {
    "text": "ID which is a foreign reference to our",
    "start": "436440",
    "end": "439440"
  },
  {
    "text": "cap type table as well as these two",
    "start": "439440",
    "end": "441539"
  },
  {
    "text": "tables we're actually going to add a",
    "start": "441539",
    "end": "443220"
  },
  {
    "text": "third table this table called trips",
    "start": "443220",
    "end": "445259"
  },
  {
    "text": "hyper is identical to our trips table",
    "start": "445259",
    "end": "447419"
  },
  {
    "text": "and has the exact same columns however",
    "start": "447419",
    "end": "450300"
  },
  {
    "text": "it is different in one major way",
    "start": "450300",
    "end": "453300"
  },
  {
    "start": "453000",
    "end": "758000"
  },
  {
    "text": "time scale operates a little differently",
    "start": "453300",
    "end": "455520"
  },
  {
    "text": "to postgres while standard postgres",
    "start": "455520",
    "end": "457740"
  },
  {
    "text": "tables will work for our database we",
    "start": "457740",
    "end": "459840"
  },
  {
    "text": "actually want to use something called a",
    "start": "459840",
    "end": "461160"
  },
  {
    "text": "hyper table when it comes to our trip",
    "start": "461160",
    "end": "462599"
  },
  {
    "text": "data a hyper table is basically a",
    "start": "462599",
    "end": "465060"
  },
  {
    "text": "postgres table that has been upgraded",
    "start": "465060",
    "end": "466919"
  },
  {
    "text": "this upgrade which is handled by",
    "start": "466919",
    "end": "469080"
  },
  {
    "text": "timescale DB will turn our table into a",
    "start": "469080",
    "end": "472020"
  },
  {
    "text": "partitioned table the kind I mentioned",
    "start": "472020",
    "end": "474180"
  },
  {
    "text": "before however the difference here is",
    "start": "474180",
    "end": "476400"
  },
  {
    "text": "that time scale is creating and",
    "start": "476400",
    "end": "477960"
  },
  {
    "text": "maintaining those partitions for us",
    "start": "477960",
    "end": "479520"
  },
  {
    "text": "which gives us the benefit of the",
    "start": "479520",
    "end": "481440"
  },
  {
    "text": "partitions without the overhead",
    "start": "481440",
    "end": "483419"
  },
  {
    "text": "let's jump back to our terminal to see",
    "start": "483419",
    "end": "485520"
  },
  {
    "text": "how we can actually create a hyper table",
    "start": "485520",
    "end": "487319"
  },
  {
    "text": "if you head back on over to the project",
    "start": "487319",
    "end": "489660"
  },
  {
    "text": "code and open up the migrations",
    "start": "489660",
    "end": "491520"
  },
  {
    "text": "directory you should see three SQL files",
    "start": "491520",
    "end": "494039"
  },
  {
    "text": "inside of here",
    "start": "494039",
    "end": "496759"
  },
  {
    "text": "inside of this file you can see we're",
    "start": "499740",
    "end": "501419"
  },
  {
    "text": "creating our two trip tables we're doing",
    "start": "501419",
    "end": "504000"
  },
  {
    "text": "this using the create table statement",
    "start": "504000",
    "end": "505879"
  },
  {
    "text": "you'll notice that our two tables are",
    "start": "505879",
    "end": "508319"
  },
  {
    "text": "exactly the same and contain the same",
    "start": "508319",
    "end": "510120"
  },
  {
    "text": "columns we saw earlier this is because",
    "start": "510120",
    "end": "512459"
  },
  {
    "text": "creating a hyper table is a two-step",
    "start": "512459",
    "end": "514560"
  },
  {
    "text": "process and the first step is to create",
    "start": "514560",
    "end": "516659"
  },
  {
    "text": "a standard postgres table the one we're",
    "start": "516659",
    "end": "519120"
  },
  {
    "text": "going to upgrade into a hyper table is",
    "start": "519120",
    "end": "521039"
  },
  {
    "text": "the table named trip underscore hyper if",
    "start": "521039",
    "end": "523860"
  },
  {
    "text": "you scroll down past our table",
    "start": "523860",
    "end": "525120"
  },
  {
    "text": "definitions you'll see another select",
    "start": "525120",
    "end": "527160"
  },
  {
    "text": "query this is the second step in our",
    "start": "527160",
    "end": "529800"
  },
  {
    "text": "hypertable creation",
    "start": "529800",
    "end": "531959"
  },
  {
    "text": "in this query we're calling the create",
    "start": "531959",
    "end": "534120"
  },
  {
    "text": "hypertable function to turn our Trip's",
    "start": "534120",
    "end": "536399"
  },
  {
    "text": "hyper table into a hyper table",
    "start": "536399",
    "end": "539220"
  },
  {
    "text": "the first parameter is the table name",
    "start": "539220",
    "end": "541440"
  },
  {
    "text": "but the second parameter is the column",
    "start": "541440",
    "end": "543600"
  },
  {
    "text": "we want to Partition by",
    "start": "543600",
    "end": "545459"
  },
  {
    "text": "we can actually choose multiple columns",
    "start": "545459",
    "end": "547019"
  },
  {
    "text": "for this if we wanted to but as most of",
    "start": "547019",
    "end": "549180"
  },
  {
    "text": "our queries are going to be bucketed by",
    "start": "549180",
    "end": "550860"
  },
  {
    "text": "our trips start time that feels like a",
    "start": "550860",
    "end": "552959"
  },
  {
    "text": "worthwhile column to partition based off",
    "start": "552959",
    "end": "554700"
  },
  {
    "text": "of what's really nice about time skill",
    "start": "554700",
    "end": "556800"
  },
  {
    "text": "is that you don't need to start with an",
    "start": "556800",
    "end": "558540"
  },
  {
    "text": "empty table in order to convert it to a",
    "start": "558540",
    "end": "560580"
  },
  {
    "text": "hyper table",
    "start": "560580",
    "end": "561720"
  },
  {
    "text": "this can be achieved by using the",
    "start": "561720",
    "end": "563820"
  },
  {
    "text": "migrate data argument in the create",
    "start": "563820",
    "end": "565680"
  },
  {
    "text": "hypertable function although it can take",
    "start": "565680",
    "end": "568140"
  },
  {
    "text": "a long time for this to actually migrate",
    "start": "568140",
    "end": "570060"
  },
  {
    "text": "okay now that we know how to create a",
    "start": "570060",
    "end": "572279"
  },
  {
    "text": "hyper table let's actually go ahead and",
    "start": "572279",
    "end": "574019"
  },
  {
    "text": "do it to do so you're going to need a",
    "start": "574019",
    "end": "576240"
  },
  {
    "text": "tool called migrate this is what we're",
    "start": "576240",
    "end": "578459"
  },
  {
    "text": "going to use to actually run our",
    "start": "578459",
    "end": "579839"
  },
  {
    "text": "database migrations there's instructions",
    "start": "579839",
    "end": "582060"
  },
  {
    "text": "on how to install this tool in the",
    "start": "582060",
    "end": "583680"
  },
  {
    "text": "project readme once you have the migrate",
    "start": "583680",
    "end": "586560"
  },
  {
    "text": "CLI installed you then need to set up",
    "start": "586560",
    "end": "588720"
  },
  {
    "text": "your database URL as an environment",
    "start": "588720",
    "end": "590519"
  },
  {
    "text": "variable you can do this by first",
    "start": "590519",
    "end": "592260"
  },
  {
    "text": "opening up the dot EMV file found in the",
    "start": "592260",
    "end": "594480"
  },
  {
    "text": "project root and setting the database",
    "start": "594480",
    "end": "596339"
  },
  {
    "text": "URL to the connection string provided by",
    "start": "596339",
    "end": "598620"
  },
  {
    "text": "timescale DB once that's done you can",
    "start": "598620",
    "end": "600959"
  },
  {
    "text": "then run the database migrations by",
    "start": "600959",
    "end": "602640"
  },
  {
    "text": "running the following makefile command",
    "start": "602640",
    "end": "604560"
  },
  {
    "text": "now we can think about loading in our",
    "start": "604560",
    "end": "606540"
  },
  {
    "text": "data I've written up another python",
    "start": "606540",
    "end": "608820"
  },
  {
    "text": "script which will automatically load in",
    "start": "608820",
    "end": "610620"
  },
  {
    "text": "the data for us now that it's been",
    "start": "610620",
    "end": "612540"
  },
  {
    "text": "downloaded to use it first make sure",
    "start": "612540",
    "end": "615000"
  },
  {
    "text": "you're inside of your python virtual",
    "start": "615000",
    "end": "616680"
  },
  {
    "text": "environment you can do this by calling",
    "start": "616680",
    "end": "618480"
  },
  {
    "text": "the source command we used earlier",
    "start": "618480",
    "end": "620700"
  },
  {
    "text": "with that done you can now run the load",
    "start": "620700",
    "end": "622800"
  },
  {
    "text": "script using the following command",
    "start": "622800",
    "end": "624779"
  },
  {
    "text": "now just to be warned this is going to",
    "start": "624779",
    "end": "626519"
  },
  {
    "text": "transfer about 160 gigabytes worth of",
    "start": "626519",
    "end": "629160"
  },
  {
    "text": "data and it took me about 12 hours to do",
    "start": "629160",
    "end": "632339"
  },
  {
    "text": "so due to the rate I was uploading at I",
    "start": "632339",
    "end": "635220"
  },
  {
    "text": "also tested this by running my upload",
    "start": "635220",
    "end": "637080"
  },
  {
    "text": "script on an AWS ec2 node which did",
    "start": "637080",
    "end": "640080"
  },
  {
    "text": "increase my upload speed so your mileage",
    "start": "640080",
    "end": "642600"
  },
  {
    "text": "may vary if for some reason it fails to",
    "start": "642600",
    "end": "645120"
  },
  {
    "text": "upload at any point the progress will be",
    "start": "645120",
    "end": "647100"
  },
  {
    "text": "saved however so you can come back to",
    "start": "647100",
    "end": "649079"
  },
  {
    "text": "this and keep restarting it honestly",
    "start": "649079",
    "end": "651360"
  },
  {
    "text": "you'll probably want to do this as an",
    "start": "651360",
    "end": "652920"
  },
  {
    "text": "overnight operation once it's done we",
    "start": "652920",
    "end": "655500"
  },
  {
    "text": "can connect to our database and check",
    "start": "655500",
    "end": "656880"
  },
  {
    "text": "the total size using the following",
    "start": "656880",
    "end": "658560"
  },
  {
    "text": "command in total about 260 gigabytes",
    "start": "658560",
    "end": "661620"
  },
  {
    "text": "pretty big that should be perfect for",
    "start": "661620",
    "end": "663660"
  },
  {
    "text": "some speed comparisons which we're going",
    "start": "663660",
    "end": "665940"
  },
  {
    "text": "to do running some queries the first",
    "start": "665940",
    "end": "668459"
  },
  {
    "text": "query we're going to do is an aggregate",
    "start": "668459",
    "end": "670380"
  },
  {
    "text": "query we're basically going to get the",
    "start": "670380",
    "end": "672540"
  },
  {
    "text": "min max and average total amount for",
    "start": "672540",
    "end": "675180"
  },
  {
    "text": "every trip that was taken in 2022 that",
    "start": "675180",
    "end": "678000"
  },
  {
    "text": "cost more than zero dollars and zero",
    "start": "678000",
    "end": "680040"
  },
  {
    "text": "cents but we're gonna group it by month",
    "start": "680040",
    "end": "682500"
  },
  {
    "text": "so we should only get 12 results back",
    "start": "682500",
    "end": "684480"
  },
  {
    "text": "we'll first run this query against our",
    "start": "684480",
    "end": "687120"
  },
  {
    "text": "standard trip table to see how long it",
    "start": "687120",
    "end": "689100"
  },
  {
    "text": "takes as a baseline comparison I'll also",
    "start": "689100",
    "end": "691620"
  },
  {
    "text": "add a stopwatch on screen so we can",
    "start": "691620",
    "end": "693480"
  },
  {
    "text": "easily time this",
    "start": "693480",
    "end": "695880"
  },
  {
    "text": "so wow that was pretty long the total",
    "start": "695880",
    "end": "698940"
  },
  {
    "text": "amount of time was about 12 and a half",
    "start": "698940",
    "end": "700620"
  },
  {
    "text": "minutes so yeah a long time let's try",
    "start": "700620",
    "end": "704459"
  },
  {
    "text": "the same query again but we're going to",
    "start": "704459",
    "end": "706320"
  },
  {
    "text": "run it against our trips hyper table",
    "start": "706320",
    "end": "708000"
  },
  {
    "text": "instead",
    "start": "708000",
    "end": "710220"
  },
  {
    "text": "and it's done blazing fast about five",
    "start": "710220",
    "end": "713880"
  },
  {
    "text": "seconds in total if we head over to the",
    "start": "713880",
    "end": "716579"
  },
  {
    "text": "time scale website we can actually look",
    "start": "716579",
    "end": "718019"
  },
  {
    "text": "at the query metrics here we can see on",
    "start": "718019",
    "end": "720660"
  },
  {
    "text": "our standard postgres table it took",
    "start": "720660",
    "end": "722279"
  },
  {
    "text": "about 761 seconds on average and for our",
    "start": "722279",
    "end": "725459"
  },
  {
    "text": "trips hyper table about 5.2 seconds so",
    "start": "725459",
    "end": "728880"
  },
  {
    "text": "that's a couple of orders of magnitude",
    "start": "728880",
    "end": "731100"
  },
  {
    "text": "which is pretty impressive considering",
    "start": "731100",
    "end": "733019"
  },
  {
    "text": "it was only one line of SQL to actually",
    "start": "733019",
    "end": "734880"
  },
  {
    "text": "create a hyper table but maybe it's just",
    "start": "734880",
    "end": "737640"
  },
  {
    "text": "the query right well this performance",
    "start": "737640",
    "end": "740040"
  },
  {
    "text": "increase will translate to any query",
    "start": "740040",
    "end": "741839"
  },
  {
    "text": "that uses the start timestamp as a range",
    "start": "741839",
    "end": "744180"
  },
  {
    "text": "I have a bunch of other queries in the",
    "start": "744180",
    "end": "746640"
  },
  {
    "text": "repo that you can use to actually see",
    "start": "746640",
    "end": "748380"
  },
  {
    "text": "this in action",
    "start": "748380",
    "end": "749940"
  },
  {
    "text": "so yeah a lot of performance increase",
    "start": "749940",
    "end": "752279"
  },
  {
    "text": "for very little effort but time scale DB",
    "start": "752279",
    "end": "755220"
  },
  {
    "text": "provides a way for us to go even faster",
    "start": "755220",
    "end": "758279"
  },
  {
    "start": "758000",
    "end": "999000"
  },
  {
    "text": "one of the biggest time syncs with big",
    "start": "758279",
    "end": "760500"
  },
  {
    "text": "data is the amount of time it can take",
    "start": "760500",
    "end": "762120"
  },
  {
    "text": "to compute an aggregation",
    "start": "762120",
    "end": "764220"
  },
  {
    "text": "a common solution within postgres is to",
    "start": "764220",
    "end": "766260"
  },
  {
    "text": "use something called a materialized view",
    "start": "766260",
    "end": "768000"
  },
  {
    "text": "this allows you to effectively",
    "start": "768000",
    "end": "769980"
  },
  {
    "text": "pre-compute queries and store them for",
    "start": "769980",
    "end": "772380"
  },
  {
    "text": "serving up later on if you have a large",
    "start": "772380",
    "end": "774720"
  },
  {
    "text": "aggregation that you need to perform",
    "start": "774720",
    "end": "776339"
  },
  {
    "text": "often then this is a decent approach for",
    "start": "776339",
    "end": "778920"
  },
  {
    "text": "improving performance but there are a",
    "start": "778920",
    "end": "781260"
  },
  {
    "text": "couple of caveats with this technique",
    "start": "781260",
    "end": "782760"
  },
  {
    "text": "the first is that you need to manually",
    "start": "782760",
    "end": "784860"
  },
  {
    "text": "tell the materialized view to update",
    "start": "784860",
    "end": "786899"
  },
  {
    "text": "which isn't a huge issue but it does",
    "start": "786899",
    "end": "788940"
  },
  {
    "text": "mean your data will be stale for a",
    "start": "788940",
    "end": "790500"
  },
  {
    "text": "period of time in between those update",
    "start": "790500",
    "end": "792300"
  },
  {
    "text": "Windows",
    "start": "792300",
    "end": "793260"
  },
  {
    "text": "the second caveat is that whenever you",
    "start": "793260",
    "end": "795600"
  },
  {
    "text": "do refresh you need to calculate the",
    "start": "795600",
    "end": "797519"
  },
  {
    "text": "entire materialized view from scratch",
    "start": "797519",
    "end": "799440"
  },
  {
    "text": "when it comes to time series databases",
    "start": "799440",
    "end": "801660"
  },
  {
    "text": "this can be wasteful as data already",
    "start": "801660",
    "end": "803639"
  },
  {
    "text": "written rarely changes",
    "start": "803639",
    "end": "805680"
  },
  {
    "text": "time scale solves both these problems",
    "start": "805680",
    "end": "807600"
  },
  {
    "text": "with its continuous aggregations feature",
    "start": "807600",
    "end": "809639"
  },
  {
    "text": "which Works hand in hand with Hyper",
    "start": "809639",
    "end": "811980"
  },
  {
    "text": "tables allowing it to both continuously",
    "start": "811980",
    "end": "814260"
  },
  {
    "text": "compute data as it comes into the",
    "start": "814260",
    "end": "816000"
  },
  {
    "text": "database and only recomputing rows that",
    "start": "816000",
    "end": "818459"
  },
  {
    "text": "have been touched so let's go ahead and",
    "start": "818459",
    "end": "820680"
  },
  {
    "text": "create a continuous aggregation if you",
    "start": "820680",
    "end": "822779"
  },
  {
    "text": "head back over to our migrations",
    "start": "822779",
    "end": "823980"
  },
  {
    "text": "directory and open up the file beginning",
    "start": "823980",
    "end": "825959"
  },
  {
    "text": "with zero zero two inside you'll see how",
    "start": "825959",
    "end": "828240"
  },
  {
    "text": "we're creating our continuous aggregate",
    "start": "828240",
    "end": "830220"
  },
  {
    "text": "similar to hyper tables this is a",
    "start": "830220",
    "end": "832440"
  },
  {
    "text": "two-step process and the first step is",
    "start": "832440",
    "end": "834839"
  },
  {
    "text": "to create a materialized view this is",
    "start": "834839",
    "end": "837300"
  },
  {
    "text": "done the same as you would do with",
    "start": "837300",
    "end": "838680"
  },
  {
    "text": "postgres however you'll notice that",
    "start": "838680",
    "end": "840360"
  },
  {
    "text": "we're using the with keyword online",
    "start": "840360",
    "end": "842399"
  },
  {
    "text": "number four this means we're defining",
    "start": "842399",
    "end": "844440"
  },
  {
    "text": "our materialized view as being a time",
    "start": "844440",
    "end": "846540"
  },
  {
    "text": "scale DB dot continuous one which is",
    "start": "846540",
    "end": "848700"
  },
  {
    "text": "provided by the time scale DPE plugin",
    "start": "848700",
    "end": "851579"
  },
  {
    "text": "other than that all this materialized",
    "start": "851579",
    "end": "853620"
  },
  {
    "text": "view is doing is aggregating based on",
    "start": "853620",
    "end": "855839"
  },
  {
    "text": "the same query we were doing before but",
    "start": "855839",
    "end": "858360"
  },
  {
    "text": "rather than bucketing by month we're",
    "start": "858360",
    "end": "860220"
  },
  {
    "text": "bucketing by day which gives us a bit",
    "start": "860220",
    "end": "862980"
  },
  {
    "text": "more flexibility for queries",
    "start": "862980",
    "end": "865139"
  },
  {
    "text": "underneath the materialized view is",
    "start": "865139",
    "end": "866880"
  },
  {
    "text": "where we add the second part to our",
    "start": "866880",
    "end": "868680"
  },
  {
    "text": "continuous aggregate here we're creating",
    "start": "868680",
    "end": "870779"
  },
  {
    "text": "a refresh policy for our continuous",
    "start": "870779",
    "end": "872760"
  },
  {
    "text": "aggregation what this is doing is",
    "start": "872760",
    "end": "874680"
  },
  {
    "text": "refreshing data in our database from",
    "start": "874680",
    "end": "876720"
  },
  {
    "text": "between one year and one month ago and",
    "start": "876720",
    "end": "879240"
  },
  {
    "text": "doing so every hour",
    "start": "879240",
    "end": "881100"
  },
  {
    "text": "and that is all we need to set up a",
    "start": "881100",
    "end": "883139"
  },
  {
    "text": "continuous aggregation",
    "start": "883139",
    "end": "884699"
  },
  {
    "text": "let's go ahead and apply this to our",
    "start": "884699",
    "end": "886560"
  },
  {
    "text": "database we can do so by using the",
    "start": "886560",
    "end": "889019"
  },
  {
    "text": "following make Command which will run",
    "start": "889019",
    "end": "890760"
  },
  {
    "text": "our database migration and do an initial",
    "start": "890760",
    "end": "893160"
  },
  {
    "text": "calculation of our materialized view",
    "start": "893160",
    "end": "895260"
  },
  {
    "text": "this will take some time as it has to",
    "start": "895260",
    "end": "897360"
  },
  {
    "text": "calculate all of the data this is the",
    "start": "897360",
    "end": "899399"
  },
  {
    "text": "kind of speed you'd expect if you",
    "start": "899399",
    "end": "900899"
  },
  {
    "text": "refresh the materialize view manually",
    "start": "900899",
    "end": "902820"
  },
  {
    "text": "once that's done let's go ahead and",
    "start": "902820",
    "end": "904440"
  },
  {
    "text": "check that our continuous aggregate has",
    "start": "904440",
    "end": "906060"
  },
  {
    "text": "been created we can do this by",
    "start": "906060",
    "end": "908040"
  },
  {
    "text": "connecting to our time scale database",
    "start": "908040",
    "end": "909540"
  },
  {
    "text": "and running the following SQL",
    "start": "909540",
    "end": "911760"
  },
  {
    "text": "as we can see our continuous aggregate",
    "start": "911760",
    "end": "913860"
  },
  {
    "text": "has been created we can now go ahead and",
    "start": "913860",
    "end": "916380"
  },
  {
    "text": "query against this view we're going to",
    "start": "916380",
    "end": "918540"
  },
  {
    "text": "run the same aggregate that we did",
    "start": "918540",
    "end": "920279"
  },
  {
    "text": "before but against our materialized view",
    "start": "920279",
    "end": "922019"
  },
  {
    "text": "instead of our hyper table running this",
    "start": "922019",
    "end": "924120"
  },
  {
    "text": "query you can see that it's pretty much",
    "start": "924120",
    "end": "925620"
  },
  {
    "text": "instant if I analyze this query you can",
    "start": "925620",
    "end": "928500"
  },
  {
    "text": "see in total it takes about 10",
    "start": "928500",
    "end": "929820"
  },
  {
    "text": "milliseconds which is a few more orders",
    "start": "929820",
    "end": "932639"
  },
  {
    "text": "of magnitude faster not only this we",
    "start": "932639",
    "end": "935100"
  },
  {
    "text": "also have this aggregate on a much more",
    "start": "935100",
    "end": "936839"
  },
  {
    "text": "granular level days instead of months",
    "start": "936839",
    "end": "939120"
  },
  {
    "text": "which enables us more flexibility with",
    "start": "939120",
    "end": "941399"
  },
  {
    "text": "our queries so this is great but it's no",
    "start": "941399",
    "end": "944100"
  },
  {
    "text": "better than a materialized view let's",
    "start": "944100",
    "end": "946500"
  },
  {
    "text": "actually see the continuous aggregate",
    "start": "946500",
    "end": "948120"
  },
  {
    "text": "part in action to do so we have one last",
    "start": "948120",
    "end": "950760"
  },
  {
    "text": "bit of data to load which is all of the",
    "start": "950760",
    "end": "952680"
  },
  {
    "text": "data from 2023 and we have one last",
    "start": "952680",
    "end": "955560"
  },
  {
    "text": "script to load this with you can do so",
    "start": "955560",
    "end": "957720"
  },
  {
    "text": "using the following command make sure",
    "start": "957720",
    "end": "960180"
  },
  {
    "text": "you're inside your virtual environment",
    "start": "960180",
    "end": "961680"
  },
  {
    "text": "before running the script however",
    "start": "961680",
    "end": "964199"
  },
  {
    "text": "and after a few minutes all of our data",
    "start": "964199",
    "end": "966420"
  },
  {
    "text": "for 2023 will be loaded in next we have",
    "start": "966420",
    "end": "969300"
  },
  {
    "text": "two options the first is to wait to the",
    "start": "969300",
    "end": "971339"
  },
  {
    "text": "end of the hour for the continuous",
    "start": "971339",
    "end": "972839"
  },
  {
    "text": "aggregate to automatically refresh or we",
    "start": "972839",
    "end": "975180"
  },
  {
    "text": "can force this manually I'm going to",
    "start": "975180",
    "end": "977100"
  },
  {
    "text": "force this manually to show you how",
    "start": "977100",
    "end": "978480"
  },
  {
    "text": "quick it actually is using the following",
    "start": "978480",
    "end": "980880"
  },
  {
    "text": "command I'm refreshing the aggregate for",
    "start": "980880",
    "end": "982860"
  },
  {
    "text": "only the data in 2023 and as you can see",
    "start": "982860",
    "end": "986220"
  },
  {
    "text": "this partial refresh is much quicker now",
    "start": "986220",
    "end": "989160"
  },
  {
    "text": "if I connect to the database I can also",
    "start": "989160",
    "end": "991139"
  },
  {
    "text": "query for data in 2023",
    "start": "991139",
    "end": "993540"
  },
  {
    "text": "as you can see this offers the power of",
    "start": "993540",
    "end": "995940"
  },
  {
    "text": "a materialized view with the benefit of",
    "start": "995940",
    "end": "997800"
  },
  {
    "text": "not needing to refresh the entire thing",
    "start": "997800",
    "end": "1000320"
  },
  {
    "start": "999000",
    "end": "1032000"
  },
  {
    "text": "so that's a surface level look at",
    "start": "1000320",
    "end": "1002540"
  },
  {
    "text": "timescale DB by using timescale DB we",
    "start": "1002540",
    "end": "1005360"
  },
  {
    "text": "were able to take a query that took 12",
    "start": "1005360",
    "end": "1007220"
  },
  {
    "text": "and a half minutes down to 10",
    "start": "1007220",
    "end": "1008899"
  },
  {
    "text": "milliseconds all whilst remaining within",
    "start": "1008899",
    "end": "1011300"
  },
  {
    "text": "a postgres interface there's a number of",
    "start": "1011300",
    "end": "1013940"
  },
  {
    "text": "other features within time scale that I",
    "start": "1013940",
    "end": "1015800"
  },
  {
    "text": "haven't even touched things like",
    "start": "1015800",
    "end": "1017360"
  },
  {
    "text": "compression or hyper functions if you'd",
    "start": "1017360",
    "end": "1019519"
  },
  {
    "text": "like to see more videos on timescale DB",
    "start": "1019519",
    "end": "1021380"
  },
  {
    "text": "then please let me know in the comments",
    "start": "1021380",
    "end": "1023000"
  },
  {
    "text": "down below a big thank you to timescale",
    "start": "1023000",
    "end": "1025459"
  },
  {
    "text": "for sponsoring this video and a big",
    "start": "1025459",
    "end": "1026959"
  },
  {
    "text": "thank you to everyone else for watching",
    "start": "1026959",
    "end": "1028339"
  },
  {
    "text": "I'll see you on the next one",
    "start": "1028339",
    "end": "1032199"
  }
]
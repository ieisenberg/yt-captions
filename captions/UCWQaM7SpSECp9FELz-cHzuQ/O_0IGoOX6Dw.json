[
  {
    "start": "0",
    "end": "102000"
  },
  {
    "text": "there's a concerning Trend at the moment",
    "start": "0",
    "end": "1979"
  },
  {
    "text": "considering apis they're getting too",
    "start": "1979",
    "end": "4799"
  },
  {
    "text": "expensive companies such as Reddit and",
    "start": "4799",
    "end": "8099"
  },
  {
    "text": "Microsoft have increased the amount they",
    "start": "8099",
    "end": "10019"
  },
  {
    "text": "charge just to programmatically access",
    "start": "10019",
    "end": "11760"
  },
  {
    "text": "their data the term API which used to",
    "start": "11760",
    "end": "14759"
  },
  {
    "text": "stand for application programming",
    "start": "14759",
    "end": "16680"
  },
  {
    "text": "interface has now become application",
    "start": "16680",
    "end": "18720"
  },
  {
    "text": "programming inflation",
    "start": "18720",
    "end": "20580"
  },
  {
    "text": "so what is a cash strap developer to do",
    "start": "20580",
    "end": "23820"
  },
  {
    "text": "well I set out on a journey to build my",
    "start": "23820",
    "end": "26340"
  },
  {
    "text": "own Reddit API",
    "start": "26340",
    "end": "28199"
  },
  {
    "text": "and I don't mean some knockoff version",
    "start": "28199",
    "end": "30300"
  },
  {
    "text": "of Reddit I mean a full-on replacement",
    "start": "30300",
    "end": "32700"
  },
  {
    "text": "API for Reddit using the same data but",
    "start": "32700",
    "end": "36000"
  },
  {
    "text": "without the associated cost now I know",
    "start": "36000",
    "end": "38820"
  },
  {
    "text": "what you're probably thinking dreams",
    "start": "38820",
    "end": "40739"
  },
  {
    "text": "it's impossible there's no way to beat",
    "start": "40739",
    "end": "43200"
  },
  {
    "text": "these company Executives in their Quest",
    "start": "43200",
    "end": "45059"
  },
  {
    "text": "For Greater profits well there's a",
    "start": "45059",
    "end": "47940"
  },
  {
    "text": "secret that these companies don't want",
    "start": "47940",
    "end": "49800"
  },
  {
    "text": "you to know",
    "start": "49800",
    "end": "50820"
  },
  {
    "text": "and that is the World Wide Web was built",
    "start": "50820",
    "end": "53160"
  },
  {
    "text": "on a principle of openness because of",
    "start": "53160",
    "end": "56399"
  },
  {
    "text": "this principle it's actually very",
    "start": "56399",
    "end": "58079"
  },
  {
    "text": "difficult for companies to close the",
    "start": "58079",
    "end": "60059"
  },
  {
    "text": "world wide webs open door policy some of",
    "start": "60059",
    "end": "63180"
  },
  {
    "text": "the approaches used to combat the web's",
    "start": "63180",
    "end": "64920"
  },
  {
    "text": "openness include rate limiting IP",
    "start": "64920",
    "end": "67200"
  },
  {
    "text": "blocking and capture these methods",
    "start": "67200",
    "end": "69960"
  },
  {
    "text": "however just cause workarounds to be",
    "start": "69960",
    "end": "71760"
  },
  {
    "text": "discovered which ends up causing a",
    "start": "71760",
    "end": "73500"
  },
  {
    "text": "technological arms race that very often",
    "start": "73500",
    "end": "75659"
  },
  {
    "text": "has a negative impact okay great so the",
    "start": "75659",
    "end": "78960"
  },
  {
    "text": "web is open but what does that mean for",
    "start": "78960",
    "end": "81180"
  },
  {
    "text": "us well it means we can acquire this",
    "start": "81180",
    "end": "83400"
  },
  {
    "text": "data from another source this source is",
    "start": "83400",
    "end": "86520"
  },
  {
    "text": "the web browser which has all of this",
    "start": "86520",
    "end": "88860"
  },
  {
    "text": "data available to it already the only",
    "start": "88860",
    "end": "91439"
  },
  {
    "text": "difference is this data is meant to be",
    "start": "91439",
    "end": "93119"
  },
  {
    "text": "available to humans instead of machines",
    "start": "93119",
    "end": "95460"
  },
  {
    "text": "this is just a minor technicality",
    "start": "95460",
    "end": "98100"
  },
  {
    "text": "however and we can use a technique to",
    "start": "98100",
    "end": "100200"
  },
  {
    "text": "pull data out of our browsers as a",
    "start": "100200",
    "end": "102600"
  },
  {
    "start": "102000",
    "end": "418000"
  },
  {
    "text": "machine this technique is called Web",
    "start": "102600",
    "end": "104759"
  },
  {
    "text": "scraping and is the process of",
    "start": "104759",
    "end": "106920"
  },
  {
    "text": "automating a web browser to pull data",
    "start": "106920",
    "end": "108840"
  },
  {
    "text": "from web pages which is exactly what we",
    "start": "108840",
    "end": "111540"
  },
  {
    "text": "want to do so how do we do that well",
    "start": "111540",
    "end": "114240"
  },
  {
    "text": "fortunately for us there are tools",
    "start": "114240",
    "end": "115860"
  },
  {
    "text": "already out there two of these tools are",
    "start": "115860",
    "end": "118079"
  },
  {
    "text": "playwright and Puppeteer which are",
    "start": "118079",
    "end": "120119"
  },
  {
    "text": "typically used for automated testing of",
    "start": "120119",
    "end": "122040"
  },
  {
    "text": "webcode however with a little",
    "start": "122040",
    "end": "124259"
  },
  {
    "text": "imagination we can also use these tools",
    "start": "124259",
    "end": "126360"
  },
  {
    "text": "to automate our data collection",
    "start": "126360",
    "end": "128399"
  },
  {
    "text": "let me show you how I did it the first",
    "start": "128399",
    "end": "130800"
  },
  {
    "text": "thing I wanted to do was to just get a",
    "start": "130800",
    "end": "132540"
  },
  {
    "text": "browser opened up and pointed to Reddit",
    "start": "132540",
    "end": "134400"
  },
  {
    "text": "as both Puppeteer and playwright come in",
    "start": "134400",
    "end": "137040"
  },
  {
    "text": "node.js flavors I decided to create a",
    "start": "137040",
    "end": "139319"
  },
  {
    "text": "new node project",
    "start": "139319",
    "end": "140819"
  },
  {
    "text": "out of our two options I decided to go",
    "start": "140819",
    "end": "142980"
  },
  {
    "text": "with playwright over Puppeteer this was",
    "start": "142980",
    "end": "145319"
  },
  {
    "text": "due to better support for pulling out",
    "start": "145319",
    "end": "146760"
  },
  {
    "text": "data attributes from HTML Elements which",
    "start": "146760",
    "end": "149340"
  },
  {
    "text": "I was going to need with the project",
    "start": "149340",
    "end": "151440"
  },
  {
    "text": "setup the next thing to do was determine",
    "start": "151440",
    "end": "153360"
  },
  {
    "text": "our scraping strategy my first goal was",
    "start": "153360",
    "end": "155879"
  },
  {
    "text": "to pull out data from the slash R",
    "start": "155879",
    "end": "157800"
  },
  {
    "text": "programming subreddit I chose this",
    "start": "157800",
    "end": "160440"
  },
  {
    "text": "subreddit initially because one I am a",
    "start": "160440",
    "end": "162780"
  },
  {
    "text": "programmer and two it would give me some",
    "start": "162780",
    "end": "164819"
  },
  {
    "text": "free ideas for videos in the future",
    "start": "164819",
    "end": "166920"
  },
  {
    "text": "the strategy for scraping I was going to",
    "start": "166920",
    "end": "169140"
  },
  {
    "text": "take was to pull out all of the posts",
    "start": "169140",
    "end": "170760"
  },
  {
    "text": "for the last 24 hours with the strategy",
    "start": "170760",
    "end": "174120"
  },
  {
    "text": "defined the next thing to do was to open",
    "start": "174120",
    "end": "176220"
  },
  {
    "text": "up the hood and see what we were working",
    "start": "176220",
    "end": "178080"
  },
  {
    "text": "with I did this by opening up the",
    "start": "178080",
    "end": "180420"
  },
  {
    "text": "developer menu and actually viewing the",
    "start": "180420",
    "end": "182280"
  },
  {
    "text": "individual HTML elements upon doing so I",
    "start": "182280",
    "end": "185220"
  },
  {
    "text": "noticed that most of the information I",
    "start": "185220",
    "end": "186959"
  },
  {
    "text": "was looking for was available in HTML",
    "start": "186959",
    "end": "189120"
  },
  {
    "text": "attributes this was a great start",
    "start": "189120",
    "end": "191300"
  },
  {
    "text": "however I did notice two potential",
    "start": "191300",
    "end": "193560"
  },
  {
    "text": "issues with the logged out version of",
    "start": "193560",
    "end": "195780"
  },
  {
    "text": "the website the first was that whenever",
    "start": "195780",
    "end": "198420"
  },
  {
    "text": "you clicked a link it would open up a",
    "start": "198420",
    "end": "200340"
  },
  {
    "text": "new tab now this wasn't a huge problem",
    "start": "200340",
    "end": "202680"
  },
  {
    "text": "and I could easily work around this but",
    "start": "202680",
    "end": "205019"
  },
  {
    "text": "it was a little bit annoying the second",
    "start": "205019",
    "end": "207420"
  },
  {
    "text": "issue that I first saw was the only way",
    "start": "207420",
    "end": "209819"
  },
  {
    "text": "to load new content was to scroll to the",
    "start": "209819",
    "end": "211920"
  },
  {
    "text": "bottom of the page",
    "start": "211920",
    "end": "213360"
  },
  {
    "text": "whilst this is possible to do it does",
    "start": "213360",
    "end": "215400"
  },
  {
    "text": "add a bit of complexity as you have to",
    "start": "215400",
    "end": "217379"
  },
  {
    "text": "constantly monitor when new resources",
    "start": "217379",
    "end": "219180"
  },
  {
    "text": "are loaded fortunately however there was",
    "start": "219180",
    "end": "221819"
  },
  {
    "text": "an easier solution which would solve",
    "start": "221819",
    "end": "223440"
  },
  {
    "text": "both of these problems Reddit still",
    "start": "223440",
    "end": "225360"
  },
  {
    "text": "keeps around a much older version of",
    "start": "225360",
    "end": "227280"
  },
  {
    "text": "their website at old.reddit.com this",
    "start": "227280",
    "end": "230760"
  },
  {
    "text": "older version of Reddit still has all",
    "start": "230760",
    "end": "232500"
  },
  {
    "text": "the exact same data and has a lot less",
    "start": "232500",
    "end": "234840"
  },
  {
    "text": "JavaScript for us to navigate when",
    "start": "234840",
    "end": "237180"
  },
  {
    "text": "opening up an inspector I could see a",
    "start": "237180",
    "end": "239159"
  },
  {
    "text": "lot of the data I was looking for was",
    "start": "239159",
    "end": "240720"
  },
  {
    "text": "available in HTML attributes",
    "start": "240720",
    "end": "242840"
  },
  {
    "text": "additionally the older subreddit has a",
    "start": "242840",
    "end": "245400"
  },
  {
    "text": "next button allowing you to easily page",
    "start": "245400",
    "end": "247260"
  },
  {
    "text": "through posts which will make it much",
    "start": "247260",
    "end": "249360"
  },
  {
    "text": "easier to scroll back through the",
    "start": "249360",
    "end": "250739"
  },
  {
    "text": "historical data with that I began",
    "start": "250739",
    "end": "252840"
  },
  {
    "text": "writing the code for my scraper pointing",
    "start": "252840",
    "end": "255060"
  },
  {
    "text": "it to R programming on the old version",
    "start": "255060",
    "end": "257100"
  },
  {
    "text": "of Reddit additionally we were hitting",
    "start": "257100",
    "end": "259139"
  },
  {
    "text": "the slash New Path which would order the",
    "start": "259139",
    "end": "260940"
  },
  {
    "text": "posts by date as the first goal was to",
    "start": "260940",
    "end": "263400"
  },
  {
    "text": "retrieve any posts I went through the",
    "start": "263400",
    "end": "265380"
  },
  {
    "text": "process of inspecting the HTML and",
    "start": "265380",
    "end": "267780"
  },
  {
    "text": "writing code to pull out any attributes",
    "start": "267780",
    "end": "269520"
  },
  {
    "text": "I can by value the attributes I cared",
    "start": "269520",
    "end": "272100"
  },
  {
    "text": "about were the post ID the post",
    "start": "272100",
    "end": "274020"
  },
  {
    "text": "subreddit the post timestamp the author",
    "start": "274020",
    "end": "276660"
  },
  {
    "text": "and the URL to the post's comments once",
    "start": "276660",
    "end": "279840"
  },
  {
    "text": "I had the function to get all of the",
    "start": "279840",
    "end": "281460"
  },
  {
    "text": "posts for our page The Next Step was to",
    "start": "281460",
    "end": "283740"
  },
  {
    "text": "run this in a loop this Loop would",
    "start": "283740",
    "end": "285720"
  },
  {
    "text": "iterate through the pages continuously",
    "start": "285720",
    "end": "287400"
  },
  {
    "text": "getting the posts for them when a page",
    "start": "287400",
    "end": "289800"
  },
  {
    "text": "contained a post that was earlier than",
    "start": "289800",
    "end": "291419"
  },
  {
    "text": "the cutoff time which was 24 hours",
    "start": "291419",
    "end": "293220"
  },
  {
    "text": "before the start of the script the loop",
    "start": "293220",
    "end": "294960"
  },
  {
    "text": "would then exit in order to iterate",
    "start": "294960",
    "end": "297000"
  },
  {
    "text": "through the pages the URL was taken from",
    "start": "297000",
    "end": "298860"
  },
  {
    "text": "the next button and given to the page to",
    "start": "298860",
    "end": "300840"
  },
  {
    "text": "go to after the loop I logged out the",
    "start": "300840",
    "end": "303060"
  },
  {
    "text": "post's length just to be sure that",
    "start": "303060",
    "end": "304620"
  },
  {
    "text": "everything was working after that I ran",
    "start": "304620",
    "end": "306720"
  },
  {
    "text": "my code to give it a test and I received",
    "start": "306720",
    "end": "309000"
  },
  {
    "text": "50 posts back from the scrape which was",
    "start": "309000",
    "end": "311400"
  },
  {
    "text": "two pages worth telling me that",
    "start": "311400",
    "end": "313080"
  },
  {
    "text": "everything was working as expected with",
    "start": "313080",
    "end": "315240"
  },
  {
    "text": "that we had achieved some level of data",
    "start": "315240",
    "end": "316800"
  },
  {
    "text": "capture from Reddit however just getting",
    "start": "316800",
    "end": "318660"
  },
  {
    "text": "the posts wasn't enough we really wanted",
    "start": "318660",
    "end": "320699"
  },
  {
    "text": "to capture the user engagement as well",
    "start": "320699",
    "end": "322620"
  },
  {
    "text": "which is where a lot of the value",
    "start": "322620",
    "end": "324120"
  },
  {
    "text": "provided by Reddit exists and it's",
    "start": "324120",
    "end": "326460"
  },
  {
    "text": "created by us to do this I would need to",
    "start": "326460",
    "end": "328860"
  },
  {
    "text": "travel to each posts page and pull out",
    "start": "328860",
    "end": "331320"
  },
  {
    "text": "all of the data there back in my code I",
    "start": "331320",
    "end": "334139"
  },
  {
    "text": "first added a filter to the posts to",
    "start": "334139",
    "end": "336060"
  },
  {
    "text": "remove any that were older than 24 hours",
    "start": "336060",
    "end": "338039"
  },
  {
    "text": "I chose 24 hours as it felt like the",
    "start": "338039",
    "end": "340680"
  },
  {
    "text": "majority of Engagement came within that",
    "start": "340680",
    "end": "342539"
  },
  {
    "text": "time frame then I would iterate over",
    "start": "342539",
    "end": "344639"
  },
  {
    "text": "every post navigate to its comments page",
    "start": "344639",
    "end": "346860"
  },
  {
    "text": "and pull out all of the data there I",
    "start": "346860",
    "end": "349020"
  },
  {
    "text": "decided to use this comments page as the",
    "start": "349020",
    "end": "351000"
  },
  {
    "text": "source of Truth and pulled out all of",
    "start": "351000",
    "end": "352740"
  },
  {
    "text": "the post data including the author and",
    "start": "352740",
    "end": "354840"
  },
  {
    "text": "the content then I looked at pulling the",
    "start": "354840",
    "end": "357360"
  },
  {
    "text": "individual comments out themselves",
    "start": "357360",
    "end": "358759"
  },
  {
    "text": "comments are pretty interesting when it",
    "start": "358759",
    "end": "361139"
  },
  {
    "text": "comes to Reddit each comment can be",
    "start": "361139",
    "end": "363240"
  },
  {
    "text": "thought of as a node and each of those",
    "start": "363240",
    "end": "365639"
  },
  {
    "text": "comments can have child nodes or child",
    "start": "365639",
    "end": "367740"
  },
  {
    "text": "comments this basically makes the",
    "start": "367740",
    "end": "369840"
  },
  {
    "text": "comments a tree structure if I took the",
    "start": "369840",
    "end": "372240"
  },
  {
    "text": "naive approach of just pulling out all",
    "start": "372240",
    "end": "373979"
  },
  {
    "text": "the comments from the page I'd actually",
    "start": "373979",
    "end": "375840"
  },
  {
    "text": "lose the association to any other",
    "start": "375840",
    "end": "378000"
  },
  {
    "text": "comments on there which provides a lot",
    "start": "378000",
    "end": "379919"
  },
  {
    "text": "of the context when it comes to Reddit",
    "start": "379919",
    "end": "381300"
  },
  {
    "text": "therefore thinking like a tree I'd need",
    "start": "381300",
    "end": "383759"
  },
  {
    "text": "to use a recursive algorithm to parse",
    "start": "383759",
    "end": "385860"
  },
  {
    "text": "the comments to achieve this I use the",
    "start": "385860",
    "end": "388440"
  },
  {
    "text": "following expression which allowed me to",
    "start": "388440",
    "end": "390180"
  },
  {
    "text": "pull only the direct descendants of an",
    "start": "390180",
    "end": "392699"
  },
  {
    "text": "element",
    "start": "392699",
    "end": "393360"
  },
  {
    "text": "I could then start the recursion by",
    "start": "393360",
    "end": "395400"
  },
  {
    "text": "using the top level element and then",
    "start": "395400",
    "end": "396960"
  },
  {
    "text": "continue it with each subsequent comment",
    "start": "396960",
    "end": "399000"
  },
  {
    "text": "then it was a case of just pulling out",
    "start": "399000",
    "end": "401280"
  },
  {
    "text": "the data values for each comment one",
    "start": "401280",
    "end": "403979"
  },
  {
    "text": "thing that did catch me out was whether",
    "start": "403979",
    "end": "405419"
  },
  {
    "text": "a comment is deleted whenever a comment",
    "start": "405419",
    "end": "408060"
  },
  {
    "text": "is deleted some of the data fields no",
    "start": "408060",
    "end": "410100"
  },
  {
    "text": "longer exist so I had to handle those",
    "start": "410100",
    "end": "411960"
  },
  {
    "text": "cases finally I gave it a quick run and",
    "start": "411960",
    "end": "414960"
  },
  {
    "text": "everything was working as expected with",
    "start": "414960",
    "end": "417660"
  },
  {
    "text": "the comments now being paused that",
    "start": "417660",
    "end": "419400"
  },
  {
    "start": "418000",
    "end": "619000"
  },
  {
    "text": "wrapped up the data scraping part of the",
    "start": "419400",
    "end": "421319"
  },
  {
    "text": "code now I needed to find somewhere to",
    "start": "421319",
    "end": "423780"
  },
  {
    "text": "actually store the data I wanted my API",
    "start": "423780",
    "end": "426000"
  },
  {
    "text": "to be Cloud hosted eventually however I",
    "start": "426000",
    "end": "428280"
  },
  {
    "text": "was also trying to do this in the lowest",
    "start": "428280",
    "end": "430259"
  },
  {
    "text": "cost possible this therefore presented a",
    "start": "430259",
    "end": "432900"
  },
  {
    "text": "challenge when choosing a database most",
    "start": "432900",
    "end": "435240"
  },
  {
    "text": "cloud-based Solutions you typically pay",
    "start": "435240",
    "end": "437220"
  },
  {
    "text": "a monthly fee for and I really wanted to",
    "start": "437220",
    "end": "439860"
  },
  {
    "text": "go for something usage based with a very",
    "start": "439860",
    "end": "442259"
  },
  {
    "text": "large free quota there was one option",
    "start": "442259",
    "end": "445139"
  },
  {
    "text": "however",
    "start": "445139",
    "end": "446300"
  },
  {
    "text": "dynamodb if you're unaware dynamodb is a",
    "start": "446300",
    "end": "450419"
  },
  {
    "text": "proprietary database by AWS it's very",
    "start": "450419",
    "end": "453300"
  },
  {
    "text": "low-cost usage based and has a very",
    "start": "453300",
    "end": "455880"
  },
  {
    "text": "generous free tier it's also a nosql",
    "start": "455880",
    "end": "458759"
  },
  {
    "text": "database and works as a key value store",
    "start": "458759",
    "end": "460919"
  },
  {
    "text": "but it's not like redis it's as far away",
    "start": "460919",
    "end": "463919"
  },
  {
    "text": "from redis as you could probably imagine",
    "start": "463919",
    "end": "465620"
  },
  {
    "text": "because of this the idea left a bit of a",
    "start": "465620",
    "end": "468539"
  },
  {
    "text": "bad taste in my mouth and I thought that",
    "start": "468539",
    "end": "470520"
  },
  {
    "text": "maybe I might find a better solution in",
    "start": "470520",
    "end": "472500"
  },
  {
    "text": "the future however I didn't want to have",
    "start": "472500",
    "end": "474120"
  },
  {
    "text": "to touch the code in my scraper if that",
    "start": "474120",
    "end": "475979"
  },
  {
    "text": "ever happened so I decided to decouple",
    "start": "475979",
    "end": "478620"
  },
  {
    "text": "my database from my scraper and write to",
    "start": "478620",
    "end": "481319"
  },
  {
    "text": "a message queue instead to do this I",
    "start": "481319",
    "end": "483539"
  },
  {
    "text": "would write the data to sqs which is a",
    "start": "483539",
    "end": "486120"
  },
  {
    "text": "low-cost message queue provided by AWS",
    "start": "486120",
    "end": "488340"
  },
  {
    "text": "this means the interface to write my",
    "start": "488340",
    "end": "490680"
  },
  {
    "text": "data to would remain constant even if I",
    "start": "490680",
    "end": "493199"
  },
  {
    "text": "change the database technology later on",
    "start": "493199",
    "end": "495060"
  },
  {
    "text": "so the first thing I needed to do was",
    "start": "495060",
    "end": "497400"
  },
  {
    "text": "create an sqsq you can do this with the",
    "start": "497400",
    "end": "499979"
  },
  {
    "text": "AWS console but I opted to do it within",
    "start": "499979",
    "end": "502139"
  },
  {
    "text": "terraform as I prefer infrastructure as",
    "start": "502139",
    "end": "504479"
  },
  {
    "text": "code this also means you're able to",
    "start": "504479",
    "end": "506400"
  },
  {
    "text": "deploy this if you want to as well you",
    "start": "506400",
    "end": "508319"
  },
  {
    "text": "can find the link to the repo in the",
    "start": "508319",
    "end": "510479"
  },
  {
    "text": "description down below as my project was",
    "start": "510479",
    "end": "512580"
  },
  {
    "text": "starting to contain more code than just",
    "start": "512580",
    "end": "514440"
  },
  {
    "text": "the web scraper I moved the existing",
    "start": "514440",
    "end": "516539"
  },
  {
    "text": "code into a new directory and created a",
    "start": "516539",
    "end": "518820"
  },
  {
    "text": "folder for the infrastructure next I",
    "start": "518820",
    "end": "521339"
  },
  {
    "text": "began writing my terraform code which",
    "start": "521339",
    "end": "523320"
  },
  {
    "text": "was only a few lines long I also made",
    "start": "523320",
    "end": "526140"
  },
  {
    "text": "sure to add some tags so I could easily",
    "start": "526140",
    "end": "527700"
  },
  {
    "text": "track the cost of this project next it",
    "start": "527700",
    "end": "530160"
  },
  {
    "text": "was time to run the terraform commands",
    "start": "530160",
    "end": "531839"
  },
  {
    "text": "to apply our infrastructure which",
    "start": "531839",
    "end": "533880"
  },
  {
    "text": "usually consists of terraform in it for",
    "start": "533880",
    "end": "535800"
  },
  {
    "text": "the start to actually go ahead and",
    "start": "535800",
    "end": "537420"
  },
  {
    "text": "initialize everything then the terraform",
    "start": "537420",
    "end": "539760"
  },
  {
    "text": "plan to make sure what I was creating is",
    "start": "539760",
    "end": "541380"
  },
  {
    "text": "what I wanted and finally terraform",
    "start": "541380",
    "end": "543540"
  },
  {
    "text": "apply after that I went to the AWS",
    "start": "543540",
    "end": "545940"
  },
  {
    "text": "console to check that my sqsq was",
    "start": "545940",
    "end": "547920"
  },
  {
    "text": "created which it was so everything was",
    "start": "547920",
    "end": "550320"
  },
  {
    "text": "working correctly the next thing to do",
    "start": "550320",
    "end": "552240"
  },
  {
    "text": "was to integrate the scraper with the",
    "start": "552240",
    "end": "554279"
  },
  {
    "text": "sqsq back in the code for my scraper I",
    "start": "554279",
    "end": "557580"
  },
  {
    "text": "created a new file for adding in the sqs",
    "start": "557580",
    "end": "559860"
  },
  {
    "text": "code and then installed the sqs client",
    "start": "559860",
    "end": "562080"
  },
  {
    "text": "from the AWS SDK package I then went",
    "start": "562080",
    "end": "565200"
  },
  {
    "text": "ahead and added in the logic to send",
    "start": "565200",
    "end": "567060"
  },
  {
    "text": "messages to the sqsq I made sure to use",
    "start": "567060",
    "end": "570060"
  },
  {
    "text": "an environment variable for the Q URL so",
    "start": "570060",
    "end": "572519"
  },
  {
    "text": "I could configure this later then all I",
    "start": "572519",
    "end": "574800"
  },
  {
    "text": "had to do was import this function in",
    "start": "574800",
    "end": "576720"
  },
  {
    "text": "the existing code and call it with my",
    "start": "576720",
    "end": "578519"
  },
  {
    "text": "data I also added a new timestamp to the",
    "start": "578519",
    "end": "581459"
  },
  {
    "text": "posts which marked the time I scraped",
    "start": "581459",
    "end": "583380"
  },
  {
    "text": "the data at this was so I'd be able to",
    "start": "583380",
    "end": "585360"
  },
  {
    "text": "determine whether or not new data coming",
    "start": "585360",
    "end": "586980"
  },
  {
    "text": "in should overwrite the existing data in",
    "start": "586980",
    "end": "589140"
  },
  {
    "text": "the database with all of the changes",
    "start": "589140",
    "end": "591000"
  },
  {
    "text": "made I went ahead and ran the code to",
    "start": "591000",
    "end": "592680"
  },
  {
    "text": "give it a test as the code was expecting",
    "start": "592680",
    "end": "595019"
  },
  {
    "text": "the cute URL from an environment",
    "start": "595019",
    "end": "596760"
  },
  {
    "text": "variable I made sure to set this before",
    "start": "596760",
    "end": "598500"
  },
  {
    "text": "running then it was just a process of",
    "start": "598500",
    "end": "601140"
  },
  {
    "text": "waiting for all of the pages to be",
    "start": "601140",
    "end": "602880"
  },
  {
    "text": "scraped once it had completed there was",
    "start": "602880",
    "end": "605040"
  },
  {
    "text": "a log message telling me there was 56",
    "start": "605040",
    "end": "606779"
  },
  {
    "text": "messages that had been published I then",
    "start": "606779",
    "end": "609060"
  },
  {
    "text": "went onto the AWS console and saw that I",
    "start": "609060",
    "end": "611100"
  },
  {
    "text": "had messages sitting on my queue this",
    "start": "611100",
    "end": "613260"
  },
  {
    "text": "meant everything was working correctly",
    "start": "613260",
    "end": "614640"
  },
  {
    "text": "and had the added benefit that I would",
    "start": "614640",
    "end": "616500"
  },
  {
    "text": "no longer lose any data whilst I was",
    "start": "616500",
    "end": "618240"
  },
  {
    "text": "implementing the rest of the",
    "start": "618240",
    "end": "619440"
  },
  {
    "start": "619000",
    "end": "803000"
  },
  {
    "text": "architecture with the message queue in",
    "start": "619440",
    "end": "621540"
  },
  {
    "text": "place now was a good time to think about",
    "start": "621540",
    "end": "623459"
  },
  {
    "text": "deploying the scraper to AWS however",
    "start": "623459",
    "end": "626519"
  },
  {
    "text": "there was another challenge to overcome",
    "start": "626519",
    "end": "628680"
  },
  {
    "text": "as I was aiming to be as low cost as",
    "start": "628680",
    "end": "631260"
  },
  {
    "text": "possible I was going to deploy my",
    "start": "631260",
    "end": "633000"
  },
  {
    "text": "scraper to run periodically on AWS",
    "start": "633000",
    "end": "635279"
  },
  {
    "text": "Lambda however playwright relies on an",
    "start": "635279",
    "end": "637740"
  },
  {
    "text": "instance of chrome in order to operate",
    "start": "637740",
    "end": "639600"
  },
  {
    "text": "which means I'd need a significant",
    "start": "639600",
    "end": "642240"
  },
  {
    "text": "amount of ram in the Lambda instance",
    "start": "642240",
    "end": "644000"
  },
  {
    "text": "additionally my scraper was more likely",
    "start": "644000",
    "end": "646440"
  },
  {
    "text": "to be blocked by Reddit as the IP would",
    "start": "646440",
    "end": "648600"
  },
  {
    "text": "be one related to AWS which is a bit of",
    "start": "648600",
    "end": "651600"
  },
  {
    "text": "a giveaway that it's an automation",
    "start": "651600",
    "end": "653040"
  },
  {
    "text": "fortunately there was another option",
    "start": "653040",
    "end": "655320"
  },
  {
    "text": "that option is bright data bright data",
    "start": "655320",
    "end": "658620"
  },
  {
    "text": "provides a number of products that are",
    "start": "658620",
    "end": "660480"
  },
  {
    "text": "incredibly useful when it comes to web",
    "start": "660480",
    "end": "662100"
  },
  {
    "text": "scraping and they also happen to be",
    "start": "662100",
    "end": "664200"
  },
  {
    "text": "sponsoring this video",
    "start": "664200",
    "end": "665640"
  },
  {
    "text": "I decided to use their scraping browser",
    "start": "665640",
    "end": "667800"
  },
  {
    "text": "product which provided two benefits the",
    "start": "667800",
    "end": "670260"
  },
  {
    "text": "first was that I was able to use the",
    "start": "670260",
    "end": "672060"
  },
  {
    "text": "same code and just connect to Bright",
    "start": "672060",
    "end": "673680"
  },
  {
    "text": "data's running instances of chrome which",
    "start": "673680",
    "end": "676079"
  },
  {
    "text": "meant I no longer had to run an instance",
    "start": "676079",
    "end": "677940"
  },
  {
    "text": "of chrome within AWS Lambda which saved",
    "start": "677940",
    "end": "680459"
  },
  {
    "text": "time and resources the second is that",
    "start": "680459",
    "end": "683220"
  },
  {
    "text": "their scraping browser product actually",
    "start": "683220",
    "end": "684660"
  },
  {
    "text": "uses residential IPS which reduces our",
    "start": "684660",
    "end": "687300"
  },
  {
    "text": "chances of being blocked significantly",
    "start": "687300",
    "end": "689459"
  },
  {
    "text": "we're also able to use concurrent",
    "start": "689459",
    "end": "691680"
  },
  {
    "text": "browsers in order to speed up this",
    "start": "691680",
    "end": "693180"
  },
  {
    "text": "scraping process which is very cool",
    "start": "693180",
    "end": "695700"
  },
  {
    "text": "to integrate with bright data is really",
    "start": "695700",
    "end": "697860"
  },
  {
    "text": "easy I just headed over to the bright",
    "start": "697860",
    "end": "700019"
  },
  {
    "text": "data website and logged in with my",
    "start": "700019",
    "end": "701820"
  },
  {
    "text": "account then I went ahead and clicked",
    "start": "701820",
    "end": "704220"
  },
  {
    "text": "the add button to go ahead and create a",
    "start": "704220",
    "end": "706200"
  },
  {
    "text": "new scraping browser resource for use",
    "start": "706200",
    "end": "707700"
  },
  {
    "text": "with Reddit",
    "start": "707700",
    "end": "708839"
  },
  {
    "text": "this then provides a connection host",
    "start": "708839",
    "end": "710640"
  },
  {
    "text": "username and password which is all we",
    "start": "710640",
    "end": "713220"
  },
  {
    "text": "need",
    "start": "713220",
    "end": "714000"
  },
  {
    "text": "in order to integrate with bright data I",
    "start": "714000",
    "end": "716579"
  },
  {
    "text": "just needed to make a couple of changes",
    "start": "716579",
    "end": "718079"
  },
  {
    "text": "the first was to add in my connection",
    "start": "718079",
    "end": "720180"
  },
  {
    "text": "URL now I did this using an environment",
    "start": "720180",
    "end": "722640"
  },
  {
    "text": "variable as it's a good practice to not",
    "start": "722640",
    "end": "724860"
  },
  {
    "text": "hard code credentials then it was just a",
    "start": "724860",
    "end": "727320"
  },
  {
    "text": "case of replacing how I was connecting",
    "start": "727320",
    "end": "729120"
  },
  {
    "text": "to chromium instead of creating a local",
    "start": "729120",
    "end": "731760"
  },
  {
    "text": "instance I would just connect over CDP",
    "start": "731760",
    "end": "734100"
  },
  {
    "text": "and that was all it took now I could",
    "start": "734100",
    "end": "736860"
  },
  {
    "text": "have left it there but I wanted to make",
    "start": "736860",
    "end": "738180"
  },
  {
    "text": "use of the concurrency and so I changed",
    "start": "738180",
    "end": "740880"
  },
  {
    "text": "the way I was loading the comment pages",
    "start": "740880",
    "end": "742380"
  },
  {
    "text": "to connect to a new browser for each one",
    "start": "742380",
    "end": "744300"
  },
  {
    "text": "this allowed me to run multiple browsers",
    "start": "744300",
    "end": "746519"
  },
  {
    "text": "in parallel next I gave this a run to",
    "start": "746519",
    "end": "749279"
  },
  {
    "text": "test it I first added my connection URL",
    "start": "749279",
    "end": "752160"
  },
  {
    "text": "to the environment variable and then",
    "start": "752160",
    "end": "754260"
  },
  {
    "text": "gave it a run the first time I deployed",
    "start": "754260",
    "end": "756480"
  },
  {
    "text": "this I noticed that the bright data",
    "start": "756480",
    "end": "758220"
  },
  {
    "text": "integration was using a lot of data and",
    "start": "758220",
    "end": "760019"
  },
  {
    "text": "taking a long time as bright data",
    "start": "760019",
    "end": "762240"
  },
  {
    "text": "charges per gigabyte of data this",
    "start": "762240",
    "end": "764399"
  },
  {
    "text": "initially wasn't cost effective however",
    "start": "764399",
    "end": "766500"
  },
  {
    "text": "after talking to the bright data team I",
    "start": "766500",
    "end": "768420"
  },
  {
    "text": "found a number of optimizations I could",
    "start": "768420",
    "end": "770220"
  },
  {
    "text": "make the first was to filter any",
    "start": "770220",
    "end": "772320"
  },
  {
    "text": "unnecessary resources from loading this",
    "start": "772320",
    "end": "774779"
  },
  {
    "text": "meant images videos CSS and JavaScript",
    "start": "774779",
    "end": "777839"
  },
  {
    "text": "the next optimization I made was to",
    "start": "777839",
    "end": "780420"
  },
  {
    "text": "change the way I was pulling out",
    "start": "780420",
    "end": "781560"
  },
  {
    "text": "attributes it was much quicker to pull",
    "start": "781560",
    "end": "783720"
  },
  {
    "text": "all of the elements attributes out in",
    "start": "783720",
    "end": "785399"
  },
  {
    "text": "one API call rather than multiple so I",
    "start": "785399",
    "end": "788459"
  },
  {
    "text": "created a helper function to do this and",
    "start": "788459",
    "end": "790139"
  },
  {
    "text": "refactored some of the code with these",
    "start": "790139",
    "end": "792060"
  },
  {
    "text": "two changes my performance increased and",
    "start": "792060",
    "end": "793860"
  },
  {
    "text": "the amount of data I was processing",
    "start": "793860",
    "end": "795420"
  },
  {
    "text": "dramatically reduced the source code",
    "start": "795420",
    "end": "797639"
  },
  {
    "text": "provides both the Chrome and bright data",
    "start": "797639",
    "end": "800100"
  },
  {
    "text": "integration so you can choose whichever",
    "start": "800100",
    "end": "801839"
  },
  {
    "text": "one you like with the scraper working",
    "start": "801839",
    "end": "803940"
  },
  {
    "start": "803000",
    "end": "858000"
  },
  {
    "text": "the next thing to do was to get it",
    "start": "803940",
    "end": "805560"
  },
  {
    "text": "deployed to AWS Lambda to do that I",
    "start": "805560",
    "end": "808139"
  },
  {
    "text": "quickly needed to export a Handler",
    "start": "808139",
    "end": "810060"
  },
  {
    "text": "function then I went and added my",
    "start": "810060",
    "end": "812639"
  },
  {
    "text": "terraform code you can find the",
    "start": "812639",
    "end": "814620"
  },
  {
    "text": "terraform inside of the infrastructure",
    "start": "814620",
    "end": "816540"
  },
  {
    "text": "directory under the scraper.tf to deploy",
    "start": "816540",
    "end": "819959"
  },
  {
    "text": "this I went ahead and ran terraform",
    "start": "819959",
    "end": "821579"
  },
  {
    "text": "apply this initiates a prompt asking for",
    "start": "821579",
    "end": "824459"
  },
  {
    "text": "my connection URL which will assign it",
    "start": "824459",
    "end": "826620"
  },
  {
    "text": "to the environment variable I pasted",
    "start": "826620",
    "end": "828779"
  },
  {
    "text": "this in and waited for everything to",
    "start": "828779",
    "end": "830459"
  },
  {
    "text": "complete I could then move over to the",
    "start": "830459",
    "end": "832380"
  },
  {
    "text": "AWS console and see that my Q was",
    "start": "832380",
    "end": "834660"
  },
  {
    "text": "created as expected and configured how I",
    "start": "834660",
    "end": "836940"
  },
  {
    "text": "wanted it to be I had a cloudwatch event",
    "start": "836940",
    "end": "839220"
  },
  {
    "text": "mapping to invoke my Lambda once every",
    "start": "839220",
    "end": "841200"
  },
  {
    "text": "hour and my environment variables were",
    "start": "841200",
    "end": "843779"
  },
  {
    "text": "both configured correctly then I double",
    "start": "843779",
    "end": "846000"
  },
  {
    "text": "checked my permissions which all looked",
    "start": "846000",
    "end": "847740"
  },
  {
    "text": "pretty good now all that remained was to",
    "start": "847740",
    "end": "849779"
  },
  {
    "text": "wait for this to go ahead and run I came",
    "start": "849779",
    "end": "852300"
  },
  {
    "text": "back a few hours later and saw I had a",
    "start": "852300",
    "end": "854339"
  },
  {
    "text": "number of events on my queue which meant",
    "start": "854339",
    "end": "856320"
  },
  {
    "text": "that everything was working as expected",
    "start": "856320",
    "end": "858240"
  },
  {
    "start": "858000",
    "end": "932000"
  },
  {
    "text": "now all I had to do was write the data",
    "start": "858240",
    "end": "860339"
  },
  {
    "text": "to dynamodb and pull it out as an API to",
    "start": "860339",
    "end": "863639"
  },
  {
    "text": "do that I needed two dynamodb tables the",
    "start": "863639",
    "end": "866700"
  },
  {
    "text": "first was going to be used to store our",
    "start": "866700",
    "end": "868260"
  },
  {
    "text": "post data this would be stored with a",
    "start": "868260",
    "end": "870240"
  },
  {
    "text": "partition key of the post ID as well as",
    "start": "870240",
    "end": "873000"
  },
  {
    "text": "a secondary index which contains both",
    "start": "873000",
    "end": "875339"
  },
  {
    "text": "the subreddit and the timestamp of the",
    "start": "875339",
    "end": "877500"
  },
  {
    "text": "post this allowed me to pull out all of",
    "start": "877500",
    "end": "879959"
  },
  {
    "text": "the posts by subreddit and order them by",
    "start": "879959",
    "end": "882240"
  },
  {
    "text": "their posted at time",
    "start": "882240",
    "end": "883860"
  },
  {
    "text": "the second table would contain all of",
    "start": "883860",
    "end": "885839"
  },
  {
    "text": "the comments for the posts and would",
    "start": "885839",
    "end": "887820"
  },
  {
    "text": "only have the post ID as the partition",
    "start": "887820",
    "end": "889860"
  },
  {
    "text": "key allowing me to only pull out",
    "start": "889860",
    "end": "891779"
  },
  {
    "text": "comments for requested posts",
    "start": "891779",
    "end": "894120"
  },
  {
    "text": "again I use terraform to create both of",
    "start": "894120",
    "end": "896519"
  },
  {
    "text": "these tables the code for this can be",
    "start": "896519",
    "end": "898620"
  },
  {
    "text": "found in the dynamodb.tf file in the",
    "start": "898620",
    "end": "901139"
  },
  {
    "text": "infrastructure directory with the tables",
    "start": "901139",
    "end": "903420"
  },
  {
    "text": "created I needed to write some code that",
    "start": "903420",
    "end": "905040"
  },
  {
    "text": "would read off the message queue and",
    "start": "905040",
    "end": "906300"
  },
  {
    "text": "write it to dynamodb I decided to do",
    "start": "906300",
    "end": "908880"
  },
  {
    "text": "this in go because I find it a little",
    "start": "908880",
    "end": "910680"
  },
  {
    "text": "faster to work with than node.js the",
    "start": "910680",
    "end": "913139"
  },
  {
    "text": "code for this is pretty simple and just",
    "start": "913139",
    "end": "914639"
  },
  {
    "text": "involved unmarshalling from Json and",
    "start": "914639",
    "end": "916620"
  },
  {
    "text": "then marshalling into the correct types",
    "start": "916620",
    "end": "918300"
  },
  {
    "text": "for dynamodb followed by writing them to",
    "start": "918300",
    "end": "921000"
  },
  {
    "text": "the associated table I then wrote some",
    "start": "921000",
    "end": "923339"
  },
  {
    "text": "terraform to deploy this to Lambda",
    "start": "923339",
    "end": "925100"
  },
  {
    "text": "afterwards I went and checked my",
    "start": "925100",
    "end": "926940"
  },
  {
    "text": "dynamodb tables to see that I had data",
    "start": "926940",
    "end": "929160"
  },
  {
    "text": "written to them and I checked my sqs",
    "start": "929160",
    "end": "931199"
  },
  {
    "text": "cues to see that they were empty so far",
    "start": "931199",
    "end": "933360"
  },
  {
    "start": "932000",
    "end": "1085000"
  },
  {
    "text": "so good all that remained was to create",
    "start": "933360",
    "end": "935880"
  },
  {
    "text": "the API to achieve this I was also going",
    "start": "935880",
    "end": "938459"
  },
  {
    "text": "to use AWS Lambda but I was going to use",
    "start": "938459",
    "end": "940800"
  },
  {
    "text": "API Gateway in front of it this meant",
    "start": "940800",
    "end": "943260"
  },
  {
    "text": "the API itself would be low cost and",
    "start": "943260",
    "end": "945300"
  },
  {
    "text": "usage based I decided to use go again to",
    "start": "945300",
    "end": "948060"
  },
  {
    "text": "write this code because of this I was",
    "start": "948060",
    "end": "950040"
  },
  {
    "text": "able to use a go module that allowed me",
    "start": "950040",
    "end": "951660"
  },
  {
    "text": "to easily route HTTP requests between a",
    "start": "951660",
    "end": "954720"
  },
  {
    "text": "Lambda API Gateway context this package",
    "start": "954720",
    "end": "957779"
  },
  {
    "text": "is the AWS Lambda go API proxy package",
    "start": "957779",
    "end": "960779"
  },
  {
    "text": "by the AWS Labs which provides adapters",
    "start": "960779",
    "end": "963420"
  },
  {
    "text": "for many different routing libraries in",
    "start": "963420",
    "end": "965519"
  },
  {
    "text": "go enabling you to write code as if it",
    "start": "965519",
    "end": "967680"
  },
  {
    "text": "was an API whilst being able to run it",
    "start": "967680",
    "end": "969540"
  },
  {
    "text": "in a Lambda context in order to",
    "start": "969540",
    "end": "971699"
  },
  {
    "text": "celebrate the return of gorilla mocks I",
    "start": "971699",
    "end": "973380"
  },
  {
    "text": "decided to use it for my router I had",
    "start": "973380",
    "end": "975839"
  },
  {
    "text": "some initial trouble getting the mux",
    "start": "975839",
    "end": "977459"
  },
  {
    "text": "adapter to work so I just went ahead and",
    "start": "977459",
    "end": "979380"
  },
  {
    "text": "used the standard HTTP adapter for the",
    "start": "979380",
    "end": "982620"
  },
  {
    "text": "API I added a total of four different",
    "start": "982620",
    "end": "984779"
  },
  {
    "text": "endpoints the first being a get request",
    "start": "984779",
    "end": "987300"
  },
  {
    "text": "to the index which would allow me to",
    "start": "987300",
    "end": "989220"
  },
  {
    "text": "test that everything was working the",
    "start": "989220",
    "end": "990839"
  },
  {
    "text": "Unix was a get request to slash R",
    "start": "990839",
    "end": "993260"
  },
  {
    "text": "subreddit this endpoint would act",
    "start": "993260",
    "end": "995699"
  },
  {
    "text": "similar to the Slash new page on Reddit",
    "start": "995699",
    "end": "997860"
  },
  {
    "text": "and would return the 25 most recent",
    "start": "997860",
    "end": "1000620"
  },
  {
    "text": "items in date descending order",
    "start": "1000620",
    "end": "1002720"
  },
  {
    "text": "this endpoint also supported pagination",
    "start": "1002720",
    "end": "1004820"
  },
  {
    "text": "the same way the reddit website did",
    "start": "1004820",
    "end": "1007040"
  },
  {
    "text": "which was to pass in a query parameter",
    "start": "1007040",
    "end": "1009920"
  },
  {
    "text": "of after with the post ID that we wanted",
    "start": "1009920",
    "end": "1011779"
  },
  {
    "text": "posts afterwards",
    "start": "1011779",
    "end": "1013459"
  },
  {
    "text": "this worked by pulling out the post with",
    "start": "1013459",
    "end": "1015800"
  },
  {
    "text": "the ID taking the timestamp and using",
    "start": "1015800",
    "end": "1018139"
  },
  {
    "text": "that in the sort key the final endpoint",
    "start": "1018139",
    "end": "1020600"
  },
  {
    "text": "was to pull out all of the posts details",
    "start": "1020600",
    "end": "1022820"
  },
  {
    "text": "by its ID this was to simulate",
    "start": "1022820",
    "end": "1025040"
  },
  {
    "text": "navigating to a page of a post in this",
    "start": "1025040",
    "end": "1027438"
  },
  {
    "text": "case both the post details and comments",
    "start": "1027439",
    "end": "1029418"
  },
  {
    "text": "would be returned this was done by",
    "start": "1029419",
    "end": "1031640"
  },
  {
    "text": "accepting a post ID in the query path",
    "start": "1031640",
    "end": "1034160"
  },
  {
    "text": "and using that ID to look up both the",
    "start": "1034160",
    "end": "1036260"
  },
  {
    "text": "post details and the comments from their",
    "start": "1036260",
    "end": "1038600"
  },
  {
    "text": "respective tables with our API endpoints",
    "start": "1038600",
    "end": "1041480"
  },
  {
    "text": "written up all that remained was",
    "start": "1041480",
    "end": "1043040"
  },
  {
    "text": "deploying it I took pretty much the same",
    "start": "1043040",
    "end": "1045079"
  },
  {
    "text": "terraform that I used for the loader",
    "start": "1045079",
    "end": "1047240"
  },
  {
    "text": "Lambda and used it for the API Lambda",
    "start": "1047240",
    "end": "1049580"
  },
  {
    "text": "the real challenge however came with the",
    "start": "1049580",
    "end": "1052040"
  },
  {
    "text": "API Gateway API Gateway has a V1 and av2",
    "start": "1052040",
    "end": "1056179"
  },
  {
    "text": "you would assume that the V2 version is",
    "start": "1056179",
    "end": "1058880"
  },
  {
    "text": "what you want to use as it's more modern",
    "start": "1058880",
    "end": "1060740"
  },
  {
    "text": "but that's not really the case",
    "start": "1060740",
    "end": "1062720"
  },
  {
    "text": "instead of proxying all endpoints to a",
    "start": "1062720",
    "end": "1065120"
  },
  {
    "text": "single Lambda like you can do with the",
    "start": "1065120",
    "end": "1066980"
  },
  {
    "text": "V1 Gateway it only allows you to proxy",
    "start": "1066980",
    "end": "1069559"
  },
  {
    "text": "paths to individual lambdas without",
    "start": "1069559",
    "end": "1071900"
  },
  {
    "text": "giving you the actual path information",
    "start": "1071900",
    "end": "1073340"
  },
  {
    "text": "this didn't work for my use case as I",
    "start": "1073340",
    "end": "1075860"
  },
  {
    "text": "was expecting the path to be in the",
    "start": "1075860",
    "end": "1077480"
  },
  {
    "text": "request so I went with the V1 Gateway",
    "start": "1077480",
    "end": "1079880"
  },
  {
    "text": "instead once the terraform was written I",
    "start": "1079880",
    "end": "1082340"
  },
  {
    "text": "went ahead and applied it when it was",
    "start": "1082340",
    "end": "1084320"
  },
  {
    "text": "done I headed over to the AWS console",
    "start": "1084320",
    "end": "1086179"
  },
  {
    "start": "1085000",
    "end": "1183000"
  },
  {
    "text": "for the API Gateway here I clicked on my",
    "start": "1086179",
    "end": "1088580"
  },
  {
    "text": "freshly created API and pulled out the",
    "start": "1088580",
    "end": "1090740"
  },
  {
    "text": "gateway's domain name in order to test",
    "start": "1090740",
    "end": "1092419"
  },
  {
    "text": "some requests I first tested my slash",
    "start": "1092419",
    "end": "1095000"
  },
  {
    "text": "route and got back the expected response",
    "start": "1095000",
    "end": "1097160"
  },
  {
    "text": "which was a really good start next I",
    "start": "1097160",
    "end": "1099799"
  },
  {
    "text": "tested the subreddit route in which I",
    "start": "1099799",
    "end": "1101840"
  },
  {
    "text": "received 25 items back if I took the",
    "start": "1101840",
    "end": "1104480"
  },
  {
    "text": "last items ID and also sent it up with",
    "start": "1104480",
    "end": "1106760"
  },
  {
    "text": "the after query parameter I then",
    "start": "1106760",
    "end": "1108679"
  },
  {
    "text": "received the next 25 items so far two",
    "start": "1108679",
    "end": "1111740"
  },
  {
    "text": "out of two lastly I tested the post",
    "start": "1111740",
    "end": "1114620"
  },
  {
    "text": "details endpoint in which I received all",
    "start": "1114620",
    "end": "1116960"
  },
  {
    "text": "of the details of the post as well as",
    "start": "1116960",
    "end": "1118520"
  },
  {
    "text": "all of the comments inside of a tree",
    "start": "1118520",
    "end": "1119960"
  },
  {
    "text": "structure with that my API was working",
    "start": "1119960",
    "end": "1122419"
  },
  {
    "text": "as expected",
    "start": "1122419",
    "end": "1123799"
  },
  {
    "text": "one thing to note the free quota for API",
    "start": "1123799",
    "end": "1126260"
  },
  {
    "text": "Gateway is 1 million requests which is",
    "start": "1126260",
    "end": "1128900"
  },
  {
    "text": "much better value compared to the",
    "start": "1128900",
    "end": "1130760"
  },
  {
    "text": "official Reddit API so how much did",
    "start": "1130760",
    "end": "1133940"
  },
  {
    "text": "everything cost me well after running",
    "start": "1133940",
    "end": "1135980"
  },
  {
    "text": "this for about three weeks it so far has",
    "start": "1135980",
    "end": "1138440"
  },
  {
    "text": "cost me around 8 cents most of this cost",
    "start": "1138440",
    "end": "1140960"
  },
  {
    "text": "actually comes from dynamodb which was a",
    "start": "1140960",
    "end": "1143840"
  },
  {
    "text": "tad more expensive than expected but is",
    "start": "1143840",
    "end": "1146360"
  },
  {
    "text": "a lot cheaper than running it in say RDS",
    "start": "1146360",
    "end": "1149000"
  },
  {
    "text": "and so the project was a success I had",
    "start": "1149000",
    "end": "1152059"
  },
  {
    "text": "managed to create my own cheaper version",
    "start": "1152059",
    "end": "1153740"
  },
  {
    "text": "of the Reddit API in order to beat",
    "start": "1153740",
    "end": "1155720"
  },
  {
    "text": "inflation now sure it can't do",
    "start": "1155720",
    "end": "1158179"
  },
  {
    "text": "everything the Reddit API can but at",
    "start": "1158179",
    "end": "1160280"
  },
  {
    "text": "least now I can Doom scroll as much as I",
    "start": "1160280",
    "end": "1162440"
  },
  {
    "text": "like I want to give a big shout out to",
    "start": "1162440",
    "end": "1164600"
  },
  {
    "text": "the sponsor of this video bright data if",
    "start": "1164600",
    "end": "1167600"
  },
  {
    "text": "you're on the market for any web",
    "start": "1167600",
    "end": "1168919"
  },
  {
    "text": "scraping or proxy based Solutions then",
    "start": "1168919",
    "end": "1171140"
  },
  {
    "text": "please consider giving bright data a go",
    "start": "1171140",
    "end": "1173000"
  },
  {
    "text": "they were an absolute joy to work with",
    "start": "1173000",
    "end": "1174980"
  },
  {
    "text": "and they have a really cool product",
    "start": "1174980",
    "end": "1176240"
  },
  {
    "text": "otherwise I want to give a big thank you",
    "start": "1176240",
    "end": "1178039"
  },
  {
    "text": "to everyone else for watching and I'll",
    "start": "1178039",
    "end": "1180020"
  },
  {
    "text": "see you on the next one",
    "start": "1180020",
    "end": "1183160"
  }
]
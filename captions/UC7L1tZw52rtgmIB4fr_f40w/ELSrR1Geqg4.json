[
  {
    "text": "[Music]",
    "start": "150",
    "end": "15259"
  },
  {
    "text": "hi",
    "start": "15839",
    "end": "16800"
  },
  {
    "text": "uh welcome to ray summit this is carson",
    "start": "16800",
    "end": "19520"
  },
  {
    "text": "one from intel",
    "start": "19520",
    "end": "21119"
  },
  {
    "text": "today i'm very excited to introduce ray",
    "start": "21119",
    "end": "23680"
  },
  {
    "text": "dp",
    "start": "23680",
    "end": "24560"
  },
  {
    "text": "and i will talk about how to build a",
    "start": "24560",
    "end": "26400"
  },
  {
    "text": "large scale energy and data analytics",
    "start": "26400",
    "end": "29279"
  },
  {
    "text": "and ai pipeline using spark and array",
    "start": "29279",
    "end": "33440"
  },
  {
    "text": "this is today's agenda i will first talk",
    "start": "33440",
    "end": "36480"
  },
  {
    "text": "about some background of the big data",
    "start": "36480",
    "end": "38719"
  },
  {
    "text": "and",
    "start": "38719",
    "end": "38960"
  },
  {
    "text": "ai how people are trying to integrate",
    "start": "38960",
    "end": "42239"
  },
  {
    "text": "big data and ai and what are the",
    "start": "42239",
    "end": "44320"
  },
  {
    "text": "challenges",
    "start": "44320",
    "end": "45280"
  },
  {
    "text": "we are facing then i will introduce",
    "start": "45280",
    "end": "47440"
  },
  {
    "text": "array and the adp",
    "start": "47440",
    "end": "48640"
  },
  {
    "text": "project and how we can build energy and",
    "start": "48640",
    "end": "52160"
  },
  {
    "text": "pipeline much",
    "start": "52160",
    "end": "52960"
  },
  {
    "text": "easily and efficiently with these",
    "start": "52960",
    "end": "54719"
  },
  {
    "text": "projects there will also introduce",
    "start": "54719",
    "end": "57520"
  },
  {
    "text": "a little more about the ready p api",
    "start": "57520",
    "end": "60719"
  },
  {
    "text": "and the architectural design finally i",
    "start": "60719",
    "end": "63520"
  },
  {
    "text": "will also show you some examples",
    "start": "63520",
    "end": "66240"
  },
  {
    "text": "about the using radep to build some",
    "start": "66240",
    "end": "68799"
  },
  {
    "text": "pipelines",
    "start": "68799",
    "end": "69600"
  },
  {
    "text": "like spark waste boost and",
    "start": "69600",
    "end": "72640"
  },
  {
    "text": "spark with whole what array",
    "start": "72640",
    "end": "76000"
  },
  {
    "text": "so let's get started with some",
    "start": "76000",
    "end": "79200"
  },
  {
    "text": "data and ai background",
    "start": "79200",
    "end": "82640"
  },
  {
    "text": "as we know big data and ai have been two",
    "start": "82640",
    "end": "85759"
  },
  {
    "text": "different communities and on one side",
    "start": "85759",
    "end": "88560"
  },
  {
    "text": "apache spark is one of the leading big",
    "start": "88560",
    "end": "90720"
  },
  {
    "text": "data",
    "start": "90720",
    "end": "91360"
  },
  {
    "text": "framework and it has been evolving",
    "start": "91360",
    "end": "93759"
  },
  {
    "text": "quickly",
    "start": "93759",
    "end": "94560"
  },
  {
    "text": "in the past few years on the other side",
    "start": "94560",
    "end": "97600"
  },
  {
    "text": "there are also more and more machine",
    "start": "97600",
    "end": "100799"
  },
  {
    "text": "learning and deep learning frameworks",
    "start": "100799",
    "end": "102960"
  },
  {
    "text": "are being very popular like a tensorflow",
    "start": "102960",
    "end": "105280"
  },
  {
    "text": "pytorch",
    "start": "105280",
    "end": "106479"
  },
  {
    "text": "and there are also more and more",
    "start": "106479",
    "end": "108479"
  },
  {
    "text": "intersections between these two",
    "start": "108479",
    "end": "110000"
  },
  {
    "text": "communities",
    "start": "110000",
    "end": "111280"
  },
  {
    "text": "one of the reason is because massive",
    "start": "111280",
    "end": "113040"
  },
  {
    "text": "data is very critical for",
    "start": "113040",
    "end": "115439"
  },
  {
    "text": "better ai to get a better",
    "start": "115439",
    "end": "119759"
  },
  {
    "text": "am model we actually need a very",
    "start": "119759",
    "end": "123840"
  },
  {
    "text": "large number of high quality data",
    "start": "123840",
    "end": "127439"
  },
  {
    "text": "and uh with more and more data being",
    "start": "127439",
    "end": "130160"
  },
  {
    "text": "used for training it's also",
    "start": "130160",
    "end": "132080"
  },
  {
    "text": "becoming clear that a single node will",
    "start": "132080",
    "end": "134319"
  },
  {
    "text": "not meet the",
    "start": "134319",
    "end": "135440"
  },
  {
    "text": "computing requirements of the training",
    "start": "135440",
    "end": "137760"
  },
  {
    "text": "so distributed training will be uh",
    "start": "137760",
    "end": "140080"
  },
  {
    "text": "known we have seen many projects uh that",
    "start": "140080",
    "end": "143280"
  },
  {
    "text": "tries to",
    "start": "143280",
    "end": "144480"
  },
  {
    "text": "uh uh integrate these uh communities",
    "start": "144480",
    "end": "147440"
  },
  {
    "text": "like hollywood",
    "start": "147440",
    "end": "148560"
  },
  {
    "text": "and spark tensorflow and spark these",
    "start": "148560",
    "end": "151519"
  },
  {
    "text": "projects",
    "start": "151519",
    "end": "152319"
  },
  {
    "text": "around the deep learning frameworks on",
    "start": "152319",
    "end": "155280"
  },
  {
    "text": "spark",
    "start": "155280",
    "end": "156080"
  },
  {
    "text": "and there are also other projects like",
    "start": "156080",
    "end": "157760"
  },
  {
    "text": "petastorm that's",
    "start": "157760",
    "end": "159200"
  },
  {
    "text": "stored as back output into file formats",
    "start": "159200",
    "end": "162640"
  },
  {
    "text": "that can be read by the deployment",
    "start": "162640",
    "end": "164800"
  },
  {
    "text": "frameworks",
    "start": "164800",
    "end": "166239"
  },
  {
    "text": "so next let's take a look at some common",
    "start": "166239",
    "end": "169280"
  },
  {
    "text": "setup",
    "start": "169280",
    "end": "169920"
  },
  {
    "text": "for integrating big data with ai",
    "start": "169920",
    "end": "174080"
  },
  {
    "text": "a traditional approach is to use",
    "start": "174080",
    "end": "177200"
  },
  {
    "text": "two clusters one for spark and another",
    "start": "177200",
    "end": "180480"
  },
  {
    "text": "one for machine learning",
    "start": "180480",
    "end": "181920"
  },
  {
    "text": "and deep learning so in this setup",
    "start": "181920",
    "end": "185120"
  },
  {
    "text": "if you have an energy in the data",
    "start": "185120",
    "end": "188000"
  },
  {
    "text": "analytics and ai pipeline",
    "start": "188000",
    "end": "189920"
  },
  {
    "text": "you first need to write a spark program",
    "start": "189920",
    "end": "192959"
  },
  {
    "text": "submit that to the spark cluster to do",
    "start": "192959",
    "end": "195599"
  },
  {
    "text": "data pre-processing",
    "start": "195599",
    "end": "196959"
  },
  {
    "text": "and then you store the output into a",
    "start": "196959",
    "end": "199680"
  },
  {
    "text": "distributed file system like edge",
    "start": "199680",
    "end": "201360"
  },
  {
    "text": "database",
    "start": "201360",
    "end": "202239"
  },
  {
    "text": "and in the next step for model training",
    "start": "202239",
    "end": "205120"
  },
  {
    "text": "if your",
    "start": "205120",
    "end": "206480"
  },
  {
    "text": "machine learning framework supports",
    "start": "206480",
    "end": "208159"
  },
  {
    "text": "reading directly from",
    "start": "208159",
    "end": "209599"
  },
  {
    "text": "our device you can do that otherwise you",
    "start": "209599",
    "end": "212799"
  },
  {
    "text": "also need to copy the data from the",
    "start": "212799",
    "end": "215120"
  },
  {
    "text": "spark cluster",
    "start": "215120",
    "end": "216080"
  },
  {
    "text": "to the machine learning and deep",
    "start": "216080",
    "end": "217760"
  },
  {
    "text": "learning cluster and load the data",
    "start": "217760",
    "end": "219680"
  },
  {
    "text": "flight's own storage",
    "start": "219680",
    "end": "221599"
  },
  {
    "text": "so there are a few challenges here",
    "start": "221599",
    "end": "225440"
  },
  {
    "text": "firstly there are data movements between",
    "start": "225440",
    "end": "227680"
  },
  {
    "text": "clusters",
    "start": "227680",
    "end": "228720"
  },
  {
    "text": "and secondly there are also overhead of",
    "start": "228720",
    "end": "231040"
  },
  {
    "text": "managing",
    "start": "231040",
    "end": "232080"
  },
  {
    "text": "two clusters and if we look at the",
    "start": "232080",
    "end": "235280"
  },
  {
    "text": "energy in the pipeline we will see",
    "start": "235280",
    "end": "238480"
  },
  {
    "text": "we will need a glue code to stitch",
    "start": "238480",
    "end": "241439"
  },
  {
    "text": "together multiple programs",
    "start": "241439",
    "end": "243200"
  },
  {
    "text": "so it will be a segmented application",
    "start": "243200",
    "end": "247680"
  },
  {
    "text": "um the second approach is to run machine",
    "start": "248799",
    "end": "251280"
  },
  {
    "text": "learning and deepening frameworks on",
    "start": "251280",
    "end": "253040"
  },
  {
    "text": "spark",
    "start": "253040",
    "end": "254159"
  },
  {
    "text": "so this is useful if you have a existing",
    "start": "254159",
    "end": "257199"
  },
  {
    "text": "spark cluster",
    "start": "257199",
    "end": "258239"
  },
  {
    "text": "and you want to utilize the resource in",
    "start": "258239",
    "end": "260320"
  },
  {
    "text": "the cluster to do",
    "start": "260320",
    "end": "261680"
  },
  {
    "text": "machine learning and deep learning so",
    "start": "261680",
    "end": "264240"
  },
  {
    "text": "there are a few",
    "start": "264240",
    "end": "265840"
  },
  {
    "text": "frameworks supported on spark and",
    "start": "265840",
    "end": "269360"
  },
  {
    "text": "by using these frameworks you can",
    "start": "269360",
    "end": "272639"
  },
  {
    "text": "implement a spark program and do both",
    "start": "272639",
    "end": "275840"
  },
  {
    "text": "data pre-processing and model training",
    "start": "275840",
    "end": "278160"
  },
  {
    "text": "in a in",
    "start": "278160",
    "end": "279199"
  },
  {
    "text": "a single spark cluster however there are",
    "start": "279199",
    "end": "282720"
  },
  {
    "text": "also a few challenges here",
    "start": "282720",
    "end": "284720"
  },
  {
    "text": "this solution first it is very specific",
    "start": "284720",
    "end": "287840"
  },
  {
    "text": "to spark and it requires the machine",
    "start": "287840",
    "end": "290320"
  },
  {
    "text": "learning and deep learning frameworks",
    "start": "290320",
    "end": "292240"
  },
  {
    "text": "supported on spark so if you have a",
    "start": "292240",
    "end": "294800"
  },
  {
    "text": "pipeline that involves",
    "start": "294800",
    "end": "296080"
  },
  {
    "text": "a framework but not supported on spark",
    "start": "296080",
    "end": "299360"
  },
  {
    "text": "or if you do not have spark involved in",
    "start": "299360",
    "end": "301360"
  },
  {
    "text": "the pipeline",
    "start": "301360",
    "end": "302400"
  },
  {
    "text": "this will not work for you uh secondly",
    "start": "302400",
    "end": "306000"
  },
  {
    "text": "when we use data exchange between spark",
    "start": "306000",
    "end": "308560"
  },
  {
    "text": "and other",
    "start": "308560",
    "end": "309840"
  },
  {
    "text": "frameworks usually to relies on",
    "start": "309840",
    "end": "312639"
  },
  {
    "text": "distributed file system like hdfs",
    "start": "312639",
    "end": "315039"
  },
  {
    "text": "so this will also add latency in your",
    "start": "315039",
    "end": "318320"
  },
  {
    "text": "entire pipeline today there are also",
    "start": "318320",
    "end": "322720"
  },
  {
    "text": "many organizations moving to a",
    "start": "322720",
    "end": "325840"
  },
  {
    "text": "single cluster managed by kubernetes and",
    "start": "325840",
    "end": "328720"
  },
  {
    "text": "by using a workflow orchestration",
    "start": "328720",
    "end": "330639"
  },
  {
    "text": "framework like",
    "start": "330639",
    "end": "331759"
  },
  {
    "text": "cubaflow it's also possible to build the",
    "start": "331759",
    "end": "334800"
  },
  {
    "text": "entertainment pipeline on a single",
    "start": "334800",
    "end": "336800"
  },
  {
    "text": "cluster managed by kubernetes",
    "start": "336800",
    "end": "338800"
  },
  {
    "text": "so we can run spark on kubernetes and we",
    "start": "338800",
    "end": "341440"
  },
  {
    "text": "can also run the",
    "start": "341440",
    "end": "343039"
  },
  {
    "text": "model training part kubernetes",
    "start": "343039",
    "end": "347199"
  },
  {
    "text": "in this setup there are also a few",
    "start": "347199",
    "end": "350880"
  },
  {
    "text": "challenges here",
    "start": "350880",
    "end": "352320"
  },
  {
    "text": "so first you to build the entire",
    "start": "352320",
    "end": "354880"
  },
  {
    "text": "pipeline you",
    "start": "354880",
    "end": "356240"
  },
  {
    "text": "probably you need to uh it needs to be",
    "start": "356240",
    "end": "359199"
  },
  {
    "text": "written",
    "start": "359199",
    "end": "359919"
  },
  {
    "text": "in multiple programs and configuration",
    "start": "359919",
    "end": "362080"
  },
  {
    "text": "files so for every step you",
    "start": "362080",
    "end": "364639"
  },
  {
    "text": "need to probably need to write the",
    "start": "364639",
    "end": "367199"
  },
  {
    "text": "docker file build the image",
    "start": "367199",
    "end": "369039"
  },
  {
    "text": "and write the spark program or the model",
    "start": "369039",
    "end": "371520"
  },
  {
    "text": "training program",
    "start": "371520",
    "end": "372560"
  },
  {
    "text": "in a constructed pipeline so this is not",
    "start": "372560",
    "end": "375039"
  },
  {
    "text": "as simple as",
    "start": "375039",
    "end": "376319"
  },
  {
    "text": "uh write the entire program in a single",
    "start": "376319",
    "end": "378800"
  },
  {
    "text": "python program",
    "start": "378800",
    "end": "380560"
  },
  {
    "text": "and secondly when we do data exchange",
    "start": "380560",
    "end": "383120"
  },
  {
    "text": "between",
    "start": "383120",
    "end": "384080"
  },
  {
    "text": "these frameworks usually it also needed",
    "start": "384080",
    "end": "387759"
  },
  {
    "text": "to rely on a distributed file system",
    "start": "387759",
    "end": "390240"
  },
  {
    "text": "like https",
    "start": "390240",
    "end": "391440"
  },
  {
    "text": "so this which will also add the latency",
    "start": "391440",
    "end": "393600"
  },
  {
    "text": "in a pipeline",
    "start": "393600",
    "end": "396880"
  },
  {
    "text": "so the question is can we have a",
    "start": "397520",
    "end": "400880"
  },
  {
    "text": "general purpose framework that can be",
    "start": "400880",
    "end": "402960"
  },
  {
    "text": "used as a",
    "start": "402960",
    "end": "404080"
  },
  {
    "text": "single substrate for both data",
    "start": "404080",
    "end": "406160"
  },
  {
    "text": "pre-processing",
    "start": "406160",
    "end": "407280"
  },
  {
    "text": "and model training and even model",
    "start": "407280",
    "end": "409680"
  },
  {
    "text": "serving",
    "start": "409680",
    "end": "411199"
  },
  {
    "text": "and we also want to make sure we can",
    "start": "411199",
    "end": "413919"
  },
  {
    "text": "develop the entire",
    "start": "413919",
    "end": "415360"
  },
  {
    "text": "pipeline easily and efficiently for",
    "start": "415360",
    "end": "418160"
  },
  {
    "text": "example",
    "start": "418160",
    "end": "418720"
  },
  {
    "text": "just write the entire pipeline in a",
    "start": "418720",
    "end": "422319"
  },
  {
    "text": "single python program",
    "start": "422319",
    "end": "424000"
  },
  {
    "text": "and instead of using a",
    "start": "424000",
    "end": "427360"
  },
  {
    "text": "distributed file system to do data",
    "start": "427360",
    "end": "429120"
  },
  {
    "text": "exchange",
    "start": "429120",
    "end": "430560"
  },
  {
    "text": "can we also use the in-memory store",
    "start": "430560",
    "end": "433759"
  },
  {
    "text": "to do efficient data exchange so the",
    "start": "433759",
    "end": "436400"
  },
  {
    "text": "answer is to use array",
    "start": "436400",
    "end": "438240"
  },
  {
    "text": "and also use the adp project to run a",
    "start": "438240",
    "end": "441120"
  },
  {
    "text": "spy count rate",
    "start": "441120",
    "end": "443440"
  },
  {
    "text": "so as we know ray is a general purpose",
    "start": "443440",
    "end": "447759"
  },
  {
    "text": "framework that provides simple and",
    "start": "447759",
    "end": "450000"
  },
  {
    "text": "universal api",
    "start": "450000",
    "end": "451440"
  },
  {
    "text": "to build distributed applications the",
    "start": "451440",
    "end": "454560"
  },
  {
    "text": "record provides some simple apis like",
    "start": "454560",
    "end": "456880"
  },
  {
    "text": "task",
    "start": "456880",
    "end": "457680"
  },
  {
    "text": "and actor but they are powerful enough",
    "start": "457680",
    "end": "460000"
  },
  {
    "text": "to",
    "start": "460000",
    "end": "460720"
  },
  {
    "text": "build distributed libraries and",
    "start": "460720",
    "end": "462400"
  },
  {
    "text": "applications today there are a few",
    "start": "462400",
    "end": "464800"
  },
  {
    "text": "built-in",
    "start": "464800",
    "end": "465759"
  },
  {
    "text": "libraries in ray like ray tune rlab",
    "start": "465759",
    "end": "468639"
  },
  {
    "text": "raysgd and reserve",
    "start": "468639",
    "end": "470479"
  },
  {
    "text": "and there are also more and more third",
    "start": "470479",
    "end": "472720"
  },
  {
    "text": "party libraries being supported on ray",
    "start": "472720",
    "end": "475199"
  },
  {
    "text": "like as you boost holobot and",
    "start": "475199",
    "end": "478720"
  },
  {
    "text": "for data pre-processing today there are",
    "start": "478720",
    "end": "480960"
  },
  {
    "text": "a few options already",
    "start": "480960",
    "end": "482879"
  },
  {
    "text": "like a modding task and a mass",
    "start": "482879",
    "end": "486800"
  },
  {
    "text": "however we notice there are also a few",
    "start": "486800",
    "end": "489840"
  },
  {
    "text": "use cases",
    "start": "489840",
    "end": "490639"
  },
  {
    "text": "that are using spark as a major data",
    "start": "490639",
    "end": "493840"
  },
  {
    "text": "pre-processing",
    "start": "493840",
    "end": "494960"
  },
  {
    "text": "framework in their pipeline so we create",
    "start": "494960",
    "end": "497680"
  },
  {
    "text": "the radp",
    "start": "497680",
    "end": "498560"
  },
  {
    "text": "project to provide simple apis for",
    "start": "498560",
    "end": "501680"
  },
  {
    "text": "running",
    "start": "501680",
    "end": "502479"
  },
  {
    "text": "spark and ray and also integrating spark",
    "start": "502479",
    "end": "505440"
  },
  {
    "text": "with",
    "start": "505440",
    "end": "506160"
  },
  {
    "text": "distributed machine learning and deep",
    "start": "506160",
    "end": "508240"
  },
  {
    "text": "learning frameworks",
    "start": "508240",
    "end": "510080"
  },
  {
    "text": "when we run spoken array we treat ray as",
    "start": "510080",
    "end": "513360"
  },
  {
    "text": "a",
    "start": "513360",
    "end": "513760"
  },
  {
    "text": "resource manager of spark and we run all",
    "start": "513760",
    "end": "516399"
  },
  {
    "text": "the spark process",
    "start": "516399",
    "end": "517599"
  },
  {
    "text": "in race actors so this makes",
    "start": "517599",
    "end": "520800"
  },
  {
    "text": "back just like a native library only",
    "start": "520800",
    "end": "524399"
  },
  {
    "text": "and to integrate spark with distributed",
    "start": "524399",
    "end": "526959"
  },
  {
    "text": "machine learning and deep learning",
    "start": "526959",
    "end": "528320"
  },
  {
    "text": "frameworks",
    "start": "528320",
    "end": "529279"
  },
  {
    "text": "we provided two approaches the first",
    "start": "529279",
    "end": "532480"
  },
  {
    "text": "one is the simplest one is to use the",
    "start": "532480",
    "end": "535360"
  },
  {
    "text": "pie torch and the",
    "start": "535360",
    "end": "536640"
  },
  {
    "text": "tensorflow estimator so you can simply",
    "start": "536640",
    "end": "539440"
  },
  {
    "text": "create a",
    "start": "539440",
    "end": "540640"
  },
  {
    "text": "estimator by passing in your model your",
    "start": "540640",
    "end": "543920"
  },
  {
    "text": "optimizer",
    "start": "543920",
    "end": "544720"
  },
  {
    "text": "your loss function and a few other",
    "start": "544720",
    "end": "546160"
  },
  {
    "text": "configurations and then you can directly",
    "start": "546160",
    "end": "549120"
  },
  {
    "text": "fix that with your spy data frame and we",
    "start": "549120",
    "end": "552160"
  },
  {
    "text": "will take care of everything else",
    "start": "552160",
    "end": "554000"
  },
  {
    "text": "i like to do the data exchange runs back",
    "start": "554000",
    "end": "556959"
  },
  {
    "text": "to",
    "start": "556959",
    "end": "557760"
  },
  {
    "text": "the deep learning framework and scale",
    "start": "557760",
    "end": "560320"
  },
  {
    "text": "out your training on a raid cluster",
    "start": "560320",
    "end": "563440"
  },
  {
    "text": "however if you prefer to use the",
    "start": "563440",
    "end": "567600"
  },
  {
    "text": "framework or library api directly we",
    "start": "567600",
    "end": "570320"
  },
  {
    "text": "also provide",
    "start": "570320",
    "end": "571200"
  },
  {
    "text": "another approach which is a ray mld stat",
    "start": "571200",
    "end": "574240"
  },
  {
    "text": "converter",
    "start": "574240",
    "end": "576080"
  },
  {
    "text": "it can allows you to convert a spark",
    "start": "576080",
    "end": "578959"
  },
  {
    "text": "data frame",
    "start": "578959",
    "end": "579760"
  },
  {
    "text": "to array mld set and the array methods",
    "start": "579760",
    "end": "583120"
  },
  {
    "text": "can be",
    "start": "583120",
    "end": "583760"
  },
  {
    "text": "actually consumed by a few libraries",
    "start": "583760",
    "end": "586880"
  },
  {
    "text": "available on array like hd boost",
    "start": "586880",
    "end": "589120"
  },
  {
    "text": "wholewhat ray cd",
    "start": "589120",
    "end": "591040"
  },
  {
    "text": "so by using this way we can also connect",
    "start": "591040",
    "end": "593839"
  },
  {
    "text": "spark",
    "start": "593839",
    "end": "594399"
  },
  {
    "text": "with this machine learning and deep",
    "start": "594399",
    "end": "596320"
  },
  {
    "text": "learning frameworks",
    "start": "596320",
    "end": "599279"
  },
  {
    "text": "so with ray as a single substrate and",
    "start": "600080",
    "end": "604240"
  },
  {
    "text": "with adp to run spa country",
    "start": "604240",
    "end": "607279"
  },
  {
    "text": "now together with a few other",
    "start": "607279",
    "end": "610480"
  },
  {
    "text": "projects and frameworks available only",
    "start": "610480",
    "end": "613519"
  },
  {
    "text": "it becomes very straightforward to build",
    "start": "613519",
    "end": "617040"
  },
  {
    "text": "energy in the python pipeline",
    "start": "617040",
    "end": "620240"
  },
  {
    "text": "on top of array and we can easily",
    "start": "620240",
    "end": "622720"
  },
  {
    "text": "implement the entire pipeline in a",
    "start": "622720",
    "end": "625120"
  },
  {
    "text": "integrated python program so in a",
    "start": "625120",
    "end": "628480"
  },
  {
    "text": "typical workflow now we can use ray dp",
    "start": "628480",
    "end": "631839"
  },
  {
    "text": "to run spoken array",
    "start": "631839",
    "end": "633519"
  },
  {
    "text": "and we can use past sequel to read the",
    "start": "633519",
    "end": "636560"
  },
  {
    "text": "data",
    "start": "636560",
    "end": "637360"
  },
  {
    "text": "in the do data pre-processing using the",
    "start": "637360",
    "end": "640560"
  },
  {
    "text": "smart c core data frame api we can also",
    "start": "640560",
    "end": "643440"
  },
  {
    "text": "use backup",
    "start": "643440",
    "end": "644720"
  },
  {
    "text": "to do feature engineering after that we",
    "start": "644720",
    "end": "647920"
  },
  {
    "text": "can",
    "start": "647920",
    "end": "648480"
  },
  {
    "text": "store the output into race in memory",
    "start": "648480",
    "end": "651680"
  },
  {
    "text": "object store",
    "start": "651680",
    "end": "652640"
  },
  {
    "text": "to efficiently exchange the data between",
    "start": "652640",
    "end": "655200"
  },
  {
    "text": "spark and other",
    "start": "655200",
    "end": "656320"
  },
  {
    "text": "frameworks in the next step for model",
    "start": "656320",
    "end": "659279"
  },
  {
    "text": "training we can use any frameworks",
    "start": "659279",
    "end": "662399"
  },
  {
    "text": "available on array like pi torch",
    "start": "662399",
    "end": "664800"
  },
  {
    "text": "tensorflow",
    "start": "664800",
    "end": "665920"
  },
  {
    "text": "whole by the way cd x boost and even",
    "start": "665920",
    "end": "669040"
  },
  {
    "text": "spark ml lab",
    "start": "669040",
    "end": "671360"
  },
  {
    "text": "it's also straightforward to integrate",
    "start": "671360",
    "end": "674160"
  },
  {
    "text": "the model training with rating",
    "start": "674160",
    "end": "676000"
  },
  {
    "text": "to do hyper parameter tuning so after",
    "start": "676000",
    "end": "679200"
  },
  {
    "text": "that we get a model",
    "start": "679200",
    "end": "680640"
  },
  {
    "text": "uh we can also use razer to do model",
    "start": "680640",
    "end": "683760"
  },
  {
    "text": "survey so everything will run on a",
    "start": "683760",
    "end": "685680"
  },
  {
    "text": "single",
    "start": "685680",
    "end": "686399"
  },
  {
    "text": "platform ray and we can build this",
    "start": "686399",
    "end": "690240"
  },
  {
    "text": "easily in a python program",
    "start": "690240",
    "end": "694640"
  },
  {
    "text": "it's also very easy to scale your ray",
    "start": "695120",
    "end": "698000"
  },
  {
    "text": "program",
    "start": "698000",
    "end": "698640"
  },
  {
    "text": "from your laptop to cloud or kubernetes",
    "start": "698640",
    "end": "702320"
  },
  {
    "text": "we usually start our development on our",
    "start": "702320",
    "end": "704800"
  },
  {
    "text": "local laptop",
    "start": "704800",
    "end": "706240"
  },
  {
    "text": "and we start with a small data set we",
    "start": "706240",
    "end": "708640"
  },
  {
    "text": "can implement our python program using",
    "start": "708640",
    "end": "710880"
  },
  {
    "text": "all the available",
    "start": "710880",
    "end": "712079"
  },
  {
    "text": "apis like railway dp and pi spark and",
    "start": "712079",
    "end": "715839"
  },
  {
    "text": "the",
    "start": "715839",
    "end": "716320"
  },
  {
    "text": "ziplining framework apis once it's",
    "start": "716320",
    "end": "719760"
  },
  {
    "text": "ready and it worked well on our local",
    "start": "719760",
    "end": "723120"
  },
  {
    "text": "laptop",
    "start": "723120",
    "end": "723920"
  },
  {
    "text": "now we can use ray cluster launcher to",
    "start": "723920",
    "end": "727040"
  },
  {
    "text": "start a ray cluster in the cloud or on a",
    "start": "727040",
    "end": "729440"
  },
  {
    "text": "kubernetes",
    "start": "729440",
    "end": "730079"
  },
  {
    "text": "class we support auto scaling so we",
    "start": "730079",
    "end": "733279"
  },
  {
    "text": "can start with a small number of",
    "start": "733279",
    "end": "735279"
  },
  {
    "text": "instances and",
    "start": "735279",
    "end": "736320"
  },
  {
    "text": "scale out when the program requires more",
    "start": "736320",
    "end": "738959"
  },
  {
    "text": "resource",
    "start": "738959",
    "end": "740000"
  },
  {
    "text": "so if you are running spark",
    "start": "740000",
    "end": "743200"
  },
  {
    "text": "on ray and uh you want to scale out to",
    "start": "743200",
    "end": "746480"
  },
  {
    "text": "the cloud",
    "start": "746480",
    "end": "747120"
  },
  {
    "text": "now you don't even need to set up a spot",
    "start": "747120",
    "end": "749920"
  },
  {
    "text": "class in the cloud",
    "start": "749920",
    "end": "751279"
  },
  {
    "text": "just use the raycast launcher to start",
    "start": "751279",
    "end": "753279"
  },
  {
    "text": "the rig reclast",
    "start": "753279",
    "end": "755120"
  },
  {
    "text": "and now you can easily scale your",
    "start": "755120",
    "end": "758399"
  },
  {
    "text": "spark program or energy and program from",
    "start": "758399",
    "end": "761519"
  },
  {
    "text": "your laptop to the cloud",
    "start": "761519",
    "end": "763200"
  },
  {
    "text": "seamlessly and efficiently",
    "start": "763200",
    "end": "766639"
  },
  {
    "text": "here are a few benefits of",
    "start": "768560",
    "end": "771600"
  },
  {
    "text": "using radp and array so first you will",
    "start": "771600",
    "end": "774720"
  },
  {
    "text": "get a",
    "start": "774720",
    "end": "775519"
  },
  {
    "text": "increased productivity it simplifies how",
    "start": "775519",
    "end": "778959"
  },
  {
    "text": "you can build and manage energy in the",
    "start": "778959",
    "end": "781279"
  },
  {
    "text": "pipeline",
    "start": "781279",
    "end": "782639"
  },
  {
    "text": "instead of write multiple programs and",
    "start": "782639",
    "end": "785600"
  },
  {
    "text": "use",
    "start": "785600",
    "end": "786480"
  },
  {
    "text": "some glue codes or workflow",
    "start": "786480",
    "end": "788320"
  },
  {
    "text": "orchestration framework to",
    "start": "788320",
    "end": "790160"
  },
  {
    "text": "stitch them together now you can",
    "start": "790160",
    "end": "792720"
  },
  {
    "text": "implement the entire pipeline in your",
    "start": "792720",
    "end": "794959"
  },
  {
    "text": "single python program you can use any",
    "start": "794959",
    "end": "797760"
  },
  {
    "text": "apis available",
    "start": "797760",
    "end": "799040"
  },
  {
    "text": "ray like spark hd boost tensorflow",
    "start": "799040",
    "end": "801760"
  },
  {
    "text": "pytorch and whole wide and more",
    "start": "801760",
    "end": "804160"
  },
  {
    "text": "secondly you will also get better",
    "start": "804160",
    "end": "806320"
  },
  {
    "text": "performance",
    "start": "806320",
    "end": "807279"
  },
  {
    "text": "so instead of using a distributed file",
    "start": "807279",
    "end": "810079"
  },
  {
    "text": "system to",
    "start": "810079",
    "end": "811279"
  },
  {
    "text": "do the data exchange now it's also",
    "start": "811279",
    "end": "813200"
  },
  {
    "text": "possible to do",
    "start": "813200",
    "end": "814480"
  },
  {
    "text": "in-memory data exchange by using race",
    "start": "814480",
    "end": "817440"
  },
  {
    "text": "object store",
    "start": "817440",
    "end": "819040"
  },
  {
    "text": "and we also plan to integrate a few",
    "start": "819040",
    "end": "823279"
  },
  {
    "text": "spark optimizations in radiopt",
    "start": "823279",
    "end": "826399"
  },
  {
    "text": "so for example we can also use race",
    "start": "826399",
    "end": "829600"
  },
  {
    "text": "in memory object store to do smart",
    "start": "829600",
    "end": "832000"
  },
  {
    "text": "shuffle",
    "start": "832000",
    "end": "832639"
  },
  {
    "text": "so when you launch back on rate you will",
    "start": "832639",
    "end": "835199"
  },
  {
    "text": "directly get",
    "start": "835199",
    "end": "836480"
  },
  {
    "text": "the benefit of that finally you will",
    "start": "836480",
    "end": "839600"
  },
  {
    "text": "also get",
    "start": "839600",
    "end": "841760"
  },
  {
    "text": "the resource utilization ray itself",
    "start": "841760",
    "end": "845360"
  },
  {
    "text": "supports auto scaling at the cluster",
    "start": "845360",
    "end": "847440"
  },
  {
    "text": "level",
    "start": "847440",
    "end": "848079"
  },
  {
    "text": "and the spark also supports dynamic",
    "start": "848079",
    "end": "850880"
  },
  {
    "text": "resource allocation",
    "start": "850880",
    "end": "852800"
  },
  {
    "text": "so by combining these two it's actually",
    "start": "852800",
    "end": "855760"
  },
  {
    "text": "possible you will",
    "start": "855760",
    "end": "857199"
  },
  {
    "text": "get a very very good resource",
    "start": "857199",
    "end": "859600"
  },
  {
    "text": "utilization",
    "start": "859600",
    "end": "860800"
  },
  {
    "text": "and receive the cost",
    "start": "860800",
    "end": "863839"
  },
  {
    "text": "next let's take a close look at the",
    "start": "865279",
    "end": "867920"
  },
  {
    "text": "ready p",
    "start": "867920",
    "end": "868560"
  },
  {
    "text": "api and the architecture design",
    "start": "868560",
    "end": "873199"
  },
  {
    "text": "first let's take a look at the spark",
    "start": "873839",
    "end": "876800"
  },
  {
    "text": "android api",
    "start": "876800",
    "end": "877839"
  },
  {
    "text": "so how you can start a spark job on ray",
    "start": "877839",
    "end": "881120"
  },
  {
    "text": "so in a python program you first you",
    "start": "881120",
    "end": "883839"
  },
  {
    "text": "need to connect",
    "start": "883839",
    "end": "884720"
  },
  {
    "text": "to a red cluster using ray.init",
    "start": "884720",
    "end": "887760"
  },
  {
    "text": "and then now you can use the ready p api",
    "start": "887760",
    "end": "891120"
  },
  {
    "text": "in meters back to start a splat job on",
    "start": "891120",
    "end": "894560"
  },
  {
    "text": "array cluster you can specify your",
    "start": "894560",
    "end": "896959"
  },
  {
    "text": "application name",
    "start": "896959",
    "end": "898320"
  },
  {
    "text": "the number of the spark executors you",
    "start": "898320",
    "end": "900800"
  },
  {
    "text": "want to launch",
    "start": "900800",
    "end": "901760"
  },
  {
    "text": "and also the resource for every smart",
    "start": "901760",
    "end": "904399"
  },
  {
    "text": "executor like the",
    "start": "904399",
    "end": "906000"
  },
  {
    "text": "number of the cores and the memory size",
    "start": "906000",
    "end": "909440"
  },
  {
    "text": "you can also pass in additional spot",
    "start": "909440",
    "end": "912160"
  },
  {
    "text": "configurations in this api",
    "start": "912160",
    "end": "914399"
  },
  {
    "text": "after that we will launch the smart job",
    "start": "914399",
    "end": "916240"
  },
  {
    "text": "on ray",
    "start": "916240",
    "end": "917680"
  },
  {
    "text": "cluster and you will get a splash",
    "start": "917680",
    "end": "920399"
  },
  {
    "text": "session",
    "start": "920399",
    "end": "921120"
  },
  {
    "text": "so now you can use any spark apis",
    "start": "921120",
    "end": "924800"
  },
  {
    "text": "to do for example read the packet file",
    "start": "924800",
    "end": "928399"
  },
  {
    "text": "and do some data frame operations",
    "start": "928399",
    "end": "932880"
  },
  {
    "text": "after you've finished your spark",
    "start": "932880",
    "end": "935279"
  },
  {
    "text": "processing",
    "start": "935279",
    "end": "936240"
  },
  {
    "text": "you can call the radip.stop spark",
    "start": "936240",
    "end": "939680"
  },
  {
    "text": "to stop the job and also release the",
    "start": "939680",
    "end": "942000"
  },
  {
    "text": "resource",
    "start": "942000",
    "end": "944480"
  },
  {
    "text": "this picture illustrates how we",
    "start": "948240",
    "end": "950880"
  },
  {
    "text": "implement spark and array",
    "start": "950880",
    "end": "952399"
  },
  {
    "text": "as i mentioned earlier we treated ray as",
    "start": "952399",
    "end": "954959"
  },
  {
    "text": "a resource manager of spark",
    "start": "954959",
    "end": "958240"
  },
  {
    "text": "so when your python program called the",
    "start": "958240",
    "end": "962480"
  },
  {
    "text": "innate spark api we first",
    "start": "962480",
    "end": "965759"
  },
  {
    "text": "we will launch a app master and",
    "start": "965759",
    "end": "969040"
  },
  {
    "text": "it we will run that in a ray java actor",
    "start": "969040",
    "end": "973519"
  },
  {
    "text": "and the spot driver also will send",
    "start": "973519",
    "end": "976959"
  },
  {
    "text": "the request to the app master for",
    "start": "976959",
    "end": "978880"
  },
  {
    "text": "example how many",
    "start": "978880",
    "end": "980000"
  },
  {
    "text": "spark executors you want to launch and",
    "start": "980000",
    "end": "982160"
  },
  {
    "text": "what are the resources for each sparkle",
    "start": "982160",
    "end": "983920"
  },
  {
    "text": "shooter",
    "start": "983920",
    "end": "984639"
  },
  {
    "text": "so the epp master is responsible for",
    "start": "984639",
    "end": "987440"
  },
  {
    "text": "starting all the",
    "start": "987440",
    "end": "988639"
  },
  {
    "text": "spark executors in the recluster so in",
    "start": "988639",
    "end": "991279"
  },
  {
    "text": "the",
    "start": "991279",
    "end": "991759"
  },
  {
    "text": "second step it will i launched these",
    "start": "991759",
    "end": "994560"
  },
  {
    "text": "executors in race java actors",
    "start": "994560",
    "end": "997839"
  },
  {
    "text": "and then in the third step these",
    "start": "997839",
    "end": "1000000"
  },
  {
    "text": "executors will",
    "start": "1000000",
    "end": "1001600"
  },
  {
    "text": "register to the spy driver so",
    "start": "1001600",
    "end": "1004880"
  },
  {
    "text": "after that they can just communicate",
    "start": "1004880",
    "end": "1007440"
  },
  {
    "text": "with each other using smart's own",
    "start": "1007440",
    "end": "1009440"
  },
  {
    "text": "communication protocol because we",
    "start": "1009440",
    "end": "1012480"
  },
  {
    "text": "start all the spark executors in array",
    "start": "1012480",
    "end": "1015680"
  },
  {
    "text": "java actor",
    "start": "1015680",
    "end": "1016880"
  },
  {
    "text": "so we can easily accessorize object",
    "start": "1016880",
    "end": "1019920"
  },
  {
    "text": "store",
    "start": "1019920",
    "end": "1020480"
  },
  {
    "text": "and to efficient data exchange between",
    "start": "1020480",
    "end": "1023279"
  },
  {
    "text": "spark and",
    "start": "1023279",
    "end": "1024000"
  },
  {
    "text": "other ray libraries",
    "start": "1024000",
    "end": "1027520"
  },
  {
    "text": "next let's take a look at the estimator",
    "start": "1029120",
    "end": "1032959"
  },
  {
    "text": "api yeah so to do distributed training",
    "start": "1032959",
    "end": "1038160"
  },
  {
    "text": "array and on a spark data frame",
    "start": "1038160",
    "end": "1041438"
  },
  {
    "text": "uh there is the simplest one approaches",
    "start": "1041439",
    "end": "1044558"
  },
  {
    "text": "to use the pipeline and tensorflow as a",
    "start": "1044559",
    "end": "1046640"
  },
  {
    "text": "meter provided by",
    "start": "1046640",
    "end": "1048160"
  },
  {
    "text": "radiop so you can create a pi torch",
    "start": "1048160",
    "end": "1050840"
  },
  {
    "text": "estimator by specifying how many",
    "start": "1050840",
    "end": "1054000"
  },
  {
    "text": "training workers you want to run and",
    "start": "1054000",
    "end": "1056160"
  },
  {
    "text": "what is your model the optimizer and the",
    "start": "1056160",
    "end": "1058559"
  },
  {
    "text": "loss function",
    "start": "1058559",
    "end": "1060000"
  },
  {
    "text": "additionally you can specify the feature",
    "start": "1060000",
    "end": "1062640"
  },
  {
    "text": "columns",
    "start": "1062640",
    "end": "1063360"
  },
  {
    "text": "the label column the batch size and also",
    "start": "1063360",
    "end": "1066559"
  },
  {
    "text": "the number of the epochs",
    "start": "1066559",
    "end": "1068480"
  },
  {
    "text": "so after that you can directly fit that",
    "start": "1068480",
    "end": "1072000"
  },
  {
    "text": "uh using a spa data frame so and we will",
    "start": "1072000",
    "end": "1075600"
  },
  {
    "text": "take everything else and just kill your",
    "start": "1075600",
    "end": "1078799"
  },
  {
    "text": "your distributed training on the right",
    "start": "1078799",
    "end": "1081120"
  },
  {
    "text": "cluster",
    "start": "1081120",
    "end": "1083679"
  },
  {
    "text": "as i mentioned the second approach to do",
    "start": "1086799",
    "end": "1089440"
  },
  {
    "text": "uh",
    "start": "1089440",
    "end": "1089919"
  },
  {
    "text": "distributed training on the spa data",
    "start": "1089919",
    "end": "1092160"
  },
  {
    "text": "frame is to use the",
    "start": "1092160",
    "end": "1093520"
  },
  {
    "text": "real mld set converter so if you prefer",
    "start": "1093520",
    "end": "1096559"
  },
  {
    "text": "to use the",
    "start": "1096559",
    "end": "1097760"
  },
  {
    "text": "for example the ray cd or whole wide api",
    "start": "1097760",
    "end": "1100480"
  },
  {
    "text": "directly",
    "start": "1100480",
    "end": "1101280"
  },
  {
    "text": "now you can use this converter to",
    "start": "1101280",
    "end": "1103440"
  },
  {
    "text": "convert a spark data frame",
    "start": "1103440",
    "end": "1105760"
  },
  {
    "text": "to array mld set the remote is that is a",
    "start": "1105760",
    "end": "1109360"
  },
  {
    "text": "distributed machine learning data stats",
    "start": "1109360",
    "end": "1112240"
  },
  {
    "text": "on",
    "start": "1112240",
    "end": "1112799"
  },
  {
    "text": "array and the data will be stored in",
    "start": "1112799",
    "end": "1115200"
  },
  {
    "text": "race",
    "start": "1115200",
    "end": "1116000"
  },
  {
    "text": "object store so we will provide the api",
    "start": "1116000",
    "end": "1118880"
  },
  {
    "text": "to create that from us by data frame",
    "start": "1118880",
    "end": "1121520"
  },
  {
    "text": "and the real media set also provides",
    "start": "1121520",
    "end": "1124160"
  },
  {
    "text": "apis",
    "start": "1124160",
    "end": "1124880"
  },
  {
    "text": "to transform your data sets",
    "start": "1124880",
    "end": "1128160"
  },
  {
    "text": "so you can use a user defined function",
    "start": "1128160",
    "end": "1130559"
  },
  {
    "text": "to transform every",
    "start": "1130559",
    "end": "1132320"
  },
  {
    "text": "data chart in the real mld set the real",
    "start": "1132320",
    "end": "1135440"
  },
  {
    "text": "media set also provides",
    "start": "1135440",
    "end": "1136799"
  },
  {
    "text": "apis to convert your dataset to a pi",
    "start": "1136799",
    "end": "1140880"
  },
  {
    "text": "torch or tensorflow",
    "start": "1140880",
    "end": "1142320"
  },
  {
    "text": "dataset so after that the data can",
    "start": "1142320",
    "end": "1145600"
  },
  {
    "text": "be easily loaded by python tensorflow",
    "start": "1145600",
    "end": "1150240"
  },
  {
    "text": "during the planning and execution phase",
    "start": "1150240",
    "end": "1154720"
  },
  {
    "text": "for the this example in this page now it",
    "start": "1155280",
    "end": "1158640"
  },
  {
    "text": "will",
    "start": "1158640",
    "end": "1160400"
  },
  {
    "text": "be divided into two phrases the first",
    "start": "1160400",
    "end": "1163280"
  },
  {
    "text": "one is to",
    "start": "1163280",
    "end": "1164640"
  },
  {
    "text": "store the spark data frame into the",
    "start": "1164640",
    "end": "1166720"
  },
  {
    "text": "array",
    "start": "1166720",
    "end": "1168000"
  },
  {
    "text": "object store and create that remedy",
    "start": "1168000",
    "end": "1170880"
  },
  {
    "text": "stats",
    "start": "1170880",
    "end": "1171600"
  },
  {
    "text": "and for every data chart there will be a",
    "start": "1171600",
    "end": "1175520"
  },
  {
    "text": "reactor to manage that data data chart",
    "start": "1175520",
    "end": "1179200"
  },
  {
    "text": "and for every uh transformation and the",
    "start": "1179200",
    "end": "1182559"
  },
  {
    "text": "conversion to pi torch or tensorflow",
    "start": "1182559",
    "end": "1185120"
  },
  {
    "text": "they",
    "start": "1185120",
    "end": "1185600"
  },
  {
    "text": "they can actually be executed in",
    "start": "1185600",
    "end": "1187120"
  },
  {
    "text": "pipeline so in this case if you want",
    "start": "1187120",
    "end": "1189919"
  },
  {
    "text": "to do the distributed python training uh",
    "start": "1189919",
    "end": "1192799"
  },
  {
    "text": "the second step",
    "start": "1192799",
    "end": "1194640"
  },
  {
    "text": "every python actor will directly",
    "start": "1194640",
    "end": "1197760"
  },
  {
    "text": "get the data from raised objects door",
    "start": "1197760",
    "end": "1200320"
  },
  {
    "text": "and do the",
    "start": "1200320",
    "end": "1201600"
  },
  {
    "text": "data transformation and convert into a",
    "start": "1201600",
    "end": "1203679"
  },
  {
    "text": "python stat",
    "start": "1203679",
    "end": "1204880"
  },
  {
    "text": "so that can be used as a",
    "start": "1204880",
    "end": "1208400"
  },
  {
    "text": "for the distributed training",
    "start": "1208400",
    "end": "1211679"
  },
  {
    "text": "next let's take a look at some",
    "start": "1214240",
    "end": "1217679"
  },
  {
    "text": "radiopa examples how we can",
    "start": "1217679",
    "end": "1220880"
  },
  {
    "text": "build energy and pipelines using spark",
    "start": "1220880",
    "end": "1224000"
  },
  {
    "text": "and other",
    "start": "1224000",
    "end": "1224960"
  },
  {
    "text": "machine learning and deep learning",
    "start": "1224960",
    "end": "1226159"
  },
  {
    "text": "frameworks",
    "start": "1226159",
    "end": "1228799"
  },
  {
    "text": "the first example is to run spark in the",
    "start": "1229280",
    "end": "1232000"
  },
  {
    "text": "exposure array",
    "start": "1232000",
    "end": "1233600"
  },
  {
    "text": "so this will be a integrated",
    "start": "1233600",
    "end": "1237039"
  },
  {
    "text": "python program and there are two parts",
    "start": "1237039",
    "end": "1240080"
  },
  {
    "text": "here",
    "start": "1240080",
    "end": "1240480"
  },
  {
    "text": "one is the data group setting part and",
    "start": "1240480",
    "end": "1242640"
  },
  {
    "text": "another one will be the model training",
    "start": "1242640",
    "end": "1244400"
  },
  {
    "text": "part",
    "start": "1244400",
    "end": "1246320"
  },
  {
    "text": "so uh in your python program for data",
    "start": "1246320",
    "end": "1249120"
  },
  {
    "text": "pre-processing",
    "start": "1249120",
    "end": "1250159"
  },
  {
    "text": "uh we can first connect to array cluster",
    "start": "1250159",
    "end": "1253600"
  },
  {
    "text": "using ray.init",
    "start": "1253600",
    "end": "1255360"
  },
  {
    "text": "and then we just use the ready p api to",
    "start": "1255360",
    "end": "1258799"
  },
  {
    "text": "start a spark job here after that we can",
    "start": "1258799",
    "end": "1262559"
  },
  {
    "text": "use any spark api to for example read",
    "start": "1262559",
    "end": "1265520"
  },
  {
    "text": "the csv",
    "start": "1265520",
    "end": "1266320"
  },
  {
    "text": "file and use the spa data frame api to",
    "start": "1266320",
    "end": "1270159"
  },
  {
    "text": "do",
    "start": "1270159",
    "end": "1270799"
  },
  {
    "text": "data pre-processing here finally we can",
    "start": "1270799",
    "end": "1274720"
  },
  {
    "text": "split our data set into a train and a",
    "start": "1274720",
    "end": "1277679"
  },
  {
    "text": "test data frame",
    "start": "1277679",
    "end": "1279200"
  },
  {
    "text": "and we can also convert the smart data",
    "start": "1279200",
    "end": "1282400"
  },
  {
    "text": "frame",
    "start": "1282400",
    "end": "1282960"
  },
  {
    "text": "to array mld set here in the model",
    "start": "1282960",
    "end": "1286159"
  },
  {
    "text": "training part we can",
    "start": "1286159",
    "end": "1287760"
  },
  {
    "text": "just follow the hd boost array",
    "start": "1287760",
    "end": "1291360"
  },
  {
    "text": "api and and uh in",
    "start": "1291360",
    "end": "1294559"
  },
  {
    "text": "for xbox one way it uses the ray d",
    "start": "1294559",
    "end": "1297039"
  },
  {
    "text": "matrix as a",
    "start": "1297039",
    "end": "1298320"
  },
  {
    "text": "basic data type for the training and",
    "start": "1298320",
    "end": "1301360"
  },
  {
    "text": "luckily it also is a support creating",
    "start": "1301360",
    "end": "1304080"
  },
  {
    "text": "uh array of dimensions from a",
    "start": "1304080",
    "end": "1307200"
  },
  {
    "text": "ray mld set so we can easily create that",
    "start": "1307200",
    "end": "1311520"
  },
  {
    "text": "using the remedies that we created",
    "start": "1311520",
    "end": "1314720"
  },
  {
    "text": "in the data pre-processing part after",
    "start": "1314720",
    "end": "1316960"
  },
  {
    "text": "that we can",
    "start": "1316960",
    "end": "1318080"
  },
  {
    "text": "uh just use the hd booster array",
    "start": "1318080",
    "end": "1321440"
  },
  {
    "text": "the train function to do distributed",
    "start": "1321440",
    "end": "1323919"
  },
  {
    "text": "attributes",
    "start": "1323919",
    "end": "1324799"
  },
  {
    "text": "uh training only so this is the example",
    "start": "1324799",
    "end": "1328080"
  },
  {
    "text": "how we can",
    "start": "1328080",
    "end": "1329440"
  },
  {
    "text": "integrate spark in each boost and",
    "start": "1329440",
    "end": "1331840"
  },
  {
    "text": "connect them",
    "start": "1331840",
    "end": "1334000"
  },
  {
    "text": "using the rear mld set and do the",
    "start": "1334000",
    "end": "1336880"
  },
  {
    "text": "discrete training array",
    "start": "1336880",
    "end": "1340320"
  },
  {
    "text": "the second example is to run spark in a",
    "start": "1341600",
    "end": "1344640"
  },
  {
    "text": "whole body array",
    "start": "1344640",
    "end": "1346159"
  },
  {
    "text": "so similarly this will be a integrated",
    "start": "1346159",
    "end": "1349200"
  },
  {
    "text": "python program",
    "start": "1349200",
    "end": "1350400"
  },
  {
    "text": "and in the data pre-processing part it",
    "start": "1350400",
    "end": "1352720"
  },
  {
    "text": "will be",
    "start": "1352720",
    "end": "1353840"
  },
  {
    "text": "very similar you connect to a way",
    "start": "1353840",
    "end": "1356159"
  },
  {
    "text": "cluster",
    "start": "1356159",
    "end": "1356960"
  },
  {
    "text": "and start a spot job array and then read",
    "start": "1356960",
    "end": "1359919"
  },
  {
    "text": "the data",
    "start": "1359919",
    "end": "1360799"
  },
  {
    "text": "and do data pre-processing using spark",
    "start": "1360799",
    "end": "1363679"
  },
  {
    "text": "api",
    "start": "1363679",
    "end": "1364400"
  },
  {
    "text": "and finally you can create a array",
    "start": "1364400",
    "end": "1367679"
  },
  {
    "text": "emergency set",
    "start": "1367679",
    "end": "1368799"
  },
  {
    "text": "and also you convert that to a",
    "start": "1368799",
    "end": "1372080"
  },
  {
    "text": "python data dataset and in the module",
    "start": "1372080",
    "end": "1375200"
  },
  {
    "text": "training pattern",
    "start": "1375200",
    "end": "1376400"
  },
  {
    "text": "now you uh define your pytorch model",
    "start": "1376400",
    "end": "1379919"
  },
  {
    "text": "and then you can follow the holovata",
    "start": "1379919",
    "end": "1382480"
  },
  {
    "text": "array",
    "start": "1382480",
    "end": "1383360"
  },
  {
    "text": "document to to do the distribute the",
    "start": "1383360",
    "end": "1386000"
  },
  {
    "text": "whole wide chaining",
    "start": "1386000",
    "end": "1387840"
  },
  {
    "text": "so in this case we need to define a",
    "start": "1387840",
    "end": "1390000"
  },
  {
    "text": "chain function",
    "start": "1390000",
    "end": "1391120"
  },
  {
    "text": "and this string function will be",
    "start": "1391120",
    "end": "1392640"
  },
  {
    "text": "executed by by",
    "start": "1392640",
    "end": "1395440"
  },
  {
    "text": "every training worker so it has the",
    "start": "1395440",
    "end": "1398400"
  },
  {
    "text": "information about the rank id",
    "start": "1398400",
    "end": "1401120"
  },
  {
    "text": "and by using this rank id we can",
    "start": "1401120",
    "end": "1404559"
  },
  {
    "text": "get the data chart from the pytorch",
    "start": "1404559",
    "end": "1407280"
  },
  {
    "text": "datasets",
    "start": "1407280",
    "end": "1408240"
  },
  {
    "text": "so every training worker will actually",
    "start": "1408240",
    "end": "1410159"
  },
  {
    "text": "get one data chart",
    "start": "1410159",
    "end": "1412799"
  },
  {
    "text": "for that for that training worker so",
    "start": "1412799",
    "end": "1415039"
  },
  {
    "text": "that they can",
    "start": "1415039",
    "end": "1416240"
  },
  {
    "text": "uh work together to do that distributed",
    "start": "1416240",
    "end": "1419360"
  },
  {
    "text": "training",
    "start": "1419360",
    "end": "1420640"
  },
  {
    "text": "and this dataset is actually the uh the",
    "start": "1420640",
    "end": "1423600"
  },
  {
    "text": "python",
    "start": "1423600",
    "end": "1424159"
  },
  {
    "text": "data that we created from the data",
    "start": "1424159",
    "end": "1426640"
  },
  {
    "text": "preprocessing part",
    "start": "1426640",
    "end": "1429520"
  },
  {
    "text": "so this is the example how we can",
    "start": "1429600",
    "end": "1431600"
  },
  {
    "text": "connect spark",
    "start": "1431600",
    "end": "1432720"
  },
  {
    "text": "with a holobot and do the data exchange",
    "start": "1432720",
    "end": "1436320"
  },
  {
    "text": "using array mld set",
    "start": "1436320",
    "end": "1440158"
  },
  {
    "text": "the next example is to run spark and a",
    "start": "1441760",
    "end": "1444960"
  },
  {
    "text": "whole lot",
    "start": "1444960",
    "end": "1445520"
  },
  {
    "text": "and also integrate them with ray tune to",
    "start": "1445520",
    "end": "1448400"
  },
  {
    "text": "do",
    "start": "1448400",
    "end": "1449039"
  },
  {
    "text": "a hyper parameter tuning array so",
    "start": "1449039",
    "end": "1453200"
  },
  {
    "text": "the data pre-processing part will be the",
    "start": "1453200",
    "end": "1454960"
  },
  {
    "text": "same but in the model training and the",
    "start": "1454960",
    "end": "1457120"
  },
  {
    "text": "tuning pattern",
    "start": "1457120",
    "end": "1458480"
  },
  {
    "text": "it's also straightforward to integrate",
    "start": "1458480",
    "end": "1461279"
  },
  {
    "text": "with ray tune to do",
    "start": "1461279",
    "end": "1462799"
  },
  {
    "text": "the high programming tuning so we can",
    "start": "1462799",
    "end": "1464960"
  },
  {
    "text": "just follow the",
    "start": "1464960",
    "end": "1466320"
  },
  {
    "text": "raytune api and in this case we can",
    "start": "1466320",
    "end": "1470640"
  },
  {
    "text": "search the the epoch and the learning",
    "start": "1470640",
    "end": "1473360"
  },
  {
    "text": "rate",
    "start": "1473360",
    "end": "1474000"
  },
  {
    "text": "and to get the better configuration for",
    "start": "1474000",
    "end": "1475919"
  },
  {
    "text": "this model training",
    "start": "1475919",
    "end": "1479200"
  },
  {
    "text": "finally let's give a brief summary",
    "start": "1480000",
    "end": "1483520"
  },
  {
    "text": "so we first discussed some background of",
    "start": "1483520",
    "end": "1487279"
  },
  {
    "text": "big data and",
    "start": "1487279",
    "end": "1488240"
  },
  {
    "text": "ai and how people are integrating them",
    "start": "1488240",
    "end": "1491039"
  },
  {
    "text": "and what are the",
    "start": "1491039",
    "end": "1492240"
  },
  {
    "text": "common challenges in different setups",
    "start": "1492240",
    "end": "1495120"
  },
  {
    "text": "and then we introduce",
    "start": "1495120",
    "end": "1496159"
  },
  {
    "text": "ray which is a general purpose framework",
    "start": "1496159",
    "end": "1498880"
  },
  {
    "text": "and that can be used",
    "start": "1498880",
    "end": "1500000"
  },
  {
    "text": "as a single substrate for energy and",
    "start": "1500000",
    "end": "1502720"
  },
  {
    "text": "data",
    "start": "1502720",
    "end": "1503200"
  },
  {
    "text": "analytics and er pipelines then we also",
    "start": "1503200",
    "end": "1506320"
  },
  {
    "text": "introduce radiop",
    "start": "1506320",
    "end": "1507760"
  },
  {
    "text": "which provides simple apis for running",
    "start": "1507760",
    "end": "1510240"
  },
  {
    "text": "spoken enrage",
    "start": "1510240",
    "end": "1511760"
  },
  {
    "text": "and also integrating spark waste",
    "start": "1511760",
    "end": "1514000"
  },
  {
    "text": "distributed machine learning and deep",
    "start": "1514000",
    "end": "1515760"
  },
  {
    "text": "learning frameworks",
    "start": "1515760",
    "end": "1517679"
  },
  {
    "text": "to get more information please visit our",
    "start": "1517679",
    "end": "1520799"
  },
  {
    "text": "github",
    "start": "1520799",
    "end": "1522080"
  },
  {
    "text": "repo and we also welcome any feedback on",
    "start": "1522080",
    "end": "1525279"
  },
  {
    "text": "this",
    "start": "1525279",
    "end": "1527360"
  },
  {
    "text": "thank you very much",
    "start": "1527360",
    "end": "1533520"
  }
]
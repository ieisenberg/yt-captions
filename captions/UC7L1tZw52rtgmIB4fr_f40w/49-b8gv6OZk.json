[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "okay so today is the 24th reno so you wanted to ask about multi-headed model functionality",
    "start": "320",
    "end": "6879"
  },
  {
    "text": "and someone wanted to ask about petting zoo integration and simon you wanted to ask",
    "start": "6879",
    "end": "12000"
  },
  {
    "text": "about gdpr okay for the multi-head one of the issues is that",
    "start": "12000",
    "end": "18400"
  },
  {
    "start": "15000",
    "end": "461000"
  },
  {
    "text": "you need to essentially separate the experiences from each",
    "start": "18400",
    "end": "25760"
  },
  {
    "text": "type of environment you need to you need to separate them in the replay buffer",
    "start": "25760",
    "end": "31599"
  },
  {
    "text": "and then so you need multiple replay levers this is what you want actually yeah because you need to sample evenly from",
    "start": "31599",
    "end": "38160"
  },
  {
    "text": "your tasks okay cool i have dealt with this before i used to do research in multitasking",
    "start": "38160",
    "end": "44879"
  },
  {
    "text": "meta reinforcement learning okay so",
    "start": "44879",
    "end": "51160"
  },
  {
    "text": "[Applause]",
    "start": "54650",
    "end": "57759"
  },
  {
    "text": "okay so essentially what you would do is like [Music]",
    "start": "78799",
    "end": "84799"
  },
  {
    "text": "you would create your own policy class in this case like overloading whichever algorithms policy",
    "start": "84799",
    "end": "90320"
  },
  {
    "text": "you want to overload or you would you can also directly inherit from this class called torch model v2",
    "start": "90320",
    "end": "97920"
  },
  {
    "text": "uh which is like the base pause uh uh well sorry not torch model v2 but torch",
    "start": "98159",
    "end": "103840"
  },
  {
    "text": "policy uh and like that's sort of the base class for our policies and",
    "start": "103840",
    "end": "109600"
  },
  {
    "text": "uh if it directly inherits all the methods that you need uh after that like what you would do is",
    "start": "109600",
    "end": "116719"
  },
  {
    "text": "you can define your own custom model over here so you could say like just like self.model is equal to",
    "start": "116719",
    "end": "123438"
  },
  {
    "text": "uh in this case like it would be like a pi torch model that has like multiple",
    "start": "123520",
    "end": "129119"
  },
  {
    "text": "heads okay uh and then when you call dot forward you have some way in order to like",
    "start": "129119",
    "end": "134160"
  },
  {
    "text": "select which head it is that you're gonna utilize in that situation",
    "start": "134160",
    "end": "140480"
  },
  {
    "text": "and then with your loss it would also",
    "start": "140720",
    "end": "146000"
  },
  {
    "text": "go pretty similarly if i understand this correctly it's like you would have a loss that uh",
    "start": "146000",
    "end": "152879"
  },
  {
    "text": "specifically propagates like through your different heads yeah which version is this",
    "start": "152879",
    "end": "159519"
  },
  {
    "text": "of ray yeah uh this is this is like currently master yeah this is the stuff that we're",
    "start": "159519",
    "end": "165200"
  },
  {
    "text": "implementing for this like new characters api it's gonna be on master you",
    "start": "165200",
    "end": "170879"
  },
  {
    "text": "okay you won't be able to find any of in 1.12 uh you will be able to find in 1.13",
    "start": "170879",
    "end": "178000"
  },
  {
    "text": "who knows if you're like still looking um you would define a",
    "start": "178000",
    "end": "183340"
  },
  {
    "text": "[Music] you define a model and this is actually like where you would implement like the",
    "start": "183340",
    "end": "189040"
  },
  {
    "text": "glue logic of your multiple heads",
    "start": "189040",
    "end": "194159"
  },
  {
    "text": "okay yeah so like over here you would like this just uh this class adherence from both torch",
    "start": "194159",
    "end": "200400"
  },
  {
    "text": "model b2 and nm module not entirely sure in this case like why we felt the need to inherit from both because this",
    "start": "200400",
    "end": "206159"
  },
  {
    "text": "inherits youtube directly from an dot module uh yeah i've seen yeah too",
    "start": "206159",
    "end": "213200"
  },
  {
    "text": "so when you do this you have to declare an attribute called self.model uh",
    "start": "213200",
    "end": "220319"
  },
  {
    "text": "in this case i think like we include something so that like you can create like a a set of like fully",
    "start": "220319",
    "end": "226560"
  },
  {
    "text": "connected layers that directly interface with your obj observation space and action space uh and then in this case like they're",
    "start": "226560",
    "end": "233120"
  },
  {
    "text": "using this centralized critic across centralized critic across multiple",
    "start": "233120",
    "end": "238720"
  },
  {
    "text": "policies and they create something here called central vf yeah and then",
    "start": "238720",
    "end": "244159"
  },
  {
    "text": "are you using torch by the way i'm sorry i forgot to ask uh yeah okay",
    "start": "244159",
    "end": "251439"
  },
  {
    "text": "yeah so you would have played your torch and also jax in the past but it seems",
    "start": "251439",
    "end": "256479"
  },
  {
    "text": "jack support is supposed to come in the next couple of months i believe right there's talk about that a couple months",
    "start": "256479",
    "end": "262720"
  },
  {
    "text": "ago we we want to do it the only thing is that uh",
    "start": "262720",
    "end": "269160"
  },
  {
    "text": "there also has to be like an implementation essentially of all the all of the distributed training",
    "start": "269360",
    "end": "275120"
  },
  {
    "text": "infrastructure for jacks which like jax doesn't technically support out of the box so",
    "start": "275120",
    "end": "281520"
  },
  {
    "text": "we have an intern on the raid train team who's working on that right now so",
    "start": "281520",
    "end": "286800"
  },
  {
    "text": "basically whenever he figures that out we will also migrate a lot of our algorithms to jax",
    "start": "286800",
    "end": "292639"
  },
  {
    "text": "and eventually drop tensorflow on support in your forward method you would",
    "start": "292639",
    "end": "298560"
  },
  {
    "text": "probably have to specify something that specifies the head that you're gonna",
    "start": "298560",
    "end": "304639"
  },
  {
    "text": "actually be using uh flexible",
    "start": "304639",
    "end": "309639"
  },
  {
    "text": "how flexible are things for me to add extra arguments to like forward for a model",
    "start": "310639",
    "end": "316880"
  },
  {
    "text": "you can so you can actually add extra arguments to forward for a model because you're also going to be the one who",
    "start": "316880",
    "end": "323520"
  },
  {
    "text": "calls forward for your model",
    "start": "323520",
    "end": "328800"
  },
  {
    "text": "yeah that's true if i understand well i mean like you you you definitely will have that",
    "start": "329120",
    "end": "334960"
  },
  {
    "text": "flexibility i'll let you know yeah",
    "start": "334960",
    "end": "339840"
  },
  {
    "text": "yeah cause one of the one of the things i've i've been having",
    "start": "340160",
    "end": "345600"
  },
  {
    "text": "some trouble with is then when when it comes to calling calling the policy",
    "start": "345600",
    "end": "352960"
  },
  {
    "text": "uh like during tests well not necessarily during test time but",
    "start": "352960",
    "end": "360560"
  },
  {
    "text": "there's let me bring this up there's like a whole rabbit hole you need to go through",
    "start": "360800",
    "end": "366479"
  },
  {
    "text": "to actually calling calling your model oh yeah okay do you want to share your",
    "start": "366479",
    "end": "372639"
  },
  {
    "text": "screen and show me what it is that you're talking about apologies i have some noise in the background a little bit",
    "start": "372639",
    "end": "379199"
  },
  {
    "text": "so listen as an example there's a couple of functions that",
    "start": "379199",
    "end": "384720"
  },
  {
    "text": "uh it's like compute single action",
    "start": "384720",
    "end": "391360"
  },
  {
    "text": "and then compute action helper and it's only like down here that you actually get into the",
    "start": "391360",
    "end": "398160"
  },
  {
    "text": "model itself so and then that's in the actual policy",
    "start": "398160",
    "end": "405199"
  },
  {
    "text": "itself so i guess my question for you then is like why would you not just",
    "start": "405199",
    "end": "411039"
  },
  {
    "text": "uh over like uh why would you just not override the compute action of the",
    "start": "411039",
    "end": "418240"
  },
  {
    "text": "policy that you're inherited from i mean you should just be able to",
    "start": "418240",
    "end": "424400"
  },
  {
    "text": "overload compute action directly and then you know so long as compute action takes",
    "start": "424479",
    "end": "429759"
  },
  {
    "text": "in whatever parameters like it's typically supposed to take in in this case like i know that a sample batch",
    "start": "429759",
    "end": "435039"
  },
  {
    "text": "would be there what i would probably do if i were you is like i would stick the task id somewhere inside",
    "start": "435039",
    "end": "440240"
  },
  {
    "text": "of m infos or i would stick it like an in another attribute you can arbitrarily",
    "start": "440240",
    "end": "445599"
  },
  {
    "text": "expand sepal batches however you want and then",
    "start": "445599",
    "end": "450960"
  },
  {
    "text": "i would feed that then to my model.forward and then inside my model off word i",
    "start": "450960",
    "end": "456160"
  },
  {
    "text": "would use like some torch conditional to select whichever head",
    "start": "456160",
    "end": "461599"
  },
  {
    "start": "461000",
    "end": "734000"
  },
  {
    "text": "i need right yeah all right so then the only other thing is uh the multiple",
    "start": "461840",
    "end": "469360"
  },
  {
    "text": "multiple experience multiple buffers oh yeah",
    "start": "469360",
    "end": "475280"
  },
  {
    "text": "essentially how to how to actually feed into those because",
    "start": "475280",
    "end": "481520"
  },
  {
    "text": "i think the best way to set up the multiple in multiple environments is through the",
    "start": "481520",
    "end": "489039"
  },
  {
    "text": "tasks edible environment but uh then how do you interface that with",
    "start": "489039",
    "end": "495919"
  },
  {
    "text": "a revit buffer yeah so are you using ppo as your base algorithm or are you planning on using another",
    "start": "495919",
    "end": "502000"
  },
  {
    "text": "algorithm i'm trying to get impala and rtd2 to work as well",
    "start": "502000",
    "end": "508000"
  },
  {
    "text": "i'll show you with impala just because we have replay buffers over impala yeah oh yeah i mean i",
    "start": "508000",
    "end": "513680"
  },
  {
    "text": "if i were to switch to this i wouldn't be using ppo since ppo doesn't use the replay buffer so",
    "start": "513680",
    "end": "519760"
  },
  {
    "text": "it doesn't directly use the replay buffer yeah so you'd probably not want to do that uh",
    "start": "519760",
    "end": "526399"
  },
  {
    "text": "i think it's on the question right so yeah it's on policy yeah uh",
    "start": "526399",
    "end": "532320"
  },
  {
    "text": "you can you can use this thing called mix and replay though which is like what impala does that's what the replay lever is before",
    "start": "532320",
    "end": "539680"
  },
  {
    "text": "yeah so i guess a couple of things let me think",
    "start": "540480",
    "end": "546080"
  },
  {
    "text": "so the first is like uh i haven't used the tasks that it will end but like",
    "start": "546080",
    "end": "551279"
  },
  {
    "text": "how has task context actually changed is it just changed on every single",
    "start": "551760",
    "end": "557040"
  },
  {
    "text": "uh environment iteration",
    "start": "557040",
    "end": "560920"
  },
  {
    "text": "um each episode yeah each episode oh okay",
    "start": "562160",
    "end": "569360"
  },
  {
    "text": "give the context too much but okay sure uh",
    "start": "569519",
    "end": "575279"
  },
  {
    "text": "okay but like how how do you how do you know which task you sampled from that's that's i guess is like my question is it",
    "start": "575440",
    "end": "580880"
  },
  {
    "text": "like a part of the admin foes or is it like how do you how do you return which",
    "start": "580880",
    "end": "586160"
  },
  {
    "text": "so like if i'm i don't know if my tasks are like different atari tasks how do i know",
    "start": "586160",
    "end": "591440"
  },
  {
    "text": "which environment it came from so i can show you the actual api",
    "start": "591440",
    "end": "598560"
  },
  {
    "text": "okay i'm pretty sure i'd have to add some sort of mix in at the end because you can",
    "start": "598560",
    "end": "605440"
  },
  {
    "text": "so there's three functions sample tasks set task and get task i'm pretty sure you'd be able to call get task",
    "start": "605440",
    "end": "614000"
  },
  {
    "text": "uh like at the end of an episode okay",
    "start": "614160",
    "end": "619600"
  },
  {
    "text": "oh use this from mammal okay that makes sense",
    "start": "619600",
    "end": "624079"
  },
  {
    "text": "okay so if i just search up like get task okay so you pass this task function to",
    "start": "625040",
    "end": "631440"
  },
  {
    "text": "the trainer and then the task function figures out based off of the results",
    "start": "631440",
    "end": "636800"
  },
  {
    "text": "whether or not it should switch to a new task and then you get the current task the current task is not equal to new",
    "start": "636800",
    "end": "642480"
  },
  {
    "text": "tasks you set the task to the mean task okay",
    "start": "642480",
    "end": "647760"
  },
  {
    "text": "cool i guess that makes sense to me",
    "start": "647760",
    "end": "655200"
  },
  {
    "text": "the only thing is we still need to wait original was meant for curriculum training which",
    "start": "655200",
    "end": "661279"
  },
  {
    "text": "makes sense for her yeah it makes sense made for like meta learning using random",
    "start": "661279",
    "end": "667680"
  },
  {
    "text": "goal half sheet of random direction pendulum with different masses",
    "start": "667680",
    "end": "674320"
  },
  {
    "text": "okay so the only thing is we just need to look at like a",
    "start": "674320",
    "end": "680800"
  },
  {
    "text": "task that will and overrides gm dot and okay so you you still definitely need something in order",
    "start": "680800",
    "end": "687360"
  },
  {
    "text": "to figure out like what tasks you actually are going to be operating on just",
    "start": "687360",
    "end": "693440"
  },
  {
    "text": "because you have multiple heads so this isn't a challenge in metal learning just because like in metal learning you're not supposed to have access to that",
    "start": "693440",
    "end": "699600"
  },
  {
    "text": "information so we didn't technically support it",
    "start": "699600",
    "end": "704640"
  },
  {
    "text": "so step one is like add something to your admin post just because like otherwise there's not",
    "start": "706000",
    "end": "711279"
  },
  {
    "text": "going to be any way to figure out which task",
    "start": "711279",
    "end": "716959"
  },
  {
    "text": "you're directly inheriting from and then",
    "start": "716959",
    "end": "722079"
  },
  {
    "text": "now for replay buffers specifically let me share my screen again",
    "start": "722720",
    "end": "728079"
  },
  {
    "text": "this is actually not too bad so do you uh so i guess my",
    "start": "729200",
    "end": "735120"
  },
  {
    "start": "734000",
    "end": "1005000"
  },
  {
    "text": "first question for you is like do you um do you pip install ray and then like try to inherit stuff and then implement it",
    "start": "735120",
    "end": "741760"
  },
  {
    "text": "or have you have you just cloned the repo and then you've installed it and then you're",
    "start": "741760",
    "end": "747839"
  },
  {
    "text": "working right inside of the install and inherit you couldn't solder here okay cool",
    "start": "747839",
    "end": "753440"
  },
  {
    "text": "let's say you're working on impala okay like you want to implement the impala agent",
    "start": "753440",
    "end": "759040"
  },
  {
    "text": "you could say like from ray.rlib dot",
    "start": "759040",
    "end": "764160"
  },
  {
    "text": "agents impala import impala trainer and then class",
    "start": "764160",
    "end": "773079"
  },
  {
    "text": "multitask learner",
    "start": "773680",
    "end": "776720"
  },
  {
    "text": "that'll extend the impala trainer but we're still going to need to read the impala code here to understand like",
    "start": "781519",
    "end": "787920"
  },
  {
    "text": "where it is i would actually stick with custom replay buffer so in impala",
    "start": "787920",
    "end": "795279"
  },
  {
    "text": "in impala we have like this gender and infection you're actually not going to touch this just because like",
    "start": "797279",
    "end": "803680"
  },
  {
    "text": "this is not what you need access to in the situation uh okay so this is some stuff for like",
    "start": "804639",
    "end": "814040"
  },
  {
    "text": "i i can walk this for a second so this this over here is like these config objects that we've",
    "start": "814320",
    "end": "819519"
  },
  {
    "text": "created because uh users typically struggle to yeah sounds like dictionaries yeah",
    "start": "819519",
    "end": "824720"
  },
  {
    "text": "replacing we're not replacing the dictionaries we're creating an interface on top of them so you can still use the dictionary directly",
    "start": "824720",
    "end": "831279"
  },
  {
    "text": "uh but [Music] just because that gives people like a lot of flexibility when they're designing their own apis on top of rlib",
    "start": "831279",
    "end": "838560"
  },
  {
    "text": "but yeah this should still make life easier so",
    "start": "838560",
    "end": "844160"
  },
  {
    "text": "if i come over to impala the first thing is like uh",
    "start": "844160",
    "end": "849519"
  },
  {
    "text": "in this case like you would stick your own policy class in here where it says get default policy class",
    "start": "849519",
    "end": "854720"
  },
  {
    "text": "so i'd say like",
    "start": "854720",
    "end": "858399"
  },
  {
    "text": "be like oh",
    "start": "862720",
    "end": "866680"
  },
  {
    "text": "[Applause] so i'd stick my own policy class here i just returned",
    "start": "874350",
    "end": "881199"
  },
  {
    "text": "uh second thing though is that like you want to know about like how i would actually implement separate replay buffers so",
    "start": "882240",
    "end": "888160"
  },
  {
    "text": "there's a setup function okay and in this setup function this is typically where we",
    "start": "888160",
    "end": "895600"
  },
  {
    "text": "we provide all of the we we instantiate all of like the",
    "start": "895839",
    "end": "901440"
  },
  {
    "text": "the necessary objects for your experiment okay like this is actually how i designed it so",
    "start": "902639",
    "end": "909120"
  },
  {
    "text": "i guess i'd first like call def set up and um",
    "start": "909120",
    "end": "915199"
  },
  {
    "text": "and then i'd say like",
    "start": "916639",
    "end": "919360"
  },
  {
    "text": "a trainer",
    "start": "921680",
    "end": "925079"
  },
  {
    "text": "so you definitely have to call super.setup just because like this will create all of this extra stuff",
    "start": "928399",
    "end": "934800"
  },
  {
    "text": "uh that you need in order to run impala or you can just uh you can just copy this also which is",
    "start": "934800",
    "end": "941440"
  },
  {
    "text": "fine in this situation uh it would require like a little bit of reading to understand all the extra",
    "start": "941440",
    "end": "947680"
  },
  {
    "text": "stuff that's happening underneath over here uh so for example like we have these replay buffer replay buffers that you do mix",
    "start": "947680",
    "end": "955120"
  },
  {
    "text": "and replay on uh but",
    "start": "955120",
    "end": "959279"
  },
  {
    "text": "we also like provide the option for them to be like separate actors that can essentially work in parallel to your",
    "start": "960720",
    "end": "966959"
  },
  {
    "text": "experiment and the reason that we do this is because we give users the options to like",
    "start": "966959",
    "end": "973199"
  },
  {
    "text": "compress their observations and this is particularly important in the situation where you are like working with these observations",
    "start": "973199",
    "end": "979199"
  },
  {
    "text": "that are like these large 3d point cloud maps or just like really large images and like",
    "start": "979199",
    "end": "984800"
  },
  {
    "text": "quite a few of them and so like the compression and decompression steps can take a pretty long time",
    "start": "984800",
    "end": "990639"
  },
  {
    "text": "but like if you do them on separate week workers like you'll see like quite a significant speed up",
    "start": "990639",
    "end": "997839"
  },
  {
    "text": "okay but in a sense like uh there's something over here that we use",
    "start": "998000",
    "end": "1003440"
  },
  {
    "text": "to create repeat buffers and if i go over to like this simple replay offer.api yeah",
    "start": "1003440",
    "end": "1009120"
  },
  {
    "start": "1005000",
    "end": "1249000"
  },
  {
    "text": "uh so the simple replay buffer has like an ad function and it has a sample function okay",
    "start": "1009120",
    "end": "1016399"
  },
  {
    "text": "and in the scenario of in a scenario like that you're",
    "start": "1016399",
    "end": "1022399"
  },
  {
    "text": "wanting to use impala which uses a mix and replay so that that would be the case for you doing an on-policy algorithm it's like if you want to have",
    "start": "1022399",
    "end": "1029918"
  },
  {
    "text": "a replay experience but then also like you needed to be on policy you would do",
    "start": "1029919",
    "end": "1035438"
  },
  {
    "text": "this thing called mix and replay i can explain it to you if like uh you want to know what that means",
    "start": "1035439",
    "end": "1041199"
  },
  {
    "text": "uh in a nutshell we mix in some of our current on policy examples with like a couple of off",
    "start": "1041199",
    "end": "1048480"
  },
  {
    "text": "policy patches and we do this just so that like we don't like",
    "start": "1048480",
    "end": "1054160"
  },
  {
    "text": "hit these uh we don't hit these weird exploration",
    "start": "1054160",
    "end": "1060080"
  },
  {
    "text": "states in during our training like this is just something that typically happens like in",
    "start": "1060080",
    "end": "1066559"
  },
  {
    "text": "on policy learning and then um yeah yeah so okay if i come back here really",
    "start": "1066559",
    "end": "1072559"
  },
  {
    "text": "quickly uh can i go to",
    "start": "1072559",
    "end": "1076720"
  },
  {
    "text": "multi-agent makes in replay buffer so there's an ad there's an ad batch",
    "start": "1078400",
    "end": "1084960"
  },
  {
    "text": "which just takes in a generic sample batch and then there's sample which takes them like a number of",
    "start": "1086400",
    "end": "1091840"
  },
  {
    "text": "items to sample so in the case of your replay buffer",
    "start": "1091840",
    "end": "1098080"
  },
  {
    "text": "you can like copy the logic from say like",
    "start": "1098320",
    "end": "1104080"
  },
  {
    "text": "fragments over here because like impala will work on like replay fragments but um",
    "start": "1104080",
    "end": "1110640"
  },
  {
    "text": "so you can copy the logic over here for add from fragments and then",
    "start": "1110640",
    "end": "1116480"
  },
  {
    "text": "there's actually multiple replay buffers that are underneath this replay buffer right so like we have this attribute",
    "start": "1116480",
    "end": "1122799"
  },
  {
    "text": "over here called self.replaybuffers and we've designed it currently in the case that like you would um",
    "start": "1122799",
    "end": "1129840"
  },
  {
    "text": "have multiple agents in your you would have multiple agents inside of",
    "start": "1129840",
    "end": "1136000"
  },
  {
    "text": "your uh inside of your environment but you can definitely use this instead to like talk",
    "start": "1136000",
    "end": "1141280"
  },
  {
    "text": "about multiple tasks and then if you come back to add then basically what i would do is i would check to see",
    "start": "1141280",
    "end": "1146880"
  },
  {
    "text": "for each one of like the fragments a fragment in this case being like some amount of like time steps that you",
    "start": "1146880",
    "end": "1152400"
  },
  {
    "text": "collected in a non-policy fashion uh i would add it by",
    "start": "1152400",
    "end": "1158640"
  },
  {
    "text": "task id and then when i come to sample i'd sample a number of items and then",
    "start": "1158640",
    "end": "1165039"
  },
  {
    "text": "uh i guess you can change like number of items to mean whatever it is that you want to so maybe in this case you could be like",
    "start": "1165039",
    "end": "1170480"
  },
  {
    "text": "number of items per task id or you could mean like the whole sum as a whole that",
    "start": "1170480",
    "end": "1176080"
  },
  {
    "text": "way you sample evenly really just like whatever makes more sense to you and then",
    "start": "1176080",
    "end": "1183919"
  },
  {
    "text": "i would follow this logic for mixing batches and then",
    "start": "1184320",
    "end": "1190720"
  },
  {
    "text": "i guess you also yeah you probably would want to copy this to this check if buffer is ready this just essentially",
    "start": "1191760",
    "end": "1198080"
  },
  {
    "text": "checks to see whether like a replay buffer has a minimum number of samples in it so that you can sample from it so",
    "start": "1198080",
    "end": "1204320"
  },
  {
    "text": "it implements like some of that starting logic from like when you're doing your sampling but you don't have enough samples yet to do your mixing",
    "start": "1204320",
    "end": "1212400"
  },
  {
    "text": "and then after that i would implement the logic over here to sample from these individual replay buffers and",
    "start": "1212400",
    "end": "1219760"
  },
  {
    "text": "the individual replay buffers are simple replay buffers so you can just query the repo buffer by",
    "start": "1219760",
    "end": "1225360"
  },
  {
    "text": "task id and then uh you could i don't know say like keep",
    "start": "1225360",
    "end": "1230960"
  },
  {
    "text": "around like a dictionary of task ids inside of your replay buffer too that way you don't have to",
    "start": "1230960",
    "end": "1236400"
  },
  {
    "text": "keep track of it anywhere else and then sample evenly from your your individual simple replay buffers having some task",
    "start": "1236400",
    "end": "1243039"
  },
  {
    "text": "id and then when you come back out um",
    "start": "1243039",
    "end": "1248600"
  },
  {
    "text": "[Music] when you come back out uh yeah you should be able to you should be",
    "start": "1248600",
    "end": "1254960"
  },
  {
    "start": "1249000",
    "end": "1390000"
  },
  {
    "text": "able to do it that way uh yeah so like this mix and replay buffer gets called inside",
    "start": "1254960",
    "end": "1260640"
  },
  {
    "text": "of a training iteration function so like if i go to this uh process experiences directly it uses the local",
    "start": "1260640",
    "end": "1266880"
  },
  {
    "text": "mix and replay lever and uh i mean let me know if this like",
    "start": "1266880",
    "end": "1272960"
  },
  {
    "text": "doesn't make sense to you just because i know it's a new code that we're reading for the first time here",
    "start": "1272960",
    "end": "1278080"
  },
  {
    "text": "but so over here like this is where you would add samples to your replay buffers",
    "start": "1278080",
    "end": "1283840"
  },
  {
    "text": "uh if you didn't want to go through the process of like implementing your own mix and replay just because i get that's",
    "start": "1283840",
    "end": "1289039"
  },
  {
    "text": "kind of like a hassle to do something else i might consider doing is i would create a mix and replay buffer for every",
    "start": "1289039",
    "end": "1295520"
  },
  {
    "text": "single task inside of my task dictionary and then",
    "start": "1295520",
    "end": "1300640"
  },
  {
    "text": "when i go to process experiences directly inside of these uh batches i can like iterate through the",
    "start": "1300640",
    "end": "1306400"
  },
  {
    "text": "batches and actually see like which batches belong to like a certain task id",
    "start": "1306400",
    "end": "1311679"
  },
  {
    "text": "and then over here like this is where i would query by task id and then add to like a",
    "start": "1311679",
    "end": "1317520"
  },
  {
    "text": "specific mix and replay buffer if that suits you better it's it's like",
    "start": "1317520",
    "end": "1324799"
  },
  {
    "text": "it's it's uh actually i'd probably do it this way just like if i was doing some rapid iteration and i didn't need to",
    "start": "1324799",
    "end": "1333600"
  },
  {
    "text": "make something that was like further extendable beyond this does that answer your question",
    "start": "1333600",
    "end": "1340480"
  },
  {
    "text": "yeah i think yeah i think that does you can probably move on now i know it's been half an hour so yeah but i hope",
    "start": "1340480",
    "end": "1346480"
  },
  {
    "text": "this helps you uh yeah no it definitely did thank you yeah i i know like it's not as",
    "start": "1346480",
    "end": "1351520"
  },
  {
    "text": "satisfying that you still do have to dig into the impala code specifically but we have done a lot of work recently to",
    "start": "1351520",
    "end": "1358400"
  },
  {
    "text": "make it really easy to read and then just like drop you know pdb breakpoints directly within",
    "start": "1358400",
    "end": "1363760"
  },
  {
    "text": "like the scope of your execution so",
    "start": "1363760",
    "end": "1368799"
  },
  {
    "text": "i hope this helps but if it doesn't like please feel free to reach out on the slack and",
    "start": "1368799",
    "end": "1374880"
  },
  {
    "text": "uh yeah we can definitely even set up time with you to help you out yeah okay yeah that's good thanks",
    "start": "1374880",
    "end": "1382320"
  },
  {
    "text": "okay simon you are next",
    "start": "1382320",
    "end": "1387000"
  },
  {
    "text": "uh i'll say sorry also joseph uh came in",
    "start": "1388400",
    "end": "1394000"
  },
  {
    "start": "1390000",
    "end": "2974000"
  },
  {
    "text": "uh he was in queue before mia hello me in",
    "start": "1394000",
    "end": "1399440"
  },
  {
    "text": "the dark okay all right can you hear me yeah i can hear you joseph",
    "start": "1399440",
    "end": "1404640"
  },
  {
    "text": "i think that i already i mentioned some of this uh uh avnish already we had some of this discussion on slack already but",
    "start": "1404640",
    "end": "1410799"
  },
  {
    "text": "it's just the case that petting zoo is becoming um an increasingly widely adapted project",
    "start": "1410799",
    "end": "1416640"
  },
  {
    "text": "i'm using it in neural mmo it's a great api it has tons of bindings for other things that people are using in rl",
    "start": "1416640",
    "end": "1423919"
  },
  {
    "text": "and it seems that it can do what just about everything that can be done with the current rlib api so it's quite",
    "start": "1423919",
    "end": "1431360"
  },
  {
    "text": "similar in fact so yeah if you want to add some details on that jordan yeah the main thing is that so",
    "start": "1431360",
    "end": "1438559"
  },
  {
    "text": "headings kind of become the standard multi-agent api it is used as the default api for pretty much all",
    "start": "1438559",
    "end": "1445279"
  },
  {
    "text": "the major um third-party environments like unity ml agents for instance and their master",
    "start": "1445279",
    "end": "1451039"
  },
  {
    "text": "switched using putting to instead of their custom thing um chiang cho is using petting zoo like literally every",
    "start": "1451039",
    "end": "1457840"
  },
  {
    "text": "meaningfully sized multi-agent or a library um outside of the minds which uses custom",
    "start": "1457840",
    "end": "1464799"
  },
  {
    "text": "stuff uses petting zoo and pretty much all the third-party um libraries like smack or",
    "start": "1464799",
    "end": "1470559"
  },
  {
    "text": "whatever do as well the environment um and so if there's a standard and so",
    "start": "1470559",
    "end": "1475840"
  },
  {
    "text": "you guys support the pending api but if there's a standard api that like all the other multiplication apis are using you",
    "start": "1475840",
    "end": "1480880"
  },
  {
    "text": "know an hour gets to gem then it is it's better for the community",
    "start": "1480880",
    "end": "1486880"
  },
  {
    "text": "and saves development costs for rl lib to switch uh your internal api to petting zoo which you already support",
    "start": "1486880",
    "end": "1494240"
  },
  {
    "text": "so i do like petting zoo okay um but i think our main we had like a couple of issues",
    "start": "1494240",
    "end": "1502240"
  },
  {
    "text": "with uh doing the migration uh so the first is that like uh",
    "start": "1502240",
    "end": "1508880"
  },
  {
    "text": "we have customers who do multiagent reinforcement learning and",
    "start": "1508880",
    "end": "1514840"
  },
  {
    "text": "we proposed to them the idea of the migration and i walked them through like how the actual migration would look and",
    "start": "1515039",
    "end": "1521039"
  },
  {
    "text": "then i had them like go and inspect the heading zoo api and",
    "start": "1521039",
    "end": "1526960"
  },
  {
    "text": "i'd say like a split of like 50 50 um",
    "start": "1526960",
    "end": "1531919"
  },
  {
    "text": "wanted and uh wanted and didn't want it and i'd say that like uh i think the predominant",
    "start": "1532400",
    "end": "1538159"
  },
  {
    "text": "issue is that like uh it's actually the issue that penning petting zoo tries to solve which like personally i'm a fan of",
    "start": "1538159",
    "end": "1543679"
  },
  {
    "text": "it's like phrasing all of these as like uh uh you know two-step games right so that",
    "start": "1543679",
    "end": "1549039"
  },
  {
    "text": "way like i think you don't have that it has the aec api and has the parallel",
    "start": "1549039",
    "end": "1554080"
  },
  {
    "text": "the parallate guy is for all functional purposes identical to rls built-in api",
    "start": "1554080",
    "end": "1559760"
  },
  {
    "text": "and the way that they're constructed is that you can switch between the two pretty much for free and and to add to that avnish um i used our libs multi so",
    "start": "1559760",
    "end": "1568240"
  },
  {
    "text": "i my main project neural mmo right i use basically all the features in relib um so i might it would i will tell you the",
    "start": "1568240",
    "end": "1575039"
  },
  {
    "text": "migration from rlibs api to pettings is it was basically trivial um because",
    "start": "1575039",
    "end": "1580880"
  },
  {
    "text": "it is using a parallel version yeah exactly so it's it's very easy to support a large number of environments",
    "start": "1580880",
    "end": "1587039"
  },
  {
    "text": "either turn based or parallel okay that that is like one problem that's definitely solved but i think",
    "start": "1587039",
    "end": "1592559"
  },
  {
    "text": "like uh a larger thing that we face right now is like we also have these customers who",
    "start": "1592559",
    "end": "1600080"
  },
  {
    "text": "work across all these different operating systems and all these different versions of python and like",
    "start": "1600080",
    "end": "1607120"
  },
  {
    "text": "as much as it is a as much it is like i don't want to call it a burden just because like it is their situation right",
    "start": "1607120",
    "end": "1614080"
  },
  {
    "text": "but like um yeah in a nutshell it makes it",
    "start": "1614080",
    "end": "1620080"
  },
  {
    "text": "difficult to support them like when uh the upstream packages that we use",
    "start": "1620080",
    "end": "1625120"
  },
  {
    "text": "don't necessarily provide that support to them heading zoo is so petting zoo is pure",
    "start": "1625120",
    "end": "1631360"
  },
  {
    "text": "python um so it'll work on any operating system",
    "start": "1631360",
    "end": "1636960"
  },
  {
    "text": "um the only exceptions to this are um",
    "start": "1636960",
    "end": "1641919"
  },
  {
    "text": "so heading do and jim both you know have um as extra dependencies things that are",
    "start": "1642159",
    "end": "1647360"
  },
  {
    "text": "compiled in c all those support mac and uh all those support mac and linux",
    "start": "1647360",
    "end": "1654000"
  },
  {
    "text": "yeah yeah and most of them support our mac that we're working on that and some of them support windows and some don't",
    "start": "1654000",
    "end": "1660080"
  },
  {
    "text": "forget that compile things to this point so that's kind of uncommon and that isn't applied because it's a core api that's a specific environmental",
    "start": "1660080",
    "end": "1666080"
  },
  {
    "text": "limitation and that's true of gem and not just pension as part as python versions go",
    "start": "1666080",
    "end": "1672159"
  },
  {
    "text": "we obviously support three point seven to three point ten you mentioned this on github that people are still using three point six and i'm still using 3.6 yeah",
    "start": "1672159",
    "end": "1679919"
  },
  {
    "text": "i'm probably confused about that you know like i i don't disagree with you by the way",
    "start": "1679919",
    "end": "1684960"
  },
  {
    "text": "like i i don't see like a reason why people should be using python 3.6 it's just that like",
    "start": "1684960",
    "end": "1691200"
  },
  {
    "text": "our customers are people who also like have the burden of migration across our whole organizations",
    "start": "1691200",
    "end": "1698080"
  },
  {
    "text": "that's like that's inevitably what this is all about it's that like sure like i i would prefer that like i",
    "start": "1698080",
    "end": "1704480"
  },
  {
    "text": "mean like you you're you're taught like you know we're not we're not on different sides of this issue effectively you know like",
    "start": "1704480",
    "end": "1711200"
  },
  {
    "text": "it's a it's it is a it is like in some ways a pain for me to have to maintain stuff for python 3.6 yeah",
    "start": "1711200",
    "end": "1718080"
  },
  {
    "text": "yeah but like i i can't help you there honestly like we have customers who pay us",
    "start": "1718080",
    "end": "1724480"
  },
  {
    "text": "3.6 will be removed like is there like a plan for this at some point",
    "start": "1724480",
    "end": "1729520"
  },
  {
    "text": "yeah i mean so like we keep bringing it like i i've brought it up before the leadership team and our staff squeeze have brought it up before too um",
    "start": "1729520",
    "end": "1738520"
  },
  {
    "text": "i'd say i'd say it's not extremely far off you",
    "start": "1739520",
    "end": "1744640"
  },
  {
    "text": "know like it's not like we're gonna just keep this around for like five years six years uh",
    "start": "1744640",
    "end": "1750799"
  },
  {
    "text": "but it's definitely like i i wouldn't hold your breath you know like i wouldn't i wouldn't expect",
    "start": "1750799",
    "end": "1756720"
  },
  {
    "text": "it to like happen [Music] until like say it like rate 3.0 yeah as like",
    "start": "1756720",
    "end": "1762960"
  },
  {
    "text": "as you know right through that would be released like next may essentially a year from now yeah",
    "start": "1762960",
    "end": "1770000"
  },
  {
    "text": "yeah as as like as difficult as that sounds so",
    "start": "1770000",
    "end": "1775540"
  },
  {
    "text": "[Music] what we may be able to do then is to have python 3.6 support the",
    "start": "1775540",
    "end": "1782960"
  },
  {
    "text": "gym and petting zoo for the api only and not all the environments",
    "start": "1782960",
    "end": "1788799"
  },
  {
    "text": "oh okay yeah i mean um because some of the environments that involve stuff with c",
    "start": "1788799",
    "end": "1794799"
  },
  {
    "text": "um going and adding 3.6 is not going to end well",
    "start": "1794799",
    "end": "1801279"
  },
  {
    "text": "but we could do releases that uh just like the core python api that re-add 3.6",
    "start": "1801279",
    "end": "1806840"
  },
  {
    "text": "support i mean i don't want to hear uh jet you have been do you have a sense of how hard",
    "start": "1806840",
    "end": "1811919"
  },
  {
    "text": "this will be uh nope not yet",
    "start": "1811919",
    "end": "1819519"
  },
  {
    "text": "depends what approach you take could just sort of i mean the approach would be to turn right through python",
    "start": "1820960",
    "end": "1827360"
  },
  {
    "text": "3.6 tests on nci again and heat and hit it with a wrench until it stops getting errors",
    "start": "1827360",
    "end": "1835320"
  },
  {
    "text": "um i mean that would include all the environments right because yeah that's all the environments oh yeah okay so",
    "start": "1837120",
    "end": "1843279"
  },
  {
    "text": "fine figure out a way to turn ci on without the environment yeah i mean we could just run i suppose",
    "start": "1843279",
    "end": "1850240"
  },
  {
    "text": "have a ci run it just doesn't really test maybe only test this upset environments which actually work",
    "start": "1850240",
    "end": "1856559"
  },
  {
    "text": "yeah you can just give us like ump because",
    "start": "1856559",
    "end": "1860720"
  },
  {
    "text": "oh yeah yeah i was i was agreeing with uh your was it ben who was talking before this sorry",
    "start": "1861679",
    "end": "1866880"
  },
  {
    "text": "uh yeah it's like if you could just give us like maybe one or two environments that we could also like design easy",
    "start": "1866880",
    "end": "1872880"
  },
  {
    "text": "ones because those are very stable slash old",
    "start": "1872880",
    "end": "1879519"
  },
  {
    "text": "yes we can do 3.6 for the mp environments um and we can probably do um",
    "start": "1879519",
    "end": "1886880"
  },
  {
    "text": "python 3.6 in gym for like classic control environments only",
    "start": "1886880",
    "end": "1892640"
  },
  {
    "text": "yeah um or no toy text only i think it will be yeah toy texts would",
    "start": "1892640",
    "end": "1901278"
  },
  {
    "text": "do toy text and classic control in gym and then new mp for patterns though yeah yeah but like we could we could",
    "start": "1902159",
    "end": "1908080"
  },
  {
    "text": "take like i don't know like some old old environment uh that we've",
    "start": "1908080",
    "end": "1913519"
  },
  {
    "text": "designed and then we could also just wrap it in the python 3.6 api and we could yeah",
    "start": "1913519",
    "end": "1919519"
  },
  {
    "text": "okay so provided that we can go and turn on i'm definitely not gonna",
    "start": "1919519",
    "end": "1924720"
  },
  {
    "text": "commit to it just right here and now just because like this is a conversation that we need to have with sven in june",
    "start": "1924720",
    "end": "1930159"
  },
  {
    "text": "but like they would definitely be interested to hear this we've definitely not i i don't think that you like it the",
    "start": "1930159",
    "end": "1935840"
  },
  {
    "text": "four of us have had this conversation before yeah so yeah definitely the whole team needs to",
    "start": "1935840",
    "end": "1941279"
  },
  {
    "text": "discuss and agree yeah yeah we need to yeah we need to talk about this one but like let's let's actually like",
    "start": "1941279",
    "end": "1947440"
  },
  {
    "text": "uh i'll i'll see june like in in an hour okay i'll see you in like an",
    "start": "1947440",
    "end": "1952880"
  },
  {
    "text": "hour and i'll talk to him and see what he says like yeah let's just like i",
    "start": "1952880",
    "end": "1958880"
  },
  {
    "text": "don't want to like i don't i don't want to get anybody's hopes up here even though like i'm very much a fan of this idea um",
    "start": "1958880",
    "end": "1964799"
  },
  {
    "text": "it would just it would be easier in some ways but i think like the the trade-offs do have to be considered the inherent",
    "start": "1964799",
    "end": "1970480"
  },
  {
    "text": "like so like another issue that i've been running to recently like with maintaining jimin jim not petting zoo code but gym",
    "start": "1970480",
    "end": "1977519"
  },
  {
    "text": "code is that um the most recent update somehow broke all of our",
    "start": "1977519",
    "end": "1982799"
  },
  {
    "text": "well not not all of it but like it broke a significant amount of cloud people",
    "start": "1982799",
    "end": "1988080"
  },
  {
    "text": "functionality uh which was challenging to get but so sorry the plan for jim there's",
    "start": "1988080",
    "end": "1994399"
  },
  {
    "text": "robot for this is that we're sort of trying to converge on sort of like a stable 1.0 package",
    "start": "1994399",
    "end": "2000159"
  },
  {
    "text": "with a fixed api and fixed set of wrappers instead of his rappers and gym are absolutely dumpster fire",
    "start": "2000159",
    "end": "2006000"
  },
  {
    "text": "yeah and as well as environment overhauls and in the update that we're about to release",
    "start": "2006000",
    "end": "2012320"
  },
  {
    "text": "um there's gonna be more breaking changes and then pretty soon we're going to get",
    "start": "2012320",
    "end": "2017519"
  },
  {
    "text": "to the 0.5 release and at that point um",
    "start": "2017519",
    "end": "2023360"
  },
  {
    "text": "the base api should be standard and the vast majority of the of the",
    "start": "2023360",
    "end": "2028960"
  },
  {
    "text": "upgrades and fixes to the environments and just like random stuff that has to be removed to standard um the new final",
    "start": "2028960",
    "end": "2034559"
  },
  {
    "text": "set of wrappers may or may not be done by 0.5 we'll have to find out and then we can't but for the most part",
    "start": "2034559",
    "end": "2040880"
  },
  {
    "text": "most of it can change will be done by this and there's a robot for the specific things that we're doing and then between 0.5 and 1.0",
    "start": "2040880",
    "end": "2048158"
  },
  {
    "text": "we're going to go and make um an overhaul",
    "start": "2048159",
    "end": "2053839"
  },
  {
    "text": "uh the vector environment api and make some other more minor things and so",
    "start": "2053839",
    "end": "2059118"
  },
  {
    "text": "essentially after 0.5 outside of the vector api the number of breaking things should be",
    "start": "2059119",
    "end": "2065679"
  },
  {
    "text": "fairly light and we're trying to get this to like okay is there is there a place where you",
    "start": "2065679",
    "end": "2071919"
  },
  {
    "text": "could like potentially write down some of this or like if it's written like maybe in a github issue somewhere",
    "start": "2071919",
    "end": "2078800"
  },
  {
    "text": "yeah like that would yeah that would be really yeah we need yeah i don't want to misquote you in any way like when we",
    "start": "2078800",
    "end": "2084878"
  },
  {
    "text": "when i go to talk about this what's that you um and as far as headings you're breaking changes for just for your",
    "start": "2084879",
    "end": "2090800"
  },
  {
    "text": "knowledge um we aren't really doing anything like",
    "start": "2090800",
    "end": "2096158"
  },
  {
    "text": "this fairly stable all we're doing on the petting zoo in is updating things to",
    "start": "2096159",
    "end": "2102560"
  },
  {
    "text": "um sort of match what's been done in in gym",
    "start": "2102560",
    "end": "2109280"
  },
  {
    "text": "after the fact you know so like you know they've actually had to make for gym we've gone and are in the process of",
    "start": "2109280",
    "end": "2114320"
  },
  {
    "text": "going you know making the you know company wants a petting zoo um at some point after all the wrappers",
    "start": "2114320",
    "end": "2120720"
  },
  {
    "text": "in gym already done we're going to do them for petting zoo to match the style of their they'll be in gym stuff like",
    "start": "2120720",
    "end": "2126480"
  },
  {
    "text": "this otherwise petting zoo are making changes too",
    "start": "2126480",
    "end": "2131160"
  },
  {
    "text": "part of the problem with all the changes to jim is i don't know if you're familiar with the code or a lot of internal logic it is it is an absolute",
    "start": "2133200",
    "end": "2139599"
  },
  {
    "text": "dumpster fire um it had a bunch of",
    "start": "2139599",
    "end": "2145200"
  },
  {
    "text": "pieces of code that people depended on that like shouldn't have been there and i mean you know a lot of those okay",
    "start": "2145200",
    "end": "2150800"
  },
  {
    "text": "sure yeah i mean like the good news is this is being fixed but like you know it has to get to the one point over at least before things stop changing point",
    "start": "2150800",
    "end": "2157280"
  },
  {
    "text": "five release is the one where things will get yeah because it gets even closer well you're doing the vector change is going",
    "start": "2157280",
    "end": "2163040"
  },
  {
    "text": "to take a really long time which is why we're gonna have a 0.5 release which is like a you know soft stable release",
    "start": "2163040",
    "end": "2170720"
  },
  {
    "text": "aside",
    "start": "2170720",
    "end": "2172960"
  },
  {
    "text": "yeah more than five at least and it's just like people have just dropped off because it's it's just too",
    "start": "2179760",
    "end": "2186000"
  },
  {
    "text": "much stuff to debug it does not make sense yeah yeah which is it's sad because like",
    "start": "2186000",
    "end": "2191359"
  },
  {
    "text": "the actual when you get everything working in relib i mean there's nothing close like you guys have amazing tech there that trajectory api that you have",
    "start": "2191359",
    "end": "2198640"
  },
  {
    "text": "is so incredibly useful for some of this stuff i mean i was trying recently to replicate like some",
    "start": "2198640",
    "end": "2204240"
  },
  {
    "text": "of the stuff you guys have for um variable agent processing and it's really hard so if if this thing if this",
    "start": "2204240",
    "end": "2210320"
  },
  {
    "text": "were supported by like you know core packages like jim and petting zoo that people are familiar with and that can be",
    "start": "2210320",
    "end": "2216000"
  },
  {
    "text": "tested independently and such right like i think that this would just ultimately",
    "start": "2216000",
    "end": "2221359"
  },
  {
    "text": "be much better at least for supporting academic stuff with our aleb there's an additional barrier and it's",
    "start": "2221359",
    "end": "2227599"
  },
  {
    "text": "that like so you know there's 80 different third-party environments of",
    "start": "2227599",
    "end": "2233040"
  },
  {
    "text": "our petting zoo right now or something stupid right and like every single third-party learning library pretty much sports",
    "start": "2233040",
    "end": "2239280"
  },
  {
    "text": "petting zoo and so what happens is that you know",
    "start": "2239280",
    "end": "2244560"
  },
  {
    "text": "okay so so i am a academic or someone in whatever i want to do a thing with something that exists right",
    "start": "2244560",
    "end": "2251760"
  },
  {
    "text": "and it's a poor trimmer petting zoo apparently i'm using jimin petting zoo now because it's like http it's a",
    "start": "2251760",
    "end": "2257520"
  },
  {
    "text": "standard interface yeah how about industry is have you",
    "start": "2257520",
    "end": "2264400"
  },
  {
    "text": "so yeah that's that's that's what i will say is like with within like uh",
    "start": "2264400",
    "end": "2271280"
  },
  {
    "text": "we have like a duty to our industry users who like have like these really",
    "start": "2271280",
    "end": "2276560"
  },
  {
    "text": "crazy and complex use cases so like as as much as yeah joseph jordan like as much as i agree with you guys it's like",
    "start": "2276560",
    "end": "2283920"
  },
  {
    "text": "we still have to balance the two yeah so like i i okay i think um",
    "start": "2283920",
    "end": "2289839"
  },
  {
    "text": "i do still want to try to answer simon's question i'm assuming you gotta get going but um",
    "start": "2289839",
    "end": "2295839"
  },
  {
    "text": "let's let's do one thing i'll i'll reach out to you guys like as soon as possible like uh either inside like the",
    "start": "2295839",
    "end": "2301520"
  },
  {
    "text": "contributors group or um okay uh",
    "start": "2301520",
    "end": "2306480"
  },
  {
    "text": "yeah i think for us the petting zoo thing you know if you can give industry examples of who's",
    "start": "2307359",
    "end": "2312720"
  },
  {
    "text": "using it and would be interested in it from from that side too that that kind of helps",
    "start": "2312720",
    "end": "2318400"
  },
  {
    "text": "as well yeah industry wants here's the here's the use case of that um it's it's sort of a flow argument",
    "start": "2318400",
    "end": "2324800"
  },
  {
    "text": "it's that academics we're implementing all these fancy algorithms right now right we're implementing the latest",
    "start": "2324800",
    "end": "2330400"
  },
  {
    "text": "state of the art people are not implementing the latest state of the art on rl because it is hard and because it",
    "start": "2330400",
    "end": "2335839"
  },
  {
    "text": "does not work with standard tools that the rest of the the rest of academia uses if it were easier to implement",
    "start": "2335839",
    "end": "2343760"
  },
  {
    "text": "things in rlib you would have access to more high quality state-of-the-art like cutting edge you just published in the",
    "start": "2343760",
    "end": "2350160"
  },
  {
    "text": "last couple of months implementations for people in industry to use yeah i mean joseph again like this is the",
    "start": "2350160",
    "end": "2356160"
  },
  {
    "text": "direction that we have been moving in for like the past three four months now yeah uh",
    "start": "2356160",
    "end": "2361520"
  },
  {
    "text": "andrew supported me on the process yeah yeah i'm just gonna add more concrete oh but",
    "start": "2361520",
    "end": "2367119"
  },
  {
    "text": "sure yeah go ahead to speak of concrete industry use cases",
    "start": "2367119",
    "end": "2372720"
  },
  {
    "text": "um i guess the industry's case comes down to i want to you know do x thing",
    "start": "2372720",
    "end": "2379359"
  },
  {
    "text": "and test it on center environment here like the smack environments let's say those are in",
    "start": "2379359",
    "end": "2384480"
  },
  {
    "text": "certain multi-agent context is very standard or i wanted to test them on mp environments they only maintain the pe",
    "start": "2384480",
    "end": "2389839"
  },
  {
    "text": "environments have to have the paintings api those very commonly used or and or you know um there's this with this",
    "start": "2389839",
    "end": "2396960"
  },
  {
    "text": "really cool um environment that does like um a smart traffic light management with the industry simulator or that does um",
    "start": "2396960",
    "end": "2404880"
  },
  {
    "text": "yeah uh power grid management with this simulator and all these petting zoo so well i want to test it on",
    "start": "2404880",
    "end": "2411599"
  },
  {
    "text": "something that exists first you know where i want to test it on the universities because that's super widely",
    "start": "2411599",
    "end": "2417359"
  },
  {
    "text": "used so the industry argument is you know well if you want to use the thing that",
    "start": "2417359",
    "end": "2422560"
  },
  {
    "text": "like you know already exists pretty much all of them",
    "start": "2422560",
    "end": "2428079"
  },
  {
    "text": "depending on the standard yeah like like like the smart traffic light",
    "start": "2428079",
    "end": "2434319"
  },
  {
    "text": "simulator that the smart traffic light companies use has penalty bindings",
    "start": "2434319",
    "end": "2440640"
  },
  {
    "text": "yeah no no i i like again fully in agreement with you um i guess like okay like to push back on",
    "start": "2443440",
    "end": "2450160"
  },
  {
    "text": "you for just a second like is there a reason like why the petting zoo rapper right now would",
    "start": "2450160",
    "end": "2455359"
  },
  {
    "text": "not work for them it is suitable for them oh it is",
    "start": "2455359",
    "end": "2460560"
  },
  {
    "text": "suitable for them but i guess like in in the context of like what joseph does which is like the",
    "start": "2460560",
    "end": "2465599"
  },
  {
    "text": "hard hitting limits of like what you would need at a multi-agent rl like it does not work for him out of the box and",
    "start": "2465599",
    "end": "2471040"
  },
  {
    "text": "like joseph i i i it does itself but yeah the api",
    "start": "2471040",
    "end": "2476800"
  },
  {
    "text": "itself does but like everything else that's around it doesn't",
    "start": "2476800",
    "end": "2480960"
  },
  {
    "text": "yet but we actually brought ron on as an intern i don't know if you know this um he sits next to me every day he's very",
    "start": "2486079",
    "end": "2491920"
  },
  {
    "text": "fun to work with and um he's going to spend a considerable amount of time on our side uh",
    "start": "2491920",
    "end": "2497440"
  },
  {
    "text": "helping you with adding like whatever uh testing infrastructure that you needed right yeah yeah like that's that's what he'll",
    "start": "2497440",
    "end": "2503040"
  },
  {
    "text": "be working on that'd be awesome actually so yeah i'm super happy to hear that so i yeah that's great now avnish i'd like",
    "start": "2503040",
    "end": "2510160"
  },
  {
    "text": "to just one thing with neural mmo so right now neural mmo is this crazy out there thing that start doing tons of",
    "start": "2510160",
    "end": "2515280"
  },
  {
    "text": "stuff right but fundamentally what i'm trying to do is make it easy to do rl on complicated",
    "start": "2515280",
    "end": "2521839"
  },
  {
    "text": "environments that don't fit into like the typical atari model where you have a flat observation",
    "start": "2521839",
    "end": "2527839"
  },
  {
    "text": "and like an mdp right this is the real world use case this is the application that industry cares about like it's just",
    "start": "2527839",
    "end": "2534240"
  },
  {
    "text": "not standard and we do not have the tools to support it which is why nobody does in the industry the project that i'm doing here it is to make that easy",
    "start": "2534240",
    "end": "2540800"
  },
  {
    "text": "and standard so yeah that's that is sort of the use case of like oh well you know only these",
    "start": "2540800",
    "end": "2546480"
  },
  {
    "text": "really out there things right now really need everything well they're really out there things it's the point of it is to",
    "start": "2546480",
    "end": "2551760"
  },
  {
    "text": "make it possible to actually run rl on environments that you would see in the real world that do not have",
    "start": "2551760",
    "end": "2557920"
  },
  {
    "text": "the well for all intensive purposes that are not atari no no i i totally get that yeah most of",
    "start": "2557920",
    "end": "2564800"
  },
  {
    "text": "our customers don't do that don't have atari right yeah i mean most most of our customers like",
    "start": "2564800",
    "end": "2570240"
  },
  {
    "text": "that's far though right",
    "start": "2570240",
    "end": "2573040"
  },
  {
    "text": "so if they're so if they're in the video game industry like uni ml agent has any opinions of bindings",
    "start": "2576400",
    "end": "2582000"
  },
  {
    "text": "yeah but i mean i guess like to maybe shed like some perspective here uh most people don't use unity mla units",
    "start": "2582000",
    "end": "2589520"
  },
  {
    "text": "like they have",
    "start": "2589520",
    "end": "2592319"
  },
  {
    "text": "custom game engines and then they need a way to interface with those game engines so",
    "start": "2597599",
    "end": "2602720"
  },
  {
    "text": "it's actually like a relatively undecided space in that sense like people are just trying to get into it uh",
    "start": "2602720",
    "end": "2609760"
  },
  {
    "text": "yeah um so anyway we've growled it for long enough i i don't mean no no no no no",
    "start": "2610160",
    "end": "2615200"
  },
  {
    "text": "yeah i i i appreciate you guys like coming here and like us like getting to have this conversation yeah let me just",
    "start": "2615200",
    "end": "2620880"
  },
  {
    "text": "mention one thing that's your question you asked isn't the petting zoo rapper adequate",
    "start": "2620880",
    "end": "2626079"
  },
  {
    "text": "yeah for for like the majority of users like i i like that that is like the one yeah so so so the petting zoo wrapper if",
    "start": "2626079",
    "end": "2633040"
  },
  {
    "text": "you want to you should like take parameter share ppo just out of the box and plug it into um",
    "start": "2633040",
    "end": "2640960"
  },
  {
    "text": "a painting to environment and it's adequate however if you want to like modify an algorithm or like you know do",
    "start": "2640960",
    "end": "2646480"
  },
  {
    "text": "more complex learning things which i'm going to go on a limb and say a lot of professors probably are doing",
    "start": "2646480",
    "end": "2652720"
  },
  {
    "text": "then um then switching to the pendings api instead of the internal one becomes much",
    "start": "2653280",
    "end": "2659040"
  },
  {
    "text": "easier yeah okay i i i yeah i mean i definitely",
    "start": "2659040",
    "end": "2666319"
  },
  {
    "text": "i definitely see like the the case for that argument it's like if people start using petting zoo environments and all of a",
    "start": "2666319",
    "end": "2672319"
  },
  {
    "text": "sudden those petting zoo environments like can't interface properly with our algorithms then that would be definitely difficult for",
    "start": "2672319",
    "end": "2677839"
  },
  {
    "text": "us yeah yeah okay so so so yeah here's here's what here's what you could do for me by the",
    "start": "2677839",
    "end": "2684240"
  },
  {
    "text": "way all right yeah so like i think i think like one thing that's made it like made the discussion like not fruitful for us on like the r11 is",
    "start": "2684240",
    "end": "2691040"
  },
  {
    "text": "just that like we i know you did tell us like in a meeting back in like october november hey we're",
    "start": "2691040",
    "end": "2696240"
  },
  {
    "text": "gonna make like certain changes and you and i even had a conversation about like changing step type and done type right",
    "start": "2696240",
    "end": "2702000"
  },
  {
    "text": "uh but like to have the written list somewhere and like the rough dates by which the",
    "start": "2702000",
    "end": "2708640"
  },
  {
    "text": "changes would land that tells us a lot about like",
    "start": "2708640",
    "end": "2714079"
  },
  {
    "text": "how we can do like our own developer iteration around what you guys are doing so uh what i don't know i'm not sure if",
    "start": "2714079",
    "end": "2720720"
  },
  {
    "text": "you're a part of like our live contributors group like on slack i know joseph is yeah i love you but i",
    "start": "2720720",
    "end": "2726079"
  },
  {
    "text": "know i know josephus and um uh joseph like if either like you you or joseph",
    "start": "2726079",
    "end": "2732560"
  },
  {
    "text": "could just like come up with this list like just roughly speaking on like the dates like we",
    "start": "2732560",
    "end": "2737599"
  },
  {
    "text": "actually have a meeting about like strategy discussion like internally at 10 30 so like if you guys like have",
    "start": "2737599",
    "end": "2744560"
  },
  {
    "text": "this list anywhere like if it would just like any bullet points it doesn't have to be like super polished so i the list",
    "start": "2744560",
    "end": "2749920"
  },
  {
    "text": "exists it needs to be cleaned up slightly i'll go do it now and send it to you yeah but like if if you're comfortable with just sharing like this",
    "start": "2749920",
    "end": "2755920"
  },
  {
    "text": "rough list like that in itself like you do it's like very small amount of cleanup and then i'll share okay yeah",
    "start": "2755920",
    "end": "2761680"
  },
  {
    "text": "all right sounds good so like yeah if we could just like have access this list like we can if you can get us out get it",
    "start": "2761680",
    "end": "2767359"
  },
  {
    "text": "out to us by like 10 o'clock we can have the discussion like today and then if not it's fine it's 9 10 at your time yeah it's not it",
    "start": "2767359",
    "end": "2774480"
  },
  {
    "text": "yeah it's it's 10 30 is like but um i'll give it to you in like 10 minutes oh okay great all right yeah so",
    "start": "2774480",
    "end": "2781359"
  },
  {
    "text": "yeah we were actually going to have this discussion today anyways because we're having some",
    "start": "2781359",
    "end": "2788480"
  },
  {
    "text": "issues online to sit in on this we can i don't have anything in half an hour if that's helpful",
    "start": "2788480",
    "end": "2793760"
  },
  {
    "text": "okay so i think um i think maybe we'll we'll talk about doing that next week but like just for",
    "start": "2793760",
    "end": "2799200"
  },
  {
    "text": "this week i think it would be a little bit too early to talk to sven about that yeah",
    "start": "2799200",
    "end": "2805440"
  },
  {
    "text": "also this is like this is a larger meeting with some of the squeeze in our company yeah",
    "start": "2805440",
    "end": "2810480"
  },
  {
    "text": "uh i mean but like i'll be real with you guys like the shed light like uh like",
    "start": "2810480",
    "end": "2816400"
  },
  {
    "text": "we're we're like we're at a point where we could go two ways we could either like double down and like really integrate",
    "start": "2816400",
    "end": "2822800"
  },
  {
    "text": "with the gym and petting zoo apis or we could uh go in the direction of",
    "start": "2822800",
    "end": "2831119"
  },
  {
    "text": "like really sticking to our own apis and then having rappers like so that people can interface uh like through their own",
    "start": "2831119",
    "end": "2837599"
  },
  {
    "text": "environment with our own apis we do have like a different set of challenges than you guys i do understand that like um",
    "start": "2837599",
    "end": "2843920"
  },
  {
    "text": "you guys like you know are making like great software but uh like we have to think about like",
    "start": "2843920",
    "end": "2848960"
  },
  {
    "text": "actually the whole end to end life cycle like in our life cycle you know so there actually are like some other issues that we do run into like",
    "start": "2848960",
    "end": "2855760"
  },
  {
    "text": "within terms of like how it is that we would actually serve like say a policy that was built on top of i don't know",
    "start": "2855760",
    "end": "2861119"
  },
  {
    "text": "gym spaces and you know things like that yeah so like some of these things are gonna play into factor but like the one",
    "start": "2861119",
    "end": "2867680"
  },
  {
    "text": "thing that i can say though is that like i will very sincerely make my best attempt to like keep you guys in the loop so that",
    "start": "2867680",
    "end": "2873760"
  },
  {
    "text": "you guys could make your own decisions based off of what we're doing you know like if there's anything that",
    "start": "2873760",
    "end": "2879520"
  },
  {
    "text": "you want to change we definitely won't have any big ass of you you know i think that would be like very unreasonable",
    "start": "2879520",
    "end": "2884640"
  },
  {
    "text": "considering that you guys are academics and you guys still do need to graduate with your phds you know here's written",
    "start": "2884640",
    "end": "2890319"
  },
  {
    "text": "from you we can probably add 3.6 support at least but we can probably rehab partial 3.6",
    "start": "2890319",
    "end": "2896480"
  },
  {
    "text": "support okay well yeah i think i think like uh i don't want to make it about that",
    "start": "2896480",
    "end": "2902160"
  },
  {
    "text": "specifically that's just like one issue that i've dealt with like but we can very honestly give you like a list of",
    "start": "2902160",
    "end": "2908960"
  },
  {
    "text": "things that we would have to deal with you know and like yeah so",
    "start": "2908960",
    "end": "2914400"
  },
  {
    "text": "i mean like if we if we think that like we can do the migration and like be successful then like",
    "start": "2914400",
    "end": "2920000"
  },
  {
    "text": "i don't see any reason why it can't happen yeah if you can get me that list that'd be great and then like",
    "start": "2920000",
    "end": "2925040"
  },
  {
    "text": "uh if you have like something roughly similar for petting zoo that would also be great yeah and then heading dude it",
    "start": "2925040",
    "end": "2930240"
  },
  {
    "text": "just whatever happened to jim two months later okay all right awesome all right cool so",
    "start": "2930240",
    "end": "2935839"
  },
  {
    "text": "i just add you know since we are open source um feature requests to get issue github issues would be really helpful to",
    "start": "2935839",
    "end": "2942559"
  },
  {
    "text": "document yeah yeah so we had a github issue for python for the update to do this version",
    "start": "2942559",
    "end": "2948079"
  },
  {
    "text": "of jim yeah that was closed i believe there's a pr created for it that's been um",
    "start": "2948079",
    "end": "2955000"
  },
  {
    "text": "update in a few weeks so i'm going to fix and see the list oh awesome all right cool sounds good yeah okay uh",
    "start": "2966240",
    "end": "2973280"
  },
  {
    "text": "okay i know we're over time but like simon if you're still here i do want to answer your question uh but i'm gonna",
    "start": "2973280",
    "end": "2978640"
  },
  {
    "start": "2974000",
    "end": "3066000"
  },
  {
    "text": "rush through it if that's okay with you thank you that's fully okay",
    "start": "2978640",
    "end": "2984640"
  },
  {
    "text": "okay so simon's question is about how to implement ddpo with",
    "start": "2984640",
    "end": "2992160"
  },
  {
    "text": "tensorflow right okay so",
    "start": "2992160",
    "end": "2997760"
  },
  {
    "text": "like the way that we do it right now i wouldn't recommend trying to do that also for tensorflow but",
    "start": "2997760",
    "end": "3004319"
  },
  {
    "text": "there is a way to do it using ray train actually so ray train is like our our distributed deep learning library uh",
    "start": "3004319",
    "end": "3012559"
  },
  {
    "text": "and it just like provides these nice and easy to use wrappers around like tensorflow distributed and torch gdp",
    "start": "3012559",
    "end": "3019359"
  },
  {
    "text": "and um yeah so i've actually like before before you had submitted your question i had",
    "start": "3019359",
    "end": "3024800"
  },
  {
    "text": "actually given your question quite a bit of thought just because like i we've been trying to migrate essentially all",
    "start": "3024800",
    "end": "3030960"
  },
  {
    "text": "of our training back in to using uh retrain and like we're in the process",
    "start": "3030960",
    "end": "3036480"
  },
  {
    "text": "of doing that right now okay so ray train has a way in which you can create multiple reactors",
    "start": "3036480",
    "end": "3043440"
  },
  {
    "text": "that have say like multiple neon networks on them and you can connect all these neural",
    "start": "3043440",
    "end": "3049680"
  },
  {
    "text": "networks like via like tensorflow distributed and in the case that you do that whenever",
    "start": "3049680",
    "end": "3056559"
  },
  {
    "text": "you do like a parameter update uh you'll be like accumulating the gradients across like all of your different neural",
    "start": "3056559",
    "end": "3061839"
  },
  {
    "text": "network parameters in a nutshell like what what it would look like is like",
    "start": "3061839",
    "end": "3067680"
  },
  {
    "start": "3066000",
    "end": "3378000"
  },
  {
    "text": "you create these ray train actors and on each one of the ray train actors you would create",
    "start": "3067680",
    "end": "3075520"
  },
  {
    "text": "a ppo worker on each one of your ray train actors",
    "start": "3075520",
    "end": "3080880"
  },
  {
    "text": "which has the ability to sample and update from like a set of samples and then",
    "start": "3080880",
    "end": "3087680"
  },
  {
    "text": "you would link these ppo workers like each one of them has like an underlying tensorflow model you could link it by",
    "start": "3087680",
    "end": "3093119"
  },
  {
    "text": "using like this with tf.distributed scope strategy",
    "start": "3093119",
    "end": "3098559"
  },
  {
    "text": "with context scope object that they have and then",
    "start": "3098720",
    "end": "3103599"
  },
  {
    "text": "i mean the only difference between like regular ppo and ddpo at that point is you collect samples and then like you",
    "start": "3104160",
    "end": "3110800"
  },
  {
    "text": "have some like coefficient that basically checks to see like okay like for every one of my distributed workers",
    "start": "3110800",
    "end": "3116319"
  },
  {
    "text": "uh i'll wait until like 10 of them are done sampling and then i'll like just do a",
    "start": "3116319",
    "end": "3122160"
  },
  {
    "text": "parameter update with whatever i have so you like implement that and then when you go to do the training update it",
    "start": "3122160",
    "end": "3128640"
  },
  {
    "text": "looks the exact same on each one of the workers as it would outside of like using raytrain",
    "start": "3128640",
    "end": "3135760"
  },
  {
    "text": "like you would just like you would call learn on batch with your with your batch like from that's",
    "start": "3135760",
    "end": "3141200"
  },
  {
    "text": "collected by the same worker and then that in theory should do the entire update",
    "start": "3141200",
    "end": "3148480"
  },
  {
    "text": "so yes it is possible uh is there a reason why you want to implement gdpo on your own though simon",
    "start": "3149839",
    "end": "3156480"
  },
  {
    "text": "i just look curious so actually i want to",
    "start": "3156480",
    "end": "3163680"
  },
  {
    "text": "use that for my uh exploration algorithm yeah okay",
    "start": "3163680",
    "end": "3170400"
  },
  {
    "text": "and sven suggested me to take a look at the ddb oh",
    "start": "3170400",
    "end": "3175760"
  },
  {
    "text": "um and that's why i why i got them okay and then is your exploration",
    "start": "3175760",
    "end": "3181440"
  },
  {
    "text": "algorithm in tf um i have both so torch and tensorflow",
    "start": "3181440",
    "end": "3188559"
  },
  {
    "text": "and i would like to parallelize it with also both torch and tensorflow and i",
    "start": "3188559",
    "end": "3194480"
  },
  {
    "text": "need the same um form like used in ddppo",
    "start": "3194480",
    "end": "3200160"
  },
  {
    "text": "because i have to like update the model after each episode",
    "start": "3200160",
    "end": "3206799"
  },
  {
    "text": "okay i see yeah so have you tried doing it for tours",
    "start": "3207680",
    "end": "3214400"
  },
  {
    "text": "right now uh no no not yet i was more into ddpo to",
    "start": "3214400",
    "end": "3220480"
  },
  {
    "text": "see how how it could be done with uh tensorflow and say i've not yet tried out with",
    "start": "3220480",
    "end": "3228319"
  },
  {
    "text": "torch which should be which should be easier okay so",
    "start": "3228319",
    "end": "3235359"
  },
  {
    "text": "but is it a requirement for you i guess for it to work in tensorflow for the time being is that a requirement",
    "start": "3235520",
    "end": "3243200"
  },
  {
    "text": "um [Music] i would say it's not a requirement it's",
    "start": "3243359",
    "end": "3249760"
  },
  {
    "text": "something i would like to see um because i'm like i'm more used to",
    "start": "3249760",
    "end": "3255200"
  },
  {
    "text": "tensorflow than torch all right i think what i'm going to do is i'm going to inspect a little bit",
    "start": "3255200",
    "end": "3261119"
  },
  {
    "text": "more like the multiple ways that you can do this but i'd say for now like just because",
    "start": "3261119",
    "end": "3267680"
  },
  {
    "text": "like your idea at its core is like i mean i guess you already implemented novelties so it",
    "start": "3267680",
    "end": "3273680"
  },
  {
    "text": "shouldn't be too bad to go from like you know you've implemented novelty to",
    "start": "3273680",
    "end": "3279040"
  },
  {
    "text": "now you have to combine that with ddbo so like",
    "start": "3279040",
    "end": "3286400"
  },
  {
    "text": "i mean like from from engineer to engineer like do the low risk thing here just test that on torch first you know",
    "start": "3287520",
    "end": "3293359"
  },
  {
    "text": "and make sure that's the direction you want to go in just because like uh yeah you'd be you'd be investing a",
    "start": "3293359",
    "end": "3298400"
  },
  {
    "text": "lot of time like trying to get that to work yeah okay um that's at",
    "start": "3298400",
    "end": "3304839"
  },
  {
    "text": "least a point with which i can work so i go first for torch",
    "start": "3304839",
    "end": "3310079"
  },
  {
    "text": "that i know that the other one is really like complicated i feel like you have your own",
    "start": "3310079",
    "end": "3316559"
  },
  {
    "text": "you have your own priorities you know like with respect to your own work so i i i",
    "start": "3316559",
    "end": "3321920"
  },
  {
    "text": "yeah i caution you against doing this okay but um it's a clear statement so uh",
    "start": "3321920",
    "end": "3329359"
  },
  {
    "text": "thanks for for answering my question i'm going to link to you like just like",
    "start": "3329359",
    "end": "3335280"
  },
  {
    "text": "the i don't link to you the pr that i did for",
    "start": "3335280",
    "end": "3340319"
  },
  {
    "text": "distributed torch like uh policy gradients algorithm so that you can take a look at it i'm",
    "start": "3340319",
    "end": "3345599"
  },
  {
    "text": "not sure if it's going to be really helpful to you in this case but uh yes please",
    "start": "3345599",
    "end": "3351359"
  },
  {
    "text": "yeah give this to you i think one thing that is nice though is",
    "start": "3351359",
    "end": "3357440"
  },
  {
    "text": "just like it just is",
    "start": "3357440",
    "end": "3362720"
  },
  {
    "text": "very simple compared to what was there before this",
    "start": "3362720",
    "end": "3367680"
  },
  {
    "text": "okay does anybody else have like any higher level questions christy is there anything you want to say too",
    "start": "3368799",
    "end": "3374000"
  },
  {
    "text": "no um thank you abnesh is a really big office hour uh yeah i have a really really quick",
    "start": "3374000",
    "end": "3380640"
  },
  {
    "start": "3378000",
    "end": "3721000"
  },
  {
    "text": "question yeah sure that's good yeah so um currently as you knew before i was just",
    "start": "3380640",
    "end": "3387520"
  },
  {
    "text": "working with uh ppo but i'm working on a multi-agent algorithm that just like",
    "start": "3387520",
    "end": "3393599"
  },
  {
    "text": "it's very very hard to train on like i've been trying to get good policies on it for like half a year now and it's",
    "start": "3393599",
    "end": "3400160"
  },
  {
    "text": "not working out i'll phrase it that way and i've tried uh some other algorithms",
    "start": "3400160",
    "end": "3407359"
  },
  {
    "text": "and did some basic hyper parameter tuning not working out either uh what algorithms would you recommend",
    "start": "3407359",
    "end": "3414559"
  },
  {
    "text": "uh would you rather recommend looking at okay can you can you talk about like the states basically your problem first and like",
    "start": "3414559",
    "end": "3420240"
  },
  {
    "text": "what it is you're trying to solve uh so it's called the ford attack environment there's a variable number of attackers",
    "start": "3420240",
    "end": "3427520"
  },
  {
    "text": "and guards um the it's a discrete and it's",
    "start": "3427520",
    "end": "3434960"
  },
  {
    "text": "it's like a discretized environment but like the environment in actuality is continuous",
    "start": "3434960",
    "end": "3440160"
  },
  {
    "text": "okay you've approximated you've approximated your actions and your observations yeah so you can this is",
    "start": "3440160",
    "end": "3446000"
  },
  {
    "text": "this is what they look like uh in another paper it's",
    "start": "3446000",
    "end": "3453599"
  },
  {
    "text": "these look like trained policies they're really not like these these actors like the guards learn to kind of just do the",
    "start": "3454720",
    "end": "3461599"
  },
  {
    "text": "same thing across each episode and the same is true for the attackers it's uh these policies are",
    "start": "3461599",
    "end": "3468640"
  },
  {
    "text": "trash so i want like actual reactive policies one of the other things as you can see these never turn like these",
    "start": "3468640",
    "end": "3475359"
  },
  {
    "text": "the action spaces essentially move in one direction shoot or turn okay what's your um",
    "start": "3475359",
    "end": "3482640"
  },
  {
    "text": "oh or turn okay uh yeah and what's your um what's your reward function looks like because i think i think that's the",
    "start": "3482640",
    "end": "3489359"
  },
  {
    "text": "i think that's a big deal here it's like so you're working on this environment and like sure these policies are like kind of bad but like",
    "start": "3489359",
    "end": "3496400"
  },
  {
    "text": "i've been doing a lot of reward shaping yeah you've got a lot of word shaping okay yeah so",
    "start": "3496400",
    "end": "3502400"
  },
  {
    "text": "at the beginning it was just whether a guard hit an attacker and whether the",
    "start": "3502400",
    "end": "3507520"
  },
  {
    "text": "attacker reached the fort or not is was the big thing uh i've added",
    "start": "3507520",
    "end": "3514000"
  },
  {
    "text": "essentially whether an attacker is facing facing the guards how far they are away",
    "start": "3514000",
    "end": "3519200"
  },
  {
    "text": "just like as proxies uh but and that has that has enabled",
    "start": "3519200",
    "end": "3524640"
  },
  {
    "text": "turning but like i'm able to get good policies for one or two agents but",
    "start": "3524640",
    "end": "3529839"
  },
  {
    "text": "beyond three i'm not able to get anything okay all right so",
    "start": "3529839",
    "end": "3537839"
  },
  {
    "text": "a couple things uh okay i used to do like rl robotics before i was doing this",
    "start": "3537839",
    "end": "3543599"
  },
  {
    "text": "and um one thing that i do know is that um",
    "start": "3543599",
    "end": "3548640"
  },
  {
    "text": "is that like if you can essentially write a controller or like a scripted policy that like",
    "start": "3548640",
    "end": "3554720"
  },
  {
    "text": "performs the sequence of like actions that is necessary in order to like you know complete this and complete this",
    "start": "3554720",
    "end": "3560720"
  },
  {
    "text": "task then like then it means that your your environment is solvable okay and like",
    "start": "3560720",
    "end": "3566079"
  },
  {
    "text": "it's just a matter of like coming up with like a nice reward space uh that's like continuous and like not too jag",
    "start": "3566079",
    "end": "3572160"
  },
  {
    "text": "and you know doesn't have like too many varying different slopes okay so that's the first thing",
    "start": "3572160",
    "end": "3577440"
  },
  {
    "text": "uh yeah the second thing is like it sounds like a problem of scale",
    "start": "3577440",
    "end": "3582720"
  },
  {
    "text": "i think like like in the sense where like you can do it with two actors but then as soon as you get to three or four",
    "start": "3582720",
    "end": "3588480"
  },
  {
    "text": "it kind of falls apart see what's difficult about this for me is like you have access to the environment so you're not",
    "start": "3588480",
    "end": "3594160"
  },
  {
    "text": "at you're not in a situation where like you have difficulty with difficulty with the number of samples",
    "start": "3594160",
    "end": "3600000"
  },
  {
    "text": "you can collect uh ppo is like extremely extremely efficient in two cases uh",
    "start": "3600000",
    "end": "3607599"
  },
  {
    "text": "in the cases like where you have like a reward function that's like a little bit of sparse or like there is like some",
    "start": "3607599",
    "end": "3612880"
  },
  {
    "text": "partially observable quantity in your environment so i don't know if there's any partially observable quantity in",
    "start": "3612880",
    "end": "3618160"
  },
  {
    "text": "your environment but i imagine that there could be i mean multi-agent is inherently partially observable right",
    "start": "3618160",
    "end": "3623920"
  },
  {
    "text": "because you don't know what the actions of the other agents are going to be but like that's semantics right if you're",
    "start": "3623920",
    "end": "3629440"
  },
  {
    "text": "not talking about that yes it's fully observable in terms of what the agent can see",
    "start": "3629440",
    "end": "3634640"
  },
  {
    "text": "well it's just it's just for that reason though yeah i guess it's just for that reason that i'd say like stick with like ppo appo ddpo like all these algorithms",
    "start": "3634640",
    "end": "3643040"
  },
  {
    "text": "should help you get to where you need to go what happens if you like uh take a",
    "start": "3643040",
    "end": "3648240"
  },
  {
    "text": "policy like for like say three four five agents and like you visualize it what happens",
    "start": "3648240",
    "end": "3654400"
  },
  {
    "text": "define visualize i mean like you can create these cool visualizations here right i'm assuming there's like a dot render you can oh yeah",
    "start": "3654400",
    "end": "3661599"
  },
  {
    "text": "the rendering they just kind of like look around and don't do anything",
    "start": "3661599",
    "end": "3666720"
  },
  {
    "text": "i can try to get an example no no that's that's fine i think i actually like as cool as it would be to",
    "start": "3668559",
    "end": "3674480"
  },
  {
    "text": "look at i'm not sure if it would help me in this case just because like i'd have to be a little bit closer to the problem to understand",
    "start": "3674480",
    "end": "3680960"
  },
  {
    "text": "yeah i guess the the point is is that the reward function does not even",
    "start": "3680960",
    "end": "3686240"
  },
  {
    "text": "slightly converge in fact it gets worse because one of the other behaviors that i notice is that",
    "start": "3686240",
    "end": "3692079"
  },
  {
    "text": "the guards just learn to not shoot at all uh",
    "start": "3692079",
    "end": "3698680"
  },
  {
    "text": "that's because i give a slight negative reward if they i give a slight negative reward if they",
    "start": "3699359",
    "end": "3705040"
  },
  {
    "text": "don't hit anything essentially and so okay as as",
    "start": "3705040",
    "end": "3710559"
  },
  {
    "text": "the issue is if you don't give them any penalty they'll just fire randomly",
    "start": "3710559",
    "end": "3715760"
  },
  {
    "text": "and no that makes sense if you give them yeah yeah",
    "start": "3715760",
    "end": "3720960"
  },
  {
    "text": "so reno's the other thing that i would recommend you is like uh in order to get ppo to work really well",
    "start": "3720960",
    "end": "3729200"
  },
  {
    "start": "3721000",
    "end": "3801000"
  },
  {
    "text": "it's like not as well a known fact but like um you do have to do like the thing that",
    "start": "3729200",
    "end": "3734960"
  },
  {
    "text": "makes ppo work in like really complex state spaces is entropy tuning",
    "start": "3734960",
    "end": "3740960"
  },
  {
    "text": "okay yeah so like if you open up your tensorboard like i'm not gonna ask you to do that right now and also i have to",
    "start": "3740960",
    "end": "3746640"
  },
  {
    "text": "get going because i have to spend in 30 minutes but um yeah sure so there's this there's a coefficient",
    "start": "3746640",
    "end": "3752559"
  },
  {
    "text": "that you can tune call your enterprise efficient okay okay yes all right maybe maybe i'll just",
    "start": "3752559",
    "end": "3757680"
  },
  {
    "text": "give like the one liner which is like yeah the one liner is like basically what we do is like for every",
    "start": "3757680",
    "end": "3763359"
  },
  {
    "text": "single like uh reward return that we evaluate like uh when we're like doing our last update we essentially like",
    "start": "3763359",
    "end": "3770799"
  },
  {
    "text": "take we add an entropy penalty so the entropy of an agent like is essentially like",
    "start": "3770799",
    "end": "3776400"
  },
  {
    "text": "controlling its likelihood to take actions that are outside like that are far outside of its",
    "start": "3776400",
    "end": "3781520"
  },
  {
    "text": "like probability distribution so you want like high entropy agents",
    "start": "3781520",
    "end": "3787119"
  },
  {
    "text": "typically in general like when you're using ppo because high entropy agents would lead to",
    "start": "3787119",
    "end": "3792400"
  },
  {
    "text": "essentially like a better explored problem so like when you tell me that like your agents like aren't learning to",
    "start": "3792400",
    "end": "3797599"
  },
  {
    "text": "do anything uh well like your reward increases in magnitude right when you",
    "start": "3797599",
    "end": "3803440"
  },
  {
    "start": "3801000",
    "end": "3957000"
  },
  {
    "text": "when you increase the number of agents right uh like the the reward range sorry reward range",
    "start": "3803440",
    "end": "3811039"
  },
  {
    "text": "right oh that was that was another question how what what reward range would you recommend keeping it in optimally for",
    "start": "3811039",
    "end": "3816640"
  },
  {
    "text": "the algorithm uh yeah okay so this is like something that just relates more on your networks but like uh",
    "start": "3816640",
    "end": "3822960"
  },
  {
    "text": "like i'd say basically per agent you could keep it between like zero and one or like zero and ten",
    "start": "3822960",
    "end": "3829119"
  },
  {
    "text": "uh zero antennas like a little nicer but like getting into the thousands is like",
    "start": "3829119",
    "end": "3835359"
  },
  {
    "text": "kind of not a good idea just because like you then you have to like deal with essentially like all these gradient regulations and the gradient",
    "start": "3835359",
    "end": "3842799"
  },
  {
    "text": "clipping and then you have to like really be careful about how you tune so this entropy coefficient directly relates to like um",
    "start": "3842799",
    "end": "3848720"
  },
  {
    "text": "your uh",
    "start": "3848720",
    "end": "3851200"
  },
  {
    "text": "it's a it's called like a entropy maybe it's not in there but it's called entropy coefficient it's definitely an",
    "start": "3856640",
    "end": "3863839"
  },
  {
    "text": "and impala you can definitely tune this",
    "start": "3863839",
    "end": "3869920"
  },
  {
    "text": "it also might not be directly in pvo it might be in one of the algorithms that ppo inherits from but if it's not in there then like and you don't find it",
    "start": "3869920",
    "end": "3876240"
  },
  {
    "text": "just like open an issue and i'll i'll i'll like very quickly pull that out",
    "start": "3876240",
    "end": "3882160"
  },
  {
    "text": "sure you wouldn't see it inside uh ppo.pi though you would see it inside of um",
    "start": "3882160",
    "end": "3888000"
  },
  {
    "text": "the ppo policy yeah okay there it is okay so",
    "start": "3888000",
    "end": "3895559"
  },
  {
    "text": "with this entropy coefficient scheduler you could try messing around this first i'm not sure like this is the same thing as like",
    "start": "3896799",
    "end": "3902400"
  },
  {
    "text": "uh passing like a an explicit entropy but in a nutshell like what this is going to do is like this this parameter over here",
    "start": "3902400",
    "end": "3909680"
  },
  {
    "text": "will control your exploration and like what you're looking for when you like go to open tensorboard on rliv is that um",
    "start": "3909680",
    "end": "3918400"
  },
  {
    "text": "this parameter if it like collapses essentially towards zero like on your tensorboard if you search of entropy if",
    "start": "3919039",
    "end": "3924880"
  },
  {
    "text": "it collapses for zero essentially what that means is like the standard the average standard deviation of any one of",
    "start": "3924880",
    "end": "3930319"
  },
  {
    "text": "your policies is extremely low and it's not likely to explore essentially outside of the mean action",
    "start": "3930319",
    "end": "3936960"
  },
  {
    "text": "taken by by the agent right that makes sense yeah so like that",
    "start": "3936960",
    "end": "3942640"
  },
  {
    "text": "is like the most important thing to control when you're doing like this on policy rl yeah so",
    "start": "3942640",
    "end": "3948799"
  },
  {
    "text": "if you're telling me that like you increase the number of agents and like you're not seeing like the reward go up it it probably means that",
    "start": "3948799",
    "end": "3955760"
  },
  {
    "text": "it goes up a bit and kind of over fits to not shooting",
    "start": "3955760",
    "end": "3961039"
  },
  {
    "start": "3957000",
    "end": "4117000"
  },
  {
    "text": "and then like trying to kind of look at some of the agents because like a lot of the reward shipping i did is making sure",
    "start": "3961039",
    "end": "3966400"
  },
  {
    "text": "that it like is kind of close to and kind of looks at at least one of the agents",
    "start": "3966400",
    "end": "3972400"
  },
  {
    "text": "uh these that that's a proxy for like being able to shoot and kill it so uh",
    "start": "3972400",
    "end": "3978799"
  },
  {
    "text": "what it does is it learns not to shoot and then just looks to like just look in the direction",
    "start": "3978799",
    "end": "3985200"
  },
  {
    "text": "of of the agents which uh it and then it just flatlines essentially with reward",
    "start": "3985200",
    "end": "3991280"
  },
  {
    "text": "because obviously that action is very suboptimal yeah but essentially what you're describing to me like",
    "start": "3991280",
    "end": "3996960"
  },
  {
    "text": "pretty much tracks with like your exploration is like not going particularly well as you increase the",
    "start": "3996960",
    "end": "4002240"
  },
  {
    "text": "number of agents yeah the max the the min reward is a lot lower than",
    "start": "4002240",
    "end": "4008160"
  },
  {
    "text": "the max reward is high because the max reward is just whenever you kill an agent you get three points and then uh",
    "start": "4008160",
    "end": "4014559"
  },
  {
    "text": "if there's no agents left everyone gets 10 points although i disabled that so okay so that's actually that's",
    "start": "4014559",
    "end": "4020319"
  },
  {
    "text": "actually also bad you should keep like you should you",
    "start": "4020319",
    "end": "4026000"
  },
  {
    "text": "should make like you should make the penalty for taking a negative action basically",
    "start": "4026000",
    "end": "4032240"
  },
  {
    "text": "the same as like how good it is to take a positive action or like even less than that and in terms",
    "start": "4032240",
    "end": "4038400"
  },
  {
    "text": "of magnitude but not necessarily direction yeah these are just like lessons that i",
    "start": "4038400",
    "end": "4043839"
  },
  {
    "text": "have learned from writing like reward functions for like these complex robotic manipulation tasks it's",
    "start": "4043839",
    "end": "4049920"
  },
  {
    "text": "like so i'd go ahead and try that out like maybe don't change your reward function first just because like there's",
    "start": "4049920",
    "end": "4054960"
  },
  {
    "text": "a lot of changes to a blade maybe just first like open up some of tensorboards and then like uh",
    "start": "4054960",
    "end": "4062240"
  },
  {
    "text": "yeah look at entropy see if like you're seeing a collapse like if you see it basically like i don't know if you can like see my hand but like basically see",
    "start": "4063119",
    "end": "4069839"
  },
  {
    "text": "it go up like this and then like essentially like just absolutely collapse to zero then",
    "start": "4069839",
    "end": "4076400"
  },
  {
    "text": "like that would be indicative that like um you're seeing entropy lapse something",
    "start": "4076400",
    "end": "4081599"
  },
  {
    "text": "that you can do also is like just take a screenshot and then post it in the rlo channel and i'll take a look at it when",
    "start": "4081599",
    "end": "4087359"
  },
  {
    "text": "i get to it you just tag me in it sure sounds good okay cool all right thanks a lot i know",
    "start": "4087359",
    "end": "4094319"
  },
  {
    "text": "this went very past but uh thanks for all the great feedback uh christy sorry if we kept you over to you by that yeah",
    "start": "4094319",
    "end": "4100719"
  },
  {
    "text": "that's okay yeah thanks fish thank you very much didn't didn't know",
    "start": "4100719",
    "end": "4105920"
  },
  {
    "text": "this was gonna go that long but yeah it is uh it was good yeah",
    "start": "4105920",
    "end": "4111440"
  },
  {
    "text": "okay thanks everybody okay bye guys all right bye",
    "start": "4111440",
    "end": "4118480"
  }
]
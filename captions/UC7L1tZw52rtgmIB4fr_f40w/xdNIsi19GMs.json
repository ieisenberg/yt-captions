[
  {
    "text": "hi everybody thanks for coming and",
    "start": "5660",
    "end": "8700"
  },
  {
    "text": "thanks a lot for staying this is a",
    "start": "8700",
    "end": "11099"
  },
  {
    "text": "gochron song and the jelly one wear",
    "start": "11099",
    "end": "13320"
  },
  {
    "text": "front Intel today we are going to",
    "start": "13320",
    "end": "15360"
  },
  {
    "text": "introduce big deal to the zero it's an",
    "start": "15360",
    "end": "17880"
  },
  {
    "text": "open source project which helps users to",
    "start": "17880",
    "end": "20340"
  },
  {
    "text": "build your AI application much easier in",
    "start": "20340",
    "end": "22920"
  },
  {
    "text": "two ways first it's faster second the",
    "start": "22920",
    "end": "27000"
  },
  {
    "text": "scalability is much easier",
    "start": "27000",
    "end": "29460"
  },
  {
    "text": "okay",
    "start": "29460",
    "end": "30599"
  },
  {
    "text": "here's what we're going to cover today",
    "start": "30599",
    "end": "32520"
  },
  {
    "text": "first we'll explain what big deal is",
    "start": "32520",
    "end": "35040"
  },
  {
    "text": "we'll explain all the major libraries",
    "start": "35040",
    "end": "37620"
  },
  {
    "text": "that in big deal how we leverage array",
    "start": "37620",
    "end": "40379"
  },
  {
    "text": "and how we make it faster and make it",
    "start": "40379",
    "end": "42360"
  },
  {
    "text": "easier at last we'll share some real",
    "start": "42360",
    "end": "45300"
  },
  {
    "text": "world use cases with our customers so if",
    "start": "45300",
    "end": "48180"
  },
  {
    "text": "you could if you have a use case it",
    "start": "48180",
    "end": "50640"
  },
  {
    "text": "could be one of our potential customers",
    "start": "50640",
    "end": "52559"
  },
  {
    "text": "and their research we're ready to help",
    "start": "52559",
    "end": "56460"
  },
  {
    "text": "um okay this is a big deal 2.0 it",
    "start": "56460",
    "end": "60300"
  },
  {
    "text": "includes three end-to-end distributed AI",
    "start": "60300",
    "end": "63120"
  },
  {
    "text": "pipelines that's Nano Orca and a DL lib",
    "start": "63120",
    "end": "66600"
  },
  {
    "text": "and three domain specific toolkits ppml",
    "start": "66600",
    "end": "70260"
  },
  {
    "text": "Cronus and fresher okay for Nano that's",
    "start": "70260",
    "end": "75299"
  },
  {
    "text": "the one we put all our CPU accelerations",
    "start": "75299",
    "end": "78000"
  },
  {
    "text": "so using Nano your training or inference",
    "start": "78000",
    "end": "81119"
  },
  {
    "text": "will be way faster than without Nano",
    "start": "81119",
    "end": "84240"
  },
  {
    "text": "Orca is the one that will help the",
    "start": "84240",
    "end": "86460"
  },
  {
    "text": "scalability so using Orca you don't have",
    "start": "86460",
    "end": "89460"
  },
  {
    "text": "to change much code you just change one",
    "start": "89460",
    "end": "91560"
  },
  {
    "text": "love code then you will get the",
    "start": "91560",
    "end": "93659"
  },
  {
    "text": "scalability much easier from local to",
    "start": "93659",
    "end": "95759"
  },
  {
    "text": "Cluster and the deal Loop is the one",
    "start": "95759",
    "end": "98700"
  },
  {
    "text": "that for spark it's organically",
    "start": "98700",
    "end": "101579"
  },
  {
    "text": "developed on spark that's not a focus of",
    "start": "101579",
    "end": "103920"
  },
  {
    "text": "today",
    "start": "103920",
    "end": "105119"
  },
  {
    "text": "then this three tour case actually it's",
    "start": "105119",
    "end": "109140"
  },
  {
    "text": "just a little special here because using",
    "start": "109140",
    "end": "111420"
  },
  {
    "text": "Nano workout with your lip you can build",
    "start": "111420",
    "end": "113579"
  },
  {
    "text": "any types of applications you want but",
    "start": "113579",
    "end": "116520"
  },
  {
    "text": "for this most popular use cases we build",
    "start": "116520",
    "end": "120240"
  },
  {
    "text": "three toolkits it's ppmo for privacy",
    "start": "120240",
    "end": "123840"
  },
  {
    "text": "preserving machine learning corners for",
    "start": "123840",
    "end": "126420"
  },
  {
    "text": "time series analysis and friction for",
    "start": "126420",
    "end": "128940"
  },
  {
    "text": "recommendation systems so jelly later",
    "start": "128940",
    "end": "132000"
  },
  {
    "text": "will explain all these specific toolkits",
    "start": "132000",
    "end": "134819"
  },
  {
    "text": "in a very detailed way and I will focus",
    "start": "134819",
    "end": "137580"
  },
  {
    "text": "on Nano and orca",
    "start": "137580",
    "end": "139620"
  },
  {
    "text": "and it okay so nalo and the orca orca",
    "start": "139620",
    "end": "144780"
  },
  {
    "text": "Mexico Orca first as I said before Orca",
    "start": "144780",
    "end": "147959"
  },
  {
    "text": "is a library that we use it to scale the",
    "start": "147959",
    "end": "150780"
  },
  {
    "text": "code from local to Cluster",
    "start": "150780",
    "end": "153599"
  },
  {
    "text": "when we built the AI applications or",
    "start": "153599",
    "end": "155879"
  },
  {
    "text": "pipelines from data ingestion or facial",
    "start": "155879",
    "end": "159000"
  },
  {
    "text": "engineering and the model training",
    "start": "159000",
    "end": "161160"
  },
  {
    "text": "evaluation through model organization",
    "start": "161160",
    "end": "163140"
  },
  {
    "text": "and inference",
    "start": "163140",
    "end": "164640"
  },
  {
    "text": "all can make it much easier first it can",
    "start": "164640",
    "end": "168900"
  },
  {
    "text": "handle different types of data formats",
    "start": "168900",
    "end": "170879"
  },
  {
    "text": "from the low like a remote storage",
    "start": "170879",
    "end": "174060"
  },
  {
    "text": "we've come to the Future engineering and",
    "start": "174060",
    "end": "176280"
  },
  {
    "text": "transformation transformation Orca can",
    "start": "176280",
    "end": "179040"
  },
  {
    "text": "handle spark data frame of course like a",
    "start": "179040",
    "end": "182280"
  },
  {
    "text": "red data set as well as like a tension",
    "start": "182280",
    "end": "184739"
  },
  {
    "text": "flow data set and so on when it comes to",
    "start": "184739",
    "end": "187620"
  },
  {
    "text": "the training evaluation and inference",
    "start": "187620",
    "end": "189900"
  },
  {
    "text": "depends on the back end of framework you",
    "start": "189900",
    "end": "192420"
  },
  {
    "text": "want to use we can handle tensorflow",
    "start": "192420",
    "end": "194580"
  },
  {
    "text": "covers Pi torch of course Ray",
    "start": "194580",
    "end": "197659"
  },
  {
    "text": "because our Nano put everything all this",
    "start": "197659",
    "end": "201360"
  },
  {
    "text": "technology together and we can support",
    "start": "201360",
    "end": "203280"
  },
  {
    "text": "so many Technologies it provides",
    "start": "203280",
    "end": "205500"
  },
  {
    "text": "simplified unified API it's much easier",
    "start": "205500",
    "end": "208920"
  },
  {
    "text": "to use",
    "start": "208920",
    "end": "211080"
  },
  {
    "text": "okay when we talk about assembly scaling",
    "start": "211080",
    "end": "213840"
  },
  {
    "text": "from laptop to distributed cluster we",
    "start": "213840",
    "end": "216060"
  },
  {
    "text": "mean this way so when we want to run",
    "start": "216060",
    "end": "218459"
  },
  {
    "text": "some applications first we install the",
    "start": "218459",
    "end": "222000"
  },
  {
    "text": "software here is big deal Orca and then",
    "start": "222000",
    "end": "224760"
  },
  {
    "text": "we pull some data and the Pro tab on the",
    "start": "224760",
    "end": "228120"
  },
  {
    "text": "laptop after that we want to",
    "start": "228120",
    "end": "230480"
  },
  {
    "text": "productionize on the digital cluster so",
    "start": "230480",
    "end": "233700"
  },
  {
    "text": "the transition from laptop to Cluster",
    "start": "233700",
    "end": "236040"
  },
  {
    "text": "could be a lot of work for many people",
    "start": "236040",
    "end": "237840"
  },
  {
    "text": "that could give you a lot of you have to",
    "start": "237840",
    "end": "241140"
  },
  {
    "text": "think about what slides you want to use",
    "start": "241140",
    "end": "242760"
  },
  {
    "text": "you want to think about like how much",
    "start": "242760",
    "end": "244500"
  },
  {
    "text": "data you handle you're assuming how many",
    "start": "244500",
    "end": "246420"
  },
  {
    "text": "cars you want to use so using big deal",
    "start": "246420",
    "end": "250080"
  },
  {
    "text": "Orca you just change it a little bit you",
    "start": "250080",
    "end": "252900"
  },
  {
    "text": "need Orca can't catch from local 2 or",
    "start": "252900",
    "end": "255659"
  },
  {
    "text": "cubes or spark Summit that's it",
    "start": "255659",
    "end": "259320"
  },
  {
    "text": "here I have a concrete example friends",
    "start": "259320",
    "end": "261299"
  },
  {
    "text": "link and you can take a look",
    "start": "261299",
    "end": "263940"
  },
  {
    "text": "um",
    "start": "263940",
    "end": "265139"
  },
  {
    "text": "another one I want to emphasize today is",
    "start": "265139",
    "end": "268740"
  },
  {
    "text": "it's still popular for engineers to do",
    "start": "268740",
    "end": "271620"
  },
  {
    "text": "the feature engineering on spark cluster",
    "start": "271620",
    "end": "273840"
  },
  {
    "text": "because most of things our data stays on",
    "start": "273840",
    "end": "276780"
  },
  {
    "text": "the spark culture which usually hdfs",
    "start": "276780",
    "end": "279780"
  },
  {
    "text": "India but we use Ray or other Frameworks",
    "start": "279780",
    "end": "282720"
  },
  {
    "text": "to train a model where to do inference",
    "start": "282720",
    "end": "285300"
  },
  {
    "text": "so big deal or car provides a pipe",
    "start": "285300",
    "end": "288360"
  },
  {
    "text": "between spark and array that's real and",
    "start": "288360",
    "end": "291660"
  },
  {
    "text": "Spark",
    "start": "291660",
    "end": "292560"
  },
  {
    "text": "so when we start the real Spark It's a",
    "start": "292560",
    "end": "295560"
  },
  {
    "text": "freshly surgery",
    "start": "295560",
    "end": "297560"
  },
  {
    "text": "context it will automatically start this",
    "start": "297560",
    "end": "301080"
  },
  {
    "text": "recontext the recontext is also our",
    "start": "301080",
    "end": "304139"
  },
  {
    "text": "entry point to run the organic reprocess",
    "start": "304139",
    "end": "307800"
  },
  {
    "text": "underneath so for each spark executor a",
    "start": "307800",
    "end": "312240"
  },
  {
    "text": "re-manager is launched to handle the",
    "start": "312240",
    "end": "315120"
  },
  {
    "text": "recontext so all the process will be",
    "start": "315120",
    "end": "318120"
  },
  {
    "text": "automatically stopped if the program",
    "start": "318120",
    "end": "320220"
  },
  {
    "text": "fails or if like the major program stops",
    "start": "320220",
    "end": "323820"
  },
  {
    "text": "so here is how we do it first we got the",
    "start": "323820",
    "end": "327180"
  },
  {
    "text": "data from a spark and builds the spark",
    "start": "327180",
    "end": "331080"
  },
  {
    "text": "data frame and we can do the process as",
    "start": "331080",
    "end": "333419"
  },
  {
    "text": "we want get all the features we want",
    "start": "333419",
    "end": "335699"
  },
  {
    "text": "after that simple you can call spark DF",
    "start": "335699",
    "end": "339000"
  },
  {
    "text": "to read data sets then you can transfer",
    "start": "339000",
    "end": "341880"
  },
  {
    "text": "this spark data frame to array data set",
    "start": "341880",
    "end": "344400"
  },
  {
    "text": "after that once you have this data let's",
    "start": "344400",
    "end": "347699"
  },
  {
    "text": "read it as it you can do all the",
    "start": "347699",
    "end": "349680"
  },
  {
    "text": "training just as usual",
    "start": "349680",
    "end": "352259"
  },
  {
    "text": "so that's a connection between spark and",
    "start": "352259",
    "end": "354720"
  },
  {
    "text": "array",
    "start": "354720",
    "end": "356880"
  },
  {
    "text": "um this is a concrete example that",
    "start": "356880",
    "end": "359520"
  },
  {
    "text": "showcase how to use Orca to build the",
    "start": "359520",
    "end": "362160"
  },
  {
    "text": "entry and distribute AI pipeline first",
    "start": "362160",
    "end": "364860"
  },
  {
    "text": "we want to initialize Orca context here",
    "start": "364860",
    "end": "367740"
  },
  {
    "text": "I use a local as example but you can",
    "start": "367740",
    "end": "369780"
  },
  {
    "text": "always use any cubes or like a spark",
    "start": "369780",
    "end": "372419"
  },
  {
    "text": "Summit or yarn here we want to make sure",
    "start": "372419",
    "end": "375060"
  },
  {
    "text": "we want to set unit rate on spark as you",
    "start": "375060",
    "end": "378060"
  },
  {
    "text": "to use three on the back end",
    "start": "378060",
    "end": "381960"
  },
  {
    "text": "after that we can read the data into",
    "start": "381960",
    "end": "384720"
  },
  {
    "text": "spark data free and process it then we",
    "start": "384720",
    "end": "387600"
  },
  {
    "text": "build the model as usual so depends on",
    "start": "387600",
    "end": "390180"
  },
  {
    "text": "like your for which model you are",
    "start": "390180",
    "end": "392580"
  },
  {
    "text": "familiar with you can use tension flow",
    "start": "392580",
    "end": "394440"
  },
  {
    "text": "or Pi torch or any other kind of stuff",
    "start": "394440",
    "end": "396419"
  },
  {
    "text": "with mainly supported through tension",
    "start": "396419",
    "end": "399000"
  },
  {
    "text": "flow and Pi torch after that then we",
    "start": "399000",
    "end": "401759"
  },
  {
    "text": "build the estimator here just from",
    "start": "401759",
    "end": "404039"
  },
  {
    "text": "carers then for other models you take it",
    "start": "404039",
    "end": "407819"
  },
  {
    "text": "to the estimator then fit will",
    "start": "407819",
    "end": "410819"
  },
  {
    "text": "automatically train this model in a",
    "start": "410819",
    "end": "412860"
  },
  {
    "text": "distributed way and on the cluster",
    "start": "412860",
    "end": "415080"
  },
  {
    "text": "except this uh courage and data frame as",
    "start": "415080",
    "end": "418440"
  },
  {
    "text": "example here at the back and we can",
    "start": "418440",
    "end": "420060"
  },
  {
    "text": "always support naked three read data",
    "start": "420060",
    "end": "422400"
  },
  {
    "text": "sets Pi torch data loader tensorflow",
    "start": "422400",
    "end": "424740"
  },
  {
    "text": "data set and so on",
    "start": "424740",
    "end": "428300"
  },
  {
    "text": "the good thing for that one is the API",
    "start": "428340",
    "end": "430919"
  },
  {
    "text": "is Unified and simple",
    "start": "430919",
    "end": "434539"
  },
  {
    "text": "we have Orca Auto ml for the hyper",
    "start": "434539",
    "end": "438479"
  },
  {
    "text": "parameter search this is like a built on",
    "start": "438479",
    "end": "442199"
  },
  {
    "text": "the top of ratio and from Ray and Spark",
    "start": "442199",
    "end": "446220"
  },
  {
    "text": "when we initialize this one you can",
    "start": "446220",
    "end": "450120"
  },
  {
    "text": "build the auto XC regressor here which",
    "start": "450120",
    "end": "453000"
  },
  {
    "text": "uses example",
    "start": "453000",
    "end": "454800"
  },
  {
    "text": "when we talk about the higher parameter",
    "start": "454800",
    "end": "456840"
  },
  {
    "text": "tuning in our implementation we include",
    "start": "456840",
    "end": "459660"
  },
  {
    "text": "both hyper parameter 24 modeling as well",
    "start": "459660",
    "end": "463080"
  },
  {
    "text": "as feature engineering so for feature",
    "start": "463080",
    "end": "465419"
  },
  {
    "text": "engineering we use this one to search a",
    "start": "465419",
    "end": "468300"
  },
  {
    "text": "subset of good features to finish the",
    "start": "468300",
    "end": "470520"
  },
  {
    "text": "model and for the model you can always",
    "start": "470520",
    "end": "473220"
  },
  {
    "text": "follow all the other like hyper",
    "start": "473220",
    "end": "475259"
  },
  {
    "text": "parameters like number of nodes per",
    "start": "475259",
    "end": "477780"
  },
  {
    "text": "layer or learning rates and so on and so",
    "start": "477780",
    "end": "480599"
  },
  {
    "text": "forth here because we use an XT boost",
    "start": "480599",
    "end": "483000"
  },
  {
    "text": "example like it's a number of estimators",
    "start": "483000",
    "end": "486180"
  },
  {
    "text": "or maximum depth or Auto you can put all",
    "start": "486180",
    "end": "489180"
  },
  {
    "text": "these hyper parameters as well as a",
    "start": "489180",
    "end": "490680"
  },
  {
    "text": "search space for the facial engineering",
    "start": "490680",
    "end": "492660"
  },
  {
    "text": "to the search space then call fit that",
    "start": "492660",
    "end": "496199"
  },
  {
    "text": "will start a bunch of Trials and the",
    "start": "496199",
    "end": "499139"
  },
  {
    "text": "distributed straps should choose a",
    "start": "499139",
    "end": "500819"
  },
  {
    "text": "cluster by ring two then after all the",
    "start": "500819",
    "end": "504180"
  },
  {
    "text": "trials finish we can get the best model",
    "start": "504180",
    "end": "506280"
  },
  {
    "text": "then we can save this model for the",
    "start": "506280",
    "end": "508620"
  },
  {
    "text": "future for inference for example or for",
    "start": "508620",
    "end": "511740"
  },
  {
    "text": "incremental learning for later we have a",
    "start": "511740",
    "end": "514740"
  },
  {
    "text": "a comparison between the young and",
    "start": "514740",
    "end": "517800"
  },
  {
    "text": "Nvidia GPU a100 using this automl orca",
    "start": "517800",
    "end": "524099"
  },
  {
    "text": "Orca or ml is 70 faster even than on GPU",
    "start": "524099",
    "end": "528660"
  },
  {
    "text": "I guess that's because we use this other",
    "start": "528660",
    "end": "531980"
  },
  {
    "text": "acceleration and uses unified API then",
    "start": "531980",
    "end": "535860"
  },
  {
    "text": "[Applause]",
    "start": "535860",
    "end": "537180"
  },
  {
    "text": "when we talk about acceleration we want",
    "start": "537180",
    "end": "540480"
  },
  {
    "text": "to make the training and influence much",
    "start": "540480",
    "end": "542279"
  },
  {
    "text": "faster that's nalo that's our library",
    "start": "542279",
    "end": "545040"
  },
  {
    "text": "called big deal Nano it puts all our CPU",
    "start": "545040",
    "end": "548820"
  },
  {
    "text": "accelerations for tensorflow and Pi",
    "start": "548820",
    "end": "551100"
  },
  {
    "text": "torch together and uncircle you don't",
    "start": "551100",
    "end": "553500"
  },
  {
    "text": "have to care about anything just use",
    "start": "553500",
    "end": "555360"
  },
  {
    "text": "another tip",
    "start": "555360",
    "end": "556920"
  },
  {
    "text": "okay so you know there are a lot of",
    "start": "556920",
    "end": "559740"
  },
  {
    "text": "accelerations outside it's uh including",
    "start": "559740",
    "end": "562140"
  },
  {
    "text": "like a better memory allocator proper",
    "start": "562140",
    "end": "564180"
  },
  {
    "text": "environment variables LX 512 multiple",
    "start": "564180",
    "end": "568140"
  },
  {
    "text": "processing influence engine and",
    "start": "568140",
    "end": "570540"
  },
  {
    "text": "quantization so on and each of the",
    "start": "570540",
    "end": "573779"
  },
  {
    "text": "acceleration will make the trading your",
    "start": "573779",
    "end": "575700"
  },
  {
    "text": "inference a slightly faster but each of",
    "start": "575700",
    "end": "579180"
  },
  {
    "text": "them takes a lot of effort and expertise",
    "start": "579180",
    "end": "582180"
  },
  {
    "text": "to do it",
    "start": "582180",
    "end": "583820"
  },
  {
    "text": "then this big deal Nano put everything",
    "start": "583820",
    "end": "587580"
  },
  {
    "text": "together and automatically convert and",
    "start": "587580",
    "end": "590640"
  },
  {
    "text": "enabled according to your platform so if",
    "start": "590640",
    "end": "593220"
  },
  {
    "text": "you use a big deal Nano you don't have",
    "start": "593220",
    "end": "595800"
  },
  {
    "text": "to care about how I do this or that then",
    "start": "595800",
    "end": "598680"
  },
  {
    "text": "you get the or even the platform you",
    "start": "598680",
    "end": "601320"
  },
  {
    "text": "don't have to care it's automatically",
    "start": "601320",
    "end": "603360"
  },
  {
    "text": "configured and enabled according to the",
    "start": "603360",
    "end": "605399"
  },
  {
    "text": "platform",
    "start": "605399",
    "end": "607680"
  },
  {
    "text": "okay here is an example to show you how",
    "start": "607680",
    "end": "610860"
  },
  {
    "text": "we do it",
    "start": "610860",
    "end": "612540"
  },
  {
    "text": "um the left parallel this is a",
    "start": "612540",
    "end": "614940"
  },
  {
    "text": "traditional way how we use a standard Pi",
    "start": "614940",
    "end": "617399"
  },
  {
    "text": "torch lightning library to train a model",
    "start": "617399",
    "end": "621000"
  },
  {
    "text": "if we want to enable a big deal Nano",
    "start": "621000",
    "end": "623880"
  },
  {
    "text": "it's just the simplest way instead of",
    "start": "623880",
    "end": "627000"
  },
  {
    "text": "import the trainer from python lighting",
    "start": "627000",
    "end": "630420"
  },
  {
    "text": "Library we just import the trainer from",
    "start": "630420",
    "end": "632760"
  },
  {
    "text": "big deal Nano that's it here resets the",
    "start": "632760",
    "end": "635700"
  },
  {
    "text": "number process and use Apex H2 to use",
    "start": "635700",
    "end": "639000"
  },
  {
    "text": "more like optimization from Intel",
    "start": "639000",
    "end": "642600"
  },
  {
    "text": "okay",
    "start": "642600",
    "end": "643860"
  },
  {
    "text": "[Music]",
    "start": "643860",
    "end": "644279"
  },
  {
    "text": "um",
    "start": "644279",
    "end": "645000"
  },
  {
    "text": "it's kind of um because the Nano gets",
    "start": "645000",
    "end": "648540"
  },
  {
    "text": "all the configuration and acceleration",
    "start": "648540",
    "end": "650779"
  },
  {
    "text": "automatically we run this Benchmark to",
    "start": "650779",
    "end": "654720"
  },
  {
    "text": "compare without Nano or with Lando",
    "start": "654720",
    "end": "657660"
  },
  {
    "text": "on both laptop or container we got the",
    "start": "657660",
    "end": "660839"
  },
  {
    "text": "substantial speed up so on local is not",
    "start": "660839",
    "end": "664019"
  },
  {
    "text": "as much as container but the container",
    "start": "664019",
    "end": "666060"
  },
  {
    "text": "is the one we care the most because",
    "start": "666060",
    "end": "667620"
  },
  {
    "text": "that's why you got the productionized",
    "start": "667620",
    "end": "669660"
  },
  {
    "text": "stuff",
    "start": "669660",
    "end": "671760"
  },
  {
    "text": "for the training on the container we get",
    "start": "671760",
    "end": "674399"
  },
  {
    "text": "almost six stamps training speed up and",
    "start": "674399",
    "end": "677399"
  },
  {
    "text": "for inference we got almost 10 times",
    "start": "677399",
    "end": "679800"
  },
  {
    "text": "inference speed up so it's kind of a",
    "start": "679800",
    "end": "682740"
  },
  {
    "text": "large if you run all the if you are pie",
    "start": "682740",
    "end": "686100"
  },
  {
    "text": "torch or tensorflow trainer you want to",
    "start": "686100",
    "end": "688800"
  },
  {
    "text": "use one I really suggest you can try big",
    "start": "688800",
    "end": "691440"
  },
  {
    "text": "deal Nano and Pikachu Orca you get it",
    "start": "691440",
    "end": "693899"
  },
  {
    "text": "much easier and they speed up",
    "start": "693899",
    "end": "696420"
  },
  {
    "text": "okay",
    "start": "696420",
    "end": "698040"
  },
  {
    "text": "um Nano also",
    "start": "698040",
    "end": "700680"
  },
  {
    "text": "have some neck oxidation on reach you",
    "start": "700680",
    "end": "704700"
  },
  {
    "text": "um",
    "start": "704700",
    "end": "705600"
  },
  {
    "text": "the first oxidation we've done is we put",
    "start": "705600",
    "end": "708240"
  },
  {
    "text": "our acceleration that said about the",
    "start": "708240",
    "end": "710760"
  },
  {
    "text": "other analog acceleration including all",
    "start": "710760",
    "end": "712560"
  },
  {
    "text": "the environments variables or multiple",
    "start": "712560",
    "end": "715079"
  },
  {
    "text": "processing and so on to into diff our",
    "start": "715079",
    "end": "719279"
  },
  {
    "text": "Orca and Define a nightling trainable",
    "start": "719279",
    "end": "722700"
  },
  {
    "text": "so in this one it includes all the",
    "start": "722700",
    "end": "725459"
  },
  {
    "text": "actuation already",
    "start": "725459",
    "end": "726959"
  },
  {
    "text": "and the second acceleration here for",
    "start": "726959",
    "end": "729180"
  },
  {
    "text": "region is for CPU binding we put it as",
    "start": "729180",
    "end": "732360"
  },
  {
    "text": "two then for each CPU I will let the CPU",
    "start": "732360",
    "end": "737459"
  },
  {
    "text": "exactly around this trial then the CPU",
    "start": "737459",
    "end": "740519"
  },
  {
    "text": "true for the child too that will make",
    "start": "740519",
    "end": "742800"
  },
  {
    "text": "the that makes it faster to access the",
    "start": "742800",
    "end": "745380"
  },
  {
    "text": "data when we after all this we run a",
    "start": "745380",
    "end": "749459"
  },
  {
    "text": "benchmark",
    "start": "749459",
    "end": "750680"
  },
  {
    "text": "compared to a program without Nano they",
    "start": "750680",
    "end": "755339"
  },
  {
    "text": "can read you it's like a lot like a",
    "start": "755339",
    "end": "758220"
  },
  {
    "text": "slower we got like four times speed up",
    "start": "758220",
    "end": "760920"
  },
  {
    "text": "but further multiple call we got at",
    "start": "760920",
    "end": "763620"
  },
  {
    "text": "least 20 percent swap because that's",
    "start": "763620",
    "end": "766079"
  },
  {
    "text": "configuring a better way because I read",
    "start": "766079",
    "end": "768240"
  },
  {
    "text": "through default is not configured in a",
    "start": "768240",
    "end": "770639"
  },
  {
    "text": "very",
    "start": "770639",
    "end": "771720"
  },
  {
    "text": "speed up way",
    "start": "771720",
    "end": "773639"
  },
  {
    "text": "um",
    "start": "773639",
    "end": "774240"
  },
  {
    "text": "after this one if we put the core",
    "start": "774240",
    "end": "777060"
  },
  {
    "text": "Binding Together We got even more that's",
    "start": "777060",
    "end": "779820"
  },
  {
    "text": "60 percent more for Nano and the core",
    "start": "779820",
    "end": "783480"
  },
  {
    "text": "biting so it's good to try",
    "start": "783480",
    "end": "787920"
  },
  {
    "text": "um for more information you can also see",
    "start": "787920",
    "end": "790079"
  },
  {
    "text": "from our website",
    "start": "790079",
    "end": "792779"
  },
  {
    "text": "this one I really want to uh maybe",
    "start": "792779",
    "end": "795420"
  },
  {
    "text": "reproject and review it faster and we",
    "start": "795420",
    "end": "797579"
  },
  {
    "text": "can merge the whole",
    "start": "797579",
    "end": "799040"
  },
  {
    "text": "PR much faster okay so after I will",
    "start": "799040",
    "end": "803880"
  },
  {
    "text": "handle this to my colleague and for the",
    "start": "803880",
    "end": "807360"
  },
  {
    "text": "three tour kids",
    "start": "807360",
    "end": "810500"
  },
  {
    "text": "thank you good job sorry",
    "start": "810779",
    "end": "813740"
  },
  {
    "text": "my name is Jenny Wong",
    "start": "813740",
    "end": "816180"
  },
  {
    "text": "and I will continue to introduce our",
    "start": "816180",
    "end": "818579"
  },
  {
    "text": "three domain specific two kids one is",
    "start": "818579",
    "end": "822720"
  },
  {
    "text": "the big deal ppmo another is the corners",
    "start": "822720",
    "end": "825959"
  },
  {
    "text": "and the last one is the friction",
    "start": "825959",
    "end": "829320"
  },
  {
    "text": "first let's look at the big deal PPM",
    "start": "829320",
    "end": "832680"
  },
  {
    "text": "as you know",
    "start": "832680",
    "end": "834480"
  },
  {
    "text": "uh",
    "start": "834480",
    "end": "836220"
  },
  {
    "text": "protection privacy and confidentiality",
    "start": "836220",
    "end": "838680"
  },
  {
    "text": "is critical",
    "start": "838680",
    "end": "840360"
  },
  {
    "text": "in the large-scale data analyst",
    "start": "840360",
    "end": "842940"
  },
  {
    "text": "analytics and machine learning",
    "start": "842940",
    "end": "844800"
  },
  {
    "text": "especially in the cloud or hybrid Cloud",
    "start": "844800",
    "end": "847579"
  },
  {
    "text": "so we create this big deal PPM solution",
    "start": "847579",
    "end": "851180"
  },
  {
    "text": "to create a secure and trusted big data",
    "start": "851180",
    "end": "855060"
  },
  {
    "text": "and the AI application environment",
    "start": "855060",
    "end": "858360"
  },
  {
    "text": "so in the this diagram from the lower",
    "start": "858360",
    "end": "861360"
  },
  {
    "text": "level",
    "start": "861360",
    "end": "862860"
  },
  {
    "text": "we combine several secure Technologies",
    "start": "862860",
    "end": "865800"
  },
  {
    "text": "like Intel sgx liberos secure Key",
    "start": "865800",
    "end": "870300"
  },
  {
    "text": "Management remote attestation data",
    "start": "870300",
    "end": "873360"
  },
  {
    "text": "encryption and decryption",
    "start": "873360",
    "end": "875040"
  },
  {
    "text": "and the",
    "start": "875040",
    "end": "876720"
  },
  {
    "text": "on button of the secure execution layer",
    "start": "876720",
    "end": "880320"
  },
  {
    "text": "user can apply their standard AI",
    "start": "880320",
    "end": "884420"
  },
  {
    "text": "workflows or that big data workflows",
    "start": "884420",
    "end": "888060"
  },
  {
    "text": "using the apart spark apart link SG",
    "start": "888060",
    "end": "891959"
  },
  {
    "text": "boost array tensorflow Pi touch Etc",
    "start": "891959",
    "end": "894800"
  },
  {
    "text": "without sacrifice the privacy",
    "start": "894800",
    "end": "898079"
  },
  {
    "text": "and on the top layer",
    "start": "898079",
    "end": "900540"
  },
  {
    "text": "we provide we provide a several trusted",
    "start": "900540",
    "end": "903839"
  },
  {
    "text": "big data and AI applications such as the",
    "start": "903839",
    "end": "907500"
  },
  {
    "text": "trusted secure and data frame trusted",
    "start": "907500",
    "end": "910860"
  },
  {
    "text": "machine learning and deep learning and",
    "start": "910860",
    "end": "913079"
  },
  {
    "text": "The Trusted Federated learning",
    "start": "913079",
    "end": "916820"
  },
  {
    "text": "so here is the workflow that how the big",
    "start": "916940",
    "end": "920639"
  },
  {
    "text": "deal PPM works",
    "start": "920639",
    "end": "922380"
  },
  {
    "text": "so it's a big deal PPM provides a",
    "start": "922380",
    "end": "926279"
  },
  {
    "text": "standard distribute air applications on",
    "start": "926279",
    "end": "929279"
  },
  {
    "text": "the encrypted data and the whole",
    "start": "929279",
    "end": "932339"
  },
  {
    "text": "pipeline the end-to-end pipeline can be",
    "start": "932339",
    "end": "935639"
  },
  {
    "text": "uh",
    "start": "935639",
    "end": "938160"
  },
  {
    "text": "security enabled you can see from the",
    "start": "938160",
    "end": "941399"
  },
  {
    "text": "data injections with a big deal PPM",
    "start": "941399",
    "end": "944519"
  },
  {
    "text": "provide the key management",
    "start": "944519",
    "end": "946920"
  },
  {
    "text": "from the Commandment service to provide",
    "start": "946920",
    "end": "949980"
  },
  {
    "text": "the data encryption and decryption and",
    "start": "949980",
    "end": "952980"
  },
  {
    "text": "do the secure data transfer from the",
    "start": "952980",
    "end": "956579"
  },
  {
    "text": "data lake or data warehouse and then",
    "start": "956579",
    "end": "959399"
  },
  {
    "text": "using the provision and the remote",
    "start": "959399",
    "end": "962399"
  },
  {
    "text": "attestation",
    "start": "962399",
    "end": "964139"
  },
  {
    "text": "to provide the trusted Cloud environment",
    "start": "964139",
    "end": "967800"
  },
  {
    "text": "either on frame or on cloud in the",
    "start": "967800",
    "end": "971519"
  },
  {
    "text": "kubernetes based on the Intel sjx nodes",
    "start": "971519",
    "end": "976199"
  },
  {
    "text": "and then leverage several",
    "start": "976199",
    "end": "980060"
  },
  {
    "text": "Technologies like Intel sjx encryption",
    "start": "980060",
    "end": "984000"
  },
  {
    "text": "TOS to do the secure data",
    "start": "984000",
    "end": "988160"
  },
  {
    "text": "computations and Communications",
    "start": "988160",
    "end": "990959"
  },
  {
    "text": "and after the data analytics and AI then",
    "start": "990959",
    "end": "994500"
  },
  {
    "text": "save the results to the distributed data",
    "start": "994500",
    "end": "997500"
  },
  {
    "text": "stores",
    "start": "997500",
    "end": "998839"
  },
  {
    "text": "with the",
    "start": "998839",
    "end": "1001759"
  },
  {
    "text": "secure data transfer and the data",
    "start": "1001759",
    "end": "1005000"
  },
  {
    "text": "encryption based on our Key Management",
    "start": "1005000",
    "end": "1007279"
  },
  {
    "text": "Service",
    "start": "1007279",
    "end": "1009320"
  },
  {
    "text": "so this is a whole workflow for the ppmr",
    "start": "1009320",
    "end": "1013160"
  },
  {
    "text": "let's look at the Coronas Coronas is a",
    "start": "1013160",
    "end": "1017240"
  },
  {
    "text": "application framework for the scalable",
    "start": "1017240",
    "end": "1020060"
  },
  {
    "text": "time series analysis with the automl",
    "start": "1020060",
    "end": "1023779"
  },
  {
    "text": "support in Coronas we support the TS",
    "start": "1023779",
    "end": "1027620"
  },
  {
    "text": "data set which provides more than 30",
    "start": "1027620",
    "end": "1031000"
  },
  {
    "text": "algorithms for the distribute time",
    "start": "1031000",
    "end": "1033438"
  },
  {
    "text": "series data operations like the scaling",
    "start": "1033439",
    "end": "1036918"
  },
  {
    "text": "rolling Etc and we also provide the more",
    "start": "1036919",
    "end": "1041600"
  },
  {
    "text": "than 10 building time series models",
    "start": "1041600",
    "end": "1045020"
  },
  {
    "text": "to do the common timers time series",
    "start": "1045020",
    "end": "1047660"
  },
  {
    "text": "analysis and we also provide the",
    "start": "1047660",
    "end": "1050660"
  },
  {
    "text": "distributed hyper parameter tuning the",
    "start": "1050660",
    "end": "1054200"
  },
  {
    "text": "user can Define their search space and",
    "start": "1054200",
    "end": "1056720"
  },
  {
    "text": "use the kernels search engine",
    "start": "1056720",
    "end": "1059480"
  },
  {
    "text": "to run the return jobs based on our real",
    "start": "1059480",
    "end": "1064520"
  },
  {
    "text": "smart framework of big deal and then get",
    "start": "1064520",
    "end": "1067700"
  },
  {
    "text": "the best model and parameters from the",
    "start": "1067700",
    "end": "1070700"
  },
  {
    "text": "routine",
    "start": "1070700",
    "end": "1073120"
  },
  {
    "text": "the big deal fruition is an application",
    "start": "1075620",
    "end": "1078860"
  },
  {
    "text": "framework especially for the large-scale",
    "start": "1078860",
    "end": "1081500"
  },
  {
    "text": "interim recommendation Solutions",
    "start": "1081500",
    "end": "1084799"
  },
  {
    "text": "based on the optimized Intel Xeon",
    "start": "1084799",
    "end": "1087440"
  },
  {
    "text": "servers",
    "start": "1087440",
    "end": "1089059"
  },
  {
    "text": "for the comp for use common users I",
    "start": "1089059",
    "end": "1092960"
  },
  {
    "text": "think to create the",
    "start": "1092960",
    "end": "1094660"
  },
  {
    "text": "whole recommendation system from scratch",
    "start": "1094660",
    "end": "1097640"
  },
  {
    "text": "which is a take a lot of efforts so we",
    "start": "1097640",
    "end": "1101539"
  },
  {
    "text": "create the friction to make the user",
    "start": "1101539",
    "end": "1103520"
  },
  {
    "text": "easy to create their recommendation",
    "start": "1103520",
    "end": "1105320"
  },
  {
    "text": "Solutions",
    "start": "1105320",
    "end": "1106940"
  },
  {
    "text": "so in this friction we we have three",
    "start": "1106940",
    "end": "1110120"
  },
  {
    "text": "stages the offline stages near line",
    "start": "1110120",
    "end": "1112880"
  },
  {
    "text": "stages and online stages",
    "start": "1112880",
    "end": "1114919"
  },
  {
    "text": "and these three stages are interacting",
    "start": "1114919",
    "end": "1117740"
  },
  {
    "text": "with each other",
    "start": "1117740",
    "end": "1119660"
  },
  {
    "text": "in the offline stages",
    "start": "1119660",
    "end": "1121760"
  },
  {
    "text": "we are focused on the distributed future",
    "start": "1121760",
    "end": "1123740"
  },
  {
    "text": "engineering and distribute training",
    "start": "1123740",
    "end": "1126799"
  },
  {
    "text": "so the user features and item features",
    "start": "1126799",
    "end": "1131059"
  },
  {
    "text": "so we create we provide several building",
    "start": "1131059",
    "end": "1134480"
  },
  {
    "text": "data processing",
    "start": "1134480",
    "end": "1136660"
  },
  {
    "text": "operations to do the data processing and",
    "start": "1136660",
    "end": "1140419"
  },
  {
    "text": "the future engineering so you will just",
    "start": "1140419",
    "end": "1142700"
  },
  {
    "text": "call our apis to do the common",
    "start": "1142700",
    "end": "1145000"
  },
  {
    "text": "recommendation data prepositions and",
    "start": "1145000",
    "end": "1148640"
  },
  {
    "text": "then after that",
    "start": "1148640",
    "end": "1150860"
  },
  {
    "text": "the friction can apply the distribute",
    "start": "1150860",
    "end": "1154039"
  },
  {
    "text": "training for the to create the to",
    "start": "1154039",
    "end": "1156620"
  },
  {
    "text": "generate the uh",
    "start": "1156620",
    "end": "1158660"
  },
  {
    "text": "user embedding and the item embedding",
    "start": "1158660",
    "end": "1161360"
  },
  {
    "text": "model and ranking models",
    "start": "1161360",
    "end": "1164900"
  },
  {
    "text": "the digital distributed training can be",
    "start": "1164900",
    "end": "1168799"
  },
  {
    "text": "running on the spark or on the real",
    "start": "1168799",
    "end": "1171380"
  },
  {
    "text": "clusters",
    "start": "1171380",
    "end": "1172460"
  },
  {
    "text": "and we already implemented several",
    "start": "1172460",
    "end": "1175039"
  },
  {
    "text": "popular recommendation models like the",
    "start": "1175039",
    "end": "1178039"
  },
  {
    "text": "white and deep",
    "start": "1178039",
    "end": "1180639"
  },
  {
    "text": "Etc to make the user easy to use",
    "start": "1181880",
    "end": "1185539"
  },
  {
    "text": "and in the near line stage which is to",
    "start": "1185539",
    "end": "1189080"
  },
  {
    "text": "provide the nearly near real-time update",
    "start": "1189080",
    "end": "1192860"
  },
  {
    "text": "we save the user features item features",
    "start": "1192860",
    "end": "1196400"
  },
  {
    "text": "and embed and user embeddings into the",
    "start": "1196400",
    "end": "1199400"
  },
  {
    "text": "American Store",
    "start": "1199400",
    "end": "1201500"
  },
  {
    "text": "and to make the easy to be retrieved",
    "start": "1201500",
    "end": "1205220"
  },
  {
    "text": "when the online request comes",
    "start": "1205220",
    "end": "1208340"
  },
  {
    "text": "and the the user profile and item",
    "start": "1208340",
    "end": "1211940"
  },
  {
    "text": "profile can be updated according to uh",
    "start": "1211940",
    "end": "1216200"
  },
  {
    "text": "from time to time according to the",
    "start": "1216200",
    "end": "1218120"
  },
  {
    "text": "system configurations",
    "start": "1218120",
    "end": "1220220"
  },
  {
    "text": "and the models are holding the",
    "start": "1220220",
    "end": "1222919"
  },
  {
    "text": "repository and also can be reached",
    "start": "1222919",
    "end": "1226660"
  },
  {
    "text": "returned according to the new coming",
    "start": "1226660",
    "end": "1229460"
  },
  {
    "text": "data",
    "start": "1229460",
    "end": "1232039"
  },
  {
    "text": "from regular basis",
    "start": "1232039",
    "end": "1234679"
  },
  {
    "text": "and in the online stage which is to do",
    "start": "1234679",
    "end": "1237679"
  },
  {
    "text": "the real-time online serving",
    "start": "1237679",
    "end": "1240440"
  },
  {
    "text": "so",
    "start": "1240440",
    "end": "1241820"
  },
  {
    "text": "when a user request comes",
    "start": "1241820",
    "end": "1244280"
  },
  {
    "text": "the feature service will retrieve the",
    "start": "1244280",
    "end": "1247220"
  },
  {
    "text": "user features and item features from",
    "start": "1247220",
    "end": "1249740"
  },
  {
    "text": "keyword store and then as the vector",
    "start": "1249740",
    "end": "1253340"
  },
  {
    "text": "Record Service will trigger the",
    "start": "1253340",
    "end": "1256520"
  },
  {
    "text": "similarity Vector search to search the",
    "start": "1256520",
    "end": "1260419"
  },
  {
    "text": "most relevant items based on the",
    "start": "1260419",
    "end": "1262940"
  },
  {
    "text": "similarity between the embeddings of the",
    "start": "1262940",
    "end": "1266360"
  },
  {
    "text": "target user and all the items and after",
    "start": "1266360",
    "end": "1269840"
  },
  {
    "text": "that it will get maybe hundreds or",
    "start": "1269840",
    "end": "1274160"
  },
  {
    "text": "thousands of item candidates",
    "start": "1274160",
    "end": "1277460"
  },
  {
    "text": "so this the first pre-filtered stage",
    "start": "1277460",
    "end": "1281660"
  },
  {
    "text": "and the the pre-filled item",
    "start": "1281660",
    "end": "1285460"
  },
  {
    "text": "candidate will be fed to the ranking",
    "start": "1285460",
    "end": "1289100"
  },
  {
    "text": "model to get the final result",
    "start": "1289100",
    "end": "1291620"
  },
  {
    "text": "so that's the whole online serving",
    "start": "1291620",
    "end": "1294020"
  },
  {
    "text": "process",
    "start": "1294020",
    "end": "1297020"
  },
  {
    "text": "and up to now big deal was already",
    "start": "1298580",
    "end": "1301880"
  },
  {
    "text": "adopted by many uh will use real real",
    "start": "1301880",
    "end": "1306260"
  },
  {
    "text": "world end users in Industries and in",
    "start": "1306260",
    "end": "1309679"
  },
  {
    "text": "various industry areas like the Consumer",
    "start": "1309679",
    "end": "1312559"
  },
  {
    "text": "Finance health",
    "start": "1312559",
    "end": "1315100"
  },
  {
    "text": "manufacturing science Etc so I would",
    "start": "1315100",
    "end": "1318500"
  },
  {
    "text": "dive in in several use cases to show how",
    "start": "1318500",
    "end": "1321559"
  },
  {
    "text": "the industry users use big deal to",
    "start": "1321559",
    "end": "1324200"
  },
  {
    "text": "create their end-to-end pipeline",
    "start": "1324200",
    "end": "1326960"
  },
  {
    "text": "first let's look at the AI skill in",
    "start": "1326960",
    "end": "1329840"
  },
  {
    "text": "MasterCard",
    "start": "1329840",
    "end": "1331100"
  },
  {
    "text": "aaf skill is a",
    "start": "1331100",
    "end": "1334960"
  },
  {
    "text": "driving force",
    "start": "1336140",
    "end": "1337700"
  },
  {
    "text": "to create a high value from data through",
    "start": "1337700",
    "end": "1340640"
  },
  {
    "text": "the Big Data AI Technologies in",
    "start": "1340640",
    "end": "1342980"
  },
  {
    "text": "MasterCard",
    "start": "1342980",
    "end": "1345140"
  },
  {
    "text": "so the whole pipeline includes the in",
    "start": "1345140",
    "end": "1348200"
  },
  {
    "text": "data injection from transactions data",
    "start": "1348200",
    "end": "1350780"
  },
  {
    "text": "ETL distribute training and tuning and",
    "start": "1350780",
    "end": "1354080"
  },
  {
    "text": "the Deep learning Model Management",
    "start": "1354080",
    "end": "1357159"
  },
  {
    "text": "distribute inference",
    "start": "1357159",
    "end": "1359480"
  },
  {
    "text": "and by",
    "start": "1359480",
    "end": "1361840"
  },
  {
    "text": "Builds on top of a big deal the AIS",
    "start": "1361840",
    "end": "1364940"
  },
  {
    "text": "skill makes the data scientist and data",
    "start": "1364940",
    "end": "1368240"
  },
  {
    "text": "engineer in MasterCard to develop",
    "start": "1368240",
    "end": "1370820"
  },
  {
    "text": "develop their distribute a applications",
    "start": "1370820",
    "end": "1374780"
  },
  {
    "text": "especially for tensorflow and Pi touch",
    "start": "1374780",
    "end": "1377380"
  },
  {
    "text": "based on their existing Enterprise data",
    "start": "1377380",
    "end": "1380780"
  },
  {
    "text": "warehouse platform",
    "start": "1380780",
    "end": "1382400"
  },
  {
    "text": "and as a result",
    "start": "1382400",
    "end": "1385659"
  },
  {
    "text": "is the AI to the several different",
    "start": "1386980",
    "end": "1390500"
  },
  {
    "text": "applications",
    "start": "1390500",
    "end": "1392240"
  },
  {
    "text": "by supporting up to two 2.2 billion",
    "start": "1392240",
    "end": "1395919"
  },
  {
    "text": "users and hundreds of billions of",
    "start": "1395919",
    "end": "1398360"
  },
  {
    "text": "records and running the distributed",
    "start": "1398360",
    "end": "1401059"
  },
  {
    "text": "training under hundreds of Intel Xeon",
    "start": "1401059",
    "end": "1403640"
  },
  {
    "text": "servers",
    "start": "1403640",
    "end": "1405440"
  },
  {
    "text": "let's look at another example that will",
    "start": "1405440",
    "end": "1408320"
  },
  {
    "text": "work with the SK Telecom",
    "start": "1408320",
    "end": "1410840"
  },
  {
    "text": "Intel work with SK Telecom",
    "start": "1410840",
    "end": "1413539"
  },
  {
    "text": "to build end-to-end AIP plan to do the",
    "start": "1413539",
    "end": "1417640"
  },
  {
    "text": "faster predictive",
    "start": "1417640",
    "end": "1420460"
  },
  {
    "text": "a network quality analysis from the SG",
    "start": "1420460",
    "end": "1425419"
  },
  {
    "text": "telecom's huge amount of live data set",
    "start": "1425419",
    "end": "1428840"
  },
  {
    "text": "the whole pipeline includes the data",
    "start": "1428840",
    "end": "1431900"
  },
  {
    "text": "injection and their purpose preparations",
    "start": "1431900",
    "end": "1434600"
  },
  {
    "text": "and the distribute training and and",
    "start": "1434600",
    "end": "1437539"
  },
  {
    "text": "inference",
    "start": "1437539",
    "end": "1439280"
  },
  {
    "text": "by leverage the aperture spark big deal",
    "start": "1439280",
    "end": "1442340"
  },
  {
    "text": "and tensorflow",
    "start": "1442340",
    "end": "1444380"
  },
  {
    "text": "we have the SK Telecom to create a",
    "start": "1444380",
    "end": "1447260"
  },
  {
    "text": "unifying pipeline",
    "start": "1447260",
    "end": "1449419"
  },
  {
    "text": "through the data processing to the",
    "start": "1449419",
    "end": "1451460"
  },
  {
    "text": "training and inference",
    "start": "1451460",
    "end": "1453200"
  },
  {
    "text": "and in the testing the end-to-end",
    "start": "1453200",
    "end": "1456620"
  },
  {
    "text": "inference pipeline gets up to six times",
    "start": "1456620",
    "end": "1459980"
  },
  {
    "text": "faster than their previous GPU Solutions",
    "start": "1459980",
    "end": "1464679"
  },
  {
    "text": "another example is a work we work with",
    "start": "1466100",
    "end": "1469039"
  },
  {
    "text": "the Burger King to create their fast",
    "start": "1469039",
    "end": "1471440"
  },
  {
    "text": "food recommendations",
    "start": "1471440",
    "end": "1473299"
  },
  {
    "text": "this is a solution use the rig apart",
    "start": "1473299",
    "end": "1477080"
  },
  {
    "text": "Spark",
    "start": "1477080",
    "end": "1478780"
  },
  {
    "text": "Apache mxnet",
    "start": "1478780",
    "end": "1481340"
  },
  {
    "text": "and a big deal working on the real spark",
    "start": "1481340",
    "end": "1484280"
  },
  {
    "text": "framework of big deal",
    "start": "1484280",
    "end": "1486679"
  },
  {
    "text": "so in this version the Burger King",
    "start": "1486679",
    "end": "1489740"
  },
  {
    "text": "integrates the data processing with",
    "start": "1489740",
    "end": "1491840"
  },
  {
    "text": "spark and distribute training with the",
    "start": "1491840",
    "end": "1495500"
  },
  {
    "text": "re and mxnet on the real Spark",
    "start": "1495500",
    "end": "1499220"
  },
  {
    "text": "and the works on the same cluster where",
    "start": "1499220",
    "end": "1502520"
  },
  {
    "text": "the big where the Perkins data is stored",
    "start": "1502520",
    "end": "1505520"
  },
  {
    "text": "and processed",
    "start": "1505520",
    "end": "1507980"
  },
  {
    "text": "so",
    "start": "1507980",
    "end": "1510020"
  },
  {
    "text": "by deploying the whole pipeline to their",
    "start": "1510020",
    "end": "1512840"
  },
  {
    "text": "production environment",
    "start": "1512840",
    "end": "1514400"
  },
  {
    "text": "Burger King gets a supreme result",
    "start": "1514400",
    "end": "1518419"
  },
  {
    "text": "in their real restaurant",
    "start": "1518419",
    "end": "1522580"
  },
  {
    "text": "so in a nutshell today",
    "start": "1524840",
    "end": "1527360"
  },
  {
    "text": "we show some key features of big deal",
    "start": "1527360",
    "end": "1529700"
  },
  {
    "text": "2.0 and how the big deal integration",
    "start": "1529700",
    "end": "1532340"
  },
  {
    "text": "with the real framework",
    "start": "1532340",
    "end": "1534200"
  },
  {
    "text": "if you want to get more informations you",
    "start": "1534200",
    "end": "1536900"
  },
  {
    "text": "can go to our GitHub repository or go to",
    "start": "1536900",
    "end": "1540200"
  },
  {
    "text": "the our doc site and you can also check",
    "start": "1540200",
    "end": "1543500"
  },
  {
    "text": "our live demo list in this reference",
    "start": "1543500",
    "end": "1547640"
  },
  {
    "text": "part",
    "start": "1547640",
    "end": "1549880"
  },
  {
    "text": "okay so any questions",
    "start": "1550520",
    "end": "1554740"
  },
  {
    "text": "[Music]",
    "start": "1559810",
    "end": "1562920"
  },
  {
    "text": "[Applause]",
    "start": "1564430",
    "end": "1569069"
  }
]
[
  {
    "start": "0",
    "end": "56000"
  },
  {
    "text": "good to see everyone who was here last year actually in the same exact room okay a few hands okay a lot okay a lot",
    "start": "4160",
    "end": "10040"
  },
  {
    "text": "of hands yeah okay I'm on time this year I promise I'm here um and yeah I'm here",
    "start": "10040",
    "end": "15480"
  },
  {
    "text": "to talk to llama and actually I think last year I talked really narrowly about like llama like uh really centered on",
    "start": "15480",
    "end": "22640"
  },
  {
    "text": "the models but I'm actually today I want to talk a lot more about like the things around llama and kind of the full stack that we're building and some of the pie",
    "start": "22640",
    "end": "29400"
  },
  {
    "text": "torch components and kind of everything this almost like an operating system that it's started to become which is really cool so uh for those who don't",
    "start": "29400",
    "end": "35719"
  },
  {
    "text": "know me um the logos are a little hard to see uh I'm Joe be I'm at meta um I've",
    "start": "35719",
    "end": "40920"
  },
  {
    "text": "spent a lot of time in kind of the open source and AI space uh more than 10 years now I guess in pie torch and llama",
    "start": "40920",
    "end": "48160"
  },
  {
    "text": "and uh building research and fair and other places I also Angel invest and advise uh some of the companies like",
    "start": "48160",
    "end": "53600"
  },
  {
    "text": "lightning and anthropic and a few others um enough about me um llama like who",
    "start": "53600",
    "end": "59000"
  },
  {
    "text": "uses llama who plays of llama models like hopefully like every hand in the room okay cool um it's been kind of",
    "start": "59000",
    "end": "66439"
  },
  {
    "text": "crazy how the adoption has has just continued to to I mean the the growth",
    "start": "66439",
    "end": "71920"
  },
  {
    "text": "has been incredible um I think we we're showing kind of the the hugging face downloads here I mean over 400 million every time I ping Omar at hugging face",
    "start": "71920",
    "end": "78560"
  },
  {
    "text": "it's like another 10 20 million downloads uh the derivatives are coming Fast and Furious over 65,000 so people",
    "start": "78560",
    "end": "84600"
  },
  {
    "text": "are using llama they're building on it and they're they're putting their models out there um it's been this it's been crazy uh we've had a number of Partners",
    "start": "84600",
    "end": "91439"
  },
  {
    "text": "every time we launch we you know we want models to be able to get you know as close to users as possible so we work",
    "start": "91439",
    "end": "98320"
  },
  {
    "text": "with everyone who you know from like AWS to IBM and Snowflake and everyone",
    "start": "98320",
    "end": "103799"
  },
  {
    "text": "basically to just really bring L of models and in our technology as close to developers as possible and it's pretty",
    "start": "103799",
    "end": "109719"
  },
  {
    "text": "awesome I think we we usually launch with close to 30 Partners on every every release um which is a lot of work but in",
    "start": "109719",
    "end": "115799"
  },
  {
    "text": "the end it's great for for developers um we've also seen um adoption and and growth of actual usage",
    "start": "115799",
    "end": "122880"
  },
  {
    "text": "this is from our some of our cloud provider Partners you can see just like very much an up and to the right you know classic graph um and there's",
    "start": "122880",
    "end": "130399"
  },
  {
    "text": "there's really no sign of this slowing down which is a lot of fun um but also we've seen costs uh drop",
    "start": "130399",
    "end": "137640"
  },
  {
    "text": "a lot so who's kind of observed like the race to the bottom like who's um you",
    "start": "137640",
    "end": "142720"
  },
  {
    "text": "know you can see like opening ey like in Google and all the prices we've actually that's been good because we want this",
    "start": "142720",
    "end": "148480"
  },
  {
    "text": "technology democratized and you can kind of see I think when we released the 45b",
    "start": "148480",
    "end": "153720"
  },
  {
    "text": "um you know back in July our friends at fireworks actually released it like $3 per million tokens Blended so you're",
    "start": "153720",
    "end": "160319"
  },
  {
    "text": "like getting a frontier scale model that you can f- tune and um and run it like on whatever you want um and even like",
    "start": "160319",
    "end": "166879"
  },
  {
    "text": "deploy it say like locally in your own data center or whatever and for $3 um",
    "start": "166879",
    "end": "172840"
  },
  {
    "text": "which is really wild I mean it's incredibly cheap um so really kind of brought this technology to to Really",
    "start": "172840",
    "end": "179080"
  },
  {
    "text": "anyone um so who knows the history of llama I think I I gave a little bit of this last",
    "start": "179080",
    "end": "184360"
  },
  {
    "start": "180000",
    "end": "380000"
  },
  {
    "text": "year in the the talk so um so llama one",
    "start": "184360",
    "end": "189440"
  },
  {
    "text": "uh so by the way these are all like uh things I've prompted on meta AI so if you want to go and prompt all this you can go to met. a and do yourself but um",
    "start": "189440",
    "end": "197400"
  },
  {
    "text": "actually who KN who actually knows the team who built llama one um does anybody kind know history few hands okay so it's",
    "start": "197400",
    "end": "203360"
  },
  {
    "text": "actually the team um in Fair so they're actually doing theorem proving um and by night they're training large language",
    "start": "203360",
    "end": "209080"
  },
  {
    "text": "models and and uh they released this llama 1 back in February of 2023 and uh it was basically just like",
    "start": "209080",
    "end": "216239"
  },
  {
    "text": "scrape together compute that they could get allocated um where possible and then they went off and started Mr all and you",
    "start": "216239",
    "end": "222120"
  },
  {
    "text": "know the rest is history like they've done some really cool stuff with uh with llms and um and really like the",
    "start": "222120",
    "end": "230439"
  },
  {
    "text": "explosion came with llama 2 that's where you know we had a commercial license and um you know this really allowed llama to",
    "start": "230439",
    "end": "237840"
  },
  {
    "text": "be brought into Enterprise and kind of for actual commercial usage and we saw like on day one um you know explosion of",
    "start": "237840",
    "end": "244319"
  },
  {
    "text": "people doing you know further fine-tuning of the models and and uh releasing chatbots and and running these",
    "start": "244319",
    "end": "249879"
  },
  {
    "text": "models in in different environments and local personal agents and it just kind of exploded from there it also was the",
    "start": "249879",
    "end": "256040"
  },
  {
    "text": "start of get my click here uh The Meta AI uh story so we have our own um you",
    "start": "256040",
    "end": "262520"
  },
  {
    "text": "know agent um at scale called meta Ai and if you go and you do search on any of the family of apps um you're using",
    "start": "262520",
    "end": "268759"
  },
  {
    "text": "meta AI and that's actually powered by llama so we're probably the only company that you know builds something that is",
    "start": "268759",
    "end": "275400"
  },
  {
    "text": "is used by you know Millions tens of millions hundreds of millions of people billions uh even um but also actually",
    "start": "275400",
    "end": "282039"
  },
  {
    "text": "open sources the underlying technology that that goes into it um obviously like post training and things are are different between the models because",
    "start": "282039",
    "end": "288160"
  },
  {
    "text": "we're we're tailoring the models for different applications um but the underlying technology is actually very",
    "start": "288160",
    "end": "293440"
  },
  {
    "text": "you know very similar and basically the same in a lot of cases in case of pre-train model um so it's a pretty rare thing which is really cool",
    "start": "293440",
    "end": "300440"
  },
  {
    "text": "and then llama 3 came um which seems like an eternity ago back in April uh so",
    "start": "300440",
    "end": "306479"
  },
  {
    "text": "we released um really I would say the this this was more of a pre-release I would say so who started using llama 3",
    "start": "306479",
    "end": "312919"
  },
  {
    "text": "um few folks so these were like you know smaller context window but like the the the reasoning ability um and the overall",
    "start": "312919",
    "end": "319639"
  },
  {
    "text": "like strength of the models improved significantly over llama 2 uh we did an update to meta AI at the same time um",
    "start": "319639",
    "end": "326039"
  },
  {
    "text": "and it was a big jump in performance uh I get my clicker to work here then um in llama 3.1 that's when we",
    "start": "326039",
    "end": "334319"
  },
  {
    "text": "really extended the context window to something that was more usable like that was 128k um but most importantly released",
    "start": "334319",
    "end": "341080"
  },
  {
    "text": "the 405b which really I would say has been um you know that the journey to",
    "start": "341080",
    "end": "346280"
  },
  {
    "text": "release that was was absolutely wild um and the impact has been has been felt I",
    "start": "346280",
    "end": "351440"
  },
  {
    "text": "mean the the amount of work happening in synthetic data and distillation and the fact that you kind of have this Frontier",
    "start": "351440",
    "end": "357160"
  },
  {
    "text": "scale model that you can then F tune and deploy um in your environment we've quantized it um in fp8 and you can",
    "start": "357160",
    "end": "363280"
  },
  {
    "text": "deploy it um on a single h100 ad100 node so it really brought the power um of I",
    "start": "363280",
    "end": "369400"
  },
  {
    "text": "would say a true foundation model um to everyone it's a very big model so not everyone can can certainly use it um but",
    "start": "369400",
    "end": "376919"
  },
  {
    "text": "it it it made it truly available to everyone and so uh who caught the",
    "start": "376919",
    "end": "382240"
  },
  {
    "start": "380000",
    "end": "561000"
  },
  {
    "text": "announcement last week anyone so timing was actually pretty good for this talk you you'll get to learn a little bit more of the details of of some of the",
    "start": "382240",
    "end": "388360"
  },
  {
    "text": "things we we released last week so um so last week we released llama 3 out2 which",
    "start": "388360",
    "end": "393880"
  },
  {
    "text": "um was again always I always say this for every release it was a labor thank you it was a labor of love um these",
    "start": "393880",
    "end": "400360"
  },
  {
    "text": "models are so freaking hard to get out to Market uh there's so much that goes into it so much in the way of weekends and Blood Sweat tiers um work with with",
    "start": "400360",
    "end": "408280"
  },
  {
    "text": "all the different uh you know Partners uh Safety Red teaming everything it takes to get them out so this time we",
    "start": "408280",
    "end": "413680"
  },
  {
    "text": "released Vision models along with some other models I'll talk about in a minute so this is our first multimodal models um uh out of llama and so we released an",
    "start": "413680",
    "end": "421840"
  },
  {
    "text": "11 and a 90b and you can think of these very much as like analoges to our 8 and70s so um basically we have adapter",
    "start": "421840",
    "end": "429440"
  },
  {
    "text": "weights which I'll talk about in in a second um but these models are essentially drop in compatible but they",
    "start": "429440",
    "end": "434479"
  },
  {
    "text": "support both um image input as well as as text and you can see here we use an",
    "start": "434479",
    "end": "439720"
  },
  {
    "text": "image adapter weight adapter approach so I'll talk about the training here in the second but it will take a an image",
    "start": "439720",
    "end": "445360"
  },
  {
    "text": "prompt it'll take a text prompt um it'll uh combine the modality um and then get kind of give you a um a",
    "start": "445360",
    "end": "453080"
  },
  {
    "text": "response and I'll show you some of the use cases here in a minute um in terms of how we actually train these so the",
    "start": "453080",
    "end": "460120"
  },
  {
    "text": "llm itself is actually you know a traditional Texton pre-training so you know much like we do um you know we do",
    "start": "460120",
    "end": "467520"
  },
  {
    "text": "large scale pretraining we pre-train 405b and and all of our other uh models like 8 and 70 um the multimodel we also",
    "start": "467520",
    "end": "473759"
  },
  {
    "text": "pre-train that um and basically uh that is then a separate set of weights um we",
    "start": "473759",
    "end": "479960"
  },
  {
    "text": "then align them together um and I'll talk more about that in a second and how we we generate the data um and then we",
    "start": "479960",
    "end": "487000"
  },
  {
    "text": "do like you know traditional kind of rhf um to steer the model and align it and",
    "start": "487000",
    "end": "493039"
  },
  {
    "text": "um and how it responds to you and how it takes in and promps and how we want it to kind of look and feel um as a",
    "start": "493039",
    "end": "499120"
  },
  {
    "text": "model um in terms of like how we think about the data so um we we used to like",
    "start": "499120",
    "end": "505440"
  },
  {
    "text": "so again like pre-training is is is unsupervised right it's a lot of a lot of images a lot of text obviously in the",
    "start": "505440",
    "end": "510759"
  },
  {
    "text": "in the llm um in sft we actually we use um you know some uh open data um from",
    "start": "510759",
    "end": "517719"
  },
  {
    "text": "academic data sets we use uh some synthetic data which I'll talk about here in a minute um and then we also um",
    "start": "517719",
    "end": "524200"
  },
  {
    "text": "we spend unfortunately a lot of money on on on annotations and and human curated data uh which is actually a lot of what",
    "start": "524200",
    "end": "531800"
  },
  {
    "text": "really makes these models great though um and so it's it's worth the money I guess so um in pre-training we use uh",
    "start": "531800",
    "end": "538320"
  },
  {
    "text": "roughly around 6 billion uh image text pairs um that gives you basically um a set of pre-trained adapter weights uh",
    "start": "538320",
    "end": "545560"
  },
  {
    "text": "that then pair with the pair with the llm and the are the kind of text base weights um and then we uh we have from",
    "start": "545560",
    "end": "551320"
  },
  {
    "text": "there kind of 600 million um that are like really high quality that are really kind of curated um that we use in in",
    "start": "551320",
    "end": "558519"
  },
  {
    "text": "post training um and so if you remember when",
    "start": "558519",
    "end": "564200"
  },
  {
    "start": "561000",
    "end": "806000"
  },
  {
    "text": "we were talking about back in July uh I think I I forget which conference I was",
    "start": "564200",
    "end": "569440"
  },
  {
    "text": "I was I was speaking like right after that and um you we were talking about kind of synthetic data generation for 45b and it was like the killer app and",
    "start": "569440",
    "end": "576640"
  },
  {
    "text": "it's like it's for us it was like a game changer because then we had a foundation True Foundation model that we can then",
    "start": "576640",
    "end": "582120"
  },
  {
    "text": "use um you know to develop smaller models we can kind of use it to generate post training data uh it's really really",
    "start": "582120",
    "end": "588600"
  },
  {
    "text": "versatile it becomes this kind of platform that you can use and and it it's it you know really allows you to do a lot of different things and so we",
    "start": "588600",
    "end": "595360"
  },
  {
    "text": "don't by the way none of the like some of this isn't isn't released in public so you'll just see that it's it's a large model it's generating data um but",
    "start": "595360",
    "end": "602320"
  },
  {
    "text": "you can imagine like taking a four or 5B class model and generating both an image and a question um doing things like uh",
    "start": "602320",
    "end": "610320"
  },
  {
    "text": "you know augment like prompt augmentation and like basically generating kind of augmented uh prompts",
    "start": "610320",
    "end": "616040"
  },
  {
    "text": "um and kind of prompt diversity uh and then from there kind of ranking like you know basically ranking them and figuring",
    "start": "616040",
    "end": "623279"
  },
  {
    "text": "out like which is kind of going to give you basically the best and this is you know of course based on like a reward model that we generate um and then",
    "start": "623279",
    "end": "629600"
  },
  {
    "text": "ultimately you can see like these get scored based on the reward model um and then what comes out of that actually",
    "start": "629600",
    "end": "635680"
  },
  {
    "text": "ends up in our sft data so basically this is what we end up using in our uh instruction tuning so this is um this",
    "start": "635680",
    "end": "642519"
  },
  {
    "text": "allows you really to scale up data for post training like in ways that you just couldn't do before like otherwise you're",
    "start": "642519",
    "end": "649040"
  },
  {
    "text": "like spending essentially you know a huge amount of money um trying to to get",
    "start": "649040",
    "end": "654240"
  },
  {
    "text": "humans to annotate these things and and figure out different prompts and generate you know different types of and",
    "start": "654240",
    "end": "659800"
  },
  {
    "text": "prompts um and it's it just becomes very very cost prohibitive for for most",
    "start": "659800",
    "end": "665000"
  },
  {
    "text": "companies this way we were actually able to scale it up and the results are really cool um so we actually so some of",
    "start": "665000",
    "end": "671920"
  },
  {
    "text": "the applications we've seen that are are really interesting so of course like visual kind of Q&A type tasks where you",
    "start": "671920",
    "end": "677240"
  },
  {
    "text": "can kind of prompt an image and like in this case like I I should eat more salads but like uh you can see I'm like",
    "start": "677240",
    "end": "683720"
  },
  {
    "text": "prompting what the salad is and it's giving me a set of ingredients and it's pretty detailed and estimate the calorie",
    "start": "683720",
    "end": "690639"
  },
  {
    "text": "count um you can see like in text understanding cases like who's read the Llama 3 paper the the her of models all",
    "start": "690639",
    "end": "698240"
  },
  {
    "text": "92 pages of it um no it's great paper um so you know we can basically prompt and",
    "start": "698240",
    "end": "704560"
  },
  {
    "text": "and use it because it has a long context um length you can actually put a lot of the paper in there and you can do in",
    "start": "704560",
    "end": "709600"
  },
  {
    "text": "context learning and and then generate um accurate responses so you can see it it goes and it we prompted said how many",
    "start": "709600",
    "end": "715839"
  },
  {
    "text": "parameters and tokens and it was actually right so four or five BM is 15 TR tokens um you can also do things like",
    "start": "715839",
    "end": "722800"
  },
  {
    "text": "chart and diagram analysis which is pretty interesting um doesn't always get the reasoning right yet I think we're still as a community trying to get our",
    "start": "722800",
    "end": "728680"
  },
  {
    "text": "models to our our Imaging models to to reason correctly but you can see it starts to give you um you know pretty",
    "start": "728680",
    "end": "734560"
  },
  {
    "text": "detailed descriptions and even like analyses of of what's happening in these graphs and this is getting pretty",
    "start": "734560",
    "end": "742000"
  },
  {
    "text": "useful and then there's like these things like you know this is a handwritten um set of equations you you can imagine you know if you have a",
    "start": "742440",
    "end": "749760"
  },
  {
    "text": "child doing homework or whatever and you want to be able to check their work like and obviously this is pretty easy for most of us probably a lot of engineers",
    "start": "749760",
    "end": "755360"
  },
  {
    "text": "in the room um but you can give it the image and and ask it to solve it and you can see it goes and kind of uh stepwise",
    "start": "755360",
    "end": "762360"
  },
  {
    "text": "goes and and solves the the problem for you and of course we do a ton of",
    "start": "762360",
    "end": "767880"
  },
  {
    "text": "benchmarks so I I won't belabor these um we were pretty happy I think with the benchmarks uh across different you know",
    "start": "767880",
    "end": "774040"
  },
  {
    "text": "both image as well as text so one unique thing I'd say about this model is we did um optimize the model really for both",
    "start": "774040",
    "end": "780680"
  },
  {
    "text": "image and and text so we didn't want text performance to suffer because we knew people would still you know use",
    "start": "780680",
    "end": "786320"
  },
  {
    "text": "this as a language model and and so text to text was really important to us because we ourselves um see the",
    "start": "786320",
    "end": "791480"
  },
  {
    "text": "usefulness of that um and then we added obviously the the ability for it to reason on images as well so um the fact",
    "start": "791480",
    "end": "797480"
  },
  {
    "text": "that it's kind of a one model drops in um you can use it for a variety of things um agents and multimodal agents",
    "start": "797480",
    "end": "803320"
  },
  {
    "text": "and so on is really powerful so um the other thing that this",
    "start": "803320",
    "end": "809600"
  },
  {
    "start": "806000",
    "end": "1308000"
  },
  {
    "text": "is super near and dear to my heart I've been pushing on this for quite a while at meta is the small model so who's played with the 1B and 3B anyone anyone",
    "start": "809600",
    "end": "816680"
  },
  {
    "text": "built like the mobile apps or like an Android app with it or um okay you got to go in on GitHub we built full apps in",
    "start": "816680",
    "end": "823519"
  },
  {
    "text": "Android and iOS and um I have a demo at the end I'll show you guys uh but I was",
    "start": "823519",
    "end": "829360"
  },
  {
    "text": "so amazed at the speed of these models um they're incredibly fast especially the 1B um it's it's a really fast model",
    "start": "829360",
    "end": "837320"
  },
  {
    "text": "so we um we we started to think about basically what you know what would be useful for applications ourselves like",
    "start": "837320",
    "end": "844160"
  },
  {
    "text": "as meta would would would like to use these models for and then you know we started talking with the community and I",
    "start": "844160",
    "end": "849639"
  },
  {
    "text": "had honestly I've been pushing on this for like well over like I think a year now and and trying to like think through what we should build and um uh and what",
    "start": "849639",
    "end": "857240"
  },
  {
    "text": "would be useful um and so we finally you know shipped these last week and I couldn't be happier honestly on the performance of them we've also uh used",
    "start": "857240",
    "end": "863440"
  },
  {
    "text": "the the 1B uh model and we've actually uh pruned as well as quantized it uh and",
    "start": "863440",
    "end": "868600"
  },
  {
    "text": "released that as a Lama guard um so you can actually use a as a safety model it's it's um it's like 500 Megs super",
    "start": "868600",
    "end": "876199"
  },
  {
    "text": "cheap it actually we have it running on uh a mobile device as well so it's actually an orchestrated safety model that's running um on a phone along with",
    "start": "876199",
    "end": "883959"
  },
  {
    "text": "the core llm it's pretty crazy um and it works really fast uh so it's it's it's",
    "start": "883959",
    "end": "889600"
  },
  {
    "text": "pretty impressive so when we thought about these models we actually uh we're pretty prescriptive in like what use",
    "start": "889600",
    "end": "896639"
  },
  {
    "text": "cases we were trying to think about so it's really hard to build a 1B model that is like very general and that like",
    "start": "896639",
    "end": "902800"
  },
  {
    "text": "has really strong reasoning right and that it's also great at coding and it's also great at math and and all these",
    "start": "902800",
    "end": "908079"
  },
  {
    "text": "things and we just like looking at the use cases for like Edge devices and like the experiences we were trying to drive",
    "start": "908079",
    "end": "914000"
  },
  {
    "text": "like uh we we decided to really focus our posttraining um on a handful of",
    "start": "914000",
    "end": "920120"
  },
  {
    "text": "things so things like summarization and retrieval augmented Generation Um writing assistance like I know it's not",
    "start": "920120",
    "end": "926360"
  },
  {
    "text": "a very sexy application but like prompt rewriting and like uh you know and be able to like generate like augmented",
    "start": "926360",
    "end": "932279"
  },
  {
    "text": "prompts like not having to go like to the cloud round trip is really useful like it's not very exciting but it's",
    "start": "932279",
    "end": "938839"
  },
  {
    "text": "really useful for like developers and for for like privacy and for applications um and so we really decided",
    "start": "938839",
    "end": "945160"
  },
  {
    "text": "to just zero in and really focus um on these like few applications and use cases in post trainining and we were",
    "start": "945160",
    "end": "951519"
  },
  {
    "text": "like super happy with the results to be honest um the uh I'll show you some benchmarks here in a minute but the way",
    "start": "951519",
    "end": "957240"
  },
  {
    "text": "we got there is we actually took both a pruning and a distillation path so again going back to like we have this great",
    "start": "957240",
    "end": "963800"
  },
  {
    "text": "Foundation set of models um how do we leverage those to to create something",
    "start": "963800",
    "end": "968839"
  },
  {
    "text": "small that's also you know really performant um and you know as strong as a model so we started with pruning the 8",
    "start": "968839",
    "end": "975920"
  },
  {
    "text": "billion parameter model so we pruned off a bunch of Weights um from it we uh then started to uh distill um logits from",
    "start": "975920",
    "end": "983600"
  },
  {
    "text": "both the 8B and the 70b as well as um is generated synthetic data from the 4 iby and I have actually",
    "start": "983600",
    "end": "991319"
  },
  {
    "text": "a I had a better more detailed chart but was kind of hard to read so I kept it out of here but you can kind of see what",
    "start": "991319",
    "end": "997199"
  },
  {
    "text": "we did here so in pre-training um you know so just like any other model you kind of have the pre-training and posttraining stepss and so in",
    "start": "997199",
    "end": "1004240"
  },
  {
    "text": "pre-training we did knowledge distillation which means we basically generated um you know basically uh",
    "start": "1004240",
    "end": "1010160"
  },
  {
    "text": "logits uh based on next token probability from the 8B and 70b and those basically waterfall into you know",
    "start": "1010160",
    "end": "1015759"
  },
  {
    "text": "the 1B and 3B respectively um in post training this is actually where like things got really interesting right we",
    "start": "1015759",
    "end": "1021560"
  },
  {
    "text": "generated synthetic data um from the 405b that was really really useful we then trained uh in sft um on synthetic",
    "start": "1021560",
    "end": "1028959"
  },
  {
    "text": "data uh for both the 1B and 3B and that's where like having really really high quality data from a foundation",
    "start": "1028959",
    "end": "1035079"
  },
  {
    "text": "model is incredibly powerful um and that the results really show and you can see actually here's the",
    "start": "1035079",
    "end": "1041880"
  },
  {
    "text": "results so you can see like some of the areas where we really focused um so like",
    "start": "1041880",
    "end": "1047160"
  },
  {
    "text": "bfcl and Nexus if you don't know those our tool use um Benchmark so we really wanted these models to be strong at like",
    "start": "1047160",
    "end": "1053160"
  },
  {
    "text": "agentic local agentic um applications so you can see those numbers are kind of bolded there um the instruction",
    "start": "1053160",
    "end": "1060080"
  },
  {
    "text": "following so if Val is an instruction following U Benchmark we're like well outp punching or outscoring I would say",
    "start": "1060080",
    "end": "1067400"
  },
  {
    "text": "larger models um uh in in some of these cases like wrote 67 versus say like the",
    "start": "1067400",
    "end": "1072640"
  },
  {
    "text": "f is like a larger model and in 3.8 versus a three billion um so you can see",
    "start": "1072640",
    "end": "1078360"
  },
  {
    "text": "like some of the areas we really really focused on um kind of shine through in the in the evals now the evals only tell",
    "start": "1078360",
    "end": "1084000"
  },
  {
    "text": "really you know part of the story they're really academic benchmarks but this was this kind of was um it",
    "start": "1084000",
    "end": "1089720"
  },
  {
    "text": "confirmed like a lot of what we thought um so Switching gears a little",
    "start": "1089720",
    "end": "1095520"
  },
  {
    "text": "bit so we also released something last week called llam stack so one of the things that um you know we've learned",
    "start": "1095520",
    "end": "1102120"
  },
  {
    "text": "over the last year or so is like you know llama models are important um but",
    "start": "1102120",
    "end": "1107200"
  },
  {
    "text": "they're also like one really like pretty big piece of the puzzle but they one piece of the puzzle and there's",
    "start": "1107200",
    "end": "1112559"
  },
  {
    "text": "a lot of other components that get orchestrated um and we kept hearing the same feedback over and over like uh you",
    "start": "1112559",
    "end": "1118159"
  },
  {
    "text": "know when you guys release models stuff changes um like your maybe the system prompt changes or um maybe your prompt",
    "start": "1118159",
    "end": "1124120"
  },
  {
    "text": "format changes or how you generate you know uh outputs for for Tool use or you know Json versus pythons we we kind of",
    "start": "1124120",
    "end": "1130080"
  },
  {
    "text": "heard a lot of feedback we also heard like from our our partners in like Cloud providers and platforms that you know",
    "start": "1130080",
    "end": "1136320"
  },
  {
    "text": "they're trying to basically uh every time we release stuff they have to go and integrate with you know things like L chain and and llama index and a lot of",
    "start": "1136320",
    "end": "1143120"
  },
  {
    "text": "these other these projects and uh VI Lam and you know kind of those type of projects and they were kind of tired of",
    "start": "1143120",
    "end": "1149760"
  },
  {
    "text": "like doing that over and over again so we decided to basically come up with a clean and and kind of um uh stable",
    "start": "1149760",
    "end": "1159640"
  },
  {
    "text": "API um and what this actually provided not only an API but a CLI so you know as a developer like having a CLI is really",
    "start": "1159640",
    "end": "1166400"
  },
  {
    "text": "handy um I don't have the slides here year I was um I I gave a similar talk at at y combinator like maybe about a month",
    "start": "1166400",
    "end": "1173159"
  },
  {
    "text": "ago where I was talking about this and it's like really handy to be able to like just be able to download the models with the CLI be able to like you know uh",
    "start": "1173159",
    "end": "1180520"
  },
  {
    "text": "inspect like what models are available like what sizes what context Windows like all that stuff and then you know be able to like very easily start to deploy",
    "start": "1180520",
    "end": "1187039"
  },
  {
    "text": "them or evaluate them or do these things all in like a nice CLI and so you can kind of pip install this or use cond um",
    "start": "1187039",
    "end": "1193720"
  },
  {
    "text": "and then you kind of have this library of things that you can do with with llama models um so it very much like it incorporates llama into like traditional",
    "start": "1193720",
    "end": "1201000"
  },
  {
    "text": "like software development workflows which is really nice um let's see uh so so this thing",
    "start": "1201000",
    "end": "1207400"
  },
  {
    "text": "called llama stack so basically it has a few different components it has this agentic system API which basically has",
    "start": "1207400",
    "end": "1213280"
  },
  {
    "text": "things like you know memory which incorporates things like rag um we also have things like Shield so if you want",
    "start": "1213280",
    "end": "1219080"
  },
  {
    "text": "to orchestrate multiple models for safety um that's like built in and you can kind of do that on day one and we",
    "start": "1219080",
    "end": "1225360"
  },
  {
    "text": "think that's really important because like it's not just going to be one model you're going to have a number of different things that are going to get",
    "start": "1225360",
    "end": "1230600"
  },
  {
    "text": "orchestrated as a system and you want to be able to kind of do that in an efficient way or not have to rewrite the",
    "start": "1230600",
    "end": "1235760"
  },
  {
    "text": "code or reimplement that um every time then there's also this model tool chain",
    "start": "1235760",
    "end": "1240840"
  },
  {
    "text": "API piece um which includes you know a lot I'll talk about py ver and all the good good stuff here in a minute um but",
    "start": "1240840",
    "end": "1246760"
  },
  {
    "text": "how do I like plug into you know projects like VM or torch tune um or torch Titan say I wanted to do like",
    "start": "1246760",
    "end": "1252760"
  },
  {
    "text": "continual pre-training you know on these models um you know what if I wanted to um you know like quanti a model for",
    "start": "1252760",
    "end": "1259600"
  },
  {
    "text": "example and use like torch AO or something like that um like having kind of a consistent like API and workflow",
    "start": "1259600",
    "end": "1264960"
  },
  {
    "text": "for that is actually pretty useful um and so what we've started to do we actually released our uh our first",
    "start": "1264960",
    "end": "1271720"
  },
  {
    "text": "distribution um and we had a number of Partners and forgive me but it's a little dark I think on the screen there",
    "start": "1271720",
    "end": "1276960"
  },
  {
    "text": "but you can kind of see some of our partners like Dell and AWS and grock and Nvidia and folks AMA and together uh",
    "start": "1276960",
    "end": "1283760"
  },
  {
    "text": "fireworks uh these are the folks that we worked with um as early Partners um they've adopted l stack and they've uh",
    "start": "1283760",
    "end": "1289600"
  },
  {
    "text": "started to build uh to the spec into our apis um and integrating with us and what this means is like they're kind of like",
    "start": "1289600",
    "end": "1295880"
  },
  {
    "text": "resilient the Next Generation that we release um and uh they'll be kind of",
    "start": "1295880",
    "end": "1300919"
  },
  {
    "text": "there on day one with us and as features start to roll out we have new features in in llama stack they'll be supporting",
    "start": "1300919",
    "end": "1306559"
  },
  {
    "text": "those um so this is probably my favorite part of the the talk uh both projects are",
    "start": "1306559",
    "end": "1313080"
  },
  {
    "start": "1308000",
    "end": "1359000"
  },
  {
    "text": "near and dear to my heart uh but I'll talk a little bit about PCH now um so",
    "start": "1313080",
    "end": "1319159"
  },
  {
    "text": "when we think about some of the things that underpin uh a lot of the work here um if you look at all the way you know",
    "start": "1319159",
    "end": "1324880"
  },
  {
    "text": "from like the 1B to the 4 or 5B um the the glue that in the the",
    "start": "1324880",
    "end": "1330320"
  },
  {
    "text": "foundational components to get all of this like to achieve all of this was py torch so whether it was like how we you",
    "start": "1330320",
    "end": "1337039"
  },
  {
    "text": "know distill the models how we deploy them onto devices like execut torch uh whether we you know through pre-training",
    "start": "1337039",
    "end": "1343679"
  },
  {
    "text": "or continual pre-training or fine-tuning all of this was really pie torch at the end of the day so it it really is kind",
    "start": "1343679",
    "end": "1349080"
  },
  {
    "text": "of like um and you know it's not just llama obviously like others like opening I Ed Pie torch and anthropic and others",
    "start": "1349080",
    "end": "1354960"
  },
  {
    "text": "so it's it's become a foundational piece of like how gender of AI is happening so just a few the cool libraries that I",
    "start": "1354960",
    "end": "1361520"
  },
  {
    "start": "1359000",
    "end": "1836000"
  },
  {
    "text": "love that I think are foundational to to how all this is happening and I'll go through them one by one here but like",
    "start": "1361520",
    "end": "1367480"
  },
  {
    "text": "I'm kind of curious like who's heard of torch dun okay cool few folks so love I",
    "start": "1367480",
    "end": "1373679"
  },
  {
    "text": "helped build that project from the beginning so I love that project torch Titan who's like actually LM here like",
    "start": "1373679",
    "end": "1379880"
  },
  {
    "text": "who uses fstp or you know a few folks okay cool uh torch chat is a fairly new",
    "start": "1379880",
    "end": "1385360"
  },
  {
    "text": "project actually for inference um torch compile probably a few folks yeah so you",
    "start": "1385360",
    "end": "1391120"
  },
  {
    "text": "know kind of optimizes your code um and then execute torch which is um we're going to do another another blog post",
    "start": "1391120",
    "end": "1397039"
  },
  {
    "text": "here on execut Torch like pretty soon but that is like the project that we're betting on for on device on device has",
    "start": "1397039",
    "end": "1402320"
  },
  {
    "text": "been you know kind of this this crazy mess in the software space for the longest time and we really excited about where execu torch is going",
    "start": "1402320",
    "end": "1409440"
  },
  {
    "text": "so first off fine tuning so torch tune U we thought long and hard about you know what we wanted to go build as far as you",
    "start": "1409440",
    "end": "1416520"
  },
  {
    "text": "know how you find tune libraries what we actually found uh let me check my time here good um is you know when when",
    "start": "1416520",
    "end": "1422880"
  },
  {
    "text": "people were taking like llama models and and they wanted to fine-tune them theistic people had was I go to llama",
    "start": "1422880",
    "end": "1430520"
  },
  {
    "text": "recipes and I grab the jupyter notebook that gentleman named Hamid over at meta built and basically like copy and paste",
    "start": "1430520",
    "end": "1436840"
  },
  {
    "text": "some you know some code so there wasn't like a really great like library that was out there there wasn't really a great like clean experience um and so we",
    "start": "1436840",
    "end": "1444480"
  },
  {
    "text": "decided to build torch tune and we started we decided to build this last year and the I think the reception's been really great um and so you can",
    "start": "1444480",
    "end": "1451120"
  },
  {
    "text": "imagine like fine tuning using things like Laura Cur um you know like basically it's it is it's a true Library",
    "start": "1451120",
    "end": "1457960"
  },
  {
    "text": "it's not you know not really a framework you can kind of plug in these capabilities to your your workflow and it's a very clean and well-maintained",
    "start": "1457960",
    "end": "1464559"
  },
  {
    "text": "project so if you're looking to fine-tune a llama model this is probably a great place to start if you are",
    "start": "1464559",
    "end": "1470320"
  },
  {
    "text": "looking to um I mean I don't know how many people are doing pre-training these days um probably probably not that many",
    "start": "1470320",
    "end": "1476679"
  },
  {
    "text": "uh this scale but but continual pre-training I think is is I hear actually quite a few folks are trying to",
    "start": "1476679",
    "end": "1481880"
  },
  {
    "text": "take models and do CPT um this is a great library and it's actually uh this is incredibly popular so if you want to",
    "start": "1481880",
    "end": "1487720"
  },
  {
    "text": "use fsdp or pipeline parallelism basically this is a really nice composable Library allows you to to",
    "start": "1487720",
    "end": "1494000"
  },
  {
    "text": "scale up things like continual pre-training um using like low Precision like fp8 um it actually has like support",
    "start": "1494000",
    "end": "1500520"
  },
  {
    "text": "for like async um checkpointing um this is like a lot of how we scale up models at meta we use um",
    "start": "1500520",
    "end": "1507200"
  },
  {
    "text": "torch Titan uh and so if you you know if if you need to do that you can kind of",
    "start": "1507200",
    "end": "1512240"
  },
  {
    "text": "import it um and use use it um on you know mainly Nvidia gpus is what we we",
    "start": "1512240",
    "end": "1517720"
  },
  {
    "text": "support today um if you need to run uh inference um you know there's obviously a number",
    "start": "1517720",
    "end": "1523640"
  },
  {
    "text": "of projects uh torch chat is a is a project that um basically allows you to",
    "start": "1523640",
    "end": "1530159"
  },
  {
    "text": "to run um across the board you can kind of run it in uh local environments you can kind of run on device um and it like",
    "start": "1530159",
    "end": "1537399"
  },
  {
    "text": "seamlessly works with execut torch we have some like demos we show how you can run like multi note inference or",
    "start": "1537399",
    "end": "1542760"
  },
  {
    "text": "distributed inference using 45b so it's a super versatile library for uh for inference as",
    "start": "1542760",
    "end": "1548120"
  },
  {
    "text": "well and then in terms of compiler so one of the things that we uh we focused on for pytorch 2.0 when that came out uh",
    "start": "1548120",
    "end": "1556159"
  },
  {
    "text": "was really the compiler the compiler was like the big the big effort and and big Delta um from like the one datto era to",
    "start": "1556159",
    "end": "1563000"
  },
  {
    "text": "the two datto era and so we've continued to push on compiler as a way to obviously drive more performance um but",
    "start": "1563000",
    "end": "1569360"
  },
  {
    "text": "also like a more diverse um Hardware like Universe around pytorch and you can see like some of the backends um",
    "start": "1569360",
    "end": "1576919"
  },
  {
    "text": "obviously torch inductor is like a is a native uh back end for for p torch um",
    "start": "1576919",
    "end": "1582360"
  },
  {
    "text": "but we also support you know like Nvidia and Intel and and a number of others um and you can you can also like",
    "start": "1582360",
    "end": "1588640"
  },
  {
    "text": "incorporate things like torch AO so if you wanted to like quantize and then you know incorporate your like compilation pass passes like that all works really",
    "start": "1588640",
    "end": "1596039"
  },
  {
    "text": "nicely together and then lastly uh execut torch",
    "start": "1596039",
    "end": "1601320"
  },
  {
    "text": "so this was uh kind of like the unsung hero I would say of like the connect launch last week uh we showed some really cool demos they were in Mark's",
    "start": "1601320",
    "end": "1608000"
  },
  {
    "text": "keynote as well as Chris Cox's keynote um uh at at at the event and you know",
    "start": "1608000",
    "end": "1613960"
  },
  {
    "text": "executive torch was the underpin like underpinning of all of our our kind of mobile demos um um and that along with",
    "start": "1613960",
    "end": "1619880"
  },
  {
    "text": "like torcho quantizing and then B basically being able to run these models uh efficiently on um say both IOS and",
    "start": "1619880",
    "end": "1626320"
  },
  {
    "text": "Android devices and we're not limited to those devices we actually showed a mixed reality demo of a headset running the 1B",
    "start": "1626320",
    "end": "1632880"
  },
  {
    "text": "model um which was really amazing um I don't think it ended up being public but I think I can post a video at some point",
    "start": "1632880",
    "end": "1640399"
  },
  {
    "text": "but it was really cool um that we're we we built that demo in like I think two weeks so really cool stuff so I'm going",
    "start": "1640399",
    "end": "1646360"
  },
  {
    "text": "to I'm going to run out of time but I want to show you really quick demo um which says it can't play the file for some reason um no the demo",
    "start": "1646360",
    "end": "1654799"
  },
  {
    "text": "Gods no where are you let's see if I can get this",
    "start": "1654799",
    "end": "1659840"
  },
  {
    "text": "worked um if it doesn't work then I will just tell you how cool it",
    "start": "1659840",
    "end": "1665919"
  },
  {
    "text": "is what's that there's a",
    "start": "1665919",
    "end": "1673440"
  },
  {
    "text": "link see oh yeah oh you know what I bet just cuz I'm not I'm not connected to",
    "start": "1673960",
    "end": "1679679"
  },
  {
    "text": "the Wi-Fi that's why let me see if I can uh let me see if",
    "start": "1679679",
    "end": "1685240"
  },
  {
    "text": "the marot conference Wi-Fi is",
    "start": "1685240",
    "end": "1689559"
  },
  {
    "text": "good is there okay is it password whose iPhone is this",
    "start": "1692480",
    "end": "1698799"
  },
  {
    "text": "I'm just [Laughter] kidding or who's DB actually I don't",
    "start": "1698799",
    "end": "1704480"
  },
  {
    "text": "know let's see if I'm connected no I'm not connected um",
    "start": "1704480",
    "end": "1710120"
  },
  {
    "text": "weird yeah it's not coming up though interestingly enough there's a hard line at the",
    "start": "1714159",
    "end": "1721720"
  },
  {
    "text": "podium whoever that is I'm sorry you want to use my hotot is this Alexander phone yeah",
    "start": "1723320",
    "end": "1729440"
  },
  {
    "text": "that's me really the password is just for you",
    "start": "1729440",
    "end": "1735000"
  },
  {
    "text": "let's see if it [Applause] works I love you man let's see if it",
    "start": "1739799",
    "end": "1748000"
  },
  {
    "text": "really works oh no where is it where is",
    "start": "1748000",
    "end": "1755399"
  },
  {
    "text": "it oh look at that I'm streaming off your phone",
    "start": "1755399",
    "end": "1760440"
  },
  {
    "text": "ah you're my hero okay so we're going to load a model this is the 1B um quanti to",
    "start": "1760440",
    "end": "1767720"
  },
  {
    "text": "uh 4 and you can see we're just doing some basic prompting here there's nothing nothing special",
    "start": "1767720",
    "end": "1773279"
  },
  {
    "text": "here so like how to start a campfire the trick here is like to to check out like",
    "start": "1773279",
    "end": "1778519"
  },
  {
    "text": "how fast this is generating so one of the coolest things we so we had arms",
    "start": "1778519",
    "end": "1784120"
  },
  {
    "text": "speak at the the conference uh last week and you can see like I'm running almost 40 over 42 tokens a second just running",
    "start": "1784120",
    "end": "1791120"
  },
  {
    "text": "on like a mainstream Android device which is like wild feel how",
    "start": "1791120",
    "end": "1797000"
  },
  {
    "text": "Snappy that is and um arm actually demoed I think 250 tokens a second like",
    "start": "1797000",
    "end": "1802559"
  },
  {
    "text": "prefill and then something like 60 tokens a second generation so if you",
    "start": "1802559",
    "end": "1808000"
  },
  {
    "text": "think about this is this is a 1B model that's really coherent that actually will do agentic stuff like on your phone",
    "start": "1808000",
    "end": "1814279"
  },
  {
    "text": "you hit almost 45 tokens a second there so all of this by the way is like open",
    "start": "1814279",
    "end": "1819399"
  },
  {
    "text": "source it's on GitHub you can get it you can build the phone you can build it on your phone whatever it's it's like free",
    "start": "1819399",
    "end": "1825480"
  },
  {
    "text": "it's the model's there all the code is there the app is there so literally go get it and and play with it fine tune it",
    "start": "1825480",
    "end": "1831320"
  },
  {
    "text": "and build your own local agent on your phone so and that is it thank you so",
    "start": "1831320",
    "end": "1836679"
  },
  {
    "start": "1836000",
    "end": "1980000"
  },
  {
    "text": "much and thank you all",
    "start": "1836679",
    "end": "1841960"
  },
  {
    "text": "right all right thank you Joe uh we have a few minutes for questions please raise your hands I'll get that back to",
    "start": "1841960",
    "end": "1850000"
  },
  {
    "text": "you um the 1B model is really impressive could you comment on the the AI",
    "start": "1851360",
    "end": "1858320"
  },
  {
    "text": "companion like we saw this new release from The Meta on the the Rayband glass",
    "start": "1858320",
    "end": "1864679"
  },
  {
    "text": "is that what's the company going for to develop more like a high intelligent AI companion with local",
    "start": "1864679",
    "end": "1871519"
  },
  {
    "text": "device yeah I mean I I I think the the glasses have been super popular the ray",
    "start": "1871519",
    "end": "1877480"
  },
  {
    "text": "band metas and it's I don't know if it's like luck or if it's like just like um",
    "start": "1877480",
    "end": "1882639"
  },
  {
    "text": "really these like Ai and and kind of mixed reality coming together did you see the uh Orion demo like it was it was",
    "start": "1882639",
    "end": "1889679"
  },
  {
    "text": "wild you got to definitely check that out Mark did the demo in in the the keynote last week and uh I think yeah I",
    "start": "1889679",
    "end": "1895720"
  },
  {
    "text": "mean I think these things are like like coming together at like the right time and like like I said we were running I",
    "start": "1895720",
    "end": "1901080"
  },
  {
    "text": "think it was on a quest 3 Pro uh we running like the 1B model and it was feeling um and and basically playing",
    "start": "1901080",
    "end": "1907559"
  },
  {
    "text": "around in mixed with mixed reality like with multiple people seeing the same thing and being able to Converse in multi you know different languages um",
    "start": "1907559",
    "end": "1915240"
  },
  {
    "text": "and do generations and all that um and input images because it was you know you can have like different we had",
    "start": "1915240",
    "end": "1921399"
  },
  {
    "text": "different multimodal models on there along with our llm and um I think this is where things are going and I think",
    "start": "1921399",
    "end": "1927000"
  },
  {
    "text": "because because you want like you want low latency and you want privacy and you want all these things you want it kind of because obviously a round trip to the",
    "start": "1927000",
    "end": "1933320"
  },
  {
    "text": "cloud if you're wearing a headset or your glasses like I don't know if you've ever played with like some of like the wearables like the Humane pin or",
    "start": "1933320",
    "end": "1938600"
  },
  {
    "text": "whatever the latency is really really long so you don't want that right obviously so uh I have another question",
    "start": "1938600",
    "end": "1944159"
  },
  {
    "text": "regarding the post training uh do you think uh synthetic data is 100% all we",
    "start": "1944159",
    "end": "1949200"
  },
  {
    "text": "need what's the percentage of sensitive data verse Real data use in the post training for L",
    "start": "1949200",
    "end": "1955360"
  },
  {
    "text": "3 what how much was the the percentage of synthetic data versus real data I",
    "start": "1955360",
    "end": "1960600"
  },
  {
    "text": "don't think it's 100% synthetic data for post training right no no it wasn't um I",
    "start": "1960600",
    "end": "1966399"
  },
  {
    "text": "don't know with the percentage off hand maybe like it was it was it was more than the curated so probably more than half was",
    "start": "1966399",
    "end": "1974039"
  },
  {
    "text": "probably uh synthetic because it's that like you can scale up the synthetic data quite quite a bit more obviously I'm",
    "start": "1974039",
    "end": "1979799"
  },
  {
    "text": "paying a lot for the curated like annotated human human data",
    "start": "1979799",
    "end": "1984799"
  },
  {
    "start": "1980000",
    "end": "2254000"
  },
  {
    "text": "so can you share with us uh what to expect uh in llama 4 or llama",
    "start": "1989840",
    "end": "1999440"
  },
  {
    "text": "5 um no um I mean we we've teased some of this stuff I think uh you can imagine",
    "start": "2000440",
    "end": "2007399"
  },
  {
    "text": "where things are are going in terms of of modalities and and languages oh sorry",
    "start": "2007399",
    "end": "2012519"
  },
  {
    "text": "not speaking in the mic here um I mean we we you saw like what if you follow kind of meta Ai and where that's going",
    "start": "2012519",
    "end": "2017960"
  },
  {
    "text": "in terms of like we showed voice and uh voice uh voice to voice um last week um",
    "start": "2017960",
    "end": "2026200"
  },
  {
    "text": "you know we're a global company with billions of of people on our platform so more languages um better",
    "start": "2026200",
    "end": "2032720"
  },
  {
    "text": "reasoning um so you know I think like you can imagine those are obviously",
    "start": "2032720",
    "end": "2037799"
  },
  {
    "text": "directions we're going U we're obviously going to continue to push scale uh cuz you know we have obviously a lot of",
    "start": "2037799",
    "end": "2042960"
  },
  {
    "text": "compute and a lot of ambition um and we want to build the best models in the world um so yeah llama four llama five",
    "start": "2042960",
    "end": "2049200"
  },
  {
    "text": "they're going to be they're going to be fun so you know I can't I can't give you any secrets away but like like stay with",
    "start": "2049200",
    "end": "2055960"
  },
  {
    "text": "us we're we're building some cool stuff yeah",
    "start": "2055960",
    "end": "2061599"
  },
  {
    "text": "yeah uh so I think we all just listened to the open IP talk about how uh they're going to be scaling up um essentially",
    "start": "2064159",
    "end": "2071158"
  },
  {
    "text": "inference time compute as well uh they're going to be start scaling up inference time compute to get better performance can you talk a little bit",
    "start": "2071159",
    "end": "2076760"
  },
  {
    "text": "about like uh meta's approach here as well um if you guys are doing stuff",
    "start": "2076760",
    "end": "2082000"
  },
  {
    "text": "there I mean I can't comment really on on what we're doing there uh I can point you to like a couple of projects in the",
    "start": "2082000",
    "end": "2087679"
  },
  {
    "text": "past though like I feel like you know inference time compute and like search research and RL like inference time like",
    "start": "2087679",
    "end": "2093960"
  },
  {
    "text": "this is um I mean there's there's some work in the past we've done um like the diplomacy project which is one of my",
    "start": "2093960",
    "end": "2099839"
  },
  {
    "text": "projects I I helped work on and uh I think that there's prior art there I",
    "start": "2099839",
    "end": "2105079"
  },
  {
    "text": "think um the trick with that technology or that approach is like how do you generalize it like in a in a way that",
    "start": "2105079",
    "end": "2110839"
  },
  {
    "text": "like can be more broadly useful uh with diplomacy for example it was it was",
    "start": "2110839",
    "end": "2116320"
  },
  {
    "text": "pretty amazing what we did um but at the same time it was like in like in the domain of like diplomacy was like really",
    "start": "2116320",
    "end": "2122880"
  },
  {
    "text": "useful but once you kind of got out outside the domain it was like very like it you know you couldn't Converse with the agent at all right just would fall",
    "start": "2122880",
    "end": "2129320"
  },
  {
    "text": "off fall fall apart so um so I think we have like a lot of those people are still around in meta and they're working",
    "start": "2129320",
    "end": "2134800"
  },
  {
    "text": "on these these things so um we have you know experts in kind of all those areas",
    "start": "2134800",
    "end": "2140280"
  },
  {
    "text": "so you can imagine kind of some of the areas we're pushing on so yeah just building off of everyone El",
    "start": "2140280",
    "end": "2149680"
  },
  {
    "text": "question just building off of everyone analysis questions does meta have plans to release a 01 equivalent",
    "start": "2149680",
    "end": "2157920"
  },
  {
    "text": "where we can see the reasoning and the change of thoughts being exposed I can't comment on on anything",
    "start": "2157920",
    "end": "2164599"
  },
  {
    "text": "we haven't released um but I mean reasoning is like an important area to push on uh because",
    "start": "2164599",
    "end": "2170000"
  },
  {
    "text": "it's it is kind of like uh it's foundational to you know agents and so",
    "start": "2170000",
    "end": "2176359"
  },
  {
    "text": "we'll obviously we have a entire team that focuses on reasoning and so we'll continue to push on that so yeah awesome",
    "start": "2176359",
    "end": "2181880"
  },
  {
    "text": "looking forward to it cool",
    "start": "2181880",
    "end": "2185920"
  },
  {
    "text": "any other",
    "start": "2188480",
    "end": "2191000"
  },
  {
    "text": "questions yeah just a a quick question around the recent uh Mommo release have",
    "start": "2195200",
    "end": "2200960"
  },
  {
    "text": "you all done any benchmarking or comparisons uh I know that the timing was pretty uh tight with both of those",
    "start": "2200960",
    "end": "2207560"
  },
  {
    "text": "models I actually haven't looked at those models I know they I'm sorry I I",
    "start": "2207560",
    "end": "2213359"
  },
  {
    "text": "mean I saw the benchmarks um and I saw there's a lot of benchmarks that fly around I honest haven't had time to to",
    "start": "2213359",
    "end": "2218520"
  },
  {
    "text": "actually play with them I think uh this these the AI ones yeah um I mean they",
    "start": "2218520",
    "end": "2224760"
  },
  {
    "text": "look good on paper um I think we've we'll probably Benchmark them and see what we can learn from them certainly I",
    "start": "2224760",
    "end": "2229800"
  },
  {
    "text": "mean um but yeah there's like I know Nvidia even like yesterday released a multimodal model as well and like so",
    "start": "2229800",
    "end": "2235760"
  },
  {
    "text": "yeah it's they're they're coming out like crazy it's it's awesome so in my opinion anyway like the more the marrier",
    "start": "2235760",
    "end": "2240880"
  },
  {
    "text": "like the more people and more companies uh release I think it's a good thing so but yeah we'll take a look at them sure",
    "start": "2240880",
    "end": "2248520"
  },
  {
    "text": "cool all right thank you all right thanks Joe thanks everyone for joining",
    "start": "2248520",
    "end": "2255160"
  }
]
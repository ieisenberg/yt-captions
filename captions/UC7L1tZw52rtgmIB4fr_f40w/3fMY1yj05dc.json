[
  {
    "text": "[Music]",
    "start": "170",
    "end": "14480"
  },
  {
    "text": "hello my name is richard decal from",
    "start": "14480",
    "end": "16320"
  },
  {
    "text": "dendrosystems",
    "start": "16320",
    "end": "17760"
  },
  {
    "text": "and thank you for the invitation to give",
    "start": "17760",
    "end": "19359"
  },
  {
    "text": "this talk i'm excited to tell you today",
    "start": "19359",
    "end": "21199"
  },
  {
    "text": "about how we use ray",
    "start": "21199",
    "end": "22640"
  },
  {
    "text": "and any scale to scale up our machine",
    "start": "22640",
    "end": "24960"
  },
  {
    "text": "learning on aerial imagery",
    "start": "24960",
    "end": "28560"
  },
  {
    "text": "our species has dedicated a tremendous",
    "start": "28800",
    "end": "31279"
  },
  {
    "text": "amount of",
    "start": "31279",
    "end": "32000"
  },
  {
    "text": "ingenuity and money to resource",
    "start": "32000",
    "end": "34480"
  },
  {
    "text": "extraction",
    "start": "34480",
    "end": "35680"
  },
  {
    "text": "and as uh as a consequence the rate of",
    "start": "35680",
    "end": "39120"
  },
  {
    "text": "ecological destruction we're seeing",
    "start": "39120",
    "end": "40640"
  },
  {
    "text": "today has never before been",
    "start": "40640",
    "end": "42239"
  },
  {
    "text": "seen in our history this as",
    "start": "42239",
    "end": "45680"
  },
  {
    "text": "as well as climate change has resulted",
    "start": "45680",
    "end": "48719"
  },
  {
    "text": "in two billion hectares of degraded land",
    "start": "48719",
    "end": "51920"
  },
  {
    "text": "that in turn has caused a bunch of",
    "start": "51920",
    "end": "54399"
  },
  {
    "text": "cascading effects such as",
    "start": "54399",
    "end": "56000"
  },
  {
    "text": "political upheaval wildfires and mass",
    "start": "56000",
    "end": "59600"
  },
  {
    "text": "extinction events",
    "start": "59600",
    "end": "61920"
  },
  {
    "text": "in contrast the ecological restoration",
    "start": "61920",
    "end": "65280"
  },
  {
    "text": "rates are",
    "start": "65280",
    "end": "66000"
  },
  {
    "text": "nowhere near the same and the",
    "start": "66000",
    "end": "68560"
  },
  {
    "text": "traditional methods of ecological",
    "start": "68560",
    "end": "70320"
  },
  {
    "text": "restoration do not scale",
    "start": "70320",
    "end": "72240"
  },
  {
    "text": "so to give you a few examples for",
    "start": "72240",
    "end": "74960"
  },
  {
    "text": "ecosystem analytics",
    "start": "74960",
    "end": "76640"
  },
  {
    "text": "unfortunately there are some things that",
    "start": "76640",
    "end": "78880"
  },
  {
    "text": "satellite imagery",
    "start": "78880",
    "end": "80000"
  },
  {
    "text": "and plane imagery cannot do at that",
    "start": "80000",
    "end": "82960"
  },
  {
    "text": "resolution",
    "start": "82960",
    "end": "84000"
  },
  {
    "text": "for example you can't look at grass from",
    "start": "84000",
    "end": "86640"
  },
  {
    "text": "plain imagery",
    "start": "86640",
    "end": "87520"
  },
  {
    "text": "and tell if it's one species or another",
    "start": "87520",
    "end": "91040"
  },
  {
    "text": "so for that you really need um either",
    "start": "91040",
    "end": "93759"
  },
  {
    "text": "ultra high resolution imagery",
    "start": "93759",
    "end": "95360"
  },
  {
    "text": "or people on the ground another uh",
    "start": "95360",
    "end": "99360"
  },
  {
    "text": "example is invasive weed monitoring",
    "start": "99360",
    "end": "102000"
  },
  {
    "text": "typically this is done",
    "start": "102000",
    "end": "103200"
  },
  {
    "text": "with a person driving around on a truck",
    "start": "103200",
    "end": "104960"
  },
  {
    "text": "and trying to spot weeds",
    "start": "104960",
    "end": "106720"
  },
  {
    "text": "and this is very error-prone it's not",
    "start": "106720",
    "end": "109200"
  },
  {
    "text": "comprehensive",
    "start": "109200",
    "end": "110399"
  },
  {
    "text": "and not ideal the",
    "start": "110399",
    "end": "114000"
  },
  {
    "text": "third thing is ecosystem restoration now",
    "start": "114000",
    "end": "116799"
  },
  {
    "text": "this tends to be very manual and have",
    "start": "116799",
    "end": "118960"
  },
  {
    "text": "little automation or it's optimized for",
    "start": "118960",
    "end": "122159"
  },
  {
    "text": "monoculture",
    "start": "122159",
    "end": "123680"
  },
  {
    "text": "so if you're wondering why we can't just",
    "start": "123680",
    "end": "125040"
  },
  {
    "text": "take tractors out into the wild",
    "start": "125040",
    "end": "127280"
  },
  {
    "text": "they have to tend to be very top-heavy",
    "start": "127280",
    "end": "129599"
  },
  {
    "text": "and they'll flip over if there's a bit",
    "start": "129599",
    "end": "130959"
  },
  {
    "text": "of an incline",
    "start": "130959",
    "end": "132160"
  },
  {
    "text": "and they're typically used for",
    "start": "132160",
    "end": "134000"
  },
  {
    "text": "monoculture",
    "start": "134000",
    "end": "135200"
  },
  {
    "text": "and all of these fail in places like",
    "start": "135200",
    "end": "137840"
  },
  {
    "text": "cliffs",
    "start": "137840",
    "end": "138480"
  },
  {
    "text": "where you just it's not",
    "start": "138480",
    "end": "141840"
  },
  {
    "text": "you can't go with a machine or on foot",
    "start": "141840",
    "end": "144720"
  },
  {
    "text": "so",
    "start": "144720",
    "end": "145360"
  },
  {
    "text": "here's where dendra is coming in to",
    "start": "145360",
    "end": "147200"
  },
  {
    "text": "build scalable ecosystem restoration",
    "start": "147200",
    "end": "150160"
  },
  {
    "text": "and we use a variety of tools we we use",
    "start": "150160",
    "end": "153599"
  },
  {
    "text": "a lot of",
    "start": "153599",
    "end": "154319"
  },
  {
    "text": "drones to do ultra high resolution",
    "start": "154319",
    "end": "157760"
  },
  {
    "text": "mapping at an unprecedented scale we can",
    "start": "157760",
    "end": "160720"
  },
  {
    "text": "then use machine learning to analyze",
    "start": "160720",
    "end": "162560"
  },
  {
    "text": "that imagery and",
    "start": "162560",
    "end": "163680"
  },
  {
    "text": "derive insights and after we could",
    "start": "163680",
    "end": "167120"
  },
  {
    "text": "use other drones that are specialized",
    "start": "167120",
    "end": "170000"
  },
  {
    "text": "for",
    "start": "170000",
    "end": "170800"
  },
  {
    "text": "seating now the advantages of this",
    "start": "170800",
    "end": "174000"
  },
  {
    "text": "is that we're much faster and cheaper",
    "start": "174000",
    "end": "175680"
  },
  {
    "text": "than traditional methods",
    "start": "175680",
    "end": "177120"
  },
  {
    "text": "and we're more robust more targeted",
    "start": "177120",
    "end": "179360"
  },
  {
    "text": "safer",
    "start": "179360",
    "end": "180239"
  },
  {
    "text": "all around we do better than the",
    "start": "180239",
    "end": "182400"
  },
  {
    "text": "traditional methods",
    "start": "182400",
    "end": "184400"
  },
  {
    "text": "now i'm going to quickly gloss over our",
    "start": "184400",
    "end": "187200"
  },
  {
    "text": "suite of products",
    "start": "187200",
    "end": "189200"
  },
  {
    "text": "we do things like biodiversity",
    "start": "189200",
    "end": "190879"
  },
  {
    "text": "assessments and biodiversity report",
    "start": "190879",
    "end": "193120"
  },
  {
    "text": "cards",
    "start": "193120",
    "end": "194000"
  },
  {
    "text": "we can quantify",
    "start": "194000",
    "end": "197040"
  },
  {
    "text": "tree stem density and native species to",
    "start": "197040",
    "end": "199760"
  },
  {
    "text": "to",
    "start": "199760",
    "end": "200159"
  },
  {
    "text": "understand how the re rehabilitation is",
    "start": "200159",
    "end": "202319"
  },
  {
    "text": "going in addition to",
    "start": "202319",
    "end": "204480"
  },
  {
    "text": "finding animals and seeing if there's",
    "start": "204480",
    "end": "206480"
  },
  {
    "text": "certain to repopulate areas that were",
    "start": "206480",
    "end": "208239"
  },
  {
    "text": "blighted before",
    "start": "208239",
    "end": "209680"
  },
  {
    "text": "we find migratory routes to understand",
    "start": "209680",
    "end": "212400"
  },
  {
    "text": "how",
    "start": "212400",
    "end": "212799"
  },
  {
    "text": "animals are are moving around in the",
    "start": "212799",
    "end": "214720"
  },
  {
    "text": "area",
    "start": "214720",
    "end": "216080"
  },
  {
    "text": "and in addition we can also find pests",
    "start": "216080",
    "end": "219519"
  },
  {
    "text": "and weeds",
    "start": "219519",
    "end": "220239"
  },
  {
    "text": "and help our customers prioritize which",
    "start": "220239",
    "end": "222319"
  },
  {
    "text": "areas need interventions",
    "start": "222319",
    "end": "224480"
  },
  {
    "text": "we can find things that are uh",
    "start": "224480",
    "end": "227599"
  },
  {
    "text": "that need to be cleaned up before we can",
    "start": "227599",
    "end": "230159"
  },
  {
    "text": "clean the land",
    "start": "230159",
    "end": "231120"
  },
  {
    "text": "for for ecosystem restoration and",
    "start": "231120",
    "end": "234159"
  },
  {
    "text": "finally",
    "start": "234159",
    "end": "235040"
  },
  {
    "text": "we can monitor erosion and soil health",
    "start": "235040",
    "end": "237840"
  },
  {
    "text": "so we could find areas that",
    "start": "237840",
    "end": "239760"
  },
  {
    "text": "may be dangerous to move on because",
    "start": "239760",
    "end": "242400"
  },
  {
    "text": "they're they're they have an imminent",
    "start": "242400",
    "end": "243840"
  },
  {
    "text": "collapse",
    "start": "243840",
    "end": "244799"
  },
  {
    "text": "we can find places where topsoil is",
    "start": "244799",
    "end": "247280"
  },
  {
    "text": "likely to get washed away or",
    "start": "247280",
    "end": "248920"
  },
  {
    "text": "desertification",
    "start": "248920",
    "end": "250560"
  },
  {
    "text": "and we can prevent things before they",
    "start": "250560",
    "end": "252959"
  },
  {
    "text": "get too",
    "start": "252959",
    "end": "253599"
  },
  {
    "text": "expensive to to treat down the line",
    "start": "253599",
    "end": "256639"
  },
  {
    "text": "and finally we could all do this on a",
    "start": "256639",
    "end": "258320"
  },
  {
    "text": "massive scale a single",
    "start": "258320",
    "end": "259759"
  },
  {
    "text": "drone can in a single day capture 400",
    "start": "259759",
    "end": "262639"
  },
  {
    "text": "soccer fields worth of imagery",
    "start": "262639",
    "end": "265759"
  },
  {
    "text": "and in addition to be able to monitor",
    "start": "265759",
    "end": "268160"
  },
  {
    "text": "these area",
    "start": "268160",
    "end": "268880"
  },
  {
    "text": "areas we could also take action we have",
    "start": "268880",
    "end": "271199"
  },
  {
    "text": "seeding drones that",
    "start": "271199",
    "end": "272479"
  },
  {
    "text": "every single one can deploy two",
    "start": "272479",
    "end": "275520"
  },
  {
    "text": "polar bears in weight worth of seeds in",
    "start": "275520",
    "end": "278479"
  },
  {
    "text": "a single day",
    "start": "278479",
    "end": "279840"
  },
  {
    "text": "these seeds by the way are can be",
    "start": "279840",
    "end": "282160"
  },
  {
    "text": "tailored mixtures of over 50 species",
    "start": "282160",
    "end": "284479"
  },
  {
    "text": "as opposed to monoculture and",
    "start": "284479",
    "end": "288720"
  },
  {
    "text": "a single pilot can fly multiple drones",
    "start": "288720",
    "end": "291280"
  },
  {
    "text": "in a swarm",
    "start": "291280",
    "end": "292080"
  },
  {
    "text": "and 10 of these drones can plant as many",
    "start": "292080",
    "end": "294080"
  },
  {
    "text": "as 300 000 trees in a day",
    "start": "294080",
    "end": "296000"
  },
  {
    "text": "so this is much more than you and i can",
    "start": "296000",
    "end": "298240"
  },
  {
    "text": "hope to plant in a single day",
    "start": "298240",
    "end": "299919"
  },
  {
    "text": "on our own so",
    "start": "299919",
    "end": "303120"
  },
  {
    "text": "taking a step back a little bit about me",
    "start": "303120",
    "end": "304800"
  },
  {
    "text": "i'm a machine learning engineer i'm",
    "start": "304800",
    "end": "306320"
  },
  {
    "text": "dedicated to fighting climate change",
    "start": "306320",
    "end": "308240"
  },
  {
    "text": "and in a past life i was a molecular",
    "start": "308240",
    "end": "310639"
  },
  {
    "text": "biologist",
    "start": "310639",
    "end": "311759"
  },
  {
    "text": "i was the first machine learning hire at",
    "start": "311759",
    "end": "314000"
  },
  {
    "text": "dendra i founded the team and i was",
    "start": "314000",
    "end": "315680"
  },
  {
    "text": "tasked with building out our machine",
    "start": "315680",
    "end": "317280"
  },
  {
    "text": "learning platform",
    "start": "317280",
    "end": "319039"
  },
  {
    "text": "so this is our platform we",
    "start": "319039",
    "end": "323120"
  },
  {
    "text": "have all the usual suspects and as you",
    "start": "323120",
    "end": "325919"
  },
  {
    "text": "can see",
    "start": "325919",
    "end": "327039"
  },
  {
    "text": "rey and any scale the their ecosystem is",
    "start": "327039",
    "end": "330479"
  },
  {
    "text": "pretty",
    "start": "330479",
    "end": "331039"
  },
  {
    "text": "uh big in our in our platform",
    "start": "331039",
    "end": "334080"
  },
  {
    "text": "and this speaks to the fact that it's a",
    "start": "334080",
    "end": "337039"
  },
  {
    "text": "very versatile",
    "start": "337039",
    "end": "338240"
  },
  {
    "text": "platform and i want to emphasize that i",
    "start": "338240",
    "end": "341520"
  },
  {
    "text": "am not a computer scientist or a",
    "start": "341520",
    "end": "344160"
  },
  {
    "text": "distributed systems expert",
    "start": "344160",
    "end": "346080"
  },
  {
    "text": "i do have experience with mapreduce and",
    "start": "346080",
    "end": "347919"
  },
  {
    "text": "pi spark but i never thought that i",
    "start": "347919",
    "end": "349840"
  },
  {
    "text": "would be able to do",
    "start": "349840",
    "end": "351039"
  },
  {
    "text": "all of this stuff in a year given my my",
    "start": "351039",
    "end": "353840"
  },
  {
    "text": "background so ray really helped with",
    "start": "353840",
    "end": "357520"
  },
  {
    "text": "increasing my leverage so to speak so",
    "start": "357520",
    "end": "361360"
  },
  {
    "text": "this also serves as a map of my talk i'm",
    "start": "361360",
    "end": "364160"
  },
  {
    "text": "going to talk about",
    "start": "364160",
    "end": "365199"
  },
  {
    "text": "these different things except for the",
    "start": "365199",
    "end": "366479"
  },
  {
    "text": "future engineering i won't go into that",
    "start": "366479",
    "end": "368479"
  },
  {
    "text": "other than to say we use ray fairly",
    "start": "368479",
    "end": "370160"
  },
  {
    "text": "extensively in our computing",
    "start": "370160",
    "end": "372479"
  },
  {
    "text": "and uh i do think that ray core is",
    "start": "372479",
    "end": "375840"
  },
  {
    "text": "much more pleasurable to use than",
    "start": "375840",
    "end": "378639"
  },
  {
    "text": "python's built-in multi-processing",
    "start": "378639",
    "end": "381360"
  },
  {
    "text": "it's easier to code easier to read and",
    "start": "381360",
    "end": "385120"
  },
  {
    "text": "easier to maintain and it also has the",
    "start": "385120",
    "end": "387919"
  },
  {
    "text": "added benefit that",
    "start": "387919",
    "end": "389199"
  },
  {
    "text": "it is capable of scaling to multiple",
    "start": "389199",
    "end": "392479"
  },
  {
    "text": "machines unlike python's",
    "start": "392479",
    "end": "394400"
  },
  {
    "text": "multi-processing that could only scale",
    "start": "394400",
    "end": "396080"
  },
  {
    "text": "vertically",
    "start": "396080",
    "end": "396800"
  },
  {
    "text": "you could also scale horizontally if",
    "start": "396800",
    "end": "398720"
  },
  {
    "text": "that's something that you need",
    "start": "398720",
    "end": "400800"
  },
  {
    "text": "so i'm going to go ahead and jump into",
    "start": "400800",
    "end": "402800"
  },
  {
    "text": "the",
    "start": "402800",
    "end": "404160"
  },
  {
    "text": "model training part of my talk so when i",
    "start": "404160",
    "end": "406880"
  },
  {
    "text": "first got hired",
    "start": "406880",
    "end": "408000"
  },
  {
    "text": "at dendra i got started on",
    "start": "408000",
    "end": "411759"
  },
  {
    "text": "aws sagemaker and i do like sagemaker if",
    "start": "411759",
    "end": "415599"
  },
  {
    "text": "you need to uh bootstrap from",
    "start": "415599",
    "end": "418880"
  },
  {
    "text": "xero they have a lot of off-the-shelf",
    "start": "418880",
    "end": "422080"
  },
  {
    "text": "templated solutions that you could just",
    "start": "422080",
    "end": "424240"
  },
  {
    "text": "you know hit the ground running with",
    "start": "424240",
    "end": "426319"
  },
  {
    "text": "however for us we had already an",
    "start": "426319",
    "end": "428560"
  },
  {
    "text": "in-house platform and we needed to have",
    "start": "428560",
    "end": "430720"
  },
  {
    "text": "specialized models",
    "start": "430720",
    "end": "432240"
  },
  {
    "text": "and the cookie cutter templates really",
    "start": "432240",
    "end": "434319"
  },
  {
    "text": "weren't flexible enough for us to",
    "start": "434319",
    "end": "436000"
  },
  {
    "text": "use so i was looking i started looking",
    "start": "436000",
    "end": "438639"
  },
  {
    "text": "at alternatives and i found a retune",
    "start": "438639",
    "end": "440639"
  },
  {
    "text": "and i'm glad that i did it was very easy",
    "start": "440639",
    "end": "442800"
  },
  {
    "text": "to adopt",
    "start": "442800",
    "end": "443759"
  },
  {
    "text": "i imported my rate my pi torch code to",
    "start": "443759",
    "end": "446720"
  },
  {
    "text": "ray sgd",
    "start": "446720",
    "end": "447840"
  },
  {
    "text": "fairly simply and what this gives us",
    "start": "447840",
    "end": "451360"
  },
  {
    "text": "is the ability to scale from a single",
    "start": "451360",
    "end": "453840"
  },
  {
    "text": "replica on my local machine",
    "start": "453840",
    "end": "455520"
  },
  {
    "text": "to dozens of gpus on the clouds without",
    "start": "455520",
    "end": "457520"
  },
  {
    "text": "changing any code",
    "start": "457520",
    "end": "458800"
  },
  {
    "text": "so that's that's a big win and",
    "start": "458800",
    "end": "462160"
  },
  {
    "text": "another one is that ray tune in the long",
    "start": "462160",
    "end": "464639"
  },
  {
    "text": "run has saved us lots of money",
    "start": "464639",
    "end": "466800"
  },
  {
    "text": "um due to a few features that it has",
    "start": "466800",
    "end": "470000"
  },
  {
    "text": "so in this image the x-axis is time and",
    "start": "470000",
    "end": "472960"
  },
  {
    "text": "the y-axis",
    "start": "472960",
    "end": "474000"
  },
  {
    "text": "is loss where the higher up this is the",
    "start": "474000",
    "end": "477440"
  },
  {
    "text": "worse",
    "start": "477440",
    "end": "478000"
  },
  {
    "text": "the the performance of the model is and",
    "start": "478000",
    "end": "480800"
  },
  {
    "text": "each one of these different traces is a",
    "start": "480800",
    "end": "482240"
  },
  {
    "text": "different trial with a different",
    "start": "482240",
    "end": "483520"
  },
  {
    "text": "hyperparameter",
    "start": "483520",
    "end": "485280"
  },
  {
    "text": "configuration so one thing that ray tung",
    "start": "485280",
    "end": "488240"
  },
  {
    "text": "does",
    "start": "488240",
    "end": "488639"
  },
  {
    "text": "is it has schedulers that can",
    "start": "488639",
    "end": "490000"
  },
  {
    "text": "aggressively terminate underperforming",
    "start": "490000",
    "end": "491759"
  },
  {
    "text": "trials",
    "start": "491759",
    "end": "492560"
  },
  {
    "text": "instead of letting them train to",
    "start": "492560",
    "end": "494240"
  },
  {
    "text": "completion",
    "start": "494240",
    "end": "495840"
  },
  {
    "text": "and uh one estimate is that if we were",
    "start": "495840",
    "end": "499599"
  },
  {
    "text": "to",
    "start": "499599",
    "end": "500240"
  },
  {
    "text": "have done this same exact hyper",
    "start": "500240",
    "end": "502319"
  },
  {
    "text": "parameter tournament",
    "start": "502319",
    "end": "503599"
  },
  {
    "text": "with without this we would have paid",
    "start": "503599",
    "end": "506639"
  },
  {
    "text": "spent around twenty thousand dollars",
    "start": "506639",
    "end": "508479"
  },
  {
    "text": "instead we spent less than four thousand",
    "start": "508479",
    "end": "510400"
  },
  {
    "text": "dollars",
    "start": "510400",
    "end": "511199"
  },
  {
    "text": "so a major win and these",
    "start": "511199",
    "end": "514399"
  },
  {
    "text": "uh since these are terminated early",
    "start": "514399",
    "end": "518000"
  },
  {
    "text": "it becomes pretty cheap to sample a",
    "start": "518000",
    "end": "520240"
  },
  {
    "text": "larger hyperparameter space",
    "start": "520240",
    "end": "522000"
  },
  {
    "text": "so this is useful if we're training a",
    "start": "522000",
    "end": "523518"
  },
  {
    "text": "new architecture or if we've made",
    "start": "523519",
    "end": "525600"
  },
  {
    "text": "major changes to the model or the the",
    "start": "525600",
    "end": "528240"
  },
  {
    "text": "processing and we want to",
    "start": "528240",
    "end": "530080"
  },
  {
    "text": "try to find it's kind of a global optima",
    "start": "530080",
    "end": "533760"
  },
  {
    "text": "we can afford to sample in a larger",
    "start": "533760",
    "end": "536320"
  },
  {
    "text": "space and then do",
    "start": "536320",
    "end": "537519"
  },
  {
    "text": "a course-defined search using this trial",
    "start": "537519",
    "end": "540640"
  },
  {
    "text": "resuming",
    "start": "540640",
    "end": "541839"
  },
  {
    "text": "so i really like ray tune if you're not",
    "start": "541839",
    "end": "543360"
  },
  {
    "text": "using it i recommend giving it a shot",
    "start": "543360",
    "end": "547440"
  },
  {
    "text": "the second thing that we used ray for",
    "start": "547440",
    "end": "550880"
  },
  {
    "text": "is inference and model serving so our",
    "start": "550880",
    "end": "553680"
  },
  {
    "text": "requirements our",
    "start": "553680",
    "end": "554720"
  },
  {
    "text": "main requirement was scale we wanted a",
    "start": "554720",
    "end": "556800"
  },
  {
    "text": "solution that could scale to hundreds of",
    "start": "556800",
    "end": "558880"
  },
  {
    "text": "millions of images in the future",
    "start": "558880",
    "end": "560720"
  },
  {
    "text": "which we're projecting to hit in just a",
    "start": "560720",
    "end": "563040"
  },
  {
    "text": "few years given our growth rates",
    "start": "563040",
    "end": "565200"
  },
  {
    "text": "and we wanted to be able to split this",
    "start": "565200",
    "end": "567040"
  },
  {
    "text": "work across many workers on",
    "start": "567040",
    "end": "569040"
  },
  {
    "text": "a in a cluster",
    "start": "569040",
    "end": "572240"
  },
  {
    "text": "the second thing we wanted to do was",
    "start": "572240",
    "end": "573600"
  },
  {
    "text": "maximize the gpu utility",
    "start": "573600",
    "end": "575440"
  },
  {
    "text": "across a culture a cluster to",
    "start": "575440",
    "end": "579120"
  },
  {
    "text": "get the most bang for our buck except",
    "start": "579120",
    "end": "581279"
  },
  {
    "text": "essentially",
    "start": "581279",
    "end": "582560"
  },
  {
    "text": "so initially i was having trouble with",
    "start": "582560",
    "end": "585680"
  },
  {
    "text": "network io as a bottleneck so i'm going",
    "start": "585680",
    "end": "587760"
  },
  {
    "text": "to talk to you about how i got around",
    "start": "587760",
    "end": "589200"
  },
  {
    "text": "that and was able to saturate our gpus",
    "start": "589200",
    "end": "592160"
  },
  {
    "text": "so this is a rough sketch of our",
    "start": "592160",
    "end": "594640"
  },
  {
    "text": "inference",
    "start": "594640",
    "end": "595360"
  },
  {
    "text": "pipeline these dotted lines are",
    "start": "595360",
    "end": "598000"
  },
  {
    "text": "different machines",
    "start": "598000",
    "end": "598959"
  },
  {
    "text": "on the cluster and these gray",
    "start": "598959",
    "end": "602000"
  },
  {
    "text": "boxes are ray actors",
    "start": "602000",
    "end": "605519"
  },
  {
    "text": "so briefly we have array actor queue",
    "start": "605519",
    "end": "609519"
  },
  {
    "text": "and this queue has a bunch of images",
    "start": "609519",
    "end": "611600"
  },
  {
    "text": "that we want results for",
    "start": "611600",
    "end": "613120"
  },
  {
    "text": "so we farm out these urls to different",
    "start": "613120",
    "end": "616720"
  },
  {
    "text": "worker nodes and the s3 clients on these",
    "start": "616720",
    "end": "620560"
  },
  {
    "text": "nodes they they fetch images off of s3",
    "start": "620560",
    "end": "624399"
  },
  {
    "text": "those images then get batched and put on",
    "start": "624399",
    "end": "626560"
  },
  {
    "text": "model replicas",
    "start": "626560",
    "end": "627839"
  },
  {
    "text": "and the results of those models get",
    "start": "627839",
    "end": "629600"
  },
  {
    "text": "streamed out to",
    "start": "629600",
    "end": "630880"
  },
  {
    "text": "aws kinesis fire hose for post",
    "start": "630880",
    "end": "633519"
  },
  {
    "text": "processing batching",
    "start": "633519",
    "end": "634800"
  },
  {
    "text": "sharding partitions all that good stuff",
    "start": "634800",
    "end": "637440"
  },
  {
    "text": "and they get saved as par k shards on",
    "start": "637440",
    "end": "639760"
  },
  {
    "text": "s3 so the main thing i want to draw",
    "start": "639760",
    "end": "643360"
  },
  {
    "text": "attention to is how i uh",
    "start": "643360",
    "end": "646399"
  },
  {
    "text": "architected these s3 client actors",
    "start": "646399",
    "end": "649600"
  },
  {
    "text": "basically i had them so that they are",
    "start": "649600",
    "end": "652560"
  },
  {
    "text": "initialized inside",
    "start": "652560",
    "end": "654079"
  },
  {
    "text": "of the ray serve actor as the the serve",
    "start": "654079",
    "end": "657120"
  },
  {
    "text": "actor gets",
    "start": "657120",
    "end": "658480"
  },
  {
    "text": "gets initialized so as these replicas",
    "start": "658480",
    "end": "661120"
  },
  {
    "text": "are created and the cluster is",
    "start": "661120",
    "end": "663040"
  },
  {
    "text": "elastically scaling either up or down",
    "start": "663040",
    "end": "665600"
  },
  {
    "text": "so too are the clients being scaled up",
    "start": "665600",
    "end": "667839"
  },
  {
    "text": "or down",
    "start": "667839",
    "end": "668640"
  },
  {
    "text": "and these clients are co-located with",
    "start": "668640",
    "end": "671360"
  },
  {
    "text": "the model replicas",
    "start": "671360",
    "end": "672800"
  },
  {
    "text": "so that minimizes the amount of traffic",
    "start": "672800",
    "end": "675360"
  },
  {
    "text": "that is crossing",
    "start": "675360",
    "end": "676880"
  },
  {
    "text": "across these workers these clients can",
    "start": "676880",
    "end": "679839"
  },
  {
    "text": "directly serve to the",
    "start": "679839",
    "end": "681120"
  },
  {
    "text": "model replica that is on the same",
    "start": "681120",
    "end": "682720"
  },
  {
    "text": "machine",
    "start": "682720",
    "end": "684560"
  },
  {
    "text": "and so that gives us a scaling of our",
    "start": "684560",
    "end": "687120"
  },
  {
    "text": "clients",
    "start": "687120",
    "end": "687760"
  },
  {
    "text": "with the cluster size and",
    "start": "687760",
    "end": "691360"
  },
  {
    "text": "a second thing that i did was making",
    "start": "691360",
    "end": "693680"
  },
  {
    "text": "these client actors",
    "start": "693680",
    "end": "695680"
  },
  {
    "text": "work with eager evaluation rather than",
    "start": "695680",
    "end": "698079"
  },
  {
    "text": "lazy evaluation",
    "start": "698079",
    "end": "699600"
  },
  {
    "text": "so with lazy evaluation ray basically",
    "start": "699600",
    "end": "702160"
  },
  {
    "text": "doesn't do work until",
    "start": "702160",
    "end": "703680"
  },
  {
    "text": "that work the the result is necessary",
    "start": "703680",
    "end": "706800"
  },
  {
    "text": "and so when i did the first um",
    "start": "706800",
    "end": "710079"
  },
  {
    "text": "version of this what i would see is that",
    "start": "710079",
    "end": "711920"
  },
  {
    "text": "the seat the gpu utility",
    "start": "711920",
    "end": "714000"
  },
  {
    "text": "would spike up while the network utility",
    "start": "714000",
    "end": "716800"
  },
  {
    "text": "would go quiet",
    "start": "716800",
    "end": "718320"
  },
  {
    "text": "once the model would flush out its",
    "start": "718320",
    "end": "720320"
  },
  {
    "text": "results it would request",
    "start": "720320",
    "end": "722000"
  },
  {
    "text": "the images the next batch of images and",
    "start": "722000",
    "end": "725519"
  },
  {
    "text": "only then would the client say okay i",
    "start": "725519",
    "end": "727279"
  },
  {
    "text": "better fetch those off of s3",
    "start": "727279",
    "end": "729519"
  },
  {
    "text": "the the network usage would then spike",
    "start": "729519",
    "end": "732240"
  },
  {
    "text": "up and the model replica would be quiet",
    "start": "732240",
    "end": "734079"
  },
  {
    "text": "while i was waiting for that so",
    "start": "734079",
    "end": "735600"
  },
  {
    "text": "they were alternating between doing work",
    "start": "735600",
    "end": "738560"
  },
  {
    "text": "by",
    "start": "738560",
    "end": "739120"
  },
  {
    "text": "instead making this eager evaluation the",
    "start": "739120",
    "end": "741760"
  },
  {
    "text": "network is constantly in use it's",
    "start": "741760",
    "end": "743360"
  },
  {
    "text": "constantly downloading images whether or",
    "start": "743360",
    "end": "745360"
  },
  {
    "text": "not the model is ready at that point",
    "start": "745360",
    "end": "747760"
  },
  {
    "text": "and so as the model is flushing um",
    "start": "747760",
    "end": "750240"
  },
  {
    "text": "results out",
    "start": "750240",
    "end": "751600"
  },
  {
    "text": "there's images that are ready to the",
    "start": "751600",
    "end": "753279"
  },
  {
    "text": "next batch of images already",
    "start": "753279",
    "end": "755040"
  },
  {
    "text": "so this has made it so that we can use",
    "start": "755040",
    "end": "758000"
  },
  {
    "text": "the most gpu possible and we're",
    "start": "758000",
    "end": "759760"
  },
  {
    "text": "constantly using",
    "start": "759760",
    "end": "760720"
  },
  {
    "text": "our network across the entire cluster",
    "start": "760720",
    "end": "763519"
  },
  {
    "text": "evenly",
    "start": "763519",
    "end": "766079"
  },
  {
    "text": "next i wanted to talk about why we",
    "start": "766480",
    "end": "768560"
  },
  {
    "text": "became any scale customers",
    "start": "768560",
    "end": "771200"
  },
  {
    "text": "there's a few deficiencies in rey",
    "start": "771200",
    "end": "774240"
  },
  {
    "text": "that made it so that we couldn't do the",
    "start": "774240",
    "end": "776399"
  },
  {
    "text": "things that we",
    "start": "776399",
    "end": "777440"
  },
  {
    "text": "i'm going to talk about in the next few",
    "start": "777440",
    "end": "779040"
  },
  {
    "text": "slides so",
    "start": "779040",
    "end": "781040"
  },
  {
    "text": "rey has problems with",
    "start": "781040",
    "end": "784639"
  },
  {
    "text": "programmatic controls of the cluster",
    "start": "784639",
    "end": "786320"
  },
  {
    "text": "namely you have to",
    "start": "786320",
    "end": "787839"
  },
  {
    "text": "use the cli and you could use oso",
    "start": "787839",
    "end": "790399"
  },
  {
    "text": "process call but it's a very clunky way",
    "start": "790399",
    "end": "792399"
  },
  {
    "text": "of",
    "start": "792399",
    "end": "792880"
  },
  {
    "text": "dealing with the clusters and any scale",
    "start": "792880",
    "end": "795600"
  },
  {
    "text": "solved that solves this with our sdk",
    "start": "795600",
    "end": "797680"
  },
  {
    "text": "which makes it really easy and",
    "start": "797680",
    "end": "799920"
  },
  {
    "text": "convenient to",
    "start": "799920",
    "end": "801120"
  },
  {
    "text": "set up clusters check their status",
    "start": "801120",
    "end": "803120"
  },
  {
    "text": "execute things on",
    "start": "803120",
    "end": "804320"
  },
  {
    "text": "shut them down whatever whatever you",
    "start": "804320",
    "end": "805680"
  },
  {
    "text": "want to do with a cluster you can do it",
    "start": "805680",
    "end": "807760"
  },
  {
    "text": "very easily the second thing",
    "start": "807760",
    "end": "811279"
  },
  {
    "text": "is the performance sometimes",
    "start": "811279",
    "end": "814800"
  },
  {
    "text": "uh with ray um you want to be able to",
    "start": "814800",
    "end": "818480"
  },
  {
    "text": "hot start clusters instead of having to",
    "start": "818480",
    "end": "820480"
  },
  {
    "text": "wait",
    "start": "820480",
    "end": "821680"
  },
  {
    "text": "20 30 40 minutes for all the nodes to",
    "start": "821680",
    "end": "824320"
  },
  {
    "text": "run through all the setup steps",
    "start": "824320",
    "end": "826720"
  },
  {
    "text": "so the way we were getting around this",
    "start": "826720",
    "end": "828959"
  },
  {
    "text": "with ray was having a bunch",
    "start": "828959",
    "end": "830480"
  },
  {
    "text": "of uh ec2 nodes that were in the stop",
    "start": "830480",
    "end": "833839"
  },
  {
    "text": "state",
    "start": "833839",
    "end": "834639"
  },
  {
    "text": "and then we could hot start those those",
    "start": "834639",
    "end": "838160"
  },
  {
    "text": "uh instances but we're still being",
    "start": "838160",
    "end": "840240"
  },
  {
    "text": "charged for those and it wasn't",
    "start": "840240",
    "end": "842240"
  },
  {
    "text": "very robust if we if we change the",
    "start": "842240",
    "end": "844320"
  },
  {
    "text": "settings or made major changes to the",
    "start": "844320",
    "end": "845760"
  },
  {
    "text": "repository",
    "start": "845760",
    "end": "846800"
  },
  {
    "text": "we'd have to destroy all their nodes and",
    "start": "846800",
    "end": "849199"
  },
  {
    "text": "start them up again",
    "start": "849199",
    "end": "850959"
  },
  {
    "text": "and rerun the whole setup step all over",
    "start": "850959",
    "end": "853040"
  },
  {
    "text": "again",
    "start": "853040",
    "end": "854639"
  },
  {
    "text": "we also were fixed in size you couldn't",
    "start": "854639",
    "end": "857760"
  },
  {
    "text": "do elastic scaling",
    "start": "857760",
    "end": "859199"
  },
  {
    "text": "with those stop nodes um and as an",
    "start": "859199",
    "end": "862160"
  },
  {
    "text": "alternative we could have",
    "start": "862160",
    "end": "863440"
  },
  {
    "text": "created a continuous deploy deployment",
    "start": "863440",
    "end": "866720"
  },
  {
    "text": "pipeline with docker this should say a",
    "start": "866720",
    "end": "868399"
  },
  {
    "text": "cd pipeline um",
    "start": "868399",
    "end": "870480"
  },
  {
    "text": "but uh instead we saw that with",
    "start": "870480",
    "end": "873839"
  },
  {
    "text": "any scale it does automatic managing of",
    "start": "873839",
    "end": "876560"
  },
  {
    "text": "our",
    "start": "876560",
    "end": "876880"
  },
  {
    "text": "application images and abstracts away",
    "start": "876880",
    "end": "879839"
  },
  {
    "text": "all of the",
    "start": "879839",
    "end": "880480"
  },
  {
    "text": "dockerization and does all the image",
    "start": "880480",
    "end": "882720"
  },
  {
    "text": "management for us",
    "start": "882720",
    "end": "884320"
  },
  {
    "text": "so i'll give you a few ideas of how we",
    "start": "884320",
    "end": "887120"
  },
  {
    "text": "use this",
    "start": "887120",
    "end": "887760"
  },
  {
    "text": "to solve some problems we were having",
    "start": "887760",
    "end": "890959"
  },
  {
    "text": "so one of the problems we were having",
    "start": "890959",
    "end": "893600"
  },
  {
    "text": "was that",
    "start": "893600",
    "end": "894480"
  },
  {
    "text": "our bitbucket ci pipelines did not",
    "start": "894480",
    "end": "897279"
  },
  {
    "text": "support",
    "start": "897279",
    "end": "898240"
  },
  {
    "text": "gpu usage the machines they provision us",
    "start": "898240",
    "end": "901360"
  },
  {
    "text": "only have cpus so we couldn't do things",
    "start": "901360",
    "end": "903920"
  },
  {
    "text": "like test our training and inference",
    "start": "903920",
    "end": "906000"
  },
  {
    "text": "infrastructure and we had a few",
    "start": "906000",
    "end": "907760"
  },
  {
    "text": "incidents where",
    "start": "907760",
    "end": "909279"
  },
  {
    "text": "we had some silent failures introduced",
    "start": "909279",
    "end": "911920"
  },
  {
    "text": "into",
    "start": "911920",
    "end": "912480"
  },
  {
    "text": "our repository and when it was time to",
    "start": "912480",
    "end": "914560"
  },
  {
    "text": "do inference",
    "start": "914560",
    "end": "915680"
  },
  {
    "text": "we couldn't do it so um",
    "start": "915680",
    "end": "919839"
  },
  {
    "text": "and the way that we used to have to to",
    "start": "919839",
    "end": "922720"
  },
  {
    "text": "mitigate this",
    "start": "922720",
    "end": "923600"
  },
  {
    "text": "was we would do all these manual testing",
    "start": "923600",
    "end": "926320"
  },
  {
    "text": "whenever we",
    "start": "926320",
    "end": "927040"
  },
  {
    "text": "had to merge a new pull request into",
    "start": "927040",
    "end": "930800"
  },
  {
    "text": "the master branch and that that wasn't",
    "start": "930800",
    "end": "933279"
  },
  {
    "text": "great",
    "start": "933279",
    "end": "934480"
  },
  {
    "text": "so the goal was to be able to",
    "start": "934480",
    "end": "938399"
  },
  {
    "text": "set up machines with gpus and run these",
    "start": "938399",
    "end": "941600"
  },
  {
    "text": "tests",
    "start": "941600",
    "end": "942480"
  },
  {
    "text": "and do things like sanity checks that",
    "start": "942480",
    "end": "945040"
  },
  {
    "text": "that our model can overfit on a single",
    "start": "945040",
    "end": "946959"
  },
  {
    "text": "image and things like that to give us",
    "start": "946959",
    "end": "948399"
  },
  {
    "text": "confidence that our",
    "start": "948399",
    "end": "949680"
  },
  {
    "text": "code was working correctly so this is",
    "start": "949680",
    "end": "952720"
  },
  {
    "text": "what it looks like",
    "start": "952720",
    "end": "954079"
  },
  {
    "text": "uh when whenever we push to bitbucket",
    "start": "954079",
    "end": "957440"
  },
  {
    "text": "the pipelines would get activated as",
    "start": "957440",
    "end": "959279"
  },
  {
    "text": "usual and",
    "start": "959279",
    "end": "960639"
  },
  {
    "text": "the any scale sdk would create a",
    "start": "960639",
    "end": "964320"
  },
  {
    "text": "app config it'll compile a build and",
    "start": "964320",
    "end": "967440"
  },
  {
    "text": "if that passes then we use any scale to",
    "start": "967440",
    "end": "970480"
  },
  {
    "text": "start",
    "start": "970480",
    "end": "970959"
  },
  {
    "text": "a a session with gpus on them",
    "start": "970959",
    "end": "974240"
  },
  {
    "text": "and run our tests to see if they pass",
    "start": "974240",
    "end": "976000"
  },
  {
    "text": "and then this these results get",
    "start": "976000",
    "end": "978079"
  },
  {
    "text": "propagated back to",
    "start": "978079",
    "end": "980079"
  },
  {
    "text": "bitbuckets ci um",
    "start": "980079",
    "end": "983759"
  },
  {
    "text": "the way this looks like this is uh",
    "start": "983759",
    "end": "985600"
  },
  {
    "text": "bitbucket right here",
    "start": "985600",
    "end": "987120"
  },
  {
    "text": "and when everything is passing and the",
    "start": "987120",
    "end": "989519"
  },
  {
    "text": "tests are passing you get the",
    "start": "989519",
    "end": "991120"
  },
  {
    "text": "the results right here in in bitbucket",
    "start": "991120",
    "end": "994320"
  },
  {
    "text": "and you could see that everything passed",
    "start": "994320",
    "end": "996959"
  },
  {
    "text": "if instead you have failing tests it'll",
    "start": "996959",
    "end": "1000160"
  },
  {
    "text": "tell you right here",
    "start": "1000160",
    "end": "1001120"
  },
  {
    "text": "that it'll give us a link to the",
    "start": "1001120",
    "end": "1004639"
  },
  {
    "text": "to the session and then you go there and",
    "start": "1004639",
    "end": "1006480"
  },
  {
    "text": "you could see all the log outputs",
    "start": "1006480",
    "end": "1008880"
  },
  {
    "text": "you can share that session with your",
    "start": "1008880",
    "end": "1010399"
  },
  {
    "text": "colleagues to do some troubleshooting",
    "start": "1010399",
    "end": "1013519"
  },
  {
    "text": "and similarly if you have a failing",
    "start": "1013519",
    "end": "1016399"
  },
  {
    "text": "build",
    "start": "1016399",
    "end": "1017360"
  },
  {
    "text": "it'll give you a similar image to this i",
    "start": "1017360",
    "end": "1020240"
  },
  {
    "text": "couldn't find an example of this because",
    "start": "1020240",
    "end": "1022320"
  },
  {
    "text": "it's very rare",
    "start": "1022320",
    "end": "1023600"
  },
  {
    "text": "basically it could happen if you make a",
    "start": "1023600",
    "end": "1025678"
  },
  {
    "text": "mistake in your setup steps or if you",
    "start": "1025679",
    "end": "1028319"
  },
  {
    "text": "introduce mistakes into your",
    "start": "1028319",
    "end": "1029600"
  },
  {
    "text": "requirements.txt file",
    "start": "1029600",
    "end": "1031520"
  },
  {
    "text": "um so so this has been great it has made",
    "start": "1031520",
    "end": "1034400"
  },
  {
    "text": "our systems much more robust and",
    "start": "1034400",
    "end": "1036959"
  },
  {
    "text": "prevented any catastrophic failures from",
    "start": "1036959",
    "end": "1039280"
  },
  {
    "text": "happening it could catch them early",
    "start": "1039280",
    "end": "1042720"
  },
  {
    "text": "another thing i want to talk to you is",
    "start": "1042799",
    "end": "1044160"
  },
  {
    "text": "programmatically standing up clusters",
    "start": "1044160",
    "end": "1046240"
  },
  {
    "text": "and running jobs on them",
    "start": "1046240",
    "end": "1047760"
  },
  {
    "text": "so the issue we were having is if we",
    "start": "1047760",
    "end": "1050080"
  },
  {
    "text": "needed say",
    "start": "1050080",
    "end": "1051039"
  },
  {
    "text": "batch inference done on a new mapping",
    "start": "1051039",
    "end": "1053760"
  },
  {
    "text": "job",
    "start": "1053760",
    "end": "1054880"
  },
  {
    "text": "my colleague would message me and say",
    "start": "1054880",
    "end": "1056400"
  },
  {
    "text": "hey we need this and this could be slow",
    "start": "1056400",
    "end": "1058640"
  },
  {
    "text": "you could imagine",
    "start": "1058640",
    "end": "1059360"
  },
  {
    "text": "with different time zones there's a bit",
    "start": "1059360",
    "end": "1062640"
  },
  {
    "text": "of a",
    "start": "1062640",
    "end": "1063200"
  },
  {
    "text": "turnaround time and sometimes clusters",
    "start": "1063200",
    "end": "1065360"
  },
  {
    "text": "would take a long time due to the many",
    "start": "1065360",
    "end": "1066960"
  },
  {
    "text": "setup",
    "start": "1066960",
    "end": "1067600"
  },
  {
    "text": "dependencies that that would go into it",
    "start": "1067600",
    "end": "1070480"
  },
  {
    "text": "so it was tedious slow and error prone",
    "start": "1070480",
    "end": "1073440"
  },
  {
    "text": "and what we wanted was to have all of",
    "start": "1073440",
    "end": "1075520"
  },
  {
    "text": "our different systems",
    "start": "1075520",
    "end": "1077440"
  },
  {
    "text": "able to talk to each other through apis",
    "start": "1077440",
    "end": "1079440"
  },
  {
    "text": "and microservices",
    "start": "1079440",
    "end": "1080720"
  },
  {
    "text": "to keep everything decoupled and make it",
    "start": "1080720",
    "end": "1082480"
  },
  {
    "text": "so that other teams",
    "start": "1082480",
    "end": "1084160"
  },
  {
    "text": "don't really have to understand uh what",
    "start": "1084160",
    "end": "1087200"
  },
  {
    "text": "we're building they could treat it as a",
    "start": "1087200",
    "end": "1088559"
  },
  {
    "text": "black box",
    "start": "1088559",
    "end": "1089280"
  },
  {
    "text": "and just fetch results and not have to",
    "start": "1089280",
    "end": "1091840"
  },
  {
    "text": "understand what we're doing",
    "start": "1091840",
    "end": "1094080"
  },
  {
    "text": "so this is what that looks like it when",
    "start": "1094080",
    "end": "1096640"
  },
  {
    "text": "users are using our platform and say",
    "start": "1096640",
    "end": "1098400"
  },
  {
    "text": "that they want",
    "start": "1098400",
    "end": "1099200"
  },
  {
    "text": "model predictions for a certain area",
    "start": "1099200",
    "end": "1102000"
  },
  {
    "text": "given a certain type of model",
    "start": "1102000",
    "end": "1104000"
  },
  {
    "text": "they can go the the",
    "start": "1104000",
    "end": "1107120"
  },
  {
    "text": "the system itself will talk to the",
    "start": "1107120",
    "end": "1109039"
  },
  {
    "text": "microservice and",
    "start": "1109039",
    "end": "1110400"
  },
  {
    "text": "request those results the microservice",
    "start": "1110400",
    "end": "1113280"
  },
  {
    "text": "then",
    "start": "1113280",
    "end": "1113679"
  },
  {
    "text": "will go to any scale and fetch a",
    "start": "1113679",
    "end": "1115760"
  },
  {
    "text": "pre-built app config",
    "start": "1115760",
    "end": "1117679"
  },
  {
    "text": "that was passing from our production",
    "start": "1117679",
    "end": "1120320"
  },
  {
    "text": "branch",
    "start": "1120320",
    "end": "1121200"
  },
  {
    "text": "and then they could using that pre-built",
    "start": "1121200",
    "end": "1123039"
  },
  {
    "text": "config it could hot start in just",
    "start": "1123039",
    "end": "1124960"
  },
  {
    "text": "a couple of minutes a session and hit",
    "start": "1124960",
    "end": "1127039"
  },
  {
    "text": "the ground running",
    "start": "1127039",
    "end": "1128160"
  },
  {
    "text": "instead of having to go through all the",
    "start": "1128160",
    "end": "1130000"
  },
  {
    "text": "setup steps on each node individually",
    "start": "1130000",
    "end": "1132880"
  },
  {
    "text": "and then inference works like i showed",
    "start": "1132880",
    "end": "1135039"
  },
  {
    "text": "you before saves everything on s3",
    "start": "1135039",
    "end": "1137360"
  },
  {
    "text": "and a web hook alert can then go talk to",
    "start": "1137360",
    "end": "1140080"
  },
  {
    "text": "this",
    "start": "1140080",
    "end": "1141679"
  },
  {
    "text": "system and say hey the results are ready",
    "start": "1141679",
    "end": "1143600"
  },
  {
    "text": "and that system can load them",
    "start": "1143600",
    "end": "1145039"
  },
  {
    "text": "right in there so this takes a human out",
    "start": "1145039",
    "end": "1147679"
  },
  {
    "text": "of the",
    "start": "1147679",
    "end": "1148400"
  },
  {
    "text": "loop and automates uh uh this this",
    "start": "1148400",
    "end": "1151440"
  },
  {
    "text": "tedious task so this is something that",
    "start": "1151440",
    "end": "1152960"
  },
  {
    "text": "we're",
    "start": "1152960",
    "end": "1153679"
  },
  {
    "text": "uh hoping to get ready for array 1.4",
    "start": "1153679",
    "end": "1156400"
  },
  {
    "text": "release",
    "start": "1156400",
    "end": "1157520"
  },
  {
    "text": "so in conclusion ray tune has enabled us",
    "start": "1157520",
    "end": "1161360"
  },
  {
    "text": "to",
    "start": "1161360",
    "end": "1161679"
  },
  {
    "text": "conduct hyper primer hyper parameter",
    "start": "1161679",
    "end": "1164080"
  },
  {
    "text": "tournaments at scale",
    "start": "1164080",
    "end": "1165520"
  },
  {
    "text": "we're able to search larger spaces",
    "start": "1165520",
    "end": "1167600"
  },
  {
    "text": "because we can terminate the trials that",
    "start": "1167600",
    "end": "1169679"
  },
  {
    "text": "aren't useful",
    "start": "1169679",
    "end": "1170960"
  },
  {
    "text": "and ray serve has feature-proofed our",
    "start": "1170960",
    "end": "1173760"
  },
  {
    "text": "inference pipelines",
    "start": "1173760",
    "end": "1175120"
  },
  {
    "text": "and we can do any job from 10 000 images",
    "start": "1175120",
    "end": "1178400"
  },
  {
    "text": "to 100 million images without having to",
    "start": "1178400",
    "end": "1180880"
  },
  {
    "text": "change our our underlying infrastructure",
    "start": "1180880",
    "end": "1184400"
  },
  {
    "text": "now any scale sdk has been very nice it",
    "start": "1184400",
    "end": "1187039"
  },
  {
    "text": "has",
    "start": "1187039",
    "end": "1187679"
  },
  {
    "text": "enabled us to test mission critical",
    "start": "1187679",
    "end": "1190320"
  },
  {
    "text": "pieces of our platform",
    "start": "1190320",
    "end": "1192320"
  },
  {
    "text": "and prevent or find failures before they",
    "start": "1192320",
    "end": "1195919"
  },
  {
    "text": "become",
    "start": "1195919",
    "end": "1196559"
  },
  {
    "text": "integrated into our production pipelines",
    "start": "1196559",
    "end": "1199600"
  },
  {
    "text": "and finally raycor is very nice",
    "start": "1199600",
    "end": "1202640"
  },
  {
    "text": "i recommend it to everyone even if",
    "start": "1202640",
    "end": "1204960"
  },
  {
    "text": "they're not",
    "start": "1204960",
    "end": "1205679"
  },
  {
    "text": "a machine learning person it's nicer to",
    "start": "1205679",
    "end": "1208400"
  },
  {
    "text": "use",
    "start": "1208400",
    "end": "1208880"
  },
  {
    "text": "than python's multi-processing and can",
    "start": "1208880",
    "end": "1211520"
  },
  {
    "text": "scale out too many machines",
    "start": "1211520",
    "end": "1213200"
  },
  {
    "text": "it's also friendlier i think than pi",
    "start": "1213200",
    "end": "1215679"
  },
  {
    "text": "spark",
    "start": "1215679",
    "end": "1216320"
  },
  {
    "text": "anyone that has worked with pi spark may",
    "start": "1216320",
    "end": "1218240"
  },
  {
    "text": "have experience having to",
    "start": "1218240",
    "end": "1220000"
  },
  {
    "text": "debug jvm stack traces which you know",
    "start": "1220000",
    "end": "1223120"
  },
  {
    "text": "they're a little bit painful",
    "start": "1223120",
    "end": "1224720"
  },
  {
    "text": "ray core is all in python which which is",
    "start": "1224720",
    "end": "1227200"
  },
  {
    "text": "very nice",
    "start": "1227200",
    "end": "1228240"
  },
  {
    "text": "and it uh lets you do horizontal scaling",
    "start": "1228240",
    "end": "1231760"
  },
  {
    "text": "in addition to vertical scaling",
    "start": "1231760",
    "end": "1234720"
  },
  {
    "text": "so that's all i have for everyone today",
    "start": "1234720",
    "end": "1236880"
  },
  {
    "text": "i hope you found this",
    "start": "1236880",
    "end": "1238080"
  },
  {
    "text": "talk helpful and i'd like to give a big",
    "start": "1238080",
    "end": "1240720"
  },
  {
    "text": "shout out to the whole any scale team",
    "start": "1240720",
    "end": "1242320"
  },
  {
    "text": "they've been very wonderful with me",
    "start": "1242320",
    "end": "1244880"
  },
  {
    "text": "always giving me advice on slack and",
    "start": "1244880",
    "end": "1247280"
  },
  {
    "text": "getting me unstuck whenever i have",
    "start": "1247280",
    "end": "1249200"
  },
  {
    "text": "questions",
    "start": "1249200",
    "end": "1249840"
  },
  {
    "text": "so thank you all for all the great work",
    "start": "1249840",
    "end": "1252159"
  },
  {
    "text": "that you do",
    "start": "1252159",
    "end": "1253200"
  },
  {
    "text": "we are on um social media if you want to",
    "start": "1253200",
    "end": "1256720"
  },
  {
    "text": "follow us",
    "start": "1256720",
    "end": "1257440"
  },
  {
    "text": "and here's our website and i'm happy to",
    "start": "1257440",
    "end": "1259600"
  },
  {
    "text": "take some questions",
    "start": "1259600",
    "end": "1263840"
  }
]
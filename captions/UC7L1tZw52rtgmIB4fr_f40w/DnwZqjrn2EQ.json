[
  {
    "start": "0",
    "end": "59000"
  },
  {
    "text": "[Music]",
    "start": "170",
    "end": "14639"
  },
  {
    "text": "hi everyone um it's my honor to be here to give you a talk about our recent work",
    "start": "14639",
    "end": "21520"
  },
  {
    "text": "martial right accelerating large-scale tensor and data frame workloads i'm chris ching now let me introduce",
    "start": "21520",
    "end": "29199"
  },
  {
    "text": "myself i'm a senior software engineer at alibaba cloud i'm now focused focusing on mars as core",
    "start": "29199",
    "end": "36000"
  },
  {
    "text": "developer and architect uh before that i developed a framework named the pyodps",
    "start": "36000",
    "end": "42000"
  },
  {
    "text": "which supports like syntax that you can write the data frame things and under the hood",
    "start": "42000",
    "end": "48879"
  },
  {
    "text": "uh the data framework operations will be translated into sql to run the big data platforms and the databases",
    "start": "48879",
    "end": "56480"
  },
  {
    "text": "including the postgresql and mysql so let's talk about the mars",
    "start": "56480",
    "end": "62160"
  },
  {
    "start": "59000",
    "end": "234000"
  },
  {
    "text": "so i would i need to talk about the workloads that we have uh inside the company uh first",
    "start": "62160",
    "end": "69680"
  },
  {
    "text": "we'll talk about the tensor workloads the first uh important workload is the knowledge",
    "start": "69680",
    "end": "75280"
  },
  {
    "text": "graph we know that knowledge graph can be uh can be encoded as the sparse tensor and",
    "start": "75280",
    "end": "83759"
  },
  {
    "text": "the user's often apply quite large uh tensor operations like matrix",
    "start": "83759",
    "end": "91200"
  },
  {
    "text": "multiplication and the margin matrix decomposition and so forth so it's uh the the knowledge graph",
    "start": "91200",
    "end": "100320"
  },
  {
    "text": "is always uh relatively large so the the the the speed",
    "start": "100320",
    "end": "106720"
  },
  {
    "text": "is very crucial for the this work this kind of workload um another workload is the vector search",
    "start": "106720",
    "end": "114320"
  },
  {
    "text": "is widely used in like entity search like picture search or recommendation",
    "start": "114320",
    "end": "119920"
  },
  {
    "text": "system um that any entity can be [Music] described as a uh and vector",
    "start": "119920",
    "end": "127920"
  },
  {
    "text": "vector um so uh we have uh for for example for take the",
    "start": "127920",
    "end": "133440"
  },
  {
    "text": "recommendation system as an example we can describe a user as a vector",
    "start": "133440",
    "end": "139440"
  },
  {
    "text": "and we can describe the item as vector so if we want to recommend some items to the",
    "start": "139440",
    "end": "145280"
  },
  {
    "text": "user we can just uh find the the vectors that is uh that are has the",
    "start": "145280",
    "end": "152800"
  },
  {
    "text": "uh the the distances that it's more the smallest ones um",
    "start": "152800",
    "end": "159680"
  },
  {
    "text": "uh we can use the uh cosine distance or euclidean distance distances that means",
    "start": "159680",
    "end": "166080"
  },
  {
    "text": "uh if the the distance between two vectors is small means that they are very similar",
    "start": "166080",
    "end": "171360"
  },
  {
    "text": "so we can recommend that us but consider this the situation that the",
    "start": "171360",
    "end": "177200"
  },
  {
    "text": "vectors could be very very large maybe billions of letters and",
    "start": "177200",
    "end": "182319"
  },
  {
    "text": "if you uh use the brute force algorithm you know it's quite a quite a",
    "start": "182319",
    "end": "188239"
  },
  {
    "text": "huge um computation because you have to uh compute compute every two pairs",
    "start": "188239",
    "end": "195440"
  },
  {
    "text": "vectors that so it's extremely heavy for the computation another workload is",
    "start": "195440",
    "end": "202720"
  },
  {
    "text": "the data processing processing and post-processing information learning um we know now",
    "start": "202720",
    "end": "208879"
  },
  {
    "text": "the deep learning is super popular now but the pre-processing is inevitable the",
    "start": "208879",
    "end": "215360"
  },
  {
    "text": "pre-processing can be on the normalization uh displaying this try and test",
    "start": "215360",
    "end": "221440"
  },
  {
    "text": "data and so forth and after the machine learning you have to",
    "start": "221440",
    "end": "226640"
  },
  {
    "text": "do some matrix or do some visualization so it's very also",
    "start": "226640",
    "end": "232319"
  },
  {
    "text": "important uh for data frame workloads we have some kind",
    "start": "232319",
    "end": "239519"
  },
  {
    "start": "234000",
    "end": "320000"
  },
  {
    "text": "of data exploration here i'm talking about some auto data exploration uh given the",
    "start": "239519",
    "end": "246560"
  },
  {
    "text": "large data frame the user wants to know if the there is any missing data in the for the",
    "start": "246560",
    "end": "252720"
  },
  {
    "text": "columns or um the distributions for of uh the columns in the data frame and",
    "start": "252720",
    "end": "259840"
  },
  {
    "text": "so forth so the user always want to do some other automatic data exploration and",
    "start": "259840",
    "end": "267040"
  },
  {
    "text": "there's always a slice a few some slices of the data",
    "start": "267040",
    "end": "272240"
  },
  {
    "text": "so they they must make sure that just the even the data is large the",
    "start": "272240",
    "end": "278560"
  },
  {
    "text": "the slice of the data frame can be affected very very quickly so that they can just do",
    "start": "278560",
    "end": "284240"
  },
  {
    "text": "some uh check some about the data",
    "start": "284240",
    "end": "289759"
  },
  {
    "text": "another one is very very popular for the data cleaning you you",
    "start": "290479",
    "end": "295919"
  },
  {
    "text": "need to remove some corrupted data or there's some missing value and so forth",
    "start": "295919",
    "end": "302560"
  },
  {
    "text": "the users also analyze the data they do some aggregations to some group lines",
    "start": "302800",
    "end": "308400"
  },
  {
    "text": "so forth the last one is visceralization the data will use maple leaf",
    "start": "308400",
    "end": "313440"
  },
  {
    "text": "seaborn or do some interactive uh visualization like broly or volcano",
    "start": "313440",
    "end": "319440"
  },
  {
    "text": "so forth so in the past the user are very familiar with the traditional data",
    "start": "319440",
    "end": "326000"
  },
  {
    "start": "320000",
    "end": "481000"
  },
  {
    "text": "science tools the data science tools can work perfectly on their laptop like numpy and",
    "start": "326000",
    "end": "334160"
  },
  {
    "text": "the user can manipulate the nd array and sci-fi is",
    "start": "334160",
    "end": "340880"
  },
  {
    "text": "another one a sci-fi can user can use somebody for some scientific computing and the penis is",
    "start": "340880",
    "end": "348479"
  },
  {
    "text": "also important panel says user can use panels to analyze the data",
    "start": "348479",
    "end": "355039"
  },
  {
    "text": "and the last one is secular secularity is a super popular machine learning platform the user can do some",
    "start": "355039",
    "end": "362479"
  },
  {
    "text": "traditional machine learning and the pre-processing post-processing and so forth",
    "start": "362479",
    "end": "368720"
  },
  {
    "text": "so the traditional data science tools is very popular they are used by",
    "start": "368720",
    "end": "375280"
  },
  {
    "text": "millions of people and they they can fit for not so large data uh you know the",
    "start": "375280",
    "end": "382800"
  },
  {
    "text": "data has to be fit into the memory and uh they are super easy to to",
    "start": "382800",
    "end": "390639"
  },
  {
    "text": "run on a laptop like you can just install them via people or contact people",
    "start": "390639",
    "end": "396479"
  },
  {
    "text": "install numpy like so their performance is okay because the underlying code is c or cython or",
    "start": "396479",
    "end": "404639"
  },
  {
    "text": "fortune so the performance is alright but nowadays the the data is getting",
    "start": "404639",
    "end": "411599"
  },
  {
    "text": "larger and larger and for a single data firm there can be",
    "start": "411599",
    "end": "416960"
  },
  {
    "text": "a billions of records and the user don't want to learn something",
    "start": "416960",
    "end": "423039"
  },
  {
    "text": "that they are not familiar i would we think that the user uh just need the familiar apis",
    "start": "423039",
    "end": "430479"
  },
  {
    "text": "so that they can make some a smooth transition so we think the familiar api is very",
    "start": "430479",
    "end": "436319"
  },
  {
    "text": "important um and we have a large cluster",
    "start": "436319",
    "end": "441840"
  },
  {
    "text": "up to thousands of workers and a four single cluster and maybe i'll",
    "start": "441840",
    "end": "447199"
  },
  {
    "text": "have a lot of clusters and for a single task it can use up to",
    "start": "447199",
    "end": "453199"
  },
  {
    "text": "twelve thousand cores and we we must make sure that the user can",
    "start": "453199",
    "end": "460400"
  },
  {
    "text": "set up their environment very super very very easily just like the traditional test science tools so we",
    "start": "460400",
    "end": "467840"
  },
  {
    "text": "developed mars mars has a familiar api for numpy and sci-fi you can use mars",
    "start": "467840",
    "end": "474400"
  },
  {
    "text": "tensor for penis you can use mars data frame for secular smart learn",
    "start": "474400",
    "end": "481919"
  },
  {
    "start": "481000",
    "end": "692000"
  },
  {
    "text": "now we have we can see it from a high level of view i've mentioned the the",
    "start": "481919",
    "end": "488479"
  },
  {
    "text": "fundamental components the mars tensor is actually the distributed numpy and we support various data teleformat",
    "start": "488479",
    "end": "496400"
  },
  {
    "text": "for tensor like hdf or zar or so forth and the mars data frame is actually the",
    "start": "496400",
    "end": "504160"
  },
  {
    "text": "distribute distributed panels and our support also has a support",
    "start": "504160",
    "end": "510160"
  },
  {
    "text": "various data formats as well like uh 4k csv or the databases like my c core",
    "start": "510160",
    "end": "518159"
  },
  {
    "text": "mysql per postgresql even click house the last one is mars remote i allow",
    "start": "518159",
    "end": "526240"
  },
  {
    "text": "users to just distribute their bunch of python functions to run in the cluster it's a little bit",
    "start": "526240",
    "end": "534399"
  },
  {
    "text": "like the right tasks and about that is the machine learning and",
    "start": "534399",
    "end": "541200"
  },
  {
    "text": "integrated libraries mars learning is actually distributed cycler and we have integrated quite a bunch of",
    "start": "541200",
    "end": "548880"
  },
  {
    "text": "popular python libraries for machine learning like tensorflow pytorch extra boost like gpm and so forth",
    "start": "548880",
    "end": "557760"
  },
  {
    "text": "and beneath the the the apis things we can take a look at the internal stuff",
    "start": "557760",
    "end": "566560"
  },
  {
    "text": "we will support various platforms the ray is the most important",
    "start": "566560",
    "end": "572399"
  },
  {
    "text": "and the kubernetes and the young are supported as well",
    "start": "572399",
    "end": "577440"
  },
  {
    "text": "and uh we we actually make a abstraction called uh oscar",
    "start": "577440",
    "end": "584080"
  },
  {
    "text": "it's a lightweight actor framework or mars uh data or mars uh",
    "start": "584080",
    "end": "590240"
  },
  {
    "text": "the runtime is built on the oscar so the oscar provides a",
    "start": "590240",
    "end": "596560"
  },
  {
    "text": "a actor api and uh leveraging leveraging the race",
    "start": "596560",
    "end": "602839"
  },
  {
    "text": "facilities we leverage the race facilities as many as possible so it's quite easy to implement",
    "start": "602839",
    "end": "610959"
  },
  {
    "text": "the oscar based on the array actor api and we use the race serialization the",
    "start": "610959",
    "end": "618720"
  },
  {
    "text": "rpc the object store which enables object spelling um",
    "start": "618720",
    "end": "624320"
  },
  {
    "text": "yeah so the oscar could be very easy to to be implemented on a piece based on",
    "start": "624320",
    "end": "631600"
  },
  {
    "text": "the right but for the kubernetes and the vr we have to",
    "start": "631600",
    "end": "637440"
  },
  {
    "text": "on our own uh the communication is via unix socket if they are on the on",
    "start": "637440",
    "end": "644399"
  },
  {
    "text": "the same machine or the socket if they are across on machines",
    "start": "644399",
    "end": "649920"
  },
  {
    "text": "and we have our own serialization based on the the pico file vertical",
    "start": "649920",
    "end": "657680"
  },
  {
    "text": "um based on the mars actors we uh implement uh we will separate the",
    "start": "658160",
    "end": "665040"
  },
  {
    "text": "mars um the runtime into quite a few different services like uh the session made and",
    "start": "665040",
    "end": "671200"
  },
  {
    "text": "the storage so that we can separate them into different modules and each service has an api and for a service",
    "start": "671200",
    "end": "679680"
  },
  {
    "text": "if they want to call another service they have to use the the api so that we can decouple some",
    "start": "679680",
    "end": "687040"
  },
  {
    "text": "modules to make the implementation mars more clear",
    "start": "687040",
    "end": "693040"
  },
  {
    "start": "692000",
    "end": "751000"
  },
  {
    "text": "now let's look at the api uh the mars tensor is quite quite uh",
    "start": "693200",
    "end": "699360"
  },
  {
    "text": "similar to the nonpine sci-fi take the black scores as the example it's very popular in",
    "start": "699360",
    "end": "707040"
  },
  {
    "text": "the financial area so how about mars tensor what you need",
    "start": "707040",
    "end": "713760"
  },
  {
    "text": "to do is just replace the import uh from the import numpy smp to",
    "start": "713760",
    "end": "720240"
  },
  {
    "text": "the import marks dot tensor smt uh so that's the this the side api",
    "start": "720240",
    "end": "726480"
  },
  {
    "text": "from mars dot tensor dot special importer erf that the functions is just identical",
    "start": "726480",
    "end": "734720"
  },
  {
    "text": "yeah and the another difference is that they have to call the mars dot execute to trigger the",
    "start": "734720",
    "end": "741360"
  },
  {
    "text": "execution that means mars is used by the for the lazy evaluation uh so you have to",
    "start": "741360",
    "end": "749200"
  },
  {
    "text": "execute it if you want to get the result uh mars data frame is pretty pretty",
    "start": "749200",
    "end": "756079"
  },
  {
    "start": "751000",
    "end": "783000"
  },
  {
    "text": "similar um you what you need to is uh from the import panel set as pd to import mars.dataframe",
    "start": "756079",
    "end": "766320"
  },
  {
    "text": "and the plot has done the execute for you",
    "start": "766320",
    "end": "772000"
  },
  {
    "text": "because uh actually if you want to get calculated trigger the execution you have to call",
    "start": "772000",
    "end": "778000"
  },
  {
    "text": "the executive by yourself but plot has done it for you so you don't have to worry about that",
    "start": "778000",
    "end": "784160"
  },
  {
    "text": "margin is pretty dissimilar and uh we came from uh import from",
    "start": "784160",
    "end": "790639"
  },
  {
    "text": "the the secular dot neighbors to mars that learned neighbors and there are the",
    "start": "790639",
    "end": "796320"
  },
  {
    "text": "process almost the same yeah and also the the",
    "start": "796320",
    "end": "802240"
  },
  {
    "text": "can never sense trigger the execution inside it and uh so so does the other neural apis",
    "start": "802240",
    "end": "810240"
  },
  {
    "text": "including the feed predict cannabis and so forth",
    "start": "810240",
    "end": "815360"
  },
  {
    "start": "815000",
    "end": "1672000"
  },
  {
    "text": "so for now the mars tensor data firm learning has implemented the",
    "start": "815360",
    "end": "820800"
  },
  {
    "text": "subset apis of non-pipeline secular but in the long term we hope that we can",
    "start": "820800",
    "end": "828320"
  },
  {
    "text": "uh implement a superset superset is actually our goal",
    "start": "828320",
    "end": "834800"
  },
  {
    "text": "the reasons are um the first some ops are born for distributed but",
    "start": "834800",
    "end": "840240"
  },
  {
    "text": "they are not actually needed for if you are running some code on your laptop",
    "start": "840240",
    "end": "845839"
  },
  {
    "text": "uh for example the map trunk the cartridge cartesian trunk and the map might produce or some",
    "start": "845839",
    "end": "851360"
  },
  {
    "text": "for something let's take the cartesian trunk as an example",
    "start": "851360",
    "end": "857120"
  },
  {
    "text": "sometimes you want to afford a record in the df1 you have to make some",
    "start": "857120",
    "end": "863680"
  },
  {
    "text": "computation over the entire data set of df2 so for pns you have just maybe",
    "start": "863680",
    "end": "871199"
  },
  {
    "text": "you can just apply a function to the dfy and the function you can just deteriorate",
    "start": "871199",
    "end": "876480"
  },
  {
    "text": "over the jf2 or it's not a big deal but consider",
    "start": "876480",
    "end": "881839"
  },
  {
    "text": "the situation that um the the df1 and the df2 for distributed setting a",
    "start": "881839",
    "end": "887120"
  },
  {
    "text": "bunch of workers the the data may be allocated to different workers so you",
    "start": "887120",
    "end": "892399"
  },
  {
    "text": "cannot just for loop or make some protocol or the similar staff so uh what you can",
    "start": "892399",
    "end": "899360"
  },
  {
    "text": "do for mars you you just need writer need to write a function maybe in this",
    "start": "899360",
    "end": "905199"
  },
  {
    "text": "example is completed a process what you need to do is just to process",
    "start": "905199",
    "end": "911680"
  },
  {
    "text": "the the one trunk of the df1 and one trunk of df2 and you can just write this put the same",
    "start": "911680",
    "end": "918000"
  },
  {
    "text": "logic into the function and the mars will make sure that each each trunk of the f2",
    "start": "918000",
    "end": "923839"
  },
  {
    "text": "and a triangle get f1 and df2 will be a chord so it's very",
    "start": "923839",
    "end": "931519"
  },
  {
    "text": "crucial for the the distributed systems if if you are using such apis",
    "start": "931519",
    "end": "939360"
  },
  {
    "text": "and the the second reason is that some ops might run differently according to",
    "start": "939680",
    "end": "945360"
  },
  {
    "text": "different situations maybe the numbers of workers or the data size or the data pattern so there are maybe",
    "start": "945360",
    "end": "953440"
  },
  {
    "text": "various algorithms under the food for the same rp",
    "start": "953440",
    "end": "958639"
  },
  {
    "text": "for example we take the group and the hg as an example if the group keys are relatively small",
    "start": "958639",
    "end": "965279"
  },
  {
    "text": "we can apply the three based algorithms we can do the group igg to each trunk and we concave them",
    "start": "965279",
    "end": "973839"
  },
  {
    "text": "a few trunks and we apply the the group igg and then contact so it will become a",
    "start": "973839",
    "end": "980240"
  },
  {
    "text": "tree tweet it's very efficient when the group keys are very small",
    "start": "980240",
    "end": "986320"
  },
  {
    "text": "but the downside is that if i have many group keys the the the final data",
    "start": "986320",
    "end": "993519"
  },
  {
    "text": "if you still apply the three based out aggregation that the final data will be",
    "start": "993519",
    "end": "999600"
  },
  {
    "text": "super large they can they can uh be too large to fit into the memory so",
    "start": "999600",
    "end": "1006320"
  },
  {
    "text": "uh we may use the shuffle based uh algorithm uh so first then you still apply the",
    "start": "1006320",
    "end": "1012320"
  },
  {
    "text": "group igt to each trunk and you you will just shuffle the data to make sure that the same key will be",
    "start": "1012320",
    "end": "1019199"
  },
  {
    "text": "shuffled to the same worker and they can apply the group iht until then so the the algorithm may",
    "start": "1019199",
    "end": "1027120"
  },
  {
    "text": "be different according to the different situations and the large",
    "start": "1027120",
    "end": "1033438"
  },
  {
    "text": "the last reason is that there are some different algorithms algorithms for",
    "start": "1033439",
    "end": "1039600"
  },
  {
    "text": "machine learning like um you know the cycle learn provides",
    "start": "1039600",
    "end": "1044720"
  },
  {
    "text": "for the nearest neighbors the cycler provides a different algorithms like the brute",
    "start": "1044720",
    "end": "1049840"
  },
  {
    "text": "force that you they will compute each a pair of vectors for the the",
    "start": "1049840",
    "end": "1058080"
  },
  {
    "text": "uh x and y and there are other algorithm rhythms",
    "start": "1058080",
    "end": "1064080"
  },
  {
    "text": "like kdt or pochi but the algorithm is not very",
    "start": "1064080",
    "end": "1069360"
  },
  {
    "text": "um it does not work work well for the distributed setting",
    "start": "1069360",
    "end": "1074480"
  },
  {
    "text": "so we have other algorithms beyond the succulents",
    "start": "1074480",
    "end": "1081440"
  },
  {
    "text": "so here we have the algorithm proxima proximizer library that highly optimize the four kind of",
    "start": "1081440",
    "end": "1089120"
  },
  {
    "text": "nearest neighbors and we we can just compute the nearest neighbors to a large",
    "start": "1089120",
    "end": "1097760"
  },
  {
    "text": "data set like for example we have the 400 million vectors to to search and 400 and",
    "start": "1097760",
    "end": "1105600"
  },
  {
    "text": "400 million vectors to index and the 400 million vectors to search so if you apply the",
    "start": "1105600",
    "end": "1113039"
  },
  {
    "text": "brute force algorithm it's super huge uh computation because you have to",
    "start": "1113039",
    "end": "1118320"
  },
  {
    "text": "do the multiplication of the the the size uh and uh actually we use that",
    "start": "1118320",
    "end": "1125280"
  },
  {
    "text": "approximate algorithm and uh it takes about three and a half hours including the reading and writing the",
    "start": "1125280",
    "end": "1132880"
  },
  {
    "text": "data frame time so and uh um even for",
    "start": "1132880",
    "end": "1138799"
  },
  {
    "text": "the the brute force algorithm it's a four to five times faster than just secular",
    "start": "1138799",
    "end": "1145360"
  },
  {
    "text": "based implementation um if you set the algorithm to brew tomorrow is in each trunk and mars will just",
    "start": "1145360",
    "end": "1152240"
  },
  {
    "text": "apply uh just delegate the the computation to the secular and uh if you",
    "start": "1152240",
    "end": "1160000"
  },
  {
    "text": "specify the proxima as the algorithm is about four to five times faster so that's why we want to",
    "start": "1160000",
    "end": "1168000"
  },
  {
    "text": "build a superset instead of instead of a subset and we have mentioned that",
    "start": "1168000",
    "end": "1176080"
  },
  {
    "text": "mars is kind of lazy evaluation if you do not trigger the execute if you just display a it",
    "start": "1176080",
    "end": "1183120"
  },
  {
    "text": "will they will you will be told that the it's a tensor while the op is and the shape and so",
    "start": "1183120",
    "end": "1189600"
  },
  {
    "text": "forth until you call to execute you you cannot get the result about the",
    "start": "1189600",
    "end": "1194720"
  },
  {
    "text": "mars uh just offer uh eager mode as well you can just specify the remote to true and then each time you",
    "start": "1194720",
    "end": "1202320"
  },
  {
    "text": "display a tensor data from and so forth it would just tell you the result but",
    "start": "1202320",
    "end": "1210159"
  },
  {
    "text": "for a lazy evaluation it has been better performance because we can just",
    "start": "1210159",
    "end": "1216559"
  },
  {
    "text": "fuse the intermediate nodes that the user does not care about and the graph size will be very small",
    "start": "1216559",
    "end": "1224400"
  },
  {
    "text": "and we can do many optimizations just uh like fuse or something to",
    "start": "1224400",
    "end": "1231600"
  },
  {
    "text": "to just to eliminate the the intermediate result and",
    "start": "1231600",
    "end": "1237760"
  },
  {
    "text": "we can schedule it more efficiently because we can just uh um",
    "start": "1237760",
    "end": "1244559"
  },
  {
    "text": "make sure that the intermediate uh node will not occupy too much memory it",
    "start": "1244720",
    "end": "1250960"
  },
  {
    "text": "can save more memory usage and on the other hand the eager mode has",
    "start": "1250960",
    "end": "1257919"
  },
  {
    "text": "worse performance because each mars object has to generate data that the data has to be",
    "start": "1257919",
    "end": "1264480"
  },
  {
    "text": "stored in the cluster so unless the object is",
    "start": "1264480",
    "end": "1269520"
  },
  {
    "text": "uh g-secated on the on the client side then mars will try to let the data in the cluster",
    "start": "1269520",
    "end": "1275280"
  },
  {
    "text": "as well and it's hard to optimize because you don't have pretty much intermediate uh results so",
    "start": "1275280",
    "end": "1282400"
  },
  {
    "text": "you can not do many optimization",
    "start": "1282400",
    "end": "1287440"
  },
  {
    "text": "so is is there any better solution uh the answer is yes we are developing uh different mode",
    "start": "1287440",
    "end": "1294720"
  },
  {
    "text": "uh the different mode does not require the executa as well but uh it would we will try to",
    "start": "1294720",
    "end": "1303039"
  },
  {
    "text": "do the lazy evaluation as much as possible it's still under we will still",
    "start": "1303039",
    "end": "1310960"
  },
  {
    "text": "try to implement this functionality so stay tuned for the functionality and then",
    "start": "1310960",
    "end": "1318960"
  },
  {
    "text": "now i will show how marks and tensor diaphragm scales the the workloads",
    "start": "1318960",
    "end": "1324559"
  },
  {
    "text": "and let's take a example called as an example um we have a bunch",
    "start": "1324559",
    "end": "1331760"
  },
  {
    "text": "of objects uh showed uh uh shown uh the first is uh the operand",
    "start": "1331760",
    "end": "1339039"
  },
  {
    "text": "and we have a title data which is uh the data frame data or the",
    "start": "1339039",
    "end": "1345440"
  },
  {
    "text": "tensor data was through and so forth and we have table that is the data frame or tensor and so",
    "start": "1345440",
    "end": "1351360"
  },
  {
    "text": "forth so we call it the ones it will just create an operand recorder once and it",
    "start": "1351360",
    "end": "1358000"
  },
  {
    "text": "has a tensor data on the client please remember there is no actual computation so far",
    "start": "1358000",
    "end": "1367200"
  },
  {
    "text": "we just created tensor a that it has just a data property that points to the tensor",
    "start": "1367200",
    "end": "1373600"
  },
  {
    "text": "data and the user set some value in the in the tensor so we'll create another operand",
    "start": "1373600",
    "end": "1379919"
  },
  {
    "text": "coordinate index set value and decrease another test data and then we just point to the data of tensor a to",
    "start": "1379919",
    "end": "1388720"
  },
  {
    "text": "the new tensor data so we can just discover that the tensor data is immutable",
    "start": "1388720",
    "end": "1394480"
  },
  {
    "text": "um the immutable is very important for the distributed setting",
    "start": "1394480",
    "end": "1399679"
  },
  {
    "text": "we don't have to care much about the consistency or so forth um so now",
    "start": "1399679",
    "end": "1406240"
  },
  {
    "text": "create another data frame it's pretty the same and the last record the sun",
    "start": "1406240",
    "end": "1412640"
  },
  {
    "text": "we have a series data so when the user triggered the execute",
    "start": "1412640",
    "end": "1420559"
  },
  {
    "text": "the the graph will be uploaded to upload it to the supervisor we'll have a bunch of characters and the",
    "start": "1420559",
    "end": "1427520"
  },
  {
    "text": "cluster like supervisor and the worker and after the graph submitted",
    "start": "1427520",
    "end": "1435600"
  },
  {
    "text": "the type of graph will be optimized into another type of graph title will graph the optimization could",
    "start": "1435600",
    "end": "1441600"
  },
  {
    "text": "be the column pruning and so forth and we'll do",
    "start": "1441600",
    "end": "1447039"
  },
  {
    "text": "a really important operation called the tile is very important in mars",
    "start": "1447039",
    "end": "1453520"
  },
  {
    "text": "yeah we can take an operand as an example basically for an operator we have to",
    "start": "1453520",
    "end": "1460159"
  },
  {
    "text": "implement two functions like the first is the tile it will it will",
    "start": "1460159",
    "end": "1465760"
  },
  {
    "text": "tell the supervisor how to uh tie your tile able into trunks and the second",
    "start": "1465760",
    "end": "1473440"
  },
  {
    "text": "function is x cube we'll talk about it later um yeah um when the tile",
    "start": "1473440",
    "end": "1481279"
  },
  {
    "text": "graph is able to tile we'll just uh it just use the topological order",
    "start": "1481279",
    "end": "1488480"
  },
  {
    "text": "uh to trade over the graph and how each uh upper account will have",
    "start": "1488480",
    "end": "1495919"
  },
  {
    "text": "one's a tensor which has which is which whose shape is 10 by 10 and the trunk size is five so two trunk",
    "start": "1495919",
    "end": "1504080"
  },
  {
    "text": "two trunks on each dimension so the final uh trunks is four and then",
    "start": "1504080",
    "end": "1511200"
  },
  {
    "text": "uh the set value the set value only affects one trunk so we just apply one trunk to and one open",
    "start": "1511200",
    "end": "1518240"
  },
  {
    "text": "to the new to one of the trunks then the created the data frame from tensor",
    "start": "1518240",
    "end": "1525279"
  },
  {
    "text": "and finally the sum will just do the tree",
    "start": "1525279",
    "end": "1530480"
  },
  {
    "text": "aggregation for the user users now the trunk graph is ready and they",
    "start": "1530480",
    "end": "1537279"
  },
  {
    "text": "will be optimized the diffusion or so forth will be applied to get the final tron graph",
    "start": "1537279",
    "end": "1545440"
  },
  {
    "text": "uh maybe the darpans in the line will be fused into one fuse operand and",
    "start": "1545440",
    "end": "1552320"
  },
  {
    "text": "so forth so we have the final trunk result chunk of graphene we'll just schedule",
    "start": "1552320",
    "end": "1557919"
  },
  {
    "text": "the trunk graph to the other workers to to for the distributed running",
    "start": "1557919",
    "end": "1563679"
  },
  {
    "text": "um each operand will be a subtask and the subtask will have the the subset",
    "start": "1563679",
    "end": "1570400"
  },
  {
    "text": "of the the entire trunk graph and the subset will be scheduled to a worker",
    "start": "1570400",
    "end": "1575760"
  },
  {
    "text": "according to a pretty complicated scheduling rules but uh simpler to",
    "start": "1575760",
    "end": "1582880"
  },
  {
    "text": "simplify it there are two crucial rules the first is the depth first uh we we need to",
    "start": "1582880",
    "end": "1590640"
  },
  {
    "text": "schedule uh the nodes that is uh has the um a deeper uh depth that",
    "start": "1590640",
    "end": "1598080"
  },
  {
    "text": "that it can be um pretty much closer to the final result so we can just freeze uh just to free",
    "start": "1598080",
    "end": "1605679"
  },
  {
    "text": "the the intermediate data as soon as possible uh the second",
    "start": "1605679",
    "end": "1610880"
  },
  {
    "text": "rule is the locality of where we we must make sure the data has to uh the operand has to be run on the",
    "start": "1610880",
    "end": "1619039"
  },
  {
    "text": "node that owns the data so because the data transfer between two nodes are",
    "start": "1619039",
    "end": "1626240"
  },
  {
    "text": "too time consuming so we need to uh schedule the calculation pretty much closer to the",
    "start": "1626240",
    "end": "1632320"
  },
  {
    "text": "data so the subset is scheduled to the worker",
    "start": "1632320",
    "end": "1637600"
  },
  {
    "text": "and when it's finished uh yeah we can tell each operand is just executed by",
    "start": "1637600",
    "end": "1645200"
  },
  {
    "text": "the execute function and for the function there are two arguments",
    "start": "1645200",
    "end": "1651200"
  },
  {
    "text": "the first is the data for the inputs and uh so does the offer",
    "start": "1651200",
    "end": "1659519"
  },
  {
    "text": "when a task subtask is finished the sub successor so will be scheduled as well so uh do all",
    "start": "1661039",
    "end": "1667679"
  },
  {
    "text": "the works will run all for the sub tasks if until they are finished",
    "start": "1667679",
    "end": "1674159"
  },
  {
    "start": "1672000",
    "end": "1739000"
  },
  {
    "text": "so we will give a tour of mars on right job first we start a new cluster and",
    "start": "1674159",
    "end": "1682720"
  },
  {
    "text": "inside it we will create a placement group according to the numbers of workers and the cpus",
    "start": "1682720",
    "end": "1688559"
  },
  {
    "text": "and we are creating mars supervisors and workers each of them is consistent several mars",
    "start": "1688559",
    "end": "1694320"
  },
  {
    "text": "actor pools it's the old car park each mars actor worker a pool actor pool will be wrapped in one",
    "start": "1694320",
    "end": "1701520"
  },
  {
    "text": "right actor and we will create more services like",
    "start": "1701520",
    "end": "1706799"
  },
  {
    "text": "the meta task and one series will create a bunch of marks adders each",
    "start": "1706799",
    "end": "1712480"
  },
  {
    "text": "actor will be allocated to one more sector pool and",
    "start": "1712480",
    "end": "1718080"
  },
  {
    "text": "then we'll create a new session and set it as default or connect to the cluster of we have",
    "start": "1718080",
    "end": "1723679"
  },
  {
    "text": "created and at last we'll call the execute the mars task will be",
    "start": "1723679",
    "end": "1730000"
  },
  {
    "text": "submit to the supervisor and when the computation is finished the",
    "start": "1730000",
    "end": "1735200"
  },
  {
    "text": "data will be fetched to the client to display now",
    "start": "1735200",
    "end": "1740480"
  },
  {
    "start": "1739000",
    "end": "1860000"
  },
  {
    "text": "just take a look at the the cluster starter part due to the reason that razip simplifies",
    "start": "1740480",
    "end": "1747600"
  },
  {
    "text": "distributed applications it's pretty easy um yeah here we have two workers to",
    "start": "1747600",
    "end": "1754320"
  },
  {
    "text": "start and each work has two cpus inside it the uh placement group will be",
    "start": "1754320",
    "end": "1760320"
  },
  {
    "text": "great the bundles tells that the service supervisor use one cpu and the first worker is to cpu",
    "start": "1760320",
    "end": "1768159"
  },
  {
    "text": "and second worker to cpu so that's the memory and the mars active pools will be created",
    "start": "1768159",
    "end": "1775600"
  },
  {
    "text": "the first for the the supervisor and the others for for the workers uh each of them is",
    "start": "1775600",
    "end": "1782640"
  },
  {
    "text": "actually one reactor and the mars actor will be created inside one",
    "start": "1782640",
    "end": "1790159"
  },
  {
    "text": "extra pool um by a task on our service like",
    "start": "1790159",
    "end": "1795600"
  },
  {
    "text": "the task service and so that's the the subtask service the subtest will",
    "start": "1795600",
    "end": "1800960"
  },
  {
    "text": "create a bunch of actors on different workers or actor pools the storage service will",
    "start": "1800960",
    "end": "1807200"
  },
  {
    "text": "also create a few actors very smart actors to clarify",
    "start": "1807200",
    "end": "1815360"
  },
  {
    "text": "and the storage service will just use the",
    "start": "1815360",
    "end": "1820880"
  },
  {
    "text": "uh the object store the ray object store that enables object spilling so when the data cannot be fit into the",
    "start": "1820880",
    "end": "1828240"
  },
  {
    "text": "memory the this feeling will try to spill the data that are not used to maybe uh",
    "start": "1828240",
    "end": "1836559"
  },
  {
    "text": "not not used uh recently into the disk and the data transfer can",
    "start": "1836559",
    "end": "1844320"
  },
  {
    "text": "also be handled by the right eye itself we don't have to care much about the data transfer",
    "start": "1844320",
    "end": "1851840"
  },
  {
    "text": "and so that's the reactor core on the mars actor called the mars actually can just become a",
    "start": "1852080",
    "end": "1858559"
  },
  {
    "text": "great obstacle so we need a few more uh works in the",
    "start": "1858559",
    "end": "1865360"
  },
  {
    "start": "1860000",
    "end": "2094000"
  },
  {
    "text": "near future uh the first is the we will try we need to try to",
    "start": "1865360",
    "end": "1870720"
  },
  {
    "text": "uh leverage the ability of ray to make a faster failover so when one worker died for",
    "start": "1870720",
    "end": "1878480"
  },
  {
    "text": "maybe the out of memory of something we can just go over quite quite quickly to by",
    "start": "1878480",
    "end": "1885279"
  },
  {
    "text": "leveraging the ability to write and auto scaling is super important the",
    "start": "1885279",
    "end": "1890840"
  },
  {
    "text": "users does not need to consider don't need to care about how",
    "start": "1890840",
    "end": "1898240"
  },
  {
    "text": "many workers they need we can just just auto scale",
    "start": "1898240",
    "end": "1903840"
  },
  {
    "text": "the clusters according to the data set or something we need algorithm to decide",
    "start": "1903840",
    "end": "1910159"
  },
  {
    "text": "how many workers we need and we we can just leverage the locality",
    "start": "1910159",
    "end": "1918080"
  },
  {
    "text": "where scheduling of ray which is pretty very recently implemented the feature",
    "start": "1918080",
    "end": "1924559"
  },
  {
    "text": "and we can generate a subtask that fuses this is more apps that can leverage this kind of scheduling",
    "start": "1924559",
    "end": "1932799"
  },
  {
    "text": "feature and the mars task can you know in the red cluster they can be other",
    "start": "1932799",
    "end": "1939279"
  },
  {
    "text": "applications not just mars we hope that we can interact with them to to maybe reduce the data transfer",
    "start": "1939279",
    "end": "1947679"
  },
  {
    "text": "cost or something in the future so let's look take a look at the demo",
    "start": "1947679",
    "end": "1953120"
  },
  {
    "text": "here now we start a cluster yeah we just",
    "start": "1953120",
    "end": "1958399"
  },
  {
    "text": "wrapped the the new class function and the user has to know about",
    "start": "1958399",
    "end": "1963679"
  },
  {
    "text": "the the worker noun yeah to to decide how many workers now we will start a worker",
    "start": "1963679",
    "end": "1971279"
  },
  {
    "text": "and it will print the the array dashboard and we can just",
    "start": "1971279",
    "end": "1977600"
  },
  {
    "text": "click the dashboard and",
    "start": "1977600",
    "end": "1981919"
  },
  {
    "text": "yeah um we can see now the actors is zero and we can refresh",
    "start": "1984399",
    "end": "1991039"
  },
  {
    "text": "you you will see a bunch of right actors are created each actor is",
    "start": "1991039",
    "end": "1996559"
  },
  {
    "text": "actually a mars after pool yeah now the the cluster is ready now we can just",
    "start": "1996559",
    "end": "2005279"
  },
  {
    "text": "do some mars computation we created mars tensor from numpy and",
    "start": "2005279",
    "end": "2011360"
  },
  {
    "text": "ray and we create a mars tensor that is relatively large and",
    "start": "2011360",
    "end": "2018720"
  },
  {
    "text": "we can just do some data frame uh computation and okay",
    "start": "2018720",
    "end": "2025760"
  },
  {
    "text": "it's pretty much like the independence itself okay that's all the the demo i want to",
    "start": "2025760",
    "end": "2032720"
  },
  {
    "text": "show so conclusion uh the margin rate is still on the quick development",
    "start": "2032720",
    "end": "2038559"
  },
  {
    "text": "we were doing a lot of work like i have mentioned and with the power the race enable",
    "start": "2038559",
    "end": "2046240"
  },
  {
    "text": "ray enables the margin rate could be not just to separate our projects",
    "start": "2046240",
    "end": "2052240"
  },
  {
    "text": "they can be much better on the master array documents here and",
    "start": "2052240",
    "end": "2059118"
  },
  {
    "text": "you can track this the progress of martian ray uh on mars project",
    "start": "2059119",
    "end": "2066480"
  },
  {
    "text": "and you can try out mars as well you can just prepare install pmrs to install pi mars is actually pretty easy",
    "start": "2066800",
    "end": "2075679"
  },
  {
    "text": "and they don't forget to start our project on the github or just the link is here",
    "start": "2075679",
    "end": "2083599"
  },
  {
    "text": "and the document thank you that's all my talk thank you for your time for listening",
    "start": "2083599",
    "end": "2090320"
  },
  {
    "text": "thank you",
    "start": "2090320",
    "end": "2096000"
  }
]
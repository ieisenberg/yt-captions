[
  {
    "text": "all right thank you very much very happy to be here uh so today what we'd like to tell you guys a little bit is obviously",
    "start": "2800",
    "end": "8480"
  },
  {
    "text": "how Ray helps Uber optimize marketplaces we'll start out by telling you a little bit about what that means and what",
    "start": "8480",
    "end": "14879"
  },
  {
    "text": "exactly we're doing then we'll tell you about how we adopted Ray and how that like how helps our system scale and our",
    "start": "14879",
    "end": "21680"
  },
  {
    "text": "Engineers to be more effective we'll Deep dive a little bit into just one of the applications that we uh migrated",
    "start": "21680",
    "end": "27880"
  },
  {
    "text": "over to Ray uh so the basic problem that we want to talk about is connecting business goals",
    "start": "27880",
    "end": "35640"
  },
  {
    "text": "to Marketplace decisions so I hope a lot of you guys have used the Uber app um so you can probably imagine that a big part",
    "start": "35640",
    "end": "42000"
  },
  {
    "text": "of like what our Tech does is figure out how to set prices for Riders and drivers in the marketplace um but on the other",
    "start": "42000",
    "end": "48680"
  },
  {
    "text": "hand having trips completed through the market is how Uber makes money we also",
    "start": "48680",
    "end": "54600"
  },
  {
    "text": "tell our investors and the public like certain goals we have and so somehow",
    "start": "54600",
    "end": "60440"
  },
  {
    "text": "there needs to be a connection between those two things and that's what we'd like to tell you about uh so",
    "start": "60440",
    "end": "66960"
  },
  {
    "text": "fundamentally I'm just going to sorry the there's a optimization problem that",
    "start": "66960",
    "end": "73040"
  },
  {
    "text": "we're trying to solve which is you know here's a business goal and then we have some things under our control for",
    "start": "73040",
    "end": "79280"
  },
  {
    "text": "different marketplaces a Marketplace might be something like you know the city of San Francisco um and you know",
    "start": "79280",
    "end": "86640"
  },
  {
    "text": "the city of San Francisco is pretty tightly coupled to say Oakland but it's not coupled really to Los Angeles uh and",
    "start": "86640",
    "end": "92920"
  },
  {
    "text": "so we have certain things under our control that we can change and these might be related to pricing or incentives or other pieces of the way",
    "start": "92920",
    "end": "100040"
  },
  {
    "text": "the marketplace operates that affect outcomes in aggregate in the marketplace",
    "start": "100040",
    "end": "105079"
  },
  {
    "text": "so what we want to understand is how to control those okay so what are we doing um we",
    "start": "105079",
    "end": "113079"
  },
  {
    "text": "have basically built an automated allocation engine and and so so there's different aspects of it uh and I'm going",
    "start": "113079",
    "end": "119520"
  },
  {
    "text": "to go into to a little bit of detail about each of them uh we train ml models on the vast amount of u Uber data that",
    "start": "119520",
    "end": "126280"
  },
  {
    "text": "we have on both users and the marketplace we have control variables that we want to maximize we have",
    "start": "126280",
    "end": "132760"
  },
  {
    "text": "constraints that we want to make sure we hit like don't lose money um we also",
    "start": "132760",
    "end": "138200"
  },
  {
    "text": "want to be able to visualize efficiency metrics and we want people to understand like what happens when they change the",
    "start": "138200",
    "end": "145160"
  },
  {
    "text": "inputs uh to our plans uh so I'm going to go and of",
    "start": "145160",
    "end": "150319"
  },
  {
    "text": "course yeah and so all of these steps uh we now use Ray for uh so I want to talk a little bit",
    "start": "150319",
    "end": "156800"
  },
  {
    "text": "about our modeling approach uh so we actually use a two-stage modeling approach uh the first stage is your sort",
    "start": "156800",
    "end": "163720"
  },
  {
    "text": "of standard deep learning MLP uh based model and that allows us to sort of",
    "start": "163720",
    "end": "169000"
  },
  {
    "text": "integrate the sort of large large volume of Highly granular data that we",
    "start": "169000",
    "end": "174040"
  },
  {
    "text": "have and that uses sort of sort of again pieces of modeling that you're probably",
    "start": "174040",
    "end": "179200"
  },
  {
    "text": "familiar with embeddings resnets um Regular fully connected layers uh then what we do is we use an",
    "start": "179200",
    "end": "187519"
  },
  {
    "text": "Adaptive search grid to generate a surrogate model and the purpose of that is a few fold first is uh if you can",
    "start": "187519",
    "end": "195200"
  },
  {
    "text": "imagine that we're changing a few parameters in our model to understand the impact of there's a lot of features",
    "start": "195200",
    "end": "202120"
  },
  {
    "text": "that like in your model predictions don't change like any historical feature so we want to marginalize over those",
    "start": "202120",
    "end": "208200"
  },
  {
    "text": "features in the surrogate model so we don't have to like sort of just keep inferring across them uh second we can",
    "start": "208200",
    "end": "214720"
  },
  {
    "text": "do some things like imposing shape constraints again you can imagine for certain things you might have some",
    "start": "214720",
    "end": "221400"
  },
  {
    "text": "intuition about how the system should behave if you change it uh one a good example is something called like",
    "start": "221400",
    "end": "227280"
  },
  {
    "text": "diminishing marginal returns which is if you spend some money on something you should get hopefully increased value but",
    "start": "227280",
    "end": "233799"
  },
  {
    "text": "the more you spend the less you get and so that's a kind of shape constraint we'd want to apply and the last piece is",
    "start": "233799",
    "end": "239959"
  },
  {
    "text": "we want to be able to ex control sort of like the extrapolation behavior of the system so as we're training obviously we",
    "start": "239959",
    "end": "247040"
  },
  {
    "text": "can only train on the sort of set of parameters that we've observed uh in",
    "start": "247040",
    "end": "252519"
  },
  {
    "text": "reality but we don't want to limit you know our system to only apply those in",
    "start": "252519",
    "end": "258359"
  },
  {
    "text": "the future so we need to be able to allow the system to extrapolate from like sort of what's supported before and",
    "start": "258359",
    "end": "264840"
  },
  {
    "text": "we can again apply these kind of constraints uh in the surrogate model so that we know what happens if we go",
    "start": "264840",
    "end": "271360"
  },
  {
    "text": "further away from what's happened before uh in optimization and we're",
    "start": "271360",
    "end": "276880"
  },
  {
    "text": "going to go a little bit more detail here later uh we use something called alterating Direction method of",
    "start": "276880",
    "end": "282440"
  },
  {
    "text": "multipliers and the reason we me mention it first of all is that it's an algorithm that's designed to be highly",
    "start": "282440",
    "end": "288639"
  },
  {
    "text": "parallelizable and so since we have a very large salale system that we're trying to optimize it's a sort of key",
    "start": "288639",
    "end": "294520"
  },
  {
    "text": "piece of technology for us for those of you guys who know about optimization it's designed to solve non linear uh and",
    "start": "294520",
    "end": "300960"
  },
  {
    "text": "non-convex model uh non-convex problems which is pretty valuable for us um and I",
    "start": "300960",
    "end": "306759"
  },
  {
    "text": "think those other parts I'll talk to in a later slide so I'm going to hand over to Kai",
    "start": "306759",
    "end": "313560"
  },
  {
    "text": "Tren who's going to tell us about how Ray helped us uh thank you Matt and uh I'm going to",
    "start": "313560",
    "end": "320720"
  },
  {
    "text": "talk about how do we adopt the ray into our tax deck so um for us I think there",
    "start": "320720",
    "end": "326440"
  },
  {
    "text": "are three goals that we want to achieve when we apply Ray into Tex Tech the first one of course is the application",
    "start": "326440",
    "end": "332759"
  },
  {
    "text": "we want to make our our application faster and I think that is the key that",
    "start": "332759",
    "end": "337960"
  },
  {
    "text": "Ray want to bring us that we want to make more paral to our functions",
    "start": "337960",
    "end": "343960"
  },
  {
    "text": "applications program in order to uh get us speed up for our applications uh the second one is code",
    "start": "343960",
    "end": "351560"
  },
  {
    "text": "because um when if you are backhand engineer or infrastructure engineer and",
    "start": "351560",
    "end": "356639"
  },
  {
    "text": "you are trying to introduce a new technology or new Library into your tax stack you will find that there may need",
    "start": "356639",
    "end": "363280"
  },
  {
    "text": "some end to endend change to a code base and usually it's very painful and of",
    "start": "363280",
    "end": "368560"
  },
  {
    "text": "course I'm a very lazy guy so I want to like make my life easier so I want to uh",
    "start": "368560",
    "end": "374560"
  },
  {
    "text": "make this code migration cut uh very low so that we can move very fast and",
    "start": "374560",
    "end": "380000"
  },
  {
    "text": "migrate to the new tech and third thing is we care about the users uh and uh as",
    "start": "380000",
    "end": "385479"
  },
  {
    "text": "you may already know wuber is a company moving very fast and we want to make our user our Engineers data scientists to",
    "start": "385479",
    "end": "391680"
  },
  {
    "text": "move very fast so we uh don't want them to wait very long when we deploy new for",
    "start": "391680",
    "end": "397759"
  },
  {
    "text": "example R clusters or uh wait very long time to get the results so we want to uh",
    "start": "397759",
    "end": "403759"
  },
  {
    "text": "make the uh iteration speed much faster so that they they can get the result faster and we also build a lot of tools",
    "start": "403759",
    "end": "411120"
  },
  {
    "text": "that to help our users to um to improve their user",
    "start": "411120",
    "end": "416639"
  },
  {
    "text": "experience and this is a picture screenshot from the rid Dock and believe",
    "start": "416639",
    "end": "422479"
  },
  {
    "text": "many of you have seen this before I would just briefly describe this one so",
    "start": "422479",
    "end": "428280"
  },
  {
    "text": "it uh the ray can be divided into three parts uh the the first part is cloud so it uh for this Cloud part it's just like",
    "start": "428280",
    "end": "435599"
  },
  {
    "text": "providing you a r back end and can contain CPU GPU memory uh dis any kind",
    "start": "435599",
    "end": "441599"
  },
  {
    "text": "of resource you may need to build your own Ray cluster and the second one is",
    "start": "441599",
    "end": "446919"
  },
  {
    "text": "Ray core so Ray core uh obviously maybe uh you have um writeen any Ray function",
    "start": "446919",
    "end": "453960"
  },
  {
    "text": "before so uh it's mainly for providing you with a base Ray functions like Ray",
    "start": "453960",
    "end": "459240"
  },
  {
    "text": "task or Ray actors that can make your program run in parallel and uh the top",
    "start": "459240",
    "end": "465479"
  },
  {
    "text": "layer is Ray AI libraries uh for this layer it will provide you with a very fancy machine learning API from Ray like",
    "start": "465479",
    "end": "473080"
  },
  {
    "text": "Ray train Ray tune uh rayer Ray data and",
    "start": "473080",
    "end": "478120"
  },
  {
    "text": "for us we have done something on each layer so for the first layer we work together with Michelangelo team to build",
    "start": "478120",
    "end": "485199"
  },
  {
    "text": "a right back end and infrastructure on kubernetes and under hood is uh using",
    "start": "485199",
    "end": "490319"
  },
  {
    "text": "kuber Ray and uh for this Uber Michelangelo team is like a platform",
    "start": "490319",
    "end": "495479"
  },
  {
    "text": "team that supporting any Uber related machine learning uh stuff that we want to build so they will support us for",
    "start": "495479",
    "end": "502440"
  },
  {
    "text": "this kind of stuffs and uh for the second layer Ray core uh that's uh the",
    "start": "502440",
    "end": "508000"
  },
  {
    "text": "layer that we utilize the most uh we heavily depending on this recall layer for distributed um parallel",
    "start": "508000",
    "end": "515518"
  },
  {
    "text": "computations because as Matt mentioned um we have a lot of algorithm related to",
    "start": "515519",
    "end": "522240"
  },
  {
    "text": "uh optimization and evaluation and obviously uh any skill didn't provide us",
    "start": "522240",
    "end": "527360"
  },
  {
    "text": "with this kind of apis so we need to uh play with them by ourselves and finally",
    "start": "527360",
    "end": "532920"
  },
  {
    "text": "we achieved five times to 40 per uh times speed Improvement and I will give",
    "start": "532920",
    "end": "538640"
  },
  {
    "text": "you uh a much more Deep dive later and uh for the top layer of course",
    "start": "538640",
    "end": "544120"
  },
  {
    "text": "we recognize that uh Ray train and race serve uh very convenient API to use uh",
    "start": "544120",
    "end": "550079"
  },
  {
    "text": "so we also adopt the ray TR Ray serve into our depl model training and we find that it can um truly improve our model",
    "start": "550079",
    "end": "557480"
  },
  {
    "text": "training and serving um for the speed and before I talk about how do we",
    "start": "557480",
    "end": "565480"
  },
  {
    "text": "adopt the ray uh into our tax tack I want to give you uh a quick uh like",
    "start": "565480",
    "end": "571760"
  },
  {
    "text": "snapshot about what does our application look like before we use Ray so that you can understand the logistic that we",
    "start": "571760",
    "end": "578720"
  },
  {
    "text": "apply Ray and why do we uh apply Ray like that so um we start with data frame",
    "start": "578720",
    "end": "585440"
  },
  {
    "text": "so uh at the left uh top left bottom corner you can see a hdfs and we load a",
    "start": "585440",
    "end": "592760"
  },
  {
    "text": "large a spar data set from this hdfs and uh we will start our application and use",
    "start": "592760",
    "end": "599360"
  },
  {
    "text": "usually it will start with a data pre-processing part which is using py spark and we run this on a spark cluster",
    "start": "599360",
    "end": "606800"
  },
  {
    "text": "U but after uh the data pre-processing part is done um so uh it comes with some",
    "start": "606800",
    "end": "613120"
  },
  {
    "text": "custom application algorithms and usually it's uh nonpar related because",
    "start": "613120",
    "end": "618680"
  },
  {
    "text": "as M Matt mentioned before we have the optimization algorithms or evaluation",
    "start": "618680",
    "end": "624079"
  },
  {
    "text": "algorithms also uh it will be contained in this part and and uh um for for our",
    "start": "624079",
    "end": "629760"
  },
  {
    "text": "mle or data scientist they will come up with different kinds of uh algorithms",
    "start": "629760",
    "end": "634920"
  },
  {
    "text": "using different kind of libraries and for those Library they are always um not",
    "start": "634920",
    "end": "640399"
  },
  {
    "text": "not related to py spark um for example they may use SK learn or uh scipi or um",
    "start": "640399",
    "end": "648320"
  },
  {
    "text": "different kind of mathematic uh libraries with very strange names um so",
    "start": "648320",
    "end": "654320"
  },
  {
    "text": "so in that case um it becomes like a bottom neck for for spark cluster because as you already know that uh for",
    "start": "654320",
    "end": "661519"
  },
  {
    "text": "spark cluster um when you write any spark function for example Pi spark um",
    "start": "661519",
    "end": "668480"
  },
  {
    "text": "data frame operations uh it can run very fast because uh spark can recognize uh",
    "start": "668480",
    "end": "674000"
  },
  {
    "text": "this kind of data frame operation and parallel or make them in parallel on different executors but if you write",
    "start": "674000",
    "end": "681600"
  },
  {
    "text": "something in penis um especially for those customized panis operations uh by",
    "start": "681600",
    "end": "686959"
  },
  {
    "text": "calling this um strange Library um the there will be operation like you",
    "start": "686959",
    "end": "693320"
  },
  {
    "text": "will collect the ppar data frame to the spark drver node only and run those kind",
    "start": "693320",
    "end": "699160"
  },
  {
    "text": "of operation on spark driver node only but uh for all the rest of the uh spark",
    "start": "699160",
    "end": "704639"
  },
  {
    "text": "executor node they were just on their PTO they will do nothing so uh we want to avoid such kind",
    "start": "704639",
    "end": "711600"
  },
  {
    "text": "of uh situation here uh but previously we don't have a solution for this and",
    "start": "711600",
    "end": "717000"
  },
  {
    "text": "later after this uh block which is is custom application algorithm we will convert uh any processed uh data frame",
    "start": "717000",
    "end": "725639"
  },
  {
    "text": "by uh by different kind of libraries and back convert it back to the py spark and",
    "start": "725639",
    "end": "730800"
  },
  {
    "text": "we will continue to do a data post processing part uh and it's do in the P spark and then we um continue to write",
    "start": "730800",
    "end": "739000"
  },
  {
    "text": "the output spark data set back to hdf hdfs so that is the whole process um our",
    "start": "739000",
    "end": "745079"
  },
  {
    "text": "application looked like so how do we change that oh so uh Ju Just in summary",
    "start": "745079",
    "end": "751120"
  },
  {
    "text": "um so uh you can see that for our previous application it is very spark heavy so that's reason why we run that",
    "start": "751120",
    "end": "757800"
  },
  {
    "text": "on a spar cluster um but as you already know that not all the computation can apply Spar patterns especially for uh",
    "start": "757800",
    "end": "765079"
  },
  {
    "text": "the middle one uh middle block which is custom application algorithm and uh as I",
    "start": "765079",
    "end": "771920"
  },
  {
    "text": "said uh for this middle one it's it can just buy uh can just be done by Spar",
    "start": "771920",
    "end": "777760"
  },
  {
    "text": "driver only but for the rest of executor they are not useful so we want to change",
    "start": "777760",
    "end": "783279"
  },
  {
    "text": "such kind of situation so that's the reason why we introduce this kind of architecture here",
    "start": "783279",
    "end": "789240"
  },
  {
    "text": "we use a hybrid execution mode here to support our use case so um so previously",
    "start": "789240",
    "end": "797399"
  },
  {
    "text": "we have uh the the left uh column here which is containing Spar driver plus",
    "start": "797399",
    "end": "803160"
  },
  {
    "text": "Spar executors um and uh actually nothing has changed here but in addition",
    "start": "803160",
    "end": "809120"
  },
  {
    "text": "addition to that we add another uh Ray cluster that is like a external plug-in",
    "start": "809120",
    "end": "815760"
  },
  {
    "text": "cluster to this Spar uh spark cluster so that in that case any kind of spark",
    "start": "815760",
    "end": "822800"
  },
  {
    "text": "computation like data pre-processing or data post processing they will still running on spark cluster only but if we",
    "start": "822800",
    "end": "831000"
  },
  {
    "text": "encounter some um like panis pattern or uh some strange P pattern that cannot be",
    "start": "831000",
    "end": "837000"
  },
  {
    "text": "run on spark um because SP does not support that kind of things but we find that actually Ray can has a kind of",
    "start": "837000",
    "end": "844720"
  },
  {
    "text": "feature that naturally support any kind of uh Python program paralysis so that's",
    "start": "844720",
    "end": "851600"
  },
  {
    "text": "in that case we think about why not just to move all this kind of",
    "start": "851600",
    "end": "856759"
  },
  {
    "text": "um um panis like computations on top of Ray instead of running that in serice in",
    "start": "856759",
    "end": "863720"
  },
  {
    "text": "Spar driver so that is our initial uh motivation to do this and uh so the our",
    "start": "863720",
    "end": "872160"
  },
  {
    "text": "uh program logistic will become like this so uh instead of just running uh",
    "start": "872160",
    "end": "878120"
  },
  {
    "text": "our application on spark only first of all we will have our data pre-processing work running on spark but after um this",
    "start": "878120",
    "end": "887079"
  },
  {
    "text": "pre-processing work is done uh we will like uh move this uh pre-processed data",
    "start": "887079",
    "end": "892639"
  },
  {
    "text": "frame to Ray to do any kind of uh Ray computation and usually it's done uh in",
    "start": "892639",
    "end": "897800"
  },
  {
    "text": "penis and because uh as Matt mentioned uh we are doing the budget allocation",
    "start": "897800",
    "end": "904600"
  },
  {
    "text": "for different cities uh so um we have a very clear granularity to do the paral",
    "start": "904600",
    "end": "910839"
  },
  {
    "text": "paralyzation here usually we divide into um different cities different weeks uh",
    "start": "910839",
    "end": "916759"
  },
  {
    "text": "and we U do a parallel function for each City for each week so that's a logistic",
    "start": "916759",
    "end": "922240"
  },
  {
    "text": "we um do the paralon on Ray and after Ray has done its job we will just um",
    "start": "922240",
    "end": "928399"
  },
  {
    "text": "gather um the result that is generated by Ray and to send it back to the spark cluster",
    "start": "928399",
    "end": "934680"
  },
  {
    "text": "so uh at the steps rate we will summarize the output from Ray and uh uh then we may convert this data frame back",
    "start": "934680",
    "end": "942040"
  },
  {
    "text": "to spark uh data frame or we do some analysis on this data frame and write",
    "start": "942040",
    "end": "947560"
  },
  {
    "text": "the output U Back to hdfs so previously as I mentioned uh we",
    "start": "947560",
    "end": "954639"
  },
  {
    "text": "don't want our uh users um to wait so long and we want to make sure that uh um",
    "start": "954639",
    "end": "961519"
  },
  {
    "text": "our user when they doing their development they can still have a very uh fast iteration speed so we don't want",
    "start": "961519",
    "end": "969160"
  },
  {
    "text": "to make our deployment and launching time for this CL this kind of hybrid",
    "start": "969160",
    "end": "974480"
  },
  {
    "text": "spark plus right clust to be very long and there is another use case that for",
    "start": "974480",
    "end": "979759"
  },
  {
    "text": "our Engineers for example they always may maybe change one line of code or just maybe just change one hyper",
    "start": "979759",
    "end": "986079"
  },
  {
    "text": "parameter and they want to run another test experiment um on our remote cluster",
    "start": "986079",
    "end": "993279"
  },
  {
    "text": "to figure out whether maybe this oneline change or this hyper perit to change can have a positive or negative impact on",
    "start": "993279",
    "end": "1000680"
  },
  {
    "text": "our on our uh application result so in that case um to accelerate accelerate",
    "start": "1000680",
    "end": "1007120"
  },
  {
    "text": "that one we introduce uh a intermediate layer which is uh the cloud storage uh",
    "start": "1007120",
    "end": "1014040"
  },
  {
    "text": "you can't regard this as just a Amazon S3 it's just a a Object Store for",
    "start": "1014040",
    "end": "1019800"
  },
  {
    "text": "storing anything any files here so um so for our previous design I believe that",
    "start": "1019800",
    "end": "1026438"
  },
  {
    "text": "is a kind of General design we just uh merge any application code into our doc",
    "start": "1026439",
    "end": "1033079"
  },
  {
    "text": "image but for generating that doc image it takes a very long time so after our",
    "start": "1033079",
    "end": "1039520"
  },
  {
    "text": "modification of if there is any application code change we will first of all deploy this applica application code",
    "start": "1039520",
    "end": "1047120"
  },
  {
    "text": "into this ASR cloud storage and then we launch uh The Spar cluster and also Ray",
    "start": "1047120",
    "end": "1053280"
  },
  {
    "text": "cluster um and then The Spar cluster and Ray cluster will load the application",
    "start": "1053280",
    "end": "1058640"
  },
  {
    "text": "code from this cloud storage so that uh for our application code it does not",
    "start": "1058640",
    "end": "1063919"
  },
  {
    "text": "need to build inside the dock image it can be like real time deployed and real",
    "start": "1063919",
    "end": "1069720"
  },
  {
    "text": "time be launched and uh we can make sure that our Spar cluster and Ray cluster can have the same uh code version for",
    "start": "1069720",
    "end": "1077159"
  },
  {
    "text": "our application code and and uh as a result we have achieved less than two",
    "start": "1077159",
    "end": "1082280"
  },
  {
    "text": "minutes deploy and launch time so it can save a lot of time for our uh users to",
    "start": "1082280",
    "end": "1088240"
  },
  {
    "text": "testing their jobs and uh there is another issue we",
    "start": "1088240",
    "end": "1093520"
  },
  {
    "text": "encountered when we designed this kind of infrastructure uh that because um as I previous mentioned we will have a ray",
    "start": "1093520",
    "end": "1100280"
  },
  {
    "text": "cluster that it is working as a external server or plug-in cluster to our spot",
    "start": "1100280",
    "end": "1105679"
  },
  {
    "text": "cluster so uh we will have a data a Tas transfer between spark cluster and R",
    "start": "1105679",
    "end": "1111760"
  },
  {
    "text": "cluster and sometimes it can be a bottleneck so if our data size is very",
    "start": "1111760",
    "end": "1117679"
  },
  {
    "text": "low I think it will not be a bottleneck because we can just transfer our functions or variables very fast from",
    "start": "1117679",
    "end": "1124240"
  },
  {
    "text": "between spark and R cluster but uh if the data size is very large then that",
    "start": "1124240",
    "end": "1130799"
  },
  {
    "text": "can be a bottleneck um so in that case uh we uh figure out a solution that is",
    "start": "1130799",
    "end": "1137200"
  },
  {
    "text": "also to add a intermediate layer uh in between and that is called htfs so",
    "start": "1137200",
    "end": "1143080"
  },
  {
    "text": "um so for the um previous design uh if we want to send a data frame large data",
    "start": "1143080",
    "end": "1148360"
  },
  {
    "text": "frame from Spar to Ray that means we need to uh because Ray does not support any uh Pi Spock version data frame so in",
    "start": "1148360",
    "end": "1156320"
  },
  {
    "text": "that case we need to first of all convert the data frame into penes or some data frame format that rate can",
    "start": "1156320",
    "end": "1163320"
  },
  {
    "text": "support and then we will um do the serialization and uh transfer the data",
    "start": "1163320",
    "end": "1168400"
  },
  {
    "text": "frame into a ray cluster and Ray cluster will do this distalization uh which is",
    "start": "1168400",
    "end": "1173760"
  },
  {
    "text": "very complicated but after adding this hdfs intermediate layer we can actually",
    "start": "1173760",
    "end": "1180080"
  },
  {
    "text": "uh directly write the um spark data frame as a paret into uh hdfs and then",
    "start": "1180080",
    "end": "1187360"
  },
  {
    "text": "we can utilize the ray data API to directly load the data from hdfs uh which does not have any like um data",
    "start": "1187360",
    "end": "1195840"
  },
  {
    "text": "Gathering issues or om issue in between so that can make our um uh make our data",
    "start": "1195840",
    "end": "1203360"
  },
  {
    "text": "transfer much more stable than before and we also uh develop a feature uh API",
    "start": "1203360",
    "end": "1209720"
  },
  {
    "text": "that uh help user to select uh what kind of uh data transfer uh method they want",
    "start": "1209720",
    "end": "1216000"
  },
  {
    "text": "to use they can directly use Ray output or directly pass the data frame as a variable inside the ray remote function",
    "start": "1216000",
    "end": "1223480"
  },
  {
    "text": "or they can use uh our API to just to uh uh send up",
    "start": "1223480",
    "end": "1229200"
  },
  {
    "text": "upload the data frame to the hdfs and get that from the r data they just need to um directly select that and we",
    "start": "1229200",
    "end": "1236120"
  },
  {
    "text": "already ready built the API for our users and uh there are some other array",
    "start": "1236120",
    "end": "1242880"
  },
  {
    "text": "backend support that we buildt together with our Uber Michelangelo team the",
    "start": "1242880",
    "end": "1248320"
  },
  {
    "text": "first one is R clust stock killer so um because we uh find that um sometimes R",
    "start": "1248320",
    "end": "1254799"
  },
  {
    "text": "cluster is not killed properly so uh for example uh the Spar cluster is killed",
    "start": "1254799",
    "end": "1259880"
  },
  {
    "text": "but the ray cluster does not have a command to kill it so we will have a monitor to detect whether this Ray",
    "start": "1259880",
    "end": "1266760"
  },
  {
    "text": "cluster is Idle uh or just do nothing like zombie Ray cluster we would just uh",
    "start": "1266760",
    "end": "1272400"
  },
  {
    "text": "monitor that and cure this kind of zombie rate clusters and then we will have uh we also have a feature to uh",
    "start": "1272400",
    "end": "1279640"
  },
  {
    "text": "improve our Ray lock because if you developing on Ray you will sometimes find the the lock um returned by Ray is",
    "start": "1279640",
    "end": "1286760"
  },
  {
    "text": "not very comprehensive or there is just no lock return from Ray for example sometimes R just kill itself",
    "start": "1286760",
    "end": "1294039"
  },
  {
    "text": "by some worker node o issue uh or um during the r cluster in Ray cluster ini",
    "start": "1294039",
    "end": "1302000"
  },
  {
    "text": "initialization uh Ray has some issues but uh uh it just kill itself but didn't",
    "start": "1302000",
    "end": "1307960"
  },
  {
    "text": "reply anything so we Tred to tackle this kind of um situations and give back our",
    "start": "1307960",
    "end": "1314000"
  },
  {
    "text": "user a very clear lock and uh the third one is r matric visualiz and I think",
    "start": "1314000",
    "end": "1319520"
  },
  {
    "text": "that is very straightforward Ray can Ray has its own dashboard which is called Ray dashboard uh and can help you",
    "start": "1319520",
    "end": "1326480"
  },
  {
    "text": "understand CPU GPU and memory usage and we also put those Matrix onto the",
    "start": "1326480",
    "end": "1331520"
  },
  {
    "text": "grafana pages so that uh uh our users can debu this things",
    "start": "1331520",
    "end": "1336640"
  },
  {
    "text": "better and uh the other one is multi-ray CL Ray cluster control um so for this",
    "start": "1336640",
    "end": "1343120"
  },
  {
    "text": "one uh we we develop a kind of parent to children",
    "start": "1343120",
    "end": "1349080"
  },
  {
    "text": "rate cluster control so we initialize a parent rate cluster and this parent rate",
    "start": "1349080",
    "end": "1355000"
  },
  {
    "text": "cluster can in can provision or kill any children R clusters so that is used for",
    "start": "1355000",
    "end": "1360720"
  },
  {
    "text": "our original uh model training so for example um when this uh parent R cluster",
    "start": "1360720",
    "end": "1368080"
  },
  {
    "text": "want to uh train a model for Region C California or region uh NYC um this um",
    "start": "1368080",
    "end": "1377440"
  },
  {
    "text": "parent R classer can just provision a children class uh for the children class",
    "start": "1377440",
    "end": "1383039"
  },
  {
    "text": "one it will train the region CA and the for the children class two it will train",
    "start": "1383039",
    "end": "1389440"
  },
  {
    "text": "the region NC uh and after one region training is done um it will the the",
    "start": "1389440",
    "end": "1394960"
  },
  {
    "text": "parent rare cluster will just directly kill the children rare cluster so that it can save a lot of U GPU and CPU uh",
    "start": "1394960",
    "end": "1401679"
  },
  {
    "text": "resource for us and for the fifth item R TR racer of course we use that for our",
    "start": "1401679",
    "end": "1407640"
  },
  {
    "text": "different model training and serving and for the sixth item we also built a",
    "start": "1407640",
    "end": "1412919"
  },
  {
    "text": "notebook that is containing um this kind of hybri mode Insight so in this",
    "start": "1412919",
    "end": "1418360"
  },
  {
    "text": "notebook we provide a environment that containing both Spar cluster and red cluster uh and our data scientist that",
    "start": "1418360",
    "end": "1425960"
  },
  {
    "text": "mle they can do their experiment on top of this notebook and the good thing about this notebook is um the the",
    "start": "1425960",
    "end": "1433799"
  },
  {
    "text": "environment provided inside this notebook is just as same as our production environment so after they",
    "start": "1433799",
    "end": "1439760"
  },
  {
    "text": "make sure that their code is working inside this notebook um so the the same",
    "start": "1439760",
    "end": "1444799"
  },
  {
    "text": "code will just be working inside our production so it's very convenient we don't need to do any",
    "start": "1444799",
    "end": "1451400"
  },
  {
    "text": "migrations and this is our Benchmark result uh as you can see we have applied",
    "start": "1451400",
    "end": "1457919"
  },
  {
    "text": "uh the right to different kind of applications we uh we apply to the our",
    "start": "1457919",
    "end": "1463520"
  },
  {
    "text": "surrogate model training and also National City level valuation jobs and",
    "start": "1463520",
    "end": "1469760"
  },
  {
    "text": "also we apply to the EDM optimization um so we actually not only apply Ray into",
    "start": "1469760",
    "end": "1477720"
  },
  {
    "text": "ml only we also apply our Ray into optimization area evaluation area and I",
    "start": "1477720",
    "end": "1484679"
  },
  {
    "text": "think that is uh uh the main takeaway uh I want to show today uh is um Ray cannot",
    "start": "1484679",
    "end": "1492279"
  },
  {
    "text": "just be used for machine learning uh and I think that is uh the main topic for",
    "start": "1492279",
    "end": "1497919"
  },
  {
    "text": "this race Summit I attended a lot of presentations but I always heard the",
    "start": "1497919",
    "end": "1503240"
  },
  {
    "text": "topic related to the L or machine learning um the B models um but uh I",
    "start": "1503240",
    "end": "1509080"
  },
  {
    "text": "think uh um the main uh rate uh the main task rate is being Creed is for",
    "start": "1509080",
    "end": "1515080"
  },
  {
    "text": "paralyzation and distribution and uh machine learning is a kind of product a",
    "start": "1515080",
    "end": "1520640"
  },
  {
    "text": "result U built on top of distribution and paralyzation and uh and in addition to",
    "start": "1520640",
    "end": "1526799"
  },
  {
    "text": "that I believe you already paid attention to this big number which is at",
    "start": "1526799",
    "end": "1532039"
  },
  {
    "text": "the right bottom AO up right bottom uh corner so we have done a",
    "start": "1532039",
    "end": "1538320"
  },
  {
    "text": "47.8 times uh Improvement for our optimization algorithm so I will let",
    "start": "1538320",
    "end": "1545279"
  },
  {
    "text": "Matt to introduce you how do we like achieve this kind of",
    "start": "1545279",
    "end": "1551159"
  },
  {
    "text": "improvement all right thanks K Chan so this will be we will show a little bit of math but so this is so this is sort",
    "start": "1551200",
    "end": "1557799"
  },
  {
    "text": "of I'm write is a diagram of like what the admm loop looks like and I'm just going to explain briefly connected to",
    "start": "1557799",
    "end": "1565159"
  },
  {
    "text": "the math so you don't really have to understand this but what I want you to take away is there's like two parts of",
    "start": "1565159",
    "end": "1570559"
  },
  {
    "text": "the optimization problem and one of the parts is this thing F subc which is",
    "start": "1570559",
    "end": "1575799"
  },
  {
    "text": "something which we've split up over in Ark cities and then there's G of Z which doesn't have the C subscript so that's",
    "start": "1575799",
    "end": "1581559"
  },
  {
    "text": "something that applies for the whole problem okay so that tells you that part of the problem is paralyzable and part",
    "start": "1581559",
    "end": "1587640"
  },
  {
    "text": "of the problem is not um and so what we wanted to make",
    "start": "1587640",
    "end": "1592880"
  },
  {
    "text": "use of with Ray obviously is to parallelize the paralyzable bit of the problem and so then the second bit of",
    "start": "1592880",
    "end": "1599320"
  },
  {
    "text": "math is like the second set of equations so for those of you are familiar with optimization there's just like always some like rules that you do to update",
    "start": "1599320",
    "end": "1606760"
  },
  {
    "text": "your variables um and you can see that two of these B and Z have something that",
    "start": "1606760",
    "end": "1612640"
  },
  {
    "text": "says argmin which means we actually have to do another optimization uh and so that's the part",
    "start": "1612640",
    "end": "1618039"
  },
  {
    "text": "which which is like definitely computationally complex and if you do this like sort of in series or in try to",
    "start": "1618039",
    "end": "1624840"
  },
  {
    "text": "do this in a single solution it's very slow uh so what we did is basically",
    "start": "1624840",
    "end": "1630159"
  },
  {
    "text": "broke up that part uh the first one actually BC this argman into per City",
    "start": "1630159",
    "end": "1636600"
  },
  {
    "text": "per week problem Solutions and that is the part that runs",
    "start": "1636600",
    "end": "1641919"
  },
  {
    "text": "on R um and so that allows us to run things in like very parallel fashion then you",
    "start": "1641919",
    "end": "1648760"
  },
  {
    "text": "get those results back in our case luckily Z of K this argument is actually",
    "start": "1648760",
    "end": "1654640"
  },
  {
    "text": "something you can solve with just a formula it's has an analytical solution and obviously the Y subk thing is",
    "start": "1654640",
    "end": "1660760"
  },
  {
    "text": "Trivial um and so I'm going to go to the next one so Ray is how we basically",
    "start": "1660760",
    "end": "1666440"
  },
  {
    "text": "solve you know in our problems we have thousands of like individual problems that we need to solve in every iteration",
    "start": "1666440",
    "end": "1672640"
  },
  {
    "text": "Loop so that's where we use leverage Ray and those can run in parallel and then",
    "start": "1672640",
    "end": "1678200"
  },
  {
    "text": "you know the spark driver as uh Kiton explained is sort of where like the sort of central uh algorithm runs and so we",
    "start": "1678200",
    "end": "1686880"
  },
  {
    "text": "are able to summarize the results from Ray and decide the next step and you know if it's optimal we can stop and if",
    "start": "1686880",
    "end": "1693880"
  },
  {
    "text": "it's not we have to keep looping and so a loop you know a normal problem might take a th000 Loops uh with a th000 city",
    "start": "1693880",
    "end": "1701320"
  },
  {
    "text": "weeks you know if we had to run those in some other way uh would make this sort of problem not sort of practically",
    "start": "1701320",
    "end": "1710519"
  },
  {
    "text": "feasible uh so that thank you all for your attention that's all we have today",
    "start": "1710519",
    "end": "1715960"
  },
  {
    "text": "uh Uber is hiring both for Ray infra and the kinds of problems we talked about uh",
    "start": "1715960",
    "end": "1721080"
  },
  {
    "text": "and I think we have a minute or two for",
    "start": "1721080",
    "end": "1724679"
  },
  {
    "text": "questions here my question is about your the hdfs",
    "start": "1727000",
    "end": "1733760"
  },
  {
    "text": "um for transfered data um when you were saying",
    "start": "1733760",
    "end": "1740039"
  },
  {
    "text": "yeah do do you mean you're uploading to some like storage with the Uber and then",
    "start": "1740519",
    "end": "1745600"
  },
  {
    "text": "just pass and then read it back to reverse way if so then how do you",
    "start": "1745600",
    "end": "1753000"
  },
  {
    "text": "manage this data because just use it once and then keep on the drive",
    "start": "1753000",
    "end": "1760360"
  },
  {
    "text": "forever yeah so the the qu the question is basically is the H htfs piece uh just",
    "start": "1760360",
    "end": "1767039"
  },
  {
    "text": "like loading it like saving it somewhere in Uber on an hdfs cluster and then if so how we manage that K do you want to",
    "start": "1767039",
    "end": "1773240"
  },
  {
    "text": "take it yes so um for those data frame or paret files that it just need to be",
    "start": "1773240",
    "end": "1779960"
  },
  {
    "text": "use for once we would just store that into a temporary uh directory and it will be cleaned",
    "start": "1779960",
    "end": "1786320"
  },
  {
    "text": "periodically so you have a TT yes we have a TTR I think uh for those data",
    "start": "1786320",
    "end": "1791679"
  },
  {
    "text": "frame just use for maybe once it would just have a three days TTL but if you need to use it multiple times it will",
    "start": "1791679",
    "end": "1797919"
  },
  {
    "text": "have have a long longer TTL you guys like explor removing spark",
    "start": "1797919",
    "end": "1805360"
  },
  {
    "text": "from",
    "start": "1805360",
    "end": "1807760"
  },
  {
    "text": "the so um is your question related to like can we just directly use Ray and",
    "start": "1813320",
    "end": "1819720"
  },
  {
    "text": "deprecate Spark oh so for for us because we mentioned that we are heavily",
    "start": "1819720",
    "end": "1824960"
  },
  {
    "text": "depending on uh spark data frame operations uh so um and rate has a",
    "start": "1824960",
    "end": "1830159"
  },
  {
    "text": "shortcoming that it does not naturally supportting py spark data frame operations so if we want to like fully",
    "start": "1830159",
    "end": "1837760"
  },
  {
    "text": "decate uh spark and just use Ray that means we need to like convert all this",
    "start": "1837760",
    "end": "1842880"
  },
  {
    "text": "data pre-processing spark um algorithms or postprocessing spark algorithm into",
    "start": "1842880",
    "end": "1848200"
  },
  {
    "text": "maybe panis like or some pattern that can be supported by Ray but this kind of",
    "start": "1848200",
    "end": "1853679"
  },
  {
    "text": "migration work will be huge because we have a lot of AR that is previously",
    "start": "1853679",
    "end": "1858840"
  },
  {
    "text": "writing in uh P spark should we take one",
    "start": "1858840",
    "end": "1866559"
  },
  {
    "text": "more yeah so uh IM that like the application code is uped to3 and by the",
    "start": "1866559",
    "end": "1874559"
  },
  {
    "text": "cler or cluster so what if like this application has different type of like Library dependencies how do you manage",
    "start": "1874559",
    "end": "1883240"
  },
  {
    "text": "those oh so for now we just make sure that uh our spark cluster and Ray",
    "start": "1883360",
    "end": "1889120"
  },
  {
    "text": "cluster having the same dependencies so we make sure that all the dependencies",
    "start": "1889120",
    "end": "1894200"
  },
  {
    "text": "that are required by Ray or spark are just pre-installing in one doc",
    "start": "1894200",
    "end": "1900679"
  },
  {
    "text": "image all right thanks everyone we happy to take uh questions or talk uh on the",
    "start": "1901880",
    "end": "1907120"
  },
  {
    "text": "side",
    "start": "1907120",
    "end": "1910120"
  }
]
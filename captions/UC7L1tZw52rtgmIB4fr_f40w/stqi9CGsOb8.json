[
  {
    "text": "right now uh so my name is Adam brindell I'm the lead instructor with any scales training team I'm super excited to have",
    "start": "120",
    "end": "8200"
  },
  {
    "text": "a chance to talk to everyone here today uh and what we're going to do is we've got like I said we've got one hour uh",
    "start": "8200",
    "end": "14679"
  },
  {
    "text": "we're going to spend the first uh little trunk of time maybe 15 minutes uh",
    "start": "14679",
    "end": "19760"
  },
  {
    "text": "something like that maybe a little bit more um talking about uh Ray and any",
    "start": "19760",
    "end": "25279"
  },
  {
    "text": "scale kind of where did any scale come from why why is it",
    "start": "25279",
    "end": "30880"
  },
  {
    "text": "um critical infrastructure and a critical product right now where does Reay the open source project fit in to",
    "start": "30880",
    "end": "38520"
  },
  {
    "text": "the landscape of AI development engineering and what is the relationship",
    "start": "38520",
    "end": "44039"
  },
  {
    "text": "between Ray and any scale uh then we're going to dive into kind of a live uh actual uh kind of",
    "start": "44039",
    "end": "51640"
  },
  {
    "text": "coding example uh so I'll switch away from the slides and we'll jump right into the any scale product itself uh",
    "start": "51640",
    "end": "59120"
  },
  {
    "text": "into a host notebook UI and we'll talk more about um the ray system and we'll",
    "start": "59120",
    "end": "66400"
  },
  {
    "text": "look at implementing uh we'll look at implementing uh some basic use cases",
    "start": "66400",
    "end": "73360"
  },
  {
    "text": "using core Ray AI Library apis uh and for the folks that stick",
    "start": "73360",
    "end": "79280"
  },
  {
    "text": "around to the very end we've actually got a uh kind of a bonus a deep discount",
    "start": "79280",
    "end": "85360"
  },
  {
    "text": "on a more extensive uh instructor-led training that will be do doing in April",
    "start": "85360",
    "end": "90920"
  },
  {
    "text": "so if uh you or anyone on your team or in your firm uh wants to go even deeper",
    "start": "90920",
    "end": "97320"
  },
  {
    "text": "on Reay in any scale there'll be a chance to do that with a huge discount so let's Jump Right In Here uh we've got",
    "start": "97320",
    "end": "106240"
  },
  {
    "text": "the platform and let's see we've already talked a little bit about this agenda so",
    "start": "106240",
    "end": "114840"
  },
  {
    "text": "intro to Ray AI complexity wall and Ray so that that's a way of thinking about",
    "start": "114840",
    "end": "121159"
  },
  {
    "text": "one of the problems that N scale and Ray solve so we'll talk about that a little",
    "start": "121159",
    "end": "126560"
  },
  {
    "text": "bit of course we're going to talk about the any scale platform uh and we're going to go Hands-On so let's just get",
    "start": "126560",
    "end": "131760"
  },
  {
    "text": "right into it uh so where did any scale come from so Founders right up here on",
    "start": "131760",
    "end": "137360"
  },
  {
    "text": "the screen and a a great kind of picture of them geeking out over on the right uh",
    "start": "137360",
    "end": "143480"
  },
  {
    "text": "coding with their advisor Yan stoa standing right there uh so Robert",
    "start": "143480",
    "end": "148879"
  },
  {
    "text": "nishihara was was uh the initial CEO of any scale uh Philip Moritz is his",
    "start": "148879",
    "end": "157000"
  },
  {
    "text": "colleague and CTO and so they were both at UC Berkeley where they worked with",
    "start": "157000",
    "end": "162640"
  },
  {
    "text": "Yan stoa uh whom you may recognize from previous uh fairly impressive projects",
    "start": "162640",
    "end": "170159"
  },
  {
    "text": "like Apache spark and data bricks uh and so he's been working with the team uh and currently still works",
    "start": "170159",
    "end": "178319"
  },
  {
    "text": "with any scale the ray project was created at the UC",
    "start": "178319",
    "end": "184840"
  },
  {
    "text": "Berkeley rise lab so it says same as Apache spark it's almost exactly the",
    "start": "184840",
    "end": "189920"
  },
  {
    "text": "same so slightly different batch of funding but basically uh basically the same group of folks uh first released in",
    "start": "189920",
    "end": "196959"
  },
  {
    "text": "May 2017 and we'll talk a little bit about what was the inspiration or the",
    "start": "196959",
    "end": "202760"
  },
  {
    "text": "purpose of creating Ray because if you've spent some time working in the large data or machine learning Le in",
    "start": "202760",
    "end": "210080"
  },
  {
    "text": "world you may be familiar with tools like Apache spark and a few others and you may think well you know those work",
    "start": "210080",
    "end": "216200"
  },
  {
    "text": "pretty well uh what is a real advantage of this new framework so we're definitely going to get into the inspiration you know why do you come",
    "start": "216200",
    "end": "222680"
  },
  {
    "text": "along in 2017 and create something brand new and why is that such a promising",
    "start": "222680",
    "end": "229920"
  },
  {
    "text": "approach uh that someone like Yan stoa and Founders uh like Robert and Phillip",
    "start": "229920",
    "end": "236239"
  },
  {
    "text": "and investors like a16z uh Foundation Capital uh and others",
    "start": "236239",
    "end": "241799"
  },
  {
    "text": "are going to jump on board uh with a lot of money to help make this thing a reality so we we'll talk a little bit about that but this is just some",
    "start": "241799",
    "end": "248480"
  },
  {
    "text": "background facts uh Rey you know like a lot of uh like a lot of these um AI",
    "start": "248480",
    "end": "255239"
  },
  {
    "text": "related projects uh has become incredibly relevant within the last uh",
    "start": "255239",
    "end": "261320"
  },
  {
    "text": "several years right so a lot of things that you can do with Ray that were not easy to do before and those happen to be",
    "start": "261320",
    "end": "268479"
  },
  {
    "text": "the things like we're going to see that more and more companies are absolutely needing to do uh and so uh you know you",
    "start": "268479",
    "end": "275240"
  },
  {
    "text": "can see all these logos here these are all firms that are using Ray uh we've",
    "start": "275240",
    "end": "280479"
  },
  {
    "text": "got lots of Ray clusters that we've been launching so you can see over a million",
    "start": "280479",
    "end": "285960"
  },
  {
    "text": "clusters per month uh and Ray is an open source project so you can also see that",
    "start": "285960",
    "end": "291080"
  },
  {
    "text": "we're rapidly increasing our number of open- source contributors so over a thousand",
    "start": "291080",
    "end": "299039"
  },
  {
    "text": "and Reay is really designed not just to accomplish these AI related use cases",
    "start": "300600",
    "end": "305680"
  },
  {
    "text": "because of course we've got to get the thing done with one tool or another uh but to do it faster and better right",
    "start": "305680",
    "end": "311600"
  },
  {
    "text": "this is this is what makes what makes the whole thing so exciting so faster better and also easier uh",
    "start": "311600",
    "end": "318560"
  },
  {
    "text": "so uh you can see a few numbers here I won't go through all these statistics you can kind of take a look at these but",
    "start": "318560",
    "end": "324880"
  },
  {
    "text": "uh you know basically this is about doing more doing it faster uh and doing it for less money which is I think",
    "start": "324880",
    "end": "331440"
  },
  {
    "text": "something that we all uh we all want and need and uh certainly our bosses want and need uh us to help them accomplish",
    "start": "331440",
    "end": "338800"
  },
  {
    "text": "that so a little bit more background on Reay and we'll do even more when we get into the actual code but let's uh just",
    "start": "338800",
    "end": "345360"
  },
  {
    "text": "fill in a little bit so we talked about this idea of complexity wall so what",
    "start": "345360",
    "end": "351039"
  },
  {
    "text": "what is that about uh the idea is to kind of get some simple way to put a",
    "start": "351039",
    "end": "356400"
  },
  {
    "text": "handle on a set of common challenges that companies have been facing within",
    "start": "356400",
    "end": "361919"
  },
  {
    "text": "the last couple of years moving from data processing and basic machine learning and deep learning on like on",
    "start": "361919",
    "end": "369039"
  },
  {
    "text": "the left side of the picture here uh into more complicated uh gen AI use",
    "start": "369039",
    "end": "374560"
  },
  {
    "text": "cases whether it's llms whether it's image or video generation and you know",
    "start": "374560",
    "end": "380560"
  },
  {
    "text": "at first you know there were a bunch of folks that thought well the the kind of Big Data revolution has been around for",
    "start": "380560",
    "end": "386840"
  },
  {
    "text": "15 years or more and in that time companies have figured out how to deploy you know lots of machines how to",
    "start": "386840",
    "end": "393360"
  },
  {
    "text": "orchestrate those machines we've learned about things like kubernetes uh if you're going more on the cloud side you",
    "start": "393360",
    "end": "400560"
  },
  {
    "text": "know we know how to operate with these clouds with multiple clouds we know how to kind of bridge our infrastructure um",
    "start": "400560",
    "end": "407759"
  },
  {
    "text": "between on-prem and Cloud we've learned all these tricks in the last 15 years and so um at first you know a lot of",
    "start": "407759",
    "end": "413960"
  },
  {
    "text": "folks thought well we learned how to do this for data you know and it was hard at first we figured it out uh and then",
    "start": "413960",
    "end": "419000"
  },
  {
    "text": "we kind of figured have to do it for machine learning so at this point you know isn't that kind of a solved problem where you know we know how to deploy uh",
    "start": "419000",
    "end": "426639"
  },
  {
    "text": "large numbers of machines and get them to you know collaborate together uh so at this point isn't it just a matter of",
    "start": "426639",
    "end": "433199"
  },
  {
    "text": "installing more software packages right so uh you know installing uh acceleration for say llm inference or",
    "start": "433199",
    "end": "440759"
  },
  {
    "text": "installing uh more uh deep learning tools uh or isn't it just a matter of provisioning nodes or buying uh gpus or",
    "start": "440759",
    "end": "449720"
  },
  {
    "text": "provisioning nodes with gpus and now we can just do all this new stuff and you know uh that's actually you know was a",
    "start": "449720",
    "end": "455879"
  },
  {
    "text": "reasonable place to start but it turned out to be a lot harder uh at scale than",
    "start": "455879",
    "end": "461599"
  },
  {
    "text": "folks were expecting uh because it turns out that there are a few new problems and we we'll talk about those in a",
    "start": "461599",
    "end": "467400"
  },
  {
    "text": "little bit but there are some new problems that come up uh when you're doing not just um high volume data",
    "start": "467400",
    "end": "474400"
  },
  {
    "text": "processing uh and deep learning but running these large gen models right and",
    "start": "474400",
    "end": "479960"
  },
  {
    "text": "just to give a little preview and not be Cy about it so some of the challenges are you know a lot of the older tools",
    "start": "479960",
    "end": "486400"
  },
  {
    "text": "assumed things they assumed us certain uh General configurations of your",
    "start": "486400",
    "end": "491680"
  },
  {
    "text": "workload and that worked really good um for a long time but it turns out that",
    "start": "491680",
    "end": "496960"
  },
  {
    "text": "when you go outside those kind of dotted lines uh things get a lot harder uh",
    "start": "496960",
    "end": "502039"
  },
  {
    "text": "another assumption was that uh you know symmetric clusters or clusters where every node has the same configuration uh",
    "start": "502039",
    "end": "509120"
  },
  {
    "text": "that that Simplicity would you know outweigh you know any you know costs associated with that well it turns out",
    "start": "509120",
    "end": "516279"
  },
  {
    "text": "in the world of geni that's just not true right we've got machines uh that",
    "start": "516279",
    "end": "521399"
  },
  {
    "text": "have lots of different kinds of accelerators and Hardware configurations and we have workloads where if we can",
    "start": "521399",
    "end": "527680"
  },
  {
    "text": "maximally utilize those heterogeneous clusters we can do things so much faster",
    "start": "527680",
    "end": "534080"
  },
  {
    "text": "and save so much money that it's worth figuring out how to uh deploy our software Ware onto those heterogeneous",
    "start": "534080",
    "end": "541320"
  },
  {
    "text": "clusters so this is a kind of a um you know I guess a few years ago there was that phrase narrative violation right I",
    "start": "541320",
    "end": "547760"
  },
  {
    "text": "don't know if it's quite that severe but this is this was something where we discovered that our assumptions about",
    "start": "547760",
    "end": "552880"
  },
  {
    "text": "cost and complexity trade-offs weren't quite true it turns out it's actually really worth it to embrace the",
    "start": "552880",
    "end": "558360"
  },
  {
    "text": "complexity uh of the picture on the right hand side here uh and worth it meaning we actually save a lot of money",
    "start": "558360",
    "end": "564760"
  },
  {
    "text": "and get more stuff done but if we're going to do that we need tools that are going to make that practical we you know",
    "start": "564760",
    "end": "569800"
  },
  {
    "text": "we're not we we're not realistically going to Brute Force you know a massive cluster that has uh a large amount of",
    "start": "569800",
    "end": "577680"
  },
  {
    "text": "heterogeneity in terms of different kinds of nodes what they're you know optimized for different kinds of",
    "start": "577680",
    "end": "583800"
  },
  {
    "text": "accelerators we need something that can handle all of that so these are some of",
    "start": "583800",
    "end": "588880"
  },
  {
    "text": "the these are some of the challenges that represent this uh complexity wall and it's what makes Ray such a useful",
    "start": "588880",
    "end": "596000"
  },
  {
    "text": "tool right because you know Ray comes along if you know if you think about uh on this picture here there are other",
    "start": "596000",
    "end": "602360"
  },
  {
    "text": "tools and there's you know I icons on there that you know symbolize some of these like uh a pachy spark um you know",
    "start": "602360",
    "end": "609200"
  },
  {
    "text": "is a pretty solid tool for data processing even at scale right and when we get into machine learning right we",
    "start": "609200",
    "end": "615160"
  },
  {
    "text": "can throw on things like scikit learn XG boost uh and then we get into deep learning and we bring in tensor flow and",
    "start": "615160",
    "end": "621680"
  },
  {
    "text": "pytorch and these other tools and that's kind of a sufficient uh infrastructure but when we get to the Gen uh picture",
    "start": "621680",
    "end": "629480"
  },
  {
    "text": "over on the right uh it becomes a little bit more complicated than just you know",
    "start": "629480",
    "end": "635399"
  },
  {
    "text": "downloading you know software packages that that match those icons you know doing a pip install uh and hoping",
    "start": "635399",
    "end": "641519"
  },
  {
    "text": "everything runs so we want to um figure out how to empower uh the engineers and",
    "start": "641519",
    "end": "647399"
  },
  {
    "text": "the infrastructure teams uh at companies that want to do this uh to be able to do it faster and easier so you know just a",
    "start": "647399",
    "end": "654720"
  },
  {
    "text": "couple of you know a couple of kind of quotes to summarize this um what does",
    "start": "654720",
    "end": "660040"
  },
  {
    "text": "the AI complexity wall cost if you don't have the tools to get past that um so",
    "start": "660040",
    "end": "665959"
  },
  {
    "text": "wasted compute right so only 6% of companies are seeing utilization above 85% uh when we consider how uh expensive",
    "start": "665959",
    "end": "673680"
  },
  {
    "text": "some of these uh GPU clusters are that's that's a really really big loss uh",
    "start": "673680",
    "end": "679360"
  },
  {
    "text": "skyrocketing costs right so AI is the single largest tech spend line item uh",
    "start": "679360",
    "end": "685079"
  },
  {
    "text": "for the next year at 44% of companies uh that's that's pretty huge that's one of these like once in a generation levels",
    "start": "685079",
    "end": "692040"
  },
  {
    "text": "of investment so if we're going to be investing uh at that level we want to be",
    "start": "692040",
    "end": "697120"
  },
  {
    "text": "paying attention to every you know every penny and making sure we're getting results uh and then you know even if we",
    "start": "697120",
    "end": "702839"
  },
  {
    "text": "you know don't care about the waste and we don't care how much it costs uh we probably you know in other words if we",
    "start": "702839",
    "end": "708000"
  },
  {
    "text": "don't care about efficiency we probably Care at least about Effectiveness about getting something out the door but it",
    "start": "708000",
    "end": "713360"
  },
  {
    "text": "turns out that's not working either right we know kind of classical uh examples of the huge fra action of",
    "start": "713360",
    "end": "720040"
  },
  {
    "text": "projects that just don't get anywhere well it turns out that you know with Gen it's it's it's even worse so even with",
    "start": "720040",
    "end": "727880"
  },
  {
    "text": "working Pilots so even with 45% rate of working pilot projects only 10% of orgs",
    "start": "727880",
    "end": "734839"
  },
  {
    "text": "are actually getting stuff into production so it's neither efficient uh nor effective uh to stick with the tools",
    "start": "734839",
    "end": "741480"
  },
  {
    "text": "that we had kind of prior to hitting this level of of complexity uh we need something different and that's where uh",
    "start": "741480",
    "end": "748680"
  },
  {
    "text": "that's where comes in so this is a kind of a simplified uh kind of a tick boox",
    "start": "748680",
    "end": "754920"
  },
  {
    "text": "list to give some sense of where Ray uh you know fits in relative to some of the",
    "start": "754920",
    "end": "761639"
  },
  {
    "text": "previous generation tools so um if we look at some of the earlier tools like",
    "start": "761639",
    "end": "766880"
  },
  {
    "text": "you know Hadoop is kind of you know uh archaeologically early at this point um but things like Hadoop and then things",
    "start": "766880",
    "end": "773199"
  },
  {
    "text": "like spark and and there are a few other big data Tools in that generation floating around right so they they check",
    "start": "773199",
    "end": "779199"
  },
  {
    "text": "the box for scaling up to thousands of nodes if you operate them correctly uh and they do uh support uh abstracting",
    "start": "779199",
    "end": "786639"
  },
  {
    "text": "away the complexity of your infrastructure again if they're if they're operated right if you don't operate them right then you know you",
    "start": "786639",
    "end": "792639"
  },
  {
    "text": "don't even get that far but if you if you operate these things well um you get those checkboxes um but they're not",
    "start": "792639",
    "end": "798920"
  },
  {
    "text": "helping you with some of the other uh some of the other pieces right so just you know not to read every single line",
    "start": "798920",
    "end": "804519"
  },
  {
    "text": "every single time but to look at the just the top here right so there are gen workloads that just don't make they",
    "start": "804519",
    "end": "809920"
  },
  {
    "text": "don't make any sense in the world of those tools right so we need something else uh in terms of any data types and",
    "start": "809920",
    "end": "815199"
  },
  {
    "text": "model architecture so what we mean by any data types are um the rise in uh",
    "start": "815199",
    "end": "821199"
  },
  {
    "text": "unstructured data of lots of different types and a necessity to connect structured data with unstructured data",
    "start": "821199",
    "end": "828120"
  },
  {
    "text": "so data sets that have tabular components but then parts or or",
    "start": "828120",
    "end": "833199"
  },
  {
    "text": "connected to particular fields we might have videos we might have whole kind of",
    "start": "833199",
    "end": "838839"
  },
  {
    "text": "sub data sets that go with particular Fields uh we have lots of audio we've got images so trying to figure out how",
    "start": "838839",
    "end": "845759"
  },
  {
    "text": "to you know make sense of those not something that uh the older Frameworks worked very well for or or in some case",
    "start": "845759",
    "end": "853160"
  },
  {
    "text": "they couldn't work at all uh you know we've got the ml Frameworks these are the ones over on the right so um you",
    "start": "853160",
    "end": "858560"
  },
  {
    "text": "know things like pytorch and and tensor flow uh those are better at dealing with different types of data and model",
    "start": "858560",
    "end": "864880"
  },
  {
    "text": "architectures right because that's what they were created for so they've got that under control control uh and they",
    "start": "864880",
    "end": "870279"
  },
  {
    "text": "can scale not necessarily easy to scale if you if you've done raw kind of you know cluster building and scaling",
    "start": "870279",
    "end": "876120"
  },
  {
    "text": "directly over those tools you know uh it's not always easy but they they can do it if you kind of operate it right",
    "start": "876120",
    "end": "881560"
  },
  {
    "text": "but then you know they're missing a lot of features uh too so uh They Don't Really abstract away that infrastructure",
    "start": "881560",
    "end": "888120"
  },
  {
    "text": "complexity you know it does like I was just kind of hinting at it does you do feel the pain when you scale those",
    "start": "888120",
    "end": "893759"
  },
  {
    "text": "things up and you know when you're feeling that pain uh in a oneoff instance that's usually a good sign that",
    "start": "893759",
    "end": "899519"
  },
  {
    "text": "is not going to operationally scale for an Enterprise because you know things need to be uh kind of painless and",
    "start": "899519",
    "end": "904800"
  },
  {
    "text": "TurnKey to really go Enterprise scale uh they certainly don't represent things like a unified platform because you know",
    "start": "904800",
    "end": "911199"
  },
  {
    "text": "the the ml Frameworks are dedicated tools right and they're great for what they are but they're not attempting to be a platform right so just you know",
    "start": "911199",
    "end": "917959"
  },
  {
    "text": "some examples of um strengths and weaknesses there uh so you know Reay is really designed to to hit all of these",
    "start": "917959",
    "end": "925440"
  },
  {
    "text": "pieces so you know all of the AI or ML workloads and that kind of connects to",
    "start": "925440",
    "end": "932240"
  },
  {
    "text": "the any model architecture in the next line the idea as we're going to see with Ray is it's designed to handle uh",
    "start": "932240",
    "end": "939279"
  },
  {
    "text": "arbitrary compute graphs which is a kind of a fancy way of saying any algorithm that you can express uh can be deployed",
    "start": "939279",
    "end": "946959"
  },
  {
    "text": "onto Ray without some massive rethinking or redesigning so it doesn't have any",
    "start": "946959",
    "end": "952560"
  },
  {
    "text": "restriction in terms of the shape of the compute uh which is a really big deal right that allows us to you know be able",
    "start": "952560",
    "end": "959360"
  },
  {
    "text": "to work with pretty much any kind of AI or ml workload you can also do classical",
    "start": "959360",
    "end": "964399"
  },
  {
    "text": "compute workloads there other stuff you can do with Ray that we're not going to talk about today uh but that the firms",
    "start": "964399",
    "end": "970240"
  },
  {
    "text": "around the world are using Ray for that are you know all kinds of typical compute jobs uh that can be deployed at",
    "start": "970240",
    "end": "975279"
  },
  {
    "text": "scale with Ray uh any type of data and model architecture uh is an assumption",
    "start": "975279",
    "end": "980440"
  },
  {
    "text": "that goes with that uh heterogeneous resources so this is one of the really key assumptions going back to the very",
    "start": "980440",
    "end": "986240"
  },
  {
    "text": "beginning of Ray was that we need to be able to uh have a collection of compute",
    "start": "986240",
    "end": "992480"
  },
  {
    "text": "resources where different nodes have different capabilities right different kinds of accelerators different kinds of",
    "start": "992480",
    "end": "997800"
  },
  {
    "text": "Hardware uh all different kinds of resources some that we are not maybe even commonly thinking of yet today so",
    "start": "997800",
    "end": "1003639"
  },
  {
    "text": "we need kind of an open-ended resource framework right on the one hand for resources and then if we switch over to",
    "start": "1003639",
    "end": "1009920"
  },
  {
    "text": "our code we know that different parts of our code are going to benefit from different kinds of resources so uh some",
    "start": "1009920",
    "end": "1016480"
  },
  {
    "text": "pieces of code may not need a they not benefit from a GPU at all maybe they're just doing some basic IO stuff or",
    "start": "1016480",
    "end": "1023560"
  },
  {
    "text": "network uh network communication so they don't need gpus at all then maybe we have some chunks of code that need a GPU",
    "start": "1023560",
    "end": "1029959"
  },
  {
    "text": "or they benefit a lot from a GPU uh but they don't need the super super fancy giant gpus so things like Computing",
    "start": "1029959",
    "end": "1036600"
  },
  {
    "text": "embeddings uh and stuff like that uh it's useful to have a GPU maybe maybe necessary but we don't need these really",
    "start": "1036600",
    "end": "1043319"
  },
  {
    "text": "expensive or rare or or giant GPS uh then we have the stuff that really does benefit even require the the latest and",
    "start": "1043319",
    "end": "1050679"
  },
  {
    "text": "greatest gpus so like the the large uh the very large language models uh and then there's other kinds of",
    "start": "1050679",
    "end": "1056679"
  },
  {
    "text": "resources uh that may be relevant also that go with specific pieces of code so what we want to be able to do is have a",
    "start": "1056679",
    "end": "1062559"
  },
  {
    "text": "pool of different kinds of resources have code that we can Mark or that the",
    "start": "1062559",
    "end": "1068000"
  },
  {
    "text": "framework is aware requires different resources and then be able to take that distributed scheduling Challenge from",
    "start": "1068000",
    "end": "1074280"
  },
  {
    "text": "the previous generation of computation Frameworks and now do elegant efficient",
    "start": "1074280",
    "end": "1080360"
  },
  {
    "text": "scheduling where we're we're not just managing you know keeping all the nodes busy but actually making sure each piece",
    "start": "1080360",
    "end": "1086400"
  },
  {
    "text": "of compute ends up running in a place where uh it can take best advantage of",
    "start": "1086400",
    "end": "1092480"
  },
  {
    "text": "the resources and that the resources are being most efficiently used so this is a whole additional dimension of constraint",
    "start": "1092480",
    "end": "1099080"
  },
  {
    "text": "uh that uh Ray takes on and has been designed for from the very beginning that wasn't really uh it was maybe a",
    "start": "1099080",
    "end": "1105159"
  },
  {
    "text": "little little too far of a leap for some of the earlier Frameworks uh to worry about uh scaling of course you know",
    "start": "1105159",
    "end": "1112240"
  },
  {
    "text": "that's kind of an assumption it's like you know table Stakes they say sometimes uh for anything these days so you know",
    "start": "1112240",
    "end": "1118320"
  },
  {
    "text": "we have to have arbitrary scaling uh we want to abstract away infrastructure complexity so this",
    "start": "1118320",
    "end": "1124840"
  },
  {
    "text": "is this is something that we need if we're going to be uh you know going",
    "start": "1124840",
    "end": "1130039"
  },
  {
    "text": "beyond the kind of scientific or research lab environment uh and going out at scale so we need simple and",
    "start": "1130039",
    "end": "1136080"
  },
  {
    "text": "declarative ways to make sure that our software is running uh getting all of",
    "start": "1136080",
    "end": "1141480"
  },
  {
    "text": "these benefits uh and then a unified platform for the entire AI ecosystem so unified platform is one of those terms",
    "start": "1141480",
    "end": "1148320"
  },
  {
    "text": "that's maybe a little overused uh so rather than try to say it a bunch of times and hope that you somehow believe",
    "start": "1148320",
    "end": "1154360"
  },
  {
    "text": "it because that's you know that's that's great but it's not maybe as convincing I'm going to leave the unified platform",
    "start": "1154360",
    "end": "1160000"
  },
  {
    "text": "piece till we get to the demo because I think when you see the demo you'll see what we mean by unii PL unified platform",
    "start": "1160000",
    "end": "1166799"
  },
  {
    "text": "uh so we'll leave that for now",
    "start": "1166799",
    "end": "1170720"
  },
  {
    "text": "in terms of the uh elements that we can take advantage of with Ray I know this",
    "start": "1171960",
    "end": "1177880"
  },
  {
    "text": "this slide unless you maybe like get a screenshot or look at the slides later and kind of zoom in uh there maybe a lot",
    "start": "1177880",
    "end": "1184919"
  },
  {
    "text": "of logos flying around here so don't worry about trying to uh you know kind",
    "start": "1184919",
    "end": "1190080"
  },
  {
    "text": "of parse this image and figure out exactly which uh logos are here and then",
    "start": "1190080",
    "end": "1195159"
  },
  {
    "text": "if there's a logo that's not here you know don't worry that this is something it's going to be a deal breaker for using the platform uh what we wanted to",
    "start": "1195159",
    "end": "1202240"
  },
  {
    "text": "do with this slide was to give a general sense of the level of ambition and uh",
    "start": "1202240",
    "end": "1208400"
  },
  {
    "text": "this ambition is translating into delivered product uh behind the N scale",
    "start": "1208400",
    "end": "1214240"
  },
  {
    "text": "uh behind the the whole any scale uh kind of platform approach so uh you know if",
    "start": "1214240",
    "end": "1221200"
  },
  {
    "text": "you're living across lots of different clouds we want to be able to handle that even if you're working with schedulers",
    "start": "1221200",
    "end": "1227240"
  },
  {
    "text": "that are not directly you know to a cloud so things like slurm or just on-prem you know collections of on-prem",
    "start": "1227240",
    "end": "1233799"
  },
  {
    "text": "Hardware uh we want to be able to make that work uh any kind of Hardware so you",
    "start": "1233799",
    "end": "1238919"
  },
  {
    "text": "know obviously everybody you know has their Intel and their Nvidia support um but we want to be able to hit uh",
    "start": "1238919",
    "end": "1246440"
  },
  {
    "text": "additional uh additional Hardware that's that's you know coming out and may not even be out yet so by having this kind",
    "start": "1246440",
    "end": "1253120"
  },
  {
    "text": "of uh open-ended uh resource framework in terms of soft software",
    "start": "1253120",
    "end": "1258919"
  },
  {
    "text": "tools uh where it's not a Walled Garden in other words any scale and Ray do do",
    "start": "1258919",
    "end": "1264200"
  },
  {
    "text": "not have like a set of very special magical apis that everything has to translate into uh they uh work the the",
    "start": "1264200",
    "end": "1271919"
  },
  {
    "text": "infrastructure of Ray and any scale work together with the open source projects that you're already using every day",
    "start": "1271919",
    "end": "1278919"
  },
  {
    "text": "right so um there's a few logos on here and again it always gets a little bit silly reciting logos because there's",
    "start": "1278919",
    "end": "1284000"
  },
  {
    "text": "always ones that you leave off but um you know those tools that you're using today whether it's you know whether it's",
    "start": "1284000",
    "end": "1289480"
  },
  {
    "text": "uh you know pie torch whether it's hugging face whether it's optuna uh for hyper pram",
    "start": "1289480",
    "end": "1295720"
  },
  {
    "text": "tuning uh whether it's VM for uh acceleration uh the idea is that you",
    "start": "1295720",
    "end": "1301039"
  },
  {
    "text": "know we're going to work with all of those we're not going to replace those and give some special you know separate world that you have to live in all of",
    "start": "1301039",
    "end": "1307360"
  },
  {
    "text": "that stuff is going to run in most cases it's going to run the way you already have it uh but we're going to be able to",
    "start": "1307360",
    "end": "1313039"
  },
  {
    "text": "scale it uh we're going to be able to integrate with other parts of your workflow and do that uh really easily so",
    "start": "1313039",
    "end": "1320000"
  },
  {
    "text": "that's probably as much as we need to worry about all of the individual logos there uh and then you know moving even",
    "start": "1320000",
    "end": "1327320"
  },
  {
    "text": "more towards uh kind of an Enterprise design uh the idea is that we've got a",
    "start": "1327320",
    "end": "1334600"
  },
  {
    "text": "separated control plane which is where the uh core any scale uh infrastructure",
    "start": "1334600",
    "end": "1342240"
  },
  {
    "text": "and software lives and then the customer's data plane so your data stays",
    "start": "1342240",
    "end": "1347840"
  },
  {
    "text": "uh in your own clouds uh and the any scale control plane uh is just",
    "start": "1347840",
    "end": "1355480"
  },
  {
    "text": "arranging uh clusters and managing resources um you know providing",
    "start": "1355480",
    "end": "1361679"
  },
  {
    "text": "reporting single sign on uh so all of that Enterprise operation stuff that you",
    "start": "1361679",
    "end": "1367520"
  },
  {
    "text": "need for a complex platform but you don't really want to build yourself if",
    "start": "1367520",
    "end": "1372559"
  },
  {
    "text": "you've never built it you probably don't want to build it if you've built it once before you probably don't want to build it again right and you can get some of",
    "start": "1372559",
    "end": "1379600"
  },
  {
    "text": "those pieces from some other products like you can get part of it from tools that are say uh coming from your Cloud",
    "start": "1379600",
    "end": "1385480"
  },
  {
    "text": "vendors but uh to get the whole collection of pieces that you need and",
    "start": "1385480",
    "end": "1390520"
  },
  {
    "text": "especially tailored around these uh endtoend AI workflows uh any scale is really going to cover that in a much",
    "start": "1390520",
    "end": "1397320"
  },
  {
    "text": "more comprehensive way so I notice uh by the way I do",
    "start": "1397320",
    "end": "1404120"
  },
  {
    "text": "notice that there is a question over in the Q and a and what I'm going to do",
    "start": "1404120",
    "end": "1410240"
  },
  {
    "text": "because we're in such a kind of a limited amount of time here today uh what I'm going to do is I'm going to",
    "start": "1410240",
    "end": "1415520"
  },
  {
    "text": "wait uh till the end of the session if we have time we'll look at some of those questions so feel free to put those",
    "start": "1415520",
    "end": "1420960"
  },
  {
    "text": "questions in there uh but what I'm going to do is I'm going to wait until the end and if we have time we'll we'll look at",
    "start": "1420960",
    "end": "1428200"
  },
  {
    "text": "those uh in terms of Ray versus any scale so Ray is open source you can see it on GitHub you can pip install it",
    "start": "1428200",
    "end": "1434799"
  },
  {
    "text": "right now there's no you know there's no accounts you don't need a license key or or anything like that uh so that's that",
    "start": "1434799",
    "end": "1442559"
  },
  {
    "text": "um you know that that you can start working with right now uh what what is the any scale platform bringing you",
    "start": "1442559",
    "end": "1447720"
  },
  {
    "text": "that's not necessarily uh in Ray in terms of support right",
    "start": "1447720",
    "end": "1454000"
  },
  {
    "text": "so uh enhanced support for Ray itself right so instead of just the community support uh actual paid commercial",
    "start": "1454000",
    "end": "1461320"
  },
  {
    "text": "support uh and then also support for things that are not uh you know they're not core to the ray uh soft software",
    "start": "1461320",
    "end": "1469240"
  },
  {
    "text": "platform itself but are important parts of actually building and deploying these systems in the real world so uh VM uh",
    "start": "1469240",
    "end": "1477679"
  },
  {
    "text": "acceleration support GPU optimization support uh infrastructure and so on you",
    "start": "1477679",
    "end": "1483240"
  },
  {
    "text": "know those are inescapable things in the real world and so any scale is bringing Enterprise support uh for those pieces",
    "start": "1483240",
    "end": "1489840"
  },
  {
    "text": "so you've got really the full support package uh it's not just you know supporting the software and then leaving",
    "start": "1489840",
    "end": "1496279"
  },
  {
    "text": "those uh leaving those problems open",
    "start": "1496279",
    "end": "1500320"
  },
  {
    "text": "Ray itself uh like I said is completely open source but any scale also has some",
    "start": "1502880",
    "end": "1509440"
  },
  {
    "text": "enhancements to Ray uh in some cases they additional features uh like",
    "start": "1509440",
    "end": "1515320"
  },
  {
    "text": "connecting more efficiently to certain data sources uh in some cases their performance features uh like being able",
    "start": "1515320",
    "end": "1522360"
  },
  {
    "text": "to uh execute certain operations more efficiently and the optimized version of",
    "start": "1522360",
    "end": "1529000"
  },
  {
    "text": "Ray that you get with the N scale platform is called Ray turbo so uh you can think of it as Ray is open",
    "start": "1529000",
    "end": "1536919"
  },
  {
    "text": "source Ray turbo is like the any scale enhanced version of Ray and Ray turbo",
    "start": "1536919",
    "end": "1542440"
  },
  {
    "text": "has the same apis as Ray but it has a few extra features and benefits so",
    "start": "1542440",
    "end": "1548080"
  },
  {
    "text": "here's like a quick overview of some of those so uh again the goal is lower",
    "start": "1548080",
    "end": "1553840"
  },
  {
    "text": "costs and you know more efficiency across the board so lower costs fewer nodes to do the same thing uh you know",
    "start": "1553840",
    "end": "1560279"
  },
  {
    "text": "accomplish the same throughput uh faster wall clock time for doing certain kinds",
    "start": "1560279",
    "end": "1565480"
  },
  {
    "text": "of work uh better scaling uh you know ultimately uh more uh efficiency end to",
    "start": "1565480",
    "end": "1573039"
  },
  {
    "text": "end uh and then down at the bottom a little bit of functionality that goes beyond just performance uh that's only",
    "start": "1573039",
    "end": "1579679"
  },
  {
    "text": "available on the any scale Ray turbo at least for now uh so additional data",
    "start": "1579679",
    "end": "1585440"
  },
  {
    "text": "connectors uh joins uh certain kinds of group buy operations some of those are",
    "start": "1585440",
    "end": "1591720"
  },
  {
    "text": "in open source but there's some new stuff that is only in Ray turbo uh partitioned rights which you might want",
    "start": "1591720",
    "end": "1598679"
  },
  {
    "text": "for compatibility with existing certain existing processes uh and some few other",
    "start": "1598679",
    "end": "1604600"
  },
  {
    "text": "optimization so a better memory allocation uh predicate push down for",
    "start": "1604600",
    "end": "1610159"
  },
  {
    "text": "certain kinds of uh data querying multi-tenancy support uh and more so um",
    "start": "1610159",
    "end": "1616320"
  },
  {
    "text": "you know if there's something that you're wondering is it in that and more is it something you want definitely you know talk to us about",
    "start": "1616320",
    "end": "1622159"
  },
  {
    "text": "that uh this has a little bit more detail I'm going to not going to get into kind of the extensive detail on",
    "start": "1622159",
    "end": "1628279"
  },
  {
    "text": "this maybe we'll come back to it uh at the end because I I know it's having uh you know being on online here and having",
    "start": "1628279",
    "end": "1634520"
  },
  {
    "text": "somebody read to you a lot of text on a slide that's always a little bit rough but I wanted to share this because this",
    "start": "1634520",
    "end": "1639640"
  },
  {
    "text": "is a slide that you'll have access to later uh and depending on your job you may kind of Zoom right in on one corner",
    "start": "1639640",
    "end": "1645600"
  },
  {
    "text": "of this and be like oh yeah so um like SS are like the biggest problem in you",
    "start": "1645600",
    "end": "1650760"
  },
  {
    "text": "know our work so far reduced ooms that's worth a conversation uh so there may be specific areas of these that are",
    "start": "1650760",
    "end": "1656320"
  },
  {
    "text": "interesting to you and we'll we'll maybe come back and Survey this near the end but let's get let's get into it uh and",
    "start": "1656320",
    "end": "1664159"
  },
  {
    "text": "look at some of this code running and talk more about what uh uh kind of we peel back the uh kind of um use case",
    "start": "1664159",
    "end": "1672000"
  },
  {
    "text": "oriented packaging uh what is the infrastructure a little bit of uh Reay",
    "start": "1672000",
    "end": "1677480"
  },
  {
    "text": "so I'm going to flip over",
    "start": "1677480",
    "end": "1681720"
  },
  {
    "text": "here so here I've got a different browser you can probably recognize this",
    "start": "1682960",
    "end": "1688480"
  },
  {
    "text": "as the Jupiter lab UI uh down here in the middle of the window uh up here at",
    "start": "1688480",
    "end": "1693960"
  },
  {
    "text": "the top you can see there's some Chrome which is associated with the any scale platform so for today's session we're",
    "start": "1693960",
    "end": "1701000"
  },
  {
    "text": "not going to do an extensive tour of the any scale platform UI kind of area by",
    "start": "1701000",
    "end": "1706720"
  },
  {
    "text": "area uh but just to give you some sense of what's kind of living up here so uh",
    "start": "1706720",
    "end": "1712440"
  },
  {
    "text": "in the upper left hand we've got this hamburger menu uh and we have things",
    "start": "1712440",
    "end": "1717640"
  },
  {
    "text": "like workspaces which is where we're going to be working today so these are focused on uh developing and debugging",
    "start": "1717640",
    "end": "1724679"
  },
  {
    "text": "and they give you an easy way to interactively run code against your cluster uh any scale jobs so these are",
    "start": "1724679",
    "end": "1733840"
  },
  {
    "text": "um these are basically batch scheduled jobs uh that we can run in you know kind",
    "start": "1733840",
    "end": "1740000"
  },
  {
    "text": "of a a more scheduled you know headless production oriented environment so this",
    "start": "1740000",
    "end": "1746360"
  },
  {
    "text": "is kind of how you productionize uh the code once you've got it uh debugged and there's all kind of nice capabilities",
    "start": "1746360",
    "end": "1752480"
  },
  {
    "text": "around jobs so the jobs all uh spin up their own clusters so they always uh run",
    "start": "1752480",
    "end": "1757720"
  },
  {
    "text": "clean and they collect all of their metrics and logs and you know they report back to you and they're finished and uh you know we have that uh kind of",
    "start": "1757720",
    "end": "1765440"
  },
  {
    "text": "um uh any scale services so um I mentioned",
    "start": "1765440",
    "end": "1771399"
  },
  {
    "text": "jobs and jobs kind of have this batch flavor like you've got some code you launch it it does a bunch of stuff and then it finishes um sometimes our",
    "start": "1771399",
    "end": "1778720"
  },
  {
    "text": "production code is different in that we want to run a uh High availability low",
    "start": "1778720",
    "end": "1785000"
  },
  {
    "text": "latency service that does something right and that something could be as simple as uh talking to a language model",
    "start": "1785000",
    "end": "1792320"
  },
  {
    "text": "or it could be a really complicated application that orchestrates business rules and a bunch of ml models and a",
    "start": "1792320",
    "end": "1798480"
  },
  {
    "text": "bunch of you know language models and does something more sophisticated so Ray has apis for that and then any scale",
    "start": "1798480",
    "end": "1805320"
  },
  {
    "text": "allows us to wrap that uh in even more bulletproof uh and operationalizable uh",
    "start": "1805320",
    "end": "1811120"
  },
  {
    "text": "way with any scale services and that allows us to do things like um in place",
    "start": "1811120",
    "end": "1816919"
  },
  {
    "text": "upgrades and Canary rollouts uh and other kinds of uh elements that go beyond just implementing a service and",
    "start": "1816919",
    "end": "1823039"
  },
  {
    "text": "really focus on operationalization uh we've got Services specifically around working with llms uh",
    "start": "1823039",
    "end": "1829919"
  },
  {
    "text": "we allow you to manage your own infrastructure by defining your own container images and uh cluster",
    "start": "1829919",
    "end": "1835440"
  },
  {
    "text": "definitions and versioning all of those uh so that you've got kind of an easy way to manage all of that and you're not",
    "start": "1835440",
    "end": "1841760"
  },
  {
    "text": "just saying oh yeah I think we ran this with 2 A1 100s last time but uh maybe sometimes it can work work with 4 A10 GS",
    "start": "1841760",
    "end": "1848679"
  },
  {
    "text": "instead you can Define these you can version them and you can make sure that all of your um your both your workspaces",
    "start": "1848679",
    "end": "1854880"
  },
  {
    "text": "your jobs uh other things that you're launching they can reference these definitions so you've got a nice way to",
    "start": "1854880",
    "end": "1860159"
  },
  {
    "text": "manage all of that uh so just those are just some of the features of the platform and not",
    "start": "1860159",
    "end": "1865440"
  },
  {
    "text": "going to get any deeper into those right now because I want to uh talk a little bit about Ray and then run some code",
    "start": "1865440",
    "end": "1874279"
  },
  {
    "text": "here so uh this is kind of a very simplified architecture kind of diagram",
    "start": "1874279",
    "end": "1880240"
  },
  {
    "text": "of um how our Ray system that we're going to be working with today kind of comes together so at the bottom we've",
    "start": "1880240",
    "end": "1886519"
  },
  {
    "text": "got some kind of compute pool of compute resources right so the the box here says Cloud um and that could be a cloud but",
    "start": "1886519",
    "end": "1892840"
  },
  {
    "text": "it could also be you know kubernetes it could be a whole bunch of on-prem machines uh it's basically your",
    "start": "1892840",
    "end": "1898799"
  },
  {
    "text": "compute Fabric or your pool of uh resources from which we can or or or against which we can",
    "start": "1898799",
    "end": "1906760"
  },
  {
    "text": "schedule chunks of work the next layer up uh is Ray core so",
    "start": "1906760",
    "end": "1912919"
  },
  {
    "text": "this was one of the this well this was kind of the original uh you know piece",
    "start": "1912919",
    "end": "1918080"
  },
  {
    "text": "of of Ray uh and it supports the more high level abstractions that we've got",
    "start": "1918080",
    "end": "1923840"
  },
  {
    "text": "built up on top uh and Ray core is the it's ultimately the scheduler and",
    "start": "1923840",
    "end": "1930720"
  },
  {
    "text": "resource scaler and allocator uh for your python",
    "start": "1930720",
    "end": "1936399"
  },
  {
    "text": "software that you want to scale so let me kind of say that again in maybe a way",
    "start": "1936399",
    "end": "1941679"
  },
  {
    "text": "that makes a little more sense uh let's start with this python software idea so let's say you've got some code and this",
    "start": "1941679",
    "end": "1947440"
  },
  {
    "text": "could be this could be python functions you know just something that you need to run somewhere maybe it needs certain",
    "start": "1947440",
    "end": "1953279"
  },
  {
    "text": "Hardware configuration maybe it doesn't uh they could be python classes so maybe these are objects that need to live for",
    "start": "1953279",
    "end": "1960639"
  },
  {
    "text": "a period of time and you're going to send them messages uh and you're going to you know maybe query their state",
    "start": "1960639",
    "end": "1966559"
  },
  {
    "text": "later uh so they're you know kind of stateful uh and they need to you need to have lots of these and they may have",
    "start": "1966559",
    "end": "1972880"
  },
  {
    "text": "their own resource requirements and uh you may want to do things like uh dynamically",
    "start": "1972880",
    "end": "1978519"
  },
  {
    "text": "uh adjust the number of these classes or class instances depending on what's going on so you've got this python you",
    "start": "1978519",
    "end": "1985600"
  },
  {
    "text": "know some kind of complicated python system that you want to deploy so the job of Ray core is to figure out the",
    "start": "1985600",
    "end": "1993000"
  },
  {
    "text": "dependencies in your code figure out the resource requirements and then schedule",
    "start": "1993000",
    "end": "1999519"
  },
  {
    "text": "those pieces against the compute resources so using that bottom layer",
    "start": "1999519",
    "end": "2004760"
  },
  {
    "text": "schedule your code in the most efficient way possible so making sure that all of",
    "start": "2004760",
    "end": "2010480"
  },
  {
    "text": "the code you know has all of its you know that satisfies all of its prerequisites in terms of previously",
    "start": "2010480",
    "end": "2016039"
  },
  {
    "text": "computed results in terms of Hardware resources uh and to do this in a",
    "start": "2016039",
    "end": "2021399"
  },
  {
    "text": "maximally efficient way so that turns out to be a really hard problem uh and you know for a lot of reasons one of",
    "start": "2021399",
    "end": "2028159"
  },
  {
    "text": "those reasons being you know if you constrain the kind of program you're running tightly enough then you can",
    "start": "2028159",
    "end": "2033880"
  },
  {
    "text": "cheat and make the scheduling easier but with Ray core the aidea was to be able to handle any kind of program well if",
    "start": "2033880",
    "end": "2042000"
  },
  {
    "text": "you're doing that you're you're really kind of Designing a whole distributed scalable computer architecture if you",
    "start": "2042000",
    "end": "2047639"
  },
  {
    "text": "want to be able to run that and that is the uh fundamental intellectual well I should say intellectual property but",
    "start": "2047639",
    "end": "2053358"
  },
  {
    "text": "it's open source it's the intellectual contribution uh that is rayor scheduler",
    "start": "2053359",
    "end": "2058560"
  },
  {
    "text": "and the the ancillary Services a few other pieces like a distributed Object Store uh and a global uh control service",
    "start": "2058560",
    "end": "2066040"
  },
  {
    "text": "which uh handles some metadata that are part of Ray cor now if you're just doing basic AI use cases you may never end up",
    "start": "2066040",
    "end": "2074240"
  },
  {
    "text": "needing to talk to Ray cor so rayor is relatively straightforward to use and",
    "start": "2074240",
    "end": "2080079"
  },
  {
    "text": "it's kind of fun to play with uh and you can do a lot with it but in the effort uh in in an attempt to kind of make",
    "start": "2080079",
    "end": "2086520"
  },
  {
    "text": "things even simpler we're not going to ask you to rewrite your code uh in terms",
    "start": "2086520",
    "end": "2093118"
  },
  {
    "text": "of Ray core entities which are you know schedulable tasks which are stateless schedulable actors which are these",
    "start": "2093119",
    "end": "2099599"
  },
  {
    "text": "stateful class instances distributed objects uh that may be a little bit you know too low level so what we want to do",
    "start": "2099599",
    "end": "2106359"
  },
  {
    "text": "is give you higher level abstractions and that's where the ray AI libraries fit in uh that are up on top there uh so",
    "start": "2106359",
    "end": "2113880"
  },
  {
    "text": "there's a couple of other libraries that aren't even in the picture but the four that are on there are probably the most",
    "start": "2113880",
    "end": "2119240"
  },
  {
    "text": "the ones that are most commonly uh being used today uh so Ray data so what does",
    "start": "2119240",
    "end": "2125079"
  },
  {
    "text": "Ray data do it simplifies uh creating large scale streams of data that you",
    "start": "2125079",
    "end": "2130560"
  },
  {
    "text": "want to do stuff with and we're going to demo that in a minute but the idea is you have some huge pool of data it may",
    "start": "2130560",
    "end": "2136280"
  },
  {
    "text": "be tabular it may be uh it may uh be multimodal you might have images videos",
    "start": "2136280",
    "end": "2142280"
  },
  {
    "text": "it might be different formats and what you need is a way to talk about doing stuff with that data uh that abstracts",
    "start": "2142280",
    "end": "2149440"
  },
  {
    "text": "you away from mechanically loading and splitting it and scaling the computation",
    "start": "2149440",
    "end": "2155000"
  },
  {
    "text": "so we give you high level abstractions to say great grab me this data in you know from here grab me this other data",
    "start": "2155000",
    "end": "2160839"
  },
  {
    "text": "from there uh Union these two things together apply certain Transformations uh and then we're going",
    "start": "2160839",
    "end": "2166720"
  },
  {
    "text": "to use that for maybe training or inference or uh something else uh we've",
    "start": "2166720",
    "end": "2171960"
  },
  {
    "text": "got Ray train so that's the second block on the picture here uh and you probably guess from the name it's about it's",
    "start": "2171960",
    "end": "2178599"
  },
  {
    "text": "about training models and the probably the most interesting thing about Ray train is that it works with existing",
    "start": "2178599",
    "end": "2186560"
  },
  {
    "text": "model framework to make the scaling easier and the integration easier but it doesn't replace those other Frameworks",
    "start": "2186560",
    "end": "2194200"
  },
  {
    "text": "so if you're using hugging face today or you're using p torch today the idea",
    "start": "2194200",
    "end": "2199760"
  },
  {
    "text": "isn't that you throw that out and use Ray train instead it's that you use Ray train with your pytorch training code",
    "start": "2199760",
    "end": "2208000"
  },
  {
    "text": "and Ray train makes it easier to scale that out to integrate it with your data flow to integrate it with tuning jobs uh",
    "start": "2208000",
    "end": "2216040"
  },
  {
    "text": "and uh take advantage of all that Hardware in that more efficient way that we uh referenced earlier uh the third",
    "start": "2216040",
    "end": "2223280"
  },
  {
    "text": "block on here Ray tune so this is around hyper pram optimization or hyper pram",
    "start": "2223280",
    "end": "2229200"
  },
  {
    "text": "tuning uh and again this is about integrating with uh approaches that you already know and use so from simple",
    "start": "2229200",
    "end": "2236319"
  },
  {
    "text": "things like grid search and random search uh to more sophisticated schedulers for things like basian",
    "start": "2236319",
    "end": "2242599"
  },
  {
    "text": "optimization uh using things like optuna and hyper opt uh and you know you being",
    "start": "2242599",
    "end": "2250000"
  },
  {
    "text": "able to accommodate the the more sophisticated uh tuning algorithms that",
    "start": "2250000",
    "end": "2255119"
  },
  {
    "text": "were using today uh and be able to again orchestrate that and get maximum use out",
    "start": "2255119",
    "end": "2260880"
  },
  {
    "text": "of uh the resources you've got uh and tuning the models that you're working on",
    "start": "2260880",
    "end": "2266319"
  },
  {
    "text": "and then the last block here is rayer so I uh talked a little bit just a few",
    "start": "2266319",
    "end": "2271720"
  },
  {
    "text": "moments back about how you may have workloads that are not about training a model or about doing some batch",
    "start": "2271720",
    "end": "2277520"
  },
  {
    "text": "inference or transformation of data uh but creating some long running service that may do simple or maybe you know",
    "start": "2277520",
    "end": "2284119"
  },
  {
    "text": "complex flow of things uh and so Ray has apis specifically designed uh to",
    "start": "2284119",
    "end": "2290880"
  },
  {
    "text": "integrate with all the rest of these pieces and provide scalable uh scalable low latency uh",
    "start": "2290880",
    "end": "2298400"
  },
  {
    "text": "componentized Services they're easy easy to develop easy to you know reuse the",
    "start": "2298400",
    "end": "2303560"
  },
  {
    "text": "code you have uh and then the any scale Service uh adds a little bit of more operational bulletproofing on top of the",
    "start": "2303560",
    "end": "2310280"
  },
  {
    "text": "ray serve services so let's get down we're about I",
    "start": "2310280",
    "end": "2316480"
  },
  {
    "text": "guess we a little more than halfway through so let's let's try and get into some code here um there's a little uh",
    "start": "2316480",
    "end": "2321880"
  },
  {
    "text": "diagram here that captures a little more about Ray data train tune and serve in",
    "start": "2321880",
    "end": "2326960"
  },
  {
    "text": "terms of where they fit into uh kind of like the textbook uh AI or machine",
    "start": "2326960",
    "end": "2333040"
  },
  {
    "text": "learning life cycle that we probably need to do some data processing first and maybe some featurization uh we may",
    "start": "2333040",
    "end": "2340040"
  },
  {
    "text": "use that data to do some training we may uh run some tuning over the models that",
    "start": "2340040",
    "end": "2346079"
  },
  {
    "text": "we're training and then ultimately we may serve those models so there's other things that we might do um but this is",
    "start": "2346079",
    "end": "2352720"
  },
  {
    "text": "uh kind of another way of thinking about where these AI libraries fit into a typical ml life cycle what I want to do",
    "start": "2352720",
    "end": "2360800"
  },
  {
    "text": "here today in terms of code because we don't want to you know in a short webinar like this we don't have time to",
    "start": "2360800",
    "end": "2366119"
  },
  {
    "text": "get into something really really complex uh if we were to try to do something",
    "start": "2366119",
    "end": "2371359"
  },
  {
    "text": "really complex like fine-tune a large language model we would end up hand waving and just saying well you know it all kind of is in this black box and you",
    "start": "2371359",
    "end": "2378000"
  },
  {
    "text": "know push go and then I'll show you what the end result looks like and that's not very convincing what I'd like to do is",
    "start": "2378000",
    "end": "2384319"
  },
  {
    "text": "um show you the actual code so we're going to use a slightly simpler example so this is a tabular data example based",
    "start": "2384319",
    "end": "2390760"
  },
  {
    "text": "on the New York City Taxi Cab data set so this is a pretty large data set that you may have come across before it's one",
    "start": "2390760",
    "end": "2397200"
  },
  {
    "text": "of the bigger kind of open tabular data sets that people use for you know benchmarking and testing uh and like it",
    "start": "2397200",
    "end": "2403960"
  },
  {
    "text": "uh like the the title says it's it's a data set of rides from uh New York City",
    "start": "2403960",
    "end": "2410160"
  },
  {
    "text": "you know Commercial Ride operators and for each ride there's a bunch of features uh that we can use to uh you",
    "start": "2410160",
    "end": "2416520"
  },
  {
    "text": "know potentially model uh create some kind of a model so in this particular data set and since the text here is",
    "start": "2416520",
    "end": "2423319"
  },
  {
    "text": "smaller than the slides I'm going to zoom in a little more see if we can make this a little bigger for everybody uh",
    "start": "2423319",
    "end": "2430440"
  },
  {
    "text": "so um the data set uh features that were that are present here and you may be",
    "start": "2430440",
    "end": "2436119"
  },
  {
    "text": "already familiar with these from from other work is you know the number of passengers in a particular ride uh the",
    "start": "2436119",
    "end": "2441800"
  },
  {
    "text": "trip distance so how far the ride went the fair amount so the price the trip",
    "start": "2441800",
    "end": "2446920"
  },
  {
    "text": "duration so how long it took uh the hour and the day of week which represent when",
    "start": "2446920",
    "end": "2452240"
  },
  {
    "text": "the trip started so was it Monday at 11: a.m. or was it Friday night at 11 p.m.",
    "start": "2452240",
    "end": "2458440"
  },
  {
    "text": "uh and then is big tip which is a flag of whether the tip amount was greater than 20% so for our little demo example",
    "start": "2458440",
    "end": "2466480"
  },
  {
    "text": "here today we're going to try and model these rides to predict whether a ride uh gets a big tip so I guess if you're you",
    "start": "2466480",
    "end": "2473480"
  },
  {
    "text": "know working maybe as a a ride share driver in New York uh it might be useful",
    "start": "2473480",
    "end": "2479359"
  },
  {
    "text": "to have a predictive model like this well to the extent that you can pick your rides it might be nice to be able to pick ones where you're going to get a",
    "start": "2479359",
    "end": "2485160"
  },
  {
    "text": "big tip uh and how does the workflow that we're going to do map to the ray AI",
    "start": "2485160",
    "end": "2491640"
  },
  {
    "text": "libraries so up here on the top you can say you can see it says Ray air component so air is uh kind of a a",
    "start": "2491640",
    "end": "2498240"
  },
  {
    "text": "slightly older packaging of these AI libraries it's the same libraries but just a little bit different arrangement",
    "start": "2498240",
    "end": "2503359"
  },
  {
    "text": "of the packaging um and what we're going to do is we're going to use Ray data to ingest and transform the data in our",
    "start": "2503359",
    "end": "2509920"
  },
  {
    "text": "case we're going to consume it from S3 as a set of parquet data files uh and",
    "start": "2509920",
    "end": "2515200"
  },
  {
    "text": "we're going to do a little bit of splitting to generate a test Set uh with Ray train we're going to do a scaled XG",
    "start": "2515200",
    "end": "2524079"
  },
  {
    "text": "boost model training so we're going to be using real XG boost because like I said Ray is not about replacing these",
    "start": "2524079",
    "end": "2530200"
  },
  {
    "text": "other libraries it's about making it really easy to run them at scale so we're going to run XG boost but we're",
    "start": "2530200",
    "end": "2535640"
  },
  {
    "text": "going to run it with large scale data large scale compute using rate train uh then we're going to demo Ray tune to",
    "start": "2535640",
    "end": "2542680"
  },
  {
    "text": "generate a few different configurations of the model uh to see how they might perform and",
    "start": "2542680",
    "end": "2549559"
  },
  {
    "text": "then we'll demonstrate both the batch inference that's not uh in this little chart but that's we can do that using",
    "start": "2549559",
    "end": "2555440"
  },
  {
    "text": "Ray data and we're also going to demonstrate online or low latency inference with",
    "start": "2555440",
    "end": "2562160"
  },
  {
    "text": "rayer so I'm going to come down here I'm going to run some I'm going to run some",
    "start": "2562359",
    "end": "2569800"
  },
  {
    "text": "imports and then just to give you a little bit of a flavor this is a very compact kind of minimal example but the",
    "start": "2569800",
    "end": "2576200"
  },
  {
    "text": "idea is to show you an endtoend example and give you the flavor of what these",
    "start": "2576200",
    "end": "2581880"
  },
  {
    "text": "apis look like what they're designed to do so Ray data I said is designed to allow you to consume data from lots of",
    "start": "2581880",
    "end": "2588480"
  },
  {
    "text": "places and in lots of formats so here we have this call ray. dat. read par right",
    "start": "2588480",
    "end": "2593720"
  },
  {
    "text": "so in this case it's paret data there's support for lots of other formats uh and we're reading it from S3 so S3 is a",
    "start": "2593720",
    "end": "2601319"
  },
  {
    "text": "storage location again there's lots of other storage locations you could use Ray doesn't care right so Ray is about",
    "start": "2601319",
    "end": "2607160"
  },
  {
    "text": "about um moving and operating on these data sets at scale uh and it doesn't",
    "start": "2607160",
    "end": "2614359"
  },
  {
    "text": "have a strong preference for what flavor your data is in that obviously there are certain formats that work better than",
    "start": "2614359",
    "end": "2619960"
  },
  {
    "text": "others but you know Ray is not going to force you to say translate everything to a particular format and what we end up",
    "start": "2619960",
    "end": "2627319"
  },
  {
    "text": "with is a thing called array data set so AR aray data set is an abstraction for an arbitrarily large collection of data",
    "start": "2627319",
    "end": "2634559"
  },
  {
    "text": "that we may want to do things with so if you've used tools like say Apache spark in the past you may be familiar with",
    "start": "2634559",
    "end": "2641559"
  },
  {
    "text": "other representations for large scale pools of data um that are somewhat",
    "start": "2641559",
    "end": "2646839"
  },
  {
    "text": "similar in that they're designed for maximum performance and unlimited size now Ray data is a little different in",
    "start": "2646839",
    "end": "2653200"
  },
  {
    "text": "terms of how it works um but you can compare it to something like an Apache spark data frame",
    "start": "2653200",
    "end": "2659200"
  },
  {
    "text": "um in terms of uh it's an abstraction not a local you know uh container class",
    "start": "2659200",
    "end": "2665640"
  },
  {
    "text": "instance but an abstract action over a source of data that we're going to process and we can do things with it",
    "start": "2665640",
    "end": "2672640"
  },
  {
    "text": "like do a train test split here so we're going to split this into a train and a",
    "start": "2672640",
    "end": "2678319"
  },
  {
    "text": "test data set and when we run this uh we're not actually uh so it",
    "start": "2678319",
    "end": "2685280"
  },
  {
    "text": "would be nice to say look how fast we ran all this computation but in fact that's not what's going on so like in",
    "start": "2685280",
    "end": "2690640"
  },
  {
    "text": "some of the other tools you may have used we're not actually doing the computation Ray data sets are lazy uh",
    "start": "2690640",
    "end": "2696359"
  },
  {
    "text": "and this is a pattern pattern that exists in lots of these tools the idea is to analyze the data figure out what",
    "start": "2696359",
    "end": "2701559"
  },
  {
    "text": "we can and may be able to uh you know need to do with it uh but not actually",
    "start": "2701559",
    "end": "2706800"
  },
  {
    "text": "move this data until we need to because it's expensive and we be able to do optimizations that save us a bunch of",
    "start": "2706800",
    "end": "2712160"
  },
  {
    "text": "work so we we have kind of um uh objects that represent these streams of data",
    "start": "2712160",
    "end": "2718000"
  },
  {
    "text": "that are ready to go and then maybe we want to train our models so we have a bunch of classes within the ray train",
    "start": "2718000",
    "end": "2726559"
  },
  {
    "text": "packages is that simplify distributed training using different existing Frameworks so XG boost trainer you could",
    "start": "2726559",
    "end": "2734040"
  },
  {
    "text": "probably guess is for XG boost uh we have Trainers for pie torch we have Trainers for hugging face we have",
    "start": "2734040",
    "end": "2739720"
  },
  {
    "text": "Trainers for tensor flow uh and on and on uh that make it fairly simple to uh",
    "start": "2739720",
    "end": "2746960"
  },
  {
    "text": "take either kind of a complete um just a recipe for training like we're going to",
    "start": "2746960",
    "end": "2752359"
  },
  {
    "text": "have here in one second or if you've got existing code so maybe you've already invested a bunch in a training loop with",
    "start": "2752359",
    "end": "2758599"
  },
  {
    "text": "P torch lightning uh or something like that uh you can take that existing training Loop and we can help you scale",
    "start": "2758599",
    "end": "2765920"
  },
  {
    "text": "that so you don't have to throw that away if you've invested in torch lightning uh bunch of you know if you",
    "start": "2765920",
    "end": "2772240"
  },
  {
    "text": "made a big investment in in torch lightning which a lot of firms have done you can basically take that lightning code and just put a little bit of um",
    "start": "2772240",
    "end": "2780119"
  },
  {
    "text": "kind of a little bit of adjustment in pattern and use it together with the ray train trainer uh and get all these",
    "start": "2780119",
    "end": "2785599"
  },
  {
    "text": "scaling benefits and integrate ation to things like Ray data here we've got the xq Boost trainer in terms of",
    "start": "2785599",
    "end": "2791640"
  },
  {
    "text": "configuration we've got things like the label which is what we're trying to predict we've got the pams dictionary",
    "start": "2791640",
    "end": "2797359"
  },
  {
    "text": "which you may be familiar with from XG boost it's like just your standard XG boost configuration course in real life",
    "start": "2797359",
    "end": "2803760"
  },
  {
    "text": "you probably have a much bigger dictionary than just this but this is where you would plug in your your dictionary so those just plug right in",
    "start": "2803760",
    "end": "2810119"
  },
  {
    "text": "here and then we've also got a couple of pieces here that are Ray specific so we've got a scaling config uh in this",
    "start": "2810119",
    "end": "2816960"
  },
  {
    "text": "case we're saying use four workers and don't use GPU but we could just as easily make something that scales larger",
    "start": "2816960",
    "end": "2823480"
  },
  {
    "text": "and does use GPU and we have this whole kind of reified uh thing called scaling",
    "start": "2823480",
    "end": "2829559"
  },
  {
    "text": "config just just for handling scaling uh data sets so we said that these data",
    "start": "2829559",
    "end": "2834640"
  },
  {
    "text": "sets were working with in rare abstractions so we're not going to be passing you know handles to an object",
    "start": "2834640",
    "end": "2840119"
  },
  {
    "text": "we're going to be passing handles to Ray data sets and we may for different kinds of training uh tasks uh we may have",
    "start": "2840119",
    "end": "2847839"
  },
  {
    "text": "multiple data sets so you can pass a dictionary of uh named keys that",
    "start": "2847839",
    "end": "2853000"
  },
  {
    "text": "correspond to Ray data sets and then those can be used either by the algorithm itself like with XG boost or",
    "start": "2853000",
    "end": "2858839"
  },
  {
    "text": "in your own code uh for your own custom Training uh and then a run config and what the run the Run config provides a",
    "start": "2858839",
    "end": "2865359"
  },
  {
    "text": "bunch of things but the most important one and the only one we've put in here today is storage path so uh if you're",
    "start": "2865359",
    "end": "2872200"
  },
  {
    "text": "doing these things at scale across lots of nodes you're going to need at least some shared storage that every node can",
    "start": "2872200",
    "end": "2878559"
  },
  {
    "text": "read and write so uh there's a bunch of ways to do that you can use S3 you can",
    "start": "2878559",
    "end": "2884880"
  },
  {
    "text": "use your own network file system if you're running any scale you get a bunch of um file system uh kind of file",
    "start": "2884880",
    "end": "2893400"
  },
  {
    "text": "systems basically um automagically created for you to use uh",
    "start": "2893400",
    "end": "2900160"
  },
  {
    "text": "that have Scopes related to uh different things you may be doing so the mount",
    "start": "2900160",
    "end": "2905720"
  },
  {
    "text": "cluster storage is a uh storage path that is scoped to your cluster so every",
    "start": "2905720",
    "end": "2911359"
  },
  {
    "text": "note in the cluster can see it but nobody else can see it now when I say things you may be doing that's a little",
    "start": "2911359",
    "end": "2916760"
  },
  {
    "text": "bit vague like if you're working across lots of projects there's a user storage so that's scoped to your user you can",
    "start": "2916760",
    "end": "2924200"
  },
  {
    "text": "always see it uh your personal user account can always see it across all of your workspaces clusters and other",
    "start": "2924200",
    "end": "2930440"
  },
  {
    "text": "things but other users can't see it and then there's you know kind of an organization wide scope there's also a",
    "start": "2930440",
    "end": "2936000"
  },
  {
    "text": "local scope for faster local storage so these are just some kind of like conveniences that you get with uh any",
    "start": "2936000",
    "end": "2942920"
  },
  {
    "text": "scales I'm going to kick off this trainer. fit",
    "start": "2942920",
    "end": "2948200"
  },
  {
    "text": "so uh this follows that kind of dotfit idiom for uh kicking off training and at",
    "start": "2948200",
    "end": "2955240"
  },
  {
    "text": "this point you can see that we're getting some compute output some of it is related to training some of it is",
    "start": "2955240",
    "end": "2961920"
  },
  {
    "text": "actually related to the data set processing so you can see that over here and this just goes back to that lazy",
    "start": "2961920",
    "end": "2967760"
  },
  {
    "text": "computation idea we defined these data sets but we didn't actually need to move the data around and process it until we",
    "start": "2967760",
    "end": "2973880"
  },
  {
    "text": "needed uh needed it for training so when we kick off the training that actually uh requires running some things",
    "start": "2973880",
    "end": "2981040"
  },
  {
    "text": "for uh requires running some things for data processing too uh here you can see the distributed workers for the XG boost",
    "start": "2981040",
    "end": "2988319"
  },
  {
    "text": "in case you're you're not totally sure if they're if they're running uh you you can convince yourself that in fact we do",
    "start": "2988319",
    "end": "2994440"
  },
  {
    "text": "have um four different workers running now in this case just for a Simplicity for the demo here today they're all on",
    "start": "2994440",
    "end": "3000400"
  },
  {
    "text": "the same node so that's why their local ranks are different and their node ranks are all zero but at this point we've got",
    "start": "3000400",
    "end": "3006559"
  },
  {
    "text": "some output from our training and the resulting file that represents the XG",
    "start": "3006559",
    "end": "3012400"
  },
  {
    "text": "boost model is stored uh in the file system and it is actually going to",
    "start": "3012400",
    "end": "3018960"
  },
  {
    "text": "be uh I think it's going to be under this path right here and I can show you how to find that uh where your outputs",
    "start": "3018960",
    "end": "3026240"
  },
  {
    "text": "go now let's demonstrate tune so let's say we want to run a few Trials of training",
    "start": "3026240",
    "end": "3031839"
  },
  {
    "text": "like that uh and we'd like to do some random search sampling different values for max depth so we're going to run uh",
    "start": "3031839",
    "end": "3040359"
  },
  {
    "text": "three trials here where we minimize the validation log loss and you can see that's done pretty",
    "start": "3040359",
    "end": "3047760"
  },
  {
    "text": "much declaratively with this tuner object the tuner plugs onto our trainer",
    "start": "3047760",
    "end": "3052880"
  },
  {
    "text": "which is how it knows what to do and the trainer plugs onto the data so it all connects together uh and we do a tuner",
    "start": "3052880",
    "end": "3059599"
  },
  {
    "text": "do fit and this is going to be launching some trials which you can see in the little HTML dashboard",
    "start": "3059599",
    "end": "3067160"
  },
  {
    "text": "here so I think these are actually finished already yeah because this is you know this is a pretty small demo but",
    "start": "3068160",
    "end": "3073559"
  },
  {
    "text": "these these trials are finished you can see the parameters that were used you can see the results uh and of course",
    "start": "3073559",
    "end": "3079240"
  },
  {
    "text": "these are all reported out uh so you don't have to be having a human look at this stuff it's just for convenience",
    "start": "3079240",
    "end": "3084520"
  },
  {
    "text": "when you're doing a little interactive test thing uh and then the final result ends up um written to a path uh that's",
    "start": "3084520",
    "end": "3092839"
  },
  {
    "text": "going to be under this variable here so you can see after the do fit we've got a call to get best result and the",
    "start": "3092839",
    "end": "3099760"
  },
  {
    "text": "checkpoint so in the ray world the checkpoint is metadata and together with a file path that points to the actual",
    "start": "3099760",
    "end": "3107040"
  },
  {
    "text": "model so let's say we've got a model now and we're happy with this model and we",
    "start": "3107040",
    "end": "3113319"
  },
  {
    "text": "would like to use this model the one we just got from our tuning to do some",
    "start": "3113319",
    "end": "3118559"
  },
  {
    "text": "batch prediction so we can do that using Ray data and we're going to do that by",
    "start": "3118559",
    "end": "3126760"
  },
  {
    "text": "taking a data set in this case we're going to use the validation data set because I don't have a set of additional",
    "start": "3126760",
    "end": "3132240"
  },
  {
    "text": "samples that I want to perform inference on we're going to prepare it for inference by dropping the you know the",
    "start": "3132240",
    "end": "3138760"
  },
  {
    "text": "the target column here the thing we're were trying to predict uh and then we're going to take this data set and we're",
    "start": "3138760",
    "end": "3144400"
  },
  {
    "text": "going to use an API called map batches is which basically says take this data and run it through um a batch at a time",
    "start": "3144400",
    "end": "3152799"
  },
  {
    "text": "through a set of processing that I'm going to Define and this processing is scalable so here I'm saying we're going",
    "start": "3152799",
    "end": "3158079"
  },
  {
    "text": "to have two workers that are doing this work uh this could be a lot more and we",
    "start": "3158079",
    "end": "3163240"
  },
  {
    "text": "could have resources like gpus doing this but it's kind of a simple example I'm defining my inference code in this",
    "start": "3163240",
    "end": "3169720"
  },
  {
    "text": "python class here and this is going to deploy using under the hood some of that",
    "start": "3169720",
    "end": "3174839"
  },
  {
    "text": "Coolray infrastructure called Ray actor so when we're doing inference whether it's lightweight in uh like low latency",
    "start": "3174839",
    "end": "3181799"
  },
  {
    "text": "inference or batch inference we typically have some expensive State we need to set up uh in this case it's",
    "start": "3181799",
    "end": "3188240"
  },
  {
    "text": "loading a model our model here isn't that big but if this were a huge language model it would be pretty expensive and we want to be able to keep",
    "start": "3188240",
    "end": "3194880"
  },
  {
    "text": "this over time so these are not stateless tasks these are things that have state and we want to use that state",
    "start": "3194880",
    "end": "3201520"
  },
  {
    "text": "multiple times so this is one of those uh code patterns that a lot of other",
    "start": "3201520",
    "end": "3206680"
  },
  {
    "text": "Frameworks were just never really designed to handle uh and Ray was you know from the ground up designed for this state full distributed compute so",
    "start": "3206680",
    "end": "3213359"
  },
  {
    "text": "okay somewhere in the cluster we're going to have an instance of offline predictor and it's going to load up a model using regular XG boost code uh",
    "start": "3213359",
    "end": "3221119"
  },
  {
    "text": "from our checkpoint path and it's going to receive batches of data and use uh XG",
    "start": "3221119",
    "end": "3227280"
  },
  {
    "text": "boost and dmatrix apis to produce a vector of predictions and we could have",
    "start": "3227280",
    "end": "3232680"
  },
  {
    "text": "a bunch of these offline predictors running in different places and Ray will make sure that the data gets routed",
    "start": "3232680",
    "end": "3238040"
  },
  {
    "text": "where it needs to go and that those resources are used uh efficiently so if we uh just do a take batch on here we",
    "start": "3238040",
    "end": "3245880"
  },
  {
    "text": "can see that this actually runs and produces uh predictions",
    "start": "3245880",
    "end": "3252040"
  },
  {
    "text": "here so here we've got a vector of predictions that went with a batch of this data and they were processed by our",
    "start": "3252040",
    "end": "3259720"
  },
  {
    "text": "offline predictor so if you look kind of squint closely at the output here you can see that uh there's a little kind of",
    "start": "3259720",
    "end": "3266440"
  },
  {
    "text": "diagram of some of the processing so we had our uh Pro pre-processing to get rid of our um Target column uh then we had",
    "start": "3266440",
    "end": "3274880"
  },
  {
    "text": "our map batches using our offline predictor uh we had a limit because we're only looking at a few of the",
    "start": "3274880",
    "end": "3281040"
  },
  {
    "text": "records and then we actually get some output here so the very last thing I want to demonstrate uh before we wrap up",
    "start": "3281040",
    "end": "3288200"
  },
  {
    "text": "here for today is Ray serve an online inference",
    "start": "3288200",
    "end": "3294680"
  },
  {
    "text": "so uh we're going to again use AR Ray uh AI libraries API that uses Ray core",
    "start": "3294680",
    "end": "3302480"
  },
  {
    "text": "stuff underneath and underneath it's using again a ray cor actor because we want to be able to load up a model and",
    "start": "3302480",
    "end": "3308640"
  },
  {
    "text": "have a have a piece of service logic that stays running in our cluster maybe even lots of them to handle scaling and",
    "start": "3308640",
    "end": "3315440"
  },
  {
    "text": "load balancing and we want Ray to do that we want to provide the code for what each of these little service",
    "start": "3315440",
    "end": "3322079"
  },
  {
    "text": "endpoints looks like and we want Ray to figure out how to scale them wire them",
    "start": "3322079",
    "end": "3327319"
  },
  {
    "text": "together route the data and all of that so we have a class called online predictor that sets up the model using",
    "start": "3327319",
    "end": "3333559"
  },
  {
    "text": "regular XG boost code we have a predict method we can name this whatever we want",
    "start": "3333559",
    "end": "3338599"
  },
  {
    "text": "but it's called predict here that uses regular XG boost to make predictions and",
    "start": "3338599",
    "end": "3344079"
  },
  {
    "text": "then we've got an async uh HTTP uh Handler here and this is kind of",
    "start": "3344079",
    "end": "3350760"
  },
  {
    "text": "an adapter that allows us to handle HTTP requests so there's other ways to do these calls you need to use HTTP but",
    "start": "3350760",
    "end": "3357640"
  },
  {
    "text": "usually there's at least one part of your service that is going to want HTTP uh and this allows us to uh handle",
    "start": "3357640",
    "end": "3364039"
  },
  {
    "text": "regular HTTP requests uh do things like asynchronously collect the payload uh",
    "start": "3364039",
    "end": "3370039"
  },
  {
    "text": "call our prediction logic and return it uh in the appropriate format uh and then",
    "start": "3370039",
    "end": "3375319"
  },
  {
    "text": "we've got an API down here that I've highlighted uh and this is the ray serve",
    "start": "3375319",
    "end": "3380880"
  },
  {
    "text": "API that plugs all of the stuff together so it takes our service class here",
    "start": "3380880",
    "end": "3386760"
  },
  {
    "text": "technically called a deployment uh this piece of functionality uh it sets it up so that Ray can generate multiple",
    "start": "3386760",
    "end": "3393880"
  },
  {
    "text": "instances of this if we need it creates a ray serve application that makes this thing live so I'm going to kick this",
    "start": "3393880",
    "end": "3400520"
  },
  {
    "text": "thing off here and you'll see some output so we've",
    "start": "3400520",
    "end": "3407000"
  },
  {
    "text": "got some stuff starting up here an application is deployed uh this next cell just prepares a data example so",
    "start": "3407000",
    "end": "3414359"
  },
  {
    "text": "from our Ray data set we pull off a single record here and generate a list",
    "start": "3414359",
    "end": "3419599"
  },
  {
    "text": "with just this Json right here just as a demo so that you can see what it looks like to call this service so here we're",
    "start": "3419599",
    "end": "3426000"
  },
  {
    "text": "using plain old HTTP request to a post",
    "start": "3426000",
    "end": "3431039"
  },
  {
    "text": "of this uh Json we're going to post it to this address so um race serve is fast",
    "start": "3431039",
    "end": "3438599"
  },
  {
    "text": "API compatible so these addresses and paths can be in other places but this is a simple default we're going to send it",
    "start": "3438599",
    "end": "3444760"
  },
  {
    "text": "to our predictor we're going to to decode the result and we get a prediction back so this is kind of a",
    "start": "3444760",
    "end": "3451720"
  },
  {
    "text": "minimal endtoend example of showing all of these steps using Ray apis at each",
    "start": "3451720",
    "end": "3458160"
  },
  {
    "text": "step here Ray and Ray AI libraries were providing the scheduling the resource",
    "start": "3458160",
    "end": "3464640"
  },
  {
    "text": "management and the simple uh orchestration but open source libraries",
    "start": "3464640",
    "end": "3470200"
  },
  {
    "text": "that you already know about like XG boost uh like the requests Library here",
    "start": "3470200",
    "end": "3475400"
  },
  {
    "text": "you know they're ating for the purpose of uh doing the actual functionality so you're using stuff that you already know",
    "start": "3475400",
    "end": "3481839"
  },
  {
    "text": "about I'm going to run this cell here to shut down our serve application our serve",
    "start": "3481839",
    "end": "3487960"
  },
  {
    "text": "infrastructure and see we're just about out of time so I want to uh promote a",
    "start": "3487960",
    "end": "3494319"
  },
  {
    "text": "much more in-depth class this is kind of a lightning demo in you know 40 minutes or something like that uh we've got a a",
    "start": "3494319",
    "end": "3501400"
  },
  {
    "text": "a class that is uh about three hours per day for a full week that goes goes in",
    "start": "3501400",
    "end": "3506760"
  },
  {
    "text": "depth on uh all the different areas of Ray uh I have a little slide about that",
    "start": "3506760",
    "end": "3513319"
  },
  {
    "text": "so let me bring this up",
    "start": "3513319",
    "end": "3516960"
  },
  {
    "text": "here so I'll draw your attention right away on the upper right there's 50% off",
    "start": "3519359",
    "end": "3525280"
  },
  {
    "text": "discount code so for you know some for sticking around this whole time we wanted to you know give you something",
    "start": "3525280",
    "end": "3530839"
  },
  {
    "text": "you know not just a chance to sign up for something but uh you know get a real break on going deep so this is a 5-day",
    "start": "3530839",
    "end": "3538359"
  },
  {
    "text": "class 3 hours each day there'll be a break in there somewhere but at three hours uh the online price is $1,500 you",
    "start": "3538359",
    "end": "3546039"
  },
  {
    "text": "can get it for half off with this code right here Ray AI 50 Ray",
    "start": "3546039",
    "end": "3552039"
  },
  {
    "text": "ai5 uh and if you're familiar with some basic AI ML and python tools you're",
    "start": "3552039",
    "end": "3558280"
  },
  {
    "text": "ready to go for this class and it covers Ray in any scale in more depth than I did today uh AI libraries overview like",
    "start": "3558280",
    "end": "3565599"
  },
  {
    "text": "what we did today but again in more depth and then going deeper on Ray train",
    "start": "3565599",
    "end": "3570720"
  },
  {
    "text": "going deeper on Ray data for both inference and data pre-processing and then uh looking at an",
    "start": "3570720",
    "end": "3578160"
  },
  {
    "text": "example use case from some commercial work that any scale did which was stable diffusion pre-training or training a",
    "start": "3578160",
    "end": "3584799"
  },
  {
    "text": "stable diffusion model from scratch at scale using um using Ray and any scale",
    "start": "3584799",
    "end": "3591240"
  },
  {
    "text": "so we're just about out of time here for today it looks like we're we're not going to have",
    "start": "3591240",
    "end": "3596920"
  },
  {
    "text": "um time for Q&A here today but that's okay I hope to see folks uh when we run",
    "start": "3596920",
    "end": "3601960"
  },
  {
    "text": "these more in-depth classes and I hope this session was really useful uh thank you so much for joining us here today",
    "start": "3601960",
    "end": "3611079"
  }
]
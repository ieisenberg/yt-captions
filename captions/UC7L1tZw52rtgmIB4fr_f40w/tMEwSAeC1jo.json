[
  {
    "text": "oh we're good thank you for coming everyone today we're going to talk about kubrey which is a kubernetes ray",
    "start": "5060",
    "end": "11820"
  },
  {
    "text": "clustering solution let's first start by introducing ourselves my name is Ali kanso I'm a",
    "start": "11820",
    "end": "17580"
  },
  {
    "text": "principal engineer at Microsoft and we use Ray as part of a product called Bonsai which is a machine teaching as a",
    "start": "17580",
    "end": "24060"
  },
  {
    "text": "service and at the heart of it we use reinforcement learning and we use array our lab for that purpose and my",
    "start": "24060",
    "end": "30779"
  },
  {
    "text": "colleague here is jashin this is Joshi I'm from binance infrastructure team uh",
    "start": "30779",
    "end": "37680"
  },
  {
    "text": "binance has a portfolio of applications uh in over 150 markets and 35 languages",
    "start": "37680",
    "end": "46260"
  },
  {
    "text": "with almost 2 billion monthly active users and Ai and machine learning are",
    "start": "46260",
    "end": "52020"
  },
  {
    "text": "the heart of the binance technology so Ray is being used in those research",
    "start": "52020",
    "end": "57960"
  },
  {
    "text": "scenarios in with the special focus on some domains like graph and batch",
    "start": "57960",
    "end": "63719"
  },
  {
    "text": "prediction for ads and search yes that's it hand over to Ali thank you",
    "start": "63719",
    "end": "69000"
  },
  {
    "text": "so just as acknowledgments cube is an open source project we want to thank any scale team Dmitry Philip the others that",
    "start": "69000",
    "end": "77340"
  },
  {
    "text": "really helped us with it all the contributors we have roughly 40 of them now and all of those supporting this",
    "start": "77340",
    "end": "83400"
  },
  {
    "text": "work in general so shout out to all of you and thank you for your support So today we're going to talk about the",
    "start": "83400",
    "end": "89520"
  },
  {
    "text": "machine learning Frameworks and how machine learning is distributed in a generic way which requires a generic",
    "start": "89520",
    "end": "95820"
  },
  {
    "text": "framework and a generic solution for that framework that brings us to kubernetes operators and then we",
    "start": "95820",
    "end": "101400"
  },
  {
    "text": "introduce kubrey and after that we go into the new features of kubrey and we",
    "start": "101400",
    "end": "106439"
  },
  {
    "text": "finish with the future plans so starting with machine learning today",
    "start": "106439",
    "end": "111659"
  },
  {
    "text": "we've heard it many times over machine learning is omnipresent there's a recent study done like two years ago from 2018",
    "start": "111659",
    "end": "118740"
  },
  {
    "text": "to 2020 there has been 14 000 Journal papers on machine learning and its",
    "start": "118740",
    "end": "124200"
  },
  {
    "text": "application and this is not just academic work so if we look in practice",
    "start": "124200",
    "end": "129319"
  },
  {
    "text": "The Edge devices where machine learning models are being deployed where inference is happening those are wide",
    "start": "129319",
    "end": "136379"
  },
  {
    "text": "scaly deployed right now so to give an example a Raspberry Pi 4",
    "start": "136379",
    "end": "141599"
  },
  {
    "text": "has now quad core at eight gigabytes of RAM that used to be considered like a",
    "start": "141599",
    "end": "148500"
  },
  {
    "text": "full-fledged laptop device or workstation and now it's simply just an edge device if we look at the car a car",
    "start": "148500",
    "end": "156300"
  },
  {
    "text": "is considered an edge device and the car has 100 million lines of code on it a",
    "start": "156300",
    "end": "163560"
  },
  {
    "text": "Tesla self-driving car has 150 million lines of code so to put things in perspective Linux",
    "start": "163560",
    "end": "170340"
  },
  {
    "text": "kernel has like 28 million lines of code in GitHub so your car now has like",
    "start": "170340",
    "end": "175500"
  },
  {
    "text": "equivalent of four Linux operating systems running on it so to do inference and to deploy machine learning on the",
    "start": "175500",
    "end": "181560"
  },
  {
    "text": "edge is very feasible today it's very doable now the thing is machine learning is still very compute intensive if we",
    "start": "181560",
    "end": "188879"
  },
  {
    "text": "think of hyper parameter tuning matrix multiplication and so on by Nature training is compute intensive and how do",
    "start": "188879",
    "end": "197159"
  },
  {
    "text": "we usually handle or mitigate this uh this compute intensive workload we go to",
    "start": "197159",
    "end": "203959"
  },
  {
    "text": "set we go to distributed deployment models so basically when we",
    "start": "203959",
    "end": "210300"
  },
  {
    "text": "think about distributed machine learning there's no single solution for it it can",
    "start": "210300",
    "end": "215580"
  },
  {
    "text": "be a centralized approach like with ensembling we can train on a subset of data and when it's time for prediction",
    "start": "215580",
    "end": "221760"
  },
  {
    "text": "we can just do aggregation or we can do for example with parameter servers we",
    "start": "221760",
    "end": "227400"
  },
  {
    "text": "can do decentralized type of distribution so basically we need a generic distributed machine learning",
    "start": "227400",
    "end": "233580"
  },
  {
    "text": "framework for that and this is where the Ray solution comes into the picture",
    "start": "233580",
    "end": "240060"
  },
  {
    "text": "so Ray basically has two things going on for it first it's a universal framework for",
    "start": "240060",
    "end": "245819"
  },
  {
    "text": "distributed computing which means it can handle a variety of workloads and the",
    "start": "245819",
    "end": "250860"
  },
  {
    "text": "second thing is it's an ecosystem so you there are many libraries that you can integrate and run on Ray and that gives",
    "start": "250860",
    "end": "258540"
  },
  {
    "text": "you the versatility of running distributed workloads for different machine learnings there now the thing is",
    "start": "258540",
    "end": "264960"
  },
  {
    "text": "if Ray is handling distributed computing house Ray itself deployed and this",
    "start": "264960",
    "end": "270540"
  },
  {
    "text": "brings us to the architecture of Rey so at the very high level we have Ray",
    "start": "270540",
    "end": "276419"
  },
  {
    "text": "distinguishes between head node and the worker node so the head node is the one",
    "start": "276419",
    "end": "281639"
  },
  {
    "text": "that will have the global control store and the worker nodes will at runtime when they instantiated they",
    "start": "281639",
    "end": "289259"
  },
  {
    "text": "will registered with that head node and be the head node would be aware of their presence now each node can have a worker",
    "start": "289259",
    "end": "298440"
  },
  {
    "text": "and here we distinguish between a worker node and the worker so when we say node what we mean by node is it this is just",
    "start": "298440",
    "end": "306240"
  },
  {
    "text": "a compute Computing environment so it could be a virtual machine it could be a physical machine it could be a Linux",
    "start": "306240",
    "end": "312960"
  },
  {
    "text": "container that's what we mean by a node now a worker is just a way of executing",
    "start": "312960",
    "end": "319500"
  },
  {
    "text": "workloads and this is just the right terminology there now if we go a bit deeper into this so",
    "start": "319500",
    "end": "326580"
  },
  {
    "text": "this is just a simple example we're showing here four tasks that we are defining in our code now those tasks are",
    "start": "326580",
    "end": "333360"
  },
  {
    "text": "going to be deployed on Ray workers Ray workers are executing array nodes and",
    "start": "333360",
    "end": "339479"
  },
  {
    "text": "the question is here who's managing the ray cluster itself who's scheduling the worker nodes who's",
    "start": "339479",
    "end": "345720"
  },
  {
    "text": "scheduling the head node who's taking care of cleaning up the cluster when we're done who's taking off upgrading",
    "start": "345720",
    "end": "351600"
  },
  {
    "text": "the cluster and so on and this brings us to where we want to deploy our cluster",
    "start": "351600",
    "end": "356940"
  },
  {
    "text": "and today we're going to talk about kubernetes because ideally what we want",
    "start": "356940",
    "end": "362039"
  },
  {
    "text": "is to have a Computing platform that's capable of handling not only the",
    "start": "362039",
    "end": "368100"
  },
  {
    "text": "scalability of machine learning workloads but also the scalability of Ray itself and here we chose kubernetes",
    "start": "368100",
    "end": "375900"
  },
  {
    "text": "mainly because it's a already battle tested architecture so kubernetes is the",
    "start": "375900",
    "end": "381780"
  },
  {
    "text": "de facto container management platform at Microsoft we run Microsoft Office 365",
    "start": "381780",
    "end": "389160"
  },
  {
    "text": "on kubernetes we have over 200 million monthly users for that we run GitHub",
    "start": "389160",
    "end": "395400"
  },
  {
    "text": "apis Microsoft teams over 100 Azure Services run on kubernetes and AKs more",
    "start": "395400",
    "end": "404520"
  },
  {
    "text": "specifically now the way kubernetes works is as a user",
    "start": "404520",
    "end": "409979"
  },
  {
    "text": "you really don't have to understand this architecture that I'm showing here you just have to provide the control plane",
    "start": "409979",
    "end": "415740"
  },
  {
    "text": "with the desired State and then you would have controllers that are relentlessly trying to make sure the",
    "start": "415740",
    "end": "422220"
  },
  {
    "text": "desired State and the actual state are the same now the unit of scheduling and",
    "start": "422220",
    "end": "427560"
  },
  {
    "text": "kubernetes is a pod and the Pod is just one or more containers a container is",
    "start": "427560",
    "end": "433620"
  },
  {
    "text": "just an instance of a container image at runtime now if kubernetes is capable of scheduling",
    "start": "433620",
    "end": "441300"
  },
  {
    "text": "pods and containers does it know how to schedule array clusters and the answer is no kubernetes has no notion of what's",
    "start": "441300",
    "end": "448919"
  },
  {
    "text": "a head node what's a worker node how they should be instantiated and how they should start up",
    "start": "448919",
    "end": "455099"
  },
  {
    "text": "so this brings us to kubray so kubrey is specifically there to extend kubernetes",
    "start": "455099",
    "end": "461340"
  },
  {
    "text": "with the knowledge of something that we call array cluster so kubernetes does not know what array cluster is we extend",
    "start": "461340",
    "end": "467699"
  },
  {
    "text": "it with the ray operator and with some custom resource definitions and the ray",
    "start": "467699",
    "end": "473099"
  },
  {
    "text": "operator is simply an extension think of it of kubernetes that understands what",
    "start": "473099",
    "end": "478500"
  },
  {
    "text": "array cluster is and at runtime it can create update delete and so on with Ray",
    "start": "478500",
    "end": "483660"
  },
  {
    "text": "clusters so if we dig a bit different to the operator the operator mainly interface",
    "start": "483660",
    "end": "491340"
  },
  {
    "text": "interfaces with the kubernetes API server so basically it has that interface we can logically and emphasize",
    "start": "491340",
    "end": "498660"
  },
  {
    "text": "on logically here so split that interface into three different parts there's the part that watches for user",
    "start": "498660",
    "end": "506039"
  },
  {
    "text": "events so if the user creates a red cluster definition or updates it or",
    "start": "506039",
    "end": "511199"
  },
  {
    "text": "deletes it the operator is watching for those events and reacting on them the second interface is the operator trying",
    "start": "511199",
    "end": "519779"
  },
  {
    "text": "to create the ray cluster artifacts those are the pods the services at runtime and making sure that the",
    "start": "519779",
    "end": "527339"
  },
  {
    "text": "desired State and the actual state are the same finally things can happen at runtime a bot for example can fail and",
    "start": "527339",
    "end": "534480"
  },
  {
    "text": "the operator is listening to those events so it's listening to Cluster failures and reacting to them so when we",
    "start": "534480",
    "end": "540540"
  },
  {
    "text": "put all those together we get kubrey which is the solution for managing gray clusters at runtime now the question is",
    "start": "540540",
    "end": "548839"
  },
  {
    "text": "why not just use a kubernetes deployment I mean array cluster is just a group of",
    "start": "548839",
    "end": "554880"
  },
  {
    "text": "PODS a kubernetes deployment or stateful set that's also a group of PODS so why",
    "start": "554880",
    "end": "560160"
  },
  {
    "text": "not just use what's already supported by kubernetes natively now there are many reasons why we don't do that I just",
    "start": "560160",
    "end": "566459"
  },
  {
    "text": "listed a few of them here first of all we can have multiple worker groups within the same array cluster and group",
    "start": "566459",
    "end": "574680"
  },
  {
    "text": "work group is a is a notation that we that we are we're defining in the kubray",
    "start": "574680",
    "end": "582000"
  },
  {
    "text": "and basically within one cluster you can have different groups of workers some group of workers may have maybe using",
    "start": "582000",
    "end": "589440"
  },
  {
    "text": "gpus others may not so they can have different resource requirements and you",
    "start": "589440",
    "end": "594600"
  },
  {
    "text": "can Define that as a configuration at runtime the second thing is with worker",
    "start": "594600",
    "end": "601019"
  },
  {
    "text": "groups you can scale them up and down and in kubernetes deployment so for",
    "start": "601019",
    "end": "606120"
  },
  {
    "text": "example scaling up and down with the horizontal pod Auto scalar it's done randomly especially scaling down so",
    "start": "606120",
    "end": "613339"
  },
  {
    "text": "kubernetes will just randomly choose a pod and it will go ahead and remove that",
    "start": "613339",
    "end": "619740"
  },
  {
    "text": "POD at runtime in our case this is not acceptable because we don't want to just",
    "start": "619740",
    "end": "625140"
  },
  {
    "text": "remove a random pod we want to remove a pod where we have no actors and no tasks",
    "start": "625140",
    "end": "630360"
  },
  {
    "text": "executing so it's not based on just resource utilization CPU and memory we",
    "start": "630360",
    "end": "636000"
  },
  {
    "text": "have other criterias here at play and kubernet United's deployment does not allow us to do that and finally we have",
    "start": "636000",
    "end": "642060"
  },
  {
    "text": "that order of instantiation so the headboard needs to start first it needs",
    "start": "642060",
    "end": "648420"
  },
  {
    "text": "to be ready and then the worker pods can go ahead and register afterwards and",
    "start": "648420",
    "end": "653579"
  },
  {
    "text": "connect to the headphone so for all those reasons a simple kubernetes deployment cannot do the job and we need",
    "start": "653579",
    "end": "659820"
  },
  {
    "text": "a smarter workload manager that's capable of doing that so if we look at the cluster Creation in",
    "start": "659820",
    "end": "666959"
  },
  {
    "text": "kubernetes by the array operator uh it starts by reading a cluster configuration",
    "start": "666959",
    "end": "672540"
  },
  {
    "text": "it generates the headboard parameters creates the headboard creates the head",
    "start": "672540",
    "end": "677940"
  },
  {
    "text": "service generates worker Port parameters wait until the headboard is ready and then the worker containers will be",
    "start": "677940",
    "end": "685860"
  },
  {
    "text": "created and this is the logic followed every time you create a dubray with",
    "start": "685860",
    "end": "690899"
  },
  {
    "text": "kubrey a ray cluster at runtime now we talked about",
    "start": "690899",
    "end": "696600"
  },
  {
    "text": "kubrey under the hood how it's working the thing is from a user perspective",
    "start": "696600",
    "end": "702360"
  },
  {
    "text": "you really don't need to know about any of the things I just talked about from user perspective you're defining array",
    "start": "702360",
    "end": "708839"
  },
  {
    "text": "cluster either as a yaml Json file and you can use cubes TL to deploy it you",
    "start": "708839",
    "end": "714540"
  },
  {
    "text": "can use the CLI or any kubernetes client python golang c-sharp Etc or you can just create a template for a",
    "start": "714540",
    "end": "722700"
  },
  {
    "text": "more configurable way of deployment and just use Helm in order to deploy your a cluster so from a user perspective you",
    "start": "722700",
    "end": "730140"
  },
  {
    "text": "really don't know that the cube Ray operator exists you don't need to know it's just there in a",
    "start": "730140",
    "end": "736980"
  },
  {
    "text": "kubernetes cluster and it can handle your requests now if we look at the configuration how",
    "start": "736980",
    "end": "743760"
  },
  {
    "text": "it looks like for a ray cluster we basically have two different",
    "start": "743760",
    "end": "749600"
  },
  {
    "text": "pod templates one of them would be for the head pod we're defining what type of",
    "start": "749600",
    "end": "755220"
  },
  {
    "text": "image we want to use what type of configuration we want to pass for it and then we have the ray workers and then",
    "start": "755220",
    "end": "761279"
  },
  {
    "text": "the ray workers there's a big distinction here which is the minimum and maximum number of replicas so you",
    "start": "761279",
    "end": "767820"
  },
  {
    "text": "can Define as many replicas As You Wish For Your Ray workers and the second thing is the worker group specs it's an",
    "start": "767820",
    "end": "775019"
  },
  {
    "text": "array so it's not just a single instance meaning that you can have different worker groups each worker group can have",
    "start": "775019",
    "end": "781139"
  },
  {
    "text": "its own resources different CPU limits memory limits and so on so basically it",
    "start": "781139",
    "end": "787260"
  },
  {
    "text": "allows you to configure your cluster to your liking and then you can update that cluster at runtime",
    "start": "787260",
    "end": "794100"
  },
  {
    "text": "let me go to a very quick demo here so what you're seeing is simply a cube CTL",
    "start": "794100",
    "end": "799680"
  },
  {
    "text": "create command and we're just passing a yaml file for it and on the my right",
    "start": "799680",
    "end": "805139"
  },
  {
    "text": "hand side you will see that now we have a cluster created the head is running the workers are waiting they are in an",
    "start": "805139",
    "end": "811560"
  },
  {
    "text": "init State and after that they will be initializing and running you can also",
    "start": "811560",
    "end": "817440"
  },
  {
    "text": "see that we have a head service that's abstracting the head pod and all of that all of this process it kind of happens",
    "start": "817440",
    "end": "824660"
  },
  {
    "text": "within less than 10 seconds so and then next slide I'm going to show some",
    "start": "824660",
    "end": "829740"
  },
  {
    "text": "experimental results and in this particular case we had two different groups we have a medium group and a",
    "start": "829740",
    "end": "835620"
  },
  {
    "text": "small group the small group has three instances the medium group has one instance and this is how easy it is for",
    "start": "835620",
    "end": "841920"
  },
  {
    "text": "a user to set up array cluster it's just a cube style create command passing some",
    "start": "841920",
    "end": "847079"
  },
  {
    "text": "yaml file so in terms of performance there are different things happening",
    "start": "847079",
    "end": "852839"
  },
  {
    "text": "some of them happening in parallel but the time to for kubernetes to react to the creation is roughly 600 milliseconds",
    "start": "852839",
    "end": "860100"
  },
  {
    "text": "time to create the head service and for the head service to be in the DNS that's",
    "start": "860100",
    "end": "865680"
  },
  {
    "text": "right to appear in the DNS that's roughly one to two seconds we have the head creation time which is three to",
    "start": "865680",
    "end": "874019"
  },
  {
    "text": "four seconds and then when the head is created the workers will come up and be ready and that's again like five to six",
    "start": "874019",
    "end": "880320"
  },
  {
    "text": "seconds so in total you can just assume that a cluster creation will take roughly 10 seconds you should account",
    "start": "880320",
    "end": "886139"
  },
  {
    "text": "for it and from there on you would have a qbre cluster we would have array",
    "start": "886139",
    "end": "891660"
  },
  {
    "text": "cluster managed by kubray up and running and you can update it you can add nodes",
    "start": "891660",
    "end": "897300"
  },
  {
    "text": "you can remove nodes from it you can delete it uh all of that happening at runtime all",
    "start": "897300",
    "end": "903779"
  },
  {
    "text": "of that could be happening with kubernetes cubes TL you can use other tools if needed and all of this would be",
    "start": "903779",
    "end": "910560"
  },
  {
    "text": "happening for the user without the user being aware that there is an operator and there is kubray running in the",
    "start": "910560",
    "end": "916560"
  },
  {
    "text": "background so next we're going to talk about the new features in version 0.3 of",
    "start": "916560",
    "end": "923279"
  },
  {
    "text": "kubray we're going to talk about the community plans and this is the part where jashin joshin and I have been",
    "start": "923279",
    "end": "931380"
  },
  {
    "text": "working for lafree a year on an open source project and this is the beauty of of community Gathering like this like",
    "start": "931380",
    "end": "939240"
  },
  {
    "text": "we're not in the same company but we meet every week we collaborate every week and we have a common interest in",
    "start": "939240",
    "end": "946260"
  },
  {
    "text": "seeing this becoming a very successful project suggestion great",
    "start": "946260",
    "end": "952019"
  },
  {
    "text": "uh yeah but by the way uh we just officially released uh 0.3 last week we",
    "start": "952019",
    "end": "957720"
  },
  {
    "text": "got uh 24 uh contributors in the country built over uh 140 PRS and to uh",
    "start": "957720",
    "end": "964380"
  },
  {
    "text": "accomplish the goal and that's a great Community efforts as uh Ali mentioned",
    "start": "964380",
    "end": "969839"
  },
  {
    "text": "um so the first part we would like to talk about the auto scouting Auto scaling actually has been added to 0.2",
    "start": "969839",
    "end": "976199"
  },
  {
    "text": "uh and but at that time it's not that stable and the recall part doesn't have the solid integration we use specific",
    "start": "976199",
    "end": "983519"
  },
  {
    "text": "version to support Auto scaling but now in 0.3 it's stable and we expose more",
    "start": "983519",
    "end": "989279"
  },
  {
    "text": "like configurations on the auto scaling side rig can actually uh manage automatically",
    "start": "989279",
    "end": "996540"
  },
  {
    "text": "manage underlying resources based on your application Matrix the uh through",
    "start": "996540",
    "end": "1001940"
  },
  {
    "text": "the auto scaler so this is a critical important and important component so in",
    "start": "1001940",
    "end": "1009320"
  },
  {
    "text": "the integration here we enabled the option for users to specify whether you",
    "start": "1009320",
    "end": "1014420"
  },
  {
    "text": "like to enable other scholar or not if so you will see in your clusters there will be a new component added which is",
    "start": "1014420",
    "end": "1020779"
  },
  {
    "text": "the auto scalar so I'll explain how it works how we make it work",
    "start": "1020779",
    "end": "1025780"
  },
  {
    "text": "from a recluster manage management perspective the integration has some",
    "start": "1025780",
    "end": "1034040"
  },
  {
    "text": "challenges the challenge is more on the splitting the responsibilities of the",
    "start": "1034040",
    "end": "1039079"
  },
  {
    "text": "life cycle management and auto scaling so we actually make this uh through uh",
    "start": "1039079",
    "end": "1044959"
  },
  {
    "text": "some uh like mechanism to clearly Define the boundary of the auto scalar",
    "start": "1044959",
    "end": "1051020"
  },
  {
    "text": "component and the recluster component so the life cycle management will only take",
    "start": "1051020",
    "end": "1056240"
  },
  {
    "text": "responsible for managing those nodes for example like adding nodes or deleting uh",
    "start": "1056240",
    "end": "1061400"
  },
  {
    "text": "I don't knows but the auto scholar side you need to read the metrics from the",
    "start": "1061400",
    "end": "1066559"
  },
  {
    "text": "monitoring system which is provided by Ray itself and then make the decision",
    "start": "1066559",
    "end": "1071780"
  },
  {
    "text": "whether I like to add some nodes to the cluster or delete some I don't know some",
    "start": "1071780",
    "end": "1077480"
  },
  {
    "text": "Target I don't knows so the boundary is very clear which makes the architecture very clean and the straightforward I'll",
    "start": "1077480",
    "end": "1084320"
  },
  {
    "text": "use the following example to explain more details from the cold perspective",
    "start": "1084320",
    "end": "1089539"
  },
  {
    "text": "that's what we it to implement this uh like kubrey Auto scholar provider so in the",
    "start": "1089539",
    "end": "1097880"
  },
  {
    "text": "recall part there is a interface called node provider and this is the like",
    "start": "1097880",
    "end": "1103880"
  },
  {
    "text": "wrapper of those like Cloud apis if you see the implementations we'll notice",
    "start": "1103880",
    "end": "1109700"
  },
  {
    "text": "like there's a AWS Solutions and gcp solutions so we add a kubernetes uh part",
    "start": "1109700",
    "end": "1116299"
  },
  {
    "text": "uh kubernetes operator provider to place a similar roles but the different part",
    "start": "1116299",
    "end": "1121760"
  },
  {
    "text": "is in AWS actually the no provider interact with the cloud API directly for",
    "start": "1121760",
    "end": "1127400"
  },
  {
    "text": "example I add an instance then it calls the ec2 API to add a like Target instance but in kubernetes since we talk",
    "start": "1127400",
    "end": "1134780"
  },
  {
    "text": "about the boundaries and the responsibilities here right it's just used to update the kubernetes results",
    "start": "1134780",
    "end": "1142460"
  },
  {
    "text": "the custom results it's just tell the customer results okay what's the desired State and the rest of the process will",
    "start": "1142460",
    "end": "1149240"
  },
  {
    "text": "be automatically hand handled by the re-operator itself",
    "start": "1149240",
    "end": "1154900"
  },
  {
    "text": "so I'll give a like example how it works the diagram is",
    "start": "1155360",
    "end": "1161000"
  },
  {
    "text": "from a Dimitri Dimitri gave a talk this the like Ray Meetup to explain the how",
    "start": "1161000",
    "end": "1169160"
  },
  {
    "text": "Auto scaling works here so I borrowed the diagram so imagine the user when",
    "start": "1169160",
    "end": "1174559"
  },
  {
    "text": "user want to submit the workflows in this case let's say it requires four gpus the workload required for gpus and",
    "start": "1174559",
    "end": "1181640"
  },
  {
    "text": "when it stopped me to the cluster the rig hat will uh we have the mechanism to",
    "start": "1181640",
    "end": "1187400"
  },
  {
    "text": "detect okay the cluster doesn't have enough resource and then if a Water",
    "start": "1187400",
    "end": "1193360"
  },
  {
    "text": "Resource request with four gpus to the re-auto scaler and what a real Auto",
    "start": "1193360",
    "end": "1199940"
  },
  {
    "text": "scalar does is it will do some uh like calculation run some algorithms to check",
    "start": "1199940",
    "end": "1205160"
  },
  {
    "text": "okay uh like uh what how many nodes we needed and what type of the node we",
    "start": "1205160",
    "end": "1210440"
  },
  {
    "text": "needed and then it will patch the cooperate it will patch the recluster",
    "start": "1210440",
    "end": "1217100"
  },
  {
    "text": "custom resource uh that's what we talked the kubrey node uh provider plays a role",
    "start": "1217100",
    "end": "1224240"
  },
  {
    "text": "it patch the results say okay I need a extra like a replica of the target node",
    "start": "1224240",
    "end": "1230720"
  },
  {
    "text": "group and the query operator side uh will wash the resources any changes on",
    "start": "1230720",
    "end": "1237320"
  },
  {
    "text": "the cluster once it detects there's a change on the cluster side it will uh it",
    "start": "1237320",
    "end": "1242360"
  },
  {
    "text": "will uh take the action to scale up in this case we will add a node with four",
    "start": "1242360",
    "end": "1248179"
  },
  {
    "text": "uh four CPUs and add to the cluster and once the node is ready then the the",
    "start": "1248179",
    "end": "1255380"
  },
  {
    "text": "original workload we submit to the cluster can be scheduled uh the second uh like important feature",
    "start": "1255380",
    "end": "1263000"
  },
  {
    "text": "we deliver in 0.3 is for tolerance uh so people actually can um enable some um",
    "start": "1263000",
    "end": "1270020"
  },
  {
    "text": "like uh higher available bank and storage for example ha Radix cluster uh",
    "start": "1270020",
    "end": "1276980"
  },
  {
    "text": "to uh use that for the GCS server so that means uh once you use the ha bank",
    "start": "1276980",
    "end": "1284539"
  },
  {
    "text": "and and some annotations like I specified a highlight here like ft",
    "start": "1284539",
    "end": "1289820"
  },
  {
    "text": "enabled then the kubri controller will add the remix prop and live news prop to",
    "start": "1289820",
    "end": "1295340"
  },
  {
    "text": "the Head node so that means the underneath the recluster will watch all the events uh from those like props the",
    "start": "1295340",
    "end": "1303320"
  },
  {
    "text": "props will detect the local Ray dashboard agent and really to check",
    "start": "1303320",
    "end": "1308960"
  },
  {
    "text": "whether the hapload is in healthy state or not if not it will delete it will",
    "start": "1308960",
    "end": "1314299"
  },
  {
    "text": "kill the head and recreate the instance your data won't be lost because if you",
    "start": "1314299",
    "end": "1319820"
  },
  {
    "text": "enable able the high available Bank hand then the GCS kind of becomes State place",
    "start": "1319820",
    "end": "1324980"
  },
  {
    "text": "so all your cluster data is there so that's a very big Improvement on the",
    "start": "1324980",
    "end": "1330200"
  },
  {
    "text": "recluster stability so that's the two major features we",
    "start": "1330200",
    "end": "1336020"
  },
  {
    "text": "delivered then we talk about the workloads uh so the first one is the redrop we introduced a new Uh custom",
    "start": "1336020",
    "end": "1343520"
  },
  {
    "text": "resource in in this release imagine how you submit the workflows against the",
    "start": "1343520",
    "end": "1348980"
  },
  {
    "text": "remote cluster in the past we create the cluster get the endpoint and then we feed the real address into the re-init",
    "start": "1348980",
    "end": "1356480"
  },
  {
    "text": "method and then run the program it's like a client mode because the driver",
    "start": "1356480",
    "end": "1362059"
  },
  {
    "text": "itself runs out of outside of the cluster redrop actually has been introduced in",
    "start": "1362059",
    "end": "1368780"
  },
  {
    "text": "uh Records since 1.9 it solves the problem like you can it provides the",
    "start": "1368780",
    "end": "1375260"
  },
  {
    "text": "light mechanism user can package and submit your workloads manage your",
    "start": "1375260",
    "end": "1380539"
  },
  {
    "text": "applications as jobs so that's pretty helpful because you can stop in the entire driver program inside the cluster",
    "start": "1380539",
    "end": "1387860"
  },
  {
    "text": "there's no client anymore well the trick is saying is the users still need to provision cluster and then submit the",
    "start": "1387860",
    "end": "1395000"
  },
  {
    "text": "workflows in two steps this can be definitely addressed by some orchestration tools but with additional",
    "start": "1395000",
    "end": "1401240"
  },
  {
    "text": "efforts what we did here in cooperate is that we make it serverless user can just",
    "start": "1401240",
    "end": "1407780"
  },
  {
    "text": "provide a redrop manifest you can type the application configurations and the",
    "start": "1407780",
    "end": "1414740"
  },
  {
    "text": "cluster resource requirements then cooperate controller will automatically",
    "start": "1414740",
    "end": "1420200"
  },
  {
    "text": "handle all the life cycle stuff for you if we check the pseudo code here it",
    "start": "1420200",
    "end": "1425840"
  },
  {
    "text": "creates a cluster and submit the jobs and periodically check the job status",
    "start": "1425840",
    "end": "1430940"
  },
  {
    "text": "and the report to the to the custom resource and after the job is down the",
    "start": "1430940",
    "end": "1437780"
  },
  {
    "text": "cluster resources will be released automatically is the I think that's the perfect way to run redrops on kubernetes",
    "start": "1437780",
    "end": "1446240"
  },
  {
    "text": "another critical features provided a by zero loss rate is reserve I think",
    "start": "1446240",
    "end": "1452059"
  },
  {
    "text": "Theresa may have the dedicated session for this part the overall idea is very similar so resource is the perfect way",
    "start": "1452059",
    "end": "1458840"
  },
  {
    "text": "to run uh reserve on kubernetes uh because it shaped a lot of like features",
    "start": "1458840",
    "end": "1465559"
  },
  {
    "text": "for example like house checking uh like status updating upgrade Etc I think",
    "start": "1465559",
    "end": "1471919"
  },
  {
    "text": "everything is automated people can interact with your own applications on",
    "start": "1471919",
    "end": "1476960"
  },
  {
    "text": "the on the kubernetes and a lot of configurations can be updated in flight for example if you upgrade the auto",
    "start": "1476960",
    "end": "1483919"
  },
  {
    "text": "scaling config for your inference servers everything is automated another powerful tool is the the deployment",
    "start": "1483919",
    "end": "1491659"
  },
  {
    "text": "graph you can build a very complex inference graph in single",
    "start": "1491659",
    "end": "1498039"
  },
  {
    "text": "resurfaced so that helps you solve the like microservice typologies automatically",
    "start": "1498039",
    "end": "1504740"
  },
  {
    "text": "okay let's talk about the community efforts and the future plans so currently there's two uh communities uh",
    "start": "1504740",
    "end": "1511700"
  },
  {
    "text": "adopt uh cooperate and they have a very solid use case the first one is the coupon which is the open source the",
    "start": "1511700",
    "end": "1518240"
  },
  {
    "text": "machine learning orchestration solution natively natively designed on kubernetes",
    "start": "1518240",
    "end": "1523600"
  },
  {
    "text": "in the POC work uh code flow uh baked the cooperate manifested in the",
    "start": "1523600",
    "end": "1531380"
  },
  {
    "text": "distribution so that means you that is deployed with other core components like",
    "start": "1531380",
    "end": "1536840"
  },
  {
    "text": "code flow pipelines there are training operators card Etc so cool flow users can use interact",
    "start": "1536840",
    "end": "1542960"
  },
  {
    "text": "with real clusters in their isolated multi-tenant notebook development",
    "start": "1542960",
    "end": "1548120"
  },
  {
    "text": "environment that's a very good supplement to the cool floor ecosystem a flight is distributed uh like engine",
    "start": "1548120",
    "end": "1556240"
  },
  {
    "text": "especially for those like machine learning workflows and data processing",
    "start": "1556240",
    "end": "1561500"
  },
  {
    "text": "workflows and the flight provides a solution to orchestrate your machine",
    "start": "1561500",
    "end": "1567260"
  },
  {
    "text": "learning pipelines so they implement the task plugin so that means all the",
    "start": "1567260",
    "end": "1572299"
  },
  {
    "text": "complexities to run real applications which is solved by group rate they encapsulate those pieces in their task",
    "start": "1572299",
    "end": "1578659"
  },
  {
    "text": "plugin so that means whenever you build a pipeline people can use the like spark",
    "start": "1578659",
    "end": "1584900"
  },
  {
    "text": "for data processing and then rest of the AI process hand over them to Rey using",
    "start": "1584900",
    "end": "1591320"
  },
  {
    "text": "the task plugin so that has been released already",
    "start": "1591320",
    "end": "1597580"
  },
  {
    "text": "okay in next release I think we'll concentrate on uh improving the uh some",
    "start": "1597580",
    "end": "1603980"
  },
  {
    "text": "stability of the alpha features like the redrop and the reserve and also reduce",
    "start": "1603980",
    "end": "1610039"
  },
  {
    "text": "the barrier for users to adopt the cooperate including like documentations uh docs like examples and deployment",
    "start": "1610039",
    "end": "1618400"
  },
  {
    "text": "like those tutorials and dogs and there's another few interesting features",
    "start": "1618400",
    "end": "1625279"
  },
  {
    "text": "we plan to do that's early stage like proposals like the plugin to scale up",
    "start": "1625279",
    "end": "1631279"
  },
  {
    "text": "and down the note groups and some node field over Handler and also some Jupiter",
    "start": "1631279",
    "end": "1638539"
  },
  {
    "text": "lab plugin to further reduce the gaps between the operations and like the",
    "start": "1638539",
    "end": "1645919"
  },
  {
    "text": "development yes that's all the update from my site yes thank you guys",
    "start": "1645919",
    "end": "1652520"
  },
  {
    "text": "foreign",
    "start": "1652520",
    "end": "1655520"
  },
  {
    "text": "hello thank you guys for your presentation and Community work so I",
    "start": "1666620",
    "end": "1672260"
  },
  {
    "text": "have a question about uh images that you create for note",
    "start": "1672260",
    "end": "1677539"
  },
  {
    "text": "worker notes so each use case have a particular requirements for tensorflow",
    "start": "1677539",
    "end": "1682880"
  },
  {
    "text": "of libraries or so on so do you do um maintain those images",
    "start": "1682880",
    "end": "1690159"
  },
  {
    "text": "separately and specify it in the configuration file or you do it through",
    "start": "1690159",
    "end": "1696679"
  },
  {
    "text": "like a raid job to install like Google libraries and so on and the second question is",
    "start": "1696679",
    "end": "1702620"
  },
  {
    "text": "uh garbage collection so you rely on users to create clusters but do they also have to like garbage collect their",
    "start": "1702620",
    "end": "1709640"
  },
  {
    "text": "clusters after they're done thank you thank you yeah so for your first question there are two ways of doing",
    "start": "1709640",
    "end": "1715940"
  },
  {
    "text": "things one way is to consider the default tray image as just as a base image and then from there do a",
    "start": "1715940",
    "end": "1723679"
  },
  {
    "text": "multi-stage Docker build and add your own image or your own application to that image and then use that one here so",
    "start": "1723679",
    "end": "1730400"
  },
  {
    "text": "the cube Ray does not really understand that this is a pure Cube image or array",
    "start": "1730400",
    "end": "1737120"
  },
  {
    "text": "image versus your own image that's built on top of that image for example in our use case we",
    "start": "1737120",
    "end": "1743720"
  },
  {
    "text": "we bake our application with the on top of the array image and we just use that",
    "start": "1743720",
    "end": "1749539"
  },
  {
    "text": "now another alternative is what you exactly just mentioned is just build a generic gray cluster and submit rate",
    "start": "1749539",
    "end": "1755240"
  },
  {
    "text": "jobs to this cluster and that's how your application can done on there you have",
    "start": "1755240",
    "end": "1760520"
  },
  {
    "text": "the second question about garbage collection and today we rely on the user",
    "start": "1760520",
    "end": "1766100"
  },
  {
    "text": "common sense to clean up their clusters after but uh",
    "start": "1766100",
    "end": "1771760"
  },
  {
    "text": "I don't know there might be something in there like specify a germination or expiration period for the",
    "start": "1771760",
    "end": "1778760"
  },
  {
    "text": "cluster that might be a flag that we can provide if if we see there's a lot of",
    "start": "1778760",
    "end": "1784539"
  },
  {
    "text": "uncollected clusters that are just laying there doing nothing yeah",
    "start": "1784539",
    "end": "1790460"
  },
  {
    "text": "actually I think that's probably the only question we can take the next session is going to come in 15 minutes but I think the speakers will be around",
    "start": "1790460",
    "end": "1797360"
  },
  {
    "text": "for questions after the talk so feel free to talk so thank you everyone for attending give a run of Applause for our",
    "start": "1797360",
    "end": "1803299"
  },
  {
    "text": "speakers [Applause]",
    "start": "1803299",
    "end": "1807619"
  }
]
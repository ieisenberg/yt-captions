[
  {
    "text": "okay I'm gonna start um so hi guys I'm sang bin from any scale and here's my",
    "start": "4140",
    "end": "9179"
  },
  {
    "text": "colleague Ricky um we're going to present radio observability present and future",
    "start": "9179",
    "end": "15179"
  },
  {
    "text": "so let me have a brief introduction about ourselves oh we are both software engineers at any scale",
    "start": "15179",
    "end": "20640"
  },
  {
    "text": "um we are working on Ray core which is building the ray core distributed systems and our recent focus is to",
    "start": "20640",
    "end": "26100"
  },
  {
    "text": "improve the ray observability um that you probably many of you already have complaints yeah",
    "start": "26100",
    "end": "33059"
  },
  {
    "text": "hahaha and also we are from any scale um any scale is a creator of Rey and we are",
    "start": "33059",
    "end": "40079"
  },
  {
    "text": "building scalable compute for AI and python okay so if you're interested in how to",
    "start": "40079",
    "end": "45780"
  },
  {
    "text": "debug Ray application um what's what tools are actually available for debugging Ray and what's",
    "start": "45780",
    "end": "51239"
  },
  {
    "text": "new in Ray 2.0 and what we're planning to do in the future then this is the talk you're looking for",
    "start": "51239",
    "end": "57180"
  },
  {
    "text": "and here's the outline so we're going to start from the requirements in radio observability and how it looked like",
    "start": "57180",
    "end": "62940"
  },
  {
    "text": "before Ray 2.0 what worked well what didn't and the new feature in Ray 2.0 and we're gonna",
    "start": "62940",
    "end": "69380"
  },
  {
    "text": "have a quick demonstration of all the features and we're gonna finish the presentation of the future roadmap so",
    "start": "69380",
    "end": "76619"
  },
  {
    "text": "let's start from the um the first section requirements in Ray observability so Ray provides apis to or build",
    "start": "76619",
    "end": "83880"
  },
  {
    "text": "distributed applications so this hides the implementation detail of distributed systems and help users to focus on",
    "start": "83880",
    "end": "90659"
  },
  {
    "text": "building applications running a scale without understanding distributed systems",
    "start": "90659",
    "end": "96119"
  },
  {
    "text": "then why is it so hard to difficult Ray um let's see how Ray actually looks like under the hood so there's actually a",
    "start": "96119",
    "end": "102780"
  },
  {
    "text": "head node in the array um when you when you have array there's a head node which is managing the whole cluster and of",
    "start": "102780",
    "end": "109619"
  },
  {
    "text": "course there are a lot of worker nodes that's actually executing your code and then if you actually have large",
    "start": "109619",
    "end": "114840"
  },
  {
    "text": "scale cluster this is how it looks like you're going to have tons of machines there and there are going to be a lot of Ray tasks great activity objects like",
    "start": "114840",
    "end": "122100"
  },
  {
    "text": "stored and running concurrently and executed um across many different machines and this is actually been distributed on",
    "start": "122100",
    "end": "129720"
  },
  {
    "text": "Benchmark we've done before so as you can see we're going we have we can have like a hundred of nodes like tens of",
    "start": "129720",
    "end": "135180"
  },
  {
    "text": "thousands of actors and tasks and they're like millions of objects so it's normal like there are so many things",
    "start": "135180",
    "end": "140640"
  },
  {
    "text": "going on in the cluster and with all this in mind or if imagine actually something went wrong like your",
    "start": "140640",
    "end": "147840"
  },
  {
    "text": "application is not as fast not fast enough it hangs or crashes um and like for example your actor",
    "start": "147840",
    "end": "154440"
  },
  {
    "text": "failed like for manual Vector failed and it's like very very very frustrating um and then you imagine you have to",
    "start": "154440",
    "end": "160560"
  },
  {
    "text": "figure out why why this failed like by Nature distributed system can have so many different failure models because",
    "start": "160560",
    "end": "167040"
  },
  {
    "text": "they have heterogeneous resources many different machines more likely to the failure across them and there are also a",
    "start": "167040",
    "end": "174120"
  },
  {
    "text": "lot of data as you see like test characters objects so debugging issues in this kind of environment is not",
    "start": "174120",
    "end": "179280"
  },
  {
    "text": "trivial and this requires the system to have a really strong support like tools",
    "start": "179280",
    "end": "184319"
  },
  {
    "text": "and other um workflow for you to actually go through to uh or make it debugging easy",
    "start": "184319",
    "end": "191220"
  },
  {
    "text": "so how can we make it still easy with this environment so in our perspective there are two important thing we need to",
    "start": "191220",
    "end": "197280"
  },
  {
    "text": "focus the first thing is we need to understand the workflow so what's the typical workflow user face when they're",
    "start": "197280",
    "end": "202980"
  },
  {
    "text": "um doing debugging and also of course we need to have the right tools to actually uh help you debugging in this",
    "start": "202980",
    "end": "209280"
  },
  {
    "text": "distributed environment oh sorry um so this is the key workflow when you",
    "start": "209280",
    "end": "215940"
  },
  {
    "text": "debug your application so first you want to have the visibility into your application so you need to have the",
    "start": "215940",
    "end": "221519"
  },
  {
    "text": "monitoring and then whenever something goes wrong the error has to surface to",
    "start": "221519",
    "end": "226680"
  },
  {
    "text": "you so there should be the right error or there should be the way to give the signal that something's going wrong and",
    "start": "226680",
    "end": "232200"
  },
  {
    "text": "of course you need to have the right tools and data in the system so you can actually debug when something goes wrong",
    "start": "232200",
    "end": "237599"
  },
  {
    "text": "and the right mitigation strategy or like and the correct guide for you to",
    "start": "237599",
    "end": "242819"
  },
  {
    "text": "fix your issue and then to a support such workflow there must be corresponding tools for",
    "start": "242819",
    "end": "248280"
  },
  {
    "text": "each step so for example when you're monitoring you need to you Pro you may want to have a dashboard that's not as",
    "start": "248280",
    "end": "254340"
  },
  {
    "text": "bad as now but really create one and also progress report or like application Level logs or when you actually surface",
    "start": "254340",
    "end": "261120"
  },
  {
    "text": "error you need to have the right exception models as well as to create error messages and for when you actually",
    "start": "261120",
    "end": "266940"
  },
  {
    "text": "debug you need to have tools like debugger or like a profiler or many other different tools for you to debug",
    "start": "266940",
    "end": "273120"
  },
  {
    "text": "Ray application and we are actually going through how it looked like D4 2.0 um and what we are good at oh and why we",
    "start": "273120",
    "end": "279900"
  },
  {
    "text": "are not so I'm gonna show Two case studies um the first thing is I think pre to",
    "start": "279900",
    "end": "285600"
  },
  {
    "text": "pre-array 2.0 the interactive development is really common on debugging new debugging case like you're",
    "start": "285600",
    "end": "291120"
  },
  {
    "text": "developing something like something's broken you fix it and like interactively um iterate it",
    "start": "291120",
    "end": "297360"
  },
  {
    "text": "and then actual production workload right like your system fail in the middle of your run",
    "start": "297360",
    "end": "302460"
  },
  {
    "text": "and then the first case scenario was actually pretty well so pretty by Ray before 2.0 and I like to go through the",
    "start": "302460",
    "end": "308340"
  },
  {
    "text": "tools we have um that help you this scenario so this is a simple toy area application",
    "start": "308340",
    "end": "315000"
  },
  {
    "text": "um so you create four actors and then you're just calling into all vectors and just getting the result so",
    "start": "315000",
    "end": "320820"
  },
  {
    "text": "pretty typical rate application and this is of course how it looks like in the real world you're going to four",
    "start": "320820",
    "end": "326940"
  },
  {
    "text": "different actors and then think about the first step so you you want to monitor your application",
    "start": "326940",
    "end": "332759"
  },
  {
    "text": "and in the interactive development the most common case is actually um writing logs right you just write print hello",
    "start": "332759",
    "end": "339360"
  },
  {
    "text": "and then you want this hello to be uh coming to you coming to your script standard out",
    "start": "339360",
    "end": "345600"
  },
  {
    "text": "and this is actually really well supported in Rey um so Ray has a native support",
    "start": "345600",
    "end": "351060"
  },
  {
    "text": "um to print logs from test connectors and by default all the standard out and standard error from your test connector",
    "start": "351060",
    "end": "357539"
  },
  {
    "text": "they are basically streamed back to the driver program so this is the example so if you have a print haha or as you see",
    "start": "357539",
    "end": "364800"
  },
  {
    "text": "from the image you can actually see haha from your driver with any shows other metadata like what's the name of task",
    "start": "364800",
    "end": "370919"
  },
  {
    "text": "what's the PID and this is a new feature at Ray 2.0 but",
    "start": "370919",
    "end": "376440"
  },
  {
    "text": "um you also have a very log API to access logo of actors test workers and other system look so for as you can see",
    "start": "376440",
    "end": "382979"
  },
  {
    "text": "from here you just specify the same PID or from the driver and you're actually able to see on the same log through the",
    "start": "382979",
    "end": "389460"
  },
  {
    "text": "CLI API after um after a task is over or actors over okay so now now you can monitor your",
    "start": "389460",
    "end": "396780"
  },
  {
    "text": "application the next thing following our workflow is how do you surface there when you do interactive development and",
    "start": "396780",
    "end": "402720"
  },
  {
    "text": "if you use Python of course the most common case is getting an exception when something fails",
    "start": "402720",
    "end": "408539"
  },
  {
    "text": "so for example you have an actor and there's a print test and let's say you have division by zero error like this",
    "start": "408539",
    "end": "414419"
  },
  {
    "text": "basically what you want is that you want to get this exception in your main program and throw the right exception",
    "start": "414419",
    "end": "420780"
  },
  {
    "text": "and Ray automatically finds the exception from its remote desk and propagate error back to the users and",
    "start": "420780",
    "end": "426660"
  },
  {
    "text": "I'm going to show you how it works so all the array Primitives like a task object connector they generate the",
    "start": "426660",
    "end": "432360"
  },
  {
    "text": "object reference like this and whenever anything goes wrong then the generator like generator",
    "start": "432360",
    "end": "438960"
  },
  {
    "text": "of the object reference so for example in this case like actor whenever actor goes wrong like there's application",
    "start": "438960",
    "end": "444599"
  },
  {
    "text": "failure actors like all of a sudden killed all of this information is automatically written to the reference",
    "start": "444599",
    "end": "450120"
  },
  {
    "text": "and when you actually call rate.get it's going to throw an exception for you so this is the example",
    "start": "450120",
    "end": "456539"
  },
  {
    "text": "um so you can actually see the exception and whenever there's system failure you can see like something like this I think",
    "start": "456539",
    "end": "462599"
  },
  {
    "text": "many of you already know this error message and then now the error is surface now",
    "start": "462599",
    "end": "468780"
  },
  {
    "text": "user wants to debug and Ray I'm going to introduce two tools and the first one",
    "start": "468780",
    "end": "473880"
  },
  {
    "text": "first one is the debugger so debugger is a very common tool when you actually debug the application in Python right so",
    "start": "473880",
    "end": "480720"
  },
  {
    "text": "what you want is you just want to have a breakpoint it's like equivalent command as regular Python and you want to",
    "start": "480720",
    "end": "485940"
  },
  {
    "text": "actually debug the program and Rey has its own distributed debugger",
    "start": "485940",
    "end": "491280"
  },
  {
    "text": "to support this case so when you develop array um you want to have like tools like pdb for you to actually",
    "start": "491280",
    "end": "498180"
  },
  {
    "text": "um get into your code and see the state of your code um interactively and Rey has its own pdb integration to",
    "start": "498180",
    "end": "504840"
  },
  {
    "text": "support distributed debugging so as you can see from here you can just use exactly the same command like just add",
    "start": "504840",
    "end": "510000"
  },
  {
    "text": "the breakpoint and in your terminal you can just call Ray debug and it's going to give you on CLI something like this",
    "start": "510000",
    "end": "516779"
  },
  {
    "text": "and you're able to actually jump through a different task connector and actually go in there and use pdb in there and we",
    "start": "516779",
    "end": "523200"
  },
  {
    "text": "are going to actually have more detailed demonstration um sooner or later",
    "start": "523200",
    "end": "528959"
  },
  {
    "text": "and then lastly your application might be slower than you think for example let's imagine tractors doing some busy",
    "start": "528959",
    "end": "535320"
  },
  {
    "text": "work and returning large objects and then one of your actors is extremely slow and you want to figure out why this",
    "start": "535320",
    "end": "541440"
  },
  {
    "text": "is slow and others is not and so this means like sometimes users",
    "start": "541440",
    "end": "546899"
  },
  {
    "text": "want to trace low level power worker like function level operation to find the bottlenecks in performance and this",
    "start": "546899",
    "end": "553080"
  },
  {
    "text": "is supported by Ray pre 2.0 as well as a rate timeline API so you're able to actually see all the workers and each",
    "start": "553080",
    "end": "559920"
  },
  {
    "text": "worker you can see um how long each operation takes so in this example we have a task and most of tasks store",
    "start": "559920",
    "end": "566459"
  },
  {
    "text": "output took the most of time and it also shows the duration like this so like for 85 milliseconds it was running a task",
    "start": "566459",
    "end": "573480"
  },
  {
    "text": "and out of 85 5 milliseconds it was storing the output meaning you know the bottleneck is storing the output so",
    "start": "573480",
    "end": "580260"
  },
  {
    "text": "you should you can figure out what's the exact problem and of course it had other tools pretty 2.0 on for example we supported metrics",
    "start": "580260",
    "end": "588060"
  },
  {
    "text": "and custom metrics and we have a native integration to Primitives so you're able to actually export the metric and made",
    "start": "588060",
    "end": "594540"
  },
  {
    "text": "it from Ray and create your own graphene dashboard and we also have a experimental distributed tracing which is useful for",
    "start": "594540",
    "end": "601680"
  },
  {
    "text": "application like race serve which is like service based applications and also we had a dashboard",
    "start": "601680",
    "end": "607920"
  },
  {
    "text": "um and I read this word previously didn't have a lot of features so it shows all the",
    "start": "607920",
    "end": "613080"
  },
  {
    "text": "node all the process resources uh you know in real time but um we're going to",
    "start": "613080",
    "end": "618240"
  },
  {
    "text": "show how we're going to improve in the future in the later of this step or later of this presentation",
    "start": "618240",
    "end": "624420"
  },
  {
    "text": "okay so I'm going to take over the talk to Ricky and he's going to talk about what's new in Ray 2.0 all right thanks",
    "start": "624420",
    "end": "631019"
  },
  {
    "text": "and um so sen has given you a kind of overview of what happens before with 2.0",
    "start": "631019",
    "end": "637680"
  },
  {
    "text": "um so Ray has many tools as you're saying but is it sufficient well apparently now right otherwise I won't",
    "start": "637680",
    "end": "642839"
  },
  {
    "text": "be seeing many of you guys here listening to the talk I guess um so it's good for interactive development",
    "start": "642839",
    "end": "649079"
  },
  {
    "text": "rights you can start at your array program you can see the logs you can see the tracing on the dashboard when it",
    "start": "649079",
    "end": "654839"
  },
  {
    "text": "comes to large system what is which is usually what Ray was actually useful for you have like system failures like",
    "start": "654839",
    "end": "660540"
  },
  {
    "text": "hanging out of memory issues right so um at that point of time it's very hard to",
    "start": "660540",
    "end": "665880"
  },
  {
    "text": "debug um and we could actually see you know some like kind of like use case for that so I",
    "start": "665880",
    "end": "671760"
  },
  {
    "text": "have the same actor um and instead of four what if I have like 30 000 actors running and then for",
    "start": "671760",
    "end": "678060"
  },
  {
    "text": "each actor I call them like one of the API like 1000 times right so this essentially gives you a ray program that",
    "start": "678060",
    "end": "685079"
  },
  {
    "text": "has like millions of actor attached running at the same time and one of them you know doesn't really do well and go",
    "start": "685079",
    "end": "691260"
  },
  {
    "text": "out of memory and the OS comes and Q is the actor you will see the error message",
    "start": "691260",
    "end": "696420"
  },
  {
    "text": "all right so um what is I mean I would be like okay wait a minute like which is",
    "start": "696420",
    "end": "702600"
  },
  {
    "text": "the uh which actor died I have like 30 000 there right where do I find the log right even if I see the log like go",
    "start": "702600",
    "end": "708959"
  },
  {
    "text": "through log like what should I do after seeing the lock um so these are the examples that why debugging Ray",
    "start": "708959",
    "end": "715200"
  },
  {
    "text": "um before might have been difficult um and what's worse is that if you have like four running actors like somehow",
    "start": "715200",
    "end": "722160"
  },
  {
    "text": "just didn't get initialized because you don't have that much cluster resources right so they get stuck forever",
    "start": "722160",
    "end": "728940"
  },
  {
    "text": "um and you don't really know that you basically have like very little way to actually inspect the actor States or the",
    "start": "728940",
    "end": "735180"
  },
  {
    "text": "scheduling states of the actor so this is what we worked on for rate 2.0 so we introduced the state API and",
    "start": "735180",
    "end": "742380"
  },
  {
    "text": "also we did a revamp on the Rex options all right so let's look at what the state apis are about so the state API",
    "start": "742380",
    "end": "748920"
  },
  {
    "text": "introduced a couple more apis that are available both in clis and also in Python sdks which gives you an overview",
    "start": "748920",
    "end": "755279"
  },
  {
    "text": "of like the ray states such as object tasks and actors Etc so um",
    "start": "755279",
    "end": "763019"
  },
  {
    "text": "one of the first group of apis are the summer API so the summary API are what",
    "start": "763019",
    "end": "768180"
  },
  {
    "text": "you probably use as the entry point for your debugging right so you could probably run it with you know watch every two seconds you could fetched it",
    "start": "768180",
    "end": "774139"
  },
  {
    "text": "and you this gives you a high overview of yours your states in the rate program",
    "start": "774139",
    "end": "779760"
  },
  {
    "text": "right so see race summary tasks you will see like a bunch of like a number of tasks running what a different tasks",
    "start": "779760",
    "end": "785220"
  },
  {
    "text": "with different names like what stage they are in um and once you have like a high overview that you might want to be like",
    "start": "785220",
    "end": "791519"
  },
  {
    "text": "narrowing down to maybe a specific group of tasks or actors or states right so you could use the list and get apis to",
    "start": "791519",
    "end": "799079"
  },
  {
    "text": "um get information with like filter um and the detail Flags so we'll go through more detail in this um like go",
    "start": "799079",
    "end": "804420"
  },
  {
    "text": "through the output of this later in the demo um so this gives you a sense of like how you should be using the API or",
    "start": "804420",
    "end": "810360"
  },
  {
    "text": "what API could I potentially do cool so other than objects tasks and",
    "start": "810360",
    "end": "815820"
  },
  {
    "text": "actors we also allow you to like query States things like you know workers nodes runtime environments jobs and",
    "start": "815820",
    "end": "821700"
  },
  {
    "text": "placement groups um so we hope this will be the first step for us to bridge the gap between",
    "start": "821700",
    "end": "826800"
  },
  {
    "text": "you know detecting what state your current rate program is um so help hopefully make uh debugging a little bit",
    "start": "826800",
    "end": "832860"
  },
  {
    "text": "easier for you on the rate cluster and another thing that we worked on with",
    "start": "832860",
    "end": "838380"
  },
  {
    "text": "we kind of revamped the rigs options the idea here is to give the users as much information as possible or when",
    "start": "838380",
    "end": "844500"
  },
  {
    "text": "something goes wrong then throw exception right so um our old friends",
    "start": "844500",
    "end": "849540"
  },
  {
    "text": "like a lot of memory issue instead of seeing the previous log that you know I didn't really know how to debug we",
    "start": "849540",
    "end": "855540"
  },
  {
    "text": "actually include the information such as like actor ID when actor died the the note that actor is running on the PID of",
    "start": "855540",
    "end": "862560"
  },
  {
    "text": "the the worker that's running the actor and also the worker access that is right so some potential reasons of why this",
    "start": "862560",
    "end": "868860"
  },
  {
    "text": "might have happened and where you could actually start debugging from right so all the the screenshots you",
    "start": "868860",
    "end": "876720"
  },
  {
    "text": "have saying are crew but we want to give you a real sense of how this works uh so we'll be doing demo that's stitching",
    "start": "876720",
    "end": "882060"
  },
  {
    "text": "together different some of the tools together and in the demo we'll be using um a simple Ray program called website",
    "start": "882060",
    "end": "888600"
  },
  {
    "text": "tracker actor so it's just like toy actor which takes in a bunch of one-dimensional integer array because",
    "start": "888600",
    "end": "894240"
  },
  {
    "text": "you could think them as like data points for you know web page reviewing right",
    "start": "894240",
    "end": "899339"
  },
  {
    "text": "and then the actor will spit out like percentage information like just this some dummy uh computation on it",
    "start": "899339",
    "end": "906660"
  },
  {
    "text": "um yeah let's I will pass the mic to um the meeting last week so um do some",
    "start": "906660",
    "end": "914639"
  },
  {
    "text": "time travel here",
    "start": "914639",
    "end": "917420"
  },
  {
    "text": "and let's get into the demo so I'm currently in a UI developed by any scale",
    "start": "920100",
    "end": "926220"
  },
  {
    "text": "so it has a rate cluster attached to it and I could just read this notes to see",
    "start": "926220",
    "end": "933120"
  },
  {
    "text": "how many nodes I have in the cluster as you can see here it prints out the node ID the IP the state outage note and also",
    "start": "933120",
    "end": "941639"
  },
  {
    "text": "a short summary of the resources each note so I have two nodes with one GPU",
    "start": "941639",
    "end": "947519"
  },
  {
    "text": "each and another note with acps I could run my wrap tracker demonstrate",
    "start": "947519",
    "end": "954060"
  },
  {
    "text": "over here in another terminal so as you can see here it connects to array running cluster and my website",
    "start": "954060",
    "end": "961860"
  },
  {
    "text": "tracker actor is now up and running so I can navigate to my another terminal",
    "start": "961860",
    "end": "967920"
  },
  {
    "text": "and I will open up another IPython notebook and there's notebook I will",
    "start": "967920",
    "end": "973500"
  },
  {
    "text": "connect to the running array cluster as well and retrieve the actor by its name my tracker",
    "start": "973500",
    "end": "980940"
  },
  {
    "text": "so I could add a few sessions of website data to adapter by calling the ass",
    "start": "980940",
    "end": "987360"
  },
  {
    "text": "sessions function on the actor as you can see one page of session data is loaded",
    "start": "987360",
    "end": "993120"
  },
  {
    "text": "and I could also get the percentile information from the data I just added",
    "start": "993120",
    "end": "999079"
  },
  {
    "text": "so now I have a running array program and also have a very running cluster you could use the ray State API to see the",
    "start": "1000139",
    "end": "1008120"
  },
  {
    "text": "internal states of the cluster so one of the sub comments of the ray",
    "start": "1008120",
    "end": "1013459"
  },
  {
    "text": "state apis is free summary so you can use very summary actor",
    "start": "1013459",
    "end": "1019100"
  },
  {
    "text": "so this will give me an overview of the actor because I only have one website",
    "start": "1019100",
    "end": "1024260"
  },
  {
    "text": "tracker actor alive so it doesn't really print out much information I could use the list actor",
    "start": "1024260",
    "end": "1031699"
  },
  {
    "text": "API to drill down so redis actors will give me the actor",
    "start": "1031699",
    "end": "1037220"
  },
  {
    "text": "ID it's name it's that cause if it has already died whether it's a detached",
    "start": "1037220",
    "end": "1042380"
  },
  {
    "text": "actor and the PID of the process is running the actor and also the serialized",
    "start": "1042380",
    "end": "1047900"
  },
  {
    "text": "runtime environment that attached to the actor when I initialized it",
    "start": "1047900",
    "end": "1052899"
  },
  {
    "text": "the reset API also supports basic filtering so I could do previous workers",
    "start": "1053840",
    "end": "1059900"
  },
  {
    "text": "with the dash as flag to see all the live workers",
    "start": "1059900",
    "end": "1066160"
  },
  {
    "text": "so as you can see here I have two driver which corresponds to the two panels on top",
    "start": "1067220",
    "end": "1072260"
  },
  {
    "text": "and I have a watcher which is actually my website tracker actor that's currently running",
    "start": "1072260",
    "end": "1077660"
  },
  {
    "text": "you see the matching key ID here and TV you can also query the different states",
    "start": "1077660",
    "end": "1083840"
  },
  {
    "text": "in ways such as runtime environments placement groups jobs in the interest of time I will not go",
    "start": "1083840",
    "end": "1090500"
  },
  {
    "text": "through them queue another group of comments is the array logs API",
    "start": "1090500",
    "end": "1096799"
  },
  {
    "text": "so you could get all the logs on the handouts by typing rate logs",
    "start": "1096799",
    "end": "1102740"
  },
  {
    "text": "so as you can see the logs that are available are grouped under different categories",
    "start": "1102740",
    "end": "1108020"
  },
  {
    "text": "there's log from the driver there is a log from the GCS server there is log",
    "start": "1108020",
    "end": "1113179"
  },
  {
    "text": "from Reddit and also logs from different workers you can see the logs from a particular",
    "start": "1113179",
    "end": "1118940"
  },
  {
    "text": "file by providing a file handle such as Ray logs python call driver",
    "start": "1118940",
    "end": "1127780"
  },
  {
    "text": "and with the following flag or an optional tail Slack",
    "start": "1128000",
    "end": "1135280"
  },
  {
    "text": "one of the handy trick of Ray logs is you could use the PID of your actor or",
    "start": "1138679",
    "end": "1144679"
  },
  {
    "text": "the actor ID to directly narrow down to a specific actor's loss for example I",
    "start": "1144679",
    "end": "1151640"
  },
  {
    "text": "have my PID here I can do Big Lots PID my website tracker SP ID",
    "start": "1151640",
    "end": "1158720"
  },
  {
    "text": "and I will get the logs from the actor directory so all the apis I talked about from the",
    "start": "1158720",
    "end": "1165260"
  },
  {
    "text": "command line are also available in the python SDK you could import the python",
    "start": "1165260",
    "end": "1171380"
  },
  {
    "text": "SDK API and then call the functions over there so this allows the rate developers to",
    "start": "1171380",
    "end": "1178580"
  },
  {
    "text": "build their own obserability stack on top of the registered API other than the Cris and the python sdks rate also has a",
    "start": "1178580",
    "end": "1186380"
  },
  {
    "text": "built-in dashboard that's really useful for high level information of the cluster so we can navigate to the",
    "start": "1186380",
    "end": "1191840"
  },
  {
    "text": "dashboard as you can see here it has a nice table view of the",
    "start": "1191840",
    "end": "1198919"
  },
  {
    "text": "different notes the actor that's running on the different notes",
    "start": "1198919",
    "end": "1203960"
  },
  {
    "text": "and also has a short overview of the memory sources and disk resources",
    "start": "1203960",
    "end": "1209840"
  },
  {
    "text": "so you could use the dashboard UI to navigate through the logs as well so it provides a nice web interface",
    "start": "1209840",
    "end": "1217400"
  },
  {
    "text": "for you to narrow down into these different logs",
    "start": "1217400",
    "end": "1221860"
  },
  {
    "text": "it also provides basic searching and filtering and time window selections",
    "start": "1223520",
    "end": "1230679"
  },
  {
    "text": "now let's get back to our terminal and I will try to simulate some failures and show you how this will come up in Ray",
    "start": "1231080",
    "end": "1237860"
  },
  {
    "text": "and potentially how you could debug this so I have a code snippet over here that",
    "start": "1237860",
    "end": "1244340"
  },
  {
    "text": "I just copy pasted into my terminal so what it does is basically it goes in the loop then keep adding",
    "start": "1244340",
    "end": "1250820"
  },
  {
    "text": "data to my website tracker onto the point that it wounds and I could also have the monitoring",
    "start": "1250820",
    "end": "1257960"
  },
  {
    "text": "using the state API to see the current stage of my actors so as you can see I",
    "start": "1257960",
    "end": "1264020"
  },
  {
    "text": "have the actor running and stay alive as I kick off my smart routine this will",
    "start": "1264020",
    "end": "1270500"
  },
  {
    "text": "keep adding more data into the actor until you wounds so here you go you see",
    "start": "1270500",
    "end": "1275720"
  },
  {
    "text": "in an error message that pops up telling me that the actor has died and you also see the latest actors shows",
    "start": "1275720",
    "end": "1282679"
  },
  {
    "text": "the error message of the actual activity so it says to actually stats because his",
    "start": "1282679",
    "end": "1288140"
  },
  {
    "text": "worker process has died and it gives you a couple of reasons or suggestions of",
    "start": "1288140",
    "end": "1293480"
  },
  {
    "text": "why this could potentially happens so we could use the rare State API that I just covered to drill down the root",
    "start": "1293480",
    "end": "1300799"
  },
  {
    "text": "cause but sometimes getting a snapshot of the system when an error happens is just not",
    "start": "1300799",
    "end": "1306559"
  },
  {
    "text": "enough and what might be more useful here is time series data that potentially reviews Trends or signals that might be",
    "start": "1306559",
    "end": "1314539"
  },
  {
    "text": "useful to indicate the root cause of an issue so Rey has time series data exported and",
    "start": "1314539",
    "end": "1321200"
  },
  {
    "text": "the users could build their own dashboard on top of those time series data for example the any skill web UI",
    "start": "1321200",
    "end": "1328820"
  },
  {
    "text": "has a grafana dashboard that's built in and let's navigate to the grafana dashboard",
    "start": "1328820",
    "end": "1335679"
  },
  {
    "text": "so as you can see here the dashboard gives me an overview of the cluster the",
    "start": "1335780",
    "end": "1340820"
  },
  {
    "text": "number of number of active nodes and for each type it also has a summary of the resources",
    "start": "1340820",
    "end": "1346700"
  },
  {
    "text": "usage and a few more other detailed information such as the object store the",
    "start": "1346700",
    "end": "1353539"
  },
  {
    "text": "CPU usage and GPU accounts the node memory the GPU memory and Network Speak",
    "start": "1353539",
    "end": "1360860"
  },
  {
    "text": "so red supports more time series data than the dashboards over here",
    "start": "1360860",
    "end": "1366020"
  },
  {
    "text": "and units of Ray could build their own dashboards with customized charts and time series based on their use cases",
    "start": "1366020",
    "end": "1373820"
  },
  {
    "text": "so for our simple script we could see that one of the interesting pattern here is the memory Spike",
    "start": "1373820",
    "end": "1381559"
  },
  {
    "text": "so this is a useful signal to indicate that some part of the system runs out of",
    "start": "1381559",
    "end": "1387260"
  },
  {
    "text": "memory so the grafana dashboard is useful to observe the trends and high",
    "start": "1387260",
    "end": "1392600"
  },
  {
    "text": "level information of our running Ray cluster and sometimes reprogrammers and users",
    "start": "1392600",
    "end": "1398000"
  },
  {
    "text": "will have to dive deeper into their way program to understand what might have happened",
    "start": "1398000",
    "end": "1403220"
  },
  {
    "text": "so Rey has a debugger that I will now show you how to use it so now let's get",
    "start": "1403220",
    "end": "1408679"
  },
  {
    "text": "back to our terminal and I have a debug script over here for",
    "start": "1408679",
    "end": "1414500"
  },
  {
    "text": "demoing the usage of debugger in the script as you can see",
    "start": "1414500",
    "end": "1420260"
  },
  {
    "text": "I have a breakpoint at the add session function not the website tracker actor and if I run this script",
    "start": "1420260",
    "end": "1427580"
  },
  {
    "text": "this will connect to a running array program and it should stop at the breakpoint",
    "start": "1427580",
    "end": "1433159"
  },
  {
    "text": "and it will spin up a remote pdb session for you to be able to connect you so you might not a terminal I can type",
    "start": "1433159",
    "end": "1440120"
  },
  {
    "text": "ready bug and now I see the list of breakpoints",
    "start": "1440120",
    "end": "1446840"
  },
  {
    "text": "that I could stop that so if I get into the first breakpoint and I mean assessments function",
    "start": "1446840",
    "end": "1455120"
  },
  {
    "text": "so you could use all the pdb commands to look around and if I hit continue",
    "start": "1455120",
    "end": "1462620"
  },
  {
    "text": "it will wait for the main program to reach the next breakpoint",
    "start": "1462620",
    "end": "1467659"
  },
  {
    "text": "now I'm at the uh the same breakpoint in the second iterations",
    "start": "1467659",
    "end": "1473360"
  },
  {
    "text": "and I could go into Brickman again and incrementally control how the",
    "start": "1473360",
    "end": "1478460"
  },
  {
    "text": "program is run so with this this marks the end of the demo",
    "start": "1478460",
    "end": "1483799"
  },
  {
    "text": "there are many more other tools that we didn't have enough time to cover so please go to the website for",
    "start": "1483799",
    "end": "1489799"
  },
  {
    "text": "documentation and we look forward to your feedback thank you",
    "start": "1489799",
    "end": "1496240"
  },
  {
    "text": "cool um now let's time travel to now all right so I talk about the future of what",
    "start": "1497360",
    "end": "1504380"
  },
  {
    "text": "happens after a rate 2.0 release so one thing that we know that we're",
    "start": "1504380",
    "end": "1509600"
  },
  {
    "text": "definitely going to work on is the uh the progress report um so this gives you a better view of",
    "start": "1509600",
    "end": "1515000"
  },
  {
    "text": "like how far you are in your great job every program right so how many tasks have finished uh how long each test has",
    "start": "1515000",
    "end": "1521000"
  },
  {
    "text": "been running um so we might work with the UI team to come up with a better uis so you could",
    "start": "1521000",
    "end": "1526700"
  },
  {
    "text": "see this so all these are prototypes so far but they will come true one day hopefully in a couple of months",
    "start": "1526700",
    "end": "1532820"
  },
  {
    "text": "and the second thing is the events right so events are State transition your array programs right for example when",
    "start": "1532820",
    "end": "1539179"
  },
  {
    "text": "your node joins when a node terminates or a task finished or a test fail uh you",
    "start": "1539179",
    "end": "1544279"
  },
  {
    "text": "might want to get a chronological view of all those events coming up in your rape program so that could give you a",
    "start": "1544279",
    "end": "1549559"
  },
  {
    "text": "better sense of like how or what kind of things um the rate program is doing in your cluster",
    "start": "1549559",
    "end": "1556760"
  },
  {
    "text": "and the third thing is better performance profiling right so we will be doing better UI for sure as you can",
    "start": "1556760",
    "end": "1563539"
  },
  {
    "text": "see here and we would do like memory profiling on top of the CPU profiling we currently support it and it would be",
    "start": "1563539",
    "end": "1569120"
  },
  {
    "text": "better um like Pro worker profiling for you to drill down into the individual workers performance",
    "start": "1569120",
    "end": "1574820"
  },
  {
    "text": "um and last but not least uh the better bad dashboard right so I've been talking to",
    "start": "1574820",
    "end": "1581179"
  },
  {
    "text": "many of you guys in the past two days of the dashboard definitely needs some love we actually had a team is wrapping up",
    "start": "1581179",
    "end": "1587059"
  },
  {
    "text": "the other UI and the user study so we have like prototypes that adds in more dashboards and charts into the existing",
    "start": "1587059",
    "end": "1593659"
  },
  {
    "text": "dashboard and we might also be doing some architecture changes to the dashboard so that it may you'll be more reliable and scalable so this will be",
    "start": "1593659",
    "end": "1601100"
  },
  {
    "text": "one of our top priority moving forward and stay tuned for this",
    "start": "1601100",
    "end": "1606140"
  },
  {
    "text": "um so in conclusion um before we 2.0 we have some tooling",
    "start": "1606140",
    "end": "1611419"
  },
  {
    "text": "that's suitable for interactive development but there is still a gap between a production debugging",
    "start": "1611419",
    "end": "1616520"
  },
  {
    "text": "experiences for users so we recognize and we also want to make the first step or one of the initial like steps to",
    "start": "1616520",
    "end": "1623659"
  },
  {
    "text": "bring state apis to brings to bridge the gap um to make it better and of course",
    "start": "1623659",
    "end": "1628820"
  },
  {
    "text": "we know there's a long way to go from here and greater obserability will always be the top priority for the red",
    "start": "1628820",
    "end": "1634700"
  },
  {
    "text": "team and we'll continue working on that in the next few months and of course this cannot be achieved without users",
    "start": "1634700",
    "end": "1641720"
  },
  {
    "text": "feedback so please take out your phone and scan a QR code and join our slack Channel and tell us what your what your",
    "start": "1641720",
    "end": "1648440"
  },
  {
    "text": "problems you run into what thoughts you have in terms of better observability and thanks to everyone to for sticking",
    "start": "1648440",
    "end": "1654980"
  },
  {
    "text": "with us foreign",
    "start": "1654980",
    "end": "1660260"
  },
  {
    "text": "do we have time for a couple more questions or okay so maybe two more minutes um yeah",
    "start": "1662620",
    "end": "1670159"
  },
  {
    "text": "so if anyone has questions feel free to shoot if not we'll be staying around for a",
    "start": "1670159",
    "end": "1676520"
  },
  {
    "text": "couple minutes on the stage",
    "start": "1676520",
    "end": "1679659"
  },
  {
    "text": "all right I guess uh I guess that's that's it um thanks everyone for oh sorry there's no question yes",
    "start": "1684440",
    "end": "1691720"
  },
  {
    "text": "no UI tracking sorry um you were talking about job completion",
    "start": "1694539",
    "end": "1700760"
  },
  {
    "text": "UI um are there any points to integrate that with like uh was it called Ray",
    "start": "1700760",
    "end": "1707000"
  },
  {
    "text": "workflow that's a great question um so the question is whether we will be",
    "start": "1707000",
    "end": "1713120"
  },
  {
    "text": "integrating that with Ray workflow yeah I think yeah I think eventually we want to help other libraries to build their",
    "start": "1713120",
    "end": "1721159"
  },
  {
    "text": "own UI and stuff using all on this low level like a API so like as you can see",
    "start": "1721159",
    "end": "1727880"
  },
  {
    "text": "um you can group the test connectors and display to the UI and I think workflow I",
    "start": "1727880",
    "end": "1733100"
  },
  {
    "text": "think it depends on like the prior radio workflow team like if they are trying to prioritize it but they'll go from us is",
    "start": "1733100",
    "end": "1740480"
  },
  {
    "text": "to basically make the fundamental API for any library to build on top of so they can actually Implement their own",
    "start": "1740480",
    "end": "1746600"
  },
  {
    "text": "progress bar and display on the dashboard some something like that yeah",
    "start": "1746600",
    "end": "1751539"
  },
  {
    "text": "all right so is there another question over there over there thank you Thomas",
    "start": "1753919",
    "end": "1762460"
  },
  {
    "text": "that was pretty awesome all the debugging tools with the ray CLI does that work if we're we're using kubray",
    "start": "1763640",
    "end": "1770240"
  },
  {
    "text": "well I think it should work when you use cube right yeah okay it's yeah all right good to hear",
    "start": "1770240",
    "end": "1777039"
  },
  {
    "text": "yes over there",
    "start": "1779419",
    "end": "1782559"
  },
  {
    "text": "the metrics that you were showing in grafana there um has there been some thought put into",
    "start": "1784640",
    "end": "1789919"
  },
  {
    "text": "like good easy ways to programmatically correlate that to the actual workloads",
    "start": "1789919",
    "end": "1795320"
  },
  {
    "text": "that we're running like okay we saw a memory Spike what tasks we're running when that memory Spike occurred like and",
    "start": "1795320",
    "end": "1801380"
  },
  {
    "text": "kind of programmatically get that information yeah definitely I think that comes up in",
    "start": "1801380",
    "end": "1806960"
  },
  {
    "text": "one of like brainstorm sessions for what to do next so something like a ray doctor uh kind of like or advisories or",
    "start": "1806960",
    "end": "1813620"
  },
  {
    "text": "whatsoever but basically as what you describe um I think um we are still kind of building infrastructure for that",
    "start": "1813620",
    "end": "1819559"
  },
  {
    "text": "those data sources um and improving the dashboard like the grafana thing and also potentially",
    "start": "1819559",
    "end": "1825500"
  },
  {
    "text": "correlate that will be we'd like be a future that we support yeah but that that that's definitely a great idea to",
    "start": "1825500",
    "end": "1831799"
  },
  {
    "text": "have and also you're saying adding like a job or like function name on the metrics is",
    "start": "1831799",
    "end": "1838340"
  },
  {
    "text": "it correct yeah I mean uh when you export them in Prometheus I guess being able to tag in",
    "start": "1838340",
    "end": "1845120"
  },
  {
    "text": "some way you know I mean obviously the memory pressure is at like the node level but if you could at least like tag",
    "start": "1845120",
    "end": "1850640"
  },
  {
    "text": "it in some way to know what was running around this time or something like that right yeah I think yeah definitely",
    "start": "1850640",
    "end": "1856159"
  },
  {
    "text": "you're we want to support that I think there's like a cardinality problem in metrics usually like when you have like",
    "start": "1856159",
    "end": "1863120"
  },
  {
    "text": "so many different tasks if you like threat each individual task it might like have two high cardinality but I",
    "start": "1863120",
    "end": "1869539"
  },
  {
    "text": "think what we're thinking is we want to or allow you to do that but maybe you should be able to like turn it on and",
    "start": "1869539",
    "end": "1875600"
  },
  {
    "text": "off or depending on your use case yeah yeah I think we should just like pass the high level application tag into the",
    "start": "1875600",
    "end": "1882440"
  },
  {
    "text": "lower level metric sporting um so that the matches will have those like high level jobs information",
    "start": "1882440",
    "end": "1888740"
  },
  {
    "text": "good idea um sorry I guess we run out of time but we'll be like sticking around for a",
    "start": "1888740",
    "end": "1894860"
  },
  {
    "text": "couple more minutes and thanks everyone for coming in and staying late for uh until this time and hope to see you at",
    "start": "1894860",
    "end": "1901700"
  },
  {
    "text": "the next Summit thank you",
    "start": "1901700",
    "end": "1904840"
  }
]
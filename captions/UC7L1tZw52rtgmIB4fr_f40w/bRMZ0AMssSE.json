[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "thank you and thank you all so much for",
    "start": "3040",
    "end": "4640"
  },
  {
    "text": "being here",
    "start": "4640",
    "end": "5520"
  },
  {
    "text": "it's thrilling to see how much the",
    "start": "5520",
    "end": "6960"
  },
  {
    "text": "community has grown recently",
    "start": "6960",
    "end": "9280"
  },
  {
    "text": "i'd like to talk a little bit about the",
    "start": "9280",
    "end": "10800"
  },
  {
    "text": "growth we've seen in the rey community",
    "start": "10800",
    "end": "12960"
  },
  {
    "text": "i'll say a bit about what makes rey",
    "start": "12960",
    "end": "14480"
  },
  {
    "text": "special why it's emerging as the tool of",
    "start": "14480",
    "end": "16880"
  },
  {
    "text": "choice for building distributed",
    "start": "16880",
    "end": "18400"
  },
  {
    "text": "applications",
    "start": "18400",
    "end": "19520"
  },
  {
    "text": "and i'll talk a bit about where we're",
    "start": "19520",
    "end": "20960"
  },
  {
    "text": "headed next",
    "start": "20960",
    "end": "23199"
  },
  {
    "start": "23000",
    "end": "23000"
  },
  {
    "text": "we've seen tremendous growth since race",
    "start": "23199",
    "end": "24880"
  },
  {
    "text": "started its life as a research project",
    "start": "24880",
    "end": "26720"
  },
  {
    "text": "at uc berkeley several years ago",
    "start": "26720",
    "end": "28960"
  },
  {
    "text": "the number of contributors has",
    "start": "28960",
    "end": "30400"
  },
  {
    "text": "skyrocketed from a handful of grad",
    "start": "30400",
    "end": "32880"
  },
  {
    "text": "students working together to today we",
    "start": "32880",
    "end": "34800"
  },
  {
    "text": "have over 350 contributors from 75",
    "start": "34800",
    "end": "37680"
  },
  {
    "text": "different companies",
    "start": "37680",
    "end": "39120"
  },
  {
    "text": "and to put that in context you can take",
    "start": "39120",
    "end": "41040"
  },
  {
    "text": "a look at other popular",
    "start": "41040",
    "end": "42239"
  },
  {
    "text": "projects in the ml and system space that",
    "start": "42239",
    "end": "44719"
  },
  {
    "text": "have been around for similar amounts of",
    "start": "44719",
    "end": "46160"
  },
  {
    "text": "time like cube flow",
    "start": "46160",
    "end": "47520"
  },
  {
    "text": "ml flow horovod these are all very",
    "start": "47520",
    "end": "50399"
  },
  {
    "text": "different projects and this gives some",
    "start": "50399",
    "end": "52160"
  },
  {
    "text": "sense of the excitement in the ray",
    "start": "52160",
    "end": "53760"
  },
  {
    "text": "community",
    "start": "53760",
    "end": "55680"
  },
  {
    "start": "55000",
    "end": "55000"
  },
  {
    "text": "and importantly these external",
    "start": "55680",
    "end": "57760"
  },
  {
    "text": "contributions are not",
    "start": "57760",
    "end": "58960"
  },
  {
    "text": "tiny contributions we're talking about",
    "start": "58960",
    "end": "61280"
  },
  {
    "text": "major features like adding support for",
    "start": "61280",
    "end": "63359"
  },
  {
    "text": "new languages",
    "start": "63359",
    "end": "64400"
  },
  {
    "text": "adding a dashboard major refactorings of",
    "start": "64400",
    "end": "66880"
  },
  {
    "text": "the worker code",
    "start": "66880",
    "end": "67840"
  },
  {
    "text": "of the back end support for additional",
    "start": "67840",
    "end": "70000"
  },
  {
    "text": "cloud providers and so on so these are",
    "start": "70000",
    "end": "72479"
  },
  {
    "text": "serious",
    "start": "72479",
    "end": "73040"
  },
  {
    "text": "serious contributions often coming from",
    "start": "73040",
    "end": "75200"
  },
  {
    "text": "companies with multiple people",
    "start": "75200",
    "end": "76960"
  },
  {
    "text": "working to improve ray and that's",
    "start": "76960",
    "end": "79119"
  },
  {
    "text": "something that we look at as a sign of a",
    "start": "79119",
    "end": "80799"
  },
  {
    "text": "strong community",
    "start": "80799",
    "end": "83439"
  },
  {
    "text": "another area where we've seen enormous",
    "start": "83439",
    "end": "85280"
  },
  {
    "text": "growth over the past couple months",
    "start": "85280",
    "end": "87200"
  },
  {
    "text": "is in the ecosystem sitting on top of",
    "start": "87200",
    "end": "89119"
  },
  {
    "text": "rey",
    "start": "89119",
    "end": "90320"
  },
  {
    "text": "some of these are libraries that we",
    "start": "90320",
    "end": "91920"
  },
  {
    "text": "develop as part of rey",
    "start": "91920",
    "end": "93840"
  },
  {
    "text": "others are third-party libraries that",
    "start": "93840",
    "end": "95600"
  },
  {
    "text": "integrate with ray",
    "start": "95600",
    "end": "97360"
  },
  {
    "text": "so two of the first libraries that we",
    "start": "97360",
    "end": "99200"
  },
  {
    "text": "began building were rl lib for",
    "start": "99200",
    "end": "101119"
  },
  {
    "text": "reinforcement learning",
    "start": "101119",
    "end": "102320"
  },
  {
    "text": "and tune for hyper parameter search and",
    "start": "102320",
    "end": "104640"
  },
  {
    "text": "today these are among the most popular",
    "start": "104640",
    "end": "106479"
  },
  {
    "text": "libraries for reinforcement learning",
    "start": "106479",
    "end": "108240"
  },
  {
    "text": "and hyper parameter tuning more recently",
    "start": "108240",
    "end": "111360"
  },
  {
    "text": "we began working on libraries for model",
    "start": "111360",
    "end": "113200"
  },
  {
    "text": "serving deploying models in production",
    "start": "113200",
    "end": "115200"
  },
  {
    "text": "and distributed training these are at a",
    "start": "115200",
    "end": "117439"
  },
  {
    "text": "much earlier stage",
    "start": "117439",
    "end": "118640"
  },
  {
    "text": "and you'll hear more about all of these",
    "start": "118640",
    "end": "120079"
  },
  {
    "text": "different libraries throughout the",
    "start": "120079",
    "end": "121280"
  },
  {
    "text": "summit",
    "start": "121280",
    "end": "122399"
  },
  {
    "text": "of course the really exciting part of",
    "start": "122399",
    "end": "124320"
  },
  {
    "text": "the growth is the what the growth we've",
    "start": "124320",
    "end": "126320"
  },
  {
    "text": "seen in third party libraries built on",
    "start": "126320",
    "end": "128160"
  },
  {
    "text": "top of ray",
    "start": "128160",
    "end": "129920"
  },
  {
    "text": "hyperopt and optuna two of the most",
    "start": "129920",
    "end": "132000"
  },
  {
    "text": "popular hyperparameter tuning libraries",
    "start": "132000",
    "end": "134319"
  },
  {
    "text": "both integrate with ray tune for",
    "start": "134319",
    "end": "135760"
  },
  {
    "text": "hyperparameter search",
    "start": "135760",
    "end": "137680"
  },
  {
    "text": "spacey and hugging face two of the most",
    "start": "137680",
    "end": "139760"
  },
  {
    "text": "popular libraries for natural language",
    "start": "139760",
    "end": "141360"
  },
  {
    "text": "processing",
    "start": "141360",
    "end": "142160"
  },
  {
    "text": "integrate with ray to scale up training",
    "start": "142160",
    "end": "143840"
  },
  {
    "text": "to multiple gpus and to tune and deploy",
    "start": "143840",
    "end": "146319"
  },
  {
    "text": "your hugging face models and you'll hear",
    "start": "146319",
    "end": "148400"
  },
  {
    "text": "book talks from both of these libraries",
    "start": "148400",
    "end": "151440"
  },
  {
    "text": "you can scale training with horovod and",
    "start": "151440",
    "end": "153280"
  },
  {
    "text": "pytorch on your raycluster",
    "start": "153280",
    "end": "154879"
  },
  {
    "text": "and use them with ray tune and serve and",
    "start": "154879",
    "end": "156959"
  },
  {
    "text": "you'll hear more in the horivod talk",
    "start": "156959",
    "end": "159680"
  },
  {
    "text": "dasc is a popular python distributed",
    "start": "159680",
    "end": "161599"
  },
  {
    "text": "system with a great data frame library",
    "start": "161599",
    "end": "163680"
  },
  {
    "text": "there have been some recent community",
    "start": "163680",
    "end": "165120"
  },
  {
    "text": "contributions that allow you to run desk",
    "start": "165120",
    "end": "166879"
  },
  {
    "text": "applications on rey",
    "start": "166879",
    "end": "168239"
  },
  {
    "text": "and you'll hear more in the dascon ray",
    "start": "168239",
    "end": "169920"
  },
  {
    "text": "talk",
    "start": "169920",
    "end": "171519"
  },
  {
    "text": "some of the major cloud ml platforms",
    "start": "171519",
    "end": "173440"
  },
  {
    "text": "like aws sagemaker",
    "start": "173440",
    "end": "175120"
  },
  {
    "text": "azure ml integrate with raytune and rlib",
    "start": "175120",
    "end": "178080"
  },
  {
    "text": "for training and reinforcement learning",
    "start": "178080",
    "end": "181040"
  },
  {
    "text": "and you'll also hear from weights and",
    "start": "181040",
    "end": "182720"
  },
  {
    "text": "biases which integrates with ray tune",
    "start": "182720",
    "end": "184879"
  },
  {
    "text": "selden which uses ray for massively",
    "start": "184879",
    "end": "186959"
  },
  {
    "text": "parallel model explainability",
    "start": "186959",
    "end": "188879"
  },
  {
    "text": "mode in and many others so what we're",
    "start": "188879",
    "end": "191680"
  },
  {
    "text": "seeing is that ray is starting to become",
    "start": "191680",
    "end": "193920"
  },
  {
    "text": "the go-to framework not just for scaling",
    "start": "193920",
    "end": "196159"
  },
  {
    "text": "python applications",
    "start": "196159",
    "end": "197440"
  },
  {
    "text": "but for scaling python libraries and of",
    "start": "197440",
    "end": "199920"
  },
  {
    "text": "course",
    "start": "199920",
    "end": "200640"
  },
  {
    "text": "the benefit here is not just that you",
    "start": "200640",
    "end": "202319"
  },
  {
    "text": "can use one of these libraries",
    "start": "202319",
    "end": "204080"
  },
  {
    "text": "but rather that you can use them all",
    "start": "204080",
    "end": "205920"
  },
  {
    "text": "together and pick and choose the",
    "start": "205920",
    "end": "207680"
  },
  {
    "text": "state-of-the-art libraries and combine",
    "start": "207680",
    "end": "209440"
  },
  {
    "text": "them together",
    "start": "209440",
    "end": "210400"
  },
  {
    "text": "in a single application so if you're a",
    "start": "210400",
    "end": "212879"
  },
  {
    "text": "library developer",
    "start": "212879",
    "end": "214000"
  },
  {
    "text": "and are interested in scaling your",
    "start": "214000",
    "end": "215360"
  },
  {
    "text": "library with ray please reach out to us",
    "start": "215360",
    "end": "217519"
  },
  {
    "text": "on the ray slack we'd absolutely love to",
    "start": "217519",
    "end": "219440"
  },
  {
    "text": "help out",
    "start": "219440",
    "end": "221680"
  },
  {
    "text": "so i'd like to illustrate this",
    "start": "221680",
    "end": "223280"
  },
  {
    "start": "222000",
    "end": "222000"
  },
  {
    "text": "illustrate the benefits in the case of",
    "start": "223280",
    "end": "225120"
  },
  {
    "text": "horyvad",
    "start": "225120",
    "end": "225920"
  },
  {
    "text": "from uber one of the most popular",
    "start": "225920",
    "end": "227680"
  },
  {
    "text": "libraries for distributed training",
    "start": "227680",
    "end": "229920"
  },
  {
    "text": "so the benefits of integrating with rey",
    "start": "229920",
    "end": "232239"
  },
  {
    "text": "include being able to run horovod",
    "start": "232239",
    "end": "234159"
  },
  {
    "text": "on aws gcp azure or kubernetes",
    "start": "234159",
    "end": "237519"
  },
  {
    "text": "using ray integration with ray tune for",
    "start": "237519",
    "end": "239920"
  },
  {
    "text": "hyperparameter tuning",
    "start": "239920",
    "end": "241599"
  },
  {
    "text": "integration with the rest of the",
    "start": "241599",
    "end": "242720"
  },
  {
    "text": "ecosystem and this was all released in",
    "start": "242720",
    "end": "245040"
  },
  {
    "text": "horowat 0.20 which just came out",
    "start": "245040",
    "end": "247360"
  },
  {
    "text": "and the whole thing took around 400",
    "start": "247360",
    "end": "249040"
  },
  {
    "text": "lines of code to implement",
    "start": "249040",
    "end": "250879"
  },
  {
    "text": "and of course this collaboration and",
    "start": "250879",
    "end": "252799"
  },
  {
    "text": "many of these other integrations are at",
    "start": "252799",
    "end": "254400"
  },
  {
    "text": "the very start",
    "start": "254400",
    "end": "255439"
  },
  {
    "text": "and there's a lot more work to do but",
    "start": "255439",
    "end": "257199"
  },
  {
    "text": "hopefully this gives a sense",
    "start": "257199",
    "end": "259040"
  },
  {
    "text": "of some of the early benefits",
    "start": "259040",
    "end": "262400"
  },
  {
    "start": "262000",
    "end": "262000"
  },
  {
    "text": "now i'd like to talk a little bit about",
    "start": "262479",
    "end": "264160"
  },
  {
    "text": "what makes ray a great choice for",
    "start": "264160",
    "end": "265680"
  },
  {
    "text": "building distributed applications",
    "start": "265680",
    "end": "267520"
  },
  {
    "text": "and why all of these libraries are",
    "start": "267520",
    "end": "269120"
  },
  {
    "text": "choosing ray i think it comes down to",
    "start": "269120",
    "end": "271600"
  },
  {
    "text": "three things",
    "start": "271600",
    "end": "272560"
  },
  {
    "text": "the api performance and the ecosystem",
    "start": "272560",
    "end": "276639"
  },
  {
    "text": "so we already talked about the ecosystem",
    "start": "276639",
    "end": "278560"
  },
  {
    "text": "and how anyone using ray can immediately",
    "start": "278560",
    "end": "280479"
  },
  {
    "text": "access a whole slew of state-of-the-art",
    "start": "280479",
    "end": "282320"
  },
  {
    "text": "libraries off the shelf",
    "start": "282320",
    "end": "284080"
  },
  {
    "text": "so i'll say a bit more about ray's api",
    "start": "284080",
    "end": "286160"
  },
  {
    "text": "and performance",
    "start": "286160",
    "end": "288639"
  },
  {
    "text": "one question we get a lot is how can ray",
    "start": "288639",
    "end": "291280"
  },
  {
    "text": "support so many different workloads like",
    "start": "291280",
    "end": "293280"
  },
  {
    "text": "so many different types of workloads",
    "start": "293280",
    "end": "294880"
  },
  {
    "text": "isn't that impossible to answer that",
    "start": "294880",
    "end": "297360"
  },
  {
    "text": "question",
    "start": "297360",
    "end": "298160"
  },
  {
    "text": "let me describe how the core ray api has",
    "start": "298160",
    "end": "300560"
  },
  {
    "text": "progressed over time",
    "start": "300560",
    "end": "303039"
  },
  {
    "text": "the core ray api has actually been quite",
    "start": "303039",
    "end": "304960"
  },
  {
    "text": "stable there have been three major",
    "start": "304960",
    "end": "306880"
  },
  {
    "text": "developments",
    "start": "306880",
    "end": "308080"
  },
  {
    "text": "we started ray with just remote",
    "start": "308080",
    "end": "309759"
  },
  {
    "text": "functions just the ability to execute",
    "start": "309759",
    "end": "311759"
  },
  {
    "text": "python functions asynchronously in a",
    "start": "311759",
    "end": "313759"
  },
  {
    "text": "cluster",
    "start": "313759",
    "end": "314639"
  },
  {
    "text": "that's very powerful and supported a lot",
    "start": "314639",
    "end": "316560"
  },
  {
    "text": "of workloads but it wasn't quite enough",
    "start": "316560",
    "end": "318560"
  },
  {
    "text": "to do machine learning",
    "start": "318560",
    "end": "320560"
  },
  {
    "text": "then we added actors so you could",
    "start": "320560",
    "end": "322400"
  },
  {
    "text": "translate python objects and classes to",
    "start": "322400",
    "end": "324400"
  },
  {
    "text": "the distributed setting",
    "start": "324400",
    "end": "325600"
  },
  {
    "text": "and support stateful applications all of",
    "start": "325600",
    "end": "328160"
  },
  {
    "text": "a sudden",
    "start": "328160",
    "end": "328800"
  },
  {
    "text": "that opened up a bunch of doors and",
    "start": "328800",
    "end": "330479"
  },
  {
    "text": "today actors are the building block for",
    "start": "330479",
    "end": "332720"
  },
  {
    "text": "most of the libraries built on ray",
    "start": "332720",
    "end": "335759"
  },
  {
    "text": "but actors were still limited because",
    "start": "335759",
    "end": "338080"
  },
  {
    "text": "only one caller",
    "start": "338080",
    "end": "339280"
  },
  {
    "text": "could invoke methods on an actor the",
    "start": "339280",
    "end": "341840"
  },
  {
    "text": "third big challenge",
    "start": "341840",
    "end": "343120"
  },
  {
    "text": "the third big change we made was to",
    "start": "343120",
    "end": "345120"
  },
  {
    "text": "introduce actor handles",
    "start": "345120",
    "end": "346720"
  },
  {
    "text": "so any actor or task could invoke",
    "start": "346720",
    "end": "348560"
  },
  {
    "text": "methods on any other actor",
    "start": "348560",
    "end": "350320"
  },
  {
    "text": "and that made the ray api as general as",
    "start": "350320",
    "end": "352960"
  },
  {
    "text": "a lower level rpc framework",
    "start": "352960",
    "end": "354880"
  },
  {
    "text": "and enabled the full diversity of",
    "start": "354880",
    "end": "356639"
  },
  {
    "text": "applications that we have today",
    "start": "356639",
    "end": "359520"
  },
  {
    "text": "and those are the core concepts in the",
    "start": "359520",
    "end": "361600"
  },
  {
    "text": "ray api",
    "start": "361600",
    "end": "362720"
  },
  {
    "text": "that's how we support such general",
    "start": "362720",
    "end": "364400"
  },
  {
    "text": "workloads the answer",
    "start": "364400",
    "end": "366000"
  },
  {
    "text": "is that our core api doesn't introduce",
    "start": "366000",
    "end": "368000"
  },
  {
    "text": "new high-level concepts like a data set",
    "start": "368000",
    "end": "370319"
  },
  {
    "text": "or a neural network or a graph or",
    "start": "370319",
    "end": "372720"
  },
  {
    "text": "anything like that",
    "start": "372720",
    "end": "373759"
  },
  {
    "text": "instead we take the existing concepts of",
    "start": "373759",
    "end": "376479"
  },
  {
    "text": "functions and classes",
    "start": "376479",
    "end": "377840"
  },
  {
    "text": "which we know are general enough to",
    "start": "377840",
    "end": "379280"
  },
  {
    "text": "express all sorts of workloads",
    "start": "379280",
    "end": "381039"
  },
  {
    "text": "and we translate those into the",
    "start": "381039",
    "end": "382560"
  },
  {
    "text": "distributed setting",
    "start": "382560",
    "end": "384400"
  },
  {
    "text": "and because the api is so general that's",
    "start": "384400",
    "end": "386560"
  },
  {
    "text": "what enables the ecosystem on top",
    "start": "386560",
    "end": "389840"
  },
  {
    "text": "now performance is another key factor",
    "start": "389840",
    "end": "392080"
  },
  {
    "start": "390000",
    "end": "390000"
  },
  {
    "text": "that makes ray a good choice for",
    "start": "392080",
    "end": "393360"
  },
  {
    "text": "building distributed applications",
    "start": "393360",
    "end": "395520"
  },
  {
    "text": "if you're developing a library or",
    "start": "395520",
    "end": "397039"
  },
  {
    "text": "application it's not enough that raise",
    "start": "397039",
    "end": "399199"
  },
  {
    "text": "api lets you express your workload",
    "start": "399199",
    "end": "401199"
  },
  {
    "text": "of course that's a necessary condition",
    "start": "401199",
    "end": "403039"
  },
  {
    "text": "but ray also needs to be fast enough to",
    "start": "403039",
    "end": "405120"
  },
  {
    "text": "support your workload efficiently",
    "start": "405120",
    "end": "407280"
  },
  {
    "text": "so performance is a key factor that",
    "start": "407280",
    "end": "409919"
  },
  {
    "text": "enables",
    "start": "409919",
    "end": "410639"
  },
  {
    "text": "generality if you're building a system",
    "start": "410639",
    "end": "413039"
  },
  {
    "text": "that supports a ton of different",
    "start": "413039",
    "end": "414400"
  },
  {
    "text": "workloads",
    "start": "414400",
    "end": "415120"
  },
  {
    "text": "then your system inherits the",
    "start": "415120",
    "end": "416800"
  },
  {
    "text": "performance requirements",
    "start": "416800",
    "end": "418160"
  },
  {
    "text": "of all those workloads so i'll show just",
    "start": "418160",
    "end": "421520"
  },
  {
    "text": "two figures",
    "start": "421520",
    "end": "422800"
  },
  {
    "text": "the first is a latency measure for",
    "start": "422800",
    "end": "424560"
  },
  {
    "text": "invoking a single task",
    "start": "424560",
    "end": "426400"
  },
  {
    "text": "now if you compare with a lower level",
    "start": "426400",
    "end": "428880"
  },
  {
    "text": "rpc framework like grpc",
    "start": "428880",
    "end": "430800"
  },
  {
    "text": "jrpt grpc takes around 220 microseconds",
    "start": "430800",
    "end": "434800"
  },
  {
    "text": "and if you do this with ray which",
    "start": "434800",
    "end": "436880"
  },
  {
    "text": "actually uses the c",
    "start": "436880",
    "end": "438000"
  },
  {
    "text": "plus plus implementation of grpc under",
    "start": "438000",
    "end": "440080"
  },
  {
    "text": "the hood it's about 190 microseconds",
    "start": "440080",
    "end": "443360"
  },
  {
    "text": "so for python developers ray outperforms",
    "start": "443360",
    "end": "446000"
  },
  {
    "text": "grpc",
    "start": "446000",
    "end": "448240"
  },
  {
    "text": "the story is similar for throughput but",
    "start": "448240",
    "end": "450400"
  },
  {
    "text": "in this case",
    "start": "450400",
    "end": "451280"
  },
  {
    "text": "rey actually uses multiple grpc channels",
    "start": "451280",
    "end": "453680"
  },
  {
    "text": "to roughly saturate the network",
    "start": "453680",
    "end": "455199"
  },
  {
    "text": "bandwidth",
    "start": "455199",
    "end": "456160"
  },
  {
    "text": "we can do way better here because grpc",
    "start": "456160",
    "end": "458479"
  },
  {
    "text": "is not built for large objects",
    "start": "458479",
    "end": "460639"
  },
  {
    "text": "so the takeaway is that if you're",
    "start": "460639",
    "end": "462160"
  },
  {
    "text": "primarily concerned about performance",
    "start": "462160",
    "end": "464400"
  },
  {
    "text": "you don't have to build your own",
    "start": "464400",
    "end": "465520"
  },
  {
    "text": "distributed system from scratch using",
    "start": "465520",
    "end": "467280"
  },
  {
    "text": "low-level rpc frameworks",
    "start": "467280",
    "end": "468800"
  },
  {
    "text": "you can get the performance you need",
    "start": "468800",
    "end": "470560"
  },
  {
    "text": "using ray",
    "start": "470560",
    "end": "473199"
  },
  {
    "text": "so as ray is becoming used more and more",
    "start": "473919",
    "end": "476400"
  },
  {
    "text": "in production settings stability and",
    "start": "476400",
    "end": "478720"
  },
  {
    "text": "maturity",
    "start": "478720",
    "end": "479440"
  },
  {
    "text": "has become an increasing focus so today",
    "start": "479440",
    "end": "482560"
  },
  {
    "text": "we're announcing ray 1.0 this is a huge",
    "start": "482560",
    "end": "485680"
  },
  {
    "text": "milestone",
    "start": "485680",
    "end": "486720"
  },
  {
    "text": "and achievement for the community and",
    "start": "486720",
    "end": "488400"
  },
  {
    "text": "it's the product of work from many many",
    "start": "488400",
    "end": "490160"
  },
  {
    "text": "people",
    "start": "490160",
    "end": "490639"
  },
  {
    "text": "and companies this indicates api",
    "start": "490639",
    "end": "493199"
  },
  {
    "text": "stability for the core ray api",
    "start": "493199",
    "end": "495840"
  },
  {
    "text": "it's the first step toward making sure",
    "start": "495840",
    "end": "497360"
  },
  {
    "text": "that ray is production ready and",
    "start": "497360",
    "end": "498879"
  },
  {
    "text": "production scale",
    "start": "498879",
    "end": "500319"
  },
  {
    "text": "and it's the beginning of a serious",
    "start": "500319",
    "end": "501759"
  },
  {
    "text": "commitment to the project's maturity and",
    "start": "501759",
    "end": "503840"
  },
  {
    "text": "stability",
    "start": "503840",
    "end": "504960"
  },
  {
    "text": "we're excited for you to try it out and",
    "start": "504960",
    "end": "506560"
  },
  {
    "text": "give us feedback",
    "start": "506560",
    "end": "508240"
  },
  {
    "text": "and if you're interested in getting",
    "start": "508240",
    "end": "509440"
  },
  {
    "text": "involved and influencing the roadmap",
    "start": "509440",
    "end": "511120"
  },
  {
    "text": "going forward",
    "start": "511120",
    "end": "512080"
  },
  {
    "text": "join our public slack and chat with us",
    "start": "512080",
    "end": "514159"
  },
  {
    "text": "there we'll also be having",
    "start": "514159",
    "end": "516320"
  },
  {
    "text": "office hours with the ray developers and",
    "start": "516320",
    "end": "518080"
  },
  {
    "text": "library developers throughout the summit",
    "start": "518080",
    "end": "520240"
  },
  {
    "text": "so be sure to join those you can bring",
    "start": "520240",
    "end": "522479"
  },
  {
    "text": "your questions or get help with your ray",
    "start": "522479",
    "end": "524320"
  },
  {
    "text": "application",
    "start": "524320",
    "end": "525040"
  },
  {
    "text": "or just chat i'd like to highlight a few",
    "start": "525040",
    "end": "529200"
  },
  {
    "start": "528000",
    "end": "528000"
  },
  {
    "text": "different features in 1.0",
    "start": "529200",
    "end": "531600"
  },
  {
    "text": "a couple of them are related to the",
    "start": "531600",
    "end": "533120"
  },
  {
    "text": "serverless experience and letting users",
    "start": "533120",
    "end": "535360"
  },
  {
    "text": "reason about their application logic and",
    "start": "535360",
    "end": "537200"
  },
  {
    "text": "not just and about the resources used by",
    "start": "537200",
    "end": "539200"
  },
  {
    "text": "their application",
    "start": "539200",
    "end": "540320"
  },
  {
    "text": "and not about servers that's a critical",
    "start": "540320",
    "end": "543360"
  },
  {
    "text": "component for making distributed",
    "start": "543360",
    "end": "544959"
  },
  {
    "text": "computing a friendlier user experience",
    "start": "544959",
    "end": "548320"
  },
  {
    "text": "one is related to stability we talked",
    "start": "548320",
    "end": "550480"
  },
  {
    "text": "with many users",
    "start": "550480",
    "end": "551600"
  },
  {
    "text": "and one persistent problem was how to",
    "start": "551600",
    "end": "553519"
  },
  {
    "text": "reason about memory management in the",
    "start": "553519",
    "end": "555279"
  },
  {
    "text": "distributed setting",
    "start": "555279",
    "end": "556560"
  },
  {
    "text": "that is now fully automatic and has a",
    "start": "556560",
    "end": "558560"
  },
  {
    "text": "huge advantage in 1.0",
    "start": "558560",
    "end": "560800"
  },
  {
    "text": "for more details there i'd recommend",
    "start": "560800",
    "end": "562800"
  },
  {
    "text": "taking a look at the ray architecture",
    "start": "562800",
    "end": "564560"
  },
  {
    "text": "white paper",
    "start": "564560",
    "end": "565360"
  },
  {
    "text": "which is linked to from the ray github",
    "start": "565360",
    "end": "566959"
  },
  {
    "text": "readme",
    "start": "566959",
    "end": "568800"
  },
  {
    "text": "two other developments are about",
    "start": "568800",
    "end": "570399"
  },
  {
    "text": "increasing the set of users",
    "start": "570399",
    "end": "571920"
  },
  {
    "text": "we can support so the ray java api is",
    "start": "571920",
    "end": "574640"
  },
  {
    "text": "now stable and ready to try",
    "start": "574640",
    "end": "576160"
  },
  {
    "text": "out and the core array api now supports",
    "start": "576160",
    "end": "578480"
  },
  {
    "text": "windows",
    "start": "578480",
    "end": "579600"
  },
  {
    "text": "so i'm not going to dive deeply into all",
    "start": "579600",
    "end": "581440"
  },
  {
    "text": "of these points i'm going to focus on",
    "start": "581440",
    "end": "583360"
  },
  {
    "text": "just the first couple points",
    "start": "583360",
    "end": "584959"
  },
  {
    "text": "about providing a serverless experience",
    "start": "584959",
    "end": "588560"
  },
  {
    "start": "588000",
    "end": "588000"
  },
  {
    "text": "so again the goal here is to let",
    "start": "588560",
    "end": "590399"
  },
  {
    "text": "developers reason about resources and",
    "start": "590399",
    "end": "592399"
  },
  {
    "text": "not machines",
    "start": "592399",
    "end": "593600"
  },
  {
    "text": "the point of serverless auto scaling is",
    "start": "593600",
    "end": "595680"
  },
  {
    "text": "to make sure that users don't have to",
    "start": "595680",
    "end": "597360"
  },
  {
    "text": "configure their array cluster",
    "start": "597360",
    "end": "598880"
  },
  {
    "text": "or say precisely how many m4 instances",
    "start": "598880",
    "end": "601440"
  },
  {
    "text": "or how many p3 instances they need",
    "start": "601440",
    "end": "603519"
  },
  {
    "text": "or how to get the precise ratio of cpus",
    "start": "603519",
    "end": "605839"
  },
  {
    "text": "to gpus",
    "start": "605839",
    "end": "606880"
  },
  {
    "text": "instead the ray cluster will just add",
    "start": "606880",
    "end": "609200"
  },
  {
    "text": "the appropriate instance types",
    "start": "609200",
    "end": "610720"
  },
  {
    "text": "and scale up and down depending on what",
    "start": "610720",
    "end": "612480"
  },
  {
    "text": "the application needs",
    "start": "612480",
    "end": "614320"
  },
  {
    "text": "so to illustrate the kind of",
    "start": "614320",
    "end": "615600"
  },
  {
    "text": "applications that this can enable",
    "start": "615600",
    "end": "617519"
  },
  {
    "text": "imagine you're running some training",
    "start": "617519",
    "end": "619279"
  },
  {
    "text": "this is just pseudo code",
    "start": "619279",
    "end": "621040"
  },
  {
    "text": "and maybe your experiment needs a bunch",
    "start": "621040",
    "end": "622640"
  },
  {
    "text": "of cpus and in fact you have a lot of",
    "start": "622640",
    "end": "625120"
  },
  {
    "text": "experiments you want to run",
    "start": "625120",
    "end": "626800"
  },
  {
    "text": "so if you run this code you'll want",
    "start": "626800",
    "end": "628640"
  },
  {
    "text": "ready to automatically scale up the",
    "start": "628640",
    "end": "630160"
  },
  {
    "text": "cluster to use tons of large cpu",
    "start": "630160",
    "end": "632079"
  },
  {
    "text": "machines",
    "start": "632079",
    "end": "632720"
  },
  {
    "text": "to run all of these experiments in",
    "start": "632720",
    "end": "634160"
  },
  {
    "text": "parallel and then when that's done",
    "start": "634160",
    "end": "636240"
  },
  {
    "text": "you want it to scale down and stop using",
    "start": "636240",
    "end": "638160"
  },
  {
    "text": "them or maybe",
    "start": "638160",
    "end": "639839"
  },
  {
    "text": "you know you run stuff requiring a bunch",
    "start": "639839",
    "end": "641600"
  },
  {
    "text": "of gpus and maybe you even have a very",
    "start": "641600",
    "end": "644000"
  },
  {
    "text": "specific kind of gpu that you care about",
    "start": "644000",
    "end": "646399"
  },
  {
    "text": "so ray will automatically start the",
    "start": "646399",
    "end": "648079"
  },
  {
    "text": "appropriate gpu instances to run your",
    "start": "648079",
    "end": "650079"
  },
  {
    "text": "application",
    "start": "650079",
    "end": "650880"
  },
  {
    "text": "you don't have to worry about instance",
    "start": "650880",
    "end": "652320"
  },
  {
    "text": "types how many machines",
    "start": "652320",
    "end": "653920"
  },
  {
    "text": "what size they are this all falls out of",
    "start": "653920",
    "end": "656160"
  },
  {
    "text": "the application's resource requirements",
    "start": "656160",
    "end": "658560"
  },
  {
    "text": "so this is a feature that we hope will",
    "start": "658560",
    "end": "660079"
  },
  {
    "text": "make running distributed applications",
    "start": "660079",
    "end": "662000"
  },
  {
    "text": "way way easier by getting rid of the",
    "start": "662000",
    "end": "663839"
  },
  {
    "text": "cluster configuration",
    "start": "663839",
    "end": "667040"
  },
  {
    "start": "667000",
    "end": "667000"
  },
  {
    "text": "the second feature i want to highlight",
    "start": "667040",
    "end": "668560"
  },
  {
    "text": "is placement groups so placement groups",
    "start": "668560",
    "end": "670720"
  },
  {
    "text": "allow atomic scheduling of resources",
    "start": "670720",
    "end": "672640"
  },
  {
    "text": "across a cluster",
    "start": "672640",
    "end": "673680"
  },
  {
    "text": "and enable things like affinity or",
    "start": "673680",
    "end": "675360"
  },
  {
    "text": "anti-affinity placement",
    "start": "675360",
    "end": "677279"
  },
  {
    "text": "a placement group is basically a",
    "start": "677279",
    "end": "678800"
  },
  {
    "text": "collection of resources that is",
    "start": "678800",
    "end": "680320"
  },
  {
    "text": "atomically reserved",
    "start": "680320",
    "end": "681680"
  },
  {
    "text": "possibly across multiple machines and",
    "start": "681680",
    "end": "684160"
  },
  {
    "text": "new tasks and actors can be scheduled to",
    "start": "684160",
    "end": "686240"
  },
  {
    "text": "run in that placement group",
    "start": "686240",
    "end": "687600"
  },
  {
    "text": "or in a particular section of the",
    "start": "687600",
    "end": "689040"
  },
  {
    "text": "placement group for example",
    "start": "689040",
    "end": "690880"
  },
  {
    "text": "if some actors need to be co-located you",
    "start": "690880",
    "end": "694000"
  },
  {
    "text": "can configure the placement group to",
    "start": "694000",
    "end": "695440"
  },
  {
    "text": "pack things together or spread them",
    "start": "695440",
    "end": "697040"
  },
  {
    "text": "apart",
    "start": "697040",
    "end": "697920"
  },
  {
    "text": "and this is what it looks like if you",
    "start": "697920",
    "end": "699120"
  },
  {
    "text": "want to schedule a task in the placement",
    "start": "699120",
    "end": "700800"
  },
  {
    "text": "group",
    "start": "700800",
    "end": "701200"
  },
  {
    "text": "it's just an additional option to the",
    "start": "701200",
    "end": "703279"
  },
  {
    "text": "normal task invocation",
    "start": "703279",
    "end": "705440"
  },
  {
    "text": "you can take it further and specify",
    "start": "705440",
    "end": "707120"
  },
  {
    "text": "which section of the placement group the",
    "start": "707120",
    "end": "708560"
  },
  {
    "text": "task runs in",
    "start": "708560",
    "end": "709760"
  },
  {
    "text": "so that's the api it's a very flexible",
    "start": "709760",
    "end": "712000"
  },
  {
    "text": "concept and of course",
    "start": "712000",
    "end": "713440"
  },
  {
    "text": "there are a number of use cases we have",
    "start": "713440",
    "end": "714959"
  },
  {
    "text": "in mind and we're excited to see",
    "start": "714959",
    "end": "717040"
  },
  {
    "text": "what people build with this",
    "start": "717040",
    "end": "720079"
  },
  {
    "text": "looking forward our goal with rey is to",
    "start": "720720",
    "end": "722880"
  },
  {
    "text": "make it as easy to program clusters of",
    "start": "722880",
    "end": "725120"
  },
  {
    "text": "machines",
    "start": "725120",
    "end": "725839"
  },
  {
    "text": "as it is to program on your laptop we'll",
    "start": "725839",
    "end": "728240"
  },
  {
    "text": "be doubling down on hardening and",
    "start": "728240",
    "end": "730079"
  },
  {
    "text": "production requirements",
    "start": "730079",
    "end": "731519"
  },
  {
    "text": "that includes support for monitoring",
    "start": "731519",
    "end": "733360"
  },
  {
    "text": "tracing metrics",
    "start": "733360",
    "end": "735279"
  },
  {
    "text": "great integration with kubernetes you'll",
    "start": "735279",
    "end": "737519"
  },
  {
    "text": "hear more about this in one of the",
    "start": "737519",
    "end": "738720"
  },
  {
    "text": "upcoming talks",
    "start": "738720",
    "end": "739760"
  },
  {
    "text": "and especially as ray is being used more",
    "start": "739760",
    "end": "741600"
  },
  {
    "text": "and more for production serving",
    "start": "741600",
    "end": "743120"
  },
  {
    "text": "workloads",
    "start": "743120",
    "end": "744000"
  },
  {
    "text": "this is a critical focus scalability and",
    "start": "744000",
    "end": "747200"
  },
  {
    "text": "performance are always on the top of our",
    "start": "747200",
    "end": "748800"
  },
  {
    "text": "mind",
    "start": "748800",
    "end": "749279"
  },
  {
    "text": "there are a number of optimizations",
    "start": "749279",
    "end": "750800"
  },
  {
    "text": "planned here especially related to data",
    "start": "750800",
    "end": "752959"
  },
  {
    "text": "intensive workloads",
    "start": "752959",
    "end": "755120"
  },
  {
    "text": "ease of use encompasses things like ease",
    "start": "755120",
    "end": "756959"
  },
  {
    "text": "of deployment on kubernetes improving",
    "start": "756959",
    "end": "758800"
  },
  {
    "text": "the dashboards",
    "start": "758800",
    "end": "759839"
  },
  {
    "text": "tools for debugging distributed",
    "start": "759839",
    "end": "761120"
  },
  {
    "text": "applications and so on",
    "start": "761120",
    "end": "763200"
  },
  {
    "text": "and lastly a big focus for us is on",
    "start": "763200",
    "end": "765360"
  },
  {
    "text": "doing everything we can to support the",
    "start": "765360",
    "end": "767120"
  },
  {
    "text": "growing ecosystem on top of rey",
    "start": "767120",
    "end": "769279"
  },
  {
    "text": "we have a ton of work planned here and",
    "start": "769279",
    "end": "771200"
  },
  {
    "text": "that's something we're super excited",
    "start": "771200",
    "end": "772720"
  },
  {
    "text": "about",
    "start": "772720",
    "end": "774639"
  },
  {
    "text": "so i hope you enjoy the race summit",
    "start": "774639",
    "end": "776560"
  },
  {
    "text": "thanks so much for being a part of the",
    "start": "776560",
    "end": "777839"
  },
  {
    "text": "ray community",
    "start": "777839",
    "end": "779040"
  },
  {
    "text": "this project you know wouldn't be",
    "start": "779040",
    "end": "780720"
  },
  {
    "text": "anywhere near where it is today without",
    "start": "780720",
    "end": "782320"
  },
  {
    "text": "such a passionate",
    "start": "782320",
    "end": "783440"
  },
  {
    "text": "and engaged community and that's",
    "start": "783440",
    "end": "785040"
  },
  {
    "text": "something we're extremely grateful for",
    "start": "785040",
    "end": "787440"
  },
  {
    "text": "if you're new to ray or looking to get",
    "start": "787440",
    "end": "789120"
  },
  {
    "text": "more involved we'd love to have you",
    "start": "789120",
    "end": "790880"
  },
  {
    "text": "involved we'd love to have you",
    "start": "790880",
    "end": "792079"
  },
  {
    "text": "influencing the roadmap",
    "start": "792079",
    "end": "793680"
  },
  {
    "text": "i'm looking forward to chatting with as",
    "start": "793680",
    "end": "795120"
  },
  {
    "text": "many of you as possible throughout the",
    "start": "795120",
    "end": "796959"
  },
  {
    "text": "summit",
    "start": "796959",
    "end": "798000"
  },
  {
    "text": "chat with us on the conference slack you",
    "start": "798000",
    "end": "800000"
  },
  {
    "text": "know join the ray developers at our",
    "start": "800000",
    "end": "801519"
  },
  {
    "text": "office hours in the any scale booth",
    "start": "801519",
    "end": "803440"
  },
  {
    "text": "we'll be there throughout the conference",
    "start": "803440",
    "end": "805600"
  },
  {
    "text": "you can get notified when the talks are",
    "start": "805600",
    "end": "807120"
  },
  {
    "text": "available through our youtube channel",
    "start": "807120",
    "end": "809200"
  },
  {
    "text": "thanks so much",
    "start": "809200",
    "end": "813360"
  }
]
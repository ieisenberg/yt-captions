[
  {
    "start": "0",
    "end": "233000"
  },
  {
    "text": "hey nice to meet everyone hi chang hey garage hey hey um yeah let's do a quick quick intro",
    "start": "0",
    "end": "6319"
  },
  {
    "text": "then um so my name is sven i'm the team lead of the reinforcement team at any scale",
    "start": "6319",
    "end": "11759"
  },
  {
    "text": "we're the company behind the ray open source project and my team is responsible for",
    "start": "11759",
    "end": "17760"
  },
  {
    "text": "developing and maintaining our lip uh we're about five or six full-time rl engineers",
    "start": "17760",
    "end": "23920"
  },
  {
    "text": "keeps changing as we as we grow and resize and yeah we'll have these office hours",
    "start": "23920",
    "end": "29599"
  },
  {
    "text": "every two weeks uh thanks christy for organizing this i think uh so far it's been going really well we're seeing",
    "start": "29599",
    "end": "35360"
  },
  {
    "text": "different people every every other every every time we do this um some regulars some new people so this is really",
    "start": "35360",
    "end": "40640"
  },
  {
    "text": "interesting uh and i think uh what this is about is for you to ask questions to get unblocked with your with your issues",
    "start": "40640",
    "end": "46399"
  },
  {
    "text": "uh and for us to give uh some some top-level overview of uh or high-level overview of um",
    "start": "46399",
    "end": "52960"
  },
  {
    "text": "we're working on what we're planning to do in the next couple quarters or next year",
    "start": "52960",
    "end": "58000"
  },
  {
    "text": "and of course answer your questions um i think what's interesting uh when you once you introduce yourself is what are you working on why are you using our lip",
    "start": "58000",
    "end": "64799"
  },
  {
    "text": "uh and maybe one sentence why you uh like our lip or why you don't or what could be better uh",
    "start": "64799",
    "end": "70400"
  },
  {
    "text": "we're always welcome um uh yeah very constructive criticism of course this is this is important okay",
    "start": "70400",
    "end": "76400"
  },
  {
    "text": "um maybe cross go ahead and then the others uh matthias mentioned yeah i'm very much",
    "start": "76400",
    "end": "82400"
  },
  {
    "text": "like seven part of our leap team um on any scale i joined about two months ago",
    "start": "82400",
    "end": "87600"
  },
  {
    "text": "very curious to what pain points people are going through when using it so we can make a better product for",
    "start": "87600",
    "end": "94159"
  },
  {
    "text": "everyone hi i'm matthias i'm a postdoc at harvard",
    "start": "94159",
    "end": "99920"
  },
  {
    "text": "working on multi-agent rl mostly methodology",
    "start": "99920",
    "end": "105680"
  },
  {
    "text": "we're using rlip i guess it's the main multi-agent table url library out there",
    "start": "105680",
    "end": "112960"
  },
  {
    "text": "and it's fantastic maybe the one pain point is that it can do so many things that it's a bit hard to get to know all",
    "start": "112960",
    "end": "119040"
  },
  {
    "text": "parts of it and sometimes the documentation is lagging a little bit behind um but i think that's just",
    "start": "119040",
    "end": "124880"
  },
  {
    "text": "the way it is if you're able to do so many things",
    "start": "124880",
    "end": "129840"
  },
  {
    "text": "yeah it's a it's a design problem i guess it comes with countless let's see the ups and downs of trying to do",
    "start": "129920",
    "end": "135280"
  },
  {
    "text": "everything you know absolutely yeah thanks cool chang you want to go next",
    "start": "135280",
    "end": "140959"
  },
  {
    "text": "right thanks man really nice to meet our liberty i am a",
    "start": "140959",
    "end": "146160"
  },
  {
    "text": "phd student at the university of sydney uh i'm studying ireland for my",
    "start": "146160",
    "end": "153120"
  },
  {
    "text": "reinforcement learning framework and i'm currently having trouble auto scaling it",
    "start": "153120",
    "end": "158879"
  },
  {
    "text": "on the aws aws cluster so yeah really looking forward to this",
    "start": "158879",
    "end": "164879"
  },
  {
    "text": "tutorial thanks so much okay yeah hi nice meeting you all again",
    "start": "164879",
    "end": "171440"
  },
  {
    "text": "um yeah i'm simon some people know know me already i'm also a contributor to ray uh",
    "start": "171440",
    "end": "178080"
  },
  {
    "text": "especially our lip um which i use um i'm coming from the field of uh math and",
    "start": "178080",
    "end": "185280"
  },
  {
    "text": "economics uh like did game theory on machine learning and from this somehow also made this",
    "start": "185280",
    "end": "192959"
  },
  {
    "text": "way towards reinforcement learning where i think like all the older guys actually make such a way like",
    "start": "192959",
    "end": "200239"
  },
  {
    "text": "there was never a straight way before um and uh yes i'm applying reinforcement",
    "start": "200239",
    "end": "206239"
  },
  {
    "text": "learning and that's also where uh where i'm using uh our lip and want to use it even more uh with my own business new",
    "start": "206239",
    "end": "213280"
  },
  {
    "text": "way.ai and yeah always like to be here and",
    "start": "213280",
    "end": "218560"
  },
  {
    "text": "discuss more uh about our lib and know where people have problems yeah thanks",
    "start": "218560",
    "end": "225280"
  },
  {
    "text": "thanks samya simon is a regular it's good to have you um",
    "start": "225280",
    "end": "230560"
  },
  {
    "text": "yeah so so i was sorry i was in the other chat with matthias in the other zoom uh zoom link uh uh so he's working",
    "start": "230560",
    "end": "237200"
  },
  {
    "start": "233000",
    "end": "263000"
  },
  {
    "text": "on multi-agent problems and he had a question on how you can he wanted to better understand how the multi-agent setup works in our lab and",
    "start": "237200",
    "end": "243599"
  },
  {
    "text": "how you could use different um different algorithms kind of within the same",
    "start": "243599",
    "end": "248640"
  },
  {
    "text": "within the same algorithm so that the different agents in the multi-agent set",
    "start": "248640",
    "end": "253840"
  },
  {
    "text": "exist in the same environment and how would this work so i was going to explain to him um i'm assuming you see my screen",
    "start": "253840",
    "end": "260400"
  },
  {
    "text": "everyone right now um so i was telling him right now so i think many uh the other day uh who's",
    "start": "260400",
    "end": "265680"
  },
  {
    "start": "263000",
    "end": "315000"
  },
  {
    "text": "also like a regular in this group manny bendjolia uh he answered this question and he's okay try to like help him a",
    "start": "265680",
    "end": "271520"
  },
  {
    "text": "little bit and he said you can use different policies you can use the same you pick one algorithm",
    "start": "271520",
    "end": "277199"
  },
  {
    "text": "and then in the algorithm in your multi-agent config dictionary you kind of set up different",
    "start": "277199",
    "end": "283280"
  },
  {
    "text": "policies for your different agents that walk around in your environment",
    "start": "283280",
    "end": "289120"
  },
  {
    "text": "and then i explain them that only works then of course if the policies are kind of matching the type of",
    "start": "289120",
    "end": "295040"
  },
  {
    "text": "algorithm that you choose so if you for example you would probably get into trouble if you chose a ppo policy",
    "start": "295040",
    "end": "301280"
  },
  {
    "text": "and a dqn policy with their losses with respective losses and you would use both of them inside a",
    "start": "301280",
    "end": "306800"
  },
  {
    "text": "dqn algorithm which has a buffer and then the ppo would probably complain because it's off policy and so on",
    "start": "306800",
    "end": "313840"
  },
  {
    "text": "um so explaining him that you could also write your own your own algorithm and we have done a lot of work to make this",
    "start": "313840",
    "end": "319120"
  },
  {
    "start": "315000",
    "end": "913000"
  },
  {
    "text": "easier um and i was showing him the uh sharma tsd the new kind of setup you have our lip now and",
    "start": "319120",
    "end": "325759"
  },
  {
    "text": "there's a there's a new algorithms folder and all the uh what you used to be called trainers are now in this",
    "start": "325759",
    "end": "331039"
  },
  {
    "text": "algorithms folder um and each of these algorithms has its own folder so so for example simple queue is no longer part",
    "start": "331039",
    "end": "337120"
  },
  {
    "text": "of the qn but it has its own top level folder and you can for example go here",
    "start": "337120",
    "end": "343120"
  },
  {
    "text": "if you take a look at simple queue there's always like one main file which is called algorithm.pi so in this camp in this",
    "start": "343120",
    "end": "349759"
  },
  {
    "text": "example simplequeue.pipe um and every algorithm now has a training step method",
    "start": "349759",
    "end": "356000"
  },
  {
    "text": "um so if you scroll down a little bit you can you see the simple queue algorithm which subclass from the from the algorithm class this was before this",
    "start": "356000",
    "end": "362800"
  },
  {
    "text": "was called trainer now it's called algorithm and then you have some conflict stuff here and further down you have basically",
    "start": "362800",
    "end": "368800"
  },
  {
    "text": "the heart of the algorithm it's the training step method um and that's the method that gets it's",
    "start": "368800",
    "end": "374240"
  },
  {
    "text": "that keeps being called repeatedly as you iterate through through your training process as",
    "start": "374240",
    "end": "380080"
  },
  {
    "text": "you call uh dot train right so you can um and then each time you call that train uh this training step method gets",
    "start": "380080",
    "end": "386080"
  },
  {
    "text": "called one or more times uh depending on how long you set your iterations to be there's you can set the",
    "start": "386080",
    "end": "391680"
  },
  {
    "text": "minimum time you can say each iteration should take 10 seconds or 100 seconds and then we'll call it several times",
    "start": "391680",
    "end": "397840"
  },
  {
    "text": "this method until it's gathered or accumulated this time and you can see here this is",
    "start": "397840",
    "end": "402880"
  },
  {
    "text": "um it's actually quite simple like you can kind of read through the code here the",
    "start": "402880",
    "end": "408400"
  },
  {
    "text": "basic idea is that you have a utility function that you call",
    "start": "408400",
    "end": "413440"
  },
  {
    "text": "you can you can use these as well for your own algorithms or you can also look inside what's happening here um",
    "start": "413440",
    "end": "419680"
  },
  {
    "text": "here in this in this function call we we parallely step or we parallelly ping all the uh all the",
    "start": "419680",
    "end": "426800"
  },
  {
    "text": "roller workers that we have um and those are the workers that step through the environment just call",
    "start": "426800",
    "end": "432160"
  },
  {
    "text": "examples so we parallel ping them using using ray and then we collect all the all these",
    "start": "432160",
    "end": "437520"
  },
  {
    "text": "samples in parallel and kind of either concatenate them or here in this case they come back as a list",
    "start": "437520",
    "end": "443680"
  },
  {
    "text": "so one one batch for each parallel rollout worker",
    "start": "443680",
    "end": "448720"
  },
  {
    "text": "next we store them in a buffer uh this is what dqm does uh then we then we sample from the buffer",
    "start": "448880",
    "end": "456240"
  },
  {
    "text": "um [Music] what else do we do uh this gives us a train batch so we we put",
    "start": "456240",
    "end": "462000"
  },
  {
    "text": "all the samples and the new samples into the buffer then we uniformly stem from the buffer and we use that uniform sample to to train one step there are",
    "start": "462000",
    "end": "468720"
  },
  {
    "text": "two different ways your multi gpu and train ones and the simple one um",
    "start": "468720",
    "end": "474319"
  },
  {
    "text": "uh and then we what else do we do we update priorities and the priorities in the buffer in case we have a project replay buffer",
    "start": "474319",
    "end": "481039"
  },
  {
    "text": "um and then we synchronize the the updated weights uh back to the rotor workers so that they the workers that",
    "start": "481039",
    "end": "487599"
  },
  {
    "text": "steps for the environment have the newest version of the weights oh yeah so basically you",
    "start": "487599",
    "end": "492800"
  },
  {
    "text": "have a local version of your of your worker uh which holds all the models and your networks it's kind of like a",
    "start": "492800",
    "end": "497919"
  },
  {
    "text": "parameter server uh and that's where the update happens uh and then after the update you you sync all the weights back",
    "start": "497919",
    "end": "503520"
  },
  {
    "text": "to the workers so that in the next step they have the newest the newest weights",
    "start": "503520",
    "end": "509599"
  },
  {
    "text": "and then you return some some results dictionary and you can you can basically now you can subclass",
    "start": "509599",
    "end": "515680"
  },
  {
    "text": "uh either from from simple queue or from algorithm directly or from any of the other algorithms",
    "start": "515680",
    "end": "521518"
  },
  {
    "text": "and overwrite this method if you want you can do some stuff here with your with your",
    "start": "521519",
    "end": "527200"
  },
  {
    "text": "worker set um feel free to browse and browse around in different algorithms if you if you say i",
    "start": "527200",
    "end": "532480"
  },
  {
    "text": "want to have some derivative of for example ppo uh feel free to go to ppo and check check that's uh",
    "start": "532480",
    "end": "539200"
  },
  {
    "text": "the training step method of that algorithm and you can see that they're all pretty simple every every training step",
    "start": "539200",
    "end": "546240"
  },
  {
    "text": "usually fits on like one page um roughly what they all do is they sample",
    "start": "546240",
    "end": "552480"
  },
  {
    "text": "store the sample somewhere or funnel them through some queue uh perform an update and then synchronize the weights",
    "start": "552480",
    "end": "557680"
  },
  {
    "text": "and that's it really ninety percent of our options",
    "start": "557680",
    "end": "562880"
  },
  {
    "text": "if i just pass in different kinds of policy classes into the policies back of",
    "start": "563760",
    "end": "569440"
  },
  {
    "text": "each agent i'm still passing in one trainer object in the",
    "start": "569440",
    "end": "575680"
  },
  {
    "text": "old version at least or one algorithm i guess in the new version of doing things um",
    "start": "575680",
    "end": "581519"
  },
  {
    "text": "so it's going to be using the training step from that trainer that i pass in correct",
    "start": "581519",
    "end": "586959"
  },
  {
    "text": "exactly correct correct so it will it will so if whatever algorithm you choose that will be the training step so so now",
    "start": "586959",
    "end": "592959"
  },
  {
    "text": "what's happening this is a great question now let me explain to you where the policies come in um",
    "start": "592959",
    "end": "598160"
  },
  {
    "text": "uh let's go back to the simple queue because that's the one we know now uh so what's happening here so we have in this",
    "start": "598160",
    "end": "603760"
  },
  {
    "text": "call here this let me actually step in here um again this is a utility function you can",
    "start": "603760",
    "end": "609200"
  },
  {
    "text": "you can take a look it's also quite simple it basically just says uh",
    "start": "609200",
    "end": "614399"
  },
  {
    "text": "while some minimum time is not reached ping all the workers in the worker set",
    "start": "614399",
    "end": "619600"
  },
  {
    "text": "uh the remote workers and say um a dot sample yeah so basically uh this is a",
    "start": "619600",
    "end": "625200"
  },
  {
    "text": "remote call here and then the sample method of these workers will do a couple of steps in the environment",
    "start": "625200",
    "end": "630480"
  },
  {
    "text": "and these steps will happen with the different policies that you specified so let's say you have a multi-agent environment where you have let's say",
    "start": "630480",
    "end": "637360"
  },
  {
    "text": "let's keep it very simple you have two agents agent a agent b and agent a maps to policy a and agent b",
    "start": "637360",
    "end": "642959"
  },
  {
    "text": "maps to policy b yeah and let's assume that maybe there are different policy classes even maybe one is the ppo policy and one is a",
    "start": "642959",
    "end": "651040"
  },
  {
    "text": "i don't know a modified version of the ppo maybe it's something that you wrote because you want to compare the loss functions or something",
    "start": "651040",
    "end": "656320"
  },
  {
    "text": "uh so then these two different policies are used in the sampling process as for calculating actions for um",
    "start": "656320",
    "end": "663279"
  },
  {
    "text": "yeah for basically computing computing using the networks and computing reactions um and the samples are gathered as a",
    "start": "663279",
    "end": "668800"
  },
  {
    "text": "what we call a multi-agent batch which is a batch of of the different of the two agents that walk around they have",
    "start": "668800",
    "end": "674320"
  },
  {
    "text": "different observations they have different rewards and different actions um and this multi-agent batch is then",
    "start": "674320",
    "end": "679360"
  },
  {
    "text": "returned uh here in this uh from this utility function let's go back to a",
    "start": "679360",
    "end": "684399"
  },
  {
    "text": "simple queue um so this into this list here so this list here will now be a a list of",
    "start": "684399",
    "end": "690079"
  },
  {
    "text": "multi-agent batches and each multi-agent batch um comes from one of the roller workers and",
    "start": "690079",
    "end": "695839"
  },
  {
    "text": "each multi-agent batch contains both the agents observations and then what we do in this in this",
    "start": "695839",
    "end": "701920"
  },
  {
    "text": "train and you can do use the same buffers here the buffers also store the multi-agent stuff uh all works pretty much the same and",
    "start": "701920",
    "end": "708399"
  },
  {
    "text": "then the next difference is here in this uh train one step or multi gpu train one step um let's take the simple one let's go to",
    "start": "708399",
    "end": "715440"
  },
  {
    "text": "train one step and what you can see here um",
    "start": "715440",
    "end": "720560"
  },
  {
    "text": "is that eventually we call the the the local workers",
    "start": "720560",
    "end": "726320"
  },
  {
    "text": "learn batch method which contains all the different policies as a parameter server so it has basically the ground",
    "start": "726320",
    "end": "731839"
  },
  {
    "text": "truth versions of all these policies and then we call this uh this one's learner batch method",
    "start": "731839",
    "end": "738880"
  },
  {
    "text": "uh and then different policies and that one different",
    "start": "738880",
    "end": "745199"
  },
  {
    "text": "i might be constructing the batches in the wrong way if i mix dq and vpo for instance",
    "start": "749040",
    "end": "755839"
  },
  {
    "text": "yes correct yeah uh yes um yeah because for ppo you need to",
    "start": "755839",
    "end": "762399"
  },
  {
    "text": "well the post processing if you want to calculate for example uh advantages for ppo",
    "start": "762399",
    "end": "768000"
  },
  {
    "text": "that would be taken care of by the policy itself as well um so policy",
    "start": "768000",
    "end": "774320"
  },
  {
    "text": "might be creating a batch that's like a prioritized experience replay sample",
    "start": "774320",
    "end": "779360"
  },
  {
    "text": "from it might be off policy but even at that point right",
    "start": "779360",
    "end": "784560"
  },
  {
    "text": "um if you use simple queue yeah because then you go through the buffer and then you sample from the buffer and at that",
    "start": "784560",
    "end": "789680"
  },
  {
    "text": "moment you get some old samples from some older policies or which you wouldn't want and that's",
    "start": "789680",
    "end": "795519"
  },
  {
    "text": "why the right way okay yeah so it's important to understand that there's a",
    "start": "795519",
    "end": "800720"
  },
  {
    "text": "there's a policy which computes actions uh and it does some post-processing of the trajectory for",
    "start": "800720",
    "end": "806240"
  },
  {
    "text": "example calculating advantages for ppo and that's what we call the policy uh and then there's the the algorithm which",
    "start": "806240",
    "end": "812880"
  },
  {
    "text": "basically tells um what should happen in which order so sample using the policies sort of buffer",
    "start": "812880",
    "end": "819760"
  },
  {
    "text": "sample from buffer updates mm-hmm and then you can really",
    "start": "819760",
    "end": "826839"
  },
  {
    "text": "yeah well that's all why it's a little bit non-trivial to me mix and match",
    "start": "826839",
    "end": "832880"
  },
  {
    "text": "random algorithms because yes a3c collect cell experiences differently",
    "start": "832880",
    "end": "838480"
  },
  {
    "text": "than dqm and so on correct correct yeah correct yeah okay um okay makes sense yeah and there",
    "start": "838480",
    "end": "845040"
  },
  {
    "text": "sometimes their losses may not even work like if you have uh yeah if you yeah trying to uh teach ppo or train pp or",
    "start": "845040",
    "end": "852160"
  },
  {
    "text": "outdated data on all data we'll let's learn",
    "start": "852160",
    "end": "856959"
  },
  {
    "text": "as the trainer then the dqn policy would only ever get most recent",
    "start": "858880",
    "end": "864560"
  },
  {
    "text": "samples and learn very efficiently correct because there's no buffer yes correct yeah that's right",
    "start": "864560",
    "end": "871839"
  },
  {
    "text": "curious mathias can you uh maybe for two one two three two minutes explain your",
    "start": "872720",
    "end": "878240"
  },
  {
    "text": "use case exactly why would you need to combine let's say two distinctly different algorithms into a multi-agent",
    "start": "878240",
    "end": "884880"
  },
  {
    "text": "scenario so so this one so far is really only a question of",
    "start": "884880",
    "end": "890560"
  },
  {
    "text": "curiosity because i want to understand how the rl lib architecture works here",
    "start": "890560",
    "end": "896480"
  },
  {
    "text": "but we do have some problems we construct where different agents are solving very different",
    "start": "896480",
    "end": "901839"
  },
  {
    "text": "problems so it would be interesting to us to see if let's say ppo for one h and then dq n",
    "start": "901839",
    "end": "908240"
  },
  {
    "text": "for the other works better than the pp over both the dq and for both you",
    "start": "908240",
    "end": "913680"
  },
  {
    "start": "913000",
    "end": "1001000"
  },
  {
    "text": "got it so maybe like the other example that seven we have that kind of",
    "start": "913680",
    "end": "919680"
  },
  {
    "text": "alternately calls the human or ppo train dot train method um",
    "start": "919680",
    "end": "925519"
  },
  {
    "text": "you have something similar to that in the examples right like i've seen that that's where i started from and with",
    "start": "925519",
    "end": "931440"
  },
  {
    "text": "that one it's sort of you create two completely separate training process basically including separate",
    "start": "931440",
    "end": "936959"
  },
  {
    "text": "environments if i understand yeah back and forth which might work for most",
    "start": "936959",
    "end": "944880"
  },
  {
    "text": "of our use cases but another hundred and one things so in one of the trainers you basically",
    "start": "944880",
    "end": "951519"
  },
  {
    "text": "specify that the dqm policy is not for you to train it's just used for sampling yeah in the dq and you say hey ppo is",
    "start": "951519",
    "end": "958880"
  },
  {
    "text": "not for you to train let's just use that first yeah then you know alternatively you sync up the",
    "start": "958880",
    "end": "964399"
  },
  {
    "text": "weights yeah so i think that captures the use case",
    "start": "964399",
    "end": "969600"
  },
  {
    "text": "that you are targeting my sort of my meta question is how can i",
    "start": "969600",
    "end": "975120"
  },
  {
    "text": "in a multi-agent setting have complete control over how experiences are generated",
    "start": "975120",
    "end": "981680"
  },
  {
    "text": "and how they go to different agents um with all of these sort of it's it's the trainer that creates environments it",
    "start": "981680",
    "end": "988399"
  },
  {
    "text": "has complete control over it but i really want to be in charge of the environment so to speak",
    "start": "988399",
    "end": "994839"
  },
  {
    "text": "and um yeah i see yeah so you haven't heard this different agents right",
    "start": "994839",
    "end": "1000959"
  },
  {
    "text": "so there are different things you could do uh yes um so one is you could use the uh the observation function in the in",
    "start": "1000959",
    "end": "1007440"
  },
  {
    "start": "1001000",
    "end": "1153000"
  },
  {
    "text": "the multi-agent um let me go back to the algorithm",
    "start": "1007440",
    "end": "1012720"
  },
  {
    "text": "algorithm conflict as you set up your multi-agent",
    "start": "1012720",
    "end": "1017839"
  },
  {
    "text": "there is a observation function and you can you can define a function",
    "start": "1018560",
    "end": "1023839"
  },
  {
    "text": "that takes in all the agents observations and then outputs um",
    "start": "1023839",
    "end": "1028959"
  },
  {
    "text": "basically a new observation stick for the for the different agents so you could mix maybe you can maybe agent one",
    "start": "1028959",
    "end": "1034160"
  },
  {
    "text": "wants to not only see its own observation that comes from the environment but also see",
    "start": "1034160",
    "end": "1039839"
  },
  {
    "text": "interesting let's see that you could combine this on the on the very lowest level of the observation so there's",
    "start": "1039839",
    "end": "1045120"
  },
  {
    "text": "there's no neural network yet it's just uh pure um yeah observation magic yeah you could",
    "start": "1045120",
    "end": "1051039"
  },
  {
    "text": "you could use that so that's tool for example um but it's kind of a function calls around the return from",
    "start": "1051039",
    "end": "1057039"
  },
  {
    "text": "environment that step basically exactly it's kind of a wrap around the environment yeah that's that's that's okay",
    "start": "1057039",
    "end": "1062799"
  },
  {
    "text": "reshuffle whatever agents",
    "start": "1062799",
    "end": "1066240"
  },
  {
    "text": "that's one thing also what may be useful for you is to take a look at the our examples folder there's a centralized",
    "start": "1068000",
    "end": "1073919"
  },
  {
    "text": "critic example and that one also shows you some stuff of how you can use post-processing in",
    "start": "1073919",
    "end": "1080880"
  },
  {
    "text": "your policy so you can you could quantify your own custom policy and then overwrite the post-process trajectory",
    "start": "1080880",
    "end": "1087440"
  },
  {
    "text": "method and in there yeah you also receive the other agent's",
    "start": "1087440",
    "end": "1094400"
  },
  {
    "text": "observations so you can you can for example maybe uh mess with the rewards or like combine",
    "start": "1094400",
    "end": "1100880"
  },
  {
    "text": "the observations or add the other agents actions to your to your observations um or to your to your sample batch in",
    "start": "1100880",
    "end": "1107200"
  },
  {
    "text": "general so that the model of agent of the other agent then sees that information um so you can you can do",
    "start": "1107200",
    "end": "1112720"
  },
  {
    "text": "that as well um so there's some there's two examples here uh there's their work slightly in",
    "start": "1112720",
    "end": "1119440"
  },
  {
    "text": "different ways um i have to say they're not truly centralized because in the end the",
    "start": "1119440",
    "end": "1125679"
  },
  {
    "text": "the critic is still uh separate for the different agents but um [Music]",
    "start": "1125679",
    "end": "1131360"
  },
  {
    "text": "yeah they have they're basically centralized in the in the sense that they do the um the criticism gets all the information",
    "start": "1131360",
    "end": "1137200"
  },
  {
    "text": "they receive the same data they receive the same post-processed data interestingly we built training",
    "start": "1137200",
    "end": "1142799"
  },
  {
    "text": "separately which is which is kind of a problem that we're trying to solve by what i mentioned before we're trying to change some of the apis",
    "start": "1142799",
    "end": "1150320"
  },
  {
    "text": "to make it easier to construct these really difficult and complex cases i mean one",
    "start": "1150320",
    "end": "1156880"
  },
  {
    "start": "1153000",
    "end": "1204000"
  },
  {
    "text": "yeah one that i've looked into last night a little bit that goes into a slightly different direction but gives",
    "start": "1156880",
    "end": "1162960"
  },
  {
    "text": "me more of what i'm looking for is external environment",
    "start": "1162960",
    "end": "1168160"
  },
  {
    "text": "um basically it's not the trailer that's in control of the main loop it's the",
    "start": "1168160",
    "end": "1173200"
  },
  {
    "text": "environment and in the environment main loop i can decide okay now i do stuff in the environment and now i pull one of",
    "start": "1173200",
    "end": "1179039"
  },
  {
    "text": "the policies for actions um i played around with that a little bit",
    "start": "1179039",
    "end": "1187039"
  },
  {
    "text": "one quick question i had about that that basically subclasses directly from",
    "start": "1187360",
    "end": "1192960"
  },
  {
    "text": "base ends um do i then need to worry myself about",
    "start": "1192960",
    "end": "1199360"
  },
  {
    "text": "sampling from multiple in parallel or does it still happen with multiple rollout workers",
    "start": "1199360",
    "end": "1205280"
  },
  {
    "start": "1204000",
    "end": "1531000"
  },
  {
    "text": "the external end setup is basically a",
    "start": "1205280",
    "end": "1211120"
  },
  {
    "text": "a setup or a design for for um having a",
    "start": "1211520",
    "end": "1218559"
  },
  {
    "text": "one or more environment clients so let's say you have let's say you have a super heavy simulator that simulates some",
    "start": "1218559",
    "end": "1225600"
  },
  {
    "text": "um yeah some process and you have uh it has to run outside of of your uh i don't",
    "start": "1225600",
    "end": "1231360"
  },
  {
    "text": "know sort of python outside of your of your regular setup um",
    "start": "1231360",
    "end": "1236480"
  },
  {
    "text": "you could run these in on different machines and they all use the uh the the rlip policy client um which uh there's",
    "start": "1236480",
    "end": "1243440"
  },
  {
    "text": "these examples here that show you how to do this um so all these environments these on the client side and now you",
    "start": "1243440",
    "end": "1249360"
  },
  {
    "text": "have this is your parallelism basically um they would they could talk to the same rlip policy server which you can",
    "start": "1249360",
    "end": "1256400"
  },
  {
    "text": "set up uh on another maybe on a gpu machine um as in a centralized way it opens a",
    "start": "1256400",
    "end": "1261919"
  },
  {
    "text": "couple of ports that server may have several workers if you want to have different incoming connections on different ports",
    "start": "1261919",
    "end": "1268640"
  },
  {
    "text": "um and then the different clients that say maybe of 100 clients they can all connect to some one of these ports",
    "start": "1268640",
    "end": "1275280"
  },
  {
    "text": "and that's how you get parallelism on the server side by by having several wall workers and several open ports and they all collect data and they batch it",
    "start": "1275280",
    "end": "1281200"
  },
  {
    "text": "together and then they do the same same that i showed before in the um it's the same algorithms same same",
    "start": "1281200",
    "end": "1286799"
  },
  {
    "text": "training step methods um they just policy client and policies are of",
    "start": "1286799",
    "end": "1293280"
  },
  {
    "text": "external length right um yeah you don't have to um",
    "start": "1293280",
    "end": "1300400"
  },
  {
    "text": "let's see uh yeah you could you could simply write",
    "start": "1300400",
    "end": "1306320"
  },
  {
    "text": "your own external environment subclass um",
    "start": "1306320",
    "end": "1311600"
  },
  {
    "text": "and then in the end so in the end in our lib as as soon as you use some of the algorithms they will always convert",
    "start": "1312720",
    "end": "1318080"
  },
  {
    "text": "everything will get always gets converted into a base end yeah so yeah um but yeah you could in your config i",
    "start": "1318080",
    "end": "1324000"
  },
  {
    "text": "actually have no issue i never did this i never tried providing a custom external length we",
    "start": "1324000",
    "end": "1329679"
  },
  {
    "text": "would have to i tried that last night that does seem to work",
    "start": "1329679",
    "end": "1334240"
  },
  {
    "text": "the one thing i notice is that with the standard environment you subtest usually from somewhere from",
    "start": "1335600",
    "end": "1341360"
  },
  {
    "text": "vector end so i think that our ellip would parallelize even within the same rollout work i could tell it to",
    "start": "1341360",
    "end": "1347600"
  },
  {
    "text": "but i don't need to worry about that if i just give it multiple rollover because it will still parallelize even with external ends right",
    "start": "1347600",
    "end": "1355679"
  },
  {
    "text": "yeah that's a good question uh the vectorized so we have external f we have external multi i'm not sure what happens in the vectorized case um i think",
    "start": "1356400",
    "end": "1363760"
  },
  {
    "text": "that's a good question but basically even without vector n if there's multiple rollout workers it will run",
    "start": "1363760",
    "end": "1368880"
  },
  {
    "text": "multiple yeah then you have the parallelism there yeah exactly even if you don't have a correlation that's that's something i",
    "start": "1368880",
    "end": "1374480"
  },
  {
    "text": "have to look up uh whether we support external ends even as a vectorized sequential stack kind of like i'm not",
    "start": "1374480",
    "end": "1380080"
  },
  {
    "text": "sure actually it can't be so much it may not be possible it's maybe something that we say because it's external",
    "start": "1380080",
    "end": "1385600"
  },
  {
    "text": "anyways i think the paradigm is a bit weird right like you yeah no one else is  you how do you say it's kind of",
    "start": "1385600",
    "end": "1391679"
  },
  {
    "text": "less like returns um",
    "start": "1391679",
    "end": "1397679"
  },
  {
    "text": "and then my second question is because yeah sorry so here is my",
    "start": "1397679",
    "end": "1403039"
  },
  {
    "text": "last direction from oh sorry or interrupt so here's the the answer so",
    "start": "1403039",
    "end": "1408320"
  },
  {
    "text": "if no not equal to one then we say uh you cannot support vectorization",
    "start": "1408320",
    "end": "1414919"
  },
  {
    "text": "if i subclass from external end the external end class itself is not a base",
    "start": "1416080",
    "end": "1421520"
  },
  {
    "text": "end i think it said subclasses from threading the thread or something correct and it's going to be the rl",
    "start": "1421520",
    "end": "1427440"
  },
  {
    "text": "internally then wraps this around something that looks like a they said it's what what happens here exactly so",
    "start": "1427440",
    "end": "1433520"
  },
  {
    "text": "everything in our lip whatever you do whether you supply a gym end or a multi-agent n or a vectorized",
    "start": "1433520",
    "end": "1439760"
  },
  {
    "text": "and or an external multi-agent and everything always automatically gets converted in the end to a base end",
    "start": "1439760",
    "end": "1445919"
  },
  {
    "text": "and our lip under the hood and then the sampling process uses that base end api so if i wanted to have an external",
    "start": "1445919",
    "end": "1452480"
  },
  {
    "text": "end and put the wrapper around it i would need to call something like two",
    "start": "1452480",
    "end": "1457919"
  },
  {
    "text": "base and on the external end then pass that into a wrapper some architecture like that",
    "start": "1457919",
    "end": "1464559"
  },
  {
    "text": "could work correct um you could just provide your subclass",
    "start": "1464559",
    "end": "1471039"
  },
  {
    "text": "of external and our liquid no oh it's an external n so let me call the two bases but my environment",
    "start": "1471039",
    "end": "1476960"
  },
  {
    "text": "you could overwrite it so if i put something like",
    "start": "1476960",
    "end": "1484480"
  },
  {
    "text": "mind observation wrappers directly around the base ends that wouldn't work because",
    "start": "1485039",
    "end": "1490880"
  },
  {
    "text": "i don't know what to do with the thread but if i end first",
    "start": "1490880",
    "end": "1497200"
  },
  {
    "text": "or do something similar with the gym and that that could work right",
    "start": "1497200",
    "end": "1503840"
  },
  {
    "text": "yeah with the gym and yeah i'm not sure about deep minds um i mean it's not specifically about the",
    "start": "1504000",
    "end": "1509840"
  },
  {
    "text": "deep mind breakfast but yeah with the gym you can definitely slap a wrap around it and then provide that that's that that works of course yeah okay and",
    "start": "1509840",
    "end": "1516240"
  },
  {
    "text": "right so yeah yeah that's the recommended way of of doing things if you want to",
    "start": "1516240",
    "end": "1521919"
  },
  {
    "text": "yeah basically hack your ends um we recommend to use gym wrappers rabbits again for the reward for the",
    "start": "1521919",
    "end": "1527520"
  },
  {
    "text": "observation and then hand that to our lid yeah okay one thing",
    "start": "1527520",
    "end": "1533600"
  },
  {
    "start": "1531000",
    "end": "1623000"
  },
  {
    "text": "i've also been trying to do in one of my settings is have multiple agents",
    "start": "1533600",
    "end": "1539120"
  },
  {
    "text": "and have from the same sequence of observations actions",
    "start": "1539120",
    "end": "1546080"
  },
  {
    "text": "have different episode segmentation so different agents so my environment generates 20 steps",
    "start": "1546080",
    "end": "1553760"
  },
  {
    "text": "for agent 1 that's one single 20 step episode for agent two it should be two",
    "start": "1553760",
    "end": "1559840"
  },
  {
    "text": "episodes of ten steps each um doesn't directly work if it just set",
    "start": "1559840",
    "end": "1567039"
  },
  {
    "text": "done for the age and true in the middle of the episode and then unset it um then there is a complaint from the",
    "start": "1567039",
    "end": "1574000"
  },
  {
    "text": "samsung collector that it's it breaks down somewhere in the sample collector um",
    "start": "1574000",
    "end": "1580240"
  },
  {
    "text": "many on on discuss had a really interesting workaround where basically",
    "start": "1580240",
    "end": "1587120"
  },
  {
    "text": "i make two copies of agent two so i have three agents in the environment and agent 2a and agent 2b are mapped to",
    "start": "1587120",
    "end": "1594720"
  },
  {
    "text": "the same policy in the policymap function and i think that does",
    "start": "1594720",
    "end": "1600640"
  },
  {
    "text": "the trick that should do what i wanted to do um it's a little bit tedious though because i now have to keep track of two",
    "start": "1600640",
    "end": "1606880"
  },
  {
    "text": "or potentially very very many copies of agent two in the environment they also have to know in advance how",
    "start": "1606880",
    "end": "1612720"
  },
  {
    "text": "many the maximum is ever going to be because rl lip wants to have this set of agents agent ids",
    "start": "1612720",
    "end": "1618640"
  },
  {
    "text": "um is there an easier way to do what i want to do that's that sounds pretty heckish pretty",
    "start": "1618640",
    "end": "1625840"
  },
  {
    "start": "1623000",
    "end": "1736000"
  },
  {
    "text": "genius um but then yeah i agree it would move the problem into the environment then it becomes ugly",
    "start": "1625840",
    "end": "1630960"
  },
  {
    "text": "there maybe um as as hopefully i understood it correctly but",
    "start": "1630960",
    "end": "1636000"
  },
  {
    "text": "yeah you can i think or you can also use a callback um yeah so if you if you go to the examples",
    "start": "1636000",
    "end": "1641760"
  },
  {
    "text": "folder there's a custom callbacks example um",
    "start": "1641760",
    "end": "1647120"
  },
  {
    "text": "you have to write a sub class yeah and then you can exactly sorry",
    "start": "1647120",
    "end": "1652320"
  },
  {
    "text": "in on post process trajectory i look for whenever in the info dictionary",
    "start": "1652320",
    "end": "1658399"
  },
  {
    "text": "my special key is set to true i insert the done",
    "start": "1658399",
    "end": "1663440"
  },
  {
    "text": "into the project correctly basically in this in this method here if you if you take the the callbacks uh just use",
    "start": "1663440",
    "end": "1670960"
  },
  {
    "text": "the default callbacks overwrite it uh overwrite the the post on postprocess trajectory methods in there you get the",
    "start": "1670960",
    "end": "1678000"
  },
  {
    "text": "uh the post process batch yeah so this is your your multi-agent batch uh arriving right now at for this",
    "start": "1678000",
    "end": "1684240"
  },
  {
    "text": "particular policy uh here you can say um you can measure the lens you can say after 20 or after 10 i'm going to insert",
    "start": "1684240",
    "end": "1690960"
  },
  {
    "text": "it done and then do something with that and then that will eventually be forwarded to the loss function yeah",
    "start": "1690960",
    "end": "1698000"
  },
  {
    "text": "okay yeah so that's i think should work uh let's say let's take ppo and then ppo",
    "start": "1698000",
    "end": "1704880"
  },
  {
    "text": "would use the done flag to properly calculate the um the advantages or the the gae whatever",
    "start": "1704880",
    "end": "1711760"
  },
  {
    "text": "um yeah and again you can you can tinker here in this you can tinker with the rewards you can add more down flags or",
    "start": "1711760",
    "end": "1718320"
  },
  {
    "text": "or change the actions or whatever you want to do um this is all pre-loss calculation so this this should",
    "start": "1718320",
    "end": "1723760"
  },
  {
    "text": "work yeah okay cool perfect thank you",
    "start": "1723760",
    "end": "1729279"
  },
  {
    "text": "yeah sure sure of course great questions really really deep that's nice um yeah so",
    "start": "1729279",
    "end": "1735840"
  },
  {
    "text": "should we uh should we talk about your uh your problem with the order skilling",
    "start": "1735840",
    "end": "1741039"
  },
  {
    "start": "1736000",
    "end": "2421000"
  },
  {
    "text": "oh yeah yeah many thanks uh yes sir would you mind if i share my screen of",
    "start": "1741039",
    "end": "1746640"
  },
  {
    "text": "course sorry let me uh yeah i stopped sharing so go ahead okay",
    "start": "1746640",
    "end": "1752399"
  },
  {
    "text": "uh i i actually uh posted uh uh my my issue on github and i just link",
    "start": "1752399",
    "end": "1759840"
  },
  {
    "text": "in the comments uh so my use case is much simpler",
    "start": "1759840",
    "end": "1767840"
  },
  {
    "text": "so as you can see here the gpu.yaml file is just the one i copy and paste from",
    "start": "1767840",
    "end": "1775360"
  },
  {
    "text": "the official github repo for the aws cluster",
    "start": "1775360",
    "end": "1782480"
  },
  {
    "text": "and for my cluster i i used the re-iml image",
    "start": "1782480",
    "end": "1790080"
  },
  {
    "text": "with real media docker and for both for both height and the worker",
    "start": "1790080",
    "end": "1797520"
  },
  {
    "text": "for both head and worker i use the same image",
    "start": "1797520",
    "end": "1802720"
  },
  {
    "text": "and also for the instance type i am for tests i'm using p2 extra large",
    "start": "1802720",
    "end": "1810480"
  },
  {
    "text": "here each instance carries two gpus and four cpus",
    "start": "1810480",
    "end": "1817440"
  },
  {
    "text": "and this is basically all my yaml file and for the i'll be",
    "start": "1817440",
    "end": "1824960"
  },
  {
    "text": "uh this one is copied from the official repos",
    "start": "1824960",
    "end": "1830720"
  },
  {
    "text": "configuration and in this particular the number of workers is four and uh uh",
    "start": "1830720",
    "end": "1837760"
  },
  {
    "text": "per gpu or gpu for workers one and uh so the way the way i'm uh i'm executing",
    "start": "1837760",
    "end": "1846640"
  },
  {
    "text": "those demo files is like reapp gpu.mo and uh synchronize my uh",
    "start": "1846640",
    "end": "1854480"
  },
  {
    "text": "my i live yaml files to the server and so this step is i'm really confused should",
    "start": "1854480",
    "end": "1863120"
  },
  {
    "text": "i just execute are i'll leave on the head node",
    "start": "1863120",
    "end": "1869039"
  },
  {
    "text": "am i doing this correct uh well can you so so your your header in your",
    "start": "1869039",
    "end": "1876399"
  },
  {
    "text": "yammer file is so the name of your uh of your cluster is gpu.yaml",
    "start": "1876399",
    "end": "1881600"
  },
  {
    "text": "yeah correct the name is gpu.yaml uh yeah and this one is just for the",
    "start": "1881600",
    "end": "1887519"
  },
  {
    "text": "ddpo bdppo algorithm um",
    "start": "1887519",
    "end": "1892960"
  },
  {
    "text": "and i haven't i haven't worked with the open source another very long time i think this is the way to do this right ray exec",
    "start": "1892960",
    "end": "1899519"
  },
  {
    "text": "uh what happens when you do this when you run the line 230 what what happens to the exact line",
    "start": "1899519",
    "end": "1905039"
  },
  {
    "text": "and the problem here is it uh it does not scale",
    "start": "1905039",
    "end": "1910159"
  },
  {
    "text": "uh so uh above this line above this line is uh",
    "start": "1910159",
    "end": "1915679"
  },
  {
    "text": "the result after executing uh the uh exaggeration uh",
    "start": "1915679",
    "end": "1922480"
  },
  {
    "text": "yeah sorry so if it's impending you don't have enough resources",
    "start": "1922480",
    "end": "1928000"
  },
  {
    "text": "on that yeah so basically so you're using gdpr using a num gpus per worker and you have",
    "start": "1928000",
    "end": "1935279"
  },
  {
    "text": "four workers so you need four gpus right uh and i think your p3",
    "start": "1935279",
    "end": "1940720"
  },
  {
    "text": "but there are only but there are only two gpus on that cluster",
    "start": "1940720",
    "end": "1946240"
  },
  {
    "text": "uh yeah or even just one in the uh holland how many do you have two what is your min number of workers and",
    "start": "1946240",
    "end": "1953120"
  },
  {
    "text": "max on the in the cluster config one of two and ten or something so it is 120",
    "start": "1953120",
    "end": "1960720"
  },
  {
    "text": "120 okay uh so you start with one and then it doesn't scale that doesn't it doesn't bring up the next machine to",
    "start": "1960720",
    "end": "1967200"
  },
  {
    "text": "reach the four gpus right so each machine has how many what is what is your machine time p2",
    "start": "1967200",
    "end": "1973679"
  },
  {
    "text": "so a p2x large has one gpu and four cpus and that's exactly what it shows in your in your pending where it says pending",
    "start": "1974799",
    "end": "1981440"
  },
  {
    "text": "and you look like three lines above that it says resources requested zero of four cpus and zero of one gpu so that's",
    "start": "1981440",
    "end": "1988240"
  },
  {
    "text": "that's you basically brought up a single machine a single p2 but but this if it's a single pd you only have one gpu there",
    "start": "1988240",
    "end": "1995039"
  },
  {
    "text": "it says zero out of one it's not true no but they only have one so",
    "start": "1995039",
    "end": "2001679"
  },
  {
    "text": "yeah the problem is that we don't it doesn't seem to auto scale and the question is why right um",
    "start": "2001760",
    "end": "2007840"
  },
  {
    "text": "yeah the quota is there right you have enough quota for",
    "start": "2007840",
    "end": "2012880"
  },
  {
    "text": "for the resources there was sometimes a problem i had uh yeah i have enough quota for that",
    "start": "2012880",
    "end": "2019919"
  },
  {
    "text": "right okay let's see and then the demand success one cpu for the driver that's",
    "start": "2019919",
    "end": "2025760"
  },
  {
    "text": "okay and then four pack that's the four workers each one has one needs one cpu and one gpu that sounds so",
    "start": "2025760",
    "end": "2032799"
  },
  {
    "text": "good placement groups okay and then the auto scale so what does the autoscaler do",
    "start": "2032799",
    "end": "2038399"
  },
  {
    "text": "pending yeah what we sometimes tell people is to try like a larger",
    "start": "2038399",
    "end": "2043600"
  },
  {
    "text": "note from from the go already um so instead of p2 x large",
    "start": "2043600",
    "end": "2050560"
  },
  {
    "text": "uh p2 8x large or something that has enough so you have enough gpus right away",
    "start": "2050560",
    "end": "2056720"
  },
  {
    "text": "um but it is i i i acknowledge it is a problem it should it should properly",
    "start": "2056720",
    "end": "2063358"
  },
  {
    "text": "auto scale i mean it may take a while and take a minute or so but at some point it should bring up all these four",
    "start": "2063359",
    "end": "2068638"
  },
  {
    "text": "it should bring up four p2x large machines because you need four gpus yeah and that's that's apparently not",
    "start": "2068639",
    "end": "2074398"
  },
  {
    "text": "happening and that's oh yeah that's not good um",
    "start": "2074399",
    "end": "2079839"
  },
  {
    "text": "um so just a couple of like debugging questions have you tried i don't know um",
    "start": "2079839",
    "end": "2085679"
  },
  {
    "text": "bringing your resource request down to to fit like in a single instance or try",
    "start": "2085679",
    "end": "2090960"
  },
  {
    "text": "a larger instance does that work uh i actually tried the noun gpu",
    "start": "2090960",
    "end": "2098079"
  },
  {
    "text": "version it it also does not work",
    "start": "2098079",
    "end": "2103520"
  },
  {
    "text": "can you try the non-gpu version with only three workers so that you have then you have four cpus right uh",
    "start": "2103520",
    "end": "2111520"
  },
  {
    "text": "three for the workers and one for the for the driver i believe should be just this jam or file just",
    "start": "2111520",
    "end": "2117040"
  },
  {
    "text": "just let me double check and yeah just get it to run with some setting and then we can we can take it",
    "start": "2117040",
    "end": "2122400"
  },
  {
    "text": "from there yeah um i do think there's a problem though you know yeah or the other scale in our lip uh",
    "start": "2122400",
    "end": "2130640"
  },
  {
    "text": "should be this one right uh yeah this is your conflict so you just try exactly just set num workers to",
    "start": "2140400",
    "end": "2147599"
  },
  {
    "text": "three let's say okay um num gpu zero uh num gpus per worker",
    "start": "2147599",
    "end": "2155760"
  },
  {
    "text": "also zero um uh sorry that looks a little different",
    "start": "2155760",
    "end": "2161839"
  },
  {
    "text": "that's that's not your ddpo file yeah that's that's pbo so",
    "start": "2161839",
    "end": "2167760"
  },
  {
    "text": "ddppo has to specify at least one gpu yeah",
    "start": "2167760",
    "end": "2172880"
  },
  {
    "text": "normally yeah yeah i think you can also run it without gpus actually but yeah",
    "start": "2172880",
    "end": "2178320"
  },
  {
    "text": "this should be already let's just roll yeah yeah that's right let me just try this one",
    "start": "2178320",
    "end": "2184839"
  },
  {
    "text": "okay terminate this",
    "start": "2184839",
    "end": "2189119"
  },
  {
    "text": "uh simon you had also sometimes problems with bringing up clusters right or with auto scaling i remember you had or was",
    "start": "2194720",
    "end": "2200240"
  },
  {
    "text": "it just a single note thing that didn't work yeah it was very similar to this one and yeah for me it was like one one",
    "start": "2200240",
    "end": "2207040"
  },
  {
    "text": "issue was actually due to to the quota so there wasn't more",
    "start": "2207040",
    "end": "2212640"
  },
  {
    "text": "gpu available for me um so that kept uh kept pending and then",
    "start": "2212640",
    "end": "2218400"
  },
  {
    "text": "i remember there was something with the accelerators i also had to like somehow increase",
    "start": "2218400",
    "end": "2225599"
  },
  {
    "text": "the accelerators or at least say that in in the yaml files such that it",
    "start": "2225599",
    "end": "2232000"
  },
  {
    "text": "um that it started to run but i try to like [Music]",
    "start": "2232000",
    "end": "2237280"
  },
  {
    "text": "find that problem again",
    "start": "2237280",
    "end": "2241400"
  },
  {
    "text": "in this case i think everything works yeah that's okay so that minimal example",
    "start": "2249440",
    "end": "2255599"
  },
  {
    "text": "works okay that's just without gpus yeah but guys running okay okay that makes sense yeah",
    "start": "2255599",
    "end": "2261440"
  },
  {
    "text": "but also also does not work yeah you can also see right like the",
    "start": "2261440",
    "end": "2266480"
  },
  {
    "text": "other ones are pending it's not requesting because you only have four cpus on that machine yeah there are four experiments right",
    "start": "2266480",
    "end": "2273520"
  },
  {
    "text": "i know but each one takes three workers so they this is yes but if the other scale it would have worked they should",
    "start": "2273520",
    "end": "2278880"
  },
  {
    "text": "have run in parallel yeah okay yeah yeah",
    "start": "2278880",
    "end": "2283559"
  },
  {
    "text": "the auto scale looks looks look like there's nothing wrong right it's just",
    "start": "2285040",
    "end": "2290480"
  },
  {
    "text": "it the demand is three pending placement group right but then it doesn't really act on",
    "start": "2290480",
    "end": "2295920"
  },
  {
    "text": "it or it doesn't say why yeah yeah",
    "start": "2295920",
    "end": "2301280"
  },
  {
    "text": "and actually if i change this one if i change the minimum workers",
    "start": "2301280",
    "end": "2306720"
  },
  {
    "text": "like to three or something uh the louis cluster can actually first up",
    "start": "2306720",
    "end": "2313680"
  },
  {
    "text": "like three workers but still uh the io leap",
    "start": "2313680",
    "end": "2319280"
  },
  {
    "text": "is not able to uh dispatch those tasks to those workers",
    "start": "2319280",
    "end": "2325520"
  },
  {
    "text": "okay yeah so that's what you'll still be pending",
    "start": "2325520",
    "end": "2330960"
  },
  {
    "text": "yeah yeah i would imagine if you if you set main workers higher then it wouldn't have to auto scale it would just start",
    "start": "2332000",
    "end": "2337359"
  },
  {
    "text": "right away with a large number of notes and then it would be okay yeah yeah yeah",
    "start": "2337359",
    "end": "2343280"
  },
  {
    "text": "it should be this way but in fact it does not work i don't know why it seems only you only",
    "start": "2343280",
    "end": "2351359"
  },
  {
    "text": "take whatever it has on the head mode so can you",
    "start": "2351359",
    "end": "2357119"
  },
  {
    "text": "attach your issue with this exact like config for the tpo one and the yaml",
    "start": "2357119",
    "end": "2362800"
  },
  {
    "text": "cluster that they are for the cluster",
    "start": "2362800",
    "end": "2368000"
  },
  {
    "text": "look at it uh yep uh in my issue i",
    "start": "2368000",
    "end": "2373200"
  },
  {
    "text": "in my issue i yeah i i i posted those files here oh okay",
    "start": "2373200",
    "end": "2378480"
  },
  {
    "text": "yeah so that's your gpu ml and then the early testimony is that the ddpo one pvo",
    "start": "2378480",
    "end": "2384640"
  },
  {
    "text": "one yeah yeah okay okay but it didn't work even for the",
    "start": "2384640",
    "end": "2390480"
  },
  {
    "text": "tune example like atari ppo right where you have four experiments but all",
    "start": "2390480",
    "end": "2396000"
  },
  {
    "text": "of them require like only force for cpus you don't run the the experiments in",
    "start": "2396000",
    "end": "2401359"
  },
  {
    "text": "parallel it just runs one at a time yeah yeah okay so it's not really a gpu issue at",
    "start": "2401359",
    "end": "2408000"
  },
  {
    "text": "all it's just like a placement yeah just uh auto scaling usual hi guys",
    "start": "2408000",
    "end": "2416400"
  },
  {
    "text": "okay we can take a look at it okay thanks so much",
    "start": "2416400",
    "end": "2421440"
  },
  {
    "start": "2421000",
    "end": "2590000"
  },
  {
    "text": "uh and also another quick question uh how do i",
    "start": "2421440",
    "end": "2427119"
  },
  {
    "text": "uh if i'm using the uh recluster and with docker image",
    "start": "2427119",
    "end": "2433359"
  },
  {
    "text": "uh i i didn't see in the yaml file where i can expose my port",
    "start": "2433359",
    "end": "2440480"
  },
  {
    "text": "so uh my my goal here is to use the uh rule dashboard",
    "start": "2440480",
    "end": "2447440"
  },
  {
    "text": "but in this case",
    "start": "2447440",
    "end": "2451318"
  },
  {
    "text": "since i did not uh forward the part uh to from from the",
    "start": "2454800",
    "end": "2461440"
  },
  {
    "text": "docker to to the instance uh",
    "start": "2461440",
    "end": "2467838"
  },
  {
    "text": "the the dashboard is actually not working yeah",
    "start": "2468079",
    "end": "2473599"
  },
  {
    "text": "now i uh so the way i'm connected to this uh fh",
    "start": "2473599",
    "end": "2481280"
  },
  {
    "text": "is through the port forwarding i specified the uh dash aisle",
    "start": "2481280",
    "end": "2487440"
  },
  {
    "text": "uh argument to forward the",
    "start": "2487440",
    "end": "2492880"
  },
  {
    "text": "this part to my local computer but but if i visit the 8265",
    "start": "2492880",
    "end": "2502680"
  },
  {
    "text": "there's nothing comes up and inside if i do not use docker image",
    "start": "2502960",
    "end": "2509520"
  },
  {
    "text": "here if i do not use docker image if i simply uh re remove this section and everything",
    "start": "2509520",
    "end": "2517520"
  },
  {
    "text": "works yeah i guess the usual is that the",
    "start": "2517520",
    "end": "2522640"
  },
  {
    "text": "docker does not forward is paul yeah it could be yeah exactly it",
    "start": "2522640",
    "end": "2527680"
  },
  {
    "text": "could be a port inside the docker or something like that uh did you ask this question on the on",
    "start": "2527680",
    "end": "2533200"
  },
  {
    "text": "the on the uh yeah like",
    "start": "2533200",
    "end": "2538880"
  },
  {
    "text": "just a quick check the issue number maybe we can escalate this yeah",
    "start": "2538880",
    "end": "2545839"
  },
  {
    "text": "ah should be this one on okay",
    "start": "2546400",
    "end": "2551838"
  },
  {
    "text": "yeah it should be this one yeah can you put in the chat here i can i can",
    "start": "2553359",
    "end": "2558800"
  },
  {
    "text": "yeah thank you so thank you guys so much that's on my channel i'll pick someone",
    "start": "2558800",
    "end": "2564240"
  },
  {
    "text": "on that issue uh take another look again yeah thanks aaron for your free time for your um sharing the problems with us um",
    "start": "2564240",
    "end": "2572160"
  },
  {
    "text": "thank you yeah of course uh again this is every two weeks feel",
    "start": "2572160",
    "end": "2577440"
  },
  {
    "text": "free to show up regularly and participate um",
    "start": "2577440",
    "end": "2582560"
  },
  {
    "text": "yeah good to see everyone yeah have a nice evening okay take care bye thank you bye",
    "start": "2582560",
    "end": "2590520"
  }
]
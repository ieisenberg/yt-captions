[
  {
    "text": "good afternoon everyone our talk is",
    "start": "4720",
    "end": "7240"
  },
  {
    "text": "autonomous Mobility at zukes meets Ray",
    "start": "7240",
    "end": "10360"
  },
  {
    "text": "uh I'm Eli uh wrong will be giving uh",
    "start": "10360",
    "end": "12719"
  },
  {
    "text": "the second half of the talk",
    "start": "12719",
    "end": "14719"
  },
  {
    "text": "today uh I've been with zuk since 2019",
    "start": "14719",
    "end": "17400"
  },
  {
    "text": "so a little over five years I've had a",
    "start": "17400",
    "end": "19199"
  },
  {
    "text": "number of roles at the company uh",
    "start": "19199",
    "end": "20800"
  },
  {
    "text": "manager of ml platform I'm currently an",
    "start": "20800",
    "end": "22680"
  },
  {
    "text": "individual contributor on the ml",
    "start": "22680",
    "end": "24199"
  },
  {
    "text": "platform team uh I focus on ML training",
    "start": "24199",
    "end": "28679"
  },
  {
    "text": "uh wrong is uh coming up on two years",
    "start": "28679",
    "end": "32160"
  },
  {
    "text": "he's also a staff software engineer on",
    "start": "32160",
    "end": "33840"
  },
  {
    "text": "the ml platform team his Focus has been",
    "start": "33840",
    "end": "36360"
  },
  {
    "text": "on inference and GPU performance",
    "start": "36360",
    "end": "39120"
  },
  {
    "text": "optimization uh zuk is an autonomous",
    "start": "39120",
    "end": "41520"
  },
  {
    "text": "Mobility company founded in",
    "start": "41520",
    "end": "43640"
  },
  {
    "text": "2014 um as you might be able to tell by",
    "start": "43640",
    "end": "47000"
  },
  {
    "text": "the image there we have a focus on",
    "start": "47000",
    "end": "48680"
  },
  {
    "text": "purpose-built",
    "start": "48680",
    "end": "50280"
  },
  {
    "text": "robotaxis okay so at zuk we use Ray for",
    "start": "50280",
    "end": "53239"
  },
  {
    "text": "quite a bit of things um you know we use",
    "start": "53239",
    "end": "55440"
  },
  {
    "text": "Ray train data tune serve uh but the",
    "start": "55440",
    "end": "58519"
  },
  {
    "text": "ways that we're using Ray not",
    "start": "58519",
    "end": "60600"
  },
  {
    "text": "particularly interesting I think for a",
    "start": "60600",
    "end": "62320"
  },
  {
    "text": "general audience like this um basically",
    "start": "62320",
    "end": "65439"
  },
  {
    "text": "we are using Ray to do the thing that it",
    "start": "65439",
    "end": "67040"
  },
  {
    "text": "says it's good at and it's good at doing",
    "start": "67040",
    "end": "68640"
  },
  {
    "text": "it so you're probably wondering okay",
    "start": "68640",
    "end": "70720"
  },
  {
    "text": "what is this talk going to be about then",
    "start": "70720",
    "end": "72640"
  },
  {
    "text": "um let's get into this but first let me",
    "start": "72640",
    "end": "75439"
  },
  {
    "text": "recap what 2014 was um that was a decade",
    "start": "75439",
    "end": "78240"
  },
  {
    "text": "ago uh Happy by farel was the number one",
    "start": "78240",
    "end": "81720"
  },
  {
    "text": "single the top of the box office was the",
    "start": "81720",
    "end": "84119"
  },
  {
    "text": "first Guardians of the Galaxy movie uh",
    "start": "84119",
    "end": "86280"
  },
  {
    "text": "and the third Hunger Games movie the ALS",
    "start": "86280",
    "end": "89159"
  },
  {
    "text": "Ice Bucket challenge was taking over",
    "start": "89159",
    "end": "90920"
  },
  {
    "text": "social media uh a little bit more on",
    "start": "90920",
    "end": "94000"
  },
  {
    "text": "topic generative adversarial networks",
    "start": "94000",
    "end": "96119"
  },
  {
    "text": "were introduced uh and kubernetes was",
    "start": "96119",
    "end": "99640"
  },
  {
    "text": "announced but 1.0 didn't come out till",
    "start": "99640",
    "end": "101799"
  },
  {
    "text": "the following year uh the gpus of the",
    "start": "101799",
    "end": "105240"
  },
  {
    "text": "year were the G uh the Nvidia GeForce",
    "start": "105240",
    "end": "107719"
  },
  {
    "text": "GTX 980 and the Tesla k80 so all in all",
    "start": "107719",
    "end": "111960"
  },
  {
    "text": "is a different era in that decade zuk",
    "start": "111960",
    "end": "115360"
  },
  {
    "text": "has built a lot of on-prem Hardware you",
    "start": "115360",
    "end": "118640"
  },
  {
    "text": "can see some of that in the picture here",
    "start": "118640",
    "end": "120759"
  },
  {
    "text": "we have an AWS compute cluster uh",
    "start": "120759",
    "end": "123320"
  },
  {
    "text": "controlled by slurm we've built wrappers",
    "start": "123320",
    "end": "125360"
  },
  {
    "text": "around slurm storage systems remote",
    "start": "125360",
    "end": "127920"
  },
  {
    "text": "build execution anal training clusters",
    "start": "127920",
    "end": "129560"
  },
  {
    "text": "simulation clusters and all of that was",
    "start": "129560",
    "end": "131959"
  },
  {
    "text": "in place before we decided to introduce",
    "start": "131959",
    "end": "135239"
  },
  {
    "text": "Ray if we can use Ry you almost it's",
    "start": "135239",
    "end": "138480"
  },
  {
    "text": "almost certainly that you can introduce",
    "start": "138480",
    "end": "139760"
  },
  {
    "text": "Ray into your environment as well um we",
    "start": "139760",
    "end": "142000"
  },
  {
    "text": "feel that the integration work that we",
    "start": "142000",
    "end": "143519"
  },
  {
    "text": "had to do in order to make it work for",
    "start": "143519",
    "end": "145040"
  },
  {
    "text": "us was reasonable and like I said the",
    "start": "145040",
    "end": "146959"
  },
  {
    "text": "features work as advertised so what",
    "start": "146959",
    "end": "149280"
  },
  {
    "text": "we're going to do here we're going to",
    "start": "149280",
    "end": "150280"
  },
  {
    "text": "talk a little bit about some of the main",
    "start": "150280",
    "end": "151680"
  },
  {
    "text": "challenges that we faced int uh",
    "start": "151680",
    "end": "153599"
  },
  {
    "text": "introducing Ray all right first is like",
    "start": "153599",
    "end": "157959"
  },
  {
    "text": "I said we use slurm the vast majority of",
    "start": "157959",
    "end": "160400"
  },
  {
    "text": "our computers managed by slurm um if",
    "start": "160400",
    "end": "162440"
  },
  {
    "text": "you're not familiar with what slurm is",
    "start": "162440",
    "end": "165239"
  },
  {
    "text": "it's cluster management job",
    "start": "165239",
    "end": "166760"
  },
  {
    "text": "orchestration software uh started at",
    "start": "166760",
    "end": "168959"
  },
  {
    "text": "Lawrence Livermore uh over 20 years ago",
    "start": "168959",
    "end": "172599"
  },
  {
    "text": "um it's the kind of software that's in",
    "start": "172599",
    "end": "174159"
  },
  {
    "text": "use by more than half of the top 500",
    "start": "174159",
    "end": "176560"
  },
  {
    "text": "supercomputer list um it could be a",
    "start": "176560",
    "end": "179560"
  },
  {
    "text": "little rigid when it comes to scheduling",
    "start": "179560",
    "end": "181400"
  },
  {
    "text": "it's very much a you're going to get 4k",
    "start": "181400",
    "end": "184319"
  },
  {
    "text": "CPUs and uh 1K gpus for 48 hours if your",
    "start": "184319",
    "end": "188319"
  },
  {
    "text": "job takes 49 too bad we're killing your",
    "start": "188319",
    "end": "190280"
  },
  {
    "text": "job and you're going to have to figure",
    "start": "190280",
    "end": "192200"
  },
  {
    "text": "out what to do with the pieces that are",
    "start": "192200",
    "end": "193280"
  },
  {
    "text": "left over",
    "start": "193280",
    "end": "194920"
  },
  {
    "text": "um it approaches scheduling as a bin",
    "start": "194920",
    "end": "197720"
  },
  {
    "text": "packing problem and so if you have 900",
    "start": "197720",
    "end": "201840"
  },
  {
    "text": "gpus free right now it's not going going",
    "start": "201840",
    "end": "203879"
  },
  {
    "text": "to start your job because you said you",
    "start": "203879",
    "end": "205239"
  },
  {
    "text": "needed a thousand um so you know it's",
    "start": "205239",
    "end": "208200"
  },
  {
    "text": "not really designed for an 8 us spot",
    "start": "208200",
    "end": "210319"
  },
  {
    "text": "instance kind of World um which means",
    "start": "210319",
    "end": "213480"
  },
  {
    "text": "that it it's kind of a mismatch between",
    "start": "213480",
    "end": "215480"
  },
  {
    "text": "how Ry thinks about the world which is I",
    "start": "215480",
    "end": "217280"
  },
  {
    "text": "think a much more modern approach um so",
    "start": "217280",
    "end": "220959"
  },
  {
    "text": "compute is allocated per job and it does",
    "start": "220959",
    "end": "223280"
  },
  {
    "text": "not persist once the job is completed so",
    "start": "223280",
    "end": "226239"
  },
  {
    "text": "trying to debug an error live by the",
    "start": "226239",
    "end": "228080"
  },
  {
    "text": "time you realize an error has happened",
    "start": "228080",
    "end": "229480"
  },
  {
    "text": "it's already torn down the the job and",
    "start": "229480",
    "end": "231159"
  },
  {
    "text": "is putting the next thing on that that",
    "start": "231159",
    "end": "233200"
  },
  {
    "text": "compute um in terms of Ray the head node",
    "start": "233200",
    "end": "236319"
  },
  {
    "text": "is going to go away at the end of the",
    "start": "236319",
    "end": "237599"
  },
  {
    "text": "job uh unless you have a head node",
    "start": "237599",
    "end": "239480"
  },
  {
    "text": "living somewhere else which we'll get to",
    "start": "239480",
    "end": "240799"
  },
  {
    "text": "in a minute um slurm has this concept of",
    "start": "240799",
    "end": "245200"
  },
  {
    "text": "being able to run multiple jobs on a",
    "start": "245200",
    "end": "247239"
  },
  {
    "text": "single note at the same time uh we ended",
    "start": "247239",
    "end": "249400"
  },
  {
    "text": "up having some Port conflicts with Rey",
    "start": "249400",
    "end": "251959"
  },
  {
    "text": "uh with that and I'll talk about this",
    "start": "251959",
    "end": "254840"
  },
  {
    "text": "more in a minute but over committing",
    "start": "254840",
    "end": "256079"
  },
  {
    "text": "resources can be very easy in this kind",
    "start": "256079",
    "end": "257799"
  },
  {
    "text": "of situation uh also slurm doesn't",
    "start": "257799",
    "end": "259959"
  },
  {
    "text": "really have a concept of adding compute",
    "start": "259959",
    "end": "261440"
  },
  {
    "text": "to a job post launch so you start with",
    "start": "261440",
    "end": "264479"
  },
  {
    "text": "the resources you're going to end with",
    "start": "264479",
    "end": "267400"
  },
  {
    "text": "okay um so let's talk about how we can",
    "start": "267400",
    "end": "269360"
  },
  {
    "text": "deal with the lack of head node",
    "start": "269360",
    "end": "270560"
  },
  {
    "text": "persistence solution solution one is my",
    "start": "270560",
    "end": "272840"
  },
  {
    "text": "favorite kind of solution you just",
    "start": "272840",
    "end": "274039"
  },
  {
    "text": "ignore the problem um and that's",
    "start": "274039",
    "end": "276160"
  },
  {
    "text": "somewhat flippant but it's true you can",
    "start": "276160",
    "end": "277600"
  },
  {
    "text": "actually get a lot of valuable work done",
    "start": "277600",
    "end": "280880"
  },
  {
    "text": "using Ray without a persistent head node",
    "start": "280880",
    "end": "283440"
  },
  {
    "text": "um you just set up and tear down your",
    "start": "283440",
    "end": "285160"
  },
  {
    "text": "entire cluster your quote unquote entire",
    "start": "285160",
    "end": "287240"
  },
  {
    "text": "cluster in the compute that slurm",
    "start": "287240",
    "end": "288800"
  },
  {
    "text": "allocates um and you like I said you can",
    "start": "288800",
    "end": "291720"
  },
  {
    "text": "get a lot done without needing to solve",
    "start": "291720",
    "end": "293240"
  },
  {
    "text": "that particular problem what we ended up",
    "start": "293240",
    "end": "295120"
  },
  {
    "text": "doing was taking all of our array",
    "start": "295120",
    "end": "297960"
  },
  {
    "text": "initialization code and centralizing it",
    "start": "297960",
    "end": "300320"
  },
  {
    "text": "then standing up a persistent head node",
    "start": "300320",
    "end": "301919"
  },
  {
    "text": "on a different piece of compute uh not",
    "start": "301919",
    "end": "304440"
  },
  {
    "text": "managed by slurm and then pointing all",
    "start": "304440",
    "end": "306720"
  },
  {
    "text": "of that centralized initialization code",
    "start": "306720",
    "end": "308600"
  },
  {
    "text": "to that new head node um one thing I do",
    "start": "308600",
    "end": "311639"
  },
  {
    "text": "want to note that since we have multiple",
    "start": "311639",
    "end": "314280"
  },
  {
    "text": "Python and Ray versions in play we",
    "start": "314280",
    "end": "316720"
  },
  {
    "text": "actually needed multiple head nodes",
    "start": "316720",
    "end": "318280"
  },
  {
    "text": "because you have to match Python and Ray",
    "start": "318280",
    "end": "319800"
  },
  {
    "text": "versions",
    "start": "319800",
    "end": "321039"
  },
  {
    "text": "exactly um I also mentioned that the uh",
    "start": "321039",
    "end": "324680"
  },
  {
    "text": "slurm has the shared compute if you're",
    "start": "324680",
    "end": "326240"
  },
  {
    "text": "only going to be using half of the CPU",
    "start": "326240",
    "end": "327840"
  },
  {
    "text": "cores on a node slurm will happily put",
    "start": "327840",
    "end": "329919"
  },
  {
    "text": "another job on it um since Ray has a",
    "start": "329919",
    "end": "332360"
  },
  {
    "text": "similar concept there these two uh",
    "start": "332360",
    "end": "334360"
  },
  {
    "text": "Concepts kind of conflict with each",
    "start": "334360",
    "end": "335560"
  },
  {
    "text": "other a little bit um trying to spin up",
    "start": "335560",
    "end": "339039"
  },
  {
    "text": "multiple Ray jobs on this on a single",
    "start": "339039",
    "end": "340960"
  },
  {
    "text": "node ended up having Port conflicts",
    "start": "340960",
    "end": "342600"
  },
  {
    "text": "because you know Ray wants to use the",
    "start": "342600",
    "end": "344000"
  },
  {
    "text": "same port by default um so we had to do",
    "start": "344000",
    "end": "346560"
  },
  {
    "text": "some work in order to tell each Ray job",
    "start": "346560",
    "end": "348680"
  },
  {
    "text": "what ports it should be",
    "start": "348680",
    "end": "350479"
  },
  {
    "text": "using um obviously there's a lot of",
    "start": "350479",
    "end": "352880"
  },
  {
    "text": "different ways that you can solve this",
    "start": "352880",
    "end": "354840"
  },
  {
    "text": "uh one thing I'll note pure random does",
    "start": "354840",
    "end": "356479"
  },
  {
    "text": "work but eventually the birthday Paradox",
    "start": "356479",
    "end": "358199"
  },
  {
    "text": "is going to mean that you're going to",
    "start": "358199",
    "end": "359120"
  },
  {
    "text": "start having uh flaky failures where two",
    "start": "359120",
    "end": "361199"
  },
  {
    "text": "jobs try and use the same uh the same",
    "start": "361199",
    "end": "363280"
  },
  {
    "text": "port um what we ended up doing was",
    "start": "363280",
    "end": "366160"
  },
  {
    "text": "something fairly simple where we just",
    "start": "366160",
    "end": "367280"
  },
  {
    "text": "checked for open ports first we're not",
    "start": "367280",
    "end": "369000"
  },
  {
    "text": "often kicking off multiple jobs on the",
    "start": "369000",
    "end": "370919"
  },
  {
    "text": "same node at the same time so if a node",
    "start": "370919",
    "end": "373240"
  },
  {
    "text": "was open that was good enough um I",
    "start": "373240",
    "end": "376000"
  },
  {
    "text": "mentioned also overc committing",
    "start": "376000",
    "end": "377639"
  },
  {
    "text": "resources uh slurm is really good about",
    "start": "377639",
    "end": "380520"
  },
  {
    "text": "matching job definitions to your act uh",
    "start": "380520",
    "end": "382520"
  },
  {
    "text": "your actual available",
    "start": "382520",
    "end": "384319"
  },
  {
    "text": "Hardware people are bad at matching job",
    "start": "384319",
    "end": "387319"
  },
  {
    "text": "definitions to the actual needs of the",
    "start": "387319",
    "end": "388960"
  },
  {
    "text": "job um now this is not explicitly a Ry",
    "start": "388960",
    "end": "393400"
  },
  {
    "text": "issue but Rey is really good at using",
    "start": "393400",
    "end": "396639"
  },
  {
    "text": "all of the resources on the Node that",
    "start": "396639",
    "end": "398479"
  },
  {
    "text": "it's running on and so if you're not",
    "start": "398479",
    "end": "400400"
  },
  {
    "text": "careful about limiting Ray to what slurm",
    "start": "400400",
    "end": "403319"
  },
  {
    "text": "thinks the job is going to use if a",
    "start": "403319",
    "end": "405680"
  },
  {
    "text": "second Ray job ends up on the same node",
    "start": "405680",
    "end": "407759"
  },
  {
    "text": "all of a sudden you now have two jobs or",
    "start": "407759",
    "end": "410360"
  },
  {
    "text": "two Ray tasks all competing for the same",
    "start": "410360",
    "end": "412599"
  },
  {
    "text": "resources um like I said that's not",
    "start": "412599",
    "end": "414680"
  },
  {
    "text": "really a ray issue uh it will cause",
    "start": "414680",
    "end": "417479"
  },
  {
    "text": "problems if your organization isn't",
    "start": "417479",
    "end": "418759"
  },
  {
    "text": "disciplined about it though um I will",
    "start": "418759",
    "end": "421120"
  },
  {
    "text": "remain tactfully silent on whether it",
    "start": "421120",
    "end": "422720"
  },
  {
    "text": "was a problem for",
    "start": "422720",
    "end": "423960"
  },
  {
    "text": "us okay so uh I'm going to talk a little",
    "start": "423960",
    "end": "426560"
  },
  {
    "text": "bit about some specific projects that",
    "start": "426560",
    "end": "428199"
  },
  {
    "text": "we've worked on um just to kind of give",
    "start": "428199",
    "end": "430479"
  },
  {
    "text": "you a sense of what Reay has actively",
    "start": "430479",
    "end": "432879"
  },
  {
    "text": "enabled for us um zuk's uses pytorch",
    "start": "432879",
    "end": "436080"
  },
  {
    "text": "lightning pretty extensively um the",
    "start": "436080",
    "end": "438759"
  },
  {
    "text": "lightning data module is used by many",
    "start": "438759",
    "end": "440479"
  },
  {
    "text": "teams and we have for the teams that are",
    "start": "440479",
    "end": "443160"
  },
  {
    "text": "using lightning essentially Universal",
    "start": "443160",
    "end": "445560"
  },
  {
    "text": "use of the lightning module and",
    "start": "445560",
    "end": "447080"
  },
  {
    "text": "lightning",
    "start": "447080",
    "end": "448280"
  },
  {
    "text": "trainer um",
    "start": "448280",
    "end": "450080"
  },
  {
    "text": "the launchers for those training jobs",
    "start": "450080",
    "end": "452199"
  },
  {
    "text": "are a lot more varied um many models",
    "start": "452199",
    "end": "454960"
  },
  {
    "text": "just have custom one-off code to go",
    "start": "454960",
    "end": "456919"
  },
  {
    "text": "ahead and launch the training job there",
    "start": "456919",
    "end": "458639"
  },
  {
    "text": "are some per team wrappers around",
    "start": "458639",
    "end": "460080"
  },
  {
    "text": "lightning to kind of standardize things",
    "start": "460080",
    "end": "461479"
  },
  {
    "text": "a bit um but across all of those the",
    "start": "461479",
    "end": "463879"
  },
  {
    "text": "support for basic infrastructure",
    "start": "463879",
    "end": "465280"
  },
  {
    "text": "features was wildly inconsistent um you",
    "start": "465280",
    "end": "468479"
  },
  {
    "text": "know some jobs would be able to do",
    "start": "468479",
    "end": "469960"
  },
  {
    "text": "multi-node training some would not uh",
    "start": "469960",
    "end": "473039"
  },
  {
    "text": "you know fault tolerance being able to",
    "start": "473039",
    "end": "474840"
  },
  {
    "text": "repeat jobs um common integration with",
    "start": "474840",
    "end": "477759"
  },
  {
    "text": "our you know uh experiment tracking all",
    "start": "477759",
    "end": "479720"
  },
  {
    "text": "of that kind of stuff was kind of all",
    "start": "479720",
    "end": "480840"
  },
  {
    "text": "over the place um I will note here",
    "start": "480840",
    "end": "484520"
  },
  {
    "text": "though that pytorch lightning has",
    "start": "484520",
    "end": "487919"
  },
  {
    "text": "excellent support in Ray um it's worked",
    "start": "487919",
    "end": "490800"
  },
  {
    "text": "flawlessly for us uh you know we take a",
    "start": "490800",
    "end": "493000"
  },
  {
    "text": "pytorch lightning trainer pass it",
    "start": "493000",
    "end": "494360"
  },
  {
    "text": "through the radar train. lightning.",
    "start": "494360",
    "end": "496319"
  },
  {
    "text": "prear trainer function and then the ray",
    "start": "496319",
    "end": "498599"
  },
  {
    "text": "train torch trainer just worked um we",
    "start": "498599",
    "end": "502000"
  },
  {
    "text": "were able to spin up a standardized set",
    "start": "502000",
    "end": "504560"
  },
  {
    "text": "of you know multi-node training etc etc",
    "start": "504560",
    "end": "506360"
  },
  {
    "text": "very easily with us um what we ended up",
    "start": "506360",
    "end": "509759"
  },
  {
    "text": "building we call the zuk's training",
    "start": "509759",
    "end": "511000"
  },
  {
    "text": "framework or Z train um it brings all of",
    "start": "511000",
    "end": "514080"
  },
  {
    "text": "our users lightning modules to a",
    "start": "514080",
    "end": "516000"
  },
  {
    "text": "standardized infrastructure layer um",
    "start": "516000",
    "end": "518640"
  },
  {
    "text": "requiring few to no changes to those",
    "start": "518640",
    "end": "520919"
  },
  {
    "text": "existing lightning modules um and what",
    "start": "520919",
    "end": "523120"
  },
  {
    "text": "it does is it allows us as an ml",
    "start": "523120",
    "end": "524640"
  },
  {
    "text": "platform team to uplift all of those",
    "start": "524640",
    "end": "526480"
  },
  {
    "text": "models with valuable features like I",
    "start": "526480",
    "end": "528440"
  },
  {
    "text": "mentioned being able to restart after an",
    "start": "528440",
    "end": "530279"
  },
  {
    "text": "error uh multi-node training um whenever",
    "start": "530279",
    "end": "533959"
  },
  {
    "text": "we introduce a new instance type on AWS",
    "start": "533959",
    "end": "535920"
  },
  {
    "text": "making sure we have the networking",
    "start": "535920",
    "end": "537040"
  },
  {
    "text": "configured properly all of that kind of",
    "start": "537040",
    "end": "538680"
  },
  {
    "text": "stuff",
    "start": "538680",
    "end": "540200"
  },
  {
    "text": "all right so we've talked a little bit",
    "start": "540200",
    "end": "542320"
  },
  {
    "text": "about uh Legacy infrastructure about how",
    "start": "542320",
    "end": "544640"
  },
  {
    "text": "ray fit into our decade old Tech stack",
    "start": "544640",
    "end": "549040"
  },
  {
    "text": "um we talked a little bit about py torch",
    "start": "549040",
    "end": "552120"
  },
  {
    "text": "uh now I'm going to have Ron come up and",
    "start": "552120",
    "end": "553839"
  },
  {
    "text": "talk about what it looks like when we do",
    "start": "553839",
    "end": "555480"
  },
  {
    "text": "a green field project thanks",
    "start": "555480",
    "end": "558720"
  },
  {
    "text": "Eli",
    "start": "558720",
    "end": "560640"
  },
  {
    "text": "so zuk has been around for 10 years and",
    "start": "560640",
    "end": "564079"
  },
  {
    "text": "it's not exactly a new setup and not",
    "start": "564079",
    "end": "566240"
  },
  {
    "text": "every day we get to work on a Greenfield",
    "start": "566240",
    "end": "568920"
  },
  {
    "text": "project",
    "start": "568920",
    "end": "569959"
  },
  {
    "text": "uh but when things like that happened uh",
    "start": "569959",
    "end": "571680"
  },
  {
    "text": "the team really got excited and wanted",
    "start": "571680",
    "end": "573680"
  },
  {
    "text": "to take full advantage of that so enter",
    "start": "573680",
    "end": "576480"
  },
  {
    "text": "Z serve um so the reason that uh zuk has",
    "start": "576480",
    "end": "580240"
  },
  {
    "text": "not been thinking about a cloud-based",
    "start": "580240",
    "end": "582399"
  },
  {
    "text": "serving framework for uh at the",
    "start": "582399",
    "end": "584480"
  },
  {
    "text": "beginning of its fun is because we are",
    "start": "584480",
    "end": "587040"
  },
  {
    "text": "in a safety critical domain and imagine",
    "start": "587040",
    "end": "589640"
  },
  {
    "text": "you sitting in a robo taxi and somehow",
    "start": "589640",
    "end": "592200"
  },
  {
    "text": "there's a data outage and they say wait",
    "start": "592200",
    "end": "595040"
  },
  {
    "text": "for connection to the machine learning",
    "start": "595040",
    "end": "596959"
  },
  {
    "text": "model in the cloud there's a spinning",
    "start": "596959",
    "end": "598959"
  },
  {
    "text": "wheel it's probably not the best you",
    "start": "598959",
    "end": "600720"
  },
  {
    "text": "know user experience zuk wants to give",
    "start": "600720",
    "end": "602839"
  },
  {
    "text": "to its customers uh but in recent years",
    "start": "602839",
    "end": "606920"
  },
  {
    "text": "we see an explosion in AI applications",
    "start": "606920",
    "end": "609880"
  },
  {
    "text": "so not everything has to be computed on",
    "start": "609880",
    "end": "612240"
  },
  {
    "text": "the vehicle right so there are plenty of",
    "start": "612240",
    "end": "614279"
  },
  {
    "text": "use cases where we can have competition",
    "start": "614279",
    "end": "616560"
  },
  {
    "text": "down off vehicle for example simulation",
    "start": "616560",
    "end": "618640"
  },
  {
    "text": "data for example the logs that are",
    "start": "618640",
    "end": "620920"
  },
  {
    "text": "generated from the actual uh vehicle",
    "start": "620920",
    "end": "623480"
  },
  {
    "text": "runs we can do a postmodem analysis and",
    "start": "623480",
    "end": "626000"
  },
  {
    "text": "that does not have to take place on",
    "start": "626000",
    "end": "628000"
  },
  {
    "text": "vehicle so it is really really a good",
    "start": "628000",
    "end": "630079"
  },
  {
    "text": "time to uh start thinking about an",
    "start": "630079",
    "end": "632240"
  },
  {
    "text": "inference service that that runs in the",
    "start": "632240",
    "end": "634560"
  },
  {
    "text": "cloud",
    "start": "634560",
    "end": "635639"
  },
  {
    "text": "247 and so uh we decide to uh uh start",
    "start": "635639",
    "end": "639920"
  },
  {
    "text": "this zerve project uh by building",
    "start": "639920",
    "end": "643160"
  },
  {
    "text": "something on top of Reserve uh and also",
    "start": "643160",
    "end": "646600"
  },
  {
    "text": "uh it runs on AWS uh eks clusters and",
    "start": "646600",
    "end": "651279"
  },
  {
    "text": "right now um I'm happy to share that",
    "start": "651279",
    "end": "653279"
  },
  {
    "text": "it's serving uh a number of uh you know",
    "start": "653279",
    "end": "656800"
  },
  {
    "text": "models in production",
    "start": "656800",
    "end": "660200"
  },
  {
    "text": "so in a nutshell uh zerve is a ml",
    "start": "660200",
    "end": "663160"
  },
  {
    "text": "framework neutral and data format",
    "start": "663160",
    "end": "665279"
  },
  {
    "text": "agnostic so we cannot predict future",
    "start": "665279",
    "end": "667760"
  },
  {
    "text": "especially for such a rapidly evolving",
    "start": "667760",
    "end": "669800"
  },
  {
    "text": "field so the best way to predict future",
    "start": "669800",
    "end": "671839"
  },
  {
    "text": "is stay framework agnostic and also data",
    "start": "671839",
    "end": "674600"
  },
  {
    "text": "format and agnostic it is also language",
    "start": "674600",
    "end": "677560"
  },
  {
    "text": "NE because we build uh it on top of",
    "start": "677560",
    "end": "680399"
  },
  {
    "text": "protuff uh and also the tensor IO format",
    "start": "680399",
    "end": "684079"
  },
  {
    "text": "are compatible with tensor flow uh so",
    "start": "684079",
    "end": "686399"
  },
  {
    "text": "that if you want to really visualize it",
    "start": "686399",
    "end": "688279"
  },
  {
    "text": "with tensor board you can do it uh also",
    "start": "688279",
    "end": "691279"
  },
  {
    "text": "uh it works really seamlessly with Rive",
    "start": "691279",
    "end": "693760"
  },
  {
    "text": "because it's a green field project we do",
    "start": "693760",
    "end": "695600"
  },
  {
    "text": "not have to uh carry the Legacy such as",
    "start": "695600",
    "end": "698120"
  },
  {
    "text": "running s on slum we can uh work with",
    "start": "698120",
    "end": "701360"
  },
  {
    "text": "kubernetes um and also uh um the",
    "start": "701360",
    "end": "704279"
  },
  {
    "text": "beginning of project is really driven by",
    "start": "704279",
    "end": "706079"
  },
  {
    "text": "lots of internal needs our internal",
    "start": "706079",
    "end": "708320"
  },
  {
    "text": "project and team have a lot of Need for",
    "start": "708320",
    "end": "710760"
  },
  {
    "text": "p torch and nepai that's why we have",
    "start": "710760",
    "end": "712600"
  },
  {
    "text": "building first class support for pytorch",
    "start": "712600",
    "end": "715279"
  },
  {
    "text": "and neai but in the future if Jacks come",
    "start": "715279",
    "end": "717839"
  },
  {
    "text": "around we can happily support Jacks as",
    "start": "717839",
    "end": "719880"
  },
  {
    "text": "well that's no problem because it's",
    "start": "719880",
    "end": "722000"
  },
  {
    "text": "easily extensible uh for U both public",
    "start": "722000",
    "end": "725480"
  },
  {
    "text": "and propriety data formats and here's a",
    "start": "725480",
    "end": "728200"
  },
  {
    "text": "typical journey of a query and so you",
    "start": "728200",
    "end": "730920"
  },
  {
    "text": "have on the client side you encode some",
    "start": "730920",
    "end": "732839"
  },
  {
    "text": "of input to into a a serializable format",
    "start": "732839",
    "end": "736760"
  },
  {
    "text": "that we call Z request you can transmit",
    "start": "736760",
    "end": "739639"
  },
  {
    "text": "that over the network and which gets",
    "start": "739639",
    "end": "741720"
  },
  {
    "text": "impacted on the server side and you can",
    "start": "741720",
    "end": "743560"
  },
  {
    "text": "either invoke the CPU or the GPU get",
    "start": "743560",
    "end": "745800"
  },
  {
    "text": "inference down either way and then have",
    "start": "745800",
    "end": "747680"
  },
  {
    "text": "it shipped back and also have it decoded",
    "start": "747680",
    "end": "749959"
  },
  {
    "text": "on the client side and that's how a",
    "start": "749959",
    "end": "752160"
  },
  {
    "text": "typical uh query uh uh life Journey",
    "start": "752160",
    "end": "754800"
  },
  {
    "text": "looks like so far I have described a",
    "start": "754800",
    "end": "757199"
  },
  {
    "text": "very standard way of you know doing",
    "start": "757199",
    "end": "759519"
  },
  {
    "text": "inference service nothing special um",
    "start": "759519",
    "end": "762680"
  },
  {
    "text": "however there's a bit of a surprise that",
    "start": "762680",
    "end": "764720"
  },
  {
    "text": "we do in some of the project we have",
    "start": "764720",
    "end": "766760"
  },
  {
    "text": "with uh the client so basically uh we",
    "start": "766760",
    "end": "770160"
  },
  {
    "text": "discovered that uh in terms of the",
    "start": "770160",
    "end": "772880"
  },
  {
    "text": "number of lmes code that cannot be",
    "start": "772880",
    "end": "774760"
  },
  {
    "text": "really reused across model because these",
    "start": "774760",
    "end": "776760"
  },
  {
    "text": "number of lmes code that we set here are",
    "start": "776760",
    "end": "779199"
  },
  {
    "text": "really model specific code for example",
    "start": "779199",
    "end": "781079"
  },
  {
    "text": "we do not include the serialization",
    "start": "781079",
    "end": "782760"
  },
  {
    "text": "engine we have built for Z because that",
    "start": "782760",
    "end": "785040"
  },
  {
    "text": "is completely generic reusable we",
    "start": "785040",
    "end": "787639"
  },
  {
    "text": "certainly would not include any lines of",
    "start": "787639",
    "end": "789440"
  },
  {
    "text": "code for pie torch because that couple",
    "start": "789440",
    "end": "791399"
  },
  {
    "text": "million laes code is completely reusable",
    "start": "791399",
    "end": "793480"
  },
  {
    "text": "across different models however there",
    "start": "793480",
    "end": "795639"
  },
  {
    "text": "always a bit of a code that it cannot",
    "start": "795639",
    "end": "798040"
  },
  {
    "text": "really generalize across the model",
    "start": "798040",
    "end": "799880"
  },
  {
    "text": "boundary you have to written those test",
    "start": "799880",
    "end": "801600"
  },
  {
    "text": "cases for the model and that cannot be",
    "start": "801600",
    "end": "803360"
  },
  {
    "text": "transferred to yet another model because",
    "start": "803360",
    "end": "805199"
  },
  {
    "text": "it has different architecture different",
    "start": "805199",
    "end": "807000"
  },
  {
    "text": "layers right so it's hard but when we",
    "start": "807000",
    "end": "809880"
  },
  {
    "text": "look at this line of code statistics we",
    "start": "809880",
    "end": "813279"
  },
  {
    "text": "kind of uh think that you need roughly",
    "start": "813279",
    "end": "817120"
  },
  {
    "text": "about 500 lines of code per model and",
    "start": "817120",
    "end": "819480"
  },
  {
    "text": "then also for each model if you want to",
    "start": "819480",
    "end": "821279"
  },
  {
    "text": "build a Do image it's about 16 GB in",
    "start": "821279",
    "end": "823920"
  },
  {
    "text": "size but we really have a handful of",
    "start": "823920",
    "end": "826880"
  },
  {
    "text": "models uh that handful is understatement",
    "start": "826880",
    "end": "829839"
  },
  {
    "text": "but imagine you can do the maass and",
    "start": "829839",
    "end": "831720"
  },
  {
    "text": "multiply by 10 you got like you know 5K",
    "start": "831720",
    "end": "834920"
  },
  {
    "text": "lines of source code and that that",
    "start": "834920",
    "end": "836440"
  },
  {
    "text": "really adds up right so here's one way",
    "start": "836440",
    "end": "839519"
  },
  {
    "text": "that we approach this problem and just",
    "start": "839519",
    "end": "841519"
  },
  {
    "text": "similar to how you can customize a a ray",
    "start": "841519",
    "end": "845320"
  },
  {
    "text": "cluster by cons configuring in the Amo",
    "start": "845320",
    "end": "848240"
  },
  {
    "text": "file same idea but we want to go one",
    "start": "848240",
    "end": "851720"
  },
  {
    "text": "step deeper in terms of uh asking the",
    "start": "851720",
    "end": "854720"
  },
  {
    "text": "user to specify not only the model",
    "start": "854720",
    "end": "857440"
  },
  {
    "text": "trivial like where to get the S3 bucket",
    "start": "857440",
    "end": "859519"
  },
  {
    "text": "and where the model file are located but",
    "start": "859519",
    "end": "861880"
  },
  {
    "text": "also ask user to define the inputs and",
    "start": "861880",
    "end": "865120"
  },
  {
    "text": "outputs in a declarative fashion and",
    "start": "865120",
    "end": "868199"
  },
  {
    "text": "therefore we get lots of benefits out of",
    "start": "868199",
    "end": "870440"
  },
  {
    "text": "this uh declarative approach first of",
    "start": "870440",
    "end": "873079"
  },
  {
    "text": "all we get an application neutral client",
    "start": "873079",
    "end": "875279"
  },
  {
    "text": "and server pair so you don't have to",
    "start": "875279",
    "end": "877959"
  },
  {
    "text": "engineer different client server for",
    "start": "877959",
    "end": "879600"
  },
  {
    "text": "different model just one version of",
    "start": "879600",
    "end": "881560"
  },
  {
    "text": "client one version of server that's all",
    "start": "881560",
    "end": "883079"
  },
  {
    "text": "you need also automatically we will get",
    "start": "883079",
    "end": "886440"
  },
  {
    "text": "the test Vector generated for your",
    "start": "886440",
    "end": "888279"
  },
  {
    "text": "application because you tell us how the",
    "start": "888279",
    "end": "891279"
  },
  {
    "text": "shapes of each tensor looks like we will",
    "start": "891279",
    "end": "893320"
  },
  {
    "text": "be able to not only generate test case",
    "start": "893320",
    "end": "895880"
  },
  {
    "text": "test Vector for you but also when you",
    "start": "895880",
    "end": "897880"
  },
  {
    "text": "supply us with different tensor shape",
    "start": "897880",
    "end": "900320"
  },
  {
    "text": "will tell you which dimension which",
    "start": "900320",
    "end": "902639"
  },
  {
    "text": "tensor key has it wrong so you will get",
    "start": "902639",
    "end": "905959"
  },
  {
    "text": "very informative error messages that way",
    "start": "905959",
    "end": "908920"
  },
  {
    "text": "and also uh we have Consolidated all our",
    "start": "908920",
    "end": "911680"
  },
  {
    "text": "models and applications in a single doc",
    "start": "911680",
    "end": "913880"
  },
  {
    "text": "image that is ready to deploy so that",
    "start": "913880",
    "end": "915839"
  },
  {
    "text": "makes really a doer deployment much",
    "start": "915839",
    "end": "918120"
  },
  {
    "text": "easier so there are other benefits of uh",
    "start": "918120",
    "end": "920880"
  },
  {
    "text": "using our so-called model Bas Z serve on",
    "start": "920880",
    "end": "923240"
  },
  {
    "text": "Ray um and I like to always side numbers",
    "start": "923240",
    "end": "926360"
  },
  {
    "text": "previously I site that 5 500 lines the",
    "start": "926360",
    "end": "929120"
  },
  {
    "text": "code is needed per model how much uh",
    "start": "929120",
    "end": "931399"
  },
  {
    "text": "lines of code uh is needed under this",
    "start": "931399",
    "end": "933560"
  },
  {
    "text": "new modelbased service uh kind of",
    "start": "933560",
    "end": "935319"
  },
  {
    "text": "architecture well looks like we only",
    "start": "935319",
    "end": "937360"
  },
  {
    "text": "need not only five models which is about",
    "start": "937360",
    "end": "940160"
  },
  {
    "text": "100 fold uh reduction um just like the",
    "start": "940160",
    "end": "943639"
  },
  {
    "text": "cost of tokens uh you know price per",
    "start": "943639",
    "end": "946319"
  },
  {
    "text": "token has come down 100 foot we also",
    "start": "946319",
    "end": "949160"
  },
  {
    "text": "want to do something drastic like 100",
    "start": "949160",
    "end": "951040"
  },
  {
    "text": "foot uh reduction in number of lines per",
    "start": "951040",
    "end": "952759"
  },
  {
    "text": "model but it's always the same F line",
    "start": "952759",
    "end": "955319"
  },
  {
    "text": "and that's interesting too because if",
    "start": "955319",
    "end": "957839"
  },
  {
    "text": "it's different F line you need to say",
    "start": "957839",
    "end": "959360"
  },
  {
    "text": "well which five lines for me because I",
    "start": "959360",
    "end": "961040"
  },
  {
    "text": "need to find out my five lines of code",
    "start": "961040",
    "end": "963360"
  },
  {
    "text": "but in most cases unless you are very",
    "start": "963360",
    "end": "965040"
  },
  {
    "text": "particular about how you name those",
    "start": "965040",
    "end": "967319"
  },
  {
    "text": "model names you can literally copy from",
    "start": "967319",
    "end": "970199"
  },
  {
    "text": "one model because the same F lines of",
    "start": "970199",
    "end": "972079"
  },
  {
    "text": "code you dump in and there you go you",
    "start": "972079",
    "end": "974680"
  },
  {
    "text": "have another model created now wait a",
    "start": "974680",
    "end": "978040"
  },
  {
    "text": "minute we have different model use cases",
    "start": "978040",
    "end": "980279"
  },
  {
    "text": "we have different inputs different",
    "start": "980279",
    "end": "981399"
  },
  {
    "text": "output how could you make sure it's",
    "start": "981399",
    "end": "982959"
  },
  {
    "text": "always the same five lines code rest",
    "start": "982959",
    "end": "985000"
  },
  {
    "text": "assured because those five lines are non",
    "start": "985000",
    "end": "987160"
  },
  {
    "text": "model specific it's always the same five",
    "start": "987160",
    "end": "988920"
  },
  {
    "text": "peline like you want initialized model",
    "start": "988920",
    "end": "990959"
  },
  {
    "text": "encoded request but the request can come",
    "start": "990959",
    "end": "993440"
  },
  {
    "text": "from for different forms how would you",
    "start": "993440",
    "end": "995279"
  },
  {
    "text": "make sure that the the same line of",
    "start": "995279",
    "end": "997319"
  },
  {
    "text": "encod request meets your need well",
    "start": "997319",
    "end": "1000120"
  },
  {
    "text": "because we have Abra away all the model",
    "start": "1000120",
    "end": "1002399"
  },
  {
    "text": "specific logic into a PB text based",
    "start": "1002399",
    "end": "1005040"
  },
  {
    "text": "configuration file in that file you can",
    "start": "1005040",
    "end": "1007160"
  },
  {
    "text": "specify one tensor in two tensor out two",
    "start": "1007160",
    "end": "1009519"
  },
  {
    "text": "tensor in one tensor out one tensor",
    "start": "1009519",
    "end": "1011560"
  },
  {
    "text": "dictionary in two tensor dictionary out",
    "start": "1011560",
    "end": "1013480"
  },
  {
    "text": "all the combination thereof we support",
    "start": "1013480",
    "end": "1015720"
  },
  {
    "text": "that but the magic is you only need to",
    "start": "1015720",
    "end": "1017959"
  },
  {
    "text": "configure that in your PB text file",
    "start": "1017959",
    "end": "1019720"
  },
  {
    "text": "which does not count as python lines of",
    "start": "1019720",
    "end": "1021680"
  },
  {
    "text": "code it's PB text right or any",
    "start": "1021680",
    "end": "1024079"
  },
  {
    "text": "configuration so that means we have",
    "start": "1024079",
    "end": "1026360"
  },
  {
    "text": "higher software quality because now we",
    "start": "1026360",
    "end": "1028480"
  },
  {
    "text": "have a single source of choose for model",
    "start": "1028480",
    "end": "1030199"
  },
  {
    "text": "inputs and outputs and before that we",
    "start": "1030199",
    "end": "1032120"
  },
  {
    "text": "have to engage our customer teams asking",
    "start": "1032120",
    "end": "1033839"
  },
  {
    "text": "for K tellers what the tensors and what",
    "start": "1033839",
    "end": "1036558"
  },
  {
    "text": "are their Dimension and they will reply",
    "start": "1036559",
    "end": "1038240"
  },
  {
    "text": "on a slack Channel which might have you",
    "start": "1038240",
    "end": "1041280"
  },
  {
    "text": "know typo errors right now we have a",
    "start": "1041280",
    "end": "1043640"
  },
  {
    "text": "single software choose for where the",
    "start": "1043640",
    "end": "1045480"
  },
  {
    "text": "model inputs and outputs come from and",
    "start": "1045480",
    "end": "1047438"
  },
  {
    "text": "also because these always tested in our",
    "start": "1047439",
    "end": "1050160"
  },
  {
    "text": "continuous integration system 24/7 so",
    "start": "1050160",
    "end": "1053679"
  },
  {
    "text": "there's no chance that this can depart",
    "start": "1053679",
    "end": "1056440"
  },
  {
    "text": "from the source of Truth and also uh",
    "start": "1056440",
    "end": "1059039"
  },
  {
    "text": "last but not least because we are small",
    "start": "1059039",
    "end": "1060760"
  },
  {
    "text": "team Eli and I plus a few colleagues",
    "start": "1060760",
    "end": "1063240"
  },
  {
    "text": "also in the audience we're small team we",
    "start": "1063240",
    "end": "1065120"
  },
  {
    "text": "are supporting maybe more than do AI",
    "start": "1065120",
    "end": "1067480"
  },
  {
    "text": "team so in order to make this whole",
    "start": "1067480",
    "end": "1069520"
  },
  {
    "text": "approach scalable we believe that we",
    "start": "1069520",
    "end": "1071679"
  },
  {
    "text": "need to have decentralized model",
    "start": "1071679",
    "end": "1073520"
  },
  {
    "text": "ownership meaning that we provide them",
    "start": "1073520",
    "end": "1075720"
  },
  {
    "text": "with the engine the tool but we're not",
    "start": "1075720",
    "end": "1077320"
  },
  {
    "text": "going to walk the work for them do lots",
    "start": "1077320",
    "end": "1079919"
  },
  {
    "text": "of handholding for them we have to let",
    "start": "1079919",
    "end": "1081960"
  },
  {
    "text": "them be able to the customer team be",
    "start": "1081960",
    "end": "1084000"
  },
  {
    "text": "able to customize models and do their",
    "start": "1084000",
    "end": "1086400"
  },
  {
    "text": "own model cre creation so that's uh what",
    "start": "1086400",
    "end": "1089760"
  },
  {
    "text": "we think that decentral model ownership",
    "start": "1089760",
    "end": "1091679"
  },
  {
    "text": "will really make a difference last but",
    "start": "1091679",
    "end": "1093960"
  },
  {
    "text": "not least we also achieve better",
    "start": "1093960",
    "end": "1095679"
  },
  {
    "text": "observability because with model based",
    "start": "1095679",
    "end": "1097400"
  },
  {
    "text": "heals uh Observer we can tailor",
    "start": "1097400",
    "end": "1100320"
  },
  {
    "text": "different alerts to a specific",
    "start": "1100320",
    "end": "1101720"
  },
  {
    "text": "application and model because now we",
    "start": "1101720",
    "end": "1103640"
  },
  {
    "text": "know the inputs and outputs we know the",
    "start": "1103640",
    "end": "1105200"
  },
  {
    "text": "criticality of the models so we can U",
    "start": "1105200",
    "end": "1107960"
  },
  {
    "text": "better tell her Alert Logic like graph",
    "start": "1107960",
    "end": "1111080"
  },
  {
    "text": "alerts uh to the needs of our",
    "start": "1111080",
    "end": "1113080"
  },
  {
    "text": "applications so in conclusion uh we",
    "start": "1113080",
    "end": "1116200"
  },
  {
    "text": "think that really really integrates well",
    "start": "1116200",
    "end": "1118280"
  },
  {
    "text": "with the ranger environments from Legacy",
    "start": "1118280",
    "end": "1120640"
  },
  {
    "text": "system that are built on top of Slum and",
    "start": "1120640",
    "end": "1123679"
  },
  {
    "text": "HPC uh in the case of zren or for a more",
    "start": "1123679",
    "end": "1127159"
  },
  {
    "text": "modern approach such as zesa which is",
    "start": "1127159",
    "end": "1129640"
  },
  {
    "text": "built on top of kubernetes and eks",
    "start": "1129640",
    "end": "1131799"
  },
  {
    "text": "clusters we're very happy with how Ray",
    "start": "1131799",
    "end": "1135000"
  },
  {
    "text": "is powering our ml uh platform because",
    "start": "1135000",
    "end": "1138039"
  },
  {
    "text": "it provides unified infra support we do",
    "start": "1138039",
    "end": "1140640"
  },
  {
    "text": "not have to use different sort of",
    "start": "1140640",
    "end": "1142679"
  },
  {
    "text": "substrates and infrastructure layer we",
    "start": "1142679",
    "end": "1144720"
  },
  {
    "text": "just build our competen all on top of",
    "start": "1144720",
    "end": "1147280"
  },
  {
    "text": "the wonderful products that n skill",
    "start": "1147280",
    "end": "1148919"
  },
  {
    "text": "Engineers has has built for us uh by the",
    "start": "1148919",
    "end": "1151720"
  },
  {
    "text": "way I like to give a shout out to the N",
    "start": "1151720",
    "end": "1153520"
  },
  {
    "text": "skill Engineers you guys really have",
    "start": "1153520",
    "end": "1155559"
  },
  {
    "text": "done a terrific job thank you uh also uh",
    "start": "1155559",
    "end": "1158760"
  },
  {
    "text": "we also uh both the training and serving",
    "start": "1158760",
    "end": "1161720"
  },
  {
    "text": "framework have embraced a declarative uh",
    "start": "1161720",
    "end": "1164600"
  },
  {
    "text": "framework and workflows that makes it",
    "start": "1164600",
    "end": "1166880"
  },
  {
    "text": "super easy for our customers to",
    "start": "1166880",
    "end": "1168760"
  },
  {
    "text": "customize their logic to be creative on",
    "start": "1168760",
    "end": "1171000"
  },
  {
    "text": "their side without really getting in the",
    "start": "1171000",
    "end": "1173000"
  },
  {
    "text": "way or without letting our Ser service",
    "start": "1173000",
    "end": "1175400"
  },
  {
    "text": "firw get in their way so I guess the",
    "start": "1175400",
    "end": "1177840"
  },
  {
    "text": "biggest surprise for using Ray so far is",
    "start": "1177840",
    "end": "1180240"
  },
  {
    "text": "there is no surprise at all it just",
    "start": "1180240",
    "end": "1182360"
  },
  {
    "text": "works and that's the best kind of",
    "start": "1182360",
    "end": "1184400"
  },
  {
    "text": "surprise we want to see going",
    "start": "1184400",
    "end": "1187080"
  },
  {
    "text": "forward uh last but not least and also",
    "start": "1187080",
    "end": "1189960"
  },
  {
    "text": "as a Shameless plug we are hiring the ml",
    "start": "1189960",
    "end": "1193039"
  },
  {
    "text": "platform team and also I would say the",
    "start": "1193039",
    "end": "1194960"
  },
  {
    "text": "entire infa team is is hiring so if",
    "start": "1194960",
    "end": "1197520"
  },
  {
    "text": "you're interested in thus driving",
    "start": "1197520",
    "end": "1199440"
  },
  {
    "text": "Mobility at the service or just machine",
    "start": "1199440",
    "end": "1201320"
  },
  {
    "text": "learning in general come talk to us",
    "start": "1201320",
    "end": "1204280"
  },
  {
    "text": "thank you and then Eli and I happy to",
    "start": "1204280",
    "end": "1206600"
  },
  {
    "text": "take",
    "start": "1206600",
    "end": "1207680"
  },
  {
    "text": "[Applause]",
    "start": "1207680",
    "end": "1211960"
  },
  {
    "text": "questions thank you for that great talk",
    "start": "1211960",
    "end": "1214559"
  },
  {
    "text": "uh for questions please come to the",
    "start": "1214559",
    "end": "1216600"
  },
  {
    "text": "middle uh and use the mic",
    "start": "1216600",
    "end": "1220240"
  },
  {
    "text": "thanks uh thank you for your",
    "start": "1222400",
    "end": "1224440"
  },
  {
    "text": "presentation can you please",
    "start": "1224440",
    "end": "1226760"
  },
  {
    "text": "elaborate uh uh about uh the hardware",
    "start": "1226760",
    "end": "1231799"
  },
  {
    "text": "kind of Hardware do you use in your",
    "start": "1231799",
    "end": "1234840"
  },
  {
    "text": "vehicles from chips to",
    "start": "1234840",
    "end": "1237720"
  },
  {
    "text": "sensors uh so we have uh an incredible",
    "start": "1237720",
    "end": "1242039"
  },
  {
    "text": "amount of compute in the vehicle we have",
    "start": "1242039",
    "end": "1244280"
  },
  {
    "text": "um a lot of Nvidia compute we have Lars",
    "start": "1244280",
    "end": "1248480"
  },
  {
    "text": "we have Radars we have cameras um I have",
    "start": "1248480",
    "end": "1252039"
  },
  {
    "text": "lost track of how many of each but tens",
    "start": "1252039",
    "end": "1254720"
  },
  {
    "text": "of different kinds tens of different",
    "start": "1254720",
    "end": "1256480"
  },
  {
    "text": "sensors all over the vehicle you can see",
    "start": "1256480",
    "end": "1258440"
  },
  {
    "text": "the the um on the top corners there's",
    "start": "1258440",
    "end": "1260520"
  },
  {
    "text": "sensor pods uh that have multiple sensor",
    "start": "1260520",
    "end": "1263320"
  },
  {
    "text": "modalities on them um in terms of",
    "start": "1263320",
    "end": "1266159"
  },
  {
    "text": "compute I don't believe I'm at Liberty",
    "start": "1266159",
    "end": "1267840"
  },
  {
    "text": "to say exactly what it is that we're",
    "start": "1267840",
    "end": "1269440"
  },
  {
    "text": "using um but you can think of it as the",
    "start": "1269440",
    "end": "1272559"
  },
  {
    "text": "equivalent of a rack mount server on",
    "start": "1272559",
    "end": "1276720"
  },
  {
    "text": "Wheels again thank you for this and",
    "start": "1281080",
    "end": "1283360"
  },
  {
    "text": "great talk I just wondering um for your",
    "start": "1283360",
    "end": "1286159"
  },
  {
    "text": "ml compute for the data PR in are you",
    "start": "1286159",
    "end": "1289279"
  },
  {
    "text": "using any like traditional ETL engines",
    "start": "1289279",
    "end": "1292039"
  },
  {
    "text": "or like spark or anything like that yeah",
    "start": "1292039",
    "end": "1296000"
  },
  {
    "text": "so um a it's actually a different team",
    "start": "1296000",
    "end": "1298480"
  },
  {
    "text": "that handles that so I'm not going to be",
    "start": "1298480",
    "end": "1299640"
  },
  {
    "text": "able to talk too in depth but yes we do",
    "start": "1299640",
    "end": "1302080"
  },
  {
    "text": "have fairly heavy um uh ingest processes",
    "start": "1302080",
    "end": "1306360"
  },
  {
    "text": "where we pull data off a vehicle and",
    "start": "1306360",
    "end": "1308240"
  },
  {
    "text": "then go through multiple stages of",
    "start": "1308240",
    "end": "1309880"
  },
  {
    "text": "processing uh using data breaks",
    "start": "1309880",
    "end": "1314360"
  },
  {
    "text": "any other questions I guess as a",
    "start": "1319279",
    "end": "1320640"
  },
  {
    "text": "followup uh some of the Z of uh use",
    "start": "1320640",
    "end": "1323480"
  },
  {
    "text": "cases were uh motivated by some of the",
    "start": "1323480",
    "end": "1326799"
  },
  {
    "text": "data process ingesting process that we",
    "start": "1326799",
    "end": "1329200"
  },
  {
    "text": "have so it's ML and data pipeline",
    "start": "1329200",
    "end": "1331960"
  },
  {
    "text": "processing is is kind of a converging in",
    "start": "1331960",
    "end": "1334760"
  },
  {
    "text": "in",
    "start": "1334760",
    "end": "1336919"
  },
  {
    "text": "zuk cool thank you all",
    "start": "1339480",
    "end": "1344600"
  }
]
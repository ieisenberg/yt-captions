[
  {
    "text": "good afternoon everyone my name is Zach Caraco and today I'm going to be talking about array-based machine learning",
    "start": "5220",
    "end": "10740"
  },
  {
    "text": "platform for early cancer detection so although I'm presenting this many people at freenom contributed to this",
    "start": "10740",
    "end": "16800"
  },
  {
    "text": "work and I would like to thank all of them we have a fantastic group of engineering scientists different types",
    "start": "16800",
    "end": "22800"
  },
  {
    "text": "of product management business and all different types of media related functionality that's have been very",
    "start": "22800",
    "end": "29279"
  },
  {
    "text": "helpful in putting these slides together so I'm going to be breaking this talk",
    "start": "29279",
    "end": "35280"
  },
  {
    "text": "down into four segments so the first one is going to be talking about freedom and early cancer detection that's really the",
    "start": "35280",
    "end": "41460"
  },
  {
    "text": "mission of Freedom the second one is machine learning applications and so that's going to be the two I'm going to",
    "start": "41460",
    "end": "47280"
  },
  {
    "text": "be focusing on are cancer risk prediction as well as cancer detection from blood samples and in the third part",
    "start": "47280",
    "end": "53879"
  },
  {
    "text": "of the talk I'll be talking about why we decided to use Rey and finally I'll be describing how we're using Rey and",
    "start": "53879",
    "end": "59039"
  },
  {
    "text": "freenom's machine learning platform so at freenom we are 100 focused on",
    "start": "59039",
    "end": "65100"
  },
  {
    "text": "early cancer detection so cancer is the number two cause of death in the U.S and globally",
    "start": "65100",
    "end": "73200"
  },
  {
    "text": "but early cancer section can have a very big impact in survival rates and so what you're seeing here on the right side is",
    "start": "73200",
    "end": "79380"
  },
  {
    "text": "a plot of survival over five years as a and then the x-axis is the different",
    "start": "79380",
    "end": "85439"
  },
  {
    "text": "types of cancers and then the the lime green bars are this localized cancers I",
    "start": "85439",
    "end": "91320"
  },
  {
    "text": "mean like it's an early stage and then the purple is metastatic so it's like a late stage and so if you can dissect",
    "start": "91320",
    "end": "98159"
  },
  {
    "text": "cancer early you really can greatly improve the survival outcome for people",
    "start": "98159",
    "end": "103939"
  },
  {
    "text": "renome is a company which is founded in 2014 we have received over a billion dollars",
    "start": "104280",
    "end": "110159"
  },
  {
    "text": "in financing since then we have over 50 biopharma and academic partners and over",
    "start": "110159",
    "end": "115439"
  },
  {
    "text": "450 employees the first product we're working on is for colorectal cancer detection",
    "start": "115439",
    "end": "122280"
  },
  {
    "text": "and as well as advanced adenomas so colorectal cancer is the second",
    "start": "122280",
    "end": "128220"
  },
  {
    "text": "deadliest cancer in the United States but when caught early it is highly",
    "start": "128220",
    "end": "133620"
  },
  {
    "text": "treatable you can get about a six that can prove 6X Improvement in the survival rate over",
    "start": "133620",
    "end": "139620"
  },
  {
    "text": "five years if you can catch colorectal cancer early enough to treat it",
    "start": "139620",
    "end": "145319"
  },
  {
    "text": "so our objective at freedom is to make color cancer screening easier and we",
    "start": "145319",
    "end": "150360"
  },
  {
    "text": "want to do that by providing an accurate and accessible blood test this can increase caloric cancer",
    "start": "150360",
    "end": "156660"
  },
  {
    "text": "screening adherence because it's just simply easier to do it than a colonoscopy",
    "start": "156660",
    "end": "162900"
  },
  {
    "text": "this can lead to an improvement in survival rates because we're able to catch cancer earlier",
    "start": "162900",
    "end": "170180"
  },
  {
    "text": "well Arctic cancer is just the first cancer of many that we plan to Target and so we've been working on other cancers as well and all this relies on",
    "start": "170640",
    "end": "178080"
  },
  {
    "text": "the same platform so we have a multi-amix platform and I'm going to be describing that later",
    "start": "178080",
    "end": "183480"
  },
  {
    "text": "the machine learning applications that I'll be describing this talk are two of them and one is cancer risk prediction",
    "start": "183480",
    "end": "189900"
  },
  {
    "text": "and this is using real world data so in this case this is data that is related to patients Healthcare",
    "start": "189900",
    "end": "195780"
  },
  {
    "text": "and the quote related to this is that our goal is to identify the right patient for the right screening tests at",
    "start": "195780",
    "end": "202019"
  },
  {
    "text": "the right time with clear next steps that is the goal of cancer risk prediction at Freedom and so what you",
    "start": "202019",
    "end": "208739"
  },
  {
    "text": "start with here is you start with real world data and you do feature extraction on it and you train a machine learning model",
    "start": "208739",
    "end": "215700"
  },
  {
    "text": "on that and from that you can predict whether or not a patient is likely to be at high risk or low risk for a certain",
    "start": "215700",
    "end": "222480"
  },
  {
    "text": "type of cancer the second machine learning application that I'll be describing in this talk is",
    "start": "222480",
    "end": "228060"
  },
  {
    "text": "cancer detection using multi-alent data from blood so multi-amlink data is data that comes",
    "start": "228060",
    "end": "233640"
  },
  {
    "text": "from different omics Technologies and there's many different omics Technologies out there you have genomics transcriptomics proteomics epigenomics",
    "start": "233640",
    "end": "241080"
  },
  {
    "text": "we use many different types of Technologies to analyze blood at Freedom",
    "start": "241080",
    "end": "246120"
  },
  {
    "text": "to provide us with a signal that we can use to classify models that can be used for cancer signal detection or in a good",
    "start": "246120",
    "end": "254879"
  },
  {
    "text": "case no cancer signal is detected in the blood so those are the two machine learning",
    "start": "254879",
    "end": "261359"
  },
  {
    "text": "applications that I'll be describing and I also want to talk about why we decided to use Rey for these machine",
    "start": "261359",
    "end": "266699"
  },
  {
    "text": "learning applications so we chose to use red because it really enables fast model training with large",
    "start": "266699",
    "end": "273540"
  },
  {
    "text": "volumes of data so Freedom's data is already very large mole diamics data can generate enormous amounts of data",
    "start": "273540",
    "end": "279720"
  },
  {
    "text": "because of just the number of different biomarkers you can measure and the number of modifications to those biomarkers",
    "start": "279720",
    "end": "286020"
  },
  {
    "text": "Ray supports distributed data parallel model training and it is supported specifically four libraries that we care",
    "start": "286020",
    "end": "292620"
  },
  {
    "text": "to use those libraries are xgboost we want to use that for the risk prediction",
    "start": "292620",
    "end": "298380"
  },
  {
    "text": "training we want to use real world data with extra boost we have large amounts of it and then for the omics related",
    "start": "298380",
    "end": "305040"
  },
  {
    "text": "training for when we're trying to detect cancer we want to use pie touch for that and Ray also supports distributed data",
    "start": "305040",
    "end": "311040"
  },
  {
    "text": "parallel model training with pytorch it also supports different types of hpo",
    "start": "311040",
    "end": "317000"
  },
  {
    "text": "using Ray tune and it has Integrations for the different types of monitoring tools that we use including ml flow",
    "start": "317000",
    "end": "323940"
  },
  {
    "text": "tensorboard Prometheus and grafana and it does this in a very simple and elegant way you can use callbacks for ML",
    "start": "323940",
    "end": "330120"
  },
  {
    "text": "flow and tensor board out of the box it immediately logs things such that you can access them and use them in",
    "start": "330120",
    "end": "335699"
  },
  {
    "text": "Prometheus and grafana and so it creates basically that's pre-built dashboards that you can use out of the box which is",
    "start": "335699",
    "end": "342120"
  },
  {
    "text": "very convenient I wanted to talk about distributed data parallel model training for a moment",
    "start": "342120",
    "end": "347580"
  },
  {
    "text": "because this is really one of the goals of ours when it comes to using Ray so in this case what we're doing is we",
    "start": "347580",
    "end": "354000"
  },
  {
    "text": "have large amounts of data and if we're going to try and train all that data in one machine it would take too",
    "start": "354000",
    "end": "359639"
  },
  {
    "text": "long because we do many many iterative batches what we can do instead is you can split up that data into separate",
    "start": "359639",
    "end": "366000"
  },
  {
    "text": "processes and then on each process in each separate process you're going to create a copy of the model you're going",
    "start": "366000",
    "end": "372479"
  },
  {
    "text": "to be using and So within each one of these processes you're going to train the model on a unique piece of that data",
    "start": "372479",
    "end": "379320"
  },
  {
    "text": "and then after a certain number of iterations of training you're going to synchronize the models such that they",
    "start": "379320",
    "end": "384419"
  },
  {
    "text": "all have been summed up the usually gradients in this case and this allows you to synchronize the",
    "start": "384419",
    "end": "389460"
  },
  {
    "text": "models and at the end you're gonna have the same model which you can return and Save there's different types of modeling",
    "start": "389460",
    "end": "395039"
  },
  {
    "text": "updating strategies such as all reduce and param server the libraries that I'm going to be discussing today are Pi",
    "start": "395039",
    "end": "400319"
  },
  {
    "text": "torch and xgboost both of those use all reduce so that's what we'll be referred to in this talk",
    "start": "400319",
    "end": "406880"
  },
  {
    "text": "so the first machine learning application that I want to describe is cancer risk prediction model training",
    "start": "407759",
    "end": "414060"
  },
  {
    "text": "the objective of this is that we want to be able to predict if a person will be diagnosed with colorectal cancer within",
    "start": "414060",
    "end": "420840"
  },
  {
    "text": "a certain time frame the data that's being used for this is electronic health records and medical claims data the data sets are tabular in",
    "start": "420840",
    "end": "428160"
  },
  {
    "text": "nature and we have many millions of patient observations each row represents a summary of a",
    "start": "428160",
    "end": "434220"
  },
  {
    "text": "patient's clinical history through a given date and this includes over a thousand features such as age sex years",
    "start": "434220",
    "end": "440520"
  },
  {
    "text": "since the first and last diagnosis of different types and so we have large amounts of features",
    "start": "440520",
    "end": "445919"
  },
  {
    "text": "large amounts of data for this and because of the tabulary nature we wanted to use XG boost for this there are many",
    "start": "445919",
    "end": "452400"
  },
  {
    "text": "other reasons that attributes is appropriate for this and what we wanted to use so actually boost is a gradient boosted",
    "start": "452400",
    "end": "458819"
  },
  {
    "text": "decision tree Library it's commonly used and it's open source it provides generally very good performance on",
    "start": "458819",
    "end": "465360"
  },
  {
    "text": "tabular data it'll natively handle missing data it's interpretable in terms of we can it'll provide the future",
    "start": "465360",
    "end": "471660"
  },
  {
    "text": "importance measurements when we need to interpret the results it'll also capture non-linear relationships and",
    "start": "471660",
    "end": "477840"
  },
  {
    "text": "interactions It's relatively fast it's paralyzable and confused can be sped up",
    "start": "477840",
    "end": "483000"
  },
  {
    "text": "with gpus it also prunes trees backwards from the maximum depth to optimize loss",
    "start": "483000",
    "end": "490039"
  },
  {
    "text": "I really like this illustration of xgboost from this great blog post which",
    "start": "490139",
    "end": "495599"
  },
  {
    "text": "really goes into the math and explains things clearly about xgboost it's called explain.ai gradient boosting",
    "start": "495599",
    "end": "502819"
  },
  {
    "text": "so with gradient boosting is it's training models in a sequential fashion",
    "start": "502819",
    "end": "508379"
  },
  {
    "text": "and so the example here is that we have a golfer aiming for a Target value this is the Y over here",
    "start": "508379",
    "end": "516260"
  },
  {
    "text": "the golfer takes a shot it's short and the value prediction is F0 value and so",
    "start": "516300",
    "end": "523440"
  },
  {
    "text": "what you can do with this is that we know our true value because it's supervised learning and so we'll take the mean squared error of this and then",
    "start": "523440",
    "end": "529920"
  },
  {
    "text": "you can train the next model another weak learner on the negative gradient of the loss function of that mean squared",
    "start": "529920",
    "end": "536880"
  },
  {
    "text": "error and this will allow you to make a second prediction and the second prediction will get you closer to the",
    "start": "536880",
    "end": "542519"
  },
  {
    "text": "Target value and so you keep doing this this gradient boosting this sort of sequential training of various weak",
    "start": "542519",
    "end": "550860"
  },
  {
    "text": "models and at the end of this you can sum up all the models to produce a",
    "start": "550860",
    "end": "555899"
  },
  {
    "text": "stronger composite model so actually boost Ray makes distributed",
    "start": "555899",
    "end": "562080"
  },
  {
    "text": "data parallelism very easy so what I'm showing here is a simplified version of the code I'm leaving out some things but",
    "start": "562080",
    "end": "568800"
  },
  {
    "text": "really it is this simple we have the extra boost radar train call and what we're passing to that is a ray",
    "start": "568800",
    "end": "575640"
  },
  {
    "text": "D Matrix so actually boost has these particular types of Matrix objects that needs and what we're passing in this",
    "start": "575640",
    "end": "582480"
  },
  {
    "text": "case if we're passing uh you can pass parquet file paths our data is been already sharded into parquet files of",
    "start": "582480",
    "end": "589980"
  },
  {
    "text": "the appropriate size and so in this case the example is we have a train one dot pair K file and a train to dot parquet",
    "start": "589980",
    "end": "596279"
  },
  {
    "text": "file and then the other thing I'm having here is we're specifying that there's two actors being used for the distributed",
    "start": "596279",
    "end": "602940"
  },
  {
    "text": "data parallel model training and so in this case the ray driver will create these two workers it'll assign each a",
    "start": "602940",
    "end": "609480"
  },
  {
    "text": "unique rank and then the next step the workers will load the data and so you have some sort",
    "start": "609480",
    "end": "615360"
  },
  {
    "text": "of source of your data it'll load one they'll have different pieces of data in each worker",
    "start": "615360",
    "end": "621839"
  },
  {
    "text": "and then you're going to start the model training and you can go either from one iteration or multiple iterations",
    "start": "621839",
    "end": "627420"
  },
  {
    "text": "and then after you've trained the model on that Unique Piece of data in each worker you're going to use rabbit all",
    "start": "627420",
    "end": "632820"
  },
  {
    "text": "reduce that's what attributes uses by default for the synchronization of the models across the workers",
    "start": "632820",
    "end": "639360"
  },
  {
    "text": "and then you can keep repeating this process of loading more pieces of data and more training and you'll continue",
    "start": "639360",
    "end": "646800"
  },
  {
    "text": "that until either things Plateau or the max number of boosts is reached",
    "start": "646800",
    "end": "652820"
  },
  {
    "text": "and at the end of this once you've used all your data and you've trained the model you can return the model from one",
    "start": "653160",
    "end": "659100"
  },
  {
    "text": "of the workers to your head node and then it'll be checkpointed",
    "start": "659100",
    "end": "663920"
  },
  {
    "text": "so I'm going to describe some of the actor failure recovery options that come out of the box with extra boost Ray this",
    "start": "665040",
    "end": "671519"
  },
  {
    "text": "has already been described in in good detail by Kai Frick and Michael newly in a previous Ray Summit in 2021 and",
    "start": "671519",
    "end": "678660"
  },
  {
    "text": "there's also some great Uber blog posts about this and that's where this figure is taken from I wanted to highlight it",
    "start": "678660",
    "end": "685200"
  },
  {
    "text": "here just because I think it's a great functionality and it's worth knowing about if you're going to use extra boost Ray",
    "start": "685200",
    "end": "691079"
  },
  {
    "text": "so there are really two fault tolerance options",
    "start": "691079",
    "end": "696240"
  },
  {
    "text": "um the first sort of row up here is showing without fault tolerance what",
    "start": "696240",
    "end": "701459"
  },
  {
    "text": "will happen and so in the very first column we're seeing all the workers loading data that's the one's in yellow",
    "start": "701459",
    "end": "707220"
  },
  {
    "text": "and then in green the second column we're showing them training and then in the third column worker 3",
    "start": "707220",
    "end": "713100"
  },
  {
    "text": "fails and so without fault tolerance what will happen here is that all the other workers will stop and then everything",
    "start": "713100",
    "end": "720240"
  },
  {
    "text": "has to restart and then you can restart the experiment so that's without any type of fault tolerance",
    "start": "720240",
    "end": "725779"
  },
  {
    "text": "Ray provides two types of fault tolerance you have non-elastic training and elastic training and so what's",
    "start": "725779",
    "end": "732480"
  },
  {
    "text": "happening in non-elastic training is that you have the same loading and then training and then when one of the",
    "start": "732480",
    "end": "739200"
  },
  {
    "text": "workers fails if one of the workers fails what will happen is that the other workers will be paused at that point",
    "start": "739200",
    "end": "745680"
  },
  {
    "text": "until that worker 3 can restart reload the data and sync back up with the other",
    "start": "745680",
    "end": "751140"
  },
  {
    "text": "workers and then training will resume the second type of fault tolerance is",
    "start": "751140",
    "end": "756720"
  },
  {
    "text": "elastic training and so again you have loading data training worker 3 failed",
    "start": "756720",
    "end": "762120"
  },
  {
    "text": "and in this case all the other workers just keep going in terms of training and they leave worker 3 behind it will",
    "start": "762120",
    "end": "769079"
  },
  {
    "text": "restart and it'll start training again um you end up actually training a little",
    "start": "769079",
    "end": "774180"
  },
  {
    "text": "bit less than you would and it'll finish early there's a marginal impact empirically on the performance of the",
    "start": "774180",
    "end": "781200"
  },
  {
    "text": "model and so this is the the second basically failure recovery option that you can use",
    "start": "781200",
    "end": "786720"
  },
  {
    "text": "out of the box using extra boost right just by specifying it as one of the parameters",
    "start": "786720",
    "end": "793339"
  },
  {
    "text": "I encourage you to look at the blog posts in the race Summit 2021 videos for more details on that",
    "start": "793440",
    "end": "800639"
  },
  {
    "text": "so Ray provides two options for using xgboost one of these is the xgboost ray",
    "start": "800639",
    "end": "806639"
  },
  {
    "text": "Library which I've been describing the other one is the extra boost trainer and that is a trainer subclass of Ray and",
    "start": "806639",
    "end": "812940"
  },
  {
    "text": "that wraps extra boost Ray so a comparison these two we did a simple comparison there's a couple",
    "start": "812940",
    "end": "820560"
  },
  {
    "text": "things that we want to be able to do one of those is to load parquet file paths directly the other one is to be able to",
    "start": "820560",
    "end": "827040"
  },
  {
    "text": "use fault tolerance options like I described and then the third is we just want it to be as fast as possible so for Action News Ray it the library",
    "start": "827040",
    "end": "835079"
  },
  {
    "text": "itself will allow you to pass parquet file paths uh it has fault tolerance parameters built into it and it trains",
    "start": "835079",
    "end": "842160"
  },
  {
    "text": "pretty fast but actually this trainer um it doesn't allow you to pass parquet file paths directly you would have to",
    "start": "842160",
    "end": "847920"
  },
  {
    "text": "put them into a ray Matrix array data set object and then you can pass up okay",
    "start": "847920",
    "end": "853620"
  },
  {
    "text": "file paths and then for the fault tolerance options these can be accessed but you sort of have to sneak in there",
    "start": "853620",
    "end": "859320"
  },
  {
    "text": "and access them via private attributes to be able to use extra boost trainer and empirically it's just slower than",
    "start": "859320",
    "end": "865560"
  },
  {
    "text": "using the extra boost rate Library directly which makes sense to a certain extent because it's wrapping the extra boost rate Library so there's gonna be a",
    "start": "865560",
    "end": "872220"
  },
  {
    "text": "certain amount of overhead we just decided to go ahead with extra boost Ray",
    "start": "872220",
    "end": "877260"
  },
  {
    "text": "one of the things we want to be able to do with it is we want to be able to cross validation cross Foundation is a really common technique in scientific",
    "start": "877260",
    "end": "883920"
  },
  {
    "text": "circles for improving the measurement of the performance of models",
    "start": "883920",
    "end": "889740"
  },
  {
    "text": "and so what's happening here for cross validation is that you're going to take all of your data and then you're going",
    "start": "889740",
    "end": "895620"
  },
  {
    "text": "to split it into k-folds and so in this case you can split it into four folds or",
    "start": "895620",
    "end": "901019"
  },
  {
    "text": "the examples for four folds and in each split one of these folds is going to be the test and the rest are going to be",
    "start": "901019",
    "end": "907079"
  },
  {
    "text": "the train so in this case we have the the first fold being the test and that's the train and the next split the second",
    "start": "907079",
    "end": "913019"
  },
  {
    "text": "fold is the test and the others are the train each one of these splits we're going to measure the performance of the",
    "start": "913019",
    "end": "918660"
  },
  {
    "text": "model and then at the end of measuring the performance of the model on each one of the splits we're going to average the",
    "start": "918660",
    "end": "923820"
  },
  {
    "text": "metrics through all of them you end up getting a better performance metrics performance metric measurement overall",
    "start": "923820",
    "end": "929820"
  },
  {
    "text": "the accuracy of the performance measurement is superior using cross validation",
    "start": "929820",
    "end": "935000"
  },
  {
    "text": "so Ray doesn't provide this option out of the box for cross validation and so knowing a little bit about how to",
    "start": "935000",
    "end": "942019"
  },
  {
    "text": "manually distribute things using Ray you can use the ray dot remote you could",
    "start": "942019",
    "end": "947279"
  },
  {
    "text": "create a function called cross file and then you can pass in the extra boost radar train within that function and",
    "start": "947279",
    "end": "954000"
  },
  {
    "text": "just pass the split data to the extra boost radar train call and in this case the next call will be",
    "start": "954000",
    "end": "961560"
  },
  {
    "text": "to um running radot remote across this function and you can do this in a list",
    "start": "961560",
    "end": "967019"
  },
  {
    "text": "comprehension and that'll give you the Futures and then when you do the actual rate.get you'll do a blocking step until",
    "start": "967019",
    "end": "973079"
  },
  {
    "text": "you get the results from all of these calls to the Cross file function so that was our original implementation",
    "start": "973079",
    "end": "979560"
  },
  {
    "text": "of this this results in an error so I put this error into a GitHub issue it",
    "start": "979560",
    "end": "984839"
  },
  {
    "text": "may be that this type of strategy for doing cross-validation with XG boost rate is just not possible",
    "start": "984839",
    "end": "990540"
  },
  {
    "text": "maybe there is a way to do it and at some point maybe we will find a solution to that but if anybody has any ideas I'm",
    "start": "990540",
    "end": "996480"
  },
  {
    "text": "more than happy to hear we're trying other types of cross Foundation as well such as nested cross foundation for",
    "start": "996480",
    "end": "1002540"
  },
  {
    "text": "hyper parameter optimization our solution currently is to serialize",
    "start": "1002540",
    "end": "1009940"
  },
  {
    "text": "cross-valuation so rather than paralyzing it to make it as fast as possible you can serialize the training",
    "start": "1009940",
    "end": "1018440"
  },
  {
    "text": "of the extra boost model on splits of data and so in this case all you do is you take off the add Ray dot remote",
    "start": "1018440",
    "end": "1024199"
  },
  {
    "text": "decorator and then you can call the list comprehension on here in this case it'll run it sequentially so it's going to be",
    "start": "1024199",
    "end": "1030380"
  },
  {
    "text": "K times slower where K is the number of folds used for the cross validation it'll work it's slower depends on your",
    "start": "1030380",
    "end": "1036620"
  },
  {
    "text": "application if you want to go this route we also wanted to evaluate what it's",
    "start": "1036620",
    "end": "1043579"
  },
  {
    "text": "like basically how much of an improvement can we get when we start to paralyze training using extra boost",
    "start": "1043579",
    "end": "1049340"
  },
  {
    "text": "radar train this is unrelated to cross Foundation this is just splitting again",
    "start": "1049340",
    "end": "1054380"
  },
  {
    "text": "the data into shards of data putting those in different processes and sharing the model on each one of those processes",
    "start": "1054380",
    "end": "1061179"
  },
  {
    "text": "and so what we're showing here on the y-axis is the time it takes to train and",
    "start": "1061179",
    "end": "1066320"
  },
  {
    "text": "then on the x-axis is the number of workers and so this first data point here is for one worker then we increase",
    "start": "1066320",
    "end": "1072559"
  },
  {
    "text": "the two workers four workers and eight workers and what you see is you see a dramatic reduction in the amount of time",
    "start": "1072559",
    "end": "1077900"
  },
  {
    "text": "it takes to train that's exactly what you want to see this is what's giving us our speed Improvement when we start to",
    "start": "1077900",
    "end": "1084080"
  },
  {
    "text": "use distributed data parallel model training on the right is just a log base 2 version of the exact same data trying",
    "start": "1084080",
    "end": "1090740"
  },
  {
    "text": "to give you a little more sense of the linearity you might be able to see with this so we're really happy about this this is",
    "start": "1090740",
    "end": "1096080"
  },
  {
    "text": "really good performance it allows us to use increasing amounts of data without taking increasing amounts of time",
    "start": "1096080",
    "end": "1101240"
  },
  {
    "text": "necessarily the other thing is that extra boost Ray does a great job uniformly in loading",
    "start": "1101240",
    "end": "1108200"
  },
  {
    "text": "this data and handling all these different workers so we have over 67",
    "start": "1108200",
    "end": "1113539"
  },
  {
    "text": "million observations and over a thousand features that we're working with for the risk prediction and the data is",
    "start": "1113539",
    "end": "1120860"
  },
  {
    "text": "partitioned into evenly sized parquet file paths and Ray is able to uniformly",
    "start": "1120860",
    "end": "1126260"
  },
  {
    "text": "load this data across all these different workers so we've got 30 64 gigabyte workers and you can't see these",
    "start": "1126260",
    "end": "1133940"
  },
  {
    "text": "numbers on the right here but this is a plot of on the y-axis the node memory",
    "start": "1133940",
    "end": "1139280"
  },
  {
    "text": "which is a combination of the Heap and the object store and on the x-axis of time this is taken straight from the",
    "start": "1139280",
    "end": "1145640"
  },
  {
    "text": "default dashboard that's created for grafana for you by Ray",
    "start": "1145640",
    "end": "1150919"
  },
  {
    "text": "what you can see from these numbers if you could see them is that the range of",
    "start": "1150919",
    "end": "1155960"
  },
  {
    "text": "memory used by each one is between 31 and 36 gigabytes and so there's a pretty",
    "start": "1155960",
    "end": "1161480"
  },
  {
    "text": "narrow range in terms of memory used and it's pretty uniform so that's great there's no bottleneck",
    "start": "1161480",
    "end": "1166880"
  },
  {
    "text": "you're not seeing certain nodes using up a ton more data than other ones which would become problematic",
    "start": "1166880",
    "end": "1173679"
  },
  {
    "text": "that's the end of the part on cancer risk prediction sorry cancer yeah cancer",
    "start": "1174559",
    "end": "1181160"
  },
  {
    "text": "risk prediction and so now I'm going to talk about cancer detection model training",
    "start": "1181160",
    "end": "1187299"
  },
  {
    "text": "so the objective of this is that we want to be able to predict the type of cancer in the cancer stage from blood samples",
    "start": "1187520",
    "end": "1194660"
  },
  {
    "text": "so here we're working with multi-amic data that's collected from blood samples so we collect blood from patients with",
    "start": "1194660",
    "end": "1201260"
  },
  {
    "text": "and without cancer in this retrospective study so we can build these machine learning models",
    "start": "1201260",
    "end": "1206419"
  },
  {
    "text": "we have a perspective study where we take these trained models and we have the largest colorectal cancer",
    "start": "1206419",
    "end": "1212960"
  },
  {
    "text": "cohort for screening and for blood-based cancer ever so we've",
    "start": "1212960",
    "end": "1218900"
  },
  {
    "text": "got 35 thousand patients already enrolled in this clinical trial",
    "start": "1218900",
    "end": "1225559"
  },
  {
    "text": "but this is the actual training stage where we're doing things retrospectively and so we have labeled blood as coming",
    "start": "1225559",
    "end": "1232760"
  },
  {
    "text": "from a cancer or non-cancer patient and um what we do here is we can from that blood do various types of",
    "start": "1232760",
    "end": "1239240"
  },
  {
    "text": "multi-amix analyzes again these are things like looking at the proteomics the genomics the transcriptomics the",
    "start": "1239240",
    "end": "1244520"
  },
  {
    "text": "epigenomics this produces a vast amount of data and for this data we want to use",
    "start": "1244520",
    "end": "1249919"
  },
  {
    "text": "pytorch so for this one of the reasons we want to use Python is that it's open source",
    "start": "1249919",
    "end": "1255679"
  },
  {
    "text": "just like Ray it's wonderful and it's open source you can see everything and it's more heavily tested",
    "start": "1255679",
    "end": "1260900"
  },
  {
    "text": "It's relatively fast and between paralyzed it has first class support for",
    "start": "1260900",
    "end": "1266000"
  },
  {
    "text": "deep learning it's flexible enough to be used for non-deep learning model development and it natively handles",
    "start": "1266000",
    "end": "1271940"
  },
  {
    "text": "multi-dimensional arrays in addition as extensive GPU support",
    "start": "1271940",
    "end": "1277419"
  },
  {
    "text": "Ray provides a torch trainer which is a subclass of the trainer class and this",
    "start": "1278480",
    "end": "1285860"
  },
  {
    "text": "allows you more flexibility than the extra boost library because what you can do here is you can pass in a function to",
    "start": "1285860",
    "end": "1293059"
  },
  {
    "text": "the torch trainer and you can customize that function as much as you want to the",
    "start": "1293059",
    "end": "1298159"
  },
  {
    "text": "extra boost radar train that's more of a closed system you're not passing in a function to it",
    "start": "1298159",
    "end": "1303679"
  },
  {
    "text": "um so in this case we can Define our training Loop that we want to pass to the torch trainer and within that the",
    "start": "1303679",
    "end": "1310580"
  },
  {
    "text": "typical things that will happen are that you're going to be loading the data and training the model evaluating the model and checkpointing the model so here is",
    "start": "1310580",
    "end": "1317480"
  },
  {
    "text": "just a little diagram of you have one choice trainer if we're using distributed data parallel model training",
    "start": "1317480",
    "end": "1323000"
  },
  {
    "text": "the data will be loaded onto each one of these workers unique shards of data and",
    "start": "1323000",
    "end": "1328760"
  },
  {
    "text": "it'll be trained and then you can use functionality that is really",
    "start": "1328760",
    "end": "1334340"
  },
  {
    "text": "greatly enabled by array for distributed data parallelism when you're doing model training",
    "start": "1334340",
    "end": "1341260"
  },
  {
    "text": "so like I was saying race simplifies this process so if you're not using right for this what you would have to do is you would",
    "start": "1341539",
    "end": "1347240"
  },
  {
    "text": "have to manually go in and provide information to the distributed data parallel class for pi torch to be able",
    "start": "1347240",
    "end": "1355400"
  },
  {
    "text": "to do this type of thing Ray provides some basically helper functions to make this really easy to do",
    "start": "1355400",
    "end": "1360500"
  },
  {
    "text": "you have this prepare model helper function and so what this will do is it'll move the model to the device it",
    "start": "1360500",
    "end": "1365840"
  },
  {
    "text": "can be a CPU or GPU and then it'll also prepare the pytorch model with the",
    "start": "1365840",
    "end": "1371240"
  },
  {
    "text": "distributed data parallel class which allows you to use distributed data parallel model training you can also",
    "start": "1371240",
    "end": "1377299"
  },
  {
    "text": "specify to use the fully sharded data parallel class with your pytorch trainer",
    "start": "1377299",
    "end": "1383000"
  },
  {
    "text": "in addition it also provides another function for preparing the data loader conveniently named prepared data loader",
    "start": "1383000",
    "end": "1389539"
  },
  {
    "text": "and so what you can do here is you can it'll move the data to the CPU or GPU it'll also apply distributed sampler to",
    "start": "1389539",
    "end": "1396080"
  },
  {
    "text": "that data loader so what this means is that your model will or your data loader",
    "start": "1396080",
    "end": "1401240"
  },
  {
    "text": "will be sampling unique pieces of data from the entire data set which is important because you don't",
    "start": "1401240",
    "end": "1406640"
  },
  {
    "text": "want to be resampling the same data across every worker what this would look like in practice is",
    "start": "1406640",
    "end": "1412880"
  },
  {
    "text": "if you were going to write this train Loop per worker you can pass in your data loaders your trained noodle loader",
    "start": "1412880",
    "end": "1418400"
  },
  {
    "text": "your evaluation data loader your model and the number of epics you want to run for and you'd apply the prepare model",
    "start": "1418400",
    "end": "1424820"
  },
  {
    "text": "you would apply the prepare data loader and then you do your your epic training",
    "start": "1424820",
    "end": "1430940"
  },
  {
    "text": "so you go your fit usually your evaluation calculations and then you'd be reporting those metrics and at the",
    "start": "1430940",
    "end": "1437480"
  },
  {
    "text": "end you would be checkpointing your best model and so when you use torch trainer to do",
    "start": "1437480",
    "end": "1442700"
  },
  {
    "text": "this each one of these workers is going to be running the same training Loop and because of this prepare model and",
    "start": "1442700",
    "end": "1449179"
  },
  {
    "text": "prepare data loader although they're running the same training Loop they're actually accessing different data and",
    "start": "1449179",
    "end": "1455780"
  },
  {
    "text": "they're training different models and after a certain number of iterations of training you're going to do an auto reduce synchronization and that'll",
    "start": "1455780",
    "end": "1462380"
  },
  {
    "text": "synchronize the models across all the workers",
    "start": "1462380",
    "end": "1466419"
  },
  {
    "text": "we also wanted to evaluate the basically Improvement that we can get from using",
    "start": "1467419",
    "end": "1473539"
  },
  {
    "text": "this distributed data parallel plus distributed sampler option that's really conveniently built into Pi torch and you",
    "start": "1473539",
    "end": "1481100"
  },
  {
    "text": "can access using Ray very easily so again we're showing the time to train on the y-axis and the number of workers",
    "start": "1481100",
    "end": "1487580"
  },
  {
    "text": "on the x-axis and so here we see that with one worker if we double the number of workers we",
    "start": "1487580",
    "end": "1493460"
  },
  {
    "text": "get nearly having and the amount of training time it takes and we keep seeing that as we increase the number of workers we decrease the",
    "start": "1493460",
    "end": "1500360"
  },
  {
    "text": "amount of time it takes to train very similar to extra boost Ray and this is just again using log base 2",
    "start": "1500360",
    "end": "1508159"
  },
  {
    "text": "so you can see a little bit more of the linearity of the plot",
    "start": "1508159",
    "end": "1512440"
  },
  {
    "text": "so the thing that's very important for us we are creating a product which is going to be",
    "start": "1514159",
    "end": "1519860"
  },
  {
    "text": "approved you know we're working towards approval body FDA everything has to be completely reproducible",
    "start": "1519860",
    "end": "1525500"
  },
  {
    "text": "and so we are making use of things like ml flow logger callback to be able to",
    "start": "1525500",
    "end": "1531860"
  },
  {
    "text": "log everything to ml flow such that it'll persist indefinitely one of the things we also want to do is we want to",
    "start": "1531860",
    "end": "1537440"
  },
  {
    "text": "make sure we're recording all the data and information we need to make each experiment reproducible",
    "start": "1537440",
    "end": "1543500"
  },
  {
    "text": "um so in this case what we're showing is just this is a screen capture from ml flow and we can see the entryway or the",
    "start": "1543500",
    "end": "1550640"
  },
  {
    "text": "entry point is Ray torch.pi and then what we're recording is other information necessary for reproducibility these include git hash",
    "start": "1550640",
    "end": "1558200"
  },
  {
    "text": "and in addition to the git hash we want to know whether or not someone forgot to commit something this will happen in the",
    "start": "1558200",
    "end": "1564200"
  },
  {
    "text": "case where someone's just tweaking little things and they're not committing every little thing if in most cases when",
    "start": "1564200",
    "end": "1570140"
  },
  {
    "text": "you're running a large experiment everything should be committed before you start it someone forgets will have a flag which says hey there",
    "start": "1570140",
    "end": "1578360"
  },
  {
    "text": "was something that wasn't committed in that case we also have a tarball of all the code that was used to run the",
    "start": "1578360",
    "end": "1584179"
  },
  {
    "text": "experiment so we're storing that as an artifact using ml flow that allows you to recover the",
    "start": "1584179",
    "end": "1590000"
  },
  {
    "text": "experiment even if you didn't commit everything in addition we're saving the experiment",
    "start": "1590000",
    "end": "1596179"
  },
  {
    "text": "configuration as a config.yaml file and we also save all the CLI overrides",
    "start": "1596179",
    "end": "1603140"
  },
  {
    "text": "so our ml flow or our ml platform has the ability to be executed using the CLI",
    "start": "1603140",
    "end": "1609380"
  },
  {
    "text": "and people can override certain parameters over the CLI and so we're recording those",
    "start": "1609380",
    "end": "1614600"
  },
  {
    "text": "and in addition we're using array cluster yaml so that's specifying everything about the ray cluster",
    "start": "1614600",
    "end": "1620539"
  },
  {
    "text": "including the docker image which is very important for reproducibility and so we're also saving an artifact of",
    "start": "1620539",
    "end": "1626960"
  },
  {
    "text": "the rate cluster definition in summary so freenom uses machine",
    "start": "1626960",
    "end": "1633140"
  },
  {
    "text": "learning to predict cancer risk and detect cancer and so it's going from Real World data",
    "start": "1633140",
    "end": "1639200"
  },
  {
    "text": "to Future extraction to train the models to being able to predict whether or not someone is at high risk or low risk of",
    "start": "1639200",
    "end": "1645559"
  },
  {
    "text": "cancer in addition we take blood we can do montail mix analysis on that blood we",
    "start": "1645559",
    "end": "1652100"
  },
  {
    "text": "train machine learning models on that and that'll allow us to detect whether or not someone has cancer or does not",
    "start": "1652100",
    "end": "1657860"
  },
  {
    "text": "have cancer Ray simplifies distributed data parallel model training a whole lot and we're",
    "start": "1657860",
    "end": "1663740"
  },
  {
    "text": "very grateful for that cross-validation is something which Ray does not provide and so we've been working through different iterations of this",
    "start": "1663740",
    "end": "1670600"
  },
  {
    "text": "I've not presenting on the nested cross validation work we've done but I've also",
    "start": "1670600",
    "end": "1676340"
  },
  {
    "text": "have some implementation design ideas which I would love to run by some people in terms of like if this is if this is",
    "start": "1676340",
    "end": "1682340"
  },
  {
    "text": "the most efficient way to be doing it with Ray so if there's any experts out there Andre I would love to talk with you afterwards",
    "start": "1682340",
    "end": "1689559"
  },
  {
    "text": "and I want to acknowledge all the Fantastic work of everybody who contributed to this presentation",
    "start": "1689600",
    "end": "1695900"
  },
  {
    "text": "um so I'm within the research platform team and then the scientists are within the risk prediction team and the multi",
    "start": "1695900",
    "end": "1702860"
  },
  {
    "text": "Amex team and this is the team which is uh using doing cancer detection using",
    "start": "1702860",
    "end": "1709039"
  },
  {
    "text": "multi-homics data and I really want to thank Rey in any scale for providing a really great product",
    "start": "1709039",
    "end": "1714460"
  },
  {
    "text": "and making it easy and accessible for everyone and I also want to thank the rate",
    "start": "1714460",
    "end": "1719539"
  },
  {
    "text": "conference organizers and everyone who's doing AV work out there for for making this a very great conference to attend",
    "start": "1719539",
    "end": "1726799"
  },
  {
    "text": "and thank you and I'll answer any questions now [Applause]",
    "start": "1726799",
    "end": "1738329"
  },
  {
    "text": "yeah I'm not uh we're not at Liberty disclose where all the the real world data comes from so we have Partnerships",
    "start": "1743440",
    "end": "1749480"
  },
  {
    "text": "with different companies",
    "start": "1749480",
    "end": "1752320"
  },
  {
    "text": "how much data do you need to train a meaningful model so the first question I",
    "start": "1755779",
    "end": "1761360"
  },
  {
    "text": "yeah um it's a good question so it's like how much do we need I don't",
    "start": "1761360",
    "end": "1768020"
  },
  {
    "text": "know that the direct answer to that uh so basically you can do estimates of how much of an improvement you get as you",
    "start": "1768020",
    "end": "1774320"
  },
  {
    "text": "increase the amount of data we're using but I haven't seen uh that type of plot",
    "start": "1774320",
    "end": "1779419"
  },
  {
    "text": "from the risk prediction team",
    "start": "1779419",
    "end": "1782500"
  },
  {
    "text": "sorry can you say it a little louder uh",
    "start": "1793279",
    "end": "1798380"
  },
  {
    "text": "oh yeah so for this project for the results I was presenting it was over 67 million uh observations of patient data",
    "start": "1798380",
    "end": "1807080"
  },
  {
    "text": "and about a thousand features extracted from that yeah",
    "start": "1807080",
    "end": "1814220"
  },
  {
    "text": "um yeah please um how much data did you have like how",
    "start": "1814220",
    "end": "1820760"
  },
  {
    "text": "like data what models on modules have you found most useful and has been featured",
    "start": "1820760",
    "end": "1827919"
  },
  {
    "text": "so the sellers part when you say cells",
    "start": "1828559",
    "end": "1832539"
  },
  {
    "text": "oh no it's not single cell um yeah so we're primarily this is a scientific question I always appreciate",
    "start": "1833600",
    "end": "1839000"
  },
  {
    "text": "these so we're using uh whatever we can get from the blood from the plasma the",
    "start": "1839000",
    "end": "1844520"
  },
  {
    "text": "cell free DNA and um that's one of the things we're using cell free DNA is one of the primary things you can measure both obviously",
    "start": "1844520",
    "end": "1851179"
  },
  {
    "text": "sequence set as well as look for any type of epigenetic modifications to that you can also look at the expression",
    "start": "1851179",
    "end": "1857000"
  },
  {
    "text": "level of different proteins in the blood but it's not a it's not single cell sequencing like",
    "start": "1857000",
    "end": "1863120"
  },
  {
    "text": "that I don't know if I answered your second question but let me actually because I've got",
    "start": "1863120",
    "end": "1869539"
  },
  {
    "text": "oh I think I'm overtime I can't tell but let me a couple more you had a question",
    "start": "1869539",
    "end": "1877720"
  },
  {
    "text": "of cancers and non-cancer yes yeah so it's we create a pretty balanced",
    "start": "1887059",
    "end": "1894260"
  },
  {
    "text": "data set I don't know the exact numbers off the top of my head but for the retrospective training we deliberately have like a large number of cancer",
    "start": "1894260",
    "end": "1901580"
  },
  {
    "text": "samples as opposed to just sampling like the real world population relative",
    "start": "1901580",
    "end": "1906799"
  },
  {
    "text": "frequencies yeah for the reproducibility",
    "start": "1906799",
    "end": "1912580"
  },
  {
    "text": "of all tolerance do you like if you have something that comes up where something has to restart we're using one of the strategies where",
    "start": "1913760",
    "end": "1922299"
  },
  {
    "text": "there was one where one of the um",
    "start": "1925399",
    "end": "1930398"
  },
  {
    "text": "yeah very good question so that we don't use that the elastic training we use the non-elastic training for that reason",
    "start": "1933799",
    "end": "1939440"
  },
  {
    "text": "good questions",
    "start": "1939440",
    "end": "1942460"
  },
  {
    "text": "variable Behavior or is that a self-selecting pretty much everything is with the FDA is we try to do our",
    "start": "1945200",
    "end": "1951620"
  },
  {
    "text": "absolute best to make things as robust as possible and then we you know we we have conversations with them about what",
    "start": "1951620",
    "end": "1958760"
  },
  {
    "text": "we're doing and the negative feedback on that and so really it's mostly self-driven in all this to just make the",
    "start": "1958760",
    "end": "1964520"
  },
  {
    "text": "best solid most solid product possible and then they can give us feedback if we can do anything better",
    "start": "1964520",
    "end": "1970640"
  },
  {
    "text": "last question okay I think I think you maybe had your question your hand yeah",
    "start": "1970640",
    "end": "1977020"
  },
  {
    "text": "largest hospital ah yeah yeah that's a good question too so um what so the question is like",
    "start": "1988419",
    "end": "1995720"
  },
  {
    "text": "vertical versus horizontal scaling I apologize I didn't repeat all of everyone's questions",
    "start": "1995720",
    "end": "2000940"
  },
  {
    "text": "um so it's for us it's uh we're really aiming for",
    "start": "2000940",
    "end": "2005980"
  },
  {
    "text": "be able to use the smallest most horizontal strategy so smallest compute size most horizontal strategy because",
    "start": "2005980",
    "end": "2011980"
  },
  {
    "text": "that is the most scalable long term and so you could increase the vertical one we didn't test that we have like",
    "start": "2011980",
    "end": "2018220"
  },
  {
    "text": "originally when people started before we had the option using Rey to use this people could use a vertical solution for",
    "start": "2018220",
    "end": "2024460"
  },
  {
    "text": "it um but when there was out of memory issues there was no place to go",
    "start": "2024460",
    "end": "2029919"
  },
  {
    "text": "you couldn't like there wasn't any charting solution in place and I'm I know some there were some other",
    "start": "2029919",
    "end": "2035620"
  },
  {
    "text": "questions I really appreciate all the questions I'd love to answer them afterwards foreign",
    "start": "2035620",
    "end": "2043380"
  }
]
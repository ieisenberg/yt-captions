[
  {
    "text": "[Music]",
    "start": "170",
    "end": "15260"
  },
  {
    "text": "hi everyone",
    "start": "15679",
    "end": "16560"
  },
  {
    "text": "and welcome to my talk on nums a",
    "start": "16560",
    "end": "19199"
  },
  {
    "text": "scalable",
    "start": "19199",
    "end": "19920"
  },
  {
    "text": "numeric array library for the cloud",
    "start": "19920",
    "end": "23840"
  },
  {
    "text": "the core objective of nums is to improve",
    "start": "24640",
    "end": "27199"
  },
  {
    "text": "the runtime of multi-dimensional",
    "start": "27199",
    "end": "29439"
  },
  {
    "text": "array programs in python and enable",
    "start": "29439",
    "end": "31840"
  },
  {
    "text": "python scientific computing community",
    "start": "31840",
    "end": "34000"
  },
  {
    "text": "to analyze and model larger data sets",
    "start": "34000",
    "end": "38480"
  },
  {
    "text": "an ideal python solution seamlessly",
    "start": "38480",
    "end": "40800"
  },
  {
    "text": "paralyzes",
    "start": "40800",
    "end": "41600"
  },
  {
    "text": "and scales a numpy like array api",
    "start": "41600",
    "end": "44399"
  },
  {
    "text": "allowing scientists",
    "start": "44399",
    "end": "45600"
  },
  {
    "text": "and statisticians to leverage their",
    "start": "45600",
    "end": "47200"
  },
  {
    "text": "existing programming knowledge without",
    "start": "47200",
    "end": "48960"
  },
  {
    "text": "having to learn",
    "start": "48960",
    "end": "49840"
  },
  {
    "text": "new skills to achieve this ideal",
    "start": "49840",
    "end": "53199"
  },
  {
    "text": "solution",
    "start": "53199",
    "end": "53760"
  },
  {
    "text": "we identify three key problems that must",
    "start": "53760",
    "end": "56160"
  },
  {
    "text": "be solved",
    "start": "56160",
    "end": "58719"
  },
  {
    "text": "first to effectively paralyze numpy like",
    "start": "58719",
    "end": "61359"
  },
  {
    "text": "code",
    "start": "61359",
    "end": "61920"
  },
  {
    "text": "we must determine dependencies between",
    "start": "61920",
    "end": "64000"
  },
  {
    "text": "operations",
    "start": "64000",
    "end": "65040"
  },
  {
    "text": "and then concurrently execute any",
    "start": "65040",
    "end": "66960"
  },
  {
    "text": "independent operations",
    "start": "66960",
    "end": "70400"
  },
  {
    "text": "second we need to avoid high overheads",
    "start": "70400",
    "end": "72960"
  },
  {
    "text": "from parallelization",
    "start": "72960",
    "end": "74880"
  },
  {
    "text": "for example the naive approach of",
    "start": "74880",
    "end": "77040"
  },
  {
    "text": "sending one eye pc",
    "start": "77040",
    "end": "78640"
  },
  {
    "text": "per element wise array operation poses",
    "start": "78640",
    "end": "80960"
  },
  {
    "text": "untenable overheads",
    "start": "80960",
    "end": "84080"
  },
  {
    "text": "third to scale array operations on",
    "start": "84320",
    "end": "86560"
  },
  {
    "text": "distributed memory",
    "start": "86560",
    "end": "88000"
  },
  {
    "text": "we must both avoid high network",
    "start": "88000",
    "end": "89840"
  },
  {
    "text": "overheads and load balance the data",
    "start": "89840",
    "end": "91840"
  },
  {
    "text": "among the different nodes",
    "start": "91840",
    "end": "95200"
  },
  {
    "text": "here are some solutions that solve some",
    "start": "96079",
    "end": "98159"
  },
  {
    "text": "of the problems we've presented so far",
    "start": "98159",
    "end": "101439"
  },
  {
    "text": "first we have numpy which primarily",
    "start": "101439",
    "end": "104560"
  },
  {
    "text": "is serially executing it provides shared",
    "start": "104560",
    "end": "107680"
  },
  {
    "text": "memory parallelism for basic linear",
    "start": "107680",
    "end": "109360"
  },
  {
    "text": "algebra operations via the system's",
    "start": "109360",
    "end": "111119"
  },
  {
    "text": "blast implementation second",
    "start": "111119",
    "end": "114799"
  },
  {
    "text": "existing single program multiple data",
    "start": "114799",
    "end": "117600"
  },
  {
    "text": "distributed memory solutions such as mpi",
    "start": "117600",
    "end": "119920"
  },
  {
    "text": "present python users with an unfamiliar",
    "start": "119920",
    "end": "122240"
  },
  {
    "text": "programming model",
    "start": "122240",
    "end": "125040"
  },
  {
    "text": "third block partition python array",
    "start": "125200",
    "end": "127439"
  },
  {
    "text": "libraries such as desk arrays rely on",
    "start": "127439",
    "end": "129920"
  },
  {
    "text": "task graph scheduling heuristics",
    "start": "129920",
    "end": "131599"
  },
  {
    "text": "optimized for",
    "start": "131599",
    "end": "132480"
  },
  {
    "text": "general workloads instead of array",
    "start": "132480",
    "end": "134400"
  },
  {
    "text": "operations",
    "start": "134400",
    "end": "136080"
  },
  {
    "text": "to our knowledge none of these solutions",
    "start": "136080",
    "end": "138480"
  },
  {
    "text": "simultaneously solves all three of these",
    "start": "138480",
    "end": "140840"
  },
  {
    "text": "problems",
    "start": "140840",
    "end": "143520"
  },
  {
    "text": "we therefore developed nums a numerical",
    "start": "143520",
    "end": "146959"
  },
  {
    "text": "cloud computing system that compiles",
    "start": "146959",
    "end": "148800"
  },
  {
    "text": "numpy to optimize distributed memory",
    "start": "148800",
    "end": "151280"
  },
  {
    "text": "code at runtime",
    "start": "151280",
    "end": "152640"
  },
  {
    "text": "the the components of nums and its",
    "start": "152640",
    "end": "155120"
  },
  {
    "text": "interactions with external processes are",
    "start": "155120",
    "end": "157120"
  },
  {
    "text": "captured by this data flow diagram",
    "start": "157120",
    "end": "159840"
  },
  {
    "text": "the user interacts with the numpy api",
    "start": "159840",
    "end": "162800"
  },
  {
    "text": "which is built atop",
    "start": "162800",
    "end": "163920"
  },
  {
    "text": "the array application the array",
    "start": "163920",
    "end": "166560"
  },
  {
    "text": "application produces block arrays",
    "start": "166560",
    "end": "168800"
  },
  {
    "text": "which can be operated on in the same",
    "start": "168800",
    "end": "170800"
  },
  {
    "text": "fashion as numpy's",
    "start": "170800",
    "end": "172400"
  },
  {
    "text": "nd arrays the block arrays can be",
    "start": "172400",
    "end": "175280"
  },
  {
    "text": "converted to",
    "start": "175280",
    "end": "176239"
  },
  {
    "text": "graph arrays for optimized scheduling",
    "start": "176239",
    "end": "179280"
  },
  {
    "text": "block level operations are then",
    "start": "179280",
    "end": "180959"
  },
  {
    "text": "submitted to the compute manager",
    "start": "180959",
    "end": "182959"
  },
  {
    "text": "which are sent to the distributed system",
    "start": "182959",
    "end": "184879"
  },
  {
    "text": "interface",
    "start": "184879",
    "end": "186879"
  },
  {
    "text": "the system interface then invokes rpcs",
    "start": "186879",
    "end": "189280"
  },
  {
    "text": "on the distributed system",
    "start": "189280",
    "end": "191040"
  },
  {
    "text": "which carry out the actual computations",
    "start": "191040",
    "end": "194400"
  },
  {
    "text": "we now turn to our solution to the three",
    "start": "194400",
    "end": "196720"
  },
  {
    "text": "key problems we solve with nums",
    "start": "196720",
    "end": "200720"
  },
  {
    "text": "first we solve problem one by exposing a",
    "start": "201599",
    "end": "204159"
  },
  {
    "text": "numpy compatible",
    "start": "204159",
    "end": "205280"
  },
  {
    "text": "array abstraction defined in terms of",
    "start": "205280",
    "end": "207120"
  },
  {
    "text": "futures",
    "start": "207120",
    "end": "208400"
  },
  {
    "text": "allowing the scheduler to see the",
    "start": "208400",
    "end": "210080"
  },
  {
    "text": "computation graph in advance and",
    "start": "210080",
    "end": "212000"
  },
  {
    "text": "paralyze execution",
    "start": "212000",
    "end": "215360"
  },
  {
    "text": "in nums arrays are comprised of futures",
    "start": "215360",
    "end": "218080"
  },
  {
    "text": "and their operations are carried out as",
    "start": "218080",
    "end": "220000"
  },
  {
    "text": "promises",
    "start": "220000",
    "end": "221680"
  },
  {
    "text": "this captures exactly the data",
    "start": "221680",
    "end": "223440"
  },
  {
    "text": "dependencies required to compute each",
    "start": "223440",
    "end": "225360"
  },
  {
    "text": "block in the output array",
    "start": "225360",
    "end": "227120"
  },
  {
    "text": "allowing for concurrent execution of",
    "start": "227120",
    "end": "229440"
  },
  {
    "text": "independent operations",
    "start": "229440",
    "end": "231040"
  },
  {
    "text": "within and between output blocks",
    "start": "231040",
    "end": "235200"
  },
  {
    "text": "whenever an array access is triggered",
    "start": "235200",
    "end": "237519"
  },
  {
    "text": "high level operations on the resulting",
    "start": "237519",
    "end": "239599"
  },
  {
    "text": "new array are captured as low-level",
    "start": "239599",
    "end": "241760"
  },
  {
    "text": "block operations",
    "start": "241760",
    "end": "243599"
  },
  {
    "text": "this dynamically constructs a task graph",
    "start": "243599",
    "end": "246159"
  },
  {
    "text": "whereby",
    "start": "246159",
    "end": "247120"
  },
  {
    "text": "dependent tasks are queued and",
    "start": "247120",
    "end": "249040"
  },
  {
    "text": "independent tasks are executed",
    "start": "249040",
    "end": "250879"
  },
  {
    "text": "concurrently",
    "start": "250879",
    "end": "251599"
  },
  {
    "text": "by the distributed system and in this",
    "start": "251599",
    "end": "253599"
  },
  {
    "text": "case the distributed system is ray",
    "start": "253599",
    "end": "257599"
  },
  {
    "text": "for our solution to problem number two",
    "start": "258720",
    "end": "262079"
  },
  {
    "text": "we solve problem number two by",
    "start": "262079",
    "end": "263840"
  },
  {
    "text": "coarsening operations by partitioning",
    "start": "263840",
    "end": "265919"
  },
  {
    "text": "arrays into a grid of blocks and",
    "start": "265919",
    "end": "267440"
  },
  {
    "text": "performing",
    "start": "267440",
    "end": "268000"
  },
  {
    "text": "array operations blockwise rather than",
    "start": "268000",
    "end": "270479"
  },
  {
    "text": "element wise",
    "start": "270479",
    "end": "273280"
  },
  {
    "text": "the block array type is the backbone of",
    "start": "273360",
    "end": "276000"
  },
  {
    "text": "nums",
    "start": "276000",
    "end": "277680"
  },
  {
    "text": "it provides an implementation of all",
    "start": "277680",
    "end": "279840"
  },
  {
    "text": "array operations in terms of blocks",
    "start": "279840",
    "end": "282960"
  },
  {
    "text": "a block array has a shape which carries",
    "start": "282960",
    "end": "285360"
  },
  {
    "text": "the same meaning",
    "start": "285360",
    "end": "286160"
  },
  {
    "text": "as a numpy and d array shape",
    "start": "286160",
    "end": "289199"
  },
  {
    "text": "here we present the block that has shape",
    "start": "289199",
    "end": "291120"
  },
  {
    "text": "four by six",
    "start": "291120",
    "end": "292800"
  },
  {
    "text": "each cell in this table specifies the",
    "start": "292800",
    "end": "294880"
  },
  {
    "text": "array index",
    "start": "294880",
    "end": "296080"
  },
  {
    "text": "used to access the corresponding value",
    "start": "296080",
    "end": "298080"
  },
  {
    "text": "within the array",
    "start": "298080",
    "end": "300879"
  },
  {
    "text": "the larger cells in this table denote",
    "start": "301039",
    "end": "303120"
  },
  {
    "text": "the block partitioning of the array",
    "start": "303120",
    "end": "305520"
  },
  {
    "text": "the block shape property indicates the",
    "start": "305520",
    "end": "307600"
  },
  {
    "text": "shape of each block",
    "start": "307600",
    "end": "309520"
  },
  {
    "text": "in this case the block shape is given as",
    "start": "309520",
    "end": "312080"
  },
  {
    "text": "two by two",
    "start": "312080",
    "end": "313600"
  },
  {
    "text": "thus nums will try to partition the",
    "start": "313600",
    "end": "315840"
  },
  {
    "text": "array blocks",
    "start": "315840",
    "end": "316960"
  },
  {
    "text": "into shapes of two by two we may end up",
    "start": "316960",
    "end": "320479"
  },
  {
    "text": "with blocks that have fewer entries in",
    "start": "320479",
    "end": "322160"
  },
  {
    "text": "the specified block shape if the array",
    "start": "322160",
    "end": "324080"
  },
  {
    "text": "shape is not divisible by the given",
    "start": "324080",
    "end": "326080"
  },
  {
    "text": "block shape",
    "start": "326080",
    "end": "328638"
  },
  {
    "text": "finally the grid shape of a block array",
    "start": "330000",
    "end": "332160"
  },
  {
    "text": "indicates the layout structure grid used",
    "start": "332160",
    "end": "334320"
  },
  {
    "text": "to organize blocks",
    "start": "334320",
    "end": "336160"
  },
  {
    "text": "the grid index or entry provided",
    "start": "336160",
    "end": "338479"
  },
  {
    "text": "provides a way to access blocks of array",
    "start": "338479",
    "end": "340800"
  },
  {
    "text": "elements within",
    "start": "340800",
    "end": "341759"
  },
  {
    "text": "a block array",
    "start": "341759",
    "end": "344479"
  },
  {
    "text": "to provide some context about the way",
    "start": "345759",
    "end": "347520"
  },
  {
    "text": "block arrays are constructed and",
    "start": "347520",
    "end": "349039"
  },
  {
    "text": "represented with",
    "start": "349039",
    "end": "350160"
  },
  {
    "text": "array back ends we provide a simplified",
    "start": "350160",
    "end": "352639"
  },
  {
    "text": "example",
    "start": "352639",
    "end": "353199"
  },
  {
    "text": "of a read operation in this example we",
    "start": "353199",
    "end": "356240"
  },
  {
    "text": "have",
    "start": "356240",
    "end": "356720"
  },
  {
    "text": "a two node ray cluster on which nums is",
    "start": "356720",
    "end": "359600"
  },
  {
    "text": "operating",
    "start": "359600",
    "end": "360880"
  },
  {
    "text": "now mass code executes on array driver",
    "start": "360880",
    "end": "364240"
  },
  {
    "text": "the read operation immediately generates",
    "start": "364240",
    "end": "366160"
  },
  {
    "text": "an object reference",
    "start": "366160",
    "end": "367520"
  },
  {
    "text": "so long as the object references are in",
    "start": "367520",
    "end": "369919"
  },
  {
    "text": "scope ray will ensure",
    "start": "369919",
    "end": "371440"
  },
  {
    "text": "the object associated with the reference",
    "start": "371440",
    "end": "373520"
  },
  {
    "text": "remains in at least",
    "start": "373520",
    "end": "374639"
  },
  {
    "text": "one store the data in s3",
    "start": "374639",
    "end": "378319"
  },
  {
    "text": "is two-dimensional and is partitioned",
    "start": "378319",
    "end": "380240"
  },
  {
    "text": "into two blocks along the first axis",
    "start": "380240",
    "end": "382800"
  },
  {
    "text": "and the s3 database is",
    "start": "382800",
    "end": "385840"
  },
  {
    "text": "denoted by the storage icon here",
    "start": "385840",
    "end": "390720"
  },
  {
    "text": "so to begin nums will issue a read rpc",
    "start": "390720",
    "end": "393919"
  },
  {
    "text": "on worker nodes",
    "start": "393919",
    "end": "396560"
  },
  {
    "text": "it then reads data from s3 in parallel",
    "start": "396560",
    "end": "399039"
  },
  {
    "text": "and caches the data locally on each node",
    "start": "399039",
    "end": "403280"
  },
  {
    "text": "finally the returned object references",
    "start": "403280",
    "end": "405440"
  },
  {
    "text": "are referenced in the driver application",
    "start": "405440",
    "end": "408720"
  },
  {
    "text": "note again that so long as the object",
    "start": "408720",
    "end": "410479"
  },
  {
    "text": "references are referenced on the driver",
    "start": "410479",
    "end": "412240"
  },
  {
    "text": "node",
    "start": "412240",
    "end": "412880"
  },
  {
    "text": "the corresponding objects are guaranteed",
    "start": "412880",
    "end": "414960"
  },
  {
    "text": "to exist somewhere on the cluster",
    "start": "414960",
    "end": "417520"
  },
  {
    "text": "to demonstrate the nums api consider a",
    "start": "417520",
    "end": "420080"
  },
  {
    "text": "basic implementation of logistic",
    "start": "420080",
    "end": "422160"
  },
  {
    "text": "regression",
    "start": "422160",
    "end": "422960"
  },
  {
    "text": "optimized using newton's method",
    "start": "422960",
    "end": "426240"
  },
  {
    "text": "nums loads x and y and initializes beta",
    "start": "426240",
    "end": "429360"
  },
  {
    "text": "concurrently",
    "start": "429360",
    "end": "430160"
  },
  {
    "text": "as block partitioned arrays",
    "start": "430160",
    "end": "433680"
  },
  {
    "text": "the block of code highlighted executes",
    "start": "433680",
    "end": "435840"
  },
  {
    "text": "in parallel",
    "start": "435840",
    "end": "437440"
  },
  {
    "text": "all operations are executed block wise",
    "start": "437440",
    "end": "440000"
  },
  {
    "text": "providing",
    "start": "440000",
    "end": "440720"
  },
  {
    "text": "intra as well as inter operation",
    "start": "440720",
    "end": "442639"
  },
  {
    "text": "parallelism",
    "start": "442639",
    "end": "445360"
  },
  {
    "text": "the termination condition is executed",
    "start": "445520",
    "end": "447840"
  },
  {
    "text": "concurrently as well here",
    "start": "447840",
    "end": "450319"
  },
  {
    "text": "the driver process blocks until the",
    "start": "450319",
    "end": "452319"
  },
  {
    "text": "resulting boolean value is evaluated",
    "start": "452319",
    "end": "455360"
  },
  {
    "text": "allowing the driver process to branch we",
    "start": "455360",
    "end": "458560"
  },
  {
    "text": "note here that",
    "start": "458560",
    "end": "459520"
  },
  {
    "text": "while this expression blocks it only",
    "start": "459520",
    "end": "461840"
  },
  {
    "text": "depends on g",
    "start": "461840",
    "end": "463520"
  },
  {
    "text": "not mu h or beta as soon as a",
    "start": "463520",
    "end": "466800"
  },
  {
    "text": "termination condition is evaluated",
    "start": "466800",
    "end": "468879"
  },
  {
    "text": "the next loop executes providing partial",
    "start": "468879",
    "end": "471520"
  },
  {
    "text": "parallelism between independent",
    "start": "471520",
    "end": "472960"
  },
  {
    "text": "operations between",
    "start": "472960",
    "end": "474560"
  },
  {
    "text": "each instance of the loop",
    "start": "474560",
    "end": "478639"
  },
  {
    "text": "finally to solve the third and final",
    "start": "478639",
    "end": "480560"
  },
  {
    "text": "problem we design a novel scheduler",
    "start": "480560",
    "end": "482960"
  },
  {
    "text": "called cyclic random tree search",
    "start": "482960",
    "end": "485039"
  },
  {
    "text": "abbreviated as",
    "start": "485039",
    "end": "486319"
  },
  {
    "text": "crts throughout the rest of the talk",
    "start": "486319",
    "end": "490000"
  },
  {
    "text": "crts combines a traditional block cyclic",
    "start": "490000",
    "end": "492479"
  },
  {
    "text": "data layout with an objective based",
    "start": "492479",
    "end": "494319"
  },
  {
    "text": "operation scheduler",
    "start": "494319",
    "end": "497520"
  },
  {
    "text": "the block cyclic data layout used in",
    "start": "498080",
    "end": "500080"
  },
  {
    "text": "crts can be described as follows",
    "start": "500080",
    "end": "504080"
  },
  {
    "text": "we represent n-dimensional arrays as",
    "start": "504400",
    "end": "506560"
  },
  {
    "text": "structured grids of blocks as previously",
    "start": "506560",
    "end": "508800"
  },
  {
    "text": "defined",
    "start": "508800",
    "end": "510960"
  },
  {
    "text": "we additionally represent a cluster as a",
    "start": "510960",
    "end": "513360"
  },
  {
    "text": "structured grid of nodes",
    "start": "513360",
    "end": "516479"
  },
  {
    "text": "we then determine the node on which each",
    "start": "516479",
    "end": "518479"
  },
  {
    "text": "block resides by cycling",
    "start": "518479",
    "end": "520000"
  },
  {
    "text": "over available nodes along each axis",
    "start": "520000",
    "end": "523919"
  },
  {
    "text": "this design strikes a balance between",
    "start": "523919",
    "end": "526000"
  },
  {
    "text": "data load and data locality",
    "start": "526000",
    "end": "527920"
  },
  {
    "text": "which provides a solution for zero",
    "start": "527920",
    "end": "530160"
  },
  {
    "text": "communication",
    "start": "530160",
    "end": "531040"
  },
  {
    "text": "element-wise operations and enhance that",
    "start": "531040",
    "end": "533600"
  },
  {
    "text": "locality for basic linear",
    "start": "533600",
    "end": "535120"
  },
  {
    "text": "algebra operations",
    "start": "535120",
    "end": "538240"
  },
  {
    "text": "we now turn to a description of our",
    "start": "539200",
    "end": "541200"
  },
  {
    "text": "scheduling optimizer",
    "start": "541200",
    "end": "543920"
  },
  {
    "text": "our optimizer is comprised of four",
    "start": "543920",
    "end": "545839"
  },
  {
    "text": "primary components first",
    "start": "545839",
    "end": "548560"
  },
  {
    "text": "we have a cluster state which is used to",
    "start": "548560",
    "end": "551440"
  },
  {
    "text": "estimate memory and network load on each",
    "start": "551440",
    "end": "553440"
  },
  {
    "text": "node by using the size of",
    "start": "553440",
    "end": "555440"
  },
  {
    "text": "every array second we have",
    "start": "555440",
    "end": "558720"
  },
  {
    "text": "an objective which places operations to",
    "start": "558720",
    "end": "562240"
  },
  {
    "text": "minimize maximum memory load",
    "start": "562240",
    "end": "563920"
  },
  {
    "text": "and network load over all nodes this is",
    "start": "563920",
    "end": "566720"
  },
  {
    "text": "very similar",
    "start": "566720",
    "end": "567519"
  },
  {
    "text": "to the objective of traditional load",
    "start": "567519",
    "end": "569440"
  },
  {
    "text": "balancing",
    "start": "569440",
    "end": "571279"
  },
  {
    "text": "third we have a computation state which",
    "start": "571279",
    "end": "574480"
  },
  {
    "text": "is represented as an array",
    "start": "574480",
    "end": "576000"
  },
  {
    "text": "of graphs data structure on which we",
    "start": "576000",
    "end": "577839"
  },
  {
    "text": "perform the computations",
    "start": "577839",
    "end": "579920"
  },
  {
    "text": "this is the graph array mentioned",
    "start": "579920",
    "end": "581760"
  },
  {
    "text": "previously",
    "start": "581760",
    "end": "584080"
  },
  {
    "text": "finally we have cyclic random tree",
    "start": "584080",
    "end": "586000"
  },
  {
    "text": "search or crts",
    "start": "586000",
    "end": "587680"
  },
  {
    "text": "an iterative algorithm that places a",
    "start": "587680",
    "end": "590080"
  },
  {
    "text": "single operation per iteration according",
    "start": "590080",
    "end": "592160"
  },
  {
    "text": "to the objective and updates both the",
    "start": "592160",
    "end": "593920"
  },
  {
    "text": "cluster state and the computation state",
    "start": "593920",
    "end": "598000"
  },
  {
    "text": "this diagram illustrates the procedure",
    "start": "598800",
    "end": "600959"
  },
  {
    "text": "numbers carries out to optimize",
    "start": "600959",
    "end": "602880"
  },
  {
    "text": "placement of expensive operations we",
    "start": "602880",
    "end": "605920"
  },
  {
    "text": "first convert block arrays to arrays of",
    "start": "605920",
    "end": "607839"
  },
  {
    "text": "graphs",
    "start": "607839",
    "end": "608560"
  },
  {
    "text": "called graph arrays consisting of a",
    "start": "608560",
    "end": "610560"
  },
  {
    "text": "single leaf node",
    "start": "610560",
    "end": "611680"
  },
  {
    "text": "denoted as circles",
    "start": "611680",
    "end": "615040"
  },
  {
    "text": "operations are performed on collections",
    "start": "615279",
    "end": "617440"
  },
  {
    "text": "of graph arrays",
    "start": "617440",
    "end": "618399"
  },
  {
    "text": "growing the computation graph within the",
    "start": "618399",
    "end": "620399"
  },
  {
    "text": "output graph array",
    "start": "620399",
    "end": "623279"
  },
  {
    "text": "the optimizer then schedules",
    "start": "623279",
    "end": "624959"
  },
  {
    "text": "computations on nodes according to our",
    "start": "624959",
    "end": "627200"
  },
  {
    "text": "objective",
    "start": "627200",
    "end": "628240"
  },
  {
    "text": "which minimizes maximum memory and",
    "start": "628240",
    "end": "630160"
  },
  {
    "text": "network load overall nodes",
    "start": "630160",
    "end": "633440"
  },
  {
    "text": "the resulting graph array consisting of",
    "start": "633440",
    "end": "635440"
  },
  {
    "text": "leafs is converted back to",
    "start": "635440",
    "end": "637279"
  },
  {
    "text": "a block array",
    "start": "637279",
    "end": "640079"
  },
  {
    "text": "digging deeper into the optimizer itself",
    "start": "641440",
    "end": "643839"
  },
  {
    "text": "consider a tensor dot",
    "start": "643839",
    "end": "645519"
  },
  {
    "text": "between two matrices a and b",
    "start": "645519",
    "end": "649200"
  },
  {
    "text": "the operation has three representations",
    "start": "649200",
    "end": "651760"
  },
  {
    "text": "it has the syntactic representation",
    "start": "651760",
    "end": "654880"
  },
  {
    "text": "it also has a block array representation",
    "start": "654880",
    "end": "657519"
  },
  {
    "text": "which decomposes the arrays",
    "start": "657519",
    "end": "659200"
  },
  {
    "text": "in two blocks and finally the graph",
    "start": "659200",
    "end": "662000"
  },
  {
    "text": "array representation which represents",
    "start": "662000",
    "end": "664079"
  },
  {
    "text": "the tensor dot operation",
    "start": "664079",
    "end": "665440"
  },
  {
    "text": "as a computation graph with frontier",
    "start": "665440",
    "end": "667519"
  },
  {
    "text": "nodes",
    "start": "667519",
    "end": "669279"
  },
  {
    "text": "frontier nodes are nodes on which",
    "start": "669279",
    "end": "671040"
  },
  {
    "text": "operations can be performed",
    "start": "671040",
    "end": "675279"
  },
  {
    "text": "the optimizer proceeds by randomly",
    "start": "675279",
    "end": "677279"
  },
  {
    "text": "sampling a frontier node",
    "start": "677279",
    "end": "679440"
  },
  {
    "text": "the sampled frontier node is then",
    "start": "679440",
    "end": "681120"
  },
  {
    "text": "scheduled on a cluster device",
    "start": "681120",
    "end": "684160"
  },
  {
    "text": "we sample to minimize the cost of",
    "start": "684160",
    "end": "685920"
  },
  {
    "text": "running the optimizer at runtime",
    "start": "685920",
    "end": "688000"
  },
  {
    "text": "and reduce the likelihood of scheduling",
    "start": "688000",
    "end": "689680"
  },
  {
    "text": "inefficiencies due to deterministic",
    "start": "689680",
    "end": "691600"
  },
  {
    "text": "enumeration of frontier nodes",
    "start": "691600",
    "end": "695199"
  },
  {
    "text": "the optimizer schedules the operation on",
    "start": "696399",
    "end": "698560"
  },
  {
    "text": "the device that minimizes maximum",
    "start": "698560",
    "end": "700320"
  },
  {
    "text": "network load and memory load on the",
    "start": "700320",
    "end": "702160"
  },
  {
    "text": "cluster",
    "start": "702160",
    "end": "703519"
  },
  {
    "text": "and this behavior is captured by the",
    "start": "703519",
    "end": "706560"
  },
  {
    "text": "objective",
    "start": "706560",
    "end": "707440"
  },
  {
    "text": "which we have here the objective",
    "start": "707440",
    "end": "710560"
  },
  {
    "text": "quantifies the cost of scheduling",
    "start": "710560",
    "end": "712079"
  },
  {
    "text": "decision i",
    "start": "712079",
    "end": "712880"
  },
  {
    "text": "from cluster state s in this example",
    "start": "712880",
    "end": "716160"
  },
  {
    "text": "the optimal choice is to schedule on",
    "start": "716160",
    "end": "718320"
  },
  {
    "text": "device 1.",
    "start": "718320",
    "end": "720079"
  },
  {
    "text": "looking closer at the objective we see",
    "start": "720079",
    "end": "723519"
  },
  {
    "text": "that",
    "start": "723519",
    "end": "724079"
  },
  {
    "text": "m is the vector of memory load on each",
    "start": "724079",
    "end": "726560"
  },
  {
    "text": "node",
    "start": "726560",
    "end": "727519"
  },
  {
    "text": "i is a vector of input load on each node",
    "start": "727519",
    "end": "730560"
  },
  {
    "text": "and o is a vector of output load on each",
    "start": "730560",
    "end": "733200"
  },
  {
    "text": "node",
    "start": "733200",
    "end": "734240"
  },
  {
    "text": "the infinity norm computes a maximum",
    "start": "734240",
    "end": "736399"
  },
  {
    "text": "value of a vector",
    "start": "736399",
    "end": "738160"
  },
  {
    "text": "so what we're really doing here is just",
    "start": "738160",
    "end": "740160"
  },
  {
    "text": "computing the",
    "start": "740160",
    "end": "741360"
  },
  {
    "text": "maximum value of each of these vectors",
    "start": "741360",
    "end": "743839"
  },
  {
    "text": "and summing them up",
    "start": "743839",
    "end": "746800"
  },
  {
    "text": "we now turn to the result of our",
    "start": "747440",
    "end": "748959"
  },
  {
    "text": "empirical analysis of nums",
    "start": "748959",
    "end": "752240"
  },
  {
    "text": "to begin we ask whether crts improves",
    "start": "752240",
    "end": "756839"
  },
  {
    "text": "performance",
    "start": "756839",
    "end": "758079"
  },
  {
    "text": "plot shows memory and network",
    "start": "758079",
    "end": "761200"
  },
  {
    "text": "load collected over the training of the",
    "start": "761200",
    "end": "763440"
  },
  {
    "text": "same logistic regression model",
    "start": "763440",
    "end": "766079"
  },
  {
    "text": "each column of plots corresponds to a",
    "start": "766079",
    "end": "768240"
  },
  {
    "text": "different scheduler",
    "start": "768240",
    "end": "769760"
  },
  {
    "text": "and each line in each plot corresponds",
    "start": "769760",
    "end": "771839"
  },
  {
    "text": "to the load of each node over time",
    "start": "771839",
    "end": "775040"
  },
  {
    "text": "the first is ray's default scheduler",
    "start": "775040",
    "end": "777040"
  },
  {
    "text": "which does well to maintain data",
    "start": "777040",
    "end": "778560"
  },
  {
    "text": "locality",
    "start": "778560",
    "end": "780079"
  },
  {
    "text": "second we use a block cyclic data layout",
    "start": "780079",
    "end": "782240"
  },
  {
    "text": "for basic linear algebra operations",
    "start": "782240",
    "end": "785839"
  },
  {
    "text": "fails under certain circumstances and",
    "start": "785839",
    "end": "788079"
  },
  {
    "text": "causes an imbalance in memory and",
    "start": "788079",
    "end": "789839"
  },
  {
    "text": "network load per node",
    "start": "789839",
    "end": "792160"
  },
  {
    "text": "finally crts is able to balance both",
    "start": "792160",
    "end": "794320"
  },
  {
    "text": "memory and network load",
    "start": "794320",
    "end": "795839"
  },
  {
    "text": "as is evident by the clustering of line",
    "start": "795839",
    "end": "797839"
  },
  {
    "text": "plots over time the memory load we do",
    "start": "797839",
    "end": "801200"
  },
  {
    "text": "see in crts is due to the data set and",
    "start": "801200",
    "end": "803760"
  },
  {
    "text": "the output",
    "start": "803760",
    "end": "804399"
  },
  {
    "text": "of rpcs the high network in at the",
    "start": "804399",
    "end": "807760"
  },
  {
    "text": "beginning of the computation is data",
    "start": "807760",
    "end": "809760"
  },
  {
    "text": "being read in from s3",
    "start": "809760",
    "end": "811519"
  },
  {
    "text": "which decreases slowly as the",
    "start": "811519",
    "end": "813120"
  },
  {
    "text": "computation reaches its end",
    "start": "813120",
    "end": "816560"
  },
  {
    "text": "we show here the execution time in",
    "start": "817120",
    "end": "819199"
  },
  {
    "text": "seconds of the various scheduling",
    "start": "819199",
    "end": "820720"
  },
  {
    "text": "algorithms we tested",
    "start": "820720",
    "end": "822880"
  },
  {
    "text": "the only scheduler that can scale to one",
    "start": "822880",
    "end": "824880"
  },
  {
    "text": "terabyte for this specific workload",
    "start": "824880",
    "end": "827199"
  },
  {
    "text": "on these specific resources is crts",
    "start": "827199",
    "end": "832160"
  },
  {
    "text": "next we answer the question how well",
    "start": "832639",
    "end": "834720"
  },
  {
    "text": "does nums scale",
    "start": "834720",
    "end": "837680"
  },
  {
    "text": "all the experiments we perform in this",
    "start": "837680",
    "end": "839920"
  },
  {
    "text": "section are",
    "start": "839920",
    "end": "840959"
  },
  {
    "text": "weak scaling experiments we showed that",
    "start": "840959",
    "end": "843199"
  },
  {
    "text": "nums scales perfectly",
    "start": "843199",
    "end": "844720"
  },
  {
    "text": "all the element-wise operations that can",
    "start": "844720",
    "end": "846639"
  },
  {
    "text": "be found in the numpy",
    "start": "846639",
    "end": "848399"
  },
  {
    "text": "api this is due to our use of the block",
    "start": "848399",
    "end": "851920"
  },
  {
    "text": "cyclic data layout",
    "start": "851920",
    "end": "854320"
  },
  {
    "text": "for this experiment we double the amount",
    "start": "854320",
    "end": "856639"
  },
  {
    "text": "of work and number of workers",
    "start": "856639",
    "end": "858320"
  },
  {
    "text": "until 512 cores on 16 nodes",
    "start": "858320",
    "end": "861519"
  },
  {
    "text": "are used also nums exhibits similar",
    "start": "861519",
    "end": "865199"
  },
  {
    "text": "scaling properties for",
    "start": "865199",
    "end": "866639"
  },
  {
    "text": "data sampling we also provide scaling",
    "start": "866639",
    "end": "869360"
  },
  {
    "text": "results for two major algorithms",
    "start": "869360",
    "end": "871360"
  },
  {
    "text": "logistic regression and qr decomposition",
    "start": "871360",
    "end": "874959"
  },
  {
    "text": "on the left we measure the throughput of",
    "start": "874959",
    "end": "876959"
  },
  {
    "text": "10 iterations of logistic regression",
    "start": "876959",
    "end": "880079"
  },
  {
    "text": "we scale near perfectly until 16 nodes",
    "start": "880079",
    "end": "883360"
  },
  {
    "text": "at 16 nodes the cost of multiple",
    "start": "883360",
    "end": "885519"
  },
  {
    "text": "reduction operations at 2.5 gigabytes",
    "start": "885519",
    "end": "887839"
  },
  {
    "text": "per second",
    "start": "887839",
    "end": "888480"
  },
  {
    "text": "decreases throughput on the right our",
    "start": "888480",
    "end": "891600"
  },
  {
    "text": "implementation of qr decomposition",
    "start": "891600",
    "end": "893839"
  },
  {
    "text": "scales near perfectly",
    "start": "893839",
    "end": "898079"
  },
  {
    "text": "next we experimentally show that numas",
    "start": "898079",
    "end": "900240"
  },
  {
    "text": "is competitive",
    "start": "900240",
    "end": "901199"
  },
  {
    "text": "and outperforms related solutions on",
    "start": "901199",
    "end": "903519"
  },
  {
    "text": "several key benchmarks",
    "start": "903519",
    "end": "906800"
  },
  {
    "text": "we compare our logistic regression and",
    "start": "907279",
    "end": "909600"
  },
  {
    "text": "qr decomposition",
    "start": "909600",
    "end": "911040"
  },
  {
    "text": "implementation to desks both",
    "start": "911040",
    "end": "914240"
  },
  {
    "text": "implementations use the same",
    "start": "914240",
    "end": "915839"
  },
  {
    "text": "algorithm the plot on the left shows",
    "start": "915839",
    "end": "918720"
  },
  {
    "text": "that our logistic regression",
    "start": "918720",
    "end": "919920"
  },
  {
    "text": "implementation can be up to 20 times",
    "start": "919920",
    "end": "921760"
  },
  {
    "text": "faster than desks",
    "start": "921760",
    "end": "923760"
  },
  {
    "text": "on the right rqr decomposition",
    "start": "923760",
    "end": "925839"
  },
  {
    "text": "implementation is competitive with desks",
    "start": "925839",
    "end": "928320"
  },
  {
    "text": "highly optimized implementation",
    "start": "928320",
    "end": "932560"
  },
  {
    "text": "we also compare our logistic regression",
    "start": "932880",
    "end": "935040"
  },
  {
    "text": "and qr decomposition implementation",
    "start": "935040",
    "end": "937759"
  },
  {
    "text": "to sparks ml lib spark's mlib",
    "start": "937759",
    "end": "941600"
  },
  {
    "text": "does not support the newton optimizer",
    "start": "941600",
    "end": "943440"
  },
  {
    "text": "for logistic regression",
    "start": "943440",
    "end": "944880"
  },
  {
    "text": "and its qr decomposition implementation",
    "start": "944880",
    "end": "947279"
  },
  {
    "text": "is different than desks",
    "start": "947279",
    "end": "949199"
  },
  {
    "text": "we therefore use a different set of",
    "start": "949199",
    "end": "951120"
  },
  {
    "text": "algorithms to provide a fair comparison",
    "start": "951120",
    "end": "953440"
  },
  {
    "text": "to spark's ml lib also",
    "start": "953440",
    "end": "956560"
  },
  {
    "text": "because sparks algorithms are sensitive",
    "start": "956560",
    "end": "958800"
  },
  {
    "text": "to the number of partitions",
    "start": "958800",
    "end": "960800"
  },
  {
    "text": "we tune the number of partitions for",
    "start": "960800",
    "end": "962560"
  },
  {
    "text": "each data set size to achieve the best",
    "start": "962560",
    "end": "964720"
  },
  {
    "text": "performance for both spark and",
    "start": "964720",
    "end": "966839"
  },
  {
    "text": "nums at one terabyte our logistic",
    "start": "966839",
    "end": "969839"
  },
  {
    "text": "regression and qr decomposition",
    "start": "969839",
    "end": "971600"
  },
  {
    "text": "implementations are two to three times",
    "start": "971600",
    "end": "973519"
  },
  {
    "text": "faster than sparks",
    "start": "973519",
    "end": "976560"
  },
  {
    "text": "next we answer the question can ms run",
    "start": "977040",
    "end": "979680"
  },
  {
    "text": "on",
    "start": "979680",
    "end": "980079"
  },
  {
    "text": "the gpu",
    "start": "980079",
    "end": "983759"
  },
  {
    "text": "here we show that namaste is able to run",
    "start": "983759",
    "end": "985839"
  },
  {
    "text": "on the gpu",
    "start": "985839",
    "end": "986800"
  },
  {
    "text": "with a re-implementation of the system",
    "start": "986800",
    "end": "989040"
  },
  {
    "text": "layer using coupei",
    "start": "989040",
    "end": "990320"
  },
  {
    "text": "and nvidia's collective communication",
    "start": "990320",
    "end": "992160"
  },
  {
    "text": "library",
    "start": "992160",
    "end": "994160"
  },
  {
    "text": "the same nums code provides a",
    "start": "994160",
    "end": "996000"
  },
  {
    "text": "significant speed up over coupei alone",
    "start": "996000",
    "end": "998399"
  },
  {
    "text": "and is able to scale to 40 gigabytes on",
    "start": "998399",
    "end": "1001120"
  },
  {
    "text": "two nodes",
    "start": "1001120",
    "end": "1003680"
  },
  {
    "text": "the results of this experiment show that",
    "start": "1004639",
    "end": "1006480"
  },
  {
    "text": "nums optimizer converges to synchronous",
    "start": "1006480",
    "end": "1009040"
  },
  {
    "text": "model and data parallelism",
    "start": "1009040",
    "end": "1010880"
  },
  {
    "text": "eliminating the need to write",
    "start": "1010880",
    "end": "1012160"
  },
  {
    "text": "specialized parallel algorithms to train",
    "start": "1012160",
    "end": "1014399"
  },
  {
    "text": "deep neural networks",
    "start": "1014399",
    "end": "1016880"
  },
  {
    "text": "both experiments are on the multi-layer",
    "start": "1016880",
    "end": "1018720"
  },
  {
    "text": "perceptron",
    "start": "1018720",
    "end": "1020320"
  },
  {
    "text": "in the model parallel case the hidden",
    "start": "1020320",
    "end": "1022240"
  },
  {
    "text": "layer size is increased and partitioned",
    "start": "1022240",
    "end": "1024400"
  },
  {
    "text": "into four blocks",
    "start": "1024400",
    "end": "1026240"
  },
  {
    "text": "any operations performed on the hidden",
    "start": "1026240",
    "end": "1028160"
  },
  {
    "text": "layer are then paralyzed",
    "start": "1028160",
    "end": "1031520"
  },
  {
    "text": "in the data parallel case data is",
    "start": "1031520",
    "end": "1033600"
  },
  {
    "text": "partitioned row-wise into four blocks",
    "start": "1033600",
    "end": "1036959"
  },
  {
    "text": "the model's hidden layer is smaller than",
    "start": "1036959",
    "end": "1038959"
  },
  {
    "text": "the data set size",
    "start": "1038959",
    "end": "1040160"
  },
  {
    "text": "so our crts scheduler broadcasts the",
    "start": "1040160",
    "end": "1042400"
  },
  {
    "text": "model to devices on which the blocks of",
    "start": "1042400",
    "end": "1044480"
  },
  {
    "text": "data are located",
    "start": "1044480",
    "end": "1046558"
  },
  {
    "text": "this achieves the ubiquitous synchronous",
    "start": "1046559",
    "end": "1048720"
  },
  {
    "text": "data parallel training procedure that is",
    "start": "1048720",
    "end": "1050640"
  },
  {
    "text": "often used to parallelize",
    "start": "1050640",
    "end": "1052000"
  },
  {
    "text": "deep neural networks trained with",
    "start": "1052000",
    "end": "1053760"
  },
  {
    "text": "stochastic gradient descent",
    "start": "1053760",
    "end": "1057120"
  },
  {
    "text": "finally we show that ms can be used to",
    "start": "1057600",
    "end": "1059600"
  },
  {
    "text": "solve real data science problems with an",
    "start": "1059600",
    "end": "1061840"
  },
  {
    "text": "end-to-end benchmark on the higgs boson",
    "start": "1061840",
    "end": "1063840"
  },
  {
    "text": "machine learning challenge",
    "start": "1063840",
    "end": "1066000"
  },
  {
    "text": "we compare panda's load time side kits",
    "start": "1066000",
    "end": "1068400"
  },
  {
    "text": "learn psychic learns",
    "start": "1068400",
    "end": "1069679"
  },
  {
    "text": "train time and psychic learns prediction",
    "start": "1069679",
    "end": "1072000"
  },
  {
    "text": "time to numb",
    "start": "1072000",
    "end": "1072960"
  },
  {
    "text": "s's we show an overall 7x speed up on a",
    "start": "1072960",
    "end": "1076480"
  },
  {
    "text": "single node",
    "start": "1076480",
    "end": "1077200"
  },
  {
    "text": "and 10x meetup on two nodes",
    "start": "1077200",
    "end": "1081840"
  },
  {
    "text": "that covers all of our experiments and",
    "start": "1081919",
    "end": "1084400"
  },
  {
    "text": "here we'll just",
    "start": "1084400",
    "end": "1086080"
  },
  {
    "text": "show how you can use nums you can simply",
    "start": "1086080",
    "end": "1089600"
  },
  {
    "text": "run pip install nums and nums has been",
    "start": "1089600",
    "end": "1093120"
  },
  {
    "text": "tested on python 3.7",
    "start": "1093120",
    "end": "1095280"
  },
  {
    "text": "3.8 and 3.1 3.9",
    "start": "1095280",
    "end": "1099200"
  },
  {
    "text": "nums runs on the latest versions of red",
    "start": "1099200",
    "end": "1102240"
  },
  {
    "text": "and that's 1.3 as of this talk",
    "start": "1102240",
    "end": "1105840"
  },
  {
    "text": "and it also runs on windows",
    "start": "1105840",
    "end": "1109039"
  },
  {
    "text": "some of the features of nums include",
    "start": "1109039",
    "end": "1110960"
  },
  {
    "text": "full support for",
    "start": "1110960",
    "end": "1112080"
  },
  {
    "text": "array assignment broadcasting and basic",
    "start": "1112080",
    "end": "1114480"
  },
  {
    "text": "operations",
    "start": "1114480",
    "end": "1115840"
  },
  {
    "text": "i o support for distributed file systems",
    "start": "1115840",
    "end": "1118320"
  },
  {
    "text": "s3",
    "start": "1118320",
    "end": "1118880"
  },
  {
    "text": "and csv files prepackaged support for",
    "start": "1118880",
    "end": "1122160"
  },
  {
    "text": "generalized linear models experimental",
    "start": "1122160",
    "end": "1125679"
  },
  {
    "text": "integration with moden which is a data",
    "start": "1125679",
    "end": "1127679"
  },
  {
    "text": "frames project",
    "start": "1127679",
    "end": "1128720"
  },
  {
    "text": "and xg boost which is a tree based",
    "start": "1128720",
    "end": "1130720"
  },
  {
    "text": "models project",
    "start": "1130720",
    "end": "1133200"
  },
  {
    "text": "and we're continuously updating the",
    "start": "1133200",
    "end": "1135520"
  },
  {
    "text": "numpy api",
    "start": "1135520",
    "end": "1137280"
  },
  {
    "text": "and we have several contributions from",
    "start": "1137280",
    "end": "1139919"
  },
  {
    "text": "several great berkeley undergrads",
    "start": "1139919",
    "end": "1143759"
  },
  {
    "text": "for future work we are hoping to",
    "start": "1145039",
    "end": "1147280"
  },
  {
    "text": "integrate our research on gpu support",
    "start": "1147280",
    "end": "1150640"
  },
  {
    "text": "add support for sparse arrays continue",
    "start": "1150640",
    "end": "1154000"
  },
  {
    "text": "improving memory and runtime performance",
    "start": "1154000",
    "end": "1156640"
  },
  {
    "text": "and of course continuing to expand the",
    "start": "1156640",
    "end": "1158720"
  },
  {
    "text": "api coverage",
    "start": "1158720",
    "end": "1160240"
  },
  {
    "text": "and continuing continuing to add support",
    "start": "1160240",
    "end": "1162640"
  },
  {
    "text": "for linear algebra and machine learning",
    "start": "1162640",
    "end": "1165760"
  },
  {
    "text": "this includes lu decomposition chelsea",
    "start": "1165760",
    "end": "1168880"
  },
  {
    "text": "decomposition",
    "start": "1168880",
    "end": "1169679"
  },
  {
    "text": "matrix inversion and multi-class",
    "start": "1169679",
    "end": "1172000"
  },
  {
    "text": "logistic regression which are all",
    "start": "1172000",
    "end": "1173679"
  },
  {
    "text": "currently in the works",
    "start": "1173679",
    "end": "1176720"
  },
  {
    "text": "and that concludes my talk and thank you",
    "start": "1176720",
    "end": "1180160"
  },
  {
    "text": "please feel free to email me or anyone",
    "start": "1180160",
    "end": "1182559"
  },
  {
    "text": "on the nums team with questions",
    "start": "1182559",
    "end": "1189600"
  }
]
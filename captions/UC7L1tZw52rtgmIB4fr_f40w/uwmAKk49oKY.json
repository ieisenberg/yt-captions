[
  {
    "start": "0",
    "end": "39000"
  },
  {
    "text": "okay thanks so much for coming out",
    "start": "60",
    "end": "2010"
  },
  {
    "text": "tonight can you all hear me okay Sam I",
    "start": "2010",
    "end": "4259"
  },
  {
    "text": "good okay not that good it's not that",
    "start": "4259",
    "end": "7230"
  },
  {
    "text": "good I said better okay I'll do my",
    "start": "7230",
    "end": "12330"
  },
  {
    "text": "stand-up routine this week I'm Dean",
    "start": "12330",
    "end": "15210"
  },
  {
    "text": "waffler I joined any scale in November",
    "start": "15210",
    "end": "17820"
  },
  {
    "text": "so I didn't make the first two meet ups",
    "start": "17820",
    "end": "19740"
  },
  {
    "text": "this is the third how many of you have",
    "start": "19740",
    "end": "21630"
  },
  {
    "text": "been to all three meet ups okay we're",
    "start": "21630",
    "end": "24359"
  },
  {
    "text": "gonna give out perfect attendance pins",
    "start": "24359",
    "end": "25920"
  },
  {
    "text": "at the end if you stick around how many",
    "start": "25920",
    "end": "28230"
  },
  {
    "text": "of you are here for the first time oh",
    "start": "28230",
    "end": "30019"
  },
  {
    "text": "great okay that's really exciting if you",
    "start": "30019",
    "end": "33960"
  },
  {
    "text": "want to complain you can send me email",
    "start": "33960",
    "end": "36210"
  },
  {
    "text": "or Twitter here just in case you're new",
    "start": "36210",
    "end": "41280"
  },
  {
    "start": "39000",
    "end": "112000"
  },
  {
    "text": "to Rea just a quick well what is it kind",
    "start": "41280",
    "end": "43920"
  },
  {
    "text": "of thing sarey is a system for basically",
    "start": "43920",
    "end": "48329"
  },
  {
    "text": "a library really for distributing Python",
    "start": "48329",
    "end": "50700"
  },
  {
    "text": "applications across a cluster with",
    "start": "50700",
    "end": "53520"
  },
  {
    "text": "minimal pain minimal tears we all know",
    "start": "53520",
    "end": "56340"
  },
  {
    "text": "that python has limitations about",
    "start": "56340",
    "end": "57989"
  },
  {
    "text": "concurrency and so forth and rays",
    "start": "57989",
    "end": "60449"
  },
  {
    "text": "designed to make it really easy to break",
    "start": "60449",
    "end": "62190"
  },
  {
    "text": "past those barriers and scale",
    "start": "62190",
    "end": "63780"
  },
  {
    "text": "arbitrarily far as you need to for you",
    "start": "63780",
    "end": "67049"
  },
  {
    "text": "know very high performance high compute",
    "start": "67049",
    "end": "69390"
  },
  {
    "text": "kind of jobs like reinforcement learning",
    "start": "69390",
    "end": "71070"
  },
  {
    "text": "hyper parameter tuning and that kind of",
    "start": "71070",
    "end": "73290"
  },
  {
    "text": "stuff and so some of the libraries have",
    "start": "73290",
    "end": "75060"
  },
  {
    "text": "been written on top of Ray that are part",
    "start": "75060",
    "end": "77189"
  },
  {
    "text": "of the Ray package include a re Lib for",
    "start": "77189",
    "end": "79860"
  },
  {
    "text": "reinforcement learning tuned for hyper",
    "start": "79860",
    "end": "82530"
  },
  {
    "text": "parameter tuning actually how many of",
    "start": "82530",
    "end": "84030"
  },
  {
    "text": "you are playing around with aural live",
    "start": "84030",
    "end": "86189"
  },
  {
    "text": "already",
    "start": "86189",
    "end": "86869"
  },
  {
    "text": "how about tuned how about Ray itself",
    "start": "86869",
    "end": "91049"
  },
  {
    "text": "maybe none of the okay",
    "start": "91049",
    "end": "92490"
  },
  {
    "text": "how many of you don't even know how to",
    "start": "92490",
    "end": "94020"
  },
  {
    "text": "spell ray all right good",
    "start": "94020",
    "end": "97829"
  },
  {
    "text": "there's a new one that we're gonna hear",
    "start": "97829",
    "end": "99509"
  },
  {
    "text": "about tonight called serve and there's a",
    "start": "99509",
    "end": "102509"
  },
  {
    "text": "project at Berkeley that's a dataframe",
    "start": "102509",
    "end": "104549"
  },
  {
    "text": "on Ray kind of project called modin and",
    "start": "104549",
    "end": "107220"
  },
  {
    "text": "then there's a bunch of other things",
    "start": "107220",
    "end": "108720"
  },
  {
    "text": "people have been working on and hope",
    "start": "108720",
    "end": "110009"
  },
  {
    "text": "you'll hear about some of those tonight",
    "start": "110009",
    "end": "112729"
  },
  {
    "start": "112000",
    "end": "183000"
  },
  {
    "text": "if you'd like to get involved and I'm",
    "start": "112729",
    "end": "115020"
  },
  {
    "text": "gonna put these slides somewhere and",
    "start": "115020",
    "end": "116939"
  },
  {
    "text": "post a comment to the meetup so you",
    "start": "116939",
    "end": "119130"
  },
  {
    "text": "don't have to you know memorize this",
    "start": "119130",
    "end": "121740"
  },
  {
    "text": "list we've got a slack channel Google",
    "start": "121740",
    "end": "123930"
  },
  {
    "text": "Group you know homepage you can go you",
    "start": "123930",
    "end": "127380"
  },
  {
    "text": "know download the code on github for kit",
    "start": "127380",
    "end": "129090"
  },
  {
    "text": "whatever any scale is the company that",
    "start": "129090",
    "end": "131129"
  },
  {
    "text": "is",
    "start": "131129",
    "end": "132150"
  },
  {
    "text": "you know basically developing right now",
    "start": "132150",
    "end": "134250"
  },
  {
    "text": "it has spun out of Berkeley if you can",
    "start": "134250",
    "end": "137040"
  },
  {
    "text": "tweet storm the interwebs a couple of",
    "start": "137040",
    "end": "139710"
  },
  {
    "text": "Twitter accounts but if you don't know",
    "start": "139710",
    "end": "142350"
  },
  {
    "text": "anything else after tonight make sure",
    "start": "142350",
    "end": "144420"
  },
  {
    "text": "you register for Rey summit that's",
    "start": "144420",
    "end": "146820"
  },
  {
    "text": "coming up May 27 and 28 the call for",
    "start": "146820",
    "end": "151500"
  },
  {
    "text": "proposals closes tomorrow but if you",
    "start": "151500",
    "end": "153360"
  },
  {
    "text": "want to put in something and can't get",
    "start": "153360",
    "end": "154860"
  },
  {
    "text": "it in then just once again you know",
    "start": "154860",
    "end": "156540"
  },
  {
    "text": "spammy on the Internet",
    "start": "156540",
    "end": "158910"
  },
  {
    "text": "and it's really cheap like right now",
    "start": "158910",
    "end": "160890"
  },
  {
    "text": "it's only 350 bucks for the you know a",
    "start": "160890",
    "end": "163440"
  },
  {
    "text": "day of tutorials in a day of keynotes",
    "start": "163440",
    "end": "165300"
  },
  {
    "text": "and talks and that I think lasts for",
    "start": "165300",
    "end": "168840"
  },
  {
    "text": "another two months or so that early bird",
    "start": "168840",
    "end": "170400"
  },
  {
    "text": "price but you can see some of the key",
    "start": "170400",
    "end": "172230"
  },
  {
    "text": "notice we've got already we're really",
    "start": "172230",
    "end": "173550"
  },
  {
    "text": "proud of some of the people we've been",
    "start": "173550",
    "end": "175260"
  },
  {
    "text": "able to get out and I hope you'll hope",
    "start": "175260",
    "end": "178800"
  },
  {
    "text": "you'll join us it'll be downtown here in",
    "start": "178800",
    "end": "180630"
  },
  {
    "text": "San Francisco at the Hyatt I guess okay",
    "start": "180630",
    "end": "184950"
  },
  {
    "start": "183000",
    "end": "257000"
  },
  {
    "text": "so here's the schedule tonight actually",
    "start": "184950",
    "end": "187140"
  },
  {
    "text": "first while I think about it just some",
    "start": "187140",
    "end": "188670"
  },
  {
    "text": "administrivia if you need the restroom",
    "start": "188670",
    "end": "190709"
  },
  {
    "text": "there down the hall here are the signs",
    "start": "190709",
    "end": "192300"
  },
  {
    "text": "on the pillars if it you know let's keep",
    "start": "192300",
    "end": "194850"
  },
  {
    "text": "it informal if you feel pangs of hunger",
    "start": "194850",
    "end": "197190"
  },
  {
    "text": "or pangs of thirst you know where to go",
    "start": "197190",
    "end": "199860"
  },
  {
    "text": "I'll feel free to do that although we",
    "start": "199860",
    "end": "201780"
  },
  {
    "text": "will take sort of quick breaks between",
    "start": "201780",
    "end": "203280"
  },
  {
    "text": "each talk to sit each one up so you can",
    "start": "203280",
    "end": "206730"
  },
  {
    "text": "hold elf if you want but anyway I hope",
    "start": "206730",
    "end": "209519"
  },
  {
    "text": "you all just did networking pizza and",
    "start": "209519",
    "end": "211260"
  },
  {
    "text": "drinks in that order right now we're",
    "start": "211260",
    "end": "213900"
  },
  {
    "text": "going to have a talk by Edward Oakes",
    "start": "213900",
    "end": "215220"
  },
  {
    "text": "he's one of the engineers from Annie",
    "start": "215220",
    "end": "218340"
  },
  {
    "text": "scale and he's going to talk about some",
    "start": "218340",
    "end": "220110"
  },
  {
    "text": "of the cool things we've done to",
    "start": "220110",
    "end": "221310"
  },
  {
    "text": "re-architect raise internals for much",
    "start": "221310",
    "end": "224010"
  },
  {
    "text": "better performance then Michelangelo",
    "start": "224010",
    "end": "226790"
  },
  {
    "text": "copper all a from lament is going to",
    "start": "226790",
    "end": "229500"
  },
  {
    "text": "talk to us about how they're using ray",
    "start": "229500",
    "end": "231030"
  },
  {
    "text": "to scale experiments eddy Palencia from",
    "start": "231030",
    "end": "235290"
  },
  {
    "text": "Microsoft is going to talk about what",
    "start": "235290",
    "end": "236880"
  },
  {
    "text": "they're doing with array and RL Lib then",
    "start": "236880",
    "end": "239400"
  },
  {
    "text": "Simon Moe from any scale is going to",
    "start": "239400",
    "end": "241320"
  },
  {
    "text": "talk about this new race serve module",
    "start": "241320",
    "end": "243239"
  },
  {
    "text": "and then general carousing and so forth",
    "start": "243239",
    "end": "245820"
  },
  {
    "text": "afterwards okay I think that's all I've",
    "start": "245820",
    "end": "249030"
  },
  {
    "text": "got",
    "start": "249030",
    "end": "249450"
  },
  {
    "text": "so yes that's it so if any word would",
    "start": "249450",
    "end": "253019"
  },
  {
    "text": "come up here",
    "start": "253019",
    "end": "253709"
  },
  {
    "text": "Mulla get started with the next talk",
    "start": "253709",
    "end": "258079"
  },
  {
    "start": "257000",
    "end": "291000"
  },
  {
    "text": "okay can everybody hear me people in the",
    "start": "258850",
    "end": "261190"
  },
  {
    "text": "back yeah okay awesome yeah so my name",
    "start": "261190",
    "end": "264370"
  },
  {
    "text": "is ed Brooks",
    "start": "264370",
    "end": "265000"
  },
  {
    "text": "I'm a software engineer at any scale",
    "start": "265000",
    "end": "266710"
  },
  {
    "text": "where I primarily work on the rake or so",
    "start": "266710",
    "end": "269860"
  },
  {
    "text": "one of the big things we've been working",
    "start": "269860",
    "end": "270940"
  },
  {
    "text": "on lately is basically this re",
    "start": "270940",
    "end": "272560"
  },
  {
    "text": "architecture to improve the performance",
    "start": "272560",
    "end": "274150"
  },
  {
    "text": "of scheduling task submissions and Rea",
    "start": "274150",
    "end": "276520"
  },
  {
    "text": "this is primarily collaboration with",
    "start": "276520",
    "end": "278860"
  },
  {
    "text": "Eric and Stephanie who are also both",
    "start": "278860",
    "end": "281200"
  },
  {
    "text": "working at any scale as well as doing",
    "start": "281200",
    "end": "282850"
  },
  {
    "text": "their PhDs at Berkeley but of course",
    "start": "282850",
    "end": "286150"
  },
  {
    "text": "this also couldn't be possible without",
    "start": "286150",
    "end": "287740"
  },
  {
    "text": "all the other people at any scale as",
    "start": "287740",
    "end": "289180"
  },
  {
    "text": "well as open source contributors so the",
    "start": "289180",
    "end": "292450"
  },
  {
    "start": "291000",
    "end": "332000"
  },
  {
    "text": "motivation for this you might be asking",
    "start": "292450",
    "end": "294700"
  },
  {
    "text": "like why do we care about having really",
    "start": "294700",
    "end": "296229"
  },
  {
    "text": "high performance for the scheduler and",
    "start": "296229",
    "end": "297639"
  },
  {
    "text": "the answer is really well we see users",
    "start": "297639",
    "end": "300580"
  },
  {
    "text": "coming to the Rea github with these",
    "start": "300580",
    "end": "301960"
  },
  {
    "text": "issues where they're indicating that",
    "start": "301960",
    "end": "304330"
  },
  {
    "text": "they're using Rea alongside these low",
    "start": "304330",
    "end": "306550"
  },
  {
    "text": "level queuing libraries like multi birth",
    "start": "306550",
    "end": "308169"
  },
  {
    "text": "like multi processing so they're using",
    "start": "308169",
    "end": "311560"
  },
  {
    "text": "rate to basically orchestrate the",
    "start": "311560",
    "end": "313720"
  },
  {
    "text": "high-level structure of their program",
    "start": "313720",
    "end": "315010"
  },
  {
    "text": "but then they run into performance",
    "start": "315010",
    "end": "316810"
  },
  {
    "text": "issues where Ray isn't fast enough and",
    "start": "316810",
    "end": "319180"
  },
  {
    "text": "they have to reach for things like multi",
    "start": "319180",
    "end": "320530"
  },
  {
    "text": "processing queues and pools in order to",
    "start": "320530",
    "end": "322419"
  },
  {
    "text": "get the performance they want on a",
    "start": "322419",
    "end": "323620"
  },
  {
    "text": "single node clearly this isn't what we",
    "start": "323620",
    "end": "326050"
  },
  {
    "text": "want",
    "start": "326050",
    "end": "326350"
  },
  {
    "text": "like ray is advertised as being really",
    "start": "326350",
    "end": "328450"
  },
  {
    "text": "high performance and having low latency",
    "start": "328450",
    "end": "330550"
  },
  {
    "text": "so this is something we need to address",
    "start": "330550",
    "end": "332910"
  },
  {
    "start": "332000",
    "end": "384000"
  },
  {
    "text": "so here's an example program of where",
    "start": "332910",
    "end": "336190"
  },
  {
    "text": "you run into issues so this is a really",
    "start": "336190",
    "end": "338289"
  },
  {
    "text": "simple program where we just have this",
    "start": "338289",
    "end": "340289"
  },
  {
    "text": "single remote task that's called process",
    "start": "340289",
    "end": "343390"
  },
  {
    "text": "I'm just going to take in some data and",
    "start": "343390",
    "end": "344830"
  },
  {
    "text": "do a really lightweight computation over",
    "start": "344830",
    "end": "346240"
  },
  {
    "text": "it so if you schedule a ton of these",
    "start": "346240",
    "end": "348520"
  },
  {
    "text": "process remote tasks say like 10,000 of",
    "start": "348520",
    "end": "350889"
  },
  {
    "text": "them and then try to get the results in",
    "start": "350889",
    "end": "354340"
  },
  {
    "text": "a single process this is like a really",
    "start": "354340",
    "end": "356289"
  },
  {
    "text": "simple embarrassingly parallel workload",
    "start": "356289",
    "end": "358210"
  },
  {
    "text": "so it should be really fast but because",
    "start": "358210",
    "end": "360789"
  },
  {
    "text": "Ray offers all these expressive offers",
    "start": "360789",
    "end": "363729"
  },
  {
    "text": "really expressive API instead of",
    "start": "363729",
    "end": "365169"
  },
  {
    "text": "features the overhead for this is",
    "start": "365169",
    "end": "366700"
  },
  {
    "text": "actually much higher than a simple",
    "start": "366700",
    "end": "368080"
  },
  {
    "text": "low-level library like multi processing",
    "start": "368080",
    "end": "369789"
  },
  {
    "text": "is so the goal with Ray's 0.8 and this",
    "start": "369789",
    "end": "374440"
  },
  {
    "text": "effort is to make ray as fast as using",
    "start": "374440",
    "end": "376450"
  },
  {
    "text": "these lower-level libraries directly in",
    "start": "376450",
    "end": "379000"
  },
  {
    "text": "situations like this where we have you",
    "start": "379000",
    "end": "380770"
  },
  {
    "text": "know sort of simple patterns and we",
    "start": "380770",
    "end": "383139"
  },
  {
    "text": "should be really fast so to understand",
    "start": "383139",
    "end": "386430"
  },
  {
    "start": "384000",
    "end": "402000"
  },
  {
    "text": "what we did to achieve this you have to",
    "start": "386430",
    "end": "389349"
  },
  {
    "text": "understand a little bit about sort of",
    "start": "389349",
    "end": "390880"
  },
  {
    "text": "the status quo",
    "start": "390880",
    "end": "392769"
  },
  {
    "text": "so prior to this effort basically every",
    "start": "392769",
    "end": "395709"
  },
  {
    "text": "time you submitted a task the task state",
    "start": "395709",
    "end": "397539"
  },
  {
    "text": "was written to what we call a global",
    "start": "397539",
    "end": "399279"
  },
  {
    "text": "control store which is just a",
    "start": "399279",
    "end": "400869"
  },
  {
    "text": "centralized metadata storage so let's",
    "start": "400869",
    "end": "404019"
  },
  {
    "start": "402000",
    "end": "445000"
  },
  {
    "text": "run through what it looks like when you",
    "start": "404019",
    "end": "405339"
  },
  {
    "text": "submit a task so in this example we're",
    "start": "405339",
    "end": "407229"
  },
  {
    "text": "just going to be submitting a single",
    "start": "407229",
    "end": "408369"
  },
  {
    "text": "task from this worker process over to",
    "start": "408369",
    "end": "410229"
  },
  {
    "text": "the other one on the right so the first",
    "start": "410229",
    "end": "412899"
  },
  {
    "text": "thing that happens is we submit the task",
    "start": "412899",
    "end": "414369"
  },
  {
    "text": "for the local rail it which just manages",
    "start": "414369",
    "end": "416019"
  },
  {
    "text": "the local machine derail it then records",
    "start": "416019",
    "end": "418929"
  },
  {
    "text": "lineage which is just information about",
    "start": "418929",
    "end": "420669"
  },
  {
    "text": "where the task came from like what",
    "start": "420669",
    "end": "422409"
  },
  {
    "text": "objects were input to it and where it",
    "start": "422409",
    "end": "425409"
  },
  {
    "text": "was ran and then also the state of its",
    "start": "425409",
    "end": "427149"
  },
  {
    "text": "execution into that GCS or global",
    "start": "427149",
    "end": "429639"
  },
  {
    "text": "control store process this is in charge",
    "start": "429639",
    "end": "433329"
  },
  {
    "text": "of storing that metadata for any",
    "start": "433329",
    "end": "435039"
  },
  {
    "text": "subsequent lookups by any other process",
    "start": "435039",
    "end": "437259"
  },
  {
    "text": "in the cluster then the rail it forwards",
    "start": "437259",
    "end": "439959"
  },
  {
    "text": "the task to another worker process this",
    "start": "439959",
    "end": "441579"
  },
  {
    "text": "might be running on the same machine or",
    "start": "441579",
    "end": "443050"
  },
  {
    "text": "it's running on a remote machine then",
    "start": "443050",
    "end": "446050"
  },
  {
    "start": "445000",
    "end": "492000"
  },
  {
    "text": "this worker communicates with another",
    "start": "446050",
    "end": "447399"
  },
  {
    "text": "process called the object store in order",
    "start": "447399",
    "end": "449949"
  },
  {
    "text": "to get any arguments that it has and",
    "start": "449949",
    "end": "451809"
  },
  {
    "text": "then also once it finishes processing to",
    "start": "451809",
    "end": "453639"
  },
  {
    "text": "store its results and then this object",
    "start": "453639",
    "end": "457269"
  },
  {
    "text": "store process also communicates with",
    "start": "457269",
    "end": "458829"
  },
  {
    "text": "derail it so we have this really",
    "start": "458829",
    "end": "460360"
  },
  {
    "text": "complicated set of things that's",
    "start": "460360",
    "end": "462069"
  },
  {
    "text": "happening just so that we can maintain",
    "start": "462069",
    "end": "464349"
  },
  {
    "text": "basically global States so that we were",
    "start": "464349",
    "end": "466979"
  },
  {
    "text": "we can support this expressive API and",
    "start": "466979",
    "end": "469599"
  },
  {
    "text": "also be tolerant to failures oh and then",
    "start": "469599",
    "end": "472329"
  },
  {
    "text": "at the very end this initial worker",
    "start": "472329",
    "end": "474339"
  },
  {
    "text": "process wants to get the result and it",
    "start": "474339",
    "end": "476319"
  },
  {
    "text": "also has to communicate with two of",
    "start": "476319",
    "end": "477939"
  },
  {
    "text": "these centralized processes so clearly",
    "start": "477939",
    "end": "482739"
  },
  {
    "text": "you can see how this is much more",
    "start": "482739",
    "end": "484479"
  },
  {
    "text": "overhead than we need for that really",
    "start": "484479",
    "end": "485739"
  },
  {
    "text": "simple example that I showed before so",
    "start": "485739",
    "end": "488079"
  },
  {
    "text": "I'll be talking about basically how we",
    "start": "488079",
    "end": "489309"
  },
  {
    "text": "address this to remove some of the",
    "start": "489309",
    "end": "490599"
  },
  {
    "text": "centralized bottlenecks the challenge",
    "start": "490599",
    "end": "493809"
  },
  {
    "start": "492000",
    "end": "510000"
  },
  {
    "text": "here is we still want to preserve the",
    "start": "493809",
    "end": "495309"
  },
  {
    "text": "generality like one of the great things",
    "start": "495309",
    "end": "496839"
  },
  {
    "text": "about Rea is we have this really",
    "start": "496839",
    "end": "498219"
  },
  {
    "text": "expressive API we automatically recover",
    "start": "498219",
    "end": "500499"
  },
  {
    "text": "from failures you can specify resources",
    "start": "500499",
    "end": "502360"
  },
  {
    "text": "and it handles scheduling across the",
    "start": "502360",
    "end": "503559"
  },
  {
    "text": "cluster etc so we don't want to",
    "start": "503559",
    "end": "505659"
  },
  {
    "text": "sacrifice any of that generality just to",
    "start": "505659",
    "end": "507729"
  },
  {
    "text": "get performance for these simple cases",
    "start": "507729",
    "end": "511110"
  },
  {
    "start": "510000",
    "end": "544000"
  },
  {
    "text": "yeah and here are some of the the",
    "start": "511110",
    "end": "513550"
  },
  {
    "text": "expressive parts of our API so these low",
    "start": "513550",
    "end": "517990"
  },
  {
    "text": "level libraries that people are reaching",
    "start": "517990",
    "end": "519339"
  },
  {
    "text": "for that have higher performance are",
    "start": "519339",
    "end": "520630"
  },
  {
    "text": "basically don't support these features",
    "start": "520630",
    "end": "522789"
  },
  {
    "text": "meaning they're sacrificing generality",
    "start": "522789",
    "end": "524559"
  },
  {
    "text": "for",
    "start": "524559",
    "end": "524840"
  },
  {
    "text": "performance and prior to this effort Rey",
    "start": "524840",
    "end": "526910"
  },
  {
    "text": "was maybe somewhere over here where we",
    "start": "526910",
    "end": "528650"
  },
  {
    "text": "were sacrificing some performance we",
    "start": "528650",
    "end": "530720"
  },
  {
    "text": "still did relatively well in exchange",
    "start": "530720",
    "end": "533120"
  },
  {
    "text": "for having really high generality",
    "start": "533120",
    "end": "534680"
  },
  {
    "text": "because we support all of these really",
    "start": "534680",
    "end": "536840"
  },
  {
    "text": "nice features and with 30.8 we're trying",
    "start": "536840",
    "end": "539180"
  },
  {
    "text": "to push up into the right and sort of",
    "start": "539180",
    "end": "541430"
  },
  {
    "text": "the ideal part of this chart so the high",
    "start": "541430",
    "end": "545720"
  },
  {
    "start": "544000",
    "end": "569000"
  },
  {
    "text": "level approach that we took to address",
    "start": "545720",
    "end": "547100"
  },
  {
    "text": "this is basically recognizing that we",
    "start": "547100",
    "end": "549980"
  },
  {
    "text": "can have like multiple paths through the",
    "start": "549980",
    "end": "551600"
  },
  {
    "text": "code so this is like something that",
    "start": "551600",
    "end": "553250"
  },
  {
    "text": "happens or this is a really common",
    "start": "553250",
    "end": "554930"
  },
  {
    "text": "optimization technique is you take the",
    "start": "554930",
    "end": "557810"
  },
  {
    "text": "fast path and make it as fast as you",
    "start": "557810",
    "end": "559670"
  },
  {
    "text": "possibly can and then fall back to a",
    "start": "559670",
    "end": "561200"
  },
  {
    "text": "slow path when you need to so in our",
    "start": "561200",
    "end": "563270"
  },
  {
    "text": "case where the goal is to make this fast",
    "start": "563270",
    "end": "565130"
  },
  {
    "text": "path for task submission as fast as just",
    "start": "565130",
    "end": "567110"
  },
  {
    "text": "doing a single RPC and we have three key",
    "start": "567110",
    "end": "571280"
  },
  {
    "start": "569000",
    "end": "579000"
  },
  {
    "text": "optimizations that let us basically",
    "start": "571280",
    "end": "572630"
  },
  {
    "text": "achieve this and I'll talk about each",
    "start": "572630",
    "end": "574250"
  },
  {
    "text": "one of these in turn so don't worry if",
    "start": "574250",
    "end": "576500"
  },
  {
    "text": "you don't understand what they mean out",
    "start": "576500",
    "end": "577940"
  },
  {
    "text": "of context here so the first of these",
    "start": "577940",
    "end": "581690"
  },
  {
    "start": "579000",
    "end": "611000"
  },
  {
    "text": "optimizations is co-locating task state",
    "start": "581690",
    "end": "584330"
  },
  {
    "text": "with the worker that submitted a task so",
    "start": "584330",
    "end": "586970"
  },
  {
    "text": "the key insight here is that actually in",
    "start": "586970",
    "end": "588650"
  },
  {
    "text": "most of the cases including the case",
    "start": "588650",
    "end": "590330"
  },
  {
    "text": "that I had flash earlier with this this",
    "start": "590330",
    "end": "592280"
  },
  {
    "text": "really simple program actually the only",
    "start": "592280",
    "end": "594770"
  },
  {
    "text": "process in the system that cares about",
    "start": "594770",
    "end": "597230"
  },
  {
    "text": "the submitted task state is the one that",
    "start": "597230",
    "end": "599690"
  },
  {
    "text": "submitted it so what this means is that",
    "start": "599690",
    "end": "602240"
  },
  {
    "text": "instead of having to update all of this",
    "start": "602240",
    "end": "604970"
  },
  {
    "text": "global state and have these centralized",
    "start": "604970",
    "end": "606380"
  },
  {
    "text": "global bottlenecks we can actually just",
    "start": "606380",
    "end": "608120"
  },
  {
    "text": "keep the state at the worker that",
    "start": "608120",
    "end": "609530"
  },
  {
    "text": "submitted the task so here this is the",
    "start": "609530",
    "end": "613910"
  },
  {
    "start": "611000",
    "end": "673000"
  },
  {
    "text": "diagram that I went through earlier and",
    "start": "613910",
    "end": "615410"
  },
  {
    "text": "what it looks like when we collocate",
    "start": "615410",
    "end": "617870"
  },
  {
    "text": "task state at the worker that submitted",
    "start": "617870",
    "end": "619310"
  },
  {
    "text": "it is instead of actually submitting the",
    "start": "619310",
    "end": "623360"
  },
  {
    "text": "task to the rail it what we're gonna do",
    "start": "623360",
    "end": "625220"
  },
  {
    "text": "now is just get a lease for a worker in",
    "start": "625220",
    "end": "627110"
  },
  {
    "text": "the cluster so this goes through all of",
    "start": "627110",
    "end": "629000"
  },
  {
    "text": "the same like scheduling mechanisms but",
    "start": "629000",
    "end": "632240"
  },
  {
    "text": "instead of actually submitting the task",
    "start": "632240",
    "end": "633710"
  },
  {
    "text": "through the rail it we're just asking",
    "start": "633710",
    "end": "635390"
  },
  {
    "text": "for a lease for a worker which means",
    "start": "635390",
    "end": "636770"
  },
  {
    "text": "that we're the only process in the",
    "start": "636770",
    "end": "639200"
  },
  {
    "text": "system that's allowed to submit tasks",
    "start": "639200",
    "end": "640760"
  },
  {
    "text": "for a certain period of time then this",
    "start": "640760",
    "end": "643460"
  },
  {
    "text": "worker directly submits the task to the",
    "start": "643460",
    "end": "645800"
  },
  {
    "text": "least worker so we still have the same",
    "start": "645800",
    "end": "648140"
  },
  {
    "text": "scheduling guarantees but we're just",
    "start": "648140",
    "end": "649550"
  },
  {
    "text": "communicating directly between the",
    "start": "649550",
    "end": "650960"
  },
  {
    "text": "worker processes and then instead of",
    "start": "650960",
    "end": "653120"
  },
  {
    "text": "storing any metadata in this global",
    "start": "653120",
    "end": "655090"
  },
  {
    "text": "control store about the",
    "start": "655090",
    "end": "657050"
  },
  {
    "text": "execution state we're just keeping it at",
    "start": "657050",
    "end": "659400"
  },
  {
    "text": "the worker that submitted the task so",
    "start": "659400",
    "end": "662970"
  },
  {
    "text": "what this means is we now have this this",
    "start": "662970",
    "end": "665160"
  },
  {
    "text": "faster scheduling where we don't have to",
    "start": "665160",
    "end": "667230"
  },
  {
    "text": "communicate with the global control",
    "start": "667230",
    "end": "668400"
  },
  {
    "text": "store at all on the task submission path",
    "start": "668400",
    "end": "670020"
  },
  {
    "text": "so we've gotten rid of one of these",
    "start": "670020",
    "end": "671310"
  },
  {
    "text": "central bottlenecks and one of the the",
    "start": "671310",
    "end": "675090"
  },
  {
    "start": "673000",
    "end": "727000"
  },
  {
    "text": "obvious questions is do we lose anything",
    "start": "675090",
    "end": "677250"
  },
  {
    "text": "by doing this right so now we're",
    "start": "677250",
    "end": "679520"
  },
  {
    "text": "basically by collocating the task state",
    "start": "679520",
    "end": "682800"
  },
  {
    "text": "we're now fake chairing that state with",
    "start": "682800",
    "end": "685590"
  },
  {
    "text": "the worker that submitted a process so",
    "start": "685590",
    "end": "687600"
  },
  {
    "text": "that means if if that worker goes down",
    "start": "687600",
    "end": "691350"
  },
  {
    "text": "then we lose all of the metadata about",
    "start": "691350",
    "end": "693360"
  },
  {
    "text": "the task that it's submitted so we may",
    "start": "693360",
    "end": "695160"
  },
  {
    "text": "have to go through like more task",
    "start": "695160",
    "end": "696720"
  },
  {
    "text": "submissions if we need to recover the",
    "start": "696720",
    "end": "698280"
  },
  {
    "text": "result but really in practice this is",
    "start": "698280",
    "end": "701520"
  },
  {
    "text": "not a big deal right failure is already",
    "start": "701520",
    "end": "703920"
  },
  {
    "text": "a slow path because we have to resubmit",
    "start": "703920",
    "end": "705330"
  },
  {
    "text": "all of these tasks we have to go to be",
    "start": "705330",
    "end": "706830"
  },
  {
    "text": "like this central control store so it's",
    "start": "706830",
    "end": "710250"
  },
  {
    "text": "already a slow path and it also",
    "start": "710250",
    "end": "711450"
  },
  {
    "text": "shouldn't be the common path and then",
    "start": "711450",
    "end": "714330"
  },
  {
    "text": "there's this other question well what if",
    "start": "714330",
    "end": "715440"
  },
  {
    "text": "other workers need to access that state",
    "start": "715440",
    "end": "717000"
  },
  {
    "text": "well it turns out that this is actually",
    "start": "717000",
    "end": "719100"
  },
  {
    "text": "pretty similar to what we had before",
    "start": "719100",
    "end": "720300"
  },
  {
    "text": "except instead of looking it up in the",
    "start": "720300",
    "end": "723090"
  },
  {
    "text": "global storage you just ask the worker",
    "start": "723090",
    "end": "724620"
  },
  {
    "text": "that holds the state ok so moving on to",
    "start": "724620",
    "end": "729420"
  },
  {
    "start": "727000",
    "end": "805000"
  },
  {
    "text": "the second optimization we made so now",
    "start": "729420",
    "end": "732300"
  },
  {
    "text": "that we can submit tasks directly to",
    "start": "732300",
    "end": "734010"
  },
  {
    "text": "other workers so yeah I showed how that",
    "start": "734010",
    "end": "737640"
  },
  {
    "text": "removes some of the central bottlenecks",
    "start": "737640",
    "end": "738900"
  },
  {
    "text": "but we still have to go through this",
    "start": "738900",
    "end": "740430"
  },
  {
    "text": "centralized or somewhat centralized",
    "start": "740430",
    "end": "742590"
  },
  {
    "text": "scheduling decision-making process when",
    "start": "742590",
    "end": "744990"
  },
  {
    "text": "we lease a worker from the raela however",
    "start": "744990",
    "end": "749220"
  },
  {
    "text": "notice that we don't actually need to do",
    "start": "749220",
    "end": "752850"
  },
  {
    "text": "this for every single task we submit we",
    "start": "752850",
    "end": "754890"
  },
  {
    "text": "can reuse these scheduling decisions",
    "start": "754890",
    "end": "757140"
  },
  {
    "text": "which is hinted out a little bit by the",
    "start": "757140",
    "end": "758550"
  },
  {
    "text": "fact that this is a lease so what we can",
    "start": "758550",
    "end": "760980"
  },
  {
    "text": "do is when we get a lease for a worker",
    "start": "760980",
    "end": "763290"
  },
  {
    "text": "instead of just submitting a single task",
    "start": "763290",
    "end": "764850"
  },
  {
    "text": "we can keep the lease and continue",
    "start": "764850",
    "end": "766560"
  },
  {
    "text": "submitting tasks however notice that in",
    "start": "766560",
    "end": "769950"
  },
  {
    "text": "order to maintain generality or to",
    "start": "769950",
    "end": "772200"
  },
  {
    "text": "maintain correctness with the scheduling",
    "start": "772200",
    "end": "774020"
  },
  {
    "text": "this work are the the subsequent tests",
    "start": "774020",
    "end": "776970"
  },
  {
    "text": "that we're submitting have to have the",
    "start": "776970",
    "end": "778050"
  },
  {
    "text": "same what we call like scheduling shape",
    "start": "778050",
    "end": "779760"
  },
  {
    "text": "so that means that the same dependencies",
    "start": "779760",
    "end": "781950"
  },
  {
    "text": "and s does have the same resources so if",
    "start": "781950",
    "end": "784950"
  },
  {
    "text": "I submit or if I get a lease for a",
    "start": "784950",
    "end": "787770"
  },
  {
    "text": "worker for a",
    "start": "787770",
    "end": "789730"
  },
  {
    "text": "single CPU tasks and then I try to",
    "start": "789730",
    "end": "792070"
  },
  {
    "text": "submit a to CPU task on that same worker",
    "start": "792070",
    "end": "794050"
  },
  {
    "text": "well obviously that breaks the",
    "start": "794050",
    "end": "795579"
  },
  {
    "text": "scheduling logic because the scheduler",
    "start": "795579",
    "end": "797740"
  },
  {
    "text": "didn't know that you were gonna use that",
    "start": "797740",
    "end": "799240"
  },
  {
    "text": "for two CPUs so we can't do that we can",
    "start": "799240",
    "end": "801699"
  },
  {
    "text": "only do this caching when the scheduling",
    "start": "801699",
    "end": "803410"
  },
  {
    "text": "shape is exactly the same so now instead",
    "start": "803410",
    "end": "808269"
  },
  {
    "text": "of having to go through this get worker",
    "start": "808269",
    "end": "810490"
  },
  {
    "text": "lease every time on the fast path when",
    "start": "810490",
    "end": "812620"
  },
  {
    "text": "we're submitting many tasks that have",
    "start": "812620",
    "end": "814810"
  },
  {
    "text": "the same scheduling shape we can",
    "start": "814810",
    "end": "816310"
  },
  {
    "text": "actually just keep that keep the lease",
    "start": "816310",
    "end": "818769"
  },
  {
    "text": "for that and submit the test directly",
    "start": "818769",
    "end": "821310"
  },
  {
    "text": "which means now we've removed another",
    "start": "821310",
    "end": "824110"
  },
  {
    "text": "centralized bottleneck and the only one",
    "start": "824110",
    "end": "825970"
  },
  {
    "text": "remaining is going through this object",
    "start": "825970",
    "end": "827199"
  },
  {
    "text": "store so the final one will be",
    "start": "827199",
    "end": "831370"
  },
  {
    "text": "addressing that problem and the key",
    "start": "831370",
    "end": "833829"
  },
  {
    "text": "insight here is that if an object is",
    "start": "833829",
    "end": "835779"
  },
  {
    "text": "passed by value and I'll explain what by",
    "start": "835779",
    "end": "838269"
  },
  {
    "text": "value means in just a second then we can",
    "start": "838269",
    "end": "840220"
  },
  {
    "text": "just inline it in the task instead of",
    "start": "840220",
    "end": "842230"
  },
  {
    "text": "having to go through this object store",
    "start": "842230",
    "end": "843579"
  },
  {
    "text": "and we don't actually externalize it say",
    "start": "843579",
    "end": "845800"
  },
  {
    "text": "ID at all meaning the the ID because we",
    "start": "845800",
    "end": "850209"
  },
  {
    "text": "know the ID won't be used in sort of",
    "start": "850209",
    "end": "852250"
  },
  {
    "text": "these like complex ways like passing IDs",
    "start": "852250",
    "end": "854260"
  },
  {
    "text": "between processes we don't have to worry",
    "start": "854260",
    "end": "857529"
  },
  {
    "text": "about updating the global metadata about",
    "start": "857529",
    "end": "859690"
  },
  {
    "text": "the ID so if we look at these two simple",
    "start": "859690",
    "end": "862600"
  },
  {
    "start": "860000",
    "end": "902000"
  },
  {
    "text": "examples the first one here we're",
    "start": "862600",
    "end": "865120"
  },
  {
    "text": "submitting a first remote function and",
    "start": "865120",
    "end": "867250"
  },
  {
    "text": "then we're taking the result from that",
    "start": "867250",
    "end": "868389"
  },
  {
    "text": "function and submitting it into a second",
    "start": "868389",
    "end": "870029"
  },
  {
    "text": "so in this case G does not actually get",
    "start": "870029",
    "end": "873970"
  },
  {
    "text": "a reference to X ID it only gets a",
    "start": "873970",
    "end": "876130"
  },
  {
    "text": "reference to the underlying value from X",
    "start": "876130",
    "end": "878290"
  },
  {
    "text": "so this means that we don't have to",
    "start": "878290",
    "end": "880180"
  },
  {
    "text": "worry about having X ID in the global",
    "start": "880180",
    "end": "883930"
  },
  {
    "text": "metadata store because we know that this",
    "start": "883930",
    "end": "886930"
  },
  {
    "text": "can only this can still only be used at",
    "start": "886930",
    "end": "889420"
  },
  {
    "text": "F or sorry at the current process here",
    "start": "889420",
    "end": "892589"
  },
  {
    "text": "so we say that the X ID does not escape",
    "start": "892589",
    "end": "895329"
  },
  {
    "text": "the current process we can we don't have",
    "start": "895329",
    "end": "897069"
  },
  {
    "text": "to worry about the caching issue that",
    "start": "897069",
    "end": "899079"
  },
  {
    "text": "the state is only at this process",
    "start": "899079",
    "end": "900550"
  },
  {
    "text": "because it can't be used anywhere else",
    "start": "900550",
    "end": "902610"
  },
  {
    "start": "902000",
    "end": "923000"
  },
  {
    "text": "in contrast if we were to pass X ID by",
    "start": "902610",
    "end": "907149"
  },
  {
    "text": "reference so in this case G does have",
    "start": "907149",
    "end": "909880"
  },
  {
    "text": "reference to the actual ID and it could",
    "start": "909880",
    "end": "911860"
  },
  {
    "text": "forward it to other tasks and so on in",
    "start": "911860",
    "end": "914470"
  },
  {
    "text": "this case we would say that X ID escaped",
    "start": "914470",
    "end": "917019"
  },
  {
    "text": "this process so in this case we do have",
    "start": "917019",
    "end": "919510"
  },
  {
    "text": "to go through",
    "start": "919510",
    "end": "920790"
  },
  {
    "text": "like entering its metadata into the",
    "start": "920790",
    "end": "922589"
  },
  {
    "text": "centralized storage so if we really",
    "start": "922589",
    "end": "925199"
  },
  {
    "start": "923000",
    "end": "929000"
  },
  {
    "text": "revisit what the task submission",
    "start": "925199",
    "end": "927839"
  },
  {
    "text": "workflow looks like now instead of going",
    "start": "927839",
    "end": "931529"
  },
  {
    "text": "through the object store for everything",
    "start": "931529",
    "end": "932760"
  },
  {
    "text": "we're only doing it when we have objects",
    "start": "932760",
    "end": "934829"
  },
  {
    "text": "that escaped like I talked about in the",
    "start": "934829",
    "end": "936240"
  },
  {
    "text": "previous slide and then also for large",
    "start": "936240",
    "end": "938040"
  },
  {
    "text": "objects because for large objects the",
    "start": "938040",
    "end": "939839"
  },
  {
    "text": "object store is like really optimized",
    "start": "939839",
    "end": "942000"
  },
  {
    "text": "for large object transfer so that turns",
    "start": "942000",
    "end": "943800"
  },
  {
    "text": "out to outweigh the downside of going",
    "start": "943800",
    "end": "946260"
  },
  {
    "text": "through like the centralized bottleneck",
    "start": "946260",
    "end": "947579"
  },
  {
    "text": "so now you'll notice that we've",
    "start": "947579",
    "end": "950190"
  },
  {
    "text": "basically achieved what I set out to do",
    "start": "950190",
    "end": "953130"
  },
  {
    "text": "in the beginning of the talk which is we",
    "start": "953130",
    "end": "954779"
  },
  {
    "text": "want this fast path to just look like a",
    "start": "954779",
    "end": "956160"
  },
  {
    "text": "single RPC between two processes so if",
    "start": "956160",
    "end": "959010"
  },
  {
    "text": "you think back to the example we had",
    "start": "959010",
    "end": "960300"
  },
  {
    "text": "where we're submitting the same task",
    "start": "960300",
    "end": "962040"
  },
  {
    "text": "just ten thousand times in a row now all",
    "start": "962040",
    "end": "965010"
  },
  {
    "text": "we have to do instead of this really",
    "start": "965010",
    "end": "966540"
  },
  {
    "text": "complex protocol for every one of those",
    "start": "966540",
    "end": "968639"
  },
  {
    "text": "test submissions is just basically do",
    "start": "968639",
    "end": "971250"
  },
  {
    "text": "that protocol once and then the",
    "start": "971250",
    "end": "973560"
  },
  {
    "text": "subsequent requests are just a single",
    "start": "973560",
    "end": "975600"
  },
  {
    "text": "RPC between two processes so what does",
    "start": "975600",
    "end": "979260"
  },
  {
    "start": "977000",
    "end": "1028000"
  },
  {
    "text": "this look like in performance so on the",
    "start": "979260",
    "end": "982649"
  },
  {
    "text": "bottom or sorry on the top you can see",
    "start": "982649",
    "end": "984360"
  },
  {
    "text": "raised 0.7 so that's before any of these",
    "start": "984360",
    "end": "986430"
  },
  {
    "text": "optimizations you can see that we were",
    "start": "986430",
    "end": "988800"
  },
  {
    "text": "just under like 300 microsecond latency",
    "start": "988800",
    "end": "990990"
  },
  {
    "text": "for doing a call between two actors and",
    "start": "990990",
    "end": "995399"
  },
  {
    "text": "you can see G RPC which can be seen as",
    "start": "995399",
    "end": "997589"
  },
  {
    "text": "like the the lower bound is around like",
    "start": "997589",
    "end": "999630"
  },
  {
    "text": "200 microseconds and the really",
    "start": "999630",
    "end": "1001639"
  },
  {
    "text": "interesting thing is now andrae's 0.8 we",
    "start": "1001639",
    "end": "1004760"
  },
  {
    "text": "do better than only G RPC so this might",
    "start": "1004760",
    "end": "1007250"
  },
  {
    "text": "look like black magic because we use G",
    "start": "1007250",
    "end": "1009110"
  },
  {
    "text": "RPC underneath but but this is actually",
    "start": "1009110",
    "end": "1012199"
  },
  {
    "text": "just because in Ray we're using the like",
    "start": "1012199",
    "end": "1016100"
  },
  {
    "text": "more optimized C++ G RPC library and",
    "start": "1016100",
    "end": "1018649"
  },
  {
    "text": "this is using the the Python G RPC",
    "start": "1018649",
    "end": "1020480"
  },
  {
    "text": "library so if you if you plot the C++",
    "start": "1020480",
    "end": "1023120"
  },
  {
    "text": "latency it ends up being like just",
    "start": "1023120",
    "end": "1025459"
  },
  {
    "text": "slightly under what we have and right so",
    "start": "1025459",
    "end": "1030319"
  },
  {
    "start": "1028000",
    "end": "1093000"
  },
  {
    "text": "if what does this mean at sort of a",
    "start": "1030319",
    "end": "1032120"
  },
  {
    "text": "higher level so here we have three",
    "start": "1032120",
    "end": "1034010"
  },
  {
    "text": "conditions and we're just plotting the",
    "start": "1034010",
    "end": "1035209"
  },
  {
    "text": "number of tasks per second that we can",
    "start": "1035209",
    "end": "1036740"
  },
  {
    "text": "submit and get the response for it so on",
    "start": "1036740",
    "end": "1039199"
  },
  {
    "text": "the Left we have tasks with a single",
    "start": "1039199",
    "end": "1041808"
  },
  {
    "text": "submitter here we have tasks with",
    "start": "1041809",
    "end": "1044030"
  },
  {
    "text": "multiple submitters and then here we",
    "start": "1044030",
    "end": "1046548"
  },
  {
    "text": "have many actors submitting to many",
    "start": "1046549",
    "end": "1048950"
  },
  {
    "text": "other actors so in raise 0.7 you can see",
    "start": "1048950",
    "end": "1052370"
  },
  {
    "text": "all of them hovered around",
    "start": "1052370",
    "end": "1054010"
  },
  {
    "text": "thousand tests per second because of",
    "start": "1054010",
    "end": "1055990"
  },
  {
    "text": "these centralized bottlenecks and now on",
    "start": "1055990",
    "end": "1057940"
  },
  {
    "text": "raise 0.8 we we do substantially better",
    "start": "1057940",
    "end": "1061090"
  },
  {
    "text": "so we do you know between like 3x and",
    "start": "1061090",
    "end": "1064320"
  },
  {
    "text": "something like 8x faster for actor calls",
    "start": "1064320",
    "end": "1069900"
  },
  {
    "text": "and we also have better scaling so",
    "start": "1069900",
    "end": "1073360"
  },
  {
    "text": "previously even if the cluster was very",
    "start": "1073360",
    "end": "1075640"
  },
  {
    "text": "large and you had many actors that were",
    "start": "1075640",
    "end": "1077560"
  },
  {
    "text": "invoking methods on many actors we",
    "start": "1077560",
    "end": "1079780"
  },
  {
    "text": "couldn't scale past this around 10000",
    "start": "1079780",
    "end": "1083860"
  },
  {
    "text": "tasks per second mark because of the",
    "start": "1083860",
    "end": "1085720"
  },
  {
    "text": "centralized bottlenecks but now you can",
    "start": "1085720",
    "end": "1087460"
  },
  {
    "text": "see because we have them communicating",
    "start": "1087460",
    "end": "1088900"
  },
  {
    "text": "directly with each other and scales",
    "start": "1088900",
    "end": "1090400"
  },
  {
    "text": "pretty much linearly with the size of",
    "start": "1090400",
    "end": "1091810"
  },
  {
    "text": "the cluster and finally so you know",
    "start": "1091810",
    "end": "1096910"
  },
  {
    "start": "1093000",
    "end": "1135000"
  },
  {
    "text": "oftentimes when you see sort of like",
    "start": "1096910",
    "end": "1098620"
  },
  {
    "text": "performance work you publish like micro",
    "start": "1098620",
    "end": "1100540"
  },
  {
    "text": "benchmarks and they look really good and",
    "start": "1100540",
    "end": "1102070"
  },
  {
    "text": "then when you actually run real",
    "start": "1102070",
    "end": "1103360"
  },
  {
    "text": "applications it sort of doesn't matter",
    "start": "1103360",
    "end": "1105280"
  },
  {
    "text": "or you know maybe you only see like a",
    "start": "1105280",
    "end": "1107110"
  },
  {
    "text": "negligible impact but actually when we",
    "start": "1107110",
    "end": "1108910"
  },
  {
    "text": "were doing the public or working on some",
    "start": "1108910",
    "end": "1111520"
  },
  {
    "text": "benchmarks during the release process we",
    "start": "1111520",
    "end": "1113110"
  },
  {
    "text": "saw that in our lib which is something a",
    "start": "1113110",
    "end": "1115630"
  },
  {
    "text": "lot of you are familiar with",
    "start": "1115630",
    "end": "1116590"
  },
  {
    "text": "reinforcement learning on top of Ray",
    "start": "1116590",
    "end": "1119340"
  },
  {
    "text": "between 0.7 which is plotted here and",
    "start": "1119340",
    "end": "1122170"
  },
  {
    "text": "0.8 we actually saw like very",
    "start": "1122170",
    "end": "1124720"
  },
  {
    "text": "substantial improvements in performance",
    "start": "1124720",
    "end": "1126180"
  },
  {
    "text": "so this is not just us optimizing away",
    "start": "1126180",
    "end": "1129160"
  },
  {
    "text": "sort of like a small toy case it",
    "start": "1129160",
    "end": "1131260"
  },
  {
    "text": "actually has like real impact on on",
    "start": "1131260",
    "end": "1133380"
  },
  {
    "text": "applications yeah so in conclusion I",
    "start": "1133380",
    "end": "1137320"
  },
  {
    "start": "1135000",
    "end": "1412000"
  },
  {
    "text": "went over three key optimizations that",
    "start": "1137320",
    "end": "1139510"
  },
  {
    "text": "we worked on for this latest release and",
    "start": "1139510",
    "end": "1141970"
  },
  {
    "text": "basically the outcome is we've",
    "start": "1141970",
    "end": "1144040"
  },
  {
    "text": "significantly improved performance for a",
    "start": "1144040",
    "end": "1145630"
  },
  {
    "text": "lot of applications without impacting",
    "start": "1145630",
    "end": "1147580"
  },
  {
    "text": "the generality of the system and then",
    "start": "1147580",
    "end": "1150100"
  },
  {
    "text": "it's also the groundwork for the next",
    "start": "1150100",
    "end": "1151840"
  },
  {
    "text": "major thing we're going to work on which",
    "start": "1151840",
    "end": "1153250"
  },
  {
    "text": "is reference counting of object IDs",
    "start": "1153250",
    "end": "1155440"
  },
  {
    "text": "which is basically the goal is basically",
    "start": "1155440",
    "end": "1159940"
  },
  {
    "text": "to make sure that anytime you have an",
    "start": "1159940",
    "end": "1161650"
  },
  {
    "text": "object ID in the system you know that",
    "start": "1161650",
    "end": "1163260"
  },
  {
    "text": "that object is still in memory somewhere",
    "start": "1163260",
    "end": "1165840"
  },
  {
    "text": "so that will be yeah that'll be a focus",
    "start": "1165840",
    "end": "1168490"
  },
  {
    "text": "in the upcoming months and I'll take any",
    "start": "1168490",
    "end": "1170830"
  },
  {
    "text": "questions that you might have about this",
    "start": "1170830",
    "end": "1174059"
  },
  {
    "text": "oh yeah",
    "start": "1174350",
    "end": "1182440"
  },
  {
    "text": "yes what's my definition of a large",
    "start": "1182809",
    "end": "1184490"
  },
  {
    "text": "object that's a really good question",
    "start": "1184490",
    "end": "1186830"
  },
  {
    "text": "do you mean like when do we spill to the",
    "start": "1186830",
    "end": "1188389"
  },
  {
    "text": "object store it's so we did benchmarks",
    "start": "1188389",
    "end": "1191059"
  },
  {
    "text": "to determine when to do it and I think",
    "start": "1191059",
    "end": "1193789"
  },
  {
    "text": "it's a hundred kilobytes so it's still",
    "start": "1193789",
    "end": "1196279"
  },
  {
    "text": "relatively small actually that's",
    "start": "1196279",
    "end": "1199070"
  },
  {
    "text": "basically yeah just the point at which",
    "start": "1199070",
    "end": "1200450"
  },
  {
    "text": "like optimizing the throughput is more",
    "start": "1200450",
    "end": "1201889"
  },
  {
    "text": "important than the latency yeah thanks I",
    "start": "1201889",
    "end": "1205179"
  },
  {
    "text": "didn't do yeah yeah the question is when",
    "start": "1205179",
    "end": "1214759"
  },
  {
    "text": "does the linear scaling of actor to",
    "start": "1214759",
    "end": "1216320"
  },
  {
    "text": "actor communications stop that's a great",
    "start": "1216320",
    "end": "1220610"
  },
  {
    "text": "question",
    "start": "1220610",
    "end": "1222019"
  },
  {
    "text": "it shouldn't yeah I don't there's no",
    "start": "1222019",
    "end": "1224509"
  },
  {
    "text": "reason why it should stop actually I",
    "start": "1224509",
    "end": "1225799"
  },
  {
    "text": "mean there's there's no centralized code",
    "start": "1225799",
    "end": "1227149"
  },
  {
    "text": "for that yeah I mean you have the same",
    "start": "1227149",
    "end": "1234919"
  },
  {
    "text": "the same bottlenecks is G RPC sure",
    "start": "1234919",
    "end": "1238898"
  },
  {
    "text": "ok I think that's it oh one more",
    "start": "1241860",
    "end": "1244409"
  },
  {
    "text": "question oh yeah so he asked what do I",
    "start": "1244409",
    "end": "1251730"
  },
  {
    "text": "mean when I say leasing yeah so the",
    "start": "1251730",
    "end": "1253409"
  },
  {
    "text": "lease is basically when we request a",
    "start": "1253409",
    "end": "1256320"
  },
  {
    "text": "worker we get it for like a maximum",
    "start": "1256320",
    "end": "1259019"
  },
  {
    "text": "predefined time I think in the code it's",
    "start": "1259019",
    "end": "1260909"
  },
  {
    "text": "like 500 milliseconds or something like",
    "start": "1260909",
    "end": "1262350"
  },
  {
    "text": "that so while that period is up if you",
    "start": "1262350",
    "end": "1264510"
  },
  {
    "text": "have more tasks that can be scheduled on",
    "start": "1264510",
    "end": "1266039"
  },
  {
    "text": "that worker you'll continue to submit",
    "start": "1266039",
    "end": "1267779"
  },
  {
    "text": "them and then once the the queue is",
    "start": "1267779",
    "end": "1269610"
  },
  {
    "text": "empty or that time is up",
    "start": "1269610",
    "end": "1271230"
  },
  {
    "text": "then the lease expires and it gets",
    "start": "1271230",
    "end": "1273059"
  },
  {
    "text": "returned to the scheduler oh right yeah",
    "start": "1273059",
    "end": "1283440"
  },
  {
    "text": "so if it if the task doesn't finish in",
    "start": "1283440",
    "end": "1285570"
  },
  {
    "text": "that time period then once the task",
    "start": "1285570",
    "end": "1287159"
  },
  {
    "text": "finishes it will be returned yeah yeah",
    "start": "1287159",
    "end": "1292850"
  },
  {
    "text": "yeah he asked if the decision to go",
    "start": "1298790",
    "end": "1301650"
  },
  {
    "text": "between fast path and slow path is only",
    "start": "1301650",
    "end": "1303330"
  },
  {
    "text": "based on object size yes so right now",
    "start": "1303330",
    "end": "1305790"
  },
  {
    "text": "it's the only performance consideration",
    "start": "1305790",
    "end": "1308160"
  },
  {
    "text": "is object size there are some other",
    "start": "1308160",
    "end": "1310380"
  },
  {
    "text": "considerations like if you get the",
    "start": "1310380",
    "end": "1312300"
  },
  {
    "text": "results of a test and then you want to",
    "start": "1312300",
    "end": "1314340"
  },
  {
    "text": "share it in other places in the cluster",
    "start": "1314340",
    "end": "1315840"
  },
  {
    "text": "so if it like escapes by what I said",
    "start": "1315840",
    "end": "1318570"
  },
  {
    "text": "earlier then we put it in the shared",
    "start": "1318570",
    "end": "1320130"
  },
  {
    "text": "object store because then you need to",
    "start": "1320130",
    "end": "1322470"
  },
  {
    "text": "have it in like global storage so anyone",
    "start": "1322470",
    "end": "1323850"
  },
  {
    "text": "can access it but the size is the only",
    "start": "1323850",
    "end": "1326310"
  },
  {
    "text": "performance decision",
    "start": "1326310",
    "end": "1329600"
  },
  {
    "text": "oh sure",
    "start": "1335580",
    "end": "1341148"
  },
  {
    "text": "I don't think yeah that sounds like kind",
    "start": "1341759",
    "end": "1343950"
  },
  {
    "text": "of a complex example I'd be happy to",
    "start": "1343950",
    "end": "1345600"
  },
  {
    "text": "talk about it offline but I think it'll",
    "start": "1345600",
    "end": "1346799"
  },
  {
    "text": "be hard to figure that out okay last",
    "start": "1346799",
    "end": "1351809"
  },
  {
    "text": "question yep",
    "start": "1351809",
    "end": "1354258"
  },
  {
    "text": "[Music]",
    "start": "1354750",
    "end": "1357910"
  },
  {
    "text": "yeah yeah that's a great question so one",
    "start": "1365570",
    "end": "1370739"
  },
  {
    "text": "of the big things that we've been",
    "start": "1370739",
    "end": "1371849"
  },
  {
    "text": "working on and actually what we're gonna",
    "start": "1371849",
    "end": "1374279"
  },
  {
    "text": "have a short demo about I thought it was",
    "start": "1374279",
    "end": "1377309"
  },
  {
    "text": "after this maybe not is we've been",
    "start": "1377309",
    "end": "1379469"
  },
  {
    "text": "working on like a dashboard where we",
    "start": "1379469",
    "end": "1380759"
  },
  {
    "text": "expose a lot of the lower level",
    "start": "1380759",
    "end": "1382409"
  },
  {
    "text": "primitives so for example one of the",
    "start": "1382409",
    "end": "1385019"
  },
  {
    "text": "things that we plan to surface in the",
    "start": "1385019",
    "end": "1386339"
  },
  {
    "text": "dashboard is like how many like you can",
    "start": "1386339",
    "end": "1388409"
  },
  {
    "text": "see how many tasks have been submitted",
    "start": "1388409",
    "end": "1390059"
  },
  {
    "text": "and we're hoping to show how many tasks",
    "start": "1390059",
    "end": "1391859"
  },
  {
    "text": "like go through the fast and the slow",
    "start": "1391859",
    "end": "1393029"
  },
  {
    "text": "path I think that would like that's that",
    "start": "1393029",
    "end": "1396089"
  },
  {
    "text": "doesn't quite get you all the way there",
    "start": "1396089",
    "end": "1397199"
  },
  {
    "text": "but I think it would like go a long ways",
    "start": "1397199",
    "end": "1399059"
  },
  {
    "text": "to help yeah that's a great question",
    "start": "1399059",
    "end": "1401839"
  },
  {
    "text": "okay thank you very much",
    "start": "1401839",
    "end": "1404600"
  },
  {
    "text": "[Applause]",
    "start": "1404600",
    "end": "1407760"
  }
]
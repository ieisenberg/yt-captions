[
  {
    "text": "hi my name is Ali kadus I'm the head of",
    "start": "120",
    "end": "2940"
  },
  {
    "text": "engineering here at any scale and today",
    "start": "2940",
    "end": "4680"
  },
  {
    "text": "I'm really excited to share with you how",
    "start": "4680",
    "end": "7020"
  },
  {
    "text": "we can build a retrieval-based question",
    "start": "7020",
    "end": "8760"
  },
  {
    "text": "answering system using a combination of",
    "start": "8760",
    "end": "11099"
  },
  {
    "text": "Lang chain Rey and weights and biases",
    "start": "11099",
    "end": "14519"
  },
  {
    "text": "so previously this is actually part two",
    "start": "14519",
    "end": "16800"
  },
  {
    "text": "part one we showed how you could use",
    "start": "16800",
    "end": "19140"
  },
  {
    "text": "embeddings to create a search engine",
    "start": "19140",
    "end": "21619"
  },
  {
    "text": "effectively in just a few lines of Lang",
    "start": "21619",
    "end": "24779"
  },
  {
    "text": "chain and rate code and we brought it up",
    "start": "24779",
    "end": "26760"
  },
  {
    "text": "as a service that we could then query so",
    "start": "26760",
    "end": "28740"
  },
  {
    "text": "now in part two we're going to build on",
    "start": "28740",
    "end": "31140"
  },
  {
    "text": "part one to create a retrieval-based",
    "start": "31140",
    "end": "34200"
  },
  {
    "text": "question answering system so that",
    "start": "34200",
    "end": "35940"
  },
  {
    "text": "basically is going to be that we take",
    "start": "35940",
    "end": "37739"
  },
  {
    "text": "the search results that we had last time",
    "start": "37739",
    "end": "39660"
  },
  {
    "text": "we use that to generate a prompt and",
    "start": "39660",
    "end": "42719"
  },
  {
    "text": "then using that prompt we ask an llm to",
    "start": "42719",
    "end": "46140"
  },
  {
    "text": "extract an answer from it now you might",
    "start": "46140",
    "end": "48360"
  },
  {
    "text": "say like why do I want to do this well",
    "start": "48360",
    "end": "51200"
  },
  {
    "text": "llms have two key problems sometimes",
    "start": "51200",
    "end": "54360"
  },
  {
    "text": "they just don't have an answer",
    "start": "54360",
    "end": "56039"
  },
  {
    "text": "and they can tell you that they don't",
    "start": "56039",
    "end": "58020"
  },
  {
    "text": "have the answer but unfortunately a lot",
    "start": "58020",
    "end": "60059"
  },
  {
    "text": "of the time they do what we call",
    "start": "60059",
    "end": "61440"
  },
  {
    "text": "hallucination which is they make up an",
    "start": "61440",
    "end": "63180"
  },
  {
    "text": "answer that they are very confident is",
    "start": "63180",
    "end": "65518"
  },
  {
    "text": "correct and that's because they don't",
    "start": "65519",
    "end": "67260"
  },
  {
    "text": "have enough data and and so uh that's",
    "start": "67260",
    "end": "69960"
  },
  {
    "text": "often a problem we encounter by using a",
    "start": "69960",
    "end": "73500"
  },
  {
    "text": "search engine combined with an llm and",
    "start": "73500",
    "end": "77220"
  },
  {
    "text": "the appropriate prompt we can actually",
    "start": "77220",
    "end": "78720"
  },
  {
    "text": "overcome in many cases both the",
    "start": "78720",
    "end": "81119"
  },
  {
    "text": "ignorance and hallucination problem",
    "start": "81119",
    "end": "83280"
  },
  {
    "text": "so last time we talked about it this is",
    "start": "83280",
    "end": "85920"
  },
  {
    "text": "how we built kind of the information",
    "start": "85920",
    "end": "87540"
  },
  {
    "text": "Source the retrieval part of the",
    "start": "87540",
    "end": "90420"
  },
  {
    "text": "retrieval engine we took some HTML files",
    "start": "90420",
    "end": "93180"
  },
  {
    "text": "we cut them into little sentences like",
    "start": "93180",
    "end": "96240"
  },
  {
    "text": "structures uh we call them chunks and we",
    "start": "96240",
    "end": "99479"
  },
  {
    "text": "embedded them into a very high",
    "start": "99479",
    "end": "101100"
  },
  {
    "text": "dimensional Vector space basically",
    "start": "101100",
    "end": "102600"
  },
  {
    "text": "converting those",
    "start": "102600",
    "end": "104659"
  },
  {
    "text": "sentences into sequences of numbers that",
    "start": "104659",
    "end": "108840"
  },
  {
    "text": "we could then use as an index so that",
    "start": "108840",
    "end": "110700"
  },
  {
    "text": "was what we did ahead of time and then",
    "start": "110700",
    "end": "113040"
  },
  {
    "text": "to serve what we did is we would take",
    "start": "113040",
    "end": "114600"
  },
  {
    "text": "the query we would then do the same kind",
    "start": "114600",
    "end": "117180"
  },
  {
    "text": "of embedding of the query and then we'd",
    "start": "117180",
    "end": "119280"
  },
  {
    "text": "find things that were similar to that",
    "start": "119280",
    "end": "121020"
  },
  {
    "text": "search result and then return the form",
    "start": "121020",
    "end": "123119"
  },
  {
    "text": "the the the most relevant results and",
    "start": "123119",
    "end": "126119"
  },
  {
    "text": "then that is the response that we've",
    "start": "126119",
    "end": "128039"
  },
  {
    "text": "shown to the user much like a normal",
    "start": "128039",
    "end": "129780"
  },
  {
    "text": "search engine bus",
    "start": "129780",
    "end": "132060"
  },
  {
    "text": "now we're going to expand it so imagine",
    "start": "132060",
    "end": "134340"
  },
  {
    "text": "that we take the system that we just",
    "start": "134340",
    "end": "135959"
  },
  {
    "text": "built and what we what we're going to do",
    "start": "135959",
    "end": "138360"
  },
  {
    "text": "is we're going to use that information",
    "start": "138360",
    "end": "140700"
  },
  {
    "text": "and combine a prompt template to",
    "start": "140700",
    "end": "143459"
  },
  {
    "text": "generate a prompt that we're now going",
    "start": "143459",
    "end": "146040"
  },
  {
    "text": "to pass to our llm to generate a useful",
    "start": "146040",
    "end": "150780"
  },
  {
    "text": "answer that addresses the concern",
    "start": "150780",
    "end": "153300"
  },
  {
    "text": "so let's have a demo uh we're going to",
    "start": "153300",
    "end": "156300"
  },
  {
    "text": "start our service",
    "start": "156300",
    "end": "158959"
  },
  {
    "text": "this is very similar to the service that",
    "start": "159000",
    "end": "161160"
  },
  {
    "text": "we set up last time and let's go through",
    "start": "161160",
    "end": "163560"
  },
  {
    "text": "the source code",
    "start": "163560",
    "end": "165180"
  },
  {
    "text": "so in many ways it's very similar to the",
    "start": "165180",
    "end": "167280"
  },
  {
    "text": "source code from last time",
    "start": "167280",
    "end": "169500"
  },
  {
    "text": "but there's a few key differences the",
    "start": "169500",
    "end": "171360"
  },
  {
    "text": "first is at the top here",
    "start": "171360",
    "end": "173340"
  },
  {
    "text": "we Define The Prompt that we're going to",
    "start": "173340",
    "end": "175560"
  },
  {
    "text": "pass to the llm search engine today",
    "start": "175560",
    "end": "177959"
  },
  {
    "text": "we'll be using stable LM which is a",
    "start": "177959",
    "end": "180120"
  },
  {
    "text": "really small llm it's only about 7",
    "start": "180120",
    "end": "182400"
  },
  {
    "text": "billion parameters so they don't always",
    "start": "182400",
    "end": "184920"
  },
  {
    "text": "have to be fancy you don't need the full",
    "start": "184920",
    "end": "187319"
  },
  {
    "text": "power of gpt4 to take answers from a",
    "start": "187319",
    "end": "190319"
  },
  {
    "text": "search engine and synthesize them into a",
    "start": "190319",
    "end": "192000"
  },
  {
    "text": "single response stable LM you first",
    "start": "192000",
    "end": "195180"
  },
  {
    "text": "Define the the system which is kind of",
    "start": "195180",
    "end": "197819"
  },
  {
    "text": "like the personality that you're trying",
    "start": "197819",
    "end": "200040"
  },
  {
    "text": "to create within the agent",
    "start": "200040",
    "end": "202159"
  },
  {
    "text": "and then make sure that you then Define",
    "start": "202159",
    "end": "206040"
  },
  {
    "text": "The Prompt that's specific to the",
    "start": "206040",
    "end": "207599"
  },
  {
    "text": "question that you have so you'll notice",
    "start": "207599",
    "end": "209400"
  },
  {
    "text": "here that we're defining we're telling",
    "start": "209400",
    "end": "211080"
  },
  {
    "text": "it here's your context and here's what",
    "start": "211080",
    "end": "213720"
  },
  {
    "text": "we want you to do we want you to be",
    "start": "213720",
    "end": "215580"
  },
  {
    "text": "conservative in describing what it is",
    "start": "215580",
    "end": "218099"
  },
  {
    "text": "that you know now once we have that",
    "start": "218099",
    "end": "220920"
  },
  {
    "text": "prompt we're now going to fill in the",
    "start": "220920",
    "end": "222720"
  },
  {
    "text": "data from the search engine and this is",
    "start": "222720",
    "end": "224519"
  },
  {
    "text": "really where the power of Lang chain",
    "start": "224519",
    "end": "226019"
  },
  {
    "text": "comes in there's one other modification",
    "start": "226019",
    "end": "228420"
  },
  {
    "text": "that we're going to make which is that",
    "start": "228420",
    "end": "229920"
  },
  {
    "text": "we're going to add support for uh word",
    "start": "229920",
    "end": "232260"
  },
  {
    "text": "um",
    "start": "232260",
    "end": "233000"
  },
  {
    "text": "weights and biases so weights and biases",
    "start": "233000",
    "end": "235920"
  },
  {
    "text": "is an evaluation tool that is freely",
    "start": "235920",
    "end": "238440"
  },
  {
    "text": "available",
    "start": "238440",
    "end": "240000"
  },
  {
    "text": "um and then what we can do is we can",
    "start": "240000",
    "end": "241860"
  },
  {
    "text": "inspect intermediate values and see how",
    "start": "241860",
    "end": "244200"
  },
  {
    "text": "long things are taking",
    "start": "244200",
    "end": "246299"
  },
  {
    "text": "so the first part of the code we'll be",
    "start": "246299",
    "end": "248159"
  },
  {
    "text": "looking at is exactly the same we create",
    "start": "248159",
    "end": "250439"
  },
  {
    "text": "the embeddings",
    "start": "250439",
    "end": "251700"
  },
  {
    "text": "but this is where we start to do a few",
    "start": "251700",
    "end": "254340"
  },
  {
    "text": "different things",
    "start": "254340",
    "end": "255360"
  },
  {
    "text": "first is that we create a pipeline we",
    "start": "255360",
    "end": "259799"
  },
  {
    "text": "have some minor modifications here to",
    "start": "259799",
    "end": "261900"
  },
  {
    "text": "how Lang Chang does things just to",
    "start": "261900",
    "end": "263699"
  },
  {
    "text": "ensure stability but you can see we're",
    "start": "263699",
    "end": "266520"
  },
  {
    "text": "specifying the 7 billion parameter model",
    "start": "266520",
    "end": "268919"
  },
  {
    "text": "and we're also specifying that it should",
    "start": "268919",
    "end": "271080"
  },
  {
    "text": "use 16 point floats now that's the model",
    "start": "271080",
    "end": "274259"
  },
  {
    "text": "then we use Lang chains capability and",
    "start": "274259",
    "end": "277680"
  },
  {
    "text": "pass it the llm we created here which is",
    "start": "277680",
    "end": "280080"
  },
  {
    "text": "a stable LM pipeline there's particular",
    "start": "280080",
    "end": "283020"
  },
  {
    "text": "different ways of mixing the data one is",
    "start": "283020",
    "end": "284940"
  },
  {
    "text": "stuff which is the simplest one and",
    "start": "284940",
    "end": "287580"
  },
  {
    "text": "we're going to take the prompt that we",
    "start": "287580",
    "end": "289020"
  },
  {
    "text": "gave above that's this long sentence",
    "start": "289020",
    "end": "291540"
  },
  {
    "text": "okay",
    "start": "291540",
    "end": "293280"
  },
  {
    "text": "now that we have the prompt we're going",
    "start": "293280",
    "end": "295560"
  },
  {
    "text": "to connect it up and so what we're going",
    "start": "295560",
    "end": "297300"
  },
  {
    "text": "to do is first we're going to get the",
    "start": "297300",
    "end": "299100"
  },
  {
    "text": "results the results from our previous",
    "start": "299100",
    "end": "301320"
  },
  {
    "text": "system",
    "start": "301320",
    "end": "302280"
  },
  {
    "text": "we're then going to um use the chain",
    "start": "302280",
    "end": "305160"
  },
  {
    "text": "that we created earlier",
    "start": "305160",
    "end": "306960"
  },
  {
    "text": "and pass in the documents that we found",
    "start": "306960",
    "end": "309419"
  },
  {
    "text": "in other words the chunks and the",
    "start": "309419",
    "end": "311280"
  },
  {
    "text": "question that we have",
    "start": "311280",
    "end": "312780"
  },
  {
    "text": "and that's where",
    "start": "312780",
    "end": "314220"
  },
  {
    "text": "um Lang chain kicks in takes the results",
    "start": "314220",
    "end": "316320"
  },
  {
    "text": "computes them and then finally passes it",
    "start": "316320",
    "end": "319740"
  },
  {
    "text": "to the llm to summarize",
    "start": "319740",
    "end": "322259"
  },
  {
    "text": "so now let's try to to hit it so we have",
    "start": "322259",
    "end": "325020"
  },
  {
    "text": "this query script that we've used before",
    "start": "325020",
    "end": "328259"
  },
  {
    "text": "let's check that the service is up and",
    "start": "328259",
    "end": "330120"
  },
  {
    "text": "running okay it looks healthy",
    "start": "330120",
    "end": "332460"
  },
  {
    "text": "and we're going to just send a query",
    "start": "332460",
    "end": "334979"
  },
  {
    "text": "you know what is the difference between",
    "start": "334979",
    "end": "336600"
  },
  {
    "text": "pack and spirit in right and what that's",
    "start": "336600",
    "end": "338820"
  },
  {
    "text": "doing is it's now sending that query",
    "start": "338820",
    "end": "341039"
  },
  {
    "text": "first it's going to get the search",
    "start": "341039",
    "end": "342539"
  },
  {
    "text": "results then it's going to pass it to",
    "start": "342539",
    "end": "344400"
  },
  {
    "text": "the llm to summarize and you can see",
    "start": "344400",
    "end": "346620"
  },
  {
    "text": "here it's not perfect because it talks",
    "start": "346620",
    "end": "348120"
  },
  {
    "text": "about an image which is what was in the",
    "start": "348120",
    "end": "349680"
  },
  {
    "text": "search results but you can see it",
    "start": "349680",
    "end": "351419"
  },
  {
    "text": "actually gets the definition correct so",
    "start": "351419",
    "end": "353639"
  },
  {
    "text": "in Ray when you want to pack a lot of",
    "start": "353639",
    "end": "356280"
  },
  {
    "text": "actors together on a single machine you",
    "start": "356280",
    "end": "358259"
  },
  {
    "text": "say I want to fit as many of these as I",
    "start": "358259",
    "end": "360600"
  },
  {
    "text": "can on a single machine but other types",
    "start": "360600",
    "end": "362639"
  },
  {
    "text": "of performance readers if you have like",
    "start": "362639",
    "end": "364259"
  },
  {
    "text": "20 machines and you have 20 actors you",
    "start": "364259",
    "end": "366600"
  },
  {
    "text": "want one actor per machine so as we can",
    "start": "366600",
    "end": "369360"
  },
  {
    "text": "see it's generated the correct answer in",
    "start": "369360",
    "end": "371639"
  },
  {
    "text": "this particular case what we want to do",
    "start": "371639",
    "end": "373860"
  },
  {
    "text": "though is kind of look at the",
    "start": "373860",
    "end": "375120"
  },
  {
    "text": "observability of this and this is where",
    "start": "375120",
    "end": "377160"
  },
  {
    "text": "weights and biases comes in now this is",
    "start": "377160",
    "end": "378840"
  },
  {
    "text": "a very recent integration like literally",
    "start": "378840",
    "end": "381060"
  },
  {
    "text": "in the last week or so it's not",
    "start": "381060",
    "end": "382919"
  },
  {
    "text": "absolutely required here we can do other",
    "start": "382919",
    "end": "384900"
  },
  {
    "text": "things like have the array serve",
    "start": "384900",
    "end": "387300"
  },
  {
    "text": "instance kind of dump output but it's a",
    "start": "387300",
    "end": "389880"
  },
  {
    "text": "really convenient way to look at the",
    "start": "389880",
    "end": "391680"
  },
  {
    "text": "experiences you go in",
    "start": "391680",
    "end": "393720"
  },
  {
    "text": "and so what we're doing here is we go to",
    "start": "393720",
    "end": "395880"
  },
  {
    "text": "the waiting biases webpage and every",
    "start": "395880",
    "end": "398039"
  },
  {
    "text": "time someone puts in an image uh sorry",
    "start": "398039",
    "end": "400860"
  },
  {
    "text": "um a query it actually captures the",
    "start": "400860",
    "end": "402960"
  },
  {
    "text": "query at all the different levels so as",
    "start": "402960",
    "end": "405300"
  },
  {
    "text": "you can see down here it has the stuff's",
    "start": "405300",
    "end": "407460"
  },
  {
    "text": "documents chain and the part that we're",
    "start": "407460",
    "end": "409139"
  },
  {
    "text": "most interested in is the stable LM",
    "start": "409139",
    "end": "410880"
  },
  {
    "text": "pipeline part and what we can do now is",
    "start": "410880",
    "end": "413280"
  },
  {
    "text": "if we go here and click to the prompt",
    "start": "413280",
    "end": "417199"
  },
  {
    "text": "you can see that in addition to the",
    "start": "417660",
    "end": "420900"
  },
  {
    "text": "template that we had",
    "start": "420900",
    "end": "422580"
  },
  {
    "text": "it is actually pulling the information",
    "start": "422580",
    "end": "425280"
  },
  {
    "text": "from the search engine and it's",
    "start": "425280",
    "end": "426840"
  },
  {
    "text": "embedding it here and then finally after",
    "start": "426840",
    "end": "429360"
  },
  {
    "text": "all of this we can now ask it the",
    "start": "429360",
    "end": "431759"
  },
  {
    "text": "question between what's the difference",
    "start": "431759",
    "end": "433080"
  },
  {
    "text": "between pack and spreading rate and now",
    "start": "433080",
    "end": "435120"
  },
  {
    "text": "we're telling you it's time for the",
    "start": "435120",
    "end": "436380"
  },
  {
    "text": "assistant to hand over and sure enough",
    "start": "436380",
    "end": "438360"
  },
  {
    "text": "that's what allows it to generate the",
    "start": "438360",
    "end": "440280"
  },
  {
    "text": "correct answer that we're looking for",
    "start": "440280",
    "end": "443819"
  },
  {
    "text": "um here in terms of",
    "start": "443819",
    "end": "445940"
  },
  {
    "text": "summarizing the contents so let's",
    "start": "445940",
    "end": "448319"
  },
  {
    "text": "summarize where we are what we've done",
    "start": "448319",
    "end": "450300"
  },
  {
    "text": "here is we've built a system that allow",
    "start": "450300",
    "end": "454800"
  },
  {
    "text": "we built a question answering system",
    "start": "454800",
    "end": "456240"
  },
  {
    "text": "that isn't just the llm by itself it's",
    "start": "456240",
    "end": "459300"
  },
  {
    "text": "retrieving information from a search",
    "start": "459300",
    "end": "461220"
  },
  {
    "text": "engine that we created earlier to",
    "start": "461220",
    "end": "463380"
  },
  {
    "text": "generate results that are super accurate",
    "start": "463380",
    "end": "465500"
  },
  {
    "text": "even though the model and the llm itself",
    "start": "465500",
    "end": "468240"
  },
  {
    "text": "is relatively small at seven billion",
    "start": "468240",
    "end": "469979"
  },
  {
    "text": "parameters it's almost as small as they",
    "start": "469979",
    "end": "471720"
  },
  {
    "text": "get and that can easily fit on a 16",
    "start": "471720",
    "end": "473819"
  },
  {
    "text": "gigabyte GPU",
    "start": "473819",
    "end": "475979"
  },
  {
    "text": "um and using that information and",
    "start": "475979",
    "end": "478020"
  },
  {
    "text": "through clever prompt engineering we've",
    "start": "478020",
    "end": "480060"
  },
  {
    "text": "created a question answering system that",
    "start": "480060",
    "end": "481919"
  },
  {
    "text": "overcomes some of the limitations of",
    "start": "481919",
    "end": "484259"
  },
  {
    "text": "llms as far as not knowing the answer",
    "start": "484259",
    "end": "486720"
  },
  {
    "text": "and also not hallucinating and making up",
    "start": "486720",
    "end": "489900"
  },
  {
    "text": "an answer by constraining it to the",
    "start": "489900",
    "end": "492060"
  },
  {
    "text": "facts that we're in the prompt that we",
    "start": "492060",
    "end": "493680"
  },
  {
    "text": "passed in",
    "start": "493680",
    "end": "495000"
  },
  {
    "text": "so what's next you can of course find",
    "start": "495000",
    "end": "497580"
  },
  {
    "text": "this code yourself and download it we",
    "start": "497580",
    "end": "499199"
  },
  {
    "text": "now have a repo with all of these",
    "start": "499199",
    "end": "500699"
  },
  {
    "text": "examples in it and if you'd like to",
    "start": "500699",
    "end": "502440"
  },
  {
    "text": "build your own systems like this check",
    "start": "502440",
    "end": "503879"
  },
  {
    "text": "out the docs at docs.ray.io Ray also has",
    "start": "503879",
    "end": "506879"
  },
  {
    "text": "a lot of discussion forums and slack",
    "start": "506879",
    "end": "508560"
  },
  {
    "text": "that you can participate in and of",
    "start": "508560",
    "end": "510479"
  },
  {
    "text": "course if you're interested in a",
    "start": "510479",
    "end": "512039"
  },
  {
    "text": "commercial version of this with",
    "start": "512039",
    "end": "514200"
  },
  {
    "text": "production level reliability just reach",
    "start": "514200",
    "end": "516779"
  },
  {
    "text": "out to us and we'll be sure to follow up",
    "start": "516779",
    "end": "520640"
  }
]
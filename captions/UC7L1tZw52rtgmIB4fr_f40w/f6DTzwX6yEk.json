[
  {
    "text": "all right well thanks everybody for",
    "start": "3480",
    "end": "5040"
  },
  {
    "text": "coming I'm Patrick Dolan I'm a senior",
    "start": "5040",
    "end": "7140"
  },
  {
    "text": "machine learning engineer at FlightAware",
    "start": "7140",
    "end": "9120"
  },
  {
    "text": "and today I'll be talking about a",
    "start": "9120",
    "end": "10740"
  },
  {
    "text": "project I worked on",
    "start": "10740",
    "end": "12240"
  },
  {
    "text": "where we needed to scale xgboost to",
    "start": "12240",
    "end": "14460"
  },
  {
    "text": "train on a really large data sets and",
    "start": "14460",
    "end": "16500"
  },
  {
    "text": "how Ray made that really easy for us and",
    "start": "16500",
    "end": "18359"
  },
  {
    "text": "I'll discuss some tips and tricks I",
    "start": "18359",
    "end": "20820"
  },
  {
    "text": "learned along the way that helped speed",
    "start": "20820",
    "end": "22199"
  },
  {
    "text": "up our model training so this isn't the",
    "start": "22199",
    "end": "24539"
  },
  {
    "text": "sexy llm use case you hear about all day",
    "start": "24539",
    "end": "27240"
  },
  {
    "text": "but if you've been around machine",
    "start": "27240",
    "end": "28740"
  },
  {
    "text": "learning a while you know xgboost is",
    "start": "28740",
    "end": "30660"
  },
  {
    "text": "still a Workhorse a lot of people use",
    "start": "30660",
    "end": "32398"
  },
  {
    "text": "and it's pretty good at solving a lot of",
    "start": "32399",
    "end": "34140"
  },
  {
    "text": "problems so it's nice to know how to",
    "start": "34140",
    "end": "36420"
  },
  {
    "text": "scale it",
    "start": "36420",
    "end": "37440"
  },
  {
    "text": "so what we'll talk about is you know",
    "start": "37440",
    "end": "39300"
  },
  {
    "text": "FlightAware who we are what we do the",
    "start": "39300",
    "end": "41340"
  },
  {
    "text": "use case in this project which was",
    "start": "41340",
    "end": "43260"
  },
  {
    "text": "predicting which Runway an airplane is",
    "start": "43260",
    "end": "45660"
  },
  {
    "text": "going to arrive on",
    "start": "45660",
    "end": "46860"
  },
  {
    "text": "how distributed xgboosts works on Ray",
    "start": "46860",
    "end": "49379"
  },
  {
    "text": "what bottlenecks you start to run into",
    "start": "49379",
    "end": "51420"
  },
  {
    "text": "and then how to overcome some of them or",
    "start": "51420",
    "end": "53820"
  },
  {
    "text": "at least speed them up then in the end",
    "start": "53820",
    "end": "55739"
  },
  {
    "text": "I'll talk about some of the actual",
    "start": "55739",
    "end": "57420"
  },
  {
    "text": "metrics and costs of stuff",
    "start": "57420",
    "end": "60600"
  },
  {
    "text": "so FlightAware started in 2005 as kind",
    "start": "60600",
    "end": "63660"
  },
  {
    "text": "of a hobby project for private pilots",
    "start": "63660",
    "end": "65760"
  },
  {
    "text": "and Aviation enthusiasts tracking planes",
    "start": "65760",
    "end": "68040"
  },
  {
    "text": "all over the world just seeing where",
    "start": "68040",
    "end": "69540"
  },
  {
    "text": "they go see you know your friends on a",
    "start": "69540",
    "end": "71820"
  },
  {
    "text": "flight you want to know where the plane",
    "start": "71820",
    "end": "73320"
  },
  {
    "text": "is so it grew into this whole worldwide",
    "start": "73320",
    "end": "75659"
  },
  {
    "text": "thing we're tracking Airlines cargo",
    "start": "75659",
    "end": "78180"
  },
  {
    "text": "military Charter anything that's",
    "start": "78180",
    "end": "80040"
  },
  {
    "text": "publicly trackable we track it so it",
    "start": "80040",
    "end": "82740"
  },
  {
    "text": "fuses data from over 50 sources into a",
    "start": "82740",
    "end": "85380"
  },
  {
    "text": "unified feed of basically what's",
    "start": "85380",
    "end": "87600"
  },
  {
    "text": "happening with aircraft all over the",
    "start": "87600",
    "end": "89520"
  },
  {
    "text": "world as soon as they turn their",
    "start": "89520",
    "end": "91439"
  },
  {
    "text": "equipment on",
    "start": "91439",
    "end": "92520"
  },
  {
    "text": "so that includes schedules from we get",
    "start": "92520",
    "end": "94740"
  },
  {
    "text": "from Airlines governmental authorities",
    "start": "94740",
    "end": "96240"
  },
  {
    "text": "like FAA Euro control adsb which is",
    "start": "96240",
    "end": "99420"
  },
  {
    "text": "automatic dependent surveillance",
    "start": "99420",
    "end": "101040"
  },
  {
    "text": "broadcast which is pretty much required",
    "start": "101040",
    "end": "102840"
  },
  {
    "text": "in all controlled airspace now they send",
    "start": "102840",
    "end": "105240"
  },
  {
    "text": "their GPS back to air traffic control",
    "start": "105240",
    "end": "107340"
  },
  {
    "text": "but you can also just pick it up on the",
    "start": "107340",
    "end": "109680"
  },
  {
    "text": "airwaves yourself so we have a network",
    "start": "109680",
    "end": "111780"
  },
  {
    "text": "of volunteers around the world that feed",
    "start": "111780",
    "end": "114540"
  },
  {
    "text": "that data back to us so we basically",
    "start": "114540",
    "end": "116460"
  },
  {
    "text": "have petabytes of historical data",
    "start": "116460",
    "end": "118380"
  },
  {
    "text": "available for both analytics and machine",
    "start": "118380",
    "end": "120299"
  },
  {
    "text": "learning so the team I'm on we come up",
    "start": "120299",
    "end": "122759"
  },
  {
    "text": "with product ideas and experiments based",
    "start": "122759",
    "end": "125159"
  },
  {
    "text": "on all this data that we have",
    "start": "125159",
    "end": "128280"
  },
  {
    "text": "so the use case here predicting arrival",
    "start": "128280",
    "end": "130619"
  },
  {
    "text": "runways and so fundamentally for this",
    "start": "130619",
    "end": "133440"
  },
  {
    "text": "project you wanted to see if we could",
    "start": "133440",
    "end": "134459"
  },
  {
    "text": "build a model that predicted What",
    "start": "134459",
    "end": "136080"
  },
  {
    "text": "airplane the runway was likely to get",
    "start": "136080",
    "end": "138060"
  },
  {
    "text": "assigned to when it landed at its",
    "start": "138060",
    "end": "139620"
  },
  {
    "text": "destination so we evaluated some",
    "start": "139620",
    "end": "142080"
  },
  {
    "text": "different neural network architectures",
    "start": "142080",
    "end": "143520"
  },
  {
    "text": "but ultimately landed on xgboost since",
    "start": "143520",
    "end": "145800"
  },
  {
    "text": "it was a tabular data data set it turns",
    "start": "145800",
    "end": "148680"
  },
  {
    "text": "out xgboost is just it's so good at this",
    "start": "148680",
    "end": "151080"
  },
  {
    "text": "it's pretty hard to tune a neural",
    "start": "151080",
    "end": "152400"
  },
  {
    "text": "network to get better performance it's",
    "start": "152400",
    "end": "154319"
  },
  {
    "text": "also really efficient to train it on a",
    "start": "154319",
    "end": "157140"
  },
  {
    "text": "CPU so you can trade on a GPU but it",
    "start": "157140",
    "end": "159360"
  },
  {
    "text": "doesn't really worth the trade-off since",
    "start": "159360",
    "end": "161940"
  },
  {
    "text": "gpus are generally pretty expensive",
    "start": "161940",
    "end": "163680"
  },
  {
    "text": "compared to CPUs so this diagram is an",
    "start": "163680",
    "end": "166260"
  },
  {
    "text": "example of SFO airport so you have like",
    "start": "166260",
    "end": "168720"
  },
  {
    "text": "four physical runways but plane can come",
    "start": "168720",
    "end": "171239"
  },
  {
    "text": "from either directions they actually",
    "start": "171239",
    "end": "172500"
  },
  {
    "text": "have eight logical runways that have",
    "start": "172500",
    "end": "174360"
  },
  {
    "text": "their own unique identifiers so this",
    "start": "174360",
    "end": "177180"
  },
  {
    "text": "problem can get pretty complex when you",
    "start": "177180",
    "end": "178860"
  },
  {
    "text": "have air airplanes getting assigned to",
    "start": "178860",
    "end": "180720"
  },
  {
    "text": "like parallel runways and things like",
    "start": "180720",
    "end": "182160"
  },
  {
    "text": "that but model trains on historical data",
    "start": "182160",
    "end": "185519"
  },
  {
    "text": "that we have collected about what's",
    "start": "185519",
    "end": "187440"
  },
  {
    "text": "happened in the past what runways they",
    "start": "187440",
    "end": "189060"
  },
  {
    "text": "were assigned where the planes were what",
    "start": "189060",
    "end": "190500"
  },
  {
    "text": "the weather was data about the runways",
    "start": "190500",
    "end": "192840"
  },
  {
    "text": "positioning of things air traffic",
    "start": "192840",
    "end": "194700"
  },
  {
    "text": "patterns all of that",
    "start": "194700",
    "end": "196379"
  },
  {
    "text": "and so kind of one of the questions we",
    "start": "196379",
    "end": "199200"
  },
  {
    "text": "wanted to answer was when we're",
    "start": "199200",
    "end": "200760"
  },
  {
    "text": "investigating this is whether a model",
    "start": "200760",
    "end": "202019"
  },
  {
    "text": "could actually learn this because the",
    "start": "202019",
    "end": "203459"
  },
  {
    "text": "classification problem but the classes",
    "start": "203459",
    "end": "205440"
  },
  {
    "text": "mean different things at every airport",
    "start": "205440",
    "end": "206640"
  },
  {
    "text": "and so we wanted to see could the model",
    "start": "206640",
    "end": "208140"
  },
  {
    "text": "discern like if this one variable is",
    "start": "208140",
    "end": "210239"
  },
  {
    "text": "different that these classes mean",
    "start": "210239",
    "end": "211800"
  },
  {
    "text": "completely different things and it turns",
    "start": "211800",
    "end": "213480"
  },
  {
    "text": "out they can the",
    "start": "213480",
    "end": "214920"
  },
  {
    "text": "XT boost does pretty well at this so",
    "start": "214920",
    "end": "216739"
  },
  {
    "text": "assigns a category from 0 to 20",
    "start": "216739",
    "end": "219360"
  },
  {
    "text": "basically a classification problem for",
    "start": "219360",
    "end": "221220"
  },
  {
    "text": "which Runway we think and then we map",
    "start": "221220",
    "end": "222900"
  },
  {
    "text": "that from a physical Runway into what",
    "start": "222900",
    "end": "225480"
  },
  {
    "text": "Runway that is for human beings right so",
    "start": "225480",
    "end": "227940"
  },
  {
    "text": "maybe 13 left is a zero here at DFW 13",
    "start": "227940",
    "end": "230700"
  },
  {
    "text": "writes of one so on so forth so this is",
    "start": "230700",
    "end": "234239"
  },
  {
    "text": "an example of a Baton Rouge to Dallas",
    "start": "234239",
    "end": "235980"
  },
  {
    "text": "Fort Worth flight where it starts off",
    "start": "235980",
    "end": "238260"
  },
  {
    "text": "you see it had one prediction about the",
    "start": "238260",
    "end": "239940"
  },
  {
    "text": "runway and then as the airplane got",
    "start": "239940",
    "end": "241319"
  },
  {
    "text": "closer the model decided it was more",
    "start": "241319",
    "end": "242940"
  },
  {
    "text": "confident in a different Runway so it's",
    "start": "242940",
    "end": "244739"
  },
  {
    "text": "continually updating its prediction",
    "start": "244739",
    "end": "246480"
  },
  {
    "text": "throughout the flight and streaming that",
    "start": "246480",
    "end": "249060"
  },
  {
    "text": "back and it's exposed to our customers",
    "start": "249060",
    "end": "250980"
  },
  {
    "text": "via apis",
    "start": "250980",
    "end": "253379"
  },
  {
    "text": "so how do we do this we basically start",
    "start": "253379",
    "end": "255480"
  },
  {
    "text": "with the raw data that we have from all",
    "start": "255480",
    "end": "256979"
  },
  {
    "text": "these different feeds it gets stored in",
    "start": "256979",
    "end": "259079"
  },
  {
    "text": "text formats with like key value Pairs",
    "start": "259079",
    "end": "261419"
  },
  {
    "text": "and then we sync all that to Amazon S3",
    "start": "261419",
    "end": "263460"
  },
  {
    "text": "we use spark and Amazon emails EMR so we",
    "start": "263460",
    "end": "266460"
  },
  {
    "text": "filter we transform We join it all",
    "start": "266460",
    "end": "268199"
  },
  {
    "text": "together into these big data frames and",
    "start": "268199",
    "end": "269940"
  },
  {
    "text": "then we spit out our feature Vector",
    "start": "269940",
    "end": "272160"
  },
  {
    "text": "which currently has 263 features that go",
    "start": "272160",
    "end": "275220"
  },
  {
    "text": "into each training example",
    "start": "275220",
    "end": "277139"
  },
  {
    "text": "so that gets ridden into a data Lake of",
    "start": "277139",
    "end": "279720"
  },
  {
    "text": "parquet files that lives in Amazon S3",
    "start": "279720",
    "end": "282060"
  },
  {
    "text": "and those are the source data that we",
    "start": "282060",
    "end": "284100"
  },
  {
    "text": "use to train the model so we need to",
    "start": "284100",
    "end": "286440"
  },
  {
    "text": "shuttle all that data into a training",
    "start": "286440",
    "end": "288660"
  },
  {
    "text": "cluster and it goes Way Beyond the",
    "start": "288660",
    "end": "290400"
  },
  {
    "text": "limits of a single machine so now we",
    "start": "290400",
    "end": "292800"
  },
  {
    "text": "have to solve the problem of working out",
    "start": "292800",
    "end": "294540"
  },
  {
    "text": "how do we distribute this since we",
    "start": "294540",
    "end": "296160"
  },
  {
    "text": "decided xgboost worked pretty well",
    "start": "296160",
    "end": "298800"
  },
  {
    "text": "so that leads me into distributed extra",
    "start": "298800",
    "end": "300900"
  },
  {
    "text": "boost on Ray",
    "start": "300900",
    "end": "302759"
  },
  {
    "text": "so there's a few different options for",
    "start": "302759",
    "end": "305580"
  },
  {
    "text": "Distributing xgboost training there's",
    "start": "305580",
    "end": "308580"
  },
  {
    "text": "Ray there's desk there's spark there's",
    "start": "308580",
    "end": "310320"
  },
  {
    "text": "kubernetes and I think there's a few",
    "start": "310320",
    "end": "311759"
  },
  {
    "text": "others and we looked at several of them",
    "start": "311759",
    "end": "314160"
  },
  {
    "text": "and we came to the conclusion that Ray",
    "start": "314160",
    "end": "316500"
  },
  {
    "text": "was the best one because you know it's",
    "start": "316500",
    "end": "318240"
  },
  {
    "text": "really simple to use it's platform",
    "start": "318240",
    "end": "319620"
  },
  {
    "text": "agnostic it's stable it has a really",
    "start": "319620",
    "end": "321419"
  },
  {
    "text": "nice UI it has metrics it has insights",
    "start": "321419",
    "end": "323639"
  },
  {
    "text": "you can just go look like how much of",
    "start": "323639",
    "end": "325500"
  },
  {
    "text": "the Clusters being utilized how much",
    "start": "325500",
    "end": "327120"
  },
  {
    "text": "network is going in with what are all",
    "start": "327120",
    "end": "329160"
  },
  {
    "text": "the graphs and we also had some other",
    "start": "329160",
    "end": "331919"
  },
  {
    "text": "projects we're working on where we",
    "start": "331919",
    "end": "333060"
  },
  {
    "text": "needed like distributed data loading and",
    "start": "333060",
    "end": "334560"
  },
  {
    "text": "we were seeing what Ray data was doing",
    "start": "334560",
    "end": "336900"
  },
  {
    "text": "with the the neural network training and",
    "start": "336900",
    "end": "338759"
  },
  {
    "text": "some of the other projects so xgboost",
    "start": "338759",
    "end": "341759"
  },
  {
    "text": "Ray is an open source library and we use",
    "start": "341759",
    "end": "344340"
  },
  {
    "text": "open source array it's pretty well",
    "start": "344340",
    "end": "346800"
  },
  {
    "text": "supported it's actively developed it's",
    "start": "346800",
    "end": "348780"
  },
  {
    "text": "apis like almost identical to just",
    "start": "348780",
    "end": "351360"
  },
  {
    "text": "native XG boost in fact we've used XG",
    "start": "351360",
    "end": "353639"
  },
  {
    "text": "boost this probably looks pretty",
    "start": "353639",
    "end": "354840"
  },
  {
    "text": "familiar to you but this is like the ray",
    "start": "354840",
    "end": "357180"
  },
  {
    "text": "stuff that's on top of it so one of the",
    "start": "357180",
    "end": "359639"
  },
  {
    "text": "core pieces of the API is that it's got",
    "start": "359639",
    "end": "362400"
  },
  {
    "text": "this Ray D Matrix object which is the",
    "start": "362400",
    "end": "364979"
  },
  {
    "text": "analog to xgboost Native D Matrix so",
    "start": "364979",
    "end": "367500"
  },
  {
    "text": "this is just basically all the training",
    "start": "367500",
    "end": "369360"
  },
  {
    "text": "examples in this giant Matrix it wants",
    "start": "369360",
    "end": "371400"
  },
  {
    "text": "to loaded into memory and then it does",
    "start": "371400",
    "end": "373380"
  },
  {
    "text": "all the tree calculation from there",
    "start": "373380",
    "end": "376979"
  },
  {
    "text": "um so it supports both centralized and",
    "start": "376979",
    "end": "378720"
  },
  {
    "text": "decentralized uh or distributed I'm",
    "start": "378720",
    "end": "381000"
  },
  {
    "text": "sorry data loading so in the centralized",
    "start": "381000",
    "end": "382979"
  },
  {
    "text": "one that's where you have like a pandas",
    "start": "382979",
    "end": "385199"
  },
  {
    "text": "data frame or some big like numpy array",
    "start": "385199",
    "end": "387780"
  },
  {
    "text": "or one big CSV file but what we use is",
    "start": "387780",
    "end": "390840"
  },
  {
    "text": "called distributed data loading so",
    "start": "390840",
    "end": "392580"
  },
  {
    "text": "basically the capability is",
    "start": "392580",
    "end": "394740"
  },
  {
    "text": "um the remote actors like the head node",
    "start": "394740",
    "end": "397199"
  },
  {
    "text": "figures out where all the files are and",
    "start": "397199",
    "end": "398699"
  },
  {
    "text": "then it distributes them among all the",
    "start": "398699",
    "end": "400620"
  },
  {
    "text": "workers so the workers are only loading",
    "start": "400620",
    "end": "403139"
  },
  {
    "text": "the data that they need to calculate",
    "start": "403139",
    "end": "404819"
  },
  {
    "text": "their portion of the solution so that",
    "start": "404819",
    "end": "407819"
  },
  {
    "text": "could be a local disk could be NFS Mal",
    "start": "407819",
    "end": "410280"
  },
  {
    "text": "hdfs S3 can and can do all that sort of",
    "start": "410280",
    "end": "413039"
  },
  {
    "text": "stuff it also supports distributed data",
    "start": "413039",
    "end": "414900"
  },
  {
    "text": "frames",
    "start": "414900",
    "end": "415620"
  },
  {
    "text": "so you could do moden or desk or Ray",
    "start": "415620",
    "end": "417960"
  },
  {
    "text": "data sets now when I in created this",
    "start": "417960",
    "end": "420900"
  },
  {
    "text": "project Ray data sets was this was like",
    "start": "420900",
    "end": "422699"
  },
  {
    "text": "over a year ago so they made tons of",
    "start": "422699",
    "end": "424800"
  },
  {
    "text": "progress so we may eventually switch to",
    "start": "424800",
    "end": "426300"
  },
  {
    "text": "raid data sets but for the time being",
    "start": "426300",
    "end": "428360"
  },
  {
    "text": "this is we're just using this uh",
    "start": "428360",
    "end": "431100"
  },
  {
    "text": "underlying so Ray data does underline",
    "start": "431100",
    "end": "433680"
  },
  {
    "text": "this but we're not using that API layer",
    "start": "433680",
    "end": "436139"
  },
  {
    "text": "directly it just kind of happens all for",
    "start": "436139",
    "end": "438180"
  },
  {
    "text": "free for us",
    "start": "438180",
    "end": "439520"
  },
  {
    "text": "so this is just an example of some of",
    "start": "439520",
    "end": "441720"
  },
  {
    "text": "the parameters you can pass into it it",
    "start": "441720",
    "end": "443340"
  },
  {
    "text": "looks really similar to xgboost training",
    "start": "443340",
    "end": "445680"
  },
  {
    "text": "so on the left you have XG boost",
    "start": "445680",
    "end": "447780"
  },
  {
    "text": "parameters so their objective is just a",
    "start": "447780",
    "end": "449639"
  },
  {
    "text": "multi-class classification",
    "start": "449639",
    "end": "451740"
  },
  {
    "text": "you know it's evaluating on log loss and",
    "start": "451740",
    "end": "453599"
  },
  {
    "text": "error the tree method the histogram",
    "start": "453599",
    "end": "455880"
  },
  {
    "text": "method this is a lot faster for CPUs",
    "start": "455880",
    "end": "457620"
  },
  {
    "text": "they invented this originally I think",
    "start": "457620",
    "end": "459060"
  },
  {
    "text": "for the gpus but then I think light GBM",
    "start": "459060",
    "end": "461699"
  },
  {
    "text": "was the first one to take it and uh and",
    "start": "461699",
    "end": "463860"
  },
  {
    "text": "make it CPU based using the same",
    "start": "463860",
    "end": "465720"
  },
  {
    "text": "algorithm so they got notorious for",
    "start": "465720",
    "end": "468180"
  },
  {
    "text": "being really fast at training and then",
    "start": "468180",
    "end": "469500"
  },
  {
    "text": "eventually xgboost brought that",
    "start": "469500",
    "end": "470819"
  },
  {
    "text": "algorithm over as well and then on the",
    "start": "470819",
    "end": "473940"
  },
  {
    "text": "right you have the ray parameters so",
    "start": "473940",
    "end": "476220"
  },
  {
    "text": "those are separately configured so you",
    "start": "476220",
    "end": "477780"
  },
  {
    "text": "can say I want this many actors I want",
    "start": "477780",
    "end": "479340"
  },
  {
    "text": "each one to have this many CPUs and of",
    "start": "479340",
    "end": "481919"
  },
  {
    "text": "course you have the elastic training",
    "start": "481919",
    "end": "483180"
  },
  {
    "text": "options that you've seen in some of",
    "start": "483180",
    "end": "484560"
  },
  {
    "text": "these other presentations so you can say",
    "start": "484560",
    "end": "486180"
  },
  {
    "text": "like I will allow this many actors to",
    "start": "486180",
    "end": "488759"
  },
  {
    "text": "fail or restart and so what this allows",
    "start": "488759",
    "end": "491099"
  },
  {
    "text": "you to do is start to use spot instances",
    "start": "491099",
    "end": "492840"
  },
  {
    "text": "so it can checkpoint it can recover it",
    "start": "492840",
    "end": "495300"
  },
  {
    "text": "can do all that stuff and then you",
    "start": "495300",
    "end": "496560"
  },
  {
    "text": "basically just call this training",
    "start": "496560",
    "end": "498180"
  },
  {
    "text": "function tell it where the data is what",
    "start": "498180",
    "end": "499919"
  },
  {
    "text": "the parameters are and",
    "start": "499919",
    "end": "502379"
  },
  {
    "text": "our code is really not much more",
    "start": "502379",
    "end": "504360"
  },
  {
    "text": "complicated than this it's just it's",
    "start": "504360",
    "end": "506280"
  },
  {
    "text": "just like really simple",
    "start": "506280",
    "end": "507960"
  },
  {
    "text": "um so this is a high level diagram of",
    "start": "507960",
    "end": "509460"
  },
  {
    "text": "like how distributed training Works in",
    "start": "509460",
    "end": "511139"
  },
  {
    "text": "xgboost so it shards that training set",
    "start": "511139",
    "end": "513719"
  },
  {
    "text": "of all those files figures out where to",
    "start": "513719",
    "end": "515760"
  },
  {
    "text": "send them and it uses this all reduce",
    "start": "515760",
    "end": "517740"
  },
  {
    "text": "function called rabbit which is the",
    "start": "517740",
    "end": "519599"
  },
  {
    "text": "reliable I'll reduce broadcast interface",
    "start": "519599",
    "end": "522419"
  },
  {
    "text": "so it integrates the results from each",
    "start": "522419",
    "end": "523979"
  },
  {
    "text": "worker into the global solution and then",
    "start": "523979",
    "end": "526740"
  },
  {
    "text": "you could using this you can basically",
    "start": "526740",
    "end": "528300"
  },
  {
    "text": "put as many workers as you want you",
    "start": "528300",
    "end": "530100"
  },
  {
    "text": "could have hundreds or thousands we've",
    "start": "530100",
    "end": "531360"
  },
  {
    "text": "never needed to go anywhere near that",
    "start": "531360",
    "end": "533339"
  },
  {
    "text": "crazy with it but like Ray makes that",
    "start": "533339",
    "end": "535560"
  },
  {
    "text": "possible and that's what's pretty",
    "start": "535560",
    "end": "536940"
  },
  {
    "text": "amazing is we're not doing any",
    "start": "536940",
    "end": "538920"
  },
  {
    "text": "distributed computing stuff in our code",
    "start": "538920",
    "end": "540899"
  },
  {
    "text": "we're just telling it where the data is",
    "start": "540899",
    "end": "543300"
  },
  {
    "text": "that there is a cluster and it just does",
    "start": "543300",
    "end": "546600"
  },
  {
    "text": "it",
    "start": "546600",
    "end": "547560"
  },
  {
    "text": "um",
    "start": "547560",
    "end": "548220"
  },
  {
    "text": "so bottlenecks so there are some things",
    "start": "548220",
    "end": "551100"
  },
  {
    "text": "that you can do to speed this up so for",
    "start": "551100",
    "end": "553320"
  },
  {
    "text": "example now we can load all our data",
    "start": "553320",
    "end": "555060"
  },
  {
    "text": "from The Source each worker is only",
    "start": "555060",
    "end": "557640"
  },
  {
    "text": "loading the data it needs but by default",
    "start": "557640",
    "end": "560160"
  },
  {
    "text": "it's going to do that over the S3 apis",
    "start": "560160",
    "end": "561720"
  },
  {
    "text": "which are https and those can sometimes",
    "start": "561720",
    "end": "564240"
  },
  {
    "text": "be not so fast we have gigabytes of",
    "start": "564240",
    "end": "566339"
  },
  {
    "text": "gigabytes of data to load then that can",
    "start": "566339",
    "end": "569519"
  },
  {
    "text": "become a bottleneck it can take hours to",
    "start": "569519",
    "end": "571620"
  },
  {
    "text": "like load that data from S3 into the",
    "start": "571620",
    "end": "573899"
  },
  {
    "text": "memory of your instances so like here's",
    "start": "573899",
    "end": "576420"
  },
  {
    "text": "an example of just default S3 apis it",
    "start": "576420",
    "end": "579420"
  },
  {
    "text": "was doing about 16 megabytes a second so",
    "start": "579420",
    "end": "581519"
  },
  {
    "text": "you can see how that can quickly become",
    "start": "581519",
    "end": "583440"
  },
  {
    "text": "a bottleneck",
    "start": "583440",
    "end": "585060"
  },
  {
    "text": "uh the second one is memory so",
    "start": "585060",
    "end": "587640"
  },
  {
    "text": "the way it works by default is it wants",
    "start": "587640",
    "end": "590040"
  },
  {
    "text": "xgboost wants the whole training data",
    "start": "590040",
    "end": "592380"
  },
  {
    "text": "set in memory there are some",
    "start": "592380",
    "end": "594000"
  },
  {
    "text": "experimental options to do kind of a",
    "start": "594000",
    "end": "596399"
  },
  {
    "text": "batch loading but they say it's not like",
    "start": "596399",
    "end": "599220"
  },
  {
    "text": "officially production ready at least",
    "start": "599220",
    "end": "601320"
  },
  {
    "text": "last time I checked but anyway this this",
    "start": "601320",
    "end": "603660"
  },
  {
    "text": "turns out to be really fast anyway if",
    "start": "603660",
    "end": "605279"
  },
  {
    "text": "you can fit it into memory because you",
    "start": "605279",
    "end": "606660"
  },
  {
    "text": "don't have to do all those",
    "start": "606660",
    "end": "607620"
  },
  {
    "text": "Transformations on the fly but the peak",
    "start": "607620",
    "end": "610080"
  },
  {
    "text": "memory usage can exceed about three",
    "start": "610080",
    "end": "612120"
  },
  {
    "text": "times the size of your actual data set",
    "start": "612120",
    "end": "614100"
  },
  {
    "text": "because of some conversions that happen",
    "start": "614100",
    "end": "615660"
  },
  {
    "text": "in there so xgboost if you're running it",
    "start": "615660",
    "end": "617880"
  },
  {
    "text": "on a 64-bit system it will convert all",
    "start": "617880",
    "end": "620279"
  },
  {
    "text": "those integers and floating points into",
    "start": "620279",
    "end": "622560"
  },
  {
    "text": "64-bit and so you want the lowest",
    "start": "622560",
    "end": "625320"
  },
  {
    "text": "Precision that's practical because it's",
    "start": "625320",
    "end": "627180"
  },
  {
    "text": "going to load some of your data from The",
    "start": "627180",
    "end": "629100"
  },
  {
    "text": "Source into memory and then it's going",
    "start": "629100",
    "end": "630300"
  },
  {
    "text": "to convert it into this D Matrix so it's",
    "start": "630300",
    "end": "631980"
  },
  {
    "text": "going to do both of these things in",
    "start": "631980",
    "end": "632880"
  },
  {
    "text": "memory at the same time",
    "start": "632880",
    "end": "634380"
  },
  {
    "text": "and so they actually boosts Ray docs",
    "start": "634380",
    "end": "636600"
  },
  {
    "text": "they show you some small like toy",
    "start": "636600",
    "end": "638459"
  },
  {
    "text": "examples but I'll show you the real ones",
    "start": "638459",
    "end": "640260"
  },
  {
    "text": "that we use so we have 263 numeric",
    "start": "640260",
    "end": "643620"
  },
  {
    "text": "inputs some managers some are floats an",
    "start": "643620",
    "end": "645839"
  },
  {
    "text": "average day's worth is 17 million",
    "start": "645839",
    "end": "647760"
  },
  {
    "text": "examples",
    "start": "647760",
    "end": "649260"
  },
  {
    "text": "so that's 4.47 billion data points so in",
    "start": "649260",
    "end": "652740"
  },
  {
    "text": "64-bit storage that ends up being about",
    "start": "652740",
    "end": "654360"
  },
  {
    "text": "36 gigabytes per day and if you train",
    "start": "654360",
    "end": "657420"
  },
  {
    "text": "six months of data at a time that 6.4",
    "start": "657420",
    "end": "659579"
  },
  {
    "text": "terabytes and so",
    "start": "659579",
    "end": "661560"
  },
  {
    "text": "what we found or what I found in like",
    "start": "661560",
    "end": "663600"
  },
  {
    "text": "actually training this thing and trying",
    "start": "663600",
    "end": "665100"
  },
  {
    "text": "to size the cluster right is it it can",
    "start": "665100",
    "end": "667380"
  },
  {
    "text": "eat about twice that memory so we've",
    "start": "667380",
    "end": "669720"
  },
  {
    "text": "often stood up clusters that are roughly",
    "start": "669720",
    "end": "672300"
  },
  {
    "text": "12 terabytes",
    "start": "672300",
    "end": "674820"
  },
  {
    "text": "of memory",
    "start": "674820",
    "end": "676260"
  },
  {
    "text": "uh the last one is disk speed so this is",
    "start": "676260",
    "end": "679140"
  },
  {
    "text": "a little less critical than the other",
    "start": "679140",
    "end": "680940"
  },
  {
    "text": "ones but it does matter right so",
    "start": "680940",
    "end": "682980"
  },
  {
    "text": "remember that each worker in the cluster",
    "start": "682980",
    "end": "684839"
  },
  {
    "text": "they have their own Object Store that",
    "start": "684839",
    "end": "687540"
  },
  {
    "text": "they write data to that needs to be fast",
    "start": "687540",
    "end": "689279"
  },
  {
    "text": "most of the cloud instances now have",
    "start": "689279",
    "end": "691560"
  },
  {
    "text": "solid state drives so this is less of a",
    "start": "691560",
    "end": "694680"
  },
  {
    "text": "concern but if you know they write to",
    "start": "694680",
    "end": "697260"
  },
  {
    "text": "Shared memory but if it starts",
    "start": "697260",
    "end": "698519"
  },
  {
    "text": "overflowing that's going to go to disk",
    "start": "698519",
    "end": "699959"
  },
  {
    "text": "so there's some help you can give it",
    "start": "699959",
    "end": "702060"
  },
  {
    "text": "there when that sort of thing starts",
    "start": "702060",
    "end": "703740"
  },
  {
    "text": "happening",
    "start": "703740",
    "end": "705480"
  },
  {
    "text": "so now let's talk about how we can speed",
    "start": "705480",
    "end": "708540"
  },
  {
    "text": "some of those things up so our objective",
    "start": "708540",
    "end": "711060"
  },
  {
    "text": "here is to get the training data from",
    "start": "711060",
    "end": "713399"
  },
  {
    "text": "the cloud into memory as quickly as",
    "start": "713399",
    "end": "715260"
  },
  {
    "text": "possible while not burning a bunch of",
    "start": "715260",
    "end": "717360"
  },
  {
    "text": "expensive ec2 time so Network file",
    "start": "717360",
    "end": "720480"
  },
  {
    "text": "systems turn out to be a pretty good",
    "start": "720480",
    "end": "721980"
  },
  {
    "text": "solution here because you can load those",
    "start": "721980",
    "end": "723839"
  },
  {
    "text": "ahead of time you don't have to do it",
    "start": "723839",
    "end": "726240"
  },
  {
    "text": "while the expensive training cluster is",
    "start": "726240",
    "end": "728519"
  },
  {
    "text": "up",
    "start": "728519",
    "end": "730140"
  },
  {
    "text": "um so Amazon has a few solutions for",
    "start": "730140",
    "end": "732420"
  },
  {
    "text": "this EFS elastic file store is a common",
    "start": "732420",
    "end": "735540"
  },
  {
    "text": "one that implements the NFS protocol but",
    "start": "735540",
    "end": "738300"
  },
  {
    "text": "there's actually a better one that's",
    "start": "738300",
    "end": "739800"
  },
  {
    "text": "highly optimized for like machine",
    "start": "739800",
    "end": "741420"
  },
  {
    "text": "learning and data processing and",
    "start": "741420",
    "end": "743399"
  },
  {
    "text": "analytics and so it's FSX for luster and",
    "start": "743399",
    "end": "745740"
  },
  {
    "text": "it's basically uh posix compliant file",
    "start": "745740",
    "end": "748620"
  },
  {
    "text": "system that you can set up ahead of time",
    "start": "748620",
    "end": "750300"
  },
  {
    "text": "and it'll basically map an S3 some",
    "start": "750300",
    "end": "754019"
  },
  {
    "text": "location inside S3 to the mount on the",
    "start": "754019",
    "end": "756600"
  },
  {
    "text": "file system and so that has uh sub",
    "start": "756600",
    "end": "760740"
  },
  {
    "text": "I'm sorry yeah that has microsecond like",
    "start": "760740",
    "end": "763260"
  },
  {
    "text": "latency gigabits per second of",
    "start": "763260",
    "end": "765540"
  },
  {
    "text": "throughput and millions of iops so it's",
    "start": "765540",
    "end": "767700"
  },
  {
    "text": "really fast and it basically acts as a",
    "start": "767700",
    "end": "770519"
  },
  {
    "text": "high performance cache that appears as a",
    "start": "770519",
    "end": "772500"
  },
  {
    "text": "Linux file system so you can really",
    "start": "772500",
    "end": "774779"
  },
  {
    "text": "maximize throughput here",
    "start": "774779",
    "end": "776880"
  },
  {
    "text": "so this table shows you kind of how fast",
    "start": "776880",
    "end": "779399"
  },
  {
    "text": "that thing can go",
    "start": "779399",
    "end": "781279"
  },
  {
    "text": "so it scales with the size and the type",
    "start": "781279",
    "end": "783959"
  },
  {
    "text": "of the volume I usually use the scratch",
    "start": "783959",
    "end": "786120"
  },
  {
    "text": "instances because we don't really need",
    "start": "786120",
    "end": "787620"
  },
  {
    "text": "it to be",
    "start": "787620",
    "end": "788760"
  },
  {
    "text": "blazing fast paying as much as possible",
    "start": "788760",
    "end": "791339"
  },
  {
    "text": "but even the scratch ones you get 200",
    "start": "791339",
    "end": "793560"
  },
  {
    "text": "megabytes per second for every terabyte",
    "start": "793560",
    "end": "795600"
  },
  {
    "text": "of storage and for that particular class",
    "start": "795600",
    "end": "798300"
  },
  {
    "text": "I think 9.6 terabytes is the maximum you",
    "start": "798300",
    "end": "801060"
  },
  {
    "text": "can use so that's the Baseline of",
    "start": "801060",
    "end": "804019"
  },
  {
    "text": "1920 megabytes a second or about two",
    "start": "804019",
    "end": "806579"
  },
  {
    "text": "gigabytes a second it can burst up to 12",
    "start": "806579",
    "end": "808620"
  },
  {
    "text": "gigabytes a second",
    "start": "808620",
    "end": "810120"
  },
  {
    "text": "so if you provision the persistent",
    "start": "810120",
    "end": "811980"
  },
  {
    "text": "volumes you get a high availability on",
    "start": "811980",
    "end": "813660"
  },
  {
    "text": "top of that so if you want that volume",
    "start": "813660",
    "end": "815040"
  },
  {
    "text": "to just live around for a while and you",
    "start": "815040",
    "end": "816540"
  },
  {
    "text": "want your data there maybe you want to",
    "start": "816540",
    "end": "817680"
  },
  {
    "text": "train multiple times or you want to do",
    "start": "817680",
    "end": "819180"
  },
  {
    "text": "different stuff with it that's an option",
    "start": "819180",
    "end": "821399"
  },
  {
    "text": "the Baseline on that is uh I think 2.6",
    "start": "821399",
    "end": "824279"
  },
  {
    "text": "gigabytes",
    "start": "824279",
    "end": "825600"
  },
  {
    "text": "or no 2600 megabytes per second per",
    "start": "825600",
    "end": "828060"
  },
  {
    "text": "terabyte so it's about 13 times faster",
    "start": "828060",
    "end": "830820"
  },
  {
    "text": "than the scratch which is what we use",
    "start": "830820",
    "end": "833040"
  },
  {
    "text": "so you can really you know go Full",
    "start": "833040",
    "end": "835740"
  },
  {
    "text": "Throttle on this thing if you need to",
    "start": "835740",
    "end": "837180"
  },
  {
    "text": "which is really cool this is an example",
    "start": "837180",
    "end": "838980"
  },
  {
    "text": "of what it takes to set one up it's",
    "start": "838980",
    "end": "840660"
  },
  {
    "text": "really simple this is just the AWS",
    "start": "840660",
    "end": "843440"
  },
  {
    "text": "CLI command so you're telling it you",
    "start": "843440",
    "end": "846060"
  },
  {
    "text": "want this luster file system how much",
    "start": "846060",
    "end": "847860"
  },
  {
    "text": "SSD type which subnets and region tags",
    "start": "847860",
    "end": "852959"
  },
  {
    "text": "you can also so you can see there it's",
    "start": "852959",
    "end": "855779"
  },
  {
    "text": "I'm mapping that particular path in the",
    "start": "855779",
    "end": "858959"
  },
  {
    "text": "S3 bucket to and that's going to be",
    "start": "858959",
    "end": "860820"
  },
  {
    "text": "mounted in the root file system when we",
    "start": "860820",
    "end": "862980"
  },
  {
    "text": "mount it to the instance",
    "start": "862980",
    "end": "864839"
  },
  {
    "text": "so this is pretty easy you can add data",
    "start": "864839",
    "end": "867899"
  },
  {
    "text": "compression if you want to in our case",
    "start": "867899",
    "end": "869399"
  },
  {
    "text": "it didn't really help me because we have",
    "start": "869399",
    "end": "870660"
  },
  {
    "text": "compressed parquet files so compressing",
    "start": "870660",
    "end": "873120"
  },
  {
    "text": "it again would save you some disk space",
    "start": "873120",
    "end": "874920"
  },
  {
    "text": "but we weren't using all 9.6 terabytes",
    "start": "874920",
    "end": "877320"
  },
  {
    "text": "so",
    "start": "877320",
    "end": "878220"
  },
  {
    "text": "there's really no no real reason to add",
    "start": "878220",
    "end": "880740"
  },
  {
    "text": "that overhead for us so",
    "start": "880740",
    "end": "883800"
  },
  {
    "text": "this is an example of how you would",
    "start": "883800",
    "end": "885240"
  },
  {
    "text": "mount it so like if you had your own",
    "start": "885240",
    "end": "886620"
  },
  {
    "text": "cluster and you were doing that with",
    "start": "886620",
    "end": "888000"
  },
  {
    "text": "yaml that's uh this is how you might do",
    "start": "888000",
    "end": "890160"
  },
  {
    "text": "it so you basically just create this",
    "start": "890160",
    "end": "892199"
  },
  {
    "text": "slash FSX folder or wherever you want",
    "start": "892199",
    "end": "894600"
  },
  {
    "text": "then you do this Mount command this",
    "start": "894600",
    "end": "896820"
  },
  {
    "text": "basically comes straight out of the AWS",
    "start": "896820",
    "end": "898440"
  },
  {
    "text": "Docs",
    "start": "898440",
    "end": "899639"
  },
  {
    "text": "and uh one of the best tricks here is",
    "start": "899639",
    "end": "901500"
  },
  {
    "text": "you can pre-populate this file system so",
    "start": "901500",
    "end": "903420"
  },
  {
    "text": "by default it's like a right through",
    "start": "903420",
    "end": "905040"
  },
  {
    "text": "cache so it's gonna when you request a",
    "start": "905040",
    "end": "907440"
  },
  {
    "text": "file it's going to load it from S3 it's",
    "start": "907440",
    "end": "909000"
  },
  {
    "text": "going to put on the disk and then it's",
    "start": "909000",
    "end": "910079"
  },
  {
    "text": "going to give it to you and so you can",
    "start": "910079",
    "end": "912600"
  },
  {
    "text": "go in here ahead of time with like a",
    "start": "912600",
    "end": "914279"
  },
  {
    "text": "really cheap instance like a T2 medium",
    "start": "914279",
    "end": "916440"
  },
  {
    "text": "or something and you can just issue",
    "start": "916440",
    "end": "918420"
  },
  {
    "text": "these commands like this command would",
    "start": "918420",
    "end": "920279"
  },
  {
    "text": "go to that directory find everything in",
    "start": "920279",
    "end": "922620"
  },
  {
    "text": "September that's a parquet file and this",
    "start": "922620",
    "end": "925440"
  },
  {
    "text": "lfsh sun restores this also comes from",
    "start": "925440",
    "end": "927839"
  },
  {
    "text": "the AWS docs it's like a little hidden",
    "start": "927839",
    "end": "929579"
  },
  {
    "text": "trick that's in there that'll basically",
    "start": "929579",
    "end": "931800"
  },
  {
    "text": "go ahead and take all the data from S3",
    "start": "931800",
    "end": "933720"
  },
  {
    "text": "and put it on that disk and so that way",
    "start": "933720",
    "end": "935940"
  },
  {
    "text": "it's uh as close as possible to the",
    "start": "935940",
    "end": "938579"
  },
  {
    "text": "instance when you need it and this is",
    "start": "938579",
    "end": "940860"
  },
  {
    "text": "really fast this loaded about 40",
    "start": "940860",
    "end": "943199"
  },
  {
    "text": "gigabytes of data which is about a month",
    "start": "943199",
    "end": "944880"
  },
  {
    "text": "of parquet data for us in about two",
    "start": "944880",
    "end": "946980"
  },
  {
    "text": "minutes",
    "start": "946980",
    "end": "947820"
  },
  {
    "text": "and we can load six months of training",
    "start": "947820",
    "end": "950160"
  },
  {
    "text": "data in under 20 minutes so when you",
    "start": "950160",
    "end": "952199"
  },
  {
    "text": "think about what we showed before where",
    "start": "952199",
    "end": "954180"
  },
  {
    "text": "it's like just downloading all the stuff",
    "start": "954180",
    "end": "955860"
  },
  {
    "text": "over S3 apis while the ec2 is just",
    "start": "955860",
    "end": "958500"
  },
  {
    "text": "sitting there burning the clock this we",
    "start": "958500",
    "end": "960779"
  },
  {
    "text": "can do we're not burning any ec2 time we",
    "start": "960779",
    "end": "963180"
  },
  {
    "text": "just load it all into this really fast",
    "start": "963180",
    "end": "965220"
  },
  {
    "text": "cache disk and then when we do spin up",
    "start": "965220",
    "end": "967920"
  },
  {
    "text": "the cluster we mount it all this data is",
    "start": "967920",
    "end": "970620"
  },
  {
    "text": "there immediately",
    "start": "970620",
    "end": "973320"
  },
  {
    "text": "um so memory is the next thing right we",
    "start": "973320",
    "end": "975060"
  },
  {
    "text": "calculated earlier we're going to",
    "start": "975060",
    "end": "976320"
  },
  {
    "text": "potentially need terabytes of memory to",
    "start": "976320",
    "end": "979019"
  },
  {
    "text": "load and transform this into that native",
    "start": "979019",
    "end": "981360"
  },
  {
    "text": "xgboost D Matrix",
    "start": "981360",
    "end": "983820"
  },
  {
    "text": "so for smaller jobs the R6 family is",
    "start": "983820",
    "end": "985980"
  },
  {
    "text": "pretty nice it's high memory uh compared",
    "start": "985980",
    "end": "988019"
  },
  {
    "text": "to the CPU but they only go up to one",
    "start": "988019",
    "end": "990779"
  },
  {
    "text": "terabyte so you end up having a whole",
    "start": "990779",
    "end": "992880"
  },
  {
    "text": "bunch of these together not only does it",
    "start": "992880",
    "end": "994440"
  },
  {
    "text": "get expensive but then you have like a",
    "start": "994440",
    "end": "995699"
  },
  {
    "text": "lot of cross-network talk",
    "start": "995699",
    "end": "997560"
  },
  {
    "text": "so what I ended up using or what we use",
    "start": "997560",
    "end": "1000199"
  },
  {
    "text": "most of the time is these x2i instances",
    "start": "1000199",
    "end": "1002300"
  },
  {
    "text": "so there's different types of high",
    "start": "1002300",
    "end": "1004639"
  },
  {
    "text": "memory instances this one has a really",
    "start": "1004639",
    "end": "1006199"
  },
  {
    "text": "high memory to CPU ratio they can",
    "start": "1006199",
    "end": "1008240"
  },
  {
    "text": "support up to four terabytes per",
    "start": "1008240",
    "end": "1010220"
  },
  {
    "text": "instance the network transfer rates up",
    "start": "1010220",
    "end": "1013160"
  },
  {
    "text": "to 100 gigabits and it comes with some",
    "start": "1013160",
    "end": "1015920"
  },
  {
    "text": "extra nvme drives attached to it which",
    "start": "1015920",
    "end": "1019160"
  },
  {
    "text": "I'll get to in a second so I get better",
    "start": "1019160",
    "end": "1021019"
  },
  {
    "text": "utilization by having fewer machines",
    "start": "1021019",
    "end": "1023060"
  },
  {
    "text": "that are really big than I do from like",
    "start": "1023060",
    "end": "1025699"
  },
  {
    "text": "a lot of machines that are smaller and",
    "start": "1025699",
    "end": "1027678"
  },
  {
    "text": "talking to each other",
    "start": "1027679",
    "end": "1029959"
  },
  {
    "text": "um and so the hourly rate here you know",
    "start": "1029959",
    "end": "1031760"
  },
  {
    "text": "that look it might look a little",
    "start": "1031760",
    "end": "1032780"
  },
  {
    "text": "daunting at 26 an hour but this is going",
    "start": "1032780",
    "end": "1035178"
  },
  {
    "text": "to be so efficient that it really isn't",
    "start": "1035179",
    "end": "1036740"
  },
  {
    "text": "a big deal at all and it actually is",
    "start": "1036740",
    "end": "1038298"
  },
  {
    "text": "cheaper than running the R6 instances so",
    "start": "1038299",
    "end": "1041418"
  },
  {
    "text": "like a",
    "start": "1041419",
    "end": "1042620"
  },
  {
    "text": "I think a one terabyte r6i and since",
    "start": "1042620",
    "end": "1044540"
  },
  {
    "text": "it's about eight dollars an hour the one",
    "start": "1044540",
    "end": "1046220"
  },
  {
    "text": "terabyte here is seven dollars an hour",
    "start": "1046220",
    "end": "1047839"
  },
  {
    "text": "and if we if we put a bunch of our sixes",
    "start": "1047839",
    "end": "1051020"
  },
  {
    "text": "together it would come up to higher than",
    "start": "1051020",
    "end": "1052880"
  },
  {
    "text": "the cost to that one instance to get the",
    "start": "1052880",
    "end": "1054620"
  },
  {
    "text": "same amount of memory and CPU capacity",
    "start": "1054620",
    "end": "1059600"
  },
  {
    "text": "um so just as since these nvme drives",
    "start": "1059600",
    "end": "1062660"
  },
  {
    "text": "are there they're not mounted by default",
    "start": "1062660",
    "end": "1064340"
  },
  {
    "text": "but uh it's not hard to do that you have",
    "start": "1064340",
    "end": "1066919"
  },
  {
    "text": "to format them and mount them so like",
    "start": "1066919",
    "end": "1069200"
  },
  {
    "text": "when we have a manual cluster set up",
    "start": "1069200",
    "end": "1071419"
  },
  {
    "text": "this is an example of how you could do",
    "start": "1071419",
    "end": "1073039"
  },
  {
    "text": "that just inside the like the ray",
    "start": "1073039",
    "end": "1074600"
  },
  {
    "text": "clustering ammo HD parm just forces the",
    "start": "1074600",
    "end": "1077360"
  },
  {
    "text": "kernel to rescan the partition table and",
    "start": "1077360",
    "end": "1079640"
  },
  {
    "text": "then you formatted an xfs or whatever",
    "start": "1079640",
    "end": "1081500"
  },
  {
    "text": "you want you make a slash data directory",
    "start": "1081500",
    "end": "1084919"
  },
  {
    "text": "you mount that drive there and then you",
    "start": "1084919",
    "end": "1087080"
  },
  {
    "text": "change the ownership this case ec2 user",
    "start": "1087080",
    "end": "1090020"
  },
  {
    "text": "is just the default Amazon Linux user",
    "start": "1090020",
    "end": "1092720"
  },
  {
    "text": "but if you had Ubuntu or something else",
    "start": "1092720",
    "end": "1094580"
  },
  {
    "text": "that would just be a slightly different",
    "start": "1094580",
    "end": "1095840"
  },
  {
    "text": "command but",
    "start": "1095840",
    "end": "1097100"
  },
  {
    "text": "you want the user to own it instead of",
    "start": "1097100",
    "end": "1099740"
  },
  {
    "text": "roots so that when Ray processes they're",
    "start": "1099740",
    "end": "1102200"
  },
  {
    "text": "running in user space they can write to",
    "start": "1102200",
    "end": "1104419"
  },
  {
    "text": "it and they don't have any issues there",
    "start": "1104419",
    "end": "1107179"
  },
  {
    "text": "so this is where that really comes in",
    "start": "1107179",
    "end": "1109100"
  },
  {
    "text": "handy because now when you start the ray",
    "start": "1109100",
    "end": "1111500"
  },
  {
    "text": "head node you can pass this you see in",
    "start": "1111500",
    "end": "1113480"
  },
  {
    "text": "the middle of this there's this uh",
    "start": "1113480",
    "end": "1114919"
  },
  {
    "text": "system config for object spilling and",
    "start": "1114919",
    "end": "1117500"
  },
  {
    "text": "you can tell it",
    "start": "1117500",
    "end": "1118820"
  },
  {
    "text": "when you spill objects I want you to",
    "start": "1118820",
    "end": "1120679"
  },
  {
    "text": "write it to slash data and so what",
    "start": "1120679",
    "end": "1122480"
  },
  {
    "text": "that's going to do is now it's going to",
    "start": "1122480",
    "end": "1124039"
  },
  {
    "text": "write any over over yeah spillage to",
    "start": "1124039",
    "end": "1128299"
  },
  {
    "text": "that nvme drive which is really fast and",
    "start": "1128299",
    "end": "1132080"
  },
  {
    "text": "so",
    "start": "1132080",
    "end": "1133340"
  },
  {
    "text": "if your cluster size is like with a lot",
    "start": "1133340",
    "end": "1135500"
  },
  {
    "text": "of overhead you might not run into this",
    "start": "1135500",
    "end": "1136880"
  },
  {
    "text": "but if you're trying to like squeeze out",
    "start": "1136880",
    "end": "1138320"
  },
  {
    "text": "as much uh",
    "start": "1138320",
    "end": "1139640"
  },
  {
    "text": "you know efficiency as you can on your",
    "start": "1139640",
    "end": "1141559"
  },
  {
    "text": "instances this helps because eventually",
    "start": "1141559",
    "end": "1143539"
  },
  {
    "text": "it'll start spilling to disk and you'll",
    "start": "1143539",
    "end": "1145039"
  },
  {
    "text": "have to read some of that stuff back and",
    "start": "1145039",
    "end": "1146900"
  },
  {
    "text": "that'll help a lot another thing you can",
    "start": "1146900",
    "end": "1149419"
  },
  {
    "text": "do is update uh what type of EBS storage",
    "start": "1149419",
    "end": "1152960"
  },
  {
    "text": "you have attached to it to the root disk",
    "start": "1152960",
    "end": "1156020"
  },
  {
    "text": "so you don't have to go too crazy here",
    "start": "1156020",
    "end": "1157400"
  },
  {
    "text": "but",
    "start": "1157400",
    "end": "1158960"
  },
  {
    "text": "um like you know it sometimes writes",
    "start": "1158960",
    "end": "1161299"
  },
  {
    "text": "things to the temp folder or you may",
    "start": "1161299",
    "end": "1162980"
  },
  {
    "text": "just need to read something you can get",
    "start": "1162980",
    "end": "1165020"
  },
  {
    "text": "a lot of iops which are expensive to",
    "start": "1165020",
    "end": "1168020"
  },
  {
    "text": "keep around for a long time but when you",
    "start": "1168020",
    "end": "1170059"
  },
  {
    "text": "just have a cluster that comes up and",
    "start": "1170059",
    "end": "1171320"
  },
  {
    "text": "goes down within a number of hours it's",
    "start": "1171320",
    "end": "1173960"
  },
  {
    "text": "pretty negligible so that's another",
    "start": "1173960",
    "end": "1176000"
  },
  {
    "text": "thing we sometimes do",
    "start": "1176000",
    "end": "1178100"
  },
  {
    "text": "so metrics",
    "start": "1178100",
    "end": "1180679"
  },
  {
    "text": "so oh",
    "start": "1180679",
    "end": "1183760"
  },
  {
    "text": "yeah so so here's an example this is a",
    "start": "1185120",
    "end": "1187280"
  },
  {
    "text": "three node cluster of those four",
    "start": "1187280",
    "end": "1188780"
  },
  {
    "text": "terabyte x2i instances they load data in",
    "start": "1188780",
    "end": "1191480"
  },
  {
    "text": "parallel so each worker is loading over",
    "start": "1191480",
    "end": "1193660"
  },
  {
    "text": "530 megabytes a second here and I've",
    "start": "1193660",
    "end": "1196760"
  },
  {
    "text": "seen this peak over a gigabyte a second",
    "start": "1196760",
    "end": "1198380"
  },
  {
    "text": "and some of the training runs I've done",
    "start": "1198380",
    "end": "1199940"
  },
  {
    "text": "and you remember it was about 18",
    "start": "1199940",
    "end": "1202220"
  },
  {
    "text": "megabytes a second and the default S3",
    "start": "1202220",
    "end": "1204200"
  },
  {
    "text": "config so you have about a 30X speed up",
    "start": "1204200",
    "end": "1206539"
  },
  {
    "text": "here just by having this disk available",
    "start": "1206539",
    "end": "1208360"
  },
  {
    "text": "and If you recall it didn't waste any",
    "start": "1208360",
    "end": "1211700"
  },
  {
    "text": "time to do that it took about 20 minutes",
    "start": "1211700",
    "end": "1213620"
  },
  {
    "text": "to populate all six months of data into",
    "start": "1213620",
    "end": "1216200"
  },
  {
    "text": "that disk cache",
    "start": "1216200",
    "end": "1218780"
  },
  {
    "text": "so that was just a really quick step we",
    "start": "1218780",
    "end": "1220940"
  },
  {
    "text": "had to do before speeding it or spinning",
    "start": "1220940",
    "end": "1223100"
  },
  {
    "text": "up the cluster so this just saves tons",
    "start": "1223100",
    "end": "1227059"
  },
  {
    "text": "of time and that way all the ec2 time",
    "start": "1227059",
    "end": "1230179"
  },
  {
    "text": "you're paying for is literally just",
    "start": "1230179",
    "end": "1231620"
  },
  {
    "text": "training time it's not spending time",
    "start": "1231620",
    "end": "1233240"
  },
  {
    "text": "just loading and loading and loading",
    "start": "1233240",
    "end": "1234860"
  },
  {
    "text": "data",
    "start": "1234860",
    "end": "1235820"
  },
  {
    "text": "so that's pretty pretty fast so here's",
    "start": "1235820",
    "end": "1238160"
  },
  {
    "text": "uh just an example I trained on one",
    "start": "1238160",
    "end": "1240500"
  },
  {
    "text": "month of data just to get some numbers",
    "start": "1240500",
    "end": "1241880"
  },
  {
    "text": "for this presentation",
    "start": "1241880",
    "end": "1243940"
  },
  {
    "text": "so all of these instances have one",
    "start": "1243940",
    "end": "1246200"
  },
  {
    "text": "terabyte memory of each so I put two of",
    "start": "1246200",
    "end": "1249080"
  },
  {
    "text": "them together for two terabytes",
    "start": "1249080",
    "end": "1251059"
  },
  {
    "text": "so in this example let's take about 32",
    "start": "1251059",
    "end": "1252860"
  },
  {
    "text": "minutes to load all the data from S3 and",
    "start": "1252860",
    "end": "1255440"
  },
  {
    "text": "train on it in the in the default",
    "start": "1255440",
    "end": "1257299"
  },
  {
    "text": "example where it was using s3fs",
    "start": "1257299",
    "end": "1260120"
  },
  {
    "text": "but then moving to luster that cut that",
    "start": "1260120",
    "end": "1262100"
  },
  {
    "text": "in half and we got a small reduction in",
    "start": "1262100",
    "end": "1264320"
  },
  {
    "text": "the pure training time as well it's a",
    "start": "1264320",
    "end": "1265820"
  },
  {
    "text": "little more efficient so this was about",
    "start": "1265820",
    "end": "1267320"
  },
  {
    "text": "16 minutes",
    "start": "1267320",
    "end": "1268580"
  },
  {
    "text": "the X2 instance is also cut the training",
    "start": "1268580",
    "end": "1272000"
  },
  {
    "text": "time slightly but it's pretty similar on",
    "start": "1272000",
    "end": "1273860"
  },
  {
    "text": "a small data set you get the bigger and",
    "start": "1273860",
    "end": "1275720"
  },
  {
    "text": "bigger instances or I'm sorry data sets",
    "start": "1275720",
    "end": "1277760"
  },
  {
    "text": "that uh that x2i comes in handy as well",
    "start": "1277760",
    "end": "1281360"
  },
  {
    "text": "as those nvme drives if you start",
    "start": "1281360",
    "end": "1282860"
  },
  {
    "text": "spilling to disk then it starts being",
    "start": "1282860",
    "end": "1284539"
  },
  {
    "text": "more noticeable that those things are",
    "start": "1284539",
    "end": "1286460"
  },
  {
    "text": "really helping you out",
    "start": "1286460",
    "end": "1288200"
  },
  {
    "text": "and in our real world in-house training",
    "start": "1288200",
    "end": "1290600"
  },
  {
    "text": "on six months of data it was taking",
    "start": "1290600",
    "end": "1292100"
  },
  {
    "text": "around nine to ten hours at least to",
    "start": "1292100",
    "end": "1293960"
  },
  {
    "text": "train on the full six months and all",
    "start": "1293960",
    "end": "1295580"
  },
  {
    "text": "like more than half of that was just",
    "start": "1295580",
    "end": "1297559"
  },
  {
    "text": "loading data from S3 and it was",
    "start": "1297559",
    "end": "1299240"
  },
  {
    "text": "expensive and kind of a waste but um and",
    "start": "1299240",
    "end": "1302059"
  },
  {
    "text": "if something happened like in the middle",
    "start": "1302059",
    "end": "1303860"
  },
  {
    "text": "of that and your cluster died well guess",
    "start": "1303860",
    "end": "1306020"
  },
  {
    "text": "what you've got to start that all over",
    "start": "1306020",
    "end": "1307400"
  },
  {
    "text": "again so you end up just wasting money",
    "start": "1307400",
    "end": "1309140"
  },
  {
    "text": "while you're developing this thing",
    "start": "1309140",
    "end": "1311200"
  },
  {
    "text": "whereas your whole cluster can go down",
    "start": "1311200",
    "end": "1313940"
  },
  {
    "text": "with this luster file system it doesn't",
    "start": "1313940",
    "end": "1315559"
  },
  {
    "text": "matter because that's decoupled from the",
    "start": "1315559",
    "end": "1317299"
  },
  {
    "text": "instances right so you can have any",
    "start": "1317299",
    "end": "1318980"
  },
  {
    "text": "number of machines pulling data out of",
    "start": "1318980",
    "end": "1321500"
  },
  {
    "text": "that disk at the same time and it does",
    "start": "1321500",
    "end": "1324140"
  },
  {
    "text": "they don't affect each other right",
    "start": "1324140",
    "end": "1326179"
  },
  {
    "text": "so that cut our training time down to",
    "start": "1326179",
    "end": "1328400"
  },
  {
    "text": "around four hours and that's four hours",
    "start": "1328400",
    "end": "1330260"
  },
  {
    "text": "spent just crunching numbers in XT boost",
    "start": "1330260",
    "end": "1332780"
  },
  {
    "text": "it's not really doing anything other",
    "start": "1332780",
    "end": "1334820"
  },
  {
    "text": "than what it's supposed to so",
    "start": "1334820",
    "end": "1337640"
  },
  {
    "text": "um",
    "start": "1337640",
    "end": "1339640"
  },
  {
    "text": "so looking at like what does this",
    "start": "1339799",
    "end": "1341659"
  },
  {
    "text": "actually cost it sounds expensive but",
    "start": "1341659",
    "end": "1343340"
  },
  {
    "text": "it's really not expensive at all so you",
    "start": "1343340",
    "end": "1345320"
  },
  {
    "text": "know you have your scratch file system",
    "start": "1345320",
    "end": "1346580"
  },
  {
    "text": "it's like 14 6 14 cents per gigabyte a",
    "start": "1346580",
    "end": "1349280"
  },
  {
    "text": "month it's so that whole almost 10",
    "start": "1349280",
    "end": "1351799"
  },
  {
    "text": "terabyte disk for the five hours of use",
    "start": "1351799",
    "end": "1353539"
  },
  {
    "text": "it's under 10 bucks",
    "start": "1353539",
    "end": "1355159"
  },
  {
    "text": "that ec2 time it's obviously the most",
    "start": "1355159",
    "end": "1357200"
  },
  {
    "text": "expensive each one of those is about 26",
    "start": "1357200",
    "end": "1358880"
  },
  {
    "text": "bucks an hour but we're not using them",
    "start": "1358880",
    "end": "1360320"
  },
  {
    "text": "for super long so it's 320 bucks",
    "start": "1360320",
    "end": "1362780"
  },
  {
    "text": "um provisioned I O like this is optional",
    "start": "1362780",
    "end": "1365120"
  },
  {
    "text": "but you could take it or leave it when",
    "start": "1365120",
    "end": "1366440"
  },
  {
    "text": "you see how cheap it is I mean it's not",
    "start": "1366440",
    "end": "1368299"
  },
  {
    "text": "a huge deal to throw that in there",
    "start": "1368299",
    "end": "1372039"
  },
  {
    "text": "so just yeah it's about roughly 350",
    "start": "1372140",
    "end": "1374360"
  },
  {
    "text": "dollars for us to train this model on",
    "start": "1374360",
    "end": "1376280"
  },
  {
    "text": "six months of data and these are pretty",
    "start": "1376280",
    "end": "1377900"
  },
  {
    "text": "good costs if you're used to neural",
    "start": "1377900",
    "end": "1380360"
  },
  {
    "text": "networks and GPU training and all this",
    "start": "1380360",
    "end": "1382100"
  },
  {
    "text": "this is like a drop in the bucket in",
    "start": "1382100",
    "end": "1383780"
  },
  {
    "text": "your budget but it's not it's just",
    "start": "1383780",
    "end": "1386240"
  },
  {
    "text": "always helps with developer you know",
    "start": "1386240",
    "end": "1388100"
  },
  {
    "text": "productivity the swords the loop and you",
    "start": "1388100",
    "end": "1391220"
  },
  {
    "text": "know you can do a lot of stuff with this",
    "start": "1391220",
    "end": "1393380"
  },
  {
    "text": "data at the same time it's just loaded",
    "start": "1393380",
    "end": "1395179"
  },
  {
    "text": "on this disk so",
    "start": "1395179",
    "end": "1398260"
  },
  {
    "text": "left so so that's that's all I had but I",
    "start": "1399860",
    "end": "1403520"
  },
  {
    "text": "guess we have time for some questions if",
    "start": "1403520",
    "end": "1404960"
  },
  {
    "text": "anybody had any and this is a there's a",
    "start": "1404960",
    "end": "1407299"
  },
  {
    "text": "link to our foresight labs this is like",
    "start": "1407299",
    "end": "1408740"
  },
  {
    "text": "a little uh kind of a fun thing we put",
    "start": "1408740",
    "end": "1411200"
  },
  {
    "text": "out there where we have a few models",
    "start": "1411200",
    "end": "1413120"
  },
  {
    "text": "that we people want to play with them",
    "start": "1413120",
    "end": "1414860"
  },
  {
    "text": "these specifically are our team our",
    "start": "1414860",
    "end": "1417200"
  },
  {
    "text": "machine learning team puts these out and",
    "start": "1417200",
    "end": "1418820"
  },
  {
    "text": "so there's one of these you can choose",
    "start": "1418820",
    "end": "1420380"
  },
  {
    "text": "for uh arrival runways and you can like",
    "start": "1420380",
    "end": "1422900"
  },
  {
    "text": "pick random flights and it'll show you",
    "start": "1422900",
    "end": "1424580"
  },
  {
    "text": "the graphs of like what it thinks like",
    "start": "1424580",
    "end": "1427340"
  },
  {
    "text": "it'll do both ones that have already",
    "start": "1427340",
    "end": "1428780"
  },
  {
    "text": "landed as well as ones that are in the",
    "start": "1428780",
    "end": "1430039"
  },
  {
    "text": "air so you can get like real time where",
    "start": "1430039",
    "end": "1431480"
  },
  {
    "text": "do I think this airplane is going to",
    "start": "1431480",
    "end": "1432679"
  },
  {
    "text": "land and what's happening with it so",
    "start": "1432679",
    "end": "1435500"
  },
  {
    "text": "um yeah this is a fun little thing we",
    "start": "1435500",
    "end": "1437299"
  },
  {
    "text": "put out there we use streamlit which is",
    "start": "1437299",
    "end": "1438799"
  },
  {
    "text": "a really cool thing if you've never",
    "start": "1438799",
    "end": "1440120"
  },
  {
    "text": "worked with a python visualization app",
    "start": "1440120",
    "end": "1442220"
  },
  {
    "text": "but uh",
    "start": "1442220",
    "end": "1443960"
  },
  {
    "text": "yeah that's all I had so",
    "start": "1443960",
    "end": "1447520"
  },
  {
    "text": "so the question was did we try live gvm",
    "start": "1449780",
    "end": "1452000"
  },
  {
    "text": "and yeah we did try light GBM so we had",
    "start": "1452000",
    "end": "1454460"
  },
  {
    "text": "some older models running on light GBM",
    "start": "1454460",
    "end": "1456140"
  },
  {
    "text": "we were pretty happy with the",
    "start": "1456140",
    "end": "1457100"
  },
  {
    "text": "performance there when we when I",
    "start": "1457100",
    "end": "1459260"
  },
  {
    "text": "researched this particular one",
    "start": "1459260",
    "end": "1461960"
  },
  {
    "text": "I tried xgbooth slide GBM and catboost",
    "start": "1461960",
    "end": "1465200"
  },
  {
    "text": "on the same data sets and they were",
    "start": "1465200",
    "end": "1466760"
  },
  {
    "text": "pretty similar but xgboost was the",
    "start": "1466760",
    "end": "1468740"
  },
  {
    "text": "winner in most cases so we just moved",
    "start": "1468740",
    "end": "1470780"
  },
  {
    "text": "forward with that but but I think light",
    "start": "1470780",
    "end": "1472880"
  },
  {
    "text": "GBM also has a version that runs on Ray",
    "start": "1472880",
    "end": "1475640"
  },
  {
    "text": "so I think you can also scale that out",
    "start": "1475640",
    "end": "1477440"
  },
  {
    "text": "as well yeah",
    "start": "1477440",
    "end": "1480100"
  },
  {
    "text": "yeah oh really that's",
    "start": "1484100",
    "end": "1487120"
  },
  {
    "text": "important oh that's good to know maybe",
    "start": "1490940",
    "end": "1492320"
  },
  {
    "text": "next time we reevaluate whether we're",
    "start": "1492320",
    "end": "1494240"
  },
  {
    "text": "gonna update it we'll look into that",
    "start": "1494240",
    "end": "1495679"
  },
  {
    "text": "because it would be nice to take that",
    "start": "1495679",
    "end": "1496880"
  },
  {
    "text": "memory pressure off but and at the end",
    "start": "1496880",
    "end": "1499220"
  },
  {
    "text": "of the day as you saw like the memory so",
    "start": "1499220",
    "end": "1500600"
  },
  {
    "text": "cheap it almost doesn't matter because",
    "start": "1500600",
    "end": "1501919"
  },
  {
    "text": "like if I spent one day like",
    "start": "1501919",
    "end": "1504080"
  },
  {
    "text": "didn't like just moving it over it would",
    "start": "1504080",
    "end": "1506240"
  },
  {
    "text": "exceed the cost of the training so",
    "start": "1506240",
    "end": "1509240"
  },
  {
    "text": "any other questions",
    "start": "1509240",
    "end": "1511960"
  },
  {
    "text": "so you're asking if we delete it after",
    "start": "1523460",
    "end": "1525620"
  },
  {
    "text": "training yes",
    "start": "1525620",
    "end": "1528400"
  },
  {
    "text": "no you can leave it you can leave it",
    "start": "1536080",
    "end": "1538400"
  },
  {
    "text": "there like you could have an automated",
    "start": "1538400",
    "end": "1539960"
  },
  {
    "text": "teardown as part of your cluster setup",
    "start": "1539960",
    "end": "1542000"
  },
  {
    "text": "and or tear down but because that's",
    "start": "1542000",
    "end": "1545000"
  },
  {
    "text": "decoupled you can just leave it there",
    "start": "1545000",
    "end": "1546500"
  },
  {
    "text": "and you could do multiple trainings you",
    "start": "1546500",
    "end": "1548360"
  },
  {
    "text": "could try different hyper parameters you",
    "start": "1548360",
    "end": "1549679"
  },
  {
    "text": "could do like Ray tuning or something",
    "start": "1549679",
    "end": "1551299"
  },
  {
    "text": "like that which we actually did that so",
    "start": "1551299",
    "end": "1553159"
  },
  {
    "text": "that's a good example and we're trying",
    "start": "1553159",
    "end": "1555559"
  },
  {
    "text": "to hyper parameter tune it we just left",
    "start": "1555559",
    "end": "1557539"
  },
  {
    "text": "the data there and just run training",
    "start": "1557539",
    "end": "1559760"
  },
  {
    "text": "Cycles over and over again so yeah you",
    "start": "1559760",
    "end": "1561620"
  },
  {
    "text": "can definitely do that",
    "start": "1561620",
    "end": "1564279"
  },
  {
    "text": "on this model 263 is what we have",
    "start": "1570220",
    "end": "1573380"
  },
  {
    "text": "currently yeah and so yeah it's a mix of",
    "start": "1573380",
    "end": "1575900"
  },
  {
    "text": "where the plane is how fast it's going",
    "start": "1575900",
    "end": "1577760"
  },
  {
    "text": "you know heading and destination origin",
    "start": "1577760",
    "end": "1580520"
  },
  {
    "text": "all these sorts of things there's some",
    "start": "1580520",
    "end": "1582740"
  },
  {
    "text": "features about the runway like how long",
    "start": "1582740",
    "end": "1585020"
  },
  {
    "text": "are all these runways and so yeah",
    "start": "1585020",
    "end": "1587900"
  },
  {
    "text": "mm-hmm",
    "start": "1587900",
    "end": "1590500"
  },
  {
    "text": "incorporate weather data into that at",
    "start": "1591440",
    "end": "1593120"
  },
  {
    "text": "all we do yeah so not only the current",
    "start": "1593120",
    "end": "1595460"
  },
  {
    "text": "uh weather conditions at the airport as",
    "start": "1595460",
    "end": "1597740"
  },
  {
    "text": "well as forecasting",
    "start": "1597740",
    "end": "1599720"
  },
  {
    "text": "so we use uh there's like the nbm which",
    "start": "1599720",
    "end": "1603200"
  },
  {
    "text": "is the national",
    "start": "1603200",
    "end": "1604880"
  },
  {
    "text": "something model that I'm forgetting now",
    "start": "1604880",
    "end": "1606440"
  },
  {
    "text": "we also use the global forecast system",
    "start": "1606440",
    "end": "1608419"
  },
  {
    "text": "and some systems since it's you know",
    "start": "1608419",
    "end": "1610580"
  },
  {
    "text": "global",
    "start": "1610580",
    "end": "1611900"
  },
  {
    "text": "and has more some more data but this one",
    "start": "1611900",
    "end": "1614980"
  },
  {
    "text": "we're only using the nbm forecast",
    "start": "1614980",
    "end": "1619299"
  },
  {
    "text": "which already integrates the numbers",
    "start": "1627620",
    "end": "1631100"
  },
  {
    "text": "so I think we did try sagemaker I know",
    "start": "1631100",
    "end": "1635000"
  },
  {
    "text": "not for training I don't think we did",
    "start": "1635000",
    "end": "1636440"
  },
  {
    "text": "because we decided we wanted to use Ray",
    "start": "1636440",
    "end": "1638600"
  },
  {
    "text": "and it was just easier to set that",
    "start": "1638600",
    "end": "1640460"
  },
  {
    "text": "cluster up ourselves exactly the way we",
    "start": "1640460",
    "end": "1642740"
  },
  {
    "text": "wanted to rather than",
    "start": "1642740",
    "end": "1644480"
  },
  {
    "text": "uh",
    "start": "1644480",
    "end": "1645740"
  },
  {
    "text": "use sagemaker but we tried we tried",
    "start": "1645740",
    "end": "1647539"
  },
  {
    "text": "sagemaker out for like some of our",
    "start": "1647539",
    "end": "1649039"
  },
  {
    "text": "inference we Host this model on Nvidia",
    "start": "1649039",
    "end": "1650900"
  },
  {
    "text": "Triton because it's like really",
    "start": "1650900",
    "end": "1652220"
  },
  {
    "text": "efficient that throughput and I think",
    "start": "1652220",
    "end": "1654320"
  },
  {
    "text": "sagemaker supports that so we kind of",
    "start": "1654320",
    "end": "1656059"
  },
  {
    "text": "evaluated that as an option too but yeah",
    "start": "1656059",
    "end": "1659919"
  },
  {
    "text": "okay",
    "start": "1663740",
    "end": "1664760"
  },
  {
    "text": "how did you come up with the",
    "start": "1664760",
    "end": "1666080"
  },
  {
    "text": "configuration of the ray cluster right",
    "start": "1666080",
    "end": "1668000"
  },
  {
    "text": "for example how did simplify okay this",
    "start": "1668000",
    "end": "1670760"
  },
  {
    "text": "is",
    "start": "1670760",
    "end": "1672799"
  },
  {
    "text": "five nodes on",
    "start": "1672799",
    "end": "1674419"
  },
  {
    "text": "the same 32 GPS",
    "start": "1674419",
    "end": "1677679"
  },
  {
    "text": "yeah",
    "start": "1681080",
    "end": "1682279"
  },
  {
    "text": "that was so he's asking how we decided",
    "start": "1682279",
    "end": "1684320"
  },
  {
    "text": "to size this cluster the way we did and",
    "start": "1684320",
    "end": "1685940"
  },
  {
    "text": "figure out like how much did we actually",
    "start": "1685940",
    "end": "1687380"
  },
  {
    "text": "need and the truth is it was trial and",
    "start": "1687380",
    "end": "1689480"
  },
  {
    "text": "error like I have that slide that shows",
    "start": "1689480",
    "end": "1691640"
  },
  {
    "text": "you how to figure it out but at the time",
    "start": "1691640",
    "end": "1693260"
  },
  {
    "text": "I didn't know how to do that so I was",
    "start": "1693260",
    "end": "1695960"
  },
  {
    "text": "just like trying to train it and it",
    "start": "1695960",
    "end": "1698120"
  },
  {
    "text": "would run out of memory and I'd give it",
    "start": "1698120",
    "end": "1699679"
  },
  {
    "text": "another node and it would run out of",
    "start": "1699679",
    "end": "1700940"
  },
  {
    "text": "memory I know I'd watch like how much",
    "start": "1700940",
    "end": "1702620"
  },
  {
    "text": "memory usage it was using until I kind",
    "start": "1702620",
    "end": "1704240"
  },
  {
    "text": "of dial it in but then",
    "start": "1704240",
    "end": "1705799"
  },
  {
    "text": "once I read more deeply in their docs",
    "start": "1705799",
    "end": "1707779"
  },
  {
    "text": "and figured out how they figure out the",
    "start": "1707779",
    "end": "1709340"
  },
  {
    "text": "memory pressure and I did the numbers I",
    "start": "1709340",
    "end": "1710779"
  },
  {
    "text": "was like oh well now it actually kind of",
    "start": "1710779",
    "end": "1712039"
  },
  {
    "text": "makes sense why it needed that much",
    "start": "1712039",
    "end": "1713779"
  },
  {
    "text": "memory",
    "start": "1713779",
    "end": "1716080"
  },
  {
    "text": "yeah so yeah we did that and kind of",
    "start": "1717260",
    "end": "1719600"
  },
  {
    "text": "extrapolated and so this is probably",
    "start": "1719600",
    "end": "1721340"
  },
  {
    "text": "about what we need and then if it wasn't",
    "start": "1721340",
    "end": "1723140"
  },
  {
    "text": "then we'd add another node or kind of",
    "start": "1723140",
    "end": "1724940"
  },
  {
    "text": "like instead of trying three four",
    "start": "1724940",
    "end": "1727279"
  },
  {
    "text": "terabyte ones maybe we try five three",
    "start": "1727279",
    "end": "1729140"
  },
  {
    "text": "terabyte ones or you know some different",
    "start": "1729140",
    "end": "1730760"
  },
  {
    "text": "configuration but yeah",
    "start": "1730760",
    "end": "1734140"
  },
  {
    "text": "cool",
    "start": "1739100",
    "end": "1740480"
  },
  {
    "text": "all right I think we are one more up on",
    "start": "1740480",
    "end": "1744080"
  },
  {
    "text": "time I got one minute but yeah go ahead",
    "start": "1744080",
    "end": "1746419"
  },
  {
    "text": "is it possible like is there an API for",
    "start": "1746419",
    "end": "1748520"
  },
  {
    "text": "the model where I can take the",
    "start": "1748520",
    "end": "1750200"
  },
  {
    "text": "80 data that I'm picking up with like",
    "start": "1750200",
    "end": "1751700"
  },
  {
    "text": "with like a RTL SDR and",
    "start": "1751700",
    "end": "1754960"
  },
  {
    "text": "public no because it requires like",
    "start": "1755960",
    "end": "1757760"
  },
  {
    "text": "features that you would have to",
    "start": "1757760",
    "end": "1759260"
  },
  {
    "text": "calculate that you don't have access to",
    "start": "1759260",
    "end": "1760760"
  },
  {
    "text": "but",
    "start": "1760760",
    "end": "1763220"
  },
  {
    "text": "it is part of our uh",
    "start": "1763220",
    "end": "1766960"
  },
  {
    "text": "the coming part of our API so it'll be",
    "start": "1767480",
    "end": "1769220"
  },
  {
    "text": "exposed pretty soon like if you use the",
    "start": "1769220",
    "end": "1770960"
  },
  {
    "text": "uh",
    "start": "1770960",
    "end": "1771740"
  },
  {
    "text": "like the Json apis or the fire hose API",
    "start": "1771740",
    "end": "1774980"
  },
  {
    "text": "it's like starting to come through there",
    "start": "1774980",
    "end": "1776360"
  },
  {
    "text": "so",
    "start": "1776360",
    "end": "1778340"
  },
  {
    "text": "um",
    "start": "1778340",
    "end": "1779600"
  },
  {
    "text": "okay I think we're up on time uh let's",
    "start": "1779600",
    "end": "1781760"
  },
  {
    "text": "give Patrick another round of applause",
    "start": "1781760",
    "end": "1785380"
  }
]
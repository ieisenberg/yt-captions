[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": "okay so yeah my my last personal",
    "start": "3179",
    "end": "7620"
  },
  {
    "text": "conference on site was three years ago",
    "start": "7620",
    "end": "10559"
  },
  {
    "text": "in Austin so I feel super excited to be",
    "start": "10559",
    "end": "13200"
  },
  {
    "text": "here again on site so nice to meet every",
    "start": "13200",
    "end": "16020"
  },
  {
    "text": "one of you here my name is Han I'm the",
    "start": "16020",
    "end": "18660"
  },
  {
    "text": "senior machine learning Engineers from",
    "start": "18660",
    "end": "20520"
  },
  {
    "text": "instacart ml infrastructure team",
    "start": "20520",
    "end": "22800"
  },
  {
    "text": "so I'm super glad to be here sharing",
    "start": "22800",
    "end": "25560"
  },
  {
    "text": "with your folks about our story on how",
    "start": "25560",
    "end": "28560"
  },
  {
    "text": "we start our journey on Ray how we find",
    "start": "28560",
    "end": "32040"
  },
  {
    "text": "out the very first use case summary at",
    "start": "32040",
    "end": "33899"
  },
  {
    "text": "instacart which is fulfillment machine",
    "start": "33899",
    "end": "36180"
  },
  {
    "text": "learning I will talk more about it later",
    "start": "36180",
    "end": "38520"
  },
  {
    "text": "and how we used to handle the",
    "start": "38520",
    "end": "41100"
  },
  {
    "text": "Fulfillment machine learning parallel",
    "start": "41100",
    "end": "42780"
  },
  {
    "text": "training workflows in production and how",
    "start": "42780",
    "end": "45360"
  },
  {
    "text": "we find it limited and how we improve it",
    "start": "45360",
    "end": "47879"
  },
  {
    "text": "with the help of three",
    "start": "47879",
    "end": "50039"
  },
  {
    "text": "okay so this is the rundown of my",
    "start": "50039",
    "end": "52680"
  },
  {
    "text": "today's talk first I will go very",
    "start": "52680",
    "end": "54840"
  },
  {
    "text": "quickly on what is instacart how it",
    "start": "54840",
    "end": "57960"
  },
  {
    "text": "works why machine learning is super",
    "start": "57960",
    "end": "59820"
  },
  {
    "text": "important at instacart",
    "start": "59820",
    "end": "61500"
  },
  {
    "text": "and then I will give you the overview of",
    "start": "61500",
    "end": "64080"
  },
  {
    "text": "the problem set of fulfillment machine",
    "start": "64080",
    "end": "66180"
  },
  {
    "text": "learning at instacart",
    "start": "66180",
    "end": "68220"
  },
  {
    "text": "and then I will go into some deep dive",
    "start": "68220",
    "end": "70619"
  },
  {
    "text": "of the system architecture and how we",
    "start": "70619",
    "end": "73500"
  },
  {
    "text": "use to support the parallel training",
    "start": "73500",
    "end": "76200"
  },
  {
    "text": "jobs on instacart fulfillment machine",
    "start": "76200",
    "end": "78659"
  },
  {
    "text": "learning and how we improve it with the",
    "start": "78659",
    "end": "80460"
  },
  {
    "text": "help of Ray",
    "start": "80460",
    "end": "81540"
  },
  {
    "text": "and in the last I will talk about our",
    "start": "81540",
    "end": "83939"
  },
  {
    "text": "integration work to integrate Ray with",
    "start": "83939",
    "end": "86820"
  },
  {
    "text": "the existing instacart MLS",
    "start": "86820",
    "end": "90000"
  },
  {
    "start": "90000",
    "end": "253000"
  },
  {
    "text": "all right",
    "start": "90000",
    "end": "91500"
  },
  {
    "text": "so what is instacart and how it works I",
    "start": "91500",
    "end": "94979"
  },
  {
    "text": "guess some of you here may have heard",
    "start": "94979",
    "end": "96960"
  },
  {
    "text": "about us or even met some others from",
    "start": "96960",
    "end": "100020"
  },
  {
    "text": "instacart application",
    "start": "100020",
    "end": "102720"
  },
  {
    "text": "our value proposition at instacart is",
    "start": "102720",
    "end": "105000"
  },
  {
    "text": "actually very straightforward",
    "start": "105000",
    "end": "106740"
  },
  {
    "text": "we are running an online platform",
    "start": "106740",
    "end": "108960"
  },
  {
    "text": "to delivery to deliver groceries and",
    "start": "108960",
    "end": "111840"
  },
  {
    "text": "non-graphy items from the store you",
    "start": "111840",
    "end": "114360"
  },
  {
    "text": "already love to your door front as fast",
    "start": "114360",
    "end": "116939"
  },
  {
    "text": "as 30 minutes",
    "start": "116939",
    "end": "118560"
  },
  {
    "text": "behind the scenes there are actually a",
    "start": "118560",
    "end": "121560"
  },
  {
    "text": "lot of complexities running this",
    "start": "121560",
    "end": "122939"
  },
  {
    "text": "platform",
    "start": "122939",
    "end": "124140"
  },
  {
    "text": "we have the customer facing application",
    "start": "124140",
    "end": "126119"
  },
  {
    "text": "which is a shopping app you will be",
    "start": "126119",
    "end": "127979"
  },
  {
    "text": "using",
    "start": "127979",
    "end": "128940"
  },
  {
    "text": "our searching and Discovery",
    "start": "128940",
    "end": "130679"
  },
  {
    "text": "infrastructure to help you find the",
    "start": "130679",
    "end": "132720"
  },
  {
    "text": "items on the rack",
    "start": "132720",
    "end": "134459"
  },
  {
    "text": "our logistic infrastructure to fulfill",
    "start": "134459",
    "end": "137280"
  },
  {
    "text": "your order",
    "start": "137280",
    "end": "138420"
  },
  {
    "text": "and the application our Shoppers are",
    "start": "138420",
    "end": "140400"
  },
  {
    "text": "using when they are working at the store",
    "start": "140400",
    "end": "143720"
  },
  {
    "text": "we are running a four-sided Marketplace",
    "start": "144360",
    "end": "146940"
  },
  {
    "text": "we connect customers to a personal",
    "start": "146940",
    "end": "149040"
  },
  {
    "text": "shopper Who deliver the service in real",
    "start": "149040",
    "end": "151500"
  },
  {
    "text": "time",
    "start": "151500",
    "end": "152459"
  },
  {
    "text": "we partner with local retailers to give",
    "start": "152459",
    "end": "155160"
  },
  {
    "text": "customers access to local stores they",
    "start": "155160",
    "end": "157200"
  },
  {
    "text": "are familiaries",
    "start": "157200",
    "end": "158700"
  },
  {
    "text": "they offer coupons and other incentives",
    "start": "158700",
    "end": "161459"
  },
  {
    "text": "from our brand Partners who can increase",
    "start": "161459",
    "end": "163500"
  },
  {
    "text": "the value proposition back to our",
    "start": "163500",
    "end": "165660"
  },
  {
    "text": "customers",
    "start": "165660",
    "end": "167220"
  },
  {
    "text": "and machine learning is widely applied",
    "start": "167220",
    "end": "169140"
  },
  {
    "text": "in almost every single edge of this",
    "start": "169140",
    "end": "170940"
  },
  {
    "text": "graph to name a few search item ranking",
    "start": "170940",
    "end": "174540"
  },
  {
    "text": "advertisement and fulfillment",
    "start": "174540",
    "end": "176700"
  },
  {
    "text": "Marketplace which is the use case I will",
    "start": "176700",
    "end": "178680"
  },
  {
    "text": "talk more about later",
    "start": "178680",
    "end": "181459"
  },
  {
    "text": "we are not covering U.S all 50 States",
    "start": "181920",
    "end": "184500"
  },
  {
    "text": "and Canada",
    "start": "184500",
    "end": "186000"
  },
  {
    "text": "as you can imagine each market is unique",
    "start": "186000",
    "end": "189180"
  },
  {
    "text": "and brings own challenges",
    "start": "189180",
    "end": "191220"
  },
  {
    "text": "as a result as a machine learning",
    "start": "191220",
    "end": "193260"
  },
  {
    "text": "engineer working at instacart",
    "start": "193260",
    "end": "195300"
  },
  {
    "text": "the approaches that we build have to",
    "start": "195300",
    "end": "197580"
  },
  {
    "text": "consider all the differences and",
    "start": "197580",
    "end": "199440"
  },
  {
    "text": "complexities",
    "start": "199440",
    "end": "201980"
  },
  {
    "text": "and here is the skill of machine",
    "start": "203159",
    "end": "204599"
  },
  {
    "text": "learning problems we are solving at",
    "start": "204599",
    "end": "206220"
  },
  {
    "text": "instacart",
    "start": "206220",
    "end": "207659"
  },
  {
    "text": "we are partnering with 900 plus",
    "start": "207659",
    "end": "209640"
  },
  {
    "text": "retailers across 75 000 Plus stores in",
    "start": "209640",
    "end": "213360"
  },
  {
    "text": "13 000 plus cities in U.S and Canada",
    "start": "213360",
    "end": "216599"
  },
  {
    "text": "we are enabling 5500 plus brand Partners",
    "start": "216599",
    "end": "220080"
  },
  {
    "text": "to connect their products with potential",
    "start": "220080",
    "end": "222720"
  },
  {
    "text": "customers",
    "start": "222720",
    "end": "224400"
  },
  {
    "text": "they are helping our customers to find",
    "start": "224400",
    "end": "226739"
  },
  {
    "text": "the items they love out of item catalog",
    "start": "226739",
    "end": "229560"
  },
  {
    "text": "as big as over 1 billion products which",
    "start": "229560",
    "end": "232140"
  },
  {
    "text": "is almost three times of U.S population",
    "start": "232140",
    "end": "235260"
  },
  {
    "text": "and at its core instacart runs a",
    "start": "235260",
    "end": "238019"
  },
  {
    "text": "real-time Logistics platform",
    "start": "238019",
    "end": "239940"
  },
  {
    "text": "our fulfillment machine learning",
    "start": "239940",
    "end": "241379"
  },
  {
    "text": "Engineers are working dedically to",
    "start": "241379",
    "end": "244260"
  },
  {
    "text": "connect millions of customers with six",
    "start": "244260",
    "end": "246900"
  },
  {
    "text": "hundred thousand plus Shoppers to get",
    "start": "246900",
    "end": "248940"
  },
  {
    "text": "every other delivered efficiently",
    "start": "248940",
    "end": "252739"
  },
  {
    "start": "253000",
    "end": "444000"
  },
  {
    "text": "we operate a very Dynamic and complex",
    "start": "254040",
    "end": "256680"
  },
  {
    "text": "fulfillment Marketplace",
    "start": "256680",
    "end": "258419"
  },
  {
    "text": "machine learning plays critical role",
    "start": "258419",
    "end": "260100"
  },
  {
    "text": "throughout the entire life cycle of",
    "start": "260100",
    "end": "262560"
  },
  {
    "text": "every order",
    "start": "262560",
    "end": "263820"
  },
  {
    "text": "here are some examples of fulfillment",
    "start": "263820",
    "end": "266100"
  },
  {
    "text": "machine learning models",
    "start": "266100",
    "end": "269180"
  },
  {
    "text": "we optimize the routing of deliveries in",
    "start": "270180",
    "end": "272520"
  },
  {
    "text": "real time",
    "start": "272520",
    "end": "273540"
  },
  {
    "text": "at any moment given a set of deliveries",
    "start": "273540",
    "end": "276360"
  },
  {
    "text": "and stores of a region",
    "start": "276360",
    "end": "278520"
  },
  {
    "text": "how do we decide which store to use for",
    "start": "278520",
    "end": "281160"
  },
  {
    "text": "a particular delivery",
    "start": "281160",
    "end": "283320"
  },
  {
    "text": "for multiple deliveries in the air",
    "start": "283320",
    "end": "285720"
  },
  {
    "text": "which deliveries should be grouped as",
    "start": "285720",
    "end": "287940"
  },
  {
    "text": "one batch to be fulfilled to be",
    "start": "287940",
    "end": "290400"
  },
  {
    "text": "fulfilled by one Shopper and at the same",
    "start": "290400",
    "end": "293160"
  },
  {
    "text": "time without delaying any orders from",
    "start": "293160",
    "end": "295139"
  },
  {
    "text": "any customers",
    "start": "295139",
    "end": "297979"
  },
  {
    "text": "predicting and balancing supply and",
    "start": "298199",
    "end": "300300"
  },
  {
    "text": "demand is extremely important in",
    "start": "300300",
    "end": "302699"
  },
  {
    "text": "real-time Marketplace",
    "start": "302699",
    "end": "304500"
  },
  {
    "text": "if Supply exists demand in the market we",
    "start": "304500",
    "end": "307259"
  },
  {
    "text": "lose money and reduce sharper happiness",
    "start": "307259",
    "end": "309660"
  },
  {
    "text": "because Shoppers are sitting idle",
    "start": "309660",
    "end": "311280"
  },
  {
    "text": "without any profit",
    "start": "311280",
    "end": "313020"
  },
  {
    "text": "If instead the other demands exceed",
    "start": "313020",
    "end": "315840"
  },
  {
    "text": "available Shoppers in the market",
    "start": "315840",
    "end": "317639"
  },
  {
    "text": "we lose customers due to limited",
    "start": "317639",
    "end": "319620"
  },
  {
    "text": "availability",
    "start": "319620",
    "end": "322040"
  },
  {
    "text": "we predict other ETA to simplify the",
    "start": "323340",
    "end": "326340"
  },
  {
    "text": "checkout process with small clarity",
    "start": "326340",
    "end": "329340"
  },
  {
    "text": "a personalized ETA on every customer",
    "start": "329340",
    "end": "332460"
  },
  {
    "text": "visit",
    "start": "332460",
    "end": "333660"
  },
  {
    "text": "instead of customer selecting Auto for",
    "start": "333660",
    "end": "336840"
  },
  {
    "text": "static delivery time windows we predict",
    "start": "336840",
    "end": "340080"
  },
  {
    "text": "ETA on a continuous time frame with",
    "start": "340080",
    "end": "342180"
  },
  {
    "text": "better control on conversion cost and",
    "start": "342180",
    "end": "345000"
  },
  {
    "text": "margin Etc",
    "start": "345000",
    "end": "347600"
  },
  {
    "text": "for all as I mentioned and I'll",
    "start": "348060",
    "end": "349740"
  },
  {
    "text": "mentioned fulfillment scenarios our",
    "start": "349740",
    "end": "351840"
  },
  {
    "text": "machine learning Engineers apply",
    "start": "351840",
    "end": "353340"
  },
  {
    "text": "different type of algorithms and",
    "start": "353340",
    "end": "355440"
  },
  {
    "text": "continue to involve the model with the",
    "start": "355440",
    "end": "357600"
  },
  {
    "text": "most up-to-date machine learning",
    "start": "357600",
    "end": "358680"
  },
  {
    "text": "techniques I will not cover about",
    "start": "358680",
    "end": "361080"
  },
  {
    "text": "details in modeling today",
    "start": "361080",
    "end": "363180"
  },
  {
    "text": "but in the end most of those models end",
    "start": "363180",
    "end": "366720"
  },
  {
    "text": "up with the same patterns of training",
    "start": "366720",
    "end": "369240"
  },
  {
    "text": "for a given type of model we want to",
    "start": "369240",
    "end": "371880"
  },
  {
    "text": "create a huge batch of training jobs",
    "start": "371880",
    "end": "373880"
  },
  {
    "text": "paralyzed on one or multiple Horizons",
    "start": "373880",
    "end": "377699"
  },
  {
    "text": "the most common Horizon is geographical",
    "start": "377699",
    "end": "380160"
  },
  {
    "text": "locations we call it zones for example",
    "start": "380160",
    "end": "383300"
  },
  {
    "text": "San Francisco South Bay Area is a unique",
    "start": "383300",
    "end": "386100"
  },
  {
    "text": "Zone",
    "start": "386100",
    "end": "387360"
  },
  {
    "text": "some models running on real-time supply",
    "start": "387360",
    "end": "389880"
  },
  {
    "text": "and demand would have another Horizon",
    "start": "389880",
    "end": "392160"
  },
  {
    "text": "without Day hours",
    "start": "392160",
    "end": "393960"
  },
  {
    "text": "which is the store open hours throughout",
    "start": "393960",
    "end": "396180"
  },
  {
    "text": "the day",
    "start": "396180",
    "end": "397380"
  },
  {
    "text": "this means that one unique model type",
    "start": "397380",
    "end": "399900"
  },
  {
    "text": "will fan out to thousands of parallel",
    "start": "399900",
    "end": "402300"
  },
  {
    "text": "training jobs in production training",
    "start": "402300",
    "end": "405860"
  },
  {
    "text": "at instacart",
    "start": "405900",
    "end": "407460"
  },
  {
    "text": "we have over 2000 unique zones in our",
    "start": "407460",
    "end": "409860"
  },
  {
    "text": "product and for each Zone we have at",
    "start": "409860",
    "end": "412680"
  },
  {
    "text": "least eight hours of store open hours",
    "start": "412680",
    "end": "414680"
  },
  {
    "text": "counting up to more than sixteen",
    "start": "414680",
    "end": "417180"
  },
  {
    "text": "thousands only our Horizons",
    "start": "417180",
    "end": "419340"
  },
  {
    "text": "we have over 30 types of models running",
    "start": "419340",
    "end": "421500"
  },
  {
    "text": "in such highly parallel pattern and the",
    "start": "421500",
    "end": "424020"
  },
  {
    "text": "number of models keep growing as our",
    "start": "424020",
    "end": "426000"
  },
  {
    "text": "Machining Engineers are producing new",
    "start": "426000",
    "end": "427680"
  },
  {
    "text": "models",
    "start": "427680",
    "end": "428819"
  },
  {
    "text": "we want to Target to retrench model with",
    "start": "428819",
    "end": "431580"
  },
  {
    "text": "most up-to-date input data on regular",
    "start": "431580",
    "end": "434160"
  },
  {
    "text": "basis",
    "start": "434160",
    "end": "435180"
  },
  {
    "text": "this screen also challenging how to",
    "start": "435180",
    "end": "437280"
  },
  {
    "text": "execute those highly parallel training",
    "start": "437280",
    "end": "439620"
  },
  {
    "text": "workflows in a scalable and efficient",
    "start": "439620",
    "end": "442319"
  },
  {
    "text": "approach",
    "start": "442319",
    "end": "444479"
  },
  {
    "start": "444000",
    "end": "868000"
  },
  {
    "text": "next I will show you how we used to",
    "start": "444479",
    "end": "446639"
  },
  {
    "text": "support highly parallel training jobs in",
    "start": "446639",
    "end": "448860"
  },
  {
    "text": "production why we find the previous",
    "start": "448860",
    "end": "450840"
  },
  {
    "text": "solution not scalable and how we improve",
    "start": "450840",
    "end": "453360"
  },
  {
    "text": "the system by introducing Ray",
    "start": "453360",
    "end": "456680"
  },
  {
    "text": "here's the architecture overview of",
    "start": "456919",
    "end": "459780"
  },
  {
    "text": "Legacy Solutions running on AWS ECS",
    "start": "459780",
    "end": "463080"
  },
  {
    "text": "there are two parts of the service",
    "start": "463080",
    "end": "464819"
  },
  {
    "text": "running together as publisher subscriber",
    "start": "464819",
    "end": "467580"
  },
  {
    "text": "system",
    "start": "467580",
    "end": "468720"
  },
  {
    "text": "on the left hand side we launch a",
    "start": "468720",
    "end": "471000"
  },
  {
    "text": "chrome-like scheduling service with",
    "start": "471000",
    "end": "472919"
  },
  {
    "text": "radius clock backend to push training",
    "start": "472919",
    "end": "475440"
  },
  {
    "text": "tasks on each of each model on regular",
    "start": "475440",
    "end": "477900"
  },
  {
    "text": "basis for example daily or weekly",
    "start": "477900",
    "end": "481560"
  },
  {
    "text": "each model has one training task per",
    "start": "481560",
    "end": "483960"
  },
  {
    "text": "zone or per Zoom Day hour which is",
    "start": "483960",
    "end": "486599"
  },
  {
    "text": "ranging from about 1000 to plus 10 000",
    "start": "486599",
    "end": "489840"
  },
  {
    "text": "of tasks",
    "start": "489840",
    "end": "491639"
  },
  {
    "text": "the model application is scheduled the",
    "start": "491639",
    "end": "494099"
  },
  {
    "text": "full list of parallel training task is",
    "start": "494099",
    "end": "496259"
  },
  {
    "text": "pushed to one of those task queue",
    "start": "496259",
    "end": "497819"
  },
  {
    "text": "running on radius message broker",
    "start": "497819",
    "end": "501180"
  },
  {
    "text": "each task queue is subscribed by an",
    "start": "501180",
    "end": "504180"
  },
  {
    "text": "Executor service running a group of",
    "start": "504180",
    "end": "506400"
  },
  {
    "text": "salary distributed workers on the right",
    "start": "506400",
    "end": "508560"
  },
  {
    "text": "hand side",
    "start": "508560",
    "end": "510240"
  },
  {
    "text": "and each worker got allocated with one",
    "start": "510240",
    "end": "512820"
  },
  {
    "text": "task to execute each time process it and",
    "start": "512820",
    "end": "515880"
  },
  {
    "text": "update the task results in message",
    "start": "515880",
    "end": "517680"
  },
  {
    "text": "backend",
    "start": "517680",
    "end": "519599"
  },
  {
    "text": "in order to make deployment process",
    "start": "519599",
    "end": "521459"
  },
  {
    "text": "easier for our machine learning",
    "start": "521459",
    "end": "522659"
  },
  {
    "text": "Engineers which is the author of the",
    "start": "522659",
    "end": "524760"
  },
  {
    "text": "model but at the same time you don't",
    "start": "524760",
    "end": "526200"
  },
  {
    "text": "want to spend much time handling system",
    "start": "526200",
    "end": "527880"
  },
  {
    "text": "complexities",
    "start": "527880",
    "end": "529380"
  },
  {
    "text": "in production it's quite common",
    "start": "529380",
    "end": "531660"
  },
  {
    "text": "implementation that multiple models",
    "start": "531660",
    "end": "534240"
  },
  {
    "text": "produced by the same business unit share",
    "start": "534240",
    "end": "537240"
  },
  {
    "text": "the same task queue to its complexity of",
    "start": "537240",
    "end": "539399"
  },
  {
    "text": "job execution",
    "start": "539399",
    "end": "541380"
  },
  {
    "text": "when machine learning Engineers wants to",
    "start": "541380",
    "end": "543300"
  },
  {
    "text": "enable a new type of model so you don't",
    "start": "543300",
    "end": "545399"
  },
  {
    "text": "need to make any changes in radius",
    "start": "545399",
    "end": "546959"
  },
  {
    "text": "cluster or in salary worker services",
    "start": "546959",
    "end": "550019"
  },
  {
    "text": "what they need to do is to redeploy the",
    "start": "550019",
    "end": "552360"
  },
  {
    "text": "Chrome scheduler service by adding",
    "start": "552360",
    "end": "554339"
  },
  {
    "text": "training task destinations and identify",
    "start": "554339",
    "end": "556620"
  },
  {
    "text": "the name of task queue to get those",
    "start": "556620",
    "end": "558540"
  },
  {
    "text": "applications connected with",
    "start": "558540",
    "end": "562040"
  },
  {
    "text": "well this solution used to work pretty",
    "start": "562500",
    "end": "564720"
  },
  {
    "text": "well at the very beginning when we have",
    "start": "564720",
    "end": "566760"
  },
  {
    "text": "very few models however later as we",
    "start": "566760",
    "end": "569519"
  },
  {
    "text": "onboard more and more models in our",
    "start": "569519",
    "end": "571080"
  },
  {
    "text": "production",
    "start": "571080",
    "end": "572339"
  },
  {
    "text": "we found this implementation is now",
    "start": "572339",
    "end": "574320"
  },
  {
    "text": "scalable and has a bunch of limitations",
    "start": "574320",
    "end": "577620"
  },
  {
    "text": "first of all we make multiple models",
    "start": "577620",
    "end": "580200"
  },
  {
    "text": "share the same task queue and Sim set of",
    "start": "580200",
    "end": "582060"
  },
  {
    "text": "distributed workers later it turned out",
    "start": "582060",
    "end": "584580"
  },
  {
    "text": "to be very difficult to tune the",
    "start": "584580",
    "end": "586860"
  },
  {
    "text": "resource requirement that fits all",
    "start": "586860",
    "end": "588660"
  },
  {
    "text": "models",
    "start": "588660",
    "end": "589740"
  },
  {
    "text": "therefore we had to be very generously",
    "start": "589740",
    "end": "592320"
  },
  {
    "text": "in provision Computer Resources and at",
    "start": "592320",
    "end": "595560"
  },
  {
    "text": "the same time be very conservative in",
    "start": "595560",
    "end": "597959"
  },
  {
    "text": "configuring the number of concurrent",
    "start": "597959",
    "end": "599580"
  },
  {
    "text": "salary workers per host",
    "start": "599580",
    "end": "601740"
  },
  {
    "text": "this end up with each host provisioned",
    "start": "601740",
    "end": "604200"
  },
  {
    "text": "with many CPU and resources however",
    "start": "604200",
    "end": "606720"
  },
  {
    "text": "running in very low latency sorry very",
    "start": "606720",
    "end": "609720"
  },
  {
    "text": "low utilization",
    "start": "609720",
    "end": "611580"
  },
  {
    "text": "and the end-to-end completion time to",
    "start": "611580",
    "end": "613620"
  },
  {
    "text": "finish parallel training job of multiple",
    "start": "613620",
    "end": "616500"
  },
  {
    "text": "thousands of zones takes very long",
    "start": "616500",
    "end": "618720"
  },
  {
    "text": "because we have very limited number of",
    "start": "618720",
    "end": "620640"
  },
  {
    "text": "parallel workers",
    "start": "620640",
    "end": "622860"
  },
  {
    "text": "since every salary",
    "start": "622860",
    "end": "624660"
  },
  {
    "text": "executor service is shared by multiple",
    "start": "624660",
    "end": "627120"
  },
  {
    "text": "models we couldn't easily increase the",
    "start": "627120",
    "end": "629700"
  },
  {
    "text": "number of",
    "start": "629700",
    "end": "630660"
  },
  {
    "text": "concurrent workers per host for a",
    "start": "630660",
    "end": "632760"
  },
  {
    "text": "particular model just to speed it up so",
    "start": "632760",
    "end": "635339"
  },
  {
    "text": "it typically takes one to two days or",
    "start": "635339",
    "end": "637620"
  },
  {
    "text": "even more to retrain a model it's very",
    "start": "637620",
    "end": "640440"
  },
  {
    "text": "high number of parallel tasks",
    "start": "640440",
    "end": "643140"
  },
  {
    "text": "we are running this system as a",
    "start": "643140",
    "end": "645600"
  },
  {
    "text": "long-running service but in reality our",
    "start": "645600",
    "end": "648720"
  },
  {
    "text": "model just needs to be retrained every",
    "start": "648720",
    "end": "651240"
  },
  {
    "text": "week or every couple of days",
    "start": "651240",
    "end": "653519"
  },
  {
    "text": "therefore our task queue May sit either",
    "start": "653519",
    "end": "655440"
  },
  {
    "text": "most of the week",
    "start": "655440",
    "end": "656760"
  },
  {
    "text": "we need to tune the auto scaling policy",
    "start": "656760",
    "end": "659220"
  },
  {
    "text": "very carefully otherwise we are visiting",
    "start": "659220",
    "end": "661200"
  },
  {
    "text": "computational resources and Company",
    "start": "661200",
    "end": "662940"
  },
  {
    "text": "money",
    "start": "662940",
    "end": "664980"
  },
  {
    "text": "we are running this monolithic service",
    "start": "664980",
    "end": "666779"
  },
  {
    "text": "hosting many models making it very",
    "start": "666779",
    "end": "669540"
  },
  {
    "text": "inflexible to manage dependencies",
    "start": "669540",
    "end": "672240"
  },
  {
    "text": "for example I couldn't change the python",
    "start": "672240",
    "end": "674760"
  },
  {
    "text": "package of one model without impacting",
    "start": "674760",
    "end": "676680"
  },
  {
    "text": "other models",
    "start": "676680",
    "end": "678540"
  },
  {
    "text": "and this system is too complex to",
    "start": "678540",
    "end": "680700"
  },
  {
    "text": "automate it's hard for machine learning",
    "start": "680700",
    "end": "682920"
  },
  {
    "text": "Engineers to run any local test on their",
    "start": "682920",
    "end": "685260"
  },
  {
    "text": "laptop or on the notebook platform",
    "start": "685260",
    "end": "687240"
  },
  {
    "text": "without diving deep into the system",
    "start": "687240",
    "end": "689160"
  },
  {
    "text": "architecture unless they go through",
    "start": "689160",
    "end": "691500"
  },
  {
    "text": "additional steps to bring everything up",
    "start": "691500",
    "end": "693240"
  },
  {
    "text": "by themselves such as local Reddit",
    "start": "693240",
    "end": "695579"
  },
  {
    "text": "server and separate sessions to start",
    "start": "695579",
    "end": "697860"
  },
  {
    "text": "salary workers and application tasks",
    "start": "697860",
    "end": "701339"
  },
  {
    "text": "and it's high maintenance to manage",
    "start": "701339",
    "end": "703560"
  },
  {
    "text": "service for all model types any xinjiang",
    "start": "703560",
    "end": "706440"
  },
  {
    "text": "one model requires a redeployment",
    "start": "706440",
    "end": "708480"
  },
  {
    "text": "process that potentially affects all",
    "start": "708480",
    "end": "710700"
  },
  {
    "text": "other models",
    "start": "710700",
    "end": "711959"
  },
  {
    "text": "and even worse is that even if we make",
    "start": "711959",
    "end": "714839"
  },
  {
    "text": "changes on the executor side for example",
    "start": "714839",
    "end": "716940"
  },
  {
    "text": "we want to move one model from one queue",
    "start": "716940",
    "end": "719399"
  },
  {
    "text": "to the other",
    "start": "719399",
    "end": "720720"
  },
  {
    "text": "it introduces an even more complicated",
    "start": "720720",
    "end": "722820"
  },
  {
    "text": "deployment process because we need to",
    "start": "722820",
    "end": "725160"
  },
  {
    "text": "redeploy both scheduler and executor",
    "start": "725160",
    "end": "727200"
  },
  {
    "text": "services",
    "start": "727200",
    "end": "729440"
  },
  {
    "text": "here are some graphs exported from our",
    "start": "731040",
    "end": "733620"
  },
  {
    "text": "monitoring dashboard just want to give",
    "start": "733620",
    "end": "735959"
  },
  {
    "text": "you some ideas on how a low utilization",
    "start": "735959",
    "end": "738180"
  },
  {
    "text": "scenario looks like",
    "start": "738180",
    "end": "740040"
  },
  {
    "text": "in fulfillment area most machine",
    "start": "740040",
    "end": "742260"
  },
  {
    "text": "learning stuff practicing with",
    "start": "742260",
    "end": "743459"
  },
  {
    "text": "algorithms such as regression",
    "start": "743459",
    "end": "745620"
  },
  {
    "text": "classification Etc",
    "start": "745620",
    "end": "747959"
  },
  {
    "text": "such algorithms are usually very",
    "start": "747959",
    "end": "750000"
  },
  {
    "text": "lightweight in terms of resource usage",
    "start": "750000",
    "end": "751860"
  },
  {
    "text": "for example in the left hand side",
    "start": "751860",
    "end": "754680"
  },
  {
    "text": "we are running a model on a 16 CPU",
    "start": "754680",
    "end": "757380"
  },
  {
    "text": "instance however the CPU utilization is",
    "start": "757380",
    "end": "759959"
  },
  {
    "text": "only around 10 to 15 percent",
    "start": "759959",
    "end": "762180"
  },
  {
    "text": "you may ask in this case why not",
    "start": "762180",
    "end": "764220"
  },
  {
    "text": "provision with a smaller instance well",
    "start": "764220",
    "end": "766560"
  },
  {
    "text": "as mentioned there are multiple models",
    "start": "766560",
    "end": "768540"
  },
  {
    "text": "sharing the same queue some models are",
    "start": "768540",
    "end": "770820"
  },
  {
    "text": "lightweight and some are heavier they",
    "start": "770820",
    "end": "772980"
  },
  {
    "text": "have to provision big enough machines to",
    "start": "772980",
    "end": "775079"
  },
  {
    "text": "leave enough headrooms to suit all",
    "start": "775079",
    "end": "777060"
  },
  {
    "text": "models this is the major drawback of",
    "start": "777060",
    "end": "780360"
  },
  {
    "text": "Hosting models as a monolithic service",
    "start": "780360",
    "end": "783600"
  },
  {
    "text": "another pinpoint is they start have a",
    "start": "783600",
    "end": "786120"
  },
  {
    "text": "long running service waiting for the",
    "start": "786120",
    "end": "788220"
  },
  {
    "text": "scheduled routine job to kick in",
    "start": "788220",
    "end": "790440"
  },
  {
    "text": "this may end up with a very unbalanced",
    "start": "790440",
    "end": "792839"
  },
  {
    "text": "load on Time series",
    "start": "792839",
    "end": "794639"
  },
  {
    "text": "on the right hand side it gives you an",
    "start": "794639",
    "end": "797459"
  },
  {
    "text": "example of a very unbalanced task queue",
    "start": "797459",
    "end": "801060"
  },
  {
    "text": "this queue is not running any task over",
    "start": "801060",
    "end": "803459"
  },
  {
    "text": "60 percent time of the day",
    "start": "803459",
    "end": "805920"
  },
  {
    "text": "therefore we need to tune the auto",
    "start": "805920",
    "end": "807540"
  },
  {
    "text": "scaling policies with extra efforts",
    "start": "807540",
    "end": "809600"
  },
  {
    "text": "expecting the service to downscale when",
    "start": "809600",
    "end": "812279"
  },
  {
    "text": "the size of red skill is small as such",
    "start": "812279",
    "end": "816200"
  },
  {
    "text": "however it's also pretty common that we",
    "start": "816200",
    "end": "819120"
  },
  {
    "text": "see another side of the extreme",
    "start": "819120",
    "end": "821100"
  },
  {
    "text": "there are many models produced by the",
    "start": "821100",
    "end": "823800"
  },
  {
    "text": "same business unit clean up in the same",
    "start": "823800",
    "end": "826079"
  },
  {
    "text": "task queue",
    "start": "826079",
    "end": "827339"
  },
  {
    "text": "such as what this graph is showing you",
    "start": "827339",
    "end": "829980"
  },
  {
    "text": "the number of tasks in queue ranges from",
    "start": "829980",
    "end": "831959"
  },
  {
    "text": "300 to over 1000 all day round",
    "start": "831959",
    "end": "835019"
  },
  {
    "text": "in such case the user have to manually",
    "start": "835019",
    "end": "837540"
  },
  {
    "text": "move some models to a lighter loaded",
    "start": "837540",
    "end": "839579"
  },
  {
    "text": "queue by going through the service",
    "start": "839579",
    "end": "841200"
  },
  {
    "text": "redeployment",
    "start": "841200",
    "end": "842820"
  },
  {
    "text": "or we do horizontal upscaling by adding",
    "start": "842820",
    "end": "846360"
  },
  {
    "text": "more salary workers to the queue to",
    "start": "846360",
    "end": "848160"
  },
  {
    "text": "process the tasks",
    "start": "848160",
    "end": "850139"
  },
  {
    "text": "however keep in mind that",
    "start": "850139",
    "end": "853860"
  },
  {
    "text": "for the added workers they will be still",
    "start": "853860",
    "end": "856440"
  },
  {
    "text": "processing very lightweight algorithms",
    "start": "856440",
    "end": "859500"
  },
  {
    "text": "therefore the horizontal scaling will",
    "start": "859500",
    "end": "861420"
  },
  {
    "text": "end up with adding more and more low",
    "start": "861420",
    "end": "863339"
  },
  {
    "text": "utilized workers",
    "start": "863339",
    "end": "864779"
  },
  {
    "text": "and continuously increasing our bill",
    "start": "864779",
    "end": "868519"
  },
  {
    "start": "868000",
    "end": "904000"
  },
  {
    "text": "and we also found the implementation of",
    "start": "869880",
    "end": "871800"
  },
  {
    "text": "scheduler service often comes with a",
    "start": "871800",
    "end": "873959"
  },
  {
    "text": "very hard-coded Crown job definition",
    "start": "873959",
    "end": "876120"
  },
  {
    "text": "here's how it typically looks like in",
    "start": "876120",
    "end": "878339"
  },
  {
    "text": "the form of pseudo code",
    "start": "878339",
    "end": "880500"
  },
  {
    "text": "this requires the model owners the",
    "start": "880500",
    "end": "883079"
  },
  {
    "text": "author of every single code block here",
    "start": "883079",
    "end": "885720"
  },
  {
    "text": "to manage and balance the load of each",
    "start": "885720",
    "end": "887699"
  },
  {
    "text": "queue all by themselves",
    "start": "887699",
    "end": "889380"
  },
  {
    "text": "for example if there are too many tasks",
    "start": "889380",
    "end": "891959"
  },
  {
    "text": "to be scheduled on the same day same",
    "start": "891959",
    "end": "894180"
  },
  {
    "text": "time window and on the same task queue",
    "start": "894180",
    "end": "896040"
  },
  {
    "text": "the user suffer from higher latency to",
    "start": "896040",
    "end": "898560"
  },
  {
    "text": "complete tasks or we compromise by",
    "start": "898560",
    "end": "901260"
  },
  {
    "text": "further scaling the number of workers",
    "start": "901260",
    "end": "902820"
  },
  {
    "text": "horizontally",
    "start": "902820",
    "end": "905420"
  },
  {
    "start": "904000",
    "end": "1043000"
  },
  {
    "text": "after reviewing the existing solution to",
    "start": "906540",
    "end": "909240"
  },
  {
    "text": "better understand the pain points and",
    "start": "909240",
    "end": "910740"
  },
  {
    "text": "the limitations we learned that we need",
    "start": "910740",
    "end": "913320"
  },
  {
    "text": "to build a new parallel execution",
    "start": "913320",
    "end": "915180"
  },
  {
    "text": "architecture which is expected to be",
    "start": "915180",
    "end": "917820"
  },
  {
    "text": "more resource efficient more flexible in",
    "start": "917820",
    "end": "920699"
  },
  {
    "text": "setup faster in end-to-end execution",
    "start": "920699",
    "end": "923100"
  },
  {
    "text": "easier to automate and with the support",
    "start": "923100",
    "end": "925860"
  },
  {
    "text": "of isolated workflow environment",
    "start": "925860",
    "end": "928800"
  },
  {
    "text": "we redesigned and proposed a new",
    "start": "928800",
    "end": "930660"
  },
  {
    "text": "fulfillment training platform to",
    "start": "930660",
    "end": "932579"
  },
  {
    "text": "Leverage The Parallel execution API free",
    "start": "932579",
    "end": "934800"
  },
  {
    "text": "and recluster",
    "start": "934800",
    "end": "936899"
  },
  {
    "text": "here's a system diagram of ray-based",
    "start": "936899",
    "end": "939480"
  },
  {
    "text": "solution",
    "start": "939480",
    "end": "940320"
  },
  {
    "text": "at the beginning of each training life",
    "start": "940320",
    "end": "941940"
  },
  {
    "text": "cycle",
    "start": "941940",
    "end": "942959"
  },
  {
    "text": "we deploy a ray cluster consisting of",
    "start": "942959",
    "end": "945420"
  },
  {
    "text": "one head and multiple distributed worker",
    "start": "945420",
    "end": "947399"
  },
  {
    "text": "paths on AWS eks",
    "start": "947399",
    "end": "950160"
  },
  {
    "text": "the resource specification of recluster",
    "start": "950160",
    "end": "952920"
  },
  {
    "text": "pod is completely customizable based on",
    "start": "952920",
    "end": "955560"
  },
  {
    "text": "model requirements",
    "start": "955560",
    "end": "957360"
  },
  {
    "text": "once the recluster is online we create a",
    "start": "957360",
    "end": "960360"
  },
  {
    "text": "client part this connection established",
    "start": "960360",
    "end": "962519"
  },
  {
    "text": "to the Head node of recluster and then",
    "start": "962519",
    "end": "965160"
  },
  {
    "text": "submit the master workflow to the Head",
    "start": "965160",
    "end": "967079"
  },
  {
    "text": "node through Ray job submission API",
    "start": "967079",
    "end": "970500"
  },
  {
    "text": "once the master workflow starts running",
    "start": "970500",
    "end": "972360"
  },
  {
    "text": "on head it fetches the full list of Zone",
    "start": "972360",
    "end": "974880"
  },
  {
    "text": "IDs to be executed and then find out one",
    "start": "974880",
    "end": "977760"
  },
  {
    "text": "remote function person ID through real",
    "start": "977760",
    "end": "979920"
  },
  {
    "text": "remote API",
    "start": "979920",
    "end": "981959"
  },
  {
    "text": "since in our workflow pattern all",
    "start": "981959",
    "end": "984180"
  },
  {
    "text": "training tasks are parallel to each",
    "start": "984180",
    "end": "985860"
  },
  {
    "text": "other there are no dependencies between",
    "start": "985860",
    "end": "988079"
  },
  {
    "text": "tasks Master workflow running on the",
    "start": "988079",
    "end": "990779"
  },
  {
    "text": "head node is the owner of all tasks",
    "start": "990779",
    "end": "993540"
  },
  {
    "text": "this makes the scheduling process behind",
    "start": "993540",
    "end": "995579"
  },
  {
    "text": "the scene very straightforward",
    "start": "995579",
    "end": "997320"
  },
  {
    "text": "the master workflow requests resources",
    "start": "997320",
    "end": "1000079"
  },
  {
    "text": "from distributed scheduler to execute",
    "start": "1000079",
    "end": "1001940"
  },
  {
    "text": "the task",
    "start": "1001940",
    "end": "1003440"
  },
  {
    "text": "once worker resources are available the",
    "start": "1003440",
    "end": "1006380"
  },
  {
    "text": "scheduler grants requests and responds",
    "start": "1006380",
    "end": "1008899"
  },
  {
    "text": "with the address of the worker that is",
    "start": "1008899",
    "end": "1011000"
  },
  {
    "text": "not least to the owner",
    "start": "1011000",
    "end": "1013100"
  },
  {
    "text": "the master workflow schedules the task",
    "start": "1013100",
    "end": "1015019"
  },
  {
    "text": "by sending the task specification with",
    "start": "1015019",
    "end": "1017420"
  },
  {
    "text": "Zone ID over GRTC to the list worker",
    "start": "1017420",
    "end": "1021259"
  },
  {
    "text": "after receiving requests of the task the",
    "start": "1021259",
    "end": "1024020"
  },
  {
    "text": "worker spins after training workflow by",
    "start": "1024020",
    "end": "1026298"
  },
  {
    "text": "taking input data from data storage",
    "start": "1026299",
    "end": "1028100"
  },
  {
    "text": "based on input Zone ID",
    "start": "1028100",
    "end": "1031100"
  },
  {
    "text": "the return value of each training",
    "start": "1031100",
    "end": "1033319"
  },
  {
    "text": "workflow is also very small in size so",
    "start": "1033319",
    "end": "1035540"
  },
  {
    "text": "that the worker returns a value in line",
    "start": "1035540",
    "end": "1037220"
  },
  {
    "text": "directly to the master after training",
    "start": "1037220",
    "end": "1039319"
  },
  {
    "text": "completes",
    "start": "1039319",
    "end": "1041798"
  },
  {
    "text": "ah",
    "start": "1042799",
    "end": "1044058"
  },
  {
    "start": "1043000",
    "end": "1111000"
  },
  {
    "text": "there are many changes between the",
    "start": "1044059",
    "end": "1046280"
  },
  {
    "text": "previous solution and the current one",
    "start": "1046280",
    "end": "1047660"
  },
  {
    "text": "one of the most significant changes that",
    "start": "1047660",
    "end": "1050000"
  },
  {
    "text": "we now move out of long running service",
    "start": "1050000",
    "end": "1052400"
  },
  {
    "text": "to a serverless architecture by Library",
    "start": "1052400",
    "end": "1054860"
  },
  {
    "text": "generally",
    "start": "1054860",
    "end": "1056240"
  },
  {
    "text": "this brings us a lot of Advantage",
    "start": "1056240",
    "end": "1058280"
  },
  {
    "text": "compared with the Legacy solution",
    "start": "1058280",
    "end": "1060559"
  },
  {
    "text": "we no longer put multiple models sharing",
    "start": "1060559",
    "end": "1063080"
  },
  {
    "text": "the same distributed executor service we",
    "start": "1063080",
    "end": "1065660"
  },
  {
    "text": "now bring up one recluster dedicated to",
    "start": "1065660",
    "end": "1068179"
  },
  {
    "text": "connect with one model application",
    "start": "1068179",
    "end": "1071240"
  },
  {
    "text": "we no longer host long-running Services",
    "start": "1071240",
    "end": "1073280"
  },
  {
    "text": "we bring up a requester at the beginning",
    "start": "1073280",
    "end": "1075200"
  },
  {
    "text": "of the life cycle and bring it down once",
    "start": "1075200",
    "end": "1078260"
  },
  {
    "text": "all workers are like all workflows are",
    "start": "1078260",
    "end": "1080360"
  },
  {
    "text": "complete which gives us advantage of",
    "start": "1080360",
    "end": "1082820"
  },
  {
    "text": "seeing more safe more resources",
    "start": "1082820",
    "end": "1086120"
  },
  {
    "text": "and we have more complexities to",
    "start": "1086120",
    "end": "1088340"
  },
  {
    "text": "customize each Ray cluster to better",
    "start": "1088340",
    "end": "1090799"
  },
  {
    "text": "accommodate the specific settings per",
    "start": "1090799",
    "end": "1092960"
  },
  {
    "text": "model for example we are able to install",
    "start": "1092960",
    "end": "1095179"
  },
  {
    "text": "different versions of python packages",
    "start": "1095179",
    "end": "1097039"
  },
  {
    "text": "for model workload we are able to be",
    "start": "1097039",
    "end": "1099740"
  },
  {
    "text": "more specific and accurate in resource",
    "start": "1099740",
    "end": "1101900"
  },
  {
    "text": "requirement per worker",
    "start": "1101900",
    "end": "1104919"
  },
  {
    "text": "we also find it very simple to adopt",
    "start": "1105260",
    "end": "1107419"
  },
  {
    "text": "three in existing model workflow",
    "start": "1107419",
    "end": "1109280"
  },
  {
    "text": "implementation",
    "start": "1109280",
    "end": "1111860"
  },
  {
    "start": "1111000",
    "end": "1138000"
  },
  {
    "text": "here's some pseudo code from the",
    "start": "1111860",
    "end": "1114200"
  },
  {
    "text": "existing workflow implemented by our",
    "start": "1114200",
    "end": "1115940"
  },
  {
    "text": "machine learning engineer",
    "start": "1115940",
    "end": "1117980"
  },
  {
    "text": "we only need to literally add one line",
    "start": "1117980",
    "end": "1120020"
  },
  {
    "text": "of code to change this into a",
    "start": "1120020",
    "end": "1122720"
  },
  {
    "text": "re-executable class object or task",
    "start": "1122720",
    "end": "1126080"
  },
  {
    "text": "function",
    "start": "1126080",
    "end": "1127520"
  },
  {
    "text": "and in addition to it we only need very",
    "start": "1127520",
    "end": "1129980"
  },
  {
    "text": "few lines of code of a for Loop to",
    "start": "1129980",
    "end": "1132260"
  },
  {
    "text": "oxidate such remote codes asynchronously",
    "start": "1132260",
    "end": "1134480"
  },
  {
    "text": "this rate limitation handling if",
    "start": "1134480",
    "end": "1137059"
  },
  {
    "text": "necessary",
    "start": "1137059",
    "end": "1139600"
  },
  {
    "start": "1138000",
    "end": "1164000"
  },
  {
    "text": "here's a diagram to quickly illustrate",
    "start": "1140059",
    "end": "1142220"
  },
  {
    "text": "the idea of work workspace isolation",
    "start": "1142220",
    "end": "1144440"
  },
  {
    "text": "between different models as you can see",
    "start": "1144440",
    "end": "1146900"
  },
  {
    "text": "even though we are developing both",
    "start": "1146900",
    "end": "1148820"
  },
  {
    "text": "models with the same set of machine",
    "start": "1148820",
    "end": "1151160"
  },
  {
    "text": "learning libraries such as cycle learn",
    "start": "1151160",
    "end": "1152840"
  },
  {
    "text": "we are still able to provide",
    "start": "1152840",
    "end": "1154640"
  },
  {
    "text": "flexibilities to the owner of each model",
    "start": "1154640",
    "end": "1156740"
  },
  {
    "text": "to develop with different package",
    "start": "1156740",
    "end": "1158660"
  },
  {
    "text": "versions by creating separate recluster",
    "start": "1158660",
    "end": "1161179"
  },
  {
    "text": "assorted with each model",
    "start": "1161179",
    "end": "1164260"
  },
  {
    "start": "1164000",
    "end": "1217000"
  },
  {
    "text": "here's an example of better CPU",
    "start": "1164900",
    "end": "1166940"
  },
  {
    "text": "utilization on the same type of node",
    "start": "1166940",
    "end": "1169100"
  },
  {
    "text": "instance here we are we have a 16 CPU",
    "start": "1169100",
    "end": "1172220"
  },
  {
    "text": "machines running the same model training",
    "start": "1172220",
    "end": "1174320"
  },
  {
    "text": "jobs",
    "start": "1174320",
    "end": "1175160"
  },
  {
    "text": "in our previous system we are unable to",
    "start": "1175160",
    "end": "1177500"
  },
  {
    "text": "create concurrent salary workers per",
    "start": "1177500",
    "end": "1179480"
  },
  {
    "text": "host due to the limitation that multiple",
    "start": "1179480",
    "end": "1181880"
  },
  {
    "text": "models share the same task queue there",
    "start": "1181880",
    "end": "1184280"
  },
  {
    "text": "was only one salary worker running on",
    "start": "1184280",
    "end": "1186620"
  },
  {
    "text": "each instance with CPU utilization as",
    "start": "1186620",
    "end": "1188780"
  },
  {
    "text": "low as 10 to 15 percent",
    "start": "1188780",
    "end": "1191780"
  },
  {
    "text": "our new solution built by Ray it could",
    "start": "1191780",
    "end": "1194539"
  },
  {
    "text": "be more accurate in per worker resource",
    "start": "1194539",
    "end": "1197120"
  },
  {
    "text": "requirement based on our training",
    "start": "1197120",
    "end": "1199280"
  },
  {
    "text": "benchmarking it's sufficient to allocate",
    "start": "1199280",
    "end": "1201500"
  },
  {
    "text": "two CPU per training tasks therefore in",
    "start": "1201500",
    "end": "1204559"
  },
  {
    "text": "the recluster setup we create each",
    "start": "1204559",
    "end": "1206600"
  },
  {
    "text": "worker with two CPUs this allows us to",
    "start": "1206600",
    "end": "1209360"
  },
  {
    "text": "create multiple reworkers running",
    "start": "1209360",
    "end": "1211100"
  },
  {
    "text": "concurrently on each instance and as a",
    "start": "1211100",
    "end": "1213799"
  },
  {
    "text": "result greatly increase the CPU",
    "start": "1213799",
    "end": "1215480"
  },
  {
    "text": "utilization",
    "start": "1215480",
    "end": "1217960"
  },
  {
    "start": "1217000",
    "end": "1294000"
  },
  {
    "text": "here are some early testing results of",
    "start": "1218600",
    "end": "1220640"
  },
  {
    "text": "running a real-time Supply demand Gap",
    "start": "1220640",
    "end": "1222799"
  },
  {
    "text": "forecasting model in the test we are",
    "start": "1222799",
    "end": "1225200"
  },
  {
    "text": "handling",
    "start": "1225200",
    "end": "1226120"
  },
  {
    "text": "1500 unique training tasks over 715",
    "start": "1226120",
    "end": "1230179"
  },
  {
    "text": "zones we provisioned 10 and 6A Forex",
    "start": "1230179",
    "end": "1233780"
  },
  {
    "text": "instances as distributed executors",
    "start": "1233780",
    "end": "1236419"
  },
  {
    "text": "in the previous implementation we are",
    "start": "1236419",
    "end": "1238280"
  },
  {
    "text": "limited to create only one set of worker",
    "start": "1238280",
    "end": "1240500"
  },
  {
    "text": "per instance which gives us only 10",
    "start": "1240500",
    "end": "1242780"
  },
  {
    "text": "concrete workers to execute parallel",
    "start": "1242780",
    "end": "1244580"
  },
  {
    "text": "tasks",
    "start": "1244580",
    "end": "1245960"
  },
  {
    "text": "in the ray-based solution we are able to",
    "start": "1245960",
    "end": "1247820"
  },
  {
    "text": "be much better utilized like we are able",
    "start": "1247820",
    "end": "1250460"
  },
  {
    "text": "to much better utilize the compute",
    "start": "1250460",
    "end": "1251960"
  },
  {
    "text": "resources we end up with creating 60 Ray",
    "start": "1251960",
    "end": "1255200"
  },
  {
    "text": "workers to execute parallel tasks out of",
    "start": "1255200",
    "end": "1257600"
  },
  {
    "text": "the same set of instances",
    "start": "1257600",
    "end": "1259820"
  },
  {
    "text": "as a result we are now able to greatly",
    "start": "1259820",
    "end": "1262160"
  },
  {
    "text": "speed up the tuning completion time from",
    "start": "1262160",
    "end": "1264740"
  },
  {
    "text": "previously around four four hours to now",
    "start": "1264740",
    "end": "1267860"
  },
  {
    "text": "like 20 minutes",
    "start": "1267860",
    "end": "1269539"
  },
  {
    "text": "we also heard from our machine Engineers",
    "start": "1269539",
    "end": "1272179"
  },
  {
    "text": "the owner of this particular model that",
    "start": "1272179",
    "end": "1274280"
  },
  {
    "text": "they plan to further paralyze this model",
    "start": "1274280",
    "end": "1276320"
  },
  {
    "text": "by applying eight hourly zones like",
    "start": "1276320",
    "end": "1278720"
  },
  {
    "text": "eight hourly Horizons per Zone",
    "start": "1278720",
    "end": "1280940"
  },
  {
    "text": "this will give us around 12 000 parallel",
    "start": "1280940",
    "end": "1283820"
  },
  {
    "text": "tasks in production which will take the",
    "start": "1283820",
    "end": "1286400"
  },
  {
    "text": "previous system about one day to finish",
    "start": "1286400",
    "end": "1288260"
  },
  {
    "text": "while on Ray we expect to complete all",
    "start": "1288260",
    "end": "1290960"
  },
  {
    "text": "tasks within two to three hours",
    "start": "1290960",
    "end": "1294340"
  },
  {
    "start": "1294000",
    "end": "1303000"
  },
  {
    "text": "and next I will talk about our",
    "start": "1294679",
    "end": "1296840"
  },
  {
    "text": "integration to integrate with our",
    "start": "1296840",
    "end": "1299120"
  },
  {
    "text": "existing ml ml Ops",
    "start": "1299120",
    "end": "1303640"
  },
  {
    "start": "1303000",
    "end": "1348000"
  },
  {
    "text": "two months ago our team announced",
    "start": "1303679",
    "end": "1306140"
  },
  {
    "text": "Griffin the instacart ml platform which",
    "start": "1306140",
    "end": "1309559"
  },
  {
    "text": "is a hybrid of third-party solutions to",
    "start": "1309559",
    "end": "1312500"
  },
  {
    "text": "support diverse use cases and in-house",
    "start": "1312500",
    "end": "1315200"
  },
  {
    "text": "abstraction layer to provide unified",
    "start": "1315200",
    "end": "1317480"
  },
  {
    "text": "access to all type of solutions",
    "start": "1317480",
    "end": "1320299"
  },
  {
    "text": "Griffin helps our Machining engineer",
    "start": "1320299",
    "end": "1322460"
  },
  {
    "text": "quickly iterate on machine learning",
    "start": "1322460",
    "end": "1324500"
  },
  {
    "text": "models effortlessly manage product",
    "start": "1324500",
    "end": "1327080"
  },
  {
    "text": "releases and close the track closely",
    "start": "1327080",
    "end": "1330140"
  },
  {
    "text": "track their production application",
    "start": "1330140",
    "end": "1332720"
  },
  {
    "text": "Griffin consists of four major",
    "start": "1332720",
    "end": "1334520"
  },
  {
    "text": "components here a interface to use this",
    "start": "1334520",
    "end": "1337159"
  },
  {
    "text": "platform an oxidator to schedule",
    "start": "1337159",
    "end": "1339919"
  },
  {
    "text": "Pipelines a data platform to manage",
    "start": "1339919",
    "end": "1342500"
  },
  {
    "text": "features and a computation platform to",
    "start": "1342500",
    "end": "1345020"
  },
  {
    "text": "run the training and inference jobs",
    "start": "1345020",
    "end": "1348880"
  },
  {
    "text": "let's take a closer look at the workflow",
    "start": "1348980",
    "end": "1351020"
  },
  {
    "text": "oxidation layer in Griffin",
    "start": "1351020",
    "end": "1353360"
  },
  {
    "text": "here we have workflow manager to",
    "start": "1353360",
    "end": "1355520"
  },
  {
    "text": "schedule and manage machine learning",
    "start": "1355520",
    "end": "1357200"
  },
  {
    "text": "Pipelines",
    "start": "1357200",
    "end": "1358280"
  },
  {
    "text": "it leverages airflow to schedule",
    "start": "1358280",
    "end": "1360740"
  },
  {
    "text": "containers on a regular basis and",
    "start": "1360740",
    "end": "1363620"
  },
  {
    "text": "utilize in-house abstraction because ml",
    "start": "1363620",
    "end": "1366559"
  },
  {
    "text": "launcher to continualize task execution",
    "start": "1366559",
    "end": "1370520"
  },
  {
    "text": "ml launcher integrates different compute",
    "start": "1370520",
    "end": "1372919"
  },
  {
    "text": "backends one of the most common ones",
    "start": "1372919",
    "end": "1375200"
  },
  {
    "text": "being used by our machine engineer is",
    "start": "1375200",
    "end": "1376880"
  },
  {
    "text": "the AWS stage maker but we also support",
    "start": "1376880",
    "end": "1379100"
  },
  {
    "text": "different type of backends",
    "start": "1379100",
    "end": "1381260"
  },
  {
    "text": "as I've mentioned in previous chapter we",
    "start": "1381260",
    "end": "1383960"
  },
  {
    "text": "are known converting the parallel",
    "start": "1383960",
    "end": "1385340"
  },
  {
    "text": "training tasks from a long-running",
    "start": "1385340",
    "end": "1387799"
  },
  {
    "text": "service to a serverless application",
    "start": "1387799",
    "end": "1390320"
  },
  {
    "text": "this makes the automation much easier by",
    "start": "1390320",
    "end": "1392720"
  },
  {
    "text": "integrating re-applications with scriven",
    "start": "1392720",
    "end": "1395120"
  },
  {
    "text": "workflow oxidation layer",
    "start": "1395120",
    "end": "1397039"
  },
  {
    "text": "here we rely on the workflow manager to",
    "start": "1397039",
    "end": "1399740"
  },
  {
    "text": "run on airflow to retrain the model",
    "start": "1399740",
    "end": "1401659"
  },
  {
    "text": "regularly",
    "start": "1401659",
    "end": "1403039"
  },
  {
    "text": "and we extend ml launcher to support",
    "start": "1403039",
    "end": "1405860"
  },
  {
    "text": "backend we are recluster and array",
    "start": "1405860",
    "end": "1408440"
  },
  {
    "text": "client are running on",
    "start": "1408440",
    "end": "1411519"
  },
  {
    "start": "1411000",
    "end": "1477000"
  },
  {
    "text": "here's the integration diagram of ml",
    "start": "1413299",
    "end": "1416059"
  },
  {
    "text": "launcher plus 3.",
    "start": "1416059",
    "end": "1418100"
  },
  {
    "text": "what ml launcher requires the user to",
    "start": "1418100",
    "end": "1420260"
  },
  {
    "text": "provide is quite high level parameters",
    "start": "1420260",
    "end": "1422380"
  },
  {
    "text": "including containerized workflow image",
    "start": "1422380",
    "end": "1425260"
  },
  {
    "text": "runtime to Launch recluster resource and",
    "start": "1425260",
    "end": "1429080"
  },
  {
    "text": "dependency requirement of the requester",
    "start": "1429080",
    "end": "1432200"
  },
  {
    "text": "ml launcher then take turns to create",
    "start": "1432200",
    "end": "1434780"
  },
  {
    "text": "customer resources of Ray cluster",
    "start": "1434780",
    "end": "1437419"
  },
  {
    "text": "confirm all workers are in running",
    "start": "1437419",
    "end": "1439640"
  },
  {
    "text": "status and then create a client pod with",
    "start": "1439640",
    "end": "1442640"
  },
  {
    "text": "recluster connection parameters and then",
    "start": "1442640",
    "end": "1445460"
  },
  {
    "text": "launch the training workflow wrapped by",
    "start": "1445460",
    "end": "1447140"
  },
  {
    "text": "the re-submit command",
    "start": "1447140",
    "end": "1449360"
  },
  {
    "text": "in this way we minimize the onboarding",
    "start": "1449360",
    "end": "1451520"
  },
  {
    "text": "efforts and overhead from machine",
    "start": "1451520",
    "end": "1453620"
  },
  {
    "text": "learning engineer side",
    "start": "1453620",
    "end": "1455299"
  },
  {
    "text": "what they need to provide to Griffin is",
    "start": "1455299",
    "end": "1457580"
  },
  {
    "text": "simply high level parameters leaving our",
    "start": "1457580",
    "end": "1460100"
  },
  {
    "text": "mL of tools to handle the complexity of",
    "start": "1460100",
    "end": "1462919"
  },
  {
    "text": "workflow and workflow automations",
    "start": "1462919",
    "end": "1465740"
  },
  {
    "text": "and on the controller side we rely on",
    "start": "1465740",
    "end": "1468500"
  },
  {
    "text": "Cube Ray to deploy rig operator as a",
    "start": "1468500",
    "end": "1471559"
  },
  {
    "text": "controller of provisioning updating",
    "start": "1471559",
    "end": "1473860"
  },
  {
    "text": "deleting request resources",
    "start": "1473860",
    "end": "1478039"
  },
  {
    "start": "1477000",
    "end": "1776000"
  },
  {
    "text": "so as a next step we plan to roll out",
    "start": "1478039",
    "end": "1480860"
  },
  {
    "text": "more parallel training workloads on",
    "start": "1480860",
    "end": "1482840"
  },
  {
    "text": "recluster",
    "start": "1482840",
    "end": "1484159"
  },
  {
    "text": "and at the same time we also look into",
    "start": "1484159",
    "end": "1486559"
  },
  {
    "text": "various use cases of Ray at instacart",
    "start": "1486559",
    "end": "1489020"
  },
  {
    "text": "for example distributed training models",
    "start": "1489020",
    "end": "1492080"
  },
  {
    "text": "to train large-scale data set ml lips to",
    "start": "1492080",
    "end": "1495620"
  },
  {
    "text": "enhance the Next Generation modeling we",
    "start": "1495620",
    "end": "1498020"
  },
  {
    "text": "are super excited about our future",
    "start": "1498020",
    "end": "1499580"
  },
  {
    "text": "vision of ml infra plus 3 at instacart",
    "start": "1499580",
    "end": "1502580"
  },
  {
    "text": "and I'm looking forward to learning more",
    "start": "1502580",
    "end": "1505700"
  },
  {
    "text": "from everyone here about your insights",
    "start": "1505700",
    "end": "1507980"
  },
  {
    "text": "of applying Ray to scalable production",
    "start": "1507980",
    "end": "1510140"
  },
  {
    "text": "machine learning so if you are",
    "start": "1510140",
    "end": "1511880"
  },
  {
    "text": "interested in the offline discussion",
    "start": "1511880",
    "end": "1513440"
  },
  {
    "text": "please feel free to reach out thank you",
    "start": "1513440",
    "end": "1517100"
  },
  {
    "text": "foreign",
    "start": "1517100",
    "end": "1520100"
  },
  {
    "text": "[Applause]",
    "start": "1521000",
    "end": "1524210"
  },
  {
    "text": "if anyone has questions I can answer it",
    "start": "1533900",
    "end": "1536059"
  },
  {
    "text": "otherwise we can leave it offline",
    "start": "1536059",
    "end": "1538039"
  },
  {
    "text": "describe",
    "start": "1538039",
    "end": "1540460"
  },
  {
    "text": "hi uh so in the beginning you mentioned",
    "start": "1550700",
    "end": "1552919"
  },
  {
    "text": "that you had a 12 core machine and then",
    "start": "1552919",
    "end": "1555020"
  },
  {
    "text": "you were not really utilizing it",
    "start": "1555020",
    "end": "1556460"
  },
  {
    "text": "completely because some jobs took two",
    "start": "1556460",
    "end": "1558140"
  },
  {
    "text": "cores and some had 12 cores but in the",
    "start": "1558140",
    "end": "1561200"
  },
  {
    "text": "middle you also mentioned that in the",
    "start": "1561200",
    "end": "1563900"
  },
  {
    "text": "ray actors that you created each actor",
    "start": "1563900",
    "end": "1566840"
  },
  {
    "text": "had just two cores yeah so did you have",
    "start": "1566840",
    "end": "1569840"
  },
  {
    "text": "actors which had higher cores as well or",
    "start": "1569840",
    "end": "1573140"
  },
  {
    "text": "yeah there are different levels we can",
    "start": "1573140",
    "end": "1576020"
  },
  {
    "text": "control the resource requirement of",
    "start": "1576020",
    "end": "1578480"
  },
  {
    "text": "distributed task running array so we can",
    "start": "1578480",
    "end": "1581360"
  },
  {
    "text": "we can configuring our Ray workers with",
    "start": "1581360",
    "end": "1584900"
  },
  {
    "text": "a specific resource requirement on the",
    "start": "1584900",
    "end": "1586820"
  },
  {
    "text": "number of exact number of CPUs and",
    "start": "1586820",
    "end": "1588380"
  },
  {
    "text": "memories to like of each worker",
    "start": "1588380",
    "end": "1591020"
  },
  {
    "text": "container or like we can handle it in",
    "start": "1591020",
    "end": "1592880"
  },
  {
    "text": "the programmatic way like let me create",
    "start": "1592880",
    "end": "1595100"
  },
  {
    "text": "the reactors or the rate has function we",
    "start": "1595100",
    "end": "1597620"
  },
  {
    "text": "also have those parameters to specify",
    "start": "1597620",
    "end": "1599720"
  },
  {
    "text": "the the exact like compute resources we",
    "start": "1599720",
    "end": "1603020"
  },
  {
    "text": "want to execute this actor or this task",
    "start": "1603020",
    "end": "1605539"
  },
  {
    "text": "function so there are two levels so so",
    "start": "1605539",
    "end": "1607580"
  },
  {
    "text": "one is on the programming level if the",
    "start": "1607580",
    "end": "1610400"
  },
  {
    "text": "owner of the code and understand the",
    "start": "1610400",
    "end": "1612460"
  },
  {
    "text": "resource utilization really well about",
    "start": "1612460",
    "end": "1614720"
  },
  {
    "text": "their functions they can insert it into",
    "start": "1614720",
    "end": "1616460"
  },
  {
    "text": "code otherwise they can leave it as a",
    "start": "1616460",
    "end": "1618440"
  },
  {
    "text": "high level parameters for the machine",
    "start": "1618440",
    "end": "1619940"
  },
  {
    "text": "learning ml Ops tool to handle it when",
    "start": "1619940",
    "end": "1622039"
  },
  {
    "text": "creates those on distributed workers",
    "start": "1622039",
    "end": "1626139"
  },
  {
    "text": "any other questions",
    "start": "1634520",
    "end": "1637659"
  },
  {
    "text": "hi",
    "start": "1643279",
    "end": "1645500"
  },
  {
    "text": "hi uh how much of Ray is actually",
    "start": "1645500",
    "end": "1647900"
  },
  {
    "text": "exposed to your users so like do users",
    "start": "1647900",
    "end": "1649940"
  },
  {
    "text": "interact with the ray API like are they",
    "start": "1649940",
    "end": "1652220"
  },
  {
    "text": "able to dive deeper into the API or is",
    "start": "1652220",
    "end": "1654500"
  },
  {
    "text": "it mostly higher level like hey like you",
    "start": "1654500",
    "end": "1656600"
  },
  {
    "text": "have the ability to map over zones and",
    "start": "1656600",
    "end": "1658880"
  },
  {
    "text": "that's kind of it",
    "start": "1658880",
    "end": "1660559"
  },
  {
    "text": "um we have a different type of users",
    "start": "1660559",
    "end": "1662360"
  },
  {
    "text": "like some users like they only they are",
    "start": "1662360",
    "end": "1665360"
  },
  {
    "text": "looking for some like abstraction",
    "start": "1665360",
    "end": "1666799"
  },
  {
    "text": "libraries to convert their tasks into",
    "start": "1666799",
    "end": "1669860"
  },
  {
    "text": "re-executable like immediately in this",
    "start": "1669860",
    "end": "1672080"
  },
  {
    "text": "case we can we provide our own like",
    "start": "1672080",
    "end": "1674559"
  },
  {
    "text": "python Library abstractions to help our",
    "start": "1674559",
    "end": "1677659"
  },
  {
    "text": "users to convert their actors or",
    "start": "1677659",
    "end": "1679340"
  },
  {
    "text": "functions into Ray executable but we",
    "start": "1679340",
    "end": "1682100"
  },
  {
    "text": "also support different users like fish",
    "start": "1682100",
    "end": "1684140"
  },
  {
    "text": "understand better or free and wants to",
    "start": "1684140",
    "end": "1686659"
  },
  {
    "text": "really fine-tune their workflows for",
    "start": "1686659",
    "end": "1688220"
  },
  {
    "text": "example the distributed training use",
    "start": "1688220",
    "end": "1690200"
  },
  {
    "text": "cases that user needs to write a lot of",
    "start": "1690200",
    "end": "1692059"
  },
  {
    "text": "code of retrain red data set they",
    "start": "1692059",
    "end": "1694220"
  },
  {
    "text": "understand better on the system like the",
    "start": "1694220",
    "end": "1697159"
  },
  {
    "text": "race operating on the in this case we",
    "start": "1697159",
    "end": "1698900"
  },
  {
    "text": "also leave the flexibilities for those",
    "start": "1698900",
    "end": "1701299"
  },
  {
    "text": "users to write their own code but in the",
    "start": "1701299",
    "end": "1703760"
  },
  {
    "text": "end we provide those launching like",
    "start": "1703760",
    "end": "1705440"
  },
  {
    "text": "tools so that no matter you are like you",
    "start": "1705440",
    "end": "1708919"
  },
  {
    "text": "you are like you are the user reliant on",
    "start": "1708919",
    "end": "1710900"
  },
  {
    "text": "the high level abstractions or you write",
    "start": "1710900",
    "end": "1712640"
  },
  {
    "text": "all your code like all those container",
    "start": "1712640",
    "end": "1714679"
  },
  {
    "text": "workflows can be launched through the",
    "start": "1714679",
    "end": "1716360"
  },
  {
    "text": "Unified toolings",
    "start": "1716360",
    "end": "1719320"
  },
  {
    "text": "and how are you handling concept drift",
    "start": "1721760",
    "end": "1724279"
  },
  {
    "text": "monitoring and other observability",
    "start": "1724279",
    "end": "1726020"
  },
  {
    "text": "factors for 1500 models",
    "start": "1726020",
    "end": "1729820"
  },
  {
    "text": "we have like we are integrating uh we",
    "start": "1730460",
    "end": "1733580"
  },
  {
    "text": "are integrating our metrics on",
    "start": "1733580",
    "end": "1735620"
  },
  {
    "text": "monitoring like with datadog like we can",
    "start": "1735620",
    "end": "1737659"
  },
  {
    "text": "push the manager like the the metrics we",
    "start": "1737659",
    "end": "1740360"
  },
  {
    "text": "care about like store datadog and create",
    "start": "1740360",
    "end": "1742039"
  },
  {
    "text": "the customized dashboard based on the",
    "start": "1742039",
    "end": "1744740"
  },
  {
    "text": "product lines and if like you are",
    "start": "1744740",
    "end": "1747440"
  },
  {
    "text": "talking about like another level of like",
    "start": "1747440",
    "end": "1749419"
  },
  {
    "text": "a model like model quality monitoring",
    "start": "1749419",
    "end": "1751820"
  },
  {
    "text": "but also like working closely with the",
    "start": "1751820",
    "end": "1753980"
  },
  {
    "text": "rise on those type of monitoring and",
    "start": "1753980",
    "end": "1756320"
  },
  {
    "text": "validation so different type of",
    "start": "1756320",
    "end": "1757940"
  },
  {
    "text": "monitoring",
    "start": "1757940",
    "end": "1760898"
  },
  {
    "text": "okay yeah we're at the end of time so",
    "start": "1762440",
    "end": "1764539"
  },
  {
    "text": "any remaining questions can be taken",
    "start": "1764539",
    "end": "1766100"
  },
  {
    "text": "offline okay thank you so much for being",
    "start": "1766100",
    "end": "1768260"
  },
  {
    "text": "here thank you",
    "start": "1768260",
    "end": "1771100"
  }
]
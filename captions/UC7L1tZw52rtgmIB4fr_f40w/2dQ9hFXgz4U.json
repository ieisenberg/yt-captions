[
  {
    "start": "0",
    "end": "43000"
  },
  {
    "text": "hey um welcome uh welcome everyone to",
    "start": "6839",
    "end": "10080"
  },
  {
    "text": "our session uh my name is Linson I'm a",
    "start": "10080",
    "end": "13080"
  },
  {
    "text": "research engineer from IBM research",
    "start": "13080",
    "end": "15660"
  },
  {
    "text": "so this will be a use case session so",
    "start": "15660",
    "end": "19140"
  },
  {
    "text": "you won't really see any codes in this",
    "start": "19140",
    "end": "21660"
  },
  {
    "text": "session but hopefully you will like this",
    "start": "21660",
    "end": "23960"
  },
  {
    "text": "so for today's topic I will talk about",
    "start": "23960",
    "end": "28439"
  },
  {
    "text": "how we leverage specifically reworkflow",
    "start": "28439",
    "end": "31740"
  },
  {
    "text": "in our effort around foundation models",
    "start": "31740",
    "end": "34800"
  },
  {
    "text": "or large language models so the two",
    "start": "34800",
    "end": "37200"
  },
  {
    "text": "keywords here today are Foundation",
    "start": "37200",
    "end": "39780"
  },
  {
    "text": "models and reworkflow",
    "start": "39780",
    "end": "43140"
  },
  {
    "start": "43000",
    "end": "76000"
  },
  {
    "text": "let's get started so we have a very",
    "start": "43140",
    "end": "45840"
  },
  {
    "text": "simple agenda today so I will start with",
    "start": "45840",
    "end": "48360"
  },
  {
    "text": "some brief introduction around",
    "start": "48360",
    "end": "50280"
  },
  {
    "text": "foundation models then I will talk about",
    "start": "50280",
    "end": "53120"
  },
  {
    "text": "one important effort we've been doing",
    "start": "53120",
    "end": "55680"
  },
  {
    "text": "around foundation model which is to",
    "start": "55680",
    "end": "57840"
  },
  {
    "text": "build the what we call scale out",
    "start": "57840",
    "end": "60120"
  },
  {
    "text": "middleware and I will also talk about",
    "start": "60120",
    "end": "62280"
  },
  {
    "text": "how refitting to the picture",
    "start": "62280",
    "end": "64680"
  },
  {
    "text": "lastly I will do a little bit deep dive",
    "start": "64680",
    "end": "67200"
  },
  {
    "text": "into how exactly why we think real",
    "start": "67200",
    "end": "70080"
  },
  {
    "text": "workflow is helpful and how we leverage",
    "start": "70080",
    "end": "72659"
  },
  {
    "text": "reworkflow around this effort",
    "start": "72659",
    "end": "76880"
  },
  {
    "start": "76000",
    "end": "146000"
  },
  {
    "text": "okay so to start with what is",
    "start": "76920",
    "end": "80400"
  },
  {
    "text": "Foundation model what are Foundation",
    "start": "80400",
    "end": "82200"
  },
  {
    "text": "models I think some of us might not uh",
    "start": "82200",
    "end": "85740"
  },
  {
    "text": "hear this term before but very likely",
    "start": "85740",
    "end": "87720"
  },
  {
    "text": "you've been using Foundation models in",
    "start": "87720",
    "end": "89340"
  },
  {
    "text": "the past so basically Foundation models",
    "start": "89340",
    "end": "91560"
  },
  {
    "text": "are essentially large pre-trained models",
    "start": "91560",
    "end": "93840"
  },
  {
    "text": "that can be fine-tuned to a variety of",
    "start": "93840",
    "end": "97140"
  },
  {
    "text": "different Downstream tasks so I think",
    "start": "97140",
    "end": "99240"
  },
  {
    "text": "nowadays the most common examples are",
    "start": "99240",
    "end": "103020"
  },
  {
    "text": "really large language models you know",
    "start": "103020",
    "end": "105360"
  },
  {
    "text": "you know those things we heard all the",
    "start": "105360",
    "end": "107460"
  },
  {
    "text": "time like birth Roberta T5 gpt3 you know",
    "start": "107460",
    "end": "111540"
  },
  {
    "text": "it's essentially large models that are",
    "start": "111540",
    "end": "114060"
  },
  {
    "text": "pre-trained to understand something in",
    "start": "114060",
    "end": "116939"
  },
  {
    "text": "general rather than a very specific task",
    "start": "116939",
    "end": "119340"
  },
  {
    "text": "which you can just later on fine tune it",
    "start": "119340",
    "end": "122220"
  },
  {
    "text": "for various of different Downstream",
    "start": "122220",
    "end": "124380"
  },
  {
    "text": "tasks",
    "start": "124380",
    "end": "126680"
  },
  {
    "text": "uh well nowadays when people talk about",
    "start": "126680",
    "end": "130080"
  },
  {
    "text": "Foundation models see uh like many of",
    "start": "130080",
    "end": "132180"
  },
  {
    "text": "them just you just meet uh large",
    "start": "132180",
    "end": "134340"
  },
  {
    "text": "language models but essentially",
    "start": "134340",
    "end": "135840"
  },
  {
    "text": "Foundation models are much more beyond",
    "start": "135840",
    "end": "138480"
  },
  {
    "text": "that so they are essentially Foundation",
    "start": "138480",
    "end": "140400"
  },
  {
    "text": "models that are built or being built in",
    "start": "140400",
    "end": "143819"
  },
  {
    "text": "obvious of domains",
    "start": "143819",
    "end": "147140"
  },
  {
    "start": "146000",
    "end": "370000"
  },
  {
    "text": "that's a very quick introduction on what",
    "start": "147720",
    "end": "150660"
  },
  {
    "text": "are Foundation models so Foundation",
    "start": "150660",
    "end": "152760"
  },
  {
    "text": "models has been a very important uh",
    "start": "152760",
    "end": "156120"
  },
  {
    "text": "piece within IBM research this year and",
    "start": "156120",
    "end": "159440"
  },
  {
    "text": "one of the major efforts we've been",
    "start": "159440",
    "end": "162180"
  },
  {
    "text": "working on is to build this thing called",
    "start": "162180",
    "end": "164220"
  },
  {
    "text": "scale out middleware",
    "start": "164220",
    "end": "167360"
  },
  {
    "text": "so this is a pretty simplified version",
    "start": "167640",
    "end": "171000"
  },
  {
    "text": "of our end to end stack for uh building",
    "start": "171000",
    "end": "174840"
  },
  {
    "text": "our foundation model so we can take a",
    "start": "174840",
    "end": "178620"
  },
  {
    "text": "look at this from bottom up so on the",
    "start": "178620",
    "end": "180720"
  },
  {
    "text": "very bottom part that is our that is",
    "start": "180720",
    "end": "183120"
  },
  {
    "text": "where our info are so you know things",
    "start": "183120",
    "end": "185819"
  },
  {
    "text": "like Hardware we are our uh you know",
    "start": "185819",
    "end": "188760"
  },
  {
    "text": "gpus clusters are slightly on top of",
    "start": "188760",
    "end": "192239"
  },
  {
    "text": "that that is our Cloud platform so we've",
    "start": "192239",
    "end": "196319"
  },
  {
    "text": "been leveraging red hat openshift which",
    "start": "196319",
    "end": "198959"
  },
  {
    "text": "is uh the commercial version of",
    "start": "198959",
    "end": "201540"
  },
  {
    "text": "kubernetes as our hybrid Cloud platform",
    "start": "201540",
    "end": "205080"
  },
  {
    "text": "here I won't go into uh details but",
    "start": "205080",
    "end": "208739"
  },
  {
    "text": "basically we leverage this to enable us",
    "start": "208739",
    "end": "211080"
  },
  {
    "text": "to run anything anywhere in hybrid Cloud",
    "start": "211080",
    "end": "213959"
  },
  {
    "text": "fashion",
    "start": "213959",
    "end": "215519"
  },
  {
    "text": "so uh typically these two things can",
    "start": "215519",
    "end": "220860"
  },
  {
    "text": "already form a stack so you can already",
    "start": "220860",
    "end": "222659"
  },
  {
    "text": "run your application code on top of that",
    "start": "222659",
    "end": "226040"
  },
  {
    "text": "but we find that our users and our",
    "start": "226040",
    "end": "229860"
  },
  {
    "text": "researchers see had many headaches when",
    "start": "229860",
    "end": "233819"
  },
  {
    "text": "they start working on Foundation models",
    "start": "233819",
    "end": "235860"
  },
  {
    "text": "when they start working on like large",
    "start": "235860",
    "end": "238019"
  },
  {
    "text": "models so I can give two quick examples",
    "start": "238019",
    "end": "241019"
  },
  {
    "text": "for example many of our users or",
    "start": "241019",
    "end": "243659"
  },
  {
    "text": "researchers they start their video model",
    "start": "243659",
    "end": "247260"
  },
  {
    "text": "scratch from their local from their",
    "start": "247260",
    "end": "249420"
  },
  {
    "text": "favorite uh like a Jupiter notebook",
    "start": "249420",
    "end": "252360"
  },
  {
    "text": "environment right so it might be easier",
    "start": "252360",
    "end": "255540"
  },
  {
    "text": "for them to just scale that on a single",
    "start": "255540",
    "end": "258780"
  },
  {
    "text": "GPU or a single node with multiple GPU",
    "start": "258780",
    "end": "261479"
  },
  {
    "text": "but they often find some headaches when",
    "start": "261479",
    "end": "265020"
  },
  {
    "text": "they try to deploy that on a large",
    "start": "265020",
    "end": "267479"
  },
  {
    "text": "cluster that has many nodes each node",
    "start": "267479",
    "end": "269880"
  },
  {
    "text": "has many gpus another headache would be",
    "start": "269880",
    "end": "273300"
  },
  {
    "text": "data ingestion pipeline so so again",
    "start": "273300",
    "end": "277139"
  },
  {
    "text": "Foundation models are large huge models",
    "start": "277139",
    "end": "279900"
  },
  {
    "text": "which also requires huge volume of input",
    "start": "279900",
    "end": "282960"
  },
  {
    "text": "data to train so it's not something you",
    "start": "282960",
    "end": "285060"
  },
  {
    "text": "can just download to your local download",
    "start": "285060",
    "end": "287160"
  },
  {
    "text": "to your node run your you know data",
    "start": "287160",
    "end": "289560"
  },
  {
    "text": "curation pipeline there you need to",
    "start": "289560",
    "end": "291540"
  },
  {
    "text": "really build a pipeline build a",
    "start": "291540",
    "end": "293639"
  },
  {
    "text": "efficient pipeline that can process",
    "start": "293639",
    "end": "296220"
  },
  {
    "text": "import data batch by batch in a very",
    "start": "296220",
    "end": "298620"
  },
  {
    "text": "efficient manner so that's also one of",
    "start": "298620",
    "end": "300840"
  },
  {
    "text": "the headaches so really we want to build",
    "start": "300840",
    "end": "304080"
  },
  {
    "text": "this middleware so it is a cloud native",
    "start": "304080",
    "end": "307080"
  },
  {
    "text": "and fully customized stack that enable",
    "start": "307080",
    "end": "310259"
  },
  {
    "text": "our users and researchers to really",
    "start": "310259",
    "end": "313259"
  },
  {
    "text": "uh be able to do something like hey this",
    "start": "313259",
    "end": "315900"
  },
  {
    "text": "is my model built from a notebook just",
    "start": "315900",
    "end": "319440"
  },
  {
    "text": "take this and uh I don't care how your",
    "start": "319440",
    "end": "322380"
  },
  {
    "text": "cluster look like just take this run",
    "start": "322380",
    "end": "324720"
  },
  {
    "text": "this on a let's say 10 nodes each with",
    "start": "324720",
    "end": "327120"
  },
  {
    "text": "eight gpus then we should be able to",
    "start": "327120",
    "end": "329400"
  },
  {
    "text": "just do that for them",
    "start": "329400",
    "end": "332479"
  },
  {
    "text": "so this is just a little bit zoomed",
    "start": "332699",
    "end": "335100"
  },
  {
    "text": "version of",
    "start": "335100",
    "end": "336660"
  },
  {
    "text": "the previous slides the upper part",
    "start": "336660",
    "end": "339479"
  },
  {
    "text": "so basically at the core we've been",
    "start": "339479",
    "end": "341759"
  },
  {
    "text": "leveraging uh Ray and torch to uh to do",
    "start": "341759",
    "end": "345600"
  },
  {
    "text": "this so we are leveraging a thought",
    "start": "345600",
    "end": "348660"
  },
  {
    "text": "portfolio to do everything that is",
    "start": "348660",
    "end": "351240"
  },
  {
    "text": "training specific uh training specific",
    "start": "351240",
    "end": "354240"
  },
  {
    "text": "and we've been leveraging rate uh",
    "start": "354240",
    "end": "356699"
  },
  {
    "text": "specifically workflow to do anything",
    "start": "356699",
    "end": "359039"
  },
  {
    "text": "that is pre-training and after training",
    "start": "359039",
    "end": "361440"
  },
  {
    "text": "for example after the fine tuning how do",
    "start": "361440",
    "end": "363960"
  },
  {
    "text": "we do evaluation we will talk more about",
    "start": "363960",
    "end": "367199"
  },
  {
    "text": "this later",
    "start": "367199",
    "end": "369660"
  },
  {
    "text": "okay so uh",
    "start": "369660",
    "end": "372900"
  },
  {
    "text": "before I talk about how Rick a",
    "start": "372900",
    "end": "375660"
  },
  {
    "text": "reworkflow helps I think uh despite I",
    "start": "375660",
    "end": "379199"
  },
  {
    "text": "think all of us are pretty familiar with",
    "start": "379199",
    "end": "381240"
  },
  {
    "text": "brie since this is recent meet but I",
    "start": "381240",
    "end": "384120"
  },
  {
    "text": "think reworkflow as a beta feature or",
    "start": "384120",
    "end": "387180"
  },
  {
    "text": "beta branch of Ray might be still new to",
    "start": "387180",
    "end": "390720"
  },
  {
    "text": "some of us so I would like to just use",
    "start": "390720",
    "end": "392940"
  },
  {
    "text": "one minute to quickly talk about",
    "start": "392940",
    "end": "394440"
  },
  {
    "text": "reworkflow so real workflow is basically",
    "start": "394440",
    "end": "397860"
  },
  {
    "text": "a durable layer on top of uh Ray core or",
    "start": "397860",
    "end": "401880"
  },
  {
    "text": "re-task whichever you prefer to call",
    "start": "401880",
    "end": "404100"
  },
  {
    "text": "that and the computation it is powered",
    "start": "404100",
    "end": "407639"
  },
  {
    "text": "by record tasks while it adds this",
    "start": "407639",
    "end": "410100"
  },
  {
    "text": "durable storage layer for Tech pointing",
    "start": "410100",
    "end": "412560"
  },
  {
    "text": "purpose it has many more but the core",
    "start": "412560",
    "end": "416580"
  },
  {
    "text": "part is basically it is powered by",
    "start": "416580",
    "end": "418740"
  },
  {
    "text": "retask and it is backed by physical",
    "start": "418740",
    "end": "422039"
  },
  {
    "text": "storage for Tech pointing purpose clear",
    "start": "422039",
    "end": "425039"
  },
  {
    "text": "the storage can be your local storage",
    "start": "425039",
    "end": "427199"
  },
  {
    "text": "can be your FS it can be S3 things like",
    "start": "427199",
    "end": "431280"
  },
  {
    "text": "that and we think real workflow because",
    "start": "431280",
    "end": "433919"
  },
  {
    "text": "of this real workflow compared to the",
    "start": "433919",
    "end": "436160"
  },
  {
    "text": "re-core task it provides actually better",
    "start": "436160",
    "end": "439800"
  },
  {
    "text": "support for production level large scale",
    "start": "439800",
    "end": "443220"
  },
  {
    "text": "and long-running workflows",
    "start": "443220",
    "end": "446520"
  },
  {
    "text": "again I won't go into any details on",
    "start": "446520",
    "end": "449280"
  },
  {
    "text": "real workflow spec but there was a very",
    "start": "449280",
    "end": "452520"
  },
  {
    "text": "good session yesterday so in case you",
    "start": "452520",
    "end": "455400"
  },
  {
    "text": "missed that I have the full link here",
    "start": "455400",
    "end": "458580"
  },
  {
    "text": "basically it's a deep dive into real",
    "start": "458580",
    "end": "460440"
  },
  {
    "text": "workflow that is presented by Ray team",
    "start": "460440",
    "end": "464720"
  },
  {
    "start": "465000",
    "end": "785000"
  },
  {
    "text": "okay",
    "start": "466020",
    "end": "467400"
  },
  {
    "text": "so Foundation model with reworkflow I",
    "start": "467400",
    "end": "470699"
  },
  {
    "text": "think to really understand why we think",
    "start": "470699",
    "end": "473280"
  },
  {
    "text": "reworkful helps in our foundation mode",
    "start": "473280",
    "end": "476160"
  },
  {
    "text": "of Pipeline and how it helps I think",
    "start": "476160",
    "end": "478560"
  },
  {
    "text": "it's better to understand better",
    "start": "478560",
    "end": "481380"
  },
  {
    "text": "um how Foundation model pipeline looks",
    "start": "481380",
    "end": "484380"
  },
  {
    "text": "like and how it is different from a",
    "start": "484380",
    "end": "487080"
  },
  {
    "text": "regular small model training or",
    "start": "487080",
    "end": "489000"
  },
  {
    "text": "evaluation pipeline",
    "start": "489000",
    "end": "491160"
  },
  {
    "text": "so here I have two very simplified",
    "start": "491160",
    "end": "494520"
  },
  {
    "text": "version of pipeline for both training",
    "start": "494520",
    "end": "497280"
  },
  {
    "text": "stage and fine-tuning Stage so from here",
    "start": "497280",
    "end": "499800"
  },
  {
    "text": "you will see it's just as simple as any",
    "start": "499800",
    "end": "502979"
  },
  {
    "text": "other small data training as well you",
    "start": "502979",
    "end": "505500"
  },
  {
    "text": "always start with some data collection",
    "start": "505500",
    "end": "507800"
  },
  {
    "text": "you go to data pre-processing you go to",
    "start": "507800",
    "end": "511440"
  },
  {
    "text": "model training and at the end you have",
    "start": "511440",
    "end": "514080"
  },
  {
    "text": "maybe hyper parameter tuning so same",
    "start": "514080",
    "end": "517200"
  },
  {
    "text": "thing for fine tuning but let's look at",
    "start": "517200",
    "end": "519659"
  },
  {
    "text": "some of the properties that maybe only a",
    "start": "519659",
    "end": "523080"
  },
  {
    "text": "large models have or only large models",
    "start": "523080",
    "end": "526020"
  },
  {
    "text": "that suffer",
    "start": "526020",
    "end": "528720"
  },
  {
    "text": "so I think the first one is multi-stage",
    "start": "528720",
    "end": "531120"
  },
  {
    "text": "and long running so again the upper part",
    "start": "531120",
    "end": "534420"
  },
  {
    "text": "is the simplified version so it's a good",
    "start": "534420",
    "end": "537180"
  },
  {
    "text": "data Gathering and data curation but if",
    "start": "537180",
    "end": "539820"
  },
  {
    "text": "you break down each one of them it is",
    "start": "539820",
    "end": "541980"
  },
  {
    "text": "actually contained it actually contains",
    "start": "541980",
    "end": "544080"
  },
  {
    "text": "many small steps so here I'm giving",
    "start": "544080",
    "end": "546540"
  },
  {
    "text": "example of the data curation pipelining",
    "start": "546540",
    "end": "549839"
  },
  {
    "text": "steps for T5 model this steps were from",
    "start": "549839",
    "end": "553320"
  },
  {
    "text": "the original T5 paper so as you can see",
    "start": "553320",
    "end": "556019"
  },
  {
    "text": "although it's only eight data curation",
    "start": "556019",
    "end": "558560"
  },
  {
    "text": "step but it is actually a very it",
    "start": "558560",
    "end": "561899"
  },
  {
    "text": "actually contains many small steps and",
    "start": "561899",
    "end": "564360"
  },
  {
    "text": "these small steps chain together",
    "start": "564360",
    "end": "566399"
  },
  {
    "text": "so one problem is so let's see uh since",
    "start": "566399",
    "end": "570779"
  },
  {
    "text": "again Foundation models are large models",
    "start": "570779",
    "end": "573240"
  },
  {
    "text": "so the input data volume is also huge so",
    "start": "573240",
    "end": "575700"
  },
  {
    "text": "we are talking about sometimes it could",
    "start": "575700",
    "end": "577380"
  },
  {
    "text": "be it could take days to fully pass all",
    "start": "577380",
    "end": "579959"
  },
  {
    "text": "your data so what if right your uh only",
    "start": "579959",
    "end": "584700"
  },
  {
    "text": "portion of your batches of data is",
    "start": "584700",
    "end": "586920"
  },
  {
    "text": "finished when your system is done or",
    "start": "586920",
    "end": "589860"
  },
  {
    "text": "even what if let's see uh",
    "start": "589860",
    "end": "592700"
  },
  {
    "text": "you go to maybe middle of the mini steps",
    "start": "592700",
    "end": "596820"
  },
  {
    "text": "and Sunday or system is done do you have",
    "start": "596820",
    "end": "599279"
  },
  {
    "text": "to restart from the very Square the very",
    "start": "599279",
    "end": "602459"
  },
  {
    "text": "scratch of that batch of data or you can",
    "start": "602459",
    "end": "604920"
  },
  {
    "text": "somehow magically just restart from the",
    "start": "604920",
    "end": "607980"
  },
  {
    "text": "exact mini mini step here so that's one",
    "start": "607980",
    "end": "611540"
  },
  {
    "text": "issue or problem that we have to solve",
    "start": "611540",
    "end": "615600"
  },
  {
    "text": "so another thing is uh resource",
    "start": "615600",
    "end": "618959"
  },
  {
    "text": "allocation and data locality here I'm",
    "start": "618959",
    "end": "621360"
  },
  {
    "text": "using the simplified version of fine",
    "start": "621360",
    "end": "624060"
  },
  {
    "text": "tuning so fine tuning usually start with",
    "start": "624060",
    "end": "626700"
  },
  {
    "text": "some domain data pre-processing and",
    "start": "626700",
    "end": "628500"
  },
  {
    "text": "Gathering followed by hap filtering hap",
    "start": "628500",
    "end": "632160"
  },
  {
    "text": "filtering for those of us who are not",
    "start": "632160",
    "end": "634560"
  },
  {
    "text": "familiar with this so This step",
    "start": "634560",
    "end": "636420"
  },
  {
    "text": "basically you pass your data to a model",
    "start": "636420",
    "end": "638880"
  },
  {
    "text": "so there is a profanity check model so",
    "start": "638880",
    "end": "642600"
  },
  {
    "text": "it's this step is essentially a model",
    "start": "642600",
    "end": "644640"
  },
  {
    "text": "influencing you pass your data to that",
    "start": "644640",
    "end": "647040"
  },
  {
    "text": "model and that model will give you a",
    "start": "647040",
    "end": "648899"
  },
  {
    "text": "score so you can leverage that score to",
    "start": "648899",
    "end": "651060"
  },
  {
    "text": "decide if you want to remove those",
    "start": "651060",
    "end": "653700"
  },
  {
    "text": "sentences for profanity check",
    "start": "653700",
    "end": "656040"
  },
  {
    "text": "and lastly we have our fine tuning which",
    "start": "656040",
    "end": "659279"
  },
  {
    "text": "is also model training so as you could",
    "start": "659279",
    "end": "661680"
  },
  {
    "text": "see these three steps are essentially",
    "start": "661680",
    "end": "663779"
  },
  {
    "text": "using very different resources data",
    "start": "663779",
    "end": "666360"
  },
  {
    "text": "pre-processing is CPU bound so you want",
    "start": "666360",
    "end": "668459"
  },
  {
    "text": "to allocate as many CPUs as possible and",
    "start": "668459",
    "end": "671820"
  },
  {
    "text": "you don't need gpus here for hap",
    "start": "671820",
    "end": "674220"
  },
  {
    "text": "filtering it since it's a model",
    "start": "674220",
    "end": "676860"
  },
  {
    "text": "influencing here it's a small model it's",
    "start": "676860",
    "end": "680160"
  },
  {
    "text": "a very efficient fast inferencing so you",
    "start": "680160",
    "end": "683399"
  },
  {
    "text": "actually only need one single GPU and",
    "start": "683399",
    "end": "685680"
  },
  {
    "text": "one node to do that so you don't want to",
    "start": "685680",
    "end": "687959"
  },
  {
    "text": "allocate one node to do that while maybe",
    "start": "687959",
    "end": "690899"
  },
  {
    "text": "most of the gpus inside that nodes are",
    "start": "690899",
    "end": "694140"
  },
  {
    "text": "idle and for the last part we need here",
    "start": "694140",
    "end": "697019"
  },
  {
    "text": "you know we just want as many nodes as",
    "start": "697019",
    "end": "699240"
  },
  {
    "text": "possible as many gpus as possible so how",
    "start": "699240",
    "end": "702300"
  },
  {
    "text": "can you do resource allocation in your",
    "start": "702300",
    "end": "704519"
  },
  {
    "text": "pro profession how can you efficiently",
    "start": "704519",
    "end": "706880"
  },
  {
    "text": "leverage all your resources and also",
    "start": "706880",
    "end": "710160"
  },
  {
    "text": "very importantly how can you achieve Max",
    "start": "710160",
    "end": "713279"
  },
  {
    "text": "data locality so minimal amount of data",
    "start": "713279",
    "end": "717060"
  },
  {
    "text": "is has to be transferred between nodes",
    "start": "717060",
    "end": "719459"
  },
  {
    "text": "or between gpus",
    "start": "719459",
    "end": "722480"
  },
  {
    "text": "so the uh the third property is what we",
    "start": "723720",
    "end": "727380"
  },
  {
    "text": "call reusable workflow and massive",
    "start": "727380",
    "end": "729660"
  },
  {
    "text": "parallel",
    "start": "729660",
    "end": "730680"
  },
  {
    "text": "so again let's go back to maybe this",
    "start": "730680",
    "end": "735060"
  },
  {
    "text": "part if you look at the upper part it",
    "start": "735060",
    "end": "737399"
  },
  {
    "text": "looks like for the fine tuning stage it",
    "start": "737399",
    "end": "740040"
  },
  {
    "text": "looks like one workflow but it is",
    "start": "740040",
    "end": "742560"
  },
  {
    "text": "essentially tons of workflows that can",
    "start": "742560",
    "end": "745140"
  },
  {
    "text": "be run in parallel because",
    "start": "745140",
    "end": "747120"
  },
  {
    "text": "for each fine-tuning job they actually",
    "start": "747120",
    "end": "750380"
  },
  {
    "text": "leverage or they require very different",
    "start": "750380",
    "end": "753060"
  },
  {
    "text": "domain data so the domain data",
    "start": "753060",
    "end": "755579"
  },
  {
    "text": "pre-processing is very different the",
    "start": "755579",
    "end": "757320"
  },
  {
    "text": "hyper parameter selection is very",
    "start": "757320",
    "end": "759180"
  },
  {
    "text": "different the fine-tuning you know you",
    "start": "759180",
    "end": "761940"
  },
  {
    "text": "train on different data and model",
    "start": "761940",
    "end": "763980"
  },
  {
    "text": "serving you serve different model based",
    "start": "763980",
    "end": "766380"
  },
  {
    "text": "on the very specific tasks so although",
    "start": "766380",
    "end": "769440"
  },
  {
    "text": "it looks like one workflow but it is",
    "start": "769440",
    "end": "772079"
  },
  {
    "text": "essentially one template of workflow",
    "start": "772079",
    "end": "774420"
  },
  {
    "text": "that you will keep reusing you will have",
    "start": "774420",
    "end": "777180"
  },
  {
    "text": "a bunch of different copies that each",
    "start": "777180",
    "end": "779940"
  },
  {
    "text": "fade into different data and goes into",
    "start": "779940",
    "end": "782220"
  },
  {
    "text": "different Pipelines",
    "start": "782220",
    "end": "785120"
  },
  {
    "start": "785000",
    "end": "840000"
  },
  {
    "text": "okay so uh I think to summarize a little",
    "start": "786360",
    "end": "789839"
  },
  {
    "text": "bit so uh I think Foundation model",
    "start": "789839",
    "end": "792240"
  },
  {
    "text": "pipeline uh due to the you know due to",
    "start": "792240",
    "end": "795959"
  },
  {
    "text": "the volume of the input data as well as",
    "start": "795959",
    "end": "798180"
  },
  {
    "text": "the complexity of the model itself it",
    "start": "798180",
    "end": "801180"
  },
  {
    "text": "naturally has these features it is a",
    "start": "801180",
    "end": "805019"
  },
  {
    "text": "multi-stage long-running pipeline which",
    "start": "805019",
    "end": "807959"
  },
  {
    "text": "requires very efficient resource",
    "start": "807959",
    "end": "810660"
  },
  {
    "text": "allocation and uh also we need a certain",
    "start": "810660",
    "end": "814139"
  },
  {
    "text": "template to be able to reuse the same",
    "start": "814139",
    "end": "817320"
  },
  {
    "text": "workflow multiple times",
    "start": "817320",
    "end": "819480"
  },
  {
    "text": "so I think uh I won't go into too much",
    "start": "819480",
    "end": "823620"
  },
  {
    "text": "detail on this slide but basically with",
    "start": "823620",
    "end": "827459"
  },
  {
    "text": "all these issues or questions we've been",
    "start": "827459",
    "end": "830459"
  },
  {
    "text": "started looking at reworkflow and",
    "start": "830459",
    "end": "832620"
  },
  {
    "text": "checking all various features from",
    "start": "832620",
    "end": "834720"
  },
  {
    "text": "workflow to see how Rick flow real",
    "start": "834720",
    "end": "837120"
  },
  {
    "text": "workflow could help and could support",
    "start": "837120",
    "end": "839160"
  },
  {
    "text": "all of this",
    "start": "839160",
    "end": "841860"
  },
  {
    "start": "840000",
    "end": "1168000"
  },
  {
    "text": "so this is what we've been currently",
    "start": "841860",
    "end": "844920"
  },
  {
    "text": "leveraging reworkflow to sort of like",
    "start": "844920",
    "end": "848279"
  },
  {
    "text": "help each of these so to start with",
    "start": "848279",
    "end": "851639"
  },
  {
    "text": "remember why uh this why introduce a",
    "start": "851639",
    "end": "856019"
  },
  {
    "text": "real workflow one important feature they",
    "start": "856019",
    "end": "859380"
  },
  {
    "text": "have is reworkflow provides this graph",
    "start": "859380",
    "end": "862260"
  },
  {
    "text": "layer they provide a dab layer so",
    "start": "862260",
    "end": "864959"
  },
  {
    "text": "because of that it's naturally a very",
    "start": "864959",
    "end": "867540"
  },
  {
    "text": "good way you can pipeline different",
    "start": "867540",
    "end": "869760"
  },
  {
    "text": "tasks together so unlike regular recall",
    "start": "869760",
    "end": "873240"
  },
  {
    "text": "where you really need to do a chain",
    "start": "873240",
    "end": "876300"
  },
  {
    "text": "remote on many different steps here you",
    "start": "876300",
    "end": "879000"
  },
  {
    "text": "can actually build a build a graph it",
    "start": "879000",
    "end": "881760"
  },
  {
    "text": "can be you know two-step nested with",
    "start": "881760",
    "end": "883920"
  },
  {
    "text": "each other they all go to the third",
    "start": "883920",
    "end": "885839"
  },
  {
    "text": "steps and you know no matter how complex",
    "start": "885839",
    "end": "889019"
  },
  {
    "text": "the graph is you can always build the",
    "start": "889019",
    "end": "890820"
  },
  {
    "text": "graph first",
    "start": "890820",
    "end": "891959"
  },
  {
    "text": "and also because of this it naturally",
    "start": "891959",
    "end": "894899"
  },
  {
    "text": "solves the problem of the last one which",
    "start": "894899",
    "end": "897060"
  },
  {
    "text": "is reusable workflow because once you",
    "start": "897060",
    "end": "899399"
  },
  {
    "text": "have a graph layer you are essentially",
    "start": "899399",
    "end": "901620"
  },
  {
    "text": "having a template so you can basically",
    "start": "901620",
    "end": "903839"
  },
  {
    "text": "reuse the same graph but feeding in",
    "start": "903839",
    "end": "907139"
  },
  {
    "text": "different input data and fading in",
    "start": "907139",
    "end": "909240"
  },
  {
    "text": "different configurations so it's the",
    "start": "909240",
    "end": "911399"
  },
  {
    "text": "same template for different workflows",
    "start": "911399",
    "end": "914220"
  },
  {
    "text": "so another thing we'll be using uh quite",
    "start": "914220",
    "end": "918000"
  },
  {
    "text": "a bit is really really workflows",
    "start": "918000",
    "end": "920820"
  },
  {
    "text": "checkpointing uh",
    "start": "920820",
    "end": "922740"
  },
  {
    "text": "uh capability so uh as I mentioned",
    "start": "922740",
    "end": "927120"
  },
  {
    "text": "earlier for large volume of import",
    "start": "927120",
    "end": "930320"
  },
  {
    "text": "pipeline it could contain dozens of",
    "start": "930320",
    "end": "933540"
  },
  {
    "text": "steps so we want our system to be able",
    "start": "933540",
    "end": "936660"
  },
  {
    "text": "to say hey my system could go down my",
    "start": "936660",
    "end": "939779"
  },
  {
    "text": "pod could die my node could fail even my",
    "start": "939779",
    "end": "942600"
  },
  {
    "text": "classical you know for whatever reason",
    "start": "942600",
    "end": "945360"
  },
  {
    "text": "my cluster can be done but I want to be",
    "start": "945360",
    "end": "948779"
  },
  {
    "text": "able to do this so once my pod is back",
    "start": "948779",
    "end": "951779"
  },
  {
    "text": "once my notice back once my cluster is",
    "start": "951779",
    "end": "954300"
  },
  {
    "text": "back I want to be able to recover from",
    "start": "954300",
    "end": "956579"
  },
  {
    "text": "exactly where I left so from the exact",
    "start": "956579",
    "end": "959519"
  },
  {
    "text": "mini mini step rather than you know from",
    "start": "959519",
    "end": "962579"
  },
  {
    "text": "the outer step or even start the whole",
    "start": "962579",
    "end": "966660"
  },
  {
    "text": "bet from scratch so that is where we",
    "start": "966660",
    "end": "969240"
  },
  {
    "text": "leverage reworkflows checkpointing and",
    "start": "969240",
    "end": "971760"
  },
  {
    "text": "we use IBM cost which is essentially our",
    "start": "971760",
    "end": "974760"
  },
  {
    "text": "version of S3 to really checkpoint all",
    "start": "974760",
    "end": "978240"
  },
  {
    "text": "those results so whatever the system so",
    "start": "978240",
    "end": "981600"
  },
  {
    "text": "whichever level of the system field it",
    "start": "981600",
    "end": "984540"
  },
  {
    "text": "can always pick up from exactly where it",
    "start": "984540",
    "end": "987060"
  },
  {
    "text": "left",
    "start": "987060",
    "end": "988019"
  },
  {
    "text": "and in terms of long running we leverage",
    "start": "988019",
    "end": "991440"
  },
  {
    "text": "the stuff like the collaboration of real",
    "start": "991440",
    "end": "995639"
  },
  {
    "text": "workflows on fault tolerance and our",
    "start": "995639",
    "end": "998339"
  },
  {
    "text": "clusters for tolerance so this is done",
    "start": "998339",
    "end": "1000920"
  },
  {
    "text": "by lab by installing a re-operator in",
    "start": "1000920",
    "end": "1004100"
  },
  {
    "text": "our cluster because openshift cluster is",
    "start": "1004100",
    "end": "1006519"
  },
  {
    "text": "essentially also a kubernetes cluster so",
    "start": "1006519",
    "end": "1010699"
  },
  {
    "text": "by doing these two together we are able",
    "start": "1010699",
    "end": "1013940"
  },
  {
    "text": "to achieve fault Tolerance on all",
    "start": "1013940",
    "end": "1016100"
  },
  {
    "text": "various of levels of failures",
    "start": "1016100",
    "end": "1020120"
  },
  {
    "text": "uh resource allocation I think I don't",
    "start": "1020120",
    "end": "1022279"
  },
  {
    "text": "need to talk too much because record",
    "start": "1022279",
    "end": "1025100"
  },
  {
    "text": "retask also has this per task resource",
    "start": "1025100",
    "end": "1028040"
  },
  {
    "text": "education I'm sure you know uh this uh",
    "start": "1028040",
    "end": "1030798"
  },
  {
    "text": "we are all very familiar with that so",
    "start": "1030799",
    "end": "1033020"
  },
  {
    "text": "and since reworkflow is powered by",
    "start": "1033020",
    "end": "1035298"
  },
  {
    "text": "retards so naturally reworkflow with",
    "start": "1035299",
    "end": "1038000"
  },
  {
    "text": "with reworkflow we can also do very",
    "start": "1038000",
    "end": "1040699"
  },
  {
    "text": "precise per task resource allocation",
    "start": "1040699",
    "end": "1044918"
  },
  {
    "text": "okay",
    "start": "1045319",
    "end": "1046640"
  },
  {
    "text": "so uh we are actually also very proud to",
    "start": "1046640",
    "end": "1050360"
  },
  {
    "text": "say that we've been collaborating very",
    "start": "1050360",
    "end": "1053299"
  },
  {
    "text": "well with re team and in this case",
    "start": "1053299",
    "end": "1055400"
  },
  {
    "text": "specifically real workflow team so we've",
    "start": "1055400",
    "end": "1058460"
  },
  {
    "text": "been uh in the past we've been keep",
    "start": "1058460",
    "end": "1059960"
  },
  {
    "text": "exchanging valuable feedbacks we've been",
    "start": "1059960",
    "end": "1062299"
  },
  {
    "text": "addressing some of the issues together",
    "start": "1062299",
    "end": "1064940"
  },
  {
    "text": "and here are at least a few of them that",
    "start": "1064940",
    "end": "1068200"
  },
  {
    "text": "retain reworkflow team has been actively",
    "start": "1068200",
    "end": "1071840"
  },
  {
    "text": "helping us to resolve based on our",
    "start": "1071840",
    "end": "1074900"
  },
  {
    "text": "feedbacks so for example for the deck",
    "start": "1074900",
    "end": "1078380"
  },
  {
    "text": "layer re already has a pretty good",
    "start": "1078380",
    "end": "1080960"
  },
  {
    "text": "observability but for the graph layer",
    "start": "1080960",
    "end": "1084020"
  },
  {
    "text": "wouldn't it be even nice nicer to have",
    "start": "1084020",
    "end": "1087620"
  },
  {
    "text": "the observability on a graph layer so",
    "start": "1087620",
    "end": "1090380"
  },
  {
    "text": "you know exactly from your graph you",
    "start": "1090380",
    "end": "1092360"
  },
  {
    "text": "know exactly which step is your",
    "start": "1092360",
    "end": "1094460"
  },
  {
    "text": "bottleneck or which step is consuming",
    "start": "1094460",
    "end": "1096799"
  },
  {
    "text": "more time than the rest and exactly",
    "start": "1096799",
    "end": "1099380"
  },
  {
    "text": "which Step that has failed which will",
    "start": "1099380",
    "end": "1102200"
  },
  {
    "text": "need to be recovered",
    "start": "1102200",
    "end": "1104179"
  },
  {
    "text": "so another thing is selective",
    "start": "1104179",
    "end": "1106280"
  },
  {
    "text": "checkpointing so",
    "start": "1106280",
    "end": "1108020"
  },
  {
    "text": "checkpoint checkpointing is a good thing",
    "start": "1108020",
    "end": "1110240"
  },
  {
    "text": "it's as always it's a good thing but",
    "start": "1110240",
    "end": "1112640"
  },
  {
    "text": "sometimes checkpoint is since you need",
    "start": "1112640",
    "end": "1114380"
  },
  {
    "text": "to checkpoint to your disk or even to a",
    "start": "1114380",
    "end": "1117020"
  },
  {
    "text": "cloud storage that also adds much of the",
    "start": "1117020",
    "end": "1120200"
  },
  {
    "text": "overhead in your computation graph so",
    "start": "1120200",
    "end": "1123020"
  },
  {
    "text": "being able to selective do checkpoint is",
    "start": "1123020",
    "end": "1125539"
  },
  {
    "text": "also very important because for some of",
    "start": "1125539",
    "end": "1127580"
  },
  {
    "text": "the steps it might be easier to just",
    "start": "1127580",
    "end": "1130820"
  },
  {
    "text": "rerun the step rather than you know",
    "start": "1130820",
    "end": "1133100"
  },
  {
    "text": "write this write the step output to your",
    "start": "1133100",
    "end": "1136820"
  },
  {
    "text": "disk and reload from that right so we",
    "start": "1136820",
    "end": "1139820"
  },
  {
    "text": "also want to achieve selective",
    "start": "1139820",
    "end": "1141320"
  },
  {
    "text": "checkpointing this is also a re workflow",
    "start": "1141320",
    "end": "1144860"
  },
  {
    "text": "team has been helping us achieved by uh",
    "start": "1144860",
    "end": "1149059"
  },
  {
    "text": "you know hearing our feedbacks",
    "start": "1149059",
    "end": "1151059"
  },
  {
    "text": "uh yes that's uh pretty much uh you know",
    "start": "1151059",
    "end": "1155140"
  },
  {
    "text": "uh the high level of how we leverage we",
    "start": "1155140",
    "end": "1159440"
  },
  {
    "text": "workflow in our uh Foundation model",
    "start": "1159440",
    "end": "1162020"
  },
  {
    "text": "Pipeline and more specifically is around",
    "start": "1162020",
    "end": "1165080"
  },
  {
    "text": "our pre-training and post training",
    "start": "1165080",
    "end": "1169240"
  },
  {
    "start": "1168000",
    "end": "1304000"
  },
  {
    "text": "actually I only have one slide left so",
    "start": "1169460",
    "end": "1172039"
  },
  {
    "text": "this is currently how it looks like so",
    "start": "1172039",
    "end": "1174559"
  },
  {
    "text": "as I mentioned the model training part",
    "start": "1174559",
    "end": "1177620"
  },
  {
    "text": "we are still leveraging uh the portfolio",
    "start": "1177620",
    "end": "1180799"
  },
  {
    "text": "of torch but for both pre-training and",
    "start": "1180799",
    "end": "1185120"
  },
  {
    "text": "after training we actually have designed",
    "start": "1185120",
    "end": "1187940"
  },
  {
    "text": "very",
    "start": "1187940",
    "end": "1188900"
  },
  {
    "text": "well working real workflows so the",
    "start": "1188900",
    "end": "1191600"
  },
  {
    "text": "reworkflow will take take care",
    "start": "1191600",
    "end": "1193520"
  },
  {
    "text": "everything from model Gathering and",
    "start": "1193520",
    "end": "1195380"
  },
  {
    "text": "collection all the way to right before",
    "start": "1195380",
    "end": "1197720"
  },
  {
    "text": "model training so here as you can see",
    "start": "1197720",
    "end": "1201200"
  },
  {
    "text": "the workflow is actually also interfere",
    "start": "1201200",
    "end": "1203660"
  },
  {
    "text": "a little bit on the training part that",
    "start": "1203660",
    "end": "1205520"
  },
  {
    "text": "is because we also include workflow for",
    "start": "1205520",
    "end": "1209059"
  },
  {
    "text": "the tokenization parts so a small",
    "start": "1209059",
    "end": "1212480"
  },
  {
    "text": "portion of the model training is also",
    "start": "1212480",
    "end": "1214280"
  },
  {
    "text": "wrapped into real workflow for",
    "start": "1214280",
    "end": "1216740"
  },
  {
    "text": "checkpointing and forth tolerance",
    "start": "1216740",
    "end": "1218720"
  },
  {
    "text": "purpose and for model fine tuning we've",
    "start": "1218720",
    "end": "1222320"
  },
  {
    "text": "been also leveraging real workflow to",
    "start": "1222320",
    "end": "1224120"
  },
  {
    "text": "wrap everything together to achieve a",
    "start": "1224120",
    "end": "1226640"
  },
  {
    "text": "fault tolerance pipelining for model",
    "start": "1226640",
    "end": "1229460"
  },
  {
    "text": "fine tuning and at the end we have the",
    "start": "1229460",
    "end": "1232160"
  },
  {
    "text": "model service so this is how our current",
    "start": "1232160",
    "end": "1234200"
  },
  {
    "text": "Foundation model pipeline looks like",
    "start": "1234200",
    "end": "1237679"
  },
  {
    "text": "okay I think we have almost two minutes",
    "start": "1237679",
    "end": "1241280"
  },
  {
    "text": "left",
    "start": "1241280",
    "end": "1242360"
  },
  {
    "text": "it's great",
    "start": "1242360",
    "end": "1244460"
  },
  {
    "text": "hey uh",
    "start": "1244460",
    "end": "1247299"
  },
  {
    "text": "okay I think yeah",
    "start": "1248419",
    "end": "1252500"
  },
  {
    "text": "oh",
    "start": "1252919",
    "end": "1254660"
  },
  {
    "text": "yes",
    "start": "1254660",
    "end": "1257320"
  },
  {
    "text": "yeah so",
    "start": "1261260",
    "end": "1263059"
  },
  {
    "text": "um as you mentioned earlier the",
    "start": "1263059",
    "end": "1265520"
  },
  {
    "text": "foundation models as we call it here are",
    "start": "1265520",
    "end": "1267679"
  },
  {
    "text": "large language models",
    "start": "1267679",
    "end": "1269960"
  },
  {
    "text": "um they are usually pre-trained right so",
    "start": "1269960",
    "end": "1273620"
  },
  {
    "text": "let's say I have a use case I want to",
    "start": "1273620",
    "end": "1276740"
  },
  {
    "text": "fine-tune that model OKAY from what I",
    "start": "1276740",
    "end": "1280580"
  },
  {
    "text": "understand fine tuning is you are taking",
    "start": "1280580",
    "end": "1282440"
  },
  {
    "text": "few layers at the bottom of the",
    "start": "1282440",
    "end": "1285260"
  },
  {
    "text": "uh stack right and uh fine-tuning with",
    "start": "1285260",
    "end": "1288500"
  },
  {
    "text": "new new data set your use case data set",
    "start": "1288500",
    "end": "1292640"
  },
  {
    "text": "so if you can just elaborate a little",
    "start": "1292640",
    "end": "1294260"
  },
  {
    "text": "bit more about uh what's",
    "start": "1294260",
    "end": "1297740"
  },
  {
    "text": "like looking at the array use case how",
    "start": "1297740",
    "end": "1300740"
  },
  {
    "text": "would I go about doing that maybe a use",
    "start": "1300740",
    "end": "1302600"
  },
  {
    "text": "case example sure sure absolutely yeah",
    "start": "1302600",
    "end": "1306140"
  },
  {
    "start": "1304000",
    "end": "1506000"
  },
  {
    "text": "so I think one",
    "start": "1306140",
    "end": "1308360"
  },
  {
    "text": "pay I would say property of fine tuning",
    "start": "1308360",
    "end": "1312559"
  },
  {
    "text": "is uh so again here I'm talking about",
    "start": "1312559",
    "end": "1315380"
  },
  {
    "text": "model evaluation meaning that it's not",
    "start": "1315380",
    "end": "1318140"
  },
  {
    "text": "really refined to uh one specific task",
    "start": "1318140",
    "end": "1320780"
  },
  {
    "text": "so here we are actually fine-tuning",
    "start": "1320780",
    "end": "1323840"
  },
  {
    "text": "hundreds of different tasks because we",
    "start": "1323840",
    "end": "1326059"
  },
  {
    "text": "need",
    "start": "1326059",
    "end": "1326780"
  },
  {
    "text": "our model evaluation performance number",
    "start": "1326780",
    "end": "1329780"
  },
  {
    "text": "on many different tasks right we want to",
    "start": "1329780",
    "end": "1332659"
  },
  {
    "text": "see how it performs on Q a we want to",
    "start": "1332659",
    "end": "1335179"
  },
  {
    "text": "see how it performs on sentiment",
    "start": "1335179",
    "end": "1336799"
  },
  {
    "text": "analysis",
    "start": "1336799",
    "end": "1339399"
  },
  {
    "text": "yes yes yes so in this case what we",
    "start": "1339679",
    "end": "1342620"
  },
  {
    "text": "really do is we just build one single",
    "start": "1342620",
    "end": "1345320"
  },
  {
    "text": "workflow it's one single deck and we",
    "start": "1345320",
    "end": "1349520"
  },
  {
    "text": "believe the input data and import",
    "start": "1349520",
    "end": "1352340"
  },
  {
    "text": "configuration outside our deck so that's",
    "start": "1352340",
    "end": "1355159"
  },
  {
    "text": "what what we do is for all these",
    "start": "1355159",
    "end": "1358220"
  },
  {
    "text": "hundreds of fine tuning we actually use",
    "start": "1358220",
    "end": "1360799"
  },
  {
    "text": "a single workflow but each time we fade",
    "start": "1360799",
    "end": "1363380"
  },
  {
    "text": "in very different data and very",
    "start": "1363380",
    "end": "1365960"
  },
  {
    "text": "different configuration so if we could",
    "start": "1365960",
    "end": "1368840"
  },
  {
    "text": "this is what we mean by using reusable",
    "start": "1368840",
    "end": "1371480"
  },
  {
    "text": "workflow a single",
    "start": "1371480",
    "end": "1373419"
  },
  {
    "text": "DAC layer as a template which can do",
    "start": "1373419",
    "end": "1377059"
  },
  {
    "text": "hundreds of different fine-tuning tasks",
    "start": "1377059",
    "end": "1380000"
  },
  {
    "text": "on different things yeah",
    "start": "1380000",
    "end": "1383080"
  },
  {
    "text": "Yeah you mentioned that some some of the",
    "start": "1390500",
    "end": "1392900"
  },
  {
    "text": "intermediate step uh storage could be",
    "start": "1392900",
    "end": "1395659"
  },
  {
    "text": "big for checkpointing too big through",
    "start": "1395659",
    "end": "1397520"
  },
  {
    "text": "checkpoint yes yes sometimes you are",
    "start": "1397520",
    "end": "1399440"
  },
  {
    "text": "infeasible but more how do you track say",
    "start": "1399440",
    "end": "1402260"
  },
  {
    "text": "a model has this input this input too",
    "start": "1402260",
    "end": "1404419"
  },
  {
    "text": "large to store and then we have a model",
    "start": "1404419",
    "end": "1406580"
  },
  {
    "text": "checkpoint say at the e-park certain",
    "start": "1406580",
    "end": "1408919"
  },
  {
    "text": "Epoch a certain example number but even",
    "start": "1408919",
    "end": "1411620"
  },
  {
    "text": "though you know which input you need for",
    "start": "1411620",
    "end": "1413720"
  },
  {
    "text": "next but since that input is not stored",
    "start": "1413720",
    "end": "1415580"
  },
  {
    "text": "it's generated by previous steps all the",
    "start": "1415580",
    "end": "1417980"
  },
  {
    "text": "way trading if we want to rerun how do",
    "start": "1417980",
    "end": "1420020"
  },
  {
    "text": "you know which original data which is",
    "start": "1420020",
    "end": "1422659"
  },
  {
    "text": "where the Mark is that's a good question",
    "start": "1422659",
    "end": "1424940"
  },
  {
    "text": "so actually for the checkpointing here",
    "start": "1424940",
    "end": "1428659"
  },
  {
    "text": "we only leverage reworkflow for all the",
    "start": "1428659",
    "end": "1432980"
  },
  {
    "text": "track pointing before training so during",
    "start": "1432980",
    "end": "1436280"
  },
  {
    "text": "training the checkpointing stuff is we",
    "start": "1436280",
    "end": "1439159"
  },
  {
    "text": "are still leveraging uh the",
    "start": "1439159",
    "end": "1441200"
  },
  {
    "text": "checkpointing from torch so the",
    "start": "1441200",
    "end": "1444080"
  },
  {
    "text": "checkpointing we are talking about here",
    "start": "1444080",
    "end": "1445700"
  },
  {
    "text": "is only for let's see you have a",
    "start": "1445700",
    "end": "1448820"
  },
  {
    "text": "sentence that has to go to three",
    "start": "1448820",
    "end": "1451520"
  },
  {
    "text": "different stages of cleaning so what if",
    "start": "1451520",
    "end": "1454520"
  },
  {
    "text": "you know after the second stage my",
    "start": "1454520",
    "end": "1457640"
  },
  {
    "text": "cluster is done so I want to be able to",
    "start": "1457640",
    "end": "1460159"
  },
  {
    "text": "do one my cluster come back I want to",
    "start": "1460159",
    "end": "1463280"
  },
  {
    "text": "resume exactly from the finish of step",
    "start": "1463280",
    "end": "1467120"
  },
  {
    "text": "two rather than all the way from Step",
    "start": "1467120",
    "end": "1469820"
  },
  {
    "text": "Zero so that's actually where we",
    "start": "1469820",
    "end": "1472460"
  },
  {
    "text": "leverage workflows checkpointing but",
    "start": "1472460",
    "end": "1475100"
  },
  {
    "text": "once it goes into the actual model",
    "start": "1475100",
    "end": "1477380"
  },
  {
    "text": "training we no longer use that we are",
    "start": "1477380",
    "end": "1480559"
  },
  {
    "text": "actually using apply torch on on a",
    "start": "1480559",
    "end": "1484100"
  },
  {
    "text": "checkpointing so at that stages there's",
    "start": "1484100",
    "end": "1487039"
  },
  {
    "text": "no more uh workflow checkpointing okay",
    "start": "1487039",
    "end": "1490159"
  },
  {
    "text": "thanks",
    "start": "1490159",
    "end": "1492520"
  },
  {
    "text": "I am um I'm interested about the the",
    "start": "1501140",
    "end": "1503539"
  },
  {
    "text": "last slide that you showed if you could",
    "start": "1503539",
    "end": "1505220"
  },
  {
    "text": "get to that",
    "start": "1505220",
    "end": "1507380"
  },
  {
    "start": "1506000",
    "end": "1738000"
  },
  {
    "text": "uh yeah here so",
    "start": "1507380",
    "end": "1509360"
  },
  {
    "text": "um you're showing that you're using the",
    "start": "1509360",
    "end": "1511159"
  },
  {
    "text": "array workflow up until a little bit of",
    "start": "1511159",
    "end": "1513679"
  },
  {
    "text": "model training I'm interested about the",
    "start": "1513679",
    "end": "1515720"
  },
  {
    "text": "model serving side uh could you talk",
    "start": "1515720",
    "end": "1517820"
  },
  {
    "text": "more about what you're doing on model",
    "start": "1517820",
    "end": "1519380"
  },
  {
    "text": "serving and have you considered Ray for",
    "start": "1519380",
    "end": "1521960"
  },
  {
    "text": "for any of that",
    "start": "1521960",
    "end": "1523640"
  },
  {
    "text": "so at this stage we haven't used reserve",
    "start": "1523640",
    "end": "1528559"
  },
  {
    "text": "for model serving yet we've been mostly",
    "start": "1528559",
    "end": "1531440"
  },
  {
    "text": "leveraging our mesh model survey and",
    "start": "1531440",
    "end": "1536179"
  },
  {
    "text": "this part is currently we I believe we",
    "start": "1536179",
    "end": "1540320"
  },
  {
    "text": "only use our first party in-house",
    "start": "1540320",
    "end": "1543340"
  },
  {
    "text": "serving to yet uh yes but basically in",
    "start": "1543340",
    "end": "1546980"
  },
  {
    "text": "short we haven't really used research",
    "start": "1546980",
    "end": "1549440"
  },
  {
    "text": "for model serving yet",
    "start": "1549440",
    "end": "1552340"
  },
  {
    "text": "but in short in this part what we do is",
    "start": "1552679",
    "end": "1555200"
  },
  {
    "text": "essentially we perform some sort of",
    "start": "1555200",
    "end": "1558559"
  },
  {
    "text": "model quantization and if you know the",
    "start": "1558559",
    "end": "1563360"
  },
  {
    "text": "model is too large with Foundation model",
    "start": "1563360",
    "end": "1565460"
  },
  {
    "text": "we will also chart the model properly",
    "start": "1565460",
    "end": "1567559"
  },
  {
    "text": "maybe across different nodes or or",
    "start": "1567559",
    "end": "1570320"
  },
  {
    "text": "across different gpus and we also",
    "start": "1570320",
    "end": "1574520"
  },
  {
    "text": "internally we have uh various of",
    "start": "1574520",
    "end": "1577039"
  },
  {
    "text": "different ways to do",
    "start": "1577039",
    "end": "1578919"
  },
  {
    "text": "mesh model serving yeah",
    "start": "1578919",
    "end": "1583480"
  },
  {
    "text": "describe what mesh model serving is in",
    "start": "1584120",
    "end": "1586820"
  },
  {
    "text": "your",
    "start": "1586820",
    "end": "1588320"
  },
  {
    "text": "yes so uh weeping mostly leveraging uh",
    "start": "1588320",
    "end": "1593600"
  },
  {
    "text": "the thing called a key serve so and",
    "start": "1593600",
    "end": "1596840"
  },
  {
    "text": "internally we've been developed this",
    "start": "1596840",
    "end": "1598940"
  },
  {
    "text": "motor serving is which is uh",
    "start": "1598940",
    "end": "1602960"
  },
  {
    "text": "I don't know too much details on that",
    "start": "1602960",
    "end": "1605659"
  },
  {
    "text": "but it's basically a mesh based model",
    "start": "1605659",
    "end": "1608179"
  },
  {
    "text": "survey but if you are interested in that",
    "start": "1608179",
    "end": "1610700"
  },
  {
    "text": "we actually for that part we actually",
    "start": "1610700",
    "end": "1612740"
  },
  {
    "text": "contribute back to the open source case",
    "start": "1612740",
    "end": "1615740"
  },
  {
    "text": "cell part so under the open source key",
    "start": "1615740",
    "end": "1618500"
  },
  {
    "text": "sub repo there's a subfolder mesh",
    "start": "1618500",
    "end": "1621559"
  },
  {
    "text": "something so that's exactly what we",
    "start": "1621559",
    "end": "1623900"
  },
  {
    "text": "developed and contributed back to the",
    "start": "1623900",
    "end": "1626059"
  },
  {
    "text": "community",
    "start": "1626059",
    "end": "1628299"
  },
  {
    "text": "project that was that was generally",
    "start": "1629480",
    "end": "1631340"
  },
  {
    "text": "currently used in production in IBM",
    "start": "1631340",
    "end": "1634700"
  },
  {
    "text": "which we have contributed",
    "start": "1634700",
    "end": "1638019"
  },
  {
    "text": "thank you",
    "start": "1641679",
    "end": "1644799"
  },
  {
    "text": "think of it as you're you're serving uh",
    "start": "1648320",
    "end": "1651140"
  },
  {
    "text": "request is going into a mesh so it's not",
    "start": "1651140",
    "end": "1654679"
  },
  {
    "text": "just like a single endpoint it goes",
    "start": "1654679",
    "end": "1657260"
  },
  {
    "text": "throughout gets routed across into",
    "start": "1657260",
    "end": "1658640"
  },
  {
    "text": "multiple of them and depending on which",
    "start": "1658640",
    "end": "1661159"
  },
  {
    "text": "one is free it will get readouted and",
    "start": "1661159",
    "end": "1663380"
  },
  {
    "text": "because ultimately it's all meant to be",
    "start": "1663380",
    "end": "1666140"
  },
  {
    "text": "providing SLA guarantees in terms of",
    "start": "1666140",
    "end": "1669400"
  },
  {
    "text": "latencies because all our like for",
    "start": "1669400",
    "end": "1672559"
  },
  {
    "text": "example our assistant service uses",
    "start": "1672559",
    "end": "1675620"
  },
  {
    "text": "modern mesh in the background and we",
    "start": "1675620",
    "end": "1677299"
  },
  {
    "text": "have to provide I don't know like tens",
    "start": "1677299",
    "end": "1679279"
  },
  {
    "text": "of milliseconds uh latencies slas for",
    "start": "1679279",
    "end": "1683059"
  },
  {
    "text": "whenever somebody types something in the",
    "start": "1683059",
    "end": "1684799"
  },
  {
    "text": "chat response has to come back within a",
    "start": "1684799",
    "end": "1686960"
  },
  {
    "text": "few tens of milliseconds and the model",
    "start": "1686960",
    "end": "1689900"
  },
  {
    "text": "mesh because of its nature of spreading",
    "start": "1689900",
    "end": "1693200"
  },
  {
    "text": "the load across knowing where to Route",
    "start": "1693200",
    "end": "1695059"
  },
  {
    "text": "the request depending on which ones are",
    "start": "1695059",
    "end": "1696919"
  },
  {
    "text": "readily available and whatnot all of",
    "start": "1696919",
    "end": "1699200"
  },
  {
    "text": "those it takes into account and it's not",
    "start": "1699200",
    "end": "1700940"
  },
  {
    "text": "a single endpoint or you're not doing a",
    "start": "1700940",
    "end": "1702679"
  },
  {
    "text": "load simple load balancing it's like a",
    "start": "1702679",
    "end": "1704779"
  },
  {
    "text": "mesh kind of a load balancing that",
    "start": "1704779",
    "end": "1706159"
  },
  {
    "text": "allows you to Route the request to the",
    "start": "1706159",
    "end": "1708080"
  },
  {
    "text": "right place which is available can",
    "start": "1708080",
    "end": "1710120"
  },
  {
    "text": "address the latency request",
    "start": "1710120",
    "end": "1713380"
  },
  {
    "text": "okay if not uh thanks",
    "start": "1721520",
    "end": "1724299"
  },
  {
    "text": "no oh we are also on top of the time now",
    "start": "1724299",
    "end": "1726860"
  },
  {
    "text": "perfect uh great uh thanks for the great",
    "start": "1726860",
    "end": "1730279"
  },
  {
    "text": "talk thank you",
    "start": "1730279",
    "end": "1731620"
  },
  {
    "text": "[Applause]",
    "start": "1731620",
    "end": "1735290"
  }
]
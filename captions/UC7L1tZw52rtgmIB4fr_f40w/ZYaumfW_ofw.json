[
  {
    "text": "[Music]",
    "start": "200",
    "end": "14559"
  },
  {
    "text": "hi",
    "start": "14559",
    "end": "14880"
  },
  {
    "text": "my name is edward oaks i'm a software",
    "start": "14880",
    "end": "16640"
  },
  {
    "text": "engineer at any scale and today i'll be",
    "start": "16640",
    "end": "18400"
  },
  {
    "text": "demoing how any scale empowers engineers",
    "start": "18400",
    "end": "20720"
  },
  {
    "text": "to build and deploy",
    "start": "20720",
    "end": "21840"
  },
  {
    "text": "machine learning applications to",
    "start": "21840",
    "end": "23199"
  },
  {
    "text": "production",
    "start": "23199",
    "end": "25199"
  },
  {
    "text": "so as robert discussed in his keynote",
    "start": "25199",
    "end": "27119"
  },
  {
    "text": "over the last year we've seen people",
    "start": "27119",
    "end": "28800"
  },
  {
    "text": "using raid to build large-scale",
    "start": "28800",
    "end": "30400"
  },
  {
    "text": "production-ready applications across the",
    "start": "30400",
    "end": "32480"
  },
  {
    "text": "machine learning life cycle",
    "start": "32480",
    "end": "34480"
  },
  {
    "text": "our mission at any scale is to enable",
    "start": "34480",
    "end": "36239"
  },
  {
    "text": "teams of all sizes to harness the power",
    "start": "36239",
    "end": "38239"
  },
  {
    "text": "of ray",
    "start": "38239",
    "end": "39360"
  },
  {
    "text": "a few examples of this being presented",
    "start": "39360",
    "end": "41120"
  },
  {
    "text": "at the summit include dangerous systems",
    "start": "41120",
    "end": "43200"
  },
  {
    "text": "who are running an automated inference",
    "start": "43200",
    "end": "44879"
  },
  {
    "text": "pipeline over terabytes of drone footage",
    "start": "44879",
    "end": "47520"
  },
  {
    "text": "anastasia ai who are scaling up and",
    "start": "47520",
    "end": "49680"
  },
  {
    "text": "automating their ml pipelines that allow",
    "start": "49680",
    "end": "51760"
  },
  {
    "text": "to deliver more value to their customers",
    "start": "51760",
    "end": "53680"
  },
  {
    "text": "faster",
    "start": "53680",
    "end": "54879"
  },
  {
    "text": "and wildlife studios who are working",
    "start": "54879",
    "end": "56559"
  },
  {
    "text": "with any scale to develop and deploy",
    "start": "56559",
    "end": "58559"
  },
  {
    "text": "rl at scale",
    "start": "58559",
    "end": "61519"
  },
  {
    "text": "any scale empowers these teams by",
    "start": "62000",
    "end": "63840"
  },
  {
    "text": "offering a seamless development",
    "start": "63840",
    "end": "65280"
  },
  {
    "text": "experience",
    "start": "65280",
    "end": "66159"
  },
  {
    "text": "and automated tooling and infrastructure",
    "start": "66159",
    "end": "68080"
  },
  {
    "text": "to reliably bring their ray applications",
    "start": "68080",
    "end": "69920"
  },
  {
    "text": "to production",
    "start": "69920",
    "end": "71040"
  },
  {
    "text": "this enables modest size teams to put",
    "start": "71040",
    "end": "73200"
  },
  {
    "text": "machine learning in production end to",
    "start": "73200",
    "end": "74799"
  },
  {
    "text": "end",
    "start": "74799",
    "end": "77119"
  },
  {
    "text": "in development any scale offers the",
    "start": "77439",
    "end": "79200"
  },
  {
    "text": "infinite laptop experience",
    "start": "79200",
    "end": "81520"
  },
  {
    "text": "the ray client is the cornerstone",
    "start": "81520",
    "end": "83280"
  },
  {
    "text": "allowing you to run ray programs on a",
    "start": "83280",
    "end": "85040"
  },
  {
    "text": "remote cluster directly from your laptop",
    "start": "85040",
    "end": "87840"
  },
  {
    "text": "any skill also enables you to",
    "start": "87840",
    "end": "89680"
  },
  {
    "text": "automatically sync local files",
    "start": "89680",
    "end": "91600"
  },
  {
    "text": "and dependencies to the cluster so you",
    "start": "91600",
    "end": "93520"
  },
  {
    "text": "can modify and update them without",
    "start": "93520",
    "end": "95200"
  },
  {
    "text": "needing to build and push a docker image",
    "start": "95200",
    "end": "98400"
  },
  {
    "text": "and finally as many of us know much of",
    "start": "98400",
    "end": "100880"
  },
  {
    "text": "our time in development is really spent",
    "start": "100880",
    "end": "102560"
  },
  {
    "text": "debugging",
    "start": "102560",
    "end": "103360"
  },
  {
    "text": "and this is notoriously hard in",
    "start": "103360",
    "end": "104960"
  },
  {
    "text": "distributed environments",
    "start": "104960",
    "end": "106799"
  },
  {
    "text": "any skill offers a remote debugger that",
    "start": "106799",
    "end": "108960"
  },
  {
    "text": "lets you attach",
    "start": "108960",
    "end": "110000"
  },
  {
    "text": "breakpoints uh lets you attach to",
    "start": "110000",
    "end": "112240"
  },
  {
    "text": "breakpoints running anywhere in the",
    "start": "112240",
    "end": "113680"
  },
  {
    "text": "cluster",
    "start": "113680",
    "end": "115280"
  },
  {
    "text": "these features allow developers to",
    "start": "115280",
    "end": "116799"
  },
  {
    "text": "iterate quickly in development",
    "start": "116799",
    "end": "118479"
  },
  {
    "text": "even when running on a cluster",
    "start": "118479",
    "end": "121759"
  },
  {
    "text": "along with making it easy to go from",
    "start": "121759",
    "end": "123280"
  },
  {
    "text": "your laptop to a cluster we're also",
    "start": "123280",
    "end": "125200"
  },
  {
    "text": "striving to make the transition from",
    "start": "125200",
    "end": "126719"
  },
  {
    "text": "development to reliable production-ready",
    "start": "126719",
    "end": "128879"
  },
  {
    "text": "applications",
    "start": "128879",
    "end": "129599"
  },
  {
    "text": "as seamless as possible any scales",
    "start": "129599",
    "end": "132160"
  },
  {
    "text": "python api and sdk",
    "start": "132160",
    "end": "134000"
  },
  {
    "text": "make it possible to integrate with your",
    "start": "134000",
    "end": "135680"
  },
  {
    "text": "existing tooling like airflow or ci",
    "start": "135680",
    "end": "137840"
  },
  {
    "text": "systems",
    "start": "137840",
    "end": "139120"
  },
  {
    "text": "an automated build farm makes building",
    "start": "139120",
    "end": "141200"
  },
  {
    "text": "reproducible environments as easy as an",
    "start": "141200",
    "end": "143280"
  },
  {
    "text": "api call",
    "start": "143280",
    "end": "144720"
  },
  {
    "text": "and industry standard monitoring",
    "start": "144720",
    "end": "146319"
  },
  {
    "text": "infrastructure comes out of the box",
    "start": "146319",
    "end": "150080"
  },
  {
    "text": "in this demo i'll be giving you a first",
    "start": "150800",
    "end": "152480"
  },
  {
    "text": "hand look at these development and",
    "start": "152480",
    "end": "153920"
  },
  {
    "text": "production workflows",
    "start": "153920",
    "end": "155280"
  },
  {
    "text": "by building an end-to-end machine",
    "start": "155280",
    "end": "156800"
  },
  {
    "text": "learning application an ml-powered",
    "start": "156800",
    "end": "159120"
  },
  {
    "text": "support bot for ray",
    "start": "159120",
    "end": "160879"
  },
  {
    "text": "this will be similar to other support",
    "start": "160879",
    "end": "162560"
  },
  {
    "text": "bots that are redefining customer",
    "start": "162560",
    "end": "164239"
  },
  {
    "text": "engagement across multiple industries",
    "start": "164239",
    "end": "166800"
  },
  {
    "text": "users will be able to ask the bot",
    "start": "166800",
    "end": "168400"
  },
  {
    "text": "questions about rey and it will respond",
    "start": "168400",
    "end": "170480"
  },
  {
    "text": "with answers and pointers to the most",
    "start": "170480",
    "end": "172080"
  },
  {
    "text": "relevant materials for them",
    "start": "172080",
    "end": "175360"
  },
  {
    "text": "support bots enable businesses to",
    "start": "175440",
    "end": "177120"
  },
  {
    "text": "resolve the majority of customer support",
    "start": "177120",
    "end": "179040"
  },
  {
    "text": "cases without ever needing a human in",
    "start": "179040",
    "end": "180720"
  },
  {
    "text": "the loop",
    "start": "180720",
    "end": "181760"
  },
  {
    "text": "however however building a support a",
    "start": "181760",
    "end": "184319"
  },
  {
    "text": "good support bot is not easy",
    "start": "184319",
    "end": "186159"
  },
  {
    "text": "it requires combining a number of",
    "start": "186159",
    "end": "187840"
  },
  {
    "text": "machine learning techniques such as text",
    "start": "187840",
    "end": "189519"
  },
  {
    "text": "classification and content",
    "start": "189519",
    "end": "190720"
  },
  {
    "text": "recommendation",
    "start": "190720",
    "end": "191760"
  },
  {
    "text": "with business logic to stitch it",
    "start": "191760",
    "end": "193360"
  },
  {
    "text": "together in a way that provides a great",
    "start": "193360",
    "end": "195120"
  },
  {
    "text": "user experience",
    "start": "195120",
    "end": "197519"
  },
  {
    "text": "we need to make sure our ml design",
    "start": "197519",
    "end": "199440"
  },
  {
    "text": "returns useful results",
    "start": "199440",
    "end": "201280"
  },
  {
    "text": "low latency is critical to the user",
    "start": "201280",
    "end": "203040"
  },
  {
    "text": "experience and the system must be able",
    "start": "203040",
    "end": "204959"
  },
  {
    "text": "to scale",
    "start": "204959",
    "end": "206159"
  },
  {
    "text": "to handle thousands of concurrent users",
    "start": "206159",
    "end": "209440"
  },
  {
    "text": "this is a problem entire companies are",
    "start": "209440",
    "end": "211120"
  },
  {
    "text": "built around and it may take",
    "start": "211120",
    "end": "212640"
  },
  {
    "text": "a team of engineers months to build this",
    "start": "212640",
    "end": "214480"
  },
  {
    "text": "complex machine learning application",
    "start": "214480",
    "end": "217040"
  },
  {
    "text": "today i'm going to show you how ray and",
    "start": "217040",
    "end": "219120"
  },
  {
    "text": "any skill can drastically improve this",
    "start": "219120",
    "end": "220879"
  },
  {
    "text": "process",
    "start": "220879",
    "end": "221680"
  },
  {
    "text": "by building and deploying a support bot",
    "start": "221680",
    "end": "223440"
  },
  {
    "text": "to production in just 20 minutes",
    "start": "223440",
    "end": "227280"
  },
  {
    "text": "in this demo we'll build a basic version",
    "start": "227280",
    "end": "229040"
  },
  {
    "text": "of a support bot using standard nlp",
    "start": "229040",
    "end": "231200"
  },
  {
    "text": "techniques",
    "start": "231200",
    "end": "232319"
  },
  {
    "text": "when a user query comes in we'll first",
    "start": "232319",
    "end": "234400"
  },
  {
    "text": "do some basic pre-processing and",
    "start": "234400",
    "end": "236159"
  },
  {
    "text": "featurization on the text",
    "start": "236159",
    "end": "238560"
  },
  {
    "text": "then we'll forward this input to two",
    "start": "238560",
    "end": "240319"
  },
  {
    "text": "separate machine learning models",
    "start": "240319",
    "end": "242239"
  },
  {
    "text": "the first will be used to classify the",
    "start": "242239",
    "end": "243920"
  },
  {
    "text": "intent of the user such as asking a",
    "start": "243920",
    "end": "245599"
  },
  {
    "text": "question reporting a bug",
    "start": "245599",
    "end": "247040"
  },
  {
    "text": "or just saying hello and the second",
    "start": "247040",
    "end": "249760"
  },
  {
    "text": "model will use an ml-powered relevant",
    "start": "249760",
    "end": "251760"
  },
  {
    "text": "search to retrieve relevant links from",
    "start": "251760",
    "end": "253599"
  },
  {
    "text": "the ray documentation",
    "start": "253599",
    "end": "255439"
  },
  {
    "text": "github page and forum posts",
    "start": "255439",
    "end": "258560"
  },
  {
    "text": "finally we'll combine the results of our",
    "start": "258560",
    "end": "260239"
  },
  {
    "text": "two models using custom business logic",
    "start": "260239",
    "end": "262320"
  },
  {
    "text": "and return the response to the user",
    "start": "262320",
    "end": "265840"
  },
  {
    "text": "so this design may seem simple at first",
    "start": "265919",
    "end": "267919"
  },
  {
    "text": "glance but as jan discussed in his",
    "start": "267919",
    "end": "269840"
  },
  {
    "text": "keynote",
    "start": "269840",
    "end": "270560"
  },
  {
    "text": "training building deploying and",
    "start": "270560",
    "end": "272479"
  },
  {
    "text": "operating the bot is something that",
    "start": "272479",
    "end": "274080"
  },
  {
    "text": "today would require stitching together a",
    "start": "274080",
    "end": "275919"
  },
  {
    "text": "number of different systems",
    "start": "275919",
    "end": "277600"
  },
  {
    "text": "all of which have different apis and",
    "start": "277600",
    "end": "279360"
  },
  {
    "text": "require different expertise",
    "start": "279360",
    "end": "281040"
  },
  {
    "text": "from ml scientists to devops engineers",
    "start": "281040",
    "end": "285360"
  },
  {
    "text": "in this demo i'll show you how ray can",
    "start": "285360",
    "end": "287440"
  },
  {
    "text": "be used as the universal compute layer",
    "start": "287440",
    "end": "289360"
  },
  {
    "text": "for our application",
    "start": "289360",
    "end": "290560"
  },
  {
    "text": "and how any scale makes developing and",
    "start": "290560",
    "end": "292320"
  },
  {
    "text": "deploying ray applications simple",
    "start": "292320",
    "end": "294639"
  },
  {
    "text": "this improves both efficiency because we",
    "start": "294639",
    "end": "296639"
  },
  {
    "text": "can leverage features like the ray",
    "start": "296639",
    "end": "298160"
  },
  {
    "text": "object store",
    "start": "298160",
    "end": "299199"
  },
  {
    "text": "and productivity because it enables ml",
    "start": "299199",
    "end": "301280"
  },
  {
    "text": "scientists and engineers to open",
    "start": "301280",
    "end": "303199"
  },
  {
    "text": "to own more of the application life",
    "start": "303199",
    "end": "304960"
  },
  {
    "text": "cycle",
    "start": "304960",
    "end": "307280"
  },
  {
    "text": "my first task in this demo will be to",
    "start": "307680",
    "end": "309600"
  },
  {
    "text": "train one of the models",
    "start": "309600",
    "end": "310800"
  },
  {
    "text": "the intent classifier by running and",
    "start": "310800",
    "end": "313039"
  },
  {
    "text": "debugging a scalable training pipeline",
    "start": "313039",
    "end": "315840"
  },
  {
    "text": "here you'll get to see the infinite",
    "start": "315840",
    "end": "317199"
  },
  {
    "text": "laptop experience firsthand",
    "start": "317199",
    "end": "319280"
  },
  {
    "text": "i'll run code on the cloud directly from",
    "start": "319280",
    "end": "321039"
  },
  {
    "text": "my laptop using the ray client",
    "start": "321039",
    "end": "323199"
  },
  {
    "text": "be able to rapidly iterate using any",
    "start": "323199",
    "end": "325039"
  },
  {
    "text": "skills dependency syncing",
    "start": "325039",
    "end": "326880"
  },
  {
    "text": "and debug my program running on a",
    "start": "326880",
    "end": "328560"
  },
  {
    "text": "cluster using the remote debugger",
    "start": "328560",
    "end": "332160"
  },
  {
    "text": "after training the model i'll build a",
    "start": "332240",
    "end": "333759"
  },
  {
    "text": "production ready inference api for the",
    "start": "333759",
    "end": "335520"
  },
  {
    "text": "support bot",
    "start": "335520",
    "end": "336880"
  },
  {
    "text": "we'll be able to develop and test the",
    "start": "336880",
    "end": "338720"
  },
  {
    "text": "end-to-end service locally",
    "start": "338720",
    "end": "340320"
  },
  {
    "text": "and then deploy to production on any",
    "start": "340320",
    "end": "341759"
  },
  {
    "text": "scale without any code changes",
    "start": "341759",
    "end": "344479"
  },
  {
    "text": "i'll then set up an automated workflow",
    "start": "344479",
    "end": "346320"
  },
  {
    "text": "to deploy the application with zero",
    "start": "346320",
    "end": "348000"
  },
  {
    "text": "downtime",
    "start": "348000",
    "end": "349120"
  },
  {
    "text": "so let's get started with the first step",
    "start": "349120",
    "end": "350800"
  },
  {
    "text": "training our classification model",
    "start": "350800",
    "end": "354160"
  },
  {
    "text": "we'll start by developing a scalable",
    "start": "354160",
    "end": "355840"
  },
  {
    "text": "training pipeline",
    "start": "355840",
    "end": "357199"
  },
  {
    "text": "this will load labeled training data",
    "start": "357199",
    "end": "359440"
  },
  {
    "text": "pre-process it using das conray",
    "start": "359440",
    "end": "361600"
  },
  {
    "text": "then use ray tune and xg boost on ray to",
    "start": "361600",
    "end": "363919"
  },
  {
    "text": "train the classifier",
    "start": "363919",
    "end": "365600"
  },
  {
    "text": "we'll first test out the pipeline",
    "start": "365600",
    "end": "367199"
  },
  {
    "text": "locally to make sure it's working",
    "start": "367199",
    "end": "370319"
  },
  {
    "text": "once we have it working we'll scale up",
    "start": "370319",
    "end": "371919"
  },
  {
    "text": "our pipeline to run on a cluster of",
    "start": "371919",
    "end": "373520"
  },
  {
    "text": "machines on any scale",
    "start": "373520",
    "end": "375680"
  },
  {
    "text": "this is as simple as setting an",
    "start": "375680",
    "end": "376960"
  },
  {
    "text": "environment variable and running on the",
    "start": "376960",
    "end": "378800"
  },
  {
    "text": "cluster will enable us to",
    "start": "378800",
    "end": "380000"
  },
  {
    "text": "train the model thousands of times with",
    "start": "380000",
    "end": "381840"
  },
  {
    "text": "different hyper parameters",
    "start": "381840",
    "end": "383039"
  },
  {
    "text": "in parallel to train the best model in a",
    "start": "383039",
    "end": "385360"
  },
  {
    "text": "fraction of the time that it would take",
    "start": "385360",
    "end": "386720"
  },
  {
    "text": "to run locally",
    "start": "386720",
    "end": "388319"
  },
  {
    "text": "so let's dive in",
    "start": "388319",
    "end": "391199"
  },
  {
    "text": "so here i have opened a terminal on my",
    "start": "392560",
    "end": "394240"
  },
  {
    "text": "laptop where i'll be developing and",
    "start": "394240",
    "end": "395759"
  },
  {
    "text": "running the training pipeline",
    "start": "395759",
    "end": "397840"
  },
  {
    "text": "let's take a look at the code for the",
    "start": "397840",
    "end": "399120"
  },
  {
    "text": "pipeline which is in this train.pi",
    "start": "399120",
    "end": "400800"
  },
  {
    "text": "script",
    "start": "400800",
    "end": "403198"
  },
  {
    "text": "in the main function we can see the core",
    "start": "403280",
    "end": "405039"
  },
  {
    "text": "logic defining our pipeline",
    "start": "405039",
    "end": "406960"
  },
  {
    "text": "the first thing that we do is connect to",
    "start": "406960",
    "end": "408560"
  },
  {
    "text": "ray using this ray.client.connect call",
    "start": "408560",
    "end": "411599"
  },
  {
    "text": "because we aren't passing any address by",
    "start": "411599",
    "end": "413599"
  },
  {
    "text": "default this is just going to start ray",
    "start": "413599",
    "end": "415280"
  },
  {
    "text": "on my laptop",
    "start": "415280",
    "end": "416160"
  },
  {
    "text": "and run the program there the next thing",
    "start": "416160",
    "end": "418960"
  },
  {
    "text": "that we do",
    "start": "418960",
    "end": "419599"
  },
  {
    "text": "is load the data and pre-process it",
    "start": "419599",
    "end": "423039"
  },
  {
    "text": "here we're calling this load and",
    "start": "423039",
    "end": "424400"
  },
  {
    "text": "pre-process remote function which is",
    "start": "424400",
    "end": "426160"
  },
  {
    "text": "going to use das conrad to do some basic",
    "start": "426160",
    "end": "428479"
  },
  {
    "text": "pre-processing",
    "start": "428479",
    "end": "429440"
  },
  {
    "text": "and feature engineering and then it's",
    "start": "429440",
    "end": "431360"
  },
  {
    "text": "going to put the result in",
    "start": "431360",
    "end": "432639"
  },
  {
    "text": "the ray shared memory object store so",
    "start": "432639",
    "end": "434560"
  },
  {
    "text": "that we can efficiently access it during",
    "start": "434560",
    "end": "436319"
  },
  {
    "text": "training",
    "start": "436319",
    "end": "438319"
  },
  {
    "text": "finally we call this tune model function",
    "start": "438319",
    "end": "440720"
  },
  {
    "text": "uh which",
    "start": "440720",
    "end": "441520"
  },
  {
    "text": "is going to run a number of hyper",
    "start": "441520",
    "end": "443280"
  },
  {
    "text": "parameter tuning trials in",
    "start": "443280",
    "end": "444800"
  },
  {
    "text": "in parallel and use xg boost on ray",
    "start": "444800",
    "end": "448319"
  },
  {
    "text": "to try to train the best intent",
    "start": "448319",
    "end": "450000"
  },
  {
    "text": "classifier that we can",
    "start": "450000",
    "end": "452160"
  },
  {
    "text": "when i'm running locally i'm just going",
    "start": "452160",
    "end": "453680"
  },
  {
    "text": "to set num trials to 1 so that we can",
    "start": "453680",
    "end": "455840"
  },
  {
    "text": "test it out but of course we want to",
    "start": "455840",
    "end": "457840"
  },
  {
    "text": "scale this up and run many trials that",
    "start": "457840",
    "end": "459680"
  },
  {
    "text": "we can find the best possible model when",
    "start": "459680",
    "end": "461440"
  },
  {
    "text": "we're running on any scale",
    "start": "461440",
    "end": "463520"
  },
  {
    "text": "so let's go ahead and run this locally",
    "start": "463520",
    "end": "465199"
  },
  {
    "text": "to verify that it's working",
    "start": "465199",
    "end": "468240"
  },
  {
    "text": "remember that because i didn't pass in",
    "start": "468240",
    "end": "469759"
  },
  {
    "text": "any address this is going to start ray",
    "start": "469759",
    "end": "471520"
  },
  {
    "text": "locally on my laptop we see a log",
    "start": "471520",
    "end": "473840"
  },
  {
    "text": "messages a log message from ray",
    "start": "473840",
    "end": "475680"
  },
  {
    "text": "indicating that and now the",
    "start": "475680",
    "end": "478319"
  },
  {
    "text": "pre-processing should be running using",
    "start": "478319",
    "end": "480080"
  },
  {
    "text": "das",
    "start": "480080",
    "end": "480400"
  },
  {
    "text": "on ray",
    "start": "480400",
    "end": "482800"
  },
  {
    "text": "so we can see a summary of the output",
    "start": "484479",
    "end": "486560"
  },
  {
    "text": "from das on ray here",
    "start": "486560",
    "end": "488639"
  },
  {
    "text": "and it looks like our trial has started",
    "start": "488639",
    "end": "490319"
  },
  {
    "text": "up we're getting some log",
    "start": "490319",
    "end": "492000"
  },
  {
    "text": "messages from xg boost on ray",
    "start": "492000",
    "end": "495280"
  },
  {
    "text": "and just like that it looks like we were",
    "start": "495280",
    "end": "496960"
  },
  {
    "text": "able to finish that one",
    "start": "496960",
    "end": "498639"
  },
  {
    "text": "test trial and train a model locally we",
    "start": "498639",
    "end": "501280"
  },
  {
    "text": "should be able to improve this accuracy",
    "start": "501280",
    "end": "503039"
  },
  {
    "text": "when we scale up and",
    "start": "503039",
    "end": "504400"
  },
  {
    "text": "and train many more models in parallel",
    "start": "504400",
    "end": "507759"
  },
  {
    "text": "so let's go ahead and run this on any",
    "start": "507759",
    "end": "510000"
  },
  {
    "text": "scale so that we can scale it up",
    "start": "510000",
    "end": "513440"
  },
  {
    "text": "so note that inside of my train dot",
    "start": "514080",
    "end": "515919"
  },
  {
    "text": "pyscript i'm using a number of",
    "start": "515919",
    "end": "517360"
  },
  {
    "text": "third-party dependencies such as",
    "start": "517360",
    "end": "519039"
  },
  {
    "text": "text hero and desk as well as this local",
    "start": "519039",
    "end": "522719"
  },
  {
    "text": "module that i have defined",
    "start": "522719",
    "end": "525279"
  },
  {
    "text": "which contains a lot of the core logic",
    "start": "525279",
    "end": "527920"
  },
  {
    "text": "so when running on a cluster we need to",
    "start": "527920",
    "end": "529440"
  },
  {
    "text": "make sure that both of these are present",
    "start": "529440",
    "end": "531440"
  },
  {
    "text": "thankfully any scale makes this really",
    "start": "531440",
    "end": "533200"
  },
  {
    "text": "easy",
    "start": "533200",
    "end": "535200"
  },
  {
    "text": "all i need to do to include the third",
    "start": "535200",
    "end": "536880"
  },
  {
    "text": "party dependencies is",
    "start": "536880",
    "end": "539680"
  },
  {
    "text": "provide this requirements.txt file which",
    "start": "539680",
    "end": "542480"
  },
  {
    "text": "has all of my",
    "start": "542480",
    "end": "543600"
  },
  {
    "text": "pip dependencies listed so here i'm just",
    "start": "543600",
    "end": "546160"
  },
  {
    "text": "going to modify",
    "start": "546160",
    "end": "547120"
  },
  {
    "text": "my connect call to say that the pip",
    "start": "547120",
    "end": "549760"
  },
  {
    "text": "dependencies are in this local file",
    "start": "549760",
    "end": "551880"
  },
  {
    "text": "requirements.txt",
    "start": "551880",
    "end": "553680"
  },
  {
    "text": "and that should be all that it takes and",
    "start": "553680",
    "end": "555200"
  },
  {
    "text": "any scale will make sure that all those",
    "start": "555200",
    "end": "556560"
  },
  {
    "text": "requirements are installed in the",
    "start": "556560",
    "end": "557920"
  },
  {
    "text": "environment across the cluster",
    "start": "557920",
    "end": "561040"
  },
  {
    "text": "for the local module any scale will make",
    "start": "561040",
    "end": "562880"
  },
  {
    "text": "sure that um all of the files in my",
    "start": "562880",
    "end": "564959"
  },
  {
    "text": "local directory are synced up synced up",
    "start": "564959",
    "end": "566800"
  },
  {
    "text": "to the cluster every time that i run",
    "start": "566800",
    "end": "570480"
  },
  {
    "text": "so this script currently has a bug in it",
    "start": "570720",
    "end": "572720"
  },
  {
    "text": "um and we're going to use the ray",
    "start": "572720",
    "end": "574240"
  },
  {
    "text": "debugger",
    "start": "574240",
    "end": "574959"
  },
  {
    "text": "to to debug it so here you can see i'm",
    "start": "574959",
    "end": "577760"
  },
  {
    "text": "setting a breakpoint",
    "start": "577760",
    "end": "579680"
  },
  {
    "text": "and this is inside of a remote function",
    "start": "579680",
    "end": "581839"
  },
  {
    "text": "but we'll be able to debug it as if it",
    "start": "581839",
    "end": "583600"
  },
  {
    "text": "was all just running in one process",
    "start": "583600",
    "end": "587360"
  },
  {
    "text": "so let's run this script on any scale",
    "start": "587360",
    "end": "589680"
  },
  {
    "text": "all i need to do is",
    "start": "589680",
    "end": "590959"
  },
  {
    "text": "run pythontrain.pi one more time",
    "start": "590959",
    "end": "594720"
  },
  {
    "text": "but this time i'm going to pass in a ray",
    "start": "594720",
    "end": "596560"
  },
  {
    "text": "address and i'm going to",
    "start": "596560",
    "end": "598080"
  },
  {
    "text": "tell it to connect to any scale and",
    "start": "598080",
    "end": "600080"
  },
  {
    "text": "connect to this training cluster that i",
    "start": "600080",
    "end": "601600"
  },
  {
    "text": "have",
    "start": "601600",
    "end": "603040"
  },
  {
    "text": "so let's go ahead and run it",
    "start": "603040",
    "end": "606160"
  },
  {
    "text": "here you can see that i get log messages",
    "start": "610800",
    "end": "612320"
  },
  {
    "text": "from any scale now",
    "start": "612320",
    "end": "613839"
  },
  {
    "text": "telling me that it's syncing up all of",
    "start": "613839",
    "end": "615360"
  },
  {
    "text": "my local files and also that we're using",
    "start": "615360",
    "end": "617600"
  },
  {
    "text": "a cached environment for those",
    "start": "617600",
    "end": "619680"
  },
  {
    "text": "pip packages so we don't need to wait",
    "start": "619680",
    "end": "621360"
  },
  {
    "text": "for them to install",
    "start": "621360",
    "end": "623040"
  },
  {
    "text": "this allows us to iterate rapidly",
    "start": "623040",
    "end": "626079"
  },
  {
    "text": "and run this repeatedly without having",
    "start": "626079",
    "end": "628160"
  },
  {
    "text": "to wait for the full environment to",
    "start": "628160",
    "end": "629440"
  },
  {
    "text": "install every time",
    "start": "629440",
    "end": "631760"
  },
  {
    "text": "so here as expected we got an error",
    "start": "631760",
    "end": "634000"
  },
  {
    "text": "message that it failed to load the data",
    "start": "634000",
    "end": "636720"
  },
  {
    "text": "but it looks like our breakpoint was set",
    "start": "636720",
    "end": "638560"
  },
  {
    "text": "so we can go ahead to it and attach to",
    "start": "638560",
    "end": "640320"
  },
  {
    "text": "that so we can debug it",
    "start": "640320",
    "end": "642880"
  },
  {
    "text": "note that i could do this from my laptop",
    "start": "642880",
    "end": "644560"
  },
  {
    "text": "but i'm going to choose to do it from",
    "start": "644560",
    "end": "645920"
  },
  {
    "text": "the any scale ui to show you the web",
    "start": "645920",
    "end": "647920"
  },
  {
    "text": "terminal that we have",
    "start": "647920",
    "end": "650800"
  },
  {
    "text": "so here i just open the link that was",
    "start": "652720",
    "end": "654480"
  },
  {
    "text": "printed in my terminal",
    "start": "654480",
    "end": "656640"
  },
  {
    "text": "and you can see that i have another",
    "start": "656640",
    "end": "658720"
  },
  {
    "text": "terminal here that's connected directly",
    "start": "658720",
    "end": "660480"
  },
  {
    "text": "to the cluster so i can run commands on",
    "start": "660480",
    "end": "662320"
  },
  {
    "text": "it",
    "start": "662320",
    "end": "663440"
  },
  {
    "text": "in this case all we want to do is use",
    "start": "663440",
    "end": "665200"
  },
  {
    "text": "the raid debug command to attach to that",
    "start": "665200",
    "end": "667360"
  },
  {
    "text": "breakpoint that we set",
    "start": "667360",
    "end": "670320"
  },
  {
    "text": "so here i'm going to attach to the",
    "start": "670320",
    "end": "671680"
  },
  {
    "text": "breakpoint that we have inside of our",
    "start": "671680",
    "end": "673440"
  },
  {
    "text": "remote function",
    "start": "673440",
    "end": "676240"
  },
  {
    "text": "and you can see that we now have this",
    "start": "676800",
    "end": "678240"
  },
  {
    "text": "breakpoint just after the exception",
    "start": "678240",
    "end": "680240"
  },
  {
    "text": "occurred",
    "start": "680240",
    "end": "681120"
  },
  {
    "text": "so we can go ahead and rerun this load",
    "start": "681120",
    "end": "683360"
  },
  {
    "text": "data from file that failed then we",
    "start": "683360",
    "end": "684880"
  },
  {
    "text": "should see it fail again",
    "start": "684880",
    "end": "687200"
  },
  {
    "text": "um so let's take a look at the file path",
    "start": "687200",
    "end": "689279"
  },
  {
    "text": "that it's trying to read from",
    "start": "689279",
    "end": "692000"
  },
  {
    "text": "here we can see that this is an absolute",
    "start": "692000",
    "end": "693680"
  },
  {
    "text": "path and it looks suspiciously like it",
    "start": "693680",
    "end": "695680"
  },
  {
    "text": "came from my laptop",
    "start": "695680",
    "end": "698160"
  },
  {
    "text": "if we take a look at what we have in the",
    "start": "698160",
    "end": "699920"
  },
  {
    "text": "working directory",
    "start": "699920",
    "end": "702079"
  },
  {
    "text": "because any scale synced up all the",
    "start": "702079",
    "end": "703839"
  },
  {
    "text": "files from my laptop to the cluster",
    "start": "703839",
    "end": "707440"
  },
  {
    "text": "we have the training data along with the",
    "start": "707440",
    "end": "709360"
  },
  {
    "text": "other code like the local module",
    "start": "709360",
    "end": "711360"
  },
  {
    "text": "so all we need to do is actually just",
    "start": "711360",
    "end": "712959"
  },
  {
    "text": "provide this relative path",
    "start": "712959",
    "end": "714720"
  },
  {
    "text": "when we're loading the data so let's go",
    "start": "714720",
    "end": "716560"
  },
  {
    "text": "ahead and make the change to do that",
    "start": "716560",
    "end": "720079"
  },
  {
    "text": "so back on my laptop i'm just going to",
    "start": "725120",
    "end": "727760"
  },
  {
    "text": "go ahead and make that small change so",
    "start": "727760",
    "end": "730000"
  },
  {
    "text": "here when we're passing in the data path",
    "start": "730000",
    "end": "731760"
  },
  {
    "text": "we just need to pass the abs or the",
    "start": "731760",
    "end": "733360"
  },
  {
    "text": "relative path",
    "start": "733360",
    "end": "735680"
  },
  {
    "text": "and we should be ready to run this once",
    "start": "735680",
    "end": "738720"
  },
  {
    "text": "again",
    "start": "738720",
    "end": "740959"
  },
  {
    "text": "okay so this time we should i think this",
    "start": "742000",
    "end": "743680"
  },
  {
    "text": "should work um so we can go ahead and",
    "start": "743680",
    "end": "745760"
  },
  {
    "text": "scale it up",
    "start": "745760",
    "end": "746639"
  },
  {
    "text": "here i'm gonna run a hundred trials in",
    "start": "746639",
    "end": "748240"
  },
  {
    "text": "parallel of course we could run",
    "start": "748240",
    "end": "750079"
  },
  {
    "text": "thousands um but i wanna make sure that",
    "start": "750079",
    "end": "752000"
  },
  {
    "text": "this finishes uh",
    "start": "752000",
    "end": "753519"
  },
  {
    "text": "in a reasonable amount of time for the",
    "start": "753519",
    "end": "756800"
  },
  {
    "text": "demo",
    "start": "756839",
    "end": "759839"
  },
  {
    "text": "so once again we're syncing up the local",
    "start": "760160",
    "end": "761920"
  },
  {
    "text": "files and using that cached environment",
    "start": "761920",
    "end": "766560"
  },
  {
    "text": "so we've now connected up to the",
    "start": "768000",
    "end": "769519"
  },
  {
    "text": "training cluster",
    "start": "769519",
    "end": "772160"
  },
  {
    "text": "and in a second if we fixed our bug we",
    "start": "772160",
    "end": "774240"
  },
  {
    "text": "should see output from das",
    "start": "774240",
    "end": "775760"
  },
  {
    "text": "on ray okay excellent so it looks like",
    "start": "775760",
    "end": "778320"
  },
  {
    "text": "the",
    "start": "778320",
    "end": "778800"
  },
  {
    "text": "loading the data and pre-processing is",
    "start": "778800",
    "end": "780560"
  },
  {
    "text": "working",
    "start": "780560",
    "end": "781839"
  },
  {
    "text": "and we see that some of our trials are",
    "start": "781839",
    "end": "783360"
  },
  {
    "text": "beginning to run so let's go ahead and",
    "start": "783360",
    "end": "785519"
  },
  {
    "text": "see what's going on in the any scale ui",
    "start": "785519",
    "end": "789360"
  },
  {
    "text": "so here i'm looking at the jobs page",
    "start": "789519",
    "end": "791760"
  },
  {
    "text": "which shows us all of the jobs that",
    "start": "791760",
    "end": "793360"
  },
  {
    "text": "we've run",
    "start": "793360",
    "end": "793920"
  },
  {
    "text": "on any scale you can see that we have a",
    "start": "793920",
    "end": "796560"
  },
  {
    "text": "log of",
    "start": "796560",
    "end": "797200"
  },
  {
    "text": "jobs we've run in the past as well as",
    "start": "797200",
    "end": "799279"
  },
  {
    "text": "the one that's currently running",
    "start": "799279",
    "end": "800880"
  },
  {
    "text": "and we can see that it's currently",
    "start": "800880",
    "end": "802079"
  },
  {
    "text": "running here we can take a look at the",
    "start": "802079",
    "end": "804639"
  },
  {
    "text": "logs for the job",
    "start": "804639",
    "end": "805920"
  },
  {
    "text": "and these should be the same as the ones",
    "start": "805920",
    "end": "807279"
  },
  {
    "text": "that are being streamed to my terminal",
    "start": "807279",
    "end": "810000"
  },
  {
    "text": "so here we can see all the same logs",
    "start": "810000",
    "end": "811680"
  },
  {
    "text": "from xg boost on ray and these will be",
    "start": "811680",
    "end": "813600"
  },
  {
    "text": "persisted after the job finishes",
    "start": "813600",
    "end": "817440"
  },
  {
    "text": "we can also click into the cluster that",
    "start": "817440",
    "end": "819040"
  },
  {
    "text": "this is running on",
    "start": "819040",
    "end": "821120"
  },
  {
    "text": "and here we can see a summary of what's",
    "start": "821120",
    "end": "822720"
  },
  {
    "text": "going on in the cluster we can see that",
    "start": "822720",
    "end": "824240"
  },
  {
    "text": "there are currently 155 cpus being used",
    "start": "824240",
    "end": "827519"
  },
  {
    "text": "as well as a lot of object store memory",
    "start": "827519",
    "end": "830880"
  },
  {
    "text": "we can see a list of the jobs that ran",
    "start": "830880",
    "end": "832880"
  },
  {
    "text": "specifically on this cluster",
    "start": "832880",
    "end": "834480"
  },
  {
    "text": "and we can even see all of the actors",
    "start": "834480",
    "end": "836399"
  },
  {
    "text": "that are currently active on the cluster",
    "start": "836399",
    "end": "838800"
  },
  {
    "text": "we could take a look at individual at",
    "start": "838800",
    "end": "841279"
  },
  {
    "text": "logs from individual actors as well",
    "start": "841279",
    "end": "843040"
  },
  {
    "text": "which is useful for debugging",
    "start": "843040",
    "end": "846240"
  },
  {
    "text": "so let's take a look at the raid",
    "start": "846240",
    "end": "847360"
  },
  {
    "text": "dashboard",
    "start": "847360",
    "end": "849440"
  },
  {
    "text": "and here we should be able to see the",
    "start": "849440",
    "end": "850880"
  },
  {
    "text": "resource utilization",
    "start": "850880",
    "end": "853279"
  },
  {
    "text": "happening on the cluster we can see that",
    "start": "853279",
    "end": "856560"
  },
  {
    "text": "because we ran 100 trials in parallel",
    "start": "856560",
    "end": "858560"
  },
  {
    "text": "any scale",
    "start": "858560",
    "end": "859600"
  },
  {
    "text": "spun up it looks like 10 worker machines",
    "start": "859600",
    "end": "862480"
  },
  {
    "text": "and we're currently running the trials",
    "start": "862480",
    "end": "864000"
  },
  {
    "text": "across over 150 cpus",
    "start": "864000",
    "end": "867199"
  },
  {
    "text": "as you can see by the cpu utilization",
    "start": "867199",
    "end": "869440"
  },
  {
    "text": "here",
    "start": "869440",
    "end": "871199"
  },
  {
    "text": "so at this point let's just give this a",
    "start": "871199",
    "end": "873920"
  },
  {
    "text": "few moments to",
    "start": "873920",
    "end": "875120"
  },
  {
    "text": "finish running all of our trials and we",
    "start": "875120",
    "end": "877199"
  },
  {
    "text": "should have our trained model",
    "start": "877199",
    "end": "880000"
  },
  {
    "text": "so it looks like the cpu utilization is",
    "start": "880000",
    "end": "882639"
  },
  {
    "text": "winding down",
    "start": "882639",
    "end": "883440"
  },
  {
    "text": "so our job should be just about finished",
    "start": "883440",
    "end": "887120"
  },
  {
    "text": "back in the terminal you can see that",
    "start": "887120",
    "end": "888880"
  },
  {
    "text": "all 100 of our trials",
    "start": "888880",
    "end": "890880"
  },
  {
    "text": "seem to have finished and in a second",
    "start": "890880",
    "end": "892880"
  },
  {
    "text": "here we should get a summary",
    "start": "892880",
    "end": "895360"
  },
  {
    "text": "it looks like we finished training the",
    "start": "895360",
    "end": "897040"
  },
  {
    "text": "the model and the best one that we got",
    "start": "897040",
    "end": "900399"
  },
  {
    "text": "was a pretty big increase in accuracy",
    "start": "900399",
    "end": "902639"
  },
  {
    "text": "from what we did locally",
    "start": "902639",
    "end": "904160"
  },
  {
    "text": "and we saved this up to s3 so that we",
    "start": "904160",
    "end": "906079"
  },
  {
    "text": "can use it when serving the model later",
    "start": "906079",
    "end": "909839"
  },
  {
    "text": "back in the any scale ui we can see that",
    "start": "909920",
    "end": "911920"
  },
  {
    "text": "the job",
    "start": "911920",
    "end": "913120"
  },
  {
    "text": "has now been marked as completed but we",
    "start": "913120",
    "end": "915279"
  },
  {
    "text": "still have this record of how long it",
    "start": "915279",
    "end": "916880"
  },
  {
    "text": "took",
    "start": "916880",
    "end": "917519"
  },
  {
    "text": "who ran it and when and we can even see",
    "start": "917519",
    "end": "919600"
  },
  {
    "text": "the logs for it",
    "start": "919600",
    "end": "922319"
  },
  {
    "text": "so at this point we've trained our our",
    "start": "922560",
    "end": "925120"
  },
  {
    "text": "intent classifier and we should be ready",
    "start": "925120",
    "end": "927040"
  },
  {
    "text": "to start working on",
    "start": "927040",
    "end": "928160"
  },
  {
    "text": "actually serving our support bot",
    "start": "928160",
    "end": "932000"
  },
  {
    "text": "so let's recap what i just did i first",
    "start": "932639",
    "end": "935199"
  },
  {
    "text": "developed and tested a scalable training",
    "start": "935199",
    "end": "937120"
  },
  {
    "text": "pipeline on my laptop",
    "start": "937120",
    "end": "938959"
  },
  {
    "text": "and then to run it on the cloud all i",
    "start": "938959",
    "end": "940720"
  },
  {
    "text": "needed to do was change an environment",
    "start": "940720",
    "end": "942399"
  },
  {
    "text": "variable",
    "start": "942399",
    "end": "943519"
  },
  {
    "text": "any scale synced up my local files and",
    "start": "943519",
    "end": "945440"
  },
  {
    "text": "dependencies and were able to debug a",
    "start": "945440",
    "end": "947680"
  },
  {
    "text": "small issue in the code using the remote",
    "start": "947680",
    "end": "949519"
  },
  {
    "text": "debugger",
    "start": "949519",
    "end": "951360"
  },
  {
    "text": "all of these tools combined offer the",
    "start": "951360",
    "end": "953120"
  },
  {
    "text": "infinite laptop experience",
    "start": "953120",
    "end": "955040"
  },
  {
    "text": "running at scale in the cloud while",
    "start": "955040",
    "end": "956800"
  },
  {
    "text": "iterating quickly on my laptop",
    "start": "956800",
    "end": "959440"
  },
  {
    "text": "now that we've trained our intent",
    "start": "959440",
    "end": "960639"
  },
  {
    "text": "classifier model let's get started with",
    "start": "960639",
    "end": "962720"
  },
  {
    "text": "building the end-to-end support bot",
    "start": "962720",
    "end": "966319"
  },
  {
    "text": "in order to build a scalable low latency",
    "start": "966399",
    "end": "968639"
  },
  {
    "text": "api we'll be building and deploying an",
    "start": "968639",
    "end": "970639"
  },
  {
    "text": "inference pipeline using race serv",
    "start": "970639",
    "end": "973440"
  },
  {
    "text": "when a user sends a message it will be",
    "start": "973440",
    "end": "975199"
  },
  {
    "text": "routed to our ray cluster running on any",
    "start": "975199",
    "end": "977120"
  },
  {
    "text": "scale",
    "start": "977120",
    "end": "978160"
  },
  {
    "text": "this cluster is running a number of",
    "start": "978160",
    "end": "979920"
  },
  {
    "text": "production deployments of actors",
    "start": "979920",
    "end": "982399"
  },
  {
    "text": "when a request comes in it will be",
    "start": "982399",
    "end": "984079"
  },
  {
    "text": "pre-processed and forwarded to the two",
    "start": "984079",
    "end": "986079"
  },
  {
    "text": "downstream models",
    "start": "986079",
    "end": "987519"
  },
  {
    "text": "these requests are made in parallel to",
    "start": "987519",
    "end": "989279"
  },
  {
    "text": "minimize latency",
    "start": "989279",
    "end": "991839"
  },
  {
    "text": "the results from each of the two models",
    "start": "991839",
    "end": "993440"
  },
  {
    "text": "will then be combined using custom",
    "start": "993440",
    "end": "995279"
  },
  {
    "text": "business logic",
    "start": "995279",
    "end": "996079"
  },
  {
    "text": "to form the response and note that each",
    "start": "996079",
    "end": "998959"
  },
  {
    "text": "of these deployments can be",
    "start": "998959",
    "end": "1000160"
  },
  {
    "text": "independently scaled to efficiently",
    "start": "1000160",
    "end": "1001920"
  },
  {
    "text": "handle many concurrent users",
    "start": "1001920",
    "end": "1003839"
  },
  {
    "text": "and they can also be declaratively",
    "start": "1003839",
    "end": "1005440"
  },
  {
    "text": "updated with zero downtime",
    "start": "1005440",
    "end": "1007920"
  },
  {
    "text": "so let's get started building and",
    "start": "1007920",
    "end": "1009360"
  },
  {
    "text": "deploying the support bot",
    "start": "1009360",
    "end": "1012639"
  },
  {
    "text": "back in the terminal on my laptop we're",
    "start": "1012720",
    "end": "1014560"
  },
  {
    "text": "ready to develop and deploy",
    "start": "1014560",
    "end": "1016320"
  },
  {
    "text": "our support bot i have the code defined",
    "start": "1016320",
    "end": "1019440"
  },
  {
    "text": "in this chatbot.pi",
    "start": "1019440",
    "end": "1020720"
  },
  {
    "text": "file here we can see that the first",
    "start": "1020720",
    "end": "1023759"
  },
  {
    "text": "thing that i'm doing once again",
    "start": "1023759",
    "end": "1025120"
  },
  {
    "text": "is calling ray.client.connect to connect",
    "start": "1025120",
    "end": "1027760"
  },
  {
    "text": "to ray",
    "start": "1027760",
    "end": "1029038"
  },
  {
    "text": "then we're defining a number of race",
    "start": "1029039",
    "end": "1030558"
  },
  {
    "text": "serve deployments",
    "start": "1030559",
    "end": "1032079"
  },
  {
    "text": "note that each of these can be",
    "start": "1032079",
    "end": "1033360"
  },
  {
    "text": "independently scaled using the number of",
    "start": "1033360",
    "end": "1035280"
  },
  {
    "text": "replicas",
    "start": "1035280",
    "end": "1036079"
  },
  {
    "text": "and also has its own version which means",
    "start": "1036079",
    "end": "1038079"
  },
  {
    "text": "that we can do incremental deployments",
    "start": "1038079",
    "end": "1040640"
  },
  {
    "text": "with zero downtime our first deployment",
    "start": "1040640",
    "end": "1043918"
  },
  {
    "text": "is the intent classifier which is",
    "start": "1043919",
    "end": "1045520"
  },
  {
    "text": "basically just wrapping the model we",
    "start": "1045520",
    "end": "1046959"
  },
  {
    "text": "just finished training",
    "start": "1046959",
    "end": "1048000"
  },
  {
    "text": "using tune and xg boost",
    "start": "1048000",
    "end": "1051120"
  },
  {
    "text": "we also have this relevant search model",
    "start": "1051120",
    "end": "1053520"
  },
  {
    "text": "which is",
    "start": "1053520",
    "end": "1054240"
  },
  {
    "text": "similarly wrapping another model that i",
    "start": "1054240",
    "end": "1056320"
  },
  {
    "text": "already had trained",
    "start": "1056320",
    "end": "1059120"
  },
  {
    "text": "finally we have our chat bot deployment",
    "start": "1059840",
    "end": "1062960"
  },
  {
    "text": "and the chat bot is using the",
    "start": "1062960",
    "end": "1066480"
  },
  {
    "text": "race serve native support for wrapping",
    "start": "1066480",
    "end": "1068400"
  },
  {
    "text": "fast api applications so we can easily",
    "start": "1068400",
    "end": "1070640"
  },
  {
    "text": "handle http traffic",
    "start": "1070640",
    "end": "1073280"
  },
  {
    "text": "in the constructor for the chat bot you",
    "start": "1073280",
    "end": "1075120"
  },
  {
    "text": "can see that we're getting a handle to",
    "start": "1075120",
    "end": "1076559"
  },
  {
    "text": "the two downstream models so that we can",
    "start": "1076559",
    "end": "1078240"
  },
  {
    "text": "send requests to them later",
    "start": "1078240",
    "end": "1081520"
  },
  {
    "text": "when a request comes in the first thing",
    "start": "1081520",
    "end": "1083360"
  },
  {
    "text": "that we're going to do is pre-process",
    "start": "1083360",
    "end": "1085039"
  },
  {
    "text": "the input and put it into the raise",
    "start": "1085039",
    "end": "1086880"
  },
  {
    "text": "shared memory object store",
    "start": "1086880",
    "end": "1088640"
  },
  {
    "text": "so that we can efficiently pass it to",
    "start": "1088640",
    "end": "1090240"
  },
  {
    "text": "the two downstream models",
    "start": "1090240",
    "end": "1092559"
  },
  {
    "text": "we then kick off the request to the two",
    "start": "1092559",
    "end": "1094480"
  },
  {
    "text": "downstream models in parallel to",
    "start": "1094480",
    "end": "1096240"
  },
  {
    "text": "minimize user facing latency",
    "start": "1096240",
    "end": "1099919"
  },
  {
    "text": "we then build the response once the",
    "start": "1099919",
    "end": "1102320"
  },
  {
    "text": "request to the two downstream models",
    "start": "1102320",
    "end": "1104000"
  },
  {
    "text": "comes back",
    "start": "1104000",
    "end": "1104960"
  },
  {
    "text": "using some custom business logic and we",
    "start": "1104960",
    "end": "1107039"
  },
  {
    "text": "return it to the user",
    "start": "1107039",
    "end": "1109840"
  },
  {
    "text": "at the bottom of the script we're just",
    "start": "1111440",
    "end": "1113200"
  },
  {
    "text": "deploying these two models",
    "start": "1113200",
    "end": "1114480"
  },
  {
    "text": "you can see that we're passing in the s3",
    "start": "1114480",
    "end": "1116160"
  },
  {
    "text": "path to the model that we just finished",
    "start": "1116160",
    "end": "1117760"
  },
  {
    "text": "training using ray tune",
    "start": "1117760",
    "end": "1119120"
  },
  {
    "text": "and xg boost and then the very last",
    "start": "1119120",
    "end": "1122080"
  },
  {
    "text": "thing that we do is run a basic test",
    "start": "1122080",
    "end": "1124320"
  },
  {
    "text": "so here we're just sending a test",
    "start": "1124320",
    "end": "1125840"
  },
  {
    "text": "message in this case we're just saying",
    "start": "1125840",
    "end": "1127679"
  },
  {
    "text": "hello",
    "start": "1127679",
    "end": "1128480"
  },
  {
    "text": "and checking that the support bot",
    "start": "1128480",
    "end": "1129919"
  },
  {
    "text": "returns something as a response",
    "start": "1129919",
    "end": "1134159"
  },
  {
    "text": "so let's go ahead and deploy this so i",
    "start": "1134240",
    "end": "1137120"
  },
  {
    "text": "could",
    "start": "1137120",
    "end": "1137679"
  },
  {
    "text": "run it locally and test it as i did with",
    "start": "1137679",
    "end": "1139679"
  },
  {
    "text": "the training script",
    "start": "1139679",
    "end": "1141440"
  },
  {
    "text": "but let's just deploy it straight to my",
    "start": "1141440",
    "end": "1143120"
  },
  {
    "text": "staging cluster for the sake of time",
    "start": "1143120",
    "end": "1151840"
  },
  {
    "text": "so we're connected to the staging",
    "start": "1152640",
    "end": "1153919"
  },
  {
    "text": "cluster and we can we're now getting a",
    "start": "1153919",
    "end": "1156000"
  },
  {
    "text": "lot of log messages from ray serve",
    "start": "1156000",
    "end": "1157600"
  },
  {
    "text": "telling us that it's starting",
    "start": "1157600",
    "end": "1159120"
  },
  {
    "text": "um the replicas that we requested and it",
    "start": "1159120",
    "end": "1161679"
  },
  {
    "text": "looks like our basic test succeeded",
    "start": "1161679",
    "end": "1164160"
  },
  {
    "text": "so we should be ready to test out our",
    "start": "1164160",
    "end": "1165919"
  },
  {
    "text": "support bot",
    "start": "1165919",
    "end": "1168559"
  },
  {
    "text": "so here you can see that i have the",
    "start": "1171919",
    "end": "1173679"
  },
  {
    "text": "regular ray webpage but now we have this",
    "start": "1173679",
    "end": "1176559"
  },
  {
    "text": "chat bubble on the bottom right if i",
    "start": "1176559",
    "end": "1179360"
  },
  {
    "text": "click into it we get a friendly greeting",
    "start": "1179360",
    "end": "1181200"
  },
  {
    "text": "message from our support bot",
    "start": "1181200",
    "end": "1183039"
  },
  {
    "text": "so let's grade it back hello nice to",
    "start": "1183039",
    "end": "1185360"
  },
  {
    "text": "meet you",
    "start": "1185360",
    "end": "1187760"
  },
  {
    "text": "in this case the support bot correctly",
    "start": "1188960",
    "end": "1191679"
  },
  {
    "text": "classified this as just a greeting and",
    "start": "1191679",
    "end": "1193280"
  },
  {
    "text": "returned another greeting in response",
    "start": "1193280",
    "end": "1195919"
  },
  {
    "text": "but maybe the user wants to learn",
    "start": "1195919",
    "end": "1197679"
  },
  {
    "text": "something more specific like they want",
    "start": "1197679",
    "end": "1199200"
  },
  {
    "text": "to learn",
    "start": "1199200",
    "end": "1200080"
  },
  {
    "text": "how to train ml models on ray",
    "start": "1200080",
    "end": "1206080"
  },
  {
    "text": "here the intent classifier correctly",
    "start": "1206080",
    "end": "1208880"
  },
  {
    "text": "classified this as a question",
    "start": "1208880",
    "end": "1210640"
  },
  {
    "text": "and the relevant search returned ray",
    "start": "1210640",
    "end": "1213039"
  },
  {
    "text": "tune as the most relevant place to look",
    "start": "1213039",
    "end": "1216799"
  },
  {
    "text": "so maybe the user is up and running with",
    "start": "1216799",
    "end": "1218400"
  },
  {
    "text": "ray tune for a while but then they run",
    "start": "1218400",
    "end": "1220080"
  },
  {
    "text": "into an issue",
    "start": "1220080",
    "end": "1220880"
  },
  {
    "text": "so they report it and say i've run into",
    "start": "1220880",
    "end": "1223200"
  },
  {
    "text": "an issue",
    "start": "1223200",
    "end": "1224480"
  },
  {
    "text": "with tune",
    "start": "1224480",
    "end": "1227039"
  },
  {
    "text": "so here it looks like our support bot",
    "start": "1227679",
    "end": "1229360"
  },
  {
    "text": "correctly classified that this might be",
    "start": "1229360",
    "end": "1231280"
  },
  {
    "text": "a bug report",
    "start": "1231280",
    "end": "1232720"
  },
  {
    "text": "but the link that it's returning doesn't",
    "start": "1232720",
    "end": "1234720"
  },
  {
    "text": "seem very helpful",
    "start": "1234720",
    "end": "1235760"
  },
  {
    "text": "this is just linking back to the",
    "start": "1235760",
    "end": "1237440"
  },
  {
    "text": "introduction to ray page",
    "start": "1237440",
    "end": "1239039"
  },
  {
    "text": "really what we want here is for the bot",
    "start": "1239039",
    "end": "1241039"
  },
  {
    "text": "to link",
    "start": "1241039",
    "end": "1242240"
  },
  {
    "text": "to the ray github issues page so the",
    "start": "1242240",
    "end": "1244960"
  },
  {
    "text": "user can report it",
    "start": "1244960",
    "end": "1246720"
  },
  {
    "text": "so let's go ahead and try to fix this",
    "start": "1246720",
    "end": "1248960"
  },
  {
    "text": "bug in our support bot",
    "start": "1248960",
    "end": "1250640"
  },
  {
    "text": "um but when we update this we really",
    "start": "1250640",
    "end": "1252960"
  },
  {
    "text": "don't want to be manually deploying from",
    "start": "1252960",
    "end": "1254640"
  },
  {
    "text": "my laptop like we did the first time",
    "start": "1254640",
    "end": "1256720"
  },
  {
    "text": "it would be great if we had an automated",
    "start": "1256720",
    "end": "1259360"
  },
  {
    "text": "ci system",
    "start": "1259360",
    "end": "1260240"
  },
  {
    "text": "that would deploy straight to any scale",
    "start": "1260240",
    "end": "1262159"
  },
  {
    "text": "for us",
    "start": "1262159",
    "end": "1264559"
  },
  {
    "text": "so let's get started with fixing the bug",
    "start": "1264559",
    "end": "1266320"
  },
  {
    "text": "and then we can set up our",
    "start": "1266320",
    "end": "1267760"
  },
  {
    "text": "zero downtime deployments from ci",
    "start": "1267760",
    "end": "1271679"
  },
  {
    "text": "fixing the bug should be relatively",
    "start": "1272880",
    "end": "1274480"
  },
  {
    "text": "simple in this case",
    "start": "1274480",
    "end": "1276000"
  },
  {
    "text": "basically what we want to do is if the",
    "start": "1276000",
    "end": "1278400"
  },
  {
    "text": "intent",
    "start": "1278400",
    "end": "1279039"
  },
  {
    "text": "classifier returns that this was a bug",
    "start": "1279039",
    "end": "1282720"
  },
  {
    "text": "then ins the response that we want to",
    "start": "1282720",
    "end": "1284960"
  },
  {
    "text": "return the link should just go to the",
    "start": "1284960",
    "end": "1287760"
  },
  {
    "text": "ray github issues page github.com",
    "start": "1287760",
    "end": "1291039"
  },
  {
    "text": "ray project slash ray issues",
    "start": "1291039",
    "end": "1295520"
  },
  {
    "text": "and we can give this a nicer title and",
    "start": "1295520",
    "end": "1297520"
  },
  {
    "text": "call it the array issues page",
    "start": "1297520",
    "end": "1302159"
  },
  {
    "text": "so that should be all of the code change",
    "start": "1302320",
    "end": "1304159"
  },
  {
    "text": "that we need here",
    "start": "1304159",
    "end": "1306240"
  },
  {
    "text": "and then we also just need to bump the",
    "start": "1306240",
    "end": "1307840"
  },
  {
    "text": "version on this deployment so that",
    "start": "1307840",
    "end": "1309440"
  },
  {
    "text": "racerv knows that we should update",
    "start": "1309440",
    "end": "1311679"
  },
  {
    "text": "this deployment and only this deployment",
    "start": "1311679",
    "end": "1315440"
  },
  {
    "text": "so we should be ready to deploy this",
    "start": "1315760",
    "end": "1318320"
  },
  {
    "text": "let's go ahead and set up our automated",
    "start": "1318320",
    "end": "1320320"
  },
  {
    "text": "ci workflow here we're using github",
    "start": "1320320",
    "end": "1323919"
  },
  {
    "text": "actions",
    "start": "1323919",
    "end": "1324400"
  },
  {
    "text": "if you're not too familiar with this",
    "start": "1324400",
    "end": "1325600"
  },
  {
    "text": "syntax that's okay",
    "start": "1325600",
    "end": "1327440"
  },
  {
    "text": "the two important parts are down at the",
    "start": "1327440",
    "end": "1329679"
  },
  {
    "text": "bottom here",
    "start": "1329679",
    "end": "1330559"
  },
  {
    "text": "where we're testing on staging and then",
    "start": "1330559",
    "end": "1332720"
  },
  {
    "text": "if that succeeds we'll deploy to",
    "start": "1332720",
    "end": "1334480"
  },
  {
    "text": "production",
    "start": "1334480",
    "end": "1336080"
  },
  {
    "text": "so all we need to do in order to test",
    "start": "1336080",
    "end": "1337840"
  },
  {
    "text": "this on staging is",
    "start": "1337840",
    "end": "1339520"
  },
  {
    "text": "exactly how we deployed from my laptop",
    "start": "1339520",
    "end": "1343280"
  },
  {
    "text": "so we're going to point it at the",
    "start": "1343919",
    "end": "1344960"
  },
  {
    "text": "staging cluster and run this chatbot.pi",
    "start": "1344960",
    "end": "1347280"
  },
  {
    "text": "script which will declaratively update",
    "start": "1347280",
    "end": "1349760"
  },
  {
    "text": "and then it'll run that basic test if",
    "start": "1349760",
    "end": "1352000"
  },
  {
    "text": "all of that passes",
    "start": "1352000",
    "end": "1353120"
  },
  {
    "text": "then we're going to deploy to production",
    "start": "1353120",
    "end": "1356559"
  },
  {
    "text": "so it's extremely easy to integrate with",
    "start": "1357200",
    "end": "1359039"
  },
  {
    "text": "this existing tooling like github",
    "start": "1359039",
    "end": "1360720"
  },
  {
    "text": "actions",
    "start": "1360720",
    "end": "1362559"
  },
  {
    "text": "and we should be good to go here",
    "start": "1362559",
    "end": "1366240"
  },
  {
    "text": "so let's go ahead and commit my changes",
    "start": "1366240",
    "end": "1370480"
  },
  {
    "text": "we can call this something like fix the",
    "start": "1370480",
    "end": "1372240"
  },
  {
    "text": "small bug",
    "start": "1372240",
    "end": "1374320"
  },
  {
    "text": "but before i push this in order to show",
    "start": "1374320",
    "end": "1377360"
  },
  {
    "text": "that this is a zero downtime",
    "start": "1377360",
    "end": "1379280"
  },
  {
    "text": "update i'm going to start a load test in",
    "start": "1379280",
    "end": "1381600"
  },
  {
    "text": "the background",
    "start": "1381600",
    "end": "1382960"
  },
  {
    "text": "so i have this tool called locust which",
    "start": "1382960",
    "end": "1384720"
  },
  {
    "text": "is just going to simulate a number of",
    "start": "1384720",
    "end": "1386320"
  },
  {
    "text": "users",
    "start": "1386320",
    "end": "1387520"
  },
  {
    "text": "chatting with the bot for us",
    "start": "1387520",
    "end": "1390720"
  },
  {
    "text": "so here we can see that we have a bunch",
    "start": "1391520",
    "end": "1393760"
  },
  {
    "text": "of requests going out",
    "start": "1393760",
    "end": "1396159"
  },
  {
    "text": "looks like a couple hundred per second",
    "start": "1396159",
    "end": "1397760"
  },
  {
    "text": "or something like that",
    "start": "1397760",
    "end": "1399360"
  },
  {
    "text": "and we'll leave this running in the",
    "start": "1399360",
    "end": "1400480"
  },
  {
    "text": "background as we do our deployment",
    "start": "1400480",
    "end": "1404158"
  },
  {
    "text": "so i'm going to push this up to ci and",
    "start": "1405120",
    "end": "1407679"
  },
  {
    "text": "this should trigger that workflow that",
    "start": "1407679",
    "end": "1409120"
  },
  {
    "text": "we just got done",
    "start": "1409120",
    "end": "1409919"
  },
  {
    "text": "editing",
    "start": "1409919",
    "end": "1412240"
  },
  {
    "text": "on the github page for the repo we can",
    "start": "1413200",
    "end": "1415039"
  },
  {
    "text": "see the commit that i just made",
    "start": "1415039",
    "end": "1417200"
  },
  {
    "text": "41 seconds ago and if we click into",
    "start": "1417200",
    "end": "1420799"
  },
  {
    "text": "the github actions workflow we should",
    "start": "1420799",
    "end": "1424240"
  },
  {
    "text": "see this start to run it may take a",
    "start": "1424240",
    "end": "1427360"
  },
  {
    "text": "couple of seconds here because we need",
    "start": "1427360",
    "end": "1428880"
  },
  {
    "text": "to",
    "start": "1428880",
    "end": "1430159"
  },
  {
    "text": "install the dependencies and and restore",
    "start": "1430159",
    "end": "1432320"
  },
  {
    "text": "any uh",
    "start": "1432320",
    "end": "1433360"
  },
  {
    "text": "cache data that we had but this should",
    "start": "1433360",
    "end": "1435360"
  },
  {
    "text": "only take a couple of seconds",
    "start": "1435360",
    "end": "1445840"
  },
  {
    "text": "so it looks like our dependencies have",
    "start": "1450320",
    "end": "1451679"
  },
  {
    "text": "finished installing and we're now",
    "start": "1451679",
    "end": "1453200"
  },
  {
    "text": "running",
    "start": "1453200",
    "end": "1454240"
  },
  {
    "text": "our chatbot script against staging",
    "start": "1454240",
    "end": "1457600"
  },
  {
    "text": "so this is going to do the exact same",
    "start": "1457600",
    "end": "1459120"
  },
  {
    "text": "thing that we were just doing from our",
    "start": "1459120",
    "end": "1460320"
  },
  {
    "text": "laptop",
    "start": "1460320",
    "end": "1461200"
  },
  {
    "text": "and if we go over to the any scale ui we",
    "start": "1461200",
    "end": "1463279"
  },
  {
    "text": "should be able to see",
    "start": "1463279",
    "end": "1464400"
  },
  {
    "text": "a record of it in the jobs page so here",
    "start": "1464400",
    "end": "1467120"
  },
  {
    "text": "we can see the deployment in project in",
    "start": "1467120",
    "end": "1469039"
  },
  {
    "text": "progress",
    "start": "1469039",
    "end": "1470640"
  },
  {
    "text": "and it's going against our staging",
    "start": "1470640",
    "end": "1472000"
  },
  {
    "text": "cluster and hopefully this succeeds in",
    "start": "1472000",
    "end": "1474000"
  },
  {
    "text": "just a couple of seconds here",
    "start": "1474000",
    "end": "1477120"
  },
  {
    "text": "it looks like that passed so why don't",
    "start": "1477200",
    "end": "1480080"
  },
  {
    "text": "we take a look",
    "start": "1480080",
    "end": "1480880"
  },
  {
    "text": "at um take a look at our staging cluster",
    "start": "1480880",
    "end": "1485679"
  },
  {
    "text": "and here we can use we can use",
    "start": "1485679",
    "end": "1489360"
  },
  {
    "text": "the any scale provided monitoring tools",
    "start": "1489360",
    "end": "1491440"
  },
  {
    "text": "to make sure that everything went off",
    "start": "1491440",
    "end": "1492799"
  },
  {
    "text": "without a hitch",
    "start": "1492799",
    "end": "1494880"
  },
  {
    "text": "so here i have a basic dashboard that's",
    "start": "1494880",
    "end": "1497520"
  },
  {
    "text": "just monitoring the health of our",
    "start": "1497520",
    "end": "1498840"
  },
  {
    "text": "application",
    "start": "1498840",
    "end": "1500000"
  },
  {
    "text": "and here you can see we have the request",
    "start": "1500000",
    "end": "1502240"
  },
  {
    "text": "latency",
    "start": "1502240",
    "end": "1503039"
  },
  {
    "text": "which looks like it remains stable",
    "start": "1503039",
    "end": "1504559"
  },
  {
    "text": "throughout the deployment as well as the",
    "start": "1504559",
    "end": "1506559"
  },
  {
    "text": "per replica",
    "start": "1506559",
    "end": "1507440"
  },
  {
    "text": "queries per second and we can even see",
    "start": "1507440",
    "end": "1509840"
  },
  {
    "text": "resource utilization and the network",
    "start": "1509840",
    "end": "1511600"
  },
  {
    "text": "speed and other",
    "start": "1511600",
    "end": "1512960"
  },
  {
    "text": "just general health indicators so this",
    "start": "1512960",
    "end": "1515600"
  },
  {
    "text": "is extremely useful for operating",
    "start": "1515600",
    "end": "1518080"
  },
  {
    "text": "production applications and uh and in",
    "start": "1518080",
    "end": "1521200"
  },
  {
    "text": "this case it was",
    "start": "1521200",
    "end": "1522240"
  },
  {
    "text": "great to see that our application was",
    "start": "1522240",
    "end": "1523760"
  },
  {
    "text": "able to be updated with no",
    "start": "1523760",
    "end": "1525679"
  },
  {
    "text": "uh no interruptions so now let's make",
    "start": "1525679",
    "end": "1528880"
  },
  {
    "text": "sure that the change actually went",
    "start": "1528880",
    "end": "1530159"
  },
  {
    "text": "through",
    "start": "1530159",
    "end": "1532480"
  },
  {
    "text": "so here i'm chatting with the bot again",
    "start": "1533840",
    "end": "1535919"
  },
  {
    "text": "and i say i run",
    "start": "1535919",
    "end": "1537039"
  },
  {
    "text": "into an issue with tune just like before",
    "start": "1537039",
    "end": "1543360"
  },
  {
    "text": "and we get another similar message",
    "start": "1543360",
    "end": "1545039"
  },
  {
    "text": "saying that this is probably a bug",
    "start": "1545039",
    "end": "1546400"
  },
  {
    "text": "report but this time we linked out to",
    "start": "1546400",
    "end": "1548400"
  },
  {
    "text": "the ray",
    "start": "1548400",
    "end": "1548880"
  },
  {
    "text": "issues page so it looks like our bug has",
    "start": "1548880",
    "end": "1551440"
  },
  {
    "text": "been solved",
    "start": "1551440",
    "end": "1552559"
  },
  {
    "text": "and we're able to update our deployment",
    "start": "1552559",
    "end": "1554240"
  },
  {
    "text": "with zero downtime",
    "start": "1554240",
    "end": "1556559"
  },
  {
    "text": "so to recap i was once again able to",
    "start": "1556559",
    "end": "1558640"
  },
  {
    "text": "build and test my application locally",
    "start": "1558640",
    "end": "1560640"
  },
  {
    "text": "and then deploy to any scale without any",
    "start": "1560640",
    "end": "1562799"
  },
  {
    "text": "code changes",
    "start": "1562799",
    "end": "1564080"
  },
  {
    "text": "i then set up a ci pipeline to deploy a",
    "start": "1564080",
    "end": "1566320"
  },
  {
    "text": "bug fix for my application with zero",
    "start": "1566320",
    "end": "1568240"
  },
  {
    "text": "downtime",
    "start": "1568240",
    "end": "1569520"
  },
  {
    "text": "as the application was running we were",
    "start": "1569520",
    "end": "1571360"
  },
  {
    "text": "able to monitor its health using",
    "start": "1571360",
    "end": "1573360"
  },
  {
    "text": "any skill provided monitoring tooling",
    "start": "1573360",
    "end": "1576400"
  },
  {
    "text": "ray and any scale provided a seamless",
    "start": "1576400",
    "end": "1578480"
  },
  {
    "text": "experience to build deploy",
    "start": "1578480",
    "end": "1580159"
  },
  {
    "text": "and operate this complex machine",
    "start": "1580159",
    "end": "1582000"
  },
  {
    "text": "learning application in production",
    "start": "1582000",
    "end": "1585279"
  },
  {
    "text": "i hope this demo has given you a sense",
    "start": "1585279",
    "end": "1587039"
  },
  {
    "text": "of what any skill has to offer",
    "start": "1587039",
    "end": "1589039"
  },
  {
    "text": "our mission is to provide the infinite",
    "start": "1589039",
    "end": "1590640"
  },
  {
    "text": "laptop experience and development",
    "start": "1590640",
    "end": "1592480"
  },
  {
    "text": "enabling developers to iterate quickly",
    "start": "1592480",
    "end": "1594480"
  },
  {
    "text": "while running on a cluster",
    "start": "1594480",
    "end": "1596000"
  },
  {
    "text": "and when it comes time to deploy to",
    "start": "1596000",
    "end": "1597440"
  },
  {
    "text": "production we want to make it seamless",
    "start": "1597440",
    "end": "1599440"
  },
  {
    "text": "to build resilient machine learning",
    "start": "1599440",
    "end": "1601120"
  },
  {
    "text": "based applications",
    "start": "1601120",
    "end": "1603679"
  },
  {
    "text": "if you'd like to learn more about the",
    "start": "1603679",
    "end": "1605039"
  },
  {
    "text": "any skill platform or get a deeper dive",
    "start": "1605039",
    "end": "1607520"
  },
  {
    "text": "on any of the features that you saw here",
    "start": "1607520",
    "end": "1609520"
  },
  {
    "text": "we're hosting live demos during the",
    "start": "1609520",
    "end": "1611200"
  },
  {
    "text": "networking and office hours both today",
    "start": "1611200",
    "end": "1613200"
  },
  {
    "text": "and tomorrow",
    "start": "1613200",
    "end": "1614080"
  },
  {
    "text": "be sure to stop by you can also drop",
    "start": "1614080",
    "end": "1616720"
  },
  {
    "text": "into the ray summit slack channel at any",
    "start": "1616720",
    "end": "1618559"
  },
  {
    "text": "time",
    "start": "1618559",
    "end": "1618960"
  },
  {
    "text": "with questions and finally as was",
    "start": "1618960",
    "end": "1621520"
  },
  {
    "text": "mentioned earlier the any skill platform",
    "start": "1621520",
    "end": "1623440"
  },
  {
    "text": "is currently in private beta",
    "start": "1623440",
    "end": "1625200"
  },
  {
    "text": "if you'd like to sign up for early",
    "start": "1625200",
    "end": "1626720"
  },
  {
    "text": "access please do so at anyscale.com",
    "start": "1626720",
    "end": "1630080"
  },
  {
    "text": "beta thank you",
    "start": "1630080",
    "end": "1634320"
  }
]
[
  {
    "text": "[Music]",
    "start": "580",
    "end": "2820"
  },
  {
    "text": "making the most of compute resources is",
    "start": "4080",
    "end": "6200"
  },
  {
    "text": "critical to reducing costs particularly",
    "start": "6200",
    "end": "8840"
  },
  {
    "text": "with Dynamic workloads where traffic",
    "start": "8840",
    "end": "10759"
  },
  {
    "text": "scales up and down over time such as",
    "start": "10759",
    "end": "13040"
  },
  {
    "text": "online model serving and inferencing one",
    "start": "13040",
    "end": "15320"
  },
  {
    "text": "of the key challenges around model",
    "start": "15320",
    "end": "16960"
  },
  {
    "text": "serving is known as resource",
    "start": "16960",
    "end": "19000"
  },
  {
    "text": "fragmentation resource fragmentation",
    "start": "19000",
    "end": "21240"
  },
  {
    "text": "occurs when scaling activities lead to",
    "start": "21240",
    "end": "23439"
  },
  {
    "text": "uneven resource utilization across nodes",
    "start": "23439",
    "end": "27000"
  },
  {
    "text": "let's walk through an example with Ray",
    "start": "27000",
    "end": "28720"
  },
  {
    "text": "in any scale Ray serve is the library",
    "start": "28720",
    "end": "31400"
  },
  {
    "text": "used for model serving one of the key",
    "start": "31400",
    "end": "33800"
  },
  {
    "text": "Concepts is a deployment which contains",
    "start": "33800",
    "end": "36000"
  },
  {
    "text": "business logic or an ml model to handle",
    "start": "36000",
    "end": "38200"
  },
  {
    "text": "incoming requests deployments can make",
    "start": "38200",
    "end": "40879"
  },
  {
    "text": "requests for certain resources in this",
    "start": "40879",
    "end": "43239"
  },
  {
    "text": "example the model requires four gpus",
    "start": "43239",
    "end": "46160"
  },
  {
    "text": "large language models like llama 3 may",
    "start": "46160",
    "end": "48399"
  },
  {
    "text": "need to use multiple gpus as part of",
    "start": "48399",
    "end": "50559"
  },
  {
    "text": "their deployment a single replica of",
    "start": "50559",
    "end": "52800"
  },
  {
    "text": "model A is assigned to node one a single",
    "start": "52800",
    "end": "56039"
  },
  {
    "text": "serve application can have multiple",
    "start": "56039",
    "end": "58000"
  },
  {
    "text": "deployments which handle incoming",
    "start": "58000",
    "end": "60120"
  },
  {
    "text": "requests independently allowing for",
    "start": "60120",
    "end": "62519"
  },
  {
    "text": "parallel processing and efficient",
    "start": "62519",
    "end": "64320"
  },
  {
    "text": "resource",
    "start": "64320",
    "end": "65920"
  },
  {
    "text": "utilization here we've added two more",
    "start": "65920",
    "end": "68040"
  },
  {
    "text": "models model B that needs two gpus and",
    "start": "68040",
    "end": "71680"
  },
  {
    "text": "model C that needs one GPU but will have",
    "start": "71680",
    "end": "74159"
  },
  {
    "text": "five replicas to scale up to meet",
    "start": "74159",
    "end": "76240"
  },
  {
    "text": "traffic when all of these models are",
    "start": "76240",
    "end": "78479"
  },
  {
    "text": "deployed we end up with one replica of",
    "start": "78479",
    "end": "80840"
  },
  {
    "text": "model a one replica of model B and five",
    "start": "80840",
    "end": "84240"
  },
  {
    "text": "replicas of model C to achieve this Ray",
    "start": "84240",
    "end": "87320"
  },
  {
    "text": "automatically deployed two nodes with",
    "start": "87320",
    "end": "89159"
  },
  {
    "text": "eight gpus each now resource",
    "start": "89159",
    "end": "91479"
  },
  {
    "text": "fragmentation may occur when traffic",
    "start": "91479",
    "end": "93320"
  },
  {
    "text": "decreases and models scale down in this",
    "start": "93320",
    "end": "95920"
  },
  {
    "text": "example Model A scales down to zero as",
    "start": "95920",
    "end": "98040"
  },
  {
    "text": "there's now no",
    "start": "98040",
    "end": "99200"
  },
  {
    "text": "traffic unfortunately this leaves us",
    "start": "99200",
    "end": "101840"
  },
  {
    "text": "with one replica of model B and five of",
    "start": "101840",
    "end": "104200"
  },
  {
    "text": "model C which can fit on one node but",
    "start": "104200",
    "end": "106960"
  },
  {
    "text": "are running on two leading to",
    "start": "106960",
    "end": "108840"
  },
  {
    "text": "underutilization and increased cost with",
    "start": "108840",
    "end": "111920"
  },
  {
    "text": "multiple models and varying resource",
    "start": "111920",
    "end": "113680"
  },
  {
    "text": "needs fragmentation is inevitable any",
    "start": "113680",
    "end": "116920"
  },
  {
    "text": "scale replica compaction addresses",
    "start": "116920",
    "end": "118960"
  },
  {
    "text": "resource fragmentation",
    "start": "118960",
    "end": "120640"
  },
  {
    "text": "ensuring the optimal usage of resources",
    "start": "120640",
    "end": "122799"
  },
  {
    "text": "for online inference applications any",
    "start": "122799",
    "end": "125159"
  },
  {
    "text": "scales replica compaction optimizes",
    "start": "125159",
    "end": "127600"
  },
  {
    "text": "resource use by consolidating replicas",
    "start": "127600",
    "end": "129840"
  },
  {
    "text": "into fewer nodes with zero downtime from",
    "start": "129840",
    "end": "133120"
  },
  {
    "text": "our example we can see how any scale",
    "start": "133120",
    "end": "135400"
  },
  {
    "text": "automatically has removed the extra node",
    "start": "135400",
    "end": "137680"
  },
  {
    "text": "and moved everything onto one node the",
    "start": "137680",
    "end": "140040"
  },
  {
    "text": "impact of replica compaction varies",
    "start": "140040",
    "end": "142000"
  },
  {
    "text": "widely depending on the distribution of",
    "start": "142000",
    "end": "143680"
  },
  {
    "text": "traffic number of deployments and",
    "start": "143680",
    "end": "146040"
  },
  {
    "text": "underlying instances in some cases it",
    "start": "146040",
    "end": "148800"
  },
  {
    "text": "can reduce cost by as much as 50% During",
    "start": "148800",
    "end": "151239"
  },
  {
    "text": "certain periods any scale replica",
    "start": "151239",
    "end": "153560"
  },
  {
    "text": "compaction is enabled by default when",
    "start": "153560",
    "end": "155480"
  },
  {
    "text": "running Ray serve applications on any",
    "start": "155480",
    "end": "157360"
  },
  {
    "text": "scale get started today and make sure",
    "start": "157360",
    "end": "159879"
  },
  {
    "text": "your applications run as efficiently as",
    "start": "159879",
    "end": "161800"
  },
  {
    "text": "possible",
    "start": "161800",
    "end": "164800"
  }
]
[
  {
    "text": "yeah thanks uh good afternoon uh welcome to this talk um today talk about like",
    "start": "4960",
    "end": "10719"
  },
  {
    "text": "building an agentic framework in sensara um I know agentic might mean many like",
    "start": "10719",
    "end": "15759"
  },
  {
    "text": "very different things to everyone but for us it refers to uh using LM to",
    "start": "15759",
    "end": "21160"
  },
  {
    "text": "automate the workflows So today we're going to talk about like three topics the first is what motivates us to adopt",
    "start": "21160",
    "end": "27320"
  },
  {
    "text": "an agent approach second um how we build one and with the focus on",
    "start": "27320",
    "end": "32758"
  },
  {
    "text": "the knowledge based chatot and lastly um how Ray helps us to um build a flywheel",
    "start": "32759",
    "end": "37960"
  },
  {
    "text": "driven by the customer feedback oh speakers uh my name is Yong",
    "start": "37960",
    "end": "44320"
  },
  {
    "text": "uh and I'm a machine Engineers from sens AI team today I'm like joined with um Sven and Brian by my",
    "start": "44320",
    "end": "52440"
  },
  {
    "text": "colleagues so let me firstly introduce about sensera U what our mission is and",
    "start": "52440",
    "end": "58440"
  },
  {
    "text": "what do we do as a company um as in Era our goal is to help our customers to increase safety efficiency",
    "start": "58440",
    "end": "64799"
  },
  {
    "text": "and sustainability of their physical operations and I know you're now wondering what do you mean by physical",
    "start": "64799",
    "end": "71920"
  },
  {
    "text": "operations so here we're talking about a wide range of like Industries uh from Transportation Public Safety um oil and",
    "start": "71920",
    "end": "79560"
  },
  {
    "text": "gas to Agriculture and others so they're usually uh very labor intensive and",
    "start": "79560",
    "end": "85119"
  },
  {
    "text": "assets heavy um so meaning many people are working working on many different",
    "start": "85119",
    "end": "90880"
  },
  {
    "text": "equipments and devices which naturally involves a lot of the manual workflows for instance like for companies uh in",
    "start": "90880",
    "end": "97320"
  },
  {
    "text": "transportation their daily uh routine jobs could be making sure the trucks can",
    "start": "97320",
    "end": "102399"
  },
  {
    "text": "deliver goods from A to B safely and on time uh to do that you'll be working with like truck drivers mechanics",
    "start": "102399",
    "end": "109119"
  },
  {
    "text": "workers to load and unload cargo dispatcher Fleet mm like Fleet admin and",
    "start": "109119",
    "end": "114840"
  },
  {
    "text": "then you will have like trucks trailers uh forklifts and other assets to making sure the whole process can run smoothly",
    "start": "114840",
    "end": "122680"
  },
  {
    "text": "this indeed is a very uh complex chain of operations that we hope to help our",
    "start": "122680",
    "end": "128000"
  },
  {
    "text": "customer optimize so all these industries together with u hundreds of U",
    "start": "128000",
    "end": "134080"
  },
  {
    "text": "millions of Frontline workers that's more than 40% of the world GDP um as you",
    "start": "134080",
    "end": "139239"
  },
  {
    "text": "can imagine any improvements or cost savings that we could do means a",
    "start": "139239",
    "end": "145040"
  },
  {
    "text": "lot um great so how does sensor achieve to go uh first off we build a platform",
    "start": "145040",
    "end": "152560"
  },
  {
    "text": "named connected op Cloud to help our customer digitize and automate workflows",
    "start": "152560",
    "end": "158440"
  },
  {
    "text": "uh we start by collecting various operational data from The Edge devices such as uh sensors dash cam sensors",
    "start": "158440",
    "end": "165440"
  },
  {
    "text": "vehicle gateways and other iot devices and these datas are transported",
    "start": "165440",
    "end": "170680"
  },
  {
    "text": "to the cloud this allows our customers to access and act on these data through",
    "start": "170680",
    "end": "175760"
  },
  {
    "text": "our dashboard um and also gaining real the real time uh operational insights on",
    "start": "175760",
    "end": "182040"
  },
  {
    "text": "top of these we also provide integrated AI experience for instance our AI dash",
    "start": "182040",
    "end": "188879"
  },
  {
    "text": "cam is able to detect um different kinds of AI events like the driver drowsiness",
    "start": "188879",
    "end": "193920"
  },
  {
    "text": "you can see here um and the D like say the dangerous like driver behaviors like rolling stop signs uh tailgating and the",
    "start": "193920",
    "end": "201920"
  },
  {
    "text": "fleet admins can provide proper like training and coaching accordingly to",
    "start": "201920",
    "end": "206959"
  },
  {
    "text": "summarize uh we help our customers uh digitize their operational data make it",
    "start": "206959",
    "end": "212040"
  },
  {
    "text": "easily accessible and providing actionable insights that can helps them optimize their",
    "start": "212040",
    "end": "218720"
  },
  {
    "text": "operations um but there are challenges uh to operate in large scale like we do",
    "start": "219000",
    "end": "225159"
  },
  {
    "text": "um our customers are from like very very like different background and they're from different Industries and they could",
    "start": "225159",
    "end": "231920"
  },
  {
    "text": "be speaking very different languages because they they're like from different regions um and the data they're trying",
    "start": "231920",
    "end": "239040"
  },
  {
    "text": "to access can range from the like device configurations to image like audio uh",
    "start": "239040",
    "end": "245200"
  },
  {
    "text": "videos and inspection reports or other types of data so as a result um there",
    "start": "245200",
    "end": "251560"
  },
  {
    "text": "are many different kinds of like customer needs which leads to a lot of like customer support tickets and costs",
    "start": "251560",
    "end": "258280"
  },
  {
    "text": "which can be quite costly um and we're not even talking about like the",
    "start": "258280",
    "end": "263320"
  },
  {
    "text": "customizations and the new feature requests so not surprisingly we saw like",
    "start": "263320",
    "end": "269840"
  },
  {
    "text": "M can help us to address at least part of the like problems um but simple LM",
    "start": "269840",
    "end": "275840"
  },
  {
    "text": "integration doesn't really work um in our case we have a lot of domain specific knowledge and data and",
    "start": "275840",
    "end": "282520"
  },
  {
    "text": "oftentimes it's private um and they're being like updated very frequently and",
    "start": "282520",
    "end": "287840"
  },
  {
    "text": "still growing which is now like trillion level uh and LM doesn't really know so",
    "start": "287840",
    "end": "293759"
  },
  {
    "text": "rag become our Top Choice uh we start to like we started to build an agented framework to test out different options",
    "start": "293759",
    "end": "300680"
  },
  {
    "text": "and uh try to integrate the whole like data that we have um but we do want to",
    "start": "300680",
    "end": "306320"
  },
  {
    "text": "start simple uh so with the help of the Llama index we are able to get a r not based",
    "start": "306320",
    "end": "312840"
  },
  {
    "text": "chatot up and running in just a few days and right now this chout has been already like being used by a small group",
    "start": "312840",
    "end": "319400"
  },
  {
    "text": "of customers and they're happy with it um but that's not it right we're also",
    "start": "319400",
    "end": "325840"
  },
  {
    "text": "trying to explore areas like uh image video search the real data queries and",
    "start": "325840",
    "end": "331400"
  },
  {
    "text": "other ways to use LM to connect your customer data um now the big question is",
    "start": "331400",
    "end": "337560"
  },
  {
    "text": "how do we keep moving fast while making sure we're building the right products for our customer our answer is to build a",
    "start": "337560",
    "end": "344479"
  },
  {
    "text": "flywheel it's a flywheel driven by the customer feedback in high level there are a few key components here first we",
    "start": "344479",
    "end": "351600"
  },
  {
    "text": "need to really build a extensive tracing capabilities that not only records whatever our customer trying to do with",
    "start": "351600",
    "end": "358000"
  },
  {
    "text": "our chat Bots but also collect the customer feedback for future triage then we can decide what's the",
    "start": "358000",
    "end": "364680"
  },
  {
    "text": "next new feature we want to build and then build them fast um and all these",
    "start": "364680",
    "end": "369759"
  },
  {
    "text": "new features are then being rolled out to to your customer with proper Evo and gading and in this flly will you can see",
    "start": "369759",
    "end": "377120"
  },
  {
    "text": "like Ray plays a very critical role to enable us to do the automated like eval and the feedback Mining and in the next",
    "start": "377120",
    "end": "384960"
  },
  {
    "text": "like two sessions we will talk more about that so next hand over to",
    "start": "384960",
    "end": "392360"
  },
  {
    "text": "Sven all right thank you I'm Sven applied scientist I've been working on the chatbot agent and I want to talk",
    "start": "392360",
    "end": "398639"
  },
  {
    "text": "about some of the challenges we ran into oh did I press the wrong button are we",
    "start": "398639",
    "end": "405680"
  },
  {
    "text": "off okay maybe I can go on while a figures this out so building a chatbot agent is actually quite simple um you",
    "start": "407160",
    "end": "414120"
  },
  {
    "text": "you just put some prompt into chat GPT say you are some SAR chatboard now and it kind of works and it's an impressive",
    "start": "414120",
    "end": "420000"
  },
  {
    "text": "demo and um unfortunately okay so unfortunately it",
    "start": "420000",
    "end": "426599"
  },
  {
    "text": "it works kind of deceptively easily for a few demo use cases but it doesn't really um scale so once you want to add",
    "start": "426599",
    "end": "434440"
  },
  {
    "text": "more use case let's say you want your customers to fetch their personal data you want the customers to um to cry",
    "start": "434440",
    "end": "439479"
  },
  {
    "text": "information about samsara you want to ask them about um okay let's say I have",
    "start": "439479",
    "end": "444759"
  },
  {
    "text": "a specific vehicle Gateway how do I connect this to my drive and so on you run into all these problems that llms",
    "start": "444759",
    "end": "450039"
  },
  {
    "text": "have um hallucinations and um just uh taking data from the wrong database and",
    "start": "450039",
    "end": "456000"
  },
  {
    "text": "so on so how do we address this and I want to give a simple example",
    "start": "456000",
    "end": "461800"
  },
  {
    "text": "here how you might start out with this chat booot so you say hey I take just let's say clo or gp4 plus my system prom",
    "start": "461800",
    "end": "468000"
  },
  {
    "text": "that says if a customer asks for sales here's the number you should give them if a customer carries the data here has",
    "start": "468000",
    "end": "474000"
  },
  {
    "text": "a function you should call and here has the Json payload for it and so on and we would start out with this and say that's wonderful these models are so powerful",
    "start": "474000",
    "end": "480720"
  },
  {
    "text": "we just tell them what to do and it works and as it turns out it it works for a quick demo but then once you give",
    "start": "480720",
    "end": "486199"
  },
  {
    "text": "it to extra customers no you run into these problems",
    "start": "486199",
    "end": "492199"
  },
  {
    "text": "so customer asked where do I get a new cable and the model kind of hallucinates something between the capabilities like",
    "start": "492199",
    "end": "497680"
  },
  {
    "text": "here's customer support and here's the Json you have to give them which is I'm not sure exactly why this happened but",
    "start": "497680",
    "end": "503120"
  },
  {
    "text": "it did happen and it was uh it's kind of funny for us but then our customers are they're not really Tech nerds they are",
    "start": "503120",
    "end": "509039"
  },
  {
    "text": "like drivers and they are um they are Fleet managers and they yeah they might not find this as funny so what do we do",
    "start": "509039",
    "end": "517000"
  },
  {
    "text": "with this and really the way we approach this now is this what we might call this agentic framework we um we Chun this",
    "start": "517000",
    "end": "524720"
  },
  {
    "text": "problem down we say whenever we say something like if customer does X follow this path of Y if they do y then then do",
    "start": "524720",
    "end": "532240"
  },
  {
    "text": "Z and so on um we turn we turn that into sort of a graph where we say we take the",
    "start": "532240",
    "end": "538399"
  },
  {
    "text": "decisions out and into separate models and these models don't have to be large language models although of course they can be they can be fine tune models",
    "start": "538399",
    "end": "545040"
  },
  {
    "text": "where you just take an llm and put some kind of um fine-tuned head on top but uh the point is you separate the decision",
    "start": "545040",
    "end": "551640"
  },
  {
    "text": "from the actual promts that don't follow up on these decisions and this works really well for um when your chatboard",
    "start": "551640",
    "end": "557560"
  },
  {
    "text": "has many different capabilities such as okay there's knowledge based queries and then there's data queries and also and",
    "start": "557560",
    "end": "563600"
  },
  {
    "text": "it's relatively easy to determine which which direction should this go now it does the downside as well and that is",
    "start": "563600",
    "end": "569920"
  },
  {
    "text": "ambiguity and of course now with um going away from this simple prompt you",
    "start": "569920",
    "end": "575120"
  },
  {
    "text": "lose some of the flexibility of the chatbot to kind of infer between these domains and we noticed that first when",
    "start": "575120",
    "end": "580600"
  },
  {
    "text": "we launched this chatbot to act customers they they wouldn't type in these nice questions that we could just classify but they would just type in",
    "start": "580600",
    "end": "587360"
  },
  {
    "text": "keywords um so what do we do if they type in Fleet utilization okay that's kind of a very common thing to ask for",
    "start": "587360",
    "end": "594079"
  },
  {
    "text": "samsara uh but it could mean that they they want to ask the knowledge base how do we compute that what does it even",
    "start": "594079",
    "end": "599120"
  },
  {
    "text": "mean and your context they could ask for their data maybe they ask for where to find the report that list that and these",
    "start": "599120",
    "end": "605560"
  },
  {
    "text": "are all Pathways in the llm but then okay how do we choose do we just choose one and then hope that the luck of the",
    "start": "605560",
    "end": "611680"
  },
  {
    "text": "draw gets it and then maybe um hope the customer ask again if they want to have something else but um the way we do this",
    "start": "611680",
    "end": "618200"
  },
  {
    "text": "is through parallel execution the idea is that when you type in a prompt you don't necessarily know yet what will",
    "start": "618200",
    "end": "624959"
  },
  {
    "text": "this will be like even you use an LM that says okay whenever customer is in this domain do this in that domain do",
    "start": "624959",
    "end": "630680"
  },
  {
    "text": "that you will always have these ambigious cases so instead of just um making a decision preemptively we say",
    "start": "630680",
    "end": "636360"
  },
  {
    "text": "hey uh let's just run all these agents in parallel let's let's always just querry all knowledge base see if there's",
    "start": "636360",
    "end": "642240"
  },
  {
    "text": "something about utilization and then afterwards we can say hey okay there was something in there that's a pathway that made sense and the same with data query",
    "start": "642240",
    "end": "648360"
  },
  {
    "text": "handlers there may be some data available there might be no data available but we don't really know",
    "start": "648360",
    "end": "653600"
  },
  {
    "text": "unless we went under that expert model once you have that expert model output you take the output and you can take something like a probability with it so",
    "start": "653600",
    "end": "659680"
  },
  {
    "text": "you know how confident you are and then you have to run a synthesizer step and that synthesizer that may do different things for example if you say okay",
    "start": "659680",
    "end": "666079"
  },
  {
    "text": "there's two pretty likely Pathways maybe I give a summary of each and then let the customer decide have say okay which",
    "start": "666079",
    "end": "672240"
  },
  {
    "text": "one did you mean or maybe I just say Okay um I I just asked him the question or maybe none of the pathways matched",
    "start": "672240",
    "end": "678440"
  },
  {
    "text": "and then you have some kind of fallback answer so then you can be really flexible but you can be uh flexible at this step after knowing okay how much",
    "start": "678440",
    "end": "684760"
  },
  {
    "text": "was there actually for each and obviously the other Advantage is you can really nicely parall ize this you could",
    "start": "684760",
    "end": "690200"
  },
  {
    "text": "run this on Ray or you can um have different expert on this that that have very different computer",
    "start": "690200",
    "end": "696480"
  },
  {
    "text": "requirements so another interesting thing that came up was multilingual because our customers come from all over",
    "start": "696480",
    "end": "702880"
  },
  {
    "text": "the world we have a lot in Europe now we have some Mexican customers and so um it's nice if the chatbot speaks their",
    "start": "702880",
    "end": "708560"
  },
  {
    "text": "language and the again the deceptively dangerous part of lmm is they kind of",
    "start": "708560",
    "end": "713959"
  },
  {
    "text": "work if you type into chat GPD something in Spanish it an in Spanish and same thing with our chatbot we put it on",
    "start": "713959",
    "end": "719760"
  },
  {
    "text": "let's say you put on clo and you put a prompt in between and then you say customer ask in Spanish usually it comes",
    "start": "719760",
    "end": "725160"
  },
  {
    "text": "out in Spanish but the key here is it's usually and not always and it's also not",
    "start": "725160",
    "end": "730680"
  },
  {
    "text": "always the complete answer so I have a German one here I'm SP going to spare the German here but basically it's mixed",
    "start": "730680",
    "end": "736959"
  },
  {
    "text": "within languages and this is actually quite common with llms because llms when when you're um you're prompt and the",
    "start": "736959",
    "end": "742839"
  },
  {
    "text": "let's say the rack notes and the documents you pull in that come from different languages uh this attention to",
    "start": "742839",
    "end": "748560"
  },
  {
    "text": "different parts of of the prompt will cause the model to switch the language so the key here is really that we have",
    "start": "748560",
    "end": "753720"
  },
  {
    "text": "to be explicit about asking which language do we want we don't just rely on llms to figure out what the customer",
    "start": "753720",
    "end": "760240"
  },
  {
    "text": "probably wants and the way we do that is by early language detector and that early detector that really just runs on",
    "start": "760240",
    "end": "766079"
  },
  {
    "text": "the initial prompt what language could this be it's just a classifier plus we can take into account the user settings",
    "start": "766079",
    "end": "771800"
  },
  {
    "text": "so if this not really clear because just a keyword like vg34 we would just fall back let's say to the users language and",
    "start": "771800",
    "end": "777839"
  },
  {
    "text": "once this language is detected we pass that into every single agent for example there's a knowledge based agent with the",
    "start": "777839",
    "end": "783079"
  },
  {
    "text": "r database that R database has localized articles so we just pull these there might be a data agent that pulls data",
    "start": "783079",
    "end": "788399"
  },
  {
    "text": "but that data is only in English that's fine we take the data plus we added a helper prompt saying okay but the answer should be in Spanish and that really",
    "start": "788399",
    "end": "794560"
  },
  {
    "text": "helps to um to really solidify the answer in in the correct",
    "start": "794560",
    "end": "799639"
  },
  {
    "text": "language now the last challenge I want to talk about is evaluation and people",
    "start": "799639",
    "end": "804880"
  },
  {
    "text": "always talk about eval and yeah we have to eval our um models and we have to run our our flight wheel and we have to make",
    "start": "804880",
    "end": "810240"
  },
  {
    "text": "sure that um we always raising the bar improving the performance but actually a big problem for the chatbot is to really",
    "start": "810240",
    "end": "816639"
  },
  {
    "text": "Define what what is good performance and it can be quite deceiving again if you get a cat GPT typical answer or some",
    "start": "816639",
    "end": "823160"
  },
  {
    "text": "some kind of Lama answer that sounds nice and even our customers sometimes they oh it's such a detailed answer but",
    "start": "823160",
    "end": "828920"
  },
  {
    "text": "then you go into it and realize hey but it didn't really help them with a question because the key here is when we build our chatbots for our customers we",
    "start": "828920",
    "end": "835959"
  },
  {
    "text": "have very very ssar specific requirements for what a good answer should be uh here's an example how to add an admin",
    "start": "835959",
    "end": "841360"
  },
  {
    "text": "to the site and and there's kind of a Wikipedia style answer to this and that's kind of bad because sure if you",
    "start": "841360",
    "end": "847480"
  },
  {
    "text": "want to learn about admins in general like what is an admin that might be useful maybe some customers like that",
    "start": "847480",
    "end": "854360"
  },
  {
    "text": "but um we know actually there's some very specific requirements that come from from our domain and the experts on",
    "start": "854360",
    "end": "861120"
  },
  {
    "text": "this domain are our customer support agents they are the people who answer phone calls today the people who help the customers who help them by email",
    "start": "861120",
    "end": "867519"
  },
  {
    "text": "help them through support tickets and we reach out to them and we ask them hey people who ask this like what should",
    "start": "867519",
    "end": "873399"
  },
  {
    "text": "they uh what should the answer be and we uh we went through our own knowledge base and we said okay here look these",
    "start": "873399",
    "end": "878800"
  },
  {
    "text": "are the Articles what do we normally answer and then we constructed this um this super detailed and and um an highly",
    "start": "878800",
    "end": "886240"
  },
  {
    "text": "specific fast data set that that contains requirements so we don't say okay this is a good answer but we say a",
    "start": "886240",
    "end": "892440"
  },
  {
    "text": "good answer to this question how do I add an admin to the side in this example is it should mention that there's two",
    "start": "892440",
    "end": "897560"
  },
  {
    "text": "admin types it should me mention that this is the page you should go to for more information it should mention that here this is the path and the settings",
    "start": "897560",
    "end": "903880"
  },
  {
    "text": "you should click through and then these become our requirements and we just judge our data and our outputs based on",
    "start": "903880",
    "end": "909040"
  },
  {
    "text": "how many of these requirements are met and the other advantage of this is compared to for example having an llm judge this is a very stable measure",
    "start": "909040",
    "end": "915600"
  },
  {
    "text": "because if you have a very concrete question does it mention two admin types yes or no that's something we can uh",
    "start": "915600",
    "end": "921720"
  },
  {
    "text": "answer pretty correctly with pretty high reliability so you don't have this problem that your evaluator itself um",
    "start": "921720",
    "end": "928360"
  },
  {
    "text": "has noise in and basically goes up and down depending on how you run it and which model you",
    "start": "928360",
    "end": "933639"
  },
  {
    "text": "use and with that I want to pass it on to our engineer for how we actually bu",
    "start": "933639",
    "end": "939279"
  },
  {
    "text": "this cool thanks everybody for attending I'm Brian Westfall and I'm an infrastructure machine learning engineer",
    "start": "939279",
    "end": "945800"
  },
  {
    "text": "on the team and I'll be covering how we designed the architecture and systems of our flywell to drive rapid development",
    "start": "945800",
    "end": "951759"
  },
  {
    "text": "so I'll be going over our iterative architecture the tracing Centric stack",
    "start": "951759",
    "end": "956839"
  },
  {
    "text": "and some feedback and insights that we've had on veloping a chat product I hope that this is like practical",
    "start": "956839",
    "end": "962399"
  },
  {
    "text": "information if you're looking to build a chat bot you can Implement some of this so let's talk about our iterative",
    "start": "962399",
    "end": "969040"
  },
  {
    "text": "architecture so the flywheel is built on a system architecture that is designed for iterative development so we maintain",
    "start": "969040",
    "end": "975959"
  },
  {
    "text": "these tenants in our approach to designing our framework so the first tenant is that we encourage",
    "start": "975959",
    "end": "981040"
  },
  {
    "text": "experimentation by enabling rapid development being fast allows us to keep up with the latest developments in the",
    "start": "981040",
    "end": "987440"
  },
  {
    "text": "AI space and innovate on on new product Solutions so thanks to this approach",
    "start": "987440",
    "end": "992480"
  },
  {
    "text": "we're able to deploy first versions of products uh directly in our application in a matter of days the second tenant is",
    "start": "992480",
    "end": "1000319"
  },
  {
    "text": "that we use a modular design with clear reusable components it's important to Define these uh architecture components",
    "start": "1000319",
    "end": "1007360"
  },
  {
    "text": "up front to establish interface boundaries such as the intent classifier agent API data connectors such that you",
    "start": "1007360",
    "end": "1014480"
  },
  {
    "text": "can work on each independently I know that this is pretty standard engineer ing practice but at the rate that we",
    "start": "1014480",
    "end": "1020920"
  },
  {
    "text": "want to deploy AI prototypes makes this a first class consideration uh when",
    "start": "1020920",
    "end": "1026640"
  },
  {
    "text": "you're designing your software so having a flexible system with common interfaces allows you to easily Test new options",
    "start": "1026640",
    "end": "1034038"
  },
  {
    "text": "and design for specific use cases uh good example of this modularity is in",
    "start": "1034039",
    "end": "1039240"
  },
  {
    "text": "constructing an agent interface just for starters so we use a mix of In-House",
    "start": "1039240",
    "end": "1044760"
  },
  {
    "text": "components uh for new agents and services but we're also flexible to to try out you know new thirdparty",
    "start": "1044760",
    "end": "1051039"
  },
  {
    "text": "libraries like llama index Lane chain Etc uh to quickly bootstrap Solutions we",
    "start": "1051039",
    "end": "1056720"
  },
  {
    "text": "do this all the time I'm sure everybody gets asked in here you know hey can you I heard about this new uh you know chat",
    "start": "1056720",
    "end": "1063400"
  },
  {
    "text": "LM stuff can you go quickly develop it for me uh this is like how we're building our software with this in mind",
    "start": "1063400",
    "end": "1070400"
  },
  {
    "text": "um another way defining system boundaries is important is in configuring models invoked and their",
    "start": "1070400",
    "end": "1076120"
  },
  {
    "text": "respected parameters such as prompts Etc um for example this allows us to e",
    "start": "1076120",
    "end": "1081440"
  },
  {
    "text": "easily pivot between you know using race serve as compute for hosting agents to execute open source models or we can",
    "start": "1081440",
    "end": "1088679"
  },
  {
    "text": "quickly switch between running a vendor such as open Ai and as we all know uh there's a new latest and greatest model",
    "start": "1088679",
    "end": "1095039"
  },
  {
    "text": "every week to try out so you want to be able to hot swap those uh the third tenant here is that our rollouts are",
    "start": "1095039",
    "end": "1101480"
  },
  {
    "text": "fully controllable for Speed and flexibility we target specific users in",
    "start": "1101480",
    "end": "1107000"
  },
  {
    "text": "our application to trial new features and agent configurations to gather feedback while minimizing the risk to",
    "start": "1107000",
    "end": "1113120"
  },
  {
    "text": "the main user base and to facilitate this our infrastructure is easily replicable and deployed with simple",
    "start": "1113120",
    "end": "1119679"
  },
  {
    "text": "controls to conduct roll outs between the experimental and the main production environments so in this diagram um over",
    "start": "1119679",
    "end": "1127039"
  },
  {
    "text": "here on the right I've shown just two environments but in reality we run over",
    "start": "1127039",
    "end": "1133480"
  },
  {
    "text": "a dozen different environments from a single source codebase and we have fine graen control over the features and",
    "start": "1133480",
    "end": "1140360"
  },
  {
    "text": "configured parameters in them to try things out um so at ssara we have an",
    "start": "1140360",
    "end": "1145880"
  },
  {
    "text": "operating principle uh that's we always want to sample the customer experience",
    "start": "1145880",
    "end": "1151559"
  },
  {
    "text": "so developers are encouraged to have their own environments where they able to easily test out new new things in the",
    "start": "1151559",
    "end": "1158799"
  },
  {
    "text": "real endtoend product and on top of that we have several dedicated deployments just for",
    "start": "1158799",
    "end": "1164640"
  },
  {
    "text": "beta customers trying out new things so we can gather feedback as well as just dedic dedicated feature demos like image",
    "start": "1164640",
    "end": "1170520"
  },
  {
    "text": "search for example and The Last Tenant here number four is that uh all development",
    "start": "1170520",
    "end": "1177320"
  },
  {
    "text": "prioritization is driven based on insights we receive from feedback throughout the app and measurement",
    "start": "1177320",
    "end": "1182640"
  },
  {
    "text": "through our systems so we treat measurement as a first class consideration and I'll speak about more",
    "start": "1182640",
    "end": "1188440"
  },
  {
    "text": "how we handle this in the next slides so tracing tracing is the",
    "start": "1188440",
    "end": "1195200"
  },
  {
    "text": "backbone of our feedback loop on the right here you can see some example traces of the data collect we collect in",
    "start": "1195200",
    "end": "1201440"
  },
  {
    "text": "our chatbot this data includes the contents of our chats for analysis as well as direct feedback like thumbs up",
    "start": "1201440",
    "end": "1208400"
  },
  {
    "text": "thumbs down and free form feedback like how are we doing like why didn't this chat help you um we also include the",
    "start": "1208400",
    "end": "1215120"
  },
  {
    "text": "user context which lets us like revisit the scenario which uh the user",
    "start": "1215120",
    "end": "1220440"
  },
  {
    "text": "approached our chat for example like what what page are they on like what are they looking at what do they need help",
    "start": "1220440",
    "end": "1225760"
  },
  {
    "text": "with what's open on the page there's a lot like metadata contextual things you",
    "start": "1225760",
    "end": "1230919"
  },
  {
    "text": "can add to your ux to help you kind of understand and you know sympathize more with your customers and all this plays a",
    "start": "1230919",
    "end": "1238360"
  },
  {
    "text": "key role when you go back and you're debugging and trying to figure out you know what's going on um why didn't",
    "start": "1238360",
    "end": "1243760"
  },
  {
    "text": "things perform as expected in addition uh this Trace data in aggregate is also used for just",
    "start": "1243760",
    "end": "1251000"
  },
  {
    "text": "prioritizing system improvements for example you know uh tracing we're measuring latency throughout all of our",
    "start": "1251000",
    "end": "1257520"
  },
  {
    "text": "agentic call chain and it lets us know like when we're um need to optimize any of those flows like",
    "start": "1257520",
    "end": "1263200"
  },
  {
    "text": "if any of them are performing slow Etc um in addition to this uh you also",
    "start": "1263200",
    "end": "1268840"
  },
  {
    "text": "probably want to instrument tracing to uh track your spend with all vendors uh",
    "start": "1268840",
    "end": "1273960"
  },
  {
    "text": "because you know it can rack up over time and next I'll talk about how we integrated this into our",
    "start": "1273960",
    "end": "1281400"
  },
  {
    "text": "framework so this is our tracing Centric stack uh tracing and measurement is",
    "start": "1282960",
    "end": "1288200"
  },
  {
    "text": "really as I mentioned like the central part of our stack so all agent components are integrated with callbacks",
    "start": "1288200",
    "end": "1294200"
  },
  {
    "text": "to our trace and measurement systems to capture the results of each step the latency and any contextual meta metadata",
    "start": "1294200",
    "end": "1301600"
  },
  {
    "text": "that we might might need later for like debugging purposes uh this provides us granular insights over the entire flow",
    "start": "1301600",
    "end": "1308360"
  },
  {
    "text": "of the system such as you know the user text query embedding step data retrieval",
    "start": "1308360",
    "end": "1313679"
  },
  {
    "text": "steps such as Rag and internal llm turns of which if you have an agent framework",
    "start": "1313679",
    "end": "1319039"
  },
  {
    "text": "you might have multiple going on and they're not always present to the user uh but you might want to go in and see",
    "start": "1319039",
    "end": "1324080"
  },
  {
    "text": "what they were doing inside later and as mentioned in the slides uh the tool we use for this tracing is link fuse and",
    "start": "1324080",
    "end": "1331200"
  },
  {
    "text": "this is really the central store of all our data and we use this to export um all the contents of the chats later for",
    "start": "1331200",
    "end": "1338360"
  },
  {
    "text": "offline um tasks such as analytics and evals which I'll cover",
    "start": "1338360",
    "end": "1344559"
  },
  {
    "text": "next so let's dive into How We Gather feedback so the driver of our flywheel",
    "start": "1344559",
    "end": "1350520"
  },
  {
    "text": "is the feedback that we we receive so we encourage users to provide feedback in many forms uh such as tracking UI",
    "start": "1350520",
    "end": "1358080"
  },
  {
    "text": "interactions and also nudging them for um you know thumbs UPS thumbs down free form type feedback and we closely",
    "start": "1358080",
    "end": "1365120"
  },
  {
    "text": "monitor these engagements uh to see you know whether um they're going through",
    "start": "1365120",
    "end": "1370480"
  },
  {
    "text": "the steps as intended did things break what are our conversion rates etc for the new features that we're hoping to",
    "start": "1370480",
    "end": "1376919"
  },
  {
    "text": "see however when ites com to getting feedback on your product uh nothing really beats kind of like the manual",
    "start": "1376919",
    "end": "1383880"
  },
  {
    "text": "approach honestly uh it's really important to like step in and see like qualitatively like after you gather",
    "start": "1383880",
    "end": "1391520"
  },
  {
    "text": "these traces like what's really going on uh if I was doing this if I retrace the steps is this really solving the",
    "start": "1391520",
    "end": "1397559"
  },
  {
    "text": "customer concern here um like the old saying do things that don't scale if you talk to your users and just ask them in",
    "start": "1397559",
    "end": "1404279"
  },
  {
    "text": "a zoom interview you'll learn a lot more about the qualitative response um but of",
    "start": "1404279",
    "end": "1409360"
  },
  {
    "text": "course you know you want to do things quantitatively as much as you can so instrument all the typical UI metrics",
    "start": "1409360",
    "end": "1416799"
  },
  {
    "text": "here and when it comes to processing this feedback uh all the DAT data points as I mentioned are collected into our",
    "start": "1416799",
    "end": "1423279"
  },
  {
    "text": "data lake so ux analytics Lane fuse data and we have multiple Ray jobs uh that",
    "start": "1423279",
    "end": "1428880"
  },
  {
    "text": "run on several Ray clusters to pull this data and perform different tasks so you can do all kinds of things with LMS",
    "start": "1428880",
    "end": "1434360"
  },
  {
    "text": "nowadays like summarization of feedback what kind of things were people asking about about um what were the failure",
    "start": "1434360",
    "end": "1440279"
  },
  {
    "text": "modes um they can help you summarize these things so you can scale it up so when you're developing AI systems",
    "start": "1440279",
    "end": "1446760"
  },
  {
    "text": "quickly there's also a really strong demand to run evals to test new approaches and to prevent regressions so",
    "start": "1446760",
    "end": "1454159"
  },
  {
    "text": "to cover this demand we built an eval engine on top of Ray clusters um so yeah Ray is really we",
    "start": "1454159",
    "end": "1460840"
  },
  {
    "text": "think like the perfect tool to just Outsource this kind of complexity of coordinating the distributed compute",
    "start": "1460840",
    "end": "1467080"
  },
  {
    "text": "workloads uh that would normally be required it's just really simple to spin up a you know a new job hey somebody",
    "start": "1467080",
    "end": "1473880"
  },
  {
    "text": "wants to run an EVO okay boom fire it off um so we have this instrumented with dagster as our or orchestration system",
    "start": "1473880",
    "end": "1481360"
  },
  {
    "text": "um which spins up Ray clusters um and this is really really important to help",
    "start": "1481360",
    "end": "1486720"
  },
  {
    "text": "you just you know speed up your own iteration Cycles because the more feed evals you run the more confidence you",
    "start": "1486720",
    "end": "1493039"
  },
  {
    "text": "have in making your changes and we're also in the process of adding Ray tune uh to to conduct",
    "start": "1493039",
    "end": "1498799"
  },
  {
    "text": "parameter search to find the best configurations for our tasks uh this goes beyond the typical hyperparameter",
    "start": "1498799",
    "end": "1504600"
  },
  {
    "text": "search uh in an agentic framework this might include like you know trying out different prompts different combinations",
    "start": "1504600",
    "end": "1510840"
  },
  {
    "text": "of models different flows and different versions of data just to name a",
    "start": "1510840",
    "end": "1517320"
  },
  {
    "text": "few so I want to talk about some of the insights that we've had developing a chat product so if you are developing",
    "start": "1517799",
    "end": "1523880"
  },
  {
    "text": "your own hopefully you can learn from this so we found some pretty common themes that influence our feature",
    "start": "1523880",
    "end": "1529720"
  },
  {
    "text": "building decisions um so the first thing is like you know why are customers using a",
    "start": "1529720",
    "end": "1535880"
  },
  {
    "text": "chatbot why do they find it so helpful so we're developing a software as a service product and often you know these",
    "start": "1535880",
    "end": "1542360"
  },
  {
    "text": "tools take some training to learn um and we found that customers are often just asking you know where the heck is the",
    "start": "1542360",
    "end": "1549240"
  },
  {
    "text": "page that does this or can you just quickly get me the data for this um so in samsar apps uh we found that this",
    "start": "1549240",
    "end": "1557440"
  },
  {
    "text": "this could just be something like okay where's this vehicle where's who's driving it Etc um having these like",
    "start": "1557440",
    "end": "1563159"
  },
  {
    "text": "really quick um modes of like hey let me just talk to my data are really important so this is these are some of",
    "start": "1563159",
    "end": "1569279"
  },
  {
    "text": "the features we're thinking about building um when it came to unexpected findings uh we were pretty surprised to",
    "start": "1569279",
    "end": "1575720"
  },
  {
    "text": "learn that customers uh were happy with like long- winded answers uh that",
    "start": "1575720",
    "end": "1580919"
  },
  {
    "text": "provided a lot of detail even though like initially we thought oh no like our key metrics have to be that our latency",
    "start": "1580919",
    "end": "1587600"
  },
  {
    "text": "is under a certain amount no customers actually liked uh when they got the the info that they needed um which plays",
    "start": "1587600",
    "end": "1594520"
  },
  {
    "text": "into my next bullet point the users were unhappy uh with the chat when it was missing any of these key details so it's",
    "start": "1594520",
    "end": "1602279"
  },
  {
    "text": "important to tune your rag performance and also handle those uh ambiguous inputs like Sven mentioned uh which is",
    "start": "1602279",
    "end": "1609159"
  },
  {
    "text": "like you know those onew searches uh those little keywords like driver okay what do you want me to do about that",
    "start": "1609159",
    "end": "1615600"
  },
  {
    "text": "it's important to in uh resolve these with like little refinement follow-ups in your UI like hey you asked about this",
    "start": "1615600",
    "end": "1622159"
  },
  {
    "text": "driver uh what about him like do you want to know how many hours he has left Etc uh it'll help you you know uh direct",
    "start": "1622159",
    "end": "1629919"
  },
  {
    "text": "the user to get on the right path and lastly I just want to mention uh to",
    "start": "1629919",
    "end": "1635600"
  },
  {
    "text": "think about your rail guards like up front and you know we found that the best QA users for these kinds of tests",
    "start": "1635600",
    "end": "1642679"
  },
  {
    "text": "for our internal co-workers actually so when we first built the chatbot we all just kind of went at it and had an",
    "start": "1642679",
    "end": "1648600"
  },
  {
    "text": "internal dog fooding session I really encourage you to like try to break your product because um your users will",
    "start": "1648600",
    "end": "1655320"
  },
  {
    "text": "inevitably test these in the wildest ways uh so you should be ready uh nobody",
    "start": "1655320",
    "end": "1661279"
  },
  {
    "text": "really wants to end up on the front page of tech crunch because your chatbot started handing out coupons to everybody",
    "start": "1661279",
    "end": "1666640"
  },
  {
    "text": "that visited your site right yeah and yeah that's a wrap uh thank you",
    "start": "1666640",
    "end": "1673480"
  },
  {
    "text": "all for joining us uh keeping it on brand with the fly well uh if you have any feedback for us as speakers uh you",
    "start": "1673480",
    "end": "1680880"
  },
  {
    "text": "can follow up with us at happy hour Etc and uh on the QR code there same s AI is",
    "start": "1680880",
    "end": "1686840"
  },
  {
    "text": "growing uh if you're interested in working on cool problems in the AI space uh real world applications we'd love to",
    "start": "1686840",
    "end": "1692960"
  },
  {
    "text": "talk to you thank [Applause]",
    "start": "1692960",
    "end": "1702279"
  },
  {
    "text": "you question any questions",
    "start": "1702279",
    "end": "1706760"
  },
  {
    "text": "hey guys thanks for the talking for sharing so openly um I'm actually curious about on the cost side of things",
    "start": "1713559",
    "end": "1718679"
  },
  {
    "text": "when you guys started uh spinning up the agents and atic workflows uh what was the impact in terms of cost uh of",
    "start": "1718679",
    "end": "1725600"
  },
  {
    "text": "inference um you know once you started to deploy this at scale um so we're in experimental mode",
    "start": "1725600",
    "end": "1732360"
  },
  {
    "text": "right now but we find that like actually the costs were like remarkably reasonable we're using mostly vendors",
    "start": "1732360",
    "end": "1739240"
  },
  {
    "text": "too so yeah okay does that answer your question kind of yeah yeah thank you",
    "start": "1739240",
    "end": "1747480"
  },
  {
    "text": "future cheaper so you know yeah it's a good curve to Great s um so one of the",
    "start": "1747480",
    "end": "1754080"
  },
  {
    "text": "questions on the development side of things SL I saw you had an experimental user um in one of the slides yeah and",
    "start": "1754080",
    "end": "1761799"
  },
  {
    "text": "you had the real user so um you know like you said there are new models new",
    "start": "1761799",
    "end": "1767559"
  },
  {
    "text": "versions of the models that's one part of it but then before even you reach to the model you have let's say a rag",
    "start": "1767559",
    "end": "1774360"
  },
  {
    "text": "system in place where you have some chunking strategy reranking strategy and all those sort of things right so a lot of uh combinations possible to test out",
    "start": "1774360",
    "end": "1782600"
  },
  {
    "text": "uh what is a good response finally coming out of this chatbot right so for",
    "start": "1782600",
    "end": "1788120"
  },
  {
    "text": "that experimental user how quickly can you test those different combinations to",
    "start": "1788120",
    "end": "1795039"
  },
  {
    "text": "frame up an evaluation strategy that this frame this model version with this",
    "start": "1795039",
    "end": "1800240"
  },
  {
    "text": "chunking strategy plus this stuff is good for my chatbot so if you could elaborate a",
    "start": "1800240",
    "end": "1806600"
  },
  {
    "text": "b okay yes I think the key is to create the golden data set I think many was like like talking about that so you have",
    "start": "1806600",
    "end": "1813360"
  },
  {
    "text": "to first example the customers like uh tracing so we have a lot of the we have very complete tracing mechanisms we",
    "start": "1813360",
    "end": "1819640"
  },
  {
    "text": "collect all the histories and then we want to curate a very good golden data set so that you can just test out",
    "start": "1819640",
    "end": "1825200"
  },
  {
    "text": "through that data set I think that's the key way because then you please is your evaluation sorry followup is your",
    "start": "1825200",
    "end": "1831080"
  },
  {
    "text": "evaluation stage wise or is it final output dependent it's like the eval like",
    "start": "1831080",
    "end": "1837159"
  },
  {
    "text": "it's eval that we run and then we just try out different parameters it's like just parameter searchy I'd like to add to that actually",
    "start": "1837159",
    "end": "1844519"
  },
  {
    "text": "um since I mentioned all these sub agents we actually started with that where we say okay we can also eval for",
    "start": "1844519",
    "end": "1850000"
  },
  {
    "text": "example the r Retriever and we when we buil this data set we actually build a little bit more fine grain that it can",
    "start": "1850000",
    "end": "1855840"
  },
  {
    "text": "cover these subc components and that's really nice about having the components because you can work on them independently we can switch out our",
    "start": "1855840",
    "end": "1862080"
  },
  {
    "text": "retriever to add some kind of like add some context to the embeddings and so on",
    "start": "1862080",
    "end": "1867320"
  },
  {
    "text": "and then run that one but of like you mentioned nothing really beats obviously the end to end because sometimes you",
    "start": "1867320",
    "end": "1872679"
  },
  {
    "text": "improve your retriever but you actually get worse on the final result because you get let's say more irrelevant",
    "start": "1872679",
    "end": "1878200"
  },
  {
    "text": "articles yeah the problem with the end result is you don't know then where in this if they have 10 stages and to come",
    "start": "1878200",
    "end": "1883960"
  },
  {
    "text": "to the 10 you don't know where to like yeah I think the answer is both yeah",
    "start": "1883960",
    "end": "1889919"
  },
  {
    "text": "should we all right I think that's it if you free to meet us happy hour or on the stage here",
    "start": "1892919",
    "end": "1900270"
  },
  {
    "text": "[Applause]",
    "start": "1900270",
    "end": "1903339"
  }
]
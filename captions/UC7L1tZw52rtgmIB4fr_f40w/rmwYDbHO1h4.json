[
  {
    "text": "thanks everyone thanks for coming to the talk um uh my name is Ken I'm the VP ofat Rai and this is my colleague prun",
    "start": "2520",
    "end": "9840"
  },
  {
    "text": "he's a senior mlops engineer uh we also do recognize that I think after this is",
    "start": "9840",
    "end": "15120"
  },
  {
    "text": "like happy hour or something like that so you know I hate to be the person standing between you and your preferred",
    "start": "15120",
    "end": "20960"
  },
  {
    "text": "drink alcoholic or not so uh we we're going to try to make this more engaging and more interactive uh as possible and",
    "start": "20960",
    "end": "27599"
  },
  {
    "text": "please ask questions as well so we're here to talk about how we can apply ML and Ray to",
    "start": "27599",
    "end": "35239"
  },
  {
    "text": "Radiology so first why Radiology as we all know the population is aging over",
    "start": "35239",
    "end": "41480"
  },
  {
    "text": "time medical technology is advancing and humans have much higher life expectancy",
    "start": "41480",
    "end": "47199"
  },
  {
    "text": "one of the side effects of having higher life expectancy and living longer is you start having more problems that comes",
    "start": "47199",
    "end": "52680"
  },
  {
    "text": "with age you start needing more scans whether it's x-rays MRIs uh you know",
    "start": "52680",
    "end": "57719"
  },
  {
    "text": "brain CT scans Etc in this chart which was uh U you know we",
    "start": "57719",
    "end": "63039"
  },
  {
    "text": "got it from the Department of Labor we can see that the demand of radiology has",
    "start": "63039",
    "end": "68040"
  },
  {
    "text": "increased far more than the increase in Radiologists we are not producing enough",
    "start": "68040",
    "end": "73600"
  },
  {
    "text": "Radiologists to match the demand of what the US needs from Radiology scans what",
    "start": "73600",
    "end": "80840"
  },
  {
    "text": "does that mean that means we have a burnout problem radiologist are burning out that means we cannot um read enough",
    "start": "80840",
    "end": "89400"
  },
  {
    "text": "studies we cannot um serve all the patients that need to be served and we",
    "start": "89400",
    "end": "94520"
  },
  {
    "text": "have a huge backlog that we just cannot process so this problem we believe can",
    "start": "94520",
    "end": "99799"
  },
  {
    "text": "be solved with AI let's talk about our first product um",
    "start": "99799",
    "end": "105920"
  },
  {
    "text": "our first product is called radi Omni so in a radiology report what a",
    "start": "105920",
    "end": "111360"
  },
  {
    "text": "radiology does is they first look at they go to a dark room sometimes in a basement sometimes not it's a super dark",
    "start": "111360",
    "end": "118200"
  },
  {
    "text": "room with like three or four monitors they look at an image and then they dictate into the void into the obliss of",
    "start": "118200",
    "end": "126640"
  },
  {
    "text": "what that image is represent the way that dictate has to follow a specific pattern the pattern of",
    "start": "126640",
    "end": "133360"
  },
  {
    "text": "the Radiology report the Radiology report has different sections there's the finding sections which is all the",
    "start": "133360",
    "end": "139120"
  },
  {
    "text": "observations they see and then there's the impression section which you can think of as conclusion SL um",
    "start": "139120",
    "end": "145560"
  },
  {
    "text": "recommendation or diagnosis in a normal workflow they dict through all of their",
    "start": "145560",
    "end": "150879"
  },
  {
    "text": "findings both the positive and the negatives basically you can think of it as they have to go through every single",
    "start": "150879",
    "end": "156480"
  },
  {
    "text": "Pixel of the image and talk about how this is normal this is normal this is not normal um I see something here I",
    "start": "156480",
    "end": "162560"
  },
  {
    "text": "don't see something there and go through everything and then they dictate the conclusion and the diagnosis section",
    "start": "162560",
    "end": "168720"
  },
  {
    "text": "which is the Impressions what we do what we started out doing is we can automate the",
    "start": "168720",
    "end": "175040"
  },
  {
    "text": "impression section why is the impression section important because when you're a",
    "start": "175040",
    "end": "180239"
  },
  {
    "text": "doctor and you're ordering a patient to do Radiology scans 90% of the time you",
    "start": "180239",
    "end": "185760"
  },
  {
    "text": "don't actually read the report this is a small fun fact and I might offend any Physicians here but 90% of the time they",
    "start": "185760",
    "end": "192000"
  },
  {
    "text": "don't read the report they go straight to the impression section read the tldr and they move on right you all most of",
    "start": "192000",
    "end": "198280"
  },
  {
    "text": "you are probably Engineers here you probably don't want to read through the entire document you go to stack Overflow you read the tldr and you move on with",
    "start": "198280",
    "end": "204120"
  },
  {
    "text": "your life maybe you know how it works under the hood maybe you don't know if you can get things through if you have a",
    "start": "204120",
    "end": "209319"
  },
  {
    "text": "lot of work if you're like behind on Deadline you just want to move on most doctors only",
    "start": "209319",
    "end": "214720"
  },
  {
    "text": "look at the impression section and that's why it's important to make sure this part is automated with high",
    "start": "214720",
    "end": "221239"
  },
  {
    "text": "quality now again to recap what do we do we generate the impression section we",
    "start": "221239",
    "end": "227879"
  },
  {
    "text": "can actually customize the generation on a per radiologist basis so a radiologist",
    "start": "227879",
    "end": "232920"
  },
  {
    "text": "that's trained in Harvard and one that's trained at Stanford can actually write their impressions in different styles",
    "start": "232920",
    "end": "238319"
  },
  {
    "text": "using different words to represent the same meaning and finally we also include consensus guidelines what is consensus",
    "start": "238319",
    "end": "244760"
  },
  {
    "text": "guideline it means I might recommend someone given the findings and say hey please come back 3 months later for a CT",
    "start": "244760",
    "end": "252400"
  },
  {
    "text": "scan in the current world a radiologist would have to look up the consensus guideline which is a bit like a",
    "start": "252400",
    "end": "257759"
  },
  {
    "text": "dictionary a book and then dictate it back in what we do is we can ingest the",
    "start": "257759",
    "end": "263360"
  },
  {
    "text": "consensus guideline and add it onto our Impressions automatically so let's look at a demo so",
    "start": "263360",
    "end": "270479"
  },
  {
    "text": "all this sounds very abstract let's look at a demo over here on the left hand side",
    "start": "270479",
    "end": "277440"
  },
  {
    "text": "what you see is a radiology reporting solution you can see that there's different sections there's the findings",
    "start": "277440",
    "end": "283800"
  },
  {
    "text": "methodology impression section uh to make the demo a bit faster we actually pre-populated the finding",
    "start": "283800",
    "end": "290840"
  },
  {
    "text": "section unlike most doctors the reporting solution is the main software",
    "start": "290840",
    "end": "296600"
  },
  {
    "text": "that the radiologist is operating on they don't actually go into the EMR electronic health record that much they",
    "start": "296600",
    "end": "302919"
  },
  {
    "text": "actually stay in this Solution on the right hand side you can see there's a Radia Omni this is a zero click solution",
    "start": "302919",
    "end": "310800"
  },
  {
    "text": "what it means is once you have it running in the background it automatically integrates with our reporting solution and it will",
    "start": "310800",
    "end": "317440"
  },
  {
    "text": "automatically trigger as long as your automatic mode is on as you can see in in in in this it automatically triggers",
    "start": "317440",
    "end": "324360"
  },
  {
    "text": "it takes about 2 seconds and it generates The Impressions down there you can probably see that the Impressions down there are not made up right the LV",
    "start": "324360",
    "end": "332160"
  },
  {
    "text": "um RV LV ratio is by 1.6 you can see that reference in the impression section as well um those of you who have a",
    "start": "332160",
    "end": "338759"
  },
  {
    "text": "really good eyesight can actually try to check um we marked the ones in green just in the key ones in green you can",
    "start": "338759",
    "end": "345080"
  },
  {
    "text": "check those are all reflected uh in the proper specifics in the impression section this is really important we need",
    "start": "345080",
    "end": "351000"
  },
  {
    "text": "to make sure that the impression section is highly accurate and we also need to make sure it's actually customized to",
    "start": "351000",
    "end": "356240"
  },
  {
    "text": "radiolog style the next thing is that we are not here to replace radiologist think of us",
    "start": "356240",
    "end": "363280"
  },
  {
    "text": "as a co-pilot for radiologist so ultimately the radiologist is always in control they can actually go in and add",
    "start": "363280",
    "end": "369319"
  },
  {
    "text": "and modify their Impressions before they sign off on the report so what we do is we're a productivity tool we help them",
    "start": "369319",
    "end": "375720"
  },
  {
    "text": "generate The Impressions automatically save them the time and then they can then ultimately decide how they want to",
    "start": "375720",
    "end": "382039"
  },
  {
    "text": "modify it before they submit it back the cool thing about this product is that when they modify things we can then",
    "start": "382039",
    "end": "388440"
  },
  {
    "text": "ingest that information back into the next round of our training think of it as a modified rhf if you will we can",
    "start": "388440",
    "end": "395120"
  },
  {
    "text": "then take the signal from the radiologist how they modify the Impressions bring it back to the next round of training",
    "start": "395120",
    "end": "402720"
  },
  {
    "text": "data now why are we satisfied with just Omni Impressions you might ask can we",
    "start": "402800",
    "end": "410680"
  },
  {
    "text": "actually automatically generate the full reporting well I'm glad you did ask or",
    "start": "410680",
    "end": "415759"
  },
  {
    "text": "in my mind you asked um that is what we're doing next recall our uh you know what is the new",
    "start": "415759",
    "end": "423560"
  },
  {
    "text": "workflow here instead of dictating the full report word for word they can actually just dictate key findings or",
    "start": "423560",
    "end": "431199"
  },
  {
    "text": "even Deltas between the last report and the current report and we can then automatically generate the full report for them they can then review it sign",
    "start": "431199",
    "end": "438280"
  },
  {
    "text": "off on it if it looks good or make some small adjustments to it so instead of just saving them the impression section",
    "start": "438280",
    "end": "443879"
  },
  {
    "text": "we can save them the whole reporting section so we can free up the radiologist to do what they do best",
    "start": "443879",
    "end": "449000"
  },
  {
    "text": "which is inter interpret images and we take the tedious you know the more um",
    "start": "449000",
    "end": "454240"
  },
  {
    "text": "mind-numbing part of dictating word for word out of their workflow let's look at",
    "start": "454240",
    "end": "459440"
  },
  {
    "text": "a look at a um demo real quick to see what it looks",
    "start": "459440",
    "end": "464919"
  },
  {
    "text": "like Radiologists can dictate findings free form into the Omni box in whatever order they",
    "start": "465360",
    "end": "471919"
  },
  {
    "text": "want by Basler out alticus period descended to pentex measuring 11 mm with",
    "start": "471919",
    "end": "477000"
  },
  {
    "text": "adjacent stranding but no abscess period 2 cmet homa in segment three of the",
    "start": "477000",
    "end": "482720"
  },
  {
    "text": "liver comma degenerative changes in the spine period 3.7 CM right renal cyst period 5.3 CM left ovarian cyst period",
    "start": "482720",
    "end": "491159"
  },
  {
    "text": "splin granulomas period status postcystectomy period Omni",
    "start": "491159",
    "end": "496680"
  },
  {
    "text": "report Omni will organize those findings and insert them into each radiologist's personal template and automatically",
    "start": "496680",
    "end": "503199"
  },
  {
    "text": "create the impression in their personal style so this is the first of the demo",
    "start": "503199",
    "end": "511639"
  },
  {
    "text": "in this demo they actually um they actually dictate most of the findings",
    "start": "511639",
    "end": "516640"
  },
  {
    "text": "and then we put them into the all the right sections of the report and we generate them now let's take a look at",
    "start": "516640",
    "end": "521760"
  },
  {
    "text": "the second demo this one is where you don't actually have to dictate the full",
    "start": "521760",
    "end": "526800"
  },
  {
    "text": "findings all you do is dictate the Delta between the two studies most patients",
    "start": "526800",
    "end": "532480"
  },
  {
    "text": "are repeat patients you can actually look at the previous study compare with the current study and dictate the Deltas",
    "start": "532480",
    "end": "539600"
  },
  {
    "text": "let's take a look at this the left side is a prior exam and the right side is the current exam new right C in the SBC",
    "start": "539600",
    "end": "546120"
  },
  {
    "text": "period feeding tub in the stomach period Omni unchanged it takes a few seconds and and um it can generate everything",
    "start": "546120",
    "end": "552800"
  },
  {
    "text": "else based on all the prior reports and metadata field comparison 10",
    "start": "552800",
    "end": "561200"
  },
  {
    "text": "3123 field support lines neid catheter is in the SVC period a feeding tube is",
    "start": "561200",
    "end": "566760"
  },
  {
    "text": "in the stomach period this going to take a long time I didn't want to make everyone have to sit",
    "start": "566760",
    "end": "572399"
  },
  {
    "text": "through this Sox here although superposed pneumonia",
    "start": "572399",
    "end": "579160"
  },
  {
    "text": "cannot be rolled out period so as you can see this is actually a pretty big difference we can",
    "start": "579160",
    "end": "586320"
  },
  {
    "text": "actually be Forex faster we can actually save radiolog just from burnout and we can actually make sure that they can um",
    "start": "586320",
    "end": "593000"
  },
  {
    "text": "go through a lot more cases than they would in the past so to recap right now for",
    "start": "593000",
    "end": "600880"
  },
  {
    "text": "Impressions alone we generate 100,000 reports a day so that's 100,000 patients",
    "start": "600880",
    "end": "606200"
  },
  {
    "text": "that we're helping every day there's about 4,000 Radiologists uh in the US that's using our uh tools every day for",
    "start": "606200",
    "end": "612839"
  },
  {
    "text": "context there's about 30,000 active Radiologists in the US um and we can actually save them quite a bit of time",
    "start": "612839",
    "end": "619160"
  },
  {
    "text": "reporting which is our new product we recently just launched this year we currently signed with five customers so",
    "start": "619160",
    "end": "625200"
  },
  {
    "text": "some of the data is still not statistically significant yet but so far what we see is we can actually save",
    "start": "625200",
    "end": "630760"
  },
  {
    "text": "Radiologists up to 90% of the words and on average is about 3C median time to",
    "start": "630760",
    "end": "636720"
  },
  {
    "text": "generate the reports so enough about the Radiology context um we're here to talk about Ray",
    "start": "636720",
    "end": "644320"
  },
  {
    "text": "and how Ray helps us here's a quick overview what Ray does is it helps us",
    "start": "644320",
    "end": "651000"
  },
  {
    "text": "with especially with how we orchestrate tasks the way we've organized is that every single model is its own python",
    "start": "651000",
    "end": "657560"
  },
  {
    "text": "project and it's templatized and those of you who are uh clearly experts in ml you know that each of the",
    "start": "657560",
    "end": "665399"
  },
  {
    "text": "ml features are not backed by just one model generally speaking you need multiple models some checking each other",
    "start": "665399",
    "end": "671160"
  },
  {
    "text": "either during training or during inference and they all need to work and sync together for a feature to work and",
    "start": "671160",
    "end": "676440"
  },
  {
    "text": "so what we do here is we can actually tempti the models um whether it's ETL",
    "start": "676440",
    "end": "681800"
  },
  {
    "text": "whether it's train whether it's deploy we can actually repeat all those things with the same template and then we can",
    "start": "681800",
    "end": "687720"
  },
  {
    "text": "run it and one of the nice things about Ray is it can actually orchestrate the model training across multiple different",
    "start": "687720",
    "end": "694240"
  },
  {
    "text": "models we actually currently have models that rely on each other and having Ray as orchestrator helps us ensure that all",
    "start": "694240",
    "end": "700760"
  },
  {
    "text": "dependencies are done in the proper way and my colleague prun is going to go through and uh go through a lot more",
    "start": "700760",
    "end": "707279"
  },
  {
    "text": "details on how we do this",
    "start": "707279",
    "end": "711040"
  },
  {
    "text": "prun this all right hey uh I'm the resident nerd at r",
    "start": "714360",
    "end": "720120"
  },
  {
    "text": "thanks Ken for an overview of our products I'm an moms engineer here and I helped build the ray infrastructure over",
    "start": "720120",
    "end": "726440"
  },
  {
    "text": "the last year at RI and I'm here to talk about it so starting out I kind of",
    "start": "726440",
    "end": "731800"
  },
  {
    "text": "wanted to talk over how our infrastructure has actually involved over time we were founded as a startup",
    "start": "731800",
    "end": "738480"
  },
  {
    "text": "back in 2018 we're a startup today and it's just interesting to see what was",
    "start": "738480",
    "end": "744000"
  },
  {
    "text": "doable for us back then in 2018 isn't today and how that just evolved over time",
    "start": "744000",
    "end": "749800"
  },
  {
    "text": "so let's go to 2018 so in 2018 we maintained an on-prem cluster and we",
    "start": "749800",
    "end": "756320"
  },
  {
    "text": "were training models in the range of around 100 million parameters at this time and this is what it looked like we",
    "start": "756320",
    "end": "763199"
  },
  {
    "text": "had three V100 nodes literally in a server in po Alto in fact an mlops",
    "start": "763199",
    "end": "768920"
  },
  {
    "text": "engineer and a researcher actually went out there uh with cables to connect it to the network and it was very raw when",
    "start": "768920",
    "end": "775720"
  },
  {
    "text": "it came to actually just putting gpus in hands of researchers and for the most part this is all that",
    "start": "775720",
    "end": "781920"
  },
  {
    "text": "was really needed for a startup and you can see that there are no abstractions around this essentially researchers were",
    "start": "781920",
    "end": "788279"
  },
  {
    "text": "essentially just sshing into the machines but that was really all that was needed to push the initial models",
    "start": "788279",
    "end": "794560"
  },
  {
    "text": "into production and you can imagine that without any kind of interfaces that this",
    "start": "794560",
    "end": "801120"
  },
  {
    "text": "could occur where a researcher comes in and asks hey I want to use gpus 7 and8",
    "start": "801120",
    "end": "806560"
  },
  {
    "text": "whereas the first re researcher says I want to use all eight well because the team was so small they could kind of",
    "start": "806560",
    "end": "812199"
  },
  {
    "text": "just work it out person to person and it wasn't much of a problem and this is literally what shipped models in",
    "start": "812199",
    "end": "817639"
  },
  {
    "text": "production back in 2018 but that was all that was needed then we come to 2021 where we",
    "start": "817639",
    "end": "824160"
  },
  {
    "text": "entered the cloud scale now we were training models in the range of around 500 million parameters so how did our",
    "start": "824160",
    "end": "831120"
  },
  {
    "text": "infrastructure change well we added the ability to scale gpus in a cloud native",
    "start": "831120",
    "end": "837000"
  },
  {
    "text": "fashion so here researchers could now simply spin up VMS when they wanted additional capacity in their cluster so",
    "start": "837000",
    "end": "843480"
  },
  {
    "text": "not only did we have those on-prem instances on the right here but also the ability to scale Cloud native and again",
    "start": "843480",
    "end": "850160"
  },
  {
    "text": "this worked quite well now we did have some interfaces in front of this we used puppet to deploy these VMS to account",
    "start": "850160",
    "end": "856440"
  },
  {
    "text": "for authentication and things like that so there was more than just say sshing into an on-prem instance but again this",
    "start": "856440",
    "end": "863320"
  },
  {
    "text": "was really enough for another year year and a half eventually researchers started",
    "start": "863320",
    "end": "868440"
  },
  {
    "text": "asking the question question though of hey can I double the size of the model can I quadruple the size of the model",
    "start": "868440",
    "end": "874360"
  },
  {
    "text": "and as an mlfs engineer you get kind of worried you ask yourself does that infrastructure we've built support it",
    "start": "874360",
    "end": "880600"
  },
  {
    "text": "they even ask hey can we one up the magnitude of the amount of data we want to push through the model oh and also",
    "start": "880600",
    "end": "886360"
  },
  {
    "text": "our deadline is next week well that presents some problems and that's where multi-node training comes into the",
    "start": "886360",
    "end": "892199"
  },
  {
    "text": "picture so if you've ever actually done multi-node training natively on a cloud VM it is quite complicated clouds",
    "start": "892199",
    "end": "899680"
  },
  {
    "text": "support it natively but in order to set the right variables if you're working with deep speed for example you have to",
    "start": "899680",
    "end": "906160"
  },
  {
    "text": "set like host files the IPS you have to run python on each of the nodes and get",
    "start": "906160",
    "end": "912240"
  },
  {
    "text": "them all to sync together it's quite a complicated ask to ask a researcher to be doing all of this in the first place",
    "start": "912240",
    "end": "919399"
  },
  {
    "text": "so that was still a problem back in 2022 now we enter 2024 where we're in",
    "start": "919399",
    "end": "926360"
  },
  {
    "text": "the multi-node phase we can train models in the range of around 10 billion parameters and more we're using OSS Ray",
    "start": "926360",
    "end": "933399"
  },
  {
    "text": "with Cube Ray and we also have cloud autoscaling enabled so what does that look like well initially back in March",
    "start": "933399",
    "end": "940959"
  },
  {
    "text": "this is really all that it looked like we put these a100 nodes into a kubernetes cluster and then we added",
    "start": "940959",
    "end": "946800"
  },
  {
    "text": "cubay which there are plenty of talks about this earlier uh in the day but it is basically a kubernetes operator that",
    "start": "946800",
    "end": "953240"
  },
  {
    "text": "allows us to deploy Ray clusters on top of these GPU nodes and what it did A1 is",
    "start": "953240",
    "end": "959680"
  },
  {
    "text": "allow us to orchestrate more than one a100 node to actually train our first production model that we pushed out back",
    "start": "959680",
    "end": "966440"
  },
  {
    "text": "in March using this new Ray based architecture this is really all that was",
    "start": "966440",
    "end": "972560"
  },
  {
    "text": "needed and here's some of the data we collected when we initially did this train so our validation loss actually",
    "start": "972680",
    "end": "979399"
  },
  {
    "text": "went down and this was because we could actually increase the batch size of the data and therefore the model could see",
    "start": "979399",
    "end": "985519"
  },
  {
    "text": "more data next we actually reduced the time per Epoch by about 3 hours and then",
    "start": "985519",
    "end": "992040"
  },
  {
    "text": "finally time for comparable accuracy which means that if we were to have stopped the train before it converged at",
    "start": "992040",
    "end": "997319"
  },
  {
    "text": "a comparable accuracy to a single node then we would have stopped it about 20%",
    "start": "997319",
    "end": "1002480"
  },
  {
    "text": "sooner and you might be looking at this and you know ask yourself hey you",
    "start": "1002480",
    "end": "1007560"
  },
  {
    "text": "doubled the number of gpus but you know the time for one Epoch didn't go down by much and the comparable accuracy also",
    "start": "1007560",
    "end": "1014720"
  },
  {
    "text": "didn't go down by much well I included this in the presentation specific spefically to call out the fact that",
    "start": "1014720",
    "end": "1020959"
  },
  {
    "text": "when you scale from just one Node 1 a100 h100 doesn't matter to two you",
    "start": "1020959",
    "end": "1026600"
  },
  {
    "text": "immediately incur a network bottleneck and you have to keep that in mind especially if all you're doing is going",
    "start": "1026600",
    "end": "1032360"
  },
  {
    "text": "from one node to two nodes in fact today when we train production models we use",
    "start": "1032360",
    "end": "1037600"
  },
  {
    "text": "at least four to six to eight a100 nodes to make sure that we don't incur that",
    "start": "1037600",
    "end": "1042760"
  },
  {
    "text": "initial loss in performance just due to that bottleneck so back to our story although",
    "start": "1042760",
    "end": "1049799"
  },
  {
    "text": "just CU was enough to actually help us train a production model it's quite hard",
    "start": "1049799",
    "end": "1055320"
  },
  {
    "text": "to write manifest directly for cubra if you've ever worked with it it's a 200",
    "start": "1055320",
    "end": "1060640"
  },
  {
    "text": "long Y Line yaml file that you would ask researchers to basically fill out what",
    "start": "1060640",
    "end": "1066280"
  },
  {
    "text": "do you want for your head node what environment variables you want to set for nickel there's just a lot that a",
    "start": "1066280",
    "end": "1071360"
  },
  {
    "text": "researcher would have to manage if the only interface they had was Q bra directly so we did two things in the",
    "start": "1071360",
    "end": "1078360"
  },
  {
    "text": "last couple month months one is we added q and another is that we added rat train",
    "start": "1078360",
    "end": "1083720"
  },
  {
    "text": "so Q is an open-source job scheduler for kubernetes that allows researchers to",
    "start": "1083720",
    "end": "1089440"
  },
  {
    "text": "essentially request a certain amount of gpus say four gpus 8 gpus 16 gpus and it",
    "start": "1089440",
    "end": "1095640"
  },
  {
    "text": "enters a work CU and once their request gets to the front of the work queue the cluster decides hey is there enough gpus",
    "start": "1095640",
    "end": "1103360"
  },
  {
    "text": "in our cluster to allocate this Ray cluster and if there is it'll be allocated if it's not it'll wait in that",
    "start": "1103360",
    "end": "1108960"
  },
  {
    "text": "q and of course with any cu's there are priorities and things and overrides that you can work with but essentially it's a",
    "start": "1108960",
    "end": "1115159"
  },
  {
    "text": "way to queue up requests for resources additionally on the bottom there that line shows that Q actually integrates",
    "start": "1115159",
    "end": "1122559"
  },
  {
    "text": "directly into our Cloud's autoscaling layer so researchers can explicitly request if our static cluster which",
    "start": "1122559",
    "end": "1129440"
  },
  {
    "text": "contains several a100 nodes doesn't have enough resources they can explicitly request autoscaling nodes and the reason",
    "start": "1129440",
    "end": "1136240"
  },
  {
    "text": "it it's explicit is because autoscaling nodes are quite more expensive than the contracts we have for our existing nodes",
    "start": "1136240",
    "end": "1143480"
  },
  {
    "text": "or our static nodes so that's that's Q so as I mentioned earlier you know you",
    "start": "1143480",
    "end": "1149200"
  },
  {
    "text": "could work with q and Q bra directly they they provide a lot however this is where we entered into developing rad",
    "start": "1149200",
    "end": "1156640"
  },
  {
    "text": "train because we wanted an actual interface for researchers to interact with these clusters instead of",
    "start": "1156640",
    "end": "1162159"
  },
  {
    "text": "interacting directly with q and qay so what is rad train one it's actually a",
    "start": "1162159",
    "end": "1168039"
  },
  {
    "text": "play on Ray train we called it rad train because rad AI you know uh and what it",
    "start": "1168039",
    "end": "1173320"
  },
  {
    "text": "does is it provides a cloud agnostic description of a user's Ray cluster by GPU type so here's actually all a",
    "start": "1173320",
    "end": "1180240"
  },
  {
    "text": "researcher has to provide to create a cluster on the infrastructure I just showed you in the last slide one is they",
    "start": "1180240",
    "end": "1187640"
  },
  {
    "text": "just provide the ray cluster's name so here just training cluster we use weights and biases for a model",
    "start": "1187640",
    "end": "1192799"
  },
  {
    "text": "governance and artifacts so here I provide my name PR then research provide exactly which",
    "start": "1192799",
    "end": "1199760"
  },
  {
    "text": "Ray cluster or Ray version that they want here I have 2.30 but let's say",
    "start": "1199760",
    "end": "1205039"
  },
  {
    "text": "there's some kind of improvement well they have full control and they can actually upgrade it to to",
    "start": "1205039",
    "end": "1210240"
  },
  {
    "text": "2.32 or they can downgrade it if there was some bug introduced they have full control there next they can say exactly",
    "start": "1210240",
    "end": "1216679"
  },
  {
    "text": "which GPU type they want to use as well so here they have the A3 h100 type A3",
    "start": "1216679",
    "end": "1223000"
  },
  {
    "text": "referencing the actual gcp type an A3 machine for these h100s but there are also A2 a100 types and then the",
    "start": "1223000",
    "end": "1230280"
  },
  {
    "text": "autoscaling equivalents of each of these and again the autoscaling piece is explicit because autoscaling is much",
    "start": "1230280",
    "end": "1236200"
  },
  {
    "text": "more expensive than just going uh to create clusters on our static",
    "start": "1236200",
    "end": "1241600"
  },
  {
    "text": "infrastructure next they can specify exactly how many replicas they want and how many gpus per worker or per replica",
    "start": "1241600",
    "end": "1248520"
  },
  {
    "text": "they that they want so what this represents here is a 4x8 setup four nodes with eight gpus each for a total",
    "start": "1248520",
    "end": "1255200"
  },
  {
    "text": "of 32 gpus that they can run this training on and then finally they can specify",
    "start": "1255200",
    "end": "1260559"
  },
  {
    "text": "exactly which Docker image that they want to use to run on these worker nodes here I just have the rml image which",
    "start": "1260559",
    "end": "1267080"
  },
  {
    "text": "contains a bunch of libraries you would expect to have as a machine learning engineer uh like torch but in production",
    "start": "1267080",
    "end": "1274120"
  },
  {
    "text": "we actually use properly built Frozen dependencies a properly built Docker file for training in production not the",
    "start": "1274120",
    "end": "1282279"
  },
  {
    "text": "rayl image additionally rat tray composes all cluster operations into Unified command",
    "start": "1282279",
    "end": "1288880"
  },
  {
    "text": "line and python interface so here's a bit of an example of what you can do with rat train there and there are all",
    "start": "1288880",
    "end": "1294960"
  },
  {
    "text": "kinds of things of course you can create a cluster you can destroy clusters you can forward to your cluster you can",
    "start": "1294960",
    "end": "1300640"
  },
  {
    "text": "create jobs stop jobs copy data to and from your cluster uh startup jupyter",
    "start": "1300640",
    "end": "1306000"
  },
  {
    "text": "notebooks as you need this is like the interface that our researchers use to interact with the cluster and here's an",
    "start": "1306000",
    "end": "1312679"
  },
  {
    "text": "example at the bottom here rad train cluster create and all we pass in as an argument for most of these is just that",
    "start": "1312679",
    "end": "1319200"
  },
  {
    "text": "yaml file that I talked about in the previous slide Dy model configs R cluster. yaml and they can create",
    "start": "1319200",
    "end": "1326600"
  },
  {
    "text": "cluster additionally rat train also promotes good workflow software engineering practices so as Ken",
    "start": "1326600",
    "end": "1333679"
  },
  {
    "text": "mentioned earlier we follow sber version packages um there's been a trend in the",
    "start": "1333679",
    "end": "1338799"
  },
  {
    "text": "industry to go deploy directly from juper notebooks but we want to apply better software engineering practices",
    "start": "1338799",
    "end": "1344919"
  },
  {
    "text": "and make sure that we're maintain our maintaining our models well not just for for the researchers that developed them",
    "start": "1344919",
    "end": "1350039"
  },
  {
    "text": "but the next researcher that comes down the line that needs to add a feature or retrain the model additionally we dockerize everything so that Docker",
    "start": "1350039",
    "end": "1357200"
  },
  {
    "text": "file. GPU is the training uh Docker file that we use in production next we use",
    "start": "1357200",
    "end": "1363400"
  },
  {
    "text": "poetry to make sure that we lock all of our dependencies and can manage them and this includes pytorch I know there has",
    "start": "1363400",
    "end": "1369440"
  },
  {
    "text": "been problems with pytorch and poetry if you're thinking this but they have resolved them uh and then finally",
    "start": "1369440",
    "end": "1374600"
  },
  {
    "text": "because we have this python package first uh view on maintaining models we",
    "start": "1374600",
    "end": "1380559"
  },
  {
    "text": "can deploy cicd to this very very easily so hopefully this has given you",
    "start": "1380559",
    "end": "1387240"
  },
  {
    "text": "bit more about what's going on on the right side of this how rad trade actually integrates with our Ray cluster",
    "start": "1387240",
    "end": "1392760"
  },
  {
    "text": "and then also the left side of how we actually maintain models as proper",
    "start": "1392760",
    "end": "1397919"
  },
  {
    "text": "python packages essentially and additionally what's going on in the center which is because they're well",
    "start": "1397919",
    "end": "1404279"
  },
  {
    "text": "provisioned python packages that we can automate ETL train and deployment very",
    "start": "1404279",
    "end": "1410640"
  },
  {
    "text": "easily so you might ask well where do we go from here things are looking pretty good at least well I designed it so I",
    "start": "1410640",
    "end": "1416279"
  },
  {
    "text": "think they're pretty good um but we're going to an Era of multicluster and hopefully the diagram on the next slide",
    "start": "1416279",
    "end": "1421919"
  },
  {
    "text": "will better explain this but in this era we're looking to train models in the range of around a 100 billion parameters",
    "start": "1421919",
    "end": "1428320"
  },
  {
    "text": "of course that's our approximation and then finally we would like to make sure that our scaling is cloud",
    "start": "1428320",
    "end": "1434360"
  },
  {
    "text": "agnostic so what does that look like well it doesn't actually look that much different than that previous diagram but",
    "start": "1434360",
    "end": "1441000"
  },
  {
    "text": "as you'll see what's missing on the right is the on-prem instances that we do do actually use for non-production",
    "start": "1441000",
    "end": "1446440"
  },
  {
    "text": "use cases today what we've done here in this diagram is actually deploy GK bare",
    "start": "1446440",
    "end": "1451559"
  },
  {
    "text": "metal directly onto those on-prem instances to bring it in essentially as just another kubernetes cluster that our",
    "start": "1451559",
    "end": "1458559"
  },
  {
    "text": "researchers can use to train on through rad train and if it's starting to look like a template where we have G key our",
    "start": "1458559",
    "end": "1465640"
  },
  {
    "text": "main cluster G key bare metal or onr cluster so on and so forth well that was",
    "start": "1465640",
    "end": "1470679"
  },
  {
    "text": "totally intentional actually this is super relevant to healthcare specifically",
    "start": "1470679",
    "end": "1475919"
  },
  {
    "text": "because there are certain restrictions on where we can take Phi personally identifiable health information in the",
    "start": "1475919",
    "end": "1482640"
  },
  {
    "text": "world so for example in Canada if we're wanting to train a multimodal model on images MRIs x-rays that's considered Phi",
    "start": "1482640",
    "end": "1491320"
  },
  {
    "text": "and we cannot train that model outside of Canada's borders and because this is essentially a template to deploy kuber",
    "start": "1491320",
    "end": "1499039"
  },
  {
    "text": "into other regions well we can do exactly that we can bring up an a100 cluster in Canada to train that",
    "start": "1499039",
    "end": "1505399"
  },
  {
    "text": "multimodal model and that's true for other countries as well the EU has its own laws Australia South America Asia",
    "start": "1505399",
    "end": "1512919"
  },
  {
    "text": "there are plenty of laws that surround Phi and the design of this infrastructure as a templated kubernetes",
    "start": "1512919",
    "end": "1518960"
  },
  {
    "text": "deployment is super important for that and multiq will help with that too we're running a little low on time so we can",
    "start": "1518960",
    "end": "1525279"
  },
  {
    "text": "perhaps save it for questions at the end if you're wondering what that is and how it helps and yeah that's it",
    "start": "1525279",
    "end": "1535200"
  },
  {
    "text": "thanks so let's take some questions looks like your last slide does this",
    "start": "1538360",
    "end": "1544000"
  },
  {
    "text": "also allow you to train models in different regions without getting the data out of",
    "start": "1544000",
    "end": "1550080"
  },
  {
    "text": "the region correct yes so the idea is that because we've basically templatized",
    "start": "1550080",
    "end": "1555159"
  },
  {
    "text": "the deployment of these GPU clusters we essentially it's I will say it's not as",
    "start": "1555159",
    "end": "1560760"
  },
  {
    "text": "easy as saying us Central one to Canada Central one it's not going to be that easy but the the infrastructure itself",
    "start": "1560760",
    "end": "1568000"
  },
  {
    "text": "is basically templatized so yes so for example we did recently train a model in",
    "start": "1568000",
    "end": "1573480"
  },
  {
    "text": "Canada essentially doing this okay but it doesn't allow you to train the same model first can and train we yeah",
    "start": "1573480",
    "end": "1581760"
  },
  {
    "text": "depending on the actually depending on the regulations of the country sometimes you can't actually train the what we",
    "start": "1581760",
    "end": "1587760"
  },
  {
    "text": "actually um depending on ration is you can first train an initial version of the model in",
    "start": "1587760",
    "end": "1593080"
  },
  {
    "text": "a particular region what you can do is then you can just like copy and paste the weights over to the US region so you",
    "start": "1593080",
    "end": "1599600"
  },
  {
    "text": "don't have any Phi violations but the weights are you're allowed to copy over then you can run either a lower adapter",
    "start": "1599600",
    "end": "1606320"
  },
  {
    "text": "or run another second fine tuning or whatever you want to do um to then train and that's kind of how we can work",
    "start": "1606320",
    "end": "1612279"
  },
  {
    "text": "around this situation yeah yeah",
    "start": "1612279",
    "end": "1616919"
  },
  {
    "text": "what does your dependency management look like for different projects Al yeah that's a great question part of",
    "start": "1618760",
    "end": "1625760"
  },
  {
    "text": "the thing I did want to solve with rat train was not only just the rate cluster side of things and orchestration but",
    "start": "1625760",
    "end": "1631679"
  },
  {
    "text": "also dependency management and I think this structure of making sure that your",
    "start": "1631679",
    "end": "1636799"
  },
  {
    "text": "models are their own python packages is what makes depend dependency management",
    "start": "1636799",
    "end": "1641880"
  },
  {
    "text": "relatively straightforward so here researchers actually have the ability to say use the latest version of pytorch",
    "start": "1641880",
    "end": "1648520"
  },
  {
    "text": "when say another model has been outdated but is still in production but there's no dependency between them and they can",
    "start": "1648520",
    "end": "1653720"
  },
  {
    "text": "update it as needed so that's essentially it we've isolated these dependency problems by just making sure",
    "start": "1653720",
    "end": "1659279"
  },
  {
    "text": "that models are their own first class python packages Yeah question",
    "start": "1659279",
    "end": "1666360"
  },
  {
    "text": "back sure yeah that's a good question so I have poet poetry in the past for a",
    "start": "1674480",
    "end": "1680080"
  },
  {
    "text": "while now so I was a bit biased when also designing it so I'm going to put that out there um you can come up with a",
    "start": "1680080",
    "end": "1686000"
  },
  {
    "text": "workflow where you use pip tools and other types of you know workflow tools like that but what I liked about poetry",
    "start": "1686000",
    "end": "1692279"
  },
  {
    "text": "and what I still like about poetry today is that the workflow is fully end to end it not only manages your dependencies",
    "start": "1692279",
    "end": "1698559"
  },
  {
    "text": "and lock files but also manages the virtual environments so at least for adoption for the researchers it was",
    "start": "1698559",
    "end": "1705360"
  },
  {
    "text": "relatively straightforward to tell them to use just single tool tool to do essentially everything versus say",
    "start": "1705360",
    "end": "1711240"
  },
  {
    "text": "cobbling together pip tools with Pip and P en and all these other things to get it working so that's why I use",
    "start": "1711240",
    "end": "1719840"
  },
  {
    "text": "poetry complely understand your training aspect of you",
    "start": "1720840",
    "end": "1726240"
  },
  {
    "text": "took the audio and then converted it into the Radiology reports right you're not doing any image training on the",
    "start": "1726240",
    "end": "1733640"
  },
  {
    "text": "Radiology speci yeah so there that's a really good question so there's two things that we're doing",
    "start": "1733640",
    "end": "1738840"
  },
  {
    "text": "first is we take voice and we turn it into text that's the first thing the",
    "start": "1738840",
    "end": "1744159"
  },
  {
    "text": "second is we then take the outputting text which is just a few bullet points we turn it into a full image uh sorry a",
    "start": "1744159",
    "end": "1750880"
  },
  {
    "text": "full report so there's voice to text and then there's text to text as well we don't do imaging yet and that's",
    "start": "1750880",
    "end": "1756120"
  },
  {
    "text": "something we're exploring for the future so how is this different from medical",
    "start": "1756120",
    "end": "1763240"
  },
  {
    "text": "transcription so medical transcription what they do is they uh convert your voice to text word for word what we do",
    "start": "1763919",
    "end": "1771120"
  },
  {
    "text": "is we take one step further we we not just convert your converting your voice to text word for word is just step one",
    "start": "1771120",
    "end": "1777200"
  },
  {
    "text": "step two is taking your words and then generating a full Radiology report right that's not what the medical",
    "start": "1777200",
    "end": "1782600"
  },
  {
    "text": "transcription workflow does right now um right now if you want to generate a full radiolog report you would have to",
    "start": "1782600",
    "end": "1788320"
  },
  {
    "text": "dictate the report word for word so imagine you're writing an article you have to dictate each word for word in your article what we do is you can",
    "start": "1788320",
    "end": "1794760"
  },
  {
    "text": "dictate a few bullet points and we generate an article for you and publish it for you that's that's that would be the analogy",
    "start": "1794760",
    "end": "1801240"
  },
  {
    "text": "so there are services that it for like the medical transcription they",
    "start": "1801240",
    "end": "1807480"
  },
  {
    "text": "don't do work to but they do convert it to speciality are",
    "start": "1807480",
    "end": "1814960"
  },
  {
    "text": "not yeah we can talk offline um there's a lot of tools to go from voice to text",
    "start": "1816519",
    "end": "1822000"
  },
  {
    "text": "but for radiology specifically I don't think there's any tools in the market that go from bullet point to the full Radiology report that current doesn't",
    "start": "1822000",
    "end": "1828679"
  },
  {
    "text": "doesn't exist in the market yeah I think we're right on time so um",
    "start": "1828679",
    "end": "1833840"
  },
  {
    "text": "thanks everyone if there's more questions happy to chat offline yeah",
    "start": "1833840",
    "end": "1839200"
  }
]
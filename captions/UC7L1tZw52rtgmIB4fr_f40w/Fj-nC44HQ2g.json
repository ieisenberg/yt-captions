[
  {
    "text": "all right hi everyone uh welcome I'm",
    "start": "3179",
    "end": "5880"
  },
  {
    "text": "Stephanie and this is Judge ring and",
    "start": "5880",
    "end": "7980"
  },
  {
    "text": "today we'll be discussing our work on",
    "start": "7980",
    "end": "9780"
  },
  {
    "text": "running large scale Shuffle on top of",
    "start": "9780",
    "end": "11580"
  },
  {
    "text": "Ray core so this work is available in",
    "start": "11580",
    "end": "14219"
  },
  {
    "text": "Ray 2.0 through the ray datasets library",
    "start": "14219",
    "end": "16440"
  },
  {
    "text": "and today we'll do a deep dive into why",
    "start": "16440",
    "end": "19199"
  },
  {
    "text": "we did this and how it works under the",
    "start": "19199",
    "end": "21060"
  },
  {
    "text": "hood",
    "start": "21060",
    "end": "22920"
  },
  {
    "text": "so first a little bit about us judgery",
    "start": "22920",
    "end": "25740"
  },
  {
    "text": "and I are both software engineers at any",
    "start": "25740",
    "end": "27539"
  },
  {
    "text": "skill and we work on the ray core team",
    "start": "27539",
    "end": "29939"
  },
  {
    "text": "so we work on the infrastructure",
    "start": "29939",
    "end": "31859"
  },
  {
    "text": "basically supporting all of the",
    "start": "31859",
    "end": "33780"
  },
  {
    "text": "libraries and the ray ecosystem",
    "start": "33780",
    "end": "36420"
  },
  {
    "text": "the work that we'll present today is",
    "start": "36420",
    "end": "38520"
  },
  {
    "text": "also in collaboration with researchers",
    "start": "38520",
    "end": "40379"
  },
  {
    "text": "at UC Berkeley on how we can Implement",
    "start": "40379",
    "end": "42719"
  },
  {
    "text": "flexible and large-scale Shuffle",
    "start": "42719",
    "end": "46340"
  },
  {
    "text": "so I also want to say a little bit about",
    "start": "46500",
    "end": "48539"
  },
  {
    "text": "any skill any skill",
    "start": "48539",
    "end": "51420"
  },
  {
    "text": "is the company behind Rey and Rey of",
    "start": "51420",
    "end": "53940"
  },
  {
    "text": "course is a unified framework for",
    "start": "53940",
    "end": "55920"
  },
  {
    "text": "scaling Python and AI applications",
    "start": "55920",
    "end": "58680"
  },
  {
    "text": "and the reason that we're building any",
    "start": "58680",
    "end": "60300"
  },
  {
    "text": "skill is we is because we believe that",
    "start": "60300",
    "end": "62760"
  },
  {
    "text": "Skilling is a necessity for AI",
    "start": "62760",
    "end": "65100"
  },
  {
    "text": "applications today and it's also very",
    "start": "65100",
    "end": "67799"
  },
  {
    "text": "hard to do so the goal behind any skill",
    "start": "67799",
    "end": "70920"
  },
  {
    "text": "is to provide a managed service around",
    "start": "70920",
    "end": "73320"
  },
  {
    "text": "great applications making it easy to",
    "start": "73320",
    "end": "75960"
  },
  {
    "text": "build scalable applications for anyone",
    "start": "75960",
    "end": "80060"
  },
  {
    "text": "so without further Ado let's take a look",
    "start": "80220",
    "end": "83040"
  },
  {
    "text": "at why we wanted to support large-scale",
    "start": "83040",
    "end": "85320"
  },
  {
    "text": "Shuffle on top of Ray",
    "start": "85320",
    "end": "88439"
  },
  {
    "text": "so to understand why we wanted to do",
    "start": "88439",
    "end": "90720"
  },
  {
    "text": "this let's first take a look at the",
    "start": "90720",
    "end": "92700"
  },
  {
    "text": "broader Ray ecosystem",
    "start": "92700",
    "end": "94439"
  },
  {
    "text": "so Ray core is a unified framework for",
    "start": "94439",
    "end": "96840"
  },
  {
    "text": "scalable computing",
    "start": "96840",
    "end": "98640"
  },
  {
    "text": "it's an open source distributed",
    "start": "98640",
    "end": "100380"
  },
  {
    "text": "framework that makes it easy to scale Ai",
    "start": "100380",
    "end": "102960"
  },
  {
    "text": "and python applications by providing",
    "start": "102960",
    "end": "105299"
  },
  {
    "text": "these core Primitives around tasks",
    "start": "105299",
    "end": "107280"
  },
  {
    "text": "actors and objects",
    "start": "107280",
    "end": "109259"
  },
  {
    "text": "and to make this even easier in Ray 2.0",
    "start": "109259",
    "end": "112380"
  },
  {
    "text": "we've also built a unified toolkit that",
    "start": "112380",
    "end": "115079"
  },
  {
    "text": "can handle different parts of building",
    "start": "115079",
    "end": "116640"
  },
  {
    "text": "an end-to-end machine learning",
    "start": "116640",
    "end": "118079"
  },
  {
    "text": "application",
    "start": "118079",
    "end": "119280"
  },
  {
    "text": "and we call this toolkit the ray AI",
    "start": "119280",
    "end": "121560"
  },
  {
    "text": "runtime or Ray air",
    "start": "121560",
    "end": "123780"
  },
  {
    "text": "so the libraries in Ray air handle",
    "start": "123780",
    "end": "126240"
  },
  {
    "text": "different parts of a machine learning",
    "start": "126240",
    "end": "127860"
  },
  {
    "text": "application including things like",
    "start": "127860",
    "end": "129840"
  },
  {
    "text": "distributed training distributed model",
    "start": "129840",
    "end": "131760"
  },
  {
    "text": "serving and distributed reinforcement",
    "start": "131760",
    "end": "133920"
  },
  {
    "text": "learning",
    "start": "133920",
    "end": "135120"
  },
  {
    "text": "and holding all of these libraries",
    "start": "135120",
    "end": "136739"
  },
  {
    "text": "together is of course distributed data",
    "start": "136739",
    "end": "139560"
  },
  {
    "text": "so raid data sets is the key library for",
    "start": "139560",
    "end": "143280"
  },
  {
    "text": "loading and passing distributed data",
    "start": "143280",
    "end": "145500"
  },
  {
    "text": "between all of the other libraries in",
    "start": "145500",
    "end": "147480"
  },
  {
    "text": "the array ecosystem",
    "start": "147480",
    "end": "149640"
  },
  {
    "text": "and a key primitive that's used in the",
    "start": "149640",
    "end": "151800"
  },
  {
    "text": "data sets library is Shuffle and Shuffle",
    "start": "151800",
    "end": "154739"
  },
  {
    "text": "is implemented directly on top of Ray",
    "start": "154739",
    "end": "157319"
  },
  {
    "text": "core and this is what we will be talking",
    "start": "157319",
    "end": "159420"
  },
  {
    "text": "about today",
    "start": "159420",
    "end": "161959"
  },
  {
    "text": "so to see how Shuffle actually fits in",
    "start": "162599",
    "end": "164640"
  },
  {
    "text": "in a real application let's take this",
    "start": "164640",
    "end": "167099"
  },
  {
    "text": "example where we want to do distributed",
    "start": "167099",
    "end": "169200"
  },
  {
    "text": "data ingest for a distributed training",
    "start": "169200",
    "end": "171660"
  },
  {
    "text": "application",
    "start": "171660",
    "end": "172980"
  },
  {
    "text": "so once we have significant data to",
    "start": "172980",
    "end": "176099"
  },
  {
    "text": "process this is actually going to be a",
    "start": "176099",
    "end": "178440"
  },
  {
    "text": "pretty difficult task",
    "start": "178440",
    "end": "180300"
  },
  {
    "text": "so we first we have to load the",
    "start": "180300",
    "end": "182340"
  },
  {
    "text": "distributed data set from Storage into",
    "start": "182340",
    "end": "184560"
  },
  {
    "text": "memory and we want to split this across",
    "start": "184560",
    "end": "186780"
  },
  {
    "text": "a pool of distributed training workers",
    "start": "186780",
    "end": "190640"
  },
  {
    "text": "eventually we'll also want to train this",
    "start": "190739",
    "end": "192900"
  },
  {
    "text": "on data that's larger that can fit in",
    "start": "192900",
    "end": "195300"
  },
  {
    "text": "the memory capacity of the cluster",
    "start": "195300",
    "end": "197819"
  },
  {
    "text": "and to improve model accuracy we'll also",
    "start": "197819",
    "end": "200459"
  },
  {
    "text": "want to randomly Shuffle the data set",
    "start": "200459",
    "end": "202680"
  },
  {
    "text": "before loading it into the training",
    "start": "202680",
    "end": "204300"
  },
  {
    "text": "workers",
    "start": "204300",
    "end": "205500"
  },
  {
    "text": "and finally to improve GPU utilization",
    "start": "205500",
    "end": "208140"
  },
  {
    "text": "oh sorry about the text not sure what",
    "start": "208140",
    "end": "210360"
  },
  {
    "text": "happened there to improve GPU",
    "start": "210360",
    "end": "212640"
  },
  {
    "text": "utilization we'll also want to pipeline",
    "start": "212640",
    "end": "214800"
  },
  {
    "text": "uh this shuffling step with the training",
    "start": "214800",
    "end": "217620"
  },
  {
    "text": "execution",
    "start": "217620",
    "end": "219480"
  },
  {
    "text": "so one thing to note here is that before",
    "start": "219480",
    "end": "221760"
  },
  {
    "text": "Ray air",
    "start": "221760",
    "end": "223500"
  },
  {
    "text": "doing this would actually require",
    "start": "223500",
    "end": "225000"
  },
  {
    "text": "stitching together multiple different",
    "start": "225000",
    "end": "226680"
  },
  {
    "text": "systems so you might think about using",
    "start": "226680",
    "end": "229080"
  },
  {
    "text": "one system for the shuffling step and",
    "start": "229080",
    "end": "231060"
  },
  {
    "text": "then one system for the training step",
    "start": "231060",
    "end": "233099"
  },
  {
    "text": "but actually pipeline a across these two",
    "start": "233099",
    "end": "235319"
  },
  {
    "text": "is a pretty challenging task because now",
    "start": "235319",
    "end": "237180"
  },
  {
    "text": "you have to stitch between these",
    "start": "237180",
    "end": "238739"
  },
  {
    "text": "different systems uh so with Ray air we",
    "start": "238739",
    "end": "241739"
  },
  {
    "text": "can actually do this all within a single",
    "start": "241739",
    "end": "243720"
  },
  {
    "text": "system by leveraging Ray core",
    "start": "243720",
    "end": "247440"
  },
  {
    "text": "and a key part of that is of course",
    "start": "247440",
    "end": "249360"
  },
  {
    "text": "doing this actual doing this large scale",
    "start": "249360",
    "end": "251580"
  },
  {
    "text": "Shuffle so that's what we'll talk about",
    "start": "251580",
    "end": "253439"
  },
  {
    "text": "next",
    "start": "253439",
    "end": "255799"
  },
  {
    "text": "okay so what exactly is Shuffle Shuffle",
    "start": "256260",
    "end": "258900"
  },
  {
    "text": "is the key operation that's used in",
    "start": "258900",
    "end": "261479"
  },
  {
    "text": "distributed mapreduce programs",
    "start": "261479",
    "end": "264540"
  },
  {
    "text": "so a mapreduce program is an application",
    "start": "264540",
    "end": "267120"
  },
  {
    "text": "that can be split into two different",
    "start": "267120",
    "end": "268800"
  },
  {
    "text": "stages",
    "start": "268800",
    "end": "269880"
  },
  {
    "text": "a map stage where we apply the same",
    "start": "269880",
    "end": "272340"
  },
  {
    "text": "function to each partition of a data set",
    "start": "272340",
    "end": "274620"
  },
  {
    "text": "and a reduced stage where we aggregate",
    "start": "274620",
    "end": "277199"
  },
  {
    "text": "the intermediate results produced by the",
    "start": "277199",
    "end": "279180"
  },
  {
    "text": "map stage into a final result",
    "start": "279180",
    "end": "281759"
  },
  {
    "text": "so in between these two stages we have a",
    "start": "281759",
    "end": "284639"
  },
  {
    "text": "shuffle operation",
    "start": "284639",
    "end": "286139"
  },
  {
    "text": "and we call this a shuffle because we're",
    "start": "286139",
    "end": "288419"
  },
  {
    "text": "taking one intermediate block from each",
    "start": "288419",
    "end": "290580"
  },
  {
    "text": "map task and taking that into a reduced",
    "start": "290580",
    "end": "293160"
  },
  {
    "text": "task to aggregate into a result as you",
    "start": "293160",
    "end": "295620"
  },
  {
    "text": "can see on the left",
    "start": "295620",
    "end": "297360"
  },
  {
    "text": "so one thing I just want to know here is",
    "start": "297360",
    "end": "299340"
  },
  {
    "text": "that this is different from randomly",
    "start": "299340",
    "end": "300840"
  },
  {
    "text": "shuffling the data set which we showed",
    "start": "300840",
    "end": "302940"
  },
  {
    "text": "in the earlier example",
    "start": "302940",
    "end": "304860"
  },
  {
    "text": "so the shuffle that we're talking about",
    "start": "304860",
    "end": "306300"
  },
  {
    "text": "here is actually a generic system level",
    "start": "306300",
    "end": "308639"
  },
  {
    "text": "operation that's used in these higher",
    "start": "308639",
    "end": "310800"
  },
  {
    "text": "level applications such as random",
    "start": "310800",
    "end": "312840"
  },
  {
    "text": "shuffling sorting and group by",
    "start": "312840",
    "end": "316580"
  },
  {
    "text": "so why is Shuffle difficult many of you",
    "start": "317820",
    "end": "320820"
  },
  {
    "text": "have probably written a simple mapreduce",
    "start": "320820",
    "end": "323340"
  },
  {
    "text": "program in Python before so why are we",
    "start": "323340",
    "end": "326280"
  },
  {
    "text": "thinking so much about a large scale",
    "start": "326280",
    "end": "328740"
  },
  {
    "text": "Shuffle",
    "start": "328740",
    "end": "329759"
  },
  {
    "text": "well the main problems that come at",
    "start": "329759",
    "end": "331979"
  },
  {
    "text": "large scale",
    "start": "331979",
    "end": "333300"
  },
  {
    "text": "and the fact that as the data set size",
    "start": "333300",
    "end": "335280"
  },
  {
    "text": "grows larger the number of blocks that",
    "start": "335280",
    "end": "337680"
  },
  {
    "text": "we have to transfer between map and",
    "start": "337680",
    "end": "339360"
  },
  {
    "text": "reduce tasks is going to grow",
    "start": "339360",
    "end": "341039"
  },
  {
    "text": "quadratically",
    "start": "341039",
    "end": "342479"
  },
  {
    "text": "so just as an example if we think about",
    "start": "342479",
    "end": "345360"
  },
  {
    "text": "a 100 terabyte data set and let's say we",
    "start": "345360",
    "end": "348600"
  },
  {
    "text": "split this into one gigabyte partitions",
    "start": "348600",
    "end": "351240"
  },
  {
    "text": "if we do this Shuffle naively we're",
    "start": "351240",
    "end": "353460"
  },
  {
    "text": "going to end up with 10 billion",
    "start": "353460",
    "end": "354840"
  },
  {
    "text": "intermediate blocks and each of these is",
    "start": "354840",
    "end": "356820"
  },
  {
    "text": "going to be 10 kilobytes",
    "start": "356820",
    "end": "359400"
  },
  {
    "text": "well that's actually not too bad if all",
    "start": "359400",
    "end": "361800"
  },
  {
    "text": "of this can fit into memory but even on",
    "start": "361800",
    "end": "364500"
  },
  {
    "text": "a large cluster you won't be able to fit",
    "start": "364500",
    "end": "366600"
  },
  {
    "text": "a 100 terabyte data set into the memory",
    "start": "366600",
    "end": "369000"
  },
  {
    "text": "or into memory at once",
    "start": "369000",
    "end": "371280"
  },
  {
    "text": "and so what that means is that actually",
    "start": "371280",
    "end": "373139"
  },
  {
    "text": "each of these 10 kilobyte blocks will",
    "start": "373139",
    "end": "375539"
  },
  {
    "text": "have to be spilled from memory to a",
    "start": "375539",
    "end": "377400"
  },
  {
    "text": "local disk it'll have to be transferred",
    "start": "377400",
    "end": "379560"
  },
  {
    "text": "across the network between the map and",
    "start": "379560",
    "end": "381240"
  },
  {
    "text": "reduce workers",
    "start": "381240",
    "end": "382860"
  },
  {
    "text": "and finally in the case of a failure",
    "start": "382860",
    "end": "384960"
  },
  {
    "text": "well we'll actually have to recover the",
    "start": "384960",
    "end": "387060"
  },
  {
    "text": "blocks",
    "start": "387060",
    "end": "388919"
  },
  {
    "text": "and so to handle this problem in the",
    "start": "388919",
    "end": "391020"
  },
  {
    "text": "past people have built a lot of",
    "start": "391020",
    "end": "393120"
  },
  {
    "text": "specialized shuffles as Shuffle systems",
    "start": "393120",
    "end": "395639"
  },
  {
    "text": "so these are systems built specifically",
    "start": "395639",
    "end": "397979"
  },
  {
    "text": "for large scale Shuffle",
    "start": "397979",
    "end": "400680"
  },
  {
    "text": "and the good thing about this is that",
    "start": "400680",
    "end": "402840"
  },
  {
    "text": "because these systems are specialized",
    "start": "402840",
    "end": "404819"
  },
  {
    "text": "they're often very high performance and",
    "start": "404819",
    "end": "407280"
  },
  {
    "text": "that's because people have built them",
    "start": "407280",
    "end": "408660"
  },
  {
    "text": "specifically for a new application and",
    "start": "408660",
    "end": "411300"
  },
  {
    "text": "Hardware environments",
    "start": "411300",
    "end": "414180"
  },
  {
    "text": "uh but the cost of doing this is that",
    "start": "414180",
    "end": "416580"
  },
  {
    "text": "there's actually a high development",
    "start": "416580",
    "end": "417900"
  },
  {
    "text": "effort needed to build an each new",
    "start": "417900",
    "end": "420360"
  },
  {
    "text": "Shuffle system",
    "start": "420360",
    "end": "422220"
  },
  {
    "text": "and in addition to that because the",
    "start": "422220",
    "end": "425400"
  },
  {
    "text": "these systems are built only for Shuffle",
    "start": "425400",
    "end": "428580"
  },
  {
    "text": "interoperability with other applications",
    "start": "428580",
    "end": "430500"
  },
  {
    "text": "is pretty challenging so if we think",
    "start": "430500",
    "end": "432840"
  },
  {
    "text": "about the data ingest problem from",
    "start": "432840",
    "end": "434940"
  },
  {
    "text": "earlier if we wanted to build this with",
    "start": "434940",
    "end": "437580"
  },
  {
    "text": "the kind of the current Shuffle systems",
    "start": "437580",
    "end": "439740"
  },
  {
    "text": "you would actually have to stitch",
    "start": "439740",
    "end": "441240"
  },
  {
    "text": "together a shuffle system with another",
    "start": "441240",
    "end": "442919"
  },
  {
    "text": "system built for training",
    "start": "442919",
    "end": "446280"
  },
  {
    "text": "so as part of this project we wanted to",
    "start": "446280",
    "end": "449340"
  },
  {
    "text": "see if there was a better way we could",
    "start": "449340",
    "end": "450900"
  },
  {
    "text": "do this by leveraging record directly to",
    "start": "450900",
    "end": "453960"
  },
  {
    "text": "build a flexible Shuffle that could",
    "start": "453960",
    "end": "455520"
  },
  {
    "text": "still handle large scales of data",
    "start": "455520",
    "end": "457979"
  },
  {
    "text": "and to see how this works we can",
    "start": "457979",
    "end": "460740"
  },
  {
    "text": "actually look first and take a contrast",
    "start": "460740",
    "end": "463259"
  },
  {
    "text": "to how Shuffle systems are being built",
    "start": "463259",
    "end": "465419"
  },
  {
    "text": "today and I'll call these monolithic",
    "start": "465419",
    "end": "467880"
  },
  {
    "text": "Shuffle systems because they're built",
    "start": "467880",
    "end": "470160"
  },
  {
    "text": "directly on top of low-level Primitives",
    "start": "470160",
    "end": "472199"
  },
  {
    "text": "such as RPC",
    "start": "472199",
    "end": "474539"
  },
  {
    "text": "and then on top of the shuffle operation",
    "start": "474539",
    "end": "476460"
  },
  {
    "text": "we have these higher level applications",
    "start": "476460",
    "end": "478440"
  },
  {
    "text": "such as sorting and group by",
    "start": "478440",
    "end": "481860"
  },
  {
    "text": "so in collaboration with Berkeley we",
    "start": "481860",
    "end": "484620"
  },
  {
    "text": "actually built out this EXO Shuffle",
    "start": "484620",
    "end": "486060"
  },
  {
    "text": "project which was seeing if we could use",
    "start": "486060",
    "end": "489000"
  },
  {
    "text": "Ray course Primitives directly to build",
    "start": "489000",
    "end": "491340"
  },
  {
    "text": "Shuffle in a way that was more flexible",
    "start": "491340",
    "end": "493919"
  },
  {
    "text": "so instead of building these Shuffle",
    "start": "493919",
    "end": "495660"
  },
  {
    "text": "algorithms directly over Primitives like",
    "start": "495660",
    "end": "497759"
  },
  {
    "text": "RPC we can use the ray core Primitives",
    "start": "497759",
    "end": "500460"
  },
  {
    "text": "like tasks and objects to build the",
    "start": "500460",
    "end": "502919"
  },
  {
    "text": "shuffle algorithm in only a few hundred",
    "start": "502919",
    "end": "504660"
  },
  {
    "text": "lines of python",
    "start": "504660",
    "end": "506819"
  },
  {
    "text": "and the other advantage of doing this is",
    "start": "506819",
    "end": "509220"
  },
  {
    "text": "that we can now easily interoperate with",
    "start": "509220",
    "end": "511259"
  },
  {
    "text": "other array applications such as",
    "start": "511259",
    "end": "513659"
  },
  {
    "text": "raytrain and that's because all of these",
    "start": "513659",
    "end": "517020"
  },
  {
    "text": "algorithms are actually just using",
    "start": "517020",
    "end": "518700"
  },
  {
    "text": "object refs under the hood",
    "start": "518700",
    "end": "521399"
  },
  {
    "text": "and so that's actually exactly what we",
    "start": "521399",
    "end": "523440"
  },
  {
    "text": "did in Ray 2.0 so in Ray 2.0",
    "start": "523440",
    "end": "528000"
  },
  {
    "text": "users of raid datasets can actually",
    "start": "528000",
    "end": "530339"
  },
  {
    "text": "scale operations like random shuffle to",
    "start": "530339",
    "end": "533100"
  },
  {
    "text": "over 100 terabytes and to more than 100",
    "start": "533100",
    "end": "535140"
  },
  {
    "text": "nodes",
    "start": "535140",
    "end": "536279"
  },
  {
    "text": "and so we still have a lot of work to do",
    "start": "536279",
    "end": "538080"
  },
  {
    "text": "here but we have some promising initial",
    "start": "538080",
    "end": "540240"
  },
  {
    "text": "results showing that we can possibly",
    "start": "540240",
    "end": "542700"
  },
  {
    "text": "achieve the same skill and performance",
    "start": "542700",
    "end": "544500"
  },
  {
    "text": "as other monolithic Shuffle systems",
    "start": "544500",
    "end": "548600"
  },
  {
    "text": "okay so let's take a look at what makes",
    "start": "549420",
    "end": "551640"
  },
  {
    "text": "all of this possible",
    "start": "551640",
    "end": "554220"
  },
  {
    "text": "so how is Shuffle actually implemented",
    "start": "554220",
    "end": "556440"
  },
  {
    "text": "in raid data sets well we have the data",
    "start": "556440",
    "end": "559200"
  },
  {
    "text": "sets Library which is going to implement",
    "start": "559200",
    "end": "560940"
  },
  {
    "text": "the shuffle algorithm in Python",
    "start": "560940",
    "end": "563160"
  },
  {
    "text": "and this tells recorder what",
    "start": "563160",
    "end": "564839"
  },
  {
    "text": "computations need to run",
    "start": "564839",
    "end": "566760"
  },
  {
    "text": "and how to move the data between the",
    "start": "566760",
    "end": "568920"
  },
  {
    "text": "different computations",
    "start": "568920",
    "end": "570779"
  },
  {
    "text": "so raycor will actually handle all of",
    "start": "570779",
    "end": "572700"
  },
  {
    "text": "the hard parts of the shuffle execution",
    "start": "572700",
    "end": "574320"
  },
  {
    "text": "here including spilling data from disk",
    "start": "574320",
    "end": "577500"
  },
  {
    "text": "or from memory to disk and loading them",
    "start": "577500",
    "end": "579660"
  },
  {
    "text": "as they're needed",
    "start": "579660",
    "end": "581880"
  },
  {
    "text": "transferring the blocks across nodes and",
    "start": "581880",
    "end": "585000"
  },
  {
    "text": "recovering blocks in the case of a",
    "start": "585000",
    "end": "586620"
  },
  {
    "text": "failure",
    "start": "586620",
    "end": "588000"
  },
  {
    "text": "and we can also take a look at how this",
    "start": "588000",
    "end": "590040"
  },
  {
    "text": "works out on a real cluster so here we",
    "start": "590040",
    "end": "592620"
  },
  {
    "text": "have two Ray notes",
    "start": "592620",
    "end": "594720"
  },
  {
    "text": "and in this diagram we'll have the data",
    "start": "594720",
    "end": "597180"
  },
  {
    "text": "sets Library code which is going to sit",
    "start": "597180",
    "end": "599040"
  },
  {
    "text": "at the application driver and you can",
    "start": "599040",
    "end": "601260"
  },
  {
    "text": "think of this as kind of the entry point",
    "start": "601260",
    "end": "602760"
  },
  {
    "text": "of your application",
    "start": "602760",
    "end": "604800"
  },
  {
    "text": "so from here raycor will handle the",
    "start": "604800",
    "end": "607440"
  },
  {
    "text": "actual Shuffle execution starting with",
    "start": "607440",
    "end": "610080"
  },
  {
    "text": "placement and scheduling for the map and",
    "start": "610080",
    "end": "612660"
  },
  {
    "text": "reduce tasks",
    "start": "612660",
    "end": "615120"
  },
  {
    "text": "each map test cure will produce some",
    "start": "615120",
    "end": "617459"
  },
  {
    "text": "intermediate objects and these will get",
    "start": "617459",
    "end": "619920"
  },
  {
    "text": "stored and raise shared memory objects",
    "start": "619920",
    "end": "621779"
  },
  {
    "text": "store",
    "start": "621779",
    "end": "622500"
  },
  {
    "text": "and Rey will also handle spilling these",
    "start": "622500",
    "end": "624540"
  },
  {
    "text": "to disc as necessary",
    "start": "624540",
    "end": "627740"
  },
  {
    "text": "Rey also handles the transfer of objects",
    "start": "628260",
    "end": "630600"
  },
  {
    "text": "between notes through its distributed",
    "start": "630600",
    "end": "632640"
  },
  {
    "text": "Object Store so here as the reduced task",
    "start": "632640",
    "end": "635220"
  },
  {
    "text": "is scheduled on the other node we're",
    "start": "635220",
    "end": "637140"
  },
  {
    "text": "going to transfer all of the map outputs",
    "start": "637140",
    "end": "639300"
  },
  {
    "text": "over to it where they could be",
    "start": "639300",
    "end": "641160"
  },
  {
    "text": "aggregated by the final reduce task",
    "start": "641160",
    "end": "644459"
  },
  {
    "text": "so that was a high level overview of the",
    "start": "644459",
    "end": "646620"
  },
  {
    "text": "different components involved in Shuffle",
    "start": "646620",
    "end": "648300"
  },
  {
    "text": "on Ray",
    "start": "648300",
    "end": "649860"
  },
  {
    "text": "and next we'll talk about how",
    "start": "649860",
    "end": "652380"
  },
  {
    "text": "the shuffle is actually implemented in",
    "start": "652380",
    "end": "654899"
  },
  {
    "text": "Python",
    "start": "654899",
    "end": "657300"
  },
  {
    "text": "so the simplest way to implement a",
    "start": "657300",
    "end": "659700"
  },
  {
    "text": "shuffle basically looks like the",
    "start": "659700",
    "end": "661380"
  },
  {
    "text": "mapreduce program that I showed earlier",
    "start": "661380",
    "end": "663240"
  },
  {
    "text": "so here what we're doing is actually",
    "start": "663240",
    "end": "665519"
  },
  {
    "text": "taking the ray core Primitives of tasks",
    "start": "665519",
    "end": "667740"
  },
  {
    "text": "and objects to create this dag which",
    "start": "667740",
    "end": "670560"
  },
  {
    "text": "tells Ray kind of what the dependencies",
    "start": "670560",
    "end": "672180"
  },
  {
    "text": "are between tasks",
    "start": "672180",
    "end": "674760"
  },
  {
    "text": "so here we have one map task for each",
    "start": "674760",
    "end": "677160"
  },
  {
    "text": "input partition of the data set",
    "start": "677160",
    "end": "679320"
  },
  {
    "text": "and each map task will produce one",
    "start": "679320",
    "end": "681360"
  },
  {
    "text": "output for each reduced task",
    "start": "681360",
    "end": "683399"
  },
  {
    "text": "and then of course we submit a reduced",
    "start": "683399",
    "end": "685920"
  },
  {
    "text": "stage that Aggregates these results",
    "start": "685920",
    "end": "688500"
  },
  {
    "text": "so there are actually a lot of different",
    "start": "688500",
    "end": "690240"
  },
  {
    "text": "ways to implement a shuffle algorithm",
    "start": "690240",
    "end": "692160"
  },
  {
    "text": "and this is a pretty active area of",
    "start": "692160",
    "end": "693839"
  },
  {
    "text": "research and development so you don't",
    "start": "693839",
    "end": "695820"
  },
  {
    "text": "necessarily need to follow all of the",
    "start": "695820",
    "end": "697680"
  },
  {
    "text": "details of the algorithms that I'll show",
    "start": "697680",
    "end": "699480"
  },
  {
    "text": "next but you can take a look at the",
    "start": "699480",
    "end": "701940"
  },
  {
    "text": "paper Linked In the QR code",
    "start": "701940",
    "end": "704220"
  },
  {
    "text": "which is the EXO Shuffle white paper",
    "start": "704220",
    "end": "707640"
  },
  {
    "text": "so a lot of the algorithms that people",
    "start": "707640",
    "end": "709500"
  },
  {
    "text": "have designed are optimized to improve i",
    "start": "709500",
    "end": "712079"
  },
  {
    "text": "o efficiency so usually what this looks",
    "start": "712079",
    "end": "714660"
  },
  {
    "text": "like is taking these small blocks and",
    "start": "714660",
    "end": "717240"
  },
  {
    "text": "merging them into larger blocks that can",
    "start": "717240",
    "end": "719700"
  },
  {
    "text": "be written out as larger files or larger",
    "start": "719700",
    "end": "722100"
  },
  {
    "text": "blocks over the network",
    "start": "722100",
    "end": "724320"
  },
  {
    "text": "here's another variation called",
    "start": "724320",
    "end": "726180"
  },
  {
    "text": "push-based Shuffle where we push the map",
    "start": "726180",
    "end": "728760"
  },
  {
    "text": "outputs directly over the network and",
    "start": "728760",
    "end": "730920"
  },
  {
    "text": "then merge them on the reduced side",
    "start": "730920",
    "end": "733680"
  },
  {
    "text": "so I want to stress here that actually",
    "start": "733680",
    "end": "735600"
  },
  {
    "text": "all of these algorithms were designed",
    "start": "735600",
    "end": "737339"
  },
  {
    "text": "and implemented as part of other",
    "start": "737339",
    "end": "738959"
  },
  {
    "text": "monolithic Shuffle systems but the cool",
    "start": "738959",
    "end": "741779"
  },
  {
    "text": "thing that we found is that by using",
    "start": "741779",
    "end": "744180"
  },
  {
    "text": "raycore directly we could actually",
    "start": "744180",
    "end": "746100"
  },
  {
    "text": "Implement a lot of the same basic",
    "start": "746100",
    "end": "747779"
  },
  {
    "text": "algorithms but without having to rebuild",
    "start": "747779",
    "end": "749760"
  },
  {
    "text": "an entire Shuffle system",
    "start": "749760",
    "end": "753079"
  },
  {
    "text": "and the difference between these Shuffle",
    "start": "753480",
    "end": "755399"
  },
  {
    "text": "algorithms is actually pretty huge so",
    "start": "755399",
    "end": "757860"
  },
  {
    "text": "this is looking just at simple versus",
    "start": "757860",
    "end": "759480"
  },
  {
    "text": "push-based random shuffle I implemented",
    "start": "759480",
    "end": "761880"
  },
  {
    "text": "on top of Ray and on the left hand side",
    "start": "761880",
    "end": "764339"
  },
  {
    "text": "we have",
    "start": "764339",
    "end": "765600"
  },
  {
    "text": "the driver memory required to run the",
    "start": "765600",
    "end": "768360"
  },
  {
    "text": "application and you can see that the",
    "start": "768360",
    "end": "770459"
  },
  {
    "text": "simple Shuffle actually runs out of",
    "start": "770459",
    "end": "772079"
  },
  {
    "text": "memory after about two terabytes of data",
    "start": "772079",
    "end": "774660"
  },
  {
    "text": "and that's because simple Shuffle",
    "start": "774660",
    "end": "776459"
  },
  {
    "text": "produces many more intermediate blocks",
    "start": "776459",
    "end": "778800"
  },
  {
    "text": "and this is adding a lot of metadata",
    "start": "778800",
    "end": "780779"
  },
  {
    "text": "overhead to the system",
    "start": "780779",
    "end": "782940"
  },
  {
    "text": "on the right hand side we have the",
    "start": "782940",
    "end": "785160"
  },
  {
    "text": "overall run time",
    "start": "785160",
    "end": "787320"
  },
  {
    "text": "and you can see that these perform about",
    "start": "787320",
    "end": "789180"
  },
  {
    "text": "the same after about 500 gigabytes",
    "start": "789180",
    "end": "792240"
  },
  {
    "text": "and that push-based shuffle continues to",
    "start": "792240",
    "end": "794339"
  },
  {
    "text": "scale past that",
    "start": "794339",
    "end": "796260"
  },
  {
    "text": "so in data sets it's actually pretty",
    "start": "796260",
    "end": "798180"
  },
  {
    "text": "simple to choose between these different",
    "start": "798180",
    "end": "799800"
  },
  {
    "text": "algorithms all you have to do is just",
    "start": "799800",
    "end": "802440"
  },
  {
    "text": "pass a flag into your program",
    "start": "802440",
    "end": "804560"
  },
  {
    "text": "and in the future we'll also look at how",
    "start": "804560",
    "end": "807240"
  },
  {
    "text": "we can automatically choose the best",
    "start": "807240",
    "end": "808800"
  },
  {
    "text": "algorithm for your application",
    "start": "808800",
    "end": "812180"
  },
  {
    "text": "so it's actually pretty easy and now we",
    "start": "813180",
    "end": "816240"
  },
  {
    "text": "can also look at like how we can",
    "start": "816240",
    "end": "818100"
  },
  {
    "text": "actually Implement these in Python so",
    "start": "818100",
    "end": "821100"
  },
  {
    "text": "I'll just walk through a simple example",
    "start": "821100",
    "end": "822660"
  },
  {
    "text": "of a simple Shuffle",
    "start": "822660",
    "end": "825300"
  },
  {
    "text": "so the parameters here are M for the",
    "start": "825300",
    "end": "828000"
  },
  {
    "text": "number of map tasks and R for the number",
    "start": "828000",
    "end": "830279"
  },
  {
    "text": "of reduced tasks",
    "start": "830279",
    "end": "833240"
  },
  {
    "text": "so first we'll submit one map test for",
    "start": "833279",
    "end": "835620"
  },
  {
    "text": "each input partition of the data set",
    "start": "835620",
    "end": "838079"
  },
  {
    "text": "and each map task here is actually going",
    "start": "838079",
    "end": "840360"
  },
  {
    "text": "to return a list of object riffs and so",
    "start": "840360",
    "end": "842880"
  },
  {
    "text": "these object refs are kind of Futures",
    "start": "842880",
    "end": "844740"
  },
  {
    "text": "that can that will point to the eventual",
    "start": "844740",
    "end": "846720"
  },
  {
    "text": "value of the map task",
    "start": "846720",
    "end": "849899"
  },
  {
    "text": "and so all map out here is actually",
    "start": "849899",
    "end": "851940"
  },
  {
    "text": "going to be a nested list of object",
    "start": "851940",
    "end": "853800"
  },
  {
    "text": "riffs which we can now use to pass to",
    "start": "853800",
    "end": "856380"
  },
  {
    "text": "the reduce tasks",
    "start": "856380",
    "end": "858959"
  },
  {
    "text": "so we'll take one output from each of",
    "start": "858959",
    "end": "861420"
  },
  {
    "text": "the map tasks and pass this to a reduced",
    "start": "861420",
    "end": "863579"
  },
  {
    "text": "task and this tells Ray that we can't",
    "start": "863579",
    "end": "865800"
  },
  {
    "text": "run this reduced task until all of those",
    "start": "865800",
    "end": "867720"
  },
  {
    "text": "map outputs are ready and local to the",
    "start": "867720",
    "end": "869880"
  },
  {
    "text": "reduced worker",
    "start": "869880",
    "end": "871320"
  },
  {
    "text": "so in between these steps Ray will also",
    "start": "871320",
    "end": "873779"
  },
  {
    "text": "spill and restore the objects as needed",
    "start": "873779",
    "end": "875639"
  },
  {
    "text": "and also transfer them across the",
    "start": "875639",
    "end": "877380"
  },
  {
    "text": "network as needed",
    "start": "877380",
    "end": "880220"
  },
  {
    "text": "so finally we'll repeat this process for",
    "start": "880320",
    "end": "882899"
  },
  {
    "text": "each of the reduced tasks and this will",
    "start": "882899",
    "end": "885060"
  },
  {
    "text": "now now return a list of our object refs",
    "start": "885060",
    "end": "887940"
  },
  {
    "text": "which we can then pass on to another",
    "start": "887940",
    "end": "889620"
  },
  {
    "text": "array application",
    "start": "889620",
    "end": "892639"
  },
  {
    "text": "and that's actually exactly what we do",
    "start": "893040",
    "end": "895019"
  },
  {
    "text": "to implement rate error or data ingest",
    "start": "895019",
    "end": "897899"
  },
  {
    "text": "and rare",
    "start": "897899",
    "end": "899279"
  },
  {
    "text": "so here let's take a look at the actual",
    "start": "899279",
    "end": "901980"
  },
  {
    "text": "code for the example that I showed",
    "start": "901980",
    "end": "903600"
  },
  {
    "text": "earlier where we want to do distributed",
    "start": "903600",
    "end": "905639"
  },
  {
    "text": "data ingest for a training job",
    "start": "905639",
    "end": "908699"
  },
  {
    "text": "so here we're first going to load the",
    "start": "908699",
    "end": "910800"
  },
  {
    "text": "data set into memory from a list of",
    "start": "910800",
    "end": "912720"
  },
  {
    "text": "parquet files on disk",
    "start": "912720",
    "end": "915120"
  },
  {
    "text": "and then we're going to tell data sets",
    "start": "915120",
    "end": "917040"
  },
  {
    "text": "the granularity that we want to execute",
    "start": "917040",
    "end": "918959"
  },
  {
    "text": "the random shuffle at so that could be",
    "start": "918959",
    "end": "921120"
  },
  {
    "text": "the entire data set size or it could be",
    "start": "921120",
    "end": "923160"
  },
  {
    "text": "just one partition of the data set",
    "start": "923160",
    "end": "926959"
  },
  {
    "text": "next we'll actually invoke the random",
    "start": "927000",
    "end": "928980"
  },
  {
    "text": "shuffle",
    "start": "928980",
    "end": "930180"
  },
  {
    "text": "and here the repeat call will give us",
    "start": "930180",
    "end": "932519"
  },
  {
    "text": "back an iterator that Loops over the",
    "start": "932519",
    "end": "934320"
  },
  {
    "text": "data set and that will allow us to",
    "start": "934320",
    "end": "936600"
  },
  {
    "text": "actually pipeline this with a training",
    "start": "936600",
    "end": "938279"
  },
  {
    "text": "step by parallelizing the shuffle",
    "start": "938279",
    "end": "940500"
  },
  {
    "text": "operation with the training execution",
    "start": "940500",
    "end": "943740"
  },
  {
    "text": "and then finally we can take this output",
    "start": "943740",
    "end": "945959"
  },
  {
    "text": "and Shard it across the pool of workers",
    "start": "945959",
    "end": "949019"
  },
  {
    "text": "so I think the cool thing here is that",
    "start": "949019",
    "end": "950940"
  },
  {
    "text": "actually what's making all of this",
    "start": "950940",
    "end": "952500"
  },
  {
    "text": "possible is the fact that all of these",
    "start": "952500",
    "end": "954420"
  },
  {
    "text": "Library calls are using Ray tasks and",
    "start": "954420",
    "end": "956940"
  },
  {
    "text": "object refs under the hood",
    "start": "956940",
    "end": "960139"
  },
  {
    "text": "okay so next I'll hand it over to judge",
    "start": "961019",
    "end": "963540"
  },
  {
    "text": "ring to talk about some of the key Ray",
    "start": "963540",
    "end": "965160"
  },
  {
    "text": "core features that made this work",
    "start": "965160",
    "end": "967019"
  },
  {
    "text": "possible",
    "start": "967019",
    "end": "969440"
  },
  {
    "text": "thanks Stephanie next I will talk about",
    "start": "971040",
    "end": "973560"
  },
  {
    "text": "several key recore features that's power",
    "start": "973560",
    "end": "975480"
  },
  {
    "text": "Shuffle only",
    "start": "975480",
    "end": "978139"
  },
  {
    "text": "first I'm going to talk about scheduling",
    "start": "978600",
    "end": "981959"
  },
  {
    "text": "so in order for the shuffle to be",
    "start": "981959",
    "end": "983639"
  },
  {
    "text": "performant the read map merge and reduce",
    "start": "983639",
    "end": "985800"
  },
  {
    "text": "task needs to be scheduled in a certain",
    "start": "985800",
    "end": "987779"
  },
  {
    "text": "way",
    "start": "987779",
    "end": "988860"
  },
  {
    "text": "specifically there are two requirements",
    "start": "988860",
    "end": "990779"
  },
  {
    "text": "first we want to balance the load to",
    "start": "990779",
    "end": "993300"
  },
  {
    "text": "improve the cluster utilization and",
    "start": "993300",
    "end": "994980"
  },
  {
    "text": "avoid data skew",
    "start": "994980",
    "end": "997139"
  },
  {
    "text": "second we want to reduce data movement",
    "start": "997139",
    "end": "999420"
  },
  {
    "text": "across nodes",
    "start": "999420",
    "end": "1000980"
  },
  {
    "text": "now let's see how different race",
    "start": "1000980",
    "end": "1002660"
  },
  {
    "text": "scheduling strategies can be used to",
    "start": "1002660",
    "end": "1004519"
  },
  {
    "text": "meet these requirements",
    "start": "1004519",
    "end": "1006740"
  },
  {
    "text": "so the first scheduling strategy is for",
    "start": "1006740",
    "end": "1008779"
  },
  {
    "text": "scheduling",
    "start": "1008779",
    "end": "1010220"
  },
  {
    "text": "so here we have four red tasks that",
    "start": "1010220",
    "end": "1012560"
  },
  {
    "text": "needs to be scheduled",
    "start": "1012560",
    "end": "1014360"
  },
  {
    "text": "in order to achieve load balancing we",
    "start": "1014360",
    "end": "1016579"
  },
  {
    "text": "want to spread this retask across the",
    "start": "1016579",
    "end": "1018440"
  },
  {
    "text": "Intel cluster so each node loads equal",
    "start": "1018440",
    "end": "1020839"
  },
  {
    "text": "amount of Shuffle data",
    "start": "1020839",
    "end": "1023540"
  },
  {
    "text": "this is how you can do it in Code by",
    "start": "1023540",
    "end": "1025339"
  },
  {
    "text": "specifying the spread scaling strategy",
    "start": "1025339",
    "end": "1027260"
  },
  {
    "text": "when submitting your rate tasks",
    "start": "1027260",
    "end": "1030980"
  },
  {
    "text": "now let's see how these four tasks are",
    "start": "1030980",
    "end": "1033740"
  },
  {
    "text": "are scheduled in a cluster of three",
    "start": "1033740",
    "end": "1035418"
  },
  {
    "text": "nodes",
    "start": "1035419",
    "end": "1036319"
  },
  {
    "text": "with Sprint scheduling",
    "start": "1036319",
    "end": "1038360"
  },
  {
    "text": "so the first risk task will go to the",
    "start": "1038360",
    "end": "1040220"
  },
  {
    "text": "first node",
    "start": "1040220",
    "end": "1041240"
  },
  {
    "text": "and the secondary task is scheduled on",
    "start": "1041240",
    "end": "1043280"
  },
  {
    "text": "the second node and the third task on",
    "start": "1043280",
    "end": "1044900"
  },
  {
    "text": "the third node",
    "start": "1044900",
    "end": "1046100"
  },
  {
    "text": "the first read task go back to the first",
    "start": "1046100",
    "end": "1048199"
  },
  {
    "text": "node as you can see the read tasks they",
    "start": "1048199",
    "end": "1050419"
  },
  {
    "text": "are spread among all three nodes in a",
    "start": "1050419",
    "end": "1052100"
  },
  {
    "text": "round robbing fashion",
    "start": "1052100",
    "end": "1055000"
  },
  {
    "text": "the second scheduling strategy is",
    "start": "1055220",
    "end": "1056900"
  },
  {
    "text": "located with our schedule",
    "start": "1056900",
    "end": "1058940"
  },
  {
    "text": "as an example here we want to schedule a",
    "start": "1058940",
    "end": "1061220"
  },
  {
    "text": "map task that processes data loaded by",
    "start": "1061220",
    "end": "1063559"
  },
  {
    "text": "its Upstream read task",
    "start": "1063559",
    "end": "1066140"
  },
  {
    "text": "we want to schedule the map task to",
    "start": "1066140",
    "end": "1068360"
  },
  {
    "text": "where the inputs are to avoid data",
    "start": "1068360",
    "end": "1070220"
  },
  {
    "text": "movement",
    "start": "1070220",
    "end": "1072080"
  },
  {
    "text": "this is how you can do it in code",
    "start": "1072080",
    "end": "1074419"
  },
  {
    "text": "so unlike the spread scheduling you",
    "start": "1074419",
    "end": "1076580"
  },
  {
    "text": "don't need to explicitly specify",
    "start": "1076580",
    "end": "1077960"
  },
  {
    "text": "allocated with our scheduling strategy",
    "start": "1077960",
    "end": "1079460"
  },
  {
    "text": "or submitting tasks the rate will",
    "start": "1079460",
    "end": "1081380"
  },
  {
    "text": "automatically do that based on the",
    "start": "1081380",
    "end": "1082940"
  },
  {
    "text": "location information of input objects so",
    "start": "1082940",
    "end": "1085820"
  },
  {
    "text": "by default risk schedules tasks to where",
    "start": "1085820",
    "end": "1087980"
  },
  {
    "text": "most inputs are",
    "start": "1087980",
    "end": "1090140"
  },
  {
    "text": "now let's see what if we don't have",
    "start": "1090140",
    "end": "1091640"
  },
  {
    "text": "locality we are scheduling",
    "start": "1091640",
    "end": "1093679"
  },
  {
    "text": "so the real task runs on the first node",
    "start": "1093679",
    "end": "1095720"
  },
  {
    "text": "and it saves its output to the local",
    "start": "1095720",
    "end": "1097580"
  },
  {
    "text": "in-memory Block store",
    "start": "1097580",
    "end": "1099740"
  },
  {
    "text": "and the map task runs on a different",
    "start": "1099740",
    "end": "1101539"
  },
  {
    "text": "node",
    "start": "1101539",
    "end": "1102559"
  },
  {
    "text": "as we can see if the map task is",
    "start": "1102559",
    "end": "1104539"
  },
  {
    "text": "scheduled onto a different node then the",
    "start": "1104539",
    "end": "1107059"
  },
  {
    "text": "data needs to be moved across the",
    "start": "1107059",
    "end": "1109220"
  },
  {
    "text": "network which is slow",
    "start": "1109220",
    "end": "1112039"
  },
  {
    "text": "on the other hand if the map task is",
    "start": "1112039",
    "end": "1114320"
  },
  {
    "text": "scheduled on the same node as a retask",
    "start": "1114320",
    "end": "1116059"
  },
  {
    "text": "due to data locality then no data",
    "start": "1116059",
    "end": "1118400"
  },
  {
    "text": "movement is needed",
    "start": "1118400",
    "end": "1121179"
  },
  {
    "text": "so the last scheduling strategy I want",
    "start": "1122480",
    "end": "1124100"
  },
  {
    "text": "to talk here is another affiliency",
    "start": "1124100",
    "end": "1125240"
  },
  {
    "text": "scheduling",
    "start": "1125240",
    "end": "1127160"
  },
  {
    "text": "so here we want to schedule two merge",
    "start": "1127160",
    "end": "1129200"
  },
  {
    "text": "tasks and one reduce task",
    "start": "1129200",
    "end": "1131900"
  },
  {
    "text": "so the goal we want to we want to",
    "start": "1131900",
    "end": "1134059"
  },
  {
    "text": "collocate to the merge task and reduce",
    "start": "1134059",
    "end": "1135559"
  },
  {
    "text": "task so that the reduced task can get",
    "start": "1135559",
    "end": "1137720"
  },
  {
    "text": "its output of its Upstream merge tasks",
    "start": "1137720",
    "end": "1139940"
  },
  {
    "text": "without data movement",
    "start": "1139940",
    "end": "1143019"
  },
  {
    "text": "so let's say if we don't have another",
    "start": "1143059",
    "end": "1144799"
  },
  {
    "text": "Affinity scheduling then the two merge",
    "start": "1144799",
    "end": "1147260"
  },
  {
    "text": "tasks may run on two different nodes",
    "start": "1147260",
    "end": "1149299"
  },
  {
    "text": "then no matter where the reduced test",
    "start": "1149299",
    "end": "1150980"
  },
  {
    "text": "score some data movement must happen",
    "start": "1150980",
    "end": "1155140"
  },
  {
    "text": "so the solution is using node Affinity",
    "start": "1156200",
    "end": "1158120"
  },
  {
    "text": "scheduling strategy which limits which",
    "start": "1158120",
    "end": "1160039"
  },
  {
    "text": "node a task can run",
    "start": "1160039",
    "end": "1162799"
  },
  {
    "text": "so this is the code how you can do it",
    "start": "1162799",
    "end": "1164600"
  },
  {
    "text": "first we Define a node Affinity",
    "start": "1164600",
    "end": "1166100"
  },
  {
    "text": "scheduling strategy with a Target node",
    "start": "1166100",
    "end": "1168620"
  },
  {
    "text": "and then you use that strategy when",
    "start": "1168620",
    "end": "1170480"
  },
  {
    "text": "submitting your task so one thing to",
    "start": "1170480",
    "end": "1172580"
  },
  {
    "text": "notice here is like we specify soft",
    "start": "1172580",
    "end": "1174260"
  },
  {
    "text": "equals to two when defining a strategy",
    "start": "1174260",
    "end": "1176480"
  },
  {
    "text": "which means like we can tolerate the",
    "start": "1176480",
    "end": "1178460"
  },
  {
    "text": "target note failure by running the task",
    "start": "1178460",
    "end": "1180799"
  },
  {
    "text": "somewhere else",
    "start": "1180799",
    "end": "1183200"
  },
  {
    "text": "so let's go back to the example with",
    "start": "1183200",
    "end": "1185179"
  },
  {
    "text": "another Affinity scheduling the merge",
    "start": "1185179",
    "end": "1187039"
  },
  {
    "text": "and the reduce test they are guaranteed",
    "start": "1187039",
    "end": "1189080"
  },
  {
    "text": "to run on the same node",
    "start": "1189080",
    "end": "1192020"
  },
  {
    "text": "so as you can see once they are",
    "start": "1192020",
    "end": "1193640"
  },
  {
    "text": "collocated no data movement is needed to",
    "start": "1193640",
    "end": "1196520"
  },
  {
    "text": "run the reduce task",
    "start": "1196520",
    "end": "1199360"
  },
  {
    "text": "so the next great feature I want to talk",
    "start": "1200900",
    "end": "1203000"
  },
  {
    "text": "about is oblique spelling which enables",
    "start": "1203000",
    "end": "1204980"
  },
  {
    "text": "out of core processing",
    "start": "1204980",
    "end": "1207020"
  },
  {
    "text": "so this is the animation showing like",
    "start": "1207020",
    "end": "1208880"
  },
  {
    "text": "office spilling happens when a running",
    "start": "1208880",
    "end": "1211100"
  },
  {
    "text": "task wants to create some object but the",
    "start": "1211100",
    "end": "1213140"
  },
  {
    "text": "local Object Store is full",
    "start": "1213140",
    "end": "1215000"
  },
  {
    "text": "so several things about obviously so",
    "start": "1215000",
    "end": "1217280"
  },
  {
    "text": "object spinning is a process of spilling",
    "start": "1217280",
    "end": "1219200"
  },
  {
    "text": "real objects to the external storage to",
    "start": "1219200",
    "end": "1221539"
  },
  {
    "text": "make room for new options",
    "start": "1221539",
    "end": "1223580"
  },
  {
    "text": "it essentially makes shuffling larger",
    "start": "1223580",
    "end": "1225500"
  },
  {
    "text": "than memory data set possible",
    "start": "1225500",
    "end": "1228200"
  },
  {
    "text": "so for the spirit of objects they are",
    "start": "1228200",
    "end": "1231020"
  },
  {
    "text": "restored when needed",
    "start": "1231020",
    "end": "1232700"
  },
  {
    "text": "last as an optimization small objects",
    "start": "1232700",
    "end": "1235580"
  },
  {
    "text": "they are fused into a single file for",
    "start": "1235580",
    "end": "1237440"
  },
  {
    "text": "performance",
    "start": "1237440",
    "end": "1239860"
  },
  {
    "text": "so the last great feature I want to talk",
    "start": "1240740",
    "end": "1242660"
  },
  {
    "text": "here is for tolerance Ray has two",
    "start": "1242660",
    "end": "1245179"
  },
  {
    "text": "mechanisms to provide four tolerance to",
    "start": "1245179",
    "end": "1247400"
  },
  {
    "text": "node failures",
    "start": "1247400",
    "end": "1248960"
  },
  {
    "text": "the first is test retry which will run",
    "start": "1248960",
    "end": "1252140"
  },
  {
    "text": "the fair task on other nodes",
    "start": "1252140",
    "end": "1254900"
  },
  {
    "text": "the second is the lineage reconstruction",
    "start": "1254900",
    "end": "1258200"
  },
  {
    "text": "which is the mechanism to automatically",
    "start": "1258200",
    "end": "1260059"
  },
  {
    "text": "reconstruct objects lost from",
    "start": "1260059",
    "end": "1261799"
  },
  {
    "text": "distributed memory by re-excluding the",
    "start": "1261799",
    "end": "1263960"
  },
  {
    "text": "object's lineage basically the task",
    "start": "1263960",
    "end": "1265820"
  },
  {
    "text": "graph that created the object originally",
    "start": "1265820",
    "end": "1268460"
  },
  {
    "text": "now let's see them in action here we",
    "start": "1268460",
    "end": "1270919"
  },
  {
    "text": "have a tag with two map tasks and one",
    "start": "1270919",
    "end": "1272840"
  },
  {
    "text": "merge task",
    "start": "1272840",
    "end": "1274460"
  },
  {
    "text": "and now the merge task is running and it",
    "start": "1274460",
    "end": "1276919"
  },
  {
    "text": "emerges the output of map task square",
    "start": "1276919",
    "end": "1279020"
  },
  {
    "text": "and the map task 2. now let's say the",
    "start": "1279020",
    "end": "1281539"
  },
  {
    "text": "first node first",
    "start": "1281539",
    "end": "1284059"
  },
  {
    "text": "due to task retry array we will try to",
    "start": "1284059",
    "end": "1286880"
  },
  {
    "text": "rerun the merge task on a different node",
    "start": "1286880",
    "end": "1288620"
  },
  {
    "text": "now let's say it's a certain node",
    "start": "1288620",
    "end": "1290840"
  },
  {
    "text": "in order to run the merge task we needed",
    "start": "1290840",
    "end": "1292760"
  },
  {
    "text": "output of map Task 1 and map task 2. but",
    "start": "1292760",
    "end": "1295460"
  },
  {
    "text": "the output of map task Y is also lost",
    "start": "1295460",
    "end": "1297620"
  },
  {
    "text": "due to the node failure so Ray will try",
    "start": "1297620",
    "end": "1300620"
  },
  {
    "text": "to reconstruct the object by re-rounding",
    "start": "1300620",
    "end": "1302419"
  },
  {
    "text": "map task 1.",
    "start": "1302419",
    "end": "1304340"
  },
  {
    "text": "and for the output of map task 2 is",
    "start": "1304340",
    "end": "1306440"
  },
  {
    "text": "still available in the cluster so all we",
    "start": "1306440",
    "end": "1308360"
  },
  {
    "text": "need to do is just copy Adobe and after",
    "start": "1308360",
    "end": "1310700"
  },
  {
    "text": "that the merge task is ready to run",
    "start": "1310700",
    "end": "1312740"
  },
  {
    "text": "again",
    "start": "1312740",
    "end": "1314919"
  },
  {
    "text": "so here is a rare example so this bar",
    "start": "1315320",
    "end": "1317720"
  },
  {
    "text": "chart shows the runtime of a one",
    "start": "1317720",
    "end": "1319700"
  },
  {
    "text": "terabyte Shuffle chaos test with",
    "start": "1319700",
    "end": "1321740"
  },
  {
    "text": "different number of injected failures as",
    "start": "1321740",
    "end": "1324200"
  },
  {
    "text": "you can see the runtime is not linear to",
    "start": "1324200",
    "end": "1326240"
  },
  {
    "text": "the number of third nodes which means",
    "start": "1326240",
    "end": "1329000"
  },
  {
    "text": "like we don't need to restart a shuffle",
    "start": "1329000",
    "end": "1330500"
  },
  {
    "text": "from beginning when failure happens",
    "start": "1330500",
    "end": "1334240"
  },
  {
    "text": "so to summarize",
    "start": "1335179",
    "end": "1337460"
  },
  {
    "text": "with raid 2.0 it supports shuffling at",
    "start": "1337460",
    "end": "1340400"
  },
  {
    "text": "least 100 terabytes of data",
    "start": "1340400",
    "end": "1343280"
  },
  {
    "text": "and it is now available through",
    "start": "1343280",
    "end": "1345020"
  },
  {
    "text": "redanasset and array air",
    "start": "1345020",
    "end": "1347900"
  },
  {
    "text": "so in the future we will focus on",
    "start": "1347900",
    "end": "1349820"
  },
  {
    "text": "greatest scalability automatic out of",
    "start": "1349820",
    "end": "1351799"
  },
  {
    "text": "memory handling and auto scaling among",
    "start": "1351799",
    "end": "1354200"
  },
  {
    "text": "other features",
    "start": "1354200",
    "end": "1356799"
  },
  {
    "text": "so here are the links to the Red Data",
    "start": "1357679",
    "end": "1360080"
  },
  {
    "text": "Center talk and the original Excel",
    "start": "1360080",
    "end": "1361460"
  },
  {
    "text": "Shuffle paper so check them out if you",
    "start": "1361460",
    "end": "1363740"
  },
  {
    "text": "are interested",
    "start": "1363740",
    "end": "1364820"
  },
  {
    "text": "and finally thanks for attending the",
    "start": "1364820",
    "end": "1366919"
  },
  {
    "text": "talk",
    "start": "1366919",
    "end": "1369100"
  },
  {
    "text": "[Applause]",
    "start": "1369320",
    "end": "1373100"
  },
  {
    "text": "if you have any questions I think we",
    "start": "1373100",
    "end": "1374780"
  },
  {
    "text": "still have some time",
    "start": "1374780",
    "end": "1377559"
  },
  {
    "text": "yeah if you raise your hand I think",
    "start": "1378140",
    "end": "1380179"
  },
  {
    "text": "Thomas will be over with the mic",
    "start": "1380179",
    "end": "1383740"
  },
  {
    "text": "I think hi um thanks for the talk",
    "start": "1387500",
    "end": "1390380"
  },
  {
    "text": "um",
    "start": "1390380",
    "end": "1391039"
  },
  {
    "text": "I I was just curious we're speaking",
    "start": "1391039",
    "end": "1393620"
  },
  {
    "text": "about node affinity and you talk about",
    "start": "1393620",
    "end": "1395780"
  },
  {
    "text": "scheduling for instance two map tasks",
    "start": "1395780",
    "end": "1397880"
  },
  {
    "text": "together that will be whose output will",
    "start": "1397880",
    "end": "1400640"
  },
  {
    "text": "be consumed by",
    "start": "1400640",
    "end": "1402980"
  },
  {
    "text": "um by the same reduced task but I",
    "start": "1402980",
    "end": "1404840"
  },
  {
    "text": "suppose when you create the map tasks",
    "start": "1404840",
    "end": "1406880"
  },
  {
    "text": "you don't yet know who's going to be",
    "start": "1406880",
    "end": "1408500"
  },
  {
    "text": "their consumer",
    "start": "1408500",
    "end": "1410360"
  },
  {
    "text": "um are you yeah how",
    "start": "1410360",
    "end": "1412460"
  },
  {
    "text": "how do you make that work",
    "start": "1412460",
    "end": "1415039"
  },
  {
    "text": "uh yeah so",
    "start": "1415039",
    "end": "1418539"
  },
  {
    "text": "so yeah so for the map task we don't use",
    "start": "1419480",
    "end": "1422000"
  },
  {
    "text": "another Affinity it's like only between",
    "start": "1422000",
    "end": "1423919"
  },
  {
    "text": "the the merge task and the reduce tag in",
    "start": "1423919",
    "end": "1426980"
  },
  {
    "text": "the push-based shuffle case",
    "start": "1426980",
    "end": "1429320"
  },
  {
    "text": "because like I for the first shutter",
    "start": "1429320",
    "end": "1431179"
  },
  {
    "text": "case the merge task article is only",
    "start": "1431179",
    "end": "1433340"
  },
  {
    "text": "consumed by one reducer so it's not like",
    "start": "1433340",
    "end": "1435860"
  },
  {
    "text": "by multiple reducer so that's why we can",
    "start": "1435860",
    "end": "1437900"
  },
  {
    "text": "have the collocation",
    "start": "1437900",
    "end": "1440860"
  },
  {
    "text": "hi thanks for the presentation what",
    "start": "1446720",
    "end": "1449539"
  },
  {
    "text": "happens when you exceed the 100",
    "start": "1449539",
    "end": "1452299"
  },
  {
    "text": "terabytes limit that you have up there",
    "start": "1452299",
    "end": "1455960"
  },
  {
    "text": "yeah so right now uh we still have some",
    "start": "1455960",
    "end": "1458840"
  },
  {
    "text": "scalability limitations that we're",
    "start": "1458840",
    "end": "1460880"
  },
  {
    "text": "actively trying to resolve I think the",
    "start": "1460880",
    "end": "1463520"
  },
  {
    "text": "main one right now has to do with the",
    "start": "1463520",
    "end": "1465080"
  },
  {
    "text": "metadata cost still",
    "start": "1465080",
    "end": "1466820"
  },
  {
    "text": "um so you can talk to us offline about",
    "start": "1466820",
    "end": "1468260"
  },
  {
    "text": "that but basically because we're having",
    "start": "1468260",
    "end": "1470360"
  },
  {
    "text": "to deal with all of these small blocks",
    "start": "1470360",
    "end": "1472760"
  },
  {
    "text": "in the system that's actually quite a",
    "start": "1472760",
    "end": "1475159"
  },
  {
    "text": "bit of overhead for the system and so",
    "start": "1475159",
    "end": "1477740"
  },
  {
    "text": "yeah we're thinking about ways to",
    "start": "1477740",
    "end": "1479240"
  },
  {
    "text": "optimize that yeah at the moment it's",
    "start": "1479240",
    "end": "1481640"
  },
  {
    "text": "not an area where we focus a lot of work",
    "start": "1481640",
    "end": "1483559"
  },
  {
    "text": "yet",
    "start": "1483559",
    "end": "1485740"
  },
  {
    "text": "okay okay cool yeah well I think that's",
    "start": "1493880",
    "end": "1497120"
  },
  {
    "text": "it oh yeah",
    "start": "1497120",
    "end": "1500140"
  },
  {
    "text": "some ways",
    "start": "1500559",
    "end": "1503659"
  },
  {
    "text": "have you compared the",
    "start": "1503659",
    "end": "1506480"
  },
  {
    "text": "shuffled performance between this and",
    "start": "1506480",
    "end": "1509360"
  },
  {
    "text": "the spark Shuffle",
    "start": "1509360",
    "end": "1510740"
  },
  {
    "text": "yeah so if you check out the EXO Shuffle",
    "start": "1510740",
    "end": "1512780"
  },
  {
    "text": "white paper you can see some performance",
    "start": "1512780",
    "end": "1514880"
  },
  {
    "text": "numbers between the two",
    "start": "1514880",
    "end": "1516860"
  },
  {
    "text": "um I think with these concept benchmarks",
    "start": "1516860",
    "end": "1518600"
  },
  {
    "text": "it's always a little bit hard to get",
    "start": "1518600",
    "end": "1519919"
  },
  {
    "text": "like a good comparison because there's",
    "start": "1519919",
    "end": "1521419"
  },
  {
    "text": "like a lot of different tuning that you",
    "start": "1521419",
    "end": "1522919"
  },
  {
    "text": "can do but so far the results look I",
    "start": "1522919",
    "end": "1525740"
  },
  {
    "text": "would say pretty comparable",
    "start": "1525740",
    "end": "1528640"
  },
  {
    "text": "[Applause]",
    "start": "1540710",
    "end": "1543940"
  }
]
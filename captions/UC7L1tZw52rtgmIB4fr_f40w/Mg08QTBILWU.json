[
  {
    "text": "yeah the title of today's talk is uh",
    "start": "3080",
    "end": "5120"
  },
  {
    "text": "Beyond fsdp multimodal and model",
    "start": "5120",
    "end": "7439"
  },
  {
    "text": "parallel training with r compil graphs",
    "start": "7439",
    "end": "10400"
  },
  {
    "text": "um my name is am Al Mahi and I'm a",
    "start": "10400",
    "end": "12599"
  },
  {
    "text": "research scientist any scale uh this is",
    "start": "12599",
    "end": "15240"
  },
  {
    "text": "Joint work with our previous colleague",
    "start": "15240",
    "end": "17320"
  },
  {
    "text": "uh yonan",
    "start": "17320",
    "end": "19960"
  },
  {
    "text": "sha so uh we can clearly um notice",
    "start": "22519",
    "end": "26400"
  },
  {
    "text": "recent Trends in large scale",
    "start": "26400",
    "end": "28519"
  },
  {
    "text": "training the first one is the use of",
    "start": "28519",
    "end": "31039"
  },
  {
    "text": "multimodal data such as text image audio",
    "start": "31039",
    "end": "33960"
  },
  {
    "text": "and and",
    "start": "33960",
    "end": "35399"
  },
  {
    "text": "video um in these cases models tend to",
    "start": "35399",
    "end": "38840"
  },
  {
    "text": "have different subm modules for each",
    "start": "38840",
    "end": "40680"
  },
  {
    "text": "modality um this is quite common in",
    "start": "40680",
    "end": "43280"
  },
  {
    "text": "recent Publications and also in the most",
    "start": "43280",
    "end": "46000"
  },
  {
    "text": "recent uh llama 2.3 uh",
    "start": "46000",
    "end": "50079"
  },
  {
    "text": "release um the other trend is the use of",
    "start": "50079",
    "end": "52879"
  },
  {
    "text": "complex parallelism strategies such as",
    "start": "52879",
    "end": "54879"
  },
  {
    "text": "data tensor Pipeline and context",
    "start": "54879",
    "end": "57399"
  },
  {
    "text": "parallelism",
    "start": "57399",
    "end": "60399"
  },
  {
    "text": "um and complex combinations of them uh",
    "start": "60719",
    "end": "63039"
  },
  {
    "text": "3D 4D or even",
    "start": "63039",
    "end": "65680"
  },
  {
    "text": "5D and final trend is uh the use of",
    "start": "65680",
    "end": "68799"
  },
  {
    "text": "massive INF",
    "start": "68799",
    "end": "70320"
  },
  {
    "text": "infrastructures uh which involves",
    "start": "70320",
    "end": "72040"
  },
  {
    "text": "thousands of gpus for uh extended",
    "start": "72040",
    "end": "74520"
  },
  {
    "text": "periods of",
    "start": "74520",
    "end": "77000"
  },
  {
    "text": "time now um the current libraries for",
    "start": "77080",
    "end": "80360"
  },
  {
    "text": "distributed computing actually favors",
    "start": "80360",
    "end": "82320"
  },
  {
    "text": "homogeneous training what we mean by",
    "start": "82320",
    "end": "84360"
  },
  {
    "text": "that is the case where each process",
    "start": "84360",
    "end": "87000"
  },
  {
    "text": "executes the same",
    "start": "87000",
    "end": "88640"
  },
  {
    "text": "program now this has some limitations",
    "start": "88640",
    "end": "92200"
  },
  {
    "text": "and the first one we can describe as",
    "start": "92200",
    "end": "94320"
  },
  {
    "text": "limited models meaning that it's",
    "start": "94320",
    "end": "96920"
  },
  {
    "text": "actually limited to homogenous models",
    "start": "96920",
    "end": "98799"
  },
  {
    "text": "like sequential ones which means that um",
    "start": "98799",
    "end": "101880"
  },
  {
    "text": "it can be suboptimal for hetrogeneous",
    "start": "101880",
    "end": "103759"
  },
  {
    "text": "models like the multimodal ones we",
    "start": "103759",
    "end": "105719"
  },
  {
    "text": "discussed before and uh it's actually",
    "start": "105719",
    "end": "108560"
  },
  {
    "text": "difficult to paralyze non-sequential",
    "start": "108560",
    "end": "111399"
  },
  {
    "text": "architectures the second limitations we",
    "start": "111399",
    "end": "114079"
  },
  {
    "text": "describe it as restrictive",
    "start": "114079",
    "end": "115719"
  },
  {
    "text": "parallelism um these libraries actually",
    "start": "115719",
    "end": "118119"
  },
  {
    "text": "are a great fit for spmd methods such as",
    "start": "118119",
    "end": "120880"
  },
  {
    "text": "fstp um or tensor parallel however it's",
    "start": "120880",
    "end": "124799"
  },
  {
    "text": "really hard to implement npmd methods",
    "start": "124799",
    "end": "127079"
  },
  {
    "text": "like pipeline parallelism where uh and",
    "start": "127079",
    "end": "129920"
  },
  {
    "text": "also it's really hard um uh or actually",
    "start": "129920",
    "end": "133440"
  },
  {
    "text": "it's actually um applies the same",
    "start": "133440",
    "end": "135360"
  },
  {
    "text": "parallelism strategy across all subm",
    "start": "135360",
    "end": "139319"
  },
  {
    "text": "modules uh the third limitation is that",
    "start": "139319",
    "end": "142120"
  },
  {
    "text": "um they actually assume hetrogeneous",
    "start": "142120",
    "end": "143599"
  },
  {
    "text": "clusters where all gpus need to be of",
    "start": "143599",
    "end": "145760"
  },
  {
    "text": "the same",
    "start": "145760",
    "end": "146879"
  },
  {
    "text": "typee and it cannot really utilize",
    "start": "146879",
    "end": "149519"
  },
  {
    "text": "different types of gpus like a10s um l4s",
    "start": "149519",
    "end": "153480"
  },
  {
    "text": "or like kind of mix of",
    "start": "153480",
    "end": "156519"
  },
  {
    "text": "gpus now um that's why um we believe Ray",
    "start": "158040",
    "end": "162080"
  },
  {
    "text": "compiled graphs actually are great for",
    "start": "162080",
    "end": "163879"
  },
  {
    "text": "hetrogeneous",
    "start": "163879",
    "end": "165080"
  },
  {
    "text": "training where different processes can",
    "start": "165080",
    "end": "167720"
  },
  {
    "text": "execute different programs what we mean",
    "start": "167720",
    "end": "170519"
  },
  {
    "text": "by that is that this gives us like the",
    "start": "170519",
    "end": "172200"
  },
  {
    "text": "following um uh uh like advantages the",
    "start": "172200",
    "end": "175680"
  },
  {
    "text": "first one is we can um Implement",
    "start": "175680",
    "end": "178360"
  },
  {
    "text": "flexible model architectures like",
    "start": "178360",
    "end": "179879"
  },
  {
    "text": "multimodel models or nonsequential uh",
    "start": "179879",
    "end": "183560"
  },
  {
    "text": "architectures uh we can easily Implement",
    "start": "183560",
    "end": "186200"
  },
  {
    "text": "mpmd parallelism so it's a great fit for",
    "start": "186200",
    "end": "189200"
  },
  {
    "text": "pipeline parallelism it's easy to",
    "start": "189200",
    "end": "190920"
  },
  {
    "text": "implement complex pipeline schedules",
    "start": "190920",
    "end": "192599"
  },
  {
    "text": "like zero bubble and we can easily apply",
    "start": "192599",
    "end": "195840"
  },
  {
    "text": "multiple parm strategies across our",
    "start": "195840",
    "end": "199879"
  },
  {
    "text": "model finally we can actually utilize",
    "start": "199879",
    "end": "202640"
  },
  {
    "text": "heterogeneous clusters and different",
    "start": "202640",
    "end": "204799"
  },
  {
    "text": "which includes different types of gpus",
    "start": "204799",
    "end": "207000"
  },
  {
    "text": "and basically optimize cost by",
    "start": "207000",
    "end": "208720"
  },
  {
    "text": "Distributing tasks across different",
    "start": "208720",
    "end": "212319"
  },
  {
    "text": "gpus so in this talk I will first give a",
    "start": "212720",
    "end": "216120"
  },
  {
    "text": "quick overview of Ray compil graphs",
    "start": "216120",
    "end": "218360"
  },
  {
    "text": "second I'll talk about an application in",
    "start": "218360",
    "end": "220480"
  },
  {
    "text": "multimol training and finally I'll talk",
    "start": "220480",
    "end": "222319"
  },
  {
    "text": "an application about uh in pipeline",
    "start": "222319",
    "end": "226400"
  },
  {
    "text": "parallelism so um what is Ray compiled",
    "start": "228120",
    "end": "231239"
  },
  {
    "text": "graphs it's basically it creates a",
    "start": "231239",
    "end": "233920"
  },
  {
    "text": "static graph of Ray tasks using an",
    "start": "233920",
    "end": "236640"
  },
  {
    "text": "intuitive like intuitive Ray Corde like",
    "start": "236640",
    "end": "240599"
  },
  {
    "text": "API this helps this is BAS this stat",
    "start": "240599",
    "end": "243599"
  },
  {
    "text": "graph is actually optimized for static",
    "start": "243599",
    "end": "245799"
  },
  {
    "text": "control flows across uh multiple gpus",
    "start": "245799",
    "end": "248879"
  },
  {
    "text": "which is quite common in large scale",
    "start": "248879",
    "end": "250920"
  },
  {
    "text": "training uh uh",
    "start": "250920",
    "end": "253079"
  },
  {
    "text": "jobs second it induces much lower system",
    "start": "253079",
    "end": "255959"
  },
  {
    "text": "overhead than the uh Ray core and that's",
    "start": "255959",
    "end": "259880"
  },
  {
    "text": "because it allocates resources once and",
    "start": "259880",
    "end": "262280"
  },
  {
    "text": "reuses for multiple uh executions and",
    "start": "262280",
    "end": "265880"
  },
  {
    "text": "finally it supports GPU to GPU",
    "start": "265880",
    "end": "267720"
  },
  {
    "text": "communication via nickel",
    "start": "267720",
    "end": "271720"
  },
  {
    "text": "so um here I'm going to give um you know",
    "start": "272080",
    "end": "275160"
  },
  {
    "text": "a quick overview of the compile graphs",
    "start": "275160",
    "end": "277320"
  },
  {
    "text": "API uh in this example I will show how",
    "start": "277320",
    "end": "280720"
  },
  {
    "text": "we can do a forward pass in a three",
    "start": "280720",
    "end": "282440"
  },
  {
    "text": "layer feed forward network uh on",
    "start": "282440",
    "end": "284600"
  },
  {
    "text": "multiple",
    "start": "284600",
    "end": "287000"
  },
  {
    "text": "gpus so the first step here is actually",
    "start": "287000",
    "end": "289680"
  },
  {
    "text": "defining a array actor for each layer so",
    "start": "289680",
    "end": "293240"
  },
  {
    "text": "in the code on the side you can see",
    "start": "293240",
    "end": "297560"
  },
  {
    "text": "um you can see this um block actually",
    "start": "297560",
    "end": "301400"
  },
  {
    "text": "creates uh defines an actor class",
    "start": "301400",
    "end": "303680"
  },
  {
    "text": "creates an actor class for every or for",
    "start": "303680",
    "end": "306400"
  },
  {
    "text": "each",
    "start": "306400",
    "end": "307560"
  },
  {
    "text": "layer the next step is defining um uh an",
    "start": "307560",
    "end": "311479"
  },
  {
    "text": "input to the",
    "start": "311479",
    "end": "313160"
  },
  {
    "text": "graph which is uh which is done by",
    "start": "313160",
    "end": "315759"
  },
  {
    "text": "binding the input node into the first uh",
    "start": "315759",
    "end": "318680"
  },
  {
    "text": "actor forward pass forward",
    "start": "318680",
    "end": "322440"
  },
  {
    "text": "function uh third we Define",
    "start": "322919",
    "end": "325039"
  },
  {
    "text": "communication between actors via",
    "start": "325039",
    "end": "327759"
  },
  {
    "text": "nickel and as you can see here we're",
    "start": "327759",
    "end": "330639"
  },
  {
    "text": "defining uh we're uh annotating the",
    "start": "330639",
    "end": "333360"
  },
  {
    "text": "activations with nickel and then uh we",
    "start": "333360",
    "end": "336280"
  },
  {
    "text": "are uh passing the activation into the",
    "start": "336280",
    "end": "338840"
  },
  {
    "text": "second uh layer or second actor uh",
    "start": "338840",
    "end": "341840"
  },
  {
    "text": "forward",
    "start": "341840",
    "end": "344120"
  },
  {
    "text": "pass finally we're compiling the graph",
    "start": "344120",
    "end": "347199"
  },
  {
    "text": "and then uh executing multiple times on",
    "start": "347199",
    "end": "350440"
  },
  {
    "text": "different uh input",
    "start": "350440",
    "end": "353720"
  },
  {
    "text": "batches so uh now I'll discuss an",
    "start": "355600",
    "end": "358400"
  },
  {
    "text": "application to multimodal Tri",
    "start": "358400",
    "end": "360479"
  },
  {
    "text": "training so uh we're going to focus on a",
    "start": "360479",
    "end": "363199"
  },
  {
    "text": "on a specific case of uh uh multimod",
    "start": "363199",
    "end": "366160"
  },
  {
    "text": "training which is quite common in",
    "start": "366160",
    "end": "367639"
  },
  {
    "text": "practice um it's the contrastive vision",
    "start": "367639",
    "end": "370599"
  },
  {
    "text": "language models like clip so in this",
    "start": "370599",
    "end": "373319"
  },
  {
    "text": "example or in this models uh we",
    "start": "373319",
    "end": "375800"
  },
  {
    "text": "typically have you know two kinds of",
    "start": "375800",
    "end": "377400"
  },
  {
    "text": "encoders um image encoder and text",
    "start": "377400",
    "end": "379720"
  },
  {
    "text": "encoder and uh we encode images and text",
    "start": "379720",
    "end": "382759"
  },
  {
    "text": "in some featur space and then align",
    "start": "382759",
    "end": "385039"
  },
  {
    "text": "their representations by Computing a",
    "start": "385039",
    "end": "386759"
  },
  {
    "text": "similarity Matrix",
    "start": "386759",
    "end": "390000"
  },
  {
    "text": "uh one key not like thing to notice here",
    "start": "390000",
    "end": "392599"
  },
  {
    "text": "is that different modalities have",
    "start": "392599",
    "end": "394520"
  },
  {
    "text": "different compute needs so in this case",
    "start": "394520",
    "end": "397240"
  },
  {
    "text": "the vision and text encoders can have",
    "start": "397240",
    "end": "399160"
  },
  {
    "text": "very different sizes however because of",
    "start": "399160",
    "end": "401560"
  },
  {
    "text": "the training objective we're actually uh",
    "start": "401560",
    "end": "404120"
  },
  {
    "text": "uh the um we're limited by having the",
    "start": "404120",
    "end": "406720"
  },
  {
    "text": "same batch size for both modules or for",
    "start": "406720",
    "end": "409160"
  },
  {
    "text": "both encoders which as a result induces",
    "start": "409160",
    "end": "412360"
  },
  {
    "text": "a significant GPU under",
    "start": "412360",
    "end": "415758"
  },
  {
    "text": "utilization let's try to kind of dig",
    "start": "415879",
    "end": "418639"
  },
  {
    "text": "deep and understand what what do we mean",
    "start": "418639",
    "end": "420360"
  },
  {
    "text": "by GPU and utilization here in clip so",
    "start": "420360",
    "end": "424520"
  },
  {
    "text": "uh in standard libraries like P torch",
    "start": "424520",
    "end": "426319"
  },
  {
    "text": "distributed uh deep speed Megatron uh we",
    "start": "426319",
    "end": "429479"
  },
  {
    "text": "place both encoders on the same",
    "start": "429479",
    "end": "433280"
  },
  {
    "text": "GPU so um what we're going to do here",
    "start": "433960",
    "end": "437039"
  },
  {
    "text": "next is that we're going to compute the",
    "start": "437039",
    "end": "438599"
  },
  {
    "text": "utilized flops uh when training this",
    "start": "438599",
    "end": "441039"
  },
  {
    "text": "model on an a00 machine in this case the",
    "start": "441039",
    "end": "443639"
  },
  {
    "text": "vision encoder is 2.5 times bigger than",
    "start": "443639",
    "end": "445879"
  },
  {
    "text": "the text encoder and again the batch",
    "start": "445879",
    "end": "447960"
  },
  {
    "text": "size is actually the same but but it's",
    "start": "447960",
    "end": "449840"
  },
  {
    "text": "restricted by the vision encoder which",
    "start": "449840",
    "end": "451400"
  },
  {
    "text": "is bigger in",
    "start": "451400",
    "end": "452800"
  },
  {
    "text": "size so in the um in this plot we're",
    "start": "452800",
    "end": "457120"
  },
  {
    "text": "basically showing on the x-axis the",
    "start": "457120",
    "end": "458759"
  },
  {
    "text": "elapse time in in in the training and uh",
    "start": "458759",
    "end": "461879"
  },
  {
    "text": "the the utilized flops for uh uh during",
    "start": "461879",
    "end": "465479"
  },
  {
    "text": "training and we're showing four",
    "start": "465479",
    "end": "467720"
  },
  {
    "text": "different boxes the first box is the uh",
    "start": "467720",
    "end": "470039"
  },
  {
    "text": "utiliz flops for the text forward the",
    "start": "470039",
    "end": "472280"
  },
  {
    "text": "image uh forward the image backward and",
    "start": "472280",
    "end": "474680"
  },
  {
    "text": "the text backward and in the top we're",
    "start": "474680",
    "end": "476680"
  },
  {
    "text": "showing the um Peak uh uh flops for an",
    "start": "476680",
    "end": "480159"
  },
  {
    "text": "a00",
    "start": "480159",
    "end": "482680"
  },
  {
    "text": "machine so we can clearly see that the",
    "start": "483280",
    "end": "485840"
  },
  {
    "text": "GPU is largely",
    "start": "485840",
    "end": "487360"
  },
  {
    "text": "underutilized uh for the uh especially",
    "start": "487360",
    "end": "489720"
  },
  {
    "text": "for the text",
    "start": "489720",
    "end": "492280"
  },
  {
    "text": "encoder now actually this gets even",
    "start": "492800",
    "end": "495800"
  },
  {
    "text": "worse as we uh train on multiple gpus so",
    "start": "495800",
    "end": "498919"
  },
  {
    "text": "um it's typical for standard libraries",
    "start": "498919",
    "end": "500800"
  },
  {
    "text": "to collocate both encoders on on all",
    "start": "500800",
    "end": "503639"
  },
  {
    "text": "gpus and then apply the same parallelism",
    "start": "503639",
    "end": "505919"
  },
  {
    "text": "for both encoders",
    "start": "505919",
    "end": "509319"
  },
  {
    "text": "yeah so um so in this example uh we're",
    "start": "513159",
    "end": "517880"
  },
  {
    "text": "actually training clip or we just",
    "start": "517880",
    "end": "519880"
  },
  {
    "text": "hypothetical example where we train clip",
    "start": "519880",
    "end": "521399"
  },
  {
    "text": "on four gpus and apply the same",
    "start": "521399",
    "end": "523200"
  },
  {
    "text": "parallelism for both the vision uh uh in",
    "start": "523200",
    "end": "526200"
  },
  {
    "text": "yellow and the text in in blue and the",
    "start": "526200",
    "end": "529120"
  },
  {
    "text": "overall overall GPU utilization is",
    "start": "529120",
    "end": "533480"
  },
  {
    "text": "22% now a solution um to improve this GP",
    "start": "533480",
    "end": "537279"
  },
  {
    "text": "utilization is actually to place the um",
    "start": "537279",
    "end": "539800"
  },
  {
    "text": "text encoder on a separate GPU apply no",
    "start": "539800",
    "end": "542279"
  },
  {
    "text": "parallelism to it and then uh um apply",
    "start": "542279",
    "end": "545880"
  },
  {
    "text": "uh place the vision encoder on three",
    "start": "545880",
    "end": "547959"
  },
  {
    "text": "gpus and apply you know some kind of",
    "start": "547959",
    "end": "550320"
  },
  {
    "text": "parameter sharding here and um we with",
    "start": "550320",
    "end": "553800"
  },
  {
    "text": "that we can actually uh improve the GP",
    "start": "553800",
    "end": "555839"
  },
  {
    "text": "utilization up to",
    "start": "555839",
    "end": "558600"
  },
  {
    "text": "30% now um let's really try to",
    "start": "558720",
    "end": "562079"
  },
  {
    "text": "understand what this solution offers",
    "start": "562079",
    "end": "563959"
  },
  {
    "text": "placing encoders on different",
    "start": "563959",
    "end": "566079"
  },
  {
    "text": "gpus now we're taking the the previous",
    "start": "566079",
    "end": "569399"
  },
  {
    "text": "graph but we're just plotting the uh",
    "start": "569399",
    "end": "571360"
  },
  {
    "text": "forward uh uh utilization of the text",
    "start": "571360",
    "end": "574480"
  },
  {
    "text": "and backward of the",
    "start": "574480",
    "end": "576640"
  },
  {
    "text": "text now basically there's two ways to",
    "start": "576640",
    "end": "579560"
  },
  {
    "text": "increase GP",
    "start": "579560",
    "end": "581120"
  },
  {
    "text": "utilization the first one is when we",
    "start": "581120",
    "end": "583839"
  },
  {
    "text": "apply different parm strategies uh we're",
    "start": "583839",
    "end": "586399"
  },
  {
    "text": "basically allowing or untying the batch",
    "start": "586399",
    "end": "588640"
  },
  {
    "text": "sizes between these two encoders and",
    "start": "588640",
    "end": "590880"
  },
  {
    "text": "increasing the batch size for the text",
    "start": "590880",
    "end": "592760"
  },
  {
    "text": "encoder mean meaning that we're going to",
    "start": "592760",
    "end": "594880"
  },
  {
    "text": "push this box up until to reach like",
    "start": "594880",
    "end": "597800"
  },
  {
    "text": "closer to the peak uh flops of the GPU",
    "start": "597800",
    "end": "601519"
  },
  {
    "text": "the second approach is actually to place",
    "start": "601519",
    "end": "603480"
  },
  {
    "text": "the the encoder on a weaker GPU and in",
    "start": "603480",
    "end": "605680"
  },
  {
    "text": "this case we're effectively pushing this",
    "start": "605680",
    "end": "608079"
  },
  {
    "text": "um horizontal line down closer to the um",
    "start": "608079",
    "end": "611680"
  },
  {
    "text": "uh the uh",
    "start": "611680",
    "end": "614760"
  },
  {
    "text": "boxes now let's look um like quickly on",
    "start": "614959",
    "end": "619200"
  },
  {
    "text": "uh how we can actually Implement that in",
    "start": "619200",
    "end": "621200"
  },
  {
    "text": "great compiled graphs we're not going to",
    "start": "621200",
    "end": "623200"
  },
  {
    "text": "go like in a lot of details I'll just",
    "start": "623200",
    "end": "625000"
  },
  {
    "text": "give you a quick overview but here the",
    "start": "625000",
    "end": "627240"
  },
  {
    "text": "general idea is that we in this example",
    "start": "627240",
    "end": "629720"
  },
  {
    "text": "we're going to um uh place the vision",
    "start": "629720",
    "end": "632360"
  },
  {
    "text": "encoder on a on a different node with",
    "start": "632360",
    "end": "634200"
  },
  {
    "text": "four gpus and uh the text encoder on an",
    "start": "634200",
    "end": "637279"
  },
  {
    "text": "L4 uh with a with a single",
    "start": "637279",
    "end": "640200"
  },
  {
    "text": "GPU um and the way we do that in this",
    "start": "640200",
    "end": "643240"
  },
  {
    "text": "code is that like in these like few",
    "start": "643240",
    "end": "645120"
  },
  {
    "text": "lines we Define those actors and and",
    "start": "645120",
    "end": "647519"
  },
  {
    "text": "specify annotate them with the gpus we",
    "start": "647519",
    "end": "649240"
  },
  {
    "text": "want them to be uh scheduled on then",
    "start": "649240",
    "end": "652120"
  },
  {
    "text": "we're going to bind the input and pass",
    "start": "652120",
    "end": "654200"
  },
  {
    "text": "it to all of the um uh workers or actors",
    "start": "654200",
    "end": "658000"
  },
  {
    "text": "that we have next we're going to pass",
    "start": "658000",
    "end": "661000"
  },
  {
    "text": "the activations reduce them from from",
    "start": "661000",
    "end": "663399"
  },
  {
    "text": "the uh vision encoders and send them to",
    "start": "663399",
    "end": "665800"
  },
  {
    "text": "the uh uh text encoder as we can see in",
    "start": "665800",
    "end": "668399"
  },
  {
    "text": "the code next to it then we're going to",
    "start": "668399",
    "end": "671320"
  },
  {
    "text": "take the activations from the text",
    "start": "671320",
    "end": "672680"
  },
  {
    "text": "encoder scatter it into the uh all",
    "start": "672680",
    "end": "675560"
  },
  {
    "text": "vision encoders and then in these cases",
    "start": "675560",
    "end": "678320"
  },
  {
    "text": "we're going to also directly apply uh or",
    "start": "678320",
    "end": "680519"
  },
  {
    "text": "compute the backward pass and that kind",
    "start": "680519",
    "end": "682480"
  },
  {
    "text": "of concludes our uh training cycle in uh",
    "start": "682480",
    "end": "686560"
  },
  {
    "text": "in this model so as you can see it's",
    "start": "686560",
    "end": "688760"
  },
  {
    "text": "it's a very short code that comp that",
    "start": "688760",
    "end": "690959"
  },
  {
    "text": "that is not very easily implemented in",
    "start": "690959",
    "end": "692600"
  },
  {
    "text": "any other",
    "start": "692600",
    "end": "695040"
  },
  {
    "text": "library now I'll I'll discuss some",
    "start": "695320",
    "end": "697519"
  },
  {
    "text": "Benchmark results um of training a clip",
    "start": "697519",
    "end": "700639"
  },
  {
    "text": "model with one uh 1.8 billion uh Vision",
    "start": "700639",
    "end": "703920"
  },
  {
    "text": "incoder in this case it's a vit and a",
    "start": "703920",
    "end": "706360"
  },
  {
    "text": "700 million text encoder",
    "start": "706360",
    "end": "709240"
  },
  {
    "text": "Transformer our Baseline is a pytorch uh",
    "start": "709240",
    "end": "713120"
  },
  {
    "text": "uh implementation which which applies",
    "start": "713120",
    "end": "715399"
  },
  {
    "text": "fstp fstp 4 uh on both encoders um and",
    "start": "715399",
    "end": "720200"
  },
  {
    "text": "it runs on 4 00s uh we plot um the uh in",
    "start": "720200",
    "end": "725320"
  },
  {
    "text": "the first figure the throughput per",
    "start": "725320",
    "end": "726600"
  },
  {
    "text": "dollar meaning like how many thousands",
    "start": "726600",
    "end": "728720"
  },
  {
    "text": "of tokens we uh we compute per the",
    "start": "728720",
    "end": "731000"
  },
  {
    "text": "dollar",
    "start": "731000",
    "end": "731800"
  },
  {
    "text": "spent in the second plot we uh we plot",
    "start": "731800",
    "end": "734519"
  },
  {
    "text": "the vision uh GPU utilization and the",
    "start": "734519",
    "end": "737120"
  },
  {
    "text": "last one is the text GP",
    "start": "737120",
    "end": "739519"
  },
  {
    "text": "utilization so our first method uh using",
    "start": "739519",
    "end": "743240"
  },
  {
    "text": "gray compile graphs actually applies uh",
    "start": "743240",
    "end": "746199"
  },
  {
    "text": "fstp 3 on div Vision encoder so",
    "start": "746199",
    "end": "748279"
  },
  {
    "text": "basically splits the text encoder on on",
    "start": "748279",
    "end": "751800"
  },
  {
    "text": "a a on a single GPU with no parallelism",
    "start": "751800",
    "end": "754360"
  },
  {
    "text": "and uh places the vision encoder on",
    "start": "754360",
    "end": "756519"
  },
  {
    "text": "three gpus with sorry with fstp uh 3 um",
    "start": "756519",
    "end": "761440"
  },
  {
    "text": "and then still uses four 00s in this",
    "start": "761440",
    "end": "764720"
  },
  {
    "text": "case we can we can increase throughput",
    "start": "764720",
    "end": "767000"
  },
  {
    "text": "by",
    "start": "767000",
    "end": "767959"
  },
  {
    "text": "23% uh uh Vision utilization by",
    "start": "767959",
    "end": "771240"
  },
  {
    "text": "64% and text GP utilization by almost",
    "start": "771240",
    "end": "774399"
  },
  {
    "text": "five",
    "start": "774399",
    "end": "776240"
  },
  {
    "text": "times and even more what we can do is",
    "start": "776240",
    "end": "779560"
  },
  {
    "text": "actually we can place the text encoder",
    "start": "779560",
    "end": "781399"
  },
  {
    "text": "on a weaker GPU which is an L4 and use",
    "start": "781399",
    "end": "784000"
  },
  {
    "text": "only two 00s for uh the vision encoder",
    "start": "784000",
    "end": "787399"
  },
  {
    "text": "and apply the same fsdp to for both",
    "start": "787399",
    "end": "789839"
  },
  {
    "text": "models in this case actually compared to",
    "start": "789839",
    "end": "792240"
  },
  {
    "text": "our Baseline we can increase the through",
    "start": "792240",
    "end": "793920"
  },
  {
    "text": "per dollar by four almost 40% and V GPU",
    "start": "793920",
    "end": "798160"
  },
  {
    "text": "uh Vision GPU utilization by 60% and",
    "start": "798160",
    "end": "800639"
  },
  {
    "text": "most impressively the text GPU",
    "start": "800639",
    "end": "802560"
  },
  {
    "text": "utilization by almost uh 17",
    "start": "802560",
    "end": "807120"
  },
  {
    "text": "times again like our library allows us",
    "start": "807399",
    "end": "810279"
  },
  {
    "text": "to experiment with different kinds of",
    "start": "810279",
    "end": "812199"
  },
  {
    "text": "parm strategies that are different for",
    "start": "812199",
    "end": "814040"
  },
  {
    "text": "both encoders and we show here like",
    "start": "814040",
    "end": "816120"
  },
  {
    "text": "different configurations like 2D even 2D",
    "start": "816120",
    "end": "818480"
  },
  {
    "text": "parallelism um uh on on one uh on one",
    "start": "818480",
    "end": "822720"
  },
  {
    "text": "encoder um no parallelism in the other",
    "start": "822720",
    "end": "825600"
  },
  {
    "text": "fstp of degree 4 versus fsp degree",
    "start": "825600",
    "end": "829040"
  },
  {
    "text": "degree",
    "start": "829040",
    "end": "831320"
  },
  {
    "text": "2 now um I'll move next to application",
    "start": "832440",
    "end": "835880"
  },
  {
    "text": "to pipeline",
    "start": "835880",
    "end": "837800"
  },
  {
    "text": "parallelism so so um just a quick",
    "start": "837800",
    "end": "840440"
  },
  {
    "text": "overview of what pipeline parallelism is",
    "start": "840440",
    "end": "842279"
  },
  {
    "text": "in pipeline parm the goal is to actually",
    "start": "842279",
    "end": "844199"
  },
  {
    "text": "to split the model uh across different",
    "start": "844199",
    "end": "846560"
  },
  {
    "text": "devices by assigning um uh like devices",
    "start": "846560",
    "end": "850959"
  },
  {
    "text": "with blocks of layers so each uh each of",
    "start": "850959",
    "end": "854120"
  },
  {
    "text": "these blocks or each of these like",
    "start": "854120",
    "end": "855720"
  },
  {
    "text": "devices are are actually called a",
    "start": "855720",
    "end": "857320"
  },
  {
    "text": "pipeline stage um and then they execute",
    "start": "857320",
    "end": "860639"
  },
  {
    "text": "uh kind of sequentially but because of",
    "start": "860639",
    "end": "862600"
  },
  {
    "text": "this pipeline that we Define we have the",
    "start": "862600",
    "end": "864600"
  },
  {
    "text": "benefits of being able to to to run them",
    "start": "864600",
    "end": "867839"
  },
  {
    "text": "Sim run stages simultaneously and most",
    "start": "867839",
    "end": "871000"
  },
  {
    "text": "importantly we can reduce the memory",
    "start": "871000",
    "end": "873120"
  },
  {
    "text": "usage uh on a single device and train",
    "start": "873120",
    "end": "875560"
  },
  {
    "text": "much larger",
    "start": "875560",
    "end": "878079"
  },
  {
    "text": "models um so here I'm going to just",
    "start": "879839",
    "end": "882320"
  },
  {
    "text": "quickly uh describe one of the simplest",
    "start": "882320",
    "end": "884959"
  },
  {
    "text": "um uh pipeline schedules uh in in",
    "start": "884959",
    "end": "888199"
  },
  {
    "text": "pipeline parallel training it's called",
    "start": "888199",
    "end": "890040"
  },
  {
    "text": "Uh all forward or all backward so in",
    "start": "890040",
    "end": "893120"
  },
  {
    "text": "this example we're actually dividing our",
    "start": "893120",
    "end": "895120"
  },
  {
    "text": "model uh splitting into model into four",
    "start": "895120",
    "end": "897440"
  },
  {
    "text": "four stages uh uh um uh on four devices",
    "start": "897440",
    "end": "901920"
  },
  {
    "text": "so each device or overall we're",
    "start": "901920",
    "end": "903800"
  },
  {
    "text": "Computing uh eight micro batches so what",
    "start": "903800",
    "end": "906519"
  },
  {
    "text": "this means is that if you have a b if",
    "start": "906519",
    "end": "908000"
  },
  {
    "text": "you have a a full batch you're going to",
    "start": "908000",
    "end": "909279"
  },
  {
    "text": "divide it by uh eight times and then",
    "start": "909279",
    "end": "911560"
  },
  {
    "text": "you're going to compute multiple forward",
    "start": "911560",
    "end": "913680"
  },
  {
    "text": "passes multiple backward passes across",
    "start": "913680",
    "end": "915399"
  },
  {
    "text": "all the stages before updating the",
    "start": "915399",
    "end": "917240"
  },
  {
    "text": "parameters at the end of this uh like",
    "start": "917240",
    "end": "919440"
  },
  {
    "text": "pipeline",
    "start": "919440",
    "end": "921160"
  },
  {
    "text": "cycle now um the core idea here is that",
    "start": "921160",
    "end": "925360"
  },
  {
    "text": "the first device is going to execute a",
    "start": "925360",
    "end": "927800"
  },
  {
    "text": "single forward batch uh forward pass on",
    "start": "927800",
    "end": "930360"
  },
  {
    "text": "its micro batch and pass its activations",
    "start": "930360",
    "end": "932399"
  },
  {
    "text": "into second layer and so on and so forth",
    "start": "932399",
    "end": "934399"
  },
  {
    "text": "until you reach the last device or the",
    "start": "934399",
    "end": "936560"
  },
  {
    "text": "last stage and this last stage is going",
    "start": "936560",
    "end": "938519"
  },
  {
    "text": "to execute all of the forward passes",
    "start": "938519",
    "end": "940800"
  },
  {
    "text": "then at the end it's going to start to",
    "start": "940800",
    "end": "942519"
  },
  {
    "text": "execute the backward passes and pass the",
    "start": "942519",
    "end": "945399"
  },
  {
    "text": "gradients back to the previous stages up",
    "start": "945399",
    "end": "947720"
  },
  {
    "text": "until you reach the first stage and then",
    "start": "947720",
    "end": "950480"
  },
  {
    "text": "once you kind of uh execute all of those",
    "start": "950480",
    "end": "953000"
  },
  {
    "text": "micro batches you can update your",
    "start": "953000",
    "end": "954720"
  },
  {
    "text": "parameters and one like you know core",
    "start": "954720",
    "end": "957560"
  },
  {
    "text": "goal of pipeline Paralis is to reduce",
    "start": "957560",
    "end": "959440"
  },
  {
    "text": "this gray area that you can see here uh",
    "start": "959440",
    "end": "961959"
  },
  {
    "text": "that actually uh causes you know uh idle",
    "start": "961959",
    "end": "965399"
  },
  {
    "text": "chime in for for uh each of these",
    "start": "965399",
    "end": "969560"
  },
  {
    "text": "devices now um this is um the pipeline",
    "start": "969639",
    "end": "973600"
  },
  {
    "text": "prism is actually implemented or are",
    "start": "973600",
    "end": "975360"
  },
  {
    "text": "supported by Deep speed however um there",
    "start": "975360",
    "end": "978120"
  },
  {
    "text": "are a few limitations to this uh support",
    "start": "978120",
    "end": "981920"
  },
  {
    "text": "first is that the implementation",
    "start": "981920",
    "end": "983959"
  },
  {
    "text": "actually is restricted to uh uh specific",
    "start": "983959",
    "end": "986920"
  },
  {
    "text": "kind of models basically models that can",
    "start": "986920",
    "end": "988720"
  },
  {
    "text": "be expressed as a list of uh uh like uh",
    "start": "988720",
    "end": "993279"
  },
  {
    "text": "list of layers or sequential list of",
    "start": "993279",
    "end": "995959"
  },
  {
    "text": "layers the second limitation is that you",
    "start": "995959",
    "end": "998959"
  },
  {
    "text": "you are actually uh have to work with",
    "start": "998959",
    "end": "1000800"
  },
  {
    "text": "some predefined pipeline schedules and",
    "start": "1000800",
    "end": "1002880"
  },
  {
    "text": "in order to extend to more complex",
    "start": "1002880",
    "end": "1004880"
  },
  {
    "text": "schedules you basically need to Fork the",
    "start": "1004880",
    "end": "1006759"
  },
  {
    "text": "code understand their internals and like",
    "start": "1006759",
    "end": "1009480"
  },
  {
    "text": "spend a lot of time to actually get it",
    "start": "1009480",
    "end": "1011199"
  },
  {
    "text": "you know kind of uh working uh for your",
    "start": "1011199",
    "end": "1014480"
  },
  {
    "text": "use case and finally uh you also",
    "start": "1014480",
    "end": "1017440"
  },
  {
    "text": "restricted to their training engine and",
    "start": "1017440",
    "end": "1019920"
  },
  {
    "text": "it's not really easy to customize the",
    "start": "1019920",
    "end": "1021759"
  },
  {
    "text": "training Logic for your specific model",
    "start": "1021759",
    "end": "1023519"
  },
  {
    "text": "and pipeline schedule and also again",
    "start": "1023519",
    "end": "1025520"
  },
  {
    "text": "requires understanding you know very",
    "start": "1025520",
    "end": "1027880"
  },
  {
    "text": "deep technical details of the library",
    "start": "1027880",
    "end": "1030760"
  },
  {
    "text": "the same also applies for",
    "start": "1030760",
    "end": "1033600"
  },
  {
    "text": "Megatron now let's look uh on the",
    "start": "1033600",
    "end": "1036520"
  },
  {
    "text": "contrary let's look on how we can",
    "start": "1036520",
    "end": "1038000"
  },
  {
    "text": "Implement all if all B schedule with Ray",
    "start": "1038000",
    "end": "1040400"
  },
  {
    "text": "compiled graphs so um uh on the right",
    "start": "1040400",
    "end": "1044760"
  },
  {
    "text": "I'm actually uh",
    "start": "1044760",
    "end": "1046678"
  },
  {
    "text": "showing I'm actually showing like the",
    "start": "1046679",
    "end": "1048600"
  },
  {
    "text": "code that you need to write to implement",
    "start": "1048600",
    "end": "1052080"
  },
  {
    "text": "uh an all of allb schedule for two",
    "start": "1052080",
    "end": "1054360"
  },
  {
    "text": "workers the first worker is on this like",
    "start": "1054360",
    "end": "1057679"
  },
  {
    "text": "uh these are the kind of task of the",
    "start": "1057679",
    "end": "1058840"
  },
  {
    "text": "first worker and these are the task of",
    "start": "1058840",
    "end": "1060280"
  },
  {
    "text": "the second worker and um so this is the",
    "start": "1060280",
    "end": "1063280"
  },
  {
    "text": "code this is the the corresponding graph",
    "start": "1063280",
    "end": "1066240"
  },
  {
    "text": "that actually our library builds uh in",
    "start": "1066240",
    "end": "1068520"
  },
  {
    "text": "the in the back end so what really what",
    "start": "1068520",
    "end": "1071320"
  },
  {
    "text": "nodes here really mean are actually Ray",
    "start": "1071320",
    "end": "1074039"
  },
  {
    "text": "tasks and um the edges here we have kind",
    "start": "1074039",
    "end": "1077960"
  },
  {
    "text": "of two kinds of edges that we Define uh",
    "start": "1077960",
    "end": "1081360"
  },
  {
    "text": "with our library the first one is uh the",
    "start": "1081360",
    "end": "1084200"
  },
  {
    "text": "data dependency which means which",
    "start": "1084200",
    "end": "1086520"
  },
  {
    "text": "actually defines the flow of data from a",
    "start": "1086520",
    "end": "1089600"
  },
  {
    "text": "task to another so in this case uh uh we",
    "start": "1089600",
    "end": "1093240"
  },
  {
    "text": "pass activations from f11 to F21 then uh",
    "start": "1093240",
    "end": "1097799"
  },
  {
    "text": "F21 to B21 then B21 to",
    "start": "1097799",
    "end": "1103320"
  },
  {
    "text": "b11 the second kind of uh edges here is",
    "start": "1104440",
    "end": "1108159"
  },
  {
    "text": "the control",
    "start": "1108159",
    "end": "1109280"
  },
  {
    "text": "dependency and what we mean here is the",
    "start": "1109280",
    "end": "1111760"
  },
  {
    "text": "what what these edges mean is the order",
    "start": "1111760",
    "end": "1114640"
  },
  {
    "text": "in which the tasks need to execute",
    "start": "1114640",
    "end": "1116640"
  },
  {
    "text": "within the single uh actor so we know",
    "start": "1116640",
    "end": "1120080"
  },
  {
    "text": "here that f11 needs to execute first",
    "start": "1120080",
    "end": "1122840"
  },
  {
    "text": "then",
    "start": "1122840",
    "end": "1123640"
  },
  {
    "text": "F12 then F then b11 then",
    "start": "1123640",
    "end": "1128679"
  },
  {
    "text": "B12 so next I'm actually going to uh to",
    "start": "1132080",
    "end": "1135360"
  },
  {
    "text": "talk about slightly more complex",
    "start": "1135360",
    "end": "1137080"
  },
  {
    "text": "schedule it's called 1 f1b",
    "start": "1137080",
    "end": "1139440"
  },
  {
    "text": "and the goal of this schedule is uh",
    "start": "1139440",
    "end": "1141840"
  },
  {
    "text": "basically to reduce the memory",
    "start": "1141840",
    "end": "1143520"
  },
  {
    "text": "requirement in the afab schedule that we",
    "start": "1143520",
    "end": "1146120"
  },
  {
    "text": "saw before the main idea here is that",
    "start": "1146120",
    "end": "1149640"
  },
  {
    "text": "we're uh each worker is going to execute",
    "start": "1149640",
    "end": "1152640"
  },
  {
    "text": "a single forward pass and a single",
    "start": "1152640",
    "end": "1154240"
  },
  {
    "text": "backward pass then a single one uh as",
    "start": "1154240",
    "end": "1156760"
  },
  {
    "text": "you can see in this like uh red box now",
    "start": "1156760",
    "end": "1160360"
  },
  {
    "text": "uh of course at the beginning there's a",
    "start": "1160360",
    "end": "1161760"
  },
  {
    "text": "warm-up stage at the end there's a cool",
    "start": "1161760",
    "end": "1163720"
  },
  {
    "text": "down",
    "start": "1163720",
    "end": "1164600"
  },
  {
    "text": "stage I'm not going to go into much",
    "start": "1164600",
    "end": "1166679"
  },
  {
    "text": "detail here all all I want to like",
    "start": "1166679",
    "end": "1168760"
  },
  {
    "text": "highlight is that uh typically the",
    "start": "1168760",
    "end": "1171840"
  },
  {
    "text": "implementing this is um like exposes",
    "start": "1171840",
    "end": "1175000"
  },
  {
    "text": "your code into potential deadlock and",
    "start": "1175000",
    "end": "1177360"
  },
  {
    "text": "that's mainly because of the um blocking",
    "start": "1177360",
    "end": "1180919"
  },
  {
    "text": "uh nickel operations that send",
    "start": "1180919",
    "end": "1183000"
  },
  {
    "text": "activations across different",
    "start": "1183000",
    "end": "1186280"
  },
  {
    "text": "stages the one of the very like cool",
    "start": "1187400",
    "end": "1190159"
  },
  {
    "text": "features of Ray compile Gaff is that we",
    "start": "1190159",
    "end": "1192640"
  },
  {
    "text": "can actually detect those uh uh",
    "start": "1192640",
    "end": "1195360"
  },
  {
    "text": "Deadlocks and resolve it for you",
    "start": "1195360",
    "end": "1196640"
  },
  {
    "text": "automatically and the way we do it in a",
    "start": "1196640",
    "end": "1198720"
  },
  {
    "text": "very high level is that we're going to",
    "start": "1198720",
    "end": "1200799"
  },
  {
    "text": "uh split uh a node or a task into three",
    "start": "1200799",
    "end": "1203440"
  },
  {
    "text": "subtasks read compute and write and then",
    "start": "1203440",
    "end": "1206240"
  },
  {
    "text": "we're going to reorder their execution",
    "start": "1206240",
    "end": "1208280"
  },
  {
    "text": "such that we can break the deadlock and",
    "start": "1208280",
    "end": "1210559"
  },
  {
    "text": "if we cannot break the deadlock we're",
    "start": "1210559",
    "end": "1211799"
  },
  {
    "text": "going to actually give you an error and",
    "start": "1211799",
    "end": "1213159"
  },
  {
    "text": "tell you hey uh revisit your",
    "start": "1213159",
    "end": "1216000"
  },
  {
    "text": "schedule now again this like two cool",
    "start": "1216000",
    "end": "1219360"
  },
  {
    "text": "features that I want to highlight here",
    "start": "1219360",
    "end": "1221039"
  },
  {
    "text": "is that first we we can automatically",
    "start": "1221039",
    "end": "1223240"
  },
  {
    "text": "resolve Deadlocks by basically uh doing",
    "start": "1223240",
    "end": "1226280"
  },
  {
    "text": "an autological Source on the tasks that",
    "start": "1226280",
    "end": "1228200"
  },
  {
    "text": "you indu in your graph and uh and",
    "start": "1228200",
    "end": "1231280"
  },
  {
    "text": "another important feature is overlap of",
    "start": "1231280",
    "end": "1232960"
  },
  {
    "text": "communication and computation which",
    "start": "1232960",
    "end": "1234320"
  },
  {
    "text": "allows you to execute your graph in a",
    "start": "1234320",
    "end": "1236120"
  },
  {
    "text": "very efficient",
    "start": "1236120",
    "end": "1238760"
  },
  {
    "text": "way now um basically this uh 1 f1b",
    "start": "1238919",
    "end": "1243480"
  },
  {
    "text": "schedule can be implemented in this code",
    "start": "1243480",
    "end": "1246200"
  },
  {
    "text": "and I'm not going to go into a lot of",
    "start": "1246200",
    "end": "1247679"
  },
  {
    "text": "details but I just want to highlight",
    "start": "1247679",
    "end": "1249159"
  },
  {
    "text": "that you know the core idea of passing",
    "start": "1249159",
    "end": "1251880"
  },
  {
    "text": "activations from one stage to another is",
    "start": "1251880",
    "end": "1253760"
  },
  {
    "text": "implemented in these few lines of code",
    "start": "1253760",
    "end": "1255880"
  },
  {
    "text": "and passing gradients from one stage to",
    "start": "1255880",
    "end": "1257960"
  },
  {
    "text": "the previous one is also implemented in",
    "start": "1257960",
    "end": "1259720"
  },
  {
    "text": "these few lines of code of course if you",
    "start": "1259720",
    "end": "1262520"
  },
  {
    "text": "kind of wanted to do that in in some",
    "start": "1262520",
    "end": "1264440"
  },
  {
    "text": "other Library it's it's going to require",
    "start": "1264440",
    "end": "1267080"
  },
  {
    "text": "a lot of like much harder work to",
    "start": "1267080",
    "end": "1271158"
  },
  {
    "text": "do so uh a final schedule I'll talk",
    "start": "1271200",
    "end": "1274200"
  },
  {
    "text": "about for uh pipeline parm is called",
    "start": "1274200",
    "end": "1276240"
  },
  {
    "text": "zero bubble and that's one of the more",
    "start": "1276240",
    "end": "1278039"
  },
  {
    "text": "advanced schedules here um again the",
    "start": "1278039",
    "end": "1280919"
  },
  {
    "text": "main idea is that we want to uh execute",
    "start": "1280919",
    "end": "1284240"
  },
  {
    "text": "the pipeline parallel algorithm and",
    "start": "1284240",
    "end": "1286080"
  },
  {
    "text": "reduce the uh bubble size which is the",
    "start": "1286080",
    "end": "1288840"
  },
  {
    "text": "time so we're going to increase the GPU",
    "start": "1288840",
    "end": "1290600"
  },
  {
    "text": "utilization as much as we",
    "start": "1290600",
    "end": "1292640"
  },
  {
    "text": "can now the the core idea here is that",
    "start": "1292640",
    "end": "1295480"
  },
  {
    "text": "the backward path of any model can be",
    "start": "1295480",
    "end": "1298000"
  },
  {
    "text": "actually uh you know divided into two uh",
    "start": "1298000",
    "end": "1301640"
  },
  {
    "text": "two steps the first one is or one of",
    "start": "1301640",
    "end": "1304159"
  },
  {
    "text": "them is actually Computing the backward",
    "start": "1304159",
    "end": "1306000"
  },
  {
    "text": "path with respect to the parameters and",
    "start": "1306000",
    "end": "1307720"
  },
  {
    "text": "the other one with respect to the ACT",
    "start": "1307720",
    "end": "1309320"
  },
  {
    "text": "input activations so we call the first",
    "start": "1309320",
    "end": "1312000"
  },
  {
    "text": "one of the or basically the gradiance",
    "start": "1312000",
    "end": "1313720"
  },
  {
    "text": "with activations we call it B and then",
    "start": "1313720",
    "end": "1316320"
  },
  {
    "text": "uh the gradiance with with the modal",
    "start": "1316320",
    "end": "1317640"
  },
  {
    "text": "ways we call it w",
    "start": "1317640",
    "end": "1320520"
  },
  {
    "text": "and again I just want to highlight that",
    "start": "1320640",
    "end": "1322480"
  },
  {
    "text": "here that um if you look at this",
    "start": "1322480",
    "end": "1324679"
  },
  {
    "text": "schedule of 1 f1b uh it takes longer",
    "start": "1324679",
    "end": "1327799"
  },
  {
    "text": "time to actually execute compared to",
    "start": "1327799",
    "end": "1329760"
  },
  {
    "text": "zero bubble because we kind of reducing",
    "start": "1329760",
    "end": "1332039"
  },
  {
    "text": "those uh White",
    "start": "1332039",
    "end": "1335000"
  },
  {
    "text": "areas and um by and the like the main",
    "start": "1335000",
    "end": "1338640"
  },
  {
    "text": "reason for that is because we can",
    "start": "1338640",
    "end": "1340559"
  },
  {
    "text": "overlap the forward uh operation with uh",
    "start": "1340559",
    "end": "1344000"
  },
  {
    "text": "with either the backward uh or B or w",
    "start": "1344000",
    "end": "1349960"
  },
  {
    "text": "now again also I'm not going to go into",
    "start": "1349960",
    "end": "1351640"
  },
  {
    "text": "much detail on how we Implement that but",
    "start": "1351640",
    "end": "1353679"
  },
  {
    "text": "I just want to highlight that if you you",
    "start": "1353679",
    "end": "1356039"
  },
  {
    "text": "can Implement uh this complex uh",
    "start": "1356039",
    "end": "1358559"
  },
  {
    "text": "schedule by modifying you know few lines",
    "start": "1358559",
    "end": "1360880"
  },
  {
    "text": "of code uh in the one uh 1 f1b schedule",
    "start": "1360880",
    "end": "1365120"
  },
  {
    "text": "um and the idea here is we simply add an",
    "start": "1365120",
    "end": "1368200"
  },
  {
    "text": "additional task of W uh after each",
    "start": "1368200",
    "end": "1371159"
  },
  {
    "text": "backward",
    "start": "1371159",
    "end": "1373880"
  },
  {
    "text": "task so now I'm going to present some",
    "start": "1374279",
    "end": "1376720"
  },
  {
    "text": "Benchmark results and on training uh",
    "start": "1376720",
    "end": "1379240"
  },
  {
    "text": "Lama 27b on uh uh two um on basically uh",
    "start": "1379240",
    "end": "1385120"
  },
  {
    "text": "four uh a800 machines actually sorry two",
    "start": "1385120",
    "end": "1387960"
  },
  {
    "text": "nodes of four 00s",
    "start": "1387960",
    "end": "1391559"
  },
  {
    "text": "gpus the um the first one uh in the",
    "start": "1391559",
    "end": "1395440"
  },
  {
    "text": "first case uh we show that uh we",
    "start": "1395440",
    "end": "1398279"
  },
  {
    "text": "basically show the number different",
    "start": "1398279",
    "end": "1399799"
  },
  {
    "text": "number of micro batches and the",
    "start": "1399799",
    "end": "1401120"
  },
  {
    "text": "throughput measured by token per second",
    "start": "1401120",
    "end": "1403520"
  },
  {
    "text": "and we can see that we can of uh get uh",
    "start": "1403520",
    "end": "1406520"
  },
  {
    "text": "basically in this in this case we're",
    "start": "1406520",
    "end": "1408039"
  },
  {
    "text": "implementing the 1 f1b schedule and we",
    "start": "1408039",
    "end": "1409960"
  },
  {
    "text": "can see that we can achieve a very close",
    "start": "1409960",
    "end": "1412120"
  },
  {
    "text": "performance to deep",
    "start": "1412120",
    "end": "1413799"
  },
  {
    "text": "speed uh while as I said uh it's a much",
    "start": "1413799",
    "end": "1417080"
  },
  {
    "text": "simpler",
    "start": "1417080",
    "end": "1419279"
  },
  {
    "text": "implementation and our uh API allows us",
    "start": "1419279",
    "end": "1422400"
  },
  {
    "text": "to implement uh zero bubble which gives",
    "start": "1422400",
    "end": "1425240"
  },
  {
    "text": "us almost 25% Improvement compared uh to",
    "start": "1425240",
    "end": "1428559"
  },
  {
    "text": "a deep speed 1 f1b",
    "start": "1428559",
    "end": "1432000"
  },
  {
    "text": "implementation so um to summarize um",
    "start": "1432760",
    "end": "1435799"
  },
  {
    "text": "we've introduced a flexible and easy API",
    "start": "1435799",
    "end": "1438200"
  },
  {
    "text": "for for hetrogeneous training uh with",
    "start": "1438200",
    "end": "1440520"
  },
  {
    "text": "our API we can achieve almost",
    "start": "1440520",
    "end": "1442760"
  },
  {
    "text": "40% um uh throughput uh per dollar gain",
    "start": "1442760",
    "end": "1445919"
  },
  {
    "text": "on multim training over pytorch fsdp and",
    "start": "1445919",
    "end": "1449159"
  },
  {
    "text": "uh almost 25% throughput gain with zero",
    "start": "1449159",
    "end": "1452360"
  },
  {
    "text": "bubble over deep",
    "start": "1452360",
    "end": "1454679"
  },
  {
    "text": "speed so um thank you so much please um",
    "start": "1454679",
    "end": "1458320"
  },
  {
    "text": "if you have any questions or uh don't",
    "start": "1458320",
    "end": "1460360"
  },
  {
    "text": "feel free to connect with me by email or",
    "start": "1460360",
    "end": "1462720"
  },
  {
    "text": "or in LinkedIn um join our slack uh and",
    "start": "1462720",
    "end": "1466799"
  },
  {
    "text": "uh specifically the channel Ray acceler",
    "start": "1466799",
    "end": "1468480"
  },
  {
    "text": "at dag uh check out what we're working",
    "start": "1468480",
    "end": "1471000"
  },
  {
    "text": "on uh on and on GitHub and uh I just",
    "start": "1471000",
    "end": "1474200"
  },
  {
    "text": "want to highlight that we are hiring",
    "start": "1474200",
    "end": "1475880"
  },
  {
    "text": "great Engineers uh to join our team so",
    "start": "1475880",
    "end": "1478440"
  },
  {
    "text": "if you're excited about the you know the",
    "start": "1478440",
    "end": "1480720"
  },
  {
    "text": "vision of developing the next uh",
    "start": "1480720",
    "end": "1483200"
  },
  {
    "text": "distributed training Library please",
    "start": "1483200",
    "end": "1485039"
  },
  {
    "text": "reach out thank",
    "start": "1485039",
    "end": "1488360"
  },
  {
    "text": "you all right for a Q&A please use this",
    "start": "1491399",
    "end": "1494559"
  },
  {
    "text": "microphone so we can record your",
    "start": "1494559",
    "end": "1497080"
  },
  {
    "text": "question and",
    "start": "1497080",
    "end": "1500320"
  },
  {
    "text": "for a little while uh Ray had like a",
    "start": "1507799",
    "end": "1509960"
  },
  {
    "text": "workflows API that was in beta is",
    "start": "1509960",
    "end": "1512279"
  },
  {
    "text": "compiled graphs intended to kind of",
    "start": "1512279",
    "end": "1514679"
  },
  {
    "text": "replace that or uh is in terms of like",
    "start": "1514679",
    "end": "1517559"
  },
  {
    "text": "the kind of your dag bindings or is this",
    "start": "1517559",
    "end": "1519279"
  },
  {
    "text": "kind of an add-on to that's kind of",
    "start": "1519279",
    "end": "1521559"
  },
  {
    "text": "separate I think we haven't really",
    "start": "1521559",
    "end": "1522840"
  },
  {
    "text": "thought about Integrations uh yet it's",
    "start": "1522840",
    "end": "1525399"
  },
  {
    "text": "mostly like another version of uh core",
    "start": "1525399",
    "end": "1528799"
  },
  {
    "text": "that is more optimized for static uh you",
    "start": "1528799",
    "end": "1531880"
  },
  {
    "text": "know graphs B static workloads okay",
    "start": "1531880",
    "end": "1537200"
  },
  {
    "text": "thanks during training the L Force",
    "start": "1540960",
    "end": "1543679"
  },
  {
    "text": "doesn't support um nickel",
    "start": "1543679",
    "end": "1547720"
  },
  {
    "text": "communication right uh how do",
    "start": "1547720",
    "end": "1550159"
  },
  {
    "text": "you combining like A1 100s and l4s and",
    "start": "1550159",
    "end": "1554240"
  },
  {
    "text": "then manage the",
    "start": "1554240",
    "end": "1556480"
  },
  {
    "text": "communication uh overhead",
    "start": "1556480",
    "end": "1558760"
  },
  {
    "text": "like we so we pass the activations",
    "start": "1558760",
    "end": "1561480"
  },
  {
    "text": "across uh nodes and um I'm not really",
    "start": "1561480",
    "end": "1564919"
  },
  {
    "text": "sure uh why you say nickel doesn't",
    "start": "1564919",
    "end": "1567480"
  },
  {
    "text": "support",
    "start": "1567480",
    "end": "1568360"
  },
  {
    "text": "L4 or those are like cheaper gpus um",
    "start": "1568360",
    "end": "1572279"
  },
  {
    "text": "yeah but they do support nickel okay",
    "start": "1572279",
    "end": "1573760"
  },
  {
    "text": "nickel",
    "start": "1573760",
    "end": "1576159"
  },
  {
    "text": "okay I don't know very much about nickel",
    "start": "1580240",
    "end": "1582760"
  },
  {
    "text": "is that does that lock you into Nvidia",
    "start": "1582760",
    "end": "1584159"
  },
  {
    "text": "gpus or can you use non- Nvidia gpus",
    "start": "1584159",
    "end": "1586399"
  },
  {
    "text": "with nickel as well no it's uh specific",
    "start": "1586399",
    "end": "1589640"
  },
  {
    "text": "to um uh to Nvidia gpus do you have",
    "start": "1589640",
    "end": "1593559"
  },
  {
    "text": "plans to figure out how to do non-",
    "start": "1593559",
    "end": "1595200"
  },
  {
    "text": "envidia gpus or I think this is",
    "start": "1595200",
    "end": "1597200"
  },
  {
    "text": "something that we yeah we have some uh",
    "start": "1597200",
    "end": "1599600"
  },
  {
    "text": "you know collaborations that we are kind",
    "start": "1599600",
    "end": "1601039"
  },
  {
    "text": "of talking to about",
    "start": "1601039",
    "end": "1604080"
  },
  {
    "text": "that uh hi I have a question about a f",
    "start": "1604080",
    "end": "1606919"
  },
  {
    "text": "Toler tolerance so uh if you compile a",
    "start": "1606919",
    "end": "1610360"
  },
  {
    "text": "graph to a static execution uh what if I",
    "start": "1610360",
    "end": "1613840"
  },
  {
    "text": "lost a node during the execution where",
    "start": "1613840",
    "end": "1616480"
  },
  {
    "text": "the cluster handle it or have to",
    "start": "1616480",
    "end": "1619720"
  },
  {
    "text": "recompile that's a very good question um",
    "start": "1619720",
    "end": "1622840"
  },
  {
    "text": "I think we are still like in an early",
    "start": "1622840",
    "end": "1624520"
  },
  {
    "text": "stage uh of of developing the library I",
    "start": "1624520",
    "end": "1627039"
  },
  {
    "text": "personally don't haven't really probably",
    "start": "1627039",
    "end": "1629520"
  },
  {
    "text": "some people in the uh Ray core team can",
    "start": "1629520",
    "end": "1631559"
  },
  {
    "text": "probably give you a better answer uh I",
    "start": "1631559",
    "end": "1634240"
  },
  {
    "text": "think this is one of the things that we",
    "start": "1634240",
    "end": "1635559"
  },
  {
    "text": "have in back of our mind because if you",
    "start": "1635559",
    "end": "1637399"
  },
  {
    "text": "want to do uh really serious uh training",
    "start": "1637399",
    "end": "1640240"
  },
  {
    "text": "you want to handle uh fault tolerance um",
    "start": "1640240",
    "end": "1643360"
  },
  {
    "text": "so I think this is definitely on our",
    "start": "1643360",
    "end": "1645039"
  },
  {
    "text": "agenda but I don't think we we have like",
    "start": "1645039",
    "end": "1647559"
  },
  {
    "text": "direct support for",
    "start": "1647559",
    "end": "1649120"
  },
  {
    "text": "it uh so I have a question actually",
    "start": "1649120",
    "end": "1651200"
  },
  {
    "text": "related to that one uh yeah so so it's",
    "start": "1651200",
    "end": "1654279"
  },
  {
    "text": "also about error handling uh I know you",
    "start": "1654279",
    "end": "1656240"
  },
  {
    "text": "guys are still thinking about how that",
    "start": "1656240",
    "end": "1657960"
  },
  {
    "text": "should be should be handled but in",
    "start": "1657960",
    "end": "1659840"
  },
  {
    "text": "theory could the uh compile graph help",
    "start": "1659840",
    "end": "1662240"
  },
  {
    "text": "with like elastic training for example",
    "start": "1662240",
    "end": "1665000"
  },
  {
    "text": "uh you know um we do have actually",
    "start": "1665000",
    "end": "1667799"
  },
  {
    "text": "another uh you know parallel effort in",
    "start": "1667799",
    "end": "1670279"
  },
  {
    "text": "the in our uh team that like kind of",
    "start": "1670279",
    "end": "1673279"
  },
  {
    "text": "supports elastic training again I we",
    "start": "1673279",
    "end": "1676200"
  },
  {
    "text": "it's still like basically a like couple",
    "start": "1676200",
    "end": "1679200"
  },
  {
    "text": "of months of work so we're still like in",
    "start": "1679200",
    "end": "1681080"
  },
  {
    "text": "early stages but we really that's this",
    "start": "1681080",
    "end": "1683399"
  },
  {
    "text": "is basically one of those like through",
    "start": "1683399",
    "end": "1684880"
  },
  {
    "text": "elastic training we want to support for",
    "start": "1684880",
    "end": "1686720"
  },
  {
    "text": "tolerance and want to integrate with",
    "start": "1686720",
    "end": "1688039"
  },
  {
    "text": "this whole uh Ray train uh kind of",
    "start": "1688039",
    "end": "1693120"
  },
  {
    "text": "ecosystem all right another round of",
    "start": "1693279",
    "end": "1695519"
  },
  {
    "text": "applause for mchat thank you",
    "start": "1695519",
    "end": "1700240"
  }
]
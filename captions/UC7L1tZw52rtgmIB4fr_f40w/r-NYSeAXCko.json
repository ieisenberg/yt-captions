[
  {
    "start": "0",
    "end": "128000"
  },
  {
    "text": "thank you",
    "start": "12679",
    "end": "15679"
  },
  {
    "text": "foreign [Music]",
    "start": "32520",
    "end": "36879"
  },
  {
    "text": "[Music]",
    "start": "39620",
    "end": "46718"
  },
  {
    "text": "please welcome to the stage co-founder and CEO any scale Robert nishihar",
    "start": "67200",
    "end": "73410"
  },
  {
    "text": "[Music]",
    "start": "73410",
    "end": "79370"
  },
  {
    "text": "all right [Music] welcome to race Summit",
    "start": "82580",
    "end": "89270"
  },
  {
    "text": "[Applause] quick show of hands who took an Uber here",
    "start": "89270",
    "end": "95579"
  },
  {
    "text": "who chatted with Chachi PT recently raise your hand if you used Spotify or",
    "start": "95579",
    "end": "102119"
  },
  {
    "text": "or Netflix or Tick Tock recently or perhaps you ordered food on instacart or",
    "start": "102119",
    "end": "108720"
  },
  {
    "text": "doordash or ubereats or used any of these products",
    "start": "108720",
    "end": "113820"
  },
  {
    "text": "just about everybody you all have interacted with models",
    "start": "113820",
    "end": "119880"
  },
  {
    "text": "built using Rey thanks to the work that this community has done that we've done together",
    "start": "119880",
    "end": "127979"
  },
  {
    "text": "for businesses scaling AI Rey is everywhere",
    "start": "127979",
    "end": "133500"
  },
  {
    "start": "128000",
    "end": "232000"
  },
  {
    "text": "and the impact has been staggering instacart instacart uses AI across the board for",
    "start": "133500",
    "end": "141360"
  },
  {
    "text": "fulfillment for ads personalization they now train 12 times faster and on up",
    "start": "141360",
    "end": "149280"
  },
  {
    "text": "to 100 times more data Pinterest has some of the world's largest computer vision data sets",
    "start": "149280",
    "end": "156540"
  },
  {
    "text": "they cut costs by 40 percent and increased developer productivity speeding up developer iterations by six",
    "start": "156540",
    "end": "165360"
  },
  {
    "text": "times Amazon processes exabytes of data with",
    "start": "165360",
    "end": "171000"
  },
  {
    "text": "Rey they reduce latency by 10 times they increased scale by 10 times",
    "start": "171000",
    "end": "177840"
  },
  {
    "text": "and they most importantly cut costs by 10 times",
    "start": "177840",
    "end": "184140"
  },
  {
    "text": "I find these numbers just extraordinary but perhaps",
    "start": "184140",
    "end": "189440"
  },
  {
    "text": "thank you",
    "start": "189440",
    "end": "192620"
  },
  {
    "text": "perhaps it'll come as a surprise that just one year ago almost none of these success stories",
    "start": "194940",
    "end": "201000"
  },
  {
    "text": "existed in fact even six months ago almost none of these success stories existed",
    "start": "201000",
    "end": "208739"
  },
  {
    "text": "the ray Community has exploded over the past six months in large part because AI has changed so rapidly",
    "start": "208739",
    "end": "216840"
  },
  {
    "text": "when we had this conference our first in-person race Summit just one year ago",
    "start": "216840",
    "end": "222420"
  },
  {
    "text": "there was no chat GPT and there were definitely no llama models",
    "start": "222420",
    "end": "228180"
  },
  {
    "text": "in that time AI has become far more capable",
    "start": "228180",
    "end": "233220"
  },
  {
    "start": "232000",
    "end": "469000"
  },
  {
    "text": "and as the capabilities have grown the challenges have also grown as well",
    "start": "233220",
    "end": "240299"
  },
  {
    "text": "so what are these challenges well we all know the models are larger",
    "start": "240299",
    "end": "245760"
  },
  {
    "text": "the computational demands are more demanding we used to actually get this question",
    "start": "245760",
    "end": "251280"
  },
  {
    "text": "all the time people would ask isn't scale something that only the biggest companies like Google need to think",
    "start": "251280",
    "end": "258239"
  },
  {
    "text": "about well we don't get that question anymore a scale has become a fact of life",
    "start": "258239",
    "end": "265740"
  },
  {
    "text": "cost is now top of mind for nearly everyone that we speak with",
    "start": "265740",
    "end": "272460"
  },
  {
    "text": "but beyond the scale and cost challenges the pace of AI itself",
    "start": "272460",
    "end": "279720"
  },
  {
    "text": "has become a challenge we've talked with so many businesses businesses who've been doing AI for",
    "start": "279720",
    "end": "286139"
  },
  {
    "text": "years who've invested heavily in AI infrastructure and yet many of these businesses have",
    "start": "286139",
    "end": "293040"
  },
  {
    "text": "found themselves lacking the capabilities to fully take advantage of llms and generative AI",
    "start": "293040",
    "end": "301500"
  },
  {
    "text": "and as a consequence they're starting to see their competitors catch up or new competitors emerge",
    "start": "301500",
    "end": "308759"
  },
  {
    "text": "succeeding with AI today is essential but just as important is preparing",
    "start": "308759",
    "end": "316199"
  },
  {
    "text": "ourselves for all of the challenges and the changing requirements coming down",
    "start": "316199",
    "end": "321360"
  },
  {
    "text": "the road AI is not done changing and the infrastructure challenges",
    "start": "321360",
    "end": "326580"
  },
  {
    "text": "are going to continue to grow now fortunately for many of us here",
    "start": "326580",
    "end": "333300"
  },
  {
    "text": "these are precisely the challenges that Rey was built for scale is our bread and butter the",
    "start": "333300",
    "end": "340139"
  },
  {
    "text": "largest models out there like chat GPT were built with Rey cost efficiency is baked into Rey at",
    "start": "340139",
    "end": "348060"
  },
  {
    "text": "every level from the way we handle Auto scaling so the way we separate CPU compute and GPU",
    "start": "348060",
    "end": "354240"
  },
  {
    "text": "compute to default tolerance capabilities that allow Ray to run on spot instances so the way we pipeline",
    "start": "354240",
    "end": "360419"
  },
  {
    "text": "data ingest and training and inference to the low-level model and GPU",
    "start": "360419",
    "end": "365699"
  },
  {
    "text": "optimizations efficiency is baked in at every level",
    "start": "365699",
    "end": "372020"
  },
  {
    "text": "but another reason when we ask businesses and teams why do they adopt Rey",
    "start": "372840",
    "end": "378539"
  },
  {
    "text": "we hear scale a lot we hear cost a lot but we also hear another reason",
    "start": "378539",
    "end": "384539"
  },
  {
    "text": "teams adopt Rey because it is strategic",
    "start": "384539",
    "end": "389940"
  },
  {
    "text": "AI is not done changing and the challenges are continuing to grow and we've seen many shifts before we've",
    "start": "389940",
    "end": "397199"
  },
  {
    "text": "moved from classical machine learning to deep learning and then from Deep learning to llms and",
    "start": "397199",
    "end": "403199"
  },
  {
    "text": "today we're all using llms but soon we'll all be using multimodal models working not just with Text data",
    "start": "403199",
    "end": "409380"
  },
  {
    "text": "but also video and image data it's going to become far more data intensive",
    "start": "409380",
    "end": "414900"
  },
  {
    "text": "on the hardware front the variety of accelerators that we need to support will grow",
    "start": "414900",
    "end": "421080"
  },
  {
    "text": "on the application front applications are becoming far more complex techniques like model routing are",
    "start": "421080",
    "end": "426660"
  },
  {
    "text": "becoming essential as many models work together to power individual applications",
    "start": "426660",
    "end": "433319"
  },
  {
    "text": "Ray is designed to be future proof to give teams the flexibility to adapt to",
    "start": "433319",
    "end": "439860"
  },
  {
    "text": "all the changing infrastructure requirements coming down the road and to stay at the Forefront of all the",
    "start": "439860",
    "end": "445440"
  },
  {
    "text": "advances in the AI and the open source community we always talk about the rapid pace of",
    "start": "445440",
    "end": "451860"
  },
  {
    "text": "progress in AI but what good is the rapid pace of progress in AI",
    "start": "451860",
    "end": "457440"
  },
  {
    "text": "if your team isn't fully prepared to take advantage of it",
    "start": "457440",
    "end": "463400"
  },
  {
    "text": "so some of you may be wondering what are we working on here at any scale",
    "start": "463860",
    "end": "469620"
  },
  {
    "start": "469000",
    "end": "596000"
  },
  {
    "text": "our first product is the any scale platform this is our managed Ray offering",
    "start": "469620",
    "end": "475080"
  },
  {
    "text": "we recently announced any scale endpoints in preview this is an llm API an llm inference API",
    "start": "475080",
    "end": "482520"
  },
  {
    "text": "like the openai API but for open models like llama 2.",
    "start": "482520",
    "end": "488880"
  },
  {
    "text": "these two products mimic different stages of the generative AI adoption",
    "start": "488880",
    "end": "494400"
  },
  {
    "text": "life cycle from talking with many of you we've seen that businesses tend to adopt",
    "start": "494400",
    "end": "501240"
  },
  {
    "text": "generative AI in two phases at the outset you're not looking to curate a large data set and train a",
    "start": "501240",
    "end": "508500"
  },
  {
    "text": "model instead what matters at this stage you want to start with an API product like any scale",
    "start": "508500",
    "end": "514919"
  },
  {
    "text": "endpoints integrate it directly into their product and features that you're shipping",
    "start": "514919",
    "end": "521459"
  },
  {
    "text": "what matters at this stage is rapid iteration shipping your products and actually",
    "start": "521459",
    "end": "528080"
  },
  {
    "text": "validating that the product makes sense that's why we built any scale endpoints",
    "start": "528080",
    "end": "533760"
  },
  {
    "text": "now once it's proven out then the story changes then it's about",
    "start": "533760",
    "end": "539640"
  },
  {
    "text": "making it real at that point what matters is scale",
    "start": "539640",
    "end": "545420"
  },
  {
    "text": "reducing costs reducing latency improving quality extending and expanding the application",
    "start": "545420",
    "end": "555019"
  },
  {
    "text": "so here's a little illustration showing what it looks like to use any scale endpoints",
    "start": "555480",
    "end": "561360"
  },
  {
    "text": "here we're passing in a query it's an API product the query is showing code Lama a code snippet in Python and asking",
    "start": "561360",
    "end": "568560"
  },
  {
    "text": "it for help debugging the code okay I'm not actually showing the full code snippet but amazingly codelama actually",
    "start": "568560",
    "end": "575060"
  },
  {
    "text": "correctly diagnoses the bug in my code and tells me how to fix it I think it's pretty impressive codelama is a great",
    "start": "575060",
    "end": "581339"
  },
  {
    "text": "model but codelama is just one of many models we support all the most popular open models",
    "start": "581339",
    "end": "587339"
  },
  {
    "text": "and helping me debug is just one of many possible use cases",
    "start": "587339",
    "end": "592740"
  },
  {
    "text": "but hopefully this gives you a taste now since we launched it in preview",
    "start": "592740",
    "end": "598560"
  },
  {
    "start": "596000",
    "end": "657000"
  },
  {
    "text": "just one month ago it's been exciting to see the first production applications roll out built with endpoints one of our",
    "start": "598560",
    "end": "605339"
  },
  {
    "text": "customers builds a browser extension an AI powered browser extension used by millions of people they use any scale endpoints to achieve",
    "start": "605339",
    "end": "612779"
  },
  {
    "text": "a five to eight X cost reduction another company Builds an AI character",
    "start": "612779",
    "end": "618000"
  },
  {
    "text": "chat bot they use any scale endpoints not just to reduce costs but also to ship new services in hours instead of",
    "start": "618000",
    "end": "625680"
  },
  {
    "text": "weeks and any scale endpoints is used to build products it's not used in isolation",
    "start": "625680",
    "end": "631320"
  },
  {
    "text": "and to support that we integrate with the rest of the AI ecosystem tools like Lang chain weights",
    "start": "631320",
    "end": "637500"
  },
  {
    "text": "and biases llama index arise and many others",
    "start": "637500",
    "end": "642800"
  },
  {
    "text": "some of you may be wondering aren't there lots of llm apis what's you know what's different about this one",
    "start": "644279",
    "end": "651779"
  },
  {
    "text": "where we go deep is on cost efficiency",
    "start": "651779",
    "end": "657500"
  },
  {
    "start": "657000",
    "end": "804000"
  },
  {
    "text": "optimizing cost for llm inference touches every layer of the stack it's a",
    "start": "658260",
    "end": "664019"
  },
  {
    "text": "very holistic problem to illustrate that requires low level GPU and model optimizations techniques",
    "start": "664019",
    "end": "671220"
  },
  {
    "text": "like page detention and pipeline parallelism taking advantage of techniques like",
    "start": "671220",
    "end": "677040"
  },
  {
    "text": "continuous batching rapid Auto scaling of model replicas to handle variable load",
    "start": "677040",
    "end": "682800"
  },
  {
    "text": "and thinking about how to take advantage of the most cost efficient and cheapest hardware and gpus across different",
    "start": "682800",
    "end": "689519"
  },
  {
    "text": "regions or maybe even different clouds this is a deep deep",
    "start": "689519",
    "end": "694980"
  },
  {
    "text": "technical challenge and our goal is to go deep at every layer to squeeze out the most",
    "start": "694980",
    "end": "700800"
  },
  {
    "text": "performance taking advantage of all the optimizations that we've built over the past couple of years",
    "start": "700800",
    "end": "708060"
  },
  {
    "text": "along with all of the latest advances from the open source community and we take all of that work and all of",
    "start": "708060",
    "end": "713760"
  },
  {
    "text": "these layers and put it behind an API and offer that for just one dollar per",
    "start": "713760",
    "end": "721019"
  },
  {
    "text": "million tokens",
    "start": "721019",
    "end": "723800"
  },
  {
    "text": "that is the price point for the 70 billion parameter llama model and that is the lowest price point on",
    "start": "727019",
    "end": "733140"
  },
  {
    "text": "the market but what if you want to go further can you reduce costs even more",
    "start": "733140",
    "end": "739320"
  },
  {
    "text": "well maybe to State the obvious one of the um you know important directions to go",
    "start": "739320",
    "end": "746279"
  },
  {
    "text": "in for cost reduction is to use smaller models the challenge there is that smaller",
    "start": "746279",
    "end": "751860"
  },
  {
    "text": "models don't work as well so what do you do about that well fine-tuning is a technique that",
    "start": "751860",
    "end": "758940"
  },
  {
    "text": "adapts models to improve their quality on specific Problems by doing a little bit extra",
    "start": "758940",
    "end": "764820"
  },
  {
    "text": "training so fine-tuning can actually enable it can make smaller models viable",
    "start": "764820",
    "end": "772560"
  },
  {
    "text": "and by enabling us to use smaller models instead of larger general purpose models",
    "start": "772560",
    "end": "778380"
  },
  {
    "text": "fine tuning can play a huge role in cost reduction so because of that I'm thrilled to",
    "start": "778380",
    "end": "784139"
  },
  {
    "text": "announce that today we are releasing fine tuning support in any scale endpoints this is now part of the API",
    "start": "784139",
    "end": "789839"
  },
  {
    "text": "and you can try it out today [Applause]",
    "start": "789839",
    "end": "796980"
  },
  {
    "text": "to give you a sense of why fine tuning is important I want",
    "start": "796980",
    "end": "802019"
  },
  {
    "text": "to share one result from a study we did so here we compared a few different llms",
    "start": "802019",
    "end": "807120"
  },
  {
    "start": "804000",
    "end": "928000"
  },
  {
    "text": "on a specific problem we actually did many problems but um the specific problem here is SQL",
    "start": "807120",
    "end": "813180"
  },
  {
    "text": "query generation so taking an English statement and translating that into a SQL query",
    "start": "813180",
    "end": "819480"
  },
  {
    "text": "out of the box the smallest llama model the 7 billion parameter llama model doesn't work okay this is unusable",
    "start": "819480",
    "end": "827820"
  },
  {
    "text": "on the other hand gpt4 actually does quite well out of the box with 78 accuracy",
    "start": "827820",
    "end": "834060"
  },
  {
    "text": "okay so the small llama model doesn't work gpt4 Works quite well there's",
    "start": "834060",
    "end": "839700"
  },
  {
    "text": "nothing surprising here what is surprising is that when we",
    "start": "839700",
    "end": "844920"
  },
  {
    "text": "fine-tune the small llama model it actually achieved 86 accuracy",
    "start": "844920",
    "end": "850260"
  },
  {
    "text": "outperforming gpt4 so",
    "start": "850260",
    "end": "856200"
  },
  {
    "text": "we are comparing a small specialized model with",
    "start": "856200",
    "end": "862800"
  },
  {
    "text": "the most advanced general purpose model out there and we're seeing Superior task",
    "start": "862800",
    "end": "867839"
  },
  {
    "text": "specific performance at 1 300th of the cost so this is we are all going to be doing fine tuning",
    "start": "867839",
    "end": "876199"
  },
  {
    "text": "so to give you a taste of what it feels like to use this API and what you can achieve with it I'd like to invite Robin from our",
    "start": "876420",
    "end": "883440"
  },
  {
    "text": "product management team and Amir from our engineering team to the stage to give you a demo please welcome Robin and",
    "start": "883440",
    "end": "889920"
  },
  {
    "text": "Amir [Applause] [Music]",
    "start": "889920",
    "end": "901680"
  },
  {
    "text": "thanks Robert with any skill endpoints you could host and scale your open source large",
    "start": "901680",
    "end": "907800"
  },
  {
    "text": "language models that can perform as well as close Source models for specific applications",
    "start": "907800",
    "end": "913380"
  },
  {
    "text": "today we are hosting llama family of models and these models are powerful enough to replace closed-source model",
    "start": "913380",
    "end": "919620"
  },
  {
    "text": "for specific applications these applications are like summarization and energy extraction let",
    "start": "919620",
    "end": "925980"
  },
  {
    "text": "me show you a quick demo of this last week Nvidia release tensor RT",
    "start": "925980",
    "end": "931380"
  },
  {
    "text": "libraries for llm they mentioned any scale as one of the partnering companies what I'm going to show you right now is",
    "start": "931380",
    "end": "938040"
  },
  {
    "text": "I'm going to ask both gbd 3.5 and lamba 70 hosted on any scale endpoints to some",
    "start": "938040",
    "end": "943680"
  },
  {
    "text": "Rice's article and give me the names of the partnering companies in this article let's look at this in action first I'm",
    "start": "943680",
    "end": "951600"
  },
  {
    "text": "going to go and ask gbd 3.5 to summarize this article for me",
    "start": "951600",
    "end": "956660"
  },
  {
    "text": "well it does a reasonably good job at being able to summarize this now let's ask Lama 70 model running on any scale",
    "start": "958500",
    "end": "964500"
  },
  {
    "text": "endpoints by the way in both the cases this openai SDK being used in both their programs",
    "start": "964500",
    "end": "970680"
  },
  {
    "text": "that's because you know any skill endpoints API is open AI compatible you see both of these things both of",
    "start": "970680",
    "end": "976920"
  },
  {
    "text": "these models are able to perform fairly well in summarization and entity extraction but any scale endpoints is",
    "start": "976920",
    "end": "982320"
  },
  {
    "text": "able to do the same exact job for 40 lower costs that's amazing",
    "start": "982320",
    "end": "988440"
  },
  {
    "text": "now let's push this model a little bit further how about we ask you to do something that it hasn't done before how",
    "start": "988440",
    "end": "994500"
  },
  {
    "text": "about we ask you to convert a natural language into a SQL query what I'm going to do is I'm going to ask",
    "start": "994500",
    "end": "1001160"
  },
  {
    "text": "lamba 70 hosted on any scale endpoints I'm going to give it a public databases",
    "start": "1001160",
    "end": "1006320"
  },
  {
    "text": "schema let's say the names of the preference and the year that they were president and ask if they generate a SQL",
    "start": "1006320",
    "end": "1013279"
  },
  {
    "text": "query which tells me precisely who was president back in 1990. now",
    "start": "1013279",
    "end": "1019220"
  },
  {
    "text": "let me just ask this tell me who exactly was the president in 1990 and generate a SQL query",
    "start": "1019220",
    "end": "1025400"
  },
  {
    "text": "well you can see it doesn't do a very good job at this and this is exactly what we have seen so",
    "start": "1025400",
    "end": "1030678"
  },
  {
    "text": "far large models both open source and closed Source are not powerful enough to be able to do this domain specific tasks",
    "start": "1030679",
    "end": "1037459"
  },
  {
    "text": "and that's exactly why I've built any scale endpoints fine tuning API to do a quick demo I'm just going to walk you",
    "start": "1037459",
    "end": "1043459"
  },
  {
    "text": "through it I'm here cool thanks Robin I'm very excited to",
    "start": "1043459",
    "end": "1051740"
  },
  {
    "text": "show you how fine tuning works on any scale endpoints right now I will be taking a 7B model which is much much",
    "start": "1051740",
    "end": "1059419"
  },
  {
    "text": "smaller than the two models Robin showed you earlier I'm gonna fine tune it and",
    "start": "1059419",
    "end": "1064520"
  },
  {
    "text": "I'm gonna send it this same exact query and you're going to see that it will handle this task correctly while being",
    "start": "1064520",
    "end": "1070880"
  },
  {
    "text": "300 times less expensive than gbd4",
    "start": "1070880",
    "end": "1076640"
  },
  {
    "text": "let's take a look this is my fine tuning script notice how short it is and notice that it uses the",
    "start": "1076640",
    "end": "1084200"
  },
  {
    "text": "open AI SDK because our any scale endpoints is compatible with the openai",
    "start": "1084200",
    "end": "1089240"
  },
  {
    "text": "SDK all I have to do is",
    "start": "1089240",
    "end": "1094660"
  },
  {
    "text": "run this script and this will get my job scheduled any scale endpoints will take",
    "start": "1094660",
    "end": "1101179"
  },
  {
    "text": "care of running my fine tuning job getting the gpus figuring out all the hyper parameters",
    "start": "1101179",
    "end": "1106940"
  },
  {
    "text": "Etc once my fine-tuning job is finished I will get an email notification and my",
    "start": "1106940",
    "end": "1113960"
  },
  {
    "text": "model will become available for serving and then I can use the same script used",
    "start": "1113960",
    "end": "1119780"
  },
  {
    "text": "earlier by Robin to query my model let's try that",
    "start": "1119780",
    "end": "1125380"
  },
  {
    "text": "now I will be pasting the same exact query that Robin used earlier but now on",
    "start": "1128660",
    "end": "1133940"
  },
  {
    "text": "my 7B model notice how clean and accurate the",
    "start": "1133940",
    "end": "1139760"
  },
  {
    "text": "response is it just gave me the exact query that I would need that would give me the response correctly I want to also",
    "start": "1139760",
    "end": "1146000"
  },
  {
    "text": "remind you that this model is 300 times less expensive than gbd4 I'm very",
    "start": "1146000",
    "end": "1152179"
  },
  {
    "text": "excited to see what you guys will be building on top of any scale in points now back to Robert",
    "start": "1152179",
    "end": "1158950"
  },
  {
    "text": "[Applause]",
    "start": "1158950",
    "end": "1163349"
  },
  {
    "text": "[Music]",
    "start": "1165950",
    "end": "1171988"
  },
  {
    "text": "thank you Robin and Amir I'm so excited for you all to try out this API",
    "start": "1178580",
    "end": "1184039"
  },
  {
    "text": "there are a lot of things you can build with it but sometimes you do need more than just",
    "start": "1184039",
    "end": "1189860"
  },
  {
    "text": "an API I may need more privacy for example I may have highly sensitive",
    "start": "1189860",
    "end": "1196400"
  },
  {
    "text": "customer data and that data and my models simply can't leave my control",
    "start": "1196400",
    "end": "1203240"
  },
  {
    "text": "or perhaps I need more customizability I want to deploy different models adapt",
    "start": "1203240",
    "end": "1208340"
  },
  {
    "text": "those models or modify the logic surrounding those models and surrounding the operation of those models",
    "start": "1208340",
    "end": "1215179"
  },
  {
    "text": "or perhaps I need other forms of control I want an SLA",
    "start": "1215179",
    "end": "1220760"
  },
  {
    "text": "I want to use dedicated compute I want to choose the hardware myself so that I can trade off cost and latency",
    "start": "1220760",
    "end": "1227360"
  },
  {
    "text": "considerations all of these requirements go beyond a typical API product",
    "start": "1227360",
    "end": "1234260"
  },
  {
    "text": "so to make this possible today I'm very very excited to be releasing any scale",
    "start": "1234260",
    "end": "1240980"
  },
  {
    "text": "private endpoints foreign",
    "start": "1240980",
    "end": "1246200"
  },
  {
    "text": "this gives it this makes it possible to deploy the entire back end including all",
    "start": "1248059",
    "end": "1254179"
  },
  {
    "text": "the llms in your cloud account private for your business",
    "start": "1254179",
    "end": "1259760"
  },
  {
    "text": "and to customize it to your heart's content I'm incredibly excited for people to try",
    "start": "1259760",
    "end": "1264919"
  },
  {
    "text": "this out there are many llm apis out there but I don't think there's anything else like this",
    "start": "1264919",
    "end": "1271280"
  },
  {
    "text": "you get the same familiar API but with the customizability and control",
    "start": "1271280",
    "end": "1277580"
  },
  {
    "text": "of your private infrastructure to show you what it feels like to run the entire back end yourself with any",
    "start": "1277580",
    "end": "1283640"
  },
  {
    "text": "scale private endpoints I'd now like to invite Praveen from our engineering team and Matt from our product managing",
    "start": "1283640",
    "end": "1289940"
  },
  {
    "text": "product management team to join me on the stage to give you a demo please Welcome Matt and Praveen",
    "start": "1289940",
    "end": "1296820"
  },
  {
    "text": "[Applause] [Music]",
    "start": "1296820",
    "end": "1302610"
  },
  {
    "text": "[Applause]",
    "start": "1302610",
    "end": "1305720"
  },
  {
    "text": "thank you Robin as Robert mentioned sometimes we need more one of the things I do in my role at any",
    "start": "1307820",
    "end": "1314780"
  },
  {
    "start": "1312000",
    "end": "1452000"
  },
  {
    "text": "scale is understand how customers use our product this means writing a lot of complex queries on a production database",
    "start": "1314780",
    "end": "1321320"
  },
  {
    "text": "systems and this could take a lot of time let me see if llama can help me here",
    "start": "1321320",
    "end": "1326780"
  },
  {
    "text": "now I'm going to start with a very simple example I want the model to give",
    "start": "1326780",
    "end": "1332059"
  },
  {
    "text": "me a query which will tell which customer used a particular product most in the last month",
    "start": "1332059",
    "end": "1338240"
  },
  {
    "text": "now before coming on the stage I've played around with the query a bit and what I've realized is I need to give it",
    "start": "1338240",
    "end": "1344240"
  },
  {
    "text": "some context the context here happens to be the database schema that we are running on",
    "start": "1344240",
    "end": "1350419"
  },
  {
    "text": "this could be a problem my security and privacy team may not be very happy with me transferring a",
    "start": "1350419",
    "end": "1357140"
  },
  {
    "text": "database schema of production system outside my arc boundaries you can imagine more use cases like these what",
    "start": "1357140",
    "end": "1363260"
  },
  {
    "text": "if you're summarizing logs which have sensitive information this is where any scale private endpoints can help I was able to take",
    "start": "1363260",
    "end": "1370400"
  },
  {
    "text": "everything that Robin and Amit have shown previously deployed in my own cloud as a private endpoint now in this",
    "start": "1370400",
    "end": "1377240"
  },
  {
    "text": "script with one line of change as you can see in the screen I was able to point this query to run it against my",
    "start": "1377240",
    "end": "1383720"
  },
  {
    "text": "private endpoint I'll still get all the benefits of the public endpoints but hopefully keep my security and privacy",
    "start": "1383720",
    "end": "1390440"
  },
  {
    "text": "team happy let's see if we can run this query",
    "start": "1390440",
    "end": "1395080"
  },
  {
    "text": "as you can see it generates a valid query valid SQL query for me but we can do more there is a bug in this query",
    "start": "1398179",
    "end": "1405140"
  },
  {
    "text": "which is not obvious the group by Clause happens to be wrong now I know I can fix it by fine-tuning",
    "start": "1405140",
    "end": "1411260"
  },
  {
    "text": "this against the production queries that I've run in the past and get the results that I want but that means exposing more",
    "start": "1411260",
    "end": "1418159"
  },
  {
    "text": "of my schema outside my arc private endpoints helps us out here as well with",
    "start": "1418159",
    "end": "1423860"
  },
  {
    "text": "the same line of change that I've shown shown you earlier I can point the fine tuning job to run against my private",
    "start": "1423860",
    "end": "1430340"
  },
  {
    "text": "endpoint I can still get all the benefits optimizations that Amir and Robin have shown by while running this",
    "start": "1430340",
    "end": "1437480"
  },
  {
    "text": "on my cloud hopefully keeping my security and privacy team happy you can do that as well let me invite Matt to",
    "start": "1437480",
    "end": "1444140"
  },
  {
    "text": "show you how to create and manage your endpoints",
    "start": "1444140",
    "end": "1448419"
  },
  {
    "text": "thank you let me show you how any skill private",
    "start": "1449720",
    "end": "1455120"
  },
  {
    "text": "endpoints made it possible for Praveen to run his llm application with more privacy control and customizability now",
    "start": "1455120",
    "end": "1463580"
  },
  {
    "text": "the first thing we wanted to do with private endpoints was make it super simple to deploy with the simple click of a button from",
    "start": "1463580",
    "end": "1470240"
  },
  {
    "text": "the anyskill platform home page Praveen was able to deploy the any skill endpoint solution privately in his own",
    "start": "1470240",
    "end": "1476960"
  },
  {
    "text": "cloud let that sink in for a moment the performance reliability and scalability",
    "start": "1476960",
    "end": "1483559"
  },
  {
    "text": "of the any scale hosted endpoint solution plus the privacy of his own cloud packaged together in a single",
    "start": "1483559",
    "end": "1491000"
  },
  {
    "text": "button but there's more to it than that with private endpoints Praveen also has the",
    "start": "1491000",
    "end": "1496280"
  },
  {
    "text": "ability to choose which clouds he wants to deploy his endpoints to he can choose to deploy his endpoint to",
    "start": "1496280",
    "end": "1502520"
  },
  {
    "text": "his AWS gcp Dev stage prod or even a",
    "start": "1502520",
    "end": "1508280"
  },
  {
    "text": "hybrid Cloud to meet his application needs he can choose to run his lmm",
    "start": "1508280",
    "end": "1513679"
  },
  {
    "text": "application in an isolated Cloud to meet strict performance requirements in a",
    "start": "1513679",
    "end": "1518780"
  },
  {
    "text": "single tenant setting private endpoints also gives Praveen more control in knowing what's happening",
    "start": "1518780",
    "end": "1525740"
  },
  {
    "text": "with the underlying system I've jumped to another private endpoint that we deployed early last week to run very",
    "start": "1525740",
    "end": "1531980"
  },
  {
    "text": "large scale load tests you can see that private endpoint has the Llama 2 family",
    "start": "1531980",
    "end": "1537320"
  },
  {
    "text": "of models deployed the Llama 2 chat models the 7 billion parameter 13",
    "start": "1537320",
    "end": "1542659"
  },
  {
    "text": "billion parameter and 70 billion parameter models deployed if I scroll down I can see the API and how I can",
    "start": "1542659",
    "end": "1549020"
  },
  {
    "text": "actually integrate private endpoints into my application it's completely compatible with public endpoints and",
    "start": "1549020",
    "end": "1554840"
  },
  {
    "text": "very very easy to integrate into your application but what Praveen also gets from this",
    "start": "1554840",
    "end": "1560000"
  },
  {
    "text": "page is a link to a real-time dashboard providing him a deep understanding of",
    "start": "1560000",
    "end": "1565520"
  },
  {
    "text": "what's happening with his underlying system he can see important metrics for example the cluster utilization the",
    "start": "1565520",
    "end": "1572179"
  },
  {
    "text": "volume and traffic that his application is serving any errors he may have that he may need to diagnose and go into logs",
    "start": "1572179",
    "end": "1579140"
  },
  {
    "text": "to investigate an important latency measures at the p50 P90 or P99 level and",
    "start": "1579140",
    "end": "1585980"
  },
  {
    "text": "so much more this sort of control gives Praveen the confidence he needs to run his llm",
    "start": "1585980",
    "end": "1592520"
  },
  {
    "text": "application in production now the last element that Robert touched on Beyond privacy and control was",
    "start": "1592520",
    "end": "1600320"
  },
  {
    "text": "customizability and this is another area where any scale private endpoints shine",
    "start": "1600320",
    "end": "1605600"
  },
  {
    "text": "at the beginning you saw as I created my endpoint I had the ability to choose which models were deployed including",
    "start": "1605600",
    "end": "1612440"
  },
  {
    "text": "custom fine-tuned models that functionality also extends to me being able to update the models that are",
    "start": "1612440",
    "end": "1619279"
  },
  {
    "text": "deployed to my um to my endpoint perhaps over time your llm application integrates new functionality and you",
    "start": "1619279",
    "end": "1626240"
  },
  {
    "text": "need to add new models or you get new data and create a new fine-tuned model that you want to add to your endpoint",
    "start": "1626240",
    "end": "1632120"
  },
  {
    "text": "and remove an older version with any skill private endpoints you can and in",
    "start": "1632120",
    "end": "1638419"
  },
  {
    "text": "fact as you do that any skill automatically handles finding the right instances and accelerators across clouds",
    "start": "1638419",
    "end": "1645200"
  },
  {
    "text": "to make sure your endpoint solution runs reliably cost effectively and with the",
    "start": "1645200",
    "end": "1650960"
  },
  {
    "text": "performance you need even and you can see that even more importantly if we scroll back up the",
    "start": "1650960",
    "end": "1657020"
  },
  {
    "text": "traffic for my application continued unabated there was no interruption for my end users so I was able to update and",
    "start": "1657020",
    "end": "1664460"
  },
  {
    "text": "customize my endpoint with zero downtime for my end users now we realize there's some customers",
    "start": "1664460",
    "end": "1670700"
  },
  {
    "text": "out there who want very specific control over Hardware and using certain instances or",
    "start": "1670700",
    "end": "1675860"
  },
  {
    "text": "accelerators with any skill private endpoints they can get it here's an example of a configuration that I used",
    "start": "1675860",
    "end": "1682520"
  },
  {
    "text": "where I wanted to run my llms on a very specific set of Hardware with any scale",
    "start": "1682520",
    "end": "1688100"
  },
  {
    "text": "private endpoints I was able to choose the exact instances capacity reservation",
    "start": "1688100",
    "end": "1693460"
  },
  {
    "text": "accelerators and scaling behavior that I needed to run my application how I",
    "start": "1693460",
    "end": "1698659"
  },
  {
    "text": "wanted and there you have it any skill private endpoints provides the same great",
    "start": "1698659",
    "end": "1704360"
  },
  {
    "text": "experience performance reliability and scalability of any skill endpoints plus",
    "start": "1704360",
    "end": "1711200"
  },
  {
    "text": "the Privacy control and customizability you need to run your llm applications",
    "start": "1711200",
    "end": "1717080"
  },
  {
    "text": "I'm really excited to see the applications you all will build with any scale private endpoints thank you",
    "start": "1717080",
    "end": "1724120"
  },
  {
    "text": "[Applause] good job",
    "start": "1724120",
    "end": "1730540"
  },
  {
    "text": "[Music] [Applause] [Music]",
    "start": "1730540",
    "end": "1735679"
  },
  {
    "text": "thank you so much we have a lot we have a lot lined up for you",
    "start": "1735679",
    "end": "1741080"
  },
  {
    "text": "over the rest of today and tomorrow we're going to be hearing from some incredible speakers we'll be hearing",
    "start": "1741080",
    "end": "1746779"
  },
  {
    "text": "from John Schulman one of the co-founders of openai and the creator of chat GPT",
    "start": "1746779",
    "end": "1752120"
  },
  {
    "text": "Ben Horowitz one of the co-founders of Andreessen Horowitz Lang chain Creator Harrison Chase as",
    "start": "1752120",
    "end": "1759559"
  },
  {
    "text": "well as engineering leaders from so many different companies from LinkedIn Niantic Adobe Airbnb Uber",
    "start": "1759559",
    "end": "1768440"
  },
  {
    "text": "about how they build and deploy llm and generative AI applications",
    "start": "1768440",
    "end": "1774080"
  },
  {
    "text": "using Ray these are some of the people moving the field forward",
    "start": "1774080",
    "end": "1779120"
  },
  {
    "text": "if you're looking to accelerate llms or generative AI",
    "start": "1779120",
    "end": "1784460"
  },
  {
    "text": "in your business I don't think you could be at a better event with that I'm very very excited to",
    "start": "1784460",
    "end": "1791299"
  },
  {
    "text": "welcome John Schulman to the stage John is one of the co-founders of openai and the creator of chat GPT please welcome",
    "start": "1791299",
    "end": "1797179"
  },
  {
    "text": "John [Applause]",
    "start": "1797179",
    "end": "1804399"
  },
  {
    "text": "thank you so much for being here pleasure to be here [Music]",
    "start": "1804399",
    "end": "1810410"
  },
  {
    "start": "1810000",
    "end": "1932000"
  },
  {
    "text": "so there are a bunch of questions I'd love to ask you about your work at open AI but before we dive into that",
    "start": "1810799",
    "end": "1818720"
  },
  {
    "text": "can you tell us a little bit about how you got excited about AI in the first place",
    "start": "1818720",
    "end": "1823880"
  },
  {
    "text": "I used to read a lot of sci-fi as a kid I liked Isaac asimov's books and burner",
    "start": "1823880",
    "end": "1829520"
  },
  {
    "text": "vinge yeah and uh I remember picking up the singularities near by Ray Kurzweil",
    "start": "1829520",
    "end": "1835340"
  },
  {
    "text": "at a garage sale once and uh looking at all the nice scaling plots uh like how",
    "start": "1835340",
    "end": "1842240"
  },
  {
    "text": "um Moore's Law and all of its uh variations so and then I did some",
    "start": "1842240",
    "end": "1848419"
  },
  {
    "text": "projects as an undergrad and um doing things with machine",
    "start": "1848419",
    "end": "1853880"
  },
  {
    "text": "learning like I worked on transcribing uh handwriting into latex for some project for some class and that",
    "start": "1853880",
    "end": "1861620"
  },
  {
    "text": "was uh that was exciting to me it also did some Physics projects right yeah oh",
    "start": "1861620",
    "end": "1866659"
  },
  {
    "text": "yeah I did an undergrad in physics okay nice and so that led you to do a PhD in",
    "start": "1866659",
    "end": "1872480"
  },
  {
    "text": "machine learning right yeah you weren't always working on language models right can you tell us about the kind of work",
    "start": "1872480",
    "end": "1878659"
  },
  {
    "text": "you did in grad school yeah I started out actually I started grad school in Neuroscience but then I",
    "start": "1878659",
    "end": "1884960"
  },
  {
    "text": "ended up switching to Robotics and to a machine learning group uh Peter reveals",
    "start": "1884960",
    "end": "1890720"
  },
  {
    "text": "group that worked on Robotics and uh so I I worked a bit with uh with the robots",
    "start": "1890720",
    "end": "1896179"
  },
  {
    "text": "of the time like there's the the PR2 personal robot 2 uh and uh",
    "start": "1896179",
    "end": "1902299"
  },
  {
    "text": "we were doing things like using it to fold laundry uh in a very uh very slow",
    "start": "1902299",
    "end": "1908059"
  },
  {
    "text": "and deliberate way and uh tying I was working on tying knots getting it to tie",
    "start": "1908059",
    "end": "1913700"
  },
  {
    "text": "knots I remember that um as a kind of simulation of um doing uh robot surgery that was the",
    "start": "1913700",
    "end": "1920299"
  },
  {
    "text": "motivating application like having suturing with a robot so yeah I worked",
    "start": "1920299",
    "end": "1925580"
  },
  {
    "text": "on robotics a bit for a while and then halfway through the PHD switched over to uh to reinforcement learning",
    "start": "1925580",
    "end": "1932299"
  },
  {
    "start": "1932000",
    "end": "1962000"
  },
  {
    "text": "if you look back on your PhD work I'm curious which projects do you think stood the test of time the most",
    "start": "1932299",
    "end": "1939799"
  },
  {
    "text": "I'd say the work on reinforcement learning and uh specifically uh applying",
    "start": "1939799",
    "end": "1945559"
  },
  {
    "text": "it to neural Nets uh definitely that was the stuff that that ended up",
    "start": "1945559",
    "end": "1951320"
  },
  {
    "text": "making a difference in the long run some of the earlier work on robotics uh definitely produced some nice demos at",
    "start": "1951320",
    "end": "1958460"
  },
  {
    "text": "the time but I don't think the methods are that General yeah cool so we all know that open AI does",
    "start": "1958460",
    "end": "1965240"
  },
  {
    "start": "1962000",
    "end": "2047000"
  },
  {
    "text": "great research and builds great products um but open AI didn't start out that way right it started out purely focused on",
    "start": "1965240",
    "end": "1972140"
  },
  {
    "text": "Research right um can you tell us about that transition what led to the decision to do both",
    "start": "1972140",
    "end": "1980960"
  },
  {
    "text": "well we we were interested in um releasing some kind of product or releasing something to the world from",
    "start": "1980960",
    "end": "1987440"
  },
  {
    "text": "the beginning but we also didn't want to go too far out of our way to to build a",
    "start": "1987440",
    "end": "1993140"
  },
  {
    "text": "product so we um um we had some there were some ideas of",
    "start": "1993140",
    "end": "1998720"
  },
  {
    "text": "being tossed around um but um nothing quite nothing quite came",
    "start": "1998720",
    "end": "2004539"
  },
  {
    "text": "together and uh we wanted to we wanted to raise more money and it was kind of",
    "start": "2004539",
    "end": "2011500"
  },
  {
    "text": "um even though our structure didn't require us to um make money",
    "start": "2011500",
    "end": "2016720"
  },
  {
    "text": "immediately or be um profitable uh it seemed like we were going to be able to raise more money if",
    "start": "2016720",
    "end": "2022779"
  },
  {
    "text": "we actually had some kind of um some kind of product out there and also we felt like it was uh it's nice if",
    "start": "2022779",
    "end": "2030340"
  },
  {
    "text": "your research actually connects to the real world instead of just uh being kind of",
    "start": "2030340",
    "end": "2036000"
  },
  {
    "text": "uh I don't know just having um",
    "start": "2036000",
    "end": "2041019"
  },
  {
    "text": "uh just being like publishing things and putting together demos yeah",
    "start": "2041019",
    "end": "2047080"
  },
  {
    "start": "2047000",
    "end": "2129000"
  },
  {
    "text": "and so your first product was the API product right how long you know once you guys",
    "start": "2047080",
    "end": "2052839"
  },
  {
    "text": "decided to start building products and shipping that um how long did it take to decide on",
    "start": "2052839",
    "end": "2059138"
  },
  {
    "text": "building an API were there other ideas you you considered yeah we had some other ideas uh a lot of",
    "start": "2059139",
    "end": "2065800"
  },
  {
    "text": "them were more like domain specific applications like doing translation so after gbd3 we we knew that",
    "start": "2065800",
    "end": "2073599"
  },
  {
    "text": "um these models were impressively smart and there must be something you can do with them uh so we we ended up thinking",
    "start": "2073599",
    "end": "2079960"
  },
  {
    "text": "about a bunch of natural language processing applications but at the time we were thinking that the model wasn't",
    "start": "2079960",
    "end": "2085960"
  },
  {
    "text": "quite good enough at anything to be useful uh by itself so we would probably need to fine-tune it and build it make",
    "start": "2085960",
    "end": "2093339"
  },
  {
    "text": "it really good for a specific application but I think then there was the other um well I actually don't think we could",
    "start": "2093339",
    "end": "2101200"
  },
  {
    "text": "have succeeded with one of those products because it would have required building up a ton of domain expertise",
    "start": "2101200",
    "end": "2107680"
  },
  {
    "text": "and really digging into that domain and it would have been it would have required a lot of work that's separate",
    "start": "2107680",
    "end": "2114099"
  },
  {
    "text": "from our main research so the nice thing about an API is it's just basically taking the thing that the research team",
    "start": "2114099",
    "end": "2120579"
  },
  {
    "text": "has built and commercializing it directly as opposed to going and building this whole other product that's",
    "start": "2120579",
    "end": "2126099"
  },
  {
    "text": "separate from what the research team is doing were you deterred At All by the fact that there were other AI apis out",
    "start": "2126099",
    "end": "2133839"
  },
  {
    "start": "2129000",
    "end": "2179000"
  },
  {
    "text": "there other companies have tried building AI apis but none of them had been a huge success",
    "start": "2133839",
    "end": "2139060"
  },
  {
    "text": "a little bit that was definitely a concern that there were some there's there was some other apis like for",
    "start": "2139060",
    "end": "2145119"
  },
  {
    "text": "object recognition and vision and um I think some of them were moderately well used but they weren't uh like uh",
    "start": "2145119",
    "end": "2153040"
  },
  {
    "text": "spectacular products so we were definitely we had some concerns about that and I think",
    "start": "2153040",
    "end": "2158440"
  },
  {
    "text": "um in retrospect those concerns were warranted because I'd say the original",
    "start": "2158440",
    "end": "2163619"
  },
  {
    "text": "model we released the API with wasn't good enough um for most people I mean it was a",
    "start": "2163619",
    "end": "2169359"
  },
  {
    "text": "pretty small business for a while and um I think it only um the model started to get good enough",
    "start": "2169359",
    "end": "2175480"
  },
  {
    "text": "only in the last year and a half or so so it wasn't an overnight success when",
    "start": "2175480",
    "end": "2181540"
  },
  {
    "start": "2179000",
    "end": "2235000"
  },
  {
    "text": "did you when did you realize that it was going to work out that the API was you know the right choice or that it was",
    "start": "2181540",
    "end": "2187839"
  },
  {
    "text": "going to work out well I think you you could have um looked at the trends and uh and",
    "start": "2187839",
    "end": "2195520"
  },
  {
    "text": "predicted what I just described that maybe the initial model wasn't good enough but uh some uh future models",
    "start": "2195520",
    "end": "2201760"
  },
  {
    "text": "would be and uh like serving uh models seemed like a generally useful thing to",
    "start": "2201760",
    "end": "2208240"
  },
  {
    "text": "do so I would say that um the API only likes saw a lot of",
    "start": "2208240",
    "end": "2214960"
  },
  {
    "text": "growth in uh 2022 uh just after we had the three point GPD 3.5 base models",
    "start": "2214960",
    "end": "2222040"
  },
  {
    "text": "coming out and then we sort of had a pretty steep growth curve",
    "start": "2222040",
    "end": "2227760"
  },
  {
    "text": "itself made the API a lot more popular because a lot more people got excited about language models in general yeah",
    "start": "2227760",
    "end": "2235000"
  },
  {
    "start": "2235000",
    "end": "2373000"
  },
  {
    "text": "yeah now before we talk about chat GPT let's talk about scaling this is a you",
    "start": "2235000",
    "end": "2241960"
  },
  {
    "text": "know distributed systems events in some extent um we all know open AI uses a huge amount of compute",
    "start": "2241960",
    "end": "2248740"
  },
  {
    "text": "and actually I think openai was perhaps the first to really go all in on scaling",
    "start": "2248740",
    "end": "2256480"
  },
  {
    "text": "where did that belief in the importance of scaling models and compute come from",
    "start": "2256480",
    "end": "2262359"
  },
  {
    "text": "the idea that bigger models are better was a bit in the Zeitgeist that people",
    "start": "2262359",
    "end": "2267940"
  },
  {
    "text": "had um produced the best Benchmark results with fairly big models and uh but I",
    "start": "2267940",
    "end": "2274240"
  },
  {
    "text": "guess it wasn't um so and I I would say the uh founding",
    "start": "2274240",
    "end": "2279400"
  },
  {
    "text": "team of openai was uh more uh leans more towards this uh",
    "start": "2279400",
    "end": "2285040"
  },
  {
    "text": "aesthetic of scale up simple things rather than trying to build uh some complicated clever thing like we",
    "start": "2285040",
    "end": "2290680"
  },
  {
    "text": "definitely believed that uh simple things that are uh doing the simple thing right was uh uh tended to win when",
    "start": "2290680",
    "end": "2299560"
  },
  {
    "text": "in machine learning but I would say for scaling it's not",
    "start": "2299560",
    "end": "2305020"
  },
  {
    "text": "um scaling looks easy when you see the final result or it looks obvious when you see the final result that uh like",
    "start": "2305020",
    "end": "2312040"
  },
  {
    "text": "curve goes up and to the right but often there's a lot of complexity in getting there and you have to yeah say I mean",
    "start": "2312040",
    "end": "2319900"
  },
  {
    "text": "there's all the systems uh just doing the engineering is very difficult to get something that's actually performing at",
    "start": "2319900",
    "end": "2325660"
  },
  {
    "text": "scale and then there's usually all these little details like you have to scale your learning rates just right otherwise",
    "start": "2325660",
    "end": "2331119"
  },
  {
    "text": "you get worse results with big models and you have to scale your data up along with the model size so I'd say that it",
    "start": "2331119",
    "end": "2337180"
  },
  {
    "text": "took several years to figure out what were the right recipes for scaling things yeah now",
    "start": "2337180",
    "end": "2342280"
  },
  {
    "text": "we talk about scaling as if it's one thing but there are many different dimensions you could scale right the",
    "start": "2342280",
    "end": "2347500"
  },
  {
    "text": "amount of data size of the model just the amount of compute you put into it maybe other things as well is it",
    "start": "2347500",
    "end": "2354040"
  },
  {
    "text": "obvious which ones matter and which ones don't well it's usually not completely obvious",
    "start": "2354040",
    "end": "2360220"
  },
  {
    "text": "I mean model size and data are the two biggest ones but then you usually have a lot of hyper parameters that have to be",
    "start": "2360220",
    "end": "2366880"
  },
  {
    "text": "scaled properly and it's uh you have to do a lot of science to figure out how to scale them yeah",
    "start": "2366880",
    "end": "2373119"
  },
  {
    "start": "2373000",
    "end": "2449000"
  },
  {
    "text": "so can you share some intuition about why scaling is hard like why",
    "start": "2373119",
    "end": "2378220"
  },
  {
    "text": "aren't we using much what's stopping us from using you know 70 trillion parameter models today or or even bigger",
    "start": "2378220",
    "end": "2385180"
  },
  {
    "text": "yeah I think um a lot of that is about um well it's about compute efficiency",
    "start": "2385180",
    "end": "2391119"
  },
  {
    "text": "like uh you can so now we know you can train a small model for really long or a",
    "start": "2391119",
    "end": "2396880"
  },
  {
    "text": "big model for short and there's some uh there's some trade-off and it turns out",
    "start": "2396880",
    "end": "2402280"
  },
  {
    "text": "the um somewhere in the middle you get the best compute efficiency so if you put the flops on the x-axis you have a bunch",
    "start": "2402280",
    "end": "2409060"
  },
  {
    "text": "of Curves of uh you and you you draw your learning curves of loss versus flops there's some optimal model size",
    "start": "2409060",
    "end": "2415900"
  },
  {
    "text": "for getting the best performance so I think what we have now is just",
    "start": "2415900",
    "end": "2420960"
  },
  {
    "text": "using Transformers and using the training recipe we have it turns out certain model sizes are the most",
    "start": "2420960",
    "end": "2428320"
  },
  {
    "text": "efficient given the amount of compute resources we're putting into it but that",
    "start": "2428320",
    "end": "2433359"
  },
  {
    "text": "that's probably going to change as we uh start putting more compute into the training runs and also maybe as we start",
    "start": "2433359",
    "end": "2439900"
  },
  {
    "text": "to change the training methodologies and the types of data we use we also might and I find that different different size",
    "start": "2439900",
    "end": "2447579"
  },
  {
    "text": "models end up working the best do you have a sense of whether this is something with diminishing returns or or",
    "start": "2447579",
    "end": "2453460"
  },
  {
    "start": "2449000",
    "end": "2485000"
  },
  {
    "text": "not like how far this will take us yeah I'd say often the",
    "start": "2453460",
    "end": "2459460"
  },
  {
    "text": "um often the returns diminish as you scale the current thing and but then",
    "start": "2459460",
    "end": "2464740"
  },
  {
    "text": "there are other innovations that let you continue uh so I guess I don't see I don't see deep",
    "start": "2464740",
    "end": "2471820"
  },
  {
    "text": "learning in general uh like uh reaching a plateau or anything or hitting diminishing returns uh maybe",
    "start": "2471820",
    "end": "2478900"
  },
  {
    "text": "um just doing the most basic thing uh reaches some diminishing returns",
    "start": "2478900",
    "end": "2484240"
  },
  {
    "text": "yeah makes sense since this is Ray Summit uh let's talk a little bit about distributed systems and",
    "start": "2484240",
    "end": "2491140"
  },
  {
    "start": "2485000",
    "end": "2611000"
  },
  {
    "text": "infrastructure so I'm sure almost no one in this audience knows this but",
    "start": "2491140",
    "end": "2497800"
  },
  {
    "text": "early on or maybe part way through your PhD you actually built your own deep learning framework called computational",
    "start": "2497800",
    "end": "2503859"
  },
  {
    "text": "computation graph toolkit can you share a little bit about why you built that and and what you were trying to achieve",
    "start": "2503859",
    "end": "2510880"
  },
  {
    "text": "yeah back uh some people might remember thiano that was this absolutely that was",
    "start": "2510880",
    "end": "2518320"
  },
  {
    "text": "the uh Auto diff framework from V4 tensorflow and pytorch so Diana was",
    "start": "2518320",
    "end": "2523540"
  },
  {
    "text": "amazing uh and but it also uh was starting to hit its limitations like uh",
    "start": "2523540",
    "end": "2530260"
  },
  {
    "text": "it would sometimes take uh half an hour to compile your your graph before you could do a single step so uh and I",
    "start": "2530260",
    "end": "2538300"
  },
  {
    "text": "wanted to do some things like um I wanted to do some things with recurrent networks and piano wasn't wasn't that",
    "start": "2538300",
    "end": "2544240"
  },
  {
    "text": "great for it so uh so I ended up working on building",
    "start": "2544240",
    "end": "2549760"
  },
  {
    "text": "building one of these things and actually I think it was a great learning experience I mean uh it turned out that",
    "start": "2549760",
    "end": "2555880"
  },
  {
    "text": "uh um Google yeah there's tensorflow and pytorch right after that and those ended",
    "start": "2555880",
    "end": "2562119"
  },
  {
    "text": "up I think you were working on or working on cgt this was 2015. uh yeah in",
    "start": "2562119",
    "end": "2568119"
  },
  {
    "text": "the fall and then tensorflow came out right after that yeah I started working on it before I knew about tensorflow and",
    "start": "2568119",
    "end": "2573339"
  },
  {
    "text": "then I found out about it and maybe part of me was disappointed but uh I was getting",
    "start": "2573339",
    "end": "2579400"
  },
  {
    "text": "um upstage on Google but uh it was it's fine yeah I think uh I think everyone",
    "start": "2579400",
    "end": "2584680"
  },
  {
    "text": "should write their own um autodif uh everyone should at least yeah write",
    "start": "2584680",
    "end": "2590020"
  },
  {
    "text": "their own little Auto diff library at one point to learn get a really good intuition for back prop it's a great",
    "start": "2590020",
    "end": "2595119"
  },
  {
    "text": "idea yeah but this is all yeah the slow compile times yeah for a neural network for",
    "start": "2595119",
    "end": "2601060"
  },
  {
    "text": "current neural networks this is uh I had forgotten about that that was a long time ago um but if I remember correctly it was",
    "start": "2601060",
    "end": "2607060"
  },
  {
    "text": "quite fast it was actually you know quite well architected um and you actually were an early Ray",
    "start": "2607060",
    "end": "2614319"
  },
  {
    "start": "2611000",
    "end": "2659000"
  },
  {
    "text": "user or maybe an you attempted to use Rey uh you used Ray quite a long time ago before it was really ready",
    "start": "2614319",
    "end": "2621099"
  },
  {
    "text": "can you share do you remember what you were trying it for and what your experience was like yeah this was back",
    "start": "2621099",
    "end": "2626440"
  },
  {
    "text": "in 2016 2017 when you guys were just getting started on it and I at the time",
    "start": "2626440",
    "end": "2632380"
  },
  {
    "text": "I was doing uh something in the realm of architecture search um and uh I remember creating some",
    "start": "2632380",
    "end": "2639460"
  },
  {
    "text": "issues on GitHub about the schedule or not doing the right thing yeah which you guys have fixed since then uh but yeah",
    "start": "2639460",
    "end": "2648339"
  },
  {
    "text": "yeah yeah that it's it's come a long way there's still GitHub issues so probably well you closed that issue at some point",
    "start": "2648339",
    "end": "2655240"
  },
  {
    "text": "so I remember seeing it I must have gotten anything about it yeah nice",
    "start": "2655240",
    "end": "2660640"
  },
  {
    "start": "2659000",
    "end": "2770000"
  },
  {
    "text": "um can you share a little bit about you know you guys are pushing the limits at open AI of scale in a lot of different",
    "start": "2660640",
    "end": "2668140"
  },
  {
    "text": "dimensions um and so you may encounter challenges that um a lot of other people don't",
    "start": "2668140",
    "end": "2674260"
  },
  {
    "text": "encounter can you share a little bit about you know what makes infrastructure hard for the kind of AI work you guys do at",
    "start": "2674260",
    "end": "2681400"
  },
  {
    "text": "open AI yeah we have a library for doing distributed training and it does model",
    "start": "2681400",
    "end": "2686619"
  },
  {
    "text": "parallelism so you're sending around weights and gradients and activations and",
    "start": "2686619",
    "end": "2694119"
  },
  {
    "text": "um yeah Ray and we use Rey as a big part of that for uh for doing all the",
    "start": "2694119",
    "end": "2699400"
  },
  {
    "text": "communication and it's um yeah it's been very useful having this uh solid",
    "start": "2699400",
    "end": "2705099"
  },
  {
    "text": "component that we can build on we've had various I mean open AI has a lot of the type of people who like writing their",
    "start": "2705099",
    "end": "2711520"
  },
  {
    "text": "own distributed systems oh yes we've had our own uh yeah Everyone likes writing their own thing we've had our own",
    "start": "2711520",
    "end": "2717280"
  },
  {
    "text": "internal libraries um nothing when you develop something internally it ends up it works great for",
    "start": "2717280",
    "end": "2724240"
  },
  {
    "text": "the person who wrote it but that person usually doesn't want to maintain it for years and uh and then it's not very well",
    "start": "2724240",
    "end": "2730480"
  },
  {
    "text": "documented or general so um yeah we've had our own um like internal systems but then uh I'd say",
    "start": "2730480",
    "end": "2737560"
  },
  {
    "text": "it's been nice switching over to Ray so we have this solid component that is uh",
    "start": "2737560",
    "end": "2743619"
  },
  {
    "text": "very well documented and supported that we can build on yeah so if you weren't using Rey",
    "start": "2743619",
    "end": "2749500"
  },
  {
    "text": "what would you be using yeah we'd probably uh have a we'd probably roll our own thing and use uh tools we'd use",
    "start": "2749500",
    "end": "2756819"
  },
  {
    "text": "the other um lower level tools out there like uh redis and MPI and so forth and just uh",
    "start": "2756819",
    "end": "2763119"
  },
  {
    "text": "glue those together lots of MPI lots of Reddit makes sense",
    "start": "2763119",
    "end": "2769240"
  },
  {
    "text": "nice um so tell us about Chachi PT",
    "start": "2769240",
    "end": "2774520"
  },
  {
    "start": "2770000",
    "end": "2986000"
  },
  {
    "text": "how did you get the idea when did you start working on it yeah right so",
    "start": "2774520",
    "end": "2781000"
  },
  {
    "text": "I'd say it started off uh well well I personally was uh working on",
    "start": "2781000",
    "end": "2788619"
  },
  {
    "text": "um a project called uh web GPT before this which is like uh a question",
    "start": "2788619",
    "end": "2793900"
  },
  {
    "text": "question answering system that does retrieval and it uh so it'll um you ask a question and then uh it'll go and find",
    "start": "2793900",
    "end": "2801099"
  },
  {
    "text": "a bunch of relevant sources by uh doing a web search and uh browsing some of the",
    "start": "2801099",
    "end": "2806440"
  },
  {
    "text": "pages it finds and then uh writing uh one or two paragraph answer with citations and this was what we were",
    "start": "2806440",
    "end": "2813700"
  },
  {
    "text": "trying to get it get at with that project was uh getting language models to use tools and uh and like trying to",
    "start": "2813700",
    "end": "2820720"
  },
  {
    "text": "we were trying to um work on this problem of truthfulness like how can you get models that uh",
    "start": "2820720",
    "end": "2826420"
  },
  {
    "text": "don't make stuff up they just uh say things that are true and based on has that one been solved I'd say we made",
    "start": "2826420",
    "end": "2832359"
  },
  {
    "text": "progress on it it's not completely solved but uh yeah we've come a long way",
    "start": "2832359",
    "end": "2838240"
  },
  {
    "text": "um so yeah we were really interested in truthfulness so that project we had worked on this project and uh done our",
    "start": "2838240",
    "end": "2844960"
  },
  {
    "text": "for we publish a paper about it and we're trying to figure out what was the next uh version of it and",
    "start": "2844960",
    "end": "2851440"
  },
  {
    "text": "um for question answering I'd say uh chat starts to make a lot of sense because you need to do things like follow-up",
    "start": "2851440",
    "end": "2858099"
  },
  {
    "text": "questions and clarifying questions and um uh so and there were some internal uh we",
    "start": "2858099",
    "end": "2865720"
  },
  {
    "text": "had been playing with uh Chad internally a bit uh like at openai and it seemed like the models were quite good at it so",
    "start": "2865720",
    "end": "2873880"
  },
  {
    "text": "um yeah we decided to um use dot like have a dialogue based system for the",
    "start": "2873880",
    "end": "2879040"
  },
  {
    "text": "next iteration of uh our our system uh so we started collecting data in um",
    "start": "2879040",
    "end": "2886119"
  },
  {
    "text": "like early 2022 um uh that was like specific for chat",
    "start": "2886119",
    "end": "2893020"
  },
  {
    "text": "um and uh we were originally it was going to be a successor to this webgbt system and eventually we we really ended",
    "start": "2893020",
    "end": "2900579"
  },
  {
    "text": "up liking the uh chat models and the the whole uh retrieval part and being a",
    "start": "2900579",
    "end": "2906640"
  },
  {
    "text": "little complicated so we temporarily dropped that and we just decided to focus on the chat models",
    "start": "2906640",
    "end": "2913180"
  },
  {
    "text": "um and uh and I'd say we were surprised by how um like how good the models were",
    "start": "2913180",
    "end": "2920920"
  },
  {
    "text": "um or how useful they were so we had an internal demo and um I definitely used the demo a lot for",
    "start": "2920920",
    "end": "2927940"
  },
  {
    "text": "uh coding help um because the models are really good at answering questions about code especially when you're trying to use new",
    "start": "2927940",
    "end": "2934660"
  },
  {
    "text": "libraries so um yeah it became uh well",
    "start": "2934660",
    "end": "2940599"
  },
  {
    "text": "um we started to think that it was a good idea to release uh to like do a public release and uh just",
    "start": "2940599",
    "end": "2947260"
  },
  {
    "text": "let other people try out the model and that that ended up getting delayed a bit because",
    "start": "2947260",
    "end": "2954160"
  },
  {
    "text": "we had uh gpd4 finished training and uh everyone got excited about that about",
    "start": "2954160",
    "end": "2960700"
  },
  {
    "text": "that model and uh the the chat model we had trained that was based on gbd 3.5",
    "start": "2960700",
    "end": "2966180"
  },
  {
    "text": "was uh that kind of got sidelined for a while but uh anyway we we ended up",
    "start": "2966180",
    "end": "2972460"
  },
  {
    "text": "deciding to do a release anyway and worked with the um worked with the",
    "start": "2972460",
    "end": "2977560"
  },
  {
    "text": "product team who put together the UI and everything for it and then ended up launching it late uh in November",
    "start": "2977560",
    "end": "2985300"
  },
  {
    "text": "a year that's a it was a great decision yeah it turned out were you surprised by",
    "start": "2985300",
    "end": "2991060"
  },
  {
    "text": "the just the world's reaction to chat GPT or you know given that you had a lot of experience using it internally did",
    "start": "2991060",
    "end": "2997480"
  },
  {
    "text": "you kind of see that coming um yeah we were very surprised I mean we did have beta testers so we had friends",
    "start": "2997480",
    "end": "3003900"
  },
  {
    "text": "and family using it for a few months beforehand and uh there were definitely some enthusiastic users especially",
    "start": "3003900",
    "end": "3011520"
  },
  {
    "text": "people using it for code but um it didn't really uh like",
    "start": "3011520",
    "end": "3017160"
  },
  {
    "text": "um I don't know people weren't that excited about it and they were not everyone uh ended up",
    "start": "3017160",
    "end": "3023520"
  },
  {
    "text": "um not all the users ended up uh coming back to it a lot so um only a few of the people who who we",
    "start": "3023520",
    "end": "3030300"
  },
  {
    "text": "gave access ended up using it regularly so I think what happened was when everyone got access people",
    "start": "3030300",
    "end": "3036720"
  },
  {
    "text": "um sort of uh taught each other how to use it and what use cases ended up working so it was kind of the social",
    "start": "3036720",
    "end": "3042780"
  },
  {
    "text": "aspect of it was pretty important like people teach each other how to prompt it and what kind of task is good at so I",
    "start": "3042780",
    "end": "3049140"
  },
  {
    "text": "think it really uh just the fact that it was really easy to use and people could uh share uh their use cases with each",
    "start": "3049140",
    "end": "3056460"
  },
  {
    "text": "other um got caused it to cause this this uh Mass",
    "start": "3056460",
    "end": "3061500"
  },
  {
    "text": "excitement yeah so you mentioned using it for help",
    "start": "3061500",
    "end": "3066780"
  },
  {
    "start": "3065000",
    "end": "3094000"
  },
  {
    "text": "coding what about today what do you use Chachi Beauty for today",
    "start": "3066780",
    "end": "3072059"
  },
  {
    "text": "I'd say that's still my uh biggest use case personally uh I I also just use it here and there as",
    "start": "3072059",
    "end": "3079440"
  },
  {
    "text": "uh just to ask questions if I have if I have random questions about history or science or whatever I'll I'll just ask",
    "start": "3079440",
    "end": "3086160"
  },
  {
    "text": "it um but um I'd say uh the one I get the most",
    "start": "3086160",
    "end": "3091200"
  },
  {
    "text": "utility out of is coding yeah so you've been in AI for quite a",
    "start": "3091200",
    "end": "3096480"
  },
  {
    "text": "long time if you look back on your time in AI you",
    "start": "3096480",
    "end": "3101520"
  },
  {
    "text": "know more than a decade what do you think of as the biggest advances or conceptual breakthroughs",
    "start": "3101520",
    "end": "3107880"
  },
  {
    "text": "that have happened during that period well yeah I guess I started grad school",
    "start": "3107880",
    "end": "3114780"
  },
  {
    "text": "in 2010 so that's when I was sort of seriously in the field um",
    "start": "3114780",
    "end": "3119880"
  },
  {
    "text": "and I'd say um back back then well deep learning",
    "start": "3119880",
    "end": "3125280"
  },
  {
    "text": "hadn't really taken off yeah so uh it wasn't even clear",
    "start": "3125280",
    "end": "3130460"
  },
  {
    "text": "I remember thinking that um it wasn't clear what you would use",
    "start": "3130460",
    "end": "3138980"
  },
  {
    "text": "neural nets for like if it wasn't clear that the making the model uh",
    "start": "3138980",
    "end": "3145319"
  },
  {
    "text": "that we would even know what to do if we had a model that had like a a model that",
    "start": "3145319",
    "end": "3150359"
  },
  {
    "text": "was um more powerful um it wasn't even clear exactly what we would do with it um so so I would say there are a few",
    "start": "3150359",
    "end": "3156300"
  },
  {
    "text": "there are a lot of things that were less obvious than like we were um we didn't know deep learning worked",
    "start": "3156300",
    "end": "3162420"
  },
  {
    "text": "really well uh we didn't know um exactly what you would what training objective you would use if you did if we",
    "start": "3162420",
    "end": "3169559"
  },
  {
    "text": "did know that neural Nets could be trained it wasn't clear exactly what to do with them and uh like",
    "start": "3169559",
    "end": "3175319"
  },
  {
    "text": "so I guess the the answer there ended up being fairly simple like whatever uh",
    "start": "3175319",
    "end": "3180599"
  },
  {
    "text": "like you can do reinforcement learning with neural Nets you can train classifiers you can do uh you can do",
    "start": "3180599",
    "end": "3185880"
  },
  {
    "text": "maximum likelihood on sequences um and all these things work pretty well I mean some things that were popular",
    "start": "3185880",
    "end": "3192420"
  },
  {
    "text": "back then didn't end up working that well or didn't scale as well um so yeah it's kind of uh",
    "start": "3192420",
    "end": "3201420"
  },
  {
    "text": "the set of things that ended up scaling wasn't easily foreseeable at that time but yeah and certainly the importance of",
    "start": "3201420",
    "end": "3208619"
  },
  {
    "text": "scaling oh yeah and definitely scaling yeah the fact that scaling was so important and the whole Paradigm of",
    "start": "3208619",
    "end": "3214619"
  },
  {
    "text": "scaling laws yeah yeah I'm sure you've you probably took an introductory machine learning class at some points",
    "start": "3214619",
    "end": "3220440"
  },
  {
    "start": "3216000",
    "end": "3295000"
  },
  {
    "text": "right and at least I don't know about now but a decade ago when they were teaching introductory machine learning",
    "start": "3220440",
    "end": "3226680"
  },
  {
    "text": "courses the course would often start by Framing different areas of machine learning they say they're supervised",
    "start": "3226680",
    "end": "3232380"
  },
  {
    "text": "learning which is like classification and regression and there's unsupervised learning",
    "start": "3232380",
    "end": "3237900"
  },
  {
    "text": "and when we talked about unsupervised learning at least when I took machine learning it was mostly about clustering",
    "start": "3237900",
    "end": "3243480"
  },
  {
    "text": "like k-means clustering and things like that I feel like I'm curious if you would agree that",
    "start": "3243480",
    "end": "3250020"
  },
  {
    "text": "our perspective on unsupervised learning is uh has changed quite a bit over the",
    "start": "3250020",
    "end": "3255780"
  },
  {
    "text": "past decade oh yeah definitely I mean now it's not even clear what unsupervised learning",
    "start": "3255780",
    "end": "3261960"
  },
  {
    "text": "means uh like uh sequence modeling is is uh like the way the language models are",
    "start": "3261960",
    "end": "3269760"
  },
  {
    "text": "trained is that unsupervised learning it's kind of supervised by predicting the future given the past it's you know",
    "start": "3269760",
    "end": "3275400"
  },
  {
    "text": "it still fits into the regression framework but or classification framework but you don't have to spend a",
    "start": "3275400",
    "end": "3281160"
  },
  {
    "text": "lot of energy labeling data and things like that yeah but yeah it's not k-means",
    "start": "3281160",
    "end": "3286500"
  },
  {
    "text": "clustering that's for sure I mean you can say that supervised learning is a special case of uh unsupervised learning",
    "start": "3286500",
    "end": "3292140"
  },
  {
    "text": "or doing maximum likelihood uh so I think you know looking back a decade ago problems like",
    "start": "3292140",
    "end": "3299819"
  },
  {
    "start": "3295000",
    "end": "3392000"
  },
  {
    "text": "unsupervised learning were not that well understood or perhaps we didn't know how",
    "start": "3299819",
    "end": "3305040"
  },
  {
    "text": "to conceptualize the problem what do you think are the problems today that we're still figuring out how to",
    "start": "3305040",
    "end": "3311880"
  },
  {
    "text": "formulate I'd say there's a lot of problems around uh",
    "start": "3311880",
    "end": "3319140"
  },
  {
    "text": "well I'd say one problem I ended up thinking about a lot is data quality and",
    "start": "3319140",
    "end": "3324420"
  },
  {
    "text": "um like how to how to get really good supervision uh for so like gpd4 is",
    "start": "3324420",
    "end": "3330599"
  },
  {
    "text": "really good at a lot of things and it has a lot of breadth of knowledge and it's often hard to even collect good",
    "start": "3330599",
    "end": "3335940"
  },
  {
    "text": "labels to make it better like if you like people ask questions about",
    "start": "3335940",
    "end": "3341520"
  },
  {
    "text": "um also like they ask about all sorts of um obscure topics or very technical topics",
    "start": "3341520",
    "end": "3347640"
  },
  {
    "text": "and it's hard to find people who can label this like who can provide good",
    "start": "3347640",
    "end": "3352920"
  },
  {
    "text": "labels so um so so this um so there's this problem of how do you um",
    "start": "3352920",
    "end": "3359040"
  },
  {
    "text": "how do you supervise a model that's kind of superhuman and uh",
    "start": "3359040",
    "end": "3364980"
  },
  {
    "text": "I would say this is so sometimes this is called scalable oversight or scalable supervision people first got interested",
    "start": "3364980",
    "end": "3371040"
  },
  {
    "text": "in this from the standpoint of alignment and how do you make uh yeah concerned",
    "start": "3371040",
    "end": "3376380"
  },
  {
    "text": "but with uh like the very smart models and how do we make sure they're doing what we like doing what humans want so",
    "start": "3376380",
    "end": "3383880"
  },
  {
    "text": "I'd say uh I'd say in this area like some of the problems haven't even been",
    "start": "3383880",
    "end": "3388920"
  },
  {
    "text": "formulated uh precisely yet yeah so you have good taste in problems and",
    "start": "3388920",
    "end": "3395339"
  },
  {
    "start": "3392000",
    "end": "3433000"
  },
  {
    "text": "what to work on how do you decide what problems to work on",
    "start": "3395339",
    "end": "3401160"
  },
  {
    "text": "yeah I don't think I have a really General uh uh framework for doing this I",
    "start": "3401160",
    "end": "3406319"
  },
  {
    "text": "try to think about what think about some uh some real world use cases and what",
    "start": "3406319",
    "end": "3412619"
  },
  {
    "text": "are some common uh like what are some common like limitations of our existing methods uh",
    "start": "3412619",
    "end": "3420240"
  },
  {
    "text": "that that would unlock a lot of uh opportunities um and I try to try to not yeah try to",
    "start": "3420240",
    "end": "3426599"
  },
  {
    "text": "think of the advances that would feed into a lot of uh that would have a lot of Downstream implications and are you",
    "start": "3426599",
    "end": "3433800"
  },
  {
    "start": "3433000",
    "end": "3532000"
  },
  {
    "text": "thinking about how we get to human level intelligence and kind of working backwards from there or thinking more",
    "start": "3433800",
    "end": "3439319"
  },
  {
    "text": "about products that could be built or applications I'd say I do a little bit of all of",
    "start": "3439319",
    "end": "3445020"
  },
  {
    "text": "those I mean I I I'm thinking about what humans can do and how the human mind can work works and like trying to introspect",
    "start": "3445020",
    "end": "3452640"
  },
  {
    "text": "is useful but it doesn't it can also be misleading so I think it's useful to think about where are humans much better",
    "start": "3452640",
    "end": "3458819"
  },
  {
    "text": "than our models and where we might be missing something but it also um it's",
    "start": "3458819",
    "end": "3463980"
  },
  {
    "text": "hard to predict uh what order we're going to get AI to solve different problems and if something is uh",
    "start": "3463980",
    "end": "3471180"
  },
  {
    "text": "how hard something is for humans doesn't necessarily correlate that well with how hard it is for AI so well math is hard",
    "start": "3471180",
    "end": "3477780"
  },
  {
    "text": "for both of us right definitely yeah so that's one yeah yeah",
    "start": "3477780",
    "end": "3482880"
  },
  {
    "text": "so when you think about the path to say human level intelligence",
    "start": "3482880",
    "end": "3488339"
  },
  {
    "text": "do you think of it as more of a research challenge an engineering challenge both or does the distinction not make sense",
    "start": "3488339",
    "end": "3496559"
  },
  {
    "text": "yeah I'd say it's uh it's both it's a little of both and the the boundary is a",
    "start": "3496559",
    "end": "3501660"
  },
  {
    "text": "little bit blurry like uh definitely um you need to do a lot of engineering to",
    "start": "3501660",
    "end": "3508559"
  },
  {
    "text": "get more data and train bigger models on that data and then there's a lot of research for um",
    "start": "3508559",
    "end": "3515160"
  },
  {
    "text": "like how you can uh to just make that scaling work you need to figure out the",
    "start": "3515160",
    "end": "3522240"
  },
  {
    "text": "recipe of how all your hyper parameters scale and then there but then there's a lot of there's open questions about",
    "start": "3522240",
    "end": "3527700"
  },
  {
    "text": "things like data quality and supervision that I just mentioned and you mentioned high quality data",
    "start": "3527700",
    "end": "3535740"
  },
  {
    "start": "3532000",
    "end": "3599000"
  },
  {
    "text": "in your view when a human is learning right how much high quality data do we",
    "start": "3535740",
    "end": "3540900"
  },
  {
    "text": "have access to like in a normal educational experience um",
    "start": "3540900",
    "end": "3547079"
  },
  {
    "text": "like how much do um like when humans are learning uh like learning from their",
    "start": "3547079",
    "end": "3552359"
  },
  {
    "text": "parents or schools and so forth like yeah I mean we have we have access to tons of data right both",
    "start": "3552359",
    "end": "3557579"
  },
  {
    "text": "things like textbooks as well as just all the you know sensory input that we we get in do you consider some of that",
    "start": "3557579",
    "end": "3565440"
  },
  {
    "text": "high quality and some of that low quality oh yeah well I guess human learning um humans are extremely",
    "start": "3565440",
    "end": "3572700"
  },
  {
    "text": "um I guess humans are able to learn from very undiverse data uh like so I think one of the most remarkable things is",
    "start": "3572700",
    "end": "3578760"
  },
  {
    "text": "that a human can grow up um in like spending most of their time",
    "start": "3578760",
    "end": "3583799"
  },
  {
    "text": "in one households and talking to a small number of people uh maybe going going to",
    "start": "3583799",
    "end": "3590099"
  },
  {
    "text": "school so there's not a lot of data diversity compared to what we train our systems deep learning systems with and",
    "start": "3590099",
    "end": "3597359"
  },
  {
    "text": "but still you get an extremely robust model like a extremely robust Vision system even though you've only seen this",
    "start": "3597359",
    "end": "3603900"
  },
  {
    "text": "one house so that's pretty crazy and I think we're nowhere near there are limits to that though right if you if",
    "start": "3603900",
    "end": "3610140"
  },
  {
    "text": "you've you know never see vertical lines or something like that you know yeah um this has been fascinating are there any",
    "start": "3610140",
    "end": "3617640"
  },
  {
    "text": "common misconceptions that people have about open AI that um you'd like to clarify for us yeah I'd",
    "start": "3617640",
    "end": "3625140"
  },
  {
    "text": "say um sometimes I read Twitter and people are talking about Chad gbt and they uh form they have some speculations",
    "start": "3625140",
    "end": "3632099"
  },
  {
    "text": "about what we're doing and sometimes I I think uh well sometimes people have some",
    "start": "3632099",
    "end": "3639359"
  },
  {
    "text": "uh uh well people often think we're doing a lot more than we're actually doing like they think we're monitoring uh",
    "start": "3639359",
    "end": "3645960"
  },
  {
    "text": "everything like monitoring Twitter and usage in real time and fixing the model uh like fine-tuning uh all the time and",
    "start": "3645960",
    "end": "3653099"
  },
  {
    "text": "fixing all these problems and uh yeah I'd love to do like the jailbreaks oh yeah fixing jailbreaks and uh like",
    "start": "3653099",
    "end": "3659579"
  },
  {
    "text": "finding uh when the model gets a riddle wrong and we're gonna go and fix that uh so yeah it's more like we uh we love to",
    "start": "3659579",
    "end": "3667980"
  },
  {
    "text": "fix things faster but uh it's it's often hard like you can't um you don't want to just and you don't",
    "start": "3667980",
    "end": "3674700"
  },
  {
    "text": "want to just play whack-a-mole and uh fix these little problems um it's I'd rather uh like look at the",
    "start": "3674700",
    "end": "3681960"
  },
  {
    "text": "bulk of use cases and make every every um everyone's experience better so it's more like we uh when we get feedback",
    "start": "3681960",
    "end": "3689160"
  },
  {
    "text": "from people like they give thumbs down we use that as part of our data labeling effort and we we try to collect some",
    "start": "3689160",
    "end": "3696420"
  },
  {
    "text": "labels to to fix those examples but um yeah it's I'd say that's",
    "start": "3696420",
    "end": "3702180"
  },
  {
    "text": "um yeah people also um yeah people think we're doing all sorts",
    "start": "3702180",
    "end": "3708119"
  },
  {
    "text": "of uh crazy things glad to hear it yeah um John it's been a pleasure",
    "start": "3708119",
    "end": "3715559"
  },
  {
    "text": "this is thank you so much for for being here I really enjoyed the conversation uh everyone please join me in thanking",
    "start": "3715559",
    "end": "3723299"
  },
  {
    "text": "John Schulman thanks for having me",
    "start": "3723299",
    "end": "3728560"
  },
  {
    "text": "[Applause] [Music]",
    "start": "3728560",
    "end": "3736740"
  },
  {
    "text": "thank you so much John next up I'm delighted to invite yashu to",
    "start": "3736740",
    "end": "3742920"
  },
  {
    "text": "the stage Yaz VP of engineering at LinkedIn and head of data and AI",
    "start": "3742920",
    "end": "3749760"
  },
  {
    "text": "please welcome yah [Music]",
    "start": "3749760",
    "end": "3761380"
  },
  {
    "text": "hello hello what amazing talk on fireside chat all the crazy and amazing",
    "start": "3762299",
    "end": "3769619"
  },
  {
    "text": "things that they do at open AI but I am mostly excited about I don't know what you all caught John mentioned about this",
    "start": "3769619",
    "end": "3776339"
  },
  {
    "text": "laundry folding robot that he worked on uh that that'll be my request to him",
    "start": "3776339",
    "end": "3783480"
  },
  {
    "text": "um so great to be here today uh to share with you a bit of what we do at LinkedIn just",
    "start": "3783480",
    "end": "3790140"
  },
  {
    "text": "a little bit of a journey that we've taken over the years um uh we're gonna cover a bunch of AI",
    "start": "3790140",
    "end": "3797520"
  },
  {
    "text": "powered products we have and go into a little bit of a take Focus that we have right now and of course at Ray Summit we",
    "start": "3797520",
    "end": "3804780"
  },
  {
    "text": "gotta talk about Rey in case anyone in the audience doesn't",
    "start": "3804780",
    "end": "3811440"
  },
  {
    "text": "know what LinkedIn does I just wanted to highlight we are really focused on",
    "start": "3811440",
    "end": "3817799"
  },
  {
    "text": "creating Economic Opportunity and of course thinking about the entities that",
    "start": "3817799",
    "end": "3824940"
  },
  {
    "text": "we have on our economic graph so that we can do that right we have lots of members schools companies were very",
    "start": "3824940",
    "end": "3833700"
  },
  {
    "text": "vibrantly interacting with each other with tons of posts and job applications",
    "start": "3833700",
    "end": "3839160"
  },
  {
    "text": "that's happening throughout our platform and of course to power all of that is AI",
    "start": "3839160",
    "end": "3846920"
  },
  {
    "text": "behind the scene not surprisingly uh lots of our products",
    "start": "3846920",
    "end": "3852780"
  },
  {
    "text": "uh using AI deeply and starting with search I think nobody here is surprised",
    "start": "3852780",
    "end": "3859799"
  },
  {
    "text": "to hear that obviously search has been the I would say very first industrial",
    "start": "3859799",
    "end": "3865200"
  },
  {
    "text": "scale AI application across and Linkedin is doing the same as well people search",
    "start": "3865200",
    "end": "3872040"
  },
  {
    "text": "job search that a lot of you who are using our consumer product is very familiar with but also with our",
    "start": "3872040",
    "end": "3878700"
  },
  {
    "text": "Enterprise product where we we search for courses search for candidates for",
    "start": "3878700",
    "end": "3883799"
  },
  {
    "text": "recruiters and search for leads on our platform for sales people as well",
    "start": "3883799",
    "end": "3891599"
  },
  {
    "text": "and recommendations another really important aspect of our platform are our products recommending posts for people",
    "start": "3891599",
    "end": "3898740"
  },
  {
    "text": "to read jobs recommending candidates for recruiters recommending people that you",
    "start": "3898740",
    "end": "3906359"
  },
  {
    "text": "may know that you want to connect with in addition to those obvious uh I would",
    "start": "3906359",
    "end": "3914339"
  },
  {
    "text": "say user facing products a lot of our Marketplace design also relies heavily",
    "start": "3914339",
    "end": "3920700"
  },
  {
    "text": "on AI as well going from bid suggestion body recommendation",
    "start": "3920700",
    "end": "3927200"
  },
  {
    "text": "forecasting pacing a lot of what goes into making Marketplace work also relies",
    "start": "3927200",
    "end": "3933900"
  },
  {
    "text": "heavily on AI of course everything we have to take",
    "start": "3933900",
    "end": "3939660"
  },
  {
    "text": "trust and responsible AI deeply from defunding and identifying detecting that",
    "start": "3939660",
    "end": "3946920"
  },
  {
    "text": "actors on the side the bad content all the way to making sure that as we are creating economic opportunities that we",
    "start": "3946920",
    "end": "3954180"
  },
  {
    "text": "really are considering that for every member in the workforce to be fair transparent a lot",
    "start": "3954180",
    "end": "3961619"
  },
  {
    "text": "of what you heard Robert talked about earlier with regarding privacy concerns how do we use differential privacy and",
    "start": "3961619",
    "end": "3968700"
  },
  {
    "text": "federal relearning is also part of what we do as well",
    "start": "3968700",
    "end": "3974520"
  },
  {
    "text": "uh and of course we cannot go on The Talk today without talk about General DVI and ever since about a year ago we",
    "start": "3974520",
    "end": "3982260"
  },
  {
    "text": "have really started to um build a lot of genotype capabilities",
    "start": "3982260",
    "end": "3987299"
  },
  {
    "text": "on our product as well uh I would like to think about uh how AI products in the",
    "start": "3987299",
    "end": "3994260"
  },
  {
    "text": "past mostly working a little bit more in the background where you have the",
    "start": "3994260",
    "end": "3999960"
  },
  {
    "text": "product and user experience and you kind of like you know talk to AI in the background but now ai really has become",
    "start": "3999960",
    "end": "4006140"
  },
  {
    "text": "the product itself and it's coming from really the background to the foreground",
    "start": "4006140",
    "end": "4011839"
  },
  {
    "text": "and we have been working on that uh very deeply over the last year or so and",
    "start": "4011839",
    "end": "4017780"
  },
  {
    "text": "starting from as you can see in the in the demo here where we are helping",
    "start": "4017780",
    "end": "4022839"
  },
  {
    "text": "members to write their profile better with generative AI and to really uh streamlining hiring",
    "start": "4022839",
    "end": "4032000"
  },
  {
    "text": "process with automatically generated job descriptions as well not only just like generating you with a job description",
    "start": "4032000",
    "end": "4038299"
  },
  {
    "text": "but also helping recruiters as they are writing that job description to leverage the skill graph that we have to be much",
    "start": "4038299",
    "end": "4047480"
  },
  {
    "text": "more customized in in the in the in the description that they they're creating",
    "start": "4047480",
    "end": "4052700"
  },
  {
    "text": "we're also helping recruiters write better emails taking into consideration of both the candidates and they are",
    "start": "4052700",
    "end": "4060260"
  },
  {
    "text": "writing email messages too and also the company that's hiring the job that they're hiring for so all these are",
    "start": "4060260",
    "end": "4066859"
  },
  {
    "text": "coming together in our product Suites and we are building way more as well",
    "start": "4066859",
    "end": "4072140"
  },
  {
    "text": "of course powering a lot of the experiences you just saw needs a lot of",
    "start": "4072140",
    "end": "4077299"
  },
  {
    "text": "technology behind the scene as well a few of the things that I'm just gonna touch upon",
    "start": "4077299",
    "end": "4083900"
  },
  {
    "text": "three challenges and opportunities that we are working on starting with AI productivity",
    "start": "4083900",
    "end": "4092680"
  },
  {
    "text": "this may not be a fancy topic to talk about but a lot of you who spend a lot",
    "start": "4092680",
    "end": "4099440"
  },
  {
    "text": "of time developing AI product also know that AI development is very different from traditional software development",
    "start": "4099440",
    "end": "4106338"
  },
  {
    "text": "process right traditionally we have when we develop software it's a by and large",
    "start": "4106339",
    "end": "4112880"
  },
  {
    "text": "a very linear process but AI development is highly non-linear",
    "start": "4112880",
    "end": "4119900"
  },
  {
    "text": "right it's very iterative as an example in order to launch one",
    "start": "4119900",
    "end": "4126318"
  },
  {
    "text": "single model in some of our product Suites it takes over a hundred offline iterations and it takes",
    "start": "4126319",
    "end": "4133100"
  },
  {
    "text": "30 plus online iterations in order to ship one product to production",
    "start": "4133100",
    "end": "4138980"
  },
  {
    "text": "right some of those offline iterations takes hours if not days to run",
    "start": "4138980",
    "end": "4145100"
  },
  {
    "text": "so in order to really leverage Ai and then having this to be magnifying the",
    "start": "4145100",
    "end": "4152960"
  },
  {
    "text": "impact the AI can create getting AI productivity into a better state is a",
    "start": "4152960",
    "end": "4158719"
  },
  {
    "text": "very important line of work that we do and this really goes across multiple different aspects right reducing",
    "start": "4158719",
    "end": "4166278"
  },
  {
    "text": "training time and be able to leverage a GPU training uh incremental training a",
    "start": "4166279",
    "end": "4172880"
  },
  {
    "text": "big effort that we're spending time on and reducing a lot of the the toil that",
    "start": "4172880",
    "end": "4178278"
  },
  {
    "text": "we have in our model development process and also be able to simplify our feature",
    "start": "4178279",
    "end": "4184160"
  },
  {
    "text": "on generation is uh all the three aspects are areas that we are spending a",
    "start": "4184160",
    "end": "4189738"
  },
  {
    "text": "lot of time on yeah we spent a lot of time as you heard earlier talking about ioms obviously",
    "start": "4189739",
    "end": "4197840"
  },
  {
    "text": "those large models they are really needs a lot of our",
    "start": "4197840",
    "end": "4203179"
  },
  {
    "text": "infrastructures to be able to support to train and to serve them but I also just wanted to remind everyone here that LM",
    "start": "4203179",
    "end": "4210260"
  },
  {
    "text": "is not the only large models that powers every line of AI work that we do",
    "start": "4210260",
    "end": "4218239"
  },
  {
    "text": "a lot of the data that we have are not languages right they're not contents",
    "start": "4218239",
    "end": "4223719"
  },
  {
    "text": "they are engagement data I like to post I send a message to somebody I connected",
    "start": "4223719",
    "end": "4230300"
  },
  {
    "text": "with somebody all this comes in a form that is not languages but in a more of a",
    "start": "4230300",
    "end": "4236239"
  },
  {
    "text": "tabular or sometimes graph structured data so we do work heavily on a couple",
    "start": "4236239",
    "end": "4243620"
  },
  {
    "text": "of other architectures that can really help us harness the value of the data in the other formats and we call them large",
    "start": "4243620",
    "end": "4250820"
  },
  {
    "text": "personalization models and graph neural network and really there there's just I'm barely",
    "start": "4250820",
    "end": "4258679"
  },
  {
    "text": "touching the Surface by the way so please feel free to reach out to me afterwards if you wanted to learn more about it but really being able to scale",
    "start": "4258679",
    "end": "4265340"
  },
  {
    "text": "our training um and to be able to uh uh train those",
    "start": "4265340",
    "end": "4271159"
  },
  {
    "text": "models within a reasonable amount of time and it takes a ton of effort uh",
    "start": "4271159",
    "end": "4276260"
  },
  {
    "text": "from both our infrastructure Network and from and algorithms as well in terms of",
    "start": "4276260",
    "end": "4282620"
  },
  {
    "text": "how we're batching them and the ilms and lpms actually also takes very different",
    "start": "4282620",
    "end": "4287739"
  },
  {
    "text": "and and sort of infrastructure needs right LPM is so much more memory and",
    "start": "4287739",
    "end": "4294320"
  },
  {
    "text": "constraint than compute constraint as example and serving them is also obviously very",
    "start": "4294320",
    "end": "4300679"
  },
  {
    "text": "different right you have lpms that takes a lot of invadings and and then being able to have distributed memory to be",
    "start": "4300679",
    "end": "4307219"
  },
  {
    "text": "able to serve them uh and is you know again it's it's quite different",
    "start": "4307219",
    "end": "4312380"
  },
  {
    "text": "um from from LMS as well so a lot of work that goes on in that space in order",
    "start": "4312380",
    "end": "4317540"
  },
  {
    "text": "to push the boundaries and we really have made a lot of uh strides around uh",
    "start": "4317540",
    "end": "4324260"
  },
  {
    "text": "getting our models to be bigger and being able to serve those bigger models but there's just like a lot that we can",
    "start": "4324260",
    "end": "4330020"
  },
  {
    "text": "do in that space as well and uh last but not least General DVI",
    "start": "4330020",
    "end": "4336320"
  },
  {
    "text": "right I mean this is a this is really the password of uh everyone uh have been",
    "start": "4336320",
    "end": "4342860"
  },
  {
    "text": "hearing uh Robert earlier mentioned about there are companies who have been developing AI for years I feel and then",
    "start": "4342860",
    "end": "4349940"
  },
  {
    "text": "but then I you know really also uh just re-evaluating everything that we're doing because General DVI does take a",
    "start": "4349940",
    "end": "4357080"
  },
  {
    "text": "very different uh stack in order to serve them in order to train them as well and here as example is what Kevin",
    "start": "4357080",
    "end": "4365900"
  },
  {
    "text": "Scott shared at the recent Microsoft build conference uh talking about in",
    "start": "4365900",
    "end": "4371780"
  },
  {
    "text": "order to build co-pilot right you got to have the right fun and stack you're going to have the strong orchestrations",
    "start": "4371780",
    "end": "4378260"
  },
  {
    "text": "deck and of course the model stack as well and recently very popular blog post",
    "start": "4378260",
    "end": "4385640"
  },
  {
    "text": "on a16z also have outlined just how",
    "start": "4385640",
    "end": "4391340"
  },
  {
    "text": "expensive in order to serve those iom apps and what's needed",
    "start": "4391340",
    "end": "4397520"
  },
  {
    "text": "and I'm just gonna quickly go through uh what we have been building um as well and then just kind of walk",
    "start": "4397520",
    "end": "4403640"
  },
  {
    "text": "you through a little bit of the stack um starting from Gateway we serve both",
    "start": "4403640",
    "end": "4410960"
  },
  {
    "text": "internal models and leverage uh heavily of open em models as example so having a",
    "start": "4410960",
    "end": "4417800"
  },
  {
    "text": "Gateway that is able to serve those models um doing quota management and monitor utilizations and then be able to",
    "start": "4417800",
    "end": "4426020"
  },
  {
    "text": "do responsible AI checks are really important orchestration layer we build on top of",
    "start": "4426020",
    "end": "4433640"
  },
  {
    "text": "launching and also being able to uh you know we",
    "start": "4433640",
    "end": "4439820"
  },
  {
    "text": "all know there are limitations of LMS a lot of times you know hallucination being able to ground it with the data",
    "start": "4439820",
    "end": "4446480"
  },
  {
    "text": "being able to integrate uh closely with the data that we have is you know using",
    "start": "4446480",
    "end": "4453140"
  },
  {
    "text": "various different internal apis and tools that we generate that we have is",
    "start": "4453140",
    "end": "4458840"
  },
  {
    "text": "really important so that layer is able to select the right tools doing retrieval augmented generation is is",
    "start": "4458840",
    "end": "4466280"
  },
  {
    "text": "very important memory uh obviously very important but also it's not just memory",
    "start": "4466280",
    "end": "4473000"
  },
  {
    "text": "but also being able to do in building-based retrieval where you can",
    "start": "4473000",
    "end": "4478520"
  },
  {
    "text": "compress a lot of the context from the past from the past conversations be able",
    "start": "4478520",
    "end": "4483860"
  },
  {
    "text": "to kind of pinpoint where uh the the the part of the conversation that's most",
    "start": "4483860",
    "end": "4489320"
  },
  {
    "text": "important and the examples that you can leverage in order to respond in the next turn of iterations",
    "start": "4489320",
    "end": "4496940"
  },
  {
    "text": "is really important as well and of course model training fine tuning domain adaptation all this",
    "start": "4496940",
    "end": "4504340"
  },
  {
    "text": "are important layer that we need to build internally as well serving models as those models get much",
    "start": "4504340",
    "end": "4512000"
  },
  {
    "text": "bigger they definitely takes multiple gpus and a lot of times multiple",
    "start": "4512000",
    "end": "4517100"
  },
  {
    "text": "machines in order to serve them trust and responsible AI another very",
    "start": "4517100",
    "end": "4523340"
  },
  {
    "text": "important aspects of our app stack being able to detect The Prompt injection",
    "start": "4523340",
    "end": "4530020"
  },
  {
    "text": "jailbreaking and a lot of our just the trust layers that we usually apply and",
    "start": "4530020",
    "end": "4537500"
  },
  {
    "text": "to our general AI applications all these are really important as well of course",
    "start": "4537500",
    "end": "4543020"
  },
  {
    "text": "also a lot of developer tools being able to help our developers to be a much more",
    "start": "4543020",
    "end": "4549739"
  },
  {
    "text": "productive to be able to do prompt playgrounds and evaluation are also",
    "start": "4549739",
    "end": "4555440"
  },
  {
    "text": "really important and a lot of this I would say that even though that we have a lot of experience building AI",
    "start": "4555440",
    "end": "4562040"
  },
  {
    "text": "applications that are very I would say functionally very similar and to the",
    "start": "4562040",
    "end": "4567500"
  },
  {
    "text": "list that I've included here but because oems work differently and these layers all need to be extended and iterated on",
    "start": "4567500",
    "end": "4575360"
  },
  {
    "text": "in order to make this work for LM applications better",
    "start": "4575360",
    "end": "4580520"
  },
  {
    "text": "okay so uh last but not least let's talk a little bit about Rey",
    "start": "4580520",
    "end": "4586580"
  },
  {
    "text": "um uh as you can tell with a lot of the scale that I just described and the",
    "start": "4586580",
    "end": "4593239"
  },
  {
    "text": "applications that we built um we heavily leverage Rey for our",
    "start": "4593239",
    "end": "4599659"
  },
  {
    "text": "training stack for hyper parameter optimization um so",
    "start": "4599659",
    "end": "4605840"
  },
  {
    "text": "um the the part where Ray camping really handy not only because a lot of our",
    "start": "4605840",
    "end": "4612520"
  },
  {
    "text": "models itself the single models needs tuning but also we a lot of times have",
    "start": "4612520",
    "end": "4618739"
  },
  {
    "text": "to trade off across multiple different objectives right this thing we call",
    "start": "4618739",
    "end": "4625420"
  },
  {
    "text": "multi-objective optimization is you also need to be able to tune the weights when",
    "start": "4625420",
    "end": "4631520"
  },
  {
    "text": "you are combining different objectives together and we for that reason we heavily uh involve Ray in our tuning and",
    "start": "4631520",
    "end": "4640219"
  },
  {
    "text": "our chain stack in order to scale and really helping our AI Engineers to be much more productive as they're building",
    "start": "4640219",
    "end": "4646640"
  },
  {
    "text": "those models and also we talk about how inference is",
    "start": "4646640",
    "end": "4652460"
  },
  {
    "text": "no longer simple right so I traditionally when we are building our search and recommendations deck you have",
    "start": "4652460",
    "end": "4660020"
  },
  {
    "text": "your model you maybe have a you know L1 L2 and you kind of have some business Logic on top of it and it wasn't uh so",
    "start": "4660020",
    "end": "4669739"
  },
  {
    "text": "complicated but as you can see in these graphs and we talk about earlier iom inference is a lot more complicated and",
    "start": "4669739",
    "end": "4677060"
  },
  {
    "text": "so in order to do uh those ml apps that",
    "start": "4677060",
    "end": "4682400"
  },
  {
    "text": "we're building you will have multiple models some of them doing intent detection some of them needed to do",
    "start": "4682400",
    "end": "4688580"
  },
  {
    "text": "multiple different sub models that the intent layer can",
    "start": "4688580",
    "end": "4694820"
  },
  {
    "text": "then route to so in order to orchestrate all that model serving we heavily rely",
    "start": "4694820",
    "end": "4702380"
  },
  {
    "text": "on right as race serving in particular that is able to help us to break the",
    "start": "4702380",
    "end": "4707420"
  },
  {
    "text": "inference graph in a much more atomic level at the same time also be able to optimize our usage between our CPUs and",
    "start": "4707420",
    "end": "4715640"
  },
  {
    "text": "gpus Etc so so really I I a great piece of infrastructure that I have built that",
    "start": "4715640",
    "end": "4722719"
  },
  {
    "text": "we are able to Leverage uh if you wanted to hear more about how we are using right we do have a couple",
    "start": "4722719",
    "end": "4729679"
  },
  {
    "text": "talks uh and this afternoon uh one by uh",
    "start": "4729679",
    "end": "4735199"
  },
  {
    "text": "Sasha and Ali I'm talking a lot about our inference graphs uh editing",
    "start": "4735199",
    "end": "4740780"
  },
  {
    "text": "um and uh Frank um and Wei is going to talk about hyper",
    "start": "4740780",
    "end": "4746840"
  },
  {
    "text": "parameter tooling and how we are integrating it in our training stack this afternoon as well so I really",
    "start": "4746840",
    "end": "4752659"
  },
  {
    "text": "highly encourage you all to attend our talks and where's that thank you for",
    "start": "4752659",
    "end": "4757940"
  },
  {
    "text": "spending the time and I'm gonna hand it over our Beauty back to Robert",
    "start": "4757940",
    "end": "4764619"
  },
  {
    "text": "please welcome to the stage executive chairman any scale professor at UC",
    "start": "4770780",
    "end": "4776900"
  },
  {
    "text": "Berkeley Jan stoica [Music]",
    "start": "4776900",
    "end": "4787159"
  },
  {
    "text": "running everyone since we had our last zombie one year ago many things happened",
    "start": "4787159",
    "end": "4793640"
  },
  {
    "text": "and of course Chief among them has been the llm revolution charging PPT was launched just two",
    "start": "4793640",
    "end": "4801800"
  },
  {
    "text": "months after our last Summit and it went to become the fastest growing consumer product",
    "start": "4801800",
    "end": "4808580"
  },
  {
    "text": "reaching 1 million users in just five days and 100 millions in just two months",
    "start": "4808580",
    "end": "4814760"
  },
  {
    "text": "and in the process achieved significant milestones",
    "start": "4814760",
    "end": "4819640"
  },
  {
    "text": "first it's it's performing now well enough so it's going to it can pass a",
    "start": "4819920",
    "end": "4825739"
  },
  {
    "text": "bad exam and in the form of the copilot it can double the product the programmer",
    "start": "4825739",
    "end": "4832460"
  },
  {
    "text": "productivity so what else has happened since then",
    "start": "4832460",
    "end": "4837739"
  },
  {
    "text": "first open source models are catching up this is a leaderboard we developed at UC",
    "start": "4837739",
    "end": "4843920"
  },
  {
    "text": "berically to evaluate the most popular chat Bots",
    "start": "4843920",
    "end": "4849260"
  },
  {
    "text": "and as you can see while the proprietary models are still at the top of the",
    "start": "4849260",
    "end": "4854659"
  },
  {
    "text": "leaderboard the open source models here with yellow are not far behind",
    "start": "4854659",
    "end": "4861739"
  },
  {
    "text": "one reason open source models are becoming an alternative to proprietary",
    "start": "4861739",
    "end": "4866900"
  },
  {
    "text": "models is fine tuning you heard about fine tuning early on let me tell you a",
    "start": "4866900",
    "end": "4872060"
  },
  {
    "text": "little bit more so here are three relatively common llm tasks",
    "start": "4872060",
    "end": "4877580"
  },
  {
    "text": "functional representation natural language to SQL translation you have",
    "start": "4877580",
    "end": "4882679"
  },
  {
    "text": "heard about that a few times already and a mass benchmark and we slide gray we have the accuracy",
    "start": "4882679",
    "end": "4890120"
  },
  {
    "text": "of gpd4 and with blue the accuracy of the smallest lamato model",
    "start": "4890120",
    "end": "4896420"
  },
  {
    "text": "as expected gpt4 performed much better there is really no competition",
    "start": "4896420",
    "end": "4901520"
  },
  {
    "text": "however if you fine-tune the open source models things change",
    "start": "4901520",
    "end": "4906860"
  },
  {
    "text": "their accuracy in two out of three tasks exceed of that of gpt4",
    "start": "4906860",
    "end": "4913100"
  },
  {
    "text": "and for the last task the mass benchmarks you can actually bridge the",
    "start": "4913100",
    "end": "4918320"
  },
  {
    "text": "gap considerably by using the largest lamatry model",
    "start": "4918320",
    "end": "4923840"
  },
  {
    "text": "so in summary fine-tune OSS mode open source model can outperform gpt4 for",
    "start": "4923840",
    "end": "4931520"
  },
  {
    "text": "some important practical tasks now this is a plot I shared with you",
    "start": "4931520",
    "end": "4938900"
  },
  {
    "text": "last year and it basically shows that the compute demands to train the largest",
    "start": "4938900",
    "end": "4945440"
  },
  {
    "text": "model have grown 10 times over every 18 months since the beginning of 2010 at",
    "start": "4945440",
    "end": "4954500"
  },
  {
    "text": "the same time the mass law is growing just twice every 18 months and actually as you know this Moore's",
    "start": "4954500",
    "end": "4962300"
  },
  {
    "text": "law has slowed down over the past two decades so actually the gap between the demand of",
    "start": "4962300",
    "end": "4968780"
  },
  {
    "text": "these models and capabilities of this a single node or a single processor it's",
    "start": "4968780",
    "end": "4975260"
  },
  {
    "text": "even bigger than this plot suggests so what happens over the last year well",
    "start": "4975260",
    "end": "4980659"
  },
  {
    "text": "here is a gpt4 so as you can see the growth in the demands of these models",
    "start": "4980659",
    "end": "4986060"
  },
  {
    "text": "has been growing unabated again this machine that there is no way",
    "start": "4986060",
    "end": "4993560"
  },
  {
    "text": "to scale these workloads but to distribute these workloads this was true to last year it's even",
    "start": "4993560",
    "end": "5000159"
  },
  {
    "text": "more true today and this of course has an impact on the costs",
    "start": "5000159",
    "end": "5005920"
  },
  {
    "text": "GPT 3 was released in 2020 and it cost between 4.6 million and 12 Millions to",
    "start": "5005920",
    "end": "5012219"
  },
  {
    "text": "train depending on what source you are using two years later",
    "start": "5012219",
    "end": "5018179"
  },
  {
    "text": "gpt4 was released and according to Sam Alman it cost over 100 million to train",
    "start": "5018179",
    "end": "5024699"
  },
  {
    "text": "so an increase between 8.8 and and 22 times",
    "start": "5024699",
    "end": "5031980"
  },
  {
    "text": "but things are even more challenging even if you have money you may not find gpus",
    "start": "5032560",
    "end": "5039580"
  },
  {
    "text": "the GPU shortage has been so severe that it has impacted the roadmap of GPU Rich",
    "start": "5039580",
    "end": "5047020"
  },
  {
    "text": "organization like open AI so what has been the consequence of such",
    "start": "5047020",
    "end": "5052659"
  },
  {
    "text": "severe shortage first this scarcity presents a big",
    "start": "5052659",
    "end": "5059080"
  },
  {
    "text": "opportunity for Hardware vendors so more and more of these vendors have",
    "start": "5059080",
    "end": "5065080"
  },
  {
    "text": "introduced or announced new hardware accelerators for AI over the past year",
    "start": "5065080",
    "end": "5072100"
  },
  {
    "text": "second over the past year we have seen the emergence of more clouds",
    "start": "5072100",
    "end": "5077380"
  },
  {
    "text": "in addition to the big three AWS Azure and gcp we are seeing more and more clouds which",
    "start": "5077380",
    "end": "5084760"
  },
  {
    "text": "targets to alleviate this scarcity of gpus by providing more GPU capacity",
    "start": "5084760",
    "end": "5090699"
  },
  {
    "text": "often at lower prices and as the llm models become more and",
    "start": "5090699",
    "end": "5099100"
  },
  {
    "text": "more powerful the application are becoming more sophisticated more complex",
    "start": "5099100",
    "end": "5105219"
  },
  {
    "text": "here again you just seen that this is the llm llm application stack according",
    "start": "5105219",
    "end": "5112659"
  },
  {
    "text": "to a16z which was published a few months ago and you can see it's quite complex",
    "start": "5112659",
    "end": "5118120"
  },
  {
    "text": "there are 15 boxes in this diagram and here is another diagram for",
    "start": "5118120",
    "end": "5123940"
  },
  {
    "text": "a canonical alarm application again quite complex so while llms are are holding a huge",
    "start": "5123940",
    "end": "5132040"
  },
  {
    "text": "promise there are three challenges that are threatening the revolution",
    "start": "5132040",
    "end": "5138040"
  },
  {
    "text": "first the growing complexity which is driven by the increasing heterogeneous",
    "start": "5138040",
    "end": "5143640"
  },
  {
    "text": "heterogeneity and hardware and in the clouds as well as a growing complexity of the",
    "start": "5143640",
    "end": "5150100"
  },
  {
    "text": "applications themselves second is an increasing scale and finally skyrocketing costs",
    "start": "5150100",
    "end": "5158940"
  },
  {
    "text": "now Ray holistically addresses all of these challenges",
    "start": "5159340",
    "end": "5164440"
  },
  {
    "text": "the central component of Ray is Ray core and Ray core is an operating system for",
    "start": "5164440",
    "end": "5171580"
  },
  {
    "text": "heterogeneous distributed computing because it's generality you support virtually any AI workload",
    "start": "5171580",
    "end": "5178960"
  },
  {
    "text": "including all llama workloads and to make it easy it provides several",
    "start": "5178960",
    "end": "5184000"
  },
  {
    "text": "libraries serve tune train reinforcement learning and data",
    "start": "5184000",
    "end": "5192100"
  },
  {
    "text": "so therefore with Ray instead of using different",
    "start": "5192100",
    "end": "5197980"
  },
  {
    "text": "each of these words and then stick together the system for your endpoint application you need to",
    "start": "5197980",
    "end": "5204159"
  },
  {
    "text": "use only one system so Rey provides you a unified",
    "start": "5204159",
    "end": "5212139"
  },
  {
    "text": "framework for all your application workloads",
    "start": "5212139",
    "end": "5217620"
  },
  {
    "text": "in addition we have been working hard to make it as easy as possible to render up",
    "start": "5218860",
    "end": "5225280"
  },
  {
    "text": "your application on a diverse set of clouds and Hardware accelerators",
    "start": "5225280",
    "end": "5231880"
  },
  {
    "text": "and finally from day one we build Rey to scale from one nodes to hundreds or even",
    "start": "5231880",
    "end": "5239500"
  },
  {
    "text": "thousands of nodes so perhaps not surprising given the",
    "start": "5239500",
    "end": "5245800"
  },
  {
    "text": "ability to address the llm challenges since last year's race adoption has accelerated",
    "start": "5245800",
    "end": "5251920"
  },
  {
    "text": "the number of yet have stars has been growing faster than ever and this is compared with other very successful open",
    "start": "5251920",
    "end": "5259120"
  },
  {
    "text": "source distributed Frameworks the number of contributors increased by",
    "start": "5259120",
    "end": "5265540"
  },
  {
    "text": "25 percent the largest year-to-year increase we have seen but most impressively the number of Ray",
    "start": "5265540",
    "end": "5274600"
  },
  {
    "text": "clusters has increased six times just from the beginning of this year so in 10",
    "start": "5274600",
    "end": "5280120"
  },
  {
    "text": "months so what we focused on over the last year",
    "start": "5280120",
    "end": "5286840"
  },
  {
    "text": "well not surprisingly we focused on further addressing the llm challenges I",
    "start": "5286840",
    "end": "5292540"
  },
  {
    "text": "just mentioned reducing complexity improving scalability reducing the cost",
    "start": "5292540",
    "end": "5300480"
  },
  {
    "text": "so let me start with what we have done to reduce the complexity and improve the",
    "start": "5300520",
    "end": "5305620"
  },
  {
    "text": "so and improve the scalability first we had improved the scalability",
    "start": "5305620",
    "end": "5311500"
  },
  {
    "text": "and stability of kubray so now you can deploy any re-application",
    "start": "5311500",
    "end": "5317920"
  },
  {
    "text": "on any kubernetes cluster and the growth in adoption was",
    "start": "5317920",
    "end": "5323260"
  },
  {
    "text": "outstanding since the beginning of the year the number of Ray clusters using",
    "start": "5323260",
    "end": "5329260"
  },
  {
    "text": "Cube Ray has grown 15 times second with Ray serve we have focused on",
    "start": "5329260",
    "end": "5336639"
  },
  {
    "text": "simplifying the development and deployment of the llm services to do so Reserve provides support for",
    "start": "5336639",
    "end": "5344020"
  },
  {
    "text": "composing service composing models the ability to serve large models on",
    "start": "5344020",
    "end": "5349719"
  },
  {
    "text": "multiple nodes to combine business logic with the inference and provide support",
    "start": "5349719",
    "end": "5357100"
  },
  {
    "text": "for streaming outputs to make it easier to build chatbot applications",
    "start": "5357100",
    "end": "5362980"
  },
  {
    "text": "and when it comes to scale and group has been running racer in production",
    "start": "5362980",
    "end": "5369400"
  },
  {
    "text": "over 4000 gpus and half a million CPUs",
    "start": "5369400",
    "end": "5374860"
  },
  {
    "text": "and since the beginning of this year the number of Ray safe clusters has increased six times",
    "start": "5374860",
    "end": "5382179"
  },
  {
    "text": "finally with raytrain we focus on simplifying the task of fine tuning",
    "start": "5382179",
    "end": "5388300"
  },
  {
    "text": "raytrain provides support for distributed training and high parameter tuning high-speed data ingestions and",
    "start": "5388300",
    "end": "5396520"
  },
  {
    "text": "support the major machine learning libraries including pytorch tensorflow",
    "start": "5396520",
    "end": "5402639"
  },
  {
    "text": "hugging phase deep speed since the beginning of the year the",
    "start": "5402639",
    "end": "5408580"
  },
  {
    "text": "number of freight train cluster has increased 10 times",
    "start": "5408580",
    "end": "5413620"
  },
  {
    "text": "these libraries are used today by hundreds of organizations and I'm very excited that a few of these leading",
    "start": "5413620",
    "end": "5421060"
  },
  {
    "text": "organizations are here as a ray Summit to share their experience with us",
    "start": "5421060",
    "end": "5427060"
  },
  {
    "text": "finally I'm very excited to announce that kubrey Ray serve and raytrain are",
    "start": "5427060",
    "end": "5434500"
  },
  {
    "text": "all now generally available",
    "start": "5434500",
    "end": "5438300"
  },
  {
    "text": "let us turn our attention to reducing the cost I will illustrate three ways Rey enables",
    "start": "5445800",
    "end": "5452739"
  },
  {
    "text": "you to reduce the cost by exploring exploiting resource heterogeneity race flexibility",
    "start": "5452739",
    "end": "5460960"
  },
  {
    "text": "and finally be taking advantage of state-of-the-art accelerators",
    "start": "5460960",
    "end": "5467800"
  },
  {
    "text": "first consider a batch inference a typical application here we first load the data then we",
    "start": "5467800",
    "end": "5475600"
  },
  {
    "text": "preprocess it then we we perform inference on the data and save the",
    "start": "5475600",
    "end": "5480940"
  },
  {
    "text": "results because of very flexibility and generality we can implement the entire",
    "start": "5480940",
    "end": "5486040"
  },
  {
    "text": "Pipeline on top of Ray in addition what Ray allows you is to",
    "start": "5486040",
    "end": "5491380"
  },
  {
    "text": "run different stages of this Pipeline on different Hardware so you can run the data stages on CPUs",
    "start": "5491380",
    "end": "5497380"
  },
  {
    "text": "and the inferences on GPS and by doing so what you get significant",
    "start": "5497380",
    "end": "5504699"
  },
  {
    "text": "cost savings for instance in this case to process 1 million images you pay only 3.5 dollars",
    "start": "5504699",
    "end": "5512860"
  },
  {
    "text": "on AWS to do the same with the leading open source framework you can pay almost",
    "start": "5512860",
    "end": "5520840"
  },
  {
    "text": "double 7.3 dollars and if you want to do this with a leading machine learning",
    "start": "5520840",
    "end": "5525940"
  },
  {
    "text": "platform you can pay 16 times more so huge cost savings",
    "start": "5525940",
    "end": "5532260"
  },
  {
    "text": "here is another example from our friends from samsara they have a serving application they",
    "start": "5532480",
    "end": "5538600"
  },
  {
    "text": "implemented using a micro service architecture again it has three stages in the first stage you get the query use",
    "start": "5538600",
    "end": "5546100"
  },
  {
    "text": "some business logic to select the model to serve that query and just do some data processing in the second stage you",
    "start": "5546100",
    "end": "5553540"
  },
  {
    "text": "are going to compute the embeddings and you are going to use a model you selected on that query and finally in",
    "start": "5553540",
    "end": "5560260"
  },
  {
    "text": "the last stage you are going to use some business logic to filter the to filter the results the first and the last stage are",
    "start": "5560260",
    "end": "5567100"
  },
  {
    "text": "implemented in goal and the stage in the middle the inference stages implemented in pi in in Python",
    "start": "5567100",
    "end": "5573880"
  },
  {
    "text": "the samsara samsara engineer they took this applications redesigned it and",
    "start": "5573880",
    "end": "5579760"
  },
  {
    "text": "implemented on top of it again because of Ray generality and flexibility they could implement the",
    "start": "5579760",
    "end": "5584920"
  },
  {
    "text": "entire Pipeline on top of in a single system and because they've done that they can",
    "start": "5584920",
    "end": "5590560"
  },
  {
    "text": "obviate the need for expensive serialization deserialization between these stages as well as more efficiently",
    "start": "5590560",
    "end": "5598300"
  },
  {
    "text": "shared resources across these different stages and by doing so they reduce our",
    "start": "5598300",
    "end": "5604540"
  },
  {
    "text": "cost by 50 percent with the advantage of this new hardware",
    "start": "5604540",
    "end": "5610360"
  },
  {
    "text": "accelerator developer developers have now more choices than ever to further reduce the cost for certain workloads to",
    "start": "5610360",
    "end": "5618460"
  },
  {
    "text": "enable Ray developers to do so we have been hard at work which are which are",
    "start": "5618460",
    "end": "5623739"
  },
  {
    "text": "adding additional support for the new hardware accelerators in addition to Nvidia gpus now Ray",
    "start": "5623739",
    "end": "5631020"
  },
  {
    "text": "supports PPO ports from gcp and is going to our support for AWS inferentia and",
    "start": "5631020",
    "end": "5638679"
  },
  {
    "text": "trainium in the next list and support for Intel Gaudi by the end of the year",
    "start": "5638679",
    "end": "5644679"
  },
  {
    "text": "you can hear more about this integration tomorrow during a special keynote on Hardware accelerators",
    "start": "5644679",
    "end": "5652500"
  },
  {
    "text": "so I hope that by now I convince you that Ray is a perfect framework to build",
    "start": "5652659",
    "end": "5659739"
  },
  {
    "text": "scale and deploy all your AI and llm workloads",
    "start": "5659739",
    "end": "5666280"
  },
  {
    "text": "however as good as Ray is any scale is even better and why because any scale is",
    "start": "5666280",
    "end": "5672639"
  },
  {
    "text": "the best place to develop and run Ray and llm applications",
    "start": "5672639",
    "end": "5677860"
  },
  {
    "text": "before you hear more about any scale platform let me give you some teasers first here are the previous results from",
    "start": "5677860",
    "end": "5685780"
  },
  {
    "text": "our batching batch inference application so how does any scale perform here well",
    "start": "5685780",
    "end": "5691540"
  },
  {
    "text": "quite well if you take the same Ray pipeline without any code changes and you run it",
    "start": "5691540",
    "end": "5698739"
  },
  {
    "text": "on top of any scale you can get a further reduction in AWS cost of 28",
    "start": "5698739",
    "end": "5704980"
  },
  {
    "text": "percent and here is another example as you heard earlier in the day one of the most",
    "start": "5704980",
    "end": "5711699"
  },
  {
    "text": "important telegram workload is servic and one of the most important metric here is how long it takes to start up a",
    "start": "5711699",
    "end": "5719620"
  },
  {
    "text": "serving instance and with any scale we reduce the time to",
    "start": "5719620",
    "end": "5726400"
  },
  {
    "text": "start this instance for serving the largest lamatoo model by 14 times",
    "start": "5726400",
    "end": "5733540"
  },
  {
    "text": "this big reduction also help us to reduce the cost by using spot instances",
    "start": "5733540",
    "end": "5738760"
  },
  {
    "text": "how is this working well assume that you use an AWS spot instance",
    "start": "5738760",
    "end": "5744639"
  },
  {
    "text": "as you know spot instances are cheap but can be preempted however before they are preempted you get a two minutes",
    "start": "5744639",
    "end": "5750580"
  },
  {
    "text": "notification any scale can use this notification to start a new instance",
    "start": "5750580",
    "end": "5756699"
  },
  {
    "text": "and redirect the request from the old instance to the new instance before the",
    "start": "5756699",
    "end": "5762760"
  },
  {
    "text": "old instance is preempted and by doing so you can use spot",
    "start": "5762760",
    "end": "5767860"
  },
  {
    "text": "instances with no impact whatsoever on availability and in the process you can save up to",
    "start": "5767860",
    "end": "5774580"
  },
  {
    "text": "three times the cost",
    "start": "5774580",
    "end": "5777360"
  },
  {
    "text": "when we created Ray and then any scale were inspired by this famous quote from",
    "start": "5782739",
    "end": "5789820"
  },
  {
    "text": "Alan K the inventor of object oriented programming and during Award winner",
    "start": "5789820",
    "end": "5794980"
  },
  {
    "text": "simplest thing should be simple and complex things should be possible with any scale endpoint",
    "start": "5794980",
    "end": "5802420"
  },
  {
    "text": "we make simple things simple you can literally start in minutes to",
    "start": "5802420",
    "end": "5807760"
  },
  {
    "text": "build your simple application however the any scale platform exposes a full power of Ray",
    "start": "5807760",
    "end": "5814480"
  },
  {
    "text": "and lets you build any kind of application no matter how complicated it is so he really there are no limits to",
    "start": "5814480",
    "end": "5821980"
  },
  {
    "text": "what you can build with any scale platform to hear more about the any scale",
    "start": "5821980",
    "end": "5827800"
  },
  {
    "text": "platform please join me in welcoming cine rapsat the head of product management at any scale",
    "start": "5827800",
    "end": "5836000"
  },
  {
    "text": "[Applause] [Music] [Applause] [Music]",
    "start": "5836000",
    "end": "5844239"
  },
  {
    "text": "all right well it's actually warmer out here than it is back there this is great I was",
    "start": "5844239",
    "end": "5849460"
  },
  {
    "text": "wondering whether I should put my sweater on um look it's really exciting to see all the great capabilities we've delivered",
    "start": "5849460",
    "end": "5854980"
  },
  {
    "text": "on the race side of things to help AI innovators really build extend and ultimately future proof their AI",
    "start": "5854980",
    "end": "5862120"
  },
  {
    "text": "platforms but there's a couple of other types of organizations that we also want to be",
    "start": "5862120",
    "end": "5867520"
  },
  {
    "text": "able to support here now we're seeing two patterns emerge with organizations we're seeing one set",
    "start": "5867520",
    "end": "5873400"
  },
  {
    "text": "of organizations that are moving very very quickly they're starting to experiment validate those experiments and ultimately start",
    "start": "5873400",
    "end": "5879639"
  },
  {
    "text": "to ramp up their applications leveraging Public Services like what you've heard we deliver but any scale",
    "start": "5879639",
    "end": "5884800"
  },
  {
    "text": "endpoints but there's a number of other organizations that do start there but they have more",
    "start": "5884800",
    "end": "5890260"
  },
  {
    "text": "requirements they need to find solutions that have the right privacy the right performance to be able to operate in the",
    "start": "5890260",
    "end": "5895900"
  },
  {
    "text": "environments and at the scale that they're going to require for their their applications as well and so a big part",
    "start": "5895900",
    "end": "5901300"
  },
  {
    "text": "of what we're focused on here at any scale is delivering a solution that helps organizations meet the needs they have today",
    "start": "5901300",
    "end": "5906940"
  },
  {
    "text": "for AI applications as well as prepare them for what they'll need tomorrow to run",
    "start": "5906940",
    "end": "5912280"
  },
  {
    "text": "their innovation and so I want to talk through",
    "start": "5912280",
    "end": "5918400"
  },
  {
    "text": "the product portfolio that we have here at any scale so first we have any skill endpoints as you saw that's our serverless solution",
    "start": "5918400",
    "end": "5926500"
  },
  {
    "text": "API based to give folks access to the best OSS llms",
    "start": "5926500",
    "end": "5932800"
  },
  {
    "text": "for the best cost and here I want to talk a little bit about what that really means when we say",
    "start": "5932800",
    "end": "5938320"
  },
  {
    "text": "the best costs we're serious we're now delivering large models so llama 70b and codelama 34b for a dollar",
    "start": "5938320",
    "end": "5945520"
  },
  {
    "text": "per million tokens but as we mentioned earlier smaller models often cost less so Lama 13B we're",
    "start": "5945520",
    "end": "5953980"
  },
  {
    "text": "now offering it for 25 cents per million tokens and we're offering llama 7B for 15 cents per million tokens",
    "start": "5953980",
    "end": "5962320"
  },
  {
    "text": "I'd encourage folks to take a look at this URL go there by the time you know maybe there's some eagle-eyed folks that",
    "start": "5962320",
    "end": "5967900"
  },
  {
    "text": "have already gone there and may even have actually gotten access to an API endpoint by the time I'm finished with this slide definitely can be done by the",
    "start": "5967900",
    "end": "5973900"
  },
  {
    "text": "time I'm done with the next slide it's a super easy process to get started and integrate llms into your application",
    "start": "5973900",
    "end": "5981540"
  },
  {
    "text": "but we don't just stop there we've also created any skills private endpoints",
    "start": "5983260",
    "end": "5988600"
  },
  {
    "text": "we needed to do this because organizations want to be able to have more ability to control customize and",
    "start": "5988600",
    "end": "5995500"
  },
  {
    "text": "ultimately get the Privacy privacy that they need to get the benefit of llm applications both for their external as",
    "start": "5995500",
    "end": "6001139"
  },
  {
    "text": "well as for their internal use cases and in addition to that we want to give folks the ability to really dial in the",
    "start": "6001139",
    "end": "6008100"
  },
  {
    "text": "right cost by taking advantage of whatever discount structures you've been able to accomplish with your Cloud",
    "start": "6008100",
    "end": "6013560"
  },
  {
    "text": "providers and be able to select which types of gpus and CPUs you use to execute your AI",
    "start": "6013560",
    "end": "6020639"
  },
  {
    "text": "workloads we also allow folks to dial in the right level of quality",
    "start": "6020639",
    "end": "6025920"
  },
  {
    "text": "by adjusting the settings that you want for the llms that you want to deliver in your applications",
    "start": "6025920",
    "end": "6033860"
  },
  {
    "text": "and these two solutions are built on top of the rich capabilities that are offered",
    "start": "6034320",
    "end": "6040860"
  },
  {
    "text": "by the full any scale AI platform and so we're gradually revealing more",
    "start": "6040860",
    "end": "6046739"
  },
  {
    "text": "and more capabilities to organizations as they go along this journey and as they go along through our",
    "start": "6046739",
    "end": "6052980"
  },
  {
    "text": "product portfolio so the any scale AI platform gives you the ability to operate across multiple",
    "start": "6052980",
    "end": "6058920"
  },
  {
    "text": "clouds scale your workloads automatically and leverage the best compute that's",
    "start": "6058920",
    "end": "6064620"
  },
  {
    "text": "available to run your workloads at any time up to an including spot instances we can dynamically schedule workloads to",
    "start": "6064620",
    "end": "6071159"
  },
  {
    "text": "take advantage of the best available resources and the best available cost",
    "start": "6071159",
    "end": "6076760"
  },
  {
    "text": "we invest heavily in optimizations of CPUs and gpus from a single GPU perspective making sure we pack the gpus",
    "start": "6076980",
    "end": "6084300"
  },
  {
    "text": "with workloads so that they're being used as efficiently as possible and scaling to be able to have workloads",
    "start": "6084300",
    "end": "6090120"
  },
  {
    "text": "run across multiple gpus to take advantage of the most complex workloads you want to be able to run",
    "start": "6090120",
    "end": "6097340"
  },
  {
    "text": "for Developers we give folks the ability to maintain a single python native environment",
    "start": "6097560",
    "end": "6104639"
  },
  {
    "text": "at any scale of workload they're trying to work with whether from their individual laptop all the way up to",
    "start": "6104639",
    "end": "6110100"
  },
  {
    "text": "cloud and global scale workloads",
    "start": "6110100",
    "end": "6114560"
  },
  {
    "text": "for those folks that are working directly with the models we offer lots of tools to help folks train models very very quickly as well",
    "start": "6115440",
    "end": "6122580"
  },
  {
    "text": "as for with quickness oftentimes comes good cost and make sure that you can continuously",
    "start": "6122580",
    "end": "6128520"
  },
  {
    "text": "tune those models as your application evolves social does the quality of your model need to evolve",
    "start": "6128520",
    "end": "6136080"
  },
  {
    "text": "and finally on top of all of that we deliver a powerful serving infrastructure both for dynamic",
    "start": "6136080",
    "end": "6141780"
  },
  {
    "text": "real-time serving as well as for batch inference to make sure that any",
    "start": "6141780",
    "end": "6147480"
  },
  {
    "text": "application architecture you want to deliver can be delivered through the any",
    "start": "6147480",
    "end": "6152580"
  },
  {
    "text": "scale AI platform",
    "start": "6152580",
    "end": "6156020"
  },
  {
    "text": "we also integrate out of the box with a wide range of ecosystem vendors a big part of this is to make sure that you",
    "start": "6158040",
    "end": "6164280"
  },
  {
    "text": "get access to the latest greatest application technology to be able to power your AI applications in addition",
    "start": "6164280",
    "end": "6171119"
  },
  {
    "text": "to making sure that your AI platform is ultimately truly future proof",
    "start": "6171119",
    "end": "6177619"
  },
  {
    "text": "and this is all based on the super solid foundation of Rey making it easier for",
    "start": "6177780",
    "end": "6183179"
  },
  {
    "text": "folks to build and deliver the AI applications they want",
    "start": "6183179",
    "end": "6188239"
  },
  {
    "text": "so what we're seeing as we talk to organizations about the patterns the application patterns they're creating it's not just a one llm world",
    "start": "6193139",
    "end": "6200699"
  },
  {
    "text": "organizations will typically start with a general purpose llm like a chat like a chat GPT or gpd35 Turbo or gpt4",
    "start": "6200699",
    "end": "6209460"
  },
  {
    "text": "and they'll use that for the general knowledge that needs to be delivered as part of the application but more and more we're seeing folks start to",
    "start": "6209460",
    "end": "6216300"
  },
  {
    "text": "train smaller models or deploy smaller models to be able to accomplish specific tasks within a broader AI application",
    "start": "6216300",
    "end": "6225119"
  },
  {
    "text": "and what we're finding is this is a perfect opportunity for open source models and ultimately any scales",
    "start": "6225119",
    "end": "6230280"
  },
  {
    "text": "platform to be able to deliver these capabilities to allow folks to right size the model right size the cost",
    "start": "6230280",
    "end": "6236400"
  },
  {
    "text": "get the performance you need as you start to integrate multiple models into a single application",
    "start": "6236400",
    "end": "6241679"
  },
  {
    "text": "coupled with the privacy and control that you ultimately want for your applications end to end",
    "start": "6241679",
    "end": "6248460"
  },
  {
    "text": "but don't just take my word for it we've been busy here at any scale not just building this great platform and this",
    "start": "6248460",
    "end": "6254580"
  },
  {
    "text": "open source solution called Ray we've also been building llm applications ourselves",
    "start": "6254580",
    "end": "6260639"
  },
  {
    "text": "and a lot of our energy has been focused on how do we help folks develop AI applications so we've actually built an",
    "start": "6260639",
    "end": "6268080"
  },
  {
    "text": "AI application that will help organizations develop AI applications and so I'd like to",
    "start": "6268080",
    "end": "6273179"
  },
  {
    "text": "introduce Philip co-founder and CTO of any scale and Goku an ml engineer here at any",
    "start": "6273179",
    "end": "6279960"
  },
  {
    "text": "scale to tell us more about what they've built with the team Goku Phillip [Applause]",
    "start": "6279960",
    "end": "6285770"
  },
  {
    "text": "[Music]",
    "start": "6285770",
    "end": "6292159"
  },
  {
    "text": "thanks Sydney so as Sydney just mentioned we've been hard at work both developing and productionizing LM",
    "start": "6292159",
    "end": "6298800"
  },
  {
    "text": "applications internally over the last several months and today we'd love to share a few of them with you and also",
    "start": "6298800",
    "end": "6305040"
  },
  {
    "text": "talk about some of the challenges we Face along the way so with impelling the ray assistant which is a tool that helps developers",
    "start": "6305040",
    "end": "6311219"
  },
  {
    "text": "answer their question about the right ecosystem and um every day thousands of people come to",
    "start": "6311219",
    "end": "6316860"
  },
  {
    "text": "the right documentation um to get help and so um we are building an assistant that",
    "start": "6316860",
    "end": "6324060"
  },
  {
    "text": "allows eclist here for that documentation and it allows you to answer the questions awesome so to",
    "start": "6324060",
    "end": "6329639"
  },
  {
    "text": "actually demo this Philip I have some workloads that I personally need help with and I'd love to use this to make that happen so I've got a lot of",
    "start": "6329639",
    "end": "6336420"
  },
  {
    "text": "documents in an S3 bucket and First Step I'd love to actually load them all right so how to load",
    "start": "6336420",
    "end": "6343260"
  },
  {
    "text": "all text files from what is the bucket it's called Ray",
    "start": "6343260",
    "end": "6348719"
  },
  {
    "text": "Dash documents all right let's see what the system says",
    "start": "6348719",
    "end": "6354540"
  },
  {
    "text": "so um it's uh um it's actually not enough for this question to just square and llm but you want the context of",
    "start": "6354540",
    "end": "6361619"
  },
  {
    "text": "array in the right documentation so we're retrieving the relevant documents and then if you see it tells us how to",
    "start": "6361619",
    "end": "6367199"
  },
  {
    "text": "load um the red and this document these documents here um and in this case actually the query",
    "start": "6367199",
    "end": "6373199"
  },
  {
    "text": "is fairly simple and it's actually going to use lamba 70b and to answer the",
    "start": "6373199",
    "end": "6379500"
  },
  {
    "text": "question so let's run this all right",
    "start": "6379500",
    "end": "6387080"
  },
  {
    "text": "excellent so that's a lot of documents and besides just loading them now I want",
    "start": "6387420",
    "end": "6392699"
  },
  {
    "text": "to be able to embed them and I just spent some time on the langchain documentation page and I learned how to",
    "start": "6392699",
    "end": "6398159"
  },
  {
    "text": "embed couple sentences using an embedding model from hugging face but we have a lot of docs and I'd love to learn",
    "start": "6398159",
    "end": "6403860"
  },
  {
    "text": "how to embed all of them in parallel all right let's ask the assistant how to paralyze",
    "start": "6403860",
    "end": "6411320"
  },
  {
    "text": "the following code example over the data set",
    "start": "6412440",
    "end": "6419900"
  },
  {
    "text": "the ads let's copy a new example",
    "start": "6420360",
    "end": "6425000"
  },
  {
    "text": "let's see what we get so in this case actually um the query is a little bit more",
    "start": "6426300",
    "end": "6432780"
  },
  {
    "text": "complicated it involves code examples and so and we actually routing the query now to gpd4 and it's actually doing a",
    "start": "6432780",
    "end": "6439560"
  },
  {
    "text": "good job so I'm it's actually quite impressive that it figures out that this model needs gpus so it's going to set",
    "start": "6439560",
    "end": "6445739"
  },
  {
    "text": "the right GPU setting here and then it also uses Ray data and predictors and",
    "start": "6445739",
    "end": "6452219"
  },
  {
    "text": "then my batches um to parallelize the model so let's try it out",
    "start": "6452219",
    "end": "6458239"
  },
  {
    "text": "and then I'm also going to",
    "start": "6461520",
    "end": "6465080"
  },
  {
    "text": "show all right so this now runs on the",
    "start": "6469139",
    "end": "6474900"
  },
  {
    "text": "document and then it shows the answer architecture to run and then you see",
    "start": "6474900",
    "end": "6482040"
  },
  {
    "text": "here the all embeddings for the documents cool so now Goku is going to tell us",
    "start": "6482040",
    "end": "6487080"
  },
  {
    "text": "what challenges we run into while developing this application awesome thanks Phillip so this application that we just saw may",
    "start": "6487080",
    "end": "6494100"
  },
  {
    "text": "feel like your canonical hello world of LM applications that we've all seen probably over the last several months",
    "start": "6494100",
    "end": "6499440"
  },
  {
    "text": "but actually developing this and productionizing it certainly came with this fair share of challenges for us to",
    "start": "6499440",
    "end": "6505679"
  },
  {
    "text": "start off as Phil mentioned at the very beginning we had to augment these LMS with the relevant context and for that",
    "start": "6505679",
    "end": "6511320"
  },
  {
    "text": "we use retrieval augmented generation or rag and if we hadn't done this rlms would",
    "start": "6511320",
    "end": "6517440"
  },
  {
    "text": "hallucinate incorrect responses now when building an application like this there are a lot of moving pieces here we had",
    "start": "6517440",
    "end": "6524280"
  },
  {
    "text": "to load our data chunk it embed it index it of course put it all together to create the application itself and we",
    "start": "6524280",
    "end": "6530699"
  },
  {
    "text": "wanted our application to not just work today but continue to work as our data sources grow and our models grow so to",
    "start": "6530699",
    "end": "6537420"
  },
  {
    "text": "help with this we used Ray data and race serve in order to scale out all of these",
    "start": "6537420",
    "end": "6543360"
  },
  {
    "text": "workloads all within python with minimal changes to our code now when you have so many moving pieces",
    "start": "6543360",
    "end": "6549060"
  },
  {
    "text": "like this there are so many different configurations that you can have for example what kind of chunking logic to",
    "start": "6549060",
    "end": "6554219"
  },
  {
    "text": "use what embedding models to use and of course what LMS to actually use as well so we actually spend a lot of time",
    "start": "6554219",
    "end": "6560520"
  },
  {
    "text": "thinking about evaluation because it's pretty non-trivial to compare different configurations across each other for a",
    "start": "6560520",
    "end": "6566580"
  },
  {
    "text": "generative tasks like this so we looked at both component wise and overall evaluation and we use the scale",
    "start": "6566580",
    "end": "6573239"
  },
  {
    "text": "workloads from the previous step to be able to run a lot of different experiments and with our experiments of course we found",
    "start": "6573239",
    "end": "6580199"
  },
  {
    "text": "that the most performant model was often the most expensive and closed Source model as well but open source models",
    "start": "6580199",
    "end": "6587280"
  },
  {
    "text": "like llama 270b were right behind in terms of quality at a fraction of the cost but our main challenge was that we",
    "start": "6587280",
    "end": "6593280"
  },
  {
    "text": "wanted to serve the most performant model but also in the most cost effective way so we implemented a hybrid",
    "start": "6593280",
    "end": "6600060"
  },
  {
    "text": "LM routing approach where we basically trained a small classifier that can discern which llm a specific query",
    "start": "6600060",
    "end": "6607260"
  },
  {
    "text": "should go to and for our specific application we found that over 95 of queries can be sent to an open source",
    "start": "6607260",
    "end": "6613560"
  },
  {
    "text": "model like llama 270b but a small subset of Highly complex queries can be routed",
    "start": "6613560",
    "end": "6619260"
  },
  {
    "text": "to a more expensive and larger model this was our way of Bridging the Gap",
    "start": "6619260",
    "end": "6624420"
  },
  {
    "text": "between closed source and open source models but most importantly helping us serve the best application we could to",
    "start": "6624420",
    "end": "6630060"
  },
  {
    "text": "all of you now putting all of this together the any scale platform was beyond crucial when",
    "start": "6630060",
    "end": "6636300"
  },
  {
    "text": "it came to development we got to choose the exact environment and compute needs that we wanted to have on top of our",
    "start": "6636300",
    "end": "6642060"
  },
  {
    "text": "workspaces and then taking all this development and actually putting into production we could use that exact same",
    "start": "6642060",
    "end": "6647219"
  },
  {
    "text": "configuration to now do things like running jobs like indexing and embedding new data that's coming in or of course",
    "start": "6647219",
    "end": "6653520"
  },
  {
    "text": "serving our actual application in a highly scalable and available manner now creating an application like this",
    "start": "6653520",
    "end": "6660420"
  },
  {
    "text": "and many others has already had tremendous impact on both our products and our productivity but it's also",
    "start": "6660420",
    "end": "6666659"
  },
  {
    "text": "opened up a whole new class of algorithms that just previously weren't possible for us so to talk a little bit",
    "start": "6666659",
    "end": "6672300"
  },
  {
    "text": "more about this I'd like to invite Sydney back up on stage thank you [Music] [Applause]",
    "start": "6672300",
    "end": "6679280"
  },
  {
    "text": "[Music] good stuff folks",
    "start": "6679280",
    "end": "6686639"
  },
  {
    "text": "so as we've seen we've developed a really cool application to help folks build AI applications",
    "start": "6686639",
    "end": "6691920"
  },
  {
    "text": "and along the way we learned a lot Goku called them challenges I also might call them learnings",
    "start": "6691920",
    "end": "6697040"
  },
  {
    "text": "uh one of the things that we learned was the importance of debugging and so another AI application that the team",
    "start": "6697040",
    "end": "6703440"
  },
  {
    "text": "created um that one gentleman is going to get to take you through is about helping folks",
    "start": "6703440",
    "end": "6709380"
  },
  {
    "text": "debug AI applications so please join me in welcoming sophian ml engineer here at Ma scale",
    "start": "6709380",
    "end": "6716960"
  },
  {
    "text": "[Applause] [Music] [Applause]",
    "start": "6717160",
    "end": "6722420"
  },
  {
    "text": "[Music] well thank you Sydney so I could as you can imagine working on",
    "start": "6722420",
    "end": "6729360"
  },
  {
    "text": "AI infrastructure we actually have to go through a lot of debugging and troubleshooting",
    "start": "6729360",
    "end": "6734639"
  },
  {
    "text": "so uh let me start with a very simple example here and it's going to be two",
    "start": "6734639",
    "end": "6739800"
  },
  {
    "text": "symbol all what I have is one one Jupiter notebook cell that is trying",
    "start": "6739800",
    "end": "6745860"
  },
  {
    "text": "to import the request module and if I were to run it surprise Price It's Gonna fail it's a debugging demo",
    "start": "6745860",
    "end": "6752760"
  },
  {
    "text": "so notice how the any scale doctor icon has showed up right here it's basically recognized that something",
    "start": "6752760",
    "end": "6759840"
  },
  {
    "text": "went wrong and it's offering to help but I know what you're thinking you're thinking this is a module not found",
    "start": "6759840",
    "end": "6765119"
  },
  {
    "text": "error it's one of the most common errors that we have to deal with as Developers and the fix is actually quite simple you",
    "start": "6765119",
    "end": "6771600"
  },
  {
    "text": "just need to start a terminal activate the right conda environment if you're using one and then get the name of the",
    "start": "6771600",
    "end": "6777960"
  },
  {
    "text": "module if you don't know it and then depending on the packaging system perhaps you're using pip or poetry you need to type that command",
    "start": "6777960",
    "end": "6786060"
  },
  {
    "text": "so it's a simple fix but it's actually one that requires understanding the",
    "start": "6786060",
    "end": "6791340"
  },
  {
    "text": "context understanding the environment that you're running in and that's perhaps why the majority of",
    "start": "6791340",
    "end": "6796619"
  },
  {
    "text": "us have developed that muscle memory to run those type of commands manually so let's take a look at what the any",
    "start": "6796619",
    "end": "6802860"
  },
  {
    "text": "scale doctor has done here so first it categorized the problem as a dependency issue and then it decided to consult",
    "start": "6802860",
    "end": "6810300"
  },
  {
    "text": "code llama for help and now it's offering me a quick fix right inside my environment so if I were",
    "start": "6810300",
    "end": "6816900"
  },
  {
    "text": "to click on it it's going to start a terminal it's gonna issue the PIP install command and when it's over I can",
    "start": "6816900",
    "end": "6822960"
  },
  {
    "text": "run it again and it passes thank you",
    "start": "6822960",
    "end": "6830000"
  },
  {
    "text": "this is a simple problem let's move on to something that is slightly more complex and what I have here is a logic",
    "start": "6830040",
    "end": "6836940"
  },
  {
    "text": "that is trying to embed a large number of documents into a vector database and it also has failed resulting in this",
    "start": "6836940",
    "end": "6843480"
  },
  {
    "text": "really massive log so I'm gonna ask any scale doctor again for help here and usually my own process stores trying to",
    "start": "6843480",
    "end": "6850260"
  },
  {
    "text": "debug those type of applications is all not the most patient person so I'll just scroll through the log as fast as I can",
    "start": "6850260",
    "end": "6856199"
  },
  {
    "text": "until I find something that looks suspicious and then if I'm lucky with a little bit of research I would come up",
    "start": "6856199",
    "end": "6862080"
  },
  {
    "text": "with a theory and come back and fix it and be out of it in 10 or 15 minutes but it's not uncommon that sometimes I",
    "start": "6862080",
    "end": "6868139"
  },
  {
    "text": "need to collect more information perhaps I need to look at the array dashboard and get more logs or I need to look at the",
    "start": "6868139",
    "end": "6873719"
  },
  {
    "text": "system metrics through the grafana dashboard if it's a really bad day and I find",
    "start": "6873719",
    "end": "6878820"
  },
  {
    "text": "myself digging through GitHub trying to find that issue or even worse writer myself",
    "start": "6878820",
    "end": "6885179"
  },
  {
    "text": "we dread those type of issue as developers because we know they can be massive productivity hits I'm sure a lot",
    "start": "6885179",
    "end": "6891600"
  },
  {
    "text": "of us here have have been in a place where a task that should have taken minutes it takes hours or perhaps days",
    "start": "6891600",
    "end": "6898739"
  },
  {
    "text": "so let's take a look here and see what the any scale doctor has done so first it started by summarizing the problem",
    "start": "6898739",
    "end": "6906540"
  },
  {
    "text": "so unlike the first example where the entire log was simply the error in this",
    "start": "6906540",
    "end": "6911820"
  },
  {
    "text": "case we have a log of thousands of lines and finding the relevant Parts is crucial",
    "start": "6911820",
    "end": "6916980"
  },
  {
    "text": "and then it went in to classify this problem as an infrastructure issue",
    "start": "6916980",
    "end": "6923100"
  },
  {
    "text": "and then it decided to consult the ray assistant for help",
    "start": "6923100",
    "end": "6928980"
  },
  {
    "text": "the ray assistant the very same system that Philip and Goku just presented except what Philip showed you is",
    "start": "6928980",
    "end": "6936300"
  },
  {
    "text": "that system powering the UI of the ray documentation and in this case we're actually using it to power a branch of",
    "start": "6936300",
    "end": "6944040"
  },
  {
    "text": "the any scale doctor and it's again providing me an error right in my environment so if I were",
    "start": "6944040",
    "end": "6950400"
  },
  {
    "text": "have I were to hover over this error and look through it obviously don't need to read this you would find an error",
    "start": "6950400",
    "end": "6956280"
  },
  {
    "text": "message that is very personalized it's basically telling me that the logic that I'm trying to run here requires access",
    "start": "6956280",
    "end": "6963179"
  },
  {
    "text": "to precisely to gpus and my environment consists of CPUs only and it's not",
    "start": "6963179",
    "end": "6968699"
  },
  {
    "text": "stopping here it's going on to explain in more details ways that I can fix this problem is suggesting that maybe I need",
    "start": "6968699",
    "end": "6975840"
  },
  {
    "text": "to update my cluster to include access to the required hardware perhaps refactor my logic so I can run it on CPU",
    "start": "6975840",
    "end": "6983100"
  },
  {
    "text": "both are examples of things that I actually want to consider",
    "start": "6983100",
    "end": "6988440"
  },
  {
    "text": "so we've seen any scale doctor helping with small repetitive tasks that until shortly where outside the",
    "start": "6988440",
    "end": "6995760"
  },
  {
    "text": "capabilities of the current tooling and with complex tasks Tesla requires understanding the environment that",
    "start": "6995760",
    "end": "7001880"
  },
  {
    "text": "requires the ability to summarize and research so let's switch back to the slides and",
    "start": "7001880",
    "end": "7007880"
  },
  {
    "text": "talk a little bit about how we build the any scale doctor so we needed to start with data data is",
    "start": "7007880",
    "end": "7014060"
  },
  {
    "text": "the foundation we had to go and categorize a large number of Errors to understand what type of issues our",
    "start": "7014060",
    "end": "7019520"
  },
  {
    "text": "customers are seeing and when when it came the time to build the llm application it wasn't just a single",
    "start": "7019520",
    "end": "7025460"
  },
  {
    "text": "application it was a graph of llm nodes where we had to break down the tasks",
    "start": "7025460",
    "end": "7030619"
  },
  {
    "text": "into smaller parts where we can optimize and choose the best alarm for the task",
    "start": "7030619",
    "end": "7037280"
  },
  {
    "text": "and that's perhaps our biggest takeaway out of this project it's very hard to do those type of applications and deliver",
    "start": "7037280",
    "end": "7043340"
  },
  {
    "text": "the experiences we wanted to deliver with a single shot llm we obviously needed a rag application we",
    "start": "7043340",
    "end": "7050900"
  },
  {
    "text": "needed to overcome that knowledge gap of llms and for that we use the ray assistant and finally all of this",
    "start": "7050900",
    "end": "7057320"
  },
  {
    "text": "required a reliable serving infrastructure and for that we use the any scale endpoints this is a simplified",
    "start": "7057320",
    "end": "7063560"
  },
  {
    "text": "version of the architecture of the unscale doctor and you can see a mixture of models being used here all the way",
    "start": "7063560",
    "end": "7070340"
  },
  {
    "text": "from Lana 70b to code Lama to the ray assistant as well and all of this is",
    "start": "7070340",
    "end": "7075860"
  },
  {
    "text": "made possible by the power of the any scale platform from development to production as well as the any scale",
    "start": "7075860",
    "end": "7081800"
  },
  {
    "text": "endpoint and the ray ecosystem so we're excited for you to build amazing applications on the any scale",
    "start": "7081800",
    "end": "7087320"
  },
  {
    "text": "platform and hopefully the unskilled doctor can help you do that just a little bit faster with that I'd like to",
    "start": "7087320",
    "end": "7092780"
  },
  {
    "text": "invite back into the stage and thank you very much [Applause]",
    "start": "7092780",
    "end": "7099920"
  },
  {
    "text": "thank you thank you Sofia [Applause] [Music]",
    "start": "7099920",
    "end": "7106979"
  },
  {
    "text": "so during this Keynote you have seen how you can use that on",
    "start": "7108440",
    "end": "7113719"
  },
  {
    "text": "any scale for developing scaling and productizing all your llm applications from the simplest one to the most",
    "start": "7113719",
    "end": "7121280"
  },
  {
    "text": "complex one there is really no limit to what you can do with Ray and any scale",
    "start": "7121280",
    "end": "7127460"
  },
  {
    "text": "and now there is a time for the last Act of the Keynote everyone here knows and loves Nvidia",
    "start": "7127460",
    "end": "7134960"
  },
  {
    "text": "they have been building the chips that have powered the llm revolution",
    "start": "7134960",
    "end": "7140900"
  },
  {
    "text": "so please join me in welcoming Justin Boitano the VP of nvidia's AI Enterprise",
    "start": "7140900",
    "end": "7147500"
  },
  {
    "text": "who is going to share with us some exciting news about Rey and nvidia's AI",
    "start": "7147500",
    "end": "7154400"
  },
  {
    "text": "ecosystem [Music] [Applause] [Music]",
    "start": "7154400",
    "end": "7164869"
  },
  {
    "text": "excellent look at this a packed house",
    "start": "7166040",
    "end": "7170800"
  },
  {
    "text": "um well I just want to start by congratulating the ray ecosystem and the",
    "start": "7171080",
    "end": "7176119"
  },
  {
    "text": "any scale team they've done an amazing job building this community and that's the reason that we're here from Nvidia",
    "start": "7176119",
    "end": "7182300"
  },
  {
    "text": "is we've been watching from the outside we're an accelerated Computing company but Rey is really this foundational run",
    "start": "7182300",
    "end": "7189320"
  },
  {
    "text": "time that the world needs to scale llms across the data center extremely efficiently and the any scale platform",
    "start": "7189320",
    "end": "7196219"
  },
  {
    "text": "and Rey provide that to customers they make it super easy to go to thousands of",
    "start": "7196219",
    "end": "7201800"
  },
  {
    "text": "nodes and and it makes it really seamless for customers to take large language models and scale them into",
    "start": "7201800",
    "end": "7207560"
  },
  {
    "text": "production as you know Nvidia is an accelerated Computing company and this means we try",
    "start": "7207560",
    "end": "7213679"
  },
  {
    "text": "to squeeze the performance out of every open framework we usually work with Frameworks like tensorflow and Pi torch",
    "start": "7213679",
    "end": "7220400"
  },
  {
    "text": "we pull them down on a monthly basis to keep up with API progress in the ecosystem we fully tune them to run on",
    "start": "7220400",
    "end": "7227840"
  },
  {
    "text": "our gpus on CPUs and on networking to give customers the benefits and advantage of performance increases in",
    "start": "7227840",
    "end": "7234980"
  },
  {
    "text": "cost savings and we Upstream all that work back into the community about five years ago we also realized that",
    "start": "7234980",
    "end": "7242000"
  },
  {
    "text": "accelerated Computing really needed to come to the world of data science and so we built on top of Apache Arrow a",
    "start": "7242000",
    "end": "7248599"
  },
  {
    "text": "project that we maintain that's called Rapids and it brings accelerated Computing into the world of scikit-learn",
    "start": "7248599",
    "end": "7255679"
  },
  {
    "text": "and pandas and again it's an open project for the community and the reason that we're here is we see the importance",
    "start": "7255679",
    "end": "7263239"
  },
  {
    "text": "of bringing together the world's best accelerated Computing together with the world's best attributed Computing and we",
    "start": "7263239",
    "end": "7270619"
  },
  {
    "text": "see this partnership with with Ray in any scale being just a very symbiotic and natural partnership",
    "start": "7270619",
    "end": "7277580"
  },
  {
    "text": "um the beauty of the open source is that Innovation can happen really quickly um last week we announced a new project",
    "start": "7277580",
    "end": "7283639"
  },
  {
    "text": "we called tensor RT llm and it's already been included into Ray serve and the",
    "start": "7283639",
    "end": "7289400"
  },
  {
    "text": "value of this is immense you know customers if they Benchmark tensor RT llm running on our Hopper h100 gpus",
    "start": "7289400",
    "end": "7296480"
  },
  {
    "text": "versus our previous generation gpus see this dramatic 8X performance Improvement",
    "start": "7296480",
    "end": "7302360"
  },
  {
    "text": "they see a 5x reduction in the cost to run large language models and they get a 5x Improvement in terms of Energy",
    "start": "7302360",
    "end": "7309080"
  },
  {
    "text": "Efficiency and running large language models at scale which is really important for you know the industry as a",
    "start": "7309080",
    "end": "7315380"
  },
  {
    "text": "whole um but beyond tensor RT llm there's a number of other projects such as Nemo",
    "start": "7315380",
    "end": "7321679"
  },
  {
    "text": "which is our large language model framework it's an open uh Cloud native",
    "start": "7321679",
    "end": "7326780"
  },
  {
    "text": "framework that helps with everything from training models to tuning models running them efficiently in production",
    "start": "7326780",
    "end": "7332900"
  },
  {
    "text": "and Guard railing them so that they say they stay on topic and the work that",
    "start": "7332900",
    "end": "7337940"
  },
  {
    "text": "we're doing through tensor rtlm and Nemo will be you know first first class",
    "start": "7337940",
    "end": "7343340"
  },
  {
    "text": "citizens and fully integrated into the ray ecosystem which is great for the community",
    "start": "7343340",
    "end": "7349159"
  },
  {
    "text": "um but the question I always get from customers is okay you know uh how do we take generative AI from this research",
    "start": "7349159",
    "end": "7356179"
  },
  {
    "text": "phase into production um and as I walk into Enterprises around the world what I constantly hear from",
    "start": "7356179",
    "end": "7361460"
  },
  {
    "text": "them is they've got you know dozens of these projects underway they're trying to use generative AI to deliver better",
    "start": "7361460",
    "end": "7367159"
  },
  {
    "text": "co-pilots uh for developers to write code faster and be more productive they're trying to provide natural",
    "start": "7367159",
    "end": "7372980"
  },
  {
    "text": "language interfaces into itinhr systems they're trying to provide customer",
    "start": "7372980",
    "end": "7378619"
  },
  {
    "text": "support chat Bots that help customers solve their problems on their own and so the use cases are Broad and wide but the",
    "start": "7378619",
    "end": "7385880"
  },
  {
    "text": "question is like how do we how do we deliver this value in a way that customers can run these in production now Nvidia knows uh working in open",
    "start": "7385880",
    "end": "7394639"
  },
  {
    "text": "source is fantastic for unlocking Innovation quickly but you need a downstream nvidia's Downstream of our AI",
    "start": "7394639",
    "end": "7401360"
  },
  {
    "text": "software is called Nvidia AI Enterprise and this is really the the operating system of artificial intelligence and I",
    "start": "7401360",
    "end": "7408679"
  },
  {
    "text": "say this because you know we work to do all this security scanning and patching and maintenance and maintain API",
    "start": "7408679",
    "end": "7416179"
  },
  {
    "text": "stability for people that want to run these large language models in production which is critical for Enterprises who don't have the manpower",
    "start": "7416179",
    "end": "7422599"
  },
  {
    "text": "to roll their own distribution and run it in production so as part of the the work that we're doing with the any scale",
    "start": "7422599",
    "end": "7429500"
  },
  {
    "text": "team is we're going to certify Nvidia AI Enterprise to run on any scale platform",
    "start": "7429500",
    "end": "7435500"
  },
  {
    "text": "so customers if they want to run these large language models in production can have the combined support from any scale",
    "start": "7435500",
    "end": "7441739"
  },
  {
    "text": "in Nvidia and have the confidence that they can run large language models in production so it's just what the",
    "start": "7441739",
    "end": "7447199"
  },
  {
    "text": "industry needs kind of at this uh the beginning here of of you know making large language models broadly available",
    "start": "7447199",
    "end": "7453739"
  },
  {
    "text": "to the world's Enterprises so thank you very much appreciate you guys having me",
    "start": "7453739",
    "end": "7461020"
  },
  {
    "text": "[Music] [Applause] [Music] and thank you all for a great start of",
    "start": "7462810",
    "end": "7469880"
  },
  {
    "text": "our Ray Summit this brings us to the lunch break but a",
    "start": "7469880",
    "end": "7475340"
  },
  {
    "text": "few announcements before then first please visit the rayground and",
    "start": "7475340",
    "end": "7481040"
  },
  {
    "text": "before that if you didn't you haven't gotten your badge please do so because you are going to need for the background",
    "start": "7481040",
    "end": "7487460"
  },
  {
    "text": "and therefore the breakout sessions also tomorrow keynote is going to start",
    "start": "7487460",
    "end": "7493880"
  },
  {
    "text": "at 9 9 am with that thank you again and enjoy the",
    "start": "7493880",
    "end": "7499099"
  },
  {
    "text": "rest of the day [Applause]",
    "start": "7499099",
    "end": "7503640"
  }
]
[
  {
    "text": "yeah so actually Frank and I both",
    "start": "3659",
    "end": "6120"
  },
  {
    "text": "started off as a PhD students at",
    "start": "6120",
    "end": "8580"
  },
  {
    "text": "Berkeley and one of the main projects",
    "start": "8580",
    "end": "10740"
  },
  {
    "text": "that we worked on together was this EXO",
    "start": "10740",
    "end": "13080"
  },
  {
    "text": "Shuffle project which was looking at how",
    "start": "13080",
    "end": "15299"
  },
  {
    "text": "we can do mapreduce on Ray and Frank",
    "start": "15299",
    "end": "18000"
  },
  {
    "text": "will tell you more about that later in",
    "start": "18000",
    "end": "19740"
  },
  {
    "text": "this talk",
    "start": "19740",
    "end": "21119"
  },
  {
    "text": "um but for first I wanted to talk a",
    "start": "21119",
    "end": "23100"
  },
  {
    "text": "little bit about just the right data",
    "start": "23100",
    "end": "24960"
  },
  {
    "text": "plane in general how it came about and",
    "start": "24960",
    "end": "27539"
  },
  {
    "text": "you know some of the major events that",
    "start": "27539",
    "end": "30000"
  },
  {
    "text": "have happened there",
    "start": "30000",
    "end": "31439"
  },
  {
    "text": "so hopefully by the end of this talk",
    "start": "31439",
    "end": "34200"
  },
  {
    "text": "um you'll understand a bit more about",
    "start": "34200",
    "end": "36239"
  },
  {
    "text": "the role of very data plane in some of",
    "start": "36239",
    "end": "39180"
  },
  {
    "text": "the libraries in the rare ecosystem like",
    "start": "39180",
    "end": "41040"
  },
  {
    "text": "Ray data you'll understand some of the",
    "start": "41040",
    "end": "43379"
  },
  {
    "text": "history of the design changes and also",
    "start": "43379",
    "end": "46559"
  },
  {
    "text": "Frank will tell you about how we were",
    "start": "46559",
    "end": "48300"
  },
  {
    "text": "able to leverage this to beat the cloud",
    "start": "48300",
    "end": "50520"
  },
  {
    "text": "sort world record and if you're not",
    "start": "50520",
    "end": "53219"
  },
  {
    "text": "familiar with this the cloud sort",
    "start": "53219",
    "end": "54660"
  },
  {
    "text": "Benchmark is a benchmark for that",
    "start": "54660",
    "end": "57239"
  },
  {
    "text": "measures the cost of sorting 100",
    "start": "57239",
    "end": "58860"
  },
  {
    "text": "terabytes of data",
    "start": "58860",
    "end": "61620"
  },
  {
    "text": "okay so first I",
    "start": "61620",
    "end": "64940"
  },
  {
    "text": "for why",
    "start": "65159",
    "end": "66540"
  },
  {
    "text": "why the ray data plane in the first",
    "start": "66540",
    "end": "68100"
  },
  {
    "text": "place",
    "start": "68100",
    "end": "69299"
  },
  {
    "text": "all right so that's probably many of you",
    "start": "69299",
    "end": "71640"
  },
  {
    "text": "are aware at this point data and ml",
    "start": "71640",
    "end": "73979"
  },
  {
    "text": "applications are of course memory",
    "start": "73979",
    "end": "76200"
  },
  {
    "text": "intensive and distributed and that's",
    "start": "76200",
    "end": "78720"
  },
  {
    "text": "often so that we can scale to larger",
    "start": "78720",
    "end": "80580"
  },
  {
    "text": "data sets or to larger compute clusters",
    "start": "80580",
    "end": "84000"
  },
  {
    "text": "and what we saw was that before Rey",
    "start": "84000",
    "end": "86580"
  },
  {
    "text": "existed we really felt that there was",
    "start": "86580",
    "end": "88799"
  },
  {
    "text": "just not a good distributed memory",
    "start": "88799",
    "end": "90479"
  },
  {
    "text": "system out there for Python and to",
    "start": "90479",
    "end": "92939"
  },
  {
    "text": "illustrate this I'm pulling some results",
    "start": "92939",
    "end": "95340"
  },
  {
    "text": "here from a comparison that we did back",
    "start": "95340",
    "end": "97500"
  },
  {
    "text": "in 2021 and this was looking at this",
    "start": "97500",
    "end": "101220"
  },
  {
    "text": "micro Benchmark comparing desk to Rey",
    "start": "101220",
    "end": "104400"
  },
  {
    "text": "and this is a very simple workload just",
    "start": "104400",
    "end": "106439"
  },
  {
    "text": "passing a large object between a bunch",
    "start": "106439",
    "end": "109020"
  },
  {
    "text": "of different tasks",
    "start": "109020",
    "end": "110759"
  },
  {
    "text": "and looking at scalability with a number",
    "start": "110759",
    "end": "112740"
  },
  {
    "text": "of notes",
    "start": "112740",
    "end": "113820"
  },
  {
    "text": "and what you can see here in this graph",
    "start": "113820",
    "end": "116220"
  },
  {
    "text": "so this is measuring runtime meaning",
    "start": "116220",
    "end": "118259"
  },
  {
    "text": "lower is better",
    "start": "118259",
    "end": "119880"
  },
  {
    "text": "and what we can see here is that with",
    "start": "119880",
    "end": "122159"
  },
  {
    "text": "desk some of the the design choices that",
    "start": "122159",
    "end": "125100"
  },
  {
    "text": "they had in their distributed memory",
    "start": "125100",
    "end": "127439"
  },
  {
    "text": "system led to poor performance so if you",
    "start": "127439",
    "end": "131220"
  },
  {
    "text": "use multi-processing in desk you could",
    "start": "131220",
    "end": "134099"
  },
  {
    "text": "avoid any issues with Gill contention",
    "start": "134099",
    "end": "137300"
  },
  {
    "text": "but it also meant a lot of unnecessary",
    "start": "137300",
    "end": "140099"
  },
  {
    "text": "memory copies because these processes",
    "start": "140099",
    "end": "142680"
  },
  {
    "text": "couldn't share the same data",
    "start": "142680",
    "end": "145200"
  },
  {
    "text": "if we used multi-threading we could",
    "start": "145200",
    "end": "147239"
  },
  {
    "text": "avoid that problem but then you became",
    "start": "147239",
    "end": "149099"
  },
  {
    "text": "quite sensitive to whether the",
    "start": "149099",
    "end": "151080"
  },
  {
    "text": "computation required holding the Gill or",
    "start": "151080",
    "end": "153060"
  },
  {
    "text": "not",
    "start": "153060",
    "end": "154379"
  },
  {
    "text": "and so this actually led us to build",
    "start": "154379",
    "end": "156420"
  },
  {
    "text": "this desk on Ray system which was",
    "start": "156420",
    "end": "158879"
  },
  {
    "text": "basically a plug-in for the Das library",
    "start": "158879",
    "end": "161580"
  },
  {
    "text": "that used the ray data plane as the",
    "start": "161580",
    "end": "163500"
  },
  {
    "text": "execution back end instead and what we",
    "start": "163500",
    "end": "165959"
  },
  {
    "text": "can see here is that we're able to",
    "start": "165959",
    "end": "167819"
  },
  {
    "text": "really improve the runtime by leveraging",
    "start": "167819",
    "end": "170459"
  },
  {
    "text": "shared memory and also using Ray core",
    "start": "170459",
    "end": "173040"
  },
  {
    "text": "for parallel execution",
    "start": "173040",
    "end": "175920"
  },
  {
    "text": "and so some of the things that made this",
    "start": "175920",
    "end": "177780"
  },
  {
    "text": "possible in the ray data plane when we",
    "start": "177780",
    "end": "180360"
  },
  {
    "text": "think of the ray data plane it's",
    "start": "180360",
    "end": "181560"
  },
  {
    "text": "essentially this distributed memory",
    "start": "181560",
    "end": "183420"
  },
  {
    "text": "layer for all application objects that",
    "start": "183420",
    "end": "186300"
  },
  {
    "text": "are created in Ray so basically this is",
    "start": "186300",
    "end": "189120"
  },
  {
    "text": "all of the different values that you",
    "start": "189120",
    "end": "190860"
  },
  {
    "text": "have for Ray object roughs and the data",
    "start": "190860",
    "end": "194040"
  },
  {
    "text": "plane provides a number of nice features",
    "start": "194040",
    "end": "195900"
  },
  {
    "text": "here including being able to do shared",
    "start": "195900",
    "end": "198959"
  },
  {
    "text": "memory reads with zero copies as long as",
    "start": "198959",
    "end": "201900"
  },
  {
    "text": "you're using types like numpy or Arrow",
    "start": "201900",
    "end": "206640"
  },
  {
    "text": "it's distributed by default so what that",
    "start": "206640",
    "end": "209220"
  },
  {
    "text": "means is that the rate data plane gives",
    "start": "209220",
    "end": "211620"
  },
  {
    "text": "you transparent transfers between",
    "start": "211620",
    "end": "213480"
  },
  {
    "text": "different python workers both within the",
    "start": "213480",
    "end": "216780"
  },
  {
    "text": "same node and across different nodes",
    "start": "216780",
    "end": "219659"
  },
  {
    "text": "it gives you a number of important",
    "start": "219659",
    "end": "222420"
  },
  {
    "text": "memory control features so that includes",
    "start": "222420",
    "end": "224580"
  },
  {
    "text": "being able to transparently spill",
    "start": "224580",
    "end": "226140"
  },
  {
    "text": "between memory and disk and also garbage",
    "start": "226140",
    "end": "228900"
  },
  {
    "text": "collection",
    "start": "228900",
    "end": "230340"
  },
  {
    "text": "and finally it's able to automatically",
    "start": "230340",
    "end": "232620"
  },
  {
    "text": "recover from certain kinds of failures",
    "start": "232620",
    "end": "236220"
  },
  {
    "text": "so the way that this all works just to",
    "start": "236220",
    "end": "238799"
  },
  {
    "text": "give you an illustration of this is when",
    "start": "238799",
    "end": "241019"
  },
  {
    "text": "we think about a typical array cluster",
    "start": "241019",
    "end": "242940"
  },
  {
    "text": "the ray data plane consists of these",
    "start": "242940",
    "end": "245580"
  },
  {
    "text": "different components so first we want to",
    "start": "245580",
    "end": "248400"
  },
  {
    "text": "think about where the object metadata is",
    "start": "248400",
    "end": "250439"
  },
  {
    "text": "stored and this is usually stored at the",
    "start": "250439",
    "end": "252840"
  },
  {
    "text": "driver",
    "start": "252840",
    "end": "254459"
  },
  {
    "text": "we call this process the owner because",
    "start": "254459",
    "end": "257280"
  },
  {
    "text": "it owns the metadata that's related to",
    "start": "257280",
    "end": "259620"
  },
  {
    "text": "an object and the way that we assign the",
    "start": "259620",
    "end": "262079"
  },
  {
    "text": "owner is basically based on who created",
    "start": "262079",
    "end": "264660"
  },
  {
    "text": "that first object ref so if you call",
    "start": "264660",
    "end": "267419"
  },
  {
    "text": "food.remote then you're going to own the",
    "start": "267419",
    "end": "269940"
  },
  {
    "text": "object ref returned by that",
    "start": "269940",
    "end": "272759"
  },
  {
    "text": "for the actual object data we have two",
    "start": "272759",
    "end": "275340"
  },
  {
    "text": "different ways of storing that for very",
    "start": "275340",
    "end": "278100"
  },
  {
    "text": "small objects these are really quick to",
    "start": "278100",
    "end": "280199"
  },
  {
    "text": "copy and so we actually just store them",
    "start": "280199",
    "end": "282000"
  },
  {
    "text": "directly at the owner and copy them",
    "start": "282000",
    "end": "283620"
  },
  {
    "text": "between workers and this is actually",
    "start": "283620",
    "end": "285419"
  },
  {
    "text": "just like using an RPC Library like grpc",
    "start": "285419",
    "end": "289560"
  },
  {
    "text": "so this makes reading really fast but it",
    "start": "289560",
    "end": "292080"
  },
  {
    "text": "doesn't mean that we create a lot of",
    "start": "292080",
    "end": "293759"
  },
  {
    "text": "copies potentially",
    "start": "293759",
    "end": "295800"
  },
  {
    "text": "so for large objects we have this",
    "start": "295800",
    "end": "298440"
  },
  {
    "text": "additional optimization of having this",
    "start": "298440",
    "end": "300180"
  },
  {
    "text": "shared memory Object Store",
    "start": "300180",
    "end": "302759"
  },
  {
    "text": "and so here even if one python process",
    "start": "302759",
    "end": "305460"
  },
  {
    "text": "has an object graph the actual value for",
    "start": "305460",
    "end": "307680"
  },
  {
    "text": "it might live on a completely different",
    "start": "307680",
    "end": "309300"
  },
  {
    "text": "node and the main benefit here is that",
    "start": "309300",
    "end": "311940"
  },
  {
    "text": "you can get this kind of distributed",
    "start": "311940",
    "end": "314040"
  },
  {
    "text": "memory abstraction and you can also",
    "start": "314040",
    "end": "316320"
  },
  {
    "text": "share the same copy of the data as long",
    "start": "316320",
    "end": "318540"
  },
  {
    "text": "as you're on the same node",
    "start": "318540",
    "end": "321560"
  },
  {
    "text": "so the ray data plane has actually gone",
    "start": "323220",
    "end": "325080"
  },
  {
    "text": "through quite a few changes in the past",
    "start": "325080",
    "end": "327320"
  },
  {
    "text": "we always had shared memory actually so",
    "start": "327320",
    "end": "330000"
  },
  {
    "text": "from the very beginning we natively",
    "start": "330000",
    "end": "332820"
  },
  {
    "text": "supported arrow and we had this shared",
    "start": "332820",
    "end": "334800"
  },
  {
    "text": "memory Object Store",
    "start": "334800",
    "end": "336320"
  },
  {
    "text": "but in the first version the first major",
    "start": "336320",
    "end": "339180"
  },
  {
    "text": "version of Rey which was released in",
    "start": "339180",
    "end": "341400"
  },
  {
    "text": "2020",
    "start": "341400",
    "end": "343199"
  },
  {
    "text": "we introduced a couple major design",
    "start": "343199",
    "end": "346080"
  },
  {
    "text": "features that were really important for",
    "start": "346080",
    "end": "347940"
  },
  {
    "text": "stability so these included automatic",
    "start": "347940",
    "end": "350820"
  },
  {
    "text": "memory management through reference",
    "start": "350820",
    "end": "352380"
  },
  {
    "text": "counting and also reliable failure",
    "start": "352380",
    "end": "354840"
  },
  {
    "text": "detection and Recovery",
    "start": "354840",
    "end": "357360"
  },
  {
    "text": "so building on top of that more stable",
    "start": "357360",
    "end": "359580"
  },
  {
    "text": "core we were able to support more",
    "start": "359580",
    "end": "361740"
  },
  {
    "text": "advanced features like being able to",
    "start": "361740",
    "end": "363479"
  },
  {
    "text": "spill from memory to disk and that in",
    "start": "363479",
    "end": "366300"
  },
  {
    "text": "turn allowed us to build out these more",
    "start": "366300",
    "end": "368280"
  },
  {
    "text": "advanced data plan libraries such as",
    "start": "368280",
    "end": "370979"
  },
  {
    "text": "raid data and at this point we also",
    "start": "370979",
    "end": "373620"
  },
  {
    "text": "started kind of pushing the scale of",
    "start": "373620",
    "end": "375300"
  },
  {
    "text": "applications that we were able to",
    "start": "375300",
    "end": "376979"
  },
  {
    "text": "support",
    "start": "376979",
    "end": "378060"
  },
  {
    "text": "and that of course culminated in the",
    "start": "378060",
    "end": "380520"
  },
  {
    "text": "cloud sort world record which Frank will",
    "start": "380520",
    "end": "382319"
  },
  {
    "text": "tell you more about",
    "start": "382319",
    "end": "384720"
  },
  {
    "text": "okay so I also thought it'd be fun to go",
    "start": "384720",
    "end": "386520"
  },
  {
    "text": "through some of the libraries that are",
    "start": "386520",
    "end": "387840"
  },
  {
    "text": "using Ray data plane to",
    "start": "387840",
    "end": "389520"
  },
  {
    "text": "I already mentioned dasco and Ray which",
    "start": "389520",
    "end": "392340"
  },
  {
    "text": "is a drop-in replacement for desk that",
    "start": "392340",
    "end": "394560"
  },
  {
    "text": "uses Ray the ray data plane as its",
    "start": "394560",
    "end": "396900"
  },
  {
    "text": "backend",
    "start": "396900",
    "end": "398580"
  },
  {
    "text": "I also mentioned Ray data and you've",
    "start": "398580",
    "end": "401160"
  },
  {
    "text": "probably heard this throughout this",
    "start": "401160",
    "end": "403680"
  },
  {
    "text": "Summit we have a few different talks",
    "start": "403680",
    "end": "405240"
  },
  {
    "text": "here from both the developers as well as",
    "start": "405240",
    "end": "407880"
  },
  {
    "text": "users of Ray data and this library is",
    "start": "407880",
    "end": "410460"
  },
  {
    "text": "basically meant to do a small data",
    "start": "410460",
    "end": "412560"
  },
  {
    "text": "pre-processing for both training and",
    "start": "412560",
    "end": "414960"
  },
  {
    "text": "batch inference workloads",
    "start": "414960",
    "end": "417900"
  },
  {
    "text": "there's also a few other libraries that",
    "start": "417900",
    "end": "420360"
  },
  {
    "text": "are contributed by the community so we",
    "start": "420360",
    "end": "422880"
  },
  {
    "text": "have Ray and polars combined in the",
    "start": "422880",
    "end": "425580"
  },
  {
    "text": "quaca library and this implements a",
    "start": "425580",
    "end": "427919"
  },
  {
    "text": "streaming time series data frames",
    "start": "427919",
    "end": "430500"
  },
  {
    "text": "we have the Daft Library which gives you",
    "start": "430500",
    "end": "432900"
  },
  {
    "text": "distributed data frames for working with",
    "start": "432900",
    "end": "435479"
  },
  {
    "text": "ML data sets",
    "start": "435479",
    "end": "437759"
  },
  {
    "text": "and finally we also have a raise SQL",
    "start": "437759",
    "end": "440220"
  },
  {
    "text": "which is a combination of which is a",
    "start": "440220",
    "end": "442860"
  },
  {
    "text": "distributed SQL engine that's built with",
    "start": "442860",
    "end": "444840"
  },
  {
    "text": "Rey and Apache Arrow so actually I think",
    "start": "444840",
    "end": "447720"
  },
  {
    "text": "the developers of all of these libraries",
    "start": "447720",
    "end": "449460"
  },
  {
    "text": "are here at Ray Summit so yeah I",
    "start": "449460",
    "end": "452400"
  },
  {
    "text": "encourage you to go and talk to them in",
    "start": "452400",
    "end": "454500"
  },
  {
    "text": "person",
    "start": "454500",
    "end": "456620"
  },
  {
    "text": "okay um so",
    "start": "457020",
    "end": "459240"
  },
  {
    "text": "I've mentioned this a couple times now",
    "start": "459240",
    "end": "460919"
  },
  {
    "text": "but I just wanted to go a bit more into",
    "start": "460919",
    "end": "462720"
  },
  {
    "text": "this Cloud store Benchmark and why we",
    "start": "462720",
    "end": "465120"
  },
  {
    "text": "think this is such a big deal so the",
    "start": "465120",
    "end": "467759"
  },
  {
    "text": "previous record here was set in 2016 by",
    "start": "467759",
    "end": "470280"
  },
  {
    "text": "spark but it actually wasn't the open",
    "start": "470280",
    "end": "472440"
  },
  {
    "text": "source version of spark it was a",
    "start": "472440",
    "end": "474840"
  },
  {
    "text": "specialized Fork that was built",
    "start": "474840",
    "end": "476340"
  },
  {
    "text": "specifically for this benchmark",
    "start": "476340",
    "end": "478680"
  },
  {
    "text": "so in contrast we actually broke this",
    "start": "478680",
    "end": "481020"
  },
  {
    "text": "record recently using an official",
    "start": "481020",
    "end": "483180"
  },
  {
    "text": "release of Rey and that was actually",
    "start": "483180",
    "end": "485400"
  },
  {
    "text": "possible because the main distributed",
    "start": "485400",
    "end": "487500"
  },
  {
    "text": "sorting logic was actually all",
    "start": "487500",
    "end": "489240"
  },
  {
    "text": "implemented at the python level and that",
    "start": "489240",
    "end": "492360"
  },
  {
    "text": "was as a part of the EXO Shuffle project",
    "start": "492360",
    "end": "495599"
  },
  {
    "text": "and one of the reasons this worked is",
    "start": "495599",
    "end": "497639"
  },
  {
    "text": "because we were able to Leverage The Ray",
    "start": "497639",
    "end": "499379"
  },
  {
    "text": "data plane to get this this good",
    "start": "499379",
    "end": "501840"
  },
  {
    "text": "performance and so I think this shows",
    "start": "501840",
    "end": "504180"
  },
  {
    "text": "that you know even though we think of",
    "start": "504180",
    "end": "505560"
  },
  {
    "text": "python as being traditionally kind of a",
    "start": "505560",
    "end": "507599"
  },
  {
    "text": "slow language when you combine it with",
    "start": "507599",
    "end": "509940"
  },
  {
    "text": "Ray data plane you can actually get",
    "start": "509940",
    "end": "511860"
  },
  {
    "text": "these pretty amazing results",
    "start": "511860",
    "end": "515060"
  },
  {
    "text": "all right so finally I just want to peek",
    "start": "515339",
    "end": "517680"
  },
  {
    "text": "under the hood a little bit and show how",
    "start": "517680",
    "end": "519719"
  },
  {
    "text": "the radiator plane is involved with this",
    "start": "519719",
    "end": "521640"
  },
  {
    "text": "kind of distributed sorting or mapreduce",
    "start": "521640",
    "end": "523979"
  },
  {
    "text": "kind of application",
    "start": "523979",
    "end": "526440"
  },
  {
    "text": "um so here when we this is kind of a a",
    "start": "526440",
    "end": "529560"
  },
  {
    "text": "typical Ray cluster setup that you might",
    "start": "529560",
    "end": "531480"
  },
  {
    "text": "have and so we first will execute some",
    "start": "531480",
    "end": "534000"
  },
  {
    "text": "map tasks and here what's going to",
    "start": "534000",
    "end": "536519"
  },
  {
    "text": "happen is once the map task completes it",
    "start": "536519",
    "end": "539640"
  },
  {
    "text": "creates one of these very objects for",
    "start": "539640",
    "end": "541800"
  },
  {
    "text": "each reduced task and these get stored",
    "start": "541800",
    "end": "544200"
  },
  {
    "text": "in shared memory",
    "start": "544200",
    "end": "545880"
  },
  {
    "text": "once that shared memory store fills up",
    "start": "545880",
    "end": "548160"
  },
  {
    "text": "it's going to spill automatically to",
    "start": "548160",
    "end": "550320"
  },
  {
    "text": "disk and so here we can see where Ray",
    "start": "550320",
    "end": "553980"
  },
  {
    "text": "core's transparent spilling is actually",
    "start": "553980",
    "end": "555720"
  },
  {
    "text": "coming into play and so raycor will",
    "start": "555720",
    "end": "557820"
  },
  {
    "text": "guarantee that the memory usage here",
    "start": "557820",
    "end": "559580"
  },
  {
    "text": "stays under a certain limit",
    "start": "559580",
    "end": "563480"
  },
  {
    "text": "later on we're going to submit some",
    "start": "563940",
    "end": "565920"
  },
  {
    "text": "reduce tasks which have dependencies on",
    "start": "565920",
    "end": "568080"
  },
  {
    "text": "those map outputs and so from here we're",
    "start": "568080",
    "end": "570480"
  },
  {
    "text": "going to transfer one map output from",
    "start": "570480",
    "end": "573180"
  },
  {
    "text": "each of those map tasks",
    "start": "573180",
    "end": "575220"
  },
  {
    "text": "and here we can see where the",
    "start": "575220",
    "end": "576959"
  },
  {
    "text": "transparent distributed transfer is",
    "start": "576959",
    "end": "579300"
  },
  {
    "text": "happening and so there's also a number",
    "start": "579300",
    "end": "581640"
  },
  {
    "text": "of nice performance optimizations that",
    "start": "581640",
    "end": "584160"
  },
  {
    "text": "are happening under the hood here so",
    "start": "584160",
    "end": "586140"
  },
  {
    "text": "things like being able to overlap this",
    "start": "586140",
    "end": "587940"
  },
  {
    "text": "transfer with the execution of other",
    "start": "587940",
    "end": "590220"
  },
  {
    "text": "reduced tasks and also multiplexing this",
    "start": "590220",
    "end": "593160"
  },
  {
    "text": "transfer across multiple connections",
    "start": "593160",
    "end": "596279"
  },
  {
    "text": "okay and then of course once this",
    "start": "596279",
    "end": "598320"
  },
  {
    "text": "reduced task reads this these objects",
    "start": "598320",
    "end": "600600"
  },
  {
    "text": "here is where we can see the benefit of",
    "start": "600600",
    "end": "602700"
  },
  {
    "text": "using this shared memory approach where",
    "start": "602700",
    "end": "604380"
  },
  {
    "text": "we get the zero copy reads",
    "start": "604380",
    "end": "606720"
  },
  {
    "text": "all right so next I'll hand it over to",
    "start": "606720",
    "end": "608459"
  },
  {
    "text": "Frank to give you more details on how",
    "start": "608459",
    "end": "611399"
  },
  {
    "text": "um we're able to break the cloud world",
    "start": "611399",
    "end": "613560"
  },
  {
    "text": "record with this",
    "start": "613560",
    "end": "615360"
  },
  {
    "text": "so it's definitely so yeah hi I'm Frank",
    "start": "615360",
    "end": "617760"
  },
  {
    "text": "and uh yeah I think let's dive into some",
    "start": "617760",
    "end": "620820"
  },
  {
    "text": "cool things that we did to actually",
    "start": "620820",
    "end": "622260"
  },
  {
    "text": "achieve that uh Cloud sort World",
    "start": "622260",
    "end": "625019"
  },
  {
    "text": "Benchmark so to understand",
    "start": "625019",
    "end": "627420"
  },
  {
    "text": "um maybe let me recap with what the",
    "start": "627420",
    "end": "629220"
  },
  {
    "text": "cloud sword Benchmark is and why we're",
    "start": "629220",
    "end": "630959"
  },
  {
    "text": "doing it so",
    "start": "630959",
    "end": "633120"
  },
  {
    "text": "um sorting sounds like a simple problem",
    "start": "633120",
    "end": "634680"
  },
  {
    "text": "if you're just sorting a list of 10",
    "start": "634680",
    "end": "636180"
  },
  {
    "text": "numbers it's trivial but actually when",
    "start": "636180",
    "end": "639120"
  },
  {
    "text": "the data size is huge as huge as 100",
    "start": "639120",
    "end": "641339"
  },
  {
    "text": "terabyte this is actually a system",
    "start": "641339",
    "end": "643200"
  },
  {
    "text": "design problem because if you think",
    "start": "643200",
    "end": "645000"
  },
  {
    "text": "about the input data has to reside on",
    "start": "645000",
    "end": "646980"
  },
  {
    "text": "some sort of storage and they're moving",
    "start": "646980",
    "end": "648899"
  },
  {
    "text": "this data from Storage to compute and",
    "start": "648899",
    "end": "651420"
  },
  {
    "text": "then there has to be an execution engine",
    "start": "651420",
    "end": "652800"
  },
  {
    "text": "for 100 terabytes it's usually a",
    "start": "652800",
    "end": "654779"
  },
  {
    "text": "distributed execution engine and then",
    "start": "654779",
    "end": "656880"
  },
  {
    "text": "you're gonna do the compute you're going",
    "start": "656880",
    "end": "658860"
  },
  {
    "text": "to do the sorting and then you're gonna",
    "start": "658860",
    "end": "659820"
  },
  {
    "text": "have to",
    "start": "659820",
    "end": "660899"
  },
  {
    "text": "type all the data back into the storage",
    "start": "660899",
    "end": "662940"
  },
  {
    "text": "so on a high level there's such a cloud",
    "start": "662940",
    "end": "666060"
  },
  {
    "text": "Source system has to um",
    "start": "666060",
    "end": "668579"
  },
  {
    "text": "has to have three three components so",
    "start": "668579",
    "end": "670500"
  },
  {
    "text": "there's execution on top that's a",
    "start": "670500",
    "end": "672000"
  },
  {
    "text": "software and there's also the compute",
    "start": "672000",
    "end": "673800"
  },
  {
    "text": "cluster and then finally there's a",
    "start": "673800",
    "end": "675360"
  },
  {
    "text": "storage layer",
    "start": "675360",
    "end": "676920"
  },
  {
    "text": "so the previous uh Cloud store record",
    "start": "676920",
    "end": "679140"
  },
  {
    "text": "was set by Apache spark in 2016. um as",
    "start": "679140",
    "end": "681899"
  },
  {
    "text": "Stephanie mentioned this was sort of a",
    "start": "681899",
    "end": "683579"
  },
  {
    "text": "specialized Fork of spark",
    "start": "683579",
    "end": "685740"
  },
  {
    "text": "um to implement these uh some low-level",
    "start": "685740",
    "end": "687899"
  },
  {
    "text": "automatages in order to make the Sorting",
    "start": "687899",
    "end": "689760"
  },
  {
    "text": "happen and then I was running on Alibaba",
    "start": "689760",
    "end": "691800"
  },
  {
    "text": "Cloud at a time because that was I think",
    "start": "691800",
    "end": "693899"
  },
  {
    "text": "the most competitive in terms of pricing",
    "start": "693899",
    "end": "696000"
  },
  {
    "text": "and then it was running it was putting",
    "start": "696000",
    "end": "698220"
  },
  {
    "text": "the data on a set of hdfs cluster on",
    "start": "698220",
    "end": "701160"
  },
  {
    "text": "like um traditional like hard disk",
    "start": "701160",
    "end": "703019"
  },
  {
    "text": "drives",
    "start": "703019",
    "end": "704279"
  },
  {
    "text": "so it was changed in our Excel Shuffle",
    "start": "704279",
    "end": "706920"
  },
  {
    "text": "Cloud sort Benchmark we uh here's the",
    "start": "706920",
    "end": "709500"
  },
  {
    "text": "architecture here so a few things are",
    "start": "709500",
    "end": "711180"
  },
  {
    "text": "different",
    "start": "711180",
    "end": "712260"
  },
  {
    "text": "um I think the most notable thing is",
    "start": "712260",
    "end": "713579"
  },
  {
    "text": "that we're able to run this on top of",
    "start": "713579",
    "end": "715019"
  },
  {
    "text": "like a public release version of",
    "start": "715019",
    "end": "716760"
  },
  {
    "text": "unmodified so basically we simply",
    "start": "716760",
    "end": "719459"
  },
  {
    "text": "implement the Sorting strategies and",
    "start": "719459",
    "end": "721980"
  },
  {
    "text": "algorithms on top as this Python program",
    "start": "721980",
    "end": "723839"
  },
  {
    "text": "and this Python program runs on the ray",
    "start": "723839",
    "end": "725820"
  },
  {
    "text": "cluster which in turn runs on the Amazon",
    "start": "725820",
    "end": "728060"
  },
  {
    "text": "ec2 cluster the other changes that we're",
    "start": "728060",
    "end": "732060"
  },
  {
    "text": "able to actually Leverage The",
    "start": "732060",
    "end": "734399"
  },
  {
    "text": "advancement in Cloud technology as well",
    "start": "734399",
    "end": "736260"
  },
  {
    "text": "so Amazon S3 has become a lot more",
    "start": "736260",
    "end": "739079"
  },
  {
    "text": "faster and uh stable over the years so",
    "start": "739079",
    "end": "741779"
  },
  {
    "text": "we're actually able to store all of the",
    "start": "741779",
    "end": "743459"
  },
  {
    "text": "data on S3 and then",
    "start": "743459",
    "end": "745920"
  },
  {
    "text": "um also write the output there",
    "start": "745920",
    "end": "748019"
  },
  {
    "text": "so the",
    "start": "748019",
    "end": "749899"
  },
  {
    "text": "cloudswords.pi that program essentially",
    "start": "749899",
    "end": "752220"
  },
  {
    "text": "is less than a thousand lines of python",
    "start": "752220",
    "end": "753779"
  },
  {
    "text": "code and then we're able to beat that uh",
    "start": "753779",
    "end": "757320"
  },
  {
    "text": "price record by about 30 percent",
    "start": "757320",
    "end": "760200"
  },
  {
    "text": "speaking of that number so uh you know",
    "start": "760200",
    "end": "763620"
  },
  {
    "text": "one reasonable question to ask is that",
    "start": "763620",
    "end": "765420"
  },
  {
    "text": "you know that was 2016 and then you know",
    "start": "765420",
    "end": "767220"
  },
  {
    "text": "Hardware got better and cheaper over the",
    "start": "767220",
    "end": "768779"
  },
  {
    "text": "years so was it just an artifact of you",
    "start": "768779",
    "end": "771720"
  },
  {
    "text": "know the uh the dollar value change so",
    "start": "771720",
    "end": "774839"
  },
  {
    "text": "we did try to interpolate that same",
    "start": "774839",
    "end": "777480"
  },
  {
    "text": "setup back in 2016",
    "start": "777480",
    "end": "780180"
  },
  {
    "text": "um to using today's Hardware pricing and",
    "start": "780180",
    "end": "782579"
  },
  {
    "text": "then we see that that's about a hundred",
    "start": "782579",
    "end": "784620"
  },
  {
    "text": "like 1.15 dollars per terabyte if that",
    "start": "784620",
    "end": "787860"
  },
  {
    "text": "setup was running on today's machines",
    "start": "787860",
    "end": "789660"
  },
  {
    "text": "but still",
    "start": "789660",
    "end": "792180"
  },
  {
    "text": "um we're able to achieve about a 15",
    "start": "792180",
    "end": "795300"
  },
  {
    "text": "um increase in price performance using",
    "start": "795300",
    "end": "797760"
  },
  {
    "text": "this new architecture and Technologies",
    "start": "797760",
    "end": "801240"
  },
  {
    "text": "so before I talk about how exactly do",
    "start": "801240",
    "end": "803700"
  },
  {
    "text": "that maybe it's it's uh useful to give",
    "start": "803700",
    "end": "805860"
  },
  {
    "text": "you some um idea of like why this Cloud",
    "start": "805860",
    "end": "808560"
  },
  {
    "text": "store record this Cloud sort Benchmark",
    "start": "808560",
    "end": "810959"
  },
  {
    "text": "is a thing",
    "start": "810959",
    "end": "812279"
  },
  {
    "text": "um so if you think about it",
    "start": "812279",
    "end": "814139"
  },
  {
    "text": "um a lot of the modern data processing",
    "start": "814139",
    "end": "816500"
  },
  {
    "text": "jobs the most expensive part in there is",
    "start": "816500",
    "end": "820079"
  },
  {
    "text": "if you have all to all communication",
    "start": "820079",
    "end": "821579"
  },
  {
    "text": "which is what Shuffle refers to here so",
    "start": "821579",
    "end": "824160"
  },
  {
    "text": "think of you have a bunch of machines on",
    "start": "824160",
    "end": "826440"
  },
  {
    "text": "the left hand side that read some data",
    "start": "826440",
    "end": "828720"
  },
  {
    "text": "if they if they can do their processing",
    "start": "828720",
    "end": "831120"
  },
  {
    "text": "locally it's not very difficult you can",
    "start": "831120",
    "end": "832680"
  },
  {
    "text": "do this in parallel way pretty easily",
    "start": "832680",
    "end": "834360"
  },
  {
    "text": "but if they all need to communicate with",
    "start": "834360",
    "end": "836639"
  },
  {
    "text": "each other and that's each each node",
    "start": "836639",
    "end": "839100"
  },
  {
    "text": "needs to send a piece of data to every",
    "start": "839100",
    "end": "840600"
  },
  {
    "text": "other node that is the definition of",
    "start": "840600",
    "end": "842279"
  },
  {
    "text": "Shuffle by the way then this creates a",
    "start": "842279",
    "end": "844139"
  },
  {
    "text": "auto communication pattern that is",
    "start": "844139",
    "end": "845700"
  },
  {
    "text": "difficult to optimize",
    "start": "845700",
    "end": "847380"
  },
  {
    "text": "so why is it difficult to optimize it so",
    "start": "847380",
    "end": "849240"
  },
  {
    "text": "let's uh let's on the high level this is",
    "start": "849240",
    "end": "851399"
  },
  {
    "text": "because if you have end nodes in a",
    "start": "851399",
    "end": "853260"
  },
  {
    "text": "cluster this results in N squared number",
    "start": "853260",
    "end": "855779"
  },
  {
    "text": "of connections between nodes because",
    "start": "855779",
    "end": "857880"
  },
  {
    "text": "every um so think of like a mapreduce",
    "start": "857880",
    "end": "860100"
  },
  {
    "text": "job every node need to send a piece of",
    "start": "860100",
    "end": "862019"
  },
  {
    "text": "data onto every other node",
    "start": "862019",
    "end": "864120"
  },
  {
    "text": "so this essentially translates into",
    "start": "864120",
    "end": "865680"
  },
  {
    "text": "moving a very large number of small",
    "start": "865680",
    "end": "867420"
  },
  {
    "text": "blocks across all nodes and let's say we",
    "start": "867420",
    "end": "870360"
  },
  {
    "text": "are doing processing a terabyte of data",
    "start": "870360",
    "end": "872519"
  },
  {
    "text": "and then you have 10 000 partitions it",
    "start": "872519",
    "end": "874740"
  },
  {
    "text": "doesn't seem like a huge number but if",
    "start": "874740",
    "end": "877019"
  },
  {
    "text": "you think about Shuffle then this",
    "start": "877019",
    "end": "878220"
  },
  {
    "text": "already translates into 100 million",
    "start": "878220",
    "end": "880380"
  },
  {
    "text": "Shuffle blocks each of them only only 10",
    "start": "880380",
    "end": "882959"
  },
  {
    "text": "kilobyte each and you need to transfer",
    "start": "882959",
    "end": "884519"
  },
  {
    "text": "those across disk Network and memory",
    "start": "884519",
    "end": "888120"
  },
  {
    "text": "so this is difficult ultimate because",
    "start": "888120",
    "end": "889980"
  },
  {
    "text": "when this creates differentiates IO",
    "start": "889980",
    "end": "892199"
  },
  {
    "text": "efficiency problems because",
    "start": "892199",
    "end": "894300"
  },
  {
    "text": "um for example hard drives are not",
    "start": "894300",
    "end": "895560"
  },
  {
    "text": "optimized for random small accesses",
    "start": "895560",
    "end": "898320"
  },
  {
    "text": "um there's the problem with fall",
    "start": "898320",
    "end": "899519"
  },
  {
    "text": "tolerance with 100 million transfers you",
    "start": "899519",
    "end": "901680"
  },
  {
    "text": "can bet on some of them might fail so",
    "start": "901680",
    "end": "903240"
  },
  {
    "text": "the system must be able to handle this",
    "start": "903240",
    "end": "905880"
  },
  {
    "text": "um for this faults transparently",
    "start": "905880",
    "end": "908279"
  },
  {
    "text": "and finally there's a problem load",
    "start": "908279",
    "end": "909839"
  },
  {
    "text": "balancing because",
    "start": "909839",
    "end": "911279"
  },
  {
    "text": "um if the so ideally we want we want the",
    "start": "911279",
    "end": "913680"
  },
  {
    "text": "pipes to be saturated as much as we can",
    "start": "913680",
    "end": "915360"
  },
  {
    "text": "but um if there are skew in in the data",
    "start": "915360",
    "end": "918480"
  },
  {
    "text": "then this becomes a challenging problem",
    "start": "918480",
    "end": "920100"
  },
  {
    "text": "as well",
    "start": "920100",
    "end": "922440"
  },
  {
    "text": "so let's uh maybe go bottom up from that",
    "start": "922440",
    "end": "925199"
  },
  {
    "text": "stack and let's first talk about uh uh",
    "start": "925199",
    "end": "927480"
  },
  {
    "text": "how we select the hardware configuration",
    "start": "927480",
    "end": "929639"
  },
  {
    "text": "for for making the call sort record",
    "start": "929639",
    "end": "932760"
  },
  {
    "text": "so",
    "start": "932760",
    "end": "933959"
  },
  {
    "text": "um we thought of a few principles that",
    "start": "933959",
    "end": "935699"
  },
  {
    "text": "we need when we're choosing the ec2",
    "start": "935699",
    "end": "937440"
  },
  {
    "text": "Clusters shape first of all we want to",
    "start": "937440",
    "end": "939779"
  },
  {
    "text": "use as few nodes as possible and why is",
    "start": "939779",
    "end": "942720"
  },
  {
    "text": "that because",
    "start": "942720",
    "end": "943740"
  },
  {
    "text": "um I should mention one more thing the",
    "start": "943740",
    "end": "945300"
  },
  {
    "text": "goal of this Cloud sort Benchmark is to",
    "start": "945300",
    "end": "947940"
  },
  {
    "text": "find the cheapest way to run sort of 100",
    "start": "947940",
    "end": "950760"
  },
  {
    "text": "terabyte white cheapest because that's I",
    "start": "950760",
    "end": "954000"
  },
  {
    "text": "think the most practical Benchmark",
    "start": "954000",
    "end": "955320"
  },
  {
    "text": "because in the end we're running these",
    "start": "955320",
    "end": "956880"
  },
  {
    "text": "large-scale data jobs they you know run",
    "start": "956880",
    "end": "958740"
  },
  {
    "text": "overnight but we want to minimize the",
    "start": "958740",
    "end": "960540"
  },
  {
    "text": "cost of running these things so the",
    "start": "960540",
    "end": "962639"
  },
  {
    "text": "again the goal is to minimize cost",
    "start": "962639",
    "end": "965160"
  },
  {
    "text": "so why do we want to feel nodes as real",
    "start": "965160",
    "end": "967320"
  },
  {
    "text": "nodes as possible if you think about it",
    "start": "967320",
    "end": "968940"
  },
  {
    "text": "every nodes receive blocks from endnotes",
    "start": "968940",
    "end": "970860"
  },
  {
    "text": "and merge them together so less nodes",
    "start": "970860",
    "end": "973260"
  },
  {
    "text": "means a smaller number of n that means",
    "start": "973260",
    "end": "975120"
  },
  {
    "text": "the faster merge so for example if we",
    "start": "975120",
    "end": "977940"
  },
  {
    "text": "are merging 100 megabyte blocks 10 of",
    "start": "977940",
    "end": "980519"
  },
  {
    "text": "those things it will be faster to merge",
    "start": "980519",
    "end": "982199"
  },
  {
    "text": "these blocks which are already sorted",
    "start": "982199",
    "end": "983940"
  },
  {
    "text": "then to merge 100 blocks each of only 10",
    "start": "983940",
    "end": "986699"
  },
  {
    "text": "megabyte blocks that's just this is more",
    "start": "986699",
    "end": "988440"
  },
  {
    "text": "computation to do",
    "start": "988440",
    "end": "990600"
  },
  {
    "text": "so that's the first thing second",
    "start": "990600",
    "end": "993600"
  },
  {
    "text": "um here's sort of interesting finding we",
    "start": "993600",
    "end": "995279"
  },
  {
    "text": "find on the modern Cloud World which is",
    "start": "995279",
    "end": "997920"
  },
  {
    "text": "a smaller instances you already have",
    "start": "997920",
    "end": "999360"
  },
  {
    "text": "better price performance to price ratio",
    "start": "999360",
    "end": "1002240"
  },
  {
    "text": "this is a little bit surprising but what",
    "start": "1002240",
    "end": "1004579"
  },
  {
    "text": "we find the reason for that is because",
    "start": "1004579",
    "end": "1006259"
  },
  {
    "text": "these smaller instances so typically the",
    "start": "1006259",
    "end": "1008480"
  },
  {
    "text": "cloud providers take a big machine and",
    "start": "1008480",
    "end": "1009980"
  },
  {
    "text": "then carve them into smaller pieces and",
    "start": "1009980",
    "end": "1011540"
  },
  {
    "text": "you know run them to you the smaller",
    "start": "1011540",
    "end": "1013459"
  },
  {
    "text": "instances have better burst networking",
    "start": "1013459",
    "end": "1015920"
  },
  {
    "text": "what that means is that the furthermore",
    "start": "1015920",
    "end": "1018740"
  },
  {
    "text": "we find that the instance is constantly",
    "start": "1018740",
    "end": "1020360"
  },
  {
    "text": "reached the first networking performance",
    "start": "1020360",
    "end": "1023000"
  },
  {
    "text": "so what does that mean",
    "start": "1023000",
    "end": "1024620"
  },
  {
    "text": "um for example we tried we compared two",
    "start": "1024620",
    "end": "1026660"
  },
  {
    "text": "instance types so so the first one is",
    "start": "1026660",
    "end": "1028640"
  },
  {
    "text": "the 4X large machines it costs 1.3",
    "start": "1028640",
    "end": "1030798"
  },
  {
    "text": "dollars per hour the Baseline networking",
    "start": "1030799",
    "end": "1032959"
  },
  {
    "text": "is 10 gigabit but they call it burst",
    "start": "1032959",
    "end": "1035540"
  },
  {
    "text": "like burstable to 25 and then we find",
    "start": "1035540",
    "end": "1037760"
  },
  {
    "text": "that basically in our experiment it",
    "start": "1037760",
    "end": "1039500"
  },
  {
    "text": "always reaches at 25 gigabit per second",
    "start": "1039500",
    "end": "1041839"
  },
  {
    "text": "link",
    "start": "1041839",
    "end": "1043160"
  },
  {
    "text": "in comparison a twice as large machine",
    "start": "1043160",
    "end": "1045678"
  },
  {
    "text": "which costs 2.7 per hour the Baseline",
    "start": "1045679",
    "end": "1048260"
  },
  {
    "text": "performance is 18 gigabit per second and",
    "start": "1048260",
    "end": "1050419"
  },
  {
    "text": "there's no bursting so it's always stays",
    "start": "1050419",
    "end": "1051860"
  },
  {
    "text": "at 18 uh 18 18 gigabit so which means",
    "start": "1051860",
    "end": "1055280"
  },
  {
    "text": "that if we use two of the smaller",
    "start": "1055280",
    "end": "1056600"
  },
  {
    "text": "machines we can get actually 50 gigabit",
    "start": "1056600",
    "end": "1058160"
  },
  {
    "text": "of networking and that's",
    "start": "1058160",
    "end": "1060380"
  },
  {
    "text": "um useful because um we use the",
    "start": "1060380",
    "end": "1062000"
  },
  {
    "text": "networking to come to communicate with",
    "start": "1062000",
    "end": "1063679"
  },
  {
    "text": "F3 to communicate between nodes so the",
    "start": "1063679",
    "end": "1065900"
  },
  {
    "text": "throughput is important to us",
    "start": "1065900",
    "end": "1068059"
  },
  {
    "text": "and then we find that only this instance",
    "start": "1068059",
    "end": "1069860"
  },
  {
    "text": "is smaller than 4X large have burst",
    "start": "1069860",
    "end": "1071780"
  },
  {
    "text": "networking",
    "start": "1071780",
    "end": "1072679"
  },
  {
    "text": "so combining these two principles we",
    "start": "1072679",
    "end": "1076160"
  },
  {
    "text": "ended up deciding to use the i4i 4X",
    "start": "1076160",
    "end": "1078679"
  },
  {
    "text": "large nodes",
    "start": "1078679",
    "end": "1080120"
  },
  {
    "text": "again why 40 nodes right so if you have",
    "start": "1080120",
    "end": "1082160"
  },
  {
    "text": "in theory you have one note and then",
    "start": "1082160",
    "end": "1084080"
  },
  {
    "text": "that one now just you know keep keep",
    "start": "1084080",
    "end": "1085820"
  },
  {
    "text": "Computing data that's good enough well",
    "start": "1085820",
    "end": "1087740"
  },
  {
    "text": "we need 40 nodes because we are",
    "start": "1087740",
    "end": "1089360"
  },
  {
    "text": "processing 100 terabyte of data and each",
    "start": "1089360",
    "end": "1091460"
  },
  {
    "text": "of these instances have a fixed amount",
    "start": "1091460",
    "end": "1093860"
  },
  {
    "text": "of SSD attached to it we need some",
    "start": "1093860",
    "end": "1096740"
  },
  {
    "text": "scratch space for right amplification so",
    "start": "1096740",
    "end": "1098780"
  },
  {
    "text": "that's why we need 40 notes in the in",
    "start": "1098780",
    "end": "1100580"
  },
  {
    "text": "the end",
    "start": "1100580",
    "end": "1102260"
  },
  {
    "text": "that's a compute so",
    "start": "1102260",
    "end": "1104660"
  },
  {
    "text": "um the second question is what kind of",
    "start": "1104660",
    "end": "1106400"
  },
  {
    "text": "storage there are a lot of storage",
    "start": "1106400",
    "end": "1107840"
  },
  {
    "text": "solutions to choose from today the two",
    "start": "1107840",
    "end": "1110299"
  },
  {
    "text": "main ones are either the um the object",
    "start": "1110299",
    "end": "1113600"
  },
  {
    "text": "stores so S3 offers basically like an",
    "start": "1113600",
    "end": "1115760"
  },
  {
    "text": "object store versus EBS which is a more",
    "start": "1115760",
    "end": "1118700"
  },
  {
    "text": "traditional they call it elastic block",
    "start": "1118700",
    "end": "1121700"
  },
  {
    "text": "devices",
    "start": "1121700",
    "end": "1123740"
  },
  {
    "text": "um and then for temporary storage there",
    "start": "1123740",
    "end": "1125539"
  },
  {
    "text": "is the choice between SSD and and also",
    "start": "1125539",
    "end": "1128539"
  },
  {
    "text": "the the blocks block devices",
    "start": "1128539",
    "end": "1131240"
  },
  {
    "text": "so we ended up choosing S3 because uh",
    "start": "1131240",
    "end": "1133460"
  },
  {
    "text": "for a few reasons um this is also sort",
    "start": "1133460",
    "end": "1135380"
  },
  {
    "text": "of only reasonably true",
    "start": "1135380",
    "end": "1137419"
  },
  {
    "text": "um which are",
    "start": "1137419",
    "end": "1139460"
  },
  {
    "text": "um first of all S3 now can can provide",
    "start": "1139460",
    "end": "1141860"
  },
  {
    "text": "very high uh throughput and they don't",
    "start": "1141860",
    "end": "1143960"
  },
  {
    "text": "actually charge for that throughput so",
    "start": "1143960",
    "end": "1146120"
  },
  {
    "text": "that um I should say they charge it by",
    "start": "1146120",
    "end": "1148640"
  },
  {
    "text": "your instance networking throughput but",
    "start": "1148640",
    "end": "1151520"
  },
  {
    "text": "basically as much as the S3 itself can",
    "start": "1151520",
    "end": "1154280"
  },
  {
    "text": "reach as much networking throughput as",
    "start": "1154280",
    "end": "1156500"
  },
  {
    "text": "you can",
    "start": "1156500",
    "end": "1157340"
  },
  {
    "text": "um for for that particular instance",
    "start": "1157340",
    "end": "1159440"
  },
  {
    "text": "um in a comparison for example if you",
    "start": "1159440",
    "end": "1161000"
  },
  {
    "text": "use a block device you need to pay for",
    "start": "1161000",
    "end": "1162919"
  },
  {
    "text": "how many i o per second or throughput",
    "start": "1162919",
    "end": "1164539"
  },
  {
    "text": "you can get from that particular device",
    "start": "1164539",
    "end": "1166880"
  },
  {
    "text": "so again for S3 you only pay for i o per",
    "start": "1166880",
    "end": "1169160"
  },
  {
    "text": "second so all of the read write requests",
    "start": "1169160",
    "end": "1170780"
  },
  {
    "text": "and also the storage of the of the data",
    "start": "1170780",
    "end": "1172820"
  },
  {
    "text": "itself which is also cheaper than the",
    "start": "1172820",
    "end": "1174860"
  },
  {
    "text": "block devices",
    "start": "1174860",
    "end": "1176299"
  },
  {
    "text": "third this is also actually important",
    "start": "1176299",
    "end": "1178640"
  },
  {
    "text": "because for S3 it's pay as you go you",
    "start": "1178640",
    "end": "1181580"
  },
  {
    "text": "don't need to provision for for disk",
    "start": "1181580",
    "end": "1183559"
  },
  {
    "text": "space for the traditional ones it's like",
    "start": "1183559",
    "end": "1185179"
  },
  {
    "text": "you have to provision that it's going to",
    "start": "1185179",
    "end": "1187400"
  },
  {
    "text": "attach that virtual disk for S3 if you",
    "start": "1187400",
    "end": "1189559"
  },
  {
    "text": "have more data you have spilled data you",
    "start": "1189559",
    "end": "1191059"
  },
  {
    "text": "can just use those as you go Auto",
    "start": "1191059",
    "end": "1193039"
  },
  {
    "text": "scaling fully",
    "start": "1193039",
    "end": "1194840"
  },
  {
    "text": "finally the data is so S3 is like this",
    "start": "1194840",
    "end": "1198140"
  },
  {
    "text": "aggregated storage so it's not it's not",
    "start": "1198140",
    "end": "1200059"
  },
  {
    "text": "attached to the instances so if you have",
    "start": "1200059",
    "end": "1202700"
  },
  {
    "text": "instance failures the uh the the your",
    "start": "1202700",
    "end": "1205100"
  },
  {
    "text": "progress is not lost because the data is",
    "start": "1205100",
    "end": "1206720"
  },
  {
    "text": "stored separately on the storage service",
    "start": "1206720",
    "end": "1209780"
  },
  {
    "text": "um this will be ideal for like Auto",
    "start": "1209780",
    "end": "1211160"
  },
  {
    "text": "scaling clusters we actually also tried",
    "start": "1211160",
    "end": "1212720"
  },
  {
    "text": "using spot instances which you know come",
    "start": "1212720",
    "end": "1214940"
  },
  {
    "text": "and go more often than these on-demand",
    "start": "1214940",
    "end": "1217039"
  },
  {
    "text": "instances and then here the use of S3 is",
    "start": "1217039",
    "end": "1219799"
  },
  {
    "text": "actually crucial",
    "start": "1219799",
    "end": "1222399"
  },
  {
    "text": "so that's the um sort of infrastructure",
    "start": "1222559",
    "end": "1224960"
  },
  {
    "text": "side of things and I also wanted to just",
    "start": "1224960",
    "end": "1227179"
  },
  {
    "text": "give you a sneak peek of how the the",
    "start": "1227179",
    "end": "1229039"
  },
  {
    "text": "program itself looks like so this is",
    "start": "1229039",
    "end": "1231260"
  },
  {
    "text": "heavily using the distributed Futures",
    "start": "1231260",
    "end": "1233000"
  },
  {
    "text": "reference uh abstractions used in Ray so",
    "start": "1233000",
    "end": "1236059"
  },
  {
    "text": "if you use Ray before this is a this is",
    "start": "1236059",
    "end": "1237980"
  },
  {
    "text": "the ray dot object ref type",
    "start": "1237980",
    "end": "1240500"
  },
  {
    "text": "so back to how Shuffle looks like this",
    "start": "1240500",
    "end": "1243799"
  },
  {
    "text": "is actually surprisingly easy to",
    "start": "1243799",
    "end": "1245419"
  },
  {
    "text": "implement in Ray so this actually these",
    "start": "1245419",
    "end": "1247340"
  },
  {
    "text": "two lines of code here basically",
    "start": "1247340",
    "end": "1249580"
  },
  {
    "text": "expresses this whole Shuffle",
    "start": "1249580",
    "end": "1251980"
  },
  {
    "text": "communication pattern so you have uh",
    "start": "1251980",
    "end": "1255020"
  },
  {
    "text": "well you need to Define map tasks and",
    "start": "1255020",
    "end": "1256580"
  },
  {
    "text": "reduce tasks but once you have those you",
    "start": "1256580",
    "end": "1258980"
  },
  {
    "text": "just call map.remote of a particular",
    "start": "1258980",
    "end": "1261679"
  },
  {
    "text": "partition number",
    "start": "1261679",
    "end": "1263240"
  },
  {
    "text": "and then if you're not familiar they",
    "start": "1263240",
    "end": "1265460"
  },
  {
    "text": "start remote uh calls essentially start",
    "start": "1265460",
    "end": "1268100"
  },
  {
    "text": "a task on a remote node in the meantime",
    "start": "1268100",
    "end": "1270140"
  },
  {
    "text": "they immediately return a distributed",
    "start": "1270140",
    "end": "1273559"
  },
  {
    "text": "future which can be or these object",
    "start": "1273559",
    "end": "1275240"
  },
  {
    "text": "references which can be passed to other",
    "start": "1275240",
    "end": "1277039"
  },
  {
    "text": "tasks so that you can you know schedule",
    "start": "1277039",
    "end": "1278840"
  },
  {
    "text": "all of this house in parallel",
    "start": "1278840",
    "end": "1281179"
  },
  {
    "text": "so we take each output from the map from",
    "start": "1281179",
    "end": "1284600"
  },
  {
    "text": "the map output and then we pass them so",
    "start": "1284600",
    "end": "1287120"
  },
  {
    "text": "each reduced task takes each uh one of",
    "start": "1287120",
    "end": "1290120"
  },
  {
    "text": "each map output so this essentially",
    "start": "1290120",
    "end": "1292460"
  },
  {
    "text": "creates this",
    "start": "1292460",
    "end": "1293720"
  },
  {
    "text": "um n-square communication pattern",
    "start": "1293720",
    "end": "1297080"
  },
  {
    "text": "so",
    "start": "1297080",
    "end": "1298220"
  },
  {
    "text": "um to sort of summarize um in Ray the",
    "start": "1298220",
    "end": "1301220"
  },
  {
    "text": "application actually only needs to",
    "start": "1301220",
    "end": "1302780"
  },
  {
    "text": "specify a few things you need to specify",
    "start": "1302780",
    "end": "1304460"
  },
  {
    "text": "the task graph and this is a very",
    "start": "1304460",
    "end": "1306200"
  },
  {
    "text": "powerful and expressive way of",
    "start": "1306200",
    "end": "1308720"
  },
  {
    "text": "specifying them because because they can",
    "start": "1308720",
    "end": "1311120"
  },
  {
    "text": "actually specify Dynamic tasks",
    "start": "1311120",
    "end": "1313760"
  },
  {
    "text": "optionally you can tell Ray and in this",
    "start": "1313760",
    "end": "1316940"
  },
  {
    "text": "project we end up doing that to tell Ray",
    "start": "1316940",
    "end": "1319039"
  },
  {
    "text": "when exactly to start these tasks using",
    "start": "1319039",
    "end": "1321140"
  },
  {
    "text": "the program itself and also where to to",
    "start": "1321140",
    "end": "1323720"
  },
  {
    "text": "start tasks using the uh the resources",
    "start": "1323720",
    "end": "1325940"
  },
  {
    "text": "tag",
    "start": "1325940",
    "end": "1328280"
  },
  {
    "text": "now",
    "start": "1328280",
    "end": "1329179"
  },
  {
    "text": "just by writing that you get a lot of",
    "start": "1329179",
    "end": "1330919"
  },
  {
    "text": "things sort of for free as an",
    "start": "1330919",
    "end": "1332480"
  },
  {
    "text": "application developer so these are the",
    "start": "1332480",
    "end": "1334100"
  },
  {
    "text": "features that Ray provides first of all",
    "start": "1334100",
    "end": "1335900"
  },
  {
    "text": "it provides resource allocation so it",
    "start": "1335900",
    "end": "1337640"
  },
  {
    "text": "manages the cluster it will put your",
    "start": "1337640",
    "end": "1339559"
  },
  {
    "text": "task onto onto onto these notes it does",
    "start": "1339559",
    "end": "1343159"
  },
  {
    "text": "memory management the data plane does a",
    "start": "1343159",
    "end": "1344900"
  },
  {
    "text": "lot of memory management memory",
    "start": "1344900",
    "end": "1346760"
  },
  {
    "text": "management by for free that includes the",
    "start": "1346760",
    "end": "1350000"
  },
  {
    "text": "transferring the actual transferring of",
    "start": "1350000",
    "end": "1351500"
  },
  {
    "text": "objects between nodes so Ray would",
    "start": "1351500",
    "end": "1353600"
  },
  {
    "text": "handle of the TCP connection the failure",
    "start": "1353600",
    "end": "1355460"
  },
  {
    "text": "recovery all of those",
    "start": "1355460",
    "end": "1357200"
  },
  {
    "text": "it will automatically handles spilling",
    "start": "1357200",
    "end": "1359659"
  },
  {
    "text": "to disk so this is sort of like a",
    "start": "1359659",
    "end": "1361280"
  },
  {
    "text": "generalized virtual memory concept like",
    "start": "1361280",
    "end": "1363320"
  },
  {
    "text": "to the application developer is",
    "start": "1363320",
    "end": "1364820"
  },
  {
    "text": "transparent you have like infinite",
    "start": "1364820",
    "end": "1366200"
  },
  {
    "text": "memory but um under the hood array would",
    "start": "1366200",
    "end": "1368659"
  },
  {
    "text": "spill objects to disk and then recover",
    "start": "1368659",
    "end": "1370640"
  },
  {
    "text": "them when they are needed again",
    "start": "1370640",
    "end": "1372980"
  },
  {
    "text": "collection so any references go out of",
    "start": "1372980",
    "end": "1375380"
  },
  {
    "text": "scope they don't take additional space",
    "start": "1375380",
    "end": "1377059"
  },
  {
    "text": "in the object store",
    "start": "1377059",
    "end": "1379580"
  },
  {
    "text": "another important feature of race",
    "start": "1379580",
    "end": "1381620"
  },
  {
    "text": "pipeline IO so this is for basically for",
    "start": "1381620",
    "end": "1384260"
  },
  {
    "text": "example when you're sorting one",
    "start": "1384260",
    "end": "1385640"
  },
  {
    "text": "partition",
    "start": "1385640",
    "end": "1386960"
  },
  {
    "text": "um the uh the the transferring of the of",
    "start": "1386960",
    "end": "1389960"
  },
  {
    "text": "the for example the previous partition",
    "start": "1389960",
    "end": "1391280"
  },
  {
    "text": "can be done in parallel so this makes",
    "start": "1391280",
    "end": "1393380"
  },
  {
    "text": "sure that you can overlap execution with",
    "start": "1393380",
    "end": "1395000"
  },
  {
    "text": "IO to maximize the system efficiency",
    "start": "1395000",
    "end": "1398120"
  },
  {
    "text": "and finally for tolerance which is about",
    "start": "1398120",
    "end": "1400280"
  },
  {
    "text": "if anything goes around Ray has this",
    "start": "1400280",
    "end": "1402740"
  },
  {
    "text": "built-in lineage reconstruction that can",
    "start": "1402740",
    "end": "1404419"
  },
  {
    "text": "basically recover the uh the objects",
    "start": "1404419",
    "end": "1406640"
  },
  {
    "text": "through by recomputing",
    "start": "1406640",
    "end": "1410360"
  },
  {
    "text": "so this gives us this sort of pipelining",
    "start": "1410360",
    "end": "1412340"
  },
  {
    "text": "thing which is pretty cool so if you",
    "start": "1412340",
    "end": "1413720"
  },
  {
    "text": "think about sorting",
    "start": "1413720",
    "end": "1415100"
  },
  {
    "text": "um it's like you start by downloading",
    "start": "1415100",
    "end": "1416900"
  },
  {
    "text": "and downloading them from S3 your store",
    "start": "1416900",
    "end": "1418700"
  },
  {
    "text": "the blocks and then you transfer the",
    "start": "1418700",
    "end": "1420440"
  },
  {
    "text": "blocks to the receiving end and now",
    "start": "1420440",
    "end": "1422059"
  },
  {
    "text": "receiving and you merge these blocks and",
    "start": "1422059",
    "end": "1423980"
  },
  {
    "text": "then you spill them and then notice that",
    "start": "1423980",
    "end": "1426080"
  },
  {
    "text": "how in every step",
    "start": "1426080",
    "end": "1428059"
  },
  {
    "text": "um there the original machine can start",
    "start": "1428059",
    "end": "1430039"
  },
  {
    "text": "another task hand and this sort of",
    "start": "1430039",
    "end": "1431360"
  },
  {
    "text": "create this cascading pipeline that's",
    "start": "1431360",
    "end": "1432980"
  },
  {
    "text": "fully saturate all of the pipes and then",
    "start": "1432980",
    "end": "1435080"
  },
  {
    "text": "on the reducer and the reducing side you",
    "start": "1435080",
    "end": "1437000"
  },
  {
    "text": "restore the blocks you do a render",
    "start": "1437000",
    "end": "1439220"
  },
  {
    "text": "reduce and then you send the results",
    "start": "1439220",
    "end": "1440600"
  },
  {
    "text": "back to S3 again this can be pipelined",
    "start": "1440600",
    "end": "1443059"
  },
  {
    "text": "with other applications",
    "start": "1443059",
    "end": "1445280"
  },
  {
    "text": "so at the end of the day",
    "start": "1445280",
    "end": "1447140"
  },
  {
    "text": "um",
    "start": "1447140",
    "end": "1447679"
  },
  {
    "text": "we get this so this is the actual system",
    "start": "1447679",
    "end": "1450799"
  },
  {
    "text": "performance chart while running the 100",
    "start": "1450799",
    "end": "1452659"
  },
  {
    "text": "terabyte sort there's a lot of things on",
    "start": "1452659",
    "end": "1454820"
  },
  {
    "text": "here I think the the the trdr here is",
    "start": "1454820",
    "end": "1457100"
  },
  {
    "text": "that everything is saturated so CPU is",
    "start": "1457100",
    "end": "1458780"
  },
  {
    "text": "saturated",
    "start": "1458780",
    "end": "1460039"
  },
  {
    "text": "um networking is pretty saturated",
    "start": "1460039",
    "end": "1462380"
  },
  {
    "text": "um we ended up using a lot of almost all",
    "start": "1462380",
    "end": "1464720"
  },
  {
    "text": "of the disk space and then also the",
    "start": "1464720",
    "end": "1467120"
  },
  {
    "text": "progress here is pretty linear which is",
    "start": "1467120",
    "end": "1468740"
  },
  {
    "text": "pretty impressive for a very large scale",
    "start": "1468740",
    "end": "1470720"
  },
  {
    "text": "system",
    "start": "1470720",
    "end": "1472960"
  },
  {
    "text": "I think we're going to skip the handling",
    "start": "1473299",
    "end": "1475220"
  },
  {
    "text": "data skew part um and uh but this",
    "start": "1475220",
    "end": "1477500"
  },
  {
    "text": "basically tells you a lot of these um",
    "start": "1477500",
    "end": "1480380"
  },
  {
    "text": "more advanced techniques for for",
    "start": "1480380",
    "end": "1482059"
  },
  {
    "text": "dynamically handling data skew can also",
    "start": "1482059",
    "end": "1484640"
  },
  {
    "text": "be implemented pretty easily in Ray we",
    "start": "1484640",
    "end": "1486500"
  },
  {
    "text": "can maybe show the size later if you're",
    "start": "1486500",
    "end": "1489440"
  },
  {
    "text": "interested in this",
    "start": "1489440",
    "end": "1491659"
  },
  {
    "text": "so yeah Stephanie we'll talk about",
    "start": "1491659",
    "end": "1492919"
  },
  {
    "text": "what's next",
    "start": "1492919",
    "end": "1495460"
  },
  {
    "text": "the things that are happening",
    "start": "1504520",
    "end": "1508240"
  },
  {
    "text": "I don't think that",
    "start": "1509140",
    "end": "1512559"
  },
  {
    "text": "okay",
    "start": "1513860",
    "end": "1515360"
  },
  {
    "text": "all right so yeah a lot of the things",
    "start": "1515360",
    "end": "1517159"
  },
  {
    "text": "that are happening next are basically",
    "start": "1517159",
    "end": "1518659"
  },
  {
    "text": "about bringing those performance gains",
    "start": "1518659",
    "end": "1520880"
  },
  {
    "text": "that Frank talked about to end users um",
    "start": "1520880",
    "end": "1523159"
  },
  {
    "text": "so that's through libraries like Ray",
    "start": "1523159",
    "end": "1524659"
  },
  {
    "text": "data and I won't go through the results",
    "start": "1524659",
    "end": "1526700"
  },
  {
    "text": "here in detail uh for sake of time uh",
    "start": "1526700",
    "end": "1529580"
  },
  {
    "text": "but I'm happy to connect you so I'm one",
    "start": "1529580",
    "end": "1531740"
  },
  {
    "text": "of the developers here at very data and",
    "start": "1531740",
    "end": "1533299"
  },
  {
    "text": "we also have several others here giving",
    "start": "1533299",
    "end": "1534980"
  },
  {
    "text": "talks",
    "start": "1534980",
    "end": "1536539"
  },
  {
    "text": "um so I just wanted to also quickly",
    "start": "1536539",
    "end": "1538100"
  },
  {
    "text": "mention some of the things that are on",
    "start": "1538100",
    "end": "1539720"
  },
  {
    "text": "the roadmap for array data plane in",
    "start": "1539720",
    "end": "1541640"
  },
  {
    "text": "particular so here we're continuing to",
    "start": "1541640",
    "end": "1544340"
  },
  {
    "text": "invest in all of the things that we",
    "start": "1544340",
    "end": "1546140"
  },
  {
    "text": "think really made ray data plane useful",
    "start": "1546140",
    "end": "1548299"
  },
  {
    "text": "in the past so for flexibility being",
    "start": "1548299",
    "end": "1551059"
  },
  {
    "text": "able to support more kinds of different",
    "start": "1551059",
    "end": "1553159"
  },
  {
    "text": "object stores especially looking at",
    "start": "1553159",
    "end": "1555020"
  },
  {
    "text": "different Hardware storage so not just",
    "start": "1555020",
    "end": "1558100"
  },
  {
    "text": "host memory but also things like GPU",
    "start": "1558100",
    "end": "1560900"
  },
  {
    "text": "memory",
    "start": "1560900",
    "end": "1562100"
  },
  {
    "text": "we're also looking at trying to enhance",
    "start": "1562100",
    "end": "1564500"
  },
  {
    "text": "stability and also interoperability with",
    "start": "1564500",
    "end": "1567320"
  },
  {
    "text": "other Frameworks",
    "start": "1567320",
    "end": "1569179"
  },
  {
    "text": "cool so I just want to keep this short",
    "start": "1569179",
    "end": "1571400"
  },
  {
    "text": "so that we have time for some questions",
    "start": "1571400",
    "end": "1573380"
  },
  {
    "text": "but yeah thanks for having us here",
    "start": "1573380",
    "end": "1576679"
  },
  {
    "text": "thank you",
    "start": "1576679",
    "end": "1578799"
  },
  {
    "text": "and hi thanks for the talk",
    "start": "1589520",
    "end": "1592400"
  },
  {
    "text": "um I had two questions which is one is",
    "start": "1592400",
    "end": "1595940"
  },
  {
    "text": "um did that 97 cents per terabyte figure",
    "start": "1595940",
    "end": "1599480"
  },
  {
    "text": "include both the read and write uh to S3",
    "start": "1599480",
    "end": "1602600"
  },
  {
    "text": "and the second one is",
    "start": "1602600",
    "end": "1605120"
  },
  {
    "text": "um for storing the Ross unsorted data in",
    "start": "1605120",
    "end": "1607820"
  },
  {
    "text": "S3 uh what were what was the format you",
    "start": "1607820",
    "end": "1610159"
  },
  {
    "text": "ended up choosing and why",
    "start": "1610159",
    "end": "1612380"
  },
  {
    "text": "yeah I can take that so uh first of all",
    "start": "1612380",
    "end": "1615080"
  },
  {
    "text": "the cost includes both the compute and",
    "start": "1615080",
    "end": "1616940"
  },
  {
    "text": "storage so includes the the clustered uh",
    "start": "1616940",
    "end": "1620240"
  },
  {
    "text": "compute cluster cost includes the cost",
    "start": "1620240",
    "end": "1623360"
  },
  {
    "text": "to store the data and also the IOP the",
    "start": "1623360",
    "end": "1625640"
  },
  {
    "text": "audit read and get requests uh read and",
    "start": "1625640",
    "end": "1629240"
  },
  {
    "text": "write requests the second question also",
    "start": "1629240",
    "end": "1632240"
  },
  {
    "text": "what format did we use um so",
    "start": "1632240",
    "end": "1634580"
  },
  {
    "text": "um that particular sorting Benchmark was",
    "start": "1634580",
    "end": "1636320"
  },
  {
    "text": "just like sorting like a hundred byte",
    "start": "1636320",
    "end": "1638840"
  },
  {
    "text": "like records so it's like a it's its own",
    "start": "1638840",
    "end": "1641360"
  },
  {
    "text": "so we just store binary records",
    "start": "1641360",
    "end": "1643640"
  },
  {
    "text": "um we could uh for like you know actual",
    "start": "1643640",
    "end": "1645559"
  },
  {
    "text": "real data we could basically use parquet",
    "start": "1645559",
    "end": "1647240"
  },
  {
    "text": "to uh store those and then uh maybe one",
    "start": "1647240",
    "end": "1649760"
  },
  {
    "text": "thing we didn't mention here is that we",
    "start": "1649760",
    "end": "1650840"
  },
  {
    "text": "also need to Shard the data so S3 has",
    "start": "1650840",
    "end": "1653419"
  },
  {
    "text": "also its own particularly charting",
    "start": "1653419",
    "end": "1656120"
  },
  {
    "text": "mechanism to maximize basically the uh",
    "start": "1656120",
    "end": "1657919"
  },
  {
    "text": "the overall throughput so we basically",
    "start": "1657919",
    "end": "1659840"
  },
  {
    "text": "store all of those data into like 50",
    "start": "1659840",
    "end": "1661340"
  },
  {
    "text": "buckets and then with some prefix prefix",
    "start": "1661340",
    "end": "1663620"
  },
  {
    "text": "charting we can get as much performance",
    "start": "1663620",
    "end": "1665840"
  },
  {
    "text": "basically throughput we can from from S3",
    "start": "1665840",
    "end": "1669020"
  },
  {
    "text": "thanks",
    "start": "1669020",
    "end": "1671500"
  },
  {
    "text": "all right another round of applause for",
    "start": "1671600",
    "end": "1673700"
  },
  {
    "text": "Stephanie and Frank thank you so much",
    "start": "1673700",
    "end": "1677380"
  }
]
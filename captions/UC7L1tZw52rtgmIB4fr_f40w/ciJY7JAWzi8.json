[
  {
    "text": "cool welcome everyone hi I hope you have",
    "start": "2679",
    "end": "5160"
  },
  {
    "text": "enjoyed Keynotes um this is the first",
    "start": "5160",
    "end": "7160"
  },
  {
    "text": "session after lunch so I hope you're not",
    "start": "7160",
    "end": "8920"
  },
  {
    "text": "too tired um so today we're going to be",
    "start": "8920",
    "end": "11799"
  },
  {
    "text": "talking about LM ecosystem on any scale",
    "start": "11799",
    "end": "15320"
  },
  {
    "text": "uh my name is kuros I'm a engineering",
    "start": "15320",
    "end": "17880"
  },
  {
    "text": "Tech lead here at any scale working on",
    "start": "17880",
    "end": "19680"
  },
  {
    "text": "LM mostly on devx side of things um yeah",
    "start": "19680",
    "end": "24279"
  },
  {
    "text": "so um I'm sure you got to to familiar",
    "start": "24279",
    "end": "27800"
  },
  {
    "text": "yourself with any skill from the",
    "start": "27800",
    "end": "29119"
  },
  {
    "text": "Keynotes but essentially to summarize",
    "start": "29119",
    "end": "31800"
  },
  {
    "text": "things uh from the keynote we have built",
    "start": "31800",
    "end": "34399"
  },
  {
    "text": "this general purpose area platform we",
    "start": "34399",
    "end": "36559"
  },
  {
    "text": "like with on top of Ray uh that",
    "start": "36559",
    "end": "40200"
  },
  {
    "text": "essentially makes distributed computing",
    "start": "40200",
    "end": "42440"
  },
  {
    "text": "easier for Enterprise use cases and",
    "start": "42440",
    "end": "45280"
  },
  {
    "text": "lately LMS are becoming a big part of",
    "start": "45280",
    "end": "47719"
  },
  {
    "text": "these kind of like ecosystem and there",
    "start": "47719",
    "end": "51160"
  },
  {
    "text": "is this constant need for like new",
    "start": "51160",
    "end": "52960"
  },
  {
    "text": "abstractions new set of Primitives to",
    "start": "52960",
    "end": "55039"
  },
  {
    "text": "make these like working and building",
    "start": "55039",
    "end": "57160"
  },
  {
    "text": "applications on LM much much easier so",
    "start": "57160",
    "end": "60680"
  },
  {
    "text": "at any scale we built like a suite of",
    "start": "60680",
    "end": "62960"
  },
  {
    "text": "tools libraries and abstraction",
    "start": "62960",
    "end": "65720"
  },
  {
    "text": "abstractions to essentially allow LM",
    "start": "65720",
    "end": "68439"
  },
  {
    "text": "developers to kind of like navigate this",
    "start": "68439",
    "end": "70720"
  },
  {
    "text": "space much much easier and faster so",
    "start": "70720",
    "end": "73119"
  },
  {
    "text": "today I'm going to be covering that um",
    "start": "73119",
    "end": "75759"
  },
  {
    "text": "and just to get things started I'm going",
    "start": "75759",
    "end": "78119"
  },
  {
    "text": "to start by like who this talk is really",
    "start": "78119",
    "end": "80200"
  },
  {
    "text": "suited for like or um most takav are for",
    "start": "80200",
    "end": "84840"
  },
  {
    "text": "um so if you're like an Enterprise with",
    "start": "84840",
    "end": "87640"
  },
  {
    "text": "a lot of LM use cases or starting to",
    "start": "87640",
    "end": "90200"
  },
  {
    "text": "essentially plan that ahead or Engineers",
    "start": "90200",
    "end": "93360"
  },
  {
    "text": "building like very generic LM workflows",
    "start": "93360",
    "end": "96960"
  },
  {
    "text": "um or broadly speaking whoever like",
    "start": "96960",
    "end": "99880"
  },
  {
    "text": "anyone who has who wants to tap into the",
    "start": "99880",
    "end": "102159"
  },
  {
    "text": "power of like open LMS um at a scale",
    "start": "102159",
    "end": "105240"
  },
  {
    "text": "this is like the talk for you I'm going",
    "start": "105240",
    "end": "107079"
  },
  {
    "text": "to talk about like how any skill fits",
    "start": "107079",
    "end": "108880"
  },
  {
    "text": "your kind of needs um so to give the",
    "start": "108880",
    "end": "112439"
  },
  {
    "text": "talk a little bit more structure I'm",
    "start": "112439",
    "end": "114040"
  },
  {
    "text": "going to start by like discussing how we",
    "start": "114040",
    "end": "116159"
  },
  {
    "text": "think about closed versus open weight",
    "start": "116159",
    "end": "118439"
  },
  {
    "text": "LMS and how you should think about a",
    "start": "118439",
    "end": "120320"
  },
  {
    "text": "strategizing around the developments",
    "start": "120320",
    "end": "122399"
  },
  {
    "text": "there uh I'm going to talk about LM dep",
    "start": "122399",
    "end": "125439"
  },
  {
    "text": "cycle a little bit how we kind of offer",
    "start": "125439",
    "end": "128080"
  },
  {
    "text": "serving training and evaluation",
    "start": "128080",
    "end": "129520"
  },
  {
    "text": "Solutions around this and lat La last",
    "start": "129520",
    "end": "132360"
  },
  {
    "text": "I'm going to talk about like any scale",
    "start": "132360",
    "end": "134599"
  },
  {
    "text": "platform Integrations and the road map",
    "start": "134599",
    "end": "137040"
  },
  {
    "text": "ahead of this",
    "start": "137040",
    "end": "138239"
  },
  {
    "text": "thing so let's start by talking about",
    "start": "138239",
    "end": "141160"
  },
  {
    "text": "Clos versus open we DMS um so if you",
    "start": "141160",
    "end": "143879"
  },
  {
    "text": "asked me this question of like how we",
    "start": "143879",
    "end": "145319"
  },
  {
    "text": "should think about this a year ago um it",
    "start": "145319",
    "end": "148080"
  },
  {
    "text": "was very easy to make an argument in",
    "start": "148080",
    "end": "150280"
  },
  {
    "text": "favor of open weight LMS just because of",
    "start": "150280",
    "end": "152360"
  },
  {
    "text": "like cost um merely considering cost it",
    "start": "152360",
    "end": "155239"
  },
  {
    "text": "was like the right choice because you",
    "start": "155239",
    "end": "156920"
  },
  {
    "text": "couldn't go into production with like",
    "start": "156920",
    "end": "158400"
  },
  {
    "text": "Clos LMS at a time so what we've seen in",
    "start": "158400",
    "end": "161480"
  },
  {
    "text": "the last I guess 18 months as also Mark",
    "start": "161480",
    "end": "164720"
  },
  {
    "text": "pointed out in this fire sight chat is",
    "start": "164720",
    "end": "166480"
  },
  {
    "text": "like Clos LMS um especially like like",
    "start": "166480",
    "end": "170000"
  },
  {
    "text": "this chart is for GPT but it kind of",
    "start": "170000",
    "end": "171680"
  },
  {
    "text": "generalizes around like all of these",
    "start": "171680",
    "end": "173720"
  },
  {
    "text": "like API providers that uh these like",
    "start": "173720",
    "end": "176400"
  },
  {
    "text": "models have got dramatically cheaper",
    "start": "176400",
    "end": "178640"
  },
  {
    "text": "like it's 100x",
    "start": "178640",
    "end": "180360"
  },
  {
    "text": "more than 100x dropping cost on",
    "start": "180360",
    "end": "182560"
  },
  {
    "text": "inference for like almost the same",
    "start": "182560",
    "end": "184959"
  },
  {
    "text": "quality of these old you know the",
    "start": "184959",
    "end": "186920"
  },
  {
    "text": "preceding",
    "start": "186920",
    "end": "188120"
  },
  {
    "text": "models and on the other side of the",
    "start": "188120",
    "end": "190879"
  },
  {
    "text": "spectrum when you look at open weight",
    "start": "190879",
    "end": "192360"
  },
  {
    "text": "models they have also been getting",
    "start": "192360",
    "end": "193920"
  },
  {
    "text": "better especially with like pushes from",
    "start": "193920",
    "end": "195840"
  },
  {
    "text": "meta and on the Llama side um so on both",
    "start": "195840",
    "end": "199319"
  },
  {
    "text": "sides you're seeing like they're",
    "start": "199319",
    "end": "200519"
  },
  {
    "text": "addressing the you know um shortcomings",
    "start": "200519",
    "end": "203879"
  },
  {
    "text": "they had compared to a year ago like",
    "start": "203879",
    "end": "206040"
  },
  {
    "text": "closed models are getting much much",
    "start": "206040",
    "end": "207400"
  },
  {
    "text": "cheaper open weight models are getting",
    "start": "207400",
    "end": "209319"
  },
  {
    "text": "like much much better in quality um so",
    "start": "209319",
    "end": "212200"
  },
  {
    "text": "it's really like hard to kind of like if",
    "start": "212200",
    "end": "214040"
  },
  {
    "text": "open AI is you know providing apis like",
    "start": "214040",
    "end": "216959"
  },
  {
    "text": "that are very robust riant and it's like",
    "start": "216959",
    "end": "218799"
  },
  {
    "text": "getting cheaper why should we you know",
    "start": "218799",
    "end": "220360"
  },
  {
    "text": "go and think about self hosting like our",
    "start": "220360",
    "end": "223080"
  },
  {
    "text": "own open mode models like that's a very",
    "start": "223080",
    "end": "225319"
  },
  {
    "text": "valid question that is actually getting",
    "start": "225319",
    "end": "226640"
  },
  {
    "text": "harder to justify um the way I think",
    "start": "226640",
    "end": "229599"
  },
  {
    "text": "about it like there are two arguments",
    "start": "229599",
    "end": "231159"
  },
  {
    "text": "for this right um one is the biggest one",
    "start": "231159",
    "end": "233959"
  },
  {
    "text": "is obviously security like there's if",
    "start": "233959",
    "end": "235840"
  },
  {
    "text": "you're a company or Enterprise like I",
    "start": "235840",
    "end": "238400"
  },
  {
    "text": "know biotech firms are folling into this",
    "start": "238400",
    "end": "240200"
  },
  {
    "text": "like banking uh companies are falling",
    "start": "240200",
    "end": "242239"
  },
  {
    "text": "into this category like you have very",
    "start": "242239",
    "end": "243879"
  },
  {
    "text": "stringent like requirements around like",
    "start": "243879",
    "end": "246439"
  },
  {
    "text": "your how your data flows where your data",
    "start": "246439",
    "end": "248280"
  },
  {
    "text": "seats um and for those I think like self",
    "start": "248280",
    "end": "251280"
  },
  {
    "text": "host like going with closed like any",
    "start": "251280",
    "end": "253200"
  },
  {
    "text": "essentially API provider is not a really",
    "start": "253200",
    "end": "255400"
  },
  {
    "text": "good option um so this is where you",
    "start": "255400",
    "end": "258199"
  },
  {
    "text": "essentially have to think about and",
    "start": "258199",
    "end": "259560"
  },
  {
    "text": "strategize okay what am I going to do uh",
    "start": "259560",
    "end": "261959"
  },
  {
    "text": "am I going to go with like you know",
    "start": "261959",
    "end": "263400"
  },
  {
    "text": "secure Enterprise version of these Clos",
    "start": "263400",
    "end": "265479"
  },
  {
    "text": "models and that those are going to be",
    "start": "265479",
    "end": "266800"
  },
  {
    "text": "much more expensive or is this like uh",
    "start": "266800",
    "end": "268919"
  },
  {
    "text": "self-hosting that is going to be much",
    "start": "268919",
    "end": "270440"
  },
  {
    "text": "much cheaper but this argument um kind",
    "start": "270440",
    "end": "273680"
  },
  {
    "text": "of doesn't generalize broadly but like",
    "start": "273680",
    "end": "275720"
  },
  {
    "text": "what I think how I think about what",
    "start": "275720",
    "end": "277720"
  },
  {
    "text": "generalizes more broadly to everyone is",
    "start": "277720",
    "end": "280360"
  },
  {
    "text": "like this this argument you know",
    "start": "280360",
    "end": "282960"
  },
  {
    "text": "depicted in this this trade of space",
    "start": "282960",
    "end": "284880"
  },
  {
    "text": "where um we and whenever we are kind of",
    "start": "284880",
    "end": "288720"
  },
  {
    "text": "building LM applications we are",
    "start": "288720",
    "end": "290560"
  },
  {
    "text": "constantly thinking about like you know",
    "start": "290560",
    "end": "292440"
  },
  {
    "text": "improving like three dimension",
    "start": "292440",
    "end": "294160"
  },
  {
    "text": "essentially these three thinking about",
    "start": "294160",
    "end": "295520"
  },
  {
    "text": "these three axises here um so we've got",
    "start": "295520",
    "end": "298120"
  },
  {
    "text": "quality latency and cost so latency is",
    "start": "298120",
    "end": "301560"
  },
  {
    "text": "about like okay user experience what",
    "start": "301560",
    "end": "303800"
  },
  {
    "text": "kind of latency profile can I tolerate",
    "start": "303800",
    "end": "305840"
  },
  {
    "text": "my streaming output building a chat but",
    "start": "305840",
    "end": "307560"
  },
  {
    "text": "that's has a different requirement than",
    "start": "307560",
    "end": "309320"
  },
  {
    "text": "if I want to build an agent uh on on the",
    "start": "309320",
    "end": "312080"
  },
  {
    "text": "cost side you're like basically",
    "start": "312080",
    "end": "313440"
  },
  {
    "text": "reasoning about okay what is my traffic",
    "start": "313440",
    "end": "315680"
  },
  {
    "text": "going to look like is there like a high",
    "start": "315680",
    "end": "317440"
  },
  {
    "text": "QPS that I'm kind of um foreseeing for",
    "start": "317440",
    "end": "320759"
  },
  {
    "text": "this application or not and that really",
    "start": "320759",
    "end": "322880"
  },
  {
    "text": "impacts your cost and at the same time",
    "start": "322880",
    "end": "324520"
  },
  {
    "text": "quality obviously so you want these",
    "start": "324520",
    "end": "326360"
  },
  {
    "text": "models to kind of operate well in the mo",
    "start": "326360",
    "end": "329240"
  },
  {
    "text": "the the for the application you're kind",
    "start": "329240",
    "end": "331080"
  },
  {
    "text": "of deploying so with Clos",
    "start": "331080",
    "end": "333600"
  },
  {
    "text": "models uh for Quality you obviously get",
    "start": "333600",
    "end": "336120"
  },
  {
    "text": "some KN knobs to control it's like",
    "start": "336120",
    "end": "338240"
  },
  {
    "text": "prompt engineering or in some cases",
    "start": "338240",
    "end": "340000"
  },
  {
    "text": "fine-tuning but pretty much like uh",
    "start": "340000",
    "end": "342840"
  },
  {
    "text": "latency or cost is dictated after that",
    "start": "342840",
    "end": "345560"
  },
  {
    "text": "so you you don't have much control over",
    "start": "345560",
    "end": "347280"
  },
  {
    "text": "like what how much is it going to cost",
    "start": "347280",
    "end": "349199"
  },
  {
    "text": "or how fast you're going to kind of um",
    "start": "349199",
    "end": "352039"
  },
  {
    "text": "output tokens um to get around this I",
    "start": "352039",
    "end": "355080"
  },
  {
    "text": "think like only solution is like you",
    "start": "355080",
    "end": "356680"
  },
  {
    "text": "know for now at least um you know taking",
    "start": "356680",
    "end": "359160"
  },
  {
    "text": "control of over your own stack and",
    "start": "359160",
    "end": "360759"
  },
  {
    "text": "deploying language models yourself um",
    "start": "360759",
    "end": "364080"
  },
  {
    "text": "and you know in open models you can",
    "start": "364080",
    "end": "365919"
  },
  {
    "text": "essentially I don't know like deploy",
    "start": "365919",
    "end": "367840"
  },
  {
    "text": "them on like different types of",
    "start": "367840",
    "end": "368919"
  },
  {
    "text": "Hardwares or like depending on your",
    "start": "368919",
    "end": "370440"
  },
  {
    "text": "workload you may actually incorporate",
    "start": "370440",
    "end": "372240"
  },
  {
    "text": "some sort of speculative decoding or",
    "start": "372240",
    "end": "373720"
  },
  {
    "text": "like prefix caching these levels like",
    "start": "373720",
    "end": "375880"
  },
  {
    "text": "these deep optimizations that could be",
    "start": "375880",
    "end": "378599"
  },
  {
    "text": "tied to your own application and you can",
    "start": "378599",
    "end": "380280"
  },
  {
    "text": "essentially decouple these like",
    "start": "380280",
    "end": "382039"
  },
  {
    "text": "inherently things like in in this um",
    "start": "382039",
    "end": "385199"
  },
  {
    "text": "interdependency between these three",
    "start": "385199",
    "end": "386919"
  },
  {
    "text": "things um and if you want to you know",
    "start": "386919",
    "end": "389639"
  },
  {
    "text": "unlock yourself from this artificial",
    "start": "389639",
    "end": "391400"
  },
  {
    "text": "bound I think like you should strategize",
    "start": "391400",
    "end": "393280"
  },
  {
    "text": "around building Primitives to be able to",
    "start": "393280",
    "end": "395199"
  },
  {
    "text": "host these models yourself and that",
    "start": "395199",
    "end": "397599"
  },
  {
    "text": "really down the line ends up being",
    "start": "397599",
    "end": "399240"
  },
  {
    "text": "cheaper you can essentially satisfy the",
    "start": "399240",
    "end": "401440"
  },
  {
    "text": "quality and even like improve your",
    "start": "401440",
    "end": "403560"
  },
  {
    "text": "margins over time as you collect more",
    "start": "403560",
    "end": "405639"
  },
  {
    "text": "data so yeah let's take a look at what",
    "start": "405639",
    "end": "408919"
  },
  {
    "text": "now an LM Dev cycle looks like so",
    "start": "408919",
    "end": "412199"
  },
  {
    "text": "usually people start from serving these",
    "start": "412199",
    "end": "414680"
  },
  {
    "text": "models so for this we've built raym",
    "start": "414680",
    "end": "417319"
  },
  {
    "text": "which is a serving liary that I'm going",
    "start": "417319",
    "end": "419000"
  },
  {
    "text": "to um talk about um and sometimes this",
    "start": "419000",
    "end": "422520"
  },
  {
    "text": "is not enough over time you collect more",
    "start": "422520",
    "end": "424560"
  },
  {
    "text": "data you want to do some sort of",
    "start": "424560",
    "end": "425919"
  },
  {
    "text": "refinement the quality F falls short and",
    "start": "425919",
    "end": "428599"
  },
  {
    "text": "for that we have built this uh fine",
    "start": "428599",
    "end": "430599"
  },
  {
    "text": "tuning Library LM Forge uh it's mostly",
    "start": "430599",
    "end": "433160"
  },
  {
    "text": "for po post trainining kind of uh",
    "start": "433160",
    "end": "435639"
  },
  {
    "text": "operations and then for eval side like",
    "start": "435639",
    "end": "438360"
  },
  {
    "text": "every time you make like design",
    "start": "438360",
    "end": "440440"
  },
  {
    "text": "decisions such as prompt engineering or",
    "start": "440440",
    "end": "442400"
  },
  {
    "text": "like fine-tuning you want to be able to",
    "start": "442400",
    "end": "444479"
  },
  {
    "text": "like um scalably like run larg scale",
    "start": "444479",
    "end": "448520"
  },
  {
    "text": "evaluations on um like large data sets",
    "start": "448520",
    "end": "452160"
  },
  {
    "text": "that you that may represent your problem",
    "start": "452160",
    "end": "454599"
  },
  {
    "text": "and this is not just a one shot like you",
    "start": "454599",
    "end": "456919"
  },
  {
    "text": "know pipeline that you go through you",
    "start": "456919",
    "end": "459080"
  },
  {
    "text": "always like almost go like form a fly",
    "start": "459080",
    "end": "461400"
  },
  {
    "text": "whe out of this you deploy you collect",
    "start": "461400",
    "end": "463879"
  },
  {
    "text": "more data you find tun this either a",
    "start": "463879",
    "end": "466120"
  },
  {
    "text": "smaller model or just like improve the",
    "start": "466120",
    "end": "467840"
  },
  {
    "text": "quality of the model and then you do",
    "start": "467840",
    "end": "469199"
  },
  {
    "text": "batch evaluation to make sure it is",
    "start": "469199",
    "end": "471319"
  },
  {
    "text": "meeting the quality bar um so it's very",
    "start": "471319",
    "end": "474039"
  },
  {
    "text": "important to have like a streamlined and",
    "start": "474039",
    "end": "476440"
  },
  {
    "text": "like um you know unified ecosystem for",
    "start": "476440",
    "end": "479599"
  },
  {
    "text": "dealing with this and this is what we've",
    "start": "479599",
    "end": "481639"
  },
  {
    "text": "built at any scale so we're going to",
    "start": "481639",
    "end": "483280"
  },
  {
    "text": "talk about each component individually",
    "start": "483280",
    "end": "485800"
  },
  {
    "text": "next so on the online serving part we've",
    "start": "485800",
    "end": "489479"
  },
  {
    "text": "built RM so RM is this um LM serving",
    "start": "489479",
    "end": "493400"
  },
  {
    "text": "system built on top of race serve where",
    "start": "493400",
    "end": "495919"
  },
  {
    "text": "you can essentially bring any inference",
    "start": "495919",
    "end": "498360"
  },
  {
    "text": "engine such as VM on or tensor RT and",
    "start": "498360",
    "end": "501840"
  },
  {
    "text": "essentially get an open a compatible",
    "start": "501840",
    "end": "504560"
  },
  {
    "text": "Service uh that has you know production",
    "start": "504560",
    "end": "508240"
  },
  {
    "text": "production like features built in like",
    "start": "508240",
    "end": "510080"
  },
  {
    "text": "Auto scaling fall tolerance",
    "start": "510080",
    "end": "512240"
  },
  {
    "text": "observability around like you know",
    "start": "512240",
    "end": "514279"
  },
  {
    "text": "things that could go wrong and Recovery",
    "start": "514279",
    "end": "516680"
  },
  {
    "text": "events and things like that um so it's",
    "start": "516680",
    "end": "519640"
  },
  {
    "text": "very feature reach the way I categorize",
    "start": "519640",
    "end": "521560"
  },
  {
    "text": "like the features is like through these",
    "start": "521560",
    "end": "523640"
  },
  {
    "text": "different um types of you know features",
    "start": "523640",
    "end": "527279"
  },
  {
    "text": "um so there's like a ton of features",
    "start": "527279",
    "end": "529080"
  },
  {
    "text": "around like production Readiness um like",
    "start": "529080",
    "end": "531440"
  },
  {
    "text": "Auto scaling cluster recovery uh being",
    "start": "531440",
    "end": "534320"
  },
  {
    "text": "able to like launch and um you know shut",
    "start": "534320",
    "end": "537240"
  },
  {
    "text": "down these services using SDK are all",
    "start": "537240",
    "end": "540200"
  },
  {
    "text": "like around this production Readiness",
    "start": "540200",
    "end": "542360"
  },
  {
    "text": "story um there are like functional",
    "start": "542360",
    "end": "544399"
  },
  {
    "text": "features like you can essentially enable",
    "start": "544399",
    "end": "546560"
  },
  {
    "text": "Jon activate Json mode or like function",
    "start": "546560",
    "end": "548760"
  },
  {
    "text": "calling on any open models even if they",
    "start": "548760",
    "end": "551200"
  },
  {
    "text": "don't support it like natively um you",
    "start": "551200",
    "end": "554120"
  },
  {
    "text": "can do like for when you have a lot of",
    "start": "554120",
    "end": "555839"
  },
  {
    "text": "fine tune models you want to deploy one",
    "start": "555839",
    "end": "558000"
  },
  {
    "text": "one base model with a lot of like loaded",
    "start": "558000",
    "end": "560120"
  },
  {
    "text": "adapter at runtime that is multil laora",
    "start": "560120",
    "end": "562560"
  },
  {
    "text": "all of these functionalities are built",
    "start": "562560",
    "end": "564560"
  },
  {
    "text": "in here um and there's a lot of like",
    "start": "564560",
    "end": "567200"
  },
  {
    "text": "cost reduction features so we heavily",
    "start": "567200",
    "end": "570000"
  },
  {
    "text": "invest in this uh Dimension as well like",
    "start": "570000",
    "end": "572560"
  },
  {
    "text": "things like initializing your model fast",
    "start": "572560",
    "end": "575480"
  },
  {
    "text": "why does it matter when you want to like",
    "start": "575480",
    "end": "577160"
  },
  {
    "text": "Autos scale and you have a dynamic",
    "start": "577160",
    "end": "578640"
  },
  {
    "text": "traffic you want to be able to respond",
    "start": "578640",
    "end": "580360"
  },
  {
    "text": "to that traffic um by not like actually",
    "start": "580360",
    "end": "583120"
  },
  {
    "text": "Auto scaling your cluster and not having",
    "start": "583120",
    "end": "585040"
  },
  {
    "text": "like a static um cluster all the time uh",
    "start": "585040",
    "end": "588320"
  },
  {
    "text": "things like prefix caching or like other",
    "start": "588320",
    "end": "590320"
  },
  {
    "text": "cost optimizations are built into this",
    "start": "590320",
    "end": "592079"
  },
  {
    "text": "framework so I'm going to show a quick",
    "start": "592079",
    "end": "595560"
  },
  {
    "text": "demo of like how it looks like in action",
    "start": "595560",
    "end": "598079"
  },
  {
    "text": "so raym essentially like um when you go",
    "start": "598079",
    "end": "601360"
  },
  {
    "text": "to on any scale cons console you go on a",
    "start": "601360",
    "end": "604399"
  },
  {
    "text": "workspace that has essentially this like",
    "start": "604399",
    "end": "606640"
  },
  {
    "text": "uh realm installed realm comes with this",
    "start": "606640",
    "end": "610600"
  },
  {
    "text": "interactive CLI um where you can",
    "start": "610600",
    "end": "613240"
  },
  {
    "text": "essentially run and like you know",
    "start": "613240",
    "end": "614959"
  },
  {
    "text": "configure the model that you want to run",
    "start": "614959",
    "end": "616880"
  },
  {
    "text": "or other settings and then in the end",
    "start": "616880",
    "end": "618920"
  },
  {
    "text": "it's going to generate like a yaml",
    "start": "618920",
    "end": "620399"
  },
  {
    "text": "config that describes your service and",
    "start": "620399",
    "end": "622959"
  },
  {
    "text": "essentially you can essentially deploy",
    "start": "622959",
    "end": "624680"
  },
  {
    "text": "this service into any skill services and",
    "start": "624680",
    "end": "627760"
  },
  {
    "text": "what any skill does it starts a cluster",
    "start": "627760",
    "end": "630720"
  },
  {
    "text": "um and load up loads up you know the",
    "start": "630720",
    "end": "632800"
  },
  {
    "text": "replicas and uh starts the engine itself",
    "start": "632800",
    "end": "635880"
  },
  {
    "text": "and you know makes the model healthy and",
    "start": "635880",
    "end": "638480"
  },
  {
    "text": "all of this is going to be really like",
    "start": "638480",
    "end": "640240"
  },
  {
    "text": "you know very simr and uh you're going",
    "start": "640240",
    "end": "642320"
  },
  {
    "text": "to get to see like an open a compatible",
    "start": "642320",
    "end": "645079"
  },
  {
    "text": "API so here I'm showing like the API",
    "start": "645079",
    "end": "647320"
  },
  {
    "text": "endpoints the chat completion API where",
    "start": "647320",
    "end": "649639"
  },
  {
    "text": "it's like you have the same arguments",
    "start": "649639",
    "end": "651519"
  },
  {
    "text": "that open a has so you can essentially",
    "start": "651519",
    "end": "653120"
  },
  {
    "text": "use this as a drop and replace for you",
    "start": "653120",
    "end": "655920"
  },
  {
    "text": "know ver open AI is active or you can",
    "start": "655920",
    "end": "658880"
  },
  {
    "text": "essentially use this UI components that",
    "start": "658880",
    "end": "660800"
  },
  {
    "text": "we have built to you know connect to",
    "start": "660800",
    "end": "662440"
  },
  {
    "text": "that service find your model and like",
    "start": "662440",
    "end": "664519"
  },
  {
    "text": "you know start doing a Vibe check or",
    "start": "664519",
    "end": "666480"
  },
  {
    "text": "like prompt engineering more extensive",
    "start": "666480",
    "end": "668040"
  },
  {
    "text": "promt engineering on",
    "start": "668040",
    "end": "669600"
  },
  {
    "text": "this um so this just gives you like a",
    "start": "669600",
    "end": "672279"
  },
  {
    "text": "Vibe of how this works um there is a",
    "start": "672279",
    "end": "674680"
  },
  {
    "text": "more indepth discussion later on like by",
    "start": "674680",
    "end": "677519"
  },
  {
    "text": "conducted by Cody and Phillips um on you",
    "start": "677519",
    "end": "680920"
  },
  {
    "text": "know the actual optimizations that were",
    "start": "680920",
    "end": "683519"
  },
  {
    "text": "put into place for doing accelerated LM",
    "start": "683519",
    "end": "685839"
  },
  {
    "text": "inference on any scale I highly",
    "start": "685839",
    "end": "687760"
  },
  {
    "text": "recommend to check this out if you're",
    "start": "687760",
    "end": "689399"
  },
  {
    "text": "interested in like the optimization",
    "start": "689399",
    "end": "691200"
  },
  {
    "text": "around like LM",
    "start": "691200",
    "end": "692760"
  },
  {
    "text": "inference um but for the sake of time",
    "start": "692760",
    "end": "694920"
  },
  {
    "text": "we're not going to dive deep here that",
    "start": "694920",
    "end": "697480"
  },
  {
    "text": "brings us to the next topic is like",
    "start": "697480",
    "end": "699440"
  },
  {
    "text": "fine-tuning so LM Forge LM Forge is this",
    "start": "699440",
    "end": "703240"
  },
  {
    "text": "like uh",
    "start": "703240",
    "end": "705560"
  },
  {
    "text": "productionizing scale which is",
    "start": "705560",
    "end": "707720"
  },
  {
    "text": "essentially uh some design patterns",
    "start": "707720",
    "end": "710480"
  },
  {
    "text": "using ray ray ray train and Ray data",
    "start": "710480",
    "end": "713639"
  },
  {
    "text": "along with other open source libraries",
    "start": "713639",
    "end": "715480"
  },
  {
    "text": "like hugging face deep speed Etc to",
    "start": "715480",
    "end": "717920"
  },
  {
    "text": "essentially enable a higher level user",
    "start": "717920",
    "end": "720160"
  },
  {
    "text": "experience um for fine-tuning and post",
    "start": "720160",
    "end": "722560"
  },
  {
    "text": "trining LMS uh again lots of features",
    "start": "722560",
    "end": "726120"
  },
  {
    "text": "categorizing them here um like for",
    "start": "726120",
    "end": "728600"
  },
  {
    "text": "example it supports Laura full pram you",
    "start": "728600",
    "end": "731079"
  },
  {
    "text": "can bring any hugging face model uh like",
    "start": "731079",
    "end": "733360"
  },
  {
    "text": "it was mentioned today in the keynote um",
    "start": "733360",
    "end": "736519"
  },
  {
    "text": "there's like very like a very flexible",
    "start": "736519",
    "end": "739199"
  },
  {
    "text": "control over all hyper parameters that",
    "start": "739199",
    "end": "740959"
  },
  {
    "text": "you have like experiment experiment",
    "start": "740959",
    "end": "742880"
  },
  {
    "text": "tracking built-in and a lot of",
    "start": "742880",
    "end": "744560"
  },
  {
    "text": "observability around like how training",
    "start": "744560",
    "end": "746760"
  },
  {
    "text": "jobs are running um",
    "start": "746760",
    "end": "749800"
  },
  {
    "text": "you can do uh essentially a wide variety",
    "start": "749800",
    "end": "752920"
  },
  {
    "text": "of fine-tuning like types like tasks you",
    "start": "752920",
    "end": "755880"
  },
  {
    "text": "can do causal language model training",
    "start": "755880",
    "end": "757480"
  },
  {
    "text": "instruction tuning classification",
    "start": "757480",
    "end": "759079"
  },
  {
    "text": "preference tuning or even continuous",
    "start": "759079",
    "end": "761839"
  },
  {
    "text": "pre-training if you have like large",
    "start": "761839",
    "end": "763199"
  },
  {
    "text": "amounts of data and you want to do",
    "start": "763199",
    "end": "764600"
  },
  {
    "text": "domain",
    "start": "764600",
    "end": "765480"
  },
  {
    "text": "adaptation um and all like a lot of like",
    "start": "765480",
    "end": "768639"
  },
  {
    "text": "performance optimizations are vak in",
    "start": "768639",
    "end": "770600"
  },
  {
    "text": "like gradient checkpointing mix",
    "start": "770600",
    "end": "772839"
  },
  {
    "text": "Precision like latest um cudak like you",
    "start": "772839",
    "end": "776160"
  },
  {
    "text": "know flash intention Kel sler kernel",
    "start": "776160",
    "end": "778279"
  },
  {
    "text": "that are kind of built from the open",
    "start": "778279",
    "end": "779680"
  },
  {
    "text": "source um on and on top of this we have",
    "start": "779680",
    "end": "782440"
  },
  {
    "text": "a few like proprietary features that I'm",
    "start": "782440",
    "end": "784760"
  },
  {
    "text": "going to talk about",
    "start": "784760",
    "end": "786040"
  },
  {
    "text": "next",
    "start": "786040",
    "end": "787639"
  },
  {
    "text": "um okay oh yeah and then the API Still",
    "start": "787639",
    "end": "791680"
  },
  {
    "text": "Remains simple even though there's like",
    "start": "791680",
    "end": "793240"
  },
  {
    "text": "a lot lot of complexity behind the scene",
    "start": "793240",
    "end": "795360"
  },
  {
    "text": "you have like a CLI you pass in a config",
    "start": "795360",
    "end": "798000"
  },
  {
    "text": "yaml where you specify like your model",
    "start": "798000",
    "end": "800160"
  },
  {
    "text": "type um the data path and bunch of hyper",
    "start": "800160",
    "end": "802880"
  },
  {
    "text": "parameters that you want to modify even",
    "start": "802880",
    "end": "805360"
  },
  {
    "text": "if you don't want the defaults for",
    "start": "805360",
    "end": "807519"
  },
  {
    "text": "example so one thing that uh sets this",
    "start": "807519",
    "end": "810959"
  },
  {
    "text": "LM Forge aside from contenders I would",
    "start": "810959",
    "end": "813199"
  },
  {
    "text": "say is it gives you very like flexible",
    "start": "813199",
    "end": "815680"
  },
  {
    "text": "control over like cluster shape that",
    "start": "815680",
    "end": "817720"
  },
  {
    "text": "controls cost and speed of training so",
    "start": "817720",
    "end": "820279"
  },
  {
    "text": "what we hear with from a lot of",
    "start": "820279",
    "end": "821880"
  },
  {
    "text": "customers is like they don't have access",
    "start": "821880",
    "end": "823360"
  },
  {
    "text": "to the latest like you know GPS or it's",
    "start": "823360",
    "end": "826079"
  },
  {
    "text": "like usually a busy pull like to a busy",
    "start": "826079",
    "end": "828839"
  },
  {
    "text": "queue to kind of get their hands on",
    "start": "828839",
    "end": "830519"
  },
  {
    "text": "these type of things the nice thing",
    "start": "830519",
    "end": "832160"
  },
  {
    "text": "about like LM Forge is like it's very",
    "start": "832160",
    "end": "833680"
  },
  {
    "text": "flexible it stays like you don't have to",
    "start": "833680",
    "end": "836040"
  },
  {
    "text": "essentially like the same code can run",
    "start": "836040",
    "end": "838240"
  },
  {
    "text": "on any sort of cluster and cluster shape",
    "start": "838240",
    "end": "840959"
  },
  {
    "text": "um and you can essentially see like and",
    "start": "840959",
    "end": "842920"
  },
  {
    "text": "you know benchmark the trade-offs here",
    "start": "842920",
    "end": "845040"
  },
  {
    "text": "so this plot shows like for example the",
    "start": "845040",
    "end": "846880"
  },
  {
    "text": "land Escape of like changing GPU type",
    "start": "846880",
    "end": "848880"
  },
  {
    "text": "from like you know and cluster shape",
    "start": "848880",
    "end": "850920"
  },
  {
    "text": "going from like one node that has eight",
    "start": "850920",
    "end": "853240"
  },
  {
    "text": "machines on the same node to like two",
    "start": "853240",
    "end": "855560"
  },
  {
    "text": "nodes that have four and then like one",
    "start": "855560",
    "end": "857720"
  },
  {
    "text": "eight of eight machines that have",
    "start": "857720",
    "end": "859560"
  },
  {
    "text": "individual like GPU course and how that",
    "start": "859560",
    "end": "862079"
  },
  {
    "text": "plays in like you know throughput for",
    "start": "862079",
    "end": "863720"
  },
  {
    "text": "example on different like zero sharding",
    "start": "863720",
    "end": "866279"
  },
  {
    "text": "like you know strategies so you get",
    "start": "866279",
    "end": "868680"
  },
  {
    "text": "maximum control over like benchmarking",
    "start": "868680",
    "end": "870720"
  },
  {
    "text": "all of these things and adjusting you",
    "start": "870720",
    "end": "873759"
  },
  {
    "text": "know training pipelines depending on how",
    "start": "873759",
    "end": "875920"
  },
  {
    "text": "what type of Hardware uh accelerators",
    "start": "875920",
    "end": "878120"
  },
  {
    "text": "you have in hand um we've done some",
    "start": "878120",
    "end": "881000"
  },
  {
    "text": "proprietor optimizations uh in some",
    "start": "881000",
    "end": "883160"
  },
  {
    "text": "places um I'm going to just mention one",
    "start": "883160",
    "end": "885759"
  },
  {
    "text": "prime example here uh so for preference",
    "start": "885759",
    "end": "889120"
  },
  {
    "text": "optimization or like distillation type",
    "start": "889120",
    "end": "891639"
  },
  {
    "text": "of workloads there um the compute",
    "start": "891639",
    "end": "894079"
  },
  {
    "text": "Paradigm is a little bit different from",
    "start": "894079",
    "end": "895680"
  },
  {
    "text": "like traditional supervised fine tuning",
    "start": "895680",
    "end": "898800"
  },
  {
    "text": "um so in this type of like algorithms",
    "start": "898800",
    "end": "901920"
  },
  {
    "text": "you usually have like a model that is",
    "start": "901920",
    "end": "904600"
  },
  {
    "text": "acting as a reference model it produces",
    "start": "904600",
    "end": "906639"
  },
  {
    "text": "some sort of logits on the output and",
    "start": "906639",
    "end": "908720"
  },
  {
    "text": "you have like a Target Model that is",
    "start": "908720",
    "end": "910399"
  },
  {
    "text": "using those Logics to kind of boot a",
    "start": "910399",
    "end": "912160"
  },
  {
    "text": "strap and form its loss based on that",
    "start": "912160",
    "end": "914279"
  },
  {
    "text": "and then you forward back prob on that",
    "start": "914279",
    "end": "916279"
  },
  {
    "text": "model um there's tons of like",
    "start": "916279",
    "end": "918399"
  },
  {
    "text": "implementations of this out there but",
    "start": "918399",
    "end": "920240"
  },
  {
    "text": "most of them fall into this like nonr",
    "start": "920240",
    "end": "923000"
  },
  {
    "text": "sort of",
    "start": "923000",
    "end": "923959"
  },
  {
    "text": "implementation um where uh a GPU a",
    "start": "923959",
    "end": "927000"
  },
  {
    "text": "single GPU like machine is kind of time",
    "start": "927000",
    "end": "929160"
  },
  {
    "text": "Multiplex between these different",
    "start": "929160",
    "end": "931319"
  },
  {
    "text": "compute layers like if you want to do",
    "start": "931319",
    "end": "933319"
  },
  {
    "text": "forward pass for the T reference model",
    "start": "933319",
    "end": "935680"
  },
  {
    "text": "that happens in sequence uh with the",
    "start": "935680",
    "end": "939000"
  },
  {
    "text": "training like the target model for",
    "start": "939000",
    "end": "940560"
  },
  {
    "text": "example what we've done in like",
    "start": "940560",
    "end": "942360"
  },
  {
    "text": "implementations of this like algorithm",
    "start": "942360",
    "end": "944480"
  },
  {
    "text": "we have overlap these computations so",
    "start": "944480",
    "end": "946920"
  },
  {
    "text": "achieving like a you know up to 50% more",
    "start": "946920",
    "end": "949199"
  },
  {
    "text": "throughput for example um and these",
    "start": "949199",
    "end": "951600"
  },
  {
    "text": "These are only possible when using Ray",
    "start": "951600",
    "end": "953399"
  },
  {
    "text": "where you can essentially independently",
    "start": "953399",
    "end": "954800"
  },
  {
    "text": "orchestrate processes and then connect",
    "start": "954800",
    "end": "956880"
  },
  {
    "text": "them to each other",
    "start": "956880",
    "end": "959199"
  },
  {
    "text": "yeah so another thing to point out on",
    "start": "959199",
    "end": "962000"
  },
  {
    "text": "like regarding fine tuning is like um",
    "start": "962000",
    "end": "965079"
  },
  {
    "text": "there was this constant need of like you",
    "start": "965079",
    "end": "967000"
  },
  {
    "text": "know continuous fine tuning you start",
    "start": "967000",
    "end": "968880"
  },
  {
    "text": "usually like with a single data set seed",
    "start": "968880",
    "end": "970800"
  },
  {
    "text": "data set you fine tune you get some you",
    "start": "970800",
    "end": "973000"
  },
  {
    "text": "know you deploy it maybe in combination",
    "start": "973000",
    "end": "975040"
  },
  {
    "text": "with some other model and then you",
    "start": "975040",
    "end": "976279"
  },
  {
    "text": "collect more data and you want to repeat",
    "start": "976279",
    "end": "978319"
  },
  {
    "text": "this process so it's very important to",
    "start": "978319",
    "end": "980279"
  },
  {
    "text": "be able to load up your weights from",
    "start": "980279",
    "end": "982360"
  },
  {
    "text": "their initial condition and continue",
    "start": "982360",
    "end": "984519"
  },
  {
    "text": "fine tuning and then mix and match these",
    "start": "984519",
    "end": "986279"
  },
  {
    "text": "different choices so we have like a few",
    "start": "986279",
    "end": "988720"
  },
  {
    "text": "cas Cas studies of like where it's going",
    "start": "988720",
    "end": "990319"
  },
  {
    "text": "to be useful like for continuous",
    "start": "990319",
    "end": "991839"
  },
  {
    "text": "supervised fine tuning in this blog post",
    "start": "991839",
    "end": "994160"
  },
  {
    "text": "for example uh we have shown that like",
    "start": "994160",
    "end": "996360"
  },
  {
    "text": "you can essentially excel math reasoning",
    "start": "996360",
    "end": "999480"
  },
  {
    "text": "um by combining different distributions",
    "start": "999480",
    "end": "1001360"
  },
  {
    "text": "of data sets um related to the task and",
    "start": "1001360",
    "end": "1005279"
  },
  {
    "text": "if you repeatedly improve you can",
    "start": "1005279",
    "end": "1006839"
  },
  {
    "text": "essentially see that okay I can you know",
    "start": "1006839",
    "end": "1008920"
  },
  {
    "text": "improve the quality uh Benchmark this is",
    "start": "1008920",
    "end": "1011120"
  },
  {
    "text": "a kind of an old like study on done on",
    "start": "1011120",
    "end": "1013639"
  },
  {
    "text": "like llama 2 but still holds through um",
    "start": "1013639",
    "end": "1017079"
  },
  {
    "text": "another more recent one is like in",
    "start": "1017079",
    "end": "1019440"
  },
  {
    "text": "preference tuning um where you don't",
    "start": "1019440",
    "end": "1021480"
  },
  {
    "text": "want to over optimize your policy so",
    "start": "1021480",
    "end": "1023759"
  },
  {
    "text": "much that it kind of like over fits to",
    "start": "1023759",
    "end": "1025678"
  },
  {
    "text": "your current distribution of like data",
    "start": "1025679",
    "end": "1028360"
  },
  {
    "text": "um so in these cases you may want to",
    "start": "1028360",
    "end": "1029839"
  },
  {
    "text": "like do iterative you know training and",
    "start": "1029839",
    "end": "1032959"
  },
  {
    "text": "then rolling out into real world collect",
    "start": "1032959",
    "end": "1035199"
  },
  {
    "text": "more data and then again retrain and",
    "start": "1035199",
    "end": "1037640"
  },
  {
    "text": "we've shown that okay with DPO with many",
    "start": "1037640",
    "end": "1039839"
  },
  {
    "text": "like two iterations of DPO you can",
    "start": "1039839",
    "end": "1041438"
  },
  {
    "text": "essentially continuously improve like",
    "start": "1041439",
    "end": "1043240"
  },
  {
    "text": "for a certain Niche task um so this",
    "start": "1043240",
    "end": "1045959"
  },
  {
    "text": "Paradigm kind of still holds true and",
    "start": "1045959",
    "end": "1047558"
  },
  {
    "text": "we've enable like made it very easy for",
    "start": "1047559",
    "end": "1049480"
  },
  {
    "text": "people to like bring their own initial",
    "start": "1049480",
    "end": "1051400"
  },
  {
    "text": "weights uh whether it's like full Prime",
    "start": "1051400",
    "end": "1053559"
  },
  {
    "text": "weights or L Lowa adapter weights and",
    "start": "1053559",
    "end": "1055400"
  },
  {
    "text": "start training from those initial",
    "start": "1055400",
    "end": "1058000"
  },
  {
    "text": "checkpoints yeah so that brings us to",
    "start": "1058000",
    "end": "1060679"
  },
  {
    "text": "the next topic um",
    "start": "1060679",
    "end": "1062679"
  },
  {
    "text": "evaluation um so we've built something",
    "start": "1062679",
    "end": "1064960"
  },
  {
    "text": "we call like Realm batch it's like um we",
    "start": "1064960",
    "end": "1067919"
  },
  {
    "text": "are still finding good names for it but",
    "start": "1067919",
    "end": "1069880"
  },
  {
    "text": "for now it's realm batch um basically uh",
    "start": "1069880",
    "end": "1073799"
  },
  {
    "text": "it's a combination of Ray data plus VM",
    "start": "1073799",
    "end": "1076520"
  },
  {
    "text": "engine so VM has this like um you know",
    "start": "1076520",
    "end": "1080559"
  },
  {
    "text": "buil-in um kind of differentiating",
    "start": "1080559",
    "end": "1083200"
  },
  {
    "text": "feature that is built for high",
    "start": "1083200",
    "end": "1084480"
  },
  {
    "text": "throughput because of page attention so",
    "start": "1084480",
    "end": "1086480"
  },
  {
    "text": "it's very useful for like these larger",
    "start": "1086480",
    "end": "1088840"
  },
  {
    "text": "scale batch offline jobs uh so we use",
    "start": "1088840",
    "end": "1092760"
  },
  {
    "text": "that engine for like building this this",
    "start": "1092760",
    "end": "1095080"
  },
  {
    "text": "kind of Paradigm here um which basically",
    "start": "1095080",
    "end": "1098559"
  },
  {
    "text": "allows you to run continuously run like",
    "start": "1098559",
    "end": "1101159"
  },
  {
    "text": "evaluation on large data sets as you",
    "start": "1101159",
    "end": "1103280"
  },
  {
    "text": "make these design decisions through the",
    "start": "1103280",
    "end": "1104760"
  },
  {
    "text": "pipeline whether it's like prompt",
    "start": "1104760",
    "end": "1106440"
  },
  {
    "text": "engineering or like fine tune a new",
    "start": "1106440",
    "end": "1108200"
  },
  {
    "text": "model or a different Paradigm that you",
    "start": "1108200",
    "end": "1110039"
  },
  {
    "text": "try and you want to see its impact on",
    "start": "1110039",
    "end": "1112200"
  },
  {
    "text": "like the global like the overall",
    "start": "1112200",
    "end": "1114520"
  },
  {
    "text": "performance um some key enablement that",
    "start": "1114520",
    "end": "1117200"
  },
  {
    "text": "are differentiators here is like we",
    "start": "1117200",
    "end": "1119240"
  },
  {
    "text": "allow you to run these on a spot",
    "start": "1119240",
    "end": "1120679"
  },
  {
    "text": "instances resulting like in a much",
    "start": "1120679",
    "end": "1122640"
  },
  {
    "text": "cheaper like um kind of like overall",
    "start": "1122640",
    "end": "1125520"
  },
  {
    "text": "cost uh mostly because these are offline",
    "start": "1125520",
    "end": "1127919"
  },
  {
    "text": "jobs and you can if you can follow like",
    "start": "1127919",
    "end": "1130080"
  },
  {
    "text": "to tolerate faults you can essentially",
    "start": "1130080",
    "end": "1131919"
  },
  {
    "text": "recover from them it's not like as",
    "start": "1131919",
    "end": "1133880"
  },
  {
    "text": "intensive as like online serving um and",
    "start": "1133880",
    "end": "1136919"
  },
  {
    "text": "obviously fall tolerance is another",
    "start": "1136919",
    "end": "1138360"
  },
  {
    "text": "feature built into this to enable spot",
    "start": "1138360",
    "end": "1140120"
  },
  {
    "text": "instances and like some specific config",
    "start": "1140120",
    "end": "1142559"
  },
  {
    "text": "tuning so it's very important to like",
    "start": "1142559",
    "end": "1144559"
  },
  {
    "text": "when you have offline batches that has a",
    "start": "1144559",
    "end": "1146280"
  },
  {
    "text": "different like um you know optimization",
    "start": "1146280",
    "end": "1149120"
  },
  {
    "text": "profile compared to online serving and",
    "start": "1149120",
    "end": "1151039"
  },
  {
    "text": "we are kind of like doing that behind",
    "start": "1151039",
    "end": "1152480"
  },
  {
    "text": "the scene for for this type of workloads",
    "start": "1152480",
    "end": "1155159"
  },
  {
    "text": "um and yet the API remains very simple",
    "start": "1155159",
    "end": "1157679"
  },
  {
    "text": "basically what you do end up doing is",
    "start": "1157679",
    "end": "1159559"
  },
  {
    "text": "like you bring your own um class",
    "start": "1159559",
    "end": "1162240"
  },
  {
    "text": "defining what type of processing you",
    "start": "1162240",
    "end": "1163960"
  },
  {
    "text": "want to do like what do you want to do",
    "start": "1163960",
    "end": "1165320"
  },
  {
    "text": "with text Data how do you want to format",
    "start": "1165320",
    "end": "1167039"
  },
  {
    "text": "it and then how do you want to pass it",
    "start": "1167039",
    "end": "1168440"
  },
  {
    "text": "to language model um and how do you want",
    "start": "1168440",
    "end": "1170760"
  },
  {
    "text": "to postprocess it maybe you want to do",
    "start": "1170760",
    "end": "1172240"
  },
  {
    "text": "an LM as a judge in the downstream task",
    "start": "1172240",
    "end": "1174919"
  },
  {
    "text": "Etc so you basically have full control",
    "start": "1174919",
    "end": "1177360"
  },
  {
    "text": "over that logical like function like",
    "start": "1177360",
    "end": "1180000"
  },
  {
    "text": "logical function and then you wrap that",
    "start": "1180000",
    "end": "1182640"
  },
  {
    "text": "in like a ray data set called like a map",
    "start": "1182640",
    "end": "1184600"
  },
  {
    "text": "batches call and then provide like some",
    "start": "1184600",
    "end": "1186720"
  },
  {
    "text": "higher level concurrency controls uh to",
    "start": "1186720",
    "end": "1189880"
  },
  {
    "text": "essentially scale this thing up and yeah",
    "start": "1189880",
    "end": "1192679"
  },
  {
    "text": "so API remains very simple and yet like",
    "start": "1192679",
    "end": "1196200"
  },
  {
    "text": "very",
    "start": "1196200",
    "end": "1197320"
  },
  {
    "text": "expressive yeah so so um again Cody and",
    "start": "1197320",
    "end": "1200960"
  },
  {
    "text": "philli are going to talk about it it was",
    "start": "1200960",
    "end": "1202679"
  },
  {
    "text": "also mentioned in the keynote some",
    "start": "1202679",
    "end": "1204640"
  },
  {
    "text": "highlights about uh this thing is like",
    "start": "1204640",
    "end": "1207039"
  },
  {
    "text": "it's going to be end up end up being",
    "start": "1207039",
    "end": "1208520"
  },
  {
    "text": "much much cheaper than contenders like",
    "start": "1208520",
    "end": "1210760"
  },
  {
    "text": "so here we have like B Bedrock batch or",
    "start": "1210760",
    "end": "1213200"
  },
  {
    "text": "open a chat gp40 minis batch cost",
    "start": "1213200",
    "end": "1216640"
  },
  {
    "text": "profile um against like these um other",
    "start": "1216640",
    "end": "1220440"
  },
  {
    "text": "any scale type of Benchmark so we have",
    "start": "1220440",
    "end": "1222039"
  },
  {
    "text": "like three variant like bf16 fp8 and fp8",
    "start": "1222039",
    "end": "1225919"
  },
  {
    "text": "with prefix caching um and you can go",
    "start": "1225919",
    "end": "1229240"
  },
  {
    "text": "anywhere from like 2x all to C 6X um",
    "start": "1229240",
    "end": "1232960"
  },
  {
    "text": "based on your preference um this result",
    "start": "1232960",
    "end": "1236000"
  },
  {
    "text": "is just obviously for a small model it",
    "start": "1236000",
    "end": "1238000"
  },
  {
    "text": "generalizes same way to large models",
    "start": "1238000",
    "end": "1240280"
  },
  {
    "text": "which Cody and Philip are going to cover",
    "start": "1240280",
    "end": "1243039"
  },
  {
    "text": "yeah",
    "start": "1243039",
    "end": "1244080"
  },
  {
    "text": "so uh I talked about like three kind of",
    "start": "1244080",
    "end": "1248720"
  },
  {
    "text": "I guess like big rocks that we have",
    "start": "1248720",
    "end": "1250520"
  },
  {
    "text": "built Primitives that you can",
    "start": "1250520",
    "end": "1252360"
  },
  {
    "text": "essentially um used to build LM",
    "start": "1252360",
    "end": "1254720"
  },
  {
    "text": "applications regarding serving training",
    "start": "1254720",
    "end": "1257000"
  },
  {
    "text": "and Eva and",
    "start": "1257000",
    "end": "1259240"
  },
  {
    "text": "um it's very important to be able to",
    "start": "1259240",
    "end": "1260919"
  },
  {
    "text": "inti like integrate them with your",
    "start": "1260919",
    "end": "1262880"
  },
  {
    "text": "existing workflow so if you have like an",
    "start": "1262880",
    "end": "1265000"
  },
  {
    "text": "ml offs built out of airflow or like",
    "start": "1265000",
    "end": "1267320"
  },
  {
    "text": "other you know um graph management like",
    "start": "1267320",
    "end": "1270559"
  },
  {
    "text": "kind of like processes tasks Etc you",
    "start": "1270559",
    "end": "1273279"
  },
  {
    "text": "want to be able to like launch these",
    "start": "1273279",
    "end": "1274840"
  },
  {
    "text": "things um you know uh through those",
    "start": "1274840",
    "end": "1277799"
  },
  {
    "text": "processes um so for this we have",
    "start": "1277799",
    "end": "1279799"
  },
  {
    "text": "introduced like any like we have",
    "start": "1279799",
    "end": "1281400"
  },
  {
    "text": "integrated with any scale SDK where you",
    "start": "1281400",
    "end": "1283760"
  },
  {
    "text": "can essentially treat fine tuning for or",
    "start": "1283760",
    "end": "1285559"
  },
  {
    "text": "batch inference as a job submission um",
    "start": "1285559",
    "end": "1288600"
  },
  {
    "text": "like for example here then I'm showing",
    "start": "1288600",
    "end": "1289960"
  },
  {
    "text": "like I'm submitting a fine-tuning job",
    "start": "1289960",
    "end": "1291960"
  },
  {
    "text": "I'm waiting for it to finish all through",
    "start": "1291960",
    "end": "1293880"
  },
  {
    "text": "this any scale API I can essentially",
    "start": "1293880",
    "end": "1295919"
  },
  {
    "text": "retrieve my model artifacts produced by",
    "start": "1295919",
    "end": "1298440"
  },
  {
    "text": "these jobs using the job ID I can",
    "start": "1298440",
    "end": "1301200"
  },
  {
    "text": "construct the Ser service config writing",
    "start": "1301200",
    "end": "1303919"
  },
  {
    "text": "code and then submit that or deploy that",
    "start": "1303919",
    "end": "1306000"
  },
  {
    "text": "through code all done here so you can",
    "start": "1306000",
    "end": "1308480"
  },
  {
    "text": "essentially build wrappers around it",
    "start": "1308480",
    "end": "1310960"
  },
  {
    "text": "make it simpler like to expose it to",
    "start": "1310960",
    "end": "1312640"
  },
  {
    "text": "data scientist however you like using",
    "start": "1312640",
    "end": "1314520"
  },
  {
    "text": "the sdks we have here um other types of",
    "start": "1314520",
    "end": "1318120"
  },
  {
    "text": "external integration uh on the serf side",
    "start": "1318120",
    "end": "1321120"
  },
  {
    "text": "since we are open ey compatible this is",
    "start": "1321120",
    "end": "1322919"
  },
  {
    "text": "mostly like a drop and replace on the",
    "start": "1322919",
    "end": "1325080"
  },
  {
    "text": "client side so if you're using things",
    "start": "1325080",
    "end": "1327080"
  },
  {
    "text": "like L chain L like there's tons of like",
    "start": "1327080",
    "end": "1329520"
  },
  {
    "text": "these uh agentic libraries that are",
    "start": "1329520",
    "end": "1331919"
  },
  {
    "text": "getting built out there um to kind of",
    "start": "1331919",
    "end": "1334240"
  },
  {
    "text": "like be able to leverage like prompt",
    "start": "1334240",
    "end": "1336039"
  },
  {
    "text": "engineering like all this like building",
    "start": "1336039",
    "end": "1338080"
  },
  {
    "text": "rag um stuff like around that this is",
    "start": "1338080",
    "end": "1341679"
  },
  {
    "text": "going to be a drop in and replace uh you",
    "start": "1341679",
    "end": "1343840"
  },
  {
    "text": "don't have to change code or anything",
    "start": "1343840",
    "end": "1345840"
  },
  {
    "text": "like that um on the fine tuning side you",
    "start": "1345840",
    "end": "1348799"
  },
  {
    "text": "may have like experiment tracking tools",
    "start": "1348799",
    "end": "1350919"
  },
  {
    "text": "like ml flow or like V and biases",
    "start": "1350919",
    "end": "1353120"
  },
  {
    "text": "already purchased from like your",
    "start": "1353120",
    "end": "1355080"
  },
  {
    "text": "Enterprises so you can essentially",
    "start": "1355080",
    "end": "1356640"
  },
  {
    "text": "readily bring them in and you know",
    "start": "1356640",
    "end": "1359080"
  },
  {
    "text": "observe like your training jobs and",
    "start": "1359080",
    "end": "1360880"
  },
  {
    "text": "their progresses and like loss functions",
    "start": "1360880",
    "end": "1362840"
  },
  {
    "text": "Etc that helps you make design decisions",
    "start": "1362840",
    "end": "1365360"
  },
  {
    "text": "better and all of these are entirely",
    "start": "1365360",
    "end": "1367840"
  },
  {
    "text": "configurable through your existing cicd",
    "start": "1367840",
    "end": "1370720"
  },
  {
    "text": "workflows yeah so that brings us to last",
    "start": "1370720",
    "end": "1374360"
  },
  {
    "text": "slide um so all of these QR codes are",
    "start": "1374360",
    "end": "1378200"
  },
  {
    "text": "like essentially starting points for all",
    "start": "1378200",
    "end": "1380400"
  },
  {
    "text": "of these like tools that I've mentioned",
    "start": "1380400",
    "end": "1383000"
  },
  {
    "text": "RM LM Forge and RM batch um you can",
    "start": "1383000",
    "end": "1387080"
  },
  {
    "text": "start there it's going to you know take",
    "start": "1387080",
    "end": "1389000"
  },
  {
    "text": "you to any scale and on the exact like",
    "start": "1389000",
    "end": "1392039"
  },
  {
    "text": "uh workspace that these are for uh built",
    "start": "1392039",
    "end": "1395200"
  },
  {
    "text": "for um regarding what's coming on the",
    "start": "1395200",
    "end": "1398120"
  },
  {
    "text": "Surf Side um we're continuously working",
    "start": "1398120",
    "end": "1400679"
  },
  {
    "text": "on like reducing cost and latency uh",
    "start": "1400679",
    "end": "1404200"
  },
  {
    "text": "obviously um there's a more stuff around",
    "start": "1404200",
    "end": "1408080"
  },
  {
    "text": "like that X um so depending on your",
    "start": "1408080",
    "end": "1411159"
  },
  {
    "text": "workload you usually have to essentially",
    "start": "1411159",
    "end": "1413240"
  },
  {
    "text": "search over like the optim like the",
    "start": "1413240",
    "end": "1416480"
  },
  {
    "text": "engine um arguments to be able to find",
    "start": "1416480",
    "end": "1419840"
  },
  {
    "text": "like the optimal setting that has I",
    "start": "1419840",
    "end": "1422520"
  },
  {
    "text": "don't know like the lowest latency or",
    "start": "1422520",
    "end": "1424159"
  },
  {
    "text": "the lowest cost or some objective mix",
    "start": "1424159",
    "end": "1426279"
  },
  {
    "text": "mix mixture of objectives you have in",
    "start": "1426279",
    "end": "1427960"
  },
  {
    "text": "mind um we want to like be able to",
    "start": "1427960",
    "end": "1430200"
  },
  {
    "text": "automate that that and like build",
    "start": "1430200",
    "end": "1432120"
  },
  {
    "text": "processes around like you define an",
    "start": "1432120",
    "end": "1434039"
  },
  {
    "text": "objective and then we go like optimize",
    "start": "1434039",
    "end": "1436320"
  },
  {
    "text": "and find the best configuration for for",
    "start": "1436320",
    "end": "1438640"
  },
  {
    "text": "you um there is another U thing for",
    "start": "1438640",
    "end": "1442039"
  },
  {
    "text": "connecting serving to like training",
    "start": "1442039",
    "end": "1444360"
  },
  {
    "text": "where we want to automate more for",
    "start": "1444360",
    "end": "1446080"
  },
  {
    "text": "example like if you you know go to",
    "start": "1446080",
    "end": "1448320"
  },
  {
    "text": "production with this serving deployment",
    "start": "1448320",
    "end": "1450440"
  },
  {
    "text": "you want to collect more data and you",
    "start": "1450440",
    "end": "1451799"
  },
  {
    "text": "want to do some sort of data curation",
    "start": "1451799",
    "end": "1453600"
  },
  {
    "text": "find where your LM is not so like that",
    "start": "1453600",
    "end": "1456279"
  },
  {
    "text": "successful and you want to like do maybe",
    "start": "1456279",
    "end": "1458279"
  },
  {
    "text": "construct Downstream data sets for fine",
    "start": "1458279",
    "end": "1460440"
  },
  {
    "text": "tuning more more automate",
    "start": "1460440",
    "end": "1463240"
  },
  {
    "text": "automatically uh on the training side",
    "start": "1463240",
    "end": "1465799"
  },
  {
    "text": "again continuous Improvement on",
    "start": "1465799",
    "end": "1467240"
  },
  {
    "text": "throughput uh make things faster that's",
    "start": "1467240",
    "end": "1470360"
  },
  {
    "text": "that's a big big thing um there's a lot",
    "start": "1470360",
    "end": "1473080"
  },
  {
    "text": "of excitement around like multimodal",
    "start": "1473080",
    "end": "1475000"
  },
  {
    "text": "models like especially with the latest",
    "start": "1475000",
    "end": "1477720"
  },
  {
    "text": "llama releases and like pix STW from",
    "start": "1477720",
    "end": "1480080"
  },
  {
    "text": "like the mistol team um and like the",
    "start": "1480080",
    "end": "1482760"
  },
  {
    "text": "quality has really come to the level",
    "start": "1482760",
    "end": "1484399"
  },
  {
    "text": "that people are thinking about like in",
    "start": "1484399",
    "end": "1486080"
  },
  {
    "text": "integrating them into their workflows",
    "start": "1486080",
    "end": "1488080"
  },
  {
    "text": "and Building Things with it um the",
    "start": "1488080",
    "end": "1490240"
  },
  {
    "text": "question is like can f juning help there",
    "start": "1490240",
    "end": "1492039"
  },
  {
    "text": "I think this is something we're going to",
    "start": "1492039",
    "end": "1493679"
  },
  {
    "text": "work on uh a little bit um and the thing",
    "start": "1493679",
    "end": "1497399"
  },
  {
    "text": "that I'm mostly excited about is like",
    "start": "1497399",
    "end": "1499600"
  },
  {
    "text": "this notion of distillation and doing it",
    "start": "1499600",
    "end": "1502640"
  },
  {
    "text": "automatically um so you can very easily",
    "start": "1502640",
    "end": "1505159"
  },
  {
    "text": "like find like applications that you you",
    "start": "1505159",
    "end": "1507919"
  },
  {
    "text": "may build like around you know large",
    "start": "1507919",
    "end": "1510000"
  },
  {
    "text": "models today maybe like llama",
    "start": "1510000",
    "end": "1512240"
  },
  {
    "text": "370b and then over time as you collect",
    "start": "1512240",
    "end": "1514799"
  },
  {
    "text": "more data you can essentially distill",
    "start": "1514799",
    "end": "1517600"
  },
  {
    "text": "that model uh for that task into a",
    "start": "1517600",
    "end": "1520480"
  },
  {
    "text": "smaller variance and you know reduce",
    "start": "1520480",
    "end": "1523760"
  },
  {
    "text": "cost or like making it cheaper",
    "start": "1523760",
    "end": "1525440"
  },
  {
    "text": "essentially making it faster yeah so",
    "start": "1525440",
    "end": "1527600"
  },
  {
    "text": "these are the stuff we're working on um",
    "start": "1527600",
    "end": "1529919"
  },
  {
    "text": "we're hiring if you're interested in",
    "start": "1529919",
    "end": "1531399"
  },
  {
    "text": "this type of problems come talk to me uh",
    "start": "1531399",
    "end": "1534080"
  },
  {
    "text": "but yeah that wraps up the talk thank",
    "start": "1534080",
    "end": "1536480"
  },
  {
    "text": "you",
    "start": "1536480",
    "end": "1539240"
  },
  {
    "text": "now questions yeah uh the cost",
    "start": "1540600",
    "end": "1544720"
  },
  {
    "text": "comparison that you did which llm was",
    "start": "1544720",
    "end": "1547760"
  },
  {
    "text": "being used behind the scen yeah so the",
    "start": "1547760",
    "end": "1550320"
  },
  {
    "text": "question was for this plot of uh the",
    "start": "1550320",
    "end": "1553679"
  },
  {
    "text": "cost profile on yeah uh batch so this is",
    "start": "1553679",
    "end": "1557200"
  },
  {
    "text": "llama 38b",
    "start": "1557200",
    "end": "1559080"
  },
  {
    "text": "um running on l4s not even like the A1",
    "start": "1559080",
    "end": "1562919"
  },
  {
    "text": "100s um FBA like the the variations like",
    "start": "1562919",
    "end": "1566399"
  },
  {
    "text": "bf16 fp8",
    "start": "1566399",
    "end": "1569559"
  },
  {
    "text": "Etc",
    "start": "1569559",
    "end": "1572559"
  },
  {
    "text": "cool other",
    "start": "1572880",
    "end": "1576480"
  },
  {
    "text": "questions yeah we have about three",
    "start": "1578039",
    "end": "1583080"
  },
  {
    "text": "minutes okay",
    "start": "1584320",
    "end": "1588320"
  },
  {
    "text": "AP",
    "start": "1593120",
    "end": "1596120"
  },
  {
    "text": "yeah so we we built this in on our kind",
    "start": "1598159",
    "end": "1602000"
  },
  {
    "text": "of Surf Side um we have some we don't",
    "start": "1602000",
    "end": "1605200"
  },
  {
    "text": "allow customization from customer site",
    "start": "1605200",
    "end": "1607600"
  },
  {
    "text": "but we expose apis that are not",
    "start": "1607600",
    "end": "1609679"
  },
  {
    "text": "compatible like we don't like they are",
    "start": "1609679",
    "end": "1611919"
  },
  {
    "text": "newer than API for example prefix",
    "start": "1611919",
    "end": "1613480"
  },
  {
    "text": "caching right is something for example",
    "start": "1613480",
    "end": "1615399"
  },
  {
    "text": "not supported by openi we Define like",
    "start": "1615399",
    "end": "1617279"
  },
  {
    "text": "our own type of like you know extra",
    "start": "1617279",
    "end": "1619440"
  },
  {
    "text": "arguments in the buddy or something",
    "start": "1619440",
    "end": "1621200"
  },
  {
    "text": "where you can pass in to enable those",
    "start": "1621200",
    "end": "1622679"
  },
  {
    "text": "features so some of these that don't fit",
    "start": "1622679",
    "end": "1624720"
  },
  {
    "text": "the existing Paradigm we kind of like",
    "start": "1624720",
    "end": "1626440"
  },
  {
    "text": "become creative like Json mode we were",
    "start": "1626440",
    "end": "1628640"
  },
  {
    "text": "ahead and then open introduce it so we",
    "start": "1628640",
    "end": "1630480"
  },
  {
    "text": "have some Divergence over there but like",
    "start": "1630480",
    "end": "1632720"
  },
  {
    "text": "overall like we build features and then",
    "start": "1632720",
    "end": "1634760"
  },
  {
    "text": "we expose somehow expose that through",
    "start": "1634760",
    "end": "1636399"
  },
  {
    "text": "that",
    "start": "1636399",
    "end": "1638559"
  },
  {
    "text": "API cool so we can end early I think",
    "start": "1642840",
    "end": "1646760"
  },
  {
    "text": "thanks for coming",
    "start": "1646760",
    "end": "1650159"
  }
]
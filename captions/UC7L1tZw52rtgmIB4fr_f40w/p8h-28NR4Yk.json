[
  {
    "text": "hey everyone thanks for coming out my",
    "start": "3159",
    "end": "5359"
  },
  {
    "text": "name is Ahad I'm a senior data scientist",
    "start": "5359",
    "end": "7240"
  },
  {
    "text": "at data dog where I'm working on the",
    "start": "7240",
    "end": "9400"
  },
  {
    "text": "large model foundations and research",
    "start": "9400",
    "end": "11400"
  },
  {
    "text": "team uh we handle like Foundation models",
    "start": "11400",
    "end": "14360"
  },
  {
    "text": "llm eval that sort of thing um I'm going",
    "start": "14360",
    "end": "17760"
  },
  {
    "text": "to be talking about Toto which is our",
    "start": "17760",
    "end": "19080"
  },
  {
    "text": "state-of-the-art time series prediction",
    "start": "19080",
    "end": "21240"
  },
  {
    "text": "model acronymous Toto um if you don't",
    "start": "21240",
    "end": "24560"
  },
  {
    "text": "know a data dog we really like dog puns",
    "start": "24560",
    "end": "26519"
  },
  {
    "text": "sub Toto is the dog from The Wizard of",
    "start": "26519",
    "end": "28759"
  },
  {
    "text": "Oz um",
    "start": "28759",
    "end": "30599"
  },
  {
    "text": "this model is specifically optimized for",
    "start": "30599",
    "end": "32920"
  },
  {
    "text": "observability data which is a really",
    "start": "32920",
    "end": "34640"
  },
  {
    "text": "important use case at data dog but we",
    "start": "34640",
    "end": "37040"
  },
  {
    "text": "found that it's just a generally general",
    "start": "37040",
    "end": "39320"
  },
  {
    "text": "purpose awesome allaround",
    "start": "39320",
    "end": "41840"
  },
  {
    "text": "model so if you don't know data dog is",
    "start": "41840",
    "end": "44360"
  },
  {
    "text": "the leading observability monitoring",
    "start": "44360",
    "end": "46000"
  },
  {
    "text": "platform for large monitoring large",
    "start": "46000",
    "end": "48079"
  },
  {
    "text": "scale Cloud applications we collect all",
    "start": "48079",
    "end": "50559"
  },
  {
    "text": "sorts of observability data across the",
    "start": "50559",
    "end": "52399"
  },
  {
    "text": "whole stack um infrastructure metrics",
    "start": "52399",
    "end": "55320"
  },
  {
    "text": "application traces logs and more soon um",
    "start": "55320",
    "end": "60079"
  },
  {
    "text": "and there's a lot of data over 100",
    "start": "60079",
    "end": "62000"
  },
  {
    "text": "trillion data points a day we ingest all",
    "start": "62000",
    "end": "64600"
  },
  {
    "text": "in seconds and we make it available with",
    "start": "64600",
    "end": "67159"
  },
  {
    "text": "very seamless and clean visualizations",
    "start": "67159",
    "end": "70240"
  },
  {
    "text": "um in addition to alerting and an",
    "start": "70240",
    "end": "72720"
  },
  {
    "text": "analytics um overall our goal is to have",
    "start": "72720",
    "end": "75080"
  },
  {
    "text": "everyone everything you need to run a",
    "start": "75080",
    "end": "76840"
  },
  {
    "text": "high-scale application in production all",
    "start": "76840",
    "end": "79640"
  },
  {
    "text": "together in one site seamlessly",
    "start": "79640",
    "end": "81520"
  },
  {
    "text": "integrated in real",
    "start": "81520",
    "end": "83640"
  },
  {
    "text": "time as part of the platform we have a",
    "start": "83640",
    "end": "86240"
  },
  {
    "text": "few time for series forecasting models",
    "start": "86240",
    "end": "89439"
  },
  {
    "text": "they're not ml per se they're more like",
    "start": "89439",
    "end": "91720"
  },
  {
    "text": "classical statistics um these are",
    "start": "91720",
    "end": "94720"
  },
  {
    "text": "outlier detection you can imagine if one",
    "start": "94720",
    "end": "97640"
  },
  {
    "text": "host is behaving differently from the",
    "start": "97640",
    "end": "99479"
  },
  {
    "text": "rest of your cluster that's something",
    "start": "99479",
    "end": "100799"
  },
  {
    "text": "you'd want to know we have anomaly",
    "start": "100799",
    "end": "102960"
  },
  {
    "text": "detection for example say say service a",
    "start": "102960",
    "end": "106600"
  },
  {
    "text": "the latency is really high today but uh",
    "start": "106600",
    "end": "109560"
  },
  {
    "text": "the typical latency on a Monday",
    "start": "109560",
    "end": "111000"
  },
  {
    "text": "afternoon is really different and",
    "start": "111000",
    "end": "112680"
  },
  {
    "text": "knowing that the traffic is highly",
    "start": "112680",
    "end": "114600"
  },
  {
    "text": "seasonal um we can detect there's",
    "start": "114600",
    "end": "117200"
  },
  {
    "text": "unusual activity on the server um and we",
    "start": "117200",
    "end": "120439"
  },
  {
    "text": "also offer forecast so let's say we have",
    "start": "120439",
    "end": "122640"
  },
  {
    "text": "a database and can data dog help me know",
    "start": "122640",
    "end": "125799"
  },
  {
    "text": "when the dis is full so I can scale up",
    "start": "125799",
    "end": "127680"
  },
  {
    "text": "or rotate the logs before hurting my",
    "start": "127680",
    "end": "130560"
  },
  {
    "text": "quality of",
    "start": "130560",
    "end": "132120"
  },
  {
    "text": "service now the issue with these models",
    "start": "132120",
    "end": "134800"
  },
  {
    "text": "is that um they really need there's",
    "start": "134800",
    "end": "138640"
  },
  {
    "text": "three main issues one is that you really",
    "start": "138640",
    "end": "140680"
  },
  {
    "text": "need to train with domain specific data",
    "start": "140680",
    "end": "144519"
  },
  {
    "text": "uh and fit that to to the model which",
    "start": "144519",
    "end": "146879"
  },
  {
    "text": "can be extremely limiting um you also to",
    "start": "146879",
    "end": "150080"
  },
  {
    "text": "do a lot of fine-tuning and parameter",
    "start": "150080",
    "end": "151920"
  },
  {
    "text": "tweaking per um like time series and",
    "start": "151920",
    "end": "155959"
  },
  {
    "text": "that becomes a problem when we have over",
    "start": "155959",
    "end": "157599"
  },
  {
    "text": "750 Integrations 10 to hundreds of",
    "start": "157599",
    "end": "160760"
  },
  {
    "text": "custom metrics where customers are just",
    "start": "160760",
    "end": "162879"
  },
  {
    "text": "putting in whatever they want um so it",
    "start": "162879",
    "end": "165959"
  },
  {
    "text": "requires an intense amount of domain",
    "start": "165959",
    "end": "167720"
  },
  {
    "text": "domain knowledge and often times we have",
    "start": "167720",
    "end": "170959"
  },
  {
    "text": "these things we call refer to as cold",
    "start": "170959",
    "end": "172400"
  },
  {
    "text": "start problems where you need a fair",
    "start": "172400",
    "end": "174680"
  },
  {
    "text": "amount of data to make good predictions",
    "start": "174680",
    "end": "177239"
  },
  {
    "text": "and often times that's not there",
    "start": "177239",
    "end": "178720"
  },
  {
    "text": "especially for short short-lived in",
    "start": "178720",
    "end": "180519"
  },
  {
    "text": "Cloud infrastructure like pods hosts and",
    "start": "180519",
    "end": "183120"
  },
  {
    "text": "containers uh so a Time series",
    "start": "183120",
    "end": "185319"
  },
  {
    "text": "forecasting model that we showed before",
    "start": "185319",
    "end": "186879"
  },
  {
    "text": "might not have enough history to make a",
    "start": "186879",
    "end": "188640"
  },
  {
    "text": "good",
    "start": "188640",
    "end": "190319"
  },
  {
    "text": "forecast So within data dog we use these",
    "start": "190319",
    "end": "192879"
  },
  {
    "text": "time series for a few different types of",
    "start": "192879",
    "end": "194440"
  },
  {
    "text": "products um the first we call Watchdog",
    "start": "194440",
    "end": "196840"
  },
  {
    "text": "on the bottom left um and that can help",
    "start": "196840",
    "end": "199239"
  },
  {
    "text": "you identify unknown unknowns within the",
    "start": "199239",
    "end": "201280"
  },
  {
    "text": "system it'll typically alert the um",
    "start": "201280",
    "end": "203920"
  },
  {
    "text": "unusual activity and ping it out in",
    "start": "203920",
    "end": "206120"
  },
  {
    "text": "slack um we also have um our bits aai",
    "start": "206120",
    "end": "211519"
  },
  {
    "text": "which is our llm based investigative",
    "start": "211519",
    "end": "213519"
  },
  {
    "text": "agent um it can detect errors help you",
    "start": "213519",
    "end": "216879"
  },
  {
    "text": "triage um recommend solutions that sort",
    "start": "216879",
    "end": "219560"
  },
  {
    "text": "of thing um and we also have insights",
    "start": "219560",
    "end": "222319"
  },
  {
    "text": "which will take all this kind of Time",
    "start": "222319",
    "end": "224000"
  },
  {
    "text": "series forecasting",
    "start": "224000",
    "end": "225400"
  },
  {
    "text": "information give you uh kind of like a",
    "start": "225400",
    "end": "228040"
  },
  {
    "text": "story of events that have occurred and",
    "start": "228040",
    "end": "229920"
  },
  {
    "text": "how you might be able to address",
    "start": "229920",
    "end": "232519"
  },
  {
    "text": "it so given all these challenges we",
    "start": "232519",
    "end": "235040"
  },
  {
    "text": "asked ourselves can we leverage all the",
    "start": "235040",
    "end": "236920"
  },
  {
    "text": "data that we have to train a foundation",
    "start": "236920",
    "end": "239239"
  },
  {
    "text": "model that overcome these issues um and",
    "start": "239239",
    "end": "242480"
  },
  {
    "text": "that brings us to our Toto pipeline so",
    "start": "242480",
    "end": "246439"
  },
  {
    "text": "highle Toto is a multivariate zero shot",
    "start": "246439",
    "end": "249159"
  },
  {
    "text": "model which means that you can Clump in",
    "start": "249159",
    "end": "251400"
  },
  {
    "text": "a bunch of related metrics together and",
    "start": "251400",
    "end": "253480"
  },
  {
    "text": "it doesn't necessarily need a whole lot",
    "start": "253480",
    "end": "254959"
  },
  {
    "text": "of data to make a prediction um we're",
    "start": "254959",
    "end": "257479"
  },
  {
    "text": "training on the largest data set that",
    "start": "257479",
    "end": "259280"
  },
  {
    "text": "anyone has trained these types of models",
    "start": "259280",
    "end": "260680"
  },
  {
    "text": "on so previous models had used 100 to",
    "start": "260680",
    "end": "263560"
  },
  {
    "text": "200 billion data points and we're",
    "start": "263560",
    "end": "265600"
  },
  {
    "text": "training on the order of 1 trillion um",
    "start": "265600",
    "end": "268840"
  },
  {
    "text": "and another thing is that it doesn't",
    "start": "268840",
    "end": "270280"
  },
  {
    "text": "necessarily make a point estimate on the",
    "start": "270280",
    "end": "273080"
  },
  {
    "text": "on a solution where people in the field",
    "start": "273080",
    "end": "275520"
  },
  {
    "text": "typically like probabilistic um",
    "start": "275520",
    "end": "277800"
  },
  {
    "text": "predictions you don't necessarily want a",
    "start": "277800",
    "end": "279960"
  },
  {
    "text": "machine to tell you an answer without",
    "start": "279960",
    "end": "281520"
  },
  {
    "text": "telling you how confident isn't that",
    "start": "281520",
    "end": "283199"
  },
  {
    "text": "answer so Toto doesn't only give you an",
    "start": "283199",
    "end": "285320"
  },
  {
    "text": "estimate on what the value will be at",
    "start": "285320",
    "end": "287639"
  },
  {
    "text": "the time series but it'll give you um",
    "start": "287639",
    "end": "289560"
  },
  {
    "text": "means standard deviation what the pro",
    "start": "289560",
    "end": "291800"
  },
  {
    "text": "what the distribution fitted to that",
    "start": "291800",
    "end": "294320"
  },
  {
    "text": "is in terms of data collection we went",
    "start": "294320",
    "end": "296880"
  },
  {
    "text": "across the data dog pipeline drawing",
    "start": "296880",
    "end": "298960"
  },
  {
    "text": "from dashboard notebooks and monitors",
    "start": "298960",
    "end": "301600"
  },
  {
    "text": "this is all anonymized data it's only",
    "start": "301600",
    "end": "303759"
  },
  {
    "text": "time series um numerical data and we",
    "start": "303759",
    "end": "307919"
  },
  {
    "text": "group them together based on user",
    "start": "307919",
    "end": "309639"
  },
  {
    "text": "generated queries that tells us which",
    "start": "309639",
    "end": "312080"
  },
  {
    "text": "metrics are related and which ones",
    "start": "312080",
    "end": "313560"
  },
  {
    "text": "aren't additionally we're pulling from",
    "start": "313560",
    "end": "315919"
  },
  {
    "text": "open source data sets um the main one",
    "start": "315919",
    "end": "318199"
  },
  {
    "text": "being the latsa data set which is a",
    "start": "318199",
    "end": "320479"
  },
  {
    "text": "whole bunch of different uh time series",
    "start": "320479",
    "end": "323400"
  },
  {
    "text": "it's got like electricity and traffic",
    "start": "323400",
    "end": "325039"
  },
  {
    "text": "and all these different things um and",
    "start": "325039",
    "end": "327120"
  },
  {
    "text": "then we also generate synthetic data on",
    "start": "327120",
    "end": "328800"
  },
  {
    "text": "the Fly which we found made our model Ro",
    "start": "328800",
    "end": "332039"
  },
  {
    "text": "more robust to",
    "start": "332039",
    "end": "333960"
  },
  {
    "text": "noise in terms of the training pipeline",
    "start": "333960",
    "end": "336880"
  },
  {
    "text": "we have our inputs that we pack together",
    "start": "336880",
    "end": "339360"
  },
  {
    "text": "we pass it through our model which goes",
    "start": "339360",
    "end": "341199"
  },
  {
    "text": "through an embedding and a Transformer",
    "start": "341199",
    "end": "343319"
  },
  {
    "text": "it gives us our probabilistic estimation",
    "start": "343319",
    "end": "346160"
  },
  {
    "text": "and then we sample from that to generate",
    "start": "346160",
    "end": "348400"
  },
  {
    "text": "our",
    "start": "348400",
    "end": "349280"
  },
  {
    "text": "output uh series and you can think of",
    "start": "349280",
    "end": "351759"
  },
  {
    "text": "this kind of like an llm you give it a",
    "start": "351759",
    "end": "354000"
  },
  {
    "text": "portion of a Time series it's generating",
    "start": "354000",
    "end": "356319"
  },
  {
    "text": "the next step successively in an honor",
    "start": "356319",
    "end": "358360"
  },
  {
    "text": "regressive fashion",
    "start": "358360",
    "end": "360520"
  },
  {
    "text": "and our main contributions here were our",
    "start": "360520",
    "end": "363000"
  },
  {
    "text": "Transformer pipeline which pulls apart",
    "start": "363000",
    "end": "366199"
  },
  {
    "text": "the attention across um the time domain",
    "start": "366199",
    "end": "369880"
  },
  {
    "text": "and the domain of the different related",
    "start": "369880",
    "end": "372080"
  },
  {
    "text": "variates and we found that we can have",
    "start": "372080",
    "end": "374840"
  },
  {
    "text": "pretty high skill training in a more",
    "start": "374840",
    "end": "377280"
  },
  {
    "text": "efficient manner than we would have had",
    "start": "377280",
    "end": "378560"
  },
  {
    "text": "we used a traditional attention model",
    "start": "378560",
    "end": "381160"
  },
  {
    "text": "and we utilized this probabilistic",
    "start": "381160",
    "end": "383160"
  },
  {
    "text": "mixture student distribution which was",
    "start": "383160",
    "end": "385880"
  },
  {
    "text": "an idea that we came up with and we",
    "start": "385880",
    "end": "387440"
  },
  {
    "text": "later found that it's been play a lot",
    "start": "387440",
    "end": "389440"
  },
  {
    "text": "with with in the '90s um but it",
    "start": "389440",
    "end": "391319"
  },
  {
    "text": "basically allowed us to fit highly",
    "start": "391319",
    "end": "393520"
  },
  {
    "text": "complex distributions more accurately",
    "start": "393520",
    "end": "395520"
  },
  {
    "text": "than existing methods had done",
    "start": "395520",
    "end": "398840"
  },
  {
    "text": "before in terms of our training pipeline",
    "start": "398840",
    "end": "401400"
  },
  {
    "text": "we do our storage and training on cloud",
    "start": "401400",
    "end": "403880"
  },
  {
    "text": "infrastructure we do our pre-processing",
    "start": "403880",
    "end": "406000"
  },
  {
    "text": "and Apache spark uh and with Ray we we",
    "start": "406000",
    "end": "409039"
  },
  {
    "text": "launch jobs for our training and we",
    "start": "409039",
    "end": "411039"
  },
  {
    "text": "track these all in ml flow and",
    "start": "411039",
    "end": "413360"
  },
  {
    "text": "additionally we have Integrations within",
    "start": "413360",
    "end": "415479"
  },
  {
    "text": "data dog to monitor all every step of",
    "start": "415479",
    "end": "417960"
  },
  {
    "text": "this pipeline",
    "start": "417960",
    "end": "420720"
  },
  {
    "text": "specifically with Ray we're deploying on",
    "start": "420720",
    "end": "422599"
  },
  {
    "text": "we're deploying on kubernetes um we",
    "start": "422599",
    "end": "424800"
  },
  {
    "text": "emphasize security so we're putting",
    "start": "424800",
    "end": "426199"
  },
  {
    "text": "authentication on all of our clusters",
    "start": "426199",
    "end": "428639"
  },
  {
    "text": "and we also have a built-in",
    "start": "428639",
    "end": "430120"
  },
  {
    "text": "observability data dog Ray integration",
    "start": "430120",
    "end": "432400"
  },
  {
    "text": "that we",
    "start": "432400",
    "end": "434400"
  },
  {
    "text": "use so terms of results as I mentioned",
    "start": "434400",
    "end": "437599"
  },
  {
    "text": "this was an observability optimized",
    "start": "437599",
    "end": "440240"
  },
  {
    "text": "model so we created a benchmark data set",
    "start": "440240",
    "end": "442879"
  },
  {
    "text": "within our data that represented uh data",
    "start": "442879",
    "end": "445879"
  },
  {
    "text": "that you typically see in observability",
    "start": "445879",
    "end": "447479"
  },
  {
    "text": "settings so think High sparity extreme R",
    "start": "447479",
    "end": "450400"
  },
  {
    "text": "SKS seasonality flat series um and we",
    "start": "450400",
    "end": "454639"
  },
  {
    "text": "have we came up with these metrics which",
    "start": "454639",
    "end": "456160"
  },
  {
    "text": "are robust to large differences in scale",
    "start": "456160",
    "end": "458680"
  },
  {
    "text": "you typically see in observability so",
    "start": "458680",
    "end": "461000"
  },
  {
    "text": "these are symmetric mean absolute",
    "start": "461000",
    "end": "463160"
  },
  {
    "text": "percentage error or we call smape and",
    "start": "463160",
    "end": "465639"
  },
  {
    "text": "symmetric median absolute procenter",
    "start": "465639",
    "end": "467960"
  },
  {
    "text": "which we call SM MD ape and we found",
    "start": "467960",
    "end": "470879"
  },
  {
    "text": "that compared to the next best model we",
    "start": "470879",
    "end": "472879"
  },
  {
    "text": "were doing 8% better on SM map and 133%",
    "start": "472879",
    "end": "475919"
  },
  {
    "text": "better on SM",
    "start": "475919",
    "end": "478199"
  },
  {
    "text": "mdap now what's really cool is that we",
    "start": "478199",
    "end": "481240"
  },
  {
    "text": "didn't specifically train for this but",
    "start": "481240",
    "end": "482759"
  },
  {
    "text": "we evaluated Toto on more General op uh",
    "start": "482759",
    "end": "486639"
  },
  {
    "text": "benchmarks um we looked at the long",
    "start": "486639",
    "end": "489280"
  },
  {
    "text": "sequence forecasting Benchmark which",
    "start": "489280",
    "end": "491000"
  },
  {
    "text": "contains models which a lot of models in",
    "start": "491000",
    "end": "493440"
  },
  {
    "text": "this domain do it it's a compendium of",
    "start": "493440",
    "end": "495520"
  },
  {
    "text": "data sets that talk about electri",
    "start": "495520",
    "end": "497879"
  },
  {
    "text": "electrical Transformer temperature",
    "start": "497879",
    "end": "499759"
  },
  {
    "text": "electricity weather across various",
    "start": "499759",
    "end": "502400"
  },
  {
    "text": "forecast lengths and we found that",
    "start": "502400",
    "end": "504360"
  },
  {
    "text": "despite not actually being trained to do",
    "start": "504360",
    "end": "506280"
  },
  {
    "text": "this we were 10% better on Mee and",
    "start": "506280",
    "end": "509960"
  },
  {
    "text": "around 20% better on MSE compared to the",
    "start": "509960",
    "end": "512159"
  },
  {
    "text": "previous state-of-the-art models so to",
    "start": "512159",
    "end": "514518"
  },
  {
    "text": "us this indicates that the data that the",
    "start": "514519",
    "end": "516560"
  },
  {
    "text": "observability that data that we have at",
    "start": "516560",
    "end": "518120"
  },
  {
    "text": "data dog has a very different content",
    "start": "518120",
    "end": "521200"
  },
  {
    "text": "from open source benchmarks that are",
    "start": "521200",
    "end": "523479"
  },
  {
    "text": "outdoor and it's extremely beneficial",
    "start": "523480",
    "end": "526000"
  },
  {
    "text": "for time series forecasting as a",
    "start": "526000",
    "end": "529440"
  },
  {
    "text": "whole so we're really interested in",
    "start": "529440",
    "end": "532120"
  },
  {
    "text": "scaling up the use of these models we're",
    "start": "532120",
    "end": "534200"
  },
  {
    "text": "looking to implement",
    "start": "534200",
    "end": "536360"
  },
  {
    "text": "multimodality more context is going to",
    "start": "536360",
    "end": "538480"
  },
  {
    "text": "be really important for doing doing good",
    "start": "538480",
    "end": "539760"
  },
  {
    "text": "at forecasting Um this can be from text",
    "start": "539760",
    "end": "542480"
  },
  {
    "text": "but also other types of related metrics",
    "start": "542480",
    "end": "545200"
  },
  {
    "text": "um we also want to be doing some kind of",
    "start": "545200",
    "end": "547800"
  },
  {
    "text": "graph learning um there's a dependency",
    "start": "547800",
    "end": "550480"
  },
  {
    "text": "graph that all that connects all these",
    "start": "550480",
    "end": "551839"
  },
  {
    "text": "metrics and ideally we'd like to inject",
    "start": "551839",
    "end": "553480"
  },
  {
    "text": "that information in make our model",
    "start": "553480",
    "end": "555600"
  },
  {
    "text": "training even better and I think a a use",
    "start": "555600",
    "end": "558839"
  },
  {
    "text": "case we're the most excited about is",
    "start": "558839",
    "end": "560320"
  },
  {
    "text": "incorporating these into our existing",
    "start": "560320",
    "end": "562440"
  },
  {
    "text": "llm agents um so we have the bits",
    "start": "562440",
    "end": "566640"
  },
  {
    "text": "investigations using this kind of",
    "start": "566640",
    "end": "568600"
  },
  {
    "text": "forecasting they can be even better at",
    "start": "568600",
    "end": "571079"
  },
  {
    "text": "like going in making estimations on the",
    "start": "571079",
    "end": "573839"
  },
  {
    "text": "types of situations that you're seeing",
    "start": "573839",
    "end": "575959"
  },
  {
    "text": "um and helping customers to investigate",
    "start": "575959",
    "end": "577760"
  },
  {
    "text": "and respond to incidents more",
    "start": "577760",
    "end": "580680"
  },
  {
    "text": "efficiently so if you're interested in",
    "start": "580680",
    "end": "583600"
  },
  {
    "text": "any of the details of this paper um",
    "start": "583600",
    "end": "585839"
  },
  {
    "text": "please feel free to reach out to check",
    "start": "585839",
    "end": "587920"
  },
  {
    "text": "out our technical report this QR code um",
    "start": "587920",
    "end": "590920"
  },
  {
    "text": "we're also hiring pretty aggressively",
    "start": "590920",
    "end": "592680"
  },
  {
    "text": "across all of these so if you're",
    "start": "592680",
    "end": "593880"
  },
  {
    "text": "interested in anything I've mentioned",
    "start": "593880",
    "end": "595120"
  },
  {
    "text": "here um pleas feel free to reach out to",
    "start": "595120",
    "end": "597440"
  },
  {
    "text": "any of the authors on the paper or check",
    "start": "597440",
    "end": "599079"
  },
  {
    "text": "out the careers page and put in an",
    "start": "599079",
    "end": "601680"
  },
  {
    "text": "application uh and many thanks to",
    "start": "601680",
    "end": "603839"
  },
  {
    "text": "everyone on the team so me and Ben were",
    "start": "603839",
    "end": "606079"
  },
  {
    "text": "primarily handling the modeling KH did",
    "start": "606079",
    "end": "608040"
  },
  {
    "text": "Khan who's right over there and can",
    "start": "608040",
    "end": "609640"
  },
  {
    "text": "speak to anything regarding Ray or",
    "start": "609640",
    "end": "612320"
  },
  {
    "text": "infrastructure pipeline uh he did a ton",
    "start": "612320",
    "end": "614760"
  },
  {
    "text": "of work on that Charles Elise YF helped",
    "start": "614760",
    "end": "617360"
  },
  {
    "text": "with the evaluation and the data",
    "start": "617360",
    "end": "618720"
  },
  {
    "text": "collection uh and rman was our",
    "start": "618720",
    "end": "622720"
  },
  {
    "text": "manager uh thanks so much if you have",
    "start": "622720",
    "end": "625120"
  },
  {
    "text": "any questions feel free to ask",
    "start": "625120",
    "end": "628340"
  },
  {
    "text": "[Applause]",
    "start": "628340",
    "end": "632179"
  },
  {
    "text": "I can't hear",
    "start": "637320",
    "end": "638680"
  },
  {
    "text": "you oh yeah",
    "start": "638680",
    "end": "642920"
  },
  {
    "text": "oh so so the question was how did we",
    "start": "665120",
    "end": "668279"
  },
  {
    "text": "ensure that our synthetic data wasn't",
    "start": "668279",
    "end": "670680"
  },
  {
    "text": "significantly different from the",
    "start": "670680",
    "end": "671880"
  },
  {
    "text": "training data that we were training on",
    "start": "671880",
    "end": "673760"
  },
  {
    "text": "actually we want it to be very different",
    "start": "673760",
    "end": "675440"
  },
  {
    "text": "we don't want the model seeing",
    "start": "675440",
    "end": "677079"
  },
  {
    "text": "distributionally similar data because",
    "start": "677079",
    "end": "678600"
  },
  {
    "text": "it's not going to be learning anything",
    "start": "678600",
    "end": "680040"
  },
  {
    "text": "different so we specifically uh we were",
    "start": "680040",
    "end": "683360"
  },
  {
    "text": "combining a bunch of different types of",
    "start": "683360",
    "end": "685000"
  },
  {
    "text": "features that you might see in classical",
    "start": "685000",
    "end": "687320"
  },
  {
    "text": "statistical like textbooks but we knew",
    "start": "687320",
    "end": "690440"
  },
  {
    "text": "that they wouldn't necessarily appear in",
    "start": "690440",
    "end": "692000"
  },
  {
    "text": "Internet of EX existing",
    "start": "692000",
    "end": "695120"
  },
  {
    "text": "data",
    "start": "695120",
    "end": "698120"
  },
  {
    "text": "yeah yeah so the question was is the",
    "start": "713920",
    "end": "716600"
  },
  {
    "text": "time series Foundation models a data dog",
    "start": "716600",
    "end": "718360"
  },
  {
    "text": "more focused on observ ability data or",
    "start": "718360",
    "end": "720200"
  },
  {
    "text": "just general purpose we found that",
    "start": "720200",
    "end": "723000"
  },
  {
    "text": "despite optimizing for observability",
    "start": "723000",
    "end": "724920"
  },
  {
    "text": "it's better in both so it's just a",
    "start": "724920",
    "end": "728760"
  },
  {
    "text": "general purpose great",
    "start": "728760",
    "end": "731720"
  },
  {
    "text": "model it's focused on the observability",
    "start": "735680",
    "end": "738240"
  },
  {
    "text": "but this but it still do does well",
    "start": "738240",
    "end": "740279"
  },
  {
    "text": "better than everyone else on the open",
    "start": "740279",
    "end": "742120"
  },
  {
    "text": "Match",
    "start": "742120",
    "end": "744399"
  },
  {
    "text": "marks okay I think think we're",
    "start": "747760",
    "end": "751440"
  },
  {
    "text": "good all right thanks so much everyone",
    "start": "751440",
    "end": "756240"
  }
]
[
  {
    "text": "uh welcome everyone uh thanks for",
    "start": "3080",
    "end": "5200"
  },
  {
    "text": "joining us and being here today and by",
    "start": "5200",
    "end": "8000"
  },
  {
    "text": "choosing this session over all the seven",
    "start": "8000",
    "end": "10360"
  },
  {
    "text": "ongoing ones and uh my name is shawe and",
    "start": "10360",
    "end": "14240"
  },
  {
    "text": "along with my colleague Mia uh we are",
    "start": "14240",
    "end": "17080"
  },
  {
    "text": "very excited to share our story of",
    "start": "17080",
    "end": "19080"
  },
  {
    "text": "integrating Ray at BBB and uh in today's",
    "start": "19080",
    "end": "22680"
  },
  {
    "text": "session we'll use Al find tuning a",
    "start": "22680",
    "end": "25000"
  },
  {
    "text": "specific case study to share our story",
    "start": "25000",
    "end": "27480"
  },
  {
    "text": "over the next 30 minutes and this is a",
    "start": "27480",
    "end": "31080"
  },
  {
    "text": "high level agenda what we will go today",
    "start": "31080",
    "end": "34040"
  },
  {
    "text": "first of all I will be sharing overview",
    "start": "34040",
    "end": "37000"
  },
  {
    "text": "of how we integrate r as the foundation",
    "start": "37000",
    "end": "39360"
  },
  {
    "text": "am our compute layer and after that I",
    "start": "39360",
    "end": "42160"
  },
  {
    "text": "will be introducing few open source",
    "start": "42160",
    "end": "44039"
  },
  {
    "text": "Frameworks that we adopted to enhance",
    "start": "44039",
    "end": "46399"
  },
  {
    "text": "the r fun ecosystem and with that I will",
    "start": "46399",
    "end": "49760"
  },
  {
    "text": "pass over to Mia to share one specific",
    "start": "49760",
    "end": "52640"
  },
  {
    "text": "Alm fun use case based on text",
    "start": "52640",
    "end": "54960"
  },
  {
    "text": "summarization and in the end we will",
    "start": "54960",
    "end": "56879"
  },
  {
    "text": "open the floor for a qui2 session before",
    "start": "56879",
    "end": "59760"
  },
  {
    "text": "uh we close today's",
    "start": "59760",
    "end": "62760"
  },
  {
    "text": "topic and uh now without the further Ado",
    "start": "62760",
    "end": "65920"
  },
  {
    "text": "uh let's dive into the infrastructure",
    "start": "65920",
    "end": "67680"
  },
  {
    "text": "overview prior to the rate integration",
    "start": "67680",
    "end": "70320"
  },
  {
    "text": "and we shared this uh stack graph last",
    "start": "70320",
    "end": "72799"
  },
  {
    "text": "year in the rmit 2023 and uh so you",
    "start": "72799",
    "end": "76720"
  },
  {
    "text": "basically have two highlights uh on one",
    "start": "76720",
    "end": "78799"
  },
  {
    "text": "side it's very kubernetes Centric uh",
    "start": "78799",
    "end": "81520"
  },
  {
    "text": "Computing for ADB is primarily built on",
    "start": "81520",
    "end": "83960"
  },
  {
    "text": "top of kuber hence the M infrastructure",
    "start": "83960",
    "end": "86720"
  },
  {
    "text": "and related application Services uh and",
    "start": "86720",
    "end": "89560"
  },
  {
    "text": "you can see all those are deployed as",
    "start": "89560",
    "end": "91799"
  },
  {
    "text": "native kuber deployment services and",
    "start": "91799",
    "end": "94479"
  },
  {
    "text": "parts and on the other side it's very",
    "start": "94479",
    "end": "97159"
  },
  {
    "text": "Operational Support burden heavy and uh",
    "start": "97159",
    "end": "100040"
  },
  {
    "text": "as you know like ml deployments often",
    "start": "100040",
    "end": "102240"
  },
  {
    "text": "requires special handling uh for example",
    "start": "102240",
    "end": "104680"
  },
  {
    "text": "for distributed training you would",
    "start": "104680",
    "end": "106040"
  },
  {
    "text": "require G scheduling for mod life",
    "start": "106040",
    "end": "108399"
  },
  {
    "text": "serving you like have a like a",
    "start": "108399",
    "end": "109960"
  },
  {
    "text": "fractional GPU supported to have a",
    "start": "109960",
    "end": "111840"
  },
  {
    "text": "higher GPU utilization rate whereas the",
    "start": "111840",
    "end": "114880"
  },
  {
    "text": "internal uh kubernetes cluster is",
    "start": "114880",
    "end": "117079"
  },
  {
    "text": "primarily designed for long running",
    "start": "117079",
    "end": "119360"
  },
  {
    "text": "micros services so those features are",
    "start": "119360",
    "end": "121360"
  },
  {
    "text": "not widely supported and in this design",
    "start": "121360",
    "end": "124240"
  },
  {
    "text": "scheme ml Ops in essence is a kubernetes",
    "start": "124240",
    "end": "127399"
  },
  {
    "text": "Ops we are in the loop of co-managing in",
    "start": "127399",
    "end": "130119"
  },
  {
    "text": "t kuber cluster with another",
    "start": "130119",
    "end": "132080"
  },
  {
    "text": "infrastructure team so this not only",
    "start": "132080",
    "end": "134800"
  },
  {
    "text": "introduce a leak abstraction between the",
    "start": "134800",
    "end": "136920"
  },
  {
    "text": "two teams uh when we do feature planning",
    "start": "136920",
    "end": "139440"
  },
  {
    "text": "Operational Support uh but also uh",
    "start": "139440",
    "end": "142000"
  },
  {
    "text": "introduce the feature gap between Vana",
    "start": "142000",
    "end": "144800"
  },
  {
    "text": "kuber ecosystem and the M applications",
    "start": "144800",
    "end": "148599"
  },
  {
    "text": "that has to be filled in by the",
    "start": "148599",
    "end": "150080"
  },
  {
    "text": "infrastructure team to overcome those",
    "start": "150080",
    "end": "153239"
  },
  {
    "text": "challenges uh We've adopted re AI run",
    "start": "153239",
    "end": "156040"
  },
  {
    "text": "time at the ml development layer that is",
    "start": "156040",
    "end": "159280"
  },
  {
    "text": "to enable the end user to use retrain R",
    "start": "159280",
    "end": "161840"
  },
  {
    "text": "data directly for their due to the L",
    "start": "161840",
    "end": "164360"
  },
  {
    "text": "model development process and uh that",
    "start": "164360",
    "end": "168120"
  },
  {
    "text": "our strategy including the deployment",
    "start": "168120",
    "end": "170360"
  },
  {
    "text": "kuate uh so which as the central",
    "start": "170360",
    "end": "173720"
  },
  {
    "text": "castrator to manage the r clusters as",
    "start": "173720",
    "end": "177120"
  },
  {
    "text": "well as the great job CR it's a customer",
    "start": "177120",
    "end": "179840"
  },
  {
    "text": "resource definition that help us to",
    "start": "179840",
    "end": "181920"
  },
  {
    "text": "manage the life cycle of each individual",
    "start": "181920",
    "end": "184159"
  },
  {
    "text": "job and we are using one job per cluster",
    "start": "184159",
    "end": "187239"
  },
  {
    "text": "mode in this",
    "start": "187239",
    "end": "189000"
  },
  {
    "text": "approach and for the end users infer",
    "start": "189000",
    "end": "192080"
  },
  {
    "text": "team offers two set of apis uh the first",
    "start": "192080",
    "end": "194640"
  },
  {
    "text": "set is based on ADH hard job submission",
    "start": "194640",
    "end": "197920"
  },
  {
    "text": "user can uh WRA a local developed full",
    "start": "197920",
    "end": "201000"
  },
  {
    "text": "flagged re application and submit to",
    "start": "201000",
    "end": "203799"
  },
  {
    "text": "remote recluster for um ad hoc execution",
    "start": "203799",
    "end": "207000"
  },
  {
    "text": "with the configurable hardware like",
    "start": "207000",
    "end": "209200"
  },
  {
    "text": "resource and",
    "start": "209200",
    "end": "210360"
  },
  {
    "text": "requests and on the other side it's a",
    "start": "210360",
    "end": "213000"
  },
  {
    "text": "workflow DSL based uh uh interface it's",
    "start": "213000",
    "end": "216840"
  },
  {
    "text": "based on python deor that allow user to",
    "start": "216840",
    "end": "219879"
  },
  {
    "text": "easily decorate their existing python",
    "start": "219879",
    "end": "222480"
  },
  {
    "text": "workloads uh and then translate into",
    "start": "222480",
    "end": "224959"
  },
  {
    "text": "heavy lifting re computation that can be",
    "start": "224959",
    "end": "227720"
  },
  {
    "text": "embedded into their existing ml",
    "start": "227720",
    "end": "229680"
  },
  {
    "text": "production",
    "start": "229680",
    "end": "232040"
  },
  {
    "text": "workflows uh now let's switch GE for a",
    "start": "232040",
    "end": "234439"
  },
  {
    "text": "moment and move on to the fing infra",
    "start": "234439",
    "end": "236840"
  },
  {
    "text": "that we build on top of this computer",
    "start": "236840",
    "end": "238840"
  },
  {
    "text": "layer I contains several functional",
    "start": "238840",
    "end": "241720"
  },
  {
    "text": "layers uh that were roughly divided into",
    "start": "241720",
    "end": "245560"
  },
  {
    "text": "three category the first category is for",
    "start": "245560",
    "end": "248159"
  },
  {
    "text": "the application Level it's a direct user",
    "start": "248159",
    "end": "250680"
  },
  {
    "text": "facing that allow ml practitioner to",
    "start": "250680",
    "end": "253079"
  },
  {
    "text": "access the foundation models and the",
    "start": "253079",
    "end": "255159"
  },
  {
    "text": "second layer is on the cluster",
    "start": "255159",
    "end": "257040"
  },
  {
    "text": "orchestration level which maintains uh",
    "start": "257040",
    "end": "259600"
  },
  {
    "text": "the efficient scheduling of those",
    "start": "259600",
    "end": "261079"
  },
  {
    "text": "workloads being scheduled to the GPU",
    "start": "261079",
    "end": "263199"
  },
  {
    "text": "cluster and the third layer is what we",
    "start": "263199",
    "end": "265320"
  },
  {
    "text": "call the computer optimization layer",
    "start": "265320",
    "end": "267560"
  },
  {
    "text": "it's primarily focused on uh maximum",
    "start": "267560",
    "end": "269759"
  },
  {
    "text": "imiz the GPU utilization rate and uh",
    "start": "269759",
    "end": "272759"
  },
  {
    "text": "building on that idea let's take a",
    "start": "272759",
    "end": "274479"
  },
  {
    "text": "closer look at each layer and the goal",
    "start": "274479",
    "end": "276600"
  },
  {
    "text": "that we're optimizing on for the Funia",
    "start": "276600",
    "end": "279600"
  },
  {
    "text": "application layer uh the it's basically",
    "start": "279600",
    "end": "283360"
  },
  {
    "text": "to make the access to open source model",
    "start": "283360",
    "end": "285320"
  },
  {
    "text": "as simple as possible and compared to",
    "start": "285320",
    "end": "287600"
  },
  {
    "text": "the traditional like ml development",
    "start": "287600",
    "end": "289919"
  },
  {
    "text": "process that require model owner to",
    "start": "289919",
    "end": "292000"
  },
  {
    "text": "write like neuron Network layers using",
    "start": "292000",
    "end": "294560"
  },
  {
    "text": "tensor Flor pytorch fun app often times",
    "start": "294560",
    "end": "297560"
  },
  {
    "text": "operate on a higher level abstraction",
    "start": "297560",
    "end": "299520"
  },
  {
    "text": "with the configurable steps uh starting",
    "start": "299520",
    "end": "301960"
  },
  {
    "text": "from choosing the foundation model the",
    "start": "301960",
    "end": "304120"
  },
  {
    "text": "post trainining alignment techniques and",
    "start": "304120",
    "end": "306600"
  },
  {
    "text": "then opting for like resource",
    "start": "306600",
    "end": "308600"
  },
  {
    "text": "optimization techniques like Lara or",
    "start": "308600",
    "end": "310479"
  },
  {
    "text": "quantized Lara and uh as you can imagine",
    "start": "310479",
    "end": "314039"
  },
  {
    "text": "like with more and more app developed",
    "start": "314039",
    "end": "316080"
  },
  {
    "text": "here uh the next layer is to make sure",
    "start": "316080",
    "end": "319360"
  },
  {
    "text": "those fun app that created can be",
    "start": "319360",
    "end": "321560"
  },
  {
    "text": "efficiently scheduled and from the",
    "start": "321560",
    "end": "323960"
  },
  {
    "text": "service access point uh Those computer",
    "start": "323960",
    "end": "326840"
  },
  {
    "text": "resource can be accessed by the job and",
    "start": "326840",
    "end": "328720"
  },
  {
    "text": "workflow apis",
    "start": "328720",
    "end": "330160"
  },
  {
    "text": "and then upon the mission there is a",
    "start": "330160",
    "end": "332400"
  },
  {
    "text": "Central Computer job scheduler uh that",
    "start": "332400",
    "end": "335000"
  },
  {
    "text": "will schedule and manage those workflows",
    "start": "335000",
    "end": "338280"
  },
  {
    "text": "based on different prioritization rules",
    "start": "338280",
    "end": "340680"
  },
  {
    "text": "and the actual rate computer cluster",
    "start": "340680",
    "end": "342680"
  },
  {
    "text": "will be materialized upon",
    "start": "342680",
    "end": "345280"
  },
  {
    "text": "scheduling uh So based on the",
    "start": "345280",
    "end": "347560"
  },
  {
    "text": "application and uh how we schedule those",
    "start": "347560",
    "end": "350240"
  },
  {
    "text": "uh just as important is the last",
    "start": "350240",
    "end": "352160"
  },
  {
    "text": "functional goal to make sure that all",
    "start": "352160",
    "end": "354319"
  },
  {
    "text": "the reserved GP capacity can be fully",
    "start": "354319",
    "end": "357199"
  },
  {
    "text": "utilized uh here on the software side we",
    "start": "357199",
    "end": "360080"
  },
  {
    "text": "maintain the Amazon machine image and",
    "start": "360080",
    "end": "362039"
  },
  {
    "text": "the darker containers to keep up to date",
    "start": "362039",
    "end": "364240"
  },
  {
    "text": "with the latest NVIDIA drivers and",
    "start": "364240",
    "end": "366120"
  },
  {
    "text": "python packages and on the hardware side",
    "start": "366120",
    "end": "369039"
  },
  {
    "text": "with each P4 host a00 gpus are connected",
    "start": "369039",
    "end": "372080"
  },
  {
    "text": "by MV links and across multiple P4 hosts",
    "start": "372080",
    "end": "374880"
  },
  {
    "text": "we use ads elastic fabric adapter to",
    "start": "374880",
    "end": "377800"
  },
  {
    "text": "achieve GP direct RDMA this is to",
    "start": "377800",
    "end": "380520"
  },
  {
    "text": "address the network throughput",
    "start": "380520",
    "end": "382639"
  },
  {
    "text": "constraints for common like they same",
    "start": "382639",
    "end": "385160"
  },
  {
    "text": "for the distributive training based on",
    "start": "385160",
    "end": "387039"
  },
  {
    "text": "model and data parallelism",
    "start": "387039",
    "end": "389880"
  },
  {
    "text": "and uh so once we launch this platform",
    "start": "389880",
    "end": "392759"
  },
  {
    "text": "there are a couple of challenges we are",
    "start": "392759",
    "end": "394120"
  },
  {
    "text": "facing uh similar to you heard from the",
    "start": "394120",
    "end": "396919"
  },
  {
    "text": "other talks the first one is uh the",
    "start": "396919",
    "end": "399520"
  },
  {
    "text": "first challenge actually lies in the",
    "start": "399520",
    "end": "400960"
  },
  {
    "text": "fact that the community are growing",
    "start": "400960",
    "end": "403240"
  },
  {
    "text": "rapidly fast we're seeing like New",
    "start": "403240",
    "end": "405199"
  },
  {
    "text": "Foundation model new elment techniques",
    "start": "405199",
    "end": "407479"
  },
  {
    "text": "developed on like monthly or even weekly",
    "start": "407479",
    "end": "409560"
  },
  {
    "text": "basis and initially we started with a",
    "start": "409560",
    "end": "412199"
  },
  {
    "text": "set of fous scripts for like Lama for FL",
    "start": "412199",
    "end": "414960"
  },
  {
    "text": "T5 but does not scale well with the the",
    "start": "414960",
    "end": "417599"
  },
  {
    "text": "velocity of the how Community grow",
    "start": "417599",
    "end": "420919"
  },
  {
    "text": "and uh the Second Challenge is on",
    "start": "420919",
    "end": "423039"
  },
  {
    "text": "relating note is around how the scarce",
    "start": "423039",
    "end": "425639"
  },
  {
    "text": "GPU under reservation those are like",
    "start": "425639",
    "end": "428240"
  },
  {
    "text": "8100s we pay 720 for regardless we use",
    "start": "428240",
    "end": "431080"
  },
  {
    "text": "those or not and how to make sure those",
    "start": "431080",
    "end": "433240"
  },
  {
    "text": "can be allocated properly and we need a",
    "start": "433240",
    "end": "435919"
  },
  {
    "text": "balance between a static allocation for",
    "start": "435919",
    "end": "438479"
  },
  {
    "text": "high SLE jobs and a dynamic allocation",
    "start": "438479",
    "end": "441680"
  },
  {
    "text": "for teams with the prototypes and like",
    "start": "441680",
    "end": "445440"
  },
  {
    "text": "ad hoc",
    "start": "445440",
    "end": "447160"
  },
  {
    "text": "usage and the last challenge is around",
    "start": "447160",
    "end": "449639"
  },
  {
    "text": "da efficiency uh so we want to make sure",
    "start": "449639",
    "end": "452879"
  },
  {
    "text": "that model can be retrained on the fixed",
    "start": "452879",
    "end": "454639"
  },
  {
    "text": "Cadence and uh those like retraining",
    "start": "454639",
    "end": "457599"
  },
  {
    "text": "process can also be shared across",
    "start": "457599",
    "end": "459199"
  },
  {
    "text": "different use cases and different teams",
    "start": "459199",
    "end": "461840"
  },
  {
    "text": "So based on those changes uh challenges",
    "start": "461840",
    "end": "464440"
  },
  {
    "text": "infer team uh started the integration",
    "start": "464440",
    "end": "466879"
  },
  {
    "text": "with the both open source and in-house",
    "start": "466879",
    "end": "468479"
  },
  {
    "text": "build Solutions uh that I'm going to",
    "start": "468479",
    "end": "470599"
  },
  {
    "text": "share and uh the first like integration",
    "start": "470599",
    "end": "474000"
  },
  {
    "text": "point is around a open source framework",
    "start": "474000",
    "end": "476560"
  },
  {
    "text": "called llama Factory it's a popular",
    "start": "476560",
    "end": "478800"
  },
  {
    "text": "project on help today with around like",
    "start": "478800",
    "end": "481159"
  },
  {
    "text": "30k stars and with the help from Lama",
    "start": "481159",
    "end": "483840"
  },
  {
    "text": "factly uh it unlocks more than 100 base",
    "start": "483840",
    "end": "486400"
  },
  {
    "text": "models with access to various alignment",
    "start": "486400",
    "end": "489280"
  },
  {
    "text": "techniques like supervis f tuning and",
    "start": "489280",
    "end": "491479"
  },
  {
    "text": "commonly used RL techniques and in the",
    "start": "491479",
    "end": "494759"
  },
  {
    "text": "meanwhile the framework offers unified",
    "start": "494759",
    "end": "497080"
  },
  {
    "text": "data templates meaning that user can",
    "start": "497080",
    "end": "499280"
  },
  {
    "text": "switch to different Foundation models",
    "start": "499280",
    "end": "501000"
  },
  {
    "text": "easily without changing like the",
    "start": "501000",
    "end": "502680"
  },
  {
    "text": "interface at all and last but not least",
    "start": "502680",
    "end": "505639"
  },
  {
    "text": "if you check the code on the right side",
    "start": "505639",
    "end": "508319"
  },
  {
    "text": "uh you can embed with the R Train",
    "start": "508319",
    "end": "510120"
  },
  {
    "text": "framework similarly in each training",
    "start": "510120",
    "end": "512560"
  },
  {
    "text": "Loop you can just import the F modules",
    "start": "512560",
    "end": "515760"
  },
  {
    "text": "from the the framework and then use a",
    "start": "515760",
    "end": "518159"
  },
  {
    "text": "torch trainer to orchestrate like",
    "start": "518159",
    "end": "520200"
  },
  {
    "text": "distributed the GPU workers to start the",
    "start": "520200",
    "end": "522440"
  },
  {
    "text": "figh workload",
    "start": "522440",
    "end": "525360"
  },
  {
    "text": "efficiently and uh next part is the uh",
    "start": "525560",
    "end": "528800"
  },
  {
    "text": "another open source framework called The",
    "start": "528800",
    "end": "530519"
  },
  {
    "text": "Q uh it's a cber 19 native system that",
    "start": "530519",
    "end": "534040"
  },
  {
    "text": "abstract the way uh how to define",
    "start": "534040",
    "end": "536240"
  },
  {
    "text": "resources and how different job can",
    "start": "536240",
    "end": "538320"
  },
  {
    "text": "consume them if you were here in the",
    "start": "538320",
    "end": "540480"
  },
  {
    "text": "last session it's uh very similar to the",
    "start": "540480",
    "end": "542959"
  },
  {
    "text": "Unicorn that uh Apple team adopted with",
    "start": "542959",
    "end": "545880"
  },
  {
    "text": "a lot of feature parities and um so the",
    "start": "545880",
    "end": "549800"
  },
  {
    "text": "most importantly the Q when we made the",
    "start": "549800",
    "end": "552240"
  },
  {
    "text": "decision was uh it's has a native",
    "start": "552240",
    "end": "555000"
  },
  {
    "text": "integration with the kubra in other",
    "start": "555000",
    "end": "556880"
  },
  {
    "text": "words it understands how KUB defines the",
    "start": "556880",
    "end": "559320"
  },
  {
    "text": "resource understands the recluster and",
    "start": "559320",
    "end": "562279"
  },
  {
    "text": "reob resources and uh here by",
    "start": "562279",
    "end": "566000"
  },
  {
    "text": "abstracting away the resource types that",
    "start": "566000",
    "end": "568000"
  },
  {
    "text": "is are the a100 gpus uh into guaranteed",
    "start": "568000",
    "end": "572040"
  },
  {
    "text": "resource cues uh those highlighted by",
    "start": "572040",
    "end": "574079"
  },
  {
    "text": "the blue color so production job can get",
    "start": "574079",
    "end": "576839"
  },
  {
    "text": "a predial SLS to access these cues and",
    "start": "576839",
    "end": "580079"
  },
  {
    "text": "on the other side for ad hog jobs like",
    "start": "580079",
    "end": "582839"
  },
  {
    "text": "prototypes and evaluations user can",
    "start": "582839",
    "end": "585200"
  },
  {
    "text": "submit to the preal Q This highlighted",
    "start": "585200",
    "end": "587800"
  },
  {
    "text": "by the yellow color where it will be one",
    "start": "587800",
    "end": "590320"
  },
  {
    "text": "to one map to the guaranteed Q size and",
    "start": "590320",
    "end": "594200"
  },
  {
    "text": "then sharding to multiple shards with",
    "start": "594200",
    "end": "596120"
  },
  {
    "text": "the fair sharing guaranteed across",
    "start": "596120",
    "end": "598079"
  },
  {
    "text": "different pre proof",
    "start": "598079",
    "end": "600680"
  },
  {
    "text": "and from the user perspective a job can",
    "start": "600680",
    "end": "603320"
  },
  {
    "text": "run into up for retri state if preempted",
    "start": "603320",
    "end": "606440"
  },
  {
    "text": "but it will run into uh success or fail",
    "start": "606440",
    "end": "609600"
  },
  {
    "text": "uh in the end",
    "start": "609600",
    "end": "611519"
  },
  {
    "text": "eventually and uh on the last note that",
    "start": "611519",
    "end": "614920"
  },
  {
    "text": "Q also offer a simple Prius and Grana",
    "start": "614920",
    "end": "618079"
  },
  {
    "text": "integration so that the infrastructure",
    "start": "618079",
    "end": "620680"
  },
  {
    "text": "team can monitor those two metrics to",
    "start": "620680",
    "end": "622800"
  },
  {
    "text": "decide on the overall cluster allocation",
    "start": "622800",
    "end": "625440"
  },
  {
    "text": "and reservation for example if the",
    "start": "625440",
    "end": "627839"
  },
  {
    "text": "number of pending jobs is hard hard than",
    "start": "627839",
    "end": "629920"
  },
  {
    "text": "a certain threshold then we decide to",
    "start": "629920",
    "end": "632279"
  },
  {
    "text": "scill up the cluster and if the certain",
    "start": "632279",
    "end": "635040"
  },
  {
    "text": "team based cluster que utilization is",
    "start": "635040",
    "end": "637440"
  },
  {
    "text": "low then we scill down the cluster",
    "start": "637440",
    "end": "639519"
  },
  {
    "text": "accordingly to save the reserved",
    "start": "639519",
    "end": "641160"
  },
  {
    "text": "instance",
    "start": "641160",
    "end": "643600"
  },
  {
    "text": "cost and one last another change around",
    "start": "643639",
    "end": "648000"
  },
  {
    "text": "the integration is between Ray and our",
    "start": "648000",
    "end": "650079"
  },
  {
    "text": "in-house uh workflow engine uh here is",
    "start": "650079",
    "end": "653399"
  },
  {
    "text": "we introduce a framework called the glow",
    "start": "653399",
    "end": "655160"
  },
  {
    "text": "short for generalized language offline",
    "start": "655160",
    "end": "657480"
  },
  {
    "text": "workflow it basically stand ardize and",
    "start": "657480",
    "end": "660440"
  },
  {
    "text": "offers reusable components for uh data",
    "start": "660440",
    "end": "663240"
  },
  {
    "text": "preparation fine tuning bat inference",
    "start": "663240",
    "end": "665160"
  },
  {
    "text": "and evaluations and take the batch",
    "start": "665160",
    "end": "667519"
  },
  {
    "text": "inference as example here uh workflow",
    "start": "667519",
    "end": "670519"
  },
  {
    "text": "will be submitted to through the central",
    "start": "670519",
    "end": "672519"
  },
  {
    "text": "workflow API uh and then uh we use KU to",
    "start": "672519",
    "end": "676720"
  },
  {
    "text": "launch the fal re cluster that takes",
    "start": "676720",
    "end": "678880"
  },
  {
    "text": "care of the data Shing uh worker",
    "start": "678880",
    "end": "681079"
  },
  {
    "text": "provisioning and the data calization via",
    "start": "681079",
    "end": "684200"
  },
  {
    "text": "R data and within the yellow box user",
    "start": "684200",
    "end": "687079"
  },
  {
    "text": "can choose to different reactor based",
    "start": "687079",
    "end": "689440"
  },
  {
    "text": "the engines for the B inference",
    "start": "689440",
    "end": "691639"
  },
  {
    "text": "including vrm trtm or like a Ser remote",
    "start": "691639",
    "end": "695320"
  },
  {
    "text": "service call to like a vendor based apis",
    "start": "695320",
    "end": "698760"
  },
  {
    "text": "and this unified API made it's easy to",
    "start": "698760",
    "end": "701000"
  },
  {
    "text": "switch between inhouse developed model",
    "start": "701000",
    "end": "703480"
  },
  {
    "text": "and vendor based uh Clos The Source",
    "start": "703480",
    "end": "706560"
  },
  {
    "text": "models and building on the idea of easy",
    "start": "706560",
    "end": "708839"
  },
  {
    "text": "sharing the entire workflow can also be",
    "start": "708839",
    "end": "710839"
  },
  {
    "text": "serialized into a Tomo config for code",
    "start": "710839",
    "end": "713160"
  },
  {
    "text": "review and",
    "start": "713160",
    "end": "715440"
  },
  {
    "text": "publish uh before we proceed uh let me",
    "start": "715440",
    "end": "718680"
  },
  {
    "text": "recap on the changes we introduced to",
    "start": "718680",
    "end": "720320"
  },
  {
    "text": "address those challenges Lama Factory",
    "start": "720320",
    "end": "722639"
  },
  {
    "text": "and it's widely support for open source",
    "start": "722639",
    "end": "725360"
  },
  {
    "text": "model uh keep the community up to date",
    "start": "725360",
    "end": "728880"
  },
  {
    "text": "with the the open source world and the Q",
    "start": "728880",
    "end": "731600"
  },
  {
    "text": "based native integration with the kubay",
    "start": "731600",
    "end": "734360"
  },
  {
    "text": "uh can help us to maintain a high alloc",
    "start": "734360",
    "end": "736720"
  },
  {
    "text": "allocation rate for the entire GPU",
    "start": "736720",
    "end": "738720"
  },
  {
    "text": "clusters and uh lastly by integrating a",
    "start": "738720",
    "end": "742000"
  },
  {
    "text": "generalized LM workflow U so it makes it",
    "start": "742000",
    "end": "745519"
  },
  {
    "text": "easy for new users and different teams",
    "start": "745519",
    "end": "747839"
  },
  {
    "text": "to share their LM Rel work production",
    "start": "747839",
    "end": "751480"
  },
  {
    "text": "workflow in the next part I will hand",
    "start": "751480",
    "end": "754160"
  },
  {
    "text": "off to my colleague Mia and she will use",
    "start": "754160",
    "end": "756240"
  },
  {
    "text": "one fun user case to show um how this",
    "start": "756240",
    "end": "760480"
  },
  {
    "text": "changes help improve her day-to-day",
    "start": "760480",
    "end": "762680"
  },
  {
    "text": "development",
    "start": "762680",
    "end": "765079"
  },
  {
    "text": "experience thanks sh",
    "start": "765079",
    "end": "767800"
  },
  {
    "text": "um now uh I'm going you through a uh",
    "start": "767800",
    "end": "771680"
  },
  {
    "text": "concrete fine tuning examples of course",
    "start": "771680",
    "end": "774199"
  },
  {
    "text": "in Airbnb there are many fine tuning",
    "start": "774199",
    "end": "776440"
  },
  {
    "text": "cases uh the purpose here is we will go",
    "start": "776440",
    "end": "779399"
  },
  {
    "text": "through one fine tuning exactly uh",
    "start": "779399",
    "end": "782320"
  },
  {
    "text": "applications to tell us what is the life",
    "start": "782320",
    "end": "784880"
  },
  {
    "text": "cycle of the fine tunings how R cluster",
    "start": "784880",
    "end": "787399"
  },
  {
    "text": "and infa setup can help in this process",
    "start": "787399",
    "end": "790760"
  },
  {
    "text": "um the the specific case we're going to",
    "start": "790760",
    "end": "793040"
  },
  {
    "text": "go through is a uh Tex summarization",
    "start": "793040",
    "end": "795399"
  },
  {
    "text": "cases um my talk will be become three",
    "start": "795399",
    "end": "798600"
  },
  {
    "text": "parts is why we choose fine tunings uh",
    "start": "798600",
    "end": "801760"
  },
  {
    "text": "from product perspectives um how the",
    "start": "801760",
    "end": "804440"
  },
  {
    "text": "supervis the fine tuning performed uh on",
    "start": "804440",
    "end": "806959"
  },
  {
    "text": "the initial model stage and how how we l",
    "start": "806959",
    "end": "809800"
  },
  {
    "text": "reinforcement learnings to continue that",
    "start": "809800",
    "end": "812079"
  },
  {
    "text": "that smaller model to",
    "start": "812079",
    "end": "815240"
  },
  {
    "text": "grow um why fine tunings um of course",
    "start": "815920",
    "end": "819480"
  },
  {
    "text": "there are um a lot of reasons why we",
    "start": "819480",
    "end": "822120"
  },
  {
    "text": "choose fine tunings um this is a typical",
    "start": "822120",
    "end": "824519"
  },
  {
    "text": "cycle of why we choose the fine tuning",
    "start": "824519",
    "end": "827560"
  },
  {
    "text": "for example in our summarization cases",
    "start": "827560",
    "end": "830199"
  },
  {
    "text": "uh we will start let human to a slap",
    "start": "830199",
    "end": "833120"
  },
  {
    "text": "Baseline to say okay we have one group",
    "start": "833120",
    "end": "835920"
  },
  {
    "text": "of humans write a",
    "start": "835920",
    "end": "837639"
  },
  {
    "text": "summarizations another group of human to",
    "start": "837639",
    "end": "840759"
  },
  {
    "text": "evaluate the quality score of that",
    "start": "840759",
    "end": "844639"
  },
  {
    "text": "summarizations and also the time",
    "start": "844639",
    "end": "846639"
  },
  {
    "text": "spending on those summarizations this",
    "start": "846639",
    "end": "848839"
  },
  {
    "text": "becomes our uh product baselines in",
    "start": "848839",
    "end": "851800"
  },
  {
    "text": "terms of applications whether we can l a",
    "start": "851800",
    "end": "854800"
  },
  {
    "text": "large language model in any of the",
    "start": "854800",
    "end": "856759"
  },
  {
    "text": "applications that's kind of one of the",
    "start": "856759",
    "end": "859600"
  },
  {
    "text": "baselines once we have the baselines now",
    "start": "859600",
    "end": "862480"
  },
  {
    "text": "we are trying to see okay how mature the",
    "start": "862480",
    "end": "864959"
  },
  {
    "text": "large language model Community is how",
    "start": "864959",
    "end": "867839"
  },
  {
    "text": "the large what is the one of the best",
    "start": "867839",
    "end": "869720"
  },
  {
    "text": "models in the market then can achieve",
    "start": "869720",
    "end": "871920"
  },
  {
    "text": "the human level of the",
    "start": "871920",
    "end": "873839"
  },
  {
    "text": "performances this has been done through",
    "start": "873839",
    "end": "876240"
  },
  {
    "text": "uh examples here is a gbd4 of course",
    "start": "876240",
    "end": "879040"
  },
  {
    "text": "there's other uh up to- dat um open",
    "start": "879040",
    "end": "882079"
  },
  {
    "text": "source models that can give us some of",
    "start": "882079",
    "end": "884639"
  },
  {
    "text": "the baselines to say okay has a large",
    "start": "884639",
    "end": "887399"
  },
  {
    "text": "langage model be mature enough to",
    "start": "887399",
    "end": "889360"
  },
  {
    "text": "capture the human level of the",
    "start": "889360",
    "end": "890759"
  },
  {
    "text": "performance in terms of the Productions",
    "start": "890759",
    "end": "893519"
  },
  {
    "text": "what are the relative improvements from",
    "start": "893519",
    "end": "895399"
  },
  {
    "text": "the human baselines and what is the",
    "start": "895399",
    "end": "897199"
  },
  {
    "text": "latency can be achieved",
    "start": "897199",
    "end": "899600"
  },
  {
    "text": "after this stage the next stage comes",
    "start": "899600",
    "end": "901759"
  },
  {
    "text": "the question is can we even optimize",
    "start": "901759",
    "end": "904399"
  },
  {
    "text": "more through fine tuning process the",
    "start": "904399",
    "end": "907519"
  },
  {
    "text": "example here is um probably a while ago",
    "start": "907519",
    "end": "910120"
  },
  {
    "text": "we were able to even use a 11 billion T5",
    "start": "910120",
    "end": "913199"
  },
  {
    "text": "models through a series of the fine",
    "start": "913199",
    "end": "915759"
  },
  {
    "text": "tunings and improve a performance Bo",
    "start": "915759",
    "end": "919279"
  },
  {
    "text": "exceed a human level and gbd4 levels uh",
    "start": "919279",
    "end": "923440"
  },
  {
    "text": "of course with a better customized",
    "start": "923440",
    "end": "926440"
  },
  {
    "text": "latency um to summarize why we tunings",
    "start": "926440",
    "end": "929959"
  },
  {
    "text": "um first um we want to get a better",
    "start": "929959",
    "end": "933279"
  },
  {
    "text": "latency better management cost and we",
    "start": "933279",
    "end": "936639"
  },
  {
    "text": "believe the performance can grow with",
    "start": "936639",
    "end": "939279"
  },
  {
    "text": "time goes",
    "start": "939279",
    "end": "941800"
  },
  {
    "text": "by um this is a very simple process to",
    "start": "941800",
    "end": "945120"
  },
  {
    "text": "see how we illustrate the supervisor fun",
    "start": "945120",
    "end": "947519"
  },
  {
    "text": "in the initial stage uh in this stage",
    "start": "947519",
    "end": "950560"
  },
  {
    "text": "the main demand from the infa",
    "start": "950560",
    "end": "952639"
  },
  {
    "text": "perspective is experimentations I think",
    "start": "952639",
    "end": "956399"
  },
  {
    "text": "one of the challenge shall we mention is",
    "start": "956399",
    "end": "958639"
  },
  {
    "text": "there there's a ton of the open source",
    "start": "958639",
    "end": "960279"
  },
  {
    "text": "model communities that came out every",
    "start": "960279",
    "end": "962720"
  },
  {
    "text": "week There's new models that we want to",
    "start": "962720",
    "end": "965199"
  },
  {
    "text": "do",
    "start": "965199",
    "end": "966319"
  },
  {
    "text": "experimentations how we uh have that so",
    "start": "966319",
    "end": "968839"
  },
  {
    "text": "we were able to leverage a preemptive",
    "start": "968839",
    "end": "971240"
  },
  {
    "text": "cues those are usually ad hoc",
    "start": "971240",
    "end": "973800"
  },
  {
    "text": "experiments sometimes it's Rong very",
    "start": "973800",
    "end": "975839"
  },
  {
    "text": "long sometimes very short experience but",
    "start": "975839",
    "end": "978959"
  },
  {
    "text": "the goal is here now we have a um human",
    "start": "978959",
    "end": "982399"
  },
  {
    "text": "R examples with some of the high quality",
    "start": "982399",
    "end": "985240"
  },
  {
    "text": "AI assistant labeling um then we can",
    "start": "985240",
    "end": "988120"
  },
  {
    "text": "achieve a fine tuning supervisor fine",
    "start": "988120",
    "end": "990120"
  },
  {
    "text": "tuning process against U mostly widely",
    "start": "990120",
    "end": "993399"
  },
  {
    "text": "available open- Source Community",
    "start": "993399",
    "end": "996839"
  },
  {
    "text": "models after we have a initial model",
    "start": "996839",
    "end": "1000240"
  },
  {
    "text": "performances um this is just the start",
    "start": "1000240",
    "end": "1003279"
  },
  {
    "text": "right so we want the fine tunity one of",
    "start": "1003279",
    "end": "1005199"
  },
  {
    "text": "the another major benefits of fine",
    "start": "1005199",
    "end": "1007160"
  },
  {
    "text": "tuning is we hope the model to grow uh",
    "start": "1007160",
    "end": "1011199"
  },
  {
    "text": "along with the application",
    "start": "1011199",
    "end": "1013360"
  },
  {
    "text": "development um so now I'm going to",
    "start": "1013360",
    "end": "1015800"
  },
  {
    "text": "through go through how we um have the",
    "start": "1015800",
    "end": "1018920"
  },
  {
    "text": "reinforcement learning in place to let",
    "start": "1018920",
    "end": "1021639"
  },
  {
    "text": "this smaller model continue to improve",
    "start": "1021639",
    "end": "1023880"
  },
  {
    "text": "its",
    "start": "1023880",
    "end": "1025079"
  },
  {
    "text": "performance um as you can see and the",
    "start": "1025079",
    "end": "1027720"
  },
  {
    "text": "first step we have here is to collect",
    "start": "1027720",
    "end": "1030959"
  },
  {
    "text": "human feedback as the model integrate",
    "start": "1030959",
    "end": "1033798"
  },
  {
    "text": "with the applications we often get some",
    "start": "1033799",
    "end": "1036520"
  },
  {
    "text": "feedbacks from humans uh some simple",
    "start": "1036520",
    "end": "1039640"
  },
  {
    "text": "feedback like some up some down",
    "start": "1039640",
    "end": "1041720"
  },
  {
    "text": "sometimes we get criticize the feedback",
    "start": "1041720",
    "end": "1043798"
  },
  {
    "text": "from humans about",
    "start": "1043799",
    "end": "1047279"
  },
  {
    "text": "models um this techniques on how we",
    "start": "1047400",
    "end": "1050160"
  },
  {
    "text": "prare the data from just the sum up sum",
    "start": "1050160",
    "end": "1053120"
  },
  {
    "text": "down to a pairwise of the training datas",
    "start": "1053120",
    "end": "1055960"
  },
  {
    "text": "right some of the technique we were",
    "start": "1055960",
    "end": "1058039"
  },
  {
    "text": "using like chain of density this is when",
    "start": "1058039",
    "end": "1061080"
  },
  {
    "text": "human just like some up some down but we",
    "start": "1061080",
    "end": "1063600"
  },
  {
    "text": "have some guidelines to say what is a",
    "start": "1063600",
    "end": "1065400"
  },
  {
    "text": "good summarization going to be what is",
    "start": "1065400",
    "end": "1067799"
  },
  {
    "text": "the key um performance of that",
    "start": "1067799",
    "end": "1070320"
  },
  {
    "text": "summarization going to be so through",
    "start": "1070320",
    "end": "1072480"
  },
  {
    "text": "that iterations uh pomping Technique we",
    "start": "1072480",
    "end": "1075360"
  },
  {
    "text": "can collect some of the pawise um",
    "start": "1075360",
    "end": "1077799"
  },
  {
    "text": "training datas",
    "start": "1077799",
    "end": "1079400"
  },
  {
    "text": "uh through uh ask model to reite it for",
    "start": "1079400",
    "end": "1082120"
  },
  {
    "text": "x times according to our",
    "start": "1082120",
    "end": "1085520"
  },
  {
    "text": "guidelines um this is another uh",
    "start": "1085520",
    "end": "1088520"
  },
  {
    "text": "interesting Pro uh techniques used in",
    "start": "1088520",
    "end": "1090960"
  },
  {
    "text": "this particular example which of course",
    "start": "1090960",
    "end": "1093600"
  },
  {
    "text": "is um get from entropic um AI so when uh",
    "start": "1093600",
    "end": "1098880"
  },
  {
    "text": "when we integrate with the product we",
    "start": "1098880",
    "end": "1100640"
  },
  {
    "text": "often get Negative feedbacks from humans",
    "start": "1100640",
    "end": "1102960"
  },
  {
    "text": "say okay this part isn't summarized well",
    "start": "1102960",
    "end": "1105720"
  },
  {
    "text": "this part needs Improvement so",
    "start": "1105720",
    "end": "1107799"
  },
  {
    "text": "continuous critique feedbacks we can",
    "start": "1107799",
    "end": "1109840"
  },
  {
    "text": "also collect uh PW preference through",
    "start": "1109840",
    "end": "1112240"
  },
  {
    "text": "human uh through that alignment",
    "start": "1112240",
    "end": "1115120"
  },
  {
    "text": "process now passing to uh getting the",
    "start": "1115120",
    "end": "1118200"
  },
  {
    "text": "data having the human Fe feedback in the",
    "start": "1118200",
    "end": "1121400"
  },
  {
    "text": "uh loop as the first steps the next step",
    "start": "1121400",
    "end": "1124400"
  },
  {
    "text": "is how we do the model",
    "start": "1124400",
    "end": "1126240"
  },
  {
    "text": "alignments um so in this example we have",
    "start": "1126240",
    "end": "1128919"
  },
  {
    "text": "been done model alignments uh both",
    "start": "1128919",
    "end": "1131520"
  },
  {
    "text": "through um human Loop uh preference data",
    "start": "1131520",
    "end": "1135200"
  },
  {
    "text": "set or through the virtual judge we see",
    "start": "1135200",
    "end": "1137880"
  },
  {
    "text": "both of the performance has been gained",
    "start": "1137880",
    "end": "1139840"
  },
  {
    "text": "a lot uh from the initial model",
    "start": "1139840",
    "end": "1144760"
  },
  {
    "text": "baselines um so this is a sample we use",
    "start": "1146039",
    "end": "1149400"
  },
  {
    "text": "of course with the open source I think",
    "start": "1149400",
    "end": "1151320"
  },
  {
    "text": "sh mentioned we were uh able to align",
    "start": "1151320",
    "end": "1154440"
  },
  {
    "text": "with different type of the alignment",
    "start": "1154440",
    "end": "1156720"
  },
  {
    "text": "strategy not only to U DP po including",
    "start": "1156720",
    "end": "1161200"
  },
  {
    "text": "like a kto IPO orpo simple po um so",
    "start": "1161200",
    "end": "1164960"
  },
  {
    "text": "there's a lot of things we try and in",
    "start": "1164960",
    "end": "1167280"
  },
  {
    "text": "this particular cases we try the DP uh",
    "start": "1167280",
    "end": "1170320"
  },
  {
    "text": "which we particular feel it it works",
    "start": "1170320",
    "end": "1172520"
  },
  {
    "text": "pretty well for summarization tasks both",
    "start": "1172520",
    "end": "1175480"
  },
  {
    "text": "from uh engineering resource efficiency",
    "start": "1175480",
    "end": "1179840"
  },
  {
    "text": "and um also from the Computing",
    "start": "1179840",
    "end": "1182559"
  },
  {
    "text": "efficiency uh also in the performance",
    "start": "1182559",
    "end": "1185039"
  },
  {
    "text": "wise we find is suceed um uh p as well",
    "start": "1185039",
    "end": "1189440"
  },
  {
    "text": "but in other cases Ami are subject to",
    "start": "1189440",
    "end": "1192240"
  },
  {
    "text": "the user",
    "start": "1192240",
    "end": "1194720"
  },
  {
    "text": "cases um after F tuning process through",
    "start": "1194880",
    "end": "1197799"
  },
  {
    "text": "this framework then we will have the",
    "start": "1197799",
    "end": "1200039"
  },
  {
    "text": "last piece which uh sh we mention about",
    "start": "1200039",
    "end": "1202320"
  },
  {
    "text": "is how we do batch inferences and how we",
    "start": "1202320",
    "end": "1205240"
  },
  {
    "text": "make that uh model Circle back to the um",
    "start": "1205240",
    "end": "1209360"
  },
  {
    "text": "applications so the bash inferences we",
    "start": "1209360",
    "end": "1211960"
  },
  {
    "text": "have here is a internal framework we",
    "start": "1211960",
    "end": "1214200"
  },
  {
    "text": "build which both integrate uh with a um",
    "start": "1214200",
    "end": "1218120"
  },
  {
    "text": "Cuma in the loop uh for the evaluation",
    "start": "1218120",
    "end": "1220919"
  },
  {
    "text": "and also U virtual judge uh systems so a",
    "start": "1220919",
    "end": "1225360"
  },
  {
    "text": "lot of generative AIS there is no ground",
    "start": "1225360",
    "end": "1227679"
  },
  {
    "text": "shoes tied to it one of the challenges",
    "start": "1227679",
    "end": "1230280"
  },
  {
    "text": "how we make the evaluation uh more sound",
    "start": "1230280",
    "end": "1233679"
  },
  {
    "text": "whenever we release the next version of",
    "start": "1233679",
    "end": "1235559"
  },
  {
    "text": "the model um combining with human uh",
    "start": "1235559",
    "end": "1239360"
  },
  {
    "text": "align with uh a list of the virtual",
    "start": "1239360",
    "end": "1241600"
  },
  {
    "text": "judges help us do uh a stage based the",
    "start": "1241600",
    "end": "1244880"
  },
  {
    "text": "evaluations and making sure uh the mo",
    "start": "1244880",
    "end": "1247720"
  },
  {
    "text": "model iteration release um capture",
    "start": "1247720",
    "end": "1252559"
  },
  {
    "text": "those um this is a uh enti cycle uh for",
    "start": "1252760",
    "end": "1256960"
  },
  {
    "text": "this specific uh summarization cases uh",
    "start": "1256960",
    "end": "1260360"
  },
  {
    "text": "we once the initial model gets",
    "start": "1260360",
    "end": "1262320"
  },
  {
    "text": "fine-tuned uh we are not stopping it we",
    "start": "1262320",
    "end": "1265120"
  },
  {
    "text": "start to collect the human feedback from",
    "start": "1265120",
    "end": "1267799"
  },
  {
    "text": "starting from some up some down leverage",
    "start": "1267799",
    "end": "1270080"
  },
  {
    "text": "a lot of uh prompting technique and uh",
    "start": "1270080",
    "end": "1272720"
  },
  {
    "text": "data alignment strategies and uh to",
    "start": "1272720",
    "end": "1275400"
  },
  {
    "text": "continue to improve the",
    "start": "1275400",
    "end": "1278440"
  },
  {
    "text": "models so um this is uh how these",
    "start": "1279360",
    "end": "1282960"
  },
  {
    "text": "examples might map to the ray train uh",
    "start": "1282960",
    "end": "1286240"
  },
  {
    "text": "first all we were able to uh get a lot",
    "start": "1286240",
    "end": "1290159"
  },
  {
    "text": "of experiment done in initial model",
    "start": "1290159",
    "end": "1292520"
  },
  {
    "text": "stage um uh to quantify 100 and of the",
    "start": "1292520",
    "end": "1296240"
  },
  {
    "text": "experiments can be done uh in a few days",
    "start": "1296240",
    "end": "1298880"
  },
  {
    "text": "of the time frame and uh through the",
    "start": "1298880",
    "end": "1302600"
  },
  {
    "text": "initial model training we were able to",
    "start": "1302600",
    "end": "1304760"
  },
  {
    "text": "achieve a relative smaller data set with",
    "start": "1304760",
    "end": "1307600"
  },
  {
    "text": "a uh comparable",
    "start": "1307600",
    "end": "1310159"
  },
  {
    "text": "performance uh last but not least um The",
    "start": "1310159",
    "end": "1313720"
  },
  {
    "text": "Grow uh infrastructures did help us to",
    "start": "1313720",
    "end": "1317679"
  },
  {
    "text": "schedule the job",
    "start": "1317679",
    "end": "1319400"
  },
  {
    "text": "uh to have the model refin tuned and",
    "start": "1319400",
    "end": "1322799"
  },
  {
    "text": "realigned with the human preference on a",
    "start": "1322799",
    "end": "1325120"
  },
  {
    "text": "periodic basis this significantly",
    "start": "1325120",
    "end": "1328000"
  },
  {
    "text": "reduced uh engineering effort in terms",
    "start": "1328000",
    "end": "1330919"
  },
  {
    "text": "of maintaining those models and keep",
    "start": "1330919",
    "end": "1333440"
  },
  {
    "text": "monitor those",
    "start": "1333440",
    "end": "1335720"
  },
  {
    "text": "models now I'm going to pass to sh to",
    "start": "1335720",
    "end": "1339679"
  },
  {
    "text": "talk about key and",
    "start": "1339679",
    "end": "1342440"
  },
  {
    "text": "takeaways uh thank you Mia uh yeah just",
    "start": "1342440",
    "end": "1345640"
  },
  {
    "text": "few highlights to conclude today's talk",
    "start": "1345640",
    "end": "1348039"
  },
  {
    "text": "the first one is around R and it's like",
    "start": "1348039",
    "end": "1351039"
  },
  {
    "text": "open source ecosystem so it's not about",
    "start": "1351039",
    "end": "1353039"
  },
  {
    "text": "only R train and R data we're seeing",
    "start": "1353039",
    "end": "1355400"
  },
  {
    "text": "like a growing like infal like related",
    "start": "1355400",
    "end": "1359279"
  },
  {
    "text": "projects around the r for example q and",
    "start": "1359279",
    "end": "1361360"
  },
  {
    "text": "the unicor those are built for you to",
    "start": "1361360",
    "end": "1364039"
  },
  {
    "text": "easily schedule Ray workloads and all",
    "start": "1364039",
    "end": "1366840"
  },
  {
    "text": "those open source Frameworks together",
    "start": "1366840",
    "end": "1368600"
  },
  {
    "text": "laid a solid foundation for us to",
    "start": "1368600",
    "end": "1370799"
  },
  {
    "text": "continue work on Ray based uh computer",
    "start": "1370799",
    "end": "1373360"
  },
  {
    "text": "layer and the second part is specific",
    "start": "1373360",
    "end": "1376039"
  },
  {
    "text": "around the fine tuning uh we're seeing",
    "start": "1376039",
    "end": "1377679"
  },
  {
    "text": "that in how fine tune a smaller model",
    "start": "1377679",
    "end": "1380400"
  },
  {
    "text": "actually out to perform the model like",
    "start": "1380400",
    "end": "1382679"
  },
  {
    "text": "larger vendor based close Source models",
    "start": "1382679",
    "end": "1385480"
  },
  {
    "text": "in specific business use cases and the",
    "start": "1385480",
    "end": "1388960"
  },
  {
    "text": "third one is uh uh we think Al fine",
    "start": "1388960",
    "end": "1391320"
  },
  {
    "text": "tuning uh and Alignment is a continuing",
    "start": "1391320",
    "end": "1393640"
  },
  {
    "text": "the process and it will take like",
    "start": "1393640",
    "end": "1395520"
  },
  {
    "text": "iterative efforts to make the system",
    "start": "1395520",
    "end": "1397720"
  },
  {
    "text": "more performant and uh looking ahead so",
    "start": "1397720",
    "end": "1401080"
  },
  {
    "text": "what we share today is just a small",
    "start": "1401080",
    "end": "1403240"
  },
  {
    "text": "model uh we started last year and",
    "start": "1403240",
    "end": "1406200"
  },
  {
    "text": "working on more like complicated the use",
    "start": "1406200",
    "end": "1409360"
  },
  {
    "text": "cases today with like a rug based system",
    "start": "1409360",
    "end": "1412559"
  },
  {
    "text": "with multiagents and multimodality",
    "start": "1412559",
    "end": "1414880"
  },
  {
    "text": "models as well hopefully we can share in",
    "start": "1414880",
    "end": "1416960"
  },
  {
    "text": "the future uh in the maybe in next three",
    "start": "1416960",
    "end": "1419240"
  },
  {
    "text": "Summit as well thank",
    "start": "1419240",
    "end": "1422320"
  },
  {
    "text": "you all right thank you sh Mia I think",
    "start": "1423480",
    "end": "1426159"
  },
  {
    "text": "we have time for a few questions um so",
    "start": "1426159",
    "end": "1428880"
  },
  {
    "text": "if you raise your hands I can pass the",
    "start": "1428880",
    "end": "1430320"
  },
  {
    "text": "mic to",
    "start": "1430320",
    "end": "1432720"
  },
  {
    "text": "you right",
    "start": "1434320",
    "end": "1438320"
  },
  {
    "text": "how difficult was it to move away from",
    "start": "1439880",
    "end": "1442400"
  },
  {
    "text": "spark to more um Ray based system uh are",
    "start": "1442400",
    "end": "1448159"
  },
  {
    "text": "there still some workflows which you",
    "start": "1448159",
    "end": "1451559"
  },
  {
    "text": "feel like are stuck over there yeah",
    "start": "1451559",
    "end": "1454039"
  },
  {
    "text": "that's a good question uh so for spark",
    "start": "1454039",
    "end": "1456279"
  },
  {
    "text": "we primar use for two uh use cases the",
    "start": "1456279",
    "end": "1459240"
  },
  {
    "text": "first one is access to data warehouse uh",
    "start": "1459240",
    "end": "1462080"
  },
  {
    "text": "which I think I believe today is still",
    "start": "1462080",
    "end": "1463799"
  },
  {
    "text": "the most efficient way to to do uh",
    "start": "1463799",
    "end": "1466799"
  },
  {
    "text": "because we don't have a good story from",
    "start": "1466799",
    "end": "1469000"
  },
  {
    "text": "RE cluster to access like Hive tables",
    "start": "1469000",
    "end": "1472000"
  },
  {
    "text": "and uh on the other side the other usage",
    "start": "1472000",
    "end": "1474640"
  },
  {
    "text": "for Spar is batch inference uh you can",
    "start": "1474640",
    "end": "1477000"
  },
  {
    "text": "think that each executor will load the",
    "start": "1477000",
    "end": "1478640"
  },
  {
    "text": "model uh we have a python kernel running",
    "start": "1478640",
    "end": "1481000"
  },
  {
    "text": "in Python Pyar executor for the",
    "start": "1481000",
    "end": "1483640"
  },
  {
    "text": "inference and all those user cases will",
    "start": "1483640",
    "end": "1485640"
  },
  {
    "text": "be replaced by R data and uh mostly",
    "start": "1485640",
    "end": "1489080"
  },
  {
    "text": "mostly down on our side",
    "start": "1489080",
    "end": "1493559"
  },
  {
    "text": "yeah yeah hi so uh you had a slide for",
    "start": "1494840",
    "end": "1498440"
  },
  {
    "text": "right here uh you had a slide for after",
    "start": "1498440",
    "end": "1501120"
  },
  {
    "text": "you started using Ray and I still saw",
    "start": "1501120",
    "end": "1502960"
  },
  {
    "text": "you had horward in there so why can't",
    "start": "1502960",
    "end": "1505919"
  },
  {
    "text": "you use like raise distributed training",
    "start": "1505919",
    "end": "1508240"
  },
  {
    "text": "abilities instead of using horward yeah",
    "start": "1508240",
    "end": "1511159"
  },
  {
    "text": "that's a another good question so uh we",
    "start": "1511159",
    "end": "1514480"
  },
  {
    "text": "run hard with the coup flow prior to re",
    "start": "1514480",
    "end": "1517000"
  },
  {
    "text": "integration we use basic the MPR",
    "start": "1517000",
    "end": "1519480"
  },
  {
    "text": "operator to orchestrate group parts and",
    "start": "1519480",
    "end": "1522640"
  },
  {
    "text": "the with the ray we can basically reuse",
    "start": "1522640",
    "end": "1525480"
  },
  {
    "text": "the hard water trainer to replace that",
    "start": "1525480",
    "end": "1527440"
  },
  {
    "text": "functionality uh that's doable we we're",
    "start": "1527440",
    "end": "1530120"
  },
  {
    "text": "not seeing any like downsides for doing",
    "start": "1530120",
    "end": "1532840"
  },
  {
    "text": "that uh the main blocker right now is",
    "start": "1532840",
    "end": "1535600"
  },
  {
    "text": "the we have this data pipeline",
    "start": "1535600",
    "end": "1537480"
  },
  {
    "text": "customized for TF records loading uh but",
    "start": "1537480",
    "end": "1540600"
  },
  {
    "text": "we're seeing yeah some support drawback",
    "start": "1540600",
    "end": "1544200"
  },
  {
    "text": "on the r data side if uh you're familiar",
    "start": "1544200",
    "end": "1547039"
  },
  {
    "text": "with r data with TF R yeah",
    "start": "1547039",
    "end": "1551679"
  },
  {
    "text": "any more",
    "start": "1560279",
    "end": "1562799"
  },
  {
    "text": "questions all right thanks again sh we",
    "start": "1564600",
    "end": "1566840"
  },
  {
    "text": "and Mia and thank you everyone for",
    "start": "1566840",
    "end": "1568440"
  },
  {
    "text": "coming enjoy the rest of your race",
    "start": "1568440",
    "end": "1570159"
  },
  {
    "text": "Summit",
    "start": "1570159",
    "end": "1573159"
  }
]
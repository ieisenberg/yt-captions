[
  {
    "text": "hello everyone uh my name is sorab I'm",
    "start": "2840",
    "end": "5319"
  },
  {
    "text": "the tech lead for the machine learning",
    "start": "5319",
    "end": "6799"
  },
  {
    "text": "platform team at Pinterest and uh today",
    "start": "6799",
    "end": "9160"
  },
  {
    "text": "with me is uh also presenting uh Raymond",
    "start": "9160",
    "end": "12240"
  },
  {
    "text": "who is a senior engineer on the ml",
    "start": "12240",
    "end": "13960"
  },
  {
    "text": "training team and uh together we are",
    "start": "13960",
    "end": "16278"
  },
  {
    "text": "here to present uh some of our recent",
    "start": "16279",
    "end": "18240"
  },
  {
    "text": "work on distributed data loading with",
    "start": "18240",
    "end": "20560"
  },
  {
    "text": "Ray uh for recommender model",
    "start": "20560",
    "end": "22880"
  },
  {
    "text": "training so just to give a little bit of",
    "start": "22880",
    "end": "24960"
  },
  {
    "text": "context this is what the primary",
    "start": "24960",
    "end": "27119"
  },
  {
    "text": "Pinterest product surfaces look like we",
    "start": "27119",
    "end": "29400"
  },
  {
    "text": "basically have home feed where we",
    "start": "29400",
    "end": "31160"
  },
  {
    "text": "recommend content to you based on your",
    "start": "31160",
    "end": "32920"
  },
  {
    "text": "interests and uh past engagements we",
    "start": "32920",
    "end": "35800"
  },
  {
    "text": "have related pins where we recommend",
    "start": "35800",
    "end": "38480"
  },
  {
    "text": "content similar to you based on the",
    "start": "38480",
    "end": "40239"
  },
  {
    "text": "content that you're currently",
    "start": "40239",
    "end": "41239"
  },
  {
    "text": "interacting with then we also have the",
    "start": "41239",
    "end": "43960"
  },
  {
    "text": "traditional shopping surfaces where you",
    "start": "43960",
    "end": "46079"
  },
  {
    "text": "can uh click on different objects that",
    "start": "46079",
    "end": "47760"
  },
  {
    "text": "are in the images and you can shop them",
    "start": "47760",
    "end": "50079"
  },
  {
    "text": "and then we also have the traditional",
    "start": "50079",
    "end": "51640"
  },
  {
    "text": "text based search surfaces and the",
    "start": "51640",
    "end": "53960"
  },
  {
    "text": "reason why I'm mentioning all of this is",
    "start": "53960",
    "end": "56239"
  },
  {
    "text": "because this is all powered by hundreds",
    "start": "56239",
    "end": "58120"
  },
  {
    "text": "of different machine learning",
    "start": "58120",
    "end": "59160"
  },
  {
    "text": "applications that is running on",
    "start": "59160",
    "end": "60800"
  },
  {
    "text": "thousands of gpus in real time on web",
    "start": "60800",
    "end": "63320"
  },
  {
    "text": "scale data so all of this is actually a",
    "start": "63320",
    "end": "65439"
  },
  {
    "text": "very massive scale machine learning",
    "start": "65439",
    "end": "67479"
  },
  {
    "text": "problem and today amongst all the",
    "start": "67479",
    "end": "69759"
  },
  {
    "text": "different ml applications that you see",
    "start": "69759",
    "end": "71320"
  },
  {
    "text": "here including recommendation systems",
    "start": "71320",
    "end": "73119"
  },
  {
    "text": "graph machine learning and so on we'll",
    "start": "73119",
    "end": "75040"
  },
  {
    "text": "be particularly narrowing down and",
    "start": "75040",
    "end": "76479"
  },
  {
    "text": "focusing on the recommender model",
    "start": "76479",
    "end": "78159"
  },
  {
    "text": "training and the reason for that is like",
    "start": "78159",
    "end": "81759"
  },
  {
    "text": "in all the uh gen discussions that are",
    "start": "81759",
    "end": "84079"
  },
  {
    "text": "happening in the industry recommender",
    "start": "84079",
    "end": "85479"
  },
  {
    "text": "models are still the bread and butter",
    "start": "85479",
    "end": "87320"
  },
  {
    "text": "for many different companies in the",
    "start": "87320",
    "end": "88799"
  },
  {
    "text": "space and they they underscore some of",
    "start": "88799",
    "end": "91360"
  },
  {
    "text": "our critical product surfaces such as",
    "start": "91360",
    "end": "93000"
  },
  {
    "text": "home feed and related pins and they're",
    "start": "93000",
    "end": "94920"
  },
  {
    "text": "also the key drivers of our",
    "start": "94920",
    "end": "96119"
  },
  {
    "text": "performance-based ads businesses and so",
    "start": "96119",
    "end": "98799"
  },
  {
    "text": "any improvements in this recommendation",
    "start": "98799",
    "end": "100439"
  },
  {
    "text": "model training can directly impact our",
    "start": "100439",
    "end": "102680"
  },
  {
    "text": "product and just for anybody who is not",
    "start": "102680",
    "end": "105200"
  },
  {
    "text": "familiar uh to define the problem",
    "start": "105200",
    "end": "107439"
  },
  {
    "text": "formulation you can think of the the the",
    "start": "107439",
    "end": "110479"
  },
  {
    "text": "main problem that we are trying to solve",
    "start": "110479",
    "end": "111840"
  },
  {
    "text": "is what is the probability that the user",
    "start": "111840",
    "end": "114000"
  },
  {
    "text": "will perform an action given some",
    "start": "114000",
    "end": "115960"
  },
  {
    "text": "context about the user uh the item that",
    "start": "115960",
    "end": "118320"
  },
  {
    "text": "we are interacting with and some other",
    "start": "118320",
    "end": "121000"
  },
  {
    "text": "features based on the description I",
    "start": "121000",
    "end": "123079"
  },
  {
    "text": "think you can imagine that most of the",
    "start": "123079",
    "end": "124479"
  },
  {
    "text": "training data sets are some form of",
    "start": "124479",
    "end": "126000"
  },
  {
    "text": "Engagement logs so they are highly",
    "start": "126000",
    "end": "127360"
  },
  {
    "text": "structured data and they are typically",
    "start": "127360",
    "end": "129080"
  },
  {
    "text": "in a tabular format and most of the",
    "start": "129080",
    "end": "131239"
  },
  {
    "text": "inference happens in near like in real",
    "start": "131239",
    "end": "133280"
  },
  {
    "text": "time at very low",
    "start": "133280",
    "end": "135519"
  },
  {
    "text": "latencies so we'll start narrowing down",
    "start": "135519",
    "end": "138000"
  },
  {
    "text": "a little bit and I'll first speak about",
    "start": "138000",
    "end": "139640"
  },
  {
    "text": "the training setup itself so this is",
    "start": "139640",
    "end": "141480"
  },
  {
    "text": "what our typical training setup looks",
    "start": "141480",
    "end": "143319"
  },
  {
    "text": "like we have a shared UniFi training",
    "start": "143319",
    "end": "145599"
  },
  {
    "text": "compute platform which we refer to as",
    "start": "145599",
    "end": "147680"
  },
  {
    "text": "TCP as you can see in the diagram both",
    "start": "147680",
    "end": "150280"
  },
  {
    "text": "the User submitted jobs and our",
    "start": "150280",
    "end": "151959"
  },
  {
    "text": "scheduled workflow jobs all are backed",
    "start": "151959",
    "end": "154400"
  },
  {
    "text": "by the same shared job submission API",
    "start": "154400",
    "end": "157239"
  },
  {
    "text": "and all of our workloads are directly",
    "start": "157239",
    "end": "158840"
  },
  {
    "text": "orchestrated on top of kubernetes which",
    "start": "158840",
    "end": "160800"
  },
  {
    "text": "is running in AWS cloud and we have a",
    "start": "160800",
    "end": "162959"
  },
  {
    "text": "variety of different gbo types that we",
    "start": "162959",
    "end": "165000"
  },
  {
    "text": "use the framework of our choice is",
    "start": "165000",
    "end": "167319"
  },
  {
    "text": "pytorch we are predominantly on pytorch",
    "start": "167319",
    "end": "169200"
  },
  {
    "text": "now and we use a thin wrapper around",
    "start": "169200",
    "end": "170879"
  },
  {
    "text": "pytorch which we refer to as mln and as",
    "start": "170879",
    "end": "173920"
  },
  {
    "text": "you may have already guessed most of our",
    "start": "173920",
    "end": "175319"
  },
  {
    "text": "training data sets are tabular ml so we",
    "start": "175319",
    "end": "177159"
  },
  {
    "text": "use Apache par heavily and they are",
    "start": "177159",
    "end": "179159"
  },
  {
    "text": "backed by High and Iceberg",
    "start": "179159",
    "end": "181120"
  },
  {
    "text": "both um so just to give you a context of",
    "start": "181120",
    "end": "184480"
  },
  {
    "text": "the scale of the jobs that we run",
    "start": "184480",
    "end": "186159"
  },
  {
    "text": "typical training jobs that we have use",
    "start": "186159",
    "end": "188400"
  },
  {
    "text": "anywhere from like 8 to 16 a100 or h100",
    "start": "188400",
    "end": "191200"
  },
  {
    "text": "gpus they can run anywhere from 20 hours",
    "start": "191200",
    "end": "193920"
  },
  {
    "text": "to 300 hours depending on the use case",
    "start": "193920",
    "end": "196879"
  },
  {
    "text": "but the most interesting part here is",
    "start": "196879",
    "end": "198440"
  },
  {
    "text": "the scale of the data sets that we use a",
    "start": "198440",
    "end": "200799"
  },
  {
    "text": "single training job can consume hundreds",
    "start": "200799",
    "end": "202599"
  },
  {
    "text": "of terabytes of data that spans across",
    "start": "202599",
    "end": "205440"
  },
  {
    "text": "like 100,000 or more files so this is",
    "start": "205440",
    "end": "207360"
  },
  {
    "text": "actually a very large data set",
    "start": "207360",
    "end": "210319"
  },
  {
    "text": "and the whole Target of the talk today",
    "start": "210319",
    "end": "212360"
  },
  {
    "text": "is going to be the GPU training pipeline",
    "start": "212360",
    "end": "215000"
  },
  {
    "text": "um and what I mean by the GPU training",
    "start": "215000",
    "end": "217159"
  },
  {
    "text": "pipeline is if we imagine the whole",
    "start": "217159",
    "end": "219319"
  },
  {
    "text": "training setup the goal is to stream",
    "start": "219319",
    "end": "221680"
  },
  {
    "text": "mini batches of training examples as",
    "start": "221680",
    "end": "224159"
  },
  {
    "text": "fast as we can throughout this Pipeline",
    "start": "224159",
    "end": "225879"
  },
  {
    "text": "and get them to the model and the the",
    "start": "225879",
    "end": "228799"
  },
  {
    "text": "idea behind this optimization is we want",
    "start": "228799",
    "end": "230519"
  },
  {
    "text": "to drive up the training throughput in",
    "start": "230519",
    "end": "232319"
  },
  {
    "text": "terms of the number of examples per",
    "start": "232319",
    "end": "233799"
  },
  {
    "text": "second that we process which naturally",
    "start": "233799",
    "end": "235840"
  },
  {
    "text": "drives down the job runtime and the job",
    "start": "235840",
    "end": "238079"
  },
  {
    "text": "cost what you can see in this diagram is",
    "start": "238079",
    "end": "240640"
  },
  {
    "text": "there is a section that I've highlighted",
    "start": "240640",
    "end": "242599"
  },
  {
    "text": "in dark gray that represents the data",
    "start": "242599",
    "end": "244720"
  },
  {
    "text": "loader or the plumbing code that gets",
    "start": "244720",
    "end": "246680"
  },
  {
    "text": "the data to the model and you can see",
    "start": "246680",
    "end": "248640"
  },
  {
    "text": "that the bottom right there are only two",
    "start": "248640",
    "end": "250400"
  },
  {
    "text": "steps that the model actually represents",
    "start": "250400",
    "end": "252079"
  },
  {
    "text": "which is the forward and the backward",
    "start": "252079",
    "end": "253680"
  },
  {
    "text": "and so it's a very small piece of this",
    "start": "253680",
    "end": "255200"
  },
  {
    "text": "whole execution",
    "start": "255200",
    "end": "257479"
  },
  {
    "text": "pipeline within the data loader itself",
    "start": "257479",
    "end": "260160"
  },
  {
    "text": "you can see that I've highlighted",
    "start": "260160",
    "end": "261840"
  },
  {
    "text": "different components and different",
    "start": "261840",
    "end": "263040"
  },
  {
    "text": "colors the yellow parts are typically",
    "start": "263040",
    "end": "265320"
  },
  {
    "text": "the CPU pre-processing Parts the green",
    "start": "265320",
    "end": "267680"
  },
  {
    "text": "parts are memory operations and the",
    "start": "267680",
    "end": "269759"
  },
  {
    "text": "purple parts are what is actually",
    "start": "269759",
    "end": "270960"
  },
  {
    "text": "executing on the GPU so if you look at",
    "start": "270960",
    "end": "274240"
  },
  {
    "text": "the typical pipeline the way it looks",
    "start": "274240",
    "end": "275919"
  },
  {
    "text": "like is you perform some kind of a file",
    "start": "275919",
    "end": "277560"
  },
  {
    "text": "IO using read from park or some other",
    "start": "277560",
    "end": "280039"
  },
  {
    "text": "object store that you have you have one",
    "start": "280039",
    "end": "282160"
  },
  {
    "text": "or more user defined functions that you",
    "start": "282160",
    "end": "283960"
  },
  {
    "text": "execute after that so these can be any",
    "start": "283960",
    "end": "286240"
  },
  {
    "text": "python based conversion uh functions",
    "start": "286240",
    "end": "288720"
  },
  {
    "text": "that you have and then you have a tensor",
    "start": "288720",
    "end": "290840"
  },
  {
    "text": "conversion step where you convert all of",
    "start": "290840",
    "end": "292440"
  },
  {
    "text": "this data into your framework native",
    "start": "292440",
    "end": "294080"
  },
  {
    "text": "format and that's when you enter the",
    "start": "294080",
    "end": "295919"
  },
  {
    "text": "memory operations where you perform say",
    "start": "295919",
    "end": "297960"
  },
  {
    "text": "copying into pin memory and from pin",
    "start": "297960",
    "end": "300039"
  },
  {
    "text": "memory you move it into GPU memory and",
    "start": "300039",
    "end": "302039"
  },
  {
    "text": "then you perform some operations in the",
    "start": "302039",
    "end": "303880"
  },
  {
    "text": "GPU and finally you yield that batch to",
    "start": "303880",
    "end": "305840"
  },
  {
    "text": "the",
    "start": "305840",
    "end": "306759"
  },
  {
    "text": "model so the target of the optimization",
    "start": "306759",
    "end": "309199"
  },
  {
    "text": "is going to be everything in the gray",
    "start": "309199",
    "end": "310560"
  },
  {
    "text": "box and it is important for us and here",
    "start": "310560",
    "end": "312600"
  },
  {
    "text": "is",
    "start": "312600",
    "end": "313440"
  },
  {
    "text": "why so the target use case that we are",
    "start": "313440",
    "end": "316160"
  },
  {
    "text": "going to look at is our home feed",
    "start": "316160",
    "end": "317680"
  },
  {
    "text": "ranking so this is a pretty important",
    "start": "317680",
    "end": "319160"
  },
  {
    "text": "use case for us this is the use case",
    "start": "319160",
    "end": "321680"
  },
  {
    "text": "that recommends valid content to the",
    "start": "321680",
    "end": "323160"
  },
  {
    "text": "users on our home feed and when we",
    "start": "323160",
    "end": "325360"
  },
  {
    "text": "started this whole optimization work the",
    "start": "325360",
    "end": "327520"
  },
  {
    "text": "throughput that we were observing for",
    "start": "327520",
    "end": "328919"
  },
  {
    "text": "our models were like about 880,000",
    "start": "328919",
    "end": "330440"
  },
  {
    "text": "examples per second and we knew that",
    "start": "330440",
    "end": "333160"
  },
  {
    "text": "there is a abundant Headroom that we can",
    "start": "333160",
    "end": "334880"
  },
  {
    "text": "squeeze out and so we started just",
    "start": "334880",
    "end": "337039"
  },
  {
    "text": "exploring what are the possible",
    "start": "337039",
    "end": "338639"
  },
  {
    "text": "bottlenecks that could be uh hampering",
    "start": "338639",
    "end": "340440"
  },
  {
    "text": "our progress um and here I've just",
    "start": "340440",
    "end": "342680"
  },
  {
    "text": "listed a couple of them so like as you",
    "start": "342680",
    "end": "344840"
  },
  {
    "text": "can imagine the most obvious bottleneck",
    "start": "344840",
    "end": "346520"
  },
  {
    "text": "could be the model itself where you are",
    "start": "346520",
    "end": "348120"
  },
  {
    "text": "just purely GPU compute bound and that's",
    "start": "348120",
    "end": "350600"
  },
  {
    "text": "that the other one could be that you are",
    "start": "350600",
    "end": "353120"
  },
  {
    "text": "actually bottleneck on the memory",
    "start": "353120",
    "end": "354400"
  },
  {
    "text": "operations where when you copy from CPU",
    "start": "354400",
    "end": "356360"
  },
  {
    "text": "to GPU you have some bottlenecks like",
    "start": "356360",
    "end": "358199"
  },
  {
    "text": "PCI bandwidth you could also end up",
    "start": "358199",
    "end": "360720"
  },
  {
    "text": "having CPU pre-processing bottlenecks",
    "start": "360720",
    "end": "362520"
  },
  {
    "text": "where you have so many inefficient",
    "start": "362520",
    "end": "364039"
  },
  {
    "text": "pre-processing operations that that is",
    "start": "364039",
    "end": "366199"
  },
  {
    "text": "hampering your throughput or you could",
    "start": "366199",
    "end": "368120"
  },
  {
    "text": "be purely file IO bound and I've just",
    "start": "368120",
    "end": "371400"
  },
  {
    "text": "tried to like illustrate this in the",
    "start": "371400",
    "end": "372840"
  },
  {
    "text": "code example like this is what a typical",
    "start": "372840",
    "end": "374560"
  },
  {
    "text": "training setup looks like the first line",
    "start": "374560",
    "end": "377160"
  },
  {
    "text": "that you see is you instantiate a model",
    "start": "377160",
    "end": "379520"
  },
  {
    "text": "then you construct some form of a data",
    "start": "379520",
    "end": "381120"
  },
  {
    "text": "set this is where you configure the file",
    "start": "381120",
    "end": "383039"
  },
  {
    "text": "IO then you pass that data set to some",
    "start": "383039",
    "end": "385160"
  },
  {
    "text": "form of a data loader where you pass a",
    "start": "385160",
    "end": "387160"
  },
  {
    "text": "collate function and the collate",
    "start": "387160",
    "end": "388680"
  },
  {
    "text": "function here is the one that is",
    "start": "388680",
    "end": "389880"
  },
  {
    "text": "responsible for applying all the CPU",
    "start": "389880",
    "end": "391560"
  },
  {
    "text": "pre-processing before your model gets",
    "start": "391560",
    "end": "393800"
  },
  {
    "text": "the batch so this is where the CPU",
    "start": "393800",
    "end": "396199"
  },
  {
    "text": "preprocessing is expressed and then you",
    "start": "396199",
    "end": "398120"
  },
  {
    "text": "have a traditional training Loop where",
    "start": "398120",
    "end": "400199"
  },
  {
    "text": "you iterate over the batches from that",
    "start": "400199",
    "end": "402000"
  },
  {
    "text": "data loader and then the first step that",
    "start": "402000",
    "end": "403960"
  },
  {
    "text": "you do is you copy that batch into the",
    "start": "403960",
    "end": "405560"
  },
  {
    "text": "GPU which is the call that you see for",
    "start": "405560",
    "end": "407560"
  },
  {
    "text": "send to device and then there are the",
    "start": "407560",
    "end": "409680"
  },
  {
    "text": "three standard steps in any model",
    "start": "409680",
    "end": "411039"
  },
  {
    "text": "training which is the forward backward",
    "start": "411039",
    "end": "412440"
  },
  {
    "text": "and the optimizer step so to understand",
    "start": "412440",
    "end": "415520"
  },
  {
    "text": "where the bottleneck is coming from what",
    "start": "415520",
    "end": "417479"
  },
  {
    "text": "we did is we tried to eliminate one",
    "start": "417479",
    "end": "419120"
  },
  {
    "text": "bottleneck at a time and so we first",
    "start": "419120",
    "end": "421039"
  },
  {
    "text": "tried to understand if model itself is",
    "start": "421039",
    "end": "422720"
  },
  {
    "text": "our bottleneck and to assess this what",
    "start": "422720",
    "end": "425199"
  },
  {
    "text": "we did is if you see the gray line that",
    "start": "425199",
    "end": "427800"
  },
  {
    "text": "I've drawn we basically froze a batch",
    "start": "427800",
    "end": "430039"
  },
  {
    "text": "and what I mean by that is after the",
    "start": "430039",
    "end": "432000"
  },
  {
    "text": "data loader produced the first batch we",
    "start": "432000",
    "end": "433919"
  },
  {
    "text": "just froze it on the GPU and then we",
    "start": "433919",
    "end": "435759"
  },
  {
    "text": "just like constantly looped over that",
    "start": "435759",
    "end": "437319"
  },
  {
    "text": "same batch effectively disabling the",
    "start": "437319",
    "end": "439000"
  },
  {
    "text": "data loader after the first batch is",
    "start": "439000",
    "end": "441160"
  },
  {
    "text": "prepared and to our surprise what we saw",
    "start": "441160",
    "end": "443800"
  },
  {
    "text": "is like if you see at the bottom the",
    "start": "443800",
    "end": "446000"
  },
  {
    "text": "after the batch is Frozen the throughput",
    "start": "446000",
    "end": "448000"
  },
  {
    "text": "jumps to like 500,000 examp examples per",
    "start": "448000",
    "end": "450000"
  },
  {
    "text": "second and what we were actually",
    "start": "450000",
    "end": "451280"
  },
  {
    "text": "observing in our real workload was just",
    "start": "451280",
    "end": "453360"
  },
  {
    "text": "880,000 examples per second so there is",
    "start": "453360",
    "end": "455240"
  },
  {
    "text": "like a 6 6 xish Headroom that we had to",
    "start": "455240",
    "end": "459240"
  },
  {
    "text": "actually optimize and squeeze out the",
    "start": "459240",
    "end": "460759"
  },
  {
    "text": "most",
    "start": "460759",
    "end": "461720"
  },
  {
    "text": "performance and what this effectively",
    "start": "461720",
    "end": "463800"
  },
  {
    "text": "meant is that the time it took for the",
    "start": "463800",
    "end": "465400"
  },
  {
    "text": "model to run is a lot lot smaller than",
    "start": "465400",
    "end": "467440"
  },
  {
    "text": "the whole training iteration so we knew",
    "start": "467440",
    "end": "469720"
  },
  {
    "text": "that we had something to play with here",
    "start": "469720",
    "end": "472360"
  },
  {
    "text": "and we just let's we just Tred to reason",
    "start": "472360",
    "end": "474400"
  },
  {
    "text": "about why this could be happening and I",
    "start": "474400",
    "end": "475840"
  },
  {
    "text": "think it's fairly intuitive as well one",
    "start": "475840",
    "end": "478599"
  },
  {
    "text": "of the most important reasons is like uh",
    "start": "478599",
    "end": "481520"
  },
  {
    "text": "these recommender models are actually",
    "start": "481520",
    "end": "482919"
  },
  {
    "text": "served at very low latencies because of",
    "start": "482919",
    "end": "485000"
  },
  {
    "text": "the product needs and so they are",
    "start": "485000",
    "end": "486720"
  },
  {
    "text": "typically a lot smaller than the",
    "start": "486720",
    "end": "488080"
  },
  {
    "text": "generative AI counterparts that you see",
    "start": "488080",
    "end": "490319"
  },
  {
    "text": "and so they end up having a lot more lot",
    "start": "490319",
    "end": "492319"
  },
  {
    "text": "less compute compared to the Gen",
    "start": "492319",
    "end": "494639"
  },
  {
    "text": "counterparts the other thing that makes",
    "start": "494639",
    "end": "496680"
  },
  {
    "text": "these models very tricky is they are",
    "start": "496680",
    "end": "498639"
  },
  {
    "text": "highly data intensive meaning that their",
    "start": "498639",
    "end": "500759"
  },
  {
    "text": "data to compute ratio is a lot higher",
    "start": "500759",
    "end": "503319"
  },
  {
    "text": "and the reason for that is like",
    "start": "503319",
    "end": "504639"
  },
  {
    "text": "typically these models use hundreds or",
    "start": "504639",
    "end": "506360"
  },
  {
    "text": "thousands of features they have very",
    "start": "506360",
    "end": "508240"
  },
  {
    "text": "large sequence features that they use",
    "start": "508240",
    "end": "509840"
  },
  {
    "text": "and so it becomes like very memory and",
    "start": "509840",
    "end": "511720"
  },
  {
    "text": "data heavy",
    "start": "511720",
    "end": "513240"
  },
  {
    "text": "operation and the the thing that like",
    "start": "513240",
    "end": "516240"
  },
  {
    "text": "makes this a little worse is cloud",
    "start": "516240",
    "end": "518120"
  },
  {
    "text": "instances typically come with like fixed",
    "start": "518120",
    "end": "519880"
  },
  {
    "text": "CPU to GPU ratios and so you cannot",
    "start": "519880",
    "end": "522039"
  },
  {
    "text": "arbitrarily scale up the CPU",
    "start": "522039",
    "end": "523518"
  },
  {
    "text": "pre-processing",
    "start": "523519",
    "end": "525000"
  },
  {
    "text": "parts so this is the bottleneck that we",
    "start": "525000",
    "end": "527600"
  },
  {
    "text": "were trying to address and before going",
    "start": "527600",
    "end": "529800"
  },
  {
    "text": "into any advanced Solutions the obvious",
    "start": "529800",
    "end": "531680"
  },
  {
    "text": "thing to do was to just reduce the",
    "start": "531680",
    "end": "533640"
  },
  {
    "text": "amount of data that we are processing",
    "start": "533640",
    "end": "535680"
  },
  {
    "text": "and so the first obvious thing that we",
    "start": "535680",
    "end": "537040"
  },
  {
    "text": "did is let's just Target the most",
    "start": "537040",
    "end": "539440"
  },
  {
    "text": "expensive features that we have and so",
    "start": "539440",
    "end": "541240"
  },
  {
    "text": "what we ended up doing is we started",
    "start": "541240",
    "end": "542720"
  },
  {
    "text": "leveraging Spar tensors and the idea",
    "start": "542720",
    "end": "545880"
  },
  {
    "text": "here is if you have a large number of",
    "start": "545880",
    "end": "547720"
  },
  {
    "text": "sequence features which can be mostly",
    "start": "547720",
    "end": "549839"
  },
  {
    "text": "empty we basically just skip storing all",
    "start": "549839",
    "end": "552279"
  },
  {
    "text": "the empty slots for this we started",
    "start": "552279",
    "end": "554440"
  },
  {
    "text": "using T Spar CSR tensor format and the",
    "start": "554440",
    "end": "557600"
  },
  {
    "text": "idea here is before the model consumes",
    "start": "557600",
    "end": "559880"
  },
  {
    "text": "it you actually densify the tensor back",
    "start": "559880",
    "end": "561920"
  },
  {
    "text": "on the GPU and the reason why this is",
    "start": "561920",
    "end": "564600"
  },
  {
    "text": "highly effective is even though you",
    "start": "564600",
    "end": "566320"
  },
  {
    "text": "still end up densifying it has some",
    "start": "566320",
    "end": "568360"
  },
  {
    "text": "implications on two fronts like the",
    "start": "568360",
    "end": "570720"
  },
  {
    "text": "first effect that you see there is the",
    "start": "570720",
    "end": "572839"
  },
  {
    "text": "data compression because you use sparse",
    "start": "572839",
    "end": "575440"
  },
  {
    "text": "formats to represent the data the amount",
    "start": "575440",
    "end": "577800"
  },
  {
    "text": "of data that you store on your bucket",
    "start": "577800",
    "end": "579680"
  },
  {
    "text": "storage is a lot less when you perform",
    "start": "579680",
    "end": "582079"
  },
  {
    "text": "any kind of file IO and you pull down",
    "start": "582079",
    "end": "583680"
  },
  {
    "text": "those bytes to the the actual training",
    "start": "583680",
    "end": "585760"
  },
  {
    "text": "node you perform a lot less file IO",
    "start": "585760",
    "end": "587600"
  },
  {
    "text": "compared to before and so both of those",
    "start": "587600",
    "end": "589519"
  },
  {
    "text": "steps are optimized the other",
    "start": "589519",
    "end": "591399"
  },
  {
    "text": "interesting effect here is the data",
    "start": "591399",
    "end": "592920"
  },
  {
    "text": "movement where those bites that you're",
    "start": "592920",
    "end": "594920"
  },
  {
    "text": "trying to carry forward from the bucket",
    "start": "594920",
    "end": "596600"
  },
  {
    "text": "storage to the CPU pre-processing steps",
    "start": "596600",
    "end": "599399"
  },
  {
    "text": "across the PCI bandwidth is a lot less",
    "start": "599399",
    "end": "602760"
  },
  {
    "text": "and so in the diagram just this is just",
    "start": "602760",
    "end": "605079"
  },
  {
    "text": "Pudo diagram but like what you can",
    "start": "605079",
    "end": "606839"
  },
  {
    "text": "understand is before if you trying to",
    "start": "606839",
    "end": "608720"
  },
  {
    "text": "transfer a lot more bytes you can see",
    "start": "608720",
    "end": "610600"
  },
  {
    "text": "that the host to device transfer can be",
    "start": "610600",
    "end": "612160"
  },
  {
    "text": "a lot larger and what we are trying to",
    "start": "612160",
    "end": "614360"
  },
  {
    "text": "do later is transfer a lot fewer bytes",
    "start": "614360",
    "end": "616920"
  },
  {
    "text": "but then densify it within the GPU the",
    "start": "616920",
    "end": "619399"
  },
  {
    "text": "reason why the second is faster is",
    "start": "619399",
    "end": "620880"
  },
  {
    "text": "because GPU has a lot more memory",
    "start": "620880",
    "end": "622320"
  },
  {
    "text": "bandwidth so even if you end up doing",
    "start": "622320",
    "end": "624160"
  },
  {
    "text": "more work the second step is actually a",
    "start": "624160",
    "end": "626240"
  },
  {
    "text": "lot faster and what we saw is because",
    "start": "626240",
    "end": "628959"
  },
  {
    "text": "our data sets are dominated by these",
    "start": "628959",
    "end": "630600"
  },
  {
    "text": "sequence features you can see that when",
    "start": "630600",
    "end": "632320"
  },
  {
    "text": "we started using Spar tensor formats our",
    "start": "632320",
    "end": "634360"
  },
  {
    "text": "through put jump to almost 2 x of what",
    "start": "634360",
    "end": "636160"
  },
  {
    "text": "it was before so we knew that we are",
    "start": "636160",
    "end": "638760"
  },
  {
    "text": "making progress in the right direction",
    "start": "638760",
    "end": "640279"
  },
  {
    "text": "like just making this one Chang brought",
    "start": "640279",
    "end": "642440"
  },
  {
    "text": "our throughput to like 160,000 examples",
    "start": "642440",
    "end": "644480"
  },
  {
    "text": "per second which is 100%",
    "start": "644480",
    "end": "646800"
  },
  {
    "text": "Improvement so we just decided to double",
    "start": "646800",
    "end": "648959"
  },
  {
    "text": "down on this approach the thing that we",
    "start": "648959",
    "end": "651160"
  },
  {
    "text": "did next was we tried to use application",
    "start": "651160",
    "end": "654959"
  },
  {
    "text": "specific optimizations where we knew",
    "start": "654959",
    "end": "657480"
  },
  {
    "text": "that given that we have Park data sets",
    "start": "657480",
    "end": "659720"
  },
  {
    "text": "that we have if we sort the records in",
    "start": "659720",
    "end": "662200"
  },
  {
    "text": "the correct order Parky can perform a",
    "start": "662200",
    "end": "664079"
  },
  {
    "text": "lot better job of compressing these data",
    "start": "664079",
    "end": "666000"
  },
  {
    "text": "sets and so like effectively reducing",
    "start": "666000",
    "end": "668959"
  },
  {
    "text": "the amount of bytes that we have been",
    "start": "668959",
    "end": "670839"
  },
  {
    "text": "using to power these machine learning",
    "start": "670839",
    "end": "673079"
  },
  {
    "text": "use cases and so like all we did is just",
    "start": "673079",
    "end": "675560"
  },
  {
    "text": "sort the data in the right order and the",
    "start": "675560",
    "end": "677639"
  },
  {
    "text": "effect of this is again the same the",
    "start": "677639",
    "end": "679320"
  },
  {
    "text": "same thing that I described before which",
    "start": "679320",
    "end": "680839"
  },
  {
    "text": "is it compresses the data on storage and",
    "start": "680839",
    "end": "683720"
  },
  {
    "text": "it minimizes the amount of bytes you",
    "start": "683720",
    "end": "685480"
  },
  {
    "text": "transfer over the file",
    "start": "685480",
    "end": "686959"
  },
  {
    "text": "iio again this change multiplied and",
    "start": "686959",
    "end": "689560"
  },
  {
    "text": "like gave us compounding effects on the",
    "start": "689560",
    "end": "691480"
  },
  {
    "text": "previous change and you see that the",
    "start": "691480",
    "end": "693440"
  },
  {
    "text": "throughput now increases on another 30%",
    "start": "693440",
    "end": "695320"
  },
  {
    "text": "so we are already at 260,000 examples",
    "start": "695320",
    "end": "697360"
  },
  {
    "text": "per second like we went from 80 to 160",
    "start": "697360",
    "end": "699279"
  },
  {
    "text": "to",
    "start": "699279",
    "end": "700440"
  },
  {
    "text": "260 but here is where we kind of hit a",
    "start": "700440",
    "end": "704040"
  },
  {
    "text": "wall where we knew that we are about",
    "start": "704040",
    "end": "706920"
  },
  {
    "text": "260,000 examples per second but based on",
    "start": "706920",
    "end": "709440"
  },
  {
    "text": "the benchmarking that we did we know",
    "start": "709440",
    "end": "711440"
  },
  {
    "text": "that the head room is like 500,000",
    "start": "711440",
    "end": "713000"
  },
  {
    "text": "examples per second so there's like",
    "start": "713000",
    "end": "714440"
  },
  {
    "text": "abundant Headroom that we can still",
    "start": "714440",
    "end": "716279"
  },
  {
    "text": "leverage and the observations that we",
    "start": "716279",
    "end": "718560"
  },
  {
    "text": "had were that that like still we were",
    "start": "718560",
    "end": "720760"
  },
  {
    "text": "very data and CPU pre-processing bound",
    "start": "720760",
    "end": "723360"
  },
  {
    "text": "and we were to a large extent also file",
    "start": "723360",
    "end": "725079"
  },
  {
    "text": "iio bound and what we had to do is",
    "start": "725079",
    "end": "728200"
  },
  {
    "text": "instead of just shrinking the data we",
    "start": "728200",
    "end": "730120"
  },
  {
    "text": "had to figure out a way where we can",
    "start": "730120",
    "end": "731560"
  },
  {
    "text": "scale out the data pre-processing itself",
    "start": "731560",
    "end": "734199"
  },
  {
    "text": "and we had to break out of this like",
    "start": "734199",
    "end": "735560"
  },
  {
    "text": "fixed CPU to GPU ratios that we had",
    "start": "735560",
    "end": "737440"
  },
  {
    "text": "available on our GPU notes and so that's",
    "start": "737440",
    "end": "739680"
  },
  {
    "text": "what we ended up doing next so as you",
    "start": "739680",
    "end": "742120"
  },
  {
    "text": "may guess Ray was actually a good fit",
    "start": "742120",
    "end": "744279"
  },
  {
    "text": "for us to solve this specific Challenge",
    "start": "744279",
    "end": "745920"
  },
  {
    "text": "and that's why we adopted",
    "start": "745920",
    "end": "747480"
  },
  {
    "text": "Ray particularly like two properties",
    "start": "747480",
    "end": "749839"
  },
  {
    "text": "were of interest to us one is Ray core",
    "start": "749839",
    "end": "752120"
  },
  {
    "text": "is actually a distributed heterogeneous",
    "start": "752120",
    "end": "754160"
  },
  {
    "text": "CPU GPU runtime which is exactly what we",
    "start": "754160",
    "end": "756160"
  },
  {
    "text": "needed we didn't just need GPU nodes we",
    "start": "756160",
    "end": "758199"
  },
  {
    "text": "wanted abundant CPU nodes to power the",
    "start": "758199",
    "end": "759959"
  },
  {
    "text": "GPU nodes as well and given that now the",
    "start": "759959",
    "end": "763440"
  },
  {
    "text": "training job is going to be distributed",
    "start": "763440",
    "end": "765000"
  },
  {
    "text": "in its nature you also need like good UI",
    "start": "765000",
    "end": "767279"
  },
  {
    "text": "and debugging tools which Ray core",
    "start": "767279",
    "end": "768839"
  },
  {
    "text": "provides out of the box and the ray ml",
    "start": "768839",
    "end": "771240"
  },
  {
    "text": "ecosystem was also of interest to us",
    "start": "771240",
    "end": "773360"
  },
  {
    "text": "particularly Ray data because it allows",
    "start": "773360",
    "end": "775079"
  },
  {
    "text": "you to express Last Mile data",
    "start": "775079",
    "end": "778120"
  },
  {
    "text": "preprocessing so what we set out to",
    "start": "778120",
    "end": "780040"
  },
  {
    "text": "build is actually what we refer to as",
    "start": "780040",
    "end": "782120"
  },
  {
    "text": "the distributed data loader with Ray and",
    "start": "782120",
    "end": "784480"
  },
  {
    "text": "the idea here is simple we basically",
    "start": "784480",
    "end": "786560"
  },
  {
    "text": "want to increase or scale out the number",
    "start": "786560",
    "end": "788720"
  },
  {
    "text": "of data loading workers that you have",
    "start": "788720",
    "end": "790760"
  },
  {
    "text": "for every GPU trainer and the way we do",
    "start": "790760",
    "end": "793680"
  },
  {
    "text": "do this is by adding like three or more",
    "start": "793680",
    "end": "795639"
  },
  {
    "text": "CPU nodes into the mix so as you can see",
    "start": "795639",
    "end": "797920"
  },
  {
    "text": "in the diagram here we have like four",
    "start": "797920",
    "end": "800240"
  },
  {
    "text": "like all of this is running on Ray the",
    "start": "800240",
    "end": "802079"
  },
  {
    "text": "dark gray ones are pure CPU nodes and",
    "start": "802079",
    "end": "804399"
  },
  {
    "text": "they are doing the job of data loading",
    "start": "804399",
    "end": "805959"
  },
  {
    "text": "which is basically file IO and any CPU",
    "start": "805959",
    "end": "808120"
  },
  {
    "text": "pre-processing and then these mini",
    "start": "808120",
    "end": "809920"
  },
  {
    "text": "patches are transferred over the network",
    "start": "809920",
    "end": "811600"
  },
  {
    "text": "into the GPU node and then the GPU node",
    "start": "811600",
    "end": "813279"
  },
  {
    "text": "is just running the training",
    "start": "813279",
    "end": "814920"
  },
  {
    "text": "Loop so as as as I described before like",
    "start": "814920",
    "end": "818079"
  },
  {
    "text": "all of the file IO and CPU",
    "start": "818079",
    "end": "819519"
  },
  {
    "text": "pre-processing is on the CPU noes and",
    "start": "819519",
    "end": "821480"
  },
  {
    "text": "the batches are transferred over and",
    "start": "821480",
    "end": "823680"
  },
  {
    "text": "this is also where we introduced Ray",
    "start": "823680",
    "end": "825399"
  },
  {
    "text": "data as a means to express map batches",
    "start": "825399",
    "end": "828320"
  },
  {
    "text": "where we can apply like any filtering",
    "start": "828320",
    "end": "830199"
  },
  {
    "text": "down sampling of the data sets as a last",
    "start": "830199",
    "end": "832360"
  },
  {
    "text": "mile",
    "start": "832360",
    "end": "833759"
  },
  {
    "text": "transform so when we actually develop",
    "start": "833759",
    "end": "836480"
  },
  {
    "text": "this and try to run a job with this the",
    "start": "836480",
    "end": "839120"
  },
  {
    "text": "expectation was that this will help us",
    "start": "839120",
    "end": "841279"
  },
  {
    "text": "bump the throughput up from like our",
    "start": "841279",
    "end": "842959"
  },
  {
    "text": "current throughput of like 260 to",
    "start": "842959",
    "end": "845600"
  },
  {
    "text": "somewhere close to 500,000 examples per",
    "start": "845600",
    "end": "847920"
  },
  {
    "text": "second but this is what actually",
    "start": "847920",
    "end": "849800"
  },
  {
    "text": "happened so we added three CPU nodes",
    "start": "849800",
    "end": "852240"
  },
  {
    "text": "into the mix and we expected the",
    "start": "852240",
    "end": "854120"
  },
  {
    "text": "throughput to be somewhere between 250",
    "start": "854120",
    "end": "855920"
  },
  {
    "text": "and 500 but the actual throughput we",
    "start": "855920",
    "end": "858320"
  },
  {
    "text": "observed was just 110 which is lower",
    "start": "858320",
    "end": "860519"
  },
  {
    "text": "than the single node throughput that we",
    "start": "860519",
    "end": "862440"
  },
  {
    "text": "have so it's clear that just adding CPU",
    "start": "862440",
    "end": "865680"
  },
  {
    "text": "nodes was not the solution and when we",
    "start": "865680",
    "end": "868360"
  },
  {
    "text": "when we fix try to figure out what went",
    "start": "868360",
    "end": "870240"
  },
  {
    "text": "wrong there were a few things that we",
    "start": "870240",
    "end": "872079"
  },
  {
    "text": "saw first is that because of the way Ray",
    "start": "872079",
    "end": "875120"
  },
  {
    "text": "data and Ray data iterators are set up",
    "start": "875120",
    "end": "877199"
  },
  {
    "text": "the expensive CPU pre-processing Parts",
    "start": "877199",
    "end": "879240"
  },
  {
    "text": "at least some of them are still",
    "start": "879240",
    "end": "880839"
  },
  {
    "text": "happening on the GPU nodes which is not",
    "start": "880839",
    "end": "882480"
  },
  {
    "text": "what we wanted the second is because of",
    "start": "882480",
    "end": "885480"
  },
  {
    "text": "the volume of the data that our model",
    "start": "885480",
    "end": "887160"
  },
  {
    "text": "needs the ray Object Store transfers",
    "start": "887160",
    "end": "889320"
  },
  {
    "text": "itself started becoming a bottleneck and",
    "start": "889320",
    "end": "891920"
  },
  {
    "text": "the third thing is because Ray data is a",
    "start": "891920",
    "end": "893800"
  },
  {
    "text": "general purpose data pre-processing",
    "start": "893800",
    "end": "895600"
  },
  {
    "text": "system it was lacking some of the",
    "start": "895600",
    "end": "897480"
  },
  {
    "text": "critical data transfer compon components",
    "start": "897480",
    "end": "899320"
  },
  {
    "text": "that machine learning models need like",
    "start": "899320",
    "end": "900880"
  },
  {
    "text": "GPU preloading memory pinning and so",
    "start": "900880",
    "end": "903759"
  },
  {
    "text": "that's what we started ended up doing",
    "start": "903759",
    "end": "905720"
  },
  {
    "text": "and I think Raymond can continue the",
    "start": "905720",
    "end": "907240"
  },
  {
    "text": "rest of the",
    "start": "907240",
    "end": "909680"
  },
  {
    "text": "story so yeah hello everybody I'm",
    "start": "912800",
    "end": "915399"
  },
  {
    "text": "Raymond I'm a senior engineers in",
    "start": "915399",
    "end": "917320"
  },
  {
    "text": "Pinterest m training INF so I'm going to",
    "start": "917320",
    "end": "920600"
  },
  {
    "text": "continue talking about the journey we",
    "start": "920600",
    "end": "922480"
  },
  {
    "text": "applying Ray to train Pinterest homey",
    "start": "922480",
    "end": "924880"
  },
  {
    "text": "rankers and then also the optimization",
    "start": "924880",
    "end": "927079"
  },
  {
    "text": "we done to further improve the data",
    "start": "927079",
    "end": "928959"
  },
  {
    "text": "building bottleneck",
    "start": "928959",
    "end": "931399"
  },
  {
    "text": "problems so before we dive into the",
    "start": "931399",
    "end": "933600"
  },
  {
    "text": "details of the optimization we have made",
    "start": "933600",
    "end": "936279"
  },
  {
    "text": "let's first take a look at the initial",
    "start": "936279",
    "end": "938279"
  },
  {
    "text": "setup of our um uh architecture of the",
    "start": "938279",
    "end": "941720"
  },
  {
    "text": "trains right so the initial setup is",
    "start": "941720",
    "end": "944160"
  },
  {
    "text": "actually follow a typical Ray data plus",
    "start": "944160",
    "end": "946480"
  },
  {
    "text": "Ray trains uh architectures so we first",
    "start": "946480",
    "end": "949920"
  },
  {
    "text": "have a ray data pipelines to do data",
    "start": "949920",
    "end": "951959"
  },
  {
    "text": "loadings on the CPU noes it is",
    "start": "951959",
    "end": "954560"
  },
  {
    "text": "responsible for iOS and also user defin",
    "start": "954560",
    "end": "957800"
  },
  {
    "text": "transformations so once data is being",
    "start": "957800",
    "end": "960360"
  },
  {
    "text": "prepared then then stream back to the",
    "start": "960360",
    "end": "962360"
  },
  {
    "text": "individual training process through R",
    "start": "962360",
    "end": "964680"
  },
  {
    "text": "data streamings and then going through a",
    "start": "964680",
    "end": "966720"
  },
  {
    "text": "few final data processings preparing the",
    "start": "966720",
    "end": "969279"
  },
  {
    "text": "best then finally sending to GPU memory",
    "start": "969279",
    "end": "971680"
  },
  {
    "text": "for",
    "start": "971680",
    "end": "973600"
  },
  {
    "text": "compute so now the first challenge we we",
    "start": "973600",
    "end": "976639"
  },
  {
    "text": "are facing here as you might already",
    "start": "976639",
    "end": "978279"
  },
  {
    "text": "seen here in the diagram is that we",
    "start": "978279",
    "end": "981240"
  },
  {
    "text": "still have some like expensive CPU",
    "start": "981240",
    "end": "983480"
  },
  {
    "text": "processing right so the first thing we",
    "start": "983480",
    "end": "985560"
  },
  {
    "text": "discover is this batch formation living",
    "start": "985560",
    "end": "987480"
  },
  {
    "text": "inside the ray data uh iterators is very",
    "start": "987480",
    "end": "990560"
  },
  {
    "text": "expensive because this need a full data",
    "start": "990560",
    "end": "993000"
  },
  {
    "text": "copying so and then since it's done in a",
    "start": "993000",
    "end": "995600"
  },
  {
    "text": "GPU process together that frequently",
    "start": "995600",
    "end": "997720"
  },
  {
    "text": "Cuts GPU idle times and then furthermore",
    "start": "997720",
    "end": "1000319"
  },
  {
    "text": "it's not allowing us to scale this",
    "start": "1000319",
    "end": "1002120"
  },
  {
    "text": "operation efficiently without without",
    "start": "1002120",
    "end": "1004000"
  },
  {
    "text": "touching the GPU resource they have to",
    "start": "1004000",
    "end": "1005880"
  },
  {
    "text": "scale togethers which is not we want not",
    "start": "1005880",
    "end": "1008440"
  },
  {
    "text": "what we want we want to scale CPU",
    "start": "1008440",
    "end": "1010360"
  },
  {
    "text": "operation",
    "start": "1010360",
    "end": "1012079"
  },
  {
    "text": "independently so then the ne the the",
    "start": "1012079",
    "end": "1014560"
  },
  {
    "text": "obvious thing we are doing is just",
    "start": "1014560",
    "end": "1016199"
  },
  {
    "text": "moving this um operations into uh",
    "start": "1016199",
    "end": "1019480"
  },
  {
    "text": "offstring pipelines so that what we do",
    "start": "1019480",
    "end": "1022040"
  },
  {
    "text": "is to implement uh batching as an actors",
    "start": "1022040",
    "end": "1025079"
  },
  {
    "text": "and then that being able to run this",
    "start": "1025079",
    "end": "1027079"
  },
  {
    "text": "operation in R data pipelines so by",
    "start": "1027079",
    "end": "1029280"
  },
  {
    "text": "uploading this CPU intensity operations",
    "start": "1029280",
    "end": "1031760"
  },
  {
    "text": "we are actually being able to reduce the",
    "start": "1031760",
    "end": "1033918"
  },
  {
    "text": "GPU idal weight times and then",
    "start": "1033919",
    "end": "1035720"
  },
  {
    "text": "furthermore this operation can naturally",
    "start": "1035720",
    "end": "1037720"
  },
  {
    "text": "scale with as part of the rate data",
    "start": "1037720",
    "end": "1039678"
  },
  {
    "text": "pipelines is",
    "start": "1039679",
    "end": "1042280"
  },
  {
    "text": "scaling so now the next bottleneck we",
    "start": "1042280",
    "end": "1045400"
  },
  {
    "text": "are facing here is the St uh Object",
    "start": "1045400",
    "end": "1048438"
  },
  {
    "text": "Store trans",
    "start": "1048439",
    "end": "1049480"
  },
  {
    "text": "we discover that no matter how much we",
    "start": "1049480",
    "end": "1052000"
  },
  {
    "text": "scale the um CPU nodes it's always",
    "start": "1052000",
    "end": "1054760"
  },
  {
    "text": "bottom from certain numbers and then",
    "start": "1054760",
    "end": "1057360"
  },
  {
    "text": "this is due to a variz the problem but",
    "start": "1057360",
    "end": "1058919"
  },
  {
    "text": "mainly because uh the data compressions",
    "start": "1058919",
    "end": "1061640"
  },
  {
    "text": "between CPU and GPU node so in I3 we",
    "start": "1061640",
    "end": "1064480"
  },
  {
    "text": "usually save the data data set into a",
    "start": "1064480",
    "end": "1067440"
  },
  {
    "text": "zsd compress format and then this is",
    "start": "1067440",
    "end": "1070160"
  },
  {
    "text": "also the uh data format we going to",
    "start": "1070160",
    "end": "1072480"
  },
  {
    "text": "transfer the data from F3 to CPU because",
    "start": "1072480",
    "end": "1076159"
  },
  {
    "text": "uh it will reduce the I cost and also",
    "start": "1076159",
    "end": "1078919"
  },
  {
    "text": "with the ID sorted data set we mentioned",
    "start": "1078919",
    "end": "1080720"
  },
  {
    "text": "before this data set is usually very",
    "start": "1080720",
    "end": "1082840"
  },
  {
    "text": "highly compressed but once the CPU gome",
    "start": "1082840",
    "end": "1085799"
  },
  {
    "text": "process read and process datas and",
    "start": "1085799",
    "end": "1088320"
  },
  {
    "text": "trying to send it into GPU node we found",
    "start": "1088320",
    "end": "1090120"
  },
  {
    "text": "that this um living in uncompressed",
    "start": "1090120",
    "end": "1093200"
  },
  {
    "text": "format because by default oper store",
    "start": "1093200",
    "end": "1095520"
  },
  {
    "text": "doesn't provide any of the compression",
    "start": "1095520",
    "end": "1097240"
  },
  {
    "text": "method so now a lot of a lot more bites",
    "start": "1097240",
    "end": "1100200"
  },
  {
    "text": "have to be sent from CPU to GPU and then",
    "start": "1100200",
    "end": "1103120"
  },
  {
    "text": "this causing a lot of severe botton X",
    "start": "1103120",
    "end": "1106960"
  },
  {
    "text": "here so now the the idea is to also",
    "start": "1106960",
    "end": "1110440"
  },
  {
    "text": "apply Z zsc compression right so so that",
    "start": "1110440",
    "end": "1113799"
  },
  {
    "text": "we don't have this um severe number of",
    "start": "1113799",
    "end": "1117000"
  },
  {
    "text": "data need to be transferred so we just",
    "start": "1117000",
    "end": "1119760"
  },
  {
    "text": "applying a custom patch to the ray core",
    "start": "1119760",
    "end": "1122320"
  },
  {
    "text": "Object Store layer in our open source",
    "start": "1122320",
    "end": "1124080"
  },
  {
    "text": "Fork so that uh one every data object",
    "start": "1124080",
    "end": "1127520"
  },
  {
    "text": "have to trans transfer between Ray",
    "start": "1127520",
    "end": "1129480"
  },
  {
    "text": "cluster between notes there are also",
    "start": "1129480",
    "end": "1131520"
  },
  {
    "text": "going to be uh Z zst",
    "start": "1131520",
    "end": "1134120"
  },
  {
    "text": "compressed so then the observation we",
    "start": "1134120",
    "end": "1136880"
  },
  {
    "text": "have here is that now uh the compression",
    "start": "1136880",
    "end": "1140240"
  },
  {
    "text": "ratio between uh for the data sending",
    "start": "1140240",
    "end": "1143480"
  },
  {
    "text": "from CPU to GPU is actually matchings",
    "start": "1143480",
    "end": "1146240"
  },
  {
    "text": "the compression ratio we have in a three",
    "start": "1146240",
    "end": "1148840"
  },
  {
    "text": "and ultimately it reduce more than 10",
    "start": "1148840",
    "end": "1151720"
  },
  {
    "text": "times of the number of B we have to be",
    "start": "1151720",
    "end": "1154039"
  },
  {
    "text": "transfer and then relieve this as the",
    "start": "1154039",
    "end": "1156120"
  },
  {
    "text": "botton",
    "start": "1156120",
    "end": "1158799"
  },
  {
    "text": "applications so now uh let's we solve",
    "start": "1159480",
    "end": "1162240"
  },
  {
    "text": "the object store bottleneck then that's",
    "start": "1162240",
    "end": "1164080"
  },
  {
    "text": "looking back to the overall pipeline",
    "start": "1164080",
    "end": "1165520"
  },
  {
    "text": "again and then we still see that there's",
    "start": "1165520",
    "end": "1167720"
  },
  {
    "text": "some other uh CPU operation as well",
    "start": "1167720",
    "end": "1170480"
  },
  {
    "text": "living inside the GPU process which is",
    "start": "1170480",
    "end": "1173440"
  },
  {
    "text": "specifically this is collate where we're",
    "start": "1173440",
    "end": "1175159"
  },
  {
    "text": "trying to convert the py table into the",
    "start": "1175159",
    "end": "1177559"
  },
  {
    "text": "dictionary",
    "start": "1177559",
    "end": "1178720"
  },
  {
    "text": "tensor and this is especially uh",
    "start": "1178720",
    "end": "1181679"
  },
  {
    "text": "expensive combining the fact that we",
    "start": "1181679",
    "end": "1184039"
  },
  {
    "text": "have complex features like sparse and",
    "start": "1184039",
    "end": "1186000"
  },
  {
    "text": "rack tensor living our batch so that it",
    "start": "1186000",
    "end": "1188919"
  },
  {
    "text": "now int still introduce an overhead",
    "start": "1188919",
    "end": "1191360"
  },
  {
    "text": "right so borrowing from the previous um",
    "start": "1191360",
    "end": "1194240"
  },
  {
    "text": "learning we also want to move this um",
    "start": "1194240",
    "end": "1197360"
  },
  {
    "text": "collat out and then move into the data",
    "start": "1197360",
    "end": "1199679"
  },
  {
    "text": "set pipeline so that it won't C to few",
    "start": "1199679",
    "end": "1201640"
  },
  {
    "text": "idle times and then um Can scale but",
    "start": "1201640",
    "end": "1204840"
  },
  {
    "text": "then the other challenge we Face here is",
    "start": "1204840",
    "end": "1206880"
  },
  {
    "text": "that the output of the uh pipeline now",
    "start": "1206880",
    "end": "1210440"
  },
  {
    "text": "become a dictionary of tensor which is",
    "start": "1210440",
    "end": "1213679"
  },
  {
    "text": "not super friendly at this point with r",
    "start": "1213679",
    "end": "1215799"
  },
  {
    "text": "data interface uh especially we have uh",
    "start": "1215799",
    "end": "1218799"
  },
  {
    "text": "this special R tensor and sparse tensor",
    "start": "1218799",
    "end": "1221679"
  },
  {
    "text": "um specific to the pytor training um uh",
    "start": "1221679",
    "end": "1226880"
  },
  {
    "text": "worlds and then",
    "start": "1226880",
    "end": "1229159"
  },
  {
    "text": "while dealing with this um bottleneck we",
    "start": "1229159",
    "end": "1232159"
  },
  {
    "text": "also in the same time discover another",
    "start": "1232159",
    "end": "1234480"
  },
  {
    "text": "kind of overhead during the entire data",
    "start": "1234480",
    "end": "1238320"
  },
  {
    "text": "movement funnels right uh meaning when",
    "start": "1238320",
    "end": "1240960"
  },
  {
    "text": "we moving data from uh remote CPU memory",
    "start": "1240960",
    "end": "1244039"
  },
  {
    "text": "to all the way to GPU memory this",
    "start": "1244039",
    "end": "1245919"
  },
  {
    "text": "overhead typically scales as number of",
    "start": "1245919",
    "end": "1248120"
  },
  {
    "text": "feature columns grows for example in",
    "start": "1248120",
    "end": "1250640"
  },
  {
    "text": "this diagram we also shows the",
    "start": "1250640",
    "end": "1252720"
  },
  {
    "text": "screenshot of the uh Trace to take a",
    "start": "1252720",
    "end": "1255640"
  },
  {
    "text": "data out from object store and then in",
    "start": "1255640",
    "end": "1258640"
  },
  {
    "text": "this example we found that for each of",
    "start": "1258640",
    "end": "1260720"
  },
  {
    "text": "the feature columns uh in the batch we",
    "start": "1260720",
    "end": "1263600"
  },
  {
    "text": "we have to pay a small amount of",
    "start": "1263600",
    "end": "1265280"
  },
  {
    "text": "unpickling overhead to take them out uh",
    "start": "1265280",
    "end": "1268440"
  },
  {
    "text": "this might be fine for some usual cases",
    "start": "1268440",
    "end": "1270799"
  },
  {
    "text": "but for Pinterest because we uh a model",
    "start": "1270799",
    "end": "1273919"
  },
  {
    "text": "consum hundreds or even thousands of the",
    "start": "1273919",
    "end": "1275960"
  },
  {
    "text": "features as an input so this over had",
    "start": "1275960",
    "end": "1278600"
  },
  {
    "text": "quickly become non-trial and then as a",
    "start": "1278600",
    "end": "1281760"
  },
  {
    "text": "comparison Weist the four pass here you",
    "start": "1281760",
    "end": "1283960"
  },
  {
    "text": "can see that this onping overhead so",
    "start": "1283960",
    "end": "1287000"
  },
  {
    "text": "itself is already 1.5 times of the",
    "start": "1287000",
    "end": "1289760"
  },
  {
    "text": "fourest so becomes another bottl nck we",
    "start": "1289760",
    "end": "1292960"
  },
  {
    "text": "we want to",
    "start": "1292960",
    "end": "1294760"
  },
  {
    "text": "solve so now um in order to deal with",
    "start": "1294760",
    "end": "1298120"
  },
  {
    "text": "two these two problem together we",
    "start": "1298120",
    "end": "1300039"
  },
  {
    "text": "introduce a custom serialized bat format",
    "start": "1300039",
    "end": "1303120"
  },
  {
    "text": "where we try to put all of the tensor",
    "start": "1303120",
    "end": "1305679"
  },
  {
    "text": "binaries uh into a single con buffer so",
    "start": "1305679",
    "end": "1308799"
  },
  {
    "text": "that this operations is done in the CPU",
    "start": "1308799",
    "end": "1311760"
  },
  {
    "text": "noes once we finalize the preparation of",
    "start": "1311760",
    "end": "1314159"
  },
  {
    "text": "a batch send them all the way to the GPU",
    "start": "1314159",
    "end": "1316799"
  },
  {
    "text": "noes and then finally only unpack Afters",
    "start": "1316799",
    "end": "1319799"
  },
  {
    "text": "the we are ready to move them to GPU",
    "start": "1319799",
    "end": "1321960"
  },
  {
    "text": "memories so the first impact of this is",
    "start": "1321960",
    "end": "1324880"
  },
  {
    "text": "now the serialized bed is now can",
    "start": "1324880",
    "end": "1327240"
  },
  {
    "text": "further fit into the r data interface",
    "start": "1327240",
    "end": "1329000"
  },
  {
    "text": "batters and it help us to move the",
    "start": "1329000",
    "end": "1331159"
  },
  {
    "text": "colate uh this expensive CPU operate the",
    "start": "1331159",
    "end": "1334080"
  },
  {
    "text": "final expensive operations out fromont",
    "start": "1334080",
    "end": "1336039"
  },
  {
    "text": "GPU",
    "start": "1336039",
    "end": "1337880"
  },
  {
    "text": "process the second effect is uh around",
    "start": "1337880",
    "end": "1340919"
  },
  {
    "text": "the fix of this data movement fun",
    "start": "1340919",
    "end": "1343919"
  },
  {
    "text": "overhead now we can reduce this o and",
    "start": "1343919",
    "end": "1346520"
  },
  {
    "text": "overhead to actually just 01 because we",
    "start": "1346520",
    "end": "1349200"
  },
  {
    "text": "now effectively only transfer one",
    "start": "1349200",
    "end": "1350760"
  },
  {
    "text": "columns so for example the pon have",
    "start": "1350760",
    "end": "1353520"
  },
  {
    "text": "drastically dropped from more than 40",
    "start": "1353520",
    "end": "1356240"
  },
  {
    "text": "more 400 millisecond to just sub 20",
    "start": "1356240",
    "end": "1360640"
  },
  {
    "text": "milliseconds right we talk about all of",
    "start": "1361919",
    "end": "1364080"
  },
  {
    "text": "these uh all of the three challenge here",
    "start": "1364080",
    "end": "1366679"
  },
  {
    "text": "then the final challenge is just the",
    "start": "1366679",
    "end": "1367919"
  },
  {
    "text": "missing uh data movement components that",
    "start": "1367919",
    "end": "1370840"
  },
  {
    "text": "we currently have the in the torch data",
    "start": "1370840",
    "end": "1373159"
  },
  {
    "text": "loader infa but it's missing the current",
    "start": "1373159",
    "end": "1375640"
  },
  {
    "text": "rate settings um so in the diagram it",
    "start": "1375640",
    "end": "1379159"
  },
  {
    "text": "shows like uh how how are the GPU",
    "start": "1379159",
    "end": "1382919"
  },
  {
    "text": "process Implement is pipelining to uh",
    "start": "1382919",
    "end": "1385120"
  },
  {
    "text": "move the data directly to uh the GPU",
    "start": "1385120",
    "end": "1387960"
  },
  {
    "text": "memory so the first thing we are missing",
    "start": "1387960",
    "end": "1390279"
  },
  {
    "text": "here is this pin memory uh stage where",
    "start": "1390279",
    "end": "1392880"
  },
  {
    "text": "uh in torch data older when we use when",
    "start": "1392880",
    "end": "1395640"
  },
  {
    "text": "the GQ process receive a b of data it",
    "start": "1395640",
    "end": "1398159"
  },
  {
    "text": "offer the functionality to move them uh",
    "start": "1398159",
    "end": "1401039"
  },
  {
    "text": "uh to pin memory uh as well uh the pin",
    "start": "1401039",
    "end": "1403840"
  },
  {
    "text": "memory is referred to the non page mod",
    "start": "1403840",
    "end": "1405799"
  },
  {
    "text": "memory uh in OS but the tldr is that",
    "start": "1405799",
    "end": "1408880"
  },
  {
    "text": "help us to speed out the GPU memory copy",
    "start": "1408880",
    "end": "1411480"
  },
  {
    "text": "in the later",
    "start": "1411480",
    "end": "1413159"
  },
  {
    "text": "stage so the second stage missing here",
    "start": "1413159",
    "end": "1416799"
  },
  {
    "text": "is that uh in our set in our previous",
    "start": "1416799",
    "end": "1419440"
  },
  {
    "text": "setup we also introduced additional",
    "start": "1419440",
    "end": "1421320"
  },
  {
    "text": "pipeline stage where we try to use",
    "start": "1421320",
    "end": "1423880"
  },
  {
    "text": "another CP thread plus the site C",
    "start": "1423880",
    "end": "1426360"
  },
  {
    "text": "streams to um preload a batch ahead of",
    "start": "1426360",
    "end": "1429880"
  },
  {
    "text": "time before the next um model Compu",
    "start": "1429880",
    "end": "1433559"
  },
  {
    "text": "executions so this effect is that once",
    "start": "1433559",
    "end": "1435760"
  },
  {
    "text": "the model finish the current",
    "start": "1435760",
    "end": "1436919"
  },
  {
    "text": "computations it can immediately start",
    "start": "1436919",
    "end": "1438880"
  },
  {
    "text": "the second one without waiting for the",
    "start": "1438880",
    "end": "1441679"
  },
  {
    "text": "moving the the batch in needed to GPU",
    "start": "1441679",
    "end": "1444200"
  },
  {
    "text": "memory it is already preloaded there",
    "start": "1444200",
    "end": "1446919"
  },
  {
    "text": "when it when you want to start the",
    "start": "1446919",
    "end": "1450840"
  },
  {
    "text": "computations so yeah so the final thing",
    "start": "1450960",
    "end": "1454000"
  },
  {
    "text": "we have to do is to add this two",
    "start": "1454000",
    "end": "1455880"
  },
  {
    "text": "pipeline stage into the um into our R uh",
    "start": "1455880",
    "end": "1459760"
  },
  {
    "text": "training setups in order to fit in more",
    "start": "1459760",
    "end": "1461960"
  },
  {
    "text": "into the M training ecosystem and then",
    "start": "1461960",
    "end": "1464919"
  },
  {
    "text": "make sure that we can offer that as much",
    "start": "1464919",
    "end": "1466840"
  },
  {
    "text": "as possible the non-computer overhead",
    "start": "1466840",
    "end": "1469360"
  },
  {
    "text": "with the GPU compute",
    "start": "1469360",
    "end": "1472760"
  },
  {
    "text": "itself so finally uh after we apply all",
    "start": "1473279",
    "end": "1476159"
  },
  {
    "text": "of this um optimization uh with the same",
    "start": "1476159",
    "end": "1479320"
  },
  {
    "text": "computer set up 1 p4d plus r uh 3 r7i we",
    "start": "1479320",
    "end": "1483600"
  },
  {
    "text": "can actually fit uh uh reach a pretty",
    "start": "1483600",
    "end": "1486640"
  },
  {
    "text": "good throughput 400k uh per seconds it",
    "start": "1486640",
    "end": "1489840"
  },
  {
    "text": "is like 3.6 times more than uh what we",
    "start": "1489840",
    "end": "1493760"
  },
  {
    "text": "pre initially have in this um in the",
    "start": "1493760",
    "end": "1496799"
  },
  {
    "text": "initial race setup it is also still 50%",
    "start": "1496799",
    "end": "1500120"
  },
  {
    "text": "more performance from the our or",
    "start": "1500120",
    "end": "1503480"
  },
  {
    "text": "original torch dealor setups with um uh",
    "start": "1503480",
    "end": "1507320"
  },
  {
    "text": "sparse tensor and ID sorted data set",
    "start": "1507320",
    "end": "1509720"
  },
  {
    "text": "applied now in our also latest",
    "start": "1509720",
    "end": "1512440"
  },
  {
    "text": "experiment we see a good scalability as",
    "start": "1512440",
    "end": "1514559"
  },
  {
    "text": "well we um when we performing complex Ro",
    "start": "1514559",
    "end": "1517600"
  },
  {
    "text": "sequence feature processing we are also",
    "start": "1517600",
    "end": "1520279"
  },
  {
    "text": "able to scale the CPU machine up to 32",
    "start": "1520279",
    "end": "1522760"
  },
  {
    "text": "nodes in order to achieve the same",
    "start": "1522760",
    "end": "1524880"
  },
  {
    "text": "througho number",
    "start": "1524880",
    "end": "1526960"
  },
  {
    "text": "here so some of the general learning",
    "start": "1526960",
    "end": "1529320"
  },
  {
    "text": "here's um rexus models in Pinterest",
    "start": "1529320",
    "end": "1532200"
  },
  {
    "text": "really moving to our data intensive U",
    "start": "1532200",
    "end": "1534720"
  },
  {
    "text": "world where we try to consume larger and",
    "start": "1534720",
    "end": "1536760"
  },
  {
    "text": "larger Ro sequence features adding more",
    "start": "1536760",
    "end": "1539320"
  },
  {
    "text": "complex in trainer data processing in",
    "start": "1539320",
    "end": "1541120"
  },
  {
    "text": "order to do experiment faster uh so we",
    "start": "1541120",
    "end": "1544679"
  },
  {
    "text": "really need this Ray hetrogeneous",
    "start": "1544679",
    "end": "1546080"
  },
  {
    "text": "cluster in order to break out the fixed",
    "start": "1546080",
    "end": "1548520"
  },
  {
    "text": "CPU to GPU resource uh",
    "start": "1548520",
    "end": "1551159"
  },
  {
    "text": "constraint and now efficient efficiency",
    "start": "1551159",
    "end": "1553720"
  },
  {
    "text": "of the training is still a complex",
    "start": "1553720",
    "end": "1555399"
  },
  {
    "text": "problem it not only need GPU compute to",
    "start": "1555399",
    "end": "1557320"
  },
  {
    "text": "be fast but also data loading and even",
    "start": "1557320",
    "end": "1559760"
  },
  {
    "text": "the data movement funnels to be uh",
    "start": "1559760",
    "end": "1562240"
  },
  {
    "text": "performant um so uh some of the useful",
    "start": "1562240",
    "end": "1565679"
  },
  {
    "text": "tip with disc cover is that um we want",
    "start": "1565679",
    "end": "1568039"
  },
  {
    "text": "to reduce the physical bites needed to",
    "start": "1568039",
    "end": "1570640"
  },
  {
    "text": "be transferred across the entire funnels",
    "start": "1570640",
    "end": "1573320"
  },
  {
    "text": "for all of the CPU operation we want to",
    "start": "1573320",
    "end": "1576039"
  },
  {
    "text": "move it uh move most of them uh as much",
    "start": "1576039",
    "end": "1579640"
  },
  {
    "text": "as possible out from the GPU process",
    "start": "1579640",
    "end": "1582360"
  },
  {
    "text": "into the pipon itself and for those",
    "start": "1582360",
    "end": "1584799"
  },
  {
    "text": "critical path that we cannot move we",
    "start": "1584799",
    "end": "1586559"
  },
  {
    "text": "want to make sure Al that to uh GPU",
    "start": "1586559",
    "end": "1590360"
  },
  {
    "text": "compute as much as possible so that",
    "start": "1590360",
    "end": "1592279"
  },
  {
    "text": "minimize the overhead coming from the",
    "start": "1592279",
    "end": "1594720"
  },
  {
    "text": "from this data",
    "start": "1594720",
    "end": "1596840"
  },
  {
    "text": "movement and then finally we really",
    "start": "1596840",
    "end": "1598919"
  },
  {
    "text": "provide this uh really good",
    "start": "1598919",
    "end": "1600399"
  },
  {
    "text": "scalabilities and also in the same time",
    "start": "1600399",
    "end": "1602520"
  },
  {
    "text": "is flexible for us to customiz any",
    "start": "1602520",
    "end": "1605200"
  },
  {
    "text": "optimization we want to fit in our own",
    "start": "1605200",
    "end": "1607679"
  },
  {
    "text": "ml training uh",
    "start": "1607679",
    "end": "1611278"
  },
  {
    "text": "systems cool uh finally just want to",
    "start": "1611520",
    "end": "1614520"
  },
  {
    "text": "mention that this work cannot be done",
    "start": "1614520",
    "end": "1616120"
  },
  {
    "text": "just by two of us and then this is",
    "start": "1616120",
    "end": "1618360"
  },
  {
    "text": "actually a lot of a lot more Works done",
    "start": "1618360",
    "end": "1620200"
  },
  {
    "text": "by multiple engineers in ml training uh",
    "start": "1620200",
    "end": "1622600"
  },
  {
    "text": "in pin ml platform and ml Engineers also",
    "start": "1622600",
    "end": "1625640"
  },
  {
    "text": "any skill engineer as well so just want",
    "start": "1625640",
    "end": "1628000"
  },
  {
    "text": "to give a quick echnology and shout out",
    "start": "1628000",
    "end": "1630159"
  },
  {
    "text": "to to them to make make this work",
    "start": "1630159",
    "end": "1634320"
  },
  {
    "text": "happens let's con",
    "start": "1634720",
    "end": "1636990"
  },
  {
    "text": "[Applause]",
    "start": "1636990",
    "end": "1641150"
  }
]
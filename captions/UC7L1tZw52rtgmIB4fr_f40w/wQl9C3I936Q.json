[
  {
    "text": "thank you uh so good afternoon everyone and today I'll be presenting gorilla",
    "start": "4860",
    "end": "10320"
  },
  {
    "text": "which is a joint work with my collaborators and Tianjin and I lead the project so let's look at the state of the world",
    "start": "10320",
    "end": "16680"
  },
  {
    "text": "today uh when you need to use an llm you as a user are at the center of uh you",
    "start": "16680",
    "end": "24060"
  },
  {
    "text": "know the task where you might go ahead and use your chat completion API or use chest your UI and then talk to the llm",
    "start": "24060",
    "end": "31320"
  },
  {
    "text": "right so you prompt the llm it gives you a response and then you take this response and it's up to you to go and",
    "start": "31320",
    "end": "37380"
  },
  {
    "text": "perform some action on the world and then see how the world responds right so fundamentally you're going to perform",
    "start": "37380",
    "end": "43559"
  },
  {
    "text": "the action and then you're going to get the response back I've shown this as zero shot interactions as in one back",
    "start": "43559",
    "end": "49200"
  },
  {
    "text": "and forth but you might have multiple back and forth but fundamentally the",
    "start": "49200",
    "end": "54600"
  },
  {
    "text": "burden lies on you to interact with the llm get the response perform some",
    "start": "54600",
    "end": "59760"
  },
  {
    "text": "activity and then get the response back and then basically relay information to and forth for the llm right so this is",
    "start": "59760",
    "end": "65640"
  },
  {
    "text": "how you tend to use uh the alarm today and there's one to many llms to choose from",
    "start": "65640",
    "end": "72180"
  },
  {
    "text": "now what we want to do and enable is actually flip this and say what if you are on the extreme end what if you go on",
    "start": "72180",
    "end": "79020"
  },
  {
    "text": "the left hand side and then you talk to the llm by asking the llm hey look I want to do X so",
    "start": "79020",
    "end": "85020"
  },
  {
    "text": "you're prompting the llm and now the llm is going to go and perform the activity on the rest of the",
    "start": "85020",
    "end": "90780"
  },
  {
    "text": "world and then you get a response and then you relay the response back to you as a user right so this is the vision",
    "start": "90780",
    "end": "96540"
  },
  {
    "text": "that we want to enable this is all too abstract to ground this in one example we're all machine",
    "start": "96540",
    "end": "103140"
  },
  {
    "text": "learning researchers over here or we use it in some sense and today the most cash commodity is gpus right so say",
    "start": "103140",
    "end": "110520"
  },
  {
    "text": "suppose you have to ask the question hey can I get an 800 GPU in East us now this is the prompt that you give to the llm",
    "start": "110520",
    "end": "117000"
  },
  {
    "text": "and what you want the model to do is go ahead and do a bunch of things right one is read the state of the world okay does",
    "start": "117000",
    "end": "122759"
  },
  {
    "text": "this user have quota on your favorite cloud provider to on this particular region is there",
    "start": "122759",
    "end": "129060"
  },
  {
    "text": "availability for this particular GPU and if so return that back to you as the user so we don't want you doing this",
    "start": "129060",
    "end": "135180"
  },
  {
    "text": "where you go and ask hey how do I get this it gives you a bunch of commands or it tells you what to do on the UI and then you as a user go and do this on the",
    "start": "135180",
    "end": "141720"
  },
  {
    "text": "UI that is not what we want can you just talk to the llm the llm performs the activity on the UI and then it tells you",
    "start": "141720",
    "end": "148379"
  },
  {
    "text": "what's going on and you can either accept or reject the response that you get so why is this is because humans are",
    "start": "148379",
    "end": "154620"
  },
  {
    "text": "good discriminators we're not good generators so let the generative AI model which by",
    "start": "154620",
    "end": "160140"
  },
  {
    "text": "definition is generative do the generation task for you and you just discriminate and say hey do I accept this response or do I reject this",
    "start": "160140",
    "end": "166500"
  },
  {
    "text": "response right so that's that's the idea over here so in this case the llm that we have trained is called gorilla so you",
    "start": "166500",
    "end": "173519"
  },
  {
    "text": "basically invoke gorilla and then Gola recognizes that you know to give you a GPU uh in East U.S I'm going to use",
    "start": "173519",
    "end": "179280"
  },
  {
    "text": "azure and then I'm going to give you uh back the SSH access to your particular GPU",
    "start": "179280",
    "end": "185580"
  },
  {
    "text": "now so this is an example of how you can invoke and hyperscaler but obviously",
    "start": "185580",
    "end": "190980"
  },
  {
    "text": "there are one too many apis that you might want to use so just remote clicker works stochastically sometimes it does",
    "start": "190980",
    "end": "197159"
  },
  {
    "text": "sometimes it doesn't okay there you go so you know similar to",
    "start": "197159",
    "end": "203519"
  },
  {
    "text": "one example of hyperscaler suppose you say Hey look I want to do X and then you teach your",
    "start": "203519",
    "end": "209280"
  },
  {
    "text": "gorilla model to call the apis to do X and then return the response to you now the obvious question is why apis right",
    "start": "209280",
    "end": "216840"
  },
  {
    "text": "so to tell this let me tell you how we start with the gorilla project sometime around November and December of last",
    "start": "216840",
    "end": "222180"
  },
  {
    "text": "year as llms came to the scene and we were early adopters of charge Equity like everybody else one thing we",
    "start": "222180",
    "end": "228120"
  },
  {
    "text": "realized is that chatting is great demonstration of the two but it's not something that you might want to do on a",
    "start": "228120",
    "end": "233220"
  },
  {
    "text": "day-to-day basis right like here you're sitting in a talk to get information it's not too great if I start chatting",
    "start": "233220",
    "end": "238440"
  },
  {
    "text": "with a few of you and during lunch or doing skiing you might want to chat but to get work done you don't want to",
    "start": "238440",
    "end": "245280"
  },
  {
    "text": "chat but you instead just want to use a tool to get work done so GitHub co-pilot is a good example all right rather than",
    "start": "245280",
    "end": "250620"
  },
  {
    "text": "chatting you ask it what needs to be done it gives you the code and you're done so what does this mean an llm is a",
    "start": "250620",
    "end": "256440"
  },
  {
    "text": "powerful tool but a tool nonetheless and one thing we know is that the way you argument tools to be more useful is by",
    "start": "256440",
    "end": "262740"
  },
  {
    "text": "connecting it to other tools right so it's only when you connect tools together do the tools become more and more powerful",
    "start": "262740",
    "end": "268380"
  },
  {
    "text": "well that's great so how do you connect Tools in computer science right and so the answer is in computer science when",
    "start": "268380",
    "end": "274199"
  },
  {
    "text": "you have different computer systems the way they talk to each other is through API calls apis is how different computer systems interact with each other that's",
    "start": "274199",
    "end": "280440"
  },
  {
    "text": "the promise and the return interface right so that's how we thought of building gorilla okay look you know a",
    "start": "280440",
    "end": "285840"
  },
  {
    "text": "lot of people are saying hey we want to connect this we want to do a bunch of things can we now just teach the llm how",
    "start": "285840",
    "end": "291600"
  },
  {
    "text": "do you invoke apis and by doing this you're taking the llm to use other tools and this was the thought process",
    "start": "291600",
    "end": "297240"
  },
  {
    "text": "ah you know we are trying to write a machine learning paper so we start off with hugging face tensorflow and pytorch",
    "start": "297240",
    "end": "302639"
  },
  {
    "text": "apis and then we realized it's not very many people who call hugging face apis on The Daily outside of machine learning",
    "start": "302639",
    "end": "308520"
  },
  {
    "text": "researchers right but we got a lot of feedback from users saying that hey look you know we use kubernetes on The Daily but that's so hard there's so so much",
    "start": "308520",
    "end": "315360"
  },
  {
    "text": "going on can you help can you you know give us gorilla that strain to use kubernetes calls so since then we have",
    "start": "315360",
    "end": "320580"
  },
  {
    "text": "gone ahead and added some more apis there's more and more that we are adding where you can just talk to the llm and",
    "start": "320580",
    "end": "325620"
  },
  {
    "text": "the llm is going to call it the apis for you so great so that's all talk uh before I",
    "start": "325620",
    "end": "331080"
  },
  {
    "text": "proceed let me just show you a quick demo so you know that this actually works so once once you teach an llm to call",
    "start": "331080",
    "end": "338220"
  },
  {
    "text": "apis you can hopefully this is visible so once you teach an llam to call apis you can wrap this in different form",
    "start": "338220",
    "end": "344460"
  },
  {
    "text": "factors right so one form factor here is the CLI tool so for example I can say",
    "start": "344460",
    "end": "349560"
  },
  {
    "text": "things like gorilla list all my gcp instances let's be",
    "start": "349560",
    "end": "356820"
  },
  {
    "text": "so if we do here is go ahead and actually go and call gorilla then we show you a bunch of options right so then you pick which option you want uh",
    "start": "356820",
    "end": "364080"
  },
  {
    "text": "let me just go with the first one so now this runs this API so this is like a command line API and then Returns the",
    "start": "364080",
    "end": "369840"
  },
  {
    "text": "response for you so I have a bunch of VMS running so on and so forth right so this is one modality now you can use the",
    "start": "369840",
    "end": "376080"
  },
  {
    "text": "same model but wrap it up in another uh different form factor which is you know",
    "start": "376080",
    "end": "381419"
  },
  {
    "text": "how do I integrate apis into my workflows so here's the example where we integrate this with long chain ah",
    "start": "381419",
    "end": "388680"
  },
  {
    "text": "which is a popular workflow manager and so the interface is pretty simple right so some of you may have used the chat",
    "start": "388680",
    "end": "394979"
  },
  {
    "text": "completion API all you do is instead of hitting the end point you hit a small boxer sitting in Berkeley",
    "start": "394979",
    "end": "401220"
  },
  {
    "text": "and then the question you ask is simple look can I I want to translate from English to Chinese go",
    "start": "401220",
    "end": "408060"
  },
  {
    "text": "so what gorilla does is it responds with a bunch of API call and to make it more usable we also give some additional",
    "start": "408060",
    "end": "413880"
  },
  {
    "text": "information so this is a natural language processing task here's the API call uh you know this is provided by",
    "start": "413880",
    "end": "421560"
  },
  {
    "text": "this particular API provider which is hugging face in this case some interpretability explanation and then this is basically the code",
    "start": "421560",
    "end": "428100"
  },
  {
    "text": "right and the best part about this is you can just execute this code this is a simple exact call that you do and what you get",
    "start": "428100",
    "end": "434639"
  },
  {
    "text": "as a response is the translation of what are the differences between renewable and non-renewable energy",
    "start": "434639",
    "end": "440280"
  },
  {
    "text": "resources right so this is one example where look you know you can ask an llm to do this for",
    "start": "440280",
    "end": "445919"
  },
  {
    "text": "you translate X but how do you know it hallucinates how do you know it's exactly what you want it to be instead of that there are tools today that can",
    "start": "445919",
    "end": "451740"
  },
  {
    "text": "do what you want to do very precisely without hallucination so why not just invoke those tools right so you use your",
    "start": "451740",
    "end": "457560"
  },
  {
    "text": "llm for the reasoning task for all the good things that comes with it but when you want more clear and deterministic",
    "start": "457560",
    "end": "463860"
  },
  {
    "text": "responses just use different tools that do that for you and this is one and I've hopefully shown you two examples where",
    "start": "463860",
    "end": "469199"
  },
  {
    "text": "you can wrap around your API calls in different modalities and form factors that you would need",
    "start": "469199",
    "end": "475259"
  },
  {
    "text": "so by the way this the demo that I showed you is live you can you can scan this I'll just go to our",
    "start": "475259",
    "end": "481500"
  },
  {
    "text": "website and we'll link you hopefully all of you won't try at the same time and break it but uh yeah so now I've shown you that it works",
    "start": "481500",
    "end": "489000"
  },
  {
    "text": "let me actually go and answer what what enabled this right so what are some of the interesting research questions we",
    "start": "489000",
    "end": "494580"
  },
  {
    "text": "had to solve to enable uh how to teach an llm to use apis so the first question and I think this",
    "start": "494580",
    "end": "501060"
  },
  {
    "text": "is probably one of the big questions for all of you are trying to use our alarms is how do you mix fine tuning and retrieval",
    "start": "501060",
    "end": "506639"
  },
  {
    "text": "right uh what's the wisdom of the crowd",
    "start": "506639",
    "end": "511759"
  },
  {
    "text": "great that is not intended",
    "start": "512339",
    "end": "518520"
  },
  {
    "text": "ah but that's okay okay",
    "start": "518520",
    "end": "524580"
  },
  {
    "text": "so the hypothesis today is that fine tuning is used to argument the behavior of the model and by fine tuning I'm referring to both the instruct tuning",
    "start": "524580",
    "end": "531120"
  },
  {
    "text": "and rlhf and retrieval is what you use to introduce a new knowledge to the model right so this is when you have out",
    "start": "531120",
    "end": "536459"
  },
  {
    "text": "of domain information or when you want to like introduce freshness of data into the model",
    "start": "536459",
    "end": "541680"
  },
  {
    "text": "but what we really find is that fine tuning is actually remarkable at both behavior and inducing knowledge into the",
    "start": "541680",
    "end": "549000"
  },
  {
    "text": "model except you still need retrievers because the help you know they help ground the",
    "start": "549000",
    "end": "555120"
  },
  {
    "text": "llm especially when you don't want to be wrong so you can say look I want you to use this piece of information to answer the question to me this is even more",
    "start": "555120",
    "end": "561660"
  },
  {
    "text": "critical if you're trying to like you know serve an llm from your proprietary data but you may not be comfortable fine",
    "start": "561660",
    "end": "566880"
  },
  {
    "text": "tuning but can you give it as a retriever except there's one thing that we know from the recommendation ranking systems",
    "start": "566880",
    "end": "573180"
  },
  {
    "text": "is that retrievals are actually pretty bad right uh how many of you have heard of bm25",
    "start": "573180",
    "end": "579540"
  },
  {
    "text": "I see a few hands go up that's like the working House of retrievers right how accurate do you think bm25 is okay",
    "start": "579540",
    "end": "585360"
  },
  {
    "text": "so I need to uh ground this question by accuracy I mean recall at K which means if I were to give you K options to",
    "start": "585360",
    "end": "591720"
  },
  {
    "text": "retrieve the answer can you be right at least to one of the K times so people typically do recall at three recall it",
    "start": "591720",
    "end": "596880"
  },
  {
    "text": "five recall it and so on and so forth and one thing that's well known outside of llms is that retrievers are actually",
    "start": "596880",
    "end": "603120"
  },
  {
    "text": "pretty bad all right so retrievers are like maybe 50 maybe 70 accurate it's your re-ranking that makes it uh better",
    "start": "603120",
    "end": "609600"
  },
  {
    "text": "but you can never do you can never be too good at building a retriever if you were to build a retriever that's like 99",
    "start": "609600",
    "end": "615060"
  },
  {
    "text": "accurate over billion scale then you basically build the next Google right so retrievers are bad so then how do you",
    "start": "615060",
    "end": "621480"
  },
  {
    "text": "solve it now to answer this what we came up with is this solution called retrieval of our",
    "start": "621480",
    "end": "627000"
  },
  {
    "text": "training right so the key takeaway is pretty simple the idea is you want to fine tune the",
    "start": "627000",
    "end": "633480"
  },
  {
    "text": "model to use or ignore the retrieved context right so you ask a question hey I want",
    "start": "633480",
    "end": "639240"
  },
  {
    "text": "to do X the model comes up with an answer you need to implicitly make this one bit information is this relevant to",
    "start": "639240",
    "end": "645180"
  },
  {
    "text": "me or is this not relevant to me if the retrieved information is relevant to the llm then use it",
    "start": "645180",
    "end": "651420"
  },
  {
    "text": "if the retrieved information is not relevant to the llm then just discard it except this is implicit right ah so I'll",
    "start": "651420",
    "end": "658260"
  },
  {
    "text": "give an example and hopefully that will make it more clear but that's the simple idea and the way you train this is by",
    "start": "658260",
    "end": "663300"
  },
  {
    "text": "introducing both correct and incorrect retrieved results during instruction fine tuning so the takeaway is your retrievers are",
    "start": "663300",
    "end": "669360"
  },
  {
    "text": "going to be inaccurate take the BM 25 Which is popular or take like you know GPD index or whatever retrievers",
    "start": "669360",
    "end": "676200"
  },
  {
    "text": "that you want it doesn't matter if your retrievers are stored in a vector DB it doesn't matter if you use Phi is an sfw uh",
    "start": "676200",
    "end": "683399"
  },
  {
    "text": "uh hnsw Etc it doesn't matter what similarity search that you use but fundamentally your retrievers are going",
    "start": "683399",
    "end": "689040"
  },
  {
    "text": "to be inaccurate can you teach the model to be robust to that so that's the high level idea",
    "start": "689040",
    "end": "695300"
  },
  {
    "text": "ah right so in short you know there's been a lot of debate where some people may use fine",
    "start": "695360",
    "end": "701760"
  },
  {
    "text": "tuning uh some people are like a fine tuning is not very relevant I don't want to give Cloud providers or language",
    "start": "701760",
    "end": "707880"
  },
  {
    "text": "models my data so then some people say Hey you know use retrieval retrieval augmented generation rack based",
    "start": "707880",
    "end": "714000"
  },
  {
    "text": "techniques but this may not be accurate either uh and some people say hey can we actually balance the two what's the",
    "start": "714000",
    "end": "720240"
  },
  {
    "text": "question and we say don't even do that right you can't pick one or the other and if you're trying to balance the two that may not work instead do what we",
    "start": "720240",
    "end": "726779"
  },
  {
    "text": "call is the retrieval of our training so here's an example to help understand",
    "start": "726779",
    "end": "731820"
  },
  {
    "text": "that better so the user prompt is ah I am an engineer at Uber I need to",
    "start": "731820",
    "end": "737640"
  },
  {
    "text": "find an API that can classify pedestrians cost Etc from an image of the scene right simple",
    "start": "737640",
    "end": "743040"
  },
  {
    "text": "self-driving car tell me if there are people of the cars now you can use rag so for those of you",
    "start": "743040",
    "end": "748800"
  },
  {
    "text": "who are not aware rag is where you take the question go to your vector DB find the most relevant documents and stick it in as a part of your prompt",
    "start": "748800",
    "end": "756120"
  },
  {
    "text": "and when you use rag I've shown top K by k equals one over here it says hey look this looks like an object detection task",
    "start": "756120",
    "end": "763079"
  },
  {
    "text": "seems reasonable why don't you use the hybrid Nets model right so what the llm",
    "start": "763079",
    "end": "769200"
  },
  {
    "text": "is supposed to do is first ask the question is this relevant",
    "start": "769200",
    "end": "774480"
  },
  {
    "text": "is this user is this API that I retrieved relevant for the user prompt",
    "start": "774480",
    "end": "779639"
  },
  {
    "text": "if it is I'm going to use that and then respond to the user on the other hand if the retriever gave",
    "start": "779639",
    "end": "786839"
  },
  {
    "text": "you uh in this case a neural machine translation API then it's not in I mean if you want to",
    "start": "786839",
    "end": "793079"
  },
  {
    "text": "do object detection a translation API is not going to help so here the we teach the llm",
    "start": "793079",
    "end": "798720"
  },
  {
    "text": "to answer this question implicitly look you know this retrieved document looks inaccurate so I'm going to discard it",
    "start": "798720",
    "end": "805019"
  },
  {
    "text": "and I'm instead going to use information that I have as a part of my pre-training or fine tuning phase right so it's",
    "start": "805019",
    "end": "810300"
  },
  {
    "text": "simple retrievers are inaccurate teacher model to be robust to it",
    "start": "810300",
    "end": "815339"
  },
  {
    "text": "ah before I move on to the next part of the talk any questions",
    "start": "815339",
    "end": "820920"
  },
  {
    "text": "on this yes question",
    "start": "820920",
    "end": "824420"
  },
  {
    "text": "yeah great question and so the to repeat the question for those of you who",
    "start": "833279",
    "end": "838620"
  },
  {
    "text": "current here is that can you instead of doing top one like pick top thousand right and hope at least one of them is correct and then give that to the llm",
    "start": "838620",
    "end": "845639"
  },
  {
    "text": "and the short answer is yes and no uh yes in the sense there's been some work that shows that big thousand and then",
    "start": "845639",
    "end": "852120"
  },
  {
    "text": "re-rank it by some other metric and then give that to the llm all right but no",
    "start": "852120",
    "end": "857579"
  },
  {
    "text": "because of two reasons one it's been shown that the more and more documents that you retrieve and give it to the llm",
    "start": "857579",
    "end": "862620"
  },
  {
    "text": "the more and more you're confusing it right and you cannot guarantee that at least one of those thousand has your",
    "start": "862620",
    "end": "868860"
  },
  {
    "text": "answer basically you don't get 100 recall right and there's a third practical aspect of it which is some",
    "start": "868860",
    "end": "874380"
  },
  {
    "text": "more documents you give you're running out of context length that becomes you especially uh acute when you do some",
    "start": "874380",
    "end": "880079"
  },
  {
    "text": "tasks like this right because there are 101 machine learning models and the constraint will tell you what's more",
    "start": "880079",
    "end": "885300"
  },
  {
    "text": "critical right for example if you say hey can I run this on a Raspberry Pi you probably can't run this you might want to use like a YOLO V5 or some of the",
    "start": "885300",
    "end": "891899"
  },
  {
    "text": "smaller models but if you say look I want the top and accuracy to be 96 on image net top one et cetera then",
    "start": "891899",
    "end": "898199"
  },
  {
    "text": "probably you want to use some of the vision Transformer style models so yes I know yes you can try to improve",
    "start": "898199",
    "end": "904500"
  },
  {
    "text": "the percentage by a few percentage points but it's not going to be 100 accurate right",
    "start": "904500",
    "end": "910740"
  },
  {
    "text": "does that make sense yeah I think there's another hand there and then I can come to you uh so the question is",
    "start": "910740",
    "end": "919399"
  },
  {
    "text": "yeah so a lot of the metrics today uh it's a good question we don't have clear",
    "start": "928519",
    "end": "933959"
  },
  {
    "text": "answers but the closest answer is from the recommendation ranking Community because that's where you typically have",
    "start": "933959",
    "end": "939360"
  },
  {
    "text": "K documents a user comes with a question and then you try to match it and so recall that case seems to be a good offline metric right uh obviously you",
    "start": "939360",
    "end": "947579"
  },
  {
    "text": "may not have offline metrics all the time and if you have the benefit then you have click-through rate and a bunch of other metrics but typically recall it",
    "start": "947579",
    "end": "953040"
  },
  {
    "text": "case it could offline metric to optimize over I think I can take one more question before I proceed yes",
    "start": "953040",
    "end": "959540"
  },
  {
    "text": "instead of making the mother um you know more context that finds irrelevant which",
    "start": "972540",
    "end": "982699"
  },
  {
    "text": "you should bending order to make to make it return more relevant contact great",
    "start": "983160",
    "end": "988560"
  },
  {
    "text": "question for which I have the next question for you how much has given for hallucinate",
    "start": "988560",
    "end": "995779"
  },
  {
    "text": "uh yeah suppose you just use the gbd for zero six one two any of your favorite",
    "start": "996980",
    "end": "1003380"
  },
  {
    "text": "checkpoint models but there's a generic question right if I were to ask you how much do llms hallucinate is there an",
    "start": "1003380",
    "end": "1009139"
  },
  {
    "text": "answer and the answers I've heard is mostly oh a lot not so much works on my task more",
    "start": "1009139",
    "end": "1015800"
  },
  {
    "text": "than 3.5 less than llama so on and so forth but these are you know it's not it's not",
    "start": "1015800",
    "end": "1021980"
  },
  {
    "text": "a very scientific metric to work with uh which also comes to your question is that how do you how do you solve something when you",
    "start": "1021980",
    "end": "1027438"
  },
  {
    "text": "can't measure it and so the first thing that we want to do which we did with kodala is give a framework where you can actually measure hallucination",
    "start": "1027439",
    "end": "1034579"
  },
  {
    "text": "now I want to preface this by saying is that this works great for API calls it could be generalized to a few domains",
    "start": "1034579",
    "end": "1040040"
  },
  {
    "text": "but it may not generalize to all the domains right like for example sometimes the prompt is not accurate if I were to",
    "start": "1040040",
    "end": "1045319"
  },
  {
    "text": "ask when was Michael Jordan born well is it Michael Jordan the basketball player which most of you may be thinking",
    "start": "1045319",
    "end": "1050660"
  },
  {
    "text": "or if you're from Berkeley Is It Michael Jordan the professor of machine learning all right so it's hard to tell even for",
    "start": "1050660",
    "end": "1056240"
  },
  {
    "text": "us as users but given the API domains that we have it's pretty easy to not easy but we have a technique to merge",
    "start": "1056240",
    "end": "1061700"
  },
  {
    "text": "hallucination right so how do we do that the technique that we use is something called the as3 subtree matching right",
    "start": "1061700",
    "end": "1068120"
  },
  {
    "text": "the abstract syntax Trace are three matching so suppose the API that's generated is the following it's Dodge Hub load by",
    "start": "1068120",
    "end": "1074660"
  },
  {
    "text": "torch Vision dance net one to one pretend equals to it doesn't matter if you know this API or not but this is basically an API that exists",
    "start": "1074660",
    "end": "1081260"
  },
  {
    "text": "the first thing that we do is we go ahead and we build a syntax tree from this API call right uh so and this",
    "start": "1081260",
    "end": "1087919"
  },
  {
    "text": "includes all the arguments the next thing that I do is ask a simple question is this API a proper subset of my",
    "start": "1087919",
    "end": "1096260"
  },
  {
    "text": "Universal set of apis now we can do this in apis because look",
    "start": "1096260",
    "end": "1101299"
  },
  {
    "text": "if your stripe and you expose a bunch of apis you only have those apis to work with a user cannot come up with a new API to",
    "start": "1101299",
    "end": "1107840"
  },
  {
    "text": "call right as a service you know up front what apis is available and unlike a lot of other domains where",
    "start": "1107840",
    "end": "1114260"
  },
  {
    "text": "there's been a lot of legal concerns and oh can I use this data can I not use this data the incentives are very well aligned there is an incentive for Google",
    "start": "1114260",
    "end": "1121580"
  },
  {
    "text": "Cloud to let you know about their apis because the more you use them the more they make money right so there's great",
    "start": "1121580",
    "end": "1126919"
  },
  {
    "text": "tutorials documentation Swagger files open API spec Etc so you can use all this information to understand clearly",
    "start": "1126919",
    "end": "1133760"
  },
  {
    "text": "what apis is available and then ask the simple question is this a proper subset of this",
    "start": "1133760",
    "end": "1139820"
  },
  {
    "text": "and in this case we find that it is uh this is the brown part that I've highlighted right so you can see some",
    "start": "1139820",
    "end": "1146059"
  },
  {
    "text": "minor implementation details like pre-20 equals true is not checked because that's an optional argument in Python",
    "start": "1146059",
    "end": "1151280"
  },
  {
    "text": "but you basically ask the question is my API that the llm generated a proper subset of what's needed if it is then",
    "start": "1151280",
    "end": "1158000"
  },
  {
    "text": "it's not hallucinated by no means it means it's accurate but at least it's not hallucinated right if this were to",
    "start": "1158000",
    "end": "1164240"
  },
  {
    "text": "say use rehab load then you know it's inaccurate right rate is many other things but this is not one of those so",
    "start": "1164240",
    "end": "1170539"
  },
  {
    "text": "that's how you know what's hallucinated what's not great so how well does gorilla perform",
    "start": "1170539",
    "end": "1175820"
  },
  {
    "text": "I've told you the two questions we had to answer to Bill gorilla one is how do you make it robust retrievers second is",
    "start": "1175820",
    "end": "1181100"
  },
  {
    "text": "how do you measure hallucination let's actually go ahead and measure hallucinations here gorilla performs right so the prompt is simple",
    "start": "1181100",
    "end": "1187820"
  },
  {
    "text": "help me find an API to convert the spoken language in recorded audio to text right and we know that there's a bunch of apis to do that today",
    "start": "1187820",
    "end": "1195559"
  },
  {
    "text": "this is how gpd4 performs where it tends to hallucinate uh Claude does not hallucinate comes with the library that",
    "start": "1195559",
    "end": "1201260"
  },
  {
    "text": "does not is not the right task uh with Gorilla we are able to come up",
    "start": "1201260",
    "end": "1206360"
  },
  {
    "text": "with and write API call if there's one thing that you need to know about researchers giving a talk is that all results are Cherry Picked right",
    "start": "1206360",
    "end": "1212840"
  },
  {
    "text": "and so this is now uh there's an exception so there's a Cherry Picked result so let's try to go and",
    "start": "1212840",
    "end": "1218240"
  },
  {
    "text": "understand how well does gorilla perform across the board so over here what you have on the",
    "start": "1218240",
    "end": "1223280"
  },
  {
    "text": "y-axis's accuracy and on the x-axis is hallucination lower is better for hallucination higher is better for",
    "start": "1223280",
    "end": "1229580"
  },
  {
    "text": "accuracy keep in mind one does not imply the other right so if I were to ask how do I",
    "start": "1229580",
    "end": "1234679"
  },
  {
    "text": "receive money if it says use the stripe API that's accurate but if it says use pytorch API then it's not accurate but",
    "start": "1234679",
    "end": "1242840"
  },
  {
    "text": "uh it's not hallucinated it's also not but it's excuse me it's not accurate but it is also not hallucinated part of",
    "start": "1242840",
    "end": "1250220"
  },
  {
    "text": "JPI access but if it were to say use shisher API then that doesn't access so then you know it's hallucinated all",
    "start": "1250220",
    "end": "1256280"
  },
  {
    "text": "right so you want to be lower and better and what I show is so we call the zero shot where you ask the prompt get a response this is how we would use",
    "start": "1256280",
    "end": "1262460"
  },
  {
    "text": "chargeupt today and you see that gorilla performs better than most closed source and open source",
    "start": "1262460",
    "end": "1268100"
  },
  {
    "text": "machine learning models now you can go ahead and augment this with a retriever so the gbt retriever is state of data",
    "start": "1268100",
    "end": "1274520"
  },
  {
    "text": "retriever today and I also included the Oracle retriever to answer some of the questions which is what happens if you improve the",
    "start": "1274520",
    "end": "1280039"
  },
  {
    "text": "embedding model right this is when your recall top k equals one is hundred percent this is if God gave you the",
    "start": "1280039",
    "end": "1286580"
  },
  {
    "text": "right answer all the time and this is to show you the Headroom right and how well you can perform and",
    "start": "1286580",
    "end": "1291620"
  },
  {
    "text": "as you can see across most techniques including zero show GPT and Oracle retriever uh gorilla matches if not",
    "start": "1291620",
    "end": "1299659"
  },
  {
    "text": "beats open source but also more interestingly closed Source models like gpd4 3.5 and Cloud",
    "start": "1299659",
    "end": "1305840"
  },
  {
    "text": "and since we have just metric this also helps you answer a lot of questions that you know people you know you saw this on",
    "start": "1305840",
    "end": "1311600"
  },
  {
    "text": "some social social media platforms but it wasn't really validated which is cheapt4 hallucinates more than 3.5 so",
    "start": "1311600",
    "end": "1318500"
  },
  {
    "text": "you can like you know for your tasks sometimes you require more hallucination if it's like a generative AI task sometimes if you're trying to like",
    "start": "1318500",
    "end": "1324500"
  },
  {
    "text": "answer the question based on Q a style summarization translation Etc you might want to use less hallucination so you",
    "start": "1324500",
    "end": "1330559"
  },
  {
    "text": "can also use this as a metric to measure and determine which model you want to use",
    "start": "1330559",
    "end": "1336640"
  },
  {
    "text": "okay uh so you know we're part of a research lab and when we present research we usually get a bunch of",
    "start": "1336980",
    "end": "1342980"
  },
  {
    "text": "feedback one of the feedback we got from practitioners is that but look apis constantly evolve right there are some",
    "start": "1342980",
    "end": "1349400"
  },
  {
    "text": "mature apis that are G8 but for the apis that are you know being built or in development apis evolve maybe weekly",
    "start": "1349400",
    "end": "1357559"
  },
  {
    "text": "sometimes even monthly right but how often do you train an llm or even find your net maybe once every six months",
    "start": "1357559",
    "end": "1363080"
  },
  {
    "text": "once every year this is because even if you have even if you could afford fine-tuning LMS evaluation is so hard",
    "start": "1363080",
    "end": "1368480"
  },
  {
    "text": "that you might think twice before deploying every new checkpoint uh into production right",
    "start": "1368480",
    "end": "1373820"
  },
  {
    "text": "so to answer this question uh what I want what I'm going to show to you is that gorilla is actually quite robust to changes in apis right",
    "start": "1373820",
    "end": "1380780"
  },
  {
    "text": "so here's an API that was used in the training so over here the user wants to do something and the API that I have is",
    "start": "1380780",
    "end": "1386960"
  },
  {
    "text": "start Vision FC investment 50 320 equals to also let me just straight up apologize for the use of so many machine",
    "start": "1386960",
    "end": "1392840"
  },
  {
    "text": "learning apis but we're trying to write a paper and this spoke to the audience but you could replace this with stripes",
    "start": "1392840",
    "end": "1398840"
  },
  {
    "text": "Salesforce servicenow datadogo any apis that you prefer",
    "start": "1398840",
    "end": "1405140"
  },
  {
    "text": "and so this is the training time it's quite likely that during inference time as time progressed the desire to update",
    "start": "1405140",
    "end": "1411620"
  },
  {
    "text": "the backbone from less than 50 to restaurant 101 right this is like V1 to V2 API version changed and as you can",
    "start": "1411620",
    "end": "1417919"
  },
  {
    "text": "see because we have this retrieval our training setup Google is actually quite robust and captures this change in API",
    "start": "1417919",
    "end": "1423620"
  },
  {
    "text": "so we were able to like serve the latest API to the user now this is where API version changes",
    "start": "1423620",
    "end": "1430820"
  },
  {
    "text": "but you can also have your repository change right so in this scenario you know instead of using pytorch we have",
    "start": "1430820",
    "end": "1436159"
  },
  {
    "text": "engineers at Nvidia who are you know writing uh code.co that's customized for your task so probably you can use a much",
    "start": "1436159",
    "end": "1443480"
  },
  {
    "text": "faster and optimized model uh if you were to go for the Nvidia repository so basically across changes in API",
    "start": "1443480",
    "end": "1450200"
  },
  {
    "text": "versioning and changes in API repository or any other changes Google is able to adapt uh to changing apis",
    "start": "1450200",
    "end": "1458980"
  },
  {
    "text": "okay so I'll take questions at the end ah",
    "start": "1459440",
    "end": "1464960"
  },
  {
    "text": "moving on so this is a fun part right so when we open source coil are like um",
    "start": "1464960",
    "end": "1470419"
  },
  {
    "text": "we also went ahead and we made of different platforms where you can access gorilla and this is we also have",
    "start": "1470419",
    "end": "1476480"
  },
  {
    "text": "a Discord server I would invite all of you to join but the feedback has been actually quite supportive right and this",
    "start": "1476480",
    "end": "1481700"
  },
  {
    "text": "is by far the best feedback I've ever received which is this is the next best thing to slice spread",
    "start": "1481700",
    "end": "1487159"
  },
  {
    "text": "I don't think it's there yet but you know a lot of people are using it and finding it useful it's not it's not just a research artifact",
    "start": "1487159",
    "end": "1493580"
  },
  {
    "text": "uh We've also been on the front page of how I can use multiple times by now there's there's a growing open source",
    "start": "1493580",
    "end": "1498799"
  },
  {
    "text": "adoption as well but also more critically for us both domestically and internationally a lot of popular press",
    "start": "1498799",
    "end": "1505280"
  },
  {
    "text": "and Ai influencers and researchers in this field think that this is the right way to go but you're trying to teach an",
    "start": "1505280",
    "end": "1511280"
  },
  {
    "text": "llm to use apis and then how this is a modality to teach the llm to interact with the world right",
    "start": "1511280",
    "end": "1517340"
  },
  {
    "text": "uh we also have a hosted box from Berkeley and where people hit our service and we give them a chat",
    "start": "1517340",
    "end": "1522980"
  },
  {
    "text": "completion API so it's basically give us a prompt to give you llm generated response and all of this is all of our",
    "start": "1522980",
    "end": "1529100"
  },
  {
    "text": "models are Apache 2.0 licensed so you could also use it commercially and you're seeing pretty healthy invocations",
    "start": "1529100",
    "end": "1534140"
  },
  {
    "text": "uh for since the two months that we have open sourced it so with that I'd like to conclude uh so",
    "start": "1534140",
    "end": "1541460"
  },
  {
    "text": "we have trained gorilla which is an llm that writes API calls and we're teaching an llm to use apis you're actually",
    "start": "1541460",
    "end": "1547340"
  },
  {
    "text": "teaching it to talk to the rest of the world through apis and this is an open source project from",
    "start": "1547340",
    "end": "1552679"
  },
  {
    "text": "Berkeley and we have an API Zoo where you can contribute your apis if your organization has a bunch of apis we",
    "start": "1552679",
    "end": "1558740"
  },
  {
    "text": "train models with it so when users request gorilla we can serve your apis to them and this includes restful apis",
    "start": "1558740",
    "end": "1564440"
  },
  {
    "text": "get post graphql apis SQL apis so on and so forth we're pretty uh agnostic to",
    "start": "1564440",
    "end": "1571279"
  },
  {
    "text": "that and this is an open source project so if you're interested in contributing then please do join us and help us build",
    "start": "1571279",
    "end": "1577940"
  },
  {
    "text": "gorilla thank you very much and I'm happy to take questions thank you",
    "start": "1577940",
    "end": "1584500"
  },
  {
    "text": "thank you great talk um I have one question so what if I wanted to use gorilla for my private",
    "start": "1588740",
    "end": "1596539"
  },
  {
    "text": "application with my private apis how can I teach it yeah so that's a good question and this",
    "start": "1596539",
    "end": "1602240"
  },
  {
    "text": "has also been a very uh growing request where you know it's like a for an Enterprise and you have a bunch of apis",
    "start": "1602240",
    "end": "1607340"
  },
  {
    "text": "can you teach them all to on your apis that serve to only your set of users within your Enterprise so we",
    "start": "1607340",
    "end": "1614480"
  },
  {
    "text": "have a bunch of Pilots going on so I'm happy to talk about it but it's fundamentally possible we have open sourced our pipeline so you",
    "start": "1614480",
    "end": "1620179"
  },
  {
    "text": "could well it's in the paper so you could do this today uh but if you need any help or we're more than happy to",
    "start": "1620179",
    "end": "1626600"
  },
  {
    "text": "collaborate and also try and see how that works because what's challenging is a how you train the model and be how you",
    "start": "1626600",
    "end": "1632179"
  },
  {
    "text": "serve the model and in both of those areas we have expertise so uh at least as an academic lab we are happy to",
    "start": "1632179",
    "end": "1639260"
  },
  {
    "text": "collaborate and help along those lines yeah",
    "start": "1639260",
    "end": "1644080"
  },
  {
    "text": "so uh typically when we do retrieval based methods when we do information retrieval uh right now we do a lot of",
    "start": "1650419",
    "end": "1657440"
  },
  {
    "text": "contractors training just to disambiguate similar apis similar API",
    "start": "1657440",
    "end": "1663679"
  },
  {
    "text": "definitions so do you have anything like do you have any thoughts on doing that",
    "start": "1663679",
    "end": "1669200"
  },
  {
    "text": "since let's say if I remember in the paper you trend on hugging face apis and",
    "start": "1669200",
    "end": "1674840"
  },
  {
    "text": "there's hundreds or if not dozens of very close and similar apis so have you",
    "start": "1674840",
    "end": "1682520"
  },
  {
    "text": "thought about like how to disambiguate the API calls and efforts there yeah so that's a good question the question is",
    "start": "1682520",
    "end": "1688640"
  },
  {
    "text": "you know if there are multiple apis that all look and feel very similar how do you how do you design back with between the two",
    "start": "1688640",
    "end": "1694640"
  },
  {
    "text": "and there's two answers to this right one is this is you can do this at the retrieval phase where you say hey look",
    "start": "1694640",
    "end": "1701000"
  },
  {
    "text": "I'm gonna try to train the model there's been a bunch of work on that but I feel like you know we are",
    "start": "1701000",
    "end": "1706279"
  },
  {
    "text": "hitting the seams if not at the seams of what retrievers can do but there's a second part of it which is can you now",
    "start": "1706279",
    "end": "1712400"
  },
  {
    "text": "have a compact enough representation build the retriever and then user allow them to actually",
    "start": "1712400",
    "end": "1718659"
  },
  {
    "text": "discern if it's right or wrong right so like you can have two models that look the same feel the same but one has",
    "start": "1718659",
    "end": "1723799"
  },
  {
    "text": "slightly better performance over the other maybe this one is faster inference than this one then you can understand",
    "start": "1723799",
    "end": "1729200"
  },
  {
    "text": "the context so when the user says look I want to do this on a smartphone well then probably you want a small capacity",
    "start": "1729200",
    "end": "1734659"
  },
  {
    "text": "model because they don't have the computing power versus doing it on a server class GPU so using the llm to",
    "start": "1734659",
    "end": "1740360"
  },
  {
    "text": "discern the performance benefits are you know more intricate details is probably a good idea and you just let your",
    "start": "1740360",
    "end": "1746900"
  },
  {
    "text": "retriever enlist the set of relevant candidates is is one way however I would",
    "start": "1746900",
    "end": "1752779"
  },
  {
    "text": "think solving it but otherwise it's like you know it's ah there's nothing much you can do",
    "start": "1752779",
    "end": "1758000"
  },
  {
    "text": "actually because you're going to have it probably increase your embedding size by K but you're playing with a few percentage",
    "start": "1758000",
    "end": "1764059"
  },
  {
    "text": "points here not really a big difference I can probably just shout it out yeah",
    "start": "1764059",
    "end": "1772658"
  },
  {
    "text": "yeah so to repeat the question is the is using AST sub 3 matching to measure",
    "start": "1782779",
    "end": "1788120"
  },
  {
    "text": "hallucination critical uh can we think of explaining this to documents Etc",
    "start": "1788120",
    "end": "1794000"
  },
  {
    "text": "and the answer is yes because I think this gives like a neat framework right but at the",
    "start": "1794000",
    "end": "1800179"
  },
  {
    "text": "fundamental is can you have a universal view of what's available with apis it's simple",
    "start": "1800179",
    "end": "1805220"
  },
  {
    "text": "if stripe says here's my set of apis there's no more until they come up with new ones right so if Ray says here's a",
    "start": "1805220",
    "end": "1811580"
  },
  {
    "text": "set of apis that you use you have no more so that's clear for documents it's hard to tell right like every web page",
    "start": "1811580",
    "end": "1818179"
  },
  {
    "text": "on the Internet is a document so it might be tricky but if you're like an Enterprise and say look here's my set of documents you can then use to ground",
    "start": "1818179",
    "end": "1823880"
  },
  {
    "text": "that and say I want your response to be only from this subset so I think ASD gives you this neat uh like a handy tool",
    "start": "1823880",
    "end": "1831380"
  },
  {
    "text": "that you can use to measure hallucination but how do you apply it out of the box documents I think requires some more thought",
    "start": "1831380",
    "end": "1839080"
  }
]
[
  {
    "start": "0",
    "end": "157000"
  },
  {
    "text": "awesome hey everyone uh excited to be closing us out today",
    "start": "3920",
    "end": "9599"
  },
  {
    "text": "I hope to be entertaining and engaging and maybe not even take up the whole 30",
    "start": "9599",
    "end": "15179"
  },
  {
    "text": "minutes we'll see uh so first a little bit about myself my name is Chris Van Pelt I'm one of the",
    "start": "15179",
    "end": "21000"
  },
  {
    "text": "co-founders of weights and biases I also founded a company named figure eight",
    "start": "21000",
    "end": "26340"
  },
  {
    "text": "back in 2007 that was helping companies create labeled data for machine learning",
    "start": "26340",
    "end": "33899"
  },
  {
    "text": "algorithms so I've been in the space for a really long time and I have kind of",
    "start": "33899",
    "end": "39420"
  },
  {
    "text": "gotten a front row seat to a lot of the changes in in ml leading up to the the",
    "start": "39420",
    "end": "45600"
  },
  {
    "text": "current uh llm craze so we're going to dig into that today",
    "start": "45600",
    "end": "51360"
  },
  {
    "text": "uh when I first started figure eight back in 2007 Ai and machine learning",
    "start": "51360",
    "end": "57899"
  },
  {
    "text": "they were kind of they worked against us when we went to investors to try to get money for the company they they seemed",
    "start": "57899",
    "end": "64559"
  },
  {
    "text": "risky they were unproven it seemed like uh Academia had been saying it's going",
    "start": "64559",
    "end": "70080"
  },
  {
    "text": "to work for years and it still wasn't working uh the time we live in now is obviously very different uh here we can",
    "start": "70080",
    "end": "76619"
  },
  {
    "text": "see uh from a recent Sequoia article you know 50 companies in Ai",
    "start": "76619",
    "end": "83659"
  },
  {
    "text": "and it's obviously like a very hot area as as you all know",
    "start": "83659",
    "end": "90000"
  },
  {
    "text": "uh and within this we have this explosion of uh generative AI companies",
    "start": "90000",
    "end": "95700"
  },
  {
    "text": "often leveraging llms or diffusion models uh if you look at the most recent like batch of YC companies I think it's",
    "start": "95700",
    "end": "102479"
  },
  {
    "text": "like 70 percent are you know somehow using llms or gen AI so it's a very",
    "start": "102479",
    "end": "107820"
  },
  {
    "text": "different world uh one area that is incredibly exciting for me as a developer is this explosion",
    "start": "107820",
    "end": "114600"
  },
  {
    "text": "of Open Source tooling and models so uh if you go on",
    "start": "114600",
    "end": "121200"
  },
  {
    "text": "GitHub you can check out this cool repository called open dash llms it kind of lists all of the new models and tools",
    "start": "121200",
    "end": "127380"
  },
  {
    "text": "that are out there this thing is a very active repo it's changing every day it's uh it's like really exciting for me to",
    "start": "127380",
    "end": "133980"
  },
  {
    "text": "just go and check every week to see like what is is being launched um you know an example of of one that",
    "start": "133980",
    "end": "141180"
  },
  {
    "text": "I'm sure many of you are aware of is uh codelama llama fine tune on",
    "start": "141180",
    "end": "146819"
  },
  {
    "text": "um coding data which as a developer someone who uses copilot it's like such a delightful",
    "start": "146819",
    "end": "153480"
  },
  {
    "text": "experience to to kind of have this uh helpful assistant so the agenda for um today first we're",
    "start": "153480",
    "end": "161459"
  },
  {
    "start": "157000",
    "end": "530000"
  },
  {
    "text": "going to talk a little bit about how we got here then we're going to dive in to uh Three core llm workflows and how we",
    "start": "161459",
    "end": "170700"
  },
  {
    "text": "at weights and biases have seen different teams and users leverage llms and and how the weights and biases",
    "start": "170700",
    "end": "177360"
  },
  {
    "text": "toolkit can help so how we got here well a big part of",
    "start": "177360",
    "end": "182819"
  },
  {
    "text": "story is just compute uh you know deep learning happens in the 2010s and at the",
    "start": "182819",
    "end": "192120"
  },
  {
    "text": "same time Moore's Law and gpus and tpus are giving us more and more compute",
    "start": "192120",
    "end": "198780"
  },
  {
    "text": "um so we have models like gpt3 which is 175 billion gpt4 we don't know how many",
    "start": "198780",
    "end": "204959"
  },
  {
    "text": "parameters but it's a lot it's more than that and then like really big models such as poem with 540 billion",
    "start": "204959",
    "end": "213500"
  },
  {
    "text": "the large language model was especially well suited for this you know increased",
    "start": "213560",
    "end": "221819"
  },
  {
    "text": "amount of compute because you didn't have to pay a company like figure eight or scale or some big labeling firm to",
    "start": "221819",
    "end": "229560"
  },
  {
    "text": "generate a ton of training data the training data was already there the base models can simply be trained on kind of",
    "start": "229560",
    "end": "237019"
  },
  {
    "text": "semi-supervised learning where we just say read this like huge Corpus of the internet and we don't have to generate a",
    "start": "237019",
    "end": "243720"
  },
  {
    "text": "whole bunch of of labeled data uh but then what we get are these models that aren't very useful and we need to uh you",
    "start": "243720",
    "end": "250980"
  },
  {
    "text": "know use our lhf or other approaches to kind of guide or steer the model towards the the use case",
    "start": "250980",
    "end": "257100"
  },
  {
    "text": "um that we want uh behind all of this is the Transformer",
    "start": "257100",
    "end": "263820"
  },
  {
    "text": "not that one this one which really changed everything right and this was",
    "start": "263820",
    "end": "269360"
  },
  {
    "text": "2017 this is about a year maybe a year and a half after we had started weights",
    "start": "269360",
    "end": "274979"
  },
  {
    "text": "and biases so when weights and biases it's a company had started tensorflow was the framework of church pie torch",
    "start": "274979",
    "end": "281400"
  },
  {
    "text": "really wasn't a thing and computer vision was like where all the action was at it was all about self-driving cars",
    "start": "281400",
    "end": "287460"
  },
  {
    "text": "Elon Musk said we're going to have one like next year uh and then this like Transformer architecture comes along and",
    "start": "287460",
    "end": "294000"
  },
  {
    "text": "the attention is all you need paper and at the time you know I don't think",
    "start": "294000",
    "end": "299340"
  },
  {
    "text": "any of us knew how big of a deal this was but I mean this is really at the core of of all of this llm craze",
    "start": "299340",
    "end": "307919"
  },
  {
    "text": "uh so gpt4 is obviously a transfer a Transformer based pre-trained model uh",
    "start": "307919",
    "end": "315240"
  },
  {
    "text": "now uh Elon Musk the Tesla autopilot is mostly Transformer based uh more and",
    "start": "315240",
    "end": "322020"
  },
  {
    "text": "more deep learning models have you know some component of it actually uh this",
    "start": "322020",
    "end": "327600"
  },
  {
    "text": "kind of attention component this is this Transformer Transformer comes in many different flavors we have decoder only",
    "start": "327600",
    "end": "333780"
  },
  {
    "text": "which is like the GPT family probably the one that's that's kind of most familiar for to folks uh things like",
    "start": "333780",
    "end": "339720"
  },
  {
    "text": "Bert which can give us like embeddings and we can use for knowledge retrieval or other use cases and then encoder",
    "start": "339720",
    "end": "345479"
  },
  {
    "text": "decoder often used for for translation uh uh the moment that like I think",
    "start": "345479",
    "end": "352440"
  },
  {
    "text": "really made it such that every tech company we go to has to say something about llm or AI was in December of last",
    "start": "352440",
    "end": "360840"
  },
  {
    "text": "year uh and I remember I was at um nureps in New Orleans and opening eye",
    "start": "360840",
    "end": "368100"
  },
  {
    "text": "releases chat GPT uh and it it's changed the world",
    "start": "368100",
    "end": "374280"
  },
  {
    "text": "um shortly after it was released I I went to Japan we have a team in Japan and I",
    "start": "374280",
    "end": "381539"
  },
  {
    "text": "was in the cab on the way to like see the team and there was a little like video screen and I you know just saw a",
    "start": "381539",
    "end": "388620"
  },
  {
    "text": "kanji and then chat GPT and I was kind of like wow it's like it's everywhere",
    "start": "388620",
    "end": "394319"
  },
  {
    "text": "um so what made this so amazing it's the I I would say it's the interface it's so",
    "start": "394319",
    "end": "399479"
  },
  {
    "text": "natural it's just communicating it's going back and forth with this agent and you can uh be delighted by uh what this",
    "start": "399479",
    "end": "408660"
  },
  {
    "text": "can understand and do I found myself often um like really amazed at what this could",
    "start": "408660",
    "end": "414720"
  },
  {
    "text": "do now before this especially weights and biases we've been working with open AI since the beginning we had played",
    "start": "414720",
    "end": "420060"
  },
  {
    "text": "with gpt2 gpt3 in their code playgrounds and it was magical it was interesting but it wasn't as magical as this and",
    "start": "420060",
    "end": "427319"
  },
  {
    "text": "it's really that fine-tuning process and making the interface designed to be an assistant that I think",
    "start": "427319",
    "end": "433440"
  },
  {
    "text": "captured everyone's imagination so the other really cool thing about a Transformer is you can feed anything",
    "start": "433440",
    "end": "440639"
  },
  {
    "text": "into it so we can have image based Transformers where we take an image and break it into chunks",
    "start": "440639",
    "end": "445800"
  },
  {
    "text": "uh we can have speech-based Transformers where we take uh spectrograms and feed",
    "start": "445800",
    "end": "451680"
  },
  {
    "text": "that in as a Time series into the Transformer just like the time series of of words from books",
    "start": "451680",
    "end": "458580"
  },
  {
    "text": "and uh I think this is an area that opening it's recently but is is",
    "start": "458580",
    "end": "464280"
  },
  {
    "text": "definitely an area of excitement and where a lot of new and interesting use cases are going to come these multimodal Transformers where we can pass in both",
    "start": "464280",
    "end": "471000"
  },
  {
    "text": "image audio video text you name it uh just model it as a Time series data and",
    "start": "471000",
    "end": "479160"
  },
  {
    "text": "the Transformer should be able to use its attention mechanism to efficiently predict whatever you're you're asking it",
    "start": "479160",
    "end": "484740"
  },
  {
    "text": "to predict uh one of my favorite things about",
    "start": "484740",
    "end": "491880"
  },
  {
    "text": "having started weights and biases is our customers we're able to work with customers across all different",
    "start": "491880",
    "end": "497460"
  },
  {
    "text": "Industries we're not focused on you know one specific use case self-driving cars uh",
    "start": "497460",
    "end": "503580"
  },
  {
    "text": "and uh we've gotten to work with everything from agriculture to medicine",
    "start": "503580",
    "end": "508800"
  },
  {
    "text": "and I think areas where AI transforming these llms are really most exciting are",
    "start": "508800",
    "end": "514500"
  },
  {
    "text": "areas like uh um medicine and assisting",
    "start": "514500",
    "end": "520320"
  },
  {
    "text": "in care of humans and you know I think this is really going to like save people's lives and and make the world a",
    "start": "520320",
    "end": "525779"
  },
  {
    "text": "better place so it it's it's super motivating to be um a part of all of this so let's talk about how weights and",
    "start": "525779",
    "end": "532320"
  },
  {
    "start": "530000",
    "end": "878000"
  },
  {
    "text": "biases uh well first what weights and biasis is and then how uh we kind of help folks",
    "start": "532320",
    "end": "539940"
  },
  {
    "text": "um with llm development so think of weights and biases as your machine learning system of record a single place",
    "start": "539940",
    "end": "547200"
  },
  {
    "text": "to capture all the various activities that need to happen when you're uh modeling so of course there's the",
    "start": "547200",
    "end": "554100"
  },
  {
    "text": "training of models but maybe you need to pre-process your data set or analyze your data set you likely want to",
    "start": "554100",
    "end": "559440"
  },
  {
    "text": "evaluate um models maybe you want to do some experiments with with prompts",
    "start": "559440",
    "end": "565560"
  },
  {
    "text": "uh as you're doing this you often have actual like file assets so we converge",
    "start": "565560",
    "end": "570600"
  },
  {
    "text": "in models and data sets and I think most importantly weights and biases allows",
    "start": "570600",
    "end": "575760"
  },
  {
    "text": "you to collaborate and Visually tell stories with your teammates about what is actually happening",
    "start": "575760",
    "end": "581580"
  },
  {
    "text": "so then you have the central repository where as team members come and go they can kind of understand how you got to",
    "start": "581580",
    "end": "588240"
  },
  {
    "text": "where you are today and have a single source of Truth for for all the activities the team is is iterating on",
    "start": "588240",
    "end": "595500"
  },
  {
    "text": "so we see three core practitioner types there's the llm creators this is really",
    "start": "595500",
    "end": "601140"
  },
  {
    "text": "the weights and biases wheelhouse we've been uh supporting the majority of of these players such as open AI uh meta",
    "start": "601140",
    "end": "609620"
  },
  {
    "text": "anthropic then we have the llm fine tuners this is a really exciting area that I'm sure many of you are",
    "start": "609620",
    "end": "615480"
  },
  {
    "text": "experimenting with with any scale and Ray where we take one of the open source models and then fine tune it on our",
    "start": "615480",
    "end": "621899"
  },
  {
    "text": "specific use case and lastly we have the llm prompt Engineers so these are cases",
    "start": "621899",
    "end": "627660"
  },
  {
    "text": "where people are just interfacing with an API this could be say the any scale endpoints or the openai API but they",
    "start": "627660",
    "end": "633779"
  },
  {
    "text": "don't really need to know anything about AI models they just use the power of",
    "start": "633779",
    "end": "638880"
  },
  {
    "text": "these pre-trained models that have often been fine-tuned for them so as mentioned uh",
    "start": "638880",
    "end": "646260"
  },
  {
    "text": "these llm creators they they're all users of weights and biases we've helped",
    "start": "646260",
    "end": "651360"
  },
  {
    "text": "them actually create these really large language models if you yourself are trying to create a model from scratch we",
    "start": "651360",
    "end": "657720"
  },
  {
    "text": "would love to to help you as well uh here's actually a picture of Carrie our head of product at openingi here in",
    "start": "657720",
    "end": "665940"
  },
  {
    "text": "San Francisco uh we were fortunate enough to have open AI as one of our first heavy users of the system this",
    "start": "665940",
    "end": "673320"
  },
  {
    "text": "allowed us first to design a system that can scale but also allowed us to design a system that was forward-looking future",
    "start": "673320",
    "end": "680160"
  },
  {
    "text": "looking because we knew the team at open AI were going to be working on the",
    "start": "680160",
    "end": "685320"
  },
  {
    "text": "things that kind of the rest of us would likely be working on should they be successful so",
    "start": "685320",
    "end": "691940"
  },
  {
    "text": "infrastructure has you know always been a challenge with these models as we're",
    "start": "691940",
    "end": "698160"
  },
  {
    "text": "able to get more parameters in these models now it starts to get a lot trickier to run them",
    "start": "698160",
    "end": "704040"
  },
  {
    "text": "so we can't fit 175 billion parameters onto any accelerator we have to split it",
    "start": "704040",
    "end": "709440"
  },
  {
    "text": "up and run it across many separate accelerators and often many",
    "start": "709440",
    "end": "714899"
  },
  {
    "text": "separate actual compute nodes so we have things like infiniband and and all of",
    "start": "714899",
    "end": "720779"
  },
  {
    "text": "these fancy approaches to scale across all of this compute weights and biases helps you kind of",
    "start": "720779",
    "end": "726779"
  },
  {
    "text": "understand any performance bottlenecks we're automatically capturing GPU usage CPU usage",
    "start": "726779",
    "end": "731899"
  },
  {
    "text": "and we have nice Integrations with tools like any scale that make the kind of",
    "start": "731899",
    "end": "736980"
  },
  {
    "text": "pain of actually dealing with really complex distributed infrastructure easier",
    "start": "736980",
    "end": "744019"
  },
  {
    "text": "uh yeah I'm just looking at these french fries and now I want some McDonald's",
    "start": "744300",
    "end": "750060"
  },
  {
    "text": "french fries and I'm questioning like how effective this image is for the slide but all right let's move on uh",
    "start": "750060",
    "end": "756079"
  },
  {
    "text": "another really powerful aspect of ways to biasis is scaling the team so now when you have these really big models",
    "start": "756079",
    "end": "761519"
  },
  {
    "text": "they're really complicated you need a bunch of different subject matter experts and you probably care about safety and privacy a lot of people start",
    "start": "761519",
    "end": "768420"
  },
  {
    "text": "working on these together so having that Central interface has proven to be",
    "start": "768420",
    "end": "773660"
  },
  {
    "text": "incredibly important for customers like openai and other companies and it's it's",
    "start": "773660",
    "end": "780240"
  },
  {
    "text": "something we're really proud that the product's able to do an example of actually using weights and",
    "start": "780240",
    "end": "785880"
  },
  {
    "text": "biases as almost like a a training Journal literally a training Journal is",
    "start": "785880",
    "end": "790980"
  },
  {
    "text": "this example for Dolly mini so Dolly mini was done by a gentleman named Boris dayma who's a long time friend of",
    "start": "790980",
    "end": "797399"
  },
  {
    "text": "weights and biases when opening I released Dolly their diffusion model they generated images uh Boris thought",
    "start": "797399",
    "end": "804660"
  },
  {
    "text": "wow it would be cool if I could actually create my own model so he went on this journey of figuring out all of these",
    "start": "804660",
    "end": "811740"
  },
  {
    "text": "different issues with his data set and the model and the hyper parameters and how to get the best model produced and",
    "start": "811740",
    "end": "817800"
  },
  {
    "text": "he kept an open journal on weights and biases so you can go to wnb.me Dolly",
    "start": "817800",
    "end": "823139"
  },
  {
    "text": "journal and actually see what he learned during that Journey",
    "start": "823139",
    "end": "828959"
  },
  {
    "text": "uh Luther AI also has a public experiment tracking journal on weights and biases so a Luther are the authors",
    "start": "828959",
    "end": "836519"
  },
  {
    "text": "of gptj GPT Neo X and you can actually go see the various experiments they've",
    "start": "836519",
    "end": "842040"
  },
  {
    "text": "done what worked what didn't work and hopefully not repeat the same mistakes that can be very expensive when you're",
    "start": "842040",
    "end": "847860"
  },
  {
    "text": "running this on um you know many different accelerated compute nodes",
    "start": "847860",
    "end": "853320"
  },
  {
    "text": "so we've taken a lot of these lessons and best practices from these friends of",
    "start": "853320",
    "end": "858480"
  },
  {
    "text": "weights and biases and customers and actually created a white paper so if you",
    "start": "858480",
    "end": "864120"
  },
  {
    "text": "are looking to be one of these llm creators or try to understand what that would look like I'd encourage you to",
    "start": "864120",
    "end": "870300"
  },
  {
    "text": "check out our free white paper at wnb.me llm white paper and uh kind of share in",
    "start": "870300",
    "end": "876060"
  },
  {
    "text": "the knowledge that we put together here so our second Persona the llm fine",
    "start": "876060",
    "end": "881699"
  },
  {
    "start": "878000",
    "end": "1111000"
  },
  {
    "text": "tuners so fine-tuning models is made actually",
    "start": "881699",
    "end": "887399"
  },
  {
    "text": "like really easy anyone can do it thanks to amazing tools like hugging face",
    "start": "887399",
    "end": "893579"
  },
  {
    "text": "uh any scale in Ray and weights and biases so we have just built-in",
    "start": "893579",
    "end": "898800"
  },
  {
    "text": "Integrations with these libraries so that you can take the you know Ray hugging face accelerate framework create",
    "start": "898800",
    "end": "905579"
  },
  {
    "text": "a trainer have it do all the complicated infrastructure scaling for you as long as wherever those nodes are doing the",
    "start": "905579",
    "end": "912060"
  },
  {
    "text": "training as long as weights and biases is installed there and you've logged in with an environment variable or by using",
    "start": "912060",
    "end": "918120"
  },
  {
    "text": "our command line tool will automatically capture all of these beautiful charts and graphs to allow you to compare",
    "start": "918120",
    "end": "924380"
  },
  {
    "text": "different Trials of of your experiments as you're fine-tuning we also have uh wage and biases sweeps",
    "start": "924380",
    "end": "931980"
  },
  {
    "text": "which allows you to automate hyper parameter search so once you have maybe done a couple",
    "start": "931980",
    "end": "937680"
  },
  {
    "text": "experiments yourself now uh you know you've got a conference like this to go to you can fire off a sweep in the",
    "start": "937680",
    "end": "944339"
  },
  {
    "text": "morning and after the conference is over go back home and see which of the sets",
    "start": "944339",
    "end": "949680"
  },
  {
    "text": "of hyper parameters actually performed best so maybe you want to tweak things like the batch size or the learning rate or the way you split the training and",
    "start": "949680",
    "end": "957480"
  },
  {
    "text": "the test data you can automate all of those trials and we give you these rich visual ways to compare what's actually",
    "start": "957480",
    "end": "963000"
  },
  {
    "text": "working and what isn't uh wait somebody says artifacts gives you data lineage tracking so you're able",
    "start": "963000",
    "end": "970019"
  },
  {
    "text": "to see exactly which data sets you use to fine tune a model at any given time exactly which Downstream models were",
    "start": "970019",
    "end": "976980"
  },
  {
    "text": "fine-tuned so next week when meta comes out with llama 2.1 you'll be able to",
    "start": "976980",
    "end": "982500"
  },
  {
    "text": "track that okay this next iteration was actually trained on that not the the previous one this is especially",
    "start": "982500",
    "end": "988019"
  },
  {
    "text": "important uh when you're working in sensitive uh areas where there's you",
    "start": "988019",
    "end": "993600"
  },
  {
    "text": "know more need for governance and in some way to to audit what could be happening with the data and",
    "start": "993600",
    "end": "1000500"
  },
  {
    "text": "um any retraining that needs to occur another really powerful feature of",
    "start": "1000500",
    "end": "1007040"
  },
  {
    "text": "weights and biases our ability to visualize the data itself so you can log actual samples from your llm to weights",
    "start": "1007040",
    "end": "1014060"
  },
  {
    "text": "and biases as a table where you could say here was the user's prompt and here's what we actually output with any additional metadata you'd like",
    "start": "1014060",
    "end": "1021620"
  },
  {
    "text": "so maybe you're trying to vary the temperature as you're iterating on this model you can capture exactly what",
    "start": "1021620",
    "end": "1026780"
  },
  {
    "text": "temperature was used for any given example and the weights and biases model",
    "start": "1026780",
    "end": "1031880"
  },
  {
    "text": "registry lets you take any of your fine two model assets and put them in a central place where now the whole team",
    "start": "1031880",
    "end": "1037280"
  },
  {
    "text": "will know this is the model we're using in production here's the current staging model that we hope to promote next week",
    "start": "1037280",
    "end": "1043459"
  },
  {
    "text": "and here's our Baseline that we always want to compare against a really powerful aspect to the weights and biases model registry is our automations",
    "start": "1043459",
    "end": "1050840"
  },
  {
    "text": "feature so automations allows you to say when someone goes into the weights and biases UI and promotes a model to",
    "start": "1050840",
    "end": "1057080"
  },
  {
    "text": "production maybe hit a web hook in my infrastructure or fire off a GitHub action to go do some evaluation or",
    "start": "1057080",
    "end": "1063200"
  },
  {
    "text": "automate some aspect of the of the actual pipeline so this is really powerful to have that single source of",
    "start": "1063200",
    "end": "1069260"
  },
  {
    "text": "truth of all right what models are we actually using right now as we as we ship something and iterate",
    "start": "1069260",
    "end": "1075260"
  },
  {
    "text": "uh so this is a bit of a humble brag I don't know how humble this is we've tracked over 200 million hours of",
    "start": "1075260",
    "end": "1081320"
  },
  {
    "text": "compute at weights and biases um which I am you know super proud of",
    "start": "1081320",
    "end": "1087020"
  },
  {
    "text": "and this is solely in our our SAS offering so we allow you to uh just sign",
    "start": "1087020",
    "end": "1093320"
  },
  {
    "text": "up online and use our cloud-based service actually the majority of our Enterprise customers are using our",
    "start": "1093320",
    "end": "1099380"
  },
  {
    "text": "dedicated offerings which means we can't really see what they're doing we don't know how many compute hours are there",
    "start": "1099380",
    "end": "1105320"
  },
  {
    "text": "it's completely isolated uh for those that have higher privacy requirements",
    "start": "1105320",
    "end": "1111919"
  },
  {
    "start": "1111000",
    "end": "1361000"
  },
  {
    "text": "so our last persona llm for prompt Engineers we were really excited uh when",
    "start": "1111919",
    "end": "1119059"
  },
  {
    "text": "chat GPT took off and now we have these apis that a lot of developers want to",
    "start": "1119059",
    "end": "1124700"
  },
  {
    "text": "use so the first thing we did was use them ourselves to really understand the pain points of this kind of new persona",
    "start": "1124700",
    "end": "1131000"
  },
  {
    "text": "that we didn't understand as well as the people that were doing data science and modeling so we built a weights and",
    "start": "1131000",
    "end": "1137780"
  },
  {
    "text": "biases support bot we call it one bot uh you can interact with onebot at wnb.me",
    "start": "1137780",
    "end": "1144679"
  },
  {
    "text": "Discord and ask it questions about weights and biases the company or the product",
    "start": "1144679",
    "end": "1150200"
  },
  {
    "text": "um and it will return them directly in the in the weights and biases UI behind the scenes this is uh you know powered",
    "start": "1150200",
    "end": "1156740"
  },
  {
    "text": "by uh chat or GPT 3.5 we kind of took a lot of the lessons we",
    "start": "1156740",
    "end": "1163760"
  },
  {
    "text": "learned while building the spot and created a course which is free for folks to download and interact with this was",
    "start": "1163760",
    "end": "1170960"
  },
  {
    "text": "actually live a few months ago but now you can still kind of download the videos and the content um to look into what it takes to",
    "start": "1170960",
    "end": "1177559"
  },
  {
    "text": "actually build one of these apps if you're interested uh one of the big questions we had to",
    "start": "1177559",
    "end": "1182600"
  },
  {
    "text": "ask ourselves when uh kind of the world shifted seven eight months ago was does building the best tools for machine",
    "start": "1182600",
    "end": "1189140"
  },
  {
    "text": "learning practitioners still matter when you know gpt4 seems to essentially",
    "start": "1189140",
    "end": "1195320"
  },
  {
    "text": "just nail most everything uh and we believe it does and this is because",
    "start": "1195320",
    "end": "1203720"
  },
  {
    "text": "we now have uh this whole new audience of users these are regular software developers that are now leveraging these",
    "start": "1203720",
    "end": "1210140"
  },
  {
    "text": "tools um they need to care about the same things that those machine learning Engineers",
    "start": "1210140",
    "end": "1216200"
  },
  {
    "text": "need to care about we need to measure things like accuracy how good is it we need to evaluate these models the",
    "start": "1216200",
    "end": "1222679"
  },
  {
    "text": "developers are often used to writing a CI CD system that's red or green and uh",
    "start": "1222679",
    "end": "1228559"
  },
  {
    "text": "everything's good to go this new world is all about probabilities and we need",
    "start": "1228559",
    "end": "1234980"
  },
  {
    "text": "to kind of have a different set of tools and a different way of thinking to deploy it effectively so I love this",
    "start": "1234980",
    "end": "1241820"
  },
  {
    "text": "example our ml practitioner still needed right all right list countries starting with the letter O gets the first one",
    "start": "1241820",
    "end": "1247760"
  },
  {
    "text": "right then you know totally doesn't follow the instructions often we can just ask these",
    "start": "1247760",
    "end": "1253400"
  },
  {
    "text": "models like hey are you sure uh uh and it'll do better it seems to have just gotten rid of a few of the the",
    "start": "1253400",
    "end": "1259700"
  },
  {
    "text": "PE countries um we ask it you know why you got rid of Poland and Portugal uh and it just kind",
    "start": "1259700",
    "end": "1266840"
  },
  {
    "text": "of goes back to where it was before um",
    "start": "1266840",
    "end": "1272240"
  },
  {
    "text": "so uh you know we have these problems with hallucination we have these problems with uh just understanding what",
    "start": "1272240",
    "end": "1278419"
  },
  {
    "text": "is right and wrong so a bunch of new Solutions have been built to handle these the one we use in our wanba is a",
    "start": "1278419",
    "end": "1284419"
  },
  {
    "text": "knowledge retrieval so with knowledge retrieval we're saying okay we're going to actually give as context",
    "start": "1284419",
    "end": "1291020"
  },
  {
    "text": "to the model some knowledge that we have when someone asks a question about weights and biases we're going to go search our documentation grab a couple",
    "start": "1291020",
    "end": "1297559"
  },
  {
    "text": "chunks from it and say hey GPT here's what weights and bias is documented here's the user's question take this",
    "start": "1297559",
    "end": "1303799"
  },
  {
    "text": "information and give us an answer which drastically improves the accuracy for domain-specific problems",
    "start": "1303799",
    "end": "1309559"
  },
  {
    "text": "this starts to get pretty complicated pretty fast right we have now a prompt that comes in we've got to go to this",
    "start": "1309559",
    "end": "1315620"
  },
  {
    "text": "Vector database we're probably using embeddings to find the appropriate",
    "start": "1315620",
    "end": "1321580"
  },
  {
    "text": "document chunks to pull down and ultimately give an answer to the user by",
    "start": "1321580",
    "end": "1326659"
  },
  {
    "text": "feeding all of that into an llm so the common approach here is to use a chain probably the most common or the",
    "start": "1326659",
    "end": "1333200"
  },
  {
    "text": "most popular library today that allows you to chain these things together is Lang chain and you can do lots of really",
    "start": "1333200",
    "end": "1338659"
  },
  {
    "text": "interesting stuff by kind of putting all these tools together and getting results out",
    "start": "1338659",
    "end": "1346700"
  },
  {
    "text": "a lot of choices in what LM them to use so there's a ton of trade-offs between these different llm vendors whether it's",
    "start": "1346700",
    "end": "1353600"
  },
  {
    "text": "cost privacy scalability that you need to think about",
    "start": "1353600",
    "end": "1359260"
  },
  {
    "text": "and when you're asking these questions weights and biases can help you answer them by letting you compare all of these",
    "start": "1359260",
    "end": "1365900"
  },
  {
    "text": "tools and debug the underlying chains so the first feature I wanted to call out is our what we call the weights and",
    "start": "1365900",
    "end": "1371299"
  },
  {
    "text": "biasis Tracer this allows you to dive into any one of these chains and see for",
    "start": "1371299",
    "end": "1376640"
  },
  {
    "text": "any given step of this retrieval process what went wrong or what went right so this specific chain was a was having us",
    "start": "1376640",
    "end": "1383480"
  },
  {
    "text": "ask questions to a database and then we use this knowledge retrieval to get the schema of the database so that the llm",
    "start": "1383480",
    "end": "1390080"
  },
  {
    "text": "could generate SQL and then we actually execute that SQL on the database to get an answer any one of those steps could",
    "start": "1390080",
    "end": "1396080"
  },
  {
    "text": "go wrong as you're debugging the llm tracing tool lets you dive into each of the steps and see exactly what went",
    "start": "1396080",
    "end": "1401659"
  },
  {
    "text": "right or what went wrong and it's a very popular tool on the platform now for",
    "start": "1401659",
    "end": "1407000"
  },
  {
    "text": "folks iterating on these chains we also need teams to be able to",
    "start": "1407000",
    "end": "1412220"
  },
  {
    "text": "evaluate the models now as we get you know new base models out or we try different fine-tuning options or we're",
    "start": "1412220",
    "end": "1418580"
  },
  {
    "text": "just taking a sub-sample of the actual uh query response pairs in production having a central dashboard to evaluate",
    "start": "1418580",
    "end": "1425900"
  },
  {
    "text": "these things is critical for the team to understand if you're getting better or worse so we've worked with Frameworks",
    "start": "1425900",
    "end": "1433400"
  },
  {
    "text": "like openai avails and other open source evaluation toolkits which often involve",
    "start": "1433400",
    "end": "1439159"
  },
  {
    "text": "just like asking GPT if the answer was right or not which is kind of mind-blowing but at least it gives you a",
    "start": "1439159",
    "end": "1445700"
  },
  {
    "text": "sense of what is working and what isn't and lastly one of our our most recent",
    "start": "1445700",
    "end": "1451700"
  },
  {
    "text": "product launches is llm usage monitoring so whether you're using openai or any",
    "start": "1451700",
    "end": "1457640"
  },
  {
    "text": "scale endpoints to query llama now you can have a single dashboard as an organization into usage number of tokens",
    "start": "1457640",
    "end": "1466240"
  },
  {
    "text": "latency and actual examples I'm clipping it on",
    "start": "1466240",
    "end": "1471320"
  },
  {
    "text": "the bottom of the table here but you actually see user examples which we can then feed into different evaluation",
    "start": "1471320",
    "end": "1477740"
  },
  {
    "text": "flows and and help the team kind of have a central view of all of this",
    "start": "1477740",
    "end": "1482780"
  },
  {
    "text": "we allow you to instrument this with code using our python libraries or we also have a proxy where by setting two",
    "start": "1482780",
    "end": "1489380"
  },
  {
    "text": "environment variables the opening eye SDK will now automatically go through this proxy and everything is is captured",
    "start": "1489380",
    "end": "1495260"
  },
  {
    "text": "automatically so we're seeing this be really popular in Enterprises where the team wants control over all the",
    "start": "1495260",
    "end": "1501440"
  },
  {
    "text": "different teams in the org that might be leveraging these apis so that they can have this auditability in governance",
    "start": "1501440",
    "end": "1508159"
  },
  {
    "text": "uh so that's an overview of wasted biases prompts we've got these improved tables uh we've got our Lang chain",
    "start": "1508159",
    "end": "1514940"
  },
  {
    "text": "integration opening eye integration Integrations with the any scale endpoints with proxy coming soon and",
    "start": "1514940",
    "end": "1523159"
  },
  {
    "text": "also a JavaScript library for those that are in Python land you can learn more about all of these tools and how we can",
    "start": "1523159",
    "end": "1530120"
  },
  {
    "text": "help at wnb.me llms and with that",
    "start": "1530120",
    "end": "1536120"
  },
  {
    "text": "stay in touch uh I'm on LinkedIn Chris Van Pelt I'm on Twitter I mean x uh hit",
    "start": "1536120",
    "end": "1542480"
  },
  {
    "text": "me up at Van Pelt and uh yeah you can learn more about the weights and biases",
    "start": "1542480",
    "end": "1547700"
  },
  {
    "text": "offerings at those two links thank you so much we've got a couple minutes for questions I really appreciate your attention",
    "start": "1547700",
    "end": "1554059"
  },
  {
    "text": "foreign",
    "start": "1554059",
    "end": "1556240"
  },
  {
    "text": "questions",
    "start": "1563000",
    "end": "1565539"
  },
  {
    "text": "hey um you talked a lot about you know the difference in adoption of these tools",
    "start": "1571220",
    "end": "1578419"
  },
  {
    "text": "between machine learning engineers and software infrastructure developers how",
    "start": "1578419",
    "end": "1585320"
  },
  {
    "text": "do you see this like push-pull evolve given the rapid Evolution like you",
    "start": "1585320",
    "end": "1591140"
  },
  {
    "text": "mentioned that you know some of the biggest open source llms can lead and lose lead within two months so",
    "start": "1591140",
    "end": "1600080"
  },
  {
    "text": "how how do you see production changing between these two engineering teams over",
    "start": "1600080",
    "end": "1606080"
  },
  {
    "text": "time in order to build AI products yeah it's a good question I think",
    "start": "1606080",
    "end": "1614419"
  },
  {
    "text": "it's it's still a little too early to say I think everyone's still trying to",
    "start": "1614419",
    "end": "1620720"
  },
  {
    "text": "figure this out I will say every Enterprise I've talked to is working on this like some team is is experimenting",
    "start": "1620720",
    "end": "1626240"
  },
  {
    "text": "with llms and trying to decide how it's going to be used my gut says there's going to be a ton of",
    "start": "1626240",
    "end": "1632059"
  },
  {
    "text": "just regular software developers that are working very closely with llms and they'll be partnering with the ml",
    "start": "1632059",
    "end": "1638539"
  },
  {
    "text": "engineering data sciency counterparts to ensure they have a strong you know data Foundation to to measure and understand",
    "start": "1638539",
    "end": "1646460"
  },
  {
    "text": "how well these things are performing a big open question for me is like are people just going to be using like any",
    "start": "1646460",
    "end": "1652880"
  },
  {
    "text": "scale endpoints uh opening eye endpoints and their equivalent like fine-tuning",
    "start": "1652880",
    "end": "1658820"
  },
  {
    "text": "apis or will they be taking on uh the rather complex responsibility running",
    "start": "1658820",
    "end": "1665360"
  },
  {
    "text": "these models in their own infrastructure I think the more sensitive Enterprises that don't want data to leave anywhere are",
    "start": "1665360",
    "end": "1672200"
  },
  {
    "text": "going to be in that second camp but it's a lot harder to do and and I think uh yeah we'll see probably some interesting",
    "start": "1672200",
    "end": "1678500"
  },
  {
    "text": "tools and companies that help with that specific problem as well",
    "start": "1678500",
    "end": "1683200"
  },
  {
    "text": "I uh this is a very interesting talk so what are your thoughts on the evaluation of these models um what how would you",
    "start": "1690620",
    "end": "1698419"
  },
  {
    "text": "how would you recommend we evaluate the models yeah great question",
    "start": "1698419",
    "end": "1703460"
  },
  {
    "text": "um so all right depending on the problem evaluation will either be easy or",
    "start": "1703460",
    "end": "1709520"
  },
  {
    "text": "difficult now if you're using these llms to do some kind of classification problem uh that's that's like a really a",
    "start": "1709520",
    "end": "1716000"
  },
  {
    "text": "relatively easy thing to evaluate you get labels you know what class some set of things are and you run it through the model and make sure that your classes",
    "start": "1716000",
    "end": "1722299"
  },
  {
    "text": "are agreeing if you're doing a problem like uh the one bot which is knowledge",
    "start": "1722299",
    "end": "1727880"
  },
  {
    "text": "retrieval uh now we can automate some of that",
    "start": "1727880",
    "end": "1733580"
  },
  {
    "text": "evaluation by you know ask asking you know maybe we're using GPT 3.5 to do the",
    "start": "1733580",
    "end": "1740360"
  },
  {
    "text": "actual one bot but then we evaluate it with gpt4 which is more powerful and",
    "start": "1740360",
    "end": "1745700"
  },
  {
    "text": "kind of give it the same information and ask it you know to grade GPT 3.5 now you get a sense for things but you can't",
    "start": "1745700",
    "end": "1751820"
  },
  {
    "text": "just blindly trust this you're going to need a human to go in and evaluate some subset of the examples so I think",
    "start": "1751820",
    "end": "1758779"
  },
  {
    "text": "another interesting area here when the output is a little more ambiguous or hard to like really automate an",
    "start": "1758779",
    "end": "1764539"
  },
  {
    "text": "understanding of brightness or wrongness is to incorporate uh you know some kind",
    "start": "1764539",
    "end": "1769820"
  },
  {
    "text": "of labeling pipeline whether that's directly in your application or product just like in chatgpt you can thumbs up",
    "start": "1769820",
    "end": "1776179"
  },
  {
    "text": "or thumbs down which open AI is using as a signal to like how good it is for any given question",
    "start": "1776179",
    "end": "1783080"
  },
  {
    "text": "uh or by you know partnering with a company like figure eight or or scale to",
    "start": "1783080",
    "end": "1788899"
  },
  {
    "text": "literally go and and label data to to get that measurement",
    "start": "1788899",
    "end": "1794000"
  },
  {
    "text": "but it is important for sure",
    "start": "1794000",
    "end": "1798039"
  }
]
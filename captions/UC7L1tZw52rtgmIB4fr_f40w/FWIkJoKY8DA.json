[
  {
    "start": "0",
    "end": "85000"
  },
  {
    "text": "hello everyone",
    "start": "2720",
    "end": "3679"
  },
  {
    "text": "thank you very much for coming to my",
    "start": "3679",
    "end": "5440"
  },
  {
    "text": "talk my name is roger",
    "start": "5440",
    "end": "7759"
  },
  {
    "text": "and i'm a research scientist and",
    "start": "7759",
    "end": "10240"
  },
  {
    "text": "autodesk ai lab",
    "start": "10240",
    "end": "13040"
  },
  {
    "text": "so first of all i want to thank any",
    "start": "13040",
    "end": "15040"
  },
  {
    "text": "skill for inviting me",
    "start": "15040",
    "end": "16880"
  },
  {
    "text": "it's really excited to share some works",
    "start": "16880",
    "end": "19039"
  },
  {
    "text": "from autodesk research",
    "start": "19039",
    "end": "22000"
  },
  {
    "text": "today i want to talk about distributed",
    "start": "22000",
    "end": "24880"
  },
  {
    "text": "reinforcement learning for robotic",
    "start": "24880",
    "end": "26720"
  },
  {
    "text": "assembly",
    "start": "26720",
    "end": "29199"
  },
  {
    "text": "it will cover three projects that we've",
    "start": "29199",
    "end": "32078"
  },
  {
    "text": "done in autodesk research",
    "start": "32079",
    "end": "34239"
  },
  {
    "text": "their project touch dynamic",
    "start": "34239",
    "end": "37280"
  },
  {
    "text": "experience replay and distribute",
    "start": "37280",
    "end": "40000"
  },
  {
    "text": "recurrent gdpg",
    "start": "40000",
    "end": "43200"
  },
  {
    "text": "before i jump into those projects i want",
    "start": "43760",
    "end": "45840"
  },
  {
    "text": "to give a brief introduction of autodesk",
    "start": "45840",
    "end": "48640"
  },
  {
    "text": "and the ai lab so autodesk builds",
    "start": "48640",
    "end": "52320"
  },
  {
    "text": "software that helps people imagine",
    "start": "52320",
    "end": "54719"
  },
  {
    "text": "design",
    "start": "54719",
    "end": "55520"
  },
  {
    "text": "and make a better world autodesk makes",
    "start": "55520",
    "end": "58320"
  },
  {
    "text": "software for",
    "start": "58320",
    "end": "59199"
  },
  {
    "text": "architecture engineering construction",
    "start": "59199",
    "end": "62719"
  },
  {
    "text": "manufacturing and media and",
    "start": "62719",
    "end": "65680"
  },
  {
    "text": "entertainment industries",
    "start": "65680",
    "end": "69040"
  },
  {
    "text": "for the ai lab we currently have 15",
    "start": "69040",
    "end": "71600"
  },
  {
    "text": "people",
    "start": "71600",
    "end": "72960"
  },
  {
    "text": "locating in three different locations",
    "start": "72960",
    "end": "76159"
  },
  {
    "text": "san francisco the u.s toronto canada",
    "start": "76159",
    "end": "79759"
  },
  {
    "text": "and london uk and will still keep",
    "start": "79759",
    "end": "84320"
  },
  {
    "text": "growing",
    "start": "84840",
    "end": "86080"
  },
  {
    "start": "85000",
    "end": "85000"
  },
  {
    "text": "so in autodesk ai research we focus on",
    "start": "86080",
    "end": "88960"
  },
  {
    "text": "three areas",
    "start": "88960",
    "end": "90799"
  },
  {
    "text": "geometry and geometric deep learning",
    "start": "90799",
    "end": "93920"
  },
  {
    "text": "semantics inference and reasoning",
    "start": "93920",
    "end": "97280"
  },
  {
    "text": "and simulation control the three",
    "start": "97280",
    "end": "100479"
  },
  {
    "text": "projects that were shared today fall",
    "start": "100479",
    "end": "102399"
  },
  {
    "text": "into the simulation control area",
    "start": "102399",
    "end": "105040"
  },
  {
    "text": "this area includes topics like surrogate",
    "start": "105040",
    "end": "108159"
  },
  {
    "text": "monitoring",
    "start": "108159",
    "end": "109360"
  },
  {
    "text": "system simulation like control systems",
    "start": "109360",
    "end": "112320"
  },
  {
    "text": "but also things like how people",
    "start": "112320",
    "end": "114079"
  },
  {
    "text": "behave in buildings and other",
    "start": "114079",
    "end": "115920"
  },
  {
    "text": "environments",
    "start": "115920",
    "end": "117439"
  },
  {
    "text": "and also agent-based and robotic",
    "start": "117439",
    "end": "119280"
  },
  {
    "text": "simulations",
    "start": "119280",
    "end": "120960"
  },
  {
    "text": "and reinforcement learning",
    "start": "120960",
    "end": "124479"
  },
  {
    "text": "so for the topic of today the",
    "start": "125840",
    "end": "128479"
  },
  {
    "text": "distributed reinforcement",
    "start": "128479",
    "end": "130239"
  },
  {
    "text": "for robotic assembly we started by",
    "start": "130239",
    "end": "133599"
  },
  {
    "text": "asking this question",
    "start": "133599",
    "end": "136160"
  },
  {
    "text": "can the robot learn how to assemble",
    "start": "136160",
    "end": "139520"
  },
  {
    "text": "timbo joints",
    "start": "139520",
    "end": "140879"
  },
  {
    "text": "based on real-time force torque feedback",
    "start": "140879",
    "end": "144959"
  },
  {
    "text": "to answer this question we did project",
    "start": "145840",
    "end": "148640"
  },
  {
    "start": "146000",
    "end": "146000"
  },
  {
    "text": "touch",
    "start": "148640",
    "end": "150160"
  },
  {
    "text": "and the vision is to automate the",
    "start": "150160",
    "end": "151680"
  },
  {
    "text": "building of free-form timbo frame",
    "start": "151680",
    "end": "153599"
  },
  {
    "text": "structures",
    "start": "153599",
    "end": "154640"
  },
  {
    "text": "like showing up here using robots",
    "start": "154640",
    "end": "158400"
  },
  {
    "text": "and composed of tight fitting timber",
    "start": "158400",
    "end": "160560"
  },
  {
    "text": "joints where",
    "start": "160560",
    "end": "161920"
  },
  {
    "text": "the force is knitted for insertion and",
    "start": "161920",
    "end": "165040"
  },
  {
    "text": "the misalignment is unavoidable",
    "start": "165040",
    "end": "167440"
  },
  {
    "text": "due to material deflection as well as",
    "start": "167440",
    "end": "170400"
  },
  {
    "text": "torrent stack up",
    "start": "170400",
    "end": "173360"
  },
  {
    "text": "so in the project touch the goal is to",
    "start": "174560",
    "end": "177440"
  },
  {
    "text": "learn a robot controller",
    "start": "177440",
    "end": "179280"
  },
  {
    "text": "that assembles tight fitting timber",
    "start": "179280",
    "end": "181120"
  },
  {
    "text": "joints",
    "start": "181120",
    "end": "182560"
  },
  {
    "text": "and made the image showing up on the",
    "start": "182560",
    "end": "184959"
  },
  {
    "text": "right",
    "start": "184959",
    "end": "185760"
  },
  {
    "text": "shows the spatial relationship of the",
    "start": "185760",
    "end": "187680"
  },
  {
    "text": "robot graper",
    "start": "187680",
    "end": "188879"
  },
  {
    "text": "and the timber members the observation",
    "start": "188879",
    "end": "193440"
  },
  {
    "text": "spaces include torque force feedback",
    "start": "193440",
    "end": "196480"
  },
  {
    "text": "and also the member pose in total of 13",
    "start": "196480",
    "end": "199440"
  },
  {
    "text": "dimensions",
    "start": "199440",
    "end": "200959"
  },
  {
    "text": "and actions are velocity command and",
    "start": "200959",
    "end": "203440"
  },
  {
    "text": "control posts",
    "start": "203440",
    "end": "206159"
  },
  {
    "text": "so to train this our reinforcement",
    "start": "206799",
    "end": "209440"
  },
  {
    "text": "learning agent",
    "start": "209440",
    "end": "211040"
  },
  {
    "text": "we started by using apex ddpg",
    "start": "211040",
    "end": "214480"
  },
  {
    "text": "implemented by ray and basically apex",
    "start": "214480",
    "end": "217680"
  },
  {
    "text": "tdpg",
    "start": "217680",
    "end": "218560"
  },
  {
    "text": "is a distributed rl algorithm that has",
    "start": "218560",
    "end": "221519"
  },
  {
    "text": "multiple a",
    "start": "221519",
    "end": "222879"
  },
  {
    "text": "uh that has multiple actual networks in",
    "start": "222879",
    "end": "225120"
  },
  {
    "text": "parallel",
    "start": "225120",
    "end": "226319"
  },
  {
    "text": "that each of them with an environment",
    "start": "226319",
    "end": "228239"
  },
  {
    "text": "instance",
    "start": "228239",
    "end": "229920"
  },
  {
    "text": "and they collect data and send the data",
    "start": "229920",
    "end": "232319"
  },
  {
    "text": "to the replay buffer",
    "start": "232319",
    "end": "234400"
  },
  {
    "text": "and also it has one learner network that",
    "start": "234400",
    "end": "237200"
  },
  {
    "text": "samples experience",
    "start": "237200",
    "end": "238640"
  },
  {
    "text": "from the replay buffer and updates",
    "start": "238640",
    "end": "241360"
  },
  {
    "text": "priorities",
    "start": "241360",
    "end": "242400"
  },
  {
    "text": "and also parameters",
    "start": "242400",
    "end": "245599"
  },
  {
    "text": "and for the replay buffer it's a",
    "start": "245599",
    "end": "247519"
  },
  {
    "text": "prioritized experience for play",
    "start": "247519",
    "end": "250000"
  },
  {
    "text": "so that it will prioritize transitions",
    "start": "250000",
    "end": "252560"
  },
  {
    "text": "in the",
    "start": "252560",
    "end": "253120"
  },
  {
    "text": "replay buffer based on how important",
    "start": "253120",
    "end": "256079"
  },
  {
    "text": "they are",
    "start": "256079",
    "end": "258479"
  },
  {
    "start": "259000",
    "end": "259000"
  },
  {
    "text": "and based on apex ddpg we added a module",
    "start": "260400",
    "end": "264000"
  },
  {
    "text": "in ray",
    "start": "264000",
    "end": "265040"
  },
  {
    "text": "so that apex ddpg can save human",
    "start": "265040",
    "end": "267520"
  },
  {
    "text": "demonstrations in replay buffer",
    "start": "267520",
    "end": "270800"
  },
  {
    "text": "and in this project we use droid",
    "start": "270800",
    "end": "273199"
  },
  {
    "text": "stickers",
    "start": "273199",
    "end": "274160"
  },
  {
    "text": "to control a virtual robot in simulation",
    "start": "274160",
    "end": "277120"
  },
  {
    "text": "to collect",
    "start": "277120",
    "end": "277919"
  },
  {
    "text": "human demonstrations",
    "start": "277919",
    "end": "282240"
  },
  {
    "text": "specifically our home demonstration",
    "start": "282240",
    "end": "284479"
  },
  {
    "text": "module has",
    "start": "284479",
    "end": "285440"
  },
  {
    "text": "three features first the demonstrations",
    "start": "285440",
    "end": "289680"
  },
  {
    "text": "were inserted before training starts",
    "start": "289680",
    "end": "293680"
  },
  {
    "text": "and those demonstrations permanently",
    "start": "293680",
    "end": "296160"
  },
  {
    "text": "stay in the replay buffer",
    "start": "296160",
    "end": "298560"
  },
  {
    "text": "meaning that they will never be replaced",
    "start": "298560",
    "end": "300320"
  },
  {
    "text": "by new transitions",
    "start": "300320",
    "end": "302560"
  },
  {
    "text": "and last those transitions always have",
    "start": "302560",
    "end": "305280"
  },
  {
    "text": "the",
    "start": "305280",
    "end": "305600"
  },
  {
    "text": "highest priorities",
    "start": "305600",
    "end": "310639"
  },
  {
    "text": "so we train our agents in the pipeline",
    "start": "310639",
    "end": "313840"
  },
  {
    "text": "simulation",
    "start": "313840",
    "end": "314639"
  },
  {
    "text": "entirely and then we deploy the train",
    "start": "314639",
    "end": "317840"
  },
  {
    "text": "policy",
    "start": "317840",
    "end": "318720"
  },
  {
    "text": "on the real robot and this video shows",
    "start": "318720",
    "end": "321759"
  },
  {
    "text": "we deploy the policy of the lab joint",
    "start": "321759",
    "end": "323919"
  },
  {
    "text": "task",
    "start": "323919",
    "end": "324560"
  },
  {
    "text": "on the real robot as you can see from",
    "start": "324560",
    "end": "328000"
  },
  {
    "text": "the video this method works well",
    "start": "328000",
    "end": "330240"
  },
  {
    "text": "in the insertion of a 75 degree single",
    "start": "330240",
    "end": "333360"
  },
  {
    "text": "lap joint",
    "start": "333360",
    "end": "335918"
  },
  {
    "text": "and also works well on a 60 degree",
    "start": "336800",
    "end": "339039"
  },
  {
    "text": "single lap joint",
    "start": "339039",
    "end": "341919"
  },
  {
    "text": "but it failed in the 45 degree single",
    "start": "347120",
    "end": "350080"
  },
  {
    "text": "lap joints",
    "start": "350080",
    "end": "353840"
  },
  {
    "text": "so that one challenge we find from this",
    "start": "356240",
    "end": "358880"
  },
  {
    "text": "project",
    "start": "358880",
    "end": "359440"
  },
  {
    "text": "is that human demonstrations could be",
    "start": "359440",
    "end": "361520"
  },
  {
    "text": "misleading sometimes",
    "start": "361520",
    "end": "363520"
  },
  {
    "start": "362000",
    "end": "362000"
  },
  {
    "text": "especially in torque force tight fade",
    "start": "363520",
    "end": "366479"
  },
  {
    "text": "assembly tasks",
    "start": "366479",
    "end": "368400"
  },
  {
    "text": "and one of the reasons is that in the",
    "start": "368400",
    "end": "370880"
  },
  {
    "text": "simulation",
    "start": "370880",
    "end": "372000"
  },
  {
    "text": "human demonstrators only have the vision",
    "start": "372000",
    "end": "374240"
  },
  {
    "text": "feedback",
    "start": "374240",
    "end": "375039"
  },
  {
    "text": "to control and perform the task however",
    "start": "375039",
    "end": "378639"
  },
  {
    "text": "when the robot performing tasks either",
    "start": "378639",
    "end": "380880"
  },
  {
    "text": "in the simulation",
    "start": "380880",
    "end": "381759"
  },
  {
    "text": "or in the real world they don't have",
    "start": "381759",
    "end": "383600"
  },
  {
    "text": "vision feedback",
    "start": "383600",
    "end": "384880"
  },
  {
    "text": "they only have haptic feedback to",
    "start": "384880",
    "end": "386960"
  },
  {
    "text": "perform the tasks",
    "start": "386960",
    "end": "388560"
  },
  {
    "text": "so there's a misalignment between real",
    "start": "388560",
    "end": "391280"
  },
  {
    "text": "transitions",
    "start": "391280",
    "end": "392560"
  },
  {
    "text": "that from the robots and demonstrations",
    "start": "392560",
    "end": "395759"
  },
  {
    "text": "collected by humans",
    "start": "395759",
    "end": "398800"
  },
  {
    "text": "so then we ask this next question can we",
    "start": "399680",
    "end": "402720"
  },
  {
    "text": "use demonstrations",
    "start": "402720",
    "end": "404000"
  },
  {
    "text": "collected from haptic feedback as the",
    "start": "404000",
    "end": "406840"
  },
  {
    "text": "demonstrations",
    "start": "406840",
    "end": "408160"
  },
  {
    "text": "in the replay buffer",
    "start": "408160",
    "end": "411199"
  },
  {
    "start": "412000",
    "end": "412000"
  },
  {
    "text": "and that resulted in the second project",
    "start": "412720",
    "end": "415599"
  },
  {
    "text": "dynamic experience for play",
    "start": "415599",
    "end": "418240"
  },
  {
    "text": "the core idea is that robots learn from",
    "start": "418240",
    "end": "420800"
  },
  {
    "text": "each other's",
    "start": "420800",
    "end": "421599"
  },
  {
    "text": "successful experience so that it's like",
    "start": "421599",
    "end": "425440"
  },
  {
    "text": "augmenting human demonstrations with",
    "start": "425440",
    "end": "427360"
  },
  {
    "text": "successful transitions",
    "start": "427360",
    "end": "428960"
  },
  {
    "text": "generated by our agents during training",
    "start": "428960",
    "end": "432240"
  },
  {
    "text": "and it can be seen as over sampling the",
    "start": "432240",
    "end": "434639"
  },
  {
    "text": "underrepresented clause",
    "start": "434639",
    "end": "436479"
  },
  {
    "text": "in imbalanced data set in supervised",
    "start": "436479",
    "end": "439280"
  },
  {
    "text": "learning",
    "start": "439280",
    "end": "440560"
  },
  {
    "text": "this work has been published in 2019",
    "start": "440560",
    "end": "443680"
  },
  {
    "text": "conference on robot learning",
    "start": "443680",
    "end": "445040"
  },
  {
    "text": "[Music]",
    "start": "445040",
    "end": "448119"
  },
  {
    "start": "448000",
    "end": "448000"
  },
  {
    "text": "so to start with this experiment we",
    "start": "448720",
    "end": "451520"
  },
  {
    "text": "proposed four different buffer",
    "start": "451520",
    "end": "453199"
  },
  {
    "text": "structures",
    "start": "453199",
    "end": "454160"
  },
  {
    "text": "for our study and we have number one",
    "start": "454160",
    "end": "458240"
  },
  {
    "text": "not using human demonstrations at all",
    "start": "458240",
    "end": "461440"
  },
  {
    "text": "number two randomly picking one human",
    "start": "461440",
    "end": "464160"
  },
  {
    "text": "demonstration",
    "start": "464160",
    "end": "464960"
  },
  {
    "text": "and inserting that demonstration into",
    "start": "464960",
    "end": "467360"
  },
  {
    "text": "all the buffers",
    "start": "467360",
    "end": "469360"
  },
  {
    "text": "number three inserting all the human",
    "start": "469360",
    "end": "471759"
  },
  {
    "text": "demonstrations to each buffer",
    "start": "471759",
    "end": "474160"
  },
  {
    "text": "and number four each buffer randomly",
    "start": "474160",
    "end": "476560"
  },
  {
    "text": "picking a single human demonstration",
    "start": "476560",
    "end": "480560"
  },
  {
    "start": "481000",
    "end": "481000"
  },
  {
    "text": "and here's our system diagram as you can",
    "start": "481680",
    "end": "484879"
  },
  {
    "text": "see it's similar to apex",
    "start": "484879",
    "end": "486960"
  },
  {
    "text": "ddpg but instead of one replay buffer",
    "start": "486960",
    "end": "491520"
  },
  {
    "text": "we have multiple replay buffers",
    "start": "491520",
    "end": "494639"
  },
  {
    "text": "and before training the replay buffers",
    "start": "494639",
    "end": "496879"
  },
  {
    "text": "are initialized",
    "start": "496879",
    "end": "498160"
  },
  {
    "text": "based on the chosen buffer structure",
    "start": "498160",
    "end": "500960"
  },
  {
    "text": "during the training each",
    "start": "500960",
    "end": "502160"
  },
  {
    "text": "virtual robot interacts with its own",
    "start": "502160",
    "end": "504160"
  },
  {
    "text": "environment to collect data",
    "start": "504160",
    "end": "506800"
  },
  {
    "text": "and once a successful episode occurs it",
    "start": "506800",
    "end": "509759"
  },
  {
    "text": "will be saved in storage",
    "start": "509759",
    "end": "512159"
  },
  {
    "text": "each buffer period periodically and",
    "start": "512159",
    "end": "515120"
  },
  {
    "text": "independently",
    "start": "515120",
    "end": "516320"
  },
  {
    "text": "samples one successful transition from",
    "start": "516320",
    "end": "518479"
  },
  {
    "text": "storage",
    "start": "518479",
    "end": "519518"
  },
  {
    "text": "and saves it in a demonstration zoom in",
    "start": "519519",
    "end": "522479"
  },
  {
    "text": "their buffer",
    "start": "522479",
    "end": "523919"
  },
  {
    "text": "so that human demonstrations will be",
    "start": "523919",
    "end": "525920"
  },
  {
    "text": "gradually replaced",
    "start": "525920",
    "end": "527440"
  },
  {
    "text": "by robot demonstrations again",
    "start": "527440",
    "end": "530560"
  },
  {
    "text": "we build our system on top of race",
    "start": "530560",
    "end": "533040"
  },
  {
    "text": "implementation",
    "start": "533040",
    "end": "534240"
  },
  {
    "text": "of apex ddbg",
    "start": "534240",
    "end": "537440"
  },
  {
    "start": "538000",
    "end": "538000"
  },
  {
    "text": "so we compare our algorithm with apex",
    "start": "538160",
    "end": "540560"
  },
  {
    "text": "gdpg on two assembly tasks",
    "start": "540560",
    "end": "543200"
  },
  {
    "text": "packing hole and lab joints here are the",
    "start": "543200",
    "end": "546080"
  },
  {
    "text": "results from the packing whole task",
    "start": "546080",
    "end": "548240"
  },
  {
    "text": "in the beginning both two agents just",
    "start": "548240",
    "end": "550240"
  },
  {
    "text": "like randomly explored",
    "start": "550240",
    "end": "552160"
  },
  {
    "text": "space",
    "start": "552160",
    "end": "554560"
  },
  {
    "text": "in the middle of the training our method",
    "start": "555440",
    "end": "557440"
  },
  {
    "text": "has figured out",
    "start": "557440",
    "end": "558959"
  },
  {
    "text": "the general goal and reach the",
    "start": "558959",
    "end": "560640"
  },
  {
    "text": "successful rate of 58 percent",
    "start": "560640",
    "end": "563200"
  },
  {
    "text": "while the veneto apex dtpg is still",
    "start": "563200",
    "end": "565519"
  },
  {
    "text": "exploring",
    "start": "565519",
    "end": "568079"
  },
  {
    "text": "by the end of the training our method",
    "start": "570880",
    "end": "572800"
  },
  {
    "text": "has reached accessible rate of 91",
    "start": "572800",
    "end": "574959"
  },
  {
    "text": "percent",
    "start": "574959",
    "end": "576640"
  },
  {
    "text": "while the pure apex tdpg only has got to",
    "start": "576640",
    "end": "579760"
  },
  {
    "text": "58 percent",
    "start": "579760",
    "end": "582800"
  },
  {
    "text": "and here are the plots to show the",
    "start": "585440",
    "end": "587040"
  },
  {
    "text": "comparative results on four different",
    "start": "587040",
    "end": "589120"
  },
  {
    "text": "buffer structures",
    "start": "589120",
    "end": "590399"
  },
  {
    "text": "of the packing hole task so with dr",
    "start": "590399",
    "end": "594000"
  },
  {
    "text": "it can largely improve the trading",
    "start": "594000",
    "end": "595839"
  },
  {
    "text": "efficiency on three other four buffer",
    "start": "595839",
    "end": "598160"
  },
  {
    "text": "structures",
    "start": "598160",
    "end": "600000"
  },
  {
    "text": "like the one in no human demos one shot",
    "start": "600000",
    "end": "602959"
  },
  {
    "text": "in all buffers",
    "start": "602959",
    "end": "604160"
  },
  {
    "text": "and all shots in all buffers",
    "start": "604160",
    "end": "607600"
  },
  {
    "text": "and here the results of the lab drawing",
    "start": "609920",
    "end": "611760"
  },
  {
    "text": "task similarly with dr",
    "start": "611760",
    "end": "614800"
  },
  {
    "text": "it has better performance on two buffer",
    "start": "614800",
    "end": "616839"
  },
  {
    "text": "structures no human demos",
    "start": "616839",
    "end": "619360"
  },
  {
    "text": "and all shots in all buffers",
    "start": "619360",
    "end": "622959"
  },
  {
    "text": "so in project touch and dynamic",
    "start": "625279",
    "end": "627839"
  },
  {
    "text": "experience replay",
    "start": "627839",
    "end": "630079"
  },
  {
    "text": "both of them require post information to",
    "start": "630079",
    "end": "632480"
  },
  {
    "text": "be available",
    "start": "632480",
    "end": "633680"
  },
  {
    "text": "in the observation spaces in many",
    "start": "633680",
    "end": "637279"
  },
  {
    "text": "current successful examples",
    "start": "637279",
    "end": "639760"
  },
  {
    "text": "of rl in assembly tasks",
    "start": "639760",
    "end": "643279"
  },
  {
    "text": "that require observation states to be",
    "start": "643279",
    "end": "645360"
  },
  {
    "text": "fully observable",
    "start": "645360",
    "end": "646480"
  },
  {
    "text": "to perform complex real-world control",
    "start": "646480",
    "end": "649279"
  },
  {
    "text": "tasks",
    "start": "649279",
    "end": "651680"
  },
  {
    "text": "and in order to do that it requires",
    "start": "651760",
    "end": "654240"
  },
  {
    "text": "additional equipment",
    "start": "654240",
    "end": "655600"
  },
  {
    "text": "like a motion interaction like a motion",
    "start": "655600",
    "end": "657680"
  },
  {
    "text": "tracking system",
    "start": "657680",
    "end": "659440"
  },
  {
    "text": "but it is unrealistic to expect a motion",
    "start": "659440",
    "end": "662079"
  },
  {
    "text": "capture another tracking system",
    "start": "662079",
    "end": "664160"
  },
  {
    "text": "and the assembly construction sites like",
    "start": "664160",
    "end": "666800"
  },
  {
    "text": "showing up in the image",
    "start": "666800",
    "end": "668560"
  },
  {
    "text": "because they are too expensive and hard",
    "start": "668560",
    "end": "670880"
  },
  {
    "text": "to scale",
    "start": "670880",
    "end": "674959"
  },
  {
    "text": "so therefore that leads to another",
    "start": "674959",
    "end": "676560"
  },
  {
    "text": "question we want to explore",
    "start": "676560",
    "end": "678640"
  },
  {
    "text": "which is can we only use workforce",
    "start": "678640",
    "end": "681360"
  },
  {
    "text": "readings",
    "start": "681360",
    "end": "682160"
  },
  {
    "text": "from the ending factor of give us the",
    "start": "682160",
    "end": "684480"
  },
  {
    "text": "observations",
    "start": "684480",
    "end": "687199"
  },
  {
    "start": "687000",
    "end": "687000"
  },
  {
    "text": "because we only use partial observation",
    "start": "687760",
    "end": "690880"
  },
  {
    "text": "it's a topic about robot robotic",
    "start": "690880",
    "end": "694079"
  },
  {
    "text": "assembly with partial observability",
    "start": "694079",
    "end": "698000"
  },
  {
    "text": "and the goal of this research is to",
    "start": "698959",
    "end": "702079"
  },
  {
    "text": "develop algorithm to solve partial",
    "start": "702079",
    "end": "704079"
  },
  {
    "text": "observable robotic assembly tasks",
    "start": "704079",
    "end": "706480"
  },
  {
    "text": "in a continuous action domain with",
    "start": "706480",
    "end": "709040"
  },
  {
    "text": "torque for sensing being the only",
    "start": "709040",
    "end": "710880"
  },
  {
    "text": "observation",
    "start": "710880",
    "end": "712800"
  },
  {
    "text": "namely that we don't need any external",
    "start": "712800",
    "end": "714800"
  },
  {
    "text": "systems to provide",
    "start": "714800",
    "end": "716079"
  },
  {
    "text": "velocity or post information which are",
    "start": "716079",
    "end": "719360"
  },
  {
    "text": "usually used in the observation",
    "start": "719360",
    "end": "723040"
  },
  {
    "text": "the robot with its own onboard sensors",
    "start": "723040",
    "end": "725360"
  },
  {
    "text": "can make decisions based on partial",
    "start": "725360",
    "end": "727360"
  },
  {
    "text": "knowledge about the environment",
    "start": "727360",
    "end": "731839"
  },
  {
    "text": "so to solve this problem we propose this",
    "start": "732079",
    "end": "734800"
  },
  {
    "text": "algorithm called",
    "start": "734800",
    "end": "736320"
  },
  {
    "text": "recurrent distributed ddpg short for rd2",
    "start": "736320",
    "end": "740480"
  },
  {
    "text": "so based on apex ddpg rd2 adds",
    "start": "740480",
    "end": "743360"
  },
  {
    "text": "recurrency to both",
    "start": "743360",
    "end": "745040"
  },
  {
    "text": "actual and critique network and their",
    "start": "745040",
    "end": "746880"
  },
  {
    "text": "target networks",
    "start": "746880",
    "end": "748800"
  },
  {
    "text": "so that the rl agent have memories",
    "start": "748800",
    "end": "752079"
  },
  {
    "text": "for purpose states and actions which can",
    "start": "752079",
    "end": "754639"
  },
  {
    "text": "improve",
    "start": "754639",
    "end": "755120"
  },
  {
    "text": "its performance in partial observable",
    "start": "755120",
    "end": "756839"
  },
  {
    "text": "tasks",
    "start": "756839",
    "end": "758240"
  },
  {
    "text": "however we find out that by only adding",
    "start": "758240",
    "end": "760480"
  },
  {
    "text": "the currency",
    "start": "760480",
    "end": "761760"
  },
  {
    "text": "cannot achieve a stable training",
    "start": "761760",
    "end": "764399"
  },
  {
    "text": "therefore we also develop",
    "start": "764399",
    "end": "766079"
  },
  {
    "text": "another two techniques to stabilize the",
    "start": "766079",
    "end": "768399"
  },
  {
    "text": "training",
    "start": "768399",
    "end": "770480"
  },
  {
    "text": "first we designed a dynamic mechanism to",
    "start": "770480",
    "end": "773200"
  },
  {
    "text": "overlap",
    "start": "773200",
    "end": "774000"
  },
  {
    "text": "the last two sequences in each episode",
    "start": "774000",
    "end": "777360"
  },
  {
    "text": "as you know in a replay uh in the replay",
    "start": "777360",
    "end": "779839"
  },
  {
    "text": "buffer",
    "start": "779839",
    "end": "780639"
  },
  {
    "text": "we store the fixed lens synchronous of",
    "start": "780639",
    "end": "782720"
  },
  {
    "text": "transitions",
    "start": "782720",
    "end": "784079"
  },
  {
    "text": "that each sequence contains m",
    "start": "784079",
    "end": "786160"
  },
  {
    "text": "transitions",
    "start": "786160",
    "end": "787760"
  },
  {
    "text": "we also make sure the adjacent sequence",
    "start": "787760",
    "end": "790000"
  },
  {
    "text": "overlapped",
    "start": "790000",
    "end": "790800"
  },
  {
    "text": "by m by two time steps and the batches",
    "start": "790800",
    "end": "793839"
  },
  {
    "text": "of sequences never cross the episode",
    "start": "793839",
    "end": "795839"
  },
  {
    "text": "boundary",
    "start": "795839",
    "end": "797600"
  },
  {
    "text": "because the length of episodes in our",
    "start": "797600",
    "end": "799839"
  },
  {
    "text": "assembly tasks varies",
    "start": "799839",
    "end": "802000"
  },
  {
    "text": "we then use this dynamic mechanism to",
    "start": "802000",
    "end": "804399"
  },
  {
    "text": "allow the last",
    "start": "804399",
    "end": "805519"
  },
  {
    "text": "overlap in each episode to be a variable",
    "start": "805519",
    "end": "809120"
  },
  {
    "text": "between",
    "start": "809120",
    "end": "809680"
  },
  {
    "text": "n by two and m minus one",
    "start": "809680",
    "end": "812480"
  },
  {
    "text": "[Music]",
    "start": "812480",
    "end": "813680"
  },
  {
    "text": "specifically the last overlap is",
    "start": "813680",
    "end": "815680"
  },
  {
    "text": "calculated as in the formula one",
    "start": "815680",
    "end": "819279"
  },
  {
    "text": "and we also create a two level",
    "start": "819279",
    "end": "821120"
  },
  {
    "text": "prioritized experience replay",
    "start": "821120",
    "end": "824240"
  },
  {
    "text": "basically we use absolute and step td",
    "start": "824240",
    "end": "827519"
  },
  {
    "text": "arrows",
    "start": "827519",
    "end": "828079"
  },
  {
    "text": "as the priorities for transitions and",
    "start": "828079",
    "end": "830959"
  },
  {
    "text": "use the formula 2 to calculate",
    "start": "830959",
    "end": "833120"
  },
  {
    "text": "priorities for sequences",
    "start": "833120",
    "end": "836160"
  },
  {
    "text": "where delta is a list of td arrows in",
    "start": "836160",
    "end": "838320"
  },
  {
    "text": "one sequence",
    "start": "838320",
    "end": "840320"
  },
  {
    "text": "and for each transition in the sequence",
    "start": "840320",
    "end": "842880"
  },
  {
    "text": "we correct the bios using important",
    "start": "842880",
    "end": "845040"
  },
  {
    "text": "sampling weights",
    "start": "845040",
    "end": "846160"
  },
  {
    "text": "as shown in formula 3 on each transition",
    "start": "846160",
    "end": "849199"
  },
  {
    "text": "and normalized weights so therefore we",
    "start": "849199",
    "end": "852480"
  },
  {
    "text": "have",
    "start": "852480",
    "end": "853040"
  },
  {
    "text": "priorities for tran for the transitions",
    "start": "853040",
    "end": "855839"
  },
  {
    "text": "and also we have priorities",
    "start": "855839",
    "end": "857519"
  },
  {
    "text": "for sequences and they are used for",
    "start": "857519",
    "end": "859600"
  },
  {
    "text": "different purposes",
    "start": "859600",
    "end": "862079"
  },
  {
    "text": "and we find out that those two methods",
    "start": "862079",
    "end": "864320"
  },
  {
    "text": "can largely improve the stability of",
    "start": "864320",
    "end": "868079"
  },
  {
    "text": "training",
    "start": "868839",
    "end": "870240"
  },
  {
    "start": "869000",
    "end": "869000"
  },
  {
    "text": "to train our rd2 agents we designed lab",
    "start": "870240",
    "end": "873279"
  },
  {
    "text": "joint environment in pi bullet",
    "start": "873279",
    "end": "875839"
  },
  {
    "text": "to evaluate rdt and compare with another",
    "start": "875839",
    "end": "878399"
  },
  {
    "text": "two state-of-arts algorithms",
    "start": "878399",
    "end": "881680"
  },
  {
    "text": "the environment consists of two",
    "start": "881680",
    "end": "883360"
  },
  {
    "text": "francopenda robot arms",
    "start": "883360",
    "end": "885440"
  },
  {
    "text": "each of which holds a member of the",
    "start": "885440",
    "end": "887440"
  },
  {
    "text": "joint and the two members are",
    "start": "887440",
    "end": "889519"
  },
  {
    "text": "perpendicular to each other by default",
    "start": "889519",
    "end": "892480"
  },
  {
    "text": "one arm is fixed as shown on the left",
    "start": "892480",
    "end": "895920"
  },
  {
    "text": "and keeping the joint member static the",
    "start": "895920",
    "end": "898639"
  },
  {
    "text": "another arm moves to another joint",
    "start": "898639",
    "end": "900240"
  },
  {
    "text": "members",
    "start": "900240",
    "end": "900880"
  },
  {
    "text": "to complete the joints and we design",
    "start": "900880",
    "end": "904160"
  },
  {
    "text": "eight different tasks in environment",
    "start": "904160",
    "end": "906079"
  },
  {
    "text": "with varying complexity",
    "start": "906079",
    "end": "908000"
  },
  {
    "text": "as shown on table here by setting the",
    "start": "908000",
    "end": "911440"
  },
  {
    "text": "fixed arm on different initial poses",
    "start": "911440",
    "end": "914480"
  },
  {
    "text": "so the joint member on the fixed arm",
    "start": "914480",
    "end": "916480"
  },
  {
    "text": "either has angular offsets",
    "start": "916480",
    "end": "918639"
  },
  {
    "text": "or a linear offset from its default pose",
    "start": "918639",
    "end": "921920"
  },
  {
    "text": "in general the larger the offsets or the",
    "start": "921920",
    "end": "924720"
  },
  {
    "text": "more",
    "start": "924720",
    "end": "925040"
  },
  {
    "text": "access are involved the more difficult",
    "start": "925040",
    "end": "927600"
  },
  {
    "text": "it is to train",
    "start": "927600",
    "end": "928500"
  },
  {
    "text": "[Music]",
    "start": "928500",
    "end": "930160"
  },
  {
    "text": "the table up here shows the details of",
    "start": "930160",
    "end": "932639"
  },
  {
    "text": "each task",
    "start": "932639",
    "end": "934399"
  },
  {
    "text": "we present these tasks because harder",
    "start": "934399",
    "end": "936639"
  },
  {
    "text": "tasks",
    "start": "936639",
    "end": "937600"
  },
  {
    "text": "result in failure among all three",
    "start": "937600",
    "end": "939360"
  },
  {
    "text": "algorithms",
    "start": "939360",
    "end": "940639"
  },
  {
    "text": "and things are not meaningful",
    "start": "940639",
    "end": "944000"
  },
  {
    "text": "so we compare our rd2 with",
    "start": "946560",
    "end": "950399"
  },
  {
    "text": "another two state of our algorithms apex",
    "start": "950399",
    "end": "953040"
  },
  {
    "text": "ddpg",
    "start": "953040",
    "end": "954079"
  },
  {
    "text": "and ppo with lstm",
    "start": "954079",
    "end": "957839"
  },
  {
    "text": "and as you can see in the chart our",
    "start": "957839",
    "end": "960399"
  },
  {
    "text": "algorithm",
    "start": "960399",
    "end": "961600"
  },
  {
    "text": "which are in the blue dots and blue area",
    "start": "961600",
    "end": "965120"
  },
  {
    "text": "has the best performance across all",
    "start": "965120",
    "end": "967360"
  },
  {
    "text": "tasks",
    "start": "967360",
    "end": "968720"
  },
  {
    "text": "i've only shown four results here but",
    "start": "968720",
    "end": "970880"
  },
  {
    "text": "also it has the best performance in",
    "start": "970880",
    "end": "973120"
  },
  {
    "text": "other four tasks",
    "start": "973120",
    "end": "975199"
  },
  {
    "text": "and in some hard tasks like the one on",
    "start": "975199",
    "end": "977759"
  },
  {
    "text": "upper right",
    "start": "977759",
    "end": "978959"
  },
  {
    "text": "it's a 8 degree angle offset around",
    "start": "978959",
    "end": "982160"
  },
  {
    "text": "x-axis rd2 is the only algorithm can",
    "start": "982160",
    "end": "986480"
  },
  {
    "text": "solve this task",
    "start": "986480",
    "end": "989279"
  },
  {
    "start": "990000",
    "end": "990000"
  },
  {
    "text": "and and last we evaluate how well the",
    "start": "990959",
    "end": "993680"
  },
  {
    "text": "trend policies adapt to new situations",
    "start": "993680",
    "end": "997120"
  },
  {
    "text": "we specifically consider two types of",
    "start": "997120",
    "end": "999279"
  },
  {
    "text": "situations",
    "start": "999279",
    "end": "1000800"
  },
  {
    "text": "one is initial offsets which are initial",
    "start": "1000800",
    "end": "1003759"
  },
  {
    "text": "positions",
    "start": "1003759",
    "end": "1004480"
  },
  {
    "text": "and initial orientations that divide",
    "start": "1004480",
    "end": "1007600"
  },
  {
    "text": "from those in trainings",
    "start": "1007600",
    "end": "1009680"
  },
  {
    "text": "another is a physical noise in",
    "start": "1009680",
    "end": "1011199"
  },
  {
    "text": "simulation such as",
    "start": "1011199",
    "end": "1012959"
  },
  {
    "text": "forward torque sensor noise and",
    "start": "1012959",
    "end": "1015120"
  },
  {
    "text": "inaccuracy in friction monitoring",
    "start": "1015120",
    "end": "1017680"
  },
  {
    "text": "we use two trend policies and around 20",
    "start": "1017680",
    "end": "1020320"
  },
  {
    "text": "row outs",
    "start": "1020320",
    "end": "1021120"
  },
  {
    "text": "for each case",
    "start": "1021120",
    "end": "1024319"
  },
  {
    "text": "so as you can see here from the video",
    "start": "1024319",
    "end": "1026720"
  },
  {
    "text": "that our trend policy adapts well",
    "start": "1026720",
    "end": "1029280"
  },
  {
    "text": "to various initial poses",
    "start": "1029280",
    "end": "1032880"
  },
  {
    "text": "and also it works well as physical noise",
    "start": "1036799",
    "end": "1039199"
  },
  {
    "text": "injected in simulation",
    "start": "1039199",
    "end": "1042640"
  },
  {
    "text": "here the results of the evaluations of",
    "start": "1046799",
    "end": "1049039"
  },
  {
    "text": "initial position offset",
    "start": "1049039",
    "end": "1050799"
  },
  {
    "text": "angular offset and physical noise",
    "start": "1050799",
    "end": "1054240"
  },
  {
    "text": "as shown in the first row on the left",
    "start": "1054240",
    "end": "1056880"
  },
  {
    "text": "our policy adapts well to linear offsets",
    "start": "1056880",
    "end": "1059200"
  },
  {
    "text": "in three axis",
    "start": "1059200",
    "end": "1061200"
  },
  {
    "text": "it gets a hundred percent successful",
    "start": "1061200",
    "end": "1063679"
  },
  {
    "text": "rate",
    "start": "1063679",
    "end": "1064480"
  },
  {
    "text": "on both the 5 millimeter and 10",
    "start": "1064480",
    "end": "1066720"
  },
  {
    "text": "millimeter offset tasks",
    "start": "1066720",
    "end": "1069120"
  },
  {
    "text": "although because 10 millimeters on all",
    "start": "1069120",
    "end": "1071200"
  },
  {
    "text": "access is not a small misalignment",
    "start": "1071200",
    "end": "1073760"
  },
  {
    "text": "the main reward to the task is lower",
    "start": "1073760",
    "end": "1078000"
  },
  {
    "text": "as shown on the right chart in the first",
    "start": "1078000",
    "end": "1080080"
  },
  {
    "text": "row our trend policy adapts well to",
    "start": "1080080",
    "end": "1082799"
  },
  {
    "text": "isolated",
    "start": "1082799",
    "end": "1084000"
  },
  {
    "text": "and small angular offsets such as five",
    "start": "1084000",
    "end": "1086799"
  },
  {
    "text": "degrees around y",
    "start": "1086799",
    "end": "1088559"
  },
  {
    "text": "and two degrees around z with successful",
    "start": "1088559",
    "end": "1091760"
  },
  {
    "text": "rate both and",
    "start": "1091760",
    "end": "1092799"
  },
  {
    "text": "and a hundred percent when there's an",
    "start": "1092799",
    "end": "1095840"
  },
  {
    "text": "offset around two or more access the",
    "start": "1095840",
    "end": "1098640"
  },
  {
    "text": "mean reward is lower",
    "start": "1098640",
    "end": "1100640"
  },
  {
    "text": "and the successful rate reduces to 55",
    "start": "1100640",
    "end": "1104080"
  },
  {
    "text": "percent",
    "start": "1104080",
    "end": "1105919"
  },
  {
    "text": "for the forced torque observation we add",
    "start": "1105919",
    "end": "1109280"
  },
  {
    "text": "zero mean gaussian noise with standard",
    "start": "1109280",
    "end": "1111840"
  },
  {
    "text": "deviation of fifty percent",
    "start": "1111840",
    "end": "1113760"
  },
  {
    "text": "and eighty percent of nominal towards",
    "start": "1113760",
    "end": "1116000"
  },
  {
    "text": "value during evaluation",
    "start": "1116000",
    "end": "1118160"
  },
  {
    "text": "as shown in the second row our trend",
    "start": "1118160",
    "end": "1121039"
  },
  {
    "text": "policy adapts well to the 50",
    "start": "1121039",
    "end": "1123200"
  },
  {
    "text": "standard deviation with successful rate",
    "start": "1123200",
    "end": "1126160"
  },
  {
    "text": "at 90 percent",
    "start": "1126160",
    "end": "1128080"
  },
  {
    "text": "as the fork towards noise standard",
    "start": "1128080",
    "end": "1130000"
  },
  {
    "text": "deviation increases to 80 percent",
    "start": "1130000",
    "end": "1132480"
  },
  {
    "text": "the mean reward of the policy lowers and",
    "start": "1132480",
    "end": "1135440"
  },
  {
    "text": "its successful rates reduced to 50",
    "start": "1135440",
    "end": "1137200"
  },
  {
    "text": "percent",
    "start": "1137200",
    "end": "1139440"
  },
  {
    "text": "for the friction parameter we add zero",
    "start": "1139440",
    "end": "1142000"
  },
  {
    "text": "mean gaussian noises with standard",
    "start": "1142000",
    "end": "1143520"
  },
  {
    "text": "deviation",
    "start": "1143520",
    "end": "1144640"
  },
  {
    "text": "of 100 of the nominal friction value",
    "start": "1144640",
    "end": "1148160"
  },
  {
    "text": "during",
    "start": "1148160",
    "end": "1149840"
  },
  {
    "text": "as shown in the second row here the",
    "start": "1149840",
    "end": "1152320"
  },
  {
    "text": "trend policy adapts well by maintaining",
    "start": "1152320",
    "end": "1155280"
  },
  {
    "text": "similar mean rewards to that without any",
    "start": "1155280",
    "end": "1158160"
  },
  {
    "text": "noise",
    "start": "1158160",
    "end": "1158960"
  },
  {
    "text": "and having slightly lower successful",
    "start": "1158960",
    "end": "1160960"
  },
  {
    "text": "rate and 80 percent",
    "start": "1160960",
    "end": "1163280"
  },
  {
    "text": "when both types of noise are combined",
    "start": "1163280",
    "end": "1166000"
  },
  {
    "text": "the successful rate and the main reward",
    "start": "1166000",
    "end": "1168400"
  },
  {
    "text": "are slightly lower so as you can see",
    "start": "1168400",
    "end": "1171679"
  },
  {
    "text": "that our algorithm rd2",
    "start": "1171679",
    "end": "1174240"
  },
  {
    "text": "can solve some partially observable",
    "start": "1174240",
    "end": "1176720"
  },
  {
    "text": "assembly tasks",
    "start": "1176720",
    "end": "1178080"
  },
  {
    "text": "that another state-of-art algorithms",
    "start": "1178080",
    "end": "1179919"
  },
  {
    "text": "cannot solve",
    "start": "1179919",
    "end": "1181280"
  },
  {
    "text": "and also it adapts well in different",
    "start": "1181280",
    "end": "1183360"
  },
  {
    "text": "simulations",
    "start": "1183360",
    "end": "1184559"
  },
  {
    "text": "with different physical conditions or",
    "start": "1184559",
    "end": "1187039"
  },
  {
    "text": "different",
    "start": "1187039",
    "end": "1187919"
  },
  {
    "text": "initial poses",
    "start": "1187919",
    "end": "1190799"
  },
  {
    "start": "1191000",
    "end": "1191000"
  },
  {
    "text": "here's a quick recap of the three",
    "start": "1191520",
    "end": "1193520"
  },
  {
    "text": "projects i just talked about",
    "start": "1193520",
    "end": "1195600"
  },
  {
    "text": "so in the project touch we demonstrate",
    "start": "1195600",
    "end": "1198080"
  },
  {
    "text": "that robots can learn to assemble temple",
    "start": "1198080",
    "end": "1200240"
  },
  {
    "text": "joints",
    "start": "1200240",
    "end": "1201039"
  },
  {
    "text": "based on real-time force torque feedback",
    "start": "1201039",
    "end": "1203600"
  },
  {
    "text": "with human demonstrations",
    "start": "1203600",
    "end": "1205760"
  },
  {
    "text": "in dynamic experience replay we use",
    "start": "1205760",
    "end": "1208640"
  },
  {
    "text": "successful robotic transitions",
    "start": "1208640",
    "end": "1210799"
  },
  {
    "text": "to replace human demonstrations to have",
    "start": "1210799",
    "end": "1213600"
  },
  {
    "text": "more accurate demonstrations in torque",
    "start": "1213600",
    "end": "1215600"
  },
  {
    "text": "force",
    "start": "1215600",
    "end": "1216240"
  },
  {
    "text": "tight fitting assembly tasks in the",
    "start": "1216240",
    "end": "1219120"
  },
  {
    "text": "distributed recurrent ddpg",
    "start": "1219120",
    "end": "1221360"
  },
  {
    "text": "we design rd2 to solve partially",
    "start": "1221360",
    "end": "1224240"
  },
  {
    "text": "observable assembly tasks",
    "start": "1224240",
    "end": "1226000"
  },
  {
    "text": "that only the torque force readings from",
    "start": "1226000",
    "end": "1228640"
  },
  {
    "text": "any factor are used as",
    "start": "1228640",
    "end": "1230400"
  },
  {
    "text": "observations and it outperforms another",
    "start": "1230400",
    "end": "1234159"
  },
  {
    "text": "state of art algorithms in same ascent",
    "start": "1234159",
    "end": "1237039"
  },
  {
    "text": "in some",
    "start": "1237039",
    "end": "1238159"
  },
  {
    "text": "assembly tasks",
    "start": "1238159",
    "end": "1241120"
  },
  {
    "text": "and last i want to thank mike hayley",
    "start": "1242799",
    "end": "1245679"
  },
  {
    "text": "tony acoustics",
    "start": "1245679",
    "end": "1247200"
  },
  {
    "text": "and aaron brender for budgetary support",
    "start": "1247200",
    "end": "1250559"
  },
  {
    "text": "i want to thank hui lee and nick code",
    "start": "1250559",
    "end": "1253840"
  },
  {
    "text": "for collaborating these projects and",
    "start": "1253840",
    "end": "1256640"
  },
  {
    "text": "also want to thank",
    "start": "1256640",
    "end": "1257600"
  },
  {
    "text": "richard lau and eric leong for their",
    "start": "1257600",
    "end": "1260240"
  },
  {
    "text": "technical support",
    "start": "1260240",
    "end": "1261520"
  },
  {
    "text": "for the raid development again thank you",
    "start": "1261520",
    "end": "1264240"
  },
  {
    "text": "so much for watching my talk",
    "start": "1264240",
    "end": "1266159"
  },
  {
    "text": "please let me know if you have any",
    "start": "1266159",
    "end": "1267919"
  },
  {
    "text": "questions",
    "start": "1267919",
    "end": "1270320"
  }
]
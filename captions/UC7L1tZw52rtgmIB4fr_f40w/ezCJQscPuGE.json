[
  {
    "text": "[Music]",
    "start": "170",
    "end": "14480"
  },
  {
    "text": "hello everyone",
    "start": "14480",
    "end": "15519"
  },
  {
    "text": "thank you all for coming uh today i'm",
    "start": "15519",
    "end": "17600"
  },
  {
    "text": "going to be talking about how you can",
    "start": "17600",
    "end": "18800"
  },
  {
    "text": "speed up your reinforcement learning",
    "start": "18800",
    "end": "20320"
  },
  {
    "text": "experiments using rlip plus ray",
    "start": "20320",
    "end": "22480"
  },
  {
    "text": "most notably we got a 24x speed up for",
    "start": "22480",
    "end": "24640"
  },
  {
    "text": "our experiments and we'll be talking",
    "start": "24640",
    "end": "25920"
  },
  {
    "text": "about why we got such large",
    "start": "25920",
    "end": "27439"
  },
  {
    "text": "uh speedups um and yeah so my name is",
    "start": "27439",
    "end": "30880"
  },
  {
    "text": "raul cory",
    "start": "30880",
    "end": "31840"
  },
  {
    "text": "i'm a quantitative software engineer at",
    "start": "31840",
    "end": "33600"
  },
  {
    "text": "the on the ai core team at two sigma",
    "start": "33600",
    "end": "35840"
  },
  {
    "text": "on that team i work on applied research",
    "start": "35840",
    "end": "38079"
  },
  {
    "text": "as well as consulting with other company",
    "start": "38079",
    "end": "39920"
  },
  {
    "text": "other teams around the company and a lot",
    "start": "39920",
    "end": "42160"
  },
  {
    "text": "of that applied research",
    "start": "42160",
    "end": "43280"
  },
  {
    "text": "uh is in reinforcement learning before",
    "start": "43280",
    "end": "45600"
  },
  {
    "text": "my time at two sigma",
    "start": "45600",
    "end": "47440"
  },
  {
    "text": "i studied my undergrad and my master's",
    "start": "47440",
    "end": "49200"
  },
  {
    "text": "at mit in ai and computer science",
    "start": "49200",
    "end": "51920"
  },
  {
    "text": "and this is my dog bowie the samoyed if",
    "start": "51920",
    "end": "54719"
  },
  {
    "text": "you want to you can follow him on",
    "start": "54719",
    "end": "55920"
  },
  {
    "text": "instagram there's his handle",
    "start": "55920",
    "end": "58399"
  },
  {
    "text": "for those of you who don't know what two",
    "start": "58399",
    "end": "59680"
  },
  {
    "text": "sigma is we're a financial scientist",
    "start": "59680",
    "end": "62320"
  },
  {
    "text": "company",
    "start": "62320",
    "end": "62800"
  },
  {
    "text": "we coined that term actually last year",
    "start": "62800",
    "end": "65760"
  },
  {
    "text": "prior to that we were just an investment",
    "start": "65760",
    "end": "67119"
  },
  {
    "text": "manager but we've started to do a lot",
    "start": "67119",
    "end": "68479"
  },
  {
    "text": "more than just that we've",
    "start": "68479",
    "end": "69760"
  },
  {
    "text": "done a lot of other financial",
    "start": "69760",
    "end": "70960"
  },
  {
    "text": "data-driven endeavors including",
    "start": "70960",
    "end": "72880"
  },
  {
    "text": "insurance real estate private equity and",
    "start": "72880",
    "end": "75600"
  },
  {
    "text": "many more",
    "start": "75600",
    "end": "76960"
  },
  {
    "text": "the company was founded in 2001 by our",
    "start": "76960",
    "end": "79280"
  },
  {
    "text": "ceos john and david",
    "start": "79280",
    "end": "80960"
  },
  {
    "text": "and we have roughly 2 000 employees so",
    "start": "80960",
    "end": "83040"
  },
  {
    "text": "about a thousand engineers and 250",
    "start": "83040",
    "end": "84880"
  },
  {
    "text": "researchers",
    "start": "84880",
    "end": "86080"
  },
  {
    "text": "and so the company is very data driven",
    "start": "86080",
    "end": "88560"
  },
  {
    "text": "very stem focused",
    "start": "88560",
    "end": "90240"
  },
  {
    "text": "and a lot as devoted to the scientific",
    "start": "90240",
    "end": "91840"
  },
  {
    "text": "process",
    "start": "91840",
    "end": "93280"
  },
  {
    "text": "and we have offices in new york london",
    "start": "93280",
    "end": "95600"
  },
  {
    "text": "houston tokyo and shanghai",
    "start": "95600",
    "end": "98240"
  },
  {
    "text": "new york being the largest office and",
    "start": "98240",
    "end": "100240"
  },
  {
    "text": "this is our new york office that i",
    "start": "100240",
    "end": "101759"
  },
  {
    "text": "haven't been in since march 2020 and i",
    "start": "101759",
    "end": "103600"
  },
  {
    "text": "miss it a lot",
    "start": "103600",
    "end": "104399"
  },
  {
    "text": "i'm excited to go back um because we're",
    "start": "104399",
    "end": "107439"
  },
  {
    "text": "a financial services company i do have",
    "start": "107439",
    "end": "109280"
  },
  {
    "text": "to show",
    "start": "109280",
    "end": "109920"
  },
  {
    "text": "uh our legal disclaimer which we can",
    "start": "109920",
    "end": "113280"
  },
  {
    "text": "skip now um so what are we going to be",
    "start": "113280",
    "end": "115439"
  },
  {
    "text": "talking about today",
    "start": "115439",
    "end": "116479"
  },
  {
    "text": "well we're going to be talking about rl",
    "start": "116479",
    "end": "118240"
  },
  {
    "text": "lib",
    "start": "118240",
    "end": "119520"
  },
  {
    "text": "so you know a lot of my applied research",
    "start": "119520",
    "end": "121680"
  },
  {
    "text": "my team supplied research",
    "start": "121680",
    "end": "123520"
  },
  {
    "text": "currently includes reinforcement",
    "start": "123520",
    "end": "124880"
  },
  {
    "text": "learning and we recently or just in",
    "start": "124880",
    "end": "127439"
  },
  {
    "text": "mid-year 2000",
    "start": "127439",
    "end": "128640"
  },
  {
    "text": "uh 2020 migrated from stable baselines",
    "start": "128640",
    "end": "132560"
  },
  {
    "text": "to rl lib",
    "start": "132560",
    "end": "134000"
  },
  {
    "text": "and for those of you who don't know what",
    "start": "134000",
    "end": "135120"
  },
  {
    "text": "stable baselines is it's an open source",
    "start": "135120",
    "end": "137760"
  },
  {
    "text": "reinforcement learning library",
    "start": "137760",
    "end": "139599"
  },
  {
    "text": "that a forked from the baselines open",
    "start": "139599",
    "end": "142000"
  },
  {
    "text": "source reinforcement learning package",
    "start": "142000",
    "end": "143920"
  },
  {
    "text": "uh out from open ai",
    "start": "143920",
    "end": "147680"
  },
  {
    "text": "and so we we migrated from stable",
    "start": "147680",
    "end": "149680"
  },
  {
    "text": "baseline to rlib we learned a lot",
    "start": "149680",
    "end": "151680"
  },
  {
    "text": "we got a 24x speedup we're going to be",
    "start": "151680",
    "end": "153920"
  },
  {
    "text": "talking about the lessons learned we did",
    "start": "153920",
    "end": "155200"
  },
  {
    "text": "from that migration",
    "start": "155200",
    "end": "156080"
  },
  {
    "text": "as well as this case study of that that",
    "start": "156080",
    "end": "158400"
  },
  {
    "text": "experiment",
    "start": "158400",
    "end": "159200"
  },
  {
    "text": "and why it got such a large speed up",
    "start": "159200",
    "end": "162720"
  },
  {
    "text": "so first of all before we you know we",
    "start": "162720",
    "end": "165680"
  },
  {
    "text": "dive right into that let's talk about",
    "start": "165680",
    "end": "167040"
  },
  {
    "text": "the rl pipeline or just a general",
    "start": "167040",
    "end": "168640"
  },
  {
    "text": "overview so we have the same jargon",
    "start": "168640",
    "end": "170959"
  },
  {
    "text": "so normally you have what's called a",
    "start": "170959",
    "end": "172480"
  },
  {
    "text": "trainer or an agent and it's responsible",
    "start": "172480",
    "end": "174720"
  },
  {
    "text": "for",
    "start": "174720",
    "end": "175120"
  },
  {
    "text": "learning a policy or figuring out how to",
    "start": "175120",
    "end": "176720"
  },
  {
    "text": "interact with the environment so it",
    "start": "176720",
    "end": "178000"
  },
  {
    "text": "applies actions",
    "start": "178000",
    "end": "179120"
  },
  {
    "text": "to some simulator or environment and",
    "start": "179120",
    "end": "181360"
  },
  {
    "text": "outcome observations and rewards and",
    "start": "181360",
    "end": "182879"
  },
  {
    "text": "this environment is basically the state",
    "start": "182879",
    "end": "184560"
  },
  {
    "text": "machine",
    "start": "184560",
    "end": "185440"
  },
  {
    "text": "right so actions go in and observations",
    "start": "185440",
    "end": "187519"
  },
  {
    "text": "and rewards come out",
    "start": "187519",
    "end": "189599"
  },
  {
    "text": "and you can imagine that there's a lot",
    "start": "189599",
    "end": "191280"
  },
  {
    "text": "of interactions required in order to get",
    "start": "191280",
    "end": "193680"
  },
  {
    "text": "the uh the agent or that policy to learn",
    "start": "193680",
    "end": "196879"
  },
  {
    "text": "of good policy in that environment",
    "start": "196879",
    "end": "200400"
  },
  {
    "text": "so many times you need tens of millions",
    "start": "200400",
    "end": "202159"
  },
  {
    "text": "or maybe hundreds of millions of",
    "start": "202159",
    "end": "203360"
  },
  {
    "text": "interactions and you need to learn on",
    "start": "203360",
    "end": "204720"
  },
  {
    "text": "all of those",
    "start": "204720",
    "end": "205680"
  },
  {
    "text": "and so we can think about what are the",
    "start": "205680",
    "end": "206959"
  },
  {
    "text": "possible bottlenecks in that pipeline",
    "start": "206959",
    "end": "209680"
  },
  {
    "text": "right so there's a possibility that you",
    "start": "209680",
    "end": "211519"
  },
  {
    "text": "have a bottleneck in learning or",
    "start": "211519",
    "end": "212799"
  },
  {
    "text": "optimization so basically you've",
    "start": "212799",
    "end": "214159"
  },
  {
    "text": "collected all those samples",
    "start": "214159",
    "end": "215599"
  },
  {
    "text": "and now you're trying to learn a good",
    "start": "215599",
    "end": "217040"
  },
  {
    "text": "policy on that but there's also",
    "start": "217040",
    "end": "219280"
  },
  {
    "text": "um you know a bottleneck in the time it",
    "start": "219280",
    "end": "221519"
  },
  {
    "text": "takes to basically sample from that",
    "start": "221519",
    "end": "223120"
  },
  {
    "text": "environment basically",
    "start": "223120",
    "end": "224080"
  },
  {
    "text": "stepping through the environment can",
    "start": "224080",
    "end": "225280"
  },
  {
    "text": "kind of be a bottleneck and so",
    "start": "225280",
    "end": "227840"
  },
  {
    "text": "very different bottlenecks today we're",
    "start": "227840",
    "end": "229760"
  },
  {
    "text": "actually going to be focusing on sample",
    "start": "229760",
    "end": "231120"
  },
  {
    "text": "boundaries",
    "start": "231120",
    "end": "231920"
  },
  {
    "text": "or basically rl experiments that have a",
    "start": "231920",
    "end": "235280"
  },
  {
    "text": "kind of an environment that is",
    "start": "235280",
    "end": "236959"
  },
  {
    "text": "bottlenecking the experiment",
    "start": "236959",
    "end": "238959"
  },
  {
    "text": "there's a really good scaling guide on",
    "start": "238959",
    "end": "240400"
  },
  {
    "text": "the ro lib documentation that included",
    "start": "240400",
    "end": "242319"
  },
  {
    "text": "the link here",
    "start": "242319",
    "end": "244480"
  },
  {
    "text": "where they talk about you know",
    "start": "244480",
    "end": "245519"
  },
  {
    "text": "trade-offs what algorithms you should",
    "start": "245519",
    "end": "246879"
  },
  {
    "text": "use and consider",
    "start": "246879",
    "end": "248080"
  },
  {
    "text": "but today we're going to kind of deep",
    "start": "248080",
    "end": "249519"
  },
  {
    "text": "dive into the sampling and especially",
    "start": "249519",
    "end": "251439"
  },
  {
    "text": "our experiment and why it benefited from",
    "start": "251439",
    "end": "253519"
  },
  {
    "text": "you know this migration and the",
    "start": "253519",
    "end": "254560"
  },
  {
    "text": "techniques we used so let's talk about",
    "start": "254560",
    "end": "256959"
  },
  {
    "text": "our experiment",
    "start": "256959",
    "end": "258239"
  },
  {
    "text": "so we deal with financial data not a uh",
    "start": "258239",
    "end": "260560"
  },
  {
    "text": "you know classic physics simulator or",
    "start": "260560",
    "end": "262000"
  },
  {
    "text": "something else you might see",
    "start": "262000",
    "end": "263759"
  },
  {
    "text": "in a normal rl package so there's a lot",
    "start": "263759",
    "end": "267120"
  },
  {
    "text": "of financial data",
    "start": "267120",
    "end": "268400"
  },
  {
    "text": "and there's low signal to noise ratio",
    "start": "268400",
    "end": "270000"
  },
  {
    "text": "when you're dealing with financial data",
    "start": "270000",
    "end": "272000"
  },
  {
    "text": "um this often really slows down",
    "start": "272000",
    "end": "273840"
  },
  {
    "text": "experiments and so the experiment we're",
    "start": "273840",
    "end": "275759"
  },
  {
    "text": "going to be talking about we're focusing",
    "start": "275759",
    "end": "277040"
  },
  {
    "text": "on today",
    "start": "277040",
    "end": "277759"
  },
  {
    "text": "was taking about seven to ten hours to",
    "start": "277759",
    "end": "279280"
  },
  {
    "text": "complete or to get stability that we",
    "start": "279280",
    "end": "281040"
  },
  {
    "text": "wanted",
    "start": "281040",
    "end": "282080"
  },
  {
    "text": "and you can imagine that's pretty",
    "start": "282080",
    "end": "283360"
  },
  {
    "text": "restrictive you know",
    "start": "283360",
    "end": "285680"
  },
  {
    "text": "it basically takes overnight or entire",
    "start": "285680",
    "end": "287520"
  },
  {
    "text": "work day",
    "start": "287520",
    "end": "288800"
  },
  {
    "text": "and well these uh",
    "start": "288800",
    "end": "292160"
  },
  {
    "text": "these experiments have low noise signal",
    "start": "292160",
    "end": "294320"
  },
  {
    "text": "to noise ratio and that you can imagine",
    "start": "294320",
    "end": "295680"
  },
  {
    "text": "you need a lot of seeds you need a lot",
    "start": "295680",
    "end": "297040"
  },
  {
    "text": "of experiments because it's financial",
    "start": "297040",
    "end": "298320"
  },
  {
    "text": "data",
    "start": "298320",
    "end": "298960"
  },
  {
    "text": "and so this was a really restrictive for",
    "start": "298960",
    "end": "302000"
  },
  {
    "text": "our research i mean i guess maybe for",
    "start": "302000",
    "end": "304080"
  },
  {
    "text": "classic deep learning this isn't too bad",
    "start": "304080",
    "end": "305680"
  },
  {
    "text": "but for",
    "start": "305680",
    "end": "306240"
  },
  {
    "text": "us this was kind of very cumbersome and",
    "start": "306240",
    "end": "309199"
  },
  {
    "text": "this was already using 24 cpus on stable",
    "start": "309199",
    "end": "311360"
  },
  {
    "text": "baselines",
    "start": "311360",
    "end": "312720"
  },
  {
    "text": "um and you know looking at the metrics",
    "start": "312720",
    "end": "314639"
  },
  {
    "text": "of our experiments we were seeing that",
    "start": "314639",
    "end": "316160"
  },
  {
    "text": "you know learning was only taking about",
    "start": "316160",
    "end": "317520"
  },
  {
    "text": "10 of the time where the other 90",
    "start": "317520",
    "end": "319919"
  },
  {
    "text": "was basically interacting with that",
    "start": "319919",
    "end": "321759"
  },
  {
    "text": "environment or generating those samples",
    "start": "321759",
    "end": "324479"
  },
  {
    "text": "so you know what what did we try at",
    "start": "324479",
    "end": "327280"
  },
  {
    "text": "first",
    "start": "327280",
    "end": "327680"
  },
  {
    "text": "um so you know classic deep learning",
    "start": "327680",
    "end": "329919"
  },
  {
    "text": "problem we throw gpus the problem",
    "start": "329919",
    "end": "331759"
  },
  {
    "text": "we you know that classic silver bullet",
    "start": "331759",
    "end": "334160"
  },
  {
    "text": "we were like yeah well gpu speed it up",
    "start": "334160",
    "end": "336160"
  },
  {
    "text": "but actually it yielded little to no",
    "start": "336160",
    "end": "337680"
  },
  {
    "text": "speed up um",
    "start": "337680",
    "end": "339199"
  },
  {
    "text": "and i guess this may be surprising but",
    "start": "339199",
    "end": "342160"
  },
  {
    "text": "um",
    "start": "342160",
    "end": "342479"
  },
  {
    "text": "i guess it's not because the simulators",
    "start": "342479",
    "end": "344400"
  },
  {
    "text": "don't use gpus and so",
    "start": "344400",
    "end": "345919"
  },
  {
    "text": "throwing gpus at the problem isn't going",
    "start": "345919",
    "end": "347759"
  },
  {
    "text": "to speed up our simulators",
    "start": "347759",
    "end": "349919"
  },
  {
    "text": "it might have sped up you know maybe the",
    "start": "349919",
    "end": "351840"
  },
  {
    "text": "inference of the learning but in our",
    "start": "351840",
    "end": "353199"
  },
  {
    "text": "case",
    "start": "353199",
    "end": "353600"
  },
  {
    "text": "the simulation of that kind of stepping",
    "start": "353600",
    "end": "355680"
  },
  {
    "text": "through the environment",
    "start": "355680",
    "end": "356800"
  },
  {
    "text": "was really slowing us down and then on",
    "start": "356800",
    "end": "359039"
  },
  {
    "text": "top of that the gpus were very expensive",
    "start": "359039",
    "end": "360960"
  },
  {
    "text": "so it was not worth",
    "start": "360960",
    "end": "362639"
  },
  {
    "text": "using those gpu machines i do remember",
    "start": "362639",
    "end": "365840"
  },
  {
    "text": "in",
    "start": "365840",
    "end": "366319"
  },
  {
    "text": "the conference last year um you know",
    "start": "366319",
    "end": "368880"
  },
  {
    "text": "someone during the q a",
    "start": "368880",
    "end": "370240"
  },
  {
    "text": "basically said hey uh you know i got a",
    "start": "370240",
    "end": "373120"
  },
  {
    "text": "larger machine with the gpu and i'm not",
    "start": "373120",
    "end": "375360"
  },
  {
    "text": "really seeing any speed up",
    "start": "375360",
    "end": "377199"
  },
  {
    "text": "um and i remember it was like oh yeah",
    "start": "377199",
    "end": "379120"
  },
  {
    "text": "like you really need to scale your you",
    "start": "379120",
    "end": "381280"
  },
  {
    "text": "know your number of cpus you really need",
    "start": "381280",
    "end": "382800"
  },
  {
    "text": "to scale your experiment the gpus",
    "start": "382800",
    "end": "384880"
  },
  {
    "text": "aren't the silver bullet for rl as they",
    "start": "384880",
    "end": "386960"
  },
  {
    "text": "are i mean aren't isn't always the",
    "start": "386960",
    "end": "388560"
  },
  {
    "text": "silver bullet",
    "start": "388560",
    "end": "389360"
  },
  {
    "text": "rl as it is in a lot of other deep",
    "start": "389360",
    "end": "391360"
  },
  {
    "text": "learning problems",
    "start": "391360",
    "end": "394159"
  },
  {
    "text": "so the other thing we actually tried is",
    "start": "394240",
    "end": "395600"
  },
  {
    "text": "to use more cpus",
    "start": "395600",
    "end": "397520"
  },
  {
    "text": "um you know at the time we were kind of",
    "start": "397520",
    "end": "399199"
  },
  {
    "text": "constrained to 24 cpus but we were able",
    "start": "399199",
    "end": "401440"
  },
  {
    "text": "to find some larger boxes",
    "start": "401440",
    "end": "403440"
  },
  {
    "text": "but we found actually we weren't getting",
    "start": "403440",
    "end": "404880"
  },
  {
    "text": "good scaling with stable baselines at",
    "start": "404880",
    "end": "406639"
  },
  {
    "text": "the time",
    "start": "406639",
    "end": "408160"
  },
  {
    "text": "and so we were getting little to no",
    "start": "408160",
    "end": "409280"
  },
  {
    "text": "speed up even going to 48 or 96",
    "start": "409280",
    "end": "411520"
  },
  {
    "text": "cpus and then the next thing you know",
    "start": "411520",
    "end": "414160"
  },
  {
    "text": "some people are trying saying well you",
    "start": "414160",
    "end": "415520"
  },
  {
    "text": "know if you're you know you have slow",
    "start": "415520",
    "end": "416560"
  },
  {
    "text": "simulator why don't you guys try off",
    "start": "416560",
    "end": "417919"
  },
  {
    "text": "policy",
    "start": "417919",
    "end": "418960"
  },
  {
    "text": "um unfortunately we were getting lower",
    "start": "418960",
    "end": "420720"
  },
  {
    "text": "solution quality than the on policy",
    "start": "420720",
    "end": "422319"
  },
  {
    "text": "algorithms and so",
    "start": "422319",
    "end": "423520"
  },
  {
    "text": "you know we could still complete the on",
    "start": "423520",
    "end": "425120"
  },
  {
    "text": "policy learning so we were just like",
    "start": "425120",
    "end": "426479"
  },
  {
    "text": "okay we might as well continue with",
    "start": "426479",
    "end": "427680"
  },
  {
    "text": "these",
    "start": "427680",
    "end": "428560"
  },
  {
    "text": "um but you know it's still uh and",
    "start": "428560",
    "end": "431919"
  },
  {
    "text": "the off policy algorithm still took a",
    "start": "431919",
    "end": "433280"
  },
  {
    "text": "while to train so we weren't really",
    "start": "433280",
    "end": "435120"
  },
  {
    "text": "considering them we wanted to stay on",
    "start": "435120",
    "end": "436479"
  },
  {
    "text": "policy",
    "start": "436479",
    "end": "437599"
  },
  {
    "text": "um and so midway through last year",
    "start": "437599",
    "end": "440000"
  },
  {
    "text": "someone recommended to us that we should",
    "start": "440000",
    "end": "441680"
  },
  {
    "text": "try rl lib",
    "start": "441680",
    "end": "443199"
  },
  {
    "text": "um and so you know okay you know it",
    "start": "443199",
    "end": "445280"
  },
  {
    "text": "seems like an interesting technology",
    "start": "445280",
    "end": "447199"
  },
  {
    "text": "has a lot of just ability to distribute",
    "start": "447199",
    "end": "449199"
  },
  {
    "text": "let's try it",
    "start": "449199",
    "end": "450639"
  },
  {
    "text": "so we migrated over to rlib and actually",
    "start": "450639",
    "end": "453680"
  },
  {
    "text": "since",
    "start": "453680",
    "end": "454560"
  },
  {
    "text": "the uh you know our exp our simulator",
    "start": "454560",
    "end": "456880"
  },
  {
    "text": "was already using the generic gym api",
    "start": "456880",
    "end": "459759"
  },
  {
    "text": "the migration was actually pretty easy",
    "start": "459759",
    "end": "461599"
  },
  {
    "text": "the enviro i personally think during",
    "start": "461599",
    "end": "464479"
  },
  {
    "text": "reinforcement learning research the",
    "start": "464479",
    "end": "466240"
  },
  {
    "text": "hardest part is the simulator and so",
    "start": "466240",
    "end": "468639"
  },
  {
    "text": "if we could just easily migrate that",
    "start": "468639",
    "end": "470639"
  },
  {
    "text": "that was a lot of the work kind of done",
    "start": "470639",
    "end": "472080"
  },
  {
    "text": "for us",
    "start": "472080",
    "end": "473039"
  },
  {
    "text": "um the only hard part i guess was",
    "start": "473039",
    "end": "475199"
  },
  {
    "text": "basically oh",
    "start": "475199",
    "end": "476400"
  },
  {
    "text": "the nice thing is that stable baselines",
    "start": "476400",
    "end": "478560"
  },
  {
    "text": "rlib had a",
    "start": "478560",
    "end": "479759"
  },
  {
    "text": "superset of the algorithms that we had",
    "start": "479759",
    "end": "481599"
  },
  {
    "text": "or cared about in stable baselines",
    "start": "481599",
    "end": "483680"
  },
  {
    "text": "um the only kind of difficult thing is",
    "start": "483680",
    "end": "485360"
  },
  {
    "text": "that we did need to make small changes",
    "start": "485360",
    "end": "487039"
  },
  {
    "text": "to our hyperparameters in order to get",
    "start": "487039",
    "end": "488800"
  },
  {
    "text": "the same solution quality",
    "start": "488800",
    "end": "490160"
  },
  {
    "text": "but we were able to eventually get the",
    "start": "490160",
    "end": "491840"
  },
  {
    "text": "same solution quality and the nice thing",
    "start": "491840",
    "end": "493759"
  },
  {
    "text": "is that tune managed our experiments",
    "start": "493759",
    "end": "495599"
  },
  {
    "text": "and we were able to use tuned for hyper",
    "start": "495599",
    "end": "497280"
  },
  {
    "text": "parameter optimization",
    "start": "497280",
    "end": "498639"
  },
  {
    "text": "in order to find those hyper parameter",
    "start": "498639",
    "end": "500319"
  },
  {
    "text": "tweaks in order to get the same solution",
    "start": "500319",
    "end": "502240"
  },
  {
    "text": "quality",
    "start": "502240",
    "end": "503520"
  },
  {
    "text": "and so in total the migration only took",
    "start": "503520",
    "end": "505199"
  },
  {
    "text": "us about a week",
    "start": "505199",
    "end": "506720"
  },
  {
    "text": "which was you know pretty painless in my",
    "start": "506720",
    "end": "508400"
  },
  {
    "text": "opinion",
    "start": "508400",
    "end": "510240"
  },
  {
    "text": "and also there was great community",
    "start": "510240",
    "end": "511599"
  },
  {
    "text": "support and as well as a lot of rlib",
    "start": "511599",
    "end": "514159"
  },
  {
    "text": "examples in their github repository",
    "start": "514159",
    "end": "515839"
  },
  {
    "text": "which i think",
    "start": "515839",
    "end": "516479"
  },
  {
    "text": "if you're doing the migration or you're",
    "start": "516479",
    "end": "517680"
  },
  {
    "text": "trying our lip for the first time you",
    "start": "517680",
    "end": "519360"
  },
  {
    "text": "should really check out",
    "start": "519360",
    "end": "521279"
  },
  {
    "text": "um so you know we finally migrated we",
    "start": "521279",
    "end": "523120"
  },
  {
    "text": "got the same solution uh",
    "start": "523120",
    "end": "524560"
  },
  {
    "text": "quality um and then we basically decided",
    "start": "524560",
    "end": "527440"
  },
  {
    "text": "okay now let's benchmark you know the",
    "start": "527440",
    "end": "528800"
  },
  {
    "text": "runtime of the experiments this is why",
    "start": "528800",
    "end": "530240"
  },
  {
    "text": "we kind of did this migration",
    "start": "530240",
    "end": "531839"
  },
  {
    "text": "um so you know on the x-axis here we",
    "start": "531839",
    "end": "533680"
  },
  {
    "text": "plotted the number of cpus we gave the",
    "start": "533680",
    "end": "535279"
  },
  {
    "text": "experiment",
    "start": "535279",
    "end": "536000"
  },
  {
    "text": "and on the y-axis you'll see the amount",
    "start": "536000",
    "end": "537839"
  },
  {
    "text": "of time it took the experiment to take",
    "start": "537839",
    "end": "539760"
  },
  {
    "text": "um and what we really care about is how",
    "start": "539760",
    "end": "541120"
  },
  {
    "text": "long it took on these 24 cpus",
    "start": "541120",
    "end": "543440"
  },
  {
    "text": "you know lower is better here basically",
    "start": "543440",
    "end": "545360"
  },
  {
    "text": "we were able to get our experiments from",
    "start": "545360",
    "end": "546720"
  },
  {
    "text": "you know seven to ten hours",
    "start": "546720",
    "end": "548320"
  },
  {
    "text": "um down to basically two hours um so",
    "start": "548320",
    "end": "550880"
  },
  {
    "text": "that was a nice forex speed up you know",
    "start": "550880",
    "end": "552240"
  },
  {
    "text": "our experiment took something overnight",
    "start": "552240",
    "end": "553680"
  },
  {
    "text": "then now can you you know can run pretty",
    "start": "553680",
    "end": "555760"
  },
  {
    "text": "fast",
    "start": "555760",
    "end": "556880"
  },
  {
    "text": "but i guess we were you know as you know",
    "start": "556880",
    "end": "559920"
  },
  {
    "text": "ai for you know you know people with the",
    "start": "559920",
    "end": "562560"
  },
  {
    "text": "data driven",
    "start": "562560",
    "end": "563519"
  },
  {
    "text": "or people who are very interested in",
    "start": "563519",
    "end": "565040"
  },
  {
    "text": "this we're really curious about",
    "start": "565040",
    "end": "566640"
  },
  {
    "text": "why was rlib paralyzing better you know",
    "start": "566640",
    "end": "568880"
  },
  {
    "text": "in theory it's doing the exact same",
    "start": "568880",
    "end": "570320"
  },
  {
    "text": "thing why is it getting this forex speed",
    "start": "570320",
    "end": "571920"
  },
  {
    "text": "up",
    "start": "571920",
    "end": "572560"
  },
  {
    "text": "um and what we found out is it actually",
    "start": "572560",
    "end": "574399"
  },
  {
    "text": "comes out to",
    "start": "574399",
    "end": "575600"
  },
  {
    "text": "the types of rl parallelization",
    "start": "575600",
    "end": "578880"
  },
  {
    "text": "so there's a type of parallelization",
    "start": "578880",
    "end": "580480"
  },
  {
    "text": "that's vectorized environments",
    "start": "580480",
    "end": "582720"
  },
  {
    "text": "and so basically during a vectorized",
    "start": "582720",
    "end": "584320"
  },
  {
    "text": "environment or vectorized",
    "start": "584320",
    "end": "585519"
  },
  {
    "text": "parallelization for an rl problem",
    "start": "585519",
    "end": "587440"
  },
  {
    "text": "what you do is you you basically take",
    "start": "587440",
    "end": "589040"
  },
  {
    "text": "all your environments and you put them",
    "start": "589040",
    "end": "590399"
  },
  {
    "text": "together in a list or a vector",
    "start": "590399",
    "end": "592560"
  },
  {
    "text": "and you do apply everything in step to",
    "start": "592560",
    "end": "595120"
  },
  {
    "text": "that vector of environment so you",
    "start": "595120",
    "end": "596959"
  },
  {
    "text": "you will step them you'll reset them",
    "start": "596959",
    "end": "598800"
  },
  {
    "text": "you'll push them through the uh",
    "start": "598800",
    "end": "600320"
  },
  {
    "text": "the graph together and it's nice that",
    "start": "600320",
    "end": "602800"
  },
  {
    "text": "you know everything is efficient in",
    "start": "602800",
    "end": "604320"
  },
  {
    "text": "inference time",
    "start": "604320",
    "end": "605360"
  },
  {
    "text": "but the issue is that everything has to",
    "start": "605360",
    "end": "607200"
  },
  {
    "text": "step together and so",
    "start": "607200",
    "end": "608800"
  },
  {
    "text": "if you have any variance in your step",
    "start": "608800",
    "end": "610480"
  },
  {
    "text": "time you actually have environments that",
    "start": "610480",
    "end": "612480"
  },
  {
    "text": "are sitting there and waiting for the",
    "start": "612480",
    "end": "613839"
  },
  {
    "text": "other environments",
    "start": "613839",
    "end": "615120"
  },
  {
    "text": "um and that's we call it the lockstep",
    "start": "615120",
    "end": "616800"
  },
  {
    "text": "issue and you're actually constrained to",
    "start": "616800",
    "end": "619040"
  },
  {
    "text": "vectorize environments by many rl",
    "start": "619040",
    "end": "620640"
  },
  {
    "text": "libraries",
    "start": "620640",
    "end": "621839"
  },
  {
    "text": "and so you can imagine a vectorized",
    "start": "621839",
    "end": "623040"
  },
  {
    "text": "environment might look like this little",
    "start": "623040",
    "end": "624399"
  },
  {
    "text": "blue box here",
    "start": "624399",
    "end": "625519"
  },
  {
    "text": "where you know you might have five",
    "start": "625519",
    "end": "627279"
  },
  {
    "text": "environments four of which stepped",
    "start": "627279",
    "end": "628880"
  },
  {
    "text": "really quickly on that set but one of",
    "start": "628880",
    "end": "630560"
  },
  {
    "text": "the environments",
    "start": "630560",
    "end": "631440"
  },
  {
    "text": "for some reason took 100 milliseconds",
    "start": "631440",
    "end": "634079"
  },
  {
    "text": "and the entire vector is going to take",
    "start": "634079",
    "end": "635519"
  },
  {
    "text": "100 milliseconds to do that step",
    "start": "635519",
    "end": "637200"
  },
  {
    "text": "and so you can imagine those four",
    "start": "637200",
    "end": "638399"
  },
  {
    "text": "environments wasted potential to be",
    "start": "638399",
    "end": "640079"
  },
  {
    "text": "continued stepping",
    "start": "640079",
    "end": "641120"
  },
  {
    "text": "so a lot of wasted potential in",
    "start": "641120",
    "end": "642399"
  },
  {
    "text": "vectorized environments for this",
    "start": "642399",
    "end": "643440"
  },
  {
    "text": "lockstep issue",
    "start": "643440",
    "end": "644959"
  },
  {
    "text": "the other type of parallelization is",
    "start": "644959",
    "end": "646880"
  },
  {
    "text": "bashed rollouts",
    "start": "646880",
    "end": "648320"
  },
  {
    "text": "the main idea here is basically you give",
    "start": "648320",
    "end": "651600"
  },
  {
    "text": "workers you know you hey go collect a",
    "start": "651600",
    "end": "653519"
  },
  {
    "text": "thousand uh samples go collect a",
    "start": "653519",
    "end": "655519"
  },
  {
    "text": "thousand samples",
    "start": "655519",
    "end": "656399"
  },
  {
    "text": "they all go collect them and they come",
    "start": "656399",
    "end": "657680"
  },
  {
    "text": "back you do have to wait at the end but",
    "start": "657680",
    "end": "659600"
  },
  {
    "text": "you don't have to wait at every single",
    "start": "659600",
    "end": "660959"
  },
  {
    "text": "step",
    "start": "660959",
    "end": "661680"
  },
  {
    "text": "it's a little less efficient at",
    "start": "661680",
    "end": "663360"
  },
  {
    "text": "inference but",
    "start": "663360",
    "end": "665279"
  },
  {
    "text": "since you sync at the end of the",
    "start": "665279",
    "end": "666320"
  },
  {
    "text": "rollouts you have a lot less waiting",
    "start": "666320",
    "end": "668800"
  },
  {
    "text": "um and you actually get to avoid a lot",
    "start": "668800",
    "end": "670399"
  },
  {
    "text": "of this lock step issue",
    "start": "670399",
    "end": "672399"
  },
  {
    "text": "and so you can imagine this might be",
    "start": "672399",
    "end": "674079"
  },
  {
    "text": "what what a batch environment might look",
    "start": "674079",
    "end": "675839"
  },
  {
    "text": "at you you know you don't really have an",
    "start": "675839",
    "end": "677440"
  },
  {
    "text": "environment but you have you know batch",
    "start": "677440",
    "end": "678720"
  },
  {
    "text": "rollouts and on average you kind of get",
    "start": "678720",
    "end": "680079"
  },
  {
    "text": "to diversify 100 milliseconds those",
    "start": "680079",
    "end": "681760"
  },
  {
    "text": "three milliseconds steps can still just",
    "start": "681760",
    "end": "683440"
  },
  {
    "text": "continue",
    "start": "683440",
    "end": "684000"
  },
  {
    "text": "rolling um and so the lock step issue is",
    "start": "684000",
    "end": "687519"
  },
  {
    "text": "actually what was causing our stable",
    "start": "687519",
    "end": "688640"
  },
  {
    "text": "baselines experiments to not paralyze",
    "start": "688640",
    "end": "690560"
  },
  {
    "text": "well",
    "start": "690560",
    "end": "691120"
  },
  {
    "text": "that's really what's slowing us down",
    "start": "691120",
    "end": "692640"
  },
  {
    "text": "there but what was actually what was rl",
    "start": "692640",
    "end": "694880"
  },
  {
    "text": "lib doing",
    "start": "694880",
    "end": "695600"
  },
  {
    "text": "um it's actually some interesting hybrid",
    "start": "695600",
    "end": "697680"
  },
  {
    "text": "solution",
    "start": "697680",
    "end": "698640"
  },
  {
    "text": "see in rlib you actually can choose the",
    "start": "698640",
    "end": "700880"
  },
  {
    "text": "num the",
    "start": "700880",
    "end": "702079"
  },
  {
    "text": "what's called the number of rollout",
    "start": "702079",
    "end": "703279"
  },
  {
    "text": "workers and those rollout workers are",
    "start": "703279",
    "end": "704640"
  },
  {
    "text": "basically the number of batch rollouts",
    "start": "704640",
    "end": "705920"
  },
  {
    "text": "so in this",
    "start": "705920",
    "end": "706640"
  },
  {
    "text": "you know sample experiment we have we",
    "start": "706640",
    "end": "708640"
  },
  {
    "text": "have four rollout workers",
    "start": "708640",
    "end": "710399"
  },
  {
    "text": "kind of working in batched fashion and",
    "start": "710399",
    "end": "712639"
  },
  {
    "text": "then inside a world out worker you",
    "start": "712639",
    "end": "714160"
  },
  {
    "text": "basically can have vectorized",
    "start": "714160",
    "end": "715519"
  },
  {
    "text": "environments",
    "start": "715519",
    "end": "716000"
  },
  {
    "text": "inside of a rollout worker and what this",
    "start": "716000",
    "end": "718160"
  },
  {
    "text": "allows you to do is",
    "start": "718160",
    "end": "719040"
  },
  {
    "text": "a lot of customization so you can",
    "start": "719040",
    "end": "720959"
  },
  {
    "text": "imagine the experiment here as well as",
    "start": "720959",
    "end": "722959"
  },
  {
    "text": "an experiment on the right",
    "start": "722959",
    "end": "724480"
  },
  {
    "text": "are actually equivalent you know they",
    "start": "724480",
    "end": "726720"
  },
  {
    "text": "both have 12 environments",
    "start": "726720",
    "end": "728560"
  },
  {
    "text": "you know you would either have four or",
    "start": "728560",
    "end": "730079"
  },
  {
    "text": "six rollout workers and you know three",
    "start": "730079",
    "end": "731760"
  },
  {
    "text": "or two",
    "start": "731760",
    "end": "732320"
  },
  {
    "text": "vectorized environments but you'll",
    "start": "732320",
    "end": "733760"
  },
  {
    "text": "notice that on the environment on the",
    "start": "733760",
    "end": "734959"
  },
  {
    "text": "right you get a lot better speed up",
    "start": "734959",
    "end": "736320"
  },
  {
    "text": "because you've diversified that",
    "start": "736320",
    "end": "737839"
  },
  {
    "text": "those slow downs for that stop time and",
    "start": "737839",
    "end": "740320"
  },
  {
    "text": "you know you can tune this to get really",
    "start": "740320",
    "end": "741920"
  },
  {
    "text": "fast results so talking about you know",
    "start": "741920",
    "end": "744959"
  },
  {
    "text": "tuning experiments let's look at our",
    "start": "744959",
    "end": "746560"
  },
  {
    "text": "experiment",
    "start": "746560",
    "end": "747519"
  },
  {
    "text": "and the kind of the runtimes of some of",
    "start": "747519",
    "end": "748959"
  },
  {
    "text": "those steps and see you know where we",
    "start": "748959",
    "end": "751040"
  },
  {
    "text": "benefited a lot from",
    "start": "751040",
    "end": "752560"
  },
  {
    "text": "so you know in the overall performance",
    "start": "752560",
    "end": "755519"
  },
  {
    "text": "of stable baselines versus rl lib",
    "start": "755519",
    "end": "757279"
  },
  {
    "text": "we were talking about earlier you know",
    "start": "757279",
    "end": "758720"
  },
  {
    "text": "stable baselines the optimization was",
    "start": "758720",
    "end": "760639"
  },
  {
    "text": "taking less than ten percent of the the",
    "start": "760639",
    "end": "762160"
  },
  {
    "text": "total you know",
    "start": "762160",
    "end": "763200"
  },
  {
    "text": "overall iteration time um but now that",
    "start": "763200",
    "end": "765600"
  },
  {
    "text": "we've we're on these batch environments",
    "start": "765600",
    "end": "767040"
  },
  {
    "text": "we'll see that that sampling time went",
    "start": "767040",
    "end": "768399"
  },
  {
    "text": "down by you know a factor of seven or",
    "start": "768399",
    "end": "769920"
  },
  {
    "text": "eight",
    "start": "769920",
    "end": "770480"
  },
  {
    "text": "um a lot faster saving us those six",
    "start": "770480",
    "end": "773279"
  },
  {
    "text": "hours",
    "start": "773279",
    "end": "774160"
  },
  {
    "text": "and if we look at what was going on",
    "start": "774160",
    "end": "776000"
  },
  {
    "text": "inside of sampling",
    "start": "776000",
    "end": "777360"
  },
  {
    "text": "the resets between the vectorize and the",
    "start": "777360",
    "end": "779200"
  },
  {
    "text": "batch were happening basically at the",
    "start": "779200",
    "end": "780480"
  },
  {
    "text": "same amount of time",
    "start": "780480",
    "end": "781839"
  },
  {
    "text": "and it and it's interesting that the",
    "start": "781839",
    "end": "783920"
  },
  {
    "text": "inference times stable baselines of the",
    "start": "783920",
    "end": "785519"
  },
  {
    "text": "vectorize was actually running faster",
    "start": "785519",
    "end": "787120"
  },
  {
    "text": "there",
    "start": "787120",
    "end": "787760"
  },
  {
    "text": "but what really made the difference was",
    "start": "787760",
    "end": "789120"
  },
  {
    "text": "during steps you know what we were",
    "start": "789120",
    "end": "790639"
  },
  {
    "text": "talking about earlier",
    "start": "790639",
    "end": "792079"
  },
  {
    "text": "the vector advised environments had very",
    "start": "792079",
    "end": "793760"
  },
  {
    "text": "slow steps and if you if you those 24",
    "start": "793760",
    "end": "796240"
  },
  {
    "text": "milliseconds if you're doing you know 20",
    "start": "796240",
    "end": "797839"
  },
  {
    "text": "million samples as we were doing for",
    "start": "797839",
    "end": "799279"
  },
  {
    "text": "this experiment",
    "start": "799279",
    "end": "800160"
  },
  {
    "text": "that's wasting six hours here that's a",
    "start": "800160",
    "end": "803200"
  },
  {
    "text": "lot of time wasted for",
    "start": "803200",
    "end": "804560"
  },
  {
    "text": "just uh cpus waiting doing no compute",
    "start": "804560",
    "end": "807760"
  },
  {
    "text": "a lot of wasted cpu capabilities so you",
    "start": "807760",
    "end": "810880"
  },
  {
    "text": "can imagine this is what kind of like",
    "start": "810880",
    "end": "812079"
  },
  {
    "text": "our environment looked like when we were",
    "start": "812079",
    "end": "813440"
  },
  {
    "text": "in stable baselines",
    "start": "813440",
    "end": "815040"
  },
  {
    "text": "with a lot of wasted potential",
    "start": "815040",
    "end": "818560"
  },
  {
    "text": "so when does a lockstep issue matter",
    "start": "818560",
    "end": "820399"
  },
  {
    "text": "well",
    "start": "820399",
    "end": "821680"
  },
  {
    "text": "if you have non-uniform step time or",
    "start": "821680",
    "end": "823839"
  },
  {
    "text": "resets times",
    "start": "823839",
    "end": "824880"
  },
  {
    "text": "like what we had in our experiments i",
    "start": "824880",
    "end": "827519"
  },
  {
    "text": "think you can expect some pretty large",
    "start": "827519",
    "end": "828880"
  },
  {
    "text": "speed ups you know we got like a little",
    "start": "828880",
    "end": "830240"
  },
  {
    "text": "bit over 4x speed up",
    "start": "830240",
    "end": "832320"
  },
  {
    "text": "which was you know pretty amazing you",
    "start": "832320",
    "end": "834560"
  },
  {
    "text": "can also imagine that",
    "start": "834560",
    "end": "835680"
  },
  {
    "text": "this isn't just reset times it might be",
    "start": "835680",
    "end": "837440"
  },
  {
    "text": "a problem you know if you have an",
    "start": "837440",
    "end": "838800"
  },
  {
    "text": "environment where let's say",
    "start": "838800",
    "end": "840800"
  },
  {
    "text": "you know some steps are very simple you",
    "start": "840800",
    "end": "842560"
  },
  {
    "text": "know maybe that you don't have to do",
    "start": "842560",
    "end": "843600"
  },
  {
    "text": "anything during some",
    "start": "843600",
    "end": "844639"
  },
  {
    "text": "type of steps but other types of steps",
    "start": "844639",
    "end": "846800"
  },
  {
    "text": "require you know a large optimization",
    "start": "846800",
    "end": "848720"
  },
  {
    "text": "maybe to be run and re-optimizing the",
    "start": "848720",
    "end": "850560"
  },
  {
    "text": "system",
    "start": "850560",
    "end": "851360"
  },
  {
    "text": "um you can imagine that yeah you're",
    "start": "851360",
    "end": "853680"
  },
  {
    "text": "going to be suffering from the lockstep",
    "start": "853680",
    "end": "854880"
  },
  {
    "text": "issue and you should really be",
    "start": "854880",
    "end": "855760"
  },
  {
    "text": "considering",
    "start": "855760",
    "end": "856639"
  },
  {
    "text": "you know avoiding a vectorized",
    "start": "856639",
    "end": "858240"
  },
  {
    "text": "environment implementation of",
    "start": "858240",
    "end": "859440"
  },
  {
    "text": "parallelization",
    "start": "859440",
    "end": "861199"
  },
  {
    "text": "what also really matters is actually if",
    "start": "861199",
    "end": "862880"
  },
  {
    "text": "you're going to large parallelization",
    "start": "862880",
    "end": "865680"
  },
  {
    "text": "you know you actually have just just",
    "start": "865680",
    "end": "867600"
  },
  {
    "text": "regular variance in this time it takes",
    "start": "867600",
    "end": "869600"
  },
  {
    "text": "to just calculate some",
    "start": "869600",
    "end": "871120"
  },
  {
    "text": "steps actually can can sum up to a big",
    "start": "871120",
    "end": "874160"
  },
  {
    "text": "slowdown so most of our other",
    "start": "874160",
    "end": "875519"
  },
  {
    "text": "experiments that weren't",
    "start": "875519",
    "end": "876560"
  },
  {
    "text": "as uh as lockstep issue as our original",
    "start": "876560",
    "end": "878880"
  },
  {
    "text": "one we're still getting about a 10 to 50",
    "start": "878880",
    "end": "880800"
  },
  {
    "text": "percent",
    "start": "880800",
    "end": "881279"
  },
  {
    "text": "speed up from just uh the regular",
    "start": "881279",
    "end": "883760"
  },
  {
    "text": "migration on the same number of cpus",
    "start": "883760",
    "end": "886320"
  },
  {
    "text": "um and in general i think you can expect",
    "start": "886320",
    "end": "888959"
  },
  {
    "text": "a seat up",
    "start": "888959",
    "end": "889760"
  },
  {
    "text": "on 24 cpus to be somewhere around two",
    "start": "889760",
    "end": "893040"
  },
  {
    "text": "times",
    "start": "893040",
    "end": "894480"
  },
  {
    "text": "the uh the step time divide the standard",
    "start": "894480",
    "end": "896800"
  },
  {
    "text": "deviation of the step time divided by",
    "start": "896800",
    "end": "898639"
  },
  {
    "text": "the mean",
    "start": "898639",
    "end": "899199"
  },
  {
    "text": "of the step time um and this basically",
    "start": "899199",
    "end": "901120"
  },
  {
    "text": "assumes that that entire",
    "start": "901120",
    "end": "902800"
  },
  {
    "text": "vector of environments is going to have",
    "start": "902800",
    "end": "904079"
  },
  {
    "text": "to weight a certain number of gaussian",
    "start": "904079",
    "end": "906240"
  },
  {
    "text": "variants for basically the max of n",
    "start": "906240",
    "end": "907920"
  },
  {
    "text": "gaussian so if you have 24 you're",
    "start": "907920",
    "end": "909519"
  },
  {
    "text": "basically have to wait two gaussian",
    "start": "909519",
    "end": "911040"
  },
  {
    "text": "variants for all of them to complete",
    "start": "911040",
    "end": "913440"
  },
  {
    "text": "and so you know if you have two uh if",
    "start": "913440",
    "end": "915920"
  },
  {
    "text": "you have 24 environments",
    "start": "915920",
    "end": "917199"
  },
  {
    "text": "this can cause a significant slowdown",
    "start": "917199",
    "end": "920720"
  },
  {
    "text": "so one of the really cool things about",
    "start": "920720",
    "end": "922240"
  },
  {
    "text": "our migration to rl liver you know the",
    "start": "922240",
    "end": "924000"
  },
  {
    "text": "rlib",
    "start": "924000",
    "end": "924880"
  },
  {
    "text": "as a rl package is that it also comes",
    "start": "924880",
    "end": "928000"
  },
  {
    "text": "with",
    "start": "928000",
    "end": "928480"
  },
  {
    "text": "ray clusters and so this opens the door",
    "start": "928480",
    "end": "930399"
  },
  {
    "text": "for you know really powerful distributed",
    "start": "930399",
    "end": "932480"
  },
  {
    "text": "computing",
    "start": "932480",
    "end": "933759"
  },
  {
    "text": "and i think this is one of the biggest",
    "start": "933759",
    "end": "935040"
  },
  {
    "text": "selling points for rlib as a you know an",
    "start": "935040",
    "end": "937199"
  },
  {
    "text": "rl package",
    "start": "937199",
    "end": "938639"
  },
  {
    "text": "so before we were comparing rlib to",
    "start": "938639",
    "end": "941199"
  },
  {
    "text": "stable baseline",
    "start": "941199",
    "end": "942000"
  },
  {
    "text": "was just one box what the really cool",
    "start": "942000",
    "end": "944399"
  },
  {
    "text": "thing was when we",
    "start": "944399",
    "end": "945440"
  },
  {
    "text": "you know introduced ray clusters now is",
    "start": "945440",
    "end": "947440"
  },
  {
    "text": "we basically open the right side of this",
    "start": "947440",
    "end": "949040"
  },
  {
    "text": "graph",
    "start": "949040",
    "end": "949920"
  },
  {
    "text": "you know we were able to add additional",
    "start": "949920",
    "end": "951120"
  },
  {
    "text": "machines into our cluster for rl lib",
    "start": "951120",
    "end": "953360"
  },
  {
    "text": "out of the box you know all we have to",
    "start": "953360",
    "end": "954800"
  },
  {
    "text": "do is connect the machine to our cluster",
    "start": "954800",
    "end": "956160"
  },
  {
    "text": "not change our code at all",
    "start": "956160",
    "end": "958000"
  },
  {
    "text": "and we were able to you know cut our",
    "start": "958000",
    "end": "959360"
  },
  {
    "text": "experiment down",
    "start": "959360",
    "end": "961199"
  },
  {
    "text": "incredibly so um when we introduced you",
    "start": "961199",
    "end": "964720"
  },
  {
    "text": "know 16x the number of machines we were",
    "start": "964720",
    "end": "966639"
  },
  {
    "text": "able to get our experiments down to",
    "start": "966639",
    "end": "968000"
  },
  {
    "text": "20 minutes which hopefully is shorter",
    "start": "968000",
    "end": "970079"
  },
  {
    "text": "than the time that took to do this",
    "start": "970079",
    "end": "971279"
  },
  {
    "text": "presentation",
    "start": "971279",
    "end": "972560"
  },
  {
    "text": "um and so you know this completely",
    "start": "972560",
    "end": "974399"
  },
  {
    "text": "changes our research cycles you know",
    "start": "974399",
    "end": "976240"
  },
  {
    "text": "we were in stable baselines we were",
    "start": "976240",
    "end": "978079"
  },
  {
    "text": "doing things that were taking overnight",
    "start": "978079",
    "end": "979680"
  },
  {
    "text": "whole days where now we're taking things",
    "start": "979680",
    "end": "981759"
  },
  {
    "text": "under 20 minutes are we able",
    "start": "981759",
    "end": "983360"
  },
  {
    "text": "we're able to research so much faster",
    "start": "983360",
    "end": "985519"
  },
  {
    "text": "now with this technology",
    "start": "985519",
    "end": "987199"
  },
  {
    "text": "um yeah it's about 6x speed up on 16",
    "start": "987199",
    "end": "989680"
  },
  {
    "text": "axis cpus which",
    "start": "989680",
    "end": "991279"
  },
  {
    "text": "i think is a pretty amazing scaling um",
    "start": "991279",
    "end": "994160"
  },
  {
    "text": "so you know",
    "start": "994160",
    "end": "994720"
  },
  {
    "text": "there are other a lot of nice things",
    "start": "994720",
    "end": "996560"
  },
  {
    "text": "when we migrated to our live plus ray",
    "start": "996560",
    "end": "998560"
  },
  {
    "text": "um you know this bonus features i like",
    "start": "998560",
    "end": "1000480"
  },
  {
    "text": "to call them um you know the entire",
    "start": "1000480",
    "end": "1002399"
  },
  {
    "text": "ecosystem",
    "start": "1002399",
    "end": "1003199"
  },
  {
    "text": "has been really interesting one of the",
    "start": "1003199",
    "end": "1005040"
  },
  {
    "text": "things the favorite things is tune",
    "start": "1005040",
    "end": "1007120"
  },
  {
    "text": "um just for the hyper parameter",
    "start": "1007120",
    "end": "1008480"
  },
  {
    "text": "optimization we were able to you know",
    "start": "1008480",
    "end": "1010399"
  },
  {
    "text": "if we want to change our algorithm it's",
    "start": "1010399",
    "end": "1011920"
  },
  {
    "text": "really easy to you know switch to",
    "start": "1011920",
    "end": "1013120"
  },
  {
    "text": "another algorithm and then run in the",
    "start": "1013120",
    "end": "1014320"
  },
  {
    "text": "hyper parameter optimization so you can",
    "start": "1014320",
    "end": "1015839"
  },
  {
    "text": "get",
    "start": "1015839",
    "end": "1016160"
  },
  {
    "text": "really good apple staples comparisons",
    "start": "1016160",
    "end": "1018480"
  },
  {
    "text": "and it also just manages our experiments",
    "start": "1018480",
    "end": "1020240"
  },
  {
    "text": "very nicely we don't have to write any",
    "start": "1020240",
    "end": "1021440"
  },
  {
    "text": "custom code",
    "start": "1021440",
    "end": "1023040"
  },
  {
    "text": "there's also a large number of supported",
    "start": "1023040",
    "end": "1024640"
  },
  {
    "text": "algorithms with rlib it had a superset",
    "start": "1024640",
    "end": "1026640"
  },
  {
    "text": "of the algorithms we cared about in",
    "start": "1026640",
    "end": "1027839"
  },
  {
    "text": "stable baselines and has many more",
    "start": "1027839",
    "end": "1029520"
  },
  {
    "text": "especially many multi-agent environments",
    "start": "1029520",
    "end": "1031280"
  },
  {
    "text": "has been really great",
    "start": "1031280",
    "end": "1032640"
  },
  {
    "text": "um also just the general array",
    "start": "1032640",
    "end": "1034640"
  },
  {
    "text": "distributed compute platform",
    "start": "1034640",
    "end": "1036319"
  },
  {
    "text": "has been useful for a lot of the",
    "start": "1036319",
    "end": "1037678"
  },
  {
    "text": "engineers who are on our team",
    "start": "1037679",
    "end": "1039520"
  },
  {
    "text": "just being able to use the the the",
    "start": "1039520",
    "end": "1041760"
  },
  {
    "text": "scalability out of array has been very",
    "start": "1041760",
    "end": "1043600"
  },
  {
    "text": "useful",
    "start": "1043600",
    "end": "1044798"
  },
  {
    "text": "so in conclusion migrating stable",
    "start": "1044799",
    "end": "1047438"
  },
  {
    "text": "baselines to rl lib",
    "start": "1047439",
    "end": "1048799"
  },
  {
    "text": "i think the mileage is going to vary",
    "start": "1048799",
    "end": "1050080"
  },
  {
    "text": "depending on your experiment especially",
    "start": "1050080",
    "end": "1051679"
  },
  {
    "text": "how",
    "start": "1051679",
    "end": "1052000"
  },
  {
    "text": "you know how much the lock step issue",
    "start": "1052000",
    "end": "1053280"
  },
  {
    "text": "matters but you know we were able to get",
    "start": "1053280",
    "end": "1055039"
  },
  {
    "text": "a 4x speed up",
    "start": "1055039",
    "end": "1056320"
  },
  {
    "text": "i think it you know miles is going to",
    "start": "1056320",
    "end": "1057840"
  },
  {
    "text": "vary here i think most people will get",
    "start": "1057840",
    "end": "1059200"
  },
  {
    "text": "something around 10 to 50",
    "start": "1059200",
    "end": "1060720"
  },
  {
    "text": "speed up that's closer to our lib you",
    "start": "1060720",
    "end": "1063200"
  },
  {
    "text": "know boast on their website",
    "start": "1063200",
    "end": "1065360"
  },
  {
    "text": "and i think you really need to be aware",
    "start": "1065360",
    "end": "1066720"
  },
  {
    "text": "of the environment parallelization",
    "start": "1066720",
    "end": "1068080"
  },
  {
    "text": "you're using you know",
    "start": "1068080",
    "end": "1068960"
  },
  {
    "text": "are you using vectorized are you using",
    "start": "1068960",
    "end": "1071679"
  },
  {
    "text": "batch",
    "start": "1071679",
    "end": "1072240"
  },
  {
    "text": "is the lockstep issue going to get you",
    "start": "1072240",
    "end": "1074559"
  },
  {
    "text": "you should be well aware of that we",
    "start": "1074559",
    "end": "1076080"
  },
  {
    "text": "weren't originally",
    "start": "1076080",
    "end": "1076960"
  },
  {
    "text": "on stable baselines now that we're on rl",
    "start": "1076960",
    "end": "1078720"
  },
  {
    "text": "lib and we kind of did this",
    "start": "1078720",
    "end": "1079760"
  },
  {
    "text": "investigation",
    "start": "1079760",
    "end": "1080799"
  },
  {
    "text": "we're aware of it and you know 24x speed",
    "start": "1080799",
    "end": "1083280"
  },
  {
    "text": "up we're definitely aware of it now",
    "start": "1083280",
    "end": "1085440"
  },
  {
    "text": "and the other really nice thing about rl",
    "start": "1085440",
    "end": "1086960"
  },
  {
    "text": "lib is that it comes with ray clusters",
    "start": "1086960",
    "end": "1089520"
  },
  {
    "text": "again now this is going to vary here",
    "start": "1089520",
    "end": "1091280"
  },
  {
    "text": "depending on you know on your experiment",
    "start": "1091280",
    "end": "1093520"
  },
  {
    "text": "but we were able to get another 6x speed",
    "start": "1093520",
    "end": "1096320"
  },
  {
    "text": "up",
    "start": "1096320",
    "end": "1096559"
  },
  {
    "text": "on 16x the number of cpus but we were",
    "start": "1096559",
    "end": "1099200"
  },
  {
    "text": "able to get our experiments down from 2",
    "start": "1099200",
    "end": "1100559"
  },
  {
    "text": "hours down to 20 minutes",
    "start": "1100559",
    "end": "1102480"
  },
  {
    "text": "and so this was this is amazing and i",
    "start": "1102480",
    "end": "1104000"
  },
  {
    "text": "think most rl experiments that are",
    "start": "1104000",
    "end": "1106080"
  },
  {
    "text": "simulation bound at least are going to",
    "start": "1106080",
    "end": "1107520"
  },
  {
    "text": "really really benefit from this",
    "start": "1107520",
    "end": "1109840"
  },
  {
    "text": "and it's it's very easy for you know to",
    "start": "1109840",
    "end": "1113039"
  },
  {
    "text": "use the distributed compute of array",
    "start": "1113039",
    "end": "1114799"
  },
  {
    "text": "clusters",
    "start": "1114799",
    "end": "1116480"
  },
  {
    "text": "and so the really nice thing is on top",
    "start": "1116480",
    "end": "1118559"
  },
  {
    "text": "of that is that it's all commodity",
    "start": "1118559",
    "end": "1119919"
  },
  {
    "text": "cpu-only machines which are relatively",
    "start": "1119919",
    "end": "1122000"
  },
  {
    "text": "cheap compared to you know those big gpu",
    "start": "1122000",
    "end": "1124480"
  },
  {
    "text": "machines that you're used to for many",
    "start": "1124480",
    "end": "1125760"
  },
  {
    "text": "deep learning projects",
    "start": "1125760",
    "end": "1128080"
  },
  {
    "text": "so together out of all this you know",
    "start": "1128080",
    "end": "1130160"
  },
  {
    "text": "both those migrations we were able to",
    "start": "1130160",
    "end": "1131600"
  },
  {
    "text": "get our 24x speed up",
    "start": "1131600",
    "end": "1133840"
  },
  {
    "text": "and i think the other really nice thing",
    "start": "1133840",
    "end": "1135280"
  },
  {
    "text": "about this migration is that the",
    "start": "1135280",
    "end": "1136559"
  },
  {
    "text": "ecosystem has been just a really nice",
    "start": "1136559",
    "end": "1138080"
  },
  {
    "text": "bonus for us",
    "start": "1138080",
    "end": "1139520"
  },
  {
    "text": "um so you know before our experiments",
    "start": "1139520",
    "end": "1141760"
  },
  {
    "text": "were slow on their back and now they're",
    "start": "1141760",
    "end": "1142960"
  },
  {
    "text": "happy",
    "start": "1142960",
    "end": "1143440"
  },
  {
    "text": "fun and running thank you guys so much",
    "start": "1143440",
    "end": "1145679"
  },
  {
    "text": "for coming to the talk",
    "start": "1145679",
    "end": "1146720"
  },
  {
    "text": "and i'm ready to you know if we want to",
    "start": "1146720",
    "end": "1148400"
  },
  {
    "text": "do any q a",
    "start": "1148400",
    "end": "1151840"
  }
]
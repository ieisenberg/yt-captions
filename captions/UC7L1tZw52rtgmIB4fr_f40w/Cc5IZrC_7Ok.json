[
  {
    "start": "0",
    "end": "31000"
  },
  {
    "text": "hello everyone thanks for tuning in for",
    "start": "2240",
    "end": "3919"
  },
  {
    "text": "this race summit",
    "start": "3919",
    "end": "4799"
  },
  {
    "text": "talk my name is sanika i'm a machine",
    "start": "4799",
    "end": "7200"
  },
  {
    "text": "learning engineer with any scale",
    "start": "7200",
    "end": "9120"
  },
  {
    "text": "and today i will talk about our open",
    "start": "9120",
    "end": "10960"
  },
  {
    "text": "source python based reinforcement",
    "start": "10960",
    "end": "12639"
  },
  {
    "text": "learning library called",
    "start": "12639",
    "end": "13759"
  },
  {
    "text": "ray rlip and even though this will be",
    "start": "13759",
    "end": "16560"
  },
  {
    "text": "somewhat of a follow-up talk from eric's",
    "start": "16560",
    "end": "18080"
  },
  {
    "text": "presentation earlier today",
    "start": "18080",
    "end": "19840"
  },
  {
    "text": "it's not required to have any experience",
    "start": "19840",
    "end": "21680"
  },
  {
    "text": "using the library to follow this talk",
    "start": "21680",
    "end": "23439"
  },
  {
    "text": "there will be lots of information",
    "start": "23439",
    "end": "24880"
  },
  {
    "text": "in the talk on how to work with our lib",
    "start": "24880",
    "end": "26560"
  },
  {
    "text": "whether you're a very advanced user",
    "start": "26560",
    "end": "28400"
  },
  {
    "text": "or you have never used outlet before",
    "start": "28400",
    "end": "31840"
  },
  {
    "start": "31000",
    "end": "154000"
  },
  {
    "text": "let me quickly recap the reinforcement",
    "start": "32800",
    "end": "34399"
  },
  {
    "text": "learning cycle and then tell you where",
    "start": "34399",
    "end": "35920"
  },
  {
    "text": "our lip comes into play here",
    "start": "35920",
    "end": "38960"
  },
  {
    "text": "we have one or more agents and each of",
    "start": "38960",
    "end": "40719"
  },
  {
    "text": "these agents maps to a policy and",
    "start": "40719",
    "end": "42719"
  },
  {
    "text": "usually these policies contain a",
    "start": "42719",
    "end": "44480"
  },
  {
    "text": "trainable neural network",
    "start": "44480",
    "end": "46480"
  },
  {
    "text": "and now we can query the policies for",
    "start": "46480",
    "end": "48879"
  },
  {
    "text": "action decisions",
    "start": "48879",
    "end": "51360"
  },
  {
    "text": "and then these actions are being applied",
    "start": "51360",
    "end": "52800"
  },
  {
    "text": "in some environment and the environment",
    "start": "52800",
    "end": "54640"
  },
  {
    "text": "is the",
    "start": "54640",
    "end": "55760"
  },
  {
    "text": "the place where the agents live or with",
    "start": "55760",
    "end": "57920"
  },
  {
    "text": "which the agents interact",
    "start": "57920",
    "end": "60079"
  },
  {
    "text": "also the interactions between the agents",
    "start": "60079",
    "end": "61840"
  },
  {
    "text": "could either be",
    "start": "61840",
    "end": "63600"
  },
  {
    "text": "a cooperative they could work towards a",
    "start": "63600",
    "end": "65280"
  },
  {
    "text": "common goal or adversarial or they could",
    "start": "65280",
    "end": "67760"
  },
  {
    "text": "simply be neutral to each other",
    "start": "67760",
    "end": "71040"
  },
  {
    "text": "upon receiving these actions the",
    "start": "71040",
    "end": "72640"
  },
  {
    "text": "environment reacts with two types of",
    "start": "72640",
    "end": "74799"
  },
  {
    "text": "information",
    "start": "74799",
    "end": "76479"
  },
  {
    "text": "first the observations which could be",
    "start": "76479",
    "end": "78400"
  },
  {
    "text": "for example a camera image of some",
    "start": "78400",
    "end": "80240"
  },
  {
    "text": "cameras filming the scene",
    "start": "80240",
    "end": "82000"
  },
  {
    "text": "or some vectorized information other",
    "start": "82000",
    "end": "84080"
  },
  {
    "text": "information of the",
    "start": "84080",
    "end": "85200"
  },
  {
    "text": "of the environment let's say the",
    "start": "85200",
    "end": "86880"
  },
  {
    "text": "positions of the agent",
    "start": "86880",
    "end": "88240"
  },
  {
    "text": "or the state and in a separate channel",
    "start": "88240",
    "end": "90560"
  },
  {
    "text": "we have the reward signals",
    "start": "90560",
    "end": "92479"
  },
  {
    "text": "one floating point number per agent and",
    "start": "92479",
    "end": "94720"
  },
  {
    "text": "what every reinforcement learning",
    "start": "94720",
    "end": "95840"
  },
  {
    "text": "algorithm",
    "start": "95840",
    "end": "96640"
  },
  {
    "text": "does is it tries to maximize the sum of",
    "start": "96640",
    "end": "98880"
  },
  {
    "text": "these rewards",
    "start": "98880",
    "end": "100000"
  },
  {
    "text": "over the lifetime of the agents",
    "start": "100000",
    "end": "103920"
  },
  {
    "text": "now our lip allows you to execute any of",
    "start": "104240",
    "end": "106880"
  },
  {
    "text": "part of the cycle in a heavily",
    "start": "106880",
    "end": "108320"
  },
  {
    "text": "distributed fashion",
    "start": "108320",
    "end": "110159"
  },
  {
    "text": "on a server in the cloud or on your",
    "start": "110159",
    "end": "111439"
  },
  {
    "text": "laptop as well as allow you to modify",
    "start": "111439",
    "end": "114000"
  },
  {
    "text": "customize and configure all these parts",
    "start": "114000",
    "end": "116320"
  },
  {
    "text": "that you see here",
    "start": "116320",
    "end": "119040"
  },
  {
    "text": "also reinforcement learning is not",
    "start": "120640",
    "end": "122640"
  },
  {
    "text": "restricted to games or to you having a",
    "start": "122640",
    "end": "124719"
  },
  {
    "text": "simulator available for your problem",
    "start": "124719",
    "end": "126960"
  },
  {
    "text": "you could you could do reinforcement",
    "start": "126960",
    "end": "128560"
  },
  {
    "text": "learning with offline data or",
    "start": "128560",
    "end": "129679"
  },
  {
    "text": "pre-recorded historical data",
    "start": "129679",
    "end": "131599"
  },
  {
    "text": "you could think of your agents being",
    "start": "131599",
    "end": "133200"
  },
  {
    "text": "server farm where you run your overlap",
    "start": "133200",
    "end": "135280"
  },
  {
    "text": "distributed algorithm your actions could",
    "start": "135280",
    "end": "137599"
  },
  {
    "text": "be pumps that you stop or start",
    "start": "137599",
    "end": "139920"
  },
  {
    "text": "or that you have started or stopped your",
    "start": "139920",
    "end": "142640"
  },
  {
    "text": "environment could be a chemical plant",
    "start": "142640",
    "end": "144319"
  },
  {
    "text": "and your observations could be",
    "start": "144319",
    "end": "145840"
  },
  {
    "text": "sensor readings temperature sensors",
    "start": "145840",
    "end": "147520"
  },
  {
    "text": "pressure sensors",
    "start": "147520",
    "end": "149120"
  },
  {
    "text": "and for example your rewards could be",
    "start": "149120",
    "end": "150480"
  },
  {
    "text": "some electricity bill that you try to",
    "start": "150480",
    "end": "151840"
  },
  {
    "text": "minimize",
    "start": "151840",
    "end": "154319"
  },
  {
    "start": "154000",
    "end": "276000"
  },
  {
    "text": "the main focus of this talk is to tell",
    "start": "155599",
    "end": "157440"
  },
  {
    "text": "you what's new in our lip and what",
    "start": "157440",
    "end": "159040"
  },
  {
    "text": "features have we added",
    "start": "159040",
    "end": "160480"
  },
  {
    "text": "over the last six months",
    "start": "160480",
    "end": "163599"
  },
  {
    "text": "we added pytorch support if you looked",
    "start": "164800",
    "end": "166560"
  },
  {
    "text": "at our lip back in january 2020 you",
    "start": "166560",
    "end": "168720"
  },
  {
    "text": "would have seen this table of",
    "start": "168720",
    "end": "170080"
  },
  {
    "text": "available algorithms and their",
    "start": "170080",
    "end": "171920"
  },
  {
    "text": "associated deep learning frameworks",
    "start": "171920",
    "end": "173920"
  },
  {
    "text": "pytorch or tensorflow this has changed",
    "start": "173920",
    "end": "177280"
  },
  {
    "text": "dramatically we have added pie chart",
    "start": "177280",
    "end": "178800"
  },
  {
    "text": "support for all available algorithms in",
    "start": "178800",
    "end": "180879"
  },
  {
    "text": "our lib",
    "start": "180879",
    "end": "182000"
  },
  {
    "text": "and we also added new algorithms some of",
    "start": "182000",
    "end": "184000"
  },
  {
    "text": "which i will talk about",
    "start": "184000",
    "end": "185440"
  },
  {
    "text": "uh in in this talk",
    "start": "185440",
    "end": "188720"
  },
  {
    "text": "what else have we done to make uh deep",
    "start": "188720",
    "end": "190800"
  },
  {
    "text": "learning framework support better we",
    "start": "190800",
    "end": "192400"
  },
  {
    "text": "have added full support for tensorflow",
    "start": "192400",
    "end": "194480"
  },
  {
    "text": "2.",
    "start": "194480",
    "end": "195280"
  },
  {
    "text": "so tensorflow 2 now runs natively in our",
    "start": "195280",
    "end": "198000"
  },
  {
    "text": "lib you can you can run any of these",
    "start": "198000",
    "end": "199360"
  },
  {
    "text": "algorithms in eager mode",
    "start": "199360",
    "end": "202080"
  },
  {
    "text": "and the way you configure the framework",
    "start": "202080",
    "end": "205920"
  },
  {
    "text": "is we have a new key called framework in",
    "start": "205920",
    "end": "208319"
  },
  {
    "text": "our main config so here's here's",
    "start": "208319",
    "end": "210080"
  },
  {
    "text": "an example command line of auto run",
    "start": "210080",
    "end": "211599"
  },
  {
    "text": "things in our lib",
    "start": "211599",
    "end": "213120"
  },
  {
    "text": "uh you say config and then you can",
    "start": "213120",
    "end": "214480"
  },
  {
    "text": "specify the config as a json string",
    "start": "214480",
    "end": "216879"
  },
  {
    "text": "and the new key is framework and you can",
    "start": "216879",
    "end": "218640"
  },
  {
    "text": "specify four",
    "start": "218640",
    "end": "220400"
  },
  {
    "text": "known types one is tf for tensorflow",
    "start": "220400",
    "end": "223519"
  },
  {
    "text": "static graph that's the default",
    "start": "223519",
    "end": "225360"
  },
  {
    "text": "tfe for tensorflow eager and tf2 for",
    "start": "225360",
    "end": "227760"
  },
  {
    "text": "tensorflow 2",
    "start": "227760",
    "end": "229040"
  },
  {
    "text": "eager mode and then of course also torch",
    "start": "229040",
    "end": "230879"
  },
  {
    "text": "for pytorch",
    "start": "230879",
    "end": "233519"
  },
  {
    "text": "our lib also runs on windows now you can",
    "start": "236000",
    "end": "238319"
  },
  {
    "text": "go to our documentation pages",
    "start": "238319",
    "end": "240000"
  },
  {
    "text": "which i have i can give you the link",
    "start": "240000",
    "end": "241840"
  },
  {
    "text": "here um",
    "start": "241840",
    "end": "243120"
  },
  {
    "text": "and then download the the respective",
    "start": "243120",
    "end": "245280"
  },
  {
    "text": "wheel for your let's say anaconda python",
    "start": "245280",
    "end": "247599"
  },
  {
    "text": "version",
    "start": "247599",
    "end": "248560"
  },
  {
    "text": "then you pip install this wheel and then",
    "start": "248560",
    "end": "250799"
  },
  {
    "text": "you can execute a command line in your",
    "start": "250799",
    "end": "252400"
  },
  {
    "text": "windows prompt",
    "start": "252400",
    "end": "253760"
  },
  {
    "text": "just like it's shown here nowadays i",
    "start": "253760",
    "end": "257280"
  },
  {
    "text": "actually switch",
    "start": "257280",
    "end": "258079"
  },
  {
    "text": "sometimes during the day between my",
    "start": "258079",
    "end": "259759"
  },
  {
    "text": "windows pc which has a gpu which is",
    "start": "259759",
    "end": "261600"
  },
  {
    "text": "really nice for gpu testing",
    "start": "261600",
    "end": "263680"
  },
  {
    "text": "local gpu testing and then i go back to",
    "start": "263680",
    "end": "266560"
  },
  {
    "text": "my",
    "start": "266560",
    "end": "266960"
  },
  {
    "text": "laptop which runs the mac system and it",
    "start": "266960",
    "end": "269520"
  },
  {
    "text": "works",
    "start": "269520",
    "end": "270000"
  },
  {
    "text": "seamlessly it takes only a few seconds",
    "start": "270000",
    "end": "271440"
  },
  {
    "text": "because i have the files synced with",
    "start": "271440",
    "end": "272720"
  },
  {
    "text": "dropbox",
    "start": "272720",
    "end": "275199"
  },
  {
    "start": "276000",
    "end": "508000"
  },
  {
    "text": "next we added two model-based rl",
    "start": "277759",
    "end": "280080"
  },
  {
    "text": "algorithms to our lip",
    "start": "280080",
    "end": "281840"
  },
  {
    "text": "called dreamer published by deepmind",
    "start": "281840",
    "end": "284000"
  },
  {
    "text": "this year",
    "start": "284000",
    "end": "284960"
  },
  {
    "text": "and mbmpo published by uc berkeley in",
    "start": "284960",
    "end": "287120"
  },
  {
    "text": "collaboration with kit",
    "start": "287120",
    "end": "290240"
  },
  {
    "text": "the algos you could find so far in our",
    "start": "290240",
    "end": "292400"
  },
  {
    "text": "lib",
    "start": "292400",
    "end": "293840"
  },
  {
    "text": "all fall under the category of model 3",
    "start": "293840",
    "end": "296080"
  },
  {
    "text": "reinforcement learning",
    "start": "296080",
    "end": "297680"
  },
  {
    "text": "so what does model based actually mean",
    "start": "297680",
    "end": "299600"
  },
  {
    "text": "as opposed to model three",
    "start": "299600",
    "end": "300800"
  },
  {
    "text": "it's quite simple let's take a look at",
    "start": "300800",
    "end": "302000"
  },
  {
    "text": "our cycle again",
    "start": "302000",
    "end": "304240"
  },
  {
    "text": "what all model based algorithms do is",
    "start": "304240",
    "end": "306639"
  },
  {
    "text": "they learn a separate model",
    "start": "306639",
    "end": "309120"
  },
  {
    "text": "this green one here using supervised",
    "start": "309120",
    "end": "312000"
  },
  {
    "text": "learning",
    "start": "312000",
    "end": "312720"
  },
  {
    "text": "and this model is supposed to predict",
    "start": "312720",
    "end": "314720"
  },
  {
    "text": "how the environment",
    "start": "314720",
    "end": "315840"
  },
  {
    "text": "behaves so if i give as inputs to this",
    "start": "315840",
    "end": "318160"
  },
  {
    "text": "model",
    "start": "318160",
    "end": "319199"
  },
  {
    "text": "the current observation plus an action i",
    "start": "319199",
    "end": "322160"
  },
  {
    "text": "would like to take next",
    "start": "322160",
    "end": "323759"
  },
  {
    "text": "then this model will output what it",
    "start": "323759",
    "end": "325759"
  },
  {
    "text": "thinks the next observation will be",
    "start": "325759",
    "end": "329280"
  },
  {
    "text": "and once i have a model like that in",
    "start": "329520",
    "end": "330880"
  },
  {
    "text": "place and trained i can use it instead",
    "start": "330880",
    "end": "332479"
  },
  {
    "text": "of the actual environment",
    "start": "332479",
    "end": "334720"
  },
  {
    "text": "and that's what model based argos do",
    "start": "334720",
    "end": "336320"
  },
  {
    "text": "some of which even go as far as not to",
    "start": "336320",
    "end": "338160"
  },
  {
    "text": "use any actual environment data for",
    "start": "338160",
    "end": "340080"
  },
  {
    "text": "training the policies",
    "start": "340080",
    "end": "342080"
  },
  {
    "text": "and you would think then that this makes",
    "start": "342080",
    "end": "343360"
  },
  {
    "text": "model-based reinforcement learning",
    "start": "343360",
    "end": "344560"
  },
  {
    "text": "algorithms extremely simple efficient",
    "start": "344560",
    "end": "346639"
  },
  {
    "text": "more about that in a second but first",
    "start": "346639",
    "end": "349039"
  },
  {
    "text": "here's what it actually looks like to",
    "start": "349039",
    "end": "350240"
  },
  {
    "text": "predict the environment these are",
    "start": "350240",
    "end": "352240"
  },
  {
    "text": "dreamer results we benchmarked the dream",
    "start": "352240",
    "end": "354479"
  },
  {
    "text": "algorithm on different deep mind control",
    "start": "354479",
    "end": "356639"
  },
  {
    "text": "tasks",
    "start": "356639",
    "end": "358479"
  },
  {
    "text": "and these are basically this deep mind",
    "start": "358479",
    "end": "360080"
  },
  {
    "text": "control is basically a 3d physics engine",
    "start": "360080",
    "end": "363840"
  },
  {
    "text": "and you can you can have different",
    "start": "363840",
    "end": "366160"
  },
  {
    "text": "environments there for example this",
    "start": "366160",
    "end": "367680"
  },
  {
    "text": "stickman trying to learn how to walk and",
    "start": "367680",
    "end": "370639"
  },
  {
    "text": "if you're familiar with it with a mojoku",
    "start": "370639",
    "end": "372240"
  },
  {
    "text": "environment",
    "start": "372240",
    "end": "373039"
  },
  {
    "text": "it's kind of the same thing but with one",
    "start": "373039",
    "end": "374880"
  },
  {
    "text": "difference that we don't receive any",
    "start": "374880",
    "end": "377280"
  },
  {
    "text": "direct information",
    "start": "377280",
    "end": "378319"
  },
  {
    "text": "on the velocities angular velocities or",
    "start": "378319",
    "end": "380639"
  },
  {
    "text": "joint positions",
    "start": "380639",
    "end": "381759"
  },
  {
    "text": "but we merely see the entire scene",
    "start": "381759",
    "end": "383600"
  },
  {
    "text": "through a camera",
    "start": "383600",
    "end": "384800"
  },
  {
    "text": "so all our observations are just pixels",
    "start": "384800",
    "end": "389039"
  },
  {
    "text": "so that means that our environment model",
    "start": "389759",
    "end": "392240"
  },
  {
    "text": "which is what you see in the",
    "start": "392240",
    "end": "393600"
  },
  {
    "text": "second row here now is to predict next",
    "start": "393600",
    "end": "396000"
  },
  {
    "text": "observation images",
    "start": "396000",
    "end": "397919"
  },
  {
    "text": "and that's where the name dreamer comes",
    "start": "397919",
    "end": "399039"
  },
  {
    "text": "from this model is basically our dream",
    "start": "399039",
    "end": "400479"
  },
  {
    "text": "and it allows us to purely act",
    "start": "400479",
    "end": "402560"
  },
  {
    "text": "and learn inside the stream uh which in",
    "start": "402560",
    "end": "405280"
  },
  {
    "text": "which we collect trajectories",
    "start": "405280",
    "end": "406800"
  },
  {
    "text": "uh for our policy updates",
    "start": "406800",
    "end": "409919"
  },
  {
    "text": "and here you see the delta between the",
    "start": "409919",
    "end": "411120"
  },
  {
    "text": "two so you can see that at the beginning",
    "start": "411120",
    "end": "412240"
  },
  {
    "text": "of the trajectory",
    "start": "412240",
    "end": "413280"
  },
  {
    "text": "uh there's of course a full match",
    "start": "413280",
    "end": "414560"
  },
  {
    "text": "because we start with the same image",
    "start": "414560",
    "end": "416400"
  },
  {
    "text": "then the we query the policy for actions",
    "start": "416400",
    "end": "418560"
  },
  {
    "text": "predict the next image",
    "start": "418560",
    "end": "419919"
  },
  {
    "text": "again we query the policy with that",
    "start": "419919",
    "end": "421360"
  },
  {
    "text": "predicted image and so on",
    "start": "421360",
    "end": "423599"
  },
  {
    "text": "and even though they diverge after a",
    "start": "423599",
    "end": "425120"
  },
  {
    "text": "while the what the model produces",
    "start": "425120",
    "end": "427520"
  },
  {
    "text": "is quite a realistic scene it also looks",
    "start": "427520",
    "end": "430240"
  },
  {
    "text": "quite funny",
    "start": "430240",
    "end": "432720"
  },
  {
    "text": "back to the sample efficiency question",
    "start": "434639",
    "end": "436319"
  },
  {
    "text": "this is from the deepmind paper but we",
    "start": "436319",
    "end": "437599"
  },
  {
    "text": "were able to reproduce these exact",
    "start": "437599",
    "end": "439360"
  },
  {
    "text": "results with our lip",
    "start": "439360",
    "end": "441039"
  },
  {
    "text": "uh dreamer implementation here you see",
    "start": "441039",
    "end": "444000"
  },
  {
    "text": "that",
    "start": "444000",
    "end": "444400"
  },
  {
    "text": "uh that dreamer and the blue bars reach",
    "start": "444400",
    "end": "447199"
  },
  {
    "text": "uh reaches some episodic reward",
    "start": "447199",
    "end": "449680"
  },
  {
    "text": "uh for for those two tasks walker walk",
    "start": "449680",
    "end": "452000"
  },
  {
    "text": "and cheetah run",
    "start": "452000",
    "end": "453199"
  },
  {
    "text": "after about five million time steps and",
    "start": "453199",
    "end": "455840"
  },
  {
    "text": "these are actual environment interaction",
    "start": "455840",
    "end": "457599"
  },
  {
    "text": "time steps",
    "start": "457599",
    "end": "458800"
  },
  {
    "text": "not model queries and fascinatingly the",
    "start": "458800",
    "end": "461919"
  },
  {
    "text": "the model three algos",
    "start": "461919",
    "end": "463599"
  },
  {
    "text": "there's a pretty strong ones d4 pg and",
    "start": "463599",
    "end": "465280"
  },
  {
    "text": "a3c uh the orange and the red one here",
    "start": "465280",
    "end": "467919"
  },
  {
    "text": "uh they reached the same reward or even",
    "start": "467919",
    "end": "469680"
  },
  {
    "text": "less reward but with",
    "start": "469680",
    "end": "471199"
  },
  {
    "text": "far more actual environment interactions",
    "start": "471199",
    "end": "474080"
  },
  {
    "text": "about 20 fold 100 million time steps",
    "start": "474080",
    "end": "476879"
  },
  {
    "text": "so the sample efficiency for model-based",
    "start": "476879",
    "end": "478639"
  },
  {
    "text": "algorithms could increase by up to",
    "start": "478639",
    "end": "480400"
  },
  {
    "text": "20-fold",
    "start": "480400",
    "end": "482639"
  },
  {
    "text": "uh if you have a very expensive",
    "start": "482639",
    "end": "484000"
  },
  {
    "text": "environment some something that's very",
    "start": "484000",
    "end": "485599"
  },
  {
    "text": "hard to simulate that's very expensive",
    "start": "485599",
    "end": "487199"
  },
  {
    "text": "to simulate",
    "start": "487199",
    "end": "487919"
  },
  {
    "text": "uh you may want to take a look at",
    "start": "487919",
    "end": "489120"
  },
  {
    "text": "model-based reinforcement learning and",
    "start": "489120",
    "end": "490960"
  },
  {
    "text": "that our ellipse all goes",
    "start": "490960",
    "end": "492000"
  },
  {
    "text": "here and again this is an example",
    "start": "492000",
    "end": "495440"
  },
  {
    "text": "command line that you can run",
    "start": "495440",
    "end": "497120"
  },
  {
    "text": "on your command line after you've",
    "start": "497120",
    "end": "498160"
  },
  {
    "text": "installed our lib and the algorithms",
    "start": "498160",
    "end": "500639"
  },
  {
    "text": "reside",
    "start": "500639",
    "end": "501199"
  },
  {
    "text": "under these two directories here inside",
    "start": "501199",
    "end": "503919"
  },
  {
    "text": "the repo",
    "start": "503919",
    "end": "507840"
  },
  {
    "start": "508000",
    "end": "670000"
  },
  {
    "text": "in february and march 2020 we added an",
    "start": "508960",
    "end": "511840"
  },
  {
    "text": "expiration api",
    "start": "511840",
    "end": "512800"
  },
  {
    "text": "to our loop now what's an expiration api",
    "start": "512800",
    "end": "516000"
  },
  {
    "text": "the expiration api allows you to fully",
    "start": "516000",
    "end": "517760"
  },
  {
    "text": "customize all aspects of an agent's",
    "start": "517760",
    "end": "519919"
  },
  {
    "text": "exploratory behavior",
    "start": "519919",
    "end": "521760"
  },
  {
    "text": "in reinforcement learning as you may",
    "start": "521760",
    "end": "523518"
  },
  {
    "text": "know every algorithm has to deal with a",
    "start": "523519",
    "end": "525040"
  },
  {
    "text": "dilemma",
    "start": "525040",
    "end": "525680"
  },
  {
    "text": "and it goes like this should i explore",
    "start": "525680",
    "end": "527920"
  },
  {
    "text": "more and risk low rewards",
    "start": "527920",
    "end": "529760"
  },
  {
    "text": "so basically should i go to the new",
    "start": "529760",
    "end": "531120"
  },
  {
    "text": "restaurant and risk that the food is not",
    "start": "531120",
    "end": "533120"
  },
  {
    "text": "so great there",
    "start": "533120",
    "end": "534080"
  },
  {
    "text": "right because i have no idea what",
    "start": "534080",
    "end": "535200"
  },
  {
    "text": "they're cooking there or should i",
    "start": "535200",
    "end": "537120"
  },
  {
    "text": "exploit what i have learned already",
    "start": "537120",
    "end": "539279"
  },
  {
    "text": "go to the usual place to receive rewards",
    "start": "539279",
    "end": "541519"
  },
  {
    "text": "i already know i will get",
    "start": "541519",
    "end": "543519"
  },
  {
    "text": "again go to the usual place get the",
    "start": "543519",
    "end": "544880"
  },
  {
    "text": "usual food i know what i'm getting",
    "start": "544880",
    "end": "546720"
  },
  {
    "text": "but then at the same time i'm risking",
    "start": "546720",
    "end": "548399"
  },
  {
    "text": "missing out on the grand opening",
    "start": "548399",
    "end": "550160"
  },
  {
    "text": "and and on the great food that may be",
    "start": "550160",
    "end": "552080"
  },
  {
    "text": "behind this new restaurant",
    "start": "552080",
    "end": "555360"
  },
  {
    "text": "so this trade-off is called exploration",
    "start": "555360",
    "end": "557040"
  },
  {
    "text": "exploitation dilemma",
    "start": "557040",
    "end": "559200"
  },
  {
    "text": "and through the exploration api in our",
    "start": "559200",
    "end": "561120"
  },
  {
    "text": "lib you can define your custom behaviors",
    "start": "561120",
    "end": "563279"
  },
  {
    "text": "to deal with this dilemma",
    "start": "563279",
    "end": "566399"
  },
  {
    "text": "and our exploration api is basically",
    "start": "566560",
    "end": "568080"
  },
  {
    "text": "just a class this is the base class here",
    "start": "568080",
    "end": "571040"
  },
  {
    "text": "and it allows you to subclass it and",
    "start": "571040",
    "end": "572640"
  },
  {
    "text": "then override one or more methods",
    "start": "572640",
    "end": "575680"
  },
  {
    "text": "and there are already lots of subclasses",
    "start": "575680",
    "end": "577839"
  },
  {
    "text": "built into the library",
    "start": "577839",
    "end": "579279"
  },
  {
    "text": "which makes sense because our algorithms",
    "start": "579279",
    "end": "582160"
  },
  {
    "text": "for example dqn",
    "start": "582160",
    "end": "584399"
  },
  {
    "text": "use these subclasses for their own",
    "start": "584399",
    "end": "586000"
  },
  {
    "text": "exploratory default behavior of course",
    "start": "586000",
    "end": "588399"
  },
  {
    "text": "you can change it you could run eqn with",
    "start": "588399",
    "end": "590000"
  },
  {
    "text": "a different",
    "start": "590000",
    "end": "590959"
  },
  {
    "text": "exploratory behavior other than epsilon",
    "start": "590959",
    "end": "592640"
  },
  {
    "text": "greedy uh and so on",
    "start": "592640",
    "end": "596240"
  },
  {
    "text": "and this is location where you can find",
    "start": "596640",
    "end": "598240"
  },
  {
    "text": "all the code some of the in the uterus",
    "start": "598240",
    "end": "600320"
  },
  {
    "text": "directory under exploration",
    "start": "600320",
    "end": "603360"
  },
  {
    "text": "now there are two important developments",
    "start": "603360",
    "end": "605120"
  },
  {
    "text": "that came out of of the fact that we",
    "start": "605120",
    "end": "606959"
  },
  {
    "text": "added this exploration api",
    "start": "606959",
    "end": "608720"
  },
  {
    "text": "to the library in the spring the first",
    "start": "608720",
    "end": "611279"
  },
  {
    "text": "one is",
    "start": "611279",
    "end": "612240"
  },
  {
    "text": "multi-armed contextual bandits our",
    "start": "612240",
    "end": "615040"
  },
  {
    "text": "friends at amazon aws contributed two",
    "start": "615040",
    "end": "617040"
  },
  {
    "text": "algorithms to our lib",
    "start": "617040",
    "end": "618560"
  },
  {
    "text": "thomson sampling and upper confidence",
    "start": "618560",
    "end": "620640"
  },
  {
    "text": "bound this was back in march using the",
    "start": "620640",
    "end": "622399"
  },
  {
    "text": "exploration api",
    "start": "622399",
    "end": "623600"
  },
  {
    "text": "and these two algos both fall under the",
    "start": "623600",
    "end": "625680"
  },
  {
    "text": "category of contextual multi-armed",
    "start": "625680",
    "end": "627279"
  },
  {
    "text": "bandits",
    "start": "627279",
    "end": "628880"
  },
  {
    "text": "and amazon is actually using these right",
    "start": "628880",
    "end": "630880"
  },
  {
    "text": "now to build quote unquote recommender",
    "start": "630880",
    "end": "633120"
  },
  {
    "text": "systems as well as a b testing tools",
    "start": "633120",
    "end": "636480"
  },
  {
    "text": "if you're interested in building your",
    "start": "636480",
    "end": "638640"
  },
  {
    "text": "own recommender systems",
    "start": "638640",
    "end": "639760"
  },
  {
    "text": "with our lib using the banded algorithms",
    "start": "639760",
    "end": "642720"
  },
  {
    "text": "i highly recommend you check out",
    "start": "642720",
    "end": "644320"
  },
  {
    "text": "paco nation's any scale academy tutorial",
    "start": "644320",
    "end": "646160"
  },
  {
    "text": "under this link here",
    "start": "646160",
    "end": "647440"
  },
  {
    "text": "in which he explains step by step how to",
    "start": "647440",
    "end": "649279"
  },
  {
    "text": "do this",
    "start": "649279",
    "end": "650880"
  },
  {
    "text": "and his example is joke recommendations",
    "start": "650880",
    "end": "653200"
  },
  {
    "text": "based on previous user ratings of jokes",
    "start": "653200",
    "end": "656880"
  },
  {
    "text": "and again here's a command line of how",
    "start": "656880",
    "end": "658399"
  },
  {
    "text": "to use these algos they reside in the",
    "start": "658399",
    "end": "660240"
  },
  {
    "text": "contract folder",
    "start": "660240",
    "end": "661760"
  },
  {
    "text": "lin ts is for thomson sampling and lin",
    "start": "661760",
    "end": "663839"
  },
  {
    "text": "ucb is for upper confidence bound",
    "start": "663839",
    "end": "667760"
  },
  {
    "start": "670000",
    "end": "910000"
  },
  {
    "text": "the other important thing that came out",
    "start": "671120",
    "end": "672720"
  },
  {
    "text": "of our exploration api is curiosity",
    "start": "672720",
    "end": "675760"
  },
  {
    "text": "now what is curiosity imagine we have an",
    "start": "675760",
    "end": "677760"
  },
  {
    "text": "environment that looks like this",
    "start": "677760",
    "end": "681040"
  },
  {
    "text": "the agent is this blue bot here which",
    "start": "681040",
    "end": "683279"
  },
  {
    "text": "can navigate",
    "start": "683279",
    "end": "684320"
  },
  {
    "text": "through a nine-room maze and the rooms",
    "start": "684320",
    "end": "686640"
  },
  {
    "text": "are connected by doors",
    "start": "686640",
    "end": "688959"
  },
  {
    "text": "and some of the rooms contain white",
    "start": "688959",
    "end": "690320"
  },
  {
    "text": "permits and only one of the rooms uh",
    "start": "690320",
    "end": "693360"
  },
  {
    "text": "this is the interesting part here",
    "start": "693360",
    "end": "694880"
  },
  {
    "text": "contain a switch",
    "start": "694880",
    "end": "696640"
  },
  {
    "text": "this yellow switch that you see in the",
    "start": "696640",
    "end": "698160"
  },
  {
    "text": "upper left room right now",
    "start": "698160",
    "end": "701040"
  },
  {
    "text": "the location of the switch and of the",
    "start": "701040",
    "end": "702720"
  },
  {
    "text": "white pyramids is randomized and it",
    "start": "702720",
    "end": "704800"
  },
  {
    "text": "changes all every time you reset the",
    "start": "704800",
    "end": "706399"
  },
  {
    "text": "environment so there's no way for the",
    "start": "706399",
    "end": "708079"
  },
  {
    "text": "for the agent uh to remember these",
    "start": "708079",
    "end": "711600"
  },
  {
    "text": "if the bots were to touch the switch and",
    "start": "711600",
    "end": "713760"
  },
  {
    "text": "flip it",
    "start": "713760",
    "end": "715120"
  },
  {
    "text": "a golden pyramid a new golden permit",
    "start": "715120",
    "end": "717040"
  },
  {
    "text": "would appear in one of the other rooms",
    "start": "717040",
    "end": "719680"
  },
  {
    "text": "again at a random location and then the",
    "start": "719680",
    "end": "722800"
  },
  {
    "text": "the bot can",
    "start": "722800",
    "end": "723600"
  },
  {
    "text": "uh basically push over the pyramid so",
    "start": "723600",
    "end": "725680"
  },
  {
    "text": "it's all the stones fall down",
    "start": "725680",
    "end": "728320"
  },
  {
    "text": "and then it has to touch the green cube",
    "start": "728320",
    "end": "730160"
  },
  {
    "text": "on top of this golden pyramid",
    "start": "730160",
    "end": "731839"
  },
  {
    "text": "to end the episode",
    "start": "731839",
    "end": "734880"
  },
  {
    "text": "there are two things here that make this",
    "start": "734880",
    "end": "736560"
  },
  {
    "text": "this environment really really hard",
    "start": "736560",
    "end": "738959"
  },
  {
    "text": "the first one is the number of time",
    "start": "738959",
    "end": "741040"
  },
  {
    "text": "steps that you have",
    "start": "741040",
    "end": "742480"
  },
  {
    "text": "to to explore this amp and to walk",
    "start": "742480",
    "end": "743920"
  },
  {
    "text": "around before the episode gets reset is",
    "start": "743920",
    "end": "745920"
  },
  {
    "text": "only five thousand",
    "start": "745920",
    "end": "748720"
  },
  {
    "text": "so you have to hurry up you have to try",
    "start": "748720",
    "end": "750079"
  },
  {
    "text": "to find the switch first then find the",
    "start": "750079",
    "end": "751600"
  },
  {
    "text": "golden pyramid",
    "start": "751600",
    "end": "753200"
  },
  {
    "text": "uh make it make it uh toggle it over and",
    "start": "753200",
    "end": "755360"
  },
  {
    "text": "then collect the green the green",
    "start": "755360",
    "end": "757839"
  },
  {
    "text": "also there are no rewards whatsoever the",
    "start": "757839",
    "end": "760240"
  },
  {
    "text": "environment always returns",
    "start": "760240",
    "end": "761839"
  },
  {
    "text": "zero as the reward every time step",
    "start": "761839",
    "end": "764160"
  },
  {
    "text": "except for one for one time when you",
    "start": "764160",
    "end": "766160"
  },
  {
    "text": "actually collect the green cube that's",
    "start": "766160",
    "end": "767760"
  },
  {
    "text": "the only reward you get which is plus",
    "start": "767760",
    "end": "769360"
  },
  {
    "text": "one",
    "start": "769360",
    "end": "771120"
  },
  {
    "text": "this type of environment is completely",
    "start": "771120",
    "end": "772639"
  },
  {
    "text": "unsolvable by any reinforcement learning",
    "start": "772639",
    "end": "774800"
  },
  {
    "text": "algorithms no matter how long you run it",
    "start": "774800",
    "end": "778560"
  },
  {
    "text": "so what's the solution what do we do we",
    "start": "779839",
    "end": "782480"
  },
  {
    "text": "add curiosity to the agent",
    "start": "782480",
    "end": "784240"
  },
  {
    "text": "so we we do actually the same thing as",
    "start": "784240",
    "end": "787360"
  },
  {
    "text": "we do for model based rl",
    "start": "787360",
    "end": "789360"
  },
  {
    "text": "we learn a model of the environment",
    "start": "789360",
    "end": "791680"
  },
  {
    "text": "which takes",
    "start": "791680",
    "end": "792639"
  },
  {
    "text": "as inputs an observation a current",
    "start": "792639",
    "end": "794639"
  },
  {
    "text": "observation and an action",
    "start": "794639",
    "end": "796320"
  },
  {
    "text": "and it outputs what it thinks the next",
    "start": "796320",
    "end": "798240"
  },
  {
    "text": "observation will be",
    "start": "798240",
    "end": "801760"
  },
  {
    "text": "and then we compare this prediction of",
    "start": "801760",
    "end": "803440"
  },
  {
    "text": "the next observation",
    "start": "803440",
    "end": "805200"
  },
  {
    "text": "with the actual next observation the",
    "start": "805200",
    "end": "807200"
  },
  {
    "text": "true one",
    "start": "807200",
    "end": "808240"
  },
  {
    "text": "and we take the delta and we say this",
    "start": "808240",
    "end": "810720"
  },
  {
    "text": "delta is our intrinsic reward so we",
    "start": "810720",
    "end": "812800"
  },
  {
    "text": "create an artificial reward signal",
    "start": "812800",
    "end": "815200"
  },
  {
    "text": "that we add to the environment's reward",
    "start": "815200",
    "end": "817360"
  },
  {
    "text": "signal which is always",
    "start": "817360",
    "end": "818560"
  },
  {
    "text": "zero anyways and with this artificially",
    "start": "818560",
    "end": "821199"
  },
  {
    "text": "calculated reward signal",
    "start": "821199",
    "end": "822800"
  },
  {
    "text": "we let any algorithm any reinforcement",
    "start": "822800",
    "end": "825440"
  },
  {
    "text": "learning algorithm on top",
    "start": "825440",
    "end": "827120"
  },
  {
    "text": "learn the policy",
    "start": "827120",
    "end": "830240"
  },
  {
    "text": "why do we take this delta for the",
    "start": "831760",
    "end": "833040"
  },
  {
    "text": "intrinsic reward the reason is very",
    "start": "833040",
    "end": "834560"
  },
  {
    "text": "simple",
    "start": "834560",
    "end": "835199"
  },
  {
    "text": "if the model if this environment model",
    "start": "835199",
    "end": "837040"
  },
  {
    "text": "is bad at predicting what's going to",
    "start": "837040",
    "end": "838480"
  },
  {
    "text": "happen",
    "start": "838480",
    "end": "839279"
  },
  {
    "text": "it means that we probably haven't been",
    "start": "839279",
    "end": "840800"
  },
  {
    "text": "there very often to these areas of the",
    "start": "840800",
    "end": "842480"
  },
  {
    "text": "environment",
    "start": "842480",
    "end": "843360"
  },
  {
    "text": "which makes us curious to go there and",
    "start": "843360",
    "end": "845199"
  },
  {
    "text": "to explore more",
    "start": "845199",
    "end": "846880"
  },
  {
    "text": "and the more we go to these areas the",
    "start": "846880",
    "end": "850560"
  },
  {
    "text": "the smaller will the the the intrinsic",
    "start": "850560",
    "end": "853600"
  },
  {
    "text": "reward will become",
    "start": "853600",
    "end": "856800"
  },
  {
    "text": "and this makes the agent explore for a",
    "start": "856800",
    "end": "858720"
  },
  {
    "text": "while to in areas that it hasn't been",
    "start": "858720",
    "end": "860800"
  },
  {
    "text": "much and then after a while leave these",
    "start": "860800",
    "end": "863680"
  },
  {
    "text": "areas alone and go to some other areas",
    "start": "863680",
    "end": "865120"
  },
  {
    "text": "that seem to be more interesting",
    "start": "865120",
    "end": "870399"
  },
  {
    "text": "you can configure your curiosity module",
    "start": "870399",
    "end": "872800"
  },
  {
    "text": "or your exploration behavior in this in",
    "start": "872800",
    "end": "874480"
  },
  {
    "text": "this following way there's a new uh",
    "start": "874480",
    "end": "876000"
  },
  {
    "text": "key in the config called exploration",
    "start": "876000",
    "end": "877680"
  },
  {
    "text": "underscore config",
    "start": "877680",
    "end": "879519"
  },
  {
    "text": "and then you give a dictionary to this",
    "start": "879519",
    "end": "881839"
  },
  {
    "text": "to this key",
    "start": "881839",
    "end": "882720"
  },
  {
    "text": "and in this dictionary you have a",
    "start": "882720",
    "end": "884000"
  },
  {
    "text": "subtype or like a type of your",
    "start": "884000",
    "end": "885680"
  },
  {
    "text": "exploration class",
    "start": "885680",
    "end": "887360"
  },
  {
    "text": "and this could be a full class path to",
    "start": "887360",
    "end": "888800"
  },
  {
    "text": "your to your own custom",
    "start": "888800",
    "end": "890880"
  },
  {
    "text": "exploration classes there's there are",
    "start": "890880",
    "end": "893519"
  },
  {
    "text": "test cases here for this curiosity",
    "start": "893519",
    "end": "894959"
  },
  {
    "text": "module that you can",
    "start": "894959",
    "end": "895920"
  },
  {
    "text": "take a look at which creates a sparse",
    "start": "895920",
    "end": "898240"
  },
  {
    "text": "simple reward",
    "start": "898240",
    "end": "899360"
  },
  {
    "text": "in a grid world and then proves that",
    "start": "899360",
    "end": "901199"
  },
  {
    "text": "cures that you can solve it",
    "start": "901199",
    "end": "902800"
  },
  {
    "text": "also this example that i just showed you",
    "start": "902800",
    "end": "904160"
  },
  {
    "text": "with the pyramids uh you can find it",
    "start": "904160",
    "end": "905600"
  },
  {
    "text": "under the script here",
    "start": "905600",
    "end": "907839"
  },
  {
    "text": "in the examples folder",
    "start": "907839",
    "end": "912320"
  },
  {
    "start": "910000",
    "end": "1024000"
  },
  {
    "text": "we put some focus this last quarter on",
    "start": "912320",
    "end": "914639"
  },
  {
    "text": "complex environments now what i mean by",
    "start": "914639",
    "end": "916480"
  },
  {
    "text": "complex",
    "start": "916480",
    "end": "918880"
  },
  {
    "text": "these are complex environments complex",
    "start": "919120",
    "end": "920560"
  },
  {
    "text": "environments are expensive to simulate",
    "start": "920560",
    "end": "923600"
  },
  {
    "text": "they are vast and may contain thousands",
    "start": "923600",
    "end": "925680"
  },
  {
    "text": "of agents",
    "start": "925680",
    "end": "926639"
  },
  {
    "text": "that are interacting with each other",
    "start": "926639",
    "end": "928240"
  },
  {
    "text": "again either in adversarial fashion or",
    "start": "928240",
    "end": "930240"
  },
  {
    "text": "in cooperative fashion or",
    "start": "930240",
    "end": "931440"
  },
  {
    "text": "simply not care about each other and",
    "start": "931440",
    "end": "934560"
  },
  {
    "text": "the trajectories that these agents live",
    "start": "934560",
    "end": "936800"
  },
  {
    "text": "for in these environments are tens of",
    "start": "936800",
    "end": "938240"
  },
  {
    "text": "thousands of time steps long",
    "start": "938240",
    "end": "941519"
  },
  {
    "text": "on the left side we have joseph suarez",
    "start": "941519",
    "end": "943839"
  },
  {
    "text": "newell mmo world",
    "start": "943839",
    "end": "945440"
  },
  {
    "text": "he's doing research on multi-agent rl at",
    "start": "945440",
    "end": "947360"
  },
  {
    "text": "mit",
    "start": "947360",
    "end": "948959"
  },
  {
    "text": "and he developed this massively",
    "start": "948959",
    "end": "950240"
  },
  {
    "text": "multi-player environment and hooked it",
    "start": "950240",
    "end": "951839"
  },
  {
    "text": "up to our lib",
    "start": "951839",
    "end": "952800"
  },
  {
    "text": "to train the thousands of agents inside",
    "start": "952800",
    "end": "954399"
  },
  {
    "text": "this world",
    "start": "954399",
    "end": "956720"
  },
  {
    "text": "the agents here uh compete for resources",
    "start": "956720",
    "end": "959120"
  },
  {
    "text": "so they walk around and",
    "start": "959120",
    "end": "960560"
  },
  {
    "text": "try to get water and they also shoot",
    "start": "960560",
    "end": "962880"
  },
  {
    "text": "each other so they're",
    "start": "962880",
    "end": "964800"
  },
  {
    "text": "heavily adversarial towards each other",
    "start": "964800",
    "end": "968399"
  },
  {
    "text": "um and they try to survive for as long",
    "start": "968399",
    "end": "970480"
  },
  {
    "text": "as possible",
    "start": "970480",
    "end": "972959"
  },
  {
    "text": "on the right side we have our new unity",
    "start": "973839",
    "end": "976480"
  },
  {
    "text": "3d adapter",
    "start": "976480",
    "end": "978639"
  },
  {
    "text": "the example i showed you earlier to",
    "start": "978639",
    "end": "980160"
  },
  {
    "text": "explain curiosity already use the unity",
    "start": "980160",
    "end": "982079"
  },
  {
    "text": "example the pyramid environment",
    "start": "982079",
    "end": "984399"
  },
  {
    "text": "so here's an example script at this",
    "start": "984399",
    "end": "986000"
  },
  {
    "text": "location here in the repo",
    "start": "986000",
    "end": "988320"
  },
  {
    "text": "that shows how to use the adapter and",
    "start": "988320",
    "end": "991759"
  },
  {
    "text": "and plug in different example",
    "start": "991759",
    "end": "993040"
  },
  {
    "text": "environments these are provided by unity",
    "start": "993040",
    "end": "994639"
  },
  {
    "text": "but you can of course create your own",
    "start": "994639",
    "end": "995839"
  },
  {
    "text": "ones as well",
    "start": "995839",
    "end": "997519"
  },
  {
    "text": "what we see here is yet another example",
    "start": "997519",
    "end": "999199"
  },
  {
    "text": "from year d which is the soccer",
    "start": "999199",
    "end": "1001199"
  },
  {
    "text": "environment",
    "start": "1001199",
    "end": "1002959"
  },
  {
    "text": "and here you have two different policies",
    "start": "1002959",
    "end": "1004560"
  },
  {
    "text": "that you train separately in a",
    "start": "1004560",
    "end": "1005839"
  },
  {
    "text": "multi-agent setting",
    "start": "1005839",
    "end": "1007199"
  },
  {
    "text": "uh one is the striker policy let's see",
    "start": "1007199",
    "end": "1009839"
  },
  {
    "text": "the two blue guys here",
    "start": "1009839",
    "end": "1011120"
  },
  {
    "text": "trying to get the ball over the uh into",
    "start": "1011120",
    "end": "1013759"
  },
  {
    "text": "the goal",
    "start": "1013759",
    "end": "1014800"
  },
  {
    "text": "and then the other policy is the",
    "start": "1014800",
    "end": "1016000"
  },
  {
    "text": "goalkeeper the purple robot here",
    "start": "1016000",
    "end": "1018480"
  },
  {
    "text": "trying to defend the goal",
    "start": "1018480",
    "end": "1025360"
  },
  {
    "text": "finally this is not a new feature but i",
    "start": "1025360",
    "end": "1026798"
  },
  {
    "text": "would like to still include it here",
    "start": "1026799",
    "end": "1027839"
  },
  {
    "text": "because it's certainly important for",
    "start": "1027839",
    "end": "1029038"
  },
  {
    "text": "running complex environments in a",
    "start": "1029039",
    "end": "1030400"
  },
  {
    "text": "production setting",
    "start": "1030400",
    "end": "1032558"
  },
  {
    "text": "here goes take a look at our circle",
    "start": "1032559",
    "end": "1033839"
  },
  {
    "text": "again in the traditional reinforcement",
    "start": "1033839",
    "end": "1035280"
  },
  {
    "text": "research setting",
    "start": "1035280",
    "end": "1036640"
  },
  {
    "text": "the agent has control over the",
    "start": "1036640",
    "end": "1038160"
  },
  {
    "text": "environment's timing",
    "start": "1038160",
    "end": "1040240"
  },
  {
    "text": "so there's a step method for the",
    "start": "1040240",
    "end": "1041760"
  },
  {
    "text": "environment and the agent controls",
    "start": "1041760",
    "end": "1044480"
  },
  {
    "text": "when that method is called to step",
    "start": "1044480",
    "end": "1047360"
  },
  {
    "text": "through the environment",
    "start": "1047360",
    "end": "1050160"
  },
  {
    "text": "now why could this possibly be a bad",
    "start": "1050160",
    "end": "1051679"
  },
  {
    "text": "thing",
    "start": "1051679",
    "end": "1053200"
  },
  {
    "text": "let's assume again we have uh complex",
    "start": "1053200",
    "end": "1055280"
  },
  {
    "text": "simulators running on separate machines",
    "start": "1055280",
    "end": "1058080"
  },
  {
    "text": "um these could be game engines or the",
    "start": "1058080",
    "end": "1060160"
  },
  {
    "text": "gazebo robotic simulator",
    "start": "1060160",
    "end": "1061919"
  },
  {
    "text": "or the any logic software",
    "start": "1061919",
    "end": "1065440"
  },
  {
    "text": "and even worse you may have outside",
    "start": "1065440",
    "end": "1068240"
  },
  {
    "text": "interactions with these",
    "start": "1068240",
    "end": "1069520"
  },
  {
    "text": "with these virtual worlds that you",
    "start": "1069520",
    "end": "1070960"
  },
  {
    "text": "create there so you could have for",
    "start": "1070960",
    "end": "1072080"
  },
  {
    "text": "example",
    "start": "1072080",
    "end": "1073440"
  },
  {
    "text": "some some human players connecting to",
    "start": "1073440",
    "end": "1075440"
  },
  {
    "text": "your game",
    "start": "1075440",
    "end": "1076480"
  },
  {
    "text": "and sending actions at their own speed",
    "start": "1076480",
    "end": "1078320"
  },
  {
    "text": "to this environment um",
    "start": "1078320",
    "end": "1080720"
  },
  {
    "text": "now i can see that this is probably a",
    "start": "1080720",
    "end": "1081840"
  },
  {
    "text": "bad idea that the agent controls uh the",
    "start": "1081840",
    "end": "1084000"
  },
  {
    "text": "flow",
    "start": "1084000",
    "end": "1084480"
  },
  {
    "text": "right or the controls the the uh the",
    "start": "1084480",
    "end": "1086640"
  },
  {
    "text": "stepping rate",
    "start": "1086640",
    "end": "1088960"
  },
  {
    "text": "so what we can do and we can again we",
    "start": "1088960",
    "end": "1090799"
  },
  {
    "text": "can do this with our lip already we can",
    "start": "1090799",
    "end": "1092320"
  },
  {
    "text": "turn this whole thing upside down",
    "start": "1092320",
    "end": "1094880"
  },
  {
    "text": "so we make our environment the client",
    "start": "1094880",
    "end": "1097919"
  },
  {
    "text": "and the client connects to some server",
    "start": "1097919",
    "end": "1100080"
  },
  {
    "text": "which runs the agent and",
    "start": "1100080",
    "end": "1101600"
  },
  {
    "text": "the algorithms and it has the policies",
    "start": "1101600",
    "end": "1103280"
  },
  {
    "text": "and it trains the policies on data that",
    "start": "1103280",
    "end": "1104799"
  },
  {
    "text": "it receives from the environment",
    "start": "1104799",
    "end": "1106240"
  },
  {
    "text": "and the environment can simply add its",
    "start": "1106240",
    "end": "1107679"
  },
  {
    "text": "own uh leisure and its own speed",
    "start": "1107679",
    "end": "1110480"
  },
  {
    "text": "um call this get action method to query",
    "start": "1110480",
    "end": "1112880"
  },
  {
    "text": "for actions whenever it wants to",
    "start": "1112880",
    "end": "1114400"
  },
  {
    "text": "whenever it needs an action",
    "start": "1114400",
    "end": "1117520"
  },
  {
    "text": "this functionality which we call",
    "start": "1118240",
    "end": "1119600"
  },
  {
    "text": "external and is already available in our",
    "start": "1119600",
    "end": "1122000"
  },
  {
    "text": "lib",
    "start": "1122000",
    "end": "1123440"
  },
  {
    "text": "you can we have two example scripts",
    "start": "1123440",
    "end": "1125600"
  },
  {
    "text": "available and each one has a client in",
    "start": "1125600",
    "end": "1127440"
  },
  {
    "text": "the server version",
    "start": "1127440",
    "end": "1128720"
  },
  {
    "text": "so there's a simple card poll example",
    "start": "1128720",
    "end": "1131360"
  },
  {
    "text": "where you can have a carpool server and",
    "start": "1131360",
    "end": "1132799"
  },
  {
    "text": "then connect the carpro client",
    "start": "1132799",
    "end": "1134720"
  },
  {
    "text": "to learn this environment or you can use",
    "start": "1134720",
    "end": "1137039"
  },
  {
    "text": "the unity",
    "start": "1137039",
    "end": "1137760"
  },
  {
    "text": "engine to hook up your unity engine",
    "start": "1137760",
    "end": "1141039"
  },
  {
    "text": "which runs any environment against some",
    "start": "1141039",
    "end": "1144080"
  },
  {
    "text": "our loop",
    "start": "1144080",
    "end": "1145200"
  },
  {
    "text": "policy server",
    "start": "1145200",
    "end": "1150880"
  },
  {
    "text": "lastly what will happen in our lib in q4",
    "start": "1150880",
    "end": "1154960"
  },
  {
    "text": "we will put a lot of focus on stability",
    "start": "1155120",
    "end": "1157280"
  },
  {
    "text": "uh because we're moving towards ray our",
    "start": "1157280",
    "end": "1158880"
  },
  {
    "text": "light one oh",
    "start": "1158880",
    "end": "1160640"
  },
  {
    "text": "which means we will automate the daily",
    "start": "1160640",
    "end": "1162559"
  },
  {
    "text": "regression testing",
    "start": "1162559",
    "end": "1163679"
  },
  {
    "text": "and the performance testing on hard",
    "start": "1163679",
    "end": "1165440"
  },
  {
    "text": "environments meaning atari environments",
    "start": "1165440",
    "end": "1166880"
  },
  {
    "text": "mojoku",
    "start": "1166880",
    "end": "1167760"
  },
  {
    "text": "to make sure that we don't include",
    "start": "1167760",
    "end": "1169520"
  },
  {
    "text": "introduce any regressions by accident",
    "start": "1169520",
    "end": "1172400"
  },
  {
    "text": "these tests will use the gpu and they",
    "start": "1172400",
    "end": "1174000"
  },
  {
    "text": "will be fully automated and run daily so",
    "start": "1174000",
    "end": "1176320"
  },
  {
    "text": "that we",
    "start": "1176320",
    "end": "1177360"
  },
  {
    "text": "catch errors in our prs early on",
    "start": "1177360",
    "end": "1181840"
  },
  {
    "text": "next we also will put a focus on",
    "start": "1182080",
    "end": "1183919"
  },
  {
    "text": "attention nets attention networks",
    "start": "1183919",
    "end": "1186240"
  },
  {
    "text": "are already available under this",
    "start": "1186240",
    "end": "1188000"
  },
  {
    "text": "directory here",
    "start": "1188000",
    "end": "1189280"
  },
  {
    "text": "we implemented the gtrxl architecture",
    "start": "1189280",
    "end": "1192080"
  },
  {
    "text": "for both tensorflow and torch",
    "start": "1192080",
    "end": "1194080"
  },
  {
    "text": "but these need more speed up and more",
    "start": "1194080",
    "end": "1195840"
  },
  {
    "text": "benchmarking so we need to",
    "start": "1195840",
    "end": "1197120"
  },
  {
    "text": "make sure they really work on the hard",
    "start": "1197120",
    "end": "1198640"
  },
  {
    "text": "environments and really are able to",
    "start": "1198640",
    "end": "1200080"
  },
  {
    "text": "learn something",
    "start": "1200080",
    "end": "1201919"
  },
  {
    "text": "using our algorithms",
    "start": "1201919",
    "end": "1204960"
  },
  {
    "text": "another effort is our trajectory view",
    "start": "1205200",
    "end": "1206799"
  },
  {
    "text": "api this will massively increase",
    "start": "1206799",
    "end": "1208480"
  },
  {
    "text": "performance and memory savings for",
    "start": "1208480",
    "end": "1210000"
  },
  {
    "text": "sampling and",
    "start": "1210000",
    "end": "1210720"
  },
  {
    "text": "training and it also allows you to fully",
    "start": "1210720",
    "end": "1213200"
  },
  {
    "text": "customize",
    "start": "1213200",
    "end": "1214080"
  },
  {
    "text": "the sample collection process as well as",
    "start": "1214080",
    "end": "1215919"
  },
  {
    "text": "establish for example multi-agent",
    "start": "1215919",
    "end": "1218880"
  },
  {
    "text": "communication channels that are",
    "start": "1218880",
    "end": "1220559"
  },
  {
    "text": "differentiable and also",
    "start": "1220559",
    "end": "1222960"
  },
  {
    "text": "define what exactly your model needs to",
    "start": "1222960",
    "end": "1226240"
  },
  {
    "text": "see",
    "start": "1226240",
    "end": "1226640"
  },
  {
    "text": "in the trajectories that you that you",
    "start": "1226640",
    "end": "1228480"
  },
  {
    "text": "collect from the environment",
    "start": "1228480",
    "end": "1231440"
  },
  {
    "text": "and lastly thank you so much for",
    "start": "1233600",
    "end": "1234799"
  },
  {
    "text": "listening again here's the documentation",
    "start": "1234799",
    "end": "1236320"
  },
  {
    "text": "link",
    "start": "1236320",
    "end": "1236960"
  },
  {
    "text": "uh to our uh ray and our lip",
    "start": "1236960",
    "end": "1238960"
  },
  {
    "text": "documentation",
    "start": "1238960",
    "end": "1240159"
  },
  {
    "text": "uh here's a simple pip command to get",
    "start": "1240159",
    "end": "1242480"
  },
  {
    "text": "our lip installed",
    "start": "1242480",
    "end": "1244000"
  },
  {
    "text": "please join our slack channel it's a",
    "start": "1244000",
    "end": "1246320"
  },
  {
    "text": "great place to",
    "start": "1246320",
    "end": "1247360"
  },
  {
    "text": "to learn and to help others uh to ask",
    "start": "1247360",
    "end": "1250159"
  },
  {
    "text": "questions",
    "start": "1250159",
    "end": "1250960"
  },
  {
    "text": "uh and to get help from us in case you",
    "start": "1250960",
    "end": "1253440"
  },
  {
    "text": "run into problems using ray or our lip",
    "start": "1253440",
    "end": "1256159"
  },
  {
    "text": "and lastly we are hiring if you're",
    "start": "1256159",
    "end": "1257679"
  },
  {
    "text": "interested in working for any scale",
    "start": "1257679",
    "end": "1258960"
  },
  {
    "text": "please send us your resume",
    "start": "1258960",
    "end": "1260320"
  },
  {
    "text": "uh you can link us you can link me on",
    "start": "1260320",
    "end": "1262000"
  },
  {
    "text": "linkedin or send me an email",
    "start": "1262000",
    "end": "1264480"
  },
  {
    "text": "again thanks so much",
    "start": "1264480",
    "end": "1267840"
  }
]
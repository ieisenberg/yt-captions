[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "[Music]",
    "start": "150",
    "end": "14799"
  },
  {
    "text": "hi every resume 2021",
    "start": "14799",
    "end": "16480"
  },
  {
    "text": "thank you for tuning in my talk reserve",
    "start": "16480",
    "end": "18880"
  },
  {
    "text": "and the pattern of machine learning",
    "start": "18880",
    "end": "20400"
  },
  {
    "text": "models in production",
    "start": "20400",
    "end": "21840"
  },
  {
    "text": "my name is diamond mo and let's get into",
    "start": "21840",
    "end": "23760"
  },
  {
    "text": "it well who am i",
    "start": "23760",
    "end": "25599"
  },
  {
    "start": "24000",
    "end": "89000"
  },
  {
    "text": "currently i'm building a python library",
    "start": "25599",
    "end": "27359"
  },
  {
    "text": "called reserve at any scale",
    "start": "27359",
    "end": "29199"
  },
  {
    "text": "and previously i worked on prediction",
    "start": "29199",
    "end": "30960"
  },
  {
    "text": "serving system at uc berkeley rice map",
    "start": "30960",
    "end": "33680"
  },
  {
    "text": "in those places i'm constantly talking",
    "start": "33680",
    "end": "36079"
  },
  {
    "text": "to machine learning practitioner to",
    "start": "36079",
    "end": "37840"
  },
  {
    "text": "learn and improve the tooling around",
    "start": "37840",
    "end": "39600"
  },
  {
    "text": "machine learning production",
    "start": "39600",
    "end": "41920"
  },
  {
    "text": "so this talk is about reserve a scalable",
    "start": "41920",
    "end": "44640"
  },
  {
    "text": "and programmable serving framework built",
    "start": "44640",
    "end": "46559"
  },
  {
    "text": "on top of ray",
    "start": "46559",
    "end": "47840"
  },
  {
    "text": "you have probably heard about it in the",
    "start": "47840",
    "end": "49600"
  },
  {
    "text": "keynote or seen in a demo",
    "start": "49600",
    "end": "51680"
  },
  {
    "text": "it is the serving framework of choice",
    "start": "51680",
    "end": "54000"
  },
  {
    "text": "for deploying microservices and machine",
    "start": "54000",
    "end": "56000"
  },
  {
    "text": "learning models on top of grade",
    "start": "56000",
    "end": "58079"
  },
  {
    "text": "and most importantly you leverage risk",
    "start": "58079",
    "end": "60320"
  },
  {
    "text": "scalability to help you scale your",
    "start": "60320",
    "end": "62239"
  },
  {
    "text": "service",
    "start": "62239",
    "end": "62879"
  },
  {
    "text": "in production this talk will be",
    "start": "62879",
    "end": "65600"
  },
  {
    "text": "structured as follows",
    "start": "65600",
    "end": "67200"
  },
  {
    "text": "i will first talk about research what",
    "start": "67200",
    "end": "69119"
  },
  {
    "text": "does it do and cover sign examples i'll",
    "start": "69119",
    "end": "72080"
  },
  {
    "text": "then discuss some common patterns of",
    "start": "72080",
    "end": "73920"
  },
  {
    "text": "machine learning in production",
    "start": "73920",
    "end": "75680"
  },
  {
    "text": "why are they useful and how are they",
    "start": "75680",
    "end": "77680"
  },
  {
    "text": "implemented",
    "start": "77680",
    "end": "79040"
  },
  {
    "text": "and then how research can help and",
    "start": "79040",
    "end": "82159"
  },
  {
    "text": "lastly i'll make the case",
    "start": "82159",
    "end": "83840"
  },
  {
    "text": "that why should ray serve to your go-to",
    "start": "83840",
    "end": "86080"
  },
  {
    "text": "framework for deploying machine learning",
    "start": "86080",
    "end": "88320"
  },
  {
    "text": "models",
    "start": "88320",
    "end": "90159"
  },
  {
    "start": "89000",
    "end": "130000"
  },
  {
    "text": "let's start with a simple example of",
    "start": "90159",
    "end": "93200"
  },
  {
    "text": "reserve as a web framework",
    "start": "93200",
    "end": "95600"
  },
  {
    "text": "to deploy a simple service on top of ray",
    "start": "95600",
    "end": "98640"
  },
  {
    "text": "you'll need a few lines of code here we",
    "start": "98640",
    "end": "101280"
  },
  {
    "text": "define a simple function",
    "start": "101280",
    "end": "102880"
  },
  {
    "text": "that responds to web requests and wrap",
    "start": "102880",
    "end": "105520"
  },
  {
    "text": "it",
    "start": "105520",
    "end": "105920"
  },
  {
    "text": "in a serve deployment decorator",
    "start": "105920",
    "end": "109439"
  },
  {
    "text": "with the serve the deployment decorator",
    "start": "109439",
    "end": "111520"
  },
  {
    "text": "we are pushing the hello",
    "start": "111520",
    "end": "113200"
  },
  {
    "text": "function to ray and allow you to be",
    "start": "113200",
    "end": "115759"
  },
  {
    "text": "queried",
    "start": "115759",
    "end": "116399"
  },
  {
    "text": "and run in real time so after you call",
    "start": "116399",
    "end": "120040"
  },
  {
    "text": "hello.deploy",
    "start": "120040",
    "end": "121360"
  },
  {
    "text": "the endpoint can be created directly and",
    "start": "121360",
    "end": "124399"
  },
  {
    "text": "reserve",
    "start": "124399",
    "end": "125360"
  },
  {
    "text": "make it very simple to deploy web",
    "start": "125360",
    "end": "127759"
  },
  {
    "text": "services",
    "start": "127759",
    "end": "128560"
  },
  {
    "text": "on top of ray a reserve is much more",
    "start": "128560",
    "end": "132239"
  },
  {
    "start": "130000",
    "end": "187000"
  },
  {
    "text": "than that",
    "start": "132239",
    "end": "133040"
  },
  {
    "text": "will allow stateful model inference to",
    "start": "133040",
    "end": "135840"
  },
  {
    "text": "be deployed as microservices on top of",
    "start": "135840",
    "end": "138239"
  },
  {
    "text": "red",
    "start": "138239",
    "end": "139520"
  },
  {
    "text": "here are some features tailored to",
    "start": "139520",
    "end": "141360"
  },
  {
    "text": "machine learning serving use case",
    "start": "141360",
    "end": "143520"
  },
  {
    "text": "you can think of reserve as a web",
    "start": "143520",
    "end": "145200"
  },
  {
    "text": "framework but specialized",
    "start": "145200",
    "end": "147040"
  },
  {
    "text": "for machine learning model serving we",
    "start": "147040",
    "end": "149360"
  },
  {
    "text": "have built-in feature",
    "start": "149360",
    "end": "150959"
  },
  {
    "text": "that will massively improve your service",
    "start": "150959",
    "end": "153360"
  },
  {
    "text": "throughput",
    "start": "153360",
    "end": "154160"
  },
  {
    "text": "and deliver cost saving with features",
    "start": "154160",
    "end": "156560"
  },
  {
    "text": "like supporting gpus",
    "start": "156560",
    "end": "158319"
  },
  {
    "text": "batching scaling out and model",
    "start": "158319",
    "end": "160239"
  },
  {
    "text": "composition",
    "start": "160239",
    "end": "162400"
  },
  {
    "text": "so where does research fit in the ray",
    "start": "162400",
    "end": "164400"
  },
  {
    "text": "ecosystem",
    "start": "164400",
    "end": "165680"
  },
  {
    "text": "while ray provides a backbone and",
    "start": "165680",
    "end": "167760"
  },
  {
    "text": "primitives for distributed computing",
    "start": "167760",
    "end": "170160"
  },
  {
    "text": "there are comprehensive setup",
    "start": "170160",
    "end": "171680"
  },
  {
    "text": "distributed library built on top",
    "start": "171680",
    "end": "174319"
  },
  {
    "text": "raised serve is one of the most outlined",
    "start": "174319",
    "end": "176959"
  },
  {
    "text": "the native library",
    "start": "176959",
    "end": "178239"
  },
  {
    "text": "built on top of ray to provide you with",
    "start": "178239",
    "end": "181200"
  },
  {
    "text": "the capability to deploy",
    "start": "181200",
    "end": "182720"
  },
  {
    "text": "machine learning application out of the",
    "start": "182720",
    "end": "185440"
  },
  {
    "text": "box",
    "start": "185440",
    "end": "187760"
  },
  {
    "start": "187000",
    "end": "270000"
  },
  {
    "text": "so that's where racer fitting the ray",
    "start": "188000",
    "end": "190400"
  },
  {
    "text": "ecosystem",
    "start": "190400",
    "end": "191920"
  },
  {
    "text": "but what about the machine learning",
    "start": "191920",
    "end": "193840"
  },
  {
    "text": "serving space",
    "start": "193840",
    "end": "195519"
  },
  {
    "text": "so when you first start to deploy a",
    "start": "195519",
    "end": "197599"
  },
  {
    "text": "machine learning service",
    "start": "197599",
    "end": "199040"
  },
  {
    "text": "people typically start with a simple",
    "start": "199040",
    "end": "200959"
  },
  {
    "text": "system out of the box",
    "start": "200959",
    "end": "203680"
  },
  {
    "text": "for example the python web framework or",
    "start": "203680",
    "end": "206159"
  },
  {
    "text": "serverless frameworks",
    "start": "206159",
    "end": "207840"
  },
  {
    "text": "however even though they can deliver a",
    "start": "207840",
    "end": "209920"
  },
  {
    "text": "single prediction well",
    "start": "209920",
    "end": "211200"
  },
  {
    "text": "and work well in proof of concept or",
    "start": "211200",
    "end": "213440"
  },
  {
    "text": "demos they cannot achieve",
    "start": "213440",
    "end": "215200"
  },
  {
    "text": "high performance and often scouting up",
    "start": "215200",
    "end": "218159"
  },
  {
    "text": "is very costly",
    "start": "218159",
    "end": "220400"
  },
  {
    "text": "then the team typically transitions to",
    "start": "220400",
    "end": "222080"
  },
  {
    "text": "some sort of custom tooling gluing",
    "start": "222080",
    "end": "224000"
  },
  {
    "text": "together several tools",
    "start": "224000",
    "end": "225680"
  },
  {
    "text": "trying to bring them some sort of",
    "start": "225680",
    "end": "227920"
  },
  {
    "text": "existing system",
    "start": "227920",
    "end": "229120"
  },
  {
    "text": "together to deliver some production",
    "start": "229120",
    "end": "231440"
  },
  {
    "text": "readiness",
    "start": "231440",
    "end": "232720"
  },
  {
    "text": "however these custom tunings are",
    "start": "232720",
    "end": "234720"
  },
  {
    "text": "typically hard to",
    "start": "234720",
    "end": "236159"
  },
  {
    "text": "deploy develop and manage",
    "start": "236159",
    "end": "240080"
  },
  {
    "text": "lastly there is a group of specialized",
    "start": "240080",
    "end": "242560"
  },
  {
    "text": "system for deploy and manage machine",
    "start": "242560",
    "end": "244400"
  },
  {
    "text": "learning models in production",
    "start": "244400",
    "end": "246239"
  },
  {
    "text": "you may recognize the ofc system as",
    "start": "246239",
    "end": "248400"
  },
  {
    "text": "shown here",
    "start": "248400",
    "end": "249360"
  },
  {
    "text": "while these systems are great at",
    "start": "249360",
    "end": "250799"
  },
  {
    "text": "managing and serving machine learning",
    "start": "250799",
    "end": "252400"
  },
  {
    "text": "models",
    "start": "252400",
    "end": "253120"
  },
  {
    "text": "there are sometimes loss of flexibility",
    "start": "253120",
    "end": "255760"
  },
  {
    "text": "you had",
    "start": "255760",
    "end": "256320"
  },
  {
    "text": "with web framework and often times",
    "start": "256320",
    "end": "258959"
  },
  {
    "text": "there's a high",
    "start": "258959",
    "end": "259919"
  },
  {
    "text": "learning curve with reserve",
    "start": "259919",
    "end": "263600"
  },
  {
    "text": "we aspire to be both easy to use easy to",
    "start": "263600",
    "end": "266240"
  },
  {
    "text": "deploy",
    "start": "266240",
    "end": "267199"
  },
  {
    "text": "as well as ready for production",
    "start": "267199",
    "end": "270800"
  },
  {
    "start": "270000",
    "end": "380000"
  },
  {
    "text": "well but what really makes reserve",
    "start": "270800",
    "end": "272800"
  },
  {
    "text": "different",
    "start": "272800",
    "end": "274880"
  },
  {
    "text": "i would have seen that there's so many",
    "start": "274880",
    "end": "276639"
  },
  {
    "text": "tools for training models and serving",
    "start": "276639",
    "end": "278639"
  },
  {
    "text": "just",
    "start": "278639",
    "end": "279040"
  },
  {
    "text": "one single models these tools help you",
    "start": "279040",
    "end": "281919"
  },
  {
    "text": "run and deploy",
    "start": "281919",
    "end": "282800"
  },
  {
    "text": "one model really well but when you",
    "start": "282800",
    "end": "284960"
  },
  {
    "text": "actually want to do that in real life",
    "start": "284960",
    "end": "286720"
  },
  {
    "text": "it's not that simple right sometimes",
    "start": "286720",
    "end": "289199"
  },
  {
    "text": "getting beyond one copy as a model just",
    "start": "289199",
    "end": "291280"
  },
  {
    "text": "isn't supported",
    "start": "291280",
    "end": "292560"
  },
  {
    "text": "sometimes you as a data scientist or ml",
    "start": "292560",
    "end": "294880"
  },
  {
    "text": "engineer have to work through complex",
    "start": "294880",
    "end": "296639"
  },
  {
    "text": "yaml configuration files",
    "start": "296639",
    "end": "298320"
  },
  {
    "text": "and learn custom tuning and become",
    "start": "298320",
    "end": "300160"
  },
  {
    "text": "kubernetes experts",
    "start": "300160",
    "end": "301919"
  },
  {
    "text": "sometimes you had the scalability of",
    "start": "301919",
    "end": "303840"
  },
  {
    "text": "performance issues very early on",
    "start": "303840",
    "end": "306160"
  },
  {
    "text": "and you even if all these worked out",
    "start": "306160",
    "end": "308400"
  },
  {
    "text": "well many of the tools are very costly",
    "start": "308400",
    "end": "310880"
  },
  {
    "text": "and often lead to underutilizing",
    "start": "310880",
    "end": "312560"
  },
  {
    "text": "resource",
    "start": "312560",
    "end": "313840"
  },
  {
    "text": "we need to recognize the reality that",
    "start": "313840",
    "end": "315759"
  },
  {
    "text": "there's always going to be new machine",
    "start": "315759",
    "end": "317440"
  },
  {
    "text": "learning model trained and deployed over",
    "start": "317440",
    "end": "319440"
  },
  {
    "text": "time",
    "start": "319440",
    "end": "320160"
  },
  {
    "text": "and there's always going to be the need",
    "start": "320160",
    "end": "322160"
  },
  {
    "text": "for production use case to scale",
    "start": "322160",
    "end": "324000"
  },
  {
    "text": "out a single model and additionally for",
    "start": "324000",
    "end": "326720"
  },
  {
    "text": "many complex real-world use cases",
    "start": "326720",
    "end": "329120"
  },
  {
    "text": "you need to compose multiple models",
    "start": "329120",
    "end": "331039"
  },
  {
    "text": "together",
    "start": "331039",
    "end": "332160"
  },
  {
    "text": "machine learning models don't get",
    "start": "332160",
    "end": "333840"
  },
  {
    "text": "deployed alone they rarely exist in",
    "start": "333840",
    "end": "336840"
  },
  {
    "text": "isolation in fact",
    "start": "336840",
    "end": "339120"
  },
  {
    "text": "we interview many practitioners over the",
    "start": "339120",
    "end": "341360"
  },
  {
    "text": "past few years",
    "start": "341360",
    "end": "342720"
  },
  {
    "text": "and we uncover there are four common",
    "start": "342720",
    "end": "345120"
  },
  {
    "text": "patterns of how machine learning models",
    "start": "345120",
    "end": "347039"
  },
  {
    "text": "are deployed in production",
    "start": "347039",
    "end": "349759"
  },
  {
    "text": "these patterns are by no means",
    "start": "349759",
    "end": "351520"
  },
  {
    "text": "comprehensive but they do represent a",
    "start": "351520",
    "end": "354000"
  },
  {
    "text": "significant portion",
    "start": "354000",
    "end": "355520"
  },
  {
    "text": "of real machine learning applications",
    "start": "355520",
    "end": "358400"
  },
  {
    "text": "there are pipeline",
    "start": "358400",
    "end": "359680"
  },
  {
    "text": "ensemble business logic and online",
    "start": "359680",
    "end": "362080"
  },
  {
    "text": "learning",
    "start": "362080",
    "end": "363120"
  },
  {
    "text": "these are core pieces of common ammo",
    "start": "363120",
    "end": "365840"
  },
  {
    "text": "apps in",
    "start": "365840",
    "end": "366560"
  },
  {
    "text": "production today we'll go over them one",
    "start": "366560",
    "end": "369199"
  },
  {
    "text": "by one",
    "start": "369199",
    "end": "370000"
  },
  {
    "text": "show you why do they exist how are they",
    "start": "370000",
    "end": "372560"
  },
  {
    "text": "used",
    "start": "372560",
    "end": "373120"
  },
  {
    "text": "how the existing tool are used to",
    "start": "373120",
    "end": "376479"
  },
  {
    "text": "implement it",
    "start": "376479",
    "end": "377520"
  },
  {
    "text": "and how can we serve solve these",
    "start": "377520",
    "end": "379360"
  },
  {
    "text": "challenges",
    "start": "379360",
    "end": "380960"
  },
  {
    "start": "380000",
    "end": "511000"
  },
  {
    "text": "let's start with pipeline let's take a",
    "start": "380960",
    "end": "383280"
  },
  {
    "text": "look at the very simple pipeline and",
    "start": "383280",
    "end": "385360"
  },
  {
    "text": "these are typical",
    "start": "385360",
    "end": "386800"
  },
  {
    "text": "showing here is a computer vision",
    "start": "386800",
    "end": "388400"
  },
  {
    "text": "pipeline where we use multiple deep",
    "start": "388400",
    "end": "390400"
  },
  {
    "text": "learning models to caption the objects",
    "start": "390400",
    "end": "392479"
  },
  {
    "text": "in the picture",
    "start": "392479",
    "end": "393680"
  },
  {
    "text": "starting with a raw image you will need",
    "start": "393680",
    "end": "395919"
  },
  {
    "text": "to go through some pre-processing like",
    "start": "395919",
    "end": "397840"
  },
  {
    "text": "image decoding augmentation and clipping",
    "start": "397840",
    "end": "400800"
  },
  {
    "text": "and then is passed into deep learning",
    "start": "400800",
    "end": "403520"
  },
  {
    "text": "detector or classifier in here the model",
    "start": "403520",
    "end": "406479"
  },
  {
    "text": "identified",
    "start": "406479",
    "end": "407360"
  },
  {
    "text": "the bounding box in the category is a",
    "start": "407360",
    "end": "409680"
  },
  {
    "text": "catch",
    "start": "409680",
    "end": "410720"
  },
  {
    "text": "once we detected some object the image",
    "start": "410720",
    "end": "413440"
  },
  {
    "text": "is passed into a keypoint detection",
    "start": "413440",
    "end": "415599"
  },
  {
    "text": "model to identify the posture of the",
    "start": "415599",
    "end": "417599"
  },
  {
    "text": "object",
    "start": "417599",
    "end": "418560"
  },
  {
    "text": "so the model identify key points like",
    "start": "418560",
    "end": "420639"
  },
  {
    "text": "hand neck or the head",
    "start": "420639",
    "end": "422800"
  },
  {
    "text": "and lastly we run through visualization",
    "start": "422800",
    "end": "424800"
  },
  {
    "text": "with all the feature",
    "start": "424800",
    "end": "426479"
  },
  {
    "text": "to generate a category of what this",
    "start": "426479",
    "end": "428800"
  },
  {
    "text": "picture show",
    "start": "428800",
    "end": "429840"
  },
  {
    "text": "a standing cat while this example might",
    "start": "429840",
    "end": "433440"
  },
  {
    "text": "seem that they contrived",
    "start": "433440",
    "end": "434880"
  },
  {
    "text": "a typical pipeline rarely consists of",
    "start": "434880",
    "end": "437039"
  },
  {
    "text": "just one model",
    "start": "437039",
    "end": "438479"
  },
  {
    "text": "to tackle real life issue machine",
    "start": "438479",
    "end": "440639"
  },
  {
    "text": "learning applications use",
    "start": "440639",
    "end": "442000"
  },
  {
    "text": "many different models to perform even a",
    "start": "442000",
    "end": "444479"
  },
  {
    "text": "simple task",
    "start": "444479",
    "end": "446400"
  },
  {
    "text": "pipeline in general breaks specific",
    "start": "446400",
    "end": "448479"
  },
  {
    "text": "tasks into many steps",
    "start": "448479",
    "end": "450240"
  },
  {
    "text": "each step is conquered by a machine",
    "start": "450240",
    "end": "451919"
  },
  {
    "text": "learning algorithm or some procedure",
    "start": "451919",
    "end": "454160"
  },
  {
    "text": "you might be familiar with psychoneuron",
    "start": "454160",
    "end": "455919"
  },
  {
    "text": "pipeline construct where you can",
    "start": "455919",
    "end": "458000"
  },
  {
    "text": "combine multiple models and processing",
    "start": "458000",
    "end": "460479"
  },
  {
    "text": "objects together and call it the fixed",
    "start": "460479",
    "end": "462400"
  },
  {
    "text": "function",
    "start": "462400",
    "end": "463120"
  },
  {
    "text": "as a whole there are also common",
    "start": "463120",
    "end": "465520"
  },
  {
    "text": "pipeline setup in recommendation system",
    "start": "465520",
    "end": "467599"
  },
  {
    "text": "where a typical recommendation",
    "start": "467599",
    "end": "469199"
  },
  {
    "text": "like item recommendation amazon or movie",
    "start": "469199",
    "end": "471520"
  },
  {
    "text": "recommendation in netflix",
    "start": "471520",
    "end": "473680"
  },
  {
    "text": "goes through multiple stages like",
    "start": "473680",
    "end": "475520"
  },
  {
    "text": "embedding luca feature interaction",
    "start": "475520",
    "end": "477599"
  },
  {
    "text": "nearest neighbor models and ranking",
    "start": "477599",
    "end": "479199"
  },
  {
    "text": "models additionally there are very",
    "start": "479199",
    "end": "481440"
  },
  {
    "text": "common use cases where some mega machine",
    "start": "481440",
    "end": "483440"
  },
  {
    "text": "learning models",
    "start": "483440",
    "end": "484479"
  },
  {
    "text": "takes care of the common pre-processing",
    "start": "484479",
    "end": "486319"
  },
  {
    "text": "for text or images",
    "start": "486319",
    "end": "488000"
  },
  {
    "text": "and then these well these mega machine",
    "start": "488000",
    "end": "490560"
  },
  {
    "text": "learning models can be studied that are",
    "start": "490560",
    "end": "492160"
  },
  {
    "text": "featurizer trend using millions of",
    "start": "492160",
    "end": "494000"
  },
  {
    "text": "dollars what's the compute time",
    "start": "494000",
    "end": "495680"
  },
  {
    "text": "maybe like gpt3 or giant image models",
    "start": "495680",
    "end": "498879"
  },
  {
    "text": "and then different team or pipeline will",
    "start": "498879",
    "end": "501280"
  },
  {
    "text": "utilize the same model",
    "start": "501280",
    "end": "503280"
  },
  {
    "text": "for downstream tasks with lighter or",
    "start": "503280",
    "end": "505280"
  },
  {
    "text": "cheaper like",
    "start": "505280",
    "end": "506800"
  },
  {
    "text": "models like decision tree or some sort",
    "start": "506800",
    "end": "508639"
  },
  {
    "text": "of boosting model for business specific",
    "start": "508639",
    "end": "510479"
  },
  {
    "text": "tasks",
    "start": "510479",
    "end": "512399"
  },
  {
    "start": "511000",
    "end": "748000"
  },
  {
    "text": "one consistent theme of today's talk",
    "start": "512399",
    "end": "514880"
  },
  {
    "text": "will be thinking about",
    "start": "514880",
    "end": "515839"
  },
  {
    "text": "how can these be implemented in general",
    "start": "515839",
    "end": "518800"
  },
  {
    "text": "there are two approaches",
    "start": "518800",
    "end": "520080"
  },
  {
    "text": "you can either wrap your model in the",
    "start": "520080",
    "end": "523039"
  },
  {
    "text": "orchestration in the web server",
    "start": "523039",
    "end": "524880"
  },
  {
    "text": "for example in the left code block here",
    "start": "524880",
    "end": "527600"
  },
  {
    "text": "models were loaded and ran",
    "start": "527600",
    "end": "529279"
  },
  {
    "text": "in a for loop during the web handling",
    "start": "529279",
    "end": "531440"
  },
  {
    "text": "path whenever a request came in we",
    "start": "531440",
    "end": "534000"
  },
  {
    "text": "load the model that can be cached of",
    "start": "534000",
    "end": "536240"
  },
  {
    "text": "course and runs through the",
    "start": "536240",
    "end": "537680"
  },
  {
    "text": "pipeline this is simple and easy to",
    "start": "537680",
    "end": "540399"
  },
  {
    "text": "implement",
    "start": "540399",
    "end": "541279"
  },
  {
    "text": "however a major flaw is that this is",
    "start": "541279",
    "end": "544080"
  },
  {
    "text": "hard to scale and not going to be",
    "start": "544080",
    "end": "546000"
  },
  {
    "text": "performant because each request will",
    "start": "546000",
    "end": "548640"
  },
  {
    "text": "handle sequentially",
    "start": "548640",
    "end": "550640"
  },
  {
    "text": "on the other hand you can use",
    "start": "550640",
    "end": "552000"
  },
  {
    "text": "specialized systems or microservices",
    "start": "552000",
    "end": "554399"
  },
  {
    "text": "essentially to build and deploy one",
    "start": "554399",
    "end": "556560"
  },
  {
    "text": "microservice per model",
    "start": "556560",
    "end": "558480"
  },
  {
    "text": "this microservice can be native ml",
    "start": "558480",
    "end": "560720"
  },
  {
    "text": "platform",
    "start": "560720",
    "end": "561680"
  },
  {
    "text": "kubeflow or even hosted services like",
    "start": "561680",
    "end": "563839"
  },
  {
    "text": "adobe stage maker",
    "start": "563839",
    "end": "565600"
  },
  {
    "text": "however as a number of model growths the",
    "start": "565600",
    "end": "567760"
  },
  {
    "text": "complexity drastically increased",
    "start": "567760",
    "end": "570320"
  },
  {
    "text": "the operation cost will skyrocket before",
    "start": "570320",
    "end": "573040"
  },
  {
    "text": "reserve",
    "start": "573040",
    "end": "574399"
  },
  {
    "text": "which the framework we're talking about",
    "start": "574399",
    "end": "576000"
  },
  {
    "text": "here you have to choose either the left",
    "start": "576000",
    "end": "578240"
  },
  {
    "text": "or right solution",
    "start": "578240",
    "end": "580399"
  },
  {
    "text": "well but how can we implement this in",
    "start": "580399",
    "end": "582160"
  },
  {
    "text": "reserve here is a pseudocode",
    "start": "582160",
    "end": "584560"
  },
  {
    "text": "in reserve you can directly call other",
    "start": "584560",
    "end": "586640"
  },
  {
    "text": "deployments within your deployments",
    "start": "586640",
    "end": "588720"
  },
  {
    "text": "and this can nest arbitrarily deep in",
    "start": "588720",
    "end": "591519"
  },
  {
    "text": "the pseudo code we have three deployment",
    "start": "591519",
    "end": "593920"
  },
  {
    "text": "featurizer and predictor are just",
    "start": "593920",
    "end": "595920"
  },
  {
    "text": "regular deployments containing the",
    "start": "595920",
    "end": "598160"
  },
  {
    "text": "models",
    "start": "598160",
    "end": "599200"
  },
  {
    "text": "the orchestrator receives the web input",
    "start": "599200",
    "end": "602000"
  },
  {
    "text": "pass it to the featurizer via",
    "start": "602000",
    "end": "603839"
  },
  {
    "text": "feature as a handle and then pass the",
    "start": "603839",
    "end": "606160"
  },
  {
    "text": "featurize",
    "start": "606160",
    "end": "607040"
  },
  {
    "text": "feature to the projector the interface",
    "start": "607040",
    "end": "610240"
  },
  {
    "text": "is just python",
    "start": "610240",
    "end": "611600"
  },
  {
    "text": "you don't need to know any new framework",
    "start": "611600",
    "end": "613360"
  },
  {
    "text": "you don't need to know any new dsl",
    "start": "613360",
    "end": "615360"
  },
  {
    "text": "as one of my colleagues will pop put it",
    "start": "615360",
    "end": "617440"
  },
  {
    "text": "you can just write your for loop however",
    "start": "617440",
    "end": "619680"
  },
  {
    "text": "you want",
    "start": "619680",
    "end": "621600"
  },
  {
    "text": "reserve achieves this with a mechanism",
    "start": "621600",
    "end": "623600"
  },
  {
    "text": "called serve handle",
    "start": "623600",
    "end": "624800"
  },
  {
    "text": "serve handle gives you the flexibility",
    "start": "624800",
    "end": "626800"
  },
  {
    "text": "similar to embedding everything in the",
    "start": "626800",
    "end": "628480"
  },
  {
    "text": "web server",
    "start": "628480",
    "end": "629360"
  },
  {
    "text": "but without the downside serve handle",
    "start": "629360",
    "end": "631839"
  },
  {
    "text": "allow you to directly call other",
    "start": "631839",
    "end": "633279"
  },
  {
    "text": "deployments that lives in",
    "start": "633279",
    "end": "634880"
  },
  {
    "text": "other processes or other nodes this",
    "start": "634880",
    "end": "637440"
  },
  {
    "text": "allows you to scale out each deployment",
    "start": "637440",
    "end": "639360"
  },
  {
    "text": "individually",
    "start": "639360",
    "end": "640240"
  },
  {
    "text": "and the handle costs will be low",
    "start": "640240",
    "end": "642480"
  },
  {
    "text": "balanced between the replicas",
    "start": "642480",
    "end": "645040"
  },
  {
    "text": "to get a deeper understanding of how",
    "start": "645040",
    "end": "646640"
  },
  {
    "text": "this works let's take a quick detour",
    "start": "646640",
    "end": "648720"
  },
  {
    "text": "into the reserve architecture",
    "start": "648720",
    "end": "651600"
  },
  {
    "text": "in the beginning you just have your rig",
    "start": "651600",
    "end": "653360"
  },
  {
    "text": "cluster let it be",
    "start": "653360",
    "end": "654720"
  },
  {
    "text": "your local machine the cloud provider",
    "start": "654720",
    "end": "656800"
  },
  {
    "text": "local in process cluster kubernetes or",
    "start": "656800",
    "end": "658959"
  },
  {
    "text": "even on any scale",
    "start": "658959",
    "end": "660399"
  },
  {
    "text": "will represent these ray nodes with",
    "start": "660399",
    "end": "663120"
  },
  {
    "text": "these boxes on the right",
    "start": "663120",
    "end": "665680"
  },
  {
    "text": "when you first call read serve that",
    "start": "665680",
    "end": "667440"
  },
  {
    "text": "start reserve deploy two",
    "start": "667440",
    "end": "669839"
  },
  {
    "text": "tolerant reactor into the app into the",
    "start": "669839",
    "end": "672160"
  },
  {
    "text": "cluster",
    "start": "672160",
    "end": "672959"
  },
  {
    "text": "the controller actor is a ghostly driven",
    "start": "672959",
    "end": "675120"
  },
  {
    "text": "process and manage all",
    "start": "675120",
    "end": "676399"
  },
  {
    "text": "other adapters while the http proxy",
    "start": "676399",
    "end": "679279"
  },
  {
    "text": "handles the web request",
    "start": "679279",
    "end": "681519"
  },
  {
    "text": "then we deploy a deployment to reserve",
    "start": "681519",
    "end": "684160"
  },
  {
    "text": "the class definition is pushed to the",
    "start": "684160",
    "end": "686160"
  },
  {
    "text": "controller actor",
    "start": "686160",
    "end": "687360"
  },
  {
    "text": "and the controller after spawns the",
    "start": "687360",
    "end": "689040"
  },
  {
    "text": "model replicas",
    "start": "689040",
    "end": "690480"
  },
  {
    "text": "once the model replica is loaded the",
    "start": "690480",
    "end": "692640"
  },
  {
    "text": "http",
    "start": "692640",
    "end": "693519"
  },
  {
    "text": "proxy is able to proxy web request to",
    "start": "693519",
    "end": "696480"
  },
  {
    "text": "the replica actor",
    "start": "696480",
    "end": "698240"
  },
  {
    "text": "the controller actor performs health",
    "start": "698240",
    "end": "700240"
  },
  {
    "text": "check zero downtime upgrades",
    "start": "700240",
    "end": "702320"
  },
  {
    "text": "as well as scale up and down for the",
    "start": "702320",
    "end": "703839"
  },
  {
    "text": "model replicas",
    "start": "703839",
    "end": "705760"
  },
  {
    "text": "when the serve handle is introduced and",
    "start": "705760",
    "end": "708800"
  },
  {
    "text": "we simply have",
    "start": "708800",
    "end": "710320"
  },
  {
    "text": "when we have multiple deployments the",
    "start": "710320",
    "end": "713440"
  },
  {
    "text": "serve handle can call each other",
    "start": "713440",
    "end": "715600"
  },
  {
    "text": "you can see it in the architecture on",
    "start": "715600",
    "end": "717279"
  },
  {
    "text": "the right when the orchestrator",
    "start": "717279",
    "end": "719760"
  },
  {
    "text": "calls the featurizer with the input it's",
    "start": "719760",
    "end": "722880"
  },
  {
    "text": "just a simple python after call",
    "start": "722880",
    "end": "725200"
  },
  {
    "text": "this is now arbitrary composition and",
    "start": "725200",
    "end": "727839"
  },
  {
    "text": "with models in reserve",
    "start": "727839",
    "end": "730079"
  },
  {
    "text": "but not just composition reserve handle",
    "start": "730079",
    "end": "732560"
  },
  {
    "text": "also provides the capability of load",
    "start": "732560",
    "end": "734560"
  },
  {
    "text": "balancing among multiple replicas",
    "start": "734560",
    "end": "736959"
  },
  {
    "text": "in this way you can scale each component",
    "start": "736959",
    "end": "739200"
  },
  {
    "text": "individually",
    "start": "739200",
    "end": "740320"
  },
  {
    "text": "for example we can have a single copy of",
    "start": "740320",
    "end": "742720"
  },
  {
    "text": "the featurizer",
    "start": "742720",
    "end": "743680"
  },
  {
    "text": "that have 10 copies of predictor to",
    "start": "743680",
    "end": "745600"
  },
  {
    "text": "achieve high throughput",
    "start": "745600",
    "end": "748000"
  },
  {
    "text": "in this way research in both seamless",
    "start": "748000",
    "end": "750240"
  },
  {
    "text": "model composition",
    "start": "750240",
    "end": "751440"
  },
  {
    "text": "will have a pure python api this means",
    "start": "751440",
    "end": "754160"
  },
  {
    "text": "you don't have to write complex gamos",
    "start": "754160",
    "end": "756079"
  },
  {
    "text": "and you can express your composition",
    "start": "756079",
    "end": "757600"
  },
  {
    "text": "logic with the smallest number",
    "start": "757600",
    "end": "759600"
  },
  {
    "text": "of lines of code it also means more",
    "start": "759600",
    "end": "762240"
  },
  {
    "text": "flexible and maintainable code base",
    "start": "762240",
    "end": "764959"
  },
  {
    "text": "the opticals are high performance grpc",
    "start": "764959",
    "end": "767760"
  },
  {
    "text": "calls",
    "start": "767760",
    "end": "768399"
  },
  {
    "text": "directly between the actors we avoid",
    "start": "768399",
    "end": "771040"
  },
  {
    "text": "heavy sterilization",
    "start": "771040",
    "end": "772000"
  },
  {
    "text": "quality serialization cost to go through",
    "start": "772000",
    "end": "774800"
  },
  {
    "text": "http between the actor",
    "start": "774800",
    "end": "777600"
  },
  {
    "text": "and lastly you can easily scale your",
    "start": "777600",
    "end": "779760"
  },
  {
    "text": "bottleneck deployment with",
    "start": "779760",
    "end": "781040"
  },
  {
    "text": "one lens of code to hundreds of machines",
    "start": "781040",
    "end": "784320"
  },
  {
    "text": "this helps you improve utilization and",
    "start": "784320",
    "end": "786399"
  },
  {
    "text": "tune each step of pipeline separately",
    "start": "786399",
    "end": "789600"
  },
  {
    "text": "now let's switch gears a little bit in",
    "start": "789600",
    "end": "791519"
  },
  {
    "text": "many cases pipeline is a good pattern to",
    "start": "791519",
    "end": "793680"
  },
  {
    "text": "have",
    "start": "793680",
    "end": "794880"
  },
  {
    "text": "however one limitation is that often",
    "start": "794880",
    "end": "797200"
  },
  {
    "text": "times there can be many options models",
    "start": "797200",
    "end": "799360"
  },
  {
    "text": "for a given",
    "start": "799360",
    "end": "800000"
  },
  {
    "text": "downstream model this is where ensemble",
    "start": "800000",
    "end": "802480"
  },
  {
    "text": "comes in",
    "start": "802480",
    "end": "803519"
  },
  {
    "text": "an example pattern deal with cases of",
    "start": "803519",
    "end": "805839"
  },
  {
    "text": "mixing output",
    "start": "805839",
    "end": "807120"
  },
  {
    "text": "from one or more models what are the",
    "start": "807120",
    "end": "809440"
  },
  {
    "text": "potential use cases",
    "start": "809440",
    "end": "811200"
  },
  {
    "text": "i'm going to list three potential use",
    "start": "811200",
    "end": "813440"
  },
  {
    "text": "case here",
    "start": "813440",
    "end": "814399"
  },
  {
    "text": "one is for model updates as we",
    "start": "814399",
    "end": "817600"
  },
  {
    "text": "discussed before new models are",
    "start": "817600",
    "end": "819760"
  },
  {
    "text": "developed and trend over time",
    "start": "819760",
    "end": "821600"
  },
  {
    "text": "this means there are always going to be",
    "start": "821600",
    "end": "823120"
  },
  {
    "text": "new versions of modeling production",
    "start": "823120",
    "end": "825440"
  },
  {
    "text": "how do we make sure the new models are",
    "start": "825440",
    "end": "827199"
  },
  {
    "text": "valid and performant in live",
    "start": "827199",
    "end": "829279"
  },
  {
    "text": "online traffic scenario we can put some",
    "start": "829279",
    "end": "832000"
  },
  {
    "text": "portion of the traffic through it",
    "start": "832000",
    "end": "833839"
  },
  {
    "text": "this is one possible use case of model",
    "start": "833839",
    "end": "835760"
  },
  {
    "text": "and sampling when you select the output",
    "start": "835760",
    "end": "837839"
  },
  {
    "text": "from",
    "start": "837839",
    "end": "838480"
  },
  {
    "text": "knowing good model but still runs the",
    "start": "838480",
    "end": "840720"
  },
  {
    "text": "inputs through",
    "start": "840720",
    "end": "841760"
  },
  {
    "text": "the newer model and collect live output",
    "start": "841760",
    "end": "844320"
  },
  {
    "text": "to validate",
    "start": "844320",
    "end": "846160"
  },
  {
    "text": "the other use case for aggregation this",
    "start": "846160",
    "end": "848399"
  },
  {
    "text": "is one of the common definition of",
    "start": "848399",
    "end": "850000"
  },
  {
    "text": "assembling",
    "start": "850000",
    "end": "851120"
  },
  {
    "text": "if it's a regression model the output",
    "start": "851120",
    "end": "853680"
  },
  {
    "text": "from multiple models are average if it's",
    "start": "853680",
    "end": "856399"
  },
  {
    "text": "a classification model",
    "start": "856399",
    "end": "858000"
  },
  {
    "text": "the output will be a voted version of",
    "start": "858000",
    "end": "860320"
  },
  {
    "text": "the output from different models",
    "start": "860320",
    "end": "862240"
  },
  {
    "text": "for example if two models is cat one",
    "start": "862240",
    "end": "864639"
  },
  {
    "text": "model system",
    "start": "864639",
    "end": "865680"
  },
  {
    "text": "then the output aggregated will be kept",
    "start": "865680",
    "end": "868560"
  },
  {
    "text": "aggregation helps combat inaccuracy in",
    "start": "868560",
    "end": "871199"
  },
  {
    "text": "individual individual model",
    "start": "871199",
    "end": "873040"
  },
  {
    "text": "and generally makes the output more",
    "start": "873040",
    "end": "874800"
  },
  {
    "text": "accurate and safer",
    "start": "874800",
    "end": "876959"
  },
  {
    "text": "one more use case for exampleing model",
    "start": "876959",
    "end": "879040"
  },
  {
    "text": "is to dynamically perform",
    "start": "879040",
    "end": "880639"
  },
  {
    "text": "model selection given input attributes",
    "start": "880639",
    "end": "883279"
  },
  {
    "text": "for example if the input contains a cat",
    "start": "883279",
    "end": "885839"
  },
  {
    "text": "then we'll use model a specialized for",
    "start": "885839",
    "end": "888079"
  },
  {
    "text": "cats",
    "start": "888079",
    "end": "888880"
  },
  {
    "text": "if the input contains a dog then we'll",
    "start": "888880",
    "end": "890720"
  },
  {
    "text": "use model b specialized for dog",
    "start": "890720",
    "end": "892959"
  },
  {
    "text": "note that this dynamic selection doesn't",
    "start": "892959",
    "end": "894639"
  },
  {
    "text": "necessarily mean the pipeline itself",
    "start": "894639",
    "end": "896880"
  },
  {
    "text": "the definition needs to be static it",
    "start": "896880",
    "end": "898880"
  },
  {
    "text": "could also be selecting models giving",
    "start": "898880",
    "end": "900800"
  },
  {
    "text": "user feedback",
    "start": "900800",
    "end": "903279"
  },
  {
    "text": "implementation wise we still have the",
    "start": "903279",
    "end": "904959"
  },
  {
    "text": "same sort of issue",
    "start": "904959",
    "end": "906320"
  },
  {
    "text": "with existing system on one hand you can",
    "start": "906320",
    "end": "909120"
  },
  {
    "text": "wrap the model in the same web handler",
    "start": "909120",
    "end": "911120"
  },
  {
    "text": "and run the models through the critical",
    "start": "911120",
    "end": "912560"
  },
  {
    "text": "path of web handling",
    "start": "912560",
    "end": "914079"
  },
  {
    "text": "on the other hand you ended up having a",
    "start": "914079",
    "end": "915920"
  },
  {
    "text": "lot of micro services to manage",
    "start": "915920",
    "end": "918079"
  },
  {
    "text": "the number of micro services scaled by",
    "start": "918079",
    "end": "920240"
  },
  {
    "text": "the number of models",
    "start": "920240",
    "end": "921440"
  },
  {
    "text": "and will have the same issue as pipeline",
    "start": "921440",
    "end": "923839"
  },
  {
    "text": "choosing web server means simple but now",
    "start": "923839",
    "end": "925920"
  },
  {
    "text": "performance",
    "start": "925920",
    "end": "926720"
  },
  {
    "text": "choosing specialized microservices means",
    "start": "926720",
    "end": "929199"
  },
  {
    "text": "complexity and operational overhead",
    "start": "929199",
    "end": "932240"
  },
  {
    "text": "always reserve this kind of pattern is",
    "start": "932240",
    "end": "934959"
  },
  {
    "text": "incredibly",
    "start": "934959",
    "end": "935759"
  },
  {
    "text": "simple you can look at the raid demo",
    "start": "935759",
    "end": "937920"
  },
  {
    "text": "from",
    "start": "937920",
    "end": "939360"
  },
  {
    "text": "we summit where we perform dynamic model",
    "start": "939360",
    "end": "942320"
  },
  {
    "text": "selection",
    "start": "942320",
    "end": "943360"
  },
  {
    "text": "using reserves handle mechanism",
    "start": "943360",
    "end": "947680"
  },
  {
    "start": "947000",
    "end": "1286000"
  },
  {
    "text": "so that's pipeline and ensemble now",
    "start": "947920",
    "end": "950399"
  },
  {
    "text": "let's take a look at two",
    "start": "950399",
    "end": "951759"
  },
  {
    "text": "other common patterns were observed one",
    "start": "951759",
    "end": "954480"
  },
  {
    "text": "of them is business logic",
    "start": "954480",
    "end": "956800"
  },
  {
    "text": "by business logic we mean everything",
    "start": "956800",
    "end": "958959"
  },
  {
    "text": "that's involved in common machine",
    "start": "958959",
    "end": "960639"
  },
  {
    "text": "learning tasks",
    "start": "960639",
    "end": "961519"
  },
  {
    "text": "that's not the machine learning model",
    "start": "961519",
    "end": "963120"
  },
  {
    "text": "influence itself there are common",
    "start": "963120",
    "end": "965040"
  },
  {
    "text": "operations like database lookup for",
    "start": "965040",
    "end": "966959"
  },
  {
    "text": "relational record",
    "start": "966959",
    "end": "968240"
  },
  {
    "text": "web api calls for external services and",
    "start": "968240",
    "end": "971279"
  },
  {
    "text": "there are also emerging",
    "start": "971279",
    "end": "972720"
  },
  {
    "text": "machine learning specific logic like",
    "start": "972720",
    "end": "974880"
  },
  {
    "text": "feature storage lookup",
    "start": "974880",
    "end": "976320"
  },
  {
    "text": "for pre-computed feature vectors or even",
    "start": "976320",
    "end": "979199"
  },
  {
    "text": "just",
    "start": "979199",
    "end": "979519"
  },
  {
    "text": "inline feature transformation like data",
    "start": "979519",
    "end": "981680"
  },
  {
    "text": "validation encoding and decoding",
    "start": "981680",
    "end": "984480"
  },
  {
    "text": "productionizing machine learning will",
    "start": "984480",
    "end": "986240"
  },
  {
    "text": "always involve",
    "start": "986240",
    "end": "987600"
  },
  {
    "text": "business logic no model can be",
    "start": "987600",
    "end": "990160"
  },
  {
    "text": "standalone and server requests by",
    "start": "990160",
    "end": "991920"
  },
  {
    "text": "themselves",
    "start": "991920",
    "end": "992800"
  },
  {
    "text": "well as the meme right here said this",
    "start": "992800",
    "end": "994959"
  },
  {
    "text": "logic is everywhere",
    "start": "994959",
    "end": "997279"
  },
  {
    "text": "however there's one critical issue",
    "start": "997279",
    "end": "999199"
  },
  {
    "text": "around business logic in machine",
    "start": "999199",
    "end": "1000880"
  },
  {
    "text": "learning based application",
    "start": "1000880",
    "end": "1002639"
  },
  {
    "text": "let's take a look at the pseudocode on",
    "start": "1002639",
    "end": "1004800"
  },
  {
    "text": "the left",
    "start": "1004800",
    "end": "1006560"
  },
  {
    "text": "let's say we first load the model say",
    "start": "1006560",
    "end": "1008880"
  },
  {
    "text": "for s3 and then validate the input using",
    "start": "1008880",
    "end": "1011519"
  },
  {
    "text": "the database",
    "start": "1011519",
    "end": "1012480"
  },
  {
    "text": "and look up the sound pre-computed",
    "start": "1012480",
    "end": "1014240"
  },
  {
    "text": "feature from the feature store",
    "start": "1014240",
    "end": "1016000"
  },
  {
    "text": "and once we have completed all these",
    "start": "1016000",
    "end": "1018079"
  },
  {
    "text": "logic then the input is passed through",
    "start": "1018079",
    "end": "1020240"
  },
  {
    "text": "the ml models",
    "start": "1020240",
    "end": "1021680"
  },
  {
    "text": "can you spot the issue here while the",
    "start": "1021680",
    "end": "1024160"
  },
  {
    "text": "model",
    "start": "1024160",
    "end": "1024720"
  },
  {
    "text": "is loading up or we're looking at for",
    "start": "1024720",
    "end": "1026798"
  },
  {
    "text": "database record",
    "start": "1026799",
    "end": "1027839"
  },
  {
    "text": "or looking out for feature store these",
    "start": "1027839",
    "end": "1030240"
  },
  {
    "text": "calls are network bounded",
    "start": "1030240",
    "end": "1031918"
  },
  {
    "text": "and i o heavy however",
    "start": "1031919",
    "end": "1034959"
  },
  {
    "text": "the model inference is compute boundary",
    "start": "1034959",
    "end": "1037678"
  },
  {
    "text": "and memory hungry",
    "start": "1037679",
    "end": "1039199"
  },
  {
    "text": "this requirement of model inference and",
    "start": "1039199",
    "end": "1041839"
  },
  {
    "text": "this logic",
    "start": "1041839",
    "end": "1043038"
  },
  {
    "text": "lead to the server being both network",
    "start": "1043039",
    "end": "1045199"
  },
  {
    "text": "bounded and compute bonded",
    "start": "1045199",
    "end": "1047438"
  },
  {
    "text": "this is bad because we cannot",
    "start": "1047439",
    "end": "1049200"
  },
  {
    "text": "efficiently utilize all the resource",
    "start": "1049200",
    "end": "1051280"
  },
  {
    "text": "and scaling them will be expensive",
    "start": "1051280",
    "end": "1054720"
  },
  {
    "text": "one common alternative is to be is to",
    "start": "1054720",
    "end": "1057039"
  },
  {
    "text": "split the model",
    "start": "1057039",
    "end": "1057919"
  },
  {
    "text": "out with a into a model server or",
    "start": "1057919",
    "end": "1060799"
  },
  {
    "text": "microservices",
    "start": "1060799",
    "end": "1062080"
  },
  {
    "text": "this approach shown on the right is",
    "start": "1062080",
    "end": "1063760"
  },
  {
    "text": "often a solution to increase utilization",
    "start": "1063760",
    "end": "1066080"
  },
  {
    "text": "as compared to the web server deployment",
    "start": "1066080",
    "end": "1067919"
  },
  {
    "text": "model shown on the left",
    "start": "1067919",
    "end": "1069600"
  },
  {
    "text": "with splitting the web app is now purely",
    "start": "1069600",
    "end": "1071919"
  },
  {
    "text": "network bounded",
    "start": "1071919",
    "end": "1073120"
  },
  {
    "text": "while the model servers are compute",
    "start": "1073120",
    "end": "1074960"
  },
  {
    "text": "bonded each services can scale",
    "start": "1074960",
    "end": "1077840"
  },
  {
    "text": "separately however a common problem is",
    "start": "1077840",
    "end": "1080559"
  },
  {
    "text": "about the interface between the two",
    "start": "1080559",
    "end": "1082799"
  },
  {
    "text": "if you put too much base logic into the",
    "start": "1082799",
    "end": "1085120"
  },
  {
    "text": "model server",
    "start": "1085120",
    "end": "1086240"
  },
  {
    "text": "then the model server can again become a",
    "start": "1086240",
    "end": "1088640"
  },
  {
    "text": "mix of network-bounded and",
    "start": "1088640",
    "end": "1090080"
  },
  {
    "text": "computer-bounded calls",
    "start": "1090080",
    "end": "1091600"
  },
  {
    "text": "but if we don't do that let the model",
    "start": "1091600",
    "end": "1093600"
  },
  {
    "text": "server be pure",
    "start": "1093600",
    "end": "1095120"
  },
  {
    "text": "model servers then you have the tensor",
    "start": "1095120",
    "end": "1097679"
  },
  {
    "text": "intensity r1",
    "start": "1097679",
    "end": "1098960"
  },
  {
    "text": "this is a generally defined to describe",
    "start": "1098960",
    "end": "1100640"
  },
  {
    "text": "this kind of interface problem",
    "start": "1100640",
    "end": "1102080"
  },
  {
    "text": "the input types of model server are",
    "start": "1102080",
    "end": "1103760"
  },
  {
    "text": "typically very constrained to just",
    "start": "1103760",
    "end": "1105760"
  },
  {
    "text": "tensor",
    "start": "1105760",
    "end": "1106720"
  },
  {
    "text": "or some other forms let's make it harder",
    "start": "1106720",
    "end": "1109200"
  },
  {
    "text": "to keep the pre-processing",
    "start": "1109200",
    "end": "1110799"
  },
  {
    "text": "post-processing and business logic",
    "start": "1110799",
    "end": "1113039"
  },
  {
    "text": "in sync with the model itself and it",
    "start": "1113039",
    "end": "1115760"
  },
  {
    "text": "becomes hard to reason about the",
    "start": "1115760",
    "end": "1117600"
  },
  {
    "text": "interaction between",
    "start": "1117600",
    "end": "1119360"
  },
  {
    "text": "processing logic and the model itself",
    "start": "1119360",
    "end": "1122000"
  },
  {
    "text": "because",
    "start": "1122000",
    "end": "1122640"
  },
  {
    "text": "doing training the processing logic and",
    "start": "1122640",
    "end": "1125039"
  },
  {
    "text": "models are very much",
    "start": "1125039",
    "end": "1126480"
  },
  {
    "text": "tightly coupled by in serving time in",
    "start": "1126480",
    "end": "1129120"
  },
  {
    "text": "this architecture",
    "start": "1129120",
    "end": "1130400"
  },
  {
    "text": "they have to be split across two server",
    "start": "1130400",
    "end": "1133360"
  },
  {
    "text": "and two implementation",
    "start": "1133360",
    "end": "1135120"
  },
  {
    "text": "again we see the current solution have",
    "start": "1135120",
    "end": "1137280"
  },
  {
    "text": "to choose either",
    "start": "1137280",
    "end": "1138240"
  },
  {
    "text": "left or right but with reserve",
    "start": "1138240",
    "end": "1142160"
  },
  {
    "text": "you just need some simple changes to the",
    "start": "1142160",
    "end": "1144320"
  },
  {
    "text": "old web server code",
    "start": "1144320",
    "end": "1146160"
  },
  {
    "text": "instead of loading the model directly",
    "start": "1146160",
    "end": "1147919"
  },
  {
    "text": "you can retrieve a serve handle that",
    "start": "1147919",
    "end": "1150000"
  },
  {
    "text": "wraps the model and offload the",
    "start": "1150000",
    "end": "1152000"
  },
  {
    "text": "computation to another deployment",
    "start": "1152000",
    "end": "1154640"
  },
  {
    "text": "all the data types preserved are",
    "start": "1154640",
    "end": "1156880"
  },
  {
    "text": "preserved and there's no need to write",
    "start": "1156880",
    "end": "1158880"
  },
  {
    "text": "tension in tension or out api calls",
    "start": "1158880",
    "end": "1161440"
  },
  {
    "text": "you can just pass in regular python",
    "start": "1161440",
    "end": "1163679"
  },
  {
    "text": "types and additionally the model",
    "start": "1163679",
    "end": "1165840"
  },
  {
    "text": "deployment class can stay",
    "start": "1165840",
    "end": "1167600"
  },
  {
    "text": "even in the same file and deploy",
    "start": "1167600",
    "end": "1169679"
  },
  {
    "text": "together with a prediction handler",
    "start": "1169679",
    "end": "1171760"
  },
  {
    "text": "this make it easy to reason about code",
    "start": "1171760",
    "end": "1174000"
  },
  {
    "text": "end to end",
    "start": "1174000",
    "end": "1175039"
  },
  {
    "text": "modular remote looks like just a",
    "start": "1175039",
    "end": "1177280"
  },
  {
    "text": "function call",
    "start": "1177280",
    "end": "1178080"
  },
  {
    "text": "and you can easily trace it to the model",
    "start": "1178080",
    "end": "1180160"
  },
  {
    "text": "deployment class",
    "start": "1180160",
    "end": "1181600"
  },
  {
    "text": "in this way research helps you stay",
    "start": "1181600",
    "end": "1183440"
  },
  {
    "text": "split as a baselogic",
    "start": "1183440",
    "end": "1184799"
  },
  {
    "text": "influence into two separate components",
    "start": "1184799",
    "end": "1187120"
  },
  {
    "text": "one io heavy",
    "start": "1187120",
    "end": "1188400"
  },
  {
    "text": "and other compute heavy you can now",
    "start": "1188400",
    "end": "1190880"
  },
  {
    "text": "scale each piece individually",
    "start": "1190880",
    "end": "1192720"
  },
  {
    "text": "without losing the ease of deployment",
    "start": "1192720",
    "end": "1194799"
  },
  {
    "text": "and ability to reason about the code end",
    "start": "1194799",
    "end": "1196960"
  },
  {
    "text": "to end",
    "start": "1196960",
    "end": "1198320"
  },
  {
    "text": "additionally because monitor remote",
    "start": "1198320",
    "end": "1200160"
  },
  {
    "text": "adjusts a function call",
    "start": "1200160",
    "end": "1201520"
  },
  {
    "text": "is a lot easier to test as well as to",
    "start": "1201520",
    "end": "1204840"
  },
  {
    "text": "debug",
    "start": "1204840",
    "end": "1206000"
  },
  {
    "text": "but why not stop there what about more",
    "start": "1206000",
    "end": "1208159"
  },
  {
    "text": "complex web features like",
    "start": "1208159",
    "end": "1209679"
  },
  {
    "text": "authentication and input validation",
    "start": "1209679",
    "end": "1212480"
  },
  {
    "text": "reserve natively integrated with fast",
    "start": "1212480",
    "end": "1214400"
  },
  {
    "text": "api which is a type safe and ergonomic",
    "start": "1214400",
    "end": "1217200"
  },
  {
    "text": "web framework fast api has feature",
    "start": "1217200",
    "end": "1219679"
  },
  {
    "text": "including automatic",
    "start": "1219679",
    "end": "1221039"
  },
  {
    "text": "automatic dependency injection type",
    "start": "1221039",
    "end": "1223200"
  },
  {
    "text": "checking validation",
    "start": "1223200",
    "end": "1224640"
  },
  {
    "text": "open api doc generation and many others",
    "start": "1224640",
    "end": "1228240"
  },
  {
    "text": "in reserve you can directly pass the",
    "start": "1228240",
    "end": "1230240"
  },
  {
    "text": "fast api app",
    "start": "1230240",
    "end": "1231600"
  },
  {
    "text": "into it with serve the ingress decorator",
    "start": "1231600",
    "end": "1234320"
  },
  {
    "text": "will make sure that all",
    "start": "1234320",
    "end": "1235600"
  },
  {
    "text": "existing fast api routes are still works",
    "start": "1235600",
    "end": "1238320"
  },
  {
    "text": "and you can attach new routes",
    "start": "1238320",
    "end": "1240320"
  },
  {
    "text": "with a deployment class so state like no",
    "start": "1240320",
    "end": "1243120"
  },
  {
    "text": "other model",
    "start": "1243120",
    "end": "1244080"
  },
  {
    "text": "network database connection can easily",
    "start": "1244080",
    "end": "1246159"
  },
  {
    "text": "be managed",
    "start": "1246159",
    "end": "1247360"
  },
  {
    "text": "architecturally we just make sure your",
    "start": "1247360",
    "end": "1249200"
  },
  {
    "text": "fast api is correctly embedded into the",
    "start": "1249200",
    "end": "1251840"
  },
  {
    "text": "replica adapter",
    "start": "1251840",
    "end": "1253120"
  },
  {
    "text": "and the fast api app can scale out",
    "start": "1253120",
    "end": "1255200"
  },
  {
    "text": "across many renaults",
    "start": "1255200",
    "end": "1257280"
  },
  {
    "text": "in short reserve enable arbitrary",
    "start": "1257280",
    "end": "1259440"
  },
  {
    "text": "business logic to be embedded into your",
    "start": "1259440",
    "end": "1261280"
  },
  {
    "text": "serving application",
    "start": "1261280",
    "end": "1262720"
  },
  {
    "text": "it helps you separate io and can be",
    "start": "1262720",
    "end": "1264640"
  },
  {
    "text": "heavy work through different processes",
    "start": "1264640",
    "end": "1266240"
  },
  {
    "text": "and scale independently",
    "start": "1266240",
    "end": "1267760"
  },
  {
    "text": "with native fast api ingress integration",
    "start": "1267760",
    "end": "1270400"
  },
  {
    "text": "it can bring existing",
    "start": "1270400",
    "end": "1271919"
  },
  {
    "text": "application and or be a new one directly",
    "start": "1271919",
    "end": "1274640"
  },
  {
    "text": "on top of reserve",
    "start": "1274640",
    "end": "1276640"
  },
  {
    "text": "additionally reserve can be used as a",
    "start": "1276640",
    "end": "1278720"
  },
  {
    "text": "dropping tool to scale out your existing",
    "start": "1278720",
    "end": "1281039"
  },
  {
    "text": "web serving application",
    "start": "1281039",
    "end": "1282960"
  },
  {
    "text": "by on top of rey and lastly i will",
    "start": "1282960",
    "end": "1286400"
  },
  {
    "start": "1286000",
    "end": "1354000"
  },
  {
    "text": "present a final pattern about online",
    "start": "1286400",
    "end": "1288080"
  },
  {
    "text": "learning which is the emerging pattern",
    "start": "1288080",
    "end": "1289840"
  },
  {
    "text": "that's become more and more widely used",
    "start": "1289840",
    "end": "1292720"
  },
  {
    "text": "by seeing online learning i mean that",
    "start": "1292720",
    "end": "1294480"
  },
  {
    "text": "the model is running",
    "start": "1294480",
    "end": "1296080"
  },
  {
    "text": "is running in production constantly",
    "start": "1296080",
    "end": "1297919"
  },
  {
    "text": "being updated trained and deployed",
    "start": "1297919",
    "end": "1300799"
  },
  {
    "text": "there are many different paradigms here",
    "start": "1300799",
    "end": "1302320"
  },
  {
    "text": "i would say online learning is by far",
    "start": "1302320",
    "end": "1304159"
  },
  {
    "text": "the most cutting-edge modes of",
    "start": "1304159",
    "end": "1305440"
  },
  {
    "text": "deployment for machine learning",
    "start": "1305440",
    "end": "1306720"
  },
  {
    "text": "production today",
    "start": "1306720",
    "end": "1308000"
  },
  {
    "text": "there are use cases for dynamically",
    "start": "1308000",
    "end": "1309600"
  },
  {
    "text": "learning model ways online as you",
    "start": "1309600",
    "end": "1312000"
  },
  {
    "text": "user interact with your services these",
    "start": "1312000",
    "end": "1314720"
  },
  {
    "text": "updated model weights can contribute to",
    "start": "1314720",
    "end": "1316799"
  },
  {
    "text": "a personalized model for",
    "start": "1316799",
    "end": "1318000"
  },
  {
    "text": "each user or each user group there are",
    "start": "1318000",
    "end": "1320000"
  },
  {
    "text": "also use cases for learning parameters",
    "start": "1320000",
    "end": "1322400"
  },
  {
    "text": "to orchestrate or compose the model for",
    "start": "1322400",
    "end": "1325039"
  },
  {
    "text": "example",
    "start": "1325039",
    "end": "1325520"
  },
  {
    "text": "learning which model does a user prefer",
    "start": "1325520",
    "end": "1328000"
  },
  {
    "text": "this often manifests",
    "start": "1328000",
    "end": "1329440"
  },
  {
    "text": "in the model selection scenario and",
    "start": "1329440",
    "end": "1331600"
  },
  {
    "text": "lastly of course there's paradigm",
    "start": "1331600",
    "end": "1333440"
  },
  {
    "text": "of reinforcement learning where you're",
    "start": "1333440",
    "end": "1335520"
  },
  {
    "text": "going to hear more in different",
    "start": "1335520",
    "end": "1337039"
  },
  {
    "text": "reinforcement learning related talks in",
    "start": "1337039",
    "end": "1339360"
  },
  {
    "text": "the wii summit",
    "start": "1339360",
    "end": "1341440"
  },
  {
    "text": "as a case study for online learning",
    "start": "1341440",
    "end": "1343600"
  },
  {
    "text": "please take a look at this blog",
    "start": "1343600",
    "end": "1345520"
  },
  {
    "text": "where the massive rate deployment at n",
    "start": "1345520",
    "end": "1348799"
  },
  {
    "text": "group",
    "start": "1348799",
    "end": "1349200"
  },
  {
    "text": "use rage and research to enable online",
    "start": "1349200",
    "end": "1352080"
  },
  {
    "text": "resource allocation",
    "start": "1352080",
    "end": "1354880"
  },
  {
    "text": "and that's the four different patterns",
    "start": "1354880",
    "end": "1356480"
  },
  {
    "text": "and how reserve can help you natively",
    "start": "1356480",
    "end": "1358720"
  },
  {
    "text": "scale and work with complex",
    "start": "1358720",
    "end": "1360240"
  },
  {
    "text": "architectures",
    "start": "1360240",
    "end": "1362960"
  },
  {
    "text": "reserve is built for scaling out with",
    "start": "1363200",
    "end": "1365360"
  },
  {
    "text": "more than just one model replicas in",
    "start": "1365360",
    "end": "1367120"
  },
  {
    "text": "production",
    "start": "1367120",
    "end": "1367840"
  },
  {
    "text": "it has three core concepts and apis",
    "start": "1367840",
    "end": "1370080"
  },
  {
    "text": "deployment help you to create scalable",
    "start": "1370080",
    "end": "1371840"
  },
  {
    "text": "deployments and update them over time",
    "start": "1371840",
    "end": "1374480"
  },
  {
    "text": "ingress helps you integrate with fully",
    "start": "1374480",
    "end": "1376559"
  },
  {
    "text": "featured http application",
    "start": "1376559",
    "end": "1379039"
  },
  {
    "text": "and lastly handle enables arbitrary",
    "start": "1379039",
    "end": "1381440"
  },
  {
    "text": "nesting on composition of the",
    "start": "1381440",
    "end": "1382880"
  },
  {
    "text": "deployments",
    "start": "1382880",
    "end": "1384240"
  },
  {
    "text": "record the earlier slides that different",
    "start": "1384240",
    "end": "1386159"
  },
  {
    "text": "solution and decision of the ml",
    "start": "1386159",
    "end": "1388080"
  },
  {
    "text": "application team need to think about",
    "start": "1388080",
    "end": "1390880"
  },
  {
    "text": "research provides the best of all the",
    "start": "1390880",
    "end": "1393280"
  },
  {
    "text": "world",
    "start": "1393280",
    "end": "1394640"
  },
  {
    "text": "by its pysonic api and native fast api",
    "start": "1394640",
    "end": "1397760"
  },
  {
    "text": "integration",
    "start": "1397760",
    "end": "1398640"
  },
  {
    "text": "we made it very easy to use and very",
    "start": "1398640",
    "end": "1401120"
  },
  {
    "text": "easy to develop",
    "start": "1401120",
    "end": "1402799"
  },
  {
    "text": "by its high performance and scalability",
    "start": "1402799",
    "end": "1405360"
  },
  {
    "text": "capabilities",
    "start": "1405360",
    "end": "1406480"
  },
  {
    "text": "reserve is ready for production and",
    "start": "1406480",
    "end": "1408640"
  },
  {
    "text": "ready for scale",
    "start": "1408640",
    "end": "1410799"
  },
  {
    "text": "and as for its real production use cases",
    "start": "1410799",
    "end": "1413520"
  },
  {
    "start": "1411000",
    "end": "1511000"
  },
  {
    "text": "instead of me telling you how reserve is",
    "start": "1413520",
    "end": "1415840"
  },
  {
    "text": "is used in production we have all the",
    "start": "1415840",
    "end": "1418400"
  },
  {
    "text": "exciting talks in the same re summit",
    "start": "1418400",
    "end": "1421520"
  },
  {
    "text": "so first we have uh the talk about",
    "start": "1421520",
    "end": "1425360"
  },
  {
    "text": "scouting out reserve on any scale in the",
    "start": "1425360",
    "end": "1428480"
  },
  {
    "text": "same session we have talks about how",
    "start": "1428480",
    "end": "1431120"
  },
  {
    "text": "research helps to perform",
    "start": "1431120",
    "end": "1433039"
  },
  {
    "text": "offline scoring with the same piece of",
    "start": "1433039",
    "end": "1435520"
  },
  {
    "text": "code",
    "start": "1435520",
    "end": "1436559"
  },
  {
    "text": "we have talked about highlighting",
    "start": "1436559",
    "end": "1438720"
  },
  {
    "text": "research business logic and flexibility",
    "start": "1438720",
    "end": "1441760"
  },
  {
    "text": "as well as some future work while",
    "start": "1441760",
    "end": "1444159"
  },
  {
    "text": "bringing together",
    "start": "1444159",
    "end": "1445520"
  },
  {
    "text": "the java version of ray serving into the",
    "start": "1445520",
    "end": "1448720"
  },
  {
    "text": "open source",
    "start": "1448720",
    "end": "1449760"
  },
  {
    "text": "with engineers front-end group as well",
    "start": "1449760",
    "end": "1452720"
  },
  {
    "text": "as lastly",
    "start": "1452720",
    "end": "1453600"
  },
  {
    "text": "but not least we have exciting talk",
    "start": "1453600",
    "end": "1455919"
  },
  {
    "text": "about fully utilizing the capability of",
    "start": "1455919",
    "end": "1458880"
  },
  {
    "text": "reserve",
    "start": "1458880",
    "end": "1459600"
  },
  {
    "text": "to perform massive scale model",
    "start": "1459600",
    "end": "1461520"
  },
  {
    "text": "composition",
    "start": "1461520",
    "end": "1463679"
  },
  {
    "text": "and in conclusion machine learning",
    "start": "1463679",
    "end": "1465520"
  },
  {
    "text": "models in production",
    "start": "1465520",
    "end": "1466960"
  },
  {
    "text": "means many models in production and over",
    "start": "1466960",
    "end": "1470080"
  },
  {
    "text": "their lifetime",
    "start": "1470080",
    "end": "1471360"
  },
  {
    "text": "as well as model are counseling retrend",
    "start": "1471360",
    "end": "1473440"
  },
  {
    "text": "updated",
    "start": "1473440",
    "end": "1474400"
  },
  {
    "text": "and models are added and scaled out",
    "start": "1474400",
    "end": "1477440"
  },
  {
    "text": "today we cover four different patterns",
    "start": "1477440",
    "end": "1480080"
  },
  {
    "text": "and show that existing tooling doesn't",
    "start": "1480080",
    "end": "1482000"
  },
  {
    "text": "work with multiple models this multiple",
    "start": "1482000",
    "end": "1484080"
  },
  {
    "text": "model reality rich serve is built for",
    "start": "1484080",
    "end": "1487039"
  },
  {
    "text": "such reality and",
    "start": "1487039",
    "end": "1488320"
  },
  {
    "text": "it is the best of both worlds between",
    "start": "1488320",
    "end": "1490159"
  },
  {
    "text": "wrapping models in web server",
    "start": "1490159",
    "end": "1491919"
  },
  {
    "text": "and working with many many micro",
    "start": "1491919",
    "end": "1493600"
  },
  {
    "text": "services to learn more about ray and",
    "start": "1493600",
    "end": "1495919"
  },
  {
    "text": "research check out radar io and",
    "start": "1495919",
    "end": "1497840"
  },
  {
    "text": "reserve.org and you can follow us at",
    "start": "1497840",
    "end": "1500240"
  },
  {
    "text": "raid distributor and sql compute on",
    "start": "1500240",
    "end": "1502000"
  },
  {
    "text": "twitter",
    "start": "1502000",
    "end": "1502640"
  },
  {
    "text": "and lastly the company behind ray and",
    "start": "1502640",
    "end": "1504720"
  },
  {
    "text": "reserve any skill is hiring",
    "start": "1504720",
    "end": "1506480"
  },
  {
    "text": "please check it out thank you",
    "start": "1506480",
    "end": "1513360"
  }
]
[
  {
    "start": "0",
    "end": "48000"
  },
  {
    "text": "hello everyone",
    "start": "2879",
    "end": "3840"
  },
  {
    "text": "my name is david talby and i'm very",
    "start": "3840",
    "end": "5839"
  },
  {
    "text": "happy to be here today to talk to you",
    "start": "5839",
    "end": "7440"
  },
  {
    "text": "about state-of-the-art natural language",
    "start": "7440",
    "end": "9280"
  },
  {
    "text": "processing on apache ray",
    "start": "9280",
    "end": "12320"
  },
  {
    "text": "our talk is going to cover three parts",
    "start": "12320",
    "end": "15839"
  },
  {
    "text": "first we're going to talk about the",
    "start": "15839",
    "end": "17039"
  },
  {
    "text": "spark nlp library",
    "start": "17039",
    "end": "18880"
  },
  {
    "text": "which is the really driving underneath",
    "start": "18880",
    "end": "21119"
  },
  {
    "text": "the ray-based library that i'm going to",
    "start": "21119",
    "end": "22880"
  },
  {
    "text": "show you",
    "start": "22880",
    "end": "23680"
  },
  {
    "text": "so that you understand the power",
    "start": "23680",
    "end": "26320"
  },
  {
    "text": "scalability and range of nlp models at",
    "start": "26320",
    "end": "28880"
  },
  {
    "text": "your disposal here",
    "start": "28880",
    "end": "30640"
  },
  {
    "text": "then we're going to talk about the nlu",
    "start": "30640",
    "end": "32160"
  },
  {
    "text": "library and show you some code examples",
    "start": "32160",
    "end": "34960"
  },
  {
    "text": "uh just you know how you can get quite a",
    "start": "34960",
    "end": "36719"
  },
  {
    "text": "few nlp tasks done with one line of code",
    "start": "36719",
    "end": "39600"
  },
  {
    "text": "and then we're going to talk",
    "start": "39600",
    "end": "41680"
  },
  {
    "text": "specifically about some of the",
    "start": "41680",
    "end": "43280"
  },
  {
    "text": "array optimizations that we've put into",
    "start": "43280",
    "end": "45600"
  },
  {
    "text": "it",
    "start": "45600",
    "end": "47760"
  },
  {
    "start": "48000",
    "end": "48000"
  },
  {
    "text": "so um spark nlp is the",
    "start": "48480",
    "end": "51520"
  },
  {
    "text": "the nlp library for apache spark it's",
    "start": "51520",
    "end": "54640"
  },
  {
    "text": "been around",
    "start": "54640",
    "end": "55920"
  },
  {
    "text": "for about three years now and has become",
    "start": "55920",
    "end": "57760"
  },
  {
    "text": "quite popular",
    "start": "57760",
    "end": "59120"
  },
  {
    "text": "er elite has three main design",
    "start": "59120",
    "end": "63120"
  },
  {
    "text": "goals which is to provide the open",
    "start": "63120",
    "end": "65360"
  },
  {
    "text": "source community with state-of-the-art",
    "start": "65360",
    "end": "67119"
  },
  {
    "text": "accuracy speed and scalability",
    "start": "67119",
    "end": "69439"
  },
  {
    "text": "and the larger game popularity because",
    "start": "69439",
    "end": "71680"
  },
  {
    "text": "it started",
    "start": "71680",
    "end": "72799"
  },
  {
    "text": "very close to the deep learning",
    "start": "72799",
    "end": "74560"
  },
  {
    "text": "revolution in nlp",
    "start": "74560",
    "end": "76400"
  },
  {
    "text": "and it was the the first to productize",
    "start": "76400",
    "end": "79280"
  },
  {
    "text": "and give",
    "start": "79280",
    "end": "79759"
  },
  {
    "text": "really production great scalable",
    "start": "79759",
    "end": "81200"
  },
  {
    "text": "trainable versions",
    "start": "81200",
    "end": "82960"
  },
  {
    "text": "of some of the new state-of-the-art deep",
    "start": "82960",
    "end": "84640"
  },
  {
    "text": "learning research",
    "start": "84640",
    "end": "86400"
  },
  {
    "text": "it the the the second thing that really",
    "start": "86400",
    "end": "88720"
  },
  {
    "text": "worked well for the library is the fact",
    "start": "88720",
    "end": "90320"
  },
  {
    "text": "that it's",
    "start": "90320",
    "end": "90799"
  },
  {
    "text": "it's the only open source nlp library",
    "start": "90799",
    "end": "92960"
  },
  {
    "text": "that's natively scalable and can use any",
    "start": "92960",
    "end": "94880"
  },
  {
    "text": "spark cluster",
    "start": "94880",
    "end": "96400"
  },
  {
    "text": "yes what you have is you have apache",
    "start": "96400",
    "end": "98479"
  },
  {
    "text": "license completely",
    "start": "98479",
    "end": "99680"
  },
  {
    "text": "free python java and scala libraries",
    "start": "99680",
    "end": "102799"
  },
  {
    "text": "over 200 pre-trained models and",
    "start": "102799",
    "end": "104960"
  },
  {
    "text": "pipelines",
    "start": "104960",
    "end": "106479"
  },
  {
    "text": "in a very frequent frequent wheelie",
    "start": "106479",
    "end": "108320"
  },
  {
    "text": "cycle with just about three years now",
    "start": "108320",
    "end": "111040"
  },
  {
    "text": "of releasing software at least every two",
    "start": "111040",
    "end": "112840"
  },
  {
    "text": "weeks",
    "start": "112840",
    "end": "114399"
  },
  {
    "text": "early last year it was the first time",
    "start": "114399",
    "end": "116560"
  },
  {
    "text": "that spark nlp was recognized as the",
    "start": "116560",
    "end": "118560"
  },
  {
    "text": "most popular nlp library in the",
    "start": "118560",
    "end": "120240"
  },
  {
    "text": "enterprise",
    "start": "120240",
    "end": "121280"
  },
  {
    "text": "and since then two more surveys in 2020",
    "start": "121280",
    "end": "123680"
  },
  {
    "text": "i've kind of",
    "start": "123680",
    "end": "124399"
  },
  {
    "text": "confirmed that from other sources that",
    "start": "124399",
    "end": "127840"
  },
  {
    "text": "you know other than the research",
    "start": "127840",
    "end": "128879"
  },
  {
    "text": "community",
    "start": "128879",
    "end": "129599"
  },
  {
    "text": "uh when practitioners want to take nlp",
    "start": "129599",
    "end": "132080"
  },
  {
    "text": "libraries",
    "start": "132080",
    "end": "133040"
  },
  {
    "text": "and use them in real companies real",
    "start": "133040",
    "end": "134640"
  },
  {
    "text": "projects they largely choose park nlp",
    "start": "134640",
    "end": "137440"
  },
  {
    "text": "um and um",
    "start": "137440",
    "end": "141040"
  },
  {
    "text": "there's a range kind of you know",
    "start": "141040",
    "end": "142319"
  },
  {
    "text": "wikipedia other sources that",
    "start": "142319",
    "end": "144160"
  },
  {
    "text": "confirm that and talk about why why the",
    "start": "144160",
    "end": "145840"
  },
  {
    "text": "library is has been adopted the way it",
    "start": "145840",
    "end": "148080"
  },
  {
    "text": "is",
    "start": "148080",
    "end": "148879"
  },
  {
    "text": "um sparking appears also won several",
    "start": "148879",
    "end": "150959"
  },
  {
    "text": "nice awards",
    "start": "150959",
    "end": "152319"
  },
  {
    "text": "uh some of them focus more like the ai",
    "start": "152319",
    "end": "154640"
  },
  {
    "text": "excellence award on",
    "start": "154640",
    "end": "155760"
  },
  {
    "text": "really taking a really very new state of",
    "start": "155760",
    "end": "159120"
  },
  {
    "text": "that list",
    "start": "159120",
    "end": "159760"
  },
  {
    "text": "research and making it available in real",
    "start": "159760",
    "end": "162720"
  },
  {
    "text": "dependable production great systems for",
    "start": "162720",
    "end": "164560"
  },
  {
    "text": "the global community",
    "start": "164560",
    "end": "166400"
  },
  {
    "text": "um some of them focus really more on",
    "start": "166400",
    "end": "169680"
  },
  {
    "text": "accuracy and some of the accuracy",
    "start": "169680",
    "end": "171040"
  },
  {
    "text": "benchmarks that the library",
    "start": "171040",
    "end": "172959"
  },
  {
    "text": "has been able to provide today",
    "start": "172959",
    "end": "176319"
  },
  {
    "start": "177000",
    "end": "177000"
  },
  {
    "text": "in terms of accuracy a state of the art",
    "start": "177440",
    "end": "179920"
  },
  {
    "text": "is not is not a marketing term",
    "start": "179920",
    "end": "181360"
  },
  {
    "text": "is is an academic term instead of that",
    "start": "181360",
    "end": "183760"
  },
  {
    "text": "really means",
    "start": "183760",
    "end": "185360"
  },
  {
    "text": "the following look at the all the",
    "start": "185360",
    "end": "187040"
  },
  {
    "text": "academic papers that are",
    "start": "187040",
    "end": "188560"
  },
  {
    "text": "peer-reviewed and validated that have",
    "start": "188560",
    "end": "190159"
  },
  {
    "text": "been published in space look at the",
    "start": "190159",
    "end": "191519"
  },
  {
    "text": "public benchmarks they've been tested",
    "start": "191519",
    "end": "193280"
  },
  {
    "text": "against",
    "start": "193280",
    "end": "194400"
  },
  {
    "text": "what's really what is the best really",
    "start": "194400",
    "end": "196400"
  },
  {
    "text": "discovered algorithm today",
    "start": "196400",
    "end": "198480"
  },
  {
    "text": "on specific benchmarks uh that defines",
    "start": "198480",
    "end": "200640"
  },
  {
    "text": "the state of the art",
    "start": "200640",
    "end": "202000"
  },
  {
    "text": "in nlp in the past really you know two",
    "start": "202000",
    "end": "204560"
  },
  {
    "text": "three years",
    "start": "204560",
    "end": "205360"
  },
  {
    "text": "uh the state of the art for very common",
    "start": "205360",
    "end": "207440"
  },
  {
    "text": "uh benchmarks",
    "start": "207440",
    "end": "209200"
  },
  {
    "text": "usually only host for a few weeks until",
    "start": "209200",
    "end": "210879"
  },
  {
    "text": "someone comes and says that they can do",
    "start": "210879",
    "end": "212159"
  },
  {
    "text": "better",
    "start": "212159",
    "end": "213200"
  },
  {
    "text": "so when you say that you deliver a set",
    "start": "213200",
    "end": "214799"
  },
  {
    "text": "of doubt accuracy it really means that",
    "start": "214799",
    "end": "216159"
  },
  {
    "text": "you keep implementing",
    "start": "216159",
    "end": "217120"
  },
  {
    "text": "the implementing new algorithms and new",
    "start": "217120",
    "end": "218959"
  },
  {
    "text": "results",
    "start": "218959",
    "end": "220720"
  },
  {
    "text": "and you can see here this is one",
    "start": "220720",
    "end": "222400"
  },
  {
    "text": "benchmark for almost a year ago",
    "start": "222400",
    "end": "224799"
  },
  {
    "text": "and but you can see over the past few",
    "start": "224799",
    "end": "226720"
  },
  {
    "text": "months spark nlp 2.4",
    "start": "226720",
    "end": "229040"
  },
  {
    "text": "we basically re-implemented entity",
    "start": "229040",
    "end": "231040"
  },
  {
    "text": "recognition ocr",
    "start": "231040",
    "end": "232799"
  },
  {
    "text": "and uh different types of matching",
    "start": "232799",
    "end": "234720"
  },
  {
    "text": "algorithms",
    "start": "234720",
    "end": "236239"
  },
  {
    "text": "in spark np 2.5 we've re-implemented",
    "start": "236239",
    "end": "238799"
  },
  {
    "text": "spell checking to have a deep learning",
    "start": "238799",
    "end": "240480"
  },
  {
    "text": "based contextual spell checker",
    "start": "240480",
    "end": "242400"
  },
  {
    "text": "and we've also implemented a",
    "start": "242400",
    "end": "244319"
  },
  {
    "text": "re-implemented sentiment analysis",
    "start": "244319",
    "end": "246480"
  },
  {
    "text": "uh so a lot of the work makes sure that",
    "start": "246480",
    "end": "248319"
  },
  {
    "text": "we we keep you and we keep the community",
    "start": "248319",
    "end": "250959"
  },
  {
    "text": "at the top of the line accuracy which",
    "start": "250959",
    "end": "253200"
  },
  {
    "text": "means that you know we follow the papers",
    "start": "253200",
    "end": "254879"
  },
  {
    "text": "we try to reproduce them",
    "start": "254879",
    "end": "256959"
  },
  {
    "text": "and when something actually improves",
    "start": "256959",
    "end": "258400"
  },
  {
    "text": "accuracy we make it",
    "start": "258400",
    "end": "260720"
  },
  {
    "text": "we make it available other than accuracy",
    "start": "260720",
    "end": "264800"
  },
  {
    "start": "264000",
    "end": "264000"
  },
  {
    "text": "one other thing that a sparkly is very",
    "start": "264800",
    "end": "266880"
  },
  {
    "text": "well known for is the ability to",
    "start": "266880",
    "end": "268400"
  },
  {
    "text": "actually leverage a cluster",
    "start": "268400",
    "end": "271520"
  },
  {
    "text": "and this is an example of a",
    "start": "271520",
    "end": "275440"
  },
  {
    "text": "of getting results on aws",
    "start": "275440",
    "end": "278639"
  },
  {
    "text": "emr with zero code changes yeah so of",
    "start": "278639",
    "end": "281600"
  },
  {
    "text": "course",
    "start": "281600",
    "end": "282000"
  },
  {
    "text": "you know if you have a large cluster yes",
    "start": "282000",
    "end": "283680"
  },
  {
    "text": "you you'll want to",
    "start": "283680",
    "end": "285520"
  },
  {
    "text": "you'll want to optimize and play with",
    "start": "285520",
    "end": "286800"
  },
  {
    "text": "different parameters but even with no",
    "start": "286800",
    "end": "289120"
  },
  {
    "text": "code changes",
    "start": "289120",
    "end": "290160"
  },
  {
    "text": "this is really the only nlp library that",
    "start": "290160",
    "end": "293199"
  },
  {
    "text": "natively scales to a cluster",
    "start": "293199",
    "end": "295520"
  },
  {
    "text": "with scalability we really take",
    "start": "295520",
    "end": "297280"
  },
  {
    "text": "advantage of spark",
    "start": "297280",
    "end": "298880"
  },
  {
    "text": "it automates execution planning uh",
    "start": "298880",
    "end": "301840"
  },
  {
    "text": "minimizing shuffling minimizing memory",
    "start": "301840",
    "end": "303840"
  },
  {
    "text": "use",
    "start": "303840",
    "end": "304240"
  },
  {
    "text": "and caching serialization and those",
    "start": "304240",
    "end": "307039"
  },
  {
    "text": "that's really the one thing that spark",
    "start": "307039",
    "end": "308479"
  },
  {
    "text": "does",
    "start": "308479",
    "end": "309039"
  },
  {
    "text": "really well and we've done a lot of work",
    "start": "309039",
    "end": "311120"
  },
  {
    "text": "with data breaks and this power",
    "start": "311120",
    "end": "312400"
  },
  {
    "text": "community",
    "start": "312400",
    "end": "313039"
  },
  {
    "text": "to make the most of it of course that",
    "start": "313039",
    "end": "316800"
  },
  {
    "text": "you know scaling is is is not you know",
    "start": "316800",
    "end": "319199"
  },
  {
    "text": "it's not magic",
    "start": "319199",
    "end": "320000"
  },
  {
    "text": "and if you have complex use cases a",
    "start": "320000",
    "end": "322800"
  },
  {
    "text": "large",
    "start": "322800",
    "end": "323440"
  },
  {
    "text": "you know very large cluster you will",
    "start": "323440",
    "end": "324720"
  },
  {
    "text": "want to optimize you know to make sure",
    "start": "324720",
    "end": "326639"
  },
  {
    "text": "to optimize your cluster and optimize",
    "start": "326639",
    "end": "328240"
  },
  {
    "text": "your program and there are you know kind",
    "start": "328240",
    "end": "329520"
  },
  {
    "text": "of tools and ways to do that",
    "start": "329520",
    "end": "331520"
  },
  {
    "text": "and not all the algorithms are scaling",
    "start": "331520",
    "end": "333600"
  },
  {
    "text": "the same way right so if you have",
    "start": "333600",
    "end": "335120"
  },
  {
    "text": "you if you're influencing that something",
    "start": "335120",
    "end": "336639"
  },
  {
    "text": "that's almost trivially parallelizable",
    "start": "336639",
    "end": "338880"
  },
  {
    "text": "and you'll get nearly now speed up if",
    "start": "338880",
    "end": "341440"
  },
  {
    "text": "you're doing things that are inherently",
    "start": "341440",
    "end": "343280"
  },
  {
    "text": "um incremental you know like like cnns",
    "start": "343280",
    "end": "346160"
  },
  {
    "text": "for example",
    "start": "346160",
    "end": "347199"
  },
  {
    "text": "you'll probably see less than linear",
    "start": "347199",
    "end": "350840"
  },
  {
    "text": "speed",
    "start": "350840",
    "end": "352800"
  },
  {
    "start": "352000",
    "end": "352000"
  },
  {
    "text": "um the other thing we focus on a lot is",
    "start": "352800",
    "end": "354800"
  },
  {
    "text": "speed",
    "start": "354800",
    "end": "356080"
  },
  {
    "text": "and speed part of it is the algorithms",
    "start": "356080",
    "end": "357840"
  },
  {
    "text": "part of it is the fact that we",
    "start": "357840",
    "end": "359759"
  },
  {
    "text": "you know the library is written in",
    "start": "359759",
    "end": "360960"
  },
  {
    "text": "skylight and within the jvm within the",
    "start": "360960",
    "end": "362880"
  },
  {
    "text": "spark process",
    "start": "362880",
    "end": "364240"
  },
  {
    "text": "here we've done a lot of work with",
    "start": "364240",
    "end": "365600"
  },
  {
    "text": "tensorflow to make sure we integrate",
    "start": "365600",
    "end": "367600"
  },
  {
    "text": "within the same process so we minimize",
    "start": "367600",
    "end": "369360"
  },
  {
    "text": "memory copying",
    "start": "369360",
    "end": "370880"
  },
  {
    "text": "uh we minimize the realization we",
    "start": "370880",
    "end": "373120"
  },
  {
    "text": "minimize communication",
    "start": "373120",
    "end": "374639"
  },
  {
    "text": "and there's a lot of profiling",
    "start": "374639",
    "end": "376000"
  },
  {
    "text": "optimization that went into it",
    "start": "376000",
    "end": "378080"
  },
  {
    "text": "the other thing that we do is we have",
    "start": "378080",
    "end": "379520"
  },
  {
    "text": "optimized builds uh for the latest and",
    "start": "379520",
    "end": "381919"
  },
  {
    "text": "greatest",
    "start": "381919",
    "end": "382639"
  },
  {
    "text": "both intel and nvidia chips uh so so the",
    "start": "382639",
    "end": "385680"
  },
  {
    "text": "kind of standard cpu builds there are",
    "start": "385680",
    "end": "387440"
  },
  {
    "text": "gpu builds for nvidia",
    "start": "387440",
    "end": "389120"
  },
  {
    "text": "and there are intel xeon and bills that",
    "start": "389120",
    "end": "391680"
  },
  {
    "text": "are also",
    "start": "391680",
    "end": "392840"
  },
  {
    "text": "specialized this is one case study on",
    "start": "392840",
    "end": "395520"
  },
  {
    "text": "aws a of training",
    "start": "395520",
    "end": "397680"
  },
  {
    "text": "a name entity recognizer in french based",
    "start": "397680",
    "end": "400400"
  },
  {
    "text": "on wiki and",
    "start": "400400",
    "end": "401680"
  },
  {
    "text": "in wikipedia and french",
    "start": "401680",
    "end": "405199"
  },
  {
    "text": "and what we did here it was really i",
    "start": "405199",
    "end": "406960"
  },
  {
    "text": "wanted to compare just run time",
    "start": "406960",
    "end": "409919"
  },
  {
    "text": "so we made sure to make it here we make",
    "start": "409919",
    "end": "413440"
  },
  {
    "text": "sure we run the same code",
    "start": "413440",
    "end": "415199"
  },
  {
    "text": "at least 80 epochs to achieve the same",
    "start": "415199",
    "end": "416880"
  },
  {
    "text": "level of accuracy see this is basically",
    "start": "416880",
    "end": "419039"
  },
  {
    "text": "how long does it take to reach a certain",
    "start": "419039",
    "end": "420560"
  },
  {
    "text": "level of accuracy on this hardware",
    "start": "420560",
    "end": "422639"
  },
  {
    "text": "in this specific case uh we as you see",
    "start": "422639",
    "end": "424880"
  },
  {
    "text": "we compared kind of five different",
    "start": "424880",
    "end": "426880"
  },
  {
    "text": "version in this specific example this is",
    "start": "426880",
    "end": "429520"
  },
  {
    "text": "something that we validated a few months",
    "start": "429520",
    "end": "431280"
  },
  {
    "text": "ago",
    "start": "431280",
    "end": "431919"
  },
  {
    "text": "intel actually outperformed nvidia both",
    "start": "431919",
    "end": "434319"
  },
  {
    "text": "in terms of time",
    "start": "434319",
    "end": "435680"
  },
  {
    "text": "it was 90 faster and it was you know",
    "start": "435680",
    "end": "437759"
  },
  {
    "text": "almost half as cheap",
    "start": "437759",
    "end": "438960"
  },
  {
    "text": "as the tesla p100s uh i would say since",
    "start": "438960",
    "end": "441759"
  },
  {
    "text": "then both intel nvidia have you know new",
    "start": "441759",
    "end": "443599"
  },
  {
    "text": "releases",
    "start": "443599",
    "end": "444319"
  },
  {
    "text": "which we have which we are testing and",
    "start": "444319",
    "end": "445680"
  },
  {
    "text": "validating as well and one of the things",
    "start": "445680",
    "end": "447919"
  },
  {
    "text": "we will promise you though",
    "start": "447919",
    "end": "449280"
  },
  {
    "text": "is that we we will make sure that we you",
    "start": "449280",
    "end": "451759"
  },
  {
    "text": "know we test we optimize we make sure",
    "start": "451759",
    "end": "454400"
  },
  {
    "text": "that you can make the most of the latest",
    "start": "454400",
    "end": "455919"
  },
  {
    "text": "hardware when you use the library",
    "start": "455919",
    "end": "459599"
  },
  {
    "text": "tell us what the library actually does",
    "start": "459599",
    "end": "461520"
  },
  {
    "text": "uh so it's a full end to an nlp library",
    "start": "461520",
    "end": "463759"
  },
  {
    "text": "starting with simple things",
    "start": "463759",
    "end": "465360"
  },
  {
    "text": "like how do i split sentences do",
    "start": "465360",
    "end": "466960"
  },
  {
    "text": "tokenization normalization",
    "start": "466960",
    "end": "468800"
  },
  {
    "text": "limitization part of speech up to you",
    "start": "468800",
    "end": "471520"
  },
  {
    "text": "know more complex things like how do i",
    "start": "471520",
    "end": "473520"
  },
  {
    "text": "do deep learning based document",
    "start": "473520",
    "end": "474960"
  },
  {
    "text": "classification emotion analysis",
    "start": "474960",
    "end": "477280"
  },
  {
    "text": "information extraction name entity",
    "start": "477280",
    "end": "478960"
  },
  {
    "text": "recognition",
    "start": "478960",
    "end": "480479"
  },
  {
    "text": "it embeds transformers meaning that",
    "start": "480479",
    "end": "483599"
  },
  {
    "text": "the library itself without external",
    "start": "483599",
    "end": "485280"
  },
  {
    "text": "dependencies uh",
    "start": "485280",
    "end": "487039"
  },
  {
    "text": "includes things like being able to",
    "start": "487039",
    "end": "488319"
  },
  {
    "text": "calculate you know birth elmo",
    "start": "488319",
    "end": "490639"
  },
  {
    "text": "albert excellent the other types of",
    "start": "490639",
    "end": "492800"
  },
  {
    "text": "transformers",
    "start": "492800",
    "end": "494080"
  },
  {
    "text": "it has a support for 46 languages today",
    "start": "494080",
    "end": "497440"
  },
  {
    "text": "and actually right now it says the 90",
    "start": "497440",
    "end": "498879"
  },
  {
    "text": "plus models we're actually at over 200",
    "start": "498879",
    "end": "500800"
  },
  {
    "text": "already",
    "start": "500800",
    "end": "502560"
  },
  {
    "text": "that come pre-trained with the library",
    "start": "502560",
    "end": "506319"
  },
  {
    "text": "so this is park nlp and we said it's",
    "start": "506319",
    "end": "509520"
  },
  {
    "text": "been around for three years",
    "start": "509520",
    "end": "510720"
  },
  {
    "text": "and we keep releasing software we keep",
    "start": "510720",
    "end": "512479"
  },
  {
    "text": "improving it and",
    "start": "512479",
    "end": "514320"
  },
  {
    "text": "one of the things that we wanted to",
    "start": "514320",
    "end": "516560"
  },
  {
    "text": "improve over time",
    "start": "516560",
    "end": "517680"
  },
  {
    "text": "and this is what the race story it's in",
    "start": "517680",
    "end": "519760"
  },
  {
    "text": "is basically better integration with the",
    "start": "519760",
    "end": "521279"
  },
  {
    "text": "python ecosystem",
    "start": "521279",
    "end": "523360"
  },
  {
    "start": "523000",
    "end": "523000"
  },
  {
    "text": "in order to better serve the python",
    "start": "523360",
    "end": "526080"
  },
  {
    "text": "community",
    "start": "526080",
    "end": "527120"
  },
  {
    "text": "we decide to build a new library the nlu",
    "start": "527120",
    "end": "529120"
  },
  {
    "text": "library that you can get today",
    "start": "529120",
    "end": "531120"
  },
  {
    "text": "by just running pip install nlu",
    "start": "531120",
    "end": "534320"
  },
  {
    "text": "that basically gives you the best of",
    "start": "534320",
    "end": "535839"
  },
  {
    "text": "both worlds it gives you all the power",
    "start": "535839",
    "end": "538720"
  },
  {
    "text": "of spark and lp and everything that",
    "start": "538720",
    "end": "540320"
  },
  {
    "text": "comes with it",
    "start": "540320",
    "end": "542240"
  },
  {
    "text": "but in a way that's a much simpler",
    "start": "542240",
    "end": "545360"
  },
  {
    "text": "and most importantly better integrated",
    "start": "545360",
    "end": "547440"
  },
  {
    "text": "with the python ecosystem",
    "start": "547440",
    "end": "548959"
  },
  {
    "text": "and and the other tools that data",
    "start": "548959",
    "end": "550560"
  },
  {
    "text": "scientists and data analysts use every",
    "start": "550560",
    "end": "552480"
  },
  {
    "text": "day",
    "start": "552480",
    "end": "553839"
  },
  {
    "text": "so we wanted to make sure that almost",
    "start": "553839",
    "end": "555680"
  },
  {
    "text": "everything you need to do",
    "start": "555680",
    "end": "557040"
  },
  {
    "text": "you can do with one line of code we",
    "start": "557040",
    "end": "559760"
  },
  {
    "text": "wanted to make sure that we",
    "start": "559760",
    "end": "561279"
  },
  {
    "text": "natively read in data frames and we",
    "start": "561279",
    "end": "564240"
  },
  {
    "text": "write back data frames",
    "start": "564240",
    "end": "565920"
  },
  {
    "text": "uh so if for example you know you get",
    "start": "565920",
    "end": "568880"
  },
  {
    "text": "some text you need to extract named",
    "start": "568880",
    "end": "570399"
  },
  {
    "text": "entities and then you feed it into you",
    "start": "570399",
    "end": "572080"
  },
  {
    "text": "know tensorflow pytorch",
    "start": "572080",
    "end": "573760"
  },
  {
    "text": "that's a very you know that's a very",
    "start": "573760",
    "end": "575440"
  },
  {
    "text": "simple thing to do",
    "start": "575440",
    "end": "577279"
  },
  {
    "text": "if you you know you run sentiment",
    "start": "577279",
    "end": "579040"
  },
  {
    "text": "analysis or language detection",
    "start": "579040",
    "end": "581519"
  },
  {
    "text": "and you want to get for example a you",
    "start": "581519",
    "end": "583200"
  },
  {
    "text": "know a bar chart with matplotlib",
    "start": "583200",
    "end": "585519"
  },
  {
    "text": "of number of documents per language or",
    "start": "585519",
    "end": "587279"
  },
  {
    "text": "number of documents per emotion you can",
    "start": "587279",
    "end": "588880"
  },
  {
    "text": "just do that with one line",
    "start": "588880",
    "end": "591279"
  },
  {
    "text": "and of course we wanted to keep the",
    "start": "591279",
    "end": "592720"
  },
  {
    "text": "whole thing completely open source",
    "start": "592720",
    "end": "594880"
  },
  {
    "text": "so everything that i'm showing you today",
    "start": "594880",
    "end": "596880"
  },
  {
    "text": "has an apache 2.0 license",
    "start": "596880",
    "end": "599360"
  },
  {
    "text": "so it's completely free including for",
    "start": "599360",
    "end": "601040"
  },
  {
    "text": "any commercial use",
    "start": "601040",
    "end": "605600"
  },
  {
    "start": "605000",
    "end": "605000"
  },
  {
    "text": "so and to see what the nlu library can",
    "start": "605600",
    "end": "608079"
  },
  {
    "text": "do let's look at a few examples",
    "start": "608079",
    "end": "610800"
  },
  {
    "text": "uh so to install the library",
    "start": "610800",
    "end": "614160"
  },
  {
    "text": "all you need is pip install nlu and then",
    "start": "614160",
    "end": "617279"
  },
  {
    "text": "once you import nlu you have this nl",
    "start": "617279",
    "end": "619279"
  },
  {
    "text": "object",
    "start": "619279",
    "end": "620160"
  },
  {
    "text": "and you do something like any new dot",
    "start": "620160",
    "end": "621760"
  },
  {
    "text": "load you know spell in this case dot",
    "start": "621760",
    "end": "623440"
  },
  {
    "text": "predict",
    "start": "623440",
    "end": "624160"
  },
  {
    "text": "i like peanut butter and jelly and so",
    "start": "624160",
    "end": "626800"
  },
  {
    "text": "the load function",
    "start": "626800",
    "end": "629120"
  },
  {
    "text": "loads a set of either models or",
    "start": "629120",
    "end": "631839"
  },
  {
    "text": "pipelines",
    "start": "631839",
    "end": "632800"
  },
  {
    "text": "okay including any embeddings and",
    "start": "632800",
    "end": "634480"
  },
  {
    "text": "resources that are required with them",
    "start": "634480",
    "end": "636720"
  },
  {
    "text": "in this case the the spell name refers",
    "start": "636720",
    "end": "639920"
  },
  {
    "text": "to a pipeline that does a tokenization",
    "start": "639920",
    "end": "642079"
  },
  {
    "text": "and then",
    "start": "642079",
    "end": "642480"
  },
  {
    "text": "then does a spell checking in english",
    "start": "642480",
    "end": "644959"
  },
  {
    "text": "and we'll see later examples from other",
    "start": "644959",
    "end": "646880"
  },
  {
    "text": "languages",
    "start": "646880",
    "end": "648079"
  },
  {
    "text": "uh so you do nlp nau.code you load them",
    "start": "648079",
    "end": "651040"
  },
  {
    "text": "all into memory it returns back a",
    "start": "651040",
    "end": "652720"
  },
  {
    "text": "pipeline",
    "start": "652720",
    "end": "653360"
  },
  {
    "text": "in nlp pipeline on which you can run the",
    "start": "653360",
    "end": "656160"
  },
  {
    "text": "predict function",
    "start": "656160",
    "end": "657440"
  },
  {
    "text": "one of the parameters that pd can take",
    "start": "657440",
    "end": "659120"
  },
  {
    "text": "is a string and in this case",
    "start": "659120",
    "end": "661360"
  },
  {
    "text": "it analyzes the text and you can see the",
    "start": "661360",
    "end": "663360"
  },
  {
    "text": "results",
    "start": "663360",
    "end": "664560"
  },
  {
    "text": "what you get back always is a data frame",
    "start": "664560",
    "end": "667279"
  },
  {
    "text": "in this case it's going to be a pandas",
    "start": "667279",
    "end": "668720"
  },
  {
    "text": "data frame",
    "start": "668720",
    "end": "670000"
  },
  {
    "text": "because it's just one string and if you",
    "start": "670000",
    "end": "672640"
  },
  {
    "text": "print the",
    "start": "672640",
    "end": "673440"
  },
  {
    "text": "you know if you print the pandas data",
    "start": "673440",
    "end": "674959"
  },
  {
    "text": "frame say in your notebook",
    "start": "674959",
    "end": "676480"
  },
  {
    "text": "here's what you're going to see you're",
    "start": "676480",
    "end": "678160"
  },
  {
    "text": "going to see that first of all",
    "start": "678160",
    "end": "679839"
  },
  {
    "text": "the the sentence was tokenized meaning",
    "start": "679839",
    "end": "681839"
  },
  {
    "text": "we split it into words",
    "start": "681839",
    "end": "683600"
  },
  {
    "text": "and then you can see that we actually",
    "start": "683600",
    "end": "684720"
  },
  {
    "text": "ran a spell tracking model",
    "start": "684720",
    "end": "687040"
  },
  {
    "text": "uh and in addition to the token column",
    "start": "687040",
    "end": "689519"
  },
  {
    "text": "that gives you the original tokenization",
    "start": "689519",
    "end": "691120"
  },
  {
    "text": "you also",
    "start": "691120",
    "end": "691680"
  },
  {
    "text": "you also have a checked column and you",
    "start": "691680",
    "end": "693519"
  },
  {
    "text": "can see that the words in this case you",
    "start": "693519",
    "end": "695120"
  },
  {
    "text": "know liked peanut butter",
    "start": "695120",
    "end": "697519"
  },
  {
    "text": "and and the jelly were actually",
    "start": "697519",
    "end": "700320"
  },
  {
    "text": "corrected",
    "start": "700320",
    "end": "701600"
  },
  {
    "text": "by the spell trigger okay so this is",
    "start": "701600",
    "end": "704800"
  },
  {
    "text": "really all you need to do to apply spell",
    "start": "704800",
    "end": "706320"
  },
  {
    "text": "checking to a sentence",
    "start": "706320",
    "end": "709200"
  },
  {
    "start": "709000",
    "end": "709000"
  },
  {
    "text": "here's another example in this case what",
    "start": "709200",
    "end": "711600"
  },
  {
    "text": "we want to do",
    "start": "711600",
    "end": "712560"
  },
  {
    "text": "is take a sentence a calculate part of",
    "start": "712560",
    "end": "714880"
  },
  {
    "text": "speech and then a calculate",
    "start": "714880",
    "end": "716959"
  },
  {
    "text": "a do dependency parser right so many",
    "start": "716959",
    "end": "719760"
  },
  {
    "text": "dependencies between the different parts",
    "start": "719760",
    "end": "721200"
  },
  {
    "text": "of speech in the sentence",
    "start": "721200",
    "end": "722880"
  },
  {
    "text": "and you can see it's still a one-liner",
    "start": "722880",
    "end": "724399"
  },
  {
    "text": "so any lieu.load dip a",
    "start": "724399",
    "end": "726320"
  },
  {
    "text": "depth is the shortcut for dependency",
    "start": "726320",
    "end": "728560"
  },
  {
    "text": "passing in english",
    "start": "728560",
    "end": "730240"
  },
  {
    "text": "and then we do dot predict then the",
    "start": "730240",
    "end": "731839"
  },
  {
    "text": "sentence we are looking to analyze",
    "start": "731839",
    "end": "734079"
  },
  {
    "text": "and you get your pandas data frame that",
    "start": "734079",
    "end": "735760"
  },
  {
    "text": "has the token column with the tokens",
    "start": "735760",
    "end": "738240"
  },
  {
    "text": "is the pos column with the parts of",
    "start": "738240",
    "end": "739760"
  },
  {
    "text": "speech",
    "start": "739760",
    "end": "741360"
  },
  {
    "text": "okay so represent is a verb a is a",
    "start": "741360",
    "end": "743760"
  },
  {
    "text": "determinant",
    "start": "743760",
    "end": "744959"
  },
  {
    "text": "a grammatical is a an adjective tree is",
    "start": "744959",
    "end": "747680"
  },
  {
    "text": "a noun",
    "start": "747680",
    "end": "748639"
  },
  {
    "text": "and then we can also look at the",
    "start": "748639",
    "end": "749839"
  },
  {
    "text": "dependencies right so so we can see",
    "start": "749839",
    "end": "752639"
  },
  {
    "text": "basically which what kind of dependency",
    "start": "752639",
    "end": "754800"
  },
  {
    "text": "is there between words in this sentence",
    "start": "754800",
    "end": "759440"
  },
  {
    "start": "759000",
    "end": "759000"
  },
  {
    "text": "uh going you know beyond kind of mode",
    "start": "759440",
    "end": "761600"
  },
  {
    "text": "the basic structural things",
    "start": "761600",
    "end": "763600"
  },
  {
    "text": "uh we can also do things like emotion",
    "start": "763600",
    "end": "765680"
  },
  {
    "text": "detection",
    "start": "765680",
    "end": "767040"
  },
  {
    "text": "so i knew you thought emotion don't",
    "start": "767040",
    "end": "769279"
  },
  {
    "text": "predict i love nlu",
    "start": "769279",
    "end": "771519"
  },
  {
    "text": "gives you the following data frame uh so",
    "start": "771519",
    "end": "774639"
  },
  {
    "text": "you have sentence embeddings because",
    "start": "774639",
    "end": "776079"
  },
  {
    "text": "it's really just one of the any",
    "start": "776079",
    "end": "777279"
  },
  {
    "text": "betting's is really kind of one of the",
    "start": "777279",
    "end": "778480"
  },
  {
    "text": "side",
    "start": "778480",
    "end": "778800"
  },
  {
    "text": "side things that need to be calculated",
    "start": "778800",
    "end": "780399"
  },
  {
    "text": "for emotion detection to work",
    "start": "780399",
    "end": "782079"
  },
  {
    "text": "because we use universal sentence",
    "start": "782079",
    "end": "783519"
  },
  {
    "text": "embeddings by the pre-trained model here",
    "start": "783519",
    "end": "787680"
  },
  {
    "text": "there are four emotions that this prim a",
    "start": "787680",
    "end": "789600"
  },
  {
    "text": "trained model looks for",
    "start": "789600",
    "end": "790880"
  },
  {
    "text": "which are fear joy sadness and surprise",
    "start": "790880",
    "end": "793440"
  },
  {
    "text": "and in this case",
    "start": "793440",
    "end": "794800"
  },
  {
    "text": "uh this as you can see with very high",
    "start": "794800",
    "end": "796800"
  },
  {
    "text": "confidence",
    "start": "796800",
    "end": "798240"
  },
  {
    "text": "this sentence qualified under the the",
    "start": "798240",
    "end": "800399"
  },
  {
    "text": "drawing motion",
    "start": "800399",
    "end": "803040"
  },
  {
    "start": "803000",
    "end": "803000"
  },
  {
    "text": "uh there are also other pre-trained",
    "start": "803040",
    "end": "804560"
  },
  {
    "text": "model for more you know classic",
    "start": "804560",
    "end": "805920"
  },
  {
    "text": "sentiment analysis",
    "start": "805920",
    "end": "807440"
  },
  {
    "text": "so any new dot load sentiment dot",
    "start": "807440",
    "end": "809360"
  },
  {
    "text": "predict i hate this guy semi",
    "start": "809360",
    "end": "811920"
  },
  {
    "text": "you can see that we have a certain",
    "start": "811920",
    "end": "813279"
  },
  {
    "text": "sentence sent in a certain confidence we",
    "start": "813279",
    "end": "815200"
  },
  {
    "text": "have the sentence",
    "start": "815200",
    "end": "816160"
  },
  {
    "text": "so here this is not at the token level",
    "start": "816160",
    "end": "817920"
  },
  {
    "text": "this is at the sentence level",
    "start": "817920",
    "end": "819440"
  },
  {
    "text": "and you can see that the sentiment is",
    "start": "819440",
    "end": "820959"
  },
  {
    "text": "negative okay so that's an example for",
    "start": "820959",
    "end": "823839"
  },
  {
    "text": "sentiment analysis now multiple",
    "start": "823839",
    "end": "825279"
  },
  {
    "text": "sentiment analysis and emotion models",
    "start": "825279",
    "end": "827760"
  },
  {
    "text": "that you can use another",
    "start": "827760",
    "end": "831040"
  },
  {
    "start": "830000",
    "end": "830000"
  },
  {
    "text": "a type of task that you can do as you",
    "start": "831040",
    "end": "832880"
  },
  {
    "text": "say among the you know 200",
    "start": "832880",
    "end": "834880"
  },
  {
    "text": "also models that are available is",
    "start": "834880",
    "end": "836800"
  },
  {
    "text": "language detection",
    "start": "836800",
    "end": "838639"
  },
  {
    "text": "uh and it's really it's you know it's",
    "start": "838639",
    "end": "841040"
  },
  {
    "text": "all the same format any",
    "start": "841040",
    "end": "842320"
  },
  {
    "text": "dot load link slang is the default model",
    "start": "842320",
    "end": "845279"
  },
  {
    "text": "for language detection",
    "start": "845279",
    "end": "846720"
  },
  {
    "text": "dot predict and in this case we don't",
    "start": "846720",
    "end": "848720"
  },
  {
    "text": "pass one string we pass an array with",
    "start": "848720",
    "end": "850720"
  },
  {
    "text": "two strings and as you can see in the",
    "start": "850720",
    "end": "853040"
  },
  {
    "text": "resulting data frame",
    "start": "853040",
    "end": "854480"
  },
  {
    "text": "you get two rows a row pair a per",
    "start": "854480",
    "end": "857279"
  },
  {
    "text": "sentence as there's a",
    "start": "857279",
    "end": "858639"
  },
  {
    "text": "id for each sentence so nlu is an open",
    "start": "858639",
    "end": "862560"
  },
  {
    "text": "source text processing library and so on",
    "start": "862560",
    "end": "864240"
  },
  {
    "text": "the language is english",
    "start": "864240",
    "end": "865680"
  },
  {
    "text": "with a 98.5 percent confidence",
    "start": "865680",
    "end": "869600"
  },
  {
    "text": "and an elio bibliotheque",
    "start": "869600",
    "end": "872720"
  },
  {
    "text": "is a french a language sentence",
    "start": "872720",
    "end": "875839"
  },
  {
    "text": "with a confidence of 99.98",
    "start": "875839",
    "end": "878959"
  },
  {
    "text": "um okay so that's another thing that",
    "start": "878959",
    "end": "882480"
  },
  {
    "text": "really",
    "start": "882480",
    "end": "883279"
  },
  {
    "text": "you know it's a one-liner you can pass",
    "start": "883279",
    "end": "885120"
  },
  {
    "text": "in strings you can pass an array or you",
    "start": "885120",
    "end": "887600"
  },
  {
    "text": "can pass a full data frame and get the",
    "start": "887600",
    "end": "889040"
  },
  {
    "text": "results",
    "start": "889040",
    "end": "889839"
  },
  {
    "text": "that way one other thing that's",
    "start": "889839",
    "end": "893440"
  },
  {
    "start": "892000",
    "end": "892000"
  },
  {
    "text": "that's popular to do is really use nlp",
    "start": "893440",
    "end": "895760"
  },
  {
    "text": "libraries to just calculate embeddings",
    "start": "895760",
    "end": "898160"
  },
  {
    "text": "uh sparkly lnp comes with a whole set of",
    "start": "898160",
    "end": "900800"
  },
  {
    "text": "them",
    "start": "900800",
    "end": "901199"
  },
  {
    "text": "uh you know embeddings for you know",
    "start": "901199",
    "end": "903279"
  },
  {
    "text": "different tastes and sizes and and uses",
    "start": "903279",
    "end": "905839"
  },
  {
    "text": "either world embeddings chunky bedding",
    "start": "905839",
    "end": "907760"
  },
  {
    "text": "sentencing weddings document embeddings",
    "start": "907760",
    "end": "910240"
  },
  {
    "text": "uh and er the nice thing you can do with",
    "start": "910240",
    "end": "912720"
  },
  {
    "text": "the nau library",
    "start": "912720",
    "end": "914160"
  },
  {
    "text": "is uh when you see in the example anywho",
    "start": "914160",
    "end": "917040"
  },
  {
    "text": "cloud",
    "start": "917040",
    "end": "917920"
  },
  {
    "text": "you don't just have one model that",
    "start": "917920",
    "end": "920320"
  },
  {
    "text": "you're calling but you have a string of",
    "start": "920320",
    "end": "922160"
  },
  {
    "text": "models",
    "start": "922160",
    "end": "923199"
  },
  {
    "text": "that are space separated and in this",
    "start": "923199",
    "end": "925920"
  },
  {
    "text": "case really",
    "start": "925920",
    "end": "926560"
  },
  {
    "text": "we just asked ask the system to",
    "start": "926560",
    "end": "928480"
  },
  {
    "text": "calculate different types of embeddings",
    "start": "928480",
    "end": "930399"
  },
  {
    "text": "so this is any little cloud and then we",
    "start": "930399",
    "end": "932000"
  },
  {
    "text": "ask give me you know bert",
    "start": "932000",
    "end": "933440"
  },
  {
    "text": "elmo albert excel net usd universal",
    "start": "933440",
    "end": "936720"
  },
  {
    "text": "sentence embeddings and glove embeddings",
    "start": "936720",
    "end": "939199"
  },
  {
    "text": "so basically what we tell the system is",
    "start": "939199",
    "end": "941440"
  },
  {
    "text": "load all of these six models for",
    "start": "941440",
    "end": "942959"
  },
  {
    "text": "embeddings",
    "start": "942959",
    "end": "943600"
  },
  {
    "text": "and calculate all of them on this",
    "start": "943600",
    "end": "945440"
  },
  {
    "text": "specific sentence",
    "start": "945440",
    "end": "946800"
  },
  {
    "text": "that we have here and you can see in the",
    "start": "946800",
    "end": "949199"
  },
  {
    "text": "resulting table that's exactly what you",
    "start": "949199",
    "end": "950800"
  },
  {
    "text": "get",
    "start": "950800",
    "end": "951279"
  },
  {
    "text": "you get per token you get the embeddings",
    "start": "951279",
    "end": "953920"
  },
  {
    "text": "all six embeddings for their token",
    "start": "953920",
    "end": "956000"
  },
  {
    "text": "right you get the glove embedding the",
    "start": "956000",
    "end": "957279"
  },
  {
    "text": "algorithm building excellent all of",
    "start": "957279",
    "end": "958880"
  },
  {
    "text": "those",
    "start": "958880",
    "end": "959680"
  },
  {
    "text": "and there are several dozen embeddings",
    "start": "959680",
    "end": "961680"
  },
  {
    "text": "that come you know",
    "start": "961680",
    "end": "963040"
  },
  {
    "text": "pre-built with spark nlp which are",
    "start": "963040",
    "end": "964639"
  },
  {
    "text": "basically all of the popular ones and",
    "start": "964639",
    "end": "966320"
  },
  {
    "text": "all the state-of-the-art ones",
    "start": "966320",
    "end": "967600"
  },
  {
    "text": "you'd expect one thing to know if you're",
    "start": "967600",
    "end": "970880"
  },
  {
    "text": "doing something like this it's super",
    "start": "970880",
    "end": "972480"
  },
  {
    "text": "useful",
    "start": "972480",
    "end": "973279"
  },
  {
    "text": "if really if you're doing",
    "start": "973279",
    "end": "974079"
  },
  {
    "text": "experimentation and you want to compare",
    "start": "974079",
    "end": "976000"
  },
  {
    "text": "different demandings you can just",
    "start": "976000",
    "end": "977360"
  },
  {
    "text": "calculate all of them at once which is",
    "start": "977360",
    "end": "979440"
  },
  {
    "text": "great",
    "start": "979440",
    "end": "981040"
  },
  {
    "text": "do pay attention to how much ram and how",
    "start": "981040",
    "end": "983120"
  },
  {
    "text": "much memory you are using",
    "start": "983120",
    "end": "984800"
  },
  {
    "text": "uh because uh the larger embeddings like",
    "start": "984800",
    "end": "987040"
  },
  {
    "text": "you know bear uh",
    "start": "987040",
    "end": "988639"
  },
  {
    "text": "excel net can be can go into several",
    "start": "988639",
    "end": "990720"
  },
  {
    "text": "gigabytes",
    "start": "990720",
    "end": "991680"
  },
  {
    "text": "and so make sure you have a lot of free",
    "start": "991680",
    "end": "993600"
  },
  {
    "text": "memory in the machine in which are",
    "start": "993600",
    "end": "995040"
  },
  {
    "text": "running this",
    "start": "995040",
    "end": "997440"
  },
  {
    "start": "997000",
    "end": "997000"
  },
  {
    "text": "so once you have embeddings there are",
    "start": "997440",
    "end": "999600"
  },
  {
    "text": "several other pre-trained models",
    "start": "999600",
    "end": "1001279"
  },
  {
    "text": "just use them under the hood and one of",
    "start": "1001279",
    "end": "1003839"
  },
  {
    "text": "them is fake effect news classifier",
    "start": "1003839",
    "end": "1006480"
  },
  {
    "text": "and in this case we do any lieu of",
    "start": "1006480",
    "end": "1010440"
  },
  {
    "text": "en.classified.fakenews",
    "start": "1010440",
    "end": "1011759"
  },
  {
    "text": "and this is really the fully qualified",
    "start": "1011759",
    "end": "1013440"
  },
  {
    "text": "name of the pre-trained model so if this",
    "start": "1013440",
    "end": "1015279"
  },
  {
    "text": "was your french for example it would be",
    "start": "1015279",
    "end": "1016959"
  },
  {
    "text": "fr dot classified",
    "start": "1016959",
    "end": "1018160"
  },
  {
    "text": "fake news and there's the namespace that",
    "start": "1018160",
    "end": "1021360"
  },
  {
    "text": "enables this scale and here we predict",
    "start": "1021360",
    "end": "1024558"
  },
  {
    "text": "you know we want to see what happens if",
    "start": "1024559",
    "end": "1026079"
  },
  {
    "text": "we ask it whether unicorns have been",
    "start": "1026079",
    "end": "1027918"
  },
  {
    "text": "cited on mars",
    "start": "1027919",
    "end": "1029360"
  },
  {
    "text": "and what he tells us in this case with",
    "start": "1029360",
    "end": "1031038"
  },
  {
    "text": "the confidence of one and this is fake",
    "start": "1031039",
    "end": "1033360"
  },
  {
    "text": "which is what we'd expect",
    "start": "1033360",
    "end": "1035120"
  },
  {
    "text": "we also get the sentence embeddings as",
    "start": "1035120",
    "end": "1036798"
  },
  {
    "text": "part of the result right in case you",
    "start": "1036799",
    "end": "1038640"
  },
  {
    "text": "want to use them",
    "start": "1038640",
    "end": "1040079"
  },
  {
    "text": "further",
    "start": "1040079",
    "end": "1042480"
  },
  {
    "start": "1043000",
    "end": "1043000"
  },
  {
    "text": "another pretend classifier is a spam",
    "start": "1043360",
    "end": "1045280"
  },
  {
    "text": "classifier that also comes pre-built as",
    "start": "1045280",
    "end": "1047839"
  },
  {
    "text": "part of",
    "start": "1047839",
    "end": "1049039"
  },
  {
    "text": "part of nlu so so angular.load",
    "start": "1049039",
    "end": "1052520"
  },
  {
    "text": "en.classify.spam",
    "start": "1052520",
    "end": "1053679"
  },
  {
    "text": "predict please sign up for this free",
    "start": "1053679",
    "end": "1055600"
  },
  {
    "text": "membership blah blah",
    "start": "1055600",
    "end": "1057120"
  },
  {
    "text": "and in this specific case you get a",
    "start": "1057120",
    "end": "1059440"
  },
  {
    "text": "pandas data frame as always you get the",
    "start": "1059440",
    "end": "1061360"
  },
  {
    "text": "sentence you get the id",
    "start": "1061360",
    "end": "1062799"
  },
  {
    "text": "and you get the category which is spam",
    "start": "1062799",
    "end": "1064480"
  },
  {
    "text": "in this case as well as the category",
    "start": "1064480",
    "end": "1066080"
  },
  {
    "text": "confidence and one more example there's",
    "start": "1066080",
    "end": "1069840"
  },
  {
    "start": "1069000",
    "end": "1069000"
  },
  {
    "text": "also a sarcasm classif",
    "start": "1069840",
    "end": "1071200"
  },
  {
    "text": "a classifier that comes pre-built",
    "start": "1071200",
    "end": "1074720"
  },
  {
    "text": "so any ludo cloud en dot",
    "start": "1074720",
    "end": "1077400"
  },
  {
    "text": "classified.sarcasm",
    "start": "1077400",
    "end": "1078799"
  },
  {
    "text": "got a lot of the teachers who give exams",
    "start": "1078799",
    "end": "1080880"
  },
  {
    "text": "on the day after halloween",
    "start": "1080880",
    "end": "1082720"
  },
  {
    "text": "okay which is classified as sarcasm",
    "start": "1082720",
    "end": "1085840"
  },
  {
    "text": "with 99.9985",
    "start": "1085840",
    "end": "1088880"
  },
  {
    "text": "probability uh so we're not going to go",
    "start": "1088880",
    "end": "1094640"
  },
  {
    "text": "over all the examples but there's quite",
    "start": "1094640",
    "end": "1096160"
  },
  {
    "text": "a few of them",
    "start": "1096160",
    "end": "1097280"
  },
  {
    "text": "uh so over 200 right now but really",
    "start": "1097280",
    "end": "1100480"
  },
  {
    "text": "it was a two-week release cycle it's",
    "start": "1100480",
    "end": "1102720"
  },
  {
    "text": "really expected almost every other week",
    "start": "1102720",
    "end": "1104480"
  },
  {
    "text": "you should expect to see",
    "start": "1104480",
    "end": "1105679"
  },
  {
    "text": "more transformers more models more",
    "start": "1105679",
    "end": "1108320"
  },
  {
    "text": "languages that have been supported",
    "start": "1108320",
    "end": "1110559"
  },
  {
    "text": "and this is all public so you",
    "start": "1110559",
    "end": "1113919"
  },
  {
    "text": "you're welcome to visit github.com john",
    "start": "1113919",
    "end": "1116240"
  },
  {
    "text": "snow labs",
    "start": "1116240",
    "end": "1116960"
  },
  {
    "text": "slash sparkling llp then other releases",
    "start": "1116960",
    "end": "1119919"
  },
  {
    "text": "there you can see what's been released",
    "start": "1119919",
    "end": "1121440"
  },
  {
    "text": "say for example over the past year",
    "start": "1121440",
    "end": "1123360"
  },
  {
    "text": "and you can look at the rate of progress",
    "start": "1123360",
    "end": "1124880"
  },
  {
    "text": "in terms of both the algorithms as well",
    "start": "1124880",
    "end": "1126640"
  },
  {
    "text": "as the models",
    "start": "1126640",
    "end": "1129360"
  },
  {
    "text": "anywhere.johnsonlabs.com has the full",
    "start": "1129559",
    "end": "1131280"
  },
  {
    "text": "documentation",
    "start": "1131280",
    "end": "1132640"
  },
  {
    "text": "in terms of all the models that are",
    "start": "1132640",
    "end": "1133840"
  },
  {
    "text": "available basically all the names that",
    "start": "1133840",
    "end": "1135200"
  },
  {
    "text": "you're allowed to use",
    "start": "1135200",
    "end": "1136000"
  },
  {
    "text": "here",
    "start": "1136000",
    "end": "1138160"
  },
  {
    "text": "okay so we talked about a spike in lp",
    "start": "1139919",
    "end": "1142640"
  },
  {
    "text": "and what spark nlp",
    "start": "1142640",
    "end": "1143760"
  },
  {
    "text": "is and what it gives you and we spoke",
    "start": "1143760",
    "end": "1145840"
  },
  {
    "text": "about the nlu library",
    "start": "1145840",
    "end": "1147919"
  },
  {
    "text": "and which is really intended to be this",
    "start": "1147919",
    "end": "1149679"
  },
  {
    "text": "kind of very simple to use yet still",
    "start": "1149679",
    "end": "1151760"
  },
  {
    "text": "just as powerful",
    "start": "1151760",
    "end": "1153280"
  },
  {
    "text": "a python library and and one of the",
    "start": "1153280",
    "end": "1156559"
  },
  {
    "text": "things that we",
    "start": "1156559",
    "end": "1157520"
  },
  {
    "text": "we wanted nlu to be is to also be able",
    "start": "1157520",
    "end": "1160960"
  },
  {
    "text": "to scale",
    "start": "1160960",
    "end": "1161679"
  },
  {
    "text": "and be able to make a really make the",
    "start": "1161679",
    "end": "1163679"
  },
  {
    "text": "most of whatever hardware you have",
    "start": "1163679",
    "end": "1166160"
  },
  {
    "text": "in terms of you know speed in terms of",
    "start": "1166160",
    "end": "1168080"
  },
  {
    "text": "memory use in terms of ability to scale",
    "start": "1168080",
    "end": "1169919"
  },
  {
    "text": "to a cluster",
    "start": "1169919",
    "end": "1171120"
  },
  {
    "text": "yeah so we then we wanted to make it you",
    "start": "1171120",
    "end": "1173120"
  },
  {
    "text": "know very simple for people",
    "start": "1173120",
    "end": "1174720"
  },
  {
    "text": "but if we don't we really did want to",
    "start": "1174720",
    "end": "1177280"
  },
  {
    "text": "did not want to lose",
    "start": "1177280",
    "end": "1179120"
  },
  {
    "text": "the advantages that sparkly milky nlp",
    "start": "1179120",
    "end": "1181360"
  },
  {
    "text": "gives you around a",
    "start": "1181360",
    "end": "1182720"
  },
  {
    "text": "scalability and around speed and this is",
    "start": "1182720",
    "end": "1185520"
  },
  {
    "text": "where",
    "start": "1185520",
    "end": "1185840"
  },
  {
    "text": "a ray comes in so and here's how it",
    "start": "1185840",
    "end": "1189679"
  },
  {
    "start": "1188000",
    "end": "1188000"
  },
  {
    "text": "works",
    "start": "1189679",
    "end": "1190559"
  },
  {
    "text": "uh nlu",
    "start": "1190559",
    "end": "1193760"
  },
  {
    "text": "returns a pipeline and and then you can",
    "start": "1193760",
    "end": "1196960"
  },
  {
    "text": "call predict on that pipeline",
    "start": "1196960",
    "end": "1198799"
  },
  {
    "text": "and and you can you can pretty much send",
    "start": "1198799",
    "end": "1200480"
  },
  {
    "text": "it everything you'd expect to be able to",
    "start": "1200480",
    "end": "1202240"
  },
  {
    "text": "send in in python",
    "start": "1202240",
    "end": "1203760"
  },
  {
    "text": "it's so you can send a single string you",
    "start": "1203760",
    "end": "1206640"
  },
  {
    "text": "can send the list of strings",
    "start": "1206640",
    "end": "1208880"
  },
  {
    "text": "you can also directly send the pandas",
    "start": "1208880",
    "end": "1210480"
  },
  {
    "text": "data frame",
    "start": "1210480",
    "end": "1212000"
  },
  {
    "text": "okay or you can send the finders a",
    "start": "1212000",
    "end": "1213919"
  },
  {
    "text": "series right so you can send the whole",
    "start": "1213919",
    "end": "1215600"
  },
  {
    "text": "data frame",
    "start": "1215600",
    "end": "1216880"
  },
  {
    "text": "and then basically assume that the text",
    "start": "1216880",
    "end": "1218240"
  },
  {
    "text": "column is the main one it needs to",
    "start": "1218240",
    "end": "1220080"
  },
  {
    "text": "process or you can if you can see an",
    "start": "1220080",
    "end": "1222799"
  },
  {
    "text": "example on the right",
    "start": "1222799",
    "end": "1224000"
  },
  {
    "text": "you do nlu dot cloud sentiment dot",
    "start": "1224000",
    "end": "1225840"
  },
  {
    "text": "predict text df",
    "start": "1225840",
    "end": "1227360"
  },
  {
    "text": "and text and then you pick the specific",
    "start": "1227360",
    "end": "1229280"
  },
  {
    "text": "column or panda series",
    "start": "1229280",
    "end": "1231840"
  },
  {
    "text": "that you wanted to analyze but",
    "start": "1231840",
    "end": "1235200"
  },
  {
    "text": "there are three other things that you",
    "start": "1235200",
    "end": "1236400"
  },
  {
    "text": "can send er that nlu recognizes",
    "start": "1236400",
    "end": "1239600"
  },
  {
    "text": "natively which are a spark data frame an",
    "start": "1239600",
    "end": "1242640"
  },
  {
    "text": "apache spark data frame an apache ray",
    "start": "1242640",
    "end": "1244480"
  },
  {
    "text": "data frame",
    "start": "1244480",
    "end": "1245280"
  },
  {
    "text": "or a dusk data frame and those are three",
    "start": "1245280",
    "end": "1248480"
  },
  {
    "text": "different implementations of the pandas",
    "start": "1248480",
    "end": "1250240"
  },
  {
    "text": "api of the pandas dataframe",
    "start": "1250240",
    "end": "1252240"
  },
  {
    "text": "it is specifically intended to be able",
    "start": "1252240",
    "end": "1254640"
  },
  {
    "text": "to scale",
    "start": "1254640",
    "end": "1255760"
  },
  {
    "text": "either to use effectively multi-core",
    "start": "1255760",
    "end": "1258320"
  },
  {
    "text": "machines or large clusters",
    "start": "1258320",
    "end": "1260400"
  },
  {
    "text": "and our goal with nlu was to to enable",
    "start": "1260400",
    "end": "1263280"
  },
  {
    "text": "you",
    "start": "1263280",
    "end": "1263760"
  },
  {
    "text": "to really just you know if you have any",
    "start": "1263760",
    "end": "1265200"
  },
  {
    "text": "of that all those data frames you send",
    "start": "1265200",
    "end": "1267200"
  },
  {
    "text": "them in",
    "start": "1267200",
    "end": "1268320"
  },
  {
    "text": "the code is exactly as as you've seen so",
    "start": "1268320",
    "end": "1270480"
  },
  {
    "text": "far and basically just works faster and",
    "start": "1270480",
    "end": "1272720"
  },
  {
    "text": "better",
    "start": "1272720",
    "end": "1273679"
  },
  {
    "text": "okay so let's see how this looks like in",
    "start": "1273679",
    "end": "1275600"
  },
  {
    "text": "practice",
    "start": "1275600",
    "end": "1277840"
  },
  {
    "text": "um so modding is the open source",
    "start": "1277840",
    "end": "1280000"
  },
  {
    "text": "projects for implementing",
    "start": "1280000",
    "end": "1281600"
  },
  {
    "text": "a pandas on ray as well as panels on",
    "start": "1281600",
    "end": "1284240"
  },
  {
    "text": "dusk",
    "start": "1284240",
    "end": "1285200"
  },
  {
    "text": "the goal of the modding project is is to",
    "start": "1285200",
    "end": "1287200"
  },
  {
    "text": "enable you to use pandas but scale your",
    "start": "1287200",
    "end": "1289280"
  },
  {
    "text": "workflows by changing just one line of",
    "start": "1289280",
    "end": "1290880"
  },
  {
    "text": "code",
    "start": "1290880",
    "end": "1291760"
  },
  {
    "text": "and here's the line of code it's first",
    "start": "1291760",
    "end": "1293440"
  },
  {
    "text": "of all to install mode in enray on",
    "start": "1293440",
    "end": "1295520"
  },
  {
    "text": "apache array",
    "start": "1295520",
    "end": "1296400"
  },
  {
    "text": "you do pip install mode in array and you",
    "start": "1296400",
    "end": "1299120"
  },
  {
    "text": "specify you want the implementation in",
    "start": "1299120",
    "end": "1300960"
  },
  {
    "text": "contrast to the task",
    "start": "1300960",
    "end": "1302840"
  },
  {
    "text": "implementation and then the one line of",
    "start": "1302840",
    "end": "1305200"
  },
  {
    "text": "code that you change is instead of",
    "start": "1305200",
    "end": "1306640"
  },
  {
    "text": "import pandas spd",
    "start": "1306640",
    "end": "1308880"
  },
  {
    "text": "you do import modding dot pandas as pd",
    "start": "1308880",
    "end": "1312000"
  },
  {
    "text": "and that's it you're done modin.pandas",
    "start": "1312000",
    "end": "1316559"
  },
  {
    "text": "gives you basically the exact same data",
    "start": "1316559",
    "end": "1318400"
  },
  {
    "text": "frame almost the same",
    "start": "1318400",
    "end": "1320000"
  },
  {
    "text": "data frame api that pandas gives you not",
    "start": "1320000",
    "end": "1321919"
  },
  {
    "text": "everything is implemented",
    "start": "1321919",
    "end": "1323120"
  },
  {
    "text": "but most of the most useful",
    "start": "1323120",
    "end": "1326640"
  },
  {
    "text": "methods and functions are implemented",
    "start": "1326640",
    "end": "1329760"
  },
  {
    "text": "what it does on top of that is it",
    "start": "1329760",
    "end": "1332080"
  },
  {
    "text": "automatically discovers how much memory",
    "start": "1332080",
    "end": "1334159"
  },
  {
    "text": "you have how many cores you have",
    "start": "1334159",
    "end": "1336559"
  },
  {
    "text": "and and makes the most of them you can",
    "start": "1336559",
    "end": "1338880"
  },
  {
    "text": "also if you really want to you can",
    "start": "1338880",
    "end": "1340080"
  },
  {
    "text": "configure it",
    "start": "1340080",
    "end": "1341360"
  },
  {
    "text": "manually semi-manually but",
    "start": "1341360",
    "end": "1344559"
  },
  {
    "text": "the beautiful automagical experience is",
    "start": "1344559",
    "end": "1346400"
  },
  {
    "text": "when you just let it let it do its",
    "start": "1346400",
    "end": "1348400"
  },
  {
    "text": "its thing and uh this is from the uh the",
    "start": "1348400",
    "end": "1351440"
  },
  {
    "text": "modern",
    "start": "1351440",
    "end": "1352080"
  },
  {
    "text": "really just github repo so this you know",
    "start": "1352080",
    "end": "1353760"
  },
  {
    "text": "say we've not done this ourselves",
    "start": "1353760",
    "end": "1356320"
  },
  {
    "text": "but here's one example of being able to",
    "start": "1356320",
    "end": "1358640"
  },
  {
    "text": "fix really one of the most",
    "start": "1358640",
    "end": "1360159"
  },
  {
    "text": "annoying things about pandas which is",
    "start": "1360159",
    "end": "1362159"
  },
  {
    "text": "the fact that just does not use multiple",
    "start": "1362159",
    "end": "1363840"
  },
  {
    "text": "cores",
    "start": "1363840",
    "end": "1364960"
  },
  {
    "text": "which almost every even developer laptop",
    "start": "1364960",
    "end": "1368559"
  },
  {
    "text": "has today so",
    "start": "1368559",
    "end": "1373280"
  },
  {
    "text": "you use modems you use really ray uh",
    "start": "1373280",
    "end": "1376400"
  },
  {
    "text": "use you know with the pandas api on top",
    "start": "1376400",
    "end": "1378400"
  },
  {
    "text": "of it and",
    "start": "1378400",
    "end": "1379840"
  },
  {
    "text": "you gain the speed up uh either on a",
    "start": "1379840",
    "end": "1382480"
  },
  {
    "text": "single machine and you can also scale it",
    "start": "1382480",
    "end": "1384400"
  },
  {
    "text": "as ray scale",
    "start": "1384400",
    "end": "1385280"
  },
  {
    "text": "to multiple machines and the way modding",
    "start": "1385280",
    "end": "1388559"
  },
  {
    "text": "is designed",
    "start": "1388559",
    "end": "1389440"
  },
  {
    "text": "and the way it's been pitched is the",
    "start": "1389440",
    "end": "1391679"
  },
  {
    "text": "optimizing full data sets between one",
    "start": "1391679",
    "end": "1393440"
  },
  {
    "text": "megabyte and one terabyte",
    "start": "1393440",
    "end": "1395440"
  },
  {
    "text": "uh well basically what they're saying",
    "start": "1395440",
    "end": "1396640"
  },
  {
    "text": "look if you under one one megabyte you",
    "start": "1396640",
    "end": "1398480"
  },
  {
    "text": "might as well just use pandas because",
    "start": "1398480",
    "end": "1399919"
  },
  {
    "text": "really it's so small it just doesn't",
    "start": "1399919",
    "end": "1401120"
  },
  {
    "text": "matter",
    "start": "1401120",
    "end": "1402080"
  },
  {
    "text": "if you're over a terabyte you should",
    "start": "1402080",
    "end": "1403600"
  },
  {
    "text": "probably go to something like apache",
    "start": "1403600",
    "end": "1405039"
  },
  {
    "text": "spark",
    "start": "1405039",
    "end": "1406320"
  },
  {
    "text": "right or something that's really been",
    "start": "1406320",
    "end": "1407520"
  },
  {
    "text": "tested on kind of really large clusters",
    "start": "1407520",
    "end": "1410080"
  },
  {
    "text": "but most of the data set you know some",
    "start": "1410080",
    "end": "1412640"
  },
  {
    "text": "would say are actually",
    "start": "1412640",
    "end": "1413600"
  },
  {
    "text": "between those ranges and modding is",
    "start": "1413600",
    "end": "1416400"
  },
  {
    "text": "trying to really optimize for that",
    "start": "1416400",
    "end": "1418559"
  },
  {
    "text": "you know that scale",
    "start": "1418559",
    "end": "1421360"
  },
  {
    "text": "so uh now that",
    "start": "1421919",
    "end": "1425440"
  },
  {
    "start": "1424000",
    "end": "1424000"
  },
  {
    "text": "that we know that we can actually use",
    "start": "1425440",
    "end": "1428159"
  },
  {
    "text": "the nau library",
    "start": "1428159",
    "end": "1429520"
  },
  {
    "text": "with modding using ray let's see one",
    "start": "1429520",
    "end": "1433039"
  },
  {
    "text": "example that we haven't seen before a",
    "start": "1433039",
    "end": "1434640"
  },
  {
    "text": "very very popular nlp",
    "start": "1434640",
    "end": "1436240"
  },
  {
    "text": "use a use case which is named entity",
    "start": "1436240",
    "end": "1438080"
  },
  {
    "text": "recognition",
    "start": "1438080",
    "end": "1439600"
  },
  {
    "text": "so just looking at the code here what we",
    "start": "1439600",
    "end": "1441919"
  },
  {
    "text": "are looking to do",
    "start": "1441919",
    "end": "1443360"
  },
  {
    "text": "is a look at the sentence like angela",
    "start": "1443360",
    "end": "1445919"
  },
  {
    "text": "merkel from germany and the american",
    "start": "1445919",
    "end": "1447840"
  },
  {
    "text": "donald trump",
    "start": "1447840",
    "end": "1449360"
  },
  {
    "text": "don't share many opinions okay the goal",
    "start": "1449360",
    "end": "1452000"
  },
  {
    "text": "is to identify named entities in this",
    "start": "1452000",
    "end": "1454000"
  },
  {
    "text": "case to identify that angela merkel is a",
    "start": "1454000",
    "end": "1456000"
  },
  {
    "text": "person",
    "start": "1456000",
    "end": "1457440"
  },
  {
    "text": "germany is the country donald trump is a",
    "start": "1457440",
    "end": "1459760"
  },
  {
    "text": "person",
    "start": "1459760",
    "end": "1460559"
  },
  {
    "text": "and american here is not you know this",
    "start": "1460559",
    "end": "1463039"
  },
  {
    "text": "is not a country so usually",
    "start": "1463039",
    "end": "1464960"
  },
  {
    "text": "the other continentalists would be kind",
    "start": "1464960",
    "end": "1466480"
  },
  {
    "text": "of a miscellaneous entity",
    "start": "1466480",
    "end": "1468159"
  },
  {
    "text": "but you do want to identify similarly in",
    "start": "1468159",
    "end": "1470880"
  },
  {
    "text": "the second sentence",
    "start": "1470880",
    "end": "1472240"
  },
  {
    "text": "nalu is a library that solves many",
    "start": "1472240",
    "end": "1473760"
  },
  {
    "text": "machine learning problems similar to",
    "start": "1473760",
    "end": "1475279"
  },
  {
    "text": "keras or tensorflow",
    "start": "1475279",
    "end": "1476799"
  },
  {
    "text": "we want to identify nlu keras and terms",
    "start": "1476799",
    "end": "1479520"
  },
  {
    "text": "of flow in a basic is kind of",
    "start": "1479520",
    "end": "1481039"
  },
  {
    "text": "as entities uh and this is useful",
    "start": "1481039",
    "end": "1484559"
  },
  {
    "text": "if you're trying to do a you know build",
    "start": "1484559",
    "end": "1486559"
  },
  {
    "text": "knowledge graphs",
    "start": "1486559",
    "end": "1488400"
  },
  {
    "text": "understand who are you talking about be",
    "start": "1488400",
    "end": "1490960"
  },
  {
    "text": "able to do anything you know even things",
    "start": "1490960",
    "end": "1492400"
  },
  {
    "text": "like your question answering a search",
    "start": "1492400",
    "end": "1495200"
  },
  {
    "text": "in many many nlp applications name any",
    "start": "1495200",
    "end": "1498559"
  },
  {
    "text": "recognition or nar in short",
    "start": "1498559",
    "end": "1500720"
  },
  {
    "text": "is a very fundamental task a",
    "start": "1500720",
    "end": "1503840"
  },
  {
    "text": "spark nlp and hence the nlu library they",
    "start": "1503840",
    "end": "1506640"
  },
  {
    "text": "come with a set of pre-trained ner",
    "start": "1506640",
    "end": "1508400"
  },
  {
    "text": "models",
    "start": "1508400",
    "end": "1509520"
  },
  {
    "text": "for quite a few languages here we're",
    "start": "1509520",
    "end": "1511520"
  },
  {
    "text": "going to use the one in english",
    "start": "1511520",
    "end": "1513279"
  },
  {
    "text": "and here's how the code looks so we",
    "start": "1513279",
    "end": "1514880"
  },
  {
    "text": "define the data and you see",
    "start": "1514880",
    "end": "1516480"
  },
  {
    "text": "the data we basically just defined",
    "start": "1516480",
    "end": "1520240"
  },
  {
    "text": "here a table with just one column text",
    "start": "1520559",
    "end": "1523919"
  },
  {
    "text": "and two",
    "start": "1523919",
    "end": "1524480"
  },
  {
    "text": "rows we create a molding data frame",
    "start": "1524480",
    "end": "1528000"
  },
  {
    "text": "okay so it will speed",
    "start": "1528000",
    "end": "1531600"
  },
  {
    "text": "data from data it just so that you",
    "start": "1531600",
    "end": "1533840"
  },
  {
    "text": "believe us we're actually using gray and",
    "start": "1533840",
    "end": "1535120"
  },
  {
    "text": "we also type here the actual type so you",
    "start": "1535120",
    "end": "1536880"
  },
  {
    "text": "can see that you know",
    "start": "1536880",
    "end": "1537840"
  },
  {
    "text": "in the when you run the notebook it's",
    "start": "1537840",
    "end": "1539440"
  },
  {
    "text": "actually it's a data frame",
    "start": "1539440",
    "end": "1541360"
  },
  {
    "text": "and then we run a one-liner which is",
    "start": "1541360",
    "end": "1543279"
  },
  {
    "text": "annually.load ner",
    "start": "1543279",
    "end": "1544720"
  },
  {
    "text": "any alpha namely recognition and the",
    "start": "1544720",
    "end": "1546720"
  },
  {
    "text": "default here uses",
    "start": "1546720",
    "end": "1548400"
  },
  {
    "text": "um i believe one of the smaller built",
    "start": "1548400",
    "end": "1550400"
  },
  {
    "text": "embeddings in english",
    "start": "1550400",
    "end": "1552159"
  },
  {
    "text": "dot predict mode in the f okay so",
    "start": "1552159",
    "end": "1555200"
  },
  {
    "text": "basically run predict on the modern data",
    "start": "1555200",
    "end": "1556799"
  },
  {
    "text": "frame natively",
    "start": "1556799",
    "end": "1558080"
  },
  {
    "text": "and there are only three columns that we",
    "start": "1558080",
    "end": "1559760"
  },
  {
    "text": "want to get from the output which is the",
    "start": "1559760",
    "end": "1561200"
  },
  {
    "text": "the original document",
    "start": "1561200",
    "end": "1562960"
  },
  {
    "text": "uh the list of entities and then the uh",
    "start": "1562960",
    "end": "1565840"
  },
  {
    "text": "and we showed the anir column we chose",
    "start": "1565840",
    "end": "1567360"
  },
  {
    "text": "the pill token",
    "start": "1567360",
    "end": "1568640"
  },
  {
    "text": "how each token is classified and you can",
    "start": "1568640",
    "end": "1571039"
  },
  {
    "text": "see the result uh so",
    "start": "1571039",
    "end": "1572640"
  },
  {
    "text": "a document angela merkel from germany",
    "start": "1572640",
    "end": "1574559"
  },
  {
    "text": "and the american and so on that's a",
    "start": "1574559",
    "end": "1576240"
  },
  {
    "text": "document",
    "start": "1576240",
    "end": "1576960"
  },
  {
    "text": "you can see the three and the four",
    "start": "1576960",
    "end": "1578559"
  },
  {
    "text": "entities that were extracted so",
    "start": "1578559",
    "end": "1580080"
  },
  {
    "text": "angela merkel germany american and",
    "start": "1580080",
    "end": "1581919"
  },
  {
    "text": "donald trump",
    "start": "1581919",
    "end": "1583679"
  },
  {
    "text": "and you can see in the ner column uh",
    "start": "1583679",
    "end": "1585760"
  },
  {
    "text": "that the first two tokens so",
    "start": "1585760",
    "end": "1587360"
  },
  {
    "text": "b pair and hyper beeper means beginning",
    "start": "1587360",
    "end": "1589679"
  },
  {
    "text": "of a person entity",
    "start": "1589679",
    "end": "1591039"
  },
  {
    "text": "hyper means a continuation of a personal",
    "start": "1591039",
    "end": "1594159"
  },
  {
    "text": "entity all means nothing",
    "start": "1594159",
    "end": "1595919"
  },
  {
    "text": "so angela is the beginning is the of a",
    "start": "1595919",
    "end": "1598240"
  },
  {
    "text": "person merkel is there of a person from",
    "start": "1598240",
    "end": "1600400"
  },
  {
    "text": "is",
    "start": "1600400",
    "end": "1600799"
  },
  {
    "text": "nothing germany is a country so it's be",
    "start": "1600799",
    "end": "1603360"
  },
  {
    "text": "location",
    "start": "1603360",
    "end": "1604159"
  },
  {
    "text": "and so on so if you don't just want the",
    "start": "1604159",
    "end": "1606480"
  },
  {
    "text": "entities but you want token by token to",
    "start": "1606480",
    "end": "1608240"
  },
  {
    "text": "understand what belongs",
    "start": "1608240",
    "end": "1609520"
  },
  {
    "text": "where you have that as well",
    "start": "1609520",
    "end": "1612640"
  },
  {
    "text": "so that's name entity recognition and we",
    "start": "1612640",
    "end": "1614880"
  },
  {
    "text": "said you know still a one-liner",
    "start": "1614880",
    "end": "1616640"
  },
  {
    "text": "even though we're using here a modding",
    "start": "1616640",
    "end": "1618240"
  },
  {
    "text": "data set and if it will allow you that's",
    "start": "1618240",
    "end": "1620080"
  },
  {
    "text": "it",
    "start": "1620080",
    "end": "1620559"
  },
  {
    "text": "you'll definitely benefit from the speed",
    "start": "1620559",
    "end": "1622240"
  },
  {
    "text": "of using at least a multi-core machine",
    "start": "1622240",
    "end": "1625840"
  },
  {
    "text": "to summarize going back to the first",
    "start": "1625840",
    "end": "1627760"
  },
  {
    "start": "1626000",
    "end": "1626000"
  },
  {
    "text": "example we looked at at spell checking",
    "start": "1627760",
    "end": "1630320"
  },
  {
    "text": "uh this time on ray uh so",
    "start": "1630320",
    "end": "1633440"
  },
  {
    "text": "uh we look at the we define the data so",
    "start": "1633440",
    "end": "1636159"
  },
  {
    "text": "we have",
    "start": "1636159",
    "end": "1636720"
  },
  {
    "text": "a we define a modern data frame with one",
    "start": "1636720",
    "end": "1639440"
  },
  {
    "text": "series one",
    "start": "1639440",
    "end": "1640000"
  },
  {
    "text": "column which is called text and has in",
    "start": "1640000",
    "end": "1642080"
  },
  {
    "text": "this case two rows",
    "start": "1642080",
    "end": "1644000"
  },
  {
    "text": "right so the same thing we define the",
    "start": "1644000",
    "end": "1645760"
  },
  {
    "text": "data frame from the data here",
    "start": "1645760",
    "end": "1647600"
  },
  {
    "text": "and we run nlu.load a spell dot predict",
    "start": "1647600",
    "end": "1651360"
  },
  {
    "text": "mode in df exactly the exact same as we",
    "start": "1651360",
    "end": "1654080"
  },
  {
    "text": "did before",
    "start": "1654080",
    "end": "1654880"
  },
  {
    "text": "and only that instead of sending a",
    "start": "1654880",
    "end": "1656559"
  },
  {
    "text": "regular pandas data frame or instead of",
    "start": "1656559",
    "end": "1658399"
  },
  {
    "text": "just sending a string",
    "start": "1658399",
    "end": "1659760"
  },
  {
    "text": "we send you know we send the array data",
    "start": "1659760",
    "end": "1662080"
  },
  {
    "text": "frame",
    "start": "1662080",
    "end": "1663679"
  },
  {
    "text": "and you can see the results which is",
    "start": "1663679",
    "end": "1665760"
  },
  {
    "text": "really what you get",
    "start": "1665760",
    "end": "1667440"
  },
  {
    "text": "what you will get back is a modding data",
    "start": "1667440",
    "end": "1669440"
  },
  {
    "text": "frame and one thing that spoken alou",
    "start": "1669440",
    "end": "1671279"
  },
  {
    "text": "does is basically it returns the same",
    "start": "1671279",
    "end": "1673440"
  },
  {
    "text": "type of data frame that you gave it",
    "start": "1673440",
    "end": "1675440"
  },
  {
    "text": "so if you give it pandas you get back",
    "start": "1675440",
    "end": "1676880"
  },
  {
    "text": "pandas you give it ray you get back",
    "start": "1676880",
    "end": "1678399"
  },
  {
    "text": "right",
    "start": "1678399",
    "end": "1680080"
  },
  {
    "text": "and when you print it here's what you",
    "start": "1680080",
    "end": "1681840"
  },
  {
    "text": "get so you can see that we",
    "start": "1681840",
    "end": "1683440"
  },
  {
    "text": "we have the token column which has the",
    "start": "1683440",
    "end": "1684799"
  },
  {
    "text": "original tokens but then we also have",
    "start": "1684799",
    "end": "1686720"
  },
  {
    "text": "the checked columns",
    "start": "1686720",
    "end": "1687840"
  },
  {
    "text": "so you can see that i like peanut butter",
    "start": "1687840",
    "end": "1689600"
  },
  {
    "text": "and jelly and actually the words",
    "start": "1689600",
    "end": "1691520"
  },
  {
    "text": "like peanut butter and the jelly were",
    "start": "1691520",
    "end": "1693919"
  },
  {
    "text": "corrected",
    "start": "1693919",
    "end": "1695520"
  },
  {
    "text": "and similarly the words sundays and the",
    "start": "1695520",
    "end": "1698559"
  },
  {
    "text": "word days",
    "start": "1698559",
    "end": "1700080"
  },
  {
    "text": "were also corrected here correct by the",
    "start": "1700080",
    "end": "1701919"
  },
  {
    "text": "spell checking algorithm",
    "start": "1701919",
    "end": "1704320"
  },
  {
    "text": "okay so as you see you get the",
    "start": "1704320",
    "end": "1706480"
  },
  {
    "text": "advantages of prey",
    "start": "1706480",
    "end": "1707760"
  },
  {
    "text": "you get the benefit it is under the hood",
    "start": "1707760",
    "end": "1710320"
  },
  {
    "text": "but you don't need to learn in your api",
    "start": "1710320",
    "end": "1713200"
  },
  {
    "text": "and really it's a you know it's kind of",
    "start": "1713200",
    "end": "1715440"
  },
  {
    "text": "a one-line change",
    "start": "1715440",
    "end": "1716559"
  },
  {
    "text": "instead of importing pandas you import",
    "start": "1716559",
    "end": "1718799"
  },
  {
    "text": "modern dot pandas and basically all that",
    "start": "1718799",
    "end": "1722080"
  },
  {
    "text": "if you're interested in trying this as",
    "start": "1722080",
    "end": "1723520"
  },
  {
    "text": "we said you know we build this for you",
    "start": "1723520",
    "end": "1725360"
  },
  {
    "text": "so yeah you know it's free it's for the",
    "start": "1725360",
    "end": "1726880"
  },
  {
    "text": "community uh we'd love you to try it",
    "start": "1726880",
    "end": "1729039"
  },
  {
    "text": "we'd love to get your feedback",
    "start": "1729039",
    "end": "1730799"
  },
  {
    "text": "uh to install it people install enelio",
    "start": "1730799",
    "end": "1733120"
  },
  {
    "text": "for the documentation",
    "start": "1733120",
    "end": "1734320"
  },
  {
    "text": "other notebooks other examples any",
    "start": "1734320",
    "end": "1736840"
  },
  {
    "text": "documents.com",
    "start": "1736840",
    "end": "1738159"
  },
  {
    "text": "if there are any questions please uh you",
    "start": "1738159",
    "end": "1741200"
  },
  {
    "text": "know email us",
    "start": "1741200",
    "end": "1742080"
  },
  {
    "text": "there's also a very active slack",
    "start": "1742080",
    "end": "1744320"
  },
  {
    "text": "community",
    "start": "1744320",
    "end": "1745279"
  },
  {
    "text": "that has i think several hundred people",
    "start": "1745279",
    "end": "1746799"
  },
  {
    "text": "per day now asking questions and sharing",
    "start": "1746799",
    "end": "1749520"
  },
  {
    "text": "tips so if you have any issue",
    "start": "1749520",
    "end": "1751360"
  },
  {
    "text": "that people will be able to help you in",
    "start": "1751360",
    "end": "1753200"
  },
  {
    "text": "the same day",
    "start": "1753200",
    "end": "1754559"
  },
  {
    "text": "uh personally i i'd love to hear from",
    "start": "1754559",
    "end": "1756960"
  },
  {
    "text": "you you know if you have",
    "start": "1756960",
    "end": "1758720"
  },
  {
    "text": "any ideas if you have questions if",
    "start": "1758720",
    "end": "1760480"
  },
  {
    "text": "things are not working so you'd expect",
    "start": "1760480",
    "end": "1762320"
  },
  {
    "text": "it",
    "start": "1762320",
    "end": "1763600"
  },
  {
    "text": "or you know just to share the project",
    "start": "1763600",
    "end": "1765440"
  },
  {
    "text": "you're working please feel free to",
    "start": "1765440",
    "end": "1767120"
  },
  {
    "text": "contact me email twitter",
    "start": "1767120",
    "end": "1768960"
  },
  {
    "text": "linkedin i'm always curious to know what",
    "start": "1768960",
    "end": "1771600"
  },
  {
    "text": "people are doing",
    "start": "1771600",
    "end": "1772720"
  },
  {
    "text": "thank you very much for listening and",
    "start": "1772720",
    "end": "1774240"
  },
  {
    "text": "best of luck with your natural language",
    "start": "1774240",
    "end": "1775840"
  },
  {
    "text": "processing projects",
    "start": "1775840",
    "end": "1779679"
  }
]
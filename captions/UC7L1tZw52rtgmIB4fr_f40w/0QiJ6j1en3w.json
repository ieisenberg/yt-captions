[
  {
    "text": "hi everyone good afternoon thank you for joining our session uh we have two",
    "start": "4120",
    "end": "9440"
  },
  {
    "text": "speakers co-presenting The Talk today um one is the How Lee our founder",
    "start": "9440",
    "end": "17640"
  },
  {
    "text": "and CEO luxu and myself founding engineer of VP technology of luxu the topic today is making data access easy",
    "start": "17640",
    "end": "24599"
  },
  {
    "text": "and fast for Ray uh before start let's do a small pull here how many of you",
    "start": "24599",
    "end": "30080"
  },
  {
    "text": "have heard of luxu before raise your hands wait actually I see a good like",
    "start": "30080",
    "end": "36120"
  },
  {
    "text": "number maybe 10 or 15 people and how many of you are doing training large",
    "start": "36120",
    "end": "42120"
  },
  {
    "text": "scale training using maybe hundred of different GPU cards one or two three four okay and how",
    "start": "42120",
    "end": "49960"
  },
  {
    "text": "many of you are doing maybe large data processing uh not just related to",
    "start": "49960",
    "end": "55480"
  },
  {
    "text": "training but maybe also data uh Big Data query or data analytics data processing",
    "start": "55480",
    "end": "62680"
  },
  {
    "text": "okay I think maybe onethird of the people in this in this room good good so",
    "start": "62680",
    "end": "67840"
  },
  {
    "text": "I think this talk will be re given the distribution is pretty even I think this talk will be relevant to you guys okay",
    "start": "67840",
    "end": "74000"
  },
  {
    "text": "so uh first let's introduce ourselves I'm Ben uh VP of Technology alexio",
    "start": "74000",
    "end": "79119"
  },
  {
    "text": "founding engineers alexio and we also have how and Lee our CEO and founder So today we're going to talk about uh data",
    "start": "79119",
    "end": "86400"
  },
  {
    "text": "access challenges in the AI and the Machine learning in the setting and specifically because this is the summit",
    "start": "86400",
    "end": "92360"
  },
  {
    "text": "for Ray and we want to really highlight the story playing with a loio and read",
    "start": "92360",
    "end": "99200"
  },
  {
    "text": "together what is the benefits we can see here and how like even why people want to think about this stock and we also",
    "start": "99200",
    "end": "106119"
  },
  {
    "text": "want to show some numbers and The Benchmark okay so first of all Ray",
    "start": "106119",
    "end": "113640"
  },
  {
    "text": "that's the that's reason we are here right for this Summit it's a distributed designed for distributed training has a",
    "start": "113640",
    "end": "120399"
  },
  {
    "text": "distribute scheduler so it can has very efficient dispatch training jobs to",
    "start": "120399",
    "end": "126079"
  },
  {
    "text": "available CPU and gpus resource optimizing the resource utilization also we provides",
    "start": "126079",
    "end": "133440"
  },
  {
    "text": "you many times some model uh model modelers very similarly to scaling",
    "start": "133440",
    "end": "140519"
  },
  {
    "text": "horizontally of applications um for example you can write a python project",
    "start": "140519",
    "end": "145560"
  },
  {
    "text": "maybe with running at a small scale even a single machine and then you can use really easily scale your projects your",
    "start": "145560",
    "end": "152360"
  },
  {
    "text": "your jobs to hundreds of thousands of different notes ensure the but also",
    "start": "152360",
    "end": "157560"
  },
  {
    "text": "ensuring the Optimal Performance at this scale right also have the streaming data",
    "start": "157560",
    "end": "162760"
  },
  {
    "text": "abstraction to provide to facilitate the parallel and distribute the data Pro pre-processing to accelerate the",
    "start": "162760",
    "end": "169120"
  },
  {
    "text": "workflow by handling the data streams efficiently okay so uh when I'm talking",
    "start": "169120",
    "end": "175280"
  },
  {
    "text": "to people in the r Community I'm I'm saying hey I'm I'm doing a Luxio and Ali",
    "start": "175280",
    "end": "180760"
  },
  {
    "text": "provides a data access or data caching layer for Ray and also for other machine",
    "start": "180760",
    "end": "186280"
  },
  {
    "text": "learning Frameworks I I got two common questions for myself okay one is how is",
    "start": "186280",
    "end": "193280"
  },
  {
    "text": "this related to uh Object Store in Ray one is how this is related to the ray",
    "start": "193280",
    "end": "199640"
  },
  {
    "text": "data okay so let's first of all take a look at what is the ray data so Ray data",
    "start": "199640",
    "end": "205360"
  },
  {
    "text": "is uh was announced last year when I was also here in the r Summit so it was a scalable data processing Library allows",
    "start": "205360",
    "end": "213439"
  },
  {
    "text": "the ray to process to to provide the streaming data sets for re applications",
    "start": "213439",
    "end": "219760"
  },
  {
    "text": "and it breaks down the large data set into smallable small and manageable chunks and divide the training jobs into",
    "start": "219760",
    "end": "227439"
  },
  {
    "text": "smaller tasks and assign the the basically it's a very well-designed data",
    "start": "227439",
    "end": "232640"
  },
  {
    "text": "loading process for many TR applications so we have seen very good results from",
    "start": "232640",
    "end": "237680"
  },
  {
    "text": "the if you see if you remember this is blog uh published announced last year in the re Summit uh very very very very",
    "start": "237680",
    "end": "245439"
  },
  {
    "text": "encouraging results from the re data so put in that way Ray data is more like a",
    "start": "245439",
    "end": "252000"
  },
  {
    "text": "data abstraction or more like a data loading process data loading",
    "start": "252000",
    "end": "258000"
  },
  {
    "text": "framework to help read jobs to get data in a queue or in the message queue to uh",
    "start": "258000",
    "end": "265440"
  },
  {
    "text": "to the to schedule the nodes well alexio is a data platform it provides you the data caching",
    "start": "265440",
    "end": "273280"
  },
  {
    "text": "capability so if you have a data um for example special locality spatial",
    "start": "273280",
    "end": "278960"
  },
  {
    "text": "locality or temporal locality which means you have different training jobs and if they access the same set of data",
    "start": "278960",
    "end": "286560"
  },
  {
    "text": "repeatedly in in different jobs or like in the in a relatively small time window",
    "start": "286560",
    "end": "292240"
  },
  {
    "text": "and you can benefit from having the data cached closer to re jobs to your GPU",
    "start": "292240",
    "end": "297800"
  },
  {
    "text": "applications so that is what how Ray data is different from Alo one is Ray",
    "start": "297800",
    "end": "302919"
  },
  {
    "text": "data is more like a data loading and dat data loading process data loading framework alio is like a horizontal but",
    "start": "302919",
    "end": "309520"
  },
  {
    "text": "independent uh framework to provide a caching capability so I will show later",
    "start": "309520",
    "end": "314720"
  },
  {
    "text": "how R data works together with alio and then why this works okay but okay so basically we have Ray",
    "start": "314720",
    "end": "324199"
  },
  {
    "text": "data we have R object drawer but still we are seeing this is I we get some screenshots from the uh R slack so",
    "start": "324199",
    "end": "331400"
  },
  {
    "text": "people are still asking questions especially they have this repeatedly loaded entire and big data set for each",
    "start": "331400",
    "end": "338639"
  },
  {
    "text": "each training ook and they want to share frequently accessed data across multiple",
    "start": "338639",
    "end": "343880"
  },
  {
    "text": "different training jobs or they are suffering from cold start every training iteration with a relatively slow or",
    "start": "343880",
    "end": "351360"
  },
  {
    "text": "congested storage so um we were serving the boots in the morning uh actually we",
    "start": "351360",
    "end": "357240"
  },
  {
    "text": "get a lot of actually re users asking questions like this I have situations like this because this is Cross jobs or",
    "start": "357240",
    "end": "366120"
  },
  {
    "text": "sometimes it's cross different regions then how can uh so Ray data is not designed for this purpose so how can you",
    "start": "366120",
    "end": "373280"
  },
  {
    "text": "help us improve the performance and also reduce the cost implication Beyond this",
    "start": "373280",
    "end": "379280"
  },
  {
    "text": "providing this streaming uh interface so that's why we're talking about alio in this picture okay uh let's take one step",
    "start": "379280",
    "end": "387400"
  },
  {
    "text": "back if I'm going to train data at scale in the cloud using GPU there are",
    "start": "387400",
    "end": "392800"
  },
  {
    "text": "typically three options to access data for the training data set okay uh",
    "start": "392800",
    "end": "397840"
  },
  {
    "text": "because we we all know how large the data set this today it requires to train",
    "start": "397840",
    "end": "403400"
  },
  {
    "text": "the model the very first one is you can just ask your training applications to access",
    "start": "403400",
    "end": "410520"
  },
  {
    "text": "data stored in your data Lake maybe on S3 or GC GCS directly well it's easy to",
    "start": "410520",
    "end": "416759"
  },
  {
    "text": "manage because you always the the data Lake on the cloud is a designed to be",
    "start": "416759",
    "end": "421960"
  },
  {
    "text": "very scalable and it's a designed to be uh for example the single source of TOS",
    "start": "421960",
    "end": "427160"
  },
  {
    "text": "across this entire organization so it's easy it's easy to manage um but the",
    "start": "427160",
    "end": "433080"
  },
  {
    "text": "problem is if you see uh this is from time to time people are complaining about this U if it's on AWS this uh",
    "start": "433080",
    "end": "440879"
  },
  {
    "text": "status code 503 which means slow down slow down okay you're reading too much",
    "start": "440879",
    "end": "445960"
  },
  {
    "text": "you're reading too fast so that is basically the a push back uh from this storage slow or inconsistent performance",
    "start": "445960",
    "end": "453680"
  },
  {
    "text": "across the entire duration but also high cost in the access cloud storage so we",
    "start": "453680",
    "end": "459080"
  },
  {
    "text": "have a a join case study with Uber and also CMU talking we're just basically",
    "start": "459080",
    "end": "465000"
  },
  {
    "text": "getting uh some data from the um from the Tes and we found actually it's very",
    "start": "465000",
    "end": "470720"
  },
  {
    "text": "high it's very expensive if you just keep requesting data even this a small amount of data from the cloud because",
    "start": "470720",
    "end": "476759"
  },
  {
    "text": "that's how the charging the pricing model works there okay the second option we see a lot is",
    "start": "476759",
    "end": "482960"
  },
  {
    "text": "really to purchase another highspeed sometimes HPC storage and putting this",
    "start": "482960",
    "end": "489080"
  },
  {
    "text": "close to the training infrastructure so this high-speed or HPC storage provides",
    "start": "489080",
    "end": "494879"
  },
  {
    "text": "the fast access to these training jobs but the problem so you get a very good",
    "start": "494879",
    "end": "499960"
  },
  {
    "text": "IO iOS per second high throughput like there are HBC storage designed for this",
    "start": "499960",
    "end": "505520"
  },
  {
    "text": "uh for a decade so there's a lot of available options there well the problem is this typically they",
    "start": "505520",
    "end": "512399"
  },
  {
    "text": "are relatively costly uh infrastructure and plus often times it requires extra",
    "start": "512399",
    "end": "519640"
  },
  {
    "text": "steps to do the data migration and data maintainance um plus if you also have",
    "start": "519640",
    "end": "526880"
  },
  {
    "text": "multiple different training Frameworks sorry training uh resources in different regions or even cross the cloud then you",
    "start": "526880",
    "end": "535480"
  },
  {
    "text": "have and you still want to maintain the single source of tooth using the single data Lake then you have to guide you",
    "start": "535480",
    "end": "541480"
  },
  {
    "text": "have to buy two different this kind of solutions which is even more expensive okay so we have seen customers uh asking",
    "start": "541480",
    "end": "549160"
  },
  {
    "text": "questions like this a lot basically they think this is not scalable especially given the today GPU scarcity is still",
    "start": "549160",
    "end": "556560"
  },
  {
    "text": "kind of like a norm and people try to just allocate their gpus whenever they can get gpus across different Cloud",
    "start": "556560",
    "end": "563760"
  },
  {
    "text": "providers or across even like different regions so this becomes also cost but",
    "start": "563760",
    "end": "570040"
  },
  {
    "text": "still it get good the performance the tradeoff you have to make well uh another interesting point",
    "start": "570040",
    "end": "577519"
  },
  {
    "text": "we are seeing is typically less than 10% data of your entire data set is hot so",
    "start": "577519",
    "end": "584640"
  },
  {
    "text": "to me this is basically a classical caching problem so add another caching",
    "start": "584640",
    "end": "589880"
  },
  {
    "text": "layer between the computer and data Lake instead of purchasing more storage uh expensive storage okay so uh we have",
    "start": "589880",
    "end": "598200"
  },
  {
    "text": "seen this kind of like we propose this solution hey if you have this problem think about this architecture instead of",
    "start": "598200",
    "end": "604880"
  },
  {
    "text": "having another storage expansive and you have to maintain it put in a caching",
    "start": "604880",
    "end": "610240"
  },
  {
    "text": "layer respect your data Lake and this caching layer can be relatively uh can",
    "start": "610240",
    "end": "615959"
  },
  {
    "text": "be cheaper than HPC storage but also it performs as good or even better than this storage because they are purposely",
    "start": "615959",
    "end": "624160"
  },
  {
    "text": "designed for the machine learning type of workloads uh we talk about later like why what why there's a chance like even",
    "start": "624160",
    "end": "630519"
  },
  {
    "text": "doing it better there okay so essentially adding a data access or caching layer between the compute and",
    "start": "630519",
    "end": "636360"
  },
  {
    "text": "this data L Storage can preserve your single source for choose from data L but",
    "start": "636360",
    "end": "641760"
  },
  {
    "text": "also solve the high demand for iops per second high throughput and share this",
    "start": "641760",
    "end": "646800"
  },
  {
    "text": "cat can cross different uh Ai workloads and",
    "start": "646800",
    "end": "652120"
  },
  {
    "text": "analytics okay so you get all these pron and you get a fast data access from hot",
    "start": "652560",
    "end": "658399"
  },
  {
    "text": "data cached so you don't have to PCH by the way if you have a say 10 pedabytes of the entirety of the data you don't",
    "start": "658399",
    "end": "665000"
  },
  {
    "text": "have to purchase the uh you don't have to provision a cach with 10 pedabytes is",
    "start": "665000",
    "end": "670920"
  },
  {
    "text": "not necessary you just need to think about like what is the amount of the capacity you need for one the largest",
    "start": "670920",
    "end": "677880"
  },
  {
    "text": "training job or the concurrent uh training capacity you need okay so that's can be much smaller than the",
    "start": "677880",
    "end": "684200"
  },
  {
    "text": "entirety of the uh data set so let's go back think about it in the ray ecosystem",
    "start": "684200",
    "end": "691360"
  },
  {
    "text": "okay so what we are providing as a luxu is really a caching layer to provide high performance distributed caching on",
    "start": "691360",
    "end": "698079"
  },
  {
    "text": "top of this persistent storage persistent data link on S3 or Azure or GCS and you can run the machine learning",
    "start": "698079",
    "end": "705480"
  },
  {
    "text": "Frameworks like a p torch or tensor flow on top of that and orchestrated by Ray",
    "start": "705480",
    "end": "711120"
  },
  {
    "text": "so that is how we view this stack uh Hy you can talk about the next",
    "start": "711120",
    "end": "716720"
  },
  {
    "text": "few slides all right so hear me all right thank you so uh",
    "start": "716720",
    "end": "723720"
  },
  {
    "text": "thank you been pleasure to be here uh at the race Summit so I'm going to uh talk a little bit about the uh uh ALU history",
    "start": "723720",
    "end": "731920"
  },
  {
    "text": "as well as ALU plus Ray so from the very high level like alio we serve data to",
    "start": "731920",
    "end": "738160"
  },
  {
    "text": "all the data driven applications like AI like uh large skill analytics etra and",
    "start": "738160",
    "end": "744199"
  },
  {
    "text": "in this particular setting so it is the key tagline if you one sentence you",
    "start": "744199",
    "end": "750079"
  },
  {
    "text": "remember it's alexio salar AI so we have many many case studies so essentially",
    "start": "750079",
    "end": "756560"
  },
  {
    "text": "from this uh like a figure you can see in the uh architecture or in ecosystem",
    "start": "756560",
    "end": "763839"
  },
  {
    "text": "how the stacks looks like you have different type of a AI Compu Frameworks",
    "start": "763839",
    "end": "769720"
  },
  {
    "text": "on top of a lock seal and can run and this environment uh this framework plus",
    "start": "769720",
    "end": "776399"
  },
  {
    "text": "alio can run in different type of environment different clouds as well say on Prime as",
    "start": "776399",
    "end": "782360"
  },
  {
    "text": "well and in the meantime alio will abstract and virtualize the data from",
    "start": "782360",
    "end": "790079"
  },
  {
    "text": "different storage environments it could be any object store any file system you",
    "start": "790079",
    "end": "796279"
  },
  {
    "text": "are using today so essentially from this perspective uh people deploy alio very",
    "start": "796279",
    "end": "804800"
  },
  {
    "text": "close to the compute side AI Frameworks and use a lual to provide the easy data",
    "start": "804800",
    "end": "813279"
  },
  {
    "text": "access using the global namespace to provide the easy data access of the data",
    "start": "813279",
    "end": "818519"
  },
  {
    "text": "stored in different storage systems and also use alus distributed caching feature to accelerate the read of the",
    "start": "818519",
    "end": "827320"
  },
  {
    "text": "data in a very significant way so this is a high level how like the uh like the",
    "start": "827320",
    "end": "834560"
  },
  {
    "text": "uh Stacks looks like and the goal of this framework a go like your system",
    "start": "834560",
    "end": "841000"
  },
  {
    "text": "also try to make the uper layers developers job as easy as possible",
    "start": "841000",
    "end": "848000"
  },
  {
    "text": "besides like bringing the performance acceleration ease of data access also it",
    "start": "848000",
    "end": "854519"
  },
  {
    "text": "will enable as long as you deploy this in your infrastructure you do not need",
    "start": "854519",
    "end": "860519"
  },
  {
    "text": "your application developers to change a single line of their code whatever",
    "start": "860519",
    "end": "867120"
  },
  {
    "text": "worked before it should automatically work essentially and you will see all",
    "start": "867120",
    "end": "873360"
  },
  {
    "text": "different type of performance improvements or uh work efficent work efficiency Improvement and we have use",
    "start": "873360",
    "end": "881000"
  },
  {
    "text": "cases later on talk about like how using like Ray or different type of Frameworks",
    "start": "881000",
    "end": "887519"
  },
  {
    "text": "running on top of a Lo seal change the training job from 4 hours to be 1 hour",
    "start": "887519",
    "end": "893759"
  },
  {
    "text": "from four weeks to be one week that means that like say uh for the machine",
    "start": "893759",
    "end": "900040"
  },
  {
    "text": "learning Engineers running on your platform instead of finishing their job",
    "start": "900040",
    "end": "905199"
  },
  {
    "text": "over a year time frame they prob can finish over 3 to four month which is significant boost this is a uh high",
    "start": "905199",
    "end": "913680"
  },
  {
    "text": "level and then uh just to talk a little bit regarding our technology Journey",
    "start": "913680",
    "end": "920759"
  },
  {
    "text": "it's a um open source software started from the UC Berkeley around 10 years ago",
    "start": "920759",
    "end": "926839"
  },
  {
    "text": "and at the beginning as actually very quickly at the beginning we have some uh",
    "start": "926839",
    "end": "932240"
  },
  {
    "text": "large like uh internet users start to run a luux seal in production and along",
    "start": "932240",
    "end": "938480"
  },
  {
    "text": "the way you can see at the beginning big data analytics Cloud adoption and now",
    "start": "938480",
    "end": "943880"
  },
  {
    "text": "it's Ai and you can see along the way we have today uh nine out of the 10 largest",
    "start": "943880",
    "end": "951720"
  },
  {
    "text": "market cap internet companies they are all running the software in production today and uh one of the largest fintech",
    "start": "951720",
    "end": "959480"
  },
  {
    "text": "company alipe they're running 80% their model training on top of this framework",
    "start": "959480",
    "end": "965199"
  },
  {
    "text": "on top of this system as well and many Global leading e-commerce company",
    "start": "965199",
    "end": "970759"
  },
  {
    "text": "running this uh software uh in production as well and this is a just slightly some",
    "start": "970759",
    "end": "978440"
  },
  {
    "text": "logos on the uh on the picture to show the company are running the software uh",
    "start": "978440",
    "end": "983639"
  },
  {
    "text": "in production today as you can see majority of these companies there are a",
    "start": "983639",
    "end": "988959"
  },
  {
    "text": "Tech forward company uh typically as SL you have a lot of data you have a lot of",
    "start": "988959",
    "end": "994920"
  },
  {
    "text": "data in your environment if your business rely on the data itself a lot",
    "start": "994920",
    "end": "1000399"
  },
  {
    "text": "of times they'll find more value of uh uh deploying and using a software like",
    "start": "1000399",
    "end": "1006519"
  },
  {
    "text": "alux and uh it's a tech internet Financial Service e-commerce Telo and",
    "start": "1006519",
    "end": "1012959"
  },
  {
    "text": "media sucha and like be mentioned from the AI perspective if you have ai",
    "start": "1012959",
    "end": "1019560"
  },
  {
    "text": "training side if you have model deployment if you have model serving",
    "start": "1019560",
    "end": "1024760"
  },
  {
    "text": "it's just the alexio will accelerate your AI Journey that's a uh what we",
    "start": "1024760",
    "end": "1031918"
  },
  {
    "text": "do so uh we have some open source uh topic here I would leave it to bin to uh",
    "start": "1031919",
    "end": "1038240"
  },
  {
    "text": "further uh further uh explain this different uh usage and the liit history as well and welcome any uh like",
    "start": "1038240",
    "end": "1046000"
  },
  {
    "text": "conversation afterward as well thank you okay uh I'm coming back to the stage",
    "start": "1046000",
    "end": "1051600"
  },
  {
    "text": "basically uh this is a I I steal the slides from Hy uh this is uh he did this",
    "start": "1051600",
    "end": "1057160"
  },
  {
    "text": "slide maybe 10 more than 10 years ago when this is do the UC brookly Retreat UC brookly M Retreat so uh during the",
    "start": "1057160",
    "end": "1064280"
  },
  {
    "text": "school days this is this project was called taang it's it's meant to be designed for Reliable memory Centric",
    "start": "1064280",
    "end": "1070520"
  },
  {
    "text": "distribut storage for off Heap storage uh off Heap storage for rdds in spark",
    "start": "1070520",
    "end": "1077240"
  },
  {
    "text": "but later on we make this is a more general purpose storage but essentially yeah so this is has a lot of long",
    "start": "1077240",
    "end": "1083240"
  },
  {
    "text": "history uh root also rooted from Berkeley and get a lot open source adoption in the early",
    "start": "1083240",
    "end": "1089960"
  },
  {
    "text": "days uh so in the early days it's more like designed I basically I'm just",
    "start": "1089960",
    "end": "1095440"
  },
  {
    "text": "sharing the journey sharing the Journey of this uh open source project and how it goes to the AI ml workflows in the",
    "start": "1095440",
    "end": "1101600"
  },
  {
    "text": "early days is heavily modeled after hdfs if you're familiar hdfs has the single U",
    "start": "1101600",
    "end": "1107360"
  },
  {
    "text": "name node as a med service and different data nodes as the you you shed workers",
    "start": "1107360",
    "end": "1112440"
  },
  {
    "text": "shed data to different data nodes okay so it's heavily modeled after hdfs but also have the unique concept called",
    "start": "1112440",
    "end": "1118919"
  },
  {
    "text": "Ender Ender storage so if the data is stored uh cached in the worker and then",
    "start": "1118919",
    "end": "1124000"
  },
  {
    "text": "you have you don't have to go to the Ender storage data cache uh cash hit otherwise you go to on the cach M you go",
    "start": "1124000",
    "end": "1129919"
  },
  {
    "text": "to Ender storage and the metadata there's also metadata in early days uh we all know name note is a bad design uh",
    "start": "1129919",
    "end": "1137320"
  },
  {
    "text": "in hdfs but still um you don't have the huge amount of the de you don't have the huge demand to store uh billions of",
    "start": "1137320",
    "end": "1144480"
  },
  {
    "text": "files or you have the Federation to solve the problem but uh also in the similar SP Spirit we're using a raft to",
    "start": "1144480",
    "end": "1151640"
  },
  {
    "text": "to coordinate a different master master is very similar to uh name note as centralized medor service okay problems",
    "start": "1151640",
    "end": "1159960"
  },
  {
    "text": "okay uh maybe about three to four years ago we start to see problems if you are using this architecture to serve this",
    "start": "1159960",
    "end": "1166039"
  },
  {
    "text": "machine learning training problem especially the hdfs interface versus posix like different object stores uh",
    "start": "1166039",
    "end": "1172880"
  },
  {
    "text": "sorry latest uh Frameworks they they like to use posic apis and also in early",
    "start": "1172880",
    "end": "1179039"
  },
  {
    "text": "days they are yarn they deployed on bare metal this days is all kubernetes uh",
    "start": "1179039",
    "end": "1184360"
  },
  {
    "text": "early days it's more like a structured data but these days we uh in in the parket files or RC files for Big Data",
    "start": "1184360",
    "end": "1192240"
  },
  {
    "text": "query engines but these days for multim model model training you see more and more unstructured data in all picture",
    "start": "1192240",
    "end": "1199440"
  },
  {
    "text": "video picture or text okay man service performance also becomes critical",
    "start": "1199440",
    "end": "1205159"
  },
  {
    "text": "especially for this multim model training we have seen uh one of largest deployment of Luxio they are using Luxio",
    "start": "1205159",
    "end": "1211840"
  },
  {
    "text": "serve one pedabytes of data and more than one billion files for one training",
    "start": "1211840",
    "end": "1217400"
  },
  {
    "text": "jobs so this is a you cannot imagine this like in the Big Data World highly concurrent jobs because they're using",
    "start": "1217400",
    "end": "1224159"
  },
  {
    "text": "gpus and what also in the training duration is from hours to days weeks to",
    "start": "1224159",
    "end": "1229480"
  },
  {
    "text": "train the job which means reliability becomes the key also model checkpointing uh takes the GPU time down so we also",
    "start": "1229480",
    "end": "1237080"
  },
  {
    "text": "want to make sure like users want to make sure faster rides through checkpointing checkpointing the model becomes really CR uh crucial okay so we",
    "start": "1237080",
    "end": "1246080"
  },
  {
    "text": "we architector allows you to help this type of workloads so essentially uh today it's there is no single point of",
    "start": "1246080",
    "end": "1253120"
  },
  {
    "text": "failure we removed this master node instead we have this uh different work",
    "start": "1253120",
    "end": "1258600"
  },
  {
    "text": "workers using consistent hashing to coordinate workers and data Shing to workers so we don't have to always go to",
    "start": "1258600",
    "end": "1265799"
  },
  {
    "text": "the master to get where data is just like in htfs uh aside from that there's a lot of also optimizations to enable",
    "start": "1265799",
    "end": "1273440"
  },
  {
    "text": "zero copy and other items so essentially uh yeah under the hood we use consistent",
    "start": "1273440",
    "end": "1278720"
  },
  {
    "text": "hashing to cash both the data and the metadata on workers to reduce the io RPC Lun uh also no single point of failure",
    "start": "1278720",
    "end": "1285440"
  },
  {
    "text": "to get improved reliability no performance B on the master because there's no master and remove the master",
    "start": "1285440",
    "end": "1291400"
  },
  {
    "text": "from the critical pass so no more Journal Journal is not required anymore to store the file system state so all",
    "start": "1291400",
    "end": "1298080"
  },
  {
    "text": "this along with the other resource and performance optimizations they are heavily heavily inspired by hey we have",
    "start": "1298080",
    "end": "1305640"
  },
  {
    "text": "this training type of workloads it's read heavy uh or sometimes read only I only need to write is to checkpointing",
    "start": "1305640",
    "end": "1312720"
  },
  {
    "text": "these models okay so we can get rid of a lot of assumptions and also uh it's",
    "start": "1312720",
    "end": "1317960"
  },
  {
    "text": "perhaps like a doing this uh simpler we we have a s we have a smaller set of",
    "start": "1317960",
    "end": "1324600"
  },
  {
    "text": "apis exposed to this applications or they only use a smaller set of applications so we can get rid of like a",
    "start": "1324600",
    "end": "1331240"
  },
  {
    "text": "lot of complicated design to coordinate uh like file lock the directory lock",
    "start": "1331240",
    "end": "1336679"
  },
  {
    "text": "these type of things so key features Byer numbers so we can",
    "start": "1336679",
    "end": "1343840"
  },
  {
    "text": "get a TENS of gigabytes per worker and because it's a consistent hashing you can scale",
    "start": "1343840",
    "end": "1349120"
  },
  {
    "text": "the total system throughput by adding more workers almost linearly okay uh",
    "start": "1349120",
    "end": "1354159"
  },
  {
    "text": "caching PR loading we redesigned this system so we get a fully we can fully almost always fully utilize the storage",
    "start": "1354159",
    "end": "1361320"
  },
  {
    "text": "network uh to load data to this storage to the luxus space low latency uh we",
    "start": "1361320",
    "end": "1367159"
  },
  {
    "text": "have seen like we can achieve sub milliseconds or single digit uh milliseconds latency for faster response",
    "start": "1367159",
    "end": "1374640"
  },
  {
    "text": "uh in comparison if you use S3 the typical latency you see is like 100",
    "start": "1374640",
    "end": "1379840"
  },
  {
    "text": "milliseconds so that's a two folds of two 's magnitude is better skining",
    "start": "1379840",
    "end": "1385760"
  },
  {
    "text": "linearly in capacity just blindly you can just add workers according to consistent hashing and we're able to",
    "start": "1385760",
    "end": "1391760"
  },
  {
    "text": "support tens of billions of objects and files which is super important for today's machine learning workloads High",
    "start": "1391760",
    "end": "1398600"
  },
  {
    "text": "availability we want to make sure there's no single point of failure no single Med centralized Med service so",
    "start": "1398600",
    "end": "1404799"
  },
  {
    "text": "the model training jobs can succeed like if you're running multiple uh days or",
    "start": "1404799",
    "end": "1410559"
  },
  {
    "text": "weeks okay ray okay so last Summit when I was here uh we were talking about hey",
    "start": "1410559",
    "end": "1417240"
  },
  {
    "text": "we can use the posix API to talk to to let R to read alexio but that sounds",
    "start": "1417240",
    "end": "1422640"
  },
  {
    "text": "cool but still there's one more steps okay so after that we have been working",
    "start": "1422640",
    "end": "1427840"
  },
  {
    "text": "closely uh with the with this Ray stack so Ray is using p AR underneath to read",
    "start": "1427840",
    "end": "1433919"
  },
  {
    "text": "data from different storage engines and Pyro is using a library card of as a spec it's in Python so we also",
    "start": "1433919",
    "end": "1440159"
  },
  {
    "text": "implemented the uh what the the fs pack implementation for alux so now we can",
    "start": "1440159",
    "end": "1446640"
  },
  {
    "text": "you this is a this is also a recommended approach to integrating r with alio we",
    "start": "1446640",
    "end": "1452240"
  },
  {
    "text": "don't have to go through the fuse or yeah fuse API to get there's a lot of",
    "start": "1452240",
    "end": "1457880"
  },
  {
    "text": "limitation there but essentially this is a sample code uh we're working on to even simplify this even simplify this uh",
    "start": "1457880",
    "end": "1464039"
  },
  {
    "text": "Ray how the integration with aray by just respecting a lot of the python apis",
    "start": "1464039",
    "end": "1470520"
  },
  {
    "text": "okay uh I have five minutes I try to go fast okay Benchmark so uh a typical Benchmark",
    "start": "1470520",
    "end": "1477279"
  },
  {
    "text": "people are doing this in the machine learning World on storage side is a micro Benchmark called I or there's also",
    "start": "1477279",
    "end": "1484399"
  },
  {
    "text": "micro Benchmark called the ml ml perf okay so I only show the fio Benchmark",
    "start": "1484399",
    "end": "1489960"
  },
  {
    "text": "here so we compare alio uh the AI 32 which is not even not the latest version",
    "start": "1489960",
    "end": "1495320"
  },
  {
    "text": "actually we have a better one now uh with some scale Nas solution and also",
    "start": "1495320",
    "end": "1500440"
  },
  {
    "text": "with a uh HPC storage like FSX which is based on lure so as you can see uh this",
    "start": "1500440",
    "end": "1507159"
  },
  {
    "text": "is on the AWS we can uh Luxio can provid much better uh throughput especially",
    "start": "1507159",
    "end": "1514200"
  },
  {
    "text": "even under the heavy load of a lot of concurrent reads uh this is for I think",
    "start": "1514200",
    "end": "1520559"
  },
  {
    "text": "this is for uh I forget this is for random reads or for oh sequential sequential reads so this is basically uh",
    "start": "1520559",
    "end": "1528320"
  },
  {
    "text": "we're able to achieve uh with one thread we can get 2 gigabytes and with 32",
    "start": "1528320",
    "end": "1533880"
  },
  {
    "text": "threads we Peak to uh 81 sorry 8 gigabytes so this is what we can provide",
    "start": "1533880",
    "end": "1541960"
  },
  {
    "text": "here um another interesting like as I mentioned earlier uh Ray has the ray",
    "start": "1542039",
    "end": "1548000"
  },
  {
    "text": "data which is the data data loading library or pipeline to help recore to to",
    "start": "1548000",
    "end": "1556039"
  },
  {
    "text": "get data more pipelining okay so we have done this uh rid data versus using R",
    "start": "1556039",
    "end": "1563240"
  },
  {
    "text": "data on top of Luxio on S3 and we're saying we're able to uh even speed up",
    "start": "1563240",
    "end": "1569640"
  },
  {
    "text": "this is n to end throughput which is image per sec this is doing the CV training we're able to improve that by",
    "start": "1569640",
    "end": "1576360"
  },
  {
    "text": "uh 3.5x and we're running the same Benchmark uh using used by the ray uh r",
    "start": "1576360",
    "end": "1584679"
  },
  {
    "text": "ray block like we have the the official block uh lastly just want to show one simple",
    "start": "1584679",
    "end": "1591679"
  },
  {
    "text": "use case this is uh how users are viewing this technology and how they can use this for their machine learning",
    "start": "1591679",
    "end": "1597960"
  },
  {
    "text": "pipeline in production okay this is already in production so in the middle column this is a this is a called",
    "start": "1597960",
    "end": "1604880"
  },
  {
    "text": "offline Cloud this is their data Lake they have this using hdfs as the centralized data Lake they want to C",
    "start": "1604880",
    "end": "1611200"
  },
  {
    "text": "have a single sourcer choose okay but they also have the training uh infrastructure in one cloud and also",
    "start": "1611200",
    "end": "1617720"
  },
  {
    "text": "have the online serving Cloud for a different uh in infrastructure for on a",
    "start": "1617720",
    "end": "1623760"
  },
  {
    "text": "different Cloud okay so what they have done is to use aluu uh to",
    "start": "1623760",
    "end": "1629480"
  },
  {
    "text": "basically Bridge their different clouds in different different regions for sure",
    "start": "1629480",
    "end": "1636159"
  },
  {
    "text": "and uh once the training uh you can use aluu to serve the training by speeding",
    "start": "1636159",
    "end": "1641360"
  },
  {
    "text": "up the training process but also after data is served to the training Pipeline",
    "start": "1641360",
    "end": "1646440"
  },
  {
    "text": "and the model files are created we can also help speed up this the time",
    "start": "1646440",
    "end": "1652720"
  },
  {
    "text": "to make these models available on this inferencing Cloud okay so that's that",
    "start": "1652720",
    "end": "1657760"
  },
  {
    "text": "was shown on the right hand side so first of all on the training side we're able to improve this is training GP",
    "start": "1657760",
    "end": "1664640"
  },
  {
    "text": "utilization from 50 to 93% but also on the uh model distribution or model",
    "start": "1664640",
    "end": "1671519"
  },
  {
    "text": "deployment site were able to reduce their uh original time to disseminate",
    "start": "1671519",
    "end": "1677200"
  },
  {
    "text": "the model files from this centralized data link to this different model influencing machines from 20 minutes to",
    "start": "1677200",
    "end": "1684120"
  },
  {
    "text": "5 minutes and this is they're doing the online training uh online model training",
    "start": "1684120",
    "end": "1689200"
  },
  {
    "text": "and online learning and this is super critical for them to increase this uh user engagement so we're able to get two",
    "start": "1689200",
    "end": "1697240"
  },
  {
    "text": "to 4X faster time to Market okay uh the key takeaway uh we are help we can help",
    "start": "1697240",
    "end": "1703799"
  },
  {
    "text": "overcoming IO bottleneck in a scalable AI training so uh ALU can help",
    "start": "1703799",
    "end": "1708840"
  },
  {
    "text": "accelerate AI uh we can maximize the efficiency uh with array Plus alio in",
    "start": "1708840",
    "end": "1714440"
  },
  {
    "text": "the setting um have two minutes left so maybe take one",
    "start": "1714440",
    "end": "1720559"
  },
  {
    "text": "question okay can you share a little bit about your cashing strategy so like for",
    "start": "1720559",
    "end": "1726840"
  },
  {
    "text": "example if I want to I know that in the next five minutes I will need to",
    "start": "1726840",
    "end": "1732360"
  },
  {
    "text": "download like some specific R can iic it through the cing lay to download",
    "start": "1732360",
    "end": "1738559"
  },
  {
    "text": "yeah so we're not in the level of rows and the the question is what's the",
    "start": "1738559",
    "end": "1743840"
  },
  {
    "text": "caching strategy uh we caty catching strategy we're supporting here especially he's talking about in the",
    "start": "1743840",
    "end": "1750000"
  },
  {
    "text": "next five in the in five minutes we're going to use these five rows and how we can do that okay so first of all let me",
    "start": "1750000",
    "end": "1756679"
  },
  {
    "text": "just clarify we're not doing a so files are like we're orthogonal to files like",
    "start": "1756679",
    "end": "1764200"
  },
  {
    "text": "we're serving files bite to bite identical to what is stored on S3 so we do not understand if if each row if if",
    "start": "1764200",
    "end": "1771200"
  },
  {
    "text": "the file has multiple different rows we do not understand which part of the bytes in this file belongs to which role",
    "start": "1771200",
    "end": "1777279"
  },
  {
    "text": "okay so that is not understand by alexu but go back to a question so if you have",
    "start": "1777279",
    "end": "1783360"
  },
  {
    "text": "a knowledge which part of the files in this data set will be needed for next",
    "start": "1783360",
    "end": "1789159"
  },
  {
    "text": "training jobs in settings like this we have the uh I just mentioned briefly we have the command you can run to preload",
    "start": "1789159",
    "end": "1796159"
  },
  {
    "text": "the data into Luxio so that's one approach okay just preload the data into",
    "start": "1796159",
    "end": "1802200"
  },
  {
    "text": "into the cache but if you do this passively so which means the part you touched in this big data set will be",
    "start": "1802200",
    "end": "1810200"
  },
  {
    "text": "passively lift to the caching space and the benefits of that is if the file is",
    "start": "1810200",
    "end": "1817360"
  },
  {
    "text": "like for example it's a parket files we have seen cases from customers only the only the header and Footers are needed a",
    "start": "1817360",
    "end": "1825760"
  },
  {
    "text": "lot so uh in if there a passively loaded it's perhaps uh we do not even need to",
    "start": "1825760",
    "end": "1832399"
  },
  {
    "text": "load the majority of the data part only the fot and parter footer and and a",
    "start": "1832399",
    "end": "1837640"
  },
  {
    "text": "header so that is another way so we have seen customers using uh they have a",
    "start": "1837640",
    "end": "1843440"
  },
  {
    "text": "pedabytes of the data Lake all parking files on S3 they want to really reduce the access latency or increase the",
    "start": "1843440",
    "end": "1851399"
  },
  {
    "text": "serving concurrency to this uh Park files or to this data lake so they just",
    "start": "1851399",
    "end": "1856679"
  },
  {
    "text": "deploy another aloy layer on this paret data link okay uh basically to back to",
    "start": "1856679",
    "end": "1862880"
  },
  {
    "text": "answer so if you know which file you want to read in the next five minutes you can run a command to preload the data or you can just rely on some",
    "start": "1862880",
    "end": "1870200"
  },
  {
    "text": "passively you can just run the data query uh like a ahead of time to",
    "start": "1870200",
    "end": "1875600"
  },
  {
    "text": "exercise which part of data to be lifted yeah and then you also",
    "start": "1875600",
    "end": "1881760"
  },
  {
    "text": "can p sorry yeah we can we can we can yes yes yes so the granularity is pretty",
    "start": "1881760",
    "end": "1888159"
  },
  {
    "text": "small it's like on the order of megabytes you can configure configure that yeah thank",
    "start": "1888159",
    "end": "1896039"
  },
  {
    "text": "you okay uh we'll be here so welcome to uh to find us me or Hy uh to answer more",
    "start": "1896039",
    "end": "1902360"
  },
  {
    "text": "questions please the oh yes",
    "start": "1902360",
    "end": "1907840"
  },
  {
    "text": "yes yeah we have the boots on S7 and you can scan this QR code uh we have a to",
    "start": "1907840",
    "end": "1914799"
  },
  {
    "text": "learn about resource and meetups coming meetups thank you thank you",
    "start": "1914799",
    "end": "1923080"
  }
]
[
  {
    "text": "hello oh sweet okay",
    "start": "5779",
    "end": "9000"
  },
  {
    "text": "um hey guys",
    "start": "9000",
    "end": "10080"
  },
  {
    "text": "um thanks for the thanks for the",
    "start": "10080",
    "end": "11400"
  },
  {
    "text": "wonderful introduction uh my name is",
    "start": "11400",
    "end": "13019"
  },
  {
    "text": "Jerry I'm co-founder CEO of lava index",
    "start": "13019",
    "end": "15780"
  },
  {
    "text": "um and today the talk will be practical",
    "start": "15780",
    "end": "17460"
  },
  {
    "text": "data considerations uh for building",
    "start": "17460",
    "end": "19500"
  },
  {
    "text": "production-ready llm applications",
    "start": "19500",
    "end": "22560"
  },
  {
    "text": "um uh Lama index by the way is open",
    "start": "22560",
    "end": "24840"
  },
  {
    "text": "source framework for building LM apps of",
    "start": "24840",
    "end": "27000"
  },
  {
    "text": "your data we came up with the name the",
    "start": "27000",
    "end": "28980"
  },
  {
    "text": "week before Mata released their model so",
    "start": "28980",
    "end": "31199"
  },
  {
    "text": "I just wanted to point that out I feel",
    "start": "31199",
    "end": "33120"
  },
  {
    "text": "like I have to point that out to at",
    "start": "33120",
    "end": "34500"
  },
  {
    "text": "every talk I go to anyhow",
    "start": "34500",
    "end": "36960"
  },
  {
    "text": "um let's talk about retrieval augmented",
    "start": "36960",
    "end": "39360"
  },
  {
    "text": "Generation",
    "start": "39360",
    "end": "40680"
  },
  {
    "text": "Um how many of you guys know what",
    "start": "40680",
    "end": "41640"
  },
  {
    "text": "retrieval augmented generation is I",
    "start": "41640",
    "end": "43320"
  },
  {
    "text": "would give a show of hands okay sweet",
    "start": "43320",
    "end": "45059"
  },
  {
    "text": "that's basically everybody awesome okay",
    "start": "45059",
    "end": "46620"
  },
  {
    "text": "so we call it rag for short",
    "start": "46620",
    "end": "49260"
  },
  {
    "text": "um and the overall context here is that",
    "start": "49260",
    "end": "51180"
  },
  {
    "text": "llms are a phenomenal piece of",
    "start": "51180",
    "end": "53280"
  },
  {
    "text": "technology for knowledge generation and",
    "start": "53280",
    "end": "55140"
  },
  {
    "text": "reasoning um they're pre-trained on",
    "start": "55140",
    "end": "56820"
  },
  {
    "text": "large amounts of publicly available data",
    "start": "56820",
    "end": "58500"
  },
  {
    "text": "but it turns out they can actually",
    "start": "58500",
    "end": "59760"
  },
  {
    "text": "reason over new information as well and",
    "start": "59760",
    "end": "61920"
  },
  {
    "text": "you can use them to answer questions uh",
    "start": "61920",
    "end": "64140"
  },
  {
    "text": "to summarize stuff like generate a bunch",
    "start": "64140",
    "end": "66180"
  },
  {
    "text": "of texts like plan out stuff automate",
    "start": "66180",
    "end": "68040"
  },
  {
    "text": "your workflows",
    "start": "68040",
    "end": "69540"
  },
  {
    "text": "and I think the key question here is",
    "start": "69540",
    "end": "71460"
  },
  {
    "text": "just how do you best augment language",
    "start": "71460",
    "end": "73200"
  },
  {
    "text": "models with our own private data um if",
    "start": "73200",
    "end": "75119"
  },
  {
    "text": "you've been to basically some of our",
    "start": "75119",
    "end": "76920"
  },
  {
    "text": "previous talks these are basically the",
    "start": "76920",
    "end": "78240"
  },
  {
    "text": "two slides that we start with but that",
    "start": "78240",
    "end": "79799"
  },
  {
    "text": "really is the mission statement of the",
    "start": "79799",
    "end": "81540"
  },
  {
    "text": "company is to figure out how do you",
    "start": "81540",
    "end": "83159"
  },
  {
    "text": "unleash the capabilities of LMS with all",
    "start": "83159",
    "end": "85920"
  },
  {
    "text": "the reasoning power on top of data that",
    "start": "85920",
    "end": "88259"
  },
  {
    "text": "it's not that it hasn't been trained",
    "start": "88259",
    "end": "90060"
  },
  {
    "text": "over",
    "start": "90060",
    "end": "91860"
  },
  {
    "text": "so a brief note on Lama indexes it's a",
    "start": "91860",
    "end": "94860"
  },
  {
    "text": "data framework for L on apps it's a data",
    "start": "94860",
    "end": "97860"
  },
  {
    "text": "management and query engine for your llm",
    "start": "97860",
    "end": "100020"
  },
  {
    "text": "application so we offer a very robust",
    "start": "100020",
    "end": "102659"
  },
  {
    "text": "production ready toolkit across the data",
    "start": "102659",
    "end": "105180"
  },
  {
    "text": "life cycle of data ingression data",
    "start": "105180",
    "end": "108060"
  },
  {
    "text": "indexing and being able to actually",
    "start": "108060",
    "end": "109619"
  },
  {
    "text": "query over your data so we have like",
    "start": "109619",
    "end": "112680"
  },
  {
    "text": "over a hundred different data loaders",
    "start": "112680",
    "end": "114119"
  },
  {
    "text": "from unstructured to structured file",
    "start": "114119",
    "end": "115740"
  },
  {
    "text": "formats through llama Hub which is a",
    "start": "115740",
    "end": "118200"
  },
  {
    "text": "Community Driven kind of like data",
    "start": "118200",
    "end": "119700"
  },
  {
    "text": "loader hub",
    "start": "119700",
    "end": "120720"
  },
  {
    "text": "once you actually load in this data we",
    "start": "120720",
    "end": "122759"
  },
  {
    "text": "have a robust Suite of tools to do a",
    "start": "122759",
    "end": "124619"
  },
  {
    "text": "bunch of Transformations on this data so",
    "start": "124619",
    "end": "126180"
  },
  {
    "text": "you can split the data",
    "start": "126180",
    "end": "127799"
  },
  {
    "text": "parse it add metadata to it add a bunch",
    "start": "127799",
    "end": "131340"
  },
  {
    "text": "of you know add embeddings to it too and",
    "start": "131340",
    "end": "133260"
  },
  {
    "text": "add other stuff so that like in the end",
    "start": "133260",
    "end": "135599"
  },
  {
    "text": "it's basically a new type of ETL",
    "start": "135599",
    "end": "137340"
  },
  {
    "text": "pipeline that you want to store in your",
    "start": "137340",
    "end": "138540"
  },
  {
    "text": "vector DB we also integrate with Vector",
    "start": "138540",
    "end": "141239"
  },
  {
    "text": "databases we have like 30 plus",
    "start": "141239",
    "end": "142560"
  },
  {
    "text": "Integrations but we also have",
    "start": "142560",
    "end": "143819"
  },
  {
    "text": "Integrations with other storage",
    "start": "143819",
    "end": "145379"
  },
  {
    "text": "providers from graph databases to",
    "start": "145379",
    "end": "147300"
  },
  {
    "text": "document stores as well",
    "start": "147300",
    "end": "148920"
  },
  {
    "text": "and then in terms of the data like once",
    "start": "148920",
    "end": "151500"
  },
  {
    "text": "the data is actually in your storage",
    "start": "151500",
    "end": "152760"
  },
  {
    "text": "system then you want to do stuff like",
    "start": "152760",
    "end": "154620"
  },
  {
    "text": "retrieval querying synthesis all these",
    "start": "154620",
    "end": "156840"
  },
  {
    "text": "things with the outline over it and so",
    "start": "156840",
    "end": "158220"
  },
  {
    "text": "this ranges from stuff like question",
    "start": "158220",
    "end": "159599"
  },
  {
    "text": "answering summarization agents and more",
    "start": "159599",
    "end": "163500"
  },
  {
    "text": "okay and and so all kind of um this is",
    "start": "163500",
    "end": "166379"
  },
  {
    "text": "just like a brief overview of Obama",
    "start": "166379",
    "end": "167640"
  },
  {
    "text": "index the formatting is a little messed",
    "start": "167640",
    "end": "168959"
  },
  {
    "text": "up here but basically the idea is that",
    "start": "168959",
    "end": "170519"
  },
  {
    "text": "you know you can basically set up a QA",
    "start": "170519",
    "end": "172319"
  },
  {
    "text": "system over your data and about three",
    "start": "172319",
    "end": "174239"
  },
  {
    "text": "lines of code right and so the advantage",
    "start": "174239",
    "end": "176640"
  },
  {
    "text": "of llama index",
    "start": "176640",
    "end": "178200"
  },
  {
    "text": "um uh one of the advantages is that it",
    "start": "178200",
    "end": "180540"
  },
  {
    "text": "has a very high level API if you want it",
    "start": "180540",
    "end": "183300"
  },
  {
    "text": "to be so that you can basically make it",
    "start": "183300",
    "end": "185519"
  },
  {
    "text": "very easy to load in a bunch of",
    "start": "185519",
    "end": "187200"
  },
  {
    "text": "documents that's the first line right",
    "start": "187200",
    "end": "188519"
  },
  {
    "text": "here index a bunch of documents and then",
    "start": "188519",
    "end": "191640"
  },
  {
    "text": "basically ask questions over it without",
    "start": "191640",
    "end": "193680"
  },
  {
    "text": "you really have having to worry about",
    "start": "193680",
    "end": "195060"
  },
  {
    "text": "the complexity and of course we have the",
    "start": "195060",
    "end": "197700"
  },
  {
    "text": "underlying lower level abstraction so",
    "start": "197700",
    "end": "199500"
  },
  {
    "text": "that if you are an advanced user that",
    "start": "199500",
    "end": "201120"
  },
  {
    "text": "wants to go in and customize things you",
    "start": "201120",
    "end": "202980"
  },
  {
    "text": "can and you absolutely should and in",
    "start": "202980",
    "end": "204720"
  },
  {
    "text": "fact that's pretty much the topic of",
    "start": "204720",
    "end": "206400"
  },
  {
    "text": "this talk is how should you iterate on",
    "start": "206400",
    "end": "208500"
  },
  {
    "text": "your retrieval algorithm and your",
    "start": "208500",
    "end": "210599"
  },
  {
    "text": "synthesis to actually create more",
    "start": "210599",
    "end": "212400"
  },
  {
    "text": "performant rag applications because this",
    "start": "212400",
    "end": "214560"
  },
  {
    "text": "thing I mean look like this thing right",
    "start": "214560",
    "end": "216060"
  },
  {
    "text": "here takes you like 10 minutes to set up",
    "start": "216060",
    "end": "217739"
  },
  {
    "text": "right like without really needing to",
    "start": "217739",
    "end": "219480"
  },
  {
    "text": "understand a bunch of stuff",
    "start": "219480",
    "end": "221220"
  },
  {
    "text": "um so what are the downsides here and",
    "start": "221220",
    "end": "222959"
  },
  {
    "text": "how can you iterate on that to fix",
    "start": "222959",
    "end": "224519"
  },
  {
    "text": "retrieval and generation issues",
    "start": "224519",
    "end": "227159"
  },
  {
    "text": "so we'll talk about what I call kind of",
    "start": "227159",
    "end": "228959"
  },
  {
    "text": "like the naive rag stack for building a",
    "start": "228959",
    "end": "230819"
  },
  {
    "text": "QA system",
    "start": "230819",
    "end": "231959"
  },
  {
    "text": "um and as I mentioned it's about five",
    "start": "231959",
    "end": "233159"
  },
  {
    "text": "lines of code um it's two main",
    "start": "233159",
    "end": "234959"
  },
  {
    "text": "components there's data ingestion and",
    "start": "234959",
    "end": "236700"
  },
  {
    "text": "parsing and then also data querying",
    "start": "236700",
    "end": "239459"
  },
  {
    "text": "so data ingestion means that you load in",
    "start": "239459",
    "end": "242640"
  },
  {
    "text": "some documents right and let's say you",
    "start": "242640",
    "end": "244739"
  },
  {
    "text": "just use a pretty simple PDF parser",
    "start": "244739",
    "end": "247500"
  },
  {
    "text": "um like Pi PDF or you know there's like",
    "start": "247500",
    "end": "250260"
  },
  {
    "text": "10 plus Integrations available on llama",
    "start": "250260",
    "end": "252480"
  },
  {
    "text": "Hub",
    "start": "252480",
    "end": "253260"
  },
  {
    "text": "um once you take in these like documents",
    "start": "253260",
    "end": "255900"
  },
  {
    "text": "you then chunk it up into a set of even",
    "start": "255900",
    "end": "259019"
  },
  {
    "text": "chunks so you split it say by sentences",
    "start": "259019",
    "end": "261359"
  },
  {
    "text": "or by by like tokens and you do like",
    "start": "261359",
    "end": "264060"
  },
  {
    "text": "every thousand words or every like 20",
    "start": "264060",
    "end": "265680"
  },
  {
    "text": "sentences or something but you basically",
    "start": "265680",
    "end": "267479"
  },
  {
    "text": "have a bunch of chunks right and each",
    "start": "267479",
    "end": "268740"
  },
  {
    "text": "chunk is just a piece of raw text",
    "start": "268740",
    "end": "271020"
  },
  {
    "text": "um and then you just dump the chunks",
    "start": "271020",
    "end": "272639"
  },
  {
    "text": "into a vector database along with an",
    "start": "272639",
    "end": "274740"
  },
  {
    "text": "embedding and that embedding is",
    "start": "274740",
    "end": "276360"
  },
  {
    "text": "generated by an embedding model like",
    "start": "276360",
    "end": "277680"
  },
  {
    "text": "open AI",
    "start": "277680",
    "end": "279540"
  },
  {
    "text": "once that is in the database then you",
    "start": "279540",
    "end": "282240"
  },
  {
    "text": "want to query over that data so you want",
    "start": "282240",
    "end": "284220"
  },
  {
    "text": "to fetch the top K most similar chunks",
    "start": "284220",
    "end": "285960"
  },
  {
    "text": "from the vector database and plug this",
    "start": "285960",
    "end": "287820"
  },
  {
    "text": "into your llm response synthesis module",
    "start": "287820",
    "end": "291300"
  },
  {
    "text": "so I think if you've actually tried",
    "start": "291300",
    "end": "293940"
  },
  {
    "text": "building this if you you know like um",
    "start": "293940",
    "end": "296820"
  },
  {
    "text": "have actually just tried doing the five",
    "start": "296820",
    "end": "298680"
  },
  {
    "text": "lines of code in llama index like",
    "start": "298680",
    "end": "300720"
  },
  {
    "text": "inevitably you're going to run into",
    "start": "300720",
    "end": "302100"
  },
  {
    "text": "failure modes um especially as you scale",
    "start": "302100",
    "end": "304320"
  },
  {
    "text": "to larger numbers of documents as you",
    "start": "304320",
    "end": "306479"
  },
  {
    "text": "scale to a diverse set of documents as",
    "start": "306479",
    "end": "308639"
  },
  {
    "text": "you scale to more complex document types",
    "start": "308639",
    "end": "310680"
  },
  {
    "text": "if a PDF has like a bunch of embedded",
    "start": "310680",
    "end": "312660"
  },
  {
    "text": "tables if you have like a markdown file",
    "start": "312660",
    "end": "314160"
  },
  {
    "text": "with a bunch of sections and so in terms",
    "start": "314160",
    "end": "316440"
  },
  {
    "text": "of failure modes there's basically two",
    "start": "316440",
    "end": "317820"
  },
  {
    "text": "main categories there's quality related",
    "start": "317820",
    "end": "319440"
  },
  {
    "text": "stuff like hallucination and accuracy",
    "start": "319440",
    "end": "321240"
  },
  {
    "text": "and there's also stuff I would say is",
    "start": "321240",
    "end": "323340"
  },
  {
    "text": "like kind of more non-quality related",
    "start": "323340",
    "end": "324960"
  },
  {
    "text": "like system level considerations like",
    "start": "324960",
    "end": "326880"
  },
  {
    "text": "latency costs and syncing",
    "start": "326880",
    "end": "329580"
  },
  {
    "text": "so from talking to a bunch of users",
    "start": "329580",
    "end": "333000"
  },
  {
    "text": "um who are just building LM apps of your",
    "start": "333000",
    "end": "334919"
  },
  {
    "text": "data like and rag pipelines the most",
    "start": "334919",
    "end": "336780"
  },
  {
    "text": "common reason for bad response quality",
    "start": "336780",
    "end": "338460"
  },
  {
    "text": "is bad retrieval if the retrieve results",
    "start": "338460",
    "end": "340919"
  },
  {
    "text": "are bad there's just no way that the llm",
    "start": "340919",
    "end": "343440"
  },
  {
    "text": "can actually synthesize a proper",
    "start": "343440",
    "end": "345180"
  },
  {
    "text": "response without hallucinating",
    "start": "345180",
    "end": "347220"
  },
  {
    "text": "and so digging into this a little bit",
    "start": "347220",
    "end": "349080"
  },
  {
    "text": "more what does bad retrieval really mean",
    "start": "349080",
    "end": "351660"
  },
  {
    "text": "um it could really it could mean a few",
    "start": "351660",
    "end": "353220"
  },
  {
    "text": "different things",
    "start": "353220",
    "end": "354300"
  },
  {
    "text": "one is low Precision so not all the",
    "start": "354300",
    "end": "357900"
  },
  {
    "text": "chunks in the retrieve set are actually",
    "start": "357900",
    "end": "359820"
  },
  {
    "text": "relevant I mean some of them might be",
    "start": "359820",
    "end": "361680"
  },
  {
    "text": "relevant but not all of them are and",
    "start": "361680",
    "end": "364380"
  },
  {
    "text": "what this means is you have a bunch of",
    "start": "364380",
    "end": "365580"
  },
  {
    "text": "irrelevant contacts you're feeding into",
    "start": "365580",
    "end": "367199"
  },
  {
    "text": "the language model which is ripe for",
    "start": "367199",
    "end": "368639"
  },
  {
    "text": "hallucination uh synthesizing stuff",
    "start": "368639",
    "end": "370560"
  },
  {
    "text": "that's not actually relevant for to your",
    "start": "370560",
    "end": "372180"
  },
  {
    "text": "question and also getting into loss in",
    "start": "372180",
    "end": "373919"
  },
  {
    "text": "the middle problems where the longer the",
    "start": "373919",
    "end": "375539"
  },
  {
    "text": "contact says counter-intuitively the",
    "start": "375539",
    "end": "377580"
  },
  {
    "text": "language model actually has a harder",
    "start": "377580",
    "end": "378960"
  },
  {
    "text": "time picking out stuff in the middle to",
    "start": "378960",
    "end": "380460"
  },
  {
    "text": "the the relevant piece of information",
    "start": "380460",
    "end": "382979"
  },
  {
    "text": "uh there's also love recall",
    "start": "382979",
    "end": "385560"
  },
  {
    "text": "um uh not all the relevant chunks are",
    "start": "385560",
    "end": "387419"
  },
  {
    "text": "actually retrieved so if you're actually",
    "start": "387419",
    "end": "388620"
  },
  {
    "text": "missing crucial context this means that",
    "start": "388620",
    "end": "390539"
  },
  {
    "text": "your llm doesn't have enough contacts to",
    "start": "390539",
    "end": "392639"
  },
  {
    "text": "synthesize a proper answer",
    "start": "392639",
    "end": "394319"
  },
  {
    "text": "there's outdated information as well",
    "start": "394319",
    "end": "396180"
  },
  {
    "text": "like the data is redundant or out of",
    "start": "396180",
    "end": "398039"
  },
  {
    "text": "date",
    "start": "398039",
    "end": "399720"
  },
  {
    "text": "so stuff that's not response quality",
    "start": "399720",
    "end": "401580"
  },
  {
    "text": "related includes the following how do",
    "start": "401580",
    "end": "403500"
  },
  {
    "text": "you deal with updates in like the source",
    "start": "403500",
    "end": "405360"
  },
  {
    "text": "document how do you uh if like your PDFs",
    "start": "405360",
    "end": "408600"
  },
  {
    "text": "actually change or you know you have new",
    "start": "408600",
    "end": "410520"
  },
  {
    "text": "slack conversations and you're using it",
    "start": "410520",
    "end": "412139"
  },
  {
    "text": "as a data loader how do you propagate",
    "start": "412139",
    "end": "413880"
  },
  {
    "text": "these updates into your Downstream",
    "start": "413880",
    "end": "415440"
  },
  {
    "text": "Vector store which contain like the",
    "start": "415440",
    "end": "416819"
  },
  {
    "text": "chunks of the original text and then",
    "start": "416819",
    "end": "419580"
  },
  {
    "text": "system-wide how do you ingest hundreds",
    "start": "419580",
    "end": "421440"
  },
  {
    "text": "and thousands of documents in a scalable",
    "start": "421440",
    "end": "423060"
  },
  {
    "text": "robust way",
    "start": "423060",
    "end": "424380"
  },
  {
    "text": "so uh I've kind of like touched on this",
    "start": "424380",
    "end": "427199"
  },
  {
    "text": "topic um but you know it's always",
    "start": "427199",
    "end": "428880"
  },
  {
    "text": "evolving but like part of the key lesson",
    "start": "428880",
    "end": "430979"
  },
  {
    "text": "here is you should always just think",
    "start": "430979",
    "end": "432419"
  },
  {
    "text": "carefully about the way you define data",
    "start": "432419",
    "end": "434400"
  },
  {
    "text": "and how data actually influences the",
    "start": "434400",
    "end": "436740"
  },
  {
    "text": "quality of your L1 application and in",
    "start": "436740",
    "end": "439199"
  },
  {
    "text": "that sense it's not really that",
    "start": "439199",
    "end": "440580"
  },
  {
    "text": "different than your traditional ml Ops",
    "start": "440580",
    "end": "442560"
  },
  {
    "text": "pipeline where again like data",
    "start": "442560",
    "end": "444419"
  },
  {
    "text": "engineering matters quite a bit to",
    "start": "444419",
    "end": "445979"
  },
  {
    "text": "actually improve the performance",
    "start": "445979",
    "end": "449220"
  },
  {
    "text": "so the bulk of this talk is basically",
    "start": "449220",
    "end": "451979"
  },
  {
    "text": "talking about some general techniques",
    "start": "451979",
    "end": "453900"
  },
  {
    "text": "for better performing uh rag Beyond kind",
    "start": "453900",
    "end": "457259"
  },
  {
    "text": "of maybe what you've seen that you can",
    "start": "457259",
    "end": "459780"
  },
  {
    "text": "do in like five lines of code from lava",
    "start": "459780",
    "end": "461580"
  },
  {
    "text": "index or Line train or other Frameworks",
    "start": "461580",
    "end": "464520"
  },
  {
    "text": "so um and and we'll try to give examples",
    "start": "464520",
    "end": "467160"
  },
  {
    "text": "for each one on like uh failure modes",
    "start": "467160",
    "end": "469139"
  },
  {
    "text": "and I'm also happy to answer some",
    "start": "469139",
    "end": "470759"
  },
  {
    "text": "questions at the end one is um so when",
    "start": "470759",
    "end": "473940"
  },
  {
    "text": "you take these chunks by default you",
    "start": "473940",
    "end": "475500"
  },
  {
    "text": "kind of embed these chunks right you",
    "start": "475500",
    "end": "477300"
  },
  {
    "text": "just generating embedding over the raw",
    "start": "477300",
    "end": "478800"
  },
  {
    "text": "tax chunks and you store in a vector",
    "start": "478800",
    "end": "480180"
  },
  {
    "text": "database and these same chunks are used",
    "start": "480180",
    "end": "482160"
  },
  {
    "text": "for both retrieval and synthesis and so",
    "start": "482160",
    "end": "484919"
  },
  {
    "text": "the main issue is that when you just",
    "start": "484919",
    "end": "486720"
  },
  {
    "text": "embed the raw tax chunks they can",
    "start": "486720",
    "end": "488759"
  },
  {
    "text": "basically bias your embedding",
    "start": "488759",
    "end": "490319"
  },
  {
    "text": "representation with a bunch of filler",
    "start": "490319",
    "end": "492000"
  },
  {
    "text": "content",
    "start": "492000",
    "end": "492960"
  },
  {
    "text": "um I've said this a few times but I",
    "start": "492960",
    "end": "494759"
  },
  {
    "text": "think this original idea was also",
    "start": "494759",
    "end": "496139"
  },
  {
    "text": "brought up by Max from said.ai so and",
    "start": "496139",
    "end": "498720"
  },
  {
    "text": "then this slide was was taken from that",
    "start": "498720",
    "end": "500460"
  },
  {
    "text": "so giving credit uh to him for bringing",
    "start": "500460",
    "end": "502979"
  },
  {
    "text": "up this great idea it's like if you have",
    "start": "502979",
    "end": "504900"
  },
  {
    "text": "like let's say you're embedding an email",
    "start": "504900",
    "end": "506819"
  },
  {
    "text": "right that email is going to have a ton",
    "start": "506819",
    "end": "508800"
  },
  {
    "text": "of filler words like um hi and sincerely",
    "start": "508800",
    "end": "511560"
  },
  {
    "text": "and looking forward to it that stuff",
    "start": "511560",
    "end": "513959"
  },
  {
    "text": "depending on your embedding model is",
    "start": "513959",
    "end": "515520"
  },
  {
    "text": "going to buy a systematic representation",
    "start": "515520",
    "end": "517020"
  },
  {
    "text": "and so if there's a way for you to",
    "start": "517020",
    "end": "519120"
  },
  {
    "text": "somehow just extract out the Salient",
    "start": "519120",
    "end": "520979"
  },
  {
    "text": "bits of information they're actually",
    "start": "520979",
    "end": "522479"
  },
  {
    "text": "relevant to the question that you want",
    "start": "522479",
    "end": "524339"
  },
  {
    "text": "to ask how can we do that",
    "start": "524339",
    "end": "527700"
  },
  {
    "text": "so one basic idea here and this is just",
    "start": "527700",
    "end": "531000"
  },
  {
    "text": "a very simple trick that I'd encourage",
    "start": "531000",
    "end": "532620"
  },
  {
    "text": "all of you guys to just try out um and",
    "start": "532620",
    "end": "534420"
  },
  {
    "text": "see see if it works is you embed the",
    "start": "534420",
    "end": "538500"
  },
  {
    "text": "text at a smaller level than the level",
    "start": "538500",
    "end": "540779"
  },
  {
    "text": "that you synthesize over so if you embed",
    "start": "540779",
    "end": "543720"
  },
  {
    "text": "the text at the sentence level and dump",
    "start": "543720",
    "end": "545760"
  },
  {
    "text": "a bunch of sentence chunks into a vector",
    "start": "545760",
    "end": "547920"
  },
  {
    "text": "database okay",
    "start": "547920",
    "end": "550080"
  },
  {
    "text": "then you have more granular chunks that",
    "start": "550080",
    "end": "552120"
  },
  {
    "text": "you can retrieve over and then you do",
    "start": "552120",
    "end": "554160"
  },
  {
    "text": "like Top Care retrieval okay over these",
    "start": "554160",
    "end": "556320"
  },
  {
    "text": "like sentence chunks and you'll just",
    "start": "556320",
    "end": "558540"
  },
  {
    "text": "retrieve individual sentences but what",
    "start": "558540",
    "end": "560640"
  },
  {
    "text": "you do before these chunks actually hit",
    "start": "560640",
    "end": "562500"
  },
  {
    "text": "the llm is you then expand the context",
    "start": "562500",
    "end": "565019"
  },
  {
    "text": "right around that window around the",
    "start": "565019",
    "end": "567300"
  },
  {
    "text": "sentence so you need like proper",
    "start": "567300",
    "end": "569339"
  },
  {
    "text": "metadata representations for this to",
    "start": "569339",
    "end": "571019"
  },
  {
    "text": "work well but the key idea here is that",
    "start": "571019",
    "end": "573360"
  },
  {
    "text": "you kind of like",
    "start": "573360",
    "end": "575399"
  },
  {
    "text": "um it's kind of like a win-win for both",
    "start": "575399",
    "end": "577200"
  },
  {
    "text": "the retrieval and synthesis side if",
    "start": "577200",
    "end": "579480"
  },
  {
    "text": "there's too much filler content on the",
    "start": "579480",
    "end": "580920"
  },
  {
    "text": "retrieval then your retrieval might be",
    "start": "580920",
    "end": "583380"
  },
  {
    "text": "bad so if you're retrieving giant text",
    "start": "583380",
    "end": "585240"
  },
  {
    "text": "chunks it might not be great for kind of",
    "start": "585240",
    "end": "587760"
  },
  {
    "text": "fetching a relevant context and you get",
    "start": "587760",
    "end": "589560"
  },
  {
    "text": "lost in the middle problems but then",
    "start": "589560",
    "end": "591240"
  },
  {
    "text": "once you actually retrieve the relevant",
    "start": "591240",
    "end": "592860"
  },
  {
    "text": "pieces you want enough context for a",
    "start": "592860",
    "end": "594600"
  },
  {
    "text": "language model to actually synthesize an",
    "start": "594600",
    "end": "595920"
  },
  {
    "text": "answer and so this is a way around that",
    "start": "595920",
    "end": "599100"
  },
  {
    "text": "we tried this with some basic",
    "start": "599100",
    "end": "600720"
  },
  {
    "text": "experiments with sentence window",
    "start": "600720",
    "end": "602339"
  },
  {
    "text": "retrievals is what we're calling it with",
    "start": "602339",
    "end": "604080"
  },
  {
    "text": "k equals two you can actually get back",
    "start": "604080",
    "end": "606300"
  },
  {
    "text": "in a form of answer over this Climate",
    "start": "606300",
    "end": "608220"
  },
  {
    "text": "Change Report that we ran over",
    "start": "608220",
    "end": "610680"
  },
  {
    "text": "but when we set k equals 5 over kind of",
    "start": "610680",
    "end": "613680"
  },
  {
    "text": "using a more naive retrieval method with",
    "start": "613680",
    "end": "615779"
  },
  {
    "text": "bigger chunk sizes you realize that the",
    "start": "615779",
    "end": "618480"
  },
  {
    "text": "actual answer is somewhere in the middle",
    "start": "618480",
    "end": "620279"
  },
  {
    "text": "but it also retrieves a bunch of",
    "start": "620279",
    "end": "621720"
  },
  {
    "text": "irrelevant contacts so there's four",
    "start": "621720",
    "end": "623220"
  },
  {
    "text": "chunks that are irrelevant and one chunk",
    "start": "623220",
    "end": "625140"
  },
  {
    "text": "that is relevant and then you get these",
    "start": "625140",
    "end": "627420"
  },
  {
    "text": "loss of the middle problems and then the",
    "start": "627420",
    "end": "629040"
  },
  {
    "text": "llm like especially if it's like a",
    "start": "629040",
    "end": "630660"
  },
  {
    "text": "crappier LM like you know gbt 3.5 versus",
    "start": "630660",
    "end": "633660"
  },
  {
    "text": "gbt4 it's not able to synthesize an",
    "start": "633660",
    "end": "636660"
  },
  {
    "text": "answer for you",
    "start": "636660",
    "end": "639199"
  },
  {
    "text": "another general idea that I think has",
    "start": "639240",
    "end": "642839"
  },
  {
    "text": "worked well uh for for us but I urge all",
    "start": "642839",
    "end": "645600"
  },
  {
    "text": "of you guys to give it a try and let us",
    "start": "645600",
    "end": "646740"
  },
  {
    "text": "know your feedback is to try embedding",
    "start": "646740",
    "end": "648899"
  },
  {
    "text": "like a reference to the actual text",
    "start": "648899",
    "end": "650579"
  },
  {
    "text": "Chunk instead of the text trunk directly",
    "start": "650579",
    "end": "653519"
  },
  {
    "text": "um and so examples of what what are",
    "start": "653519",
    "end": "655620"
  },
  {
    "text": "references right it could be literally",
    "start": "655620",
    "end": "657240"
  },
  {
    "text": "anything but the idea is again in the",
    "start": "657240",
    "end": "659700"
  },
  {
    "text": "spirit of decoupling embeddings from",
    "start": "659700",
    "end": "661500"
  },
  {
    "text": "retrieval on synthesis it could be a",
    "start": "661500",
    "end": "663720"
  },
  {
    "text": "smaller chunk if your original chunk is",
    "start": "663720",
    "end": "665459"
  },
  {
    "text": "very big it could be an extracted",
    "start": "665459",
    "end": "667260"
  },
  {
    "text": "summary it could be a set of like you",
    "start": "667260",
    "end": "669839"
  },
  {
    "text": "know LM generated questions that you",
    "start": "669839",
    "end": "672180"
  },
  {
    "text": "might want to ask the chunk so like",
    "start": "672180",
    "end": "674160"
  },
  {
    "text": "hallucinated questions given the chunk",
    "start": "674160",
    "end": "675720"
  },
  {
    "text": "itself so you want to retrieve those",
    "start": "675720",
    "end": "678180"
  },
  {
    "text": "references first",
    "start": "678180",
    "end": "679920"
  },
  {
    "text": "um and then you know once you actually",
    "start": "679920",
    "end": "681420"
  },
  {
    "text": "retrieve those then link to the actual",
    "start": "681420",
    "end": "684300"
  },
  {
    "text": "text chunks that again goes into the",
    "start": "684300",
    "end": "686040"
  },
  {
    "text": "language model during synthesis",
    "start": "686040",
    "end": "688380"
  },
  {
    "text": "we tried this on a few kind of basic",
    "start": "688380",
    "end": "690779"
  },
  {
    "text": "experiments",
    "start": "690779",
    "end": "692279"
  },
  {
    "text": "um and so you know the base retriever is",
    "start": "692279",
    "end": "694260"
  },
  {
    "text": "like naive retrieval and we tried both",
    "start": "694260",
    "end": "696660"
  },
  {
    "text": "kind of like chunk based references uh",
    "start": "696660",
    "end": "698880"
  },
  {
    "text": "with like extracted summaries and also",
    "start": "698880",
    "end": "701459"
  },
  {
    "text": "metadata references",
    "start": "701459",
    "end": "703140"
  },
  {
    "text": "um with with uh with kind of like",
    "start": "703140",
    "end": "705480"
  },
  {
    "text": "extracted like structured information",
    "start": "705480",
    "end": "707000"
  },
  {
    "text": "and in both cases when you actually",
    "start": "707000",
    "end": "709260"
  },
  {
    "text": "retrieve those instead of the raw text",
    "start": "709260",
    "end": "711600"
  },
  {
    "text": "chunks you get better retrieval",
    "start": "711600",
    "end": "713160"
  },
  {
    "text": "performance which that in turn leads to",
    "start": "713160",
    "end": "714959"
  },
  {
    "text": "better generation",
    "start": "714959",
    "end": "717680"
  },
  {
    "text": "the next concept here is this idea of",
    "start": "719399",
    "end": "722399"
  },
  {
    "text": "organizing your data for more structured",
    "start": "722399",
    "end": "725459"
  },
  {
    "text": "retrieval and so this is the idea of",
    "start": "725459",
    "end": "727740"
  },
  {
    "text": "injecting you know metadata or",
    "start": "727740",
    "end": "729600"
  },
  {
    "text": "structured information into your",
    "start": "729600",
    "end": "731100"
  },
  {
    "text": "document",
    "start": "731100",
    "end": "732180"
  },
  {
    "text": "so the thing with metadata is imagine",
    "start": "732180",
    "end": "735540"
  },
  {
    "text": "you have like just a raw like text Chunk",
    "start": "735540",
    "end": "737820"
  },
  {
    "text": "here right and this is just a random",
    "start": "737820",
    "end": "739440"
  },
  {
    "text": "snippet from the lgbt4 paper",
    "start": "739440",
    "end": "741500"
  },
  {
    "text": "metadata is basically just a Json",
    "start": "741500",
    "end": "743399"
  },
  {
    "text": "dictionary that you attach on top",
    "start": "743399",
    "end": "745800"
  },
  {
    "text": "um and the thing about metadata is that",
    "start": "745800",
    "end": "747959"
  },
  {
    "text": "it's useful for both retrieval right it",
    "start": "747959",
    "end": "750600"
  },
  {
    "text": "can't help retrieval as I basically just",
    "start": "750600",
    "end": "752339"
  },
  {
    "text": "showed I'm here",
    "start": "752339",
    "end": "754440"
  },
  {
    "text": "it can also just help a synthesis it can",
    "start": "754440",
    "end": "757140"
  },
  {
    "text": "add more context to the language model",
    "start": "757140",
    "end": "758880"
  },
  {
    "text": "kind of understands what's going on at a",
    "start": "758880",
    "end": "760740"
  },
  {
    "text": "higher level and the other thing is that",
    "start": "760740",
    "end": "763500"
  },
  {
    "text": "it directly plugs into your vector",
    "start": "763500",
    "end": "765420"
  },
  {
    "text": "database like metadata filters these",
    "start": "765420",
    "end": "767519"
  },
  {
    "text": "days all the major Vector DBS so chroma",
    "start": "767519",
    "end": "770579"
  },
  {
    "text": "pine cone weeva quadrant Novus like and",
    "start": "770579",
    "end": "773700"
  },
  {
    "text": "and all the other ones like they all",
    "start": "773700",
    "end": "775079"
  },
  {
    "text": "support some aspect of structured",
    "start": "775079",
    "end": "776700"
  },
  {
    "text": "filtering and so that you can directly",
    "start": "776700",
    "end": "779220"
  },
  {
    "text": "query for both a structured information",
    "start": "779220",
    "end": "781440"
  },
  {
    "text": "as well as semantic queries",
    "start": "781440",
    "end": "784079"
  },
  {
    "text": "examples of metadata include things that",
    "start": "784079",
    "end": "786720"
  },
  {
    "text": "you would Define yourself things that",
    "start": "786720",
    "end": "788880"
  },
  {
    "text": "are part of like common like data",
    "start": "788880",
    "end": "791100"
  },
  {
    "text": "parsers like PDF parsers and also things",
    "start": "791100",
    "end": "793680"
  },
  {
    "text": "that llms can probably extract for you",
    "start": "793680",
    "end": "795660"
  },
  {
    "text": "and so these include stuff like page",
    "start": "795660",
    "end": "797700"
  },
  {
    "text": "numbers",
    "start": "797700",
    "end": "798720"
  },
  {
    "text": "um document titles it could be even more",
    "start": "798720",
    "end": "801120"
  },
  {
    "text": "creative like a summary of adjacent",
    "start": "801120",
    "end": "802500"
  },
  {
    "text": "chunks is something you can use in llm",
    "start": "802500",
    "end": "804120"
  },
  {
    "text": "for or even questions that a chunk can",
    "start": "804120",
    "end": "806639"
  },
  {
    "text": "answer if you're familiar with like hide",
    "start": "806639",
    "end": "807959"
  },
  {
    "text": "which hallucinates an answer given a",
    "start": "807959",
    "end": "809519"
  },
  {
    "text": "question this is kind of like reverse",
    "start": "809519",
    "end": "810899"
  },
  {
    "text": "HUD given like a chunk of contact",
    "start": "810899",
    "end": "812220"
  },
  {
    "text": "solution a bunch of questions I can",
    "start": "812220",
    "end": "813660"
  },
  {
    "text": "answer that that can be answered by the",
    "start": "813660",
    "end": "815160"
  },
  {
    "text": "context and we found you know we're",
    "start": "815160",
    "end": "817620"
  },
  {
    "text": "still kind of experimenting with like",
    "start": "817620",
    "end": "819120"
  },
  {
    "text": "the very best practices for this but we",
    "start": "819120",
    "end": "821279"
  },
  {
    "text": "have found in a lot of cases on a more",
    "start": "821279",
    "end": "823200"
  },
  {
    "text": "case-by-case basis some of these",
    "start": "823200",
    "end": "824940"
  },
  {
    "text": "techniques can basically help your use",
    "start": "824940",
    "end": "826680"
  },
  {
    "text": "cases",
    "start": "826680",
    "end": "827639"
  },
  {
    "text": "so a very simple use case here is that",
    "start": "827639",
    "end": "830639"
  },
  {
    "text": "um you can for instance like add page",
    "start": "830639",
    "end": "833459"
  },
  {
    "text": "numbers as metadata once you have page",
    "start": "833459",
    "end": "835800"
  },
  {
    "text": "numbers in the metadata and assuming the",
    "start": "835800",
    "end": "837540"
  },
  {
    "text": "metadata actually gets injected as text",
    "start": "837540",
    "end": "839220"
  },
  {
    "text": "then you can basically kind of get",
    "start": "839220",
    "end": "841380"
  },
  {
    "text": "inline citations over your answers right",
    "start": "841380",
    "end": "843480"
  },
  {
    "text": "because when the llmcs a bunch of text",
    "start": "843480",
    "end": "846660"
  },
  {
    "text": "and it has the meta like the page",
    "start": "846660",
    "end": "849180"
  },
  {
    "text": "numbers associated with the text then it",
    "start": "849180",
    "end": "851700"
  },
  {
    "text": "can actually give you kind of inline",
    "start": "851700",
    "end": "853500"
  },
  {
    "text": "citations like here it's giving an",
    "start": "853500",
    "end": "855480"
  },
  {
    "text": "answer on bullet points and it has like",
    "start": "855480",
    "end": "857339"
  },
  {
    "text": "parentheses page six page six page 18",
    "start": "857339",
    "end": "860279"
  },
  {
    "text": "over here",
    "start": "860279",
    "end": "862880"
  },
  {
    "text": "here's just uh I don't know if you guys",
    "start": "865700",
    "end": "868200"
  },
  {
    "text": "can see this kind of but this is just an",
    "start": "868200",
    "end": "870060"
  },
  {
    "text": "example of like a text Chunk",
    "start": "870060",
    "end": "872100"
  },
  {
    "text": "um and this everything here in this top",
    "start": "872100",
    "end": "875399"
  },
  {
    "text": "half like before this like these Dash",
    "start": "875399",
    "end": "878220"
  },
  {
    "text": "lines are metadata so there's stuff like",
    "start": "878220",
    "end": "880500"
  },
  {
    "text": "page label file name document title",
    "start": "880500",
    "end": "883500"
  },
  {
    "text": "questions this excerpt can answer and",
    "start": "883500",
    "end": "886079"
  },
  {
    "text": "then this is the actual text Chunk",
    "start": "886079",
    "end": "887459"
  },
  {
    "text": "itself and so what you get is your final",
    "start": "887459",
    "end": "889260"
  },
  {
    "text": "uh chunk representation looks something",
    "start": "889260",
    "end": "891660"
  },
  {
    "text": "like this where it's like structured",
    "start": "891660",
    "end": "893100"
  },
  {
    "text": "information Dash Dash and then like",
    "start": "893100",
    "end": "894839"
  },
  {
    "text": "unstructured information",
    "start": "894839",
    "end": "896399"
  },
  {
    "text": "some of the stuff I've gotten is kind of",
    "start": "896399",
    "end": "898139"
  },
  {
    "text": "manually defined or through a parser",
    "start": "898139",
    "end": "899579"
  },
  {
    "text": "some of this can be extracted with an",
    "start": "899579",
    "end": "901139"
  },
  {
    "text": "lln like what is Uber Technology's uh",
    "start": "901139",
    "end": "903540"
  },
  {
    "text": "definition of adjusted ebitda",
    "start": "903540",
    "end": "905880"
  },
  {
    "text": "so",
    "start": "905880",
    "end": "907139"
  },
  {
    "text": "um it's kind of up to you there are",
    "start": "907139",
    "end": "908639"
  },
  {
    "text": "downsides to adding too much metadata uh",
    "start": "908639",
    "end": "911279"
  },
  {
    "text": "one it makes your retrievable a bit",
    "start": "911279",
    "end": "912720"
  },
  {
    "text": "slower and then two it can actually kind",
    "start": "912720",
    "end": "915300"
  },
  {
    "text": "of hurt your performance if you just",
    "start": "915300",
    "end": "916980"
  },
  {
    "text": "dump too much metadata so it's hard to",
    "start": "916980",
    "end": "918720"
  },
  {
    "text": "descend big weight between different",
    "start": "918720",
    "end": "919800"
  },
  {
    "text": "chunks but it's just like a tool in your",
    "start": "919800",
    "end": "921839"
  },
  {
    "text": "toolkit that you can use",
    "start": "921839",
    "end": "923339"
  },
  {
    "text": "elaborating on that last bit of how this",
    "start": "923339",
    "end": "925620"
  },
  {
    "text": "can actually plug into kind of the",
    "start": "925620",
    "end": "927600"
  },
  {
    "text": "vector DB right how you can actually",
    "start": "927600",
    "end": "929220"
  },
  {
    "text": "take this metadata and plug it into",
    "start": "929220",
    "end": "930920"
  },
  {
    "text": "integrate with Vector database like",
    "start": "930920",
    "end": "932880"
  },
  {
    "text": "metadata filtering is",
    "start": "932880",
    "end": "935220"
  },
  {
    "text": "imagine you have like some basic",
    "start": "935220",
    "end": "937199"
  },
  {
    "text": "question like can you tell me about",
    "start": "937199",
    "end": "939300"
  },
  {
    "text": "Google's like r d initiatives from 2020",
    "start": "939300",
    "end": "941760"
  },
  {
    "text": "to 2023.",
    "start": "941760",
    "end": "943800"
  },
  {
    "text": "um and assume like you know that there",
    "start": "943800",
    "end": "945899"
  },
  {
    "text": "was some parser that's able to take the",
    "start": "945899",
    "end": "948839"
  },
  {
    "text": "set of like financial statements uh for",
    "start": "948839",
    "end": "951120"
  },
  {
    "text": "Google uh and then actually kind of like",
    "start": "951120",
    "end": "953760"
  },
  {
    "text": "the 10ks for instance and then actually",
    "start": "953760",
    "end": "955620"
  },
  {
    "text": "tag it with each year",
    "start": "955620",
    "end": "957420"
  },
  {
    "text": "now if you don't take advantage of that",
    "start": "957420",
    "end": "959579"
  },
  {
    "text": "at all and then you just dump all the",
    "start": "959579",
    "end": "961680"
  },
  {
    "text": "10K document chunks into a single",
    "start": "961680",
    "end": "963360"
  },
  {
    "text": "collection and you just do like say top",
    "start": "963360",
    "end": "965040"
  },
  {
    "text": "four retrieval you're just going to get",
    "start": "965040",
    "end": "967019"
  },
  {
    "text": "like a random mess like chances are",
    "start": "967019",
    "end": "968399"
  },
  {
    "text": "you're not actually going to get like",
    "start": "968399",
    "end": "969720"
  },
  {
    "text": "specifically the you know each year uh",
    "start": "969720",
    "end": "972420"
  },
  {
    "text": "the relevant context so you might get",
    "start": "972420",
    "end": "974339"
  },
  {
    "text": "two from 2020 you might get two from",
    "start": "974339",
    "end": "976079"
  },
  {
    "text": "2022 you might get none for like 2023.",
    "start": "976079",
    "end": "979199"
  },
  {
    "text": "um and so there's no guarantee it'll",
    "start": "979199",
    "end": "980459"
  },
  {
    "text": "actually return the relevant tax chunks",
    "start": "980459",
    "end": "982019"
  },
  {
    "text": "purely with semantic search it's a",
    "start": "982019",
    "end": "983699"
  },
  {
    "text": "little bit fickle that way",
    "start": "983699",
    "end": "986540"
  },
  {
    "text": "but let's say you actually tag the",
    "start": "986639",
    "end": "988560"
  },
  {
    "text": "documents with metadata filters right",
    "start": "988560",
    "end": "990300"
  },
  {
    "text": "you use metadata attach the Year to each",
    "start": "990300",
    "end": "992399"
  },
  {
    "text": "document and then you actually store",
    "start": "992399",
    "end": "995100"
  },
  {
    "text": "this in say like Pinecone or something",
    "start": "995100",
    "end": "996720"
  },
  {
    "text": "with like the documents with the year",
    "start": "996720",
    "end": "998579"
  },
  {
    "text": "itself so when you ask a question",
    "start": "998579",
    "end": "1001639"
  },
  {
    "text": "um you cannot one one trick you can do",
    "start": "1001639",
    "end": "1003740"
  },
  {
    "text": "is you can actually have the language",
    "start": "1003740",
    "end": "1005120"
  },
  {
    "text": "model not just like pass along this",
    "start": "1005120",
    "end": "1007100"
  },
  {
    "text": "question but actually infer the set of",
    "start": "1007100",
    "end": "1008899"
  },
  {
    "text": "metadata filters right that I might need",
    "start": "1008899",
    "end": "1010759"
  },
  {
    "text": "to ask to actually query this database",
    "start": "1010759",
    "end": "1012620"
  },
  {
    "text": "effectively and so ideally right in this",
    "start": "1012620",
    "end": "1015980"
  },
  {
    "text": "setting the language model can actually",
    "start": "1015980",
    "end": "1017959"
  },
  {
    "text": "infer that hey like you know the set of",
    "start": "1017959",
    "end": "1020060"
  },
  {
    "text": "metadata filters that I want is from",
    "start": "1020060",
    "end": "1022579"
  },
  {
    "text": "specifically like you know range 2020 to",
    "start": "1022579",
    "end": "1025339"
  },
  {
    "text": "2023 and identify those specific",
    "start": "1025339",
    "end": "1027620"
  },
  {
    "text": "documents and retrieve the relevant",
    "start": "1027620",
    "end": "1029480"
  },
  {
    "text": "trunks of text and so it helps to narrow",
    "start": "1029480",
    "end": "1031699"
  },
  {
    "text": "down the candidate set to something",
    "start": "1031699",
    "end": "1033260"
  },
  {
    "text": "that's a lot more precise and then",
    "start": "1033260",
    "end": "1034819"
  },
  {
    "text": "that's something that can basically help",
    "start": "1034819",
    "end": "1036260"
  },
  {
    "text": "your retrieval",
    "start": "1036260",
    "end": "1039280"
  },
  {
    "text": "um the next idea that I think um I've",
    "start": "1041900",
    "end": "1044540"
  },
  {
    "text": "I've kind of been like becoming a bigger",
    "start": "1044540",
    "end": "1046819"
  },
  {
    "text": "and bigger fan of because I think it's",
    "start": "1046819",
    "end": "1048500"
  },
  {
    "text": "actually pretty General",
    "start": "1048500",
    "end": "1049820"
  },
  {
    "text": "um and I'm noticing the diagram kind of",
    "start": "1049820",
    "end": "1051559"
  },
  {
    "text": "cuts off here but",
    "start": "1051559",
    "end": "1053059"
  },
  {
    "text": "um the idea here is like this idea of",
    "start": "1053059",
    "end": "1054799"
  },
  {
    "text": "hierarchical or recursive retrieval",
    "start": "1054799",
    "end": "1057260"
  },
  {
    "text": "um a lot of times your data",
    "start": "1057260",
    "end": "1058640"
  },
  {
    "text": "representations are not flat there is",
    "start": "1058640",
    "end": "1060679"
  },
  {
    "text": "kind of some aspect of like a hierarchy",
    "start": "1060679",
    "end": "1062539"
  },
  {
    "text": "or a relationship between them if you",
    "start": "1062539",
    "end": "1064820"
  },
  {
    "text": "have a bunch of documents let's say you",
    "start": "1064820",
    "end": "1066500"
  },
  {
    "text": "have like 100 PDFs you can like separate",
    "start": "1066500",
    "end": "1068720"
  },
  {
    "text": "group them by like category and then you",
    "start": "1068720",
    "end": "1071000"
  },
  {
    "text": "know within each document like a",
    "start": "1071000",
    "end": "1072740"
  },
  {
    "text": "document could be very long you could",
    "start": "1072740",
    "end": "1074299"
  },
  {
    "text": "represent each document by its summary",
    "start": "1074299",
    "end": "1076520"
  },
  {
    "text": "a lot of times when you do retrieval it",
    "start": "1076520",
    "end": "1078860"
  },
  {
    "text": "helps to retrieve stuff at the top level",
    "start": "1078860",
    "end": "1080539"
  },
  {
    "text": "first before just like directly trying",
    "start": "1080539",
    "end": "1082580"
  },
  {
    "text": "to fetch the relevant chunks so for",
    "start": "1082580",
    "end": "1085039"
  },
  {
    "text": "instance if you model documents first by",
    "start": "1085039",
    "end": "1086960"
  },
  {
    "text": "their summaries retrieve based on that",
    "start": "1086960",
    "end": "1088580"
  },
  {
    "text": "and then you go down into the relevant",
    "start": "1088580",
    "end": "1090320"
  },
  {
    "text": "chunks that can oftentimes get you more",
    "start": "1090320",
    "end": "1092480"
  },
  {
    "text": "relevant context than actually fetching",
    "start": "1092480",
    "end": "1094400"
  },
  {
    "text": "the specific document chunks directly",
    "start": "1094400",
    "end": "1096740"
  },
  {
    "text": "another aspect here is um a lot of PDFs",
    "start": "1096740",
    "end": "1100580"
  },
  {
    "text": "right have like embedded tables and",
    "start": "1100580",
    "end": "1102559"
  },
  {
    "text": "graphs and a bunch of other stuff so how",
    "start": "1102559",
    "end": "1104780"
  },
  {
    "text": "do you actually model this appropriately",
    "start": "1104780",
    "end": "1106120"
  },
  {
    "text": "and we've been kind of thinking about",
    "start": "1106120",
    "end": "1108080"
  },
  {
    "text": "this a lot and it turns out like you",
    "start": "1108080",
    "end": "1109880"
  },
  {
    "text": "know if you like represent each embedded",
    "start": "1109880",
    "end": "1112520"
  },
  {
    "text": "object as its own kind of entity right",
    "start": "1112520",
    "end": "1114620"
  },
  {
    "text": "and and maybe",
    "start": "1114620",
    "end": "1116000"
  },
  {
    "text": "um uh like you you vectorize it or have",
    "start": "1116000",
    "end": "1119179"
  },
  {
    "text": "some way of like querying that embedded",
    "start": "1119179",
    "end": "1120679"
  },
  {
    "text": "object you can Stitch things together in",
    "start": "1120679",
    "end": "1123080"
  },
  {
    "text": "some sort of graph and then you can",
    "start": "1123080",
    "end": "1124400"
  },
  {
    "text": "basically recursively query uh start at",
    "start": "1124400",
    "end": "1126679"
  },
  {
    "text": "the top level find whether or not this",
    "start": "1126679",
    "end": "1128780"
  },
  {
    "text": "embedded object is actually relevant to",
    "start": "1128780",
    "end": "1130460"
  },
  {
    "text": "the query and if it is then go down and",
    "start": "1130460",
    "end": "1132440"
  },
  {
    "text": "actually call the the query on the",
    "start": "1132440",
    "end": "1134539"
  },
  {
    "text": "embedded object",
    "start": "1134539",
    "end": "1137200"
  },
  {
    "text": "so um elaborating on on this first",
    "start": "1137419",
    "end": "1139880"
  },
  {
    "text": "aspect a little bit more I think one",
    "start": "1139880",
    "end": "1142100"
  },
  {
    "text": "thing we're actually doing is just you",
    "start": "1142100",
    "end": "1143600"
  },
  {
    "text": "know for all these techniques it's like",
    "start": "1143600",
    "end": "1145100"
  },
  {
    "text": "a large scale retrieval benchmarking and",
    "start": "1145100",
    "end": "1147320"
  },
  {
    "text": "kind of uh evaluation just to make sure",
    "start": "1147320",
    "end": "1149360"
  },
  {
    "text": "that you know it actually works well I",
    "start": "1149360",
    "end": "1151640"
  },
  {
    "text": "have a bit on retrieval evaluation so",
    "start": "1151640",
    "end": "1153740"
  },
  {
    "text": "that you can for yourself validate",
    "start": "1153740",
    "end": "1155240"
  },
  {
    "text": "whether or not you know this actually",
    "start": "1155240",
    "end": "1156440"
  },
  {
    "text": "works but in the meantime",
    "start": "1156440",
    "end": "1158780"
  },
  {
    "text": "um the idea is for each document just",
    "start": "1158780",
    "end": "1160760"
  },
  {
    "text": "extract out a summary embed the",
    "start": "1160760",
    "end": "1162740"
  },
  {
    "text": "summaries first and then when you",
    "start": "1162740",
    "end": "1164299"
  },
  {
    "text": "actually kind of like ask a question",
    "start": "1164299",
    "end": "1165919"
  },
  {
    "text": "maybe fetch the relevant set of",
    "start": "1165919",
    "end": "1167419"
  },
  {
    "text": "documents before going into the",
    "start": "1167419",
    "end": "1169100"
  },
  {
    "text": "documents and fetching the relevant",
    "start": "1169100",
    "end": "1170419"
  },
  {
    "text": "chunks this could be like a simple but",
    "start": "1170419",
    "end": "1172220"
  },
  {
    "text": "effective technique to make sure you're",
    "start": "1172220",
    "end": "1173600"
  },
  {
    "text": "actually fetching context so it's like",
    "start": "1173600",
    "end": "1175520"
  },
  {
    "text": "Global context to course context",
    "start": "1175520",
    "end": "1179059"
  },
  {
    "text": "and kind of similar to what I described",
    "start": "1179059",
    "end": "1180919"
  },
  {
    "text": "if you have like you know like a a bunch",
    "start": "1180919",
    "end": "1183679"
  },
  {
    "text": "of tables like graphs like or even",
    "start": "1183679",
    "end": "1185480"
  },
  {
    "text": "related documents within a PDF um like",
    "start": "1185480",
    "end": "1188360"
  },
  {
    "text": "if archive paper has like related Works",
    "start": "1188360",
    "end": "1190880"
  },
  {
    "text": "how do you model this in some sort of",
    "start": "1190880",
    "end": "1192559"
  },
  {
    "text": "graph right the embedded objects on a",
    "start": "1192559",
    "end": "1194360"
  },
  {
    "text": "graph",
    "start": "1194360",
    "end": "1195260"
  },
  {
    "text": "so then when you run a query you start",
    "start": "1195260",
    "end": "1197000"
  },
  {
    "text": "off at the top level nodes each",
    "start": "1197000",
    "end": "1198620"
  },
  {
    "text": "corresponding to maybe a sub-object",
    "start": "1198620",
    "end": "1200299"
  },
  {
    "text": "retrieve the nodes and then go down and",
    "start": "1200299",
    "end": "1202640"
  },
  {
    "text": "actually try retrieving the sub-objects",
    "start": "1202640",
    "end": "1204260"
  },
  {
    "text": "and it's interesting I think we have",
    "start": "1204260",
    "end": "1206120"
  },
  {
    "text": "like a few kind of qualitative analyzes",
    "start": "1206120",
    "end": "1207740"
  },
  {
    "text": "showing that if you just do the naive",
    "start": "1207740",
    "end": "1209360"
  },
  {
    "text": "like text splitting thing a lot of times",
    "start": "1209360",
    "end": "1210799"
  },
  {
    "text": "you just can't parse like tables right",
    "start": "1210799",
    "end": "1212360"
  },
  {
    "text": "it just doesn't work at all and and kind",
    "start": "1212360",
    "end": "1215000"
  },
  {
    "text": "of uh like embedding search has a pretty",
    "start": "1215000",
    "end": "1217820"
  },
  {
    "text": "like it's pretty bad at just being able",
    "start": "1217820",
    "end": "1219620"
  },
  {
    "text": "to parse out relevant information from",
    "start": "1219620",
    "end": "1221960"
  },
  {
    "text": "like a random like dumped table uh",
    "start": "1221960",
    "end": "1224539"
  },
  {
    "text": "within a document but this might warrant",
    "start": "1224539",
    "end": "1227179"
  },
  {
    "text": "like a more structured approach like",
    "start": "1227179",
    "end": "1228380"
  },
  {
    "text": "this",
    "start": "1228380",
    "end": "1230559"
  },
  {
    "text": "cool okay I'm actually doing pretty good",
    "start": "1231440",
    "end": "1234140"
  },
  {
    "text": "on time",
    "start": "1234140",
    "end": "1235160"
  },
  {
    "text": "um I think in the last like three",
    "start": "1235160",
    "end": "1236480"
  },
  {
    "text": "minutes or so I'll talk a little bit",
    "start": "1236480",
    "end": "1238280"
  },
  {
    "text": "about evaluation",
    "start": "1238280",
    "end": "1240620"
  },
  {
    "text": "so maybe this is just a kind of I think",
    "start": "1240620",
    "end": "1243620"
  },
  {
    "text": "I have one slide here but the idea is",
    "start": "1243620",
    "end": "1245480"
  },
  {
    "text": "how exactly do you evaluate retrieval um",
    "start": "1245480",
    "end": "1247940"
  },
  {
    "text": "I actually think evaluating retrieval is",
    "start": "1247940",
    "end": "1249740"
  },
  {
    "text": "pretty important if you want to evaluate",
    "start": "1249740",
    "end": "1251299"
  },
  {
    "text": "like llm stuff in general",
    "start": "1251299",
    "end": "1254000"
  },
  {
    "text": "um I feel like it's something that",
    "start": "1254000",
    "end": "1255080"
  },
  {
    "text": "people don't quite talk about as much as",
    "start": "1255080",
    "end": "1257000"
  },
  {
    "text": "just like measuring the generated uh",
    "start": "1257000",
    "end": "1258740"
  },
  {
    "text": "response quality and hallucination and",
    "start": "1258740",
    "end": "1260360"
  },
  {
    "text": "using like LMS to parse the response",
    "start": "1260360",
    "end": "1263360"
  },
  {
    "text": "um but like the retrieval itself is not",
    "start": "1263360",
    "end": "1265520"
  },
  {
    "text": "really like a new uh problem",
    "start": "1265520",
    "end": "1268160"
  },
  {
    "text": "um it's something that's kind of existed",
    "start": "1268160",
    "end": "1269720"
  },
  {
    "text": "in information retrieval recommender",
    "start": "1269720",
    "end": "1271520"
  },
  {
    "text": "systems for a while but the interesting",
    "start": "1271520",
    "end": "1273679"
  },
  {
    "text": "thing with llms is that they can",
    "start": "1273679",
    "end": "1275419"
  },
  {
    "text": "basically help you generate a synthetic",
    "start": "1275419",
    "end": "1276860"
  },
  {
    "text": "data set and and the better llms get the",
    "start": "1276860",
    "end": "1278960"
  },
  {
    "text": "better the data set that you can",
    "start": "1278960",
    "end": "1280460"
  },
  {
    "text": "Benchmark on can be and then you don't",
    "start": "1280460",
    "end": "1282320"
  },
  {
    "text": "actually need a human in the loop to",
    "start": "1282320",
    "end": "1283700"
  },
  {
    "text": "actually generate this data set so the",
    "start": "1283700",
    "end": "1286340"
  },
  {
    "text": "way this works is that if you want to",
    "start": "1286340",
    "end": "1288320"
  },
  {
    "text": "generate a retrieval data set okay take",
    "start": "1288320",
    "end": "1291020"
  },
  {
    "text": "your documents and similar to rag just",
    "start": "1291020",
    "end": "1292760"
  },
  {
    "text": "like parse and chunk it up now for each",
    "start": "1292760",
    "end": "1294740"
  },
  {
    "text": "chunk uh prompt gbz4 to generate like a",
    "start": "1294740",
    "end": "1297380"
  },
  {
    "text": "set of questions from each chunk or each",
    "start": "1297380",
    "end": "1299240"
  },
  {
    "text": "set of chunks",
    "start": "1299240",
    "end": "1300620"
  },
  {
    "text": "now you have question chunk pairs right",
    "start": "1300620",
    "end": "1303919"
  },
  {
    "text": "and that's basically our ground truth",
    "start": "1303919",
    "end": "1305240"
  },
  {
    "text": "because given a question you know what",
    "start": "1305240",
    "end": "1307640"
  },
  {
    "text": "the ground truth context should be",
    "start": "1307640",
    "end": "1308960"
  },
  {
    "text": "because you just generated a question",
    "start": "1308960",
    "end": "1310159"
  },
  {
    "text": "from that trunk using like group D4",
    "start": "1310159",
    "end": "1312799"
  },
  {
    "text": "so then when you run through your",
    "start": "1312799",
    "end": "1314840"
  },
  {
    "text": "retrieval system on your entire Corpus",
    "start": "1314840",
    "end": "1316700"
  },
  {
    "text": "you can basically measure where in that",
    "start": "1316700",
    "end": "1318679"
  },
  {
    "text": "ranking of retrieve results is that",
    "start": "1318679",
    "end": "1320360"
  },
  {
    "text": "ground truth chunk and then use like",
    "start": "1320360",
    "end": "1322039"
  },
  {
    "text": "traditional ranking metrics and this",
    "start": "1322039",
    "end": "1323900"
  },
  {
    "text": "becomes kind of like an ml ranking",
    "start": "1323900",
    "end": "1325400"
  },
  {
    "text": "problem you can use like ndc3 like Mr a",
    "start": "1325400",
    "end": "1327980"
  },
  {
    "text": "bunch of this stuff to actually measure",
    "start": "1327980",
    "end": "1329720"
  },
  {
    "text": "the performance of it so I think when we",
    "start": "1329720",
    "end": "1331400"
  },
  {
    "text": "evaluated this like this is basically",
    "start": "1331400",
    "end": "1332840"
  },
  {
    "text": "what we did",
    "start": "1332840",
    "end": "1333799"
  },
  {
    "text": "um you can see the Mr performance notice",
    "start": "1333799",
    "end": "1336679"
  },
  {
    "text": "all the numbers are kind of low I can",
    "start": "1336679",
    "end": "1338900"
  },
  {
    "text": "talk a little bit about that turns out a",
    "start": "1338900",
    "end": "1341419"
  },
  {
    "text": "lot of like generated questions become",
    "start": "1341419",
    "end": "1343340"
  },
  {
    "text": "kind of actually irrelevant and so",
    "start": "1343340",
    "end": "1345440"
  },
  {
    "text": "that's kind of like a separate challenge",
    "start": "1345440",
    "end": "1346880"
  },
  {
    "text": "like you do have to make sure that like",
    "start": "1346880",
    "end": "1349100"
  },
  {
    "text": "when you generate these questions",
    "start": "1349100",
    "end": "1350179"
  },
  {
    "text": "they're not just asking about like",
    "start": "1350179",
    "end": "1351740"
  },
  {
    "text": "random things but also like specifically",
    "start": "1351740",
    "end": "1354080"
  },
  {
    "text": "about stuff that can be answered by the",
    "start": "1354080",
    "end": "1355520"
  },
  {
    "text": "context",
    "start": "1355520",
    "end": "1356360"
  },
  {
    "text": "um but that aside I think it's a very",
    "start": "1356360",
    "end": "1358520"
  },
  {
    "text": "powerful approach that basically kind of",
    "start": "1358520",
    "end": "1360260"
  },
  {
    "text": "automates away the need for human",
    "start": "1360260",
    "end": "1361640"
  },
  {
    "text": "curated data sets",
    "start": "1361640",
    "end": "1365260"
  },
  {
    "text": "the last bit I'll probably touch on a",
    "start": "1366080",
    "end": "1368179"
  },
  {
    "text": "little bit um I don't think we'll have",
    "start": "1368179",
    "end": "1369559"
  },
  {
    "text": "time to talk about like document updates",
    "start": "1369559",
    "end": "1370940"
  },
  {
    "text": "but in terms of like addressing",
    "start": "1370940",
    "end": "1372679"
  },
  {
    "text": "scalability challenges",
    "start": "1372679",
    "end": "1374240"
  },
  {
    "text": "is that um yeah I mean I think like",
    "start": "1374240",
    "end": "1377480"
  },
  {
    "text": "um and this is where Ray comes in and",
    "start": "1377480",
    "end": "1379159"
  },
  {
    "text": "can be actually really helpful uh like",
    "start": "1379159",
    "end": "1381260"
  },
  {
    "text": "if you've ever built like a rag pipeline",
    "start": "1381260",
    "end": "1384380"
  },
  {
    "text": "um it's actually quite slow um if you",
    "start": "1384380",
    "end": "1386659"
  },
  {
    "text": "basically just use uh kind of out of the",
    "start": "1386659",
    "end": "1388580"
  },
  {
    "text": "box on there I readily admit this right",
    "start": "1388580",
    "end": "1390140"
  },
  {
    "text": "like llama index or Line train over like",
    "start": "1390140",
    "end": "1392059"
  },
  {
    "text": "10 PDFs or something especially if those",
    "start": "1392059",
    "end": "1393860"
  },
  {
    "text": "PDFs are pretty big it can take a while",
    "start": "1393860",
    "end": "1395720"
  },
  {
    "text": "to actually load in all this data",
    "start": "1395720",
    "end": "1398059"
  },
  {
    "text": "um like parse and chunk this data and",
    "start": "1398059",
    "end": "1399559"
  },
  {
    "text": "embed this data I remember when I was",
    "start": "1399559",
    "end": "1401299"
  },
  {
    "text": "working with omog on this on the blog",
    "start": "1401299",
    "end": "1403039"
  },
  {
    "text": "post we tried indexing like the red",
    "start": "1403039",
    "end": "1404480"
  },
  {
    "text": "documentation which had like 100 like",
    "start": "1404480",
    "end": "1406280"
  },
  {
    "text": "hundreds of files and it took like 20 30",
    "start": "1406280",
    "end": "1408620"
  },
  {
    "text": "minutes if like you just kind of did it",
    "start": "1408620",
    "end": "1410539"
  },
  {
    "text": "naively which was like surprising to me",
    "start": "1410539",
    "end": "1412460"
  },
  {
    "text": "right and it might be because of like",
    "start": "1412460",
    "end": "1413780"
  },
  {
    "text": "the embedding model it might be because",
    "start": "1413780",
    "end": "1415280"
  },
  {
    "text": "of like the parsing algorithm but like",
    "start": "1415280",
    "end": "1418340"
  },
  {
    "text": "uh this is actually something Rey can",
    "start": "1418340",
    "end": "1420140"
  },
  {
    "text": "actually help a lot with that we",
    "start": "1420140",
    "end": "1421640"
  },
  {
    "text": "basically got a 10x Improvement by just",
    "start": "1421640",
    "end": "1423500"
  },
  {
    "text": "like using Rey with different parts of",
    "start": "1423500",
    "end": "1427100"
  },
  {
    "text": "lava index",
    "start": "1427100",
    "end": "1428360"
  },
  {
    "text": "um you know just like massively paralyze",
    "start": "1428360",
    "end": "1430520"
  },
  {
    "text": "a lot of these operations parsing across",
    "start": "1430520",
    "end": "1432620"
  },
  {
    "text": "a bunch of documents can be paralyzed",
    "start": "1432620",
    "end": "1433940"
  },
  {
    "text": "and batting can absolutely be paralyzed",
    "start": "1433940",
    "end": "1435799"
  },
  {
    "text": "loading into like a vector database can",
    "start": "1435799",
    "end": "1438679"
  },
  {
    "text": "can be paralyzed and and so if you can",
    "start": "1438679",
    "end": "1441320"
  },
  {
    "text": "just like figure out the right chunks",
    "start": "1441320",
    "end": "1443000"
  },
  {
    "text": "that parallelize you can massively speed",
    "start": "1443000",
    "end": "1444200"
  },
  {
    "text": "up ingression and if you are interested",
    "start": "1444200",
    "end": "1446240"
  },
  {
    "text": "in this you should check out our blog",
    "start": "1446240",
    "end": "1447380"
  },
  {
    "text": "posts",
    "start": "1447380",
    "end": "1449679"
  },
  {
    "text": "um a quick call out we have a full",
    "start": "1450140",
    "end": "1451580"
  },
  {
    "text": "workshop with cybin my co-founder and",
    "start": "1451580",
    "end": "1454280"
  },
  {
    "text": "CTO along with amag and Goku on",
    "start": "1454280",
    "end": "1457400"
  },
  {
    "text": "Wednesday",
    "start": "1457400",
    "end": "1458120"
  },
  {
    "text": "um it's I think it's like a three hour",
    "start": "1458120",
    "end": "1459559"
  },
  {
    "text": "Workshop or something and so basically a",
    "start": "1459559",
    "end": "1461720"
  },
  {
    "text": "lot of these Concepts I just talked",
    "start": "1461720",
    "end": "1463220"
  },
  {
    "text": "about you'll actually learn how to",
    "start": "1463220",
    "end": "1464720"
  },
  {
    "text": "implement them and then have evaluation",
    "start": "1464720",
    "end": "1467659"
  },
  {
    "text": "in the loop so that you can pretty much",
    "start": "1467659",
    "end": "1469880"
  },
  {
    "text": "validate whether or not this is",
    "start": "1469880",
    "end": "1471440"
  },
  {
    "text": "something that you know is actually",
    "start": "1471440",
    "end": "1472820"
  },
  {
    "text": "useful to help you iterate on your Mac",
    "start": "1472820",
    "end": "1474740"
  },
  {
    "text": "system and improve it and so it's",
    "start": "1474740",
    "end": "1476720"
  },
  {
    "text": "actually really really comprehensive we",
    "start": "1476720",
    "end": "1478520"
  },
  {
    "text": "obviously I mean we have Ray at every",
    "start": "1478520",
    "end": "1480380"
  },
  {
    "text": "step to help you like speed up stuff and",
    "start": "1480380",
    "end": "1481880"
  },
  {
    "text": "also help you deploy the final thing at",
    "start": "1481880",
    "end": "1484100"
  },
  {
    "text": "the end but it's everything from",
    "start": "1484100",
    "end": "1485900"
  },
  {
    "text": "prototype to production and at the end",
    "start": "1485900",
    "end": "1488120"
  },
  {
    "text": "of the day that's basically what watam",
    "start": "1488120",
    "end": "1489919"
  },
  {
    "text": "index is focused on we don't want you to",
    "start": "1489919",
    "end": "1491480"
  },
  {
    "text": "just build the easy stuff in five lines",
    "start": "1491480",
    "end": "1493220"
  },
  {
    "text": "code we want you to really iterate on",
    "start": "1493220",
    "end": "1495380"
  },
  {
    "text": "improve the retrieval system and create",
    "start": "1495380",
    "end": "1497419"
  },
  {
    "text": "something production quality",
    "start": "1497419",
    "end": "1499220"
  },
  {
    "text": "um I think that's it thank you",
    "start": "1499220",
    "end": "1502360"
  },
  {
    "text": "you can",
    "start": "1505880",
    "end": "1507260"
  },
  {
    "text": "we can probably have two questions",
    "start": "1507260",
    "end": "1508760"
  },
  {
    "text": "please raise your hand I like it",
    "start": "1508760",
    "end": "1512500"
  },
  {
    "text": "thank you I have a question in your",
    "start": "1512780",
    "end": "1515600"
  },
  {
    "text": "experience like",
    "start": "1515600",
    "end": "1517520"
  },
  {
    "text": "um our gpt4 models and so on",
    "start": "1517520",
    "end": "1520100"
  },
  {
    "text": "um those are the capabilities to answer",
    "start": "1520100",
    "end": "1522080"
  },
  {
    "text": "is that provide is the right chunks or",
    "start": "1522080",
    "end": "1524720"
  },
  {
    "text": "you also potentially need to fine tune",
    "start": "1524720",
    "end": "1526159"
  },
  {
    "text": "the llm sanitizer too",
    "start": "1526159",
    "end": "1528919"
  },
  {
    "text": "sorry that was a question whether you",
    "start": "1528919",
    "end": "1530900"
  },
  {
    "text": "need to fine-tune the llm for yeah my",
    "start": "1530900",
    "end": "1533360"
  },
  {
    "text": "question is like do they have",
    "start": "1533360",
    "end": "1534740"
  },
  {
    "text": "capabilities built in on and then they",
    "start": "1534740",
    "end": "1537440"
  },
  {
    "text": "just need the right context or in your",
    "start": "1537440",
    "end": "1540200"
  },
  {
    "text": "experience you also think that it's",
    "start": "1540200",
    "end": "1542120"
  },
  {
    "text": "sometimes needed to fine-tune the llm",
    "start": "1542120",
    "end": "1545360"
  },
  {
    "text": "synthetizer too yeah that's a good",
    "start": "1545360",
    "end": "1547279"
  },
  {
    "text": "question I have like an entire separate",
    "start": "1547279",
    "end": "1548840"
  },
  {
    "text": "talk on on fine tuning I think it's",
    "start": "1548840",
    "end": "1550400"
  },
  {
    "text": "something we're actively trying to",
    "start": "1550400",
    "end": "1551600"
  },
  {
    "text": "figure out right now I will say for gpt4",
    "start": "1551600",
    "end": "1554240"
  },
  {
    "text": "gbd4 is probably like the gold standard",
    "start": "1554240",
    "end": "1556640"
  },
  {
    "text": "of Ally models these days and so",
    "start": "1556640",
    "end": "1558320"
  },
  {
    "text": "actually we haven't really tried",
    "start": "1558320",
    "end": "1560240"
  },
  {
    "text": "fine-tuning gbt4 and I was open AI",
    "start": "1560240",
    "end": "1562400"
  },
  {
    "text": "definitely has but what we have done is",
    "start": "1562400",
    "end": "1564080"
  },
  {
    "text": "use GPT 4's ground truth to fine-tune",
    "start": "1564080",
    "end": "1566000"
  },
  {
    "text": "like a weaker model like Mama 2 or um",
    "start": "1566000",
    "end": "1568220"
  },
  {
    "text": "GPT 3.5 and it turns out it actually",
    "start": "1568220",
    "end": "1570440"
  },
  {
    "text": "does pretty well you can have if you",
    "start": "1570440",
    "end": "1572360"
  },
  {
    "text": "fine-tune llama2 or group D 3.5 on like",
    "start": "1572360",
    "end": "1574880"
  },
  {
    "text": "the Chain of Thought reasoning of gpd4",
    "start": "1574880",
    "end": "1576640"
  },
  {
    "text": "on its ability to write text to SQL on",
    "start": "1576640",
    "end": "1579559"
  },
  {
    "text": "its ability to generate like coherent",
    "start": "1579559",
    "end": "1581120"
  },
  {
    "text": "responses given context it actually",
    "start": "1581120",
    "end": "1583220"
  },
  {
    "text": "works pretty well and so I would I would",
    "start": "1583220",
    "end": "1585020"
  },
  {
    "text": "definitely encourage you to do that if",
    "start": "1585020",
    "end": "1586100"
  },
  {
    "text": "you're using a cheaper model",
    "start": "1586100",
    "end": "1588860"
  },
  {
    "text": "um I have a question about this all",
    "start": "1588860",
    "end": "1590900"
  },
  {
    "text": "sounds good but the issue is context",
    "start": "1590900",
    "end": "1592460"
  },
  {
    "text": "window size so",
    "start": "1592460",
    "end": "1594919"
  },
  {
    "text": "um you know some of the models like",
    "start": "1594919",
    "end": "1596360"
  },
  {
    "text": "llama2 for example only have a four four",
    "start": "1596360",
    "end": "1598580"
  },
  {
    "text": "K tokens right that's not a lot and by",
    "start": "1598580",
    "end": "1600919"
  },
  {
    "text": "the time you add this metadata you can",
    "start": "1600919",
    "end": "1602539"
  },
  {
    "text": "maybe get two or three documents at most",
    "start": "1602539",
    "end": "1604700"
  },
  {
    "text": "in there how do you handle the",
    "start": "1604700",
    "end": "1606860"
  },
  {
    "text": "limitations of the context window size",
    "start": "1606860",
    "end": "1609140"
  },
  {
    "text": "so that's a great question I think",
    "start": "1609140",
    "end": "1611000"
  },
  {
    "text": "that's uh precisely the trade-off of",
    "start": "1611000",
    "end": "1613279"
  },
  {
    "text": "metadata if you inject it into that tax",
    "start": "1613279",
    "end": "1615740"
  },
  {
    "text": "itself and so I think for when you",
    "start": "1615740",
    "end": "1618260"
  },
  {
    "text": "inject it into that text there is really",
    "start": "1618260",
    "end": "1620299"
  },
  {
    "text": "two ways you can use metadata you can",
    "start": "1620299",
    "end": "1622159"
  },
  {
    "text": "use that for a batting based retrieval",
    "start": "1622159",
    "end": "1623659"
  },
  {
    "text": "or you can use it for LM synthesis and",
    "start": "1623659",
    "end": "1625820"
  },
  {
    "text": "with alarm index you can actually",
    "start": "1625820",
    "end": "1626960"
  },
  {
    "text": "control whether or not the metadata as a",
    "start": "1626960",
    "end": "1630620"
  },
  {
    "text": "structured dictionary actually gets",
    "start": "1630620",
    "end": "1632840"
  },
  {
    "text": "injected during a batting time or during",
    "start": "1632840",
    "end": "1635000"
  },
  {
    "text": "synthesis time and so if you're really",
    "start": "1635000",
    "end": "1637400"
  },
  {
    "text": "worried about like limited context",
    "start": "1637400",
    "end": "1638720"
  },
  {
    "text": "windows and again it makes retrieval a",
    "start": "1638720",
    "end": "1640940"
  },
  {
    "text": "little bit slower too you could just not",
    "start": "1640940",
    "end": "1642799"
  },
  {
    "text": "put the metadata into the",
    "start": "1642799",
    "end": "1645140"
  },
  {
    "text": "um into the text itself during",
    "start": "1645140",
    "end": "1647059"
  },
  {
    "text": "generation time but you could still use",
    "start": "1647059",
    "end": "1648980"
  },
  {
    "text": "that for metadata filtering right for",
    "start": "1648980",
    "end": "1650600"
  },
  {
    "text": "for Vector databases and stuff so",
    "start": "1650600",
    "end": "1653000"
  },
  {
    "text": "there's ways that you can use it without",
    "start": "1653000",
    "end": "1654260"
  },
  {
    "text": "stuffing the contacts window",
    "start": "1654260",
    "end": "1657100"
  },
  {
    "text": "quick question on uh rag so when you're",
    "start": "1657140",
    "end": "1659840"
  },
  {
    "text": "retrieving information from Vector DB",
    "start": "1659840",
    "end": "1661880"
  },
  {
    "text": "are you guys doing any optimization on",
    "start": "1661880",
    "end": "1663740"
  },
  {
    "text": "that because I've seen that most of the",
    "start": "1663740",
    "end": "1665659"
  },
  {
    "text": "next solution they only do use KNN",
    "start": "1665659",
    "end": "1668720"
  },
  {
    "text": "yeah um I guess all these are",
    "start": "1668720",
    "end": "1672440"
  },
  {
    "text": "optimizations but these are pretty much",
    "start": "1672440",
    "end": "1675020"
  },
  {
    "text": "like um I I'll try to send the slides as",
    "start": "1675020",
    "end": "1677539"
  },
  {
    "text": "well uh I think like the idea here is um",
    "start": "1677539",
    "end": "1681020"
  },
  {
    "text": "pretty much every technique mentioned is",
    "start": "1681020",
    "end": "1682880"
  },
  {
    "text": "on like a single page in our docs called",
    "start": "1682880",
    "end": "1684740"
  },
  {
    "text": "like kind of techniques you can try it",
    "start": "1684740",
    "end": "1686539"
  },
  {
    "text": "to create like more performant rag",
    "start": "1686539",
    "end": "1688039"
  },
  {
    "text": "Beyond just like standard top K and so",
    "start": "1688039",
    "end": "1691039"
  },
  {
    "text": "there's like I guess the idea is there's",
    "start": "1691039",
    "end": "1693260"
  },
  {
    "text": "like the data representations there's",
    "start": "1693260",
    "end": "1694940"
  },
  {
    "text": "like the retrieval algorithm itself it",
    "start": "1694940",
    "end": "1696740"
  },
  {
    "text": "could be top K it could be using",
    "start": "1696740",
    "end": "1698000"
  },
  {
    "text": "metadata filters it could be using",
    "start": "1698000",
    "end": "1699260"
  },
  {
    "text": "hybrid search and then it's also the way",
    "start": "1699260",
    "end": "1701360"
  },
  {
    "text": "you like kind of organize and structure",
    "start": "1701360",
    "end": "1703039"
  },
  {
    "text": "the retrieval Hardware them and so it's",
    "start": "1703039",
    "end": "1704840"
  },
  {
    "text": "like all these things that you can do to",
    "start": "1704840",
    "end": "1705980"
  },
  {
    "text": "try to optimize beyond the existing",
    "start": "1705980",
    "end": "1707659"
  },
  {
    "text": "approaches",
    "start": "1707659",
    "end": "1709460"
  },
  {
    "text": "um so we're gonna take the rest of the",
    "start": "1709460",
    "end": "1710779"
  },
  {
    "text": "question offline so thank you very much",
    "start": "1710779",
    "end": "1713000"
  },
  {
    "text": "Sherry for a very insightful",
    "start": "1713000",
    "end": "1714380"
  },
  {
    "text": "presentations uh please give another",
    "start": "1714380",
    "end": "1716419"
  },
  {
    "text": "round of applause for cherry",
    "start": "1716419",
    "end": "1719679"
  }
]
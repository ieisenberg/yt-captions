[
  {
    "text": "foreign",
    "start": "4860",
    "end": "7040"
  },
  {
    "text": "a software engineer at any skill",
    "start": "9559",
    "end": "12420"
  },
  {
    "text": "with me today is Kai shinchen kashin you",
    "start": "12420",
    "end": "14940"
  },
  {
    "text": "want to introduce oh hi I'm kaishin and",
    "start": "14940",
    "end": "16740"
  },
  {
    "text": "I'm a software engineering and scale and",
    "start": "16740",
    "end": "18539"
  },
  {
    "text": "the focus here on kilbrey",
    "start": "18539",
    "end": "20880"
  },
  {
    "text": "thanks so much for joining us today",
    "start": "20880",
    "end": "22980"
  },
  {
    "text": "um we're delighted to talk to you about",
    "start": "22980",
    "end": "24779"
  },
  {
    "text": "kubrey which is a kubernetes operator",
    "start": "24779",
    "end": "26939"
  },
  {
    "text": "for deploying and managing Ray",
    "start": "26939",
    "end": "28619"
  },
  {
    "text": "applications",
    "start": "28619",
    "end": "31160"
  },
  {
    "text": "today's agenda will cover the core",
    "start": "32640",
    "end": "34260"
  },
  {
    "text": "components of kubrey including the ray",
    "start": "34260",
    "end": "36719"
  },
  {
    "text": "cluster custom resource rayjob custom",
    "start": "36719",
    "end": "39300"
  },
  {
    "text": "resource and Race Service custom",
    "start": "39300",
    "end": "41460"
  },
  {
    "text": "resource",
    "start": "41460",
    "end": "43140"
  },
  {
    "text": "we'll also dive into some real world use",
    "start": "43140",
    "end": "45180"
  },
  {
    "text": "cases and even walk you through a demo",
    "start": "45180",
    "end": "47579"
  },
  {
    "text": "of how Cuba can handle the whole llm",
    "start": "47579",
    "end": "50039"
  },
  {
    "text": "lifecycle from fine tuning to serving",
    "start": "50039",
    "end": "52920"
  },
  {
    "text": "and more",
    "start": "52920",
    "end": "54719"
  },
  {
    "text": "finally we'll discuss some Community",
    "start": "54719",
    "end": "56340"
  },
  {
    "text": "News including collaborations and",
    "start": "56340",
    "end": "58980"
  },
  {
    "text": "testimonials",
    "start": "58980",
    "end": "61760"
  },
  {
    "text": "so what exactly is kubrey",
    "start": "63480",
    "end": "66659"
  },
  {
    "text": "kubrey is a kubernetes operator that",
    "start": "66659",
    "end": "69000"
  },
  {
    "text": "manages the entire life cycle of Ray",
    "start": "69000",
    "end": "70979"
  },
  {
    "text": "clusters and their Associated",
    "start": "70979",
    "end": "72780"
  },
  {
    "text": "applications on kubernetes",
    "start": "72780",
    "end": "75479"
  },
  {
    "text": "to paraphrase the kubernetes docs",
    "start": "75479",
    "end": "77640"
  },
  {
    "text": "operators are software extensions to",
    "start": "77640",
    "end": "80040"
  },
  {
    "text": "kubernetes that make use of custom",
    "start": "80040",
    "end": "81960"
  },
  {
    "text": "resources to manage applications and",
    "start": "81960",
    "end": "84360"
  },
  {
    "text": "their components in this case Ray",
    "start": "84360",
    "end": "86880"
  },
  {
    "text": "clusters Ray jobs and race services and",
    "start": "86880",
    "end": "91080"
  },
  {
    "text": "I'll talk more about those later",
    "start": "91080",
    "end": "94280"
  },
  {
    "text": "Rey excels at large-scale data",
    "start": "94799",
    "end": "97200"
  },
  {
    "text": "computation especially for machine",
    "start": "97200",
    "end": "99180"
  },
  {
    "text": "learning tasks",
    "start": "99180",
    "end": "100619"
  },
  {
    "text": "while kubrey focuses on seamlessly",
    "start": "100619",
    "end": "102960"
  },
  {
    "text": "integrating Ray into the kubernetes",
    "start": "102960",
    "end": "105000"
  },
  {
    "text": "ecosystem",
    "start": "105000",
    "end": "107220"
  },
  {
    "text": "what you can see from this diagram",
    "start": "107220",
    "end": "109500"
  },
  {
    "text": "is that Ray provides you with two ways",
    "start": "109500",
    "end": "111960"
  },
  {
    "text": "to manage the array infrastructure",
    "start": "111960",
    "end": "114420"
  },
  {
    "text": "either directly through the ray VM",
    "start": "114420",
    "end": "116700"
  },
  {
    "text": "cluster launchers",
    "start": "116700",
    "end": "118320"
  },
  {
    "text": "or through kubre for kubernetes",
    "start": "118320",
    "end": "120780"
  },
  {
    "text": "deployments",
    "start": "120780",
    "end": "122700"
  },
  {
    "text": "in this talk we're focusing on kubre",
    "start": "122700",
    "end": "127039"
  },
  {
    "text": "why is kubray the best solution for",
    "start": "129360",
    "end": "131160"
  },
  {
    "text": "running rayon kubernetes",
    "start": "131160",
    "end": "133260"
  },
  {
    "text": "well",
    "start": "133260",
    "end": "134400"
  },
  {
    "text": "kubre enables data and ml scientists to",
    "start": "134400",
    "end": "137640"
  },
  {
    "text": "focus on what they do best",
    "start": "137640",
    "end": "139459"
  },
  {
    "text": "experiments and computation",
    "start": "139459",
    "end": "142680"
  },
  {
    "text": "meanwhile infrastructure Engineers can",
    "start": "142680",
    "end": "145680"
  },
  {
    "text": "concentrate on the deployment side and",
    "start": "145680",
    "end": "148140"
  },
  {
    "text": "on integrating Cube Ray with kubernetes",
    "start": "148140",
    "end": "150060"
  },
  {
    "text": "ecosystem tools like Prometheus grafana",
    "start": "150060",
    "end": "153680"
  },
  {
    "text": "nginx and others",
    "start": "153680",
    "end": "157819"
  },
  {
    "text": "the details of the arrows here are not",
    "start": "158160",
    "end": "160140"
  },
  {
    "text": "so important if you're familiar with",
    "start": "160140",
    "end": "161459"
  },
  {
    "text": "kubernetes operators already it's just a",
    "start": "161459",
    "end": "163739"
  },
  {
    "text": "standard pattern for operators",
    "start": "163739",
    "end": "165959"
  },
  {
    "text": "some the summary is that both Rey and",
    "start": "165959",
    "end": "168300"
  },
  {
    "text": "kubernetes serve as resource",
    "start": "168300",
    "end": "169800"
  },
  {
    "text": "orchestrators but they focus on",
    "start": "169800",
    "end": "171660"
  },
  {
    "text": "different aspects",
    "start": "171660",
    "end": "173280"
  },
  {
    "text": "Rey is all about computation",
    "start": "173280",
    "end": "175500"
  },
  {
    "text": "handling tasks and actors while",
    "start": "175500",
    "end": "178080"
  },
  {
    "text": "kubernetes is geared towards deployment",
    "start": "178080",
    "end": "180239"
  },
  {
    "text": "managing pods as its scheduling units",
    "start": "180239",
    "end": "183959"
  },
  {
    "text": "so the main takeaway here is that this",
    "start": "183959",
    "end": "186060"
  },
  {
    "text": "allows for the separation of",
    "start": "186060",
    "end": "187319"
  },
  {
    "text": "responsibilities between data and ml",
    "start": "187319",
    "end": "189959"
  },
  {
    "text": "scientists and infrastructure engineers",
    "start": "189959",
    "end": "194360"
  },
  {
    "text": "kubrey offers Three core components for",
    "start": "197760",
    "end": "200220"
  },
  {
    "text": "different workloads",
    "start": "200220",
    "end": "202560"
  },
  {
    "text": "for the first use case",
    "start": "202560",
    "end": "204540"
  },
  {
    "text": "imagine you want to have a long-running",
    "start": "204540",
    "end": "206459"
  },
  {
    "text": "cluster to submit multiple workloads to",
    "start": "206459",
    "end": "210300"
  },
  {
    "text": "possibly from multiple users",
    "start": "210300",
    "end": "213420"
  },
  {
    "text": "or perhaps you want to spin up a",
    "start": "213420",
    "end": "215760"
  },
  {
    "text": "temporary cluster for debugging writing",
    "start": "215760",
    "end": "218099"
  },
  {
    "text": "unit tests or prototyping",
    "start": "218099",
    "end": "221340"
  },
  {
    "text": "for these use cases you can use the ray",
    "start": "221340",
    "end": "224280"
  },
  {
    "text": "cluster custom resource at the top here",
    "start": "224280",
    "end": "227700"
  },
  {
    "text": "the ray cluster custom resource manages",
    "start": "227700",
    "end": "229799"
  },
  {
    "text": "the life cycle of array cluster",
    "start": "229799",
    "end": "232319"
  },
  {
    "text": "it supports Auto scaling and it also",
    "start": "232319",
    "end": "234959"
  },
  {
    "text": "supports GCS fault tolerance for if the",
    "start": "234959",
    "end": "237720"
  },
  {
    "text": "ray head node goes down and I'll talk",
    "start": "237720",
    "end": "239519"
  },
  {
    "text": "more about that later",
    "start": "239519",
    "end": "242420"
  },
  {
    "text": "for the Second Use case imagine you have",
    "start": "243480",
    "end": "245940"
  },
  {
    "text": "ad hoc workloads where you don't know",
    "start": "245940",
    "end": "248400"
  },
  {
    "text": "when they'll be submitted",
    "start": "248400",
    "end": "250140"
  },
  {
    "text": "but you don't want to pay the cost of",
    "start": "250140",
    "end": "252360"
  },
  {
    "text": "having a live cluster up and running all",
    "start": "252360",
    "end": "255060"
  },
  {
    "text": "the time",
    "start": "255060",
    "end": "257040"
  },
  {
    "text": "for a case like this you can use the ray",
    "start": "257040",
    "end": "259199"
  },
  {
    "text": "job custom resource",
    "start": "259199",
    "end": "262320"
  },
  {
    "text": "Ray job is essentially two components",
    "start": "262320",
    "end": "264900"
  },
  {
    "text": "array cluster",
    "start": "264900",
    "end": "266460"
  },
  {
    "text": "plus a job",
    "start": "266460",
    "end": "268560"
  },
  {
    "text": "it automatically creates a re-cluster",
    "start": "268560",
    "end": "270600"
  },
  {
    "text": "and submits a job when the cluster is",
    "start": "270600",
    "end": "272340"
  },
  {
    "text": "ready using the ray job API",
    "start": "272340",
    "end": "275880"
  },
  {
    "text": "best of all you can recycle the ray",
    "start": "275880",
    "end": "277620"
  },
  {
    "text": "cluster automatically after the job",
    "start": "277620",
    "end": "279419"
  },
  {
    "text": "completes",
    "start": "279419",
    "end": "281960"
  },
  {
    "text": "finally suppose you're responsible for a",
    "start": "283139",
    "end": "285840"
  },
  {
    "text": "service",
    "start": "285840",
    "end": "286800"
  },
  {
    "text": "so uptime and latency are prime concerns",
    "start": "286800",
    "end": "289320"
  },
  {
    "text": "for you",
    "start": "289320",
    "end": "290639"
  },
  {
    "text": "for this use case you can use the ray",
    "start": "290639",
    "end": "292680"
  },
  {
    "text": "service custom resource",
    "start": "292680",
    "end": "294540"
  },
  {
    "text": "it not only creates a ray cluster but",
    "start": "294540",
    "end": "297479"
  },
  {
    "text": "also ensures zero downtime upgrades and",
    "start": "297479",
    "end": "300120"
  },
  {
    "text": "high availability",
    "start": "300120",
    "end": "301440"
  },
  {
    "text": "which are features that we'll dive into",
    "start": "301440",
    "end": "302880"
  },
  {
    "text": "in the next few slides",
    "start": "302880",
    "end": "305940"
  },
  {
    "text": "to sum it up you can use the ray cluster",
    "start": "305940",
    "end": "308040"
  },
  {
    "text": "custom resource for both long running",
    "start": "308040",
    "end": "310620"
  },
  {
    "text": "clusters or lightweight ephemeral",
    "start": "310620",
    "end": "312900"
  },
  {
    "text": "clusters",
    "start": "312900",
    "end": "314400"
  },
  {
    "text": "you can use the raid job custom resource",
    "start": "314400",
    "end": "316560"
  },
  {
    "text": "for ad hoc or scheduled workloads",
    "start": "316560",
    "end": "319259"
  },
  {
    "text": "and you can use the ray service custom",
    "start": "319259",
    "end": "320759"
  },
  {
    "text": "resource when uptime is Paramount",
    "start": "320759",
    "end": "325080"
  },
  {
    "text": "and for those who may be less familiar a",
    "start": "325080",
    "end": "327479"
  },
  {
    "text": "custom resource is simply an extension",
    "start": "327479",
    "end": "330120"
  },
  {
    "text": "of the kubernetes API that can be used",
    "start": "330120",
    "end": "332520"
  },
  {
    "text": "alongside the built-in resources that",
    "start": "332520",
    "end": "334740"
  },
  {
    "text": "you're familiar with such as pods for",
    "start": "334740",
    "end": "336479"
  },
  {
    "text": "example",
    "start": "336479",
    "end": "337860"
  },
  {
    "text": "like other resources you declare the",
    "start": "337860",
    "end": "339600"
  },
  {
    "text": "desired state of the resource",
    "start": "339600",
    "end": "341460"
  },
  {
    "text": "and the kubrey operator keeps the",
    "start": "341460",
    "end": "343380"
  },
  {
    "text": "current state of kubernetes objects in",
    "start": "343380",
    "end": "345600"
  },
  {
    "text": "sync with the declared desired state",
    "start": "345600",
    "end": "349080"
  },
  {
    "text": "and so for each of these three custom",
    "start": "349080",
    "end": "350880"
  },
  {
    "text": "resources we're going to dive into the",
    "start": "350880",
    "end": "352860"
  },
  {
    "text": "details of how that's accomplished",
    "start": "352860",
    "end": "356478"
  },
  {
    "text": "we'll start with the ray cluster custom",
    "start": "360120",
    "end": "361800"
  },
  {
    "text": "resource definition",
    "start": "361800",
    "end": "363419"
  },
  {
    "text": "as mentioned earlier kubre follows the",
    "start": "363419",
    "end": "366120"
  },
  {
    "text": "classic kubernetes operator pattern for",
    "start": "366120",
    "end": "368639"
  },
  {
    "text": "managing ra clusters",
    "start": "368639",
    "end": "370740"
  },
  {
    "text": "this slide shows the architecture of the",
    "start": "370740",
    "end": "372840"
  },
  {
    "text": "ray cluster custom resource definition",
    "start": "372840",
    "end": "375840"
  },
  {
    "text": "as a user you just need to create array",
    "start": "375840",
    "end": "378120"
  },
  {
    "text": "cluster custom resource",
    "start": "378120",
    "end": "380100"
  },
  {
    "text": "the kubrey operator then automatically",
    "start": "380100",
    "end": "382380"
  },
  {
    "text": "takes care of the creation deletion and",
    "start": "382380",
    "end": "385560"
  },
  {
    "text": "updating of any kubernetes resources",
    "start": "385560",
    "end": "388020"
  },
  {
    "text": "that it needs to spin up the ray head",
    "start": "388020",
    "end": "389819"
  },
  {
    "text": "and worker pods",
    "start": "389819",
    "end": "392280"
  },
  {
    "text": "the idea is to let you focus on the ray",
    "start": "392280",
    "end": "394380"
  },
  {
    "text": "cluster configuration while kubre takes",
    "start": "394380",
    "end": "397199"
  },
  {
    "text": "care of the kubernetes aspects",
    "start": "397199",
    "end": "400759"
  },
  {
    "text": "one key feature here is that kubray",
    "start": "403740",
    "end": "406199"
  },
  {
    "text": "integrates seamlessly with the ray Auto",
    "start": "406199",
    "end": "408180"
  },
  {
    "text": "scaler",
    "start": "408180",
    "end": "409560"
  },
  {
    "text": "this allows your raid clusters to",
    "start": "409560",
    "end": "411539"
  },
  {
    "text": "dynamically Scale based on the workload",
    "start": "411539",
    "end": "414780"
  },
  {
    "text": "you can add GPU pods",
    "start": "414780",
    "end": "417120"
  },
  {
    "text": "when they're needed",
    "start": "417120",
    "end": "419039"
  },
  {
    "text": "and remove them when they're not",
    "start": "419039",
    "end": "421800"
  },
  {
    "text": "so here we have array cluster that's",
    "start": "421800",
    "end": "423660"
  },
  {
    "text": "going back and forth between these two",
    "start": "423660",
    "end": "425819"
  },
  {
    "text": "states where in the minimal State it's",
    "start": "425819",
    "end": "427800"
  },
  {
    "text": "just a head node which only has a CPU",
    "start": "427800",
    "end": "429780"
  },
  {
    "text": "but if gpus are needed for a workload",
    "start": "429780",
    "end": "432479"
  },
  {
    "text": "that same cluster can scale up",
    "start": "432479",
    "end": "436100"
  },
  {
    "text": "using this you get both performance and",
    "start": "437580",
    "end": "440400"
  },
  {
    "text": "cost efficiency",
    "start": "440400",
    "end": "443240"
  },
  {
    "text": "now let's talk about Ray job a custom",
    "start": "446639",
    "end": "449400"
  },
  {
    "text": "resource that's particularly beneficial",
    "start": "449400",
    "end": "451259"
  },
  {
    "text": "for those concerned about Cloud resource",
    "start": "451259",
    "end": "453180"
  },
  {
    "text": "costs",
    "start": "453180",
    "end": "455099"
  },
  {
    "text": "you create a ray job",
    "start": "455099",
    "end": "457080"
  },
  {
    "text": "and then the kubrey operator Springs",
    "start": "457080",
    "end": "458639"
  },
  {
    "text": "into action creating updating and",
    "start": "458639",
    "end": "460979"
  },
  {
    "text": "deleting the kubernetes resources",
    "start": "460979",
    "end": "463979"
  },
  {
    "text": "and one great thing about this is as we",
    "start": "463979",
    "end": "466139"
  },
  {
    "text": "mentioned previously",
    "start": "466139",
    "end": "467580"
  },
  {
    "text": "once the job is done",
    "start": "467580",
    "end": "469740"
  },
  {
    "text": "it will automatically delete the ray",
    "start": "469740",
    "end": "471539"
  },
  {
    "text": "cluster conserving your valuable Cloud",
    "start": "471539",
    "end": "473759"
  },
  {
    "text": "resources",
    "start": "473759",
    "end": "475560"
  },
  {
    "text": "and the deletion of course is an",
    "start": "475560",
    "end": "477840"
  },
  {
    "text": "optional feature you can disable it in",
    "start": "477840",
    "end": "479520"
  },
  {
    "text": "case you'd rather leave the cluster up",
    "start": "479520",
    "end": "481139"
  },
  {
    "text": "and running for postmortem debugging",
    "start": "481139",
    "end": "484639"
  },
  {
    "text": "finally let's talk about the race",
    "start": "487440",
    "end": "489180"
  },
  {
    "text": "service custom resource",
    "start": "489180",
    "end": "491520"
  },
  {
    "text": "before going into the architecture",
    "start": "491520",
    "end": "493139"
  },
  {
    "text": "diagram for the ray service let's just",
    "start": "493139",
    "end": "494759"
  },
  {
    "text": "describe two of the key stability",
    "start": "494759",
    "end": "496500"
  },
  {
    "text": "features that Ray service brings to the",
    "start": "496500",
    "end": "498300"
  },
  {
    "text": "table",
    "start": "498300",
    "end": "500400"
  },
  {
    "text": "first up is zero downtime cluster",
    "start": "500400",
    "end": "502979"
  },
  {
    "text": "changes",
    "start": "502979",
    "end": "504960"
  },
  {
    "text": "Race Service automatically detects both",
    "start": "504960",
    "end": "507419"
  },
  {
    "text": "unhealthy cluster States",
    "start": "507419",
    "end": "509520"
  },
  {
    "text": "and user config changes that would",
    "start": "509520",
    "end": "511800"
  },
  {
    "text": "necessitate a new cluster",
    "start": "511800",
    "end": "514560"
  },
  {
    "text": "in response it spins up a new Ray",
    "start": "514560",
    "end": "516959"
  },
  {
    "text": "cluster shifts the traffic and finally",
    "start": "516959",
    "end": "519779"
  },
  {
    "text": "deletes the old array cluster",
    "start": "519779",
    "end": "523080"
  },
  {
    "text": "and what about high availability and GCS",
    "start": "523080",
    "end": "525660"
  },
  {
    "text": "fault tolerance",
    "start": "525660",
    "end": "527459"
  },
  {
    "text": "the GCS or Global control service is a",
    "start": "527459",
    "end": "531120"
  },
  {
    "text": "core component of the ray head node that",
    "start": "531120",
    "end": "533339"
  },
  {
    "text": "manages cluster level metadata",
    "start": "533339",
    "end": "536220"
  },
  {
    "text": "but even if the ray head pod goes down",
    "start": "536220",
    "end": "538920"
  },
  {
    "text": "Ray service ensures that user traffic",
    "start": "538920",
    "end": "541019"
  },
  {
    "text": "continues to flow to worker pods",
    "start": "541019",
    "end": "543080"
  },
  {
    "text": "uninterrupted while the new head pod",
    "start": "543080",
    "end": "545399"
  },
  {
    "text": "starts back up",
    "start": "545399",
    "end": "547080"
  },
  {
    "text": "this makes it highly available and fault",
    "start": "547080",
    "end": "548940"
  },
  {
    "text": "tolerant",
    "start": "548940",
    "end": "551420"
  },
  {
    "text": "the architecture diagram for Race",
    "start": "553560",
    "end": "555240"
  },
  {
    "text": "Service is pretty similar to the ones",
    "start": "555240",
    "end": "556620"
  },
  {
    "text": "we've seen before",
    "start": "556620",
    "end": "558360"
  },
  {
    "text": "the user creates array service custom",
    "start": "558360",
    "end": "560160"
  },
  {
    "text": "resource the operator monitors the",
    "start": "560160",
    "end": "562860"
  },
  {
    "text": "service and updates race serve",
    "start": "562860",
    "end": "565080"
  },
  {
    "text": "applications in place",
    "start": "565080",
    "end": "567600"
  },
  {
    "text": "the kubrey operator takes care of",
    "start": "567600",
    "end": "569160"
  },
  {
    "text": "creating updating deleting the",
    "start": "569160",
    "end": "570839"
  },
  {
    "text": "kubernetes resources just like it does",
    "start": "570839",
    "end": "572399"
  },
  {
    "text": "for Ray cluster and Ray job",
    "start": "572399",
    "end": "575100"
  },
  {
    "text": "and note that in the case of the zero",
    "start": "575100",
    "end": "577019"
  },
  {
    "text": "downtime feature that I mentioned in the",
    "start": "577019",
    "end": "578700"
  },
  {
    "text": "previous Slide the race service might be",
    "start": "578700",
    "end": "580860"
  },
  {
    "text": "managing two Ray clusters one of them",
    "start": "580860",
    "end": "582720"
  },
  {
    "text": "pending one of them active as indicated",
    "start": "582720",
    "end": "584760"
  },
  {
    "text": "in the picture",
    "start": "584760",
    "end": "586980"
  },
  {
    "text": "finally with the setup",
    "start": "586980",
    "end": "589140"
  },
  {
    "text": "the user maybe a different user from the",
    "start": "589140",
    "end": "591180"
  },
  {
    "text": "one who started the race service can",
    "start": "591180",
    "end": "593160"
  },
  {
    "text": "directly query the race serve",
    "start": "593160",
    "end": "594959"
  },
  {
    "text": "application",
    "start": "594959",
    "end": "596459"
  },
  {
    "text": "which is exposed as a kubernetes service",
    "start": "596459",
    "end": "600620"
  },
  {
    "text": "in summary kubray is the go-to solution",
    "start": "603540",
    "end": "606360"
  },
  {
    "text": "for managing Ray clusters and",
    "start": "606360",
    "end": "608220"
  },
  {
    "text": "applications on kubernetes",
    "start": "608220",
    "end": "610260"
  },
  {
    "text": "it saves time reduces costs and enhances",
    "start": "610260",
    "end": "613920"
  },
  {
    "text": "stability",
    "start": "613920",
    "end": "616080"
  },
  {
    "text": "so far we've talked about what kubray",
    "start": "616080",
    "end": "617820"
  },
  {
    "text": "can do for General rate clusters and",
    "start": "617820",
    "end": "619440"
  },
  {
    "text": "applications",
    "start": "619440",
    "end": "620880"
  },
  {
    "text": "but let's focus on an area that's",
    "start": "620880",
    "end": "622620"
  },
  {
    "text": "increasingly important large language",
    "start": "622620",
    "end": "624660"
  },
  {
    "text": "models or llms",
    "start": "624660",
    "end": "627959"
  },
  {
    "text": "why is this different from traditional",
    "start": "627959",
    "end": "629519"
  },
  {
    "text": "ml workloads",
    "start": "629519",
    "end": "631380"
  },
  {
    "text": "there's a transition from CPU to GPU",
    "start": "631380",
    "end": "633420"
  },
  {
    "text": "inference the computational costs",
    "start": "633420",
    "end": "635459"
  },
  {
    "text": "increase dramatically",
    "start": "635459",
    "end": "637560"
  },
  {
    "text": "there's also a change in the life cycle",
    "start": "637560",
    "end": "639720"
  },
  {
    "text": "instead of starting with data and using",
    "start": "639720",
    "end": "641880"
  },
  {
    "text": "it to train a model for specific tasks",
    "start": "641880",
    "end": "644160"
  },
  {
    "text": "companies and startups can take a",
    "start": "644160",
    "end": "645720"
  },
  {
    "text": "pre-trained foundational model which may",
    "start": "645720",
    "end": "647880"
  },
  {
    "text": "have been too costly to train themselves",
    "start": "647880",
    "end": "649320"
  },
  {
    "text": "from scratch and then they can fine tune",
    "start": "649320",
    "end": "651480"
  },
  {
    "text": "it for their use case",
    "start": "651480",
    "end": "653339"
  },
  {
    "text": "this shift has resulted in an increasing",
    "start": "653339",
    "end": "655500"
  },
  {
    "text": "number of llm application Developers",
    "start": "655500",
    "end": "659160"
  },
  {
    "text": "for llm's distributed computation is a",
    "start": "659160",
    "end": "661920"
  },
  {
    "text": "must-have",
    "start": "661920",
    "end": "662940"
  },
  {
    "text": "we think Cube Ray is uniquely positioned",
    "start": "662940",
    "end": "665040"
  },
  {
    "text": "as an optimal solution for deploying and",
    "start": "665040",
    "end": "667500"
  },
  {
    "text": "managing llms on kubernetes",
    "start": "667500",
    "end": "669839"
  },
  {
    "text": "we'll share insights on how you can",
    "start": "669839",
    "end": "671579"
  },
  {
    "text": "manage all stages of the life cycle of",
    "start": "671579",
    "end": "673380"
  },
  {
    "text": "LM deployments using kubray",
    "start": "673380",
    "end": "675899"
  },
  {
    "text": "and with that said I'll now hand it over",
    "start": "675899",
    "end": "677579"
  },
  {
    "text": "to kaishin to tell you more",
    "start": "677579",
    "end": "680899"
  },
  {
    "text": "thanks Asha I'm Kai Shin today I will",
    "start": "681180",
    "end": "684420"
  },
  {
    "text": "talk about LM with kubray",
    "start": "684420",
    "end": "687839"
  },
  {
    "text": "the first is that we will compare",
    "start": "687839",
    "end": "691200"
  },
  {
    "text": "compare the difference between the",
    "start": "691200",
    "end": "692940"
  },
  {
    "text": "traditional ml model life cycle and the",
    "start": "692940",
    "end": "695820"
  },
  {
    "text": "LM model life cycle",
    "start": "695820",
    "end": "698060"
  },
  {
    "text": "for the traditional ml my life cycle it",
    "start": "698060",
    "end": "701100"
  },
  {
    "text": "consists of several stage including like",
    "start": "701100",
    "end": "703440"
  },
  {
    "text": "data preparation model training tuning",
    "start": "703440",
    "end": "706019"
  },
  {
    "text": "and the model serving",
    "start": "706019",
    "end": "707760"
  },
  {
    "text": "and typically the most expensive part is",
    "start": "707760",
    "end": "710519"
  },
  {
    "text": "the model training because it requires a",
    "start": "710519",
    "end": "713519"
  },
  {
    "text": "lot of GPU",
    "start": "713519",
    "end": "715200"
  },
  {
    "text": "and therefore the serving part maybe it",
    "start": "715200",
    "end": "717600"
  },
  {
    "text": "is not that expensive because the model",
    "start": "717600",
    "end": "720420"
  },
  {
    "text": "is not large so you can use single or a",
    "start": "720420",
    "end": "723600"
  },
  {
    "text": "small GPU for the inference",
    "start": "723600",
    "end": "725700"
  },
  {
    "text": "and as I know if your workload is not",
    "start": "725700",
    "end": "729120"
  },
  {
    "text": "very sensitive to the latency or some",
    "start": "729120",
    "end": "731760"
  },
  {
    "text": "company also use CPU for the inference",
    "start": "731760",
    "end": "733800"
  },
  {
    "text": "to set the cost",
    "start": "733800",
    "end": "735420"
  },
  {
    "text": "uh and our acceleration is that the",
    "start": "735420",
    "end": "738420"
  },
  {
    "text": "performance bottleneck for the model",
    "start": "738420",
    "end": "739980"
  },
  {
    "text": "serving for a traditional ml is about",
    "start": "739980",
    "end": "742500"
  },
  {
    "text": "the computation not memory",
    "start": "742500",
    "end": "746540"
  },
  {
    "text": "and then uh for the LM model life cycle",
    "start": "747240",
    "end": "750360"
  },
  {
    "text": "it is a bit different the main",
    "start": "750360",
    "end": "752519"
  },
  {
    "text": "difference is that still then P sell the",
    "start": "752519",
    "end": "755160"
  },
  {
    "text": "company that's a trend layer Foundation",
    "start": "755160",
    "end": "758279"
  },
  {
    "text": "model from scratch because prescribing a",
    "start": "758279",
    "end": "761160"
  },
  {
    "text": "large language model is pretty expensive",
    "start": "761160",
    "end": "763440"
  },
  {
    "text": "and the inmate Tech uh several million",
    "start": "763440",
    "end": "766740"
  },
  {
    "text": "dollars and the only big Tech can afford",
    "start": "766740",
    "end": "769740"
  },
  {
    "text": "it like The Meta like open AI",
    "start": "769740",
    "end": "773339"
  },
  {
    "text": "yeah so based on our observation most",
    "start": "773339",
    "end": "776639"
  },
  {
    "text": "users use open source pre-trained large",
    "start": "776639",
    "end": "779459"
  },
  {
    "text": "language models like a metas or Lama two",
    "start": "779459",
    "end": "782880"
  },
  {
    "text": "like Falcon like vicuna and then use",
    "start": "782880",
    "end": "785459"
  },
  {
    "text": "their data set for the fight tuning",
    "start": "785459",
    "end": "789079"
  },
  {
    "text": "yeah and the fine tuning is will not uh",
    "start": "789720",
    "end": "793860"
  },
  {
    "text": "will not cost a lot of money but for the",
    "start": "793860",
    "end": "796620"
  },
  {
    "text": "serving it's a totally different story",
    "start": "796620",
    "end": "798959"
  },
  {
    "text": "because the not because the model",
    "start": "798959",
    "end": "801300"
  },
  {
    "text": "becomes very large for example like the",
    "start": "801300",
    "end": "803880"
  },
  {
    "text": "number 270b uh in most of Industry case",
    "start": "803880",
    "end": "807800"
  },
  {
    "text": "uh we will not use the consultation so",
    "start": "807800",
    "end": "811260"
  },
  {
    "text": "we will use f316 for each parameter so",
    "start": "811260",
    "end": "814200"
  },
  {
    "text": "it's required 140 gigabyte of GPU memory",
    "start": "814200",
    "end": "818579"
  },
  {
    "text": "so we need multiple and the largest GPU",
    "start": "818579",
    "end": "821220"
  },
  {
    "text": "for the inference",
    "start": "821220",
    "end": "822959"
  },
  {
    "text": "so uh it becomes very uh memory",
    "start": "822959",
    "end": "826860"
  },
  {
    "text": "intensive so there are a larger of the",
    "start": "826860",
    "end": "829260"
  },
  {
    "text": "memory appendation technique uh like the",
    "start": "829260",
    "end": "832019"
  },
  {
    "text": "continuous batching uh like the patch",
    "start": "832019",
    "end": "834420"
  },
  {
    "text": "attention from the vln like a fashion",
    "start": "834420",
    "end": "836940"
  },
  {
    "text": "attention",
    "start": "836940",
    "end": "837959"
  },
  {
    "text": "yeah and we have any scale published a",
    "start": "837959",
    "end": "840240"
  },
  {
    "text": "lot of blogs a lot about that so if you",
    "start": "840240",
    "end": "842399"
  },
  {
    "text": "are interested you can take a look at it",
    "start": "842399",
    "end": "846360"
  },
  {
    "text": "yeah so uh our problem is that the",
    "start": "846360",
    "end": "849720"
  },
  {
    "text": "serving becomes much more expensive and",
    "start": "849720",
    "end": "852000"
  },
  {
    "text": "important than before",
    "start": "852000",
    "end": "853740"
  },
  {
    "text": "right the ml industry ml apps industry",
    "start": "853740",
    "end": "857160"
  },
  {
    "text": "move from the training to the serving",
    "start": "857160",
    "end": "860959"
  },
  {
    "text": "yeah and uh for the Aon with qbrew can",
    "start": "861300",
    "end": "865860"
  },
  {
    "text": "match the end to end Ln life cycle on",
    "start": "865860",
    "end": "868800"
  },
  {
    "text": "kubernetes",
    "start": "868800",
    "end": "870060"
  },
  {
    "text": "and we think that the cube and array are",
    "start": "870060",
    "end": "872700"
  },
  {
    "text": "the best solution for large language",
    "start": "872700",
    "end": "874680"
  },
  {
    "text": "model and kubernetes especially for",
    "start": "874680",
    "end": "877500"
  },
  {
    "text": "large language model serving cost",
    "start": "877500",
    "end": "880139"
  },
  {
    "text": "the first is that I should introduce",
    "start": "880139",
    "end": "882660"
  },
  {
    "text": "that we have the auto scaling because",
    "start": "882660",
    "end": "885120"
  },
  {
    "text": "the online serving the the workload is",
    "start": "885120",
    "end": "887880"
  },
  {
    "text": "not it's hard to predict so we require",
    "start": "887880",
    "end": "890940"
  },
  {
    "text": "the auto scouting to add our data our",
    "start": "890940",
    "end": "893820"
  },
  {
    "text": "computer resource based on the dynamic",
    "start": "893820",
    "end": "895860"
  },
  {
    "text": "load to step the cost",
    "start": "895860",
    "end": "898079"
  },
  {
    "text": "the second is the heterogeneous",
    "start": "898079",
    "end": "900600"
  },
  {
    "text": "because currently it's not it's not that",
    "start": "900600",
    "end": "903600"
  },
  {
    "text": "you have money so you can get a GPU a",
    "start": "903600",
    "end": "906600"
  },
  {
    "text": "lot of times that you have money but you",
    "start": "906600",
    "end": "908279"
  },
  {
    "text": "cannot get GPU especially for some",
    "start": "908279",
    "end": "910500"
  },
  {
    "text": "high-end GPU like a100 or h100 so",
    "start": "910500",
    "end": "914100"
  },
  {
    "text": "supportive support the heterogeneous",
    "start": "914100",
    "end": "916079"
  },
  {
    "text": "computer resource are very important",
    "start": "916079",
    "end": "917639"
  },
  {
    "text": "like a different types of GPU like a",
    "start": "917639",
    "end": "920639"
  },
  {
    "text": "gpus or CPUs",
    "start": "920639",
    "end": "924139"
  },
  {
    "text": "and then we will demo the end-to-end a",
    "start": "924300",
    "end": "927779"
  },
  {
    "text": "large language model lifecycle with QB",
    "start": "927779",
    "end": "932120"
  },
  {
    "text": "yeah this is our architecture of our",
    "start": "932279",
    "end": "934440"
  },
  {
    "text": "demo the first is that",
    "start": "934440",
    "end": "937620"
  },
  {
    "text": "we will do their processing with the",
    "start": "937620",
    "end": "940139"
  },
  {
    "text": "recursor Jupiter notebook and the auto",
    "start": "940139",
    "end": "942420"
  },
  {
    "text": "scaling",
    "start": "942420",
    "end": "944880"
  },
  {
    "text": "and then after we finish the data",
    "start": "944880",
    "end": "947579"
  },
  {
    "text": "processing we will create a region for",
    "start": "947579",
    "end": "950519"
  },
  {
    "text": "the phytuning because the workload the",
    "start": "950519",
    "end": "953160"
  },
  {
    "text": "resource Computing resource requirement",
    "start": "953160",
    "end": "954660"
  },
  {
    "text": "for the fine tuning is is able to",
    "start": "954660",
    "end": "957060"
  },
  {
    "text": "predict so we decided to use rate drop",
    "start": "957060",
    "end": "959279"
  },
  {
    "text": "to several course",
    "start": "959279",
    "end": "961920"
  },
  {
    "text": "and then after the fire tuning it will",
    "start": "961920",
    "end": "963899"
  },
  {
    "text": "upload the model checkpoint to the",
    "start": "963899",
    "end": "966600"
  },
  {
    "text": "account storage and then step three we",
    "start": "966600",
    "end": "969420"
  },
  {
    "text": "can use the ray service to serve our",
    "start": "969420",
    "end": "971339"
  },
  {
    "text": "fine to large language model",
    "start": "971339",
    "end": "974519"
  },
  {
    "text": "and the first therefore we will build an",
    "start": "974519",
    "end": "977040"
  },
  {
    "text": "LM application with the lension and the",
    "start": "977040",
    "end": "979440"
  },
  {
    "text": "gradual to showcase the application",
    "start": "979440",
    "end": "981660"
  },
  {
    "text": "based on our endpoints served by Race",
    "start": "981660",
    "end": "983760"
  },
  {
    "text": "Service",
    "start": "983760",
    "end": "986120"
  },
  {
    "text": "yeah for the prototyping side uh in this",
    "start": "986220",
    "end": "989279"
  },
  {
    "text": "demo we will not cover this part but uh",
    "start": "989279",
    "end": "992940"
  },
  {
    "text": "but this is a x this is a recommendation",
    "start": "992940",
    "end": "995579"
  },
  {
    "text": "architecture",
    "start": "995579",
    "end": "996959"
  },
  {
    "text": "uh the first is that we typically",
    "start": "996959",
    "end": "998880"
  },
  {
    "text": "recommend user to run a Jupiter notebook",
    "start": "998880",
    "end": "1001279"
  },
  {
    "text": "as a head pass cycle container",
    "start": "1001279",
    "end": "1003980"
  },
  {
    "text": "and land uh user we also in uh recommend",
    "start": "1003980",
    "end": "1009079"
  },
  {
    "text": "user to enable the auto scaler and the",
    "start": "1009079",
    "end": "1011480"
  },
  {
    "text": "auto scaler will inject a cycle",
    "start": "1011480",
    "end": "1013639"
  },
  {
    "text": "container into the headspot",
    "start": "1013639",
    "end": "1017240"
  },
  {
    "text": "and for the and the second",
    "start": "1017240",
    "end": "1020380"
  },
  {
    "text": "for a second we will fine-tuning with",
    "start": "1020380",
    "end": "1023120"
  },
  {
    "text": "the ray job and in this demo we find you",
    "start": "1023120",
    "end": "1025938"
  },
  {
    "text": "a llama27b on the math data set",
    "start": "1025939",
    "end": "1030500"
  },
  {
    "text": "and in the demo we use a raychen and a",
    "start": "1030500",
    "end": "1033140"
  },
  {
    "text": "disk bit",
    "start": "1033140",
    "end": "1034220"
  },
  {
    "text": "and then we have the 16 Nvidia A10 gpus",
    "start": "1034220",
    "end": "1037640"
  },
  {
    "text": "and a 24 gigabyte RAM for per GPU",
    "start": "1037640",
    "end": "1041178"
  },
  {
    "text": "and we only find you for one Epoch and",
    "start": "1041179",
    "end": "1043938"
  },
  {
    "text": "it takes 22 minutes",
    "start": "1043939",
    "end": "1047199"
  },
  {
    "text": "yeah analysis our demo video the first",
    "start": "1052040",
    "end": "1055039"
  },
  {
    "text": "is that we install a qbre operator",
    "start": "1055039",
    "end": "1059200"
  },
  {
    "text": "yeah and the ones for it should be ready",
    "start": "1061880",
    "end": "1065919"
  },
  {
    "text": "right and then creates a great job for",
    "start": "1066440",
    "end": "1068480"
  },
  {
    "text": "fine tuning",
    "start": "1068480",
    "end": "1071140"
  },
  {
    "text": "yeah and check the custom resource",
    "start": "1074120",
    "end": "1078100"
  },
  {
    "text": "yeah and we watch it apart and it one",
    "start": "1078679",
    "end": "1081380"
  },
  {
    "text": "has node and the 16 GPU working nodes",
    "start": "1081380",
    "end": "1085780"
  },
  {
    "text": "and then we watch the monitor the",
    "start": "1085880",
    "end": "1088100"
  },
  {
    "text": "fine-tuning job progress",
    "start": "1088100",
    "end": "1091660"
  },
  {
    "text": "and then after 20 minutes",
    "start": "1092480",
    "end": "1095299"
  },
  {
    "text": "right it's the state and you can see the",
    "start": "1095299",
    "end": "1097880"
  },
  {
    "text": "checkpoint here",
    "start": "1097880",
    "end": "1100600"
  },
  {
    "text": "yeah and then because this is for demo",
    "start": "1102080",
    "end": "1104480"
  },
  {
    "text": "purpose we didn't configure the auto",
    "start": "1104480",
    "end": "1106340"
  },
  {
    "text": "detecting Direction so after this is by",
    "start": "1106340",
    "end": "1110480"
  },
  {
    "text": "ourselves",
    "start": "1110480",
    "end": "1112100"
  },
  {
    "text": "and then after we finish the phytonin we",
    "start": "1112100",
    "end": "1115400"
  },
  {
    "text": "can serve the we can serve the fighting",
    "start": "1115400",
    "end": "1117980"
  },
  {
    "text": "model with Race Service and the ray Ln",
    "start": "1117980",
    "end": "1120799"
  },
  {
    "text": "and the real m is a previously named",
    "start": "1120799",
    "end": "1124760"
  },
  {
    "text": "every it is a tool that can help you to",
    "start": "1124760",
    "end": "1128059"
  },
  {
    "text": "serve your large language model in Array",
    "start": "1128059",
    "end": "1131059"
  },
  {
    "text": "and it provides open AI compatible API",
    "start": "1131059",
    "end": "1134539"
  },
  {
    "text": "so it's pretty easy to use the open air",
    "start": "1134539",
    "end": "1137179"
  },
  {
    "text": "python package to use the to use the",
    "start": "1137179",
    "end": "1140299"
  },
  {
    "text": "endpoint Leicester by Ray service",
    "start": "1140299",
    "end": "1143799"
  },
  {
    "text": "and this is the demo",
    "start": "1143900",
    "end": "1147340"
  },
  {
    "text": "what should you do last time oh here we",
    "start": "1155120",
    "end": "1157160"
  },
  {
    "text": "go",
    "start": "1157160",
    "end": "1159220"
  },
  {
    "text": "yeah we have already have a operator",
    "start": "1161360",
    "end": "1163820"
  },
  {
    "text": "that in our cluster so we create a red",
    "start": "1163820",
    "end": "1166640"
  },
  {
    "text": "service",
    "start": "1166640",
    "end": "1168880"
  },
  {
    "text": "yeah and then we watch our part and in",
    "start": "1180440",
    "end": "1183080"
  },
  {
    "text": "the raycaster it will have one head no",
    "start": "1183080",
    "end": "1185240"
  },
  {
    "text": "and the one GPU work node and we will",
    "start": "1185240",
    "end": "1188179"
  },
  {
    "text": "serve law serve a large language model",
    "start": "1188179",
    "end": "1190820"
  },
  {
    "text": "on the GPU node and then it has a it is",
    "start": "1190820",
    "end": "1194720"
  },
  {
    "text": "ready so we just try to pull forwarding",
    "start": "1194720",
    "end": "1197840"
  },
  {
    "text": "and then",
    "start": "1197840",
    "end": "1199400"
  },
  {
    "text": "and then use the curl request to test it",
    "start": "1199400",
    "end": "1203980"
  },
  {
    "text": "yeah and we got a response",
    "start": "1210620",
    "end": "1214360"
  },
  {
    "text": "cool",
    "start": "1216080",
    "end": "1218500"
  },
  {
    "text": "and then uh the last step is that we",
    "start": "1222260",
    "end": "1225980"
  },
  {
    "text": "have a endpoint let's start by our array",
    "start": "1225980",
    "end": "1228559"
  },
  {
    "text": "service with our fine tune llama27b",
    "start": "1228559",
    "end": "1231500"
  },
  {
    "text": "model so the last step is that I want to",
    "start": "1231500",
    "end": "1234559"
  },
  {
    "text": "build an LM application with Lane Chen",
    "start": "1234559",
    "end": "1237440"
  },
  {
    "text": "and the gradual and here we use",
    "start": "1237440",
    "end": "1239780"
  },
  {
    "text": "graduation for to build a web UI and use",
    "start": "1239780",
    "end": "1244640"
  },
  {
    "text": "the engine to handle the i o between the",
    "start": "1244640",
    "end": "1247100"
  },
  {
    "text": "race service endpoints and our users",
    "start": "1247100",
    "end": "1249740"
  },
  {
    "text": "inputs and output",
    "start": "1249740",
    "end": "1252200"
  },
  {
    "text": "right and because this one is a RFI 2",
    "start": "1252200",
    "end": "1255440"
  },
  {
    "text": "model is fine too with the math data set",
    "start": "1255440",
    "end": "1257299"
  },
  {
    "text": "so we we will use a math question for",
    "start": "1257299",
    "end": "1260000"
  },
  {
    "text": "the demo and the lantern has a it will",
    "start": "1260000",
    "end": "1263179"
  },
  {
    "text": "use a prompt canvas that's as we've",
    "start": "1263179",
    "end": "1265940"
  },
  {
    "text": "shown in the slide right this is how we",
    "start": "1265940",
    "end": "1268460"
  },
  {
    "text": "find to our model so that's why we use",
    "start": "1268460",
    "end": "1270740"
  },
  {
    "text": "this prompt template",
    "start": "1270740",
    "end": "1273880"
  },
  {
    "text": "yeah and this is a math problem that we",
    "start": "1273919",
    "end": "1276559"
  },
  {
    "text": "will use it is the same from our math",
    "start": "1276559",
    "end": "1280100"
  },
  {
    "text": "data set and the answer is five it's a",
    "start": "1280100",
    "end": "1283039"
  },
  {
    "text": "pretty simple math question",
    "start": "1283039",
    "end": "1286240"
  },
  {
    "text": "yeah and the list is the",
    "start": "1290840",
    "end": "1293480"
  },
  {
    "text": "very short video",
    "start": "1293480",
    "end": "1296799"
  },
  {
    "text": "yeah because I have already put",
    "start": "1300740",
    "end": "1303260"
  },
  {
    "text": "forwarding that to my Dev box so I just",
    "start": "1303260",
    "end": "1305900"
  },
  {
    "text": "run the gradual server that's on my",
    "start": "1305900",
    "end": "1308059"
  },
  {
    "text": "local box and then you can see this UI",
    "start": "1308059",
    "end": "1310820"
  },
  {
    "text": "and we use the question that's in the",
    "start": "1310820",
    "end": "1312980"
  },
  {
    "text": "last slide and the summit should our",
    "start": "1312980",
    "end": "1315500"
  },
  {
    "text": "endpoints",
    "start": "1315500",
    "end": "1317299"
  },
  {
    "text": "yeah and the result from our model is",
    "start": "1317299",
    "end": "1320780"
  },
  {
    "text": "not correct because we just find you for",
    "start": "1320780",
    "end": "1323059"
  },
  {
    "text": "one Epoch but the response is that it",
    "start": "1323059",
    "end": "1326059"
  },
  {
    "text": "has already followed our data says",
    "start": "1326059",
    "end": "1327919"
  },
  {
    "text": "format so it is better than the best",
    "start": "1327919",
    "end": "1330260"
  },
  {
    "text": "model",
    "start": "1330260",
    "end": "1332500"
  },
  {
    "text": "no",
    "start": "1337580",
    "end": "1340000"
  },
  {
    "text": "yeah and uh and uh actually introduced",
    "start": "1341179",
    "end": "1344120"
  },
  {
    "text": "the current status of the qbre and I",
    "start": "1344120",
    "end": "1347000"
  },
  {
    "text": "introd I talked about the LM with qbre",
    "start": "1347000",
    "end": "1349880"
  },
  {
    "text": "So currently I want to recapital 2003",
    "start": "1349880",
    "end": "1352940"
  },
  {
    "text": "for qbre community",
    "start": "1352940",
    "end": "1355960"
  },
  {
    "text": "uh from the last restaurant until today",
    "start": "1356240",
    "end": "1359480"
  },
  {
    "text": "we have four major release from 230",
    "start": "1359480",
    "end": "1362780"
  },
  {
    "text": "companies to six more than 600 comments",
    "start": "1362780",
    "end": "1367840"
  },
  {
    "text": "and we have a more than 90 contributors",
    "start": "1368059",
    "end": "1371000"
  },
  {
    "text": "uh like Dimitri from curse and uh",
    "start": "1371000",
    "end": "1374360"
  },
  {
    "text": "joshing Wilson and Chinese from bidance",
    "start": "1374360",
    "end": "1377059"
  },
  {
    "text": "and RD from Microsoft and like each time",
    "start": "1377059",
    "end": "1380539"
  },
  {
    "text": "from the",
    "start": "1380539",
    "end": "1382299"
  },
  {
    "text": "and several folks from the red hat and",
    "start": "1382299",
    "end": "1385039"
  },
  {
    "text": "IBN right we have a very very good",
    "start": "1385039",
    "end": "1388159"
  },
  {
    "text": "community and thanks for the",
    "start": "1388159",
    "end": "1389539"
  },
  {
    "text": "contribution",
    "start": "1389539",
    "end": "1391880"
  },
  {
    "text": "and then we have a lot of users blocked",
    "start": "1391880",
    "end": "1395120"
  },
  {
    "text": "like the like the insta cards uh sansara",
    "start": "1395120",
    "end": "1398539"
  },
  {
    "text": "Spotify and the draw Dash and the Google",
    "start": "1398539",
    "end": "1403720"
  },
  {
    "text": "and uh we have a massive growth in the",
    "start": "1403760",
    "end": "1406580"
  },
  {
    "text": "number of qbre clusters we have a 9x",
    "start": "1406580",
    "end": "1409580"
  },
  {
    "text": "growth in the last six months and the",
    "start": "1409580",
    "end": "1412280"
  },
  {
    "text": "two acts in the August",
    "start": "1412280",
    "end": "1414559"
  },
  {
    "text": "and uh in our expectation we think that",
    "start": "1414559",
    "end": "1417740"
  },
  {
    "text": "this uh this month will have another 2x",
    "start": "1417740",
    "end": "1420740"
  },
  {
    "text": "in September",
    "start": "1420740",
    "end": "1424059"
  },
  {
    "text": "and this is our user's feedback uh from",
    "start": "1424940",
    "end": "1428659"
  },
  {
    "text": "the Antics right because I am not sure a",
    "start": "1428659",
    "end": "1430760"
  },
  {
    "text": "lot is this a legal for me to use their",
    "start": "1430760",
    "end": "1432860"
  },
  {
    "text": "logo so I decided to use the Psyduck",
    "start": "1432860",
    "end": "1435679"
  },
  {
    "text": "which is my favorite Pokemon",
    "start": "1435679",
    "end": "1439340"
  },
  {
    "text": "yeah and uh niantics with kubrey and",
    "start": "1439340",
    "end": "1443059"
  },
  {
    "text": "they used to for Less game processing",
    "start": "1443059",
    "end": "1444980"
  },
  {
    "text": "and it's definitely caused by 60 percent",
    "start": "1444980",
    "end": "1449419"
  },
  {
    "text": "right which is very fantastic",
    "start": "1449419",
    "end": "1452539"
  },
  {
    "text": "right so we are very happy to announce",
    "start": "1452539",
    "end": "1454640"
  },
  {
    "text": "that uh Cube rates generally available",
    "start": "1454640",
    "end": "1457039"
  },
  {
    "text": "right I think you guys know that in the",
    "start": "1457039",
    "end": "1459559"
  },
  {
    "text": "ion's Keynote",
    "start": "1459559",
    "end": "1461240"
  },
  {
    "text": "right and then uh the currency the cube",
    "start": "1461240",
    "end": "1464720"
  },
  {
    "text": "rate 1.0 the first race candy is",
    "start": "1464720",
    "end": "1467419"
  },
  {
    "text": "available so feel free to try it on this",
    "start": "1467419",
    "end": "1470600"
  },
  {
    "text": "really extended will be very different",
    "start": "1470600",
    "end": "1471980"
  },
  {
    "text": "from the previous one for the previous",
    "start": "1471980",
    "end": "1473900"
  },
  {
    "text": "one we will just iterate with user for",
    "start": "1473900",
    "end": "1476419"
  },
  {
    "text": "this case for one to two weeks but this",
    "start": "1476419",
    "end": "1478700"
  },
  {
    "text": "one we will iterate maybe for six weeks",
    "start": "1478700",
    "end": "1480860"
  },
  {
    "text": "so it is a good time if you have any bug",
    "start": "1480860",
    "end": "1483919"
  },
  {
    "text": "right it will be fixed very fast so it's",
    "start": "1483919",
    "end": "1487460"
  },
  {
    "text": "a good time to open some issue",
    "start": "1487460",
    "end": "1490340"
  },
  {
    "text": "yeah and thanks for you guys to",
    "start": "1490340",
    "end": "1492559"
  },
  {
    "text": "attending our talk thanks",
    "start": "1492559",
    "end": "1496120"
  }
]
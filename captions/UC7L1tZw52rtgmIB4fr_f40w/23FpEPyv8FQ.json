[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": "[Music]",
    "start": "170",
    "end": "14480"
  },
  {
    "text": "hi everyone and thank you for attending",
    "start": "14480",
    "end": "16560"
  },
  {
    "text": "this presentation my name is amel",
    "start": "16560",
    "end": "18400"
  },
  {
    "text": "kemsetti and i'm a software engineer at",
    "start": "18400",
    "end": "20240"
  },
  {
    "text": "any scale",
    "start": "20240",
    "end": "21039"
  },
  {
    "text": "working on ray and its usage in the",
    "start": "21039",
    "end": "22640"
  },
  {
    "text": "broader ml ecosystem",
    "start": "22640",
    "end": "24160"
  },
  {
    "text": "in this talk i'll be going over some of",
    "start": "24160",
    "end": "25840"
  },
  {
    "text": "the work that our team has done",
    "start": "25840",
    "end": "27039"
  },
  {
    "text": "integrating array as a distributed",
    "start": "27039",
    "end": "29039"
  },
  {
    "text": "compute backend for open source ml",
    "start": "29039",
    "end": "30880"
  },
  {
    "text": "libraries as well as discussing our",
    "start": "30880",
    "end": "32960"
  },
  {
    "text": "experiences and using array for",
    "start": "32960",
    "end": "34640"
  },
  {
    "text": "distributed machine learning",
    "start": "34640",
    "end": "37840"
  },
  {
    "text": "so quick overview of today's talk i'll",
    "start": "37840",
    "end": "40320"
  },
  {
    "text": "first start with some intro on why we",
    "start": "40320",
    "end": "42160"
  },
  {
    "text": "need distributed machine learning in the",
    "start": "42160",
    "end": "43600"
  },
  {
    "text": "first place",
    "start": "43600",
    "end": "44399"
  },
  {
    "text": "and how recent trends in the past few",
    "start": "44399",
    "end": "46160"
  },
  {
    "text": "years have shaped how machine learning",
    "start": "46160",
    "end": "47760"
  },
  {
    "text": "is done",
    "start": "47760",
    "end": "49039"
  },
  {
    "text": "then i'll talk about some of the",
    "start": "49039",
    "end": "50160"
  },
  {
    "text": "challenges that are that",
    "start": "50160",
    "end": "52320"
  },
  {
    "text": "commonly face when we want to actually",
    "start": "52320",
    "end": "54399"
  },
  {
    "text": "implement distributed machine learning",
    "start": "54399",
    "end": "56000"
  },
  {
    "text": "and particularly",
    "start": "56000",
    "end": "56879"
  },
  {
    "text": "challenges from the system's perspective",
    "start": "56879",
    "end": "59280"
  },
  {
    "text": "then i'll go over a walkthrough of how",
    "start": "59280",
    "end": "61280"
  },
  {
    "text": "of how ray works and how ray's features",
    "start": "61280",
    "end": "63120"
  },
  {
    "text": "can actually solve these challenges that",
    "start": "63120",
    "end": "64559"
  },
  {
    "text": "i'll be talking about",
    "start": "64559",
    "end": "65680"
  },
  {
    "text": "and enable us to build distributed ml",
    "start": "65680",
    "end": "68080"
  },
  {
    "text": "libraries on top of ray",
    "start": "68080",
    "end": "69600"
  },
  {
    "text": "and finally i'll show three integrations",
    "start": "69600",
    "end": "71520"
  },
  {
    "text": "that we've done of ml libraries using",
    "start": "71520",
    "end": "73520"
  },
  {
    "text": "ray for distributed",
    "start": "73520",
    "end": "74799"
  },
  {
    "text": "computing horovod high torch lightning",
    "start": "74799",
    "end": "77119"
  },
  {
    "text": "and hugging phase transformers",
    "start": "77119",
    "end": "80479"
  },
  {
    "text": "okay great so why do we need distributed",
    "start": "81600",
    "end": "83680"
  },
  {
    "text": "machine learning in the first place",
    "start": "83680",
    "end": "86640"
  },
  {
    "text": "the need for parallel machine learning",
    "start": "86640",
    "end": "88159"
  },
  {
    "text": "is necessitated by two main trends",
    "start": "88159",
    "end": "90479"
  },
  {
    "start": "90000",
    "end": "90000"
  },
  {
    "text": "the first one is that throughout the",
    "start": "90479",
    "end": "91759"
  },
  {
    "text": "years achieving state of the art ml",
    "start": "91759",
    "end": "93360"
  },
  {
    "text": "result",
    "start": "93360",
    "end": "93920"
  },
  {
    "text": "results is requiring significantly more",
    "start": "93920",
    "end": "95920"
  },
  {
    "text": "compute demand and memory",
    "start": "95920",
    "end": "99119"
  },
  {
    "text": "over the past eight years the",
    "start": "99119",
    "end": "100400"
  },
  {
    "text": "computation required to train the state",
    "start": "100400",
    "end": "102320"
  },
  {
    "text": "of state-of-the-art ml models has",
    "start": "102320",
    "end": "104000"
  },
  {
    "text": "astonished",
    "start": "104000",
    "end": "105040"
  },
  {
    "text": "as astonishingly increased 35 times",
    "start": "105040",
    "end": "107040"
  },
  {
    "text": "every 18 months",
    "start": "107040",
    "end": "108399"
  },
  {
    "text": "and this is a 300k times increase in",
    "start": "108399",
    "end": "111360"
  },
  {
    "text": "compute from alexnet to alphago zero",
    "start": "111360",
    "end": "115119"
  },
  {
    "text": "and not only have mo has model training",
    "start": "115119",
    "end": "117040"
  },
  {
    "text": "compute demands and size increased but",
    "start": "117040",
    "end": "119040"
  },
  {
    "text": "the number of hyper parameters is",
    "start": "119040",
    "end": "120399"
  },
  {
    "text": "increased as well",
    "start": "120399",
    "end": "121520"
  },
  {
    "text": "here's an example of the roberta",
    "start": "121520",
    "end": "123040"
  },
  {
    "text": "transformer model with over 15 different",
    "start": "123040",
    "end": "125040"
  },
  {
    "text": "hyper parameters that need to be tuned",
    "start": "125040",
    "end": "127119"
  },
  {
    "text": "you have to train a model for each hyper",
    "start": "127119",
    "end": "128800"
  },
  {
    "text": "perimeter configuration that we want to",
    "start": "128800",
    "end": "130239"
  },
  {
    "text": "test out",
    "start": "130239",
    "end": "130959"
  },
  {
    "text": "thus further increasing the compute",
    "start": "130959",
    "end": "132480"
  },
  {
    "text": "demand required for deep learning",
    "start": "132480",
    "end": "133920"
  },
  {
    "text": "training and hyperparameter tuning",
    "start": "133920",
    "end": "137440"
  },
  {
    "text": "the second trend that we are seeing is",
    "start": "137440",
    "end": "138879"
  },
  {
    "text": "the end of moore's law processor",
    "start": "138879",
    "end": "140800"
  },
  {
    "text": "performance is not able to keep up with",
    "start": "140800",
    "end": "142400"
  },
  {
    "text": "the compute demands modern deep learning",
    "start": "142400",
    "end": "144239"
  },
  {
    "text": "models so you have no choice but to",
    "start": "144239",
    "end": "146239"
  },
  {
    "text": "scale out",
    "start": "146239",
    "end": "148560"
  },
  {
    "text": "many of you have seen something similar",
    "start": "148560",
    "end": "150080"
  },
  {
    "text": "to this before but here's another famous",
    "start": "150080",
    "end": "152080"
  },
  {
    "text": "plot",
    "start": "152080",
    "end": "152720"
  },
  {
    "text": "which uh plots the performance of a",
    "start": "152720",
    "end": "154319"
  },
  {
    "text": "single processor core",
    "start": "154319",
    "end": "156480"
  },
  {
    "text": "and shows that it used to double 18",
    "start": "156480",
    "end": "158160"
  },
  {
    "text": "months but now it just increases by just",
    "start": "158160",
    "end": "160160"
  },
  {
    "text": "a few percent",
    "start": "160160",
    "end": "161040"
  },
  {
    "text": "over the same time period",
    "start": "161040",
    "end": "164239"
  },
  {
    "text": "and plotting these in the same plot you",
    "start": "164560",
    "end": "166000"
  },
  {
    "text": "can see the performance gap of a single",
    "start": "166000",
    "end": "167840"
  },
  {
    "text": "core",
    "start": "167840",
    "end": "168400"
  },
  {
    "text": "and new deep learning models is enormous",
    "start": "168400",
    "end": "171440"
  },
  {
    "text": "in fact even if moore's law hadn't ended",
    "start": "171440",
    "end": "173599"
  },
  {
    "text": "it would still fall way short of",
    "start": "173599",
    "end": "175040"
  },
  {
    "text": "satisfying the demands of training these",
    "start": "175040",
    "end": "176879"
  },
  {
    "text": "new state-of-the-art models",
    "start": "176879",
    "end": "179920"
  },
  {
    "text": "and you might say that with specialized",
    "start": "179920",
    "end": "181440"
  },
  {
    "start": "180000",
    "end": "180000"
  },
  {
    "text": "hardware like gpus and tpus this",
    "start": "181440",
    "end": "183760"
  },
  {
    "text": "wouldn't be a problem",
    "start": "183760",
    "end": "184959"
  },
  {
    "text": "but even specialized hardware is not",
    "start": "184959",
    "end": "186560"
  },
  {
    "text": "able to keep up with the compute demand",
    "start": "186560",
    "end": "188640"
  },
  {
    "text": "here we are overlaying the performance",
    "start": "188640",
    "end": "190159"
  },
  {
    "text": "of nvidia gpus and google tpus over the",
    "start": "190159",
    "end": "192319"
  },
  {
    "text": "same openai plot that we saw earlier",
    "start": "192319",
    "end": "194560"
  },
  {
    "text": "and as you can see while they do provide",
    "start": "194560",
    "end": "196080"
  },
  {
    "text": "orders of magnitude improvements over a",
    "start": "196080",
    "end": "197760"
  },
  {
    "text": "single processor",
    "start": "197760",
    "end": "198879"
  },
  {
    "text": "the performance doesn't grow faster than",
    "start": "198879",
    "end": "201280"
  },
  {
    "text": "moore's law so they still fall way short",
    "start": "201280",
    "end": "203200"
  },
  {
    "text": "of the demands of ml models",
    "start": "203200",
    "end": "206080"
  },
  {
    "text": "so with these two trends we have no",
    "start": "206080",
    "end": "208080"
  },
  {
    "text": "choice but to go distributed",
    "start": "208080",
    "end": "211519"
  },
  {
    "text": "so now that we know that ml has to go",
    "start": "211599",
    "end": "213200"
  },
  {
    "text": "distributed in order to leverage",
    "start": "213200",
    "end": "214480"
  },
  {
    "text": "state-of-the-art models and meet their",
    "start": "214480",
    "end": "216000"
  },
  {
    "text": "compute demands",
    "start": "216000",
    "end": "217599"
  },
  {
    "text": "uh now we can discuss about some other",
    "start": "217599",
    "end": "219519"
  },
  {
    "text": "challenges that are faced when we",
    "start": "219519",
    "end": "220560"
  },
  {
    "text": "actually want to implement",
    "start": "220560",
    "end": "221519"
  },
  {
    "text": "scalable and distributed machine",
    "start": "221519",
    "end": "222879"
  },
  {
    "text": "learning in practice many of you",
    "start": "222879",
    "end": "225120"
  },
  {
    "text": "are are already familiar with how",
    "start": "225120",
    "end": "227200"
  },
  {
    "text": "distributed training algorithms work",
    "start": "227200",
    "end": "229040"
  },
  {
    "text": "like implementations for data parallel",
    "start": "229040",
    "end": "230959"
  },
  {
    "text": "or model parallel training",
    "start": "230959",
    "end": "232560"
  },
  {
    "text": "but in practice to actually facilitate",
    "start": "232560",
    "end": "234239"
  },
  {
    "text": "the scaling of machine learning",
    "start": "234239",
    "end": "236319"
  },
  {
    "text": "there are some other crucial challenges",
    "start": "236319",
    "end": "237760"
  },
  {
    "text": "and particularly those from a systems",
    "start": "237760",
    "end": "239439"
  },
  {
    "text": "perspective",
    "start": "239439",
    "end": "240720"
  },
  {
    "text": "we'll go into what these challenges are",
    "start": "240720",
    "end": "242640"
  },
  {
    "text": "then talk about how array can actually",
    "start": "242640",
    "end": "244400"
  },
  {
    "text": "provide benefits and solves these",
    "start": "244400",
    "end": "246000"
  },
  {
    "text": "challenges",
    "start": "246000",
    "end": "246799"
  },
  {
    "text": "which are a big part of the problem and",
    "start": "246799",
    "end": "249040"
  },
  {
    "text": "finally we can go over how we've",
    "start": "249040",
    "end": "251040"
  },
  {
    "text": "done this work and through integrating",
    "start": "251040",
    "end": "253760"
  },
  {
    "text": "array",
    "start": "253760",
    "end": "254159"
  },
  {
    "text": "with other libraries the ammo ecosystem",
    "start": "254159",
    "end": "255840"
  },
  {
    "text": "and how the ecosystem at large is",
    "start": "255840",
    "end": "257919"
  },
  {
    "text": "adopting ray",
    "start": "257919",
    "end": "259680"
  },
  {
    "text": "okay so what are the challenges with",
    "start": "259680",
    "end": "261280"
  },
  {
    "text": "distributed machine learning",
    "start": "261280",
    "end": "264160"
  },
  {
    "text": "well the first one is that cutting edge",
    "start": "264160",
    "end": "266720"
  },
  {
    "text": "uh new cutting-edge approaches require",
    "start": "266720",
    "end": "268639"
  },
  {
    "start": "267000",
    "end": "267000"
  },
  {
    "text": "ad-hoc distributed computation",
    "start": "268639",
    "end": "271520"
  },
  {
    "text": "so this is especially true for",
    "start": "271520",
    "end": "273120"
  },
  {
    "text": "reinforcement learning but more recently",
    "start": "273120",
    "end": "274960"
  },
  {
    "text": "this has also been the case for nlp as",
    "start": "274960",
    "end": "276560"
  },
  {
    "text": "well",
    "start": "276560",
    "end": "277199"
  },
  {
    "text": "what this means is that in order to",
    "start": "277199",
    "end": "279440"
  },
  {
    "text": "leverage these new machine learning",
    "start": "279440",
    "end": "281120"
  },
  {
    "text": "models it's not only the training that",
    "start": "281120",
    "end": "282880"
  },
  {
    "text": "has to be distributed",
    "start": "282880",
    "end": "284080"
  },
  {
    "text": "but there's other aspects of the process",
    "start": "284080",
    "end": "286400"
  },
  {
    "text": "that has to be distributed as well",
    "start": "286400",
    "end": "288000"
  },
  {
    "text": "so for example take this new retrieval",
    "start": "288000",
    "end": "290160"
  },
  {
    "text": "augmented generation model",
    "start": "290160",
    "end": "291759"
  },
  {
    "text": "it's a new type of nlp architecture",
    "start": "291759",
    "end": "293919"
  },
  {
    "text": "created by facebook ai",
    "start": "293919",
    "end": "295360"
  },
  {
    "text": "which allows you to do things like",
    "start": "295360",
    "end": "298720"
  },
  {
    "text": "jeopardy question generation or just",
    "start": "298720",
    "end": "300800"
  },
  {
    "text": "trivia question answering or fact",
    "start": "300800",
    "end": "302320"
  },
  {
    "text": "verification",
    "start": "302320",
    "end": "303600"
  },
  {
    "text": "but the way it works is that during the",
    "start": "303600",
    "end": "306080"
  },
  {
    "text": "uh",
    "start": "306080",
    "end": "306800"
  },
  {
    "text": "during the the model itself actually",
    "start": "306800",
    "end": "308960"
  },
  {
    "text": "pulls contextual",
    "start": "308960",
    "end": "310000"
  },
  {
    "text": "documents from some sort of external",
    "start": "310000",
    "end": "311600"
  },
  {
    "text": "corpus so for example",
    "start": "311600",
    "end": "313199"
  },
  {
    "text": "pull any relevant passages from",
    "start": "313199",
    "end": "315440"
  },
  {
    "text": "wikipedia",
    "start": "315440",
    "end": "316479"
  },
  {
    "text": "and these documents are encoded and used",
    "start": "316479",
    "end": "318479"
  },
  {
    "text": "in conjunction with",
    "start": "318479",
    "end": "319680"
  },
  {
    "text": "the the model to then produce the final",
    "start": "319680",
    "end": "322639"
  },
  {
    "text": "result",
    "start": "322639",
    "end": "323759"
  },
  {
    "text": "this retrieval from this external data",
    "start": "323759",
    "end": "325919"
  },
  {
    "text": "set like",
    "start": "325919",
    "end": "326880"
  },
  {
    "text": "wikipedia this is not actually trained",
    "start": "326880",
    "end": "329039"
  },
  {
    "text": "as part of the model",
    "start": "329039",
    "end": "330400"
  },
  {
    "text": "back propagation this is an auxiliaries",
    "start": "330400",
    "end": "333520"
  },
  {
    "text": "auxiliary step that is used in order to",
    "start": "333520",
    "end": "335919"
  },
  {
    "text": "help with the performance of the model",
    "start": "335919",
    "end": "337840"
  },
  {
    "text": "which means that when you want to scale",
    "start": "337840",
    "end": "339440"
  },
  {
    "text": "model training for this retrieval",
    "start": "339440",
    "end": "341199"
  },
  {
    "text": "augmented generation setup",
    "start": "341199",
    "end": "342960"
  },
  {
    "text": "we not only have to train uh scale out",
    "start": "342960",
    "end": "345039"
  },
  {
    "text": "the model training itself but we have to",
    "start": "345039",
    "end": "346720"
  },
  {
    "text": "scale out this document retrieval also",
    "start": "346720",
    "end": "349360"
  },
  {
    "text": "in order to do that we need a way to",
    "start": "349360",
    "end": "351520"
  },
  {
    "text": "have ad hoc distribute a computation",
    "start": "351520",
    "end": "353600"
  },
  {
    "text": "with the easy to use api and also",
    "start": "353600",
    "end": "355600"
  },
  {
    "text": "flexible programming interface",
    "start": "355600",
    "end": "359039"
  },
  {
    "text": "the second challenge that we have with",
    "start": "359039",
    "end": "360560"
  },
  {
    "start": "360000",
    "end": "360000"
  },
  {
    "text": "distributed machine learning is elastic",
    "start": "360560",
    "end": "362400"
  },
  {
    "text": "training",
    "start": "362400",
    "end": "362960"
  },
  {
    "text": "which means being able to support",
    "start": "362960",
    "end": "365199"
  },
  {
    "text": "training even when the number of workers",
    "start": "365199",
    "end": "367280"
  },
  {
    "text": "are changing throughout the training",
    "start": "367280",
    "end": "368639"
  },
  {
    "text": "process",
    "start": "368639",
    "end": "370080"
  },
  {
    "text": "this is important because it allows us",
    "start": "370080",
    "end": "371600"
  },
  {
    "text": "to leverage spot instances",
    "start": "371600",
    "end": "373680"
  },
  {
    "text": "uh so we can which are which are much",
    "start": "373680",
    "end": "376240"
  },
  {
    "text": "cheaper",
    "start": "376240",
    "end": "376720"
  },
  {
    "text": "right so even if one of our nodes dies",
    "start": "376720",
    "end": "378960"
  },
  {
    "text": "we lose some workers",
    "start": "378960",
    "end": "380000"
  },
  {
    "text": "we should still be able to continue",
    "start": "380000",
    "end": "381440"
  },
  {
    "text": "training without having to restart the",
    "start": "381440",
    "end": "383600"
  },
  {
    "text": "full process",
    "start": "383600",
    "end": "384960"
  },
  {
    "text": "uh and by using spontaneous spot",
    "start": "384960",
    "end": "387039"
  },
  {
    "text": "instances we can cut down a lot of our",
    "start": "387039",
    "end": "389120"
  },
  {
    "text": "gpu costs",
    "start": "389120",
    "end": "390400"
  },
  {
    "text": "also this allows us to leverage auto",
    "start": "390400",
    "end": "392000"
  },
  {
    "text": "scaling so if you want to actually add",
    "start": "392000",
    "end": "393600"
  },
  {
    "text": "more workers to our tr to our training",
    "start": "393600",
    "end": "395360"
  },
  {
    "text": "status setup",
    "start": "395360",
    "end": "396400"
  },
  {
    "text": "if more resources become available we",
    "start": "396400",
    "end": "399120"
  },
  {
    "text": "want to be able to easily do that as",
    "start": "399120",
    "end": "400479"
  },
  {
    "text": "well",
    "start": "400479",
    "end": "401600"
  },
  {
    "text": "so through elastic training we can",
    "start": "401600",
    "end": "403199"
  },
  {
    "text": "handle work or failures any point during",
    "start": "403199",
    "end": "405199"
  },
  {
    "text": "the training process but also speed up",
    "start": "405199",
    "end": "406960"
  },
  {
    "text": "our training if resources become",
    "start": "406960",
    "end": "408400"
  },
  {
    "text": "available",
    "start": "408400",
    "end": "409280"
  },
  {
    "text": "but implementing this can actually be",
    "start": "409280",
    "end": "411120"
  },
  {
    "text": "difficult to to",
    "start": "411120",
    "end": "413039"
  },
  {
    "text": "to do and finally the last challenge is",
    "start": "413039",
    "end": "416479"
  },
  {
    "text": "implementing custom placement strategies",
    "start": "416479",
    "end": "418160"
  },
  {
    "text": "for training workers and processes",
    "start": "418160",
    "end": "420639"
  },
  {
    "text": "so many times you want to optimize the",
    "start": "420639",
    "end": "422720"
  },
  {
    "text": "placement of our workers",
    "start": "422720",
    "end": "423919"
  },
  {
    "text": "for example specifying that a data shard",
    "start": "423919",
    "end": "425919"
  },
  {
    "text": "and its corresponding training worker",
    "start": "425919",
    "end": "427360"
  },
  {
    "text": "should be co-located on the same node",
    "start": "427360",
    "end": "429360"
  },
  {
    "text": "or specifying that we want to spread out",
    "start": "429360",
    "end": "430720"
  },
  {
    "text": "our training workers across nodes as",
    "start": "430720",
    "end": "432319"
  },
  {
    "text": "much as possible to minimize the impact",
    "start": "432319",
    "end": "434160"
  },
  {
    "text": "of node failure",
    "start": "434160",
    "end": "435440"
  },
  {
    "text": "or we might want to ensure we have",
    "start": "435440",
    "end": "436800"
  },
  {
    "text": "homogenous setup where each node is",
    "start": "436800",
    "end": "438319"
  },
  {
    "text": "exactly the same number of training",
    "start": "438319",
    "end": "439759"
  },
  {
    "text": "workers",
    "start": "439759",
    "end": "441039"
  },
  {
    "text": "these sort of uh custom placement",
    "start": "441039",
    "end": "443759"
  },
  {
    "text": "strategies",
    "start": "443759",
    "end": "444639"
  },
  {
    "text": "are not really easy to implement and",
    "start": "444639",
    "end": "446319"
  },
  {
    "text": "could be a",
    "start": "446319",
    "end": "447680"
  },
  {
    "text": "main challenge in really having scaled",
    "start": "447680",
    "end": "451440"
  },
  {
    "text": "scale distributed training",
    "start": "451440",
    "end": "454639"
  },
  {
    "text": "so now that we've gone over the",
    "start": "455039",
    "end": "456160"
  },
  {
    "text": "challenges with distributed ml let's see",
    "start": "456160",
    "end": "458080"
  },
  {
    "text": "how ray can help you",
    "start": "458080",
    "end": "459280"
  },
  {
    "text": "help solve those and does enable us to",
    "start": "459280",
    "end": "461840"
  },
  {
    "text": "build distributed ml applications in ray",
    "start": "461840",
    "end": "464240"
  },
  {
    "text": "so first give us small crash course on",
    "start": "464240",
    "end": "466319"
  },
  {
    "text": "ray i mean many of you are already",
    "start": "466319",
    "end": "467520"
  },
  {
    "text": "familiar on it but i'll go through it",
    "start": "467520",
    "end": "468800"
  },
  {
    "text": "really quickly",
    "start": "468800",
    "end": "469759"
  },
  {
    "text": "and then we can also talk about",
    "start": "469759",
    "end": "471759"
  },
  {
    "text": "specifically what about ray can help us",
    "start": "471759",
    "end": "473440"
  },
  {
    "text": "solve those",
    "start": "473440",
    "end": "474080"
  },
  {
    "text": "three challenges that i mentioned",
    "start": "474080",
    "end": "475360"
  },
  {
    "text": "previously",
    "start": "475360",
    "end": "477759"
  },
  {
    "text": "so first what is rey so specifically for",
    "start": "477759",
    "end": "480960"
  },
  {
    "text": "for training uh ray uh",
    "start": "480960",
    "end": "484160"
  },
  {
    "text": "has a mix of native and third-party",
    "start": "484160",
    "end": "485840"
  },
  {
    "text": "libraries and these libraries are",
    "start": "485840",
    "end": "487680"
  },
  {
    "text": "integrated with very different levels of",
    "start": "487680",
    "end": "489199"
  },
  {
    "text": "the training stack",
    "start": "489199",
    "end": "490080"
  },
  {
    "text": "so ray provides like a universal",
    "start": "490080",
    "end": "491759"
  },
  {
    "text": "distributed company framework",
    "start": "491759",
    "end": "493120"
  },
  {
    "text": "these libraries whether they're native",
    "start": "493120",
    "end": "494720"
  },
  {
    "text": "or third-party are built on top of ray",
    "start": "494720",
    "end": "496879"
  },
  {
    "text": "and these libraries could exist across a",
    "start": "496879",
    "end": "498639"
  },
  {
    "text": "variety of domains and within training",
    "start": "498639",
    "end": "500639"
  },
  {
    "text": "at different levels of the training",
    "start": "500639",
    "end": "502080"
  },
  {
    "text": "process",
    "start": "502080",
    "end": "504478"
  },
  {
    "text": "so the three key benefits that ray",
    "start": "504720",
    "end": "506240"
  },
  {
    "start": "506000",
    "end": "506000"
  },
  {
    "text": "provides to solve those three challenges",
    "start": "506240",
    "end": "508000"
  },
  {
    "text": "earlier",
    "start": "508000",
    "end": "508639"
  },
  {
    "text": "is that we first have a simple api to",
    "start": "508639",
    "end": "510879"
  },
  {
    "text": "support ad-hoc",
    "start": "510879",
    "end": "511840"
  },
  {
    "text": "uh concurrent programming ray also makes",
    "start": "511840",
    "end": "514640"
  },
  {
    "text": "it very easy to",
    "start": "514640",
    "end": "515680"
  },
  {
    "text": "support uh elastic workloads uh you can",
    "start": "515680",
    "end": "518719"
  },
  {
    "text": "easily implement elastic training on ray",
    "start": "518719",
    "end": "520959"
  },
  {
    "text": "because of its auto-scaling",
    "start": "520959",
    "end": "522560"
  },
  {
    "text": "capabilities and finally rape provides",
    "start": "522560",
    "end": "524800"
  },
  {
    "text": "apis to handle complex worker",
    "start": "524800",
    "end": "526720"
  },
  {
    "text": "task placement so we can do things like",
    "start": "526720",
    "end": "530080"
  },
  {
    "text": "ensuring that certain processes are",
    "start": "530080",
    "end": "532560"
  },
  {
    "text": "co-located in the same node or",
    "start": "532560",
    "end": "534240"
  },
  {
    "text": "ensuring that there's equal number of",
    "start": "534240",
    "end": "536399"
  },
  {
    "text": "training workers on each node in our",
    "start": "536399",
    "end": "537920"
  },
  {
    "text": "cluster",
    "start": "537920",
    "end": "540320"
  },
  {
    "text": "so most of you guys are already very",
    "start": "540399",
    "end": "541600"
  },
  {
    "text": "familiar with this already but i'll do a",
    "start": "541600",
    "end": "542880"
  },
  {
    "text": "quick refresher on the right api",
    "start": "542880",
    "end": "544880"
  },
  {
    "text": "here we have a couple of simple python",
    "start": "544880",
    "end": "546839"
  },
  {
    "text": "functions",
    "start": "546839",
    "end": "548399"
  },
  {
    "text": "and the primitive array exposes is this",
    "start": "548399",
    "end": "550399"
  },
  {
    "text": "radar remote decorator",
    "start": "550399",
    "end": "551920"
  },
  {
    "text": "which takes an arbitrary python function",
    "start": "551920",
    "end": "554000"
  },
  {
    "text": "and designates it as a remote function",
    "start": "554000",
    "end": "557680"
  },
  {
    "text": "so now so what this means is that we can",
    "start": "557680",
    "end": "559839"
  },
  {
    "text": "then call uh",
    "start": "559839",
    "end": "562080"
  },
  {
    "text": "our function.remote and this will return",
    "start": "562080",
    "end": "564560"
  },
  {
    "text": "a future",
    "start": "564560",
    "end": "565760"
  },
  {
    "text": "so this returns immediately while the",
    "start": "565760",
    "end": "568240"
  },
  {
    "text": "the function is still executing",
    "start": "568240",
    "end": "569920"
  },
  {
    "text": "we can get the result immediately and",
    "start": "569920",
    "end": "571600"
  },
  {
    "text": "then we can combine multiple results so",
    "start": "571600",
    "end": "573920"
  },
  {
    "text": "here",
    "start": "573920",
    "end": "574800"
  },
  {
    "text": "we do read a radar remote twice and then",
    "start": "574800",
    "end": "577200"
  },
  {
    "text": "we can pass",
    "start": "577200",
    "end": "577920"
  },
  {
    "text": "those object references or futures into",
    "start": "577920",
    "end": "580399"
  },
  {
    "text": "add.remote",
    "start": "580399",
    "end": "581760"
  },
  {
    "text": "and then finally if we want to um",
    "start": "581760",
    "end": "585440"
  },
  {
    "text": "get the final result all you have to do",
    "start": "585440",
    "end": "587120"
  },
  {
    "text": "is like a ray.getcall on the object",
    "start": "587120",
    "end": "588959"
  },
  {
    "text": "reference that we want",
    "start": "588959",
    "end": "590320"
  },
  {
    "text": "and just like with functions we can also",
    "start": "590320",
    "end": "591760"
  },
  {
    "text": "do the same thing with actors which are",
    "start": "591760",
    "end": "593440"
  },
  {
    "text": "essentially remote classes",
    "start": "593440",
    "end": "595760"
  },
  {
    "text": "so here's another example we have a",
    "start": "595760",
    "end": "597279"
  },
  {
    "text": "simple python class",
    "start": "597279",
    "end": "599120"
  },
  {
    "text": "which is as a method for incrementing",
    "start": "599120",
    "end": "600560"
  },
  {
    "text": "counter you can add the remote decorator",
    "start": "600560",
    "end": "602800"
  },
  {
    "text": "to convert it into an actor",
    "start": "602800",
    "end": "605760"
  },
  {
    "text": "and then what we can do is a call",
    "start": "605760",
    "end": "608240"
  },
  {
    "text": "counter.remote to instantiate the class",
    "start": "608240",
    "end": "610800"
  },
  {
    "text": "this will create a new worker process",
    "start": "610800",
    "end": "612480"
  },
  {
    "text": "and the actor is created somewhere in",
    "start": "612480",
    "end": "613920"
  },
  {
    "text": "the cluster",
    "start": "613920",
    "end": "615279"
  },
  {
    "text": "and each method call creates tasks that",
    "start": "615279",
    "end": "617440"
  },
  {
    "text": "are scheduled on that worker process",
    "start": "617440",
    "end": "619839"
  },
  {
    "text": "so in this example these three tasks are",
    "start": "619839",
    "end": "622640"
  },
  {
    "text": "are",
    "start": "622640",
    "end": "622959"
  },
  {
    "text": "executed sequentially on the actor and",
    "start": "622959",
    "end": "625200"
  },
  {
    "text": "there's no parallelism across these",
    "start": "625200",
    "end": "626959"
  },
  {
    "text": "tasks because they all share the mutable",
    "start": "626959",
    "end": "628399"
  },
  {
    "text": "state of the actor",
    "start": "628399",
    "end": "630079"
  },
  {
    "text": "and finally these tasks that are",
    "start": "630079",
    "end": "632800"
  },
  {
    "text": "executed on the actor once again will",
    "start": "632800",
    "end": "634399"
  },
  {
    "text": "return object references and then we",
    "start": "634399",
    "end": "635760"
  },
  {
    "text": "simply do a ray.getcall",
    "start": "635760",
    "end": "637279"
  },
  {
    "text": "to get the actual value that these",
    "start": "637279",
    "end": "639279"
  },
  {
    "text": "object references refer to",
    "start": "639279",
    "end": "642640"
  },
  {
    "start": "642000",
    "end": "642000"
  },
  {
    "text": "great so another api that ray exposes is",
    "start": "643279",
    "end": "645519"
  },
  {
    "text": "placement groups",
    "start": "645519",
    "end": "646640"
  },
  {
    "text": "so this allows us to have flexible",
    "start": "646640",
    "end": "648720"
  },
  {
    "text": "placement strategies",
    "start": "648720",
    "end": "649920"
  },
  {
    "text": "and it provides an interface for custom",
    "start": "649920",
    "end": "651600"
  },
  {
    "text": "placement of tasks and actors",
    "start": "651600",
    "end": "653440"
  },
  {
    "text": "the way it works is that we create",
    "start": "653440",
    "end": "655040"
  },
  {
    "text": "bundles of resources",
    "start": "655040",
    "end": "656640"
  },
  {
    "text": "so in this example we create a bundle of",
    "start": "656640",
    "end": "659279"
  },
  {
    "text": "two gpus",
    "start": "659279",
    "end": "660640"
  },
  {
    "text": "and then we create a bundle of this",
    "start": "660640",
    "end": "662880"
  },
  {
    "text": "custom extra resources that we",
    "start": "662880",
    "end": "664800"
  },
  {
    "text": "extra resource we want called extra",
    "start": "664800",
    "end": "666399"
  },
  {
    "text": "resource",
    "start": "666399",
    "end": "668160"
  },
  {
    "text": "and then we can schedule workers using",
    "start": "668160",
    "end": "670000"
  },
  {
    "text": "each bundle so we can create a",
    "start": "670000",
    "end": "671680"
  },
  {
    "text": "great placement group from these bundles",
    "start": "671680",
    "end": "674000"
  },
  {
    "text": "and say that we want these uh bundles to",
    "start": "674000",
    "end": "676480"
  },
  {
    "text": "be packed together",
    "start": "676480",
    "end": "677920"
  },
  {
    "text": "which means they want to be placed in",
    "start": "677920",
    "end": "679279"
  },
  {
    "text": "the same nodes so any",
    "start": "679279",
    "end": "681120"
  },
  {
    "text": "any reactor or task in this placement",
    "start": "681120",
    "end": "684079"
  },
  {
    "text": "group",
    "start": "684079",
    "end": "684560"
  },
  {
    "text": "will be guaranteed to be placed in the",
    "start": "684560",
    "end": "685920"
  },
  {
    "text": "same node alternatively you can use",
    "start": "685920",
    "end": "687760"
  },
  {
    "text": "other",
    "start": "687760",
    "end": "688000"
  },
  {
    "text": "strategies like spread which will make",
    "start": "688000",
    "end": "689680"
  },
  {
    "text": "sure that the bundles are spread on",
    "start": "689680",
    "end": "691120"
  },
  {
    "text": "different nodes",
    "start": "691120",
    "end": "692320"
  },
  {
    "text": "and there's other strategies as well so",
    "start": "692320",
    "end": "694320"
  },
  {
    "text": "with the rate placement groups we can",
    "start": "694320",
    "end": "695760"
  },
  {
    "text": "implement the custom placement",
    "start": "695760",
    "end": "697040"
  },
  {
    "text": "strategies that are required for",
    "start": "697040",
    "end": "698320"
  },
  {
    "text": "distributed machine learning then",
    "start": "698320",
    "end": "702079"
  },
  {
    "start": "701000",
    "end": "701000"
  },
  {
    "text": "finally we have the ray auto scaler or",
    "start": "702079",
    "end": "703760"
  },
  {
    "text": "the ray cluster launcher",
    "start": "703760",
    "end": "705519"
  },
  {
    "text": "so the ray cluster launcher allows you",
    "start": "705519",
    "end": "707839"
  },
  {
    "text": "to easily spin up a cluster",
    "start": "707839",
    "end": "709680"
  },
  {
    "text": "on any cloud provider of your choice and",
    "start": "709680",
    "end": "711920"
  },
  {
    "text": "will automatically enable a load-based",
    "start": "711920",
    "end": "714320"
  },
  {
    "text": "auto scaler",
    "start": "714320",
    "end": "715680"
  },
  {
    "text": "so what this allows you to do is that",
    "start": "715680",
    "end": "717200"
  },
  {
    "text": "you can with just like a single line you",
    "start": "717200",
    "end": "718800"
  },
  {
    "text": "can create a ray cluster",
    "start": "718800",
    "end": "720320"
  },
  {
    "text": "on the cloud and then run your array",
    "start": "720320",
    "end": "721920"
  },
  {
    "text": "program using the same code that you",
    "start": "721920",
    "end": "723680"
  },
  {
    "text": "would use to paralyze your laptop but",
    "start": "723680",
    "end": "725519"
  },
  {
    "text": "now to paralyze across",
    "start": "725519",
    "end": "726880"
  },
  {
    "text": "all the machines and cluster the ray",
    "start": "726880",
    "end": "729040"
  },
  {
    "text": "autoscaler will automatically add new",
    "start": "729040",
    "end": "730800"
  },
  {
    "text": "nodes",
    "start": "730800",
    "end": "731279"
  },
  {
    "text": "to satisfy resource demands by your",
    "start": "731279",
    "end": "733279"
  },
  {
    "text": "application and will automatically",
    "start": "733279",
    "end": "735120"
  },
  {
    "text": "remove idle nodes",
    "start": "735120",
    "end": "736639"
  },
  {
    "text": "therefore with the ray autoscaler and",
    "start": "736639",
    "end": "738880"
  },
  {
    "text": "the ray apis",
    "start": "738880",
    "end": "739920"
  },
  {
    "text": "it provides an easy interface to",
    "start": "739920",
    "end": "741279"
  },
  {
    "text": "implement elastic training in the",
    "start": "741279",
    "end": "742880"
  },
  {
    "text": "application layer",
    "start": "742880",
    "end": "744000"
  },
  {
    "text": "which is one of the challenges that we",
    "start": "744000",
    "end": "745279"
  },
  {
    "text": "talked about earlier",
    "start": "745279",
    "end": "748079"
  },
  {
    "text": "great so now we know how ray works and",
    "start": "749040",
    "end": "751279"
  },
  {
    "text": "how some of his features help",
    "start": "751279",
    "end": "752639"
  },
  {
    "text": "solve the challenges of distributed",
    "start": "752639",
    "end": "754480"
  },
  {
    "text": "machine learning now let's see how",
    "start": "754480",
    "end": "757120"
  },
  {
    "text": "we've used ray to integrate with various",
    "start": "757120",
    "end": "759279"
  },
  {
    "text": "libraries in the ml ecosystem",
    "start": "759279",
    "end": "760880"
  },
  {
    "text": "and how the ml ecosystem is unifying",
    "start": "760880",
    "end": "762880"
  },
  {
    "text": "around ray across different levels of",
    "start": "762880",
    "end": "765360"
  },
  {
    "text": "the",
    "start": "765360",
    "end": "766320"
  },
  {
    "text": "across different layers in the training",
    "start": "766320",
    "end": "767839"
  },
  {
    "text": "stack",
    "start": "767839",
    "end": "770160"
  },
  {
    "start": "770000",
    "end": "770000"
  },
  {
    "text": "so there's three types of integrations",
    "start": "770240",
    "end": "772160"
  },
  {
    "text": "that we have with array",
    "start": "772160",
    "end": "774079"
  },
  {
    "text": "one of them is uh lower level",
    "start": "774079",
    "end": "776959"
  },
  {
    "text": "communicators",
    "start": "776959",
    "end": "777920"
  },
  {
    "text": "so for example horavod uh what this",
    "start": "777920",
    "end": "780800"
  },
  {
    "text": "means like ray is pretty deeply",
    "start": "780800",
    "end": "782399"
  },
  {
    "text": "integrated with horovod and is actually",
    "start": "782399",
    "end": "784839"
  },
  {
    "text": "used",
    "start": "784839",
    "end": "786160"
  },
  {
    "text": "actually checked into the horvat repo",
    "start": "786160",
    "end": "788480"
  },
  {
    "text": "and",
    "start": "788480",
    "end": "789519"
  },
  {
    "text": "it is used at a very low level",
    "start": "789519",
    "end": "792320"
  },
  {
    "text": "additionally we also have models and",
    "start": "792320",
    "end": "794079"
  },
  {
    "text": "algorithms which leverage ray",
    "start": "794079",
    "end": "795760"
  },
  {
    "text": "so this is when the actual machine",
    "start": "795760",
    "end": "797360"
  },
  {
    "text": "learning model itself has the need for",
    "start": "797360",
    "end": "799360"
  },
  {
    "text": "some sort of distributed computation",
    "start": "799360",
    "end": "801600"
  },
  {
    "text": "so for example this is the case with",
    "start": "801600",
    "end": "802880"
  },
  {
    "text": "rlib and reinforcement learning",
    "start": "802880",
    "end": "804320"
  },
  {
    "text": "algorithms",
    "start": "804320",
    "end": "805120"
  },
  {
    "text": "and also like i mentioned before the",
    "start": "805120",
    "end": "807519"
  },
  {
    "text": "retrieval augmented generation model",
    "start": "807519",
    "end": "809279"
  },
  {
    "text": "which pulls documents from external data",
    "start": "809279",
    "end": "811360"
  },
  {
    "text": "sets",
    "start": "811360",
    "end": "812320"
  },
  {
    "text": "can also leverage array to scale that",
    "start": "812320",
    "end": "814800"
  },
  {
    "text": "document retrieval out",
    "start": "814800",
    "end": "816399"
  },
  {
    "text": "and finally we have integration with",
    "start": "816399",
    "end": "817839"
  },
  {
    "text": "higher level trainers",
    "start": "817839",
    "end": "819920"
  },
  {
    "text": "so this is where the the model or any",
    "start": "819920",
    "end": "822560"
  },
  {
    "text": "low-level communication may not",
    "start": "822560",
    "end": "823839"
  },
  {
    "text": "necessarily use ray",
    "start": "823839",
    "end": "825519"
  },
  {
    "text": "but when you actually want to do",
    "start": "825519",
    "end": "827600"
  },
  {
    "text": "distributed training and create",
    "start": "827600",
    "end": "829279"
  },
  {
    "text": "various worker processes ray can be",
    "start": "829279",
    "end": "832000"
  },
  {
    "text": "useful here",
    "start": "832000",
    "end": "833040"
  },
  {
    "text": "to make sure these workers are scheduled",
    "start": "833040",
    "end": "834800"
  },
  {
    "text": "properly to handle the resource",
    "start": "834800",
    "end": "836720"
  },
  {
    "text": "management",
    "start": "836720",
    "end": "837600"
  },
  {
    "text": "uh any custom placement strategies that",
    "start": "837600",
    "end": "839519"
  },
  {
    "text": "we want as well",
    "start": "839519",
    "end": "840959"
  },
  {
    "text": "so we have ray sgd which is like a",
    "start": "840959",
    "end": "842959"
  },
  {
    "text": "native library which",
    "start": "842959",
    "end": "844560"
  },
  {
    "text": "integrates which builds a high level",
    "start": "844560",
    "end": "846880"
  },
  {
    "text": "trainer on top",
    "start": "846880",
    "end": "847680"
  },
  {
    "text": "using the ray api and we also have",
    "start": "847680",
    "end": "849440"
  },
  {
    "text": "integrations with hugging face",
    "start": "849440",
    "end": "851519"
  },
  {
    "text": "trainer as well as with pytorch",
    "start": "851519",
    "end": "853199"
  },
  {
    "text": "lightning",
    "start": "853199",
    "end": "855600"
  },
  {
    "text": "so let's first start off with horvath",
    "start": "855600",
    "end": "857279"
  },
  {
    "text": "which is a pretty deep integration with",
    "start": "857279",
    "end": "859040"
  },
  {
    "text": "ray",
    "start": "859040",
    "end": "861199"
  },
  {
    "text": "horovod is an open source library for",
    "start": "861199",
    "end": "863279"
  },
  {
    "text": "fast and easy distributed training",
    "start": "863279",
    "end": "865120"
  },
  {
    "text": "uh and it allows you to use any deep",
    "start": "865120",
    "end": "866639"
  },
  {
    "text": "learning framework so tensorflow torch",
    "start": "866639",
    "end": "868959"
  },
  {
    "text": "keras mxnet",
    "start": "868959",
    "end": "870720"
  },
  {
    "text": "horvat implements its own uh distributed",
    "start": "870720",
    "end": "873360"
  },
  {
    "text": "optimizers and has its own all reduced",
    "start": "873360",
    "end": "875360"
  },
  {
    "text": "communication protocol which provides",
    "start": "875360",
    "end": "876959"
  },
  {
    "text": "excellent scaling efficiency",
    "start": "876959",
    "end": "878800"
  },
  {
    "text": "and in addition elastic horovod was",
    "start": "878800",
    "end": "880639"
  },
  {
    "text": "released last year to allow for dynamic",
    "start": "880639",
    "end": "883199"
  },
  {
    "text": "scaling during training",
    "start": "883199",
    "end": "885600"
  },
  {
    "text": "however the problem with horovod was",
    "start": "885600",
    "end": "887920"
  },
  {
    "text": "that it did not actually implement",
    "start": "887920",
    "end": "889360"
  },
  {
    "text": "actual the actual operation of adding or",
    "start": "889360",
    "end": "891360"
  },
  {
    "text": "removing nodes",
    "start": "891360",
    "end": "892480"
  },
  {
    "text": "or making resource requests therefore it",
    "start": "892480",
    "end": "895760"
  },
  {
    "text": "sort of relied on",
    "start": "895760",
    "end": "897199"
  },
  {
    "text": "the user to implement it themselves on",
    "start": "897199",
    "end": "899360"
  },
  {
    "text": "the various cloud providers",
    "start": "899360",
    "end": "902480"
  },
  {
    "text": "and it requires a lot of custom code to",
    "start": "902480",
    "end": "904320"
  },
  {
    "text": "make this work and this is where rey",
    "start": "904320",
    "end": "906240"
  },
  {
    "text": "comes in",
    "start": "906240",
    "end": "908240"
  },
  {
    "text": "so with horvat and ray allows you to use",
    "start": "908240",
    "end": "911279"
  },
  {
    "text": "uh ray's autoscaler in any cloud",
    "start": "911279",
    "end": "913040"
  },
  {
    "text": "provider or orchestrator",
    "start": "913040",
    "end": "915199"
  },
  {
    "text": "and also this integration supports",
    "start": "915199",
    "end": "917360"
  },
  {
    "text": "various custom placement strategies",
    "start": "917360",
    "end": "919440"
  },
  {
    "text": "uh so you can leverage uh raised",
    "start": "919440",
    "end": "921519"
  },
  {
    "text": "placement groups",
    "start": "921519",
    "end": "922560"
  },
  {
    "text": "even raise object store and raise",
    "start": "922560",
    "end": "924399"
  },
  {
    "text": "resource management abilities",
    "start": "924399",
    "end": "926959"
  },
  {
    "text": "so if you look at this code here all you",
    "start": "926959",
    "end": "930240"
  },
  {
    "text": "have to do is create your ray cluster",
    "start": "930240",
    "end": "931920"
  },
  {
    "text": "and attach to it",
    "start": "931920",
    "end": "933279"
  },
  {
    "text": "create a ray executor this is like a",
    "start": "933279",
    "end": "935839"
  },
  {
    "text": "specific module in the horovod",
    "start": "935839",
    "end": "938320"
  },
  {
    "text": "codebase uh specify that we want to use",
    "start": "938320",
    "end": "940959"
  },
  {
    "text": "gpus and the number of workers we want",
    "start": "940959",
    "end": "942720"
  },
  {
    "text": "or we can create an elastic ray executor",
    "start": "942720",
    "end": "944720"
  },
  {
    "text": "which will do elastic training for us",
    "start": "944720",
    "end": "947040"
  },
  {
    "text": "then what we do is we start the executor",
    "start": "947040",
    "end": "949199"
  },
  {
    "text": "and then run the training function with",
    "start": "949199",
    "end": "950800"
  },
  {
    "text": "our",
    "start": "950800",
    "end": "951040"
  },
  {
    "text": "robot code this will automatically place",
    "start": "951040",
    "end": "953680"
  },
  {
    "text": "these workers on the right cluster",
    "start": "953680",
    "end": "955839"
  },
  {
    "text": "horvat will be used for communication",
    "start": "955839",
    "end": "958160"
  },
  {
    "text": "but",
    "start": "958160",
    "end": "959040"
  },
  {
    "text": "the ray will handle the placement and",
    "start": "959040",
    "end": "960639"
  },
  {
    "text": "the resource management here and this",
    "start": "960639",
    "end": "962160"
  },
  {
    "text": "also allows you to leverage the right",
    "start": "962160",
    "end": "963600"
  },
  {
    "text": "ecosystem",
    "start": "963600",
    "end": "964560"
  },
  {
    "text": "so for example if you want to do",
    "start": "964560",
    "end": "965839"
  },
  {
    "text": "distributed data loading you can use",
    "start": "965839",
    "end": "967839"
  },
  {
    "text": "other",
    "start": "967839",
    "end": "968800"
  },
  {
    "text": "integrations that we have for data",
    "start": "968800",
    "end": "970160"
  },
  {
    "text": "processing on array to do so",
    "start": "970160",
    "end": "972480"
  },
  {
    "text": "and you can also leverage ray 2 and",
    "start": "972480",
    "end": "974079"
  },
  {
    "text": "easily via ray tune",
    "start": "974079",
    "end": "976079"
  },
  {
    "text": "and finally using ray can allow you to",
    "start": "976079",
    "end": "977920"
  },
  {
    "text": "support jupiter notebooks for",
    "start": "977920",
    "end": "980160"
  },
  {
    "text": "horizon training because ray provides a",
    "start": "980160",
    "end": "982560"
  },
  {
    "text": "pythonic interface",
    "start": "982560",
    "end": "983920"
  },
  {
    "text": "it's easy to do like an interactive",
    "start": "983920",
    "end": "986079"
  },
  {
    "text": "workload here",
    "start": "986079",
    "end": "987199"
  },
  {
    "text": "via jupyter notebooks",
    "start": "987199",
    "end": "990319"
  },
  {
    "text": "so here's an example of what the",
    "start": "990639",
    "end": "992480"
  },
  {
    "text": "architecture looks like for horizontal",
    "start": "992480",
    "end": "994000"
  },
  {
    "text": "array",
    "start": "994000",
    "end": "994639"
  },
  {
    "text": "so ray handles creating the actors on",
    "start": "994639",
    "end": "996560"
  },
  {
    "text": "the ray cluster it handles the resource",
    "start": "996560",
    "end": "998480"
  },
  {
    "text": "management",
    "start": "998480",
    "end": "999199"
  },
  {
    "text": "the placement and scheduling and also",
    "start": "999199",
    "end": "1001199"
  },
  {
    "text": "the auto scaling to really make it easy",
    "start": "1001199",
    "end": "1003199"
  },
  {
    "text": "for uh elastic training but we still get",
    "start": "1003199",
    "end": "1006000"
  },
  {
    "text": "all the benefits of horvat all reduce",
    "start": "1006000",
    "end": "1008240"
  },
  {
    "text": "any any custom communication protocols",
    "start": "1008240",
    "end": "1010800"
  },
  {
    "text": "or horvat implements",
    "start": "1010800",
    "end": "1011839"
  },
  {
    "text": "for very efficient uh gradient",
    "start": "1011839",
    "end": "1013360"
  },
  {
    "text": "synchronization",
    "start": "1013360",
    "end": "1016079"
  },
  {
    "start": "1017000",
    "end": "1017000"
  },
  {
    "text": "great so now let's go over some of the",
    "start": "1018000",
    "end": "1019519"
  },
  {
    "text": "adoption that we have for horror vote",
    "start": "1019519",
    "end": "1020959"
  },
  {
    "text": "and ray",
    "start": "1020959",
    "end": "1021440"
  },
  {
    "text": "so this was integrated as a back end in",
    "start": "1021440",
    "end": "1023199"
  },
  {
    "text": "the horowat repository and you've seen",
    "start": "1023199",
    "end": "1025038"
  },
  {
    "text": "many users in the open source community",
    "start": "1025039",
    "end": "1027600"
  },
  {
    "text": "use harvard array because it's very easy",
    "start": "1027600",
    "end": "1029520"
  },
  {
    "text": "to use and also integrates with other",
    "start": "1029520",
    "end": "1031760"
  },
  {
    "text": "easily integrates with other libraries",
    "start": "1031760",
    "end": "1033600"
  },
  {
    "text": "in the red ecosystem we have dozens of",
    "start": "1033600",
    "end": "1035520"
  },
  {
    "text": "issues",
    "start": "1035520",
    "end": "1036319"
  },
  {
    "text": "for this and beyond the open source uber",
    "start": "1036319",
    "end": "1039038"
  },
  {
    "text": "itself is also",
    "start": "1039039",
    "end": "1040000"
  },
  {
    "text": "working on moving the deep learning",
    "start": "1040000",
    "end": "1041438"
  },
  {
    "text": "workloads to horror mode and right",
    "start": "1041439",
    "end": "1043360"
  },
  {
    "text": "and we're going to continue working on",
    "start": "1043360",
    "end": "1044959"
  },
  {
    "text": "this integration",
    "start": "1044959",
    "end": "1046400"
  },
  {
    "text": "trying to add more features trying to",
    "start": "1046400",
    "end": "1048799"
  },
  {
    "text": "tighten uh this integration some more",
    "start": "1048799",
    "end": "1050720"
  },
  {
    "text": "and create an even deeper integration",
    "start": "1050720",
    "end": "1052080"
  },
  {
    "text": "with horowat and ray",
    "start": "1052080",
    "end": "1055039"
  },
  {
    "text": "so the next level that we have is in the",
    "start": "1055600",
    "end": "1057280"
  },
  {
    "text": "model slash algorithms level",
    "start": "1057280",
    "end": "1059039"
  },
  {
    "text": "where the model itself has some sort of",
    "start": "1059039",
    "end": "1061200"
  },
  {
    "text": "component which",
    "start": "1061200",
    "end": "1062480"
  },
  {
    "text": "needs to be distributed uh when you want",
    "start": "1062480",
    "end": "1064640"
  },
  {
    "text": "to scale the model training out",
    "start": "1064640",
    "end": "1066559"
  },
  {
    "text": "so this is our lib is a great example",
    "start": "1066559",
    "end": "1068400"
  },
  {
    "text": "for this but i'll actually be going over",
    "start": "1068400",
    "end": "1070400"
  },
  {
    "text": "the hugging phase uh and particularly",
    "start": "1070400",
    "end": "1073280"
  },
  {
    "text": "the retrieval augmented generation model",
    "start": "1073280",
    "end": "1075200"
  },
  {
    "text": "that i discussed earlier and how it's",
    "start": "1075200",
    "end": "1077039"
  },
  {
    "text": "leveraging array for distributed",
    "start": "1077039",
    "end": "1079200"
  },
  {
    "text": "document retrieval",
    "start": "1079200",
    "end": "1082240"
  },
  {
    "text": "so retrieval augmented generation as i",
    "start": "1082400",
    "end": "1084640"
  },
  {
    "text": "mentioned is a",
    "start": "1084640",
    "end": "1085520"
  },
  {
    "text": "new nlp architecture by facebook ai and",
    "start": "1085520",
    "end": "1087760"
  },
  {
    "text": "it's implemented in hugging face as part",
    "start": "1087760",
    "end": "1089520"
  },
  {
    "text": "of its suite of nlp models",
    "start": "1089520",
    "end": "1091200"
  },
  {
    "text": "and like i mentioned before it leverages",
    "start": "1091200",
    "end": "1093280"
  },
  {
    "text": "external documents for state-of-the-art",
    "start": "1093280",
    "end": "1095039"
  },
  {
    "text": "results and knowledge of",
    "start": "1095039",
    "end": "1096480"
  },
  {
    "text": "knowledge intensive tasks like question",
    "start": "1096480",
    "end": "1098160"
  },
  {
    "text": "answering or a jeopardy jeopardy",
    "start": "1098160",
    "end": "1100400"
  },
  {
    "text": "question generation",
    "start": "1100400",
    "end": "1103280"
  },
  {
    "text": "so previously the document retrieval",
    "start": "1103600",
    "end": "1107679"
  },
  {
    "start": "1106000",
    "end": "1106000"
  },
  {
    "text": "was implemented with torch distributed",
    "start": "1107679",
    "end": "1110160"
  },
  {
    "text": "and this retrieval of contextual",
    "start": "1110160",
    "end": "1111760"
  },
  {
    "text": "documents is crucial for",
    "start": "1111760",
    "end": "1113760"
  },
  {
    "text": "rags state-of-the-art results",
    "start": "1113760",
    "end": "1117120"
  },
  {
    "text": "but the the problem with the torch",
    "start": "1117120",
    "end": "1119200"
  },
  {
    "text": "distributed implementation",
    "start": "1119200",
    "end": "1121039"
  },
  {
    "text": "is that one had a synchronization",
    "start": "1121039",
    "end": "1123280"
  },
  {
    "text": "bottleneck so the rank zero worker had",
    "start": "1123280",
    "end": "1125520"
  },
  {
    "text": "to receive inputs from all the other",
    "start": "1125520",
    "end": "1127039"
  },
  {
    "text": "workers",
    "start": "1127039",
    "end": "1128320"
  },
  {
    "text": "and that's in the results back so this",
    "start": "1128320",
    "end": "1130400"
  },
  {
    "text": "sort of limited the performance if you",
    "start": "1130400",
    "end": "1131760"
  },
  {
    "text": "had multiple workers",
    "start": "1131760",
    "end": "1133200"
  },
  {
    "text": "and the second is that it's pi torch",
    "start": "1133200",
    "end": "1134640"
  },
  {
    "text": "specific so it made it very difficult to",
    "start": "1134640",
    "end": "1136480"
  },
  {
    "text": "implement a tensorflow version of",
    "start": "1136480",
    "end": "1138240"
  },
  {
    "text": "the rag model because uh the",
    "start": "1138240",
    "end": "1141520"
  },
  {
    "text": "document retrieval was implemented with",
    "start": "1141520",
    "end": "1143120"
  },
  {
    "text": "pytorch",
    "start": "1143120",
    "end": "1145600"
  },
  {
    "text": "so so this is where rake comes in right",
    "start": "1145600",
    "end": "1148080"
  },
  {
    "text": "using raised simple",
    "start": "1148080",
    "end": "1149200"
  },
  {
    "text": "apis we can we can",
    "start": "1149200",
    "end": "1152240"
  },
  {
    "text": "use uh the reactor abstraction that i",
    "start": "1152240",
    "end": "1154480"
  },
  {
    "text": "mentioned before",
    "start": "1154480",
    "end": "1155919"
  },
  {
    "text": "to create multiple processes that are",
    "start": "1155919",
    "end": "1157919"
  },
  {
    "text": "separate from the training processes",
    "start": "1157919",
    "end": "1159919"
  },
  {
    "text": "and these additional reactors are used",
    "start": "1159919",
    "end": "1161679"
  },
  {
    "text": "to load the index and handle the",
    "start": "1161679",
    "end": "1163120"
  },
  {
    "text": "retrieval queries",
    "start": "1163120",
    "end": "1164400"
  },
  {
    "text": "and with multiple reactors retrieval is",
    "start": "1164400",
    "end": "1166320"
  },
  {
    "text": "no longer a bottleneck",
    "start": "1166320",
    "end": "1167679"
  },
  {
    "text": "and pi torch is no longer a requirement",
    "start": "1167679",
    "end": "1170000"
  },
  {
    "text": "for uh",
    "start": "1170000",
    "end": "1170880"
  },
  {
    "text": "for implementing retrieval augmented",
    "start": "1170880",
    "end": "1172720"
  },
  {
    "text": "generation",
    "start": "1172720",
    "end": "1174240"
  },
  {
    "text": "so using ray it was pretty easy to to",
    "start": "1174240",
    "end": "1177360"
  },
  {
    "text": "add this ad hoc",
    "start": "1177360",
    "end": "1178799"
  },
  {
    "text": "uh distributed programming because ray",
    "start": "1178799",
    "end": "1181679"
  },
  {
    "text": "provides a simple api",
    "start": "1181679",
    "end": "1183200"
  },
  {
    "text": "and also we were able to actually get",
    "start": "1183200",
    "end": "1184559"
  },
  {
    "text": "better retrieval performance but",
    "start": "1184559",
    "end": "1186480"
  },
  {
    "text": "because we were able to remove the",
    "start": "1186480",
    "end": "1187679"
  },
  {
    "text": "bottleneck that the torch.distributed uh",
    "start": "1187679",
    "end": "1190480"
  },
  {
    "text": "limitation",
    "start": "1190480",
    "end": "1191120"
  },
  {
    "text": "uh the bottleneck the torch that",
    "start": "1191120",
    "end": "1192799"
  },
  {
    "text": "distributed had",
    "start": "1192799",
    "end": "1194400"
  },
  {
    "text": "so you're able to get up to 2x speed up",
    "start": "1194400",
    "end": "1196400"
  },
  {
    "text": "on document retrieval",
    "start": "1196400",
    "end": "1198400"
  },
  {
    "text": "in multi gpu fine tuning using ray",
    "start": "1198400",
    "end": "1201200"
  },
  {
    "text": "compared to torch",
    "start": "1201200",
    "end": "1204240"
  },
  {
    "text": "great so lastly we have integrations",
    "start": "1204960",
    "end": "1207280"
  },
  {
    "text": "with higher level training libraries",
    "start": "1207280",
    "end": "1209840"
  },
  {
    "text": "so these uh libraries provide some sort",
    "start": "1209840",
    "end": "1213039"
  },
  {
    "text": "of training interface",
    "start": "1213039",
    "end": "1214480"
  },
  {
    "text": "and ray is used uh to facilitate",
    "start": "1214480",
    "end": "1217919"
  },
  {
    "text": "the uh scaling of the trainer",
    "start": "1217919",
    "end": "1221520"
  },
  {
    "text": "distributed training as well as also",
    "start": "1221520",
    "end": "1223520"
  },
  {
    "text": "make it very easy to deploy a",
    "start": "1223520",
    "end": "1225039"
  },
  {
    "text": "distributed training job",
    "start": "1225039",
    "end": "1226640"
  },
  {
    "text": "so ray sgd is one example for this which",
    "start": "1226640",
    "end": "1228559"
  },
  {
    "text": "is a native library package with ray",
    "start": "1228559",
    "end": "1230640"
  },
  {
    "text": "but we also have integrations with",
    "start": "1230640",
    "end": "1232000"
  },
  {
    "text": "hugging face and pytorch landing which",
    "start": "1232000",
    "end": "1233360"
  },
  {
    "text": "is what i'll be going over",
    "start": "1233360",
    "end": "1235679"
  },
  {
    "start": "1235000",
    "end": "1235000"
  },
  {
    "text": "so hugging face transformers also",
    "start": "1235679",
    "end": "1238640"
  },
  {
    "text": "exposes a trainer interface",
    "start": "1238640",
    "end": "1241280"
  },
  {
    "text": "to make it very easy to leverage their",
    "start": "1241280",
    "end": "1243200"
  },
  {
    "text": "uh transformer models or any data sets",
    "start": "1243200",
    "end": "1245600"
  },
  {
    "text": "so the api is that you simply create a",
    "start": "1245600",
    "end": "1247200"
  },
  {
    "text": "trainer",
    "start": "1247200",
    "end": "1248720"
  },
  {
    "text": "and then we use ray to",
    "start": "1248720",
    "end": "1252000"
  },
  {
    "text": "specifically retune to make it very easy",
    "start": "1252000",
    "end": "1254320"
  },
  {
    "text": "to do hyper parameter optimization with",
    "start": "1254320",
    "end": "1256000"
  },
  {
    "text": "the trainer",
    "start": "1256000",
    "end": "1256720"
  },
  {
    "text": "so all you have to do is",
    "start": "1256720",
    "end": "1257880"
  },
  {
    "text": "trainer.hyperparameter search specify",
    "start": "1257880",
    "end": "1259919"
  },
  {
    "text": "your backend os ray",
    "start": "1259919",
    "end": "1261440"
  },
  {
    "text": "and you can run distributed",
    "start": "1261440",
    "end": "1262480"
  },
  {
    "text": "hyper-parameter optimization experiment",
    "start": "1262480",
    "end": "1265039"
  },
  {
    "text": "with your hugging phase trainer",
    "start": "1265039",
    "end": "1268240"
  },
  {
    "text": "and in addition we also have integration",
    "start": "1268240",
    "end": "1269840"
  },
  {
    "text": "with pytorch lightning which is another",
    "start": "1269840",
    "end": "1271760"
  },
  {
    "start": "1270000",
    "end": "1270000"
  },
  {
    "text": "open source library that provides a high",
    "start": "1271760",
    "end": "1273360"
  },
  {
    "text": "level interface on top of pytorch",
    "start": "1273360",
    "end": "1275600"
  },
  {
    "text": "so this allows developers to focus on",
    "start": "1275600",
    "end": "1277360"
  },
  {
    "text": "research code not really worry about the",
    "start": "1277360",
    "end": "1279039"
  },
  {
    "text": "boiler plate",
    "start": "1279039",
    "end": "1280720"
  },
  {
    "text": "that's required for distributed uh high",
    "start": "1280720",
    "end": "1282880"
  },
  {
    "text": "torch training",
    "start": "1282880",
    "end": "1284080"
  },
  {
    "text": "however the problem with pythagoras",
    "start": "1284080",
    "end": "1285200"
  },
  {
    "text": "lighting is that it's not very easy to",
    "start": "1285200",
    "end": "1286640"
  },
  {
    "text": "deploy",
    "start": "1286640",
    "end": "1288000"
  },
  {
    "text": "if you want to do multi-node distributed",
    "start": "1288000",
    "end": "1290240"
  },
  {
    "text": "training you'd have to write",
    "start": "1290240",
    "end": "1291919"
  },
  {
    "text": "custom bash scripts uh ssh into each",
    "start": "1291919",
    "end": "1294799"
  },
  {
    "text": "node and then",
    "start": "1294799",
    "end": "1295679"
  },
  {
    "text": "run those scripts onto each node and",
    "start": "1295679",
    "end": "1297760"
  },
  {
    "text": "pytorch lighting also doesn't have any",
    "start": "1297760",
    "end": "1299440"
  },
  {
    "text": "cluster launching or auto-scaling",
    "start": "1299440",
    "end": "1300799"
  },
  {
    "text": "capabilities",
    "start": "1300799",
    "end": "1302240"
  },
  {
    "text": "so through this ray integration you can",
    "start": "1302240",
    "end": "1304080"
  },
  {
    "text": "actually launch your distributed",
    "start": "1304080",
    "end": "1305840"
  },
  {
    "text": "training job on a rate cluster",
    "start": "1305840",
    "end": "1307679"
  },
  {
    "text": "through a single python script this",
    "start": "1307679",
    "end": "1309840"
  },
  {
    "text": "makes it very easy to run your job",
    "start": "1309840",
    "end": "1311679"
  },
  {
    "text": "uh it also integrates with the right",
    "start": "1311679",
    "end": "1313280"
  },
  {
    "text": "tune for hyper parameter optimization as",
    "start": "1313280",
    "end": "1314960"
  },
  {
    "text": "well",
    "start": "1314960",
    "end": "1317200"
  },
  {
    "start": "1316000",
    "end": "1316000"
  },
  {
    "text": "so ray so adds support for pythor",
    "start": "1317440",
    "end": "1319679"
  },
  {
    "text": "sliding distributed back ends",
    "start": "1319679",
    "end": "1321840"
  },
  {
    "text": "uh so just like any standard python",
    "start": "1321840",
    "end": "1324400"
  },
  {
    "text": "lighting plug-in we've implemented a ray",
    "start": "1324400",
    "end": "1326400"
  },
  {
    "text": "plug-in as part of this ray lightning uh",
    "start": "1326400",
    "end": "1328799"
  },
  {
    "text": "library uh so ray plugin can then just",
    "start": "1328799",
    "end": "1331760"
  },
  {
    "text": "be passed to your python sliding trainer",
    "start": "1331760",
    "end": "1333840"
  },
  {
    "text": "so now you can run distributed training",
    "start": "1333840",
    "end": "1335679"
  },
  {
    "text": "on array cluster",
    "start": "1335679",
    "end": "1337200"
  },
  {
    "text": "uh without having to write any like",
    "start": "1337200",
    "end": "1339520"
  },
  {
    "text": "scripts or anything like that all from a",
    "start": "1339520",
    "end": "1340880"
  },
  {
    "text": "single python",
    "start": "1340880",
    "end": "1341679"
  },
  {
    "text": "uh python application and then you can",
    "start": "1341679",
    "end": "1344400"
  },
  {
    "text": "still interact with the pythagoras",
    "start": "1344400",
    "end": "1345679"
  },
  {
    "text": "lighting trainer like you normally would",
    "start": "1345679",
    "end": "1347520"
  },
  {
    "text": "so you get the benefits of pything but",
    "start": "1347520",
    "end": "1349440"
  },
  {
    "text": "then also the same benefits of raid that",
    "start": "1349440",
    "end": "1351120"
  },
  {
    "text": "you had before",
    "start": "1351120",
    "end": "1352559"
  },
  {
    "text": "such as auto scaling or cluster",
    "start": "1352559",
    "end": "1354480"
  },
  {
    "text": "launching as well as the benefits of the",
    "start": "1354480",
    "end": "1356240"
  },
  {
    "text": "ray ecosystem at large",
    "start": "1356240",
    "end": "1359360"
  },
  {
    "text": "uh ray also has like a supports a",
    "start": "1359360",
    "end": "1361520"
  },
  {
    "text": "horrified rape plug-in so if you don't",
    "start": "1361520",
    "end": "1362960"
  },
  {
    "text": "want to use pytorch distributed data",
    "start": "1362960",
    "end": "1364400"
  },
  {
    "text": "parallel",
    "start": "1364400",
    "end": "1365039"
  },
  {
    "text": "uh back-end you can use horrible instead",
    "start": "1365039",
    "end": "1368240"
  },
  {
    "text": "and ray also supports a model parallel",
    "start": "1368240",
    "end": "1370720"
  },
  {
    "text": "training",
    "start": "1370720",
    "end": "1371360"
  },
  {
    "text": "via fair scale so sharded uh training",
    "start": "1371360",
    "end": "1374480"
  },
  {
    "text": "with fair scale",
    "start": "1374480",
    "end": "1375600"
  },
  {
    "text": "support utilizes data parallel training",
    "start": "1375600",
    "end": "1378320"
  },
  {
    "text": "under the hood",
    "start": "1378320",
    "end": "1379280"
  },
  {
    "text": "except the optimizer and gradients are",
    "start": "1379280",
    "end": "1380960"
  },
  {
    "text": "sharded across gpus",
    "start": "1380960",
    "end": "1382720"
  },
  {
    "text": "so that way you can get similar accuracy",
    "start": "1382720",
    "end": "1384640"
  },
  {
    "text": "levels as you had before",
    "start": "1384640",
    "end": "1385919"
  },
  {
    "text": "but your memory overhead per gpu is",
    "start": "1385919",
    "end": "1387919"
  },
  {
    "text": "lower since each gpu only maintains of",
    "start": "1387919",
    "end": "1390480"
  },
  {
    "text": "some partition of your optimizer state",
    "start": "1390480",
    "end": "1392400"
  },
  {
    "text": "and gradients",
    "start": "1392400",
    "end": "1393919"
  },
  {
    "text": "so the raid landing library also has a",
    "start": "1393919",
    "end": "1395679"
  },
  {
    "text": "plug-in for uh",
    "start": "1395679",
    "end": "1397120"
  },
  {
    "text": "for sharded training via fair scale",
    "start": "1397120",
    "end": "1400320"
  },
  {
    "text": "so the architecture for this uh pie",
    "start": "1400320",
    "end": "1402320"
  },
  {
    "text": "church landing with ray integration",
    "start": "1402320",
    "end": "1404159"
  },
  {
    "text": "looks similar to what we had for",
    "start": "1404159",
    "end": "1405360"
  },
  {
    "text": "horrifying ray so we have our",
    "start": "1405360",
    "end": "1407520"
  },
  {
    "start": "1407000",
    "end": "1407000"
  },
  {
    "text": "workers which are reactors you can run",
    "start": "1407520",
    "end": "1409440"
  },
  {
    "text": "them on a raid cluster",
    "start": "1409440",
    "end": "1410640"
  },
  {
    "text": "except this time we can actually",
    "start": "1410640",
    "end": "1411840"
  },
  {
    "text": "interact with the higher level",
    "start": "1411840",
    "end": "1412880"
  },
  {
    "text": "pythagoras landing interface",
    "start": "1412880",
    "end": "1416880"
  },
  {
    "text": "great so now we've gone over some of the",
    "start": "1416880",
    "end": "1418640"
  },
  {
    "text": "integrations that we have with ray",
    "start": "1418640",
    "end": "1420400"
  },
  {
    "text": "both at a low level and the model level",
    "start": "1420400",
    "end": "1422640"
  },
  {
    "text": "as well as a higher level trainer level",
    "start": "1422640",
    "end": "1424559"
  },
  {
    "text": "so we can really see that the ecosystem",
    "start": "1424559",
    "end": "1426559"
  },
  {
    "text": "uh the ml ecosystem regardless of which",
    "start": "1426559",
    "end": "1429520"
  },
  {
    "text": "level that the libraries are at are",
    "start": "1429520",
    "end": "1431760"
  },
  {
    "text": "integrating with array to take advantage",
    "start": "1431760",
    "end": "1433360"
  },
  {
    "text": "of",
    "start": "1433360",
    "end": "1433919"
  },
  {
    "text": "its capabilities such as auto scaling",
    "start": "1433919",
    "end": "1436559"
  },
  {
    "text": "easy to use api",
    "start": "1436559",
    "end": "1437840"
  },
  {
    "text": "as well as the other libraries in the",
    "start": "1437840",
    "end": "1439360"
  },
  {
    "text": "red ecosystem so the ml ecosystem at",
    "start": "1439360",
    "end": "1441440"
  },
  {
    "text": "large is unifying on ray",
    "start": "1441440",
    "end": "1443120"
  },
  {
    "text": "so what's next well a few things we have",
    "start": "1443120",
    "end": "1445600"
  },
  {
    "text": "on the road map",
    "start": "1445600",
    "end": "1446640"
  },
  {
    "text": "one is more support for model parallel",
    "start": "1446640",
    "end": "1448559"
  },
  {
    "text": "training so we're also potentially",
    "start": "1448559",
    "end": "1450000"
  },
  {
    "text": "looking at integrations with deep speech",
    "start": "1450000",
    "end": "1451520"
  },
  {
    "text": "for example",
    "start": "1451520",
    "end": "1452640"
  },
  {
    "text": "we're also looking into how we can",
    "start": "1452640",
    "end": "1453919"
  },
  {
    "text": "better tie raid data processing efforts",
    "start": "1453919",
    "end": "1456000"
  },
  {
    "text": "with training",
    "start": "1456000",
    "end": "1457679"
  },
  {
    "text": "so this is uh we have other race summit",
    "start": "1457679",
    "end": "1460240"
  },
  {
    "text": "talks discussing some efforts on data",
    "start": "1460240",
    "end": "1462000"
  },
  {
    "text": "processing array",
    "start": "1462000",
    "end": "1463120"
  },
  {
    "text": "and how we can better stitch these two",
    "start": "1463120",
    "end": "1464880"
  },
  {
    "text": "together uh finally we're also looking",
    "start": "1464880",
    "end": "1466960"
  },
  {
    "text": "at how we can better provide a",
    "start": "1466960",
    "end": "1468080"
  },
  {
    "text": "serverless experience for distributed",
    "start": "1468080",
    "end": "1469840"
  },
  {
    "text": "training on array",
    "start": "1469840",
    "end": "1470799"
  },
  {
    "text": "so being able to launch a distributed",
    "start": "1470799",
    "end": "1472960"
  },
  {
    "text": "array",
    "start": "1472960",
    "end": "1474159"
  },
  {
    "text": "distributed training job on a raid",
    "start": "1474159",
    "end": "1475840"
  },
  {
    "text": "cluster from your laptop",
    "start": "1475840",
    "end": "1477440"
  },
  {
    "text": "and you're making sure that all of our",
    "start": "1477440",
    "end": "1479039"
  },
  {
    "text": "integrations on raid libraries can",
    "start": "1479039",
    "end": "1480880"
  },
  {
    "text": "support this",
    "start": "1480880",
    "end": "1481919"
  },
  {
    "text": "experience and finally we have research",
    "start": "1481919",
    "end": "1484400"
  },
  {
    "text": "projects at uc berkeley",
    "start": "1484400",
    "end": "1486080"
  },
  {
    "text": "for example we have the ray collective",
    "start": "1486080",
    "end": "1488159"
  },
  {
    "text": "communications library",
    "start": "1488159",
    "end": "1489600"
  },
  {
    "text": "which was also an another race summit",
    "start": "1489600",
    "end": "1492080"
  },
  {
    "text": "session",
    "start": "1492080",
    "end": "1492799"
  },
  {
    "text": "for even more integrations with ray",
    "start": "1492799",
    "end": "1494960"
  },
  {
    "text": "particularly at a lower level",
    "start": "1494960",
    "end": "1498158"
  },
  {
    "text": "so if you want to connect with us uh",
    "start": "1499600",
    "end": "1501520"
  },
  {
    "text": "we'd be happy to",
    "start": "1501520",
    "end": "1502799"
  },
  {
    "text": "to hear about your use cases how you're",
    "start": "1502799",
    "end": "1504799"
  },
  {
    "text": "using ray or any help out with",
    "start": "1504799",
    "end": "1506400"
  },
  {
    "text": "um with uh with any any issues you run",
    "start": "1506400",
    "end": "1509039"
  },
  {
    "text": "into with rey so you can check out the",
    "start": "1509039",
    "end": "1510720"
  },
  {
    "text": "repositories on github for ray",
    "start": "1510720",
    "end": "1512799"
  },
  {
    "text": "orvad lighting and hugging fish",
    "start": "1512799",
    "end": "1514400"
  },
  {
    "text": "transformers and also join our ray",
    "start": "1514400",
    "end": "1516480"
  },
  {
    "text": "discussion forum at discuss.ray.io",
    "start": "1516480",
    "end": "1520720"
  },
  {
    "text": "so thank you for attending this",
    "start": "1521520",
    "end": "1523039"
  },
  {
    "text": "presentation and",
    "start": "1523039",
    "end": "1524799"
  },
  {
    "text": "hope you enjoy the rest of the race",
    "start": "1524799",
    "end": "1526840"
  },
  {
    "text": "summits",
    "start": "1526840",
    "end": "1529840"
  }
]
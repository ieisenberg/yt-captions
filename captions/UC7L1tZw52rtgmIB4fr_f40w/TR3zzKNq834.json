[
  {
    "text": "okay hello everyone really happy to be",
    "start": "3780",
    "end": "6660"
  },
  {
    "text": "here at race Summit 2023 and I'm excited",
    "start": "6660",
    "end": "9960"
  },
  {
    "text": "to showcase our work with Ray",
    "start": "9960",
    "end": "12300"
  },
  {
    "text": "so my name is harshit and I'm working as",
    "start": "12300",
    "end": "14580"
  },
  {
    "text": "a senior data scientist at LexisNexis",
    "start": "14580",
    "end": "16980"
  },
  {
    "text": "and today I'll be sharing some insights",
    "start": "16980",
    "end": "19260"
  },
  {
    "text": "on how we are using Ray to scale our",
    "start": "19260",
    "end": "21180"
  },
  {
    "text": "offline batch inference ml Pipelines",
    "start": "21180",
    "end": "24779"
  },
  {
    "text": "so this is the agenda for today",
    "start": "24779",
    "end": "28279"
  },
  {
    "text": "so a bit about our company Lexus Nexus",
    "start": "31260",
    "end": "33719"
  },
  {
    "text": "so Lexus Nexus is a legal tech company",
    "start": "33719",
    "end": "36000"
  },
  {
    "text": "that enables lawyers litigators",
    "start": "36000",
    "end": "38880"
  },
  {
    "text": "attorneys all around the globe to",
    "start": "38880",
    "end": "40980"
  },
  {
    "text": "conduct in-depth research and Analysis",
    "start": "40980",
    "end": "43260"
  },
  {
    "text": "in order to win cases",
    "start": "43260",
    "end": "45360"
  },
  {
    "text": "so our products at Lexus",
    "start": "45360",
    "end": "48059"
  },
  {
    "text": "help lawyers in efficiently conducting",
    "start": "48059",
    "end": "50100"
  },
  {
    "text": "their research by providing the data and",
    "start": "50100",
    "end": "52559"
  },
  {
    "text": "insights they need",
    "start": "52559",
    "end": "55399"
  },
  {
    "text": "next I'll talk a little bit about the",
    "start": "57120",
    "end": "58800"
  },
  {
    "text": "data science landscape at LexisNexis",
    "start": "58800",
    "end": "61739"
  },
  {
    "text": "so we have access to huge amount of",
    "start": "61739",
    "end": "64500"
  },
  {
    "text": "legal data which is mostly in",
    "start": "64500",
    "end": "67380"
  },
  {
    "text": "unstructured format and we receive from",
    "start": "67380",
    "end": "69180"
  },
  {
    "text": "variety of source sources so to put some",
    "start": "69180",
    "end": "72060"
  },
  {
    "text": "numbers we have around 40 million",
    "start": "72060",
    "end": "74659"
  },
  {
    "text": "documents related to law firms where the",
    "start": "74659",
    "end": "77700"
  },
  {
    "text": "legal arguments are crafted around 250",
    "start": "77700",
    "end": "81119"
  },
  {
    "text": "million code related documents where the",
    "start": "81119",
    "end": "83939"
  },
  {
    "text": "outcomes are provided and the legal",
    "start": "83939",
    "end": "85680"
  },
  {
    "text": "arguments are tested and finally we have",
    "start": "85680",
    "end": "88619"
  },
  {
    "text": "about 1.5 billion documents from vendors",
    "start": "88619",
    "end": "91979"
  },
  {
    "text": "and these are mostly third-party",
    "start": "91979",
    "end": "94619"
  },
  {
    "text": "external analysts and news publishers",
    "start": "94619",
    "end": "97500"
  },
  {
    "text": "so having the access to huge amount of",
    "start": "97500",
    "end": "100380"
  },
  {
    "text": "data it allows us to run a lot of",
    "start": "100380",
    "end": "102479"
  },
  {
    "text": "inferences and do machine learning on it",
    "start": "102479",
    "end": "105840"
  },
  {
    "text": "a few years ago we recently developed a",
    "start": "105840",
    "end": "107939"
  },
  {
    "text": "legal Knowledge Graph on AWS Neptune",
    "start": "107939",
    "end": "110399"
  },
  {
    "text": "that allowed allowed us to uncover",
    "start": "110399",
    "end": "113159"
  },
  {
    "text": "complex relationships between different",
    "start": "113159",
    "end": "115200"
  },
  {
    "text": "legal entities like plaintiffs judges",
    "start": "115200",
    "end": "117960"
  },
  {
    "text": "courts and law firms and in that way we",
    "start": "117960",
    "end": "120780"
  },
  {
    "text": "were able to provide better inferences",
    "start": "120780",
    "end": "122340"
  },
  {
    "text": "and better insights to our customers",
    "start": "122340",
    "end": "123960"
  },
  {
    "text": "like lawyers",
    "start": "123960",
    "end": "125460"
  },
  {
    "text": "machine learning is widely used across",
    "start": "125460",
    "end": "127500"
  },
  {
    "text": "Lexus Nexus across many domains and this",
    "start": "127500",
    "end": "130979"
  },
  {
    "text": "talk is about one such machine learning",
    "start": "130979",
    "end": "133379"
  },
  {
    "text": "use case and all of these things combine",
    "start": "133379",
    "end": "135599"
  },
  {
    "text": "they power our legal products at Lexis",
    "start": "135599",
    "end": "139700"
  },
  {
    "text": "so next I'll be explaining about our ml",
    "start": "141599",
    "end": "143879"
  },
  {
    "text": "use case uh the business aspect of it",
    "start": "143879",
    "end": "145800"
  },
  {
    "text": "the expert witness profiling so some of",
    "start": "145800",
    "end": "148140"
  },
  {
    "text": "you might already be aware that",
    "start": "148140",
    "end": "149459"
  },
  {
    "text": "attorneys or lawyers often need to",
    "start": "149459",
    "end": "151860"
  },
  {
    "text": "recruit expert Witnesses so that they",
    "start": "151860",
    "end": "155220"
  },
  {
    "text": "can evaluate claims and testifying codes",
    "start": "155220",
    "end": "158520"
  },
  {
    "text": "hiring the right expert witness can be",
    "start": "158520",
    "end": "161700"
  },
  {
    "text": "an important uh can play an important",
    "start": "161700",
    "end": "164220"
  },
  {
    "text": "role in determining the outcome of your",
    "start": "164220",
    "end": "165900"
  },
  {
    "text": "case they can make your case more",
    "start": "165900",
    "end": "167400"
  },
  {
    "text": "stronger and they can actually increase",
    "start": "167400",
    "end": "169560"
  },
  {
    "text": "the probability uh for a lawyer to win",
    "start": "169560",
    "end": "173280"
  },
  {
    "text": "that case so it's very important that",
    "start": "173280",
    "end": "175200"
  },
  {
    "text": "attorneys hire the right expert witness",
    "start": "175200",
    "end": "177840"
  },
  {
    "text": "for their particular case",
    "start": "177840",
    "end": "179459"
  },
  {
    "text": "so how do they do that so in modern day",
    "start": "179459",
    "end": "182099"
  },
  {
    "text": "an attorney has access to hundreds of",
    "start": "182099",
    "end": "184440"
  },
  {
    "text": "experts spread across variety of fields",
    "start": "184440",
    "end": "187560"
  },
  {
    "text": "so if they have to do it uh let's say in",
    "start": "187560",
    "end": "190500"
  },
  {
    "text": "a traditional manner they will have to",
    "start": "190500",
    "end": "192120"
  },
  {
    "text": "scan through or read through a lot of",
    "start": "192120",
    "end": "194400"
  },
  {
    "text": "legal documents and these documents and",
    "start": "194400",
    "end": "198540"
  },
  {
    "text": "they need to also know what particular",
    "start": "198540",
    "end": "201000"
  },
  {
    "text": "expert can comment on for that",
    "start": "201000",
    "end": "202860"
  },
  {
    "text": "particular case or what are the topics",
    "start": "202860",
    "end": "204959"
  },
  {
    "text": "and what are the issues they have",
    "start": "204959",
    "end": "206280"
  },
  {
    "text": "commented on in the past so that they",
    "start": "206280",
    "end": "209459"
  },
  {
    "text": "can better evaluate that particular",
    "start": "209459",
    "end": "211680"
  },
  {
    "text": "expert witness whether they would be",
    "start": "211680",
    "end": "213300"
  },
  {
    "text": "good for this case or not",
    "start": "213300",
    "end": "215519"
  },
  {
    "text": "so uh but going but doing this manually",
    "start": "215519",
    "end": "218879"
  },
  {
    "text": "would be like a lot of time taking",
    "start": "218879",
    "end": "220379"
  },
  {
    "text": "process and very not not efficient so we",
    "start": "220379",
    "end": "223620"
  },
  {
    "text": "frame this uh problem into a machine",
    "start": "223620",
    "end": "226379"
  },
  {
    "text": "learning use case where",
    "start": "226379",
    "end": "228599"
  },
  {
    "text": "we built a automated key for instruction",
    "start": "228599",
    "end": "230640"
  },
  {
    "text": "Pipeline and a clustering pipeline so",
    "start": "230640",
    "end": "233340"
  },
  {
    "text": "that uh attorneys can get the data and",
    "start": "233340",
    "end": "236819"
  },
  {
    "text": "insights they need in a very condensed",
    "start": "236819",
    "end": "239280"
  },
  {
    "text": "and very refined manner so this is the",
    "start": "239280",
    "end": "241319"
  },
  {
    "text": "snapshot uh of our one of the flagship",
    "start": "241319",
    "end": "243900"
  },
  {
    "text": "products are called context and this is",
    "start": "243900",
    "end": "246239"
  },
  {
    "text": "how an attorney would uh see this a",
    "start": "246239",
    "end": "249180"
  },
  {
    "text": "screen on their laptops for example if",
    "start": "249180",
    "end": "250799"
  },
  {
    "text": "they are searching for an expert related",
    "start": "250799",
    "end": "252659"
  },
  {
    "text": "to a medical case let's say two parties",
    "start": "252659",
    "end": "255599"
  },
  {
    "text": "are involved in a in a in a in a car",
    "start": "255599",
    "end": "258900"
  },
  {
    "text": "accident and uh and the parties need to",
    "start": "258900",
    "end": "261600"
  },
  {
    "text": "hire expert Witnesses so that they can",
    "start": "261600",
    "end": "263160"
  },
  {
    "text": "make their case more stronger so in",
    "start": "263160",
    "end": "265320"
  },
  {
    "text": "order to search for Relevant experts uh",
    "start": "265320",
    "end": "268080"
  },
  {
    "text": "in this case they'll need to search",
    "start": "268080",
    "end": "270060"
  },
  {
    "text": "through many uh doctors and specifically",
    "start": "270060",
    "end": "273979"
  },
  {
    "text": "uh you know for in in which particular",
    "start": "273979",
    "end": "278040"
  },
  {
    "text": "fee in which particular field they are",
    "start": "278040",
    "end": "280979"
  },
  {
    "text": "experiencing so as you can see the",
    "start": "280979",
    "end": "283259"
  },
  {
    "text": "attorney can just open this up the",
    "start": "283259",
    "end": "285240"
  },
  {
    "text": "profile of the attorney of the expert",
    "start": "285240",
    "end": "287340"
  },
  {
    "text": "and they'll be able to see okay",
    "start": "287340",
    "end": "289940"
  },
  {
    "text": "for example in this case this person is",
    "start": "289940",
    "end": "292740"
  },
  {
    "text": "an expert in neurological surgery and if",
    "start": "292740",
    "end": "296100"
  },
  {
    "text": "you pay attention to the most discussed",
    "start": "296100",
    "end": "298440"
  },
  {
    "text": "facts and subjects you can see topics",
    "start": "298440",
    "end": "300780"
  },
  {
    "text": "and issues uh this particular expert has",
    "start": "300780",
    "end": "304320"
  },
  {
    "text": "commented in the past for example this",
    "start": "304320",
    "end": "306600"
  },
  {
    "text": "expert can talk about MRI scans you know",
    "start": "306600",
    "end": "310320"
  },
  {
    "text": "function physical therapy and medical",
    "start": "310320",
    "end": "313259"
  },
  {
    "text": "malpractice as well so they have several",
    "start": "313259",
    "end": "315500"
  },
  {
    "text": "several topics that this expert in",
    "start": "315500",
    "end": "317880"
  },
  {
    "text": "comment on and infinite only feels like",
    "start": "317880",
    "end": "320400"
  },
  {
    "text": "okay this is this seems okay and this",
    "start": "320400",
    "end": "324060"
  },
  {
    "text": "expert is worth more",
    "start": "324060",
    "end": "326539"
  },
  {
    "text": "exploration and so that they can click",
    "start": "326539",
    "end": "328860"
  },
  {
    "text": "on the topic and on the side they would",
    "start": "328860",
    "end": "331380"
  },
  {
    "text": "see a relevant document uh that it would",
    "start": "331380",
    "end": "335160"
  },
  {
    "text": "open up and we will highlight the",
    "start": "335160",
    "end": "337080"
  },
  {
    "text": "paragraph which in which that topic was",
    "start": "337080",
    "end": "339180"
  },
  {
    "text": "mentioned so attorneys can proceed in a",
    "start": "339180",
    "end": "342240"
  },
  {
    "text": "very grandular fashion fashion and they",
    "start": "342240",
    "end": "344280"
  },
  {
    "text": "would this would help us in you know",
    "start": "344280",
    "end": "346560"
  },
  {
    "text": "increasing their efficiency in searching",
    "start": "346560",
    "end": "349860"
  },
  {
    "text": "for experts",
    "start": "349860",
    "end": "351180"
  },
  {
    "text": "so that was the basic uh general idea",
    "start": "351180",
    "end": "354120"
  },
  {
    "text": "behind the use case and this is the high",
    "start": "354120",
    "end": "358199"
  },
  {
    "text": "level overview of our architecture",
    "start": "358199",
    "end": "360320"
  },
  {
    "text": "pipeline it looks like",
    "start": "360320",
    "end": "362699"
  },
  {
    "text": "so we have data Lake and many",
    "start": "362699",
    "end": "365160"
  },
  {
    "text": "engineering teams I'd like to subscribe",
    "start": "365160",
    "end": "366660"
  },
  {
    "text": "to this and our team responsible for",
    "start": "366660",
    "end": "368580"
  },
  {
    "text": "this machine learning use case we run a",
    "start": "368580",
    "end": "370680"
  },
  {
    "text": "daily job that pulls the relevant data",
    "start": "370680",
    "end": "372720"
  },
  {
    "text": "from the data Lake and store in S3 we",
    "start": "372720",
    "end": "375360"
  },
  {
    "text": "run data cleaning and pre-processing on",
    "start": "375360",
    "end": "377400"
  },
  {
    "text": "AWS EMR and using the spark framework",
    "start": "377400",
    "end": "381479"
  },
  {
    "text": "and the output of this",
    "start": "381479",
    "end": "384319"
  },
  {
    "text": "is stored in S3 as a high quality data",
    "start": "384319",
    "end": "387360"
  },
  {
    "text": "set which is an input to our further",
    "start": "387360",
    "end": "389340"
  },
  {
    "text": "machine learning workloads",
    "start": "389340",
    "end": "391080"
  },
  {
    "text": "so next uh so earlier we were using",
    "start": "391080",
    "end": "393600"
  },
  {
    "text": "sagemaker processing jobs to run our",
    "start": "393600",
    "end": "397080"
  },
  {
    "text": "four machine learning workloads that",
    "start": "397080",
    "end": "399060"
  },
  {
    "text": "builds up our entire pipeline so I'll",
    "start": "399060",
    "end": "401460"
  },
  {
    "text": "talk a little bit about these ml",
    "start": "401460",
    "end": "403080"
  },
  {
    "text": "workloads too so that you guys have a",
    "start": "403080",
    "end": "404880"
  },
  {
    "text": "flare of what they are about so our",
    "start": "404880",
    "end": "407100"
  },
  {
    "text": "first ml workload is key phrase",
    "start": "407100",
    "end": "409259"
  },
  {
    "text": "extraction and ranking it uses a large",
    "start": "409259",
    "end": "412319"
  },
  {
    "text": "pre-trained model from Spacey we are",
    "start": "412319",
    "end": "414780"
  },
  {
    "text": "also using a third-party library for",
    "start": "414780",
    "end": "416580"
  },
  {
    "text": "ranking and",
    "start": "416580",
    "end": "418080"
  },
  {
    "text": "we have also defined a custom scrubber",
    "start": "418080",
    "end": "420120"
  },
  {
    "text": "function",
    "start": "420120",
    "end": "420960"
  },
  {
    "text": "followed by that we have a data",
    "start": "420960",
    "end": "422520"
  },
  {
    "text": "transformation step in which we",
    "start": "422520",
    "end": "424199"
  },
  {
    "text": "incorporate a legal domain knowledge and",
    "start": "424199",
    "end": "426300"
  },
  {
    "text": "some business logic",
    "start": "426300",
    "end": "427860"
  },
  {
    "text": "and Then followed by that we have",
    "start": "427860",
    "end": "429600"
  },
  {
    "text": "embedding base key phrase filtering step",
    "start": "429600",
    "end": "432060"
  },
  {
    "text": "in which we use sentence transform model",
    "start": "432060",
    "end": "434520"
  },
  {
    "text": "from hugging phase follow that bad",
    "start": "434520",
    "end": "436800"
  },
  {
    "text": "followed uh by this step we have a",
    "start": "436800",
    "end": "439860"
  },
  {
    "text": "clustering key phrases in which we use",
    "start": "439860",
    "end": "441419"
  },
  {
    "text": "hierarchical clustering from cycle learn",
    "start": "441419",
    "end": "443580"
  },
  {
    "text": "library and the output is stored in S3",
    "start": "443580",
    "end": "445560"
  },
  {
    "text": "bucket",
    "start": "445560",
    "end": "447240"
  },
  {
    "text": "so there are some problems uh with the",
    "start": "447240",
    "end": "450240"
  },
  {
    "text": "existing pipeline so we observed uh low",
    "start": "450240",
    "end": "453599"
  },
  {
    "text": "CPU CPU utilization across many nodes in",
    "start": "453599",
    "end": "456360"
  },
  {
    "text": "the sagemaker uh pre-processing jobs",
    "start": "456360",
    "end": "459960"
  },
  {
    "text": "also inefficient data transfer between",
    "start": "459960",
    "end": "462000"
  },
  {
    "text": "SC bucket and CPU RAM and no matter how",
    "start": "462000",
    "end": "465300"
  },
  {
    "text": "many instances you add up in your",
    "start": "465300",
    "end": "467099"
  },
  {
    "text": "sagemaker processing job we're always",
    "start": "467099",
    "end": "469860"
  },
  {
    "text": "limited by the API rate limit which is",
    "start": "469860",
    "end": "472800"
  },
  {
    "text": "100 MB Max",
    "start": "472800",
    "end": "474840"
  },
  {
    "text": "and although sagemaker provides",
    "start": "474840",
    "end": "478139"
  },
  {
    "text": "distributed training libraries but they",
    "start": "478139",
    "end": "480539"
  },
  {
    "text": "don't natively support uh distributed",
    "start": "480539",
    "end": "482880"
  },
  {
    "text": "execution of tasks and uh",
    "start": "482880",
    "end": "485660"
  },
  {
    "text": "in like natively so if they are on a",
    "start": "485660",
    "end": "488940"
  },
  {
    "text": "distributed Library Distributing",
    "start": "488940",
    "end": "490440"
  },
  {
    "text": "logarithms you can use that but for",
    "start": "490440",
    "end": "491880"
  },
  {
    "text": "custom transformation uh sagemaker",
    "start": "491880",
    "end": "494460"
  },
  {
    "text": "doesn't provide easy to use apis so we",
    "start": "494460",
    "end": "496919"
  },
  {
    "text": "found it hard to assign custom number of",
    "start": "496919",
    "end": "498539"
  },
  {
    "text": "workers per model or compute resources",
    "start": "498539",
    "end": "502340"
  },
  {
    "text": "or to assign custom resources to more",
    "start": "502340",
    "end": "505440"
  },
  {
    "text": "granular tasks in an ml workload",
    "start": "505440",
    "end": "508860"
  },
  {
    "text": "moving from local laptop to a production",
    "start": "508860",
    "end": "512159"
  },
  {
    "text": "environment was also difficult and it",
    "start": "512159",
    "end": "514440"
  },
  {
    "text": "required several iterations",
    "start": "514440",
    "end": "516360"
  },
  {
    "text": "so all of the SE limitations combined",
    "start": "516360",
    "end": "518339"
  },
  {
    "text": "led to low throughput of our entire",
    "start": "518339",
    "end": "520020"
  },
  {
    "text": "pipeline longer run times and high cost",
    "start": "520020",
    "end": "524779"
  },
  {
    "text": "so we decided to experiment with Ray in",
    "start": "525540",
    "end": "528180"
  },
  {
    "text": "order to scale this offline batch",
    "start": "528180",
    "end": "529500"
  },
  {
    "text": "inference Pipeline and more specifically",
    "start": "529500",
    "end": "531959"
  },
  {
    "text": "Ray data API",
    "start": "531959",
    "end": "534920"
  },
  {
    "text": "so this is the updated architecture",
    "start": "535260",
    "end": "537779"
  },
  {
    "text": "diagram of an uh of our pipeline as you",
    "start": "537779",
    "end": "541320"
  },
  {
    "text": "can see we have used Ray for Last Mile",
    "start": "541320",
    "end": "543720"
  },
  {
    "text": "processing and you can see from this",
    "start": "543720",
    "end": "546000"
  },
  {
    "text": "diagram that the first part of the",
    "start": "546000",
    "end": "547560"
  },
  {
    "text": "pipeline looks the same we are using",
    "start": "547560",
    "end": "550740"
  },
  {
    "text": "spark for data cleaning and",
    "start": "550740",
    "end": "552600"
  },
  {
    "text": "pre-processing and storing the data the",
    "start": "552600",
    "end": "555779"
  },
  {
    "text": "high quality data set in SC bucket",
    "start": "555779",
    "end": "559200"
  },
  {
    "text": "in order to reply the day cluster we use",
    "start": "559200",
    "end": "561120"
  },
  {
    "text": "very simple Ray launcher API uh it's",
    "start": "561120",
    "end": "565019"
  },
  {
    "text": "just very easy to use and we could",
    "start": "565019",
    "end": "566760"
  },
  {
    "text": "select the instance type and the number",
    "start": "566760",
    "end": "568260"
  },
  {
    "text": "of instances for our custom workloads",
    "start": "568260",
    "end": "570779"
  },
  {
    "text": "and we have used Ray data for these four",
    "start": "570779",
    "end": "574200"
  },
  {
    "text": "ml workloads that basically Define our",
    "start": "574200",
    "end": "576959"
  },
  {
    "text": "entire ml pipeline",
    "start": "576959",
    "end": "578880"
  },
  {
    "text": "we started with uh so we use the ray",
    "start": "578880",
    "end": "581940"
  },
  {
    "text": "data API for ingesting the high quality",
    "start": "581940",
    "end": "584399"
  },
  {
    "text": "data sets stored in SC and which are",
    "start": "584399",
    "end": "587040"
  },
  {
    "text": "read as a ray data set and they are",
    "start": "587040",
    "end": "589500"
  },
  {
    "text": "represented as Ray blocks and each block",
    "start": "589500",
    "end": "592440"
  },
  {
    "text": "is stored somewhere in the cluster",
    "start": "592440",
    "end": "595620"
  },
  {
    "text": "moving ahead um",
    "start": "595620",
    "end": "597720"
  },
  {
    "text": "for example in the case of key for",
    "start": "597720",
    "end": "599459"
  },
  {
    "text": "instruction and ranking we use the actor",
    "start": "599459",
    "end": "601380"
  },
  {
    "text": "cooling strategy as we are using the",
    "start": "601380",
    "end": "603839"
  },
  {
    "text": "large pre-trained model from Spacey and",
    "start": "603839",
    "end": "606000"
  },
  {
    "text": "it's expensive to set up",
    "start": "606000",
    "end": "607680"
  },
  {
    "text": "and yeah so as you can see uh in the",
    "start": "607680",
    "end": "610560"
  },
  {
    "text": "case of Ray it creates multiple replicas",
    "start": "610560",
    "end": "612839"
  },
  {
    "text": "of model in the cluster and all of these",
    "start": "612839",
    "end": "615180"
  },
  {
    "text": "uh models they work in parallel and they",
    "start": "615180",
    "end": "618839"
  },
  {
    "text": "do transformation on each block uh in",
    "start": "618839",
    "end": "620880"
  },
  {
    "text": "parallel thereby reducing the runtime",
    "start": "620880",
    "end": "624600"
  },
  {
    "text": "Follow That by uh for uh after that we",
    "start": "624600",
    "end": "627180"
  },
  {
    "text": "have data transformation task in which",
    "start": "627180",
    "end": "629640"
  },
  {
    "text": "we use Ray task as a default compute",
    "start": "629640",
    "end": "633540"
  },
  {
    "text": "strategy and similarly we use actor put",
    "start": "633540",
    "end": "636300"
  },
  {
    "text": "strategy for",
    "start": "636300",
    "end": "637880"
  },
  {
    "text": "embedding base key phrase filtering",
    "start": "637880",
    "end": "639839"
  },
  {
    "text": "which uses the sentence Transformer",
    "start": "639839",
    "end": "642240"
  },
  {
    "text": "model from hugging face",
    "start": "642240",
    "end": "643880"
  },
  {
    "text": "similarly we have actor cooling strategy",
    "start": "643880",
    "end": "646560"
  },
  {
    "text": "for clustering key phrases that uses",
    "start": "646560",
    "end": "648779"
  },
  {
    "text": "hierarchy clustering model from the",
    "start": "648779",
    "end": "651060"
  },
  {
    "text": "scikit-learns library",
    "start": "651060",
    "end": "654060"
  },
  {
    "text": "and find and we have the predictions uh",
    "start": "654060",
    "end": "656760"
  },
  {
    "text": "inferences and they are these are again",
    "start": "656760",
    "end": "658920"
  },
  {
    "text": "stored in S3 bucket",
    "start": "658920",
    "end": "662060"
  },
  {
    "text": "so next I'd like to talk about the",
    "start": "662399",
    "end": "664260"
  },
  {
    "text": "results that we observed uh uh and",
    "start": "664260",
    "end": "666899"
  },
  {
    "text": "comparison analysis between Ray and AWS",
    "start": "666899",
    "end": "669540"
  },
  {
    "text": "sagemaker",
    "start": "669540",
    "end": "672060"
  },
  {
    "text": "so we saw we saw significant reduction",
    "start": "672060",
    "end": "674760"
  },
  {
    "text": "in our ml workload runtimes so these are",
    "start": "674760",
    "end": "677399"
  },
  {
    "text": "some of the statistics that we observed",
    "start": "677399",
    "end": "679860"
  },
  {
    "text": "so in the case of key phrases traction",
    "start": "679860",
    "end": "681899"
  },
  {
    "text": "and ranking we saw uh Forex uh",
    "start": "681899",
    "end": "686640"
  },
  {
    "text": "Forex return for example gray performed",
    "start": "686640",
    "end": "689220"
  },
  {
    "text": "four times better than as compared to",
    "start": "689220",
    "end": "691380"
  },
  {
    "text": "Sage Mega pre-processing job data",
    "start": "691380",
    "end": "693420"
  },
  {
    "text": "transformation performed 50 next better",
    "start": "693420",
    "end": "695300"
  },
  {
    "text": "embedding base key phrase filtering",
    "start": "695300",
    "end": "697320"
  },
  {
    "text": "performed around 20 times better and",
    "start": "697320",
    "end": "699600"
  },
  {
    "text": "hierarchy clustering performed around",
    "start": "699600",
    "end": "700980"
  },
  {
    "text": "10.5 times better",
    "start": "700980",
    "end": "704040"
  },
  {
    "text": "in addition to solving our current",
    "start": "704040",
    "end": "705779"
  },
  {
    "text": "limitations like uh reducing the runtime",
    "start": "705779",
    "end": "709200"
  },
  {
    "text": "and Maxima maximizing our CPU usage it",
    "start": "709200",
    "end": "713459"
  },
  {
    "text": "was relatively easy to scale ml",
    "start": "713459",
    "end": "716339"
  },
  {
    "text": "workloads in a distributed fashion for",
    "start": "716339",
    "end": "718560"
  },
  {
    "text": "example it's easy to customize compute",
    "start": "718560",
    "end": "721260"
  },
  {
    "text": "resource assignments per task in ml",
    "start": "721260",
    "end": "724079"
  },
  {
    "text": "workload and it leads to better CPU",
    "start": "724079",
    "end": "726240"
  },
  {
    "text": "utilization and prevents um errors",
    "start": "726240",
    "end": "728820"
  },
  {
    "text": "and scaling from local to production uh",
    "start": "728820",
    "end": "731760"
  },
  {
    "text": "it was very easy for a data scientist",
    "start": "731760",
    "end": "734339"
  },
  {
    "text": "and and building a distributed pipeline",
    "start": "734339",
    "end": "737519"
  },
  {
    "text": "the ray handles very python dependencies",
    "start": "737519",
    "end": "740339"
  },
  {
    "text": "very seamlessly",
    "start": "740339",
    "end": "743240"
  },
  {
    "text": "so this is the uh little uh code snippet",
    "start": "743339",
    "end": "746820"
  },
  {
    "text": "uh to show how Ray handles uh",
    "start": "746820",
    "end": "750540"
  },
  {
    "text": "many things in a very easy it is a",
    "start": "750540",
    "end": "753300"
  },
  {
    "text": "fashion so that it allows us to scale",
    "start": "753300",
    "end": "755399"
  },
  {
    "text": "pipelines for example in this case you",
    "start": "755399",
    "end": "757620"
  },
  {
    "text": "can see we have a key phrase tracker",
    "start": "757620",
    "end": "759540"
  },
  {
    "text": "class and we are using a third-party",
    "start": "759540",
    "end": "761700"
  },
  {
    "text": "Library Pi text rank we are also",
    "start": "761700",
    "end": "764399"
  },
  {
    "text": "importing a large model from Spacey we",
    "start": "764399",
    "end": "768660"
  },
  {
    "text": "have also defined our custom scrubber",
    "start": "768660",
    "end": "770459"
  },
  {
    "text": "function so that we don't want our",
    "start": "770459",
    "end": "774420"
  },
  {
    "text": "python algorithm to discuss certain",
    "start": "774420",
    "end": "776579"
  },
  {
    "text": "entities that we are not interested in",
    "start": "776579",
    "end": "778500"
  },
  {
    "text": "and you can see we are registering us",
    "start": "778500",
    "end": "780600"
  },
  {
    "text": "custom scrubber function in Spacey and",
    "start": "780600",
    "end": "784019"
  },
  {
    "text": "adding it to the Spacey pipeline so it",
    "start": "784019",
    "end": "786839"
  },
  {
    "text": "requires really minimal code changes in",
    "start": "786839",
    "end": "789000"
  },
  {
    "text": "handling external dependencies",
    "start": "789000",
    "end": "792240"
  },
  {
    "text": "and if you look below uh we have also",
    "start": "792240",
    "end": "795800"
  },
  {
    "text": "divided the uh two tasks so that we can",
    "start": "795800",
    "end": "800220"
  },
  {
    "text": "assign custom resource assignments",
    "start": "800220",
    "end": "801720"
  },
  {
    "text": "depending upon the type of custom",
    "start": "801720",
    "end": "802980"
  },
  {
    "text": "workload we have so for example in the",
    "start": "802980",
    "end": "805800"
  },
  {
    "text": "post processing step we are using array",
    "start": "805800",
    "end": "807720"
  },
  {
    "text": "task for the uh for the default",
    "start": "807720",
    "end": "810120"
  },
  {
    "text": "Computing strategy and actor tool",
    "start": "810120",
    "end": "811920"
  },
  {
    "text": "strategy for doing inferences with",
    "start": "811920",
    "end": "814019"
  },
  {
    "text": "Spacey model",
    "start": "814019",
    "end": "815940"
  },
  {
    "text": "so that was our experimentation with Ray",
    "start": "815940",
    "end": "819000"
  },
  {
    "text": "uh for scaling our ml workload we are",
    "start": "819000",
    "end": "821220"
  },
  {
    "text": "just getting started with Ray and we",
    "start": "821220",
    "end": "823139"
  },
  {
    "text": "also hope to adopt other ml workloads at",
    "start": "823139",
    "end": "825839"
  },
  {
    "text": "Lexus thank you so much everyone",
    "start": "825839",
    "end": "829639"
  }
]
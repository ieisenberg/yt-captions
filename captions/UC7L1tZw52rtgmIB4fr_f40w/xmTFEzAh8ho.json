[
  {
    "text": "so thanks for coming I know uh it's the second day and it's late and we're the",
    "start": "3120",
    "end": "8480"
  },
  {
    "text": "last thing that stands you between you and beer or dinner or whatever so",
    "start": "8480",
    "end": "13880"
  },
  {
    "text": "hopefully we'll be able to make this interesting right um cool so um anybody know what this",
    "start": "13880",
    "end": "22680"
  },
  {
    "text": "what this building issh khif Bush Khalifa the bush is the world's tallest",
    "start": "22680",
    "end": "27880"
  },
  {
    "text": "building today in Dubai it stands at around 2,700 ft right the Spire is",
    "start": "27880",
    "end": "33559"
  },
  {
    "text": "visible from supposedly 60 Mi away um it's got both the world's highest",
    "start": "33559",
    "end": "39680"
  },
  {
    "text": "nightclub and the world's highest mosque right so this building is so tall the",
    "start": "39680",
    "end": "44920"
  },
  {
    "text": "top is 20Â° cooler than the bottom all right and so this is a",
    "start": "44920",
    "end": "50840"
  },
  {
    "text": "pretty I don't know if effing amazing feed of human engineering right so now",
    "start": "50840",
    "end": "57960"
  },
  {
    "text": "we know that to build tall you got go deep with the foundation right the Burge is no exception that concrete slab",
    "start": "57960",
    "end": "65040"
  },
  {
    "text": "Foundation you see there it's extremely solid it's more than 12 foot thick um",
    "start": "65040",
    "end": "70240"
  },
  {
    "text": "and it's huge right and that might be enough in other places but remember",
    "start": "70240",
    "end": "75400"
  },
  {
    "text": "Dubai is a desert and sand is super soft so in addition to that concrete",
    "start": "75400",
    "end": "81680"
  },
  {
    "text": "slab there are um like 190 some what do they call hanging piles that like",
    "start": "81680",
    "end": "87960"
  },
  {
    "text": "basically long steel rods that drive into the ground more than 140 ft uh so",
    "start": "87960",
    "end": "93720"
  },
  {
    "text": "together with the slab it can provide enough support for about",
    "start": "93720",
    "end": "99200"
  },
  {
    "text": "400,000 tons of a building right and that might be enough in other places but",
    "start": "99200",
    "end": "104920"
  },
  {
    "text": "Dubai is both in the desert and by the Sea so at a depth of more than like 100",
    "start": "104920",
    "end": "110119"
  },
  {
    "text": "feet Salty Sea water seeps into the ground um and it's going to corrode the metal piles so not only do you need a",
    "start": "110119",
    "end": "117079"
  },
  {
    "text": "massive amount of concrete and steel piles there needs to be a constant flow of electricity throughout the foundation",
    "start": "117079",
    "end": "123520"
  },
  {
    "text": "to neutralize the ions uh from the seawater um and",
    "start": "123520",
    "end": "130119"
  },
  {
    "text": "so it's only when you put all those three things together can you successfully put the burs on top of that",
    "start": "130120",
    "end": "138120"
  },
  {
    "text": "and if you're not paying attention to the foundation enough you you might end up with the leaning tower of if you said",
    "start": "138120",
    "end": "146000"
  },
  {
    "text": "Pisa you'd be wrong uh I'm I'm talking about the Leaning Tower of San Francisco which you might recognize as the",
    "start": "146000",
    "end": "152400"
  },
  {
    "text": "Millennium tower on Market Street just nearby so this Tower right opened in 2009 and it's been sinking and tilting",
    "start": "152400",
    "end": "159640"
  },
  {
    "text": "since uh I people have poured like hundreds of millions of dollars in",
    "start": "159640",
    "end": "164720"
  },
  {
    "text": "repairs there like huge drops in property value um residence report like",
    "start": "164720",
    "end": "170239"
  },
  {
    "text": "crack cracking sounds and uh window noises during high wind and like",
    "start": "170239",
    "end": "175879"
  },
  {
    "text": "apparently today if you open the wrong if you open your window at the wrong time time of day you get fined like",
    "start": "175879",
    "end": "181200"
  },
  {
    "text": "$10,000 by the HOA or something like that right so um foundations foundations",
    "start": "181200",
    "end": "187239"
  },
  {
    "text": "are important but uh we're not here to talk about architecture we're we're here",
    "start": "187239",
    "end": "192400"
  },
  {
    "text": "to talk about machine learning and Ai and the foundation for machine learning in AI is",
    "start": "192400",
    "end": "197799"
  },
  {
    "text": "data so hello my name is Chong CEO and co-founder of Lan CB uh we're the",
    "start": "197799",
    "end": "202840"
  },
  {
    "text": "database for multimodel AI so from rag to model training U Lancy makes massive",
    "start": "202840",
    "end": "208720"
  },
  {
    "text": "scale AI not just possible but easy I was one of the original contributors to the pandas Library um and I've been",
    "start": "208720",
    "end": "215840"
  },
  {
    "text": "building data tools for almost two decades my co-founder Le here uh was a core contributor to Hadoop uh which",
    "start": "215840",
    "end": "222640"
  },
  {
    "text": "looks like some of you might have used and um LED ml platform I can't see who who is who",
    "start": "222640",
    "end": "229760"
  },
  {
    "text": "because the there's like two giant spotlights shining into my eye um and he let ml platforms at cruise for",
    "start": "229760",
    "end": "236360"
  },
  {
    "text": "automation for years right so our team has contributors from do Pache Aro Delta",
    "start": "236360",
    "end": "241959"
  },
  {
    "text": "many other important projects in the data ecosystem so I think it's no exaggerating to say no exaggeration to",
    "start": "241959",
    "end": "248200"
  },
  {
    "text": "say if you've kind of touched data in the past like decade or so you've used projects that we made um so why does AI",
    "start": "248200",
    "end": "256639"
  },
  {
    "text": "need New Foundations well first it's the size AI data is much bigger than uh",
    "start": "256639",
    "end": "262360"
  },
  {
    "text": "tabul data right so if you look at tpch typical database table is around 145 bytes per row if you add embeddings to",
    "start": "262360",
    "end": "269280"
  },
  {
    "text": "that immediately 25 times larger if you're storing images that can get up to",
    "start": "269280",
    "end": "275080"
  },
  {
    "text": "500 times if you're storing videos well you know easily gigabytes into per row",
    "start": "275080",
    "end": "280360"
  },
  {
    "text": "which is kind of crazy in addition um uh to that right it the data is also coming",
    "start": "280360",
    "end": "287680"
  },
  {
    "text": "in a lot faster than ever before so instead of being limited by um just manual human input to generate data",
    "start": "287680",
    "end": "294960"
  },
  {
    "text": "we're automatically generating data at thousands of tokens per second now when you put these two facts",
    "start": "294960",
    "end": "300800"
  },
  {
    "text": "together the phenomenon we see is that AI training data sets grow by several orders of magnitude every few years",
    "start": "300800",
    "end": "306479"
  },
  {
    "text": "right so CFR was roughly 163 megabytes image net up to about 150 gbes um modern",
    "start": "306479",
    "end": "314560"
  },
  {
    "text": "llm training data sets like text only um you know gets up to like uh 10 terabytes",
    "start": "314560",
    "end": "321520"
  },
  {
    "text": "orish roughly um and if you're working with images and videos uh Foundation",
    "start": "321520",
    "end": "326639"
  },
  {
    "text": "models for those it's easily you get to petabyte scale so scale is one thing um AI",
    "start": "326639",
    "end": "335160"
  },
  {
    "text": "workloads are also more diverse than what we had before right you're not just running analytics before uh anymore",
    "start": "335160",
    "end": "342039"
  },
  {
    "text": "we're talking about training um often times on multimodal data um and to",
    "start": "342039",
    "end": "347520"
  },
  {
    "text": "support these runs we need to work with the data for exploration for curation uh",
    "start": "347520",
    "end": "353319"
  },
  {
    "text": "evaluation and a and a bunch of other things right so if you just take a single training run for example first",
    "start": "353319",
    "end": "360000"
  },
  {
    "text": "you need to filter the data to get to the right subset that this requires a fast scan of the filtering Dimensions um",
    "start": "360000",
    "end": "366599"
  },
  {
    "text": "and but remember we're building on sand right we need to shuffle this data so the model isn't seeing in the same rows",
    "start": "366599",
    "end": "372000"
  },
  {
    "text": "uh in the same order all the time right so now we need fast random access and finally here comes the seawater we need",
    "start": "372000",
    "end": "378520"
  },
  {
    "text": "to be able to quickly stream the data that you've identified um in the right order to the right uh workers for",
    "start": "378520",
    "end": "386080"
  },
  {
    "text": "distributed training right and most of the time from um Object Store right so",
    "start": "386080",
    "end": "391840"
  },
  {
    "text": "you need to be able to work with large blobs effectively as well so um typically if you look at existing",
    "start": "391840",
    "end": "398479"
  },
  {
    "text": "systems today they're only good for one you know maybe two out of those three but never all three and I'm dubbing this",
    "start": "398479",
    "end": "405280"
  },
  {
    "text": "the new cap theorem of AI data right this is a loose uh modiker because as",
    "start": "405280",
    "end": "410880"
  },
  {
    "text": "we'll show you um you know the real cap theorem is unsolvable but you know this new cap theorem for AI data is actually",
    "start": "410880",
    "end": "417720"
  },
  {
    "text": "solvable um so the consequence of building on top of these existing foundations is you",
    "start": "417720",
    "end": "423800"
  },
  {
    "text": "often need to have multiple copies of the data for many different purposes right so when you have pedabytes of",
    "start": "423800",
    "end": "429879"
  },
  {
    "text": "training data this is too expensive to have multiple copies if you're managing those multiple copies you need to",
    "start": "429879",
    "end": "436360"
  },
  {
    "text": "manually translate between them keep them in sync you have to use different tools that are optimized for each task",
    "start": "436360",
    "end": "442160"
  },
  {
    "text": "and each individual format um this makes it too complicated right and doing all",
    "start": "442160",
    "end": "447599"
  },
  {
    "text": "that means the most expens expensive hires in your organization are spending too much time managing lowl details on",
    "start": "447599",
    "end": "454280"
  },
  {
    "text": "your data set rather than um improving the model or improving your AI applications so um for larger",
    "start": "454280",
    "end": "462160"
  },
  {
    "text": "organizations to work around these limitations right we've both seen uh",
    "start": "462160",
    "end": "467240"
  },
  {
    "text": "these these sort of rubbe Goldberg data Stacks right where each uh each task",
    "start": "467240",
    "end": "472479"
  },
  {
    "text": "come with its own copy of data in its own format and its own single purpose compute and then for different tasks you",
    "start": "472479",
    "end": "479199"
  },
  {
    "text": "have to go from system to system translating and uh um and uh copying",
    "start": "479199",
    "end": "485360"
  },
  {
    "text": "data back and forth right so it becomes a nightmare to just navigate these systems and when you try to build a data",
    "start": "485360",
    "end": "491960"
  },
  {
    "text": "flywheel to support rapid iteration that's all but impossible right so",
    "start": "491960",
    "end": "498879"
  },
  {
    "text": "um so uh we started Lance CB about two and a half years ago and by asking this",
    "start": "498879",
    "end": "504120"
  },
  {
    "text": "question what if we can have it all um and you know have your cake and eat it too",
    "start": "504120",
    "end": "510919"
  },
  {
    "text": "so uh let me introduce you to Lan CB our new new way of thinking about multimodal data infrastructure",
    "start": "510919",
    "end": "517800"
  },
  {
    "text": "thanks so let's talk about how we make this",
    "start": "517800",
    "end": "523479"
  },
  {
    "text": "possible so we are rethinking um the data infrastructure for those AI",
    "start": "523480",
    "end": "529959"
  },
  {
    "text": "especially those new generation uh generations of AI companies as uh like",
    "start": "529959",
    "end": "535560"
  },
  {
    "text": "as not your old father's data link right so we want to design everything from the",
    "start": "535560",
    "end": "541760"
  },
  {
    "text": "scratch on top of Object Store to be Cloud native and try to uh gathered all",
    "start": "541760",
    "end": "548079"
  },
  {
    "text": "the badage uh from the previous generation of data infrastructure so the tech uh technical solution which use is",
    "start": "548079",
    "end": "555959"
  },
  {
    "text": "we depend uh we develop open source uh open source data infrastructure and and",
    "start": "555959",
    "end": "561519"
  },
  {
    "text": "the format on top of S3 or or GCS as po uh on top of apach Aro and building rust",
    "start": "561519",
    "end": "569760"
  },
  {
    "text": "we provide uh basically what machine learning engineer is most familiar uh",
    "start": "569760",
    "end": "576720"
  },
  {
    "text": "with SD case in python typescript or JavaScript and it can actually store all",
    "start": "576720",
    "end": "582600"
  },
  {
    "text": "the different modalities of data within the same infrastructure so they can use the uh data frames pandas poers or even",
    "start": "582600",
    "end": "591200"
  },
  {
    "text": "SQL to just manipulate those data and all of those data Foundation is open",
    "start": "591200",
    "end": "598519"
  },
  {
    "text": "sourc so every can have access to it it's does not prevent you to use that",
    "start": "598519",
    "end": "603560"
  },
  {
    "text": "into different cases where we still uh be able to deploy into uh very hyper",
    "start": "603560",
    "end": "610640"
  },
  {
    "text": "hyper laric scale into Enterprise and uh uh some like most demanding uh use cases",
    "start": "610640",
    "end": "617560"
  },
  {
    "text": "in the world that actually store pabit of data into into lens DB itself and the",
    "start": "617560",
    "end": "624279"
  },
  {
    "text": "based on uh multi multiple layers of uh uh caching uh optimizations we can",
    "start": "624279",
    "end": "630959"
  },
  {
    "text": "deliver low latency and very high QPS um much faster than many of the competitors",
    "start": "630959",
    "end": "637440"
  },
  {
    "text": "in the market and our we have learned a lot of lessons from a previous",
    "start": "637440",
    "end": "643760"
  },
  {
    "text": "generation of Big Data infrastructure so we uh from the very beginning we designed this thing as a Compu storage",
    "start": "643760",
    "end": "650760"
  },
  {
    "text": "uh separations so you each of our customer will see different uh configuration and cost uh structure to",
    "start": "650760",
    "end": "658560"
  },
  {
    "text": "make this system works for",
    "start": "658560",
    "end": "662360"
  },
  {
    "text": "them so the l d be open source is buil on top of our in-house uh lens DB uh",
    "start": "664079",
    "end": "671040"
  },
  {
    "text": "lens column format we build that from scratch try to addressed the um three",
    "start": "671040",
    "end": "676839"
  },
  {
    "text": "different workloads that we mentioned um in the previous slides by itself it have",
    "start": "676839",
    "end": "683480"
  },
  {
    "text": "three major components first it is a new file format is a new colmer file format",
    "start": "683480",
    "end": "689600"
  },
  {
    "text": "that designed uh with the support of",
    "start": "689600",
    "end": "694720"
  },
  {
    "text": "fast scan and the support of uh uh 01 Random Access which enable us to do a",
    "start": "694720",
    "end": "701760"
  },
  {
    "text": "very fast filtering and shuffling just withing the data set itself and we",
    "start": "701760",
    "end": "707000"
  },
  {
    "text": "support storing large blobs in line so that user can actually use your existing",
    "start": "707000",
    "end": "713200"
  },
  {
    "text": "pendas or or dub uh data toolings to directly operate on top of those data uh",
    "start": "713200",
    "end": "718880"
  },
  {
    "text": "data typ have itself and by removing many of the uh assumptions storage",
    "start": "718880",
    "end": "726880"
  },
  {
    "text": "assumptions from the previous generation or pet or or uh like o o OCR that we",
    "start": "726880",
    "end": "734560"
  },
  {
    "text": "actually uh develop optimize the full access patterns for for the new",
    "start": "734560",
    "end": "740600"
  },
  {
    "text": "generations of storage device that we can we uh commonly see today like mme or",
    "start": "740600",
    "end": "746639"
  },
  {
    "text": "uh object store and on top of that we bring uh many AI native features that",
    "start": "746639",
    "end": "753120"
  },
  {
    "text": "necessary for the table as a table format that we support multiple versions",
    "start": "753120",
    "end": "759320"
  },
  {
    "text": "like basically you can use this data set as a g repo that you can tag any uh any",
    "start": "759320",
    "end": "765880"
  },
  {
    "text": "tax with aversions within this data set to uh track your eval evaluation or",
    "start": "765880",
    "end": "772160"
  },
  {
    "text": "experiment mations within uh your activities and lot of our existing",
    "start": "772160",
    "end": "779199"
  },
  {
    "text": "customers actually come to us for these zero copy schema Evolutions features if you think that you store a paby s image",
    "start": "779199",
    "end": "786680"
  },
  {
    "text": "or images or videos and you want to add embeddings or feature on top of it you",
    "start": "786680",
    "end": "792040"
  },
  {
    "text": "don't want to actually have like two different copy of that we can easily to add single column uh with a very minimal",
    "start": "792040",
    "end": "799920"
  },
  {
    "text": "computation and storage overhead and other than that that thanks for uh our",
    "start": "799920",
    "end": "805760"
  },
  {
    "text": "fundamental optim design principle try to get this running access uh working we",
    "start": "805760",
    "end": "811680"
  },
  {
    "text": "actually can build secondary index on top of this format to provide a very",
    "start": "811680",
    "end": "817399"
  },
  {
    "text": "fast uh Run Access and search capabilities where on in a very",
    "start": "817399",
    "end": "823120"
  },
  {
    "text": "beginning we use Vector uh index as a proof concept to support uh to prove how",
    "start": "823120",
    "end": "829480"
  },
  {
    "text": "fast the random access we can do and by the end of the day we can easily to do",
    "start": "829480",
    "end": "835199"
  },
  {
    "text": "Millions App Ops per per second on uh our uh certain certain setup in in our",
    "start": "835199",
    "end": "841880"
  },
  {
    "text": "uh clusters so the long-term Visions we",
    "start": "841880",
    "end": "850000"
  },
  {
    "text": "want to uh we want to achieve is that we will um within different workload we",
    "start": "850000",
    "end": "855560"
  },
  {
    "text": "will have single source of choose but we can actually uh support from data generation feature engineering to uh",
    "start": "855560",
    "end": "862120"
  },
  {
    "text": "explorate to uh data analytics and it actually can support training as well",
    "start": "862120",
    "end": "868440"
  },
  {
    "text": "and for lens DB itself all the other components will work well with the rest",
    "start": "868440",
    "end": "874160"
  },
  {
    "text": "of uh open source communities to provide native and transparent access to them",
    "start": "874160",
    "end": "881360"
  },
  {
    "text": "and for L DB itself we are more focusing on high throughput high qpi serving uh",
    "start": "881360",
    "end": "889240"
  },
  {
    "text": "directly from the store of lens lens data",
    "start": "889240",
    "end": "895120"
  },
  {
    "text": "set so the the the word we want to toor to is that we will have a single source",
    "start": "897600",
    "end": "904399"
  },
  {
    "text": "of troice store as a table withing lens and we have different uh FAS retrieval",
    "start": "904399",
    "end": "911240"
  },
  {
    "text": "mechanisms on top of it for example assuming we have a table like this we have metadata columns we have prompt we",
    "start": "911240",
    "end": "918800"
  },
  {
    "text": "have like image or video columns and also we have embeddings right then",
    "start": "918800",
    "end": "923880"
  },
  {
    "text": "within uh lens itself we have different index to accelerate access patterns on",
    "start": "923880",
    "end": "929120"
  },
  {
    "text": "each of different columns where you can uh basically you can try to pattern",
    "start": "929120",
    "end": "934639"
  },
  {
    "text": "match that into your different exising workload like uh trainings exploration",
    "start": "934639",
    "end": "940480"
  },
  {
    "text": "based on say sematics of the data set where you can use like olab to actually",
    "start": "940480",
    "end": "945639"
  },
  {
    "text": "run the analytics of your stats uh of the the distributions of your training",
    "start": "945639",
    "end": "951000"
  },
  {
    "text": "sample within your data set that's where u a few of our customers is actually found this can save them multiple copies",
    "start": "951000",
    "end": "958240"
  },
  {
    "text": "of a pabas data to just get one copy of",
    "start": "958240",
    "end": "963079"
  },
  {
    "text": "that so and thanks for N scale we have uh very deep Integrations with with Ray",
    "start": "965160",
    "end": "972560"
  },
  {
    "text": "and we have uh like we have Ser U the same same set of users at Large Scale so",
    "start": "972560",
    "end": "981639"
  },
  {
    "text": "why I think we uh lb and Ray have shared a lot of common uh design principles",
    "start": "981639",
    "end": "988959"
  },
  {
    "text": "first thing is like we want to be first first class uh first level of class",
    "start": "988959",
    "end": "995600"
  },
  {
    "text": "citizens of uh say uh be python first apis so all all our API because the the",
    "start": "995600",
    "end": "1003399"
  },
  {
    "text": "nature of our teams we build on top of Arrow and pandas so it's very easy for",
    "start": "1003399",
    "end": "1008560"
  },
  {
    "text": "for user to adopt and our open source our open source offering is a embedded",
    "start": "1008560",
    "end": "1015560"
  },
  {
    "text": "uh database where you can use that as as simple as a c so that you can use that on a laptop and",
    "start": "1015560",
    "end": "1021880"
  },
  {
    "text": "also we have large scale uh computer storage separations that you can actually run that as a large scale",
    "start": "1021880",
    "end": "1028160"
  },
  {
    "text": "system as well and we want to be the data layer for uh AI practicers to to do",
    "start": "1028160",
    "end": "1035438"
  },
  {
    "text": "data processing model training evaluation and all that and Ray is the perfect match on top of lens DB to be",
    "start": "1035439",
    "end": "1043319"
  },
  {
    "text": "the computation layer to to handle uh such workload",
    "start": "1043319",
    "end": "1049279"
  },
  {
    "text": "so since uh rate 2.21 uh we have official uh lens Source",
    "start": "1049440",
    "end": "1057880"
  },
  {
    "text": "in in the ray integration so you can directly use that today it can directly read from any object store or local uh",
    "start": "1057880",
    "end": "1065320"
  },
  {
    "text": "proxy based fire system and we are working on uh",
    "start": "1065320",
    "end": "1073039"
  },
  {
    "text": "making the data sync into into Ray as well and we are actually activ working",
    "start": "1073039",
    "end": "1079360"
  },
  {
    "text": "with uh the any skele team to make this happen and other than that uh many of",
    "start": "1079360",
    "end": "1084960"
  },
  {
    "text": "our uh users is actually come to us for for the large scale schema Evolutions",
    "start": "1084960",
    "end": "1090559"
  },
  {
    "text": "which basically a essential piece of uh feature engineering uh workflow so we",
    "start": "1090559",
    "end": "1096640"
  },
  {
    "text": "have that in Ray as well and we are working on uh make sure this can be uh",
    "start": "1096640",
    "end": "1101760"
  },
  {
    "text": "get to getting into Ray release as",
    "start": "1101760",
    "end": "1107159"
  },
  {
    "text": "well so other than provide this SDK for our uh our users we use that in our",
    "start": "1107400",
    "end": "1113280"
  },
  {
    "text": "production as well we U some of uh we work with some of our customers to",
    "start": "1113280",
    "end": "1118720"
  },
  {
    "text": "generate like more than 10 paby of uh image and window data set and using that",
    "start": "1118720",
    "end": "1124240"
  },
  {
    "text": "to be the base of feature engineering and it runs on like more than hundreds",
    "start": "1124240",
    "end": "1129520"
  },
  {
    "text": "of notes and very large scale a background completion and uh and the",
    "start": "1129520",
    "end": "1134880"
  },
  {
    "text": "indexing jobs we do have a l CB Cloud offering as",
    "start": "1134880",
    "end": "1139919"
  },
  {
    "text": "well and raise a big piece of our backend indexing infrastructure to make sure we can um distribut Le to uh to",
    "start": "1139919",
    "end": "1148200"
  },
  {
    "text": "build large large scale of for index okay thank you very much and in",
    "start": "1148200",
    "end": "1155320"
  },
  {
    "text": "summary we are Developer friendly open source uh Vector multi model AI database",
    "start": "1155320",
    "end": "1162280"
  },
  {
    "text": "and uh we have our GitHub repo here please check out and we have Discord for",
    "start": "1162280",
    "end": "1169080"
  },
  {
    "text": "anyone want to join join our community thanks and any",
    "start": "1169080",
    "end": "1175340"
  },
  {
    "text": "[Applause] questions question what's the VY between",
    "start": "1175340",
    "end": "1183159"
  },
  {
    "text": "having a new indexing how what's the of the calculation what have you",
    "start": "1183159",
    "end": "1190720"
  },
  {
    "text": "seen from what kind of data to the point the indexes is there is there a mic I'm",
    "start": "1190720",
    "end": "1196240"
  },
  {
    "text": "going to repeat the question so uh the question was what's the latency between adding a column and",
    "start": "1196240",
    "end": "1203240"
  },
  {
    "text": "indexing um so the uh data writing and indexing are are separate activities",
    "start": "1203240",
    "end": "1210240"
  },
  {
    "text": "that uh can be configured by the user and um you know it really depends on how",
    "start": "1210240",
    "end": "1217919"
  },
  {
    "text": "you structure your process how big is the data set and what kind of index is being being done so like you know any",
    "start": "1217919",
    "end": "1225880"
  },
  {
    "text": "anywhere from like a second to you know like",
    "start": "1225880",
    "end": "1233039"
  },
  {
    "text": "hours uh so so you mentioned compaction um which you know is pretty standard for",
    "start": "1233720",
    "end": "1239919"
  },
  {
    "text": "for like par so I guess um when when do we need to do compaction like what kind",
    "start": "1239919",
    "end": "1245679"
  },
  {
    "text": "of scales of of data does that start to kick in um does it change the versioning",
    "start": "1245679",
    "end": "1251600"
  },
  {
    "text": "guarantees at all um and uh yeah I guess like what would downtime look like like",
    "start": "1251600",
    "end": "1259120"
  },
  {
    "text": "terab Orab scale right so uh so the question is like uh what would be the",
    "start": "1259120",
    "end": "1265679"
  },
  {
    "text": "oceny of competion and whether it will um introduce down time of uh life",
    "start": "1265679",
    "end": "1272919"
  },
  {
    "text": "data so firstly lens format itself is a immutable uh data set in immutable data",
    "start": "1272919",
    "end": "1280400"
  },
  {
    "text": "format it has its own versioning which means that the compact compaction will generate a new version of data but old",
    "start": "1280400",
    "end": "1287400"
  },
  {
    "text": "version is still access the the main purpose of is very similar to P iceberg that we we want to run",
    "start": "1287400",
    "end": "1295039"
  },
  {
    "text": "compaction because we have too many small files we want to combine them together right that's where uh open",
    "start": "1295039",
    "end": "1302360"
  },
  {
    "text": "source side you can you can basically trigger that manually by yourself and our Enterprise offering have a few cisic",
    "start": "1302360",
    "end": "1309760"
  },
  {
    "text": "uh measures to see how many smaller files within the same same data set and",
    "start": "1309760",
    "end": "1315000"
  },
  {
    "text": "other than that it's a background process that does not make a new commit",
    "start": "1315000",
    "end": "1320880"
  },
  {
    "text": "as a new version so old version is still there until like many many days we have a clean up garbage collection to delete",
    "start": "1320880",
    "end": "1328120"
  },
  {
    "text": "them makes did that answer your question",
    "start": "1328120",
    "end": "1333440"
  },
  {
    "text": "sure question let's assume that the data is in GCS 50 million rows and it's like Text",
    "start": "1333919",
    "end": "1342200"
  },
  {
    "text": "data and betting that's about4 um Dimensions how long do you",
    "start": "1342200",
    "end": "1350519"
  },
  {
    "text": "uh so question is 1550 millions of 15",
    "start": "1354559",
    "end": "1360400"
  },
  {
    "text": "embeddings 1,25 yeah yeah yeah uh and hsw",
    "start": "1360400",
    "end": "1367320"
  },
  {
    "text": "so uh 50 million okay so like with we have done some",
    "start": "1367320",
    "end": "1375400"
  },
  {
    "text": "Benchmark at around 50 to 100 Millions with either ipq or NW inw we can reach",
    "start": "1375400",
    "end": "1382279"
  },
  {
    "text": "to about 10 to 1 million depending on your CPU type on hssw and with filters",
    "start": "1382279",
    "end": "1389880"
  },
  {
    "text": "with a pre- filter in and we can with a like Banner retri scalar index we can",
    "start": "1389880",
    "end": "1396919"
  },
  {
    "text": "get around 40 to 50 combined hybrid search uh combined search together with",
    "start": "1396919",
    "end": "1403400"
  },
  {
    "text": "a 50 m 1550 MC thank you yeah from GCS directly",
    "start": "1403400",
    "end": "1409000"
  },
  {
    "text": "yeah from GCS directly yeah he Leo's manually running",
    "start": "1409000",
    "end": "1414720"
  },
  {
    "text": "through the simd code here so sorry like rough rule of thumb",
    "start": "1414720",
    "end": "1421440"
  },
  {
    "text": "as I think about this stuff you guys are are like could be 10 or 100 times faster than par for reading an individual",
    "start": "1421440",
    "end": "1427760"
  },
  {
    "text": "record right what is the overhead cost relative to park of like scanning an entire file I don't want to do any",
    "start": "1427760",
    "end": "1434760"
  },
  {
    "text": "filtering no printing whatsoever I just want to like scan the entire thing as fast as a okay it's a actually let me",
    "start": "1434760",
    "end": "1441799"
  },
  {
    "text": "repeat your question so if we just do p pure scan compared to pet where we are",
    "start": "1441799",
    "end": "1448320"
  },
  {
    "text": "in terms of Benchmark there are two aspect of this one thing is that how aggressive packet is in",
    "start": "1448320",
    "end": "1455120"
  },
  {
    "text": "uh compressed okay so that's that's one thing for for us we use those like o1",
    "start": "1455120",
    "end": "1462279"
  },
  {
    "text": "based encodings animals we can compress to up to two two times of that but if",
    "start": "1462279",
    "end": "1467760"
  },
  {
    "text": "the the size of pet and us is the same similar we there are another two aspect",
    "start": "1467760",
    "end": "1475120"
  },
  {
    "text": "of this for for the best pet libraries we are as fast as them but many of the",
    "start": "1475120",
    "end": "1482039"
  },
  {
    "text": "library out there are not that fast so we are actually faster than that yeah so depends on the par Library yeah parket",
    "start": "1482039",
    "end": "1488720"
  },
  {
    "text": "libraries especially we in general yeah in general",
    "start": "1488720",
    "end": "1495440"
  },
  {
    "text": "we can basically use through all the BWI of WM on Google or",
    "start": "1495440",
    "end": "1501679"
  },
  {
    "text": "yeah yeah if you if you are um if you are looking for a fast parket reader talk to the talk to that guy over there",
    "start": "1501679",
    "end": "1510879"
  },
  {
    "text": "yeah you do uh is your database good at uh",
    "start": "1511120",
    "end": "1518000"
  },
  {
    "text": "searching querying Us in by structure data like",
    "start": "1518000",
    "end": "1523679"
  },
  {
    "text": "SQL yes in uh so C is our table or or database good at searching or or serving",
    "start": "1523679",
    "end": "1531960"
  },
  {
    "text": "of cod each uh data yes as uh serving",
    "start": "1531960",
    "end": "1538000"
  },
  {
    "text": "mean we are ask in terms some latency we can ask F even faster than R is when you",
    "start": "1538000",
    "end": "1545320"
  },
  {
    "text": "configure that correctly the only thing that I think we we trade off is like our R Pro is not as",
    "start": "1545320",
    "end": "1552480"
  },
  {
    "text": "good as a post yeah but read is very good yeah and you mentioned that uh I mean your",
    "start": "1552480",
    "end": "1560080"
  },
  {
    "text": "database can handle with very Advanced rack I mean uh queries y yeah can you",
    "start": "1560080",
    "end": "1567559"
  },
  {
    "text": "elaborate I mean uh with the samples what kind of examples of",
    "start": "1567559",
    "end": "1574640"
  },
  {
    "text": "advanc yeah so so typically these are things that are like um I need to have",
    "start": "1574640",
    "end": "1580279"
  },
  {
    "text": "multiple modes of retrieval or if you're talking about multi multimodal data um in practice what we find is that our",
    "start": "1580279",
    "end": "1587480"
  },
  {
    "text": "many of our users get better results having um different embeddings for from different models for",
    "start": "1587480",
    "end": "1593880"
  },
  {
    "text": "different pairs of modalities and so the the sort of top level retrieval they're",
    "start": "1593880",
    "end": "1599080"
  },
  {
    "text": "looking for is okay I may have multiple embedding columns or I have like an embedding column and um a full text",
    "start": "1599080",
    "end": "1605840"
  },
  {
    "text": "index built on the text Data how do I search both of them combine them and",
    "start": "1605840",
    "end": "1611080"
  },
  {
    "text": "then maybe uh plug it into a a ranker uh for like really um and really like",
    "start": "1611080",
    "end": "1619080"
  },
  {
    "text": "production quality retrieval and then layer on these SQL style filters on top",
    "start": "1619080",
    "end": "1624120"
  },
  {
    "text": "of that that are like you know maybe it's like a tag tag list of tags intersection um you know categorical",
    "start": "1624120",
    "end": "1630960"
  },
  {
    "text": "like I want top 10 matches only from um only from these document sources that",
    "start": "1630960",
    "end": "1637399"
  },
  {
    "text": "only apply to these customer IDs and so on and so forth yeah did I answer your",
    "start": "1637399",
    "end": "1642919"
  },
  {
    "text": "question okay cool I a question about um so I mean y are multimodel but is this",
    "start": "1642919",
    "end": "1648600"
  },
  {
    "text": "number one still good for stuff that's you know like arcade style numbers floats esm strings and then how does",
    "start": "1648600",
    "end": "1654640"
  },
  {
    "text": "that perform over say text how does text perform images how does images perform over video right what are like the",
    "start": "1654640",
    "end": "1660880"
  },
  {
    "text": "various trade outs and what you see where that stands a spectrum of totally",
    "start": "1660880",
    "end": "1666360"
  },
  {
    "text": "totally so the question uh for the other side of the room is what about performance for different modalities of",
    "start": "1666360",
    "end": "1672880"
  },
  {
    "text": "data from you know like images videos to text to um just pure tabular data and so",
    "start": "1672880",
    "end": "1679120"
  },
  {
    "text": "I think this is a great question because it hits on one of the key trade-offs with Lance format is in order to have",
    "start": "1679120",
    "end": "1685120"
  },
  {
    "text": "good scam perform and good Random Access you can't use file level compression so we're trying to solve that for different",
    "start": "1685120",
    "end": "1691840"
  },
  {
    "text": "data types using en coding so for images and videos typically they are compressed",
    "start": "1691840",
    "end": "1697600"
  },
  {
    "text": "at the record level already in the in the binary representation",
    "start": "1697600",
    "end": "1702840"
  },
  {
    "text": "representations um it's almost 5 o'cl uh so it's not um uh there's no difference",
    "start": "1702840",
    "end": "1710399"
  },
  {
    "text": "there right so for Strings yes uh you that that makes a big difference so we've added fsst which is also used in",
    "start": "1710399",
    "end": "1717480"
  },
  {
    "text": "duct DB and that's basically compressive strain coding that also preserves random",
    "start": "1717480",
    "end": "1722960"
  },
  {
    "text": "accessibility um so that gets us very pretty close like almost the same as paron dis size for Strings um and then",
    "start": "1722960",
    "end": "1730640"
  },
  {
    "text": "we're working on various encodings uh like bit packing and others from like Fast L lanes for let's say integer",
    "start": "1730640",
    "end": "1736919"
  },
  {
    "text": "compression um and then you know we'll work on floats and then there are some",
    "start": "1736919",
    "end": "1742000"
  },
  {
    "text": "partners that we're working with that are looking to add like time series encodings and maybe like rolling with no",
    "start": "1742000",
    "end": "1747559"
  },
  {
    "text": "functionality and things like that so if you're interested in any of those um definitely talk to us so we've made the",
    "start": "1747559",
    "end": "1753640"
  },
  {
    "text": "encoding subsystem extensible so in parket if you want to add a new encoding",
    "start": "1753640",
    "end": "1758760"
  },
  {
    "text": "you literally have to touch everything um whereas with Lance think of it more like MP4 where you can or like you know",
    "start": "1758760",
    "end": "1766440"
  },
  {
    "text": "uh it's like container format where you can download different codecs so you only have to write the encoder and decoder to add a new um data type",
    "start": "1766440",
    "end": "1775840"
  },
  {
    "text": "there um you have streaming data in uh how do I say update a",
    "start": "1776279",
    "end": "1782440"
  },
  {
    "text": "ro uh somehow right so our update is uh",
    "start": "1782440",
    "end": "1788519"
  },
  {
    "text": "including rights is a relatively expensive so B uh we will overwrite that piece of",
    "start": "1788519",
    "end": "1796760"
  },
  {
    "text": "fragment Within the whole data set and Mark that as a new version of this data set so next time you access you can you",
    "start": "1796760",
    "end": "1804120"
  },
  {
    "text": "can find that so there will be new files Crea yeah new new F yeah yeah new files",
    "start": "1804120",
    "end": "1809600"
  },
  {
    "text": "we don't do in place updates but yeah so we are running of time but let's we can talk take one one",
    "start": "1809600",
    "end": "1816159"
  },
  {
    "text": "last question and then we can talk offline yeah yeah yeah so for um managing",
    "start": "1816159",
    "end": "1821960"
  },
  {
    "text": "edings it'd be best practice to be able to find your schema for your content uh from I can tell when value",
    "start": "1821960",
    "end": "1829000"
  },
  {
    "text": "ads of PL to embedding API that you don't have to go and try to Define like the the schema for your embeddings you",
    "start": "1829000",
    "end": "1834919"
  },
  {
    "text": "just kind of attach it to the content schema that you're doing is that an accurate description uh yeah so the",
    "start": "1834919",
    "end": "1841600"
  },
  {
    "text": "you're talking about sort of the the API for the Lan CB SDK so yeah there's an",
    "start": "1841600",
    "end": "1846880"
  },
  {
    "text": "embedding function uh embedding registry functionality where you can declare when you declare the schema using pedantic",
    "start": "1846880",
    "end": "1853840"
  },
  {
    "text": "let's say you can say this Vector Fields generated from this embedding function so then when you insert data you only",
    "start": "1853840",
    "end": "1860919"
  },
  {
    "text": "have to insert the the raw Text data or like the the raw image data and then the",
    "start": "1860919",
    "end": "1866440"
  },
  {
    "text": "the metadata that you declared the schema with will trigger lanb in the background to automatically generate the",
    "start": "1866440",
    "end": "1872799"
  },
  {
    "text": "the embeding for you okay and that's just depending as as like the embeding call right right right exactly",
    "start": "1872799",
    "end": "1879279"
  },
  {
    "text": "y okay cool thank you so much for coming to the talk so late uh we'll be hanging",
    "start": "1879279",
    "end": "1885320"
  },
  {
    "text": "around for a little bit",
    "start": "1885320",
    "end": "1888919"
  }
]
[
  {
    "text": "uh this talk is how Spotify built a robust Ray platform with a frictionless",
    "start": "3659",
    "end": "9840"
  },
  {
    "text": "developer experience my name is David and I'll be co-presenting this with my colleague",
    "start": "9840",
    "end": "15719"
  },
  {
    "text": "keshi",
    "start": "15719",
    "end": "18199"
  },
  {
    "text": "there's the two of us uh I'm a senior engineer on spotify's ML platform team",
    "start": "21960",
    "end": "27420"
  },
  {
    "text": "and Kashi is a staff engineer on the same team and today we'll tell you again how we",
    "start": "27420",
    "end": "33480"
  },
  {
    "text": "built an internal platform on top of Rey this talk is split up into two parts the",
    "start": "33480",
    "end": "40860"
  },
  {
    "text": "first part is actually not it's like pretty ml agnostic um it's a little bit of background on",
    "start": "40860",
    "end": "46920"
  },
  {
    "text": "Spotify our local development problem the cloud development environment solution we came up with and the lessons",
    "start": "46920",
    "end": "53579"
  },
  {
    "text": "we learned from that and not much of this is actually ml you could apply this to like backend or web but what's",
    "start": "53579",
    "end": "60960"
  },
  {
    "text": "specific here is how we actually use Rey as part of this Cloud development environment solution",
    "start": "60960",
    "end": "68540"
  },
  {
    "text": "so Spotify is an audio streaming platform with over 515 million users and",
    "start": "69000",
    "end": "74520"
  },
  {
    "text": "210 million subscribers across 184 markets hopefully a lot of you have",
    "start": "74520",
    "end": "80880"
  },
  {
    "text": "tried it out and used it and we machine learning is at the heart of a lot of the things we do at Spotify",
    "start": "80880",
    "end": "87659"
  },
  {
    "text": "applications include recommending personalized content on the home page",
    "start": "87659",
    "end": "92840"
  },
  {
    "text": "optimizing ranking results from searches helping you discover and explore new",
    "start": "92840",
    "end": "99119"
  },
  {
    "text": "audio content so to power all these ml products at Spotify our team is building and",
    "start": "99119",
    "end": "105360"
  },
  {
    "text": "managing a centralized machine learning platform that provides our Engineers with the tools and environments to",
    "start": "105360",
    "end": "111840"
  },
  {
    "text": "quickly productionize their ml applications",
    "start": "111840",
    "end": "115820"
  },
  {
    "text": "and the name of this internal platform is called Hendrix um in a nutshell",
    "start": "117060",
    "end": "124340"
  },
  {
    "text": "Ray clusters on the platform are deployed under kubernetes so and we also",
    "start": "124340",
    "end": "129660"
  },
  {
    "text": "use gcp so we use gke or Google kubernetes engine you've got GPU nodes",
    "start": "129660",
    "end": "135480"
  },
  {
    "text": "attached to it we use the open source kubernetes operator called kubre and then on top of that we built a",
    "start": "135480",
    "end": "142920"
  },
  {
    "text": "python SDK that includes Ray and pytorch libraries",
    "start": "142920",
    "end": "148260"
  },
  {
    "text": "has about 100 users currently inside the company",
    "start": "148260",
    "end": "153859"
  },
  {
    "text": "this is a slide about our diverse potential users like all the different",
    "start": "155400",
    "end": "160800"
  },
  {
    "text": "types of people we want to serve at Spotify so an ideal ml platform should",
    "start": "160800",
    "end": "166200"
  },
  {
    "text": "cover both breadth and depth of users and offer a wide range of tools to tackle different problems in a scalable",
    "start": "166200",
    "end": "173160"
  },
  {
    "text": "maintainable and enjoyable way so we wanted a unified and easy to use interface",
    "start": "173160",
    "end": "179340"
  },
  {
    "text": "to access managed Ray infrastructure for users of all these different types of",
    "start": "179340",
    "end": "184620"
  },
  {
    "text": "backgrounds and it spans the range from research scientists",
    "start": "184620",
    "end": "189860"
  },
  {
    "text": "who prototype and experiment on new ideas data Engineers who explore and optimize",
    "start": "189860",
    "end": "195780"
  },
  {
    "text": "features to ml Engineers who Implement and productionize models and also data",
    "start": "195780",
    "end": "202379"
  },
  {
    "text": "scientists who analyze and a B test results and also like back Engineers back-end Engineers who want to serve the",
    "start": "202379",
    "end": "210000"
  },
  {
    "text": "final model in production and I want to emphasize that these these groups of users sometimes there's definitely",
    "start": "210000",
    "end": "215280"
  },
  {
    "text": "overlap but there's often vastly different backgrounds that they",
    "start": "215280",
    "end": "222540"
  },
  {
    "text": "come from for example um back-end Engineers probably know how to SSH into a machine",
    "start": "222540",
    "end": "228239"
  },
  {
    "text": "but some data scientists or maybe even researchers they don't know how to do",
    "start": "228239",
    "end": "234780"
  },
  {
    "text": "that or if they do they don't know things like how do I forward my agent so I can get pushed you know get into why that's important later so we wanted to",
    "start": "234780",
    "end": "240900"
  },
  {
    "text": "create a platform that would simplify and cater to all these different types of users",
    "start": "240900",
    "end": "247580"
  },
  {
    "text": "uh this is the part where it's kind of ml agnostic but it's exacerbated by the",
    "start": "248400",
    "end": "253799"
  },
  {
    "text": "ml ecosystem um we built Hendrix SDK and",
    "start": "253799",
    "end": "259380"
  },
  {
    "text": "most of our users have expensive MacBooks usually the newer ones and ones m2s okay",
    "start": "259380",
    "end": "266940"
  },
  {
    "text": "some of you probably already know where I'm going with this but um they're the culture at Spotify is you work by",
    "start": "266940",
    "end": "273600"
  },
  {
    "text": "default locally you try to set up your local workstation there's not really a tradition of starting in the cloud so",
    "start": "273600",
    "end": "281220"
  },
  {
    "text": "people try to pip install Hendrix and they have a variety of different workstations you know CPU architectures",
    "start": "281220",
    "end": "288900"
  },
  {
    "text": "can be different their operating system can be different from one to one they have different python versions that",
    "start": "288900",
    "end": "295139"
  },
  {
    "text": "they're using and Bam they're hit with like can't pip and solve failure can't",
    "start": "295139",
    "end": "300780"
  },
  {
    "text": "install like grpcio I'm just curious like how many of you have actually run into some kind of weird Apple silicon",
    "start": "300780",
    "end": "307560"
  },
  {
    "text": "yeah so I see a bunch of cans and like how much of a productivity killer is that right like you don't want to be you",
    "start": "307560",
    "end": "313800"
  },
  {
    "text": "want to be doing ml you want to be doing like AI stuff you don't want to be Googling obscure compiler flags that you just get",
    "start": "313800",
    "end": "320699"
  },
  {
    "text": "the thing installed so our support burden was like just horrible um and even if they did let's go on to",
    "start": "320699",
    "end": "327419"
  },
  {
    "text": "number two like even if these users did manage somehow if they run into these bad edge cases of being able to like",
    "start": "327419",
    "end": "335400"
  },
  {
    "text": "install stuff locally then When developing the array applications interactively and connecting to a remote",
    "start": "335400",
    "end": "341460"
  },
  {
    "text": "cluster so our infrastructure helps them create a remote cluster and they have to connect to that they're writing code",
    "start": "341460",
    "end": "347340"
  },
  {
    "text": "locally connecting to a remote cluster they have oftentimes trouble um achieving like consistency between",
    "start": "347340",
    "end": "354300"
  },
  {
    "text": "their local development environment and the remote runtime environment which is really important and Rey in the best",
    "start": "354300",
    "end": "359759"
  },
  {
    "text": "case tells you you're using different python versions I'm not going to run your code and the worst case scenario it",
    "start": "359759",
    "end": "365400"
  },
  {
    "text": "runs it but your checkpoint is null for some weird reason right so strange bugs when running on a ray client that's not",
    "start": "365400",
    "end": "372120"
  },
  {
    "text": "a rate on the ray cluster and users have to spend also time setting up their development environment",
    "start": "372120",
    "end": "378240"
  },
  {
    "text": "for each repo Spotify is a mono Repo Company or sorry it's not a mono Repo",
    "start": "378240",
    "end": "384000"
  },
  {
    "text": "Company it's like multi-repo microservices so a lot of times users have to switch",
    "start": "384000",
    "end": "390120"
  },
  {
    "text": "between different repos and each repo might have different setup or different configuration new Pi MV environment for",
    "start": "390120",
    "end": "396300"
  },
  {
    "text": "each one different pip you know requirements files so juggling all of those different python virtual",
    "start": "396300",
    "end": "401940"
  },
  {
    "text": "environments can also be kind of that context switching can be tedious and error prone",
    "start": "401940",
    "end": "407100"
  },
  {
    "text": "and then yeah at the very end of the day often boils down to lots of slack requests for help of this doesn't work",
    "start": "407100",
    "end": "413580"
  },
  {
    "text": "why help me um we want it to reduce and solve all of",
    "start": "413580",
    "end": "419400"
  },
  {
    "text": "these problems so Cloud development environments uh we",
    "start": "419400",
    "end": "425520"
  },
  {
    "text": "figured it's very hard to support and maintain and make sure everything works on all the permutations of local",
    "start": "425520",
    "end": "432360"
  },
  {
    "text": "workstations and CPU architectures python versions why not just standardize and work in the cloud Linux 686 usually",
    "start": "432360",
    "end": "440460"
  },
  {
    "text": "works for everything at least the ecosystem has like first class support for this right",
    "start": "440460",
    "end": "446220"
  },
  {
    "text": "so basically we're building actually show of hands how many people have used like a CDE kind of managed CDE",
    "start": "446220",
    "end": "454380"
  },
  {
    "text": "solution like GitHub code spaces raise of hands okay so see a few hands",
    "start": "454380",
    "end": "460259"
  },
  {
    "text": "so basically we're building that but with Rey and gpus and for those of you",
    "start": "460259",
    "end": "466860"
  },
  {
    "text": "who've tried out the any scale platform yeah we're basically kind of building an internal version of the any skill platform at Spotify the benefits are",
    "start": "466860",
    "end": "473759"
  },
  {
    "text": "that people can start coding instantly you've got fully configured Dev environments starting in seconds no more",
    "start": "473759",
    "end": "480419"
  },
  {
    "text": "time wasted fixing broken Dev environments they're more powerful so when you're running small models sure",
    "start": "480419",
    "end": "486180"
  },
  {
    "text": "but when you're running or training or serving big ones you want more CPUs memory specialized Hardware accelerators",
    "start": "486180",
    "end": "491280"
  },
  {
    "text": "that your local workstation usually just can't provide you can work from any device",
    "start": "491280",
    "end": "496639"
  },
  {
    "text": "we first class support vs code in the browser it works the same on any device",
    "start": "496639",
    "end": "501900"
  },
  {
    "text": "you don't have to mess with it and frictionless experimentation so people",
    "start": "501900",
    "end": "506940"
  },
  {
    "text": "of all backgrounds can onboard very easily which is super important at a",
    "start": "506940",
    "end": "512159"
  },
  {
    "text": "large multi-repo company like Spotify we had certain requirements for these",
    "start": "512159",
    "end": "520140"
  },
  {
    "text": "cdes basic functionality and security persistence reliability and resource",
    "start": "520140",
    "end": "527279"
  },
  {
    "text": "customization and very important was fast startup and low latency people who",
    "start": "527279",
    "end": "533160"
  },
  {
    "text": "are coming from a habit of working locally expect something in the cloud to",
    "start": "533160",
    "end": "538800"
  },
  {
    "text": "be very fast and performant if it starts slow it's usually going to be hard for",
    "start": "538800",
    "end": "544380"
  },
  {
    "text": "them to adopt it so when we're building it we had all these things in mind",
    "start": "544380",
    "end": "550680"
  },
  {
    "text": "this is a little bit this is a slide about a little bit of context at Spotify",
    "start": "550680",
    "end": "555779"
  },
  {
    "text": "and why like usually um a caveat here is that building a",
    "start": "555779",
    "end": "561120"
  },
  {
    "text": "platform like this doesn't make sense for every company if you're a small company that doesn't have the resources and the Staffing or expertise to devote",
    "start": "561120",
    "end": "567660"
  },
  {
    "text": "to building a CDE platform using Rey you know any skill platform is great you can",
    "start": "567660",
    "end": "573959"
  },
  {
    "text": "start off with that but if you're in our boat things may be different so some",
    "start": "573959",
    "end": "580080"
  },
  {
    "text": "history uh the original CDE platform at Spotify was Jupiter Hub based platform for data",
    "start": "580080",
    "end": "586740"
  },
  {
    "text": "scientists really just running like SQL queries exploring data",
    "start": "586740",
    "end": "592260"
  },
  {
    "text": "um and then the ml platform team we created",
    "start": "592260",
    "end": "597839"
  },
  {
    "text": "a CDE prototype for our own ml users that showed some promise and actually",
    "start": "597839",
    "end": "603000"
  },
  {
    "text": "gain some traction and then we decided to consolidate these two efforts in build one CDE platform to",
    "start": "603000",
    "end": "609480"
  },
  {
    "text": "serve both groups of users because there's a lot of overlap between you know the data Discovery and data",
    "start": "609480",
    "end": "614760"
  },
  {
    "text": "exploration side of things and then the transition into doing some ml based on that data",
    "start": "614760",
    "end": "621000"
  },
  {
    "text": "so this actually Justified we tried using the old Jupiter hub-based platform but it was just I had a lot of old",
    "start": "621000",
    "end": "627839"
  },
  {
    "text": "assumptions that were outdated and it wasn't flexible enough to accommodate",
    "start": "627839",
    "end": "633240"
  },
  {
    "text": "um for example like running array cluster as a custom resource in kubernetes so it really Justified a",
    "start": "633240",
    "end": "639240"
  },
  {
    "text": "complete rewrite of the entire original data science CDE platform to be more",
    "start": "639240",
    "end": "644279"
  },
  {
    "text": "powerful performant and flexible and it's just a prototype even even today",
    "start": "644279",
    "end": "649740"
  },
  {
    "text": "it's just a prototype but it should make a big impact because the total internal like addressable Market at Spotify",
    "start": "649740",
    "end": "655620"
  },
  {
    "text": "internally is about 500 to 1200 users Spotify is like that",
    "start": "655620",
    "end": "662220"
  },
  {
    "text": "um I'm gonna get the numbers wrong but it's like northwards probably like 10 000 employees and this many people",
    "start": "662220",
    "end": "667560"
  },
  {
    "text": "actually do run like SQL queries or do some kind of data science or ml have ml",
    "start": "667560",
    "end": "672899"
  },
  {
    "text": "use cases that 1200 is actually like if you include all people on Spotify who use",
    "start": "672899",
    "end": "679140"
  },
  {
    "text": "Google bigquery in some way or potentially could use it in some way",
    "start": "679140",
    "end": "684480"
  },
  {
    "text": "we went through the decision making process of like do you buy versus build",
    "start": "684480",
    "end": "689760"
  },
  {
    "text": "and again landed on the build part because we have the expertise and the Staffing we really needed deeper",
    "start": "689760",
    "end": "696120"
  },
  {
    "text": "Integrations with the rest of our platform um like backstage which is an open source thing that manages like your",
    "start": "696120",
    "end": "702660"
  },
  {
    "text": "internal software catalog we also need a lot more control over vs",
    "start": "702660",
    "end": "708120"
  },
  {
    "text": "code specifically the custom extensions so we've written a lot of custom extensions to hook into other parts of",
    "start": "708120",
    "end": "714420"
  },
  {
    "text": "Spotify for example you can query like internal data endpoints straight from vs",
    "start": "714420",
    "end": "719700"
  },
  {
    "text": "code uh SQL writing to be able to write custom um",
    "start": "719700",
    "end": "725279"
  },
  {
    "text": "SQL or SQL writing and then being able to run like a custom SQL engine underneath that and then also we wanted",
    "start": "725279",
    "end": "731700"
  },
  {
    "text": "more granular telemetry down to the level of python notebook cell execution times and what people are",
    "start": "731700",
    "end": "738300"
  },
  {
    "text": "actually running in their python notebook cells so all these reasons are why we decided eventually to to build",
    "start": "738300",
    "end": "745440"
  },
  {
    "text": "this thing internally this is I know it's very hard to see and I'm",
    "start": "745440",
    "end": "752040"
  },
  {
    "text": "looking at the time to see if I have enough time to go into this I'm going to go very quickly but this is the system design",
    "start": "752040",
    "end": "758279"
  },
  {
    "text": "and in a nutshell um you know people can access these CDs or",
    "start": "758279",
    "end": "765480"
  },
  {
    "text": "create one through their terminal or through their browser and we have a back-end service that creates uh",
    "start": "765480",
    "end": "774240"
  },
  {
    "text": "inside this is all in kubernetes we have a backend service that creates the ray cluster custom resource we then wire the",
    "start": "774240",
    "end": "780540"
  },
  {
    "text": "whole thing up with istio to do the networking and the security uh and of course we use a gcp load",
    "start": "780540",
    "end": "787139"
  },
  {
    "text": "balancer to kind of distribute and proxy all the requests there's a lot here I'm",
    "start": "787139",
    "end": "792300"
  },
  {
    "text": "don't think I have too much time to dive into it but I wanted to go to a quick demo",
    "start": "792300",
    "end": "800040"
  },
  {
    "text": "um I'm going to try to demo this live if it goes badly I have a video backup so we'll see",
    "start": "800040",
    "end": "806160"
  },
  {
    "text": "pray to the demo Gods because I've seen so many live demos this this conference so I want to try one",
    "start": "806160",
    "end": "811260"
  },
  {
    "text": "uh how do I oh I have to like here we go okay",
    "start": "811260",
    "end": "818940"
  },
  {
    "text": "doing two screens is hard okay so here what you're saying is kind of like we have a Hendrix CLI",
    "start": "818940",
    "end": "825480"
  },
  {
    "text": "and we build functionality so that you can list your CDs so here you can actually see like",
    "start": "825480",
    "end": "832019"
  },
  {
    "text": "namespace CDE is the name this one's Regional ramp it's the only one that's ready uh there's some stuff that we",
    "start": "832019",
    "end": "837959"
  },
  {
    "text": "didn't do so that's to choose to Do's we have a column called those are the actual number of Ray workers in this CDE",
    "start": "837959",
    "end": "843720"
  },
  {
    "text": "so it has two and how many you know hours it was live what does this look like from a user",
    "start": "843720",
    "end": "849779"
  },
  {
    "text": "point of view this is our GitHub Enterprise this is the Hendrix SDK itself so let's say I",
    "start": "849779",
    "end": "856680"
  },
  {
    "text": "want to develop this thing right get a nice little button here this button says open up this repo in",
    "start": "856680",
    "end": "864720"
  },
  {
    "text": "the CDE and imagine this was like a ray repo right so you've got some Ray code",
    "start": "864720",
    "end": "869880"
  },
  {
    "text": "then you see this welcome screen it's going to load it's going to take a little bit of time to load but in the meantime",
    "start": "869880",
    "end": "877139"
  },
  {
    "text": "I have an already opened one so what it's going to do is once your CD is ready it's going to drop you into vs",
    "start": "877139",
    "end": "883440"
  },
  {
    "text": "code your repo is going to be cloned and then from there you can just open a python notebook",
    "start": "883440",
    "end": "889079"
  },
  {
    "text": "and just run all the cells so for people who are coming from a lot of diverse backgrounds",
    "start": "889079",
    "end": "894720"
  },
  {
    "text": "in like a click of a button they can just get started they don't have to worry about how do I connect to the right cluster how do I ssh in how do I",
    "start": "894720",
    "end": "903000"
  },
  {
    "text": "push even if you want to like make some changes to these files and you can just push it to GitHub because your personal",
    "start": "903000",
    "end": "908880"
  },
  {
    "text": "access token is already there they don't need to know about how to like for their SSH agent",
    "start": "908880",
    "end": "915240"
  },
  {
    "text": "so this should be running um you can see that this cluster actually",
    "start": "915240",
    "end": "920519"
  },
  {
    "text": "has do I have it up here yeah it's a little small but I created",
    "start": "920519",
    "end": "925980"
  },
  {
    "text": "this cluster with two gpus so it has all the power of like gpus and it's just going through this example notebook",
    "start": "925980",
    "end": "932399"
  },
  {
    "text": "where we're preparing training data doing the splits and actually training and doing the fitting",
    "start": "932399",
    "end": "937740"
  },
  {
    "text": "uh and then going back to this yeah this CDE over here is also just show you it",
    "start": "937740",
    "end": "942959"
  },
  {
    "text": "was real it came up it cloned the repo everything works let me switch back",
    "start": "942959",
    "end": "949100"
  },
  {
    "text": "yeah that was the okay so some lessons learned what do we learn from all this prototyping",
    "start": "954120",
    "end": "959940"
  },
  {
    "text": "um we learned that you have to ensure availability and performance you know there's like you saw there was a reverse",
    "start": "959940",
    "end": "965399"
  },
  {
    "text": "proxy in the system design that needs to be fast and highly available startup times must be fast you we also learned",
    "start": "965399",
    "end": "972360"
  },
  {
    "text": "that we should allow for a lot of customization and extensibility people first thing they ask is okay great I want my DOT files or how do I customize",
    "start": "972360",
    "end": "979800"
  },
  {
    "text": "my repo so that I have pre-commit hooks there were like two levels of customization one was for personal",
    "start": "979800",
    "end": "985260"
  },
  {
    "text": "customization people might want to use vimkey bindings other people are emacs then there's Reaper level customization",
    "start": "985260",
    "end": "991500"
  },
  {
    "text": "where there's like a certain number of setup steps for the repo to get initialized properly a lot of times it's",
    "start": "991500",
    "end": "997980"
  },
  {
    "text": "just like pip install make sure every dependency is installed uh",
    "start": "997980",
    "end": "1003199"
  },
  {
    "text": "a lot of people ask for jetbrain support and SSH because they weren't used to vs code and we learned to leverage vs code",
    "start": "1003199",
    "end": "1010699"
  },
  {
    "text": "extensions pre-install commonly used ones create custom ones to integrate with the rest of your ecosystem and we",
    "start": "1010699",
    "end": "1016699"
  },
  {
    "text": "also learned to really just from our security teams encouraging us to design for security and telemetry uh and also",
    "start": "1016699",
    "end": "1024740"
  },
  {
    "text": "hopefully being able to apply like security auto updates",
    "start": "1024740",
    "end": "1029260"
  },
  {
    "text": "and we also learned to design for efficiency and cost savings users forget",
    "start": "1030260",
    "end": "1035360"
  },
  {
    "text": "all the time to shut down so we would like to build like idle shutdown and we learned to also really leverage",
    "start": "1035360",
    "end": "1043040"
  },
  {
    "text": "we're all on kubernetes so really leverage kubernetes if you're using it using the SCD as a database try not to",
    "start": "1043040",
    "end": "1049700"
  },
  {
    "text": "have like external data store if you don't need it um so you have one source of Truth",
    "start": "1049700",
    "end": "1056059"
  },
  {
    "text": "and we learned a lot about how to just design stuff on kubernetes in general using like a custom resource",
    "start": "1056059",
    "end": "1061880"
  },
  {
    "text": "in our in our case it was called the workbench the crd will really abstract away a lot of underlying kubernetes",
    "start": "1061880",
    "end": "1067360"
  },
  {
    "text": "resources and details and then provide like a higher level primitive that the rest of the platform can build on top of",
    "start": "1067360",
    "end": "1076720"
  },
  {
    "text": "think I think that was mostly it I'm going to transition to then giving the talk over",
    "start": "1076940",
    "end": "1082640"
  },
  {
    "text": "to keshi who's going to talk about the ecosystem on Rey and this will be much more like how do we actually have Ray",
    "start": "1082640",
    "end": "1088940"
  },
  {
    "text": "use cases at Spotify but first i'm gonna I think I started without the",
    "start": "1088940",
    "end": "1094520"
  },
  {
    "text": "speaker notes so let me go back to that",
    "start": "1094520",
    "end": "1098440"
  },
  {
    "text": "and here you go take it away",
    "start": "1103640",
    "end": "1107799"
  },
  {
    "text": "yeah um thank you very much David um for introducing our new cloud of Dev environment now I'm going to talk about",
    "start": "1116780",
    "end": "1124640"
  },
  {
    "text": "um the ecosystem around Rey at Spotify so as we saw earlier and the new Cloud",
    "start": "1124640",
    "end": "1130640"
  },
  {
    "text": "Dev environment offers ml practitioners and managers user-friendly interface to",
    "start": "1130640",
    "end": "1137600"
  },
  {
    "text": "leverage the rate to solve many ml problems so for ML researchers raise",
    "start": "1137600",
    "end": "1143000"
  },
  {
    "text": "flexible and easy to use distribute compute framework and can help them to",
    "start": "1143000",
    "end": "1148340"
  },
  {
    "text": "scale the training job for advanced problems such as neuronial work",
    "start": "1148340",
    "end": "1154100"
  },
  {
    "text": "um the graph neural networks and Foundations models for data scientists race ecosystem",
    "start": "1154100",
    "end": "1160820"
  },
  {
    "text": "and I run a small small thing LG boots can help them solve forecasting problems and speed up the panda workflows on",
    "start": "1160820",
    "end": "1168200"
  },
  {
    "text": "large data sets and for ML Engineers who are mostly building the ml systems and",
    "start": "1168200",
    "end": "1173660"
  },
  {
    "text": "rehabs them to protyping the new ideas and provides common operations around pytorch",
    "start": "1173660",
    "end": "1179780"
  },
  {
    "text": "so let's zoom in a little bit and talk a little bit more about the pie touch support on Rey and we have been working",
    "start": "1179780",
    "end": "1186320"
  },
  {
    "text": "on since this year so historically our ml platform has been",
    "start": "1186320",
    "end": "1191360"
  },
  {
    "text": "standardized around a tensorflow ecosystem with the rising popularity of the pie torch and more and more open source",
    "start": "1191360",
    "end": "1198559"
  },
  {
    "text": "models and the two things have been developed sorry for pytorch so to quickly bootstrap the pytorch",
    "start": "1198559",
    "end": "1205340"
  },
  {
    "text": "ecosystem support we decided to leverage the gray as much as we can to reach the",
    "start": "1205340",
    "end": "1210620"
  },
  {
    "text": "future parity and with the tensorflow ecosystem so why do we choose way first",
    "start": "1210620",
    "end": "1216400"
  },
  {
    "text": "Ray is important in common ml Ops such as feature pre-processing distributed",
    "start": "1216400",
    "end": "1222620"
  },
  {
    "text": "training Prime tuning and batch projection so this provides building blocks for common ml tasks for pytorch",
    "start": "1222620",
    "end": "1231200"
  },
  {
    "text": "and second we also come with a great ecosystem support users can easily",
    "start": "1231200",
    "end": "1236660"
  },
  {
    "text": "access popular ml libraries such as hacking face deep speed Pi G",
    "start": "1236660",
    "end": "1241700"
  },
  {
    "text": "and so they can bring in many novel Solutions so the cube Ray manager our array",
    "start": "1241700",
    "end": "1248120"
  },
  {
    "text": "infrastructure at scale it creates a feminal clusters for scheduled workflows",
    "start": "1248120",
    "end": "1254419"
  },
  {
    "text": "it has been integrated with flight which is our workflow orchestration system at",
    "start": "1254419",
    "end": "1259520"
  },
  {
    "text": "Spotify and lastly raise distributed application is just a regular Python program it's",
    "start": "1259520",
    "end": "1266780"
  },
  {
    "text": "easier to demonstrate the student notebooks as we just saw the example David showed us so we can provide",
    "start": "1266780",
    "end": "1273919"
  },
  {
    "text": "end-to-end notebooks for different ml use cases and ship them",
    "start": "1273919",
    "end": "1279440"
  },
  {
    "text": "with our SDK so overall and we build our platform and",
    "start": "1279440",
    "end": "1286520"
  },
  {
    "text": "Runway ecosystem with three core components Hendrix compute Hendrix ml",
    "start": "1286520",
    "end": "1292340"
  },
  {
    "text": "Ops library for pytorch and open source ecosystem integration",
    "start": "1292340",
    "end": "1298419"
  },
  {
    "text": "the button foundational block is what we call Hendrix compute which is manager reinstructure it provides us",
    "start": "1298460",
    "end": "1305120"
  },
  {
    "text": "standardized interface for users who don't know much about kubernetes knowledge to interact with the array",
    "start": "1305120",
    "end": "1311600"
  },
  {
    "text": "infrastructure on rgke it also offers GPU management Network",
    "start": "1311600",
    "end": "1318320"
  },
  {
    "text": "optimization and resource scheduling and a different runtime environments for",
    "start": "1318320",
    "end": "1324200"
  },
  {
    "text": "different ml problems on top of that we have our ml op library",
    "start": "1324200",
    "end": "1331760"
  },
  {
    "text": "for pytorch this SDK does the heavy lifting for users to accomplish common",
    "start": "1331760",
    "end": "1338179"
  },
  {
    "text": "Mr tasks it provides many standardized operations including future engineering",
    "start": "1338179",
    "end": "1345280"
  },
  {
    "text": "training serving and experiment tracking",
    "start": "1345280",
    "end": "1350780"
  },
  {
    "text": "the other Cornerstone of unifying the user experience our platform",
    "start": "1350780",
    "end": "1356860"
  },
  {
    "text": "but there will be still use cases that cannot be well dressed by the mL of",
    "start": "1357380",
    "end": "1363260"
  },
  {
    "text": "standardized Mr Ops they are either due to the emerging topics in ml research or",
    "start": "1363260",
    "end": "1369559"
  },
  {
    "text": "very specialized process for ad hoc ml workloads for those use cases users can",
    "start": "1369559",
    "end": "1375799"
  },
  {
    "text": "still rely on Race broader ecosystem to solve their own problems",
    "start": "1375799",
    "end": "1381679"
  },
  {
    "text": "so this gave Advanced Mr researchers and data scientists more flexibility to",
    "start": "1381679",
    "end": "1387260"
  },
  {
    "text": "build their own Solution on top of our platform it also gave us the opportunity",
    "start": "1387260",
    "end": "1392480"
  },
  {
    "text": "to standardize them in the future when they become more common and mature",
    "start": "1392480",
    "end": "1399620"
  },
  {
    "text": "so with all those three components and the newly developed Cloud Dev environment we look forward in Ray",
    "start": "1399620",
    "end": "1406520"
  },
  {
    "text": "ecosystem at Spotify to drive more ml Innovations and and keep our customers",
    "start": "1406520",
    "end": "1412280"
  },
  {
    "text": "happy so in the future we are going to complete pie touch development on way to",
    "start": "1412280",
    "end": "1420440"
  },
  {
    "text": "support more production workflows we will open up maximize ml compute",
    "start": "1420440",
    "end": "1425780"
  },
  {
    "text": "accelerator regarding to Resource allocation cost optimization for Android",
    "start": "1425780",
    "end": "1431659"
  },
  {
    "text": "compute we also plan to build the rlm option part on Ray last but not least we",
    "start": "1431659",
    "end": "1439220"
  },
  {
    "text": "are going to further platformize our Androids compute as a service to offer",
    "start": "1439220",
    "end": "1444679"
  },
  {
    "text": "better accessibility reliability and observability",
    "start": "1444679",
    "end": "1449720"
  },
  {
    "text": "so that concludes our talk in the end I would like to take this opportunity to",
    "start": "1449720",
    "end": "1455179"
  },
  {
    "text": "thank everyone at Spotify ML and analytics platform teams for their amazing and hard work so David and I can",
    "start": "1455179",
    "end": "1463000"
  },
  {
    "text": "have this opportunity to give this talk here at a razermit we also want to thank",
    "start": "1463000",
    "end": "1468320"
  },
  {
    "text": "any skill and Ray open source community and for all the help and that's a part we have received and that's it thank you",
    "start": "1468320",
    "end": "1475520"
  },
  {
    "text": "very much [Applause]",
    "start": "1475520",
    "end": "1482419"
  },
  {
    "text": "oops oh oh sorry oh",
    "start": "1482419",
    "end": "1489700"
  },
  {
    "text": "like when you have that development environment",
    "start": "1507220",
    "end": "1513399"
  },
  {
    "text": "to those remote yeah",
    "start": "1515600",
    "end": "1519860"
  },
  {
    "text": "David do you want to repeat questions",
    "start": "1521360",
    "end": "1524679"
  },
  {
    "text": "so the question was how do you ship the code or the notebook",
    "start": "1527380",
    "end": "1532880"
  },
  {
    "text": "how do you get it into the CDE right so you saw that button that I clicked if",
    "start": "1532880",
    "end": "1537980"
  },
  {
    "text": "it's in the repo that repo is cloned down and then you have all the things in the repo in the CD just automatically",
    "start": "1537980",
    "end": "1543919"
  },
  {
    "text": "and then you're just editing live files that are remote does that answer",
    "start": "1543919",
    "end": "1550840"
  },
  {
    "text": "yeah right the question was how do you handle unsaved changes or work in progress in",
    "start": "1560240",
    "end": "1566179"
  },
  {
    "text": "the CDE yeah it's all kubernetes and of course you know pods are ephemeral so if",
    "start": "1566179",
    "end": "1571279"
  },
  {
    "text": "they get restarted the data is gone unless you mount we mounted uh persistent volumes into them so those on",
    "start": "1571279",
    "end": "1578059"
  },
  {
    "text": "gcp are backed by GCE persistent disks even the Pod restarts new pod comes up",
    "start": "1578059",
    "end": "1583640"
  },
  {
    "text": "the mount happens again all the work is there so if it's on disk it's it's saved",
    "start": "1583640",
    "end": "1589279"
  },
  {
    "text": "um we also don't decide to shut it down",
    "start": "1589279",
    "end": "1595360"
  },
  {
    "text": "right the question was what if the CDE itself is shut down or you know what happens to the work on that persistent",
    "start": "1596779",
    "end": "1603200"
  },
  {
    "text": "disk so we have I think what we're planning on doing is we have functionality so that you can like a",
    "start": "1603200",
    "end": "1610039"
  },
  {
    "text": "user can just stop we have this um like State changes like there's a concept of a state where the CD is stopped and",
    "start": "1610039",
    "end": "1616820"
  },
  {
    "text": "there's a concept where the CDE is like entirely deleted stop just means that",
    "start": "1616820",
    "end": "1621919"
  },
  {
    "text": "the compute resources like the ray cluster that that kubernetes resource is deleted so it's releasing the CPU the",
    "start": "1621919",
    "end": "1628220"
  },
  {
    "text": "memory the GPU but stopped does not delete the persistent volume so that",
    "start": "1628220",
    "end": "1633679"
  },
  {
    "text": "remains in the kubernetes cluster and then we're thinking about even if someone deletes their their CDE maybe",
    "start": "1633679",
    "end": "1641419"
  },
  {
    "text": "they're sometimes they're going to do it accidentally right and then they're going to want to recover something uh we're thinking of not even then not",
    "start": "1641419",
    "end": "1648799"
  },
  {
    "text": "deleting the persistent disk maybe a retention policy of 30 days so give them 30 days to kind of change their mind we",
    "start": "1648799",
    "end": "1654020"
  },
  {
    "text": "can still recover the stuff that they had on the disk",
    "start": "1654020",
    "end": "1658059"
  },
  {
    "text": "yeah do you want to take this one or um yeah so yeah it's a little bit different so this is the separate",
    "start": "1667279",
    "end": "1674059"
  },
  {
    "text": "project we have at ml platform so backstage is different",
    "start": "1674059",
    "end": "1679700"
  },
  {
    "text": "pause pause portal but in the future maybe that can be a backstage plug-in yeah something like that yeah I think I",
    "start": "1679700",
    "end": "1686360"
  },
  {
    "text": "think the LA the question was we had like backstage how does this go in relation to Backstage the CE I think",
    "start": "1686360",
    "end": "1692480"
  },
  {
    "text": "they're kind of complementary they're orthogonal like we're probably there's ideas floating around like how she said of building a backstage Plug-In or",
    "start": "1692480",
    "end": "1699620"
  },
  {
    "text": "integration in the form of maybe like a vs code extension right so you can browse other stuff in backstage directly",
    "start": "1699620",
    "end": "1705980"
  },
  {
    "text": "from the editor",
    "start": "1705980",
    "end": "1708700"
  },
  {
    "text": "yeah the question is why did we choose to use istio as the networking layer of",
    "start": "1716779",
    "end": "1722059"
  },
  {
    "text": "the CDE system instead of using um just the kubernetes like native",
    "start": "1722059",
    "end": "1727880"
  },
  {
    "text": "kubernetes things uh we needed very our specific requirements were we wanted uh",
    "start": "1727880",
    "end": "1736400"
  },
  {
    "text": "https so when you go to your CD it has to be secure a memorable URL I don't know if you",
    "start": "1736400",
    "end": "1742640"
  },
  {
    "text": "notice what the URLs were some adjective Dash noun and randomly chosen so",
    "start": "1742640",
    "end": "1748640"
  },
  {
    "text": "sometimes you get funny combinations and then like hendrix.spotify.net it's going to be workbench.spotify.net but it's not you",
    "start": "1748640",
    "end": "1755299"
  },
  {
    "text": "know details so something memorable with https and the DNS has to be instantly",
    "start": "1755299",
    "end": "1762200"
  },
  {
    "text": "routable right like these are going to be randomly generated dynamic host names",
    "start": "1762200",
    "end": "1767600"
  },
  {
    "text": "that have to be instantly routable and also just basic create read update delete on them the the one that we found",
    "start": "1767600",
    "end": "1773779"
  },
  {
    "text": "that worked pretty well out of the box was istio and it mapped pretty well you could have like an istio Gateway all the",
    "start": "1773779",
    "end": "1779960"
  },
  {
    "text": "traffic comes in and then it's a reverse proxy and then you can set up things called like virtual Services where this",
    "start": "1779960",
    "end": "1785899"
  },
  {
    "text": "host name goes to this pod this other host name goes to this other pod and it",
    "start": "1785899",
    "end": "1791299"
  },
  {
    "text": "also had really nice out of the box security we could issue Json web tokens so that only you can access the CDE that",
    "start": "1791299",
    "end": "1798440"
  },
  {
    "text": "you created no one else can and that was done through an issue resource called uh",
    "start": "1798440",
    "end": "1803600"
  },
  {
    "text": "it's a combinations like requests authentication plus the resource or authorization policy but yeah a lot of a",
    "start": "1803600",
    "end": "1809960"
  },
  {
    "text": "lot of SEO things and almost all of it was just like North South traffic because you're talking from outside the",
    "start": "1809960",
    "end": "1815960"
  },
  {
    "text": "data center into the data center not a lot of the East-West which is what istio is probably better known for a lot of",
    "start": "1815960",
    "end": "1822919"
  },
  {
    "text": "like service mesh East-West traffic but we're just using the north south and it works out pretty well too there may be other Solutions out there but we haven't",
    "start": "1822919",
    "end": "1828980"
  },
  {
    "text": "like fully explored it",
    "start": "1828980",
    "end": "1832059"
  },
  {
    "text": "yeah so um the question is are raycast issue by different",
    "start": "1841120",
    "end": "1846679"
  },
  {
    "text": "macro users or everybody how to get their own history cluster so it's kind of mixed so in this case in our setup on",
    "start": "1846679",
    "end": "1855200"
  },
  {
    "text": "rgke every team has its own namespace so they can every user can create their own",
    "start": "1855200",
    "end": "1861679"
  },
  {
    "text": "Ray cluster but if you they want to share with the cluster in the with their teammates they can also do that",
    "start": "1861679",
    "end": "1869080"
  },
  {
    "text": "that's a good question so the question is we have fried integration what's the",
    "start": "1882860",
    "end": "1888320"
  },
  {
    "text": "relationship with CDE and a fly so the city is more for the interactive",
    "start": "1888320",
    "end": "1894080"
  },
  {
    "text": "development experience the flight is more on the production side say I'm",
    "start": "1894080",
    "end": "1900200"
  },
  {
    "text": "working on a new ml problem I use CDE to build ml pipeline after that is done",
    "start": "1900200",
    "end": "1907340"
  },
  {
    "text": "we're going to use fried to orchestrate and scale you to run in production every day",
    "start": "1907340",
    "end": "1914080"
  },
  {
    "text": "so",
    "start": "1915500",
    "end": "1918500"
  },
  {
    "text": "different development do you actually write a flight crew",
    "start": "1920720",
    "end": "1927320"
  },
  {
    "text": "or because potentially",
    "start": "1927320",
    "end": "1931779"
  },
  {
    "text": "the right tasks gotcha so the question is during the",
    "start": "1941000",
    "end": "1948559"
  },
  {
    "text": "index development mode does the user write five code direct say in CDE and",
    "start": "1948559",
    "end": "1954140"
  },
  {
    "text": "the current answer is no so there's a we have our own flight plug-in in our SDK",
    "start": "1954140",
    "end": "1962480"
  },
  {
    "text": "so what people usually does is they build an ml applications using our API",
    "start": "1962480",
    "end": "1970159"
  },
  {
    "text": "so they cannot build it on top of us then they have their own functions",
    "start": "1970159",
    "end": "1975860"
  },
  {
    "text": "libraries then on the Fly side is simply just cause certain apis for each flight",
    "start": "1975860",
    "end": "1982220"
  },
  {
    "text": "task so on the right side the logic is relatively simple so they trying to wrap",
    "start": "1982220",
    "end": "1987919"
  },
  {
    "text": "up everything in one python module then flight can call that causal functions in",
    "start": "1987919",
    "end": "1994159"
  },
  {
    "text": "the python module yeah",
    "start": "1994159",
    "end": "1997419"
  },
  {
    "text": "slide that you integrated what else do you need to do",
    "start": "2001480",
    "end": "2007320"
  },
  {
    "text": "it's a good question do you want that one yeah so at this point on our Ray",
    "start": "2010000",
    "end": "2015100"
  },
  {
    "text": "Journey we're using just kind of a subset of Ray and I think or the question was we're integrating with",
    "start": "2015100",
    "end": "2020440"
  },
  {
    "text": "flight what else is needed for a minimum viable platform I guess right okay so we",
    "start": "2020440",
    "end": "2027460"
  },
  {
    "text": "have flight it really depends on the use case and the business problem you're",
    "start": "2027460",
    "end": "2033159"
  },
  {
    "text": "trying to solve in our case we already had a pre-existing ml platform which was",
    "start": "2033159",
    "end": "2039159"
  },
  {
    "text": "great for production scheduled like production offline batch jobs based on",
    "start": "2039159",
    "end": "2044620"
  },
  {
    "text": "tensorflow and what we were missing was uh a product or tool or platform for AI",
    "start": "2044620",
    "end": "2052419"
  },
  {
    "text": "researchers people who wanted to prototype not really sure if it's going to go into production or not",
    "start": "2052419",
    "end": "2058898"
  },
  {
    "text": "um and that's where Ray really stood out and that's where um we really wanted to develop towards",
    "start": "2058899",
    "end": "2064720"
  },
  {
    "text": "or address that that need in terms of we're using a subset of Ray right now so",
    "start": "2064720",
    "end": "2070240"
  },
  {
    "text": "because we're only addressing that part it's it's Ray Trane Ray data and not so",
    "start": "2070240",
    "end": "2076599"
  },
  {
    "text": "much but we're really going to look into it race serve yet so we're exploring like how once people have prototype",
    "start": "2076599",
    "end": "2082898"
  },
  {
    "text": "stuff if they actually want to do inference uh what's that going to look like and how do we optimize that yeah",
    "start": "2082899",
    "end": "2089339"
  },
  {
    "text": "take this point yeah uh yeah I think the question was uh we had an old we had an",
    "start": "2110020",
    "end": "2115540"
  },
  {
    "text": "existing ml platform and we have a new one and I guess the question is about experiment tracking right yeah how do",
    "start": "2115540",
    "end": "2121180"
  },
  {
    "text": "you do we use sagemaker things like that so we had an existing also ml experiment",
    "start": "2121180",
    "end": "2126520"
  },
  {
    "text": "tracking system um and I think I wish that team was here to probably answer this question a lot",
    "start": "2126520",
    "end": "2132700"
  },
  {
    "text": "better uh they're looking into vendored Solutions they're looking into uh uh",
    "start": "2132700",
    "end": "2138160"
  },
  {
    "text": "yeah weights and biases is one we could uh ml flow",
    "start": "2138160",
    "end": "2143500"
  },
  {
    "text": "um the tricky part is how do we if we were to buy something how do we integrate it with the rest of the",
    "start": "2143500",
    "end": "2148960"
  },
  {
    "text": "Spotify ecosystem and then if we were to build something uh what the cost would",
    "start": "2148960",
    "end": "2154960"
  },
  {
    "text": "be again this this kind of build versus by you know trade-offs kind of not sure if that answers your question",
    "start": "2154960",
    "end": "2160599"
  },
  {
    "text": "though so it's really context dependent will be available for questions if",
    "start": "2160599",
    "end": "2167079"
  },
  {
    "text": "people want to come up and chat with us but thank you for attending our talk thank you very much",
    "start": "2167079",
    "end": "2172859"
  }
]
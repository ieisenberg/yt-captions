[
  {
    "text": "all right thanks everyone and thanks for",
    "start": "3159",
    "end": "5720"
  },
  {
    "text": "coming um and I'm very delighted to be",
    "start": "5720",
    "end": "7799"
  },
  {
    "text": "here to share with you uh our work on uh",
    "start": "7799",
    "end": "10960"
  },
  {
    "text": "how we pionering efficient hyperscale",
    "start": "10960",
    "end": "13440"
  },
  {
    "text": "Ray MP cluster um just for the sake of",
    "start": "13440",
    "end": "17240"
  },
  {
    "text": "everyone basically the npu is uh in is a",
    "start": "17240",
    "end": "21119"
  },
  {
    "text": "product from Huawei uh which we call",
    "start": "21119",
    "end": "23199"
  },
  {
    "text": "Asen the the product name called as an",
    "start": "23199",
    "end": "25160"
  },
  {
    "text": "npu uh the performance is slightly kind",
    "start": "25160",
    "end": "27920"
  },
  {
    "text": "of about the same like a a100 all right",
    "start": "27920",
    "end": "31119"
  },
  {
    "text": "and so this is a work in conjunction",
    "start": "31119",
    "end": "32920"
  },
  {
    "text": "with our my team in China as well as our",
    "start": "32920",
    "end": "35200"
  },
  {
    "text": "team in Canada so uh my name is KF and",
    "start": "35200",
    "end": "38120"
  },
  {
    "text": "with me is uh boan uh so I myself is a",
    "start": "38120",
    "end": "41920"
  },
  {
    "text": "uh Chief system architect from Huawei",
    "start": "41920",
    "end": "44000"
  },
  {
    "text": "and specialize in heterogeneous",
    "start": "44000",
    "end": "45879"
  },
  {
    "text": "Computing so it was about two years ago",
    "start": "45879",
    "end": "49399"
  },
  {
    "text": "when we start thinking about like how we",
    "start": "49399",
    "end": "51920"
  },
  {
    "text": "bu uh need to build the hypers skill",
    "start": "51920",
    "end": "53840"
  },
  {
    "text": "cluster the first thing that we think is",
    "start": "53840",
    "end": "55960"
  },
  {
    "text": "that what program model that fits those",
    "start": "55960",
    "end": "58559"
  },
  {
    "text": "kind of cluster right so we have a few",
    "start": "58559",
    "end": "61160"
  },
  {
    "text": "things in my our head is that we would",
    "start": "61160",
    "end": "63120"
  },
  {
    "text": "like to have this cluster to be able to",
    "start": "63120",
    "end": "65439"
  },
  {
    "text": "handle uh conventional workload as well",
    "start": "65439",
    "end": "68119"
  },
  {
    "text": "as AI workload as well as a type of",
    "start": "68119",
    "end": "70520"
  },
  {
    "text": "workload which we call converg workload",
    "start": "70520",
    "end": "72840"
  },
  {
    "text": "which is AI plus X that kind of workload",
    "start": "72840",
    "end": "75720"
  },
  {
    "text": "right so and we come across Ray and we",
    "start": "75720",
    "end": "78439"
  },
  {
    "text": "we think that Ray actually is one of the",
    "start": "78439",
    "end": "80640"
  },
  {
    "text": "very U perfect solution of what we need",
    "start": "80640",
    "end": "83320"
  },
  {
    "text": "um for a few reasons for example like we",
    "start": "83320",
    "end": "85840"
  },
  {
    "text": "looking into Ray and then it can do",
    "start": "85840",
    "end": "87680"
  },
  {
    "text": "things like uh this deferred executions",
    "start": "87680",
    "end": "90320"
  },
  {
    "text": "and is very flexible and it's very agile",
    "start": "90320",
    "end": "94399"
  },
  {
    "text": "and so we we think that this is a",
    "start": "94399",
    "end": "95960"
  },
  {
    "text": "perfect solution for what we need uh but",
    "start": "95960",
    "end": "98200"
  },
  {
    "text": "the problem is that at the time when we",
    "start": "98200",
    "end": "100200"
  },
  {
    "text": "look into Ray it uh mostly Ray only",
    "start": "100200",
    "end": "102399"
  },
  {
    "text": "support GPU right so then um the very",
    "start": "102399",
    "end": "105240"
  },
  {
    "text": "first thing that come into our mind is",
    "start": "105240",
    "end": "107119"
  },
  {
    "text": "that hey we need to integrate um third",
    "start": "107119",
    "end": "109759"
  },
  {
    "text": "party solutions that non GPU Solutions",
    "start": "109759",
    "end": "112119"
  },
  {
    "text": "into Ray um so then that's what you can",
    "start": "112119",
    "end": "114719"
  },
  {
    "text": "see in the boxes on the on the on the",
    "start": "114719",
    "end": "116880"
  },
  {
    "text": "top top left which is color in red so",
    "start": "116880",
    "end": "119560"
  },
  {
    "text": "that's basically uh hway solutions that",
    "start": "119560",
    "end": "121719"
  },
  {
    "text": "we have basically on top is a pring",
    "start": "121719",
    "end": "124119"
  },
  {
    "text": "model uh equalent to pych called myp and",
    "start": "124119",
    "end": "127520"
  },
  {
    "text": "underneath we have a runtime called can",
    "start": "127520",
    "end": "129520"
  },
  {
    "text": "which is equivalent Cuda right so our",
    "start": "129520",
    "end": "132080"
  },
  {
    "text": "team basically go through a lot of um uh",
    "start": "132080",
    "end": "134280"
  },
  {
    "text": "troubles integrating this solutions",
    "start": "134280",
    "end": "136560"
  },
  {
    "text": "because for example like uh in can uh",
    "start": "136560",
    "end": "139440"
  },
  {
    "text": "the topology used in can and the GPU",
    "start": "139440",
    "end": "142040"
  },
  {
    "text": "Cuda is very different so when it",
    "start": "142040",
    "end": "144400"
  },
  {
    "text": "present to Ray what it means to the",
    "start": "144400",
    "end": "146680"
  },
  {
    "text": "developer is that you know you cannot",
    "start": "146680",
    "end": "148640"
  },
  {
    "text": "use the same concept that you",
    "start": "148640",
    "end": "150480"
  },
  {
    "text": "understands GPU to configure your ray",
    "start": "150480",
    "end": "153239"
  },
  {
    "text": "cluster for for for for the npu so um we",
    "start": "153239",
    "end": "157599"
  },
  {
    "text": "thank thankfully you know our team",
    "start": "157599",
    "end": "158959"
  },
  {
    "text": "basically solved all this problem so",
    "start": "158959",
    "end": "160440"
  },
  {
    "text": "right now basically we mix the way that",
    "start": "160440",
    "end": "162480"
  },
  {
    "text": "you use uh our Solutions uh on on Ray",
    "start": "162480",
    "end": "165480"
  },
  {
    "text": "will be very similar to like how you use",
    "start": "165480",
    "end": "167599"
  },
  {
    "text": "it on the GPU so um as we integrate",
    "start": "167599",
    "end": "171599"
  },
  {
    "text": "through this whole thing the magic",
    "start": "171599",
    "end": "173319"
  },
  {
    "text": "actually happens right so we started to",
    "start": "173319",
    "end": "175640"
  },
  {
    "text": "to see that we able to schedule the",
    "start": "175640",
    "end": "177599"
  },
  {
    "text": "workload uh for that you have developed",
    "start": "177599",
    "end": "179640"
  },
  {
    "text": "in pie torch now you can either select",
    "start": "179640",
    "end": "182159"
  },
  {
    "text": "to run on npu cluster or GPU cluster or",
    "start": "182159",
    "end": "185239"
  },
  {
    "text": "run on both at the same time so magic",
    "start": "185239",
    "end": "187680"
  },
  {
    "text": "happen right so um and also like this is",
    "start": "187680",
    "end": "191560"
  },
  {
    "text": "about back like 6 months ago so we start",
    "start": "191560",
    "end": "193879"
  },
  {
    "text": "to think that hey we need to contribute",
    "start": "193879",
    "end": "196200"
  },
  {
    "text": "what we do here back to the open source",
    "start": "196200",
    "end": "198640"
  },
  {
    "text": "Community that's why in the last six",
    "start": "198640",
    "end": "200440"
  },
  {
    "text": "months uh we have been basically",
    "start": "200440",
    "end": "202319"
  },
  {
    "text": "engaging with this Ray open source",
    "start": "202319",
    "end": "204239"
  },
  {
    "text": "community and up to this point",
    "start": "204239",
    "end": "205920"
  },
  {
    "text": "thankfully we already have submitted",
    "start": "205920",
    "end": "207840"
  },
  {
    "text": "about like a 20 uh the P request to the",
    "start": "207840",
    "end": "211120"
  },
  {
    "text": "to to the repository so everything that",
    "start": "211120",
    "end": "213120"
  },
  {
    "text": "you see right here almost all of them",
    "start": "213120",
    "end": "215360"
  },
  {
    "text": "right 99% of them are available in the",
    "start": "215360",
    "end": "218319"
  },
  {
    "text": "source code in the in the open source uh",
    "start": "218319",
    "end": "220599"
  },
  {
    "text": "source code uh freay so um yeah so the",
    "start": "220599",
    "end": "224439"
  },
  {
    "text": "the very first customer that we",
    "start": "224439",
    "end": "225799"
  },
  {
    "text": "encounter is our internal customer that",
    "start": "225799",
    "end": "228480"
  },
  {
    "text": "um they basically what they did with",
    "start": "228480",
    "end": "230040"
  },
  {
    "text": "this uh system is that they wanted to uh",
    "start": "230040",
    "end": "232599"
  },
  {
    "text": "do a offline batch uh uh inference uh uh",
    "start": "232599",
    "end": "236040"
  },
  {
    "text": "workload on the thousands of uh this mpu",
    "start": "236040",
    "end": "239079"
  },
  {
    "text": "and GPU and this system is running 24/7",
    "start": "239079",
    "end": "242439"
  },
  {
    "text": "and then they are processing like 100",
    "start": "242439",
    "end": "244200"
  },
  {
    "text": "tabt of data daily uh and the the",
    "start": "244200",
    "end": "247120"
  },
  {
    "text": "workload is schedule like every like a",
    "start": "247120",
    "end": "249799"
  },
  {
    "text": "minutes a few minutes and the the",
    "start": "249799",
    "end": "252799"
  },
  {
    "text": "original design architecture of this of",
    "start": "252799",
    "end": "255239"
  },
  {
    "text": "this uh system is that they basically",
    "start": "255239",
    "end": "258000"
  },
  {
    "text": "have this Argo um on different kind of",
    "start": "258000",
    "end": "261400"
  },
  {
    "text": "uh cluster so they have two type of",
    "start": "261400",
    "end": "263040"
  },
  {
    "text": "cluster one a CPU cluster the other one",
    "start": "263040",
    "end": "264960"
  },
  {
    "text": "is a GPU cluster so each of them",
    "start": "264960",
    "end": "267400"
  },
  {
    "text": "basically have this ago running the jobs",
    "start": "267400",
    "end": "269919"
  },
  {
    "text": "inside managing the jobs inside and the",
    "start": "269919",
    "end": "272160"
  },
  {
    "text": "scheduling is firing off from airflow to",
    "start": "272160",
    "end": "275039"
  },
  {
    "text": "Aro cluster as you can see the the the",
    "start": "275039",
    "end": "277680"
  },
  {
    "text": "the system like this means that each of",
    "start": "277680",
    "end": "279600"
  },
  {
    "text": "the cluster have its own isolated",
    "start": "279600",
    "end": "281639"
  },
  {
    "text": "workload so the workload doesn't stare",
    "start": "281639",
    "end": "283759"
  },
  {
    "text": "across you know different type of a",
    "start": "283759",
    "end": "285440"
  },
  {
    "text": "clust so the utilization the resource",
    "start": "285440",
    "end": "288039"
  },
  {
    "text": "utilization efficiency is kind of",
    "start": "288039",
    "end": "290759"
  },
  {
    "text": "limited in this kind of setup right and",
    "start": "290759",
    "end": "294000"
  },
  {
    "text": "um the other thing is that this team",
    "start": "294000",
    "end": "295720"
  },
  {
    "text": "they also thinking that hey they want to",
    "start": "295720",
    "end": "297560"
  },
  {
    "text": "expand because um 100 terabyte was",
    "start": "297560",
    "end": "300800"
  },
  {
    "text": "something that about uh a year ago so",
    "start": "300800",
    "end": "303600"
  },
  {
    "text": "they they the amount of data they",
    "start": "303600",
    "end": "305240"
  },
  {
    "text": "processing is increasing um you know uh",
    "start": "305240",
    "end": "308320"
  },
  {
    "text": "uh uh U uh uh exponentially so then they",
    "start": "308320",
    "end": "311840"
  },
  {
    "text": "need to increase that pler size and with",
    "start": "311840",
    "end": "314320"
  },
  {
    "text": "such kind of efficiency classer setup",
    "start": "314320",
    "end": "316520"
  },
  {
    "text": "they cannot scale so and therefore they",
    "start": "316520",
    "end": "319520"
  },
  {
    "text": "um would like to also uh to migrate some",
    "start": "319520",
    "end": "321960"
  },
  {
    "text": "of their workload from originary from uh",
    "start": "321960",
    "end": "324160"
  },
  {
    "text": "GPU to mpu right so they were the they",
    "start": "324160",
    "end": "329000"
  },
  {
    "text": "uh you know uh um dealing with us and",
    "start": "329000",
    "end": "331240"
  },
  {
    "text": "how they can actually do that so they",
    "start": "331240",
    "end": "333080"
  },
  {
    "text": "can basically um without interrupting",
    "start": "333080",
    "end": "335720"
  },
  {
    "text": "their business they can do their",
    "start": "335720",
    "end": "337000"
  },
  {
    "text": "migration and increase the efficiency",
    "start": "337000",
    "end": "339199"
  },
  {
    "text": "and therefore they started when they",
    "start": "339199",
    "end": "341160"
  },
  {
    "text": "started to use our Solution on on on uh",
    "start": "341160",
    "end": "344000"
  },
  {
    "text": "using Ray now the the workflow I'm sorry",
    "start": "344000",
    "end": "347360"
  },
  {
    "text": "about the the the the the the dotted",
    "start": "347360",
    "end": "349440"
  },
  {
    "text": "lines the red dotted lines here this is",
    "start": "349440",
    "end": "351000"
  },
  {
    "text": "supposed to be uh connected okay so uh",
    "start": "351000",
    "end": "354120"
  },
  {
    "text": "now the workflow is connected right so",
    "start": "354120",
    "end": "356759"
  },
  {
    "text": "we basically using Ray to manage both",
    "start": "356759",
    "end": "359160"
  },
  {
    "text": "CPU cluster and uh the npu cluster",
    "start": "359160",
    "end": "362039"
  },
  {
    "text": "everything will be managed by Ray so the",
    "start": "362039",
    "end": "364240"
  },
  {
    "text": "job is still firing off from the uh",
    "start": "364240",
    "end": "366120"
  },
  {
    "text": "airflow but then you know the the ray",
    "start": "366120",
    "end": "369039"
  },
  {
    "text": "basically you know thankfully we also",
    "start": "369039",
    "end": "370880"
  },
  {
    "text": "have this Ray data where we can now do",
    "start": "370880",
    "end": "373280"
  },
  {
    "text": "the uh data pipelining uh across",
    "start": "373280",
    "end": "375960"
  },
  {
    "text": "different cluster so then we can",
    "start": "375960",
    "end": "377599"
  },
  {
    "text": "basically hide a lot of transfer latency",
    "start": "377599",
    "end": "379840"
  },
  {
    "text": "and so on and what does that bring us",
    "start": "379840",
    "end": "382720"
  },
  {
    "text": "right so oh before I forgot um uh",
    "start": "382720",
    "end": "386880"
  },
  {
    "text": "because we enabled both GPU and npu uh",
    "start": "386880",
    "end": "389880"
  },
  {
    "text": "with this solutions so the customer um",
    "start": "389880",
    "end": "392560"
  },
  {
    "text": "the workload that they run on the mpu",
    "start": "392560",
    "end": "394599"
  },
  {
    "text": "are not like uh this huge influencing uh",
    "start": "394599",
    "end": "397919"
  },
  {
    "text": "kind of model they basically have a lot",
    "start": "397919",
    "end": "400039"
  },
  {
    "text": "of small models that's also add into",
    "start": "400039",
    "end": "402000"
  },
  {
    "text": "like a complexity in managing the small",
    "start": "402000",
    "end": "404199"
  },
  {
    "text": "model which bu later on going to share",
    "start": "404199",
    "end": "406240"
  },
  {
    "text": "with us actually how we do this uh small",
    "start": "406240",
    "end": "408160"
  },
  {
    "text": "Model Management and also with this",
    "start": "408160",
    "end": "410240"
  },
  {
    "text": "small model they do not want to migrate",
    "start": "410240",
    "end": "412039"
  },
  {
    "text": "all their models at at the same time",
    "start": "412039",
    "end": "414599"
  },
  {
    "text": "they wanted to migrate part of their",
    "start": "414599",
    "end": "416000"
  },
  {
    "text": "model and slowly you know so therefore",
    "start": "416000",
    "end": "418000"
  },
  {
    "text": "the system will have mpu GPU code exist",
    "start": "418000",
    "end": "420599"
  },
  {
    "text": "at the same time and and we have really",
    "start": "420599",
    "end": "422840"
  },
  {
    "text": "enabled them to of doing so uh with our",
    "start": "422840",
    "end": "425520"
  },
  {
    "text": "solution and this is the out outcome",
    "start": "425520",
    "end": "427479"
  },
  {
    "text": "right so we the the Improvement the the",
    "start": "427479",
    "end": "430759"
  },
  {
    "text": "utilizations um system utilization",
    "start": "430759",
    "end": "433240"
  },
  {
    "text": "improved by four times and throughput",
    "start": "433240",
    "end": "435400"
  },
  {
    "text": "improved by 2.5x right um so and with",
    "start": "435400",
    "end": "439639"
  },
  {
    "text": "this uh we although we have uh you know",
    "start": "439639",
    "end": "442680"
  },
  {
    "text": "uh achieved um kind of a very",
    "start": "442680",
    "end": "444759"
  },
  {
    "text": "significant kind of improvement which is",
    "start": "444759",
    "end": "447319"
  },
  {
    "text": "out of our expectation honestly and",
    "start": "447319",
    "end": "449560"
  },
  {
    "text": "basically oh before I forget as well so",
    "start": "449560",
    "end": "452319"
  },
  {
    "text": "the four times and two for pi times is a",
    "start": "452319",
    "end": "454680"
  },
  {
    "text": "very conservative number it's an end to",
    "start": "454680",
    "end": "456479"
  },
  {
    "text": "end number right in some cases we see",
    "start": "456479",
    "end": "458840"
  },
  {
    "text": "this number go like very crazy like a",
    "start": "458840",
    "end": "460800"
  },
  {
    "text": "20x 40x whatever you call it and but we",
    "start": "460800",
    "end": "464720"
  },
  {
    "text": "are not going to stop here we are we",
    "start": "464720",
    "end": "466319"
  },
  {
    "text": "would like to expand this cluster to",
    "start": "466319",
    "end": "468319"
  },
  {
    "text": "support more npu um so then we are going",
    "start": "468319",
    "end": "471360"
  },
  {
    "text": "to face a lot of problems again like",
    "start": "471360",
    "end": "474080"
  },
  {
    "text": "stability and scalability as you all",
    "start": "474080",
    "end": "475800"
  },
  {
    "text": "know Ray actually based on GCS right",
    "start": "475800",
    "end": "478360"
  },
  {
    "text": "there a single point of failure",
    "start": "478360",
    "end": "480039"
  },
  {
    "text": "so how we basically able to scale is",
    "start": "480039",
    "end": "482199"
  },
  {
    "text": "really depending on how we basically",
    "start": "482199",
    "end": "483599"
  },
  {
    "text": "deal with this limitation of GCS and",
    "start": "483599",
    "end": "486000"
  },
  {
    "text": "also how we maintain good utilization",
    "start": "486000",
    "end": "488120"
  },
  {
    "text": "and performance on the larger scale of",
    "start": "488120",
    "end": "490280"
  },
  {
    "text": "of uh this MP cluster and and and most",
    "start": "490280",
    "end": "493599"
  },
  {
    "text": "importantly when the cluster increase we",
    "start": "493599",
    "end": "495960"
  },
  {
    "text": "would like to have multiple users to use",
    "start": "495960",
    "end": "498280"
  },
  {
    "text": "this cluster and not just one type of",
    "start": "498280",
    "end": "499919"
  },
  {
    "text": "user so how all the user are able to use",
    "start": "499919",
    "end": "502800"
  },
  {
    "text": "this cluster together and then they can",
    "start": "502800",
    "end": "504879"
  },
  {
    "text": "able to share the resource effectively",
    "start": "504879",
    "end": "507120"
  },
  {
    "text": "will be uh one of our challenges and and",
    "start": "507120",
    "end": "509840"
  },
  {
    "text": "more is a usability so I will let that",
    "start": "509840",
    "end": "512240"
  },
  {
    "text": "uh bu to introduce the",
    "start": "512240",
    "end": "515120"
  },
  {
    "text": "rest um thanks kenis for the great",
    "start": "515120",
    "end": "517760"
  },
  {
    "text": "introduction uh hello everyone uh my",
    "start": "517760",
    "end": "519599"
  },
  {
    "text": "name is boan Chen and I'm a researcher",
    "start": "519599",
    "end": "521959"
  },
  {
    "text": "from Hai Canada so uh in the next I'm",
    "start": "521959",
    "end": "525320"
  },
  {
    "text": "going to walk you through with some of",
    "start": "525320",
    "end": "527040"
  },
  {
    "text": "the main challenges we're trying to",
    "start": "527040",
    "end": "528320"
  },
  {
    "text": "tackle when we really want to scale the",
    "start": "528320",
    "end": "530720"
  },
  {
    "text": "whole cluster to thousands of Nos and uh",
    "start": "530720",
    "end": "533399"
  },
  {
    "text": "10K mpus so we'll go through these three",
    "start": "533399",
    "end": "536480"
  },
  {
    "text": "directions one by one um the first",
    "start": "536480",
    "end": "538959"
  },
  {
    "text": "Direction is of course towards a more",
    "start": "538959",
    "end": "541040"
  },
  {
    "text": "stable cluster so um some of you might",
    "start": "541040",
    "end": "545440"
  },
  {
    "text": "not know but when the scale goes really",
    "start": "545440",
    "end": "548240"
  },
  {
    "text": "large many things can go wrong so what",
    "start": "548240",
    "end": "550920"
  },
  {
    "text": "we commonly experience are four things",
    "start": "550920",
    "end": "554120"
  },
  {
    "text": "uh not to list out of them the first one",
    "start": "554120",
    "end": "556640"
  },
  {
    "text": "is unexpected P rest start on the kuber",
    "start": "556640",
    "end": "559519"
  },
  {
    "text": "and kubernetes uh cluster and the second",
    "start": "559519",
    "end": "562480"
  },
  {
    "text": "one is the dashboard requests uh being",
    "start": "562480",
    "end": "564720"
  },
  {
    "text": "timed out because of too many numbers of",
    "start": "564720",
    "end": "566800"
  },
  {
    "text": "jobs being submitted and number three is",
    "start": "566800",
    "end": "569640"
  },
  {
    "text": "the same kind of consequences where we",
    "start": "569640",
    "end": "571680"
  },
  {
    "text": "have unresponsible uh job requests",
    "start": "571680",
    "end": "574440"
  },
  {
    "text": "because of the um push on the dashboard",
    "start": "574440",
    "end": "577560"
  },
  {
    "text": "hat and the last point is that we",
    "start": "577560",
    "end": "579920"
  },
  {
    "text": "observe sometimes we observe very high",
    "start": "579920",
    "end": "582200"
  },
  {
    "text": "Network IO so that the nose cannot be",
    "start": "582200",
    "end": "584720"
  },
  {
    "text": "Health checked so that it does not",
    "start": "584720",
    "end": "586560"
  },
  {
    "text": "respond to GCS and considered to be a",
    "start": "586560",
    "end": "588360"
  },
  {
    "text": "dead um so how do we do this um we did a",
    "start": "588360",
    "end": "593160"
  },
  {
    "text": "lot of monitoring and testing kind of",
    "start": "593160",
    "end": "595279"
  },
  {
    "text": "software engineering efforts to",
    "start": "595279",
    "end": "597079"
  },
  {
    "text": "repeatedly test the cluster into some uh",
    "start": "597079",
    "end": "599760"
  },
  {
    "text": "stress setting setting and we want to",
    "start": "599760",
    "end": "601680"
  },
  {
    "text": "monitor every re process about their CPU",
    "start": "601680",
    "end": "604079"
  },
  {
    "text": "time memory Network which I will go",
    "start": "604079",
    "end": "606519"
  },
  {
    "text": "through later on um but essentially I'll",
    "start": "606519",
    "end": "609399"
  },
  {
    "text": "give you a hint of what are the uh parts",
    "start": "609399",
    "end": "611920"
  },
  {
    "text": "that we have been working on one of the",
    "start": "611920",
    "end": "613839"
  },
  {
    "text": "graph you will see in the bottom left is",
    "start": "613839",
    "end": "616040"
  },
  {
    "text": "the uh redis uh performance optimization",
    "start": "616040",
    "end": "619480"
  },
  {
    "text": "uh performance profiling figure so one",
    "start": "619480",
    "end": "622160"
  },
  {
    "text": "thing we observe is that when we have um",
    "start": "622160",
    "end": "625040"
  },
  {
    "text": "thousands of jobs submitting to one uh R",
    "start": "625040",
    "end": "627959"
  },
  {
    "text": "cluster we will see see that the redis",
    "start": "627959",
    "end": "630360"
  },
  {
    "text": "record number could go even millions and",
    "start": "630360",
    "end": "632839"
  },
  {
    "text": "at that time go through traversing the",
    "start": "632839",
    "end": "634760"
  },
  {
    "text": "redis uh for the GCS could lead to very",
    "start": "634760",
    "end": "638560"
  },
  {
    "text": "long time and that's because it",
    "start": "638560",
    "end": "640839"
  },
  {
    "text": "basically goes through every table of",
    "start": "640839",
    "end": "642279"
  },
  {
    "text": "the redit to get the uh table they",
    "start": "642279",
    "end": "644720"
  },
  {
    "text": "actually want so what we do is we",
    "start": "644720",
    "end": "646959"
  },
  {
    "text": "basically try to have a radic cach to",
    "start": "646959",
    "end": "649240"
  },
  {
    "text": "improve the cury performance and open a",
    "start": "649240",
    "end": "651880"
  },
  {
    "text": "PR later on resulting the total redesign",
    "start": "651880",
    "end": "654240"
  },
  {
    "text": "of the how red is table was looked up uh",
    "start": "654240",
    "end": "656880"
  },
  {
    "text": "in the open source so now it's available",
    "start": "656880",
    "end": "658839"
  },
  {
    "text": "to everybody body and the other things",
    "start": "658839",
    "end": "661360"
  },
  {
    "text": "um due to time constraint I won't go I",
    "start": "661360",
    "end": "663040"
  },
  {
    "text": "mean detail of every aspect but we're",
    "start": "663040",
    "end": "666079"
  },
  {
    "text": "basically trying to reduce the GCS",
    "start": "666079",
    "end": "668160"
  },
  {
    "text": "pressure as Ken just mentioned so the",
    "start": "668160",
    "end": "670200"
  },
  {
    "text": "GCS will talk to drivers the GCS will",
    "start": "670200",
    "end": "672480"
  },
  {
    "text": "talk to the dashboard agent and all of",
    "start": "672480",
    "end": "674760"
  },
  {
    "text": "the things that um the key is to",
    "start": "674760",
    "end": "677760"
  },
  {
    "text": "basically reduce the GCS Communications",
    "start": "677760",
    "end": "680800"
  },
  {
    "text": "through the uh through the information",
    "start": "680800",
    "end": "683120"
  },
  {
    "text": "uh have been passed through different",
    "start": "683120",
    "end": "685279"
  },
  {
    "text": "components um the pr number is here and",
    "start": "685279",
    "end": "687880"
  },
  {
    "text": "feel free to check it out if you're",
    "start": "687880",
    "end": "689000"
  },
  {
    "text": "interested interested the next aspect is",
    "start": "689000",
    "end": "692040"
  },
  {
    "text": "how we achieve High utilization of a",
    "start": "692040",
    "end": "694240"
  },
  {
    "text": "cluster so one common question I got",
    "start": "694240",
    "end": "696279"
  },
  {
    "text": "from my boss is like okay I give you all",
    "start": "696279",
    "end": "698480"
  },
  {
    "text": "these mpus and gpus how come these",
    "start": "698480",
    "end": "700600"
  },
  {
    "text": "utilization are so low right so",
    "start": "700600",
    "end": "704399"
  },
  {
    "text": "um we tackle this problem from three",
    "start": "704399",
    "end": "707200"
  },
  {
    "text": "levels which are cluster level job level",
    "start": "707200",
    "end": "710200"
  },
  {
    "text": "and task level so at cluster level we",
    "start": "710200",
    "end": "712920"
  },
  {
    "text": "realize that uh rate open source rate",
    "start": "712920",
    "end": "715279"
  },
  {
    "text": "doesn't really have a cluster level uh",
    "start": "715279",
    "end": "717160"
  },
  {
    "text": "job job queue management kind of thing",
    "start": "717160",
    "end": "719600"
  },
  {
    "text": "so we developed something called a",
    "start": "719600",
    "end": "721480"
  },
  {
    "text": "cluster and job dispatcher uh where you",
    "start": "721480",
    "end": "723839"
  },
  {
    "text": "can actually do hot updates of the rate",
    "start": "723839",
    "end": "726160"
  },
  {
    "text": "clusters you can create read update",
    "start": "726160",
    "end": "728079"
  },
  {
    "text": "delete and all these clusters won't give",
    "start": "728079",
    "end": "731079"
  },
  {
    "text": "you a feeling for the users that you",
    "start": "731079",
    "end": "732880"
  },
  {
    "text": "know some of your works are are are are",
    "start": "732880",
    "end": "734680"
  },
  {
    "text": "done so when we s set a particular",
    "start": "734680",
    "end": "737560"
  },
  {
    "text": "cluster like a uh version one uh shows",
    "start": "737560",
    "end": "740639"
  },
  {
    "text": "here we will basically stop stop sending",
    "start": "740639",
    "end": "743519"
  },
  {
    "text": "new job request to the cluster and start",
    "start": "743519",
    "end": "745360"
  },
  {
    "text": "to send the job request to new newly",
    "start": "745360",
    "end": "747760"
  },
  {
    "text": "initialize the cluster and the old",
    "start": "747760",
    "end": "749639"
  },
  {
    "text": "cluster will be Auto scale down so that",
    "start": "749639",
    "end": "751440"
  },
  {
    "text": "new cluster can take the resources and",
    "start": "751440",
    "end": "753880"
  },
  {
    "text": "we're currently uh working progress is",
    "start": "753880",
    "end": "756120"
  },
  {
    "text": "that we want to develop some more",
    "start": "756120",
    "end": "757839"
  },
  {
    "text": "advanced Autos scaling priority policies",
    "start": "757839",
    "end": "760480"
  },
  {
    "text": "for this to uh boost the utilization of",
    "start": "760480",
    "end": "763560"
  },
  {
    "text": "a cluster",
    "start": "763560",
    "end": "765199"
  },
  {
    "text": "overall at a job level uh one thing we",
    "start": "765199",
    "end": "768199"
  },
  {
    "text": "observed is very interesting is that is",
    "start": "768199",
    "end": "770839"
  },
  {
    "text": "very hard or it requires a lot of trial",
    "start": "770839",
    "end": "773600"
  },
  {
    "text": "and eror efforts to actually decide the",
    "start": "773600",
    "end": "775800"
  },
  {
    "text": "best configuration of a particular job",
    "start": "775800",
    "end": "777600"
  },
  {
    "text": "running on the rig cluster so for",
    "start": "777600",
    "end": "779560"
  },
  {
    "text": "example here the upper one uh Cod",
    "start": "779560",
    "end": "782040"
  },
  {
    "text": "snippet requires you know the number of",
    "start": "782040",
    "end": "784399"
  },
  {
    "text": "devices which uh give you the um",
    "start": "784399",
    "end": "787160"
  },
  {
    "text": "configuration of how much um model or",
    "start": "787160",
    "end": "789480"
  },
  {
    "text": "actor needs for the mpu and the",
    "start": "789480",
    "end": "792240"
  },
  {
    "text": "concurrency number and batch size and",
    "start": "792240",
    "end": "794320"
  },
  {
    "text": "other parameters um but what we observed",
    "start": "794320",
    "end": "798000"
  },
  {
    "text": "in real setting is that the post-process",
    "start": "798000",
    "end": "800519"
  },
  {
    "text": "actors here are mostly addal which means",
    "start": "800519",
    "end": "802600"
  },
  {
    "text": "that the previous task are kind of um",
    "start": "802600",
    "end": "805240"
  },
  {
    "text": "they're they're they're short of",
    "start": "805240",
    "end": "806320"
  },
  {
    "text": "resources so we have to tune the",
    "start": "806320",
    "end": "808240"
  },
  {
    "text": "resources uh um so that the overall",
    "start": "808240",
    "end": "811240"
  },
  {
    "text": "pipeline looks fluent without bubbles",
    "start": "811240",
    "end": "813920"
  },
  {
    "text": "that no resources are basically have",
    "start": "813920",
    "end": "816000"
  },
  {
    "text": "starvations what we do end up with is",
    "start": "816000",
    "end": "818600"
  },
  {
    "text": "like we spend quite a lot of time trying",
    "start": "818600",
    "end": "820120"
  },
  {
    "text": "to tune these fistic numbers um and U",
    "start": "820120",
    "end": "824480"
  },
  {
    "text": "what we end up with is you know reduce",
    "start": "824480",
    "end": "826639"
  },
  {
    "text": "the batch size and reduce the reduce the",
    "start": "826639",
    "end": "829079"
  },
  {
    "text": "memory needs but at the it turns out it",
    "start": "829079",
    "end": "831560"
  },
  {
    "text": "can fit more models into the into the",
    "start": "831560",
    "end": "833639"
  },
  {
    "text": "mpu so that the performance actually",
    "start": "833639",
    "end": "835759"
  },
  {
    "text": "improved so we guess around 30% Improv",
    "start": "835759",
    "end": "839079"
  },
  {
    "text": "improvent on MP utilization and 25%",
    "start": "839079",
    "end": "842000"
  },
  {
    "text": "Improvement on throughput but again this",
    "start": "842000",
    "end": "843800"
  },
  {
    "text": "is really Case by case so we were trying",
    "start": "843800",
    "end": "846560"
  },
  {
    "text": "to develop something more General so",
    "start": "846560",
    "end": "848399"
  },
  {
    "text": "that you can autotune the uh job",
    "start": "848399",
    "end": "850680"
  },
  {
    "text": "configuration so that you can you",
    "start": "850680",
    "end": "852440"
  },
  {
    "text": "developers don't need to worry about",
    "start": "852440",
    "end": "853880"
  },
  {
    "text": "these configurations",
    "start": "853880",
    "end": "856000"
  },
  {
    "text": "right um the last part is uh down to the",
    "start": "856000",
    "end": "859040"
  },
  {
    "text": "ray core level so although Ray data has",
    "start": "859040",
    "end": "861720"
  },
  {
    "text": "a lot of fancy um you know back pressure",
    "start": "861720",
    "end": "864360"
  },
  {
    "text": "control but one thing they didn't do",
    "start": "864360",
    "end": "866759"
  },
  {
    "text": "well when they submit the task to record",
    "start": "866759",
    "end": "869800"
  },
  {
    "text": "is that we actually find quite a lot of",
    "start": "869800",
    "end": "872000"
  },
  {
    "text": "high memory pressure and low uh M",
    "start": "872000",
    "end": "874560"
  },
  {
    "text": "utilization so I would like to uh have a",
    "start": "874560",
    "end": "877079"
  },
  {
    "text": "quote here for from some guy who worked",
    "start": "877079",
    "end": "879560"
  },
  {
    "text": "at vrm he said you know if anything when",
    "start": "879560",
    "end": "883000"
  },
  {
    "text": "you try to say the performance",
    "start": "883000",
    "end": "884440"
  },
  {
    "text": "bottleneck of VM is actually caused by",
    "start": "884440",
    "end": "886600"
  },
  {
    "text": "CPU overhead which is actually the case",
    "start": "886600",
    "end": "888920"
  },
  {
    "text": "here so the upper L upper one you you",
    "start": "888920",
    "end": "891639"
  },
  {
    "text": "see is actually the default record",
    "start": "891639",
    "end": "893959"
  },
  {
    "text": "scheduling policy where it still follows",
    "start": "893959",
    "end": "896120"
  },
  {
    "text": "a five-fold kind of a um uh pattern to",
    "start": "896120",
    "end": "899839"
  },
  {
    "text": "give you execute CPU task first and NP",
    "start": "899839",
    "end": "902440"
  },
  {
    "text": "task later this way will result a lot of",
    "start": "902440",
    "end": "905600"
  },
  {
    "text": "intermediate data stored in the object",
    "start": "905600",
    "end": "907360"
  },
  {
    "text": "store sometimes even spill to the dis so",
    "start": "907360",
    "end": "909720"
  },
  {
    "text": "it will have very high memory pressures",
    "start": "909720",
    "end": "911880"
  },
  {
    "text": "as well as lower down the npus are",
    "start": "911880",
    "end": "914160"
  },
  {
    "text": "basically waiting for the jobs so we",
    "start": "914160",
    "end": "916959"
  },
  {
    "text": "have developed some scheduling technique",
    "start": "916959",
    "end": "919040"
  },
  {
    "text": "called Fair dispatching so this PR is",
    "start": "919040",
    "end": "921320"
  },
  {
    "text": "basically trying to solve this issue and",
    "start": "921320",
    "end": "922800"
  },
  {
    "text": "reduce the memory pressure uh and",
    "start": "922800",
    "end": "924680"
  },
  {
    "text": "improve the performance and now it's",
    "start": "924680",
    "end": "926839"
  },
  {
    "text": "basically the default recore scheduling",
    "start": "926839",
    "end": "929000"
  },
  {
    "text": "policy so everybody can use it and it's",
    "start": "929000",
    "end": "930720"
  },
  {
    "text": "not just about uh mpu it's also about",
    "start": "930720",
    "end": "933759"
  },
  {
    "text": "gpus um so the last thing is a shared uh",
    "start": "933759",
    "end": "937279"
  },
  {
    "text": "easy to use cluster where we try to",
    "start": "937279",
    "end": "939279"
  },
  {
    "text": "improve the usability of the cluster um",
    "start": "939279",
    "end": "942000"
  },
  {
    "text": "the original R dashboard as it is we",
    "start": "942000",
    "end": "943959"
  },
  {
    "text": "think is more like a cluster level",
    "start": "943959",
    "end": "945720"
  },
  {
    "text": "dashboard where you can only see the",
    "start": "945720",
    "end": "947440"
  },
  {
    "text": "cluster level information but in fact in",
    "start": "947440",
    "end": "950560"
  },
  {
    "text": "in production settings you will actually",
    "start": "950560",
    "end": "952399"
  },
  {
    "text": "have a lot of jobs like I mentioned",
    "start": "952399",
    "end": "954199"
  },
  {
    "text": "before you could have inference fine",
    "start": "954199",
    "end": "955800"
  },
  {
    "text": "tuning data processing even training all",
    "start": "955800",
    "end": "958480"
  },
  {
    "text": "happening on the same R cluster because",
    "start": "958480",
    "end": "960279"
  },
  {
    "text": "you want to fully utilize your all your",
    "start": "960279",
    "end": "962040"
  },
  {
    "text": "all your resources right but then is",
    "start": "962040",
    "end": "964880"
  },
  {
    "text": "really hard for you to tune look at each",
    "start": "964880",
    "end": "967160"
  },
  {
    "text": "job's um you know performance uh how",
    "start": "967160",
    "end": "969959"
  },
  {
    "text": "good it performs or what are the issues",
    "start": "969959",
    "end": "971800"
  },
  {
    "text": "in there so what we really want to do is",
    "start": "971800",
    "end": "974519"
  },
  {
    "text": "a um job level Ray dashboard where you",
    "start": "974519",
    "end": "978040"
  },
  {
    "text": "actually can for for each job you can",
    "start": "978040",
    "end": "979959"
  },
  {
    "text": "actually uh actually look at what of the",
    "start": "979959",
    "end": "982519"
  },
  {
    "text": "jobs topology is and how is the peline",
    "start": "982519",
    "end": "985399"
  },
  {
    "text": "of the job how much resource it takes so",
    "start": "985399",
    "end": "988959"
  },
  {
    "text": "on the on the on the right of the image",
    "start": "988959",
    "end": "991319"
  },
  {
    "text": "uh we can uh we show basically a",
    "start": "991319",
    "end": "993759"
  },
  {
    "text": "pipeline of the one of the array data",
    "start": "993759",
    "end": "996040"
  },
  {
    "text": "job running on this uh running on uh one",
    "start": "996040",
    "end": "999120"
  },
  {
    "text": "cluster and you could see you know we",
    "start": "999120",
    "end": "1001360"
  },
  {
    "text": "have the profiler we have the M usage",
    "start": "1001360",
    "end": "1003959"
  },
  {
    "text": "that we actually have logical usage and",
    "start": "1003959",
    "end": "1006279"
  },
  {
    "text": "the physical usage compar side by side",
    "start": "1006279",
    "end": "1008519"
  },
  {
    "text": "so that you know whether your logical",
    "start": "1008519",
    "end": "1010560"
  },
  {
    "text": "usage and the physical usage actually",
    "start": "1010560",
    "end": "1012880"
  },
  {
    "text": "match right and we even have dis IO and",
    "start": "1012880",
    "end": "1015560"
  },
  {
    "text": "also Network IO because this is exactly",
    "start": "1015560",
    "end": "1017720"
  },
  {
    "text": "the problem we we counters then later on",
    "start": "1017720",
    "end": "1020399"
  },
  {
    "text": "realize the network IO actually",
    "start": "1020399",
    "end": "1022519"
  },
  {
    "text": "represents a lot of data unnecessary",
    "start": "1022519",
    "end": "1024438"
  },
  {
    "text": "data movement so moving forward what we",
    "start": "1024439",
    "end": "1027400"
  },
  {
    "text": "want to do is to extract outto topology",
    "start": "1027400",
    "end": "1029798"
  },
  {
    "text": "from the ray task uh Ray job and we want",
    "start": "1029799",
    "end": "1032640"
  },
  {
    "text": "to have fine grin uh xpu resource",
    "start": "1032640",
    "end": "1035000"
  },
  {
    "text": "analysis we want to have IO analysis and",
    "start": "1035000",
    "end": "1037880"
  },
  {
    "text": "combining all these kind of information",
    "start": "1037880",
    "end": "1040120"
  },
  {
    "text": "uh hopefully we can give developers more",
    "start": "1040120",
    "end": "1042240"
  },
  {
    "text": "insight of how to use your R cluster",
    "start": "1042240",
    "end": "1045000"
  },
  {
    "text": "better okay so um finally the ke",
    "start": "1045000",
    "end": "1049080"
  },
  {
    "text": "takeaways of this talk and our future",
    "start": "1049080",
    "end": "1051400"
  },
  {
    "text": "plans so the takeaway you can say Ray is",
    "start": "1051400",
    "end": "1054160"
  },
  {
    "text": "really awesome open source Ray is",
    "start": "1054160",
    "end": "1055840"
  },
  {
    "text": "awesome but to enable Ray for hypers",
    "start": "1055840",
    "end": "1058400"
  },
  {
    "text": "scale clusters requires huge software",
    "start": "1058400",
    "end": "1061400"
  },
  {
    "text": "engineering efforts right a cluster",
    "start": "1061400",
    "end": "1063480"
  },
  {
    "text": "needs to be very stable a scalable to",
    "start": "1063480",
    "end": "1065520"
  },
  {
    "text": "Long running jobs a cluster needs to be",
    "start": "1065520",
    "end": "1067679"
  },
  {
    "text": "very efficient at cluster job or task",
    "start": "1067679",
    "end": "1070280"
  },
  {
    "text": "level and users developers need to",
    "start": "1070280",
    "end": "1073280"
  },
  {
    "text": "actually use these clusters wisely right",
    "start": "1073280",
    "end": "1076919"
  },
  {
    "text": "um our future plans will continue",
    "start": "1076919",
    "end": "1078919"
  },
  {
    "text": "working on the asend M capabilities for",
    "start": "1078919",
    "end": "1081760"
  },
  {
    "text": "sure and actually we are currently",
    "start": "1081760",
    "end": "1083919"
  },
  {
    "text": "actually working on the compiled graphs",
    "start": "1083919",
    "end": "1086440"
  },
  {
    "text": "uh actually we started like a few months",
    "start": "1086440",
    "end": "1088120"
  },
  {
    "text": "ago with the ancal team uh for these",
    "start": "1088120",
    "end": "1091039"
  },
  {
    "text": "topology aware data oriented",
    "start": "1091039",
    "end": "1092960"
  },
  {
    "text": "organizations um I remember somebody's",
    "start": "1092960",
    "end": "1095480"
  },
  {
    "text": "asked today for the compel graphs so",
    "start": "1095480",
    "end": "1097400"
  },
  {
    "text": "whether this would work for other",
    "start": "1097400",
    "end": "1099080"
  },
  {
    "text": "options other than uh uh gpus so stay",
    "start": "1099080",
    "end": "1101880"
  },
  {
    "text": "tuned for for the changes we contributed",
    "start": "1101880",
    "end": "1104159"
  },
  {
    "text": "to the open source um at the end we have",
    "start": "1104159",
    "end": "1106919"
  },
  {
    "text": "some engineering uh Improvement such as",
    "start": "1106919",
    "end": "1108799"
  },
  {
    "text": "is cluster job management with",
    "start": "1108799",
    "end": "1110360"
  },
  {
    "text": "multitenancy scalability developer",
    "start": "1110360",
    "end": "1112679"
  },
  {
    "text": "testing to to to basically say this",
    "start": "1112679",
    "end": "1114679"
  },
  {
    "text": "cluster is good for you know 2K nodes 4K",
    "start": "1114679",
    "end": "1118480"
  },
  {
    "text": "noes or 8K nodes um finally a Shameless",
    "start": "1118480",
    "end": "1122520"
  },
  {
    "text": "uh ad that U where we're hiring uh both",
    "start": "1122520",
    "end": "1125640"
  },
  {
    "text": "in Canada and China and if you're",
    "start": "1125640",
    "end": "1127679"
  },
  {
    "text": "interested please contact canes or me",
    "start": "1127679",
    "end": "1130720"
  },
  {
    "text": "and in addition we're actually hosting a",
    "start": "1130720",
    "end": "1132600"
  },
  {
    "text": "local Ray workshop on October 19th at",
    "start": "1132600",
    "end": "1135520"
  },
  {
    "text": "Shanghai in China and here is our QR",
    "start": "1135520",
    "end": "1138520"
  },
  {
    "text": "code you can scan and see our um you",
    "start": "1138520",
    "end": "1141080"
  },
  {
    "text": "know uh invited experts to talk about",
    "start": "1141080",
    "end": "1144039"
  },
  {
    "text": "how they use Ray clusters from uh",
    "start": "1144039",
    "end": "1146200"
  },
  {
    "text": "companies like band dance Alibaba and uh",
    "start": "1146200",
    "end": "1149240"
  },
  {
    "text": "uh Little Red Book yeah that would be",
    "start": "1149240",
    "end": "1151520"
  },
  {
    "text": "all thank you so",
    "start": "1151520",
    "end": "1154050"
  },
  {
    "text": "[Applause]",
    "start": "1154050",
    "end": "1158950"
  },
  {
    "text": "much uh we we can discuss offline for",
    "start": "1167000",
    "end": "1169840"
  },
  {
    "text": "question questions",
    "start": "1169840",
    "end": "1173080"
  }
]
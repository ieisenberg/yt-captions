[
  {
    "text": "uh so yeah I'm Alex Corbin I'm an",
    "start": "4980",
    "end": "7259"
  },
  {
    "text": "engineering manager at Red Hat I have my",
    "start": "7259",
    "end": "9000"
  },
  {
    "text": "colleague here Yuan Chi from IBM with me",
    "start": "9000",
    "end": "11580"
  },
  {
    "text": "um",
    "start": "11580",
    "end": "12300"
  },
  {
    "text": "and so an IBM and red hat just like",
    "start": "12300",
    "end": "14460"
  },
  {
    "text": "pretty much the rest of the world",
    "start": "14460",
    "end": "16740"
  },
  {
    "text": "we've been pretty captivated by the",
    "start": "16740",
    "end": "18720"
  },
  {
    "text": "power of AI recently",
    "start": "18720",
    "end": "20279"
  },
  {
    "text": "we're on something of a mission to",
    "start": "20279",
    "end": "22080"
  },
  {
    "text": "enable to unlock the power of AI for",
    "start": "22080",
    "end": "24420"
  },
  {
    "text": "businesses to create real value for",
    "start": "24420",
    "end": "26699"
  },
  {
    "text": "their own businesses right to enable",
    "start": "26699",
    "end": "28199"
  },
  {
    "text": "them to add value by creating their own",
    "start": "28199",
    "end": "29880"
  },
  {
    "text": "custom AI specifically their Downstream",
    "start": "29880",
    "end": "31740"
  },
  {
    "text": "use cases and so as we pursue this goal",
    "start": "31740",
    "end": "34079"
  },
  {
    "text": "we have teams of data scientists",
    "start": "34079",
    "end": "35840"
  },
  {
    "text": "creating hundreds of models using",
    "start": "35840",
    "end": "38219"
  },
  {
    "text": "thousands of gpus all leveraging the",
    "start": "38219",
    "end": "41040"
  },
  {
    "text": "power of Ray",
    "start": "41040",
    "end": "42480"
  },
  {
    "text": "and as we've scaled up this effort we've",
    "start": "42480",
    "end": "44760"
  },
  {
    "text": "created a few projects to make managing",
    "start": "44760",
    "end": "47280"
  },
  {
    "text": "all these Ray clusters these thousands",
    "start": "47280",
    "end": "49020"
  },
  {
    "text": "of Ray clusters and orchestrating these",
    "start": "49020",
    "end": "50700"
  },
  {
    "text": "hundreds and thousands of training jobs",
    "start": "50700",
    "end": "52200"
  },
  {
    "text": "to make that that process of scaling",
    "start": "52200",
    "end": "54840"
  },
  {
    "text": "that easier so in this talk we want to",
    "start": "54840",
    "end": "56940"
  },
  {
    "text": "tell you a little bit about some of",
    "start": "56940",
    "end": "58559"
  },
  {
    "text": "these key projects we've created of",
    "start": "58559",
    "end": "61199"
  },
  {
    "text": "course this is red hat and IBM",
    "start": "61199",
    "end": "63120"
  },
  {
    "text": "everything we do is open source so we'd",
    "start": "63120",
    "end": "65460"
  },
  {
    "text": "love for you to contribute to these",
    "start": "65460",
    "end": "67439"
  },
  {
    "text": "efforts or at least try out some of",
    "start": "67439",
    "end": "68820"
  },
  {
    "text": "these tools we'll be talking about we've",
    "start": "68820",
    "end": "70560"
  },
  {
    "text": "got some slides at the end of this that",
    "start": "70560",
    "end": "72119"
  },
  {
    "text": "uh with links for how you can do so",
    "start": "72119",
    "end": "74580"
  },
  {
    "text": "that so let's Dive In",
    "start": "74580",
    "end": "76619"
  },
  {
    "text": "so in this talk some of the key projects",
    "start": "76619",
    "end": "79140"
  },
  {
    "text": "we'll be talking about are the open data",
    "start": "79140",
    "end": "80759"
  },
  {
    "text": "Hub which is a project that red hat",
    "start": "80759",
    "end": "82799"
  },
  {
    "text": "started in one of its components which",
    "start": "82799",
    "end": "84900"
  },
  {
    "text": "is data science pipelines as well as the",
    "start": "84900",
    "end": "87060"
  },
  {
    "text": "code flare project that we started",
    "start": "87060",
    "end": "88259"
  },
  {
    "text": "jointly with IBM",
    "start": "88259",
    "end": "90060"
  },
  {
    "text": "share how at IBM we're using gray to",
    "start": "90060",
    "end": "92880"
  },
  {
    "text": "prepare data for generative AI training",
    "start": "92880",
    "end": "94860"
  },
  {
    "text": "and then training those models using Rey",
    "start": "94860",
    "end": "97799"
  },
  {
    "text": "on uh on code flare and openshift using",
    "start": "97799",
    "end": "100860"
  },
  {
    "text": "the open data Hub and orchestrating all",
    "start": "100860",
    "end": "102720"
  },
  {
    "text": "that with data science pipelines we'll",
    "start": "102720",
    "end": "105119"
  },
  {
    "text": "have a demo of that and finally we'll",
    "start": "105119",
    "end": "106500"
  },
  {
    "text": "discuss some some lessons learned some",
    "start": "106500",
    "end": "108119"
  },
  {
    "text": "Next Step next steps rather I I'm going",
    "start": "108119",
    "end": "111180"
  },
  {
    "text": "to lay the kind of the groundwork with",
    "start": "111180",
    "end": "113100"
  },
  {
    "text": "introducing a lot of these a lot of",
    "start": "113100",
    "end": "114600"
  },
  {
    "text": "these projects and I'll hand it over to",
    "start": "114600",
    "end": "116280"
  },
  {
    "text": "you on tune in a couple minutes to",
    "start": "116280",
    "end": "117420"
  },
  {
    "text": "really show you the interesting cool",
    "start": "117420",
    "end": "118979"
  },
  {
    "text": "stuff that we're doing with them",
    "start": "118979",
    "end": "119939"
  },
  {
    "text": "together",
    "start": "119939",
    "end": "121740"
  },
  {
    "text": "we're hoping to leave today's talk with",
    "start": "121740",
    "end": "123299"
  },
  {
    "text": "just a few key takeaway messages this is",
    "start": "123299",
    "end": "126180"
  },
  {
    "text": "of course Ray Summit right we've we",
    "start": "126180",
    "end": "128099"
  },
  {
    "text": "think that Rey is is the best tool out",
    "start": "128099",
    "end": "130259"
  },
  {
    "text": "there today for doing data preparation",
    "start": "130259",
    "end": "132000"
  },
  {
    "text": "tuning training serving of of models to",
    "start": "132000",
    "end": "136680"
  },
  {
    "text": "build intelligent applications",
    "start": "136680",
    "end": "139500"
  },
  {
    "text": "one step further we think that",
    "start": "139500",
    "end": "141300"
  },
  {
    "text": "kubernetes is the best platform for",
    "start": "141300",
    "end": "143220"
  },
  {
    "text": "running Ray clusters in large part",
    "start": "143220",
    "end": "145260"
  },
  {
    "text": "thanks to the the the great capabilities",
    "start": "145260",
    "end": "147840"
  },
  {
    "text": "kubernetes gives you around scaling and",
    "start": "147840",
    "end": "150959"
  },
  {
    "text": "flexibility of how you deploy your right",
    "start": "150959",
    "end": "153120"
  },
  {
    "text": "clusters",
    "start": "153120",
    "end": "154680"
  },
  {
    "text": "started the code glare project and that",
    "start": "154680",
    "end": "156540"
  },
  {
    "text": "makes it really easy for data scientists",
    "start": "156540",
    "end": "158340"
  },
  {
    "text": "to deploy Ray clusters we'll show you",
    "start": "158340",
    "end": "160680"
  },
  {
    "text": "more about that finally we use the data",
    "start": "160680",
    "end": "162780"
  },
  {
    "text": "science pipelines component of the open",
    "start": "162780",
    "end": "164220"
  },
  {
    "text": "data Hub to chain together all the",
    "start": "164220",
    "end": "166379"
  },
  {
    "text": "really complex heterogeneous tasks",
    "start": "166379",
    "end": "168780"
  },
  {
    "text": "multiple Ray clusters in a given",
    "start": "168780",
    "end": "170700"
  },
  {
    "text": "workload we use data science pipelines",
    "start": "170700",
    "end": "172560"
  },
  {
    "text": "to make that easy and repeatable",
    "start": "172560",
    "end": "174840"
  },
  {
    "text": "I'm going to start by showing you the",
    "start": "174840",
    "end": "176700"
  },
  {
    "text": "open data project",
    "start": "176700",
    "end": "179160"
  },
  {
    "text": "so the open data Hub is a project that",
    "start": "179160",
    "end": "181080"
  },
  {
    "text": "red hat founded a few years ago AI we",
    "start": "181080",
    "end": "184260"
  },
  {
    "text": "think is driven by open source I think",
    "start": "184260",
    "end": "186120"
  },
  {
    "text": "it's pretty unquestionable at this point",
    "start": "186120",
    "end": "187560"
  },
  {
    "text": "that AI that open source is the new",
    "start": "187560",
    "end": "189480"
  },
  {
    "text": "model for Innovation particularly in AI",
    "start": "189480",
    "end": "192840"
  },
  {
    "text": "everything from pytorch to Ray to",
    "start": "192840",
    "end": "194879"
  },
  {
    "text": "tensorflow are all advancing at",
    "start": "194879",
    "end": "196560"
  },
  {
    "text": "ridiculous speeds due to the",
    "start": "196560",
    "end": "198780"
  },
  {
    "text": "collaborative contributions from a",
    "start": "198780",
    "end": "200459"
  },
  {
    "text": "strong open source communities Red Hat",
    "start": "200459",
    "end": "202860"
  },
  {
    "text": "bleeds open source we've established the",
    "start": "202860",
    "end": "205920"
  },
  {
    "text": "open dataub project to bring together",
    "start": "205920",
    "end": "207599"
  },
  {
    "text": "lots of discrete open source communities",
    "start": "207599",
    "end": "210420"
  },
  {
    "text": "into a single cohesive platform all",
    "start": "210420",
    "end": "212819"
  },
  {
    "text": "running on on openshift which is red",
    "start": "212819",
    "end": "214379"
  },
  {
    "text": "Hat's kubernetes distribution",
    "start": "214379",
    "end": "217379"
  },
  {
    "text": "uh really the key value proposition is",
    "start": "217379",
    "end": "220440"
  },
  {
    "text": "that by running really nicely on",
    "start": "220440",
    "end": "222599"
  },
  {
    "text": "openshift uh which runs wherever your",
    "start": "222599",
    "end": "226440"
  },
  {
    "text": "compute power is be it on-prem in the CR",
    "start": "226440",
    "end": "228659"
  },
  {
    "text": "in the cloud even at the edge",
    "start": "228659",
    "end": "230760"
  },
  {
    "text": "um we give you a full end-to-end",
    "start": "230760",
    "end": "232379"
  },
  {
    "text": "platform that is consistent across all",
    "start": "232379",
    "end": "234599"
  },
  {
    "text": "those in all those environments uh again",
    "start": "234599",
    "end": "237659"
  },
  {
    "text": "open data Hub consists of many different",
    "start": "237659",
    "end": "239760"
  },
  {
    "text": "components Rey being one of them via",
    "start": "239760",
    "end": "242400"
  },
  {
    "text": "Cube Ray and with the full Suite of of",
    "start": "242400",
    "end": "244799"
  },
  {
    "text": "tools in the open data Hub a data",
    "start": "244799",
    "end": "246780"
  },
  {
    "text": "scientist can spin up a jupyter notebook",
    "start": "246780",
    "end": "249120"
  },
  {
    "text": "to develop a model they can create a ray",
    "start": "249120",
    "end": "250980"
  },
  {
    "text": "cluster to prepare data they can spin up",
    "start": "250980",
    "end": "253439"
  },
  {
    "text": "another rate cluster to train their",
    "start": "253439",
    "end": "254819"
  },
  {
    "text": "model they can take the resultant model",
    "start": "254819",
    "end": "257040"
  },
  {
    "text": "and serve it maybe in a totally",
    "start": "257040",
    "end": "258840"
  },
  {
    "text": "different Cloud environment they can",
    "start": "258840",
    "end": "261540"
  },
  {
    "text": "spin all these complex or chain all",
    "start": "261540",
    "end": "263759"
  },
  {
    "text": "these complex tasks together into",
    "start": "263759",
    "end": "265020"
  },
  {
    "text": "repeatable pipelines and put all that",
    "start": "265020",
    "end": "267180"
  },
  {
    "text": "and get ups and again the open data Hub",
    "start": "267180",
    "end": "268860"
  },
  {
    "text": "gives you the tools to do all this in",
    "start": "268860",
    "end": "270960"
  },
  {
    "text": "kubernetes and openshift",
    "start": "270960",
    "end": "274220"
  },
  {
    "text": "I mentioned the open data Hub is is many",
    "start": "274380",
    "end": "276660"
  },
  {
    "text": "different components one of them that is",
    "start": "276660",
    "end": "279180"
  },
  {
    "text": "is really key to what yunq is going to",
    "start": "279180",
    "end": "281639"
  },
  {
    "text": "share is called data science pipelines",
    "start": "281639",
    "end": "283340"
  },
  {
    "text": "so if you're familiar with the Upstream",
    "start": "283340",
    "end": "285419"
  },
  {
    "text": "kubeflow pipelines project data science",
    "start": "285419",
    "end": "287160"
  },
  {
    "text": "pipelines is based on that and it allows",
    "start": "287160",
    "end": "289680"
  },
  {
    "text": "data scientists and ml Ops professionals",
    "start": "289680",
    "end": "291660"
  },
  {
    "text": "again to chain together any complex",
    "start": "291660",
    "end": "294240"
  },
  {
    "text": "tasks into repeatable workflows",
    "start": "294240",
    "end": "296580"
  },
  {
    "text": "chances are when you train and serve",
    "start": "296580",
    "end": "299280"
  },
  {
    "text": "your model you're you're probably not",
    "start": "299280",
    "end": "301080"
  },
  {
    "text": "done with it right in our experience you",
    "start": "301080",
    "end": "303479"
  },
  {
    "text": "probably are going to want to retrain it",
    "start": "303479",
    "end": "304740"
  },
  {
    "text": "again on new data you might want to",
    "start": "304740",
    "end": "306540"
  },
  {
    "text": "tweak the hyper parameters a little bit",
    "start": "306540",
    "end": "308540"
  },
  {
    "text": "and that can be quite complex right UNG",
    "start": "308540",
    "end": "311580"
  },
  {
    "text": "is going to talk in depth about this but",
    "start": "311580",
    "end": "313620"
  },
  {
    "text": "data preparation often requires",
    "start": "313620",
    "end": "315300"
  },
  {
    "text": "significant compute resources and tools",
    "start": "315300",
    "end": "317400"
  },
  {
    "text": "like Ray to be able to process the data",
    "start": "317400",
    "end": "319259"
  },
  {
    "text": "training models takes you know",
    "start": "319259",
    "end": "321660"
  },
  {
    "text": "completely different Hardware oftentimes",
    "start": "321660",
    "end": "324120"
  },
  {
    "text": "usually requiring pretty specialized",
    "start": "324120",
    "end": "325979"
  },
  {
    "text": "gpus maybe you have really critical",
    "start": "325979",
    "end": "328620"
  },
  {
    "text": "business logic that you want to make",
    "start": "328620",
    "end": "330060"
  },
  {
    "text": "sure it gets consistently applied across",
    "start": "330060",
    "end": "332639"
  },
  {
    "text": "your teams of data scientists",
    "start": "332639",
    "end": "334500"
  },
  {
    "text": "again like this requires gluing together",
    "start": "334500",
    "end": "337320"
  },
  {
    "text": "many different discrete tools into",
    "start": "337320",
    "end": "339000"
  },
  {
    "text": "repeatable ways and we do so at IBM",
    "start": "339000",
    "end": "342000"
  },
  {
    "text": "using this data science pipelines tool",
    "start": "342000",
    "end": "344880"
  },
  {
    "text": "um in the workflows we develop and run",
    "start": "344880",
    "end": "347100"
  },
  {
    "text": "Ray plays a really critical role",
    "start": "347100",
    "end": "350340"
  },
  {
    "text": "um",
    "start": "350340",
    "end": "351300"
  },
  {
    "text": "our data scientists again and the the",
    "start": "351300",
    "end": "353580"
  },
  {
    "text": "course of creating hundreds of models we",
    "start": "353580",
    "end": "355740"
  },
  {
    "text": "spin up thousands of different Ray",
    "start": "355740",
    "end": "357120"
  },
  {
    "text": "clusters all with really you know custom",
    "start": "357120",
    "end": "359220"
  },
  {
    "text": "tailored fit compute requirements number",
    "start": "359220",
    "end": "361740"
  },
  {
    "text": "of worker nodes Etc",
    "start": "361740",
    "end": "364080"
  },
  {
    "text": "and openshift gives us the perfect",
    "start": "364080",
    "end": "365880"
  },
  {
    "text": "platform to providing easy access to the",
    "start": "365880",
    "end": "368699"
  },
  {
    "text": "underlying compute resources but we",
    "start": "368699",
    "end": "371039"
  },
  {
    "text": "needed a way to make it easy for data",
    "start": "371039",
    "end": "372539"
  },
  {
    "text": "scientists to actually request those",
    "start": "372539",
    "end": "374280"
  },
  {
    "text": "raid clusters and at the same time we",
    "start": "374280",
    "end": "375900"
  },
  {
    "text": "need to make it easy for our it",
    "start": "375900",
    "end": "377580"
  },
  {
    "text": "operations teams to give those teams of",
    "start": "377580",
    "end": "381180"
  },
  {
    "text": "data scientists Fair access to compute",
    "start": "381180",
    "end": "383280"
  },
  {
    "text": "resources and also make sure that",
    "start": "383280",
    "end": "384840"
  },
  {
    "text": "compute costs didn't just Spyro out of",
    "start": "384840",
    "end": "386699"
  },
  {
    "text": "control",
    "start": "386699",
    "end": "388139"
  },
  {
    "text": "this is where the code flare project",
    "start": "388139",
    "end": "389460"
  },
  {
    "text": "comes in so uh just real quick we'll",
    "start": "389460",
    "end": "392280"
  },
  {
    "text": "touch briefly on codeflare here but one",
    "start": "392280",
    "end": "395340"
  },
  {
    "text": "of my colleagues Mustafa will be giving",
    "start": "395340",
    "end": "396720"
  },
  {
    "text": "a more in-depth lightning talk on this",
    "start": "396720",
    "end": "398400"
  },
  {
    "text": "tomorrow at 11 45 so if you're if you're",
    "start": "398400",
    "end": "401160"
  },
  {
    "text": "peaked to I Peak your interest with",
    "start": "401160",
    "end": "402539"
  },
  {
    "text": "codeflare here be sure to attend his",
    "start": "402539",
    "end": "404160"
  },
  {
    "text": "talk to to see it in action more",
    "start": "404160",
    "end": "407280"
  },
  {
    "text": "um anyways as we started using Ray",
    "start": "407280",
    "end": "409139"
  },
  {
    "text": "heavily we wanted to make it easier for",
    "start": "409139",
    "end": "411120"
  },
  {
    "text": "our data scientists to provision rate",
    "start": "411120",
    "end": "413340"
  },
  {
    "text": "clusters suited Theory requirements",
    "start": "413340",
    "end": "415919"
  },
  {
    "text": "we also wanted to make sure that we",
    "start": "415919",
    "end": "417300"
  },
  {
    "text": "could ensure Fair access to compute",
    "start": "417300",
    "end": "418979"
  },
  {
    "text": "resources across our data science teams",
    "start": "418979",
    "end": "422160"
  },
  {
    "text": "while at the same time allowing for like",
    "start": "422160",
    "end": "424620"
  },
  {
    "text": "critical high priority training jobs to",
    "start": "424620",
    "end": "427020"
  },
  {
    "text": "take priority so we created the code",
    "start": "427020",
    "end": "429360"
  },
  {
    "text": "flare project to kind of achieve these",
    "start": "429360",
    "end": "431280"
  },
  {
    "text": "goals",
    "start": "431280",
    "end": "432539"
  },
  {
    "text": "code flare is just a set of Open Source",
    "start": "432539",
    "end": "435120"
  },
  {
    "text": "tools",
    "start": "435120",
    "end": "436340"
  },
  {
    "text": "that help with scaling up Ray and other",
    "start": "436340",
    "end": "439440"
  },
  {
    "text": "AIML workloads on kubernetes",
    "start": "439440",
    "end": "441960"
  },
  {
    "text": "we created the code player SDK which",
    "start": "441960",
    "end": "444539"
  },
  {
    "text": "contains really simple easy use",
    "start": "444539",
    "end": "446340"
  },
  {
    "text": "abstractions for deploying Ray clusters",
    "start": "446340",
    "end": "448319"
  },
  {
    "text": "onto kubernetes and then managing the",
    "start": "448319",
    "end": "450240"
  },
  {
    "text": "full life cycle of those Ray clusters",
    "start": "450240",
    "end": "452039"
  },
  {
    "text": "including submitting training and tuning",
    "start": "452039",
    "end": "454319"
  },
  {
    "text": "in data processing jobs to them",
    "start": "454319",
    "end": "457199"
  },
  {
    "text": "we created the multi-cluster app",
    "start": "457199",
    "end": "458940"
  },
  {
    "text": "dispatcher or mcad which provides the",
    "start": "458940",
    "end": "462360"
  },
  {
    "text": "notion of a job queue so that as data",
    "start": "462360",
    "end": "464880"
  },
  {
    "text": "scientists are submitting resource",
    "start": "464880",
    "end": "467099"
  },
  {
    "text": "requests to provision rate clusters all",
    "start": "467099",
    "end": "469740"
  },
  {
    "text": "those requests get balanced and we can",
    "start": "469740",
    "end": "471300"
  },
  {
    "text": "apply priorities to them we can apply",
    "start": "471300",
    "end": "472979"
  },
  {
    "text": "quotas to teams and teams can share",
    "start": "472979",
    "end": "474900"
  },
  {
    "text": "quotas from each other",
    "start": "474900",
    "end": "477000"
  },
  {
    "text": "um and then really the Third Leg of this",
    "start": "477000",
    "end": "479099"
  },
  {
    "text": "the code flare stack is called",
    "start": "479099",
    "end": "480360"
  },
  {
    "text": "instascale which watches that queue of",
    "start": "480360",
    "end": "482759"
  },
  {
    "text": "jobs and can automatically dynamically",
    "start": "482759",
    "end": "484500"
  },
  {
    "text": "scale up and down the openshift cluster",
    "start": "484500",
    "end": "486240"
  },
  {
    "text": "so your openshift cluster need not",
    "start": "486240",
    "end": "488340"
  },
  {
    "text": "consume nodes with gpus and incur",
    "start": "488340",
    "end": "490800"
  },
  {
    "text": "ridiculous costs when you're not using",
    "start": "490800",
    "end": "492360"
  },
  {
    "text": "those gpus",
    "start": "492360",
    "end": "493940"
  },
  {
    "text": "and all of this runs natively on",
    "start": "493940",
    "end": "496979"
  },
  {
    "text": "kubernetes and so we get super easy",
    "start": "496979",
    "end": "499440"
  },
  {
    "text": "flexibility across the AIML life cycle",
    "start": "499440",
    "end": "502080"
  },
  {
    "text": "you can train your models in one",
    "start": "502080",
    "end": "503639"
  },
  {
    "text": "location maybe it's on-prem in a lot of",
    "start": "503639",
    "end": "505560"
  },
  {
    "text": "cases we are our customers have like",
    "start": "505560",
    "end": "507840"
  },
  {
    "text": "specialized local compute GPU locally in",
    "start": "507840",
    "end": "510960"
  },
  {
    "text": "their data centers or maybe they need to",
    "start": "510960",
    "end": "512459"
  },
  {
    "text": "keep their data residing for training",
    "start": "512459",
    "end": "514800"
  },
  {
    "text": "on-prem and you can use kubernetes and",
    "start": "514800",
    "end": "516959"
  },
  {
    "text": "our code flare stack there",
    "start": "516959",
    "end": "518700"
  },
  {
    "text": "but then maybe they want to use the",
    "start": "518700",
    "end": "520680"
  },
  {
    "text": "public Cloud to be able to dynamically",
    "start": "520680",
    "end": "522419"
  },
  {
    "text": "scale up and down serving their models",
    "start": "522419",
    "end": "524159"
  },
  {
    "text": "in production based on you know as",
    "start": "524159",
    "end": "525899"
  },
  {
    "text": "production traffic fluctuates right and",
    "start": "525899",
    "end": "528120"
  },
  {
    "text": "you can do all this kubernetes gives us",
    "start": "528120",
    "end": "530220"
  },
  {
    "text": "a consistent platform across all those",
    "start": "530220",
    "end": "532260"
  },
  {
    "text": "environments",
    "start": "532260",
    "end": "534720"
  },
  {
    "text": "so",
    "start": "534720",
    "end": "535980"
  },
  {
    "text": "kind of closing up here with code flare",
    "start": "535980",
    "end": "538140"
  },
  {
    "text": "a data scientist gets a familiar",
    "start": "538140",
    "end": "540060"
  },
  {
    "text": "pythonic interface for resource and job",
    "start": "540060",
    "end": "542040"
  },
  {
    "text": "management they get seamless integration",
    "start": "542040",
    "end": "544380"
  },
  {
    "text": "with the training tools of their choice",
    "start": "544380",
    "end": "545700"
  },
  {
    "text": "like Pi torch tensorflow",
    "start": "545700",
    "end": "547800"
  },
  {
    "text": "they get guaranteed access to the",
    "start": "547800",
    "end": "550019"
  },
  {
    "text": "resources they request the ability to",
    "start": "550019",
    "end": "552000"
  },
  {
    "text": "fire forget a large unattended training",
    "start": "552000",
    "end": "554279"
  },
  {
    "text": "job that maybe runs for weeks and",
    "start": "554279",
    "end": "556140"
  },
  {
    "text": "finally they get the ability to",
    "start": "556140",
    "end": "557459"
  },
  {
    "text": "interactively iterate over their model",
    "start": "557459",
    "end": "559800"
  },
  {
    "text": "development against the ray cluster they",
    "start": "559800",
    "end": "561420"
  },
  {
    "text": "request at the same time our it",
    "start": "561420",
    "end": "563700"
  },
  {
    "text": "operations teams get simple management",
    "start": "563700",
    "end": "565620"
  },
  {
    "text": "of resource quota across data Sciences",
    "start": "565620",
    "end": "567779"
  },
  {
    "text": "teams through quotas jobs priorities Etc",
    "start": "567779",
    "end": "570000"
  },
  {
    "text": "they get these simple application stack",
    "start": "570000",
    "end": "572820"
  },
  {
    "text": "through kubernetes and code flare across",
    "start": "572820",
    "end": "574920"
  },
  {
    "text": "their Computing environments and finally",
    "start": "574920",
    "end": "576839"
  },
  {
    "text": "they realize compute cost savings",
    "start": "576839",
    "end": "578339"
  },
  {
    "text": "through Dynamic resource scaling",
    "start": "578339",
    "end": "580620"
  },
  {
    "text": "I'm going to turn it over to you on",
    "start": "580620",
    "end": "581760"
  },
  {
    "text": "chino who's going to talk about how",
    "start": "581760",
    "end": "583140"
  },
  {
    "text": "we're combining all three of these",
    "start": "583140",
    "end": "585060"
  },
  {
    "text": "projects to do generative AI work at IBM",
    "start": "585060",
    "end": "588480"
  },
  {
    "text": "thank you Alex",
    "start": "588480",
    "end": "591199"
  },
  {
    "text": "hi my name is juanji Chang I work for",
    "start": "591240",
    "end": "593519"
  },
  {
    "text": "IBM research and pleasure to be here and",
    "start": "593519",
    "end": "596279"
  },
  {
    "text": "this morning you have been hearing a lot",
    "start": "596279",
    "end": "598860"
  },
  {
    "text": "about model training fine tuning",
    "start": "598860",
    "end": "601680"
  },
  {
    "text": "influencing of these exciting uh",
    "start": "601680",
    "end": "606420"
  },
  {
    "text": "generative AI models I'm not going to",
    "start": "606420",
    "end": "609959"
  },
  {
    "text": "talk about them that will be the topic",
    "start": "609959",
    "end": "612360"
  },
  {
    "text": "for our end-to-end Target tomorrow",
    "start": "612360",
    "end": "615480"
  },
  {
    "text": "afternoon instead I want to share with",
    "start": "615480",
    "end": "618300"
  },
  {
    "text": "you what goes into the process of model",
    "start": "618300",
    "end": "621360"
  },
  {
    "text": "training and fine-tuning I.E the data",
    "start": "621360",
    "end": "624720"
  },
  {
    "text": "prep",
    "start": "624720",
    "end": "625500"
  },
  {
    "text": "you get what you your data learned so",
    "start": "625500",
    "end": "629459"
  },
  {
    "text": "data prep is really really important",
    "start": "629459",
    "end": "632100"
  },
  {
    "text": "then to train such generative AI models",
    "start": "632100",
    "end": "636240"
  },
  {
    "text": "the quality of the input documents are",
    "start": "636240",
    "end": "640260"
  },
  {
    "text": "critically important",
    "start": "640260",
    "end": "642060"
  },
  {
    "text": "if your documents going in with lots of",
    "start": "642060",
    "end": "645720"
  },
  {
    "text": "hate speech and curse words your model",
    "start": "645720",
    "end": "648600"
  },
  {
    "text": "most likely will give you curse words",
    "start": "648600",
    "end": "650640"
  },
  {
    "text": "and hate speeches and therefore",
    "start": "650640",
    "end": "653519"
  },
  {
    "text": "it's important that we actually have",
    "start": "653519",
    "end": "656820"
  },
  {
    "text": "quality improvement and annotation steps",
    "start": "656820",
    "end": "661019"
  },
  {
    "text": "to analyze the content remove the",
    "start": "661019",
    "end": "664740"
  },
  {
    "text": "offensive uh content as well as track",
    "start": "664740",
    "end": "668700"
  },
  {
    "text": "the rights uh personal identifiable",
    "start": "668700",
    "end": "672300"
  },
  {
    "text": "information",
    "start": "672300",
    "end": "673500"
  },
  {
    "text": "Etc it's a sequence of data processing",
    "start": "673500",
    "end": "677399"
  },
  {
    "text": "pipelines before we feed them into model",
    "start": "677399",
    "end": "680339"
  },
  {
    "text": "training and tune it",
    "start": "680339",
    "end": "682560"
  },
  {
    "text": "today at IBM the majority of these",
    "start": "682560",
    "end": "685079"
  },
  {
    "text": "processing stages are built on Ray for",
    "start": "685079",
    "end": "688200"
  },
  {
    "text": "scaling from",
    "start": "688200",
    "end": "690120"
  },
  {
    "text": "to tens and hundreds of terabytes of",
    "start": "690120",
    "end": "693540"
  },
  {
    "text": "text documents across different domains",
    "start": "693540",
    "end": "696300"
  },
  {
    "text": "and multiple different languages",
    "start": "696300",
    "end": "698519"
  },
  {
    "text": "and I can speak for article developers",
    "start": "698519",
    "end": "701160"
  },
  {
    "text": "we like array enable EG's transition",
    "start": "701160",
    "end": "703800"
  },
  {
    "text": "because we can",
    "start": "703800",
    "end": "705660"
  },
  {
    "text": "develop and test on a laptop and then",
    "start": "705660",
    "end": "709260"
  },
  {
    "text": "suit the Innovative approach of using",
    "start": "709260",
    "end": "712560"
  },
  {
    "text": "Ray we can scale up to pass so much data",
    "start": "712560",
    "end": "716160"
  },
  {
    "text": "furthermore over time the past two",
    "start": "716160",
    "end": "719640"
  },
  {
    "text": "decades IBM research has accumulated",
    "start": "719640",
    "end": "723019"
  },
  {
    "text": "significant amount of intellectual",
    "start": "723019",
    "end": "725760"
  },
  {
    "text": "property which with natural language",
    "start": "725760",
    "end": "728339"
  },
  {
    "text": "processing and they can be reused and",
    "start": "728339",
    "end": "732120"
  },
  {
    "text": "revitalized through the use of rainforce",
    "start": "732120",
    "end": "735779"
  },
  {
    "text": "scaled processing and finally these",
    "start": "735779",
    "end": "739980"
  },
  {
    "text": "pipelines are orchestrated by open data",
    "start": "739980",
    "end": "743339"
  },
  {
    "text": "Hub as Alex just introduced to you",
    "start": "743339",
    "end": "747600"
  },
  {
    "text": "so over the past couple of decades IBM",
    "start": "747600",
    "end": "751560"
  },
  {
    "text": "was a natural language processing",
    "start": "751560",
    "end": "753959"
  },
  {
    "text": "library has a long Legacy of doing",
    "start": "753959",
    "end": "757279"
  },
  {
    "text": "multi-language detection entity",
    "start": "757279",
    "end": "760320"
  },
  {
    "text": "extraction",
    "start": "760320",
    "end": "761519"
  },
  {
    "text": "task classification among many things",
    "start": "761519",
    "end": "764940"
  },
  {
    "text": "and the challenge of reusing these",
    "start": "764940",
    "end": "767519"
  },
  {
    "text": "language the library is that that they",
    "start": "767519",
    "end": "770279"
  },
  {
    "text": "were originally developed for Standalone",
    "start": "770279",
    "end": "772200"
  },
  {
    "text": "environment",
    "start": "772200",
    "end": "774180"
  },
  {
    "text": "um they may have a c or Java code base",
    "start": "774180",
    "end": "777600"
  },
  {
    "text": "and finally",
    "start": "777600",
    "end": "779459"
  },
  {
    "text": "lots of unique dependencies versioning",
    "start": "779459",
    "end": "782459"
  },
  {
    "text": "and over time security patches",
    "start": "782459",
    "end": "785160"
  },
  {
    "text": "so it's not very straightforward",
    "start": "785160",
    "end": "788420"
  },
  {
    "text": "to actually scaling them out",
    "start": "788420",
    "end": "791880"
  },
  {
    "text": "and as we",
    "start": "791880",
    "end": "793740"
  },
  {
    "text": "um",
    "start": "793740",
    "end": "794279"
  },
  {
    "text": "Bank on the capability of kubernetes and",
    "start": "794279",
    "end": "797279"
  },
  {
    "text": "openshift cluster",
    "start": "797279",
    "end": "799260"
  },
  {
    "text": "we are containerizing these Legacy",
    "start": "799260",
    "end": "802560"
  },
  {
    "text": "modules uh into python code base with",
    "start": "802560",
    "end": "807180"
  },
  {
    "text": "the dependency and the environment",
    "start": "807180",
    "end": "809220"
  },
  {
    "text": "variable specific to these Legacy",
    "start": "809220",
    "end": "813240"
  },
  {
    "text": "libraries and then we isolate the states",
    "start": "813240",
    "end": "816240"
  },
  {
    "text": "when people talk about",
    "start": "816240",
    "end": "819200"
  },
  {
    "text": "these document pre-processing they don't",
    "start": "819200",
    "end": "822540"
  },
  {
    "text": "normally associate with these document",
    "start": "822540",
    "end": "825000"
  },
  {
    "text": "preposition with specialized language",
    "start": "825000",
    "end": "828899"
  },
  {
    "text": "models these may be smaller fine-tuned",
    "start": "828899",
    "end": "832380"
  },
  {
    "text": "language models that are",
    "start": "832380",
    "end": "835079"
  },
  {
    "text": "focusing on specific aspect such as Hape",
    "start": "835079",
    "end": "839040"
  },
  {
    "text": "speech detection those models need to be",
    "start": "839040",
    "end": "842220"
  },
  {
    "text": "brought in with their own dependencies",
    "start": "842220",
    "end": "844560"
  },
  {
    "text": "as well so the containerization process",
    "start": "844560",
    "end": "848220"
  },
  {
    "text": "essentially shrinks up these",
    "start": "848220",
    "end": "849899"
  },
  {
    "text": "capabilities so that we can launch parts",
    "start": "849899",
    "end": "852800"
  },
  {
    "text": "that",
    "start": "852800",
    "end": "854420"
  },
  {
    "text": "offer these distinct capabilities",
    "start": "854420",
    "end": "858540"
  },
  {
    "text": "the railing enablement is really the",
    "start": "858540",
    "end": "860700"
  },
  {
    "text": "last step",
    "start": "860700",
    "end": "862100"
  },
  {
    "text": "that allows us to scale out these",
    "start": "862100",
    "end": "865200"
  },
  {
    "text": "containerized process",
    "start": "865200",
    "end": "867600"
  },
  {
    "text": "now I will dip into a little bit deeper",
    "start": "867600",
    "end": "870240"
  },
  {
    "text": "about what we how we use red",
    "start": "870240",
    "end": "873079"
  },
  {
    "text": "specifically we use Ray actors",
    "start": "873079",
    "end": "876600"
  },
  {
    "text": "what happens to these specific tasks is",
    "start": "876600",
    "end": "880199"
  },
  {
    "text": "we have a typically a test driver",
    "start": "880199",
    "end": "883199"
  },
  {
    "text": "which will then dispatch assignments of",
    "start": "883199",
    "end": "885899"
  },
  {
    "text": "the shards of deja in this case possibly",
    "start": "885899",
    "end": "888779"
  },
  {
    "text": "a partition of the collection with",
    "start": "888779",
    "end": "892440"
  },
  {
    "text": "parquet files and these test workers are",
    "start": "892440",
    "end": "895380"
  },
  {
    "text": "actually implemented as reactors which",
    "start": "895380",
    "end": "898079"
  },
  {
    "text": "load the specific state in the custom",
    "start": "898079",
    "end": "902339"
  },
  {
    "text": "container image and this comes custom",
    "start": "902339",
    "end": "905220"
  },
  {
    "text": "container images contain the proper",
    "start": "905220",
    "end": "908459"
  },
  {
    "text": "resource footprint and dependencies such",
    "start": "908459",
    "end": "911399"
  },
  {
    "text": "that the model and Library once loaded",
    "start": "911399",
    "end": "914279"
  },
  {
    "text": "can be subsequently applied in in the",
    "start": "914279",
    "end": "918540"
  },
  {
    "text": "cost to",
    "start": "918540",
    "end": "919680"
  },
  {
    "text": "uh finish the assignments given by the",
    "start": "919680",
    "end": "923220"
  },
  {
    "text": "uh test driver",
    "start": "923220",
    "end": "925620"
  },
  {
    "text": "the interaction mostly happened against",
    "start": "925620",
    "end": "928199"
  },
  {
    "text": "an object storage where the parquet",
    "start": "928199",
    "end": "932040"
  },
  {
    "text": "files gets ready and the parquet files",
    "start": "932040",
    "end": "934440"
  },
  {
    "text": "after processing gets written out",
    "start": "934440",
    "end": "938760"
  },
  {
    "text": "um the we truly leverage we raise uh",
    "start": "938760",
    "end": "942300"
  },
  {
    "text": "checkpoint and Recovery mechanism of the",
    "start": "942300",
    "end": "945660"
  },
  {
    "text": "reactors such that in case of a failure",
    "start": "945660",
    "end": "949019"
  },
  {
    "text": "we can",
    "start": "949019",
    "end": "950160"
  },
  {
    "text": "uh return that",
    "start": "950160",
    "end": "952380"
  },
  {
    "text": "now come to the the nature of the data",
    "start": "952380",
    "end": "958079"
  },
  {
    "text": "stage data State Pipeline",
    "start": "958079",
    "end": "961940"
  },
  {
    "text": "we as you can see in this picture we",
    "start": "961940",
    "end": "965279"
  },
  {
    "text": "have three different colors of kubrey",
    "start": "965279",
    "end": "967920"
  },
  {
    "text": "deployment",
    "start": "967920",
    "end": "969000"
  },
  {
    "text": "to code fair and specifically",
    "start": "969000",
    "end": "972320"
  },
  {
    "text": "each of them actually have their own",
    "start": "972320",
    "end": "974579"
  },
  {
    "text": "different footprint",
    "start": "974579",
    "end": "976139"
  },
  {
    "text": "Custom Image and environment and they",
    "start": "976139",
    "end": "979620"
  },
  {
    "text": "are all orchestrated from open data hub",
    "start": "979620",
    "end": "983639"
  },
  {
    "text": "and here just a quick highlight before",
    "start": "983639",
    "end": "986940"
  },
  {
    "text": "you go to tomorrow's session uh deep",
    "start": "986940",
    "end": "989519"
  },
  {
    "text": "dive on code Flair basically we use the",
    "start": "989519",
    "end": "993180"
  },
  {
    "text": "co-flare cluster object to declare the",
    "start": "993180",
    "end": "996300"
  },
  {
    "text": "size of the cluster we want and then use",
    "start": "996300",
    "end": "999959"
  },
  {
    "text": "the API from code flare SDK to bring up",
    "start": "999959",
    "end": "1003860"
  },
  {
    "text": "the cluster",
    "start": "1003860",
    "end": "1005420"
  },
  {
    "text": "and get the cluster URL in order to",
    "start": "1005420",
    "end": "1008839"
  },
  {
    "text": "launch the job kick off the data",
    "start": "1008839",
    "end": "1011240"
  },
  {
    "text": "processing and finally when it's done we",
    "start": "1011240",
    "end": "1014120"
  },
  {
    "text": "close down the cluster",
    "start": "1014120",
    "end": "1015860"
  },
  {
    "text": "and in this interaction is through the",
    "start": "1015860",
    "end": "1019639"
  },
  {
    "text": "odh data science pipeline",
    "start": "1019639",
    "end": "1023120"
  },
  {
    "text": "which uh goes through the pipeline",
    "start": "1023120",
    "end": "1026178"
  },
  {
    "text": "deployment to launch a component as a",
    "start": "1026179",
    "end": "1029839"
  },
  {
    "text": "part but in this part",
    "start": "1029839",
    "end": "1033079"
  },
  {
    "text": "um it actually is responsible for using",
    "start": "1033079",
    "end": "1035600"
  },
  {
    "text": "Code flarese SDK to",
    "start": "1035600",
    "end": "1039699"
  },
  {
    "text": "deploy a cluster and in certain stage we",
    "start": "1039699",
    "end": "1043459"
  },
  {
    "text": "may use",
    "start": "1043459",
    "end": "1044600"
  },
  {
    "text": "a smaller cluster in other stages we",
    "start": "1044600",
    "end": "1047798"
  },
  {
    "text": "deploy more parts in order to",
    "start": "1047799",
    "end": "1050870"
  },
  {
    "text": "[Music]",
    "start": "1050870",
    "end": "1051440"
  },
  {
    "text": "um",
    "start": "1051440",
    "end": "1052940"
  },
  {
    "text": "finish the processing job in the desired",
    "start": "1052940",
    "end": "1056179"
  },
  {
    "text": "time frame",
    "start": "1056179",
    "end": "1057799"
  },
  {
    "text": "so this is just a screenshot which you",
    "start": "1057799",
    "end": "1060080"
  },
  {
    "text": "will soon see on the demo",
    "start": "1060080",
    "end": "1063400"
  },
  {
    "text": "recorded So it's no different from the",
    "start": "1063400",
    "end": "1068179"
  },
  {
    "text": "many data pipelining functionality",
    "start": "1068179",
    "end": "1071240"
  },
  {
    "text": "you're already familiar with but this is",
    "start": "1071240",
    "end": "1073340"
  },
  {
    "text": "all done in open data hub",
    "start": "1073340",
    "end": "1077780"
  },
  {
    "text": "um and not only that we very much like",
    "start": "1077780",
    "end": "1080539"
  },
  {
    "text": "to have the trigger and scheduled rounds",
    "start": "1080539",
    "end": "1083840"
  },
  {
    "text": "of the pipelines so that uh people who",
    "start": "1083840",
    "end": "1087080"
  },
  {
    "text": "are not familiar with kubernetes can use",
    "start": "1087080",
    "end": "1089600"
  },
  {
    "text": "this interface to launch their data",
    "start": "1089600",
    "end": "1091820"
  },
  {
    "text": "processing and furthermore open data Hub",
    "start": "1091820",
    "end": "1095419"
  },
  {
    "text": "has its own run management so we can",
    "start": "1095419",
    "end": "1097460"
  },
  {
    "text": "actually recall through using this",
    "start": "1097460",
    "end": "1099980"
  },
  {
    "text": "dashboard for team collaboration",
    "start": "1099980",
    "end": "1102860"
  },
  {
    "text": "and then finally",
    "start": "1102860",
    "end": "1105020"
  },
  {
    "text": "we must have logs to diagonals and",
    "start": "1105020",
    "end": "1108080"
  },
  {
    "text": "understand the progress and therefore",
    "start": "1108080",
    "end": "1111020"
  },
  {
    "text": "the pipeline log streaming is a valuable",
    "start": "1111020",
    "end": "1114559"
  },
  {
    "text": "tool so next I want to show you a a",
    "start": "1114559",
    "end": "1118940"
  },
  {
    "text": "small recorded demo which in real time",
    "start": "1118940",
    "end": "1122000"
  },
  {
    "text": "is 40 minutes long but I cut it down to",
    "start": "1122000",
    "end": "1126200"
  },
  {
    "text": "a five minute clip to just show the",
    "start": "1126200",
    "end": "1128600"
  },
  {
    "text": "highlights uh we use this open data Hub",
    "start": "1128600",
    "end": "1131960"
  },
  {
    "text": "to launch a pipeline to go through the",
    "start": "1131960",
    "end": "1135320"
  },
  {
    "text": "following step first we remove the",
    "start": "1135320",
    "end": "1137539"
  },
  {
    "text": "duplicates from a collection of the",
    "start": "1137539",
    "end": "1140260"
  },
  {
    "text": "documents then we detect the language",
    "start": "1140260",
    "end": "1143419"
  },
  {
    "text": "associated with these documents then we",
    "start": "1143419",
    "end": "1147500"
  },
  {
    "text": "let it go through some natural language",
    "start": "1147500",
    "end": "1150320"
  },
  {
    "text": "processing analytics to split sentences",
    "start": "1150320",
    "end": "1153140"
  },
  {
    "text": "as well as assess the quality of the",
    "start": "1153140",
    "end": "1156380"
  },
  {
    "text": "documents so that we don't end up",
    "start": "1156380",
    "end": "1158480"
  },
  {
    "text": "feeding a lot of",
    "start": "1158480",
    "end": "1160840"
  },
  {
    "text": "random characters into this model and",
    "start": "1160840",
    "end": "1165320"
  },
  {
    "text": "finally we will merge the results",
    "start": "1165320",
    "end": "1169000"
  },
  {
    "text": "so let me",
    "start": "1172940",
    "end": "1174860"
  },
  {
    "text": "switch to the",
    "start": "1174860",
    "end": "1177799"
  },
  {
    "text": "player",
    "start": "1177799",
    "end": "1180140"
  },
  {
    "text": "oh",
    "start": "1180140",
    "end": "1181340"
  },
  {
    "text": "you have to drag it across the screen to",
    "start": "1181340",
    "end": "1184100"
  },
  {
    "text": "put it here",
    "start": "1184100",
    "end": "1186799"
  },
  {
    "text": "is it refreshing",
    "start": "1186799",
    "end": "1189820"
  },
  {
    "text": "oops",
    "start": "1197059",
    "end": "1199720"
  },
  {
    "text": "this is uh",
    "start": "1201340",
    "end": "1204919"
  },
  {
    "text": "mirror",
    "start": "1204919",
    "end": "1207919"
  },
  {
    "text": "okay much better so I'll read about the",
    "start": "1210740",
    "end": "1213440"
  },
  {
    "text": "screen mishap so what you are seeing now",
    "start": "1213440",
    "end": "1216620"
  },
  {
    "text": "is the openshift uh operator data Hub",
    "start": "1216620",
    "end": "1220820"
  },
  {
    "text": "view to install open data Hub you just",
    "start": "1220820",
    "end": "1223520"
  },
  {
    "text": "go through the operator Hub find the",
    "start": "1223520",
    "end": "1226520"
  },
  {
    "text": "open data Hub operator and the code",
    "start": "1226520",
    "end": "1229160"
  },
  {
    "text": "flare operator and you can install that",
    "start": "1229160",
    "end": "1231679"
  },
  {
    "text": "in your environment",
    "start": "1231679",
    "end": "1235340"
  },
  {
    "text": "next we are going to switch over to look",
    "start": "1236480",
    "end": "1240980"
  },
  {
    "text": "at the",
    "start": "1240980",
    "end": "1242200"
  },
  {
    "text": "pipelines that has been registered with",
    "start": "1242200",
    "end": "1246140"
  },
  {
    "text": "the data science pipeline project",
    "start": "1246140",
    "end": "1250160"
  },
  {
    "text": "so to do that you go to the",
    "start": "1250160",
    "end": "1253100"
  },
  {
    "text": "project",
    "start": "1253100",
    "end": "1254480"
  },
  {
    "text": "dashboard",
    "start": "1254480",
    "end": "1257240"
  },
  {
    "text": "and what you are seeing here is the",
    "start": "1257240",
    "end": "1260240"
  },
  {
    "text": "open data Hub project installing our",
    "start": "1260240",
    "end": "1263360"
  },
  {
    "text": "environment and you can have multiple",
    "start": "1263360",
    "end": "1265580"
  },
  {
    "text": "name spaces each has its own pipeline",
    "start": "1265580",
    "end": "1268760"
  },
  {
    "text": "registration",
    "start": "1268760",
    "end": "1270559"
  },
  {
    "text": "and the pipeline named Summit is the one",
    "start": "1270559",
    "end": "1275179"
  },
  {
    "text": "that I'll be showing you",
    "start": "1275179",
    "end": "1278179"
  },
  {
    "text": "and like I said the you can schedule",
    "start": "1278179",
    "end": "1282080"
  },
  {
    "text": "the pipeline execution as well as a",
    "start": "1282080",
    "end": "1285020"
  },
  {
    "text": "trigger the pipeline execution from the",
    "start": "1285020",
    "end": "1287240"
  },
  {
    "text": "operational perspective having the",
    "start": "1287240",
    "end": "1289520"
  },
  {
    "text": "ability to schedule uh the pipeline is",
    "start": "1289520",
    "end": "1293179"
  },
  {
    "text": "really useful",
    "start": "1293179",
    "end": "1295520"
  },
  {
    "text": "and furthermore before I made this",
    "start": "1295520",
    "end": "1297980"
  },
  {
    "text": "recording I already did a dry run so",
    "start": "1297980",
    "end": "1300500"
  },
  {
    "text": "this is a completely dry rung and it's",
    "start": "1300500",
    "end": "1303020"
  },
  {
    "text": "also very convenient in open data Hub to",
    "start": "1303020",
    "end": "1305360"
  },
  {
    "text": "allow me to clone what I did",
    "start": "1305360",
    "end": "1308720"
  },
  {
    "text": "so from the dry wrong now I'm doing a",
    "start": "1308720",
    "end": "1311840"
  },
  {
    "text": "recording run",
    "start": "1311840",
    "end": "1313100"
  },
  {
    "text": "and as you can see in this pipeline",
    "start": "1313100",
    "end": "1317000"
  },
  {
    "text": "you can turn on the scheduling depending",
    "start": "1317000",
    "end": "1319700"
  },
  {
    "text": "on the cluster availability and capacity",
    "start": "1319700",
    "end": "1322700"
  },
  {
    "text": "as well as",
    "start": "1322700",
    "end": "1324620"
  },
  {
    "text": "trigger the Run",
    "start": "1324620",
    "end": "1326600"
  },
  {
    "text": "and you will see here that you can set",
    "start": "1326600",
    "end": "1329720"
  },
  {
    "text": "the runtime configuration parameters",
    "start": "1329720",
    "end": "1332360"
  },
  {
    "text": "based on the amount of data you need to",
    "start": "1332360",
    "end": "1335840"
  },
  {
    "text": "process and how much time you want to",
    "start": "1335840",
    "end": "1337880"
  },
  {
    "text": "have it processed this is the same",
    "start": "1337880",
    "end": "1341980"
  },
  {
    "text": "pipeline I just showed you earlier",
    "start": "1341980",
    "end": "1344960"
  },
  {
    "text": "and just to quickly show you the python",
    "start": "1344960",
    "end": "1347900"
  },
  {
    "text": "code be behind the scene",
    "start": "1347900",
    "end": "1350260"
  },
  {
    "text": "these are the four tasks that we get",
    "start": "1350260",
    "end": "1354740"
  },
  {
    "text": "them scheduled to work on the the",
    "start": "1354740",
    "end": "1356840"
  },
  {
    "text": "pipeline",
    "start": "1356840",
    "end": "1358580"
  },
  {
    "text": "um so you can see the uh a very simple",
    "start": "1358580",
    "end": "1362299"
  },
  {
    "text": "python definition interface",
    "start": "1362299",
    "end": "1365960"
  },
  {
    "text": "and the logging that's coming out of the",
    "start": "1365960",
    "end": "1369860"
  },
  {
    "text": "the execution",
    "start": "1369860",
    "end": "1371720"
  },
  {
    "text": "and for each of these rungs",
    "start": "1371720",
    "end": "1375919"
  },
  {
    "text": "what's happening behind the scene as you",
    "start": "1375919",
    "end": "1378140"
  },
  {
    "text": "can see is a",
    "start": "1378140",
    "end": "1380020"
  },
  {
    "text": "ray cluster",
    "start": "1380020",
    "end": "1382159"
  },
  {
    "text": "and during the execution",
    "start": "1382159",
    "end": "1384559"
  },
  {
    "text": "the pipeline",
    "start": "1384559",
    "end": "1386980"
  },
  {
    "text": "interface actually connect to a route",
    "start": "1386980",
    "end": "1390200"
  },
  {
    "text": "that surfaces the array dashboard",
    "start": "1390200",
    "end": "1394400"
  },
  {
    "text": "and for those of you are familiar with",
    "start": "1394400",
    "end": "1396679"
  },
  {
    "text": "the ray dashboard you you can watch and",
    "start": "1396679",
    "end": "1400159"
  },
  {
    "text": "see how the progress and the utilization",
    "start": "1400159",
    "end": "1405740"
  },
  {
    "text": "of the CPU memory and sometimes the GPU",
    "start": "1405740",
    "end": "1408980"
  },
  {
    "text": "depending on the nature of the task",
    "start": "1408980",
    "end": "1413440"
  },
  {
    "text": "um and we often find it is a very useful",
    "start": "1413840",
    "end": "1415700"
  },
  {
    "text": "for export users however it's not",
    "start": "1415700",
    "end": "1418700"
  },
  {
    "text": "necessarily",
    "start": "1418700",
    "end": "1420159"
  },
  {
    "text": "for the usual production users",
    "start": "1420159",
    "end": "1423440"
  },
  {
    "text": "now",
    "start": "1423440",
    "end": "1424640"
  },
  {
    "text": "in this pipeline intentionally chose",
    "start": "1424640",
    "end": "1428539"
  },
  {
    "text": "two stages to run and execute in",
    "start": "1428539",
    "end": "1431900"
  },
  {
    "text": "parallel the intent is to show you that",
    "start": "1431900",
    "end": "1436159"
  },
  {
    "text": "as this pipeline is running these two",
    "start": "1436159",
    "end": "1439760"
  },
  {
    "text": "stages they will actually",
    "start": "1439760",
    "end": "1442360"
  },
  {
    "text": "simultaneously running two different Ray",
    "start": "1442360",
    "end": "1445100"
  },
  {
    "text": "clusters and these red clusters",
    "start": "1445100",
    "end": "1448580"
  },
  {
    "text": "has their own custom image so these",
    "start": "1448580",
    "end": "1451580"
  },
  {
    "text": "custom images enable them to execute",
    "start": "1451580",
    "end": "1453980"
  },
  {
    "text": "different tasks",
    "start": "1453980",
    "end": "1455720"
  },
  {
    "text": "and possibly at a different rate as well",
    "start": "1455720",
    "end": "1458200"
  },
  {
    "text": "that's just the nature of the data",
    "start": "1458200",
    "end": "1460880"
  },
  {
    "text": "processing",
    "start": "1460880",
    "end": "1462400"
  },
  {
    "text": "so this is the kind of a more detailed",
    "start": "1462400",
    "end": "1465679"
  },
  {
    "text": "View",
    "start": "1465679",
    "end": "1467059"
  },
  {
    "text": "given the overall multi-stage workflow",
    "start": "1467059",
    "end": "1470960"
  },
  {
    "text": "you can actually zoom in",
    "start": "1470960",
    "end": "1473419"
  },
  {
    "text": "to the ray dashboard for the sub",
    "start": "1473419",
    "end": "1475760"
  },
  {
    "text": "workflows",
    "start": "1475760",
    "end": "1478400"
  },
  {
    "text": "and again one of them is doing document",
    "start": "1478400",
    "end": "1482120"
  },
  {
    "text": "quality assessment and as you can see",
    "start": "1482120",
    "end": "1484880"
  },
  {
    "text": "the",
    "start": "1484880",
    "end": "1486080"
  },
  {
    "text": "usage of the resources here",
    "start": "1486080",
    "end": "1488780"
  },
  {
    "text": "and the second one is doing sentence",
    "start": "1488780",
    "end": "1491600"
  },
  {
    "text": "splitting which you will subsequently be",
    "start": "1491600",
    "end": "1493880"
  },
  {
    "text": "used for",
    "start": "1493880",
    "end": "1495520"
  },
  {
    "text": "additional sentence analysis",
    "start": "1495520",
    "end": "1500000"
  },
  {
    "text": "and uh",
    "start": "1500000",
    "end": "1502640"
  },
  {
    "text": "so in this recording you can see the CPU",
    "start": "1502640",
    "end": "1505820"
  },
  {
    "text": "usage change over time",
    "start": "1505820",
    "end": "1509240"
  },
  {
    "text": "like I said it's a 40 minute shortened",
    "start": "1509240",
    "end": "1512539"
  },
  {
    "text": "uh editing so",
    "start": "1512539",
    "end": "1515179"
  },
  {
    "text": "um",
    "start": "1515179",
    "end": "1516740"
  },
  {
    "text": "at the end you can check the output of",
    "start": "1516740",
    "end": "1520700"
  },
  {
    "text": "these different two pipelines and they",
    "start": "1520700",
    "end": "1524419"
  },
  {
    "text": "are",
    "start": "1524419",
    "end": "1525220"
  },
  {
    "text": "completed",
    "start": "1525220",
    "end": "1526820"
  },
  {
    "text": "now next let me go back to the",
    "start": "1526820",
    "end": "1529820"
  },
  {
    "text": "presentation",
    "start": "1529820",
    "end": "1532360"
  },
  {
    "text": "so this is really very exciting for us",
    "start": "1552260",
    "end": "1556039"
  },
  {
    "text": "to have the such flexibility and be able",
    "start": "1556039",
    "end": "1558980"
  },
  {
    "text": "to operationalize meaning that we don't",
    "start": "1558980",
    "end": "1561620"
  },
  {
    "text": "need our core developers or expertise",
    "start": "1561620",
    "end": "1564320"
  },
  {
    "text": "tied to running these on a day-to-day",
    "start": "1564320",
    "end": "1567620"
  },
  {
    "text": "basis",
    "start": "1567620",
    "end": "1568640"
  },
  {
    "text": "furthermore",
    "start": "1568640",
    "end": "1569980"
  },
  {
    "text": "we believe that we can continue to load",
    "start": "1569980",
    "end": "1573020"
  },
  {
    "text": "the entry barrier to Port the best uh",
    "start": "1573020",
    "end": "1576320"
  },
  {
    "text": "Legacy code base to take advantage of",
    "start": "1576320",
    "end": "1578419"
  },
  {
    "text": "the scale out and the open data Hub",
    "start": "1578419",
    "end": "1582080"
  },
  {
    "text": "integration",
    "start": "1582080",
    "end": "1583480"
  },
  {
    "text": "we will continue to improve the",
    "start": "1583480",
    "end": "1585740"
  },
  {
    "text": "automation for such routine operations",
    "start": "1585740",
    "end": "1588279"
  },
  {
    "text": "and furthermore we aim to",
    "start": "1588279",
    "end": "1591100"
  },
  {
    "text": "opportunistically run these different",
    "start": "1591100",
    "end": "1593059"
  },
  {
    "text": "stages in different clusters",
    "start": "1593059",
    "end": "1595760"
  },
  {
    "text": "lastly I want to acknowledge the",
    "start": "1595760",
    "end": "1598580"
  },
  {
    "text": "contributors from both IBM and red hat",
    "start": "1598580",
    "end": "1601580"
  },
  {
    "text": "teams and some of them are sitting in",
    "start": "1601580",
    "end": "1604760"
  },
  {
    "text": "this room in the audience",
    "start": "1604760",
    "end": "1607220"
  },
  {
    "text": "and that we would encourage you to try",
    "start": "1607220",
    "end": "1609440"
  },
  {
    "text": "it out to give up",
    "start": "1609440",
    "end": "1613120"
  },
  {
    "text": "our open data Hub community project uh a",
    "start": "1613120",
    "end": "1618080"
  },
  {
    "text": "try and also attend the end-to-end talk",
    "start": "1618080",
    "end": "1621380"
  },
  {
    "text": "at 1 pm tomorrow",
    "start": "1621380",
    "end": "1624640"
  },
  {
    "text": "thank you",
    "start": "1625039",
    "end": "1626970"
  },
  {
    "text": "[Applause]",
    "start": "1626970",
    "end": "1633380"
  },
  {
    "text": "we still have about three minutes if you",
    "start": "1633380",
    "end": "1634820"
  },
  {
    "text": "want to open it up for Q a yeah",
    "start": "1634820",
    "end": "1637460"
  },
  {
    "text": "absolutely so we would like to invite",
    "start": "1637460",
    "end": "1639919"
  },
  {
    "text": "you feedback and comments",
    "start": "1639919",
    "end": "1643840"
  },
  {
    "text": "yes",
    "start": "1645200",
    "end": "1647740"
  },
  {
    "text": "likes so thank you for the Fantastic",
    "start": "1649039",
    "end": "1652100"
  },
  {
    "text": "demo like just want to ask some",
    "start": "1652100",
    "end": "1655039"
  },
  {
    "text": "questions like uh you show a pipeline",
    "start": "1655039",
    "end": "1657799"
  },
  {
    "text": "there and there are several notes yes",
    "start": "1657799",
    "end": "1659960"
  },
  {
    "text": "that means like for every note you will",
    "start": "1659960",
    "end": "1662240"
  },
  {
    "text": "raise the requester",
    "start": "1662240",
    "end": "1664279"
  },
  {
    "text": "yes indeed just just to confirm your",
    "start": "1664279",
    "end": "1666559"
  },
  {
    "text": "observation in this case it's a",
    "start": "1666559",
    "end": "1668779"
  },
  {
    "text": "composition of multiple workflows to be",
    "start": "1668779",
    "end": "1672559"
  },
  {
    "text": "precise four of them each of them have",
    "start": "1672559",
    "end": "1675080"
  },
  {
    "text": "their own Ray cluster launched and",
    "start": "1675080",
    "end": "1678200"
  },
  {
    "text": "closed down through the code Flair",
    "start": "1678200",
    "end": "1680380"
  },
  {
    "text": "SDK and furthermore they have their own",
    "start": "1680380",
    "end": "1683299"
  },
  {
    "text": "custom image so they are not all the",
    "start": "1683299",
    "end": "1685820"
  },
  {
    "text": "same",
    "start": "1685820",
    "end": "1687140"
  },
  {
    "text": "um yeah oh I see so if I want to rerun",
    "start": "1687140",
    "end": "1691340"
  },
  {
    "text": "the pipeline is that uh okay if I phrase",
    "start": "1691340",
    "end": "1695120"
  },
  {
    "text": "some Pipeline and only wrong that those",
    "start": "1695120",
    "end": "1697760"
  },
  {
    "text": "ones I mean will the data be cached or",
    "start": "1697760",
    "end": "1701000"
  },
  {
    "text": "like you need to run the entire public",
    "start": "1701000",
    "end": "1703340"
  },
  {
    "text": "again very good question that was one of",
    "start": "1703340",
    "end": "1706220"
  },
  {
    "text": "the raised the question about the",
    "start": "1706220",
    "end": "1707779"
  },
  {
    "text": "checkpoint and the in the automation so",
    "start": "1707779",
    "end": "1710360"
  },
  {
    "text": "from the individual pipeline perspective",
    "start": "1710360",
    "end": "1712880"
  },
  {
    "text": "each of the sub ones we can restart",
    "start": "1712880",
    "end": "1715100"
  },
  {
    "text": "easily but from the overall composite",
    "start": "1715100",
    "end": "1718279"
  },
  {
    "text": "workflow perspective we have not yet put",
    "start": "1718279",
    "end": "1721340"
  },
  {
    "text": "into the ability to restart in the",
    "start": "1721340",
    "end": "1724340"
  },
  {
    "text": "middle",
    "start": "1724340",
    "end": "1726220"
  },
  {
    "text": "yeah but that's our next steps to make",
    "start": "1726220",
    "end": "1729860"
  },
  {
    "text": "it more usable by operational team",
    "start": "1729860",
    "end": "1734919"
  },
  {
    "text": "any other questions",
    "start": "1737900",
    "end": "1740860"
  },
  {
    "text": "uh hi I'm Melanie how do you access to",
    "start": "1744440",
    "end": "1748760"
  },
  {
    "text": "the logs after the read job is finished",
    "start": "1748760",
    "end": "1753380"
  },
  {
    "text": "um so all the parts that are completed",
    "start": "1753380",
    "end": "1755799"
  },
  {
    "text": "we can just click on those parts they",
    "start": "1755799",
    "end": "1758720"
  },
  {
    "text": "would still be the logs are still",
    "start": "1758720",
    "end": "1761480"
  },
  {
    "text": "available",
    "start": "1761480",
    "end": "1762399"
  },
  {
    "text": "and we also have the mechanism of",
    "start": "1762399",
    "end": "1764960"
  },
  {
    "text": "writing them to the cloud object storage",
    "start": "1764960",
    "end": "1767539"
  },
  {
    "text": "as a designated",
    "start": "1767539",
    "end": "1769360"
  },
  {
    "text": "bucket and pass so that we can recover",
    "start": "1769360",
    "end": "1772460"
  },
  {
    "text": "them",
    "start": "1772460",
    "end": "1773740"
  },
  {
    "text": "but in terms of the overall air clock",
    "start": "1773740",
    "end": "1778399"
  },
  {
    "text": "aggregation that's still uh item that we",
    "start": "1778399",
    "end": "1782240"
  },
  {
    "text": "are working on",
    "start": "1782240",
    "end": "1783919"
  },
  {
    "text": "thank you",
    "start": "1783919",
    "end": "1786639"
  },
  {
    "text": "all right thank you Alex and Yoshi thank",
    "start": "1787340",
    "end": "1789919"
  },
  {
    "text": "you very much",
    "start": "1789919",
    "end": "1792340"
  }
]
[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "[Music]",
    "start": "170",
    "end": "14920"
  },
  {
    "text": "hello this is juan roerto honorado",
    "start": "14920",
    "end": "18800"
  },
  {
    "text": "at anastasia and today with",
    "start": "18800",
    "end": "22080"
  },
  {
    "text": "domingortuzar we're going to take a look",
    "start": "22080",
    "end": "24720"
  },
  {
    "text": "into a quick journey",
    "start": "24720",
    "end": "26400"
  },
  {
    "text": "into how we use ray and how we",
    "start": "26400",
    "end": "29439"
  },
  {
    "text": "implemented ray and any scale to speed",
    "start": "29439",
    "end": "32078"
  },
  {
    "text": "up our",
    "start": "32079",
    "end": "32640"
  },
  {
    "text": "mlo processes so",
    "start": "32640",
    "end": "36000"
  },
  {
    "start": "35000",
    "end": "63000"
  },
  {
    "text": "at anastasia we provide a powerful",
    "start": "36000",
    "end": "38879"
  },
  {
    "text": "platform with",
    "start": "38879",
    "end": "40239"
  },
  {
    "text": "business solutions in mind that enables",
    "start": "40239",
    "end": "43120"
  },
  {
    "text": "organizations",
    "start": "43120",
    "end": "44399"
  },
  {
    "text": "across a different industries to operate",
    "start": "44399",
    "end": "46879"
  },
  {
    "text": "ai capacities",
    "start": "46879",
    "end": "48000"
  },
  {
    "text": "at scale with a fraction of the",
    "start": "48000",
    "end": "49920"
  },
  {
    "text": "resources and effort",
    "start": "49920",
    "end": "51280"
  },
  {
    "text": "that it's traditionally needed um",
    "start": "51280",
    "end": "54800"
  },
  {
    "text": "those two points of the scale and the",
    "start": "54800",
    "end": "57600"
  },
  {
    "text": "resources needed",
    "start": "57600",
    "end": "59359"
  },
  {
    "text": "are key and we'll get back to those in a",
    "start": "59359",
    "end": "61920"
  },
  {
    "text": "minute",
    "start": "61920",
    "end": "63840"
  },
  {
    "start": "63000",
    "end": "96000"
  },
  {
    "text": "so today we're going to take a look into",
    "start": "63840",
    "end": "66640"
  },
  {
    "text": "a particular problem of ours",
    "start": "66640",
    "end": "68720"
  },
  {
    "text": "and how we initially implemented that in",
    "start": "68720",
    "end": "72479"
  },
  {
    "text": "pure python then what we saw",
    "start": "72479",
    "end": "75920"
  },
  {
    "text": "uh the issues we faced and how we",
    "start": "75920",
    "end": "79520"
  },
  {
    "text": "came to the new uh to scale horizontally",
    "start": "79520",
    "end": "83200"
  },
  {
    "text": "and how then we how we came into",
    "start": "83200",
    "end": "87439"
  },
  {
    "text": "rey and using rey on any scale to solve",
    "start": "87439",
    "end": "90159"
  },
  {
    "text": "those",
    "start": "90159",
    "end": "91520"
  },
  {
    "text": "finally seeing some astonishing results",
    "start": "91520",
    "end": "94479"
  },
  {
    "text": "that we got",
    "start": "94479",
    "end": "97118"
  },
  {
    "start": "96000",
    "end": "140000"
  },
  {
    "text": "the problem i was referring to is demand",
    "start": "97520",
    "end": "100560"
  },
  {
    "text": "prediction",
    "start": "100560",
    "end": "101920"
  },
  {
    "text": "this problem typically reduces the",
    "start": "101920",
    "end": "104799"
  },
  {
    "text": "operational expenses of business",
    "start": "104799",
    "end": "106720"
  },
  {
    "text": "businesses",
    "start": "106720",
    "end": "108079"
  },
  {
    "text": "and this business problem brings lots of",
    "start": "108079",
    "end": "111360"
  },
  {
    "text": "challenges",
    "start": "111360",
    "end": "112079"
  },
  {
    "text": "and nuances depending on the particular",
    "start": "112079",
    "end": "115759"
  },
  {
    "text": "industry you're on you may want to",
    "start": "115759",
    "end": "118320"
  },
  {
    "text": "tackle it in a different way",
    "start": "118320",
    "end": "120640"
  },
  {
    "text": "but at the machine learning level at",
    "start": "120640",
    "end": "123520"
  },
  {
    "text": "least we can",
    "start": "123520",
    "end": "124399"
  },
  {
    "text": "boil it down into a time series",
    "start": "124399",
    "end": "126560"
  },
  {
    "text": "forecasting problem",
    "start": "126560",
    "end": "128720"
  },
  {
    "text": "and our approach at anastasia",
    "start": "128720",
    "end": "131840"
  },
  {
    "text": "is to predict using a multi-model and",
    "start": "131840",
    "end": "135120"
  },
  {
    "text": "symbol for every item that's",
    "start": "135120",
    "end": "138319"
  },
  {
    "text": "needed of prediction",
    "start": "138319",
    "end": "141520"
  },
  {
    "start": "140000",
    "end": "235000"
  },
  {
    "text": "so um we can look at it uh in in this",
    "start": "141520",
    "end": "144720"
  },
  {
    "text": "diagram",
    "start": "144720",
    "end": "146560"
  },
  {
    "text": "we first start with a data set",
    "start": "146560",
    "end": "149840"
  },
  {
    "text": "from the customer and in this sense the",
    "start": "149840",
    "end": "152800"
  },
  {
    "text": "the data set consists",
    "start": "152800",
    "end": "154800"
  },
  {
    "text": "at least of three columns",
    "start": "154800",
    "end": "158720"
  },
  {
    "text": "we have a number uh a set of",
    "start": "158720",
    "end": "162160"
  },
  {
    "text": "items in this case the shirt pants",
    "start": "162160",
    "end": "165280"
  },
  {
    "text": "and shoes are shown then for each one of",
    "start": "165280",
    "end": "168560"
  },
  {
    "text": "those we have a",
    "start": "168560",
    "end": "170239"
  },
  {
    "text": "series of dates",
    "start": "170239",
    "end": "173280"
  },
  {
    "text": "each one of those having their own",
    "start": "173280",
    "end": "176480"
  },
  {
    "text": "values and we can think of those values",
    "start": "176480",
    "end": "179680"
  },
  {
    "text": "in this case for example let's say it's",
    "start": "179680",
    "end": "183280"
  },
  {
    "text": "the number of items sold in that",
    "start": "183280",
    "end": "186080"
  },
  {
    "text": "particular",
    "start": "186080",
    "end": "186879"
  },
  {
    "text": "uh date so though that that data set",
    "start": "186879",
    "end": "190319"
  },
  {
    "text": "is fed into a number of",
    "start": "190319",
    "end": "193519"
  },
  {
    "text": "models uh we we've got a pool of models",
    "start": "193519",
    "end": "196640"
  },
  {
    "text": "for prediction",
    "start": "196640",
    "end": "199680"
  },
  {
    "text": "and each model we will output",
    "start": "199680",
    "end": "203440"
  },
  {
    "text": "their own prediction into the future for",
    "start": "203440",
    "end": "206080"
  },
  {
    "text": "the values",
    "start": "206080",
    "end": "207040"
  },
  {
    "text": "that we want to predict for each one of",
    "start": "207040",
    "end": "209440"
  },
  {
    "text": "those",
    "start": "209440",
    "end": "210879"
  },
  {
    "text": "items in in question so",
    "start": "210879",
    "end": "214000"
  },
  {
    "text": "we have a number of predictions uh",
    "start": "214000",
    "end": "217440"
  },
  {
    "text": "each one uh independent on on the other",
    "start": "217440",
    "end": "221440"
  },
  {
    "text": "uh finally we have uh the last step",
    "start": "221440",
    "end": "225360"
  },
  {
    "text": "is to assemble all of those and output a",
    "start": "225360",
    "end": "228159"
  },
  {
    "text": "single prediction",
    "start": "228159",
    "end": "229680"
  },
  {
    "text": "for each date and item",
    "start": "229680",
    "end": "235120"
  },
  {
    "start": "235000",
    "end": "286000"
  },
  {
    "text": "so we can see the process uh",
    "start": "236400",
    "end": "240000"
  },
  {
    "text": "like this in this diagram the job we get",
    "start": "240000",
    "end": "242640"
  },
  {
    "text": "the",
    "start": "242640",
    "end": "243040"
  },
  {
    "text": "the job start signal that comes from our",
    "start": "243040",
    "end": "245439"
  },
  {
    "text": "customers",
    "start": "245439",
    "end": "246400"
  },
  {
    "text": "and then the there's the time series",
    "start": "246400",
    "end": "249599"
  },
  {
    "text": "generation the data set that we fed into",
    "start": "249599",
    "end": "252159"
  },
  {
    "text": "the ml process",
    "start": "252159",
    "end": "253680"
  },
  {
    "text": "this ml process inside",
    "start": "253680",
    "end": "257120"
  },
  {
    "text": "we initially used the aws batch managed",
    "start": "257120",
    "end": "260560"
  },
  {
    "text": "service this service",
    "start": "260560",
    "end": "264479"
  },
  {
    "text": "what it does is to run",
    "start": "264479",
    "end": "267520"
  },
  {
    "text": "docker images and we would run",
    "start": "267520",
    "end": "270560"
  },
  {
    "text": "one instance ec2 instance",
    "start": "270560",
    "end": "274080"
  },
  {
    "text": "for each model type so",
    "start": "274080",
    "end": "277120"
  },
  {
    "text": "we would end up with the output of all",
    "start": "277120",
    "end": "279520"
  },
  {
    "text": "of those",
    "start": "279520",
    "end": "280479"
  },
  {
    "text": "into s fed and saved into",
    "start": "280479",
    "end": "283840"
  },
  {
    "text": "s3 and this",
    "start": "283840",
    "end": "287759"
  },
  {
    "text": "uh this diagram we we saw that each",
    "start": "287759",
    "end": "291199"
  },
  {
    "text": "ec2 instance regard was related",
    "start": "291199",
    "end": "294880"
  },
  {
    "text": "for a particular type of model",
    "start": "294880",
    "end": "298080"
  },
  {
    "text": "so uh in our implementation",
    "start": "298080",
    "end": "301440"
  },
  {
    "text": "we had done ourselves the the part of",
    "start": "301440",
    "end": "304400"
  },
  {
    "text": "parallelizing",
    "start": "304400",
    "end": "306000"
  },
  {
    "text": "and running in in parallel all of those",
    "start": "306000",
    "end": "309199"
  },
  {
    "text": "training and prediction within each",
    "start": "309199",
    "end": "311919"
  },
  {
    "text": "instance",
    "start": "311919",
    "end": "312960"
  },
  {
    "text": "and after a number of iterations",
    "start": "312960",
    "end": "316400"
  },
  {
    "text": "we were able to fully the the",
    "start": "316400",
    "end": "319919"
  },
  {
    "text": "cpu usage that the instances were",
    "start": "319919",
    "end": "322320"
  },
  {
    "text": "reporting",
    "start": "322320",
    "end": "323039"
  },
  {
    "text": "were at their full their fullest",
    "start": "323039",
    "end": "327919"
  },
  {
    "text": "we were pretty happy with those results",
    "start": "328080",
    "end": "330639"
  },
  {
    "text": "we considered the code very optimized",
    "start": "330639",
    "end": "334320"
  },
  {
    "text": "but we would then find out that it was",
    "start": "334320",
    "end": "337039"
  },
  {
    "text": "not so",
    "start": "337039",
    "end": "339680"
  },
  {
    "start": "339000",
    "end": "403000"
  },
  {
    "text": "um aside from that we rapidly",
    "start": "339680",
    "end": "343039"
  },
  {
    "text": "hit a ceiling when we tried to",
    "start": "343039",
    "end": "345280"
  },
  {
    "text": "vertically scale",
    "start": "345280",
    "end": "347360"
  },
  {
    "text": "we we started",
    "start": "347360",
    "end": "350479"
  },
  {
    "text": "when we used the maxed the bigger",
    "start": "350479",
    "end": "353520"
  },
  {
    "text": "machines",
    "start": "353520",
    "end": "354639"
  },
  {
    "text": "that um on a side note",
    "start": "354639",
    "end": "357919"
  },
  {
    "text": "and not not so much as a side note but",
    "start": "357919",
    "end": "361360"
  },
  {
    "text": "those machines the bigger machines were",
    "start": "361360",
    "end": "363440"
  },
  {
    "text": "pretty expensive",
    "start": "363440",
    "end": "364400"
  },
  {
    "text": "and meant that the jobs for us were too",
    "start": "364400",
    "end": "366639"
  },
  {
    "text": "expensive",
    "start": "366639",
    "end": "367440"
  },
  {
    "text": "the bigger the bigger jobs",
    "start": "367440",
    "end": "370880"
  },
  {
    "text": "and also that the big data we were not",
    "start": "370880",
    "end": "374479"
  },
  {
    "text": "able to",
    "start": "374479",
    "end": "375360"
  },
  {
    "text": "scale accordingly and they were taking",
    "start": "375360",
    "end": "378080"
  },
  {
    "text": "too long",
    "start": "378080",
    "end": "378880"
  },
  {
    "text": "to finish lastly we were seeing",
    "start": "378880",
    "end": "383600"
  },
  {
    "text": "some vendor looking we were just",
    "start": "383600",
    "end": "387840"
  },
  {
    "text": "running docker images and that's pretty",
    "start": "387840",
    "end": "391199"
  },
  {
    "text": "cloud agnostic but still the way to",
    "start": "391199",
    "end": "394160"
  },
  {
    "text": "interact with other",
    "start": "394160",
    "end": "395360"
  },
  {
    "text": "those jobs um was not very easy",
    "start": "395360",
    "end": "398639"
  },
  {
    "text": "to migrate uh somewhere else",
    "start": "398639",
    "end": "402960"
  },
  {
    "start": "403000",
    "end": "494000"
  },
  {
    "text": "and so uh why it's hard",
    "start": "403520",
    "end": "406840"
  },
  {
    "text": "then to solve this the issues we were",
    "start": "406840",
    "end": "410080"
  },
  {
    "text": "seeing namely",
    "start": "410080",
    "end": "411120"
  },
  {
    "text": "namely the scaling part and as well the",
    "start": "411120",
    "end": "413840"
  },
  {
    "text": "cost",
    "start": "413840",
    "end": "415120"
  },
  {
    "text": "um with the with a particular service",
    "start": "415120",
    "end": "419039"
  },
  {
    "text": "that we were using",
    "start": "419039",
    "end": "420400"
  },
  {
    "text": "being aws badge you can",
    "start": "420400",
    "end": "423440"
  },
  {
    "text": "do horizontal scaling and in that way",
    "start": "423440",
    "end": "426479"
  },
  {
    "text": "process and distributedly",
    "start": "426479",
    "end": "430800"
  },
  {
    "text": "your data set but",
    "start": "430800",
    "end": "435198"
  },
  {
    "text": "you still if you did that for once",
    "start": "435440",
    "end": "438880"
  },
  {
    "text": "those instances the the ones that you're",
    "start": "438880",
    "end": "442160"
  },
  {
    "text": "horizontally scaling",
    "start": "442160",
    "end": "444080"
  },
  {
    "text": "those don't see each other so you it's",
    "start": "444080",
    "end": "447199"
  },
  {
    "text": "really hard to maintain",
    "start": "447199",
    "end": "450560"
  },
  {
    "text": "to maintain a certain",
    "start": "450720",
    "end": "454080"
  },
  {
    "text": "state or global state",
    "start": "454080",
    "end": "457199"
  },
  {
    "text": "between those and to communicate those",
    "start": "457199",
    "end": "459599"
  },
  {
    "text": "machines",
    "start": "459599",
    "end": "460800"
  },
  {
    "text": "and to do so big code changes are",
    "start": "460800",
    "end": "463280"
  },
  {
    "text": "required",
    "start": "463280",
    "end": "464319"
  },
  {
    "text": "also to do to make it fault tolerant in",
    "start": "464319",
    "end": "467120"
  },
  {
    "text": "order to be able to use",
    "start": "467120",
    "end": "468639"
  },
  {
    "text": "spot instances it's not easy to do",
    "start": "468639",
    "end": "472560"
  },
  {
    "text": "finally you can't scale that",
    "start": "472560",
    "end": "476840"
  },
  {
    "text": "particular",
    "start": "476840",
    "end": "479680"
  },
  {
    "text": "particular process dynamically",
    "start": "479680",
    "end": "483199"
  },
  {
    "text": "when you're running it you need to to",
    "start": "483199",
    "end": "486500"
  },
  {
    "text": "[Music]",
    "start": "486500",
    "end": "488080"
  },
  {
    "text": "to ask for the particular resources",
    "start": "488080",
    "end": "490160"
  },
  {
    "text": "beforehand and to know them beforehand",
    "start": "490160",
    "end": "494319"
  },
  {
    "start": "494000",
    "end": "586000"
  },
  {
    "text": "so to solve those issues we looked into",
    "start": "494720",
    "end": "497520"
  },
  {
    "text": "a number of",
    "start": "497520",
    "end": "498560"
  },
  {
    "text": "alternatives one of those was this",
    "start": "498560",
    "end": "502560"
  },
  {
    "text": "batch mode that was called the",
    "start": "502560",
    "end": "505440"
  },
  {
    "text": "multi-node",
    "start": "505440",
    "end": "506080"
  },
  {
    "text": "parallel jobs and the especially the",
    "start": "506080",
    "end": "509440"
  },
  {
    "text": "fault tolerance part",
    "start": "509440",
    "end": "510879"
  },
  {
    "text": "was difficult to implement um",
    "start": "510879",
    "end": "514640"
  },
  {
    "text": "so we discarded that um then",
    "start": "514640",
    "end": "517680"
  },
  {
    "text": "the emr service that's designed for",
    "start": "517680",
    "end": "521279"
  },
  {
    "text": "spark workloads and even though it it",
    "start": "521279",
    "end": "524000"
  },
  {
    "text": "can run python code",
    "start": "524000",
    "end": "526720"
  },
  {
    "text": "it's not designed to do so",
    "start": "526720",
    "end": "530000"
  },
  {
    "text": "so you have a very limited number of",
    "start": "530000",
    "end": "533360"
  },
  {
    "text": "libraries available to you",
    "start": "533360",
    "end": "535839"
  },
  {
    "text": "then we got the sh maker suite that",
    "start": "535839",
    "end": "538959"
  },
  {
    "text": "if you're running on aws that's",
    "start": "538959",
    "end": "542080"
  },
  {
    "text": "the most natural choice to look into but",
    "start": "542080",
    "end": "546800"
  },
  {
    "text": "at least when you're running batch jobs",
    "start": "546800",
    "end": "550080"
  },
  {
    "text": "that's underneath the apis are very",
    "start": "550080",
    "end": "553360"
  },
  {
    "text": "similar into",
    "start": "553360",
    "end": "554640"
  },
  {
    "text": "batches but service",
    "start": "554640",
    "end": "558160"
  },
  {
    "text": "so we discarded that as well",
    "start": "558160",
    "end": "562080"
  },
  {
    "text": "and yeah finally we came into rey",
    "start": "562080",
    "end": "565519"
  },
  {
    "text": "we found out about it on the auto scaler",
    "start": "565519",
    "end": "570000"
  },
  {
    "text": "um right from the very beginning",
    "start": "570000",
    "end": "573040"
  },
  {
    "text": "we saw that very small code changes",
    "start": "573040",
    "end": "576080"
  },
  {
    "text": "could solve the scaling and the cost",
    "start": "576080",
    "end": "578800"
  },
  {
    "text": "issues at the same time",
    "start": "578800",
    "end": "580560"
  },
  {
    "text": "so it looked very attractive for us",
    "start": "580560",
    "end": "583600"
  },
  {
    "text": "at first glance",
    "start": "583600",
    "end": "586639"
  },
  {
    "text": "so now i'll hand it off to domingo to",
    "start": "586720",
    "end": "590560"
  },
  {
    "text": "to take a look into that particular",
    "start": "590560",
    "end": "593839"
  },
  {
    "text": "scenario thank you roberto hi everyone",
    "start": "593839",
    "end": "597360"
  },
  {
    "text": "my name is duane ortuzar and i'm a",
    "start": "597360",
    "end": "599120"
  },
  {
    "text": "senior in a machine learning engineer",
    "start": "599120",
    "end": "601519"
  },
  {
    "text": "here at",
    "start": "601519",
    "end": "602079"
  },
  {
    "text": "anastasi i'm here to talk",
    "start": "602079",
    "end": "605120"
  },
  {
    "text": "about a deeper look inside our process",
    "start": "605120",
    "end": "608079"
  },
  {
    "text": "with ray",
    "start": "608079",
    "end": "608800"
  },
  {
    "text": "and how it helped us scale better",
    "start": "608800",
    "end": "612399"
  },
  {
    "text": "in the in the graphic in front you can",
    "start": "612399",
    "end": "614560"
  },
  {
    "text": "see that",
    "start": "614560",
    "end": "615440"
  },
  {
    "text": "at first first look looks very similar",
    "start": "615440",
    "end": "619600"
  },
  {
    "text": "to",
    "start": "619600",
    "end": "620480"
  },
  {
    "text": "our aws batch implementation",
    "start": "620480",
    "end": "624000"
  },
  {
    "text": "the biggest difference is that we are",
    "start": "624000",
    "end": "627839"
  },
  {
    "text": "better managing the work the workload",
    "start": "627839",
    "end": "630399"
  },
  {
    "text": "across the different instances",
    "start": "630399",
    "end": "633839"
  },
  {
    "text": "we are also using a head node to",
    "start": "633839",
    "end": "636560"
  },
  {
    "text": "properly",
    "start": "636560",
    "end": "637760"
  },
  {
    "text": "send the task to the different worker",
    "start": "637760",
    "end": "639920"
  },
  {
    "text": "nodes",
    "start": "639920",
    "end": "640880"
  },
  {
    "text": "and we also made some fixes inside our",
    "start": "640880",
    "end": "643920"
  },
  {
    "text": "code that",
    "start": "643920",
    "end": "644560"
  },
  {
    "text": "allows for every node to work with",
    "start": "644560",
    "end": "647839"
  },
  {
    "text": "every single every single type of model",
    "start": "647839",
    "end": "652079"
  },
  {
    "text": "so how about we take a little a",
    "start": "652079",
    "end": "655519"
  },
  {
    "text": "closer look inside what what's going on",
    "start": "655519",
    "end": "657760"
  },
  {
    "text": "in the nodes",
    "start": "657760",
    "end": "660000"
  },
  {
    "start": "659000",
    "end": "758000"
  },
  {
    "text": "so our approach for",
    "start": "660000",
    "end": "663120"
  },
  {
    "text": "designing our code was based on",
    "start": "663120",
    "end": "666720"
  },
  {
    "text": "queues and actors we use queues to load",
    "start": "666720",
    "end": "670480"
  },
  {
    "text": "up the data",
    "start": "670480",
    "end": "671680"
  },
  {
    "text": "from anastasia's many data sources both",
    "start": "671680",
    "end": "675040"
  },
  {
    "text": "private and open then this data",
    "start": "675040",
    "end": "678320"
  },
  {
    "text": "is passed down to the consumer actor",
    "start": "678320",
    "end": "681600"
  },
  {
    "text": "who then processes it and creates new",
    "start": "681600",
    "end": "684640"
  },
  {
    "text": "prediction",
    "start": "684640",
    "end": "686000"
  },
  {
    "text": "then this new are then sent to the data",
    "start": "686000",
    "end": "688800"
  },
  {
    "text": "transfer actors",
    "start": "688800",
    "end": "690160"
  },
  {
    "text": "who will save it on aws s3",
    "start": "690160",
    "end": "693600"
  },
  {
    "text": "this allows us to be using all the",
    "start": "693600",
    "end": "696720"
  },
  {
    "text": "resources available from different nodes",
    "start": "696720",
    "end": "699680"
  },
  {
    "text": "and we can also experience a great",
    "start": "699680",
    "end": "703200"
  },
  {
    "text": "improvement in our both cpu usage and",
    "start": "703200",
    "end": "707279"
  },
  {
    "text": "speed",
    "start": "707279",
    "end": "708720"
  },
  {
    "text": "so this allows us to",
    "start": "708720",
    "end": "712720"
  },
  {
    "text": "greatly increase our processing speed",
    "start": "712720",
    "end": "715839"
  },
  {
    "text": "while decreasing the number of",
    "start": "715839",
    "end": "718560"
  },
  {
    "text": "resources used during a job",
    "start": "718560",
    "end": "721760"
  },
  {
    "text": "now also another thing that our code",
    "start": "721760",
    "end": "724800"
  },
  {
    "text": "allows us to",
    "start": "724800",
    "end": "726000"
  },
  {
    "text": "set man both manually and automatically",
    "start": "726000",
    "end": "728399"
  },
  {
    "text": "the number of actors that are working",
    "start": "728399",
    "end": "731200"
  },
  {
    "text": "in the whole entire job one of the",
    "start": "731200",
    "end": "734160"
  },
  {
    "text": "things that we were very surprised to",
    "start": "734160",
    "end": "735920"
  },
  {
    "text": "see",
    "start": "735920",
    "end": "736800"
  },
  {
    "text": "is that with this type of implementation",
    "start": "736800",
    "end": "739519"
  },
  {
    "text": "we are able to",
    "start": "739519",
    "end": "741040"
  },
  {
    "text": "reduce the number of",
    "start": "741040",
    "end": "745360"
  },
  {
    "text": "reduce the number of actors used during",
    "start": "745360",
    "end": "748079"
  },
  {
    "text": "a process",
    "start": "748079",
    "end": "750800"
  },
  {
    "text": "now let's look into some of the some of",
    "start": "751360",
    "end": "754079"
  },
  {
    "text": "the",
    "start": "754079",
    "end": "755200"
  },
  {
    "text": "conclusion some of the results we had",
    "start": "755200",
    "end": "758959"
  },
  {
    "start": "758000",
    "end": "829000"
  },
  {
    "text": "so we tested our current",
    "start": "758959",
    "end": "761079"
  },
  {
    "text": "reimplementation",
    "start": "761079",
    "end": "762720"
  },
  {
    "text": "with our with the same configuration and",
    "start": "762720",
    "end": "765839"
  },
  {
    "text": "the same",
    "start": "765839",
    "end": "767120"
  },
  {
    "text": "models that our aws patch implementation",
    "start": "767120",
    "end": "770800"
  },
  {
    "text": "also we are using any scale to configure",
    "start": "770800",
    "end": "773120"
  },
  {
    "text": "the different clusters",
    "start": "773120",
    "end": "775440"
  },
  {
    "text": "so this implementation",
    "start": "775440",
    "end": "778720"
  },
  {
    "text": "reduce the cost by lowering the amount",
    "start": "778720",
    "end": "780720"
  },
  {
    "text": "of cpu needed",
    "start": "780720",
    "end": "782399"
  },
  {
    "text": "for running a job also the speed of",
    "start": "782399",
    "end": "786000"
  },
  {
    "text": "the processing it increase it also",
    "start": "786000",
    "end": "788160"
  },
  {
    "text": "lowers the time that",
    "start": "788160",
    "end": "789680"
  },
  {
    "text": "the aws instances needed to be up also",
    "start": "789680",
    "end": "792399"
  },
  {
    "text": "lowering the cost",
    "start": "792399",
    "end": "794079"
  },
  {
    "text": "we also got faster results because we're",
    "start": "794079",
    "end": "797519"
  },
  {
    "text": "not using",
    "start": "797519",
    "end": "798560"
  },
  {
    "text": "one instance per model but every",
    "start": "798560",
    "end": "801120"
  },
  {
    "text": "instance",
    "start": "801120",
    "end": "801760"
  },
  {
    "text": "is able to run every single model making",
    "start": "801760",
    "end": "804959"
  },
  {
    "text": "it",
    "start": "804959",
    "end": "805360"
  },
  {
    "text": "faster as we are always using all the",
    "start": "805360",
    "end": "808399"
  },
  {
    "text": "resources available",
    "start": "808399",
    "end": "810720"
  },
  {
    "text": "so also one of the surprising",
    "start": "810720",
    "end": "814079"
  },
  {
    "text": "results we got is that our per core",
    "start": "814079",
    "end": "818639"
  },
  {
    "text": "speed was actually faster than using a",
    "start": "818639",
    "end": "821440"
  },
  {
    "text": "python's built-in multi-processing",
    "start": "821440",
    "end": "824160"
  },
  {
    "text": "so i'll hand it back to roberto who can",
    "start": "824160",
    "end": "826800"
  },
  {
    "text": "talk to you more about these results",
    "start": "826800",
    "end": "830160"
  },
  {
    "start": "829000",
    "end": "900000"
  },
  {
    "text": "okay thank you domingo and now let's",
    "start": "830160",
    "end": "833120"
  },
  {
    "text": "take a",
    "start": "833120",
    "end": "833519"
  },
  {
    "text": "closer look into what the details of",
    "start": "833519",
    "end": "836240"
  },
  {
    "text": "what",
    "start": "836240",
    "end": "837120"
  },
  {
    "text": "domingo described what what were the",
    "start": "837120",
    "end": "839760"
  },
  {
    "text": "results and how we tested them",
    "start": "839760",
    "end": "842320"
  },
  {
    "text": "so we did a test job consisting of",
    "start": "842320",
    "end": "845600"
  },
  {
    "text": "100 000 time series each with 120",
    "start": "845600",
    "end": "849440"
  },
  {
    "text": "data points for each item",
    "start": "849440",
    "end": "852959"
  },
  {
    "text": "and then we used 384 cpu",
    "start": "852959",
    "end": "856240"
  },
  {
    "text": "cores in in the pure python",
    "start": "856240",
    "end": "859360"
  },
  {
    "text": "implementation the aws patch",
    "start": "859360",
    "end": "861279"
  },
  {
    "text": "if you recall the instances were",
    "start": "861279",
    "end": "864480"
  },
  {
    "text": "isolated",
    "start": "864480",
    "end": "865839"
  },
  {
    "text": "between them and each were processing a",
    "start": "865839",
    "end": "868399"
  },
  {
    "text": "single",
    "start": "868399",
    "end": "868959"
  },
  {
    "text": "model type those were using the",
    "start": "868959",
    "end": "873199"
  },
  {
    "text": "on-demand instances so the price was the",
    "start": "873199",
    "end": "875680"
  },
  {
    "text": "full",
    "start": "875680",
    "end": "876320"
  },
  {
    "text": "100 listing price",
    "start": "876320",
    "end": "880880"
  },
  {
    "text": "on the right side the instances were",
    "start": "880880",
    "end": "883279"
  },
  {
    "text": "forming a true cluster setup",
    "start": "883279",
    "end": "885920"
  },
  {
    "text": "uh we had more east",
    "start": "885920",
    "end": "889279"
  },
  {
    "text": "more instances distributed uh with",
    "start": "889279",
    "end": "892399"
  },
  {
    "text": "fewer cpu cores for each and we were",
    "start": "892399",
    "end": "895199"
  },
  {
    "text": "using",
    "start": "895199",
    "end": "895680"
  },
  {
    "text": "spot instances with their discounts",
    "start": "895680",
    "end": "898240"
  },
  {
    "text": "associated",
    "start": "898240",
    "end": "900720"
  },
  {
    "start": "900000",
    "end": "949000"
  },
  {
    "text": "we saw a tremendous",
    "start": "900720",
    "end": "904879"
  },
  {
    "text": "um results the the array implementation",
    "start": "904959",
    "end": "907920"
  },
  {
    "text": "was nine",
    "start": "907920",
    "end": "908560"
  },
  {
    "text": "times faster and 87 cheaper",
    "start": "908560",
    "end": "912000"
  },
  {
    "text": "at the same time",
    "start": "912000",
    "end": "914720"
  },
  {
    "text": "this cost reduction as domingo was",
    "start": "915040",
    "end": "917760"
  },
  {
    "text": "saying",
    "start": "917760",
    "end": "918399"
  },
  {
    "text": "not only is reflected because of the",
    "start": "918399",
    "end": "921199"
  },
  {
    "text": "spot instance",
    "start": "921199",
    "end": "923360"
  },
  {
    "text": "cheaper discounts also we saw that",
    "start": "923360",
    "end": "927199"
  },
  {
    "text": "as the instances were able to",
    "start": "927199",
    "end": "931120"
  },
  {
    "text": "process more or faster",
    "start": "931120",
    "end": "934720"
  },
  {
    "text": "per cpu core then the whole",
    "start": "934720",
    "end": "937759"
  },
  {
    "text": "job in itself was",
    "start": "937759",
    "end": "940880"
  },
  {
    "text": "shorter and thus the",
    "start": "940880",
    "end": "945120"
  },
  {
    "text": "the price was further decreased",
    "start": "945120",
    "end": "949279"
  },
  {
    "start": "949000",
    "end": "1037000"
  },
  {
    "text": "um so after starting",
    "start": "950000",
    "end": "953120"
  },
  {
    "text": "after starting to use the rey auto",
    "start": "953120",
    "end": "955360"
  },
  {
    "text": "scaler",
    "start": "955360",
    "end": "956720"
  },
  {
    "text": "we came to see more sophisticated issues",
    "start": "956720",
    "end": "960399"
  },
  {
    "text": "than before so for example",
    "start": "960399",
    "end": "963839"
  },
  {
    "text": "the production use of the rail to scaler",
    "start": "963839",
    "end": "967120"
  },
  {
    "text": "requires careful devops processes",
    "start": "967120",
    "end": "970399"
  },
  {
    "text": "that were not um",
    "start": "970399",
    "end": "973600"
  },
  {
    "text": "that were managed by aws service before",
    "start": "973600",
    "end": "977519"
  },
  {
    "text": "also the bottlenecks are",
    "start": "977519",
    "end": "981040"
  },
  {
    "text": "start to be harder to identify when",
    "start": "981040",
    "end": "983360"
  },
  {
    "text": "running from your laptop",
    "start": "983360",
    "end": "984959"
  },
  {
    "text": "because you can the same",
    "start": "984959",
    "end": "988720"
  },
  {
    "text": "one of ray's strengths is that",
    "start": "988720",
    "end": "991759"
  },
  {
    "text": "is that the same code can be run on your",
    "start": "991759",
    "end": "994240"
  },
  {
    "text": "laptop and then on the cluster",
    "start": "994240",
    "end": "996320"
  },
  {
    "text": "so if you run on your laptop and you see",
    "start": "996320",
    "end": "998399"
  },
  {
    "text": "everything",
    "start": "998399",
    "end": "999600"
  },
  {
    "text": "running fine using all the all the cpu",
    "start": "999600",
    "end": "1003040"
  },
  {
    "text": "at hand or the gpus",
    "start": "1003040",
    "end": "1004720"
  },
  {
    "text": "and etc it's not",
    "start": "1004720",
    "end": "1009040"
  },
  {
    "text": "easy to to identify if you'll have",
    "start": "1009040",
    "end": "1013279"
  },
  {
    "text": "a bottleneck then when you run on the",
    "start": "1013279",
    "end": "1015279"
  },
  {
    "text": "cluster with all that",
    "start": "1015279",
    "end": "1017440"
  },
  {
    "text": "power at hand and",
    "start": "1017440",
    "end": "1020800"
  },
  {
    "text": "we saw that so we we needed to do some",
    "start": "1020800",
    "end": "1023839"
  },
  {
    "text": "iterations on the code",
    "start": "1023839",
    "end": "1026000"
  },
  {
    "text": "uh to remedy that then",
    "start": "1026000",
    "end": "1029760"
  },
  {
    "text": "also sharing a cluster is is not easy to",
    "start": "1029760",
    "end": "1032959"
  },
  {
    "text": "do",
    "start": "1032959",
    "end": "1033438"
  },
  {
    "text": "when you're working on a team for",
    "start": "1033439",
    "end": "1035360"
  },
  {
    "text": "example",
    "start": "1035360",
    "end": "1037678"
  },
  {
    "start": "1037000",
    "end": "1138000"
  },
  {
    "text": "so that brings us to any scale uh any",
    "start": "1037679",
    "end": "1040640"
  },
  {
    "text": "scale",
    "start": "1040640",
    "end": "1041280"
  },
  {
    "text": "makes it extremely easy from the devops",
    "start": "1041280",
    "end": "1044160"
  },
  {
    "text": "side",
    "start": "1044160",
    "end": "1044880"
  },
  {
    "text": "because you have at your at your",
    "start": "1044880",
    "end": "1046798"
  },
  {
    "text": "disposal a",
    "start": "1046799",
    "end": "1047918"
  },
  {
    "text": "python sdk and an api then you've got",
    "start": "1047919",
    "end": "1051440"
  },
  {
    "text": "the",
    "start": "1051440",
    "end": "1052240"
  },
  {
    "text": "versioning and the governance they've",
    "start": "1052240",
    "end": "1054640"
  },
  {
    "text": "taken",
    "start": "1054640",
    "end": "1055440"
  },
  {
    "text": "taken care of so you have",
    "start": "1055440",
    "end": "1058960"
  },
  {
    "text": "visibility into who did what",
    "start": "1058960",
    "end": "1062799"
  },
  {
    "text": "and when then you can",
    "start": "1062799",
    "end": "1066160"
  },
  {
    "text": "seamlessly manage share and run those",
    "start": "1066160",
    "end": "1068720"
  },
  {
    "text": "clusters across multiple themes",
    "start": "1068720",
    "end": "1071280"
  },
  {
    "text": "uh in that's very helpful for us",
    "start": "1071280",
    "end": "1075440"
  },
  {
    "text": "especially when you're working",
    "start": "1075440",
    "end": "1079120"
  },
  {
    "text": "on on the business you have multiple",
    "start": "1079280",
    "end": "1082400"
  },
  {
    "text": "people running",
    "start": "1082400",
    "end": "1083760"
  },
  {
    "text": "the same code within the same clusters",
    "start": "1083760",
    "end": "1087200"
  },
  {
    "text": "and finally the optimal orchestration of",
    "start": "1087200",
    "end": "1090799"
  },
  {
    "text": "those ray clusters",
    "start": "1090799",
    "end": "1092559"
  },
  {
    "text": "it's taken care of by ray's own creators",
    "start": "1092559",
    "end": "1096320"
  },
  {
    "text": "so in that sense if",
    "start": "1096320",
    "end": "1099600"
  },
  {
    "text": "if you were to to do all of this",
    "start": "1099600",
    "end": "1104000"
  },
  {
    "text": "in-house you would end up having",
    "start": "1104000",
    "end": "1109520"
  },
  {
    "text": "a a whole team dedicated",
    "start": "1109520",
    "end": "1112559"
  },
  {
    "text": "into doing what they already",
    "start": "1112559",
    "end": "1115760"
  },
  {
    "text": "offering us so so for us",
    "start": "1115760",
    "end": "1119840"
  },
  {
    "text": "it was it was very",
    "start": "1119840",
    "end": "1123120"
  },
  {
    "text": "evident that we needed to to absorb",
    "start": "1123120",
    "end": "1126320"
  },
  {
    "text": "all of that using any scale tool",
    "start": "1126320",
    "end": "1130160"
  },
  {
    "text": "and instead of instead of using",
    "start": "1130160",
    "end": "1134160"
  },
  {
    "text": "ray's autoscaler itself",
    "start": "1134160",
    "end": "1139039"
  },
  {
    "start": "1138000",
    "end": "1180000"
  },
  {
    "text": "so to conclude the talk um we can say",
    "start": "1139039",
    "end": "1142559"
  },
  {
    "text": "that",
    "start": "1142559",
    "end": "1143360"
  },
  {
    "text": "implementing these end-to-end ai",
    "start": "1143360",
    "end": "1145280"
  },
  {
    "text": "workloads using ray",
    "start": "1145280",
    "end": "1148000"
  },
  {
    "text": "you get like a really simple experience",
    "start": "1148000",
    "end": "1151120"
  },
  {
    "text": "for develop",
    "start": "1151120",
    "end": "1151919"
  },
  {
    "text": "developers to scale their code",
    "start": "1151919",
    "end": "1156080"
  },
  {
    "text": "and doing so brings improves the",
    "start": "1156080",
    "end": "1159360"
  },
  {
    "text": "the performance and lowers the cost",
    "start": "1159360",
    "end": "1162840"
  },
  {
    "text": "infrastructure tremendously",
    "start": "1162840",
    "end": "1165760"
  },
  {
    "text": "and finally that any scale helps you",
    "start": "1165760",
    "end": "1169120"
  },
  {
    "text": "manage",
    "start": "1169120",
    "end": "1169760"
  },
  {
    "text": "and automate those ray clusters",
    "start": "1169760",
    "end": "1174320"
  },
  {
    "text": "and with that thank you for listening",
    "start": "1174720",
    "end": "1177600"
  },
  {
    "text": "have a nice day",
    "start": "1177600",
    "end": "1182240"
  }
]
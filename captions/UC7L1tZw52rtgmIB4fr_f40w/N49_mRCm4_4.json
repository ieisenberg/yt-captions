[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "[Music]",
    "start": "170",
    "end": "14559"
  },
  {
    "text": "hi",
    "start": "14559",
    "end": "14880"
  },
  {
    "text": "and welcome to our talk on disrevoted",
    "start": "14880",
    "end": "16480"
  },
  {
    "text": "extra boost on rey my name is kai and",
    "start": "16480",
    "end": "18400"
  },
  {
    "text": "i'm a software engineer at any skill",
    "start": "18400",
    "end": "20320"
  },
  {
    "text": "i'll be holding this talk with michael",
    "start": "20320",
    "end": "21760"
  },
  {
    "text": "mooey who is a senior software engineer",
    "start": "21760",
    "end": "23359"
  },
  {
    "text": "at uber",
    "start": "23359",
    "end": "25119"
  },
  {
    "text": "we divided this talk into two parts",
    "start": "25119",
    "end": "27359"
  },
  {
    "text": "first i'll be talking about extra boost",
    "start": "27359",
    "end": "29199"
  },
  {
    "text": "ray",
    "start": "29199",
    "end": "30160"
  },
  {
    "text": "i'll start with a quick motivation and",
    "start": "30160",
    "end": "31599"
  },
  {
    "text": "recap after which i'll introduce the",
    "start": "31599",
    "end": "33360"
  },
  {
    "text": "general architecture and the features of",
    "start": "33360",
    "end": "35280"
  },
  {
    "text": "actual straight",
    "start": "35280",
    "end": "36719"
  },
  {
    "text": "then michael will talk about actual ray",
    "start": "36719",
    "end": "39040"
  },
  {
    "text": "adoption at uber",
    "start": "39040",
    "end": "41920"
  },
  {
    "start": "41000",
    "end": "41000"
  },
  {
    "text": "so there is a number of existing",
    "start": "41920",
    "end": "43600"
  },
  {
    "text": "solutions for distributed attributes",
    "start": "43600",
    "end": "46079"
  },
  {
    "text": "training",
    "start": "46079",
    "end": "46559"
  },
  {
    "text": "for instance on spark dask and",
    "start": "46559",
    "end": "48559"
  },
  {
    "text": "kubernetes",
    "start": "48559",
    "end": "50079"
  },
  {
    "text": "but most of these are lacking important",
    "start": "50079",
    "end": "51840"
  },
  {
    "text": "features spark for instance",
    "start": "51840",
    "end": "54000"
  },
  {
    "text": "uses a static computation graph which",
    "start": "54000",
    "end": "55920"
  },
  {
    "text": "does not work well with dynamics",
    "start": "55920",
    "end": "57760"
  },
  {
    "text": "scheduling decisions we might get during",
    "start": "57760",
    "end": "59520"
  },
  {
    "text": "hyper parameter optimization",
    "start": "59520",
    "end": "62079"
  },
  {
    "text": "related to that the existing solutions",
    "start": "62079",
    "end": "64158"
  },
  {
    "text": "don't offer good fall tolerance handling",
    "start": "64159",
    "end": "66720"
  },
  {
    "text": "you usually just restart the training",
    "start": "66720",
    "end": "68560"
  },
  {
    "text": "run when something is wrong",
    "start": "68560",
    "end": "70880"
  },
  {
    "text": "some implementations don't support gpus",
    "start": "70880",
    "end": "72960"
  },
  {
    "text": "very well or",
    "start": "72960",
    "end": "73920"
  },
  {
    "text": "at all and lastly it's not easy to make",
    "start": "73920",
    "end": "76560"
  },
  {
    "text": "them work with the hyperparameter tuning",
    "start": "76560",
    "end": "78400"
  },
  {
    "text": "libraries",
    "start": "78400",
    "end": "80240"
  },
  {
    "start": "79000",
    "end": "79000"
  },
  {
    "text": "with actual boost ray we try to address",
    "start": "80240",
    "end": "82240"
  },
  {
    "text": "these issues",
    "start": "82240",
    "end": "83840"
  },
  {
    "text": "actually with ray leverages the ray",
    "start": "83840",
    "end": "85759"
  },
  {
    "text": "actor model to implement stateful",
    "start": "85759",
    "end": "87280"
  },
  {
    "text": "training workers",
    "start": "87280",
    "end": "88799"
  },
  {
    "text": "this in turn enables us to implement",
    "start": "88799",
    "end": "90799"
  },
  {
    "text": "advanced fault tolerance mechanisms",
    "start": "90799",
    "end": "92560"
  },
  {
    "text": "where actors can retain their state even",
    "start": "92560",
    "end": "94400"
  },
  {
    "text": "when other actors die",
    "start": "94400",
    "end": "96880"
  },
  {
    "text": "actually with ray comes with full",
    "start": "96880",
    "end": "98560"
  },
  {
    "text": "multi-node multi-gpu",
    "start": "98560",
    "end": "100000"
  },
  {
    "text": "support we implemented locality aware",
    "start": "100000",
    "end": "102799"
  },
  {
    "text": "distributed data loading for distributed",
    "start": "102799",
    "end": "104960"
  },
  {
    "text": "data frames such as modern audac",
    "start": "104960",
    "end": "107680"
  },
  {
    "text": "and lastly we integrate seamlessly with",
    "start": "107680",
    "end": "109600"
  },
  {
    "text": "hyper parameter optimization framework",
    "start": "109600",
    "end": "111600"
  },
  {
    "text": "ray tune",
    "start": "111600",
    "end": "113759"
  },
  {
    "start": "113000",
    "end": "113000"
  },
  {
    "text": "before we head into the architecture",
    "start": "113759",
    "end": "115759"
  },
  {
    "text": "let's very briefly recap on how",
    "start": "115759",
    "end": "117680"
  },
  {
    "text": "extra boost and distributed attributes",
    "start": "117680",
    "end": "119600"
  },
  {
    "text": "works in general",
    "start": "119600",
    "end": "121600"
  },
  {
    "text": "so actually boost is a gradient boosting",
    "start": "121600",
    "end": "123680"
  },
  {
    "text": "algorithm",
    "start": "123680",
    "end": "124640"
  },
  {
    "text": "and this means that at each iteration a",
    "start": "124640",
    "end": "127119"
  },
  {
    "text": "new simple model is trained",
    "start": "127119",
    "end": "129759"
  },
  {
    "text": "these models are often decision trees",
    "start": "129759",
    "end": "131680"
  },
  {
    "text": "especially for classification but they",
    "start": "131680",
    "end": "133440"
  },
  {
    "text": "can also be linear models",
    "start": "133440",
    "end": "136160"
  },
  {
    "text": "and then at each step the next model",
    "start": "136160",
    "end": "138319"
  },
  {
    "text": "tries to fit the residuals of the",
    "start": "138319",
    "end": "139920"
  },
  {
    "text": "combined previous models",
    "start": "139920",
    "end": "142480"
  },
  {
    "text": "this optimization is done via loss",
    "start": "142480",
    "end": "144160"
  },
  {
    "text": "gradients and in the case of actual",
    "start": "144160",
    "end": "145920"
  },
  {
    "text": "boost using second order taylor",
    "start": "145920",
    "end": "147440"
  },
  {
    "text": "approximations",
    "start": "147440",
    "end": "149360"
  },
  {
    "text": "by adding more and more models we are",
    "start": "149360",
    "end": "151120"
  },
  {
    "text": "slowly refining the model ensemble to",
    "start": "151120",
    "end": "153120"
  },
  {
    "text": "give a better and better fit",
    "start": "153120",
    "end": "156560"
  },
  {
    "start": "156000",
    "end": "156000"
  },
  {
    "text": "distributed attributes takes a data",
    "start": "156560",
    "end": "158239"
  },
  {
    "text": "parallel approach this means that each",
    "start": "158239",
    "end": "160640"
  },
  {
    "text": "worker shares the same model but trains",
    "start": "160640",
    "end": "162720"
  },
  {
    "text": "on a different part of the data set",
    "start": "162720",
    "end": "165200"
  },
  {
    "text": "the yellow boxes in the figure represent",
    "start": "165200",
    "end": "167200"
  },
  {
    "text": "the data set and",
    "start": "167200",
    "end": "168239"
  },
  {
    "text": "its partitions workers are represented",
    "start": "168239",
    "end": "171680"
  },
  {
    "text": "by the green boxes",
    "start": "171680",
    "end": "172879"
  },
  {
    "text": "each worker independently trains a full",
    "start": "172879",
    "end": "174879"
  },
  {
    "text": "model using its available data",
    "start": "174879",
    "end": "177280"
  },
  {
    "text": "the per-feature loss gradients are then",
    "start": "177280",
    "end": "179120"
  },
  {
    "text": "communicated synchronized and merged to",
    "start": "179120",
    "end": "181360"
  },
  {
    "text": "construct a full tree of the iteration",
    "start": "181360",
    "end": "184319"
  },
  {
    "text": "axoboost uses an all-reduce",
    "start": "184319",
    "end": "185920"
  },
  {
    "text": "implementation called rabbit to",
    "start": "185920",
    "end": "187599"
  },
  {
    "text": "synchronize",
    "start": "187599",
    "end": "188239"
  },
  {
    "text": "gradients a centralized tracker is used",
    "start": "188239",
    "end": "190959"
  },
  {
    "text": "to register distributed workers",
    "start": "190959",
    "end": "192879"
  },
  {
    "text": "and is shown in the red box workers then",
    "start": "192879",
    "end": "195760"
  },
  {
    "text": "communicate directly with each other and",
    "start": "195760",
    "end": "197599"
  },
  {
    "text": "pass their gradients around until each",
    "start": "197599",
    "end": "199440"
  },
  {
    "text": "worker ends up with the same information",
    "start": "199440",
    "end": "203120"
  },
  {
    "start": "202000",
    "end": "202000"
  },
  {
    "text": "let's take a look at the actual ray",
    "start": "204319",
    "end": "206159"
  },
  {
    "text": "architecture in this example we have",
    "start": "206159",
    "end": "208480"
  },
  {
    "text": "four distributed training workers",
    "start": "208480",
    "end": "211040"
  },
  {
    "text": "in raid terms these are all remote",
    "start": "211040",
    "end": "213120"
  },
  {
    "text": "actors and can live on the same or",
    "start": "213120",
    "end": "214799"
  },
  {
    "text": "different machines on the cluster",
    "start": "214799",
    "end": "218080"
  },
  {
    "text": "the driver first kicks off the",
    "start": "218080",
    "end": "219519"
  },
  {
    "text": "distributed data loading",
    "start": "219519",
    "end": "221599"
  },
  {
    "text": "each worker loads their respective share",
    "start": "221599",
    "end": "223360"
  },
  {
    "text": "of data and this happens in parallel",
    "start": "223360",
    "end": "227519"
  },
  {
    "text": "next the driver invokes the native",
    "start": "227519",
    "end": "229440"
  },
  {
    "text": "activist.train methods on each remote",
    "start": "229440",
    "end": "231519"
  },
  {
    "text": "actor",
    "start": "231519",
    "end": "233040"
  },
  {
    "text": "as discussed activist communicates the",
    "start": "233040",
    "end": "235280"
  },
  {
    "text": "gradients via revit",
    "start": "235280",
    "end": "236560"
  },
  {
    "text": "all we have to do is set up the rabbit",
    "start": "236560",
    "end": "238319"
  },
  {
    "text": "parameter tracking server",
    "start": "238319",
    "end": "241840"
  },
  {
    "text": "the worker with the lowest rank is a",
    "start": "241840",
    "end": "243519"
  },
  {
    "text": "designated actor to report evaluation",
    "start": "243519",
    "end": "245680"
  },
  {
    "text": "results and checkpoints to the driver",
    "start": "245680",
    "end": "248159"
  },
  {
    "text": "since every worker works with the same",
    "start": "248159",
    "end": "249840"
  },
  {
    "text": "model this is an arbitrary choice",
    "start": "249840",
    "end": "252239"
  },
  {
    "text": "also note that this is not a single",
    "start": "252239",
    "end": "254000"
  },
  {
    "text": "point of failure if the lowest rank",
    "start": "254000",
    "end": "256000"
  },
  {
    "text": "actor dies the next actor takes its",
    "start": "256000",
    "end": "257759"
  },
  {
    "text": "place and communicates with the driver",
    "start": "257759",
    "end": "259199"
  },
  {
    "text": "instead",
    "start": "259199",
    "end": "261600"
  },
  {
    "start": "260000",
    "end": "260000"
  },
  {
    "text": "for distributed data loading we can load",
    "start": "261919",
    "end": "263759"
  },
  {
    "text": "from various sources",
    "start": "263759",
    "end": "265040"
  },
  {
    "text": "such as hdfs or cloud storage like s3 or",
    "start": "265040",
    "end": "268160"
  },
  {
    "text": "google storage",
    "start": "268160",
    "end": "269600"
  },
  {
    "text": "but actually with ray can also leverage",
    "start": "269600",
    "end": "271440"
  },
  {
    "text": "existing distributed data frame",
    "start": "271440",
    "end": "273360"
  },
  {
    "text": "representations such as modern data",
    "start": "273360",
    "end": "275600"
  },
  {
    "text": "frames",
    "start": "275600",
    "end": "276880"
  },
  {
    "text": "say you have four nodes and eight data",
    "start": "276880",
    "end": "279440"
  },
  {
    "text": "frame partitions",
    "start": "279440",
    "end": "280639"
  },
  {
    "text": "in this example they are unevenly",
    "start": "280639",
    "end": "282160"
  },
  {
    "text": "distributed",
    "start": "282160",
    "end": "284160"
  },
  {
    "text": "when you start actually with ray here it",
    "start": "284160",
    "end": "286240"
  },
  {
    "text": "will be aware of the data locality",
    "start": "286240",
    "end": "288320"
  },
  {
    "text": "and assigned petitions to the workers by",
    "start": "288320",
    "end": "290240"
  },
  {
    "text": "node thus",
    "start": "290240",
    "end": "291600"
  },
  {
    "text": "each worker will first be assigned",
    "start": "291600",
    "end": "293120"
  },
  {
    "text": "co-located partitions",
    "start": "293120",
    "end": "295440"
  },
  {
    "text": "afterwards petitions are moved between",
    "start": "295440",
    "end": "297840"
  },
  {
    "text": "nodes so that each worker",
    "start": "297840",
    "end": "299360"
  },
  {
    "text": "ends up with an even amount of petitions",
    "start": "299360",
    "end": "302639"
  },
  {
    "text": "this is a simple example with an even",
    "start": "302639",
    "end": "304479"
  },
  {
    "text": "total number of petitions",
    "start": "304479",
    "end": "306000"
  },
  {
    "text": "but it also works with odd numbers and",
    "start": "306000",
    "end": "307919"
  },
  {
    "text": "unfavorable initial data distributions",
    "start": "307919",
    "end": "312240"
  },
  {
    "text": "in distributed training you will",
    "start": "313199",
    "end": "314880"
  },
  {
    "text": "eventually find that some nodes die",
    "start": "314880",
    "end": "317039"
  },
  {
    "text": "or get disconnected from the cluster the",
    "start": "317039",
    "end": "319520"
  },
  {
    "text": "default way",
    "start": "319520",
    "end": "320639"
  },
  {
    "text": "to handle this is to just restart the",
    "start": "320639",
    "end": "322720"
  },
  {
    "text": "training job from the latest checkpoint",
    "start": "322720",
    "end": "324479"
  },
  {
    "text": "and for the remaining amount of",
    "start": "324479",
    "end": "325680"
  },
  {
    "text": "iterations",
    "start": "325680",
    "end": "326960"
  },
  {
    "text": "usually this requires the full training",
    "start": "326960",
    "end": "329039"
  },
  {
    "text": "cycle to start anew",
    "start": "329039",
    "end": "330479"
  },
  {
    "text": "including data loading and other setup",
    "start": "330479",
    "end": "332400"
  },
  {
    "text": "overhead",
    "start": "332400",
    "end": "334479"
  },
  {
    "text": "activist ray comes with two more",
    "start": "334479",
    "end": "336400"
  },
  {
    "text": "advanced fault tolerance mechanisms",
    "start": "336400",
    "end": "339039"
  },
  {
    "text": "in non-elastic training we use a warm",
    "start": "339039",
    "end": "341199"
  },
  {
    "text": "restart approach where only the failing",
    "start": "341199",
    "end": "343199"
  },
  {
    "text": "actors are restarted and have to reload",
    "start": "343199",
    "end": "344960"
  },
  {
    "text": "their data",
    "start": "344960",
    "end": "347120"
  },
  {
    "text": "in elastic training we even continue",
    "start": "347120",
    "end": "349120"
  },
  {
    "text": "training with fewer workers and",
    "start": "349120",
    "end": "350560"
  },
  {
    "text": "reintegrate the restarted workers once",
    "start": "350560",
    "end": "352560"
  },
  {
    "text": "they are back",
    "start": "352560",
    "end": "353680"
  },
  {
    "text": "but let's get into a bit of more detail",
    "start": "353680",
    "end": "355759"
  },
  {
    "text": "here",
    "start": "355759",
    "end": "357600"
  },
  {
    "start": "357000",
    "end": "357000"
  },
  {
    "text": "let's start with the base case the",
    "start": "357600",
    "end": "359600"
  },
  {
    "text": "simple code restart",
    "start": "359600",
    "end": "361840"
  },
  {
    "text": "first all workers load their data",
    "start": "361840",
    "end": "364880"
  },
  {
    "text": "and then they begin training at some",
    "start": "364880",
    "end": "367280"
  },
  {
    "text": "point one of the workers dies",
    "start": "367280",
    "end": "370000"
  },
  {
    "text": "all remaining actors are then stopped as",
    "start": "370000",
    "end": "372080"
  },
  {
    "text": "well we restart the full training job",
    "start": "372080",
    "end": "374880"
  },
  {
    "text": "from the latest checkpoint",
    "start": "374880",
    "end": "376479"
  },
  {
    "text": "all actors reload their data and then",
    "start": "376479",
    "end": "378720"
  },
  {
    "text": "all actors begin training again",
    "start": "378720",
    "end": "381199"
  },
  {
    "text": "and it takes some time until it is",
    "start": "381199",
    "end": "382880"
  },
  {
    "text": "finished",
    "start": "382880",
    "end": "385280"
  },
  {
    "start": "384000",
    "end": "384000"
  },
  {
    "text": "in actual boost race warm restart case",
    "start": "386000",
    "end": "388240"
  },
  {
    "text": "we also start with data loading and",
    "start": "388240",
    "end": "389919"
  },
  {
    "text": "training",
    "start": "389919",
    "end": "390960"
  },
  {
    "text": "but once the actor dies the remaining",
    "start": "390960",
    "end": "393039"
  },
  {
    "text": "actors retain their state and they are",
    "start": "393039",
    "end": "394800"
  },
  {
    "text": "loaded data",
    "start": "394800",
    "end": "395680"
  },
  {
    "text": "and they are just put into an idle state",
    "start": "395680",
    "end": "398560"
  },
  {
    "text": "only the third actor reloads the data",
    "start": "398560",
    "end": "401840"
  },
  {
    "text": "training is then continued once the",
    "start": "401840",
    "end": "403680"
  },
  {
    "text": "third actor is ready again",
    "start": "403680",
    "end": "405440"
  },
  {
    "text": "it takes about the same time as the code",
    "start": "405440",
    "end": "407280"
  },
  {
    "text": "restart approach but it invokes much",
    "start": "407280",
    "end": "409199"
  },
  {
    "text": "less data transfer",
    "start": "409199",
    "end": "412240"
  },
  {
    "start": "411000",
    "end": "411000"
  },
  {
    "text": "in the elastic training case we take it",
    "start": "412560",
    "end": "414479"
  },
  {
    "text": "one step further",
    "start": "414479",
    "end": "416960"
  },
  {
    "text": "once the third worker dies the rest of",
    "start": "416960",
    "end": "419120"
  },
  {
    "text": "the workers just continue",
    "start": "419120",
    "end": "420400"
  },
  {
    "text": "training the third worker is restarted",
    "start": "420400",
    "end": "423360"
  },
  {
    "text": "and data loading is triggered",
    "start": "423360",
    "end": "424800"
  },
  {
    "text": "the rest of the workers still continue",
    "start": "424800",
    "end": "426880"
  },
  {
    "text": "training",
    "start": "426880",
    "end": "428479"
  },
  {
    "text": "only once the third worker is back is it",
    "start": "428479",
    "end": "430560"
  },
  {
    "text": "reintegrated into training again",
    "start": "430560",
    "end": "433199"
  },
  {
    "text": "this will finish much quicker than the",
    "start": "433199",
    "end": "434800"
  },
  {
    "text": "other modes however",
    "start": "434800",
    "end": "436319"
  },
  {
    "text": "since we train on fewer data for some",
    "start": "436319",
    "end": "438080"
  },
  {
    "text": "time there might be performance",
    "start": "438080",
    "end": "439599"
  },
  {
    "text": "impairments of the final model",
    "start": "439599",
    "end": "441360"
  },
  {
    "text": "so how great are those",
    "start": "441360",
    "end": "444560"
  },
  {
    "start": "444000",
    "end": "444000"
  },
  {
    "text": "we wear them we ran a benchmark on a",
    "start": "444880",
    "end": "448000"
  },
  {
    "text": "production size classification data set",
    "start": "448000",
    "end": "450160"
  },
  {
    "text": "with 30 million rows and 500 features",
    "start": "450160",
    "end": "452560"
  },
  {
    "text": "over 100",
    "start": "452560",
    "end": "453440"
  },
  {
    "text": "boosting rounds the baseline trains with",
    "start": "453440",
    "end": "456720"
  },
  {
    "text": "10 workers on the full data set",
    "start": "456720",
    "end": "458800"
  },
  {
    "text": "it shows an evaluation error of about",
    "start": "458800",
    "end": "461039"
  },
  {
    "text": "13.3 percent",
    "start": "461039",
    "end": "463120"
  },
  {
    "text": "it takes a bit more than 20 minutes to",
    "start": "463120",
    "end": "464879"
  },
  {
    "text": "run the training",
    "start": "464879",
    "end": "467360"
  },
  {
    "text": "the fewer workers condition is a sanity",
    "start": "467360",
    "end": "469280"
  },
  {
    "text": "check to see what happens if we train on",
    "start": "469280",
    "end": "471039"
  },
  {
    "text": "fewer data",
    "start": "471039",
    "end": "472319"
  },
  {
    "text": "we observe a little regression on the",
    "start": "472319",
    "end": "473840"
  },
  {
    "text": "evol error though not by much",
    "start": "473840",
    "end": "475680"
  },
  {
    "text": "and the error seems to get better with",
    "start": "475680",
    "end": "477759"
  },
  {
    "text": "fewer data",
    "start": "477759",
    "end": "478720"
  },
  {
    "text": "we attribute this to chance in the",
    "start": "478720",
    "end": "480240"
  },
  {
    "text": "random selection of the data partitions",
    "start": "480240",
    "end": "482639"
  },
  {
    "text": "the training time is comparable if",
    "start": "482639",
    "end": "484479"
  },
  {
    "text": "anything the baseline time might be a",
    "start": "484479",
    "end": "486240"
  },
  {
    "text": "bit off",
    "start": "486240",
    "end": "488720"
  },
  {
    "text": "next we'll check the non-elastic",
    "start": "489039",
    "end": "490720"
  },
  {
    "text": "training the actors die after about 50",
    "start": "490720",
    "end": "493120"
  },
  {
    "text": "percent of the training time",
    "start": "493120",
    "end": "494800"
  },
  {
    "text": "the eval error is slightly better than",
    "start": "494800",
    "end": "496639"
  },
  {
    "text": "in the field workers condition which",
    "start": "496639",
    "end": "498240"
  },
  {
    "text": "makes sense as we continue to train on",
    "start": "498240",
    "end": "499840"
  },
  {
    "text": "the full data set",
    "start": "499840",
    "end": "501520"
  },
  {
    "text": "we sometimes achieve better performance",
    "start": "501520",
    "end": "503280"
  },
  {
    "text": "than in the baseline so generally we can",
    "start": "503280",
    "end": "505440"
  },
  {
    "text": "say we are",
    "start": "505440",
    "end": "506160"
  },
  {
    "text": "on par however it takes almost twice as",
    "start": "506160",
    "end": "509039"
  },
  {
    "text": "long to train",
    "start": "509039",
    "end": "510080"
  },
  {
    "text": "mostly because we wait for the failed",
    "start": "510080",
    "end": "511680"
  },
  {
    "text": "actors to reload their data which makes",
    "start": "511680",
    "end": "513518"
  },
  {
    "text": "up a huge chunk of the workload",
    "start": "513519",
    "end": "516800"
  },
  {
    "text": "finally in elastic training we can see",
    "start": "516800",
    "end": "519039"
  },
  {
    "text": "that our evaluation error is ever so",
    "start": "519039",
    "end": "521039"
  },
  {
    "text": "slightly worse than in the non-elastic",
    "start": "521039",
    "end": "522800"
  },
  {
    "text": "case",
    "start": "522800",
    "end": "523360"
  },
  {
    "text": "but not off by much compared to the",
    "start": "523360",
    "end": "524880"
  },
  {
    "text": "baseline and usually better than in the",
    "start": "524880",
    "end": "526959"
  },
  {
    "text": "fewer workers condition",
    "start": "526959",
    "end": "528800"
  },
  {
    "text": "most importantly the training time is",
    "start": "528800",
    "end": "531200"
  },
  {
    "text": "basically the same as in the non-failing",
    "start": "531200",
    "end": "532959"
  },
  {
    "text": "cases",
    "start": "532959",
    "end": "534240"
  },
  {
    "text": "thus at least in the case where we have",
    "start": "534240",
    "end": "536160"
  },
  {
    "text": "large shuffle data sets",
    "start": "536160",
    "end": "537440"
  },
  {
    "text": "elastic training can give a great speed",
    "start": "537440",
    "end": "539279"
  },
  {
    "text": "up compared to other methods",
    "start": "539279",
    "end": "540880"
  },
  {
    "text": "without much performance impairment",
    "start": "540880",
    "end": "544480"
  },
  {
    "start": "543000",
    "end": "543000"
  },
  {
    "text": "for hyperparameter tuning we work on a",
    "start": "545279",
    "end": "547360"
  },
  {
    "text": "seamless integration with ray tune",
    "start": "547360",
    "end": "550880"
  },
  {
    "text": "using ray tune we can start multiply",
    "start": "550880",
    "end": "553200"
  },
  {
    "text": "distributed training runs",
    "start": "553200",
    "end": "555120"
  },
  {
    "text": "each of these trials uses their own",
    "start": "555120",
    "end": "556880"
  },
  {
    "text": "hyper parameter configuration",
    "start": "556880",
    "end": "559760"
  },
  {
    "text": "and each trial then starts a number of",
    "start": "559760",
    "end": "561600"
  },
  {
    "text": "distributed workers",
    "start": "561600",
    "end": "563120"
  },
  {
    "text": "the workers are scheduled so that",
    "start": "563120",
    "end": "564640"
  },
  {
    "text": "workers of a single trial are co-located",
    "start": "564640",
    "end": "567440"
  },
  {
    "text": "this is done to minimize the number of",
    "start": "567440",
    "end": "569200"
  },
  {
    "text": "trials impacted by node failures",
    "start": "569200",
    "end": "572560"
  },
  {
    "text": "the integration automatically reports",
    "start": "572560",
    "end": "574480"
  },
  {
    "text": "training and evaluation results",
    "start": "574480",
    "end": "576000"
  },
  {
    "text": "back to ray tune and it also saves",
    "start": "576000",
    "end": "578399"
  },
  {
    "text": "checkpoints",
    "start": "578399",
    "end": "580000"
  },
  {
    "text": "the integration can also make use of all",
    "start": "580000",
    "end": "582640"
  },
  {
    "text": "raytune features such as dynamic",
    "start": "582640",
    "end": "584640"
  },
  {
    "text": "scheduling decisions",
    "start": "584640",
    "end": "585760"
  },
  {
    "text": "like early stopping or search algorithms",
    "start": "585760",
    "end": "588160"
  },
  {
    "text": "like base opt or tree parson estimators",
    "start": "588160",
    "end": "592240"
  },
  {
    "text": "here's an api example on how to use",
    "start": "592800",
    "end": "595440"
  },
  {
    "text": "actually boost ray",
    "start": "595440",
    "end": "597040"
  },
  {
    "text": "first we'll show a non-distributed",
    "start": "597040",
    "end": "598640"
  },
  {
    "text": "training script",
    "start": "598640",
    "end": "600640"
  },
  {
    "text": "after the inputs we just load some data",
    "start": "600640",
    "end": "602839"
  },
  {
    "text": "set",
    "start": "602839",
    "end": "604240"
  },
  {
    "text": "initialize the actual d matrix train the",
    "start": "604240",
    "end": "607279"
  },
  {
    "text": "model",
    "start": "607279",
    "end": "608800"
  },
  {
    "text": "and save it afterwards now to make it",
    "start": "608800",
    "end": "611920"
  },
  {
    "text": "distributed we only have to change three",
    "start": "611920",
    "end": "614320"
  },
  {
    "text": "lines of codes",
    "start": "614320",
    "end": "616160"
  },
  {
    "text": "first we change the input instead of",
    "start": "616160",
    "end": "618959"
  },
  {
    "text": "importing from actually boost",
    "start": "618959",
    "end": "620560"
  },
  {
    "text": "we import from actual boost ray",
    "start": "620560",
    "end": "623600"
  },
  {
    "text": "the d matrix becomes the radius matrix",
    "start": "623600",
    "end": "626399"
  },
  {
    "text": "which is capable of loading from",
    "start": "626399",
    "end": "627920"
  },
  {
    "text": "distributed sources",
    "start": "627920",
    "end": "630160"
  },
  {
    "text": "and lastly we pass a raid params object",
    "start": "630160",
    "end": "633760"
  },
  {
    "text": "to configure distributed training here",
    "start": "633760",
    "end": "636240"
  },
  {
    "text": "we just set the number of actors to two",
    "start": "636240",
    "end": "638560"
  },
  {
    "text": "but we could also use this object to",
    "start": "638560",
    "end": "640399"
  },
  {
    "text": "configure fault tolerance",
    "start": "640399",
    "end": "643360"
  },
  {
    "text": "and that's it for the actual ray",
    "start": "643360",
    "end": "644880"
  },
  {
    "text": "architecture",
    "start": "644880",
    "end": "646399"
  },
  {
    "text": "next michael moore will continue with",
    "start": "646399",
    "end": "648000"
  },
  {
    "text": "the actual booster ray adoption at uber",
    "start": "648000",
    "end": "651360"
  },
  {
    "text": "thanks kai hello everyone my name is",
    "start": "651360",
    "end": "654000"
  },
  {
    "text": "michael",
    "start": "654000",
    "end": "654640"
  },
  {
    "text": "and i'm from the microangelo team at",
    "start": "654640",
    "end": "656399"
  },
  {
    "text": "uber which is our internal machine",
    "start": "656399",
    "end": "658240"
  },
  {
    "text": "learning platform team so building on",
    "start": "658240",
    "end": "660560"
  },
  {
    "text": "kai's introduction to actually boost ray",
    "start": "660560",
    "end": "662560"
  },
  {
    "text": "i'll be telling you more about how we in",
    "start": "662560",
    "end": "664640"
  },
  {
    "text": "collaboration with the folks at any",
    "start": "664640",
    "end": "665920"
  },
  {
    "text": "scale",
    "start": "665920",
    "end": "666640"
  },
  {
    "text": "bring extra boost rate into uber's",
    "start": "666640",
    "end": "668480"
  },
  {
    "text": "machine learning ecosystem",
    "start": "668480",
    "end": "670720"
  },
  {
    "text": "but before that i would like to take a",
    "start": "670720",
    "end": "672320"
  },
  {
    "text": "moment to provide some context on our",
    "start": "672320",
    "end": "674160"
  },
  {
    "text": "broader motivations",
    "start": "674160",
    "end": "675200"
  },
  {
    "text": "to bring rey into our machine learning",
    "start": "675200",
    "end": "677040"
  },
  {
    "text": "and deep learning ecosystem",
    "start": "677040",
    "end": "678640"
  },
  {
    "text": "and how it helps us tackle some of the",
    "start": "678640",
    "end": "680480"
  },
  {
    "text": "challenges we increasingly observe",
    "start": "680480",
    "end": "682240"
  },
  {
    "text": "as we continue to scale machine learning",
    "start": "682240",
    "end": "683839"
  },
  {
    "text": "at uber",
    "start": "683839",
    "end": "685839"
  },
  {
    "text": "i'll first start off with a quick",
    "start": "685839",
    "end": "686959"
  },
  {
    "text": "discussion on some of the challenges we",
    "start": "686959",
    "end": "688480"
  },
  {
    "text": "see at uber",
    "start": "688480",
    "end": "689360"
  },
  {
    "text": "how ray with a better attraction for",
    "start": "689360",
    "end": "691040"
  },
  {
    "text": "doing distributed ml can help",
    "start": "691040",
    "end": "693120"
  },
  {
    "text": "then i will dive into how we incorporate",
    "start": "693120",
    "end": "694880"
  },
  {
    "text": "extra booze on ray into our ecosystem",
    "start": "694880",
    "end": "697040"
  },
  {
    "text": "finally i will share some of the lessons",
    "start": "697040",
    "end": "698640"
  },
  {
    "text": "learned and wrap up with some",
    "start": "698640",
    "end": "699920"
  },
  {
    "text": "forward-looking ideas that we're",
    "start": "699920",
    "end": "701040"
  },
  {
    "text": "thinking about",
    "start": "701040",
    "end": "703440"
  },
  {
    "start": "703000",
    "end": "703000"
  },
  {
    "text": "here are some of the challenges for",
    "start": "703440",
    "end": "704560"
  },
  {
    "text": "distributed ml and dl that we start to",
    "start": "704560",
    "end": "706720"
  },
  {
    "text": "see as we scale i just wanted to point",
    "start": "706720",
    "end": "709360"
  },
  {
    "text": "out that travis from our team",
    "start": "709360",
    "end": "710880"
  },
  {
    "text": "has also explored some of these ideas in",
    "start": "710880",
    "end": "712880"
  },
  {
    "text": "the elastic cover blog as well as in",
    "start": "712880",
    "end": "714639"
  },
  {
    "text": "last year's race summit",
    "start": "714639",
    "end": "716000"
  },
  {
    "text": "so i will encourage you to check it out",
    "start": "716000",
    "end": "718959"
  },
  {
    "text": "first for distributed training",
    "start": "718959",
    "end": "720720"
  },
  {
    "text": "uh even with easy to use frameworks like",
    "start": "720720",
    "end": "722800"
  },
  {
    "text": "extra boost or horowit",
    "start": "722800",
    "end": "724639"
  },
  {
    "text": "doing resource aware scheduling and",
    "start": "724639",
    "end": "726399"
  },
  {
    "text": "provisioning jobs",
    "start": "726399",
    "end": "728000"
  },
  {
    "text": "still involves setting up the containers",
    "start": "728000",
    "end": "729839"
  },
  {
    "text": "and enabling stuff like gang scheduling",
    "start": "729839",
    "end": "731839"
  },
  {
    "text": "are still not that straightforward and",
    "start": "731839",
    "end": "734079"
  },
  {
    "text": "for for fault tolerance and auto scaling",
    "start": "734079",
    "end": "736240"
  },
  {
    "text": "there is a somewhat similar challenge",
    "start": "736240",
    "end": "737760"
  },
  {
    "text": "related to dynamic resource allocation",
    "start": "737760",
    "end": "739680"
  },
  {
    "text": "and host discovery and orchestration",
    "start": "739680",
    "end": "741440"
  },
  {
    "text": "throughout the job depending on the kind",
    "start": "741440",
    "end": "743120"
  },
  {
    "text": "of infrastructure you're running with",
    "start": "743120",
    "end": "745600"
  },
  {
    "text": "complex computational patterns are also",
    "start": "745600",
    "end": "747600"
  },
  {
    "text": "increasingly uh becoming relevant in ml",
    "start": "747600",
    "end": "749839"
  },
  {
    "text": "and large scales",
    "start": "749839",
    "end": "750959"
  },
  {
    "text": "uh an example of that is distributed",
    "start": "750959",
    "end": "752959"
  },
  {
    "text": "hyper parameter search",
    "start": "752959",
    "end": "754399"
  },
  {
    "text": "for which we start to see parallel",
    "start": "754399",
    "end": "756800"
  },
  {
    "text": "export exploit patterns",
    "start": "756800",
    "end": "758079"
  },
  {
    "text": "becoming more common with each trial",
    "start": "758079",
    "end": "760720"
  },
  {
    "text": "allocated",
    "start": "760720",
    "end": "761360"
  },
  {
    "text": "a resource or time constraint budget",
    "start": "761360",
    "end": "764480"
  },
  {
    "text": "they're also interested in doing dynamic",
    "start": "764480",
    "end": "765839"
  },
  {
    "text": "resource allocation throughout the study",
    "start": "765839",
    "end": "768079"
  },
  {
    "text": "where we combine these xy exploit models",
    "start": "768079",
    "end": "769920"
  },
  {
    "text": "with elastic distributor training",
    "start": "769920",
    "end": "771839"
  },
  {
    "text": "basically saying that we want to be able",
    "start": "771839",
    "end": "773360"
  },
  {
    "text": "to fan out during the initial explore",
    "start": "773360",
    "end": "775040"
  },
  {
    "text": "phase",
    "start": "775040",
    "end": "775440"
  },
  {
    "text": "and then dynamically allocate more",
    "start": "775440",
    "end": "776959"
  },
  {
    "text": "resources to the more promising trials",
    "start": "776959",
    "end": "778639"
  },
  {
    "text": "in that exploit phase",
    "start": "778639",
    "end": "781040"
  },
  {
    "text": "finally for end-to-end machine learning",
    "start": "781040",
    "end": "783360"
  },
  {
    "text": "and deep learning workflows",
    "start": "783360",
    "end": "784720"
  },
  {
    "text": "a common state of the world that we",
    "start": "784720",
    "end": "786480"
  },
  {
    "text": "start to see is that we have these",
    "start": "786480",
    "end": "788560"
  },
  {
    "text": "heterogeneous computes throughout the",
    "start": "788560",
    "end": "790399"
  },
  {
    "text": "workflow where we may use",
    "start": "790399",
    "end": "792000"
  },
  {
    "text": "say spark to do etl and then",
    "start": "792000",
    "end": "793680"
  },
  {
    "text": "distributing another framework for doing",
    "start": "793680",
    "end": "795360"
  },
  {
    "text": "distributor training",
    "start": "795360",
    "end": "797680"
  },
  {
    "text": "a lot of the efforts end up just",
    "start": "797680",
    "end": "799200"
  },
  {
    "text": "provisioning and stitching these uh",
    "start": "799200",
    "end": "800800"
  },
  {
    "text": "bespoke systems together",
    "start": "800800",
    "end": "802399"
  },
  {
    "text": "right so some some questions start to",
    "start": "802399",
    "end": "804079"
  },
  {
    "text": "quickly come up like how do you move",
    "start": "804079",
    "end": "805920"
  },
  {
    "text": "data",
    "start": "805920",
    "end": "806480"
  },
  {
    "text": "between these stages can we take",
    "start": "806480",
    "end": "808240"
  },
  {
    "text": "advantage of data locality and somehow",
    "start": "808240",
    "end": "810000"
  },
  {
    "text": "avoid having materialized data sets",
    "start": "810000",
    "end": "812079"
  },
  {
    "text": "right all these things start to our",
    "start": "812079",
    "end": "814800"
  },
  {
    "text": "complications",
    "start": "814800",
    "end": "815440"
  },
  {
    "text": "start to come up when you're stitching",
    "start": "815440",
    "end": "816880"
  },
  {
    "text": "together these um uh bespoke distributed",
    "start": "816880",
    "end": "819360"
  },
  {
    "text": "systems",
    "start": "819360",
    "end": "821680"
  },
  {
    "start": "821000",
    "end": "821000"
  },
  {
    "text": "and and so this is where ray starts to",
    "start": "821680",
    "end": "823360"
  },
  {
    "text": "come in the picture right uh and just to",
    "start": "823360",
    "end": "825360"
  },
  {
    "text": "highlight a few things that we really",
    "start": "825360",
    "end": "826959"
  },
  {
    "text": "like about ray",
    "start": "826959",
    "end": "828399"
  },
  {
    "text": "for one it's an open framework it's open",
    "start": "828399",
    "end": "830639"
  },
  {
    "text": "source it runs",
    "start": "830639",
    "end": "831600"
  },
  {
    "text": "almost anywhere on kubernetes gcp aws",
    "start": "831600",
    "end": "835120"
  },
  {
    "text": "anywhere you would like it to run it",
    "start": "835120",
    "end": "836800"
  },
  {
    "text": "most likely already has done the legwork",
    "start": "836800",
    "end": "838800"
  },
  {
    "text": "to run there",
    "start": "838800",
    "end": "840800"
  },
  {
    "text": "two it also provides a set of general",
    "start": "840800",
    "end": "842880"
  },
  {
    "text": "distributed computing primitives",
    "start": "842880",
    "end": "844800"
  },
  {
    "text": "so that just by using ray and the",
    "start": "844800",
    "end": "846079"
  },
  {
    "text": "stateful apis we can get fault tolerance",
    "start": "846079",
    "end": "848160"
  },
  {
    "text": "and all the scaling",
    "start": "848160",
    "end": "849440"
  },
  {
    "text": "of tasks and actors just out of the box",
    "start": "849440",
    "end": "851839"
  },
  {
    "text": "and and just one point on share memory",
    "start": "851839",
    "end": "853760"
  },
  {
    "text": "uh ray also holds immutable objects in",
    "start": "853760",
    "end": "856160"
  },
  {
    "text": "shared memory",
    "start": "856160",
    "end": "857199"
  },
  {
    "text": "so that they can be efficiently",
    "start": "857199",
    "end": "858720"
  },
  {
    "text": "transferred across processes and nodes",
    "start": "858720",
    "end": "860959"
  },
  {
    "text": "this is particularly important in",
    "start": "860959",
    "end": "862160"
  },
  {
    "text": "distributed settings because as we know",
    "start": "862160",
    "end": "863920"
  },
  {
    "text": "data serialization and copying are",
    "start": "863920",
    "end": "865839"
  },
  {
    "text": "a common bottlenecks and finally it has",
    "start": "865839",
    "end": "868880"
  },
  {
    "text": "a rich ml ecosystem",
    "start": "868880",
    "end": "870399"
  },
  {
    "text": "with many out-of-the-box libraries and",
    "start": "870399",
    "end": "872000"
  },
  {
    "text": "frameworks built on top of red",
    "start": "872000",
    "end": "873839"
  },
  {
    "text": "and ray 2 in particular which is one of",
    "start": "873839",
    "end": "876160"
  },
  {
    "text": "the most popular distributed hybrid",
    "start": "876160",
    "end": "877680"
  },
  {
    "text": "parameter search framework",
    "start": "877680",
    "end": "879279"
  },
  {
    "text": "comes with very natively and because it",
    "start": "879279",
    "end": "881279"
  },
  {
    "text": "leverages array support",
    "start": "881279",
    "end": "882720"
  },
  {
    "text": "and for nested parallelism and",
    "start": "882720",
    "end": "884560"
  },
  {
    "text": "primitives a lot of the benefits that we",
    "start": "884560",
    "end": "886639"
  },
  {
    "text": "just talked about essentially comes for",
    "start": "886639",
    "end": "887920"
  },
  {
    "text": "free",
    "start": "887920",
    "end": "888560"
  },
  {
    "text": "and which as you will see really helped",
    "start": "888560",
    "end": "890000"
  },
  {
    "text": "with some of the challenges we outlined",
    "start": "890000",
    "end": "891600"
  },
  {
    "text": "on the previous slide so at uber",
    "start": "891600",
    "end": "895839"
  },
  {
    "text": "how can ray help us out with some of the",
    "start": "895839",
    "end": "897440"
  },
  {
    "text": "problems we just talked about right",
    "start": "897440",
    "end": "900079"
  },
  {
    "text": "so on a very high level first a unified",
    "start": "900079",
    "end": "903440"
  },
  {
    "text": "background for distributor training",
    "start": "903440",
    "end": "904880"
  },
  {
    "text": "right so with recently we released",
    "start": "904880",
    "end": "907040"
  },
  {
    "text": "elastic horror on array which allows us",
    "start": "907040",
    "end": "908880"
  },
  {
    "text": "to get the fault tolerance and auto",
    "start": "908880",
    "end": "910240"
  },
  {
    "text": "scaling properties",
    "start": "910240",
    "end": "911120"
  },
  {
    "text": "to operate operationalize elastic deep",
    "start": "911120",
    "end": "913519"
  },
  {
    "text": "learning",
    "start": "913519",
    "end": "914399"
  },
  {
    "text": "right so ray takes care of kind of the",
    "start": "914399",
    "end": "916560"
  },
  {
    "text": "dynamic resource allocation and then the",
    "start": "916560",
    "end": "918240"
  },
  {
    "text": "discovery and construction of hosts",
    "start": "918240",
    "end": "920320"
  },
  {
    "text": "and by moving extra boost also to ray",
    "start": "920320",
    "end": "922399"
  },
  {
    "text": "we'll get fault tolerance and other",
    "start": "922399",
    "end": "924000"
  },
  {
    "text": "benefits that kaiju spoke about",
    "start": "924000",
    "end": "925440"
  },
  {
    "text": "previously",
    "start": "925440",
    "end": "926880"
  },
  {
    "text": "and we get to consolidate distributed",
    "start": "926880",
    "end": "928560"
  },
  {
    "text": "training on a unified compute backend",
    "start": "928560",
    "end": "930240"
  },
  {
    "text": "which is one step towards addressing the",
    "start": "930240",
    "end": "931839"
  },
  {
    "text": "fragmentation and compute across",
    "start": "931839",
    "end": "933199"
  },
  {
    "text": "uh workflows next uh we also have a",
    "start": "933199",
    "end": "937040"
  },
  {
    "text": "unified backend for distributed",
    "start": "937040",
    "end": "938240"
  },
  {
    "text": "hyper-prime research with both extra",
    "start": "938240",
    "end": "940320"
  },
  {
    "text": "boost and harvard",
    "start": "940320",
    "end": "941519"
  },
  {
    "text": "on ray readily supporting our ray tune",
    "start": "941519",
    "end": "945040"
  },
  {
    "text": "this immediately opens up the ability to",
    "start": "945040",
    "end": "946639"
  },
  {
    "text": "do some of the latest",
    "start": "946639",
    "end": "948079"
  },
  {
    "text": "budget constraints and population based",
    "start": "948079",
    "end": "949600"
  },
  {
    "text": "uh explore exploit patterns",
    "start": "949600",
    "end": "952240"
  },
  {
    "text": "with dynamic resource allocation over",
    "start": "952240",
    "end": "953920"
  },
  {
    "text": "time",
    "start": "953920",
    "end": "955360"
  },
  {
    "text": "and finally as we start to look ahead uh",
    "start": "955360",
    "end": "957519"
  },
  {
    "text": "we think that uh extra boost or horrible",
    "start": "957519",
    "end": "959519"
  },
  {
    "text": "array plus ray tune",
    "start": "959519",
    "end": "960880"
  },
  {
    "text": "plus the recent work on that on ray is",
    "start": "960880",
    "end": "962720"
  },
  {
    "text": "something that's very exciting and",
    "start": "962720",
    "end": "963759"
  },
  {
    "text": "promising",
    "start": "963759",
    "end": "964800"
  },
  {
    "text": "and definitely a good step towards a",
    "start": "964800",
    "end": "966320"
  },
  {
    "text": "unified compute back-end for n2m machine",
    "start": "966320",
    "end": "968240"
  },
  {
    "text": "learning workflows",
    "start": "968240",
    "end": "969279"
  },
  {
    "text": "i'll briefly touch upon this again at",
    "start": "969279",
    "end": "970800"
  },
  {
    "text": "the end of this talk",
    "start": "970800",
    "end": "973360"
  },
  {
    "text": "so so how do we actually bring ray and",
    "start": "973360",
    "end": "975519"
  },
  {
    "text": "extra boost rate into uber's ml",
    "start": "975519",
    "end": "977279"
  },
  {
    "text": "ecosystem",
    "start": "977279",
    "end": "978160"
  },
  {
    "text": "and what are some of the challenges in",
    "start": "978160",
    "end": "979600"
  },
  {
    "text": "doing that",
    "start": "979600",
    "end": "982079"
  },
  {
    "start": "982000",
    "end": "982000"
  },
  {
    "text": "as a starter uh we'll quickly walk",
    "start": "982079",
    "end": "983839"
  },
  {
    "text": "through what our internal ml system on a",
    "start": "983839",
    "end": "985680"
  },
  {
    "text": "very high level looks like",
    "start": "985680",
    "end": "986800"
  },
  {
    "text": "and this is probably pretty familiar for",
    "start": "986800",
    "end": "989199"
  },
  {
    "text": "batch we have some data lake and a spark",
    "start": "989199",
    "end": "991519"
  },
  {
    "text": "etl process that will pull the data from",
    "start": "991519",
    "end": "993040"
  },
  {
    "text": "the data lake",
    "start": "993040",
    "end": "994000"
  },
  {
    "text": "do some pre-processing and write it out",
    "start": "994000",
    "end": "995440"
  },
  {
    "text": "to our feature store and label store",
    "start": "995440",
    "end": "997600"
  },
  {
    "text": "when a user starts the training job the",
    "start": "997600",
    "end": "999519"
  },
  {
    "text": "job fetches the data from these stores",
    "start": "999519",
    "end": "1001440"
  },
  {
    "text": "perform any pre-processing and then just",
    "start": "1001440",
    "end": "1003519"
  },
  {
    "text": "starts training",
    "start": "1003519",
    "end": "1004639"
  },
  {
    "text": "and when it's done it starts it will",
    "start": "1004639",
    "end": "1006320"
  },
  {
    "text": "write the fitted model binary back to",
    "start": "1006320",
    "end": "1008240"
  },
  {
    "text": "our model store",
    "start": "1008240",
    "end": "1009199"
  },
  {
    "text": "which can then be used in either real",
    "start": "1009199",
    "end": "1010720"
  },
  {
    "text": "time serving or batch serving",
    "start": "1010720",
    "end": "1014000"
  },
  {
    "text": "and and basically and in our previous",
    "start": "1014880",
    "end": "1017839"
  },
  {
    "text": "talks and blogs",
    "start": "1017839",
    "end": "1018959"
  },
  {
    "text": "we have talked about how in an effort to",
    "start": "1018959",
    "end": "1021440"
  },
  {
    "text": "have a unified model representation",
    "start": "1021440",
    "end": "1023519"
  },
  {
    "text": "that guarantees training and serving",
    "start": "1023519",
    "end": "1025038"
  },
  {
    "text": "consistency we have essentially",
    "start": "1025039",
    "end": "1026959"
  },
  {
    "text": "encapsulated much of this end-to-end",
    "start": "1026959",
    "end": "1028558"
  },
  {
    "text": "life cycle",
    "start": "1028559",
    "end": "1029438"
  },
  {
    "text": "that we just talked about using sparks",
    "start": "1029439",
    "end": "1031438"
  },
  {
    "text": "ml abstractions",
    "start": "1031439",
    "end": "1033038"
  },
  {
    "text": "uh we'll cover that again in a little",
    "start": "1033039",
    "end": "1035038"
  },
  {
    "text": "bit",
    "start": "1035039",
    "end": "1037120"
  },
  {
    "start": "1037000",
    "end": "1037000"
  },
  {
    "text": "now this essentially raises the question",
    "start": "1037120",
    "end": "1039038"
  },
  {
    "text": "of uh if you're doing data processing",
    "start": "1039039",
    "end": "1040959"
  },
  {
    "text": "and transformation in spark",
    "start": "1040959",
    "end": "1042400"
  },
  {
    "text": "and want to do distributed model",
    "start": "1042400",
    "end": "1043760"
  },
  {
    "text": "training in ray using extra boost ray",
    "start": "1043760",
    "end": "1046000"
  },
  {
    "text": "how do we combine these two so that we",
    "start": "1046000",
    "end": "1047760"
  },
  {
    "text": "can efficiently pre-process data in",
    "start": "1047760",
    "end": "1049280"
  },
  {
    "text": "spark",
    "start": "1049280",
    "end": "1050080"
  },
  {
    "text": "then let ray take over to run the",
    "start": "1050080",
    "end": "1052400"
  },
  {
    "text": "distributed execution of some training",
    "start": "1052400",
    "end": "1053919"
  },
  {
    "text": "jobs",
    "start": "1053919",
    "end": "1054799"
  },
  {
    "text": "which in this case can be a single extra",
    "start": "1054799",
    "end": "1056320"
  },
  {
    "text": "boost rate job or entire hyper parameter",
    "start": "1056320",
    "end": "1058160"
  },
  {
    "text": "search workflow",
    "start": "1058160",
    "end": "1058960"
  },
  {
    "text": "that fan out to multiple parallel jobs",
    "start": "1058960",
    "end": "1062640"
  },
  {
    "text": "and then after that to package those",
    "start": "1062960",
    "end": "1065360"
  },
  {
    "text": "fitter models",
    "start": "1065360",
    "end": "1066160"
  },
  {
    "text": "into serverable components that can be",
    "start": "1066160",
    "end": "1068559"
  },
  {
    "text": "pushed to production for serving",
    "start": "1068559",
    "end": "1070480"
  },
  {
    "text": "so this this particular boundary between",
    "start": "1070480",
    "end": "1072400"
  },
  {
    "text": "different computes for data",
    "start": "1072400",
    "end": "1073760"
  },
  {
    "text": "pre-processing",
    "start": "1073760",
    "end": "1074799"
  },
  {
    "text": "model training and serving and what kind",
    "start": "1074799",
    "end": "1076880"
  },
  {
    "text": "of abstractions that we can have to",
    "start": "1076880",
    "end": "1078640"
  },
  {
    "text": "encapsulate this",
    "start": "1078640",
    "end": "1079760"
  },
  {
    "text": "it's really what we need to focus on",
    "start": "1079760",
    "end": "1081360"
  },
  {
    "text": "when we talk about how we're going to",
    "start": "1081360",
    "end": "1082559"
  },
  {
    "text": "integrate these two components together",
    "start": "1082559",
    "end": "1086160"
  },
  {
    "start": "1085000",
    "end": "1085000"
  },
  {
    "text": "uh and just now when we said that we",
    "start": "1086160",
    "end": "1088080"
  },
  {
    "text": "encapsulate the entire end-to-end",
    "start": "1088080",
    "end": "1089679"
  },
  {
    "text": "ml life cycle using sparks abstractions",
    "start": "1089679",
    "end": "1092400"
  },
  {
    "text": "what we really mean is that we're using",
    "start": "1092400",
    "end": "1094640"
  },
  {
    "text": "spark ml's pipeline abstractions to",
    "start": "1094640",
    "end": "1096480"
  },
  {
    "text": "represent each stage of the life cycle",
    "start": "1096480",
    "end": "1098799"
  },
  {
    "text": "uh in spark ml pipelines we have",
    "start": "1098799",
    "end": "1101200"
  },
  {
    "text": "concepts such as estimators transformers",
    "start": "1101200",
    "end": "1103200"
  },
  {
    "text": "and pipelines",
    "start": "1103200",
    "end": "1104320"
  },
  {
    "text": "similar to those concepts in the",
    "start": "1104320",
    "end": "1106240"
  },
  {
    "text": "succulent library",
    "start": "1106240",
    "end": "1108240"
  },
  {
    "text": "so estimates estimators essentially kind",
    "start": "1108240",
    "end": "1110240"
  },
  {
    "text": "of",
    "start": "1110240",
    "end": "1111760"
  },
  {
    "text": "fit on the data frame to to estimate or",
    "start": "1111760",
    "end": "1113840"
  },
  {
    "text": "learn the value of some parameters from",
    "start": "1113840",
    "end": "1115200"
  },
  {
    "text": "the data sets",
    "start": "1115200",
    "end": "1116160"
  },
  {
    "text": "an example of this will be learning the",
    "start": "1116160",
    "end": "1117679"
  },
  {
    "text": "values of coefficients in a linear",
    "start": "1117679",
    "end": "1119440"
  },
  {
    "text": "regression estimator",
    "start": "1119440",
    "end": "1121280"
  },
  {
    "text": "we then we have transformers which takes",
    "start": "1121280",
    "end": "1123200"
  },
  {
    "text": "the data from one state to another by",
    "start": "1123200",
    "end": "1124720"
  },
  {
    "text": "transforming it",
    "start": "1124720",
    "end": "1126080"
  },
  {
    "text": "and finally we have the idea of",
    "start": "1126080",
    "end": "1127200"
  },
  {
    "text": "pipelines that strings together a",
    "start": "1127200",
    "end": "1128559"
  },
  {
    "text": "sequence of transformers and estimators",
    "start": "1128559",
    "end": "1130640"
  },
  {
    "text": "right so you can imagine within our",
    "start": "1130640",
    "end": "1132240"
  },
  {
    "text": "setup at uber we can have a pipeline",
    "start": "1132240",
    "end": "1134480"
  },
  {
    "text": "with estimators that does pre-processing",
    "start": "1134480",
    "end": "1136160"
  },
  {
    "text": "steps",
    "start": "1136160",
    "end": "1136799"
  },
  {
    "text": "followed by an estimator that's the",
    "start": "1136799",
    "end": "1138080"
  },
  {
    "text": "actual model fitting and",
    "start": "1138080",
    "end": "1139840"
  },
  {
    "text": "an arbitrary number of transformers that",
    "start": "1139840",
    "end": "1141600"
  },
  {
    "text": "do post training",
    "start": "1141600",
    "end": "1143120"
  },
  {
    "text": "transformations",
    "start": "1143120",
    "end": "1145840"
  },
  {
    "start": "1146000",
    "end": "1146000"
  },
  {
    "text": "i also want to quickly note that uh",
    "start": "1147039",
    "end": "1149280"
  },
  {
    "text": "spark pipeline",
    "start": "1149280",
    "end": "1150559"
  },
  {
    "text": "attractions also serves as our contract",
    "start": "1150559",
    "end": "1152640"
  },
  {
    "text": "between training and serving to",
    "start": "1152640",
    "end": "1153760"
  },
  {
    "text": "guarantee online and offline consistency",
    "start": "1153760",
    "end": "1156400"
  },
  {
    "text": "a trade model essentially is a pipeline",
    "start": "1156400",
    "end": "1159280"
  },
  {
    "text": "model with a sequence of serialized",
    "start": "1159280",
    "end": "1160880"
  },
  {
    "text": "transformers",
    "start": "1160880",
    "end": "1161679"
  },
  {
    "text": "right so our prediction service expects",
    "start": "1161679",
    "end": "1163679"
  },
  {
    "text": "that and simply loads the pipeline model",
    "start": "1163679",
    "end": "1166000"
  },
  {
    "text": "and passes in the data to be scored to",
    "start": "1166000",
    "end": "1168400"
  },
  {
    "text": "be transformed by each stage and then",
    "start": "1168400",
    "end": "1170000"
  },
  {
    "text": "returns the final prediction",
    "start": "1170000",
    "end": "1173200"
  },
  {
    "text": "so essentially to be consistent with the",
    "start": "1173760",
    "end": "1176160"
  },
  {
    "text": "rest of the attractions that we have we",
    "start": "1176160",
    "end": "1178080"
  },
  {
    "text": "figure we can encapsulate the complexity",
    "start": "1178080",
    "end": "1180000"
  },
  {
    "text": "of",
    "start": "1180000",
    "end": "1180400"
  },
  {
    "text": "going from spark to ray for distributed",
    "start": "1180400",
    "end": "1182559"
  },
  {
    "text": "training and back to spark",
    "start": "1182559",
    "end": "1184240"
  },
  {
    "text": "within a spark pipeline abstraction this",
    "start": "1184240",
    "end": "1187200"
  },
  {
    "text": "also ensures that it",
    "start": "1187200",
    "end": "1188559"
  },
  {
    "text": "respects the serverable contracts with",
    "start": "1188559",
    "end": "1190320"
  },
  {
    "text": "the prediction service",
    "start": "1190320",
    "end": "1192000"
  },
  {
    "text": "so ideally users shouldn't have to worry",
    "start": "1192000",
    "end": "1193520"
  },
  {
    "text": "about any of the ray-related knobs",
    "start": "1193520",
    "end": "1195360"
  },
  {
    "text": "uh and they should strictly be",
    "start": "1195360",
    "end": "1197120"
  },
  {
    "text": "interacting with the model code and the",
    "start": "1197120",
    "end": "1198960"
  },
  {
    "text": "rest should be just abstracted away",
    "start": "1198960",
    "end": "1201760"
  },
  {
    "text": "and so basically this is what we came up",
    "start": "1201760",
    "end": "1203360"
  },
  {
    "text": "with uh this is what we call the the",
    "start": "1203360",
    "end": "1205520"
  },
  {
    "text": "actual boost ray estimator",
    "start": "1205520",
    "end": "1206799"
  },
  {
    "text": "which is an api built on top of the",
    "start": "1206799",
    "end": "1209440"
  },
  {
    "text": "spark estimator framework",
    "start": "1209440",
    "end": "1210799"
  },
  {
    "text": "that takes in xbox ray's train function",
    "start": "1210799",
    "end": "1212799"
  },
  {
    "text": "and fitting it directly on a spark data",
    "start": "1212799",
    "end": "1214400"
  },
  {
    "text": "frame",
    "start": "1214400",
    "end": "1215440"
  },
  {
    "text": "um we would soon see that instead of",
    "start": "1215440",
    "end": "1218159"
  },
  {
    "text": "actually raised train function the ray",
    "start": "1218159",
    "end": "1220159"
  },
  {
    "text": "estimator should be able to take in any",
    "start": "1220159",
    "end": "1221440"
  },
  {
    "text": "arbitrary function to be executed",
    "start": "1221440",
    "end": "1222880"
  },
  {
    "text": "remotely on the raycluster",
    "start": "1222880",
    "end": "1224240"
  },
  {
    "text": "but for now we'll just use actual ray's",
    "start": "1224240",
    "end": "1226880"
  },
  {
    "text": "train function",
    "start": "1226880",
    "end": "1227840"
  },
  {
    "text": "as an example to start in this example",
    "start": "1227840",
    "end": "1231440"
  },
  {
    "text": "as you can see",
    "start": "1231440",
    "end": "1232240"
  },
  {
    "text": "we we first import the train function",
    "start": "1232240",
    "end": "1234320"
  },
  {
    "text": "from function boost ray",
    "start": "1234320",
    "end": "1236000"
  },
  {
    "text": "specify the config and hyper parameters",
    "start": "1236000",
    "end": "1237679"
  },
  {
    "text": "required by regular extra boost",
    "start": "1237679",
    "end": "1239280"
  },
  {
    "text": "and pass it to the ray estimator and",
    "start": "1239280",
    "end": "1241679"
  },
  {
    "text": "then we construct a regular spark",
    "start": "1241679",
    "end": "1243120"
  },
  {
    "text": "pipeline that includes",
    "start": "1243120",
    "end": "1244480"
  },
  {
    "text": "different pre-processing steps and",
    "start": "1244480",
    "end": "1246000"
  },
  {
    "text": "post-processing steps using regular",
    "start": "1246000",
    "end": "1247440"
  },
  {
    "text": "spark transformers",
    "start": "1247440",
    "end": "1248720"
  },
  {
    "text": "as well as our array estimators and and",
    "start": "1248720",
    "end": "1251280"
  },
  {
    "text": "then we're ready to fit this entire",
    "start": "1251280",
    "end": "1252480"
  },
  {
    "text": "pipeline",
    "start": "1252480",
    "end": "1253120"
  },
  {
    "text": "we'll simply call pipeline.fit as usual",
    "start": "1253120",
    "end": "1255440"
  },
  {
    "text": "and you and",
    "start": "1255440",
    "end": "1256159"
  },
  {
    "text": "and then we get a fitted model using it",
    "start": "1256159",
    "end": "1258240"
  },
  {
    "text": "we can then",
    "start": "1258240",
    "end": "1259200"
  },
  {
    "text": "transform the test data sets to produce",
    "start": "1259200",
    "end": "1261280"
  },
  {
    "text": "the final predicted data frame",
    "start": "1261280",
    "end": "1263919"
  },
  {
    "text": "uh you'll notice that uh the we're only",
    "start": "1263919",
    "end": "1267039"
  },
  {
    "text": "using a few lines that has anything to",
    "start": "1267039",
    "end": "1268559"
  },
  {
    "text": "do with right",
    "start": "1268559",
    "end": "1269360"
  },
  {
    "text": "right so the vast majority of this is",
    "start": "1269360",
    "end": "1271039"
  },
  {
    "text": "still standard actually because of",
    "start": "1271039",
    "end": "1272080"
  },
  {
    "text": "center spark",
    "start": "1272080",
    "end": "1272960"
  },
  {
    "text": "right so we essentially are able to",
    "start": "1272960",
    "end": "1274960"
  },
  {
    "text": "reuse the spark pipeline",
    "start": "1274960",
    "end": "1276400"
  },
  {
    "text": "abstractions that does distribute the",
    "start": "1276400",
    "end": "1277760"
  },
  {
    "text": "training without introducing any",
    "start": "1277760",
    "end": "1279760"
  },
  {
    "text": "special uh concepts reconciles",
    "start": "1279760",
    "end": "1283360"
  },
  {
    "text": "uh that's exposed to the user so how do",
    "start": "1283360",
    "end": "1285840"
  },
  {
    "text": "we actually do that",
    "start": "1285840",
    "end": "1288320"
  },
  {
    "text": "so in our ray estimator uh what's",
    "start": "1288320",
    "end": "1290240"
  },
  {
    "text": "actually happening under the hood",
    "start": "1290240",
    "end": "1291600"
  },
  {
    "text": "is that when you call fits on your",
    "start": "1291600",
    "end": "1293440"
  },
  {
    "text": "training data sets which is",
    "start": "1293440",
    "end": "1294880"
  },
  {
    "text": "usually a spark data frame the estimator",
    "start": "1294880",
    "end": "1297200"
  },
  {
    "text": "will take it",
    "start": "1297200",
    "end": "1298159"
  },
  {
    "text": "and write it out some storage layer like",
    "start": "1298159",
    "end": "1300080"
  },
  {
    "text": "hdfs or s3",
    "start": "1300080",
    "end": "1302080"
  },
  {
    "text": "we'll materialize it to the parquet file",
    "start": "1302080",
    "end": "1303679"
  },
  {
    "text": "format which is very useful for",
    "start": "1303679",
    "end": "1305200"
  },
  {
    "text": "distributed training overall",
    "start": "1305200",
    "end": "1306640"
  },
  {
    "text": "uh for a few reasons such as uh it",
    "start": "1306640",
    "end": "1309360"
  },
  {
    "text": "supports",
    "start": "1309360",
    "end": "1310080"
  },
  {
    "text": "large continuous reads so it's very",
    "start": "1310080",
    "end": "1311919"
  },
  {
    "text": "friendly to the storage",
    "start": "1311919",
    "end": "1313440"
  },
  {
    "text": "uh it has very fast real queries and",
    "start": "1313440",
    "end": "1315600"
  },
  {
    "text": "provides fast access to individual",
    "start": "1315600",
    "end": "1317120"
  },
  {
    "text": "columns if you only want a subset of",
    "start": "1317120",
    "end": "1318559"
  },
  {
    "text": "your data to go into your final",
    "start": "1318559",
    "end": "1320320"
  },
  {
    "text": "training data sets this can definitely",
    "start": "1320320",
    "end": "1322240"
  },
  {
    "text": "happen if your pre-processing steps",
    "start": "1322240",
    "end": "1323600"
  },
  {
    "text": "materialize some intermediate columns",
    "start": "1323600",
    "end": "1324960"
  },
  {
    "text": "that you may or may not want to include",
    "start": "1324960",
    "end": "1326400"
  },
  {
    "text": "it",
    "start": "1326400",
    "end": "1327840"
  },
  {
    "text": "and of course rk files also have native",
    "start": "1327840",
    "end": "1330080"
  },
  {
    "text": "read write support from spark so which",
    "start": "1330080",
    "end": "1331520"
  },
  {
    "text": "is important",
    "start": "1331520",
    "end": "1333200"
  },
  {
    "text": "and after the data is materialized we'll",
    "start": "1333200",
    "end": "1335280"
  },
  {
    "text": "serialize the remote function that we",
    "start": "1335280",
    "end": "1336480"
  },
  {
    "text": "want to execute",
    "start": "1336480",
    "end": "1337600"
  },
  {
    "text": "and in this case that's our exchange",
    "start": "1337600",
    "end": "1338960"
  },
  {
    "text": "rate training function our rate contact",
    "start": "1338960",
    "end": "1341039"
  },
  {
    "text": "system",
    "start": "1341039",
    "end": "1341840"
  },
  {
    "text": "will then take the user-specified",
    "start": "1341840",
    "end": "1343600"
  },
  {
    "text": "requirements spin up the corresponding",
    "start": "1343600",
    "end": "1345679"
  },
  {
    "text": "ray cluster with the specified number of",
    "start": "1345679",
    "end": "1347200"
  },
  {
    "text": "actors",
    "start": "1347200",
    "end": "1348000"
  },
  {
    "text": "and each of these actors will start",
    "start": "1348000",
    "end": "1349200"
  },
  {
    "text": "reading different shots of the parquet",
    "start": "1349200",
    "end": "1350400"
  },
  {
    "text": "files we materialized",
    "start": "1350400",
    "end": "1352080"
  },
  {
    "text": "perform distributed training and then",
    "start": "1352080",
    "end": "1354480"
  },
  {
    "text": "after the job is completed",
    "start": "1354480",
    "end": "1355919"
  },
  {
    "text": "the raid driver will fetch the final",
    "start": "1355919",
    "end": "1357360"
  },
  {
    "text": "train model from one of the actors",
    "start": "1357360",
    "end": "1358960"
  },
  {
    "text": "write it out to storage and package it",
    "start": "1358960",
    "end": "1360640"
  },
  {
    "text": "into a spot transformer for serving",
    "start": "1360640",
    "end": "1364480"
  },
  {
    "text": "and to make this more concrete i do want",
    "start": "1364880",
    "end": "1366640"
  },
  {
    "start": "1365000",
    "end": "1365000"
  },
  {
    "text": "to show you an example how",
    "start": "1366640",
    "end": "1367919"
  },
  {
    "text": "we this can be authored by a user at",
    "start": "1367919",
    "end": "1369840"
  },
  {
    "text": "uber typically using our workflow",
    "start": "1369840",
    "end": "1371760"
  },
  {
    "text": "authoring framework or within a jupiter",
    "start": "1371760",
    "end": "1373360"
  },
  {
    "text": "environment a typical flow may look",
    "start": "1373360",
    "end": "1375760"
  },
  {
    "text": "something like this",
    "start": "1375760",
    "end": "1376640"
  },
  {
    "text": "where in the first step you'll create",
    "start": "1376640",
    "end": "1378799"
  },
  {
    "text": "some kind of data processing pipeline",
    "start": "1378799",
    "end": "1380640"
  },
  {
    "start": "1380000",
    "end": "1380000"
  },
  {
    "text": "composed of transformers and estimators",
    "start": "1380640",
    "end": "1383919"
  },
  {
    "text": "and in this example we have string",
    "start": "1383919",
    "end": "1385280"
  },
  {
    "text": "encoders string and indexer",
    "start": "1385280",
    "end": "1387120"
  },
  {
    "text": "and string to flow encoders and we",
    "start": "1387120",
    "end": "1389440"
  },
  {
    "text": "randomly split the data set in the train",
    "start": "1389440",
    "end": "1390799"
  },
  {
    "text": "test for cross validation",
    "start": "1390799",
    "end": "1392320"
  },
  {
    "text": "and by fitting the pipeline to the train",
    "start": "1392320",
    "end": "1393600"
  },
  {
    "text": "data frame we get our fitted data",
    "start": "1393600",
    "end": "1395200"
  },
  {
    "text": "pipeline",
    "start": "1395200",
    "end": "1395760"
  },
  {
    "text": "that will transform the raw data into",
    "start": "1395760",
    "end": "1397200"
  },
  {
    "text": "features",
    "start": "1397200",
    "end": "1399520"
  },
  {
    "text": "but in the next step but before you can",
    "start": "1399520",
    "end": "1401360"
  },
  {
    "start": "1400000",
    "end": "1400000"
  },
  {
    "text": "start training we require you to create",
    "start": "1401360",
    "end": "1402960"
  },
  {
    "text": "a rate context",
    "start": "1402960",
    "end": "1403919"
  },
  {
    "text": "which allows you to speculate the",
    "start": "1403919",
    "end": "1404960"
  },
  {
    "text": "requirements of where you would like to",
    "start": "1404960",
    "end": "1406400"
  },
  {
    "text": "run your distributor training",
    "start": "1406400",
    "end": "1408000"
  },
  {
    "text": "job at and under the hood uh it takes",
    "start": "1408000",
    "end": "1410960"
  },
  {
    "text": "care of spinning up the raycluster",
    "start": "1410960",
    "end": "1412400"
  },
  {
    "text": "provides an entry point to the cluster",
    "start": "1412400",
    "end": "1413919"
  },
  {
    "text": "via the rate clients that allows us to",
    "start": "1413919",
    "end": "1415840"
  },
  {
    "text": "remotely execute functions on the",
    "start": "1415840",
    "end": "1417120"
  },
  {
    "text": "workers and get the results",
    "start": "1417120",
    "end": "1418640"
  },
  {
    "text": "of those executions back right in this",
    "start": "1418640",
    "end": "1421039"
  },
  {
    "text": "example",
    "start": "1421039",
    "end": "1421760"
  },
  {
    "text": "we specify the resources we want number",
    "start": "1421760",
    "end": "1423919"
  },
  {
    "text": "of workers and what is the custom docker",
    "start": "1423919",
    "end": "1425440"
  },
  {
    "text": "image we want to use to spin up the",
    "start": "1425440",
    "end": "1426720"
  },
  {
    "text": "cluster",
    "start": "1426720",
    "end": "1429120"
  },
  {
    "start": "1428000",
    "end": "1428000"
  },
  {
    "text": "and next we will define the ray",
    "start": "1429120",
    "end": "1430720"
  },
  {
    "text": "estimator as we did in the previous",
    "start": "1430720",
    "end": "1432000"
  },
  {
    "text": "example",
    "start": "1432000",
    "end": "1433600"
  },
  {
    "start": "1433000",
    "end": "1433000"
  },
  {
    "text": "and with this ray estimator we can call",
    "start": "1433600",
    "end": "1435840"
  },
  {
    "text": "fits",
    "start": "1435840",
    "end": "1436640"
  },
  {
    "text": "on the spark data frame directly and",
    "start": "1436640",
    "end": "1438480"
  },
  {
    "text": "passing the ray context at the back end",
    "start": "1438480",
    "end": "1440240"
  },
  {
    "text": "and again this spins up the cluster",
    "start": "1440240",
    "end": "1441919"
  },
  {
    "text": "remote remotely executes the function",
    "start": "1441919",
    "end": "1444480"
  },
  {
    "text": "and retrieve the train uh model binary",
    "start": "1444480",
    "end": "1446480"
  },
  {
    "text": "and package it as a regular spark",
    "start": "1446480",
    "end": "1447679"
  },
  {
    "text": "transformer for serving",
    "start": "1447679",
    "end": "1450480"
  },
  {
    "start": "1450000",
    "end": "1450000"
  },
  {
    "text": "you can also easily persist and reload",
    "start": "1450480",
    "end": "1452240"
  },
  {
    "text": "your transformer objects",
    "start": "1452240",
    "end": "1453520"
  },
  {
    "text": "using spark's native serialization and",
    "start": "1453520",
    "end": "1455279"
  },
  {
    "text": "deserialization",
    "start": "1455279",
    "end": "1456880"
  },
  {
    "text": "and when you call save uh sprock",
    "start": "1456880",
    "end": "1459039"
  },
  {
    "text": "essentially serializes all the params",
    "start": "1459039",
    "end": "1460799"
  },
  {
    "text": "the model binary and basically",
    "start": "1460799",
    "end": "1462159"
  },
  {
    "text": "everything you need to load that model a",
    "start": "1462159",
    "end": "1464480"
  },
  {
    "text": "transformer back in the future",
    "start": "1464480",
    "end": "1465840"
  },
  {
    "text": "to do any transformer other data sets",
    "start": "1465840",
    "end": "1469600"
  },
  {
    "text": "uh previously um we mentioned that our",
    "start": "1469919",
    "end": "1473120"
  },
  {
    "start": "1470000",
    "end": "1470000"
  },
  {
    "text": "ray estimator interface should be",
    "start": "1473120",
    "end": "1474480"
  },
  {
    "text": "generic enough to support",
    "start": "1474480",
    "end": "1475919"
  },
  {
    "text": "not only the extra boots ray train",
    "start": "1475919",
    "end": "1477200"
  },
  {
    "text": "function but really any arbitrary",
    "start": "1477200",
    "end": "1478880"
  },
  {
    "text": "serialization",
    "start": "1478880",
    "end": "1479760"
  },
  {
    "text": "serializable function and executed",
    "start": "1479760",
    "end": "1481919"
  },
  {
    "text": "remotely",
    "start": "1481919",
    "end": "1482799"
  },
  {
    "text": "on the ray cluster right so to go from",
    "start": "1482799",
    "end": "1484960"
  },
  {
    "text": "running a single extra boost rate job",
    "start": "1484960",
    "end": "1486480"
  },
  {
    "text": "using our array estimator to doing",
    "start": "1486480",
    "end": "1487840"
  },
  {
    "text": "distributed hybrid parameter search",
    "start": "1487840",
    "end": "1489440"
  },
  {
    "text": "uh using ray tune it should be as simple",
    "start": "1489440",
    "end": "1491679"
  },
  {
    "text": "as providing an entry point like above",
    "start": "1491679",
    "end": "1493520"
  },
  {
    "text": "to the team run function uh in this",
    "start": "1493520",
    "end": "1496080"
  },
  {
    "text": "example",
    "start": "1496080",
    "end": "1496640"
  },
  {
    "text": "we're doing actually boost ray with ray",
    "start": "1496640",
    "end": "1498720"
  },
  {
    "text": "tune that's why we're passing actually",
    "start": "1498720",
    "end": "1500720"
  },
  {
    "text": "with raise train function as a handle to",
    "start": "1500720",
    "end": "1502400"
  },
  {
    "text": "the rate",
    "start": "1502400",
    "end": "1503120"
  },
  {
    "text": "to the tune run method and the rest is",
    "start": "1503120",
    "end": "1505679"
  },
  {
    "text": "basically similar where you provide rate",
    "start": "1505679",
    "end": "1506960"
  },
  {
    "text": "params to specify the job requirements",
    "start": "1506960",
    "end": "1509039"
  },
  {
    "text": "and config which now also includes",
    "start": "1509039",
    "end": "1511440"
  },
  {
    "text": "parameters related to raytune",
    "start": "1511440",
    "end": "1515039"
  },
  {
    "start": "1515000",
    "end": "1515000"
  },
  {
    "text": "and now just to kind of tie this back to",
    "start": "1515039",
    "end": "1516640"
  },
  {
    "text": "our new initial motivations of can we",
    "start": "1516640",
    "end": "1518559"
  },
  {
    "text": "combine hyper frame research and",
    "start": "1518559",
    "end": "1519840"
  },
  {
    "text": "distributed static",
    "start": "1519840",
    "end": "1520799"
  },
  {
    "text": "training in an elastic sense meaning",
    "start": "1520799",
    "end": "1523120"
  },
  {
    "text": "that in in the time constraint search",
    "start": "1523120",
    "end": "1524799"
  },
  {
    "text": "can we dynamically",
    "start": "1524799",
    "end": "1526000"
  },
  {
    "text": "allocate more resources to more",
    "start": "1526000",
    "end": "1527760"
  },
  {
    "text": "promising trials to ensure we find the",
    "start": "1527760",
    "end": "1529600"
  },
  {
    "text": "best candidate within the fixed amount",
    "start": "1529600",
    "end": "1531120"
  },
  {
    "text": "of time",
    "start": "1531120",
    "end": "1531840"
  },
  {
    "text": "and compute resources this is",
    "start": "1531840",
    "end": "1534960"
  },
  {
    "text": "useful uh particularly useful to an",
    "start": "1534960",
    "end": "1536880"
  },
  {
    "text": "organization like ours at uber",
    "start": "1536880",
    "end": "1538480"
  },
  {
    "text": "where most of our training occurs on",
    "start": "1538480",
    "end": "1540320"
  },
  {
    "text": "fixed size on-premise",
    "start": "1540320",
    "end": "1542240"
  },
  {
    "text": "gpu and cpu clusters uh there are",
    "start": "1542240",
    "end": "1545279"
  },
  {
    "text": "definitely",
    "start": "1545279",
    "end": "1545679"
  },
  {
    "text": "some ongoing work at berkeley and any",
    "start": "1545679",
    "end": "1547440"
  },
  {
    "text": "scale",
    "start": "1547440",
    "end": "1549279"
  },
  {
    "text": "such as implementing this hyperscale",
    "start": "1549279",
    "end": "1550799"
  },
  {
    "text": "scheduler on top of ray tune and ray",
    "start": "1550799",
    "end": "1552400"
  },
  {
    "text": "primitives",
    "start": "1552400",
    "end": "1553279"
  },
  {
    "text": "and that is precisely going to help us",
    "start": "1553279",
    "end": "1555039"
  },
  {
    "text": "solve this problem",
    "start": "1555039",
    "end": "1556559"
  },
  {
    "text": "so we are definitely looking forward to",
    "start": "1556559",
    "end": "1558000"
  },
  {
    "text": "exploring these capabilities",
    "start": "1558000",
    "end": "1559840"
  },
  {
    "text": "using extra boost and hover on ray with",
    "start": "1559840",
    "end": "1561600"
  },
  {
    "text": "rating in the near future",
    "start": "1561600",
    "end": "1564640"
  },
  {
    "text": "and just to wrap up we move towards",
    "start": "1564960",
    "end": "1567039"
  },
  {
    "start": "1565000",
    "end": "1565000"
  },
  {
    "text": "elastic horizontal boost on ray for fall",
    "start": "1567039",
    "end": "1569120"
  },
  {
    "text": "tolerant auto scaling distributor",
    "start": "1569120",
    "end": "1570480"
  },
  {
    "text": "training",
    "start": "1570480",
    "end": "1571440"
  },
  {
    "text": "with radio integration we have now a",
    "start": "1571440",
    "end": "1573520"
  },
  {
    "text": "unified distributed hyper primary search",
    "start": "1573520",
    "end": "1575120"
  },
  {
    "text": "experience",
    "start": "1575120",
    "end": "1575919"
  },
  {
    "text": "that opens up the latest search patterns",
    "start": "1575919",
    "end": "1578640"
  },
  {
    "text": "and hopefully in the near future",
    "start": "1578640",
    "end": "1580320"
  },
  {
    "text": "with something like hyperscad we can",
    "start": "1580320",
    "end": "1582559"
  },
  {
    "text": "further improve its efficiency",
    "start": "1582559",
    "end": "1584640"
  },
  {
    "text": "using dynamic resource allocation and",
    "start": "1584640",
    "end": "1586720"
  },
  {
    "text": "these are all steps towards a more",
    "start": "1586720",
    "end": "1587840"
  },
  {
    "text": "unified compute packet",
    "start": "1587840",
    "end": "1589200"
  },
  {
    "text": "for ml and dr some other ongoing things",
    "start": "1589200",
    "end": "1592320"
  },
  {
    "text": "that we're exploring",
    "start": "1592320",
    "end": "1593279"
  },
  {
    "text": "like that's on ray for pre-processing",
    "start": "1593279",
    "end": "1595200"
  },
  {
    "text": "we're also looking into",
    "start": "1595200",
    "end": "1596960"
  },
  {
    "text": "rey to solve the shuffling data loader",
    "start": "1596960",
    "end": "1599440"
  },
  {
    "text": "issue in deep learning training",
    "start": "1599440",
    "end": "1601360"
  },
  {
    "text": "so in deep learning training shuffling",
    "start": "1601360",
    "end": "1603039"
  },
  {
    "text": "is often required to decorate the data",
    "start": "1603039",
    "end": "1605360"
  },
  {
    "text": "and improve generalization but it's",
    "start": "1605360",
    "end": "1607360"
  },
  {
    "text": "expensive at times especially for large",
    "start": "1607360",
    "end": "1608880"
  },
  {
    "text": "amount of data",
    "start": "1608880",
    "end": "1610240"
  },
  {
    "text": "because one can only shuffle a portion",
    "start": "1610240",
    "end": "1612159"
  },
  {
    "text": "at a time while being consumed",
    "start": "1612159",
    "end": "1614000"
  },
  {
    "text": "this portion size ends up being a",
    "start": "1614000",
    "end": "1615679"
  },
  {
    "text": "trade-off between training quality and",
    "start": "1615679",
    "end": "1617039"
  },
  {
    "text": "data loading speed",
    "start": "1617039",
    "end": "1618159"
  },
  {
    "text": "and we're we're looking to see if we can",
    "start": "1618159",
    "end": "1620080"
  },
  {
    "text": "use ray to solve this problem as well",
    "start": "1620080",
    "end": "1623520"
  },
  {
    "text": "uh so finally by standardizing around a",
    "start": "1623520",
    "end": "1626400"
  },
  {
    "text": "unified backend ideally",
    "start": "1626400",
    "end": "1628559"
  },
  {
    "text": "we should no longer have any need to",
    "start": "1628559",
    "end": "1630240"
  },
  {
    "text": "maintain or provision separate",
    "start": "1630240",
    "end": "1631440"
  },
  {
    "text": "infrastructure",
    "start": "1631440",
    "end": "1632559"
  },
  {
    "text": "uh across the the n2ml workflow right so",
    "start": "1632559",
    "end": "1635679"
  },
  {
    "text": "we don't need to set up a separate spark",
    "start": "1635679",
    "end": "1637279"
  },
  {
    "text": "cluster or",
    "start": "1637279",
    "end": "1638080"
  },
  {
    "text": "or a separate orchestration layer just",
    "start": "1638080",
    "end": "1639600"
  },
  {
    "text": "for hyper grammar search",
    "start": "1639600",
    "end": "1641440"
  },
  {
    "text": "uh and and two we should no longer",
    "start": "1641440",
    "end": "1645039"
  },
  {
    "text": "need to have materialized any",
    "start": "1645039",
    "end": "1646480"
  },
  {
    "text": "pre-processing data to disk",
    "start": "1646480",
    "end": "1648080"
  },
  {
    "text": "so you can potentially leverage stuff",
    "start": "1648080",
    "end": "1649279"
  },
  {
    "text": "like data locality and the collocation",
    "start": "1649279",
    "end": "1651360"
  },
  {
    "text": "of the actors to take advantage of race",
    "start": "1651360",
    "end": "1653279"
  },
  {
    "text": "zero copy shared memory using the object",
    "start": "1653279",
    "end": "1655279"
  },
  {
    "text": "store",
    "start": "1655279",
    "end": "1657279"
  },
  {
    "text": "and and so that kind of concludes our",
    "start": "1657279",
    "end": "1659120"
  },
  {
    "text": "talk for today thank you so much for",
    "start": "1659120",
    "end": "1660880"
  },
  {
    "text": "your time",
    "start": "1660880",
    "end": "1662000"
  },
  {
    "text": "please check out the xboots ready",
    "start": "1662000",
    "end": "1663279"
  },
  {
    "text": "project on github and the documentations",
    "start": "1663279",
    "end": "1664960"
  },
  {
    "text": "we have link here",
    "start": "1664960",
    "end": "1665840"
  },
  {
    "text": "if you want to learn more thanks again",
    "start": "1665840",
    "end": "1667679"
  },
  {
    "text": "and we're happy to answer any questions",
    "start": "1667679",
    "end": "1668960"
  },
  {
    "text": "you might have",
    "start": "1668960",
    "end": "1669600"
  },
  {
    "text": "thank you",
    "start": "1669600",
    "end": "1674799"
  }
]
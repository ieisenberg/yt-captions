[
  {
    "text": "hi how's everyone doing uh I'm Todd I work for cubis systematic if you've",
    "start": "3360",
    "end": "8880"
  },
  {
    "text": "never heard of cubis systematic we are the systematic trading arm of 72 if",
    "start": "8880",
    "end": "14160"
  },
  {
    "text": "you've never heard of 72 we're a hedge fund in New York City well based in Connecticut owned by Steve Cohen and if",
    "start": "14160",
    "end": "19920"
  },
  {
    "text": "you don't know who Steve Cohen is he owns the playoff bound Mets and this is usually as far as I back this out for",
    "start": "19920",
    "end": "25000"
  },
  {
    "text": "friends and family so like that's that's what you get um I work on the Cubist",
    "start": "25000",
    "end": "30279"
  },
  {
    "text": "research Technologies team we sort of stand as an interface between a lot of like Traders and Quant developers and",
    "start": "30279",
    "end": "36520"
  },
  {
    "text": "array cluster be it one of our on Prem clusters or an any scale cluster um and",
    "start": "36520",
    "end": "41840"
  },
  {
    "text": "we handle a lot of like inter like questions from them we're like hey like I want to do X and I can't do it like can you build that out for me um uh the",
    "start": "41840",
    "end": "49760"
  },
  {
    "text": "title of this talk is radar understanding observability at scale I think there's also an extra part with",
    "start": "49760",
    "end": "55440"
  },
  {
    "text": "like with minimal overhead and like that's not on the slide because it looked jeny but like we're still going to talk about it uh I'm hoping to motivate what radar is",
    "start": "55440",
    "end": "63199"
  },
  {
    "text": "and why we built it quickly by example so let's talk about the ray dashboard for a second um the following is just a",
    "start": "63199",
    "end": "71119"
  },
  {
    "text": "generic remote function right it's going to do a couple of imports it's going to",
    "start": "71119",
    "end": "76320"
  },
  {
    "text": "sleep for a second to simulate what maybe like real work would look like it's going to like roll the dice for",
    "start": "76320",
    "end": "81640"
  },
  {
    "text": "something and maybe 10% of the time we'll just raise an exception and fail this task and uh what we'll do is let's",
    "start": "81640",
    "end": "87960"
  },
  {
    "text": "collect a list of references that launches this task maybe like a hundred times or so right so if you're a",
    "start": "87960",
    "end": "93360"
  },
  {
    "text": "developer and you've launched this to a ray cluster your next question is like what's going on like is are my jobs",
    "start": "93360",
    "end": "98640"
  },
  {
    "text": "running and you can usually open up the ray dashboard and when you do so you get like this great breakdown of what's",
    "start": "98640",
    "end": "104280"
  },
  {
    "text": "going on with your job you get like these colorcoded like different signals to say like you've got these jobs",
    "start": "104280",
    "end": "110000"
  },
  {
    "text": "running these jobs are pending these jobs have failed um and if you work a little bit harder you can dig down into",
    "start": "110000",
    "end": "115680"
  },
  {
    "text": "some of these links and you can even find like worker logs to say like hey like I found fail jobs but like what was",
    "start": "115680",
    "end": "121600"
  },
  {
    "text": "the stack Trace like what happened here really handy um the thing is uh if",
    "start": "121600",
    "end": "126880"
  },
  {
    "text": "you're like some of the developers that we work with they find out that they have like hundreds of cores and like tons of gpus and all this horizontal",
    "start": "126880",
    "end": "132599"
  },
  {
    "text": "scaling and they say like great I'm going to run all my tasks like let's go crazy so let's take like for just like a",
    "start": "132599",
    "end": "139680"
  },
  {
    "text": "hypothetical example let's say we launched this task half a million times right and then you've got the same",
    "start": "139680",
    "end": "145680"
  },
  {
    "text": "question which is like well what's going on with all these tasks that I launched like how are things going um and you sort of get a dashboard that",
    "start": "145680",
    "end": "151840"
  },
  {
    "text": "starts off looking good and then you get this and you just sort of see like information about 10,000 tasks but",
    "start": "151840",
    "end": "157680"
  },
  {
    "text": "you've got half a million and this starts to like prompt some natural questions like what's what's going on",
    "start": "157680",
    "end": "163080"
  },
  {
    "text": "like how's this happening also if you refresh this sometimes you get an even scarier message that says like all of your tasks are unaccounted for which is",
    "start": "163080",
    "end": "169840"
  },
  {
    "text": "like oh and then they come to us and like the rain cluster is broken something horrible has happened um I guess the there's two like important",
    "start": "169840",
    "end": "176440"
  },
  {
    "text": "reasons for this one is that by default The Raid dashboard caps out at 10,000 th tasks the other and I might get this",
    "start": "176440",
    "end": "182080"
  },
  {
    "text": "number wrong is that the the ray GCS which contains lots of task related metadata and it runs somewhere on your",
    "start": "182080",
    "end": "187799"
  },
  {
    "text": "ray head caps out somewhere in the like 25 to 50,000 task range so like you",
    "start": "187799",
    "end": "192879"
  },
  {
    "text": "might be sending more tasks to your ray cluster and at some point like it stops keeping track of like some of the older metadata that it might have um which is",
    "start": "192879",
    "end": "199599"
  },
  {
    "text": "a bummer if you want to say like hey I want I ran this task a while ago like what happened to it and the GC is like I",
    "start": "199599",
    "end": "205120"
  },
  {
    "text": "don't know I saw that a while ago I forgot about it so we had to figure out some way say like how how can we address",
    "start": "205120",
    "end": "211319"
  },
  {
    "text": "this problem for some of these these Quant developers that say like I ran this huge job I think some of them",
    "start": "211319",
    "end": "217159"
  },
  {
    "text": "failed I don't really know which ones failed I can't even find my error logs anymore because like my worker scaled down and I lost that worker um and so we",
    "start": "217159",
    "end": "224080"
  },
  {
    "text": "built something called radar there's supposed to be a really cool logo here on the right but compliance didn't okay",
    "start": "224080",
    "end": "229280"
  },
  {
    "text": "it so just like imagine that that white space looks like really cool um here's like high level what radar can do it can",
    "start": "229280",
    "end": "235599"
  },
  {
    "text": "track hundreds of thousands of tasks and it can do it live so this scale is like reason well there's lots of utilities to",
    "start": "235599",
    "end": "241959"
  },
  {
    "text": "do things like aggregations and persist your information about your tasks it can do lots of interesting like user custom",
    "start": "241959",
    "end": "249560"
  },
  {
    "text": "visualizations which I think is what I'm hoping to have most of this talk focus on because that's like the cool thing about radar and uh it integrates really",
    "start": "249560",
    "end": "257359"
  },
  {
    "text": "really well into the any scale dashboard and the setup is really really minimal so since it's minimal let's just start",
    "start": "257359",
    "end": "263639"
  },
  {
    "text": "there as far as the setup goes for radar you really only have to do two things the first is it's a package on pii so",
    "start": "263639",
    "end": "270280"
  },
  {
    "text": "pip install it that's that's one and then you have to figure out a way to get it into your ray cluster you can either",
    "start": "270280",
    "end": "275720"
  },
  {
    "text": "do that by uploading it as a pi module in your runtime environment you can bake it into your image somehow you can add",
    "start": "275720",
    "end": "281800"
  },
  {
    "text": "it as a pip argument when you connect to your cluster you've got a couple of options either way it's like two lines",
    "start": "281800",
    "end": "286840"
  },
  {
    "text": "like you don't have to do a ton here um so now let's let's take that example",
    "start": "286840",
    "end": "292120"
  },
  {
    "text": "that we had previously and let's talk about like how radar could interact and like solve some of these problems that we have right um so everything is the",
    "start": "292120",
    "end": "299080"
  },
  {
    "text": "same but now we're going to import this this class called the Ray task tracker and let's just default initialize it um",
    "start": "299080",
    "end": "305840"
  },
  {
    "text": "and then we'll tell it like hey process all these references that we're holding and this now suddenly exposes a bunch of",
    "start": "305840",
    "end": "312120"
  },
  {
    "text": "useful helper functions that like are kind of interesting like you can do this task tracker get data frame call that",
    "start": "312120",
    "end": "318280"
  },
  {
    "text": "gets back to your client this big polar data frame with like all this information that should normally be stored in the ray GCS so you've got like",
    "start": "318280",
    "end": "325039"
  },
  {
    "text": "task information you've got like worker ID and like function name and maybe you have status maybe you have like exception and like stack Trace",
    "start": "325039",
    "end": "331240"
  },
  {
    "text": "information if like that's applicable uh it's cool and you also have the option to save this data frame somewhere like",
    "start": "331240",
    "end": "337319"
  },
  {
    "text": "maybe you want to save it to the cloud maybe you have like a mount somewhere maybe you want to like save it to like a local file you can persist this",
    "start": "337319",
    "end": "343080"
  },
  {
    "text": "information and you can clear it cuz like otherwise this is a memory leak risk and like that's that's like no great um I guess this is like vaguely",
    "start": "343080",
    "end": "351039"
  },
  {
    "text": "intriguing maybe but it's like this kind of stinks like it seems manual like what if I want to interact with it a lot",
    "start": "351039",
    "end": "357120"
  },
  {
    "text": "seems like I'm sending like a big data frame over the wireless this seem suboptimal and like not very fun or interesting um so you're right and this",
    "start": "357120",
    "end": "364440"
  },
  {
    "text": "is we where we're going to introduce like a new component of this like radar Ray task tracker object we are going to",
    "start": "364440",
    "end": "370759"
  },
  {
    "text": "set this parameter which indicates that we are enabling a prospective dashboard I don't know how many of you have heard",
    "start": "370759",
    "end": "376400"
  },
  {
    "text": "of perspective before but it's got a great website perspective is this like analytics engine which offers lots of",
    "start": "376400",
    "end": "383599"
  },
  {
    "text": "like really cool visualization options especially for large data sets and for streaming data sets um this gift that",
    "start": "383599",
    "end": "390120"
  },
  {
    "text": "you're looking at is a bunch of the examples that they have on their website so if you fall asleep during this talk definitely check out their website CU",
    "start": "390120",
    "end": "396479"
  },
  {
    "text": "like they've got really really cool and useful and interesting looking graphs um lots of different types of charts",
    "start": "396479",
    "end": "402199"
  },
  {
    "text": "different like on thefly aggregations that we'll talk about a little bit under the hood the idea is that perspective",
    "start": "402199",
    "end": "407599"
  },
  {
    "text": "allows you to Define some sort of like table schema in like its back end and",
    "start": "407599",
    "end": "413360"
  },
  {
    "text": "then you can update that table via like either a JavaScript call or like a python call it's got like a reasonably flexible API and then it also exposes",
    "start": "413360",
    "end": "420960"
  },
  {
    "text": "like the frontend component which lets you like look at that data and visualize it in interesting ways um so now if",
    "start": "420960",
    "end": "427080"
  },
  {
    "text": "we're running what we just saw before on Port 8000 on your ray cluster you're suddenly getting this as your tasks run",
    "start": "427080",
    "end": "434560"
  },
  {
    "text": "it's like oh cool like interesting it's live I'm not like downloading data like over the wire like that that seems nice",
    "start": "434560",
    "end": "440879"
  },
  {
    "text": "it's the same information that otherwise was somewhat contained inside of the data frame that we talked about earlier",
    "start": "440879",
    "end": "446639"
  },
  {
    "text": "but you know at least it's not like something that I have to like go and like set up and download or like save somewhere like we can just kind of like",
    "start": "446639",
    "end": "452199"
  },
  {
    "text": "hit like a port on our cluster and like see it and that's kind of interesting um but admittedly this is still like how",
    "start": "452199",
    "end": "457400"
  },
  {
    "text": "does this solve any of the problems that we talked about earlier like I can't look at this and understand like what my jobs are doing how things are working",
    "start": "457400",
    "end": "463400"
  },
  {
    "text": "like so on and so on so it's probably a quick time to talk about like what perspective can do perspective has lots",
    "start": "463400",
    "end": "469520"
  },
  {
    "text": "of different charting types it's got bar charts and tree charts and heat maps and pie charts and all sorts of like",
    "start": "469520",
    "end": "475080"
  },
  {
    "text": "interesting things that you can graph it's got like aggregation options and groups and sorts and filters which is",
    "start": "475080",
    "end": "480960"
  },
  {
    "text": "you know like reasonably helpful for any like UI that you might want it to apply on top of data um it also has a",
    "start": "480960",
    "end": "486599"
  },
  {
    "text": "reasonably good expression API so if you have a lot of different columns in your table you can on the Fly do like",
    "start": "486599",
    "end": "492240"
  },
  {
    "text": "aggregations you can do interesting computations that like maybe you care about um here for instance the GCS logs",
    "start": "492240",
    "end": "498400"
  },
  {
    "text": "your start and end time in milliseconds but it actually does it in strings so if you like do like a cast take a",
    "start": "498400",
    "end": "503520"
  },
  {
    "text": "difference divide like all of a sudden like I have like a more useful column that like maybe I'm going to call like seconds that it took my job to run which",
    "start": "503520",
    "end": "509919"
  },
  {
    "text": "is like oh like cute um so for the sake of like illustration let's also",
    "start": "509919",
    "end": "516518"
  },
  {
    "text": "introduce a second remote function called my other remote function it's going to be almost the exact same thing",
    "start": "516519",
    "end": "522120"
  },
  {
    "text": "as we had previously the only difference is like now maybe like we'll simulate work by you know rolling the dice and",
    "start": "522120",
    "end": "527640"
  },
  {
    "text": "we'll sleep for like a unset amount of time and we'll also like toggle the parameters by like how often this task",
    "start": "527640",
    "end": "533560"
  },
  {
    "text": "will fail now like let's say that like if it's like 60% of the time let's just like have it fail throw a separate exception message and like that's fine",
    "start": "533560",
    "end": "540720"
  },
  {
    "text": "let's launch half a million of those too and let's also tell our task tracker to process this information um now you can",
    "start": "540720",
    "end": "547399"
  },
  {
    "text": "suddenly build interesting charts that might actually help you solve like some questions that like maybe you were wondering about um on the bottom left",
    "start": "547399",
    "end": "554640"
  },
  {
    "text": "hand side here is still that like familiar table that has all the generic information coming out from the GCS but",
    "start": "554640",
    "end": "560079"
  },
  {
    "text": "on the top left you've got a breakdown per task per function type about like what your like success failure rate is",
    "start": "560079",
    "end": "566920"
  },
  {
    "text": "for these tasks on the bottom right live your seeing how long it took each one of these tasks to like die or succeed um",
    "start": "566920",
    "end": "573760"
  },
  {
    "text": "and on the top we get a breakdown of like exactly what exception messages are being thrown and like live and how many",
    "start": "573760",
    "end": "579480"
  },
  {
    "text": "so you can like show up to this scroll see like exactly what's going on and like maybe now that if you're running",
    "start": "579480",
    "end": "584800"
  },
  {
    "text": "like many many many tasks you can get like a live on the Fly answer to some questions about like why are some of my tasks failing like do I need to like is",
    "start": "584800",
    "end": "591200"
  },
  {
    "text": "there like a weird Edge case that like my jobs are hitting and this can help you address some of those um I'm hoping",
    "start": "591200",
    "end": "597480"
  },
  {
    "text": "to provide a couple of like hopefully compelling examples that you can like of",
    "start": "597480",
    "end": "603279"
  },
  {
    "text": "things that you can do with radar um the first one is graphon like metrics I don't know if you've ever poked around",
    "start": "603279",
    "end": "609600"
  },
  {
    "text": "the metrics tab on the ray dashboard but if you go into the grafana view you get",
    "start": "609600",
    "end": "614640"
  },
  {
    "text": "a lot of really interesting cluster level breakdowns right like you get like Network and CPU and like task and actor",
    "start": "614640",
    "end": "621920"
  },
  {
    "text": "level breakdowns like all really cool really useful and interesting stuff like maybe you have like some like",
    "start": "621920",
    "end": "627279"
  },
  {
    "text": "particularly nasty job that needs like some very spe specific debugging like maybe this is the place that you should go and you should graan is awesome um",
    "start": "627279",
    "end": "633839"
  },
  {
    "text": "the only downside is let's say that you're doing this on like a company cluster or like something that you don't really have access to setting up grafana",
    "start": "633839",
    "end": "640399"
  },
  {
    "text": "like takes some time it takes doing you just have to um which isn't a bad thing and it's something that you still should",
    "start": "640399",
    "end": "646040"
  },
  {
    "text": "be doing but like what if you're in a hurry and like you don't feel like doing it right um well fun fact if you look at",
    "start": "646040",
    "end": "653040"
  },
  {
    "text": "your ray nodes and you inspect your uh your node manager address and then you look at your metrics export port and you",
    "start": "653040",
    "end": "660000"
  },
  {
    "text": "hit that on your cluster you can actually get like this big wall of text of Prometheus metrics that like you look",
    "start": "660000",
    "end": "666200"
  },
  {
    "text": "at you're like what is all of this format like this looks like really it's a lot um it's ultimately the same data",
    "start": "666200",
    "end": "672440"
  },
  {
    "text": "that you're seeing in grafana and you can write parsers for it and they're exist like open source parses for it that are like great so we figured like",
    "start": "672440",
    "end": "679360"
  },
  {
    "text": "hey why don't we just take this endpoint take the parser use this Prometheus",
    "start": "679360",
    "end": "684720"
  },
  {
    "text": "endpoint that we now have and let's publish all of these metrics to like our own tables and then like let's just use",
    "start": "684720",
    "end": "691320"
  },
  {
    "text": "that data in a perspective dashboard and that's what you can do so",
    "start": "691320",
    "end": "696440"
  },
  {
    "text": "just set this parameter and all of a sudden under the hood with like no real extra work you're doing so and that lets",
    "start": "696440",
    "end": "702839"
  },
  {
    "text": "you build out like interesting looking charts like this we now have like cluster level State distributions across",
    "start": "702839",
    "end": "709040"
  },
  {
    "text": "all your tasks you have like what functions are running on what node IP uh what like CPU look CPU usage looks like",
    "start": "709040",
    "end": "716360"
  },
  {
    "text": "across your cluster it's interesting like it's not like a built-in replacement for gravana but like maybe",
    "start": "716360",
    "end": "721839"
  },
  {
    "text": "you have some very specific thing that you want to inspect quickly like this is a user definable",
    "start": "721839",
    "end": "727519"
  },
  {
    "text": "option um quick plug for any scale which is if you're an any scale cluster everything that we've talked about so",
    "start": "727519",
    "end": "733560"
  },
  {
    "text": "far and will talk about for the rest of this stock works really great in any scale any scale if you open up their UI",
    "start": "733560",
    "end": "740160"
  },
  {
    "text": "they have a ports option on the tab and if you're running radar and you click into that you like instantly get a link",
    "start": "740160",
    "end": "745880"
  },
  {
    "text": "to this UI so you don't have to worry about like how do I hit a port on my cluster like how do I worry about like I don't know reverse proxy forwarding or",
    "start": "745880",
    "end": "753040"
  },
  {
    "text": "something on like some fancy fancy cluster that like I may or may not have any access to um I want to move way away",
    "start": "753040",
    "end": "760440"
  },
  {
    "text": "from that and go more into custom user stuff because I think this is a little bit more interesting um but to talk",
    "start": "760440",
    "end": "766199"
  },
  {
    "text": "about it I think we should maybe break into the back end of what's going on with your raid task tracker in the first",
    "start": "766199",
    "end": "771600"
  },
  {
    "text": "place um more or less it works kind of like this if that stick figure is your client when you initialize a task",
    "start": "771600",
    "end": "778600"
  },
  {
    "text": "tracker object you're actually interacting with a handle to an actor which lives on your head note and that's",
    "start": "778600",
    "end": "784279"
  },
  {
    "text": "just the radar actor and that actor owns this like callback actor handle which is like doing a lot of the task processing",
    "start": "784279",
    "end": "791120"
  },
  {
    "text": "that callback actor is interfacing with the GCS which is saying like hey like GCS here's this list of tasks like do",
    "start": "791120",
    "end": "796480"
  },
  {
    "text": "you know information about any of them if you do I'm going to send them back and like publish that out to the user and then all these things ultimately are",
    "start": "796480",
    "end": "802760"
  },
  {
    "text": "interacting with Ray serve some sort of like proxy service that like hosts something that like you care about from",
    "start": "802760",
    "end": "808160"
  },
  {
    "text": "your UI perspective um you might also think like I don't really care about that part like the GCS",
    "start": "808160",
    "end": "813519"
  },
  {
    "text": "part is not especially compelling to me I would rather just do this I just want some sort of interface to like give me",
    "start": "813519",
    "end": "819920"
  },
  {
    "text": "an actor handle I want to make my own tables I want to publish my own data to my own tables and then expose that",
    "start": "819920",
    "end": "825720"
  },
  {
    "text": "somewhere and that's super reasonable um another reason that the actor piece is kind of important is if you have an",
    "start": "825720",
    "end": "832639"
  },
  {
    "text": "actor that means that you can fetch that actor handle really from not just your client code but it could also be inside",
    "start": "832639",
    "end": "838199"
  },
  {
    "text": "of like an arbitrary remote call it could even be in like a torch train object or like array train Tor array",
    "start": "838199",
    "end": "843880"
  },
  {
    "text": "torch trainer object because all of these things really just need to use ray. getet to interface with your actor",
    "start": "843880",
    "end": "849720"
  },
  {
    "text": "handle so that's important and we'll see why in a moment um so let's introduce a new task",
    "start": "849720",
    "end": "856279"
  },
  {
    "text": "tracker we'll still enable the prospective dashboard but this time we'll give it explicitly a name and a name space um and we have a bunch of",
    "start": "856279",
    "end": "863240"
  },
  {
    "text": "utility functions to do things like create and update tables so let's let's create a table we'll call it like the goofy demo table and we'll just give it",
    "start": "863240",
    "end": "869920"
  },
  {
    "text": "a bunch of table schema we'll ask for a worker ID a string type a metric value an INT some other metric value we'll",
    "start": "869920",
    "end": "876160"
  },
  {
    "text": "just make that a float typed and some like timestamp date time okay um if I",
    "start": "876160",
    "end": "883000"
  },
  {
    "text": "now have a remote call that maybe I care about and maybe I generate some data for on the fly I can do a couple of things",
    "start": "883000",
    "end": "890040"
  },
  {
    "text": "the first is I can initialize a new task tracker object with that same name and",
    "start": "890040",
    "end": "895600"
  },
  {
    "text": "name space doing so allows the ray task tracker under the hood Hood to fetch that handle that it has to the actor and",
    "start": "895600",
    "end": "902199"
  },
  {
    "text": "so like without actually recreating anything it just like knows where this object is and it knows how to create it",
    "start": "902199",
    "end": "907240"
  },
  {
    "text": "because it knows how to fetch that actor from your cluster sorry um let's also do",
    "start": "907240",
    "end": "913240"
  },
  {
    "text": "a couple of other things in this function so let's pretend that this data this remote call takes a parameter I an",
    "start": "913240",
    "end": "919279"
  },
  {
    "text": "integer parameter I and let's say that we'll just like hardcode this worker ID",
    "start": "919279",
    "end": "924320"
  },
  {
    "text": "as like our string for now because this was my local cluster uh the metric value will just make it whatever we pass so I",
    "start": "924320",
    "end": "930639"
  },
  {
    "text": "and this other metric value will make it like I times some noise so like something a little bit noisy right and",
    "start": "930639",
    "end": "937399"
  },
  {
    "text": "we'll just say like the time stamp is whenever this task runs if we run this now all of a sudden",
    "start": "937399",
    "end": "944759"
  },
  {
    "text": "in our UI we have the ability to look at our tables and kind of compare that",
    "start": "944759",
    "end": "950120"
  },
  {
    "text": "metric value and other metric value as these tasks run live so the one side looks kind of exactly what you'd think",
    "start": "950120",
    "end": "956519"
  },
  {
    "text": "it's just like a linear bunch of lines going up over time and the other is sort of the same thing but like interspersed",
    "start": "956519",
    "end": "961920"
  },
  {
    "text": "with a bunch of noise this isn't really like a compelling or like exciting example but like hopefully it prompts",
    "start": "961920",
    "end": "967199"
  },
  {
    "text": "the idea that like if I have data that I care about in remote tasks I can publish that live and I can do this like at",
    "start": "967199",
    "end": "973240"
  },
  {
    "text": "scale if like I feel like digging into something um we were thinking about other interesting and cool examples to",
    "start": "973240",
    "end": "979639"
  },
  {
    "text": "do with radar and we were like what should we do and we're like crypto and it's like no we're going to do ml",
    "start": "979639",
    "end": "985360"
  },
  {
    "text": "instead so let's get into like the ml example for this talk right um if you've ever looked at the pytorch",
    "start": "985360",
    "end": "991680"
  },
  {
    "text": "lightning code there's a way to define your own custom logger and like more or less the documentation says interface",
    "start": "991680",
    "end": "998600"
  },
  {
    "text": "like here you go implement this and you have your own custom pytorch logger there's a lot of methods here that like",
    "start": "998600",
    "end": "1004959"
  },
  {
    "text": "aren't like either super super interesting or they're like optional so I'm going to mostly ignore those and just focus on these highlighted ones um",
    "start": "1004959",
    "end": "1012000"
  },
  {
    "text": "more or less the log metrics option is saying like I'm going to hand your",
    "start": "1012000",
    "end": "1017600"
  },
  {
    "text": "logger Class A dictionary of metrics like do something with it and like often times you publish that to like a log",
    "start": "1017600",
    "end": "1024199"
  },
  {
    "text": "Handler like you do something interesting with it it seems super reasonable to say like hey that seems to",
    "start": "1024199",
    "end": "1029480"
  },
  {
    "text": "fit the Paradigm that we've built with this like task tracking object right so let's define our own custom logger and",
    "start": "1029480",
    "end": "1036280"
  },
  {
    "text": "I'm going to handwave here I'm missing a function but like it was too big to fit on the slide anyway what we'll do is we will pass our custom logger a instance",
    "start": "1036280",
    "end": "1044880"
  },
  {
    "text": "of our Ray task tracker object right in construction and then when we when it comes time to log metrics just tell my",
    "start": "1044880",
    "end": "1051840"
  },
  {
    "text": "task tracker to update the table that we care about let's call it like my metrics table with those metrics right so now",
    "start": "1051840",
    "end": "1060120"
  },
  {
    "text": "all you really need to do is three things one you initialize a task tracker give it like a name in a namespace if you want like maybe that's useful",
    "start": "1060120",
    "end": "1066799"
  },
  {
    "text": "initialize a table that you care about for perspective so Define some metrics table give it like some schema for some",
    "start": "1066799",
    "end": "1072400"
  },
  {
    "text": "metrics that you feel like implementing from within pytorch lightning and create your",
    "start": "1072400",
    "end": "1077440"
  },
  {
    "text": "logger now if you're implementing a pytorch lightning module you can use the",
    "start": "1077440",
    "end": "1083600"
  },
  {
    "text": "the self. log dict function which under the hood really is interfacing with",
    "start": "1083600",
    "end": "1088640"
  },
  {
    "text": "whatever logger option you've defined in your pytorch lightning trainer initialization so when you see something",
    "start": "1088640",
    "end": "1095520"
  },
  {
    "text": "like that second line here so I'm Computing a loss in the forward step of my model training and I'm building out",
    "start": "1095520",
    "end": "1101000"
  },
  {
    "text": "this dictionary of like MSE loss and like what step I'm at total for the",
    "start": "1101000",
    "end": "1106159"
  },
  {
    "text": "entire model training process and what work ID I have and I'm saying like send this to whatever logger you've got and",
    "start": "1106159",
    "end": "1112520"
  },
  {
    "text": "like Let It handle that information so on the top is sort of how things would have been prior to any of",
    "start": "1112520",
    "end": "1119000"
  },
  {
    "text": "this discussion you build some sort of pie torch lightning model you build some P torch lightning trainer using that",
    "start": "1119000",
    "end": "1124360"
  },
  {
    "text": "loger using that model and then you tell your trainer like hey go fit this uh now what I'm saying is do these things build",
    "start": "1124360",
    "end": "1130159"
  },
  {
    "text": "a task tracker build the table that you care about initialize this custom logger",
    "start": "1130159",
    "end": "1135440"
  },
  {
    "text": "and then when you're building your P torch lightning trainer just tell it like use my logger don't use like the default logger use mine and if you do so",
    "start": "1135440",
    "end": "1142799"
  },
  {
    "text": "suddenly you get live visualizations like this on a ray cluster what you're seeing here is your msse across your",
    "start": "1142799",
    "end": "1149000"
  },
  {
    "text": "Epoch so different colors correspond to different Epoch and you can see like over time like oh cool like my model",
    "start": "1149000",
    "end": "1155480"
  },
  {
    "text": "it's it's learning some stuff and like maybe this informs some stuff about like I don't know how many epochs you really",
    "start": "1155480",
    "end": "1160880"
  },
  {
    "text": "needed to set in your trainer process so this is interesting I mean taking this a single step further if you check out the",
    "start": "1160880",
    "end": "1168919"
  },
  {
    "text": "the radar docks about P torch lightning and this is going to be a little bit handwavy but it more or less says that",
    "start": "1168919",
    "end": "1174520"
  },
  {
    "text": "like you can kind of write P torch lightning code like the way you always have but set like these extra six",
    "start": "1174520",
    "end": "1179919"
  },
  {
    "text": "parameters give it like devices and accelerator like the these blue parameters here right um and what",
    "start": "1179919",
    "end": "1185039"
  },
  {
    "text": "that'll suddenly let you do is it'll allow you to take a pytorch lightning model and train it on a raid cluster and like distributed in a distributed way",
    "start": "1185039",
    "end": "1191679"
  },
  {
    "text": "with like multi-gpu which is really cool what I'm saying is like if you just take this one tiny step further and you add",
    "start": "1191679",
    "end": "1198760"
  },
  {
    "text": "that logger object that we had previously suddenly you now have like",
    "start": "1198760",
    "end": "1204240"
  },
  {
    "text": "distributed metrics computation and like UI publishing baked into everything that",
    "start": "1204240",
    "end": "1209360"
  },
  {
    "text": "you were already doing here already with like a single line of code like that feels like easy enough to do so if you",
    "start": "1209360",
    "end": "1215919"
  },
  {
    "text": "do this now you get that same degree of like worker of like loss metrics but now",
    "start": "1215919",
    "end": "1221720"
  },
  {
    "text": "instead of like broken down by Epoch you get it broken down by worker which is like it's kind of interesting and like",
    "start": "1221720",
    "end": "1227320"
  },
  {
    "text": "hopefully this is like slightly more compelling um what I was going to say is that I think I sort of am burying the",
    "start": "1227320",
    "end": "1234080"
  },
  {
    "text": "lead here with the introduction of radar being like hey like doesn't the dashboard like break sometimes like",
    "start": "1234080",
    "end": "1239320"
  },
  {
    "text": "maybe we could fix that I don't really think that radar is a good drop in replacement for the dashboard or for",
    "start": "1239320",
    "end": "1245600"
  },
  {
    "text": "like you know tensor board or for grafana I think where radar is really good is it's good for like saying I have",
    "start": "1245600",
    "end": "1251760"
  },
  {
    "text": "this very specific custom use case that is like a weird Edge case for tensor board or for grafana or for the",
    "start": "1251760",
    "end": "1257760"
  },
  {
    "text": "dashboard already but I really want to see it live like it's really going to be something that I would love to be able to see as my tasks progress and I also",
    "start": "1257760",
    "end": "1264760"
  },
  {
    "text": "don't really want to spend a lot of time setting this all up um so here's like a real example of that very thing um at",
    "start": "1264760",
    "end": "1272760"
  },
  {
    "text": "cubis we were training like a really big model on lots and lots of data with like",
    "start": "1272760",
    "end": "1277960"
  },
  {
    "text": "40 different GPU workers at a time and a lot of questions were like why why is this taking so long like what is",
    "start": "1277960",
    "end": "1284080"
  },
  {
    "text": "happening at scale here um and so like we defined this we we kind of walk through everything that I just did here",
    "start": "1284080",
    "end": "1290039"
  },
  {
    "text": "but within a array torch trainer object I'm figuring out how to like publish a data that I care about and now I have",
    "start": "1290039",
    "end": "1296039"
  },
  {
    "text": "this UI that like I can watch live and I can kind of see my my loss curves go down across my workers I can get a",
    "start": "1296039",
    "end": "1302240"
  },
  {
    "text": "breakdown of like how each trainer process is spending its time it turned out that like data loading here was kind",
    "start": "1302240",
    "end": "1308960"
  },
  {
    "text": "of a lot you get this nice chart with like all these different like color codes and you can see like whether or not like one or two of them was like",
    "start": "1308960",
    "end": "1314960"
  },
  {
    "text": "spiking for weird reasons at different times which like helped us figure out like okay probably need to figure out some Network changes which is nice um",
    "start": "1314960",
    "end": "1321760"
  },
  {
    "text": "and it also helped dispel this myth that we were thinking that oh like perhaps um as we do distributed training in pytorch",
    "start": "1321760",
    "end": "1328279"
  },
  {
    "text": "maybe like some of the workers are getting like stuck and like maybe there's like a weird like fan in fanan",
    "start": "1328279",
    "end": "1333400"
  },
  {
    "text": "out process and we were able to look at this and realize that like no it's actually mostly data like all the workers are like actually kind of",
    "start": "1333400",
    "end": "1338960"
  },
  {
    "text": "running through their loops and updating and going to their next stages like reasonably quickly um radar is in like",
    "start": "1338960",
    "end": "1346200"
  },
  {
    "text": "pretty active development and we really like updating it because we open sourced it uh what you're seeing here is a lot",
    "start": "1346200",
    "end": "1352480"
  },
  {
    "text": "of users were telling us that hey I spent all this time going through your UI and building out these charts and",
    "start": "1352480",
    "end": "1359000"
  },
  {
    "text": "like hand crafting all these custom visualizations but then if I terminate my cluster like oh this all goes away",
    "start": "1359000",
    "end": "1365480"
  },
  {
    "text": "like that's a really crappy user experience and and it's true so like we built this quick thing to say like hey",
    "start": "1365480",
    "end": "1370799"
  },
  {
    "text": "like wouldn't it be nice if you just hit a button on the top right and it saved your configuration and if you felt like",
    "start": "1370799",
    "end": "1375840"
  },
  {
    "text": "restoring it just like drag and drop it into your window and like get things running again it's nice and it's just",
    "start": "1375840",
    "end": "1381440"
  },
  {
    "text": "one of the ways that I think that we as a group are kind of committed to saying like yeah like we would like this user experience to be good because like we",
    "start": "1381440",
    "end": "1388000"
  },
  {
    "text": "like contributions we like people like showing up and like adding things to our repos like this is a hopefully this is a",
    "start": "1388000",
    "end": "1393960"
  },
  {
    "text": "good sign for people who are thinking about like I'd like to poke around in your repo um that's mostly it thank you",
    "start": "1393960",
    "end": "1399880"
  },
  {
    "text": "for coming I know there's a lot of like other really cool talks right now so I appreciate it here's our GitHub repo um",
    "start": "1399880",
    "end": "1406559"
  },
  {
    "text": "check it out I think that we like stars so if you feel like starring it please do like and subscribe um I think that if",
    "start": "1406559",
    "end": "1414440"
  },
  {
    "text": "you have some like issues like please feel free raise them on the GitHub page and we like addressing them so we're not",
    "start": "1414440",
    "end": "1420919"
  },
  {
    "text": "super uh gatekeeping about PR so if you feel like changing something like put it up and we enjoy it are there any",
    "start": "1420919",
    "end": "1427120"
  },
  {
    "text": "questions anything like that yeah",
    "start": "1427120",
    "end": "1432720"
  },
  {
    "text": "behind so the question was what's like why perspective right so perspective I",
    "start": "1434000",
    "end": "1440240"
  },
  {
    "text": "think I think a couple reasons like one is that one of the people that we worked with has a lot of experience with it and",
    "start": "1440240",
    "end": "1446039"
  },
  {
    "text": "like that was like Hey like that's a tool that like I think I can help use build this stuff the other is that I think it scaled like surprisingly well",
    "start": "1446039",
    "end": "1453279"
  },
  {
    "text": "for our use case like it does some like tricky things in your browser under the hood with like trying to keep like",
    "start": "1453279",
    "end": "1458480"
  },
  {
    "text": "rendering a little bit like sane so you can say like I'm going to tell the ray task tracker to process 250,000 tasks",
    "start": "1458480",
    "end": "1466120"
  },
  {
    "text": "and like that doesn't like cause your dashboard to explode like you can still see like meaningful stuff as you go um I",
    "start": "1466120",
    "end": "1471360"
  },
  {
    "text": "think that was mostly it yeah okay yeah yeah yeah in HC we don't have theity to",
    "start": "1471360",
    "end": "1478039"
  },
  {
    "text": "check is there possibility to have like kind of at the end of the",
    "start": "1478039",
    "end": "1484320"
  },
  {
    "text": "train so what do you want what do you want to do ahead of time so basically we have we cannot check stuff live so we",
    "start": "1484320",
    "end": "1490440"
  },
  {
    "text": "would like once the training has finished to have aort as a file or something using oh so",
    "start": "1490440",
    "end": "1498679"
  },
  {
    "text": "you want to like you want to like run some stuff publish it to radar and then",
    "start": "1498679",
    "end": "1503760"
  },
  {
    "text": "like you want to like be like a a human in the loop and be like do this and then like your job continues no no like once the job is done you have the report oh",
    "start": "1503760",
    "end": "1512080"
  },
  {
    "text": "like an automated report so I guess in the sense that like the UI",
    "start": "1512080",
    "end": "1518799"
  },
  {
    "text": "exists and it'll be there and all your data will exist it just won't be updating so not in the sense that",
    "start": "1518799",
    "end": "1524080"
  },
  {
    "text": "there's like you could always print it out as like a PDF or something I guess there's also an export option in",
    "start": "1524080",
    "end": "1529399"
  },
  {
    "text": "perspective that's like save all of my tables and all of their data to some like local file and then you can",
    "start": "1529399",
    "end": "1534960"
  },
  {
    "text": "interact with it that way too but there's not like an out- of the-box way to say like generate me a latch doc with",
    "start": "1534960",
    "end": "1540559"
  },
  {
    "text": "like all this cool stuff in it right now so open it as an issue on GitHub yeah um you mentioned that radar",
    "start": "1540559",
    "end": "1548799"
  },
  {
    "text": "supports interesting metrics fromus also and you compar to the gra how would you",
    "start": "1548799",
    "end": "1554600"
  },
  {
    "text": "compare like the and of the gra UI",
    "start": "1554600",
    "end": "1559640"
  },
  {
    "text": "um so from a scaling perspective I think they're both going to be really good I think the only difference is what if you",
    "start": "1559640",
    "end": "1567039"
  },
  {
    "text": "want to come to grafana with like your own custom metrics like I don't want to use I don't want to use like something from like your node",
    "start": "1567039",
    "end": "1574880"
  },
  {
    "text": "manager Port I want to like write my own custom stuff um and that's I think where the biggest Delta is like I have my own",
    "start": "1574880",
    "end": "1581320"
  },
  {
    "text": "tables I have my own columns that I'm going to update and like see cool things about that's I think the biggest difference",
    "start": "1581320",
    "end": "1589200"
  },
  {
    "text": "yeah so I would run it I would run it regularly just to be safe but there's",
    "start": "1606320",
    "end": "1612000"
  },
  {
    "text": "like a way that perspective does some of this stuff in like your browser storage where like it tries to offload some of",
    "start": "1612000",
    "end": "1617360"
  },
  {
    "text": "that to your browser I think think um now if you're going to ask me like more technical details on like how it's doing that I'm like oh man that's really like",
    "start": "1617360",
    "end": "1623440"
  },
  {
    "text": "the guy that I work with that knows that stuff um but like what you're saying is right like in general you should probably be like saving and clearing",
    "start": "1623440",
    "end": "1629279"
  },
  {
    "text": "these things just from like a sanity perspective and like sanitation good like practice so yeah",
    "start": "1629279",
    "end": "1637880"
  },
  {
    "text": "yeah oh like you want to rewind it and like see your lost curves go oh that's a cool idea uh not right now",
    "start": "1640120",
    "end": "1650158"
  },
  {
    "text": "that would have been really helpful when I was making all these gifts cuz I can't tell you how many times I have to like start doing it over um not right now but",
    "start": "1650240",
    "end": "1657840"
  },
  {
    "text": "like again another issue for the GitHub yeah hey so R is something that's",
    "start": "1657840",
    "end": "1663399"
  },
  {
    "text": "running on a local machine and connect a local CL so um your task tracker is like",
    "start": "1663399",
    "end": "1671120"
  },
  {
    "text": "an object that you can hold on like your client it's also something you can hold and own in like a remote function",
    "start": "1671120",
    "end": "1677320"
  },
  {
    "text": "ultimately what it's really doing is it's connecting to actors which live on your cluster so it that's the piece that",
    "start": "1677320",
    "end": "1684320"
  },
  {
    "text": "like is like the the heavyweight stuff and that's all cluster side not client side okay so I'm just asking is there",
    "start": "1684320",
    "end": "1690799"
  },
  {
    "text": "something you have done that living the like rad on the centralized service like a centralized UI then data science",
    "start": "1690799",
    "end": "1697720"
  },
  {
    "text": "connect to that UI instead running the local something thought about and that's",
    "start": "1697720",
    "end": "1702760"
  },
  {
    "text": "UI kind of connecting to the for example I have a great FAS running on thewhere",
    "start": "1702760",
    "end": "1708200"
  },
  {
    "text": "and that UI just connect to data source instead of I configuring any data source or anything automatically everyone can",
    "start": "1708200",
    "end": "1713960"
  },
  {
    "text": "see that live is that something a okay so oh where's that picture that I had so you're saying like hold on like cut this",
    "start": "1713960",
    "end": "1721679"
  },
  {
    "text": "out like I don't want this at all I just want task the radar stuff to like open up some like race serve application and",
    "start": "1721679",
    "end": "1728200"
  },
  {
    "text": "like host the UI um it's very doable like we don't need the actor really like the actor mostly exists to do this weird",
    "start": "1728200",
    "end": "1734600"
  },
  {
    "text": "callback hacky thing to like interface with the GCS um there's no reason that we couldn't make it even easier to just",
    "start": "1734600",
    "end": "1742440"
  },
  {
    "text": "like launch the serve application um but as of now like the API is more",
    "start": "1742440",
    "end": "1748960"
  },
  {
    "text": "like build a task tracker do something with it I think like the bigger question is if you're using that like serve",
    "start": "1748960",
    "end": "1754640"
  },
  {
    "text": "application um you have to be a little bit careful about how you interface with your serve stuff in the sense that like",
    "start": "1754640",
    "end": "1761760"
  },
  {
    "text": "what if you have like multiple proxy servers like how do you like update the right one at each time without like like",
    "start": "1761760",
    "end": "1767720"
  },
  {
    "text": "a weird conflict like that's where the actor stuff comes in handy cuz like you just get the right name and name space and you're updating the right tables in",
    "start": "1767720",
    "end": "1773679"
  },
  {
    "text": "the right UI yeah do you the data sorry data so",
    "start": "1773679",
    "end": "1783399"
  },
  {
    "text": "the data is owned somewhere in like realistically plasma um and then it's",
    "start": "1783399",
    "end": "1789320"
  },
  {
    "text": "also there's something that perspective does to leverage like storing stuff in your browser but like realistically it's",
    "start": "1789320",
    "end": "1795120"
  },
  {
    "text": "on your ray head at least for a little while the ideal is that like it's not really that much data especially if",
    "start": "1795120",
    "end": "1801000"
  },
  {
    "text": "you're if you're already running compute loads that are in the like the 200 500,000 tasks range then like like it's",
    "start": "1801000",
    "end": "1807240"
  },
  {
    "text": "probably going to eventually be like enough data to be annoying but like generally speaking that hasn't been the case",
    "start": "1807240",
    "end": "1812919"
  },
  {
    "text": "yet yeah I know prome own language to",
    "start": "1812919",
    "end": "1818320"
  },
  {
    "text": "I'm curious perspective has something simar um I don't know enough about its",
    "start": "1818320",
    "end": "1826080"
  },
  {
    "text": "query language but the perspective query language has a lot of like I don't know",
    "start": "1826080",
    "end": "1831159"
  },
  {
    "text": "it's it's have you ever used scuba scuba is from meta like it's the same kind of query language where it's like I want to",
    "start": "1831159",
    "end": "1837720"
  },
  {
    "text": "do some generic combination of columns I have like I want to take an average of",
    "start": "1837720",
    "end": "1842799"
  },
  {
    "text": "min mean Max that kind of thing yeah",
    "start": "1842799",
    "end": "1850480"
  },
  {
    "text": "question with Rune yeah so um I'm G to fast forward",
    "start": "1850480",
    "end": "1858159"
  },
  {
    "text": "I don't know if you can still see that well anyway this example is with Ray train but not with Ray tune I think the",
    "start": "1858159",
    "end": "1864360"
  },
  {
    "text": "only thing that we need to change with Ray tune is you need to figure out a way so like when Ray tune like fans out and",
    "start": "1864360",
    "end": "1870679"
  },
  {
    "text": "it's like going over all of its hyper parameters to do like its tuning you would need to make sure that like each one of those processes owns its own",
    "start": "1870679",
    "end": "1876600"
  },
  {
    "text": "handle to radar um to make sure that like each one of your separate processes is updating like the right thing um how",
    "start": "1876600",
    "end": "1884200"
  },
  {
    "text": "does Ray tune differentiate each process like under the the hood I don't I don't",
    "start": "1884200",
    "end": "1889840"
  },
  {
    "text": "either um I'm wondering if you have like access to like I don't know like a meaningful like string for each process",
    "start": "1889840",
    "end": "1895880"
  },
  {
    "text": "to be like this is this set of hyper parameters it's like and if you could then you could then it's reasonable to",
    "start": "1895880",
    "end": "1901120"
  },
  {
    "text": "like update us like the UI again with",
    "start": "1901120",
    "end": "1905519"
  },
  {
    "text": "like um I don't know that's a good question yeah example is dat Lo",
    "start": "1908639",
    "end": "1919360"
  },
  {
    "text": "um this very example is actually not it's like this weird actor level thing that I was poking around with we've used",
    "start": "1919399",
    "end": "1925559"
  },
  {
    "text": "Ray data too um and there's no reason why we couldn't like figure out latency through Ray data with the same tool like especially you have like a custom like",
    "start": "1925559",
    "end": "1931799"
  },
  {
    "text": "Ray data implementation like yeah I wrote this weird actor thing that",
    "start": "1931799",
    "end": "1937320"
  },
  {
    "text": "does a lot of stuff through S3 like it's yeah oh shoot I got to go thank you guys",
    "start": "1937320",
    "end": "1944440"
  },
  {
    "text": "appreciate it",
    "start": "1944440",
    "end": "1947799"
  }
]
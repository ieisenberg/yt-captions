[
  {
    "text": "uh hi I am Eric I'm speaking along with Richard today um we're here to tell you about Ray air",
    "start": "6600",
    "end": "11880"
  },
  {
    "text": "a scalable runtime for end-to-end ML applications that will be beta and Ray 2.0",
    "start": "11880",
    "end": "18960"
  },
  {
    "text": "um so first a bit about any skill uh any skill is a unified compute platform that makes it easy to develop deploy and",
    "start": "18960",
    "end": "24960"
  },
  {
    "text": "manage scalable AI python applications using Ray",
    "start": "24960",
    "end": "29960"
  },
  {
    "text": "um so where is this AI Pro AI runtime project coming from as a part of the ray",
    "start": "30720",
    "end": "36000"
  },
  {
    "text": "team we've worked with ML users and infra groups at leading companies such as Uber ant Shopify and so on over the",
    "start": "36000",
    "end": "43500"
  },
  {
    "text": "past several years and error is our effort to synthesize the Lessons Learned into a simple toolkit for the community",
    "start": "43500",
    "end": "50460"
  },
  {
    "text": "so kind of in a nutshell um air is uh built on Ray's existing scalable libraries it provides unified",
    "start": "50460",
    "end": "57300"
  },
  {
    "text": "apis for end-to-end machine learning and the goal is really to simplify ml infrastructure",
    "start": "57300",
    "end": "64339"
  },
  {
    "text": "so let me tell you about some of the challenges we've heard from our users about their ml infrastructure",
    "start": "64440",
    "end": "70680"
  },
  {
    "text": "a common theme is that it's still not easy to take ml from development to production at scale on the right you can",
    "start": "70680",
    "end": "78360"
  },
  {
    "text": "see an example of an everyday ml pipeline you do some pre-processing you're doing some training and then",
    "start": "78360",
    "end": "83880"
  },
  {
    "text": "you're doing inference on your model and even with this quite basic you know pattern you can see that we already have",
    "start": "83880",
    "end": "88979"
  },
  {
    "text": "two or three distributed systems and this can be adding a lot of operational",
    "start": "88979",
    "end": "94080"
  },
  {
    "text": "overheads a lot of development overhead statistics together on top of that the machine learning",
    "start": "94080",
    "end": "100320"
  },
  {
    "text": "field moves quite quickly so um infrastructure teams often have to",
    "start": "100320",
    "end": "105479"
  },
  {
    "text": "you know move their users through many migrations and the teams get like a little fatigued about having to migrate over time to catch up",
    "start": "105479",
    "end": "113720"
  },
  {
    "text": "so let's dig into this these problems a little bit more um there are really three main problems",
    "start": "114960",
    "end": "120060"
  },
  {
    "text": "at play and the root cause is kind of a scaling so scaling is hard especially if you're a data scientist and you really",
    "start": "120060",
    "end": "126000"
  },
  {
    "text": "want to focus on just machine learning uh platform Solutions of course are one way of addressing this problem",
    "start": "126000",
    "end": "132480"
  },
  {
    "text": "um but you know a purpose skilled platform can limit your flexibility as the field is rapidly changing",
    "start": "132480",
    "end": "137819"
  },
  {
    "text": "and um then you have kind of a catch-22 of course you can build your own but",
    "start": "137819",
    "end": "144120"
  },
  {
    "text": "um you know building and orchestrating distributed systems is from scratch to address new use cases is incredibly time",
    "start": "144120",
    "end": "150239"
  },
  {
    "text": "consuming and it's Out Of Reach of most organizations",
    "start": "150239",
    "end": "155000"
  },
  {
    "text": "so to understand um kind of the root cause of these problems more scaling that travel back into time to 2010.",
    "start": "155280",
    "end": "162239"
  },
  {
    "text": "um so back then we were all probably working you were all working on a single machine um data was just some files and you can",
    "start": "162239",
    "end": "168000"
  },
  {
    "text": "run uh you know ml script on your laptop and these problems were much much easier to tackle back then",
    "start": "168000",
    "end": "174920"
  },
  {
    "text": "with Ray and error we're trying to bring a similar experience to ml practitioners in today's landscape so today machine",
    "start": "175500",
    "end": "181080"
  },
  {
    "text": "learning is much more effective it's much more powerful which is really great but now there's a million different libraries and systems out there",
    "start": "181080",
    "end": "188819"
  },
  {
    "text": "so what our users really like about Ray is um the ability to build any kind of distributed machine learning pipeline or",
    "start": "188819",
    "end": "194879"
  },
  {
    "text": "application in just a single python script um using the you know Best in Class libraries from the ecosystem",
    "start": "194879",
    "end": "201840"
  },
  {
    "text": "for example you might leverage data libraries and ml libraries for pre-processing and training and other",
    "start": "201840",
    "end": "209040"
  },
  {
    "text": "libraries for for inference and and for serving",
    "start": "209040",
    "end": "213920"
  },
  {
    "text": "so um let's talk about Ray air uh air is a scalable toolkit for end-to-end ML",
    "start": "214620",
    "end": "222420"
  },
  {
    "text": "um uh errors built on rate core for open and",
    "start": "222420",
    "end": "228480"
  },
  {
    "text": "flexible ml compute end-to-end so Rey is really focusing on compute",
    "start": "228480",
    "end": "234120"
  },
  {
    "text": "just distributed compute so air leverages Integrations for things like storage and tracking",
    "start": "234120",
    "end": "241099"
  },
  {
    "text": "air also has high level libraries that make scaling easy for both data scientists and engineers",
    "start": "241200",
    "end": "246299"
  },
  {
    "text": "and what's new since Ray 1.0 um in the ray libraries is a unified API",
    "start": "246299",
    "end": "251519"
  },
  {
    "text": "so air libraries now work seamlessly with each other and they seamlessly integrate with the ecosystem by a common",
    "start": "251519",
    "end": "257160"
  },
  {
    "text": "integration points um it's actually this this scalable",
    "start": "257160",
    "end": "262919"
  },
  {
    "text": "Library layer is really important and this is why if you have non-scalable libraries there",
    "start": "262919",
    "end": "269100"
  },
  {
    "text": "can be a high friction handoff between development and going to production but if you have a scalable Library layer",
    "start": "269100",
    "end": "275940"
  },
  {
    "text": "you can use the same infrastructure the same code in both development and production improving productivity for",
    "start": "275940",
    "end": "281160"
  },
  {
    "text": "both data scientists and the platform engineers",
    "start": "281160",
    "end": "285380"
  },
  {
    "text": "finally air offers scalable integration with best debride libraries and ml Ops",
    "start": "286320",
    "end": "291419"
  },
  {
    "text": "tools this includes of course built-in Integrations for the most popular",
    "start": "291419",
    "end": "296880"
  },
  {
    "text": "Frameworks some of which Robert showed there are Developer apis to easily add",
    "start": "296880",
    "end": "303120"
  },
  {
    "text": "new Integrations and new Frameworks and finally since era is built on Ray you can also build custom scalable",
    "start": "303120",
    "end": "310020"
  },
  {
    "text": "components using Ray core directly so overall air is is really simplifying",
    "start": "310020",
    "end": "316800"
  },
  {
    "text": "scalable ml infrastructure scaling is made easy with with Ray since you can scale from dead to prod with the same",
    "start": "316800",
    "end": "322919"
  },
  {
    "text": "code air has a unified API for scalable Integrations which means you can choose your own best-in-class ecosystem",
    "start": "322919",
    "end": "329160"
  },
  {
    "text": "libraries and it and uh finally it's Error is capable of running",
    "start": "329160",
    "end": "337500"
  },
  {
    "text": "a diverse set of workloads so you can deal with one system Ray instead of managing many different systems",
    "start": "337500",
    "end": "344759"
  },
  {
    "text": "foreign would you use rare so probably the most common use case is",
    "start": "344759",
    "end": "351479"
  },
  {
    "text": "just using air to scale a single workload such as training or batch prediction and this means you don't need",
    "start": "351479",
    "end": "357060"
  },
  {
    "text": "to you know learn really about all the libraries and that rate offers just just the one that you're interested in",
    "start": "357060",
    "end": "363740"
  },
  {
    "text": "you can also build end-to-end scalable applications and error",
    "start": "363960",
    "end": "369380"
  },
  {
    "text": "air makes it easy to Plug and Play new tools from the ecosystem through simple apis like the the trainer API or the",
    "start": "370139",
    "end": "376020"
  },
  {
    "text": "tuner API um so I can use can be used to set up any kind of distributed training or",
    "start": "376020",
    "end": "381240"
  },
  {
    "text": "tuning job and finally um users are using Ray and air to build",
    "start": "381240",
    "end": "386280"
  },
  {
    "text": "custom ml platforms and we have a few talks on this later in the summit",
    "start": "386280",
    "end": "392699"
  },
  {
    "text": "so air is really it's really about for the entire ml Organization for data scientists it's enables simple",
    "start": "392699",
    "end": "398520"
  },
  {
    "text": "scalability of particular workloads or entire ml Pipelines for ML Engineers it provides the unified",
    "start": "398520",
    "end": "405300"
  },
  {
    "text": "platform abstractions that can be used to easily onboard and integrate necessary toolings so in short error is",
    "start": "405300",
    "end": "411780"
  },
  {
    "text": "a scalable and unified toolkit for for both roles",
    "start": "411780",
    "end": "416419"
  },
  {
    "text": "um you might be wondering when would you use Ray air this new library layer versus Ray core",
    "start": "418319",
    "end": "424800"
  },
  {
    "text": "um so the answer is like if you're a data scientist or animal engineer you probably want to start with error which",
    "start": "424800",
    "end": "430860"
  },
  {
    "text": "is um you know easy to get started with has a bunch of apis to interact with the ecosystem",
    "start": "430860",
    "end": "436080"
  },
  {
    "text": "but if you're if you're um you know pushing the bleeding edge you're building new things at hyperscale or",
    "start": "436080",
    "end": "441780"
  },
  {
    "text": "specialized use cases you might want to consider Ray core which provides more customizability and control because it's",
    "start": "441780",
    "end": "447539"
  },
  {
    "text": "a lower level layer but it's important to note that you can these work well together and you can use",
    "start": "447539",
    "end": "452580"
  },
  {
    "text": "one or or both that's that's okay so what comes out of the box",
    "start": "452580",
    "end": "459300"
  },
  {
    "text": "with air air has high level modules for data reprocessing training tuning batch",
    "start": "459300",
    "end": "465240"
  },
  {
    "text": "scripting prediction and serving um and I'm going to walk through just a",
    "start": "465240",
    "end": "470340"
  },
  {
    "text": "quick overview of all of these libraries so we have scalable data preparation and loading with Ray data so this is the",
    "start": "470340",
    "end": "476639"
  },
  {
    "text": "data set Library built specifically for machine learning let's use seamlessly to distributed data from megabyte scale to",
    "start": "476639",
    "end": "483060"
  },
  {
    "text": "you know terabyte scale and allows you to build a training training pipelines with this preprocessor abstraction",
    "start": "483060",
    "end": "489660"
  },
  {
    "text": "so you can kind of create a data set from data create a preprocessor and set",
    "start": "489660",
    "end": "495360"
  },
  {
    "text": "up a distributed training pipeline this leads to the raid train Library",
    "start": "495360",
    "end": "500580"
  },
  {
    "text": "which provides scalable model training so train is the single API to run the",
    "start": "500580",
    "end": "505919"
  },
  {
    "text": "most popular ml training Frameworks and offer seamless integration with the other other Ray libraries",
    "start": "505919",
    "end": "511259"
  },
  {
    "text": "for example you can easily create a torch trainer or extra boost trainer or hugging face trainer and so on and",
    "start": "511259",
    "end": "518839"
  },
  {
    "text": "these trainers integrate seamlessly with data sets and and with with tune",
    "start": "518839",
    "end": "525380"
  },
  {
    "text": "uh the tune Library provides scalable hyper parameter tuning so you can use it to run a hyper parameter Suite but",
    "start": "526140",
    "end": "532980"
  },
  {
    "text": "multiple concurrent training jobs it integrates with The Cutting Edge optimization algorithms from the open",
    "start": "532980",
    "end": "538800"
  },
  {
    "text": "source ecosystem and it provides fault tolerance for your experiments at skill so given an existing trainer such as",
    "start": "538800",
    "end": "545399"
  },
  {
    "text": "torch trainer or it could be just some other function it doesn't have to be you know trained you can create a tuner give",
    "start": "545399",
    "end": "551820"
  },
  {
    "text": "a pram space and then run that experiment with tuner.fit",
    "start": "551820",
    "end": "556820"
  },
  {
    "text": "air also includes a batch prediction utility batch predictor lets you execute inference on distributed data sets using",
    "start": "557700",
    "end": "564480"
  },
  {
    "text": "CPUs and gpus and you can bring your own model or you can load existing checkpoints from Train",
    "start": "564480",
    "end": "570980"
  },
  {
    "text": "here are a very simple example of creating a predictor from an XG boost model XC boost checkpoint",
    "start": "571140",
    "end": "577560"
  },
  {
    "text": "call predict on a rate data set I can write of course write the results back to storage",
    "start": "577560",
    "end": "584180"
  },
  {
    "text": "finally raise serve lets you deploy models as highly available inference Services array and you can also build",
    "start": "584459",
    "end": "591420"
  },
  {
    "text": "multi-model pipelines with with custom business logic with the serves new deployment graph feature",
    "start": "591420",
    "end": "598380"
  },
  {
    "text": "um and as usual this this integrates well with a lot of libraries you can load a checkpoint into into a sort of",
    "start": "598380",
    "end": "603899"
  },
  {
    "text": "deployment with just one line of code and deploy it and and start using it right away",
    "start": "603899",
    "end": "609740"
  },
  {
    "text": "so I I just want to recap what I walked through so far uh we talked about what air is it's a scalable toolkit for",
    "start": "610500",
    "end": "616380"
  },
  {
    "text": "end-to-end Mo applications it's built on rate core um uh it has a number of high-level",
    "start": "616380",
    "end": "622380"
  },
  {
    "text": "libraries and these libraries have really great Integrations with each other and with the ml ecosystem",
    "start": "622380",
    "end": "628680"
  },
  {
    "text": "we also talk about when you use Rey when you use Ray air for for scaling workloads",
    "start": "628680",
    "end": "634980"
  },
  {
    "text": "um and leveraging is Unified machine learning API and platforms finally talked about who airs four",
    "start": "634980",
    "end": "642480"
  },
  {
    "text": "errors for both data scientists and ml engineers um",
    "start": "642480",
    "end": "648120"
  },
  {
    "text": "yeah so next I'm going to hand it off to Richard we'll tell you a little bit more about how to use air diving in more",
    "start": "648120",
    "end": "654540"
  },
  {
    "text": "details of the code and and talking about user experiences",
    "start": "654540",
    "end": "658880"
  },
  {
    "text": "thanks Eric so hi I'm Richard I'm an engineering manager here on the open source team at any skill and I'd love to",
    "start": "662519",
    "end": "669360"
  },
  {
    "text": "welcome you to come dive with me into how you can use air in practice",
    "start": "669360",
    "end": "674459"
  },
  {
    "text": "so you might recall this slide from Eric's part of the talk there are four situations where you'll",
    "start": "674459",
    "end": "679920"
  },
  {
    "text": "be using Ray air you should be using rare and I'll be walking through concrete examples for each one of these",
    "start": "679920",
    "end": "684959"
  },
  {
    "text": "different use cases let's first walk through the example where you have a single Machinery work though that you want to scale",
    "start": "684959",
    "end": "691560"
  },
  {
    "text": "right so oftentimes you might already have an existing platform solution and you don't want to replace the entire",
    "start": "691560",
    "end": "697500"
  },
  {
    "text": "platform so Ray Air does not require you to rip out your existing end-to-end solution",
    "start": "697500",
    "end": "704120"
  },
  {
    "text": "error can be used in a piecemeal fashion so let's take an example where you would",
    "start": "704120",
    "end": "709320"
  },
  {
    "text": "use Ray air in the situation where you only want to replace the bash prediction stage of your pipeline",
    "start": "709320",
    "end": "716640"
  },
  {
    "text": "so in less than 20 lines of code I'm going to show on the screen here how you might do this with Ray air so first you",
    "start": "716640",
    "end": "723000"
  },
  {
    "text": "have here on the on the screen uh two lines of code and these two lines represent one a pre-trained model and",
    "start": "723000",
    "end": "729420"
  },
  {
    "text": "second it called storage URL so then what we can do in in just a",
    "start": "729420",
    "end": "735300"
  },
  {
    "text": "couple lines of code here is we can use Ray data to create a ray data set reading from this S3 bucket that we have",
    "start": "735300",
    "end": "742140"
  },
  {
    "text": "above we'll then create a python checkpoint from the model and this checkpoint is",
    "start": "742140",
    "end": "748620"
  },
  {
    "text": "then used to create a batch predictor object which we saw from a previous section on the talk by calling",
    "start": "748620",
    "end": "754700"
  },
  {
    "text": "predictor.predict uh you can call it and and do distributed inference on this data set automatically scaling out the",
    "start": "754700",
    "end": "761820"
  },
  {
    "text": "number of workers and also increasing the size of your cluster if you're on a cloud if necessary",
    "start": "761820",
    "end": "767700"
  },
  {
    "text": "and it's also not shown here but you can also configure this to use uh gpus for for batch prediction",
    "start": "767700",
    "end": "774120"
  },
  {
    "text": "and finally with with the simple simple API call you can write these outputs back to S3",
    "start": "774120",
    "end": "780779"
  },
  {
    "text": "so what we've demonstrated here is a really simple way of doing batch prediction uh and to run this in inside",
    "start": "780779",
    "end": "786839"
  },
  {
    "text": "a machine learning pipeline you might also want to add a couple other logic lines to to Startup or shut down your",
    "start": "786839",
    "end": "792600"
  },
  {
    "text": "cluster now on the other hand compared to other existing Solutions such as sagemaker Ray",
    "start": "792600",
    "end": "799019"
  },
  {
    "text": "air actually reduces a lot of unnecessary complexity so compared to rare you might have the",
    "start": "799019",
    "end": "805740"
  },
  {
    "text": "batch inference module from sagemaker requiring multiple steps for the user to get working such as creating the airflow",
    "start": "805740",
    "end": "811860"
  },
  {
    "text": "tag creating a Docker image testing things with like the ECR and and and",
    "start": "811860",
    "end": "817560"
  },
  {
    "text": "deciding all these other scalability parameters that that really aren't and it really are abstractive way if you use",
    "start": "817560",
    "end": "823620"
  },
  {
    "text": "Ray air so so again so the idea here is that like you can use Ray air in the",
    "start": "823620",
    "end": "828899"
  },
  {
    "text": "policeman fashion and even by using just a single part you can reduce the complexity significantly",
    "start": "828899",
    "end": "835940"
  },
  {
    "text": "so so that was the first use case how about let's walk through the Second Use case here which is scaling end-to-end Machinery applications right",
    "start": "835980",
    "end": "843360"
  },
  {
    "text": "um and so let's walk through an example of a ml pipeline you might want to scale",
    "start": "843360",
    "end": "848779"
  },
  {
    "text": "so um the takeaway here is that if you want to use these multiple way air components",
    "start": "848779",
    "end": "854959"
  },
  {
    "text": "you can actually do so in the very seamless intuitive interface using Ray",
    "start": "854959",
    "end": "860339"
  },
  {
    "text": "airs end-to-end apis so let's walk through this example with",
    "start": "860339",
    "end": "865560"
  },
  {
    "text": "the code on the screen right so first you have data processing so here we're loading a CSV uh file from from some",
    "start": "865560",
    "end": "872579"
  },
  {
    "text": "custom location like cloud storage or your hdfs cluster or something like that and uh you can generate a training",
    "start": "872579",
    "end": "880260"
  },
  {
    "text": "validation and test that using some of the area apis that we provide for distributed doing this in the",
    "start": "880260",
    "end": "885660"
  },
  {
    "text": "distributed fashion we then create a preprocessor which will be used to normalize a given column of",
    "start": "885660",
    "end": "891839"
  },
  {
    "text": "the data set for model training I'm going to take extra boost as an example but we also",
    "start": "891839",
    "end": "897600"
  },
  {
    "text": "support obviously the doing deep learning Frameworks um and such as hugging phase pythorage",
    "start": "897600",
    "end": "903000"
  },
  {
    "text": "tensorflow in this example I'm passing in the training and validation data set in",
    "start": "903000",
    "end": "908279"
  },
  {
    "text": "addition to the defined preprocessor and by calling trained trainer.fit we'll be",
    "start": "908279",
    "end": "914040"
  },
  {
    "text": "running the pre-processing uh on the training data set and taking that given preprocessor and then running distribute",
    "start": "914040",
    "end": "920699"
  },
  {
    "text": "actually boost on on the X on the data set and then calling into the validation",
    "start": "920699",
    "end": "925740"
  },
  {
    "text": "data set at a periodic frequency to to generate validation statistics",
    "start": "925740",
    "end": "931560"
  },
  {
    "text": "you can also pass in this trainer object into a tuner object just via the symbol",
    "start": "931560",
    "end": "936600"
  },
  {
    "text": "composition API now this is the new default API for Ray tune if you've been using retune before with this",
    "start": "936600",
    "end": "942660"
  },
  {
    "text": "class-based tuner object notice here that both the trainer and the tuner object can be both distributed",
    "start": "942660",
    "end": "950880"
  },
  {
    "text": "and finally we'll take that trained model checkpoint from the tuner and we'll pass it into a batch prediction",
    "start": "950880",
    "end": "956639"
  },
  {
    "text": "module that we've seen in this previous example so to further to further emphasize this",
    "start": "956639",
    "end": "964680"
  },
  {
    "text": "this is I really want to make sure that that we we get this across clearance that is actually very easy to scale rare",
    "start": "964680",
    "end": "970740"
  },
  {
    "text": "you just need to change one line uh parameters in various different components to increase the amount of",
    "start": "970740",
    "end": "976199"
  },
  {
    "text": "parallelism per per different component so here we have you know just like changing number workers for the trainer",
    "start": "976199",
    "end": "982680"
  },
  {
    "text": "will increase the size of the retraining job and then you can also simultaneously increase the number of parallelism uh",
    "start": "982680",
    "end": "989579"
  },
  {
    "text": "for for your tuning job so you can do a double scale out so here clearly in 20",
    "start": "989579",
    "end": "994620"
  },
  {
    "text": "lines of code we're able to do an end-to-end a scalable machine learning pipeline workload",
    "start": "994620",
    "end": "1001360"
  },
  {
    "text": "um so let's walk on to the next use case where we have a multiple different libraries or services that you want to",
    "start": "1002180",
    "end": "1008240"
  },
  {
    "text": "integrate with your machine learning platform and that the point here is that Ray area actually allows allows us to be",
    "start": "1008240",
    "end": "1013399"
  },
  {
    "text": "done really easily with with uh specific apis and Integrations become out of the box",
    "start": "1013399",
    "end": "1019220"
  },
  {
    "text": "right so if you're a machine learning or platform team you often want to support uh the latest and greatest tooling for",
    "start": "1019220",
    "end": "1024860"
  },
  {
    "text": "your machine learning engineers and your data scientists and this this is primarily because the the field moves so",
    "start": "1024860",
    "end": "1031220"
  },
  {
    "text": "quickly and you want to stay ahead of the curve and so Ray air actually comes with a large number of Integrations with",
    "start": "1031220",
    "end": "1037339"
  },
  {
    "text": "open source there's a bunch of different logos on this page but I think at the",
    "start": "1037339",
    "end": "1042438"
  },
  {
    "text": "very high level right we have Integrations with the data ecosystem such as like pandas or or Arrow right",
    "start": "1042439",
    "end": "1049580"
  },
  {
    "text": "there's Integrations with machine learning Frameworks actually boosts python Rich tensorflow hugging phase so",
    "start": "1049580",
    "end": "1054679"
  },
  {
    "text": "and so forth Integrations with optimization libraries such as optuna and hyperopt",
    "start": "1054679",
    "end": "1060799"
  },
  {
    "text": "and Integrations with with uh with model monitoring services and tracking",
    "start": "1060799",
    "end": "1066020"
  },
  {
    "text": "services such as arise such as waste and biases such as mlflow and finally",
    "start": "1066020",
    "end": "1072100"
  },
  {
    "text": "Integrations with with other models serving apis such as fast API",
    "start": "1072100",
    "end": "1078500"
  },
  {
    "text": "so so again there's a there's a ton of things that come out of the box already and we're going to be working towards more Integrations in the next release",
    "start": "1078500",
    "end": "1085660"
  },
  {
    "text": "but this is just to give you a flavor of how Ray air can sort of fit into your existing machine learning ecosystem that",
    "start": "1085660",
    "end": "1091760"
  },
  {
    "text": "you have within your organization but not that's not only it Ray air also",
    "start": "1091760",
    "end": "1097580"
  },
  {
    "text": "provides integration apis to plug in new machine learning ecosystem libraries this allows your team to be future proof",
    "start": "1097580",
    "end": "1104539"
  },
  {
    "text": "and avoid avoid migration fatigue as the ecosystem continues to evolve",
    "start": "1104539",
    "end": "1109820"
  },
  {
    "text": "so let's take example workflow that we've seen before multiple times already",
    "start": "1109820",
    "end": "1115039"
  },
  {
    "text": "now if you have a custom solution for a data storage with a raid data source integration you're going to be able to",
    "start": "1115039",
    "end": "1121760"
  },
  {
    "text": "implement an adapter to read and write now this is used in data processing used",
    "start": "1121760",
    "end": "1127220"
  },
  {
    "text": "in batch prediction and so on and so forth let's say there's a new hot machine learning training framework that's on",
    "start": "1127220",
    "end": "1133460"
  },
  {
    "text": "the block with a new uh with a ray train API with a data parallel trainer you're",
    "start": "1133460",
    "end": "1139460"
  },
  {
    "text": "able to easily integrate this new framework enable multi-gpu multi-node training and still integrate with the",
    "start": "1139460",
    "end": "1146179"
  },
  {
    "text": "rest of the ecosystems such as hyper parametering using preprocessors all within this trainer API",
    "start": "1146179",
    "end": "1153140"
  },
  {
    "text": "and finally if you there's a custom machine learning uh tracking system that",
    "start": "1153140",
    "end": "1158240"
  },
  {
    "text": "you have in in-house or some experiment registry or experiment tracking system you can use a callback with within both",
    "start": "1158240",
    "end": "1165380"
  },
  {
    "text": "the trainer and tuner interface which allows you to plug in your training metrics without needing to rewrite or re",
    "start": "1165380",
    "end": "1171799"
  },
  {
    "text": "refactor a large amount infrastructure so the goal here is to sort of emphasize",
    "start": "1171799",
    "end": "1177380"
  },
  {
    "text": "that Ray air allows your organization to be future proof and uh and especially",
    "start": "1177380",
    "end": "1182720"
  },
  {
    "text": "because it's open source uh there's all a lot of extensibility that we offer within uh within just like the",
    "start": "1182720",
    "end": "1188600"
  },
  {
    "text": "interfaces that we provide in great air um finally let's talk about when you",
    "start": "1188600",
    "end": "1194660"
  },
  {
    "text": "would use Ray air as part of a custom machine learning platform and specifically uh Ray air as the compute",
    "start": "1194660",
    "end": "1201380"
  },
  {
    "text": "core for this machine learning platform so at a later talking Summit Shopify is",
    "start": "1201380",
    "end": "1208100"
  },
  {
    "text": "a machine learning platform team we'll be talking about how they use the ray air libraries for multiple components",
    "start": "1208100",
    "end": "1214880"
  },
  {
    "text": "within their machine learning platform so we're talking about like pre-processing training batch inference",
    "start": "1214880",
    "end": "1220580"
  },
  {
    "text": "so on and so forth and this example is precisely what we foresee users to be building uh with Ray air right so Cruz",
    "start": "1220580",
    "end": "1228320"
  },
  {
    "text": "and Uber also will be talking about how they're using Ray within their machine learning platform as uh as the compute",
    "start": "1228320",
    "end": "1233480"
  },
  {
    "text": "core for for their infrastructure and what I want to emphasize here is that Ray air uh Ray and the libraries",
    "start": "1233480",
    "end": "1240440"
  },
  {
    "text": "and Ray air are just only a part of the Machining platform the platform actually includes many other components and we'll",
    "start": "1240440",
    "end": "1246080"
  },
  {
    "text": "dive into why they exist and what what's what's going to be missing so",
    "start": "1246080",
    "end": "1251900"
  },
  {
    "text": "um so just to build out sort of a mental model for for everyone here um you might start off with a simple Ray",
    "start": "1251900",
    "end": "1257600"
  },
  {
    "text": "air program which is just a python script that we showed before right and this python script it will basically",
    "start": "1257600",
    "end": "1264380"
  },
  {
    "text": "be the core for your platform if you decide to build your own you might have multiple users uh using",
    "start": "1264380",
    "end": "1270320"
  },
  {
    "text": "your platform so you're going to want to use some sort of cluster scheduling mechanism this can be on kubernetes with",
    "start": "1270320",
    "end": "1276140"
  },
  {
    "text": "their new kubray integration uh or even on any scale which provides managed array services and raid clusters",
    "start": "1276140",
    "end": "1283940"
  },
  {
    "text": "right and each of these programs will probably interact with a large number of other components uh as you saw like",
    "start": "1283940",
    "end": "1289880"
  },
  {
    "text": "array air programs are largely focused on compute but you also want to have things such as a feature store of the a",
    "start": "1289880",
    "end": "1296600"
  },
  {
    "text": "callus or experiment tracking system the mod registry so on and so forth or also you might want to have some some sort of",
    "start": "1296600",
    "end": "1303200"
  },
  {
    "text": "dedicated way for users to interact with the platform so you're going to need something like a notebook service or a",
    "start": "1303200",
    "end": "1308360"
  },
  {
    "text": "job scheduler these aren't part of Ray air but as previously mentioned Ray air",
    "start": "1308360",
    "end": "1313700"
  },
  {
    "text": "integrates with these systems and also provides the scalable compute there so that you can reduce the friction from",
    "start": "1313700",
    "end": "1318980"
  },
  {
    "text": "development to production so now we've covered how you can use rare let's talk about air itself",
    "start": "1318980",
    "end": "1326120"
  },
  {
    "text": "so with the current status Ray air is going to be released as beta in 2.0 which means that you are all encouraged",
    "start": "1326120",
    "end": "1332480"
  },
  {
    "text": "to try it out and let us know what sort of features requests or sort of pain points that you run into in future releases we really plan to uh",
    "start": "1332480",
    "end": "1340460"
  },
  {
    "text": "focus on both improving our integration story so providing out of box Integrations with data sources or future",
    "start": "1340460",
    "end": "1347299"
  },
  {
    "text": "storage and mod monitoring services and also improving the data intensive workloads in terms of scalability and",
    "start": "1347299",
    "end": "1354020"
  },
  {
    "text": "performance and reliability obviously this roadmap is uh currently fungible and and and flexible here so if",
    "start": "1354020",
    "end": "1360799"
  },
  {
    "text": "you have anything that you'd love to see in air or any sort of workload that you'd love to integrate or even contribute back to into air we'd love to",
    "start": "1360799",
    "end": "1367520"
  },
  {
    "text": "talk to you um so a little bit about some of the user experiences that we've been having",
    "start": "1367520",
    "end": "1373940"
  },
  {
    "text": "with uh Ray air especially during the alpha and prototyping stage",
    "start": "1373940",
    "end": "1378980"
  },
  {
    "text": "um we've had a couple users that are just really really excited about about Aaron just want to give us some testimonials here one data scientist has",
    "start": "1378980",
    "end": "1386539"
  },
  {
    "text": "mentioned that the productivity has felt like the has doubled um and can't wait until air is released",
    "start": "1386539",
    "end": "1392600"
  },
  {
    "text": "and they've been using the 90 build um which is you know like kind of scary for me but uh is is incredibly you know",
    "start": "1392600",
    "end": "1399620"
  },
  {
    "text": "exciting that someone is willing to sort uh take The Cutting Edge and bleeding edge there and just because they see",
    "start": "1399620",
    "end": "1405140"
  },
  {
    "text": "such a massive product that they boost from using rare another Machinery engineer at a local",
    "start": "1405140",
    "end": "1411020"
  },
  {
    "text": "startup uh has mentioned that they've been able to recreate uh data and just pipeline for training",
    "start": "1411020",
    "end": "1416480"
  },
  {
    "text": "um within two weeks even though they've built the previous solution over six months so what basically the takeaway",
    "start": "1416480",
    "end": "1422059"
  },
  {
    "text": "here is that Ray air is really going to provide I really do think a lot of users are going to get a massive product",
    "start": "1422059",
    "end": "1428020"
  },
  {
    "text": "productivity boost and machine learning teams are going to move much faster now that now that radiator is released",
    "start": "1428020",
    "end": "1435460"
  },
  {
    "text": "um so if you want to get involved if you're excited about rare as as much as you are as much as I am",
    "start": "1435620",
    "end": "1441440"
  },
  {
    "text": "um so you can chat with the developers on the race stack there's going to be our air dog fooding channel uh that that",
    "start": "1441440",
    "end": "1446900"
  },
  {
    "text": "you can you can take part in and sort of post questions or interact with the developers",
    "start": "1446900",
    "end": "1452360"
  },
  {
    "text": "um the entire team will be there and actively monitoring and answering questions well we'll be having many more meetups",
    "start": "1452360",
    "end": "1458000"
  },
  {
    "text": "uh after this race Summit so uh please come out to that we'll be trying to make this more of like a not just a San",
    "start": "1458000",
    "end": "1464419"
  },
  {
    "text": "Francisco thing but it's all across the world and then also you can come chat with chat with me or Eric uh at the race",
    "start": "1464419",
    "end": "1470480"
  },
  {
    "text": "Summit um so so that's it for a rare and really hope uh oh this gives a great overview",
    "start": "1470480",
    "end": "1477919"
  },
  {
    "text": "over the project and if you have any questions or have any sort of feature requests or or want to just share your",
    "start": "1477919",
    "end": "1483200"
  },
  {
    "text": "excitement uh just please come talk to me or and we will be happy to answer any questions at this point",
    "start": "1483200",
    "end": "1490240"
  },
  {
    "text": "[Applause]",
    "start": "1491850",
    "end": "1498200"
  },
  {
    "text": "I think Thomas has a mic so if anyone has any questions just raise your hand oh yeah there's one question right here",
    "start": "1502340",
    "end": "1509919"
  },
  {
    "text": "thank you um thanks Richard and Eric that was a really great presentation",
    "start": "1518840",
    "end": "1524240"
  },
  {
    "text": "um so I just was curious about like the differences between uh Ray data sets as it is offered today versus like Ray data",
    "start": "1524240",
    "end": "1531200"
  },
  {
    "text": "sets and how that would be offered for example in in uh Ray air so how would the API differ",
    "start": "1531200",
    "end": "1538340"
  },
  {
    "text": "um in terms of you know like um scaling Etc like what are some of the performance differences that we can",
    "start": "1538340",
    "end": "1544220"
  },
  {
    "text": "expect concretely yeah uh sure yeah so the question was how",
    "start": "1544220",
    "end": "1549559"
  },
  {
    "text": "does the data sets in the previous version already differ from data sets over there I think there's two things uh",
    "start": "1549559",
    "end": "1554960"
  },
  {
    "text": "first the data team and any scale has been pushing on the scalability of data sets so there'll be a talk later",
    "start": "1554960",
    "end": "1560779"
  },
  {
    "text": "um I think today on like you know a terabyte scale Shuffle with data sets and the second thing is integrating data",
    "start": "1560779",
    "end": "1568100"
  },
  {
    "text": "sets with with with the error apis so like we have a really good Integrations for batch inference and for the training",
    "start": "1568100",
    "end": "1574460"
  },
  {
    "text": "pipelines that it's not actually changing the data sets apis but it's just letting you easily pass the data",
    "start": "1574460",
    "end": "1580039"
  },
  {
    "text": "sets to you know torch trainer to batch inference and so on so it's about it's about Integrations yeah",
    "start": "1580039",
    "end": "1587259"
  },
  {
    "text": "can you keep your hand up if you have questions yeah",
    "start": "1593320",
    "end": "1598400"
  },
  {
    "text": "thank you for the great presentation um I have a question regarding the integration with ML Ops including kfp",
    "start": "1598400",
    "end": "1605539"
  },
  {
    "text": "um and also tfx how well are is Rey integrated with those and are people",
    "start": "1605539",
    "end": "1611480"
  },
  {
    "text": "using these Integrations currently thank you yeah so I can take that so",
    "start": "1611480",
    "end": "1617659"
  },
  {
    "text": "um right now like uh users don't necessarily use uh Ray Ray air with kfp",
    "start": "1617659",
    "end": "1624140"
  },
  {
    "text": "or with with tfx but rather use it alongside uh tfx and uh as for for kfp",
    "start": "1624140",
    "end": "1631100"
  },
  {
    "text": "uh users I think basically like we've we've been Alpha so for a bit of time so",
    "start": "1631100",
    "end": "1636919"
  },
  {
    "text": "we haven't heard that much usage with kfp uh but but if if we were to sort of architect it like one way of doing this",
    "start": "1636919",
    "end": "1643159"
  },
  {
    "text": "is running uh kfp as the orchestrator and then running Ray air uh workloads on",
    "start": "1643159",
    "end": "1648260"
  },
  {
    "text": "top um now that being said if if you don't need uh if you don't need a workflow orchestrator then you can simply just",
    "start": "1648260",
    "end": "1655100"
  },
  {
    "text": "have everything in a single program and you don't need to insert uh different sort of like container boxes in order to",
    "start": "1655100",
    "end": "1660620"
  },
  {
    "text": "to orchestrate like a like the workflow you can just have everything in a single python script",
    "start": "1660620",
    "end": "1666320"
  },
  {
    "text": "cool any other questions oh there's a couple hands over here please keep your",
    "start": "1666320",
    "end": "1671779"
  },
  {
    "text": "hand up so that Thomas can see you hi yes so thanks for the talk uh I was",
    "start": "1671779",
    "end": "1677539"
  },
  {
    "text": "wondering if you could uh mention any plans that you have or any functionality that you currently have around uh kind",
    "start": "1677539",
    "end": "1684260"
  },
  {
    "text": "of reproducibility so let's say uh you ran one of these scripts uh and you know",
    "start": "1684260",
    "end": "1689299"
  },
  {
    "text": "out came a model on the other side and uh you know a month later you wanted to go back and say oh how could I reproduce",
    "start": "1689299",
    "end": "1695779"
  },
  {
    "text": "that model again um do you have any functionality around like tracking of executions that would",
    "start": "1695779",
    "end": "1701120"
  },
  {
    "text": "allow you to uh you know go back and reproduce those sort of things that's a great question so I think right now the",
    "start": "1701120",
    "end": "1706700"
  },
  {
    "text": "story with regards to tracking every disability will be offloaded to some other systems such as ml flow or weights",
    "start": "1706700",
    "end": "1712279"
  },
  {
    "text": "and biases um at a very very high level I think Ray era doesn't necessarily want to",
    "start": "1712279",
    "end": "1717460"
  },
  {
    "text": "integrate with those uh sorry it doesn't want to sort of extend its own functionality to provide a tracking",
    "start": "1717460",
    "end": "1723860"
  },
  {
    "text": "service tracking services but rather integrate with these third-party ecosystem projects that are actually really really great projects though I",
    "start": "1723860",
    "end": "1730580"
  },
  {
    "text": "would say one thing is that like because everything is so so self-contained that that you can write because you can write",
    "start": "1730580",
    "end": "1735860"
  },
  {
    "text": "like these skillable pipelines and scalable workflows with Ray area as a single Python program it becomes much",
    "start": "1735860",
    "end": "1741919"
  },
  {
    "text": "easier to integrate into like uh say say GitHub without needing to sort of do like some crazy like you know",
    "start": "1741919",
    "end": "1748220"
  },
  {
    "text": "docker-based uh git uh like cicd sort of thing in order to enable reproducibility",
    "start": "1748220",
    "end": "1754460"
  },
  {
    "text": "does it make sense cool another question here",
    "start": "1754460",
    "end": "1760220"
  },
  {
    "text": "yeah so if I use the spark connector with Ray do I have to run a spark",
    "start": "1760220",
    "end": "1765740"
  },
  {
    "text": "cluster as well great question um so we have several ways of",
    "start": "1765740",
    "end": "1770960"
  },
  {
    "text": "interoperating with spark and um one one way is just you know you run a separate cluster spark writes to parquet and we",
    "start": "1770960",
    "end": "1778159"
  },
  {
    "text": "can read it you know load it for ammo so that's kind of like the basic way um there is a community project to run",
    "start": "1778159",
    "end": "1783440"
  },
  {
    "text": "spark directly within Ray just like you know run torch within Ray so we have some users are pretty happy with that",
    "start": "1783440",
    "end": "1789320"
  },
  {
    "text": "um so it's like basically a spark is like running within like reactors and then it's like you have there are some optimizations around the memory sharing",
    "start": "1789320",
    "end": "1796220"
  },
  {
    "text": "yeah the Project's called great DP so if you're interested you can definitely Google that and take a look",
    "start": "1796220",
    "end": "1802820"
  },
  {
    "text": "yeah one last question I would say maybe in the back",
    "start": "1802820",
    "end": "1807700"
  },
  {
    "text": "yeah you can there's a horrible trainer that's actually built out of the box and and maintained by the ray team so would",
    "start": "1813080",
    "end": "1818840"
  },
  {
    "text": "it have to be a ray cluster to use yeah yeah you would have to you'd run it on a",
    "start": "1818840",
    "end": "1824299"
  },
  {
    "text": "ray cluster but you would run the horrible communication protocol and the communication workers",
    "start": "1824299",
    "end": "1829520"
  },
  {
    "text": "um uh within uh on rare",
    "start": "1829520",
    "end": "1834399"
  },
  {
    "text": "any other questions",
    "start": "1839120",
    "end": "1842380"
  },
  {
    "text": "are there any plans to add profit to the list of model Integrations yeah so",
    "start": "1844940",
    "end": "1851659"
  },
  {
    "text": "that's that's actually a really good question so we've actually interacted with multiple users uh who are interested in in adding profit and other",
    "start": "1851659",
    "end": "1859220"
  },
  {
    "text": "time series uh libraries um I think that's something that will definitely uh that is like you know",
    "start": "1859220",
    "end": "1864860"
  },
  {
    "text": "somewhere on the roadmap but if you'd like to you know ask us to prioritize it you come talk to us I'd love to hear about your use case and sort of work",
    "start": "1864860",
    "end": "1871220"
  },
  {
    "text": "with you to sort of co-design the right apis uh you know in order to enable a lot",
    "start": "1871220",
    "end": "1877539"
  },
  {
    "text": "there's one more question over there or two more uh how do you manage uh versions and",
    "start": "1878779",
    "end": "1885679"
  },
  {
    "text": "Library dependencies versions that could be conflicting between different applications like yeah I could take that so um yeah",
    "start": "1885679",
    "end": "1893480"
  },
  {
    "text": "that's this is tying more to raise a story for dependency management so we have a concept of a runtime environment",
    "start": "1893480",
    "end": "1898760"
  },
  {
    "text": "in Ray which um it's kind of like saying for this job these are these are the dependencies",
    "start": "1898760",
    "end": "1904039"
  },
  {
    "text": "um of course there's always the you know the the environment dependencies in the cluster as a fallback",
    "start": "1904039",
    "end": "1910059"
  },
  {
    "text": "hey um I think one question was definitely about dependencies and the other one was",
    "start": "1916940",
    "end": "1922399"
  },
  {
    "text": "about um testing as in when we're rolling it out I didn't I haven't particularly heard anything concrete about like a b",
    "start": "1922399",
    "end": "1930140"
  },
  {
    "text": "testing hypothetically or how do we sort of when we're productionizing is that an air thing or is it really core thing I",
    "start": "1930140",
    "end": "1936740"
  },
  {
    "text": "guess yeah so so the question is about a b testing in the context of serving and I think Ray Ray serve has itself already",
    "start": "1936740",
    "end": "1942140"
  },
  {
    "text": "a really great uh a b testing support so I um there might be a talk about it and you can connect with a surf team there",
    "start": "1942140",
    "end": "1947779"
  },
  {
    "text": "yeah",
    "start": "1947779",
    "end": "1949960"
  },
  {
    "text": "I think that would probably be it cool thanks everyone thanks",
    "start": "1958460",
    "end": "1964000"
  }
]
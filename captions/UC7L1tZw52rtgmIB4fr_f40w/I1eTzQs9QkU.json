[
  {
    "text": "hey uh good afternoon",
    "start": "5120",
    "end": "7379"
  },
  {
    "text": "um Welcome to our talk so my name is",
    "start": "7379",
    "end": "10320"
  },
  {
    "text": "xinjiang joining me today is Raymond and",
    "start": "10320",
    "end": "13320"
  },
  {
    "text": "Choi my proficient colleagues from",
    "start": "13320",
    "end": "15839"
  },
  {
    "text": "Pinterest the machine learning platform",
    "start": "15839",
    "end": "17820"
  },
  {
    "text": "so today we will walk you through the",
    "start": "17820",
    "end": "20340"
  },
  {
    "text": "Journey about how we enable efficient",
    "start": "20340",
    "end": "23279"
  },
  {
    "text": "Last Mile data processing with Ray",
    "start": "23279",
    "end": "26279"
  },
  {
    "text": "so here is the agenda for today",
    "start": "26279",
    "end": "29519"
  },
  {
    "text": "and let's get started",
    "start": "29519",
    "end": "32398"
  },
  {
    "text": "so just give a quick overview about the",
    "start": "32399",
    "end": "35219"
  },
  {
    "text": "machine learning at Pinterest so you",
    "start": "35219",
    "end": "37500"
  },
  {
    "text": "might already know Pinterest mission is",
    "start": "37500",
    "end": "39360"
  },
  {
    "text": "to bring The Inspirations for everyone",
    "start": "39360",
    "end": "42180"
  },
  {
    "text": "to create the life they love",
    "start": "42180",
    "end": "44340"
  },
  {
    "text": "and when you can imagine like machine",
    "start": "44340",
    "end": "46620"
  },
  {
    "text": "learning plays a very critical role in",
    "start": "46620",
    "end": "49079"
  },
  {
    "text": "this mission it basically allowed us to",
    "start": "49079",
    "end": "52520"
  },
  {
    "text": "continuously deliver high quality",
    "start": "52520",
    "end": "54840"
  },
  {
    "text": "Inspirations for more than 460 million",
    "start": "54840",
    "end": "58980"
  },
  {
    "text": "monthly active users across the globe",
    "start": "58980",
    "end": "62820"
  },
  {
    "text": "behind the curtain there are hundreds of",
    "start": "62820",
    "end": "64799"
  },
  {
    "text": "machine learning Engineers working",
    "start": "64799",
    "end": "66299"
  },
  {
    "text": "really hard to building all kinds of ml",
    "start": "66299",
    "end": "68460"
  },
  {
    "text": "applications to power Pinterest",
    "start": "68460",
    "end": "71220"
  },
  {
    "text": "this just names a few",
    "start": "71220",
    "end": "73020"
  },
  {
    "text": "and to give a kind of the skill we",
    "start": "73020",
    "end": "76380"
  },
  {
    "text": "handling so our models are fairly",
    "start": "76380",
    "end": "78840"
  },
  {
    "text": "complicated we adopted many of the state",
    "start": "78840",
    "end": "81659"
  },
  {
    "text": "of the art model architecture such as",
    "start": "81659",
    "end": "84439"
  },
  {
    "text": "Transformer Dave cross Network",
    "start": "84439",
    "end": "87360"
  },
  {
    "text": "and our training that training data set",
    "start": "87360",
    "end": "89520"
  },
  {
    "text": "can range to multi petabytes",
    "start": "89520",
    "end": "92119"
  },
  {
    "text": "containing like tens of thousands of",
    "start": "92119",
    "end": "94560"
  },
  {
    "text": "features",
    "start": "94560",
    "end": "95640"
  },
  {
    "text": "every day there are about thousands of",
    "start": "95640",
    "end": "97860"
  },
  {
    "text": "training jobs running either to refresh",
    "start": "97860",
    "end": "100439"
  },
  {
    "text": "the model or our Engineers are trying",
    "start": "100439",
    "end": "102659"
  },
  {
    "text": "new ideas",
    "start": "102659",
    "end": "104040"
  },
  {
    "text": "and this number if you look at this",
    "start": "104040",
    "end": "105900"
  },
  {
    "text": "chart this number has been doubled since",
    "start": "105900",
    "end": "107520"
  },
  {
    "text": "last year",
    "start": "107520",
    "end": "108540"
  },
  {
    "text": "so with this continuous expression of",
    "start": "108540",
    "end": "111240"
  },
  {
    "text": "the training scale I think it's a really",
    "start": "111240",
    "end": "114420"
  },
  {
    "text": "good opportunity for us to level up our",
    "start": "114420",
    "end": "116640"
  },
  {
    "text": "motion learning platform",
    "start": "116640",
    "end": "118860"
  },
  {
    "text": "so the vision of machine learning",
    "start": "118860",
    "end": "120659"
  },
  {
    "text": "platform mainly come with two aspects",
    "start": "120659",
    "end": "123360"
  },
  {
    "text": "the first is to build the and improve",
    "start": "123360",
    "end": "125939"
  },
  {
    "text": "the very basic fundamental components",
    "start": "125939",
    "end": "130979"
  },
  {
    "text": "such as the feature store inference",
    "start": "130979",
    "end": "132959"
  },
  {
    "text": "Services training platform but more",
    "start": "132959",
    "end": "135480"
  },
  {
    "text": "importantly is to improve the that",
    "start": "135480",
    "end": "138540"
  },
  {
    "text": "velocity for our hundreds of ml",
    "start": "138540",
    "end": "140280"
  },
  {
    "text": "engineers so you might know like the",
    "start": "140280",
    "end": "142319"
  },
  {
    "text": "gpus are quite expensive and really hard",
    "start": "142319",
    "end": "144060"
  },
  {
    "text": "to get recently but we believe that",
    "start": "144060",
    "end": "146220"
  },
  {
    "text": "developers time is much more expensive",
    "start": "146220",
    "end": "148800"
  },
  {
    "text": "than GPU",
    "start": "148800",
    "end": "150120"
  },
  {
    "text": "that's why we are working really hard to",
    "start": "150120",
    "end": "152040"
  },
  {
    "text": "improve their productivity both in terms",
    "start": "152040",
    "end": "154140"
  },
  {
    "text": "of the calendar days meaning that new",
    "start": "154140",
    "end": "156420"
  },
  {
    "text": "models can launch much quicker and also",
    "start": "156420",
    "end": "159959"
  },
  {
    "text": "to reduce the engineer days where",
    "start": "159959",
    "end": "161879"
  },
  {
    "text": "Engineers can actually try out multiple",
    "start": "161879",
    "end": "163739"
  },
  {
    "text": "ideas at the same time",
    "start": "163739",
    "end": "165540"
  },
  {
    "text": "this leads to two important questions we",
    "start": "165540",
    "end": "167340"
  },
  {
    "text": "need to answer what are our Engineers",
    "start": "167340",
    "end": "169379"
  },
  {
    "text": "spending most of their time and the",
    "start": "169379",
    "end": "171120"
  },
  {
    "text": "whole can be improved",
    "start": "171120",
    "end": "173160"
  },
  {
    "text": "and we observed that our engineer mostly",
    "start": "173160",
    "end": "176519"
  },
  {
    "text": "on two parts so which we call First is",
    "start": "176519",
    "end": "178860"
  },
  {
    "text": "the model iteration",
    "start": "178860",
    "end": "180680"
  },
  {
    "text": "so tickling the model architecture try",
    "start": "180680",
    "end": "183599"
  },
  {
    "text": "out some new layers and although this",
    "start": "183599",
    "end": "187080"
  },
  {
    "text": "can bring a lot of great Improvement to",
    "start": "187080",
    "end": "189300"
  },
  {
    "text": "the model qualities we find that it's",
    "start": "189300",
    "end": "191459"
  },
  {
    "text": "not really the most time consuming part",
    "start": "191459",
    "end": "193260"
  },
  {
    "text": "why is that because with today like all",
    "start": "193260",
    "end": "196860"
  },
  {
    "text": "of the model architecture are pretty",
    "start": "196860",
    "end": "199080"
  },
  {
    "text": "standardized and with many of the common",
    "start": "199080",
    "end": "201420"
  },
  {
    "text": "building blocks like Transformers",
    "start": "201420",
    "end": "204239"
  },
  {
    "text": "and the modern GPU and the training",
    "start": "204239",
    "end": "206459"
  },
  {
    "text": "framework has significantly shortened",
    "start": "206459",
    "end": "208080"
  },
  {
    "text": "the time for engineers to build and the",
    "start": "208080",
    "end": "210300"
  },
  {
    "text": "training their job to training their",
    "start": "210300",
    "end": "211860"
  },
  {
    "text": "models uh take a look at this well-known",
    "start": "211860",
    "end": "214620"
  },
  {
    "text": "chart",
    "start": "214620",
    "end": "215519"
  },
  {
    "text": "um so you can see that the machine",
    "start": "215519",
    "end": "216900"
  },
  {
    "text": "learning model the machine learning code",
    "start": "216900",
    "end": "218340"
  },
  {
    "text": "is only account for very small fraction",
    "start": "218340",
    "end": "220080"
  },
  {
    "text": "of the time",
    "start": "220080",
    "end": "221340"
  },
  {
    "text": "uh what about the data iteration which",
    "start": "221340",
    "end": "223379"
  },
  {
    "text": "we kind of consider the other part of",
    "start": "223379",
    "end": "225480"
  },
  {
    "text": "the time splint",
    "start": "225480",
    "end": "227420"
  },
  {
    "text": "we find that putting together a right",
    "start": "227420",
    "end": "231299"
  },
  {
    "text": "set of data preparation can actually",
    "start": "231299",
    "end": "233580"
  },
  {
    "text": "achieve really good result as well",
    "start": "233580",
    "end": "235760"
  },
  {
    "text": "actually many of the biggest win we have",
    "start": "235760",
    "end": "238560"
  },
  {
    "text": "recently at Pinterest coming from this",
    "start": "238560",
    "end": "241319"
  },
  {
    "text": "uh putting this data set iterations",
    "start": "241319",
    "end": "244140"
  },
  {
    "text": "correct",
    "start": "244140",
    "end": "245400"
  },
  {
    "text": "but this also means our model Engineers",
    "start": "245400",
    "end": "248519"
  },
  {
    "text": "need to put a lot of time to iterating",
    "start": "248519",
    "end": "250739"
  },
  {
    "text": "to find out the the best combination of",
    "start": "250739",
    "end": "253680"
  },
  {
    "text": "different processing and we're fully",
    "start": "253680",
    "end": "255959"
  },
  {
    "text": "aware that the data set iteration is",
    "start": "255959",
    "end": "257880"
  },
  {
    "text": "super slow",
    "start": "257880",
    "end": "259220"
  },
  {
    "text": "at this skill",
    "start": "259220",
    "end": "261479"
  },
  {
    "text": "um so but for us at the platform we saw",
    "start": "261479",
    "end": "264840"
  },
  {
    "text": "this opportunity to optimize",
    "start": "264840",
    "end": "267300"
  },
  {
    "text": "so let's take a look at what exactly",
    "start": "267300",
    "end": "268860"
  },
  {
    "text": "slows down the data set iterations for",
    "start": "268860",
    "end": "271500"
  },
  {
    "text": "engineers",
    "start": "271500",
    "end": "273060"
  },
  {
    "text": "so we generally observe there's two",
    "start": "273060",
    "end": "274680"
  },
  {
    "text": "patterns where our Engineers to",
    "start": "274680",
    "end": "277320"
  },
  {
    "text": "iterating on the data set the first is",
    "start": "277320",
    "end": "279360"
  },
  {
    "text": "the using as the first is most commonly",
    "start": "279360",
    "end": "281460"
  },
  {
    "text": "used one is to just writing spark jobs",
    "start": "281460",
    "end": "284100"
  },
  {
    "text": "and with workflows so what it does is",
    "start": "284100",
    "end": "286919"
  },
  {
    "text": "like Engineers start to composing their",
    "start": "286919",
    "end": "288960"
  },
  {
    "text": "data processing logic in spark job their",
    "start": "288960",
    "end": "292500"
  },
  {
    "text": "training logic in pytorch and then they",
    "start": "292500",
    "end": "295259"
  },
  {
    "text": "Bridge all the stages of data processing",
    "start": "295259",
    "end": "297419"
  },
  {
    "text": "and the trainings into a workflow",
    "start": "297419",
    "end": "299639"
  },
  {
    "text": "spinner for example I mean airflow sorry",
    "start": "299639",
    "end": "303419"
  },
  {
    "text": "um",
    "start": "303419",
    "end": "304259"
  },
  {
    "text": "this approach brings us a lot of",
    "start": "304259",
    "end": "306419"
  },
  {
    "text": "benefits so we get we can easily skin",
    "start": "306419",
    "end": "308759"
  },
  {
    "text": "out scale up the data processing with",
    "start": "308759",
    "end": "311340"
  },
  {
    "text": "spark",
    "start": "311340",
    "end": "312240"
  },
  {
    "text": "and the workflows can be templatized for",
    "start": "312240",
    "end": "315479"
  },
  {
    "text": "better usability some of the common data",
    "start": "315479",
    "end": "317699"
  },
  {
    "text": "processing modules we can extract it",
    "start": "317699",
    "end": "319800"
  },
  {
    "text": "away so different people can actually",
    "start": "319800",
    "end": "321180"
  },
  {
    "text": "reuse those modules",
    "start": "321180",
    "end": "322919"
  },
  {
    "text": "this also provides a really good",
    "start": "322919",
    "end": "324720"
  },
  {
    "text": "reproducibility so each model is",
    "start": "324720",
    "end": "326520"
  },
  {
    "text": "essentially determined by some",
    "start": "326520",
    "end": "328560"
  },
  {
    "text": "configurations plus template",
    "start": "328560",
    "end": "332280"
  },
  {
    "text": "however this comes with its own",
    "start": "332280",
    "end": "334199"
  },
  {
    "text": "challenge as well so first is like",
    "start": "334199",
    "end": "336479"
  },
  {
    "text": "Engineers need to jumping around",
    "start": "336479",
    "end": "338820"
  },
  {
    "text": "multiple Frameworks to just setting up",
    "start": "338820",
    "end": "341400"
  },
  {
    "text": "even a very very basic data for data",
    "start": "341400",
    "end": "345180"
  },
  {
    "text": "transformations",
    "start": "345180",
    "end": "346380"
  },
  {
    "text": "so this means the high engineer they",
    "start": "346380",
    "end": "348300"
  },
  {
    "text": "cost",
    "start": "348300",
    "end": "349880"
  },
  {
    "text": "but also it also comes with very high",
    "start": "349880",
    "end": "353160"
  },
  {
    "text": "calendar day cost that's because the",
    "start": "353160",
    "end": "355680"
  },
  {
    "text": "each of the batch jobs has to process",
    "start": "355680",
    "end": "357960"
  },
  {
    "text": "the full data sets so it's a making the",
    "start": "357960",
    "end": "360960"
  },
  {
    "text": "feedback loop very long and some of the",
    "start": "360960",
    "end": "364520"
  },
  {
    "text": "bugs for example in the very early stage",
    "start": "364520",
    "end": "367020"
  },
  {
    "text": "can only be fined until very late",
    "start": "367020",
    "end": "371100"
  },
  {
    "text": "and our very smart Engineers start to",
    "start": "371100",
    "end": "373620"
  },
  {
    "text": "explore if there's other way so they",
    "start": "373620",
    "end": "377160"
  },
  {
    "text": "start to moving the data processing into",
    "start": "377160",
    "end": "379259"
  },
  {
    "text": "the trainer",
    "start": "379259",
    "end": "380699"
  },
  {
    "text": "for example in pi torch you can actually",
    "start": "380699",
    "end": "382979"
  },
  {
    "text": "specify some transforms inside the data",
    "start": "382979",
    "end": "385919"
  },
  {
    "text": "loader workers before sending the rows",
    "start": "385919",
    "end": "387960"
  },
  {
    "text": "to the trainer Loop this is what we call",
    "start": "387960",
    "end": "390660"
  },
  {
    "text": "the last mile data processing because",
    "start": "390660",
    "end": "392460"
  },
  {
    "text": "the data is right before entering the",
    "start": "392460",
    "end": "394560"
  },
  {
    "text": "training Loop",
    "start": "394560",
    "end": "395819"
  },
  {
    "text": "this turns out to be pretty great",
    "start": "395819",
    "end": "397199"
  },
  {
    "text": "because user can actually specify all",
    "start": "397199",
    "end": "399600"
  },
  {
    "text": "the logic in one framework pytorch for",
    "start": "399600",
    "end": "402000"
  },
  {
    "text": "example and make the iteration really",
    "start": "402000",
    "end": "404520"
  },
  {
    "text": "easy and fast it also streamlines the",
    "start": "404520",
    "end": "407520"
  },
  {
    "text": "pipelines that the feedback loop is",
    "start": "407520",
    "end": "409500"
  },
  {
    "text": "immediate so you can quickly know what",
    "start": "409500",
    "end": "411120"
  },
  {
    "text": "what went wrong and then it's really on",
    "start": "411120",
    "end": "413160"
  },
  {
    "text": "top of that this has greatly reduced the",
    "start": "413160",
    "end": "415500"
  },
  {
    "text": "time for our Engineers to like building",
    "start": "415500",
    "end": "418259"
  },
  {
    "text": "and the fixing their mod their model",
    "start": "418259",
    "end": "420720"
  },
  {
    "text": "training",
    "start": "420720",
    "end": "422160"
  },
  {
    "text": "but this also comes with its own",
    "start": "422160",
    "end": "423840"
  },
  {
    "text": "challenge",
    "start": "423840",
    "end": "424699"
  },
  {
    "text": "mostly around the scalability so",
    "start": "424699",
    "end": "427259"
  },
  {
    "text": "basically you cannot scanning up your",
    "start": "427259",
    "end": "428940"
  },
  {
    "text": "data processing beyond the single",
    "start": "428940",
    "end": "430319"
  },
  {
    "text": "machine",
    "start": "430319",
    "end": "431520"
  },
  {
    "text": "and what makes things worse is like if",
    "start": "431520",
    "end": "434039"
  },
  {
    "text": "you put in more data processing workload",
    "start": "434039",
    "end": "436620"
  },
  {
    "text": "on the data loaders you will quickly",
    "start": "436620",
    "end": "439440"
  },
  {
    "text": "observe that the CP utilizations",
    "start": "439440",
    "end": "441060"
  },
  {
    "text": "increase much faster than GP utilization",
    "start": "441060",
    "end": "443220"
  },
  {
    "text": "causing the GPU to be underutilized",
    "start": "443220",
    "end": "446520"
  },
  {
    "text": "take a look at this recent experiment we",
    "start": "446520",
    "end": "449759"
  },
  {
    "text": "did you can see we're gradually adding",
    "start": "449759",
    "end": "451860"
  },
  {
    "text": "more data processing on the data loader",
    "start": "451860",
    "end": "454560"
  },
  {
    "text": "and the Chinese rope will drop",
    "start": "454560",
    "end": "456300"
  },
  {
    "text": "significantly which result in much",
    "start": "456300",
    "end": "458699"
  },
  {
    "text": "longer training time",
    "start": "458699",
    "end": "461280"
  },
  {
    "text": "so in their way we can find a solution",
    "start": "461280",
    "end": "464400"
  },
  {
    "text": "to horizontally scaling up the data",
    "start": "464400",
    "end": "467039"
  },
  {
    "text": "processing The Last Mile data processing",
    "start": "467039",
    "end": "468840"
  },
  {
    "text": "uh we imagine ideal solution will meet",
    "start": "468840",
    "end": "472500"
  },
  {
    "text": "all these three requirements so first it",
    "start": "472500",
    "end": "475199"
  },
  {
    "text": "should be able to efficiently scheduling",
    "start": "475199",
    "end": "477180"
  },
  {
    "text": "a large-scale data processing across",
    "start": "477180",
    "end": "480060"
  },
  {
    "text": "multiple nodes not only a single",
    "start": "480060",
    "end": "481800"
  },
  {
    "text": "training node it should be able to",
    "start": "481800",
    "end": "484380"
  },
  {
    "text": "heterogeneously manage the resource so",
    "start": "484380",
    "end": "487560"
  },
  {
    "text": "both GPU and the CPU ensuring the",
    "start": "487560",
    "end": "490620"
  },
  {
    "text": "workload can be scheduled on the most",
    "start": "490620",
    "end": "492060"
  },
  {
    "text": "efficient Hardwares and hopefully",
    "start": "492060",
    "end": "494160"
  },
  {
    "text": "everything can be done with infant",
    "start": "494160",
    "end": "495479"
  },
  {
    "text": "framework so that we can still have the",
    "start": "495479",
    "end": "497039"
  },
  {
    "text": "high velocity that velocity",
    "start": "497039",
    "end": "499860"
  },
  {
    "text": "so turns out",
    "start": "499860",
    "end": "501900"
  },
  {
    "text": "um it's we are really excited to find",
    "start": "501900",
    "end": "504539"
  },
  {
    "text": "that real fulfill all this requirements",
    "start": "504539",
    "end": "506580"
  },
  {
    "text": "in addition it presents a very unique",
    "start": "506580",
    "end": "509699"
  },
  {
    "text": "opportunities for us to provide a unique",
    "start": "509699",
    "end": "512159"
  },
  {
    "text": "AI runtime for all the ml offs",
    "start": "512159",
    "end": "514680"
  },
  {
    "text": "components",
    "start": "514680",
    "end": "515880"
  },
  {
    "text": "so take a look at the words after the",
    "start": "515880",
    "end": "517800"
  },
  {
    "text": "interviewing with Ray so you can see",
    "start": "517800",
    "end": "519240"
  },
  {
    "text": "many of the data Transformations have",
    "start": "519240",
    "end": "521640"
  },
  {
    "text": "now expressed as it re-transforms so",
    "start": "521640",
    "end": "524899"
  },
  {
    "text": "next I will hand over to Raymond to talk",
    "start": "524899",
    "end": "527820"
  },
  {
    "text": "about how we actually integrate array",
    "start": "527820",
    "end": "529560"
  },
  {
    "text": "into our training stack",
    "start": "529560",
    "end": "533000"
  },
  {
    "text": "foreign",
    "start": "533220",
    "end": "535459"
  },
  {
    "text": "I'm Raymond and I'm going to continue",
    "start": "539420",
    "end": "542700"
  },
  {
    "text": "talking about how we integrate great",
    "start": "542700",
    "end": "544500"
  },
  {
    "text": "data which is a data processing",
    "start": "544500",
    "end": "546899"
  },
  {
    "text": "libraries built on top of three to our",
    "start": "546899",
    "end": "549360"
  },
  {
    "text": "email machine learning training",
    "start": "549360",
    "end": "551100"
  },
  {
    "text": "Frameworks and the case study on one of",
    "start": "551100",
    "end": "553980"
  },
  {
    "text": "our critical recommendation models",
    "start": "553980",
    "end": "556680"
  },
  {
    "text": "so before we talk about the detail of",
    "start": "556680",
    "end": "559320"
  },
  {
    "text": "the Integrations let's give a background",
    "start": "559320",
    "end": "561240"
  },
  {
    "text": "of how ml is done in Pinterest in",
    "start": "561240",
    "end": "564120"
  },
  {
    "text": "Pinterest we have a unified pytorch",
    "start": "564120",
    "end": "566820"
  },
  {
    "text": "based machine learning Frameworks aimed",
    "start": "566820",
    "end": "569160"
  },
  {
    "text": "to minimize the repeated effort of",
    "start": "569160",
    "end": "570839"
  },
  {
    "text": "building common ml infrastructures so it",
    "start": "570839",
    "end": "574080"
  },
  {
    "text": "provides standardized CI CDs ml ml",
    "start": "574080",
    "end": "578220"
  },
  {
    "text": "specific Docker image standardized ml",
    "start": "578220",
    "end": "580980"
  },
  {
    "text": "Ops Integrations and then also reusable",
    "start": "580980",
    "end": "583500"
  },
  {
    "text": "ml building blocks to accelerate",
    "start": "583500",
    "end": "586440"
  },
  {
    "text": "people's experimentations",
    "start": "586440",
    "end": "588300"
  },
  {
    "text": "currently 95 of the training jobs are",
    "start": "588300",
    "end": "590760"
  },
  {
    "text": "running and building with these",
    "start": "590760",
    "end": "592440"
  },
  {
    "text": "Frameworks and then if you are",
    "start": "592440",
    "end": "594420"
  },
  {
    "text": "interested into how we unify ml in",
    "start": "594420",
    "end": "597000"
  },
  {
    "text": "Pinterest please CL blog posts for",
    "start": "597000",
    "end": "598740"
  },
  {
    "text": "further details",
    "start": "598740",
    "end": "601459"
  },
  {
    "text": "so after knowing the background let's",
    "start": "601640",
    "end": "604140"
  },
  {
    "text": "talk starting taking a look taking a",
    "start": "604140",
    "end": "606180"
  },
  {
    "text": "look at how we integrate rain so we",
    "start": "606180",
    "end": "608220"
  },
  {
    "text": "actually took several iterations to",
    "start": "608220",
    "end": "609839"
  },
  {
    "text": "finalize the architectures the first one",
    "start": "609839",
    "end": "612300"
  },
  {
    "text": "the first iteration and to minimize the",
    "start": "612300",
    "end": "614820"
  },
  {
    "text": "amount of efforts for our users and",
    "start": "614820",
    "end": "617580"
  },
  {
    "text": "integrated as a library extensions",
    "start": "617580",
    "end": "620160"
  },
  {
    "text": "so in the setup training job or launch",
    "start": "620160",
    "end": "622620"
  },
  {
    "text": "as usuals in the pure GPU clusters but",
    "start": "622620",
    "end": "625560"
  },
  {
    "text": "in addition to it we say that a separate",
    "start": "625560",
    "end": "627420"
  },
  {
    "text": "CPU rate clusters to handle data",
    "start": "627420",
    "end": "629339"
  },
  {
    "text": "processing workloads",
    "start": "629339",
    "end": "630839"
  },
  {
    "text": "so in this setup each of the GPU worker",
    "start": "630839",
    "end": "633959"
  },
  {
    "text": "here are also become an individual rate",
    "start": "633959",
    "end": "635700"
  },
  {
    "text": "drivers which can initialize free data",
    "start": "635700",
    "end": "638940"
  },
  {
    "text": "set to process data in the CPU clusters",
    "start": "638940",
    "end": "641220"
  },
  {
    "text": "and then streaming back to uh for",
    "start": "641220",
    "end": "643560"
  },
  {
    "text": "training compute",
    "start": "643560",
    "end": "646399"
  },
  {
    "text": "so we quickly realized this approach of",
    "start": "646560",
    "end": "648959"
  },
  {
    "text": "its pros and cons right so first of all",
    "start": "648959",
    "end": "651120"
  },
  {
    "text": "it minimizes the upside stem in like the",
    "start": "651120",
    "end": "653820"
  },
  {
    "text": "code change that required by our ml",
    "start": "653820",
    "end": "655800"
  },
  {
    "text": "users because users simply need to swap",
    "start": "655800",
    "end": "658500"
  },
  {
    "text": "out one API to the one that we built on",
    "start": "658500",
    "end": "661019"
  },
  {
    "text": "top of without changing the other part",
    "start": "661019",
    "end": "663000"
  },
  {
    "text": "of the code or how they launch the jobs",
    "start": "663000",
    "end": "664740"
  },
  {
    "text": "but the downside is that it complicates",
    "start": "664740",
    "end": "668160"
  },
  {
    "text": "our infrastructure setups for examples",
    "start": "668160",
    "end": "670740"
  },
  {
    "text": "one jobs now have to maintain multiple",
    "start": "670740",
    "end": "673079"
  },
  {
    "text": "drivers and data sets versus for single",
    "start": "673079",
    "end": "675660"
  },
  {
    "text": "jobs and then we also have to carefully",
    "start": "675660",
    "end": "678360"
  },
  {
    "text": "spin up and tear down the two clusters",
    "start": "678360",
    "end": "680339"
  },
  {
    "text": "in order for the job to run properties",
    "start": "680339",
    "end": "682760"
  },
  {
    "text": "the second reason but the most important",
    "start": "682760",
    "end": "685380"
  },
  {
    "text": "one is the the way we integrate Ray has",
    "start": "685380",
    "end": "688620"
  },
  {
    "text": "limited the features you can provide",
    "start": "688620",
    "end": "690660"
  },
  {
    "text": "Ray actually it's a more powerful",
    "start": "690660",
    "end": "692820"
  },
  {
    "text": "Frameworks they provide a lot more ml ml",
    "start": "692820",
    "end": "695339"
  },
  {
    "text": "Ops no more more than raid datas",
    "start": "695339",
    "end": "698880"
  },
  {
    "text": "um but in this approach we only",
    "start": "698880",
    "end": "700440"
  },
  {
    "text": "integrate redidize the library to our ml",
    "start": "700440",
    "end": "702480"
  },
  {
    "text": "Frameworks but other things like Ray",
    "start": "702480",
    "end": "704519"
  },
  {
    "text": "Trends ratings for hyper parameter",
    "start": "704519",
    "end": "706500"
  },
  {
    "text": "tunings it's not immediately available",
    "start": "706500",
    "end": "708360"
  },
  {
    "text": "to us",
    "start": "708360",
    "end": "710640"
  },
  {
    "text": "so with all the learning we move on to",
    "start": "710640",
    "end": "712440"
  },
  {
    "text": "the next iterations which which aim to",
    "start": "712440",
    "end": "715380"
  },
  {
    "text": "use rate as a unified framework to host",
    "start": "715380",
    "end": "717660"
  },
  {
    "text": "all of the email workloads and then our",
    "start": "717660",
    "end": "720420"
  },
  {
    "text": "machine learning framework just become",
    "start": "720420",
    "end": "721980"
  },
  {
    "text": "the extension to the radio ecosystems",
    "start": "721980",
    "end": "724380"
  },
  {
    "text": "and they set up a single heterogeneous",
    "start": "724380",
    "end": "726600"
  },
  {
    "text": "three clusters will be launched to",
    "start": "726600",
    "end": "728519"
  },
  {
    "text": "manage a mixture of CPU and GPU resource",
    "start": "728519",
    "end": "730740"
  },
  {
    "text": "and then this will also be used to run",
    "start": "730740",
    "end": "732899"
  },
  {
    "text": "both data processing and trainings",
    "start": "732899",
    "end": "735660"
  },
  {
    "text": "we also have to revamp our trainer",
    "start": "735660",
    "end": "739079"
  },
  {
    "text": "launchers to use rate native Concepts",
    "start": "739079",
    "end": "741420"
  },
  {
    "text": "like actors in order to orchestrate the",
    "start": "741420",
    "end": "743279"
  },
  {
    "text": "GPU or training process inside the ring",
    "start": "743279",
    "end": "746579"
  },
  {
    "text": "clusters",
    "start": "746579",
    "end": "748380"
  },
  {
    "text": "now we have the training directory",
    "start": "748380",
    "end": "750959"
  },
  {
    "text": "running the rate cluster we can also",
    "start": "750959",
    "end": "752459"
  },
  {
    "text": "have a global Ray data set pipeline",
    "start": "752459",
    "end": "755040"
  },
  {
    "text": "um statistical in the CPU workloads",
    "start": "755040",
    "end": "757800"
  },
  {
    "text": "inside every clusters the CPU resource",
    "start": "757800",
    "end": "760560"
  },
  {
    "text": "of request anime and then be jointly",
    "start": "760560",
    "end": "762779"
  },
  {
    "text": "concerned by all the GPU workers that",
    "start": "762779",
    "end": "765959"
  },
  {
    "text": "have been launched",
    "start": "765959",
    "end": "767459"
  },
  {
    "text": "this moved us to closer to how rain",
    "start": "767459",
    "end": "770639"
  },
  {
    "text": "natively tackle machine learning",
    "start": "770639",
    "end": "772019"
  },
  {
    "text": "trainings and position our ml Platforms",
    "start": "772019",
    "end": "774600"
  },
  {
    "text": "in Pinterest as a SDK provider today",
    "start": "774600",
    "end": "778880"
  },
  {
    "text": "so let's take a look how the user",
    "start": "779339",
    "end": "781680"
  },
  {
    "text": "experience looks like so the data",
    "start": "781680",
    "end": "784620"
  },
  {
    "text": "transformation here can be defined as a",
    "start": "784620",
    "end": "786360"
  },
  {
    "text": "simple python functions and apply to Ray",
    "start": "786360",
    "end": "788639"
  },
  {
    "text": "data set with a simple map batch of",
    "start": "788639",
    "end": "790980"
  },
  {
    "text": "functions call",
    "start": "790980",
    "end": "792500"
  },
  {
    "text": "GPU training can now be launched with a",
    "start": "792500",
    "end": "795839"
  },
  {
    "text": "simple API provided by us and consume",
    "start": "795839",
    "end": "798300"
  },
  {
    "text": "the data from the red data set as shown",
    "start": "798300",
    "end": "800160"
  },
  {
    "text": "here's and then once this application is",
    "start": "800160",
    "end": "802920"
  },
  {
    "text": "running this will be on this application",
    "start": "802920",
    "end": "805260"
  },
  {
    "text": "will be distributed as a pipeline like",
    "start": "805260",
    "end": "806940"
  },
  {
    "text": "below where data can string all the way",
    "start": "806940",
    "end": "809040"
  },
  {
    "text": "from the re-stage to the trainer for",
    "start": "809040",
    "end": "813019"
  },
  {
    "text": "training computes",
    "start": "813019",
    "end": "815220"
  },
  {
    "text": "and then more first this data inspection",
    "start": "815220",
    "end": "817800"
  },
  {
    "text": "API provided by radiator natively",
    "start": "817800",
    "end": "820639"
  },
  {
    "text": "making the developing very easy this",
    "start": "820639",
    "end": "823380"
  },
  {
    "text": "means that no more workflow kickoff and",
    "start": "823380",
    "end": "826079"
  },
  {
    "text": "manually construct the table to offer",
    "start": "826079",
    "end": "828660"
  },
  {
    "text": "data validations over and over again",
    "start": "828660",
    "end": "830700"
  },
  {
    "text": "everything can be done just in Ray",
    "start": "830700",
    "end": "834680"
  },
  {
    "text": "so besides the general architectures we",
    "start": "834899",
    "end": "837839"
  },
  {
    "text": "also spend a good amount of time",
    "start": "837839",
    "end": "839279"
  },
  {
    "text": "optimize the performance one of the",
    "start": "839279",
    "end": "841860"
  },
  {
    "text": "biggest breakthrough we see in Ray data",
    "start": "841860",
    "end": "843839"
  },
  {
    "text": "is it's showing executions",
    "start": "843839",
    "end": "845940"
  },
  {
    "text": "this is some features we've been asking",
    "start": "845940",
    "end": "848399"
  },
  {
    "text": "through our journeys of the exploring",
    "start": "848399",
    "end": "850139"
  },
  {
    "text": "Rey and it is finally out in Ray 2.3",
    "start": "850139",
    "end": "854060"
  },
  {
    "text": "with this streaming execution it enable",
    "start": "854060",
    "end": "857040"
  },
  {
    "text": "concurrent executions of different data",
    "start": "857040",
    "end": "859380"
  },
  {
    "text": "set stage and eliminate the needs of",
    "start": "859380",
    "end": "861720"
  },
  {
    "text": "loading the entire DSA into memories it",
    "start": "861720",
    "end": "865079"
  },
  {
    "text": "really is uh the approach to lower the",
    "start": "865079",
    "end": "867959"
  },
  {
    "text": "resource requirement for large data set",
    "start": "867959",
    "end": "869820"
  },
  {
    "text": "ingestions and make trainings of um",
    "start": "869820",
    "end": "872820"
  },
  {
    "text": "better by scale data set possible",
    "start": "872820",
    "end": "875160"
  },
  {
    "text": "for the mores with streaming executions",
    "start": "875160",
    "end": "877320"
  },
  {
    "text": "email Engineers can now receive",
    "start": "877320",
    "end": "879420"
  },
  {
    "text": "immediate and end-to-end feedbacks as",
    "start": "879420",
    "end": "882180"
  },
  {
    "text": "soon as the First Data block being",
    "start": "882180",
    "end": "883800"
  },
  {
    "text": "ingested",
    "start": "883800",
    "end": "886339"
  },
  {
    "text": "the other performance aspect we are",
    "start": "887399",
    "end": "889440"
  },
  {
    "text": "focusing on in is the data movement part",
    "start": "889440",
    "end": "891779"
  },
  {
    "text": "data movement referred to the operations",
    "start": "891779",
    "end": "894180"
  },
  {
    "text": "of moving data in GPU workers from the",
    "start": "894180",
    "end": "897660"
  },
  {
    "text": "data buffer all the way to GPU memories",
    "start": "897660",
    "end": "900000"
  },
  {
    "text": "in the ideal world we want data movement",
    "start": "900000",
    "end": "902100"
  },
  {
    "text": "overhead to be really small so the",
    "start": "902100",
    "end": "904560"
  },
  {
    "text": "training worker can keep launching GPU",
    "start": "904560",
    "end": "906540"
  },
  {
    "text": "operations to keep High utilizations",
    "start": "906540",
    "end": "910440"
  },
  {
    "text": "however as you can see here in the",
    "start": "910440",
    "end": "912660"
  },
  {
    "text": "realities there's actually a lot of the",
    "start": "912660",
    "end": "915240"
  },
  {
    "text": "data movement overhead in the betweens",
    "start": "915240",
    "end": "917279"
  },
  {
    "text": "of each of iterations making delays and",
    "start": "917279",
    "end": "920760"
  },
  {
    "text": "then reduce the GPU utilizations we are",
    "start": "920760",
    "end": "922860"
  },
  {
    "text": "going to have data transfer from remote",
    "start": "922860",
    "end": "925440"
  },
  {
    "text": "to local GPU nodes into the serial",
    "start": "925440",
    "end": "928139"
  },
  {
    "text": "select data need to do batch formations",
    "start": "928139",
    "end": "930060"
  },
  {
    "text": "and then transfer the data to GPU",
    "start": "930060",
    "end": "932220"
  },
  {
    "text": "memories which is offered to the slowing",
    "start": "932220",
    "end": "934620"
  },
  {
    "text": "sometimes",
    "start": "934620",
    "end": "936980"
  },
  {
    "text": "so with three uh it actually offers a",
    "start": "937019",
    "end": "940320"
  },
  {
    "text": "handful of optimization of best practice",
    "start": "940320",
    "end": "942240"
  },
  {
    "text": "for it to optimize this for them uh for",
    "start": "942240",
    "end": "946380"
  },
  {
    "text": "examples first it offers a further",
    "start": "946380",
    "end": "948540"
  },
  {
    "text": "pipeline data movement so they can",
    "start": "948540",
    "end": "950639"
  },
  {
    "text": "perform in the background first and then",
    "start": "950639",
    "end": "952320"
  },
  {
    "text": "not directly block the main training set",
    "start": "952320",
    "end": "954779"
  },
  {
    "text": "also you provide optimization on data",
    "start": "954779",
    "end": "957060"
  },
  {
    "text": "transfer with techniques such as data",
    "start": "957060",
    "end": "959339"
  },
  {
    "text": "prefetchings and ocathy over schedulings",
    "start": "959339",
    "end": "962100"
  },
  {
    "text": "we also adopt Aero table as the unified",
    "start": "962100",
    "end": "965000"
  },
  {
    "text": "or as the center data set",
    "start": "965000",
    "end": "967079"
  },
  {
    "text": "representations for more efficient data",
    "start": "967079",
    "end": "969660"
  },
  {
    "text": "civilizations",
    "start": "969660",
    "end": "972620"
  },
  {
    "text": "beside all of the previous optimizations",
    "start": "973079",
    "end": "976019"
  },
  {
    "text": "one thing that we found interesting and",
    "start": "976019",
    "end": "978060"
  },
  {
    "text": "differently with Ray is the batch",
    "start": "978060",
    "end": "979620"
  },
  {
    "text": "formation part our best formation refers",
    "start": "979620",
    "end": "982320"
  },
  {
    "text": "to taking a variable size data block and",
    "start": "982320",
    "end": "984720"
  },
  {
    "text": "form a fixed size batch which typically",
    "start": "984720",
    "end": "986880"
  },
  {
    "text": "involve memory copying and memory",
    "start": "986880",
    "end": "989399"
  },
  {
    "text": "allocations",
    "start": "989399",
    "end": "990660"
  },
  {
    "text": "it is particularly expensive in",
    "start": "990660",
    "end": "992940"
  },
  {
    "text": "Pinterest since our recommendation model",
    "start": "992940",
    "end": "994680"
  },
  {
    "text": "usually have very big batch size",
    "start": "994680",
    "end": "996660"
  },
  {
    "text": "hundreds of columns High dimensional",
    "start": "996660",
    "end": "999060"
  },
  {
    "text": "features and then one batch can easily",
    "start": "999060",
    "end": "1001339"
  },
  {
    "text": "go over 250 megabytes",
    "start": "1001339",
    "end": "1003860"
  },
  {
    "text": "just to have a comparison for you a",
    "start": "1003860",
    "end": "1006860"
  },
  {
    "text": "batch of typical image tensor for",
    "start": "1006860",
    "end": "1009860"
  },
  {
    "text": "efficient model training can be just",
    "start": "1009860",
    "end": "1011720"
  },
  {
    "text": "around 50 megabytes which is five times",
    "start": "1011720",
    "end": "1013820"
  },
  {
    "text": "smallers",
    "start": "1013820",
    "end": "1016100"
  },
  {
    "text": "so to tackle this problem for we move",
    "start": "1016100",
    "end": "1019100"
  },
  {
    "text": "batching our operation from the GPU",
    "start": "1019100",
    "end": "1021680"
  },
  {
    "text": "workers to Ray data set so now this",
    "start": "1021680",
    "end": "1024740"
  },
  {
    "text": "allows us to better scale this expensive",
    "start": "1024740",
    "end": "1026900"
  },
  {
    "text": "CPU workload and make sure the alpha",
    "start": "1026900",
    "end": "1028819"
  },
  {
    "text": "head is not directly causing delays on",
    "start": "1028819",
    "end": "1031760"
  },
  {
    "text": "the training workers",
    "start": "1031760",
    "end": "1034540"
  },
  {
    "text": "so finally with all the optimization and",
    "start": "1035660",
    "end": "1037880"
  },
  {
    "text": "other architecture we've done some",
    "start": "1037880",
    "end": "1040160"
  },
  {
    "text": "Benchmark on one of our critical",
    "start": "1040160",
    "end": "1042140"
  },
  {
    "text": "recommendation models in Pinterest",
    "start": "1042140",
    "end": "1045319"
  },
  {
    "text": "um",
    "start": "1045319",
    "end": "1045980"
  },
  {
    "text": "so it used the same model architectures",
    "start": "1045980",
    "end": "1048079"
  },
  {
    "text": "and sync training settings but just",
    "start": "1048079",
    "end": "1049820"
  },
  {
    "text": "progressively more complex",
    "start": "1049820",
    "end": "1051380"
  },
  {
    "text": "transformations",
    "start": "1051380",
    "end": "1052880"
  },
  {
    "text": "two of the infra are setting here we",
    "start": "1052880",
    "end": "1055220"
  },
  {
    "text": "have baselines using torch data loaders",
    "start": "1055220",
    "end": "1057200"
  },
  {
    "text": "training on one P40 GPU machines the",
    "start": "1057200",
    "end": "1060380"
  },
  {
    "text": "other is Ray we use Ray data set and",
    "start": "1060380",
    "end": "1063320"
  },
  {
    "text": "then training on 1p4ds plus five",
    "start": "1063320",
    "end": "1066080"
  },
  {
    "text": "additional R5 CPU machines",
    "start": "1066080",
    "end": "1068600"
  },
  {
    "text": "so as we can see here the training",
    "start": "1068600",
    "end": "1070280"
  },
  {
    "text": "runtime for Ray stay at the similar",
    "start": "1070280",
    "end": "1072200"
  },
  {
    "text": "levels which indicate that even with",
    "start": "1072200",
    "end": "1074240"
  },
  {
    "text": "more complex data Transformations Ray",
    "start": "1074240",
    "end": "1077360"
  },
  {
    "text": "can help us to scale the data processing",
    "start": "1077360",
    "end": "1079280"
  },
  {
    "text": "work though to additional CPU machines",
    "start": "1079280",
    "end": "1081020"
  },
  {
    "text": "and ultimately maintain a better",
    "start": "1081020",
    "end": "1084039"
  },
  {
    "text": "High data data throughputs",
    "start": "1084039",
    "end": "1088039"
  },
  {
    "text": "and then on the other hand",
    "start": "1088039",
    "end": "1090020"
  },
  {
    "text": "um we can see that if we just use torch",
    "start": "1090020",
    "end": "1092000"
  },
  {
    "text": "data loaders on the runtime will rise",
    "start": "1092000",
    "end": "1094760"
  },
  {
    "text": "significantly because it cannot use",
    "start": "1094760",
    "end": "1096380"
  },
  {
    "text": "additional ocp machines",
    "start": "1096380",
    "end": "1098500"
  },
  {
    "text": "on the coast side as well we see that",
    "start": "1098500",
    "end": "1101059"
  },
  {
    "text": "the job running with three scale more",
    "start": "1101059",
    "end": "1103100"
  },
  {
    "text": "efficiently compared to torch data",
    "start": "1103100",
    "end": "1104660"
  },
  {
    "text": "loader because of the because of the",
    "start": "1104660",
    "end": "1106460"
  },
  {
    "text": "faster runtimes ultimately we result in",
    "start": "1106460",
    "end": "1109100"
  },
  {
    "text": "25 more savings even though rate use",
    "start": "1109100",
    "end": "1111860"
  },
  {
    "text": "more resource to train",
    "start": "1111860",
    "end": "1116200"
  },
  {
    "text": "so so far we have talked about the setup",
    "start": "1117080",
    "end": "1119960"
  },
  {
    "text": "application therefore and the benefit it",
    "start": "1119960",
    "end": "1121760"
  },
  {
    "text": "brings to machine learning in Pinterest",
    "start": "1121760",
    "end": "1123440"
  },
  {
    "text": "but how do we actually build on the",
    "start": "1123440",
    "end": "1125600"
  },
  {
    "text": "light infrastructures to support the",
    "start": "1125600",
    "end": "1127220"
  },
  {
    "text": "workload in production skill",
    "start": "1127220",
    "end": "1129260"
  },
  {
    "text": "for the rest of the tour I'm going to",
    "start": "1129260",
    "end": "1131059"
  },
  {
    "text": "hand off to Joey and then he will talk",
    "start": "1131059",
    "end": "1133220"
  },
  {
    "text": "about how we set out rate",
    "start": "1133220",
    "end": "1134539"
  },
  {
    "text": "infrastructures",
    "start": "1134539",
    "end": "1137200"
  },
  {
    "text": "uh hi everyone I'm Joey and I'm going to",
    "start": "1143900",
    "end": "1146539"
  },
  {
    "text": "hear about how we built uh integrate Ray",
    "start": "1146539",
    "end": "1149360"
  },
  {
    "text": "infrastructure into our own Pinterest",
    "start": "1149360",
    "end": "1152200"
  },
  {
    "text": "specific compute environment",
    "start": "1152200",
    "end": "1155419"
  },
  {
    "text": "so Adventures we have a training company",
    "start": "1155419",
    "end": "1158539"
  },
  {
    "text": "platform code TCP which is highly",
    "start": "1158539",
    "end": "1161120"
  },
  {
    "text": "integrated with internal service such as",
    "start": "1161120",
    "end": "1163039"
  },
  {
    "text": "feature store low gain matrix model Hub",
    "start": "1163039",
    "end": "1165740"
  },
  {
    "text": "some ml libraries security and data",
    "start": "1165740",
    "end": "1168860"
  },
  {
    "text": "assets and some traffic reality",
    "start": "1168860",
    "end": "1171260"
  },
  {
    "text": "the scale that we have is around",
    "start": "1171260",
    "end": "1172820"
  },
  {
    "text": "thousands of manual training and",
    "start": "1172820",
    "end": "1174500"
  },
  {
    "text": "influence every day and we have hundreds",
    "start": "1174500",
    "end": "1176900"
  },
  {
    "text": "of ml engineers and data scientists",
    "start": "1176900",
    "end": "1178760"
  },
  {
    "text": "being powered by TCP so under the hood",
    "start": "1178760",
    "end": "1181520"
  },
  {
    "text": "we're using kubernetes and AWS batch for",
    "start": "1181520",
    "end": "1184940"
  },
  {
    "text": "the warming workload",
    "start": "1184940",
    "end": "1188120"
  },
  {
    "text": "so how do we run great uh Ray is",
    "start": "1188120",
    "end": "1190460"
  },
  {
    "text": "actually running on kubernetes in-house",
    "start": "1190460",
    "end": "1193240"
  },
  {
    "text": "Pinterest in health kubernetes coding",
    "start": "1193240",
    "end": "1195919"
  },
  {
    "text": "compute it's a multi-10 and it's a",
    "start": "1195919",
    "end": "1198200"
  },
  {
    "text": "multi-kubernetes clusters across",
    "start": "1198200",
    "end": "1200179"
  },
  {
    "text": "different availability zones in AWS and",
    "start": "1200179",
    "end": "1203120"
  },
  {
    "text": "it's a multi-tenant so all the workload",
    "start": "1203120",
    "end": "1204919"
  },
  {
    "text": "share resource across thousands of nodes",
    "start": "1204919",
    "end": "1206600"
  },
  {
    "text": "we have hundreds of GPU nodes of course",
    "start": "1206600",
    "end": "1209120"
  },
  {
    "text": "a100 A10 and V100 for some of it and we",
    "start": "1209120",
    "end": "1213440"
  },
  {
    "text": "have thousand of CPU nodes to make great",
    "start": "1213440",
    "end": "1216020"
  },
  {
    "text": "integrate with spin compute we largely",
    "start": "1216020",
    "end": "1218059"
  },
  {
    "text": "follow the documentation that based on",
    "start": "1218059",
    "end": "1220220"
  },
  {
    "text": "Ray which is how to manually set up a",
    "start": "1220220",
    "end": "1223160"
  },
  {
    "text": "recluster however with some limitations",
    "start": "1223160",
    "end": "1225500"
  },
  {
    "text": "that we Face such as as a client into",
    "start": "1225500",
    "end": "1228500"
  },
  {
    "text": "kubernetes platform where we don't have",
    "start": "1228500",
    "end": "1230539"
  },
  {
    "text": "like direct assets to the kubernetes API",
    "start": "1230539",
    "end": "1233299"
  },
  {
    "text": "so we end up building our own controller",
    "start": "1233299",
    "end": "1235160"
  },
  {
    "text": "to orchestrate the life cycle of",
    "start": "1235160",
    "end": "1236960"
  },
  {
    "text": "recluster and rejob",
    "start": "1236960",
    "end": "1238940"
  },
  {
    "text": "or furthermore we build a command line",
    "start": "1238940",
    "end": "1241280"
  },
  {
    "text": "tool for launching Ray cluster job from",
    "start": "1241280",
    "end": "1243200"
  },
  {
    "text": "Dev server as well as python API to",
    "start": "1243200",
    "end": "1245840"
  },
  {
    "text": "create a recluster and attach from",
    "start": "1245840",
    "end": "1248360"
  },
  {
    "text": "Jupiter we also have the dedicated UI",
    "start": "1248360",
    "end": "1251059"
  },
  {
    "text": "for manage and tracking the rate cluster",
    "start": "1251059",
    "end": "1255080"
  },
  {
    "text": "so as a platform team there's three kind",
    "start": "1255080",
    "end": "1257419"
  },
  {
    "text": "of challenge that we first face first",
    "start": "1257419",
    "end": "1259520"
  },
  {
    "text": "when we start to explore Ray first on",
    "start": "1259520",
    "end": "1262100"
  },
  {
    "text": "the kubernetes operation site it's not",
    "start": "1262100",
    "end": "1264380"
  },
  {
    "text": "recommended to add a customized operator",
    "start": "1264380",
    "end": "1267620"
  },
  {
    "text": "in our in-house kubernetes since we'll",
    "start": "1267620",
    "end": "1269660"
  },
  {
    "text": "have access to the native API so we",
    "start": "1269660",
    "end": "1271760"
  },
  {
    "text": "basically don't use Cube rate",
    "start": "1271760",
    "end": "1273880"
  },
  {
    "text": "especially difficult for this kind of",
    "start": "1273880",
    "end": "1276740"
  },
  {
    "text": "Ray head and worker service topology not",
    "start": "1276740",
    "end": "1279860"
  },
  {
    "text": "to mention we need to support",
    "start": "1279860",
    "end": "1281000"
  },
  {
    "text": "heterogeneous resource like recluster",
    "start": "1281000",
    "end": "1283400"
  },
  {
    "text": "can have mixture of GPU and CPU nodes",
    "start": "1283400",
    "end": "1286000"
  },
  {
    "text": "secondly in our in-house kubernetes we",
    "start": "1286000",
    "end": "1289340"
  },
  {
    "text": "use Envoy as for service Discovery so we",
    "start": "1289340",
    "end": "1292940"
  },
  {
    "text": "need to set up the custom traffic",
    "start": "1292940",
    "end": "1294440"
  },
  {
    "text": "routines run boy for Ray dashboard or",
    "start": "1294440",
    "end": "1296780"
  },
  {
    "text": "grafana that's it's a very important",
    "start": "1296780",
    "end": "1299179"
  },
  {
    "text": "component for users to debugging and do",
    "start": "1299179",
    "end": "1302659"
  },
  {
    "text": "a visualization",
    "start": "1302659",
    "end": "1304400"
  },
  {
    "text": "last but not least workload running on",
    "start": "1304400",
    "end": "1307340"
  },
  {
    "text": "kubernetes are known to be informal",
    "start": "1307340",
    "end": "1308780"
  },
  {
    "text": "meaning that we don't have access to the",
    "start": "1308780",
    "end": "1310400"
  },
  {
    "text": "log and Matrix after the great cluster",
    "start": "1310400",
    "end": "1312440"
  },
  {
    "text": "is being cleaned up so we need to sync",
    "start": "1312440",
    "end": "1314120"
  },
  {
    "text": "up some alternative for users to replay",
    "start": "1314120",
    "end": "1316100"
  },
  {
    "text": "those uh",
    "start": "1316100",
    "end": "1317360"
  },
  {
    "text": "critical Matrix",
    "start": "1317360",
    "end": "1319880"
  },
  {
    "text": "so to solve the first operation problem",
    "start": "1319880",
    "end": "1322220"
  },
  {
    "text": "we built the custom controller on top of",
    "start": "1322220",
    "end": "1324440"
  },
  {
    "text": "In-House supporting kubernetes primitive",
    "start": "1324440",
    "end": "1326360"
  },
  {
    "text": "it can be part or the deployment it's",
    "start": "1326360",
    "end": "1330200"
  },
  {
    "text": "pretty generic that we are able to use",
    "start": "1330200",
    "end": "1332000"
  },
  {
    "text": "whatever provided from kubernetes site",
    "start": "1332000",
    "end": "1334580"
  },
  {
    "text": "to build our own controller",
    "start": "1334580",
    "end": "1336380"
  },
  {
    "text": "so the user Journey would be like they",
    "start": "1336380",
    "end": "1338120"
  },
  {
    "text": "send a request to our TCP API category",
    "start": "1338120",
    "end": "1340400"
  },
  {
    "text": "and we propagate the request to our",
    "start": "1340400",
    "end": "1342320"
  },
  {
    "text": "controller controller will spin down the",
    "start": "1342320",
    "end": "1344419"
  },
  {
    "text": "ray hat and reworker at the same time",
    "start": "1344419",
    "end": "1346159"
  },
  {
    "text": "and with a given resource request from",
    "start": "1346159",
    "end": "1348440"
  },
  {
    "text": "the user and Ray has simply just saw the",
    "start": "1348440",
    "end": "1350720"
  },
  {
    "text": "head process while reworkers could pull",
    "start": "1350720",
    "end": "1352820"
  },
  {
    "text": "in the head IP address and ensure it's",
    "start": "1352820",
    "end": "1356659"
  },
  {
    "text": "up and running they had will wait until",
    "start": "1356659",
    "end": "1358640"
  },
  {
    "text": "all the way worker is ready and then the",
    "start": "1358640",
    "end": "1362120"
  },
  {
    "text": "controller will update the state of this",
    "start": "1362120",
    "end": "1363740"
  },
  {
    "text": "Ray cluster cleanse I will keep pulling",
    "start": "1363740",
    "end": "1365960"
  },
  {
    "text": "until every Clause is ready to use and",
    "start": "1365960",
    "end": "1368179"
  },
  {
    "text": "finally they can connect to the brake",
    "start": "1368179",
    "end": "1369980"
  },
  {
    "text": "cluster either on Jupiter or the",
    "start": "1369980",
    "end": "1372260"
  },
  {
    "text": "submitter patch job from Dev server to",
    "start": "1372260",
    "end": "1375260"
  },
  {
    "text": "the recluster",
    "start": "1375260",
    "end": "1378020"
  },
  {
    "text": "to solve the service uh Discovery issue",
    "start": "1378020",
    "end": "1380299"
  },
  {
    "text": "we set up custom traffic routines around",
    "start": "1380299",
    "end": "1382460"
  },
  {
    "text": "voice so that when a web application run",
    "start": "1382460",
    "end": "1384980"
  },
  {
    "text": "on rehab that certain ports services are",
    "start": "1384980",
    "end": "1387020"
  },
  {
    "text": "will be accessible from through Ingress",
    "start": "1387020",
    "end": "1390260"
  },
  {
    "text": "from the browser",
    "start": "1390260",
    "end": "1391640"
  },
  {
    "text": "otab app",
    "start": "1391640",
    "end": "1393140"
  },
  {
    "text": "for observation issue we export previous",
    "start": "1393140",
    "end": "1396140"
  },
  {
    "text": "metrics that generate from Ray to stat",
    "start": "1396140",
    "end": "1399320"
  },
  {
    "text": "support which is our in-house time",
    "start": "1399320",
    "end": "1401360"
  },
  {
    "text": "series database and we'll store the real",
    "start": "1401360",
    "end": "1404360"
  },
  {
    "text": "application log stream into S3 for",
    "start": "1404360",
    "end": "1406580"
  },
  {
    "text": "offline replay",
    "start": "1406580",
    "end": "1409179"
  },
  {
    "text": "to enhance the user experience on Ray we",
    "start": "1409700",
    "end": "1412460"
  },
  {
    "text": "build array specific UI page that",
    "start": "1412460",
    "end": "1414500"
  },
  {
    "text": "integrates with our original TCP UI to",
    "start": "1414500",
    "end": "1418100"
  },
  {
    "text": "display the array cluster State ml data",
    "start": "1418100",
    "end": "1421220"
  },
  {
    "text": "such as cost estimation and users can",
    "start": "1421220",
    "end": "1424159"
  },
  {
    "text": "even terminate their array cluster",
    "start": "1424159",
    "end": "1425960"
  },
  {
    "text": "easily on the UI we also add in some",
    "start": "1425960",
    "end": "1427880"
  },
  {
    "text": "like user attribution about this rate",
    "start": "1427880",
    "end": "1430039"
  },
  {
    "text": "cluster so we are able to track which",
    "start": "1430039",
    "end": "1432620"
  },
  {
    "text": "users are using this way for a given of",
    "start": "1432620",
    "end": "1435020"
  },
  {
    "text": "the time",
    "start": "1435020",
    "end": "1437179"
  },
  {
    "text": "for the logic plane if user click on one",
    "start": "1437179",
    "end": "1439580"
  },
  {
    "text": "of the like button on the UI you're able",
    "start": "1439580",
    "end": "1441980"
  },
  {
    "text": "to see the log even if the red cluster",
    "start": "1441980",
    "end": "1444559"
  },
  {
    "text": "was terminated",
    "start": "1444559",
    "end": "1447158"
  },
  {
    "text": "for metrics we're playing we're using",
    "start": "1447440",
    "end": "1449240"
  },
  {
    "text": "our in-house time series database tool",
    "start": "1449240",
    "end": "1451159"
  },
  {
    "text": "instead of kubernet but we export those",
    "start": "1451159",
    "end": "1455000"
  },
  {
    "text": "Prometheus metrics to our time series",
    "start": "1455000",
    "end": "1457100"
  },
  {
    "text": "database so we are able to replay it as",
    "start": "1457100",
    "end": "1459020"
  },
  {
    "text": "well",
    "start": "1459020",
    "end": "1461200"
  },
  {
    "text": "to get started with spray right away at",
    "start": "1461900",
    "end": "1463640"
  },
  {
    "text": "interest we support various Dev and",
    "start": "1463640",
    "end": "1466039"
  },
  {
    "text": "production methods for interactive",
    "start": "1466039",
    "end": "1468140"
  },
  {
    "text": "development we add Ray helper libraries",
    "start": "1468140",
    "end": "1470299"
  },
  {
    "text": "that can be used in Jubilee Hub users",
    "start": "1470299",
    "end": "1472460"
  },
  {
    "text": "can launch array cluster can activate or",
    "start": "1472460",
    "end": "1474380"
  },
  {
    "text": "even connect to an existing recluster",
    "start": "1474380",
    "end": "1476419"
  },
  {
    "text": "for reusing those resources",
    "start": "1476419",
    "end": "1480140"
  },
  {
    "text": "we just have command line tool that can",
    "start": "1480140",
    "end": "1482059"
  },
  {
    "text": "be used from Dev server users can just",
    "start": "1482059",
    "end": "1484159"
  },
  {
    "text": "submit the arbitrary application with",
    "start": "1484159",
    "end": "1486260"
  },
  {
    "text": "some contract that we did predefined and",
    "start": "1486260",
    "end": "1488659"
  },
  {
    "text": "they can easily handle this as a ad hard",
    "start": "1488659",
    "end": "1490700"
  },
  {
    "text": "job",
    "start": "1490700",
    "end": "1492919"
  },
  {
    "text": "to further productionize we make",
    "start": "1492919",
    "end": "1494539"
  },
  {
    "text": "integration with the workflow system",
    "start": "1494539",
    "end": "1496159"
  },
  {
    "text": "that Pinterest which is uh airflow so",
    "start": "1496159",
    "end": "1498620"
  },
  {
    "text": "people can swap out the original",
    "start": "1498620",
    "end": "1499880"
  },
  {
    "text": "training job part with the job operator",
    "start": "1499880",
    "end": "1502280"
  },
  {
    "text": "that we provide and do a seamless",
    "start": "1502280",
    "end": "1504320"
  },
  {
    "text": "migration",
    "start": "1504320",
    "end": "1506860"
  },
  {
    "text": "so here it comes the Future Works on the",
    "start": "1507559",
    "end": "1511159"
  },
  {
    "text": "infrastructure side we are actively",
    "start": "1511159",
    "end": "1512900"
  },
  {
    "text": "evaluating dedicated email kubernetes",
    "start": "1512900",
    "end": "1515720"
  },
  {
    "text": "cluster for example using eks where we",
    "start": "1515720",
    "end": "1518900"
  },
  {
    "text": "can do some optimization specific for",
    "start": "1518900",
    "end": "1521360"
  },
  {
    "text": "example like we can get rid of the",
    "start": "1521360",
    "end": "1523580"
  },
  {
    "text": "general purpose of sidecar we can do",
    "start": "1523580",
    "end": "1526400"
  },
  {
    "text": "Docker caching for on the worker nodes",
    "start": "1526400",
    "end": "1529220"
  },
  {
    "text": "to increase the provision time and most",
    "start": "1529220",
    "end": "1533240"
  },
  {
    "text": "importantly we want to try out like Cube",
    "start": "1533240",
    "end": "1535760"
  },
  {
    "text": "rate which can benefit from the official",
    "start": "1535760",
    "end": "1538279"
  },
  {
    "text": "support of all the scaling for tolerance",
    "start": "1538279",
    "end": "1540500"
  },
  {
    "text": "and gain scheduling",
    "start": "1540500",
    "end": "1541880"
  },
  {
    "text": "uh another thing that we look into is to",
    "start": "1541880",
    "end": "1545120"
  },
  {
    "text": "uh do more about the internal service",
    "start": "1545120",
    "end": "1547400"
  },
  {
    "text": "integration for example like",
    "start": "1547400",
    "end": "1549260"
  },
  {
    "text": "authentication authorization for",
    "start": "1549260",
    "end": "1551000"
  },
  {
    "text": "February assets control which is uh",
    "start": "1551000",
    "end": "1553400"
  },
  {
    "text": "non-provided by Ray and we also want to",
    "start": "1553400",
    "end": "1555860"
  },
  {
    "text": "integrate ratio in our in-house hyper",
    "start": "1555860",
    "end": "1558919"
  },
  {
    "text": "parameter tuning service we also want to",
    "start": "1558919",
    "end": "1561860"
  },
  {
    "text": "make the unit test and integration test",
    "start": "1561860",
    "end": "1564020"
  },
  {
    "text": "framework much better so that it can",
    "start": "1564020",
    "end": "1566600"
  },
  {
    "text": "benefit post developer and the client",
    "start": "1566600",
    "end": "1569120"
  },
  {
    "text": "that using Gray",
    "start": "1569120",
    "end": "1572140"
  },
  {
    "text": "on the application side we work on the",
    "start": "1572240",
    "end": "1574820"
  },
  {
    "text": "ml training will continue be the SDK",
    "start": "1574820",
    "end": "1577400"
  },
  {
    "text": "provider and use Ray as a uniform Ops",
    "start": "1577400",
    "end": "1580159"
  },
  {
    "text": "framework we will continue to build sdks",
    "start": "1580159",
    "end": "1582440"
  },
  {
    "text": "to provide deeper integration with",
    "start": "1582440",
    "end": "1584419"
  },
  {
    "text": "Pinterest ecosystem from ml data to Ms",
    "start": "1584419",
    "end": "1587779"
  },
  {
    "text": "serving such as Iceberg data set",
    "start": "1587779",
    "end": "1590659"
  },
  {
    "text": "injection and batch inference",
    "start": "1590659",
    "end": "1593179"
  },
  {
    "text": "for those customers that cannot use a",
    "start": "1593179",
    "end": "1595880"
  },
  {
    "text": "directly use our SDK they still provide",
    "start": "1595880",
    "end": "1598100"
  },
  {
    "text": "a wide support for Financial open source",
    "start": "1598100",
    "end": "1600080"
  },
  {
    "text": "community in fact there is already three",
    "start": "1600080",
    "end": "1602419"
  },
  {
    "text": "use case or even more in Pinterest or",
    "start": "1602419",
    "end": "1605059"
  },
  {
    "text": "using the features that provided by Ray",
    "start": "1605059",
    "end": "1608059"
  },
  {
    "text": "directly",
    "start": "1608059",
    "end": "1610640"
  },
  {
    "text": "so this presentation marks the beginning",
    "start": "1610640",
    "end": "1612919"
  },
  {
    "text": "of our journey it pinches to use rate",
    "start": "1612919",
    "end": "1615320"
  },
  {
    "text": "we're going to share a series of react",
    "start": "1615320",
    "end": "1618260"
  },
  {
    "text": "Pinterest blog posts to deep live",
    "start": "1618260",
    "end": "1621140"
  },
  {
    "text": "several important components such as",
    "start": "1621140",
    "end": "1622760"
  },
  {
    "text": "like less mild data processing",
    "start": "1622760",
    "end": "1624760"
  },
  {
    "text": "reinfrastructure future importance",
    "start": "1624760",
    "end": "1626720"
  },
  {
    "text": "Iceberg ingestion so stay tuned for the",
    "start": "1626720",
    "end": "1630500"
  },
  {
    "text": "upcoming post",
    "start": "1630500",
    "end": "1632120"
  },
  {
    "text": "also we are actively looking for strong",
    "start": "1632120",
    "end": "1634580"
  },
  {
    "text": "talent to work on those very exciting",
    "start": "1634580",
    "end": "1637400"
  },
  {
    "text": "great projects of Interest so feel free",
    "start": "1637400",
    "end": "1639440"
  },
  {
    "text": "to take a look",
    "start": "1639440",
    "end": "1641600"
  },
  {
    "text": "uh we also want to thank uh Pinterest",
    "start": "1641600",
    "end": "1644779"
  },
  {
    "text": "partner team for their support in our",
    "start": "1644779",
    "end": "1646760"
  },
  {
    "text": "projects as well as the any skill team",
    "start": "1646760",
    "end": "1649400"
  },
  {
    "text": "for their valuable guidance and",
    "start": "1649400",
    "end": "1651919"
  },
  {
    "text": "collaboration on Ray",
    "start": "1651919",
    "end": "1653900"
  },
  {
    "text": "so yep that's it",
    "start": "1653900",
    "end": "1656100"
  },
  {
    "text": "[Applause]",
    "start": "1656100",
    "end": "1660850"
  }
]
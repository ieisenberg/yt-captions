[
  {
    "text": "foreign",
    "start": "4920",
    "end": "6300"
  },
  {
    "text": "[Applause]",
    "start": "6300",
    "end": "9980"
  },
  {
    "text": "it's a great flower to be on the stated",
    "start": "9980",
    "end": "12420"
  },
  {
    "text": "video today my name is Xiao Wei and I'm",
    "start": "12420",
    "end": "14940"
  },
  {
    "text": "a software engineer on ML info team at",
    "start": "14940",
    "end": "16740"
  },
  {
    "text": "Airbnb I'm delighted to have this",
    "start": "16740",
    "end": "19320"
  },
  {
    "text": "opportunity to share with you our",
    "start": "19320",
    "end": "21060"
  },
  {
    "text": "journey with the way and how we evolve",
    "start": "21060",
    "end": "23039"
  },
  {
    "text": "ml platform and Airbnb with the real air",
    "start": "23039",
    "end": "25199"
  },
  {
    "text": "util system",
    "start": "25199",
    "end": "26580"
  },
  {
    "text": "so to many of us today we're aware that",
    "start": "26580",
    "end": "29160"
  },
  {
    "text": "real air stands for real AR runtime but",
    "start": "29160",
    "end": "31980"
  },
  {
    "text": "when I first introduced you to my",
    "start": "31980",
    "end": "33660"
  },
  {
    "text": "colleagues at Airbnb there was this",
    "start": "33660",
    "end": "35460"
  },
  {
    "text": "moment of confusion like they thought",
    "start": "35460",
    "end": "37079"
  },
  {
    "text": "it's in-house development libraries",
    "start": "37079",
    "end": "38700"
  },
  {
    "text": "because our trend of naming internal",
    "start": "38700",
    "end": "41219"
  },
  {
    "text": "services with the keyword air like the",
    "start": "41219",
    "end": "43620"
  },
  {
    "text": "workflow engine is called airflow the",
    "start": "43620",
    "end": "45420"
  },
  {
    "text": "service mesh system is called air mesh",
    "start": "45420",
    "end": "47700"
  },
  {
    "text": "so naturally the name re-air seemed to",
    "start": "47700",
    "end": "50700"
  },
  {
    "text": "be a perfect fit to our ecosystem and",
    "start": "50700",
    "end": "53340"
  },
  {
    "text": "later on it proved that the integration",
    "start": "53340",
    "end": "55559"
  },
  {
    "text": "we are into ethosis into our ecosystem",
    "start": "55559",
    "end": "58440"
  },
  {
    "text": "was a seamless process",
    "start": "58440",
    "end": "61320"
  },
  {
    "text": "so without further Ado let's get into",
    "start": "61320",
    "end": "64320"
  },
  {
    "text": "today's agenda we have to start off I",
    "start": "64320",
    "end": "67979"
  },
  {
    "text": "will introduce the existing ml",
    "start": "67979",
    "end": "69420"
  },
  {
    "text": "infrastructure at Airbnb with the",
    "start": "69420",
    "end": "71220"
  },
  {
    "text": "side-by-side comparison between Cloud",
    "start": "71220",
    "end": "73260"
  },
  {
    "text": "native solution built on kubernetes",
    "start": "73260",
    "end": "75240"
  },
  {
    "text": "versus really for ML developments here",
    "start": "75240",
    "end": "78360"
  },
  {
    "text": "we aim to offer a comparison that will",
    "start": "78360",
    "end": "80580"
  },
  {
    "text": "highlight the benefits of each approach",
    "start": "80580",
    "end": "82320"
  },
  {
    "text": "and provide a foundation for the next",
    "start": "82320",
    "end": "84060"
  },
  {
    "text": "section",
    "start": "84060",
    "end": "85080"
  },
  {
    "text": "next I will delve into our learnings on",
    "start": "85080",
    "end": "88140"
  },
  {
    "text": "how we integrate the way in terms of",
    "start": "88140",
    "end": "90000"
  },
  {
    "text": "user-facing API and system efficiency in",
    "start": "90000",
    "end": "92939"
  },
  {
    "text": "the end of this section we will review",
    "start": "92939",
    "end": "94680"
  },
  {
    "text": "The Benchmark results we achieved for",
    "start": "94680",
    "end": "96720"
  },
  {
    "text": "our offline training together",
    "start": "96720",
    "end": "98579"
  },
  {
    "text": "this will provide a clear future of our",
    "start": "98579",
    "end": "100979"
  },
  {
    "text": "current standing and the progress we've",
    "start": "100979",
    "end": "103380"
  },
  {
    "text": "made so far",
    "start": "103380",
    "end": "104579"
  },
  {
    "text": "lastly we will close our session with",
    "start": "104579",
    "end": "107280"
  },
  {
    "text": "the forward looting discussion and sneak",
    "start": "107280",
    "end": "109200"
  },
  {
    "text": "peek into our future plans",
    "start": "109200",
    "end": "112380"
  },
  {
    "text": "now let's get started with our first",
    "start": "112380",
    "end": "114180"
  },
  {
    "text": "topic and my infrared Airbnb",
    "start": "114180",
    "end": "116820"
  },
  {
    "text": "before we jump into the info text that I",
    "start": "116820",
    "end": "119759"
  },
  {
    "text": "like to take a step back and see how we",
    "start": "119759",
    "end": "121860"
  },
  {
    "text": "adopt machine learning in general and in",
    "start": "121860",
    "end": "124200"
  },
  {
    "text": "fact ml plays a crucial role in the",
    "start": "124200",
    "end": "126540"
  },
  {
    "text": "end-to-end user customer workflow on the",
    "start": "126540",
    "end": "128580"
  },
  {
    "text": "platform let's take the journey through",
    "start": "128580",
    "end": "130679"
  },
  {
    "text": "this process starting from the home page",
    "start": "130679",
    "end": "133020"
  },
  {
    "text": "and the search box search ranking model",
    "start": "133020",
    "end": "135540"
  },
  {
    "text": "Bridge together guests with the curated",
    "start": "135540",
    "end": "137760"
  },
  {
    "text": "list of Airbnb stays when just rolled",
    "start": "137760",
    "end": "140879"
  },
  {
    "text": "through the list Smart Pricing model",
    "start": "140879",
    "end": "142800"
  },
  {
    "text": "behind the scenes just most competitive",
    "start": "142800",
    "end": "144900"
  },
  {
    "text": "prices for each listing following that",
    "start": "144900",
    "end": "147840"
  },
  {
    "text": "once the drafts have completed their",
    "start": "147840",
    "end": "149640"
  },
  {
    "text": "bootcare on the platform trusted and",
    "start": "149640",
    "end": "151560"
  },
  {
    "text": "safety model ensures that accounts and",
    "start": "151560",
    "end": "154020"
  },
  {
    "text": "the sensitive Financial informations are",
    "start": "154020",
    "end": "156000"
  },
  {
    "text": "kept securely in safety hands",
    "start": "156000",
    "end": "158940"
  },
  {
    "text": "additionally NLP and nowadays the LM",
    "start": "158940",
    "end": "162319"
  },
  {
    "text": "assists the tools help the customer",
    "start": "162319",
    "end": "165060"
  },
  {
    "text": "support agent in solving extra requests",
    "start": "165060",
    "end": "167760"
  },
  {
    "text": "efficiently if needed",
    "start": "167760",
    "end": "170640"
  },
  {
    "text": "now having understood the role of",
    "start": "170640",
    "end": "172500"
  },
  {
    "text": "machine learning let's move on to the",
    "start": "172500",
    "end": "174420"
  },
  {
    "text": "Stars the touch stack",
    "start": "174420",
    "end": "176400"
  },
  {
    "text": "to support the diverse range of use",
    "start": "176400",
    "end": "178319"
  },
  {
    "text": "cases infra team at Airbnb offer a",
    "start": "178319",
    "end": "181440"
  },
  {
    "text": "comprehensive set of In-House developed",
    "start": "181440",
    "end": "183480"
  },
  {
    "text": "libraries and and apis that build on top",
    "start": "183480",
    "end": "186780"
  },
  {
    "text": "options are software to name a few the",
    "start": "186780",
    "end": "190140"
  },
  {
    "text": "offline tensorflow distributive training",
    "start": "190140",
    "end": "191879"
  },
  {
    "text": "adopts Harvard and approval flow that",
    "start": "191879",
    "end": "194400"
  },
  {
    "text": "allows us to train over tens of build",
    "start": "194400",
    "end": "196920"
  },
  {
    "text": "tens of terabytes data sets efficiently",
    "start": "196920",
    "end": "200040"
  },
  {
    "text": "once the model is trained and the",
    "start": "200040",
    "end": "201959"
  },
  {
    "text": "reality for online use model owner could",
    "start": "201959",
    "end": "204239"
  },
  {
    "text": "choose from a wide range of serving",
    "start": "204239",
    "end": "206099"
  },
  {
    "text": "backhands like Nvidia trading inference",
    "start": "206099",
    "end": "208019"
  },
  {
    "text": "server or tensorflow serving",
    "start": "208019",
    "end": "210659"
  },
  {
    "text": "other open source software example",
    "start": "210659",
    "end": "212459"
  },
  {
    "text": "including Jupiter notebooks and airflow",
    "start": "212459",
    "end": "214560"
  },
  {
    "text": "that are used by prototypes and",
    "start": "214560",
    "end": "216840"
  },
  {
    "text": "production workflow respectively",
    "start": "216840",
    "end": "219480"
  },
  {
    "text": "and majority of the ml applications are",
    "start": "219480",
    "end": "221760"
  },
  {
    "text": "running on top of kubernetes with the",
    "start": "221760",
    "end": "223620"
  },
  {
    "text": "exception of spark based data ETL",
    "start": "223620",
    "end": "225599"
  },
  {
    "text": "pipelines and in nutshell ml info is a",
    "start": "225599",
    "end": "228780"
  },
  {
    "text": "kubernetes Centric",
    "start": "228780",
    "end": "230700"
  },
  {
    "text": "and building on what we just discussed",
    "start": "230700",
    "end": "232680"
  },
  {
    "text": "let's take a closer look at the",
    "start": "232680",
    "end": "234239"
  },
  {
    "text": "kubernetes application runtime from this",
    "start": "234239",
    "end": "236760"
  },
  {
    "text": "diagram you can see that ml applications",
    "start": "236760",
    "end": "239340"
  },
  {
    "text": "are fully encapsulated as native",
    "start": "239340",
    "end": "241440"
  },
  {
    "text": "kubernetes resource this kind of setup",
    "start": "241440",
    "end": "243959"
  },
  {
    "text": "makes managing and staining our",
    "start": "243959",
    "end": "245700"
  },
  {
    "text": "application much easier let me break it",
    "start": "245700",
    "end": "248220"
  },
  {
    "text": "down for you so the leftmost blue box is",
    "start": "248220",
    "end": "251700"
  },
  {
    "text": "the low user local prototype",
    "start": "251700",
    "end": "253799"
  },
  {
    "text": "environments on Jupiter notebooks and it",
    "start": "253799",
    "end": "256199"
  },
  {
    "text": "is deployed as a single program native",
    "start": "256199",
    "end": "258180"
  },
  {
    "text": "pod with a remote developer access",
    "start": "258180",
    "end": "261180"
  },
  {
    "text": "now it's I'm an online serving is fully",
    "start": "261180",
    "end": "263940"
  },
  {
    "text": "managed as a kubernetes deployment that",
    "start": "263940",
    "end": "265979"
  },
  {
    "text": "supports building upgrades horizontal",
    "start": "265979",
    "end": "268139"
  },
  {
    "text": "pad Auto scaling and service discovery",
    "start": "268139",
    "end": "270900"
  },
  {
    "text": "moving on to the ml offline computation",
    "start": "270900",
    "end": "273600"
  },
  {
    "text": "these are fully wrapped as the",
    "start": "273600",
    "end": "275580"
  },
  {
    "text": "kubernetes job for round two complete ml",
    "start": "275580",
    "end": "277680"
  },
  {
    "text": "tests like model training or model",
    "start": "277680",
    "end": "279419"
  },
  {
    "text": "evaluation Etc",
    "start": "279419",
    "end": "281220"
  },
  {
    "text": "and in the case of distributed training",
    "start": "281220",
    "end": "283320"
  },
  {
    "text": "Cooper flow training operator",
    "start": "283320",
    "end": "284759"
  },
  {
    "text": "orchestrates a fleet of worker pods for",
    "start": "284759",
    "end": "287940"
  },
  {
    "text": "data parallelism Based training",
    "start": "287940",
    "end": "289979"
  },
  {
    "text": "workloads",
    "start": "289979",
    "end": "291139"
  },
  {
    "text": "so as you can see we got a pretty neat",
    "start": "291139",
    "end": "294120"
  },
  {
    "text": "setup here with kubernetes that doesn't",
    "start": "294120",
    "end": "296040"
  },
  {
    "text": "make our infrastructure management",
    "start": "296040",
    "end": "297419"
  },
  {
    "text": "easier",
    "start": "297419",
    "end": "299280"
  },
  {
    "text": "on the other side",
    "start": "299280",
    "end": "300960"
  },
  {
    "text": "despite the fact that the kubernetes is",
    "start": "300960",
    "end": "303120"
  },
  {
    "text": "a powerful and versatile platform there",
    "start": "303120",
    "end": "305280"
  },
  {
    "text": "are various feature gaps that we've",
    "start": "305280",
    "end": "306840"
  },
  {
    "text": "encountered in the past and we roughly",
    "start": "306840",
    "end": "308940"
  },
  {
    "text": "try to write those into three buckets",
    "start": "308940",
    "end": "311340"
  },
  {
    "text": "the first bucket is around the",
    "start": "311340",
    "end": "312780"
  },
  {
    "text": "kubernetes Operational Support",
    "start": "312780",
    "end": "314639"
  },
  {
    "text": "for example we have issues regarding the",
    "start": "314639",
    "end": "316860"
  },
  {
    "text": "default scheduler's ability to support",
    "start": "316860",
    "end": "318720"
  },
  {
    "text": "the fractional gpus or exposing runtime",
    "start": "318720",
    "end": "322020"
  },
  {
    "text": "Criterion Matrix and the telemetries for",
    "start": "322020",
    "end": "324840"
  },
  {
    "text": "end users",
    "start": "324840",
    "end": "326460"
  },
  {
    "text": "the certain battery that contains issues",
    "start": "326460",
    "end": "328500"
  },
  {
    "text": "around usability and the developer",
    "start": "328500",
    "end": "330479"
  },
  {
    "text": "efficiency Mi application written from",
    "start": "330479",
    "end": "333060"
  },
  {
    "text": "local environments requires address for",
    "start": "333060",
    "end": "335520"
  },
  {
    "text": "infrar overheads that are invasive to",
    "start": "335520",
    "end": "337979"
  },
  {
    "text": "user code base to be able to submit for",
    "start": "337979",
    "end": "339960"
  },
  {
    "text": "remote execution and we will review one",
    "start": "339960",
    "end": "342960"
  },
  {
    "text": "example in the next slide",
    "start": "342960",
    "end": "345000"
  },
  {
    "text": "last but not least the recently emerging",
    "start": "345000",
    "end": "347460"
  },
  {
    "text": "needs for LM development has Broadway",
    "start": "347460",
    "end": "349979"
  },
  {
    "text": "did a new set of infrastructure",
    "start": "349979",
    "end": "351960"
  },
  {
    "text": "challenge",
    "start": "351960",
    "end": "352880"
  },
  {
    "text": "these are primarily related to serial",
    "start": "352880",
    "end": "355680"
  },
  {
    "text": "ability Hardware efficiency and the need",
    "start": "355680",
    "end": "358500"
  },
  {
    "text": "to support more latest ml Frameworks",
    "start": "358500",
    "end": "361280"
  },
  {
    "text": "for contacts prior to 2023 ml community",
    "start": "361280",
    "end": "365220"
  },
  {
    "text": "at Airbnb are heavily invested in",
    "start": "365220",
    "end": "367139"
  },
  {
    "text": "tensorflow whereas nowadays for open",
    "start": "367139",
    "end": "369720"
  },
  {
    "text": "source LMS these are dominated by",
    "start": "369720",
    "end": "371820"
  },
  {
    "text": "pytorch",
    "start": "371820",
    "end": "372960"
  },
  {
    "text": "Additionally the advances in LM",
    "start": "372960",
    "end": "375479"
  },
  {
    "text": "libraries such as plytorch fsdp hiding",
    "start": "375479",
    "end": "378180"
  },
  {
    "text": "face accelerate and deep speed are not",
    "start": "378180",
    "end": "380400"
  },
  {
    "text": "yet well integrated into the existing",
    "start": "380400",
    "end": "382800"
  },
  {
    "text": "training orchestration layer built on",
    "start": "382800",
    "end": "384539"
  },
  {
    "text": "kubernet kubeflow training operators",
    "start": "384539",
    "end": "387840"
  },
  {
    "text": "well this sum up the future gaps for",
    "start": "387840",
    "end": "390300"
  },
  {
    "text": "Cloud native-based solution in the",
    "start": "390300",
    "end": "392580"
  },
  {
    "text": "coming slides I will provide a few more",
    "start": "392580",
    "end": "394199"
  },
  {
    "text": "examples and share our learnings from",
    "start": "394199",
    "end": "396419"
  },
  {
    "text": "Ray let's Dive In",
    "start": "396419",
    "end": "400259"
  },
  {
    "text": "one common Operational Support issue",
    "start": "400259",
    "end": "402600"
  },
  {
    "text": "will be encountered with kubernetes",
    "start": "402600",
    "end": "404479"
  },
  {
    "text": "particularly when we are troubleshooting",
    "start": "404479",
    "end": "407580"
  },
  {
    "text": "and debugging tests that are run out of",
    "start": "407580",
    "end": "409860"
  },
  {
    "text": "memory or cloud",
    "start": "409860",
    "end": "412020"
  },
  {
    "text": "so you may have noticed that kubernetes",
    "start": "412020",
    "end": "413940"
  },
  {
    "text": "have this very rigid memory management",
    "start": "413940",
    "end": "416000"
  },
  {
    "text": "like cdos so which means that as soon as",
    "start": "416000",
    "end": "419819"
  },
  {
    "text": "the job is running over the memory limit",
    "start": "419819",
    "end": "421860"
  },
  {
    "text": "the main container in the job itself got",
    "start": "421860",
    "end": "424500"
  },
  {
    "text": "terminated almost instantly so it's try",
    "start": "424500",
    "end": "427139"
  },
  {
    "text": "to like to flipping a switch and the",
    "start": "427139",
    "end": "429419"
  },
  {
    "text": "downside of this is that the Pod logs",
    "start": "429419",
    "end": "432000"
  },
  {
    "text": "and T Matrix oftentimes are not properly",
    "start": "432000",
    "end": "434819"
  },
  {
    "text": "forwarded to another system",
    "start": "434819",
    "end": "436740"
  },
  {
    "text": "and two minutes this is more challenging",
    "start": "436740",
    "end": "438900"
  },
  {
    "text": "our job Telemetry are scattered across",
    "start": "438900",
    "end": "441780"
  },
  {
    "text": "different like systems and components",
    "start": "441780",
    "end": "443520"
  },
  {
    "text": "like lots are saved in tibana and",
    "start": "443520",
    "end": "446340"
  },
  {
    "text": "metrics are in datadot and those are not",
    "start": "446340",
    "end": "449880"
  },
  {
    "text": "directly linked to the kubernetes",
    "start": "449880",
    "end": "451860"
  },
  {
    "text": "runtime execution runtimes",
    "start": "451860",
    "end": "454500"
  },
  {
    "text": "for example the images of missing",
    "start": "454500",
    "end": "457740"
  },
  {
    "text": "critical container logs we have to rely",
    "start": "457740",
    "end": "459660"
  },
  {
    "text": "on the runtime usage metrics uh that's",
    "start": "459660",
    "end": "462000"
  },
  {
    "text": "the one on top that has this about the",
    "start": "462000",
    "end": "465120"
  },
  {
    "text": "container that has memory liturgy to",
    "start": "465120",
    "end": "467039"
  },
  {
    "text": "keep restarting itself and the metrics",
    "start": "467039",
    "end": "470220"
  },
  {
    "text": "on the bottom is the actual memory like",
    "start": "470220",
    "end": "472560"
  },
  {
    "text": "limit at 40 gigabytes so understand",
    "start": "472560",
    "end": "476400"
  },
  {
    "text": "these two metrics we can tell and debug",
    "start": "476400",
    "end": "478860"
  },
  {
    "text": "what happened exactly at the runtime",
    "start": "478860",
    "end": "481319"
  },
  {
    "text": "so in that chapter I will demonstrate",
    "start": "481319",
    "end": "484860"
  },
  {
    "text": "how we're tackling this challenge with",
    "start": "484860",
    "end": "486720"
  },
  {
    "text": "help away",
    "start": "486720",
    "end": "488099"
  },
  {
    "text": "for the real runtime control the auto",
    "start": "488099",
    "end": "490620"
  },
  {
    "text": "memory prevention support offers active",
    "start": "490620",
    "end": "492960"
  },
  {
    "text": "memory usage monitoring and a direct",
    "start": "492960",
    "end": "495120"
  },
  {
    "text": "intervention so as a result infra is to",
    "start": "495120",
    "end": "498479"
  },
  {
    "text": "interact while the user application",
    "start": "498479",
    "end": "500099"
  },
  {
    "text": "crashes and we could achieve a clean",
    "start": "500099",
    "end": "502919"
  },
  {
    "text": "separation between the user code base",
    "start": "502919",
    "end": "504780"
  },
  {
    "text": "and underlying infrastructure in this",
    "start": "504780",
    "end": "507000"
  },
  {
    "text": "case that's the recluster itself",
    "start": "507000",
    "end": "509400"
  },
  {
    "text": "to meet the debugging process even",
    "start": "509400",
    "end": "511919"
  },
  {
    "text": "easier the rear dashboard allows end",
    "start": "511919",
    "end": "513839"
  },
  {
    "text": "user to have a task level debugging",
    "start": "513839",
    "end": "515820"
  },
  {
    "text": "support like detailed logs metrics and",
    "start": "515820",
    "end": "518279"
  },
  {
    "text": "profiler all living in one Central",
    "start": "518279",
    "end": "520140"
  },
  {
    "text": "application",
    "start": "520140",
    "end": "522599"
  },
  {
    "text": "so kubernetes Operational Support is not",
    "start": "522599",
    "end": "525300"
  },
  {
    "text": "only feature Gap now let's move on to",
    "start": "525300",
    "end": "528420"
  },
  {
    "text": "the another issue around the usability",
    "start": "528420",
    "end": "531720"
  },
  {
    "text": "and the developer efficiency here is the",
    "start": "531720",
    "end": "534180"
  },
  {
    "text": "one great example the yellow Bots is",
    "start": "534180",
    "end": "536519"
  },
  {
    "text": "user local development environment and",
    "start": "536519",
    "end": "539160"
  },
  {
    "text": "the blue box on the right side is a",
    "start": "539160",
    "end": "540720"
  },
  {
    "text": "kubernetes remote runtime as you can see",
    "start": "540720",
    "end": "543300"
  },
  {
    "text": "model training functions divide locally",
    "start": "543300",
    "end": "546000"
  },
  {
    "text": "will be involved at runtime with an",
    "start": "546000",
    "end": "548279"
  },
  {
    "text": "infrastructure driver logic that load",
    "start": "548279",
    "end": "551220"
  },
  {
    "text": "the training function modules of runtime",
    "start": "551220",
    "end": "553140"
  },
  {
    "text": "dependencies and manage the function",
    "start": "553140",
    "end": "555000"
  },
  {
    "text": "input output on behalf of the",
    "start": "555000",
    "end": "557160"
  },
  {
    "text": "application owner as a result it's hard",
    "start": "557160",
    "end": "560519"
  },
  {
    "text": "to fully reproduce the remote failures",
    "start": "560519",
    "end": "562560"
  },
  {
    "text": "locally and in the case of distributive",
    "start": "562560",
    "end": "564959"
  },
  {
    "text": "training you will take significant",
    "start": "564959",
    "end": "566880"
  },
  {
    "text": "longer time to replicate a hardware",
    "start": "566880",
    "end": "568620"
  },
  {
    "text": "runtime locally",
    "start": "568620",
    "end": "570480"
  },
  {
    "text": "and at the same time mixing user code",
    "start": "570480",
    "end": "573360"
  },
  {
    "text": "with the infrastructure API also made",
    "start": "573360",
    "end": "575880"
  },
  {
    "text": "means there will be apps for overheads",
    "start": "575880",
    "end": "577800"
  },
  {
    "text": "government infrastructure migration like",
    "start": "577800",
    "end": "580260"
  },
  {
    "text": "system upgrades or security patches",
    "start": "580260",
    "end": "583880"
  },
  {
    "text": "alternatively remote execution with raid",
    "start": "583880",
    "end": "586680"
  },
  {
    "text": "can be similar scaled from local to",
    "start": "586680",
    "end": "588600"
  },
  {
    "text": "remote",
    "start": "588600",
    "end": "589680"
  },
  {
    "text": "here's this example during the Prototype",
    "start": "589680",
    "end": "592080"
  },
  {
    "text": "phase Rehabilitation can be attitudely",
    "start": "592080",
    "end": "594480"
  },
  {
    "text": "locally with the hardware cluster",
    "start": "594480",
    "end": "596640"
  },
  {
    "text": "created by the way init function and the",
    "start": "596640",
    "end": "599580"
  },
  {
    "text": "same app can then be submitted to remote",
    "start": "599580",
    "end": "601740"
  },
  {
    "text": "cluster with different scaling config",
    "start": "601740",
    "end": "603959"
  },
  {
    "text": "like number of gpus or number of workers",
    "start": "603959",
    "end": "606720"
  },
  {
    "text": "in the meanwhile Dynamic runtime control",
    "start": "606720",
    "end": "609120"
  },
  {
    "text": "or dynamic runtime environment allows",
    "start": "609120",
    "end": "611519"
  },
  {
    "text": "users to fully customize and control the",
    "start": "611519",
    "end": "613800"
  },
  {
    "text": "remote execution entry point and the",
    "start": "613800",
    "end": "615779"
  },
  {
    "text": "dependencies",
    "start": "615779",
    "end": "616860"
  },
  {
    "text": "this is further guarantee that local and",
    "start": "616860",
    "end": "619740"
  },
  {
    "text": "remote runtime are consistent",
    "start": "619740",
    "end": "622920"
  },
  {
    "text": "in conclusion we provides a robust",
    "start": "622920",
    "end": "625440"
  },
  {
    "text": "solution that not only supports fast",
    "start": "625440",
    "end": "627720"
  },
  {
    "text": "iterations but also ensure similar",
    "start": "627720",
    "end": "630000"
  },
  {
    "text": "screening",
    "start": "630000",
    "end": "631500"
  },
  {
    "text": "now let's review the last feature that",
    "start": "631500",
    "end": "633660"
  },
  {
    "text": "we've mentioned earlier around the",
    "start": "633660",
    "end": "635459"
  },
  {
    "text": "kubernetes century ml in front",
    "start": "635459",
    "end": "637740"
  },
  {
    "text": "as we briefly mentioned",
    "start": "637740",
    "end": "639839"
  },
  {
    "text": "physics physical limits or in general",
    "start": "639839",
    "end": "642420"
  },
  {
    "text": "amount of developments is often referred",
    "start": "642420",
    "end": "644940"
  },
  {
    "text": "to as the GPU memory wall challenge the",
    "start": "644940",
    "end": "647940"
  },
  {
    "text": "general rule and thumb here is that each",
    "start": "647940",
    "end": "649680"
  },
  {
    "text": "model parameter is going to consume at",
    "start": "649680",
    "end": "651899"
  },
  {
    "text": "least 18 bytes at the training time so",
    "start": "651899",
    "end": "654240"
  },
  {
    "text": "that roughly translates one billion",
    "start": "654240",
    "end": "656279"
  },
  {
    "text": "model as 18 gigabytes of vram",
    "start": "656279",
    "end": "657959"
  },
  {
    "text": "requirement without considering other",
    "start": "657959",
    "end": "660300"
  },
  {
    "text": "overheads like GPU memory for",
    "start": "660300",
    "end": "662160"
  },
  {
    "text": "augmentation",
    "start": "662160",
    "end": "663360"
  },
  {
    "text": "Etc",
    "start": "663360",
    "end": "664380"
  },
  {
    "text": "and however the typical commercial",
    "start": "664380",
    "end": "666360"
  },
  {
    "text": "available gpus like a100 or the latest",
    "start": "666360",
    "end": "669000"
  },
  {
    "text": "h100 generation only offer up to 80",
    "start": "669000",
    "end": "671880"
  },
  {
    "text": "gigabytes of memory",
    "start": "671880",
    "end": "673800"
  },
  {
    "text": "to make this even more challenging as",
    "start": "673800",
    "end": "675899"
  },
  {
    "text": "the blood pulls from 10 to 18 from",
    "start": "675899",
    "end": "678420"
  },
  {
    "text": "openly Illustrated in this diagram the",
    "start": "678420",
    "end": "680940"
  },
  {
    "text": "y-axis indicated report the GPU",
    "start": "680940",
    "end": "683160"
  },
  {
    "text": "computation power is growing about five",
    "start": "683160",
    "end": "685500"
  },
  {
    "text": "to six times faster than underlying GPU",
    "start": "685500",
    "end": "687899"
  },
  {
    "text": "Hardware capacity",
    "start": "687899",
    "end": "689279"
  },
  {
    "text": "and this diagram ends in 2018 actually",
    "start": "689279",
    "end": "692180"
  },
  {
    "text": "nowadays with the state of art LMS those",
    "start": "692180",
    "end": "696240"
  },
  {
    "text": "models are actually developing even",
    "start": "696240",
    "end": "697920"
  },
  {
    "text": "faster at the other magnitudes higher",
    "start": "697920",
    "end": "701339"
  },
  {
    "text": "than the GPU capacity",
    "start": "701339",
    "end": "703079"
  },
  {
    "text": "so as you can see there is always this",
    "start": "703079",
    "end": "705720"
  },
  {
    "text": "contention between model size and",
    "start": "705720",
    "end": "707700"
  },
  {
    "text": "Hardware limits",
    "start": "707700",
    "end": "710100"
  },
  {
    "text": "to truly democratize the armed",
    "start": "710100",
    "end": "712320"
  },
  {
    "text": "developments a number of innovative",
    "start": "712320",
    "end": "714120"
  },
  {
    "text": "matters have been introduced by the",
    "start": "714120",
    "end": "715920"
  },
  {
    "text": "community for example a deep speed zero",
    "start": "715920",
    "end": "718680"
  },
  {
    "text": "redundancy Optimizer and pytorch fsdp so",
    "start": "718680",
    "end": "721920"
  },
  {
    "text": "those methods worked by fully shared",
    "start": "721920",
    "end": "724079"
  },
  {
    "text": "model optimized status gradients and",
    "start": "724079",
    "end": "727079"
  },
  {
    "text": "parameters across multiple workers so as",
    "start": "727079",
    "end": "729480"
  },
  {
    "text": "a result it's possible to fully to steal",
    "start": "729480",
    "end": "732720"
  },
  {
    "text": "your model capacity linearly with the",
    "start": "732720",
    "end": "734579"
  },
  {
    "text": "number of gpus",
    "start": "734579",
    "end": "736260"
  },
  {
    "text": "and there are other optimization",
    "start": "736260",
    "end": "738899"
  },
  {
    "text": "Solutions like CPU offloading and the",
    "start": "738899",
    "end": "741839"
  },
  {
    "text": "activation chart pointing that the",
    "start": "741839",
    "end": "743700"
  },
  {
    "text": "trades the computation power for less",
    "start": "743700",
    "end": "746100"
  },
  {
    "text": "memory consumption",
    "start": "746100",
    "end": "747600"
  },
  {
    "text": "and in theory thanks to the combined",
    "start": "747600",
    "end": "750300"
  },
  {
    "text": "solution of those type needs LMS that",
    "start": "750300",
    "end": "754019"
  },
  {
    "text": "will be on the single GPU limit can now",
    "start": "754019",
    "end": "756060"
  },
  {
    "text": "be trained and the fine-tuned on cheaper",
    "start": "756060",
    "end": "758160"
  },
  {
    "text": "GPU clusters",
    "start": "758160",
    "end": "759779"
  },
  {
    "text": "and in that slide we will delve into how",
    "start": "759779",
    "end": "762240"
  },
  {
    "text": "these Solutions can be practical applied",
    "start": "762240",
    "end": "764160"
  },
  {
    "text": "with the real Air Trainer",
    "start": "764160",
    "end": "766920"
  },
  {
    "text": "in fact it's very straightforward to",
    "start": "766920",
    "end": "768959"
  },
  {
    "text": "enable this these changes so in the",
    "start": "768959",
    "end": "771839"
  },
  {
    "text": "diagram on the left side there are three",
    "start": "771839",
    "end": "773880"
  },
  {
    "text": "major code updates including a much",
    "start": "773880",
    "end": "776579"
  },
  {
    "text": "simplified resource configuration in",
    "start": "776579",
    "end": "779339"
  },
  {
    "text": "stating config and then a real trainer",
    "start": "779339",
    "end": "782880"
  },
  {
    "text": "that wraps the existing python training",
    "start": "782880",
    "end": "785040"
  },
  {
    "text": "loops and the Third change is the",
    "start": "785040",
    "end": "787260"
  },
  {
    "text": "customized deep speed configuration",
    "start": "787260",
    "end": "789420"
  },
  {
    "text": "as a result ml Community had Airbnb got",
    "start": "789420",
    "end": "792540"
  },
  {
    "text": "immediate access to vast majority of",
    "start": "792540",
    "end": "794880"
  },
  {
    "text": "Open Source lab LMS from hiding phase",
    "start": "794880",
    "end": "797399"
  },
  {
    "text": "and the training can be deployed to less",
    "start": "797399",
    "end": "800160"
  },
  {
    "text": "expensive gpus like a10g",
    "start": "800160",
    "end": "803220"
  },
  {
    "text": "and here's a great test we had offline",
    "start": "803220",
    "end": "806399"
  },
  {
    "text": "so one single host containing eight",
    "start": "806399",
    "end": "809279"
  },
  {
    "text": "eight NG GPU is possible to fine-tune",
    "start": "809279",
    "end": "812100"
  },
  {
    "text": "model up to 12 billion parameters with a",
    "start": "812100",
    "end": "814560"
  },
  {
    "text": "reasonable speed",
    "start": "814560",
    "end": "815880"
  },
  {
    "text": "and fine tune your model up to 60",
    "start": "815880",
    "end": "817920"
  },
  {
    "text": "billion Prem is also possible if we",
    "start": "817920",
    "end": "820620"
  },
  {
    "text": "further steal the number of GPU from 8",
    "start": "820620",
    "end": "822899"
  },
  {
    "text": "to 30 to 18gs",
    "start": "822899",
    "end": "826579"
  },
  {
    "text": "uh now we just finished the brief intro",
    "start": "826620",
    "end": "829500"
  },
  {
    "text": "ml platform and how we air solve a lot",
    "start": "829500",
    "end": "832320"
  },
  {
    "text": "of the feature gaps between kubernetes",
    "start": "832320",
    "end": "834060"
  },
  {
    "text": "and ml applications",
    "start": "834060",
    "end": "836040"
  },
  {
    "text": "next let's move forward and take a",
    "start": "836040",
    "end": "838320"
  },
  {
    "text": "closer look at our integration Journey",
    "start": "838320",
    "end": "840060"
  },
  {
    "text": "with every error",
    "start": "840060",
    "end": "842399"
  },
  {
    "text": "here is a high level overview on how we",
    "start": "842399",
    "end": "844860"
  },
  {
    "text": "set up really based maps on top of",
    "start": "844860",
    "end": "846959"
  },
  {
    "text": "public cloud provider there are three",
    "start": "846959",
    "end": "849480"
  },
  {
    "text": "primary design code we outline",
    "start": "849480",
    "end": "851760"
  },
  {
    "text": "first of all developing with the real",
    "start": "851760",
    "end": "853800"
  },
  {
    "text": "error API should be easy if you check",
    "start": "853800",
    "end": "856019"
  },
  {
    "text": "the diagram on the left side the user",
    "start": "856019",
    "end": "858060"
  },
  {
    "text": "app logic is developed with the rear",
    "start": "858060",
    "end": "860579"
  },
  {
    "text": "Library entirely there is no more",
    "start": "860579",
    "end": "862740"
  },
  {
    "text": "invasive ml info drivers or libraries so",
    "start": "862740",
    "end": "865860"
  },
  {
    "text": "that ml Engineers or data scientists can",
    "start": "865860",
    "end": "868860"
  },
  {
    "text": "take advantage of any recent progress",
    "start": "868860",
    "end": "871320"
  },
  {
    "text": "and upgrades made available by the open",
    "start": "871320",
    "end": "873300"
  },
  {
    "text": "source community",
    "start": "873300",
    "end": "874800"
  },
  {
    "text": "and the layer below the user app is a",
    "start": "874800",
    "end": "878220"
  },
  {
    "text": "full set of info API that submits redraw",
    "start": "878220",
    "end": "881040"
  },
  {
    "text": "to remote ephemeral clusters so that end",
    "start": "881040",
    "end": "883680"
  },
  {
    "text": "user don't need to worry about how the",
    "start": "883680",
    "end": "885360"
  },
  {
    "text": "info setup works",
    "start": "885360",
    "end": "887820"
  },
  {
    "text": "the certain goal here is to ensure cost",
    "start": "887820",
    "end": "889740"
  },
  {
    "text": "efficiency as we all aware that is at",
    "start": "889740",
    "end": "892800"
  },
  {
    "text": "this point that model training",
    "start": "892800",
    "end": "894300"
  },
  {
    "text": "especially for LMS are extremely",
    "start": "894300",
    "end": "896760"
  },
  {
    "text": "expensive and achieving cost efficiency",
    "start": "896760",
    "end": "899339"
  },
  {
    "text": "is Mission critical we will Deep dive",
    "start": "899339",
    "end": "902100"
  },
  {
    "text": "into the details of achieving fully",
    "start": "902100",
    "end": "904019"
  },
  {
    "text": "lasted real cluster in the next few",
    "start": "904019",
    "end": "906420"
  },
  {
    "text": "slides",
    "start": "906420",
    "end": "907620"
  },
  {
    "text": "and the third Fortress here is arm",
    "start": "907620",
    "end": "910320"
  },
  {
    "text": "training efficiency that is to achieve",
    "start": "910320",
    "end": "912540"
  },
  {
    "text": "High GPU utilization grid and I'm going",
    "start": "912540",
    "end": "915839"
  },
  {
    "text": "to share a few more Hardware",
    "start": "915839",
    "end": "916800"
  },
  {
    "text": "customization in the end of this section",
    "start": "916800",
    "end": "919740"
  },
  {
    "text": "so let's now go deeper into these goals",
    "start": "919740",
    "end": "923279"
  },
  {
    "text": "and how we achieve them on the real base",
    "start": "923279",
    "end": "925440"
  },
  {
    "text": "demo infrastructure setup",
    "start": "925440",
    "end": "928320"
  },
  {
    "text": "to start off there are a few common user",
    "start": "928320",
    "end": "931860"
  },
  {
    "text": "Dev scenarios",
    "start": "931860",
    "end": "933740"
  },
  {
    "text": "so starting from local prototypes and ml",
    "start": "933740",
    "end": "937380"
  },
  {
    "text": "model owner could easily provision",
    "start": "937380",
    "end": "939240"
  },
  {
    "text": "on-demand recluster locally to test out",
    "start": "939240",
    "end": "941579"
  },
  {
    "text": "the code changes Library upgrades and",
    "start": "941579",
    "end": "943740"
  },
  {
    "text": "the different reversions",
    "start": "943740",
    "end": "945480"
  },
  {
    "text": "and once the result is validated ml",
    "start": "945480",
    "end": "948600"
  },
  {
    "text": "applications can be stealed out and",
    "start": "948600",
    "end": "951060"
  },
  {
    "text": "submitted to a remote execution engine",
    "start": "951060",
    "end": "953160"
  },
  {
    "text": "that the provision ephemeral recluster",
    "start": "953160",
    "end": "955440"
  },
  {
    "text": "on demand so this could be single round",
    "start": "955440",
    "end": "958019"
  },
  {
    "text": "to complete reapp or a full-fledged ml",
    "start": "958019",
    "end": "960720"
  },
  {
    "text": "workflow",
    "start": "960720",
    "end": "961740"
  },
  {
    "text": "we will review both cases later",
    "start": "961740",
    "end": "964920"
  },
  {
    "text": "after the remote job is run successfully",
    "start": "964920",
    "end": "967440"
  },
  {
    "text": "model owner could charging the bridge",
    "start": "967440",
    "end": "969959"
  },
  {
    "text": "drop code and the code have code",
    "start": "969959",
    "end": "971760"
  },
  {
    "text": "reviewed which later become part of ml",
    "start": "971760",
    "end": "974279"
  },
  {
    "text": "production workflow that is scheduled to",
    "start": "974279",
    "end": "976199"
  },
  {
    "text": "run on the future tatums",
    "start": "976199",
    "end": "978660"
  },
  {
    "text": "so this flow from local prototype to",
    "start": "978660",
    "end": "981779"
  },
  {
    "text": "remote execution and finally to",
    "start": "981779",
    "end": "983820"
  },
  {
    "text": "production forms the backbone of ml app",
    "start": "983820",
    "end": "986579"
  },
  {
    "text": "development process and let's proceed to",
    "start": "986579",
    "end": "989339"
  },
  {
    "text": "next section where we'll Deep dive into",
    "start": "989339",
    "end": "991320"
  },
  {
    "text": "the specific API designs",
    "start": "991320",
    "end": "995360"
  },
  {
    "text": "here's a great overview of the the rate",
    "start": "995940",
    "end": "998579"
  },
  {
    "text": "drop API the first diagram on the left",
    "start": "998579",
    "end": "1000920"
  },
  {
    "text": "side shows the user app logic that's",
    "start": "1000920",
    "end": "1003259"
  },
  {
    "text": "implemented with real error so this can",
    "start": "1003259",
    "end": "1005600"
  },
  {
    "text": "be any like Public Access tutorials from",
    "start": "1005600",
    "end": "1008600"
  },
  {
    "text": "Red documentation site",
    "start": "1008600",
    "end": "1010639"
  },
  {
    "text": "and the certain diagram on the right",
    "start": "1010639",
    "end": "1012680"
  },
  {
    "text": "shows the job submission process that",
    "start": "1012680",
    "end": "1014959"
  },
  {
    "text": "the part is the user code onto a",
    "start": "1014959",
    "end": "1016820"
  },
  {
    "text": "persistent storage remotely and then",
    "start": "1016820",
    "end": "1018920"
  },
  {
    "text": "request to provision requests On Demand",
    "start": "1018920",
    "end": "1021019"
  },
  {
    "text": "with different Hardware resources so in",
    "start": "1021019",
    "end": "1023720"
  },
  {
    "text": "this case it's requesting 10 workers",
    "start": "1023720",
    "end": "1026000"
  },
  {
    "text": "with the a100 gpus",
    "start": "1026000",
    "end": "1028880"
  },
  {
    "text": "and that's the highlighted with Java API",
    "start": "1028880",
    "end": "1032178"
  },
  {
    "text": "now let's take a look at the workflow",
    "start": "1032179",
    "end": "1033980"
  },
  {
    "text": "API which can add multiple different",
    "start": "1033980",
    "end": "1036020"
  },
  {
    "text": "jobs",
    "start": "1036020",
    "end": "1037400"
  },
  {
    "text": "and to work with with the degree",
    "start": "1037400",
    "end": "1039798"
  },
  {
    "text": "application in end-to-end ml workflow we",
    "start": "1039799",
    "end": "1043280"
  },
  {
    "text": "extended our workflow DSL support to",
    "start": "1043280",
    "end": "1045558"
  },
  {
    "text": "integrate debris application as a",
    "start": "1045559",
    "end": "1047360"
  },
  {
    "text": "workflow building blocks in this example",
    "start": "1047360",
    "end": "1050360"
  },
  {
    "text": "a decorated python function is defined",
    "start": "1050360",
    "end": "1053059"
  },
  {
    "text": "as a part of the workflow that and the",
    "start": "1053059",
    "end": "1055280"
  },
  {
    "text": "three steps contains first of all a",
    "start": "1055280",
    "end": "1057980"
  },
  {
    "text": "clusters about for your family cluster",
    "start": "1057980",
    "end": "1059960"
  },
  {
    "text": "similar to the redrop API",
    "start": "1059960",
    "end": "1062240"
  },
  {
    "text": "and secondly a re-application defined in",
    "start": "1062240",
    "end": "1065000"
  },
  {
    "text": "the python function body",
    "start": "1065000",
    "end": "1066980"
  },
  {
    "text": "and in this way the real base ml",
    "start": "1066980",
    "end": "1069500"
  },
  {
    "text": "workflow achieved both for one meeting",
    "start": "1069500",
    "end": "1072020"
  },
  {
    "text": "up with the number very based steps like",
    "start": "1072020",
    "end": "1074840"
  },
  {
    "text": "data fetching from external data",
    "start": "1074840",
    "end": "1076640"
  },
  {
    "text": "warehouse using press tool or hive",
    "start": "1076640",
    "end": "1079240"
  },
  {
    "text": "certainly the workflow ensures that the",
    "start": "1079240",
    "end": "1081919"
  },
  {
    "text": "data persistence so after the ephemeral",
    "start": "1081919",
    "end": "1084679"
  },
  {
    "text": "cluster is decommissioned that is when",
    "start": "1084679",
    "end": "1087260"
  },
  {
    "text": "we tear down the ray Object Store",
    "start": "1087260",
    "end": "1089539"
  },
  {
    "text": "critical data sets and the training",
    "start": "1089539",
    "end": "1091880"
  },
  {
    "text": "models are stored properly",
    "start": "1091880",
    "end": "1095500"
  },
  {
    "text": "now we did the easy user arches API",
    "start": "1095660",
    "end": "1098299"
  },
  {
    "text": "let's we need to pay extra attention on",
    "start": "1098299",
    "end": "1101539"
  },
  {
    "text": "the overall cost",
    "start": "1101539",
    "end": "1103700"
  },
  {
    "text": "this slide will be mostly focus on the",
    "start": "1103700",
    "end": "1106400"
  },
  {
    "text": "cost efficiency factor and the primary",
    "start": "1106400",
    "end": "1108620"
  },
  {
    "text": "goal here is to achieve a fully",
    "start": "1108620",
    "end": "1110299"
  },
  {
    "text": "elasticity rate cluster built on top of",
    "start": "1110299",
    "end": "1112220"
  },
  {
    "text": "AWS",
    "start": "1112220",
    "end": "1113360"
  },
  {
    "text": "there are three major components in our",
    "start": "1113360",
    "end": "1116660"
  },
  {
    "text": "custom managed kubernetes cluster",
    "start": "1116660",
    "end": "1118660"
  },
  {
    "text": "including the ec2 auto experience group",
    "start": "1118660",
    "end": "1121520"
  },
  {
    "text": "or ESG and the kubernetes cluster Auto",
    "start": "1121520",
    "end": "1124460"
  },
  {
    "text": "scaler and kubrey here's the sequence of",
    "start": "1124460",
    "end": "1127640"
  },
  {
    "text": "events during the rear cluster starting",
    "start": "1127640",
    "end": "1129500"
  },
  {
    "text": "up",
    "start": "1129500",
    "end": "1130460"
  },
  {
    "text": "once the job is accepted by real cluster",
    "start": "1130460",
    "end": "1133220"
  },
  {
    "text": "if the triggers the auto stealer side",
    "start": "1133220",
    "end": "1135260"
  },
  {
    "text": "part to modify customer resource",
    "start": "1135260",
    "end": "1137120"
  },
  {
    "text": "definition of the cluster with",
    "start": "1137120",
    "end": "1139220"
  },
  {
    "text": "additional replicasing worker group",
    "start": "1139220",
    "end": "1142100"
  },
  {
    "text": "and then one additional kubernetes pod",
    "start": "1142100",
    "end": "1144500"
  },
  {
    "text": "will be provisioned by a group array",
    "start": "1144500",
    "end": "1146480"
  },
  {
    "text": "operator during reconciliation process",
    "start": "1146480",
    "end": "1148940"
  },
  {
    "text": "and following the unschedulable Pod",
    "start": "1148940",
    "end": "1150860"
  },
  {
    "text": "events kubernetes Class Auto stealer",
    "start": "1150860",
    "end": "1153500"
  },
  {
    "text": "invoked the ESG API to add the new easy",
    "start": "1153500",
    "end": "1155840"
  },
  {
    "text": "to compute the node at the kubernetes",
    "start": "1155840",
    "end": "1157640"
  },
  {
    "text": "meanings in the end a new worker pod",
    "start": "1157640",
    "end": "1160700"
  },
  {
    "text": "will be scheduled and then join the re",
    "start": "1160700",
    "end": "1162559"
  },
  {
    "text": "cluster as a worker",
    "start": "1162559",
    "end": "1164679"
  },
  {
    "text": "likewise the cluster scaling down follow",
    "start": "1164679",
    "end": "1167480"
  },
  {
    "text": "the similar event sequence but the other",
    "start": "1167480",
    "end": "1170360"
  },
  {
    "text": "way around",
    "start": "1170360",
    "end": "1171980"
  },
  {
    "text": "to sum up the Synergy of these",
    "start": "1171980",
    "end": "1174320"
  },
  {
    "text": "components ensures that our cluster are",
    "start": "1174320",
    "end": "1176600"
  },
  {
    "text": "in Fault steel mode so this setup",
    "start": "1176600",
    "end": "1178700"
  },
  {
    "text": "minimized the resource fragmentation",
    "start": "1178700",
    "end": "1180620"
  },
  {
    "text": "across rate clusters and then enhance",
    "start": "1180620",
    "end": "1183559"
  },
  {
    "text": "the cost efficiency Factor",
    "start": "1183559",
    "end": "1186380"
  },
  {
    "text": "now that we have offered a easy user",
    "start": "1186380",
    "end": "1189080"
  },
  {
    "text": "access to a cost efficient recluster our",
    "start": "1189080",
    "end": "1191720"
  },
  {
    "text": "next step is to ensure the efficiency of",
    "start": "1191720",
    "end": "1194179"
  },
  {
    "text": "each individual rate drop",
    "start": "1194179",
    "end": "1196880"
  },
  {
    "text": "an important factor to consider when we",
    "start": "1196880",
    "end": "1199940"
  },
  {
    "text": "discuss training efficiency is the",
    "start": "1199940",
    "end": "1202100"
  },
  {
    "text": "hardware accelerations and the",
    "start": "1202100",
    "end": "1203780"
  },
  {
    "text": "underlying Network setups uh as we all",
    "start": "1203780",
    "end": "1206600"
  },
  {
    "text": "know that the data parallel based",
    "start": "1206600",
    "end": "1208220"
  },
  {
    "text": "distributive training requires a",
    "start": "1208220",
    "end": "1209960"
  },
  {
    "text": "consistent network communication to sync",
    "start": "1209960",
    "end": "1211940"
  },
  {
    "text": "the gradients at annoyage steps and by",
    "start": "1211940",
    "end": "1214400"
  },
  {
    "text": "adopting deep through the stage 3 based",
    "start": "1214400",
    "end": "1217100"
  },
  {
    "text": "optimization there will be another 50",
    "start": "1217100",
    "end": "1219280"
  },
  {
    "text": "overheads on the overall Networks",
    "start": "1219280",
    "end": "1221660"
  },
  {
    "text": "throughput so enabling High throughput",
    "start": "1221660",
    "end": "1223940"
  },
  {
    "text": "Communication channel across the workers",
    "start": "1223940",
    "end": "1226400"
  },
  {
    "text": "are essential to LM trainings and to",
    "start": "1226400",
    "end": "1229039"
  },
  {
    "text": "achieve this goal we've got the AWS",
    "start": "1229039",
    "end": "1231860"
  },
  {
    "text": "elasticity fabric adapter that supports",
    "start": "1231860",
    "end": "1234440"
  },
  {
    "text": "OS bypassing GPU direct RDMA across",
    "start": "1234440",
    "end": "1237679"
  },
  {
    "text": "physical hosts",
    "start": "1237679",
    "end": "1239000"
  },
  {
    "text": "for example the P4 nodes come with the",
    "start": "1239000",
    "end": "1242059"
  },
  {
    "text": "four-way 100 database per second Channel",
    "start": "1242059",
    "end": "1244480"
  },
  {
    "text": "and most importantly those improvements",
    "start": "1244480",
    "end": "1247340"
  },
  {
    "text": "are fully transparent to the real",
    "start": "1247340",
    "end": "1248840"
  },
  {
    "text": "cluster setup and it's compatible with",
    "start": "1248840",
    "end": "1251360"
  },
  {
    "text": "chrome ml Frameworks like Nvidia and",
    "start": "1251360",
    "end": "1253700"
  },
  {
    "text": "nickel",
    "start": "1253700",
    "end": "1255080"
  },
  {
    "text": "in our offline Benchmark with the Llama",
    "start": "1255080",
    "end": "1257480"
  },
  {
    "text": "V1 model enabling the four-way EFA",
    "start": "1257480",
    "end": "1260360"
  },
  {
    "text": "achieves about six to eight times speed",
    "start": "1260360",
    "end": "1263000"
  },
  {
    "text": "up",
    "start": "1263000",
    "end": "1265179"
  },
  {
    "text": "and having said that let's examine the",
    "start": "1265220",
    "end": "1267860"
  },
  {
    "text": "final achieve the GPU utilization rate",
    "start": "1267860",
    "end": "1270400"
  },
  {
    "text": "with the wonderb Benchmark model here",
    "start": "1270400",
    "end": "1273980"
  },
  {
    "text": "so in this table we train the gbd new",
    "start": "1273980",
    "end": "1276679"
  },
  {
    "text": "ads 20 billion model with array on deep",
    "start": "1276679",
    "end": "1278900"
  },
  {
    "text": "speed stage 3 and by using limited",
    "start": "1278900",
    "end": "1281780"
  },
  {
    "text": "number of gpus like 16 or 32 it's",
    "start": "1281780",
    "end": "1284780"
  },
  {
    "text": "possible to achieve around 150 T flops",
    "start": "1284780",
    "end": "1287299"
  },
  {
    "text": "per a100 GPU and the interim person as",
    "start": "1287299",
    "end": "1291380"
  },
  {
    "text": "the blog post Transformer math 101",
    "start": "1291380",
    "end": "1293659"
  },
  {
    "text": "outlined from your Luther AI they",
    "start": "1293659",
    "end": "1296299"
  },
  {
    "text": "achieved the tflops number is around the",
    "start": "1296299",
    "end": "1298159"
  },
  {
    "text": "180 and this also aligned with other",
    "start": "1298159",
    "end": "1300559"
  },
  {
    "text": "industry standard Solutions like",
    "start": "1300559",
    "end": "1302120"
  },
  {
    "text": "Metatron deep speed",
    "start": "1302120",
    "end": "1304880"
  },
  {
    "text": "here one quick note is that the GPU",
    "start": "1304880",
    "end": "1307460"
  },
  {
    "text": "kernel Fusion optimization strategies",
    "start": "1307460",
    "end": "1310220"
  },
  {
    "text": "like to flash attention can also work",
    "start": "1310220",
    "end": "1312380"
  },
  {
    "text": "with retrainer seamlessly",
    "start": "1312380",
    "end": "1316120"
  },
  {
    "text": "before we proceed let's recap what we've",
    "start": "1317360",
    "end": "1320720"
  },
  {
    "text": "achieved during the rear integration by",
    "start": "1320720",
    "end": "1323360"
  },
  {
    "text": "using the element developments as an",
    "start": "1323360",
    "end": "1325460"
  },
  {
    "text": "example firstly retrain and its wide",
    "start": "1325460",
    "end": "1329240"
  },
  {
    "text": "range of ml framework support like fsdp",
    "start": "1329240",
    "end": "1331760"
  },
  {
    "text": "and deep speed made it possible to train",
    "start": "1331760",
    "end": "1334280"
  },
  {
    "text": "and find two LMS on any expensive gpus",
    "start": "1334280",
    "end": "1338419"
  },
  {
    "text": "certainly by introducing easy user",
    "start": "1338419",
    "end": "1341059"
  },
  {
    "text": "artist apis then really can be",
    "start": "1341059",
    "end": "1343280"
  },
  {
    "text": "seamlessly integrated into our",
    "start": "1343280",
    "end": "1345020"
  },
  {
    "text": "production and our life cycles and in",
    "start": "1345020",
    "end": "1348200"
  },
  {
    "text": "the third equation play well with the",
    "start": "1348200",
    "end": "1350600"
  },
  {
    "text": "cloud native Auto screening strategy so",
    "start": "1350600",
    "end": "1352820"
  },
  {
    "text": "that we can create a full elastic real",
    "start": "1352820",
    "end": "1354799"
  },
  {
    "text": "cluster that minimize idle resources and",
    "start": "1354799",
    "end": "1357440"
  },
  {
    "text": "cluster fragmentation",
    "start": "1357440",
    "end": "1359179"
  },
  {
    "text": "last but not least both hardware and",
    "start": "1359179",
    "end": "1362480"
  },
  {
    "text": "software optimization like RDMA and the",
    "start": "1362480",
    "end": "1365059"
  },
  {
    "text": "Flash attention can enhance retrain long",
    "start": "1365059",
    "end": "1367280"
  },
  {
    "text": "time transparently",
    "start": "1367280",
    "end": "1370360"
  },
  {
    "text": "so this concludes that our integration",
    "start": "1370880",
    "end": "1374059"
  },
  {
    "text": "story in this section but this is just",
    "start": "1374059",
    "end": "1377059"
  },
  {
    "text": "the beginning and there are more",
    "start": "1377059",
    "end": "1379039"
  },
  {
    "text": "exciting projects I'm doing to start off",
    "start": "1379039",
    "end": "1381919"
  },
  {
    "text": "we're investigating 3D model parallelism",
    "start": "1381919",
    "end": "1384200"
  },
  {
    "text": "so this primarily targeted model Beyond",
    "start": "1384200",
    "end": "1386840"
  },
  {
    "text": "30 billion level and involve a pipeline",
    "start": "1386840",
    "end": "1389059"
  },
  {
    "text": "parallelism for internal nodes workers",
    "start": "1389059",
    "end": "1391280"
  },
  {
    "text": "coupled with tensor parallelism for",
    "start": "1391280",
    "end": "1393260"
  },
  {
    "text": "intra-node workers",
    "start": "1393260",
    "end": "1394760"
  },
  {
    "text": "and at the same time we're also",
    "start": "1394760",
    "end": "1396620"
  },
  {
    "text": "assessing the integration of Reserve",
    "start": "1396620",
    "end": "1399320"
  },
  {
    "text": "using Aviary so this is another",
    "start": "1399320",
    "end": "1402200"
  },
  {
    "text": "interesting area that we believe it",
    "start": "1402200",
    "end": "1404120"
  },
  {
    "text": "could potentially save the alarms online",
    "start": "1404120",
    "end": "1406159"
  },
  {
    "text": "serving cost by features like continuous",
    "start": "1406159",
    "end": "1408980"
  },
  {
    "text": "batching",
    "start": "1408980",
    "end": "1410360"
  },
  {
    "text": "lastly we plan to consolidate different",
    "start": "1410360",
    "end": "1413240"
  },
  {
    "text": "training engines like the group flow",
    "start": "1413240",
    "end": "1415400"
  },
  {
    "text": "training operator and creative so that",
    "start": "1415400",
    "end": "1417740"
  },
  {
    "text": "we can minimize the Operational Support",
    "start": "1417740",
    "end": "1419419"
  },
  {
    "text": "burden on infra team",
    "start": "1419419",
    "end": "1422240"
  },
  {
    "text": "so as you can see we have a very",
    "start": "1422240",
    "end": "1424460"
  },
  {
    "text": "exciting journey ahead of us and one",
    "start": "1424460",
    "end": "1426799"
  },
  {
    "text": "thing I've learned throughout the",
    "start": "1426799",
    "end": "1428000"
  },
  {
    "text": "integration process with the Ray and LMC",
    "start": "1428000",
    "end": "1430520"
  },
  {
    "text": "that the open source Community is",
    "start": "1430520",
    "end": "1432500"
  },
  {
    "text": "developing so fast like the foundation",
    "start": "1432500",
    "end": "1435020"
  },
  {
    "text": "LM models and the online serving",
    "start": "1435020",
    "end": "1437240"
  },
  {
    "text": "techniques and fine-tuning strategies",
    "start": "1437240",
    "end": "1439340"
  },
  {
    "text": "are oftentimes shifting on a daily basis",
    "start": "1439340",
    "end": "1442340"
  },
  {
    "text": "so I'm very excited about what's ahead",
    "start": "1442340",
    "end": "1444980"
  },
  {
    "text": "of us and looking forward to engaging",
    "start": "1444980",
    "end": "1446840"
  },
  {
    "text": "more in the open source community",
    "start": "1446840",
    "end": "1450158"
  },
  {
    "text": "thank you",
    "start": "1454039",
    "end": "1455200"
  },
  {
    "text": "we can have a couple of questions",
    "start": "1455200",
    "end": "1459399"
  },
  {
    "text": "from Uber so I have a few questions",
    "start": "1465100",
    "end": "1467659"
  },
  {
    "text": "related to the model parallelism part",
    "start": "1467659",
    "end": "1470240"
  },
  {
    "text": "because we're also working on that part",
    "start": "1470240",
    "end": "1472280"
  },
  {
    "text": "first you mentioned that with deep speed",
    "start": "1472280",
    "end": "1474440"
  },
  {
    "text": "stage 3 and the uh activation checkpoint",
    "start": "1474440",
    "end": "1477860"
  },
  {
    "text": "and other fancy stuff it is possible to",
    "start": "1477860",
    "end": "1480679"
  },
  {
    "text": "scale number of tunable parameters",
    "start": "1480679",
    "end": "1482360"
  },
  {
    "text": "linearly so my questions in your real",
    "start": "1482360",
    "end": "1485480"
  },
  {
    "text": "case did you see the linear scanning",
    "start": "1485480",
    "end": "1488600"
  },
  {
    "text": "happening or actually you see it's below",
    "start": "1488600",
    "end": "1490580"
  },
  {
    "text": "the linear scaling what's your what's",
    "start": "1490580",
    "end": "1491960"
  },
  {
    "text": "your lesson",
    "start": "1491960",
    "end": "1493940"
  },
  {
    "text": "oh yeah that's a great question so in",
    "start": "1493940",
    "end": "1496940"
  },
  {
    "text": "our offline test we're actually very",
    "start": "1496940",
    "end": "1498740"
  },
  {
    "text": "limited by the number of gpus at this",
    "start": "1498740",
    "end": "1501080"
  },
  {
    "text": "point and uh so with the model up to",
    "start": "1501080",
    "end": "1505520"
  },
  {
    "text": "13 billion parameters we are able to run",
    "start": "1505520",
    "end": "1509240"
  },
  {
    "text": "those distributed training tests with",
    "start": "1509240",
    "end": "1511340"
  },
  {
    "text": "the like number of people up to four to",
    "start": "1511340",
    "end": "1513799"
  },
  {
    "text": "eight so the other device number of gpus",
    "start": "1513799",
    "end": "1516140"
  },
  {
    "text": "to 30 plus but we don't get the chance",
    "start": "1516140",
    "end": "1519140"
  },
  {
    "text": "to further like experiment within more",
    "start": "1519140",
    "end": "1522020"
  },
  {
    "text": "number of gpus",
    "start": "1522020",
    "end": "1524980"
  },
  {
    "text": "hi uh thanks for the speech my question",
    "start": "1526760",
    "end": "1529220"
  },
  {
    "text": "is about RDMA so the first one are you",
    "start": "1529220",
    "end": "1531679"
  },
  {
    "text": "using it at Airbnb and",
    "start": "1531679",
    "end": "1534140"
  },
  {
    "text": "if you do what kind of use cases are",
    "start": "1534140",
    "end": "1537740"
  },
  {
    "text": "using it for",
    "start": "1537740",
    "end": "1539900"
  },
  {
    "text": "uh so in our case it's mostly for",
    "start": "1539900",
    "end": "1541820"
  },
  {
    "text": "distributed training like if the like",
    "start": "1541820",
    "end": "1545299"
  },
  {
    "text": "all reduced communication is based on",
    "start": "1545299",
    "end": "1547580"
  },
  {
    "text": "nickel for example those can take",
    "start": "1547580",
    "end": "1549679"
  },
  {
    "text": "advantage of our dma directly",
    "start": "1549679",
    "end": "1553039"
  },
  {
    "text": "does that answer the question",
    "start": "1553039",
    "end": "1556600"
  },
  {
    "text": "uh it's actually at the one layer like",
    "start": "1563600",
    "end": "1566779"
  },
  {
    "text": "below way so retrainer help us schedule",
    "start": "1566779",
    "end": "1569179"
  },
  {
    "text": "all these like parallel workers in that",
    "start": "1569179",
    "end": "1571039"
  },
  {
    "text": "sense right but the retrainer is not",
    "start": "1571039",
    "end": "1574100"
  },
  {
    "text": "opinionated about how the communication",
    "start": "1574100",
    "end": "1576020"
  },
  {
    "text": "channel are created across those workers",
    "start": "1576020",
    "end": "1578679"
  },
  {
    "text": "and for example Ray doesn't solve the or",
    "start": "1578679",
    "end": "1581960"
  },
  {
    "text": "reduce communication like",
    "start": "1581960",
    "end": "1584779"
  },
  {
    "text": "like issues right so that's all handled",
    "start": "1584779",
    "end": "1588080"
  },
  {
    "text": "by one layer below by the Nvidia Nico",
    "start": "1588080",
    "end": "1590900"
  },
  {
    "text": "Library",
    "start": "1590900",
    "end": "1593080"
  },
  {
    "text": "okay thanks for the talk this is Anand",
    "start": "1594620",
    "end": "1596960"
  },
  {
    "text": "from Uber I was wondering have you done",
    "start": "1596960",
    "end": "1598760"
  },
  {
    "text": "any benchmarks between deep speed and",
    "start": "1598760",
    "end": "1601039"
  },
  {
    "text": "fsdp like",
    "start": "1601039",
    "end": "1603580"
  },
  {
    "text": "I I think I've tried both but there's no",
    "start": "1603580",
    "end": "1607340"
  },
  {
    "text": "like of like observable difference",
    "start": "1607340",
    "end": "1610039"
  },
  {
    "text": "between these two at least from our",
    "start": "1610039",
    "end": "1612140"
  },
  {
    "text": "offline benchmarks",
    "start": "1612140",
    "end": "1615100"
  },
  {
    "text": "hi thank you so much for the talk I was",
    "start": "1623779",
    "end": "1626000"
  },
  {
    "text": "curious for the cost optimization of",
    "start": "1626000",
    "end": "1628220"
  },
  {
    "text": "using of gpus and stuff is it just the",
    "start": "1628220",
    "end": "1630140"
  },
  {
    "text": "ephemeral clusters which are leading to",
    "start": "1630140",
    "end": "1632360"
  },
  {
    "text": "cost optimizations are you doing",
    "start": "1632360",
    "end": "1634159"
  },
  {
    "text": "anything on top also to kind of conserve",
    "start": "1634159",
    "end": "1637159"
  },
  {
    "text": "costs and conserve GPU usage Etc",
    "start": "1637159",
    "end": "1640279"
  },
  {
    "text": "uh so yeah for the job facing API we",
    "start": "1640279",
    "end": "1643700"
  },
  {
    "text": "have a resource manager so that's just",
    "start": "1643700",
    "end": "1646039"
  },
  {
    "text": "like one layer of like guardrail before",
    "start": "1646039",
    "end": "1648760"
  },
  {
    "text": "any job that was scheduled or any",
    "start": "1648760",
    "end": "1651260"
  },
  {
    "text": "re-plus or the provision and across",
    "start": "1651260",
    "end": "1654440"
  },
  {
    "text": "different teams and different",
    "start": "1654440",
    "end": "1655460"
  },
  {
    "text": "organizations we have a different level",
    "start": "1655460",
    "end": "1658039"
  },
  {
    "text": "of like Resource Management so that",
    "start": "1658039",
    "end": "1660620"
  },
  {
    "text": "that's like one factor and the other one",
    "start": "1660620",
    "end": "1663200"
  },
  {
    "text": "is yeah we basically rely on the auto",
    "start": "1663200",
    "end": "1665179"
  },
  {
    "text": "scaling feature of the cluster so we",
    "start": "1665179",
    "end": "1667880"
  },
  {
    "text": "don't have idle resources",
    "start": "1667880",
    "end": "1670960"
  },
  {
    "text": "all right another hour Applause for",
    "start": "1671720",
    "end": "1674059"
  },
  {
    "text": "Shaway thank you so much",
    "start": "1674059",
    "end": "1675740"
  },
  {
    "text": "thank you",
    "start": "1675740",
    "end": "1678400"
  }
]
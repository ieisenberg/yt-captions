[
  {
    "text": "hey everyone um the title is introduced uh the transforming ml training at coinbase um we used to use sagemaker",
    "start": "3480",
    "end": "10080"
  },
  {
    "text": "related infra and we move to r i want to tell a story of this uh this is when um",
    "start": "10080",
    "end": "16000"
  },
  {
    "text": "from coinbase yeah um the content of today um we talk about a mission that's",
    "start": "16000",
    "end": "21560"
  },
  {
    "text": "the first thing in coinbase and then talking about ml machine learning at coinbase how we transform the",
    "start": "21560",
    "end": "27800"
  },
  {
    "text": "transformation with d which we improve the speed scale and the efficiency uh",
    "start": "27800",
    "end": "33360"
  },
  {
    "text": "talk about how we do the migration talk about the impact and the future all right the first uh mission in",
    "start": "33360",
    "end": "40840"
  },
  {
    "text": "coinbase we are um the coins based mission is increase of economic freedom in the world and just translate to uh",
    "start": "40840",
    "end": "48680"
  },
  {
    "text": "machine learning training platforms Mission we're uh uh focusing on improved U ml step velocity we're making um sure",
    "start": "48680",
    "end": "57399"
  },
  {
    "text": "ml can build a scalable training model we can um improve the cost",
    "start": "57399",
    "end": "63040"
  },
  {
    "text": "efficiency uh for our training system yeah give you a a short history",
    "start": "63040",
    "end": "69479"
  },
  {
    "text": "of uh a machine learning coinbase probably on could be a story of any fast growing company uh we started um with",
    "start": "69479",
    "end": "77680"
  },
  {
    "text": "the first machine learning model in 2017 we're uh using this um a uh I think it's",
    "start": "77680",
    "end": "82960"
  },
  {
    "text": "at or user uh user risk model which is talking about if your you you should",
    "start": "82960",
    "end": "88920"
  },
  {
    "text": "transfer money to to this suspicious user right and then in 2020 which is the",
    "start": "88920",
    "end": "95159"
  },
  {
    "text": "last bu wrong uh we introduced a a package called easy ml uh which is",
    "start": "95159",
    "end": "100920"
  },
  {
    "text": "helping our machine learning model uh machine learning engineers build the model faster in 2020 uh we also build",
    "start": "100920",
    "end": "108759"
  },
  {
    "text": "our internal feature store 2022 introduced easy tensor which is better",
    "start": "108759",
    "end": "114280"
  },
  {
    "text": "uh suit for our recommendation system or model uh 203 we introduce cbgp as you",
    "start": "114280",
    "end": "120439"
  },
  {
    "text": "can tell the name is about GPT helping internal or external um um chatbot or",
    "start": "120439",
    "end": "127600"
  },
  {
    "text": "internal tooling uh in 2023 Q3 last year exactly the same time we joined Ray 2023",
    "start": "127600",
    "end": "134599"
  },
  {
    "text": "and we we were interested in this tag and we uh decided to um move our train",
    "start": "134599",
    "end": "141080"
  },
  {
    "text": "and serve from uh our in-house solution to Ray and uh by Q2 2024 we finished",
    "start": "141080",
    "end": "148239"
  },
  {
    "text": "everything on machine learning serving to move to Ray and we just finished our",
    "start": "148239",
    "end": "154120"
  },
  {
    "text": "training and batch prediction um migrate everything to Ray um we are also investigating how to use uh Ray for fine",
    "start": "154120",
    "end": "162080"
  },
  {
    "text": "tune and serving that's a brief history of our uh our machine Learning",
    "start": "162080",
    "end": "168959"
  },
  {
    "text": "System um some use cases um are predictive we we just talk more about pric ml um but um some use case like",
    "start": "168959",
    "end": "177360"
  },
  {
    "text": "login atto say uh account take over if your account is stolen you know as there",
    "start": "177360",
    "end": "183480"
  },
  {
    "text": "are a lot of fraud in uh in in in crypto area but uh we we try to block this fund",
    "start": "183480",
    "end": "189560"
  },
  {
    "text": "transfer um withdraws risk and risk of external ethereum and Bitcoin wallet uh",
    "start": "189560",
    "end": "197799"
  },
  {
    "text": "we also have some like notification optimization we have this um asset you might to uh interest you might",
    "start": "197799",
    "end": "204599"
  },
  {
    "text": "interested in asset you you might like or we also have something like uh related CBGB um chat bot or customer",
    "start": "204599",
    "end": "212280"
  },
  {
    "text": "service experience yeah that's um the overview of our machine learning um so talk about",
    "start": "212280",
    "end": "219519"
  },
  {
    "text": "go back to Ray and talk about this improvements or our achievement uh we talk about three areas first is the",
    "start": "219519",
    "end": "226159"
  },
  {
    "text": "iteration speed or da velocity so um in the stage maker based",
    "start": "226159",
    "end": "233720"
  },
  {
    "text": "um area um or the era the um that go",
    "start": "233720",
    "end": "239040"
  },
  {
    "text": "back to before we move to aray um the the we just realized this uh take you a",
    "start": "239040",
    "end": "244640"
  },
  {
    "text": "lot of time to wait and then go to the doing the iteration so the typical flow",
    "start": "244640",
    "end": "250799"
  },
  {
    "text": "here is um the mle machine learning Engineers um make a PR and then build a",
    "start": "250799",
    "end": "257639"
  },
  {
    "text": "Docker and push it to ECR uh because stemer required to have a Docker image",
    "start": "257639",
    "end": "263840"
  },
  {
    "text": "right and then once you have this build and have a ECR link ready you can use",
    "start": "263840",
    "end": "269280"
  },
  {
    "text": "this as a as a link to send to our internal service and then trigger a stagemaker training job uh we just",
    "start": "269280",
    "end": "276919"
  },
  {
    "text": "realized it's take you up to like two hours to to prepare this scene and then see how your job is working that super",
    "start": "276919",
    "end": "285680"
  },
  {
    "text": "slow and it's just crazy sometimes people just think okay maybe I just work on the feature instead of like working",
    "start": "285680",
    "end": "291479"
  },
  {
    "text": "on the model because who knows if my PR will work or not and if I do like three",
    "start": "291479",
    "end": "296840"
  },
  {
    "text": "or four times that's that's how like they have been passed right so why why it has like so long",
    "start": "296840",
    "end": "306120"
  },
  {
    "text": "iteration time first is because sagemaker requires or at least our infra",
    "start": "306120",
    "end": "311680"
  },
  {
    "text": "requires to have a doer image darker image is very heavy component and u i we",
    "start": "311680",
    "end": "318600"
  },
  {
    "text": "think it should be as L as possible but um but do darker image is trying to",
    "start": "318600",
    "end": "324240"
  },
  {
    "text": "build everything inside of it but actually when you are training a model especially when you having like 20",
    "start": "324240",
    "end": "331759"
  },
  {
    "text": "models running on same using the same doer image you probably want to have a separation so ml P platform maybe just",
    "start": "331759",
    "end": "339840"
  },
  {
    "text": "maintain a small one and then people can just use um um their own way to control",
    "start": "339840",
    "end": "346400"
  },
  {
    "text": "like what actually to plug into this doer image but that's it's kind of impossible so if you're looking",
    "start": "346400",
    "end": "354759"
  },
  {
    "text": "um uh the screenshot or the picture um you'll see like in the darker image we",
    "start": "354759",
    "end": "360680"
  },
  {
    "text": "used have like model artifact uh model um python model code right we have all",
    "start": "360680",
    "end": "367479"
  },
  {
    "text": "the U functions we have this peping install list everything is uh on it we",
    "start": "367479",
    "end": "372720"
  },
  {
    "text": "have the Cuda we have the python version we have all of this information but actually what we want to do for machine",
    "start": "372720",
    "end": "378840"
  },
  {
    "text": "learning training is actually very simple one um just do python version",
    "start": "378840",
    "end": "384000"
  },
  {
    "text": "Cuda version and some like 8 best CLI which essential to you know move some",
    "start": "384000",
    "end": "389120"
  },
  {
    "text": "data from S3 other things could be added as a plugin um at the wrong time instead",
    "start": "389120",
    "end": "395840"
  },
  {
    "text": "of like pre-build into the docker image um yeah that's um the actual reason and",
    "start": "395840",
    "end": "402599"
  },
  {
    "text": "how to achieve this um moving to Ray we us this new uh workflow so we can create",
    "start": "402599",
    "end": "410000"
  },
  {
    "text": "a working directory uh with the training logic if you're seeing the screenshot that's you can call a basic ml basic",
    "start": "410000",
    "end": "417000"
  },
  {
    "text": "model.py right uh we can let you to build some local zip file or whe files",
    "start": "417000",
    "end": "422840"
  },
  {
    "text": "and then uh we let you to write a config yo file um using our internal uh CLI",
    "start": "422840",
    "end": "430199"
  },
  {
    "text": "wrapper we can trigger the job using this information very simple",
    "start": "430199",
    "end": "435680"
  },
  {
    "text": "and yeah and give you an example how we do this uh if you're just having a basic",
    "start": "435680",
    "end": "441199"
  },
  {
    "text": "model um just I say this python python and you train a Titanic model uh what do",
    "start": "441199",
    "end": "446639"
  },
  {
    "text": "you need three files a build file this py file and this um config yo file and",
    "start": "446639",
    "end": "452360"
  },
  {
    "text": "you can trigger it immediately and in a snap you can see this running on your um",
    "start": "452360",
    "end": "458520"
  },
  {
    "text": "uh kuber cluster or the the r cluster yeah and then uh after this models",
    "start": "458520",
    "end": "465360"
  },
  {
    "text": "finish the training uh we can push this model artifact to mlflow and then go to the",
    "start": "465360",
    "end": "470400"
  },
  {
    "text": "serving so give you a look of what the yam file looks like uh it's pretty similar to what we have for uh for Ray",
    "start": "470400",
    "end": "478360"
  },
  {
    "text": "yo conf yo file um uh we add this thing called um P module part we let you to",
    "start": "478360",
    "end": "486199"
  },
  {
    "text": "build your local uh wheel file and then add this local wheel files uh to to to",
    "start": "486199",
    "end": "492400"
  },
  {
    "text": "send to remote or we can use this Pine which our our repo called my pance but",
    "start": "492400",
    "end": "497840"
  },
  {
    "text": "basically like um telling like okay what is the remote one which is already checking in the code at and then you can",
    "start": "497840",
    "end": "504960"
  },
  {
    "text": "either use the remote one already checking Master Branch one or you use your local Branch one so your local",
    "start": "504960",
    "end": "511199"
  },
  {
    "text": "branch use your build file to build a local zip file or wheel file and then submit directly you don't need to wait",
    "start": "511199",
    "end": "518120"
  },
  {
    "text": "to say okay go through the whole Loop build uh Docker and then go back right",
    "start": "518120",
    "end": "523959"
  },
  {
    "text": "to have this uh e link to trigger the job so it's super fast it's just like um",
    "start": "523959",
    "end": "529399"
  },
  {
    "text": "if you don't change your code on this like uh wheel file zip file it probably",
    "start": "529399",
    "end": "534560"
  },
  {
    "text": "just take you like a snap like five 5 Seconds to trigger the job if you do need this then depends on how big your",
    "start": "534560",
    "end": "541480"
  },
  {
    "text": "your how big your your files are but um probably just take you two or three minutes because you eventually you",
    "start": "541480",
    "end": "547920"
  },
  {
    "text": "upload this wheel file and let the U the recluster understand",
    "start": "547920",
    "end": "553079"
  },
  {
    "text": "it yeah another thing really can help or re actually helped us is the GCS so um",
    "start": "553079",
    "end": "560560"
  },
  {
    "text": "instead of uh if you trigger a job on stagemaker you probably want to wait a little bit when say okay this is a",
    "start": "560560",
    "end": "567440"
  },
  {
    "text": "Docker file and then put the docker file um create a instance and then install",
    "start": "567440",
    "end": "572760"
  },
  {
    "text": "everything right U into that instance and start it wrong but um we have a a a",
    "start": "572760",
    "end": "579519"
  },
  {
    "text": "long running cluster so all most of our files are cached in this GCS so that's",
    "start": "579519",
    "end": "585600"
  },
  {
    "text": "why you can trigger the job within second instead of like um you need to wait for installation of this pre-build",
    "start": "585600",
    "end": "593760"
  },
  {
    "text": "packages yeah so that's the before after comparison before we took two hours um",
    "start": "593760",
    "end": "599640"
  },
  {
    "text": "for a Syle change most of the time it's just building waiting for doer build um right now we use you know if you need to",
    "start": "599640",
    "end": "607000"
  },
  {
    "text": "make a code change shareed code change you take five five minutes if you're just like loc C your main logic uh",
    "start": "607000",
    "end": "613440"
  },
  {
    "text": "change you just get the result in like 5 Second probably yeah another thing is about",
    "start": "613440",
    "end": "621000"
  },
  {
    "text": "scale um yeah so for sage maker um most likely",
    "start": "621000",
    "end": "628000"
  },
  {
    "text": "Sage maker train job is using using a single instance and our system used to be very heavily based on stit maker",
    "start": "628000",
    "end": "635120"
  },
  {
    "text": "training job so it's always as a single instance um yeah and uh we use some tree",
    "start": "635120",
    "end": "640839"
  },
  {
    "text": "based models um used to use some tree based models for tabular data on the working flow is like this we have the",
    "start": "640839",
    "end": "647360"
  },
  {
    "text": "raw data Maybe from C or fromwhere and then go to spark Snowflake and then",
    "start": "647360",
    "end": "653639"
  },
  {
    "text": "process either dump to S3 or not dump to S3 and pass it to a training job uh and",
    "start": "653639",
    "end": "659839"
  },
  {
    "text": "we do some last mile data transformation say some one encoding or something like",
    "start": "659839",
    "end": "666000"
  },
  {
    "text": "that and then go to machine learning model actually P torch or something cular and then go to ml",
    "start": "666000",
    "end": "672360"
  },
  {
    "text": "flow um the problem is uh single instance is like hor uh vertical scouting not horizontal scouting so um",
    "start": "672360",
    "end": "680920"
  },
  {
    "text": "so definitely you cannot getting more like U memory more than maybe half",
    "start": "680920",
    "end": "686200"
  },
  {
    "text": "terabyte of memory because there's no instance available right um another thing is like what if we just",
    "start": "686200",
    "end": "692279"
  },
  {
    "text": "distribute your job on stage Baker um I think the problem is like stage makers",
    "start": "692279",
    "end": "698000"
  },
  {
    "text": "um distribut training is um basically for tablet it means you need to use py spark so that means you need to build",
    "start": "698000",
    "end": "705279"
  },
  {
    "text": "like two things first is a pie spark to process your data and then dump to",
    "start": "705279",
    "end": "710360"
  },
  {
    "text": "somewhere and then pick it up by a machine learning models like pie torch um yeah that's a you know that's like a",
    "start": "710360",
    "end": "717560"
  },
  {
    "text": "not a single step it's a mod uh multistep",
    "start": "717560",
    "end": "722639"
  },
  {
    "text": "scouting yeah and also um when when we were researching on this distribute job",
    "start": "722639",
    "end": "727680"
  },
  {
    "text": "on S M doesn't support a tree models uh which we we must use um before we might",
    "start": "727680",
    "end": "732720"
  },
  {
    "text": "fully migrate to other models so under this limitation we're um try to use",
    "start": "732720",
    "end": "738959"
  },
  {
    "text": "instance with largest memory uh which introduce huge resource waste because the CPU and GPU they provide with this",
    "start": "738959",
    "end": "747120"
  },
  {
    "text": "memory so basically wasted we don't actually need this we just need this memory to keep our data uh processing",
    "start": "747120",
    "end": "755040"
  },
  {
    "text": "the data what we actually need is horizontal um multi-step",
    "start": "755040",
    "end": "760480"
  },
  {
    "text": "scouting okay so uh moving to Ray um uh the the thing like we use Ray data",
    "start": "760480",
    "end": "767600"
  },
  {
    "text": "to read the data from S3 or data sharing data sharing is open source protocol uh",
    "start": "767600",
    "end": "773600"
  },
  {
    "text": "from database uh we rewrite this easy tensor to make this pre-processing",
    "start": "773600",
    "end": "779800"
  },
  {
    "text": "and um Pi Pi torch training distributed we also rewrite this last mile data transformation using rate data U map",
    "start": "779800",
    "end": "787600"
  },
  {
    "text": "bash function so what we can do right now is we can use TB de uh level of um",
    "start": "787600",
    "end": "793600"
  },
  {
    "text": "tabular data for training we use billions of drows our data size maximum",
    "start": "793600",
    "end": "799199"
  },
  {
    "text": "is like f 50x then previous Max um we use um S3 and data connect data sharing",
    "start": "799199",
    "end": "806880"
  },
  {
    "text": "to connect spark and Ray uh which which spark is for our data processing um we",
    "start": "806880",
    "end": "812720"
  },
  {
    "text": "have cluster with over 70 workers sometimes more uh the last Last Mile",
    "start": "812720",
    "end": "818560"
  },
  {
    "text": "data transformation um dropped from 120 Minutes to 15 minutes because data uh R",
    "start": "818560",
    "end": "823959"
  },
  {
    "text": "data distributed data processing um yeah um so actually we got",
    "start": "823959",
    "end": "830560"
  },
  {
    "text": "a Boton NE um here um say when we are trying to read the data over 100 gab",
    "start": "830560",
    "end": "837320"
  },
  {
    "text": "from spark or from data braks um we realize okay um we just called to say we",
    "start": "837320",
    "end": "844000"
  },
  {
    "text": "we assume we can pass like one terabyte data from from calling the API but using this read data uh read data read data",
    "start": "844000",
    "end": "851480"
  },
  {
    "text": "brakes table but we realize the backhand is um sorted by this databas API only",
    "start": "851480",
    "end": "857440"
  },
  {
    "text": "100 gigabyte data can be passed um and we ask we we directly ask the datab",
    "start": "857440",
    "end": "862639"
  },
  {
    "text": "braas team is possible to let us to pass like one terab data they say no um uh is",
    "start": "862639",
    "end": "869519"
  },
  {
    "text": "impossible so uh we realize okay that's a Bott NE we we must use S3 and then",
    "start": "869519",
    "end": "874880"
  },
  {
    "text": "probably you know when you are doing the transform um dropping the data to sray",
    "start": "874880",
    "end": "879920"
  },
  {
    "text": "and read back to Ray then you have a lot of resource waste maybe if you just forgot to delete the file and you have",
    "start": "879920",
    "end": "887000"
  },
  {
    "text": "like a terabyte data living as3 forever so um so what we do we uh we introduce",
    "start": "887000",
    "end": "892959"
  },
  {
    "text": "this uh R data read dat sharing table this API um just provide your um your",
    "start": "892959",
    "end": "900320"
  },
  {
    "text": "profile I think is called profile in data sharing um and then say how many rols you want uh you could be you know",
    "start": "900320",
    "end": "909079"
  },
  {
    "text": "um one billion row or whatever uh we we achieved this using this one and achieve",
    "start": "909079",
    "end": "915279"
  },
  {
    "text": "the reading 200 gigabyte of data using the API within uh 2 minutes it's pretty fast um the the backand is actually it's",
    "start": "915279",
    "end": "924279"
  },
  {
    "text": "drop it to a temporary s bucket and then pass it read it back so it's it's",
    "start": "924279",
    "end": "930480"
  },
  {
    "text": "so on the surface using API but the back end is actually using some uh reading from the dis and you can use multiple",
    "start": "930480",
    "end": "938279"
  },
  {
    "text": "distributed way to read this so super fast feel free to try after 2 point 33",
    "start": "938279",
    "end": "944519"
  },
  {
    "text": "is available on Ray open source um so before typical cases like we use this P3",
    "start": "944519",
    "end": "951519"
  },
  {
    "text": "16x large um a lot of gpus a lot of CPUs a lot of memories but very very",
    "start": "951519",
    "end": "957079"
  },
  {
    "text": "expensive uh right now we go back to use um G5 x large um a1g GPU so uh it's it's",
    "start": "957079",
    "end": "965880"
  },
  {
    "text": "uh relatively uh cheap compared to before and uh that's uh that's what we have uh",
    "start": "965880",
    "end": "972600"
  },
  {
    "text": "we did some optimization to use data do metrics uh like logical that's the",
    "start": "972600",
    "end": "978480"
  },
  {
    "text": "concept of R logic CPU GPU utilization to guide our kuet to scale for some",
    "start": "978480",
    "end": "983959"
  },
  {
    "text": "reason we cannot use kuay so we use this um hack to use this log CPU GPU",
    "start": "983959",
    "end": "989759"
  },
  {
    "text": "utilization to guide the scale up and down um and we provide a cluster with",
    "start": "989759",
    "end": "995120"
  },
  {
    "text": "different CPU GPU ratio for different cases sometimes as CPU intensive you probably want to have a higher CPU rate",
    "start": "995120",
    "end": "1002519"
  },
  {
    "text": "um then sometimes you just um you know more GPU as a suit your case",
    "start": "1002519",
    "end": "1009480"
  },
  {
    "text": "better uh the last one is uh resource sharing and the cost",
    "start": "1009480",
    "end": "1015160"
  },
  {
    "text": "efficiency um we talk for more about this hyper parameter optimization scene",
    "start": "1015160",
    "end": "1022160"
  },
  {
    "text": "um when we're talking resource sharing so if you see the the graph on the right side um that's how Sage maker or typical",
    "start": "1022160",
    "end": "1030120"
  },
  {
    "text": "machine learning workflow use um um doing the hpo so you read the data first",
    "start": "1030120",
    "end": "1037319"
  },
  {
    "text": "and then do whatever transformation you want and then trigger a p torch orbut training um multiple jobs are",
    "start": "1037319",
    "end": "1045798"
  },
  {
    "text": "running in parallel on different machine and then you you report the result to",
    "start": "1045799",
    "end": "1051480"
  },
  {
    "text": "some like controller and see like which one is getting better performance and then the the the the uh the worst one",
    "start": "1051480",
    "end": "1059640"
  },
  {
    "text": "will be killed right because um this you you assume it won't give you a good",
    "start": "1059640",
    "end": "1064919"
  },
  {
    "text": "result but actually think about this why do you want to read this as refile 10",
    "start": "1064919",
    "end": "1070400"
  },
  {
    "text": "times or 20 times you just need to read them once do the transform formation",
    "start": "1070400",
    "end": "1075640"
  },
  {
    "text": "once and then trigger three jobs that in parallel right that's how uh R tune help us",
    "start": "1075640",
    "end": "1084559"
  },
  {
    "text": "um um yeah so so when we're sending a job to R cluster we will use WR time",
    "start": "1084559",
    "end": "1090640"
  },
  {
    "text": "environment to cach in previous job which is a um sorry um yeah so so when",
    "start": "1090640",
    "end": "1097679"
  },
  {
    "text": "we doing the hyper par optimization it means all this can be shared and we don't need to run this multiple jobs",
    "start": "1097679",
    "end": "1105400"
  },
  {
    "text": "together and you can uh scale it uh when when you go into the training stage",
    "start": "1105400",
    "end": "1110480"
  },
  {
    "text": "instead of like at the early stage you use all the resource um yeah and uh",
    "start": "1110480",
    "end": "1117039"
  },
  {
    "text": "another thing actually for resource sharing is as I said we have the long running cluster we have the scale up and",
    "start": "1117039",
    "end": "1124320"
  },
  {
    "text": "down um the thing is like when you are triggering a a job on single uh on on",
    "start": "1124320",
    "end": "1129880"
  },
  {
    "text": "sagemaker instance or some some other instance you need to wait like 5 to 10 minutes to let it ready for you to to",
    "start": "1129880",
    "end": "1136960"
  },
  {
    "text": "trigger the job but um uh moving to this thing you have all",
    "start": "1136960",
    "end": "1142559"
  },
  {
    "text": "this cached on the GCS so you don't need to wait this long time and you know one job is waiting 10 minutes and what if",
    "start": "1142559",
    "end": "1149320"
  },
  {
    "text": "you have multiple ones that's all saving of your time and improve your",
    "start": "1149320",
    "end": "1155360"
  },
  {
    "text": "efficiency yep that's all the benefits talking about the migration process and",
    "start": "1155360",
    "end": "1161360"
  },
  {
    "text": "results um so what we do we decompose our Docker image into multiple",
    "start": "1161360",
    "end": "1167280"
  },
  {
    "text": "components and then pushing them to our internal piie uh we set up this Ray",
    "start": "1167280",
    "end": "1173000"
  },
  {
    "text": "kubernetes uh Ray clusters on kubernetes and then have all kind of DNS S3 private",
    "start": "1173000",
    "end": "1179039"
  },
  {
    "text": "link whatever connections U for single instance um model training just say you",
    "start": "1179039",
    "end": "1185320"
  },
  {
    "text": "have a job you just want to reproduce whatever you have before uh you just",
    "start": "1185320",
    "end": "1190520"
  },
  {
    "text": "have this array in orray remote and give it um moving to a ray sing Single Ray uh",
    "start": "1190520",
    "end": "1197679"
  },
  {
    "text": "task right and then uh run is re task inside of uh inside of that um uh worker",
    "start": "1197679",
    "end": "1205200"
  },
  {
    "text": "node right um and if you are uh which makes your trans uh transition very fast",
    "start": "1205200",
    "end": "1211520"
  },
  {
    "text": "because you basically just add a add a wrapper outside um and if you thinking",
    "start": "1211520",
    "end": "1217440"
  },
  {
    "text": "okay my model is limited by stage maker I need to do horizontal scaling then you",
    "start": "1217440",
    "end": "1223159"
  },
  {
    "text": "need to reconstruct your data connection like using R data uh then rewrite your",
    "start": "1223159",
    "end": "1229840"
  },
  {
    "text": "data transformation uh rewrite the job using rre um and for HBO it can support",
    "start": "1229840",
    "end": "1236360"
  },
  {
    "text": "both case uh yeah the full migration took us like three quarters is we",
    "start": "1236360",
    "end": "1242760"
  },
  {
    "text": "finished everything and we are actually closing our stagemaker training job this",
    "start": "1242760",
    "end": "1248840"
  },
  {
    "text": "week yeah um some challenges we face",
    "start": "1248840",
    "end": "1253880"
  },
  {
    "text": "during the migration uh some there are many but um um first is um how to scale",
    "start": "1253880",
    "end": "1261440"
  },
  {
    "text": "uh how to do this uh logical CPU GPU job supervisor scaling uh basically you",
    "start": "1261440",
    "end": "1266559"
  },
  {
    "text": "don't want to kill your cluster or remove this instance if if you have like",
    "start": "1266559",
    "end": "1272799"
  },
  {
    "text": "one single R cluster running multiple jobs you don't want to kill uh reduce this number of worker when while there",
    "start": "1272799",
    "end": "1279960"
  },
  {
    "text": "is still one job or two jobs running so you need to use a concept called job supervisor always monitor that one to",
    "start": "1279960",
    "end": "1286919"
  },
  {
    "text": "see okay I only scale down when everything's done otherwise you are just",
    "start": "1286919",
    "end": "1293039"
  },
  {
    "text": "removing something saving in the memory and then you know uh that that's a big problem because you cannot reproduce",
    "start": "1293039",
    "end": "1299760"
  },
  {
    "text": "things maybe you cannot and uh um using this logical CPU GPU which um say you",
    "start": "1299760",
    "end": "1308080"
  },
  {
    "text": "when you are having high logical CPU GPU that means you you you need the resource and into scale right um we have this um",
    "start": "1308080",
    "end": "1316880"
  },
  {
    "text": "problem of reading data from databas so we resolved it by introduce array uh data",
    "start": "1316880",
    "end": "1322520"
  },
  {
    "text": "sharing um yeah and also the MLP and mle",
    "start": "1322520",
    "end": "1328279"
  },
  {
    "text": "ownership separation before is like everything mixed it together right now MLP only maintain this R cluster and the",
    "start": "1328279",
    "end": "1336200"
  },
  {
    "text": "base um the base Docker and ml are",
    "start": "1336200",
    "end": "1341320"
  },
  {
    "text": "responsible for all this customized code and uh and your package like you need to",
    "start": "1341320",
    "end": "1348919"
  },
  {
    "text": "resolve your uh version conflict you can overwrite something but um you need to",
    "start": "1348919",
    "end": "1354400"
  },
  {
    "text": "make sure your code and your pip installed um p uh package versions are",
    "start": "1354400",
    "end": "1359799"
  },
  {
    "text": "aligned um we also introduce some like job status on notification so when you're triggered job once a job status",
    "start": "1359799",
    "end": "1367000"
  },
  {
    "text": "change uh we're just always paying this job and this status change then you got",
    "start": "1367000",
    "end": "1372120"
  },
  {
    "text": "a notification either email or message uh slack message so you can fast uh",
    "start": "1372120",
    "end": "1377799"
  },
  {
    "text": "iterate and just monitor your your job um yeah this is summary of what we",
    "start": "1377799",
    "end": "1383760"
  },
  {
    "text": "have um speed Wise from hours to seconds um size 50x billion row TB",
    "start": "1383760",
    "end": "1390760"
  },
  {
    "text": "data cost we are sharing the resource and even the instance cost dropped by",
    "start": "1390760",
    "end": "1395799"
  },
  {
    "text": "20% because of the Third charge um yeah and this is the our chart from ml flow I",
    "start": "1395799",
    "end": "1402640"
  },
  {
    "text": "made a screenshot so uh you see like before um you see like because of introducing of hpo have a significant",
    "start": "1402640",
    "end": "1409520"
  },
  {
    "text": "High number of model training uh compared to before that's U the benefit of using Ray uh we we used to have uh",
    "start": "1409520",
    "end": "1418400"
  },
  {
    "text": "HBO like setting using Sage maker but that's super super expensive and I we",
    "start": "1418400",
    "end": "1423600"
  },
  {
    "text": "never use it because um someone would come and find out say say stop that's",
    "start": "1423600",
    "end": "1428840"
  },
  {
    "text": "too expensive um yeah and further Improvement future",
    "start": "1428840",
    "end": "1435080"
  },
  {
    "text": "Improvement um we currently we're doing the test uh at the job level but not a",
    "start": "1435080",
    "end": "1441840"
  },
  {
    "text": "task and actor level eventually people uh ml want to just take a look of this",
    "start": "1441840",
    "end": "1447400"
  },
  {
    "text": "actor's Improvement but you don't want to read the data and wait for maybe 20",
    "start": "1447400",
    "end": "1452440"
  },
  {
    "text": "minutes to process or maybe whatever minutes to process this you just want to",
    "start": "1452440",
    "end": "1457559"
  },
  {
    "text": "U pinpoint on this task actor um the CPU GPU efficiency utilization monitoring um",
    "start": "1457559",
    "end": "1465080"
  },
  {
    "text": "and this closers further scale up uh if you CPU a number of CPU and GPU setting",
    "start": "1465080",
    "end": "1471520"
  },
  {
    "text": "we just need to provide some guides to our mle say you need to maybe reduce",
    "start": "1471520",
    "end": "1476760"
  },
  {
    "text": "your number of CPU to fractional maybe 0.1 instead of just using one and also add this LM fine tune",
    "start": "1476760",
    "end": "1484799"
  },
  {
    "text": "support um yeah this is a term we Ed today uh at",
    "start": "1484799",
    "end": "1491000"
  },
  {
    "text": "ECR um sces like this um that's all about what I want to",
    "start": "1491000",
    "end": "1497440"
  },
  {
    "text": "talk about uh today um we are hiring uh mle mlpm Rose um and we got a lot a lot",
    "start": "1497440",
    "end": "1506159"
  },
  {
    "text": "of support from record data retre Community R Jun M ch um Justin uh they",
    "start": "1506159",
    "end": "1515279"
  },
  {
    "text": "provide a lot of um feedbacks guide to us yeah um that that's all um yeah any",
    "start": "1515279",
    "end": "1522520"
  },
  {
    "text": "questions",
    "start": "1522520",
    "end": "1525520"
  },
  {
    "text": "oh yeah question so do you also use R for serving the model uh the question is",
    "start": "1531200",
    "end": "1537120"
  },
  {
    "text": "do use Ray for serving yes we uh moved the our machine learning serving to Ray in Q2 100% that and also I know there's",
    "start": "1537120",
    "end": "1547080"
  },
  {
    "text": "my experience that there are different model training purposes like some just",
    "start": "1547080",
    "end": "1552320"
  },
  {
    "text": "want to try new model sometimes you have established the ret Trend model with",
    "start": "1552320",
    "end": "1557559"
  },
  {
    "text": "some different with some new data like this platform is that more for the first purpose or second",
    "start": "1557559",
    "end": "1564080"
  },
  {
    "text": "purpose um the question is um this R train platform is for uh like",
    "start": "1564080",
    "end": "1571520"
  },
  {
    "text": "experiments um training or some like re reproduce retrain thing right uh I we we",
    "start": "1571520",
    "end": "1579200"
  },
  {
    "text": "don't separate this we all use the same CLI or command to trigger the job it's",
    "start": "1579200",
    "end": "1584799"
  },
  {
    "text": "more depends on how you write airflow de or something or how if you want to train",
    "start": "1584799",
    "end": "1590559"
  },
  {
    "text": "from local or train from airflow scheduled job um we use ml flow to",
    "start": "1590559",
    "end": "1596799"
  },
  {
    "text": "control which job can be us used to um for badge prediction or for U production",
    "start": "1596799",
    "end": "1605398"
  },
  {
    "text": "serving um sorry sorry if I missed it but where do you publish like trained",
    "start": "1606120",
    "end": "1611919"
  },
  {
    "text": "model artifacts when you're done with like an experiment uh the question is where you publish train um",
    "start": "1611919",
    "end": "1619000"
  },
  {
    "text": "model the train model artifacts we publish to mlflow internally",
    "start": "1619000",
    "end": "1626399"
  },
  {
    "text": "hosted yeah I just curious you said that for your kubernetes clustering you use",
    "start": "1626399",
    "end": "1631440"
  },
  {
    "text": "data do metrics or something could you elaborate uh yeah the the question is um",
    "start": "1631440",
    "end": "1637720"
  },
  {
    "text": "are we us U are you using uh data do metrics to uh to um guide the Kuan scale",
    "start": "1637720",
    "end": "1644320"
  },
  {
    "text": "right uh yeah um yes we do um the re is because we have a layer built on top of",
    "start": "1644320",
    "end": "1651919"
  },
  {
    "text": "eks the company infra layer um built on top of eks so you cannot directly touch",
    "start": "1651919",
    "end": "1657679"
  },
  {
    "text": "eks but you must go through this layer uh and um and this layer actually have",
    "start": "1657679",
    "end": "1663559"
  },
  {
    "text": "this dat agent to monitor all of our eks cers so um yes and then we add some",
    "start": "1663559",
    "end": "1671600"
  },
  {
    "text": "customization collabor with our infro team to say um what is the some custom",
    "start": "1671600",
    "end": "1678840"
  },
  {
    "text": "well so we we actually pushing this lot data um this Matrix to data dog right",
    "start": "1678840",
    "end": "1686000"
  },
  {
    "text": "and then when we are guiding this uh cluster to scale we can use this custom",
    "start": "1686000",
    "end": "1691919"
  },
  {
    "text": "feature um back to um HP uh what's called U uh HPA horizontal P Auto",
    "start": "1691919",
    "end": "1700679"
  },
  {
    "text": "scaling so that's a collaboration yeah um this one question remember like",
    "start": "1700679",
    "end": "1709399"
  },
  {
    "text": "talk about the migration works so how many used to be you",
    "start": "1709399",
    "end": "1717360"
  },
  {
    "text": "do and do you mean like how many engineers in my team to help this many",
    "start": "1717559",
    "end": "1725600"
  },
  {
    "text": "tal so how do you do for",
    "start": "1732880",
    "end": "1738760"
  },
  {
    "text": "servic oh um how the question is how many models or Engineers are working on",
    "start": "1740559",
    "end": "1747320"
  },
  {
    "text": "model trainings we have 20 10 15ish engineer working on the traditional ml",
    "start": "1747320",
    "end": "1754440"
  },
  {
    "text": "models um how we achieve this I I said we if you just need to reproduce your",
    "start": "1754440",
    "end": "1760600"
  },
  {
    "text": "model what do you need is basically add a radar remote on your out side of your model right that that migration is",
    "start": "1760600",
    "end": "1767000"
  },
  {
    "text": "pretty simple um but if you want to have your model performance better then you",
    "start": "1767000",
    "end": "1772159"
  },
  {
    "text": "need to rewrite your code so we we just ask them to move because the cost is so",
    "start": "1772159",
    "end": "1777399"
  },
  {
    "text": "high yeah um yes did you get any bottlenecks",
    "start": "1777399",
    "end": "1783720"
  },
  {
    "text": "migrating The Last Mile transformations to Ray data I think some operations",
    "start": "1783720",
    "end": "1789000"
  },
  {
    "text": "weren't as performant as they have been previously um the question is um do you have any Bott NE um moving your as my",
    "start": "1789000",
    "end": "1796880"
  },
  {
    "text": "data transformation from uh Sage maker to Ray um there are a lot um so we we have",
    "start": "1796880",
    "end": "1805640"
  },
  {
    "text": "couple of hundreds of lot M data transform functions um they're not Implement um the same way so um most of",
    "start": "1805640",
    "end": "1814519"
  },
  {
    "text": "them are similar So I myself write rewrite all most of them myself um try",
    "start": "1814519",
    "end": "1822640"
  },
  {
    "text": "to yeah for map batch uh you need to make sure it's like always using panders",
    "start": "1822640",
    "end": "1828000"
  },
  {
    "text": "or nonp to do this because vectorization rewrite them and then set",
    "start": "1828000",
    "end": "1834000"
  },
  {
    "text": "up a example if you have something you want to trans uh you want to migrate then for for large models right uh you",
    "start": "1834000",
    "end": "1841159"
  },
  {
    "text": "need to rewrite your leftover functions but yeah that's a lot of work we have",
    "start": "1841159",
    "end": "1847080"
  },
  {
    "text": "done on this migration you mention that you Mo to you",
    "start": "1847080",
    "end": "1853880"
  },
  {
    "text": "don't need to do anys you can just help the job on that",
    "start": "1853880",
    "end": "1861600"
  },
  {
    "text": "that um the question here is um because we remove this PR request is that",
    "start": "1864840",
    "end": "1873000"
  },
  {
    "text": "possible we just push whatever model or whatever things to production um",
    "start": "1873000",
    "end": "1879399"
  },
  {
    "text": "actually no uh the reason is we use uh we used to use PR to frontload the",
    "start": "1879399",
    "end": "1885399"
  },
  {
    "text": "control right um but when we are moving this you know security and this",
    "start": "1885399",
    "end": "1891519"
  },
  {
    "text": "convenience is always conflict right so we move this control to the ml flow",
    "start": "1891519",
    "end": "1896960"
  },
  {
    "text": "layer so you can drop a lot of things to ml flow but when you are deploying through racer you must get a PR and you",
    "start": "1896960",
    "end": "1904480"
  },
  {
    "text": "you must have show me this link and show okay this is a triggered from a production pipeline inad from your local",
    "start": "1904480",
    "end": "1912240"
  },
  {
    "text": "do that make sense yeah oh question uh so the",
    "start": "1912240",
    "end": "1918720"
  },
  {
    "text": "pre-processing on existing data set makes sense did you guys also Lage the",
    "start": "1918720",
    "end": "1924360"
  },
  {
    "text": "data pipelines to build dat something",
    "start": "1924360",
    "end": "1931278"
  },
  {
    "text": "toist um the question is do you U preist some of your data transformation thing",
    "start": "1931559",
    "end": "1939120"
  },
  {
    "text": "um we do some of them but not at the data transformation part because you",
    "start": "1939120",
    "end": "1946039"
  },
  {
    "text": "read the data and you base on reading you process it but we do some",
    "start": "1946039",
    "end": "1952919"
  },
  {
    "text": "encoding um process so say you transer your your model is using some special",
    "start": "1952919",
    "end": "1959240"
  },
  {
    "text": "encodings like text encoding um you only train once and then you dump it to S3 so",
    "start": "1959240",
    "end": "1965120"
  },
  {
    "text": "next time you are training this one you pick up this artifact this this weights",
    "start": "1965120",
    "end": "1970320"
  },
  {
    "text": "something like that and then go back you don't need and you just fix this uh parameters this portion of parameters in",
    "start": "1970320",
    "end": "1976240"
  },
  {
    "text": "your model um so that's even speed up your training",
    "start": "1976240",
    "end": "1983159"
  },
  {
    "text": "pipeline model um the phot up question is",
    "start": "1989320",
    "end": "1997679"
  },
  {
    "text": "um um Can can you repeat your question sorry I was just like preparing the data",
    "start": "1997679",
    "end": "2003279"
  },
  {
    "text": "and having it saved for I don't know if it's like a long list of Co",
    "start": "2003279",
    "end": "2009760"
  },
  {
    "text": "uh oh I I see um um the question is like do you keep this data Pipeline on Ray we",
    "start": "2017039",
    "end": "2023760"
  },
  {
    "text": "most of our data processing is actually on either on like Legacy one is on Snowflake and we moved a lot of them to",
    "start": "2023760",
    "end": "2030760"
  },
  {
    "text": "data brakes um for so yeah your your processing is ons spark and then use",
    "start": "2030760",
    "end": "2036880"
  },
  {
    "text": "data sharing to",
    "start": "2036880",
    "end": "2040240"
  },
  {
    "text": "job um the question is why you move from Snowflake to data brakes um um we we the",
    "start": "2045559",
    "end": "2053240"
  },
  {
    "text": "the reason not first Spark is we think spark is faster and we are R we we rol",
    "start": "2053240",
    "end": "2060440"
  },
  {
    "text": "many um low efficiency sequels on on on snowflake but I I cannot speak too much",
    "start": "2060440",
    "end": "2066878"
  },
  {
    "text": "on this is a another part of this work um but we another reason is we are using",
    "start": "2066879",
    "end": "2072480"
  },
  {
    "text": "another uh using a feature store vendor which help us to move a little bit more on um future store and they have a lot",
    "start": "2072480",
    "end": "2079679"
  },
  {
    "text": "of features uh like um you know features from from from this Vander",
    "start": "2079679",
    "end": "2086760"
  },
  {
    "text": "yes um I think question yeah maybe uh if you have question here yeah right thanks",
    "start": "2086760",
    "end": "2096800"
  }
]
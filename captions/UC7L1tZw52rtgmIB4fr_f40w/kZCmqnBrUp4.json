[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "my name is clark zinzo i'm a software",
    "start": "0",
    "end": "2159"
  },
  {
    "text": "engineer at descartes labs",
    "start": "2159",
    "end": "4000"
  },
  {
    "text": "and today i'm going to be giving a talk",
    "start": "4000",
    "end": "6080"
  },
  {
    "text": "on a desk",
    "start": "6080",
    "end": "7359"
  },
  {
    "text": "and ray integration that i contributed",
    "start": "7359",
    "end": "10240"
  },
  {
    "text": "to",
    "start": "10240",
    "end": "10800"
  },
  {
    "text": "upstream ray and the company that i work",
    "start": "10800",
    "end": "14000"
  },
  {
    "text": "for at descartes labs has been using",
    "start": "14000",
    "end": "15519"
  },
  {
    "text": "this internally",
    "start": "15519",
    "end": "17039"
  },
  {
    "text": "to offer a a massively scalable",
    "start": "17039",
    "end": "20400"
  },
  {
    "text": "geospatial data analytics product",
    "start": "20400",
    "end": "23439"
  },
  {
    "text": "that allows remote sensing scientists",
    "start": "23439",
    "end": "26160"
  },
  {
    "text": "data scientists",
    "start": "26160",
    "end": "27439"
  },
  {
    "text": "to analyze petabytes of remote sensing",
    "start": "27439",
    "end": "30800"
  },
  {
    "text": "imagery and vector data",
    "start": "30800",
    "end": "33040"
  },
  {
    "text": "and scaling up their computations to",
    "start": "33040",
    "end": "35040"
  },
  {
    "text": "tens of thousands of cores",
    "start": "35040",
    "end": "36880"
  },
  {
    "text": "lots of fun a brief overview of the talk",
    "start": "36880",
    "end": "41760"
  },
  {
    "start": "38000",
    "end": "38000"
  },
  {
    "text": "i'm going to give an overview of the",
    "start": "41760",
    "end": "43520"
  },
  {
    "text": "desk ecosystem",
    "start": "43520",
    "end": "44960"
  },
  {
    "text": "and the desk distributed which is a",
    "start": "44960",
    "end": "47920"
  },
  {
    "text": "particular task execution framework and",
    "start": "47920",
    "end": "50239"
  },
  {
    "text": "scheduler for desk",
    "start": "50239",
    "end": "52239"
  },
  {
    "text": "i'm going to go into some of the",
    "start": "52239",
    "end": "54239"
  },
  {
    "text": "pitfalls of the das distributed systems",
    "start": "54239",
    "end": "56399"
  },
  {
    "text": "architecture",
    "start": "56399",
    "end": "57520"
  },
  {
    "text": "especially for the date production data",
    "start": "57520",
    "end": "60079"
  },
  {
    "text": "analytics",
    "start": "60079",
    "end": "60879"
  },
  {
    "text": "use case i'm going to give an overview",
    "start": "60879",
    "end": "64000"
  },
  {
    "text": "of ray's programming model",
    "start": "64000",
    "end": "65518"
  },
  {
    "text": "and briefly talk about ray's",
    "start": "65519",
    "end": "67040"
  },
  {
    "text": "architecture",
    "start": "67040",
    "end": "68960"
  },
  {
    "text": "i'm going to describe the dascon ray",
    "start": "68960",
    "end": "71280"
  },
  {
    "text": "integration",
    "start": "71280",
    "end": "72799"
  },
  {
    "text": "and i'm going to demo and talk about",
    "start": "72799",
    "end": "75920"
  },
  {
    "text": "uh the massively scalable geospatial",
    "start": "75920",
    "end": "78479"
  },
  {
    "text": "analysis product",
    "start": "78479",
    "end": "79520"
  },
  {
    "text": "workflows that descartes labs has been",
    "start": "79520",
    "end": "81119"
  },
  {
    "text": "developing and how exactly it uses dask",
    "start": "81119",
    "end": "83840"
  },
  {
    "text": "and ray so first what is desk",
    "start": "83840",
    "end": "87040"
  },
  {
    "text": "for those that don't know desk is a",
    "start": "87040",
    "end": "89920"
  },
  {
    "text": "parallel computing library for python",
    "start": "89920",
    "end": "92720"
  },
  {
    "text": "very much so geared towards scalable",
    "start": "92720",
    "end": "95200"
  },
  {
    "text": "data analytics",
    "start": "95200",
    "end": "97680"
  },
  {
    "text": "and desk integrates very nicely with",
    "start": "97680",
    "end": "100079"
  },
  {
    "text": "like the python data science ecosystem",
    "start": "100079",
    "end": "102479"
  },
  {
    "text": "by providing these nd array and data",
    "start": "102479",
    "end": "104560"
  },
  {
    "text": "frame abstractions",
    "start": "104560",
    "end": "105920"
  },
  {
    "text": "that extend the very familiar interfaces",
    "start": "105920",
    "end": "108320"
  },
  {
    "text": "of numpy and pandas",
    "start": "108320",
    "end": "110000"
  },
  {
    "text": "that if you've ever done python data",
    "start": "110000",
    "end": "112320"
  },
  {
    "text": "science or",
    "start": "112320",
    "end": "113200"
  },
  {
    "text": "python you know machine learning if you",
    "start": "113200",
    "end": "115759"
  },
  {
    "text": "ever did research as a scientist",
    "start": "115759",
    "end": "117360"
  },
  {
    "text": "i'm sure you're very familiar with those",
    "start": "117360",
    "end": "118719"
  },
  {
    "text": "interfaces but unfortunately those",
    "start": "118719",
    "end": "120240"
  },
  {
    "text": "interfaces",
    "start": "120240",
    "end": "121360"
  },
  {
    "text": "uh are to a library that's generally",
    "start": "121360",
    "end": "124479"
  },
  {
    "text": "built for",
    "start": "124479",
    "end": "125759"
  },
  {
    "text": "in-core single machine workloads",
    "start": "125759",
    "end": "129840"
  },
  {
    "text": "and desk provides those same interfaces",
    "start": "129840",
    "end": "133440"
  },
  {
    "text": "but under the hood it will partition",
    "start": "133440",
    "end": "134959"
  },
  {
    "text": "data",
    "start": "134959",
    "end": "135840"
  },
  {
    "text": "and it will farm underlying tasks on",
    "start": "135840",
    "end": "138879"
  },
  {
    "text": "that partition data",
    "start": "138879",
    "end": "140959"
  },
  {
    "text": "out to multiple cores or out to multiple",
    "start": "140959",
    "end": "143360"
  },
  {
    "text": "machines",
    "start": "143360",
    "end": "144239"
  },
  {
    "text": "enabling larger than memory workloads",
    "start": "144239",
    "end": "146560"
  },
  {
    "text": "and enabling you to run",
    "start": "146560",
    "end": "148319"
  },
  {
    "text": "your nd rare data frame data analysis",
    "start": "148319",
    "end": "151760"
  },
  {
    "text": "on a distributed environment on a",
    "start": "151760",
    "end": "154840"
  },
  {
    "text": "cluster",
    "start": "154840",
    "end": "156080"
  },
  {
    "text": "brief overview of the das collections",
    "start": "156080",
    "end": "158959"
  },
  {
    "text": "and the broader ecosystem",
    "start": "158959",
    "end": "160879"
  },
  {
    "text": "desk arrays mimic the very familiar",
    "start": "160879",
    "end": "163440"
  },
  {
    "text": "numpy api",
    "start": "163440",
    "end": "165120"
  },
  {
    "text": "the desk data frames abstraction mimics",
    "start": "165120",
    "end": "167519"
  },
  {
    "text": "the pandas api",
    "start": "167519",
    "end": "169519"
  },
  {
    "text": "the pandas data frame api desk ml",
    "start": "169519",
    "end": "172640"
  },
  {
    "text": "implements the scikit learn api and that",
    "start": "172640",
    "end": "175760"
  },
  {
    "text": "allows you to do very basic model",
    "start": "175760",
    "end": "177360"
  },
  {
    "text": "training and inference on desk",
    "start": "177360",
    "end": "180800"
  },
  {
    "text": "and then desk bags mimic the familiar",
    "start": "181040",
    "end": "185200"
  },
  {
    "text": "pi spark apis and then if you're",
    "start": "185200",
    "end": "186959"
  },
  {
    "text": "familiar with iterators or the python",
    "start": "186959",
    "end": "189280"
  },
  {
    "text": "specific tools library",
    "start": "189280",
    "end": "191760"
  },
  {
    "text": "desk bags offer a very",
    "start": "191760",
    "end": "194879"
  },
  {
    "text": "very familiar api to those very similar",
    "start": "194879",
    "end": "198000"
  },
  {
    "start": "197000",
    "end": "197000"
  },
  {
    "text": "api desk has three big core components",
    "start": "198000",
    "end": "202000"
  },
  {
    "text": "uh the nice stratified layers that we",
    "start": "202000",
    "end": "204959"
  },
  {
    "text": "can talk about",
    "start": "204959",
    "end": "206000"
  },
  {
    "text": "there are the collections abstractions",
    "start": "206000",
    "end": "208400"
  },
  {
    "text": "these mimic the interfaces of those",
    "start": "208400",
    "end": "210000"
  },
  {
    "text": "popular data science libraries that i",
    "start": "210000",
    "end": "211599"
  },
  {
    "text": "just mentioned",
    "start": "211599",
    "end": "212400"
  },
  {
    "text": "there is also the desk delayed concept",
    "start": "212400",
    "end": "214799"
  },
  {
    "text": "which allows you to wrap",
    "start": "214799",
    "end": "216879"
  },
  {
    "text": "custom arbitrary functions so that's",
    "start": "216879",
    "end": "219760"
  },
  {
    "text": "that gives",
    "start": "219760",
    "end": "220560"
  },
  {
    "text": "a ton of flexibility there's the task",
    "start": "220560",
    "end": "223440"
  },
  {
    "text": "graph specification",
    "start": "223440",
    "end": "224959"
  },
  {
    "text": "and that's for representing the",
    "start": "224959",
    "end": "226720"
  },
  {
    "text": "imperative operations",
    "start": "226720",
    "end": "228000"
  },
  {
    "text": "on those collection abstractions as a",
    "start": "228000",
    "end": "230799"
  },
  {
    "text": "dag of function application tasks under",
    "start": "230799",
    "end": "232959"
  },
  {
    "text": "the hood",
    "start": "232959",
    "end": "233599"
  },
  {
    "text": "you can think of that task graph either",
    "start": "233599",
    "end": "235760"
  },
  {
    "text": "as like a you know a",
    "start": "235760",
    "end": "237439"
  },
  {
    "text": "bunch of tasks that are just simple",
    "start": "237439",
    "end": "239519"
  },
  {
    "text": "python function applications",
    "start": "239519",
    "end": "241280"
  },
  {
    "text": "and you can also think of it as like a",
    "start": "241280",
    "end": "242879"
  },
  {
    "text": "data flow graph of",
    "start": "242879",
    "end": "244560"
  },
  {
    "text": "data flowing through operator nodes in",
    "start": "244560",
    "end": "247280"
  },
  {
    "text": "the graph",
    "start": "247280",
    "end": "248239"
  },
  {
    "text": "and then there is of course schedulers",
    "start": "248239",
    "end": "250720"
  },
  {
    "text": "and execution backends",
    "start": "250720",
    "end": "252319"
  },
  {
    "text": "for executing that actual uh for",
    "start": "252319",
    "end": "254720"
  },
  {
    "text": "actually executing that task graph",
    "start": "254720",
    "end": "256959"
  },
  {
    "text": "uh and that allows you to execute a",
    "start": "256959",
    "end": "259519"
  },
  {
    "text": "standardized",
    "start": "259519",
    "end": "260320"
  },
  {
    "text": "graph spec uh either on a single core",
    "start": "260320",
    "end": "264000"
  },
  {
    "text": "multiple cores uh or even multiple",
    "start": "264000",
    "end": "266400"
  },
  {
    "text": "machines across the clustered machines",
    "start": "266400",
    "end": "269360"
  },
  {
    "start": "269000",
    "end": "269000"
  },
  {
    "text": "the task the das task graph",
    "start": "269360",
    "end": "272080"
  },
  {
    "text": "specification is pretty simple",
    "start": "272080",
    "end": "274160"
  },
  {
    "text": "uh first of all the task graph it just",
    "start": "274160",
    "end": "276479"
  },
  {
    "text": "captures data dependencies of graphs",
    "start": "276479",
    "end": "279600"
  },
  {
    "text": "each node in the graph represents an",
    "start": "279600",
    "end": "282080"
  },
  {
    "text": "operation",
    "start": "282080",
    "end": "282800"
  },
  {
    "text": "which is a it's just a python function",
    "start": "282800",
    "end": "285280"
  },
  {
    "text": "and then each edge represents a data",
    "start": "285280",
    "end": "287120"
  },
  {
    "text": "dependency between",
    "start": "287120",
    "end": "288320"
  },
  {
    "text": "two operations and uh it's just",
    "start": "288320",
    "end": "291600"
  },
  {
    "text": "represented in memory as a simple python",
    "start": "291600",
    "end": "294840"
  },
  {
    "text": "dictionary",
    "start": "294840",
    "end": "296240"
  },
  {
    "start": "295000",
    "end": "295000"
  },
  {
    "text": "as for actually scheduling and execution",
    "start": "296240",
    "end": "298639"
  },
  {
    "text": "and executing these tasks",
    "start": "298639",
    "end": "300800"
  },
  {
    "text": "uh desk will schedule these tasks for",
    "start": "300800",
    "end": "303840"
  },
  {
    "text": "execution on one or more cores",
    "start": "303840",
    "end": "306479"
  },
  {
    "text": "or and or on one or more machines",
    "start": "306479",
    "end": "310479"
  },
  {
    "text": "they provide several scheduler options",
    "start": "310479",
    "end": "312400"
  },
  {
    "text": "out of the box there is primarily a",
    "start": "312400",
    "end": "314240"
  },
  {
    "text": "delay",
    "start": "314240",
    "end": "314800"
  },
  {
    "text": "delineation between the very simple",
    "start": "314800",
    "end": "317840"
  },
  {
    "text": "local schedulers",
    "start": "317840",
    "end": "318960"
  },
  {
    "text": "that will execute on a single node and",
    "start": "318960",
    "end": "321600"
  },
  {
    "text": "there are three big ones there is the",
    "start": "321600",
    "end": "323199"
  },
  {
    "text": "synchronous scheduler that executes",
    "start": "323199",
    "end": "324880"
  },
  {
    "text": "tasks serially",
    "start": "324880",
    "end": "326240"
  },
  {
    "text": "there's the multi-threaded scheduler",
    "start": "326240",
    "end": "328000"
  },
  {
    "text": "that will execute tasks over a thread",
    "start": "328000",
    "end": "329600"
  },
  {
    "text": "pool",
    "start": "329600",
    "end": "330320"
  },
  {
    "text": "and then there's the multi-processing",
    "start": "330320",
    "end": "331680"
  },
  {
    "text": "scheduler that will execute tasks on a",
    "start": "331680",
    "end": "333680"
  },
  {
    "text": "pool of processes",
    "start": "333680",
    "end": "335520"
  },
  {
    "text": "most uses of the local scheduler will",
    "start": "335520",
    "end": "338880"
  },
  {
    "text": "use a multi-threaded scheduler",
    "start": "338880",
    "end": "340880"
  },
  {
    "text": "uh but the multi-processing scheduler",
    "start": "340880",
    "end": "342800"
  },
  {
    "text": "could be good for tasks that will not",
    "start": "342800",
    "end": "344479"
  },
  {
    "text": "release the gill",
    "start": "344479",
    "end": "345759"
  },
  {
    "text": "but most things that do like either uh",
    "start": "345759",
    "end": "348800"
  },
  {
    "text": "that either do like io",
    "start": "348800",
    "end": "350400"
  },
  {
    "text": "or that call into libraries like numpy",
    "start": "350400",
    "end": "353840"
  },
  {
    "text": "and pandas that will release the gill as",
    "start": "353840",
    "end": "357120"
  },
  {
    "text": "soon as it leaves python land and goes",
    "start": "357120",
    "end": "358880"
  },
  {
    "text": "into cython and sealand",
    "start": "358880",
    "end": "362240"
  },
  {
    "text": "and then there are two forms of the",
    "start": "362319",
    "end": "365280"
  },
  {
    "text": "distributed scheduler",
    "start": "365280",
    "end": "366720"
  },
  {
    "text": "there's the local version can be run",
    "start": "366720",
    "end": "368960"
  },
  {
    "text": "locally which is advantageous because",
    "start": "368960",
    "end": "370319"
  },
  {
    "text": "it's pretty smart",
    "start": "370319",
    "end": "371520"
  },
  {
    "text": "and then there's the uh it can be run on",
    "start": "371520",
    "end": "374639"
  },
  {
    "text": "a cluster",
    "start": "374639",
    "end": "375280"
  },
  {
    "text": "where there is a single global",
    "start": "375280",
    "end": "377600"
  },
  {
    "text": "distributed scheduler",
    "start": "377600",
    "end": "379280"
  },
  {
    "text": "and there's a single global scheduler",
    "start": "379280",
    "end": "381600"
  },
  {
    "text": "that is then able to distribute work",
    "start": "381600",
    "end": "383840"
  },
  {
    "text": "to multiple nodes and it's for executing",
    "start": "383840",
    "end": "386080"
  },
  {
    "text": "tasks on the cluster machines",
    "start": "386080",
    "end": "387520"
  },
  {
    "text": "and as soon as you want as soon as you",
    "start": "387520",
    "end": "390479"
  },
  {
    "text": "well really need",
    "start": "390479",
    "end": "391919"
  },
  {
    "text": "to go to uh distributed execution the",
    "start": "391919",
    "end": "395039"
  },
  {
    "text": "distributed scheduler must be used",
    "start": "395039",
    "end": "396720"
  },
  {
    "text": "that's the primary and really only",
    "start": "396720",
    "end": "399199"
  },
  {
    "text": "option in the desk ecosystem right now",
    "start": "399199",
    "end": "401280"
  },
  {
    "text": "now there are a couple of pitfalls of",
    "start": "401280",
    "end": "403280"
  },
  {
    "start": "402000",
    "end": "402000"
  },
  {
    "text": "das distributed particularly for the",
    "start": "403280",
    "end": "404880"
  },
  {
    "text": "production data analytics use case",
    "start": "404880",
    "end": "407360"
  },
  {
    "text": "that global schedule is both a",
    "start": "407360",
    "end": "409039"
  },
  {
    "text": "performance bottleneck and a single",
    "start": "409039",
    "end": "410639"
  },
  {
    "text": "point of failure",
    "start": "410639",
    "end": "412240"
  },
  {
    "text": "which is not nice there's no schedule or",
    "start": "412240",
    "end": "414400"
  },
  {
    "text": "fault tolerance yet",
    "start": "414400",
    "end": "415680"
  },
  {
    "text": "um there's no like uh there's no like",
    "start": "415680",
    "end": "418080"
  },
  {
    "text": "follower leader",
    "start": "418080",
    "end": "419280"
  },
  {
    "text": "pattern um if the if the global",
    "start": "419280",
    "end": "422560"
  },
  {
    "text": "scheduler goes down",
    "start": "422560",
    "end": "424000"
  },
  {
    "text": "you'll lose all like in progress tasks",
    "start": "424000",
    "end": "427759"
  },
  {
    "text": "and uh and you'll have essentially have",
    "start": "427759",
    "end": "430319"
  },
  {
    "text": "to like restart the cluster",
    "start": "430319",
    "end": "432560"
  },
  {
    "text": "uh maintenance and introspection of like",
    "start": "432560",
    "end": "435120"
  },
  {
    "text": "the cluster and task skate",
    "start": "435120",
    "end": "436639"
  },
  {
    "text": "task state adds to the task scheduling",
    "start": "436639",
    "end": "439360"
  },
  {
    "text": "overhead",
    "start": "439360",
    "end": "440000"
  },
  {
    "text": "which is not great so if you're looking",
    "start": "440000",
    "end": "441599"
  },
  {
    "text": "at the dashboard that can decrease the",
    "start": "441599",
    "end": "443520"
  },
  {
    "text": "scheduling throughput",
    "start": "443520",
    "end": "445840"
  },
  {
    "text": "um the schedule is written in python and",
    "start": "445840",
    "end": "447520"
  },
  {
    "text": "so naturally it herons it inherits",
    "start": "447520",
    "end": "449520"
  },
  {
    "text": "a lot of python's performance",
    "start": "449520",
    "end": "450720"
  },
  {
    "text": "characteristics and resource footprint",
    "start": "450720",
    "end": "452720"
  },
  {
    "text": "aka can be bad and suffer from bloated",
    "start": "452720",
    "end": "455759"
  },
  {
    "text": "uh memory utilization for example",
    "start": "455759",
    "end": "458880"
  },
  {
    "text": "it can't be natively or naively scaled",
    "start": "458880",
    "end": "462400"
  },
  {
    "text": "you'd have to resort to sharding",
    "start": "462400",
    "end": "463680"
  },
  {
    "text": "schedulers which for right now",
    "start": "463680",
    "end": "466240"
  },
  {
    "text": "uh will be equivalent to sharding uh",
    "start": "466240",
    "end": "469440"
  },
  {
    "text": "entire desk clusters so uh if you",
    "start": "469440",
    "end": "472879"
  },
  {
    "text": "have a cold shard for example one that's",
    "start": "472879",
    "end": "475680"
  },
  {
    "text": "a lot of architectural complexity",
    "start": "475680",
    "end": "477280"
  },
  {
    "text": "a lot of infrastructural complexity to",
    "start": "477280",
    "end": "478960"
  },
  {
    "text": "add and then if you have",
    "start": "478960",
    "end": "481440"
  },
  {
    "text": "a cold shard you then might have a lot",
    "start": "481440",
    "end": "483680"
  },
  {
    "text": "of wasted worker resources where a lot",
    "start": "483680",
    "end": "485440"
  },
  {
    "text": "of like",
    "start": "485440",
    "end": "486000"
  },
  {
    "text": "a cluster of workers will just be",
    "start": "486000",
    "end": "487440"
  },
  {
    "text": "sitting there because they are not",
    "start": "487440",
    "end": "489360"
  },
  {
    "text": "uh they are not getting hit very often",
    "start": "489360",
    "end": "492240"
  },
  {
    "text": "in the sharding pattern",
    "start": "492240",
    "end": "494319"
  },
  {
    "text": "the clients are generally designed for",
    "start": "494319",
    "end": "495759"
  },
  {
    "text": "end users not really for like a large",
    "start": "495759",
    "end": "497360"
  },
  {
    "text": "production system",
    "start": "497360",
    "end": "498560"
  },
  {
    "text": "it's assumed that clients are long-lived",
    "start": "498560",
    "end": "501599"
  },
  {
    "text": "it's assumed that's going to there's",
    "start": "501599",
    "end": "502720"
  },
  {
    "text": "going to be frequent communication",
    "start": "502720",
    "end": "504800"
  },
  {
    "text": "and the api is generally kind of meant",
    "start": "504800",
    "end": "506400"
  },
  {
    "text": "for like you know you're using it uh",
    "start": "506400",
    "end": "507919"
  },
  {
    "text": "from like a jupiter notebook or",
    "start": "507919",
    "end": "509120"
  },
  {
    "text": "something",
    "start": "509120",
    "end": "509759"
  },
  {
    "text": "instead of calling in uh calling into",
    "start": "509759",
    "end": "512399"
  },
  {
    "text": "like the",
    "start": "512399",
    "end": "513039"
  },
  {
    "text": "the das cluster uh from you know uh",
    "start": "513039",
    "end": "516240"
  },
  {
    "text": "from like in a highly available very",
    "start": "516240",
    "end": "518719"
  },
  {
    "text": "scalable service that",
    "start": "518719",
    "end": "520479"
  },
  {
    "text": "lots of clients calling in it's not it",
    "start": "520479",
    "end": "522800"
  },
  {
    "text": "wasn't really designed for that use case",
    "start": "522800",
    "end": "524959"
  },
  {
    "text": "and there's only very nascent support",
    "start": "524959",
    "end": "526399"
  },
  {
    "text": "for stateful execution which becomes an",
    "start": "526399",
    "end": "528240"
  },
  {
    "text": "issue when you start moving to stuff",
    "start": "528240",
    "end": "529760"
  },
  {
    "text": "like",
    "start": "529760",
    "end": "530880"
  },
  {
    "text": "fault tolerant machine learning training",
    "start": "530880",
    "end": "534480"
  },
  {
    "text": "as as one example anything that you want",
    "start": "534480",
    "end": "536320"
  },
  {
    "text": "to do that's stateful",
    "start": "536320",
    "end": "539200"
  },
  {
    "text": "so yeah given these issues how could we",
    "start": "539360",
    "end": "542640"
  },
  {
    "text": "potentially execute das graphs",
    "start": "542640",
    "end": "544959"
  },
  {
    "text": "on a cluster of machines without using",
    "start": "544959",
    "end": "546560"
  },
  {
    "text": "das distributed",
    "start": "546560",
    "end": "548000"
  },
  {
    "text": "and so of course we're at ray summit",
    "start": "548000",
    "end": "551040"
  },
  {
    "text": "how about rey could we potentially use",
    "start": "551040",
    "end": "552720"
  },
  {
    "text": "ray",
    "start": "552720",
    "end": "554480"
  },
  {
    "start": "553000",
    "end": "553000"
  },
  {
    "text": "quick intro it's a framework for",
    "start": "554480",
    "end": "556959"
  },
  {
    "text": "building distributed applications",
    "start": "556959",
    "end": "559040"
  },
  {
    "text": "and under the hood it contains a really",
    "start": "559040",
    "end": "561519"
  },
  {
    "text": "cool really fast",
    "start": "561519",
    "end": "563200"
  },
  {
    "text": "next-gen task execution engine",
    "start": "563200",
    "end": "565760"
  },
  {
    "text": "emphasizing performance and reliability",
    "start": "565760",
    "end": "567839"
  },
  {
    "text": "you can",
    "start": "567839",
    "end": "568480"
  },
  {
    "text": "see um the ray the ray devs talk about",
    "start": "568480",
    "end": "571040"
  },
  {
    "text": "that a little bit more",
    "start": "571040",
    "end": "572399"
  },
  {
    "text": "in the ray 1.0 white paper that they put",
    "start": "572399",
    "end": "575600"
  },
  {
    "text": "out",
    "start": "575600",
    "end": "576480"
  },
  {
    "text": "but they're really focusing on ensuring",
    "start": "576480",
    "end": "578959"
  },
  {
    "text": "correctness in the face of failures",
    "start": "578959",
    "end": "580800"
  },
  {
    "text": "without compromising the happy path",
    "start": "580800",
    "end": "583680"
  },
  {
    "text": "without compromising",
    "start": "583680",
    "end": "585200"
  },
  {
    "text": "uh the performance characteristics you",
    "start": "585200",
    "end": "587440"
  },
  {
    "text": "know throughput latency",
    "start": "587440",
    "end": "589200"
  },
  {
    "text": "of the very common case where nothing",
    "start": "589200",
    "end": "591680"
  },
  {
    "text": "fails",
    "start": "591680",
    "end": "592480"
  },
  {
    "text": "and that's very hard to do",
    "start": "592480",
    "end": "595519"
  },
  {
    "text": "and but the resulting product after all",
    "start": "595519",
    "end": "597680"
  },
  {
    "text": "the engineering effort you get a",
    "start": "597680",
    "end": "599440"
  },
  {
    "text": "fault tolerant uh task execution",
    "start": "599440",
    "end": "602160"
  },
  {
    "text": "framework that's capable of extremely",
    "start": "602160",
    "end": "604000"
  },
  {
    "text": "high task throughput and then the key",
    "start": "604000",
    "end": "606720"
  },
  {
    "start": "606000",
    "end": "606000"
  },
  {
    "text": "architecture paradigms particularly",
    "start": "606720",
    "end": "608160"
  },
  {
    "text": "highlighting the differences",
    "start": "608160",
    "end": "609760"
  },
  {
    "text": "uh between ray and desk distributed it",
    "start": "609760",
    "end": "612399"
  },
  {
    "text": "has a decentralized peer-to-peer",
    "start": "612399",
    "end": "613839"
  },
  {
    "text": "distributed scheduler so there's no",
    "start": "613839",
    "end": "615279"
  },
  {
    "text": "global scheduler bottleneck",
    "start": "615279",
    "end": "616720"
  },
  {
    "text": "which is really nice um",
    "start": "616720",
    "end": "619760"
  },
  {
    "text": "all cluster and task state is has still",
    "start": "619760",
    "end": "622160"
  },
  {
    "text": "has to be centralized",
    "start": "622160",
    "end": "623360"
  },
  {
    "text": "somewhere and in this case it's",
    "start": "623360",
    "end": "625040"
  },
  {
    "text": "centralized in the global control store",
    "start": "625040",
    "end": "626560"
  },
  {
    "text": "which right now is backed by redis",
    "start": "626560",
    "end": "628720"
  },
  {
    "text": "and it but it makes all those",
    "start": "628720",
    "end": "629839"
  },
  {
    "text": "decentralized schedulers essentially",
    "start": "629839",
    "end": "631519"
  },
  {
    "text": "stateless",
    "start": "631519",
    "end": "633040"
  },
  {
    "text": "and it also means that the cluster and",
    "start": "633040",
    "end": "635279"
  },
  {
    "text": "task state introspection that you want",
    "start": "635279",
    "end": "636800"
  },
  {
    "text": "to do like a dashboard",
    "start": "636800",
    "end": "638480"
  },
  {
    "text": "or uh or constructing metrics",
    "start": "638480",
    "end": "641920"
  },
  {
    "text": "uh like that can that doesn't have that",
    "start": "641920",
    "end": "644720"
  },
  {
    "text": "doesn't affect scheduling throughput",
    "start": "644720",
    "end": "646320"
  },
  {
    "text": "nearly as much",
    "start": "646320",
    "end": "647200"
  },
  {
    "text": "as a global single",
    "start": "647200",
    "end": "650399"
  },
  {
    "text": "scheduler process that has to be uh that",
    "start": "650399",
    "end": "653279"
  },
  {
    "text": "has to",
    "start": "653279",
    "end": "654399"
  },
  {
    "text": "that that has to like you know basically",
    "start": "654399",
    "end": "656160"
  },
  {
    "text": "export metrics or",
    "start": "656160",
    "end": "657680"
  },
  {
    "text": "provide a dashboard yada yada",
    "start": "657680",
    "end": "661279"
  },
  {
    "text": "so that's really nice and then apache",
    "start": "661279",
    "end": "664079"
  },
  {
    "text": "plasma the distributed in-memory object",
    "start": "664079",
    "end": "665920"
  },
  {
    "text": "store which is used for peer-to-peer",
    "start": "665920",
    "end": "667360"
  },
  {
    "text": "data communication and zero copy",
    "start": "667360",
    "end": "668800"
  },
  {
    "text": "intranode reads",
    "start": "668800",
    "end": "670640"
  },
  {
    "text": "provides very very fast local data",
    "start": "670640",
    "end": "672800"
  },
  {
    "text": "sharing between tasks",
    "start": "672800",
    "end": "674160"
  },
  {
    "text": "tasks are this are on the same node um",
    "start": "674160",
    "end": "676720"
  },
  {
    "text": "and it's dealing with like",
    "start": "676720",
    "end": "677760"
  },
  {
    "text": "nd arrays or really anything that's",
    "start": "677760",
    "end": "679519"
  },
  {
    "text": "supported by like apache arrow",
    "start": "679519",
    "end": "681600"
  },
  {
    "text": "um it will uh it will provide",
    "start": "681600",
    "end": "685120"
  },
  {
    "text": "zero copy reads which is cool",
    "start": "685120",
    "end": "688480"
  },
  {
    "text": "uh and then there's support for",
    "start": "688480",
    "end": "690000"
  },
  {
    "text": "fault-tolerant stateful actors it's",
    "start": "690000",
    "end": "691519"
  },
  {
    "text": "really",
    "start": "691519",
    "end": "692160"
  },
  {
    "text": "the the support for actors in rey is",
    "start": "692160",
    "end": "694560"
  },
  {
    "text": "truly first class",
    "start": "694560",
    "end": "696000"
  },
  {
    "text": "um so there's been recent efforts in",
    "start": "696000",
    "end": "698160"
  },
  {
    "text": "desk but ray",
    "start": "698160",
    "end": "699440"
  },
  {
    "text": "was kind of like almost like actor first",
    "start": "699440",
    "end": "701839"
  },
  {
    "text": "um",
    "start": "701839",
    "end": "702560"
  },
  {
    "text": "yeah great support for state for",
    "start": "702560",
    "end": "703760"
  },
  {
    "text": "execution and its scheduler is still",
    "start": "703760",
    "end": "705760"
  },
  {
    "text": "really smart despite being decentralized",
    "start": "705760",
    "end": "708079"
  },
  {
    "text": "uh it's resource aware it it's local",
    "start": "708079",
    "end": "711279"
  },
  {
    "text": "first",
    "start": "711279",
    "end": "711760"
  },
  {
    "text": "there's the sk the scheduled decision",
    "start": "711760",
    "end": "714399"
  },
  {
    "text": "caching",
    "start": "714399",
    "end": "715680"
  },
  {
    "text": "like uh maps a lot of scheduling",
    "start": "715680",
    "end": "718800"
  },
  {
    "text": "decisions to essentially just work at a",
    "start": "718800",
    "end": "720560"
  },
  {
    "text": "worker rpcs",
    "start": "720560",
    "end": "721839"
  },
  {
    "text": "it doesn't even have to consult the rail",
    "start": "721839",
    "end": "723279"
  },
  {
    "text": "it uh or it doesn't have to ask the rail",
    "start": "723279",
    "end": "726000"
  },
  {
    "text": "it to",
    "start": "726000",
    "end": "726399"
  },
  {
    "text": "please make a scheduling decision and",
    "start": "726399",
    "end": "728720"
  },
  {
    "text": "that where as long as the task",
    "start": "728720",
    "end": "730880"
  },
  {
    "text": "has the same resource shape and there's",
    "start": "730880",
    "end": "732720"
  },
  {
    "text": "already a work release then it's just a",
    "start": "732720",
    "end": "734480"
  },
  {
    "text": "worker to work or rpc and it's super",
    "start": "734480",
    "end": "735920"
  },
  {
    "text": "fast",
    "start": "735920",
    "end": "736399"
  },
  {
    "text": "and there's stuff coming down the pike",
    "start": "736399",
    "end": "737760"
  },
  {
    "text": "such as uh",
    "start": "737760",
    "end": "739440"
  },
  {
    "text": "locality aware um scheduling",
    "start": "739440",
    "end": "742480"
  },
  {
    "text": "and work stealing that's also super cool",
    "start": "742480",
    "end": "745200"
  },
  {
    "text": "and very hard to do in a decentralized",
    "start": "745200",
    "end": "746800"
  },
  {
    "text": "scheduler",
    "start": "746800",
    "end": "748800"
  },
  {
    "text": "so how do we actually get das to run on",
    "start": "748800",
    "end": "750800"
  },
  {
    "text": "rey you know let's try it out",
    "start": "750800",
    "end": "753279"
  },
  {
    "text": "um well given that ray tasks are just",
    "start": "753279",
    "end": "755440"
  },
  {
    "text": "like you know pickled python functions",
    "start": "755440",
    "end": "758480"
  },
  {
    "text": "and given that das task graphs are just",
    "start": "758480",
    "end": "761040"
  },
  {
    "text": "function application graphs",
    "start": "761040",
    "end": "762720"
  },
  {
    "text": "containing python functions in memory",
    "start": "762720",
    "end": "765360"
  },
  {
    "text": "and then",
    "start": "765360",
    "end": "765760"
  },
  {
    "text": "you know when decentralized or when uh",
    "start": "765760",
    "end": "768160"
  },
  {
    "text": "the work is when the tasks are",
    "start": "768160",
    "end": "769440"
  },
  {
    "text": "distributed those python functions are",
    "start": "769440",
    "end": "770880"
  },
  {
    "text": "pickled",
    "start": "770880",
    "end": "772000"
  },
  {
    "text": "if we just convert convert each",
    "start": "772000",
    "end": "774240"
  },
  {
    "text": "dasktask's python function to a",
    "start": "774240",
    "end": "775920"
  },
  {
    "text": "ray.remote function if we just",
    "start": "775920",
    "end": "777680"
  },
  {
    "text": "reify it we can execute any dash graph",
    "start": "777680",
    "end": "781279"
  },
  {
    "text": "on ray",
    "start": "781279",
    "end": "782000"
  },
  {
    "start": "782000",
    "end": "782000"
  },
  {
    "text": "very simple so the desk on ray scheduler",
    "start": "782000",
    "end": "784720"
  },
  {
    "text": "is essentially this with some",
    "start": "784720",
    "end": "786079"
  },
  {
    "text": "optimizations and extensions",
    "start": "786079",
    "end": "788160"
  },
  {
    "text": "we t we tweak the semantics of the",
    "start": "788160",
    "end": "790240"
  },
  {
    "text": "existing local dash scheduler which",
    "start": "790240",
    "end": "792000"
  },
  {
    "text": "already traverses the das",
    "start": "792000",
    "end": "793519"
  },
  {
    "text": "graph and executes the tasks to instead",
    "start": "793519",
    "end": "797360"
  },
  {
    "text": "traverse the dash graph and farm the",
    "start": "797360",
    "end": "799839"
  },
  {
    "text": "actual task execution out to ray",
    "start": "799839",
    "end": "803440"
  },
  {
    "text": "and then after all of the task tasks",
    "start": "803440",
    "end": "805600"
  },
  {
    "text": "have been submitted to the raycluster as",
    "start": "805600",
    "end": "807040"
  },
  {
    "text": "arraytask",
    "start": "807040",
    "end": "808079"
  },
  {
    "text": "we just call ray.get on the output",
    "start": "808079",
    "end": "811040"
  },
  {
    "text": "object reference",
    "start": "811040",
    "end": "811920"
  },
  {
    "text": "on the sync node of the das graph on and",
    "start": "811920",
    "end": "815120"
  },
  {
    "text": "that",
    "start": "815120",
    "end": "816079"
  },
  {
    "text": "that that will then uh cause execution",
    "start": "816079",
    "end": "819120"
  },
  {
    "text": "to wait and fetch the output of that das",
    "start": "819120",
    "end": "821120"
  },
  {
    "text": "computation",
    "start": "821120",
    "end": "821839"
  },
  {
    "text": "once that final output uh",
    "start": "821839",
    "end": "824959"
  },
  {
    "text": "once that final output node has",
    "start": "824959",
    "end": "827040"
  },
  {
    "text": "materialized",
    "start": "827040",
    "end": "829760"
  },
  {
    "start": "829000",
    "end": "829000"
  },
  {
    "text": "and so usage it's very simple it's like",
    "start": "829760",
    "end": "832320"
  },
  {
    "text": "uh",
    "start": "832320",
    "end": "833199"
  },
  {
    "text": "suppose some computable is like a desk",
    "start": "833199",
    "end": "834959"
  },
  {
    "text": "array or something",
    "start": "834959",
    "end": "837199"
  },
  {
    "text": "some sort of like a desk object",
    "start": "837199",
    "end": "840639"
  },
  {
    "text": "typically call compute instead it turns",
    "start": "840639",
    "end": "842320"
  },
  {
    "text": "into this you just like connect to the",
    "start": "842320",
    "end": "843920"
  },
  {
    "text": "cluster at one point in your program",
    "start": "843920",
    "end": "846000"
  },
  {
    "text": "and then you pass in the ray desk",
    "start": "846000",
    "end": "848959"
  },
  {
    "text": "scheduler",
    "start": "848959",
    "end": "850480"
  },
  {
    "text": "um the ray das get so",
    "start": "850480",
    "end": "854320"
  },
  {
    "text": "really big kudos to desk for making the",
    "start": "854320",
    "end": "856560"
  },
  {
    "text": "scheduler so pluggable",
    "start": "856560",
    "end": "857760"
  },
  {
    "text": "uh it was very very easy to create this",
    "start": "857760",
    "end": "860480"
  },
  {
    "start": "860000",
    "end": "860000"
  },
  {
    "text": "i think the initial version was like",
    "start": "860480",
    "end": "862000"
  },
  {
    "text": "eight lines um so yeah we have uh",
    "start": "862000",
    "end": "866639"
  },
  {
    "text": "uh in addition to the scheduler we've",
    "start": "866639",
    "end": "868560"
  },
  {
    "text": "implemented the scheduler callback",
    "start": "868560",
    "end": "870000"
  },
  {
    "text": "abstractions which allow you to hook",
    "start": "870000",
    "end": "872000"
  },
  {
    "text": "into the raytask",
    "start": "872000",
    "end": "873519"
  },
  {
    "text": "lifecycle and this is something that's",
    "start": "873519",
    "end": "876639"
  },
  {
    "text": "that people who've used desk might be",
    "start": "876639",
    "end": "878800"
  },
  {
    "text": "familiar with the custom callback",
    "start": "878800",
    "end": "880480"
  },
  {
    "text": "abstraction",
    "start": "880480",
    "end": "881440"
  },
  {
    "text": "this is pretty much the same thing",
    "start": "881440",
    "end": "882880"
  },
  {
    "text": "except it's race-specific uh hooks",
    "start": "882880",
    "end": "885839"
  },
  {
    "text": "and this makes implementing desk level",
    "start": "885839",
    "end": "887440"
  },
  {
    "text": "stuff uh like a",
    "start": "887440",
    "end": "889600"
  },
  {
    "text": "task introspection such as like progress",
    "start": "889600",
    "end": "891680"
  },
  {
    "text": "reporting diagnostics caching",
    "start": "891680",
    "end": "893279"
  },
  {
    "text": "super simple we've used this extensively",
    "start": "893279",
    "end": "897120"
  },
  {
    "text": "and then we have a series of callback",
    "start": "897120",
    "end": "899920"
  },
  {
    "text": "hooks there's a pre-submit which runs",
    "start": "899920",
    "end": "901920"
  },
  {
    "text": "before submitting ray task",
    "start": "901920",
    "end": "903199"
  },
  {
    "text": "post submit runs after submitting array",
    "start": "903199",
    "end": "905600"
  },
  {
    "text": "task",
    "start": "905600",
    "end": "906480"
  },
  {
    "text": "pre-task which runs before executing a",
    "start": "906480",
    "end": "908880"
  },
  {
    "text": "das task",
    "start": "908880",
    "end": "910480"
  },
  {
    "text": "and then post task which runs after",
    "start": "910480",
    "end": "913279"
  },
  {
    "text": "executing a desk task",
    "start": "913279",
    "end": "914800"
  },
  {
    "text": "post submit all that runs after all ray",
    "start": "914800",
    "end": "916639"
  },
  {
    "text": "tests have been submitted and then",
    "start": "916639",
    "end": "917839"
  },
  {
    "text": "finally finish",
    "start": "917839",
    "end": "918800"
  },
  {
    "text": "after all ray tasks have finished that",
    "start": "918800",
    "end": "920399"
  },
  {
    "text": "will run and the pre-task and post task",
    "start": "920399",
    "end": "922560"
  },
  {
    "text": "will run",
    "start": "922560",
    "end": "923519"
  },
  {
    "text": "within the ray worker um like within the",
    "start": "923519",
    "end": "926399"
  },
  {
    "text": "ray task function",
    "start": "926399",
    "end": "927600"
  },
  {
    "text": "essentially so time for some benchmarks",
    "start": "927600",
    "end": "930399"
  },
  {
    "text": "how how fast is this i'd admit i",
    "start": "930399",
    "end": "932320"
  },
  {
    "text": "thought it would be way slower in every",
    "start": "932320",
    "end": "934079"
  },
  {
    "text": "case because it's super naive what we're",
    "start": "934079",
    "end": "936079"
  },
  {
    "start": "936000",
    "end": "936000"
  },
  {
    "text": "doing",
    "start": "936079",
    "end": "937040"
  },
  {
    "text": "so we use a popular data frame group by",
    "start": "937040",
    "end": "939279"
  },
  {
    "text": "benchmark and where you uh",
    "start": "939279",
    "end": "941360"
  },
  {
    "text": "yeah you take a data frame and you do a",
    "start": "941360",
    "end": "942959"
  },
  {
    "text": "group by in a mean",
    "start": "942959",
    "end": "944639"
  },
  {
    "text": "uh i've seen some matt rocklin blog post",
    "start": "944639",
    "end": "946959"
  },
  {
    "text": "before",
    "start": "946959",
    "end": "947839"
  },
  {
    "text": "matt rocklin the creator of desk uh",
    "start": "947839",
    "end": "950240"
  },
  {
    "text": "detailing",
    "start": "950240",
    "end": "951199"
  },
  {
    "text": "the detailing this benchmark",
    "start": "951199",
    "end": "954639"
  },
  {
    "text": "uh he's used it before so we write",
    "start": "954639",
    "end": "956800"
  },
  {
    "text": "anywhere from one megabyte to one",
    "start": "956800",
    "end": "958160"
  },
  {
    "text": "gigabyte of data frames to",
    "start": "958160",
    "end": "959680"
  },
  {
    "text": "disk if running the benchmark on a",
    "start": "959680",
    "end": "962000"
  },
  {
    "text": "single node or to google cloud storage",
    "start": "962000",
    "end": "964639"
  },
  {
    "text": "if running the benchmark on multiple",
    "start": "964639",
    "end": "966880"
  },
  {
    "text": "nodes in it like on a cluster",
    "start": "966880",
    "end": "968639"
  },
  {
    "text": "and we write those as parquet files and",
    "start": "968639",
    "end": "971120"
  },
  {
    "text": "then the benchmark just reads those",
    "start": "971120",
    "end": "972399"
  },
  {
    "text": "files in the data frames and computes",
    "start": "972399",
    "end": "973759"
  },
  {
    "text": "groupon amine",
    "start": "973759",
    "end": "974720"
  },
  {
    "text": "so very very simple benchmark",
    "start": "974720",
    "end": "978639"
  },
  {
    "start": "978000",
    "end": "978000"
  },
  {
    "text": "so the single node case we run it on a",
    "start": "978639",
    "end": "980880"
  },
  {
    "text": "96 core",
    "start": "980880",
    "end": "982720"
  },
  {
    "text": "uh 386 gigabyte uh",
    "start": "982720",
    "end": "986079"
  },
  {
    "text": "ram instance on aws a huge machine",
    "start": "986079",
    "end": "989759"
  },
  {
    "text": "just just for fun and very surprisingly",
    "start": "989759",
    "end": "993519"
  },
  {
    "text": "uh desk on ray is anywhere from 10 times",
    "start": "993519",
    "end": "996320"
  },
  {
    "text": "faster",
    "start": "996320",
    "end": "998399"
  },
  {
    "text": "to or anywhere from two times faster to",
    "start": "998399",
    "end": "1000399"
  },
  {
    "text": "10 times faster on this single large",
    "start": "1000399",
    "end": "1001920"
  },
  {
    "text": "machine",
    "start": "1001920",
    "end": "1002880"
  },
  {
    "text": "which was pretty surprising i'm thinking",
    "start": "1002880",
    "end": "1005440"
  },
  {
    "text": "possibly due to intranode",
    "start": "1005440",
    "end": "1006959"
  },
  {
    "text": "zero copy reads by the plasma shared",
    "start": "1006959",
    "end": "1009040"
  },
  {
    "text": "memory you know that's",
    "start": "1009040",
    "end": "1010000"
  },
  {
    "text": "that's potentially an advantage for the",
    "start": "1010000",
    "end": "1011600"
  },
  {
    "text": "single node use case",
    "start": "1011600",
    "end": "1013279"
  },
  {
    "text": "um i we tried to take pretty good care",
    "start": "1013279",
    "end": "1016160"
  },
  {
    "text": "to make sure that",
    "start": "1016160",
    "end": "1017600"
  },
  {
    "text": "nothing like like the buffer cache",
    "start": "1017600",
    "end": "1019519"
  },
  {
    "text": "wasn't getting hit by",
    "start": "1019519",
    "end": "1021199"
  },
  {
    "text": "by desk on ray and not desk and stuff",
    "start": "1021199",
    "end": "1023680"
  },
  {
    "text": "like that",
    "start": "1023680",
    "end": "1024720"
  },
  {
    "text": "like we are generating you know for each",
    "start": "1024720",
    "end": "1026798"
  },
  {
    "text": "for each case generating",
    "start": "1026799",
    "end": "1028720"
  },
  {
    "text": "completely random data frames and",
    "start": "1028720",
    "end": "1030319"
  },
  {
    "text": "writing them to disk or gcs",
    "start": "1030319",
    "end": "1032880"
  },
  {
    "text": "so uh but yeah i gotta i gotta profile",
    "start": "1032880",
    "end": "1035520"
  },
  {
    "text": "more to find out why",
    "start": "1035520",
    "end": "1036640"
  },
  {
    "text": "it's really interesting now the five",
    "start": "1036640",
    "end": "1038880"
  },
  {
    "start": "1037000",
    "end": "1037000"
  },
  {
    "text": "node cluster",
    "start": "1038880",
    "end": "1039760"
  },
  {
    "text": "this is uh each one is 16 cores 64",
    "start": "1039760",
    "end": "1042319"
  },
  {
    "text": "gigabits",
    "start": "1042319",
    "end": "1043199"
  },
  {
    "text": "uh 64 gigabytes uh gibby bytes",
    "start": "1043199",
    "end": "1046558"
  },
  {
    "text": "of ram it's uh this is on gcp actually",
    "start": "1046559",
    "end": "1049200"
  },
  {
    "text": "it's",
    "start": "1049200",
    "end": "1050080"
  },
  {
    "text": "all these instances are n2 standard 16",
    "start": "1050080",
    "end": "1052400"
  },
  {
    "text": "instances if you're",
    "start": "1052400",
    "end": "1053440"
  },
  {
    "text": "if you're familiar with those this desk",
    "start": "1053440",
    "end": "1056640"
  },
  {
    "text": "on ray is about as fast as dash",
    "start": "1056640",
    "end": "1058480"
  },
  {
    "text": "distributed",
    "start": "1058480",
    "end": "1059679"
  },
  {
    "text": "um like uh which which",
    "start": "1059679",
    "end": "1062880"
  },
  {
    "text": "makes sense because distributed's global",
    "start": "1062880",
    "end": "1065200"
  },
  {
    "text": "scheduler is really smart",
    "start": "1065200",
    "end": "1067039"
  },
  {
    "text": "uh it has locality aware scheduling it",
    "start": "1067039",
    "end": "1069120"
  },
  {
    "text": "has work stealing",
    "start": "1069120",
    "end": "1070640"
  },
  {
    "text": "uh it potentially might have some low",
    "start": "1070640",
    "end": "1073440"
  },
  {
    "text": "some like like less overhead",
    "start": "1073440",
    "end": "1075760"
  },
  {
    "text": "for um the small cluster use case again",
    "start": "1075760",
    "end": "1079039"
  },
  {
    "text": "i gotta i gotta profile more i'm looking",
    "start": "1079039",
    "end": "1080720"
  },
  {
    "text": "forward to digging into this over the",
    "start": "1080720",
    "end": "1081840"
  },
  {
    "text": "next couple weeks",
    "start": "1081840",
    "end": "1082880"
  },
  {
    "text": "but there's lots of low-hanging fruit",
    "start": "1082880",
    "end": "1084400"
  },
  {
    "text": "for rae here because ray does not have",
    "start": "1084400",
    "end": "1086320"
  },
  {
    "text": "locality aware scheduling or work",
    "start": "1086320",
    "end": "1088000"
  },
  {
    "text": "stealing yet",
    "start": "1088000",
    "end": "1089200"
  },
  {
    "text": "so lots of potential fun stuff to do",
    "start": "1089200",
    "end": "1090960"
  },
  {
    "text": "there uh",
    "start": "1090960",
    "end": "1092480"
  },
  {
    "text": "so what does descartes labs use to ask",
    "start": "1092480",
    "end": "1094160"
  },
  {
    "text": "and ray for it's for",
    "start": "1094160",
    "end": "1096080"
  },
  {
    "text": "our workflows product which is a",
    "start": "1096080",
    "end": "1098480"
  },
  {
    "text": "computation engine for",
    "start": "1098480",
    "end": "1099760"
  },
  {
    "text": "interactive and batch geospatial data",
    "start": "1099760",
    "end": "1101840"
  },
  {
    "text": "analysis",
    "start": "1101840",
    "end": "1102799"
  },
  {
    "text": "uh so here you see like this uh somebody",
    "start": "1102799",
    "end": "1105280"
  },
  {
    "text": "composing a geospatial workflow a little",
    "start": "1105280",
    "end": "1107919"
  },
  {
    "text": "geospatial model",
    "start": "1107919",
    "end": "1109280"
  },
  {
    "text": "they're composing a composite and then",
    "start": "1109280",
    "end": "1111440"
  },
  {
    "text": "they're visualizing on the map",
    "start": "1111440",
    "end": "1113039"
  },
  {
    "text": "and i'm not going to demo this today but",
    "start": "1113039",
    "end": "1115280"
  },
  {
    "text": "the the map widget today",
    "start": "1115280",
    "end": "1117039"
  },
  {
    "text": "but when you pan around it basically",
    "start": "1117039",
    "end": "1118559"
  },
  {
    "text": "like recomputes on the fly",
    "start": "1118559",
    "end": "1121520"
  },
  {
    "text": "and then that's the interactive uh",
    "start": "1121520",
    "end": "1123600"
  },
  {
    "text": "version and then we also have batch",
    "start": "1123600",
    "end": "1125280"
  },
  {
    "text": "a batch system so the idea is you",
    "start": "1125280",
    "end": "1127919"
  },
  {
    "text": "express your",
    "start": "1127919",
    "end": "1128880"
  },
  {
    "text": "your geospatial model using these high",
    "start": "1128880",
    "end": "1130640"
  },
  {
    "text": "level abstractions like image",
    "start": "1130640",
    "end": "1132480"
  },
  {
    "text": "image collection feature feature",
    "start": "1132480",
    "end": "1133760"
  },
  {
    "text": "collection uh and then",
    "start": "1133760",
    "end": "1135600"
  },
  {
    "text": "you uh you express operations high level",
    "start": "1135600",
    "end": "1138960"
  },
  {
    "text": "operations on these abstractions",
    "start": "1138960",
    "end": "1140880"
  },
  {
    "text": "and then you visualize the results on",
    "start": "1140880",
    "end": "1142320"
  },
  {
    "text": "the fly the workflows back end will take",
    "start": "1142320",
    "end": "1145120"
  },
  {
    "text": "uh an intermediate representation of",
    "start": "1145120",
    "end": "1147200"
  },
  {
    "text": "those high level operations",
    "start": "1147200",
    "end": "1148720"
  },
  {
    "text": "compile it into a low-level task graph",
    "start": "1148720",
    "end": "1151600"
  },
  {
    "text": "which will then do some automatic data",
    "start": "1151600",
    "end": "1153280"
  },
  {
    "text": "partitioning to provide data parallelism",
    "start": "1153280",
    "end": "1155440"
  },
  {
    "text": "in addition to task parallelism and then",
    "start": "1155440",
    "end": "1157520"
  },
  {
    "text": "it'll execute those tasks on a cluster",
    "start": "1157520",
    "end": "1159600"
  },
  {
    "text": "of workers",
    "start": "1159600",
    "end": "1160640"
  },
  {
    "text": "and it allows for these high level model",
    "start": "1160640",
    "end": "1163039"
  },
  {
    "text": "descriptions that",
    "start": "1163039",
    "end": "1164000"
  },
  {
    "text": "are pretty much uh parallelism and data",
    "start": "1164000",
    "end": "1166480"
  },
  {
    "text": "partition",
    "start": "1166480",
    "end": "1167440"
  },
  {
    "text": "agnostic you can almost say like scale",
    "start": "1167440",
    "end": "1169440"
  },
  {
    "text": "agnostic",
    "start": "1169440",
    "end": "1170880"
  },
  {
    "text": "and they can be transparently run over",
    "start": "1170880",
    "end": "1172559"
  },
  {
    "text": "tens of thousands of cores",
    "start": "1172559",
    "end": "1174720"
  },
  {
    "text": "and then searching over and pulling",
    "start": "1174720",
    "end": "1177360"
  },
  {
    "text": "petabytes of imagery from our data",
    "start": "1177360",
    "end": "1178720"
  },
  {
    "text": "catalog",
    "start": "1178720",
    "end": "1179760"
  },
  {
    "text": "programming model very simple kind of",
    "start": "1179760",
    "end": "1181679"
  },
  {
    "start": "1180000",
    "end": "1180000"
  },
  {
    "text": "went over it a little bit already",
    "start": "1181679",
    "end": "1183679"
  },
  {
    "text": "we have these proxy objects in the",
    "start": "1183679",
    "end": "1185360"
  },
  {
    "text": "client that the user imperatively",
    "start": "1185360",
    "end": "1187280"
  },
  {
    "text": "manipulates",
    "start": "1187280",
    "end": "1188240"
  },
  {
    "text": "and under the hood this composes a dag",
    "start": "1188240",
    "end": "1190080"
  },
  {
    "text": "of data transformations um which is",
    "start": "1190080",
    "end": "1192400"
  },
  {
    "text": "represented in our graphed intermediate",
    "start": "1192400",
    "end": "1193919"
  },
  {
    "text": "representation",
    "start": "1193919",
    "end": "1194799"
  },
  {
    "text": "and this gives us that lazy execution um",
    "start": "1194799",
    "end": "1197840"
  },
  {
    "text": "which if you're familiar with like",
    "start": "1197840",
    "end": "1198960"
  },
  {
    "text": "machine learning frameworks or if you've",
    "start": "1198960",
    "end": "1200640"
  },
  {
    "text": "used haskell you know",
    "start": "1200640",
    "end": "1202400"
  },
  {
    "text": "you're probably pretty familiar with",
    "start": "1202400",
    "end": "1203679"
  },
  {
    "text": "like lazy evaluation and",
    "start": "1203679",
    "end": "1206159"
  },
  {
    "text": "what's nice is this graft ir composition",
    "start": "1206159",
    "end": "1208240"
  },
  {
    "text": "is totally done on the client there's no",
    "start": "1208240",
    "end": "1210400"
  },
  {
    "text": "network communication",
    "start": "1210400",
    "end": "1212000"
  },
  {
    "text": "or any interpretation of the graft until",
    "start": "1212000",
    "end": "1214480"
  },
  {
    "text": "you call compute",
    "start": "1214480",
    "end": "1215760"
  },
  {
    "text": "then once you call compute it's sent to",
    "start": "1215760",
    "end": "1217280"
  },
  {
    "text": "our back end and executed",
    "start": "1217280",
    "end": "1220080"
  },
  {
    "text": "so uh quick workflows demo",
    "start": "1220080",
    "end": "1224080"
  },
  {
    "text": "this is uh this is a fun one so um",
    "start": "1225039",
    "end": "1228240"
  },
  {
    "text": "we uh there's if you're not familiar",
    "start": "1228240",
    "end": "1230960"
  },
  {
    "text": "with synthetic aperture radar",
    "start": "1230960",
    "end": "1233760"
  },
  {
    "text": "imagery this is uh it's it's pretty cool",
    "start": "1233760",
    "end": "1237120"
  },
  {
    "text": "um it's a satellite that has like a",
    "start": "1237120",
    "end": "1238960"
  },
  {
    "text": "radio antenna um it emits pulses of",
    "start": "1238960",
    "end": "1241440"
  },
  {
    "text": "microwave radiation and measures the",
    "start": "1241440",
    "end": "1243039"
  },
  {
    "text": "echoes from the earth",
    "start": "1243039",
    "end": "1244640"
  },
  {
    "text": "and there's a synthetic aperture that's",
    "start": "1244640",
    "end": "1246640"
  },
  {
    "text": "created by the motion of the sensor",
    "start": "1246640",
    "end": "1248880"
  },
  {
    "text": "uh in the orbit because it's sending",
    "start": "1248880",
    "end": "1250880"
  },
  {
    "text": "multiple pulses down",
    "start": "1250880",
    "end": "1252240"
  },
  {
    "text": "to the earth measuring the echo a",
    "start": "1252240",
    "end": "1254559"
  },
  {
    "text": "virtual",
    "start": "1254559",
    "end": "1255280"
  },
  {
    "text": "aperture is created by the motion of the",
    "start": "1255280",
    "end": "1256960"
  },
  {
    "text": "sensor which is pretty cool",
    "start": "1256960",
    "end": "1258640"
  },
  {
    "text": "it's it allows you to get super high",
    "start": "1258640",
    "end": "1260960"
  },
  {
    "text": "spatial resolution imaging with a small",
    "start": "1260960",
    "end": "1262799"
  },
  {
    "text": "antenna",
    "start": "1262799",
    "end": "1263840"
  },
  {
    "text": "um and since it's microwave radiation",
    "start": "1263840",
    "end": "1266000"
  },
  {
    "text": "it's an all-weather",
    "start": "1266000",
    "end": "1267360"
  },
  {
    "text": "day and night uh imaging system like",
    "start": "1267360",
    "end": "1270480"
  },
  {
    "text": "uh it it provides its own radiation so",
    "start": "1270480",
    "end": "1273120"
  },
  {
    "text": "you don't have to wait for the sun",
    "start": "1273120",
    "end": "1275520"
  },
  {
    "text": "and then it uh microwave radiation does",
    "start": "1275520",
    "end": "1278080"
  },
  {
    "text": "a very good job of penetrating clouds",
    "start": "1278080",
    "end": "1279600"
  },
  {
    "text": "and all that jazz",
    "start": "1279600",
    "end": "1280880"
  },
  {
    "text": "we construct this like sentinel one",
    "start": "1280880",
    "end": "1282640"
  },
  {
    "text": "image collection let's we're going to do",
    "start": "1282640",
    "end": "1284400"
  },
  {
    "text": "a",
    "start": "1284400",
    "end": "1284640"
  },
  {
    "text": "five-year max composite so there's that",
    "start": "1284640",
    "end": "1287600"
  },
  {
    "text": "uh that date range",
    "start": "1287600",
    "end": "1289440"
  },
  {
    "text": "um we're going to pick the dual",
    "start": "1289440",
    "end": "1291280"
  },
  {
    "text": "polarization band",
    "start": "1291280",
    "end": "1293120"
  },
  {
    "text": "i won't go into that due to a shortness",
    "start": "1293120",
    "end": "1295360"
  },
  {
    "text": "in time",
    "start": "1295360",
    "end": "1296240"
  },
  {
    "text": "and we're only going to use the",
    "start": "1296240",
    "end": "1297280"
  },
  {
    "text": "ascending orbit so that's the orbit of",
    "start": "1297280",
    "end": "1299440"
  },
  {
    "text": "the satellite that goes towards the",
    "start": "1299440",
    "end": "1300559"
  },
  {
    "text": "north pole",
    "start": "1300559",
    "end": "1301840"
  },
  {
    "text": "and then yeah we're going to do a max",
    "start": "1301840",
    "end": "1303600"
  },
  {
    "text": "over the image",
    "start": "1303600",
    "end": "1305280"
  },
  {
    "text": "axis or you could think of this as the",
    "start": "1305280",
    "end": "1307039"
  },
  {
    "text": "time axis as well",
    "start": "1307039",
    "end": "1308720"
  },
  {
    "text": "and then we're going to scale the values",
    "start": "1308720",
    "end": "1311120"
  },
  {
    "text": "to 0 and 1.",
    "start": "1311120",
    "end": "1313360"
  },
  {
    "text": "now one fun place to look would be the",
    "start": "1313360",
    "end": "1316880"
  },
  {
    "text": "straight of gibraltar which is",
    "start": "1316880",
    "end": "1318400"
  },
  {
    "text": "that's where this geometry is that's",
    "start": "1318400",
    "end": "1321520"
  },
  {
    "text": "uh and we're doing a resolution of 200",
    "start": "1321520",
    "end": "1323840"
  },
  {
    "text": "meters per pixel",
    "start": "1323840",
    "end": "1325840"
  },
  {
    "text": "so we uh this right now just launched",
    "start": "1325840",
    "end": "1328720"
  },
  {
    "text": "the job over this aoi",
    "start": "1328720",
    "end": "1330240"
  },
  {
    "text": "right now it's preparing which is it's",
    "start": "1330240",
    "end": "1332159"
  },
  {
    "text": "interpreting the graft it's",
    "start": "1332159",
    "end": "1333440"
  },
  {
    "text": "creating the das graph and then when",
    "start": "1333440",
    "end": "1335440"
  },
  {
    "text": "it's running we have this is the number",
    "start": "1335440",
    "end": "1337520"
  },
  {
    "text": "of desk tasks",
    "start": "1337520",
    "end": "1339039"
  },
  {
    "text": "um it's running it's running it's doing",
    "start": "1339039",
    "end": "1341039"
  },
  {
    "text": "all these computations it's creating the",
    "start": "1341039",
    "end": "1342960"
  },
  {
    "text": "composite it's doing",
    "start": "1342960",
    "end": "1344400"
  },
  {
    "text": "you know the filtering cool 18.5 seconds",
    "start": "1344400",
    "end": "1347600"
  },
  {
    "text": "that's about",
    "start": "1347600",
    "end": "1348240"
  },
  {
    "text": "30 faster than i've seen with the non uh",
    "start": "1348240",
    "end": "1351679"
  },
  {
    "text": "ray back end so that's pretty cool and",
    "start": "1351679",
    "end": "1354640"
  },
  {
    "text": "then now we're gonna visualize it",
    "start": "1354640",
    "end": "1357840"
  },
  {
    "text": "and uh this might actually take a second",
    "start": "1357840",
    "end": "1360480"
  },
  {
    "text": "it might take almost as long as it took",
    "start": "1360480",
    "end": "1362320"
  },
  {
    "text": "to compute the result because at",
    "start": "1362320",
    "end": "1364080"
  },
  {
    "text": "matplotlib um and so this is going to",
    "start": "1364080",
    "end": "1367520"
  },
  {
    "text": "show us vessel traffic",
    "start": "1367520",
    "end": "1369520"
  },
  {
    "text": "in the strait of gibraltar using",
    "start": "1369520",
    "end": "1371600"
  },
  {
    "text": "synthetic aperture radar using a max",
    "start": "1371600",
    "end": "1373520"
  },
  {
    "text": "composite",
    "start": "1373520",
    "end": "1374000"
  },
  {
    "text": "over five years so we get like a nice",
    "start": "1374000",
    "end": "1376480"
  },
  {
    "text": "cool like",
    "start": "1376480",
    "end": "1377120"
  },
  {
    "text": "peak summary of vessel traffic",
    "start": "1377120",
    "end": "1380799"
  },
  {
    "text": "super cool how cool is that so you see",
    "start": "1380799",
    "end": "1383919"
  },
  {
    "text": "here this is the this is the straight of",
    "start": "1383919",
    "end": "1385520"
  },
  {
    "text": "gibraltar and these are the shipping",
    "start": "1385520",
    "end": "1386720"
  },
  {
    "text": "lanes",
    "start": "1386720",
    "end": "1387679"
  },
  {
    "text": "and even here like gibraltar i'm sure",
    "start": "1387679",
    "end": "1390080"
  },
  {
    "text": "like the the rock of gibraltar is like",
    "start": "1390080",
    "end": "1391679"
  },
  {
    "text": "right here",
    "start": "1391679",
    "end": "1392320"
  },
  {
    "text": "so this is uh gibraltar which is i",
    "start": "1392320",
    "end": "1394400"
  },
  {
    "text": "believe like a",
    "start": "1394400",
    "end": "1395440"
  },
  {
    "text": "british territory and then you have",
    "start": "1395440",
    "end": "1397039"
  },
  {
    "text": "morocco you know northern africa right",
    "start": "1397039",
    "end": "1399360"
  },
  {
    "text": "here",
    "start": "1399360",
    "end": "1400240"
  },
  {
    "text": "i think you know southern spain up here",
    "start": "1400240",
    "end": "1402640"
  },
  {
    "text": "and then",
    "start": "1402640",
    "end": "1403280"
  },
  {
    "text": "here you see this these are this all",
    "start": "1403280",
    "end": "1405280"
  },
  {
    "text": "should be water so this is all like",
    "start": "1405280",
    "end": "1407039"
  },
  {
    "text": "actually like clusters of ships",
    "start": "1407039",
    "end": "1409200"
  },
  {
    "text": "um super busy port and if uh",
    "start": "1409200",
    "end": "1413600"
  },
  {
    "text": "and if anybody wants to see i've also",
    "start": "1413600",
    "end": "1415600"
  },
  {
    "text": "had a lot of fun generating these images",
    "start": "1415600",
    "end": "1417120"
  },
  {
    "text": "so i've generated some offline as well",
    "start": "1417120",
    "end": "1419679"
  },
  {
    "text": "um so this is these were four-year",
    "start": "1419679",
    "end": "1422720"
  },
  {
    "text": "composites",
    "start": "1422720",
    "end": "1424480"
  },
  {
    "text": "and it's like it's nuts look at all",
    "start": "1424480",
    "end": "1427520"
  },
  {
    "text": "those ships",
    "start": "1427520",
    "end": "1429440"
  },
  {
    "text": "so cool and uh",
    "start": "1429440",
    "end": "1432960"
  },
  {
    "text": "just to see like the number of images",
    "start": "1432960",
    "end": "1435360"
  },
  {
    "text": "that we",
    "start": "1435360",
    "end": "1436400"
  },
  {
    "text": "uh that we just computed that composite",
    "start": "1436400",
    "end": "1438480"
  },
  {
    "text": "over it's almo",
    "start": "1438480",
    "end": "1439600"
  },
  {
    "text": "it's over 1700 sentinel 2 images",
    "start": "1439600",
    "end": "1443360"
  },
  {
    "text": "which is a lot of imagery that's a lot",
    "start": "1443360",
    "end": "1446240"
  },
  {
    "text": "of bytes that we just processed",
    "start": "1446240",
    "end": "1448400"
  },
  {
    "text": "um and the fact that we did that another",
    "start": "1448400",
    "end": "1450640"
  },
  {
    "text": "20 seconds is pretty cool",
    "start": "1450640",
    "end": "1453520"
  },
  {
    "text": "um so yeah that's the uh that's a quick",
    "start": "1453520",
    "end": "1455919"
  },
  {
    "text": "demo of workflows",
    "start": "1455919",
    "end": "1457679"
  },
  {
    "text": "so back to the presentation",
    "start": "1457679",
    "end": "1461600"
  },
  {
    "start": "1463000",
    "end": "1463000"
  },
  {
    "text": "and uh how about some benchmarks between",
    "start": "1463360",
    "end": "1466159"
  },
  {
    "text": "the desk on ray back end versus the pure",
    "start": "1466159",
    "end": "1468880"
  },
  {
    "text": "local desk back end so uh one example",
    "start": "1468880",
    "end": "1472080"
  },
  {
    "text": "here's a three and a half year",
    "start": "1472080",
    "end": "1473520"
  },
  {
    "text": "uh sentinel-2 mean ndvi composite ndvi",
    "start": "1473520",
    "end": "1476799"
  },
  {
    "text": "is a very popular vegetation index",
    "start": "1476799",
    "end": "1479360"
  },
  {
    "text": "that vegetation uh it's it's basically",
    "start": "1479360",
    "end": "1481600"
  },
  {
    "text": "like a i think it's like a one or two",
    "start": "1481600",
    "end": "1483440"
  },
  {
    "text": "week",
    "start": "1483440",
    "end": "1484080"
  },
  {
    "text": "proxy for vegetation health um the",
    "start": "1484080",
    "end": "1487279"
  },
  {
    "text": "brightness of ndvi and here we go this",
    "start": "1487279",
    "end": "1490559"
  },
  {
    "text": "is actually very surprising to me",
    "start": "1490559",
    "end": "1492240"
  },
  {
    "text": "desk on ray is anywhere from",
    "start": "1492240",
    "end": "1496000"
  },
  {
    "text": "20 30",
    "start": "1496000",
    "end": "1499039"
  },
  {
    "text": "uh and then like uh",
    "start": "1499039",
    "end": "1502080"
  },
  {
    "text": "over you know like uh over 50 percent",
    "start": "1502080",
    "end": "1505039"
  },
  {
    "text": "faster",
    "start": "1505039",
    "end": "1506480"
  },
  {
    "text": "than um than plain desk which is very",
    "start": "1506480",
    "end": "1510320"
  },
  {
    "text": "surprising",
    "start": "1510320",
    "end": "1512880"
  },
  {
    "text": "still very surprising to me i actually",
    "start": "1513279",
    "end": "1514720"
  },
  {
    "text": "thought it was going to be a good bit",
    "start": "1514720",
    "end": "1515679"
  },
  {
    "text": "slower because there's so much overhead",
    "start": "1515679",
    "end": "1517039"
  },
  {
    "text": "we're creating the dash graph traversing",
    "start": "1517039",
    "end": "1518720"
  },
  {
    "text": "the dash graph to farm the tasks out to",
    "start": "1518720",
    "end": "1520640"
  },
  {
    "text": "a rate cluster and yet",
    "start": "1520640",
    "end": "1521840"
  },
  {
    "text": "uh somehow it's faster for these like",
    "start": "1521840",
    "end": "1524240"
  },
  {
    "text": "medium sized work uh",
    "start": "1524240",
    "end": "1525760"
  },
  {
    "text": "use cases which is surprising to me and",
    "start": "1525760",
    "end": "1528559"
  },
  {
    "text": "then",
    "start": "1528559",
    "end": "1529279"
  },
  {
    "text": "the previously impossible is now enabled",
    "start": "1529279",
    "end": "1531120"
  },
  {
    "text": "for example very temporarily dense",
    "start": "1531120",
    "end": "1533440"
  },
  {
    "text": "lots of scenes at thousands upon",
    "start": "1533440",
    "end": "1535279"
  },
  {
    "text": "thousands of scenes in this composite",
    "start": "1535279",
    "end": "1537600"
  },
  {
    "text": "at a high resolution the plane dashed",
    "start": "1537600",
    "end": "1539600"
  },
  {
    "text": "back in failed with an out of memory",
    "start": "1539600",
    "end": "1541279"
  },
  {
    "text": "error",
    "start": "1541279",
    "end": "1542240"
  },
  {
    "text": "and the raid back end i mean it took a",
    "start": "1542240",
    "end": "1544000"
  },
  {
    "text": "while it took like three",
    "start": "1544000",
    "end": "1545760"
  },
  {
    "text": "over three minutes but it uh it did it",
    "start": "1545760",
    "end": "1548559"
  },
  {
    "text": "this",
    "start": "1548559",
    "end": "1548880"
  },
  {
    "text": "this uh wasn't previously possible with",
    "start": "1548880",
    "end": "1551440"
  },
  {
    "text": "our with our with our last back end",
    "start": "1551440",
    "end": "1553360"
  },
  {
    "start": "1553000",
    "end": "1553000"
  },
  {
    "text": "which is cool",
    "start": "1553360",
    "end": "1554880"
  },
  {
    "text": "so future directions for desk on ray",
    "start": "1554880",
    "end": "1558000"
  },
  {
    "text": "where do we go from here um an actor",
    "start": "1558000",
    "end": "1560559"
  },
  {
    "text": "native callback abstraction i think",
    "start": "1560559",
    "end": "1562000"
  },
  {
    "text": "would be very compelling",
    "start": "1562000",
    "end": "1563440"
  },
  {
    "text": "uh this would be a tighter integration",
    "start": "1563440",
    "end": "1565679"
  },
  {
    "text": "with actors",
    "start": "1565679",
    "end": "1566640"
  },
  {
    "text": "when uh when hooking into the",
    "start": "1566640",
    "end": "1568840"
  },
  {
    "text": "race-specific",
    "start": "1568840",
    "end": "1570080"
  },
  {
    "text": "like the ray task execution life cycle",
    "start": "1570080",
    "end": "1572799"
  },
  {
    "text": "and",
    "start": "1572799",
    "end": "1573360"
  },
  {
    "text": "uh the reason why this is nice",
    "start": "1573360",
    "end": "1575840"
  },
  {
    "text": "everything that you want to do that does",
    "start": "1575840",
    "end": "1576960"
  },
  {
    "text": "any sort of like aggregation of state",
    "start": "1576960",
    "end": "1578640"
  },
  {
    "text": "is fundamentally going to require an",
    "start": "1578640",
    "end": "1579919"
  },
  {
    "text": "actor that that's a",
    "start": "1579919",
    "end": "1581679"
  },
  {
    "text": "that's what you're going to have to do",
    "start": "1581679",
    "end": "1583039"
  },
  {
    "text": "and the current pattern is you",
    "start": "1583039",
    "end": "1585039"
  },
  {
    "text": "you create like a ray das callback and",
    "start": "1585039",
    "end": "1587120"
  },
  {
    "text": "then you pass it an actor handle on",
    "start": "1587120",
    "end": "1589520"
  },
  {
    "text": "instantiation",
    "start": "1589520",
    "end": "1590559"
  },
  {
    "text": "and then whenever in any of those",
    "start": "1590559",
    "end": "1592320"
  },
  {
    "text": "callback hooks in any of those methods",
    "start": "1592320",
    "end": "1595039"
  },
  {
    "text": "that you implement and if you need to do",
    "start": "1595039",
    "end": "1596799"
  },
  {
    "text": "any sort of like state aggregation you",
    "start": "1596799",
    "end": "1598799"
  },
  {
    "text": "you pass that state to the actor via",
    "start": "1598799",
    "end": "1601919"
  },
  {
    "text": "like a remote method indication on the",
    "start": "1601919",
    "end": "1603679"
  },
  {
    "text": "actor handle",
    "start": "1603679",
    "end": "1605120"
  },
  {
    "text": "but we could have a much tighter",
    "start": "1605120",
    "end": "1606720"
  },
  {
    "text": "integration i didn't go that route the",
    "start": "1606720",
    "end": "1608080"
  },
  {
    "text": "first",
    "start": "1608080",
    "end": "1608480"
  },
  {
    "text": "time because i didn't there's some",
    "start": "1608480",
    "end": "1610480"
  },
  {
    "text": "callbacks that don't need an actor and",
    "start": "1610480",
    "end": "1612480"
  },
  {
    "text": "then that's unnecessary overhead if",
    "start": "1612480",
    "end": "1613919"
  },
  {
    "text": "you're having to do after rpc's",
    "start": "1613919",
    "end": "1616400"
  },
  {
    "text": "for pretty much everything um move the",
    "start": "1616400",
    "end": "1619360"
  },
  {
    "text": "unpacking and repacking of object",
    "start": "1619360",
    "end": "1620799"
  },
  {
    "text": "references into core array",
    "start": "1620799",
    "end": "1622799"
  },
  {
    "text": "right now in the desk on ray scheduler",
    "start": "1622799",
    "end": "1626799"
  },
  {
    "text": "what you have to do is you uh you given",
    "start": "1626799",
    "end": "1630000"
  },
  {
    "text": "that ray does not traverse",
    "start": "1630000",
    "end": "1632080"
  },
  {
    "text": "arbitrary python arbitrarily nested",
    "start": "1632080",
    "end": "1634480"
  },
  {
    "text": "python data structures to pull out",
    "start": "1634480",
    "end": "1636320"
  },
  {
    "text": "object references and to loop them into",
    "start": "1636320",
    "end": "1639600"
  },
  {
    "text": "the task's uh",
    "start": "1639600",
    "end": "1640720"
  },
  {
    "text": "argument dependencies you actually have",
    "start": "1640720",
    "end": "1643039"
  },
  {
    "text": "to do that unpacking and repacking",
    "start": "1643039",
    "end": "1645360"
  },
  {
    "text": "uh before task submission and then",
    "start": "1645360",
    "end": "1648080"
  },
  {
    "text": "flatten out the object references",
    "start": "1648080",
    "end": "1650000"
  },
  {
    "text": "and then passed uh pass a repackaging",
    "start": "1650000",
    "end": "1652320"
  },
  {
    "text": "function enclosure",
    "start": "1652320",
    "end": "1654000"
  },
  {
    "text": "into the ray task and then within the",
    "start": "1654000",
    "end": "1656159"
  },
  {
    "text": "rate task do",
    "start": "1656159",
    "end": "1657200"
  },
  {
    "text": "the unpacking um or do oh sorry do the",
    "start": "1657200",
    "end": "1660720"
  },
  {
    "text": "repacking within the rate task",
    "start": "1660720",
    "end": "1662640"
  },
  {
    "text": "and uh you know like i implemented that",
    "start": "1662640",
    "end": "1665840"
  },
  {
    "text": "it was fine",
    "start": "1665840",
    "end": "1666640"
  },
  {
    "text": "but it's something that could certainly",
    "start": "1666640",
    "end": "1667919"
  },
  {
    "text": "be supported natively within rey",
    "start": "1667919",
    "end": "1669600"
  },
  {
    "text": "probably more efficiently",
    "start": "1669600",
    "end": "1671039"
  },
  {
    "text": "just with like a little traverse keyword",
    "start": "1671039",
    "end": "1672960"
  },
  {
    "text": "argument for like the remote function",
    "start": "1672960",
    "end": "1675120"
  },
  {
    "text": "a plasma based caching solution would be",
    "start": "1675120",
    "end": "1677360"
  },
  {
    "text": "great task tasks are deterministic and",
    "start": "1677360",
    "end": "1679679"
  },
  {
    "text": "pure in general",
    "start": "1679679",
    "end": "1681120"
  },
  {
    "text": "um and they have like a content-based",
    "start": "1681120",
    "end": "1683600"
  },
  {
    "text": "key",
    "start": "1683600",
    "end": "1684799"
  },
  {
    "text": "content based like hash within its das",
    "start": "1684799",
    "end": "1687840"
  },
  {
    "text": "key and we've implemented caching",
    "start": "1687840",
    "end": "1690159"
  },
  {
    "text": "solutions on top of it before",
    "start": "1690159",
    "end": "1692080"
  },
  {
    "text": "but with apache plasma being distributed",
    "start": "1692080",
    "end": "1694320"
  },
  {
    "text": "in memory you know object store it's",
    "start": "1694320",
    "end": "1695760"
  },
  {
    "text": "like",
    "start": "1695760",
    "end": "1696080"
  },
  {
    "text": "well the data's already there be great",
    "start": "1696080",
    "end": "1698559"
  },
  {
    "text": "if like we could just",
    "start": "1698559",
    "end": "1699760"
  },
  {
    "text": "uh if we could use apache plasma as the",
    "start": "1699760",
    "end": "1703600"
  },
  {
    "text": "distributed cache",
    "start": "1703600",
    "end": "1705039"
  },
  {
    "text": "for the dascon ray system and we've",
    "start": "1705039",
    "end": "1708320"
  },
  {
    "text": "implemented that we've had to jump",
    "start": "1708320",
    "end": "1709840"
  },
  {
    "text": "through some hoops because of like",
    "start": "1709840",
    "end": "1711840"
  },
  {
    "text": "uh the like object ownership semantics",
    "start": "1711840",
    "end": "1715440"
  },
  {
    "text": "and not being able to transfer the",
    "start": "1715440",
    "end": "1716880"
  },
  {
    "text": "ownership of an object to like a",
    "start": "1716880",
    "end": "1718320"
  },
  {
    "text": "long-lived caching actor",
    "start": "1718320",
    "end": "1720000"
  },
  {
    "text": "uh adding locality aware scheduling in",
    "start": "1720000",
    "end": "1722240"
  },
  {
    "text": "core ray would bring us",
    "start": "1722240",
    "end": "1723679"
  },
  {
    "text": "closer to the scheduling intelligence of",
    "start": "1723679",
    "end": "1725679"
  },
  {
    "text": "death distributed global scheduler",
    "start": "1725679",
    "end": "1728159"
  },
  {
    "text": "and uh it's i think i've",
    "start": "1728159",
    "end": "1731360"
  },
  {
    "text": "seen it mentioned a few times there's",
    "start": "1731360",
    "end": "1733440"
  },
  {
    "text": "some blockers but that's going to",
    "start": "1733440",
    "end": "1734960"
  },
  {
    "text": "probably be coming up in the medium term",
    "start": "1734960",
    "end": "1738080"
  },
  {
    "text": "and then work stealing there's actually",
    "start": "1738080",
    "end": "1739520"
  },
  {
    "text": "an open pr for that right now",
    "start": "1739520",
    "end": "1741200"
  },
  {
    "text": "in rey uh which would be super super",
    "start": "1741200",
    "end": "1743600"
  },
  {
    "text": "cool",
    "start": "1743600",
    "end": "1745679"
  },
  {
    "text": "uh so that was that was my talk thank",
    "start": "1745679",
    "end": "1747760"
  },
  {
    "text": "you i hope that there are some questions",
    "start": "1747760",
    "end": "1749760"
  },
  {
    "text": "thank you very much for listening let me",
    "start": "1749760",
    "end": "1752080"
  },
  {
    "text": "know if you have any questions",
    "start": "1752080",
    "end": "1753880"
  },
  {
    "text": "thanks",
    "start": "1753880",
    "end": "1756880"
  }
]
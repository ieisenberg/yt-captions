[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "[Music]",
    "start": "200",
    "end": "14639"
  },
  {
    "text": "hi",
    "start": "14639",
    "end": "15200"
  },
  {
    "text": "i am peter abeel and i'm a professor at",
    "start": "15200",
    "end": "18000"
  },
  {
    "text": "uc berkeley",
    "start": "18000",
    "end": "19119"
  },
  {
    "text": "founder of covariant and also host of",
    "start": "19119",
    "end": "21439"
  },
  {
    "text": "the robot brains podcast",
    "start": "21439",
    "end": "23840"
  },
  {
    "text": "and today i'd like to share with you a",
    "start": "23840",
    "end": "26960"
  },
  {
    "text": "new direction",
    "start": "26960",
    "end": "28000"
  },
  {
    "text": "in reinforced learning research that i",
    "start": "28000",
    "end": "30160"
  },
  {
    "text": "think will be really important",
    "start": "30160",
    "end": "31519"
  },
  {
    "text": "as we try to put reinforcement learning",
    "start": "31519",
    "end": "33920"
  },
  {
    "text": "to work in the real world",
    "start": "33920",
    "end": "35520"
  },
  {
    "text": "and that is human in the loop",
    "start": "35520",
    "end": "36960"
  },
  {
    "text": "reinforcement learning",
    "start": "36960",
    "end": "39520"
  },
  {
    "start": "38000",
    "end": "113000"
  },
  {
    "text": "before we dive into that let's take a",
    "start": "39520",
    "end": "41520"
  },
  {
    "text": "look at the recent fast progress",
    "start": "41520",
    "end": "43520"
  },
  {
    "text": "in deep reinforcement learning arguably",
    "start": "43520",
    "end": "46239"
  },
  {
    "text": "the result that",
    "start": "46239",
    "end": "47360"
  },
  {
    "text": "got everybody so excited about deep",
    "start": "47360",
    "end": "49120"
  },
  {
    "text": "reinforced learning was back in 2013",
    "start": "49120",
    "end": "51840"
  },
  {
    "text": "when deepmind showed that neural",
    "start": "51840",
    "end": "54000"
  },
  {
    "text": "networks can learn to play video games",
    "start": "54000",
    "end": "56239"
  },
  {
    "text": "from their own trial and airplane",
    "start": "56239",
    "end": "58879"
  },
  {
    "text": "actually interestingly under the hood",
    "start": "58879",
    "end": "60480"
  },
  {
    "text": "it was just a standard convolutional",
    "start": "60480",
    "end": "62399"
  },
  {
    "text": "network clock used in computer vision",
    "start": "62399",
    "end": "64478"
  },
  {
    "text": "but it was trained very differently it",
    "start": "64479",
    "end": "66000"
  },
  {
    "text": "was trained from its own trial and error",
    "start": "66000",
    "end": "67840"
  },
  {
    "text": "from its own practice of playing the",
    "start": "67840",
    "end": "69520"
  },
  {
    "text": "games",
    "start": "69520",
    "end": "70479"
  },
  {
    "text": "rather than from human labels of what to",
    "start": "70479",
    "end": "73200"
  },
  {
    "text": "do",
    "start": "73200",
    "end": "74799"
  },
  {
    "text": "then deepmind showed that actually",
    "start": "74799",
    "end": "76720"
  },
  {
    "text": "reinforcement learning can master the",
    "start": "76720",
    "end": "78400"
  },
  {
    "text": "game of go",
    "start": "78400",
    "end": "79759"
  },
  {
    "text": "uh be top human players",
    "start": "79759",
    "end": "83759"
  },
  {
    "text": "while deepmind was working on deep",
    "start": "83759",
    "end": "86159"
  },
  {
    "text": "reinforced learning for the game of go",
    "start": "86159",
    "end": "87840"
  },
  {
    "text": "and video games",
    "start": "87840",
    "end": "88880"
  },
  {
    "text": "at berkeley actually in my lab we worked",
    "start": "88880",
    "end": "90560"
  },
  {
    "text": "on deep reinforcement learning",
    "start": "90560",
    "end": "92400"
  },
  {
    "text": "same ideas effectively but for robotic",
    "start": "92400",
    "end": "95600"
  },
  {
    "text": "control",
    "start": "95600",
    "end": "96479"
  },
  {
    "text": "and so we're watching here is a robot",
    "start": "96479",
    "end": "98640"
  },
  {
    "text": "that's running reinforcement learning",
    "start": "98640",
    "end": "100799"
  },
  {
    "text": "and you see through trial and error it's",
    "start": "100799",
    "end": "103040"
  },
  {
    "text": "improving",
    "start": "103040",
    "end": "103920"
  },
  {
    "text": "its performance in this case the further",
    "start": "103920",
    "end": "106159"
  },
  {
    "text": "it runs to the right the better",
    "start": "106159",
    "end": "107920"
  },
  {
    "text": "and indeed over time it becomes better",
    "start": "107920",
    "end": "109840"
  },
  {
    "text": "and better at running off to the right",
    "start": "109840",
    "end": "113520"
  },
  {
    "start": "113000",
    "end": "269000"
  },
  {
    "text": "then from there we took this to some",
    "start": "113600",
    "end": "116640"
  },
  {
    "text": "real robots so what you see here is the",
    "start": "116640",
    "end": "118560"
  },
  {
    "text": "berkeley robot for the elimination of",
    "start": "118560",
    "end": "120479"
  },
  {
    "text": "tedious tasks brett",
    "start": "120479",
    "end": "122320"
  },
  {
    "text": "who lives in the berkeley ai lab",
    "start": "122320",
    "end": "125280"
  },
  {
    "text": "learning to put the block into the",
    "start": "125280",
    "end": "126560"
  },
  {
    "text": "matching opening",
    "start": "126560",
    "end": "127759"
  },
  {
    "text": "and so here a neural network is being",
    "start": "127759",
    "end": "129679"
  },
  {
    "text": "trained that learns both a vision system",
    "start": "129679",
    "end": "132080"
  },
  {
    "text": "and a control system to put the block",
    "start": "132080",
    "end": "134480"
  },
  {
    "text": "into its target location",
    "start": "134480",
    "end": "136560"
  },
  {
    "text": "and this can be learned in about one",
    "start": "136560",
    "end": "138640"
  },
  {
    "text": "hour of uh",
    "start": "138640",
    "end": "140239"
  },
  {
    "text": "training time and maybe one of the most",
    "start": "140239",
    "end": "143520"
  },
  {
    "text": "visible results recently",
    "start": "143520",
    "end": "145280"
  },
  {
    "text": "was when opening eyes showed that it's",
    "start": "145280",
    "end": "147520"
  },
  {
    "text": "possible",
    "start": "147520",
    "end": "148720"
  },
  {
    "text": "to train a robotic hand to solve rubik's",
    "start": "148720",
    "end": "151519"
  },
  {
    "text": "cubes",
    "start": "151519",
    "end": "152400"
  },
  {
    "text": "and that's what we're watching in action",
    "start": "152400",
    "end": "154080"
  },
  {
    "text": "here after a lot of training it's",
    "start": "154080",
    "end": "156319"
  },
  {
    "text": "figured it out and as we",
    "start": "156319",
    "end": "157920"
  },
  {
    "text": "fast forward it's actually able to solve",
    "start": "157920",
    "end": "160879"
  },
  {
    "text": "this rubik's cube",
    "start": "160879",
    "end": "163680"
  },
  {
    "text": "so a lot of progress has been made",
    "start": "163680",
    "end": "166160"
  },
  {
    "text": "through this paradigm of",
    "start": "166160",
    "end": "167680"
  },
  {
    "text": "repeated trial and error learning where",
    "start": "167680",
    "end": "169280"
  },
  {
    "text": "the robot or",
    "start": "169280",
    "end": "170959"
  },
  {
    "text": "other decision making system will take",
    "start": "170959",
    "end": "172800"
  },
  {
    "text": "actions in the world",
    "start": "172800",
    "end": "174239"
  },
  {
    "text": "it will then be faced with the",
    "start": "174239",
    "end": "175360"
  },
  {
    "text": "consequences of those actions observing",
    "start": "175360",
    "end": "177360"
  },
  {
    "text": "those",
    "start": "177360",
    "end": "178080"
  },
  {
    "text": "as well as possibly get rewarded uh when",
    "start": "178080",
    "end": "180959"
  },
  {
    "text": "there are good outcomes",
    "start": "180959",
    "end": "182319"
  },
  {
    "text": "and of course the goal is for the system",
    "start": "182319",
    "end": "184959"
  },
  {
    "text": "to learn to optimize the rewards",
    "start": "184959",
    "end": "188159"
  },
  {
    "text": "now when you do this and start putting",
    "start": "188159",
    "end": "190879"
  },
  {
    "text": "this into practice one thing you'll",
    "start": "190879",
    "end": "192319"
  },
  {
    "text": "quickly notice",
    "start": "192319",
    "end": "193519"
  },
  {
    "text": "even though our reinforcement audience",
    "start": "193519",
    "end": "195760"
  },
  {
    "text": "have become very good",
    "start": "195760",
    "end": "197040"
  },
  {
    "text": "when you run them they're very good at",
    "start": "197040",
    "end": "199840"
  },
  {
    "text": "optimizing",
    "start": "199840",
    "end": "200800"
  },
  {
    "text": "whatever it is you ask them to optimize",
    "start": "200800",
    "end": "202800"
  },
  {
    "text": "so in this case",
    "start": "202800",
    "end": "204000"
  },
  {
    "text": "this robot learned to run but not in a",
    "start": "204000",
    "end": "205760"
  },
  {
    "text": "very natural way",
    "start": "205760",
    "end": "207200"
  },
  {
    "text": "what is it optimizing it's optimizing",
    "start": "207200",
    "end": "209040"
  },
  {
    "text": "the x-coordinate the further forward the",
    "start": "209040",
    "end": "210879"
  },
  {
    "text": "better",
    "start": "210879",
    "end": "211599"
  },
  {
    "text": "it's minimizing torques that seems",
    "start": "211599",
    "end": "213280"
  },
  {
    "text": "natural minimizing energy expended",
    "start": "213280",
    "end": "215440"
  },
  {
    "text": "and then it's trying to keep the center",
    "start": "215440",
    "end": "217200"
  },
  {
    "text": "of gravity of the robot",
    "start": "217200",
    "end": "218959"
  },
  {
    "text": "close to 1.3 meters height so those seem",
    "start": "218959",
    "end": "222879"
  },
  {
    "text": "somewhat natural objectives but it",
    "start": "222879",
    "end": "225920"
  },
  {
    "text": "doesn't result in natural running",
    "start": "225920",
    "end": "228159"
  },
  {
    "text": "and so yes it's optimized but is that",
    "start": "228159",
    "end": "231360"
  },
  {
    "text": "what you want",
    "start": "231360",
    "end": "232400"
  },
  {
    "text": "um imagine taking it to a different kind",
    "start": "232400",
    "end": "234959"
  },
  {
    "text": "of application domain like let's say",
    "start": "234959",
    "end": "236799"
  },
  {
    "text": "cooking",
    "start": "236799",
    "end": "237599"
  },
  {
    "text": "it's going to be really hard to specify",
    "start": "237599",
    "end": "239280"
  },
  {
    "text": "exactly what you want there",
    "start": "239280",
    "end": "240959"
  },
  {
    "text": "and even in games it can happen that you",
    "start": "240959",
    "end": "243680"
  },
  {
    "text": "misspecify",
    "start": "243680",
    "end": "244879"
  },
  {
    "text": "the score in the game so here's an ai",
    "start": "244879",
    "end": "246799"
  },
  {
    "text": "playing",
    "start": "246799",
    "end": "248480"
  },
  {
    "text": "this boat racing game but it turns out",
    "start": "248480",
    "end": "250480"
  },
  {
    "text": "that you get a higher score in the game",
    "start": "250480",
    "end": "252400"
  },
  {
    "text": "for just circling around in the harbor",
    "start": "252400",
    "end": "254640"
  },
  {
    "text": "rather than actually participating in",
    "start": "254640",
    "end": "256160"
  },
  {
    "text": "the race",
    "start": "256160",
    "end": "256880"
  },
  {
    "text": "which you see in the top left graphic",
    "start": "256880",
    "end": "258880"
  },
  {
    "text": "here all the other boats are doing",
    "start": "258880",
    "end": "260720"
  },
  {
    "text": "and so it shows that the score in the",
    "start": "260720",
    "end": "262639"
  },
  {
    "text": "game even in a game can be hard to",
    "start": "262639",
    "end": "264560"
  },
  {
    "text": "specify",
    "start": "264560",
    "end": "265680"
  },
  {
    "text": "correctly to get the desired behavior",
    "start": "265680",
    "end": "267600"
  },
  {
    "text": "out",
    "start": "267600",
    "end": "269040"
  },
  {
    "text": "so what could be an alternative solution",
    "start": "269040",
    "end": "272800"
  },
  {
    "text": "to you know this struggle of designing",
    "start": "272800",
    "end": "275120"
  },
  {
    "text": "the correct reward function",
    "start": "275120",
    "end": "277680"
  },
  {
    "text": "well reinforced learning algorithms",
    "start": "277680",
    "end": "280320"
  },
  {
    "text": "operate by interacting with the",
    "start": "280320",
    "end": "281759"
  },
  {
    "text": "environment",
    "start": "281759",
    "end": "282479"
  },
  {
    "text": "and the way to get scored is with reward",
    "start": "282479",
    "end": "285520"
  },
  {
    "text": "can we maybe replace this with human",
    "start": "285520",
    "end": "287919"
  },
  {
    "text": "input",
    "start": "287919",
    "end": "288880"
  },
  {
    "text": "because if as humans we know what we",
    "start": "288880",
    "end": "291840"
  },
  {
    "text": "want",
    "start": "291840",
    "end": "292960"
  },
  {
    "text": "maybe we could give feedback just like",
    "start": "292960",
    "end": "294639"
  },
  {
    "text": "we do when we teach other humans",
    "start": "294639",
    "end": "296880"
  },
  {
    "text": "and then we could actually get what we",
    "start": "296880",
    "end": "298720"
  },
  {
    "text": "want if the boat were going in circles",
    "start": "298720",
    "end": "300479"
  },
  {
    "text": "we",
    "start": "300479",
    "end": "301039"
  },
  {
    "text": "would give it negative feedback if it's",
    "start": "301039",
    "end": "303120"
  },
  {
    "text": "racing",
    "start": "303120",
    "end": "304400"
  },
  {
    "text": "against the other boats we would give it",
    "start": "304400",
    "end": "305840"
  },
  {
    "text": "positive feedback",
    "start": "305840",
    "end": "307840"
  },
  {
    "text": "of course now the question is how to",
    "start": "307840",
    "end": "309680"
  },
  {
    "text": "formalize this how do we formally get a",
    "start": "309680",
    "end": "311360"
  },
  {
    "text": "human",
    "start": "311360",
    "end": "311919"
  },
  {
    "text": "into the reinforcement learning loop",
    "start": "311919",
    "end": "316400"
  },
  {
    "text": "it's a bunch of papers that have",
    "start": "316479",
    "end": "317680"
  },
  {
    "text": "happened a couple years ago that",
    "start": "317680",
    "end": "319680"
  },
  {
    "text": "started looking at this within the",
    "start": "319680",
    "end": "321440"
  },
  {
    "text": "modern era of deep reinforcement",
    "start": "321440",
    "end": "323520"
  },
  {
    "text": "learning",
    "start": "323520",
    "end": "324320"
  },
  {
    "text": "and the general idea here that we're",
    "start": "324320",
    "end": "327280"
  },
  {
    "text": "also building upon",
    "start": "327280",
    "end": "328720"
  },
  {
    "text": "and what i'll present here is the idea",
    "start": "328720",
    "end": "330240"
  },
  {
    "text": "that the way the human interacts with",
    "start": "330240",
    "end": "332880"
  },
  {
    "text": "our system",
    "start": "332880",
    "end": "333840"
  },
  {
    "text": "is by looking at two executions",
    "start": "333840",
    "end": "337120"
  },
  {
    "text": "two rollouts and the human will say",
    "start": "337120",
    "end": "340479"
  },
  {
    "text": "one is better than the other specifying",
    "start": "340479",
    "end": "342880"
  },
  {
    "text": "a preference",
    "start": "342880",
    "end": "344160"
  },
  {
    "text": "over behaviors and that's what we're",
    "start": "344160",
    "end": "346479"
  },
  {
    "text": "gonna get",
    "start": "346479",
    "end": "347520"
  },
  {
    "text": "so that's the only thing human will have",
    "start": "347520",
    "end": "350320"
  },
  {
    "text": "to do is",
    "start": "350320",
    "end": "351520"
  },
  {
    "text": "say which rollout they prefer between",
    "start": "351520",
    "end": "354080"
  },
  {
    "text": "two rollouts",
    "start": "354080",
    "end": "356720"
  },
  {
    "text": "human this way has the ability to",
    "start": "356720",
    "end": "358319"
  },
  {
    "text": "interactively guide agents according to",
    "start": "358319",
    "end": "360080"
  },
  {
    "text": "their progress",
    "start": "360080",
    "end": "361600"
  },
  {
    "text": "this allows us as you'll see to teach",
    "start": "361600",
    "end": "363759"
  },
  {
    "text": "harder tasks",
    "start": "363759",
    "end": "364960"
  },
  {
    "text": "or it's hard to specify a reward",
    "start": "364960",
    "end": "366720"
  },
  {
    "text": "function by hand",
    "start": "366720",
    "end": "368240"
  },
  {
    "text": "and also can avoid reward exploitation",
    "start": "368240",
    "end": "370880"
  },
  {
    "text": "where",
    "start": "370880",
    "end": "371759"
  },
  {
    "text": "the wrong reward is being optimized and",
    "start": "371759",
    "end": "374720"
  },
  {
    "text": "we don't get the behavior",
    "start": "374720",
    "end": "375919"
  },
  {
    "text": "we want so the pebble algorithm which",
    "start": "375919",
    "end": "380000"
  },
  {
    "text": "is a recently uh proposed algorithm that",
    "start": "380000",
    "end": "383039"
  },
  {
    "text": "we developed over the last few months",
    "start": "383039",
    "end": "386000"
  },
  {
    "text": "operates as follows",
    "start": "386000",
    "end": "387199"
  },
  {
    "text": "step one we collect samples via",
    "start": "387199",
    "end": "389440"
  },
  {
    "text": "interaction with the environment so the",
    "start": "389440",
    "end": "390800"
  },
  {
    "text": "agent just goes and interacts",
    "start": "390800",
    "end": "393600"
  },
  {
    "text": "then we present some of those",
    "start": "393600",
    "end": "395520"
  },
  {
    "text": "interactions with the environment to our",
    "start": "395520",
    "end": "397199"
  },
  {
    "text": "human supervisor",
    "start": "397199",
    "end": "398560"
  },
  {
    "text": "who can then decide which between pairs",
    "start": "398560",
    "end": "401199"
  },
  {
    "text": "of interactions they prefer",
    "start": "401199",
    "end": "404000"
  },
  {
    "text": "then a reward model is trained",
    "start": "404000",
    "end": "407840"
  },
  {
    "text": "using cross-entropy laws meaning that",
    "start": "407840",
    "end": "409840"
  },
  {
    "text": "we're going to turn these human",
    "start": "409840",
    "end": "411199"
  },
  {
    "text": "preferences between trajectories",
    "start": "411199",
    "end": "413759"
  },
  {
    "text": "into a learned reward function",
    "start": "413759",
    "end": "417520"
  },
  {
    "text": "now the beauty about doing this is that",
    "start": "417520",
    "end": "419039"
  },
  {
    "text": "once we learn a reward function",
    "start": "419039",
    "end": "420960"
  },
  {
    "text": "we can again rely on the really powerful",
    "start": "420960",
    "end": "423440"
  },
  {
    "text": "reinforcement algorithms we have these",
    "start": "423440",
    "end": "425199"
  },
  {
    "text": "days",
    "start": "425199",
    "end": "425759"
  },
  {
    "text": "to optimize that reward so we're going",
    "start": "425759",
    "end": "427759"
  },
  {
    "text": "to turn human input",
    "start": "427759",
    "end": "429520"
  },
  {
    "text": "into a reward we can then optimize now",
    "start": "429520",
    "end": "432240"
  },
  {
    "text": "how do we do this",
    "start": "432240",
    "end": "434000"
  },
  {
    "text": "we actually train a classifier for that",
    "start": "434000",
    "end": "435919"
  },
  {
    "text": "effectively so this follows the bradley",
    "start": "435919",
    "end": "438400"
  },
  {
    "text": "terry model",
    "start": "438400",
    "end": "439599"
  },
  {
    "text": "um what we're looking at here is we're",
    "start": "439599",
    "end": "442080"
  },
  {
    "text": "looking at the probability that",
    "start": "442080",
    "end": "443360"
  },
  {
    "text": "trajectory one sigma one",
    "start": "443360",
    "end": "445199"
  },
  {
    "text": "is better according to human prefaces",
    "start": "445199",
    "end": "447440"
  },
  {
    "text": "than trajectory two sigma zero",
    "start": "447440",
    "end": "451120"
  },
  {
    "text": "is based on the exponentiated sum of",
    "start": "451120",
    "end": "453759"
  },
  {
    "text": "rewards",
    "start": "453759",
    "end": "454479"
  },
  {
    "text": "along trajectory 1 divided by the sum",
    "start": "454479",
    "end": "457919"
  },
  {
    "text": "of exponentiated rewards along the other",
    "start": "457919",
    "end": "460319"
  },
  {
    "text": "trajectories",
    "start": "460319",
    "end": "462000"
  },
  {
    "text": "so if a charger is preferred i'll have",
    "start": "462000",
    "end": "465039"
  },
  {
    "text": "high reward",
    "start": "465039",
    "end": "466560"
  },
  {
    "text": "and we'll have a high score here if it's",
    "start": "466560",
    "end": "468479"
  },
  {
    "text": "not preferred",
    "start": "468479",
    "end": "469840"
  },
  {
    "text": "it should have a low score low reward",
    "start": "469840",
    "end": "474319"
  },
  {
    "text": "so that is our training objective for",
    "start": "474319",
    "end": "476720"
  },
  {
    "text": "training the reward function so we try",
    "start": "476720",
    "end": "478240"
  },
  {
    "text": "to find a reward function consistent",
    "start": "478240",
    "end": "480000"
  },
  {
    "text": "with human preferences",
    "start": "480000",
    "end": "481520"
  },
  {
    "text": "according to this model once we have",
    "start": "481520",
    "end": "484479"
  },
  {
    "text": "trained that reward function which will",
    "start": "484479",
    "end": "486080"
  },
  {
    "text": "be a deep neural network in itself",
    "start": "486080",
    "end": "488080"
  },
  {
    "text": "we can then optimize the policy using in",
    "start": "488080",
    "end": "491039"
  },
  {
    "text": "our case of pulse and reinforced",
    "start": "491039",
    "end": "492560"
  },
  {
    "text": "learning algorithms we use soft active",
    "start": "492560",
    "end": "494240"
  },
  {
    "text": "critic",
    "start": "494240",
    "end": "495759"
  },
  {
    "text": "and then we repeat we collect new",
    "start": "495759",
    "end": "498319"
  },
  {
    "text": "interactions with the environment",
    "start": "498319",
    "end": "499840"
  },
  {
    "text": "again collect human preferences update",
    "start": "499840",
    "end": "502479"
  },
  {
    "start": "502000",
    "end": "763000"
  },
  {
    "text": "our reward model",
    "start": "502479",
    "end": "504000"
  },
  {
    "text": "then optimize our policy again and keep",
    "start": "504000",
    "end": "506319"
  },
  {
    "text": "repeating",
    "start": "506319",
    "end": "508080"
  },
  {
    "text": "so now one thing you might wonder if",
    "start": "508080",
    "end": "511759"
  },
  {
    "text": "the human has to right away supervise",
    "start": "511759",
    "end": "513839"
  },
  {
    "text": "the reinforcement agent",
    "start": "513839",
    "end": "515760"
  },
  {
    "text": "in the beginning the agent doesn't know",
    "start": "515760",
    "end": "517120"
  },
  {
    "text": "what to do at all it might look pretty",
    "start": "517120",
    "end": "518640"
  },
  {
    "text": "random",
    "start": "518640",
    "end": "519440"
  },
  {
    "text": "and so we use something called",
    "start": "519440",
    "end": "520800"
  },
  {
    "text": "unsupervised pre-training",
    "start": "520800",
    "end": "523120"
  },
  {
    "text": "apt to help us there so if you just have",
    "start": "523120",
    "end": "526080"
  },
  {
    "text": "random interactions",
    "start": "526080",
    "end": "527839"
  },
  {
    "text": "you get what you see on the left and if",
    "start": "527839",
    "end": "529839"
  },
  {
    "text": "you see many versions of that it might",
    "start": "529839",
    "end": "531279"
  },
  {
    "text": "be hard to decide which one's better or",
    "start": "531279",
    "end": "532880"
  },
  {
    "text": "worse",
    "start": "532880",
    "end": "533600"
  },
  {
    "text": "but if you do unsupervised pre-training",
    "start": "533600",
    "end": "536720"
  },
  {
    "text": "you get what you see on the right as the",
    "start": "536720",
    "end": "538959"
  },
  {
    "text": "initial behaviors",
    "start": "538959",
    "end": "540240"
  },
  {
    "text": "and now you might start having clear",
    "start": "540240",
    "end": "542320"
  },
  {
    "text": "preferences between",
    "start": "542320",
    "end": "543920"
  },
  {
    "text": "different behaviors you see there",
    "start": "543920",
    "end": "547279"
  },
  {
    "text": "so we do first the pre-training and then",
    "start": "547360",
    "end": "549920"
  },
  {
    "text": "bring human in the loop",
    "start": "549920",
    "end": "551519"
  },
  {
    "text": "can you must teach novel behaviors this",
    "start": "551519",
    "end": "553680"
  },
  {
    "text": "way",
    "start": "553680",
    "end": "555440"
  },
  {
    "text": "well let's take a look what we see here",
    "start": "555440",
    "end": "558000"
  },
  {
    "text": "is",
    "start": "558000",
    "end": "559680"
  },
  {
    "text": "two different behaviors we have a card",
    "start": "559680",
    "end": "562320"
  },
  {
    "text": "pole spinning clockwise",
    "start": "562320",
    "end": "563920"
  },
  {
    "text": "and counterclockwise and this was",
    "start": "563920",
    "end": "566959"
  },
  {
    "text": "trained in less than five minutes",
    "start": "566959",
    "end": "569120"
  },
  {
    "text": "with just 40 queries to the human",
    "start": "569120",
    "end": "571279"
  },
  {
    "text": "supervisor",
    "start": "571279",
    "end": "572399"
  },
  {
    "text": "with two different runs the reason i'm",
    "start": "572399",
    "end": "574959"
  },
  {
    "text": "showing two different runs",
    "start": "574959",
    "end": "576720"
  },
  {
    "text": "is because i want to show that the human",
    "start": "576720",
    "end": "579680"
  },
  {
    "text": "who supervises the learning",
    "start": "579680",
    "end": "581600"
  },
  {
    "text": "can direct the behavior can choose to",
    "start": "581600",
    "end": "583760"
  },
  {
    "text": "get it to turn clockwise or",
    "start": "583760",
    "end": "585279"
  },
  {
    "text": "counterclockwise",
    "start": "585279",
    "end": "586480"
  },
  {
    "text": "depending on what they want um here's",
    "start": "586480",
    "end": "589519"
  },
  {
    "text": "another example here it's a",
    "start": "589519",
    "end": "591200"
  },
  {
    "text": "four-legged robot uh often referred to",
    "start": "591200",
    "end": "593920"
  },
  {
    "text": "as an ant robot from the majoko",
    "start": "593920",
    "end": "595760"
  },
  {
    "text": "environment",
    "start": "595760",
    "end": "596720"
  },
  {
    "text": "and we see that here in 200 queries less",
    "start": "596720",
    "end": "599440"
  },
  {
    "text": "than 30 minutes of interaction",
    "start": "599440",
    "end": "601680"
  },
  {
    "text": "the human was able to in one",
    "start": "601680",
    "end": "604800"
  },
  {
    "text": "run teach you to lift the left front leg",
    "start": "604800",
    "end": "607519"
  },
  {
    "text": "and the other run",
    "start": "607519",
    "end": "608800"
  },
  {
    "text": "lift the right front leg so you can",
    "start": "608800",
    "end": "610720"
  },
  {
    "text": "deliberately teach it different",
    "start": "610720",
    "end": "612240"
  },
  {
    "text": "behaviors",
    "start": "612240",
    "end": "613360"
  },
  {
    "text": "through specifying preferences between",
    "start": "613360",
    "end": "615360"
  },
  {
    "text": "rollouts",
    "start": "615360",
    "end": "617839"
  },
  {
    "text": "also been able to teach it a backflip",
    "start": "617839",
    "end": "619760"
  },
  {
    "text": "which is a very complex behavior if you",
    "start": "619760",
    "end": "621440"
  },
  {
    "text": "think about",
    "start": "621440",
    "end": "622399"
  },
  {
    "text": "how you design a reward function for a",
    "start": "622399",
    "end": "624240"
  },
  {
    "text": "backflip it's not really clear what",
    "start": "624240",
    "end": "626079"
  },
  {
    "text": "you'd want to do",
    "start": "626079",
    "end": "627440"
  },
  {
    "text": "but when you see it's a backflip you",
    "start": "627440",
    "end": "629920"
  },
  {
    "text": "recognize it",
    "start": "629920",
    "end": "630880"
  },
  {
    "text": "and when you get something that's closer",
    "start": "630880",
    "end": "632399"
  },
  {
    "text": "to it you might recognize it and that as",
    "start": "632399",
    "end": "634240"
  },
  {
    "text": "a human gives you the ability to provide",
    "start": "634240",
    "end": "636079"
  },
  {
    "text": "preferences between different behaviors",
    "start": "636079",
    "end": "638880"
  },
  {
    "text": "and hence teach",
    "start": "638880",
    "end": "639920"
  },
  {
    "text": "this robot to do backflips",
    "start": "639920",
    "end": "643360"
  },
  {
    "text": "now one of the original questions we had",
    "start": "643360",
    "end": "645279"
  },
  {
    "text": "can we avoid reward exploitation",
    "start": "645279",
    "end": "647680"
  },
  {
    "text": "where we just naturally in",
    "start": "647680",
    "end": "650800"
  },
  {
    "text": "prior work on reinforcement we design a",
    "start": "650800",
    "end": "652720"
  },
  {
    "text": "reward function",
    "start": "652720",
    "end": "654160"
  },
  {
    "text": "we then get a behavior out that",
    "start": "654160",
    "end": "655920"
  },
  {
    "text": "optimizes the reward function but it's",
    "start": "655920",
    "end": "657519"
  },
  {
    "text": "actually not the behavior",
    "start": "657519",
    "end": "658720"
  },
  {
    "text": "we want so what we see here is uh reward",
    "start": "658720",
    "end": "662320"
  },
  {
    "text": "exploitation happening on the left",
    "start": "662320",
    "end": "664399"
  },
  {
    "text": "when we just train the standard uh",
    "start": "664399",
    "end": "666320"
  },
  {
    "text": "majoka walker",
    "start": "666320",
    "end": "667680"
  },
  {
    "text": "with the standard reward function in",
    "start": "667680",
    "end": "669279"
  },
  {
    "text": "there that is a reward function",
    "start": "669279",
    "end": "670720"
  },
  {
    "text": "supposedly for running",
    "start": "670720",
    "end": "672000"
  },
  {
    "text": "but it's doing this dragging thing which",
    "start": "672000",
    "end": "673839"
  },
  {
    "text": "is not what we want",
    "start": "673839",
    "end": "675200"
  },
  {
    "text": "um well if we teach with human",
    "start": "675200",
    "end": "677680"
  },
  {
    "text": "preferences",
    "start": "677680",
    "end": "678720"
  },
  {
    "text": "we can actually get it to run in a way",
    "start": "678720",
    "end": "680399"
  },
  {
    "text": "that is much more natural",
    "start": "680399",
    "end": "682160"
  },
  {
    "text": "than we can with uh reward functions",
    "start": "682160",
    "end": "685040"
  },
  {
    "text": "that we",
    "start": "685040",
    "end": "686839"
  },
  {
    "text": "design",
    "start": "686839",
    "end": "689200"
  },
  {
    "text": "so we also compare this with um",
    "start": "689200",
    "end": "692399"
  },
  {
    "text": "different methods so when we look at the",
    "start": "692399",
    "end": "694480"
  },
  {
    "text": "graphs here we have three different",
    "start": "694480",
    "end": "696000"
  },
  {
    "text": "environments",
    "start": "696000",
    "end": "696959"
  },
  {
    "text": "quadruped cheetah and walker left to",
    "start": "696959",
    "end": "699600"
  },
  {
    "text": "right",
    "start": "699600",
    "end": "700640"
  },
  {
    "text": "they're showing at the bottom and then",
    "start": "700640",
    "end": "702399"
  },
  {
    "text": "we see at the top are learning curves",
    "start": "702399",
    "end": "704240"
  },
  {
    "text": "so the further we go to the right the",
    "start": "704240",
    "end": "706399"
  },
  {
    "text": "more interaction",
    "start": "706399",
    "end": "707519"
  },
  {
    "text": "the robot has had with the environment",
    "start": "707519",
    "end": "709920"
  },
  {
    "text": "and the more it's",
    "start": "709920",
    "end": "710880"
  },
  {
    "text": "up the higher it is scoring um",
    "start": "710880",
    "end": "714399"
  },
  {
    "text": "and what we see here is that the pebble",
    "start": "714399",
    "end": "716959"
  },
  {
    "text": "approach",
    "start": "716959",
    "end": "717839"
  },
  {
    "text": "um which uh uses soft anti-critic",
    "start": "717839",
    "end": "723040"
  },
  {
    "text": "scores the best what are we comparing",
    "start": "723200",
    "end": "725040"
  },
  {
    "text": "with so the green",
    "start": "725040",
    "end": "726399"
  },
  {
    "text": "green curve and yellow curve are pebble",
    "start": "726399",
    "end": "729040"
  },
  {
    "text": "red",
    "start": "729040",
    "end": "729600"
  },
  {
    "text": "which is slightly running on top of that",
    "start": "729600",
    "end": "731360"
  },
  {
    "text": "is the oracle approach",
    "start": "731360",
    "end": "733200"
  },
  {
    "text": "which is giving it access to a ground",
    "start": "733200",
    "end": "735120"
  },
  {
    "text": "truth reward function which is very",
    "start": "735120",
    "end": "736800"
  },
  {
    "text": "carefully designed which is",
    "start": "736800",
    "end": "738240"
  },
  {
    "text": "often impractical but which we did here",
    "start": "738240",
    "end": "740399"
  },
  {
    "text": "for evaluation purposes",
    "start": "740399",
    "end": "742320"
  },
  {
    "text": "so red is the oracle green and yellow",
    "start": "742320",
    "end": "745440"
  },
  {
    "text": "are our approach",
    "start": "745440",
    "end": "746480"
  },
  {
    "text": "and it's actually getting very close to",
    "start": "746480",
    "end": "747920"
  },
  {
    "text": "the oracle in most of these uh",
    "start": "747920",
    "end": "749760"
  },
  {
    "text": "runs and then uh the black",
    "start": "749760",
    "end": "753200"
  },
  {
    "text": "blue and purple are a prior approach uh",
    "start": "753200",
    "end": "755920"
  },
  {
    "text": "preference ppo",
    "start": "755920",
    "end": "757120"
  },
  {
    "text": "which we see is not as effective and",
    "start": "757120",
    "end": "758720"
  },
  {
    "text": "seems to saturate at lower levels",
    "start": "758720",
    "end": "760959"
  },
  {
    "text": "of performance",
    "start": "760959",
    "end": "763839"
  },
  {
    "start": "763000",
    "end": "833000"
  },
  {
    "text": "so in summary uh reinforcement",
    "start": "764480",
    "end": "767920"
  },
  {
    "text": "algorithms are becoming very effective",
    "start": "767920",
    "end": "769920"
  },
  {
    "text": "at optimizing reward",
    "start": "769920",
    "end": "771440"
  },
  {
    "text": "as we've seen in many environments",
    "start": "771440",
    "end": "772800"
  },
  {
    "text": "including go",
    "start": "772800",
    "end": "774560"
  },
  {
    "text": "but outside of games it's actually very",
    "start": "774560",
    "end": "777279"
  },
  {
    "text": "hard often to specify the reward",
    "start": "777279",
    "end": "779279"
  },
  {
    "text": "function",
    "start": "779279",
    "end": "780160"
  },
  {
    "text": "correctly what we've been working on and",
    "start": "780160",
    "end": "784079"
  },
  {
    "text": "i think will be a very important trend",
    "start": "784079",
    "end": "785519"
  },
  {
    "text": "going forward as people try to deploy",
    "start": "785519",
    "end": "788000"
  },
  {
    "text": "reinforcement learning for real world",
    "start": "788000",
    "end": "789760"
  },
  {
    "text": "problems is",
    "start": "789760",
    "end": "791200"
  },
  {
    "text": "a way to sidestep the need to hand",
    "start": "791200",
    "end": "794720"
  },
  {
    "text": "specify a reward function",
    "start": "794720",
    "end": "797200"
  },
  {
    "text": "and instead rely on human input",
    "start": "797200",
    "end": "800480"
  },
  {
    "text": "so while the learning is happening a",
    "start": "800480",
    "end": "802560"
  },
  {
    "text": "human watches the learning",
    "start": "802560",
    "end": "804399"
  },
  {
    "text": "and provides preferences between",
    "start": "804399",
    "end": "806320"
  },
  {
    "text": "different rollouts",
    "start": "806320",
    "end": "807920"
  },
  {
    "text": "then under the hood there will be a",
    "start": "807920",
    "end": "810399"
  },
  {
    "text": "reward function that's learned from that",
    "start": "810399",
    "end": "812160"
  },
  {
    "text": "which is optimized against",
    "start": "812160",
    "end": "814160"
  },
  {
    "text": "and then this process iterates several",
    "start": "814160",
    "end": "816560"
  },
  {
    "text": "times over",
    "start": "816560",
    "end": "817760"
  },
  {
    "text": "until we converge and get behaviors out",
    "start": "817760",
    "end": "820639"
  },
  {
    "text": "that actually match what the human",
    "start": "820639",
    "end": "822480"
  },
  {
    "text": "supervisor wants as opposed to a highly",
    "start": "822480",
    "end": "825680"
  },
  {
    "text": "optimized behavior that might actually",
    "start": "825680",
    "end": "827360"
  },
  {
    "text": "not be what we want",
    "start": "827360",
    "end": "830399"
  },
  {
    "text": "thank you",
    "start": "830399",
    "end": "835600"
  }
]